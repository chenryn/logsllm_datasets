2.7.4
Hardware Overflow Protection
Buffer overflows have been so troublesome for software developers (and so nice for
hackers) that both hardware and software protections have been developed. In this
section two hardware/software solutions are shown.
2.7.4.1
Secure Bit
Secure bit is an example of a hardware/software overflow solution, which is cur-
rently under study at Michigan State University. Secure bit is a patent pending tech-
nology developed to help reduce the risks of buffer overflow attacks on control data
(return addresses and function pointers). Secure bit requires hardware (processor)
and kernel OS modifications. Secure bit is transparent to user software and is com-
patible with legacy code.
Secure bit works by marking addresses passed between buffers as insecure. This
is also known as user input tainting. Once data has been tainted, there is no way to
unmark it. If control instructions try to use these marked addresses, an exception is
raised. Robustness and minimal run-time impact are two impressive elements of the
secure bit technology.30
2.7
Defenses
65
30R. Enbody and K. Piromsopa, “Secure Bit: Transparent, Hardware Buffer-Overflow Protection,”
IEEE Transactions on Dependable and Secure Computing,” 3(4)(October 2006): 365–376.
ISSN:1545-5971
2.7.4.2
Hardware DEP
Data execution protection is a Microsoft hardware/software solution to perform
additional checks to help prevent malicious exploits from executing in memory. In
Windows Server 2003 with Service Pack 1, XP SP2, and Vista, DEP is enforced by
both hardware and software.
Hardware-enforced DEP marks all noncode segments in a process as nonexe-
cutable unless the location explicitly contains executable code. Attacks such as
overflows attempt to insert and execute code from nonexecutable memory loca-
tions, such as the stack or heap. DEP helps prevent these attacks by raising an
exception when execution is attempted from such locations.
Hardware-enforced DEP relies on processor hardware to mark memory with an
attribute that indicates that code should not be executed from that memory. DEP
functions on a per-virtual-memory-page basis, usually changing a bit in the page
table entry (PTE) to mark the memory page.
The actual hardware implementation of DEP and marking of the virtual mem-
ory page varies by processor architecture. However, processors that support
hardware-enforced DEP are capable of raising an exception when code is executed
from a page marked with the appropriate attribute set.
Both Advanced Micro Devices (AMD) and Intel Corporation have defined and
shipped Windows-compatible architectures that are compatible with DEP.
32-bit versions of Windows Server 2003 with Service Pack 1 utilize the no-
execute page-protection (NX) processor feature as defined by AMD or the Execute
Disable bit (XD) feature as defined by Intel. In order to use these processor features,
the processor must be running in Physical Address Extension (PAE) mode. The 64-
bit versions of Windows use the NX or XD processor feature on 64-bit extension
processors and certain values of the access rights page table entry (PTE) field on
IPF processors.31
2.7.5
Software Overflow Protection
This section will present some of the software protections that are available to try
to mitigate the effects of buffer overflows. The idea is that no one protection is suf-
ficient and that a “defense in depth” strategy is required.
2.7.5.1
GS
The Buffer Security Check (“/GS” compile flag) is a Microsoft Visual Studio C++
compile option that works by placing a “cookie” (referred to as a “canary” in other
technologies) on the stack, between the return address and local variables, as each
function is called. This cookie is initialized to a new value each time the application
is run. The integrity of the cookie is checked before a function returns. If a buffer
overflow occurred, which normally overwrites a contiguous block of data values,
66
Software Vulnerability Analysis
31http://technet2.microsoft.com/windowsserver/en/library/b0de1052-4101-44c3-a294-4da1bd1ef
2271033.mspx?mfr=true
the cookie will have been altered, and the application will terminate with an error.
Guessing the cookie value is difficult, but much work has been done on defeating
canary-based stack protection.32,33
2.7.5.2
Software DEP
An additional set of DEP security checks has been added to Windows Server 2003
with Service Pack 1. These checks, known as software-enforced DEP, are designed
to mitigate exploits of exception handling mechanisms in Windows. Software-
enforced DEP runs on any processor that is capable of running Windows Server
2003 with Service Pack 1. By default, software-enforced DEP protects only lim-
ited system binaries, regardless of the hardware-enforced DEP capabilities of the
processor.
Software-enforced DEP performs additional checks on exception handling
mechanisms in Windows. If the program’s image files are built with Safe Structured
Exception Handling (SafeSEH), software-enforced DEP ensures that before an
exception is dispatched, the exception handler is registered in the function table
located within the image file.
If the program’s image files are not built with SafeSEH, software-enforced DEP
ensures that before an exception is dispatched, the exception handler is located
within a memory region marked as executable.
2.7.5.3
SafeSEH and more
Figure 2.9 shows all of the security enhancements added in the Vista platform. Each
of these will not be explained as that is not the focus of this book. However, a few
of the hardware and software protections have been discussed. SafeSEH will be fur-
ther detailed because it is very interesting to hackers.
There is a class of attacks used by hackers and security researchers, against
Windows, called an SEH overwrite. SEH is short for Structured Exception Han-
dler. In the case of a stack overflow, even if a return address cannot be affected, if
an exception handler address can be overwritten, malicious execution control can
still be obtained. On the next exception, Windows will attempt to execute code at
the address pointed to by the overwritten exception pointer. To limit the success of
such attacks, Microsoft developed SafeSEH, which is the heart of the Software DEP
described in the previous section. Again, SafeSEH works by not allowing an SEH
pointer to be an arbitrary value. It must point to a registered exception handler (as
opposed to some spot in the heap or stack like an attacker would prefer). However,
if the attack returns to code in a .211 not protected by SafeSEH, the attack may
still succeed.
2.7
Defenses
67
32D. Litchfield, “Defeating the Stack Based Overflow Prevention Mechanism of Microsoft Windows
2003 Server,” Sept. 2003, www.ngssoftware.com/papers/defeating-w2k3-stack-protection.pdf
33Analysis of GS protections in Microsoft® Windows Vista(tm) Ollie Whitehouse, Architect,
Symantec Advanced Threat Research. www.symantec.com/avcenter/reference/GS_Protections_
in_Vista.pdf
2.7.5.4
PAX and ExecShield
PAX from the GRSec family of kernel patches and ExecShield (originally from Red-
Hat) are both methods of marking data memory as nonexecutable and by marking
the program memory as nonwritable (on the Linux operating systems). The result
of these protections is the lack of memory pages that are both writable and exe-
cutable. This method helps to protect the system from code that has been injected
into the process through a vulnerability. Although there has been heated debate and
exploit workarounds for both of these solutions, it is an excellent safeguard against
most generic exploitation attempts. The exact implementation of these technolo-
gies has subtle differences, and is worth investigating.
2.7.5.5
StackGuard
StackGuard is also a protection mechanism on Linux, but uses a slightly different
method than the previous two protections mentioned. It is more akin to the GS
compiler flag from Microsoft. StackGuard uses a canary value that gets checked
after a function call, and when destroyed, shows that a stack overflow has occurred
somewhere in the preceding code.
2.8
Summary
Fuzzing used to be a secretive activity. Although developed through publicly avail-
able research, mostly only government agencies and underground hackers per-
formed fuzzing as part of their vulnerability assessment practices. But now, as is
68
Software Vulnerability Analysis
Figure 2.9
Overview of Microsoft Windows Vista’s security enhancements.34
34”Security Implications of Microsoft® Windows Vista™,” Symantec Advanced Threat Research,
www.symantec.com/avcenter/reference/Security_Implications_of_Windows_Vista.pdf
evidenced by this book, it is an openly talked about subject. As fuzzing blends more
and more with the software development process, university courses that talk about
fuzzing have appeared. Fuzzing is already a frequent subject at most security con-
ferences like BlackHat, Defcon, Chaos Communication Congress (CCC), CanSecWest,
and Toorcon. A large percent of all vulnerabilities are reported to have been found
via fuzz testing.
Chapter 2 was intended to whet one’s appetite for bug hunting by presenting
various types of bugs, defenses, security career paths, and more. This hopefully
made you hunger for the more in-depth chapters on fuzzing and available fuzz
tools, as well as gave you a solid introduction into the security mindset and com-
munity experiences of those who have worked for years in security.
2.8
Summary
69
C H A P T E R  3
Quality Assurance and Testing
The purpose of this chapter is to give you some relevant background information if
you would like to integrate any form of fuzzing into your standard software testing
processes. This topic may be familiar to you if you have experience in any type of
testing including fuzzing as part of the software development process. You might
disagree with some of the arguments presented. This is not exactly the same infor-
mation you would find in generic testing textbooks, rather, it is based on our prac-
tical real-life experience. And your experience might differ from ours.
Our purpose is not to describe testing processes and experiences, but we urge
you to look for a book on testing techniques, if you are interested in learning more
on this topic. Indeed, many of the topics discussed in this chapter are much better
explained in the amazing book called Software Testing Techniques, 2nd edition,
written by Boris Beizer in 1990. We highly recommend that you read that book if
you work in a testing profession. In this chapter, we will look at fuzzing from the
eyes of a quality assurance professional, identifying the challenges of integrating
fuzzing in your QA methods. We will leverage the similar nature of fuzzing when
compared to more traditional testing techniques in functional testing.
For readers with a security background, this chapter gives an overview of the
quality assurance techniques typically used in the software development life cycle
(SDLC), with the purpose of introducing common terminology and definitions.
The focus is on testing approaches that are relevant to fuzzing techniques,
although we briefly mention other techniques. To those who are new to both the
security assessment and testing scenes, we provide all the information you will need
to get started. We also recommend further reading that will give you more detailed
information on any of the presented testing approaches.
3.1
Quality Assurance and Security
How is quality assurance relevant to the topic of fuzzing? In short, software qual-
ity issues, such as design flaws or programming flaws, are the main reason behind
most, if not all, known software vulnerabilities. Quality assurance practices such as
validation and verification, and especially software testing, are proactive measures
used to prevent the introduction of such flaws, and to catch those quality flaws that
are left in a product or service before its initial release. Fuzzing is one of the tools
that will help in that process.
On the other hand, traditional vulnerability assurance practices have typi-
cally taken place in a very late phase of the software development life cycle. Most
71
security assessments are reactive: They react to security-related discoveries (bugs) in
software. They focus on protecting you from known attacks and in identifying known
vulnerabilities in already deployed systems. Although traditional security assessment,
consisting of running security scanners and other vulnerability detection tools, does
not attempt to find anything new and unique, it is still well suited for post-deployment
processes. But for really efficient QA purposes, we need something else.
The main reason why we will discuss quality assurance in this book is to show
how current quality assurance processes can be improved if fuzzing is integrated
within them. Fuzzing is very different from vulnerability scanners, as its purpose is
to find new, previously undetected flaws. The discovery of those flaws after deploy-
ment of the software is costly. Fuzzing tools are very much like any traditional test-
ing tools used in quality assurance practices. Still, unfortunately, fuzzing is often
not part of the product development process. Security assessment using fuzzing is
almost always performed on a completed or even deployed product. Only vulnera-
bility assessment professionals usually conduct fuzzing. Hopefully, this will begin to
change as testers realize the utility that fuzzing can bring to the process.
Quality assurance is also an interesting topic to vulnerability assessment people
due to the possibility of learning from those practices. Although security experts
often focus on looking for known vulnerabilities in released products, sometimes
the processes and tools used by security assessment experts can be very similar to
those used by quality assurance professionals who take a more proactive approach.
Vulnerability assessment professionals already use many of those same processes
and tools, as you will see.
3.1.1
Security in Software Development
Security testing, as part of a quality assurance process, is a tough domain to explain.
This is partly because of the vagueness of the definition. As far as we know, there
is no clear definition for security testing. Far too many product managers view
security as a feature to be added during software development. Also, for some end
users, security is a necessary but very difficult-to-define property that needs to be
added to communications products and services. Both of these definitions are
partly correct, as many security requirements are fulfilled with various security
mechanisms.
Think of encryption or authentication. These are typical security features that
are implemented to protect against various mistakes related to confidentiality and
integrity. A security requirement will define a security mechanism, and testing for
that requirement can sometimes be very difficult. Some R&D managers have a mis-
conception that when all security requirements have been tested, the security test is
complete. For example, a team of developers at a company we worked with felt
they had excellent security and had designed their applications with security in
mind at every step of development. They implemented complex authentication and
authorization code and utilized strong encryption at all times. However, they had
never heard of buffer overflows and command injection flaws, or didn’t think they
were relevant. Consequently, their applications were vulnerable to many of these
implementation-level vulnerabilities.
72
Quality Assurance and Testing
3.1.2
Security Defects
One of the main reasons behind compromises of security are implementation mis-
takes—simple programming errors that enable the existence of security vulnerabil-
ities—and the existence of attacks such as viruses and worms that exploit those
vulnerabilities. End users neither care to nor have the skills necessary to assess the
security of applications. They rely on quality assurance professionals and, unwit-
tingly, on security researchers.
Certainly, some security features may be of interest to end users, such as the
presence and strength of encryption. Nevertheless, flaws such as buffer overflows or
cross-site scripting issues comprise a majority of security incidents, and malicious
hackers abuse them on a daily basis. It is uncommon that anyone actually exploits
a flaw in the design of a security mechanism, partly because those techniques are
today based on industry-proven reusable libraries. For example, very few people
will implement their own encryption algorithm. In general, it is a very bad idea to
implement your own security library, as you are almost doomed to fail in your
attempt. This is another example in which it doesn’t make sense to reinvent the
wheel.
In software development, quality assurance practices are responsible for the dis-
covery and correction of these types of flaws created during the implementation
and design of the software.
3.2
Measuring Quality
What is “good enough” quality? How do we define quality? And how can we meas-
ure against that quality definition? These are important questions, especially be-
cause it is impossible with current technologies to make complex code perfect. In all
quality assurance-related efforts, we need to be able to say when the product is
ready. Like the software developer who defines code as being ready by stating that
“it compiles,” at some point testers need to be able to say “it works and is mostly
free of bugs.” But, as everyone knows, software is far from ready when it compiles
for the first time. In similar fashion, it is very difficult to say when software really
works correctly.
Similarly, product security is also a challenging metric. When can we say that a
product is “secure enough,” and what are the security measures needed for that?
3.2.1
Quality Is About Validation of Features
The simplest measurement used in testing is checking against the features or use
cases defined in the requirement or test specifications. These requirements are then
directly mapped to individual test cases. If a test cycle consists of a thousand tests,
then each test has to have a test verdict that defines whether it passed or failed.
A requirement for systematic testing is that you know the test purpose before-
hand. This is the opposite to “kiddie testing,” in which any bug found in the test is
a good result, and before the test is started there is very little forecast as to what might
3.2
Measuring Quality
73
be found. Note that we do not want to downplay this approach! On the contrary!
Any exploratory testing approaches are very good at testing outside the specifica-
tions, and a good exploratory tester will always find unexpected flaws in software.
The “out-of-the-box” perspective of exploratory testing can reveal bugs that might
be missed by testers blinded by the specifications. But there is always a risk involved
when the quality of the tests is based on chance and on the skills of the individual
tester.
Common technique for defining test success in functional, feature-oriented
black-box testing is by using an input/output oracle, which defines the right coun-
terpart for each request (or the right request to each response if testing client soft-
ware). Similarly, if you are able to monitor the internals of the software, an oracle
can define the right internal actions that have to be performed in a test.
A 100% success rate based on feature testing means everything that was spec-
ified in the test specification was tested, and the software passed the specified tests.
This metric is very feature-oriented, as it can be very challenging to proactively
assign verdicts to some tests during the test specification phase.
Fuzzing is an excellent example in which a test can consist of millions of test
cases, and whether each test case passes or fails is very difficult to assess. A strict test
plan that requires a pass/fail criterion for every single test case in the specification
phase will restrict the introduction of new testing techniques such as fuzzing. Let’s
look at an example from the fuzzing perspective.
In the protocol standardization side, IETF has defined a set of tests for testing
different anomalous communication inputs for the SIP1 protocol. IETF calls these
test specifications “torture tests.” Many commercial test tools implement these
tests, but when you think about them from a fuzzing perspective, the test coverage
in these specifications is very limited. An example test description from SIP
RFC4475 is shown below:
3.1.2.4.
Request Scalar Fields with Overlarge Values
This request contains several scalar header field values outside
their legal range.
o
The CSeq sequence number is >2**32-1.
o
The Max-Forwards value is >255.
o
The Expires value is >2**32-1.
o
The Contact expires parameter value is >2**32-1.
An element receiving this request should respond with a 400 Bad
Request due to the CSeq error. If only the Max-Forwards field were
in error, the element could choose to process the request as if the
field were absent. If only the expiry values were in error, the
element could treat them as if they contained the default values for
expiration (3600 in this case).