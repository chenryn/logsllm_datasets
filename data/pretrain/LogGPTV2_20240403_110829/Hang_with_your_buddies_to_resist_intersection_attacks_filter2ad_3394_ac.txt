either temporarily or permanently. This policy has the ad-
vantage of not reducing the usability of N , or artiﬁcially
delaying the time at which the user’s posts appear, as long
as the possinymity set remains above-threshold. Once N ’s
possinymity set reaches the set threshold, however, all of
the users remaining in this set become critical, in that N
becomes unusable for posting once any remaining member
goes oﬄine. In the “dissident scenario” we envision this event
might be the user’s signal to move to a new network location:
e.g., get a fresh IP address at a diﬀerent Internet cafe.
Limiting Possinymity Loss Rate.
An alternative, or complementary, goal is to reduce the
rate at which N ’s possinymity decreases. In realistic scenar-
ios, as our trace data in Section 5 illustrates, clients often get
delayed or disconnected temporarily but return soon there-
after. Thus, a more reﬁned policy might temporarily halt all
posting for Nym N —by returning Pi = ∅—when members
of N ’s current possinymity set go oﬄine, in hopes that the
missing members will soon return. To ensure progress and
get N “unstuck” if members remain oﬄine for a suﬃcient
number of rounds, however, the policy eliminates these per-
sistently oﬄine members from N ’s permanent possinymity
set by returning a smaller (but nonempty) Pi. Such a pol-
icy may “ﬁlter out” possinymity set losses due to otherwise-
reliable users going oﬄine brieﬂy, at the cost of delaying a
user’s posting to Nym N for a few rounds if some current
possinymity set member goes oﬄine permanently. Of course,
a loss rate limiting policy may readily be combined with
a threshold-maintaining policy of the form above. A fur-
ther reﬁnement of this combination might be to increase the
loss limiting policy’s “tolerance”—number of rounds a user
may remain oﬄine before being eliminated—as the Nym’s
possinymity set size falls to approach the user’s speciﬁed
lower bound. Such a policy in essence trades more tempo-
rary unavailability for greater total Nym longevity.
Users Worth Waiting For.
While the above simple variants suggest starting points,
we envision many ways to reﬁne policies further, for example
by recognizing that a user’s record of past reliability is often
a predictor of future reliability. To maximize a Nym N ’s
possinymity and minimize anonymity loss rate, while also
limiting delays caused by unreliable users, we may wish to
consider some members of N ’s current possinymity set to be
“more valuable” than others: e.g., users who have remained
online and participating reliably for a long period with at
most a few brief oﬄine periods. In particular, a policy might
apply an oﬄine-time threshold as discussed above to limit
loss rate, but apply diﬀerent thresholds to diﬀerent members
of N ’s current possinymity set, giving longer, more generous
thresholds to more “valued” users.
The Policy Oracle can build up reliability information
about users starting when those users ﬁrst appear—not just
when a particular pseudonym of interest is created. Thus,
a policy that Buddies applies to a particular Nym N can
beneﬁt from user history state that the Policy Oracle may
have built up since long before N was created.
3.2 Guaranteeing Minimum Indinymity
The possinymity metric considers intersection attacks only
across rounds in which non-null messages appear, but in
realistic chat or blogging scenarios a user’s posts will be
interspersed with idle periods during which no message ap-
pears. A smarter adversary can use the predictive techniques
discussed in Section 2.3.2 to glean probabilistic information
from such rounds. We therefore wish to guarantee users some
level of indinymity, even under probabilistic attacks.
Forming and Enforcing Buddy-Sets.
To guarantee a Nym N will have a minimum indinymity of
some value K, the Policy Oracle must ensure that all of N ’s
buddy-sets—subsets of users whose members exhibit iden-
tical online behavior across rounds after user ﬁltering—are
all of size at least K. As a straw-man approach to buddy-
set formation, on the creation of Nym N , the Policy Oracle
could divide N ’s initial user roster M into (cid:98)|M|/K(cid:99) arbitrary
buddy-sets “up-front,” each containing at least K users. At
step 5 of each round i, for each buddy-set B containing any
oﬄine user u (cid:54)∈ Oi, the Policy Oracle removes all mem-
bers of u’s buddy set B from its ﬁltered user set Pi. The
1157Policy Oracle eﬀectively forces members of each buddy set
to come online or go oﬄine “in unison,” keeping them per-
manently indistinguishable under probabilistic intersection
attack (even if the adversary can distinguish one buddy set
from another). This straw-man policy is likely to yield poor
availability, however, as it prevents N ’s owner from posting
whenever any member of the owner’s buddy-set is oﬄine,
making N unusable in the fairly likely event that any mem-
ber of this buddy set is unreliable or disappears permanently.
Lazy Buddy-Set Formation.
As a ﬁrst reﬁnement, therefore, the Policy Oracle can de-
lay buddy-set decisions until users actually go oﬄine. At cre-
ation, a Nym N starts with one large buddy-set containing
its entire user roster M. In the ﬁrst round i in which mem-
ber(s) of M go oﬄine, the Policy Oracle might ﬁrst delay all
posting for Nym N by returning Pi = ∅, in hopes the miss-
ing member(s) will return online soon, as discussed above.
Once the Policy Oracle “gives up” on one or more members,
however, it splits N ’s current buddy-sets into two, isolat-
ing all persistently oﬄine members into one of the resulting
buddy-sets. By delaying the decision of how to split buddy-
sets, the Policy Oracle guarantees that after the split-point,
the buddy-set containing only online members will have a
chance to “make progress”—at least until more users go of-
ﬂine for suﬃciently long to force another buddy set split.
After a split, each of of the resulting buddy-sets must be
at least of size K to maintain an indinymity lower bound. If
fewer than K total users are actually oﬄine (|M−Oi| < K),
then the Policy Oracle must “sacriﬁce” a few online users,
placing them in the oﬄine users’ buddy-set. Otherwise, if
for example a single oﬄine user forcing a split is actually the
owner of Nym N , then placing the oﬄine user in a buddy
set of size 1 would quickly reveal to a probabilistic attacker
that the now-oﬄine user owned the pseudonym, once the
attacker notices that posts have stopped appearing on Nym
N . By “sacriﬁcing” K − 1 additional users at the split point,
even if the attacker infers from the absence of posts that
N ’s owner is in the now-oﬄine buddy-set, he cannot tell
whether the owner is the user who caused the split, or is one
of those sacriﬁced and forced oﬄine to “keep him company.”
If the oﬄine users in a buddy set eventually return online,
then the whole buddy set rejoins in unison, making the Nym
usable again if the owner was a member of this buddy set.
Choosing Whom to Sacriﬁce.
When the Policy Oracle must “sacriﬁce” online users to
pad an oﬄine buddy set to size K, an important issue is how
to choose which online users to sacriﬁce. We investigated two
classes of sacriﬁcial policies: random, and least reliable users.
Random choice clusters users into buddy sets regardless of
reliability, which is simple but risks sacriﬁcing reliable users
by mixing them into buddy sets containing unreliable or
permanently oﬄine users. Alternatively, the Policy Oracle
might ﬁrst sacriﬁce users with the weakest historical record
of reliability: e.g., users who arrived recently or exhibited
long oﬄine periods. By this heuristic we hope to retain the
most reliable users in the buddy set that remains online
immediately after the split—though this buddy set may split
further if more nodes go oﬄine in the future.
We expect reliability-sensitive policies to maximize a Nym’s
eﬀective lifetime, provided the Nym’s true owner is one of the
more reliable users and does not get sacriﬁced into an un-
reliable or permanently oﬄine buddy set. A short-lived or
unreliable user cannot expect his Nyms to be long-lived in
any case: a long-lived Nym must have a “base” of reliable,
long-lived users to maintain anonymity under intersection
attack, and the Nym’s owner must obviously be a member
of the long-lived anonymity set he wishes to “hide in.”
3.3 Varying Policies and Nym Independence
So far we have assumed the Policy Oracle enforces a “global
policy” on all Nyms, but this would limit ﬂexibility and per-
haps unrealistically require all users to “agree on” one pol-
icy. Instead, Buddies allows each Nym to have a separate
policy—e.g., diﬀerent lower bounds and anonymity loss mit-
igation tradeoﬀs—chosen by the Nym’s owner.
Since intersection attacks are by deﬁnition not an issue
until a Nym N has been in use for more than one round,
N ’s owner speciﬁes the policy parameters for a Nym N in
its ﬁrst post to N . The set of users online in this ﬁrst message
round, in which N ’s policy is set, forms N ’s initial user roster
M, which is also by deﬁnition the maximum anonymity set
N can ever achieve under intersection attack. In subsequent
rounds in which Nym N is scheduled, the announced policy
for N determines the Policy Oracle’s behavior in ﬁltering
N ’s user sets to mitigate intersection attacks.
Each Nym’s policy is thus independent of other Nyms—
including other Nyms owned by the same user. This policy
independence, and the correctness of Section 2’s analysis,
depend on the assumption made in Section 2.1 that the An-
onymizer assigns Nyms to users uniformly at random and
independent of all other Nyms. Otherwise, the choices the
Policy Oracle makes on behalf of one Nym might well leak
information about other Nyms. This leads to some speciﬁc
design challenges addressed below in Section 4.2.
To illustrate the importance of independent Nym assign-
ment, suppose there are two users, to whom the Anonymizer
non-independently issues two Nyms N1 and N2, via a ran-
dom 1-to-1 permutation—always giving each user exactly
one Nym. In the ﬁrst communication round, N1’s owner an-
nounces a weak policy with a minimum buddy set size of 1,
but N2 demands a buddy set size of 2. The adversary later
sees a non-null post to N1 while user B is oﬄine, and as N1’s
weak policy permits, infers that A must own N1. If each user
owns exactly one Nym, then the adversary can also infer that
B must own N2, violating N2’s stronger policy. With inde-
pendent Nym assignment, in contrast, the knowledge that
A owns N1 gives the adversary no information about which
user owns N2, because it is just as likely that A owns both
N1 and N2, as it is that each user owns exactly one Nym.
4. BUDDIES IN PRACTICAL SYSTEMS
Since Buddies’ conceptual model in Section 2 is unrealisti-
cally simple in several ways, we now address key challenges
of implementing Buddies in practical anonymity systems.
For concreteness we will focus on the design of our Buddies
prototype built as an extension to Dissent [11, 13, 52], but
we also discuss the Buddies architecture’s potential applica-
bility to other existing anonymous communication systems.
4.1 Decentralizing the Anonymizer
So far we have treated the Anonymizer as a trusted “black
box” component, but in a practical anonymity system we do
not wish to require users to trust any single component.
In a practical design, therefore, we replace Buddies’ Ano-
nymizer with one of the standard decentralized schemes for
1158anonymous message transmission, such as mix-nets [6,8,15],
DC-nets [9, 50], or veriﬁable shuﬄes [7, 25, 39].
While agnostic in principle to speciﬁc anonymous com-
munication mechanisms, Buddies makes two important as-
sumptions about the Anonymizer’s design. First, Buddies
assumes the Anonymizer is already resistant to basic, short-
term network-level traﬃc analysis and timing attacks [34,38,
45]. Without basic traﬃc analysis protection necessary for
unlinkable message traﬃc, we cannot expect to achieve reli-
able long-term protection for linkable posts via pseudonyms.
Second, we assume the Anonymizer distributes trust across
some group of servers, and that there exists at least one
trustworthy server in this group—although the user need not
know which server is trustworthy. This anytrust model [51] is
already embodied in the relays used in mix-nets or Tor cir-
cuits [18], the “authorities” assumed in veriﬁable shuﬄes [39],
or Dissent’s multi-provider cloud model [52].
While “ad hoc” mix-nets and onion routing schemes are
vulnerable to many traﬃc analysis and active attacks, vari-
ants such as MIX cascades [5,7,41] and veriﬁable shuﬄes [25,
39] oﬀer formally provable traﬃc analysis resistance. These
systems typically work in synchronous rounds, where users
submit onion-encrypted ciphertexts to a common set of mixes,
who serially decrypt and permute the ciphertexts to reveal
the anonymous plaintexts. To resist traﬃc analysis, users
with no useful message to send in a round must submit en-
crypted “empty” messages as cover traﬃc.
DC-nets [9, 50] similarly operate in synchronous rounds,
but derive anonymity from parallel information coding tech-
niques rather than serial mixing, achieving traﬃc analy-
sis protection in fewer communication hops. Dissent [11, 13,
52] adapts DC-nets to a practical and scalable client-server
model. By leveraging the parallel communication structure
of DC-nets, Dissent achieves per-round latencies orders of
magnitudes lower than a veriﬁable shuﬄe or cascade mix
guaranteeing equivalent security. Dissent thus forms a nat-
ural foundation for our Buddies prototype to build on.
4.2 Creating and Extending Nyms
Buddies can conveniently represent Nyms as public/private
key pairs, so that anyone may learn the public keys of all
Nyms in existence, but only a Nym’s owner holds the cor-
responding private key. Dissent runs Neﬀ’s veriﬁable key-
shuﬄe [39], once per communication epoch, to generate a list
of public keys forming a DC-nets transmission schedule for
that epoch. Each client submits one public key to the shuf-
ﬂe, which the servers re-encrypt and randomly permute, to
produce a well-known list of slot keys. The client holding a
slot’s matching key can identify its own slot, but neither the
servers nor other clients learn who owns any honest client’s
slot. Adapting this mechanism to create fresh Nyms in Bud-
dies introduces two further technical challenges: assigning
Nyms to users independently at random, and enabling Nyms
to have unlimited lifetimes.
Creating Nyms via Lotteries.
A simple way to create independent Nyms meeting the
requirements in Section 3.3 is by “lottery.” Each user sub-