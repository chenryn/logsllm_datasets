they can be combined for sophisticated verification tasks.
Counterexample Generation. Ding et al. [23] and Bichsel et al.
[14] proposed counterexample generators that rely on sampling –
running an algorithm hundreds of thousands of times to estimate
the output distribution of mechanisms (this information is then
used to find counterexamples). The strength of these methods is
that they do not rely on external solvers, and more importantly, they
are not tied to (the limitation of) any particular proof technique
(e.g., randomness alignment and coupling). However, sampling also
make the counterexample detectors imprecise and more likely to
fail in some cases, as confirmed in the evaluation.
7 CONCLUSIONS AND FUTURE WORK
We proposed CheckDP, an integrated tool based on static analysis
for automatically proving or disproving that a mechanism satisfies
differential privacy. Evaluation shows that CheckDP is able to pro-
vide proofs for a number of algorithms, as well as counterexamples
for their incorrect variants within 2 to 70 seconds. Moreover, all
generated proofs and counterexamples are validated.
For future work, CheckDP relies on the underlying randomness
alignment technique; hence it is subject to its limitations, including
lack of support for (ϵ, δ)-differential privacy and renyi differential
privacy [43]. We plan to extend the underlying proof technique for
other variants of differential privacy.
Moreover, subtle mechanisms such as PrivTree [52] and private
selection [39], where the costs of intermediate results are dependent
on the data but the cost of sum is data-independent, is still out of
reach for formal verification (including CheckDP).
Finally, CheckDP is designed for DP mechanisms, rather than
larger programs built on top of them. An interesting area of future
work is integrating CheckDP with tools like DFuzz [32], which are
more efficient on programs built on top of DP mechanisms (but
don’t verify the mechanisms themselves).
ACKNOWLEDGMENTS
We thank the anonymous reviewers for their insightful feedbacks.
This work was supported by NSF Awards CNS-1702760.
REFERENCES
[1] John M. Abowd. 2018. The U.S. Census Bureau Adopts Differential Privacy.
In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining (London, United Kingdom) (KDD ’18). ACM, New
York, NY, USA, 2867–2867.
[2] Alfred V Aho, Ravi Sethi, and Jeffrey D Ullman. 1986. Compilers, principles,
techniques. Addison wesley 7, 8 (1986), 9.
[3] Aws Albarghouthi and Justin Hsu. 2017. Synthesizing Coupling Proofs of Differ-
ential Privacy. Proceedings of ACM Programming Languages 2, POPL, Article 58
(Dec. 2017), 30 pages.
[4] Gilles Barthe, Rohit Chadha, Vishal Jagannath, A. Prasad Sistla, and Mahesh
Viswanathan. 2020. Deciding Differential Privacy for Programs with Finite
Inputs and Outputs. In Proceedings of the 35th Annual ACM/IEEE Symposium on
Logic in Computer Science (Saarbrücken, Germany) (LICS ’20). Association for
Computing Machinery, New York, NY, USA, 141–154. https://doi.org/10.1145/
3373718.3394796
[5] Gilles Barthe, George Danezis, Benjamin Gregoire, Cesar Kunz, and Santiago
Zanella-Beguelin. 2013. Verified Computational Differential Privacy with Appli-
cations to Smart Metering. In Proceedings of the 2013 IEEE 26th Computer Security
Foundations Symposium (CSF ’13). IEEE Computer Society, Washington, DC, USA,
287–301.
[6] Gilles Barthe, Pedro R. D’Argenio, and Tamara Rezk. 2004. Secure Information
Flow by Self-Composition. In Proceedings of the 17th IEEE Workshop on Computer
Security Foundations (CSFW ’04). IEEE Computer Society, Washington, DC, USA,
100–.
[7] Gilles Barthe, Noémie Fong, Marco Gaboardi, Benjamin Grégoire, Justin Hsu,
and Pierre-Yves Strub. 2016. Advanced Probabilistic Couplings for Differential
Privacy. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and
Communications Security (Vienna, Austria) (CCS ’16). ACM, New York, NY, USA,
55–67.
[8] Gilles Barthe, Marco Gaboardi, Emilio Jesús Gallego Arias, Justin Hsu, César
Kunz, and Pierre-Yves Strub. 2014. Proving Differential Privacy in Hoare Logic.
In Proceedings of the 2014 IEEE 27th Computer Security Foundations Symposium
(CSF ’14). IEEE Computer Society, Washington, DC, USA, 411–424.
[9] Gilles Barthe, Marco Gaboardi, Benjamin Grégoire, Justin Hsu, and Pierre-Yves
Strub. 2016. Proving Differential Privacy via Probabilistic Couplings. In Proceed-
ings of the 31st Annual ACM/IEEE Symposium on Logic in Computer Science (New
York, NY, USA) (LICS ’16). ACM, New York, NY, USA, 749–758.
[10] Gilles Barthe, Boris Köpf, Federico Olmedo, and Santiago Zanella Béguelin. 2012.
Probabilistic Relational Reasoning for Differential Privacy. In Proceedings of the
39th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages (Philadelphia, PA, USA) (POPL ’12). ACM, New York, NY, USA, 97–110.
[11] Gilles Barthe and Federico Olmedo. 2013. Beyond Differential Privacy: Compo-
sition Theorems and Relational Logic for f-divergences Between Probabilistic
Programs. In Proceedings of the 40th International Conference on Automata, Lan-
guages, and Programming - Volume Part II (Riga, Latvia) (ICALP’13). Springer-
Verlag, Berlin, Heidelberg, 49–60.
[12] Jean-Francois Bergeretti and Bernard A. Carré. 1985. Information-flow and Data-
flow Analysis of While-programs. ACM Trans. Program. Lang. Syst. 7, 1 (Jan.
1985), 37–61. https://doi.org/10.1145/2363.2366
[13] Dirk Beyer and M. Erkan Keremoglu. 2011. CPACHECKER: A Tool for Config-
urable Software Verification. In Proceedings of the 23rd International Conference
on Computer Aided Verification (Snowbird, UT) (CAV’11). Springer-Verlag, Berlin,
Heidelberg, 184–190.
[14] Benjamin Bichsel, Timon Gehr, Dana Drachsler-Cohen, Petar Tsankov, and Martin
Vechev. 2018. DP-Finder: Finding Differential Privacy Violations by Sampling and
Optimization. In Proceedings of the 2018 ACM SIGSAC Conference on Computer
and Communications Security (Toronto, Canada) (CCS ’18). ACM, New York, NY,
USA, 508–524.
[15] Andrea Bittau, Úlfar Erlingsson, Petros Maniatis, Ilya Mironov, Ananth Raghu-
nathan, David Lie, Mitch Rudominer, Ushasree Kode, Julien Tinnes, and Bernhard
Seefeld. 2017. Prochlo: Strong Privacy for Analytics in the Crowd. In Proceedings
of the 26th Symposium on Operating Systems Principles (Shanghai, China) (SOSP
’17). ACM, New York, NY, USA, 441–459. https://doi.org/10.1145/3132747.3132769
[16] Mark Bun and Thomas Steinke. 2016. Concentrated Differential Privacy: Sim-
plifications, Extensions, and Lower Bounds. In Proceedings, Part I, of the 14th
International Conference on Theory of Cryptography - Volume 9985. Springer-Verlag
New York, Inc., New York, NY, USA, 635–658.
13
[17] U. S. Census Bureau. 2019. On The Map: Longitudinal Employer-Household
https://lehd.ces.census.gov/applications/help/onthemap.html#
Dynamics.
!confidentiality_protection
[18] Cristian Cadar, Daniel Dunbar, and Dawson Engler. 2008. KLEE: Unassisted and
Automatic Generation of High-coverage Tests for Complex Systems Programs.
In Proceedings of the 8th USENIX Conference on Operating Systems Design and
Implementation (San Diego, California) (OSDI’08). USENIX Association, Berkeley,
CA, USA, 209–224. http://dl.acm.org/citation.cfm?id=1855741.1855756
[19] T.-H. Hubert Chan, Elaine Shi, and Dawn Song. 2011. Private and Continual
Release of Statistics. ACM Trans. Inf. Syst. Secur. 14, 3, Article 26 (Nov. 2011),
24 pages.
[20] Rui Chen, Qian Xiao, Yu Zhang, and Jianliang Xu. 2015. Differentially Private
High-Dimensional Data Publication via Sampling-Based Inference. In Proceedings
of the 21th ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining (Sydney, NSW, Australia) (KDD ’15). ACM, New York, NY, USA,
129–138. https://doi.org/10.1145/2783258.2783379
[21] Yan Chen and Ashwin Machanavajjhala. 2015. On the Privacy Properties of
Variants on the Sparse Vector Technique. http://arxiv.org/abs/1508.07306.
[22] Bolin Ding, Janardhan Kulkarni, and Sergey Yekhanin. 2017. Collecting Telemetry
Data Privately. In Proceedings of the 31st International Conference on Neural
Information Processing Systems (Long Beach, California, USA) (NIPS’17). Curran
Associates Inc., USA, 3574–3583. http://dl.acm.org/citation.cfm?id=3294996.
3295115
[23] Zeyu Ding, Yuxin Wang, Guanhong Wang, Danfeng Zhang, and Daniel Kifer.
2018. Detecting Violations of Differential Privacy. In Proceedings of the 2018 ACM
SIGSAC Conference on Computer and Communications Security (Toronto, Canada)
(CCS ’18). ACM, New York, NY, USA, 475–489.
[24] Zeyu Ding, Yuxin Wang, Danfeng Zhang, and Daniel Kifer. 2019. Free Gap Infor-
mation from the Differentially Private Sparse Vector and Noisy Max Mechanisms.
PVLDB 13, 3 (2019), 293–306. https://doi.org/10.14778/3368289.3368295
[25] Cynthia Dwork. 2006. Differential Privacy. In Proceedings of the 33rd International
Conference on Automata, Languages and Programming - Volume Part II (Venice,
Italy) (ICALP’06). Springer-Verlag, Berlin, Heidelberg, 1–12. https://doi.org/10.
1007/11787006_1
[26] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and
Moni Naor. 2006. Our Data, Ourselves: Privacy via Distributed Noise Generation.
In Proceedings of the 24th Annual International Conference on The Theory and
Applications of Cryptographic Techniques (St. Petersburg, Russia) (EUROCRYPT’06).
Springer-Verlag, Berlin, Heidelberg, 486–503.
[27] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. 2006. Cali-
brating Noise to Sensitivity in Private Data Analysis. In Theory of Cryptography,
Shai Halevi and Tal Rabin (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg,
265–284.
[28] Cynthia Dwork, Aaron Roth, et al. 2014. The algorithmic foundations of differ-
ential privacy. Theoretical Computer Science 9, 3–4 (2014), 211–407.
[29] Úlfar Erlingsson, Vasyl Pihur, and Aleksandra Korolova. 2014. RAPPOR: Ran-
domized Aggregatable Privacy-Preserving Ordinal Response. In Proceedings of
the 2014 ACM SIGSAC Conference on Computer and Communications Security
(Scottsdale, Arizona, USA) (CCS ’14). ACM, New York, NY, USA, 1054–1067.
[30] Gian Pietro Farina. 2020. Coupled Relational Symbolic Execution. Ph.D. Disserta-
tion. State University of New York at Buffalo.
[31] Jeanne Ferrante, Karl J Ottenstein, and Joe D Warren. 1987. The program de-
pendence graph and its use in optimization. ACM Transactions on Programming
Languages and Systems (TOPLAS) 9, 3 (1987), 319–349.
[32] Marco Gaboardi, Andreas Haeberlen, Justin Hsu, Arjun Narayan, and Benjamin C.
Pierce. 2013. Linear Dependent Types for Differential Privacy. In Proceedings of
the 40th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages (Rome, Italy) (POPL ’13). ACM, New York, NY, USA, 357–370. https:
//doi.org/10.1145/2429069.2429113
[33] Timon Gehr, Sasa Misailovic, and Martin Vechev. 2016. PSI: Exact Symbolic
Inference for Probabilistic Programs. In Computer Aided Verification, Swarat
Chaudhuri and Azadeh Farzan (Eds.). Springer International Publishing, Cham,
62–83.
[34] Anna Gilbert and Audra McMillan. 2018. Property Testing for Differential Privacy.
arXiv:1806.06427 [cs.CR]
[35] Samuel Haney, Ashwin Machanavajjhala, John M. Abowd, Matthew Graham,
Mark Kutzbach, and Lars Vilhuber. 2017. Utility Cost of Formal Privacy for
Releasing National Employer-Employee Statistics. In Proceedings of the 2017
ACM International Conference on Management of Data (Chicago, Illinois, USA)
(SIGMOD ’17). ACM, New York, NY, USA, 1339–1354. https://doi.org/10.1145/
3035918.3035940
[36] Noah Johnson, Joseph P Near, and Dawn Song. 2018. Towards practical differential
privacy for SQL queries. Proceedings of the VLDB Endowment 11, 5 (2018), 526–
539.
[37] Dexter Kozen. 1981. Semantics of probabilistic programs. J. Comput. System Sci.
[38] Jaewoo Lee and Christopher W. Clifton. 2014. Top-k Frequent Itemsets via Dif-
ferentially Private FP-trees. In Proceedings of the 20th ACM SIGKDD International
22, 3 (1981), 328 – 350.
[46] Armando Solar-Lezama, Liviu Tancau, Rastislav Bodik, Sanjit Seshia, and Vijay
Saraswat. 2006. Combinatorial Sketching for Finite Programs. In Proceedings of the
12th International Conference on Architectural Support for Programming Languages
and Operating Systems (San Jose, California, USA) (ASPLOS XII). Association for
Computing Machinery, New York, NY, USA, 404–415. https://doi.org/10.1145/
1168857.1168907
[47] Ben Stoddard, Yan Chen, and Ashwin Machanavajjhala. 2014. Differentially
Private Algorithms for Empirical Machine Learning. arXiv:1411.5428 [cs.LG]
[48] Apple Differential Privacy Team. 2017. Learning with Privacy at Scale. https:
//machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html
[49] Tachio Terauchi and Alex Aiken. 2005. Secure information flow as a safety
problem. In International Static Analysis Symposium. Springer, 352–367.
[50] Yuxin Wang, Zeyu Ding, Guanhong Wang, Daniel Kifer, and Danfeng Zhang. 2019.
Proving Differential Privacy with Shadow Execution. In Proceedings of the 40th
ACM SIGPLAN Conference on Programming Language Design and Implementation
(Phoenix, AZ, USA) (PLDI 2019). ACM, New York, NY, USA, 655–669. https:
//doi.org/10.1145/3314221.3314619
[51] Danfeng Zhang and Daniel Kifer. 2017. LightDP: Towards Automating Differential
Privacy Proofs. In Proceedings of the 44th ACM SIGPLAN Symposium on Principles
of Programming Languages (Paris, France) (POPL 2017). ACM, New York, NY,
USA, 888–901.
[52] Jun Zhang, Xiaokui Xiao, and Xing Xie. 2016. PrivTree: A Differentially Private
Algorithm for Hierarchical Decompositions. In Proceedings of the 2016 Interna-
tional Conference on Management of Data (San Francisco, California, USA) (SIG-
MOD ’16). Association for Computing Machinery, New York, NY, USA, 155–170.
https://doi.org/10.1145/2882903.2882928
Conference on Knowledge Discovery and Data Mining (New York, New York, USA)
(KDD ’14). ACM, New York, NY, USA, 931–940. https://doi.org/10.1145/2623330.
2623723
[39] Jingcheng Liu and Kunal Talwar. 2019. Private Selection from Private Candidates.
In Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing
(Phoenix, AZ, USA) (STOC 2019). Association for Computing Machinery, New
York, NY, USA, 298–309. https://doi.org/10.1145/3313276.3316377
[40] Min Lyu, Dong Su, and Ninghui Li. 2017. Understanding the sparse vector
technique for differential privacy. Proceedings of the VLDB Endowment 10, 6
(2017), 637–648.
[41] A. Machanavajjhala, D. Kifer, J. Abowd, J. Gehrke, and L. Vilhuber. 2008. Privacy:
Theory meets Practice on the Map. In 2008 IEEE 24th International Conference on
Data Engineering. IEEE, Piscataway, NJ, USA, 277–286. https://doi.org/10.1109/
ICDE.2008.4497436
[42] Frank McSherry. 2018. Uber’s differential privacy .. probably isn’t. https:
//github.com/frankmcsherry/blog/blob/master/posts/2018-02-25.md (retrieved
11/15/2019).
[43] I. Mironov. 2017. Rényi Differential Privacy. In 2017 IEEE 30th Computer Security
Foundations Symposium (CSF). IEEE, Piscataway, NJ, USA, 263–275. https://doi.
org/10.1109/CSF.2017.11
[44] Jason Reed and Benjamin C. Pierce. 2010. Distance Makes the Types Grow
Stronger: A Calculus for Differential Privacy. In Proceedings of the 15th ACM SIG-
PLAN International Conference on Functional Programming (Baltimore, Maryland,
USA) (ICFP ’10). ACM, New York, NY, USA, 157–168. https://doi.org/10.1145/
1863543.1863568
[45] Aaron Roth. 2011. The Sparse Vector Technique. http://www.cis.upenn.edu/
~aaroth/courses/slides/Lecture11.pdf.
14

butions (those µ such that
A CHECKDP SEMANTICS
Let A be a discrete set. The set of sub-distributions over A, writ-
ten Dist(A), to be the set of functions µ : A → [0, 1] such that
a∈A µ(a) ≤ 1. The reason to use sub-distributions instead of distri-
a∈A µ(a) = 1) is that sub-distributions
give rise to an elegant semantics for programs that do not nec-
essarily terminate [37]. We use 1a to represent the degenerate
distribution µ that µ(a) = 1 and µ(a′) = 0 if a′ (cid:44) a. Moreover, we
define monadic functions unit and bind functions to formalize the
semantics for commands:
unit : A → Dist(A) ≜ λa. 1a
bind : Dist(A) → (A → Dist(B)) → Dist(B)
≜ λµ. λ f . (λb.
(f a b) × µ(a))

a∈A
That is, unit takes an element in A and returns the Dirac distribu-
tion where all mass is assigned to a; bind takes µ, a distribution on
A, and f , a mapping from A to distributions on B (e.g., a conditional
distribution of B given A), and returns the corresponding marginal
distribution on B. This monadic view avoids cluttered definitions
and proofs when probabilistic programs are involved.
B SHADOW EXECUTION
We show how to extend the program transformation in Figure 3
to support shadow execution. At a high level, the extension en-
codes the selectors (which requires manual annotations in Shad-
owDP [50]) and integrates them with the generated templates. With
the extra “holes” in the templates, the verify-invalidate loop will au-
tomatically find alignments (including selectors)/counterexamples.
The complete set of transformation rules with shadow execution is
shown in Figure 7, where the extensions are highlighted in gray.
Syntax and Expressions. Since a new shadow execution is tracked,
types for each variable would be expanded to include a pair of dis-
tances ⟨d◦, d†⟩. More specifically, the types should now be defined
as: τ ::= num⟨d◦,d†⟩ | bool | list τ.
With the modified types, corresponding modifications to the
transformation rules for expressions are straightforward and mini-
mal: the handling of shadow distances are essentially the same as
that of aligned distances.
Normal Commands. Following the type system of ShadowDP,
a program counter pc ∈ {⊤,⊥} is introduced to each transforma-
tion rule for commands to capture potential divergence of shadow
execution. Specifically, pc ⊢ c ⇀ c′. pc = ⊤ (resp. ⊥) means that
the branch / loop command might diverge in the shadow execu-
tion (resp. must stay the same). The value of pc is used to guide
how each rule should handle the shadow distances (e.g., (T-Asgn)),
which we will explain shortly. Therefore, another auxiliary function
updatePC is added to track the value of pc.
Compared with the type system of ShadowDP, the first major
difference is in (T-Asgn). If pc = ⊥, shadow distances are handled
as the aligned distances. However, when pc = ⊤ (shadow execution
diverges), it updates the shadow distance of the variable to make
†) remains the same af-
ter the assignment. For example, Line 20 in Figure 8 is instrumented
†), so
sure the value in shadow execution (i.e., x +(cid:98)x
to maintain the value of bq in the shadow execution (bq +(cid:99)bq
15
that the branch at Line 26 is not affected by the new assignment of
bq.
x
(cid:76)r, Γ(cid:77)⋆ = r
, if Γ ⊢ x : num⟨n◦,n†⟩
, else