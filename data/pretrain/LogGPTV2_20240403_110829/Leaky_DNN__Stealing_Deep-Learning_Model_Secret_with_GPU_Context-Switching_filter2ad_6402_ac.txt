Weighted
Sum
FC
Softmax
Cross-Entropy
Sumif
Sum
Sumif
“syntax” about the order of ops and hyper-parameters (e.g.,
pooling should presume conv). Based on those insights, we
develop 5 LSTM models and one simple machine-learning
model (Mgap) for different tasks and assemble their results.
Below we overview the attack ﬂow (also illustrated in Fig-
ure 4). The structures of all LSTM models are shown in
Table III.
• Splitting iterations. After the attacker obtains CUPTI
samples, she splits them based on the gap between
consecutive iterations using an inference model Mgap.
• Recognizing long ops. The attacker looks into the sam-
ples within one iteration, and classiﬁes each one into
conv, MatMul or OtherOp using Mlong. Then, the
attacker combines the predicted ops across all iterations to
correct the misclassiﬁed ones, in a process called voting
using Vlong.
• Recognizing other ops. For other
layer ops (e.g.,
MaxPool) or activation functions (e.g., ReLU), the at-
tacker classiﬁes them using Mop. The attacker uses Vop
to vote and reﬁne the classiﬁcation result. OpSeq is
generated by combining all inferred ops.
• Inferring hyper-parameters. The attacker uses Mhp
to infer hyper-parameters related to ops and the whole
model (e.g., optimizer).
• Model correction. After the above steps, the adversary
corrects ops and hyper-parameters according to DNN
syntax.
After the above steps,
the attacker can reconstruct
the
victim’s model structure. In most cases,combinations of con-
secutive ops can be deterministically mapped to layers. For
example, a convolutional layer runs conv and BiasAdd,
while a fully-connected layer runs MatMul and BiasAdd.
However, when non-sequential connection between layers are
introduced, like shortcut used in ResNet [22], OpSeq could
reﬂect multiple model structures. We discuss this issue in
Section IV-C.
Selecting CUPTI counters. While Nvidia provides tens of
CUPTI counters, using all of them for MoSConS does not
lead to an optimal result. Firstly, some of them are always
zero or constant, revealing nothing about the victim. Secondly,
using more counters will increase the execution time of the
spy kernel, reducing the sampling rate. By checking the doc-
umentation, we found the counters are divided into multiple
groups and the execution time of a spy kernel depends on the
number of groups it access. In the end, we select 3 groups of
10 counters relevant to convolution or matrix multiplication
operations and they are listed in Table IV.
Fig. 4. Overview of attack ﬂow. The sample sequence of spy is split to
multiple iterations 1(cid:13). Then they are sent to Mlong, Mop and Mhp models to
predict the victim ops (e.g., N at 2(cid:13) and (R)elu, (P)ooling, (M)atMul
and (B)iasAdd at 3(cid:13)), hyper-parameters 4(cid:13) and optimizer 5(cid:13). Voting is done
by Vlong 7(cid:13) and Vop 6(cid:13) to correct mis-predicted ops. Finally, the victim’s
model structure is revealed after collapsing consecutive ops and correction
with model syntax ( 8(cid:13) 9(cid:13)).
A. Splitting Iterations
We choose to split the iterations ﬁrst because 1) voting
across layers cannot be achieved otherwise; 2) the gaps be-
tween consecutive iterations are easier to identify.
We develop a model (called Mgap) based on Light Gradient
Boosting Machine (LightGBM) [37] to classify each sample of
spy into NOP3 or BUSY. The input to the LightGBM is a vector
of CUPTI samples and each sample contains values from the
counters (all integer values) described in Table IV. Before
classiﬁcation, we also apply MinMaxScale to pre-process the
input and convert each feature value to be ranged from 0 to
1, in order to prevent training bias.
While the NOP sample is usually associated with the iter-
ation gap, we found sometimes it also exists within a layer.
On the other hand, the gap usually contains multiple NOP.
As such, we set a threshold T Hgap and split iterations if the
number of consecutive NOP is above T Hgap. Before moving
to the next step, we also need to identify the iterations with
invalid sample sequence and remove them. Those iterations
emerge because of incomplete sampling, e.g.,
the spy is
launched in the middle of a training iteration. To remove
them, we compare the number of samples to the average
across iterations. Assuming the average number of samples is
3We use NOP for simpler presentation. It does not mean that the GPU is
executing a NOP instruction.
7
RCavg and the lower-bound and upper-bound threshold ratios
are Rmin and Rmax, the samples of a valid iteration should
be within [RCavg ∗ Rmin, RCavg ∗ Rmax]. We elaborate on
the parameter choices in Section V-A.
B. Predicting OpSeq
Recognizing long ops. Spy’s primary goal
is to identify
convolutional layers and fully-connected layers, because they
have the biggest
impact on the performance of a CNN
model. During feed-forward training, a convolutional layer
sequentially invokes conv (e.g., Conv2D), BiasAdd and
an activation op (e.g., ReLU). During back-propagation, it
calculates the gradient in a reverse order using ops according
to the feed-forward pass (e.g., ReLUgrad, BiasAddGrad
and Conv2DBackprop). Fully-connected layer executes
MatMul, BiasAdd, and activation op like ReLU in feed-
forward training. Similarly to the convolutional
the
reverse of the feed-forward ops will be executed during
back-propagation (e.g., ReLUgrad, BiasAddGrad, and
MatMul).
layer,
Among those ops, conv and MatMul are easier to identify
because of their long execution time. We develop Mlong, an
LSTM model to classify each CUPTI sample into four classes:
conv, MatMul, OtherOp and NOP. LSTM is used for this
task because it has shown many successes in handling complex
time-series [31], [36] and can remember features over the long
term or short term.
Our LSTM model takes a vector of the selected counters
under a CUPTI sample as word input and outputs a four-
dimension vector, which contains the logit values of the 4
targeted classes. When training the LSTM model, we found
the number of samples for conv differs a lot from other ops,
leading to a very imbalanced training dataset. As a result,
using the samples for training under the default LSTM settings
would not yield good accuracy. To address this issue, we
designed weighted softmax and customized cross-entropy loss
to compensate for the imbalanced data. Speciﬁcally, when
calculating the loss for a sample, we calculate the softmax
and cross-entropy loss between the logits outputted by the
LSTM model and the ground-truth labels (the op names of
TensorFlow) processed by one-hot encoding. Then, the loss is
ampliﬁed by a constant if the sample is from the minor class.
Voting. DNN training usually takes many iterations and there-
fore the spy can obtain multiple predicted OpSeqs, which can
be combined to correct the erroneous predictions at individual
sequence. As such, we designed a voting procedure for error
correction.
Our voting model, named Vlong, is developed also based on
LSTM. The model consumes the output from Mlong over all
iterations to correct the mispredictions. The model is trained
with standard softmax and cross-entropy loss against ground-
truth. Speciﬁcally, when the attacker monitored n iterations,
the input would be a 4 ∗ n dimension vector where each 4-
dimension word is a one-hot prediction from one iteration.
To be noticed is that the predicted OpSeqs across iterations
need not be aligned before being inputted to the voting model
SELECTED CUPTI EVENTS & METRICS COUNTERS.
TABLE IV
Group(#counters) Counter
1(2)
2(4)
3(4)
Tex0/1 cache sector queries
Fb subp0/1 read/write sectors
L2 subp0/1 write/read sector misses Number of write/read requests sent to DRAM from slice 0/1 of L2 cache.
Description
Number of texture cache 0/1 requests..
Number of DRAM read/write requests to sub partition 0/1.
as LSTM is capable of memorizing values over arbitrary time
intervals. Without losing generality, we choose the timeline of
the ﬁrst iteration’s OpSeq as the base timeline, and let other
OpSeqs be compared with it.
Recognizing other ops (OtherOps). The rest ops of con-
volutional and fully-connected layer, as well as ops of other
layers, are recognized by another inference model named Mop.
We aim to detect BiasAdd, activation functions like ReLU
and their back-propagation versions (e.g., BiasAddGrad
and ReLUgrad) for convolutional and fully-connected lay-
ers. For pooling layers, only one op is executed for feed-
forward (e.g., MaxPool) and back-propagation passes (e.g.,
MaxPoolGrad). We call those ops as OtherOp. Mop takes
the same input as Mlong and outputs class logits of OtherOp.
It also uses the softmax and cross-entropy loss. But when
calculating the total loss, it does not sum up the loss from
all samples. Instead,
to
OtherOp. In other words, the loss resulted from Conv2D,
Conv2DBackprop and NOP samples are all neglected. The
prediction results are reﬁned by a voting model named Vop,
which is almost the same as Vlong. Similar to the step above,
when training the voting model, only the loss from OtherOp
are counted.
it only counts in those relevant
To notice, Mop still makes predictions for those samples
that are irrelevant to OtherOp, like the back-propagation ops.
Those predictions though are not used by the attacker but they
are implicitly used by the LSTM model to make predictions
for the subsequent sample, as the LSTM model can memorize
the input status.
Collapsing ops. For long ops like conv, multiple samples
can be observed, leading to multiple predictions. We collapse
the consecutive predictions if they are identical into one op.
For example, if the predicted OpSeq is {ReLU, conv, conv,
conv, BiasAdd}, the new OpSeq after collapsing will be
{ReLU, conv, BiasAdd}.
C. Inferring Hyper-parameters
In addition to learning ops,
the attacker also needs to
learn the layer hyper-parameters, like ﬁlter size as stated in
Section II-A. We designed an LSTM model named Mhp to
predict them. The model has the same structure as Mop, but the
training data is constructed differently. For neuron numbers,
the label is assigned to the last sample of a convolutional
or fully-connected layer. We use the last sample because it
encourages Mhp to make full use of the information from all
the samples related to the layer.
Other hyper-parameters. MoSConS reveals most of the
hyper-parameters uncovered by previous works, even though
we assume a much weaker adversary (remote attacker without
physical access). On the other hand, the difﬁculties of un-
covering all hyper-parameters are not the same. For example,
shortcut [22], a technique to add a connection between non-
adjacent layers, is not recovered by MoSConS. The model
developer can choose where to place the shortcut but such
information is not visible to the spy with only CUPTI access.
However, the attacker can leverage the domain knowledge
to infer the places of shortcuts after the layers are learnt. For
example, if the layer structure is similar to ResNet [22], the
shortcut is likely to bypass every 2 convolutional layers.
D. Correction with Model Syntax
After the previous steps, the attacker will obtain an OpSeq
augmented with hyper-parameters but errors exist due to
imperfect prediction. On the other hand, we found the attacker
can correct the predicted OpSeq with heuristics pertinent to
DNN syntax. Firstly, certain ops have inherent dependencies
and the wrong order will break the training process. For
example, in the feed-forwarding phase, conv and MatMul
are always followed by a BiasAdd and an activation op
like ReLU. Secondly, the layer hyper-parameters depend on
the ops of the current and adjacent layers. For example, the
number of ﬁlters for a convolutional layer or the number of
neurons for a fully-connected layer usually gets doubled when
the layers go deeper. Besides, they are set to the power of
two as choosing other values often leads to inferior model
performance. Therefore, the attacker can correct the wrong
hyper-parameters based on these rules.
While this step requires the attacker’s domain knowledge in
DNN, we want to point out those heuristics are well known.
In addition, as shown in our evaluation, previous steps already
produce high-quality OpSeq and hyper-parameters. In fact,
only a few predictions need to be corrected.
V. EVALUATION
In this section, we evaluate the inference accuracy of
MoSConS. Firstly, we introduce the settings for our evaluation,
including the testing procedure, the parameter settings, the
dataset, and the evaluation metrics. Then, we describe the
evaluation result, focusing on OpSeq and hyper-parameters.
A. Experiment Settings
Experiment procedure. Our experiment consists of two steps.
Firstly, we use the spy program to proﬁle a set of CNNs
and train the inference models. Each spy’s CUPTI reading
is attached with ground-truth values (e.g., conv and ﬁlter
size 3x3). We achieve this goal by aligning the model’s ops
with spy’s readings using the TensorFlow timeline proﬁler.
Sometimes, a spy kernel can overlap with multiple victim ops
on the timeline and we choose the TensorFlow label having
8
TABLE V
THE LAYERS AND HYPER-PARAMETERS OF PROFILED MODELS. THE
SUBSCRIPTS ARE HYPER-PARAMETERS, INCLUDING THE NUMBER OF
NEURONS, FILTER SIZE, NUMBER OF FILTERS, STRIDE AND ACTIVATION
FUNCTIONS. THE LETTERS ARE EXPLAINED IN TABLE VII.
Model
Cust.
MLP
AlexNet
Cust.
VGG19
Structure
M64,R − M128,T − M256,S − M512,R − M1024,T −
M2048,S − M4096,R − M8192,R − M16384,S −
OptimizerAdagrad
C11,96,4,R − P − C5,256,1,R − P − C3,384,1,R −
C3,384,1,R − C3,256,1,R − P − M4096,R − M4096,R −
M1000,R − OptimizerAdam
C13,64,1,R − C13,64,1,R − P − C11,192,1,R − C9,256,1,R −
P − C7,256,1,R − C5,256,1,R − C3,256,1,R − C1,256,1,R −
P − C3,512,1,R − C3,512,1,R − C3,512,1,R − C3,512,1,R −
P −C1,512,1,R−C1,1024,1,R−C1,2048,1,R−C1,4096,1,R−
P − M4096,R − M4096,R − M1000,R − OptimizerGD
the largest overlap with the spy kernel. Secondly, we run a
different set of models and use the trained inference model to
reveal the model secret.
For the models to be proﬁled, we choose MLP (Multilayer
Perceptron), AlexNet [29] and VGG19 [57]. They cover most
of the CNN building blocks. Table V lists their structures.
For the models to be tested, we choose a different MLP (ﬁve
fully-connected layers), ZFNet [66] and VGG16. By testing
this combination, we evaluate the effectiveness of MoSConS
against
the victim’s model customization under the same
family and across families (AlexNet and ZFNet are different
families). Table IX shows the structures of tested models.
image size is 64x64 and we convert
We feed images from ImageNet [54] to the proﬁled and
tested models to simulate the normal training workload. The
original
the size to
224x224, which is a standard pre-processing technique used
by model developers to smooth the gradient [8]. We randomly
choose 10,000 images to train each model. The batch size is
set to 64 for VGG19 and VGG16, 512 for AlexNet, 256 for
ZFNet, and 128 for MLP and customized MLP. Each model
is trained for 500 iterations.
Parameter settings. We use a few pre-deﬁned parameters for
iteration splitting based on empirical analysis. In particular,