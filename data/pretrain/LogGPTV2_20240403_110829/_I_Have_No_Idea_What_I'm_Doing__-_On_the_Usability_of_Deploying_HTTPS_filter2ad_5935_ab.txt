Currently administrating
Company web server
Private web server
Number
Percent
2
26
21
32
23
2
120
25
17
11
17
11
5
17
10%
90%
60%
40%
60%
40%
17%
83%
Table 1: Participant characteristics from the lab experi-
ments. n=28
3.3 Data Analysis
For a qualitative analysis of the observation protocols we
performed a series of iterative coding which is often used
in usable security research to develop models and theo-
ries from qualitative data [27, 34, 39]. Our approach in-
volved several steps in the analysis process and was im-
plemented as follows: At ﬁrst, two researchers traversed
all data segments independently point-by-point and as-
signed descriptive codes. This process is referred to as
open coding. The two researchers performed the initial
coding independently from each other to minimize the
susceptibility of biased interpretation. We evaluated the
quality of our initial codes and agreed on a ﬁnal set of
codes which was then used to code the protocols. Our
analysis showed a good inter-rater agreement between
the two coders (Cohen’s κ=0.78). On the resulting initial
set of coded data we performed axial coding to look for
explanations and relationships among the codes and top-
ics to uncover structures in the data. Then we performed
selective coding to put the results together and derive a
theory from the data.
In order to structure the data from the open-ended ques-
tions collected through the questionnaire we used an it-
erative coding process. Hence we went through the col-
lected data and produced an initial set of codes. Then
we revised the retrieved codes and discussed recurring
themes, patterns and interconnections. After agreeing on
a ﬁnal set of codes, we coded the entire data. As a result
of our analysis, we obtained a picture of usability chal-
lenges in the deployment process which is presented in
Section 4, grouped by themes.
To evaluate the (mostly) quantitative data acquired via
the bash/browser history and Apache log ﬁles, we ap-
plied metrics and measures to evaluate the quality of the
resulting conﬁguration.
4 Results
In this section we present the results from our lab study
which are based on the data from the think-aloud proto-
col, the collected log ﬁles and the self-reported data from
the exit-questionnaire.
4.1 Security Evaluation
We based our evaluation criteria on Qualy’s SSL Test.2
We consider this rating scheme a useful benchmark
to assess the quality of a TLS conﬁguration based
on the state of the art recommendations from various
RFCs [37, 38] and with respect to the most recently
discovered vulnerabilities and attacks in the protocol.
Since web services have different requirements, e.g.,
backward compatibility for outdated browsers, there is
no universally applicable recommendation to get the
highest grade. Still, the rating is widely accepted and
applicable to generic web services like in our study.
It must be mentioned that this benchmark reﬂects the
best-case scenario at the time of writing, but could
be different
in the future if new vulnerabilities are
discovered.
The rating of the evaluation criteria is expressed with
a grade from A to F and composed out of three inde-
pendent values:
(1) protocol support (30%), (2) key
exchange (30%) and (3) cipher strength (40%). Some
properties, e.g., support for the RC4 cipher cap the
overall grade as shown in Table 3. Table 2 summarizes
the results of a security evaluation based on the ﬁnal
conﬁguration per participant with additional information
in Table 3. The full set of evaluation criteria based on the
metrics used in Qualy’s SSL Test is listed in Appendix A.
Only four participants managed to deploy an A grade
TLS conﬁguration, P24 received the best overall score.
B was the most commonly awarded grade (15 out of 28).
Four participants did not manage to deploy a valid TLS
conﬁguration in the given time (P7, P18, P23, P26). Two
2https://www.ssllabs.com
1342    26th USENIX Security Symposium
USENIX Association
participants (P10 and P19) encrypted their private keys,
the passphrases were “abc123” and “pass”. One of these
two did not share the passphrase with us, however it was
easy to brute-force.
Fortunately, none of our participants chose a key size
smaller than 2048 for their RSA key. 15 participants
chose 2k- and eight chose 4k-sized keys. Five out of the
28 participants deployed the certiﬁcate chain correctly,
which is necessary to receive a grade better than B ac-
cording to our rating scheme.
Two participants did not make use of the study CA and
used self-signed certiﬁcates. Only one participant en-
abled a TLS version lower than TLS 1.0 (P8), another
participant had all versions but TLS 1.2 disabled (P14).
Only two participants conﬁgured RC4 support and only
one conﬁguration (P8) was vulnerable to the POODLE
attack as SSL 3 was still supported. 14 participants fully
conﬁgured forward secrecy, the remaining participants
with valid conﬁgurations managed to at least partially
support it. Eleven participants included HSTS headers
to improve the security of their conﬁguration and only
two participants deployed HPKP.
To determine whether the distribution of SSL Test
grades from our lab study reﬂects those from conﬁg-
urations found in the wild, we consider the estimation
from SSL Pulse [6] who regularly publishes data sets of
grade distribution measures based on the Alexa Top 1
Million. This data set as of the time our study was con-
ducted contains 141.890 surveyed sites of which 34.1%
were graded with A, 20.2% with B, 27.1% with C and
18.5% failed. Based on the 24 valid conﬁgurations from
our study, 25% of the study conﬁgurations were graded
with A, 67% with B and 8% with C. Given that the data
set from SSL Pulse [6] contains websites with potentially
higher security requirements or sites were administrators
were presumably given more time to obtain a secure con-
ﬁguration. In particular the possibly very complex struc-
tures of real-world websites, as well as the inclusion of
third-party content, make our study non-representative.
4.2 TLS Deployment Model
Our qualitative analysis of the think-aloud protocols
from our lab study yielded a process model for a success-
ful TLS conﬁguration. All participants who managed
a valid conﬁguration in the given time can be mapped
to the stages presented in this model. The four partic-
ipants who did not manage to deploy TLS in the given
time signiﬁcantly deviate from this model. We divide
the steps from our model into two phases, a setup phase
and a hardening phase. We refer to the setup phase as
to a set of tasks to get a basic TLS conﬁguration, i.e.,
the service is reachable via https if requested. The hard-
ening phase comprises all necessary tasks to get a con-
Figure 1: Schematic representation of a successful work-
ﬂow.
ﬁguration which is widely considered secure with re-
spect to the metrics deﬁned in A. Figure 1 shows our
deployment model. Participants who achieved at least
a basic conﬁguration successfully completed all steps of
the setup phase, while better-graded conﬁgurations com-
pleted some steps from the hardening phase as well. We
identiﬁed iterative (tool-supported) security testing as a
key element for a successful hardening phase, since the
participants relied on external sources to evaluate the
quality of their conﬁguration.
4.3 Usability Challenges in TLS Deploy-
ment
In the following, we present the usability challenges
identiﬁed through our analysis of qualitative data from
the think-aloud protocols and the quantitative data from
the collected log ﬁles.
Searching for information and ﬁnding the right work-
ﬂow. Except for 3 experienced participants, who ex-
plicitly searched for tutorials they were aware of (e.g.,
bettercrypto.org), the study participants visited a
high number of websites and used multiple sources of in-
formation. The information sources were diverse regard-
ing their suggested deployment approaches and informa-
tion quality respectively. We frequently observed that a
participant started to follow an approach from one tuto-
rial and soon had to switch to another as the presented
approach was not feasible for our deployment scenario
and the given server conﬁguration.
The lowest number of visited websites during the
lab study was 20 (P21).
In contrary, participant P4
visited 147 websites during the given time. The average
USENIX Association
26th USENIX Security Symposium    1343
Errors/ Warnings/Highlights
ProtocolSupportScore
CipherStrengthScore
KeyExchangeScore
Com mon Name
KeySize
UsedProvided CAtoSign
CertiﬁcateChainLength
EncryptedPrivate Key
SSL3
VulnerabletoPO O DLE(SSL3)
ForwardSecrecy
Grade
2
3
2,3
ID
P1 A
P2
B
P3
B
P4 A
B
P5
3
P6
B
P7 Not valid
3-6,8
C
P8
1-3
B
P9
1-3
B
P10
3,4
B
P11
2,3
B
P12
3
P13
B
4
P14 A-
4,7
P15
C
4
P16 A-
P17
2,3
B
P18 Not valid
P19
2,3
2,3
P20
3,4
P21
P22
3,4
P23 Not valid
2
P24 A
P25
B
3
P26 Not valid
B
P27
3,4
2
P28 A
B
B
B
B
90
90
90
90
90
90
90
100
90
90
90
90
90
50
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
90
95
95
95
95