type =\> \"syslog\"
}
}
filter{
grok {
match =\> { \"message\" =\> \"%{COMBINEDAPACHELOG}\" }
}
}
output{
stdout{ codec =\> \"rubydebug\" }
if \[type\] == \"apachelog\"{
elasticsearch {
hosts =\> \[\"http://esl:9200\", \"http://esl2:9200\",
\"http://esl3:9200\"\]
index =\> \"weblog\"
}
}
}
**做测试**
访问web的网站:http://192.168.1.20 看logstash是否有接收到数据
\[root@logstash \~\]# /opt/logstash/bin/logstash -f
/etc/logstash/logstash.conf
> #挂起后访问网站刷新几次
{
\"message\" =\> \"192.168.1.254 - - \[26/Mar/2019:20:05:12 +0800\]
\\\"GET / HTTP/1.1\\\" 403 3985 \\\"-\\\" \\\"Mozilla/5.0 (X11; Linux
x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113
Safari/537.36\\\"\",
\"@version\" =\> \"1\",
\"@timestamp\" =\> \"2019-03-26T12:05:13.814Z\",
\"source\" =\> \"/var/log/httpd/access_log\",
\"type\" =\> \"apachelog\",
\"fields\" =\> nil,
\"input_type\" =\> \"log\",
\"count\" =\> 1,
\"beat\" =\> {
\"hostname\" =\> \"web\",
\"name\" =\> \"web\"
},
\"offset\" =\> 2103,
\"host\" =\> \"web\",
\"tags\" =\> \[
\[0\] \"beats_input_codec_plain_applied\"
\],
\"clientip\" =\> \"192.168.1.254\",
\"ident\" =\> \"-\",
\"auth\" =\> \"-\",
\"timestamp\" =\> \"26/Mar/2019:20:05:12 +0800\",
\"verb\" =\> \"GET\",
\"request\" =\> \"/\",
\"httpversion\" =\> \"1.1\",
\"response\" =\> \"403\",
\"bytes\" =\> \"3985\",
\"referrer\" =\> \"\\\"-\\\"\",
\"agent\" =\> \"\\\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36\\\"\"
}
## Elasticsearch:数据库配置
\[root@room9pc01 \~\]# curl -XDELETE http://192.168.1.11:9200/oo #删除
\[root@room9pc01 \~\]# curl -XDELETE http://192.168.1.11:9200/tarena
{\"acknowledged\":true}
\[root@room9pc01 \~\]# curl -XDELETE
http://192.168.1.11:9200/shakespeare
{\"acknowledged\":true}
\[root@room9pc01 \~\]# curl -XDELETE
http://192.168.1.11:9200/logstash-2015.05.20
{\"acknowledged\":true}
\[root@room9pc01 \~\]# curl -XDELETE
http://192.168.1.11:9200/logstash-2015.05.19
{\"acknowledged\":true}
\[root@room9pc01 \~\]# curl -XDELETE
http://192.168.1.11:9200/logstash-2015.05.18
{\"acknowledged\":true}
然后刷新网页,可看到weblog索引以及访问数据如下图
![](media/image140.png){width="7.030555555555556in"
height="3.4993055555555554in"}
![](media/image141.png){width="7.264583333333333in"
height="2.3722222222222222in"}
## kinbana服务配置
清空所有的可视化图标,重新定义图表
### 安装kibana
11 yum -y install kibana-4.5.2-1.x86_64.rpm
安装包在自己制作的yum源里面,也可以直接将安装包拷贝到主机上面直接安装,无依赖包
### 修改配置文件
13 vim /opt/kibana/config/kibana.yml
23 sed -i \'s/\^#\[\[:space:\]\]server.port/server.port/\'
/opt/kibana/config/kibana.yml
24 sed -i \'s/\^#\[\[:space:\]\]server.host/server.host/\'
/opt/kibana/config/kibana.yml
25 sed -i \'s/\^#\[\[:space:\]\]kibana.index/kibana.index/\'
/opt/kibana/config/kibana.yml
26 sed -i \'s/\^#\[\[:space:\]\]kibana.d/kibana.d/\'
/opt/kibana/config/kibana.yml
27 sed -i \'s/\^#\[\[:space:\]\]elasticsearch.ping/elasticsearch.ping/\'
/opt/kibana/config/kibana.yml
28 sed -i
\'s/\^#\[\[:space:\]\]elasticsearch.request/elasticsearch.request/\'
/opt/kibana/config/kibana.yml
29 sed -i
\'s/\^#\[\[:space:\]\]elasticsearch.startup/elasticsearch.startup/\'
/opt/kibana/config/kibana.yml
修改后如下
elasticsearch.url: \"http://esl:9200\"
server.port: 5601
server.host: \"0.0.0.0\"
kibana.index: \".kibana\"
kibana.defaultAppId: \"discover\"
elasticsearch.pingTimeout: 1500
elasticsearch.requestTimeout: 30000
elasticsearch.startupTimeout: 5000
\[root@kibana103 \~\]# systemctl start kibana.service
\[root@kibana103 \~\]# systemctl status kibana.service
安装完毕:访问:http://192.168.4.103:5601/status #kibana状态
![](media/image133.png){width="6.985416666666667in"
height="3.5590277777777777in"}
配置成功,会多了.kibana的库,表示kibana与elasticsearch对接成功,如下图
![](media/image134.png){width="7.264583333333333in"
height="2.9090277777777778in"}
# 案例
案例1：导入数据
案例2：综合练习
1 案例1：导入数据
1.1 问题
本案例要求批量导入数据：
批量导入数据并查看
1.2 步骤
实现此案例需要按照如下步骤进行。
步骤一：导入数据
使用POST方式批量导入数据，数据格式为json，url
编码使用data-binary导入含有index配置的json文件
\[root@room9pc01 \~\]# scp /var/ftp/elk/\*.gz 192.168.1.66:/root/
\[root@kibana \~\]# gzip -d logs.jsonl.gz
\[root@kibana \~\]# gzip -d accounts.json.gz
\[root@kibana \~\]# gzip -d shakespeare.json.gz
\[root@kibana \~\]# curl -X POST \"http://192.168.1.61:9200/\_bulk\" \\
\--data-binary \@shakespeare.json
\[root@kibana \~\]# curl -X POST
\"http://192.168.1.61:9200/xixi/haha/\_bulk\" \\
\--data-binary \@accounts.json
//索引是xixi，类型是haha，必须导入索引和类型，没有索引，要加上
\[root@kibana \~\]# curl -X POST \"http://192.168.1.61:9200/\_bulk\" \\
\--data-binary \@logs.jsonl
2）使用GET查询结果
\[root@kibana \~\]# curl -XGET
\'http://192.168.1.61:9200/\_mget?pretty\' -d \'{
\"docs\":\[
{
\"\_index\":\"shakespeare\",
\"\_type:\":\"act\",
\"\_id\":0
},
{
\"\_index\":\"shakespeare\",
\"\_type:\":\"line\",
\"\_id\":0
},
{
\"\_index\":\"xixi\",
\"\_type:\":\"haha\",
\"\_id\":25
}
\]
}\'
{ //查询的结果
\"docs\" : \[ {
\"\_index\" : \"shakespeare\",
\"\_type\" : \"act\",
\"\_id\" : \"0\",
\"\_version\" : 1,
\"found\" : true,
\"\_source\" : {
\"line_id\" : 1,
\"play_name\" : \"Henry IV\",
\"speech_number\" : \"\",
\"line_number\" : \"\",
\"speaker\" : \"\",
\"text_entry\" : \"ACT I\"
}
}, {
\"\_index\" : \"shakespeare\",
\"\_type\" : \"act\",
\"\_id\" : \"0\",
\"\_version\" : 1,
\"found\" : true,
\"\_source\" : {
\"line_id\" : 1,
\"play_name\" : \"Henry IV\",
\"speech_number\" : \"\",
\"line_number\" : \"\",
\"speaker\" : \"\",
\"text_entry\" : \"ACT I\"
}
}, {
\"\_index\" : \"xixi\",
\"\_type\" : \"haha\",
\"\_id\" : \"25\",
\"\_version\" : 1,
\"found\" : true,
\"\_source\" : {
\"account_number\" : 25,
\"balance\" : 40540,
\"firstname\" : \"Virginia\",
\"lastname\" : \"Ayala\",
\"age\" : 39,
\"gender\" : \"F\",
\"address\" : \"171 Putnam Avenue\",
\"employer\" : \"Filodyne\",
\"email\" : \"PI:EMAIL\",
\"city\" : \"Nicholson\",
\"state\" : \"PA\"
}
} \]
}
步骤二：使用kibana查看数据是否导入成功
1）数据导入以后查看logs是否导入成功，如图-1所示：
\[root@se5 \~\]# firefox 
![image001](media/image142.png){width="3.683333333333333in"
height="4.750694444444444in"}
图-1
2）kibana导入数据，如图-2所示：
\[root@kibana \~\]# firefox http://192.168.1.66:5601
![image002](media/image143.png){width="4.617361111111111in"
height="2.3666666666666667in"}
图-2
3）成功创建会有logstash-\*，如图-3所示：
/
图-3
4）导入成功之后选择Discover，如图-4所示：
![image003](media/image144.png){width="4.617361111111111in"
height="1.1916666666666667in"}
图-4
注意：
这里没有数据的原因是导入日志的时间段不对，默认配置是最近15分钟，在这可以修改一下时间来显示
5）kibana修改时间，选择Lsat 15 miuntes，如图-5所示：
![image004](media/image145.png){width="4.600694444444445in"
height="0.5916666666666667in"}
图-5
6）选择Absolute，如图-6所示：
![image005](media/image146.png){width="4.617361111111111in"
height="0.975in"}
图-6
7）选择时间2015-5-15到2015-5-22，如图-7所示：
![image006](media/image147.png){width="4.617361111111111in"
height="2.025in"}
图-7
8）查看结果，如图-8所示：
![image007](media/image148.png){width="4.617361111111111in"
height="0.9416666666666667in"}
图-8
9）除了柱状图，Kibana还支持很多种展示方式 ，如图-9所示：
![image008](media/image149.png){width="4.617361111111111in"
height="2.25in"}
图-9
10）做一个饼图，选择Pie chart，如图-10所示：
![image009](media/image150.png){width="4.617361111111111in"
height="2.25in"}
图-10
11）选择from a new serach，如图-11所示：
![image010](media/image151.png){width="4.600694444444445in"
height="0.85in"}
图-11
12）选择Spilt Slices，如图-12所示：
![image011](media/image152.png){width="4.617361111111111in"
height="4.0in"}
图-12
13）选择Trems,Memary(也可以选择其他的，这个不固定)，如图-13所示：
![image012](media/image153.png){width="3.5416666666666665in"
height="5.059027777777778in"}
图-13
14）结果，如图-14所示：
![image013](media/image154.png){width="4.617361111111111in"
height="2.95in"}
图-14
15）保存后可以在Dashboard查看，如图-15所示：
![image014](media/image155.png){width="4.617361111111111in"
height="1.9166666666666667in"}
图-15
2 案例2：综合练习
2.1 问题
本案例要求：
练习插件
安装一台Apache服务并配置
使用filebeat收集Apache服务器的日志
使用grok处理filebeat发送过来的日志
存入elasticsearch
2.2 步骤
实现此案例需要按照如下步骤进行。
步骤一：安装logstash
1）配置主机名，ip和yum源，配置/etc/hosts（请把se1-se5和kibana主机配置和logstash一样的/etc/hosts）
\[root@logstash \~\]# vim /etc/hosts
192.168.1.61 se1
192.168.1.62 se2
192.168.1.63 se3
192.168.1.64 se4
192.168.1.65 se5