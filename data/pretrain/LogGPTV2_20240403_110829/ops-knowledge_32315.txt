User: I have a pipeline which at some point splits work into various sub-processes that do the same thing in parallel. Thus their output should go into the same file.
Is it too risky to say all of those processes should write into the same file? Or does python try and retry if it sees that this resource is occupied?
Assistant: How about having all of the different processes write their output into a queue, and have a single process that reads that queue, and writes to the file?