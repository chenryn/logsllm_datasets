Conference on Computer Vision and Pattern Recognition (2016),
pp. 770–778.
[21] HE, K., ZHANG, X., REN, S., AND SUN, J. Identity mappings
in deep residual networks. In European Conference on Computer
Vision (2016), Springer, pp. 630–645.
[22] HOSSEINI, H., CHEN, Y., KANNAN, S., ZHANG, B., AND
Blocking transferability of adversar-
arXiv preprint
POOVENDRAN, R.
ial examples in black-box learning systems.
arXiv:1703.04318 (2017).
[23] IOFFE, S., AND SZEGEDY, C. Batch normalization: Accelerating
deep network training by reducing internal covariate shift.
In
International conference on machine learning (2015), pp. 448–
456.
[24] KATZENBEISSER, S., AND PETITCOLAS, F. Information hiding.
Artech house, 2016.
[25] KESHET, J. Optimizing the measure of performance in structured
prediction. Advanced Structured Prediction. The MIT Press. URL
http://u. cs. biu. ac. il/˜ jkeshet/papers/Keshet14. pdf (2014).
[26] KIM, S., AND WU, D. J. Watermarking cryptographic function-
alities from standard lattice assumptions. In Advances in Cryp-
tology - CRYPTO 2017 - 37th Annual International Cryptology
Conference, Santa Barbara, CA, USA, August 20-24, 2017, Pro-
ceedings, Part I (2017), pp. 503–536.
[27] KREUK, F., ADI, Y., CISSE, M., AND KESHET, J. Fooling
end-to-end speaker veriﬁcation by adversarial examples. arXiv
preprint arXiv:1801.03339 (2018).
[28] KRIZHEVSKY, A., AND HINTON, G. Learning multiple layers
of features from tiny images.
[29] LECUN, Y., BENGIO, Y., AND HINTON, G. Deep learning. Na-
ture 521, 7553 (2015), 436–444.
[30] LIU, Y., MA, S., AAFER, Y., LEE, W.-C., AND ZHAI, J. Tro-
janing attack on neural networks. Tech Report, 2017.
[31] MERRER, E. L., PEREZ, P., AND TR ´EDAN, G. Adversarial fron-
tier stitching for remote neural network watermarking, 2017.
[32] NAOR, D., NAOR, M., AND LOTSPIECH, J. Revocation and
tracing schemes for stateless receivers. In Annual International
Cryptology Conference (2001), Springer, pp. 41–62.
[33] PASZKE, A., GROSS, S., CHINTALA, S., CHANAN, G., YANG,
E., DEVITO, Z., LIN, Z., DESMAISON, A., ANTIGA, L., AND
LERER, A. Automatic differentiation in pytorch.
[34] PETITCOLAS, F. A., ANDERSON, R. J., AND KUHN, M. G. In-
formation hiding-a survey. Proceedings of the IEEE 87, 7 (1999),
1062–1078.
[35] RAZAVIAN, A. S., AZIZPOUR, H., SULLIVAN, J., AND CARLS-
SON, S. Cnn features off-the-shelf: an astounding baseline
In Computer Vision and Pattern Recognition
for recognition.
Workshops (CVPRW), 2014 IEEE Conference on (2014), IEEE,
pp. 512–519.
[36] RIBEIRO, M., GROLINGER, K., AND CAPRETZ, M. A. Mlaas:
Machine learning as a service. In Machine Learning and Appli-
cations (ICMLA), 2015 IEEE 14th International Conference on
(2015), IEEE, pp. 896–902.
[37] RUSSAKOVSKY, O., DENG,
J., SU, H., KRAUSE,
J.,
SATHEESH, S., MA, S., HUANG, Z., KARPATHY, A., KHOSLA,
A., BERNSTEIN, M., ET AL. Imagenet large scale visual recog-
nition challenge. International Journal of Computer Vision 115,
3 (2015), 211–252.
1628    27th USENIX Security Symposium
USENIX Association
A Supplementary Material
In this appendix we further discuss how to achieve public
veriﬁability for a variant of our watermarking scheme.
Let us ﬁrst introduce the following additional notation:
for a vector e ∈ {0,1}(cid:96), let e|0 = {i ∈ [(cid:96)] | e[i] = 0} be the
set of all indices where e is 0 and deﬁne e|1 accordingly.
Given a veriﬁcation key vk = {c(i)
L }i∈[(cid:96)] containing (cid:96)
,c(i)
t
elements and a vector e ∈ {0,1}(cid:96), we write the selection
of elements from vk according to e as
vk|e
vk|e
For a marking key mk = (b,{r(i)
t
L }i∈e|1.
1 = {c(i)
,c(i)
L }i∈[(cid:96)]) with (cid:96) ele-
,r(i)
L }i∈e|0
,c(i)
0 = {c(i)
and
t
t
0 = (b|e
L }i∈[(cid:96)] we then deﬁne
L }i∈e|0) with b|e
,r(i)
ments and b = {T (i),T (i)
mk|e
(and mk|e
cryptographic hash function H : {0,1}p(n) → {0,1}n.
L }i∈e|0
1 accordingly). We assume the existence of a
0 = {T (i),T (i)
0,{r(i)
t
A.1 From Private to Public Veriﬁability
To achieve public veriﬁability, we will make use of
a cryptographic tool called a zero-knowledge argument
[15], which is a technique that allows a prover P to con-
vince a veriﬁer V that a certain public statement is true,
without giving away any further information. This idea
is similar to the idea of unlimited public veriﬁcation as
outlined in Section 4.1.
Zero-Knowledge Arguments. Let TM be an abbrevi-
ation for Turing Machines. An iTM is deﬁned to be an in-
teractive TM, i.e. a Turing Machine with a special com-
munication tape. Let LR ⊆{0,1}∗ be an NP language and
R be its related NP-relation, i.e. (x,w) ∈ R iff x ∈ LR and
the TM used to deﬁne LR outputs 1 on input of the state-
ment x and the witness w. We write Rx = {w | (x,w) ∈ R}
for the set of witnesses for a ﬁxed x. Moreover, let P,V
be a pair of PPT iTMs. For (x,w) ∈ R, P will obtain
w as input while V obtains an auxiliary random string
z ∈ {0,1}∗. In addition, x will be input to both TMs. De-
note with VP(a)(b) the output of the iTM V with input
b when communicating with an instance of P that has
input a.
(P,V) is called an interactive proof system for the lan-
guage L if the following two conditions hold:
Completeness: For every x ∈ LR there exists a string w
such that for every z: Pr[VP(x,w)(x,z) = 1] is negli-
gibly close to 1.
Soundness: For every x (cid:54)∈ LR, every PPT iTM P∗ and
every string w,z: Pr[VP∗(x,w)(x,z) = 1] is negligible.
An interactive proof system is called computational
zero-knowledge if for every PPT ˆV there exists a PPT
simulator S such that for any x ∈ LR
{ ˆV P(x,w)(x,z)}w∈Rx,z∈{0,1}∗ ≈c {S(x,z)}z∈{0,1}∗,
meaning that all information which can be learned from
observing a protocol transcript can also be obtained from
running a polynomial-time simulator S which has no
knowledge of the witness w.
A.1.1 Outlining the Idea
An intuitive approach to build PVerify is to convert the
algorithm Verify(mk, vk,M) from Section 4 into an NP
relation R and use a zero-knowledge argument system.
Unfortunately, this must fail due to Step 1 of Verify:
there, one tests if the item b contained in mk actually is
a backdoor as deﬁned above. Therefore, we would need
access to the ground-truth function f in the interactive ar-
gument system. This ﬁrst of all needs human assistance,
but is moreover only possible by revealing the backdoor
elements.
We will now give a different version of the scheme
from Section 4 which embeds an additional proof into vk.
This proof shows that, with overwhelming probability,
most of the elements in the veriﬁcation key indeed form
a backdoor. Based on this, we will then design a dif-
ferent veriﬁcation procedure, based on a zero-knowledge
argument system.
A.1.2 A Convincing Argument that most Commit-
ted Values are Wrongly Classiﬁed
Verifying that most of the elements of the trigger set
are labeled wrongly is possible, if one accepts5 to re-
lease a portion of this set. To solve the proof-of-
misclassiﬁcation problem, we use the so-called cut-and-
choose technique: in cut-and-choose, the veriﬁer V will
ask the prover P to open a subset of the committed inputs
and labels from the veriﬁcation key. Here, V is allowed
to choose the subset that will be opened to him. Intu-
itively, if P committed to a large number elements that
are correctly labeled (according to O f ), then at least one
of them will show up in the values opened by P with
overwhelming probability over the choice that V makes.
Hence, most of the remaining commitments which were
not opened must form a correct backdoor.
5This is ﬁne if T , as in our experiments, only consists of random
images.
USENIX Association
27th USENIX Security Symposium    1629
To use cut-and-choose, the backdoor size must con-
tain (cid:96) > n elements, where our analysis will use (cid:96) = 4n
(other values of (cid:96) are also possible). Then, consider the
following protocol between P and V:
CnC((cid:96)) :
1. P runs (mk, vk) ← KeyGen((cid:96)) to obtain a backdoor
of size (cid:96) and sends vk to V. We again deﬁne mk =
(b,{r(i)
t
L }i∈[(cid:96)]), vk = {c(i)
,r(i)
L }i∈[(cid:96)]
,c(i)
t
2. V chooses e ← {0,1}(cid:96) uniformly at random and
sends it to P.
3. P sends mk|e
4. V checks that for i ∈ e|1 that
1 to V.
(a) Open(c(i)
,t(i),r(i)
t
L ,T (i)
(b) Open(c(i)
L ,r(i)
(cid:54)= f (t(i)).
(c) T (i)
L
t ) = 1;
L ) = 1; and
1 to the values he put into c(i)
t
Assume that P chose exactly one element of the back-
door in vk wrongly, then this will be revealed by CnC to
an honest V with probability 1/2 (where P must open
vk|e
L during KeyGen due
to the binding-property of the commitment). In general,
one can show that a cheating P can put at most n non-
backdooring inputs into vk|e
0 except with probability neg-
ligible in n. Therefore, if the above check passes for
(cid:96) = 4n at then least 1/2 of the values for vk|e
0 must have
the wrong committed label as in a valid backdoor with
overwhelming probability.
,c(i)
The above argument can be made non-interactive
and thus publicly veriﬁable using the Fiat-Shamir
transform[13]: in the protocol CnC, P can generate the
bit string e itself by hashing vk using a cryptographic
hash function H. Then e will be distributed as if it was
chosen by an honest veriﬁer, while it is sufﬁciently ran-
dom by the guarantees of the hash function to allow
the same analysis for cut-and-choose. Any V can re-
compute the value e if it is generated from the commit-
ments (while this also means that the challenge e is gen-
erated after the commitments were computed), and we
can turn the above algorithm CnC into the following non-
interactive key-generation algorithm PKeyGen.
3. Set mkp ← (mk,e), vkp ← (vk, mk|e
1) and return
(mkp, vkp).
A.1.3 Constructing the Public Veriﬁcation Algo-
rithm
0, vk|e
0 hold.
In the modiﬁed scheme, the Mark algorithm will only
use the private subset mk|e
0 of mkp but will otherwise re-
main unchanged. The public veriﬁcation algorithm for
a model M then follows the following structure: (i) V
recomputes the challenge e; (ii) V checks vkp to assure
that all of vk|e
1 will form a valid backdoor ; and (iii) P,V
run Classify on mk|e
0 using the interactive zero-knowl-
edge argument system, and further test if the watermark-
ing conditions on M, mk|e
0 which opens vk|e
For an arbitrary model M, one can rewrite the steps
2 and 3 of Verify (using M, Open, Classify) into a
binary circuit C that outputs 1 iff the prover inputs the
correct mk|e
0 and if enough of these
openings satisfy Classify. Both P,V can generate
this circuit C as its construction does not involve private
information. For the interactive zero-knowledge argu-
ment, we let the relation R be deﬁned by boolean cir-
cuits that output 1 where x = C,w = mk|e
0 in the follow-
ing protocol PVerify, which will obtain the model M
as well as mkp = (mk,e) and vkp = (vk, mk|e
1) where
vk = {c(i)
L }i∈[(cid:96)]) and b =
,r(i)
t
{T (i),T (i)
1. V computes e(cid:48) ← H(vk). If mk|e
1 in vkp does not
match e(cid:48) then abort, else continue assuming e = e(cid:48).
L }i∈[(cid:96)], mk = (b,{r(i)
,c(i)
L }i∈[(cid:96)] as input.
t
2. V checks that for all i ∈ e|1:
t ) = 1
L ) = 1
(a) Open(c(i)
,t(i),r(i)
t
L ,T (i)
(b) Open(c(i)
L ,r(i)
(cid:54)= f (t(i))
(c) T (i)
L
If one of the checks fails, then V aborts.
3. P,V compute a circuit C with input mk|e
0 that out-
puts 1 iff for all i ∈ e|0:
(a) Open(c(i)
,t(i),r(i)
t
(b) Open(c(i)
L ,r(i)
L ,T (i)
Moreover, it tests that Classify(t(i),M) = T (i)
L
all but ε|e|0| elements.
t ) = 1
L ) = 1.
for
PKeyGen((cid:96)) :
1. Run (mk, vk) ← KeyGen((cid:96)).
2. Compute e ← H(vk).
4. P,V run a zero-knowledge argument for the given
relation R using C as the statement, where the wit-
0 is the secret input of P. V accepts iff the
ness mk|e
argument succeeds.
1630    27th USENIX Security Symposium
USENIX Association
Assume the protocol PVerify succeeds. Then in the
interactive argument, M classiﬁes at least (1− ε)|e|0| ≈
(1 − ε)2n values of the backdoor b to the committed
value. For ≈ n of the commitments, we can assume that
the committed label does not coincide with the ground-
truth function f due to the guarantees of Step 1. It is easy
to see that this translates into a 2ε-guarantee for the cor-
rect backdoor. By choosing a larger number (cid:96) for the size
of the backdoor, one can achieve values that are arbitrar-
ily close to ε in the above protocol.
USENIX Association
27th USENIX Security Symposium    1631