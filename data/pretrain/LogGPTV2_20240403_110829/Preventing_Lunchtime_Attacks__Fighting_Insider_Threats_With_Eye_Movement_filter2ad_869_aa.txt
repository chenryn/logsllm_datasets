title:Preventing Lunchtime Attacks: Fighting Insider Threats With Eye Movement
Biometrics
author:Simon Eberz and
Kasper Bonne Rasmussen and
Vincent Lenders and
Ivan Martinovic
Preventing Lunchtime Attacks: Fighting Insider
Threats With Eye Movement Biometrics
Simon Eberz
University of Oxford, UK
PI:EMAIL
Kasper B. Rasmussen
University of Oxford, UK
Vincent Lenders
Armasuisse, Switzerland
PI:EMAIL
PI:EMAIL
Ivan Martinovic
University of Oxford, UK
PI:EMAIL
Abstract—We introduce a novel biometric based on distinctive
eye movement patterns. The biometric consists of 21 features that
allow us to reliably distinguish users based on differences in these
patterns. We leverage this distinguishing power along with the
ability to gauge the users’ task familiarity, i.e., level of knowledge,
to address insider threats. In a controlled experiment we test
how both time and task familiarity inﬂuence eye movements
and feature stability, and how different subsets of features affect
the classiﬁer performance. These feature subsets can be used
to tailor the eye movement biometric to different authentication
methods and threat models. Our results show that eye movement
biometrics support reliable and stable identiﬁcation and authen-
tication of users. We investigate different approaches in which
an attacker could attempt to use inside knowledge to mimic
the legitimate user. Our results show that while this advance
knowledge is measurable, it does not increase the likelihood of
successful impersonation. In order to determine the time stability
of our features we repeat the experiment twice within two weeks.
The results indicate that we can reliably authenticate users over
the entire period. We show that the classiﬁcation decision depends
on all features and mimicking a few of them will not be sufﬁcient
to trick the classiﬁer. We discuss the advantages and limitations
of our approach in detail and give practical insights on the use
of this biometric in a real-world environment.
I.
INTRODUCTION
In this paper, we evaluate the effectiveness of using eye
movement biometrics as a novel defence against the “lunchtime
attack” by an insider threat. An insider threat in this context
refers to a person with physical access to a workstation that he
is not supposed to use (e.g., using a coworker’s workstation
while he is at lunch). As such our system serves as a second line
of defense after the workstation has already been compromised
(i.e., the attacker has physical access and the workstation is
either unlocked or he is in possession of all necessary passwords
and access tokens). Our approach considers both users that
are simply careless and users that are actively collaborating
with the attacker by giving up information. The second case
makes this attack notoriously difﬁcult to defend against. We
propose a set of features that can be extracted from human eye
Permission to freely reproduce all or part of this paper for noncommercial
purposes is granted provided that copies bear this notice and the full citation
on the ﬁrst page. Reproduction for commercial purposes is strictly prohibited
without the prior written consent of the Internet Society, the ﬁrst-named author
(for reproduction of an entire paper only), and the author’s employer if the
paper was prepared within the scope of employment.
NDSS ’15, 8-11 February 2015, San Diego, CA, USA
Copyright 2015 Internet Society, ISBN 1-891562-38-X
http://dx.doi.org/10.14722/ndss.2015.23203
movements and analyze their distinctiveness and robustness
using a systematic experimental design.
The human eyes offer a rich feature space based on volun-
tary, involuntary, and reﬂexive eye movements. Traditionally,
the analysis of eye movements has been used in the medical
domain to facilitate diagnosis of different ocular and neuronal
disorders. Eye tracking devices have become much cheaper
within the last years and even low-cost open-source hardware
and software is available [1]. Recent advances in video-based
eye tracking technology makes eye tracking applicable to a
conventional workplace as it does not require any physical
contact with the users (more detail on eye tracking is given in
Section II).
Our experimental design captures the unique characteristics
of each user’s eye movements as measured by the eye tracker.
We also consider ways in which the attacker could use his
position to gain inside information about the user and the system
through observation or social engineering. We deﬁne metrics to
measure this advance knowledge through eye movement data
and determine whether it affects the authentication decision. We
consider three scenarios in particular: (i) no prior knowledge,
i.e., no information advantage; (ii) knowledge gained through
a description, e.g., the adversary is provided with a textual
description by a colluding legitimate user; and (iii) knowledge
gain through observation, e.g., by looking over the shoulder of
a legitimate user performing a task (shoulder-surﬁng).
We perform these experiments with 30 subjects recruited
from the general public and repeat them after two weeks to
test the time-stability of the proposed features. While our
experimental results show that an adversary does beneﬁt from an
increased level of knowledge when executing a task, the analysis
of the proposed features also shows that he cannot utilize that
knowledge to circumvent the eye movement biometric.
Our main contributions are a set of 21 features and
measurements that conﬁrm that these features are suitable
to perform user authentication. We carefully consider various
error sources and validate our design by looking at the learning
behavior of our test subjects. We further show that it is possible
to gauge the level of familiarity with a speciﬁc task through
the eye tracker biometric. This property is very useful when
dealing with an insider threat. Finally we also present a basic
authentication system based on this biometric as well as a
discussion of the robustness of our results over time.
The rest of the paper is organized as follows: Section II gives
an overview over the relevant background on the human visual
III. THREAT MODEL
The adversary model considered in this paper focuses on
insider threats. A well known example of an insider threat is the
so called “lunchtime attack” where an adversary temporarily
gains access to a co-worker’s workstation while the co-worker
is away for lunch. Other examples include cleaning staff getting
access to workstations after hours, or the trivial case where
one employee simply allows another employee to use his
workstation or access credentials. In all these scenarios, an
adversary might gain access to a fully operational system,
already logged into a privileged account, and with access to
everything that the legitimate user of the workstation would
normally have access to. Any subsequent attack mounted from
such a compromised workstation can be very hard to trace
back to the real attacker. A 2011 study has shown that 33% of
electronic crimes in companies are committed by insiders [19].
60% of these attacks use a compromised account, in the
remaining cases the attacker uses their own account [20].
Account compromise is particularly difﬁcult to detect as the
account used to carry out the attack typically was not associated
with suspicious activity before. Furthermore, it is more difﬁcult
to trace back the attack (and investigation may even put false
blame on the victim). Most organisations allow their employees
remote access (e.g., via SSH or a VPN connection), nevertheless
43% of attacks are performed locally using physical access to
the workstation [20].
In our model the adversary is aware of the gaze tracking
system and will do his best to imitate the behavior of the
legitimate user. This can be done by familiarizing himself with
the system before sitting down at the terminal, thus trying to
appear to the gaze tracking system as an experienced user. From
the attacker’s perspective there are two incentives to obtain this
kind of information: If he manages to observe how the user
accesses sensitive data or performs some sort of transaction
he will most likely be able to carry out his attack much faster,
helping him to avoid detection. Besides this, performing a task
in a similar way may result in ocular characteristics being
closer to the legitimate user. The adversary will win if he
can circumvent the gaze tracking system, i.e., exhibit ocular
characteristics that are similar enough to the legitimate user.
We consider two models of knowledge transfer to help the
adversary familiarize himself with a system: (1) The adversary
has gained knowledge about the system by reading (or being
told) how the system works; and (2) the adversary has seen
(e.g., by shouldersurﬁng) how a legitimate user operates the
system.
We assume the adversary cannot disable the gaze tracking
system, nor can he interfere with its operation in any way,
as doing so would quickly lead to the detection of his attack.
We don’t consider insider threats which involve the attacker
using his own workstation. These attacks can always be traced
back to the actual attacker and are better dealt with through
behavioural monitoring[21]. The aim here is to show that gaze
tracking is a viable way of identifying users, as well as gauge
a user’s level of knowledge and familiarity with a particular
task.
Fig. 3: Video-based gaze tracking: the tracking of eye move-
ments is software-based and does not require any physical
contact with a subject. The gaze position is calculated using
the distance between pupil position and the corneal reﬂections
(shown as two white crosses).
are calibrated with respect to an external display then the
process is called gaze tracking. There are many types of eye
tracking techniques, with the main trade-off between tempo-
ral/spacial accuracy vs. intrusiveness and usability. Traditional
eye tracking techniques require either a head-mounted device or
electrodes attached to the subject’s face. One such example is
electrooculography (EOG), which is a technique for recording
eye movements by measuring electric potential at the electrodes
placed around the eyes. While this technique can be used to
capture the eye movements even during sleep (e.g., to monitor
REM sleep), its main disadvantage is the high intrusiveness
since the electrodes must be attached to a person’s face.
Recently there has been signiﬁcant progress in eye tracking
technology driven by its importance in many commercial scenar-
ios, such as advertising and usability studies. The gaming and
entertainment industries also show a trend towards consumer-
level eye tracking devices not only as an additional control
channel, but also to enhance computer-human interaction. The
most widely used eye tracking technology today is video-
based. Video-based eye tracking uses a video camera which
focuses on the pupils and records their movements and size.
To improve the tracking accuracy, these devices usually use
a source of controlled infrared or near-infrared light to create
distinctive reﬂexion patterns (see Figure 3). Importantly, the
current video-based eye tracking is non-invasive and remote,
operating without any contact with the subject. The required
hardware is only a standard webcam capable of recording
infrared light. For example, the ITU Gaze Tracker [1] is an
open source project which offers eye tracking software that
can be used by many low-cost webcams. Some smartphone
manufacturers such as Samsung have also recently started to
include basic eye tracking capabilities to their phones.
Given the increasing availability and simplicity of eye
tracking, it is likely that the trend of using eye tracking outside
of the medical and research domain will continue. The current
non-invasive eye tracking technology already enables an easy
access to a rich and distinctive feature space of ﬁxational eye
movements. Their distinctive capabilities and involuntary nature
makes them a potentially valuable biometric.
3
experimental design (i.e., the tasks performed by the subjects)
is interchangeable, and the results are transferable to a wide
set of general tasks.
B. Grouping of Samples
The gazetracker reports raw samples containing X/Y co-
ordinates and the current pupil diameter. As a single raw
sample does not contain any distinguishing information it
is necessary to combine multiple raw samples and use the
relationships between these samples (i.e., movements instead
of static positions) as features. Given the nature of the data we
consider ﬁxations to be the most natural level of abstraction.
The gazetracker groups samples collected over at least 50ms
that lie within a 30-pixel radius into a ﬁxation (see Figure 1).
In the context of this Section the term sample will refer to one
ﬁxation (i.e., a set of raw samples). In our data we observe one
ﬁxation on average every 250ms, yielding a sampling rate of
4Hz. It is important to note that this rate may change depending
on the experimental design (e.g., reading will lead to longer
ﬁxations and a lower sampling rate) and across different users.
C. Feature Types
A complete list of our features is given in Table I. We
types of features: Pupil features,
consider three different
temporal features and spatial features.
Pupil features can be split into static and dynamic features.
As outlined in Section II the range of the pupil diameter is
largely constant for each person. We capture this static range
using the maximal, minimal and mean pupil diameter that
is observed during one ﬁxation. The dynamic component is
reﬂected by the short-term changes of the pupil diameter. These
changes can be caused by cognitive load or different stimulation
through lighting. While these external stimuli are equal for
all participants their reactions to them may not be. We model
these changes through the standard deviation and the difference
between the minimal and maximal pupil diameter observed
during a ﬁxation.
Temporal features include both the duration of saccades
and ﬁxations as well as speed and acceleration. Both the
peak and the average velocity of movements within a ﬁx-
ation have been shown to differ greatly between people in
related neuroscientiﬁc work (see Section II). These differences
are mainly caused through different prevalence of saccadic
intrusions and microsaccades, both of which are characterized
by high velocity and acceleration. Different studies report
similar ranges for these values, even though their experimental
designs differ signiﬁcantly. This suggests that these features
show a high degree of task independence, which makes them
particularly desirable for classiﬁcation. We compute the velocity
between each pair of consecutive samples and only use the
magnitude of acceleration (i.e., we do not use the direction).
The reasoning behind this is that the direction of acceleration
depends on the location of the target stimulus and is therefore
task-dependent [24].
Spatial features are a method to measure the steadiness
of a person’s gaze. A ﬁxation is a group of samples within a
ﬁxed-size circle, which consists of the samples and a center
point (see Figure 1 for an illustration). While the total area
that can be covered by a ﬁxation is limited by this deﬁnition,
Fig. 4: Feature correlation measured by the pearson correlation
coefﬁcient. A value of 0 indicates no correlation, values of 1
and -1 signify positive and negative correlation, respectively.
IV. FEATURE DEFINITION
In this Section we describe different types of features,
explain the reasoning behind each choice and link them to
the foundations in neuroscientiﬁc work described in Section II.
We will rank these features according to the information they
reveal about the user ID and discuss the implications of using
different sets of features for classiﬁcation.
A. Design Criteria
An important consideration when choosing features is
what data is required to compute them and whether there
are any constraints regarding the environment in which they
are collected. In order to make the authentication system
usable in a standard working environment the calculation of
the features must only use raw eyetracking data without relying
on controlling, or even being aware of, running applications
or screen content. This assumption distinguishes our approach
from related work, which measures the user’s reactions to
controlled stimuli, and is therefore unsuitable for transparent
continuous authentication [22], [23].
It is important to know to which degree features are
inﬂuenced by the task the user performs while the features
are collected. As eye movements are always a reaction to a
stimulus perfect task independence can never be guaranteed,
but some features are more susceptible to such inﬂuences than
others. Largely task-independent features allow conducting the
training phase with a task different to the one performed during
the system’s actual operation. This is particularly desirable in
an ofﬁce environment, as a wide variety of tasks are performed
on a daily basis. A higher degree of task independence will
signiﬁcantly reduce the error rates exhibited by the system.
We choose our features such that
they are as task-
independent as possible and do not require any controlled
stimuli. The main advantage of this approach is that the