hitter. We can achieve very high accuracy of detecting heavy
hitter, because we record flow IDs in the heavy part, only a
very small part of flows those are exchanged from the light
part could have error.
Heavy Change Detection: For two adjacent time windows,
we build two Elastic sketches, respectively. To find heavy
changes with threshold T , one common used method is to
check all flows in each time window with size no less than
T . Therefore, we check all flows in the heavy parts of the
two sketches, and if the size difference of a flow in the two
windows is larger than T , we report it as a heavy change.
Estimation of Flow Size Distribution, Entropy, and
Cardinality: These three tasks care about both the elephant
flows and mouse flows. For flows in the heavy part, we can
get their information directly. For flows in the light part, we
can get the needed information from the counter distribution.
So at the end of each time window, we collect the counter
distribution array (n0, n1, ..., n255) of the light part, where ni
is the number of counters whose value is i. Then we send
this array together with the heavy part and the compressed
light part to the collector.
1) Estimating flow size distribution: we first estimate the
distribution of the light part using the basic MRAC algorithm
proposed by [17], and then sum it with the distribution of
the heavy part.
2) Estimating entropy: we compute the entropy based on the
m ), where m is the
sum of ni, and ni is the number of flows with size of i.
3) Cardinality: we first count the number of distinct flows
in the heavy part. Then we calculate the number of distinct
flows in the light part using the method of linear counting
[59]. The cardinality is the sum of the two numbers.
flow size distribution as −(i ∗ ni
For other tasks (e.g., DDoS, SuperSpreader, and more [60–
62]), we will study how to apply Elastic in the future work.
log ni
m
6 IMPLEMENTATIONS
In this section, we briefly describe the implementation of
hardware and software versions of the Elastic sketch on
P4, FPGA, GPU platforms, and CPU, multi-core CPU, OVS
platforms, respectively. More implementation details are pro-
vided in our technical report, and the source code from all
platforms is available at Github [47].
6.1 Hardware Version Implementations
P4 Implementation: We have fully built a P4 prototype of
the Elastic sketch on top of a baseline switch.p4 [38] and
compiled on a programmable switch ASIC [63]. We add 500
lines of P4 code that implements all the registers and meta-
data needed for managing the Elastic sketch in the data
plane.
We implement both heavy part and light part of the hard-
ware version in registers instead of match-action tables be-
cause those parts require updating the entries directly from
the data plane. We leverage the Stateful Algorithm and Logi-
cal Unit (Stateful ALU) in each stage to lookup and update
(f3,72,F)f8(f2,16,F)f9. . .(f6,11,F)(f1,74,F). . .(f5,55,F)(f4,7,F). . .10+155+1. . .1f42+7f8+10(f9,1,T)vote-12Table 1: Additional H/W resources used by Elastic sketch,
normalized by the usage of the baseline switch.P4. The total
memory usage of our P4Switch is the product of the baseline
usage and the additional usage.
Resource
Match Crossbar
SRAM
TCAM
VLIW Actions
Hash Bits
Stateful ALUs
Packet Header Vector
Baseline Additional usage
5.9%
12.5%
0%
5.5%
2.3%
75%
0.36%
474
288
102
145
1605
4
277
the entries in register array. However, Stateful ALU has its
resource limitation: each Stateful ALU can only update a
pair of up to 32-bit registers while our hardware version of
Elastic needs to access four fields in a bucket for an insertion.
To address this issue, we tailor our Elastic sketch implemen-
tation for running in P4 switch at line-rate but with a small
accuracy drop.
The P4 version of the Elastic sketch: It is based on the hard-
ware version of the Elastic sketch, and we only show the
differences below. 1) We only store three fields in two phys-
ical stages: voteall, and (key, vote+), where voteall refers
to the sum of positive votes and negative votes. 2) When
vote + ⩾ λ′, we perform an eviction operation. We rec-
vote all
ommend λ′ = 32, and the reason behind is shown in Sec-
tion B of our technical report. 3) When a flow (f , vote +)
is evicted by another flow (f1, vote +1 ), we set the bucket to
(f1, vote + + vote +1 ). As mentioned in Section 4.2, we recom-
mend using 4 subtables in the hardware version. In this way,
we only need 4*2=8 stages for the heavy part, and 1 stage for
the light part, and thus in total 9 stages. Note, we are not us-
ing additional stages for Elastic. Instead, incoming packets go
through the Elastic sketch and other data plane forwarding
tables in parallel in the multi-stage pipeline. Table 1 shows
the additional resources that the Elastic sketch needs on top
of the baseline switch.p4 mentioned before. We can see that
additional resource use is less than 6% across all resources,
except for SRAM and stateful ALUs. We need to use SRAM to
store the Elastic sketch and stateful ALUs to perform transac-
tional read-test-write operations on the Elastic sketch. Note,
adding additional logics into ASIC pipeline does not really
affect the ASIC processing throughput as long as it can fit
into the ASIC resource constraint. As a result, we can fit
the Elastic sketch into switch ASIC for packet processing at
line-rate.
Comparison of the four versions: In sum, there are four
versions of the Elastic sketch, and we compare the accuracy
of them. Experimental results are shown in Figure 8. We
compare the accuracy of these four versions for two tasks:
flow size estimation and heavy hitter detection. As shown
(a) Flow size.
(b) Heavy hitter.
Figure 8: Accuracy comparison for three versions
of Elastic on the tasks of flow size estimation and
heavy hitter detection. Results are evaluated using the
CAIDA4 trace. Each algorithm uses 600KB memory.
The heavy part in Elastic is 150KB.
in Figure 8, the software, hardware, and P4 versions are
always more accurate than the basic version. Specifically,
when using monitoring time interval of 5s, for flow size
estimation, the software and hardware version are 2.14, 1.6
times, and 1.46 times more accurate than the basic version,
respectively; for heavy hitter detection, these three versions
are 1.18, 1.18, and 1.17 times more accurate, respectively.
FPGA Implementation: We implement the Elastic sketch
on a Stratix V family of Altera FPGA (model 5SEEBF45I2).
The capacity of the on-chip RAMs (Block RAM) is 54,067,200
bits. The resource usage information is as follows: 1) We use
1,978,368 bits of Block RAM, 4% of the total on-chip RAM. 2)
We use 36/840 pins, 4% of the total 840 pins. 3) We use 2939
logics, less than %1 of the 359,200 total available. The clock
frequency of our implemented FPGA is 162.6 MHz, meaning
processing speed of 162.6 Mpps.
GPU Implementation: We use the CUDA toolkit [64] to
write programs on GPU to accelerate the insertion time of
Elastic sketch. Two techniques, batch processing and multi-
streaming, are applied to achieve the acceleration. We use
an NVIDIA GPU (GeForce GTX 1080, the frequency is 1607
MHz. It has 8 GB GDDR5X memory and 2560 CUDA cores).
6.2 Software Version Implementations
We have implemented the software version of Elastic on
three software platforms: CPU, multi-core CPU, and OVS.
Implementation details are provided in the our technical
report [47], due to space limitation.
7 EXPERIMENTAL RESULTS
7.1 Experimental Setup
Traces: We use four one-hour public traffic traces collected
in Equinix-Chicago monitor from CAIDA [65]. The details
of these traces are shown in technical report. We divide each
trace into different time intervals (1s, 5s, 10s, 30s, and 60s).
For example, each one-hour trace contains 720 5s-long sub-
traces, and we plot 10th and 90th percentile error bars across
 0 2 4 6 8 0 10 20 30 40 50 60AREMonitoring time interval (s)BasicFPGAP4Software 0 0.2 0.4 0.6 0.8 1 0 10 20 30 40 50 60F1 scoreMonitoring time interval (s)BasicFPGAP4Softwarethese 720 sub-traces. We use the CAIDA4 trace with a mon-
itoring time interval of 5s as default trace, which contains
1.1M to 2.8M packets with 60K to 110K flows (SrcIP). Due to
space limitations, we only show the results with the source
IP as the flow ID; the results are qualitatively similar for
other flow IDs (e.g., destination IP, 5-tuple).
|fi−(cid:98)fi |
Evaluation metrics:
• ARE (Average Relative Error): 1
number of flows, and fi and(cid:98)fi are the actual and estimated
, where n is the
n
i =1
fi
n
P R+RR
flow sizes respectively. We use ARE to evaluate the accu-
racy of flow size (FS) estimation and heavy hitter (HH)
detection. Note that the value of ARE for flow size esti-
mation could be larger than anticipated, since the sizes
of mouse flows are often over-estimated while they are
in the denominator of the ARE formula, leading to large
average value of relative error.
• F1 score: 2×P R×RR
, where PR (Precision Rate) refers to the
ratio of true instances reported and RR (Recall Rate) refers
to the ratio of reported true instances. We use F1 score to
evaluate the accuracy of heavy hitter and heavy change
z
i =1 |ni−(cid:98)ni |
(HC) detection.
z
where z is the maximum flow size, and ni and(cid:98)ni are the
i =1( ni +(cid:98)ni2
• WMRE (Weighted Mean Relative Error) [12, 17]:
true and estimated numbers of flows of size i respectively.
We use W MRE to evaluate the accuracy of the flow size
distribution (FSD).
• RE (Relative Error):
, where True and
Estimate are the true and estimated values, respectively.
We use RE to evaluate the accuracy of entropy and cardi-
nality estimations.
• Throughput: million packets per second (Mpps). We use
Throuдhput to evaluate the processing speed of the six
tasks.
|T rue−Estimated |
T rue
)
,
Setup: When comparing with other algorithms, we use the
software version of Elastic. Specifically, we store 7 flows
and a vote− for each bucket in the heavy part, and use one
hash function and 8-bit counters in the light part. For each
algorithm in each task, the default memory size is 600KB.
The heavy part does not dynamically resize except for the ex-
periments of adaptivity to traffic distribution (Section 7.4.3).
Detailed configurations for each task are as follows:
• Flow size estimation: We compare four approaches:
CM [10], CU [4], Count [14], and Elastic. For CM, CU, and
Count, we use 3 hash functions as recommended in [66].
• Heavy hitter detection: We compare six approaches: Space-
Saving (SS) [15], Count/CM sketch [10, 14] with a min-
heap (CountHeap/CMHeap), UnivMon [2], HashPipe [16]
and Elastic. For CountHeap/CMHeap, we use 3 hash func-
tions and set the heap capacity to 4096. For UninMon, we
use 14 levels and each level records 1000 heavy hitters. We
set the HH threshold to 0.02% of the number of packets in
one measurement epoch.
• Heavy change detection: We
compare Reversible
sketch [67], FlowRadar [18], UnivMon, and Elastic. For
Reversible, we use 4 hash functions as recommended
in [67]. For FlowRadar, we use 3 hash functions in both
the Bloom filter [44] and the IBLT part [45]; we allocate
1/10 of the memory for the Bloom filter and the rest for
IBLT. UnivMon uses the same setting as before. We set the
HC threshold as 0.05% of total changes over two adjacent
measurement epochs.