invoke the corresponding methods via reﬂection. For such an
application, the detection approach outlined above would not
work, because it would not contain any suspicious API calls.
Furthermore, it is difﬁcult to detect in an automated analysis
that an application implements such a “reﬂection VM.” A
possible remediation is for veriﬁcation services to reject all
applications that make extensive use of reﬂection.
A. System protection
Google introduced a security mechanism in Android 4.2
that contacts the Google servers whenever an application is
installed via sideloading [2]. The system computes a SHA-
256 hash of the APK and sends it to Google along with
other information about the application, asking if it is known
to be malicious. If so, the system warns the user instead
of installing the application. Google effectively implements
a blacklist approach with this protection mechanism. Such a
system has the considerable disadvantage that it is restricted
to known malware. Note that the protection scheme is only
active if Google Play is installed on the device and a network
connection is available. If the device is not currently connected,
the system silently allows the user to install the application.
Furthermore, the protection mechanism is only invoked during
application installations, so most of the techniques described
in Section III-A can be used to circumvent it.
Apple uses a technique called Mandatory Code Signing
in iOS [11]. It enforces at a memory-page level that all exe-
cuted code is signed. Developers sign their applications with
certiﬁcates issued by Apple. Additionally, from the moment
the system is powered on, it ensures that only signed code
is executed, including veriﬁcation of the boot loader and the
operating system itself (the Secure Boot Chain) [4]. The chain
starts from a key that is hard-coded into read-only memory
on the chip of any device running iOS. While this approach
provides a high level of security against code injection and
execution of unapproved code, it requires modiﬁcations deep
within the operating system as well as changes to the hardware.
We feel that Android cannot adopt a similar mechanism in
the near future due to the extensive changes to hardware
and software that would be necessary. Furthermore, Apple’s
approach ties the user to a single application veriﬁcation entity:
If Apple does not approve an application, then there is no
way to run it on an iOS device (as long as the device is
not “jailbroken”). Our approach addresses this issue by giving
users the possibility to choose which veriﬁcation services to
trust.
Smalley and Craig ported the well-known security kernel
extension SELinux [28], [33] to Android [32]. SELinux is able
to enforce policies on the behavior of running applications,
thus limiting the interaction of a surveyed process with its
environment to those activities that it legitimately requires.
However, without tailoring policies speciﬁcally to the applica-
tion in question, only general rules can be established. Thus,
SELinux on Android does not restrain an application that
loads and executes additional code but only conducts activities
within the limits of its permissions. Alternatively, application
developers would have to write policies for their applications.
The risk in such a scenario is that developers write policies that
are not strict enough to avoid malicious activity. Also, the need
to deﬁne a policy in SELinux’s extensive policy language [31]
would slow down application development and would thus be
difﬁcult to enforce.
Another widely researched technique to protect Android
systems is Dalvik bytecode rewriting [20]. The basic idea
is to detect the portions of an application that call security-
sensitive APIs and to redirect the calls to a monitor service
14
that implements ﬁne-grained access control. This modiﬁcation
of the bytecode can take place ofﬂine if static analysis is
used. However, external code that an application might load
at runtime poses a problem [12]. If rewriting takes place
before the application is installed, then code loaded at runtime
evades the rewriting process and is thus not restricted by
the added protection mechanisms. To counter this attack,
bytecode rewriters would have to run on the Android device
and constantly watch for attempts to access sensitive APIs that
have not been rewritten. This is computationally expensive and
not desirable on mobile devices, where system resources are
limited and battery life is a crucial factor.
B. Vulnerability analysis
In a study on the use of SSL in Android applications,
Fahl et al. show that a large portion of applications does not
make appropriate use of the security beneﬁts of SSL [15]. In
fact, they demonstrate that many popular applications from
Google Play are vulnerable to various attacks, because the
developers did not implement security mechanisms correctly.
They conclude that one part of the problem is the lack of
easy-to-use security features for application developers. Their
results emphasize the necessity of security mechanisms that
the operating system enforces for all applications, independent
from the individual application developers, as implemented in
our approach.
In 2010, Jon Oberheide demonstrated how to download ar-
bitrary additional code in Android applications at runtime [26].
He used the technique to distribute root exploits to devices
running his application.
Bellissimo et al. demonstrated in 2006 that many update
mechanisms of applications and operating systems are inse-
cure [6]. Their attacks are similar to those that we apply against
Android applications, but targeted at desktop software.
the ﬁrst
We are not
to use static analysis in order to
detect vulnerabilities in Android applications. Au et al. use
it
to ﬁnd a mapping between Android APIs and required
permissions for different versions of Android [5]. Lu et al.
employ static analysis techniques to detect applications that
expose components to other applications in an insecure way,
leading to the risk of what they call component hijacking [22].
Zhou and Jiang ﬁnd similar vulnerabilities – they detect
applications that expose access to content providers in a way
that allows other applications to read or modify protected
content [38]. Chin et al. analyze the general communication
interface that an application provides to other applications in
order to detect possibilities of information leakage [9]. Grace et
al. detect capability leaks in preinstalled Android applications,
i.e., permissions that are requested by system applications, but
not properly protected against unauthorized use by third-party
applications [17].
The previously presented approaches focus on detecting
speciﬁc vulnerabilities in applications. They could be used by
the veriﬁcation services that we propose in order to detect
vulnerabilities in benign applications.
In 2012, Grace et al. used static analysis to detect some
of the code-loading techniques discussed in this paper [18].
Speciﬁcally, they searched for uses of native code and Dex-
ClassLoader in Android applications in an effort to identify
malicious applications in stores. However, their work does not
cover the other categories of code-loading techniques discussed
in Section III-A, nor do the authors propose a protection
scheme to systematically prevent the risks associated with
dynamic code loading. Similarly, another publication by Grace
et al. leverages static analysis to ﬁnd uses of DexClassLoader
during the analysis of advertisement frameworks [19] but also
falls short of detecting the other code-loading techniques or
offering a protection mechanism in solution.
IX. CONCLUSION
Our analysis shows that the ability of Android applications
to load code at runtime causes signiﬁcant security issues. We
were able to demonstrate that a surprisingly large portion of
existing applications is vulnerable to code injection due to
improper use of different loading techniques. This is made
worse by the fact that the vulnerabilities are often found in
frameworks that are used by large numbers of applications.
Additionally, we showed that attackers could use dynamic
code-loading to avoid detection by ofﬂine application analysis
engines, in particular the Google Bouncer. In order to auto-
matically detect such vulnerable or malicious functionalities,
we implemented a static analysis tool and we showed its
effectiveness in detecting interesting samples.
Furthermore, we presented a modiﬁcation to the Android
system that prevents exploits resulting from vulnerable loading
techniques by ensuring that all loaded code is approved by
an application veriﬁcation service. Based on this mechanism,
we proposed a general architecture of different veriﬁcation
services that users can choose from. We showed that our
protection system is able to prevent all attacks presented in
this paper. It is our hope that the proposed modiﬁcation will
ﬁnd its way into a future release of Android in order to be
distributed to as many devices as possible.
ACKNOWLEDGEMENTS
This material is based on research sponsored by DARPA
under agreement number FA8750-12-2-0101. The U.S. Gov-
ernment is authorized to reproduce and distribute reprints for
Governmental purposes notwithstanding any copyright nota-
tion thereon. The work was also supported by the Ofﬁce of
Naval Research (ONR) under grant N000140911042, the Army
Research Ofﬁce (ARO) under grant W911NF0910553, and by
Secure Business Austria.
REFERENCES
“Android NDK.” [Online]. Available: http://developer.android.com/
tools/sdk/ndk/index.html
“Security Enhancements
in Android 4.2,” accessed July 2013.
[Online]. Available: https://source.android.com/devices/tech/security/
enhancements.html
“Android library statistics,” AppBrain, URL shortened to protect
users of
[Online]. Available: http:
//www.appbrain.com/stats/libraries
the vulnerable
framework.
iOS Security, Apple, October 2012.
//images.apple.com/iphone/business/docs/iOS Security Oct12.pdf
[Online]. Available: http:
[1]
[2]
[3]
[4]
[5] K. W. Y. Au, Y. F. Zhou, Z. Huang, and D. Lie, “Pscout: analyzing
the android permission speciﬁcation,” in Proceedings of
the ACM
Conference on Computer and Communications Security. ACM, 2012,
pp. 217–228.
15
[22] L. Lu, Z. Li, Z. Wu, W. Lee, and G. Jiang, “Chex: statically vetting
android apps for component hijacking vulnerabilities,” in Proceedings
of the ACM Conference on Computer and Communications Security.
ACM, 2012, pp. 229–240.
[23] T. Luo, H. Hao, W. Du, Y. Wang, and H. Yin, “Attacks on WebView in
the Android system,” in Proceedings of the Annual Computer Security
Applications Conference. ACM, 2011, pp. 343–352.
Threats
Report:
First
[25]
Quarter
[24] McAfee
2013, McAfee,
2013. [Online]. Available: http://www.mcafee.com/us/resources/reports/
rp-quarterly-threat-q1-2013.pdf
J. Oberheide and C. Miller, “Dissecting the android bouncer,” Summer-
Con New York, 2012.
J. Oberheide, “Android hax,” SummerCon New York, 2010.
[26]
[27] N. J. Percoco and S. Schulte, “Adventures in bouncerland,” Black Hat
USA, 2012.
[28] N. Peter Loscocco, “Integrating ﬂexible support for security policies
into the Linux operating system,” in Proceedings of the FREENIX Track,
USENIX Annual Technical Conference. The Association, 2001, p. 29.
[29] D. Sehr, R. Muth, C. Bifﬂe, V. Khimenko, E. Pasko, K. Schimpf,
B. Yee, and B. Chen, “Adapting software fault isolation to contemporary
cpu architectures.” in Proceedings of the USENIX Security Symposium,
2010, pp. 1–12.
[30] H. Shacham, “The geometry of innocent ﬂesh on the bone: Return-into-
libc without function calls (on the x86),” in Proceedings of the ACM
Conference on Computer and Communications Security. ACM, 2007,
pp. 552–561.
[31] S. Smalley, “Conﬁguring the SELinux policy,” NAI Labs Rep, pp. 02–
007, 2002.
[32] S. Smalley and R. Craig, “Security Enhanced (SE) Android: Bringing
Flexible MAC to Android,” in Proceedings of the Network and Dis-
tributed System Security Symposium, 2013.
[33] S. Smalley, C. Vance, and W. Salamon, “Implementing SELinux as a
Linux security module,” NAI Labs Report, vol. 1, p. 43, 2001.
[34] T. Vidas, D. Votipka, and N. Christin, “All Your Droid Are Belong
to Us: A Survey of Current Android Attacks.” in Proceedings of the
USENIX Workshop on Offensive Technologies, 2011, pp. 81–90.
Conference on Software Engineering.
[35] M. Weiser, “Program slicing,” in Proceedings of
the International
IEEE Press, 1981, pp. 439–449.
[36] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth, T. Ormandy,
S. Okasaka, N. Narula, and N. Fullagar, “Native client: A sandbox
for portable, untrusted x86 native code,” in Proceedings of the IEEE
Symposium on Security and Privacy.
IEEE, 2009, pp. 79–93.
[37] Y. Zhou and X. Jiang, “Dissecting android malware: Characterization
and evolution,” in Proceedings of the IEEE Symposium on Security and
Privacy.
IEEE, 2012, pp. 95–109.
[38] ——, “Detecting passive content leaks and pollution in android applica-
tions,” in Proceedings of the Network and Distributed System Security
Symposium, 2013.
[39] Y. Zhou, Z. Wang, W. Zhou, and X. Jiang, “Hey, you, get off of my
market: Detecting malicious apps in ofﬁcial and alternative android mar-
kets,” in Proceedings of the Network and Distributed System Security
Symposium, 2012.
[6] A. Bellissimo, J. Burgess, and K. Fu, “Secure software updates:
disappointments and new challenges,” USENIX Hot Topics in Security,
2006.
J. Callas, L. Donnerhacke, H. Finney, D. Shaw, and R. Thayer,
“OpenPGP Message Format,” RFC 4880.
[Online]. Available:
http://tools.ietf.org/html/rfc4880#section-5.2
[7]
[8] S. Checkoway, L. Davi, A. Dmitrienko, A.-R. Sadeghi, H. Shacham,
and M. Winandy, “Return-oriented programming without returns,” in
Proceedings of the ACM Conference on Computer and Communications
Security. ACM, 2010, pp. 559–572.
[9] E. Chin, A. P. Felt, K. Greenwood, and D. Wagner, “Analyzing inter-
application communication in Android,” in Proceedings of the Inter-
national Conference on Mobile Systems, Applications, and Services.
ACM, 2011, pp. 239–252.
[10] R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and F. K. Zadeck,
“Efﬁciently computing static single assignment form and the control
dependence graph,” ACM Transactions on Programming Languages and
Systems, vol. 13, no. 4, pp. 451–490, 1991.
[11] D. A. Dai Zovi, “Apple iOS 4 security evaluation,” Black Hat USA,
2011.
[12] B. Davis, B. Sanders, A. Khodaverdian, and H. Chen, “I-arm-droid:
A rewriting framework for in-app reference monitors for android
applications,” Mobile Security Technologies, vol. 2012, 2012.
[13] A. Desnos, “androguard – Reverse engineering, Malware and goodware
analysis of Android applications . . . and more (ninja !).” [Online].
Available: http://code.google.com/p/androguard/
[14] M. Egele, D. Brumley, Y. Fratantonio, and C. Kruegel, “An empirical
study of cryptographic misuse in android applications,” in Proceedings
of the ACM Conference on Computer and Communications Security.
ACM, 2013, pp. 73–84.
[15] S. Fahl, M. Harbach, T. Muders, M. Smith, L. Baumg¨artner, and
B. Freisleben, “Why Eve and Mallory love Android: An analysis of
Android SSL (in) security,” in Proceedings of the ACM Conference on
Computer and Communications Security. ACM, 2012, pp. 50–61.
“Google
accessed July 2013.
about/developer-content-policy.html
Inc.,
[Online]. Available: https://play.google.com/
Program Policies,” Google,
Play Developer
[16]
[17] M. Grace, Y. Zhou, Z. Wang, and X. Jiang, “Systematic detection of
capability leaks in stock Android smartphones,” in Proceedings of the
Network and Distributed System Security Symposium, 2012.
[18] M. Grace, Y. Zhou, Q. Zhang, S. Zou, and X. Jiang, “Riskranker: scal-
able and accurate zero-day android malware detection,” in Proceedings
of the International Conference on Mobile Systems, Applications, and
Services. ACM, 2012, pp. 281–294.
[19] M. C. Grace, W. Zhou, X. Jiang, and A.-R. Sadeghi, “Unsafe exposure
analysis of mobile in-app advertisements,” in Proceedings of the ACM
Conference on Security and Privacy in Wireless and Mobile Networks.
ACM, 2012, pp. 101–112.
[20] H. Hao, V. Singh, and W. Du, “On the effectiveness of API-level access
control using bytecode rewriting in Android,” in Proceedings of the
ACM SIGSAC Symposium on Information, Computer and Communica-
tions Security. ACM, 2013, pp. 25–36.
[21] H. Lockheimer, “Android and security.” [Online]. Available: http:
//googlemobile.blogspot.com/2012/02/android-and-security.html
16