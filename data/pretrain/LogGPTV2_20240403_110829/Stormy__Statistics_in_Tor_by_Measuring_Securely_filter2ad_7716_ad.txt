h
{(x(i)
h
+ s(i)
h )).
8. C locally computes [[sh]] + (xh + sh) = [[xh]] for 1 ≤ h ≤ b.
Figure 4: Protocol for input sharing.
(6) Each relay runs FInput with the CC to provide its input. If
an input relay is disqualified, his input is dropped but the
protocol continues. If a CC member aborts, the protocol
stops.
(7) The CC runs FOnline to securely evaluate the circuit C. If
any party in the CC aborts, the protocol stops.
To analyze the security of this protocol, we introduce a new
model of security for Relay Model MPC protocols (FRM−MPC)
that we believe captures the requirements for MPC protocols run
between a large number of parties. Specifically, our model builds on
the secure computation with abort and no fairness definition given
by Goldwasser and Lindell (Def. 5, [34]). This is a relaxation of
security with abort in which the adversary is allowed to specify
which honest parties abort and which ones receive output.
In our model we additionally designate a small set of parties (the
CC) such that an adversary A is only allowed to abort the func-
tionality (as described above) if CC ∩ A , ∅. This is necessary in a
large-scale deployment where many more parties may participate
in the protocol, but should not be able to interrupt the computation
(either due to churn or malicious failure). Informally, the function-
ality provides security with abort against members of CC and full
security (without allowing abort) against everyone else. A formal
description of FRM−MPC is given in Figure 10 (Appendix A) and a
proof of the following theorem is given in the technical report [65].
Theorem 4.4. If m committees of size c = ⌈(λ + log2(m)) /
log2(1/f )⌉ are sampled, then ΠRM−MPC securely realizes FRM−MPC
in a standalone (FPre, FInput, FOnline)-hybrid model against a static,
malicious adversary corrupting less than an f fraction of the total
available bandwidth.
5 HANDLING PARTY CHURN
A key goal of Stormy is to be resilient to party failures as well
as malicious behavior. We now discuss how we use the protocols
described in Section 4 to achieve this. The discussion in this section
is restricted to the Relay Model.
In Stormy, time is partitioned into a series of epochs (e.g. 24 hour
periods). During an epoch, committees are elected once (when in the
Relay Model), and then many rounds of offline preprocessing and
online computation are run within the epoch. We wish to provide
security over an epoch; that is, we bound the probability that the
adversary succeeds in subverting security in committee election,
offline preprocessing, or online computations to be at most 2−λ
during an epoch. In this section, we describe how Stormy operates
over an epoch.
5.1 Committee Usage
In the Relay Model, two hours before the start of the epoch, Tor’s
DirAuths create an Epoch Document. This document is produced
and distributed using Tor’s existing consensus mechanism (Sec-
tion 2) and is an extension of the existing daily generaton of shared
randomness. Each relay downloads the Epoch Document in addi-
tion to the current consensus, and can be expected to be able to
obtain it in time as relays already must have a consenus within
two hours of the current time. The Epoch Document contains: (1)
the random string currently produced daily by Tor, and (2) a list of
relays and their consensus weights. The Epoch Document provides
a consistent view of the network for a given epoch that each relay
uses to locally determine the Triple Committees and Computation
Committees. An Epoch Document is valid for only its epoch.
Session 3C: Secure Computing IICCS ’19, November 11–15, 2019, London, United Kingdom622During the committee-election process in the Relay Model, we
select mTC Triple Committees and mCC Computation Committees
(see Sec. 4.1). However, we do not use all of these simultaneously; we
find subsets with good performance, and hold some committees in
reserve to replace committees that die due to churn. We consider
every committee elected in an epoch to be in one of three states:
active, inactive, and dead. Active committees are actively running a
system protocol. Inactive committees are still responsive and avail-
able for use but have not yet been made active. Dead committees
failed or aborted at some point in the epoch, and they are not used.
All committees begin the epoch as inactive, some initial subset
is made active, and, as active committees die, inactive ones may
become active to replace them.
A main constraint on the use of TC committees is that we wish to
limit Stormy’s bandwidth consumption to a fraction b of Tor’s total
bandwidth. This reserves Tor’s resources for its primary purpose of
relaying client traffic. We set b = 0.25, leaving room for variation
in Tor’s traffic, as one half of Tor’s bandwidth goes unused and 95%
of relay bandwidth has at least 25% spare capacity.
The other main constraint on TC is the limited memory of the
relays. A single relay may belong to several active TCs and thus
simultaneously run many protocol executions. Each execution uses
a non-trivial amount of memory (e.g. 291 MiB in the setting we will
consider). Therefore, we must limit the number of active committees
that share a single member.
We initially activate a TC if doing so doesn’t violate these con-
straints, and increases overall bandwidth. That is, we consider the
TCs in order and add them if the total bandwidth used is less than
a b-fraction of Tor’s total bandwidth, if no relay would use too
much memory (we can use a conservative limit of 8 GiB for the
largest 1% of relays and 3 GiB for the rest), and if no member of
the committee has its bandwidth fully allocated to already-active
committees. Then, when a committee dies during the epoch, we
repeat the process with the remaining inactive committees.
We use a different process to activate a CC, because only one
is active at a time. This committee has sole responsibility for bit
generation and online computation, and thus should have high
bandwidth. Therefore, we simply activate the inactive committee
with the highest bandwidth. The same process applies if the active
CC dies during the epoch.
5.2 Protocol Aborts
Unlike the set of stable authorities, temporary relay downtime is
commonplace for benign reasons; for example, a relay operator may
take his relay down to apply software patches, or a hosting center
may lose power. To account for this natural churn, a design goal for
Stormy is that the system should tolerate some failures instead of
completely halting for the epoch when a relay goes offline or causes
an abort. During triple generation, if a TC fails, each member of the
TC notifies each member of the active CC, and the TC is marked
dead. If there exist any inactive TCs, a new TC will be activated.
The CC runs a MAC check on each batch of triples it receives
from a TC to ensure that no errors have been introduced during
transfer; if the MAC check fails, the TC is marked dead, and a new
TC is activated if possible. The only other possible failures occur
during bit generation, input sharing, and online computationÐall
within the active CC. If the active CC fails, each CC member notifies
each relay in the network, and a new CC is activated if there are
any inactive CCs. Stormy halts in RelMode only when all TCs or
CCs are marked dead. Committees are reelected and protocols are
restarted at the beginning of the next epoch.
5.3 Security Parameters
Among the system components, many of the potential security
failure events occur independently. During committee election,
there is a chance that some committee is composed entirely of
malicious parties. There is a chance that a given triple committee
deviates from the protocol and is not caught. Finally, there is a
chance that the computation committee acts maliciously during bit
generation, input sharing, or online computation and is not caught.
To achieve λ-bit statistical security overall for an epoch, we must
consider the probability that any one of these occurs.
In the Authority Model, setting all statistical security parame-
ters to λ is sufficient regardless of the number of authorities, because
there is no committee election, and all computation halts for the
epoch upon any abort. The same is not true of the Relay Model
Ð mTC TCs and mCC CCs are elected, and the adversary can at-
tempt to cheat in each of them. The chance that a given committee
is entirely malicious is f c , where f denotes the adversary’s frac-
tion of bandwidth, and c denotes the size of each committee. Let
m = mTC + mCC, let λ1 be the statistical security parameter dur-
ing triple generation, and let λ2 be statistical security parameter
during bit generation, input sharing, and online computation. By
applying a union bound, the adversary’s overall success probability
is at most m f c + mTC2−λ1 + mCC2−λ2 . To bound this by 2−λ , we
simplify the security constraint by setting λ1 = λ2 = λ′, which
yields the requirement that m(f c + 2−λ′) ≤ 2−λ . With m = 1008,
f = 0.25, and c = 25, setting λ′ = 56 is sufficiently large to provide
overall λ = 40-bit statistical security.
6 TOR COMPUTATIONS
We present two computations that are useful in Tor, median and
set-union cardinality, and we describe how they can be efficiently
computed via MPC. Even just these two functions could be applied
to measure and monitor many types of activity on the Tor network.
Moreover, they demonstrate key techniques, such as sorting and
sketching, needed for other types of computations. We expect that
these methods could be applied to a wide variety of use cases within
Tor, including for denial-of-service detection and mitigation, moni-
toring for protocol anomalies, detecting network errors and failures,
understanding user behavior, tracking performance characteristics,
and detecting blocking of clients and exits.
6.1 Median
The first function we demonstrate is the median of the relay in-
puts. The median is a robust statistic, insensitive to the presence
of outliers. This property is valuable in the context of Tor because
malicious relays can provide arbitrary inputs that might make other
statistics, such as average or maximum, meaningless. For an ex-
ample of how we might use median to to securely determine the
number of circuit failures in a day, each relay can count the num-
ber it observes, then it can infer a global count by dividing by the
fraction of circuits its sees (i.e. its bandwidth fraction), and then the
Session 3C: Secure Computing IICCS ’19, November 11–15, 2019, London, United Kingdom623Table 1: Median circuit properties with 32-bit inputs.
# Inputs
# Input Bits
# Gates (×106)
# AND Gates (×106)
Depth
AND Depth
1,000
32,000
6.70
1.51
7,031
1,815
3,000
96,000
2.76
6.19
9,973
2,574
5,000
160,000
54.0
12.1
11,636
3,003
7,000
224,000
78.4
17.6
11,636
3,003
median of these values provides a robust estimate of the true total
count. This method can be used for any measurement for which
a relay can use its local measurements to make an inference of
the global statistic, such as counting the number of circuits, bytes,
clients, etc.
To securely compute the median, we use a circuit that sorts the
input values and then outputs the middle one. We use a Batcher odd-
even mergesort, which is a practical sorting network for realistic
numbers of inputs [66]. For each compare-and-swap operation
in the network, we use a comparison circuit with low AND-gate
complexity [52]. The total number of AND gates in the resulting
circuit on n inputs of b bits each is at most bn⌈log2
2(n)⌉/2, and
its AND depth is (b + 1)(⌈log2(n) + 1⌉⌈log2(n)⌉/2). Table 1 shows
the size and depth of the median circuit for different numbers of
32-bit inputs. Using 32-bit inputs enables integer input values up
to 4 billion, which is sufficient for most measurements of the Tor
network that relays might make.
6.2 Set-Union Cardinality
The second function we demonstrate is the cardinality of the union
of sets observed at the relays. That is, this function counts the num-
ber of distinct items among all items seen by relays. This computa-
tion is not robust, but could still provide much useful information
about the Tor network, such as how many unique users it has,
how that population changes over time, and how many different
domains are visited.
Computing set-union cardinality is straightforward if the do-
main is smallÐeach relay maintains its set as a bit vector, each
observed item is hashed to an entry, and its value set to 1. The
relays use the vectors as input to a secure computation of the OR
of each entry, receiving as output the total number of entries with
value 1. However, this approach doesn’t scale well with the domain.
Tor has estimated as many as 4 million different users in a day.
Taking the union (i.e. the OR) of million-bit inputs from thousands
of relays would require billions of expensive triples to be gener-
ated offline. Similarly, counting billions of distinct items (e.g. URLs
visited) would require billions of additions and thus triples.
Therefore, we instead use a representation of set cardinalities
that is much smaller and enables cheaper MPC through the use of
free-XOR. Each relay stores a LogLog sketch [27], which provides
space-efficient counting of distinct items given a fixed relative error.
We choose LogLog over more-recent improvements [37] because
the circuit computing the count of a LogLog sketch is simpler.
Each LogLog sketch consists of k counters of bit-width w. We
modify the standard sketch by (1) storing each counter in a unary
representation (making the maximum stored value 2w instead of
22w
), and (2) representing the 0 or 1 value at each counter entry
with a bitstring of length s, where 0s represents 0 and any non-
zero string represents 1. These changes will reduce the number of
expensive AND gates needed during the MPC computation.
A relay locally updates its LogLog sketch when it observes an
item x. The relay hashes x to H(x) and uses the first log2(k) bits
of H(x) to determine which counter, Ci , to update. Examining the
remaining bits of H(x), the relay determines the largest number j
of consecutive ones at the beginning of that bitstring. The relay
then sets the first j entries of the chosen counter Ci to 1. The s-bit
representation of each of those entries is set to 1 by choosing each
of its s bits uniformly at random. We set s ≥ ⌈λ + log2(kw)⌉ so that,
over all counter entries, a random value results in a non-zero value
with probability at least 1 − 2−λ .
Using this input representation significantly improves the effi-
ciency of the computation. It reduces the OR of the counter bits
to XOR operations, which are free. This opens an attack in which
a malicious Computation Committee member sets a counter to 0,
but doing so requires guessing an unknown random s-bit value,
and s is chosen so that this occurs with probability at most 2−λ .
(Note that a CC member can easily change a 0 value to a 1, but
this is allowed, since it can provide a logical 1 in its own input
for any counter entry, which remains 1 after taking the union.)
Therefore, we do not need to protect against errors until after in-
put sharing and union are computed through bitwise XORÐinput
parties simply secret-share their inputs to the CC using FAccMsg,
and committee members then just XOR the inputs. Only afterwards
do they use the preprocessed random bits to add MAC tags to the
resulting secret-shared values. The unique count is then computed
from those aggregated counters.
To obtain this cardinality, the secure computation determines
the last index zi of a 1 entry in each counter Ci (0 if none) and
returns the sum z = i zi of these indices. Durand and Flajolet [27]
show that αk2z/k is an unbiased estimator of the true distinct count,
where α is a constant that adjusts for bias. They also show that
√k. Thus the value
it has a standard error of approximately 1.3/
produced by the secure computation can be transformed into a
cardinality estimate using public information.
The total number of AND gates in this LogLog circuit is at
most k(w(s + 1) + ⌈log2(w)⌉ + ⌈log2(k)⌉). Its AND depth is at most
⌈log2(s)⌉ + w + ⌈log2(k)⌉(⌈log2(w)⌉ + ⌈log2(k)⌉). Table 2 shows the
size and accuracy of the LogLog circuit with counters of width
w = 32 and counter entries of size s = 55 bits. With 32 entries
per counter, cardinalities above 4 billion can be measured. For
k = 1, 024, setting the bits per entry at s = 55 yields the desired
failure probability of at most 2−40. Note the circuit size doesn’t
vary with the number of inputs, which means that the amount of
MPC communication after input sharing would not be affected by
growth in the Tor network.
7 EXPERIMENTAL EVALUATION
In this section, we evaluate the performance of Stormy. We have
implemented all of the protocols in roughly 10k lines of C/C++. 3