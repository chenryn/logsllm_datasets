To propagate to the application outputs, an error must corrupt at least one register. NVBitFI models faults based on their eventual impact on registers. Specifically, our transient fault model simulates the effect of a single dynamic instruction's destination register being corrupted by a transient fault. The bit-level corruption is modeled as either a single or double bit-flip, random corruption, or a zeroing effect. Although real-world faults may have more complex manifestations, we offer these fault models as a generalizable approach.

Errors can spread across multiple registers if the fault affects persistent microarchitectural state. Additionally, bit-level error patterns are likely influenced by the opcode and instruction inputs. Since these more realistic error effects are difficult to generalize in a parameterized fault model, we provide a simpler but more generalizable fault model. Future work includes targeting specific threads, incorporating more complex bit patterns, using fault models with a greater number of parameters, and developing a fault dictionary parameterized based on opcodes, input registers, and other states.

**Permanent Fault Model:**
NVBitFI also supports a permanent fault model, which assumes that the fault affects all dynamic instances of a particular instruction type. For example, a permanent fault in an Arithmetic Logic Unit (ALU) would affect the results of all ADD instructions. The permanent fault model corrupts the destination registers of all dynamic instances of a specific opcode using the same bit-flip XOR mask.

Table III outlines the parameters for permanent faults. The list is simpler than for transient faults because the dynamic instruction to inject does not need to be specified. Instead, the opcode is specified, and all dynamic instructions with that opcode are injected. The permanent fault model is mapped to a physical location on the GPU, so the SM (Streaming Multiprocessor) and lane parameters indicate which SM and hardware lane to target for injection. All threads executing in the target SM and lane are considered for injection.

As with transient faults, we focus on a simple permanent fault model to present a generalizable approach. We recognize that realistic permanent faults may have error effects not always dependent on the execution of specific opcodes. Some permanent fault models, such as a stuck-at fault on the output of a register file, could be emulated as a corruption of the nth bit of every read from the register file. A fault in an ALU could corrupt the result of multiple opcodes that use that ALU. Future work includes determining which specialized permanent fault models are of interest to users and utilizing a fault dictionary approach, especially if derived from circuit and microarchitectural simulations. More sophisticated permanent fault models are discussed in Section V, but our current model allows analysis of a fault that repeatedly creates errors.

**C. NVBit:**
The `profiler.so` and `injector.so` libraries are built using NVBit [9], a dynamic binary instrumentation framework for NVIDIA GPUs. NVBit provides a convenient API for instruction inspection, callbacks to CUDA driver APIs, and injection of arbitrary CUDA functions into any application before kernel launch. This allows instrumentation tools to be created for CUDA programs without requiring detailed knowledge of the underlying GPU architecture.

By leveraging NVBit, the same tool can be used to inject faults into any CUDA executable without recompilation, simplifying the usage of the fault injector. The dynamic library is attached to a CUDA process using the `LD_PRELOAD` environment variable. As each dynamic kernel is launched, NVBit determines if it needs to be instrumented. If so, the kernel is instrumented and built with just-in-time compilation, and the compiled version is cached for subsequent launches. Kernels that do not need to be instrumented are executed without modification. This mechanism allows for selective and fast instrumentation.

**IV. Tool Evaluation:**
NVBitFI has been successfully applied to a large, commercial autonomous vehicle software (AV) application [22]. This complex application uses many dynamic libraries from several software packages, making fault injection tools that require source code recompilation impractical. A fault injection tool based on `cuda-gdb` would not require recompilation or management of source code, but `cuda-gdb` is a general debugger not designed specifically for fault injection, leading to significant performance overhead. This overhead would trigger real-time assertions in the AV application, which is a real-time system.

**SPECACCEL OpenACC 1.2 Benchmark Programs:**
Table IV describes the benchmark programs used in the evaluation. These include applications from various domains such as thermodynamics, computational fluid dynamics, medicine, molecular dynamics, and weather modeling.

**Possible Error Propagation Outcomes:**
Table V lists the possible outcomes of NVBitFI injections, including Silent Data Corruption (SDC), Detected Uncorrected Errors (DUE), and masked errors. SDC occurs when the standard output or output files differ from the golden output, or an application-specific check fails. DUE results from hangs, crashes, and non-zero exit status. If the application passes the SDC check, the error is masked. In some cases, a potential DUE can be declared if a non-handled anomaly is recorded by the system, such as a non-fatal CUDA message involving a memory access violation.

**A. Outcome Determination:**
For each application, we add an SDC checking script to determine if an SDC has occurred. The SDC checking script should reference a saved, golden version of the standard output and any files created without fault injection. The SpecACCEL package includes a program-specific checking script for each program, which we use to determine if an SDC has occurred.

**B. Benchmark Fault Injection Outcomes:**
We conducted three types of fault injection experiments on each of the 15 SpecACCEL programs: (1) transient faults with exact profiling, (2) transient faults with approximate profiling, and (3) permanent faults. For each transient fault experiment, we injected 100 faults per program. For the permanent fault experiment, we injected one fault for each opcode. The outcomes were classified based on the criteria in Section IV-A. The specific insights we aimed to analyze include the differences between exact and approximate profiling and the manifestation of permanent faults. More injected faults are necessary to tighten the confidence interval for all results [24], [25]. While we show experiments with 100 injections (providing 90% confidence intervals and ±8% error margins), 1000 injections are necessary for 95% confidence intervals and ±3% error margins.

**Exact vs. Approximate Profiling:**
Figure 2 compares the error propagation outcomes for exact and approximate profiling. The results show that although the results do not match completely, they are quite similar for most programs. The SDC, DUE, and masked differences are 32.5% vs. 37.9%, 4.2% vs. 4.5%, and 63.3% vs. 57.6%, respectively. These results suggest that approximate profiling produces sufficiently similar results to exact profiling for fault injection fidelity, though the similarity depends on the application.

[Figure 2: Exact vs. Approximate Profiling for Transient Fault Injection Results]

This figure illustrates the comparison of SDC, DUE, and masked outcomes for both exact and approximate profiling across the 15 SpecACCEL programs.