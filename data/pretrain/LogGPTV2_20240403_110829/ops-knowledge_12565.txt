User: Encounter an error "RequestTooLargeError: The request to API call datastore_v3.Put() was too large.". 
After looking through the code, it happens on the place where it is using task queue.
So how can I split a large queue task into several smaller ones?
Assistant: The maximum size of a task is 100KB. That's a lot of data. It's hard to give specific advice without looking at your code, but I would mention this:

If you pass a collection to be processed in a task in a loop, than the obvious solution is to split the entire collection into smaller chunks, e.g. instead of passing 1000 entities to one task, pass 100 entities to 10 tasks.
If you pass a collection to a task that cannot be split into chunks (e.g. you need to calculate totals, averages, etc.), then don't pass this collection, but query/retrieve it in the task itself. Every task is saved back to the datastore, so you don't win much by passing the collection to the task - it has to be retrieved from the datastore anyway.
If you pass a very large object to a task, pass only data that the task actually needs. For example, if your task sends an email message, you may want to pass Email, Name, and Message, instead of passing the entire User entity which may include a lot of other properties.

Again, 100KB is a lot of data. If you are not using a loop to process many entities in your task, the problem with the task queue may indicate that there is a bigger problem with your data model in general if you have to push around so much data every time. You may want to consider splitting huge entities into several smaller entities.