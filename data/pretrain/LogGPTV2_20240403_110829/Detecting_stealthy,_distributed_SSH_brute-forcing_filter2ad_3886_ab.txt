moved using this deﬁnition.
Finally, to give a sense of the volume of activity that remains af-
ter these ﬁltering steps, Figure 2 shows the empirical CDF of the
hourly and daily numbers of successful logins. A typical day sees
500 successful logins (maximum seen: 1,200) involving 117 dis-
tinct users (maximum: 197).
3.2 Correlation datasets
The HONEY dataset reﬂects ﬁve manually identiﬁed SSH brute-
forcing “campaigns” (our term for ongoing instances, as discussed
later) as captured by 2 SSH honeypot servers in Norway [4]. Ta-
ble 2 summarizes these campaigns, which for the most part we
characterize as large-scale, persistent, and stealthy. For all but the
last campaign, many of the remote clients would evade detection
by our simple per-host detector.
The RSRCHLAB dataset reﬂects ﬂow data from the International
Computer Science Institute, a research organization in Berkeley,
CA, with a /23 address block. The dataset spans the same time as
that of LBNL, though due to the limitations of ﬂow data, we cannot
Attack Episode
Oct 2009–Jan 2010
Jun 2010–Aug 2010
Oct 2011
Nov 2011
Apr 2012
Days
78
56
6
13
6
Remote
clients
4,158
5,568
338
252
23
Login
attempts
44,513
23,009
4,773
4,903
4,757
Avg. attempts
per remote client
10 (σ=24)
4 (σ=7)
14 (σ=16)
20 (σ=24)
206 (σ=760)
Table 2: Summary of attacks in the HONEY data.
8788than real-valued. We do so for our subsequent development of the
detector.
We then accumulate Zn over time using the following (again
discrete) test statistic: Sn = max(0, Sn−1 + Zn), where S0 = 0.
In the case of no change, the value of Sn hovers around zero, but
in the face of a change (increase), Sn starts to accumulate in the
positive direction.
By convention, one terms the situation of the mean correspond-
ing to normality as in-control. When the mean shifts by an amount
Δμ, one terms the situation out-of-control, which corresponds to
an attack in our problem domain. Note that the choice of Δμ is
speciﬁc to the problem we design the detector to detect. In some
situations, we might desire a small Δμ, while in others we might
only have interest in detecting changes corresponding to a large
value of Δμ. In practical terms, we achieve a given target Δμ by
setting two detector parameters, k and H, as discussed below.
The algorithm ﬂags an out-of-control situation when Sn crosses
an operator-set threshold, H. The subsequent appearance of an
event with normal mean marks the return of the situation to in-
control, and we reset the test statistic Sn to zero at this point. Thus,
the CUSUM detector decides whether the mean has shifted or not
according to the decision function Dn:
(cid:2)
Dn =
1,
0,
if Sn > Sn−1 and Sn > H
otherwise.
Determining CUSUM parameters and span of change. One
tunes the parameters k and H of CUSUM based on: the amount of
change Δμ to detect, the desired false alarm rate, and the desired
time to detection. First, a general rule of thumb when designing
a CUSUM detector to detect a mean shift of Δμ is to set k equal
to half the change in shift [10]. The other parameter, H, controls
both the false alarm rate and the detection speed. A lower H means
faster detection but a higher false alarm rate.
To assess the balance between these two, we consider the effects
of H on the average number of steps the CUSUM detector takes
to raise an alarm under in-control and out-of-control distributions.
(Note that the ﬁrst of these corresponds to alarms reﬂecting false
positives, while the latter corresponds to true positives.) We refer to
these as in-control ARL (Average Run Length) and out-of-control
ARL, respectively, and choose the value of H that results in the
closest match with the desired ARLs.
To determine these ARLs, we can model the CUSUM process as
a Markov chain with ﬁnite states X0, X1, . . . , XH, corresponding
to the test statistic values Sn ≤ 0, Sn = 1, Sn = 2, . . . , Sn ≥ H
(Recall that we constrain Z and thus S to discrete
respectively.
integer values.) Note that XH is the absorbing state. The transition
probabilities of this Markov chain depend only on the underlying
distribution of the random variable Z:
P [Xi → X0] = P [Z ≤ −i]
P [Xi → Xj] = P [Z = j − i]
P [Xi → XH ] = P [Z ≥ H − i]
For the intuition behind this formulation, consider the ﬁrst equa-
If the cumulative sum has reached i (i.e., Sn = i, corre-
tion.
sponding to the state Xi) then the possible ways for progressing
from it to the state X0 (i.e., Sn ≤ 0) are to add a value of Z less
than or equal to −i. A similar perspective holds for the other two
equations. Given the complete transition probability matrix R of
the Markov chain, we can compute the above probabilities and the
in-control ARL as:
in-control ARL = (I − R)−11
where R is the transition probability matrix, I is the (H + 1) ×
(H + 1) identity matrix, and 1 the (H + 1) × 1 matrix of ones [7].
We can likewise compute the out-of-control ARL of the detector
using the same formulation but substituting k(cid:2) = k − Δμ [10].
We can then estimate the point of the true start of a change by
subtracting the value of out-of-control ARL (detection delay) from
the time of detection.
Finally, the Aggregate Site Analyzer reports the information from
CUSUM in the form of attack epochs. An attack epoch constitutes
of: (i) the set of consecutive out-of-control events (i.e., i = 1 . . . n
where Di = 1), and (ii) the set of previous events also incorporated
into the epoch based on stepping back through the number of events
given by the out-of-control ARL.
Each attack epoch can reﬂect instances of either singleton or co-
ordinated attacks. The ﬁrst of these corresponds to a global pertur-
bation of the site-wide variable Y induced by a single source. The
second refers to the perturbation arising due to the combined ac-
tion of multiple sources. Since in this work we focus on distributed
attack epochs, we need at this point to exclude singleton attacks.3
We do so by checking whether CUSUM still ﬂags any events in
the epoch as reﬂecting an attack even if we remove the remote host
with the highest number of failed login attempts. If so, we mark the
attack epoch as a coordinated attack epoch, and proceed to the sec-
ond component of our analysis. Otherwise, we discard the epoch
as uninteresting (which occurred about 3/4s of the time).
4.2 Attack Participants Classiﬁer
The second component of our general detection approach ad-
dresses how to go from the global site-wide view to that of indi-
vidual entities. Here we employ a set of heuristics to analyze ac-
tivity in the attack epochs ﬂagged by the Aggregate Site Analyzer
to identify who participated in the attack. (The need for heuristics
rather than more principled identiﬁcation arises almost fundamen-
tally from the problem domain: if we could directly identify partic-
ipants with conﬁdence, we could very likely use the same approach
to develop an effective pointwise detector and not have to employ
a separate approach for detecting stealthy distributed activity in the
ﬁrst place.)
For our particular problem of detecting distributed SSH brute-
force attacks, the individual entities we wish to identify are re-
mote hosts (clients). In addition to the problem of including re-
mote hosts corresponding to legitimate users within it, a distributed
attack epoch—particularly if spanning a long period of time—can
capture multiple brute-forcers, some of whom might operate in a
coordinated fashion, while others might function independently.
For example, an attack epoch we detect that includes activity from
ﬁve remote hosts might in fact be composed of four coordinating
remote hosts and one singleton brute-forcer that happens to probe
the site at the same time.
For each remote host that appears during the attack epoch, we
make a decision about whether to classify it as a legitimate re-
mote host, a singleton brute-forcer (operating alone), or a brute-
forcer working with other hosts as part of a coordinated attack.
This decision might require manual analysis, as sometimes the cat-
egories have signiﬁcant overlap. To illustrate, Figure 4 diagrams
the characteristics that remote hosts in each of these categories can
manifest. Legitimate users that fail due to forgotten or mistyped
usernames/passwords generally exhibit only a modest number of
attempts, similar to low-rate distributed brute-forcers. A remote
3 Note that such single sources can arise even though we previously
ﬁltered out high-rate brute-forcers (per § 3.1) because these single-
tons might spread their activity across multiple servers, or probe at
a rate lower than the 20 failures/hour threshold.
899091instead used a beta-binomial distribution. We see from the inset
that the actual data exhibits more variance than we can capture us-
ing a binomial model. The beta-binomial model provides a sig-
niﬁcantly better ﬁt as it allows for an extra variance factor termed
over-dispersion. Beta-binomial is the predictive distribution of a
binomial random variable with a beta distribution prior on the suc-
cess probability, i.e., k ∼ Binomial(p, n) where p ∼ Beta(α, β).
Then for a given n, α and β, we have:
n
k
Beta(k + α, n − k + β)
Beta(α, β)
(cid:3)
(cid:4)
k ∼
We can interpret the success of this ﬁtting in terms of lack of in-
dependence. If all login attempts were IID, then we would expect
to capture GFI effectively using a binomial distribution. The need to
resort to a beta-binomial distribution indicates that the random vari-
ables lack independence or come from different distributions, such
that the probability of success has a beta-prior instead of being con-
stant. This makes sense intuitively because (i) different users will
have different probabilities of success, and (ii) the login attempts
from a single user are not independent: one failed login attempt
affects the probability of success of the next login attempt (neg-
atively if the user has forgotten their password, positively if they
simply mistyped it).
6. EVALUATION
In this section we apply our detection procedure to the extensive
LBNL dataset. We discuss parameterizing the detector, assess its
accuracy, and characterize the attacks it ﬁnds, including whether
the attacks appear targeted or indiscriminant.
6.1 Parameterization
Our procedure ﬁrst requires selecting a mean shift Δμ that we
wish to detect. We set this to 10 failed logins per event of 100 lo-
gins, basing our choice on the stealthiest attack we wish to de-
tect without overburdening the analyst. On average this site sees
500 logins per day, so a threshold of Δμ = 10 bounds the number
of attempts a brute-forcer can on average make without detection
to 45 (9 attempts × 5 events) spread over a day. Fitting our beta-
binomial distribution (§ 5) to the 2005–2008 data yields the param-
eters μ = 7 and σ = 4.24, and so our chosen value corresponds
to a shift in mean of approximately 2σ. (Note that this is different
from stating that we detect a “two sigma” event, because due to
the cumulative nature of the detection process, it takes signiﬁcantly
more perturbation to the site’s activity than simple stochastic ﬂuc-
tuations to reach this level.)
We choose the other parameter, the decision threshold H, based
on computing ARLs using the Markov chain analysis sketched
in § 4.1. Table 3 shows the in-control and out-of-control ARLs for
k = 5 and varying values of H. (We use k = 5 based on the rule-
of-thumb of setting k = Δµ
2 [10].) Given these results, we choose
H = 20, as this gives a quite manageable expected false alarm rate
of one-per-3,720 events, which, given that the site produces about
5 events per day, translates to an average of two alarms per year,
and thus an expected 16 false alarms for the complete dataset. This
level detects actual stealthy attacks after 5 events (50 brute-forcer
login attempts, since the computation is for a shift in the mean of
Δμ = 10). In a practical setting, H = 10 (one false alarm per
month) could work effectively.
To validate the assumptions underlying our detection model, we
ran the CUSUM detector on the “cleaned” data (per § 5) to compare
the expected false alarms with empirical false alarms. The detector
H In-control ARL Out-of-control ARL
1
1
3
10
20
5
7
30
40
9
9
144
3,720
99,548
2,643,440
Table 3: In-control and out-of-control ARLs for k = 5 and varying values
of H.
ﬂagged a total of 12 false alarms, reﬂecting cases where the failure
of benign users lead to the alarm.
6.2 Assessment of Detection
The two components of our detector can each exhibit false
alarms: false coordinated attack epochs and false attack partici-
pants. We can readily identify the former by inspection, as incor-
rect attack epochs can manifest in one of three ways: (i) the epoch
consists of a singleton brute-forcer and a collection of legitimate
users who had failures, (ii) the epoch consists of non-coordinating
brute-forcers having no apparent coordination glue, and (iii) bad
luck: the epoch consists of just legitimate users who failed. The
latter kind of false alarms (false attack participants) pose a harder
challenge to classify, given we lack ground truth. Since LBNL
didn’t itself detect and assess the majority of the attacks we de-
tect, we use the following heuristic to gauge whether our procedure
correctly classiﬁed a remote host as a brute-forcer. We inspect the
the host’s login activity in the attack epoch along with its future
activity. If none of this succeeded, we can with high conﬁdence
deem that host as a brute-forcer. For hosts that ultimately succeed,
we conﬁrm whether the success reﬂected a break-in by checking
whether LBNL’s incident database eventually noted the activity.
Running the procedure over 8 years of data, the Aggregate Site
Analyzer detected a total of 99 attack epochs. After then processing
these with the Attack Participants Classiﬁer, we ﬁnd nine5 repre-
sent false alarms. We detect a total of 9,306 unique attack hosts
participating in the distributed attack epochs, two of which suc-
ceed in breaking-in. The procedure classiﬁed only 37 benign hosts
as attack hosts, reﬂecting a very low false alarm rate. On days
that include an attack epoch, we ﬁnd on average about 100 benign
(cid:7)R, U(cid:8) pairs ﬁltered out using our past-history assessment, but on
average only about 1.7 “forgotten username” instances detected and
removed.
F
D
C
E
8
.
0
4
.
0
0
.
0
1
2
5
10
20
Duration of attack (days)
Figure 7: Empirical CDF of the duration of attacks (number of days)
5Note that this number differs from that found earlier on “cleaned”
data because some of those false alarms coincided with actual at-
tack epochs, and the Attack Participants Classiﬁer then removed
them due to a mismatch of coordination glue.
92s
s
e
r
d
d
a
k
r
o
w
t
e
n
e
t
o
m
e
r
d
e
z
m
y
n
o
n
A
i
0
0
0
8
0
0
0
6