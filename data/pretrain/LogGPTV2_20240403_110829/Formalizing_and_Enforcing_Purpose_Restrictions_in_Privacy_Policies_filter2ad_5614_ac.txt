ex1 ) includes this strategy despite the send actions
from state s6 being redundant since no positive rewards
follow the send actions. Fortunately, nopt(rtreat
ex1 ) does not
include σ3 since σ1 is both in opt(rtreat
ex1 ) and σ1 ≺ σ3. To
see that σ1 ≺ σ3 note that for every contingency κ and
state s, the mex1(s, κ, σ1) has the form b followed by an
ﬁnite sequence of nothing actions (interleaved with the state
s6) for some ﬁnite preﬁx b. For the same κ, mex1(s, κ, σ3)
has the form b followed by an inﬁnite sequence of send
actions (interleaved with the state s6) for the same b. Thus,
mex1(s, κ, σ1) is a proper sub-execution of mex1(s, κ, σ3).
The above modeling implies that the strategy σ1 can be
for the purpose of treatment but σ2 and σ3 cannot be.
IV. AUDITING
In the above example, the auditor constructed a model of
the environment in which the auditee operates. The auditor
must use the model to determine whether the auditee obeyed
the policy. We ﬁrst discuss this process for auditing exclu-
sivity policy rules and revisit the above example. Then, we
discuss the process for prohibitive policy rules. In Section V,
we provide an auditing algorithm that automates comparing
the auditee’s behavior to the set of allowed behaviors.
A. Auditing Exclusivity Rules
Suppose that an auditor would like to determine whether
an auditee performed some logged actions only for the
purpose p. The auditor can compare the logged behavior to
the behavior that a hypothetical agent would perform when
planning for the purpose p. In particular, the hypothetical
agent selects a strategy from nopt(hS, A, t, rp, γi) where S,
A, and t models the environment of the auditee; rp is a
reward function modeling the degree to which the purpose
p is satisﬁed; and γ is an appropriately selected discounting
factor. If the logged behavior of the auditee would never have
been performed by the hypothetical agent, then the auditor
knows that the auditee violated the policy.
In particular, the auditor must consider all the possible
behaviors the hypothetical agent could have performed. For
a model m, let behv∗(rp) represent this set where a ﬁnite
preﬁx b of an execution is in nbehv(rp) if and only if there
exists a strategy σ in nopt(rp), a contingency κ, and a state
s such that b is a preﬁx of m(s, κ, σ).
The auditor must compare nbehv(rp) to the set of all
behaviors that could have caused the auditor to observe the
log that he did. We presume that the log ℓ was created by
a process log that records features of the current behavior.
That is, log: B → L where B is the set of behaviors and
L the set of logs, and ℓ = log(b) where b is the preﬁx
of the actual execution of the environment available at the
time of auditing. The auditor must consider all the behaviors
in log−1(ℓ) as possible where log−1 is the inverse of the
logging function. In the best case for the auditor, the log
records the whole preﬁx b of the execution that transpired
until the time of auditing, in which case log−1(ℓ) = {ℓ}.
However, the log may be incomplete by missing actions, or
may include only partial information about an action such
as that it was one of a set of actions.
If log−1(ℓ) ∩ nbehv(rp) is empty, then the auditor may
conclude that the auditee did not plan for the purpose p, and,
thus, violated the rule that the auditee must only perform
the actions recorded in ℓ for the purpose p; otherwise, the
auditor must consider it possible that the auditee planned for
the purpose p.
If log−1(ℓ) ⊆ nbehv(rp), the auditor might be tempted
to conclude that the auditee surely obeyed the policy rule.
However, as illustrated by the inconclusive example below,
this is not necessarily true. The problem is that log−1(ℓ)
might have a non-empty intersection with nbehv(rp′
) for
some other purpose p′. In this case,
the auditee might
have been actually planning for a disallowed purpose p′
instead of the allowed purpose p, but the auditor cannot
181
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:51 UTC from IEEE Xplore.  Restrictions apply. 
tell the difference since both purposes can lead to the same
actions. Indeed, given the likelihood of such other purposes
for non-trivial scenarios, we consider proving compliance
practically impossible. However, this incapability is of little
consequence: log−1(ℓ) ⊆ nbehv(rp) does imply that the
auditee is behaving as though he is obeying the policy. That
is, in the worst case, the auditee is still doing the right things
even if for the wrong reasons.
B. Example: Auditing the Physician
Below we revisit the example of Section III-C and con-
sider two cases. In the ﬁrst,
the auditor shows that the
physician violated the policy. In the second, auditing is
inconclusive.
Violation Found: Suppose after constructing the model
as above in Section III-C,
the auditor maps the actions
recorded in the access log ℓ1 to the actions of the model
mex1, and ﬁnds log−1(ℓ1) holds only a single behavior:
b1 = [s1, take, s2, send, s3, diagnose, s6, Stop, s6]. Next, us-
ing nopt(rtreat
ex1 ), as computed above, the auditor constructs
the set nbehv(rtreat
ex1 ) of all behaviors an agent planning for
treatment might exhibit. The auditor would ﬁnd that b1 is
not in nbehv(rtreat
ex1 ).
To see this, note that every execution e1 that has b1 as a
preﬁx is generated from a strategy σ such that σ(s2) = send.
None of these strategies are members of opt(rtreat
ex1 ) for the
same reason that σ2 is not a member as found in Sec-
tion III-C: performing send at s2 needlessly delays (thereby
discounting) the reward from providing treatment. Thus, b1
ex1 ). Since log−1(ℓ) ∩ nbehv(rtreat
cannot be in nbehv(rtreat
ex1 )
is empty, the audit reveals that the physician violated the
policy.
Inconclusive: Now suppose that
the auditor sees a
different log ℓ2 such that log−1(ℓ2) = {b2} where b2 =
[s1, take, s4, send, s5, diagnose, s6, Stop, s6].
In this case,
our formalism would not ﬁnd a violation since b2 is in
nbehv(rtreat
the strategy σ1 from above
produces the behavior b2 under the contingency that selects
the bottom probabilistic transition from state s1 to state
s4 under the action take. (Recall
that σ1(s1) = take,
σ1(s4) = send, σ1(s2) = σ1(s3) = σ1(s5) = diagnose,
and σ1(s6) = Stop.)
ex1 ). In particular,
Nevertheless, the auditor cannot be sure that the physician
ex1
ex1
ex1 . rproﬁt
obeyed the policy. For example, consider the NMDP m′
ex1
that is mex1 altered to use the reward function rproﬁt
instead
of rtreat
assigns a reward of zero to all transitions
except for the send actions from states s2 and s4, to which
it assigns a reward of 9. σ1 is in nopt(rproﬁt
ex1 ) meaning that
not only the same actions (those in b2), but even the exact
same strategy can be either for the allowed purpose treat
or the disallowed purpose proﬁt. Thus, if the physician did
refer the record to his practice for proﬁt, he cannot be caught
as he has tenable deniability of his ulterior motive of proﬁt.
C. Auditing Prohibitive Rules
In the above example, the auditor was enforcing the rule
that the physician’s actions be only for treatment. Now,
consider auditing to enforce the rule that the physician’s
actions are not for personal proﬁt. After seeing the log ℓ,
the auditor could check whether log−1(ℓ) ∩ nbehv(rproﬁt
ex1 )
is empty. If so, then the auditor knows that the policy was
obeyed. If not, then the auditor cannot prove nor disprove
a violation. In the above example, just as the auditor is
unsure whether the actions were for the required purpose
of treatment, the auditor is unsure whether the actions are
not for the prohibited purpose of proﬁt.
Leveraging Multiple Restrictions: An auditor might
decide to investigate some of the cases where log−1(ℓ) ∩
nbehv(rproﬁt
ex1 ) is not empty. The auditor can limit his atten-
tion to only those possible violations of a prohibitive rule
that cannot be explained away by some allowed purpose. For
example, in the inconclusive example above, the physician’s
actions can be explained with the allowed purpose of treat-
ment. As the physician has tenable deniability, it is unlikely
that investigating his actions would be a productive use of
the auditor’s time. Thus, the auditor should limit his attention
to those logs ℓ such that both log−1(ℓ) ∩ nbehv(rproﬁt
ex1 ) is
non-empty and log−1(ℓ) ∩ nbehv(rtreat
ex1 ) is empty.
A similar additional check using disallowed purposes
could be applied to enforcing exclusivity rules. However, for
exclusivity rules, this check would identify cases where the
auditee’s behavior could have been either for the allowed
purpose or a disallowed purpose. Thus, it would serve to
ﬁnd additional cases to investigate and increase the auditor’s
workload rather than reduce it. Furthermore, the auditee
would have tenable deniability for these possible ulterior
motives, making these investigations a poor use of the
auditor’s time.
V. AUDITING ALGORITHM
A. Algorithm
Figure 2 presents the algorithm AUDIT that aids the
auditor in comparing the log to the set of allowed behaviors.
Since we are not interested in the details of the logging
process and would like to focus on the planning aspects
of our semantics, we limit our attention to the case where
log(b) = b (i.e., the log is simply the behavior of the
auditee). However, future work could extend our algorithm
to handle incomplete logs by constructing the set of all
possible behaviors that could give rise to that log.
As proved below (Theorem 2), AUDIT(m, b) returns true
if and only if log−1(b) ∩ nbehv(m) is empty. In the case
of an exclusivity rule, the auditor may conclude that the
policy was violated when AUDIT returns true. In case of a
prohibitive rule, the auditor may conclude the policy was
obeyed when AUDIT returns true.
The algorithm operates by checking a series of local con-
ditions of the NMDP m and behavior b that are equivalent
182
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:51 UTC from IEEE Xplore.  Restrictions apply. 
// behavior impossible for NMDP
AUDIT(m = hS, A, t, r, γi, b = [s1, a1, . . . , sn, an]):
01 if (IMPOSSIBLE(m, b))
return true
02
03 V ∗
m := SOLVEMDP(m)
04 for (i := 1; i ≤ n; i++):
m, si, ai) < V ∗
05
06
07
08
09 return false
m, si, ai) ≤ 0 and ai 6= Stop):
action redundant
m(si)):
action suboptimal
if (Q∗(V ∗
if (Q∗(V ∗
return true
return true
//
//
Figure 2. The algorithm AUDIT
to the global property of whether log−1(b) ∩ nbehv(m) is
empty.
First, AUDIT checks whether the behavior b is possible
for m using the sub-routine IMPOSSIBLE. IMPOSSIBLE
checks whether every state and action is valid, every state
is reachable by the state proceeding it, and that the same
action is performed from equal states in b.
Next, AUDIT checks whether the behavior b is optimal
(Line 05) and non-redundant (Line 07). To do so, AUDIT
uses a sub-routine SOLVEMDP to compute V ∗
m, which for
each state s records V ∗
m(s), the optimal value for s. Since
NMDPs are a type of MDP, AUDIT may use any MDP
optimization algorithm for SOLVEMDP, such as reducing
the optimization to a system of linear equations [23].
AUDIT uses a function Q∗ that computes the value of
m, s, a) = r(si, ai) +
performing an action in a state: Q∗(V ∗
γPs′ ∈S t(si, ai)(s′) ∗ V ∗
m(s′).
Theorem 2. For all ﬁnite NMDPs m and behaviors b,
AUDIT is a decision procedure for whether log−1(b) ∩
nbehv(m) is empty.
The essence of
the algorithm is checking whether
log−1(ℓ) ∩ nbehv(m) is empty. For simplicity, we presumed
that log−1(ℓ) holds only one behavior. If this is not the
case, but log−1(ℓ) is a small set, then the auditor may run
the algorithm for each behavior in log−1(ℓ). Alternatively,
in some cases the set log−1(ℓ) may have structure that a
modiﬁed algorithm could leverage. For example, if log−1(ℓ)
is missing what action is taken at some states of the
execution or only narrows down the taken action to a set
of possible alternatives, a conjunction of constraints on the
action taken at each state may identify the set.
The running time of the algorithm is dominated by the
MDP optimization conducted by SOLVEMDP. SOLVEMDP
may be done exactly by reducing the optimization to a
system of linear equations [23]. Such systems may be solved
in polynomial time [24], [25]. However, in practice, large
systems are often difﬁcult to solve. Fortunately, a large
number of algorithms for making iterative approximations
exist whose running time depends on the quality of the ap-
proximation. (See [26] for a discussion.) In the next section,
183
we discuss an implementation using such a technique.
B. Approximation Algorithm and Implementation
We implemented the AUDIT algorithm using the standard
value iteration algorithm to solve MDPs (see, e.g., [22]).
The value iteration algorithm starts with an arbitrary guess
of an optimal strategy for an MDP and the value of each
state under that policy. With each iteration, the algorithm
improves its estimation of the optimal strategy and its value.
It continues until the improvement between one iteration and
next is below some threshold ǫ. The difference between its
ﬁnal estimation of the value of each state under the optimal
policy and the true value is bounded by 2ǫγ/(1 − γ) where
γ is the discount factor of the MDP [27]. The number of
iterations needed to reach convergence grows quickly in
γ making the algorithm pseudo-polynomial time in γ and
polynomial time in |A| and |S| [28]. Despite the linear
programming approach having better worst-case complexity,
value iteration tends to perform well in practice. Using value
iteration in our AUDIT algorithm results in it having the same
asymptotic running time of pseudo-polynomial in γ.
To maintain soundness, we must account for the approx-