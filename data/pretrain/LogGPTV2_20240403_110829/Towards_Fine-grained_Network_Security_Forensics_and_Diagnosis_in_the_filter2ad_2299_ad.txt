# of State
Variables
Instrumented
Lines of Code
Forwarding
Hub
LearningSwitch
Topology
MacTracker
Firewall
LinkDiscovery
32
23
18
148
12
27
96
5
0
1
8
1
1
14
197
25
173
192
16
145
498
Table 3: Static Analysis and Instrumentation Results of Part
of Controller Applications
We implement a prototype system of ForenGuard on top of
the Floodlight [3] controller (Java language) version 1.0. Foren-
Guard extends the Soot [27] framework which provides the global
control flow analysis, data dependency analysis and instrumenta-
tion function on the intermediate representation Jimple code of
the controller. We separately analyze each module/application in
Floodlight controller and set the event handler functions as the
entry points for analysis. Our data dependency analysis is built
on top of the flow-insensitive, context-sensitive and field-sensitive
analysis using Soot Pointer Analysis Research Kit (SPARK).
Instrumentation: We do not instrument any statement which
only accesses variables that are used for collecting system logs ,
debugging or providing interfaces. For read/write operations of
state variables, we add instrumentation to log every read and write
statement that accesses static and instance field variables on the
heap memory. We observe that the SDN controller leverages hetero-
geneous storages for network state using complicated data types
(e.g., the HashMap in the running example). For some methods
of these kind of data types (e.g., HashMap.put()), the Jimple code
would miss the read/write operations. This is because the analysis
will not go through the HashMap.put() function and only consider
this is a read operation (but actually a write operation). Therefore,
we maintain a static mapping of those methods and their read/write
operations for a set of commonly used data types. For example, we
consider ArrayList.add() as a write operation. Besides, we log the
memory access operation in a fine-grained field level (e.g., each
entry of the hash map).
Event Dispatching: There are two types of event dispatch-
ing schemes in FloodLight controller, which are queue-based and
observer-based. Queue-based schemes are mostly used for the Core
Services to dispatch data plane events (e.g., PacketIn Event).
Observer-based schemes are mostly used for inter-application event
dispatch. For queue-based schemes, we log the write/read the global
queue as Dispatch and Receive operations. For observer-based
schemes, we log the statements of dispatching the events as the
Dispatch operations and the invocations of handler functions as
the Receive operations.
System Environment: We select MongoDB [6] as our database
to store the activities and their causal relations. We use Mininet
[5] to emulate the SDN data plane topologies. For the performance
evaluation, we use Cbench [1] as a benchmark tool to generate
OpenFlow messages. The setting of our host machines is dual-core
Intel Core2 3GHz CPU running 64-bit Ubuntu Linux. We select
some controller modules and show the static analysis and instru-
mentation results in Table 3.
5.2 Effectiveness Evaluation
Running Example: We first illustrate the forensics of the running
example (mentioned earlier as Listing 1 in Section 2) and how
ForenGuard helps diagnose the networking forwarding problem.
If we observe that one host lost its network connectivity, we can
use the routing_path() function to diagnose the issue. By call-
ing the routing_path() function, ForenGuard can automatically
find out the suspicious activities that cause the network problem.
We visualize the activities that are recorded in the database (left
side) and the result output by ForenGuard (right side) in Figure
7. To make the graph concise, we omit the timestamps and thread
information of each activity and use numbers (instead of the actual
names) to denote activity details (e.g., using f1,2,3... to show func-
tion calls). We can observe that, the two installed flow rules are
the direct reason that causes the forwarding issue. Behind the two
installed flow rules, there are four PacketIn events (Event1-4 in
the figure) that are the potential root causes. By further checking
the detailed information of these four events, we can reason where
and why the events come from. Event 1 and 3 are triggered by the
packet from the attacker to Host1 at Sw1 and Sw2. Event 4 and 2 are
triggered by the response packet from Host1 to the attacker at Sw2
and Sw1. Therefore, we find Event 1 and 3 are the root causes of
the issue and we can also locate the attacker. The figure shows that
ForenGuard can significantly reduce the human effort to diagnose
network forwarding problems.
Figure 7: Simplified Dependency Graph of Execution Traces of the Running Example. Box denotes switches, Hexagon denotes
events, Circle denotes function calls, Diamond denotes variable fields, Trapezium denotes OpenFlow messages.
Attack Code
Root Causes
Problem
# of Most Relevant
Data Plane Activities
# of Most Relevant
Control Plane Activities
flooding
flooding
18
9
16
3
3
3
14
14
10
# of Involved
Applications
5
2
5
1
1
1
1
6
1
1
1
A1
A2
A3
A4
A5
A6
A7
A8
A9
A10
A11
Loss of LLDP Packets [35]
Race Condition [44]
Link Fabrication [19]
Switch Table Flooding [28]
Switch ID. Spoofing [28]
Malformed Control Message [28]
Control Message Manipulation [28]
PacketIn Flooding [41]
Host Location Hijacking [19]
LoadBalancer Misconfiguration
Firewall Misconfiguration
Routing Loop
Application Crash
Packet Loss
Disconnection
Disconnection
Disconnection
Disconnection
6
3
2
1
1
1
1
Application Crash
flooding
Disconnection
Load Unbalanced
2
3
2
Table 4: Diagnosis Cases
Routing Loop
Extended Evaluation: We reproduce 11 attack cases that cause
network forwarding problems and use ForenGuard to diagnose
the root causes. Most these attacks are reported from previous
research [19, 28, 35, 41, 44]. Table 4 summarizes the cases and the
observed problems from the data plane. Among these attacks, A3,
A8 and A9 can be generated by an attacker from a compromised
host. Attacks A1, A2, A4, A5 A6 and A7 are initiated from the data
plane switches or man-in-the-middle attackers who can manipulate
the control messages between the control plane and the data plane.
Attacks A10 and A11 are from the north bound configuration of
the controller through the REST interface. All the above attacks
generate thousands of data plane activities and tens of thousands of
control plane activities totally. To demonstrate how ForenGuard is
helpful to diagnose the root causes, we also show the most relevant
control and data plane activities that can identify the attacks after
using ForenGuard to narrow down the recorded activities. The
numbers of control/data plane activities show the most relevant
activities after narrowing down from a large dataset of logs. Many
attacks involve more than one application (e.g., A1), which means
individually checking every application is hard to diagnose the root
cause of these attacks. However, ForenGuard is able to find out the
involved applications quickly and help to diagnose the problems.
By leveraging the simplified dependency graphs (e.g., the exam-
ple in Figure 7) generated by ForenGuard, the network administra-
tor can further pinpoint the root causes of each network forwarding
problem. In the following, we show how an administrator can bene-
fit from ForenGuard and pinpoint the root causes of two problems
from Table 4 step by step.
Pinpoint the Problem in A3: Similar to the Host Location
Hijacking attack in the running example, a malicious attacker can
also launch Link Fabrication attack by poisoning state variables in
some applications. Host 10.0.0.2 reports a packet loss problem to
ForenGuard and the output results are shown in Figure 8. We omit
some redundant activities and the the detailed information of most
activities in the execution trace but remain the description of the
important activities. From the results, we can first observe the flow
rule that directly causes the packet loss problem. This flow rule
is triggered by a PacketIn event and affected by a pre-generated
routing decision. Then we can keep reasoning who makes this
routing decision. The routing decision is triggered by a linkUpdate
event, and this event is caused by a PacketIn event at Sw1 from
port 3, which is the root cause of this packet loss issue. By further
checking the details of this PacketIn event, we can see that this
event is triggered by a faked LLDP packet from Port 3 of Sw1, which
is where the attacker locates.
WriteWriteWriteWriteReadReadOF_PacketOut: floodingOF_PacketOut: floodingOF_FlowMod:Flow ruleOF_FlowMod:Flow ruleSwitch 1Switch 2Query: routing_path(...)Event1Event2Event3Event4of this machine is connected to the controller port of the switch and
will receive the corresponding PacketIn messages. To measure the
delay of processing StatsRes messages, we use the same machine
to keep sending stats query messages to the data plane and measure
the delay between the StatsReq and StatsRes messages.
Figure 9 shows the overhead evaluation results. Figure 9 (a)
shows the throughput results with and without using ForenGuard.
We can observe that ForenGuard decreases the throughput of the
SDN control from 751.2 to 660.1 messages per second, i.e., about
12.1% decrease. Figure 9 (b) and (c) show the delay overhead when
using ForenGuard. For PacketIn messages, the average process-
ing time with and without ForenGuard is 0.886ms and 0.719ms,
which means about 23.4% overhead. Similarly, for StatsReq/Res
messages, the average processing time with and without Foren-
Guard is 1.12ms and 0.928ms, which means about 20.4% overhead.
We think the overhead increased by ForenGuard is reasonably
acceptable, especially compared with dynamic taint-tracking ap-
proaches which normally suffer a slowdown of 2-10 times [46].
The scalability results are important since network operators
should decide how much computing and storage resources are
needed to support ForenGuard. We measure the scalability of data
generating rate in our system. The data generating rate measures
how much data will be generated by our system and stored into the
database. To measure the data generating rate, we use Mininet to
emulate several network topologies (from a small size to a 10-switch
topology). Every end host in the data plane will generate 10 new
flow events (PacketIn messages) per second to the control plane.
We keep running the system for around one hour per topology.
Shown in Figure 11, the rate of logged data increases linearly with
the size of the data plane. The workload of with about 1,000 new
flows per second (the 10-switch topology) is comparable to the
workload of typical enterprise networks [33]. For this workload,
ForenGuard will averagely generate about 0.93GB data per hour
into the database.
6 RELATED WORK
Digital Forensics: Digital forensics is a well studied research topic.
In the past decade, research of network-level forensics focuses more
on handling the large amount of data (storing, indexing and re-
trieval) in large-scale, complex networks. TimeMachine [30] records
raw network packets and builds the index for the headers of the
likely-interesting packets. Anteater [29] monitors the data plane
state and uses formal analysis to check if the state violates specified
invariants. Teryl et al. proposed a storage system [39] to efficiently
build the index of payload information of network packets. VAST
[40] is a platform that uses the actor model to capture different levels
of network activities and provides a declarative language for query.
Network provenance [49] is also a relevant research topic in recent
years. The basic principle of ForenGuard is similar to network
provenance, which is to track causality and capture diagnostic data
at runtime that can be queried later. Unlike existing tools [14, 42]
which mostly target declarative languages or require at least some
manual annotations from software developers, ForenGuard can
directly work on the general-purpose programming language (e.g.,
Java). On host-level forensics, Forenscope [13] proposes a frame-
work that can investigate the state of a running operating system
Figure 8: Diagnosing a Packet Loss Problem Using Foren-
Guard
Pinpoint the Problem in A11: There is a Firewall application
in which users can configure firewall rules (e.g., block a black list
of IPs). When the user observes a network disconnection from the
data plane, he can report this problem to the network administrator
by using the function routing_path(). The detailed output from
ForenGuard are shown in Figure 10. The diagnosis process of