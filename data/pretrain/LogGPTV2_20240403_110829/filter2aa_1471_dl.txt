The biggest improvement has been made thanks to the Extra Write Behind
worker threads. In server SKUs, the maximum number of these threads is
nine (which corresponds to the total number of critical system worker threads
minus one), while in client editions it is only one. When a system lazy write
scan is requested by the cache manager, the system checks whether dirty
pages are contributing to memory pressure (using a simple formula that
verifies that the number of dirty pages are less than a quarter of the dirty page
threshold, and less than half of the available pages). If so, the systemwide
cache manager thread pool routine (CcWorkerThread) uses a complex
algorithm that determines whether it can add another lazy writer thread that
will write dirty pages to disk in parallel with the others.
To correctly understand whether it is possible to add another thread that
will emit additional I/Os, without getting worse system performance, the
cache manager calculates the disk throughput of the old lazy write cycles and
keeps track of their performance. If the throughput of the current cycles is
equal or better than the previous one, it means that the disk can support the
overall I/O level, so it makes sense to add another lazy writer thread (which
is called an Extra Write Behind thread in this case). If, on the other hand, the
current throughput is lower than the previous cycle, it means that the
underlying disk is not able to sustain additional parallel writes, so the Extra
Write Behind thread is removed. This feature is called Aggressive Write
Behind.
In Windows client editions, the cache manager enables an optimization
designed to deal with low-speed disks. When a lazy writer scan is requested,
and when the file system drivers write to the cache, the cache manager
employs an algorithm to decide if the lazy writers threads should execute at
low priority. (For more information about thread priorities, refer to Chapter 4
of Part 1.) The cache manager applies by-default low priority to the lazy
writers if the following conditions are met (otherwise, the cache manager still
uses the normal priority):
■    The caller is not waiting for the current lazy scan to be finished.
■    The total size of the partition’s dirty pages is less than 32 MB.
If the two conditions are satisfied, the cache manager queues the work
items for the lazy writers in the low-priority queue. The lazy writers are
started by a system worker thread, which executes at priority 6 – Lowest.
Furthermore, the lazy writer set its I/O priority to Lowest just before emitting
the actual I/O to the correct file-system driver.
Dynamic memory
As seen in the previous paragraph, the dirty page threshold is calculated
dynamically based on the available amount of physical memory. The cache
manager uses the threshold to decide when to throttle incoming writes and
whether to be more aggressive about writing behind.
Before the introduction of partitions, the calculation was made in the
CcInitializeCacheManager routine (by checking the
MmNumberOfPhysicalPages global value), which was executed during the
kernel’s phase 1 initialization. Now, the cache manager Partition’s
initialization function performs the calculation based on the available
physical memory pages that belong to the associated memory partition. (For
further details about cache manager partitions, see the section “Memory
partitions support,” earlier in this chapter.) This is not enough, though,
because Windows also supports the hot-addition of physical memory, a
feature that is deeply used by HyperV for supporting dynamic memory for
child VMs.
During memory manager phase 0 initialization, MiCreatePfnDatabase
calculates the maximum possible size of the PFN database. On 64-bit
systems, the memory manager assumes that the maximum possible amount
of installed physical memory is equal to all the addressable virtual memory
range (256 TB on non-LA57 systems, for example). The system asks the
memory manager to reserve the amount of virtual address space needed to
store a PFN for each virtual page in the entire address space. (The size of this
hypothetical PFN database is around 64 GB.) MiCreateSparsePfnDatabase
then cycles between each valid physical memory range that Winload has
detected and maps valid PFNs into the database. The PFN database uses
sparse memory. When the MiAddPhysicalMemory routines detect new
physical memory, it creates new PFNs simply by allocating new regions
inside the PFN databases. Dynamic Memory has already been described in
Chapter 9, “Virtualization technologies”; further details are available there.
The cache manager needs to detect the new hot-added or hot-removed
memory and adapt to the new system configuration, otherwise multiple
problems could arise:
■    In cases where new memory has been hot-added, the cache manager
might think that the system has less memory, so its dirty pages
threshold is lower than it should be. As a result, the cache manager
doesn’t cache as many dirty pages as it should, so it throttles writes
much sooner.
■    If large portions of available memory are locked or aren’t available
anymore, performing cached I/O on the system could hurt the
responsiveness of other applications (which, after the hot-remove,
will basically have no more memory).
To correctly deal with this situation, the cache manager doesn’t register a
callback with the memory manager but implements an adaptive correction in
the lazy writer scan (LWS) thread. Other than scanning the list of shared
cache map and deciding which dirty page to write, the LWS thread has the
ability to change the dirty pages threshold depending on foreground rate, its
write rate, and available memory. The LWS maintains a history of average
available physical pages and dirty pages that belong to the partition. Every
second, the LWS thread updates these lists and calculates aggregate values.
Using the aggregate values, the LWS is able to respond to memory size
variations, absorbing the spikes and gradually modifying the top and bottom
thresholds.
Cache manager disk I/O accounting
Before Windows 8.1, it wasn’t possible to precisely determine the total
amount of I/O performed by a single process. The reasons behind this were
multiple:
■    Lazy writes and read-aheads don’t happen in the context of the
process/thread that caused the I/O. The cache manager writes out the
data lazily, completing the write in a different context (usually the
System context) of the thread that originally wrote the file. (The
actual I/O can even happen after the process has terminated.)
Likewise, the cache manager can choose to read-ahead, bringing in
more data from the file than the process requested.
■    Asynchronous I/O is still managed by the cache manager, but there
are cases in which the cache manager is not involved at all, like for
non-cached I/Os.
■    Some specialized applications can emit low-level disk I/O using a
lower-level driver in the disk stack.
Windows stores a pointer to the thread that emitted the I/O in the tail of the
IRP. This thread is not always the one that originally started the I/O request.
As a result, a lot of times the I/O accounting was wrongly associated with the
System process. Windows 8.1 resolved the problem by introducing the
PsUpdateDiskCounters API, used by both the cache manager and file system
drivers, which need to tightly cooperate. The function stores the total number
of bytes read and written and the number of I/O operations in the core
EPROCESS data structure that is used by the NT kernel to describe a process.
(You can read more details in Chapter 3 of Part 1.)
The cache manager updates the process disk counters (by calling the
PsUpdateDiskCounters function) while performing cached reads and writes
(through all of its exposed file system interfaces) and while emitting read-
aheads I/O (through CcScheduleReadAheadEx exported API). NTFS and
ReFS file systems drivers call the PsUpdateDiskCounters while performing
non-cached and paging I/O.
Like CcScheduleReadAheadEx, multiple cache manager APIs have been
extended to accept a pointer to the thread that has emitted the I/O and should
be charged for it (CcCopyReadEx and CcCopyWriteEx are good examples).
In this way, updated file system drivers can even control which thread to
charge in case of asynchronous I/O.
Other than per-process counters, the cache manager also maintains a
Global Disk I/O counter, which globally keeps track of all the I/O that has
been issued by file systems to the storage stack. (The counter is updated
every time a non-cached and paging I/O is emitted through file system
drivers.) Thus, this global counter, when subtracted from the total I/O emitted
to a particular disk device (a value that an application can obtain by using the
IOCTL_DISK_PERFORMANCE control code), represents the I/O that could
not be attributed to any particular process (paging I/O emitted by the
Modified Page Writer for example, or I/O performed internally by Mini-filter
drivers).
The new per-process disk counters are exposed through the
NtQuerySystemInformation API using the SystemProcessInformation
information class. This is the method that diagnostics tools like Task
Manager or Process Explorer use for precisely querying the I/O numbers
related to the processes currently running in the system.
EXPERIMENT: Counting disk I/Os
You can see a precise counting of the total system I/Os by using the
different counters exposed by the Performance Monitor. Open
Performance Monitor and add the FileSystem Bytes Read and
FileSystem Bytes Written counters, which are available in the
FileSystem Disk Activity group. Furthermore, for this experiment
you need to add the per-process disk I/O counters that are available
in the Process group, named IO Read Bytes/sec and IO Write
Bytes/sec. When you add these last two counters, make sure that
you select the Explorer process in the Instances Of Selected Object
box.
When you start to copy a big file, you see the counters belonging
to Explorer processes increasing until they reach the counters
showed in the global file System Disk activity.
File systems
In this section, we present an overview of the supported file system formats
supported by Windows. We then describe the types of file system drivers and
their basic operation, including how they interact with other system
components, such as the memory manager and the cache manager. Following
that, we describe in detail the functionality and the data structures of the two
most important file systems: NTFS and ReFS. We start by analyzing their
internal architectures and then focus on the on-disk layout of the two file
systems and their advanced features, such as compression, recoverability,
encryption, tiering support, file-snapshot, and so on.
Windows file system formats
Windows includes support for the following file system formats:
■    CDFS
■    UDF
■    FAT12, FAT16, and FAT32
■    exFAT
■    NTFS
■    ReFS
Each of these formats is best suited for certain environments, as you’ll see
in the following sections.
CDFS
CDFS (%SystemRoot%\System32\Drivers\Cdfs.sys), or CD-ROM file
system, is a read-only file system driver that supports a superset of the ISO-
9660 format as well as a superset of the Joliet disk format. Although the ISO-
9660 format is relatively simple and has limitations such as ASCII uppercase
names with a maximum length of 32 characters, Joliet is more flexible and
supports Unicode names of arbitrary length. If structures for both formats are
present on a disk (to offer maximum compatibility), CDFS uses the Joliet
format. CDFS has a couple of restrictions:
■    A maximum file size of 4 GB
■    A maximum of 65,535 directories
CDFS is considered a legacy format because the industry has adopted the
Universal Disk Format (UDF) as the standard for optical media.
UDF
The Windows Universal Disk Format (UDF) file system implementation is
OSTA (Optical Storage Technology Association) UDF-compliant. (UDF is a
subset of the ISO-13346 format with extensions for formats such as CD-R
and DVD-R/RW.) OSTA defined UDF in 1995 as a format to replace the
ISO-9660 format for magneto-optical storage media, mainly DVD-ROM.
UDF is included in the DVD specification and is more flexible than CDFS.
The UDF file system format has the following traits:
■    Directory and file names can be 254 ASCII or 127 Unicode characters
long.
■    Files can be sparse. (Sparse files are defined later in this chapter, in
the “Compression and sparse files” section.)
■    File sizes are specified with 64 bits.
■    Support for access control lists (ACLs).
■    Support for alternate data streams.
The UDF driver supports UDF versions up to 2.60. The UDF format was
designed with rewritable media in mind. The Windows UDF driver
(%SystemRoot%\System32\Drivers\Udfs.sys) provides read-write support
for Blu-ray, DVD-RAM, CD-R/RW, and DVD+-R/RW drives when using
UDF 2.50 and read-only support when using UDF 2.60. However, Windows
does not implement support for certain UDF features such as named streams
and access control lists.
FAT12, FAT16, and FAT32
Windows supports the FAT file system primarily for compatibility with other
operating systems in multiboot systems, and as a format for flash drives or
memory cards. The Windows FAT file system driver is implemented in
%SystemRoot%\System32\Drivers\Fastfat.sys.
The name of each FAT format includes a number that indicates the number
of bits that the particular format uses to identify clusters on a disk. FAT12’s
12-bit cluster identifier limits a partition to storing a maximum of 212 (4,096)
clusters. Windows permits cluster sizes from 512 bytes to 8 KB, which limits
a FAT12 volume size to 32 MB.
 Note
All FAT file system types reserve the first 2 clusters and the last 16
clusters of a volume, so the number of usable clusters for a FAT12
volume, for instance, is slightly less than 4,096.
FAT16, with a 16-bit cluster identifier, can address 216 (65,536) clusters.
On Windows, FAT16 cluster sizes range from 512 bytes (the sector size) to
64 KB (on disks with a 512-byte sector size), which limits FAT16 volume
sizes to 4 GB. Disks with a sector size of 4,096 bytes allow for clusters of
256 KB. The cluster size Windows uses depends on the size of a volume. The
various sizes are listed in Table 11-2. If you format a volume that is less than
16 MB as FAT by using the format command or the Disk Management snap-
in, Windows uses the FAT12 format instead of FAT16.
Table 11-2 Default FAT16 cluster sizes in Windows
Volume Size
Default Cluster Size
16 GB
Not supported
A FAT volume is divided into several regions, which are shown in Figure
11-14. The file allocation table, which gives the FAT file system format its
name, has one entry for each cluster on a volume. Because the file allocation
table is critical to the successful interpretation of a volume’s contents, the
FAT format maintains two copies of the table so that if a file system driver or
consistency-checking program (such as Chkdsk) can’t access one (because of
a bad disk sector, for example), it can read from the other.
Figure 11-14 FAT format organization.
Entries in the file allocation table define file-allocation chains (shown in
Figure 11-15) for files and directories, where the links in the chain are
indexes to the next cluster of a file’s data. A file’s directory entry stores the
starting cluster of the file. The last entry of the file’s allocation chain is the
reserved value of 0xFFFF for FAT16 and 0xFFF for FAT12. The FAT
entries for unused clusters have a value of 0. You can see in Figure 11-15
that FILE1 is assigned clusters 2, 3, and 4; FILE2 is fragmented and uses
clusters 5, 6, and 8; and FILE3 uses only cluster 7. Reading a file from a
FAT volume can involve reading large portions of a file allocation table to
traverse the file’s allocation chains.
Figure 11-15 Sample FAT file-allocation chains.
The root directory of FAT12 and FAT16 volumes is preassigned enough
space at the start of a volume to store 256 directory entries, which places an
upper limit on the number of files and directories that can be stored in the
root directory. (There’s no preassigned space or size limit on FAT32 root
directories.) A FAT directory entry is 32 bytes and stores a file’s name, size,
starting cluster, and time stamp (last-accessed, created, and so on)
information. If a file has a name that is Unicode or that doesn’t follow the
MS-DOS 8.3 naming convention, additional directory entries are allocated to
store the long file name. The supplementary entries precede the file’s main
entry. Figure 11-16 shows a sample directory entry for a file named “The
quick brown fox.” The system has created a THEQUI~1.FOX 8.3
representation of the name (that is, you don’t see a “.” in the directory entry
because it is assumed to come after the eighth character) and used two more
directory entries to store the Unicode long file name. Each row in the figure
is made up of 16 bytes.
Figure 11-16 FAT directory entry.
FAT32 uses 32-bit cluster identifiers but reserves the high 4 bits, so in
effect it has 28-bit cluster identifiers. Because FAT32 cluster sizes can be as
large as 64 KB, FAT32 has a theoretical ability to address 16-terabyte (TB)
volumes. Although Windows works with existing FAT32 volumes of larger
sizes (created in other operating systems), it limits new FAT32 volumes to a
maximum of 32 GB. FAT32’s higher potential cluster numbers let it manage
disks more efficiently than FAT16; it can handle up to 128-GB volumes with
512-byte clusters. Table 11-3 shows default cluster sizes for FAT32 volumes.
Table 11-3 Default cluster sizes for FAT32 volumes
Partition Size
Default Cluster Size
32 GB
Not supported
Besides the higher limit on cluster numbers, other advantages FAT32 has
over FAT12 and FAT16 include the fact that the FAT32 root directory isn’t
stored at a predefined location on the volume, the root directory doesn’t have
an upper limit on its size, and FAT32 stores a second copy of the boot sector
for reliability. A limitation FAT32 shares with FAT16 is that the maximum
file size is 4 GB because directories store file sizes as 32-bit values.
exFAT
Designed by Microsoft, the Extended File Allocation Table file system
(exFAT, also called FAT64) is an improvement over the traditional FAT file
systems and is specifically designed for flash drives. The main goal of exFAT
is to provide some of the advanced functionality offered by NTFS without the
metadata structure overhead and metadata logging that create write patterns
not suited for many flash media devices. Table 11-4 lists the default cluster
sizes for exFAT.
As the FAT64 name implies, the file size limit is increased to 264, allowing
files up to 16 exabytes. This change is also matched by an increase in the
maximum cluster size, which is currently implemented as 32 MB but can be
as large as 2255 sectors. exFAT also adds a bitmap that tracks free clusters,
which improves the performance of allocation and deletion operations.
Finally, exFAT allows more than 1,000 files in a single directory. These
characteristics result in increased scalability and support for large disk sizes.
Table 11-4 Default cluster sizes for exFAT volumes, 512-byte sector
Volume Size
Default Cluster Size
= 64 TB