(pCC1) for the voter’s expected code. The other partial choice
code—pCC1—is invalid. This construction, though invalid,
passes veriﬁcaion. The attacker transfers the code substitution
to Question 2 and hopes the voter doesn’t notice.
Suppose the voter wants to vote ‘yes’ for Question 1, but
the cheating client wants to vote ‘no’ and retrieve the voter’s
expected choice codes. Suppose the voter wants choice p3 for
Question 2.
The cheating client generates a random r and computes the
vote as
E1 = (gr,ELr
pk pno p3)
3In real Swiss referenda, there are also explicit “blank” codes, but they are
omitted here for simplicity. The attack works exactly the same if they are
included.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:41:54 UTC from IEEE Xplore.  Restrictions apply. 
648
where ELr
pk is the election public key and pno and p3 are
primes used to represent vote choices. This correctly reﬂects
the voter’s choice for Question 2, but the client’s substitute for
Question 1.
It then generates the partial choice codes pCC1 = pkid
yes and
pCC2 = (pno p3/pyes)kid where kid is a secret speciﬁc to that
card/voter (spec 5.4.1 (2)). Note that the partial choice code
for Question 1 reﬂects the voter’s choice, not the actual vote.
The partial choice code for Question 2 is not valid.
It generates E2 honestly from pCC1 and pCC2.
E2 = (gr
(cid:4)
, (pk(1)
CCR
)r
(cid:4) · pCC1, (pk(2)
CCR
)r
(cid:4) · pCC2)
It generates the zero knowledge proofs entirely honestly,
because all the facts they are claiming are true. To see why,
observe that it needs to prove that the product of partial choice
codes is properly exponentiated, not the individual codes.
Recall
that
˜E2
is
˜E2 = (gr
which it generates honestly from E2.
(cid:4)
, (pkCC1pkCC2
pCC1pCC2),
(cid:4)
)r
Similarly, the exponentiation F1 = (gr.kid ,ELr.kid (pno p3)kid ),
the result of exponentiating each element of E1 by kid.
The Schnorr proof proves that the client knows the encryption
used to generate E1, which it does.
The exponentiation proof proves that F1 is generated by
exponentiating each element of E1 to the private exponent
corresponding to the public key Kid = gkid , which it is.
The proof of plaintext equality proves that F1 encrypts the
same value, under EL, as ˜E2, under the product public key
Πk
i=1pkCCi, which in our example is simply pkCC1pkCC2. This
is true. The message represented by ˜E2 is
pCC1pCC2 = pvcsk
yes (pno p3/pyes)vcsk = (pno p3)vcsk
which is exactly the plaintext of Eexp.
So this vote will pass veriﬁcation even though the pCC1
does not match the vote. Now consider whether the ﬁrst choice
code will be returned from the server side.
B. How will this be treated at the server side?
Vote validity will pass because all the ZKPs are valid. Now
consider what happens when the VVC attempts to retrieve the
choice code. Choice codes are stored in a codes mapping table
and retrieved in sequence. The ﬁrst code will be successfully
retrieved because it is an entirely valid code (for a different
option from the one the client sent). The second code is not
valid. The speciﬁcation does not say explicitly what should
happen when some, but not all, of the codes can be successfully
retrieved. That part of the spec is shown in Figure 1.
In practice this would probably fail at the server side without
collusion—the code for version 1.0 throws an exception and
refuses to return any of the codes. However, the spec should
be updated to ensure that a voter’s codes are returned only if
all choice codes are correctly retrieved.
Even if this last step defeats the attack, it doesn’t really solve
the fundamental problem, which is that the logical conjunction
of all the facts proved by the ZKPs does not imply that the
Fig. 1. Choice code return in the spec. It’s not clear whether the ﬁrst code
is returned if subsequent lookups fail. Nor is it clear in Step 3 whether the
status is updated if any codes are correctly retrieved, or only if all are.
ballot is correctly formed. In particular, it does not imply that
the pre-choice-codes are consistent with the vote. This can
be corrected (at a signiﬁcant cost to efﬁciency) by providing
separate proofs for each element (rather than the products).
More importantly, even if the spec is corrected, a cheating
VVC may simply ignore it and return the codes that can
be retrieved even if others cannot. This would require no
misbehaviour from the CCRs—see Step 4 of the code return in
Section II-B2. This attack is within the security model because
the server side is not supposed to be trusted.
Although a misleadingly comforting code can be returned
with VVC collusion, it is much less clear that the manipulated
(’no’) vote can be inserted into the tally and pass audit. We
have not detailed the audit speciﬁcation for this part of the
protocol in this paper, but we think it would detect (and refuse
to pass) if a vote was accepted when one of its partial choice
codes was invalid. However, there is nothing to stop the vote
being dropped—this leaves us with a voter who receives their
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:41:54 UTC from IEEE Xplore.  Restrictions apply. 
649
expected choice code, when the vote has not been included.
We also do not claim that the conﬁrmation step (which we
have also not detailed here) could be successfully subverted.
In short, this seems to be a problem, though it is not clear that
it leads to a real attack.
a) Summary of the problem: The vote ZKPs are not
sufﬁcient for vote validity. In particular, they rely on the product
of the codes not the individual codes. This results in a practical
attack if some codes are returned to the voter despite others
being irretrievable, which might happen accidentally (the spec
is vague) or deliberately (server-side collusion).
b) Fixing the problem: One possible ﬁx is to produce
separate ZKPs for each element. Alternatively, it might be
possible to prove that the product proof is sufﬁcient if the
server-side can provably only return codes if all the codes
are correctly retrieved. However, this latter approach seems
difﬁcult in the presence of possibly misbehaving servers.
c) Current status of the problem: It is not entirely agreed
that this is a problem, since the voter does receive a wrong
code (or no code at all) for at least some choices, though she
receives the expected code for the choice that was manipulated.
We believe the spec will be updated to specify that the VVC
should return codes only if they are all retrieved, though this
does not address the problem of a colluding VVC.
V. INDIVIDUAL VERIFIABILITY: RETURNING THE RIGHT
CHOICE CODES FOR A MANIPULATED VOTE WITH SERVER
Assume that a voter would like to submit a yes vote. The
voting client cheats and computes a no vote, that is, E1 =
(cid:4) · pkidno ), together with all the
(gr,ELr pno), E2 = (gr
expected ZKPs, which can be honestly computed based on E1
and E2 since they are consistent.
,pk(1)
CCR
(cid:4)
)r
A. Faking correct choice return code generation
1) The cheat: The cheating VVC follows the choice-code
generation protocol (Section II) almost perfectly, until it needs
to compute the pre-Choice Return Code. It is supposed to be
generated as
pCid
1 = pkid
no .
no )k = pk
no)b/a = (pb/a
If VVC uses this code, it will obtain the return code for
the no choice, and an honest and diligent voter will notice
that this code is wrong. However, VVC can also compute
(pk
yes, which is the pre-Choice return code
from which it can derive the return code for the yes choice.
From this observation, we see that, if the group parameters
are selected in a malicious way, then a cheating voting client
and a cheating voting server (VVC) can collude to modify a
voter’s choice in a way that is completely undetectable. Indeed,
the voter receives the codes that she expects to see, the votes
that are transmitted and tallied are perfectly valid, all the ZK
proofs are valid, and all the decryption operations lead to
plausible values.
COLLUSION
B. Does it pass veriﬁcation?
In this section we show how a cheating client, in collusion
with a cheating Vote Veriﬁcation Context (VVC), can manipu-
late the vote but retrieve all the voter’s expected choice codes.
This will pass veriﬁcation and show the voter her expected
choice codes even though the vote is chosen by the client.
The attack relies on maliciously generated parameters for
representing the voting options, a reasonable assumption given
the weaknesses that were identiﬁed in practice in version 1.0 [3].
Although patching that gap thwarts the attack described here,
it does not really solve the fundamental problem, which is
that the code-return process (Section II-B2) is meant to be
a veriﬁable distributed computation among 5 parties, with
detectable misbehaviour if any subset of the CCRs collude, but
there is no proof that this property holds and, indeed, it does not
hold in its current form. There may be other exploitable failures
even if the system is patched to thwart this particular attack.
For example, although the speciﬁcation document requires the
VVC to verify some zero knowledge proofs that the CCRs
generate, the audit document [12] does not require the auditor
to verify them again. There may be other attacks in which
a cheating VVC colludes with a CCR to allow the wrong
computation even though the ZKPs do not verify.
We require only a cheating VVC colluding with a client—all
the CCRs can be honest. However, the VVC must know some-
thing about maliciously-generated voting parameters. In this
example, assume that it knows a,b such that pa
no mod p.
Easily-computed example parameters are in Appendix B1.
yes = pb
We have not detailed the audit speciﬁcation for this part of
the election, but it is available in [12], Section 8.5. The audit
process will pass because the multiplication that the auditor
does compute in Steps 4 and 5 will work perfectly to retrieve
pk
yes from the codes table. The audit speciﬁes that the auditor
must check that the value is “a valid entry of the mapping
table,” but it has no way of knowing which value was sent
back to the voter.
Summary of the problem: The underlying problem is that
the MPC protocol to retrieve the choice codes uses ﬁve parties
but is not secure against misbehaviour by one. This example
shows that maliciously-generated voting parameters can be used
by a malicious VVC, colluding only with a client, to return
a correct choice code for a vote that was manipulated. The
voter would receive exactly the expected codes, and veriﬁcation
would pass.
Fixing the problem: This speciﬁc example can be solved
by provably-correct voting parameter generation. However, is
much more difﬁcult to guaranteeing security of the multiparty
ballot processing protocol, in the presence of a dishonest VVC
and up to three dishonest CCRs.
Current status of the problem: We believe that future
versions will prove that
the voting parameters have been
properly generated, thus preventing the speciﬁc attack described
here. We are not aware of any changes to the multiparty vote
processing protocol. There may be other attacks that exploit it
in a different way.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:41:54 UTC from IEEE Xplore.  Restrictions apply. 
650
VI. PICKING ELECTION PUBLIC PARAMETERS: THE USE OF
TRAPDOOR COMMITMENTS IN BAYER-GROTH PROOFS AND
reason, these constraints are not satisﬁed, then the same strategy
can still be used to render some chosen votes invalid.
WHY THE SHUFFLE PROOF CAN BE FAKED
We now turn our attention to what happens when votes are
received by the mix servers, after they have been processed as
described in Section II-B2. At this point in the sVote process,
a list of accepted encrypted votes is available. Auditors have to
check whether those votes are properly shufﬂed and decrypted
to produce the announced election outcome.
There are four servers called CCM j for j = 1, . . .4. In order
to achieve universal veriﬁability, each one is supposed to prove
that the set of input votes it received correspond exactly to
the differently-encrypted votes it output—this is called a proof
of shufﬂe. (They also perform partial decryptions which they
must prove correct—see Section VII.)
These proofs can be complicated because they need to protect
voter privacy. However, their trust assumptions are simple: it
should not be possible for any collusion of authorities, whether
those who hold the decryption keys, those who write the
software, or those who mix the votes, to provide a proof
transcript that passes veriﬁcation but alters votes.
A. Overview of this section: faking the shufﬂe proof
We show that the SwissPost-Scytl mixnet speciﬁcation and
code does not meet the assumptions of a sound shufﬂe proof.
The problem derives from the use of a trapdoor commitment
scheme in the shufﬂe proof—if a malicious authority knows the
trapdoors for the cryptographic commitments, it can provide
an apparently-valid proof, which passes veriﬁcation, while
actually having manipulated votes. There is no modiﬁcation
of the audit process that would make it possible to detect if
a manipulation happened. Instead, the key generation process
for the commitment scheme should be modiﬁed in such a way
that it offers evidence that no trapdoor has been produced,
and the audit process should include the veriﬁcation of this
new evidence. The same point was made independently by
Haenni [13].
We give two examples of how knowledge of the commitment
trapdoors could be used to provide a perfectly-verifying
transcript while actually manipulating votes.
The ﬁrst example allows the ﬁrst mix to use the trapdoors
to substitute votes for which it knows the randomness used to
generate the encrypted vote. While this requires some violation
of privacy, it is consistent with the requirements of the system,
which state that an attacker shall not be able to change a
vote even if voting clients are compromised [10], and such
a compromise could violate privacy. (We believe that the
assumption that voting clients may be compromised is sound
too: the voting system cannot do anything to guarantee that
the computer of the voter does not contain any malware.)
The second example allows the last mix to use the same
trapdoors to modify votes and does not require any data leakage
from the client, but has some constraints on the candidates
for which votes could be added or removed and some extra
assumptions about corrupt parameter generation. If, for some
B. The soundness of the shufﬂe proof
The Scytl-Swisspost mixnet uses a provable shufﬂe due
to Bayer and Groth [14]. We describe here an important
implementation detail that allows the forging of apparently-
verifying Bayer-Groth proofs. It is not a fault in the B-G proof
mechanism, but rather a misalignment of its assumptions with
the context that sVote uses it in.
The issue concerns the soundness of the commitments. A
core security requirement of commitment schemes is that they
be binding: once someone has committed to a particular value,
they can open the commitment only to that value.