### Recognition and Analysis of Cloud Buckets

#### Introduction
To identify cloud buckets, various platforms use distinct URL formats. For instance, Amazon S3 repositories are accessed via URLs formatted as `w + .s3{−w+}[?].amazonaws.com`, while Amazon CloudFront generates resource URLs in the form `w + .cloudfront.net`. In our research, we examined 20 cloud platforms to identify the buckets they host.

#### Feature Analysis
At the feature-analysis stage, BarFinder inspects all redirection paths for each bucket, converts every node into a Fully Qualified Domain Name (FQDN) to compute their topological features, and then connects different nodes based on their content and network properties to determine site similarities, as detailed in Section 3.1.

Each cloud bucket \( i \) is uniquely characterized by a vector:
\[
\langle D_i, B_i, L_i, S_{i,1}, \ldots, S_{i,n} \rangle
\]
where each element represents a collective feature. The individual features have varying power in differentiating good and bad buckets, which we measured using the F-Score (see Table 3). Features with higher F-Scores are more effective in classifying these vectors. Therefore, a binary classifier with a model for weighing the features and other parameters can be used to classify the vector set and determine whether individual buckets are legitimate or not. This model is learned from a seed dataset. In our research, we utilized a Support Vector Machine (SVM) as the classifier, which showed the best performance among other classification algorithms (see Table 4). The SVM's classification model is built upon the F-Scores for the collective features (D, B, etc.) and a threshold set according to the expected false positive and negative discovery rates. The SVM also reports the confidence of the classification for each bucket.

#### Implementation
Our design was implemented in a prototype system. The web crawler was developed as a Firefox add-on, and 20 such crawlers were deployed. We also developed a Python tool to recover cloud URLs from the web content gathered by Common Crawl. The feature analyzer, consisting of approximately 500 lines of Python code, processes the data collected by the crawler and computes the collective features (Section 3.1). Each feature in the vector is normalized using the L1 norm before being passed to the SVM classifier. We incorporated the SVM provided by the scikit-learn open-source machine learning library [?].

#### Evaluation
We evaluated BarFinder on both the ground truth and an unknown set. All experiments were conducted on an Amazon EC2 C4.8xlarge instance equipped with an Intel Xeon E5-2666 36 vCPU and 60GiB of memory.

**Evaluation on the Seed Set:**
We tested the effectiveness of BarFinder over our ground-truth dataset (i.e., the seed set) through five-fold cross-validation. Specifically, 4/5 of the data was used for training the SVM, and the remaining 1/5 for evaluating the accuracy of bar detection. We randomly selected 80 bars (out of 100) from the Badset and 240 (out of 300) legitimate buckets from the Goodset, along with related websites (out of 141,149). These data were processed by our prototype to adjust the weights and other parameters for the model. The model was then tested on the remaining dataset (20 bars, 60 legitimate buckets), and this process was repeated five times. BarFinder achieved a low false discovery rate (FDR: 1 - precision) and high recall: only 5.6% of reported bars turned out to be legitimate (i.e., 1.6% false positive rate), and over 89.3% of the bars were detected. The Area Under Curve (AUC) of the Receiver Operating Characteristics (ROC) graph was 0.96, demonstrating a good balance between the FDR and coverage. This analysis shows that the collective features of sites connecting to cloud repositories are promising in detecting bars.

**Evaluation on the Unknown Set:**
We used BarFinder to scan an unknown set containing HTTP traffic collected using a crawler as described in Section 3.1. This unknown set included HTTP traffic generated from dynamically visiting 1M websites loading content from 20 cloud platforms and 6,885 cloud buckets. To validate our evaluation results, we employed a methodology combining anti-virus (AV) scanning, blacklist checking, and manual analysis. For the bars flagged by our system, we first scanned their cloud URLs with VirusTotal for malware and checked them against the list of suspicious cloud URLs collected from our Spamtrap honeypot. A URL was considered suspicious if at least two scanners raised an alarm. All such suspicious URLs (from either VirusTotal or the Spamtrap list) were cross-checked against the CleanMX blacklist. Only those also found there were reported as true positives. Once a URL was confirmed malicious, its corresponding bucket was labeled as bad. Unlabeled but flagged buckets were further validated manually.

In the experiment, BarFinder reported a total of 730 bars, about 10.6% of the 6,885 buckets. Among them, AV scanning and blacklist verification confirmed that 502 buckets were indeed bad. The remaining 228 were manually analyzed, confirming 192 bars. The FDR was found to be at most 5% (assuming those not confirmed to be legitimate), consistent with the findings from the seed set.

### Measurement and Discoveries
Based on the discoveries made by BarFinder, we conducted a measurement study to better understand the fundamental issues of bar-based malicious services, particularly how cloud repositories facilitate malicious activities, how adversaries exploit legitimate cloud buckets, and why they use bars. Our research shows that bars play a pivotal role in the infrastructure, possibly because they are hosted on popular cloud services, making them hard to blacklist and easy to share across different campaigns. Adversaries may use multiple bars at different attack stages to construct a complex infrastructure supporting their mission (Section 4.1). More importantly, we discovered that adversaries effectively exploited misconfigured legitimate buckets to infect a large number of front-end web services (Section 4.2), and cloud providers have not done much to counteract the threat, often leaving bars there for a long time (Section 4.3), possibly due to privacy constraints and limited means to detect individual components of malicious activity. These observations, combined with the challenge in blocking bars, offer insights into the motivation for moving toward this new trend of repository-based attacks.

#### Bar-Based Malicious Web Infrastructure Landscape
BarFinder reported 730 suspicious repositories from 6,885 cloud buckets over 20 cloud platforms. We utilized 694 confirmed bars (through AV/blacklist scanning or manual validation, see Section 3.3) for the measurement study. These bars directly served 156,608 domains (i.e., front-end websites), through which they were further attached to 6,513,519 redirection paths involving 166,772 domains. Figure 5 illustrates the number of bars found on different cloud platforms. Amazon S3 was the most popular, hosting the most bars (45%), followed by CloudFront (Amazon’s CDN) at 25.1% and Akamaihd at 9.3%. Seven of these 20 clouds provide free storage services (e.g., 15GB free space on Google Drive, 5GB for Amazon S3), making them ideal platforms for low-budget miscreants to distribute illicit content. Eleven of them support HTTPS, on which malicious activities are difficult to catch by existing signature-based intrusion detection systems like Snort and Shadow[?][?]. On some prominent platforms, miscreants took advantage of the cloud providers' reputations to make their phishing campaigns look more credible. For example, adversaries continuously spoofed Gmail’s login page on Google Drive and the software download page for Amazon FireTV in an Amazon S3 bucket.

Figure 6 shows the distribution of bars' frontend websites across 81 countries, determined by the geolocations of the sites. The number of bars' frontend sites in each country is ranked and described with different levels of darkness in the figure. Most of these frontends are located in the United States (14%), followed by Germany (7%) and the United Kingdom (5%).

**Role in Attack Infrastructures:**
Most nodes on a malicious infrastructure are newly registered malicious websites and compromised sites. To better understand the critical roles of bars, we compared these nodes with bad cloud buckets. We identified both types of nodes from the redirection paths and analyzed the number of unique paths each member in either category is associated with and their position on the path. Figure 7(a) presents the cumulative distribution of paths going through a bar and a compromised or malicious site. Bars sit on many more paths (47.4 on average vs. 8.6), indicating their importance. Figure 7(b) shows the histogram of position distributions, revealing that more bars (41%, 11%) appear at the beginnings and ends of paths than bad websites (22%, 5%), demonstrating that they often act as first-hop redirectors or attack-payload repositories. For example, in our three-month-long monitoring of the campaign based on the spyware distribution bar `akamaihd.net_rvar-a`, we found that besides the bar, 320 newly-registered websites participated in the attack; the bar acted like a dispatcher, providing JavaScript to identify the victim’s geolocation and then using an iframe to redirect her to a selected bad site.

**Content Sharing:**
Our research reveals that bars have been extensively shared among malicious or compromised websites, across different positions on malicious redirection chains. Figure 7(c) illustrates the cumulative distribution of bars' in-degrees, showing that bars are frequently reused and play a central role in attack infrastructures.