platforms to recognize cloud buckets. For example, the reposi-
tory on Amazon S3 is accessed through the URL formatted as
w + .s3{−w+}[?].amazonaws.com, and Amazon CloudFront
produces resource URLs in the form of w + .cloudf ront.net. In
our research, 20 cloud platforms were examined to identify the
buckets they host. At the feature-analysis stage, for each bucket,
BarFinder inspects all its redirection paths, converts every node into
an FQDN to compute their topological features, and then connects
different nodes according to their content and network properties to
ﬁnd out their site similarities, as described in Section 3.1.
Next, each cloud bucket i is uniquely characterized by a vector:
(cid:104)Di, Bi, Li, Si,1 ··· Si,n(cid:105), with each element a collective feature.
Individual features have different power in differentiating good and
bad buckets, which we measured using the F-Score [?] (see Table 3).
Note that the feature with a large score can better classify these
vectors than the one with a small value. Therefore, a binary classiﬁer
with a model for weighing the features and other parameters can
be used to classify the vector set and determine whether individual
buckets are legitimate or not. Such a model is learned from the
seed dataset. In our research, we utilized a Support Vector Machine
(SVM) as the classiﬁer, which showed the best performance among
other classiﬁcation algorithms (see Table 4). Its classiﬁcation model
is built upon the F-Scores for the collective features (D, B, etc.) and
a threshold set according to the false positive and negative discovery
expected to achieve. For each bucket classiﬁed, the SVM can also
report the conﬁdence of the classiﬁcation.
Implementation. This simple design was implemented in our study
into a prototype system. The web crawler was built as a Firefox add-
on. In total, 20 such crawlers were deployed. We further developed a
tool in Python to recover cloud URLs from the web content gathered
by Common Crawl. The feature analyzer includes around 500 lines
of Python code for processing the data collected by the crawler and
Feature
Connection ratio
Bucket usage similarity
Landing similarity
CMS information
Meta-data information
Analytics and tracking
Widget
CloudURL information
s
Label Metric
1 − n|V |
1 − i
1 − l
1 − n|V (cid:48)|
1 − n|V (cid:48)|
1 − n|V (cid:48)|
1 − n|V (cid:48)|
1 − n|V (cid:48)|
D
B
L
S1
S2
S3
S4
S5
s
F-score
0.084
0.076
0.072
0.037
0.033
0.032
0.031
0.024
Table 4: Performance comparison under ﬁve-fold cross valida-
tion.
Classiﬁer
SVM
Decision Tree
Logistic Regression
Naive Bayes
Random Forest
Precision Recall
0.89
0.83
0.87
0.79
0.82
0.94
0.9
0.91
0.9
0.85
computing the collective features (Section 3.1). Each feature in the
vector is normalized using the L1 norm before passed to the SVM
classiﬁer. In our system, we incorporated the SVM provided by the
scikit-learn open-source machine learning library [?].
3.3 Evaluation
Here we report our evaluation of BarFinder on both the ground
truth and the Unknown sets. All the experiments were conducted
within an Amazon EC2 C4.8xlarge instance equipped with Intel
Xeon E5-2666 36 vCPU and 60GiB of memory.
Evaluation on the seed set. We tested the effectiveness of BarFinder
over our ground-truth dataset (i.e., the seed set) through the standard
ﬁve-fold cross validation: that is, 4/5 of the data was used for train-
ing the SVM and the remaining 1/5 for evaluating the accuracy of
Bar detection. Speciﬁcally, we randomly chose 80 Bars (out of 100)
from the Badset and 240 (out of 300) legitimate buckets from the
Goodset, together with the related websites (out of 141,149). These
data were ﬁrst processed by our prototype to adjust the weights and
other parameters for its model. Then we tested the model on the
remaining dataset (20 Bars, 60 legitimate buckets). The process
is then repeated 5 times. BarFinder achieved both a low false dis-
covery rate (FDR: 1- precision) and a high recall in detection: only
5.6% of reported Bars turned out to be legitimate (i.e., 1.6% of false
positive rate), and over 89.3% of the Bars were detected. We fur-
ther show the Area Under Curve (AUC) of the Receiver Operating
Characteristics (ROC) graph, which comes very close to 1 (0.96),
demonstrating the good balance we strike between the FD rate and
the coverage. This preliminary analysis shows that the collective
features of the sites connecting to cloud repositories are promising
in detecting Bars.
Evaluation on the Unknown set. We now use BarFinder to scan
an unknown set. This unknown set contains HTTP trafﬁc collected
using a crawler as described in Section 3.1 to visit a list of websites.
This list of websites is also extracted from common crawl [?] by
searching for websites that have loaded some content in the past
from the cloud platforms listed in Table 7. As a result, the unknown
data set contained HTTP trafﬁc generated from dynamically visiting
1M websites loading content from 20 cloud platforms and 6,885
cloud buckets.
To validate our evaluation results, we employ a methodology
that combines anti-virus (AV) scanning, blacklist checking, and
manual analysis. Speciﬁcally, for the Bars ﬂagged by our system,
we ﬁrst scan their cloud URLs with VirusTotal for malware and
1546Figure 5: Top 10 cloud platforms with most Bars, compared
with their total number of cloud buckets in our dataset.
check them against the list of suspicious cloud URLs collected
from our Spamtrap honeypot for Spam, Phishing, blackhat Search
Engine Optimization (SEO), etc. In the case of VirusTotal, a URL
is considered to be suspicious if at least two scanners raise the
alarm. All such suspicious URLs (from either VirusTotal or the
Spamtrap list) are cross-checked against the blacklist of CleanMX.
Only those also found there are reported to be a true positive. Once
a URL is conﬁrmed malicious, its corresponding bucket is labeled
as bad. Those unlabeled but ﬂagged (by BarFinder) buckets are
further validated manually.
In the experiment, BarFinder reported a total of 730 Bars, about
10.6% of the 6,885 buckets. Among them, the AV scanning and
blacklist veriﬁcation conﬁrmed that 502 buckets were indeed bad.
The remaining 228 were manually analyzed through, e.g., inspecting
the resources in the buckets for phishing or scam content, running
scripts in the VM to capture binary code download. This validation
further conﬁrmed 192 Bars. The FDR was found to be at most 5%
(assuming those not conﬁrmed to be legitimate), in line with the
ﬁnding from the seed set.
4. MEASUREMENT AND DISCOVERIES
Based on the discoveries made by BarFinder, we further con-
ducted a measurement study to better understand the fundamental
issues about Bar-based malicious services, particularly how the
cloud repositories help facilitate malicious activities, how the adver-
sary exploited legitimate cloud buckets and why the adversary uses
Bars in the ﬁrst place. Our research shows that on the infrastructure,
Bars play a pivotal role, compared with the content kept on other
malicious or compromised sites, possibly because they are hosted on
popular cloud services, and therefore hard to blacklist and also easy
to share across different campaigns. Also, in a malicious campaign,
the adversary may take advantage of multiple Bars, at different at-
tack stages, to construct a complicated infrastructure that supports
her mission (Section 4.1). More importantly, we discovered that the
adversary effectively exploited misconﬁgured legitimate buckets to
infect a large number of their front-end web services (Section 4.2),
and the cloud providers have not done much to counteract the threat,
often leaving Bars there for a long time (Section 4.3), possibly due to
the privacy constraints and limited means to detect individual com-
ponents of a malicious activity. Such observations, together with
the challenge in blocking Bars, offer insights into the motivation for
moving toward this new trend of repository-based attacks.
4.1 Bar-based Malicious Web Infrastructure
Landscape. As mentioned earlier, BarFinder reported 730 suspi-
cious repositories from 6885 cloud buckets over 20 cloud platforms.
Among them, we utilized 694 conﬁrmed Bars (through AV/blacklist
scanning or manual validation, see Section 3.3) for the measurement
study. These Bars were found to directly serve 156,608 domains
Figure 6: Impact of Bars’ front-end websites around the globe.
(i.e., front-end websites), through which they are further attached to
6,513,519 redirection paths involving 166,772 domains. Figure 5
illustrates the number of Bars we found on different cloud platforms.
Among them, Amazon S3 is the most popular one in our dataset,
hosting the most Bars (45%), which is followed by CloudFront
(Amazon’s CDN) 25.1% and Akamaihd 9.3%. Note that of these 20
clouds, seven of them provide free storage services (e.g., 15GB free
space on Google Drive, 5GB for Amazon S3), and therefore easily
become the ideal platforms for low-budget miscreants to distribute
their illicit content. Also, eleven of them support HTTPS, on which
malicious activities are difﬁcult to catch by existing signature-based
intrusion detection systems like snort and Shadow[?][?]. Interest-
ingly, on some of the most prominent platforms, the miscreants
are found to take advantage of the cloud providers’ reputations to
make their Phishing campaigns look more credible: for example,
we found that the adversary continuously spoofed Gmail’s login
page on Google Drive, and the software download page for Amazon
FireTV in an Amazon S3 bucket.
Figure 6 shows the distribution of Bars’ frontend websites across
81 countries, as determined by the geolocations of the sites. The
number of Bars’ frontend sites in each country is ranked and de-
scribed with different levels of darkness in the ﬁgure. We observe
that most of these frontends stay in United States (14%), followed
by Germany (7%) and United Kingdom (5%).
Role in attack infrastructures. Actually, most nodes on a mali-
cious infrastructure are the malicious websites with newly registered
domains and those that are compromised. To better understand the
critical roles of Bars, we compared those nodes with the bad cloud
buckets. Speciﬁcally, we ﬁrst identiﬁed both types of nodes from
the redirection paths and then analyzed the number of unique paths
each member in either category is associated with and the position
of the member on the path. Figure 7(a) presents the cumulative dis-
tribution of the paths going through a Bar and that of a compromised
or malicious site. As seen in the ﬁgure, compared with other nodes
on the infrastructure, Bars clearly sit on much more paths (47.4 on
average vs. 8.6), indicating their importance.
Further, Figure 7(b) shows the histogram of position distributions
(again, Bars vs. bad sites). The observation is that more Bars (41%,
11%) show up at the beginnings and the ends of the paths than bad
websites (22%, 5%), which demonstrates that they often act as ﬁrst-
hop redirectors or attack-payload repositories. For example, in our
three-month-long monitoring of the campaign based on the Spyware
distribution Bar akamaihd.net_rvar-a, we found that besides the
Bar, 320 newly-registered websites participated in the attack; here
the Bar acted very much like a dispatcher: providing JavaScript
that identiﬁed the victim’s geolocation and then using an iframe to
redirect her to a selected bad site.
Content sharing. Our research reveals that Bars have been ex-
1547Rank
Cloud bucket
# of front-end sites Avg path len
Popularity
Table 5: Top 10 most popular Bars.
1
2
3
4
5
6
7
8
9
10
s3.amazonaws.com_content.sitezoogle.com
cloudfront.net_d3n8a8pro7vhmx
s3.amazonaws.com_assets.ngin.com
s3.amazonaws.com_publisher_conﬁgurations.shareaholic
cloudfront.net_d2e48ltfsb5exy
cloudfront.net_d1t3gia0in9tdj
cloudfront.net_d2i2wahzwrm1n5
cloudfront.net_d202m5krfqbpi5
s3.amazonaws.com_ﬁles.enjin.com
akamaihd.net_cdncache3-a
4,429
1,829
1,643
1,434
1,340
1,297
1,249
1,062
1,020
976
2.9
3.3
3.2
2.7
4.0
3.2
2.5
2.8
7.1
6.4
2.8%
1.4%
1.2%
0.9%
0.9%
0.9%
0.8%
0.8%
0.7%
0.6%
(a) Cumulative distribution of degrees
per sites.
(b) Percentage of Bars in each posi-
tion of redirection path (Ignoring those
traces with length of 2).
(c) Cumulative distribution of number
of in-degrees per Bar.
Figure 7: Bars play critical roles in attack infrastructures.
tensively shared among malicious or compromised websites, also
across different positions on malicious redirection chains. Fig-
ure 7(c) illustrates the cumulative distribution of Bars’ in-degrees in