title:Isolated Program Execution: An Application Transparent Approach for
Executing Untrusted Programs
author:Zhenkai Liang and
V. N. Venkatakrishnan and
R. Sekar
Isolated Program Execution: An Application Transparent Approach for
Executing Untrusted Programs∗
Zhenkai Liang, V.N. Venkatakrishnan and R. Sekar
Department of Computer Science
Stony Brook University, Stony Brook, NY 11794.
{zliang, venkat, sekar}@cs.sunysb.edu
Abstract
In this paper, we present a new approach for safe exe-
cution of untrusted programs by isolating their effects from
the rest of the system. Isolation is achieved by intercepting
ﬁle operations made by untrusted processes, and redirect-
ing any change operations to a “modiﬁcation cache” that
is invisible to other processes in the system. File read op-
erations performed by the untrusted process are also cor-
respondingly modiﬁed, so that the process has a consistent
view of system state that incorporates the contents of the ﬁle
system as well as the modiﬁcation cache. On termination of
the untrusted process, its user is presented with a concise
summary of the ﬁles modiﬁed by the process. Additionally,
the user can inspect these ﬁles using various software util-
ities (e.g., helper applications to view multimedia ﬁles) to
determine if the modiﬁcations are acceptable. The user then
has the option to commit these modiﬁcations, or simply dis-
card them. Essentially, our approach provides “play” and
“rewind” buttons for running untrusted software. Key ben-
eﬁts of our approach are that it requires no changes to the
untrusted programs (to be isolated) or the underlying oper-
ating system; it cannot be subverted by malicious programs;
and it achieves these beneﬁts with acceptable runtime over-
heads. We describe a prototype implementation of this sys-
tem for Linux called Alcatraz and discuss its performance
and effectiveness.
1. Introduction
The widespread deployment of ﬁrewalls and related so-
lutions for network security has signiﬁcantly raised the bar
for remote attacks on an enterprise network. However, even
the best perimeter solutions can be easily defeated by an at-
tacker that can induce users inside the enterprise to down-
load and execute malicious code. While virus detection and
similar techniques can be deployed to detect widely preva-
∗
This research is supported in part by an ONR grant N000140110967
and an NSF grant CCR-0208877.
lent instances of malicious code, such techniques are limited
in theory (by the fact that detection of malicious code is un-
decidable in general) as well as practice (by factors such as
the difﬁculty of object code analysis and encryption).
A more promising approach for defending against mali-
cious code is based on sandboxing, wherein the resource ac-
cesses made by untrusted code are suitably restricted to en-
sure security. However, use of such approaches in practice
has been hampered by the difﬁculty of policy selection: de-
termining resource access rights that would allow the code
to execute successfully without compromising system secu-
rity. Too often, sandboxing tools incorporate highly restric-
tive policies that preclude execution of most useful applica-
tions. The net result is that users end up choosing function-
ality over security, and thus execute untrusted code outside
such sandboxing tools, exposing themselves to unbounded
damage if this code turned out to be malicious.
An alternative to sandboxing is
isolated execu-
tion, wherein the actions of untrusted code are isolated
from other applications. Isolated execution has previ-
ously been studied by researchers [15, 7] in the context
of Java applets. Such applets do not require much ac-
cess to system resources, other than being able to inter-
act with a user. Hence the implementation approach used by
these works relied on executing untrusted applets on a “re-
mote playground”,
(other
than a user’s desktop). However, applications that per-
form more useful functions will require access to resources
such as the ﬁle system on the user’s computer. To pro-
vide such access, the entire environment on the user’s
computer, including ﬁle system contents, must be dupli-
cated on the remote playground.
i.e., an isolated computer
Logical isolation, wherein the effects of a malicious pro-
cess are logically isolated from other processes, can achieve
the beneﬁts of isolated execution without the drawback of
requiring dedicated hardware or solving the difﬁcult prob-
lem of accurate duplication of environment. It was proposed
in [19] to permit continued operation of compromised pro-
cesses without alerting attackers and without risking dam-
age to the rest of the system, and in [11] in the context of
Proceedings of the 19th Annual Computer Security Applications Conference (ACSAC 2003) 
1063-9527/03 $17.00 © 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:43:46 UTC from IEEE Xplore.  Restrictions apply. 
databases. The theory of data isolation was further devel-
oped systematically in [14] in the context of databases as
well as ﬁle systems, and isolation protocols that demon-
strate the feasibility of the approach were presented. How-
ever, practical issues that arise in implementing this ap-
proach on contemporary operating systems were not stud-
ied. In contrast, this paper develops an application- and
OS-transparent approach for isolated execution of untrusted
programs, and describes a tool called Alcatraz that imple-
ments this approach on the Linux operating system.
Our approach permits untrusted applications to access
the entire ﬁle system that is accessible to the end users,
thereby making it possible for most applications to carry
out their tasks. Using a copy-on-write semantics, modiﬁca-
tions to the ﬁle system that are performed by the untrusted
application are hidden from the rest of the system, which
ensures that malicious actions of the untrusted code will not
compromise the integrity of the system. Accesses to non-
ﬁle resources are restricted as needed to ensure integrity. At
the completion of execution, the users can inspect the ac-
cesses made by the untrusted code to see if it changed any
ﬁles of interest to them, and if so, examine these changes. If
the users are convinced that these changes are benign, then
they can commit these changes, so that they become visi-
ble to the rest of the system. Otherwise, the users can abort
these changes. The key beneﬁts of our approach are:
• Application and operating system transparency. Our ap-
proach requires no changes to the underlying operating
system or the untrusted application itself. Moreover, the
technique can be applied regardless of whether the ﬁles
accessed by the application are local, or are located on
a remote ﬁle server.
• Secure yet application-friendly. Our approach provides
security against malicious code without imposing un-
due restrictions on such code. This makes it possible
for a large class of existing software to execute success-
fully, unlike sandboxing based approaches.
• Convenient and user-friendly. Our approach provides a
compact summary of the ﬁle system resource accesses
made by untrusted code at the end of its execution. This
contrasts with sandboxing approaches that prompt users
on each ﬁle access disallowed by the sandbox policy. In
addition, the user is given the ability to examine these
ﬁles to determine whether the application carried out the
functionality that the user wanted.
Our implementation does not require the users of our system
to possess administrator privileges. It imposes modest over-
heads for isolation (below 20% for all the applications we
have studied). However, the mechanism we have used for
system call interposition poses moderate overheads, ranging
from under 10% for CPU-intensive applications to nearly
100% for I/O-intensive applications.
The description in the rest of the paper is set in the con-
text of Linux, but the techniques are applicable to most
modern operating systems. The organization of the rest of
paper is as follows. We begin with two motivating examples
in Section 1.1. Section 2 provides an overview of the sys-
tem design, followed by more detailed descriptions of the
system components. Implementation results are discussed
in Section 3, followed by related work in Section 4. Finally,
concluding remarks appear in Section 5.
1.1. Motivating Examples
Photo organizer. Consider an application that scans spec-
iﬁed directories for image ﬁles and generates photo album
ﬁles that are written to the same directories. It also gener-
ates thumbnail pictures from these ﬁles (for creating index
ﬁles) and has the ability to modify/resize these ﬁles. Simi-
lar applications that modify images and other media such as
audio ﬁles are available as freeware on the Internet, e.g., the
picturepages [21] package. Safe execution of such ap-
plications poses two challenges for sandboxing approaches.
• policy selection: Users have to anticipate the resource
access requirements of a program prior to its execu-
tion, which is often difﬁcult. To overcome this problem,
some sandboxing approaches allow changes to policies
through runtime prompts to the user: when the sand-
boxed application violates the initially speciﬁed pol-
icy, the user is informed and queried whether he/she
wants to permit this access. Unfortunately, such re-
peated prompts lead to “click-fatigue,” as a result of
which the user simply grants (or refuses) all subsequent
prompts without reviewing them.
• policy granularity: Users need to develop policies that
permit an application to access the resources that it
needs, while ensuring that these resources are not cor-
rupted or deleted. For the photo organizer example, such
a policy would have to permit “legitimate” changes to
image ﬁles, as needed for resizing images or including
previews, while disallowing other changes. Develop-
ment of a policy that can capture such legitimate trans-
formations is likely to be hard. Even if such policies can
be expressed, enforcement of such policies is likely to
be inefﬁcient, if not impossible [18].
Due to these difﬁculties, sandboxing policies tend to be con-
servative and often disallow a large class of useful programs
such as the picturepages program. In contrast, our pro-
posed approach will permit execution of programs as long
as they don’t make system changes other than ﬁle modiﬁca-
tion operations. Most applications observe this constraint,
and hence they can be run safely using isolation. Moreover,
users need not develop safety policies ahead of time. Fi-
nally, they have the opportunity to examine the system state
resulting due to the execution of the untrusted program, and
then decide whether to “keep” or “rollback” these changes.
They can use standard system utilities such as find and
Proceedings of the 19th Annual Computer Security Applications Conference (ACSAC 2003) 
1063-9527/03 $17.00 © 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:43:46 UTC from IEEE Xplore.  Restrictions apply. 
diff, as well as arbitrary helper applications such as im-
age viewers, to examine the system state.
Software installation. Users are all
too familiar with
poorly packaged software that crashes during its installa-
tion, or simply does not function correctly. Even worse,
the new package may “break” other applications in-
stalled on the system. In all these cases, the users are
faced with the daunting task of rolling back the instal-
lation. If the package made use of standard package
management utilities, this rollback is usually not burden-
some. However, if the package came as a self-installing
executable or as a source package, rollbacks are al-
most always very difﬁcult. The package may install its
ﬁles into standard directories such as /usr/local/bin
and /lib. It may also modify system conﬁguration ﬁles
such as /etc/passwd, /etc/mime.types or user pro-
ﬁle ﬁles such as ˜/.bashrc. Identifying the exact set
of ﬁles that were modiﬁed is cumbersome. It
is also
prone to errors as the user does not know the directo-
ries where the package installed ﬁles, and hence has to
search the entire ﬁle system. This may result in identify-
ing many ﬁles that may have been modiﬁed by applications
other than the installer. Even if the modiﬁed ﬁles are identi-
ﬁed correctly, rollback is still a hard problem: it is possible
only if the user had backed up modiﬁed ﬁles, but unfor-
tunately, the user did not know ahead of time which ﬁles
would be modiﬁed by the installation.
Using our isolation approach, all of the above problems
can be tackled easily. Users simply install the package in
isolation. Within this isolation environment, users can then
try out the package. They can also examine the ﬁles mod-
iﬁed by the package, and see if it includes security-critical
ﬁles, or ﬁles that may be used by other packages. (System
conﬁguration databases, such as the Redhat Package Man-
ager database, can help in identifying ﬁles used by other
packages.) If so, they can examine these ﬁles to identify the
changes made. Alternatively, they can try out the applica-
tions that depend on these modiﬁed ﬁles to ensure that they
are not broken. If the users are convinced, after making all
these checks, that the new package has been installed cor-
rectly and is functioning properly, they can commit the in-
stallation. Otherwise they can can discard the installation —
at this point, the ﬁle system state will be as if the installa-
tion never took place.
2. System Description
2.1. Technical Goals and Design Approaches
The goal of logical isolation is to preserve system in-
tegrity.1 In particular, if the ﬁle system changes made by an
1 Conﬁdentiality can be preserved to the extent the untrusted applica-
tion can be prevented from making network communications, but this
untrusted application were not committed, then the integrity
of the system must not be compromised by this application.
Moreover, there should be no data loss, such as the loss as-
sociated with rolling back the effects of other system and
user processes. In effect, the system state should be as if the
untrusted application was never run.
Our approach is focused on preserving the contents of
the ﬁle system. However, in order to ensure overall sys-
tem integrity, we also need to consider operations other than
those involving ﬁle systems. Such operations must be pre-
vented from being executed if they can change the system
state. We need to be conservative in determining whether
an operation can change system state: unless we know for
sure, an operation made by an untrusted process must be
disallowed. A simple implementation of such a conserva-
tive approach may disallow all network communications (as
they can modify the state of other hosts), ﬁle operations that
modify devices, etc. A more usable approach will recog-