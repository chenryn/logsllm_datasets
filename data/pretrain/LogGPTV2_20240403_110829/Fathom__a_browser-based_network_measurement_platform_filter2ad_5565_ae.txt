bandwidth measurement, and in-path buffer size measurements.
Standard JavaScript APIs provide no equivalent functionality, but
Fathom’s UDP access allowed us to realize the tests.
HTTP functionality & correctness: These tests determine the
presence of HTTP proxies and, if found, the use of caching and
caching correctness. The JavaScript XMLHttpRequest API is in-
sufﬁcient to implement Netalyzr’s proxy tests as it provides in-
adequate control over raw message headers and browser caching.
Fathom’s TCP APIs allow us to realize these tests.
DNS functionality & correctness: This category broadly cov-
ers DNS feature support tests, lookup performance measurements,
lookup result correctness, and tests for known security problems.
While standard JavaScript APIs can use the success status of HTTP
requests as an implicit signal of success for the underlying DNS
lookup, one cannot obtain the actual IP address resulting from the
request, which virtually all tests in this category require. Fathom’s
DNS API allows us to conduct these tests.
IPv6 support: This category includes reachability tests to IPv6-
only servers as well as performance comparisons to servers reach-
able over IPv6 as well as IPv4. As the address family effectively
remains abstracted, standard JavaScript can handle these tests via
URL requests from the servers in question.
API usability: The Java-to-JavaScript porting effort also allow
us to compare programming paradigms. JavaScript’s basic single-
threaded execution model with callback-driven asynchronicity dif-
fers substantially from Java’s lightweight threading model. Ac-
cordingly, restructuring the client’s overall execution ﬂow required
signiﬁcant reworking of the basic design, while porting the tests
themselves felt quite straightforward. Netalyzr’s tests execute in
individual threads using I/O that may block, with a main thread
monitoring test durations. In writing our JavaScript version, we re-
structured each test into a larger set of individual functions chained
together via callbacks invoked by Fathom upon I/O progress. The
main test sequence likewise leverages test completion callbacks.
We implemented the Fathom-driven Netalyzr subset in two weeks,
the majority of which went into replicating the overall test execu-
tion, reporting harness, and GUI. Each test took on the order of an
hour to port.
Fathom bandwidth tests: Netalyzr’s testsuite includes measure-
ments of the available send and receive bandwidths. We implement
two versions of the bandwidth test:
• In-Fathom. To estimate the maximum possible send/receive
rate that Fathom can achieve, we invoke NSPR’s UDP
send/recv APIs within a tight loop to saturate the available
network bandwidth. Since executing a tight loop increases CPU
load, we repeat the experiment and invoke the NSPR send
81Send /
Receive
Send
Recv
Payload
(bytes)
0
1024
0
1024
Iperf
(Mbps)
13.60
93.90
4.89
93.70
In-Fathom (Mbps) Web page (Mbps)
Callback
Loop
0.75
6.64
92.35
24.51
0.02
4.55
73.36
1.69
Callback
2.42
81.41
0.79
52.85
Loop
1.66
49.48
0.84
22.63
Table 6: Fathom’s send/receive data rates for different pay-
loads.
API within a setTimeout with delay 0, which enables other
events in the event queue to get processed.
• Web page. To get an estimate of the send/receive trafﬁc that
JavaScript on a web page can achieve, we perform the same
tests but invoking Fathom’s socket send/recv APIs, both
within a loop and using a timer.
We perform all tests between a laptop and a desktop connected
over a 100 Mbps Ethernet and compare them with the speed
achieved by iperf. We determine the maximum available send
bandwidth using a Fathom client and an iperf server. We deter-
mine the maximum available receive bandwidth using a Fathom-
based server and an iperf client. Table 6 shows the results. We
observe that under the In-Fathom category, using the NSPR APIs
we get much higher trafﬁc rates than the web pages using Fathom’s
APIs. We expect this, since NSPR APIs are synchronous, while
due to the asynchronous nature of Fathom APIs every additional
callback in the call sequence affects the bandwidth rates.
We also observe that send rates increase as the payloads increase
and match iperf send rates at high payload size. But the maximum
achievable receive rate did not exceed 73.4 Mbps. Although we
could not experimentally verify the cause of the imbalance in the
send and receive rates, the discrepancy could arise due to the js-
ctypes library used for Fathom’s socket APIs. We suspect js-ctypes,
which does not beneﬁt from JavaScript’s JIT optimizations [18, 6],
may pose a signiﬁcant performance bottleneck.
A natural way to improve the send/receive bandwidths is to par-
allelize the tests. We tried using HTML5 Web Workers, which
spawn OS-level threads to concurrently perform the bandwidth
tests. We observed that the reported bandwidth did not increase
when running the test in a tight loop. We attribute this to a lim-
itation of the Workers, which cannot access the page’s JavaScript
namespace, including the window object. Workers, thus, cannot
access Fathom APIs deﬁned on the window.fathom object. All
accesses to Fathom APIs must require another level of indirection
using the asynchronous message passing postMessage API be-
tween the Worker thread and the main UI thread (which has ac-
cess to the window.fathom object). This indirection limits the
achieved bandwidth.
To enable better bandwidth tests from a web page, script authors
should therefore implement bandwidth tests via FathomScripts (re-
call § 5.4), as they obviate the message passing overhead.
Summary: Our implementation of key Netalyzr tests that prove
difﬁcult or infeasible to realize in standard JavaScript (local net-
work conﬁguration, UPnP probing, DNS features, and particu-
larly UDP-based latency and bandwidth tests) conﬁrm Fathom’s
versatility.
For tests leveraging low-level APIs, particularly
fathom.socket.*,
the coding effort compares to that re-
quired in Java, while tests that could leverage Fathom’s APIs (e.g.
fathom.proto.upnp.*) instead of needing full protocol im-
plementations required a fraction of the code.
7.2 Web access failure debugging
While troubleshooting suites such as Netalyzr work well when the
user has access to sufﬁcient connectivity to download and run the
testsuite, such an approach fails in the presence of more funda-
mental connectivity problems. Indeed, a frequent request we re-
ceive from Netalyzr users is to expand the connectivity tests in that
direction, particularly in Netalyzr’s command-line interface. For
such scenarios, we developed a “Debug my connection” measure-
ment application. We include this script as a built-in part of the
Fathom distribution (which provides an immediate incentive for
users to install Fathom), but emphasize that we implement it solely
in JavaScript using the existing Fathom API. The script is currently
400 LOC.
Implementation: We structure the connectivity debugger by start-
ing at the host’s link-level network interface conﬁguration and
progressing upward through the protocol stack, identifying and
reporting problems at each layer. The test begins by obtain-
ing basic system usage statistics from Fathom’s usage baseline,
including memory usage and process load. Using fathom.
system.getActiveIntefaces(), we detect whether the
system actually connects to any network.
If so, we report re-
cent link quality and throughput counters for the active interfaces,
as reported by fathom.system.getNetworkUsage(), and,
again using the baseline counters, report on cross trafﬁc originat-
ing from outside of the browser. We then move up to the net-
work layer and test the availability of a default route in the sys-
tem’s routing table, as well as IP-level connectivity (via fathom.
system.doPing()) to the gateway and DNS resolver(s) (via
fathom.system.getResolvers()), and relevant browser-
level conﬁguration settings such as proxies (via fathom.utils.
browser.getProxyConfig()). Moving up to the transport
level, we attempt retrieval of an image from www.google.com,
and the test completes.
At each stage, we report on the outcome of the tests involved. In
the current version, users click on a “Debug my connectivity” but-
ton provided in the browser toolbar in order to initiate diagnosis,
but we envision hooking the connectivity debugger into relevant
parts of the browser in order to automatically provide contextual
information to the user. For example, upon failing DNS lookups,
we can automatically test the DNS conﬁguration, and for unavail-
able servers we can test whether the user experiences a full outage
or one just affecting the destination site.
Collaborative debugging: We can further troubleshoot possible
connectivity problems in the local network by leveraging Fathom’s
rendezvous and server-side abilities. In particular, we can leverage
Fathom’s UPnP and zeroconf capabilities (via fathom.proto.
{mdns,upnp}.*) as follows. First, using UPnP we can try to lo-
cate UPnP-enabled gateway devices. If available, such devices can
report uplink type, upstream/downstream throughput counters, and
other information [51]. Second, using UPnP and Zeroconf we can
locate other Fathom-enabled devices. Since Fathom supports lis-
tening sockets, we can then engage in both local and remote latency
and throughput tests. Correlating the resulting numbers allows us
to pinpoint packet loss problems.
To test this approach, we have implemented a Fathom-powered
web application in 320 lines of code that lets two Fathom instances
detect each other using UPnP and initiate probes to measure uni-
directional loss and latency between each pair of Fathom-enabled
nodes. The script then compares these values with historic val-
ues of loss rates and delays for the local networks, obtained from
Fathom’s passive data collection. Values greater than expected
cause the application to report poor local network performance.
Crucially, in order to conduct this testing the user neither needs to
82work). Fathom tracks all HTTP-level metrics for the last 20 user
sessions. Using DOM localStorage, it makes the results avail-
able to all scripts of the same origin. We then average these values
to generate baseline values for Google Maps. As a result, the debug
script can identify the problem by checking if the amount of down-
loaded content for the web page reduced substantially, if the data
rate for individual resources in the web page improved, and also if
the browser fetched a web page resource entirely from the cache.
If the load time far exceeds the baseline, it could indicate a net-
work impediment or a host problem. To distinguish between the
two cases, the debug script examines the content time, i.e., the time
elapsed to download the content of the web page. A content time
less than or equal to the baseline indicates that a problem with the
host machine or the browser slowed down the rendering. Such a
condition could also arise if the user explicitly stops the loading of
the web page and then invokes the debug script. Our debug script
uses fathom.system.* APIs to determine resource utilization.
If content time proves larger than the baseline, the problem most
likely resides in the network. We debug slow networks as discussed
in the previous section.
Emulating Google Maps: Since we did not have access to Google
Maps servers, we modiﬁed the site’s JavaScript code at runtime.
When visiting the Google Maps page, we inject the debug script
and the Fathom debug button using Greasemonkey [30]. Our debug
script uses Fathom APIs to implement all diagnostic cases shown
in Figure 4.
We implemented Fathom’s Google Maps debug script
in
640 lines. It imposes no observable runtime overheads. The bulk of
the script implements parsing routines to interpret responses from
fathom.system.* as well as statistical utilities to compute av-
erage and standard deviation for metric values. Fathom’s system,
network, and browser-level APIs directly provide all values except
for cross-trafﬁc, which we measure using a combination of APIs:
cross-trafﬁc at the host is the fraction of HTTP trafﬁc observed
by the browser over the TCP-level trafﬁc approximated from the
link-level network measurements. In order to estimate cross-trafﬁc
given only transport level information from the browser, Fathom
must also account for the effect of framing. To do so, Fathom as-
sumes all link-level trafﬁc to be TCP and subtracts the per-packet
overhead from the trafﬁc counters (in bytes) to get approximate
transport level TCP trafﬁc. It then compares this value against the
TCP trafﬁc values available from the browser.
We used our debug script and performed 10 trials of loading the
Google Maps home page with packet loss of 10, 20, 30 and 50
percent and packet delays of 0.5, 1.0, 1.5 and 2.0 seconds. We
emulate packet loss and delays with netem. In each case, before
starting the experiments, we loaded the Google Maps home page
repeatedly to allow Fathom to calculate the starting baseline metrics
using 20 normal sessions.
While the page load time increased in the presence of packet
loss rates up to 20%, the content download time remained within
two standard deviations. Higher packet loss rates severely affected
the goodput and the page took much longer to load. We observed
that for all packet delays (starting from 0.5 seconds), the debug
script indicated load times larger than two standard deviations and
the content download time also increased. In all cases, the debug
script identiﬁed a change in the network operating conditions. As
the number of completed connection trials increased, more sam-
ples fell into the range of two standard deviations and so Fathom
could include the HTTP metric values from the newer sessions.
The debug script thus adjusted the baseline correspondingly, with
the result that some of the later trials reported normal operating
conditions.
Figure 4: Diagnosis logic when the page load failed (top) vs.
when it succeeded (bottom).
understand command-line tools that might serve similar purposes,
nor orchestrate the testing procedure manually. Currently, the web
application consists of stand-alone web pages. Integrating its func-
tionality into the debug button forms part of our future work.
7.3 Web services debugging: Google Maps
Fathom substantially expands the ability of web site developers to
understand the context and impediments that affect the way their
pages render in the client’s browser. Fathom’s API enables a range
of potential measurements of interest in this context, such as pin-
pointing of loss in the home or backbone [11], system and I/O load
on the client’s device, and network connectivity conﬁgurations that
hamper performance (e.g., via slow HTTP proxies). In the follow-
ing, we demonstrate Fathom’s utility in troubleshooting client-side
issues for web services by playing the role of the developer for
Google Maps. We make two modiﬁcations to the Google Maps web
page code. First, we embed a diagnostic script that uses Fathom
APIs to obtain results for passive and active measurements. Sec-
ond, we provide a debug button on the Google Maps page, which
enables a user to initiate execution of the debug script. In the spe-
cial case when the button itself does not render (because page load-
ing failed), users can employ Fathom’s connectivity debugger as
explained in the previous section.
Implementation: The debug script ﬁrst veriﬁes if the Load event
for the Google Maps web page ﬁred, conﬁrming full page load.
Figure 4 illustrates the decision logic Fathom follows for failures
If the load
(top) and successes (bottom) of page load attempts.
time—i.e., the time elapsed between the ﬁrst HTTP request and
when the Load event ﬁres—resembles9 the corresponding baseline
value, then the algorithm reports a normal load and terminates.
If the load time turns out far smaller than the baseline value, the
baseline metric does not apply to the current scenario. Possible
causes include changing content size, page caching, and improving
network conditions (such as when the user moved to a faster net-
9We say that a value is similar to the corresponding baseline value
if it lies within ±2 σ of the baseline value.
838 Discussion