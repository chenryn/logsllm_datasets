Caching Service: In order to faithfully record the in-
fection trails (for later replay or analysis), we propose a
proxy-like caching solution to complete the snapshot task.
“Proxy-like” means that it is in the middle of the client and
the server and behaves like a proxy. The advantage of the
proxy-like approach is that it records the necessary informa-
tion without the awareness of both client and server. The
analyzer can cache all the resources it retrieves by simply
setting its proxy address to the address of the caching ser-
vice. The diﬀerences between our caching service and a real
web proxy are as follows:
• A web proxy typically only caches static HTML pages
and ignores the dynamic HTML pages, and it will not
cache responses with the private/no-cache/no-store cache
control setting in the request header. However, our
caching service needs to store every web resources trig-
gered by the analyzer.
• Cached data in a normal proxy may expire, and need to
be updated, but our caching service do not need such
validation. In contrast, the cache resources should be
stabilized, and should not be modiﬁed after it is col-
lected.
4.2 Scenario Replay
The goal of WMS replay is to provide a service to third
party analysts or other analysis tools so that they can ana-
lyze the malicious scenario faithfully, just as they visit the
original web-based malware in the wild at a given (previous)
time.
Replay Service: We use the same proxy-like caching
system to provide the WMS replay service. The diﬀerence
between the caching service and the replay service is that
the replay service is operated in an oﬄine fashion so that it
will not interact with the actual/original remote servers, and
all the response contents needed are provided by the cached
WMS data. Also, the replayer provides isolation between
diﬀerent scenarios. This is necessary because the content of
the same URL may change as time passes, and it may refer
to diﬀerent resources when collected at diﬀerent times.
Figure 2: The architecture of automated WMS col-
lection and replay system
4.1 Scenario Collection
The enumeration of all possible web resources in a web-
based malware scenario is actually very hard due to the
complex and obscure HTML/Javascript components, not to
mention various obfuscation tricks introduced by the ad-
versaries. As a result, it is very diﬃcult, or nearly impos-
sible to collect the complete original scenario (µ, V, E, T ).
Therefore, the goal of our scenario collection is to obtain
(µ, V (cid:48), E(cid:48), T (cid:48)), so that V ∩ V (cid:48), E ∩ E(cid:48) and T ∩ T (cid:48) are max-
imized and the replay service can reconstruct web infection
trails as complete as possible using the recorded data. Two
modules are used in our design: a light-weight analyzer and
a proxy-like caching service.
Analyzer: Web-based malware collection heavily relies
on the analysis of web response/content. As mentioned ear-
lier, the malicious web logics are stored on the (distributed)
remote sites, and adversaries introduce many tricks to hide
the essential exploit vectors from being easily discovered.
Constructing a collection of malicious resources requires enu-
merating all (if possible) outgoing links from a given re-
source node, some of which may be obfuscated or embed-
ded in shellcode. Thus, the analyzer is designed to analyze
web response/content and discover as many outgoing links
in E as possible. To facilitate the analysis, we employ a low-
interaction (LI) client honeypot based on browser emulation
technique, and introduce several techniques to increase the
coverage of infection trails.
We choose LI client honeypots rather than high-interaction
(HI) client honeypots, because HI client honeypots, such as a
real browser within a virtual machine, usually have a limited
number of vulnerabilities/extensions in a speciﬁc version of
a browser and an operating system. As we discussed be-
fore, a dispatching page usually checks if the target system
has a certain vulnerability or plugin before triggering the
retrieval of the exploit scripts. For example, Figure 3 shows
a JavaScript snippet intercepted from a real-world dispatch-
Replay Client: The replay service can be provided to
other users, e.g., security researchers/analysts. We can serve
any kind of client software for live/interactive replay. For
example, the client can be a real browser, a client honeypot
(HI or LI), or an analyst using wget to fetch and analyze
the scenario manually.
5.
IMPLEMENTATION
To implement WebPatrol, we use an improved version of
PHoneyC [11] as the analyzer2, aiming to increase the cov-
erage of outgoing links enumeration. We also use a modiﬁed
version of Polipo [4], referred to as wmPolipo, to provide the
caching and replay service 3.
5.1
Improved PHoneyC
PHoneyC is a client honeypot written in Python that
provides visibility into new and complex client-side attacks.
The original PHoneyC contains three key modules: an HTML
parser, a JavaScript (JS) engine and a plugin/ActiveX em-
ulator. It will try to emulate a real browser’s JS context, let
suspicious scripts run inside the emulated environment, and
raise an alert if it detects malicious activities.
Our improvement on PHoneyC aims to trigger as many
outgoing links as possible, so that the caching service can
collect a fairly complete scenario. To achieve this, we not
only enhanced the emulation of a browser within PHoneyC,
but also implemented new techniques to trigger more outgo-
ing links. Generally, there are three kinds of obstacles that
PHoneyC should deal with: the ﬁrst one is dynamically gen-
erated outgoing links via document.write or eval, etc. The
second is conditional outgoing links (as previously shown in
Figure 3), and the third is further downloads through vul-
nerable API misuses or the shellcodes.
Dynamically generated outgoing links: The key for
extracting the dynamically generated outgoing links is to
provide a solid JS context, so that the outgoing links in the
obfuscated scripts can be outputted correctly as it does in
the real browser after the interpretation of JS scripts. DOM
(Document Object Model) plays an indispensable role in
building a solid JS context. As for the enhancement of the
previous framework, we rewrote the DOM simulation en-
gine in PHoneyC. The previous version of PHoneyC does
not generate a DOM tree for the web pages, namely it will
only add DOM nodes into the JS context but never main-
tains reference relationships between them. We enhanced
it by providing a complete DOM tree to the JS context,
as well as adding most of the methods and attributes pro-
vided by a DOM node in a real browser (e.g. innerHTML,
and manipulation of a DOM node through a DOM path).
Those improvements guarantee the successful execution of
JavaScript scripts, and can extract dynamically generated
outgoing links after the execution.
Conditional outgoing links: As shown in Figure 3, vul-
nerability existence checks or other condition checks prevent
the creation of the IFRAMEs that may contain the outgoing
links to the exploit pages. We partially solved this problem
by implementing a mock ActiveXObject class and adding
to
modiﬁcation
to
PHoneyC’s
2The
merged
http://code.google.com/p/phoneyc/
3The
ical
http://59.108.116.135/login.psp.
in-the-wild WMS
replay service,
together with a set of
available
samples,
is
typ-
from
PHoneyC
oﬃcial
svn
has
been
repository:
it into the JavaScript context of PHoneyC. Therefore, the
instantiation of ActiveXObject is actually handled by our
dummy class, and the dummy class will always return like
the object is successfully created. Consequently, the dis-
patching script will be deceived and generate the outgoing
links.
Further downloads after a successful exploit: Be-
cause of the limited emulation level of real environments in
a LI client honeypot, no attack can be launched practically.
Thus, it is diﬃcult for PHoneyC to get the URL of further
downloads after the successful compromise (e.g., through an
API misuse or exploitation by injected shellcode). To deal
with this, we enhance PHoneyC by implementing both simu-
lated modules for several known vulnerable ActiveX objects
and a shellcode detection and emulation module.
We have implemented several known vulnerable ActiveX
objects such as Baidu Soba Remote Code Execute Vulnera-
bility[7] (shown in Figure 4). In this case (Baidu vulnerabil-
ity exploitation), we implement the vulnerable methods of
the objects and can download the URL passed in. To handle
the cases of unknown (zero-day) vulnerabilities, we simply
search for URLs in the arguments using regular expression,
and download them no matter whether it is needed by the
exploit or not.
try{var j;
var Baidu=new ActiveXObject("BaiduBar.Tool")}
catch(j){};
finally{
if(j!="[object Error]")
{Baidu["DloadDS"]("http://l.XXXX.com/Baidu.cab",
"Baidu.exe",0)}
}
Figure 4: Baidu Soba Remote Code Execute Vul-
nerability Exploit
Our shellcode detection and emulation module is imple-
mented as a dynamic instrumentation of the opcodes used in
PHoneyC’s JavaScript engine, and as a check of the r-values
of all string assignments. This detection is accomplished by
libemu[2], a shellcode detection and emulation library. If a
shellcode snippet is recognized, we use libemu to emulate
the execution of the shellcode. During its execution, libemu
will recognize API calls such as URLDownloadToFile, which
will then trigger the download of URLs in arguments.
5.2 wmPolipo
Polipo[4] is a small and fast web proxy. It can cache the
responses from a server on a local storage. We modiﬁed
Polipo to accomplish the snapshoting and replay of the sce-
narios in a tool we call wmPolipo. Diﬀerent from a normal
proxy server, wmPolipo aims to record and stabilize all data
from the server side in a WMS on a local storage. There-
fore we have to modify the cache control policy of Polipo to
ignore the cache control ﬁeld in HTTP headers and record
whatever it receives to disks.
Randomized URL: Sometimes web-based malware will
generate an outgoing link URL including a randomized ar-
gument or ﬁle name, as shown in Figure 5. This trick aims to
resist some static caching technique in a replayer, and also it
can escape a URL blacklist-based ﬁlter in IDS/IPS or AVs.
wmPolipo replayer can defend against such obfuscation us-
ing a “URL-similarity-check” approach. When wmPolipo
cannot ﬁnd the cached resources according to its URL, it
will compare all the same-domain cached URLs with the re-
quested one, simply by a string comparison, and provide the
most similar one (sharing a longest common subsequence).
document.write(’’);
Figure 5: Randomized URL
Furthermore, as we provide collected scenarios to multi-
ple individuals, we have to modify the architecture of Polipo,
from the old single-user, single-cache-directory architecture
to a multi-user, multi-cache-directory one. These modiﬁca-
tions make the isolation between web-based malware sce-
narios and dynamic switching among them possible. Thus,
diﬀerent clients can access the replay service using diﬀerent
user accounts simultaneously. If those clients access diﬀerent
or even same web-based malware scenarios, the replay ser-
vice will distinguish diﬀerent clients by their username and
provide diﬀerent contents according to their current selected
scenario and client environment, even if the URLs requested
from diﬀerent clients are the same.
6. EVALUATION AND MEASUREMENT
6.1 Data Collection
Since Jan. 01, 2010, we have been using WebPatrol to
monitor web sites in CERNET (China Education and Re-
search Network, mostly .edu.cn domain, about 35,000 web-
sites in total) periodically (every two days). To obtain the
ground truth, we ﬁrst use a crawler-like detection system
which takes advantages of a high-interaction client honey-
pot, to hunt malicious URLs and feed them to WebPatrol
for collection of the web-based malware scenarios. Our client
honeypots cover the most popular client software and plug-
ins such as Internet Explorer (6.0, 7.0), Adobe Reader, Flash
Player, Storm Player, etc on Windows XP (SP1, SP2). If the
access to some URL triggers some unexpected state changes,
such as creating a new process, downloading some binaries to
sensitive directories, this URL will be labeled as malicious.
When a malicious URL is detected, the scenario collec-
tion module in WebPatrol collects the web-based malware
scenario behind the malicious URL, labeled with the landing
URL and the collecting timestamp. The replay service lists
them and replays selected scenario to other analysis tools.
In our case studies, we run multiple analysis tools, such as
some HI honeypots, Malzilla [3], and wget, to automatically
or manually analyze the scenarios for statistics and some
interesting ﬁndings.
In the following sections, we ﬁrst present some overall
statistics to show the severity of web-based malware in CER-
NET, and then we measure the collection completeness of
WebPatrol compared with other existing honeypot systems.
Finally we provide several case studies of analyzing the char-
acteristics of our collected web-based malware.
6.2 Basic Statistics of Collected WMS
During the period from Jan. 2010 to May. 2010, we col-
lected 26,498 malicious scenarios from 1,248 distinct landing
sites4. This accounts for 3.52% of all the websites on CER-
4As we are not discussing web-based malware detection in
NET. For the discovered 1,248 landing sites, we checked it
against Google Safe Browsing API5 immediately after our
detection, it turns out that Google only labeled 295 web
sites as malicious. 76.4% of all the landing sites are not
labeled. Also, for the overall 1,248 landing sites, we mea-
sure how long the injected malicious content can last within
it. It turns out that the average lasting time of an injected
malware is 23.2 days, and the longest lasting time is 132
days, which means it remain malicious nearly for the whole
measurement period. These two statistics shows that CER-
NET is a hot spot for web-based malwares, but it has not
received enough attention from the security companies and
the website administrators.
Furthermore, we count the number of times that the ex-
ploit hosting sites changes behind one landing site. In our
statistics, exploit hosting sites behind a single landing site
change 4.82 times on average, which means the exploit kits
behind a single site are highly changeable. We also count the
number of injected websites that contains malicious script
with the same top-level domain name. From the whois in-
formation against these malicious hosting domains (Table 2)
we can see that most(8 of 10) of the top 10 malicious do-
mains are subdomains registered at dynamic DNS providers
(e.g. Yaako Ltd. and GoDaddy.com). This result reveals
that the abuse of the dynamic DNS services is quite severe,
and need actions to respond to the situation.
Domain Name
8800.org
6600.org
3322.org
Registrant No. of Inject Sites
610
Yaako Ltd.
475
Yaako Ltd.
Yaako Ltd.
255
255
lookforhosting.com GoDaddy.com
163
Yaako Ltd.
157
Yue You
129
Yue You
cptiandi.com Melbourne IT
118
110
Yaako Ltd.
Yaako Ltd.
54
9966.org
caipiaoyuce.info
chinawordpress.info
8866.org
2288.org
Table 2: Top 10 Malicious Hosting Domains Discov-
ered during the Measurement of WMS on CERNET
6.3 Collection Completeness Evaluation
Web-based malware exploit kit: In some scenarios,
the dispatching page and exploit pages of diﬀerent scenar-
ios share similar reference sub-graph and also directory/ﬁle
names. This is because the dispatching pages and exploit
pages in the two scenarios are generated automatically by
the same web-base malware generator. Those similar infec-
tion graphs can be grouped together as a web-based malware
exploit kit.
To evaluate the completeness and limitations of WebPa-
trol, we randomly choose 2,000 WMSs as the sample set.
After grouping those 2,000 samples by their exploit kits, we
select the top 12 most popular exploit kits and 3 scenarios
this paper, we are not going to discuss the false positives
in this sample set in detail, however, as all of these samples
cause the download of executables and the execution of pro-
grams with malicious behaviors, such as writing to system
directories, modifying registry values, we can reasonably as-
sume there are no false positives here.
5http://code.google.com/apis/safebrowsing/