title:CT-GAN: Malicious Tampering of 3D Medical Imagery using Deep Learning
author:Yisroel Mirsky and
Tom Mahler and
Ilan Shelef and
Yuval Elovici
CT-GAN: Malicious Tampering of 
3D Medical Imagery using Deep Learning
Yisroel Mirsky and Tom Mahler, Ben-Gurion University; Ilan Shelef, 
Soroka University Medical Center; Yuval Elovici, Ben-Gurion University
https://www.usenix.org/conference/usenixsecurity19/presentation/mirsky
This paper is included in the Proceedings of the 28th USENIX Security Symposium.August 14–16, 2019 • Santa Clara, CA, USA978-1-939133-06-9Open access to the Proceedings of the 28th USENIX Security Symposium is sponsored by USENIX.CT-GAN: Malicious Tampering of 3D Medical Imagery using Deep Learning
Yisroel Mirsky1, Tom Mahler1, Ilan Shelef2, and Yuval Elovici1
1Department of Information Systems Engineering, Ben-Gurion University, Israel
2Soroka University Medical Center, Beer-Sheva, Israel
PI:EMAIL, PI:EMAIL, PI:EMAIL, and PI:EMAIL
Abstract
In 2018, clinics and hospitals were hit with numerous attacks
leading to signiﬁcant data breaches and interruptions in
medical services. An attacker with access to medical records
can do much more than hold the data for ransom or sell it on
the black market.
In this paper, we show how an attacker can use deep-
learning to add or remove evidence of medical conditions
from volumetric (3D) medical scans. An attacker may perform
this act in order to stop a political candidate, sabotage research,
commit insurance fraud, perform an act of terrorism, or
even commit murder. We implement the attack using a 3D
conditional GAN and show how the framework (CT-GAN)
can be automated. Although the body is complex and 3D
medical scans are very large, CT-GAN achieves realistic
results which can be executed in milliseconds.
To evaluate the attack, we focused on injecting and
removing lung cancer from CT scans. We show how three
expert radiologists and a state-of-the-art deep learning AI are
highly susceptible to the attack. We also explore the attack
surface of a modern radiology network and demonstrate one
attack vector: we intercepted and manipulated CT scans in an
active hospital network with a covert penetration test.
1 Introduction
Medical imaging is the non-invasive process of producing
internal visuals of a body for the purpose of medical examina-
tion, analysis, and treatment. In some cases, volumetric (3D)
scans are required to diagnose certain conditions. The two
most common techniques for producing detailed 3D medical
imagery are Magnetic Resonance Imaging (MRI), and CT
(Computed Tomography). Both MRI and CT scanner are
essential tools in the medical domain. In 2016, there were
approximately 38 million MRI scans and 79 million CT scans
performed in the United States [1].1
MRI and CT scanners are similar in that they both create
3D images by taking many 2D scans of the body over the
axial plane (from front to back) along the body. The difference
between the two is that MRIs use powerful magnetic ﬁelds
and CTs use X-Rays. As a result, the two modalities capture
body tissues differently: MRIs are used to diagnose issues
with bone, joint, ligament, cartilage, and herniated discs.
CTs are used to diagnose cancer, heart disease, appendicitis,
musculoskeletal disorders, trauma, and infectious diseases [2].
Today, CT and MRI scanners are managed though a picture
archiving and communication system (PACS). A PACS is
essentially an Ethernet-based network involving a central
server which (1) receives scans from connected imaging
devices, (2) stores the scans in a database for later retrieval,
and (3) retrieves the scans for radiologists to analyze and
annotate. The digital medical scans are sent and stored using
the standardized DICOM format.2
1.1 The Vulnerability
The security of health-care systems has been lagging behind
modern standards [3–6]. This is partially because health-care
security policies mostly address data privacy (access-control)
but not data security (availability/integrity) [7]. Some PACS
are intentionally or accidentally exposed to the Internet
via web access solutions. Some example products include
Centricity PACS (GE Healthcare), IntelliSpace (Philips),
Synapse Mobility (FujiFilm), and PowerServer (RamSoft).
A quick search on Shodan.io reveals 1,849 medical image
(DICOM) servers and 842 PACS servers exposed to the
Internet. Recently, a researcher at McAfee demonstrated
how these web portals can be exploited to view and modify
a patient’s 3D DICOM imagery [8]. PACS which are not
directly connected to the Internet are indirectly connected via
the facility’s internal network [9]. They are also vulnerable to
social engineering attacks, physical access, and insiders [10].
Therefore, a motivated attacker will likely be able to access
a target PACS and the medical imagery within it. Later in
section 4 we will discuss the attack vectors in greater detail.
1.2 The Threat
An attacker with access to medical imagery can alter the
contents to cause a misdiagnosis. Concretely, the attacker can
1245 CT scans and 118 MRI scans per 1,000 inhabitants.
2https://www.dicomstandard.org/about/
USENIX Association
28th USENIX Security Symposium    461
Table 1: Summary of an attacker’s motivations and goals for
injecting/removing evidence in 3D medical imagery.
Figure 1: By tampering with the medical imagery between
the investigation and diagnosis stages, both the radiologist and
the reporting physician believe the fallacy set by the attacker.
add or remove evidence of some medical condition. Fig. 1
illustrates this process where an attacker injects/removes lung
cancer from a scan.
Volumetric medical scans provide strong evidence of
medical conditions. In many cases, a patient may be treated
based on this evidence without the need to consider other
medical tests. For example, some lesions are obvious or
require immediate surgery. Moreover, some lesions will
legitimately not show up on other medical tests (e.g., meniscus
trauma and some breast cancers). Regardless, even if other
tests aren’t usually negative, ultimately, the evidence in the
scan will be used to diagnose and treat the patient. As a result,
an attacker with access to a scan has the power to change the
outcome of the patient’s diagnosis. For example, an attacker
can add or remove evidence of aneurysms, heart disease, blood
clots, infections, arthritis, cartilage problems, torn ligaments or
tendons, tumors in the brain, heart, or spine, and other cancers.
There are many reasons why an attacker would want to
alter medical imagery. Consider the following scenario: An
individual or state adversary wants to affect the outcome of
an election. To do so, the attacker adds cancer to a CT scan
performed on a political candidate (the appointment/referral
can be pre-existing, setup via social engineering, or part of
a lung cancer screening program). After learning of the cancer,
the candidate steps-down from his or her position. The same
scenario can be applied to existing leadership.
Another scenario to consider is that of ransomware: An
attacker seeks out monetary gain by holding the integrity
of the medical imagery hostage. The attacker achieves this
by altering a few scans and then by demanding payment for
revealing which scans have been affected.
Furthermore, consider the case of insurance fraud: Some-
body alters his or her own medical records in order to receive
money directly from his or her insurance company, or receive
handicap beneﬁts (e.g., lower taxes etc.) In this case, there is
no risk of physical injury to others, and the payout can be very
large. For example, one can (1) sign up for disability/life insur-
ance, then (2) fake a car accident or other incident, (3) complain
of an inability to work, sense, or sleep, then (4) add a small brain
hemorrhage or spinal fracture to his or her own scan during an
investigation (this evidence is very hard to refute), and then (5)
ﬁle a claim and receive cash from the insurance company.3
There are many more reasons why an attacker would want
to tamper with the imagery. For example: falsifying research
evidence, sabotaging another company’s research, job theft,
terrorism, assassination, and even murder.
Depending on the attacker’s goal, the attack may be either
untargeted or targeted:
Untargeted Attacks are where there is no speciﬁc target
patient. In this case, the attacker targets a victim who is
receiving a random voluntary cancer screening, is having
an annual scan (e.g., BRACA patients, smokers...), or is
being scanned due to an injury. These victims will either
have an ‘incidental ﬁnding’ when the radiologist reviews
the scan (injection) or are indeed sick but the evidence
won’t show (removal).
Targeted Attacks are where there is a speciﬁc target patient.
In these attacks, the patient may be lured to the hospital
for a scan. This can be accomplished by (1) adding
an appointment in the system, (2) crafting a cancer
screening invite, (3) spooﬁng the patient’s doctor, or (4)
tampering/appending the patient’s routine lab tests. For
3For example, see products such as AIG’s Quality of Life insurance.
462    28th USENIX Security Symposium
USENIX Association
    Goal (cid:3397) : (cid:3398) : (cid:3399) :  ● : ○ :    Add Evidence Remove Evidence Either  Target Effect Side Effect    Steal Job Position Affect Elections Remove Leader Sabotage Research Falsify Research Hold Data Hostage Insurance Fraud Murder Terrorize  Motivation Ideological   (cid:3397)     (cid:3399)Political  (cid:3397) (cid:3397)    (cid:3398) Money (cid:3397)  (cid:3397)(cid:3397)(cid:3398)(cid:3399)(cid:3397)  Fame/Attn. (cid:3397)  (cid:3397) (cid:3399)    Revenge (cid:3397)  (cid:3397)    (cid:3398)(cid:3397)Effect Physical Injury ○ ○ ○○○○●Death   ○●●Mental Trauma ○ ○ ○○○●Life Course ● ● ●○○○●Monetary Cause Loss ○  ○●○○●Payout ●  ○●●●Attack  Type Untargeted   XXXTargeted X X XXXXX example, high-PSA in blood indicates prostate cancer
leading to an abdominal MRI, high thyrotropin in blood
indicates a brain tumor leading to a head MRI, and
metanephrine in urine of hypertensive patients indicates
cancer/tumor leading to a chest/abdominal CT
In this paper we will focus on the injection and removal
of lung cancer from CT scans. Table 1 summarizes attacker’s
motivations, goals, and effects by doing so. The reason we
investigate this attack is because lung cancer is common
and has the highest mortality rate [11]. Therefore, due its
impact, an attacker is likely to manipulate lung cancer to
achieve his or her goal. We note that the threat, attack, and
countermeasures proposed in this paper also apply to MRIs
and medical conditions other than those listed above.
1.3 The Attack
With the help of machine learning, the domain of image
generation has advanced signiﬁcantly over the last ten
years [12]. In 2014, there was a breakthrough in the domain
when Goodfellow et al. [13] introduced a special kind of
deep neural network called a generative adversarial network
(GAN). GANs consist of two neural networks which work
against each other: the generator and the discriminator. The
generator creates fake samples with the aim of fooling the
discriminator, and the discriminator learns to differentiate
between real and fake samples. When applied to images, the
result of this game helps the generator create fake imagery
which are photo realistic. While GANs have been used for
positive tasks, researchers have also shown how they can be
used for malicious tasks such as malware obfuscation [14, 15]
and misinformation (e.g., deepfakes [16]).
In this paper, we show how an attacker can realistically
inject and remove medical conditions with 3D CT scans. The
framework, called CT-GAN, uses two conditional GANs
(cGAN) to perform in-painting (image completion) [17] on
3D imagery. For injection, a cGAN is trained on unhealthy
samples so that the generator will always complete the images
accordingly. Conversely, for removal, another cGAN is trained
on healthy samples only.
To make the process efﬁcient and the output anatomically
realistic, we perform the following steps: (1) locate where the
evidence should be inject/removed, (2) cut out a rectangular
cuboid from the location, (3) interpolate (scale) the cuboid, (4)
modify the cuboid with the cGAN, (5) rescale, and (6) paste
it back into the original scan. By dealing with a small portion
of the scan, the problem complexity is reduced by focusing
the GAN on the relevant area of the body (as opposed to the
entire CT). Moreover, the algorithm complexity is reduced
by processing fewer inputs4 (pixels) and concepts (anatomical
features). This results in fast execution and high anatomical
realism. The interpolation step is necessary because the scale
of a scan can be different between patients. To compensate for
the resulting interpolation blur, we mask the relevant content
4A 3D CT scan can have over 157 million pixels whereas the latest
advances in GANs can only handle about 2 million pixels (HD images).
according to water density in the tissue (Hounsﬁeld units) and
hide the smoothness by adding Gaussian white noise. In order
to assist the GAN in generating realistic features, histogram
equalization is performed on the input samples. We found that
this transformation helps the 3D convolutional neural networks
in the GAN learn how to generate the subtle features found
in the human body. The entire process is automated, meanings
that the attack can be deployed in an air gapped PACS.
To verify the threat of this attack, we trained CT-GAN
to inject/remove lung cancer and hired three radiologists to
diagnose a mix of 70 tampered and 30 authentic CT scans.
The radiologists diagnosed 99% of the injected patients with
malign cancer, and 94% of cancer removed patients as being
healthy. After informing the radiologists of the attack, they
still misdiagnosed 60% of those with injections, and 87% of
those with removals. In addition to the radiologists, we also
showed how CT-GAN is an effective adversarial machine
learning attack. We found that the state-of-the-art lung cancer
screening model misdiagnosed 100% of the tampered patients.
Thus, cancer screening tools, used by some radiologists, are
also vulnerable to this attack.
This attack is a concern because inﬁltration of healthcare
networks has become common [3], and internal network
security is often poor [18]. Moreover, for injection, the attacker
is still likely to succeed even if medical treatment is not
performed. This is because many goals rely on simply scaring
the patient enough to affect his/her daily/professional life. For
example, even if an immediate deletion surgery is not deemed
necessary based on the scan and lab results, there will still be
weekly/monthly follow-up scans to track the tumor’s growth.
This will affect the patient’s life given the uncertainty of his
or her future.
1.4 The Contribution
To the best of our knowledge, it has not been shown how an
attacker can maliciously alter the content of a 3D medical im-
age in a realistic and automated way. Therefore, this is the ﬁrst
comprehensive research which exposes, demonstrates, and ver-