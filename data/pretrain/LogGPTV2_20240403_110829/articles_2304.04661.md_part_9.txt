scalingpolicytoresizecontainers.[215]alsoleveragedneural consumption and then do resource provisioning or scheduling
networks (especially MLP) for workload prediction and com- based on the forecasting results. For instance, [223] uses ran-
pared this approach with traditional machine learning models, dom forest and XGBoost to predict VM behaviors including
e.g.,linearregressionandK-nearestneighbors.[216]applieda maximum deployment sizes and workloads. [224] proposes
bidirectionalLSTMtopredictthenumberofHTTPworkloads a linear regression based approach to predict the resource
and showed that Bi-LSTM works better than LSTM and utilization of the VMs based on their historical data, and then
ARIMA on the tested use cases. These approaches require leverage the prediction results to reduce energy consumption.
accurate forecasting results to avoid over- or under-allocated [225] applies gradient boosting models for temperature pre-
of resources, while it is hard to develop a robust forecasting- diction, based on which a dynamic scheduling algorithm is
based approach due to the existence of noises and sudden developed to minimize the peak temperature of hosts. [226]
spikes in user requests. proposes a RL-based workload-specific scheduling algorithm
Theothertypeisbasedonreinforcementlearning(RL)that to minimize average task completion time.
treats auto-scaling as an automatic control problem, whose TheaccuracyoftheMLmodelisthekeyfactorthataffects
goal is to learn an optimal auto-scaling policy for the best the efficiency of a resource management system. Applying
resource provision action under each observed state. [217] more sophisticated traditional ML models or even deep learn-
presentsanexhaustivesurveyonreinforcementlearning-based ing models to improve prediction accuracy is a promising
auto-scalingapproaches,andcomparesthembasedonasetof research direction. Besides accuracy, the time complexity of
proposed taxonomies. This survey is very worth reading for modelpredictionisanotherimportantfactorneededtobecon-
developers or researchers who are interested in this direction. sidered. If a ML model is over-complicated, it cannot handle
Although RL looks promising in auto-scaling, there are many real-time requests of resource allocation and scheduling. How
issuesneededtoberesolved.Forexample,model-basedmeth- to make a trade-off between accuracy and time complexity
odsrequireaperfectmodeloftheenvironmentandthelearned needs to be explored further.
policiescannotadapttothechangesintheenvironment,while
model-free methods have very poor initial performance and VIII. FUTUREOFAIOPS
slow convergence so that they will introduce high cost if they
are applied in real-world cloud platforms. A. Common AI Challenges for AIOps
We have discussed the challenges and future trends in each
C. Resource Management
task sections according to how to employ AI techniques. In
summary, there are some common challenges across different
Problem Definition AIOps tasks.
Resource management is another important topic in cloud Data Quality. For all AIOps task there are data quality
computing, which includes resource provisioning, allocation issues. Most real-world AIOps data are extremely imbalanced
and scheduling, e.g., workload estimation, task scheduling, duetothenaturethatincidentsonlyoccursoccasionally.Also,
energy optimization, etc. Even small provisioning inefficien- most of the real-world AIOps data are very noisy. Significant
cies, such as selecting the wrong resources for a task, can efforts are needed in data cleaning and pre-processing before
affect quality of service (QoS) and thus lead to significant it can be used as input to train ML models.
monetarycosts.Therefore,thegoalofresourcemanagementis Lack of Labels. It’s extremely difficult to acquire quality
toprovisiontherightamountofresourcesfortaskstoimprove labels sufficiently. We need a lot of domain experts who are
QoS, mitigate imbalance workloads, and avoid service level very familiar with system operations to evaluate incidents,
agreements violations. root-causesandservicegraphs,inordertoprovidehigh-quality
Because of multiple tenants sharing storage and computa- labels. This is extremely time consuming and require specific
tion resources on cloud platforms, resource management is expertise,whichcannotbehandledbygeneralcrowdsourcing
a difficult task that involves dynamically allocating resources approaches like Mechanical Turk.
23
Non-stationarity and heterogeneity. Systems are ever- Human-centric AIOps means human processes still play
changing.AIOpsarefacingnon-stationaryproblemspace.The criticalrolesintheentireAIOpseco-systems,andAImodules
AI models in this domain need to have mechanisms to deal help humans with better decisions and executions. While
with this non-stationary nature. Meanwhile, AIOps data are in Machine-centric mode, AIOps systems require minimum
heterogeneous, meaning the same telemetry data can have a human intervention and can be in human-free state for most
variety of underlying behaviors. For example, CPU utilization of its lifetime. AIOps systems continuously monitor the IT
pattern can be totally different when the resources are used to infrastructure, detecting and analysis issues, finding the right
host different applications. Thus, discovery the hidden states pathstodrivefixes.Inthisstage,engineersfocusprimarilyon
andhandleheterogeneityisveryimportantforAIOpssolutions development tasks rather than operations.
to succeed.
Lack of Public Benchmarking. Even though AIOps re- IX. CONCLUSION
search communities are growing rapidly, there are still very
Digital transformation creates tremendous needs for com-
limitednumberofpublicdatasetsforresearcherstobenchmark
putingresources.Thetrendboostsstronggrowthoflargescale
andevaluatetheirresults.Operationaldataarehighlysensitive.
IT infrastructure, such as cloud computing, edge computing,
Existing research are done either with simulated data or
searchengines,etc.SinceproposedbyGartnerin2016,AIOps
enterprise production data which can hardly be shared with
is emerging rapidly and now it draws the attention from large
other groups and organizations.
enterprisesandorganizations.AsthescaleofITinfrastructure
Human-in-the-loop.Humanfeedbackareveryimportantto
grows to a level where human operation cannot catch up,
build AIOps solutions. Currently most of the human feedback
AIOpsbecomestheonlypromisingsolutiontoguaranteehigh
are collected in ad-hoc fashion, which is inefficient. There
availability of these gigantic IT infrastructures. AIOps covers
are lack of human-in-the-loop studies in AIOps domain to
different stages of software lifecycles, including development,
automate feedback collection and utilize the feedback to
testing, deployment and maintenance.
improve model performance.
Different AI techniques are now applied in AIOps applica-
tions, including anomaly detection, root-cause analysis, fail-
B. Opportunities and Future Trends ure predictions, automated actions and resource management.
Our literature review of existing AIOps work shows cur- However, the entire AIOps industry is still in a very early
rent AIOps research still focuses more on infrastructure and stage where AI only plays supporting roles to help human
tooling. We see AI technologies being successfully applied conductingoperationworkflows.Weforeseethetrendshifting
in incident detection, RCA applications and some of the from human-centric Operations to AI-centric Operations in
solutions has been adopted by large distributed systems like the near future. During the shift, Development of AIOps
AWS, Alibaba cloud. While it is still in very early stages for techniques will also transit from build tools to create human-
AIOpsprocessstandardizationandfullautomation.Withthese free end-to-end solutions.
evidences, we can foresee the promising topics of AIOps in In this survey, we discovered that most of the current
the next few years. AIOps outcomes focus on detections and root cause analysis,
while research work on automations is still very limited. The
High Quality AIOps Infrastructure and Tooling AI techniques used in AIOps are mainly traditional machine
TherearesomesuccessfulAIOpsplatformsandtoolsbeing learning and statistical models.
developed in recent years. But still there are opportunities
where AI can help enhance the efficiency of IT operations. ACKNOWLEDGMENT
AI is also growing rapidly and new AI technologies are
We want to thank all participants who took the time to ac-
inventedandsuccessfullyappliedinotherdomains.Thedigital
complish this survey. Their knowledge and experiences about
transformation trend also brings challenges to traditional IT
AI fundamentals were invaluable to our study. We are also
operation and Devops. This creates tremendous needs for
grateful to our colleagues at the Salesforce AI Research Lab
highqualityAItooling,includingmonitoring,detection,RCA,
and collaborators from other organizations for their helpful
predictions and automations.
feedback and support.
AIOps Standardization
APPENDIXA
Whilebuildingtheinfrastructureandtooling,AIOpsexperts
TERMINOLOGY
also better understand the full picture of the entire domain.
AIOpsmodulescanbeidentifiedandextractedfromtraditional DevOps: Modern software development requires not only
processes to form its own standard. With clear goals and higher development quality but also higher operations quality.
measures, it becomes possible to standardize AIOps systems, DevOps, as a set of best practices that combines the devel-
just as what has been done in domains like recommendation opment (Dev) and operations (Ops) processes, is created to
systems or NLP. With such standardization, it will be much achieve high quality software development and after release
easier to experiment a large variety of AI techniques to management [3].
improve AIOps performance. Application Performance Monitoring (APM): Applica-
tion performance monitoring is the practice of tracking key
Human-centric to Machine-centric AIOps software application performance using monitoring software
24
and telemetry data[227]. APM is used to guarantee high
systemavailability,optimizeserviceperformanceandimprove
user experiences. Originally APM was mostly adopted in
websites, mobile apps and other similar online business appli-
cations. However, with more and more traditional softwares
transforming to leverage cloud based, highly distributed sys-
tems,APMisnowwidelyusedforalargervarietyofsoftware
applications and backends.
Observability: Observability is the ability to measure the
internal states of a system by examining its outputs [228]. A
system is “observable” if the current state can be estimated
by only using the information from outputs. Observability
data includes metrics, logs, traces and other system generated
information.
Cloud Intelligence: The artificial intelligent features that
improve cloud applications.
MLOps: MLOps stands for machine learning operations.
MLOps is the full process life cycle of deploying machine
learning models to production.
Site Reliability Engineering (SRE):Thetypeofengineer-
ing that bridge the gap between software development and
operations.
Cloud Computing: Cloud computing is a technique, and
a business model, that builds highly scalable distributed
computer systems and lends computing resources, e.g. hosts,
platforms,apps,totenantstogeneraterevenue.Therearethree
main category of cloud computing: infrastructure as a service
(IaaS), platform as a service (PaaS) and software as a service
(SaaS)
IT Service Management (ITSM): ITSM refers to all
processes and activities to design, create, deliver, and support
the IT services to customers.
IT Operations Management (ITOM): ITOM overlaps
withITSM,focusingmoreontheoperationsideofITservices
and infrastructures.
25
APPENDIXB
TABLES
TABLEI
TABLEOFPOPULARPUBLICDATASETSFORMETRICSOBSERVABILITY
Name Description Tasks
Azure Public These datasets contain a representative subset of first-party Workload characterization, VM Pre-provisioning, Workload
Dataset Azurevirtualmachineworkloadsfromageographicalregion. prediction
Google Cluster 30continuousdaysofinformationfromGoogleBorgcells. Workloadcharacterization,Workloadprediction
Data
Alibaba Cluster ClustertracesofrealproductionserversfromAlibabaGroup. Workloadcharacterization,Workloadprediction
Trace
MIT Combinationofhigh-leveldata(e.g.SlurmWorkloadManager Workloadcharacterization
Supercloud schedulerdata)andlow-leveljob-specifictimeseriesdata.
Dataset
Numenta AWS server metrics as collected by the AmazonCloudwatch Incidentdetection
Anomaly service. Example metrics include CPU Utilization, Network
Benchmark (re- BytesIn,andDiskReadBytes.
alAWSCloud-
watch)
YahooS5(A1) A1benchmarkcontainsrealYahoo!webtrafficmetrics. Incidentdetection