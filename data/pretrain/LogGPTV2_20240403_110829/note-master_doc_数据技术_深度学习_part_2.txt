可以通过不同的核函数来提取不同的特征
### 卷积神经网络
一个卷积神经网络的工作流程：
输入层将待处理的图像转化为一个或者多个像素矩阵，卷积层利用一个或多个卷积核从像素矩阵中提取特征，得到的特征映射经过非线性函数处理后被送入池化层，由池化层执行降维操作。卷积层和池化层的交替使用可以使卷积神经网络提取出不同层次上的图像特征。最后得到的特征作为全连接层的输入，由全连接层的分类器输出分类结果
![卷积网络的结构图](/assets/2024117155242.webp)
### 深度信念网络
一种概率生成模型，能够建立输入数据和输出类别的联合概率分布
深度信念网络可以看成由若干简单的学习单元构成的整体，而构成它的基本单元就是受限玻尔兹曼机，受限玻尔兹曼机的模型非常简单，就是一个两层的神经网络，包括一个可见层和一个隐藏层
### 感知机模型
一种二分类的监督学习算法，能够决定由向量表示的输入是否属于某个特定类别
1. 初始化权重 $w(0)$ 和阈值，其中权重可以初始化为 0 或较小的随机数
2. 对训练集中的第 $j$ 个样本，将其输入向量 $x_j$​ 送入已初始化的感知器，得到输出 $y_j(t)$
3. 根据 $y_j​(t)$ 和样本 $j$ 的给定输出结果 $d_j$​，按以下规则更新权重向量
$$
w_i(t+1)=w_i(t)+\eta[d_j-y_j(t)]\cdot x_{j,i}
$$
即找出合适的 $W$ 使得训练样本的预测值与实际值的差别最小
感知机以所有误分类点到超平面的总距离作为损失函数，用随机梯度下降法不断使损失函数下降，直到得到正确的分类结果
![感知器的学习过程](/assets/2024117191239.webp)
### 径向基神经网络
包含三层：一个输入层、一个隐藏层和一个输出层。其中隐藏层是径向基网络的核心结构
每个隐藏神经元都选择径向基函数作为传递函数
训练过程：
1. 通过一些方法选择隐藏层中的中心点。常见的方法包括使用样本数据的子集或者通过聚类算法确定中心点
2. 对于每个径向基函数，需要确定其宽度参数，决定了径向基函数在输入空间中的影响范围
3.  对于每个样本，计算其与每个中心点的距离，并将距离作为径向基函数的输入，得到隐藏层的输出
4.  输出层训练：使用类似于其他神经网络的方法，通过反向传播算法来调整输出层的权重，以最小化训练误差
### 自组织特征映射
能够将高维的输入数据映射到低维空间之上（通常是二维空间），采用的是竞争性学习
自组织映射的结构是，一张一维或者二维的网格，网格中的每个节点都代表一个神经元，神经元的权重系数则是和输入数据的维度相同的向量，距离较近的神经元能够处理模式相似的数据，训练过程就是在空间上对神经元进行有序排列的过程
### 模糊神经网络
将常规的神经网络赋予模糊输入信号和模糊权值，其作用在于利用神经网络结构来实现模糊逻辑推理
构成模糊神经网络的基本单元是模糊化的神经元。模糊神经元的输入信号和权重系数都是模糊数，传递函数也需要对模糊集合上的加权结果进行处理，模糊数就是只有取值范围而没有精确数值的数
为了训练网络，如果保持学习率参数不变，误差函数就难以快速收敛。即使收敛也可能陷入局部最小值上，在不同的学习率参数下得到不同的局部最小值。为了处理这个问题，模糊神经网络引入了一种叫做共轭梯度（conjugate gradient）的机制
### 循环神经网络
引入了时间的维度，因而适用于处理时间序列类型的数据
$$
\mathbf{h}_t=f(\mathbf{W}\mathbf{x}_t+\mathbf{U}\mathbf{h}_{t-1})
$$
当前时刻的状态与先前的状态有关
普通的循环神经网络中，记忆只会涉及到过去的状态。如果想让循环神经网络利用来自未来的信息，就要让当前的状态和以后时刻的状态同样建立起联系，得到的就是双向循环神经网络
### 递归神经网络
循环神经网络的特点是在时间维度上共享参数，从而展开处理序列。如果换一种展开方式，将序列数据展开成树状结构，用到的就是递归神经网络
### 生成式对抗网络
- 生成器（generator）：从随机噪声中模拟真实数据样本的潜在分布
- 判别器（discriminator）：判断输入是真实数据还是模拟的数据
对网络的训练就是让判别器区分真实数据和伪造数据的准确率最大化，让生成器生成的数据被判别器发现的概率最小化
$$
\arg\min_g\max_D-\dfrac12\int_x[p_{aata}(x)\log(D(x))+p_g(x)\log(1-D(x))]\mathrm{d}x
$$
### 长短期记忆网络
长短期记忆的基本单元的作用在需要时取出并聚焦记忆，通常包括四个功能不同的隐藏层：记忆模块（memory cell）、输入门（input gate）、输出门（output gate）和遗忘门（forget gate）
首先，遗忘门根据当前输入和前一步隐藏状态，决定哪些信息要从细胞状态中遗忘。
然后，输入门根据当前输入和前一步隐藏状态，确定更新细胞状态的新信息，并结合遗忘门的结果更新细胞状态。
最后，输出门根据当前的细胞状态和输入，计算并输出当前时刻的隐藏状态
## 表示学习
学习数据的有用特征，使得这些特征能够更好地捕捉数据的结构和模式