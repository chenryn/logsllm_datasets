### ZAFL vs. AFL-Dyninst and AFL-QEMU: Real-World Software Evaluation

#### 7.3.1 Benchmarks
To evaluate the performance of ZAFL on real-world software, we selected eight diverse binaries that have been previously used in fuzzing literature: `bsdtar`, `cert-basic`, `clean_text`, `jasper`, `readelf`, `sfconvert`, `tcpdump`, and `unrtf`. We intentionally chose older versions known to contain bugs detectable by AFL, to facilitate a clear bug-finding comparison. Detailed statistics for each binary (e.g., package, size, number of basic blocks) are provided in Table 8.

#### 7.3.2 Experimental Setup and Infrastructure
For both crash-finding and overhead experiments, we configured the instrumenters and binaries as described in § 7.1 and § 7.2.1. We used either AFL-provided or developer-provided seed inputs for the fuzzing evaluations. For crash-finding, we conducted 8 trials of 24 hours each on a cluster. For overhead evaluation, we performed 5 trials of 24 hours each using our LAVA-M experiment infrastructure (§ 7.2.2).

#### 7.3.3 Real-World Crash-Finding
We applied all ZAFL-implemented transformations (Table 3) to the eight binaries, except for `clean_text` where context sensitivity was omitted due to its high coverage map consumption. Triage was based on stack hashing, as seen in the literature [52, 57, 66]. Table 5 summarizes the crash-finding results and the total/queued test cases relative to AFL-Dyninst and AFL-QEMU. Geometric mean Mann-Whitney U significance test p-values across all metrics are also reported.

**ZAFL vs. AFL-Dyninst:**
- ZAFL averaged 26% more real-world crashes and 48% more test cases than AFL-Dyninst over 24 hours.
- On `bsdtar` and `tcpdump`, ZAFL found 10-20% fewer crashes, but the raw differences were only 1-2 crashes, indicating convergence on these benchmarks.
- For `readelf`, triage revealed two unique crashes, both found by all three instrumenters.
- Overall, ZAFL showed a 61% increase in crashes, with statistically significant Mann-Whitney U p-values (0.001-0.018).

**ZAFL vs. AFL-QEMU:**
- ZAFL surpassed AFL-QEMU's LAVA-M crash-finding by 42% and real-world crash-finding by 131%.
- Apart from the two `readelf` bugs, ZAFL's program transformations and 159% higher execution rate allowed it to find more crash-triggering paths.
- The Mann-Whitney U p-values (0.001-0.002) confirmed the statistical significance of ZAFL's increased effectiveness.
- The disparity between AFL-QEMU's LAVA-M and real-world crash-finding suggests that complex binaries benefit more from powerful binary rewriters.

#### 7.3.4 Real-World Coverage-Tracing Overhead
For the coverage-tracing overhead evaluation, we followed established practices [62]:
- Collected 5 sets of 24-hour test case dumps per benchmark.
- Instrumented a forkserver-only "baseline" version of each benchmark.
- Logged the coverage-tracing time for each test case.
- Applied 30% trimmed-mean de-noising on execution times.
- Scaled the results to baseline.

**Comparison with Compiler Instrumentation:**
- ZAFL incurred a baseline overhead of 5% for adding rewriting support.
- Tracing all code coverage increased overhead to 32%, which was reduced to 20% with graph analysis.
- Applying all fuzzing-enhancing program transformations brought the overhead back up to 27%.
- These overheads are similar to AFL's compiler-based instrumentation (24%) and slightly better than assembler-based trampolining (34%).
- Mann-Whitney U p-values (0.12-0.18) indicated that ZAFL's performance is indistinguishable from compiler-level performance.

### 7.4 Fuzzing Closed-Source Binaries

#### 7.4.1 Benchmarks
To evaluate ZAFL's performance on closed-source binaries, we selected five diverse, command-line interfacing benchmarks: `idat64` from IDA Pro, `nconvert` from XNView’s NConvert, `nvdisasm` from NVIDIA’s CUDA Utilities, `pngout` from Ken Silverman’s PNGOUT, and `unrar` from RarLab’s RAR. Key features of each benchmark are listed in Table 9.

#### 7.4.2 Closed-Source Crash-Finding
We repeated the evaluation from § 7.3.3, running five 24-hour experiments per configuration. Results (mean unique triaged crashes, total and queued test cases, and MWU p-scores) are shown in Table 6, and plots of unique triaged crashes over time are in Figure 5.

**ZAFL vs. AFL-Dyninst:**
- Despite AFL-Dyninst being faster on `idat64`, `nconvert`, `nvdisasm`, and `unrar`, ZAFL achieved a statistically significant 55% higher crash-finding rate (mean MWU p-value of 0.036).
- AFL-Dyninst's speed and small queues, along with the lack of crashes in `unrar`, suggest it missed significant parts of these binaries.

**ZAFL vs. AFL-QEMU:**
- ZAFL averaged 38% more triaged crashes and 52% more test cases than AFL-QEMU.
- Statistically significant improvements were observed for four benchmarks (mean MWU p-value of 0.021).
- ZAFL's initial speed on `nvdisasm` was over 2× that of AFL-QEMU, but it fluctuated around 5 execs/s during the campaign.
- ZAFL successfully uncovered a heap overread crash in `idat64`, while AFL-QEMU found nothing.

#### 7.4.3 Bug-Finding Case Study
We conducted additional manual triage with binary-level memory error checkers (e.g., QASan [30] and Dr. Memory [16]) to compare the time-to-discovery (TTD) for five closed-source binary bugs found by ZAFL, AFL-Dyninst, or AFL-QEMU:
- A heap overflow in `nconvert`.
- A stack overflow in `unrar`.
- A heap use-after-free and heap overflow in `pngout`.
- A heap overread in `idat64`'s `libida64.so`.

Table 7 reports the geometric mean TTD for all five bugs. ZAFL found these bugs 660% faster than AFL-Dyninst and 113% faster than AFL-QEMU, highlighting its balance of transformation quality and performance in closed-source code.

| Location | Error Type | ZAFL Mean Rel. Decrease |
|----------|------------|-------------------------|
| `nconvert` | Heap overflow | -660% |
| `unrar` | Stack overflow | -660% |
| `pngout` | Heap overflow | -660% |
| `pngout` | Use-after-free | -660% |
| `libida64.so` | Heap overread | -113% |

This comprehensive evaluation demonstrates that ZAFL provides a significant advantage in both open-source and closed-source binary fuzzing, achieving better crash-finding and performance compared to existing tools.