k-concealment
NH
Greedy
SortGreedy
Hungarian
20
40
60
80 100 120 140
k
(b) GCP vs. k, 10K tuples
Figure 8: Effect of k
k-concealment
NH
Greedy
SortGreedy
Hungarian
3
4
5
d
6
7
8
(b) Difference Quotient, k = 30
)
d
(
P
C
G
t
n
e
i
t
o
u
q
e
c
n
e
r
e
f
f
i
d
0.06
0.05
0.04
0.03
0.02
0.01
0
k-concealment
NH
Greedy
SortGreedy
Hungarian
3
4
5
d
6
7
8
(e) Difference Quotient, k = 50
1e+05
10000
1000
100
10
1
0.1
)
c
e
s
(
e
m
T
i
)
c
e
s
(
e
m
T
i
)
c
e
s
(
e
m
T
i
1e+05
10000
1000
100
10
1
0.1
0.01
1e+05
10000
1000
100
10
1
0.1
0.01
k-concealment
NH
Greedy
SortGreedy
Hungarian
20
40
60
80 100 120 140
k
(c) time vs. k, 10K tuples
k-concealment
NH
Greedy
SortGreedy
Hungarian
2
3
4
6
7
8
5
d
(c) time, k = 30
k-concealment
NH
Greedy
SortGreedy
Hungarian
2
3
4
6
7
8
5
d
(f) time, k = 50
Figure 9: Effect of dimensionality
large k. In terms of runtime, our techniques scale equally well as
NH with k, while k−c exhibits unstable behavior (Figure 8(c)).
We reiterate that paying some extra runtime is worthwhile for the
sake of data utility, given that anonymization is an one-off process.
The performance of minCostFlow on the 1k data reconﬁrms that
optimizing a non-GCP objective function is not a viable approach.
Thus, we omit minCostFlow from subsequent experiments.
8.4 Effect of Dimensionality
Next, we study the effect of dimensionality on each of the com-
peting techniques. We select the ﬁrst 10K tuples from the CENSUS
data set, and examine the performance of our algorithms as a func-
tion of the number of selected attributes d, letting d range from 2
to 8, and setting k = 30 and k = 50. Figure 9 shows the re-
sults. We observe that, not only do our three algorithms achieve
better GCP than the competing NH and k−c methods, but they
also present better resistance to the curse of dimensionality; the
GCP they achieve does not deteriorate as severely as that of the
other two methods as d grows. To make this effect more visible,
we measure the difference quotient (i.e., the slope) of the GCP as
a function of d, GCP (d)−GCP (2)
. The middle column in Figure 9
presents our results. Remarkably, k−c has the worst behavior with
d−2
respect to growing dimensionality, with NH coming second worst.
On the other hand, our three algorithms exhibit much better dimen-
sionality robustness, with SortGreedy and Hungarian being con-
sistently the best performers. We also present runtime results for
this experiment in the third column of Figure 9 in logarithmic time
axes. As before, the runtime of our three methods falls between
those of NH and k−c. Still, all algorithms scale equally well with
growing dimensionality.
8.5 Effect of Size
Last, we investigate the scalability of the compared algorithms
as the data set size grows. We obtain data sets of exponentially
growing size, ranging from 1k to 64k tuples, from the CENSUS
data set, with full dimensionality d = 8. We present GCP and run-
time results in Figure 10, for k values set at k = 15 and k = 50,
using logarithmic scales for all size and time axes. The GCP
results present a familiar pattern. Remarkably, our methods con-
sistently outperform NH and k−c, with SortGreedy approaching
Hungarian. Concerning the two methods we compare against, it
is interesting to note that k−c achieves better GCP than NH for
small k. This ﬁnding is consistent with the results in Figure 8.
The runtime results show that our two greedy methods, Greedy and
0.16
0.14
0.12
P
C
G
0.1
0.08
0.06
0.04
0.02
k-concealment
NH
Greedy
SortGreedy
Hungarian
0.3
0.25
P
C
G
0.2
0.15
k-concealment
NH
Greedy
SortGreedy
Hungarian
1k
4k
16k
64k
dataset size (# of tuples)
(b) GCP vs. size, k = 50
Figure 10: Effect of size
)
c
e
s
(
e
m
T
i
1e+06
1e+05
10000
1000
100
10
1
0.1
0.01
k-concealment
NH
Greedy
SortGreedy
Hungarian
1k
4k
16k
64k
dataset size (# of tuples)
(c) time vs. size, k = 50
[7] J. Cao, P. Karras, P. Kalnis, and K.-L. Tan. SABRE: a Sensitive
Attribute Bucketization and REdistribution framework for
t-closeness. The VLDB Journal, 20(1):59–81, 2011.
[8] R. Chaytor and K. Wang. Small domain randomization: Same
privacy, more utility. PVLDB, 3(1):608–618, 2010.
[9] K. Choromanski, T. Jebara, and K. Tang. Adaptive anonymity via
b-matching. In NIPS, pages 3192–3200, 2013.
[10] C. Clifton and T. Tassa. On syntactic anonymity and differential
privacy. In PrivDB, 2013.
[11] G. Cormode, N. Li, T. Li, and D. Srivastava. Minimizing minimality
and maximizing utility: Analyzing method-based attacks on
anonymized data. PVLDB, 3(1):1045–1056, 2010.
[12] C. Dwork. Differential privacy. In ICALP (2), 2006.
[13] J. Edmonds and R. M. Karp. Theoretical improvements in
algorithmic efﬁciency for network ﬂow problems. J. of the ACM,
19(2):248–264, 1972.
[14] G. Ghinita, P. Karras, P. Kalnis, and N. Mamoulis. Fast data
anonymization with low information loss. In VLDB, 2007.
[15] G. Ghinita, P. Karras, P. Kalnis, and N. Mamoulis. A framework for
efﬁcient data anonymization under privacy and accuracy constraints.
ACM TODS, 34(2):1–47, 2009.
[16] A. Gionis, A. Mazza, and T. Tassa. k-anonymization revisited. In
ICDE, 2008.
[17] A. Korolova. Privacy violations using microtargeted ads: A case
study. In ICDM Workshops, 2010.
[18] H. W. Kuhn. The hungarian method for the assignment problem.
Naval Research Logistics Quarterly, 2(1–2):83–97, 1955.
[19] K. LeFevre, D. J. DeWitt, and R. Ramakrishnan. Workload-aware
anonymization techniques for large-scale datasets. ACM TODS,
33(3):17:1–17:47, 2008.
[20] N. Li, T. Li, and S. Venkatasubramanian. Closeness: A new privacy
measure for data publishing. IEEE TKDE, 22(7):943–956, 2010.
[21] N. Li, W. H. Qardaji, and D. Su. On sampling, anonymization, and
differential privacy or, k-anonymization meets differential privacy. In
ASIACCS, 2012.
[22] T. Li and N. Li. On the tradeoff between privacy and utility in data
publishing. In KDD, 2009.
[23] A. Machanavajjhala, D. Kifer, J. Gehrke, and
M. Venkitasubramaniam. (cid:2)-diversity: Privacy beyond k-anonymity.
ACM TKDD, 1(1):3, 2007.
[24] P. Samarati. Protecting respondents’ identities in microdata release.
IEEE TKDE, 13(6):1010–1027, 2001.
[25] T. Tassa, A. Mazza, and A. Gionis. k-concealment: An alternative
model of k-type anonymity. Transactions on Data Privacy,
5(1):189–222, 2012.
[26] N. Tomizawa. On some techniques useful for solution of
transportation network problems. Networks, 1:173–194, 1971.
[27] R. Wacks. Privacy. A very short introduction, volume 221 of Very
short introductions. Oxford University Press, 2010.
[28] W. K. Wong, N. Mamoulis, and D. W. L. Cheung. Non-homogeneous
generalization in privacy preserving data publishing. In SIGMOD,
2010.
[29] M. Xue, P. Karras, C. Raïssi, J. Vaidya, and K.-L. Tan. Anonymizing
set-valued data by nonreciprocal recoding. In KDD, 2012.
0.1
0.05
64k
1k
4k
16k
dataset size (# of tuples)
(a) GCP vs. size, k = 15
SortGreedy are similarly scalable as k−c, as is expected theoreti-
cally. While NH has the same quadratic complexity as those three,
its default version which we are running does not actually run the
algorithm on the complete data set, but only on partitions thereof.
As we saw in Section 8.1, our algorithms have an efﬁciency advan-
tage when given the beneﬁts of data partitioning and parallelism.
9. CONCLUSIONS
This paper casts new light on the k-anonymity privacy model,
which remains a prerequisite for more advanced models as well as
a useful device in its own right. We treat k-anonymization as a
network ﬂow problem, aiming to minimize the information lost by
value generalization. While previous works suggested the graph
analogy, they either imposed superﬂuous constraints, or employed
value suppression, compromising data utility in both cases. We
devise solutions for the most general form of the problem, achiev-
ing signiﬁcantly lower information loss. Conceived in this manner,
the problem amounts to building a k-regular bipartite graph that
deﬁnes an anonymization of high utility. We model an optimal so-
lution using Mixed Integer Programming. Furthermore, we devise
a greedy algorithm having the same O(kn2) time complexity as
more restrictive previous solutions, an O(kn2 log n) enhancement
thereof, and an O(kn3) solution based on the Hungarian algorithm.
Our techniques provide the same privacy guarantee as previous
research on k-anonymity, as well as security against adversaries
reverse-engineering the algorithm. Our experimental study shows
that our algorithms achieve near-optimal utility and reliably out-
perform previous work, while their advantage is enhanced as the
data dimensionality grows. We show this advantage applies also
in terms of time efﬁciency when working in a parallel processing
environment, after we divide a large data set into partitions.
Acknowledgments
We thank Wai Kit Wong and Arnon Mazza, who shared the codes
for NH and k-concealment, respectively, as well as Aristides Gionis
and Jonathan Eckstein for fruitful discussions on this topic.
10. REFERENCES
[1] http://www.ipums.org.
[2] C. C. Aggarwal. On k-anonymity and the curse of dimensionality. In
VLDB, 2005.
[3] R. K. Ahuja, T. L. Magnanti, and J. B. Orlin. Network Flows:
Theory, Algorithms, and Applications. Prentice Hall, 1993.
[4] R. E. Bixby, M. Fenelon, Z. Gu, E. Rothberg, and R. Wunderling.
Mixed-integer programming: A progress report. In M. Grötschel,
editor, The Sharpest Cut, chapter 18, pages 309–325. 2004.
[5] J. Brickell and V. Shmatikov. The cost of privacy: destruction of
data-mining utility in anonymized data publishing. In KDD, 2008.
[6] J. Cao and P. Karras. Publishing microdata with a robust privacy
guarantee. PVLDB, 5(11):1388–1399, 2012.