Certainly! Here is the optimized version of your text, with improved clarity, coherence, and professionalism:

---

**Exception Handling and Memory Errors**

Exception handling can be employed to detect and resolve potential memory errors. Our findings indicate that filtering exceptions before handling them can effectively limit the risks associated with specific exception handlers. Even applications that heavily rely on exception handling do not necessarily contain a memory oracle if proper filtering is implemented. However, we also observed multiple instances of catch-all filters or filters with broad criteria. Some of these were combined with memory dereferences outside the protected code area, which typically indicates an improperly configured handler that should not cover access violations but does so due to overly broad filtering.

Another observation is that exception handling is more prevalent in client applications on Windows compared to server applications on Linux. This difference can be attributed to the distinct methods used by these operating systems to report memory faults. Linux employs the signal model, requiring a global signal handler to catch the corresponding signals [4], whereas Windows supports Structured Exception Handling (SEH), which provides a convenient way to protect specific code blocks.

**Potential Countermeasures**

Depending on the system and application, various countermeasures can be implemented. We outline some possible defenses, ranging from system redesigns to ad-hoc fixes in either the application or the system itself.

**System Design Changes**

Completely eliminating memory oracles would likely require fundamental changes to both programs and the underlying operating systems. Most of these countermeasures reduce the feature set provided to user-space programs, necessitating a balance between functionality loss and security gain. Given a mechanism to recover from access violations or query the state of memory addresses (directly or indirectly), an attacker can construct crash-resistant primitives and bypass information hiding defenses. Therefore, we propose the following properties:

- Any access violation should be critical for the application and lead to its termination.
- Exception handling should be limited to program-level exceptions (e.g., C++ exceptions) and not system-level exceptions (e.g., access violations).
- Error reporting and data collection should be possible, but care must be taken to prevent resuming normal execution.
- System APIs and system calls must terminate the offending application on a memory error as if the application received the fault.
- Exception masking should not be possible; any fault, regardless of the call stack, should terminate the process.
- Facilities to infer the memory layout, such as information in `/proc` or `VirtualQuery`, should be removed to prevent probing.
- Allocation functions that allow specifying the desired address should be removed.
- The memory layout of restarting processes should not persist between restarts.

**Improving Exception Filtering**

A less general approach would be to narrow the exceptions caught by specific exception handlers. This usually means that exception filters should accept only the minimal necessary set of exception codes. While some handlers may need to catch access violations, their widespread use is questionable. In addition to hardening the exception handling in applications, system-level oracles must also be addressed. For example, treating a memory error within the system API or system call the same as any error in the application would mean that instead of silently discarding the exception or catching it and setting the appropriate error state, the application would need to explicitly employ exception handling around these functions. This reduces the opportunities for an attacker to abuse such functionality, provided the application ensures no invalid pointer is passed to this API during normal operation.

**Restricting Access Violations**

Another, more compatible approach, is to allow handling and resuming of expected access violations only. There are two common reasons for a memory access to fail: (i) there is no mapped memory at the given address, or (ii) the permissions of the memory do not allow the intended access. The first case almost always results from a miscalculation or an exploit attempt and should be considered abnormal behavior. The application tried to access memory that it has not previously allocated, and the operating system did not allocate it for the process, so there should be no references to this memory region. This is different from the second case, where the address itself is valid—there is allocated memory at the specified location, but its permissions do not match the requested access.

Generating a fault based on permissions can be intentional, as seen in Firefox [22], where the application explicitly allocates a region of memory but marks it as inaccessible. The program expects an access violation to occur under certain known circumstances. Thus, it can be viable to allow handling only those access violations that occur at mapped memory. This is similar to the method described by Gawlik et al. for removing the scanning primitive from Firefox, but we propose employing this policy at the system level. This means any memory access to an unmapped page causes an unrecoverable error without invoking any exception handler in the faulting process. This can be simulated by the application itself by performing checks on the supplied exception information and terminating in the case of an unmapped access. Using this approach would still allow optimizations as used in Firefox, but scanning attempts would be detected at the first unmapped region encountered. While not providing as much security as a hard policy concerning memory errors, it significantly reduces the likelihood of successful guessing, thereby maintaining the security guarantees of information hiding.

**Rate-Based Detection**

An orthogonal defense is a simple anomaly detection that analyzes the number of access violations. This is similar to detecting crashes in server applications to identify BROP attacks [29]. With some applications using expected access violations for performance optimizations, we established a baseline of how many such faults are generated during normal usage. A well-known instance of this design choice is found in the Firefox web browser, so we used this program to test our theory. We added logging code to report any fault caught and handled in the browser. Using this modified version, we crawled the top 40,000 websites according to Alexa [1] and logged any occurrence. Our tests showed that none of these websites exhibited an access violation when accessed. Additionally, we tested the corner case of using asm.js-heavy websites in the form of a dedicated asm.js benchmark [3]. This tool represents a stress test as it always forces native code generation and applies some optimizations, one of which is the use of faults to catch out-of-bound accesses. While we observed access violations, they were far less frequent than during a probing attack, with multiple thousands per second. The benchmark triggered faults in groups of up to 20 in short succession, but the overall rate was much lower, with breaks between the groups. Even if we interpret the peak rate as our baseline, the faults caused by actual scanning attempts are several orders of magnitude more frequent. Therefore, we conclude that the rate of access violations can provide a viable heuristic for a defense. Even if an attacker tries to circumvent detection by performing a much slower scan, the duration will likely be too high to be practical.

**Conclusion**

In this paper, we demonstrated that crash-resistant primitives are not unique oddities. We showed that memory oracles exhibit specific properties that can be used to locate them in real-world applications. We developed tools that facilitate the discovery of these code locations even in complex, closed-source programs. Once located, these primitives can be used by attackers as demonstrated by previous work [22]. Our results also show that not only client programs are threatened by crash resistance; even servers can exhibit not only crash-tolerant behavior but are also susceptible to this new kind of vulnerability. Overall, our results demonstrate that locating a crash-resistant primitive is no longer left to chance but poses a threat to defenses that rely on information hiding in any kind of application.

**Acknowledgements**

We thank the anonymous reviewers for their valuable comments. This work was supported by the European Commission through the projects H2020 ICT-32-2014 “SHARCS” under Grant Agreement No. 644571, H2020 MSCA-RISE-2015 “PROTASIS” under Grant Agreement No. 690972, and ERC Starting Grant No. 640110 “BASTION,” and by the Netherlands Organisation for Scientific Research through the NWO 639.023.309 VICI “Dowsing” project.

**References**

[1] Alexa - Actionable Analytics for the Web. http://www.alexa.com/.
[2] BrowserBench. http://browserbench.org/.
[3] MASSIVE - the asm.js benchmark. https://kripken.github.io/Massive/.
[4] WineHQ - Structured Exception Handling. https://www.winehq.org/docs/winedev-guide/seh.
[5] ERRNO(3) Linux Programmer’s Manual. Linux Manual Page, 2016.
[6] SIGNAL(7) Linux Programmer’s Manual. Linux Manual Page, 2016.
[7] P. Akritidis, M. Costa, M. Castro, and S. Hand. Baggy bounds checking: An efficient and backwards-compatible defense against out-of-bounds errors. In USENIX Security Symposium, 2009.
[8] M. Backes, T. Holz, B. Kollenda, P. Koppe, S. Nürnberger, and J. Pewny. You can run but you can’t read: Preventing disclosure exploits in executable code. In ACM Conference on Computer and Communications Security (CCS), 2014.
[9] M. Backes and S. Nürnberger. Oxymoron: Making fine-grained memory randomization practical by allowing code sharing. In USENIX Security Symposium, 2014.
[10] P. Betts. The case of the disappearing OnLoad exception. http://blog.paulbetts.org/index.php/2010/07/20/the-case-of-the-disappearing-onload-exception-user-mode-callback-exceptions-in-x64/.
[11] S. Bhatkar, D. C. DuVarney, and R. Sekar. Efficient techniques for comprehensive protection from memory error exploits. In USENIX Security Symposium, 2005.
[12] D. Bigelow, T. Hobson, R. Rudd, W. Streilein, and H. Okhravi. Timely rerandomization for mitigating memory disclosures. In ACM SIGSAC Conference on Computer and Communications Security, 2015.
[13] A. Bittau, A. Belay, A. Mashtizadeh, D. Mazieres, and D. Boneh. Hacking blind. In IEEE Symposium on Security and Privacy, 2014.
[14] N. Carlini, A. Barresi, M. Payer, D. Wagner, and T. R. Gross. Control-flow bending: On the effectiveness of control-flow integrity. In USENIX Security Symposium, 2015.
[15] S. Crane, C. Liebchen, A. Homescu, L. Davi, P. Larsen, A.-R. Sadeghi, S. Brunthaler, and M. Franz. Readactor: Practical code randomization resilient to memory disclosure. In IEEE Symposium on Security and Privacy, 2015.
[16] S. Crane, S. Volckaert, F. Schuster, C. Liebchen, P. Larsen, L. Davi, A.-R. Sadeghi, T. Holz, B. D. Sutter, and M. Franz. It’s a TRAP: Table Randomization and Protection against Function Reuse Attacks. In ACM Conference on Computer and Communications Security (CCS), 2015.
[17] T. H. Dang, P. Maniatis, and D. Wagner. The performance cost of shadow stacks and stack canaries. In ACM Symposium on Information, Computer and Communications Security (ASIACCS), 2015.
[18] L. Davi, C. Liebchen, A.-R. Sadeghi, K. Z. Snow, and F. Monrose. Isomeron: Code randomization resilient to (just-in-time) return-oriented programming. In Symposium on Network and Distributed System Security (NDSS), 2015.
[19] DynamoRIO contributors. DynamoRIO Dynamic Instrumentation Tool Platform. http://www.dynamorio.org/.
[20] U. Erlingsson, M. Abadi, M. Vrable, M. Budiu, and G. C. Necula. XFI: Software guards for system address spaces. In Symposium on Operating Systems Design and Implementation (OSDI), 2006.
[21] I. Evans, S. Fingeret, J. González, U. Otgonbaatar, T. Tang, H. Shrobe, S. Sidiroglou-Douskos, M. Rinard, and H. Okhravi. Missing the point (er): On the effectiveness of code pointer integrity. In IEEE Symposium on Security and Privacy, 2015.
[22] R. Gawlik, B. Kollenda, P. Koppe, B. Garmany, and T. Holz. Enabling client-side crash-resistance to overcome diversification and information hiding. In Symposium on Network and Distributed System Security (NDSS), 2016.
[23] J. Gionta, W. Enck, and P. Ning. HideM: Protecting the contents of userspace memory in the face of disclosure vulnerabilities. In ACM Conference on Data and Application Security and Privacy, 2015.
[24] E. Göktas, R. Gawlik, B. Kollenda, E. Athanasopoulos, G. Portokalidis, C. Giuffrida, and H. Bos. Undermining information hiding (and what to do about it). In USENIX Security Symposium, 2016.
[25] V. P. Kemerlis, G. Portokalidis, K. Jee, and A. D. Keromytis. libdft: Practical dynamic data flow tracking for commodity systems. In ACM SIGPLAN Notices, 2012.
[26] C. Kil, J. Jim, C. Bookholt, J. Xu, and P. Ning. Address space layout permutation (ASLP): Towards fine-grained randomization of commodity software. In Annual Computer Security Applications Conference (ACSAC), 2006.
[27] B. Kollenda, E. Göktas, T. Blazytko, P. Koppe, R. Gawlik, R. Konoth, C. Giuffrida, H. Bos, and T. Holz. Towards Automated Discovery of Crash-Resistant Primitives in Binary Executables. Technical report, Ruhr-University Bochum, 2016.
[28] V. Kuznetsov, L. Szekeres, M. Payer, G. Candea, R. Sekar, and D. Song. Code-pointer integrity. In Symposium on Operating Systems Design and Implementation (OSDI), 2014.
[29] V. Kuznetsov, L. Szekeres, M. Payer, G. Candea, and D. Song. Poster: Getting the point(er): On the feasibility of attacks on code-pointer integrity. In IEEE Symposium on Security and Privacy, 2015.
[30] K. Lu, S. Nürnberger, M. Backes, and W. Lee. How to make ASLR win the clone wars: Runtime re-randomization. In Symposium on Network and Distributed System Security (NDSS), 2016.
[31] K. Lu, C. Song, B. Lee, S. P. Chung, T. Kim, and W. Lee. ASLR-guard: Stopping address space leakage for code reuse attacks. In ACM Conference on Computer and Communications Security (CCS), 2015.
[32] Microsoft Research. The Z3 Theorem Prover. https://github.com/Z3Prover/z3.
[33] V. Mohan, P. Larsen, S. Brunthaler, K. W. Hamlen, and M. Franz. Opaque Control-Flow Integrity. In Symposium on Network and Distributed System Security (NDSS), 2015.
[34] S. Nagarakatte, J. Zhao, M. M. Martin, and S. Zdancewic. SoftBound: Highly compatible and complete spatial memory safety for C. In ACM SIGPLAN Workshop on Programming Languages and Analysis for Security (PLAS), 2009.
[35] A. Oikonomopoulos, E. Athanasopoulos, H. Bos, and C. Giuffrida. Poking holes in information hiding. In USENIX Security Symposium, 2016.
[36] M. Pietrek. A crash course on the depths of win32 structured exception handling. Microsoft Systems Journal, 1997.
[37] M. Pietrek. New vectored exception handling in Windows XP. MSDN Magazine, 2001.
[38] M. Prandini and M. Ramilli. Return-Oriented Programming. In IEEE Symposium on Security and Privacy, 2012.
[39] M. Russinovich, D. A. Solomon, and A. Ionescu. Windows Internals, Part 1. Microsoft Press, 2012.
[40] F. Schuster, T. Tendyck, C. Liebchen, L. Davi, A.-R. Sadeghi, and T. Holz. Counterfeit object-oriented programming: On the difficulty of preventing code reuse attacks in C++ applications. In IEEE Symposium on Security and Privacy, 2015.
[41] H. Shacham, M. Page, B. Pfaff, E.-J. Goh, N. Modadugu, and D. Boneh. On the effectiveness of address-space randomization. In ACM Conference on Computer and Communications Security (CCS), 2004.
[42] K. Z. Snow, F. Monrose, L. Davi, A. Dmitrienko, C. Liebchen, and A.-R. Sadeghi. Just-in-time code reuse: On the effectiveness of fine-grained address space layout randomization. In IEEE Symposium on Security and Privacy, 2013.
[43] L. Szekeres, M. Payer, T. Wei, and D. Song. Sok: Eternal war in memory. In IEEE Symposium on Security and Privacy, 2013.
[44] Thomas Patzke. Browser Crasher. https://github.com/thomaspatzke/BrowserCrasher.
[45] R. Wahbe, S. Lucco, T. E. Anderson, and S. L. Graham. Efficient software-based fault isolation. In ACM Symposium on Operating Systems Principles, 1993.
[46] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin. Binary stirring: Self-randomizing instruction addresses of legacy x86 binary code. In ACM Conference on Computer and Communications Security (CCS), 2012.

---

This version maintains the original content while improving readability, structure, and professional tone.