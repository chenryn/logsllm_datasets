can also use exception handling to detect and resolve potential
memory errors. Our results show that ﬁltering prior to handling
an exception can be effective in limiting the danger of a speciﬁc
exception handler. Even applications that heavily use exception
handling do not necessarily contain a memory oracle, if the
proper ﬁltering is performed. However we also located multiple
examples of catch-all ﬁlters or ﬁlters with broad ﬁltering criteria.
Some of these were combined with memory dereferences
outside of the protected code area, which usually indicates
a handler which should not cover access violations, but does
so anyway due to too broad ﬁltering. Another observation
is that exception handling is much more common in client
applications on Windows than it is in servers for Linux. This
can be explained by the differences in the way memory faults
are reported on these systems. Linux uses the signal model,
requiring a global signal handler to catch the corresponding
signal [4], whereas Windows allows the usage of SEH, which
provides a comfortable way to protect speciﬁc code blocks.
C. Potential countermeasures
Depending on the system and application different coun-
termeasures are possible. We outline some possible defenses
ranging from a system redesign to ad-hoc ﬁxes in either the
application or the system itself.
System design changes Completely eliminating memory
oracles would most likely require fundamental changes to
both programs and the underlying operating systems. Most
of these countermeasures intentionally reduce the feature set
provided to user space programs and therefore the balance
between loss of functionality and gain of security must be
considered. Given a mechanism to either recover from access
violations or querying the state of memory addresses (either
directly or indirectly), an attacker can construct crash-resistant
primitives and bypass information hiding defenses. As such,
we propose the following properties:
• any access violation is critical for the application and
yields to termination
• exception handling can only be used for program-level
exceptions (e.g., C++ exceptions), not system-level (e.g.,
access violations)
• error reporting and data collection is possible, but care
must be taken to not allow resuming the normal execution
• system APIs and system calls must terminate the offending
application on a memory error, as if the application
received the fault
198
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:22 UTC from IEEE Xplore.  Restrictions apply. 
• exception masking must not be possible, any fault no
matter the callstack terminates the process
• facilities to infer the memory layout, e.g., information in
/proc or VirtualQuery, are questionable and should be
removed to prevent probing using them
• allocation functions that allow specifying the desired
address should be removed
• the memory layout of restarting processes must not persist
between restarts
Improving exception ﬁltering A less general approach would
be to narrow the exceptions caught by speciﬁc exception
handlers. This usually means that the exception ﬁlters must not
accept more than the minimal needed set of exception codes.
While some handlers might need to catch access violations,
their widespread use is questionable. In addition to hardening
the exception handling in applications the system level oracles
need to be covered as well. This could, for example, be achieved
by treating a memory error within the system API or system
call the same as any error in the application. This means
instead of either silently discarding the exception or catching it
and setting the appropriate error state, but allowing execution
to continue, the application would need to explicitly employ
exception handling around these functions. This results in less
possibilities for an attacker to abuse such functionality, if the
application can ensure no invalid pointer is passed to this API
during normal operation.
Restricting access violations Another, more compatible, ap-
proach concerning memory probing itself is to only allow
handling and resuming of expected access violations. There are
two common reasons for a memory access to fail: (i) there is
no mapped memory at the given address or (ii) the permissions
of the memory do not allow the intended access. The ﬁrst
case almost always results from a wrong calculation, or in our
case an exploit attempt, so it should be considered abnormal
behavior. The application tried to access memory that it has
not previously allocated and it also was not allocated by
the operating system for the process, so there should be no
references to this memory region. This is different compared
to the second case where the address itself is valid—there is
allocated memory at the speciﬁed location, but its permissions
do not match the requested access.
Generating a fault based on permissions can be intended, it
can be used for performance reasons as seen in Firefox [22],
so the application explicitly allocates a region of memory,
but marks it as inaccessible. In a way the program expects
an access violation to occur under some previously known
circumstances. As such it can be viable to only allow access
violations that occur at mapped memory to be handled. This is
similar to the method described by Gawlik et al. in regards to
removing the scanning primitive from Firefox, but we propose
to employ this policy at the system level. This means any
memory access to an unmapped page causes an unrecoverable
error, without invoking any exception handler in the faulting
process. This can be simulated by the application itself by
performing checks on the supplied exception information and
terminating in the case of an unmapped access. Using this
approach would still allow optimizations as used in Firefox,
but scanning attempts would be detected at the ﬁrst unmapped
region encountered. While not providing as much security as a
hard policy concerning memory errors, it reduces the odds of
successful guessing signiﬁcantly. This results in information
hiding providing the same security guarantees as in the absence
of crash resistance.
Rate based detection An orthogonal defense is a simple
anomaly detection that analyzes the number of access violations.
In principle, this is similar to the detection of crashes for
server applications to detect a BROP attack [29]. With some
applications using expected access violations for performance
optimizations, we wanted to establish a baseline of how many
such faults are generated during normal usage in practice. A
well known instance of this design choice can be found in
the Firefox web browser, so we used this program to test
our theory. We added logging code to report any fault caught
and handled in the browser. Using this modiﬁed version, we
crawled the top 40,000 websites according to Alexa [1] and
logged any occurrence. Our tests showed that none of these
websites exhibited an access violation when accessing the site.
Additionally, we tested the corner case of using asm.js-
heavy websites in the form of a dedicated asm.js bench-
mark [3]. This tool represents a stress test as it always forces
native code to be generated and applies some optimizations,
one of them being the usage of faults to catch out-of-bound
accesses. While we observed access violations, they are far
less frequent than during a probing attack similar to the one
described by Gawlik et. al. [22] with multiple thousands per
second. The benchmark triggered faults in groups of up to 20
in short succession, but the overall rate was much lower as
there were breaks between the groups. Even if we interpret the
peak rate as our baseline, the faults caused by actual scanning
attempts are several orders of magnitude more frequent.
As such, we conclude that the rate of access violations can
provide a viable heuristic for a defense. Even if an attacker
tries to circumvent detection by performing a far slower scan,
she will be slowed to a level where the duration will most
likely be too high to be practical.
VIII. CONCLUSION
In this paper, we showed that crash-resistant primitives are
not unique oddities. Most importantly, we demonstrated that
memory oracles exhibit speciﬁc properties that can be used
to locate them in real-world applications. We showed that it
is possible to develop tools that ease the discovery of those
code locations even for complex, closed-source programs. Once
located, these primitives can be used by an attacker in the same
way as demonstrated by previous work [22]. In addition, our
results show that not only client programs are threatened by
crash resistance: even servers can exhibit not only crash-tolerant
behavior (as demonstrated before), but such applications are
also susceptible to this new kind of vulnerabilities. Overall,
our results demonstrate that locating a crash-resistant primitive
199
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:22 UTC from IEEE Xplore.  Restrictions apply. 
is no longer left to pure chance, but poses a threat for defenses
that rely on information hiding in any kind of application.
ACKNOWLEDGEMENTS
We thank the anonymous reviewers for their valuable
comments. This work was supported by the European Com-
mission through the projects H2020 ICT-32-2014 “SHARCS”
under Grant Agreement No. 644571, H2020 MSCA-RISE-
2015 “PROTASIS” under Grant Agreement No. 690972 and
ERC Starting Grant No. 640110 “BASTION”, and by the
Netherlands Organisation for Scientiﬁc Research through the
NWO 639.023.309 VICI “Dowsing” project.
REFERENCES
[1] Alexa - Actionable Analytics for the Web. http://www.alexa.com/.
[2] BrowserBench. http://browserbench.org/.
[3] MASSIVE - the asm.js benchmark. https://kripken.github.io/Massive/.
[4] WineHQ - Structured Exception Handling. https://www.winehq.org/docs/
winedev-guide/seh.
[5] ERRNO(3) Linux Programmer’s Manual. Linux Manual Page, 2016.
[6] SIGNAL(7) Linux Programmer’s Manual. Linux Manual Page, 2016.
[7] P. Akritidis, M. Costa, M. Castro, and S. Hand. Baggy bounds checking:
An efﬁcient and backwards-compatible defense against out-of-bounds
errors. In USENIX Security Symposium, 2009.
[8] M. Backes, T. Holz, B. Kollenda, P. Koppe, S. N¨urnberger, and J. Pewny.
You can run but you can’t read: Preventing disclosure exploits in
executable code. In ACM Conference on Computer and Communications
Security (CCS), 2014.
[9] M. Backes and S. N¨urnberger. Oxymoron: Making ﬁne-grained memory
randomization practical by allowing code sharing. In USENIX Security
Symposium, 2014.
[10] P. Betts.
The case of
the disappearing OnLoad exception.
http://blog.paulbetts.org/index.php/2010/07/20/the-case-of-the-
disappearing-onload-exception-user-mode-callback-exceptions-in-x64/.
[11] S. Bhatkar, D. C. DuVarney, and R. Sekar. Efﬁcient techniques for
In USENIX
comprehensive protection from memory error exploits.
Security Symposium, 2005.
[12] D. Bigelow, T. Hobson, R. Rudd, W. Streilein, and H. Okhravi. Timely
rerandomization for mitigating memory disclosures. In ACM SIGSAC
Conference on Computer and Communications Security, 2015.
[13] A. Bittau, A. Belay, A. Mashtizadeh, D. Mazieres, and D. Boneh. Hacking
blind. In IEEE Symposium on Security and Privacy, 2014.
[14] N. Carlini, A. Barresi, M. Payer, D. Wagner, and T. R. Gross. Control-
ﬂow bending: On the effectiveness of control-ﬂow integrity. In USENIX
Security Symposium, 2015.
[15] S. Crane, C. Liebchen, A. Homescu, L. Davi, P. Larsen, A.-R. Sadeghi,
S. Brunthaler, and M. Franz. Readactor: Practical code randomization
resilient to memory disclosure. In IEEE Symposium on Security and
Privacy, 2015.
[16] S. Crane, S. Volckaert, F. Schuster, C. Liebchen, P. Larsen, L. Davi,
A.-R. Sadeghi, T. Holz, B. D. Sutter, and M. Franz. It’s a TRAP: Table
Randomization and Protection against Function Reuse Attacks. In ACM
Conference on Computer and Communications Security (CCS), 2015.
[17] T. H. Dang, P. Maniatis, and D. Wagner. The performance cost of shadow
stacks and stack canaries. In ACM Symposium on Information, Computer
and Communications Security (ASIACCS), 2015.
[18] L. Davi, C. Liebchen, A.-R. Sadeghi, K. Z. Snow, and F. Monrose.
Isomeron: Code randomization resilient to (just-in-time) return-oriented
programming. In Symposium on Network and Distributed System Security
(NDSS), 2015.
[19] DynamoRIO contributors. DynamoRIO Dynamic Instrumentation Tool
Platform. http://www.dynamorio.org/.
[20] U. Erlingsson, M. Abadi, M. Vrable, M. Budiu, and G. C. Necula. XFI:
Software guards for system address spaces. In Symposium on Operating
Systems Design and Implementation (OSDI), 2006.
[21] I. Evans, S. Fingeret, J. Gonz´alez, U. Otgonbaatar, T. Tang, H. Shrobe,
S. Sidiroglou-Douskos, M. Rinard, and H. Okhravi. Missing the point
(er): On the effectiveness of code pointer integrity. In IEEE Symposium
on Security and Privacy, 2015.
[22] R. Gawlik, B. Kollenda, P. Koppe, B. Garmany, and T. Holz. Enabling
client-side crash-resistance to overcome diversiﬁcation and information
hiding.
In Symposium on Network and Distributed System Security
(NDSS), 2016.
[23] J. Gionta, W. Enck, and P. Ning. HideM: Protecting the contents of
In ACM
userspace memory in the face of disclosure vulnerabilities.
Conference on Data and Application Security and Privacy, 2015.
[24] E. G¨oktas¸, R. Gawlik, B. Kollenda, E. Athanasopoulos, G. Portokalidis,
C. Giuffrida, and H. Bos. Undermining information hiding (and what to
do about it). In USENIX Security Symposium, 2016.
[25] V. P. Kemerlis, G. Portokalidis, K. Jee, and A. D. Keromytis.
libdft:
Practical dynamic data ﬂow tracking for commodity systems. In ACM
SIGPLAN Notices, 2012.
[26] C. Kil, J. Jim, C. Bookholt, J. Xu, and P. Ning. Address space layout
permutation (ASLP): Towards ﬁne-grained randomization of commodity
software. In Annual Computer Security Applications Conference (ACSAC),
2006.
[27] B. Kollenda, E. G¨oktas¸, T. Blazytko, P. Koppe, R. Gawlik, R. Konoth,
C. Giuffrida, H. Bos, and T. Holz. Towards Automated Discovery
of Crash-Resistant Primitives in Binary Executables. Technical report,
Ruhr-University Bochum, 2016.
[28] V. Kuznetsov, L. Szekeres, M. Payer, G. Candea, R. Sekar, and D. Song.
Code-pointer integrity. In Symposium on Operating Systems Design and
Implementation (OSDI), 2014.
[29] V. Kuznetsov, L. Szekeres, M. Payer, G. Candea, and D. Song. Poster:
Getting the point(er): On the feasibility of attacks on code-pointer
integrity. In IEEE Symposium on Security and Privacy, 2015.
[30] K. Lu, S. N¨urnberger, M. Backes, and W. Lee. How to make ASLR win
the clone wars: Runtime re-randomization. In Symposium on Network
and Distributed System Security (NDSS), 2016.
[31] K. Lu, C. Song, B. Lee, S. P. Chung, T. Kim, and W. Lee. ASLR-
guard: Stopping address space leakage for code reuse attacks. In ACM
Conference on Computer and Communications Security (CCS), 2015.
[32] Microsoft Research. The Z3 Theorem Prover. https://github.com/
Z3Prover/z3.
[33] V. Mohan, P. Larsen, S. Brunthaler, K. W. Hamlen, and M. Franz. Opaque
Control-Flow Integrity. In Symposium on Network and Distributed System
Security (NDSS), 2015.
[34] S. Nagarakatte, J. Zhao, M. M. Martin, and S. Zdancewic. SoftBound:
Highly compatible and complete spatial memory safety for C.
In
ACM SIGPLAN Workshop on Programming Languages and Analysis for
Security (PLAS), 2009.
[35] A. Oikonomopoulos, E. Athanasopoulos, H. Bos, and C. Giuffrida. Poking
holes in information hiding. In USENIX Security Symposium, 2016.
[36] M. Pietrek. A crash course on the depths of win32 structured exception
handling. Microsoft Systems Journal, 1997.
[37] M. Pietrek. New vectored exception handling in Windows XP. MSDN
Magazine, 2001.
[38] M. Prandini and M. Ramilli. Return-Oriented Programming. In IEEE
Symposium on Security and Privacy, 2012.
[39] M. Russinovich, D. A. Solomon, and A. Ionescu. Windows Internals,
Part 1. Microsoft Press, 2012.
[40] F. Schuster, T. Tendyck, C. Liebchen, L. Davi, A.-R. Sadeghi, and T. Holz.
Counterfeit object-oriented programming: On the difﬁculty of preventing
code reuse attacks in C++ applications. In IEEE Symposium on Security
and Privacy, 2015.
[41] H. Shacham, M. Page, B. Pfaff, E.-J. Goh, N. Modadugu, and D. Boneh.
On the effectiveness of address-space randomization. In ACM Conference
on Computer and Communications Security (CCS), 2004.
[42] K. Z. Snow, F. Monrose, L. Davi, A. Dmitrienko, C. Liebchen, and A.-R.
Sadeghi. Just-in-time code reuse: On the effectiveness of ﬁne-grained
address space layout randomization. In IEEE Symposium on Security
and Privacy, 2013.
[43] L. Szekeres, M. Payer, T. Wei, and D. Song. Sok: Eternal war in memory.
In IEEE Symposium on Security and Privacy, 2013.
[44] Thomas Patzke. Browser Crasher. https://github.com/thomaspatzke/
BrowserCrasher.
[45] R. Wahbe, S. Lucco, T. E. Anderson, and S. L. Graham. Efﬁcient
software-based fault isolation. In ACM Symposium on Operating Systems
Principles, 1993.
[46] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin. Binary stirring: Self-
randomizing instruction addresses of legacy x86 binary code. In ACM
Conference on Computer and Communications Security (CCS), 2012.
200
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:22 UTC from IEEE Xplore.  Restrictions apply.