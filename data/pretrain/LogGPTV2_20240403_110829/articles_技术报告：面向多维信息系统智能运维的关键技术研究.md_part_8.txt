对于不同来源、不同特征的数据如何鉴别其中的"固有模式"以进行异常检测，就是异常检测算法需要解决的问题。
1.  单指标异常检测算法。
```{=html}
```
1.  三西格玛检测
![](media/image19.png){width="2.9875in" height="2.142361111111111in"}
![](media/image20.png){width="2.25625in" height="0.4479166666666667in"}
西格玛检测是一种非常经典的传统检测方法，通过对历史数据计算均值和方差并据此来判断待检测数据是否在合理范围内。西格玛检测非常容易理解，就是单纯的看数据是否符合历史期望与方差的约束，对于若干倍西格玛约束以外的数据视为异常。
优点：
-   简便易行，易于理解，可解释性强；
-   适合无内在规律可循的数据。
缺点：
-   完全不考虑数据本身的时序模式、时间特征、周期性等等；
-   识别逻辑过于简单，约束之外不一定就是异常，很多异常也可能在西格玛约束以内。
2.  ARIMA检测
ARIMA（Autoregressive Integrated Moving Average
model）差分整合移动平均回归模型，是一种经典统计学模型，通过计算历史数据的一些统计学特征，来试图预测未来数据，在异常检测领域，通过待检测数据和预测数据的差距来判断是否是异常。它是AR、AVR、ARMA模型的后续改进。
ARIMA(p, d, q)由三个部分组成：
AR(p)：AR是autoregressive的缩写，表示自回归模型，含义是当前时间点的值等于过去若干个时间点的值的回归------因为不依赖于别的解释变量，只依赖于自己过去的历史值，故称为自回归；如果依赖过去最近的p个历史值，称阶数为p，记为AR(p)模型。
I(d)：I是integrated的缩写，含义是模型对时间序列进行了差分；因为时间序列分析要求平稳性，不平稳的序列需要通过一定手段转化为平稳序列，一般采用的手段是差分；d表示差分的阶数，t时刻的值减去t-1时刻的值，得到新的时间序列称为1阶差分序列；1阶差分序列的1阶差分序列称为2阶差分序列，以此类推；另外，还有一种特殊的差分是季节性差分S，即一些时间序列反映出一定的周期T，让t时刻的值减去t-T时刻的值得到季节性差分序列。
MA(q)：MA是moving
average的缩写，表示移动平均模型，含义是当前时间点的值等于过去若干个时间点的预测误差的回归；预测误差=模型预测值-真实值；如果序列依赖过去最近的q个历史预测误差值，称阶数为q，记为MA(q)模型。
优点：
-   简单，易实现；
-   适用于无噪音、模式简单的数据。
缺点：
-   调参难度大，每个参数都需要对具体数据进行适配；
-   只能使用模式简单的数据，对于模式复杂的数据表现很差；
-   不考虑时间特征；
对数据波动非常敏感，容易产生误报和漏报。
3.  孤立森林算法
孤立森林算法是一种基于决策树森林的集成算法，无监督。在时序数据异常检测中，将窗口化后的多维数据输入模型，得到数据的异常分数。复杂度低，可以分布式计算。通过训练若干决策树，再由所有的决策树投票共同决定是否是异常。这种训练多个弱学习器来达到强学习器的思想称之为集成打包（bagging）思想。
使用样本在空间中的孤立程度作为异常判定标准。在指标异常检测中，所有一维训练数据和测试数据都需要窗口化为高维数据，窗口大小由数据的周期和模式决定。
学习过程：构造多棵分类树，组成森林，每棵树在构造时所用的数据是在总样本里随机抽样得到的。建一棵树的过程类似于构造一个分类树，每次在样本空间里随机选择一个维度进行划分，如果划分后的子空间里的样本数小于某一阈值则停止划分，否则继续划分，直到到达树的最大深度或无可划分。
估计过程：将新样本输入森林，以新样本所在子空间在每棵树里的深度（即划分次数）作为异常指数，越深则说明越正常，越浅越异常。最后取森林里每棵树的结果共同决策出总异常分。
优点：
-   简单，速度快，易训练；
-   擅长处理与时间不相关的异常，异常的偏移程度远大于自身的离散程度的简单情况（周期或非周期数据中的极值、大段异常）；
-   对缺漏点不敏感。
缺点：
-   不考虑时间特征
-   训练数据中的噪音会产生较大影响
-   对于细微异常不敏感，对于数值在整体数据范围内的异常不敏感
4.  滑动平均算法
滑动平均算法是一种基于数值的简单阈值算法，通过比较滑动窗口内的平均值的某种关系（比值、差分等等）的历史分布，来判断数据是否在合理的范围内波动，是否产生了历史习惯外的波动情况。
原理：通过计算相邻窗口内数据和的商来考量数据变化的程度，基于商值序列的分布来学习相对稳态下的阈值。在KPI异常检测中，所有一维训练数据和测试数据都需要窗口化为高维数据，窗口大小由数据的波动程度决定。窗口越小，模型对数据波动越敏感；窗口越大对数据波动越不敏感。
学习过程：对两个相邻窗口的数据按照窗口分别求和再相除，得到前后窗口的数值商，进而得到训练数据的商序列。如果数据波动越剧烈，那么商值就会越大，反之则反。为了对商序列的分布做简单描述，对其求均值和期望。此期望和均值将作为后面检测所用的阈值。其意义是指如果数据的波动程度在历史数据波动程度内，则认为是正常。
相比于单纯的比较平均值的历史分布，使用前后窗口可以增加算法的鲁棒性，削弱因为数据中噪音的影响。对于偶发性的波动异常，如果单纯比较历史均值分布，由于偶发异常在窗口内对均值偏移产生的影响有限，最终会导致容易产生漏报。而如果使用前后窗口的比较关系，在正常情况下这种比较关系都是平稳的，偶发异常虽然在均值后只能造成较小的影响，但是在比较关系中会被放大，进而偏离关系数值的历史分布从而可以被捕捉到。
评估过程：对待预测序列进行窗口化并计算商序列，使用历史学到的均值和方差配合灵敏度构造阈值，商在阈值外的被认为是异常。
优点：
-   简单，快速，易训练。训练和检测过程均可以在O(n) 的复杂度内完成；
-   适用于无规律的非周期数据，能容忍一定的噪音。
缺点：
-   不考虑时间特征；
-   不考虑数据本身的模式异常，仅在历史分布的范围内进行判断；
-   效果比较依赖数据本身的波动程度，如果数据自身波动很大，波动类型的异常可能难以被捕获；
-   对于细微异常不敏感，对于数值在整体数据范围内的异常不敏感。
5.  梯度增强回归树算法
梯度增强回归树算法，（简称GBRT）是一种基于增强思想的决策树森林算法，有监督。在时序数据异常检测中，将数据输入模型，得到数据的异常分数。和孤立森林不同，GBRT是一种使用不同的"集成"思想的算法。孤立森林通过训练多个不同的决策树，采用投票的形式决定最终结果，而GBRT则是通过不断地训练新树去优化或是改进之前的决策结果，因此被称为增强思想。以最后一棵树的结果作为最终结果。正因为需要涉及到对之前结果的修正，因此和孤立森林的不同之处便是GBRT是一个有监督模型------训练数据中必须有明确的标记用以反馈训练后续的决策树。
对于每个给定窗口内的数据，根据窗口大小计算若干统计学特征和基于时间戳的时间特征。由上述特征共同组成此数据的特征维度，输入到决策树森林中。
学习过程：使用Boost思想训练决策树森林，除第一棵树外，其余树的构造全部基于前面树决策结果的目标函数结果来构造。每棵决策树的构造方式是通过不断从数据的特征维度中选取信息增益最大且降低目标函数的维度和该维度的分界点来构造，直到符合停止条件（比如树深度、最小子集划分、最小信息增益等等）。最终得到一个相互修正的决策树森林。
评估过程：将数据的特征维度输入森林，从第一棵树开始每棵树修正前面的结果直到最终的树输出最终的异常score。
优点：
-   训练过程中通过对模型不断增强，具有较强的学习能力，但比较依赖训练数据的质量；
-   通过人为标记或特征工程，可以有针对性地去适应某些数据需求，比如周期型异常，可以加入乱序周期的数据作为反例来训练一个可以识别周期异常的模型；
-   在多数情况下，效果不会弱于孤立森林，但是如果训练数据不理想，可能会发生相反的情况。
缺点：
-   因为涉及不断的反馈迭代，训练时间很长；
-   对数据要求很高，要求数据必须有标记（或是必须人为引入）；
    > 对数据量要求比较大。
6.  核密度分析
核密度分析（Kernel Density Estimation，
简称KDE），是一种基于历史数据分布的无监督算法。在时序数据异常检测中，将数据输入模型，得到数据的异常分数。
对于一个给定带宽，以带宽为间隔划分整个数据集，使用每个间隔内的点构造高斯分布，将所有间隔得到的高斯分布线性叠加并归一化，最终得到一个由多个高斯分布组合而成的分布模型。原理上类似对统计数据做直方图，可以将数据在各个数值上的分布通过频率计算出来，只不过使用的不是简单的直方图而是将柱换成了高斯分布。
学习过程：对每天处于同一时刻的数据点，选取其相邻一定范围内的点，构成一个点集，对点集做核密度分析，构造一个核密度模型。对一天中的所有时刻构造一个对应的核模型，则得到了最终的KDE模型。根据需要精度，可以生成数量不同的模型。
评估过程：首先找到待评估点所属的时刻，使用该时刻代表的核密度模型对数据点进行评估，拟合分布的概率分布给出异常score，最终根据灵敏度阈值去判断score是否符合异常标准。
优点：
-   对于周期规律明确的数据具有较好的评估效果，对任意时刻的灵敏度取决于该时刻数据的波动程度；
-   如果对不同时间模式训练不同的KDE模型，可以精准捕获周期模式异常，对证券类数据等具有良好的识别效果；
-   模型完全不受少量缺失点的影响。
缺点：
-   比较简单暴力的模式，对每个单独建模，空间消耗比较大；
-   对数据量要求比较高，精准度和数据量直接挂钩。
7.  编码器家族
条件变分自编码器（Conditional Variational
Autoencoder，简称CVAE），是基于变分自编码器的改进方法，是一种涉及神经网络的机器学习算法。理解CVAE需要先从最原始的自编码器开始：在时序序列异常检测中，通过将输入数据窗口化，通过编码器映射为维度更低的隐变量，再由解码器进行复原，如果复原出的数据和原始的数据接近程度较高，说明输入数据的模式是见过的反之就是异常。而网络训练过程就是通过输入无异常的数据让网络训练编码器和解码器的能力，使之尽可能地确保将模式相似的数据都复原出来。