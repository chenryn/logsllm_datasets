repeated queries for two hostnames, one accelerated by each CDN,
directly to their respective authoritative nameservers. However,
to make the authoritative nameservers use probes’ location rather
than ours, we include into our queries ECS options with client sub-
net prefixes derived from the 800 IP addresses of our Atlas probe
sample. For each DNS response received, we leverage RIPE Atlas
SSL measurements to perform three certificate downloads from the
corresponding Atlas probe using the first IP address in the DNS
response, and use the median of the TCP handshake latencies as
our metric for the resulting user-to-edge-server proximity.
For CDN-1, with 24-bit prefixes of our 800 probe addresses, the
authoritative nameserver returns 400 unique first IP addresses in
their responses. However, with any shorter source prefixes (we
study prefix lengths between 16-24), the total number of unique first
IP addresses returned by the authoritative server falls drastically,
to between 5 and 14.
126
110100100000.10.20.30.40.50.60.70.80.91Time to connect in msec (log scale)CDF  161718192021222324110100100000.10.20.30.40.50.60.70.80.91Time to connect in msec (log scale)CDF  2021222324IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Rami Al-Dalky, Michael Rabinovich, and Kyle Schomp
Figure 8: CNAME flattening when accessing customer.com.
Figure 6 shows the cumulative distribution function (CDF) of the
median TCP handshake latencies for the hostname accelerated by
CDN-1, using the edge server obtained with an ECS prefix of a given
length. The figure shows a huge degradation in CDN-1 mapping
latency when reducing source prefix length from 24 to 23, while
further shortening of the prefix has no visible effect. Together with
the observation on the number of edge servers produced by different
prefix lengths, it appears that CDN-1 does not use proximity-based
server selection for prefixes shorter than /24.
Turning to CDN-2, we find that when sending source prefix
length values between 16-20 a single IP address is returned from
CDN-2 authoritative DNS server for all queries with scope prefix
length of zero. Using traceroute, we find that the IP address is in
Toronto, near our lab machine (located in Cleveland). Thus, CDN-2
appears to ignore the ECS information when source prefix length is
20 or less and use the IP address of the resolver that sends the query
as a proxy for the end-device location. However, as soon as the
prefix length reaches 21 or above, CDN-2 returns 41-42 different IP
addresses. Figure 7 shows the CDF of the median TCP handshake
latencies for the hostname accelerated by CDN-2, excluding the
results for source prefix length 16-19 because they are identical to
length 2011 We can see that using source prefix length of 21 and
longer have the same quality of mapping but dropping to /20 leads
to a dramatic penalty. It appears that CDN-2 leverages ECS prefixes
in its edge server selection for prefixes of at least 21 bits not for
shorter prefixes.
The results in this section bring interesting questions about
how resolvers should choose the prefix lengths when sending ECS
queries to CDNs. They could just blindly use the most specific pre-
fixes recommended by the RFC (/24), but in the case of CDN-2 this
would expose more client information than needed for proximity
mapping by the CDN – sending 21 bits would suffice. However,
sending any fewer than 24 bits to CDN-1 would negate any benefits
from ECS and then whatever client information is submitted in
fewer bits would still be exposed unnecessarily.
11We note a similarity of the CDFs in both CDNs. We explain it by the disproportionally
high representation of Europe in RIPE Atlas probes, where both CDNs have dense
footprint.
127
Furthermore, while the RFC suggests that the resolvers utilize
knowledge of their clients to use shorter source prefixes when
all addresses covered by these prefixes are known to be in the
same location, this recommendation assumes that the authoritative
nameservers would use whatever number of client subnet bits they
receive for server selection. The results from both CDNs above
show this assumption is not always accurate. Both CDNs appear
to stop using ECS once the source prefix length drops to a certain
limit.
On the balance, it would appear that using /24 for all ECS queries
is the most practical approach. An alternative would be to track the
source prefix lengths needed per CDN, or even per subdomain and
per client address block, since a CDN can in principle use different
prefix lengths for different subdomains and clients. This can get
complicated very quickly.
8.4 CNAME Flattening
The DNS standard [16] does not allow CNAME records to co-exist
with other record types at the same name. This poses a problem as
CNAME records are a common method to onboard traffic to a CDN
and content providers often desire for their content to be reachable
from the apex of their zones, e.g., example.com, which at a mini-
mum must have NS and SOA records. CNAME flattening [8, 18]
has emerged to circumvent this obstacle. With CNAME flattening,
when an authoritative nameserver receives a query for N1 that
it would normally redirect to a CDN by returning a CNAME N2
from the CDN’s domain, the authoritative server instead resolves
N2 itself by interacting with the CDN’s authoritative DNS on the
backend, and then returns the final A/AAAA record(s) of the edge
server(s) to the original querier. Thus, recursive resolvers query-
ing the authoritative DNS server receive A/AAAA record(s) for
N1, while N2 is invisible externally, outside the authoritative DNS
servers of the website and the CDN involved. In this section, we
demonstrate how careless implementations of CNAME flattening
may eliminate the ECS benefits even when ECS is supported by
both the recursive resolver and the CDN.
We use an imaginary domain “customer.com” in this discussion,
as our goal is to draw attention to this pitfall and not to single
Major Public  DNS Service Client [C1] 1. ex.com DNS Provider  Authoritative Nameserver 2. ex.com Major CDN  Authoritative Nameserver 3. ex.cdn.net 4. ex.cdn.net  [E1] 5. ex.com [E1] 6. ex.com [E1] E1 7. HTTP Request [ex.com] 8. HTTP Redirection [www. ex.com] 9. www. ex.com 14. www. ex.com [E2] 12. ex.cdn.net (C1) 13. ex.cdn.net [E2] E2 10. www. ex.com 11. www. ex.com [ex.cdn.net] A Look at the ECS Behavior of DNS Resolvers
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
out one of the websites that fell into it. However, this discussion
represents a real website of a prominent content provider that
we tested. The DNS zone is hosted with a major DNS provider
while its web acceleration is provided by a major CDN. The web
site can be accessed either via the apex of the zone, i.e., through
URL http://customer.com (using CNAME flattening) or with www
prepended, with URL http://www.customer.com.
We access customer.com from the Chrome browser using a major
Public DNS service as our recursive resolver as this Public DNS
and the major CDN are known to support ECS with one another.
We use Wireshark to collect a packet trace while loading the page.
The order of actions is depicted in Figure 8 and is as follows: (i)
(Steps 1-6) The client resolves customer.com to the IP address E1
of an edge server of the major CDN via CNAME flattening; (ii)
(Steps 7-8) The client performs HTTP interaction with E1, receiving
HTTP redirect to www.customer.com. This incurred 125 ms to
complete TCP handshake and 650ms in total elapsed time from step
1. (iv) (Steps 9-14) The client resolves www.customer.com, using
the regular CNAME-based DNS redirection, to the IP address of a
different edge server of the major CDN, and finally (v) (Not shown
in the figure) the HTTP download of the page from the second IP
address, taking 45ms for the TCP handshake. Note that when the
client accesses the same page using www.customer.com directly, it
would only execute phases (iv) and (v).
From the results, we can infer that the mapping of customer.com
to edge server E1 is poor (likely due to the absence of ECS in the
DNS transaction in steps 3-4 between the DNS provider and the
major CDN for the flattened CNAME, forcing the CDN to map
the query based on the IP address of customer.com’s authoritative
nameserver, which has no bearing on the client’s location), and
HTTP redirection is used to correct the mapping. The overall Web
access incurs 650ms penalty due to the lack of ECS on part of the
resolution path.
It would appear authoritative DNS servers that implement CNAME
flattening could mitigate this issue by using ECS and passing ECS
source prefixes to the CDN when they resolve the flattened name.
This would indeed help if customer.com’s authoritative nameserver
received queries directly from clients or from clients’ nearby ISP
resolvers. However, with public DNS resolvers, the queries can still
arrive from senders that are distant from the end-devices. Further-
more, even if the public DNS and the CDN mutually whitelist each
other to support ECS, the problem remains unless the Public DNS
also whitelists customer.com for ECS support. In summary, full
elimination of the performance penalty due to CNAME flattening
requires careful planning to enact pair-wise coordination of multi-
ple parties: customer.com’s authoritative DNS service provider, the
CDN used to accelerate customer.com’s content delivery, and any
public DNS resolution services.
9 LIMITATIONS & FUTURE WORK
In this section, we describe topics that we did not study yet would
complement our work nicely. This includes extensions of our anal-
ysis as well as entirely new research questions.
Our study of source prefix lengths in Section 6.2 uses the data
from our scan that probes each forwarder only once. Thus, the num-
ber of times egress resolvers are engaged is variable and depends
128
on how many open forwarders share a given resolver. Further, our
authoritative nameserver in the scan always answers ECS queries
with a deterministic scope (4 shorter than the source prefix length).
It would be interesting to engage the same resolver repeatedly in
a more systematic manner and explore if changing the scope in
authoritative nameserver’s responses would affect the source prefix
length of subsequent queries.
In Section 7, we study the impact ECS has on cache size for the
portion of DNS responses that carry the ECS option only. To un-
derstand the impact on overall cache size including DNS responses
that do not carry the ECS option, future work should focus on
the fraction of DNS responses that carry ECS options today and
attempt to predict what that fraction will be as ECS support grows.
From such a study, it would be possible to predict that overall cache
blow up factor for recursive resolvers at both present levels of ECS
deployment by authoritative nameservers and future increases in
deployment.
Another direction for future work is to conduct a compara-
tive analysis of different whitelisted recursive resolvers as well
as whitelisted vs. non-whitelisted resolvers in terms of their com-
pliance with RFC recommendations and consequences of ECS on
caching.
Our study of the ECS caching behavior of recursive resolvers in
Section 6.3 includes only recursive resolvers that are discoverable
through open forwarders in the Scan dataset and is not exhaustive
of all recursive resolvers. Other techniques for probing recursive
resolvers including Ripe Atlas [26] would complement our study,
increasing overall coverage.
In Section 8.1, we report a behavior of PowerDNS that has im-
plications on authoritative nameserver handling of ECS. Similar
nuanced behaviors may exist in other recursive resolver software.
A lab based analysis of ECS behavior in popular recursive resolver
software could detect the PowerDNS behavior and many other sim-
ilar behaviors, and would be beneficial to the developer community.
10 CONCLUSION
This paper studies the behavior of recursive resolvers that have
adopted EDNS0-Client-Subnet (ECS) extension to the DNS protocol.
ECS has been proposed to facilitate proximity-based server selec-
tion by content delivery networks (CDNs), especially in the face
of increasing use of public DNS resolvers that can be far removed
from the end-devices. Using diverse sources of data, we examine
important aspects of ECS-related behavior and find a wide range
of detrimental behaviors that negatively affect client privacy, ECS
benefits in improving server selection, and effectiveness of DNS
caching. This shows that despite its apparent simplicity, ECS adop-
tion requires careful engineering of a proper setup to get the most
benefits from ECS and avoid harm.
Acknowledgements. We thank the anonymous reviewers for ex-
tensive and useful comments. We are especially grateful to our
shepherd, Tobias Fiebig, for his insightful comments and discus-
sions during the final revision, which significantly improved the
paper. The work of Michael Rabinovich was supported in part by
NSF through grant CNS-1647145.
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Rami Al-Dalky, Michael Rabinovich, and Kyle Schomp
REFERENCES
[1] Bernhard Ager, Wolfgang Mühlbauer, Georgios Smaragdakis, and Steve Uhlig.
2010. Comparing DNS resolvers in the wild. In Proceedings of the Internet Mea-
surement Conference. ACM, 15–21.
[2] Akamai 2019. Akamai Technologies, Inc. Retrieved 2019-09-07 from https:
//www.akamai.com/
[3] Rami Al-Dalky, Michael Rabinovich, and Mark Allman. 2018. Practical challenge-
response for DNS. ACM SIGCOMM Computer Communication Review 48, 3 (2018),
20–28.
[4] Matt Calder, Xun Fan, Zi Hu, Ethan Katz-Bassett, John Heidemann, and Ramesh
Govindan. 2013. Mapping the expansion of Google’s serving infrastructure. In
Proceedings of the Internet Measurement Conference. ACM, 313–326.
[5] Matt Calder, Xun Fan, and Liang Zhu. 2019. A Cloud Provider’s View of EDNS
Client-Subnet Adoption. In Network Traffic Measurement and Analysis Conference
(TMA). IEEE, 129–136.
[6] Fangfei Chen, Ramesh K Sitaraman, and Marcelo Torres. 2015. End-User Map-
ping: Next Generation Request Routing for Content Delivery. ACM SIGCOMM
Computer Communication Review 45, 4 (2015), 167–181.
[7] CloudFront 2019. Amazon CloudFront. Retrieved 2019-09-07 from https://aws.
amazon.com/cloudfront/
[8] CNAME 2019.
Introducing CNAME Flattening: RFC-Compliant CNAMEs at a
Domain’s Root. https://blog.cloudflare.com/introducing-cname-flattening-rfc-
compliant-cnames-at-a-domains-root/
[9] C. Contavalli, W. van der Gaast, D. Lawrence, and W. Kumari. 2016. Client Subnet
in DNS Queries. RFC 7871. RFC Editor. https://tools.ietf.org/html/rfc7871
[10] D. Dagon, N. Provos, C.P. Lee, and W. Lee. 2008. Corrupted DNS Resolution
Paths: The Rise of a Malicious Resolution Authority. In Network and Distributed
System Security Symposium.
[11] J. Damas, M. Graff, and P. Vixie. 2013. Extension Mechanisms for DNS (EDNS(0)).
RFC 6891. RFC Editor. https://tools.ietf.org/html/rfc6891
[12] Wouter B De Vries, Roland van Rijswijk-Deij, Pieter-Tjerk de Boer, and Aiko Pras.
2018. Passive observations of a large DNS service: 2.5 years in the life of Google.
In Network Traffic Measurement and Analysis Conference (TMA). IEEE, 1–8.
[13] DITL 2018. A-Root DITL Data, submitted to DNS-OARC by Verisign. https:
//www.dns-oarc.net/oarc/data/ditl/2018.
[14] ECS 2019. EDNS Client Subnet FAQ. Retrieved 2019-09-07 from https://support.
opendns.com/hc/en-us/articles/227987647-EDNS-Client-Subnet-FAQ
[15] EdgeScape 2019. Akamai EdgeScape. Retrieved 2019-09-07 from https://developer.
akamai.com/edgescape
[16] R. Elz and R. Bush. 1997. Clarifications To the DNS Specification. RFC 2181.
https://tools.ietf.org/html/rfc2181
[17] Fastly 2019. Fastly, Inc. Retrieved 2019-09-07 from https://www.fastly.com/
[18] T. Finch, E. Hunt, P. van Dijk, and A. Eden. 2018. Address-specific DNS aliases
(ANAME). https://tools.ietf.org/html/draft-ietf-dnsop-aname-02. https://tools.
ietf.org/html/draft-ietf-dnsop-aname-02
[19] Cheng Huang, David A Maltz, Jin Li, and Albert Greenberg. 2011. Public DNS
system and global traffic management. In IEEE INFOCOM - The 30th Conference
on Computer Communications. 2615–2623.
[20] Ben Jones, Nick Feamster, Vern Paxson, Nicholas Weaver, and Mark Allman. 2016.
Detecting DNS root manipulation. In International Conference on Passive and
Active Network Measurement. Springer, 276–288.
[21] Panagiotis Kintis, Yacin Nadji, David Dagon, Michael Farrell, and Manos Anton-
akakis. 2016. Understanding the Privacy Implications of ECS. In International
Conference on Detection of Intrusions and Malware, and Vulnerability Assessment.
343–353.
[22] D. Leonard and D. Loguinov. 2008. Turbo King: Framework for Large-Scale Inter-
net Delay Measurements. In IEEE INFOCOM - The 27th Conference on Computer
Communications. 31–35.
[23] J Ott, M Sanchez, J Rula, and F Bustamante. 2012. Content delivery and the
natural evolution of DNS. In Proceedings of the Internet Measurement Conference.
ACM, 523–536.
[24] PDNS 2019. PowerDNS Recursor.
Retrieved 2019-09-07 from https://www.
powerdns.com/recursor.html
[25] David Plonka and Arthur Berger. 2017. kIP: a Measured Approach to IPv6 Address
Anonymization. arXiv preprint arXiv:1707.03900 (2017).
[26] RIPE Atlas 2019. Welcome to RIPE Atlas. Retrieved 2019-09-07 from https:
//atlas.ripe.net/
[27] Kyle Schomp, Tom Callahan, Michael Rabinovich, and Mark Allman. 2013. On
Measuring the Client-Side DNS Infrastructure. In Proceedings of the Internet
Measurement Conference. ACM, 77–90.
[28] Shadow 2019. Open Resolver Scanning Project. Retrieved 2019-09-07 from https:
//dnsscan.shadowserver.org/
[29] Philip Smith, Rob Evans, and Mike Hughes. 2006. RIPE routing working group
recommendations on route aggregation. Document ripe-399, RIPE (2006).
[30] Florian Streibelt, Jan Böttger, Nikolaos Chatzis, Georgios Smaragdakis, and Anja
Feldmann. 2013. Exploring EDNS-Client-Subnet Adopters in your Free Time. In
Proceedings of the Internet Measurement Conference. ACM, 305–312.
129