registers’ content in memory upon context switches. Thus,
we also present how the ciphertext side channel caused by
register states stored inside kernel structures can be mitigated
with a kernel patch, to achieve the invariant of secure registers
(Section VI-C), and measure the kernel patch performance
(Section VI-D).
Secret-aware register allocation. If secret-related variables
would ﬁt into a register, but are kept in memory due to register
pressure, changing the register allocation strategy may be
worth pursuing. The secret-related variables can be protected
by staying inside the register during their lifecycle and never
being spilled to memory.
In order to do that, compiler-level modiﬁcations are needed.
Even though developers can suggest the compiler to keep some
variables into registers by applying a register hint (e.g.,
register int var;), the variables are not guaranteed to
be placed inside registers. Thus, a compiler can be modiﬁed
to prioritize variables marked as ‘secret’ when allocating
registers. An example of a similar scheme is GINSENG [37],
which employs a custom register allocation strategy and a
secure storage in a TEE to shield sensitive variables from
a malicious operating system. In case a register containing a
secret must be spilled to the stack anyway (e.g., it is frequently
used in function calls or large variables), it can be protected
using a random mask as described in the later software-based
probabilistic encryption part.
Limiting reuse of memory locations. Both the dictionary
attack and the collision attack rely on repeated writes to a
ﬁxed physical memory address. Thus, limiting reuse of a ﬁxed
memory address leads to fresh ciphertext and can prevent the
attacker from inferring secrets via the ciphertext.
To achieve this, the application developer has to identify
and rewrite vulnerable code sections. For example, in our
collision attack (Section V-B), the conditional swap operation
should not be written to be performed in-place, but should
store the result in a newly allocated memory area. In this
way, an attacker always observes a fresh ciphertext in a new
location, independent from the value of the decision byte ci.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:55:46 UTC from IEEE Xplore.  Restrictions apply. 
10346
Software-based probabilistic encryption. If the aforemen-
tioned methods are not applicable, one can mimic probabilistic
encryption in software and add a random nonce to the secret
data each time when the data is written to the memory.
the ciphertext changes. In addition,
This can be approached in two ways: First, one can modify
the memory layout of the affected data structures to include
random nonces in between, such that each memory block gets
a sufﬁcient amount of random bits. Second, the memory layout
is left as-is, but a second buffer of the same size is allocated
for storing masks, which are then XOR-ed onto the plaintext.
The ﬁrst approach can be implemented by reserving the high
8 bytes of each 16-byte encryption block for a random nonce,
while the low 8 bytes are used for payload. When storing
a value in this block, the nonce is incremented to ensure
that
the old plaintext
must be overwritten with a random value before storing the
new plaintext, to keep the attacker from detecting consecutive
writes of the same value. In the second approach, the nonces
and the data are stored in separate locations, and the nonces
are XOR-ed onto the data as a mask. On each memory write,
the corresponding location in the mask buffer is resolved, the
mask value is updated and then XOR-ed to the new plaintext.
Finally, the masked plaintext is written to the desired memory
address. As the nonces are high entropy values and updated
independently of the written data, they are not susceptible
to the dictionary attack or collision attack. Due to its high
locality, the ﬁrst approach is better suited for small variables
(e.g., variables on the stack), while the second approach has
better support for pointer arithmetic and should thus be used
for buffers and complex data structures. Both countermeasures
could be implemented as a compiler extension, that automat-
ically applies them to variables marked as secret.
C. Software-based Countermeasures: Kernel Context Switch
While the generic software-based countermeasures are suf-
ﬁcient to protect applications in user mode, they make the
critical assumption that registers are immune to ciphertext side
channels. However, our attack in Section IV shows that the
attacker can inspect the ciphertext in the kernel’s pt_regs
structure to infer register values. To mitigate the ciphertext
leakage on register-level, we developed a kernel patch that
protects registers during context switches. We focus on the
Linux kernel, but similar methods can also be applied to other
operating systems.
Speciﬁcally, the kernel patch protects the pt_regs struc-
ture, which stores x86-64 user space registers as described
in Section II-D. We present two methods for securing this
structure. One is to insert a random nonce alongside each
register. The other is to randomize the stack location on each
context switch.
Storing a nonce alongside registers. A random 64 bits
nonce can be stored next to each register (64-bit) to add
enough randomization. In this way, on a context switch, the
kernel doesn’t simply push all registers to the stack, but
interleaves them with pushes of a random value, which is
incremented on every context switch. This method gives us
64 bits of security, which makes it impossible for the attacker
to infer the plaintext even for long running VMs. However,
this strategy comes with a major caveat: It requires signiﬁcant
changes to existing highly-optimized code paths, as a lot of
exception/signal handling functions rely on the exact offset of
the registers in pt_regs and would thus may not be adapted
by the upstream kernel committee.
Context switch stack randomization. As an alternative strat-
egy, we adapt the memory address randomization idea to the
kernel entry point stack. Instead of inserting nonces between
the saved registers, we randomize the address of the stack
where the exception/interrupt handlers store the register values
of the interrupted user space application.
This method is much less intrusive than the nonce approach
and easy to hide behind a feature ﬂag, as we only need to keep
track of stack pages and replace the stack pointer on each exit
from kernel space to user space. However, it also comes with
a high memory overhead, as we have to reserve a lot physical
memory only for the kernel entry point stacks. Also, at some
point we will run out of physical memory, giving us a hard
limit on the reachable entropy.
For example, if we assume that we have 8 GB of physical
memory which can be freely used for our stack countermea-
sure, with a stack size of 4 KB (one page) we get 221 possible
stack locations (21 bits of entropy). This is signiﬁcantly less
than the 64 bits obtained with the nonce approach, but still
considerably reduces the attack bandwidth, as the attacker
would have to wait until a stack page repeats. To assess the
practicality and the resulting overhead, we implemented the
stack randomization countermeasure in the Linux kernel.
D. Case Study: Randomizing pt regs Location
For our case study, we focused on the common ex-
ception and interrupt path described by idtentry_body
which is deﬁned in arch/x86/entry/entry_64.S. The
idtentry_body path is e.g. used for the high frequency
page fault exception as well as for the local APIC timer
interrupt. The latter is especially interesting, as it is the main
driver in determining if a task has used up its time slice,
leading to a reschedule to a different task. While interrupts
and exceptions can also occur when the CPU is already in
kernel mode, we restrict our countermeasure to events that
interrupt a user space application, as they contain the register
values that we want to protect.
Since the thread stack is empty upon entering the kernel
from user space, we can simply replace it with a newly
allocated stack. For the entry stack, randomizing the stack
upon entry to the kernel is more difﬁcult, as all general purpose
registers hold user data and thus cannot be used to perform
the change. To circumvent this, we randomize the stack on the
exit path before returning back to user space. Thus upon the
next entry, we have a fresh entry stack.
Using the regular memory allocation mechanisms of the
Linux kernel for the stack allocation proves difﬁcult, as they
were not build with guarantees regarding not returning a
recently freed page upon a new allocation. In addition, they
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:55:46 UTC from IEEE Xplore.  Restrictions apply. 
11347
share a common memory pool with the rest of the system,
which increases the collision probability under high memory
load, if taking random pages from the pool. Instead we allocate
a large chunk of memory at boot time and manage the stacks in
a ﬁrst-in-ﬁrst-out queue, maximizing the time between reuses.
To evaluate the performance of our prototype implemen-
tation, we call the cpuid instruction 10 million times in a
tight loop from a user space application. Under SEV, this is
an emulated instruction that will directly trigger the modiﬁed
code paths in idtentry_body without doing further ex-
pensive computations, allowing us to efﬁciently measure the
performance impact of the modiﬁcations to the context switch.
Using this strategy, we measured a total average overhead of
1063 nanoseconds per context switch with standard derivation
4.93. We also ran a modiﬁed benchmark, where the application
also loops over a large memory buffer each iteration, to mea-
sure the additional cache pressure created by randomizing the
kernel stack. We ran the experiment 1000000 times resulting
in a total average overhead of 2232 nanoseconds with standard
derivation 297.
VII. DISCUSSION
Secure encryption of large memory. Memory encryption is a
basic building block used in TEEs to establish the conﬁdential-
ity of data that leaves the CPU. Ideally, a probabilistic authenti-
cated encryption scheme needs to be used, as was implemented
for the ﬁrst generation of Intel SGX [16]. However, managing
and updating authentication tags and counter values consumes
additional storage, costs latency and decreases the memory
bandwidth for payload data. Thus, we do not believe that
integrity trees can scale to protect large amounts of memory,
as it is required for the conﬁdential VM usage model.
To cope with these conﬂicting properties, many conﬁdential
VM designs use a mixture of cryptography and additional,
architectural permission checks to achieve their security guar-
antees. Since random memory access latency is a critical
performance property for the entire system, ECB would be the
best candidate from a performance point of view. However, the
independent encryption of all memory blocks with the same
key leaks repetition patterns, as there is only one ciphertext for
each plaintext. Thus, current conﬁdential VM designs (AMD
SEV [22]), but also designs to be commercially available in
the near feature (Intel TDX [19] and ARM CCA [7], [8]) all
adopt a tweaked block cipher, like AES XTS/XEX. Table II
shows a more comprehensive overview. These modes offer
a middle ground between performance and security, as the
tweak mechanism offers a cheap way to ensure that the same
plaintext encrypts to different ciphertexts when stored in two
different addresses. However, for a given memory block, there
is still only one ciphertext for each plaintext. As we have seen
throughout this paper, this is the root cause of the ciphertext
side channels.
To prevent attacks on the missing integrity protection,
systems like SEV-SNP or Intel TDX and Intel SGX prevent
untrusted parties from writing to protected memory [4], [13].
Intel TDX and SGX also prevent read accesses to the cipher-
text [13], [19]. However, as discussed in Section II-C, these
checks do not prevent physical attacks like bus snooping.
Finally,
the implementation of access right checks also
comes with technical hurdles. On the one hand, they need
to be fast, as they inﬂuence the memory access latency. On
the other hand, static approaches that simply block access to
a ﬁxed range, like in Intel SGX, hinder efﬁcient memory use
and scaling. These hurdles remain open research questions to
be answered in the future works.
Side-channel resistant cryptosystems. With decades of stud-
ies on micro-architectural side channels, including cache or
TLB side channels, building side-channel resistant crypto-
graphic implementations has become a common practice. Most
practically used cryptographic libraries adopt some levels of
side-channel defenses, to prevent exploitation from a remote
attacker [1] or another user on shared machines [38], [39].
The known best practice for defeating side channels is data-
oblivious constant-time implementation, which dictates the
execution time of the cryptographic operations (or an arbitrary
portion of it) is constant regardless of the secret values used in
the computation and that branch decisions or memory accesses
may not depend on secret values. Data oblivious Constant-time
implementation has been shown to defeat all known micro-
architectural side-channel attacks, except the ciphertext side-
channel attacks discussed in this work.
The ciphertext side channel opens up a new way of exploit-
ing cryptographic code, which the data oblivious constant-time
implementation is no longer sufﬁcient to guard against. Given
the difﬁculties of securing accesses to the ciphertext through
memory access or bus snooping (Section II-C), we envision
cryptographic code to be used in TEEs with large memory
needs to adopt a new paradigm that achieves indistinguisha-
bility not only on execution time and access patterns, but on
the ciphertext values. We hope our work will inspire a new
research direction on secure implementation of cryptography,
such as tools to automate the discovery of such vulnerabilities,
compilers to transform a vulnerable code to a secure one, or
formal provers to assert the absence of such vulnerabilities.
VIII. RELATED WORK
To protect SEV-protected VMs against an untrusted cloud
service provider, SEV adopts some additional designs atop
traditional Virtualization. Some of those adjustments are chal-
lenged, including AES memory encryption, the I/O bounce
buffer and ASID-based key management. Meanwhile, some
designs inherited from AMD’s traditional hardware-based vir-
tualization are also proven to be insecure under the assumption
of the untrusted host, including the VM control block, Nested
Page Tables, and ASID-tagged TLB entries. Besides the Ci-
phertext leakage caused by VMSA, this section summarizes
other attacks against SEV.
Intercept plaintext in VMCB (SEV). The original SEV
allows the adversary to intercept and manipulate register values
inside the unencrypted VMCB. Several existing works exploit
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:55:46 UTC from IEEE Xplore.  Restrictions apply. 
12348
Table II: Comparison of hardware memory encryption-based TEEs. Drop-In replacement means that applications do not need
to be adjusted to work with the TEE. * denotes the release time of the whitepapers while the commercial machine is not
available yet. † to our understanding only a recommendation for a possible instantiation.
Project
SEV [22]
SEV-ES [21]
SEV-SNP [4]
SGX [13]
TDX [19]
CCA [7]
SGX on Ice Lake SP [20]
Vendor
AMD
AMD
AMD
Intel
Intel
Intel
ARM
Release
2016
2017
2020
2015
2021
*2020
*2021
TCB type
VM
VM
VM
Enclave
Enclave
VM
VM
TCB size
No Limit
No Limit
No Limit
256 MB [18]
up to 1 TB
No limit
No limit
Drop-In
replacement
(cid:88)
(cid:88)
(cid:88)


(cid:88)
(cid:88)