way:
1. For the root r, γ(r) ={ε }
2. For v with L(v) =(cid:21) and predecessors u1, . . . ,u n,
γ(v) = (cid:31)n
3. For v with L(v) (cid:19)= (cid:21) and predecessors u1, . . . ,u n,
γ(v) = {t.u | u ∈ L(v)∧t ∈ (cid:31)n
Intuitively, every v ∈ V represents a set of event traces,
namely the sequences of labels of paths from r to v.
In the context of CacheAudit, we need to implement
two operations on this data structure, namely (1) the join
(cid:21)E(cid:31) of two sets of traces and the (2) addition upd
E(cid:31)(S,E)
of a cache event to a particular set of traces.
For the join of two sets of traces represented by v and
w, we add a new vertex u with label (cid:21) and add edges
from v and w to u.
For the extension of a set of traces represented by
a vertex v by a set of cache events E, we ﬁrst check
whether v already has a child w labeled with E. If so, we
use w as a representation of the extended set of traces. If
not, we add a new vertex u with label E and add an edge
(u,v). In this way we make maximal use of sharing and
obtain a preﬁx DAG. The correctness of the representa-
tion follows by construction. In CacheAudit, we use hash
consing for efﬁciently building the preﬁx DAG.
440  22nd USENIX Security Symposium 
USENIX Association
Counting Sets of Traces The following algorithm
counttr overapproximates the number of traces that are
represented by a given graph.
1. For the root r, counttr(r) =1
2. For v with L(v) =(cid:31) and predecessors u1, . . . ,u n,
counttr(v) = ∑n
i=1 countτ (ui)
3. For v with L(v) (cid:30)= (cid:31) and predecessors u1, . . . ,u n,
counttr(v) = |L(v)|· ∑n
i=1 counttr(ui)
The soundness of this counting, i.e. the fact that |γ(v)| ≤
counttr(v), follows by construction. Notice that the pre-
cision dramatically decreases with larger sets of labels.
In our case, labels contain at most three events and the
counting is sufﬁciently precise.
Counting Timing Variations We currently model ex-
ecution time as a simple abstraction of traces, see Sec-
tion 3. In particular, timing is computed from a trace over
E = {hit,miss,⊥} by multiplying the number of occur-
rences of each event by the time they consume: thit, tmiss,
and t⊥, respectively. The following algorithm counttime
over-approximates the set of timing behaviors that are
represented by a given graph.
1. For the root r, counttime(r) ={0}
2. For v with L(v) =(cid:31) and predecessors u1, . . . ,u n,
counttime(v) = (cid:31)n
3. For v with L(v) (cid:30)= (cid:31) and predecessors u1 . . . ,u n,
i=1 counttime(ui)
counttime(v) =
x ∈ L(v)∧t ∈
counttime(ui)(cid:27)
n
(cid:28)i=1
(cid:30)tx +t (cid:29)(cid:29)(cid:29)(cid:29)(cid:29)
The soundness of counttime, i.e. the fact that it delivers
a superset of the number of possible timing behaviors,
follows by construction.
7 Case Studies
In this section we demonstrate the capabilities of Cache-
Audit in case studies where we use it to analyze the cache
side channels of algorithms for sorting and symmetric
encryption. All results are based on the automatic anal-
ysis of corresponding 32-bit x86 Linux executables that
we compiled using gcc.
200
150
100
50
]
t
i
b
[
e
g
a
k
a
e
L
0
4
8
16
32
Cache Size [KB]
64
128
256
Figure 5: Effect of the attacker model and preloading
(PL) on the security guarantee, for varying cache sizes.
The results are given for a 4-way set associative cache
with a line size of 64B and the LRU replacement strategy.
200
150
100
]
t
i
b
[
e
g
a
k
a
e
L
50
4
8
16
32
Cache Size [KB]
64
128
256
Figure 6: Effect of the cache line size on the security
guarantee, for Cacc and Caccd, for varying cache sizes.
The results are given for a 4-way set associative cache
with the LRU replacement strategy.
7.1 AES 128
We analyze the AES implementation from the PolarSSL
library [3] with keys of 128 bits, where we consider the
implementation with and without preloading of tables,
for all attacker models, different replacement strategies,
associativities, and line sizes. All results are presented as
upper bounds of the leakage in bits; for their interpreta-
tion see Theorem 1. In some cases, CacheAudit reports
upper bounds that exceed the key size (128 bits), which
corresponds to an imprecision of the static analysis. We
opted against truncating to 128 bits to illustrate the de-
gree of imprecision. The full data of our analysis are
given in the extended version of this paper [19]. Here,
we highlight some of our ﬁndings.
• Preloading almost consistently leads to better secu-
rity guarantees in all scenarios (see e.g. Figure 5). How-
ever, the effect becomes clearly more apparent for cache
sizes beyond 8KB, which is explained by the PolarSSL
AES tables exceeding the size of the 4KB cache by 256B.
For cache sizes that are larger than the preloaded ta-
bles, we can prove noninterference for Cacc and FIFO,
Caccd and LRU, and for Ctr and Ctime on LRU, FIFO, and
PLRU. For Cacc with shared memory spaces and LRU,
USENIX Association  
22nd USENIX Security Symposium  441
CtrCaccCaccdCtimeCtr/PLCacc/PLCaccd/PLCtime/PLCacc/32BCaccd/32BCacc/64BCaccd/64BCacc/128BCaccd/128B100
]
t
i
b
[
e
g
a
k
a
e
L
50
0
4
8
16
32
Cache Size [KB]
64
128
256
Figure 7: Effect of the replacement strategy on the se-
curity guarantee for Cacc, with and without preloading
(PL), for varying cache sizes. The results are given for a
4-way set associative cache with a line size of 64B.
100
]
t
i
b
[
e
g
a
k
a
e
L
50
4
8
16
32
Cache Size [KB]
64
128
Figure 8: Effect of the associativity on the security guar-
antee, for Cacc and Caccd, without preloading, for varying
cache sizes. The results are given for a cache with a line
size of 64B and the LRU replacement strategy.
this result does not hold because the adversary can ob-
tain information about the order of memory blocks in the
cache.
• A larger line size consistently leads to better se-
curity guarantees for access-based adversaries (see e.g.
Figure 6). This follows because more array indices map
to a line which decreases the resolution of the attacker’s
observations.
• In terms of replacement strategies, we consistently
derive the lowest bounds for LRU, followed by PLRU
and FIFO (see the extended version [19]), where the only
exception is the case of Cacc and preloading (see Fig-
ure 7). In this case FIFO is more secure because with
LRU the adversary can obtain information about the or-
dering of memory blocks in the cache.
• In terms of cache size, we consistently derive bet-
ter bounds for larger caches, with the exception of Caccd.
For this adversary model the bounds increase because
larger caches correspond to distributing the table to more
sets, which increases its possibilities to observe varia-
tions. The guarantees we obtain for Caccd and Cacc con-
verge for caches of 4 ways and sizes beyond 16KB (see
e.g. Figure 6). This is due to the fact that each cache
set can contain at most one unique block of the 4KB ta-
ble. In that way, the ability to observe ordering of blocks
within a set does not give Cacc any advantage.
• When increasing associativity, we observe oppos-
ing effects on the leakage of Cacc and Caccd (see Fig-
ure 8). This is explained by the fact that, for a ﬁxed
cache size, increasing associativity means decreasing the
number of sets. For Caccd which can only observe the
number of blocks that have been loaded into each set,
this corresponds to a decrease in observational capabil-
ity; for Cacc which can observe the ordering of blocks,
this corresponds to an increase. This difference vanishes
for larger cache sizes because then each set contains at
most one unique block of the AES tables.
Comparison to [34]:
In a recent study [34] we ana-
lyzed the PolarSSL AES implementation with respect
to access-based adversaries and LRU replacement, using
the cache component of a closed-source tool for worst-
case execution time analysis [1]. The results we obtain
using CacheAudit go beyond that analysis in that we de-
rive bounds w.r.t. access-based, trace-based, and time-
based adversaries, for LRU, FIFO, and PLRU strategies.
For access-based adversaries and LRU, the bounds we
derive are lower than those in [34]; in particular, for
Caccd we derive bounds of zero for implementations with
preloading for all caches sizes that are larger than the
AES tables—which is obtained in [34] only for caches
of 128KB. While these results are obtained for differ-
ent platforms (x86 vs. ARM) and are hence not directly
comparable, they do suggest a signiﬁcant increase in pre-
cision. In contrast to [34], this is achieved without any
code instrumentation.
7.2 Salsa20
Salsa20 is a stream cipher by Bernstein [11]. Internally,
the cipher uses XOR, addition mod 232, and constant-
distance rotation operations on an internal state of 16 32-
bit words. The lack of key-dependent memory lookups
intends to avoid cache side channels in software imple-
mentations of the cipher. With CacheAudit we could for-
mally conﬁrm this intuition by automated analysis of the
reference implementation of Salsa20 encryption, which
includes a function call to a hash function. Speciﬁcally,
we analyze the leakage of the encryption operation on
an arbitrary 512-byte message for Cacc, Ctr, and Ctime,
FIFO and LRU strategies, on 4KB caches with line size
of 32B, where we consistently obtain upper bounds of 0
for the leakage. The time required for analyzing each of
the cases was below 11s.
442  22nd USENIX Security Symposium 
USENIX Association
LRUFIFOLRU/PLFIFO/PLCacc/1-wayCacc/2-wayCacc/4-wayCacc/8-wayCaccd/1-wayCaccd/2-wayCaccd/4-wayCaccd/8-way7.3 Sorting Algorithms
In this section we use CacheAudit to establish bounds on
the cache side channels of different sorting algorithms.
This case study is inspired by an early investigation of se-
cure sorting algorithms [8]. While the authors of [8] con-
sider only time-based adversaries and noninterference as
a security property, CacheAudit allows us to give quanti-
tative answers for a comprehensive set of side-channel
adversaries, based on the binary executables and con-
crete cache models.
As examples, we use the implementations of Bubble-
Sort, InsertionSort, and SelectionSort from [4], which
are given in Section 2 and Appendix A, respectively,
where we use integer arrays of lengths from 8 to 64.
The results of our analysis are summarized in Figure 9.
In the following we highlight some of our ﬁndings.
• We obtain the same bounds for BubbleSort and Se-
lectionSort, which is explained by the similar structure
of their control ﬂow. A detailed explanation of those
bounds is given in Section 2. InsertionSort has a differ-
ent control ﬂow structure, which is reﬂected by our data.
In particular InsertionSort has only n! possible execution
traces due to the possibility of leaving the inner loop,
which leads to better bounds w.r.t.
trace-based adver-
saries. However, InsertionSort leaks more information
to timing-based adversaries, because the number of iter-
ations in the inner loop varies and thus fewer executions
have the same timing.
• For access-based adversaries we obtain zero bounds
for all algorithms. For trace-based adversaries, the de-
rived bounds do not imply meaningful security guaran-
tees: the bounds reported for InsertionSort are in the or-
der of log2(n!), which corresponds to the maximum in-
formation contained in the ordering of the elements; the
bounds reported for the other sorting algorithms exceed
this maximum, which is caused by the imprecision of the
static analysis.
• We performed an analysis of the sorting algorithms
for smaller (256B) and larger (64KB) cache sizes and
obtained the exact same bounds as in Figure 9, with the
exception of the case of arrays of 64 entries and 256B
caches: there the leakage increases because the arrays do
not ﬁt entirely into the cache due to their misalignment
with the memory blocks.
7.4 Discussion and Outlook
A number of comments are in order when interpreting
the bounds delivered by CacheAudit. First, we obtained
all of the bounds for an empty initial cache. As described
in Section 3.6, they immediately extend to bounds for ar-
bitrary initial cache states, as long as the victim does not
access any block that is contained in it. This is relevant,
e.g. for an adversary who can ﬁll the initial cache state
only with lines from its own disjoint memory space. For
LRU and access-based adversaries, our bounds extend to
arbitrary initial cache states without further restriction.
Second, while CacheAudit relies on more accurate
models of cache and timing than any information-ﬂow
analysis we are aware of,
timing-
relevant features of hardware it does not capture (and
make assertions about) yet, including out-of-order exe-
cution, which may reorder memory accesses, TLBs, and
multiple levels of caches.
there are several
Third, for the case of AES and Salsa20, the derived
bounds hold for the leakage about the key in one execu-
tion, with respect to any payload. For the case of zero
leakage (i.e., noninterference), the bounds trivially ex-
tend to bounds for multiple executions and imply strong
security guarantees. For the case of non-zero leakage, the
bounds can add up when repeatedly running the victim
process with a ﬁxed key and varying payload, leading to
a decrease in security guarantees. One of our prime tar-
gets for future work is to derive security guarantees that
hold for multiple executions of the victim process. One
possibility to achieve this is to employ leakage-resilient
cryptosystems [20, 47], where our work can be used to
bound the range of the leakage functions.
Finally, note that the bounds delivered by CacheAudit
can only be used for certifying that a system is se-
cure;