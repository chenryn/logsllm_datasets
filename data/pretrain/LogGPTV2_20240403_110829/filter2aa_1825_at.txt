_In_ LONG Adjustment,
_In_ BOOLEAN Wait);
The Increment parameter indicates the priority boost to apply to the thread that has a successful waiting
on the semaphore. The details of how this boost works are described in the next chapter. Most drivers
should provide the value 1 (that’s the default used by the kernel when a semaphore is released by the
user mode ReleaseSemaphore API). Adjustment is the value to add to the semaphore’s current count.
It’s typically one, but can be a higher value if that makes sense. The last parameter (Wait) indicates
whether a wait operation (KeWaitForSingleObject or KeWaitFOrMultipleObjects) immediately
follows (see the information bar in the mutex discussion above). The function returns the old count of the
semaphore.
Is a semaphore with a maximum count of one equivalent to a mutex? At first, it seems so,
but this is not the case. A semaphore lacks ownership, meaning one thread can acquire the
semaphore, while another can release it. This is a strength, not a weakness, as described in the
above example. A Semaphore’s purpose is very different from that of a mutex.
You can read the current count of the semaphore by calling KeReadStateSemaphore:
LONG KeReadStateSemaphore (_In_ PRKSEMAPHORE Semaphore);
Event
An event encapsulates a boolean flag - either true (signaled) or false (non-signaled). The primary purpose
of an event is to signal something has happened, to provide flow synchronization. For example, if some
condition becomes true, an event can be set, and a bunch of threads can be released from waiting and
continue working on some data that perhaps is now ready for processing.
The are two types of events, the type being specified at event initialization time:
• Notification event (manual reset) - when this event is set, it releases any number of waiting threads,
and the event state remains set (signaled) until explicitly reset.
• Synchronization event (auto reset) - when this event is set, it releases at most one thread (no matter
how many are waiting for the event), and once released the event goes back to the reset (non-
signaled) state automatically.
An event is created by allocating a KEVENT structure from non-paged memory and then calling
KeInitializeEvent to initialize it, specifying the event type (NotificationEvent or Synchro-
nizationEvent) and the initial event state (signaled or non-signaled):
Chapter 6: Kernel Mechanisms
171
VOID KeInitializeEvent (
_Out_ PRKEVENT Event,
_In_ EVENT_TYPE Type,
// NotificationEvent or SynchronizationEvent
_In_ BOOLEAN State);
// initial state (signaled=TRUE)
Notification events are called Manual-reset in user-mode terminology, while Synchronization events are
called Auto-reset. Despite the name changes, these are the same.
Waiting for an event is done normally with the KeWaitXxx functions. Calling KeSetEvent sets the event
to the signaled state, while calling KeResetEvent or KeClearEvent resets it (non-signaled state) (the
latter function being a bit quicker as it does not return the previous state of the event):
LONG KeSetEvent (
_Inout_ PRKEVENT Event,
_In_ KPRIORITY Increment,
_In_ BOOLEAN Wait);
VOID KeClearEvent (_Inout_ PRKEVENT Event);
LONG KeResetEvent (_Inout_ PRKEVENT Event);
Just like with a semaphore, setting an event allows providing a priority boost to the next successful wait
on the event.
Finally, The current state of an event (signaled or non-signaled) can be read with KeReadStateEvent:
LONG KeReadStateEvent (_In_ PRKEVENT Event);
Named Events
Event objects can be named (as can mutexes and semaphores). This can be used as an easy way
of sharing an event object with other drivers or with user-mode clients. One way of creating or
opening a named event by name is with the helper functions IoCreateSynchronizationEvent and
IoCreateNotificationEvent APIs:
PKEVENT IoCreateSynchronizationEvent(
_In_
PUNICODE_STRING EventName,
_Out_ PHANDLE EventHandle);
PKEVENT IoCreateNotificationEvent(
_In_
PUNICODE_STRING EventName,
_Out_ PHANDLE EventHandle);
Chapter 6: Kernel Mechanisms
172
These APIs create the named event object if it does not exist and set its state to signaled, or obtain another
handle to the named event if it does exist. The name itself is provided as a normal UNICODE_STRING and
must be a full path in the Object Manager’s namespace, as can be observed in the Sysinternals WinObj
tool.
These APIs return two values: the pointer to the event object (direct returned value) and an open handle in
the EventHandle parameter. The returned handle is a kernel handle, to be used by the driver only. The
functions return NULL on failure.
You can use the previously described events API to manipulate the returned event by address. Don’t
forget to close the returned handle (ZwClose) to prevent a leak. Alternatively, you can call ObRefer-
enceObject on the returned pointer to make sure it’s not prematurely destroyed and close the handle
immediately. In that case, call ObDereferenceObject when you’re done with the event.
Built-in Named Kernel Events
One use of the IoCreateNotificationEvent API is to gain access to a bunch of named event objects
the kernel provides in the \KernelObejcts directory. These events provide various notifications for memory
related status, that may be useful for kernel drivers.
Figure 6-11 shows the named events in WinObj. Note that the lower symbolic links are actually events, as
these are internally implemented as Dynamic Symbolic Links (see more details at https://scorpiosoftware.
net/2021/04/30/dynamic-symbolic-links/).
Figure 6-11: Kernel Named Events
Chapter 6: Kernel Mechanisms
173
All the events shown in figure 6-11 are Notification events. Table 6-5 lists these events with their meaning.
Table 6-5: Named kernel events
Name
Description
HighMemoryCondition
The system has lots of free physical memory
LowMemoryCondition
The system is low on physical memory
HighPagedPoolCondition
The system has lots of free paged pool memory
LowPagedPoolCondition
The system is low on paged pool memory
HighNonPagedPoolCondition
The system has lots of free non-paged pool memory
LowNonPagedPoolCondition
The system is low on non-paged pool memory
HighCommitCondition
The system has lots of free memory in RAM and paging file(s)
LowCommitCondition
The system is low on RAM and paging file(s)
MaximumCommitCondition
The system is almost out of memory, and no further increase in page files size is
possible
Drivers can use these events as hints to either allocate more memory or free memory as required. The
following example shows how to obtain one of these events and wait for it on some thread (error handling
ommitted):
UNICODE_STRING name;
RtlInitUnicodeString(&name, L"\\KernelObjects\\LowCommitCondition");
HANDLE hEvent;
auto event = IoCreateNotificationEvent(&name, &hEvent);
// on some driver-created thread...
KeWaitForSingleObject(event, Executive, KernelMode, FALSE, nullptr);
// free some memory if possible...
//
// close the handle
ZwClose(hEvent);
Write a driver that waits on all these named events and uses DbgPrint to indicate a signaled
event with its description.
Executive Resource
The classic synchronization problem of accessing a shared resource by multiple threads was dealt with by
using a mutex or fast mutex. This works, but mutexes are pessimistic, meaning they allow a single thread
Chapter 6: Kernel Mechanisms
174
to access a shared resource. That may be unfortunate in cases where multiple threads access a shared
resource by reading only.
In cases where it’s possible to distinguish data changes (writes) vs. just looking at the data (reading)
- there is a possible optimization. A thread that requires access to the shared resource can declare its
intentions - read or write. If it declares read, other threads declaring read can do so concurrently, improving
performance. This is especially useful if the shared data changes infrequently, i.e. there are considerably
more reads than writes.
Mutexes by their very nature are pessimistic locks, since they enforce a single thread at a time execution.
This makes them always work at the expense of possible performance gains with concurrency.
The kernel provides yet another synchronization primitive that is geared towards this scenario, known as
single writer, multiple readers. This object is the Executive Resource, another special object which is not a
dispatcher object.
Initializing an executive resource is done by allocating an ERESOURCE structure from non-paged pool
and calling ExInitializeResourceLite. Once initialized, threads can acquire either the exclusive
lock (for writes) using ExAcquireResourceExclusiveLite or the shared lock by calling ExAc-
quireResourceSharedLite. Once done the work, a thread releases the executive resource with
ExReleaseResourceLite (no matter whether it acquired as exclusive or not).
The requirement for using the acquire and release functions is that normal kernel APCs must be
disabled. This can be done with KeEnterCtriticalRegion just before the acquire call, and then
KeLeaveCriticalRegion just after the release call. The following code snippet demonstrates that:
ERESOURCE resource;
void WriteData() {
KeEnterCriticalRegion();
ExAcquireResourceExclusiveLite(&resource, TRUE);
// wait until acquired
// Write to the data
ExReleaseResourceLite(&resource);
KeLeaveCriticalRegion();
}
Since these calls are so common when working with executive resources, there are functions that perform
both operations with a single call:
Chapter 6: Kernel Mechanisms
175
void WriteData() {
ExEnterCriticalRegionAndAcquireResourceExclusive(&resource);
// Write to the data
ExReleaseResourceAndLeaveCriticalRegion(&resource);
}
A similar function exists for shared acquisition, ExEnterCriticalRegionAndAcquireResource-
Shared. Finally, before freeing the memory the resource occupies, call ExDeleteResourceLite to
remove the resource from the kernel’s resource list:
NTSTATUS ExDeleteResourceLite(
_Inout_ PERESOURCE Resource);
You can query the number of waiting threads for exclusive and shared access of a resource with the
functions ExGetExclusiveWaiterCount and ExGetSharedWaiterCount, respectively.
There are other functions for working with executive resources for some specialized cases. Consult the
WDK documentation for more information.
Create appropriate C++ RAII wrappers for executive resources.
High IRQL Synchronization
The sections on synchronization so far have dealt with threads waiting for various types of objects. How-
ever, in some scenarios, threads cannot wait - specifically, when the processor’s IRQL is DISPATCH_LEVEL
(2) or higher. This section discusses these scenarios and how to handle them.
Let’s examine an example scenario: A driver has a timer, set up with KeSetTimer and uses a DPC to
execute code when the timer expires. At the same time, other functions in the driver, such an IRP_MJ_-
DEVICE_CONTROL may execute at the same time (runs at IRQL 0). If both these functions need to access
a shared resource (e.g. a linked list), they must synchronize access to prevent data corruption.
The problem is that a DPC cannot call KeWaitForSingleObject or any other waiting function - calling
any of these is fatal. So how can these functions synchronize access?
The simple case is where the system has a single CPU. In this case, when accessing the shared resource, the
low IRQL function just needs to raise IRQL to DISPATCH_LEVEL and then access the resource. During
Chapter 6: Kernel Mechanisms
176
that time a DPC cannot interfere with this code since the CPU’s IRQL is already 2. Once the code is done
with the shared resource, it can lower the IRQL back to zero, allowing the DPC to execute. This prevents
execution of these routines at the same time. Figure 6-12 shows this setup.
Figure 6-12: High-IRQL synchronization by manipulating IRQL
In standard systems, where there is more than one CPU, this synchronization method is not enough,
because the IRQL is a CPU’s property, not a system-wide property. If one CPU’s IRQL is raised to 2, if a
DPC needs to execute, it can execute on another CPU whose IRQL may be zero. In this case, it’s possible
that both functions execute at the same time, accessing the shared data, causing a data race.
How can we solve that? We need something like a mutex, but that can synchronize between processors -
not threads. That’s because when the CPU’s IRQL is 2 or higher, the thread itself loses meaning because
the scheduler cannot do work on that CPU. This kind of object exists - the Spin Lock.
Chapter 6: Kernel Mechanisms
177
The Spin Lock
The Spin Lock is just a bit in memory that is used with atomic test-and-set operations via an API. When
a CPU tries to acquire a spin lock, and that spin lock is not currently free (the bit is set), the CPU keeps
spinning on the spin lock, busy waiting for it to be released by another CPU (remember, putting the thread
into a waiting state cannot be done at IRQL DISPATCH_LEVEL or higher).
In the scenario depicted in the previous section, a spin lock would need to be allocated and initialized. Each
function that requires access to the shared data needs to raise IRQL to 2 (if not already there), acquire the
spin lock, perform the work on the shared data, and finally release the spin lock and lower IRQL back (if
applicable; not so for a DPC). This chain of events is depicted in figure 6-13.
Creating a spin lock requires allocating a KSPIN_LOCK structure from non-paged pool, and calling
KeInitializeSpinLock. This puts the spin lock in the unowned state.
Chapter 6: Kernel Mechanisms
178
Figure 6-13: High-IRQL synchronization with a Spin Lock
Acquiring a spin lock is always a two-step process: first, raise the IRQL to the proper level, which is the
highest level of any function trying to synchronize access to a shared resource. In the previous example, this
associated IRQL is 2. Second, acquire the spin lock. These two steps are combined by using the appropriate
API. This process is depicted in figure 6-14.
Chapter 6: Kernel Mechanisms
179
Figure 6-14: Acquiring a Spin Lock
Acquiring and releasing a spin lock is done using an API that performs the two steps outlined in figure
6-12. Table 6-4 shows the relevant APIs and the associated IRQL for the spin locks they operate on.
Table 6-4: APIs for working with spin locks
IRQL
Acquire function
Release function
Remarks
DISPATCH_LEVEL (2)
KeAcquireSpinLock
KeReleaseSpinLock
DISPATCH_LEVEL (2)
KeAcquireSpinLockAtDpcLevel KeReleaseSpinLockFromDpcLevel
(a)
Device IRQL
KeAcquireInterruptSpinLock
KeReleaseInterruptSpinLock
(b)
Device IRQL
KeSynchronizeExecution
(none)
(c)
HIGH_LEVEL
ExInterlockedXxx
(none)
(d)
Remarks on table 6-4:
(a) Can be called at IRQL 2 only. Provides an optimization that just acquires the spin lock without changing
IRQLs. The canonical scenario is calling these APIs within a DPC routine.
(b) Useful for synchronizing an ISR with any other function. Hardware-based drivers with an interrupt
source use these routines. The argument is an interrupt object (KINTERRUPT), where the spin lock is part
of it.
(c) KeSynchronizeExecution acquires the interrupt object spin lock, calls the porovided callback and
releases the spin lock. The net effect is the same as calling the pair KeAcquireInterruptSpinLock /
Chapter 6: Kernel Mechanisms
180
KeReleaseInterruptSpinLock.
(d) A set of three functions for manipulating LIST_ENTRY-based linked lists. These functions use the
provided spin lock and raise IRQL to HIGH_LEVEL. Because of the high IRQL, these routines can be used
in any IRQL, since raising IRQL is always a safe operation.
If you acquire a spin lock, be sure to release it in the same function. Otherwise, you’re risking
a deadlock or a system crash.
Where do spin locks come from? The scenario described here requires the driver to allocate its
own spin lock to protect concurrent access to its own data from high-IRQL functions. Some spin
locks exist as part of other objects, such as the KINTERRUPT object used by hardware-based
drivers that handle interrupts. Another example is a system-wide spin lock known as the Cancel
spin lock, which is acquired by the kernel before calling a cancellation routine registered by a
driver. This is the only case where a driver released a spin lock it has not acquired explicitly.
If several CPUs try to acquire the same spin lock at the same time, which CPU gets the spin lock
first? Normally, there is no order - the CPU with fastest electrons wins :). The kernel does pro-
vide an alternative, called Queued spin locks that serve CPUs on a FIFO basis. These only work
with IRQL DISPATCH_LEVEL. The relevant APIs are KeAcquireInStackQueuedSpinLock
and KeReleaseInStackQueuedSpinLock. Check the WDK documentation for more de-
tails.
Write a C++ wrapper for a DISPATCH_LEVEL spin lock that works with the Locker RAII class
defined earlier in this chapter.
Queued Spin Locks
A variant on classic spin locks are queued spin locks. These behave the same as normal spin locks, with
the following differences:
• Queued spin locks always raise to IRQL DISPTACH_LEVEL (2). This means they cannot be used for
synchronizing with an ISR, for example.
• There is a queue of CPU waiting to acquire the spin lock, on a FIFO basis. This is more efficient when
high contention is expected. Normal spin locks provide no gauarantee as to the order of acquisition
when multiple CPUs attempt to acquire a spin lock.
A queued spin lock is initialized just like a normal spin lock (KeInitializeSpinLock). Acquiring and
releasing a queued spin lock is achieved with different APIs:
Chapter 6: Kernel Mechanisms
181
void KeAcquireInStackQueuedSpinLock (
_Inout_ PKSPIN_LOCK SpinLock,
_Out_ PKLOCK_QUEUE_HANDLE LockHandle);
void KeReleaseInStackQueuedSpinLock (
_In_ PKLOCK_QUEUE_HANDLE LockHandle);
Except for a spin lock, the caller provides an opaque KLOCK_QUEUE_HANDLE structure that is filled in by
KeAcquireInStackQueuedSpinLock. The same one must be passed to KeReleaseInStackQueued-
SpinLock.
Just like with normal dispatch-level spin locks, shortcuts exist if the caller is already at IRQL DIS-
PATCH_LEVEL. KeAcquireInStackQueuedSpinLockAtDpcLevel acquires the spin lock with no
IRQL changes, while KeReleaseInStackQueuedSpinLockFromDpcLevel releases it.
Write a C++ RAII wrapper for a queued spin lock.
Work Items
Sometimes there is a need to run a piece of code on a different thread than the executing one. One
way to do that is to create a thread explicitly and task it with running the code. The kernel provides
functions that allow a driver to create a separate thread of execution: PsCreateSystemThread and
IoCreateSystemThread (available in Windows 8+). These functions are appropriate if the driver needs
to run code in the background for a long time. However, for time-bound operations, it’s better to use a
kernel-provided thread pool that will execute your code on some system worker thread.
PsCreateSystemThread and IoCreateSystemThread are discussed in chapter 8.
IoCreateSystemThread is preferred over PsCreateSystemThread, because is allows
associating a device or driver object with the thread. This makes the I/O system add a reference