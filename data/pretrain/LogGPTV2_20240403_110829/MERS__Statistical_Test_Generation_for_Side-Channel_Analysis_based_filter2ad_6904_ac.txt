### Circuit Simulation and Trojan Detection

Our approach can simulate circuit netlists, generate MERS testsets, further tune the testset, and evaluate the effectiveness of these testsets on random Trojans. We evaluated our method on a subset of ISCAS-85 and ISCAS-89 benchmark circuits, converting sequential circuits into full scan mode for this purpose. For comparison, we also implemented the MERO [5] approach with parameter \( N = 1000 \). Our experiments were conducted on a server equipped with an AMD Opteron Processor 6378 (2.4GHz).

#### Table 1: Runtime for MERS Test Generation and Reordering

| Benchmark | Nodes (rare / total) | Run-time (s) |
|-----------|----------------------|--------------|
| c2670     | 63 / 1010            | 13370.86 (MERS), 6097.51 (MERS-h reordering), 45595.97 (MERS-s reordering) |
| c3540     | 331 / 1184           | 4154.62 (MERS), 81405.89 (MERS-h reordering), 12511.95 (MERS-s reordering) |
| c5315     | 255 / 2485           | 19903.44 (MERS), 7295.74 (MERS-h reordering), 4925.23 (MERS-s reordering) |
| c6288     | 45 / 2448            | 18166.94 (MERS), 39073.81 (MERS-h reordering), 2802.85 (MERS-s reordering) |
| c7552     | 306 / 3720           | 63502.19 (MERS), 29064.72 (MERS-h reordering), 38181.49 (MERS-s reordering) |
| s13207    | 592 / 2504           | 31201.04 (MERS), 7.24 (MERS-h reordering), 9.43 (MERS-s reordering) |
| s15850    | 679 / 3004           | 11.04 (MERS-h reordering), 0.31 (MERS-s reordering) |
| s35932    | 896 / 6500           | 25.2 (MERS), 365.02 (MERS-h reordering), 728.14 (MERS-s reordering) |

The rare threshold used to select rare nodes was set to 0.1.

### Evaluation Criteria

When applying a testset to a circuit with a Trojan, the following four criteria are used to evaluate the effectiveness of the testset:

- **AvgDeltaSwitch**: The average delta switch when applying the testset to a Trojan-infected circuit.
- **MaxDeltaSwitch**: The maximum delta switch when applying the testset.
- **AvgRelativeSwitch**: The average relative switch when applying the testset.
- **MaxRelativeSwitch**: The maximum relative switch when applying the testset. This criterion is chosen as the Side Channel Sensitivity because it directly determines whether a Trojan can be detected through side-channel analysis.

**AvgDeltaSwitch** and **MaxDeltaSwitch** reflect the activity in the Trojan, while **AvgRelativeSwitch** and **MaxRelativeSwitch** reflect the sensitivity of the side channel signal in detecting the Trojan.

For the evaluation of testsets, we expect a high-quality testset to have good coverage over all possible Trojans. In our experiments, we applied the testset to 1000 randomly inserted Trojan samples and computed these four values for each Trojan instance. The average of these four metrics reflects the capability of the testset to enable detection of different Trojans through side-channel analysis. The average **MaxRelativeSwitch** is the most suitable for evaluating Side Channel Sensitivity, which aims to maximize the sensitivity for an arbitrary Trojan in an unknown circuit location.

### Exploration of N

Figure 4 shows the distribution of **MaxDeltaSwitch** over 1000 random 8-trigger Trojan samples for two ISCAS-85 benchmarks, c2670 and c3540. We chose different values of \( N \) to generate MERS testsets and compared them with the Random (10K vectors) testset. For each testset, the box plot shows the (minimum, first quartile, median, third quartile, maximum) values of **MaxDeltaSwitch** for the 1000 Trojan samples. The plots clearly show that the distribution of **MaxDeltaSwitch** improves with increasing \( N \). For c2670, the average **MaxDeltaSwitch** for MERS (N = 1000) is 18.67, while for the Random testset it is 12.15. For c3540, the average **MaxDeltaSwitch** for MERS (N = 1000) is 11.13, while for the Random testset it is 9.19. The quality of MERS tests improves with increasing \( N \), similar to N-detect tests for stuck-at faults. The testset size also increases with \( N \). The sizes of testsets for MERS (N = 10, 20, 50, 100, 200, 500, 1000) are (71, 140, 347, 656, 1262, 3142, 6199) for c2670 and (161, 302, 742, 1441, 2858, 7070, 14250) for c3540. In most of our experiments, we chose \( N = 1000 \), which provides a good balance between testset quality and size. For fair comparison with the Random testset, we only took the first 10K vectors of the MERS testset if it was larger than 10K.

### Effect of Increased Total Switching

Figure 5 shows the average **MaxDeltaSwitch** and the average **TotalSwitch** of the testsets for 1000 8-trigger Trojan samples for different values of \( N \). For both benchmarks, the average **TotalSwitch** increases with \( N \) as well as the average **MaxDeltaSwitch**. It is evident that all MERS testsets have much larger average **TotalSwitch** compared to the Random testset. For c2670, the average **TotalSwitch** for MERS (N = 1000) is 644.9, which is about 1.25 times that of the Random testset (515.7). For c3540, the average **TotalSwitch** for MERS (N = 1000) is 808, while for the Random testset it is 649.2. The insight here is that MERS tends to increase the **TotalSwitch** of the circuit, although it is designed to increase switches in rare nodes. The following subsection will show that the proposed reordering methods effectively reduce **TotalSwitch** and thus increase side channel sensitivity.

### Effect of Weight Ratio (C)

The effectiveness of the two reordering methods, MERS-h and MERS-s, can be observed in Figures 6 and 7. As shown in Figure 6, MERS-h can reduce **TotalSwitch** and thus increase the relative switching (i.e., the Side Channel Sensitivity) compared to the original MERS testset. For MERS-s with different weight ratios \( C \), the side channel sensitivity improves steadily with a small \( C \) and then decreases when \( C \) is too large. The weight ratio balances **DeltaSwitch** and **TotalSwitch**; a large \( C \) will outweigh the influence of **TotalSwitch**, making it less different from the original MERS testset. In the following experiments, we chose the weight ratio as \( C = 5 \), providing a good balance between total switching and rare switching.

Figure 7 shows the detailed distribution of Side Channel Sensitivity for 1000 8-trigger Trojan samples with different choices of \( C \). The reordering methods effectively improve Side Channel Sensitivity, built on the fact that the original MERS testset is already of high quality in terms of **DeltaSwitch** or switching in Trojans.

### Increase in Trojan Activity

Table 2 shows that MERS (N = 1000) is very effective in creating **DeltaSwitch** caused by arbitrary Trojans due to its statistical nature. The average **Max Delta Switch** increases by 31.11%, and the average **Avg Delta Switch** increases by 187.33% on average for different benchmarks compared to the Random testset. This demonstrates the effectiveness of MERS in creating Trojan activity.

Table 3 shows that MERS is also helpful in improving **RelativeSwitch**. The average **AvgRelativeSwitch** increased by 158.16% compared to the Random testset. For the average **MaxRelativeSwitch** (Side Channel Sensitivity), MERS has an average improvement of 18.89%. However, the Side Channel Sensitivity values for benchmarks c3540 and c6288 are not as good as those of the Random testset. This is because the MERS testset also increases the total switching when it causes rare nodes to switch. This phenomenon is illustrated and explained in Figures 5 and 6, and this side effect can be improved by the two reordering algorithms as shown in Tables 4 and 5.

### Side Channel Sensitivity Improvement

We explored the parameters \( N \) for MERS and \( C \) for MERS-s. We chose \( N = 1000 \) and \( C = 5 \) in the following experiment to compare our proposed schemes with the Random testset and MERO. Tables 4 and 5 show the improvement of the proposed approaches on Side Channel Sensitivity for 4-trigger and 8-trigger Trojans.

Table 4 shows that MERS, MERS-h, and MERS-s have 10.37%, 138.44%, and 152.26% improvement over the Random testsets, respectively. While the original MERS testset is 23.95% worse than the MERO testset, MERS-h and MERS-s have 52.62% and 62.01% improvement over MERO. Table 5 shows the results for 8-trigger Trojans. Compared to the Random testset, MERS, MERS-h, and MERS-s can have 18.89%, 107.53%, and 96.61% improvement, respectively. The original MERS testset is 12.43% worse than the MERO testset, while MERS-h and MERS-s testsets can improve the Side Channel Sensitivity by 40.79% and 38.50%, respectively.

In this section, we explored the impact of different values of \( N \) for MERS and observed the effectiveness of MERS in maximizing Trojan activity as \( N \) increases. We confirmed the superiority of MERS testsets over Random testsets in creating switching activity in randomly sampled Trojans. We observed that the total switching was also likely to increase while MERS made efforts to maximize rare switching in Trojans. The two reordering methods (MERS-h and MERS-s) successfully controlled the total switching while maintaining high rare switching. The comparison with Random and MERO testsets shows the effectiveness of our test generation framework in maximizing Side Channel Sensitivity for Trojan detection.

By obtaining the limiting threshold values, beyond which any chip is classified as Trojan-infected, MERS can simultaneously maximize the switching in Trojans and minimize background switching to maximize relative switching. By calibration or reference to a golden chip, MERS helps side-channel analysis to reduce intra-die systematic process variations. Moreover, as shown in [23], various measurable parameters can be used for multiple-parameter side-channel-based Trojan detection, where at least one parameter is critical.