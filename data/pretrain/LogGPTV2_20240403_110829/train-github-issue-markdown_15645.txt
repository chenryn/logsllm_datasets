##### System information (version)
  * OpenCV =>4.4
  * Operating System / Platform => Windows 64 Bit
  * Compiler => Visual Studio 2017
##### Detailed description
I tried some models from https://github.com/AlexeyAB/darknet，as listed bellow:
模型 | 模型大小 | FPS  
---|---|---  
YOLOv2 | 194 MB | -  
YOLOv2-tiny | 43MB | 15.3  
YOLOv3 | 236 MB | 1.3  
YOLOv3-tiny | 33.7 MB | 13.3  
YOLOv3-tiny-prn | 18.8 MB | 17.1  
YOLOv3-SPP | 240 MB | -  
csresnext50-panet-spp-original-optimal_final | 217 MB | 1.8  
YOLOv4 | 245 MB | 1.2  
YOLOV4-tiny | 23.1 MB | 9.8  
enet-coco | 18.3 MB | 4.9  
It failed to load `yolov3-spp` and `yolov2` using the same code as other
models uesd.
##### Steps to reproduce
The code is listed bellow:
    import cv2
    import matplotlib.pyplot as plt
    import time
    import numpy as np
    coco_names = r"F:\opencv\sources\samples\dnn\coco.names"
    model_yolov2 = r"F:\opencv\sources\samples\dnn\yolov2.weights"
    cfg_yolov2 = r"F:\opencv\sources\samples\dnn\yolov2.cfg"
    model_yolov2_tiny = r"E:\MachineLearning\darknet\yolov2-tiny.weights"
    cfg_yolov2_tiny = "E:\MachineLearning\darknet\cfg\yolov2-tiny.cfg"
    model_yolov3 = r"F:\opencv\sources\samples\dnn\yolov3.weights"
    cfg_yolov3 = r"F:\opencv\sources\samples\dnn\yolov3.cfg"
    model_yolov3_tiny = r"E:\MachineLearning\darknet\yolov3-tiny.weights"
    cfg_yolov3_tiny = "E:\MachineLearning\darknet\cfg\yolov3-tiny.cfg"
    model_yolov3_tiny_prn = r"E:\MachineLearning\darknet\yolov3-tiny-prn.weights"
    cfg_yolov3_tiny_prn = "E:\MachineLearning\darknet\cfg\yolov3-tiny-prn.cfg"
    model_yolov3_spp = r"F:\opencv\sources\samples\dnn\yolov3-spp.weights"
    cfg_yolov3_spp = r"F:\opencv\sources\samples\dnn\yolov3-spp.cfg"
    csresnext_model = r"E:\MachineLearning\darknet\csresnext50-panet-spp-original-optimal_final.weights"
    csresnext_cfg = r"E:\MachineLearning\darknet\cfg\csresnext50-panet-spp-original-optimal.cfg"
    model_yolov4 = r"F:\opencv\sources\samples\dnn\yolov4.weights"
    cfg_yolov4 = r"F:\opencv\sources\samples\dnn\yolov4.cfg"
    model_yolov4_tiny = r"E:\MachineLearning\darknet\yolov4-tiny.weights"
    cfg_yolov4_tiny = "E:\MachineLearning\darknet\cfg\yolov4-tiny.cfg"
    enet_model = r"E:\MachineLearning\darknet\enetb0-coco_final.weights"
    enet_cfg = r"E:\MachineLearning\darknet\cfg\enet-coco.cfg"
    img_file = r"C:\Users\admin\Pictures\car.jpg"
    video_file = r'F:/opencv-4.4.0/samples/data/vtest.avi'
    model = model_yolov3_spp
    cfg = cfg_yolov3_spp
    with open(coco_names,'rt') as f:
        names = f.read().rstrip('\n').split('\n')
    def det_image_v1(model, cfg, img_file, c_threshold=0.5, nms=0.5):
        classes = names
        # initialize a list of colors to represent each possible class label
        COLORS = np.random.randint(0, 255, size=(len(classes), 3),dtype="uint8")
        print("[INFO] loading model...")
        net = cv2.dnn.readNetFromDarknet(cfg, model)
        # load the input image and construct an input blob for the image
        # by resizing to a fixed 300x300 pixels and then normalizing it
        image = cv2.imread(img_file)
        (H,W) = image.shape[:2]
        # Get the names of output layers
        ln = net.getLayerNames()
        ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]
        # generate blob for image input to the network
        blob = cv2.dnn.blobFromImage(image,1/255,(416,416),swapRB=True, crop=False)
        net.setInput(blob)
        start = time.time()
        layersOutputs = net.forward(ln)
        print(layersOutputs)
        boxes = []
        confidences = []
        classIDs = []
        for output in layersOutputs:
        	# loop over each of the detections
        	for detection in output:
        		# extract the class ID and confidence (i.e., probability) of
        		# the current object detection
        		scores = detection[5:]
        		classID = np.argmax(scores)
        		confidence = scores[classID]
        		# filter out weak predictions by ensuring the detected
        		# probability is greater than the minimum probability
        		if confidence > 0.5:
        			box = detection[0:4]* np.array([W, H, W, H])
        			(centerX, centerY, width, height) = box.astype("int")
        			# use the center (x, y)-coordinates to derive the top and
        			# and left corner of the bounding box
        			x = int(centerX - (width / 2))
        			y = int(centerY - (height / 2))
        			# update our list of bounding box coordinates, confidences,
        			# and class IDs
        			boxes.append([x, y, int(width), int(height)])
        			confidences.append(float(confidence))
        			classIDs.append(classID)
        # Remove unnecessary boxes using non maximum suppression
        idxs = cv2.dnn.NMSBoxes(boxes, confidences, c_threshold, nms)
        if len(idxs) > 0:
        	# loop over the indexes we are keeping
        	for i in idxs.flatten():
        		# extract the bounding box coordinates
        		(x, y) = (boxes[i][0], boxes[i][1])
        		(w, h) = (boxes[i][2], boxes[i][3])
        		# draw a bounding box rectangle and label on the image
        		color = [int(c) for c in COLORS[classIDs[i]]]
        		cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)
        		text = "{}: {:.4f}".format(classes[classIDs[i]], confidences[i])
        		cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,
        			0.4, color, 1)
        end = time.time()
        # print the time required
        print('FPS:', 1/(end- start))
        # show the output image
        cv2.imshow("Image", image)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    det_image_v1(model,cfg, img_file)
    def det_image_v2(model, cfg, img_file, c_threshold=0.5, nms=0.5):
        # 加载yolo模型
        net = cv2.dnn_DetectionModel(model, cfg)
        net.setInputSize(512,512) # 设置网络输入尺寸
        net.setInputScale(1.0/255)
        net.setInputSwapRB(True)
        frame=cv2.imread(img_file)
        classes, confs, boxes = net.detect(frame, c_threshold, nms)
        for id, conf, box in zip(classes.flatten(), confs.flatten(), boxes):
            label = '{}, {:.2f}'.format(names[id], conf)
            # print(label)
            labelsize, baseLine= cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX,0.5,1)
            left, top, width, height = box
            top = max(top, labelsize[1])
            cv2.rectangle(frame, box, color=(0, 255, 0), thickness=3)
            cv2.rectangle(frame, (left, top-labelsize[1]),
                         (left+labelsize[0], top+baseLine),(255, 255, 255), cv2.FILLED)
            cv2.putText (frame, label,(left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,0, 0))
        # plt.imshow(frame[:,:,::-1])
        # plt.show()
        cv2.imshow('frame', frame)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    det_image_v2(model, cfg, img_file)
I used `cv2.dnn.readNetFromDarknet()` and `cv2.dnn_DetectionModel()`， both of
them failed. The error is:
    error: OpenCV(4.4.0) C:\Users\appveyor\AppData\Local\Temp\1\pip-req-build-2b5g8ysb\opencv\modules\dnn\src\darknet\darknet_importer.cpp:207: error: (-212:Parsing error) Failed to parse NetParameter file: F:\opencv\sources\samples\dnn\yolov3-spp.cfg in function 'cv::dnn::dnn4_v20200609::readNetFromDarknet'
##### Issue submission checklist
  * I report the issue, it's not a question 
  * I checked the problem with documentation, FAQ, open issues,  
answers.opencv.org, Stack Overflow, etc and have not found solution
  * I updated to latest OpenCV version and the issue is still there 
  * There is reproducer code and related data files: videos, images, onnx, etc 