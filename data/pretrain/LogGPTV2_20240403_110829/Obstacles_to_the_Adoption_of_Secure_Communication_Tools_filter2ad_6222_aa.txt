title:Obstacles to the Adoption of Secure Communication Tools
author:Ruba Abu-Salma and
M. Angela Sasse and
Joseph Bonneau and
Anastasia Danilova and
Alena Naiakshina and
Matthew Smith
2017 IEEE Symposium on Security and Privacy
Obstacles to the Adoption of Secure
Communication Tools
Ruba Abu-Salma
M. Angela Sasse
Joseph Bonneau
University College London, UK
University College London, UK
Stanford University & EFF, USA
Anastasia Danilova
Alena Naiakshina
Matthew Smith
University of Bonn, Germany
University of Bonn, Germany
University of Bonn, Germany
Abstract—The computer security community has advocated
widespread adoption of secure communication tools to counter
mass surveillance. Several popular personal communication tools
(e.g., WhatsApp, iMessage) have adopted end-to-end encryption,
and many new tools (e.g., Signal, Telegram) have been launched
with security as a key selling point. However it remains unclear
if users understand what protection these tools offer, and if they
value that protection. In this study, we interviewed 60 partici-
pants about their experience with different communication tools
and their perceptions of the tools’ security properties. We found
that the adoption of secure communication tools is hindered by
fragmented user bases and incompatible tools. Furthermore, the
vast majority of participants did not understand the essential
concept of end-to-end encryption, limiting their motivation to
adopt secure tools. We identiﬁed a number of incorrect mental
models that underpinned participants’ beliefs.
I. INTRODUCTION
The majority of web trafﬁc between clients and servers
is now encrypted via TLS, however, the majority of com-
munications between users are not yet end-to-end (E2E)
encrypted [1], [2]. Whenever plaintext is processed or stored
by remote servers, users are vulnerable to mass surveillance [3]
or hackers. Their personal data is also subject to commercial
analysis by service providers for advertising and enhanced
personalization [4]. As a result, security experts have long
advocated increased use of E2E encryption.
Usability has long been considered a key challenge for
secure communications, especially E2E encryption. However,
the design of most communication tools (and likewise most
of the cryptographic literature on secure communication proto-
cols) has typically not involved those who are ultimately meant
to use these tools, certainly not in the early to middle stages
of design [5], [6]. Several user studies (e.g.,
[7]–[9]) have
examined why users fail to use existing secure communication
tools (e.g., PGP) correctly, often concluding that signiﬁcant
security failures arise due to user interface (UI) design ﬂaws.
Furthermore, there has been an effort to produce educational
materials (e.g.,
[10]–[12]) to explain existing security tools
and extensions, such as OpenPGP [13], Tor [14], Tails [15],
off-the-record (OTR) messaging [16], and SecureDrop [17].
These guidelines provide step-by-step instructions to install
and use these tools securely. However, documentation only
helps the users who read it and are already motivated enough
to adopt a new tool.
Recent mobile phone-based secure communication tools
have often been designed to hide security from the user com-
pletely (albeit at some security cost [1]). WhatsApp famously
deployed E2E encryption to approximately a billion users
through a code update to its application for messages, voice
calls and video communications [18], with only negligible
changes to the user experience. Some other communication
tools (e.g., Signal, Threema) have launched with security
as an explicit selling point, but
they also hide nearly all
cryptographic details.
There are key differences in the security model of dif-
ferent E2E-encrypted tools,
in addition to a large gap in
security compared to competitors (e.g., Google Hangouts,
Skype) which do not offer E2E encryption. Yet, we have little
understanding of how users perceive the threats to their com-
munications, or whether they believe secure communication
tools protect against these threats. The Electronic Frontier
Foundation (EFF) Secure Messaging Scorecard [2] is one
attempt to provide security information to non-expert users,
a kind of a “consumer guide” to secure communication tools.
However, there has been no evaluation to see if the target users
understand the scorecard, or will select more secure tools as
a result of it.
We argue that to design and build communication tools that
effectively protect users, we need to understand how users
perceive secure communications, and what inﬂuences their
decision to adopt (or not adopt) secure tools. To make a
preliminary step in this direction, we used a qualitative ap-
proach [19]–[21]. We ﬁrst conducted 10 unstructured face-to-
face interviews (35 minutes on average), followed by 50 semi-
structured face-to-face interviews (90 minutes on average).
The key qualitative insights from our interviews are:
• Usability is not the primary obstacle to adoption.
Participants reported usability issues with different tools,
but did not stop using the tools mainly because of them.
• Fragmented users bases and lack of interoperability
are signiﬁcant obstacles. The common trend of creating
new secure communication tools and assessing the usabil-
ity of these tools is a signiﬁcant obstacle to adoption due
to creating fragmented user bases. Also, to reach their
communication partners, participants needed to use tools
that are interoperable (i.e., work across different devices).
© 2017, Ruba Abu-Salma. Under license to IEEE.
DOI 10.1109/SP.2017.65
137
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:20:09 UTC from IEEE Xplore.  Restrictions apply. 
• Low Quality of Service (QoS) is an obstacle to adop-
tion. Participants assessed the reliability and security
of a communication tool by the QoS of messages and
voice calls they experienced. Low QoS does not only
hinder adoption, but also creates general doubts about
how reliable and secure the tool is.
• Sensitivity of information does not drive adoption.
Perceived sensitivity of information should drive the
adoption of secure communication tools, but this was
not the case with our participants. Instead, they used
voice calls (regardless of the tool) and other obfuscation
techniques to exchange sensitive information.
• Secure communications were perceived as futile. Most
participants did not believe secure tools could offer pro-
tection against powerful or knowledgeable adversaries.
Most participants had incorrect mental models of how
encryption works,
let alone more advanced concepts
(e.g., digital signatures, veriﬁcation ﬁngerprints). If the
perception that secure communications are futile persists,
this will continue to hinder adoption.
• Participants’ security rankings of tools were inaccu-
rate. We asked our participants to rank the tools they have
used in terms of how secure they are. Many participants
ranked the services (e.g., voice calls, messages) offered
by the tools, rather than ranking the tools ﬁrst. They
perceived calls more secure than messages. Furthermore,
they based their rankings on how large the tool’s user
base is, QoS, social factors and other criteria, rather than
assessing the security properties a secure tool offers.
• Participants did not understand the EFF Secure Mes-
saging Scorecard. The scorecard contains seven security
properties. Four of these were misunderstood: participants
did not appreciate the difference between point-to-point
and E2E encryption, and did not comprehend forward
secrecy or veriﬁcation ﬁngerprints. The other three prop-
erties reﬂecting open design (documentation, open-source
code and security audits) were considered to be negative
security properties, with participants believing security
requires obscurity.
Our ﬁndings suggest not only a gap between users’ under-
standing of secure tools and the technical reality, but also a gap
between users’ communication priorities and what the security
research community imagines them to be.
II. RELATED WORK
A. Secure Communications
For a detailed review of the literature on secure com-
munication tools, we refer the reader to Unger et al. [1].
Secure communication tools became widely available with
the release of PGP in 1991 [22], which was followed by
the creation of a large ecosystem of PGP tools [13], [23],
[24]. PGP was designed for asynchronous, high-latency email
communications. OTR [16], originally released in 2004, was
designed for low-latency messaging environments like chat
clients, introducing additional security features (e.g., forward
138
secrecy, deniability). OTR has inﬂuenced many secure commu-
nication tools designed since [25]–[30], including the Signal
protocol [31], which has recently gained popularity.
The use of self-destructing messages was popularized by
Snapchat, which was released in 2011. While popular with
users who perceived this feature as an effective solution to
some of their security and privacy needs, Snapchat offers little
security against motivated attackers, and secure data deletion
in messaging has proved elusive [32]–[34]. Other tools that
appear to provide certain security properties fail to provide
these properties in the face of government requests [3].
Usability has long been considered a challenge for secure
communications, especially E2E encryption. The main UI
challenge for E2E-encrypted communication tools is believed
to be providing assurance that a user is truly communicating
with the intended party (called trust establishment by Unger
et al. [1]). This is often reduced to verifying ownership of
cryptographic keys in some fashion. In traditional PKI, this
assurance is delivered in the form of a signed certiﬁcate from
a trusted authority [35]. However, there are many issues with
PKI associated with certiﬁcate management, including key
storage, distribution and revocation, as outlined in [36]. Pop-
ular E2E-encrypted tools (e.g., iMessage, WhatsApp, Signal)
relieve users of key management; they simply query a trusted
server that vouches for the authentic public keys of other users.
Recent proposals attempt to limit the trust in these servers
using transparency logs [37], [38], but this approach has not
been deployed in practice.
The smartphone era has seen an explosion of new com-
munication tools (typically called messengers or messaging
applications). Many of these applications claim to be “secure”,
but they often do not provide speciﬁc security guarantees or
documentation, and fail to draw upon the existing crypto-
graphic literature [1], [39]. This led the EFF to develop the
Secure Messaging Scorecard in 2014 – 2015 to attempt to
provide objective information about what security properties
communication tools actually offer, providing a Consumer
Reports-style guide and encouraging adoption of tools that
offer better security [2]. Yet, there was no evaluation of the
scorecard with the target community (i.e., users who are not
security specialists) to see if the scorecard was perceived as
helpful, or did inﬂuence users’ decision to adopt secure tools.
B. User Studies of Secure Communication Tools
Lack of usability has been shown to hamper both adoption
of secure communication tools and the actual level of security
in real-world use. In their seminal paper [7], Whitten and Tygar
designed a case study to assess whether PGP 5.0 could be
effectively used by non-specialist users to secure their email.
They identiﬁed some problems in the UI design relevant to
security risks (e.g., irreversible errors, lack of consistency and
feedback). They also found that only one-third of participants
were capable of using the PGP software to correctly sign
and encrypt an email. They concluded that making security
usable requires the development of domain-speciﬁc UI design
principles and techniques.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:20:09 UTC from IEEE Xplore.  Restrictions apply. 
Using a similar study to [7], Garﬁnkel and Miller studied
CoPilot, an email prototype based on Key Continuity Man-
agement (KCM) [8]. KCM attempts to make secure commu-
nication tools more usable by making key generation, key
management, and message signing automatic. Garﬁnkel and
Miller concluded that KCM is a workable model for improving
email security, and that the UI of CoPilot enables users to
send protected emails easily because, for example, it visually
distinguishes encrypted emails from unencrypted ones.
Ruoti et al. conducted a user study of two mail systems:
Private Webmail (Pwm) and Message Protector (MP) [40].
They found both systems to be usable, but participants trusted
MP more than Pwm because they “could see the ciphertext
after encryption takes place”, equating this with protection.
More recently, Ruoti et al. conducted a lab-based study with
pairs of novice users cooperating to send encrypted emails
with a range of email tools [41]. Again, they found that hiding
the details of how a secure system provides security reduces
trust in the system, however, participants preferred integrated
over standalone encryption solutions. They concluded that
integrated encryption solutions are a key step to increase us-
ability, but complete transparency (i.e., hiding security details)
is counterproductive. The need for visible feedback matches
the ﬁndings of Whitten and Tygar [7] as well as the “visibility
of system status” usability engineering principle encouraged
by Nielsen and Molich in 1990 [42].
Bai et al. investigated whether non-expert users can evaluate
the security trade-offs between two encryption models: a
traditional key-exchange model (analogous to PGP) and a
registration model (analogous to iMessage) [43]. They asked
participants to complete a set of encryption tasks using both
models. They also described each model’s security properties
and asked participants for their opinion. They found that
participants understood both models “fairly well”. Even though
participants recognized the beneﬁts of the exchange model
for “very sensitive communications”, they preferred (and also
trusted) the more usable, but less secure, registration model
for “everyday communications”. Bai et al. concluded that
designers should explain the security properties an encryption
tool offers, and that the EFF Secure Messaging Scorecard
provides an “excellent start in this direction”.
Other studies (e.g.,
[44]–[48]) have considered PGP fur-
ther as well as contact veriﬁcation in OTR [26], secure
communications in two-way radios [9], opportunistic email
encryption [49], and public-key ﬁngerprints [50], [51]. Fur-
thermore, several studies have explored users’ perceptions of
email signatures [52], browser security indicators (e.g.,
[53],
[54]), and speciﬁc features of speciﬁc security tools (e.g., self-
destructing messages in Snapchat [55]).
eral communications as “paranoid”) inﬂuenced participants’
decision to adopt encrypted email.
In [57], Renaud et al. proposed seven possible explanations
for the non-adoption of E2E encryption in email, based on
the literature and researchers’ own observations. To validate
these explanations, they interviewed students and staff mem-
bers (not security experts), and surveyed computer science
students. They found that,