# Obstacles to the Adoption of Secure Communication Tools

**Authors:**
- Ruba Abu-Salma
- M. Angela Sasse
- Joseph Bonneau
- Anastasia Danilova
- Alena Naiakshina
- Matthew Smith

**Affiliations:**
- University College London, UK
- Stanford University & EFF, USA
- University of Bonn, Germany

**Abstract:**
The computer security community has long advocated for the widespread adoption of secure communication tools to counter mass surveillance. Several popular personal communication tools, such as WhatsApp and iMessage, have adopted end-to-end (E2E) encryption, and new tools like Signal and Telegram have been launched with security as a key feature. However, it remains unclear whether users understand the protection these tools offer and if they value that protection. In this study, we interviewed 60 participants about their experiences with different communication tools and their perceptions of the tools' security properties. We found that the adoption of secure communication tools is hindered by fragmented user bases and incompatible tools. Furthermore, the majority of participants did not understand the essential concept of E2E encryption, limiting their motivation to adopt secure tools. We identified several incorrect mental models that underpinned participants' beliefs.

## I. Introduction

While the majority of web traffic between clients and servers is now encrypted via TLS, most communications between users are not yet E2E encrypted [1], [2]. Whenever plaintext is processed or stored by remote servers, users are vulnerable to mass surveillance [3] or hacking. Additionally, their personal data is subject to commercial analysis by service providers for advertising and enhanced personalization [4]. As a result, security experts have long advocated for increased use of E2E encryption.

Usability has long been considered a key challenge for secure communications, especially E2E encryption. However, the design of most communication tools, and much of the cryptographic literature on secure communication protocols, has typically not involved the end-users in the early to middle stages of design [5], [6]. Several user studies (e.g., [7]–[9]) have examined why users fail to use existing secure communication tools (e.g., PGP) correctly, often concluding that significant security failures arise due to user interface (UI) design flaws. There has also been an effort to produce educational materials (e.g., [10]–[12]) to explain existing security tools and extensions, such as OpenPGP [13], Tor [14], Tails [15], off-the-record (OTR) messaging [16], and SecureDrop [17]. These guidelines provide step-by-step instructions to install and use these tools securely. However, documentation only helps users who read it and are already motivated to adopt a new tool.

Recent mobile phone-based secure communication tools have often been designed to hide security from the user completely, albeit at some security cost [1]. For example, WhatsApp deployed E2E encryption to approximately a billion users through a code update to its application for messages, voice calls, and video communications [18], with negligible changes to the user experience. Other communication tools, such as Signal and Threema, have launched with security as an explicit selling point but also hide nearly all cryptographic details.

There are key differences in the security model of different E2E-encrypted tools, in addition to a large gap in security compared to competitors (e.g., Google Hangouts, Skype) that do not offer E2E encryption. However, we have little understanding of how users perceive the threats to their communications or whether they believe secure communication tools protect against these threats. The Electronic Frontier Foundation (EFF) Secure Messaging Scorecard [2] is one attempt to provide security information to non-expert users, acting as a kind of "consumer guide" to secure communication tools. However, there has been no evaluation to see if the target users understand the scorecard or will select more secure tools as a result of it.

We argue that to design and build communication tools that effectively protect users, we need to understand how users perceive secure communications and what influences their decision to adopt (or not adopt) secure tools. To make a preliminary step in this direction, we used a qualitative approach [19]–[21]. We first conducted 10 unstructured face-to-face interviews (averaging 35 minutes each), followed by 50 semi-structured face-to-face interviews (averaging 90 minutes each). The key qualitative insights from our interviews are:

- **Usability is not the primary obstacle to adoption.** Participants reported usability issues with different tools but did not stop using them mainly because of these issues.
- **Fragmented user bases and lack of interoperability are significant obstacles.** The trend of creating new secure communication tools and assessing their usability creates fragmented user bases. Participants needed to use tools that are interoperable (i.e., work across different devices).
- **Low Quality of Service (QoS) is an obstacle to adoption.** Participants assessed the reliability and security of a communication tool by the QoS of messages and voice calls. Low QoS not only hinders adoption but also creates general doubts about the tool's reliability and security.
- **Sensitivity of information does not drive adoption.** Perceived sensitivity of information should drive the adoption of secure communication tools, but this was not the case with our participants. Instead, they used voice calls (regardless of the tool) and other obfuscation techniques to exchange sensitive information.
- **Secure communications were perceived as futile.** Most participants did not believe secure tools could offer protection against powerful or knowledgeable adversaries. They had incorrect mental models of how encryption works, let alone more advanced concepts (e.g., digital signatures, verification fingerprints). If the perception that secure communications are futile persists, this will continue to hinder adoption.
- **Participants’ security rankings of tools were inaccurate.** When asked to rank the tools they have used in terms of security, many participants ranked the services (e.g., voice calls, messages) rather than the tools themselves. They perceived calls as more secure than messages and based their rankings on factors such as the size of the user base, QoS, social factors, and other criteria, rather than the security properties offered by the tool.
- **Participants did not understand the EFF Secure Messaging Scorecard.** The scorecard contains seven security properties. Four of these were misunderstood: participants did not appreciate the difference between point-to-point and E2E encryption and did not comprehend forward secrecy or verification fingerprints. The other three properties (documentation, open-source code, and security audits) were considered negative security properties, with participants believing security requires obscurity.

Our findings suggest not only a gap between users' understanding of secure tools and the technical reality but also a gap between users' communication priorities and what the security research community imagines them to be.

## II. Related Work

### A. Secure Communications

For a detailed review of the literature on secure communication tools, we refer the reader to Unger et al. [1]. Secure communication tools became widely available with the release of PGP in 1991 [22], which was followed by the creation of a large ecosystem of PGP tools [13], [23], [24]. PGP was designed for asynchronous, high-latency email communications. OTR [16], originally released in 2004, was designed for low-latency messaging environments like chat clients, introducing additional security features (e.g., forward secrecy, deniability). OTR has influenced many secure communication tools designed since [25]–[30], including the Signal protocol [31], which has recently gained popularity.

The use of self-destructing messages was popularized by Snapchat, which was released in 2011. While popular with users who perceived this feature as an effective solution to some of their security and privacy needs, Snapchat offers little security against motivated attackers, and secure data deletion in messaging has proven elusive [32]–[34]. Other tools that appear to provide certain security properties fail to provide these properties in the face of government requests [3].

Usability has long been considered a challenge for secure communications, especially E2E encryption. The main UI challenge for E2E-encrypted communication tools is providing assurance that a user is truly communicating with the intended party (called trust establishment by Unger et al. [1]). This is often reduced to verifying ownership of cryptographic keys in some fashion. In traditional PKI, this assurance is delivered in the form of a signed certificate from a trusted authority [35]. However, there are many issues with PKI associated with certificate management, including key storage, distribution, and revocation, as outlined in [36]. Popular E2E-encrypted tools (e.g., iMessage, WhatsApp, Signal) relieve users of key management; they simply query a trusted server that vouches for the authentic public keys of other users. Recent proposals attempt to limit the trust in these servers using transparency logs [37], [38], but this approach has not been deployed in practice.

The smartphone era has seen an explosion of new communication tools (typically called messengers or messaging applications). Many of these applications claim to be "secure," but they often do not provide specific security guarantees or documentation and fail to draw upon the existing cryptographic literature [1], [39]. This led the EFF to develop the Secure Messaging Scorecard in 2014–2015 to provide objective information about the security properties of communication tools, offering a Consumer Reports-style guide and encouraging the adoption of tools that offer better security [2]. However, there was no evaluation of the scorecard with the target community (i.e., users who are not security specialists) to see if the scorecard was perceived as helpful or influenced users' decisions to adopt secure tools.

### B. User Studies of Secure Communication Tools

Lack of usability has been shown to hamper both the adoption of secure communication tools and the actual level of security in real-world use. In their seminal paper [7], Whitten and Tygar designed a case study to assess whether PGP 5.0 could be effectively used by non-specialist users to secure their email. They identified problems in the UI design relevant to security risks (e.g., irreversible errors, lack of consistency, and feedback). They also found that only one-third of participants were capable of using the PGP software to correctly sign and encrypt an email. They concluded that making security usable requires the development of domain-specific UI design principles and techniques.

Using a similar study to [7], Garfinkel and Miller studied CoPilot, an email prototype based on Key Continuity Management (KCM) [8]. KCM attempts to make secure communication tools more usable by making key generation, key management, and message signing automatic. Garfinkel and Miller concluded that KCM is a workable model for improving email security and that the UI of CoPilot enables users to send protected emails easily because, for example, it visually distinguishes encrypted emails from unencrypted ones.

Ruoti et al. conducted a user study of two mail systems: Private Webmail (Pwm) and Message Protector (MP) [40]. They found both systems to be usable, but participants trusted MP more than Pwm because they "could see the ciphertext after encryption takes place," equating this with protection. More recently, Ruoti et al. conducted a lab-based study with pairs of novice users cooperating to send encrypted emails with a range of email tools [41]. Again, they found that hiding the details of how a secure system provides security reduces trust in the system. However, participants preferred integrated over standalone encryption solutions. They concluded that integrated encryption solutions are a key step to increase usability, but complete transparency (i.e., hiding security details) is counterproductive. The need for visible feedback matches the findings of Whitten and Tygar [7] as well as the "visibility of system status" usability engineering principle encouraged by Nielsen and Molich in 1990 [42].

Bai et al. investigated whether non-expert users can evaluate the security trade-offs between two encryption models: a traditional key-exchange model (analogous to PGP) and a registration model (analogous to iMessage) [43]. They asked participants to complete a set of encryption tasks using both models and described each model's security properties, asking for their opinions. They found that participants understood both models "fairly well." Even though participants recognized the benefits of the exchange model for "very sensitive communications," they preferred (and also trusted) the more usable, but less secure, registration model for "everyday communications." Bai et al. concluded that designers should explain the security properties an encryption tool offers, and that the EFF Secure Messaging Scorecard provides an "excellent start in this direction."

Other studies (e.g., [44]–[48]) have further considered PGP, contact verification in OTR [26], secure communications in two-way radios [9], opportunistic email encryption [49], and public-key fingerprints [50], [51]. Furthermore, several studies have explored users' perceptions of email signatures [52], browser security indicators (e.g., [53], [54]), and specific features of specific security tools (e.g., self-destructing messages in Snapchat [55]).

In [57], Renaud et al. proposed seven possible explanations for the non-adoption of E2E encryption in email, based on the literature and researchers' own observations. To validate these explanations, they interviewed students and staff members (not security experts) and surveyed computer science students. They found that,