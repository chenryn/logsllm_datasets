12.6h
1.4h
52.3h
3.6h
6410
7423
4865
4929
3122
3329
2229
2449
6034
6012
2.2h
51.3h
12.3h 227.5h
0.3h
18.1h
8.4h
0.1h
9.3h
0.2h
7957
7923
4926
4926
3347
3347
2457
2453
6038
6233
72.3h
16.8h
58.0h
8287
4846
3339
2406
5952
setting used by other concolic executors [56, 57, 77] and 50ms
timeout is the setting that offers a similar solving capability
as JIGSAW-1K. The next one is Angora [17]. We believe the
comparison with Angora is especially meaningful because:
(1) Our constraint collector and Angora’s taint analysis are
both implemented based on DFSan; and (2) JIGSAW uses the
same gradient-guided searching algorithm as Angora so the
main difference is the search throughput. In short, JIGSAW,
Z3, and Angora are almost identical except for how they try
to flip a particular branch: Angora [17] performs gradient-
guided search with the original program, JIGSAW performs
gradient-guided search with the JIT’ed path constraints, and
Z3 performs SMT solving with path constraints. We believe
this setup can better reflect JIGSAW’s impact on end-to-end
fuzzing. We also compared with SymCC [56], a state-of-the-art
CE engine also uses compile-time instrumentation to collect
constraints. Since it also uses Z3 as the solver, comparison
with it shows the advantages of our DFSan-based constraint
collector. The last one is Fuzzolic [10], with Fuzzy-Sat [9],
another fuzzing-based constraint solver. Note that we have
disabled input level timeout so all tools will finish flipping all
branches in one seed before moving on to the next.
Table IX shows the results over the corpora from Neuzz4.
As we can see, JIGSAW can flip branches much faster than
other tools. Z3-50ms was faster than Z3-10s but also flipped
fewer branches (i.e., achieved lower code coverage). We want
to point out that most other tools cannot even finish processing
the corpora in 24 hours, which means under a normal fuzzing
setup where the seed level timeout is enabled, they may have
problems flipping branches in deep execution traces.
Local Fuzzing. Next, we evaluated three fuzzers that are not
supported by Fuzzbench. The first one is Angora [17]. We want
to emphasize again that the comparison between JIGSAW, Z3,
and Angora (where everything is the same except the solver)
can better reflect JIGSAW’s impact on end-to-end fuzzing. Note
that for a better comparison with Angora, JIGSAW and Z3 use
Angora’s AFL mutator instead of AFL++ in this experiment.
The second one is QSYM [77], a state-of-the-art hybrid fuzzer,
paired with AFL++. The third one is Neuzz [66], which also
4https://github.com/Dongdongshe/neuzz
TABLE X: Comparing JIGSAW with other state-of-the-art symbolic
executors based on their publicly available Fuzzbench results. The
metric is median coverage reached in 24 hours. We show the results
of 16 programs where all tools generate valid results. JIGSAW takes
the lead in 7 out of 16 programs among 5 hybrid fuzzers (two from
us) and 1 non-hybrid fuzzer AFL++.
JIGSAW
Target
17956.5 17931.0 17622.0
curl
28026.0 27932.5 25496.0
freetype
8705.0 8959.0
8482.5
harfbuzz
3872.0
3701.5
2874.0
lcms
3809.0
3802.5
3810.5
libjpeg
2128.0
1914.5
2124.0
libpng
13010.5 13056.0 11097.0
libxml2
19083.5 19064.5 18577.0
libxslt
8297.0 8310.0
8260.0
mbedtls
13768.0 13778.0 13777.0
openssl
openthread 7199.5
5935.0
6919.0
5365.0
proj4
3518.0
re2
3521.5
35767.0 35886.5 35478.5
sqlite3
2169.5
2167.5
vorbis
woff2
1858.0
1934.0
Z3 SymCC SymQEMU Fuzzolic AFL++
17564.5 17599.5 17948.5
24028.0 26371.0 27956.5
8515.0 8427.0
8482.5
3770.0 3446.0
3656.0
3819.0
3814.0 3798.0
2149.5
2146.5 2080.5
12305.0 12072.0 12429.5
18592.5 18515.0 18963.5
8244.5
8268.0 8252.5
13777.0 13767.5 13779.0
5862.5
5912.0 5837.5
5836.5 5563.5
5314.0
3544.5
3519.0
3517.0
35845.5 35922.5 36699.0
2168.0 2168.0
2168.0
1936.5
1934.0
1871.5
7197.5
6785.0
3533.5
2166.5
1875.5
uses gradient-guide search. However, instead of using numerical
approximation, it uses a neural network to approximate the
program under test. The fourth one is Fuzzolic [10] with Fuzzy-
Sat [9] as the solver. Finally, we also included AFL++ [26]
(3.12c with cmplog enabled), the state-of-the-art fuzzer.
For comparison, we used the same strategy as Neuzz [66].
Specifically, all fuzzers use a larger set of initial corpus instead
of a single seed. To facilitate better reproducibility, we used
the corpora from the Neuzz repository. We chose 5 programs
from Table III: readelf, objdump, nm, size, and libxml2, as
we can find the corresponding corpus from Neuzz’s repository
and they can be successfully compiled by Angora. Note that
we did not use the binaries in Neuzz’s repository because both
JIGSAW and Angora need to compile the target program from
the source code. To ensure a fair comparison, we followed
Fuzzbench’s setting: each fuzzing trial runs inside a docker
container which is assigned and limited to one physical CPU
core. The only exception is Neuzz, which also uses a dedicated
GPU (P5000). All experiments are run 10 times, except Neuzz,
which we cannot run in parallel. We use afl-cov to measure
the edge coverage with binaries built for Neuzz.
Figure 4 shows the accumulated coverage growth. Compared
to the two Z3 configurations, JIGSAW is better on objdump and
size, worse on nm, and similar on readelf and libxml. This
is similar to the CE testing results: given enough time (i.e.,
the per-input timeout), Z3 can solve more constraints and
achieve higher coverage; otherwise, JIGSAW can go deeper
into the execution trace and flip more branches. Compared to
Angora, JIGSAW’s coverage growth is much faster, reflecting
the advantage of its higher search throughput. For the rest
fuzzers, JIGSAW is significantly better on the four binutils
programs in terms of both final coverage and the coverage
growth rate; it achieved similar final coverage as QSYM and
AFL++ on libxml, but the coverage growth rate is higher.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:24:56 UTC from IEEE Xplore.  Restrictions apply. 
1128
Fig. 4: Edge coverage growth over time for local fuzzing.
Fuzzbench. Next, we compared JIGSAW with other popular
fuzzers on Google the Fuzzbench dataset [37]. We used two
configurations of our fuzzing driver. The first one uses JIGSAW
as the solver, denoted as JIGSAW. The second one uses the
same setup except using Z3 with 10s timeout as the solver,
denoted as Z3. This setup is to show the benefit of JIGSAW
over Z3. Both configurations use AFL++ (commit 70bf4b4
with the default build and fuzz options5) for hybrid fuzzing.
The experiment is conducted by Google on its cloud. Due to
the page limit, we only provide a summary in this section. The
more detailed results are presented in §X.
Out of 13 fuzzers (11 state-of-the-art and 2 from us), JIGSAW
is 1st by average score and 1st (tied) by average rank, Z3 is
2rd by average score, and 1st by average rank. For median
coverage, JIGSAW leads in 4 programs, Z3 leads in 3 programs,
and AFL++ leads in 2 programs.
We also compared JIGSAW’s performance with other con-
colic executors based on their publicly available experiment
report6. Table X shows the result. We can see that JIGSAW
can outperform other CE engines including SYMCC [56],
SymQEMU [57], and Fuzzolic [10].
Analysis. Because our hybrid fuzzer with JIGSAW did
not outperform all other tools, including AFL++ across all
benchmarks in end-to-end fuzzing, we analyzed the results
to figure out the reason. The most important factor is the
ability to track branches that can be affected by the inputs.
Specifically, our constraint collector performs instrumentation
during the compile time so it cannot collect and update path
constraints in uninstrumented third-party libraries and across
system calls (e.g., when the input is written to another file and
read back). As a result, it may try to flip fewer branches
than runtime-instrumentation-based tools like QSYM [77]
and SymQEMU [57]. In addition, all the evaluated concolic
executors did not support tracking of floating-point number
constraints, so they would not try to flip branches with floating-
point number constraints. On the contrary, fuzzers like AFL++
can flip such branches.
The second issue is that the existing hybrid fuzzing scheme
cannot fully utilize JIGSAW’s fast-solving capability. Specifi-
cally, our hybrid fuzzer used the branch filter from QSYM [77]
to determine whether a branch should be flipped or not. Because
5https://github.com/google/fuzzbench/blob/master/fuzzers/aflplusplus/
6https://www.fuzzbench.com/reports/experimental/2021-07-03-
fuzzer.py
symbolic/index.html
this filter is coarse-grained, many branches will be filtered. As
a result, JIGSAW ended up idling most time of the fuzzing
campaign. We believe a new hybrid fuzzing scheme is required
to address this issue and leave it for future work.
Finally, the performance of a (hybrid) fuzzer is also con-
strained by other well-known factors, such as (1) the fuzzing
harness [3, 39], which limits the upper bound of the code
coverage that can be achieved (e.g., all fuzzers saturated the
coverage on some FuzzBench programs), and (2) scheduling
(e.g., which input to fuzz next and which technique (mutation
or constraint solving) to apply).
Summary. Based on these three experiments, we conclude
that the answer to RQ4 is yes: our approach can improve the
performance of coverage-guided testing.
C. Threat to Validity
There are three major threats to the validity of our evaluation.
First, although we tried to use a relatively large and diverse set
of programs for evaluation, it cannot represent all programs,
so the conclusion may not be generalizable to all programs.
Similarly, because our constraint collector and JIGSAW only
handle bitvector constraints, the conclusion may not be general-
izable to other types of constraints SMT solvers support, such
as floating-point numbers and strings. Second, the end-to-end
performance of a coverage-guided testing tool depends on many
aspects. Besides the speed of branch flipping, it also depends
on path/seed scheduling, branch filtering, seed synchronization,
randomness, etc. Although we have performed each experiment
several times and used statistical tools, the result may not truly
reflect the advantages and drawbacks of our approach. Finally,
our prototype implementation could have bugs. During our
evaluation, we have identified and fixed several bugs that led
to poor coverage, but there could be more bugs that we have
missed.
VII. DISCUSSION
In this section, we discuss the limitations of our current
prototype and potential future works.
Faster JIT Engine.
In our current prototype, LLVM’s JIT
engine is a main performance bottleneck (i.e., JIGSAW spends
similar time on JIT as time on solving). We expect a faster
JIT engine that can directly compile the AST into native code
(e.g., the tiny code generator from QEMU) can help further
improve the performance and scalability of JIGSAW.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:24:56 UTC from IEEE Xplore.  Restrictions apply. 
1229
0.040.020.000.020.04time (hour)0.040.020.000.020.04number of edgesJIGSAWAngoraZ310SZ350MSNEUZZQSYMFUZZOLICAFL++13691215182124200040006000800010000objdump13691215182124100020003000400050006000size136912151821240200040006000800010000120001400016000readelf1369121518212410002000300040005000600070008000nm1369121518212420003000400050006000700080009000xmlBetter Task Scheduling. Different constraints require different
numbers of iterations to solve. Right now we use a single
timeout for all tasks. As a result, if we make this timeout too
large, more complex constraints may block simpler constraints
and reduce the total branch flipping rate; on the other hand, if
we make this timeout too small, we may not be able to solve
those more complex constraints. We plan to adopt an OS-style
scheduler to balance this. Essentially, we can prioritize simpler
constraints to be solved first but still allow more complex
constraints to run for a much longer time.
String and Floating-point Operations. Due to the limitation
of concolic execution engines (both QSYM [77] and our DFSan-
based executor), our current prototype neither collects nor
solves constraints involving string and floating-point operations.
However, as shown in previous work [45, 53], even random-
mutation-based fuzzing can be more efficient
than SMT
solvers in solving constraints involving string and floating-point
operations. We believe it is possible to apply their algorithms
to JIGSAW. We will explore this direction in future work.
Better Searching Algorithms. Since the main focus of
JIGSAW is to improve the execution throughput, we did not
spend too much effort on improving the search algorithm itself
and simply adopted the numeric gradient descent algorithm
from Angora [17]. While this algorithm is general, it is not the
most efficient one [9] and does not work very well when the
number of conjunct constraints is large. We plan to investigate
and adopt other searching heuristics, including ones from SMT
solvers to overcome this limitation.
VIII. RELATED WORK
A. Improving Search Accuracy
The main task for automated test generation is solving
branch constraints. There are two main ways to improve
the performance of branch constraint solving. The first way
is to improve the efficiency of the solving algorithm. To
solve complex constraints or constraints with tight conditions
(e.g., magic bytes matching), researchers have proposed many
solutions. Vuzzer [60] uses taint analysis to find magic bytes
matching and solves them by copying the expected values.
Steelix [44] and REDQUEEN also aim to solve magic bytes and
simple input transformation but use offset inference instead of
heavy dynamic taint analysis. TaintScope [73] and T-Fuzz [54]
avoid complex constraints (e.g., checksum check) by patching
the corresponding branches. The problem with these approaches
is that they only target one or few types of constraints and
thus are not very generalizable.
Angora [17] and Matryoshka [18] use taint analysis to collect
input dependencies and use numerical gradient descent to solve
branch constraints. Eclipser [20] uses coverage information
to infer input dependencies and then uses binary search to
solve branch constraints. GreyOne [27] also uses coverage
information to infer input dependencies but
the scope is
expanded to both direct dependencies and indirect dependencies,
then it uses a genetic algorithm to solve the constraints.
Whitebox fuzzers [11–15, 19, 31, 32, 64, 77] collect branch
constraints as symbolic formulas and use SMT solvers to solve
them. While SMT solvers are very powerful, they are not very
efficient at solving constraints over floating-point and strings.
To overcome this limitation, researchers have proposed using
a deep neural network to simulate the target constraints and
solve them using gradient descent [67]. They have also shown
that random-mutation-based fuzzing can be more efficient at
solving these constraints [45, 53].
JIGSAW does not aim to improve the efficiency of the solving
algorithm. We simply adopted the numeric gradient descent
algorithm from [17]. Our goal is to improve search throughput.
B. Improving Fuzzing Throughput
When a branch solving algorithm is fixed, another way to
improve the performance of branch solving is to improve the