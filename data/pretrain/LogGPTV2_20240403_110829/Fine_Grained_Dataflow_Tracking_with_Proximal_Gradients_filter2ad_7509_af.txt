### Floating Point Gradient Information Performance

The use of floating point gradient information in PGA (Probabilistic Gradient Analysis) significantly outperforms PGA with binary gradients for all tested programs. This indicates that precise gradients are crucial for the performance gains achieved by PGA, as they allow for more accurate composition over multiple operations.

### Compiler Optimization Impact

We evaluated the impact of compiler optimization levels on dataflow accuracy at three optimization levels: -O0, -O1, and -O2. Table 5 summarizes the effects of these compiler optimization levels on dataflow F1 accuracy. Increasing the compiler optimization level slightly reduces the accuracy of both PGA and DTA (Dynamic Taint Analysis) by less than 3.6% for both -O1 and -O2. On average, PGA is at least 18% more accurate than DTA across all three tested optimization levels.

### Neutaint Hotbyte Evaluation

Neutaint's neural network-based approach excels in identifying hot bytes (input bytes that significantly influence program behavior) but performs poorly in fine-grained dataflow prediction. We conducted the hot byte evaluation described in [43] on PGA. The results, summarized in Table 6, show that PGA predicts hot bytes with 43.75% accuracy, while Neutaint achieves 64.25% accuracy. We view Neutaint as a complementary method to PGA, where PGA is better suited for fine-grained dataflow prediction, and both methods can be used together in program analysis.

### Zero Gradient Analysis

PGA avoids over-tainting by computing zero gradients on instructions that DTA would mark as tainted. To determine where and how PGA is more precise, we analyzed the distribution of zero gradients across programs and instruction types. For each program and instruction type, we counted the number of times the instruction had a zero gradient in the execution traces from the accuracy evaluation. Table 8 presents the results of this analysis.

### QIF Comparison

We compared PGA with the latest version of the publicly available QIF tool, Flowcheck [28]. We performed a similar experiment to Section 5.2.1, but since Flowcheck does not support byte-level granularity, we computed accuracy by aggregating flows over all bytes to ensure a fair comparison. PGA outperformed Flowcheck by 22% on average in terms of F1 accuracy, as summarized in Table 7.

### Runtime and Memory Overhead

#### Program Overhead

We evaluated the runtime and memory overhead introduced by our implementation of PGA and compared it to dfsan for a single taint/gradient source. Each program was executed 5,000 times, and each measurement was repeated five times to average the runtime and memory usage. Tables 9 and 10 detail the runtime and memory overhead per program. In the worst case, PGA has 21.7% greater overhead in runtime and 21.5% in memory relative to DTA, but on average, it adds only 3.21% relative overhead in runtime and 1.48% in memory. Libdft, which uses binary instrumentation, adds significantly more overhead.

### Edge Coverage Improvement

We also evaluated whether the gradient information from PGA can improve the performance of state-of-the-art fuzzers like NEUZZ and VUzzer. We modified NEUZZ to use PGA gradients to guide its mutation strategy. Table 11 summarizes the new edge coverage for each program over 24 hours by three different fuzzers. Overall, PGA+NEUZZ improves NEUZZ's edge coverage by an average of 12.9%. The improvement is attributed to the more precise gradients produced by PGA compared to the neural-network-based gradients used by NEUZZ. VUzzer encounters an error in its taint tracking on minigzip and crashes, leading to low edge coverage for djpeg due to the high overhead of PINâ€™s dynamic binary instrumentation for taint tracking.

Note that our results differ slightly from the original NEUZZ and VUzzer results due to differences in test environments, input corpuses, and program versions.