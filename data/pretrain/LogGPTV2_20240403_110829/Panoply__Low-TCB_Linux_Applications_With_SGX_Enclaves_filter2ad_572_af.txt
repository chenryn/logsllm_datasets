### Detection and Utilization of Hardware AES Support

When the hardware supports AES (Advanced Encryption Standard) instructions, cryptographic operations leverage these hardware capabilities. If not, they fall back to a software-based implementation. In our experiments, we observed that the OpenSSL library, when executed within the enclave, fails to detect the presence of AES-NI (AES New Instructions) support in the hardware. Consequently, it resorts to a slower AES routine, which increases latency by consuming more CPU cycles. We suspect that the SDK (Software Development Kit) does not yet support the execution of the `cpuid` instruction inside the enclave, a change also proposed by previous work [21].

It is worth noting that the Linux SDK itself does not utilize hardware AES-NI instructions for encryption and decryption. Instead, it relies on a software implementation of the AES routine, as highlighted in recent public disclosures [34]. In our case studies, this results in a 20% increase in the total execution time for each encrypt/decrypt operation.

### Comparison with Graphene-SGX

Our design does not significantly degrade performance compared to Graphene-SGX. To evaluate this, we tested various sizes and frequencies of data written out of the micron-enclave, as this is a primary factor for PANOPLY overheads. We configured an SSL client-server setup and measured the CPU execution time for six configurations: 512/2014 bytes of data for 10/100/1000 client connections. Figure 9 illustrates the performance of Graphene-SGX and PANOPLY. For these configurations, PANOPLY has 5-10% higher overheads than Graphene-SGX.

To provide a more comprehensive comparison, we ported the LMBench benchmark to PANOPLY, which is also supported by Graphene-SGX. Figures 8 and 10 present the latency and bandwidth performance of both systems. Our first observation is that both systems exhibit significant performance overheads compared to a native application running without any enclave infrastructure. This reiterates our earlier findings that the slowdown due to enclave lifecycle operations (create and destroy) is common to any system using SGX. Secondly, the memory latencies of PANOPLY and Graphene-SGX are comparable. As shown in Figure 8, PANOPLY's latency is almost always lower than that of Graphene-SGX, although both systems have similar overheads over the absolute baseline. Finally, we measured the bandwidth for various types of operations, including network, memory, and file I/O, for both systems. PANOPLY performs comparably to Graphene-SGX for memory and network operations (Figure 10). For file-backed `mmap` operations, PANOPLY shows a noticeably higher overhead than Graphene-SGX. This is because PANOPLY performs these operations via the libc interface, resulting in a higher number of enclave entries and exits per operation. In contrast, Graphene-SGX uses a narrower interface, leading to fewer enclave transitions for file I/O, which contributes to the observed bandwidth variation.

### Related Work

PANOPLY represents a new design point in the SGX enclave design space, achieving a low TCB (Trusted Computing Base) while maintaining expressiveness for enclave-bound code. PANOPLY's inter-micron flow integrity ensures a higher level of security, unlike previous systems that focus on low-level confidentiality primitives [47], [48]. Below, we discuss how PANOPLY differs from existing systems in terms of TCB, design goals, scope, and end-to-end guarantees.

#### TCB

PANOPLY's design is guided by the "delegate-rather-than-emulate" philosophy, which is key to lowering the TCB. Specifically, we do not perform namespace management inside the enclave, a common approach in library OS designs. Library OSes aim to achieve a narrow ABI (Application Binary Interface) to maintain compatibility and portability, implementing much of the system logic inside the library OS to map system call APIs to their narrow ABI. In PANOPLY, we expose a larger POSIX API to microns and delegate all system logic to the underlying operating system. This is a reasonable choice because the OS can perpetrate the same set of attacks even with a narrow interface. Thus, our design allows us to keep system libraries such as libc outside the TCB while achieving the same level of security.

#### Security of Single Enclave

PANOPLY is the first system to demonstrate control and data-flow attacks on enclave-enclave interactions. It prevents such attacks by ensuring inter-micron flow integrity. Recent works have pointed out that enclaves are susceptible to side-channel attacks via page faults [55] and cache [28]. Currently, PANOPLY does not guarantee defenses against such side-channels, but applications can employ off-the-shelf defenses proposed recently [29], [38], [43], [44]. Weichbrodt et al. [53] showed that if the enclave logic contains use-after-free or TOCTOU (Time of Check to Time of Use) bugs, the OS can exacerbate these bugs to perpetrate control-flow attacks inside the enclave code. PANOPLY assumes that the enclave is free of any logic or memory bugs. Strackx et al. highlight that adversaries can shut down enclaves and abuse the execution through hardware state-replay attacks [49], [50]. PANOPLY can use their proposed solution to ensure hardware state contiguity in the future.

#### Partitioning Applications for SGX

PANOPLY enables expressive enclave-bound code with a low TCB, allowing maximum application logic to be executed inside one or more microns while maintaining security guarantees. However, PANOPLY leaves the choice of partition design to the security architect [22], [24], [35]. Jain et al. [32] propose using enclaves to protect Tor DA server keys against well-known attacks [14], [15]. Kim et al. [36] propose designs to use SGX for networking applications such as SDN-based inter-domain routing, Tor directory servers, and ORs. Atamli-Reineh et al. [20] propose four partitioning schemes ranging from coarse-grained (single enclave for the whole application) to ultra-fine (one enclave per application secret) for executing the OpenSSL library in enclaves.

#### SGX Containers & Sandboxes Using Enclaves

Scone [19] is a concurrent system that uses Intel SGX enclaves to isolate Docker containers in a public cloud setting. The key design differences between Scone and PANOPLY include:
1. **Interface Level**: PANOPLY exposes a POSIX-level interface, whereas Scone exposes a system call interface to the enclaves. As a result, PANOPLY does not execute any libc library inside the enclave, while Scone executes musl libc.
2. **Execution Model**: PANOPLY performs synchronous exits for executing code outside the enclave, while Scone uses asynchronous exits. These variations lead to different TCB, performance, and system challenges.
3. **Threading Model**: PANOPLY's on-demand threading model spawns new microns in separate enclaves to scale the number of threads, associating each thread in the application with a unique thread in the enclave. Scone uses an M:N threading model, multiplexing on a limited number of existing threads in a single enclave.
4. **Multi-Process Support**: PANOPLY is designed for multi-process applications, supporting multiple micron containers and user processes with in-built support for fork, exec, clone, and secure communication interfaces. Scone only supports single-container processes running inside a single enclave.

Ryoan [31] is another concurrent work for executing distributed SGX native client (NaCl) sandboxes. PANOPLY's execution model for multi-micron applications differs from Ryoan, as in PANOPLY, all microns belonging to the same application trust each other. Ryoan introduces a request-oriented data model where each enclave processes input only once, confining user-data to itself while allowing mutually distrustful parties to compute over sensitive data. In Ryoan, NaCl executes system calls, and all buffer and file I/O operations are backed by in-enclave memory.

### Conclusion

PANOPLY bridges the gap between the expressiveness of SGX-native abstractions and the requirements of feature-rich Linux applications. It offers a new design point, prioritizing TCB over performance without sacrificing compatibility, achieving two orders of magnitude lower TCB than previous systems.

### Acknowledgments

We thank Mona Vij and Simon Johnson from Intel for their feedback. Thanks to Chia-Che Tsai and Donald Porter for releasing code and discussions on Graphene-SGX. This research was partially supported by a grant from the National Research Foundation, Prime Minister's Office, Singapore under its National Cybersecurity R&D Program (TSUNAMi project, No. NRF2014NCR-NCR001-21) and administered by the National Cybersecurity R&D Directorate.

### References

[References listed here as in the original text.]

This revised version aims to improve clarity, coherence, and professionalism, making the content more accessible and understandable.