thoroughlyreviewed.com,
top10news.com, and WirelessShack.org
TheWirecutter.com,
Product category
Smart home devices
Multimedia devices
Printers
Tablets
Wearable electronic devices
Computers and accessories
Consumer software
Networking devices
Smart toys and gadgets
Drones
Video games
Cameras
Automotive GPS devices
Photo frames
Sample size
Number of devices
13
12
6
6
6
5
5
5
5
3
3
2
2
2
75
Table 1: The categories of target products selected for use
in the study; each product is marketed by a unique contact
company.
represent the approximate end points of the low, middle and top
thirds of the revenue distribution.
Together, the companies selected for this study have a combined
revenue amounting to over 1.5 trillion dollars, or about 8% of the
U.S. gross domestic product.
2.3 Product selection
Having selected a set of target companies, we identified one product
from each company that could plausibly be the target of vulnera-
bility research. Popular and noteworthy products are particularly
desirable targets for vulnerability researchers, as they might have
a monetary reward attached (e.g. bug bounty programs), and could
enhance the researcher’s reputation. We used two distinct methods
to select the products under test.
The most reviewed items on amazon.com. We presume the
number of reviews for a product listing on amazon.com is a rea-
sonable metric of product popularity. For each company identified
previously, we selected the product which complied with our crite-
ria and had the highest number of reviews, limiting the search to
the first three pages after filtering by manufacturer.
Press lists of consumer products. In some limited instances, a
selected manufacturer did not sell their product on Amazon, or
the number of reviews did not give us confidence that the product
was all that popular. In such cases, we used additional sources
from the technology-consumer press, as listed above, to identify an
appropriate product.
2.4 Contact selection
We hypothesized that the authorization request addressees may
impact how they are handled within an organization. Requests
directed to corporate counsel may engender a more legalistic re-
sponse, while more informal requests of broader scope directed to
the personnel responsible for software security may not. To illumi-
nate that question, we prioritized technical managers for the contact
employee selection, and measured how many of the contacts were
(explicitly) forwarded to legal. Of the responsive companies (n=30),
70% had a technical contact employee.
LinkedIn Search. LinkedIn is a professional network with over
130 million members in the United States [30]. The platform had
several distinct advantages for our study:
• It established the presence of a U.S.-based workforce that
could appropriately handle a request, given our objective of
illuminating federal policy;
• The profiles there contain a range of self-reported, publicly-
available data points about employees in our target com-
panies, which might help us disentangle the impact of the
request addressee on the request outcome;
• Finally, the network’s extensive footprint make it suitable
for finding people at organizations ranging from early-stage
startups to very large corporations.
Our search protocol was relatively simple: we used the “advanced
search” feature and filtered by current company and location (U.S.
only). We prioritized contacting senior management in technical
functions, and populated profiles with a higher number of connec-
tions.
We used publicly available tools such as lead-generation sites [1,
10, 20], Google Chrome extensions [4, 14, 15], and email verification
tools [3, 5, 7, 9, 12, 18] to find and verify email addresses for the
target employees identified on LinkedIn. Some addresses produced
“risky” assessments, e.g. when a mail server flags all handles as
valid (catchall). In those cases, we did the verification by sending
two emails from an account belonging to a fictitious person: one
to the intended address; and another to a bogus address such as
sslkgjsfg8975@example.com. In most cases, the bogus address
would explicitly bounce our email, whereas the other email would
not generate a bounce warning.
General Counsel or Chief Legal Officer. Our verification proto-
col cannot guarantee that an email was delivered to the inbox of a
real person, let alone that that person opened the communication
and explicitly decided to ignore it. Since we wanted to assert with
higher confidence whether or not our request was processed, we
sent regular letters (via registered, private courier) to the general
counsel listed on the corporate website for the companies that did
not respond to our email request.
2.5 Procedure
Having identified a set of target companies and then a product
and contact at each company, we were ready to contact each com-
pany. In an effort to most faithfully replicate the steps an actual
researcher would take, we started with the most lightweight form
of communication—email—and only escalated to postal mail if nec-
essary. We eschewed telephonic communication due to the inherent
challenges in standardizing interactive dialogues in real time and
to avoid imposing undue burden on the companies under test.
We divided the study into two rounds, so that, should we en-
counter a problem with our methodology, we could correct it for
the remainder of the sample. In the first round, we randomly as-
signed 10 products to the senior faculty member. We encountered
no problems during the first round and proceeded to randomly
Researcher type
Junior faculty
Senior faculty
U.S. ind. researcher
E.U. ind. researcher
All groups
Targets
29
9
17
20
75
letter
Email Email then
only
20
6
3
3
32
2
2
—
0
4
No
resp.
7
1
14
17(2)
39
Table 2: Breakdown of the method that was effective in elic-
iting company responses per researcher. The U.S. researcher
did not opt-in to our regular mail contact stage, and two of
the 17 letters mailed by the E.U. researcher were returned to
sender.
Dear Company Representative,
My name is Joe Hacker and I am a security analyst at Hacking
Hackers, Inc., one of the nation’s leading institutions working on
cybersecurity and vulnerability analysis. Currently, my team is
investigating vulnerabilities of computing devices, and we would
like to include your product Sample Product in our tests. This email
is a formal request for permission to evaluate, alter, and potentially
circumvent security mechanisms (as defined by the Digital
Millennium Copyright Act - U.S. Title 17 Section 1201) of the
Sample Product for legitimate research purposes.
Should you have any questions regarding this request or the
nature of our research, please contact me or browse our recent
publications at www.example.com.
Sincerely,
Joe Hacker
Senior Security Analyst
Hacking Hackers, Inc.
Figure 1: Sample first email. The underlined sentence was
included in approximately half of the requests.
assign 30 products to the junior faculty member and 20 to each of
the independent researchers for the second round.
Initial contact. In each round, we created a properly instantiated
version of the letter shown in Figure 1 for each contact address, with
the obvious adaptations for each company, product, industry and
contact person. We varied only one sentence (underlined) which
changed the overall tone of the request and, we hypothesized, made
one version more likely to be forwarded to the legal department or
its equivalent. Each researcher sent approximately the same number
of emails with and without the modifying legal sentence. We then
asked each researcher to send the letters to the corresponding
contact address at the company using their normal email account
and include us in the BCC line and asked them to forward us any
replies.
We were forced to excluded five companies at this stage of the
experiment for the following reasons: the junior researcher received
one response that the company had sold the product line to another
company we had already contacted, the senior researcher excluded
one company from the contact list because of existing work involv-
ing the company; and three of the emails sent by U.S. independent
researcher bounced and we were unable to find alternative contact
addresses. Table 2 shows the number of targets assigned to each
researcher and the breakdown of their responses.
Email interaction. In some cases, the initial letter sent by the
researchers generated a request for more information from the
company. For these, we crafted a response and asked the researcher
to send it to the company. Whenever the company requested more
details about the testing, we had a fixed corpus of responses to draw
from. The text of the first follow-up we sent was some version of:
In general, the students are interested in exploring
what kinds of network vulnerabilities might exist in
product category and will mirror the kinds of assess-
ments that we’ve done in the past. Regarding specific
tests, expect that our students will use a combination
of fuzz testing against network interfaces, reverse
engineering using tools like IDA Pro, runtime taint-
tracking of input buffers and so on. We may publish
our findings (subject to coordinated disclosure) at a
technical conference.
Please do let me know if there are any other aspects
of our study I could clarify further, and which steps
we could take to obtain Company’s authorization.
We often provided a second follow-up, usually after the firm
requested information about the working process of the researcher,
which described the researcher’s methodology in very high-level
terms. One such example with an audio device manufacturer is
below.
Currently we are assessing consumer bluetooth audio
devices, including speakers and headphones. Our stu-
dents will be looking for vulnerabilities that can be
exploited without physical access to the devices, for
example infiltrations that can be accomplished from
a remote network location.
In general, we are looking for vulnerabilities that
could be exploited by a malicious actor to compromise
the device’s correct and safe operation, and potentially
access data stored in the host cellphone or computer.
We follow responsible disclosure practices, and would
keep Company informed of our findings. Our goal is to
help manufacturers address previously undiscovered
vulnerabilities, so we would coordinate the disclosure
(either at a technical conference or elsewhere) with
you.
When a company requested a phone call, which nine of them
did, we ignored the phone call request (while not explicitly denying
it) and simply continued to respond via email. Of these exchanges,
three companies ended up approving the request anyway. The
other six stopped responding to our emails, and we terminated the
exchange.
Postal followup. As noted above, we also attempted to reach each
company that did not respond by email by sending a registered
letter to the company’s legal department by post. The content of
Figure 2: Timeline of researcher outgoing communications; companies are ordered by the length of the engagement. We in-
clude only the 36 companies that responded to any of our communications.
the letter was very similar to that of the email request, with a minor
addition: “Please note that, despite our best efforts, we could not
obtain authorization from your company by electronic means.” In
25% of cases, this resulted in an email sent by the company to the
researcher. In one case, a company representative called the faculty
involved and conditionally granted the request. Companies only
responded to (a subset of the) letters sent by academic researchers;
most were unanswered while two of the letters mailed by the E.U.
researcher were returned as undeliverable.
3 AUTHORIZATION STUDY RESULTS
We now present the results of our authorization study, focusing
first on the quantity and types of responses we obtained, and then
analyzing whether either was influenced by our test variables (in-
cluding researcher type and whether the DMCA was mentioned
explicitly), as well as external factors such as company ownership
and whether legal staff was explicitly engaged.
3.1 Company responsiveness
We find that, for the subset of companies that responded to our
initial requests, typical response times ranged from same day to a
few weeks, although several took significantly longer to resolve;
e.g., one approval was not received until eight months later. Figure
2 shows this variability in response time and researcher workload.
The interaction with each company is depicted as a timeline starting
from initial contact; each communication is marked as a point on
the line, and the entire line is colored according to the final outcome
of the exchange. The four physical letters (that generated responses)
are marked with red circles.
3.1.1 Classification of responses. We coded all responses to ad-
dress three questions: Did the company engage with our request?
If so, did the firm respond to the request definitively? And for those
that granted our request, what conditions did they seek to impose
on the research? These classifications result in the following seven
mutually distinct result conditions:
Unresponsive: The company did not respond to our emails,
nor postal mail to general counsel (if applicable).
Rejected: The company explicitly rejected our request.
Unconditionally granted: The company explicitly granted
our request with no restrictions or requirements imposed
on the research.
Conditionally granted: The company explicitly granted our
request and imposed certain restrictions or requirements on
the research.
Indeterminate: The company initially engaged with our re-
quest, but the exchange did not conclude with a definitive
response.
Terminated: We terminated the exchange due to deviations
from the prescribed protocol, usually following a phone call
request.4
Unless indicated otherwise, in the following analysis we refer to
requests that were either conditionally granted or unconditionally
granted simply as granted. Further, we exclude the 16 unresponsive
companies that only received electronic communications (the U.S.
independent researcher did not send mailed letters, and two of
the E.U. independent researcher’s letters were returned), as we
4We decided not to pursue phone calls for two reasons: we would not have fine-grained
control over the exchange, as we had with written communications; and also to be
mindful of the associated costs for the company involved.
050100150200NumberofDaysSinceInitialContact05101520253035CompanyIDMailedlettersGrantedIndeterminateRejectedTerminatedhave no explicit indication that they ignored our request. Finally,
for the 36 responsive companies, we further tracked whether they
responded to our email queries, or only after we sent a physical
letter to general counsel (there is no need to differentiate based
upon the method of communication used in their response, as all
responses we received were electronic).
3.1.2 Response types. In this section we describe some common