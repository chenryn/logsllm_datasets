### 2.3 Product Selection

After selecting a set of target companies, we identified one product from each company that could plausibly be the subject of vulnerability research. Popular and noteworthy products are particularly attractive targets for vulnerability researchers, as they may offer monetary rewards (e.g., through bug bounty programs) and can enhance the researcher’s reputation. We used two distinct methods to select the products for testing:

1. **Most Reviewed Items on Amazon.com**: We presumed that the number of reviews for a product listing on Amazon.com is a reasonable metric of product popularity. For each company, we selected the product that met our criteria and had the highest number of reviews, limiting the search to the first three pages after filtering by manufacturer.

2. **Press Lists of Consumer Products**: In some cases, a selected manufacturer did not sell their product on Amazon, or the number of reviews did not provide confidence in the product's popularity. In such instances, we used additional sources from the technology-consumer press, such as thoroughlyreviewed.com, top10news.com, WirelessShack.org, and TheWirecutter.com, to identify an appropriate product.

### 2.4 Contact Selection

We hypothesized that the addressee of the authorization request might impact how it is handled within an organization. Requests directed to corporate counsel may elicit a more legalistic response, while more informal requests directed to technical security personnel may receive a different treatment. To explore this, we prioritized technical managers for contact and measured how many of these contacts were forwarded to legal. Of the responsive companies (n=30), 70% had a technical contact employee.

**LinkedIn Search**: LinkedIn, with over 130 million members in the United States, offered several advantages for our study:
- It established the presence of a U.S.-based workforce capable of handling the request, given our objective of understanding federal policy.
- The profiles contain self-reported, publicly available data points about employees in our target companies, which could help us understand the impact of the addressee on the request outcome.
- The platform's extensive reach made it suitable for finding people at organizations ranging from early-stage startups to large corporations.

Our search protocol was straightforward: we used the "advanced search" feature and filtered by current company and location (U.S. only). We prioritized contacting senior management in technical functions and focused on profiles with a higher number of connections.

To find and verify email addresses, we used publicly available tools such as lead-generation sites, Google Chrome extensions, and email verification tools. If an email address generated a "risky" assessment (e.g., when a mail server flags all handles as valid), we verified it by sending two emails from a fictitious account: one to the intended address and another to a bogus address. Typically, the bogus address would bounce, while the intended email would not generate a bounce warning.

**General Counsel or Chief Legal Officer**: Our verification protocol cannot guarantee that an email was delivered to a real person or that it was opened and explicitly ignored. To assert with higher confidence whether our request was processed, we sent regular letters via registered, private courier to the general counsel listed on the corporate website for companies that did not respond to our email request.

### 2.5 Procedure

After identifying the target companies, products, and contacts, we were ready to initiate communication. To replicate the steps an actual researcher would take, we started with email and escalated to postal mail if necessary. We avoided telephonic communication due to the challenges in standardizing interactive dialogues and to avoid imposing undue burden on the companies.

The study was divided into two rounds to allow for methodological adjustments if needed. In the first round, we randomly assigned 10 products to a senior faculty member. No issues arose, so we proceeded to assign 30 products to a junior faculty member and 20 to each independent researcher for the second round.

**Initial Contact**: For each contact, we created a properly instantiated version of the letter shown in Figure 1, with adaptations for each company, product, industry, and contact person. We varied one sentence (underlined) to change the tone of the request, hypothesizing that it might make one version more likely to be forwarded to the legal department. Each researcher sent approximately the same number of emails with and without the modifying legal sentence. We asked each researcher to send the letters using their normal email account, include us in the BCC line, and forward any replies.

Five companies were excluded at this stage due to various reasons: the junior researcher received a response indicating the product line had been sold to another company, the senior researcher excluded one company due to existing work, and three emails sent by the U.S. independent researcher bounced with no alternative contact found. Table 2 shows the number of targets assigned to each researcher and the breakdown of their responses.

**Email Interaction**: In some cases, the initial letter generated a request for more information. We crafted a response and asked the researcher to send it to the company. If the company requested more details about the testing, we provided a fixed corpus of responses. The text of the first follow-up was generally:

"In general, the students are interested in exploring what kinds of network vulnerabilities might exist in [product category] and will mirror the kinds of assessments we’ve done in the past. Regarding specific tests, expect that our students will use a combination of fuzz testing against network interfaces, reverse engineering using tools like IDA Pro, runtime taint-tracking of input buffers, and so on. We may publish our findings (subject to coordinated disclosure) at a technical conference. Please let me know if there are any other aspects of our study I could clarify further, and which steps we could take to obtain Company’s authorization."

A second follow-up was often provided, describing the researcher’s methodology in high-level terms. When a company requested a phone call, we continued to respond via email. Three companies approved the request despite the phone call request, while six stopped responding, and we terminated the exchange.

**Postal Follow-Up**: For companies that did not respond by email, we sent a registered letter to the company’s legal department. The content was similar to the email request, with a minor addition: "Please note that, despite our best efforts, we could not obtain authorization from your company by electronic means." This resulted in an email response in 25% of cases. One company representative called the faculty involved and conditionally granted the request. Companies only responded to letters sent by academic researchers; most were unanswered, and two of the letters mailed by the E.U. researcher were returned as undeliverable.

### 3. Authorization Study Results

#### 3.1 Company Responsiveness

For the subset of companies that responded to our initial requests, typical response times ranged from the same day to a few weeks, with some taking significantly longer. Figure 2 shows the variability in response time and researcher workload. Each interaction is depicted as a timeline starting from the initial contact, with each communication marked as a point on the line, colored according to the final outcome. The four physical letters that generated responses are marked with red circles.

**3.1.1 Classification of Responses**: We coded all responses to address three questions: Did the company engage with our request? If so, did the firm respond definitively? And for those that granted our request, what conditions did they seek to impose on the research? These classifications result in the following seven mutually distinct result conditions:

- **Unresponsive**: The company did not respond to our emails or postal mail.
- **Rejected**: The company explicitly rejected our request.
- **Unconditionally Granted**: The company explicitly granted our request with no restrictions.
- **Conditionally Granted**: The company explicitly granted our request with certain restrictions.
- **Indeterminate**: The company initially engaged but did not provide a definitive response.
- **Terminated**: We terminated the exchange due to deviations from the prescribed protocol.

Unless indicated otherwise, we refer to requests that were either conditionally or unconditionally granted as "granted." We exclude the 16 unresponsive companies that only received electronic communications, as we have no explicit indication that they ignored our request. For the 36 responsive companies, we tracked whether they responded to our email queries or only after we sent a physical letter to general counsel.

**3.1.2 Response Types**: In this section, we describe some common response types and analyze whether they were influenced by our test variables (including researcher type and whether the DMCA was mentioned explicitly) and external factors such as company ownership and legal staff engagement.