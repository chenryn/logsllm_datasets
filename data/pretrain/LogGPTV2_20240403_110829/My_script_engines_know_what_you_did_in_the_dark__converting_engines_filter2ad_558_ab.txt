2.3 Approach and Assumption
Table 1 summarizes how each design fulfills the requirements men-
tioned in Section 2.1. As mentioned in the previous section, neither
script-level nor system-level monitoring can fulfill all the require-
ments. It is also in principle difficult for them to fulfill the require-
ments through improvement. The problem of the binary applica-
bility of script engine-level monitoring will be solved if automatic
reverse-engineering of script engines is enabled. Therefore, our
approach automatically obtains information required for hooking
by analyzing script engine binaries, which makes it applicable to
binaries.
When analyzing script engine binaries, we assume knowledge
of the language specifications of the target script. This knowledge
is used for writing test scripts that are input to script engines
during analysis. We do not assume knowledge of insider implemen-
tation of the target script engines. Therefore, no previous reverse-
engineering of the target script engines is required.
3 METHOD
3.1 Overview
Figure 1 shows an overview of our method. The main purpose of our
method is automatically detecting hook and tap points by analyzing
script engine binaries. The method uses test scripts that are input
to the target script engine and executed during dynamic analysis
of the engine. These test scripts are manually written before using
our method.
468As mentioned above, our method is composed of four steps:
execution trace logging, hook point detection, tap point detection,
and script API tracer generation. The execution trace logging step
first acquires execution traces by monitoring the script engine
executing the test scripts. The hook point detection step extracts
hook point candidates by the application of our proposing algorithm
to the execution trace obtained in the previous step. After the hook
point candidates are obtained, the tap point detection step extracts
tap points and confirms the hook point. Using the obtained hook
and tap points, the final step inserts hooks into the script engine
and outputs it as the script API tracer.
Note that we define hook and tap points as follows.
• A hook point is the top of any local function that corresponds
• A tap point is defined as any argument of the local function
to the target script API in a script engine.
at which the hook point is set.
Figure 1: Overview of our method
3.2 Preliminary: Test Script Preparation
Test scripts used with our method have to fulfill the following four
requirements.
(1) A test script executes the target script API with no error.
(2) A test script only has the behavior relating to the target
script API. It is also allowed to execute script APIs essen-
tial for executing the target script API. For example, if the
target script API is Invoke (i.e., COM method invocation),
CreateObject is essentially required.
(3) Two test scripts are required to analyze one target script API.
One calls the target script API only once and the other calls
it N times. Note that N is a predefined parameter.
(4) The arguments of the target script API are arbitrarily defined
as long as the script API is not skipped when it is executed
multiple times. For example, executing CreateObject multi-
ple times with the same argument may be skipped because
copying the existing object instead of creating a new object
is a better approach.
A test script works as a specifier of the target script API which
our method analyzes. Therefore, it contains only the target script
Listing 2: Example of Test Script of CreateObject in VBScript
1Dim objShell
2Set objShell = CreateObject("WScript.Shell")
API. For example, when one wants to analyze the local functions
regarding the script API CreateObject and obtain the corresponding
hook point, the test script only contains a call of CreateObject such
as in Listing 2. These test scripts have to be manually prepared
before the analysis. Writing test scripts requires knowledge of the
language specifications of the target script language, which does
not conflict with the assumption given in Section 2.3.
3.3 Execution Trace Logging
An execution trace with our method consists of an API trace and
branch trace. The API trace contains the system APIs and their
arguments called during the execution. This trace is acquired by in-
serting code for outputting logs by API hooks and executing the test
scripts. The branch trace logs the type of an executed branch instruc-
tion and their source and destination addresses. This is achieved
by instruction hooks, which inserts code for log output to each
branch instruction. This step logs only call, ret, and indirect jmp
instructions because these types of branch instructions generally
relate to script API calls.
3.4 Hook Point Detection
The hook point detection step uses a dynamic analysis technique
called differential execution analysis. This analysis technique first
acquires multiple execution traces by changing their execution
conditions then analyzes their differences. A concept of this step is
illustrated in Figure 2. With this step, it is assumed that an execution
trace with one script API call differs from another with multiple
calls only in the limited part of the trace regarding the called script
API.
Since we use a branch trace in this step, its analysis granularity
is code block-level. Therefore, this step is even effective for script
APIs that do not call system APIs. For example of such script APIs,
Eval in VBScript, which only interacts with the script engine, does
not need to call system APIs. Also, script APIs regarding COM
method invocation does not call system APIs. Therefore, system-
level monitoring, which uses system API calls as a clue, cannot
observe the behavior of these script APIs. However, our method is
effective even for these script APIs since this step is independent
from system API calls.
This step uses multiple test scripts, i.e., one that calls the target
script API once and the other(s) that calls it multiple times, as
described in Section 3.2. This step differentiates the execution traces
acquired with these test scripts and finds the parts of the traces
related to the target script API that appears in the difference. This
differentiation is done by finding common subsequences with high
similarity from multiple branch traces. Note that this common
subsequence is defined as a subset of branch traces, which appears
once in the trace of the test script that calls the target script API
once and appears N times in the trace of one that calls it N times.
To extract these common sequences, our method leverages the
Smith-Waterman algorithm borrowed from bioinformatics. The
469subsequences of high similarity from the rows that are the same
as the common subsequence extracted with the original Smith-
Waterman algorithm (i.e., the dashed rounded rectangle in Figure 3).
This is done by recursively applying the original Smith-Waterman
algorithm to the same rows of the rest columns of the DP table as
described in Figure 3.
The modified Smith-Waterman algorithm repeats this proce-
dure N times to extract N common subsequences (the three dotted
rounded rectangles in Figure 3). The algorithm then calculates the
final common subsequence of the N subsequences and detects the
branches constructing it as hook point candidates.
Figure 2: Concept of hook point detection by differential ex-
ecution analysis.
Smith-Waterman algorithm performs local sequence alignment,
which extracts a subsequence with high similarity from two or
more sequences. However, we have a problem that it does not take
into account the number of common subsequences that appeared;
therefore we modified it to take this account.
We first explain the original Smith-Waterman algorithm then
introduce our modified version. The Smith-Waterman algorithm is a
sequence alignment algorithm based on dynamic programming (DP)
that can detect a subsequence of the highest similarity appearing in
two or more sequences. This algorithm uses a table called a DP table.
In a DP table, one sequence is located at the table head, another is
located at the table side, and each cell contains a match score. A
match score F(i, j) of cell (i, j) is calculated based on Equation (1),
where i is the index of rows and j is the index of columns.
F(i, j) = max
where
0
F(i − 1, j − 1) + s(i, j)
F(i − 1, j) + d
F(i, j − 1) + d
(cid:40)2
(1)
(2)
s(i, j) =
−2
d = −1
(match)
(unmatch)
(3)
Our modified algorithm is the same as the original one up to
filling all cells of the DP table. We provide an example of a DP table
in Figure 3 for further explanation. A sequence of A, B, and C in
this figure indicates one of the gray boxes in Figure 2. The letter S
indicates the white box that appears at the start of the execution
trace, whereas E indicates the white box at the end. The letter M
denotes the gray boxes that appear between the white boxes as
margins.
Although, these elements actually consist of multiple lines of
branch logs, they are compressed as A, B, etc. for simplification.
The original Smith-Waterman algorithm only finds the common
subsecquence of the highest similarity (SABC with the dotted rec-
tangle in Figure 3) by backtracking from the cell with the local
maximum score (the cell with score 8 in Figure 3). After finding
one such sequence, it exits the exploration.
After this procedure, the modified Smith-Waterman algorithm
performs further exploration. Algorithm 1 shows our modified
Smith-Waterman algorithm. This algorithm repeatedly extracts
if len(seq2) > len(seq1) then
Algorithm 1 Our Modified Smith-Waterman Algorithm
Input: seq1, seq2, N
Output: result_seq
rows ⇐ seq1
columns ⇐ seq2
rows ⇐ seq2
columns ⇐ seq1
end if
common_seqs ⇐ []
for i = 0 to N do
else
dptbl ⇐ DPTable(rows, columns).fillCell()
j = 1
repeat
max_cell ⇐ dptbl .searchJthLocalMaxCell(j)
max_seq ⇐ dptbl .backtrackFrom(max_cell)
rows ⇐ dptbl .getSameRows(max_seq)
columns ⇐ dptbl .getRestColumns(max_seq)
j = j + 1
until len(columns)! = 0
common_seqs.append(max_seq)
end for
result_seq ⇐ calcCommonSubseq(common_seqs)
3.5 Tap Point Detection
The tap point detection step plays two important roles. The first
is to select the final hook points from the hook point candidates
obtained in the previous step. The second is to find the memory
regions that should be dumped into logs. The memory regions that
would be dumped have two patterns: arguments and a return value
of script APIs.
3.5.1 Argument. Tap point detection adopts a value-based approach
for finding the matching value in the test script and script engine
memory. If an argument value of script APIs in test scripts also
appear in a specific memory location of the script engine process,
the memory location is identified as a tap point.
Tap points detection for arguments of script APIs is carried out
by exploring arguments of the functions detected as hook point
candidates. To do so, the proposed method acquires the execution
trace again with hooks inserted into the hook point candidates
obtained in the previous step. Arguments of hook point candidates
470Figure 4: Concept of tap point detection.
Section 3.5, tap point detection uses matching between the values
in a test script and thouse in script engines. If a value in a test script
is hardly controllable (e.g., it will always be 0 or 1), its matching
would be more difficult than that with controllable values.
The second problem is a gap between a script and script engine.
Due to this gap, how a variable is managed in a script and script
engine may differ. This makes the return values in scripts and actual
values in script engines different. For example, an object in a script
engine returned by an object creation function may be returned as
an integer that indicates the index of an object management table
in scripts.
We use value-based detection in a similar manner as tap point
detection for arguments. The difference is the entry point of the ex-
ploration. Since return values of script APIs may be passed through
the return value and output arguments of the corresponding func-
tion in the script engine, the proposed method begins to explorer
from them. If the return value in the test script does not appear
in the script engine, the proposed method tentatively regards the
return value of the hook point function as that of script APIs.
3.6 Script API Tracer Generation
We use the hook and tap points obtained above for appending script
API trace capability to the target script engines. Our method hooks
the local functions that correspond to the hook points and inserts
analysis code. Note that a hook point indicates the top of a local
function that is related to a script API, as mentioned in Section
3.1. The analysis code dumps the memory of the tap points with
the appropriate type into the analysis log. This code insertion is
achieved using generic binary instrumentation techniques.
4 IMPLEMENTATION
For evaluating our method, we implemented a prototype system
that uses our method called STAGER, a script analyzer generator
based on engine reversing. STAGER uses Intel Pin [20] to insert
hooks into the target script engine for acquiring execution traces.
STAGER enumerates symbols of the system libraries in the target
script engine process and inserts hooks into them for obtaining
called system APIs and their arguments. In addition, STAGER hooks
an instruction ins executed in the target script engine process when
one of the following conditions is true.
Figure 3: Modified Smith-Waterman algorithm.
are available by referring to the memory location on the basis
of the calling convention. Since type information (e.g., integer,
string, structure pointer) of each argument is not available, further
exploration requires heuristics.
Figure 4 illustrates the exploration heuristics used with the pro-
posed method. First, if an argument of a hook point candidate is
not dereferenced as a pointer, we regard it as a value. Otherwise,
we regard and dereference it as a pointer. When regarding it as
a value, we regard the value as various known types including
known structures. As a result of this exploration, if the arguments
in the test script are observed as the arguments at the hook point
candidate, the proposed method regards the candidate as legitimate
and defines the point of the argument as a tap point.
The exploration is improved if the type information is available.
Therefore, the proposed method may more precisely explore by
applying research of reverse-engineering type information such
as TIE [19] or those of type prediction such as Debin [12] and
TypeMiner [21].
3.5.2 Return Value. There are two problems with tap point detec-
tion for return values of script APIs. The first is that return values
in test scripts tend to have low controllability. As mentioned in
471&& INS_IsBranch(ins)
• INS_IsIndirectBranchOrCall(ins)
• INS_IsCall(ins)
• INS_IsRet(ins)
duce to generate a script API tracer?
5 EVALUATION
We conducted experiments on STAGER to answer the following
research questions (RQs).
• RQ1: What is the accuracy of hook and tap point detection
with STAGER?
• RQ2: How much performance overhead does STAGER intro-
• RQ3: How much false positives (FPs) and false negatives
(FNs) does the script API tracer generated by STAGER (STAGER-
generated tracer) produce?
• RQ4: Is the STAGER-generated tracer applicable to malicious
• RQ5: How well does the STAGER-generated tracer work
• RQ6: How much human effort is required to prepare test
compared with existing analysis tools?
scripts in the wild?
scripts?
5.1 Experimental Setup
Table 2 summarizes the experimental setup. We set up this environ-
ment as a virtual machine (VM). One virtual CPU was assigned to
this VM.
Although STAGER is more beneficial for proprietary script en-
gines, we applied it to both open source and proprietary script
engines. Open source engines are used because we can easily con-
firm the correctness of the hook and tap points. Note that the source
code is only used for confirming the results, and STAGER did not
use it for its analysis. Therefore, the analysis with STAGER is done
in the same manner as that of proprietary script engines. In addi-
tion, proprietary engines are used to confirm the effectiveness of
STAGER for real-world proprietary engines.
For open source engines, we used VBScript implemented in
ReactOS project [25] and PowerShell Core [29] which is a open
source version of PowerShell implementation We selected these
script engines for the experiments because both have open source
implementation of proprietary script engines and their supporting
languages are frequently used by attackers for writing malicious