### Register Injections and Recovery Times

- **Perceived Performance**: 71.96 ± 0.32
- **Actual Performance**: 70.03 ± 0.27
- **Recovery Time (s)**: 
  - **Register Injections**: 88.81 ± 2.57
  - **Text-Segment Injections**: 73.42 ± 1.28
  - **Heartbeat ARMOR**: 
    - **Register Errors**: 0.70 ± 0.21
    - **Text-Segment Injections**: 0.71 ± 0.03

In addition to the system failures described above, three text-segment injections into the Execution ARMOR resulted in the restarting of the texture analysis application. All three correlated failures were successfully recovered.

- **Recovery Time (s) for Heartbeat ARMOR**:
  - **Register Errors**: 0.31 ± 0.04
  - **Text-Segment Injections**: 0.45 ± 0.08

### Heartbeat ARMOR Behavior

The Heartbeat ARMOR recovered from all register errors, but text-segment injections caused two system failures. Although no corrupted state escaped the Heartbeat ARMOR, the error prevented it from receiving a heartbeat reply from the FTM. Consequently, the Heartbeat ARMOR falsely detected that the FTM had failed and initiated recovery by:

1. Instructing the FTM’s daemon to reinstall the FTM process.
2. Instructing the FTM to restore its state from a checkpoint after receiving acknowledgment that the FTM has been successfully reinstalled.

However, due to the error, the Heartbeat ARMOR never received the acknowledgment, preventing it from sending a follow-up message to restore the FTM state. The immediate problem can be solved by combining the reinstallation of the FTM and state restoration into a single operation without the intermediate acknowledgment. However, the underlying issue persists: the Heartbeat ARMOR suffers from receive omissions and will continue to detect a failed FTM during subsequent heartbeat rounds.

To detect the receive omission error, an element can be added to the Heartbeat ARMOR that performs a series of self-tests on key functionality before sending heartbeat messages. These self-tests generate a signature, which can be verified by either the local daemon or the receiving ARMOR. Additional error injection experiments can be used to evaluate the coverage of these self-checks on ARMOR functionality.

### Target Recoveries/Failures

| Element          | Baseline | Seg. fault | Application | FTM | Execution ARMOR | Heartbeat ARMOR |
|------------------|----------|------------|-------------|-----|-----------------|-----------------|
| **Target Recoveries/Failures** | 95 / 95 | 84 / 84 | 77 / 80 | 77 / 77 | 82 / 82 | 84 / 88 |
| **Successful Recoveries** | 93 / 95 | 95 / 97 | 71 | 58 | 56 | 62 |
| **Failures** | 4 | 6 | 6 | 6 | 23 | 28 |
| **System Failures** | 31 | 33 | 20 | 16 | 15 | 8 |
| **No Failures** | 0 | 4 | 3 | 1 | 90.70 ± 2.57 | 75.65 ± 1.54 |
| **Text-segment Injections** | 76.19 ± 1.82 | 73.00 ± 0.22 | 89.47 ± 2.87 | 76.47 ± 2.87 | 77.48 ± 1.93 | 73.23 ± 0.37 |

### FTM Recovery

Table 4 shows that the FTM successfully recovered from all register injections. Two text-segment injections were detected through assertions on the FTM’s internal data structures, and both errors were recovered. The extent to which assertions prevent corrupted state from escaping the process is investigated via heap injections in Section 6.

Table 4 also shows that the FTM could not recover from four text-segment errors. In each case, the error corrupted the FTM’s checkpoint prior to crashing. Because the checkpoint was corrupted, the FTM crashed shortly after being recovered, leading to a cycle of failure and recovery until the run timed out.

There were seven cases of a correlated failure in which the FTM failed during the application’s initialization: three from the Proceedings of the International Conference on Dependable Systems and Networks (DSN’02).

### Heap Injections

Careful examination of the register injection experiments showed that crash failures were most often caused by segmentation faults raised from dereferencing a corrupted pointer. To maximize the chances for error propagation, only data (not pointers) were injected on the heap. Results from targeted injections into FTM heap memory were grouped by the element into which the error was injected. Table 5 shows the number of system failures observed from 100 error injections per element, classified by their effect on the system. One hundred targeted injections were sufficient to observe either escaped or detected errors given the amount of state in each element; overall, 500 heap injections were conducted on the FTM.

Many data errors were detectable through assertions within the FTM, but not all assertions were effective in preventing system failures. Four scenarios resulted after a data error was injected (the last three columns in Table 5 are numbered to refer to scenarios 2-4):

1. **Undetected and No Effect**: The data error was not detected by an assertion and had no effect on the system. The application completed successfully as if there were no error.
2. **Undetected and System Failure**: The data error was not detected by an assertion but led to a system failure. None of the system failures impacted the application while it was executing.
3. **Detected and Propagated**: The data error was detected by an assertion check, but only after the error had propagated to the FTM’s checkpoint or to another process. Rolling back the FTM’s state in these circumstances was ineffective, and system failures resulted from which the SIFT environment could not recover. These cases show that error latency is a factor when attempting to recover from errors in a distributed environment.
4. **Detected and Recovered**: The data error was detected by an assertion check before propagating to the FTM’s checkpoint or to another process. After an assertion fired, the FTM killed itself and recovered as if it had experienced an ordinary crash failure.

The injection results in Table 5 show that some state information was more sensitive to error propagation than others. The `mgr_app_detect` and `app_param` modules were those whose state was substantially read-only after being written early in the run. With assertions in place, none of the data errors led to system failures. At the other end of the sensitivity spectrum, 28 errors in two elements caused system failures. In contrast, the `mgr_armor_info` and `node_mgmt` elements were repeatedly written during the initialization phases of a run, causing no system failures.