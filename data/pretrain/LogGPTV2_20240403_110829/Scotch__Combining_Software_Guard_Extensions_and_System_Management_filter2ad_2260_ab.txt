90ms
120ms 150ms 180ms
CPU time
CPU time
(a) Non-attack scenario.
(b) Attack scenario.
Fig. 1. Resource accounting scenario. A potential schedule of two benign VMs (denoted
1 and 2) with ideal CPU-bound workloads. The orange arrows represent when a VMM
would poll which guest is running as part of determining billing. The accounting infor-
mation inferred is accurate over time. In (b), a malicious guest closely controls CPU
usage so that the benign guest (1) appears to use all of the CPU time. (Color ﬁgure
online)
3.3 VM Escape Attacks
Virtualization technologies, such as Xen, nominally isolate guest VMs from one
another. Indeed, with full hardware virtualization, each guest believes it has
control of an entire system. However, vulnerabilities inevitably ﬁnd their way
into hypervisors that allow malicious guests to escape out of the virtualization
environment and execute arbitrary code within the hypervisor context [15,27].
Naturally, such attacks can have a devastating impact on cloud providers, poten-
tially exposing private or valuable data to the attacker. In this paper, we consider
an attacker capable of escaping the guest context, and taking over the VMM.1
In this paper, we do not assume VM escape attacks that completely disable
the system. For instance, it is very possible that a VM escape attack could
compromise the hypervisor and stop executing all guests, or an attacker could
attempt to disable network communications in the SMI handler with the Remote
System. These sorts of denial-of-service (DoS) attacks can often be detected with
timeouts and are out of scope for this work. Instead, we consider escape attacks
where the attacker is capable of corrupting data structures related to resource
usage.
4 Architecture
The goal of the Scotch architecture is to provide accurate and transparent
resource accounting for cloud computing systems. This is done via resource
accounting code that measures resources consumed by each guest residing on
a hypervisor during every task switch and interrupt. We take advantage of hard-
ware support to provide incorruptible accounting code and data storage as well
as tamper-proof event-based invocation.
1 We assume the attacker can gain ring 0 (i.e., kernel) privilege after escaping the
guest VM environment.
Scotch
409
Figure 2 illustrates our system architecture. We have two or more systems in
our approach. First, one or more Protected Systems run Virtual Machine Monitor
(VMM) software capable of hosting multiple benign or malicious VM guests.
Each Protected System reliably collects resource consumption information about
each guest, periodically reporting this information to an SGX enclave. The SGX
enclave stores all of the resource consumption information from the VMs on the
Protected System for further processing or analysis in a way that cannot be read
or tampered with by a malicious guest, operating system, or hypervisor. In our
implemented prototype of Scotch, we consider one Protected Machine with
one SGX enclave.
4.1 Resource Accounting Workﬂow
The Protected Machine described in Fig. 2 is responsible for collecting reliable
and tamper-resistant resource consumption information about each VM guest
whether it is malicious or benign. To accomplish this goal, we will discuss ﬁve
steps (marked 1(cid:2)– 5(cid:2) in Fig. 2) taken by the Protected System to ensure the
integrity of the resource accounting information.
In step 1(cid:2), the VMM is engaged by a VM guest through preemption or
a hypercall to service an I/O request. Using hardware support (q.v. Sect. 5),
we capture all such events, and execute our custom resource accounting code
(denoted step 2(cid:2)). Note that the VM guest could be malicious or benign—we
make no distinction in our approach because we are simply computing accurate
and tamper-resistant resource accounting so that benign customers are eventu-
ally notiﬁed of the resources actually consumed.
During a context switch, step 2(cid:2) invokes an SMI, causing our accounting
code to run in the SMI handler. Using further hardware support, we can con-
vert certain types of I/O and event interrupts into SMIs. For instance, when
a VM’s time quantum elapses, a timer raises an interrupt telling the VMM to
switch guests. In Scotch, we change such interrupts to invoke SMIs instead.
Invoking an SMI is critically important to the continued reliability of accounting
information provided by our system.
In step 3(cid:2), our accounting code records which VM guest will run next as
well as the time elapsed since the last time our code executed (i.e., the last con-
text switch event). This information is recorded in an isolated region of system
memory, inaccessible from the hypervisor (or guest) context. For I/O events, we
record information about what type of I/O is being done. For recording resource
consumption besides CPU time, capturing these I/O events allows us to reason
about whether a guest is consuming disk or network.
In step 4(cid:2), our accounting code ﬁnishes executing and transfers control back
to the guest. We do not pass control back to the hypervisor because a com-
promised hypervisor may change the result of a task switch event (cf. time-of-
check-to-time-of-use attacks). For example, during a context switch, the hyper-
visor scheduler will select a new guest to run. If one were to perform resource
accounting before the hypervisor ﬁnalizes the scheduling decision, a compromised
hypervisor could spoof which guest will run next, perform accounting, and then
410
K. Leach et al.
Protected System
VMM (e.g., Xen)
1
VM1
VM2
VM3
2
4
SGX Enclave
3
SMI Handler Data
5
SGX Enclave
VM1 data
VM2 data
VM3 data
True timer
Fig. 2. High level overview of Scotch. The system contains one Protected System
running VMM software containing a number of benign and malicious guests. One
of the benign guests has an SGX enclave application running that receives account-
ing information from our tamper-resistant resource monitoring code. The annotations
1(cid:2)– 5(cid:2) correspond to the order of events in an indicative workﬂow. We assume benign
guests are motivated to know their resource consumption.
run a diﬀerent guest. Instead, in Scotch we invoke the resource accounting
code right before control would have been transferred to the guest. After our
accounting code completes, control ﬂows directly to the correct guest.
Finally, step 5(cid:2) represents a task that is completed occasionally. It is possible
that a malicious guest that escapes to the hypervisor could corrupt data. In
particular, if such an attacker is trying to hide the resources they consume, they
might corrupt timers on the hypervisor that we use to measure the amount of
time each guest spends consuming a resource. In such cases, we could use the
SMI handler code (Step 2(cid:2)) to occasionally request time information from a
trusted remote server (cf. Spectre [43]).
Cost of Accounting. Recall that our approach invokes SMIs to reliably exe-
cute our resource accounting code. The invocation of the SMI and the resource
accounting code itself both incur overhead on the hypervisor. This, in turn,
aﬀects the performance of the guests on the system, even if no malicious guests
are running. For example, assuming a CPU-bound workload in which all guests
consume all of their allocated time quanta, adding our resource accounting code
essentially increases the amount of time taken to complete a context switch.
Thus, deploying Scotch means accepting an associated performance loss in
order to gain high accuracy, tamper-resistant resource accounting information.
As we discuss in Sect. 6, we also consider an alternative scenario to mitigate
performance impact by invoking our code at diﬀerent intervals. Ideally, we would
invoke our accounting code on every possible task switch and I/O interrupt event.
However, we could instead elect to invoke our code every x such events, where
Scotch
411
x is some random interval from 1 to some maximum interval. Essentially, every
time an interrupt or task switch occurs, we ﬂip a coin to decide whether to
invoke our resource accounting code. This requires adding such decision code
to the hypervisor, which could be noticed (or altered) by malicious, escaped
guests. However, we propose this approach as a means to signiﬁcantly improve
performance on diverse workloads. This option allows a cloud provider to trade
oﬀ resource accounting granularity and overhead.
5 Implementation
In this section, we discuss how we implement our approach on a real system.
Recall there are ﬁve steps in our workﬂow from Fig. 2:
1. Capture interrupts and task switch events,
2. Redirect interrupts to invoke resource accounting code,
3. Compute resource usage impact of the current event,
4. Transfer CPU control to next guest, and
5. Relay accounting information into a trusted SGX enclave running within a
VM guest.
Capturing these interrupts depends on features from Intel’s Virtualization
(VT-x) extension. In particular, we use VT-x’s intercept capability, which allows
us to control what happens as a result of a diverse array of events that can
happen during execution, including task switching and interrupts. VT-x supports
intercepting other events such as when a guest executes certain instructions, but
we do not use this feature in Scotch. After intercepting task switches and I/O
interrupts, we execute our resource accounting code.
We use System Management Mode (SMM) to implement our resource
accounting code. We invoke a System Management Interrupt (SMI), which
causes the CPU to save its state and transfer control to the SMI handler. The
SMI handler is stored in the BIOS and loaded into the special SMRAM memory
region upon booting the system. SMRAM is only addressable by SMM, and so
any hypervisor or guest code running in Protected or Long Mode are not capable
of reading or writing our SMI handler code. We overwrite the SMI handler with
custom resource accounting code, which is then executed every time we assert
an SMI.
SMIs can be asserted in several ways according to the platform’s chipset.
For our prototype, we use the AMD 800 series chipset. This platform supports
invoking SMIs by writing to the legacy I/O port 0xb0 [5]. By executing outb
instructions, we can invoke SMIs. Alternatively, we can also write to oﬀset 0x9b
of the SMI control register of the advanced conﬁguration and power interface
(ACPI) MMIO conﬁguration space.2 Writes to this address causes an SMI to
occur. Once an SMI is asserted, the CPU switches to SMM and begins executing
the SMI handler at a ﬁxed oﬀset. Finally, we can also assert SMIs by conﬁguring
timing registers to deliver SMIs at conﬁgurable intervals.
2 On our platform, the speciﬁc physical address was 0xfed8029b.
412
K. Leach et al.
We wrote a custom SMI handler that locates the VM guests residing on the
system, identify which one was executing when the SMI occurred, and updates
resource account information about that guest. On x86 machines, the control
register CR3 contains a pointer to the physical location of the page directory
associated with a process—in Xen, the CR3 value can uniquely identify guests.
We maintain a map of CR3 register values to VM guest IDs. We can also com-
pute the location of the Virtual Machine Control Structure (VMCS) of each
guest, which contains information about virtualized timers (and other informa-
tion related to VM guest context). In our prototype, we have two guest VMs
executing on one physical core—this setup simpliﬁes identifying which guest is
currently executing.
Recall that our SMI handler is invoked for one of two reasons: task switching
or interrupt servicing. During a task switch, the VMCS page contains a pointer
to the next guest that will run after the task switch completes. In other words, we
know which guest will run next but not the guest that just completed running.
Nonetheless, we can record current timestamp t1 using the rdtsc instruction.
Then, when the next task switch occurs, we can get another timestamp t2, and
use the diﬀerence t2 − t1 to estimate the amount of CPU time consumed by
the guest that was previously executing. For interrupts, we can determine which
IRQ was involved using the VMCS, from which we can determine the device
that caused the interrupt. For our current prototype, we track the number of
interrupts and associated IRQs corresponding to each guest.
After our resource accounting SMI handler completes, it switches back to Pro-
tected Mode to resume normal execution. Executing an RSM instruction restores
the previous state and conﬁguration registers. Ultimately, in our prototype, this
transfers control of the CPU to the next guest task to execute without any
space for the VMM to execute any instructions. Thus, even if the hypervisor is
compromised, it does not have an opportunity to change the results of a task
switch or interrupt event after we have completed our accounting code. This
approach allows a highly granular and accurate view of resource consumption of
each guest.
Next, we relay our accounting information to the SGX enclave, which stores
data for later analysis in an isolated space. We cannot use SGX-related instruc-
tions while in SMM [23]. Instead, we perform several steps to get the data into
the SGX enclave. First, we create a normal userspace stub program in the vir-
tual machine guest containing the SGX enclave. This stub program contains a
page of memory for arbitrary data, and code to marshall that data into the
SGX enclave (via EENTER). We use the SMI handler to check the integrity of the
stub program to detect potential tampering. Next, we note the physical address
of this starting page, and the SMI handler writes its accounting data into that
location. We conﬁgure the SMI handler to transfer control to the stub code after
exiting SMM (by changing save state). The stub code (executing in Protected
Mode at ring 3) then places that data into the enclave. This approach allows us
conﬁdence that the accounting data is securely relayed to user space.
Scotch
413
Finally, we implement a network card driver in the SMI handler to com-
municate with the Remote System for accurate, external timing information.
A similar approach was used in Spectre [43] and MalT [45]. We use symmet-
ric key encryption with a key stored in SMRAM transmitted by the Remote
System as the BIOS is booting the Protected System. This ensures that the
key is stored securely before the Protected System has an opportunity to load
potentially-compromised hypervisor code.
6 Evaluation
In this section, we evaluate Scotch. We present experimental results and dis-
cussion. We seek to answer the following research questions:
RQ1 Can we perform accurate resource accounting during scheduler attacks?
RQ2 What is the overhead of our accounting approach on benign workloads?
RQ3 Can we accurately account resources during resource interference attacks?
RQ4 Can we perform accurate resource accounting during VM escape attacks?
RQ5 How do our CPU-based techniques apply to other resources?
6.1 Experimental Setup
Our experiments were carried out on an Intel Core i7-7700HQ 2.8 GHz CPU with
32 GB of memory. We ran two identical Ubuntu 15.04 guests, each given 256 MB
of memory and 1CPU core. We recorded the physical memory addresses of each
guest’s Virtual Machine Control Structure (VMCS) to ease experimentation.
For ground truth data, we used Xen’s built-in instrumentation, xentrace [3].
Xentrace behaves similarly to perf in that it can monitor for certain events
and record resource usage. For some research questions, we developed our own
attacks to mimic the behavior of possible attacks that would occur in the wild.
Those implementations are detailed in the appropriate sections that follow.
6.2 RQ1: Scheduler Attack
Our ﬁrst research question asks whether our system is capable of accurately
recording CPU time consumption when a malicious guest uses a scheduler attack
to steal CPU time. For this experiment, we have one malicious guest VM and
one victim guest VM competing for the same amount of CPU time on a physical
core. We wrote ten variants of the Xen credit scheduler, each of which gives the
malicious VM an increasing amount of CPU time by inﬂuencing credit allocation
in the scheduler. This is similar to the pseudo-attack implemented in [24], though
we eﬀect changes in the credits assigned to each guest over time to achieve
changes in CPU time.