# An OpenFlow-based Energy-Efficient Data Center Approach

**Authors:** Michael Jarschel and Rastin Pries  
**Affiliation:** University of Würzburg, Institute of Computer Science  
**Emails:** {michael.jarschel|pries}@informatik.uni-wuerzburg.de  
**Location:** Würzburg, Germany

## Categories and Subject Descriptors
- **C.2.1 [COMPUTER-COMMUNICATION NETWORKS]:** Network Architecture and Design—Network Communications, Network Topology
- **C.4 [PERFORMANCE OF SYSTEMS]:** Reliability, Availability, and Serviceability

## Keywords
- Data Center
- OpenFlow
- Energy Efficiency

## 1. Introduction
Infrastructure as a Service (IaaS) is a prevalent business model in cloud computing that has garnered significant customer interest over the past few years. IaaS providers offer temporary deployment and maintenance of custom virtual host and network infrastructure, enabling customers to run and host arbitrary applications. Providers face several challenges in their data centers, primarily due to the inherent heterogeneity of systems and applications from different customers. This results in a variety of load and traffic patterns that must be managed by the same data center infrastructure.

There are two primary approaches to address this challenge:
1. **Overprovisioning:** This classical approach ensures a constant service quality but is highly inefficient and only feasible for companies with large budgets and extensive resources.
2. **Smart Resource Management:** A more efficient approach involves finding a balance between meeting various customer application requirements and optimizing the use of available resources in the data center.

The Energy-Efficient Data Center (ECDC) approach, showcased in this demonstration, is a smart mechanism that leverages monitoring information from machines, network devices, and environmental data to create a coherent view of the current situation in a data center. This enables a single network operator to react to system changes in real-time. Additionally, the monitoring data is used by a smart control application to redistribute virtual machines, traffic flows, and VLANs, as well as to power devices up and down as needed.

**Permission Notice:**
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.

**Conference Information:**
SIGCOMM’12, August 13–17, 2012, Helsinki, Finland.  
Copyright 2012 ACM 978-1-4503-1419-0/12/08 ...$15.00.

## 2. Architecture
Figure 1 illustrates the ECDC architecture in a simple data center scenario. On the right, servers host the customers' virtual infrastructures, organized in racks with a top-of-rack switch each. The entry point into the network from the service side is the virtual switches integrated into the hypervisor of each server. On the left, two types of customers connect to the data center network from the Internet:
- **Type A Customer:** A private home user who uses an entertainment service, such as video streaming, hosted in racks B and C.
- **Type B Customer:** A business user who uses a business application, such as a virtual desktop infrastructure (VDI), set up by their company in the data center.

To manage these different types of customers independently, their traffic is kept in separate VLANs. Type A traffic is represented by red lines, and Type B traffic by green lines. Packets are tagged at the entry switch into the data center network. The network is OpenFlow-enabled, and forwarding decisions for all network elements (access, edge, and hypervisor switches) are handled by a central entity, the OpenFlow controller (OFC). The control connection for each network element is established via a physically isolated management network. This network also connects the controller, OpenFlow switches, physical servers, and environmental sensors to the central data center management entity, the management station.

The management station queries monitoring information on CPU, network, memory load, and power consumption from the connected devices via SNMP. Using this information, the management station generates appropriate network policies for the OFC, distributes virtual machines across the servers, and powers down unused devices to ensure efficient resource utilization while maintaining good service quality. The management station achieves this by observing configured thresholds and timeouts for each service class. If a monitored parameter, such as CPU load, falls below or rises above a threshold for a certain amount of time, the management station takes action, such as consolidating multiple virtual machines to one host or spreading them over multiple hosts. The network, i.e., the OpenFlow controller, is immediately notified and can adapt the flow rules in the switches with minimal delay, minimizing the impact on the service.

The gathered information is also presented to the data center operator through a graphical user interface (GUI), as shown in Figure 2. The GUI displays the current topology of the network and a time series of monitored values, allowing the operator to facilitate changes in the operation of the data center if necessary, such as introducing a new service class.

## 3. Demonstration
The demonstration testbed is hosted on the German-Lab (G-Lab) facility in Würzburg, Germany. Four rack servers are used as computing nodes, running OpenNebula and KVM as the hypervisor, using Open vSwitch as the virtual switch. The management station is hosted on a fifth server, running the OpenNebula management software and our Java-based data center management software. The management network is a legacy IP network realized by the Cisco top-of-rack switch of the G-Lab facility. We use BigSwitch’s Floodlight as the OpenFlow controller, hosted in a G-Lab virtual machine. The OpenFlow data center network is represented by a Pronto 3290 OpenFlow switch.

The demonstration will show the operation of the ECDC-enabled data center over the course of a business day. Using our own traffic generator, we emulate the behavior of the two types of users introduced in Section 2. For demonstration purposes, we condense the emulated "day" into a short cycle. During this cycle, we show the changes in the system as an operator would perceive them using our ECDC GUI. In the topology section of the GUI, topology changes caused by the migration of virtual machines and the powering up and down of physical hosts are displayed. In the monitoring section, line graphs illustrate load changes in servers. Selecting an OpenFlow switch in the topology display shows the switch's flow table entries, and selecting an entry displays the path of the corresponding flow through the network.

## 4. Conclusion
In this demonstration, we showcase our smart data center management software, ECDC. It allows for an integrated adaptation of computing and network resources according to the required capacity, ensuring smooth operation of services in an IaaS scenario. At the same time, the software aims to minimize the carbon footprint of the data center by consolidating capacities and powering down unused resources. To achieve this, we leverage modern software-defined networking (SDN) and proven open-source cloud management software. Challenges include integrating network and server virtualization using Open vSwitch and OpenNebula. We believe there is significant potential for optimization in data centers, and this approach may be applicable to larger-scale scenarios.

## 5. Acknowledgments
The authors would like to thank Thomas Höhn, Christopher Metter, and Phuoc Tran-Gia from the University of Würzburg for their valuable work and discussions. This work was funded by the international bureau of the Federal Ministry of Education and Research (Förderkennzeichen VNM10/073).

## 6. References
[1] J. Fontán, T. Vázquez, L. Gonzalez, R. Montero, and I. Llorente. OpenNebula: The open source virtual machine manager for cluster computing. In Open Source Grid and Cluster Software Conference, 2008.

[2] A. Kivity, Y. Kamay, D. Laor, U. Lublin, and A. Liguori. KVM: The Linux Virtual Machine Monitor. In Proceedings of the Linux Symposium, volume 1, pages 225–230, 2007.

[3] N. McKeown, T. Anderson, H. Balakrishnan, G. Parulkar, L. Peterson, J. Rexford, S. Shenker, and J. Turner. OpenFlow: Enabling Innovation in Campus Networks. ACM SIGCOMM Computer Communication Review, 38(2):69–74, 2008.

[4] B. Pfaff, J. Pettit, T. Koponen, K. Amidon, M. Casado, and S. Shenker. Extending Networking into the Virtualization Layer. Proc. HotNets (October 2009), 2009.

[5] Pica8. Pronto 3290 OpenFlow Switch. http://www.pica8.org/products/p3290.php.

[6] D. Schwerdel, D. Günther, R. Henjes, B. Reuther, and P. Müller. German-Lab Experimental Facility. Future Internet-FIS 2010, pages 1–10, 2010.