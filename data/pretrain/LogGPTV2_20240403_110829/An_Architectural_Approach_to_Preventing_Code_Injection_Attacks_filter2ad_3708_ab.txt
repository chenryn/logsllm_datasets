could simply maintain one pagetable and point both regis-
ters to it if a process requires a von Neumann architecture.
We note that no changes would need to be made to the pro-
cessor’s translation lookaside buffer (TLB) as modern x86
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:52:10 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007Physical Memory
Instructions
Data
…
Instruction/Data 
Fetch
Processor
(a)
Instruction Memory
Data Memory
Processor
Instructions
Instructions
…
Instruction
Fetch
Data
Fetch
(b)
Data
Data
…
Figure 1. (a) von Neumann architecture. (b) Harvard architecture
processors already have a separate TLB for code and data.
While this approach to the problem may be effective, the
requirement that the protected system be run on top of hard-
ware virtualization inhibits its practicality. As such, another
approach is needed.
Exploiting x86
Another technique for creating this Harvard architecture is
to make unconventional use of some of the architecture’s
features in order to create the appearance of a memory that
is split between code and data. Through careful use of the
pagetable and the TLBs on x86, it is possible to construct
a Harvard memory architecture at the process level using
only operating system level modiﬁcations. No modiﬁca-
tions need to be made to the underlying x86 architecture,
and the system can be run on conventional x86 hardware
without the need for hardware virtualization as in the previ-
ous method.
In the following sections we will further describe this
technique as well as its unique advantages.
4. Split Memory: A Harvard Architecture on
x86
Now that we have established that it is our intention to
exploit, not change, the x86 architecture in order to create
a virtual split memory system, we will now describe the
technique in greater detail.
4.1. Virtualizing Split Memory on x86
In order to speed up pagetable lookup time, many pro-
cessors include a small hardware cache called a translation
lookaside buffer (TLB) which is used to cache pagetable en-
tries. In order to better exploit locality, modern processors
actually split the TLB into two TLBs, one for code and one
for data. This feature can be exploited by a keen operating
system to route data accesses for a given virtual address to
one physical page, while routing instruction fetches to an-
other. By desynchronizing the TLBs and having each con-
tain a different mapping for the same virtual page, every vir-
tual page may have two corresponding physical pages: One
for code fetch and one for data access. In essence, a system
is produced where any given virtual memory address could
be routed to two possible physical memory locations. This
creates a split memory architecture, as illustrated in Figure
Memory
Instructions
Instructions
Data
Data
Instruction
Fetch
Data
Fetch
Processor
Figure 2. Split memory architecture
2.
This split memory architecture is an environment
wherein an attacker can exploit a vulnerable program and
inject code into its memory space, but never be able to actu-
ally fetch it for execution. This is because the physical page
that contains the data the attacker managed to write into the
program is not accessible during an instruction fetch, as in-
struction fetches will be routed to an un-compromised code
page. This also creates the unique opportunity to support
and protect pages that contain both code and data by keep-
ing the two physically separated but logically combined.
What to Split
Before we discuss the technical details behind successfully
splitting a given page, it is important to note that different
pages in a process’ address space may be chosen to split
based on how our system will be used.
One potential use of the system is to augment the exist-
ing non-executable page methods by expanding their pro-
tection to allow for protecting mixed code and data pages.
Under this usage of the system, the majority of pages un-
der a process’ address space would be protected using the
non-executable pages, while the mixed code and data pages
would be protected using our technique. Using this scheme,
chances are high that only a few of the process’ pages would
need to be protected using our method. Note that this as-
sumes we have a good understanding of the memory space
of the program being protected.
Another potential use of our system, and the one which
we use in our prototype in section 5.1, is to protect every
page in a process’ memory space. This is a more compre-
hensive type of protection than simply augmenting existing
schemes. Note that in this case, more pages are chosen to
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:52:10 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007Algorithm 1: Split memory page fault handler
Input: Faulting Address (addr), CPU instruction
pointer (EIP), Pagetable Entry for addr (pte)
Algorithm 2: Debug interrupt handler
Input: Pagetable Entry for previously faulting address
(pte)
/* Code Access */
/* Data Access */
1
2
3
4
5
6
7
8
9
10
11
12
if addr == EIP then
pte = the code page;
unrestrict(pte);
enable single step();
return;
else
pte = the data page;
unrestrict(pte);
read byte(addr);
restrict(pte);
return;
end
be split and thus protected.
How to Split
Once it is determined which pages will be split, the tech-
nique for splitting a given page is as follows:
1) On program start-up, the page that needs to be split is du-
plicated. This produces two copies of the page in phys-
ical memory. We choose one page to be the target of
instruction fetches, and the other to be the target of data
accesses.
2) The pagetable entry (PTE) corresponding to the page we
are splitting is set to ensure a page fault will occur on a
TLB miss. In this case, the page is considered restricted,
meaning it is only accessible when the processor is in
supervisor mode. We accomplish it by setting or en-
abling the supervisor bit [3] in the PTE for that page.
If supervisor is marked in a PTE and a user-level pro-
cess attempts to access that page for any reason, a page
fault will be generated and the corresponding page fault
handler will be automatically invoked.
3) Depending on the reasons for the page fault, i.e., either
this page fault is caused by a data TLB miss or it is
caused by an instruction TLB miss, the page fault han-
dler behaves differently. Note that for an instruction-
TLB miss, the faulting address (saved in the CR2 reg-
ister [3]) is equal to the program counter (contained in
the EIP register); while for a data-TLB miss, the page
fault address is different from the program counter. In
the following, we describe how different TLB misses are
handled. The algorithm is outlined in algorithm 1.
Loading the Data-TLB
The data-TLB is loaded using a technique called a pagetable
walk, which is a procedure for loading the TLB from within
the page fault handler. The pagetable entry (PTE) in ques-
tion is set to point to the data page for that address, the en-
1
2
3
4
if processor is in single step mode then
restrict(pte);
disable single step();
end
try is unrestricted (we unset the supervisor bit in the PTE),
and a read off of that page is performed. As soon as the
read occurs, the memory management unit in the hardware
reads the newly modiﬁed PTE, loads it into the data-TLB,
and returns the content. At this point the data-TLB con-
tains the entry to the data page for that particular address
while the instruction-TLB remains untouched. Finally, the
PTE is restricted again to prevent a later instruction access
from improperly ﬁlling the instruction-TLB. Note that even
though the PTE is restricted, later data accesses to that page
can occur unhindered because the data-TLB contains a valid
mapping. This loading method is also used in the PAX [2]
protection model and is known to bring the overhead for a
data-TLB load down to reasonable levels.
In algorithm 1 this process can be seen in lines 7–11.
First, the pagetable entry is set to point to the data page
and unrestricted by setting the entry to be user accessible
instead of supervisor accessible. Next, a byte on the page is
touched, causing the hardware to load the data-TLB with a
pagetable entry corresponding to the data page. Finally, the
pagetable entry is re-protected by setting it into supervisor
mode once again.
Loading the Instruction-TLB
The loading of the instruction-TLB has additional compli-
cations compared to that of the data-TLB, namely because
there does not appear to be a simple procedure such as a
pagetable walk that can accomplish the same task. De-
spite these complications, however, a technique introduced
in [10] can be used to load the instruction-TLB on the x86.
Once it is determined that the instruction-TLB needs
to be loaded,
the processor is
placed into single step mode, and the faulting instruction
is restarted. When the instruction runs this time the PTE is
read out of the pagetable and stored in the instruction-TLB.
After the instruction ﬁnishes then the single step mode of
the processor generates an interrupt, which is used as an
opportunity to restrict the PTE.
the PTE is unrestricted,
This functionality can be seen in algorithm 1 lines 2–5
as well as in algorithm 2. First, the PTE is set to point to
the corresponding code page and is unprotected. Next, the
processor is placed into single step mode and the page fault
handler returns, resulting in the faulting instruction being
restarted. Once the single step interrupt occurs, algorithm
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:52:10 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 20072 is run, effectively restricting the PTE and disabling single
step mode.
4.2. Eﬀects on Code Injection
A split memory architecture produces an address space
where data cannot be fetched by the processor for execu-
tion. For an attacker attempting a code injection, this will
prevent him from fetching and executing any injected code.
A sample code injection attack attempt on a split memory
architecture can be seen in Figure 3 and described as fol-
lows:
1. The attacker injects his code into a string buffer start-
ing at address 0xbf000000. The memory writes are
routed to physical pages corresponding to data.
2. At the same time as the injection, the attacker over-
ﬂows the buffer and changes the return address of the
function to point to 0xbf000000, the expected loca-
tion of his malicious code.
3. The function returns and control is transferred to ad-
dress 0xbf000000. The processor’s instruction fetch
is routed to the physical pages corresponding to in-
structions.
4. The attacker’s malicious code is not on the instruc-
tion page (the code was injected as data and therefore
routed to a different physical page) and is not run. In
all likelihood, the program simply crashes.
4.3. Overhead
This technique of splitting memory does not come with-
there is some overhead associated with the
out a cost,
methodologies described above.
One potential problem is the use of the processor’s sin-
gle step mode for the instruction-TLB load. This loading
process has a fairly signiﬁcant overhead due to the fact that
two interrupts (the page fault and the debug interrupt) are
required in order to complete it. This overhead ends up be-
ing minimal overall for many applications due to the fact
that instruction-TLB loads are fairly infrequent, as it only
needs to be done once per page of instructions.
Another problem is that of context switches in the op-
erating system. Whenever a context switch (meaning the
OS changes running processes) occurs, the TLB is ﬂushed.
This means that every time a protected process is switched
out and then back in, any memory accesses it makes will
trigger a page fault and subsequent TLB load. The over-
heard of these TLB loads is signiﬁcantly higher than a tra-
ditional page fault, and hence causes the majority of our
slowdown. The problem of context switches is, in fact, the
greatest cause of overhead in the implemented system. The
experimental details of the overhead can be seen in section
5.3.
5. Implementation and Evaluation
5.1. Proof of Concept Implementation
An x86 implementation of the above method has been
created by modifying version 2.6.13 of the Linux kernel. In
this section, we present a description of the modiﬁcations to
create the architecture.
Modiﬁcations to the ELF Loader
ELF is a format that deﬁnes the layout of an executable ﬁle
stored on disk. The ELF loader is used to load those ﬁles
into memory and begin executing them. This work includes
setting up all of the code, data, bss, stack, and heap pages
as well as bringing in most of the dynamic libraries used by
a given program.
The modiﬁcations to the loader are as follows: After the
ELF loader maps the code and data pages from the ELF ﬁle,
for each one of those pages two new, side-by-side, physical