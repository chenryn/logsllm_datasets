further discussed in Sec. 7.3. We use the For scheme (k=3) weaved
Tool
P1
(basic)
Robust ?
P2
(obfuscated)
P3
(weak)
✓
✓
✓
✓
✓
✓
×
×
×
✓
✓
✓
GCC -Ofast
clang -Ofast
Frama-C Slice
Frama-C Taint
Triton (taint)
KLEE
✓
×
✓
✓
✓
✓
✓: no protection simplified
×: ≥ 1 protection simplified
into the code following our robust-by-design method (Sec. 6.2). Ac-
tually we consider 3 variants of the scheme: P1, P2 and P3. P1 is the
simple version of For presented in Fig. 8, P2 is a mildly obfuscated
version (adds a if statement always evaluating to true in the loop
– opaque predicate) and P3 naively relies on fake inputs, as Fig. 2’s
Split (a dangerous construction discussed in Sec. 7.3). A protection
will be said to be simplified when the number of explored paths for
full coverage is much lower than expected (DSE tools), no protec-
tion code is marked by the analysis tool (Frama-C) or running KLEE
on the produced code does not show any difference (compilers).
Results & Observations. Results in Table 5 confirm expectations.
No analyzer but clang is able to simplify our robust-by-design
protections (P1 and P2), whereas the weaker P3 is broken by slicing
(GCC, clang, Frama-C) but not by tainting – exactly as pointed
out in Sec. 7.3. Interestingly, clang -Ofast simplifies scheme P1, not
due to slicing (this is resistant by design), but thanks to some loop
simplification more akin to a pattern attack, relying on finding an
affine relation between variables and loop counters. The slightly
obfuscated version P2 is immune to this particular attack.
Conclusion. Our robust-by-design method experimentally works
as expected against taint and slice (RQ3). Yet, care must be taken
to avoid pattern-like simplifications. Note that in a real scenario,
the attacker must work on binary code, making static analysis
much more complicated. Also, virtualization, unpacking or self-
modification can be added to path-oriented protections to preclude
static analysis.
9 APPLICATION: HARDENED BENCHMARK
We propose new benchmarks containing 4 programs from Banes-
cu’s dataset and Sec. 8.2’s 6 real-world programs (GRUB excluded)
to help advance the state of the art of symbolic deobfuscation.
Each program comes with two setups, Path Exploration and Se-
cret Finding, obfuscated with both a path-oriented protection (For
k=5, taint- and slice- resistant) and a virtualization layer against
human and static attacks4. Table 6 shows the performance of KLEE,
Triton, Binsec and Angr (Secret Finding, 24h timeout). Hardened
codes remain unsolved within the timeout, for every tool.
4Sources available at https://bit.ly/2GNxNv9
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
Mathilde Ollivier, Sébastien Bardin, Richard Bonichon, and Jean-Yves Marion
Table 6: Results on 10 hardened examples (secret finding)
Unprotected
(TO = 10 sec)
10/10
10/10
10/10
10/10
KLEE
Binsec
Triton
Angr
Virt ×1
(TO = 5 min)
10/10
10/10
10/10
10/10
Hardened – For (k=5)
(TO = 24h)
0/10 ✓
0/10 ✓
0/10 ✓
0/10 ✓
10 DISCUSSION
10.1 On the methodology
We discuss potential biases of our experimental evaluation.
Metrics. We add overhead metrics (runtime, code size) to the com-
monly used “DSE slowdown” measure [5, 37], giving a better ac-
count of the pros and cons of obfuscation methods.
Obfuscation techniques & tools. We consider the strongest stan-
dard obfuscation methods known against DSE, as identified in
previous systematic studies [5, 37]. We restrict ourselves to their
implementation in Tigress, a widely respected and freely available
obfuscation tool considered state-of-the-art – studies including Ti-
gress along packers and protected malware [8, 51] do not report
serious deficiencies about its protections. Anyway, the evaluation
of the path-oriented protections is independent of Tigress.
DSE engines. We use 4 symbolic execution engines (mostly KLEE,
also: Binsec, Triton, Angr) working on different program repre-
sentations (C source, binary), with very similar final results. More-
over, KLEE is a highly respected tool, implementing advanced path
pruning methods (path merging) and solving strategies. It also ben-
efits from code-level optimizations of Clang as it operates on LLVM
bitcode. Previous work [5] considers KLEE as the worst-case off-the-
shelf attacker, in front of Triton [38] and Angr [43].
Benchmarks. Our benchmarks include Banescu et al.’s synthetic
benchmarks [5], enriched by 7 larger real-life programs consisting
essentially of hash functions (a typical software asset one has to
protect) [37]. We also work both on source and binary code to
add another level of variability. As already said, the considered
programs are rather small, on purpose, to embody the defender worst
case. Note that this case still represents real life situations, e.g.,
protecting small critical assets from targeted DSE attacks.
10.2 Generality of path-oriented protections
Path-oriented protections should be effective on a larger class of
attacks besides DSE – actually, all major semantic program analysis
techniques. Indeed, all path-unrolling methods will suffer from
path explosion, including Bounded model checking [10], backward
bounded DSE [8] and abstract interpretation with aggressive trace
partitioning [33]. Model checking based on counter-example guided
refinement [31] will suffer both from path explosion and Single
Value Path protections – yielding ineffective refinements in the
vein of [15]. Finally, standard abstract interpretation [4] will suffer
from significant precision loss due to the many introduced merge
points – anyway purely static techniques cannot currently cope
with self-modification or packing.
10.3 Countermeasures and mitigations
Slicing, tainting and pattern attacks, are thoroughly discussed in
Sec. 6.2 and 7.
Advanced program analysis techniques for loops is a very hot
research topic, still largely open in the case of under-approximation
methods such as DSE. The best methods for DSE are based on
path merging [3], but they lack a generalization step allowing to
completely capture loop semantics. Even though KLEE implements
such path merging, it still fails against our protections. Widening
in abstract interpretation [4] over-approximates loop semantics,
but the result is often very crude: using such over-approximations
inside DSE is still an open question. Anti-implicit flow techniques
[34, 35] may identify dataflow hidden as control-flow (it identified
for instance a For forking point), yet they do not recover any precise
loop semantics and thus cannot reduce path explosion.
Finally, note that: (1) obfuscation schemes can easily be scattered
along several functions (see alternative For encodings in Sec. 7.1)
to bar expensive but targeted intra-procedural attacks – attackers
will need (costly) precise inter-procedural methods, (2) real-life
attacks are performed on binary code – binary-level static analysis
is known to be extremely hard to get precise; and (3) static analysis
is completely broken by packing or self-modification.
11 RELATED WORK
We have already discussed obfuscation, symbolic execution and
symbolic deobfuscation throughout the paper, including successful
applications to deobfuscation [8, 24, 37, 51]. In addition, Schrit-
twieser et al. [39] give an exhaustive survey about program analysis-
based deobfuscation, while Schwartz et al. [40] review DSE and
tainting for security.
Limits of symbolic execution. Anand et al. [2] describe, in the
setting of automatic testing, the three major weaknesses of DSE:
Path explosion, Path divergence and Complex constraints. Cadar [16]
shows that compiler optimizations can sensibly alter the perfor-
mance of a symbolic analyzer like KLEE, confirming the folklore
knowledge that strong enough compiler optimizations resemble
code obfuscations. That said, the performance penalty is far from
offering a strong defense against symbolic deobfuscation.
Constraint-based anti-DSE protections. Most anti-DSE tech-
niques target the constraint solving engine through hard-to-solve
predicates. The impact on symbolic deobfuscation through the com-
plexification of constraints has been studied by Banescu et al. [6].
Biondi et al. [11] propose an obfuscation based on Mixed Boolean-
Arithmetic expressions [52] to complexify points-to functions, mak-
ing it harder for solvers to determine the trigger. Eyrolles et al.
[29] present a similar obfuscation together with a MBA expression
simplifier based on pattern matching and arithmetic simplifications.
Cryptographic hash functions hinder current solvers and can re-
place MBA [42]. In general, formula hardness is difficult to predict,
and solving such formulas is a hot research topic. Though cryp-
tographic functions resist solvers up to now, promising attempts
exist [36]. More importantly, private keys must also be protected
against symbolic attacks, yielding a potentially easier deobfuscation
subgoal – a standard whitebox cryptography issue.
Other anti-DSE protections. Yadegari and Debray [50] describe
obfuscations thwarting standard byte-level taint analysis, possibly
How to Kill Symbolic Deobfuscation for Free
(or: Unleashing the Potential of Path-Oriented Protections)
resulting in missing legitimate paths for DSE engines using taint
analysis (Triton does, KLEE and Binsec do not). It can be circum-
vented in the case of taint-based DSE by bit-level tainting [50]. Sym-
bolic Code combines this idea with trigger-based self modifications.
Solutions exist but must be carefully integrated [12, 50]. Wang et
al. [49] propose an obfuscation based on mathematical conjectures
(e.g., Collatz) to conceal a trigger condition. This transformation
increases the number of paths through specifically crafted loops,
ensured by the conjecture to always converge to the same result.
The main differences are that (1) we seek to protect the entire code,
and (2) we do not rely on conjectures. In addition, the method is
highly susceptible to pattern attacks since there are few well-suited
conjectures. Banescu et al. [5] propose an anti-DSE technique based
on encryption and proved to be highly effective, but it requires
some form of secret sharing (the key) and thus falls outside the
strict scope of MATE attacks that we consider here. Stephens et
al. [45] recently proposed an obfuscation based on covert chan-
nels (timing, etc.) to hide data flow within invisible states. Current
tools do not handle correctly this kind of protections. However, the
method ensures only probabilistic correctness and thus cannot be
applied in every context.
Systematic evaluation of anti-DSE techniques. Banescu et al. [5]
set the ground for the experimental evaluation of symbolic deobfus-
cation techniques. Our own experimental evaluation extends and
refines their method in several ways: new metrics, different DSE
settings, larger examples. Bruni et al. [15] propose a mathematically
proven obfuscation against Abstract Model Checking attacks.
12 CONCLUSION
Code obfuscation intends to protect proprietary software assets
against attacks such as reverse engineering or code tampering. Yet,
recently proposed (automated) attacks based on symbolic execution
(DSE) and semantic reasoning have shown a great potential against
traditional obfuscation methods. We explore a new class of anti-
DSE techniques targeting the very weak spot of these approaches,
namely path exploration. We propose a predictive framework for
understanding such path-oriented protections, and we propose
new lightweight, efficient and resistant obfuscations. Experimental
evaluation indicates that our method critically damages symbolic
deobfuscation while yielding only a very small overhead.
REFERENCES
[1] Tigress challenge. http://tigress.cs.arizona.edu/challenges.html.
[2] S. Anand, E. K. Burke, T. Y. Chen, J. Clark, M. B. Cohen, W. Grieskamp, M. Harman,
M. J. Harrold, and P. McMinn. An orchestrated survey of methodologies for
automated software test case generation. Journal of Systems and Software, 2013.
[3] Thanassis Avgerinos, Alexandre Rebert, Sang Kil Cha, and David Brumley. En-
hancing symbolic execution with veritesting. Commun. ACM, 59(6), 2016.
[4] Gogul Balakrishnan and Thomas W. Reps. WYSINWYX: what you see is not
what you execute. ACM Trans. Program. Lang. Syst., 32, 2010.
[5] Sebastian Banescu, Christian S. Collberg, Vijay Ganesh, Zack Newsham, and
Alexander Pretschner. Code obfuscation against symbolic execution attacks. In
Annual Conference on Computer Security Applications, ACSAC 2016, 2016.
[6] Sebastian Banescu, Christian S. Collberg, and Alexander Pretschner. Predicting
the resilience of obfuscated code against symbolic execution attacks via machine
learning. In USENIX Security Symposium, 2017.
[7] Boaz Barak, Oded Goldreich, Russell Impagliazzo, Steven Rudich, Amit Sahai,
Salil P. Vadhan, and Ke Yang. On the (im)possibility of obfuscating programs. In
Advances in Cryptology - CRYPTO, 2001.
[8] Sébastien Bardin, Robin David, and Jean-Yves Marion. Backward-bounded DSE:
targeting infeasibility questions on obfuscated codes. In 2017 IEEE Symposium
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
[9] Clark Barrett and Cesare Tinelli. Satisfiability Modulo Theories. Springer Interna-
on Security and Privacy, SP, 2017.
tional Publishing, 2018.
[10] Armin Biere. Bounded Model Checking. In Handbook of Satisfiability. 2009.
[11] Fabrizio Biondi, Sébastien Josse, Axel Legay, and Thomas Sirvent. Effectiveness
of synthesis in concolic deobfuscation. Computers & Security, 70, 2017.
[12] Guillaume Bonfante, José M. Fernandez, Jean-Yves Marion, Benjamin Rouxel,
Fabrice Sabatier, and Aurélien Thierry. Codisasm: Medium scale concatic disas-
sembly of self-modifying binaries with overlapping instructions. In Conference
on Computer and Communications Security, 2015.
[13] David Brumley, Cody Hartwig, Zhenkai Liang, James Newsome, Dawn Xiaodong
Song, and Heng Yin. Automatically identifying trigger-based behavior in malware.
In Wenke Lee, Cliff Wang, and David Dagon, editors, Botnet Detection: Countering
the Largest Security Threat, volume 36 of Advances in Information Security, pages
65–88. Springer, 2008.
[14] Robert Brummayer and Armin Biere. Boolector: An efficient SMT solver for
bit-vectors and arrays. In International Conference on Tools and Algorithms for
the Construction and Analysis of Systems, TACAS, 2009.
[15] Roberto Bruni, Roberto Giacobazzi, and Roberta Gori. Code obfuscation against
abstract model checking attacks. In Verification, Model Checking, and Abstract
Interpretation - 19th International Conference, VMCAI, 2018.
[16] Cristian Cadar. Targeted program transformations for symbolic execution. In
Meeting on Foundations of Software Engineering, ESEC/FSE, 2015.
[17] Cristian Cadar, Daniel Dunbar, and Dawson R. Engler. KLEE: unassisted and
automatic generation of high-coverage tests for complex systems programs. In
8th USENIX Symposium on Operating Systems Design and Implementation, OSDI,
2008.
[18] Cristian Cadar and Koushik Sen. Symbolic execution for software testing: three
decades later. Commun. ACM, 56(2), 2013.
[19] Mariano Ceccato, Paolo Tonella, Cataldo Basile, Paolo Falcarin, Marco Torchiano,
Bart Coppens, and Bjorn De Sutter. Understanding the behaviour of hackers
while performing attack tasks in a professional setting and in a public challenge.
Empirical Software Engineering, 24(1):240–286, Feb 2019.
[20] Sang Kil Cha, Thanassis Avgerinos, Alexandre Rebert, and David Brumley. Un-
leashing mayhem on binary code. In Symposium on Security and Privacy, SP,
2012.
[21] Christian Collberg and Jasvir Nagra. Surreptitious Software: Obfuscation, Water-
marking, and Tamperproofing for Software Protection. Addison-Wesley Profes-
sional, 1st edition, 2009.
[22] Christian Collberg, Clark Thomborson, and Douglas Low. A taxonomy of obfus-
cating transformations, 1997.
[23] Christian S. Collberg, Sam Martin, Jonathan Myers, and Jasvir Nagra. Distributed
application tamper detection via continuous software updates. In Annual Com-
puter Security Applications Conference, ACSAC, 2012.
[24] Kevin Coogan, Gen Lu, and Saumya K. Debray. Deobfuscation of virtualization-
obfuscated software: a semantics-based approach. In Conference on Computer