vice in a closed loop -
clients submit a job, receive the
response and then "thin "for some amount of time (20ms)
before submitting the next job [33]. Every experiment had
a startup phase in which we populated the data repository
with 1024 distinct objects identified by object identifiers.
Client requests were drawn from a Zipf distribution (with
8=1) over the space of object identifiers - reads and writes
equally distributed. In all experiments clients are the front-
ends from Figure 2. We measure the Web Service Interac(cid:173)
tion Time, Le.
the request latency as observed by 1, 2, 4,
16, 32, 64, 128, 256, 512, 800 and 1024 concurrent clients
- multiple virtual clients ran on the same 64 physical ma(cid:173)
chines. During each run, all clients are initially instructed
by a coordinator to start the experiment without ta ing any
measurements - this warm up period of roughly 20 seconds
is required for various reasons for example it is well nown
that to-date JVM's notoriously underperform until the just
in time compiler is fired up. At this point the coordinator
instructs all clients to start ta ing measurements - this lasts
20 seconds as well, at which point the coordinator instructs
nodes to cool down for 20 seconds and then stop.
Figure 4 shows that Tempest latency is significantly less
than any of the baselines, thus confirming that fault-tolerant
services with performance-critical properties can be built on
top of the Tempest platform. The graphs also indicate that
Tempest scales well with the number of concurrent requests.
As can be seen from the brea down of the latency, the
baselines distribution of overhead is bimodal. For up to
64 concurrent clients the database interaction time (data ac(cid:173)
cess) increases roughly linearly. For more than 64 clients
the data access time remains the same while the total la(cid:173)
tency continues to increase with the number of concurrent
requests. This indicates that the databases and / or the Tom(cid:173)
cat application server have some sort of queueing admission
control that ta es effect under severe load.
Loo ing carefully at the brea down of the latency in Fig(cid:173)
ure 4 (the I-to-32 concurrent clients spectrum) one can no(cid:173)
tice that the time spent by a Tempest service manipulating
the data (Le. performing object deep cloning, data structure
lock contention, web service invocation identifier tagging
and index maintenance) is an order of magnitude smaller
as a matter of fact
compared to the database interaction -
it is around 1 millisecond no matter what the number of
concurrent clients is -
thus showing that fine grained data
structures allow for better performance under contention.
4.2 Graceful Recovery under Heavy Load
Next, we ran a set of experiments to report on Tempest's
behavior in the face of failures. Node crashes turned out
not to be especially interesting since the gossip failure de(cid:173)
tection protocols quic ly detects failed nodes, expels them
from the group and shifts wor
to other nodes. More details
on the timeliness of a variant of the gossip based failure de(cid:173)
tector we used can be found in our previous wor
[26]. We
did however identify a class of overload scenarios that have
a more visible impact on the Tempest replicated services.
These scenarios degrade some service components without
crashing them. The services become lossy and inconsistent,
and queries return results based on stale data. Two ques(cid:173)
tions are of interest here: behavior during the overload, and
1-4244-2398-9/08/$20.00 ©2008 IEEE
232
DSN 2008: Marian et at
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:30:40 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 2008
90 ,......,.---r---r-T"-r--.---r-....--r-.----,........,___r_T-----r--r-r~-.-.,.......,-......._____r_T___.__r__,__,
2000 ...---.--T---,---,---.----........---,---,---r-........-.-........-,....,.....,-----r--,--r-~~_.___._,....,
latency ~
data access -
latency ~
data access _
80
70
.-,
60g
~ 50
uG 40
30
~
~
20
10
o ............."""""""""""'--.-.><l'I""""""".................--.....-"--
1800
1600
1400
1200
1000
800
600
400
200
0~_0lI----lIAll
Figure 4. Request latency. Each group of bars represent Tempest (tempest), TimesTen on the local
machine with tomcat (ttlocal), TimesTen on a remote machine (tt), TimesTen in primary-backup mode
with the primary on the same machine as tomcat and the backup on a remote machine (ttrepl), and
MySQL on a remote machine (mysql).
the time required to recover after it ends.
We replicated the ShoppingCart service on 6 Tem(cid:173)
pest low-end servers on the Cornell cluster. A client in(cid:173)
jects a single source stream of updates at a particular rate of
one update every 20 milliseconds. This client also concur(cid:173)
rently performs query requests on 8 concurrent threads (cid:173)
the query rate is therefore roughly 8 times higher than the
update rate. Under these circumstances Tempest nodes are
not overloaded -
the overload unfolds as follows:
• At time t, from the start of the experiment 128 "rogue"
clients bombard 3 of the Tempest servers with re(cid:173)
quests. We call the Tempest services victims.
• At time t + ~, the rogue clients terminate. At roughly
the same time, the stream of updates also ceases.
In the experiment we report on t is 10, and ~ is 30 sec(cid:173)
onds. The rogue clients bombard the victims with multiple
streams of continuous IP multicast requests in the attempt
to saturate their processing capacity and have their ernel
/ NIC queues drop pac ets. We found that this was not
enough to perturb the normal behavior of the servers, hence
at the same time we superimposed additional bac ground
load on the victim servers. These attac s do not cause the
servers to crash, but they do cause them to become over(cid:173)
loaded, drop pac ets and therefore return stale results.
Server overloads will not influence the performance of
Tempest at non-attac ed services, hence we report only on
the impact of the disruption at the victim replicas. Fig(cid:173)
ure 5 shows the number of "stale" query results on the y(cid:173)
axis against the time in seconds on the x-axis, binned in
2-second intervals. The Tempest gossip rate is set at once
500----0----0----,----,----------,
Q)
UJ 40
.~a.
~ 30
(ij
1;)
'0
CD 20
.c
E
::J
Z 10
50
100
Time(s)
150
200
250
Figure 5. Number of stale results.
every 40 milliseconds. Throughout this period, the victim
nodes are overloaded and drop pac ets, while the Tempest
repair protocols labor to repair the resulting inconsistencies.
Meanwhile, queries that manage to reach the overloaded
nodes could glimpse stale data (not reflecting recent issued
updates since the updates were lost).
Note that once the attac
ends, Tempest is able to re(cid:173)
cover gracefully. The number of stale replies observed fol(cid:173)
Iowa tri-modal distribution corresponding to normal oper(cid:173)
ational regime, response under heavy load (between 30 and
40 seconds in the experiment) and a transient recovery pe(cid:173)
riod during which the gossip protocol brings the state up to
date (between 40 and 65 seconds in the experiment) - as
mentioned before the update stream ceases at the same time
as the attac does therefore new updates are not responsible
1-4244-2398-9/08/$20.00 ©2008 IEEE
233
DSN 2008: Marian et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:30:40 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-27 2008
10, VAR
CPU, VAR---
..
:
;
CPU & 10 ~·_·_·_·-I
CPU & 10 VAR ~.....•.,.,..
10 i·..• B
CPU )
I,
\....._.
t.:~~~~~"~.:::~::.::~.;;~.;.:~:-.::;.:.~:-~::~:;':~:~:::~:;::.;:.;::;'.~;
140.--~-~-~-----,
120
100
80
60
200
400
Latency (ms)
600
E
~ 100
'0
~ 80
:is
!
:g
'5i 40a
60
120
20
l
200
400
Latency (ms)
600
800
. 120
100
80
60
40
20
".....,
!
~
u
s::QJ
~
t-J
0
0
10
30
20
50
Number of service replicas
40
Figure 7. Pet-store response time his(cid:173)
tograms, left: no replicas, right: 8 replicas.
60
70
Figure 6. PetStore services characteristics.
for "clearing up" the stale state.
4.3
Scalability in the Number of Services
To estimate how Tempest scales in different dimensions
in particular, the si e of the collaborating services, num(cid:173)
-
ber of front-ends and number of replicas - we built a syn(cid:173)
thetic PetStore on top of Tempest and evaluated it on the
Emulab testbed. The application consists of a battery of
front ends issuing requests to a "cloud" of services.
The services in the cloud have different response time
characteristics: some are 10 intensive - for example an in(cid:173)
dexing service may access dis much more often than the
average service, others are CPU intensive - for example
a recommendation service may require considerably more
CPU cycles than the average service, while other services
are both 10 and CPU bound. We also consider the response
time variances for these types of services, in particular the
PetStore services have both small and large response time
variance. We observed that services performing multiple 10
operations are li ely to suffer from scheduling delays. Loc
contention within Tempest may be another cause for large
response time variance. All PetStore services store soft state
using some form of a TempestMap or TempestSet.
Initially we ran a set of baseline experiments to measure
the behavior of each type of service individually, under nor(cid:173)
mal load. The experiment consisted of two front ends issu(cid:173)
ing request streams (half updates half reads) of one query
every 40 milliseconds in closed loop to a single replicated
service. Services have the gossip rate set for once every 100
milliseconds. We repeated the experiment for various num(cid:173)
ber of replicas and for each of the types of services men(cid:173)
tioned above. Figure 6 shows the query latency for all ser(cid:173)
vices; the error bars represent standard error. Note that even
for services that we instrumented to have small response
time variance, if they are 10 bound they do exhibit large
-1 query, baseline
- - - 1 queries, adaptive
,- ,- ,2 queries, adaptive
",,'" 5 queries, adaptive
" " " I
- -1-__ ,_
,,,~:.,:i~~~::.r~~: ~,F,7'71","""!
" _
~",...,,,,i·':'·'
120
100
en 80
.s