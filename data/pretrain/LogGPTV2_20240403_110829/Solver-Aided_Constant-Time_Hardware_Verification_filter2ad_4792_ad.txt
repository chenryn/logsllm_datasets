The previous step leaves us with a set of nodes Cex, which lost
the constant-time property first. Since these nodes must have lost
the constant-time property through a control dependency on a
secret value, we can compute a set of variables Blame that are
directly responsible: the immediate predecessors of Cex in the
dependency graph with respect to a control dependency. Formally,
for dependency graph ğº = (ğ‘‰ , ğ· âˆª ğ¶), we let Blame â‰œ {ğ‘¤ | ğ‘£ âˆˆ
Cexâˆ§ (ğ‘¤, ğ‘£) âˆˆ ğ¶} . To synthesize secrecy assumptions that remove
the constant-time violation, we could directly assume that all nodes
in Blame are public. But this is often a poor choice: variables in
Blame can be defined deep inside the circuit, whereas we would
like to phrase our assumptions in terms of externally visible input
sources.
Finding Secrecy Assumptions via ILP. Instead, we compute a
minimal set of assumptions close to the input sources via a reduc-
tion to Integer Linear Programming (ILP). To this end, we use a sec-
ond proof artifact, a map secret thatâ€”similar to varTimeâ€”describes
the temporal order in which the verifier determines variables have
become secret, i.e., ceased being public. Let ğºâ€² = (ğ‘‰ â€², ğ·â€²âˆªğ¶â€²) be the
reduced dependency graph with respect to secret, and let No âŠ† ğ‘‰ â€²
be a set of variables that the user chose to exclude from considera-
tion. Xenon produces constraints on a new set of variables: two
constraint variables ğ‘šğ‘£ âˆˆ {0, 1} and ğ‘ğ‘£ âˆˆ {0, 1}, for each program
variable ğ‘£, such that ğ‘šğ‘£ = 1, if program variable ğ‘£ is marked public
by an assumption, and ğ‘ğ‘£ = 1, if ğ‘£ can be shown to be public, that is,
it is either marked public, or all its predecessors are public. Then,
Xenon produces the following set of constraints.
ğ‘šv â‰¥ ğ‘v,
ğ‘šv +(cid:16)ğ‘¤âˆˆpre(ğ‘£,ğºâ€²) ğ‘w
#pre(ğ‘£,ğºâ€²)
ğ‘v = 1
ğ‘šv = 0
(cid:17) â‰¥ ğ‘v
if ğ‘£ âˆˆ ğ‘‰ â€² , pre(ğ‘£, ğºâ€²) = âˆ…
if ğ‘£ âˆˆ ğ‘‰ â€² , pre(ğ‘£, ğºâ€²) â‰  âˆ…
if ğ‘£ âˆˆ (Blame \ No)
if ğ‘£ âˆˆ No
(1)
(2)
(3)
(4)
Constraints (1) and (2) ensure that a variable is public, if either it
is marked public, or all its predecessors in ğºâ€² are public. Constraint
(3) ensures that all blamed variables that have not been excluded
can be shown to be public, and finally, constraint (4) ensures that
all excluded constraints are not marked. Let ğ‘‘(ğ‘£, ğ‘¤) be a distance
metric, i.e., a function that maps pairs of nodes to the natural num-
bers. Then we want to solve the constraints using the following
objective function that we wish to minimize, where for ğ‘£ âˆˆ ğ‘‰ â€², we
define as weight the minimal distance from one of the source nodes:
ğ‘¤ğ‘£ğ‘šv,
(objective)

ğ‘£âˆˆğ‘‰ â€²
and we let ğ‘¤ğ‘£ = (minğ‘–ğ‘›âˆˆSrc ğ‘‘(ğ‘–ğ‘›, ğ‘£)). A solution to the constraints
defines a set of assumptions A = (Flush, Pub), with Flush â‰œ
{ğ‘£ âˆˆ ğ‘‰ â€² | ğ‘šv = 0 âˆ§ ğ‘v = 0} and Pub â‰œ {ğ‘£ âˆˆ ğ‘‰ â€² | ğ‘šv = 1}. The
constraints can be solved efficiently by an off-the-shelf ILP solver.
Example: Simplified Pipeline. Consider again the pipeline in Fig-
ure 8. As we identified ID_instr as counterexample in the previous
step, we need to ensure that its blame-set consisting of all indirect
influences is public. ID_instr only depends on Stall, and there-
fore we add constraint ğ‘Stall = 1. Since all variables are secret (i.e.,
we didnâ€™t make any public-assumptions yet), the reduced graph is
equal to the original graph. For variables IF_instr and ID_instr,
we get: ğ‘šIF_instr + ğ‘IF_pc â‰¥ ğ‘IF_instr and
ğ‘šID_Instr + ğ‘IF_instr + ğ‘Stall
â‰¥ ğ‘ID_Instr.
2
We obtain the following objective function: ğ‘šIF_pc + 2ğ‘šIF_instr +
3ğ‘šID_instr +. . . . Sending the constraints to an ILP solver produces
a solution, where ğ‘šIF_pc = 1, and ğ‘šv = 0, for all variables ğ‘£ â‰ 
IF_PC, and ğ‘v = 1, for all ğ‘£. This corresponds to the following
assumption set A â‰œ (ğ¹ğ‘™ğ‘¢ğ‘ â„, {IF_PC}), where ğ¹ğ‘™ğ‘¢ğ‘ â„ includes all
variables except IF_PC. This is exactly our desired minimal solution
where we only mark IF_pc as public. Note that our method does
not necessarily result in all variables becoming public. We give an
example in Appendix A.
Session 2B: Formal Analysis and Verification CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea4364.3 Modular Assumption Synthesis
To avoid a blowup in constraint size and to keep counterexamples
and assumptions local, we want to avoid inlining instantiated mod-
ules. We, therefore, extract a dependency graph from the module
summary. Whenever the summary requires an input in to be public
for an output out to be constant-time, we draw a control depen-
dency between in and out. Whenever the summary requires an
input in to be constant-time for an output out to be constant-time,
we draw a data dependency. Finally, we insert the computed sum-
mary graph into the top-level dependency graph, and connect the
instantiation parameters to the graphâ€™s inputs and outputs.
Example. We modify Figure 8 to factor out the updates to ID_instr
into a separate module. Xenon computes the following summary
invariant, from which we create the graph in Figure 9c
ğ‘ğ‘¡(IF_instr) âˆ§ ğ‘ğ‘¢ğ‘(Stall) â‡’ ğ‘ğ‘¢ğ‘(ID_instr) .
Since connecting the instantiated variables to the summary graph
is equivalent to (Figure 9a), our analysis returns the same result.
5 IMPLEMENTATION
Xenon is split into front-end and back-end. Our front-end trans-
lates Verilog to an intermediate representation (IR) and asso-
ciates secrecy assumptions with input and output wires. Our back-
end translates this annotated IR into verification conditions (Horn
clauses); when verification fails, we generate counterexamples and
secrecy assumptions and present them to the user for feedback.
We implement the back-end in roughly 9KLOC Haskell, using
the liquid-fixpoint (0.8.0.2) [8] and Z3 (4.8.1) [37] libraries for
verification, and the GLPK (4.65) [7] library for synthesizing as-
sumptions by solving the ILP problem of Â§ 4. Our tool and evalu-
ation data sets, including the secrecy assumptions discovered for
SCARV (Â§ 7) are open source and available on GitHub at https:
//xenon.programming.systems.
6 EVALUATION
We evaluate Xenon by asking the following questions:
â–¶ Q1: Are constant-time counterexamples effective at localiz-
ing the cause of verification failures?
â–¶ Q2: Are the secrecy assumptions suggested by Xenon use-
ful?
â–¶ Q3: What is the combined effect of counterexamples and
secrecy assumption generation on the verification effort?
â–¶ Q4: Do module summaries improve scalability?
â–¶ Q5: Does Xenon reduce verification time by helping users
find secrecy assumptions?
â–¶ Q6: How does using Xenon affect assumption quality?
To answer questions Q1 and Q2, we use Xenon to recover the
assumptions for the benchmark suite from [50]. These benchmarks
include a MIPS and RISC-V core, ALU and FPU modules, and RSA
and SHA-256 crypto modules. To answer Q3 and Q4, we evaluate
Xenon on two challenging new benchmarks, the SCARV â€œside-
channel hardened RISC-Vâ€ processor [4] whose size exceeds the
largest benchmark from [50] by a factor of 10, and a highly modular
AES-256 implementation [10]. Finally, we conduct a user study
to answer Q5 and Q6, in which participants were asked to find
assumptions for three benchmarks from [50]: two benchmarks
with relatively simple assumptions (ALU and FPU) and RISC-V core
with a more complex assumption set.4
Summary. Xenonâ€™s counterexample synthesis dramatically re-
duces the number of potential error locations users have to manu-
ally inspect (6% of its original size) and most of Xenonâ€™s assumption
suggestions are accepted by the user (on average 81.67%). Module
summaries are key to reducing verification times for certain designs
(e.g., for AES-256 summaries reduced the verification time from six
hours to three seconds). We find the counterexamples and secrecy
assumptions suggested by Xenon to be crucial to reducing the
human-in-the-loop time from days to (at worst) hours. Our user-
study findings indicate thatâ€”using Xenonâ€”participants were able
to correctly complete significantly more tasks, showing a very large
(ğ‘‘ = 1.62), statistically significant (ğ‘¡(8) = 2.56, ğ‘ = .016) positive ef-
fect on correct completion. Participants in the test group produced
fewer (ğ‘‘ = 1.03) incorrect solutions (ğ‘¡(5.5) = 1.63, ğ‘ = .07), and
solution sizes were smaller on average.
Experimental Setup. We run all experiments on a 1.9GHz Intel
Core i7-8650U machine with 16 GB of RAM, running Ubuntu 20.04
with Linux kernel 5.4.
Methodology. For every benchmark used to answer Q1â€“Q4, we
start with an empty set of secrecy assumptions and run Xenon
repeatedly to recover the missing assumptions needed to verify the
benchmark. We collect the following information after every invoca-
tion of the tool: the total number of variables that are variable-time
and secret; the size of the counterexamples measured by the num-
ber of variables they contain; the number of assumptions Xenon
suggests, and how many of these assumptions we reject; finally,
we record the number of times we invoke Xenon to complete each
verification task. With all the assumptions in place, we measure
the time it takes for the tool to verify each benchmark; we report
the median of thirty runs for all but the non-modular (inlined) AES
benchmark, for whichâ€”due to its sizeâ€”we report the median of
three runs.
User-Study Design. For our user study, we recruited ten partici-
pants who had some familiarity with software constant-time ex-
ecution, but had never used Xenon or Iodine. The participants
were randomly split into two equally sized groups: Test who were
given Xenon and Control who were given Iodine. Participants
using Iodine were given access to Iodineâ€™s counterexample out-
puts. After reading the instructions, both groups were given 40
minutes to complete the three tasks, i.e., find assumptions for three
Iodine benchmarks. For each task, we recorded the time taken to
complete the task in minutes (Time), the number of annotations
in the solution set (Size), and whether the solution was correct
(Crt). We rejected solutions for ALU and FPU if they contained
assumptions about the operands, and for RISC-V, if they contained
assumptions about memory or the register-file.
Q1: Error Localization. To understand whether our counterex-
ample generation is effective at localizing the cause of verification
failures, we compare the number of variables in the counterexample
to the total number of non-constant-time variables. The CEX Ratio
column Table 1 reports the average ratio per iteration. We observe
4We include the larger RISC-V core to evaluate the hypothesis that Xenon benefits
users even if many of Xenonâ€™s suggestions are eventually rejected. We chose this
benchmark because Xenon achieves the lowest accept-ratio over all benchmarks.
Session 2B: Formal Analysis and Verification CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea437MIPS [9]
RISC-V [6]
SHA-256 [11]
FPU [2]
ALU [5]
FPU2 [3]
RSA
AES-256 [10]
SCARV [4]
Total
447
514
563
1108
1327
272
855
800
8468
#flush
28
10
4
3
1
24
29
0
73
#public
3
11
3
1
3
4
4
0
54
CT
âœ“
âœ“
âœ“
âœ“
âœ“
âœ—
âœ—
âœ“
âœ“
-
Check (H:M:S)
Inlined Modular
3.13
10.23
8.90
11.54
2.29
3.65
1.51
2.74
8:35.46
2.42
13.21
7.21
9.10
2.01
1.31
2.87
6:05:01.82
14:20.93
6:20:00.88
9:19.45
# Iter
3
5
2
1
2
-
-
-
34
47
CEX
Ratio
2.50%
16.24%
4.28%
0.33%
0.88%
-
-
-
9.08%
Sugg
Ratio
1.73%
3.98%
3.57%
0.26%
1.38%
-
-
-
5.68%
Accept
Ratio
83.33%
46.90%
100.00%
100.00%
75.00%
-
-
-
84.80%
5.55%*
2.77%*
81.67%*
Name
#LOC
#Assum
14354
159
89
Table 1: #LOC is the number of lines of Verilog code (without comments or empty lines), #Assum is the number of assumptions; flush and
public are sizes of the sets Flush and Pub respectively, CT shows if the program is constant-time, Check is the time Xenon took to check
the program; Inlined and Modular represent inlining module instances and using module summaries respectively. # Iter is the number of
times the user has to invoke Xenon to verify the benchmark starting with an empty set of assumptions; CEX Ratio is the average ratio of
the number of identifiers in the counterexample to all variable-time identifiers in a given iteration; Sugg Ratio is the average ratio of the
number of secrecy assumptions that Xenon suggests to all secret variables in a given iteration, and Accept Ratio is the ratio of user-accepted
assumptions to all Xenon suggestions. In the Total row, we use * to denote averages instead of sums. We do not run error localization on FPU2
and RSA because they are variable-time; AES-256 does not need any assumptions.
that fewer than 6% of non-constant-time variables are included in