## PostgreSQL 流式数据处理(聚合、过滤、转换...)系列 - 8              
### 作者                                                                       
digoal                                                                        
### 日期                                                                       
2017-01-05                                                                            
### 标签                                                                      
PostgreSQL , 流式 , 函数 , 流式处理 , 异步统计 , count , group , agg , 触发器 , xid , 事务隔离 , 异步气泡 , gap , function , 串行处理
----                                                                      
## 背景                   
2013年帮朋友做的方案。写了一些列文档来解决当时某个大数据BI平台的异步流式数据处理的功能。                
逐步优化，化繁为简。                   
在业务层面，统计，数据的过滤，数据的清洗，数据的事件触发等。是比较常见的需求。                    
比如以COUNT就是一个很典型的例子。                
在9.2以前全表的count只能通过扫描全表来得到, 即使有pk也必须扫描全表.                
9.2版本增加了index only scan的功能, count(*)可以通过仅仅扫描pk就可以得到.                
但是如果是一个比较大的表, pk也是很大的, 扫描pk也是个不小的开销.                
到了9.6，开始支持并行查询，通过并行，一张1亿的表，COUNT可能只需要几百毫秒。这是一个质的飞跃。（但是还有很多时候用并行并不是最好的）                
另外社区也除了一个流式处理的数据库，pipelineDB，但是它的社区版本限制了一个DATABASE只能使用1024个流视图，在编码的地方使用了1BYTE存储CV。                
那么回到postgresql数据库本身，有没有办法来优化count全表的操作呢, 如果你的场景真的有必要频繁的count全表, 那么可以尝试一下使用以下方法来优化你的场景.                
## 正文                
前面以及写了7篇关于count(*)准实时和实时统计的案例, 有基于触发器的, 有基于xid单线程取数据的.  
本文的优化方法与londiste的ticket有点类似, 即数据切片.  
将log表切分为多段, 这样的话如果分析线程串行处理速度跟不上的话, 可以并行处理. 有效的解决了基于xid单线程取数据的性能问题.  
具体的场景就不介绍了, 前面7篇按顺序读下来就知道了.  
1\. http://blog.163.com/digoal@126/blog/static/163877040201331252945440/  
2\. http://blog.163.com/digoal@126/blog/static/16387704020133151402415/  
3\. http://blog.163.com/digoal@126/blog/static/16387704020133155179877/  
4\. http://blog.163.com/digoal@126/blog/static/16387704020133156636579/  
5\. http://blog.163.com/digoal@126/blog/static/16387704020133218305242/  
6\. http://blog.163.com/digoal@126/blog/static/16387704020133224161563/  
7\. http://blog.163.com/digoal@126/blog/static/16387704020133271134563/  
这里只介绍切片函数和取数据函数.  
测试表 :   
```  
create table log   
(  
  id serial primary key,   
  xid int8 default txid_current() not null,   
  c1 int not null,   
  c2 int not null,   
  c3 int not null,   
  c4 text not null,   
  crt_time timestamp default now()  
);  
create index idx_log_1 on log(xid);  
```  
切片表  
```  
create table log_ticket(   
  id serial8 primary key,   
  split_xid int8 not null default txid_current(), -- 切片时的xid, 取数据的事务的xid必须大于该xid  
  split_time timestamp not null default now(),   
  log_xid_le int8 not null,   
  log_xid_st int8 not null,   
  log_xip int8[],   
  xid_readed boolean not null default false,   
  xip_readed boolean not null default false  
);  
```  
切片函数  
```  
create or replace function log_spilt(  
  i_timeout_sec int, -- 上次切片以来超出多少秒, 则新增切片  
  i_limit int  -- 上次切片以来超出多少条, 则新增切片  
) returns void as $$  
declare  
  v_advisory_xact_lock int8 := null;  -- 串行处理锁.  
  v_xid_snap txid_snapshot := null;  -- 当前事务状态快照  
  v_xmin int8 := null;  -- 当前事务状态快照中未完成的最小事务  
  v_xmax int8 := null;  -- 当前事务状态快照中未分配的最小事务  
  v_xip int8[] := null;  -- 当前事务状态快照中未完成的事务数组  
  v_log_xid_le int8 := null;  -- 大于等于该xid  
  v_log_xid_st int8 := null;  -- 小于该xid  
  v_split_time timestamp := null;  -- 上次切片时间  
  v_cnt int := null;  -- 从上次切片后有多少条log被插入了  
  v_log_xip int8[] := null;  -- 记录切片数据段内未完成的xid  
begin  
  -- 判断i_timeout_sec, i_limit  
  if ( i_timeout_sec 0 and i_limit > 0 .';  
    return;  
  end if;  
  -- 串行处理, 如果不能获得锁则直接退出. 确保v_advisory_xact_lock全局唯一.  
  v_advisory_xact_lock := 1;  
  if not pg_try_advisory_xact_lock(v_advisory_xact_lock) then  
    raise notice 'Another function is calling, this call will exit.';  
    return;  
  end if;  
  -- 生成 xid snapshot 数据.  
  v_xid_snap := txid_current_snapshot();  
  v_xmin := txid_snapshot_xmin(v_xid_snap);  
  v_xmax := txid_snapshot_xmax(v_xid_snap);  
  select array_agg(t) into v_xip from txid_snapshot_xip(v_xid_snap) g(t);  
  perform 1 from log_ticket limit 1;  
  if found then  
    select log_xid_st,split_time into v_log_xid_le,v_split_time from log_ticket order by split_xid desc limit 1;  
    select count(*),(max(xid)+1) into v_cnt,v_log_xid_st from (select xid from log where xid >= v_log_xid_le and xid = i_timeout_sec::text::interval or v_cnt>=i_limit) and v_cnt>=1 ) then  
      select array_agg(i) into v_log_xip from unnest(v_xip) i where i>=v_log_xid_le and i=i_limit ) then  
      select array_agg(i) into v_log_xip from unnest(v_xip) i where i>=v_log_xid_le and i0) or (not (i_mod_rem>=0 and i_mod_rem0 and 0=v_log_xid_le and xid cat ins.sql  
begin;  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
end;  
begin;  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
rollback;  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);  
```  
pgbench  
```  
pg92@digoal-PowerEdge-R610-> pgbench -M prepared -f ./ins.sql -r -n -h $PGDATA -U postgres -T 60 -c 32 -j 2  
transaction type: Custom query  
scaling factor: 1  
query mode: prepared  
number of clients: 32  
number of threads: 2  
duration: 60 s  
number of transactions actually processed: 84781  
tps = 1411.655384 (including connections establishing)  
tps = 1412.958688 (excluding connections establishing)  
```  
pgbench测试过程中执行select log_spilt(1,100000);  
```  