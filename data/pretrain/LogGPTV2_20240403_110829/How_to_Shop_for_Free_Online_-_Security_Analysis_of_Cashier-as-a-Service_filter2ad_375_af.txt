Signed message fields 
Functions annotated as wAPIs 
Function or function pointers 
Function calls 
Variables of type SignedObject 
The  merchant  module  in  our  program  was  directly 
transformed  from  the  source  code  of  Interspire,  with  the 
program elements in the original code replaced  with the C 
code  according  to  Table  IV.  In  the  absence  of  the  source 
code on the CaaS side, we built its module based upon the 
specifications  of  its  APIs,  with  a  focus  on  the  security-
476
If 
the  attacker 
is  not  allowed 
related call arguments and other parameters as described in 
Section  III.B.  We  also  emulated  the  signing  operation  on 
API  arguments  using  a  special  type  SignedObject, 
which describes a signed data item with a pair of fields, Obj 
and signer. To indicate the item is signed, its content was 
copied  into  Obj,  and  the  signing  party  was  recorded  in 
signer.  This  “signing”  of  course  has  no  cryptographic 
strength,  but  since  we  only  want  to  examine  the  program 
logic,  this  is  sufficient  for  our  definition  of  the  payment-
completion invariant, which is: 
• 
create  any 
SignedObject  bearing  the  signer  field  TargetStore  or 
CaaS, and can only call the functions annotated as wAPIs, is it 
always true that whenever an order is marked PAID, there is 
always a corresponding correct payment completed in CaaS? 
(We  will  explain  what  constitutes  “a  corresponding  correct 
payment”  later.)  
The  attacker.  In  the  C  program,  we  implemented  two 
attacker  modules,  one  concrete  and  one  symbolic.  The 
concrete  module  was  compiled  together  with  the  code  for 
the merchant and the CaaS to generate a normal executable. 
It  executed  normal  checkouts  as  well  as  all  the  attacks 
described in Section III.B. This was used to perform a sanity 
check  on  our  model,  including  the  functionalities  of  the 
merchant and the CaaS, and all the exploits we discovered. 
The symbolic module was to analyze the complexity of 
to 
finding logic flaws. It is sketched in Table V.  
TABLE V.   A SKETCH OF THE SYMBOLIC ATTACKER CODE 
#include “MerchantAndCaaS.h” 
typedef struct  
       { SignedObject * msg;  int msgType; } Knowledge; 
Knowledge[100]  Knowledgebase;  
void main() {       while (1)  call_a_wAPI(nonDet()); 
} 
void call_a_wAPI (int  wAPI_ID) { 
   switch (wAPI_ID) {        //we have modeled 10 wAPIs 
case 1:      /*call placeOrder(), see RT1.a of Figure 8 */ 
      paymentType=nonDet(); 
      Merchant_placeOrder(paymentType); 
           break; 
case 2:   /*call paypal’s stdPay() , see RT2.a of Figure 8 */ 
    orderID= nonDet();   gross= nonDet ();   recipient= nonDet (); 
    if   (nonDet ())  IPNHandler= TargetStore_PPLStdIPNHandler; 
                      else  IPNHandler= Attacker_PPLStdIPNHandler; 
         PPLStd_MakePayment(orderID,gross,recipient,IPNHandler); 
         break; … 
case 10: … 
} 
} 
wAPI void Attacker_PPLStdIPNHandler(SignedObject * obj) {  
     //handling RT2.a.a of Figure 9 
     addToKnowledgebase(obj, PPLStdIPN); 
}  …  
The  idea  is  to  let  the  attacker,  i.e.,  the  malicious 
shopper,  repeatedly  invoke  the  wAPI  functions  (emulated 
web  APIs)  on  the  merchant  and  the  CaaS  modules,  using 
symbolic  arguments,  which  was  assigned 
the  non-
deterministic value “nonDet()”. The symbolic attacker was 
compiled by Poirot to analyze for violations of the payment-
477
completion  invariant.  As  illustrated  in  Table  V,  the  whole 
attacker  module  is  organized  as  an  infinite  loop:  each 
iteration  uses  call_a_wAPI(nonDet()) 
to  non-
deterministically  select  a  web  API  to  call.  Inside  the 
implementation  of  call_a_wAPI,  we  also  assign 
symbolic values to arguments of each wAPI. For example, 
consider the code under case 2 in Table V, which is used to 
call the API https://paypal/stdPay (See RT2.a in Figure 8). 
Some  arguments  of  the  call,  including  orderID,  gross 
and  recipient,  are  directly  assigned  symbolic  values, 
while  the  value  of  IPNHandler,  which  can  be  either 
PayPal’s handler or the attacker’s, are chosen according to a 
symbolic value. Once all the arguments are set, the attacker 
calls MakePayment of PayPal Standard. 
When the attacker  module gets return  values of  wAPI 
calls  (or  its  own  wAPIs  are  called),  it  simply  ignores  the 
return values (or the argument values of incoming calls) if 
the values do not carry any signed data; otherwise (e.g., in 
the attacker function Attacker_PPLStdIPNHandler), 
it only needs is to record the signed data for later use. Note 
that  in  the  current  pseudo  code,  we  define  the  return  type 
void,  which  omits  possibilities  of  exploiting  bugs  by 
sending  error  responses  (e.g.,  RT2.a.b  is  not  OK).  In  a 
more faithful model that aims at covering the error handling 
logic, the function should return a nondeterministic value.    
C.  Automatic verification 
into  an 
intermediate 
(VC)  based  on 
Poirot first compiles the symbolic model (consisting of 
the symbolic attacker along with the concrete merchant and 
language,  generates  a 
CaaS) 
verification  condition 
the  payment-
completion  invariant,  then  verifies  the  VC  by  a  theorem 
prover.  As  mentioned  earlier,  the  invariant  requires  that 
whenever  an  order  is  changed  to  the  PAID  state,  there 
should be a “corresponding correct payment” record in the 
CaaS.  This  is  interpreted  in  our  current  implementation  as 
the  situation  when  the  gross  of  the  payment  matches  the 
order’s gross, its payee is the merchant, and its record is not 
matched  by  that  of  any  previous  order.  Note  that  this 
invariant is only a necessary-yet-insufficient condition for a 
secure checkout:  particularly, the invariant does not bind a 
product  (an  item)  to  the  merchant  who  owns  it,  and  as  a 
result,  exploits  like  the  one  that  happens  to  JR.com  could 
not be discovered. Nevertheless, our study reveals a lower-
bound of the complexity for verifying the model.    
By  setting  how  many  times  Poirot  should  unroll  the 
loop  in  function  main(),  we  can  control  the  depth  of 
Poirot’s search effort. We call this setting the bound. Bound 
x  means  that  Poirot  only  considers  all  the  execution  paths 
that contain x or less web API calls. 
Finding  attacks.  We  ran  Poirot  on  our  model 
to 
automatically  analyze  all  four  payment  methods  that  we 
studied manually. By setting the bound to 6, Poirot captured 
all the logic flaws discussed in Section III.B. The analyses 
took  355,  328,  381  and  330  seconds  for  PayPal  Standard, 
PayPal Express, Amazon Simple Pay and Google Checkout.   
It  is  particularly  interesting  that  our  analysis  also 
discovered  new  and  more  efficient  attack  avenues.  For 
example,  we thought that the attack on Interspire’s PayPal 
Express  (Section  III.B.1)  must  be  launched  through  two 
sessions  (e.g.,  through  IE  and  Firefox  as  described  in  the 
section);  the  attack  instance  reported  by  Poirot,  however, 
only needed one session. We performed this new attack on 
the  real  Interspire  executable,  which  was  found  to  work 
exactly as indicated by the tool. The details of this exploit is 
given in [37], due to the space constraint of this conference 
version. What is important here is that it demonstrates that 
the  formal  reasoning  approach  seems  promising  in  getting 
insights about the program logic that we focus on.   
Empirical  analysis  of  the  complexity.  We  hypothetically 
fixed the logic flaws in the model, so that we can measure 
the complexity of each bounded verification, i.e., to verify 
no attack possibility within each bound. Table VI gives two 
complexity  metrics:  the  number  of  conflicts  the  theorem 
prover encountered and the total time for verification, in the 
shaded  rows  and  the  clear  rows,  respectively.  When  a 
theorem is being proved, there are many Boolean decisions 
to explore. For each decision point, the theorem prover takes 
one  branch  and  goes  deeper  into  the  search.  A  conflict 
happens  when  the  theorem  prover  needs  to  backtrack  and 
take the second branch of the decision point. Conflicts are 
the  most  important  reason  for  the  state  explosion  in  the 
search; therefore, the number of conflicts is a good indicator 
of the complexity of verification3. The time measures were 
based on our PC specification: Intel Core 2 Duo CPU 3.00 
GHz, 4GB memory, 80GB hard disk.    
Table VI shows that both metrics increase significantly 
with the bound. For bound 7, most verifications encountered 
out-of-memory  errors  (OOM).  The  last  row  is  for  the 
verification of the APIs for all four payment methods. This 
best reflects the complexity in the actual implementation of 
Interspire, which currently has no mechanism to prevent the 
attacker  from  calling  all  APIs  that  belong  to  all  payment 
methods.  In  this  scenario,  the  verification  for  bound  6 
already ended with an OOM. 
2 
3 
4 
PayPal Express  
Total time in seconds 
PayPal Standard  
103  253 
TABLE VI.   NUMBER OF CONFLICTS AND TIME FOR EACH BOUND  
7 
5 
1 
574K OOM
167  574  1.3K 4.4K  42K 
3645
OOM
15.2 
385 
229K
29K
33  247  595 1.3K  4.1K 
379
1492
16.1 
225 
324K OOM
120  479  1K  3.2K  26K 
14.9 
2295
OOM
302 
123  523  1.3K  6K  74K  1636K OOM
14.5 
OOM
567  1.7K 4.5K 74K 2313K  OOM OOM
21.5  156  258  926  17384  OOM OOM
113  193 
85  145 
92  156 
15113
Total time in seconds 
Google Checkout  
Total time in seconds 
Amazon Simple Pay 
Total time in seconds 
Total time in seconds 
All APIs 
48 
42 
44 
49 
476 
6 
D.  Implications of the complexity analysis results 
Our  measurement  data  seem 
to 
indicate  a  few 
interesting points for developers:  
3 Poirot’s runtime is proportional to the number of conflicts and the work 
done per conflict in theory reasoning. The explosive growth in the number 
of conflicts leads us to believe that the cost of theory reasoning is dwarfed 
by the cost of the backtracking search. 
1)  Automatic  verification  is  necessary.  On  one  hand,  tools 
exist today to find flaws in extracted logic models, as we 
empirically  demonstrated.  On  the  other  hand,  manual 
verification  of  its  security  is  really  hard.  Hundreds  of 
thousands  of  backtracks  in  the  reasoning  process  are 
involved, well beyond what human brains can handle. 
2) Application developers should help lower the complexity 
so  that  higher  confidence  can  be  achieved  by  bounded 
verifications. Currently, bound 6 is often the limit of our 
machine’s  computational  power  for  individual  payment 
methods, and bound 5 is the limit for all payment methods 
together.  However,  many  of  our  known  attacks  already 
take 5 or 6 steps to accomplish, so the “margin of safety” 
is too small. We believe that some efforts can be taken by 
developers  to  lower  the  logic  complexity,  and  thus  to 
increase the margin of safety. For example, the payment 
methods  should  be  strictly  separated  at  runtime  so  that 
static  verification  only  deals  with  each  payment  method 
individually.  Also,  annotating  the  code  with  pre-  and 
post-conditions would make verifications much easier.  
VI.  PAYMENT PROTOCOLS VS. PAYMENT APIS 
Secure payment protocols have been studied for a long 
time.  Early  efforts  can  be  traced  back  to  the  dawn  of  the 
Internet  age.  Examples  of  these  protocols  include  iKP  of 
IBM and STT of Microsoft/Visa [18], as well as a number of 
digital cash protocols.  Among them, the most well known 
is  perhaps  Secure  Electronic  Transaction  (SET)  [39] 
proposed  by  Visa  and  MasterCard,  in  collaboration  with 
GTE,  IBM,  Microsoft,  Netscape,  RSA  and  VeriSign.  The 
security  properties  of  this  protocol  were  partially  checked 
through formal verification by many researchers, including 
Bolignano [10], Lu et al [23], Meadows et al [25] and others.  
Formal analyses [19] were also performed on other payment 
protocols, such as NetBill [13] and DigiCash [11]. 
However, to the best of our knowledge, none of these 
protocols  was  deployed  on  the  Internet  and  used  by  real-
world  e-commerce  systems.  The  technologies  that  are 
actually  adopted  by  today’s  e-commerce  are  web  services 
like  PayPal,  Amazon  Payments  and  Google  Checkout, 
which are never referred to as “payment protocols”.  Indeed 
they  are  not  protocols  –  they  are  APIs  with  proprietary 
implementations and public interfaces, accompanied by the 
developer’s  guides  and  sample  code.  Compared  with 
protocols, which clearly specify the actions different parties 
are supposed to take, the ways these APIs are used are less 
rigorously  defined,  thus  offering  flexibility  to  their  callers. 
Presumably,  the  flexibility  contributed  to  the  programmer 
friendliness and thus the popularity of these payment APIs. 
However, it leaves the security of today’s checkout systems 