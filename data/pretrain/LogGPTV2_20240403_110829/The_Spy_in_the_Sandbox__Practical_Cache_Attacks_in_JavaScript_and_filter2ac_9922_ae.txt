misses. In our measurements we noticed that Sandy Bridge
CPUs kept using the LRU policy throughout our experi-
ments. On Ivy Bridge processors, however, we witnessed
situations where some sets operated in LRU mode and some
in BIP mode. This suggests a “set dueling” mechanism, in
which the two policies are compared in real time to examine
which generates less cache misses. Haswell and Broadwell
CPUs switched between policies with high frequency, but we
could not locate regions in time where both policies were in
eﬀect (in diﬀerent cache sets).
We hypothesize that Haswell (and newer) CPUs do not
use simple set dueling, but rather a diﬀerent method, to
choose the optimal cache replacement policy. The choice of
policy had a impact on our measurements, since the BIP
policy makes the priming and probing steps harder. Prim-
ing is more diﬃcult since sequentially accessing all entries
in the eviction set does not bring the cache into a known
state—some of the entries used by the victim process may
still be in the cache set. As a result, the probing step may
spuriously indicate that the victim has accessed the cache set
in a certain time period. The combined eﬀect of these two
artifacts is an eﬀective low-pass ﬁlter applied to the memo-
rygram, which reduces our temporal resolution by a factor of
up to 16. To avoid triggering the switch to BIP, we designed
our attack code to minimize the amount of cache misses it
generates in benign cases, both by choosing a zig-zag access
pattern (as suggested by Osvik et al. [19]), and by actively
pruning our measurement data set to remove overly active
cache sets.
6.3 Noise Effects
Sources. Side-channel attacks have to deal with three
general categories of noise [18]: electronic, switching, and
quantization (or measurement). Electronic noise refers to
the “thermal noise” which is inherent in any physical sys-
tem. This source of noise is less prevalent in our attack
setup due to its relatively low resolution. Switching noise
refers to the fact that the measurements capture not only
the victim’s secret information, but also other activities of
the device under test, either correlated or uncorrelated to
the measurement. In our speciﬁc case, this noise is caused
by the spurious cache events due to background process ac-
tivity, as well as by the cache activity of the attack code and
the underlying JavaScript runtime itself. Quantization noise
refers to the inaccuracies introduced by the measurement ap-
paratus. In our speciﬁc case, this noise can be caused by the
limited resolution of the JavaScript performance counter, or
by low-level events such as context switches that occur while
the measurement code is running. It should be noted that,
with the exception of timer granularity, all sources of noise
in our system are additive (i.e., noise will only cause a mea-
surement to take longer).
Eﬀects. There are two main elements of our attack that
can be impacted by noise. The ﬁrst is the cache proﬁling pro-
cess, in which the eviction sets are created. The second is the
online step, in which the individual cache sets are probed.
Noise during the proﬁling process, speciﬁcally during steps
(1.b) and (1.e) of Algorithm 1, will cause the algorithm to
erroneously include or exclude a memory address from an
eviction set. Noise during the online step will cause the at-
tacker to erroneously detect activity on a cache set when
there is none, or to erroneously associate cache activity to a
victim process when in fact it was caused by another source.
Interestingly, one formidable source of switching noise is the
measurement process itself—since a memorygram contains
millions of measurements collected over a short period of
time, creating it has a considerable impact on the cache.
Mitigations. To quantify the prevalence of measurement
noise in our system, we measured the proportion of cache
misses in an area with no cache activity. We discovered that
around 0.3% of cache hits were mis-detected as cache misses
due to timing jitter, mostly because oﬀ context switches in
the middle of the measurement process.
1416Such events are easy to detect since the time that is re-
turned is more than the OS multitasking quantum (10ms on
our system). However, since we want our measurement loop
to be as simple as possible, we did not apply this logic in
our actual attack. To deal with the limited resolution of the
timer on some targets, we could either use the workarounds
suggested in the previous section or ﬁnd an alternative form
of time-taking that does not rely on JavaScript’s built-in
timer API. Timing jitter was generally not inﬂuenced by
CPU-intensive background activities. However, memory-
intensive activities, such as ﬁle transfers or video encoders
caused a large amount of switching noise and degraded the
eﬀectiveness of our attack considerably. To deal with the
switching noise caused by our measurement code, we spread
out our data structures so that they occupied only the ﬁrst
64 bytes of every 4KB block of memory. This guaranteed
that at most 1/64 of the cache was aﬀected by the construc-
tion of the memorygram.
Another source of noise was Intel’s Turbo Boost feature,
which dynamically varied our CPU clock speed between 2.5
GHz and 3.2 GHz. This changed the cache hit timings on
our CPU by a large factor between measurements, making
it diﬃcult to detect cache misses. To mitigate this eﬀect,
we periodically estimated the cache hit time (by measuring
the access time of a cache set immediately after priming it),
and measured cache misses against this baseline.
6.4 Additional Attack Vectors
The general mechanism we presented in this paper can be
used for many purposes other than the attack we presented.
We survey a few interesting directions below.
KASLR Derandomization. Kernel control-ﬂow hijack-
ing attacks often rely on pre-existing code deployed by the
OS. By forcing the OS kernel to jump to this code (for in-
stance by exploiting a memory corruption vulnerability that
overwrites control data), attackers can take over the entire
system [12]. A common countermeasure to such attacks is
the Kernel Address Space Layout Randomization (KASLR),
which shifts kernel code by a random oﬀset, making it harder
for an attacker to hard-code a jump to kernel code in her
exploits. Hund et al. showed that probing the LLC can help
defeat this randomization countermeasure [10].
We demonstrated that LLC probing can also be carried
out in JavaScript, implying that the attack of Hund et al.
can also be carried out by an untrusted webpage. Such at-
tacks are specially suited to our attacker model, because
of drive-by exploits that attempt to proﬁle and then infect
users with a particular strain of malware, tailored to be ef-
fective for their speciﬁc software conﬁguration [22]. The
derandomization method we present can be used for boot-
strapping a drive-by exploit, dividing the attack into two
phases. In the ﬁrst phase, an unprivileged JavaScript func-
tion proﬁles the system and discovers the address of a kernel
data structure. Next, the JavaScript code connects to the
web server again and downloads a tailored exploit for the
running kernel.
Note that cache sets are not immediately mappable to
virtual addresses, especially in the case of JavaScript where
pointers are not available. An additional building block used
by Hund et al., which is not available to us, is the call to
sysenter with an unused syscall number. This call resulted
in a very quick and reliable trip into the kernel, allowing
eﬃcient measurements [10].
Secret State Recovery. Cache-based key recovery has
been widely discussed in the scientiﬁc community and needs
no justiﬁcation. In the case of cache attacks in the browser,
the adversary may be interested in discovering the user’s
TLS session key, any VPN or IPSec keys used by the sys-
tem, or perhaps the secret key used by the system’s disk
encryption software. There are additional secret state ele-
ments that are even more relevant than cryptographic keys
in the context of network attacks. One secret which is of
particular interest in this context is the sequence number
in an open TCP session. Discovering this value will enable
traﬃc injection and session hijacking attacks.
6.5 Countermeasures
The attacks described in this paper are possible because
of a conﬂuence of design and implementation decisions start-
ing at the micro-architectural level and ending at the Java-
Script runtime: the method of mapping a physical memory
address to cache set; the inclusive cache micro-architecture;
JavaScript’s high-speed memory access and high-resolution
timer; and ﬁnally, JavaScript’s permission model. Mitiga-
tion steps can be applied at each of these junctions, but each
will impose a drawback on the benign uses of the system.
On the micro-architectural level, changes to the way physi-
cal memory addresses are mapped to cache lines will severely
confound our attack, which makes great use of the fact that
6 out of the lower 12 bits of an address are used directly to
select a cache set. Similarly, the move to an exclusive cache
micro-architecture, instead of an inclusive one, will make it
impossible for our code to trivially evict entries from the
L1 cache, resulting in less accurate measurements. These
two design decisions, however, were chosen deliberately to
make the CPU more eﬃcient in its design and use of cache
memory, and changing them will exact a performance cost
on many other applications. In addition, modifying a CPU’s
micro-architecture is far from trivial, and deﬁnitely impos-
sible as an upgrade to already deployed hardware.
On the JavaScript level, it seems that reducing the resolu-
tion of the high-resolution timer will make our attack more
diﬃcult to launch. However, the hi-res timer was created
to address a real need of JavaScript developers for applica-
tions ranging from music and games to augmented reality. A
possible stopgap measure would be to restrict access to this
timer to applications that gain the user’s consent (e.g., by
displaying a conﬁrmation window) or the approval of some
third party (e.g., downloaded from a trusted “app store”).
An interesting approach could be the use of heuristic pro-
ﬁling to detect and prevent this speciﬁc kind of attack. Just
like the abundance of arithmetic and bitwise instructions
used by Wang et al.
to indicate the existence of crypto-
graphic primitives [28], it can be noted that the various
(measurement) steps of our attack access memory in a very
particular pattern. Since modern JavaScript runtimes al-
ready scrutinize the runtime performance of code as part
of their proﬁle-guided optimization mechanisms, it could be
possible for the JavaScript runtime to detect proﬁling-like
behavior from executing code, and modify its response ac-
cordingly (e.g., by jittering the high-resolution timer or dy-
namically moving arrays around in memory).
14177. CONCLUSION
We demonstrated how a micro-architectural, side-channel
cache attack, which is already recognised as an extremely
potent attack method, can be eﬀectively launched from an
untrusted webpage. Instead of the traditional cryptanalytic
applications of the cache attack, we instead showed how user
behaviour can be successfully tracked using our method(s).
The potential reach of side-channel attacks has been ex-
tended, meaning that additional classes of systems must be
designed with side-channel countermeasures in mind.
Acknowledgments
We are grateful to Yinqian Zhang, our shepherd, and the
anonymous reviewers for their valuable comments. We also
thank Kiril Tsemekhman and Jason Shaw for providing in-
teresting directions regarding this research. This work was
supported by the Oﬃce of Naval Research (ONR) through
Contract N00014-12-1-0166. Any opinions, ﬁndings, con-
clusions, or recommendations expressed herein are those of
the authors, and do not necessarily reﬂect those of the US
Government or ONR.
8. REFERENCES
[1] O. Acii¸cmez. Yet Another MicroArchitectural Attack:
Exploiting I-Cache. In Proc. of ACM CSAW, pages
11–18, 2007.
[2] G. I. Apecechea, M. S. Inci, T. Eisenbarth, and
B. Sunar. Wait a Minute! A fast, Cross-VM Attack on
AES. In Proc. of RAID, pages 299–319, 2014.
[3] D. J. Bernstein. Cache-timing attacks on AES.
http://cr.yp.to/papers.html#cachetiming,
April 2005. [Online; accessed August-2015].
[5] Ecma International. Standard ECMA-262:
[4] D. Brumley and D. Boneh. Remote Timing Attacks
are Practical. In Proc. of USENIX Sec., pages 1–14,
2005.
ECMAScript R(cid:13)Language Speciﬁcation.
http://www.ecma-international.org/
ecma-262/5.1/index.html, June 2011. [Online;
accessed August-2015].
[6] T. Eisenbarth, T. Kasper, A. Moradi, C. Paar,
M. Salmasizadeh, and M. T. M. Shalmani. On the
Power of Power Analysis in the Real World: A
Complete Break of the KEELOQ Code Hopping
Scheme. In Proc. of CRYPTO, pages 203–220, 2008.
[7] D. Herman and K. Russell. Typed Array Speciﬁcation.
https://www.khronos.org/registry/
typedarray/specs/latest/, July 2013. [Online;
accessed August-2015].
[8] G. Ho, D. Boneh, L. Ballard, and N. Provos. Tick
Tock: Building Browser Red Pills from Timing Side
Channels. In Proc. of WOOT, 2014.
[9] W. Hu. Lattice Scheduling and Covert Channels. In
Proc. of IEEE S&P, pages 52–61, 1992.
[10] R. Hund, C. Willems, and T. Holz. Practical Timing
Side Channel Attacks Against Kernel Space ASLR. In
Proc. of IEEE S&P, pages 191–205, 2013.
[11] S. Jana and V. Shmatikov. Memento: Learning
Secrets from Process Footprints. In Proc. of IEEE
S&P, pages 143–157, 2012.
[12] V. P. Kemerlis, M. Polychronakis, and A. D.
Keromytis. ret2dir: Rethinking Kernel Isolation. In
Proc. of USENIX Sec, pages 957–972, 2014.
[13] P. C. Kocher. Timing Attacks on Implementations of
Diﬃe-Hellman, RSA, DSS, and Other Systems. In
Proc. of CRYPTO, pages 104–113, 1996.
[14] F. Liu, Y. Yarom, Q. Ge, G. Heiser, and R. B. Lee.
Last-Level Cache Side-Channel Attacks are Practical.
In Proc. of IEEE S&P, pages 605–622, 2015.
[15] S. Mangard, E. Oswald, and T. Popp. Power Analysis
Attacks: Revealing the Secrets of Smart Cards.
Springer, 2007.
[16] J. Mann. High Resolution Time.
http://www.w3.org/TR/hr-time/, December
2012. [Online; accessed August-2015].
[17] C. Maurice, C. Neumann, O. Heen, and A. Francillon.
C5: Cross-Cores Cache Covert Channel. In Proc. of
DIMVA, pages 46–64, 2015.
[18] Y. Oren, M. Kirschbaum, T. Popp, and A. Wool.
Algebraic side-channel analysis in the presence of
errors. In Proc. of CHES, pages 428–442, 2010.
[19] D. A. Osvik, A. Shamir, and E. Tromer. Cache
Attacks and Countermeasures: The Case of AES. In
Proc. of CT-RSA, pages 1–20, 2006.
[20] D. Oswald and C. Paar. Breaking Mifare DESFire
MF3ICD40: Power Analysis and Templates in the
Real World. In Proc. of CHES, pages 207–222, 2011.
[21] C. Percival. Cache Missing for Fun and Proﬁt. In
Proc. of BSDCan, 2005.
[22] N. Provos, P. Mavrommatis, M. A. Rajab, and
F. Monrose. All Your iFRAMEs Point to Us. In Proc.
of USENIX Sec., pages 1–15, 2008.
[23] M. K. Qureshi, A. Jaleel, Y. N. Patt, S. C. S. Jr., and
J. Emer. Adaptive Insertion Policies for High
Performance Caching. In Proc. of ISCA, pages
381–391, 2007.
[24] T. Ristenpart, E. Tromer, H. Shacham, and S. Savage.
Hey, You, Get Oﬀ of My Cloud: Exploring
Information Leakage in Third-Party Compute Clouds.
In Proc. of CCS, pages 199–212, 2009.
[25] K. A. Shutemov. pagemap: do not leak physical
addresses to non-privileged userspace.
https://lwn.net/Articles/642074/, March
2015. [Online; accessed August-2015].
[26] StatCounter. GlobalStats.
http://gs.statcounter.com, January 2015.
[Online; accessed August-2015].
[27] W3C. Javascript APIs Current Status.
http://www.w3.org/standards/techs/js.
[Online; accessed August-2015].
[28] Z. Wang, X. Jiang, W. Cui, X. Wang, and M. Grace.
ReFormat: Automatic Reverse Engineering of
Encrypted Messages. In Proc. of ESORICS, pages
200–215, 2009.
[29] Y. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart.
Cross-VM Side Channels and Their Use to Extract
Private Keys. In Proc. of CCS, pages 305–316, 2012.
[30] Y. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart.
Cross-Tenant Side-Channel Attacks in PaaS Clouds.
In Proc. of ACM CCS, pages 990–1003, 2014.
1418