### 5. Performance Evaluation

#### 5.1 Latency and Throughput
When Y! was enabled, the average latency increased by 29%, from 48.38 ms to 62.63 ms, and the throughput decreased by 14%, from 56.0 to 48.4 requests per second. However, these results are difficult to generalize because RapidNet’s performance as an SDN controller is not competitive with state-of-the-art controllers, even without Y!. To address this, we repeated the experiment using our Y! extension for native Trema (Section 7.1). In this case, adding Y! increased the average latency by only 1.6% to 33 microseconds and decreased the average throughput by 8.9% to 100,540 PacketIn messages per second.

We note that this comparison is slightly unfair because we manually instrumented a specific Trema program to work with our extension, whereas the RapidNet prototype can work with any program. However, adding instrumentation to Trema programs is not difficult and could be automated. Our results suggest that capturing provenance is not inherently expensive, and an optimized RapidNet could potentially perform much better.

#### 5.2 Query Processing Speed
When a user issues a provenance query, Y! must recursively construct the response using the process described in Section 3.5 and then post-process it using the heuristics from Section 4. Since debugging is an interactive process, a quick response is crucial. To evaluate whether Y! meets this requirement, we measured the turnaround time for the queries listed in Table 2, as well as the fraction of time consumed by Y!’s major components.

Figure 12 shows our results. We make two high-level observations:
1. The turnaround time is dominated by R-tree and packet recorder lookups. This is expected because the graph construction algorithm itself is not very complex.
2. Although the queries vary in complexity, none of them took more than one second to complete. The most expensive query, Q9, took 0.33 seconds.

#### 5.3 Scalability
We have not yet deployed Y! or negative provenance in a large-scale environment. However, we have conducted several experiments to gain an initial impression of its scalability. Due to space constraints, we report only a subset of our results here.

**Complexity:**
In our first experiment, we tested whether the complexity of the provenance increases with the number of possible traffic sources. We simulated a four-layer fat-tree topology with 15 switches, placing the client and server on different leaves to vary the hop distance between them from 2 to 6. Our results for running the learning-switch query (Q1) are shown in Figure 13a. As expected, the size of the raw provenance for Q1 grew substantially, from 250 to 386 vertices, due to:
1. An increase in the number of possible sources for the missing traffic, as each additional hop brings additional branches on the backtrace path.
2. Additional hops requiring extra vertices to be represented in the provenance.

However, the first effect was mitigated by our pruning heuristics, which eliminated inconsistent sources with the network state, and the second effect was addressed by summarization, which merged vertices along the propagation path into a single super-vertex. After applying all heuristics, the size of the provenance was 16 vertices, independent of the hop count.

**Storage:**
In our second experiment, we simulated three-layer fat-tree topologies of different sizes (i.e., with different node degrees). Each edge switch was connected to a fixed number of active hosts constantly sending HTTP requests to the server. Figure 13b shows how Y!’s storage requirements grew with the number of switches in the network. As expected, the size of both the pcap trace and the R-tree was roughly proportional to the size of the network. This is because:
1. Each new switch added a fixed number of hosts.
2. The depth of the tree, and thus the hop count between the server and its clients, remained constant.

Generally, the storage requirement depends on the rate at which events of interest (packet transmissions, routing changes, etc.) are captured, as well as the retention period for these records.

**Query Speed:**
Our third experiment is analogous to the second, except that we issued a query at the end and measured its turnaround time. Figure 13c shows our results. The dominant cost was the time it took to find packets in the pcap trace; R-tree lookups were much faster, and the time needed to construct and post-process the graph was negligible. Overall, the lookup time was below one second even for the largest network we tried.

**Possible Optimizations:**
Since our implementation has not been optimized, some costs could grow quickly in a large-scale deployment. For instance, in a data center with 400 switches handling 1 Gbps of traffic each, our simple approach of recording pcap traces at each switch would consume approximately 30 GB of storage per second for the data center, or about 75 MB for each switch. Packet recorder lookups, which account for a major portion of query latency, in such a large trace would be limited by disk read throughput and could take minutes. However, there are several ways to reduce these costs. For example, techniques from the database literature, such as a simple time index, could speed up lookups, and storage costs could be reduced by applying filters.

### 5.4 Summary
Our results show that Y! and, more generally, negative provenance can be useful tools for diagnosing problems in networks. The provenance of the issues we examined was compact and readable, and Y! was able to find it in less than a second in each case. The readability is significantly enhanced by Y!’s post-processing heuristics, which reduced the number of vertices by more than an order of magnitude. Y!’s main runtime cost is the storage needed to maintain a history of the system’s past states, but a commodity hard drive should be sufficient to keep this history for more than a day.

### 6. Related Work
**Network Debugging:**
Many tools and techniques for network debugging and root cause analysis have been proposed, such as [5, 9, 18, 26]. However, most focus on explaining positive events. These tools can indirectly troubleshoot negative symptoms, but the lack of direct support for negative queries makes this significantly more difficult. Hubble [12] uses probing to find AS-level reachability problems but is protocol-specific. Header space analysis [13] provides finer-grain results but relies on static analysis and cannot explain complex, dynamic interactions like those we consider. ATPG [34] tests for liveness, reachability, and performance but cannot handle dynamic nodes like the SDN controller. NICE [2] uses model checking to test whether a given SDN program has specific correctness properties, which is complementary to our approach, which focuses on diagnosing unforeseen problems at runtime. We are not aware of any protocol-independent systems that can explain negative events in a dynamic distributed system.

**Negative Provenance:**
There is substantial literature on tracking provenance in databases [1, 6, 11, 25, 31] and networks [35, 37], but only a few papers have considered negative provenance. Huang et al. [10] and Meliou et al. [19] focus on instance-based explanations for missing answers, while Why-Not [3] and ConQueR [28] provide query-based explanations for SQL queries, revealing over-constrained conditions and suggesting modifications. None of these papers considers distributed environments and networks. In the networking literature, there is some prior work on positive provenance, including ExSPAN [37], SNP [35], and DTaP [36], but none of these systems can answer (or even formulate) negative queries. To our knowledge, the only existing work that supports such queries is our own workshop paper [32], on which this paper is based.

### 7. Conclusion
In this paper, we argue that debuggers for distributed systems should not only explain why an unexpected event occurred but also why an expected event did not occur. We have shown how this can be accomplished with the concept of negative provenance, which has received relatively little attention. We have defined a formal model of negative provenance, presented an algorithm for generating such provenance, and introduced Y!, a practical system that can maintain both positive and negative provenance in a distributed system and answer queries about it. Our evaluation in the context of software-defined networks and BGP suggests that negative provenance can be a useful tool for diagnosing complex problems in distributed systems.

### Acknowledgments
We thank our shepherd Nate Foster and the anonymous reviewers for their comments and suggestions. We also thank Behnaz Arzani for helpful comments on earlier drafts of this paper. This work was supported by NSF grants CNS-1065130, CNS-1054229, CNS-1040672, and CNS-0845552, as well as DARPA contract FA8650-11-C-7189.

### References
[1] P. Buneman, S. Khanna, and W. C. Tan. Why and where: A characterization of data provenance. In Proc. ICDT, Jan. 2001.
[2] M. Canini, D. Venzano, P. Perešíni, D. Kosti´c, and J. Rexford. A NICE way to test OpenFlow applications. In Proc. NSDI, Apr. 2012.
[3] A. Chapman and H. V. Jagadish. Why not? In Proc. SIGMOD, June 2009.
[4] D. Erickson. The Beacon OpenFlow controller. In Proc. HotSDN, Aug. 2013.
[5] A. Feldmann, O. Maennel, Z. M. Mao, A. Berger, and B. Maggs. Locating Internet routing instabilities. In Proc. SIGCOMM, Aug. 2004.
[6] T. J. Green, G. Karvounarakis, N. E. Taylor, O. Biton, Z. G. Ives, and V. Tannen. ORCHESTRA: Facilitating collaborative data sharing. In Proc. SIGMOD, June 2007.
[7] A. Guttman. R-trees: A dynamic index structure for spatial searching. In Proc. SIGMOD, June 1984.
[8] N. Handigol, B. Heller, V. Jeyakumar, D. Mazières, and N. McKeown. Where is the debugger for my software-defined network? In Proc. HotSDN, Aug. 2012.
[9] N. Handigol, B. Heller, V. Jeyakumar, D. Mazières, and N. McKeown. I know what your packet did last hop: Using packet histories to troubleshoot networks. In Proc. NSDI, Apr. 2014.
[10] J. Huang, T. Chen, A. Doan, and J. F. Naughton. On the provenance of non-answers to queries over extracted data. Proc. VLDB Endow., 1(1):736–747, Aug. 2008.
[11] R. Ikeda, H. Park, and J. Widom. Provenance for generalized map and reduce workflows. In Proc. CIDR, Jan. 2011.
[12] E. Katz-Bassett, H. V. Madhyastha, J. P. John, A. Krishnamurthy, D. Wetherall, and T. Anderson. Studying black holes in the Internet with Hubble. In Proc. NSDI, Apr. 2008.
[13] P. Kazemian, G. Varghese, and N. McKeown. Header space analysis: static checking for networks. In Proc. NSDI, Apr. 2012.
[14] libspatialindex. http://libspatialindex.github.io/.
[15] D. Logothetis, S. De, and K. Yocum. Scalable lineage capture for debugging DISC analysis. Technical Report CSE2012-0990, UCSD.
[16] B. T. Loo, T. Condie, M. Garofalakis, D. E. Gay, J. M. Hellerstein, P. Maniatis, R. Ramakrishnan, T. Roscoe, and I. Stoica. Declarative networking. Commun. ACM, 52(11):87–95, Nov. 2009.
[17] P. Macko and M. Seltzer. Provenance Map Orbiter: Interactive exploration of large provenance graphs. In Proc. TaPP, June 2011.
[18] H. Mai, A. Khurshid, R. Agarwal, M. Caesar, P. B. Godfrey, and S. T. King. Debugging the data plane with Anteater. In Proc. SIGCOMM, Aug. 2011.
[19] A. Meliou and D. Suciu. Tiresias: the database oracle for how-to queries. In Proc. SIGMOD, May 2012.
[20] Mininet. http://mininet.org/.
[21] C. Monsanto, J. Reich, N. Foster, J. Rexford, and D. Walker. Composing software-defined networks. In Proc. NSDI, Apr. 2013.
[22] K.-K. Muniswamy-Reddy, D. A. Holland, U. Braun, and M. Seltzer. Provenance-aware storage systems. In Proc. USENIX ATC, May 2006.
[23] Outages mailing list. http://wiki.outages.org/index.php/Main_Page#Outages_Mailing_Lists.
[24] RapidNet. http://netdb.cis.upenn.edu/rapidnet/.
[25] C. Ré, N. Dalvi, and D. Suciu. Efficient top-k query evaluation on probabilistic data. In Proc. ICDE, Apr. 2007.
[26] A. Singh, P. Maniatis, T. Roscoe, and P. Druschel. Using queries for distributed monitoring and forensics. In Proc. EuroSys, Apr. 2006.
[27] R. Teixeira and J. Rexford. A measurement framework for pin-pointing routing changes. In Proc. Network Troubleshooting workshop (NetTS), Sept. 2004.
[28] Q. T. Tran and C.-Y. Chan. How to ConQueR why-not questions. In Proc. SIGMOD, June 2010.
[29] Trema. http://trema.github.io/trema/.
[30] A. Wang, L. Jia, W. Zhou, Y. Ren, B. T. Loo, J. Rexford, V. Nigam, A. Scedrov, and C. L. Talcott. FSR: Formal analysis and implementation toolkit for safe inter-domain routing. IEEE/ACM ToN, 20(6):1814–1827, Dec. 2012.
[31] J. Widom. Trio: A system for integrated management of data, accuracy, and lineage. In Proc. CIDR, Jan. 2005.
[32] Y. Wu, A. Haeberlen, W. Zhou, and B. T. Loo. Answering Why-Not queries in software-defined networks with negative provenance. In Proc. HotNets, 2013.
[33] Y. Wu, M. Zhao, A. Haeberlen, W. Zhou, and B. T. Loo. Diagnosing missing events in distributed systems with negative provenance. Technical Report MS-CIS-14-06, University of Pennsylvania, 2014.
[34] H. Zeng, P. Kazemian, G. Varghese, and N. McKeown. Automatic test packet generation. In Proc. CoNEXT, Dec. 2012.
[35] W. Zhou, Q. Fei, A. Narayan, A. Haeberlen, B. T. Loo, and M. Sherr. Secure network provenance. In Proc. SOSP, Oct. 2011.
[36] W. Zhou, S. Mapara, Y. Ren, Y. Li, A. Haeberlen, Z. Ives, B. T. Loo, and M. Sherr. Distributed time-aware provenance. In Proc. VLDB, Aug. 2013.
[37] W. Zhou, M. Sherr, T. Tao, X. Li, B. T. Loo, and Y. Mao. Efficient querying and maintenance of network provenance at Internet-scale. In Proc. SIGMOD, 2010.