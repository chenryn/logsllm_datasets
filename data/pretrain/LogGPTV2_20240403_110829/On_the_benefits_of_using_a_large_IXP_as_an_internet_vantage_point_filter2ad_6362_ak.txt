●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●● ●
●
●
● ●
●
●● ●
●
●
●
100
20
80
Perc. of Akamai traffic on Akamai link
40
60
(b) Perc. of Akamai trafﬁc vs. perc. of Akamai trafﬁc via
direct link
l
)
e
a
c
s
−
g
o
l
(
c
i
f
f
10−1
a
r
t
r
e
v
r
e
s
i
a
m
a
k
A
10−4
10−7
f
o
.
c
r
e
P
l
)
e
a
c
s
−
g
o
l
(
c
i
f
f
a
r
t
r
e
v
r
e
s
e
r
a
l
f
d
u
o
C
l
f
o
.
c
r
e
P
10−1
10−4
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●●
●
●
●
●
●
●●
●
●
●●
●
0
●
●
●
●
●
●●
●
●
●
●●●
●
●
●
●
●●●
●●●
●●
●
●
●●
●●
●●●
●
●
●●●●●
0
● Member
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●●●●●●
●
●
●
●●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●●●●●●●●●●●●●●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●●●
●
●
●
●●●
●
●
●
●
●
●
●
●
●
●
●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
●
●
●
●●
●●
●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
20
40
60
80
Perc. of Cloudflare traffic on Cloudflare link
●●●
●●●●●
●
●
●●●●●●●●●●●
100
(c) Perc. of CloudFlare trafﬁc vs. perc. of CloudFlare trafﬁc
via direct link
Figure 7: AS link heterogeneity: Trafﬁc via direct member link
relative to other member links.
mai (AS20940) is a member of the IXP and peers with some 400
other member ASes. In the traditional view, accounting for Aka-
mai trafﬁc traversing the IXP simply means capturing the trafﬁc
on all the peering links between Akamai and those member ASes.
Unfortunately, this simple view is no longer reﬂecting reality when
Akamai servers are hosted inside or “behind” (non-Akamai) IXP
member ASes. To capture this aspect, Figure 7(b) shows for each
IXP member that peers with Akamai (indicated by a dot) the per-
centage of Akamai trafﬁc on the direct peering link to Akamai
(x-axis) vs. the percentage of total Akamai-server trafﬁc for this
member AS (y-axis). Under the traditional assumption, all dots
would be stacked up at x=100, reﬂecting the fact that to account for
Akamai-related trafﬁc, all that is needed is to measure the Akamai
peering links. However, with Akamai servers being massively de-
ployed in third-party networks, including many of the other mem-
ber ASes of the IXP, we observe that some members get all their
Akamai-related trafﬁc from ASes other than the (member) Akamai
AS (x=0), even when that trafﬁc is sizable (y>>0). Moreover, the
scattering of dots across Figure 7(b) succinctly captures the diverse
spread of trafﬁc across the direct peering link vs. the other member
links. In terms of numbers, Akamai sends 11.1% of its trafﬁc not
via its peering links with the member AS. Put differently, trafﬁc
from more than 15K out of the 28K Akamai servers that we iden-
tiﬁed in our IXP data is seen at the IXP via non-IXP member links
to Akamai. The same holds true for other major CDNs but also for
relatively new players such as CloudFlare. Figure 7(c) shows the
same kind of plot as Figure 7(b) for CloudFlare. It demonstrates
that despite adhering to very different business models (i. e., Aka-
mai deploys servers inside ISPs vs. CloudFlare operates its own
data centers), the two CDNs have similar usage patters as far as
their peering links are concerned.
Looking beyond Akamai, we observe that different services from
the same organization use their servers differently resulting in dif-
ferent usage patterns of the peering links. For example, for Amazon
CloudFront, Amazon’s “CDN part”, almost all trafﬁc is send via
the IXP’s Amazon links. However, for Amazon EC2, the “cloud
part”, a sizable fraction comes via other IXP peering links. We also
noticed that for most cases where we see the use of the non-IXP
member links, the percentage of trafﬁc in those links increases dur-
ing peak times. This may be due to reasons such as load balancing,
performance improvement, or cost savings. Lastly, how our view
of the usage of the IXP’s public peering links is impacted by pri-
vate peerings that may be in place between member ASes of the
IXP remains unexplored.
Summary: To illustrate the kind of beneﬁts that arise from having
access to a global Internet vantage point in the form or our large
European IXP, we conﬁrm a feature of today’s Internet that is well-
known among experts but remains largely under-reported in the net-
working research literature—a tendency of certain Internet players
to either host servers from third-party networks within their own
network infrastructures or deploy their own servers in strategically-
chosen third-party ASes. More importantly, we present a method-
ology for discovering an organization’s servers, whether they are
deployed within the organization’s own AS (or ASes) or inside
some third-party network’s infrastructure, and use it to systemat-
ically assess the extent of this network heterogenization and study
its impact on the usage of peering links at IXPs by these increas-
ingly more heterogeneous member ASes. However, we want to
stress that our AS-links usage-related ﬁndings are not IXP-speciﬁc
(i. e., public peering links), but apply to any AS-link in the Inter-
net, pointing towards serious challenges when trying to attribute
the right trafﬁc to the right party.
6. DISCUSSION AND CAVEATS
We are not the ﬁrst to try and uncover the footprints of the in-
frastructures of commercial Internet players. One group of prior
studies targets speciﬁc Internet companies (e. g., Akamai [54, 39,
52], Youtube [11, 37, 26], Netﬂix [10]), or one click hosters [19]).
Other work is more concerned with inferring Web hosting infras-
tructures by relying on content only [14]. Our approach differs
from these earlier works. For one, we rely on a unique vantage
point in the form of one of the largest European IXPs to supply us
with a weekly pool of some 230M IPs from which we diligently ex-
tract some 1.5M server IPs. Next, we rely exclusively on publicly
available data4 to group these servers by organizations that have
4Note that our use of the set of DNS resolvers from a large com-
mercial CDN in Section 2.3 is a shortcut. A similar list could also
344the administrative authority over them and are responsible for their
content. In doing so, we are inspired by earlier studies such as [20,
48]. Lastly, the methodology we develop for grouping servers by
their organization is general in the sense that it applies equally well
to content providers, CDNs, hosting companies, cloud infrastruc-
ture providers, eyeball ASes, or other Internet players.
The difference in perspective between the more traditional AS-
level view of the Internet and our perspective that centers around
organizations and companies and their heterogeneously deployed
server-based infrastructure becomes evident when comparing our
approach to the recent work by Cai et al. [24] on mapping ASes
to organizations. For one, the starting point for [24] is the tradi-
tional AS-level view of the Internet, and two ASes are grouped into
two different organizations if neither of the organizations is a sub-
sidiary of the other (i. e., majority-owned by the other). While such
a top-down ownership-based grouping of ASes captures one aspect
of how ASes are inter-related, it is oblivious to how network infras-
tructures get used and deployed in today’s Internet. In particular,
while the method described in [24] may succeed in clustering all
Akamai-owned ASes under the umbrella organization Akamai, the
publicly known fact that Akamai has more than 100K servers de-
ployed in hundreds of different third-party non-Akamai ASes [46]
cannot be accounted for at all by that approach.
Our work relies critically on the sFlow records provided by one
of the largest IXPs in Europe, and it can be argued that for many
researchers, access to such data cannot be taken for granted. How-
ever, it is important to note that some of these largest IXPs in Eu-
rope generally welcome collaborations with researchers and are
supportive of research efforts that make explicit use of their data
(see for instance [18]). Once access to data collected from such
unique and powerful vantage points is established, the opportuni-
ties for researchers are plentiful.
After presenting evidence for the kind of visibility into the In-
ternet that comes with using one of these largest European IXPs
as a vantage point, we highlight in this paper some of the beneﬁts
that arises from having access to such a vantage point. However,
despite its impressive capabilities, our IXP and the measurements
it collects can only tell us so much about the network’s “state”,
and many important issues remain concerning our knowledge about
what exactly we can and cannot discern about the Internet as whole
and its individual constituents. While we have identiﬁed a number
of “blind spots”, much remains to be done in terms of identifying
and collecting IXP-external information that can be brought to the
table for either checking, validating, or reﬁning the ﬁndings ob-
tained from the use of IXP-internal data only. The question of how
to appropriately fuse selective IXP-external data with IXP-internal
measurements to obtain a picture of the global network and its in-
dividual constituents that is unprecedented in terms of its accuracy,
details, and insight looms as an important open research problem.
7. CONCLUSION
This paper contributes to Internet measurements by reporting on
the existence of single, well-localized physical locations or vantage
points within the Internet infrastructure where one can “see” much
of the global Internet. Mining the data collected at one such vantage
point reveals a network that teems with heterogeneity whichever
way one looks. Given that economic incentives drive many of the
main commercial Internet players to either host third-party servers
in their own network infrastructures or deploy their own servers,
often in massive numbers, in strategically selected (close to the
end users) third-party networks, we expect the observed trend to-
wards increasingly more heterogeneous networks and increasingly
diverse usage of IXP peering links, in particular, and AS-links, in
general, to accelerate, especially in view of the growing importance
of cloud providers. As an interesting consequence of more servers
being deployed close to the end users, we also expect that IXPs in
the future will “see” less end user-to-server trafﬁc but an increasing
amount of server-to-server trafﬁc.
In response to this observed heterogeneity, the paper also con-
tributes to Internet topology research by advancing a new mental
model for the Internet’s ecosystem that accounts for the observed
network heterogenization, points towards measurements that reveal
and keep track of this ongoing heterogenization process, and is rich
and ﬂexible enough to adapt to a constantly changing Internet envi-
ronment. Doing so only scratches the surface of a new and rich
problem space, and our efforts reported in this paper that focus
less on the Internet’s connectivity structure and more on how traf-
ﬁc ﬂows over this connectivity structure are just a ﬁrst step towards
exploring that space.
8. REFERENCES
[1] Akamai and AT&T Forge Global Strategic Alliance to
Provide Content Delivery Network Solutions.
http://www.akamai.com/html/about/press/
releases/2012/press_120612.html.
[2] Amazon CloudFront - Amazon Web Services.
http://aws.amazon.com/cloudfront/.
[3] CIDR Report. http://www.cidr-report.org/.
[4] Like Netﬂix, Facebook is boosting its edge network.
http://gigaom.com/2012/06/21/
like-netflix-facebook-is-planning-its-own-cdn/.
[5] Netﬂix Open Connect.
https://signup.netflix.com/openconnect.
[6] Orange and Akamai form Content Delivery Strategic
Alliance. http://www.akamai.com/html/about/
press/releases/2012/press_112012_1.html.
[7] RIPE RIS. http://www.ripe.net/ris/.
[8] Route Views Project, University of Oregon.
http://www.routeviews.org/.
[9] Team Cymru. http://www.team-cymru.org/.
[10] V. Adhikari, Y. Guo, F. Hao, M. Varvello, V. Hilt, M. Steiner,
and Z.-L. Zhang. Unreeling Netﬂix: Understanding and
Improving multi-CDN Movie Delivery. In IEEE INFOCOM,
2012.
[11] V. K. Adhikari, S. Jain, Y. Chen, and Z.-L. Zhang.
Vivisecting YouTube: An Active Measurement Study. In
IEEE INFOCOM, 2012.
[12] P. Aditya, M. Zhao, Y. Lin, A. Haeberlen, P. Druschel,
B. Maggs, and B. Wishon. Reliable Client Accounting for
Hybrid Content-Distribution Networks. In NSDI, 2012.
[13] B. Ager, N. Chatzis, A. Feldmann, N. Sarrar, S. Uhlig, and
W. Willinger. Anatomy of a Large European IXP. In ACM
SIGCOMM, 2012.
[14] B. Ager, W. Mühlbauer, G. Smaragdakis, and S. Uhlig. Web
Content Cartography. In ACM IMC, 2011.
[15] Akamai. Facts and Figures: Network Deployment.
http://www.akamai.com/html/about/facts_
figures.html.
[16] Amazon. AWS Dashboard.
http://status.aws.amazon.com/.
have been obtained by relying on publicly available data only [52,
54, 39], e. g., via active scanning or from DNS logs.
[17] Amazon. EC2 Public IP ranges. https://forums.aws.
amazon.com/ann.jspa?annID=1701.
345[18] AMS-IX. AMS-IX hosts BGP-Mux research project.
https://www.ams-ix.net/newsitems/82.
[19] D. Antoniades, E. Markatos, and C. Dovrolis. One-click
Hosting Services: A File-Sharing Hideout. In ACM IMC,
2009.
[20] I. Bermudez, M. Mellia, M. Munafà, R. Keralapura, and
A. Nucci. DNS to the Rescue: Discerning Content and
Services in a Tangled Web. In ACM IMC, 2012.
[21] Facebook blog. A Continued Commitment to Security.
http://www.facebook.com/blog/blog.php?
post=486790652130.
[22] Google Search Blog. Making Search More Secure.
http://googleblog.blogspot.com/2011/10/
making-search-more-secure.html.
[23] Netﬂix Nordics blog. Netﬂix Launches Today in Sweden,
Denmark, Norway, Finland.
http://nordicsblog.netflix.com/2012/10/.
[24] X. Cai, J. Heidemann, B. Krishnamurthy, and W. Willinger.
Towards an AS-to-Organization Map. In ACM IMC, 2010.
[25] M. Calder, X. Fan, Z. Hu, E. Katz-Bassett, J. Heidemann,
and R. Govindan. Mapping the Expansion of Google’s
Serving Infrastructure. In ACM IMC, 2013.
[26] M. Cha, H. Kwak, P. Rodriguez, Y. Y. Ahn, and S. Moon. I
Tube, You Tube, Everybody Tubes: Analyzing the World’s
Largest User Generated Content Video System. In ACM
IMC, 2008.
[27] H. Chang, S. Jamin, Z. M. Mao, and W. Willinger. An
Empirical Approach to Modeling Inter-AS Trafﬁc Matrices.
In ACM IMC, 2005.
[28] N. Chatzis, G. Smaragdakis, and A. Feldmann. On the
Importance of Internet eXchange Points for Today’s Internet
Ecosystem. http://arxiv-web3.library.
cornell.edu/abs/1307.5264v2.
[29] K. Cho, C. Pelsser, R. Bush, and Y. Won. The Japan
Earthquake: the Impact on Trafﬁc and Routing Observed by
a Local ISP. In In ACM SWID, 2011.
[30] Cisco. Visual Networking Index (VNI) and Forecast.
http://www.cisco.com/en/US/netsol/ns827/
networking_solutions_sub_solution.html.
[31] Private communication.
[32] D. Dainotti, C. Squarcella, E. Aben, K.C. Claffy, M. Chiesa,
M. Russo, and A. Pescapé. Analysis of Country-Wide
Internet Outages Caused by Censorship. In ACM IMC, 2011.
[33] J. Erman, A. Gerber, M. Hajiaghayi, D. Pei, and
O. Spatscheck. Network-aware Forward Caching. In WWW,
2009.
[34] T. Flach, N. Dukkipati, A. Terzis, B. Raghavan, N. Cardwell,
Y. Cheng, A. Jain, S. Hao, E. Katz-Bassett, and R. Govindan.
Reducing Web Latency: the Virtue of Gentle Aggression. In
ACM SIGCOMM, 2013.
[35] Mozilla Foundation. Publicsufﬁx.org.
http://publicsuffix.org/.
[36] A. Gerber and R. Doverspike. Trafﬁc Types and Growth in
Backbone Networks. In OFC/NFOEC, 2011.
[37] P. Gill, M. F. Arlitt, Z. Li, and A. Mahanti. Youtube Trafﬁc
Characterization: A View From the Edge. In ACM IMC,
2007.
[38] Google. What is 1e100.net?
http://support.google.com/bin/answer.py?
hl=en&answer=174717.
[39] C. Huang, A. Wang, J. Li, and K. Ross. Measuring and
Evaluating Large-scale CDNs. In ACM IMC, 2008.
[40] Data Center Knowledge. Who Has the Most Web Servers?
http://www.datacenterknowledge.com/
archives/2009/05/14/
whos-got-the-most-web-servers.
[41] C. Labovitz, S. Iekel-Johnson, D. McPherson, J. Oberheide,
and F. Jahanian. Internet Inter-Domain Trafﬁc. In ACM
SIGCOMM, 2010.
[42] T. Leighton. Improving Performance on the Internet.
Commun. ACM, 52(2):44–51, 2009.
[43] G. Maier, A. Feldmann, V. Paxson, and M. Allman. On
Dominant Characteristics of Residential Broadband Internet
Trafﬁc. In ACM IMC, 2009.
[44] Maxmind. GeoLite Country. http:
//dev.maxmind.com/geoip/legacy/geolite.
[45] Netcraft. January 2013 Web Server Survey. http:
//news.netcraft.com/archives/2013/01/07/
january-2013-web-server-survey-2.html.
[46] E. Nygren, R. K. Sitaraman, and J. Sun. The Akamai
Network: A Platform for High-performance Internet
Applications. SIGOPS Oper. Syst. Rev., 2010.
[47] V. Paxson. Bro: A System for Detecting Network Intruders
in Real-Time. In Usenix Security Symposium, 1998.
[48] D. Plonka and P. Barford. Flexible Trafﬁc and Host Proﬁling
via DNS Rendezvous. In SATIN, 2011.
[49] I. Poese, S. Uhlig, M. A. Kaafar, B. Donnet, and B. Gueye.
IP Geolocation Databases: Unreliable? ACM CCR, 2011.
[50] Sandvine. Global Internet Phenomena Report.
http://www.sandvine.com/news/global_
broadband_trends.asp.
[51] F. Streibelt, J. Böttger, N. Chatzis, G. Smaragdakis, and
A. Feldmann. Exploring EDNS-Client-Subnet Adopters in
your Free Time. In ACM IMC, 2013.
[52] A. Su, D. Choffnes, A. Kuzmanovic, and F. Bustamante.
Drafting Behind Akamai. In ACM SIGCOMM, 2006.
[53] S. Triukose, Z. Al-Qudah, and M. Rabinovich. Content
Delivery Networks: Protection or Threat? In ESORICS,
2009.
[54] S. Triukose, Z. Wen, and M. Rabinovich. Measuring a
Commercial Content Delivery Network. In WWW, 2011.
346