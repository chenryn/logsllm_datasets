converges when the maximum separability is reached. Once
4
the images are automatically downloaded and thresholded,
a manual clean up session by human subjects needs to be
done. This manual cleaning session is necessary because some
images that are automatically downloaded from the web may
not include the object that corresponds to the search word
(e. g., cat), hence, need to be removed from the image set [15].
Subsequently, a selection of suitable Mooney images took
place. While the original Mooney image database contained
330 images [25], for our experiments we considered images
with a mean recognition rate of 5 seconds and longer resulting
in 250 images. We further reduced this set to 120 images to
obtain enough samples per image for an estimated 100 partic-
ipants.
A suitable Mooney image for the purpose of this appli-
cation is an image that is difﬁcult to recognize without a
previous explicit presentation of the original image. At the
same time, if the user has seen the original image then the
user should be able to correctly identify and label the hidden
object. This procedure makes use of implicit memory as the
users ﬁrst learn the association between the original image and
the corresponding Mooney image without an explicit effort. As
in the example of riding a bike, users usually do not remember
the details of the original image but can name the hidden
object in the Mooney image when they have previously seen
the original image. For some images, the object shown in the
Mooney image can be recognizable by a non-primed user as
well, but only after a relatively long time, whereas primed
users will recognize it almost instantly. Therefore, within this
work, we will treat images with a recognition time beyond a
set threshold as “likely not primed”.
B. Description
We use a (large) set of images I and their corresponding
Mooney images.
Enrollment (Priming) Phase
• When a new user is enrolled, the server ﬁrst assigns two
disjoint subsets IP , IN ⊂ I with |IP| = |IN| = k to the
user. IP reﬂects the primed images, IN the non-primed
images.
• The subset IP is then used to prime the user. During this
session, ﬁrst a Mooney image, then the original image and
a label that describes the object in the image is presented
to the user. This procedure creates an association between
the original image, the correct label of the image and the
corresponding Mooney image.
Authentication (Recall) Phase
• At the beginning of the authentication phase, the two sub-
sets IP , IN for this user are retrieved from the database.
The primed and non-primed Mooney images (IP ∪ IN )
are then presented to the user in a pseudo-randomized
order. For each Mooney image presentation, the user is
requested to type in the label of the object that the image
contains, or skip the image if the user is not able to
recognize any object.
• Two metrics are then computed for each image:
(i) The correctness of the label is computed by comparing
the typed label to a list of previously deﬁned labels. This
is achieved by a distance metric that measures how similar
the label provided by the user matched the deﬁned labels.
(ii) The recognition time, i. e., the time between displaying
the image and the ﬁrst keystroke. If the recognition time
is longer than 20 seconds, we treat the image as if the
label were incorrect, i.e., “likely non-primed”. (We chose
20 seconds as threshold as we expect the recognition
for primed images to occur almost instantaneous, but
then allow the user to hesitate a couple of seconds
before starting to type the label. From our experience,
recognition without being primed takes closer towards a
minute to happen.)
• Authentication is based on the hypothesis that the user
labels the primed images more often (and faster) correctly
than those Mooney images that the user was not primed
on. Sometimes primed images will be labeled incorrectly
and vice versa. To tolerate some of these errors, we
compute a score from the correct and incorrect labels
and accept a user if the reached score is above a speciﬁc
threshold. There are several possibilities to perform this
scoring. After the necessary terminology is introduced in
the next section, we will discuss two scoring methods.
C. Terminology
This section introduces some of the notations that are used
throughout this paper. For one speciﬁc image with index i
(which is displayed to the user) there are four possible events
that we need to consider: the image was/was not primed for
the user (i. e., it is in IP or in IN ), and the user provides
a correct or an incorrect label for the image. We denote the
probability that a (randomly chosen) user correctly labels a
primed image with pi, and the probability that a user correctly
labels a non-primed image with ni. We expect pi to be larger
than ni, and we denote the difference with di := pi − ni. A
positive di indicates that priming is working for this image.
For a reasonably well-working priming, images should have
di > 0.5. (Those are called “ideal” in [16], which is slightly
misleading as “ideal” in a strict sense is di = 1.) In Section IV
we will see that 1/3 of the total images have di > 0.5, i. e.,
we can identify a good amount of images that work well for
our authentication scheme.
D. Adversary Model
We consider a strong adversary that has detailed informa-
tion about the image database I, but has no information about
the subsets IP and IN .
1) We assume the adversary knows the correct labels for all
images in I. This is a strong assumption, as a substantial
fraction of images are hard to label for humans if not
primed. The rationale is that a motivated attacker may
spend substantial effort to label the images, automated
image search facilities might reveal the source image, or
algorithmic classiﬁers may be able to label images. (We
are unaware of any algorithm that can identify objects
in Mooney images, but we cannot guarantee that such
algorithm does not exist; thus we assume the attacker
(artiﬁcially) knows all labels.)
2) We assume the adversary knows the probabilities ni and
pi. While knowing the exact values requires substantial
work by the attacker (basically replicating our study),
getting approximations is relatively easy, and one should
not rely on an assumed bound on their correctness.
3) The adversary is free to answer the questions at any time,
i. e., the answer times can be freely manipulated. (Even
though the adversary cannot gain any advantage from
this with the current prototype, this may be relevant for
alternative implementations that more carefully take the
answer time into account.)
Consequently, the security of the scheme solely relies on
the partition of the shown images into the primed and non-
primed images, i. e., the sets IP and IN .
E. Static Scoring
One straightforward scoring strategy, used by Denning et
al. [16], is what we call static scoring. We brieﬂy describe
static scoring here so later we can compare our new scoring
strategy, dynamic scoring, with it. There are four basic events
that can occur for a single image:
• A primed image (with index i) is
◦ labeled correctly:
◦ labeled incorrectly:
Occurs with probability pi, assigned score sp,c.
Occurs with probability 1 − pi, assigned score sp,f .
• A non-primed image (with index i) is
◦ labeled correctly:
◦ labeled incorrectly:
Occurs with probability ni, assigned score sn,c.
Occurs with probability 1 − ni, assigned score sn,f .
Now static scoring assigns the value 1 to the two “good”
events, i. e., sp,c = 1, sn,f = 1 and 0 to the two “bad” events
sp,f = 0, sn,c = 0. In other words, this scoring strategy counts
the “good” events that happened.
F. Dynamic Scoring
Static scoring does not differentiate between different
thus loses information. We propose an
probability values,
alternative method, dynamic scoring, which takes inspiration
from the notion of self-information or surprisal, a well-known
concept in information theory [40]. Self-information denotes
the information content associated with a single event, as
opposed to entropy which is a property of an entire distribution.
The self-information I(E∗) of an event E∗ with probability
pi is deﬁned as
I(E∗) = − log(pi),
where we use logarithms to base e throughout this work. For
dynamic scoring, score each event with its surprisal, i. e.,
sp,c = ln(pi),
sn,c = ln(ni),
sp,f = ln(1 − pi),
sn,f = ln(1 − ni).
Note that we invert the sign of I(E∗) so that a higher score
refers to a better match, i. e., “less surprisal”. Consequently,
the scores are negative.
For an intuition on why dynamic scoring improves on static
scoring consider the event E∗ that the user wrongly labels a
primed image. Let us assume a ﬁxed “priming effect”, i. e.,
the difference di = pi − ni = 0.5 is constant. We ﬁrst
consider an image where pi = 0.5 (and thus ni = 0), i. e., the
5
primed image is labeled correctly and incorrectly with the same
probability. Then the event E∗ does carry little information, as
it is a plausible outcome for a legitimate (primed) user. Second,
we consider the case where pi = 1 (and thus ni = 0.5), then
every primed image will be labeled correctly by the legitimate
(primed) user. Thus, if event E∗ happens, we can be certain
that it’s not the legitimate user participating in the protocol.
Static scoring gives the same score 0 in both cases, while
dynamic scoring gives a score of −∞ and thus indicates that
this event can only be caused by an impostor.
Legitimate (Primed) User Score. For the legitimate user, the
expected value of the score Si for a single image with index
i equals
E(Si) =
1
2
+
· (pi · ln(pi) + (1 − pi) · ln(1 − pi))
· (ni · ln(ni) + (1 − ni) · ln(1 − ni)) ,
1
2
which equals the average of the Shannon entropies of
Bernoulli-distributed random variables B1,pi and B1,ni with
mean pi and ni, respectively,
E(Si) =
1
2
(H(B1,pi) + H(B1,ni)) ,
where H(X) denotes the Shannon entropy, which is the
expected value of the self-information H(X) = E[I(X)].
Adversary Score. The adversary does not know whether the
image was primed or not (this is what the security of the
scheme rests on). Recall that we assume the adversary knows
the labels and knows the probabilities pi and ni. We assume
that the same number of images is primed and non-primed so
that a single random image is primed with probability 1
2. An
adversary can basically decide to give the correct label or the
wrong label, based on the known probabilities. If the adversary
gives the correct label, the score (for that single image) will
be
(sp,c + sn,c)/2 = (ln(pi) + ln(ni))/2,
and if the adversary gives the incorrect label the score will be
(sp,f + sn,f )/2 = (ln(1 − pi) + ln(1 − ni))/2.
So an adversary can calculate both values and pick the one
that has a higher expected score.
IV. EXPERIMENT 1: PRE-STUDY
A pre-study was performed to identify the critical param-
eters of the MooneyAuth scheme. The critical parameters are:
(1) pi, the probability that a primed image is correctly labeled
and (2) ni, the probability that a non-primed image is labeled
correctly. From these values, we can then derive (3) the size
k of the sets IP and IN . These parameters were then used in
the following experiments.
While there is no ethics committee covering this type of
studies at the organizations involved in this research, there
are strict laws and privacy regulations in place that must be
obeyed. The experiments comply with these strict regulations.
The data we collected about a participant cannot be linked
back to a respondent, as the data is in quite broad categories
only. We did not collect any personal identiﬁers (IP address,
device identiﬁer, name, or similar), and did not use third-party
components that may still log such data. Before any data was
recorded, the respondents were informed about the purpose of
the experiment and how the contributed data will be managed,
and that they can leave the experiment at any time.
A. Experimental Setup
We used a total of 120 images. For each participant, we
used 10 primed images |IP| = 10 and 20 non-primed images
|IN| = 20, i. e., an asymmetric distribution of primed and
non-primed images, randomly selected from the 120 images.
Choosing |IN| to be larger than |IP| helps to speedup the
enrollment process. We developed a web application to conduct
the experiment and measured the parameters pi, ni.
Enrollment (Priming) Phase. For the enrollment phase, a
random subset of |IP| = 10 Mooney images was selected
for each participant. Priming consisted of four steps:
(i) Introduction: The experiment started with a brief intro-
duction and explanation of how the experiment will pro-
ceed. We provided participants with the necessary written
explanation on the web page that this study was about an
alternative web-based authentication scheme. Participants
were informed about the two experimental phases (enroll-
ment and authentication). They were further informed to
be contacted via email, after the enrollment phase, to take
part in the authentication phase. Besides, we provided a
link with further information about Mooney images and
implicit memory for the interested participant.
(ii) Priming 1: For each image from the subset IP , we
ﬁrst presented the Mooney image for 3.5 seconds, then
the original gray-scale image for another 3.5 seconds,
then again the Mooney image. To make the shifting
between the images more comprehensible, we gradually
transitioned between the images, i. e., fading out the ﬁrst
image, while fading in the second image. A label (a
single English word) that described the hidden object
in the image was displayed during the original gray-
scale image presentation. We consider this approach a
reasonable tradeoff between giving enough time to prime
the image and spending time on the enrollment process.
(iii) Survey: After the ﬁrst priming phase, the participants
were asked to ﬁll out a short questionnaire with basic
questions such as age, ﬁeld of work, gender, and opinion
about the usability of current web authentication systems.
This survey was intended to provide the participants
with a short break before the second priming phase. In
addition, we used the data collected from this survey for
a statistical assessment of the participants.
(iv) Priming 2: In the second priming phase, we repeated
the ﬁrst priming phase for the same 10 images in a
new pseudo-randomized order. Overall, users saw each
Mooney image and its corresponding gray-scale image
twice.
Authentication (Recall) Phase. Participants were invited via
email to take part in the authentication phase. Each participant
was provided with an individual link. In order to test how
6
long the effects of priming and authentication performance
lasted, we performed the authentication phase in two separate
groups at two different points in time (approximately two
weeks apart). The authentication phase was composed of two
main steps:
(i) Introduction: Before the authentication started the task
was described. Each participant was asked to view the
Mooney image, and to label the hidden object in the
image as fast as possible. Participants were speciﬁcally
asked to label each image using a single English word.
Importantly, participants were asked to label the images
regardless of what they have seen in the priming phase.
If the participants could not identify the hidden object
(possibly because this image was not used in the priming
phase), they were asked to press the “I don’t know”
button. These instructions were provided in a written
form on the web page.
(ii) Authentication: For each returning participant, we se-
lected a subset IN ⊂ I \ IP of size |IN| = 20.
All Mooney images from the entire set IP ∪ IN were
presented to the participants for labeling in random order.
The interface used for this labeling task can be seen in
Figure 2.
Fig. 2. Screenshot of the user interface during the authentication phase.
Please note that the website as used in Experiment 1 had
a bug, which led to a layout change caused by an information
banner fading out during the labeling process in the authen-
tication phase. This could have led participants to click the
“I don’t know” button accidentally instead of selecting the text
entry ﬁeld. It seems very unlikely that this bug has affected
the results: we have not received any feedback from the
participants mentioning this issue, the fading out related miss-
click could have only occurred in speciﬁc instances with a slow
Internet connections, and when we ﬁltered the participants
that may have been affected based on the text input time the
overall results even slightly improved. Furthermore, we ﬁxed
this potential issue for Experiments 2 and 3, and these report
very similar results. This conﬁrms that the bug had minimal
or no inﬂuence on the results.
7
B. Implementation
To perform the experiments, we implemented a web ap-
plication based on the Model, View, Controller (MVC) de-
sign pattern. The front-end (View) is based on the Bootstrap
framework to accelerate development, the back-end (Model
and Controller) is written in PHP, and data is stored in a
MySQL database. To compute an edit distance during the
authentication phase, we used a C implementation of the
Damerau-Levenshtein algorithm which was included as exter-
nal PHP module. Data was transmitted using transport layer
security (TLS) to protect the privacy of the participants. To be
compliant with the federal data protection act and privacy laws,
users were informed about what data was collected and had to
consent to the processing and storing of the data. Collected
data was stored in encrypted form. We used the free web
analytics software Piwik on the web server to derive statistics
about the web application’s usage. Every user was able to opt-
out and the usage of the Do Not Track (DNT) HTTP header
was honored.
C. Matching Labels
For each image, we created a small set of correct labels
(typically two to ﬁve labels). All labels were converted to
lowercase before comparison. We computed the Damerau-
Levenshtein distance (string edit distance considering inser-
tion, deletion, substitution, and transposition of adjacent let-
ters) between the provided label and all given labels for that
image. If one label had a distance less or equal to 1, we
marked it to be correct. This ensures that a variety of typical
deviations is accepted, such as simple spelling errors, plural
endings, British/American spelling differences, and such.
Although, the use of an open text ﬁeld to provide answers
has drawbacks considering entry time and error rate (especially
on mobile devices), we decided not to use alternative methods
such as selecting the correct answer from multiple choice.
Previous work has shown that using multiple choice answers
leads to higher recognition rates for non-primed Mooney
images [28]. First, the number of choices gives us a lower
bound for the ni and second providing a choice of labels
already exhibits priming effects.
D. User Participation
Participants were recruited via several email distribution
lists and social media. To motivate participants, we rafﬂed gift
cards to those who ﬁnished both phases. For this experiment,
360 people started the enrollment phase. We sent out 323 invite
emails for the authentication phase because 37 participants had
not ﬁnished their enrollment (6 stopped at the introduction
tutorial, 16 during the ﬁrst priming, 6 during the survey,
9 during the second priming). From those re-invited to the
authentication phase 230 ﬁnished, 6 started but have not
ﬁnished, and 87 never tried to start the phase. A high dropout
rate between enrollment and authentication was expected, as
we have not veriﬁed email addresses during the enrollment
of Experiment 1 nor have we ﬁltered obviously fake email
addresses. Furthermore, misclassiﬁcation of our invite email
as spam might have occurred, as well, which would explain
the high number of users that not even tried to start
the
authentication phase.
We collected, with users’ consent, basic statistics such as
country of origin and timing from the server logs, as well as
the results from a survey; a summary of the statistics can be