51%
48%
55%
36%
71%
46%
46%
38%
38%
80%
(in Bytes)
1512075005
672975164
422691678
68598926
2158
(in Bytes)
8215706
582889
294
13173
156
Secure computation outsourcing. Secure computation outsourc-
ing has been studied for more than a decade. Early research is
mainly on delegating cryptographic operations (e.g., modular ex-
ponentiations) to a set of untrusted helpers [38, 31]. More recent
studies include the techniques for secure computing of edit dis-
tances and string alignments [19, 16, 32, 20, 44], which are too
heavyweight for data-intensive computations. Effort has also been
made to securely outsource the computations such as linear alge-
bra operations [15] and machine-learning tasks [25]. For exam-
ple, Peer-for-Privacy decomposes a category of data mining algo-
rithms into vector addition steps and distributes them to multiple
nodes on a cloud, which can be securely evaluated through a spe-
cial secret sharing scheme [25]. All these approaches, however,
incur a large amount of communication during the computation.
Also, secret-sharing based approaches may bring in new policy
challenges: once the data has been shared to multiple parties, an
organization completely loses the control of it, since these parties
can work together to restore the data; it is still unclear whether the
organization needs to sign an agreement with each of them, which
these parties may want to avoid for liability concerns [36], and if
so, what the agreement will look like. This concern is also applied
to the approaches that decompose a computation problem [44] into
small sub-problems and allocates them to multiple problem solvers,
under the assumption that these parties will not collude.
Computation split. The idea of splitting a computation among
multiple parties for security purposes has been explored under dif-
ferent scenarios. For example, Swift [21] uses a secure information-
ﬂow analysis [39] to partition a web application into client and
server components. Other examples include distributing a genomic
computation to two or more parties [44, 48]. However, none of
these techniques are designed for data-intensive computations, the
focus of our research.
7. DISCUSSION
Sedic is designed to work on the data whose sensitive records
are known to its owner and can therefore be marked out. This is
true in most real-life situations: for example, documents in orga-
nizations’ ﬁle systems oftentimes are already labeled by their ac-
cess privileges. On the other hand, there are situations when the
owner herself has no idea about which part of the data is sensitive.
A prominent example here is mapping of human DNA sequences,
which is also known as read mapping [45]. The task is to align a
short human DNA sequence to a long reference genome, so as to
identify the genetic location of the sequence. The challenge here
is that before the alignment, we have no idea where the sequence
belongs, no to mention whether it carries sensitive information. In
this case, we have to come up with a speciﬁc solution to such a
problem, by carefully considering its special features.
Our approach is built upon Hadoop, which does not support
iterative MapReduce [23]. To execute a task that needs to per-
form multiple rounds of map-reduce operations, we have to break
it down into multiple Hadoop jobs. Also, Sedic requires an addi-
tional step to label the output of one job so that its follow-up job
can be split between the public and the private clouds. In the future
research, we plan to move our design to Twister [27] to support
iterative MapReduce, which is important to a set of data mining
analyses [24]. We could also embed a lightweight information-ﬂow
tracking and declassiﬁcation mechanisms into the execution frame-
work to enable automatic labeling of a job’s sensitive outputs.
The design of Sedic can also be improved. For example, our ex-
perimental study found that the data block involving public or sen-
sitive data alone can be more efﬁciently processed than those con-
taining both types of information. A straightforward solution seems
to be simply re-organizing the data, clustering sensitive records
from different blocks into new blocks. This approach, however,
could cause the outcomes of the computation to be incorrect, as
the keys generated by mappers are often related to the positions
of the blocks in the datasets. To solve this problem, we need to
attach such position information to individual records being clus-
tered. The question is, whether the extra workload to process such
information can lead to a signiﬁcant performance degradation. This
will be investigated in the future research.
Our current code analysis and transformation tool can only han-
dle the type of the reducers as described in Section 4.1. This ap-
proach seems to be good enough, as the vast majority of the re-
ducers in real-world jobs are rather simple. However, it is still im-
portant to understand whether there are strong demands for more
complicated reduction operations, which may not be associative.
If such demands are indeed there, the analysis and transformation
techniques certainly need to be improved to accommodate the new
applications. This issue, again, is on our research agenda.
8. CONCLUSION
Commercial cloud services, such as the Amazon EC2, enable
their customers to process a large amount of data at a low cost. This
beneﬁt, however, comes with privacy risks: the computing tasks of
organizations often involves sensitive data and therefore cannot be
directly delegated to the public cloud without proper protection.
Such protection cannot be expected from traditional secure out-
sourcing techniques, which often cannot handle the large amount
of data such computation involves. A more practical solution is to
split the computation so as to move the workload unrelated to sen-
sitive data to the commercial cloud, while keeping the rest within
an organization’s private cloud. This hybrid computing paradigm
needs to be supported by a new privacy-aware computation frame-
work. To this end, we present Sedic, the ﬁrst secure data-intensive
computing system, in this paper. Our approach leverages the spe-
cial features of MapReduce to schedule individual map tasks over
a carefully planned data placement, in a way that the tasks within
the private cloud only work on sensitive data and those on the pub-
lic cloud only processes public data. As a result, all the workload
that does not involve private information can be ofﬂoaded to the
low-cost commercial cloud. To avoid an intensive data exchange
524between clouds, Sedic also automatically analyzes the reducer of a
legacy MapReduce job to extract a combiner for aggregating the
map outcomes on the public cloud. We implemented our tech-
niques on Hadoop and evaluated our prototype on FutureGrid, a
large-scale cloud test-bed. Our study shows that without jeopar-
dizing user privacy, Sedic effectively outsourced a large amount of
computing workload to the public cloud, fully preserved the scala-
bility of MapReduce and also conveniently accommodated legacy
computing jobs.
Acknowledgements
We thank Kumar Bhaskaran, Milton H. Hernandez and Xiaolan
(Catherine) Zhang for their valuable comments and advices, and
Vijay Naik for his knowledge about hybrid cloud. We also thank
anonymous reviewers for their insightful comments. Kehuan Zhang
was also supported in part by the NSF CNS-0716292, CNS-1017782
and the IBM internship program.
9. REFERENCES
[1] Network performance within amazon ec2 and to amazon s3. http://blog.
rightscale.com/2007/10/28/network-performance-
within-amazon-ec2-and-to-amazon-s3/, 2008.
[2] Testing amazon web services bandwidth. http://jonathanmaim.com/
2008/05/testing-amazon-web-services-bandwidth.html,
2008.
[3] Amazon virtual private cloud. http://aws.amazon.com/vpc/, 2011.
[4] Awareness, trust and security to shape government cloud adoption. http://
www.lockheedmartin.com/data/assets/isgs/documents/
CloudComputingWhitePaper.pdf, 2011.
[5] Darpa intrusion detection data set. http://www.ll.mit.edu/mission/
communications/ist/corpora/ideval/data/index.html,
2011.
[6] Enron email dataset. http://www.cs.cmu.edu/~enron/, 2011.
[7] Future grid portal. https://portal.futuregrid.org/, 2011.
[8] An introduction to distributed intrusion detection systems. http://www.
symantec.com/connect/articles/introduction/
distributed/intrusion/detection/systems, 2011.
[9] Social media data helping to target extend demand gen campaigns. http://
www.demandgenreport.com/archives/feature-articles/
594-social-media.html, 2011.
[10] Sony: Hacker stole playstation users’ personal info. http://edition.
cnn.com/2011/TECH/gaming.gadgets/04/26/playstation.
network.hack/index.html, 2011.
[11] Soot: a java optimization framework. http://www.sable.mcgill.ca/
soot/, 2011.
[12] Spam archieve. http://untroubled.org/spam/, 2011.
[13] Summary of the amazon ec2 and amazon rds service disruption in the us east
region. http://aws.amazon.com/message/65648/, 2011.
[14] Target marketing. http://en.wikipedia.org/wiki/Target_
market, 2011.
[15] M. J. Atallah and K. B. Frikken. Securely outsourcing linear algebra
computations. In Proceedings of the 5th ACM Symposium on Information,
Computer and Communications Security, ASIACCS ’10, pages 48–59, New
York, NY, USA, 2010. ACM.
[16] M. J. Atallah, F. Kerschbaum, and W. Du. Secure and private sequence
comparisons. In Proceedings of the 2003 ACM workshop on Privacy in the
electronic society, WPES ’03, pages 39–44, New York, NY, USA, 2003. ACM.
[17] M. J. Atallah and J. Li. Secure outsourcing of sequence comparisons. Int. J. Inf.
Secur., 4:277–287, October 2005.
[18] D. Bernstein, E. Ludvigson, K. Sankar, S. Diamond, and M. Morrow. Blueprint
for the intercloud - protocols and formats for cloud computing interoperability.
Internet and Web Applications and Services, International Conference on,
0:328–336, 2009.
[19] M. Blanton and M. Aliasgari. Secure outsourcing of dna searching via ﬁnite
automata. In S. Foresti and S. Jajodia, editors, DBSec, volume 6166 of Lecture
Notes in Computer Science, pages 49–64. Springer, 2010.
[20] F. Bruekers, S. Katzenbeisser, K. Kursawe, and P. Tuyls. Privacy-preserving
matching of dna proﬁles. Technical Report Report 2008/203, ACR Cryptology
ePrint Archive, 2008.
[21] S. Chong, J. Liu, A. C. Myers, X. Qi, K. Vikram, L. Zheng, and X. Zheng.
Secure web applications via automatic partitioning. SIGOPS Oper. Syst. Rev.,
41:31–44, October 2007.
[22] J. Dean and S. Ghemawat. Mapreduce: simpliﬁed data processing on large
clusters. Commun. ACM, 51:107–113, January 2008.
[23] J. Dean and S. Ghemawat. Mapreduce: simpliﬁed data processing on large
clusters. Commun. ACM, 51:107–113, January 2008.
[24] A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from
incomplete data via the em algorithm. JOURNAL OF THE ROYAL
STATISTICAL SOCIETY, SERIES B, 39(1):1–38, 1977.
[25] Y. Duan, N. Youdao, J. Canny, and J. Zhan. P4p: Practical large-scale
privacy-preserving distributed computation robust against malicious users
abstract. In Proceedings of the 19th USENIX Security Symposium, Washington,
DC, August 2010.
[26] C. Dwork. Differential privacy. In in ICALP, pages 1–12. Springer, 2006.
[27] J. Ekanayake, H. Li, B. Zhang, T. Gunarathne, S.-H. Bae, J. Qiu, and G. Fox.
Twister: A runtime for iterative mapreduce. Technical report, Indiana
University, Bloomington, IN, 2010.
[28] T. A. S. Foundation. Apache Hadoop Project. http://hadoop.apache.
org/, 2010.
[29] B. Furht. Cloud computing fundamentals. In B. Furht and A. Escalante, editors,
Handbook of Cloud Computing, pages 3–19. Springer US, 2010.
[30] C. Gentry. Fully homomorphic encryption using ideal lattices. In Proceedings
of the 41st annual ACM symposium on Theory of computing, STOC ’09, pages
169–178, New York, NY, USA, 2009. ACM.
[31] S. Hohenberger and A. Lysyanskaya. How to securely outsource cryptographic
computations. In J. Kilian, editor, Theory of Cryptography, volume 3378 of
Lecture Notes in Computer Science, pages 264–282. Springer Berlin /
Heidelberg, 2005.
[32] S. Jha, L. Kruger, and V. Shmatikov. Towards practical privacy for genomic
computation. In 2008 IEEE Symposium on Security and Privacy, 2008.
[33] A. V. Konstantinou, T. Eilam, M. Kalantar, A. A. Totok, W. Arnold, and
E. Snible. An architecture for virtual solution composition and deployment in
infrastructure clouds. In Proceedings of the 3rd international workshop on
Virtualization technologies in distributed computing, VTDC ’09, pages 9–18,
New York, NY, USA, 2009. ACM.
[34] B. Langmead, M. Schatz, J. Lin, M. Pop, and S. Salzberg. Searching for SNPs
with cloud computing. Genome Biology, 10(11):R134+, November 2009.
[35] A. W. S. LLC. Amazon Elastic Compute Cloud (Amazon EC2). http://
aws.amazon.com/ec2/, 2010.
[36] A. W. S. LLC. Amazon Web Services Customer Agreement. http://aws.
amazon.com/agreement/, 2010.
[37] M. C. I. Lockheed Martin, LM Cyber Security Alliance. Awareness, trust and
security to shape government cloud adoption. http://www.
lockheedmartin.com/data/assets/isgs/documents/
CloudComputingWhitePaper.pdf, April 2010.
[38] T. Matsumoto, K. Kato, and H. Imai. Speeding up secret computations with
insecure auxiliary devices. In Proceedings of the 8th Annual International
Cryptology Conference on Advances in Cryptology, pages 497–506, London,
UK, 1990. Springer-Verlag.
[39] A. C. Myers and B. Liskov. Protecting privacy using the decentralized label
model. ACM Trans. Softw. Eng. Methodol., 9(4):410–442, 2000.
[40] NSF. Award abstract #091081 - futuregrid: An experimental,
high-performance grid test-bed, 2009.
[41] I. Roy, S. T. V. Setty, A. Kilzer, V. Shmatikov, and E. Witchel. Airavat: Security
and privacy for mapreduce. In NSDI, pages 297–312. USENIX Association,
2010.
[42] M. C. Schatz. CloudBurst: highly sensitive read mapping with MapReduce.
Bioinformatics, 25(11):1363–1369, 2009.
[43] A. W. Services. Aws case study: Washington post.
http://aws.amazon.com/solutions/case-studies/washington-post/, December As
of 2010.
[44] D. Szajda, M. Pohl, J. Owen, and B. G. Lawson. Toward a practical data privacy
scheme for a distributed implementation of the smith-waterman genome
sequence comparison algorithm. In NDSS. The Internet Society, 2006.
[45] C. Trapnell and S. L. Salzberg. How to map billions of short reads onto
genomes. Nature biotechnology, 27(5):455–457, May 2009.
[46] M. van Dijk, C. Gentry, S. Halevi, and V. Vaikuntanathan. Fully homomorphic
encryption over the integers. In H. Gilbert, editor, Advances in Cryptology -
EUROCRYPT 2010, volume 6110 of Lecture Notes in Computer Science, pages
24–43. Springer Berlin / Heidelberg, 2010.
[47] C. Wang, Q. Wang, K. Ren, and W. Lou. Privacy-preserving public auditing for
data storage security in cloud computing. In Proceedings of the 29th conference
on Information communications, INFOCOM’10, pages 525–533, Piscataway,
NJ, USA, 2010. IEEE Press.
[48] R. Wang, X. Wang, Z. Li, H. Tang, M. K. Reiter, and Z. Dong.
Privacy-preserving genomic computation through program specialization. In
CCS ’09: Proceedings of the 16th ACM conference on Computer and
communications security, pages 338–347, New York, NY, USA, 2009. ACM.
[49] Z. Yang, S. Zhong, and R. N. Wright. Privacy-preserving classiﬁcation of
customer data without loss of accuracy. In In SIAM SDM, pages 21–23, 2005.
525