[40], List [53], and their targeted versions. The ﬁrst ques-
tion we are confronted with is: As there are a number of
candidates, which password model shall be preferred? To
answer it, we investigate the weaknesses of each individual
model. Generally, the effectiveness of a machine-learning-
based password model relies on two factors: The model itself
and the training sets used. To preclude the impacts of training
sets, as recommended in [53], [56], we randomly split the
Dodonew dataset into two equal parts, and use part-1 (i.e.,
Dodonew-tr) for training and part-2 (i.e., Dodonew-ts) for
testing. We implement the PCFG model and Markov model
according to the most recent improvements in [40]. More
speciﬁcally, for PCFG model the probabilities associated with
letter segments are learned directly from the training process,
and for Markov model we use a fourth order Markov chain
with end-symbol normalization and Laplace smoothing.
Guided by Eq. 4, we know the defects of password model
≫ 1. These passwords will be
are the passwords pw, PrPW(pw)
PrHW(pw)
cracked ﬁrst by the optimal adversary. In Table VII, we mea-
sure the value of PrPW(pw)
PrHW(pw) for typical passwords pw, where
PrPW(pw) comes directly from Dodonew-ts and PrHW(pw)
is output by each password model. We can conjecture that:
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:19:56 UTC from IEEE Xplore.  Restrictions apply. 
981
THE VALUE OF PrPW(·)
TABLE VII
PrHW(·) GIVEN BY EACH PASSWORD MODEL FOR TYPICAL
PWS (DODONEW-TR VS. DODONEW-TS).†
Probability PrPW(·)
Typical password
PCFG Markov
List
0.96
0.99
1.25
123456
1.25
1.02
1.63
password
1.39
0.95
46.35
123qwe
1.14 6.57 · 1010
1.18
1q2w3e4r
0.92
1.07
107.42
147852369
0.86 5059.23
0.84
110120130
0.77
41.06
1.05
110011
1.82
1.07
0.55
password123
0.78 8.74 · 1010
1.25
p@ssw0rd
4.58
1.39
13.00
XX123456
6.92
6.87
12.53
34567890
27.13
6662.66
0.77
123qwe123qwe
0.60
2.02
5.31
Password123
0.51
0.59
0.67
iloveyou123456
0.31
7.98
0.09
123456abcdefg
0.51
0.09
0.44
520yong
† A value of PrPW (·)
real probability PrPW(·), and light gray means the 2nd worst one.
0.01443750
0.00044136
0.00027111
0.00011588
0.00004293
0.00002337
0.00000886
0.00000381
0.00000221
0.00000160
0.00000148
0.00000123
0.00000037
0.00000025
0.00000012
0.00000011
PrHW (·) with dark gray means it’s the worst one to approximate the
The List model is good at approximating popular passwords,
PCFG good at passwords with a simple structure, and Markov
good at short passwords. All this suggest that each individual
password model has it own advantages, and a hybrid model
would be desirable when A (e.g., a type A3 attacker) may
exploit each model’s disadvantages.
PrB(pw)
PrAB(pw)
3List + 1
≫ 1 and PrPW(pw)
models A and B, denoted by PrAB(pw) = 1
2 PrB(pw)), the event PrPW(pw)
1
Note that, for a hybrid model A&B that is resulted from
2 PrA(pw) +
≫ 1 happens if and only if
≫ 1. So such hybrid models can
PrPW(pw)
PrA(pw)
signiﬁcantly alleviate defects of individual password model.
Therefore, we use hybird models (e.g., 1
3Markov +
3PCFG) to resist type A3 and A4 attackers.
1
The above conjectures are corroborated by Table VIII. We
measure the passwords that appear in the top-103 PrPW(·)
PrHW(·) list
under each model. According to our theories in Sec. III, these
passwords will be attacked in A’s ﬁrst 1000 attempts and thus
they are the top-1000 most vulnerable ones. As expected, all
methods are not good at dealing with PII-semantic involved
passwords and passwords not covered by the training set. This
outlines the need for designing PII-aware methods when type
A2 attacker (i.e., with PII) is considered.
Table VIII also re-
veals some unexpected
results. No matter hon-
eywords are generated
by which model, all
these top-103 most vul-
nerable passwords are
not popular ones—they
do not fall into the top-
104 popular password
list. When combining the 3rd and 4th rows, one can infer
that the List model is not good at predicting these passwords
with a frequency 22 (in test set)
1.000
Feq.<10 (in test set) 0.960 1.000
Password len. ≥16
1.000
0.000 0.906
Structure len. ≥6
0.001 0.995
0.576
0.051
0.012 0.016
With semantic info
0.000 0.442
0.695
Email/site address
* feq.=frequencey; len.=length.
BASIC INFO ABOUT PWS IN THE TOP-103
PrPW(·)
PrHW(·) LIST UNDER EACH PW MODEL.
TABLE VIII
E. Additional experiments and discussions
Fig. 6 demonstrates the effectiveness of our List-model
three different password
based honeyword method against
guessing models, under the basic attacker A1 who only has
public datasets. A1 can merely distinguish about 526=104/19
passwords (see Fig. 6(a)∼6(c)); A gains a success rate of 5%
with one guess against 20 sweetwords (see Fig. 6(d)∼6(f)).
Interestingly, when A1 does not employ List-model based
attacks, Markov or hybrid methods sometimes perform the best
over other methods including the List-model based one. This
indicates the importance of designing optimal attacks for a
given scenario, otherwise the security might be overestimated.
Fig. 4 of Sec. IV-B shows that DoS can be largely mitigated
that ﬁlters weak passwords
by imposing a 105 blocklist
and honeywords, under the alarm policy T1=1 that a single
honeyword attempt against an account raises an alarm. Still,
when allowed 100 online lo-
gin attempts, the DoS attack-
er can achieve a success rate
of 6.08% when k=20 and a
success rate of 12.13% when
k=40. The effectiveness is
not very desirable. Fig. 7
further investigates the effec-
Fig. 7. DoS success rate against
1
3 List+ 1
3 PCFG. Trained on
tiveness of this same block-
Dodonew-tr,
tested on Dodonew-ts.
list under the case when we
set T1=3. Results show that
“Blocklist” means a 100k blocklist is
used to ﬁlter weak passwords (and
honeywords), while “Normal” means
this countermeasure signiﬁ-
no blocklist
is used. “DoS success
cantly alleviates DoS risks:
rate” means the probability of hitting
T1=3 honeywords for each account.
Within 100 guesses, the DoS
attacker can only achieve a success rate of 0.003% when k=20,
0.010% when k=30, and 0.025% when k=40. In contrast,
without this blocklist, this ﬁgure will be 5.45% when k=20,
14.64% when k=30, and 26.41% when k=40.
3 Markov+ 1
Fig. 8 illustrates how ﬂatness varies with the number (i.e.,
k) of sweetwords that are associated with each user account.
There are obvious diminish-returns: When k is large enough
(e.g., ≥60), marginal security gains will be achieved when k is
further increased. On the other hand, a larger k means a larger
storage cost. Thus, we recommend k=40 to be cost-effective.
We choose Dodonew as the dataset used in our human-based
experiments, because: (1) Dodonew is a canonical dataset for
Chinese users, and it has been used in almost every research
regarding passwords of Chinese users (see [12], [40], [52],
[53], [56]); and (2) For ethics considerations—Dodonew was
leaked in 2011, ten years ago, and it is reasonable to assume
that Dodonew users have already changed their passwords.
Fig. 9 shows the ﬂatness curves of human-based evaluation,
and detailed setups can be found in Sec. V-C. The four
methods in [35] achieve 0.40+-ﬂatness under A1 and 0.48+-
ﬂatness under A2, far from perfect. In comparison, both List
3PCFG methods achieve almost perfect
and 1
ﬂatness (i.e., ϵ≈ 1
20) under non PII-aware human attackers.
Even when attackers are PII-aware (see Figs. 9(j) and 9(l)),
−-ﬂatness. This implies that our
our methods still achieve 0.09
targeted methods can well capture user PII semantics.
3Markov+ 1
3List+ 1
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:19:56 UTC from IEEE Xplore.  Restrictions apply. 
982
(a)Tweaking-tail: How ﬂatness varies with k
Fig. 8. How the ﬂatness curve varies with k, trained on Dodonew-tr and tested on Dodonew-ts. Here we use tweaking-tail (under A1) and
3 PCFG (under A3) as examples. The sub-ﬁg(c) shows how ϵ (=yjx=1 in sub-ﬁg(b)) in our hybrid method evolves with k.
3 List+ 1
(b) Our method: How ﬂatness varies with k.
3 Markov+ 1
1
(c) Ours: The relationship between ϵ and k.
(a) Flatness graph of Tweaking-tail (under a type-
A1 attacker).
(b) Flatness graph of modeling syntax (under
a
type-A1 attacker).
(c) Flatness graph of hybrid (under a type-A1
attacker).
(d) Flatness graph of Tweaking-tail (under a type-
A2 attacker).
(e) Flatness graph of modeling syntax (under a
type-A2 attacker).
(f) Flatness graph of hybrid method (under a type-
A2 attacker)
(g) Flatness graph of simple model (under a type-
A1 attacker).
(h) Flatness graph of our list method (under a type-
A1 attacker).
(i) Flatness graph of 1
type-A3 attacker).
3 List+ 1
3 PCFG+ 1
3 PCFG (under a
(j) Flatness graph of simple model (under a type-
3 TarMarkov +
A2 attacker).
Fig. 9. Evaluating our methods and Juels-Rivest’s ones [35] by using human-expert-based attacks. “under Ax” means experts are simulating
type-Ax attackers. Humans are particularly effective at telling apart real PWs generated by Juels-Rivest’s methods [35] when given PII (see
sub-ﬁgs d, e, f and j), yet they show no advantages over computer-based attackers against our methods. The 5,280 tested accounts are from
PII-Dodonew. All our four methods show signiﬁcantly better security than Juels-Rivest’s four real-password related methods [35].
(k) Flatness graph of our TarList method (under a
type-A2 attacker).
(l) Flatness graph of
3 TarPCFG (under a type-A4 attacker).
1
3 TarList + 1
1
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:19:56 UTC from IEEE Xplore.  Restrictions apply. 
983
(cid:3)(cid:1)(cid:2)(cid:6)(cid:2)(cid:1)(cid:5)(cid:6)(cid:1)(cid:2)(cid:1)(cid:2)(cid:3)(cid:4)(cid:1)(cid:2)(cid:5)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:4)(cid:2)(cid:1)(cid:3)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:3)(cid:1)(cid:2)(cid:1)(cid:2)(cid:31)(cid:36)(cid:5)(cid:30)(cid:22)(cid:14)(cid:23)(cid:26)(cid:36)(cid:6)(cid:3)(cid:32)(cid:33)(cid:3)(cid:34)(cid:36)(cid:5)(cid:30)(cid:22)(cid:14)(cid:23)(cid:26)(cid:36)(cid:7)(cid:1)(cid:35)(cid:2)(cid:5)(cid:30)(cid:22)(cid:14)(cid:23)(cid:27)(cid:36)(cid:8)(cid:5)(cid:30)(cid:22)(cid:14)(cid:23)(cid:27)(cid:36)(cid:9)(cid:36)(cid:4)(cid:4)(cid:4)(cid:4)(cid:4)(cid:5)(cid:30)(cid:22)(cid:14)(cid:23)(cid:26)(cid:36)(cid:10)(cid:3)(cid:2)(cid:6)(cid:3)(cid:4)(cid:6)(cid:3)(cid:2)(cid:5)(cid:11)(cid:29)(cid:15)(cid:15)(cid:28)(cid:29)(cid:21)(cid:24)(cid:13)(cid:36)(cid:18)(cid:21)(cid:16)(cid:17)(cid:20)(cid:36)(cid:12)(cid:28)(cid:28)(cid:15)(cid:19)(cid:22)(cid:28)(cid:25)(cid:36)(cid:3)(cid:1)(cid:2)(cid:7)(cid:2)(cid:1)(cid:6)(cid:7)(cid:1)(cid:1)(cid:1)(cid:2)(cid:1)(cid:3)(cid:3)(cid:1)(cid:2)(cid:1)(cid:1)(cid:4)(cid:2)(cid:4)(cid:1)(cid:3)(cid:1)(cid:5)(cid:3)(cid:2)(cid:4)(cid:6)(cid:5)(cid:7)(cid:4)(cid:2)(cid:7)(cid:3)(cid:5)(cid:7)(cid:1)(cid:15)(cid:4)(cid:4)(cid:14)(cid:15)(cid:10)(cid:12)(cid:3)(cid:16)(cid:7)(cid:10)(cid:5)(cid:6)(cid:9)(cid:16)(cid:2)(cid:14)(cid:14)(cid:4)(cid:8)(cid:11)(cid:14)(cid:13)(cid:16)(cid:4)(cid:3)(cid:6)