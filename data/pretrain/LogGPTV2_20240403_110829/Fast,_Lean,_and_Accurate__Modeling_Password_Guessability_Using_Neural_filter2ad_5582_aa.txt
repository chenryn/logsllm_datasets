title:Fast, Lean, and Accurate: Modeling Password Guessability Using Neural
Networks
author:William Melicher and
Blase Ur and
Sean M. Segreti and
Saranga Komanduri and
Lujo Bauer and
Nicolas Christin and
Lorrie Faith Cranor
Fast, Lean, and Accurate: Modeling Password 
Guessability Using Neural Networks
William Melicher, Blase Ur, Sean M. Segreti, Saranga Komanduri, Lujo Bauer,  
Nicolas Christin, and Lorrie Faith Cranor, Carnegie Mellon University
 https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/melicher
This paper is included in the Proceedings of the 25th USENIX Security SymposiumAugust 10–12, 2016 • Austin, TXISBN 978-1-931971-32-4Open access to the Proceedings of the 25th USENIX Security Symposium is sponsored by USENIX Fast, Lean, and Accurate:
Modeling Password Guessability Using Neural Networks
William Melicher, Blase Ur, Sean M. Segreti, Saranga Komanduri,
Lujo Bauer, Nicolas Christin, Lorrie Faith Cranor
Carnegie Mellon University
Abstract
Human-chosen text passwords, today’s dominant form of
authentication, are vulnerable to guessing attacks. Un-
fortunately, existing approaches for evaluating password
strength by modeling adversarial password guessing are
either inaccurate or orders of magnitude too large and
too slow for real-time, client-side password checking.
We propose using artiﬁcial neural networks to model
text passwords’ resistance to guessing attacks and ex-
plore how different architectures and training methods
impact neural networks’ guessing effectiveness. We
show that neural networks can often guess passwords
more effectively than state-of-the-art approaches, such
as probabilistic context-free grammars and Markov mod-
els. We also show that our neural networks can be highly
compressed—to as little as hundreds of kilobytes—
without substantially worsening guessing effectiveness.
Building on these results, we implement in JavaScript
the ﬁrst principled client-side model of password guess-
ing, which analyzes a password’s resistance to a guessing
attack of arbitrary duration with sub-second latency. To-
gether, our contributions enable more accurate and prac-
tical password checking than was previously possible.
1
Introduction
Text passwords are currently the most common form of
authentication, and they promise to continue to be so
for the foreseeable future [53]. Unfortunately, users of-
ten choose predictable passwords, enabling password-
guessing attacks. In response, proactive password check-
ing is used to evaluate password strength [19].
A common way to evaluate the strength of a pass-
word is by running or simulating password-guessing
techniques [35,59,92]. A suite of well-conﬁgured guess-
ing techniques, encompassing both probabilistic ap-
proaches [37,65,93] and off-the-shelf password-recovery
tools [74, 83], can accurately model the vulnerability of
passwords to guessing by expert attackers [89]. Unfortu-
nately, these techniques are often very computationally
intensive, requiring hundreds of megabytes to gigabytes
of disk space, and taking days to execute. Therefore, they
are typically unsuitable for real-time evaluation of pass-
word strength, and sometimes for any practically useful
evaluation of password strength.
With the goal of gauging the strength of human-chosen
text passwords both more accurately and more prac-
tically, we propose using artiﬁcial neural networks to
guess passwords. Artiﬁcial neural networks (hereafter
referred to as “neural networks”) are a machine-learning
technique designed to approximate highly dimensional
functions. They have been shown to be very effective at
generating novel sequences [49,84], suggesting a natural
ﬁt for generating password guesses.
In this paper, we ﬁrst comprehensively test the impact
of varying the neural network model size, model archi-
tecture, training data, and training technique on the net-
work’s ability to guess different types of passwords. We
compare our implementation of neural networks to state-
of-the-art password-guessing models, including widely
studied Markov models [65] and probabilistic context-
free grammars [59, 93], as well as software tools using
mangled dictionary entries [74, 83].
In our tests, we
evaluate the performance of probabilistic models to large
numbers of guesses using recently proposed Monte Carlo
methods [34]. We ﬁnd that neural networks guess pass-
words more successfully than other password-guessing
methods in general, especially so beyond 1010 guesses
and on non-traditional password policies. These cases
are interesting because password-guessing attacks often
proceed far beyond 1010 guesses [44,46] and because ex-
isting password-guessing attacks underperform on new,
non-traditional password policies [79, 80].
Although more effective password guessing using
neural networks is an important contribution on its own,
we also show that the neural networks we use can be
highly compressed with minimal loss of guessing ef-
USENIX Association  
25th USENIX Security Symposium  175
fectiveness. Our approach is thus far more suitable
than existing password-guessing methods for client-side
password checking. Most existing client-side password
checkers are inaccurate [33] because they rely on simple,
easily compressible heuristics, such as counting the num-
ber of characters or character classes in a password. In
contrast, we show that a highly compressed neural net-
work more accurately measures password strength than
existing client-side checkers. We can compress such a
neural network into hundreds of kilobytes, which is small
enough to be included in an app for mobile devices, bun-
dled with encryption software, or used in a web page
password meter.
To demonstrate the practical suitability of neural net-
works for client-side password checking, we implement
and benchmark a neural-network password checker in
JavaScript. This implementation, which we have re-
leased as open-source software,1 is immediately suitable
for use in mobile apps, browser extensions, and web page
password meters. Our implementation gives real-time
feedback on password strength in fractions of a second,
and it more accurately measures resistance to guessing
than existing client-side methods.
In summary, this paper makes three main contribu-
tions that together substantially increase our ability to
detect and help eliminate weak passwords. First, we pro-
pose neural networks as a model for guessing human-
chosen passwords and comprehensively evaluate how
varying their training, parameters, and compression im-
pacts guessing effectiveness.
In many circumstances,
neural networks guess more accurately than state-of-art
techniques. Second, leveraging neural networks, we cre-
ate a password-guessing model sufﬁciently compressible
and efﬁcient for client-side proactive password checking.
Third, we build and benchmark a JavaScript implementa-
tion of such a checker. In common web browsers running
on commodity hardware, this implementation models an
arbitrarily high number of adversarial guesses with sub-
second latency, while requiring only hundreds of kilo-
bytes of data to be transferred to a client. Together, our
contributions enable more accurate proactive password
checking, in a far broader range of common scenarios,
than was previously possible.
2 Background and Related Work
To highlight when password strength matters, we ﬁrst
summarize password-guessing attacks. We then discuss
metrics and models for evaluating password strength,
as well as lightweight methods for estimating password
strength during password creation. Finally, we summa-
rize prior work on generating text using neural networks.
1https://github.com/cupslab/neural_network_cracking
2.1 Password-Guessing Attacks
The extent to which passwords are vulnerable to guess-
ing attacks is highly situational. For phishing attacks,
keyloggers, or shoulder surﬁng, password strength does
not matter. Some systems implement rate-limiting poli-
cies, locking an online account or a device after a small
number of incorrect attempts. In these cases, passwords
other than perhaps the million most predictable are un-
likely to be guessed [39].
Guessing attacks are a threat, however, in three other
scenarios. First, if rate limiting is not properly im-
plemented, as is believed to have been the case in the
2014 theft of celebrities’ personal photos from Apple’s
iCloud [50], large-scale guessing becomes possible. Sec-
ond, if a database of hashed passwords is stolen, which
sadly occurs frequently [20, 23, 27, 45, 46, 67, 73, 75, 87],
an ofﬂine attack is possible. An attacker chooses likely
candidate passwords, hashes them, and searches the
database for a matching hash. When a match is found,
attackers can rely on the high likelihood of password
reuse across accounts and try the same credentials on
other systems [32]. Attacks leveraging password reuse
have real-world consequences, including the recent com-
promise of Mozilla’s Bugzilla database due to an admin-
istrator reusing a password [76] and the compromise of
20 million accounts on Taobao, a Chinese online shop-
ping website similar to eBay, due to password reuse [36].
Third, common scenarios in which cryptographic key
material is derived from, or protected by, a password
are vulnerable to large-scale guessing in the same way
as hashed password databases for online accounts. For
instance, for password managers that sync across de-
vices [52] or privacy-preserving cloud backup tools (e.g.,
SpiderOak [82]), the security of ﬁles stored in the cloud
depends directly on password strength. Furthermore,
cryptographic keys used for asymmetric secure messag-
ing (e.g., GPG private keys), disk-encryption tools (e.g.,
TrueCrypt), and Windows Domain Kerberos Tickets [31]
are protected by human-generated passwords. If the ﬁle
containing this key material is compromised, the strength
of the password is critical for security. The importance
of this ﬁnal scenario is likely to grow with the adoption
of password managers and encryption tools.
2.2 Measuring Password Strength
Models of password strength often take one of two con-
ceptual forms. The ﬁrst relies on purely statistical meth-
ods, such as Shannon entropy or other advanced sta-
tistical approaches [21, 22]. However, because of the
unrealistically large sample sizes required, we consider
these types of model out of scope. The second concep-
tual approach is to simulate adversarial password guess-
176  25th USENIX Security Symposium 
USENIX Association
2
ing [34, 65, 89]. Our application of neural networks fol-
lows this method. Below, we describe the password-
guessing approaches that have been widely studied in
academia and used in adversarial password cracking, all
of which we compare to neural networks in our analyses.
Academic studies of password guessing have focused on
probabilistic methods that take as input large password
sets, then output guesses in descending probability or-
der. Password cracking tools rely on efﬁcient heuristics
to model common password characteristics.
Probabilistic Context-Free Grammars One proba-
bilistic method uses probabilistic context-free grammars
(PCFGs) [93]. The intuition behind PCFGs is that pass-
words are built with template structures (e.g., 6 letters
followed by 2 digits) and terminals that ﬁt into those
structures. A password’s probability is the probability
of its structure multiplied by those of its terminals.
Researchers have found that using separate training
sources for structures and terminals improves guess-
ing [59].
It is also beneﬁcial to assign probabilities
to unseen terminals by smoothing, as well as to aug-
ment guesses generated by the grammar with passwords
taken verbatim from the training data without abstracting
them into the grammar [60]. Furthermore, using natural-
language dictionaries to instantiate terminals improves
guessing, particularly for long passwords [91].
Markov Models Using Markov models to guess pass-
words, ﬁrst proposed in 2005 [70], has recently been
studied more comprehensively [37, 65]. Conceptually,
Markov models predict the probability of the next char-
acter in a password based on the previous characters, or
context characters. Using more context characters can
allow for better guesses, yet risks overﬁtting. Smooth-
ing and backoff methods compensate for overﬁtting.
Researchers have found that a 6-gram Markov model
with additive smoothing is often optimal for modeling
English-language passwords [65]. We use that conﬁgu-
ration in our analyses.
Mangled Wordlist Methods
In adversarial password
cracking, software tools are commonly used to generate
password guesses [44]. The most popular tools transform
a wordlist (passwords and dictionary entries) using man-
gling rules, or transformations intended to model com-
mon behaviors in how humans craft passwords. For ex-
ample, a mangling rule may append a digit and change
each ‘a’ to ‘@’. Two popular tools of this type are Hash-
cat [83] and John the Ripper (JtR, [74]). While these ap-
proaches are not directly based on statistical modeling,
they produce fairly accurate guesses [89] quickly, which
has led to their wide use [44].
2.3 Proactive Password Checking
Although the previously discussed password-guessing
models can accurately model human-created pass-
words [89],
they take hours or days and megabytes
or gigabytes of disk space, making them too resource-
intensive to provide real-time feedback to users. Current
real-time password checkers can be categorized based
on whether they run entirely client-side. Checkers with
a server-side component can be more accurate because
they can leverage large amounts of data. For instance, re-
searchers have proposed using server-side Markov mod-
els to gauge password strength [26]. Others have studied
using training data from leaked passwords and natural-
language corpora to show users predictions about what
they will type next [61].
Unfortunately, a server-side component
introduces
In some cases,
substantial disadvantages for security.
sending a password to a server for password checking
destroys all security guarantees. For instance, passwords
that protect an encrypted volume (e.g., TrueCrypt) or
cryptographic keys (e.g., GPG), as well as the master
password for a password manager, should never leave
the user’s device, even for proactive password checking.
As a result, accurate password checking is often miss-
ing from these security-critical applications.
In cases
when a password is eventually sent to the server (e.g.,
for an online account), a real-time, server-side compo-
nent both adds latency and opens password meters to
powerful side-channel attacks based on keyboard timing,
message size, and caching [81].
Prior client-side password checkers, such as those run-
ning entirely in a web browser, rely on heuristics that can
be easily encoded. Many common meters rate passwords
based on their length or inclusion of different character
classes [33,88]. Unfortunately, in comprehensive tests of
both client- and server-side password meters, all but one
meter was highly inaccurate [33]. Only zxcvbn [94,95],
which uses dozens of more advanced heuristics, gave
reasonably accurate strength estimations. Such meters,
however, do not directly model adversarial guessing be-
cause of the inability to succinctly encode models and
calculate real-time results.
In contrast, our approach
models adversarial guessing entirely on the client side.
2.4 Neural Networks
Neural networks, which we use to model passwords, are
a machine-learning technique for approximating highly
dimensional functions. Designed to model human neu-
rons, they are particularly adept at fuzzy classiﬁcation
problems and generating novel sequences. Our method
of generating candidate password guesses draws heav-
ily on previous work that generated the probability of
USENIX Association  
25th USENIX Security Symposium  177
3
the next element in a string based on the preceding el-
ements [49, 84]. For example, in generating the string
password, a neural network might be given passwor and
output that d has a high probability of occurring next.
Although password creation and text generation are
conceptually similar, little research has attempted to use
insights from text generation to model passwords. A
decade ago, neural networks were proposed as a method
for classifying passwords into two very broad categories
(weak or strong) [30], but that work did not seek to
model the order in which passwords would be guessed
or other aspects of a guessing attack. To our knowledge,
the only proposal to use neural networks in a password-
guessing attack was a recent blog post [71].
In sharp
contrast to our extensive testing of different parameters
to make neural networks effective in practice, that work
made few reﬁnements to the application of neural net-
works, leading the author to doubt that the approach has
“any practical relevance.” Additionally, that work sought
only to model a few likely password guesses, as opposed
to our use of Monte Carlo methods to simulate an arbi-
trary number of guesses.
Conceptually, neural networks have advantages over
other methods. In contrast to PCFGs and Markov mod-
els, the sequences generated by neural networks can be
inexact, novel sequences [49], which led to our intu-
ition that neural networks might be appropriate for pass-
word guessing. Prior approaches to probabilistic pass-
word guessing (e.g., Markov models [26]) were sufﬁ-
ciently memory-intensive to be impractical on only the
client-side. However, neural networks can model natu-
ral language in far less space than Markov models [68].
Neural networks have also been shown to transfer knowl-
edge about one task to related tasks [97]. This is cru-
cial for targeting novel password-composition policies,
for which training data is sparse at best.
3 System Design
We experimented with a broad range of options in a large
design space and eventually arrived at a system design
that 1) leverages neural networks for password guessing,
and 2) provides a client-side guess estimation method.
3.1 Measuring Password Strength
Similarly to Markov models, neural networks in our sys-
tem are trained to generate the next character of a pass-
word given the preceding characters of a password. Fig-
ure 1 illustrates our construction. Like in Markov mod-
els [34, 65], we rely on a special password-ending sym-
bol to model the probability of ending a password af-
ter a sequence of characters. For example, to calculate
the probability of the entire password ‘bad’, we would
context: ba
Input
Context 
characters
a: 0, b: 1
c: 0, d: 0
END: 0
a: 1, b: 0
c: 0, d: 0
END: 0
a: 0, b: 0
c: 0, d: 0
END: 0
a: 0, b: 0
c: 0, d: 0
END: 0
a: .001
b: .001
c: .20
d: .80
END: 0
Post- 
processing
Neural 
Network
A: 0.0001
a: 0.0009
B: 0.0001
b: 0.0009
C: 0.02
c: 0.18
D: 0.08
d: 0.72
END: 0
Uppercase 