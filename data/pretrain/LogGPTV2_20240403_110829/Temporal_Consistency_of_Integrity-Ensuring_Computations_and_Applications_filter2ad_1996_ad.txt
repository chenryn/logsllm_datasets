(b) 64KB Page Size
Figure 9: Run-time of various temporal consistency ensuring
mechanisms in I.MX6-SabreLite.
Unlike Thchecksum and Thmain, implementing Thfault is not triv-
ial; it requires support from the underlying hardware and/or kernel
in order to: (1) detect whenever a process causes a fault and (2)
examine whether the fault is caused by an invalid write access and
whether it happens within a specific memory range. Fortunately,
these operations are already available in seL4 without requiring
modifications to the kernel.
We implement Thfault by leveraging how a fault endpoint works
in seL4. An endpoint is an seL4 object that allows a small amount
of data to be transferred between two threads. When a process
or a thread faults, the seL4 kernel automatically sends a fault IPC
message to its registered fault endpoint. This fault IPC message
provides useful information that helps Thfault decide whether the
fault will result in memory inconsistency. For instance, the message
includes a type of fault (e.g. page fault, capability fault, or unknown
syscall), address that causes the fault and whether a read or write
access causes the fault6. In our implementation, Thmain shares a
single fault endpoint among all user-space processes, allowing a
fault caused by any process to be transmitted to this fault endpoint.
The last step of the implementation is to have Thfault wait for an
incoming message from the fault endpoint and notify Thmain if the
6See http://sel4.systems/Info/Docs/seL4-manual-latest.pdf for full details.
LockPageUnlockPageCopyMemMacMem (KeyedBLAKE2S)10-310-210-1100run-time in [s]I.MX6-SabreLiteODROID-XU4102030405060708090100memory size [MB]012345run-time [s]No-Lock (Baseline)Inc-LockDec-LockAll-LockCpy-Lock102030405060708090100memory size [MB]012345run-time [s]No-Lock (Baseline)Inc-LockDec-LockAll-LockCpy-LockThfault
Thmain
Thchecksum
LockPaдe
DetectInconsist
altalt
Thchecksum replies first
Suspend
return: InconsistDetected, P′
ComputeChecksum
return: Checksum
U nlockPaдe
output:
Checksum
Suspend
U nlockPaдe+
Resume(P′)
Resume
return: Checksum
output:
Checksum + Inconsist
Figure 11: Run-time of inconsistency detection with 4KB page size
on I.MX6-SabreLite.
Figure 10: Sequence diagram of PAt t with memory inconsistency
detection during single attestation instance. PAt t chooses to resume
execution of Thchecksum after P′ causes memory inconsistency.
Figure 12: Downtime of the faulting process P′ when its actions re-
sult in an inconsistency with 4KB page size on I.MX6-SabreLite. Hor-
izontal lines represent downtime from the approach where PAt t re-
solves inconsistency by unlocking entire memory of P′.
message indicates the attempted write access on memory being
attested. A sample code for Thfault is provided in Appendix C.
A diagram in Figure 10 summarizes the sequence of operation
of our modified PAtt during a single attestation instance. First,
Thmain locks entire memory to be attested, then calls Thchecksum
and Thfault via a shared endpoint and waits for their replies. There
are two possible scenarios:
(1) If no process attempts to write into attested memory during
attestation, Thchecksum successfully completes and returns
to Thmain with an attestation token. Thmain then promptly
unlocks attested memory.
(2) Otherwise, the kernel suspends P′ and transmits a fault IPC
message to Thfault. Once receiving it, Thfault replies back to
Thmain, which suspends Thchecksum, unlocks memory, and
resumes execution of P′. Thmain can also choose to abort,
continue or restart execution of Thchecksum.
Finally, Thmain outputs the result (an attestation token and/or
whether any inconsistency occurs or not) back to Vrf.
5.6 Experimental Results: Inconsistency
Detection
To evaluate performance of the inconsistency detection mechanism,
we experimented by running two processes – modified PAtt and P′
– with the same execution priority on I.MX6-SabreLite. (Multiple
same-priority processes are scheduled in a round-robin fashion.)
Thus, timing results for this experiment differ from others that
consider only PAtt running at any given time.
Results in Figure 11 show the performance comparison of: (1)
the inconsistency detection mechanism (with and without incon-
sistency occurring), (2) All-Lock, and (3) attestation without con-
sistency guarantee or No-Lock on 16MB to 96MB memory. In this
experiment, we assume that PAtt chooses to resolve inconsistency
by unlocking the entire memory of P′. In case of no inconsistency,
our mechanism (as expected) performs as well as All-Lock and
roughly 6% slower than No-Lock. On the other hand, when an in-
consistency occurs, the mechanism (surprisingly) runs 3% faster.
While this may seem counter-intuitive, we found that improved
performance is caused by Thmain performing memory unlocking
while P′ is being suspended. This results in run-time of the unlock
102030405060708090100memory size [MB]0246810run-time [s]All-Lock: Temporal Consistency MechanismInconsistency Detection (without inconsistency)Inconsistency Detection (with inconsistency)No-Lock: Attestation without Consistency Guarantee05101520253035# of modified pages0.000.020.040.060.080.100.120.140.16run-time [s]Unlock Only Page Causing Inconsist (Alt)Attested Mem: 80MB Mem (20480 pages)Attested Mem: 48MB Mem (12288 pages)Attested Mem: 16MB Mem (4096 pages)operation being ∼2x faster than that of the same operation in its
counterpart, where memory unlocking is performed concurrently
with P′.
We now consider the alternative, whereby PAtt resolves the
inconsistency by unlocking only the page that causes it, instead
of unlocking entire memory. Clearly, runtime overhead of this
approach depends on the number of times inconsistency is trig-
gered 7 during attestation. In this experiment, we measure overhead
through downtime of P′, i.e., total elapsed time for P′ to complete
writing into locked pages. Figure 12 illustrates that overhead, as
expected, is linear in terms of a number of modified pages. It also
shows that it is more beneficial to use the alternative approach
where P′ is expected to perform only a few memory writes. In our
experimental setting, this threshold is around 0.12% of P′ memory
pages.
6 RELATED WORK
To the best of our knowledge, there has been no prior work on tem-
poral consistency of integrity-ensuring functions, though it is pos-
sible that this concept has been considered under a different guise
in the cryptographic literature. Extended versions Inc-Lock-Ext
and Cpy-Lock & Writeback can be viewed as a form of protection
against “Time of Check Time of Use” (TOCTOU) attacks in certain
applications.
The “Provable Virus Detection” method discussed in [22] is a
very relevant result. In it, a secret is embedded within software
running on a device is periodically checked by a trusted verifier.
The argument is that injected malware consistently destroys the
secret, and its presence is therefore detectable. While promising,
[22] only deals with malware directly inserted into a system (e.g.,
via DMA) and requires substantial modifications to the CPU.
One alternative way to detect malware without locking mem-
ory (however, without guaranteed consistency) is explored in [4].
Memory is measured in a random order, which cannot be learned
or anticipated by malware. Since memory is never locked, this is
an advantage for time-sensitive applications. The main drawback
of [4] is its probabilistic nature, which can lead to a significantly
increased time to perform attestation.
The rest of this section focuses on related work in RA.
RA aims to detect malware presence by verifying integrity of
a remote and untrusted embedded (or IoT) device. It is typically
realized as a protocol, whereby a trusted verifier interacts with a
remote prover to obtain a challenge-based integrity measurement
of the latter’s memory state. RA techniques fall into three main
categories: hardware-based, software-based, and hybrid.
Hardware-based attestation [32, 38] uses dedicated hardware com-
ponents, such as a Trusted Platform Module (TPM) [15], ARM Trust-
Zone [23] or Intel SGX [8] to execute attestation code in a trusted
execution environment. Even though such features are currently
available in personal computers, laptops and smartphones, they are
still considered a “luxury” for low-end embedded devices.
Software-based attestation [34, 35] requires no hardware support
and performs attestation solely based on software and precise tim-
ing measurements. When deployed on a single-processor system,
this approach can ensure temporal consistency; malware could try
7This is equivalent to the number of memory pages of P′ modified during attestation.
to interrupt the measurement process and cause temporal inconsis-
tency (e.g. by moving itself around) during attestation. However,
this action will result in additional delay, which is then detectable by
Vrf. Software-based approaches limit the prover to being one-hop
away from the verifier, in order to ensure that the round-trip time
is either negligible or fixed. Such approaches also rely on strong
assumptions about attackers’ behavior [1] and are typically used
only for legacy devices, where no other RA techniques are viable.
Finally, hybrid attestation [2, 11, 19], based on software/hardware
co-design, realizes RA while attempting to minimize required hard-
ware features and the software footprint. SMART [11] is the first
hybrid RA design with minimal hardware modifications to existing
microcontroller units (MCUs). It has the following key features:
• Attestation code is immutable: it is located in, and executed
• Attestation code is safe: its execution always terminates and
• Attestation code is executed atomically: (1) it is uninterrupt-
ible, and (2) it starts from the first instruction and exits at the
last instruction. (This is enforced by hard-wired MCU access
controls and disabling interrupts upon entry of attestation
code.)
• A secret attestation key is stored in an isolated memory
location that can be accessed (based on hard-wired MCU
rules) only from within attestation code.
leaks no information other than the attestation result.
from, ROM.
Subsequently, [3] extended SMART to defend against verifier imper-
sonation and denial-of-service (DoS) attacks. The resultant design
(SMART+) additionally requires prover to have a Reliable Read-Only
Clock (RROC), which is needed to perform verifier authentication
and prevent replay, reorder and delay attacks. To ensure reliability,
RROC cannot be modified by non-physical (software) means. Upon
receiving a verifier request, ROM-resident attestation code checks
the request’s freshness using RROC, authenticates it, and only then
proceeds to perform attestation.
TrustLite [19] security architecture also supports RA for low-end
devices. It differs from SMART in two ways: First, interrupts are
allowed and are handled securely by the CPU Exception Engine.
Second, static access control rules can be programmed in software
using an Execution-Aware Memory Protection Unit (EA-MPU). A
follow-on effort, called TyTAN [2], adopts a similar approach while
providing additional real-time guarantees and dynamic configu-
ration for safety- and security-critical applications. As mentioned
earlier, both TrustLite [19] and TyTAN [2] support interrupts. While
this allows for time-critical processes to take priority over others
and to preserve Prv’s functionality, attestation results may not be
consistent. Memory can change once attestation is interrupted and
the final attestation result might correspond to a state of Prv’s
memory that never existed.
In summary, RA architectures that disable interrupts, or ensure
atomic execution through other means, automatically (though only
coincidentally) ensure temporal consistency on single-processor
devices. In multi-processor settings, atomic execution is insufficient.
Whereas, RA architectures that allow interrupts must ensure tem-
poral consistency (e.g., via mechanisms described in this paper);
otherwise nonsensical or incorrect results might be produced.
[16] SANS Institute. 2014.
Securing the Internet of Things Survey.
https://www.sans.org/reading-room/whitepapers/analyst/
(2014).
securing-internet-things-survey-34785
[17] ISO/IEC. 2011. Information technology – Security techniques – Message Authenti-
cation Codes (MACs) – Part 1: Mechanisms using a block cipher. Standard. ISO.
[18] Gerwin Klein, Kevin Elphinstone, Gernot Heiser, et al. 2009. seL4: Formal verifi-
cation of an OS kernel. In Proceedings of the ACM SIGOPS 22nd symposium on
Operating systems principles.
[19] Patrick Koeberl, Steffen Schulz, Ahmad-Reza Sadeghi, and Vijay Varadharajan.
2014. TrustLite: A security architecture for tiny embedded devices. In ACM
European Conference on Computer Systems (EuroSys).
[20] Ralph Langner. 2013. To Kill a Centrifuge a Technical Analysis of What Stuxnet’s
Creators Tried to Achieve. (2013).
[21] Yanlin Li, Jonathan M. McCune, and Adrian Perrig. 2011. VIPER: Verifying the
Integrity of PERipherals’ Firmware. In Proceedings of the 18th ACM Conference
on Computer and Communications Security (CCS).
[22] Richard J. Lipton, Rafail Ostrovsky, and Vassilis Zikas. 2016. Provably Secure
Virus Detection: Using The Observer Effect Against Malware. In 43rd International
Colloquium on Automata, Languages, and Programming, ICALP.
(2017). https://www.arm.com/products/
security-on-arm/trustzone
[23] ARM Ltd. 2017. ARM TrustZone.
[24] LWN.net. 2018. DR rootkit released under the GPL. (2018). https://lwn.net/
Articles/297775/
[25] Wired Magazine. 2013. Trojan Turns Your PC Into Bitcoin Mining Slave. (2013).
https://www.wired.com/2013/04/bitcoin-trojan
[26] National ICT Australia and other contributors. 2014. seL4 Libraries.
(2014).
[27] National ICT Australia and other contributors. 2014. The seL4 Repository. (2014).
https://github.com/seL4/seL4_libs
https://github.com/seL4/seL4
[28] Daniele Perito and Gene Tsudik. 2010. Secure Code Update for Embedded Devices
via Proofs of Secure Erasure.. In ESORICS.
[29] Ryan Roemer, Erik Buchanan, Hovav Shacham, and Stefan Savage. 2012. Return-
Oriented Programming: Systems, Languages, and Applications. ACM Trans. Inf.
Syst. Secur. (2012).
[30] Ethan M Rudd, Andras Rozsa, Manuel Günther, and Terrance E Boult. 2017. A
Survey of Stealth Malware Attacks, Mitigation Measures, and Steps Toward
Autonomous Open World Solutions. IEEE Communications Surveys & Tutorials
(2017).
[31] MJ Saarinen and JP Aumasson. 2015. The BLAKE2 cryptographic hash and message
authentication code (MAC), RFC 7693. Technical Report. IETF.
[32] Dries Schellekens, Brecht Wyseur, and Bart Preneel. 2008. Remote attestation on
legacy operating systems with trusted platform modules. Science of Computer
Programming (2008).
[33] Arvind Seshadri, Mark Luk, Adrian Perrig, Leendert van Doorn, and Pradeep
Khosla. 2006. SCUBA: Secure Code Update By Attestation in Sensor Networks.
In ACM Workshop on Wireless Security (WiSe).
[34] Arvind Seshadri, Mark Luk, Elaine Shi, Adrian Perrig, Leendert van Doorn,
and Pradeep Khosla. 2005. Pioneer: Verifying Code Integrity and Enforcing
Untampered Code Execution on Legacy Systems. In Proceedings of the Twentieth
ACM Symposium on Operating Systems Principles.
[35] Arvind Seshadri, Adrian Perrig, Leendert Van Doorn, and Pradeep Khosla. 2004.
SWATT: Software-based attestation for embedded devices. In IEEE Symposium
on Research in Security and Privacy (S&P).
[36] IEEE Spectrum. 2013. The Real Story of Stuxnet. (2013). http://spectrum.ieee.
org/telecom/security/the-real-story-of-stuxnet
[37] Secure Hash Standard. 2002. FIPS PUB 180-2. (2002).
[38] Frederic Stumpf, Omid Tafreschi, Patrick Röder, and Claudia Eckert. 2006. A
Robust Integrity Reporting Protocol for Remote Attestation. In Workshop on
Advances in Trusted Computing (WATC).
[39] Symantec. 2015. GreenDispencer: Self-deleting Malware. (2015). https://www.
symantec.com/security_response/writeup.jsp?docid=2015-092513-0300-99
[40] Wei Yan, Zheng Zhang, and Nirwan Ansari. 2008. Revealing packed malware.
seCurity & PrivaCy (2008).
7 CONCLUSIONS
In this paper we explore the discrepancy between (implicit) theoret-
ical assumptions and implementations of cryptographic integrity-
ensuring functions, focusing on the context of Remote Attestation
(RA). We show that, in practice, inputs to such functions can change
during computation, and that the vulnerability window can be
large, since cryptographic computations can be time-consuming.
We propose multiple practical mechanisms to ensure consistency of
integrity-ensuring functions. They offer tradeoffs between consis-
tency guarantees, performance overhead, and impact on memory
availability. We implement proposed mechanisms on two commod-
ity platforms in the context of a hybrid RA architecture for em-
bedded systems. Results show that locking/unlocking of memory
incurs negligible overhead over computing cryptographic integrity-
ensuring functions, e.g., MACs. We demonstrate that ensuring tem-
poral consistency can be achieved with less than 10% overhead
on both platforms, while providing much better availability for
time-critical applications. We believe that this paper highlights im-