At each iteration i, each committee picks a leader randomly using the epoch randomness. The leader
is responsible for driving the consensus protocol. First, the leader gathers all the transactions it
has received (from users or other committees) in a block Bi. The leader gossips the block using
IDA-gossip and creates the block header Hi that contains the iteration number as well as the root
of the Merkle tree from IDA-Gossip. Next, the leader initiates consensus protocol on Hi. Before
describing the consensus protocol, we remark that all the messages that the leader or other nodes
send during the consensus is signed by their public key and thus the sender of the message and its
integrity is veriﬁed.
Our consensus protocol consists of four synchronous rounds. First, the leader gossips a messages
containing Hi and a tag in the header of the message that the leader sets it to propose. Second, all
other nodes in the network echo the headers they received from the leader, i.e., they gossip Hi again
with the tag echo. This step ensures that all the honest nodes will see all versions of the header that
other honest nodes received in the ﬁrst round. Thus, if the leader equivocates and gossips more
than one version of the message, it will be noticed by the honest nodes. In the third round, if an
honest node receives more than one version of the header for iteration i, it knows that the leader is
corrupt and will gossip H (cid:48)
contains a null Merkle root and iteration
number i.
with the tag pending, where H (cid:48)
Finally, in the last round, if an honest node receives m f + 1 echoes of the same and the only
header Hi for iteration i, it accepts Hi and gossips Hi with the tag accept along with all the m f + 1
echoes of Hi. The m f + 1 echoes serve as the proof of why the node accepts Hi. Clearly, it is
impossible for any node to create this proof if the leader has not gossiped Hi to at least one honest
node. If an honest node accepts a header, then all other honest nodes either accept the same header
or they reject any header from the leader. In the above scenario, if the leader is corrupt, then some
honest nodes reject the header and tag it as pending.
Deﬁnition 1 (Pending Block). A block is pending at iteration i if it is proposed by a leader at some
iteration j before i, while there are honest nodes that have not accepted the block header at iteration
i.
i
i
Since less than m/2 of the committee members are corrupt, the leader will be corrupt with a
probability less than 1/2. Thus, to ensure a block header gets accepted, two leaders have to propose
it in expectation. One way to deal with this issue is to ask the leader of the next iteration to propose
the same block again if it is still pending. This, however, reduces the throughput by roughly half.
Improving Performance via Pipelining
4.3.4
RapidChain allows a new leader to propose a new block while re-proposing the headers of the pending
blocks. This allows RapidChain to pipeline its consensus iterations, maximizing its throughput.
Since the consensus is happening during multiple iterations, we let nodes count votes for the header
proposed in each iteration to determine if a block is pending or accepted. The votes can be permanent
or temporary relative to the current iteration. If a node gossips an accept for header Hj at any
iteration i ≥ j, its permanent vote for the header of iteration j is Hj. If the node sends two accepts
for two diﬀerent headers Hj and H (cid:48)
If a node sends an echo for Hj at any iteration i ≥ j, its temporary vote is Hj in iteration i.
To accept a header, a node requires at least m f + 1 votes (permanent or temporary for the current
iteration). If a node accepts a header, it will not gossip more headers since all nodes already know its
vote. This will protect honest nodes against denial-of-service attacks by corrupt leaders attempting
to force them echo a large number of non-pending blocks.
, then the honest nodes will ignore the vote.
j
15
Figure 2: UTXO states before and after a transaction
It is left to describe how the leader proposes a header for a pending block even if some honest
nodes might have already accepted a value for it. A new proposal is safe if it does not conﬂict with
any accepted value with a correct proof, if there is any. Thus, at iteration i, for all pending block
headers, the leader proposes a safe value. For a new block, any value is considered safe while for
a pending block of previous iterations, the value is safe if and only if it has a correct proof of at
least m f + 1 votes (permanent or temporary from iteration i − 1). If there is no value with enough
votes, then any value is safe. In Section 6.3, we prove that our consensus protocol achieves safety
and liveness in a committee with honest majority.
4.4 Cross-Shard Transactions
In this section, we describe a mechanism by which RapidChain reduces the communication, compu-
tation, and storage requirement of each node by dividing the blockchain into partitions each stored
by one of the committees. While sharding the blockchain can reduce the storage overhead of the
blockchain, it makes the veriﬁcation of transactions challenging, because the inputs and outputs of
each transaction might reside in multiple committees.
Similar to Bitcoin, each transaction in RapidChain has a unique identity, a list of inputs (depicted
by their identities), and a list of outputs that is shown by the transaction ID and their row number
(see Figure 2). All inputs to a transaction must be unspent transaction outputs (UTXOs) which are
unused coins from previous transactions. The outputs of the transaction are new coins generated
for the recipients of the exchanged money. After receiving a transaction, the nodes verify if a
transaction is valid by checking (1) if the input is unspent; and (2) if the sum of outputs is less than
the sum of the inputs. The nodes add the valid transaction to the next block they are accepting.
RapidChain partitions the transactions based on their transaction ID among the committees which
will be responsible for storing the transaction outputs in their UTXO databases. Each committee
only stores transactions that have the committee ID as their preﬁx in their IDs.
.
(N)
in
Let tx denote the transaction sent by the user. In the veriﬁcation process, multiple committees
may be involved to ensure all the input UTXOs to tx are valid. We refer to the committee that
stores tx and its possible UTXOs as the output committee, and denote it by Cout. We refer to
the committees that store the input UTXOs to tx as the input committees, and denoted them by
(1)
in , . . . , C
C
To verify the input UTXOs, OmniLedger [42] proposes that the user obtain a proof-of-acceptance
from every input committee and submit the proof to the output committee for validation. If each
input committee commits to tx (and marks the corresponding input UTXO as "spent") indepen-
dently from other input committees, then tx may be committed partially, i.e., some of its inputs
UTXOs are spent while the others are not. To avoid this situation and ensure transaction atomicity,
OmniLedger takes a two-phase approach, where each input committee ﬁrst locks the corresponding
input UTXO(s) and issues a proof-of-acceptance, if the UTXO is valid. The user collects responses
from all input committees and issues an “unlock to commit”.
While this allows the output committee to verify tx independently, the transaction has to be
16
UTXO StateTX1:row2TX5:row6TX7:row3TX8:row2UTXO StateTX1:row2TX7:row3TX9:row1   TX9:row2Transaction (ID=TX9)Input  SignatureTX5:row6           67a8b7635789 TX8:row2           8774bb84274cOutputTX9:row1   TX9:row2gossiped to the entire network and one proof needs to be generated for every transaction, incurring
a large communication overhead. Another drawback of this scheme is that it depends on the user
to retrieve the proof which puts extra burden on typically lightweight user nodes.
In RapidChain, the user does not attach any proof to tx. Instead, we let the user communicate
with any committee who routes tx to the output committee via the inter-committee routing protocol.
Without loss of generality, we assume tx has two inputs I1, I2 and one output O. If I1, I2 belong to
diﬀerent committees other than Cout, then the leader of Cout, creates three new transactions: For
i ∈ {1, 2}, txi with input Ii and output I (cid:48)
belongs to
and I (cid:48)
Cout. tx3 with inputs I (cid:48)
via the inter-committee
1
routing protocol, and Ci
to Cout. Finally, Cout
adds txi to its ledger. If txi is successful, Ci
in
in
adds tx3 to its ledger.
Batching Veriﬁcation Requests. At each round, the output committee combines the transactions
that use UTXOs belonging to the same input committee into batches and sends a single UTXO
request to the input committee. The input committee checks the validity of each UTXO and sends
the result of the batch to the output committee. Since multiple UTXO requests are batched into
the same request, a result can be generated for multiple requests at the input committee.
i | = |Ii| (i.e., the same amounts) and I (cid:48)
and output O. The leader sends txi to Ci
in
sends I (cid:48)
i
, where |I (cid:48)
i
2
i
Inter-Committee Routing
4.5
RapidChain requires a routing scheme that enables the users and committee leaders to quickly
locate to which committees they should send their transactions.
Strawman Scheme. One approach is to require every node to store the network information of
all committee members in the network. This allows every node to quickly locate the IP addresses
of members of any committee in constant time. Then, nodes can create a connection to members
of the target committee and gossip among them. However, this requires every node to store the
network information about all committee members that compromise privacy and simplify the denial
of service attack. Moreover, in practice each node should connect to large number of nodes during
his life time which cannot scale for thousands of nodes in the network.
A diﬀerent solution is to have a dedicated committee (e.g., the reference committee) to be
responsible for transaction routing. Every user will obtain network information from reference
committee. This approach oﬀers eﬃcient routing, which takes only one communication round.
However, reference committee becomes a centralized hub of the network that needs to handle a
large amount of communication and thus will be a likely bottleneck.
Routing Overlay Network. To construct the routing protocol in RapidChain, we use ideas from
the design of the routing algorithm in Kademlia [48].
In Kademlia, each node in the system is
assigned an identiﬁer and there is a metric of distance between identiﬁers (for example, the Hamming
distance of the identiﬁers). A node stores information about all nodes which are within a logarithmic
distance. When a node wants to send a message to another node in the system it identiﬁes the node
among its neighbors (which it stores locally) that is closest to the destination node’s Kademlia ID
(or KID) and it asks it to run recursively the discovery mechanism. This enables node discovery
and message routing in log n steps. We refer the reader to Section 2 of [48] for more details about
the Kademlia routing protocol.
We employ the Kademlia routing mechanism in RapidChain at the level of committee-to-
committee communication. Speciﬁcally, each RapidChain committee maintains a routing table
of log n records which point to log n diﬀerent committees which are distance 2i for 0 ≤ i ≤ log n − 1
17
Figure 3: (Left) Each committee in RapidChain maintains a routing table containing log n other committees.
(Right) Committee C0 wants to locate committee C7 (via C4 and C6) responsible for transactions with preﬁx
0x111.
away (see Figure 3 for an example). More speciﬁcally, each node stores information about all mem-
bers of its committee as well as about log log(n) nodes in each of the log n closest committees to its
own committee. Each committee-to-committee message is implemented by having all nodes in the
sender committee send the message to all nodes they know in the receiver committee. Each node
who receives a message invokes the IDA-gossip protocol to send the message to all other members
of its committee.
When a user wants to submit a transaction, it sends the transaction to any arbitrary RapidChain
node who will forward it to the corresponding committee via the Kademlia routing mechanism.
We present in Figure 3 an example of the routing protocol initiated by committee C0 to request
information for committee C7.
4.6 Committee Reconﬁguration
Protocol 1 presents our reconﬁguration protocol. In the following, we describe the core techniques
used in this protocol.
4.6.1 Oﬄine PoW
RapidChain relies on PoW only to protect against Sybil attacks by requiring every node who wants
to join or stay in the protocol to solve a PoW puzzle. In each epoch, a fresh puzzle is generated
based on the epoch randomness so that the adversary cannot precompute the solutions ahead of the
time to compromise the committees. In RapidChain, all nodes solve a PoW oﬄine without making
the protocol stop and wait for the solution. Thus, the expensive PoW calculations are performed
oﬀ the critical latency path.
Since the adversary is bounded to a 1/3 fraction of the total computation power during each
epoch, the fraction of total adversarial nodes is strictly less than n/3. In RapidChain, the reference
committee (CR) is responsible to check the PoW solutions of all nodes. At the start of each epoch,
CR agrees on a reference block consisting of the list of all active nodes for that epoch as well as their
assigned committees. CR also informs other committees by sending the reference block to all other
committees.
4.6.2 Epoch Randomness Generation
In each epoch, the members of the reference committee run a distributed random generation (DRG)
protocol to agree on an unbiased random value. CR includes the randomness in the reference block
18
202122202122C3C4C5C6C7C2C1C00x0000x0010x0100x0110x1000x1010x1100x1112122C3C4C5C6C7C2C1C00x0000x0010x0100x0110x1000x1010x1100x11120Protocol 1 Epoch Reconﬁguration
1. Random generation during epoch i − 1
epoch.
(a) The reference committee (CR) runs the DRG protocol to generate a random string ri for the next
(b) Members of CR reveal ri at the end of epoch i − 1.
2. Join during epoch i
(a) Invariant: All committees at the start of round i receive the random string ri from CR.
(b) New nodes locally choose a public key PK and contact a random committee C to request a PoW puzzle.
(c) C sends the ri for the current epoch along with a timestamp and 16 random nodes in CR to P.
(d) All the nodes who wish to participate in the next epoch ﬁnd x such that O = H(timestamp||PK||ri||x) ≤
2γ−d and sends x to Cr .
(e) Cr conﬁrms the solution if it received it before the end of the epoch i.
3. Cuckoo exchange at round i + 1
(a) Invariant: All members of CR participate in the DRG protocol during epoch i and have the value ri +1.
(b) Invariant: During the epoch i, all members of CR receive all the conﬁrmed transactions for the active
nodes of round i + 1.
(c) Members of Cr will create the list of all active nodes for round i + 1 and also create A, the set of active
committees, and I, the set of inactive committees.
(d) CR uses ri +1 to assign a committees in A for each new node.
(e) For each committee C, CR evicts a constant number of nodes in C uniformly at random using ri +1 as
the seed.
(f) For all the evicted nodes, CR chooses a committee uniformly at random using ri +1 as the seed and
assigns the node to the committee.
(g) CR adds ri and the new list of all the members and their committees and add it as the ﬁrst block of
the epoch to the CR’s chain.
(h) CR gossips the ﬁrst block to all the committees in the system using the inter-committee routing
protocol.
so other committees can randomize their epochs. RapidChain uses a well-known technique based
on the veriﬁable secret sharing (VSS) of Feldman [30] to generate unbiased randomness within the
reference committee.
by calculatingm
Let Fp denote a ﬁnite ﬁeld of prime order p, m denote the size of the reference committee, and r
denote the randomness for the current epoch to be generated by the protocol. For all i ∈ [m], node
i chooses ρi ∈ Fp uniformly at random and VSS-shares it to all other node. Next, for all j ∈ [m],