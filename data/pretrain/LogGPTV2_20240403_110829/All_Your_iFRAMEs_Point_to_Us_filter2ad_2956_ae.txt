to “downloader” binaries that fetch, in some cases, up
to 60 binaries over HTTP. We also observe a signiﬁcant
percentage of connection attempts to typical IRC ports,
accounting for more than 50% of all non-HTTP connec-
tions. As a number of earlier studies have already shown
(e.g., [, 1, , 1, 
are most likely for unwillingly (to the owner) adding the
compromised machine to an IRC botnet, conﬁrming the
earlier conjecture by Provos et al. [0] regarding the con-
nection between web malware and botnets. More de-
tailed examples of malware’s behavior can be found in
, 1]), the IRC connection attempts
7.1 Anti-virus engine detection rates
As we discussed earlier, web based malware uses a pull-
based delivery mechanism in which a victim is required
to visit the malware hosting server or any URL linking to
it in order to download the malware. This behavior puts
forward a number of challenges to defense mechanisms
(e.g., malware signature generation schemes) mainly due
to the inadequate coverage of the malware collection sys-
tem. For example, unlike active scanning malware which
uses a push-based delivery mechanism (and so sufﬁcient
placement of honeypot sensors can provide good cover-
age), the web is signiﬁcantly more sparse and, therefore,
more difﬁcult to cover.
In what follows, we evaluate the potential implications
of the web malware delivery mechanism by measuring
the detection rates of several well known anti-virus en-
gines. Speciﬁcally, we evaluate the detection rate of each
anti-virus engine against the set of suspected malware
samples collected by our infrastructure. Since we can not
rely on anti-virus engines, we developed a heuristic to
detect these suspected binaries before subjecting them to
the anti-virus scanners. For each inspected URL via our
in-depth veriﬁcation system we test whether visiting the
URL caused the creation of at least one new process on
the virtual machine. For the URLs that satisfy this condi-
tion, we simply extract any binary download(s) from the
recorded HTTP response and “ﬂag” them as suspicious.
We applied the above methodology to identify suspi-
cious binaries on a daily basis over a one month period
of April, 007. We subject each binary for each of the
anti-virus scanners using the latest virus deﬁnitions on
that day. Then, for an anti-virus engine, the detection
rate is simply the number of detected (ﬂagged) samples
divided by the total number of suspicious malware in-
stances inspected on that day. Figure 1 illustrates the
individual detection rates of each of the anti-virus en-
gines. The graph reveals that the detection capability of
1  
17th USENIX Security Symposium 
USENIX Association


the anti-virus engines is lacking, with an average detec-
tion rate of 70% for the best engine. These results are
disturbing as they show that even the best anti-virus en-
gines in the market (armed with their latest deﬁnitions)
fail to cover a signiﬁcant fraction of web malware.
AV I
AV II
AV III
 100
 80
 60
 40
 20
)
%
(
e
t
a
R
n
o
i
t
c
e
t
e
D
 0
 0
 5
 10
 15
 20
 25
 30
 35
 40
Days since April, 1st
Figure 1: Detection rates of  anti-virus engines.
False Positives. Notice that the above strategy may
falsely classify benign binaries as malicious. To eval-
uate the false positives, we use the following heuristic:
we optimistically assume that all suspicious binaries will
eventually be discovered by the anti-virus vendors. Us-
ing the set of suspicious binaries collected over a month
historic period, we re-scan all undetected binaries two
months later (in July, 007) using the latest virus deﬁni-
tions. Then, all undetected binaries from the rescanning
step are considered false positives. Overall, our results
show that the earlier analysis is fairly accurate with false
positive rates of less than 10%. We further investigated a
number of binaries identiﬁed as false positives and found
that a number of popular installers exhibit a behavior
similar to that of drive-by downloads, where the installer
process ﬁrst runs and then downloads the associated soft-
ware package. To minimize the impact of false positives,
we created a white-list of all known benign downloads,
and all binaries in the white-list are exempted from the
analysis in this paper.
Of course, we are being overly conservative here as
our heuristic does not account for binaries that are never
detected by any anti-virus engine. However, for our
goals, this method produces an upper bound for the re-
sulting false positives. As an additional benchmark we
asked for direct feedback from anti-virus vendors about
the accuracy of the undetected binaries that we (now)
share with them. On average, they reported about 6%
false positives in the shared binaries, which is within the
bounds of our prediction.
8 Discussion
Undoubtedly, the level of malfeasance on the Internet is a
cause for concern. That said, while our work to date has
shown that the prevalence of web-malware is indeed a
serious threat, the analysis herein says nothing about the
number of visitors that become infected as a result of vis-
iting a malicious page. In particular, we note that since
our goal is to survey the landscape, our infrastructure is
intentionally conﬁgured to be vulnerable to a wide range
of attacks; hopefully, savvy computer users who dili-
gently apply software updates would be far less vulnera-
ble to infection. To be clear, while our analysis unequiv-
ocally shows that millions of users are exposed to ma-
licious content every day, without a wide-scale browser
vulnerability study, the actual number of compromises
remains unknown. Nonetheless, we believe the perva-
sive nature of the results in this study elucidates the state
of the malware problem today, and hopefully, serves to
educate both users, web masters and other researchers
about the security challenges ahead.
Lastly, we note that several outlets exists for taking
advantage of the results of our infrastructure. For in-
stance, the data that Google uses to ﬂag search results
is freely available through the Safe Browsing API [], as
well as via the Safe Browsing diagnostic page []. We
hope these services prove to be of beneﬁt to the greater
community at large.
9 Related Work
]. Although, honeypots have traditionally been
Virtual machines have been used as honeypots for de-
tecting unknown attacks by several researchers [, 1,
17, 
, 
used mostly for detecting attacks against servers, the
same principles also apply to client honeypots (e.g., an
instrumented browser running on a virtual machine). For
example, Moshchuk et al. used client-side techniques
to study spyware on the web (by crawling 1 million
URLs in May 00 [17]). Their primary focus was not on
detecting drive-by downloads, but in ﬁnding links to ex-
ecutables labeled spyware by an adware scanner. Addi-
tionally, they sampled 45, 000 URLs for drive-by down-
loads and showed a decrease over time. However, the
fundamental limitation of analyzing the malicious nature
of URLs discovered by “spidering” is that a crawl can
only follow content links, whereas the malicious nature
USENIX Association  
17th USENIX Security Symposium 
1
of a page is often determined by the web hosting infras-
tructure. As such, while the study of Moshchuk et al.
provides valuable insights, a truly comprehensive analy-
sis of this problem requires a much more in-depth crawl
of the web. As we were able to analyze many billions of
URLs , we believe our ﬁndings are more representative
of the state of the overall problem.
]. Their approach is capable of de-
More closely related is the work of Provos et al. [0]
] which raised awareness of the
and Seifert et al. [
threat posed by drive-by downloads. These works are
aimed at explaining how different web page compo-
nents are used to exploit web browsers, and provides an
overview of the different exploitation techniques in use
today. Wang et al. proposed an approach for detecting
exploits against Windows XP when visiting webpages in
Internet Explorer [
tecting zero-day exploits against Windows and can de-
termine which vulnerability is being exploited by expos-
ing Windows systems with different patch levels to dan-
gerous URLs. Their results, on roughly 17, 000 URLs,
showed that about 200 of these were dangerous to users.
This paper differs from all of these works in that it of-
fers a far more comprehensive analysis of the different
aspects of the problem posed by web-based malware, in-
cluding an examination of its prevalence, the structure of
the distribution networks, and the major driving forces.
Lastly, malware detection via dynamic tainting analy-
sis may provide deeper insight into the mechanisms by
which malware installs itself and how it operates [10, 1,
7]. In this work, we are more interested in structural
properties of the distribution sites themselves, and how
malware behaves once it has been implanted. Therefore,
we do not employ tainting because of its computational
expense, and instead, simply collect changes made by the
malware that do not require having the ability to trace the
information ﬂow in detail.
10 Conclusion
The fact that malicious URLs that initiate drive-by down-
loads are spread far and wide raises concerns regarding
the safety of browsing the Web. However, to date, little
is known about the speciﬁcs of this increasingly common
malware distribution technique. In this work, we attempt
to ﬁll in the gaps about this growing phenomenon by pro-
viding a comprehensive look at the problem from several
perspectives. Our study uses a large scale data collection
infrastructure that continuously detects and monitors the
behavior of websites that perpetrate drive-by downloads.
Our in-depth analysis of over 66 million URLs (spanning
a 10 month period) reveals that the scope of the problem
is signiﬁcant. For instance, we ﬁnd that 1.3% of the in-
coming search queries to Google’s search engine return
at least one link to a malicious site.
Moreover, our analysis reveals several forms of rela-
tions between some distribution sites and networks. A
more troubling concern is the extent to which users may
be lured into the malware distribution networks by con-
tent served through online Ads. For the most part, the
syndication relations that implicitly exist in advertising
networks are being abused to deliver malware through
Ads. Lastly, we show that merely avoiding the dark
corners of the Internet does not limit exposure to mal-
ware. Unfortunately, we also ﬁnd that even state-of-the-
art anti-virus engines are lacking in their ability to protect
against drive-by downloads. While this is to be expected,
it does call for more elaborate defense mechanisms to
curtail this rapidly increasing threat.
Acknowledgments
We would like to thank Oliver Fisher, Dean Mc-
Namee, Mark Palatucci and Ke Wang for their help with
Google’s malware detection infrastructure. This work
was funded in part by NSF grants CNS-0
0
CNS-0
.
711 and
References
[1] The open directory project. See http://www.news.
com/2100-1023-877568.html.
[] Safe Browsing API, June 007. See
http://code.
google.com/apis/safebrowsing/.
[] Safe Browsing diagnostic page, May 00.
See
http://www.google.com/safebrowsing/
diagnostic?site=yoursite.com.
[] A NAGNOSTAKIS, K. G., SIDIROGLOU, S., AKRITIDIS,
P., XINIDIS, K., MARKATOS, E., AND KEROMYTIS,
A. D. Detecting Targeted Attacks Using Shadow Hon-
eypots.
[] A NDERSON, D. S., FLEIZACH, C., SAVAGE, S., AND
VOELKER, G. M. Spamscatter: Characterizing Inter-
net Scam Hosting Infrastructure.
In Proceedings of the
USENIX Security Symposium (August 007).
[] B ARFORD, P., AND YAGNESWARAN, V. An Inside Look
at Botnets. Advances in Information Security. Springer,
007.
[7] BEM, J., HARIK, G., LEVENBERG, J., SHAZEER, N.,
AND TONG, S. Large scale machine learning and meth-
ods. US Patent: 7
17.
[] C OOKE, E., JAHANIAN, F., AND MCPHERSON, D. The
Zombie Roundup: Understanding, Detecting, and Dis-
turbing Botnets. In Proceedings of the ﬁrst Workshop on
1  
17th USENIX Security Symposium 
USENIX Association


Steps to Reducing Unwanted Trafﬁc on the Internet (July
00).
[] D EAN, J., AND GHEMAWAT, S. Mapreduce: Simpliﬁed
data processing on large clusters. In Proceedings of the
Sixth Symposium on Operating System Design and Imple-
mentation (Dec 00), pp. 17–10.
[10] EGELE, M., KRUEGEL, C., KIRDA, E., YIN, H., AND
SONG, D. Dynamic Spyware Analysis. In Proceedings of
the USENIX Annual Technical Conference (June 007).
[11] FRANKLIN, J., PAXSON, V., PERRIG, A., AND SAVAGE,
S. An Inquiry into the Nature and Causes of the Wealth of
Internet Miscreants. In Proceedings of the ACM Confer-
ence on Computer and Communications Security (CCS)
(October 007).
[1] G U, G., PORRAS, P., YEGNESWARAN, V., FONG, M.,
AND LEE, W. BotHunter: Detecting Malware Infection
through IDS-driven Dialog Correlation. In Proceedings of
the 16th USENIX Security Symposium (007), pp. 17–
1
.
[1] M ODADUGU,
N.
Web
Server
and Malware,
ware
007.
http://googleonlinesecurity.
blogspot.com/2007/06/
web-server-software-and-malware.html.
June
Soft-
See
[1] M OORE, D., VOELKER, G. M., AND SAVAGE, S. Infer-
ring Internet Denial of Service Activity. In Proceedings
of 10th USENIX Security Symposium (Aug. 001).
[1] M OSER, A., KRUEGEL, C., AND KIRDA, E. Exploring
Multiple Execution Paths for Malware Analysis. In Pro-
ceedings of the 2007 IEEE Symposium on Security and
Privacy (May 007).
[1] R AJAB, M. A., ZARFOSS, J., MONROSE, F., AND
TERZIS, A. A Multifaceted Approach to Understand-
ing the Botnet Phenomenon.
In Proceedings of ACM
SIGCOMM/USENIX Internet Measurement Conference
(IMC) (Oct., 00), pp. 1–
.
[
] R AMACHANDRAN, A., FEAMSTER, N., AND DAGON,
Revealing Botnet Membership using DNSBL
D.
Counter-Intelligence.
In Proceedings of the 2nd Work-
shop on Steps to Reducing Unwanted Trafﬁc on the Inter-
net (SRUTI) (July 00).
[
] The Route Views Project.
http://www.antc.
uoregon.edu/route-views/.
] S EIFERT, C., STEENSON, R., HOLZ, T., BING, Y., AND
[
DAVIS, M. A. Know Your Enemy: Malicious Web
Servers. http://www.honeynet.org/papers/
mws/, August 007.
] W ANG, Y.-M., BECK, D., JIANG, X., ROUSSEV, R.,
[
VERBOWSKI, C., CHEN, S., AND KING, S. Automated
web patrol with strider honeymonkeys.
In Proceedings
of Network and Distributed Systems Security Symposium
–
(00), pp. 
.
[
] W ANG, Y.-M., NIU, Y., CHEN, H., BECK, D.,
JIANG, X., ROUSSEV, R., VERBOWSKI, C., CHEN,
S., AND KING, S.
Strider honeymonkeys: Ac-
tive, client-side honeypots for ﬁnding malicious web-
sites. See http://research.microsoft.com/
users/shuochen/HM.PDF.
[7] Y IN, H., SONG, D., EGELE, M., KRUEGEL, C., AND
KIRDA, E. Panorama: Capturing System-wide Informa-
tion Flow for Malware Detection and Analysis. In Pro-
ceedings of the 14th ACM Conference of Computer and
Communication Security (October 007).
[1] M OSHCHUK, A., BRAGIN, T., DEVILLE, D., GRIBBLE,
S., AND LEVY, H. SpyProxy: Execution-based Detection
of Malicious Web Content.
Notes
1Some compromised web servers also trigger dialog windows ask-
ing users to manually download and run malware. However, this anal-
ysis considers only malware installs that require no user interaction.
 This mapping is readily available at Google.
 We consider a version as outdated if it is older than the latest corre-
sponding version released by January, 007 (the start date f or our data
collection).
 We restrict our analysis to Windows executables identiﬁed by
searching for PE headers in each payload.
[17] MOSHCHUK, A., BRAGIN, T., GRIBBLE, S., AND
LEVY, H. A crawler-based study of spyware in the web.
In Proceedings of Network and Distributed Systems Secu-
rity Symposium (00).
[1] P OLYCHRONAKIS, M., MAVROMMATIS, P., AND
PROVOS, N. Ghost Turns Zombie: Exploring the Life
Cycle of Web-based Malware. In Proceedings of the 1st
USENIX Workshop on Large-Scale Exploits and Emer-
gent Threats (LEET) (April 00).
[1] P ROJECT, H., AND ALLIANCE, R. Know your enemy:
http://www.
Tracking Botnets, March 00. See
honeynet.org/papers/bots/.
[0] P ROVOS, N., MCNAMEE, D., MAVROMMATIS, P.,
WANG, K., AND MODADUGU, N. The Ghost in the
Browser: Analysis of Web-based Malware. In Proceed-
ings of the ﬁrst USENIX workshop on hot topics in Bot-
nets (HotBots’07). (April 007).
USENIX Association  
17th USENIX Security Symposium 
1