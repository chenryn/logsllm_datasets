ofthebottlnecks.Intheevaluation,weconductexperimentsbyapplyingvarious
techniques to perform analysis at a coarser granular level of a process. The
techniques are compared with the following questions:
– Howmuchisthemanipulationofaneventlogrequiredtoanalyzetheprocess
performance at a coarser granular level?
Stage-Based Process Performance Analysis 359
– How much domain knowledge is required for the abstraction of an event log?
– How reliable is the resulting performance metrics?
To the best of our knowledge, the stage performance evolution proposed
is the only visualization that supports our goal for such analysis. Therefore,
we conduct the experiments by using various event abstraction techniques of
which our visualization is applied on top. Table2 lists the implementations of
thetechniquesevaluatedwiththeirabbreviationsforconvenience.Exceptforthe
proposed approach2, other techniques are available in ProM [24]. This section
presents the evaluation from the aspects of the ease of use and the reliability by
analyzing two event logs, PermitLog [23] and BPIC15 1 [22].
Fig.7.Aschematicoverviewofanalyzingperformanceatacoarsergranularlevelusing
different event abstraction techniques.
Table 2. Overview: Techniques used for Experiments.
Techniques Abbreviation
- Proposed Approach PA
- Abstract Event Labels using linear chaining [18,19] CRF
Conditional Random Field (GRMM)
- Log Abstraction - Abstract Log based on Patterns [16] PNP
- Session-based Log Abstraction [12] SESS
- Stage Mining (SM) [15] SM
2 The implementation and the datasets used for experiments are in https://github.
com/chiaoyunli/spm.
360 C.-Y. Li et al.
4.1 Evaluation on Ease of Use
The ease of use of a tool is evaluated from two aspects, the amount of the
domain knowledge required and the necessity of the manipulation of an event
log.Theinputsandoutputsoftheeventabstractiontechniquesvary.Therefore,
foreachtechnique,wemanipulatetheeventlogsforperformanceanalysisatthe
abstracted level if necessary.
External Effort Required. Figure7presentstheoverviewofthestepstoana-
lyze the performance at the coarser granularity level using the techniques. The
dashed line indicates the data flow and the solid line refers to the control flow.
Each box represents a step and the steps that require human intervention are
emphasized with the green outline of the steps. We further group the steps and
annotatethegroupswiththecorrespondingtechniques.Sincetheexistingevent
abstractiontechniquesarenotspecificallydesignedforperformanceanalysis,we
manipulate the output of the event abstraction techniques to compute the per-
formancemetrics(Transform step).Iftheoutputdoesnotcontaintheattribute
to indicate the instance of a concept at a coarser level of a process, we consider
the continuous events with the same targeting instance at a coarser granularity
level as an instance, i.e., the duration between the first and the last event of
such instance corresponds to the cycle time in our approach. For other metrics,
we apply the same definition in our approach, e.g., flow time of an instance of a
higher level concept is the duration from the first to the last event of which the
activities are contained in the high-level concept identified. As shown in Fig.7,
theproposedapproach,i.e.,PA,requirestheleaststepsanddoesnotrequireany
transformation for the performance visualization. Note that other performance
analysis techniques can be applied to analyze other aspects of the performance.
In this case, our approach can, alternatively, generate an event log consisting of
the events in the stage instances and the Transform step should be applied like
the other techniques.
Domain Knowledge Required. The domain knowledge required for each
technique varies. For example, to train a prediction model, CRF requires an
event log with every event being labeled; for PNP, a coarse-granular instance
is extracted with a pattern of the activities. To compare the domain knowledge
quantitatively, we calculate the percentage of the activities required to extract
acoarse-granularinstance.Table3showshowthedomainknowledgeisrequired
for every technique evaluated and the corresponding number of activities in the
input of the techniques in the experiments. Our approach outperforms the CRF
and PNP. However, it is inferior to SESS and SM since the two techniques are
unsupervised.Nevertheless,SESSrequiresexhaustivelytuningoftheparameters
and the results are non deterministic. SM, as presented in the next section,
cannot guarantee the availability of the results.
Stage-Based Process Performance Analysis 361
Table 3. Overview: Techniques used for Experiments.
DomainKnowledgeRequired #ActivitiesRequired(%)
(PermitLog/BPIC151)
CRF Alleventslabeledwiththecoarse-granularinstancefortraining 1/1
PNP Behavioroftheactivitiesofeveryconceptatacoarsergranularlevel 0.71/0.9
PA Startandendactivitiesofastageclass 0.37/0.78
SESS Parameterstuning 0/0
SM Minimumnumberofactivitiesinaconceptatacoarsergranularlevel 0/0
4.2 Evaluation on Metrics Reliability
We perform analysis using the methods based on the steps illustrated in Fig.7.
To evaluate the results, generally speaking, the accuracy is an ideal indicator of
the reliability of the results. However, due to the assumptions of different tech-
niques, e.g., some are supervised while others are unsupervised approaches, it is
unfairtocomparetheaccuracyforthereliability.Therefore,theexperimentsare
conducted on a best effort basis and we consider the number of measurements
includedastheindicatorforthereliabilityofthemetrics,i.e.,themoremeasure-
ments and cases used to compute a performance metrics, the more reliable the
resultsare.Notethat,exceptforSMofwhichtheresultsareunavailable,allthe
techniquesrequireausertodeterminethenumberofconceptsinacoarsergran-
ular level, i.e., the number of stage classes in terms of the proposed approach.
Therefore,fortheconceptsatacoarsergranularlevel,wedefinefourconceptsfor
a travel reimbursement management process for PermitLog [8] and nine phases
whichareimpliedinactivitycodeinadutchmunicipalityforBPIC15 1 [6].The
quality of the results are examined from two perspectives, whether the number
of the concepts identified matches with the number of the concepts defined and
the amount of the measurements.
Table4 presents the performance statistics with the number of the measure-
mentsforthecycletimeandthecasesexecutingtheconceptsatacoarsergranu-
larlevel,i.e.,#ft.Forbotheventlogs,CRFandSESScannotextracttheexact
number of concepts defined. CRF identifies too many concepts which include
the events that the technique fails to predict (None) using PermitLog and too
less concepts using BPIC15 1. SESS extracts less clusters despite the fact that
the numbers of clusters desired are specified with the parameter. Therefore,
only PNP generates the same number of concepts at a coarser granular level
as specified. However, only the results using PermitLog are available while they
are inferior to the proposed approach in terms of the number of measurements
included.Toconclude,theproposedapproachprovidesthemostreliablemetrics
compared with the other techniques in the experiments.
362 C.-Y. Li et al.
Table 4. Number of measurements per high-level concept identified using PermitLog
and BPIC15 1. NaN indicates that the results are unavailable.
[][PermitLog]
High-LevelConceptIdentified(#ct/#ft)
CRF PNP PA SESS SM
-Apply(7911/7062) -Apply(7911/7062) -Apply(7911/7062) -Starttrip+(5406/3965) NaN
-Claim(1715/1336) -Claim(1605/1296) -Claim(2026/1314) -PermitFINALAPPROVED
-Travel(7843/7065) -Travel(6331/633) -Travel(7065/7065) bySUPERVISOR+(5715/4095)
-Declare(5980/5718) -Declare(5043/4963) -Declare(7401/5569) -RequestPayment+(10512/5856)
-None(1276/1276)
[][BPIC151
High-LevelConceptIdentified(#ct/#ft)
CRF PNP PA SESS SM
-Phase1(29/29) NaN -Phase0(1992/1199) -registersubmissiondate NaN
-Phase2(29/29) -Phase1(3967/1119) request+complete(901/670)
-Phase3(193/178) -Phase2(2727/969) -entersenddatedecisionenvironmental
-Phase4(200/178) -Phase3(2573/1028) permit+complete(1498/948)
-Phase5(180/176) -Phase4(3397/925) -registrationdatepublication+complete(105/102)
-Phase8(1027/1027) -Phase5(2054/899) -entersenddateprocedure
-Phase6(1/1) confirmation+complete(100/97)
-Phase7(138/138) -entersenddateacknowledgement+complete(106/102)
-Phase8(156/153) -generatepublicationdocumentdecision
environmentalpermit+complete(154/147)
-createsubcasescompleteness+complete(18/18)
4.3 Experiments Summary
We perform a comparative evaluation by analyzing stage performance using
various techniques. We compare the ease of the use of the techniques and the
reliability of the resulting performance metrics. In terms of the ease of use, our
approach requires the least effort from a user. However, we still require some
domain knowledge in comparison with the unsupervised techniques. The relia-
bilityofthemetricsisbasedonwhetherthenumberoftheconceptsatacoarser
granular level is the same as specified and the number of measurements. The
proposedapproachoutperformsalltheothertechniquesevaluated.Toconclude,
the results show that our approach meets the balance between the ease of use
and the reliability of the metrics.
4.4 Threats to Validity
Theexistingtechniquesarenotdesignedforanalyzingtheperformanceatahigh
level of a process. Therefore, some information that is required to compute the
duration of a coarse-granular instance, i.e., the start and complete time of the
instance, is left for users to determine. Consider two interleaving instances of
two concepts at a coarser granular level. Such behavior may result in multiple
cycle time for each instance in the Transform step. However, in fact, only two
measurements should be extracted. Thus, despite the best effort to apply the
techniques, the results may not be accurate due to the manipulation.
For the proposed approach, the implementation allows an analyst to define
onlythestageclasseswiththedistanceandthemappingofeventsconfiguredas
Stage-Based Process Performance Analysis 363
default. However, there may be some scenarios where the parameters may not
be defined easily and, thus, require further effort to configure the parameters
to obtain reliable results. In addition, the performance of stage instances is
aggregatedatthecaselevel.Whichmetricsmakessensefortheanalysisdepends
onthecontext.Forexample,intermsofstageinstancesofastageclassexecuted
in parallel, the average cycle time may not be a reasonable choice for some
processes. Nevertheless, consider the scenario in Fig.3, the average can be used
tocomputethecostsforhiringthestaffinthelaboratories.Suchdecisionrequires
analysts to be aware of the context.
5 Conclusion
The diagnosis of inefficiencies requires performance metrics provided based on
interpretable results. We elevate the analysis to the stage level and visualize
the performance accordingly. Existing techniques are insufficient for stage per-
formance analysis. The evaluation shows that combining existing techniques
requires additional manipulation of an event log and domain knowledge from a
user.Moreover,theresultsmaybeunreliableorunavailable.Weproposeanapp-
roachthat supportsperformanceanalysis atthestage level byextracting events
thatarecriticalforthemetrics.Assuch,ourapproachminimizestheeffortfrom
users while providing the most reliable results compared to the existing works.
Meanwhile, the technique can be flexibly combined with other visualization to
analyze other aspects of a process. To facilitate the analysis at the stage level,
further research aims at automatic identification of stage classes.
References
1. vanderAalst,W.,Unterberg,D.T.G.,Denisov,V.,Fahland,D.:Visualizingtoken
flowsusinginteractiveperformancespectra.In:InternationalConferenceonAppli-
cations and Theory of Petri Nets and Concurrency (2020)
2. Denisov, V., Belkina, E., Fahland, D., van der Aalst, W.: The performance spec-
trumminer:visualanalyticsforfine-grainedperformanceanalysisofprocesses.In:
BPM (Dissertation/Demos/Industry) (2018)
3. Denisov,V.,Fahland,D.,vanderAalst,W.:Unbiased,fine-graineddescriptionof
processes performance from event data. In: International Conference on Business
Process Management (2018)
4. Dumas, M., La Rosa, M., Mendling, J., Reijers, H.A.: Fundamentals of Business
Process Management (2018)
5. Gu¨nther,C.W.,Rozinat,A.:Disco:Discoveryourprocesses.BPM(Demos)(2012)
6. van der Ham, U.: Benchmarking of five dutch municipalities with process mining
techniques reveals opportunities for improvement (2015)
7. Haziza, D., Rapin, J., Synnaeve, G.: Hiplot, interactive high-dimensionality plots.
https://github.com/facebookresearch/hiplot (2020)
8. Hobeck,R.,etal.:Performance,variant,andconformanceanalysisofanacademic
travel reimbursement process (2020)
9. Hornix, P.T.: Performance analysis of business processes through process mining.
Master’s thesis, Eindhoven University of Technology (2007)
364 C.-Y. Li et al.
10. Kasim, T., Haracic, M., Haracic, M.: The improvement of business efficiency
through business process management. Econ. Rev. J. Econ. Bus. 16(1), 31–43
(2018)
11. Leemans, S.J., Fahland, D., van der Aalst, W.: Discovering block-structured pro-
cessmodelsfromeventlogscontaininginfrequentbehaviour.In:InternationalCon-
ference on Business Process Management (2013)
12. de Leoni, M., Du¨ndar, S.: Event-log abstraction using batch session identification
and clustering. In: Proceedings of the 35th Annual ACM Symposium on Applied
Computing (2020)
13. Li, C.Y., van Zelst, S.J., van der Aalst, W.: A generic approach for process per-
formanceanalysisusingbipartitegraphmatching.In:InternationalConferenceon
Business Process Management (2019)
14. Mannhardt,F.,Tax,N.:Unsupervisedeventabstractionusingpatternabstraction
and local process models. arXiv preprint arXiv:1704.03520 (2017)
15. Nguyen,H.,Dumas,M.,terHofstede,A.H.,LaRosa,M.,Maggi,F.M.:Stage-based
discovery of business process models from event logs. Inf. Syst. (2019)
16. Nguyen,H.,Dumas,M.,terHofstede,A.,LaRosa,M.,Maggi,F.:Businessprocess
performance mining with staged process flows. In: International Conference on
Advanced Information Systems Engineering (2016)
17. Song, M., van der Aalst, W.: Supporting process mining by showing events at a
glance.In:Proceedingsofthe17thAnnualWorkshoponInformationTechnologies
and Systems (2007)
18. Tax, N., Sidorova, N., Haakma, R., van der Aalst, W.: Mining process model
descriptionsofdaily life throughevent abstraction.In:Proceedings ofSAIIntelli-
gent Systems Conference (2016)
19. Tax,N.,Sidorova,N.,Haakma,R.,vanderAalst,W.:Eventabstractionforprocess
mining using supervised learning techniques. In: Proceedings of SAI Intelligent
Systems Conference (2016)
20. van der Aalst, W.: Process Mining: Data Science in Action. Springer, Heideberg
(2016). https://doi.org/10.1007/978-3-662-49851-4
21. van der Aalst, W., Adriansyah, A., van Dongen, B.: Replaying history on pro-
cessmodelsforconformancecheckingandperformanceanalysis.DataMiningand
Knowledge Discovery, Wiley Interdisciplinary Reviews (2012)
22. van Dongen, B.: BPI challenge 2015 municipality 1 (2015). https://doi.org/10.
4121/uuid:a0addfda-2044-4541-a450-fdcc9fe16d17
23. van Dongen, B.: BPI challenge 2020: Travel permit data (2020). https://doi.org/
10.4121/uuid:ea03d361-a7cd-4f5e-83d8-5fbdf0362550
24. vanDongen,B.,deMedeiros,A.K.A.,Verbeek,H.,Weijters,A.,vanderAalst,W.:
The prom framework: a new era in process mining tool support. In: International
conference on application and theory of petri nets (2005)
AudioLens: Audio-Aware Video
Recommendation for Mitigating New
Item Problem
B
Mohammad Hossein Rimaz1( ) , Reza Hosseini2, Mehdi Elahi3 ,
and Farshad Bakhshandegan Moghaddam4
1 Technical University of Kaiserslautern, Erwin-Schr¨odinger-Str 52,
67663 Kaiserslautern, Germany
PI:EMAIL
2 Vaillant Group Business Services, Berghauser Str. 63, 42859 Remscheid, Germany
PI:EMAIL
3 University of Bergen, Fosswinckelsgt. 6, 5007 Bergen, Norway
PI:EMAIL
4 University of Bonn, Regina-Pacis-Weg 3, 53113 Bonn, Germany