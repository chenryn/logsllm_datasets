are executed as soon as one of the incoming transitions is enabled. As with and-split and
xor-split activities, and-join activities and xor-join activities are represented with the
symbol ‘•’ and ‘⊕‘, respectively. An example of a process is shown in Figure 4.
Figure 4 The loan process
4.2 Business process scenario
In this section, we describe a scenario that will be used throughout the paper to explain
and illustrate the use of data mining techniques to predict path executions.
A major bank has realised that to be competitive and efficient it must adopt a new and
modern information system infrastructure. Therefore, a first step was taken in that
direction with the adoption of a workflow management system to support its business
processes. Since the bank supplies several services to its customers, the adoption of a
WfMS has enabled the logic of bank processes to be captured in web processes schema.
As a result, all the services available to customers are stored and executed under the
supervision of the workflow system. One of the services supplied by the bank is the loan
process depicted in Figure 1.
The web process is composed of fourteen web services. The Fill Loan Request Web
service allows clients to request a loan from the bank. In this step, the client is asked to
fill in an electronic form with personal information and data describing the condition of
the loan being requested.
The second web service, Check Loan Type, determines the type of loan a client has
requested and, based on the type, forwards the request to one of three web services:
Check Home Loan, Check Educational Home Loan, or Check Car Loan.
Web process and workflow path mining using the Multimethod approach 311
A loan request can be either accepted or rejected. In the case of a home loan,
however, the loan can also be approved conditionally. The web services in charge of
accepting a particular type of loan are Approve Home Loan, Approve Educational
Loan, and Approve Car Loan. The web services responsible for rejecting a loan are
Reject Car Loan, Reject Educational Loan, and Reject Car Loan. The web service
Approve Home Loan Conditionally, as the name suggests, approves a home loan under a
set of conditions.
When the result of a loan application is known, it is e-mailed to the client. Finally, the
Archive Application web service creates a report and stores the loan application data in a
database record.
A complete explanation of the process is described in Cardoso (2005).
4.3 Process quality of service
One important missing requirement for workflow systems and BPMS is the management
of QoS. Organisations operating in modern markets, such as e-commerce activities and
distributed services interactions require QoS management. Appropriate control of quality
leads to the creation of quality products and services; these, in turn, fulfill customer
expectations and achieve customer satisfaction.
4.3.1 QoS model
Quality of service can be characterised according to various dimensions. We have
investigated related work to decide which dimensions would be relevant to compose our
QoS model. Our research targeted two distinct areas: operations management for
organisations and quality of service for software systems. The study of these two areas is
important, since BPMS are widely used to model organisational business processes, and
workflow systems are themselves software systems.
Based on previous studies and experience in the business process and workflow
domain, a QoS model composed of the following dimensions has been constructed
(Cardoso et al., 2004): time, cost, and reliability. QoS specifications are set for activity
definitions. Based on this information, QoS metrics are computed for processes.
4.3.2 Creation of QoS estimates
In order to allow the analysis and computation of process QoS, it is necessary to initialise
activities QoS metrics and also initialise stochastic information which indicates the
probability of transitions being fired at runtime. Once activities and transitions have their
estimates set, algorithms (e.g., the SWR Cardoso, 2002; Cardoso et al., 2004; algorithm)
and mechanisms, such as simulation (Chandrasekaran et al., 2002; Miller et al., 2002),
can be applied to compute overall process QoS.
• Creation of QoS estimates for activities. The specification of QoS metrics for
activities is made at design time and re-computed at runtime, when activities are
executed. During the graphical construction of a process, the business analyst and
domain expert set QoS estimates for each activity. The estimates characterise the
quality of service that the activities will exhibit at runtime (see Figure 2).
312 J. Cardoso and M. Lenič
• Creation of probabilities estimates for transitions. In the same way we seed
activities’ QoS, we also need to seed process transitions. Initially, the designer sets
the transition probabilities at design time. At runtime, the transitions’ probabilities
are re-computed. The method used to re-compute the transitions’ probabilities
follows the same lines of the method used to re-compute activities’ QoS. The
creation of probabilities estimates for transitions, to subsequently estimate processes’
QoS, is based on a simple statistical technique (Cardoso, 2002; Cardoso et al., 2004).
Figure 5 shows some of the paths that can be followed at runtime during the
execution of a process. Each path has enabling probabilities associated with the
transitions. We will see that the use of adequate data mining techniques yields better
results for path mining compared to a simple statistical approach.
Figure 5 The loan process with QoS estimates for activities and probabilities estimates for
transitions
5 Process path mining
The material presented in this section emphasises the use of data mining concepts and
techniques for uncovering interesting process patterns hidden in large process logs.
Our path mining technique is composed of three steps. In the first step, a process log is
constructed. The process log structure must store activities’ input and output parameters
and the path followed during the execution of process instances. In the second step, we
construct a process profile. This profile is composed of a set of attributes that will be
analysed to establish a relationship between the attributes and the web services executed
(i.e., the path followed during the execution of process instances). Finally, in the third
step, we use data mining methods to determine the paths followed based on process
profiles.
Web process and workflow path mining using the Multimethod approach 313
The method presented in the next sections is more suitable for administrative
and production processes (McCready, 1992) compared to Ad-hoc and collaborative
processes, since they are more repetitive and predictive.
5.1 Process log
During the execution of processes, events and messages generated by the enactment
system are stored in a process log. Types of events that occur during process executions
include the start and completion of each activity, the resource utilised, and any failure
that occurred during activity or process execution. Typically, log systems are
implemented using relational databases, transactional databases, or flat files. These data
stores provide an adequate format on which path mining can be performed. The data
includes real-time information describing the execution and behaviour of processes, web
services, instances, transitions, and other elements such as runtime QoS metrics.
To perform path mining, current process logs need to be extended to store
information indicating the values and the type of the input parameters passed to activities
and the output parameters received from activities. Table 1 shows an extended process
log which accommodates input/output values of activities parameters that have been
generated at runtime. Each ‘Parameter/Value’ entry as a type, a parameter name, and a
value (for example, string loan-type = ‘car-loan’).
Additionally, the process log needs to include path information: a path describing the
activities that have been executed during the enactment of a process. This information
can easily be stored in the log. For example, an extra field can be added to the log system
to contain the information indicating the path followed. The path needs only to be
associated with the entry corresponding to the last service of a process to be executed.
For example, in the process log illustrated in Table 2, the service NotifyUser is the last
activity of a process. The log has been extended in such a way that the NotifyUser record
contains information about the path followed during the process execution.
5.2 Process profile
When beginning work on path mining, it is necessary to elaborate a profile for each
process. A profile provides the input to machine learning and it is characterised by its
values on a fixed, predefined set of attributes. The attributes correspond to the activity
input/output parameters that have been stored previously in the process log. Path mining
will be performed on these attributes.
The concept of profile has been exploited in other research areas. For example,
operational profiles (Musa, 1993) have been used to test the reliability of programs.
The idea is to test a program based on specific inputs. This can be achieved by the
elaboration of an operational profile (Musa, 1999). The input space is partitioned into
domains, and each input is associated with a probability of being selected during
operational use. The probability is employed in the input domain to guide input
generation. At runtime, programs have a probability associated with each input.
314 J. Cardoso and M. Lenič
Table 1 Extended process log
Conventional
process log Process log extension
… Process Activity Activity … Parameter/value Path
instance instance
… LA04 RejectCarLoan RCL03 … int LoanNum = 14357; …
string loan-type = ‘car-loan’
… LA04 NotifyCLoanClient NLC07 … string e-mail = ‘PI:EMAIL’ …
… TR08 FillRequestTravel FRT03 … string City = ‘Atlanta’; …
string Country = ‘USA’;
long BudgetCode = 193432
… LA05 CheckLoanRequest CLR05 … double income = 12000; …
string Name = ‘Eibe Frank’
… TR09 NotifyUser NU07 … String e-mail = PI:EMAIL; FillForm-
String >CheckForm-
telef = ‘35129170023’ >Approve-
>Sign->Report
… … … … … … …
Table 2 Process instance profile and process path class
Process instance profile Class
income Loan_type loan_amount loan_years Name SSN Path
5.3 Output of process path mining
The output of applying process path mining to a WfMS log and to a process in execution
is a structure that predicts the probability that a given path will be followed during the
remaining execution of the process. Figure 2 illustrates a very simple process for which
three different paths can be followed at runtime, A, B, and C. Using path mining we can
predict in an early execution of the process which path that will be most likely followed
during the execution of the process. As an example, the path mining approach can
indicate that path A will be most likely followed, with an accuracy of 76% (see Figure 3).
Figure 3 Process path mining
Web process and workflow path mining using the Multimethod approach 315
6 The Multimethod approach
The attributes present in a process profile trigger the execution of a specific set of
activities. Therefore, for each profile previously constructed, we associate an additional
attribute, the path attribute, indicating the path followed when the attributes of the profile
have been assigned to specific values. In data mining, the path attribute is considered to
be a class.
Once the profiles and a path attribute value for each profile have been determined, we
can use data mining methods to establish a relationship between the profiles and the paths
followed at runtime. A learning schema takes a set of classified profiles from which it is
expected to learn a way of classifying unseen profiles.
In this section we explain in detailed the Multimethod approach since it will be used
in our experiments and it is new and different from more traditional approaches.
6.1 Introduction
When we observe some event or when collecting data for analysis, we assume that there
is some target concept present in the data. It has been always a dream of computer
scientists to produce intelligent learning machine methods that could learn from past
experience and recognise target concepts from observations. Of course we are still far
from achieving this goal since we still don’t fully understand the human learning process.
Despite this fact, many successful approaches have been developed in the field of
data mining. One important component of data mining is machine learning, which is used
to automatically extract knowledge from sampled and preprocessed data. The extracted
knowledge is then post-processed to derive rules and patterns.
In the short history of data mining and machine learning many approaches that use
different techniques have evolved. These approaches are based on the different
interpretation of learning and exploit different laws to extract knowledge from data.
The main differences are related to the way the learning process is implemented and to
the way the extracted knowledge is represented. For example, neural networks attempt
to model the human brain and in practice can produce highly accurate knowledge models.
On other hand, the knowledge representation used, which involve connections between
neurons, is hard to understand.
With the variety of existing domains it is almost impossible to develop a single
machine learning algorithm that would work well in all the environments. If you
consider single data mining methods it becomes clear that there is no clear winner
(Wolpert and Macready, 1997), since learning algorithms and knowledge representations
have an important impact on the performance of algorithms depending on the domain and
application for which they are being used. Additionally, by considering the ‘no free lunch
theorem’ we realise that there is no single method that would outperform all other
methods in all the domains. To surpass this difficulty, we have constructed a new data
mining technique called the Multimethod approach. To clarify the concepts behind the
Multimethod approach we start by giving a short introduction of single and hybrid
approaches.
316 J. Cardoso and M. Lenič
6.2 Single method approaches
Single method approaches use a single knowledge representation to structure the
discovered/extracted knowledge from data. The knowledge representation has a dramatic
impact on the learning capabilities of a method. For example, if there is a target concept
in the data that cannot be described by a knowledge representation it is impossible
for a machine learning algorithm to find the target concept. On the other hand, by
introducing a very complex knowledge representation, the number of possible solutions
and the search space for the model (hypothesis) that describes the target concept is
increased. Each knowledge representation, and thereby each method, has advantages and
inherent limitations.
Decision trees (Quinlan, 1993), for example, are easily understandable to humans and
can be constructed and used without the help of a computer, but they are not appropriate
for discovering complex nonlinear concepts. Most connectivistics approaches that model
cognitive abilities of the brain can extract complex relations, but unfortunately the
knowledge representation is not easily understandable to humans and, therefore, they
cannot be directly used for data mining. Evolutionary approaches to knowledge
extraction pose an alternative, because they are not inherently limited to local solutions
(Goldberg, 1989), but are computationally expensive and do not always guarantee good
results.
There are many different approaches to knowledge representation, such as rules,
rough-sets, case based reasoning, support vector machines, and different fuzzy
methodologies. Unfortunately, they all subvert to some of the mentioned limitations.
6.3 Hybrid approaches
Hybrid approaches are based on the assumption that the synergetic combination of single
models can produced a more powerful data mining approach, i.e., ‘the whole is greater
than the sum of the parts’. Each of the single methods has its advantages but also inherent
limitations and disadvantages, which must be taken into account when using a particular
method. Therefore, a sound solution is to combine one or more methods to overcome
the disadvantages and limitations of a single method.
Hybrid systems are generally static and cannot change the structure of the methods
they use. To be able to use hybrids with different knowledge representations, it is
commonly required to transform one method knowledge model into another. Some
transformations can be trivial, especially when converting knowledge from symbolic
approaches. When the knowledge is not clearly represented, such as with neural networks
(Todorovski and Dzeroski, 2000; McGarry et al., 2001), it is very likely that some
concept elements may be lost during transformation because of the different hypothesis
spaces in the knowledge representations. The Multimethod approach presented in the
next section addresses precisely this problem.
6.4 The Multimethod approach
To address the problems previously described we have adopted and followed a set of
established approaches from other research fields, especially from social sciences, that