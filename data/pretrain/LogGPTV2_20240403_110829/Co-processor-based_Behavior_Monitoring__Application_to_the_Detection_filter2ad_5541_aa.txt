title:Co-processor-based Behavior Monitoring: Application to the Detection
of Attacks Against the System Management Mode
author:Ronny Chevalier and
Maugan Villatel and
David Plaquin and
Guillaume Hiet
Co-processor-based Behavior Monitoring: Application to the
Detection of Attacks Against the System Management Mode
Ronny Chevalier
HP Labs
PI:EMAIL
Maugan Villatel
HP Labs
PI:EMAIL
David Plaquin
HP Labs
PI:EMAIL
ABSTRACT
Highly privileged software, such as firmware, is an attractive target
for attackers. Thus, BIOS vendors use cryptographic signatures to
ensure firmware integrity at boot time. Nevertheless, such protec-
tion does not prevent an attacker from exploiting vulnerabilities at
runtime. To detect such attacks, we propose an event-based behav-
ior monitoring approach that relies on an isolated co-processor. We
instrument the code executed on the main CPU to send information
about its behavior to the monitor. This information helps to resolve
the semantic gap issue. Our approach does not depend on a specific
model of the behavior nor on a specific target. We apply this ap-
proach to detect attacks targeting the System Management Mode
(SMM), a highly privileged x86 execution mode executing firmware
code at runtime. We model the behavior of SMM using invariants
of its control-flow and relevant CPU registers (CR3 and SMBASE).
We instrument two open-source firmware implementations: EDK II
and coreboot. We evaluate the ability of our approach to detect
state-of-the-art attacks and its runtime execution overhead by simu-
lating an x86 system coupled with an ARM Cortex A5 co-processor.
The results show that our solution detects intrusions from the state
of the art, without any false positives, while remaining acceptable
in terms of performance overhead in the context of the SMM (i.e.,
less than the 150 µs threshold defined by Intel).
CCS CONCEPTS
• Security and privacy → Intrusion detection systems; Sys-
tems security; Security in hardware;
KEYWORDS
Hardware-based monitoring, firmware, SMM, co-processor, CFI
ACM Reference Format:
Ronny Chevalier, Maugan Villatel, David Plaquin, and Guillaume Hiet. 2017.
Co-processor-based Behavior Monitoring: Application to the Detection of
Attacks Against the System Management Mode. In Proceedings of ACSAC
2017. ACM, New York, NY, USA, 13 pages. https://doi.org/10.1145/3134600.
3134622
Publication rights licensed to ACM. ACM acknowledges that this contribution was 
authored or co-authored by an employee, contractor or affiliate of a national govern-
ment. As such, the Government retains a nonexclusive, royalty-free right to publish or 
reproduce this article, or to allow others to do so, for Government purposes only. 
ACSAC 2017, December 4–8, 2017, Orlando, FL, USA
© 2017 Copyright held by the owner/author(s). Publication rights licensed to Associa-
tion for Computing Machinery.
ACM ISBN 978-1-4503-5345-8/17/12. . . $15.00
https://doi.org/10.1145/3134600.3134622
Guillaume Hiet
CentraleSupélec
PI:EMAIL
1 INTRODUCTION
Computers often relies on low-level software, like the kernel of
an Operating System (OS) or software embedded in the hardware,
called firmware. Due to their early execution and their direct access
to the hardware, these low-level components are highly privileged
programs. Hence, any alteration to their expected behavior, mali-
cious or not, can have dramatic consequences on the confidentiality,
integrity or availability of the system.
Boot firmware, like the Basic Input/Output System (BIOS) or
Unified Extensible Firmware Interface (UEFI) compliant firmware,
is in charge of testing and initializing hardware components before
transferring the execution to an OS. In addition to boot firmware,
the platform initializes and executes runtime firmware code while
the OS is running. On x86 systems, a highly privileged execution
mode of the CPU, the System Management Mode (SMM) [41], exe-
cutes runtime firmware code.
Any attacker that can change the original behavior of boot or
runtime firmware, like skipping a verification step, can compro-
mise the system. For this reason, tampering with the firmware is
appealing for an attacker and sophisticated malware tries to infect
it. Such malware is persistent, hard to detect, and does not depend
on the OS installed on the platform [28, 33, 52].
Firmware code is stored on dedicated flash memory. On x86
systems, only runtime firmware code executed in SMM is allowed
to modify the flash. It prevents a compromised OS from infecting
the firmware. During the boot phase and before executing the OS,
the boot firmware loads some code in System Management RAM
(SMRAM). This code corresponds to privileged functions that will
be executed in SMM. Then, the firmware locks the SMRAM and the
flash (using hardware features) to prevent any modification from
the OS. Furthermore, recent firmware uses cryptographic signatures
during the boot process [30, 36, 67] and the update process [19] to
ensure that only firmware signed by the vendor’s key is updated
and is executed. In addition, measurements (cryptographic hash) of
all the components and configurations of the boot process can be
computed and securely stored at boot time, to attest the integrity
of the platform [34].
While cryptographic signatures and measurements provide code
and data integrity at boot time, they do not prevent an attacker from
exploiting a vulnerability in SMM at runtime [8, 27, 74]. Hence, we
need ways to prevent vulnerabilities in SMM, or at least to detect
intrusions exploiting such vulnerabilities.
Our work focuses on designing an event-based monitor for de-
tecting intrusions that modify the expected behavior of the SMM
399code at runtime. While monitoring the behavior of SMM is our
primary goal, ensuring the integrity of the monitor itself is critical
to prevent an attacker from evading detection. Thus, we isolate the
monitor from the monitored component (i.e., the target) by using a
co-processor.
A common issue affecting hardware-based approaches that rely
on an isolated monitor is the semantic gap between the monitor
and the target [48, 55, 63]. Such semantic gap issue occurs when the
monitor only has a partial view of the target state. For example, if
the monitor gets a snapshot of the physical memory without know-
ing virtual to physical mapping (e.g., CR3 register value on x86) it
cannot reconstruct accurately the memory layout of the target. Our
monitor addresses this issue by leveraging a communication chan-
nel that allows the target to send any information required to bridge
this semantic gap. We enforce the communication of information
relevant to the detection method via an instrumentation phase.
In addition, we ensure that the attacker cannot forge messages
without first being detected.
Our detection approach relies on a model of the expected behav-
ior of the monitored component, while any significant deviation
from this behavior is flagged as illegal. We chose an anomaly-based
approach as we aim to detect exploits of unknown vulnerabilities.
In summary, our approach consists in detecting malicious be-
havior of a target program executed on a main CPU. The detection
is implemented in a monitor executed on an isolated co-processor.
We also instrument the target code to enforce the communication
between the target and the monitor at runtime.
This approach can be applied to monitor various low level soft-
ware, such as SMM or ARM TrustZone secure world [4], which have
the following properties: expose primitives called infrequently by
upper layers and perform minimal computation per primitive. More-
over, different detection approaches could be used. While generic,
such approach introduces multiple challenges (e.g., the overhead
involved by the communication, the provenance of the messages,
or the integrity of the code added by the instrumentation phase). In
this paper, we focus on the detection of attacks targeting the SMM
code as a use case and show how we tackled these challenges. We
enforce Control-Flow Integrity (CFI) [1, 14, 16, 59, 62, 71, 72, 80] and
monitor the integrity of relevant CPU registers (CR3 and SMBASE)
to illustrate the feasibility of our approach.
targeting low-level software (§ 2).
Our contributions are the following:
• We propose a new approach using an event-based monitor
• We study the applicability of our approach using CFI to
• We develop a prototype implementing our approach.
• We evaluate our approach in terms of detection capability
and performance overhead on real-world firmware widely
used in the industry (§ 6).
detect attacks against SMM runtime firmware code (§ 5).
This paper is structured as follows. First, in § 2, we provide an
overview of our generic approach. Then, in § 3, we give a brief
background on CFI and SMM. We detail the threat model associated
with this use case in § 4. We describe the design and implementation
of our prototype in § 5. In § 6, we evaluate our approach. In § 7, we
compare our approach with related work. Finally, we conclude and
propose some future work in § 8.
2 APPROACH OVERVIEW & REQUIREMENTS
In this section, we describe the generic concepts and requirements
of our event-based behavior monitoring approach. As explained
in § 1, such concepts could be used to monitor different targets and
could rely on different detection approaches. We detail in § 5 one
possible implementation of this generic approach to detect runtime
attacks on SMM code using CFI.
Our approach, illustrated in Figure 1, relies on three key compo-
nents, which we detail in the following subsections: a co-processor,
a communication channel, and an instrumentation step. The co-
processor isolates the monitor from the target. The target uses the
communication channel to give more precise information about
its behavior to the monitor. The instrumentation step enforces the
communication.
Co-processor
monitor
Communication
channel
Processor
target
Co-processor RAM
Expected
target behavior
Processor RAM
Instrumented code
Figure 1: High-level overview of the approach
2.1 Co-processor
The integrity of the monitor is crucial, because it is a trusted compo-
nent that we rely on to detect intrusions in our system. The monitor
could also be used to start remediation strategies and restore the
system to a safe state. If the attacker compromised our monitor, we
could not trust the detection nor the remediation.
When the target and the monitor share the same resources
(e.g., CPU or memory), it gives the attacker a wide attack surface.
Thus, it is necessary to isolate the monitor from the target. Mod-
ern CPUs provide hardware isolation features (e.g., SMM or ARM
TrustZone [4]) reducing the attack surface. However, if one wants
to monitor the code executed in such environment, the monitor
itself cannot benefit from these isolation features.
In our approach, we use a co-processor to execute the monitor.
Such co-processor has its own execution environment and memory.
Thus, the attacker cannot directly access this dedicated memory
even if the target has been compromised. The attacker could only in-
fluence the behavior of the monitor via the communication channel,
which becomes the only remaining attack surface. The simplicity of
such an interface, however, makes it harder to find vulnerabilities
and to attack the monitor. Such design reduces the attack surface.
In the following subsection, we discuss the requirements for our
communication channel.
2.2 Communication with the monitor
Being isolated from the target, the monitor cannot retrieve entirely
the execution context of the target. Thus, there is a semantic gap
400between the current behavior of the target and what the monitor,
executed on the co-processor, can infer about this behavior [7, 43].
For example, the monitor does not have sufficient information to
infer the virtual to physical address mapping, nor the execution
path taken at any point in time.
We introduce a communication channel between the monitor
and the target. It allows the target to send messages to the monitor.
Different types of information could be sent using this communi-
cation channel such as the content of a variable in memory, the
content of a register, or the address of a variable. The nature of such
information depends on the detection approaches implemented on
the monitor, providing flexibility in our approach.
The communication channel is the only remaining attack vector
against the monitor. Thus, how the monitor processes the messages
and how the target sends them are an important part of the security
of the approach. To this end, we require the following properties:
(CC1) Message integrity If a message is sent to the monitor,
it cannot be removed or modified. Otherwise, an attacker
could compromise the target and then modify or delete the
messages before they are processed by the monitor to hide
the intrusion.
(CC2) Chronological order Messages are retrieved by the
monitor in the order of their emission. Otherwise, an at-
tacker could rearrange the order to evade the detection.
(CC3) Exclusive access The instrumented code has exclusive
access to the communication channel. Otherwise, an attacker
could forge messages faking a legitimate behavior.
(CC4) Low latency Sending a message should be fast (e.g.,
sub-microsecond), because low-level components need to
minimize the time spent performing their task to avoid im-
pacting higher-level components and the user experience.
2.3 Instrumentation of the target
We enforce the communication from the target to the monitor by
adding the communication code during an instrumentation step.
This instrumentation step can be performed during the compilation
or by rewriting the executable binary code.
Our approach relies on this enforcement, as should an attacker
tamper with the instrumentation, the monitor would get inaccurate
context of the behavior of the target making avoiding detection
possible. Thus, the integrity of the instrumentation (i.e., the com-
munication code of the target) is crucial. To this end, we require
the following properties:
(I1) Boot time integrity The code and data at boot time are
genuine and cannot be tampered with by the attacker.
(I2) Runtime code integrity The code cannot be modified by
the attacker at runtime.
3 BACKGROUND
In this section, we provide an overview on control-flow hijacking
and CFI. Then, we give some background regarding the SMM.
3.1 Control Flow Integrity (CFI)
Widely used defense mechanisms such as non-executable data and
non-writable executable code impede attackers in their ability to
exploit low-level vulnerabilities. Nevertheless, if an attacker man-
aged to modify an instruction pointer due to a vulnerability, then
program execution would be compromised. For example, in an x86
architecture, programs store the return address of function calls on
the stack. An attacker could exploit a buffer overflow to overwrite
the return address with an arbitrary one that redirect the execution
flow. Code-reuse attacks, such as Return-Oriented Programming
(ROP) [66] or Jump-Oriented Programming (JOP) [11, 17], use indi-
rect branch instructions (i.e., indirect call to a function, return from
a function and indirect jump) to chain together short instruction
sequences of the existing code to perform arbitrary computations.
The enforcement of a policy over the control-flow can prevent
such attack. This defense mechanism, called Control-Flow Integrity
(CFI), enforces integrity properties for each indirect branch where
the control-flow transfer is determined at runtime. It ensures that
a given execution of a program follows only paths defined by a
Control-Flow Graph (CFG). This graph represents all the legitimate
paths that the program can follow. The CFG needs to be defined
ahead of time and it can be computed via source code analysis [1],
binary analysis [80], or execution profiling [76].
A typical way to enforce CFI is by instrumenting the code, e.g.,
during the compilation phase. This inlined-based approach adds
runtime checks before each indirect branch [1, 71, 72]. If the address
is not within a finite set of allowed targets, the program stops.
A fined-grained CFI combines a shadow call stack (i.e., an in-
dependent protected stack that only stores return addresses) and
a precise CFG (i.e., a CFG with a small approximation regarding
indirect branches) to enforce CFI on all indirect control transfers.
Some implementations [31, 80] sacrifice security over perfor-
mance by building a less precise CFI. They either focus on pro-
tecting the backward-edge on the CFG (e.g., with a shadow call
stack) or on protecting the forward-edge (e.g., indirect calls). Davi
and Monrose [25] demonstrated that such implementations, called
coarse-grained CFI, fail to protect against control-flow hijacking.
Carlini et al. [16] also raised awareness on this issue by consolidat-
ing the argument that without stack integrity (i.e., without using a
shadow call stack), CFI is insecure.
Our solution uses a type-based CFI inspired by the work of Niu
and Tan [59] and Tice et al. [71]. We implement a shadow call stack
and verify that each indirect call branches to a function with an
expected type signature known at compile time (more details in § 5).
3.2 System Management Mode (SMM)
SMM [41] is a highly privileged execution mode of x86 processors.
It provides the ability to implement OS-independent functions (e.g.,
advanced power management, secure firmware update, or config-
uration of UEFI secure boot variables) [41, 77]. The particularity
of the SMM is that it provides a separate execution environment,
invisible to the OS. The code and data used in SMM are stored in a
hardware-protected memory region only accessible in SMM, called
SMRAM. SMM is entered by generating a System Management
Interrupt (SMI), which is a hardware interrupt. Software can also
make the hardware trigger an SMI.
Access to the SMRAM depends on the configuration of the mem-
ory controller, done by the firmware during the boot. Once all the
necessary code and data have been loaded in SMRAM, the firmware
401locks the memory region so that it can only be accessed by code run-