2 using the following mathemat-
α , i.e., z(cid:48) = 
1, z(cid:48)
α z.
(cid:107)z(cid:48)
1(cid:107)1
minimize
subject to Cz2 ≤ 1, z(cid:48)
1z(cid:48)
2
T ≥ I, z(cid:48)
1, z(cid:48)
2 ≥ 0
(4.6)
Our S-PBQ algorithm ﬁrst solves (4.6) and then sets z(cid:48)
I =
z(cid:48)
2 and each entry in z(cid:48) as the reciprocal of each entry in z(cid:48)
I.
Phase 2: Privacy budget optimization. This phase deter-
mines the privacy budget  using the above z(cid:48)
I, z(cid:48). Based on
the idea that the utility loss of perturbed data will not sig-
niﬁcantly decrease after  is larger than some threshold, we
search for the optimal  from 0 using a small learning step
186Input : item-category matrix C, learning step rate δ
Output: quantiﬁed optimal privacy budget 
// Phase 1: Noise magnitude determination
1 Solve mathematical programming (4.6);
2 z(cid:48) ← reciprocal of each entry in zI;
// Phase 2: Privacy budget calculation
3 Formulate (4.7) with sampled S and RandAs;
4 foreach i = 1, 2, . . . do
5
Solve relaxed (4.7) with I = 1
as line 5-10 in Algorithm 1);
err(i) ← 1
if i ≥ 2 & err(i) − err(i − 1) ≥ err(i − 1) − err(i − 2)
then
m(cid:107)l + r(cid:107)1 + I with rounded dp;
iδ and round dp (similar
6
7
8
9
 ← (i − 1)δ;
break;
end
10
11 end
// Repeat Phase 2
12 Repeat [Phase 2] N times and return averaged ;
Algorithm 2: S-PBQ Algorithm
rate δ (we choose δ = 0.02 as an experience value in prac-
tice). That is, we solve the following formulation (4.7) by
substituting I with 1
3δ , . . . The algorithm terminates
at ith iteration when the improvement of optimal utility loss
obtained by (4.7) using I = 1
(i−1)δ is no smaller
than that using I = 1
(i−2)δ . At last, we set
 = (i − 1)δ.
(i−1)δ over I = 1
iδ over I = 1
2δ , 1
δ , 1
minimize
subject to RandAs + I Sz(cid:48) − l ≤ CT dp
2
1
2(cid:107)l + r(cid:107)2
≤ RandAs + I Sz(cid:48) + r
dp ∈ {0, 1}n
(4.7)
where S = diag(s1, . . . , sm), in which each diagonal entry
sj is sampled from Laplace distribution Lap(1) such that
z(cid:48)(j)s(j) is a sample from Laplace distribution Lap(z(cid:48)(j))
due to the property of Laplace distribution kX ∼ Lap(kµ, kβ)
for a random variable X ∼ Lap(µ, β) for a positive constant
k [16]. In addition, in order to avoid potential privacy leak-
age caused by  quantiﬁcation, we do not use user’s private
history dr. Instead, we consider using RandAs, the cate-
gory aggregates on randomly selected items from all public
items. For simplicity, we use uniform sampling with sam-
pling rate as the averaged number of items for each user.
Our S-PBQ algorithm repeatedly samples diﬀerent S and
RandAs to obtain I by solving (4.7) in this phase. In the
experiment, we select the number of repeat times N to be 10
by considering the eﬃciency of S-PBQ algorithm. At last,
the averaged  is chosen as the quantiﬁed privacy budget.
Time Complexity Analysis. S-PBQ algorithm is sim-
ilar as S-DPDP algorithm with O(n) (phase 1 and rounding
steps in phase 2) and the running time to solve relaxed (4.7).
The second phase has its time complexity O(T ) similar as
that of solving relaxed (4.5). To provide strong privacy guar-
antee, we consider  ≤ 1 and therefore the repeat of phase
2 will take at most O(T + n). Our experimental results in
Figure 7 shows the eﬃcient running time in practice.
4.5 Overall Analysis of S-EpicRec System
We summarize the performance of S-EpicRec, that is, the
output of S-DPDP algorithm with the quantiﬁed privacy
budget using S-PBQ algorithm.
Privacy Guarantee. The perturbed data using S-EpicRec
satisﬁes -diﬀerential privacy where  is determined by S-
PBQ algorithm (Algorithm 2).
(cid:80)c
j=1 cij.
c
(cid:107)C(cid:107)1
), where (cid:107)C(cid:107)1 = max1≤i≤n
Utility Guarantee. The expected MAE between raw
and perturbed category aggregates (output of S-EpicRec) is
upper bounded by O(
It is not hard to see that the optimal solution of (4.6) is
upper bounded by (cid:107)C(cid:107)1. Therefore, the optimal solution of
(4.4) is upper bounded by O(
) based on Theorem 3, in
which the constant factor is dependent on the quantiﬁed .
Time Complexity. The overall time complexity of S-
EpicRec is O(n + T ) where T is the time complexity of solv-
ing relaxed (4.5) as discussed in [2].
(cid:107)C(cid:107)1
c
5. DESIGN OF M-EpicRec:
MULTI-LEVEL PRIVACY CONTROL
In this section, we further design a M-EpicRec framework
to enable the category-based privacy concern controls. The
idea of M-EpicRec is extended from S-EpicRec proposed in
Section 4. Basically, we consider using the same privacy
and utility notions for designing C-4 and C-5 components in
M-EpicRec system. The rest of this section focuses on the
diﬀerent parts between S-EpicRec and M-EpicRec, mainly
in terms of notations and the design of C-4 and C-5.
5.1 Notations
In M-EpicRec, the only diﬀerent notation from those in S-
EpicRec is in user privacy control component (C-3). Specif-
ically, we deﬁne the vector of privacy concern levels PT =
{PT(1), . . . , PT(c)} to replace a single PT. Each entry PT(j)
is the user-speciﬁed privacy concern level for category j,
which still belongs to one of the same three levels {“No
Release”, “Perturbed Release”, “All Release” }. Correspond-
ingly, we deﬁne the vector privacy budget  = {(1), . . . , (c)},
where (j) =  when PT(j) is selected as “Perturbed Release”
and (j) = 0 when PT(j) is selected as either “No Release”
or “All Release” indicating that no randomness is considered
for these categories.
Moreover, we deﬁne three vectors Ln, Lp, La with respect
to three privacy concern levels {“No Release”, “Perturbed
Release”, “All Release” }, based on PT. For example, when
PT=(no, perturbed, no, all, all, perturbed) w.r.t. 6 cate-
gories, we have Ln = (1, 0, 1, 0, 0, 0), Lp = (0, 1, 0, 0, 0, 1), La =
(0, 0, 0, 1, 1, 0). Note that each category has one privacy tol-
erance level and Ln + Lp + Ln = 1.
5.2 Design of Data Perturbation (C-4)
5.2.1 Problem Deﬁnition
We consider M-Perturbation Problem which diﬀers
from S-Perturbation Problem deﬁned in Section 4.3.1
from the following aspects:
(1) M-Perturbation problem
takes two diﬀerent inputs: the category-based privacy con-
cern levels Ln, Lp, La (derived from PT) and a privacy bud-
get  for categories with “perturbed release” privacy concern
level; (2) M-Perturbation problem targets on maintaining
the quality of category aggregates on perturbed data only
associated with “perturbed release” categories while releas-
ing no data in “no release” categories and all raw data only
associated with “all release” categories. (Note that we choose
to prioritize privacy protection when it conﬂicts with util-
ity. That is, we do not release an item as long as one of its
categories is set “no release”; we perturb an item if one of
its categories is set “perturbed release” privacy concern level
187and none of its categories is set “no release”; we release an
item only if all of its categories are set “all release”.)
5.2.2 Challenges
In addition to the challenges of S-Perturbation problem
described in Section 4.3.2, M-Perturbation problem poses
some additional challenges mainly from the constraints from
“no release” and “all release” categories. Especially when an
item belongs to multiple categories, the preservation of util-
ity on category aggregates on perturbed data in the “per-
turbed release” categories becomes more diﬃcult.
5.2.3 Proposed M-DPDP Approach
In this subsection, we focus on discussing about the novel
part of M-DPDP approach beyond S-DPDP approach (in
Section 4.3.3), which is developed to support multi-level pri-
vacy control. Speciﬁcally, as the key idea of these two ap-
proaches are consistent, we will mainly present the diﬀerence
in phase 1 and 2 respectively.
Phase 1: Noise calibration. The major diﬀerence between
phase 1 in M-DPDP and that in S-DPDP is that the noises
are injected only on categories with “perturbed release” pri-
vacy level while the noise magnitude on other categories are
enforced to be 0. Thus, (4.3) can be rewritten as follows:
minimize
subject to CzILpI ≤ 1, (Ln + La)T z = 0
(cid:107)z(cid:107)1
(Ln + La)T zI = 0, z, zI ≥ 0
(5.1)
where the ﬁrst constraint imposes the satisfaction of diﬀer-
ential privacy on these categories with “perturbed release”
privacy level; the next two constraints ensure no noise cal-
ibration into other categories. Accordingly, the quadratic
programming (4.4) can be rewritten as follows:
(cid:107)z1(cid:107)1
minimize
subject to Cz2LpI ≤ 1
(Ln + La)T z1 = 0, (Ln + La)T z2 = 0
z1z2
T ≥ IT LpI, z1, z2 ≥ 0
(5.2)
In this phase, M-DPDP algorithm solves (5.2) and sets
z2(j) if category j has “perturbed release” privacy
z(j) = 1
level and z(j) = 0 otherwise.
Phase 2: Data sanitization. The major diﬀerence in phase
2 is from the following two aspects:
First, in order to address the constraints of categories with
“no release” and “all release” privacy levels, we select “all
release” user data (denoted as da
r ) from user raw data dr,
where the ith entry in da
r is 1 if and only if this data belongs
to user raw data (ith entry in dr is 1) and all of its associated
categories have “all release” privacy levels.
Second, we inject Lap(z(j)) into the jth category for those
categories with “perturbed release” privacy level. Then, we
reformulate (4.7) as follows:
1
2
minimize
subject to NA − l ≤ CT dp ≤ NA + r
2(cid:107)l + r(cid:107)2
dp ≥ da
(Ln + La)T l = 0, (Ln + La)T r = 0
r , dp ∈ {0, 1}n
where N A(j) = (cid:80)
lease” privacy level; and N A(j) =(cid:80)
i∈I cijdr(i) for categories with “all re-
lease” privacy level; N A(j) = 0 for categories with “no re-
i∈I cijdr(i) + Lap(z(j))
for categories with “perturbed release” privacy level. The
second constraint imposes that the raw data only in cate-
gories with “all release” privacy level will be released; the
(5.3)
last two constraints guarantee the equivalence for categories
with “all release” and “no release” privacy levels.
5.2.4 Theoretical Analysis.
Theorem 4
(M-DPDP Privacy Analysis). M-DPDP
algorithm enjoys -diﬀerential privacy.
Theorem 5
(M-DPDP Utility Analysis). The expected
MAE between raw and perturbed aggregates (via M-DPDP
algorithm) is upper bounded by 2(cid:107)z(cid:107)1/c, where z is the op-
timal solution of (5.2).
The proofs are similar as Theorem 2, 3 and omitted due to
space limit. The time complexity of M-DPDP is also similar
as S-DPDP and omitted.
5.3 Design of Privacy Quantiﬁcation (C-5)
We propose M-PBQ approach in this section, extending
from S-PBQ algorithm in S-EpicRec system (Section 4.4).
Similarly, in phase 1, M-PBQ replace unknown  in (5.2) by
1 and solve it to obtain z(cid:48).
The diﬀerence between them mainly lies in the second
phase. In phase 2, we substitute (4.7) in Algorithm 2 with
the following formulation:
2
1
minimize
subject to RandAm + I Sz(cid:48) − l ≤ CT dp
2(cid:107)l + r(cid:107)2
≤ RandAm + I Sz(cid:48) + r
dp ≥ da
(Ln + La)T l = 0, (Ln + La)T r = 0
r , dp ∈ {0, 1}n
(5.4)
where S = diag(s1, . . . , sm) , in which the jth diagonal entry
s(j) is sampled from Laplace distribution Lap(1) if this cat-
egory has “perturbed release” privacy level and 0 otherwise;
RandAm is the category aggregates on randomly selected
items from all public items, in which Randm(j) = 0 for cat-
egories with “no release” privacy level. The time complexity
of M-PBQ is similar as S-PBQ and omitted.
5.4 Performance Analysis of M-EpicRec
We summarize the performance of M-EpicRec as follows:
Privacy Guarantee. The category aggregates of per-
turbed data from M-EpicRec satisfy -diﬀerential privacy
where  is determined by M-PBQ algorithm.
Utility Guarantee. The expectation of MAE between
(cid:80)m
raw and perturbed category aggregates (output of M-EpicRec)
is upper bounded by O(
), where (cid:107)C(cid:107)1 = max1≤i≤n
(cid:107)C(cid:107)1
j=1 cij.
c
Time Complexity. The overall time complexity of S-
EpicRec is O(n + T ) where T is the time complexity of solv-
ing relaxed (5.3) as discussed in [2].
6. EXPERIMENTAL EVALUATION
6.1 Datasets, Metrics, Competitors & Settings
Datasets. We test EpicRec on two real-world datasets:
MovieLens1: a movie rating dataset collected by the Grou-
pLens Research Project at the University of Minnesota through
the website movielens.umn.edu during the 7-month period
from September 19th, 1997 through April 22nd, 1998. The
number of movie categories is 18. We use the MovieLens-
1M, with 1000,209 ratings from 6,040 users on 3,883 movies.
1
http://grouplens.org/datasets/movielens
188Yelp2: a business rating data provided by RecSys Chal-
lenge 2013, in which Yelp reviews, businesses and users are