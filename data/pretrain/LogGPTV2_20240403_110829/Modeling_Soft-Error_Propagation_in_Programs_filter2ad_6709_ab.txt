our proposed model, TRIDENT, and then present the overall
structure of the model and the key insights it leverages. Finally
we present the details of TRIDENT using the running example.
A. Inputs and Outputs
The workﬂow of TRIDENT is shown in Figure 1b. We
require the user to supply three inputs: (1) The program code
compiled to the LLVM IR, (2) a program input to execute the
program and obtain its execution proﬁle (similar to FI methods,
we also require a single input to obtain runtime information),
and (3) the output instruction(s) in the program that are used
for determining if a fault resulted in an SDC. For example,
the user can specify printf instructions that are responsible for
the program’s output and used to determine SDCs. On the
other hand, printfs that log debugging information or statistics
about the program execution can be excluded as they do not
typically determine SDCs. Without this information, all the
output instructions are assumed to determine SDCs by default.
TRIDENT consists of two phases: (1) Proﬁling and (2)
inferencing. In the proﬁling phase, TRIDENT executes the
program, performing dynamic analysis of the program to
gather information such as the count and data dependency
of instructions. After collecting all the information, TRIDENT
starts the inferencing phase which is based on static analysis of
the program. In this phase, TRIDENT automatically computes
(1) the SDC probabilities of individual instructions, and (2)
the overall SDC probability of the program. In the latter case,
the user needs to specify the number of sampled instructions
when calculating the overall SDC probability of the program,
in order to balance the time for analysis with accuracy.
B. Overview and Insights
Because error propagation follows program data-ﬂow at
runtime, we need to model program data-ﬂow in the presence
of faults at three levels: (1) Static-instruction level, which cor-
responds to the execution of a static data-dependent instruction
sequence and the transfer of results between registers. (2)
Control-ﬂow level, when execution jumps to another program
location. (3) Memory level, when the results need to be
transferred back to memory. TRIDENT is divided into three
sub-models to abstract the three levels, respectively, and we
use fs , fc and fm to represent them. The main algorithm of
TRIDENT tracking error propagation from a given location to
the program output is summarized in Algorithm 1.
$1 = load …cmp gt $1, 0TF… ...load …store …… ...init()run()bb7$0 = load …$1 = add $0, 1cmp gt $1, 0…INDEX 1 (1, 0, 0)INDEX 2 (1, 0, 0)INDEX 3 (0.03, 0.97, 0)… ...Static-Instruction Sub-Model (fs ): First, fs is used to
trace error propagation of an arbitrary fault activated on a
static data-dependent instruction sequence. It determines the
propagation probability of the fault from where it was activated
to the end of the sequence. For example, in Figure 2b, the
model computes the probability of the fault propagating to
the result of the comparison instruction given that the fault
is activated at the load instruction (Line 4 in Algorithm 1).
Previous models trace error propagation in data dependant
instructions based on the dynamic data dependency graph
(DDG) which records the output and operand values of each
dynamic instruction in the sequence [9], [27]. However, such
detailed DDGs are very expensive to generate and process,
and hence the models do not scale. fs avoids generating
detailed dynamic traces and instead computes the propagation
probability of each static instruction based on its average case
at runtime to determine the error propagation in a static data-
dependent instruction sequence. Since each static instruction
is designed to manipulate target bits in a pre-deﬁned way,
the propagation probability of each static instruction can be
derived. We can then aggregate the probabilities to calculate
the probability of a fault propagating from a given instruction
to another instruction within the same static data-dependent
instruction sequence.
Control-Flow Sub-Model (fc ): As explained, a fault may
propagate to branches and cause the execution path of the
program to diverge from its fault-free execution. We divide
the propagation into two phases after divergence: The ﬁrst
phase, modeled by fc , attempts to ﬁgure out which dynamic
store instructions will be corrupted at what probabilities if a
conditional branch is corrupted (Lines 3-5 in Algorithm 1).
The second phase traces what happens if the fault propagates
to memory, and is modeled by fm . The key observation is
that error propagation to memory through a conditional branch
that leads to control-ﬂow divergence can be abstracted into a
few probabilistic events based on branch directions. This is
because the probabilities of the incorrect executions of store
instructions are decided by their execution paths and the cor-
responding branch probabilities. For example, in the function
init() in Figure 2a, if the comparison instruction takes the F
branch, the store instruction is not supposed to be executed,
but if a fault modiﬁes the direction of the branch to the T
branch, then it will be executed and lead to memory corruption.
A similar case occurs where the comparison instruction is
supposed to take the T branch. Thus, the store instruction is
corrupted in either case.
Memory Sub-Model (fm ): fm tracks the propagation from
corrupted store instructions to the program output, by tracking
memory dependencies of erroneous values until the output
of the program is reached. During the tracking, other sub-
models are recursively invoked where appropriate. fm then
computes the propagation probability from the corrupted store
instruction to the program output (Lines 7-9 in Algorithm 1).
A memory data-dependency graph needs to be generated for
tracing propagations at the memory level because we have to
know which dynamic load instruction reloads the faulty data
previously written by an erroneous store instruction (if any).
This graph can be expensive to construct and traverse due to
the huge number of the dynamic store and load instructions in
the program. However, we ﬁnd that the graph can be pruned by
removing redundant dependencies between symmetric loops,
if there are any. Consider as an example the two loops in
init() and run() in Figure 2a. The ﬁrst loop updates an array,
and the second one reads from the same array. Thus, there
is a memory dependence between every pair of iterations
of the two loops. In this case,
instead of tracking every
dependency between dynamic instructions, we only track the
aggregate dependencies between the two loops. As a result, the
memory dependence graph needs only two nodes to project the
dependencies between the stores and loads in their iterations.
Algorithm 1: The Core Algorithm in TRIDENT
1 sub-models fs , fc , and fm ;
: I: Instruction where the fault occurs
Input
Output: PSDC: SDC probability
2 ps = fs (I);
3 if inst. sequence containing I ends with branch Ib then
// Get the list of stores corrupted and their prob.
4
[, ...] = fc (Ib);
5
// Maximum propagation prob. is 1
6
Foreach(): PSDC += ps * pc * fm (Ic);
7
8 else if inst. sequence containing I ends with store Is
then
9
PSDC = ps*fm (Is);
C. Details: Static-Instruction Sub-Model (fs )
Once a fault is activated at an executed instruction, it starts
propagating on its static data-dependent instruction sequence.
Each sequence ends with a store, a comparison or an instruc-
tion of program output. In these sequences, the probability that
each instruction masks the fault during the propagation can be
determined by analyzing the mechanism and operand values of
the instruction. This is because instructions often manipulate
target bits in predeﬁned ways.
Given a fault that occurs and is activated on an instruction,
fs computes the probability of error propagation when the
execution reaches the end of the static computation sequence
of the instruction. We use a code example in Figure 2b to
explain the idea. The code is from Pathﬁnder [5], and shows a
counter being incremented until a positive value is reached. In
Figure 2b, INDEX 1-3 form a static data-dependent instruction
sequence, which an error may propagate along. Assuming a
fault is activated at INDEX 1 and affects $1, the goal of fs
is to tell the probabilities of propagation, masking and crash
after the execution of INDEX 3, which is the last instruction
on the sequence. fs traces the error propagation from INDEX
1 to INDEX 3 by aggregating the propagation probability of
each instruction on the sequence. We use a tuple for each
instruction to represent its probabilities which are shown in the
brackets on the right of each instruction in Figure 2b. There
are three numbers in each tuple, which are the probabilities
of propagation, masking and crash respectively, given that
an operand of the instruction is erroneous (we explain how
to compute these later). For example, for INDEX 3, (0.03,
0.97, 0) means that the probability of the error continuing to
propagate when INDEX 3 is corrupted is 0.03, whereas 0.97 is
the probability that the error will be masked and not propagate
beyond INDEX 3. Finally, the probability of a crash at INDEX
3, in this case, is 0. Note that the probabilities in each tuple
should sum to 1.
After calculating the individual probabilities, fs aggregates
the propagation probability in each tuple of INDEX 1, 2 and
3 to calculate the propagation probability from INDEX 1 to
INDEX 3. That is given by 1*1*0.03=3% for the probability
of propagation, and the probabilities of masking and crash are
97% and 0% respectively. Thus, if a fault is activated at INDEX
1, there is a 3% of probability that the branch controlled by
INDEX 3 will be ﬂipped, causing a control-ﬂow divergence.
We now explain how to obtain the tuple for each instruc-
tion. Each tuple is approximated based on the mechanism of
the instruction and/or the proﬁled values of the instruction’s
operands. We observe that there are only a few types of in-
structions that have non-negligible masking probabilities: they
are comparisons (e.g., CMP), logic operators (e.g., XOR) and
casts (e.g., TRUNC). We assume the rest of instructions neither
move nor discard corrupted bits - this is a heuristic we use for
simplicity (we discuss its pros and cons in Section VII-A).
In the example in Figure 2b, the branch direction will be
modiﬁed based on whether INDEX 3 computes a positive or
negative value. In either case, only a ﬂip of the sign bit of $1
will modify the branch direction. Hence, the error propagation
probability in the tuple of INDEX 3 is 1/32 = 0.03, assuming
a 32-bit data width. We derive crash probabilities in the tuples
for instructions accessing memory (i.e., load and store instruc-
tions). We consider crashes that are caused by program reading
or writing out-of-bound memory addresses. Their probabilities
can be approximated by proﬁling memory size allocated for
the program (this is found in the /proc/ ﬁlesystem in Linux).
Prior work [9] has shown that these are the dominant causes
of crashes in programs due to soft errors.
(a) Example of NLT
(b) Example of LT
Fig. 3: NLT and LT Examples of the CFG
D. Details: Control-Flow Sub-Model (fc )
Recall that the goal of fc is to ﬁgure out which dynamic
store instructions will be corrupted and at what probabilities, if
a conditional branch is corrupted. We classify all comparison
instructions that are used in branch conditions into two types
based on whether they terminate a loop. The two types are (1)
Non-Loop-Terminating cmp (NLT), and (2) Loop-Terminating
cmp (LT). Figure 3 shows two Control Flow Graphs (CFGs),
one for each case. We also proﬁle the branch probability of
each branch and mark it beside each corresponding branch for
our analysis purpose. For example, if a branch probability is
0.2, it means during the execution there is 20% probability the
branch is taken. We will use the two examples in Figure 3 to
explain fc in each case.
1) Non-Loop-Terminating CMP (NLT):
If a comparison
instruction does not control the termination of a loop, it is
NLT. In Figure 3a, INDEX 1 is a NLT, dominating a store
instruction in bb4. There are two cases for the store considered
as being corrupted in fc : (1) The store is not executed while
it should be executed in a fault-free execution. (2) The store
is executed while it should not be executed in a fault-free
execution. Combining these cases, the probability of the store
instruction being corrupted can be represented by Equation 1.
(1)
Pc = Pe /Pd
is the probability of the store being
corrupted, Pe is the execution probability of the store instruc-
tion in fault-free execution, and Pd is the branch probability
of which direction dominates the store.
In the equation, Pc
We illustrate how to derive the above equation using the
example in Figure 3a. There are two legal directions a branch
can take. In the ﬁrst case, the branch of INDEX 1 is supposed to
take the T branch at the fault-free execution (20% probability),
but the F branch is taken instead due to the corrupted INDEX
1. The store instruction in bb4 will be executed when it is
not supposed to be executed and will hence be corrupted. The
probability that the store instruction is executed in this case is
calculated as 0.2∗ 0.9∗ 0.7 = 0.126 based on the probabilities
on its execution path (bb0-bb1-bb3-bb4). In the second case, if
the F branch is supposed to be taken in a fault-free execution
(80% probability), but the T branch is taken instead due to the
fault, the store instruction in bb4 will not be executed, while it
is supposed to have been executed in some execution path in
the fault-free execution under the F branch. For example, in
the fault-free execution, path bb0-bb1-bb3-bb4 will trigger the
execution of the store. Therefore, the probability of the store
instruction being corrupted in this case is 0.8∗0.9∗0.7 = 0.504.
Therefore, adding the two cases together, we get fc in this
example as 0.126+0.504 = 0.63. The Equation 1 is simpliﬁed
by integrating the terms in the calculations.
In this example,
in Equation 1, Pe is 0.8 ∗ 0.9 ∗ 0.7 (bb0-bb1-bb3-bb4), Pd is
0.8 (bb0-bb1), thus Pc is 0.8∗ 0.9∗ 0.7/0.8 = 0.63. Note that
if the branch immediately dominates the store instruction, then
the probability of the store being corrupted is 1, as shown by
the example in Figure 2.
2) Loop-Terminating CMP (LT): If a comparison instruc-
tion controls the termination of a loop, it is LT. For example,
in Figure 3b, the back-edge of bb0 forms a loop, which can
be terminated by the condition computed by INDEX 2. Hence,
INDEX 2 is a LT. We ﬁnd that the probability of the store
instruction being corrupted can be represented by Equation. 2.
(2)
is the probability that a dynamic store instruction
is the execution
is corrupted if the branch is modiﬁed, Pb
probability of the back-edge of the branch, and Pe
is the
execution probability of the store instruction dominated by the
back-edge.
Pc = Pb ∗ Pe
Pc
We show the derivation of the above equation using the
if the T branch
example in Figure 3b. In the ﬁrst case,
(the loop back-edge) is supposed to be taken in a fault-free
execution (99% probability), the store instruction in bb4 may
or may not execute, depending on the branch in bb2. But
if a fault modiﬁes the branch of INDEX 2, the store will
certainly not execute. So we need to omit the probabilities
that the store is not executed in the fault-free execution to
calculate the corruption probability of the store. They are
0.99 ∗ 0.9 ∗ 0.3 = 0.27 for the path bb0-bb1-bb2-bb3 and
bb0cmp …  INDEX 1F 0.8bb2bb3bb5bb4store ...bb1bb10T 0.20.90.10.70.30.9bb3bb4store ...bb20.10.70.3cmp …     INDEX 2bb0bb1bb5T 0.99F 0.010.99 ∗ 0.1 = 0.099 for bb0-bb1-bb0. Hence, the probability of
a corrupted store in this case is 0.99 − 0.27 − 0.099 = 0.62.
In the second case where the F branch should be taken in
a fault-free execution (1% probability), if the fault modiﬁes