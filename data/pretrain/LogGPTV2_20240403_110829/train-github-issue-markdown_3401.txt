**Elasticsearch Version**: 2.3.2

### Scenario: Simulating a Read-Only Disk

This test aims to simulate a scenario where one of the data nodes in an Elasticsearch cluster has a read-only disk, and observe how the cluster handles this situation.

#### Steps:
1. **Start Two Data Nodes**: 
   - Two data nodes (node-1 and node-2) are started.
   
2. **Set Permissions for Node-2's Data Path**:
   - The data path for node-2 is set to read-only for all users.
   
3. **Create a New Index**:
   - A new index (e.g., `testindex`) is created with only primary shards.
   
4. **Shard Allocation**:
   - As expected, all shards assigned to node-2 remain unassigned because it cannot write to its file system. The primary shards for the healthy node (node-1) are allocated successfully.
   - Example shard allocation status:
     ```
     testindex 3 p STARTED 0 130b 127.0.0.1 node1
     testindex 4 p UNASSIGNED
     testindex 2 p UNASSIGNED
     testindex 1 p STARTED 0 130b 127.0.0.1 node1
     testindex 0 p UNASSIGNED
     ```

#### Observations:
- **Master Node Behavior**:
  - The master node repeatedly attempts to allocate the unassigned shards to node-2, even though it is read-only. This results in a continuous loop of failed attempts.
  - Example error log:
    ```
    [2016-08-03 11:45:04,927][WARN ][gateway                  ] [node1] [testindex][2]: failed to list shard for shard_started on node [Cr5kuAANQAi7dShxyW83Jg]
    FailedNodeException[Failed node [Cr5kuAANQAi7dShxyW83Jg]]; nested: RemoteTransportException[[node2][127.0.0.1:9301][internal:gateway/local/started_shards[n]]]; nested: ElasticsearchException[failed to load started shards]; nested: NotSerializableExceptionWrapper[access_denied_exception: /Users/User/ELK/ElasticStack_2_0/elasticsearch-2.3.2_node2/data/my-application1/nodes/0/indices/testindex/2/_state];
    ```

- **Pending Tasks**:
  - The master node continuously adds and re-adds tasks to the pending task queue, leading to an endless loop of failed attempts.
  - Example pending tasks:
    ```json
    {
      "tasks": [
        {
          "insert_order": 141469,
          "priority": "HIGH",
          "source": "cluster_reroute(async_shard_fetch)",
          "executing": true,
          "time_in_queue_millis": 1,
          "time_in_queue": "1ms"
        },
        {
          "insert_order": 141470,
          "priority": "HIGH",
          "source": "cluster_reroute(async_shard_fetch)",
          "executing": false,
          "time_in_queue_millis": 0,
          "time_in_queue": "0s"
        }
      ]
    }
    ```

- **Resolution**:
  - The issue persists until node-2 is stopped and the file system permissions are corrected.
  - After restarting node-2 with a writable data path, the index remains in a red state, and the unassigned shards do not get reallocated.
  - Example shard allocation status after fixing permissions:
    ```
    testindex 3 p STARTED 0 130b 127.0.0.1 node1
    testindex 4 p UNASSIGNED
    testindex 2 p UNASSIGNED
    testindex 1 p STARTED 0 130b 127.0.0.1 node1
    testindex 0 p UNASSIGNED
    ```

#### Recommendations:
- **Retry Mechanism**:
  - The master node should have a more robust retry mechanism that eventually gives up after a certain number of failed attempts, rather than continuously spewing exceptions and performing `async_shard_fetch` actions.
  
- **Shard Reallocation**:
  - If the permission issues are resolved while the master node is still retrying, the master should detect the change and attempt to reallocate the unassigned shards to the now-healthy node-2.
  - Even after a full cluster restart, the unassigned shards should be automatically reallocated to ensure the index returns to a green state.

By addressing these points, the cluster can handle read-only disk scenarios more gracefully and maintain better overall stability.