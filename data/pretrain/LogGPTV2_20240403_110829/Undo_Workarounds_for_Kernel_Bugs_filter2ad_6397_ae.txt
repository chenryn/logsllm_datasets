Complete
Bowknot
Trigger
Mode
Manual
Automatic
Automatic
Automatic Not-Complete
Automatic Not-Complete
Automatic Not-Complete
Automatic
Automatic
Automatic
Complete
Complete
Complete
Table 1: CVEs and real kernel bugs tested with bowknots. (* In these cases, the system was functional right after mitigation by
Talos, but it stopped working after a while due to a memory leak resulting from code disabling.)
Total # of
tested Bugs
30
# mitigated
by
Talos
20
# function
preserved
by Talos
8
# mitigated
by
bowknots
27
# function
preserved
by bowknots
27
# automatic
bowknot
trigger
30
# complete
bowknots
by Hecaton
18
Avg. # added undo sta-
tements for incomplete
bowknots by Hecaton
2
Table 2: Unpatched bugs experiments (x86 Linux kernel bugs reported by Syzbot).
bugs in 94.6% of cases and maintain the system functionality
in 85.1% of these cases. Moreover, Hecaton is capable of
generating complete bowknots in 70.4% of cases. In con-
trast, Talos can only mitigate the bugs in 64.9% of cases and
preserve the functionality in 23.9% of these cases.
For all bugs for which Hecaton’s bowknots were incom-
plete (injected bugs as well as real bugs and vulnerabilities),
we needed to add on average 3 statements.
7.1.2 Effectiveness of Syscall Undo
We perform a detailed case study to evaluate bowknots’
syscall undo capability. We perform a manual line-by-line
investigation on the execution path of 10 real bugs (5 Android
kernel and 5 x86 Linux bugs randomly chosen from the bugs
discussed in §7.1.1). In this investigation, we search for any
statement that changes the global state of the system but is
not undone by bowknots. The result of this analysis shows
that, to the best of our knowledge, for 6 cases the undo was
complete and there were no changes to the system global state
that did not get undone by the bowknots. Additionally, in 3 of
the 4 failed cases, we could manually add the undo statements
for the missed state-mutating statements and complete the
bowknot in less than 2 hours. In the remaining one case, the
state gets corrupted in a way that we even could not generate
a complete bowknot manually. We discuss this case-by-case
analysis in detail in the Appendix.
7.1.3 Effectiveness of Conﬁdence Score
To evaluate Hecaton’s conﬁdence score, we use our corpus
of 30 unpatched real bugs in x86 Linux kernel, which we
discussed in §7.1.1. As mentioned in §5.3, Hecaton generates
a conﬁdence score for each bowknot instrumented function.
Even if only one bowknot fails to undo the side effects of
a partially executed function, the system state might remain
inconsistent. As a result, to evaluate each bug, we consider
the minimum conﬁdence score for the bowknot instrumented
functions in its call stack. We divide these 30 bugs into two
sets of 20 and 10 bugs for respectively tuning and testing our
conﬁdence score. We tune the six coefﬁcients of the conﬁ-
dence score (§5.3) in a way that it best separates the tuning
set of bugs into two groups, one with complete bowknots and
one that needs manual effort. Then we measure how well the
tuned conﬁdence score can predict the completeness of the
bowknots Hecaton generates for 10 bugs in the testing set.
Note that a false negative prediction is more acceptable than
a false positive because in the case of a false negative the
conﬁdence score predicts an incomplete bowknot, which ends
up being complete. Figure 4 shows that the conﬁdence score
works for 95% of the cases in the tuning set, and it predicts
the completeness of generated bowknot with 90% accuracy in
the testing set. Please note that there is no false positive in the
results. In other words, whenever the minimum conﬁdence
score is greater than 50, the bowknots are complete.
7.2 Manual Effort for the Pair Database
We measure how much manual effort is needed to keep Heca-
ton’s function-pair knowledge database updated with the on-
going updates in the kernel. For this purpose, we use Hecaton
to generate the databases for 9 consecutive versions of x86
upstream Linux kernel, i.e., v5.0 to v5.8. As we discuss in
§5.1, this database needs to be manually inspected and veri-
USENIX Association
30th USENIX Security Symposium    2391
Kernel
Modules
# Injected
Bugs
Camera
Binder
41
33
# mitigated
by
Talos
34
14
# function
preserved
by Talos
5
12
# mitigated
by
bowknots
40
30
# function
preserved
by bowknots
33
30
# automatic
bowknot
trigger
33
26
# complete
bowknots
by Hecaton
26
24
Avg. # added undo sta-
tements for incomplete
bowknots by Hecaton
2
4
device
driver
Camera
Pixel3
Nexus 5X Camera
2018-08-22
2016-10-13
3
6
B. up time
24h
24h
B. fuzz time
22h49m± 1h5m
23h19m± 1m
Table 3: Bug injection experiments (camera device driver and Binder IPC).
version
U. up time
bugs
U. reboots
1035± 60
622.3± 48
24h
24h
U. fuzz time
12h18m± 9m
12h10m± 19m
B. reboots
98.3± 114
12.0± 0.0
Table 4: Effective fuzzing time. U. and B. refer to using unmodiﬁed kernel vs. a kernel updated with bowknots. The number of
reboots are per hour. Up time is the overall time during which the fuzzer is running including wasted reboot time. Fuzz time (i.e.,
effective fuzz time) is the time during which the fuzzer is actually fuzzing the kernel of the device.
Figure 4: Hecaton Conﬁdence score prediction for Tuning
and Testing sets
ﬁed. Our measurements show that when we move from one
kernel version to the next, on average 115± 18 additional
function pairs need to be veriﬁed, which in our experience
takes between 2 to 3 hours.
7.3 Performance Overhead
We measure the overhead of bowknots on the normal perfor-
mance of the system. To do so, we measure how the perfor-
mance overhead increases as the number of executed func-
tions with bowknot instrumentation increases. To test the per-
formance overhead of bowknots in our ARM implementation,
we use two benchmark applications, “GPU Mark benchmark”
that measures the output frame-rate of GPU renderings, and
“Tamosoft Throughput Test” that measures the downlink TCP
throughput. To test the performance overhead of bowknots in
our x86 implementation, we use iPerf tool [1] in Linux kernel
to measure the downlink TCP throughput.
Each benchmark results in the execution of many functions
in their corresponding kernel components. First, we detect all
these triggered functions (410 functions in the Pixel3 GPU
driver, 390 functions in the Pixel3 networking stack, and 370
functions in x86 Linux networking stack). We then randomly
choose a number of these functions and instrument them with
bowknots. For all modules, we either instrument 100, 200, or
all available functions in them. We run the benchmarks 10
Figure 5: GPU and TCP performance as the number of ex-
ecuted bowknots increase. (a) Pixel3 GPU , (b) Pixel3 TCP,
(c) x86 upstream Linux (running in QEMU) TCP.
times and show the average±stdev throughput in Figure 5.
The results show that there are no statistically noticeable
performance drops even if all executed functions are instru-
mented with bowknots.
7.4 Use-Case Evaluation
As discussed in §2.2, by neutralizing bug-triggering syscalls,
bowknots can help reduce the number of repetitive reboots
during a fuzzing session. We evaluate the beneﬁts of bowknots
for fuzzing in this section. We fuzzed 13 device drivers and
kernel components (camera driver, GPU driver, audio driver,
WiFi driver, ION, Binder, and Ashmem) in three smartphones
(Pixel3, Nexus 5X, and Samsung S7). Out of these, 5 of them
showed repetitive reboots due to easily-triggered bugs. Out
of these 5 drivers, 2 of them had easily-triggered bugs that
bowknots could effectively mitigate. We show the results for
these two drivers: the camera device driver of Pixel3 and the
camera device driver of Nexus 5X. We note that bowknots
cannot provide any beneﬁts for the other three drivers.
We use the following experimental methodology. We run
each fuzzing experiment for 24 hours as suggested by Klees
et al. [23]. Moreover, we repeat each experiment 3 times and
report averages and standard deviations. To implement this
methodology, we faced and solved a practical challenge. More
speciﬁcally, running 24-hour kernel fuzzing experiments on
2392    30th USENIX Security Symposium
USENIX Association
Tuning setTesting set0255075100Confidence scoreCompleteNot-complete0100200410#Bowknots(a)020406080100120140GPU rendering (FPS)0100200390#Bowknots(b)0246810121416TCP downlink (Mb/S)0100200370#Bowknots(c)020406080100120140160180TCP downlink (Mb/S)Figure 6: The setup used in our fuzzing experiments.
(a)
(b)
Figure 7: (a) Total executed fuzzing programs. (b) Covered
basic blocks (code coverage percentage is also reported on
top of each bar).
smartphones proved to be challenging due to unreliability
of the Android Debug Bridge (ADB). Occasionally, ADB
would malfunction and the desktop machine running the
fuzzer would lose its connection to the device, disrupting
the experiment. This phenomenon happened more frequently
when the device was rebooted more often. Our ﬁrst attempt
to address this problem was to restart the experiment from
scratch when this issue happened. Given that experiments
are 24 hours long, this proved to be a very lengthy process.
Therefore, we built a custom hardware-software framework
to programmatically and forcefully reboot the device using
its power button when the connection to the device was lost.
Figure 6 shows this setup. We 3D printed the cover to hold
the smartphone in place, used a 45 Newton linear solenoid to
press and hold the power button, and used an Arduino Uno
board to control the solenoid from the fuzzer.
Increased fuzzing time. Table 4 shows the effective fuzzing
time achieved when fuzzing the unmodiﬁed driver and the
driver with bowknots. As the table shows, bowknots increase
the effective fuzzing time by 88.6%± 4.6%.
Executed programs.
Figure 7a shows the total number
of executed fuzzing programs. Bowknots eliminate wasted
fuzz time and hence the fuzzer executes more programs. Our
results show that we manage to execute 723.5%±124% more
fuzzing programs on average with bowknots.
Code coverage. Figure 7b shows the code coverage in the
driver under test. As can be seen, the higher number of ex-
ecuted programs and fewer reboots result in 54.3%± 6.1%
higher code coverage.
Comparison with Talos. We compare the effectiveness of
Figure 8: Time taken for the fuzzer to discover a bug (i.e.,
trigger a bug for the ﬁrst time). Each x-axis tick represents a
unique bug.The points with no error bars represent bugs only
found once during experiments
Bug
triggered
by fuzzer
msm_actuator_subdev_ioctl
msm_camera_io_w_mb
msm_camera_io_r
msm_ﬂash_conﬁg
msm_csid_conﬁg
msm_cpp_subdev_ioctl