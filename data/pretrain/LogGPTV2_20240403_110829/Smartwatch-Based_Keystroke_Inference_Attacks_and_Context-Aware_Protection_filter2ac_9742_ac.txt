ﬁxed length time-domain feature vector (as used in feature
vectors with (L/R) labels). As a solution, we use frequency-
domain features such as Fast Fourier Transformation (FFT)
of the transition data.
Labeling: Each training word is broken down into its
constituent characters and character-pairs. As a result, a
word of length n letters would be broken into n charac-
ters and n − 1 character-pairs. Feature vector of each key-
stroke is labeled (L/R) using the ground truth characters
recorded during data collection. Feature vectors of direc-
tions are labeled (N/E/S/W/O) by calculating the direc-
tion between character-pairs obtained from the same ground
truth. An additional processing is performed to select a set
of character-pairs with even distribution of L and R and N,
E, S, W and O labels. Note that the number of N, E, S, W
and O labels will be approximately one-fourth of the num-
L, L R, R L and R R pairs because the
ber of L
direction is determined only in case of L L transition (or R
R if the target wears the smartwatch on right hand). For
L R, R L and R R character-pairs, the direction for
transition cannot be determined (which is denoted by X in
the word-proﬁle), and thus, they are not used in the training
phase.
Supervised Learning: We created two separate training
models that will be used during the attack phase to classify
keystrokes and keystroke-pairs. The two trained models are
L-R and N-E-S-W-O neural networks for classifying (L/R)
and (N/E/S/W/O) feature vectors, respectively. Because of
the complex interactions possible between consecutive key-
strokes, we train our classiﬁers using neural networks. Neu-
ral networks are speciﬁcally useful in discovering these com-
plex interactions between the corresponding feature vectors,
and improving the classiﬁcation model based on it. Our
L-R neural network uses a back-propagation algorithm for
learning at a rate of 0.01 and with a momentum of 0.99.
This neural network has 30 hidden layers and training was
performed for 2000 epochs. Our N-E-S-W-O neural network
also uses a back-propagation algorithm for learning at a rate
of 0.001 and with a momentum of 0.99. This neural net-
work has 100 hidden layers and the training was performed
for 1000 epochs. These parameters for our neural network
based classiﬁers were chosen heuristically. Training of these
neural networks completes the learning phase.
4.2.2 Attack Phase
The attack phase follows a similar procedure as the learn-
ing phase, with the exception that the goal here is to recover
test words using the trained neural networks-based classiﬁ-
cation models from the learning phase. In order to do so,
the adversary must ﬁrst create a dictionary of words, and
their corresponding word-proﬁles, that the target is most
likely of typing. The dictionary size can vary from a few
words to thousands of words, depending on the target and
his/her context. If the adversary is unaware of the target’s
context, he could also create a large dictionary of most pop-
ular or all words in the English language. The dictionary
creation involves a preprocessing step to obtain equivalent
word-proﬁles of each word in the L/R and X/N/E/S/W/O
representation (as discussed before). The attack phase is
then executed in sequential steps of: (i) data collection, (ii)
feature extraction, (iii) keystroke classiﬁcation, and (iv) word
matching.
Data Collection: The same properties and operations
from the data collection operation of the learning phase also
applies to the data collection during the attack phase. The
only exception is that the malicious Android Wear applica-
tion does not have the ability to clock and tag ground truth
characters. As the smartwatch can only detect motion cause
by one (watch-wearing) hand, a signiﬁcant challenge of the
Figure 3: Learning Phase: A high level overview of the data processing architecture used to train the neural
networks.
Figure 4: Attack Phase: A high level overview of the data processing architecture used to analyze keyboard
input using the trained neural networks.
proposed inference attack is due to the inability to detect
keystrokes made by the non-watch-wearing hand. However,
our attack framework requires to know the number of typed
characters. To solve this problem, here we assume that the
adversary can employ an alternate source or sensor on the
smartwatch that can detect keystroke events typed by either
hand. The intention for using such an auxiliary sensor is not
to classify the keystrokes using it, but to clock the time when
a keystroke occurs in the stream of raw linear acceleration
data. A microphone can perfectly serve this purpose. Even
though a smartwatch’s microphone is not eﬀective for recov-
ering keystrokes (due to the aforementioned reasons), it can
certainly be used to detect the occurrence of a keystroke it-
self, made by either hand. This is where the naturally close
positioning of the smartwatch near the keyboard is beneﬁ-
cial. Thus, the malicious application uses the microphone
to detect keystroke acoustics, and in the case a keystroke
event is detected from the acoustic signal, it logs a key-
stroke event in the linear accelerometer data stream. Space
key press events are also clocked or logged because they act
as word separators. Fortunately, as we empirically deter-
mined, space keys are easy to identify in an audio recording
because of the key’s distinctive sound and frequency of use.
Feature Extraction: During the attack phase, the same
features as in the learning phase are extracted from the raw
linear acceleration data recorded by the malicious applica-
tion. The feature vectors are then used to create two sets of
data, one for classifying L vs. R, and one for classifying N
vs. E vs. S vs. W vs. O.
Keystroke Classiﬁcation: The adversary initiates the
classiﬁcation process after extracting all feature vectors. The
trained L-R neural network is used to predict the (L/R) label
for each individual keystroke. Only when a L L key-pair
is detected in the data stream by the L-R neural network,
the N-E-S-W-O neural network classiﬁcation is conducted to
predict the transition direction label (N/E/S/W/O). Oth-
erwise, the transition direction is labeled as X. Using the
predicted labels (and the recognized space keys as described
earlier), a word-proﬁle is constructed for each word in the
keystroke stream. All the constructed word-proﬁles are then
passed as input to a word matching algorithm described
next.
Word Matching: Word matching is the ﬁnal step of the
attack phase, where each predicted word-proﬁle of length m
is matched with all words of length m + 1 in the prepro-
cessed dictionary by the adversary. For each matched word
TypingRaw Linear Accelerometer DataFeature Extraction ModulePosition FeaturesL/R LabelerLabeled L/R FeaturesL-R Neural NetworkN/E/S/W/O LabelerLabeled N/E/S/W/O FeaturesN-E-S-W-O Neural NetworkTransition FeaturesRandom Training WordsSupervised Learning ModuleTypingRaw Linear Accelerometer DataFeature Extraction ModulePosition FeaturesTransition FeaturesContextual DictionaryClassification and Word Matching ModuleAcoustic Keystroke DetectionKeystroke TimestampsFeature MatchingPredicted WordsN-E-S-W-O Neural NetworkClassifierL-R Neural Network Classifierin the dictionary, a similarity score is computed based on
the number of matching labels between the predicted word-
proﬁle and the corresponding word-proﬁle in the dictionary
(see details in Algorithm 1). The dictionary word with the
highest similarity score is then output as the word corre-
sponding to the predicted word-proﬁle. For some evaluation
experiments, we also use a ‘similarity list’ made of dictionary
words with descending order of similarity scores.
Algorithm 1 Word Matching Algorithm
1: similarityScore = 0
2: for all words of len(m) ∈ dic do
3:
4:
5:
for pair = 1 to m − 1 do
for label = 1 to 3 do
if
dic.word.prof ile[pair][label]
predicted.prof ile[pair][label] then
=
similarityScore++
end if
6:
7:
8:
9:
10: end for
11: return similarityScore
end for
end for
4.3 Experimental Setup
In our experimental evaluation of the proposed inference
attack and keystroke characterization framework, we use a
setup similar to the one shown in Figure 1. We recruit 25
participants1 who wear the smartwatch on their left wrist
and type test words on an external QWERTY keyboard. All
data recorded by the smartwatch was transferred to a remote
server. Both the training and attack phases are executed on
this remote server which is assumed to possess enough com-
putational and storage resources in order to carry out these
operations. The speciﬁcations of important hardware and
software components used in our experiments are outlined
below:
1. Smartwatch and sensor hardware: We used the Sam-
sung Gear Live smartwatch running Android Wear build
1.1.1.1944630. The Gear Live is equipped with an In-
venSense ICS-43430 microphone and an InvenSense MP-
92M 9-axis Gyro + Accelerometer + Compass sensor.
The maximum average linear accelerometer sampling rate
achieved in our experiments was 50 Hz. Our data collec-
tion application can be readily used on any Android Wear
smartwatch, which makes the attack framework compat-
ible with a diverse set of smartwatches.
2. Keyboard hardware: We chose to use the Anker A7726121
bluetooth keyboard because of its generic design. The
bluetooth connectivity aided in accurate labeling of sen-
sor data, by allowing us to aggregate recorded sensor data
and corresponding typed character on the smartwatch in
very close to real time.
3. Signal processing tool: Most of the features are calculated
using MatLab 2015a libraries.
4. Supervised machine learning tool: We used PyBrain v0.31
to train and test the neural networks in our framework.
1Our experiments have been approved by Wichita State Uni-
versity’s Institutional Review Board (IRB).
PyBrain is an open-source modular machine learning li-
brary for Python, supporting easy integration with un-
derlying environment.
5. EVALUATION
We ﬁrst perform two preliminary experiments (involving
only one participant) in order to evaluate (i) the base accu-
racy of the L-R and N-S-E-W-O classiﬁers by analyzing a set
of test sentences from the set of Harvard sentences [1] and
(ii) the word recovery accuracy of the proposed inference at-
tack strategy by using a dictionary of ten Harvard sentences
and attempting to recover each of the same ten sentences as
test data. We choose Harvard sentences because they are
phonetically-balanced. In the two preliminary experiments
we make the assumption of ‘perfect typing’, i.e. the par-
ticipant follows our L/R separation. After the preliminary
experiments, we conduct more realistic experiments involv-
ing all 25 participants, real-life sentences, larger dictionaries,
and without the assumption of perfect typing.
5.1 Feature Accuracy
In the ﬁrst experiment, we examine the base accuracy of
both L-R and N-S-E-W-O classiﬁers in correctly distinguish-
ing between L/R region for individual letters and N/S/E/
W/O transition between pairs of letters. We evaluate our
trained classiﬁers using all the ten sentences in List 6 of
Harvard sentences. Interestingly, without any typing errors,
the L-R classiﬁer was able to correctly identify 100% of the
individual key press events as left or right. However, the
N-E-S-W-O classiﬁer had two mis-classiﬁcations, resulting
in 95% accuracy.
5.2 Basic Text Recovery
Our next experiment examines the percentage of text (in
terms of words) correctly matched by the word matcher.
In this preliminary experimental results, we observed that
the overall percentage of words correctly matched notice-
ably dropped due to mismatched two and three letter words
in the analyzed text. The smaller number of features in
these words results in several of these ‘small’ words having
the same word-proﬁle, thus causing more collisions during
matching. We also observed that most of these words are
generally articles and conjunctions (e.g. an, the, and, or),
which can be easily interpolated by analyzing the language
semantics of the recovered text. As a result, we opted to
consider only ‘long’ words of four letters or more in all ﬁ-
nal percentages of recovered words in our remaining experi-
ments. The ‘short’ words are instead denoted with asterisks
(“*”) in the recovered sentences.
In this experiment, we used the same ten sentences in
List 6 of Harvard sentences, as from the ﬁrst experiment.
Among the 48 words of length four or more, only three
were erroneous (93.75% successful recovery). Out of the
Figure 5: Sentence 4 from List 6 of Harvard Sen-
tences. The words ‘show’ and ‘sums’ have the same
word-proﬁle resulting in a collision in the dictionary.
Typed Text:Theshowwasaflopfromtheverystart.Recovered:*** sums****flopfrom***verystart.Colliding Word-Profiles:Show: LXR . RXR . RXL, Sums: LXR . RXR . RXLFigure 6: Contextual Dictionary: Percentage of
words recovered per participant, presented in de-
scending order of typing speed of the participants.
three, two had incorrect N/E/S/W/O classiﬁcation, while
the other was due to collisions in the word-proﬁles. Fig-
ure 5 shows the sentence where the collision occurred. The
problem of collision will increase with increasing size of the
dictionary. However, if we also take in to account second
and third ranked similar word-proﬁles during word match-
ing, this problem can be moderated. Errors in word recovery
(especially, due to collisions) can be further diminished by
analyzing language semantics, and then selecting the word
(from the multiple colliding words in the dictionary) that is
semantically best ﬁt.
5.3 Contextual Dictionary
This experiment evaluates how our attack performs when
the adversary has some knowledge about what their targets
are typing. All the 25 participants typed a paragraph of 40
words (of length four or more) that appear in a National
Public Radio (NPR) news article on Greece debt crisis, and