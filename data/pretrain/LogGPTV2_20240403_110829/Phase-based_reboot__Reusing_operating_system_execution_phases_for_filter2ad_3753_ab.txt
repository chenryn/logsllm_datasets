state kernel objects include caches for disk blocks and caches
for kernel resource managers. A ﬁle cache is a typical
example of soft-state kernel objects. Because a ﬁle cache
contains the data on disk, the guest can reproduce it by
reading the data from the disk. Likewise, caches for resource
managers such as a slab cache can be reproduced from the
original data structure.
To avoid saving these pages, we modify the guest kernel
to explicitly inform the VMM which pages are unnecessary.
When a snapshot is taken, the guest kernel examines its
memory objects and sends the VMM the guest physical
address of the unnecessary pages. The VMM does not store
them in a snapshot, based on the given addresses. When
the snapshot is restored, the VMM compensates for the lost
pages by allocating new pages to the guest. After that, the
restored VM starts to run.
Shrinking the VM memory checkpoints also enables us
to put the checkpoints on small and faster access devices.
When a VM memory checkpoint is signiﬁcantly small, we
can place it on solid state drives or RAM disks whose
accesses are much faster than disk drives. This accelerates
the restoration of the restartable image, leading to much
faster reboot-based recovery.
B. Update of File System Objects
We need to take into account the memory objects of
ﬁle systems after restoration from a restartable image. File
systems are OS core components that manage disk caches
including the cache of data blocks, metadata, and ﬁle sys-
tem metadata. Because ﬁle systems manage such memory
objects, a restartable image naturally contains them, but the
ﬁle systems fail to keep the disk updates in the service
phase when a restartable image is restored. For example,
the ﬁlesystems’ metadata such as the super block cause this
problem. The kernel only updates these metadata in the
memory, and writes them back to the disks; the metadata
are never read from the disks after the partition has been
mounted. When a restartable image is restored, the older ﬁle
system metadata are overwritten on the current metadata.
This causes the ﬁle system to inconsistently manage disk
blocks such as free blocks and data blocks.
The i-node cache of the ﬁle opened with the append
mode causes a similar problem. When the i-node cache
preserved in a restartable image does not have an append
region, restoring the restartable image results in the i-node
data being overwritten on the newer data on the disk. This
means the appended regions of the ﬁle are eliminated.
Although remounting the disk volumes is a simple so-
lution for this inconsistency problem, this solution is not
suitable for phase-based reboots. Speciﬁcally, we take a
snapshot after unmounting the disk volumes. When the
snapshot is restored, we mount them. This way naturally
refreshes ﬁle system objects, thus avoiding the inconsistency
problem described above. However, we have to close all the
ﬁles in the disk volumes to safely unmount the disk volumes.
This constraint is critical for the phase-based reboot because
some applications keep ﬁles open while running. For exam-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:15:28 UTC from IEEE Xplore.  Restrictions apply. 
172ple, syslog_d keeps its log ﬁle open with O_APPEND,
and crond keeps its pid ﬁle open. Therefore, we cannot
put these applications into restartable candidates. To put such
applications on a restartable image, we explore an alternative
to solve the inconsistency of ﬁle system objects.
To solve the inconsistency, our kernel module forces the
kernel ﬁle system component to read such metadata again
just after a restartable image has been restored. When the
restoration of a snapshot is completed, our kernel module
forces the ﬁle system component to read the ﬁle system
metadata and i-node from the disk and it updates them.
C. Finding Restartable Images
We use as a restartable image a restartable candidate,
where the application states are the same as after a nor-
mal OS reboot. Because the memory contents saved in
a restartable image are overwritten to the target VM, the
restartable image needs to contain applications’ memory
contents that will be built by the normal OS reboot. If an
application memory image in a restartable image is different
from that after the normal OS reboot, the wrong memory
image will be built on the VM. This means we cannot
produce the effect of the reboot-based recovery.
Suppose that a restartable candidate contains a running
application that reads a conﬁguration ﬁle in its boot phase.
If the ﬁle is updated, the application should be launched with
the new conﬁguration after reboot-based recovery. However,
restoring the restartable candidate builds an application
image that is based on the older conﬁguration. Another
example is that a restartable candidate contains a running
application that keeps a ﬁle open to log its state. Restoring
this image may cause a log corruption if the application logs
its state in the service phase. Because the ﬁle offset of the
application is also restored, the application may overwrite
the log contents that were logged before restoring. Although
one way to solve this problem is to redesign applications
to force them to reconstruct their states after a snapshot is
restored, modifying all of the applications is unreasonable.
To ﬁnd an appropriate restartable image, our checker
infers the application states that will be built by the normal
reboot. To do so, it checks whether ﬁles accessed until a
restartable candidate is taken are updated in the service
operation. If these ﬁles are not updated, we evaluate whether
the selected restartable candidate can be used as a restartable
image. We assume that applications launch in the same way
if ﬁles accessed by them are not updated. For example, some
applications start to run based on their conﬁguration ﬁles.
If the conﬁguration ﬁles are not modiﬁed, the applications
start in the same way at the next OS boot. Even if an
application reads ﬁles and caches their contents in memory,
it builds the cache again when the ﬁle contents have not been
modiﬁed. When a log ﬁle is not updated, the application does
not overwrite old log contents since the ﬁle offset has not
changed.
We note that our checker does not cover all types of
applications. For example, it does not manage applications
whose behavior is deﬁned by network conditions and time.
If such applications are put into a restartable image, the
phase-based reboot may build the wrong application states
after network conditions and times are changed. To manage
the applications, we need to extend our checker to determine
whether applications’ states in the restartable candidates are
the same as those built by the normal OS reboot.
We prepare a mechanism for ﬁles opened with the append
mode such as O_APPEND to aggressively omit the boot
phase. When ﬁles are opened with the append mode, the
kernel sets ﬁles’ offset of the application to the end of the
ﬁles in write(). This means the ﬁle offset is automatically
set to the end of the ﬁle by write() even after the snapshot
is restored. If the ﬁle contents are not updated, except for
the appended region, the checker determines whether the
application that opens the ﬁle with the append mode can
consistently run after a restartable image is restored. In
this situation, it does not issue a warning that a restartable
candidate is not a restartable image.
D. Discussion
it cannot handle all
As previously described, the phase-based reboot has lim-
itations. First,
types of failures, as
described in Sec. II-B. Also, the phase-based reboot is not
very effective in cases where daemons’ states are different at
every boot. If the daemons are launched earlier, the phase-
based reboot cannot reuse many previous system states.
Fortunately, there were no such daemons in our experiments
where we used a real Linux distribution and the RUBiS
benchmark.
Moreover, the phase-based reboot does not always auto-
matically produce the effect of an OS reboot, as described in
Section II-A. Some applications create a ﬁle to avoid being
doubly launched. For example, vsftpd creates its lock ﬁle
in /var/lock/subsys. Because the ﬁle is preserved in
the disk after a restartable image is restored, the system fails
to start the applications when we restore a restartable image
where they have not been started yet. In order to obtain the
effect of an OS reboot from the phase-based reboot in this
situation, we need to shut down such applications before
conducting the phase-based reboot.
Our snapshot optimization conﬂicts with a daemon
that puts frequently used ﬁles into buffer cache to im-
prove the performance in the service phase. For example,
readahead_early accesses frequently used ﬁles to put
them into the buffer cache of the kernel. Our optimization
shortens the time for restoring a snapshot at the expense of
disposing of soft-state objects that improve system perfor-
mance. We can adjust how many pages of buffer cache we
release, taking into account the importance of performance
in the service. However, there is a trade-off between the
performance and the time for restoring the restartable image;
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:15:28 UTC from IEEE Xplore.  Restrictions apply. 
173the more buffer cache we leave, the longer time it takes to
restore the restartable image.
V. IMPLEMENTATION
We implemented the phase-based reboot in Linux 2.6.18
running on Xen 3.4.1. Our core implementation consists of
three modules; a ﬁle access monitor, kernel object manager,
and ﬁle update checker. Both the ﬁle access monitor and
kernel object manager are running inside the guest kernel
in a domain U. The ﬁle update checker is running inside
domain 0. The ﬁle access monitor logs the name and
last modiﬁcation time of ﬁles accessed until a restartable
candidate is taken. To do so,
it records information on
ﬁles accessed by the processes. The kernel object manager
appropriately handles disk cache being managed by the ext3
ﬁle system. In addition, it frees slab cache and tells the
addresses of free pages to the underlying hypervisor in order
to remove the entries of the P2M table when a restartable
candidate is taken. The ﬁle update checker inspects virtual
disk images mounted by the target VM and checks ﬁle
updates by referring to a log produced by the ﬁle access
monitor.
Our implementation is overviewed in Fig. 3. Fig. 3 (a)
depicts the execution of saving restartable candidates. For
ease of implementation, we run a daemon server that triggers
our guest kernel-level mechanism. Since we can take a
snapshot only in domain 0, the client running in domain 0
communicates with the daemon server. To take a restartable
candidate, the client asks the server to run the kernel-level
mechanism. The client starts taking a snapshot when it is
notiﬁed of the completion of the module tasks by the daemon
server. Note that there is a race condition where a process
can modify ﬁles until the client starts taking a snapshot after
the completion of the module tasks. To avoid this situation,
we need to implement a mechanism that enables domain U
to take its snapshot.
First, the ﬁle access monitor logs information on accessed
ﬁles for the ﬁle update checker. Next, the kernel object
manager ﬂushes the dirty buffer and releases the disk cache
and slab cache. Then, the kernel object manager tells the
underlying hypervisor to remove entries of free pages in the
P2M table with the balloon driver to shrink the memory
checkpoint. Finally, we save the shrunken memory image as
a restartable candidate.
shows
Figure 3 (b)
the execution ﬂow when the
phase-based reboot is triggered. Xen restores the selected
restartable candidate, and the kernel object manager reallo-
cates free pages because the VM snapshot has been shrunk.
Finally, the kernel object manager updates i-nodes, dentries,
and super block data in the memory. If necessary, the ﬁle
update checker checks whether the VM has updated the
ﬁles in the ﬁle access logs and determines which restartable
candidate is restartable.
A. File Access Monitor
The ﬁle access monitor logs information on accessed
ﬁles for the ﬁle update checker. Speciﬁcally, it memorizes
the absolute path of the accessed ﬁle, its i-node number,
and its last modiﬁcation time. The ﬁle access monitor also
memorizes whether a ﬁle has been opened with O_APPEND.
It saves the memorized information as a ﬁle on the guest ﬁle
system when the kernel object manager triggers it. The log
is used by the ﬁle update checker, as will be described later.
sys_open,
sys_stat, and sys_exec to ﬁnd out which ﬁles
have been accessed. The monitoring is stopped when our
system call, pbr_ready(), is issued in order to avoid
overhead of ﬁle access monitor activities in the service
phase.
access monitor monitors
The
ﬁle
B. Kernel Object Manager
The kernel object manager manipulates kernel objects
being managed by ext3 and the slab allocator. The manip-
ulation is carried out when restartable candidates are taken
and when they are restored. When a restartable candidate is
taken, the kernel object manager ﬂushes the dirty buffer and
releases the page cache corresponding to the buffer cache,
i-nodes, and dentries. This is done to shrink the memory
checkpoint. If some processes are using i-nodes and dentries,
the kernel object manager does not release these objects.
When the restartable candidate is restored, the kernel object
manager updates the unreleased cache by fetching the data
from the virtual disk. At the same time, it updates the super
block data in the memory.
The kernel object manager also unregisters free pages
from the P2M table for the Xen hypervisor to shrink the
memory checkpoint of the domain. To remove the entries
of free pages in the P2M table, the kernel object manager
leverages a balloon driver [5]. When the balloon is inﬂated,
it pins down free pages and tells the Xen hypervisor to
remove their entries in the P2M table. When the balloon
is deﬂated, it releases the pinned pages and registers their
entries to the P2M table again.
The kernel object manager controls the balloon when a
restartable candidate is taken and restored. After releasing
the page cache and slab cache, it inﬂates the balloon to
remove the entries of free pages in the P2M table. When the
restartable candidate is restored, the kernel object manager
deﬂates the balloon to register the free pages in the P2M
table again.
C. File Update Checker
The ﬁle update checker helps
to determine which
restartable candidate is restartable. We can run the ﬁle
update checker just after a restartable candidate is taken.
To detect ﬁle updates, it pairs the log produced by the
ﬁle access monitor with the restartable candidate. The ﬁle
update checker mounts the virtual disk used by the target
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:15:28 UTC from IEEE Xplore.  Restrictions apply. 
174Restartable Candidates
Restartable
Candidates
Domain 0
Client
Domain U
Server
User
Kernel
File Access
Monitor
Domain 0
Domain U
    1. Destroys a VM
    2. Restores the
        restartable image
File Update
Checker
User
Kernel
Kernel
Object
Manager
   5. Saves a snapshot
       as a restartable
       candidate
Kernel
Object
Manager
File access logs
   1. Logs information 
       on accessed files
File access logs
    4. Removes entries of 
        free pages in P2M table
    2. Flushes dirty buffer
    3. Releases buffer cache
   5. Checks updated files and selects
       a restartable image if necessary
     3. Reallocates free pages
P2M Mapping Table
Xen
Virtual Disk
    4. Updates inodes, dentries,
        and super block data
P2M Mapping Table
Virtual Disk
Xen
(a) Execution of saving a restartable candidate
(b) Execution of phase-based reboot
Figure 3. An Overview of Phase-based reboot
domain U after the restartable candidate is taken to salvage
the produced log.
To determine which restartable candidate is restartable, the
ﬁle update checker detects ﬁle updates by referring to the log
paired with the restartable candidate. The ﬁle update checker
obtains the current state of the logged ﬁles by mounting the
used virtual disks. It compares the obtained i-node number
and the last modiﬁcation time with the corresponding values
in the log. If the current values are different from the logged
ones, the ﬁle update checker judges the ﬁles to be updated,
and the restartable candidate cannot be used as a restartable
image.
To successfully deal with the ﬁles opened with
O_APPEND, the ﬁle update checker calculates and logs the
hash value of their contents just after a restartable candidate
is taken. The ﬁle update checker gets the ﬁle contents
by mounting the virtual disks. When we check whether a
restartable candidate is restartable, the ﬁle update checker
calculates the ﬁle contents except for the appended region
again, and compares it with the logged value. If the values
are the same, the ﬁle update checker does not issue a warning
that the restartable candidate is not restartable.
VI. EXPERIMENTS
We conducted experiments to evaluate the effectiveness of
the phase-based reboot. We used a machine equipped with
a 3 GHz quad-core Xeon processor, 16 GB of memory, and
a 73-GB SAS NHS 10,000 rpm hard disk. On this machine,
we ran Xen 3.4.1 and the Linux 2.6.18 kernel in domain 0.
We also ran the modiﬁed Linux 2.6.18 para-virtualized for
Xen on guest domains connected to a 10-GB virtual disk.
We installed Fedora Core 8 on each domain, and turned off
unnecessary service daemons.
We investigated the following fundamental issues in our
experiments. The ﬁrst was how the phase-based reboot short-
ens the downtime of reboot-based recovery. The second was
which restartable candidate can be a restartable image under
a complicated workload. The last was whether the phase-
based reboot can recover from kernel transient failures.
A. Downtime
We measured the downtime of the phase-based reboot
to determine how the phase-based reboot shortens the
downtime of reboot-based recovery. To execute the phase-
based reboot, we prepared two restartable images. The ﬁrst