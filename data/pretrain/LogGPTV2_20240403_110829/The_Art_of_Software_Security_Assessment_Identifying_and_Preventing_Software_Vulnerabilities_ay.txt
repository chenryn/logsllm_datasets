a comprehensive study of protection mechanisms, but it does touch on the most 
commonly deployed ones. 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
203 
Stack Cookies 
Stack cookies (also known as "canary values") are a method devised to detect and 
prevent exploitation of a buffer overflow on the stack. Stack cookies are a 
compile-time solution present in most default applications and libraries shipped with 
Windows XP SP2 and later. There are also several UNIX implementations of stack 
cookie protections, most notably ProPolice and Stackguard. 
Stack cookies work by inserting a random 32-bit value (usually generated at runtime) 
on the stack immediately after the saved return address and saved frame pointer but 
before the local variables in each stack frame, as shown in Figure 5-13. This cookie is 
inserted when the function is entered and is checked immediately before the function 
returns. If the cookie value has been altered, the program can infer that the stack has 
been corrupted and take appropriate action. This response usually involves logging 
the problem and terminating immediately. The stack cookie prevents traditional stack 
overflows from being exploitable, as the corrupted return address is never used. 
Figure 5-13. Stack frame with and without cookies 
Limitations 
This technology is effective but not foolproof. Although it prevents overwriting the 
saved frame pointer and saved return address, it doesn't protect against overwriting 
adjacent local variables. Figure 5-5(? [????.]) showed how overwriting local variables 
can subvert system security, especially when you corrupt pointer values the function 
uses to modify data. Modification of these pointer values usually results in the 
attacker seizing control of the application by overwriting a function pointer or other 
useful value. However, many stack protection systems reorder local variables, which 
can minimize the risk of adjacent variable overwriting. 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
204 
Another attack is to write past the stack cookie and overwrite the parameters to the 
current function. The attacker corrupts the stack cookie by overwriting function 
parameters, but the goal of the attack is to not let the function return. In certain cases, 
overwriting function parameters allows the attacker to gain control of the application 
before the function returns, thus rendering the stack cookie protection ineffective. 
Although this technique seems as though it would be useful to attackers, optimization 
can sometimes inadvertently eliminate the chance of a bug being exploited. When a 
variable value is used frequently, the compiler usually generates code that reads it off 
the stack once and then keeps it in a register for the duration of the function or the 
part of the function in which the value is used repeatedly. So even though an 
argument or local variable might be accessed frequently after an overflow is triggered, 
attackers might not be able to use that argument to perform arbitrary overwrites. 
Another similar technique on Windows is to not worry about the saved return address 
and instead shoot for an SEH overwrite. This way, the attacker can corrupt SEH 
records and trigger an access violation before the currently running function returns; 
therefore, attacker-controlled code runs and the overflow is never detected. 
Finally, note that stack cookies are a compile-time solution and might not be a 
realistic option if developers can't recompile the whole application. The developers 
might not have access to all the source code, such as code in commercial libraries. 
There might also be issues with making changes to the build environment for a large 
application, especially with hand-optimized components. 
Heap Implementation Hardening 
Heap overflows are typically exploited through the unlinking operations performed by 
the system's memory allocation and deallocation routines. The list operations in 
memory management routines can be leveraged to write to arbitrary locations in 
memory and seize complete control of the application. In response to this threat, a 
number of systems have hardened their heap implementations to make them more 
resistant to exploitation. 
Windows XP SP2 and later have implemented various protections to ensure that heap 
operations don't inadvertently allow attackers to manipulate the process in a harmful 
manner. These mechanisms include the following: 
An 8-bit cookie is stored in each heap header structure. An XOR operation 
combines this cookie with a global heap cookie, and the heap chunk's address 
divided by 8. If the resulting value is not 0, heap corruption has occurred. 
Because the address of the heap chunk is used in this operation, cookies 
shouldn't be vulnerable to brute-force attacks. 
Checks are done whenever an unlink operation occurs to ensure that the 
previous and next elements are indeed valid. Specifically, both the next and 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
205 
previous elements must point back to the current element about to be 
unlinked. If they don't, the heap is assumed to be corrupt and the operation is 
aborted. 
The UNIX glibc heap implementation has also been hardened to prevent easy heap 
exploitation. The glibc developers have added unlink checks to their heap 
management code, similar to the Windows XP SP2 defenses. 
Limitations 
Heap protection technologies aren't perfect. Most have weaknesses that still allow 
attackers to leverage heap data structures for reliable (or relatively reliable) 
exploitation. Some of the published works on defeating Windows heap protection 
include the following: 
"Defeating Microsoft Windows XP SP2 Heap Protection and DEP Bypass" by 
Alexander Anisimov 
(www.maxpatrol.com/defeating-xpsp2-heap-protection.htm) 
"A New Way to Bypass Windows Heap Protections" by Nicolas Falliere 
(www.securityfocus.com/infocus/1846) 
"Windows Heap Exploitation" by Oded Horovitz and Matt Connover 
(www.cybertech.net/~sh0ksh0k/heap/XPSP2%20Heap%20Exploitation.ppt) 
UNIX glibc implementations have undergone similar scrutiny. One useful resource is 
"The Malloc Maleficarum" by Phantasmal Phantasmagoria 
(www.securityfocus.com/archive/1/413007/30/0/threaded). 
The most important limitation of these heap protection mechanisms is that they 
protect only the internal heap management structures. They don't prevent attackers 
from modifying application data on the heap. If you are able to modify other 
meaningful data, exploitation is usually just a matter of time and effort. Modifying 
program variables is difficult, however, as it requires specific variable layouts. An 
attacker can create these layouts in many applications, but it isn't always a reliable 
form of exploitationespecially in multithreaded applications. 
Another point to keep in mind is that it's not uncommon for applications to implement 
their own memory management strategies on top of the system allocation routines. 
In this situation, the application in question usually requests a page or series of pages 
from the system at once and then manages them internally with its own algorithm. 
This can be advantageous for attackers because custom memory-management 
algorithms are often unprotected, leaving them vulnerable to variations on classic 
heap overwrite attacks. 
Nonexecutable Stack and Heap Protection 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
206 
Many CPUs provide fine-grained protection for memory pages, allowing the CPU to 
mark a page in memory as readable, writable, or executable. If the program keeps its 
code and data completely separate, it's possible to prevent shellcode from running by 
marking data pages as nonexecutable. By enforcing nonexecutable protections, the 
CPU prevents the most popular exploitation method, which is to transfer control flow 
to a location in memory where attacker-created data already resides. 
Note 
Intel CPUs didn't enforce nonexecutable memory pages until recently (2004). Some 
interesting workarounds were developed to overcome this limitation, most notably by 
the PaX development team (now part of the GR-Security team). Documentation on 
the inner workings of PaX is available at http://pax.grsecurity.net/. 
Limitations 
Because nonexecutable memory is enforced by the CPU, bypassing this protection 
directly isn't feasiblegenerally, the attacker is completely incapacitated from directing 
execution to a location on the stack or the heap. However, this does not prevent 
attackers from returning to useful code in the executable code sections, whether it's 
in the application being exploited or a shared library. One popular technique to 
circumvent these protections is to have a series of return addresses constructed on 
the stack so that the attacker can make multiple calls to useful API functions. Often, 
attackers can return to an API function for unprotecting a region of memory with data 
they control. This marks the target page as executable and disables the protection, 
allowing the exploit to run its own shellcode. 
In general, this protection mechanism makes exploiting protected systems more 
difficult, but sophisticated attackers can usually find a way around it. With a little 
creativity, the existing code can be spliced, diced, and coerced into serving the 
attacker's purpose. 
Address Space Layout Randomization 
Address space layout randomization (ASLR) is a technology that attempts to 
mitigate the threat of buffer overflows by randomizing where application data and 
code is mapped at runtime. Essentially, data and code sections are mapped at a 
(somewhat) random memory location when they are loaded. Because a crucial part of 
buffer overflow exploitation involves overwriting key data structures or returning to 
specific places in memory, ASLR should, in theory, prevent reliable exploitation 
because attackers can no longer rely on static addresses. Although ASLR is a form of 
security by obscurity, it's a highly effective technique for preventing exploitation, 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
207 
especially when used with some of the other preventative technologies already 
discussed. 
Limitations 
Defeating ASLR essentially relies on finding a weak point in the ASLR implementation. 
Attackers usually attempt to adopt one of the following approaches: 
Find something in memory that's in a static location despite the ASLR. No 
matter what the static element is, it's probably useful in one way or another. 
Examples of statically located elements might include base executables that 
don't contain relocation information (so the loader might not be able to 
relocate it), specialized data structures present in all mapped processes (such 
as the Windows PEB and the Linux vsyscall page), the loader itself, and 
nonrelocatable shared libraries. If ASLR fails to randomize any specific part of 
the process, it can be relied on and potentially used to undermine the ASLR 
protection. 
Brute force where possible. In a lot of cases, data elements are shifted around 
in memory but not by a large amount. For example, the current Linux 
exec-shield ASLR maps the stack at a random location; however, closer 
inspection of the code shows these mappings include only 256 possible 
locations. This small set of possible locations doesn't provide for a large 
randomness factor, and most ASLR implementations don't randomize a child 
process's memory layout. This lack of randomness creates the potential for a 
brute force attack when a vulnerable service creates child processes to service 
requests. An attacker can send requests for each possible offset and 
eventually achieve successful exploitation when the correct offset is found. 
SafeSEH 
Modern Windows systems (XP SP2+, Windows 2003, Vista) implement protection 
mechanisms for the SEH structures located on the stack. When an exception is 
triggered, the exception handler target addresses are examined before they are 
called to ensure that every one is a valid exception handler routine. At the time of this 
writing, the following procedure determines an exception handler's validity: 
1.  Get the exception handler address, and determine which module (DLL or 
executable) the handler address is pointing into. 
2.  Check whether the module has an exception table registered. An exception table 
is a table of valid exception handlers that can legitimately be entered in an 
_EXCEPTION_REGISTRATION structure. This table is optional and modules might omit 
it. In this case, the handler is assumed to be valid and can be called. 
3.  If 
the 
exception 
table 
exists 
and 
the 
handler 
address 
in 
the 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
208 
_EXCEPTION_REGISTRATION structure doesn't match a valid handler entry, the 
structure is deemed corrupt and the handler isn't called. 
Limitations 
SafeSEH protection is a good complement to the stack cookies used in recent 
Windows releases, in that it prevents attackers from using SEH overwrites as a 
method for bypassing the stack cookie protection. However, as with other protection 
mechanisms, it has had weaknesses in the past. David Litchfield of Next Generation 
Security Software (NGSSoftware) wrote a paper detailing some problems with early 
implementations of SafeSEH that have since been addressed (available at 
www.ngssoftware.com/papers/defeating-w2k3-stack-protection.pdf). Primary 
methods for bypassing SafeSEH included returning to a location in memory that 
doesn't belong to any module (such as the PEB), returning into modules without an 
exception table registered, or abusing defined exception handlers that might allow 
indirect running of arbitrary code. 
Function Pointer Obfuscation 
Long-lived function pointers are often the target of memory corruption exploits 
because they provide a direct method for seizing control of program execution. One 
method of preventing this attack is to obfuscate any sensitive pointers stored in 
globally visible data structures. This protection mechanism doesn't prevent memory 
corruption, but it does reduce the probability of a successful exploit for any attack 
other than a denial of service. For example, you saw earlier that an attacker might be 
able to leverage function pointers in the PEB of a running Windows process. To help 
mitigate this attack, Microsoft is now using the EncodePointer(), DecodePointer(), 
EncodeSystemPointer(), and DecodeSystemPointer() functions to obfuscate many of 
these values. These functions obfuscate a pointer by combining its pointer value with 
a secret cookie value using an XOR operation. Recent versions of Windows also use 
this anti-exploitation technique in parts of the heap implementation. 
Limitations 
This technology certainly raises the bar for exploit developers, especially when 
combined with other technologies, such as ASLR and nonexecutable memory pages. 
However, it's not a complete solution in itself and has only limited use. Attackers can 
still overwrite application-specific function pointers, as compilers currently don't 
encode function pointers the application uses. An attacker might also be able to 
overwrite normal unencoded variables that eventually provide execution control 
through a less direct vector. Finally, attackers might identify circumstances that 
redirect execution control in a limited but useful way. For example, when 
user-controlled data is in close proximity to a function pointer, just corrupting the low 
byte of an encoded function pointer might give attackers a reasonable chance of 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
209 
running arbitrary code, especially when they can make repeated exploit attempts 
until a successful value is identified. 
7.1.5 Assessing Memory Corruption Impact 
Now that you're familiar with the landscape of memory corruption, you need to know 
how to accurately assess the risk these vulnerabilities represent. A number of factors 
affect how exploitable a vulnerability is. By being aware of these factors, code 
auditors can estimate how serious a vulnerability is and the extent to which it can be 
exploited. Can it be used just to crash the application? Can arbitrary code be run? The 
only way to know for certain is to write a proof-of-concept exploit, but that approach 
can be far too time consuming for even a moderate-sized application assessment. 
Instead, you can reasonably estimate exploitability by answering a few questions 
about the resulting memory corruption. This approach is not as definitive as a 
proof-of-concept exploit, but it's far less time consuming, making it adequate for 
most assessments. 
The Real Cost of Fixing Vulnerabilities 
You might be surprised at the amount of resistance you can encounter when 
disclosing vulnerabilities to vendorseven vendors who specifically hired you 
to perform an assessment. Vendors often say that potential memory 
corruption bugs aren't exploitable or aren't problems for some reason or 
another. However, memory corruption affects an application at its most 
basic level, so all instances need to be given serious consideration. Indeed, 
history has shown that attackers and security researchers alike have come 
up with ingenious ways to exploit the seemingly unexploitable. The old adage 
"where there's a will, there's a way" comes to mind, and when it comes to 
compromising computer systems, there's definitely a lot of will. 
Therefore, most auditors think that software vendors should treat all issues 
as high priority; after all, why wouldn't vendors want their code to be as 
secure as possible and not fix problems as quickly as they can? The truth is 
that there's always a price attached to fixing software bugs, including 
developer time, patch deployment cost, and possible product recalls or 
reissues. Consider, for example, the cost of distributing a vulnerability 
update to a widely deployed embedded system, like a smart card or cell 
phone. Updating these embedded systems often requires hardware 
modifications or some other intervention by a qualified technician. A 
company would be irresponsible to incur the costs associated with an update 
if it doesn't have a reasonable expectation that the bug is exploitable. 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
210 
Where Is the Buffer Located in Memory? 
The location of the buffer in memory is important; it affects what choices an attacker 
has when trying to seize control of the process. Variables are stored mainly in three 
memory areas: stack, heap, and persistent data (including static and global 
variables). However, different OSs often further segment these three regions or add 
new regions. There might be distinctions between initialized and uninitialized global 
data, or the system might place thread local storage (TLS) at a special location. Also, 
shared libraries typically have their own uninitialized and initialized data mapped into 
the process memory immediately after their program code. When determining 
exploitability, you need to keep track of where the memory corruption occurs and 
what special considerations apply. This task might include conducting some additional 
research to understand the process memory layout for a particular OS. 
What Other Data Is Overwritten? 
Memory corruption might not be isolated to just the variables an attacker is targeting. 
It can also overwrite other variables that might complicate the exploitation process. 
This happens commonly when trying to exploit corruption on the process stack. You 
already know that vulnerabilities in the stack segment are most often exploited by 
overwriting the saved program counter. It's not always that straightforward, however; 
often attackers overwrite local variables before overwriting the saved program 
counter, which can complicate exploitation, as shown in Listing 5-4. 
Listing 5-4. Overflowing into Local Variables 
int dostuff(char *login) 
{ 
    char *ptr = (char *)malloc(1024); 
    char buf[1024]; 
    ... 
    strcpy(buf, login); 
    ... 
    free(ptr); 
    return 0; 
} 
This example has a small issue: Although attackers can overwrite the saved program 
counter, they also overwrite the ptr variable, which gets freed right before the 
function returns. This means attackers must overwrite ptr with a location in memory 
that's valid and doesn't result in a crash in the call to free(). Although this method 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
211 
makes it possible for attackers to exploit the call to free(), the attack method is more 
complicated than a simple program counter overwrite (especially if there's no 
user-controlled data at a static location in memory). 
When evaluating the risk of buffer overflow vulnerabilities, pay special attention to 
any variables in the overflow path that mitigate exploit attempts. Also, remember 
that the compiler might reorder the variable layout during compilation, so you might 
need to check the binary to confirm exploitability. 
Note 
Sometimes more than one function return is required for a bug to be exploitable. For 
example, OSs running on Sun SPARC CPUs often require two function returns because 
of the way SPARC register windows work. 