done without
than
can
be
the
Our strategy is to instead inject a micro virtual machine
(MicroVM) in the region of memory where we know
the key masks. The MicroVM executes the worm code
by moving small chunks of it at a time into the region
where the key masks are known. The next subsections
describe the MicroVM and how worm code can be
written to work within our MicroVM. In order to make
the MicroVM as small as possible we place restrictions
and additional burdens on the worm code.   
4.1 MicroVM Implementation 
The MicroVM is illustrated in Figure 6. At the heart of
the MicroVM is a loop that repeatedly reads a block of
worm code into a region of memory where the masks
154
14th USENIX Security Symposium
USENIX Association
_start:
save worm address in ebp
move stack frame pointer
read_more_worm:
s
k
s
a
m
y
e
k
n
w
o
n
k
WormIP = 0
copy worm code
update worm IP
save VM registers
load worm registers
22−byte worm
execution buffer
save worm registers
load VM registers
jmp read_more_worm
worm_code:
worm IP
.
.
.
.
.
begin_ worm_data:
register data
.
.
.
host key masks
.
.
.
guessed target key masks
.
.
.
other worm data
.
.
.
Figure 6.  MicroVM.
are known and executes that code. The code (shown in
Appendix A) is 98 bytes long (including the 22 bytes of
space reserved for executing worm code).  
Before starting the execution loop, the MicroVM in-
itializes the worm instruction pointer (WormIP) to
contain 0 to represent the beginning of the worm code.
The WormIP stores the next location to read a block of
worm code. Next, a block of worm code is fetched by
copying the bytes from the worm code (from the
WormIP) into an execution buffer inside the MicroVM
itself, so that execution can simply continue through
the worm code and then back into the MicroVM code
without needing a call. The addresses of the beginning
of the worm code and worm data space are hardcoded
by the worm code into the MicroVM when it
is
deployed on a new host.
No encryption is necessary when worm code is copied
into the execution buffer, since the worm code was
already encrypted with known key masks for the worm
execution buffer locations where it will be loaded into
the worm execution buffer.
Just before the execution of the worm block,
the
MicroVM pushes its registers on the stack and then
restores the worm’s registers from the beginning of the
worm data region. After the buffer’s execution, the
MicroVM saves the worm’s registers to the worm data
In the last step,
region.
the MicroVM restores its
registers and then jumps back to the beginning of the
MicroVM code to execute the next block of worm
code.  
4.2 Worm Code
To work in the MicroVM, the worm code is divided
into blocks matching the size of the worm execution
buffer (22 bytes in our implementation). No instruction
can be split across these blocks, so the worm code is
padded with nops as necessary to prevent instructions
from crossing block boundaries.
The worm code
cannot leave data on the execution stack at the end of a
block, since the MicroVM registers are pushed on the
stack just before the worm execution begins. To use
persistent data, the worm must write into locations in
the worm data space instead of using the execution
stack.
The most cumbersome restrictions involve jumps. Any
jump can occur within a single worm block, but
jumps
that transfer control to locations outside the buffer must
be done differently since all worm code must executed
at known mask locations in the worm buffer. Our
solution is to require that all jumps must be at the end
of a worm code block, and all jump targets must be to
the beginning of a worm code block.
Instead of
actually executing a jump, the worm code updates the
value of the WormIP (which is now stored in a known
location in memory, and will be restored when the
MicroVM resumes) to point to the target location, and
then continues into the MicroVM code normally so the
target block will be the next worm code block to
execute. To implement a conditional jump, we use a
short conditional
jump with the opposite condition
within the worm buffer to skip the instruction that
updates the WormIP when the condition is unsatisfied. 
4.3 Propagation
To propagate, the worm uses the techniques described
in Section 3 to acquire enough key bytes to hold the
MicroVM. Those key bytes are stored in the worm
data region. The MicroVM code is 98 bytes long so at
least 98 key bytes are needed. We may need to acquire
a few additional key bytes to avoid needing to place
null bytes in the attack code.
If the mask found for a
given location matches the bytes we want to put there,
we instead put a nop instruction at that location and
obtain an extra key byte. As long as the masks are
randomly distributed, two or fewer will be sufficient
USENIX Association
14th USENIX Security Symposium
155
over 99% of the time, so we can nearly always inject
the worm once 100 key bytes have been acquired. 
To generate an instance of the worm for a new key, we
XOR out the old key bytes from the worm code and
XOR in the new key bytes. To support this, the propa-
gated worm data includes th host’s acquired mask
bytes. As with the injected MicroVM code, we need to
worry about the impossibility of injecting null bytes.
We insert nops in the injected worm code as necessary
If the added nops would cause a
to avoid null bytes.
worm code block to exceed the available space, we
need to create a new block and move the overflow in-
structions into that block.
Jump targets in the worm
code may need to be updated to reflect insertion of the
new block.
5.  Results
To test our attack we built a small echo server with a
buffer overflow vulnerability. The application waits
for a client to connect. When the client connects, the
server forks a process to process its request. The next
step is to call a method which has a local buffer that
can be overflowed. This method reads the request from
the client and writes back an acknowledgment message.
After
the application sends a
termination message (“Bye”) and closes the socket.
Although we use a contrived vulnerability to make the
attack easier to execute and analyze, similar vulnerabil-
ities are  found in real applications.  
this method call
5.1 Attack Client
The attack client structure is the same for both the jump
and return attacks. For each guess attempt, the attack
client (1) opens a socket to the server, (2) builds an
attack string, (3) writes it to the socket, (4) reads the
acknowledgment, (5) installs an alarm signal handler,
(6) sets up an alarm, and (7) reads the termination
message or handles the alarm signal. The return attack
recognizes a possibly correct guess when it receives the
termination message in step 7; the jump attack  recogni-
zes a possibly correct guess when the alarm signal
handler is called before the socket is closed.  
The attack strategy used for different key bytes is
depicted in Figure 7. The number of key bytes guessed
by the attack is denoted by size. For vulnerabilities
suitable for the return attack, the first eight positions
are guessed using the return instruction. The rest are
guessed using the extended short jump attack (expected
23.5 attempts per byte). For the jump attack, the first
0
short jump
0
short jump
.
.
.
size−9
size−8
short jump
near return
.
.
.
size−1
near return
.
.
.
size−12
size−11
short jump
near jump
.
.
.
size−5
size−4
size−3
size−2
size−1
near jump
infinite loop 8
infinte loop 8
infinite loop 16
infinite loop 16
Return Attack
Jump Attack
Figure 7.  Guessing strategies.
two key bytes acquired have positions size-1 and size-2.
We guess those two bytes simultaneously, using the 2-
byte jump instruction to create an infinite loop. The
next two bytes are guessed separately using the jump
instruction to create an infinite loop. After the fourth
byte is acquired, we do not (intentionally) create any
more infinite loops. For the next six bytes, we use near
jump, with a worst case of 1024 attempts per byte.
After this position, we use the extended short jump
attack. 
For the attack client to be efficient there are some
constraints on the address where the attack starts. For
both attacks the address has to be far enough from the
next smaller address which has null as its last byte so
we have enough space to place two short jump instruc-
tions, and a sufficient number of illegal opcodes. As
long as the vulnerable buffer is sufficiently large, the
attack client can find a good location to begin the
attack. 
We ran our client normally, not inside the MicroVM.
Hence, our results correspond to the time needed to
launch the initial attack on the first ISR-protected
server.
later
infections because of the additional overhead associated
with executing in the MicroVM.
The attack time would increase for
protected
by RISE [3].
5.2 Target
We executed our attack on our constructed vulnerable
server
The RISE
implementation presents a major difficulty in executing
our attack because of the way it
implements fork,
pthreads and randomization keys. This necessitated a
small modification to RISE in order for our attack to
succeed. Other ISR implementations, however, may be
vulnerable
this
modification.
attack without
to
our
needing
RISE uses a different key to randomize an application
each time it is started. Since the attack causes the
156
14th USENIX Security Symposium
USENIX Association
server to crash, the attack can only work against a
server that forks separate processes to handle client
requests. Valgrind [16] (the emulator modified to
implement RISE) implements pthreads to use only one
process. Thus, if the attack crashes a thread, then the
entire server will crash and the next execution will use
a different randomization key. So, our attack will only
work against a server that forks separate processes. 
When RISE loads an application, a cache data structure
is initialized that holds the key mask for each instruc-
tion address that has been loaded. There is a different
randomization key byte for each byte in the text
segment, and the mask value is stored in the cache the
first
time the corresponding instruction address is
loaded.
The fork call is forwarded to the operating system and
results in a new child process running the emulator.
When the injected instructions execute,
the child
process will determine that no mask has been initialized
for the address on the stack and it will generate a new
one. Hence, the child process will share the same ran-
domization key for the addresses already loaded in
memory at fork time, but for the addresses it accesses
later it will use it’s own key. This is problematic since
the incremental attack only works if multiple attempts
can be launched attacking the same key.
Perhaps an attacker could control the execution enough
to ensure that the necessary masks are initialized before
the child process forks to ensure they would be the
same on all executions. This would only happen,
however, if the server legitimately ran code on the
stack before reaching the vulnerability. Hence, the
RISE implementation of ISR is not vulnerable to our
attack.  
In order to experiment with our attack, we modified
RISE to initialize the masks for all used instruction
addresses before the child process forks to ensure that
all child processes have the same key. Obviously, a
real attacker would not have this opportunity.  
In addition to the problems caused by the emulator
itself, we encountered others caused by the operating
system. The Fedora Linux distribution has address
space layout randomization enabled by default.  For our
experiments, we disabled this defense. Attacks on
systems using both address and instruction randomiza-
tion pose additional challenges that are beyond the
scope of this paper.
5.3 Experimental Results
Table 1, Figure 8 and Figure 9 summarize the results
from our experiments. The target and client ran on
separate Linux dual AMD Athlon XP 2400+ machines.
connected to the same network switch. For key lengths
up to 128, we executed 100 trials; for longer keys, we
executed 20 trials. In all cases, our attacks are nearly
always able to obtain the correct key and the attack
completes in under one hour, even for acquiring a
4096-byte key using the jump attack. A successful
attack is an execution in which the attack client
correctly guesses the desired number of key bytes.
Every key byte must be correct for us to consider the
attack a success.  
The experiments confirm the analytical predictions
regarding the decrease of number of attempts per byte
as key length increases. After breaking the first 12
bytes, fewer than 24 guess attempts are required per
byte to acquire additional key bytes. On average, we
can break a 100-byte key (enough to inject our
MicroVM code) in just over six minutes with the jump
attack. The return attack is faster, and requires less
than two minutes. The difference is the additional
approximately 4000 expected attempts the jump attack
needs to guess the first two bytes simultaneously. The
other difference is the increased time per attempt
needed for the jump attack stemming from the infinite
loops running on the server.  The return attack produces
an infinite loop on the server only in the unlucky
circumstances when a random instruction happens to
produce an infinite loop.
the
average number of infinite loops created during a return
attack is 0.76. Rarely, we may be unlucky and create
many infinite loops with the return attack (such as was
the case for the extreme maximum time value in
breaking a 4-byte key in Figure 8). The jump attack