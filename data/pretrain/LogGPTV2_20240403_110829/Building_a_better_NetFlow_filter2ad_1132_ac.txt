1Since this is a very unlikely scenario, especially for fast
backbone links, in actual practice Adaptive NetFlow will
never use more than a small percentage of the processor.
Even if the router receives this unfavorable traﬃc mix due to
a massive ﬂooding attack, ANF will keep the processor fully
loaded only for a short time until it decreases the sampling
rate in response to the memory being consumed.
Figure 5: ANF limits memory usage during a DoS
attack. While NetFlow’s memory consumption in-
creases during a DoS attack our Adaptive NetFlow
keeps its memory usage bounded.
measurement bin with the highest sampling rate the proces-
sor can support exceeds the tens to hundreds of megabytes
of memory typically reserved for ﬂow records.
Instead of
choosing the sampling rate in advance, ANF dynamically
decreases the sampling rate until it is low enough for the
ﬂow records to ﬁt into memory. Figure 4 shows how this
process ﬁnds diﬀerent sampling rates for normal traﬃc and
for a DoS attack.
Traﬃc analysis multiplies the measured traﬃc by the in-
verse of the sampling rate to estimate the actual traﬃc,
but if we keep changing the sampling rate while the ﬂow
records count the traﬃc, it is hard to determine what sam-
pling rate to use as a basis for this compensation during
analysis. To avoid this problem, we need to renormalize
existing ﬂow entries when we decrease the sampling rate.
The renormalization process is equivalent to stopping the
operation of NetFlow and going through all records to ad-
just the byte and packet counters to reﬂect the values they
would have had if the new sampling rate had been in eﬀect
from the start of the bin. This way traﬃc analysis needs
to know only the ﬁnal sampling rate. Renormalization also
removes the ﬂow entries for which no packets would have
been sampled with the new sampling rate. By freeing en-
tries, renormalization ensures that there is enough memory
to accommodate the records of new ﬂows that appear until
the end of the bin. Figure 5 illustrates how this eﬀectively
caps the memory usage during a DoS attack. The actual
renormalization used by ANF does not require NetFlow to
stop its operation, but operates concurrently. Section 2.2.1
gives a detailed description of how our eﬃcient renormaliza-
tion works and Section 2.2.2 explains how we use eﬃcient
and exact computations of the number of entries removed
to ﬁnd the new sampling rate that guarantees that renor-
malization removes enough entries to keep the memory from
ever ﬁlling.
If the actual sampling rate is dynamic, one cannot ensure
that it is the same for all routers nor even for diﬀerent time
bins at the same router. This does not cause problems with
combining data from diﬀerent bins or from multiple sources
(e.g. combining the 60 one minute bins to get the traﬃc
for the whole hour, or combining the traﬃc of many routers
to get the traﬃc of a PoP) because we can simply add the
counters from the ﬂow records after having divided them by
the respective sampling rates.
By adapting the sampling rate we ensure that ANF gen-
erates a ﬁxed number of ﬂow records. It is useful to quantify
the accuracy of the analysis results one can obtain from a
ﬁxed number of records. Lemma 1 shows that, when esti-
mating packets and bytes in arbitrary traﬃc aggregates that
constitute a certain fraction of the total traﬃc, the worst
case relative standard deviation depends only on the num-
ber of entries and not on the speed of the link. More simply
put this means that you can slice and dice the data in any
way, and as long as your slices are no smaller than a certain
percentage of the pie, the relative errors of the estimates are
small. For example, let’s say we use a sampling rate that
produces 100,000 ﬂow entries, and network A accounts for
10% of the total packets, we will be able to measure its traf-
ﬁc with a relative standard deviation of at most 1%. If it
accounts for 10% of the bytes, while the average packet size
is 400 bytes and the maximum size 1500, we will be able to
measure its traﬃc with an average relative standard devia-
tion of at most 1.94% (irrespective of the size of the packets
of network A).
Lemma 1. From the NetFlow records produced with in-
dependent random sampling at a rate at which the expected
number of ﬂow records is M , we can estimate the traﬃc of
any aggregate amounting to a fraction f of the total traf-
p
1/(M f )
ﬁc with a relative standard deviation of at most
p
smax/(savgM f )  fi
fi = fi + 1
return true
else
return f alse
endif
Figure 7: Calls to the random number generator not
needed for each renormalized entry. By associating a
random seed and a small amount of other state with
each histogram bin, we can perform the per entry
processing using only integer arithmetic.
much larger than any of the others and together with
the next few ones it accounts for more than 90% of
the entries. DDoS attacks only increase this ﬁrst bin
because all sampled attack packets generate 1 packet
ﬂows. Therefore in practice setting the number of his-
togram bins to 32 is more than suﬃcient;
• Histograms with bin sizes increasing exponentially at
a slow rate (e.g. each histogram bin is 10% larger than
the previous one) give estimates for the number of bins
freed with small bounded error and the number of bins
they need is logarithmic in P/M . Since this solution is
not necessary for conﬁgurations we consider realistic,
we do not pursue it any further.
As discussed so far, renormalization requires a random
decision for each entry, but calls to the random number gen-
erator are expensive. With periodic 1 in N sampling as an
inspiration, we use the histogram bins to derive a more eﬃ-
cient method for updating the packet entries, without calls
to the random number generator for each entry. For each
histogram bin, we keep a counter for the number of entries
in that bin visited for renormalization vi a and the number
of entries freed fi. Let ri = 1 − ri be the probability of
removing an entry with a packet counter of i and si a small
random seed between 0 and 1 initialized before the start of
the normalization. Figure 7 gives the criterion used at each
entry to decide whether to remove it or not. Using the fact
that all sampling probabilities are of the form 1/N where N
is an integer, this decision can be implemented using only
integer additions, multiplications, and comparisons.
It is
easy to extended eﬃcient update to entries from other bins
for which we need to decide which of two possible values to
update the counter to. We can even extend it to the last
histogram bin counting ﬂows with 32 packets or more, but
we also need to perform an integer division for entries from
this bin. Since the expected value for each packet counter
does not change with our eﬃcient simpliﬁed update method,
we introduce no bias. In the technical report [14] we also
show that eﬃcient update does not increase the variance of
the estimates for aggregates.
Using the random seeds in the histogram bin, we can com-
pute the exact number of entries freed in advance. This al-
lows us to quickly ﬁnd the exact sampling rate for which
renormalization frees the desired number of entries. Can it
happen that during normalization the number of freed en-
tries is temporarily smaller than the number of new entries,
due to the random order in which normalization processes
the entries? It can, and exact modeling of this phenomenon
is complex, but due to the fact that sampling with replace-
ment has higher variance than sampling without replace-
ment, we can upper bound the deviation by the deviation of
a binomial process of T random decisions with probability
p
M/T (T > M is the threshold for starting renormalization).
M (T − M )/T extra entries is enough to ac-
Thus leaving 3
commodate these random variations with probability much
larger than 99.87% even for the severest of DoS attacks.
2.3 Conﬁguration example for Adaptive Net-
Flow
This section provides an example for conservatively con-
ﬁguring Adaptive NetFlow on an OC-48 interface (2488.32
Mbps). When choosing the conﬁguration parameters, our
aim is to ensure that the processor and the memory avail-
able for the ﬂow cache are not overwhelmed under any pos-
sible traﬃc pattern. The work of ﬁnding the right values
for the various parameters is the responsibility of the router
manufacturer. All the router operator has to do is to specify
the reported number of ﬂow records M desired for each one
minute measurement bin. If the memory on the line card is
not suﬃcient, the router can override the parameter with a
lower value. ANF guarantees that it will never report more
ﬂow records and it will report fewer only for pathological
traﬃc mixes such as fewer than M large ﬂows generating all
the traﬃc or an extremely lightly loaded link.
The parameters the router manufacturer needs to deter-
mine are: the maximum sampling rate p0 = 1/N0, the av-
erage number of renormalization operations per processed
packet when renormalization is in progress and the actual
number of ﬂow cache entries the router needs given the pa-
rameter M . By proﬁling the processor on the line card, the
router manufacturer ﬁnds that the average time to process
a sampled packet is tp = 3.4µs and renormalizing an entry
takes on average tr = 1.5µs.2 We ﬁrst compute the initial
sampling rate and we want it as high as possible so that we
get accurate results even on lightly loaded links. To keep up
before the ﬁrst renormalization, the per packet processing
time for a link fully loaded with minimum size packets tmin
could be as low as tp, but we choose tmin = tp + tr = 4.9µs
to reduce the amount of memory needed. At a minimum
size of 40 bytes for the IP packets to which we add 4 bytes
of lower layer SONET CHDLC overhead, for our OC-48 we
obtain a maximum sampling rate of 1 in 35 packets.
After the ﬁrst renormalization starts we will process pack-
ets at a lower rate because the sampling rate decreases, but