settings, TCP Cubic and TCP New Reno are slow to
adapt to varying channel conditions and therefore in-
cur high buﬀering delays while Verus quickly adapts to
channel variations and experiences much lower buﬀer-
Table 1 shows Jain’s fairness index for all three pro-
tocols. We report the average fairness index across all
ﬁve diﬀerent scenarios. Our results show that although
TCP Cubic achieves high fairness among the scenarios
with a small number of users, the fairness drops signiﬁ-
cantly under high contention (achieving about 70% fair-
ness). In contrast, Verus shows slightly lower fairness
compared to TCP Cubic for scenarios with a low num-
ber of users, while maintaining reasonable fairness at
higher contention. TCP NewReno is almost consistent
with the fairness it achieves across all scenarios, but
achieves marginally lower fairness compared to Verus
for scenarios with low number of users.
7. VERUS MICRO-EVALUATION
While the previous section detailed a macro-evaluation
of Verus,
in this section we focus on speciﬁc micro-
evaluations of Verus to describe its fairness and adap-
tation properties. All the evaluations in this section are
10−210−1Delay(ms)012345Throughput(Mbps)TCPCubicTCPNewRenoVerus(R=2)Verus(R=4)Verus(R=6)10−210−1Delay(ms)012345Throughput(Mbps)TCPCubicTCPNewRenoVerus(R=2)Verus(R=4)Verus(R=6)10−210−1Delay(ms)012345Throughput(Mbps)TCPCubicTCPNewRenoVerus(R=2)Verus(R=4)Verus(R=6)518performed in a simpliﬁed network conﬁguration consist-
ing of a dumbbell topology with three laptops connected
to an Ethernet Gigabit switch, which in turn is con-
nected to a server. The server outgoing bandwidth is
controlled through the Linux Traﬃc Control (tc) tool.
The tool is also used to emulate delays for each of the
clients, this is used to conﬁgure the RTT.
Rapidly Changing Networks
We wanted to measure how quickly Verus can adapt to
high channel variations. This experiment is conﬁgured
so that the network condition would change suddenly.
Every ﬁve seconds the whole network parameters, i.e.
link capacity, network RTT, and loss rate, are changed.
We have considered two variations of the experiment:
where in the ﬁrst version the network link capacity var-
ied between 10 Mbps and 100 Mbps. whereas, in the
second version, the link capacity varied between 2 Mbps
and 20 Mbps. The reason behind the two versions
was because the Sprout implementation bandwidth is
capped at 18 Mbps. In both scenarios, the RTT was
varied between 10 ms and 100 ms, and the loss rate
between 0% and 1%.
Figure 11a shows the throughput over time for the
ﬁrst experiment where the gray shaded area represents
the available link capacity. We observe that Verus out-
performs the other protocols and manages to adapt very
quickly to the rapid network changes. Understandably,
Sprout does not perform well because of the bandwidth
cap introduced by the Sprout implementation. Fig-
ure 11b shows the throughput and delay results of Verus
compared to Sprout with a lower link capacity varia-
tion up to 20 Mbps. Here, we observe that Sprout per-
forms better than before, but Verus still achieves higher
throughput on average than Sprout.
Newly Arriving Flows
To understand the impact of the arrival of new ﬂows,
we consider a situation where eight competing Verus
ﬂows share a 90 Mbps bottleneck link. The experiment
is conﬁgured so that every 30 seconds a new Verus ﬂow
starts, thus increasing the number of competing ﬂows
over time. Figure 12 shows the throughput of seven
Verus clients over time. During the ﬁrst 30 seconds
when only one Verus ﬂow is active, the ﬂow is fully uti-
lizing the 90 Mbps link. We observe that Verus quickly
adapts to the arrival of new ﬂows and also reaches good
fairness across competing Verus ﬂows when new ﬂows
arrive and depart.
(a) Scenario I
Figure 12: Verus intra-fairness among seven ﬂows
Varying RTTs
To understand the impact of varying RTTs on Verus
ﬂows, we consider a simple experiment where three com-
peting Verus ﬂows with three diﬀerent RTTs of 20 ms,
50 ms and 100 ms share a 60 Mbps bottleneck link.
Figure 13 shows the temporal variation in the through-
put of the diﬀerent Verus ﬂows. We observe that the
throughput of Verus ﬂows is independent of the RTT
of the ﬂows which is indicative that the Verus fairness
model is close to Max-Min fairness. Given that delay-
based protocols use non-linear control mechanisms, these
protocols are harder to model analytically than conven-
tional window-based protocols. We plan to develop a
model to more fully characterize the behavior of Verus
and other delay-based control protocols in future work.
Verus vs. TCP
One crucial issue when a new congestion control proto-
col is introduced is fairness to legacy TCP. We inves-
tigated how several Verus ﬂows share an Ethernet bot-
tleneck with several other TCP Cubic ﬂows (since TCP
(b) Scenario II
Figure 11: Rapidly changing network evaluations under
two diﬀerent link capacities
0100200300400500Time(s)020406080100Throughput(Mbps)VerusTCPCubicTCPVegasSprout0100200300400500Time(s)05101520Throughput(Mbps)VerusSprout0100200300400500Time(s)0100200300400500Delay(ms)VerusSprout050100150200Time(s)020406080100Throughput(Mbps)Verus1Verus2Verus3Verus4Verus5Verus6Verus7519Figure 13: Verus intra-fairness with 3 diﬀerent RTTs
Figure 15: Verus with and without updating delay curve
Cubic is currently used as the standard in most TCP
installations). The experiment consisted of three Verus
and three TCP Cubic ﬂows sharing a link capacity of
60 Mbps.
At the beginning of the experiment, every 30 seconds
one new Verus ﬂow is added to the network. Once all
three Verus ﬂows are present, a new TCP Cubic ﬂow
is added to the network every 30 seconds (at time 90,
120 and 150 seconds). The throughput comparison over
time is shown in Figure 14. Our results show that Verus
shares the bottleneck capacity equally with TCP Cubic.
Figure 14: Verus fairness vs. TCP Cubic
Eﬀect of Verus Delay Curve
In order to evaluate the eﬀect of the delay proﬁle curve,
we compared two scenarios: one where the delay proﬁle
curve would update normally every second, and the sec-
ond where Verus uses the ﬁrst curve it generates without
updating it. Figure 15 shows the results of this simu-
lation for all of our ﬁve diﬀerent collected traces. The
results clearly show that updating the curve has an im-
pact on performance due to the fact that the cellular
channel changes and Verus needs to update its operat-
ing point on the curve based on these changes.
Short Flows
Short ﬂows are a dominant feature in normal network
traﬃc due to the nature of the commonly retrieved con-
tent. Although Verus is not speciﬁcally designed to cope
with short ﬂows, it is naturally able to handle short con-
nections. When considering a short ﬂow that does not
progress beyond slow start, Verus behaves like legacy
TCP due to the same slow start mechanism. After slow
start, Verus uses the recorded delay proﬁle to adapt
quickly as it does with channel changes.
8. CONCLUSIONS
In this paper, we presented Verus, an adaptive explo-
ration congestion control protocol that is tailored for
unpredictable cellular networks. Through continuous
exploration using delay measurements and a delay pro-
ﬁle, Verus adapts to both rapidly changing cellular con-
ditions and to competing traﬃc. We tested Verus under
a variety of experimental scenarios through simulation
and real-world experiments over 3G and LTE networks.
We show that in cellular networks Verus achieves higher
throughput than TCP Cubic while maintaining a dra-
matically lower end-to-end delay, particularly over LTE.
Verus also outperforms very recent congestion control
protocols for cellular networks like Sprout under rapidly
changing network conditions. In the future, we plan to
experiment with other rapid adaptation mechanisms to
theoretically characterize the behavior of Verus and de-
velop a kernel implementation of Verus.
9. ACKNOWLEDGMENTS
We would like to thank Ali Raza for his help run-
ning measurements and experiments. We would also
like to thank our shepherd Sachin Katti and the anony-
mous reviewers for their valuable feedback. We also
want to extend our gratitude to Keith Winstein for his
help with Sprout. Thomas P¨otsch has been funded by
the International Graduate School for Dynamics in Lo-
gistics, University of Bremen, Germany. We thank the
the NYU Abu Dhabi Research institute and the Cen-
ter for Technology and Economic Development (CTED)
for supporting Lakshminarayanan Subramanian on this
research work.
10. REFERENCES
[1] M. Alizadeh, A. Greenberg, D. A. Maltz,
J. Padhye, P. Patel, B. Prabhakar, S. Sengupta,
and M. Sridharan. DCTCP: Eﬃcient Packet
Transport for the Commoditized Data Center.
ACM SIGCOMM, January 2010.
[2] D. Bansal and H. Balakrishnan. Binomial
congestion control algorithms. In Proceedings of
20th Conference of the IEEE Computer and
Communications Societies. INFOCOM 2001,
Volume 2, 2001.
050100150200250Time(s)020406080100Throughput(Mbps)Verus20msVerus50msVerus100ms20406080100120140160180Time(s)010203040506070Throughput(Mbps)Verus1Verus2Verus3TCPCubic1TCPCubic2TCPCubic310−210−1Delay(s)012345Throughput(Mbps)Verus(R=2)Verus(R=2)staticdelayproﬁle520[3] L. S. Brakmo, S. W. O’Malley, and L. L. Peterson.
TCP Vegas: New techniques for congestion
detection and avoidance, volume 24. ACM, 1994.
[4] W. chang Feng, K. G. Shin, D. D. Kandlur, and
D. Saha. The BLUE active queue management
algorithms. IEEE/ACM TRANS.
NETWORKING, pages 513–528, 2002.
[5] D. Cox and L.-R. Dependence. a review.
Statistics: An Appraisal, HA David and HT
David (Eds.), The Iowa State University Press,
Ames, Iowa, pages 55–74, 1984.
[6] M. Dong, Q. Li, D. Zarchy, B. Godfrey, and
M. Schapira. PCC: Re-architecting congestion
control for consistent high performance. 12th
USENIX Symposium on Networked Systems
Design and Implementation (NSDI), 2015.
[7] T. Ekman. Prediction of Mobile Radio Channels -
Modeling and Design. PhD thesis, Signals and
Systems, Uppsala University, Sweden, 2002.
[8] S. Floyd. TCP and Explicit Congestion
Notiﬁcation. SIGCOMM Comput. Commun. Rev.,
24(5), Oct. 1994.
[9] S. Floyd, M. Handley, J. Padhye, and J. Widmer.
Equation-based congestion control for unicast
applications, volume 30. ACM, 2000.
[10] S. Floyd and V. Jacobson. Random early
detection gateways for congestion avoidance.
IEEE/ACM Transactions on Networking, 1(4),
1993.
[11] S. Floyd and V. Jacobson. Random early
detection gateways for congestion avoidance.
IEEE/ACM Transactions on Networking,
1(4):397–413, 1993.
[12] J. Gettys. Buﬀerbloat: Dark Buﬀers in the
Internet. Internet Computing, IEEE, 15(3), May
2011.
[13] S. Ha, I. Rhee, and L. Xu. CUBIC: A New
TCP-friendly High-speed TCP Variant. SIGOPS
Oper. Syst. Rev., 42(5), July 2008.
[14] T. Henderson, S. Floyd, A. Gurtov, and
Y. Nishida. The NewReno modiﬁcation to TCP’s
fast recovery algorithm, April 2012. RFC6582.
[15] J. Huang, F. Qian, Y. Guo, Y. Zhou, Q. Xu,
Z. M. Mao, S. Sen, and O. Spatscheck. An
in-depth study of LTE: eﬀect of network protocol
and application behavior on performance. In
ACM SIGCOMM 2013 Conference, Hong Kong,
China, August 12-16 2013.
[16] V. Jacobson. Congestion avoidance and control.
In Symposium Proceedings on Communications
Architectures and Protocols, SIGCOMM ’88,
pages 314–329, New York, NY, USA, 1988. ACM.
[17] R. Jain. Art of Computer Systems Performance
Analysis Techniques for Experimental Design
Measurements Simulation and Modeling. John
Wiley & Sons, May 1991.
[18] H. Jiang, Y. Wang, K. Lee, and I. Rhee. Tackling
Buﬀerbloat in 3G/4G Networks. In Proceedings of
the ACM Conference on Internet Measurement
Conference (IMC), 2012.
[19] S. Kunniyur and R. Srikant. Analysis and Design
of an Adaptive Virtual Queue (AVQ) Algorithm
for Active Queue Management. In ACM
SIGCOMM, 2001.
[20] W. Lum Tan, F. Lam, and W. Cheong Lau. An
Empirical Study on 3G Network Capacity and
Performance. In Proceedings of the 26th IEEE
International Conference on Computer
Communications. INFOCOM 2007., May 2007.
[21] R. Mittal, J. Sherry, R. Ratnasamy, and
S. Shenker. Recursively Cautious Congestion
Control. In 11th USENIX Symposium on
Networked Systems Design and Implementation
(NSDI 14), pages 373–385, Seattle, WA, Apr.
2014. USENIX Association.
[22] K. Nichols and V. Jacobson. Controlling Queue
Delay. Queue, 10(5), May 2012.
[23] A. Nikravesh, D. R. Choﬀnes, E. Katz-Bassett,
Z. M. Mao, and M. Welsh. Mobile Network
Performance from User Devices: A Longitudinal,
Multidimensional Analysis. In M. Faloutsos and
A. Kuzmanovic, editors, Passive and Active
Measurement - 15th International Conference,
PAM 2014, Los Angeles, CA, USA, March 10-11,
2014, Proceedings, pages 12–22. Springer, 2014.
[24] OPNET Modeler. http://www.opnet.com.
[25] P. Rong, B. Prabhakar, and K. Psounis. CHOKe -
a stateless active queue management scheme for
approximating fair bandwidth allocation. In
Proceedings of 19th Conference of the IEEE
Computer and Communications Societies.
INFOCOM 2000., volume 2, 2000.
[26] R. Schoenen, A. Otyakmaz, and Z. Xu. Resource
Allocation and Scheduling in FDD Multihop
Cellular Systems. In ICC Workshops 2009. IEEE
International Conference on, pages 1–6, June
2009.
[27] S. Shalunov. Low extra delay background
transport. Internet-draft, Internet Engineering
Task Force, 2010.
[28] A. Sivaraman, K. Winstein, P. Thaker, and
H. Balakrishnan. An Experimental Study of the
Learnability of Congestion Control. In ACM
SIGCOMM 2014, Chicago, IL, August 2014.
[29] K. Tan, J. Song, Q. Zhang, and M. Sridharan. A
compound TCP approach for high-speed and long
distance networks. In Proceedings of 25th
Conference of the IEEE Computer and
Communications Societies. INFOCOM, 2006.
[30] A. Venkataramani, R. Kokku, and M. Dahlin.
TCP Nice: A mechanism for background
transfers. ACM SIGOPS Operating Systems
Review, 36(SI), 2002.
521[31] K. Winstein and H. Balakrishnan. End-to-end
Transmission Control by Modeling Uncertainty
About the Network State. In Proceedings of the
10th ACM Workshop on Hot Topics in Networks,
HotNets-X, pages 19:1–19:6, New York, NY, USA,
2011. ACM.
[32] K. Winstein and H. Balakrishnan. TCP Ex
Machina: Computer-generated Congestion
Control. In Proceedings of the ACM SIGCOMM
2013 Conference, 2013.
[33] K. Winstein, A. Sivaraman, and H. Balakrishnan.
Stochastic forecasts achieve high throughput and
low delay over cellular networks. In Proceedings of
the 10th USENIX conference on Networked
Systems Design and Implementation, 2013.
[34] Y. Xia, L. Subramanian, I. Stoica, and
S. Kalyanaraman. One More Bit is Enough.
SIGCOMM 2005, 2005.
[35] Y. Zaki, J. Chen, T. P¨otsch, T. Ahmad, and
L. Subramanian. Dissecting Web Latency in
Ghana. In Proceedings of the ACM Internet
Measurement Conference (IMC), Vancouver, BC,
Canada, 2014.
522