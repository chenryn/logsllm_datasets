# Understanding and Mitigating Packet Corruption in Data Center Networks

## Authors
- Danyang Zhuo, University of Washington
- Monia Ghobadi, Microsoft Research
- Ratul Mahajan, Microsoft Research & Intentionet
- Klaus-Tycho Förster, Aalborg University
- Arvind Krishnamurthy, University of Washington
- Thomas E. Anderson, University of Washington

## Abstract
This paper provides a comprehensive analysis of packet corruption in data center networks, which leads to packet losses and degradation in application performance. By studying 350,000 links across 15 production data centers, we find that the extent of corruption-induced losses is significant and differs markedly from congestion-induced losses. While corruption impacts fewer links than congestion, it imposes a higher loss rate. Additionally, the corruption rate on a link remains stable over time and is not correlated with its utilization.

Based on these observations, we developed CorrOpt, a system designed to mitigate packet corruption. CorrOpt intelligently selects which corrupting links can be safely disabled, ensuring that each top-of-rack switch has a minimum number of paths to reach other switches. It also recommends specific actions (e.g., replacing cables, cleaning connectors) to repair disabled links, based on our analysis of common symptoms and root causes of corruption. Our recommendation engine has been deployed in over 70 data centers of a large cloud provider. Our analysis shows that, compared to current state-of-the-art methods, CorrOpt can reduce corruption losses by three to six orders of magnitude and improve repair accuracy by 60%.

## CCS Concepts
- **Networks**: Network measurement, Network reliability, Data center networks, Network management

## Keywords
- CorrOpt, Packet Corruption, Data Center Networks, Optics, Fault Mitigation

## ACM Reference Format
Danyang Zhuo, Monia Ghobadi, Ratul Mahajan, Klaus-Tycho Förster, Arvind Krishnamurthy, and Thomas Anderson. 2017. Understanding and Mitigating Packet Corruption in Data Center Networks. In Proceedings of SIGCOMM '17, Los Angeles, CA, USA, August 21–25, 2017, 14 pages. https://doi.org/10.1145/3098822.3098849

## Introduction
Packet losses in data center networks (DCNs) can significantly impact applications, leading to substantial financial losses [20, 26, 37]. For example, a packet loss rate above 0.1% can cause RDMA’s throughput to drop by 25% for bulk transfers [36]. For user-facing video traffic, a loss rate of 0.01% can reduce TCP CUBIC’s throughput by 50% [10]. Even sporadic packet losses can cause catastrophic virtual machine reboots [5].

To address this, researchers have explored various approaches to reduce packet loss, including congestion control, active queue management, load balancing, and traffic engineering [2–4, 12, 28, 31, 32, 36]. However, these approaches primarily focus on congestion, which occurs when network load exceeds capacity.

Another significant source of packet loss, packet corruption, has received less attention. Packet corruption occurs when the receiver cannot correctly decode transmitted bits, causing the cyclic redundancy check in the Ethernet frame to fail and forcing the receiver to drop the packet. Recent studies acknowledge packet corruption as a contributor to packet loss [5, 34, 37], but little is known about its extent and characteristics.

This paper presents the first large-scale study of packet corruption in DCNs. We monitored 350,000 switch-to-switch optical links within 15 data centers of a major cloud provider over seven months. Despite the cloud provider's efforts to mitigate corruption, the number of packets lost due to corruption is significant. To improve mitigation techniques, we need a thorough understanding of its characteristics.

We uncover several relevant characteristics of corruption losses and contrast them with those of congestion. For instance, while the loss rate due to congestion varies with link utilization, the corruption rate is relatively stable over time and independent of link utilization. This implies that reducing the load on the link, as in congestion control, will not reduce the packet corruption rate. We also find that, compared to congestion, corruption affects fewer links but imposes higher loss rates on those links. Finally, we find that corruption exhibits weak locality, i.e., the chances of multiple corrupting links being on the same switch or being topologically close are noticeable but low, while congestion exhibits strong locality.

We analyze hundreds of trouble ticket logs to identify common root causes of corruption, ranging from faulty transceivers and switches to poorly installed hardware, damaged optical fiber, and dirty optical connectors. By monitoring the optical layer, we uncover the common symptoms for each root cause.

The prevalent method to mitigate corruption is to disable links with a corruption loss rate above a certain level (e.g., 10−6), provided that the switches to which they attach have at least a threshold number of active uplinks toward the spine of the DCN [26]. This ensures that hosts using the switch have enough leftover capacity. Links are disabled automatically using software that monitors the corruption loss rate. Though it does not repair corrupting links, this software reduces the chances of application traffic experiencing corruption losses. For each disabled link, a maintenance ticket is issued for operators to manually repair the link. The operators attempt to repair the link via a sequence of steps (e.g., clean the optical fiber and connectors; replace the transceiver; replace the cable), based on their expertise and largely independent of the root cause. The link is enabled after each step, and the next step is taken if the previous one did not succeed.

This method has two limitations. First, the criterion for disabling links is greedy and local, missing better opportunities to reduce corruption losses. Second, since the repair strategy is agnostic of the root cause, it often takes multiple steps to eliminate corruption. With the current strategy, the link is fixed in the first step only 50% of the time.

Based on these observations, we developed CorrOpt, a system to mitigate corruption in DCNs. Because the problem of identifying the optimal set of corrupting links to disable, which minimizes corruption losses while meeting capacity constraints, is NP-hard, CorrOpt uses a two-phase approach. First, when a link starts corrupting packets, a fast decision is made on whether the link can be safely turned off. This fast decision allows us to lower corruption losses more effectively than the current method by considering the entire set of paths from top-of-rack switches to the spine, rather than just the adjacent switches. However, this fast decision is not optimal. To approximate optimality, we use a second phase that performs a global optimization to determine the set of links that can be safely disabled. The combination of the two phases allows us to react quickly and optimize later.

CorrOpt also includes a recommendation engine that uses a root-cause-aware approach to propose the right repair for corrupting links. Based on the link's characteristics (i.e., corruption rate, optical transmit power, optical receive power) and the history of actions taken, it generates concrete recommendations for operators on what corrective action is needed. This recommendation engine has been deployed in over 70 DCNs of our cloud provider.

We evaluate CorrOpt using the deployment of the recommendation engine and a trace-based analysis using data from production DCNs. We find that CorrOpt responds to packet corruption quickly and lowers the amount of corruption losses by up to three to six orders of magnitude, while meeting the desired capacity constraints. We also find that our recommendation engine has improved the accuracy of repairing the link at the first attempt from 50% to 80%.

## Extent of Packet Corruption
We demonstrate the need to understand and mitigate packet corruption by quantifying its extent in today’s DCNs. Our analysis considers corruption- and congestion-induced losses in 15 production data centers, focusing on switch-to-switch links. Corruption mitigation, by disabling or routing around corrupting links, is relevant only for such links, not server-to-ToR links. Further, the complexity of repair is a concern only for switch-to-switch links, which are optical and can go long distances; server-to-ToR links, which are electrical and short, simply get replaced. As the data centers in our study use standard designs and physical layer technologies, we expect our findings to be applicable to other data centers as well.

The DCNs in our study have 4,000 to 50,000 links, totaling 350,000. For each link, we use SNMP [11] to query its packet drop, packet error, and total packet counts, as well as its optical power levels every 15 minutes. Our network operators found SNMP to be a reliable and lightweight mechanism for monitoring these counters. The data cover a period of seven months. The results in this section are based on three weeks of data, and the next section looks deeply into one representative week. The rest of the paper uses the entire data set.

Figure 1 shows the number of packets lost per day due to packet corruption and congestion. The DCNs are sorted by size. For confidentiality, the number of packet losses on the Y-axis is normalized with respect to mean congestion per DCN. The error bars represent the standard variation around the mean for packets lost due to corruption on different days.

We see that, while results vary across data centers and days, in aggregate, the number of corruption losses is on par with congestion losses on the switch-to-switch links we study. In other words, for every congestion loss that applications experience, they will experience a corruption loss. Although this graph does not show corruption rate, the next section shows that it can be quite high for some links. This high level of corruption loss happens even though there is already a system to discover and turn off links with corruption. While this system has limitations, which we explain in §5, we estimate that without it, corruption-induced losses would be two orders of magnitude higher.

Our results clearly demonstrate the need for an effective strategy to mitigate corruption in DCNs. Our proposed system, CorrOpt, provides such a strategy. To explain the rationale underlying its design, in the next two sections, we delve more deeply into the nature of corruption and its root causes.

## Characteristics of Packet Corruption
To develop a thorough understanding of packet corruption, we identify the characteristics of corruption and compare them to congestion. Though not our primary focus, our observations can help load balancing and congestion control systems appropriately handle congestion vs. corruption losses when switch counters are not available to distinguish the two.

Corruption impacts fewer links but can be more severe than congestion. Our data reveal that while congestion is a more widespread phenomenon in terms of the links it impacts, packet corruption affects fewer links. We compute the percentage of links with congestion and corruption loss rates above 10−8 and find that the total number of links with corruption is less than 2-4% of those with congestion.2

This difference suggests that a small set of links have high corruption loss rates, given that the number of corruption and congestion losses is similar. Table 1 shows the distribution of links with corruption and congestion in different loss buckets, normalized such that the total in each column adds to 100%. Overall, only a small fraction of links experience high corruption loss rates, but these links impose a significant burden on the network.

(a) Loss rate of one link
(b) Coefficient of variation (CV) of loss rate for all links

**Figure 2: Corruption loss rate is more stable over time than congestion loss rate.**

[Continued...]

---

This revised version aims to provide a clearer, more coherent, and professional presentation of the original text.