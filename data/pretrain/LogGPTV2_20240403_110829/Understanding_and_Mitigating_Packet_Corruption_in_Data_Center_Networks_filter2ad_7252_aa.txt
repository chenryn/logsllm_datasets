title:Understanding and Mitigating Packet Corruption in Data Center Networks
author:Danyang Zhuo and
Monia Ghobadi and
Ratul Mahajan and
Klaus-Tycho F&quot;orster and
Arvind Krishnamurthy and
Thomas E. Anderson
Understanding and Mitigating Packet Corruption
in Data Center Networks
Danyang Zhuo
University of Washington
Klaus-Tycho Förster
Aalborg University
Monia Ghobadi
Microsoft Research
Ratul Mahajan
Microsoft Research & Intentionet
Arvind Krishnamurthy
University of Washington
Thomas Anderson
University of Washington
ABSTRACT
We take a comprehensive look at packet corruption in data center
networks, which leads to packet losses and application performance
degradation. By studying 350K links across 15 production data
centers, we find that the extent of corruption losses is significant
and that its characteristics differ markedly from congestion losses.
Corruption impacts fewer links than congestion, but imposes a
heavier loss rate; and unlike congestion, corruption rate on a link
is stable over time and is not correlated with its utilization.
Based on these observations, we developed CorrOpt, a system to
mitigate corruption. To minimize corruption losses, it intelligently
selects which corrupting links can be safely disabled, while ensuring
that each top-of-rack switch has a minimum number of paths to
reach other switches. CorrOpt also recommends specific actions
(e.g., replace cables, clean connectors) to repair disabled links, based
on our analysis of common symptoms of different root causes of
corruption. Our recommendation engine has been deployed in over
seventy data centers of a large cloud provider. Our analysis shows
that, compared to current state of the art, CorrOpt can reduce
corruption losses by three to six orders of magnitude and improve
repair accuracy by 60%.
CCS CONCEPTS
• Networks → Network measurement; Network reliability; Data
center networks; Network management;
KEYWORDS
CorrOpt, Packet Corruption, Data Center Networks, Optics, Fault
Mitigation
ACM Reference format:
Danyang Zhuo, Monia Ghobadi, Ratul Mahajan, Klaus-Tycho Förster, Arvind
Krishnamurthy, and Thomas Anderson. 2017. Understanding and Mitigating
Packet Corruption in Data Center Networks. In Proceedings of SIGCOMM
’17, Los Angeles, CA, USA, August 21–25, 2017, 14 pages.
https://doi.org/10.1145/3098822.3098849
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
SIGCOMM ’17, August 21–25, 2017, Los Angeles, CA, USA
© 2017 Association for Computing Machinery.
ACM ISBN 978-1-4503-4653-5/17/08...$15.00
https://doi.org/10.1145/3098822.3098849
1 INTRODUCTION
Packet losses in data center networks (DCNs) hurt applications
and can lead to millions of dollars in lost revenue [20, 26, 37]. For
instance, packet loss rate above 0.1% causes RDMA’s throughput
to drop by 25% for bulk transfer [36]. For user-facing video traffic,
loss rates of 0.01% can cause TCP CUBIC’s throughput to drop by
50% [10]. Even sporadic packet losses can cause catastrophic virtual
machine reboots [5].
Consequently, researchers have explored several approaches
to reduce packet loss, including congestion control, active queue
management, load balancing, and traffic engineering [2–4, 12, 28,
31, 32, 36]. All of these approaches, however, focus on one source
of packet loss—congestion that occurs when the network’s load
exceeds its capacity.
However, another significant source of packet loss, namely packet
corruption, has received little attention. Packet corruption occurs
when the receiver cannot correctly decode transmitted bits. Such
decoding errors cause the cyclic redundancy check in the Ethernet
frame to fail and force the receiver to drop the packet. While recent
studies categorize different sources of packet loss and acknowledge
packet corruption as a contributor [5, 34, 37], not much is known
today about the extent and characteristics of corruption-induced
packet loss.
This paper presents what to our knowledge is the first large-scale
study of packet corruption in DCNs. We monitor 350K switch-to-
switch, optical links within 15 data centers of a major cloud provider,
over seven months. We find that, despite the cloud provider’s efforts
to mitigate corruption, the number of packets lost due to corrup-
tion is significant. To improve mitigation techniques for packet
corruption, we need a thorough understanding of its characteristics.
We uncover several relevant characteristics of corruption losses
and contrast them with those of congestion. For instance, while
the loss rate due to congestion varies with link utilization, that due
to corruption is relatively stable over time and is independent of
the link’s utilization. This observation implies that reducing the
load on the link, as in congestion control, will not reduce packet
corruption rate. We also find that, compared to congestion, cor-
ruption plagues fewer links but imposes higher loss rates on those
links. Finally, we find that corruption exhibits weak locality, i.e., the
chances of multiple corrupting links being on the same switch or
being topologically close are noticeable but low, while congestion
exhibits strong locality.
We also analyze hundreds of trouble ticket logs to find the com-
mon root causes of corruption. These range from faulty transceivers
(i.e., devices that convert between optical and electrical signals) and
switches, to poorly installed hardware, to damaged optical fiber, to
SIGCOMM ’17, August 21–25, 2017, Los Angeles, CA, USA
D. Zhuo et al.
dirty optical connectors. By monitoring the optical layer contem-
poraneously with the tickets, we uncover the common symptoms
for each such root cause.
The prevalent method to mitigate corruption is to disable links
with corruption loss rate above a certain level (e.g., 10−6), provided
that the switches to which they attach have at least a threshold
number of active uplinks toward the spine of the DCN [26]. This
threshold ensures that the hosts using the switch have enough left-
over capacity—otherwise, we might replace corruption losses with
heavy congestion losses. Links are disabled automatically using soft-
ware that monitors the corruption loss rate of each link. Though it
does not repair corrupting links, this software is important because
it reduces the chances of application traffic experiencing corruption
losses. For each disabled link, a maintenance ticket is issued for
operators to manually repair the link. The operators attempt to
repair the link via a sequence of steps (e.g., clean the optical fiber
and connectors; replace the transceiver; replace the cable), based on
their expertise and largely independent of the root cause. The link
is enabled after each step, and the next step is taken if the previous
one did not succeed at eliminating corruption.
The method above has two limitations. First, the criterion for
disabling links is greedy and local. While such decisions can be made
quickly, they miss better opportunities that can reduce the level of
corruption losses, i.e., disable links with higher corruption rates or
disable more corrupting links. We show that such opportunities
exist while meeting the same capacity constraint. Second, since the
strategy to repair corruption is agnostic of the root cause, it can
take multiple steps to eliminate corruption. In fact, with the current
strategy, the link is fixed in the first step only 50% of the time.
Based on the observations above, we develop CorrOpt, a system
to mitigate corruption in DCNs. Because the problem of identifying
the optimal set of corrupting links to disable, which minimizes
corruption losses while meeting capacity constraints, is NP-hard,
CorrOpt uses a two-phase approach. First, when a link starts cor-
rupting packets, a fast decision is made on whether the link can
be safely turned off. Even this fast decision allows us to lower cor-
ruption losses than the current method because it considers the
entire set paths from top-of-rack switches to the spine, instead of
just the switches adjacent to the link. But this fast decision is not
optimal. To approximate optimality, we use a second phase that
does a global optimization to determine the set of links that can
be safely disabled. The combination of the two phases allows us to
react quickly and optimize later.
CorrOpt also has a recommendation engine that uses a root
cause-aware approach to propose the right repair for corrupting
links. Based on the link’s characteristics (i.e., corruption rate, optical
transmit power, optical receive power) and history of actions taken
thus far (if any), it generates concrete recommendations for oper-
ators on what corrective action is needed. This recommendation
engine has been deployed in over 70 DCNs of our cloud provider.
We evaluate CorrOpt using the deployment of the recommenda-
tion engine and a trace-based analysis using data from production
DCNs. We find that CorrOpt responds to packet corruption quickly
and lowers the amount of corruption losses by up to three to six
orders of magnitude, while meeting the desired capacity constraints.
Figure 1: Mean and standard deviation of packets lost per
day due to corruption across 15 DCNs, sorted by their size.
Values are normalized by the mean number of congestion
losses in each DCN. Horizontal dashed line denotes the
threshold when packets loss due to corruption and conges-
tion are the same. In most cases, corruption and congestion
losses are on par.
We also find that our recommendation engine has improved the
accuracy of repairing the link at the first attempt from 50% to 80%.
2 EXTENT OF PACKET CORRUPTION
We demonstrate the need to understand and mitigate packet cor-
ruption by quantifying its extent in today’s DCNs. We show that
the number of packets lost due to corruption is startlingly high.
Our analysis considers corruption- and congestion-induced losses
in 15 production data centers. We focus on switch-to-switch links.
Corruption mitigation, by disabling or routing around corrupting
links, is relevant only for such links, not server-to-ToR links. Fur-
ther, as we discuss later, the complexity of repair is a concern only
for switch-to-switch links, which are optical and can go long dis-
tances; server-to-ToR links, which are electrical and short, simply
get replaced. As the data centers that we study use standard designs
and physical layer technologies (e.g., transceivers, fibers), we expect
our findings to be applicable to other data centers as well.1
The DCNs in our study have 4–50K links, and the total across all
of them is 350K. For each link, we use SNMP [11] to query its packet
drop, packet error, and total packet counts, as well as its optical
power levels every 15 minutes. Our network operators found SNMP
to be a reliable and lightweight mechanism for monitoring these
counters. The data cover a period of seven months. The results in
this section are based on three weeks of data, and the next section
looks deeply into one representative week. The rest of the paper
uses the entire data set.
Figure 1 shows the number of packets lost per day due to packet
corruption and congestion. The DCNs are sorted by size. For confi-
dentiality, the number of packet losses on the Y-axis is normalized
with respect to mean congestion per DCN. The error bars represent
the standard variation around the mean for packets lost due to
corruption on different days.
We see that, while results vary across data centers and days, in
aggregate, the number of corruption losses is on par with conges-
tion losses on the switch-to-switch links that we study. (Results
1Our data centers have diverse ages and have been through different rounds of equip-
ment replacement cycles. We do not have data of when each device is installed and
thus cannot study the effect of packet corruption over device lifetime.
Understanding and Mitigating Packet Corruption in DCNs
SIGCOMM ’17, August 21–25, 2017, Los Angeles, CA, USA
)
)
)
links w. corruption
47.23%
18.43%
21.66%
12.67%
100%
links w. congestion
92.44%
6.35%
0.99%
0.22%
100%
Loss bucket
[10−8 - 10−5
[10−5 - 10−4
[10−4 - 10−3
[10−3+)
total
Table 1: Comparison of the normalized distribution of links
with congestion and corruption loss for different loss buck-
ets. 12.67% of total links that experience corruption, have
a corruption loss rate greater than or equal to 10−3 (0.1%
loss rate) whereas only 0.22% of links with congestion, have
congestion loss rate of 10−3. The numbers in each column
are normalized so that the table does not reveal the overall
percentage of links with congestion or corruption losses for
confidentiality reasons.
for server-attached links may differ.) In other words, for every con-
gestion loss that applications experience, they will experience a
corruption loss. Although this graph does not show corruption rate,
the next section shows that it can be quite high for some links.
This high level of corruption loss happens even though there is al-
ready a system to discover and turn off links with corruption. While
this system has limitations, which we explain in §5, we estimate
that without it, corruption-induced losses would be two orders of
magnitude higher.
Our results clearly demonstrate the need for an effective strategy
to mitigate corruption in DCNs. Our proposed system, CorrOpt,
provides such a strategy. To explain the rationale underlying its
design, in the next two sections, we dig more deeply into the nature
of corruption and its root causes.
3 CORRUPTION CHARACTERISTICS
To develop a thorough understanding of packet corruption, in this
section we identify the characteristics of corruption and compare
them to congestion. Though not our focus, our observations can also
help load balancing and congestion control systems appropriately
handle congestion vs. corruption losses when switch counters are
not available to distinguish the two.
Corruption impacts fewer links but can be more severe than conges-
tion. Our data reveal that while congestion is a more widespread
phenomenon in terms of the links it impacts, packet corruption
affects fewer links. We compute the percentage of links with con-
gestion and corruption loss rate above 10−8 and find that the total
number of links with corruption is less than 2-4% of those with
congestion.2
This difference suggests that a small set of links have high corrup-
tion loss rate, given that the number of corruption and congestion
losses is similar. Table 1 shows the distribution of links with cor-
ruption and congestion in different loss buckets, normalized such
that the total in each column adds to 100%. Overall, only a small
2IEEE 802.3 standard requires each link to have corruption loss rate under 10−8, but
operators today tend to worry only when packet loss rates start approaching 10−6.
In this paper, we conservatively use 10−8 as the threshold to deem a link as lossy or
non-lossy.
(a) Loss rate of one link
(b) CV of loss rate for all links
Figure 2: Corruption loss rate is more stable over time than