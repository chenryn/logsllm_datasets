title:The Last Mile: An Empirical Study of Timing Channels on seL4
author:David Cock and
Qian Ge and
Toby C. Murray and
Gernot Heiser
The Last Mile
An Empirical Study of Timing Channels on seL4
David Cock, Qian Ge, Toby Murray, Gernot Heiser
PI:EMAIL, PI:EMAIL, PI:EMAIL, PI:EMAIL
NICTA and UNSW, Sydney, Australia
ABSTRACT
Storage channels can be provably eliminated in well-designed, high-
assurance kernels. Timing channels remain the last mile for conﬁ-
dentiality and are still beyond the reach of formal analysis, so must
be dealt with empirically. We perform such an analysis, collecting
a large data set (2,000 hours of observations) for two representative
timing channels, the locally-exploitable cache channel and a remote
exploit of OpenSSL execution timing, on the veriﬁed seL4 micro-
kernel. We also evaluate the effectiveness, in bandwidth reduction,
of a number of black-box mitigation techniques (cache colouring,
instruction-based scheduling and deterministic delivery of server
responses) across a number of hardware platforms. Our (somewhat
unexpected) results show that while these defences were highly ef-
fective a few processor generations ago, the trend towards impre-
cise events in modern microarchitectures weakens the defences and
introduces new channels. This demonstrates the necessity of care-
ful empirical analysis of timing channels.
Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection—Informa-
tion Flow Controls
General Terms
Security, Measurement, Performance
Keywords
Conﬁdentiality; covert channels; side channels; mitigation; micro-
kernels; cache coloring; seL4
1.
INTRODUCTION
Unanticipated information leaks are one of the oldest problems
in computer security, with documented cases from as early as the
1940s [NSA, 1972]. Such leaks are traditionally classiﬁed as either
storage or timing channels, depending on whether time is used to
exploit them [Wray, 1991].
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from PI:EMAIL
CCS’14 November 3–7, 2014, Scottsdale, Arizona, U.S.A.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2957-6/14/11 ... $15.00.
http://dx.doi.org/10.1145/2660267.2660294.
We can now prove the absence of storage channels in small and
well-designed security-critical software, such as the seL4 micro-
kernel [Klein et al., 2009, 2014], as demonstrated by the recent
veriﬁcation of intransitive noninterference for seL4 [Murray et al.,
2013], in C. Notwithstanding some recent promising work, e.g. on
proving upper bounds for and the absence of cache side channels
in block cipher implementations [Doychev et al., 2013; Köpf et al.,
2012] or proving the absence of cache leakage in an abstract hyper-
visor model [Barthe et al., 2012], proofs regarding timing channels
in an operating system, even one as small as seL4, is beyond the
reach of current approaches.
Therefore, for now such channels must be dealt with empirically.
Their bandwidth can be measured by careful experiment, and the
effectiveness of mitigations assessed according to how they reduce
this. Such an empirical approach must be based on sound infor-
mation theory, by accurately measuring and analysing the channel
matrix [Shannon, 1948].
Figure 1 shows the empirical channel matrix (see Section 4.1) of
the cache channel under seL4 on the Exynos4412 platform, which
is summarised in Table 1. Each point {x, y} gives the probabil-
ity of an attacker making a particular observation (y: number of
cache lines touched within a single timeslice) given the working set
size (x: the number of cache lines evicted) of a sending program.
Darker colours are higher probabilities, shown on the scale at right.
The sender here might be an unwitting victim or might collaborate
with the attacker. The clear correlation between the sender’s work-
ing set size and the attacker’s (most likely) observations, shown in
the narrow band of non-zero probabilities, shows that the attacker
can infer this size with high conﬁdence. The bandwidth of the chan-
nel is calculated from this matrix (see Section 4.2), and in this case
is 2400 bits/sec.
3
0
1
/
d
e
h
c
u
o
t
s
e
n
i
L
40
30
20
10−1
10−2
10−3
10−4
0
10
20
30
Lines evicted /103
Figure 1: Exynos4412 cache channel matrix, no countermea-
sure. N = 1000, B = 2400 b/s. Colours indicate probabili-
ties, further explanation in Section 4.1.
570seL4 is a general-purpose operating system (OS) kernel, de-
signed for security- as well as safety-critical use cases. Its notable
features are comprehensive formal veriﬁcation, with a complete
proof chain from high-level security and safety properties to binary
code [Klein et al., 2014], and performance at least as good as that
of traditionally-engineered kernels [Elphinstone and Heiser, 2013].
These desirable properties come at a cost. Formal veriﬁcation
is expensive: a disincentive to modifying the system for a partic-
ular use case (although no worse than traditional assurance pro-
cesses such as Common Criteria [NIST]). We thus look for ways to
combat timing channels in seL4 without undermining its general-
purpose nature.
We consider several timing channels that are relevant to an seL4-
based system, and how they can be mitigated with minimal over-
head, and minimal changes (hence re-veriﬁcation) to the kernel.
The need for low overhead rules out those that add noise (see Sec-
tion 2). Furthermore, we only consider black box techniques, which
require no insight into the internals of software running on seL4, as
retroﬁtting security into complex software is generally impossible.
We do not yet aim for comprehensive coverage of timing chan-
nels related to seL4, but analyse representative examples in detail,
to explore the limits of what we can achieve under the above con-
straints. A wider study of timing channels is planned for future
work. Despite these limitations, we make several unexpected ob-
servations that generalise beyond seL4.
We look at one local vulnerability, the cache-contention chan-
nel, and two countermeasures, instruction-based scheduling [Ste-
fan et al., 2013] and cache colouring [Liedtke et al., 1997]. We
also examine a remote vulnerability, the distinguishing portion of
the Lucky 13 attack of AlFardan and Paterson [2013] against DTLS
in OpenSSL 1.0.1c.
very high conﬁdence, for the following claims:
The contribution of this paper is robust empirical evidence, at
• Black-box techniques, such as instruction-based scheduling
and cache colouring, can be highly effective, but are less so
on modern processors. For example, even with a partitioned
L2 cache, ﬂushing the L1 and TLB on a context switch,
we still see a cache-channel bandwidth of 25b/s on a recent
ARM processor (Exynos4412 see Section 5.4). This could
(in theory), be exploited to leak a 1024 bit encryption key in
a little over 40 seconds.
• On recent ARM processors, the instruction counter provides
a timing channel not previously described, and with a band-
width of 1100b/s, if exploited using the preemption tick as a
clock. This channel can be closed by virtualising the counter.
• The “constant-time” Lucky 13 ﬁx in OpenSSL 1.0.1e still
• Operating-system techniques provide better mitigation of
OpenSSL’s Lucky 13 channel at lower performance penalty
(10µs vs. 60µs latency).
exhibits a considerable side channel, at least on ARM.
We conclude that timing channels, especially local channels, re-
main a real threat and are becoming more difﬁcult to close. How-
ever, in the right environment, simple mitigations, carefully de-
ployed on a well-designed kernel, can be effective. As hardware
becomes more complex and opaque, any assurance case must be
backed by solid, empirical analysis on the deployment platform.
2. TIMING CHANNELS: BACKGROUND
A timing channel transfers information in the (relative) timing of
events. The OS does not usually control the timing of all events in
the system. Timing channels thus often bypass operating system
protections, and so pose a threat to conﬁdentiality.
Despite decades of research, timing channels continue to plague
mainstream systems [AlFardan and Paterson, 2013; Hund et al.,
2013]. Historically, concern about timing channels was conﬁned to
high-assurance systems: certiﬁed separation kernels are required
to limit their bandwidth [IAD] and the NSA provides guidance
on how to avoid cache channels for systems built on secure real-
time OSes [NSA]. While they remain a concern for modern high-
assurance systems [Owen et al., 2011], timing channels are now
recognised as a threat to co-tenant cloud computing [Ristenpart
et al., 2009], in which mutually distrusting tenants pay for access to
common computing infrastructure. Hence timing channel mitiga-
tion has again become a hot topic in computer security [Kim et al.,
2012; Stefan et al., 2013; Zhang and Reiter, 2013].
One high-bandwidth timing channel is the cache-contention
channel, which we cover in Section 5.
In a cloud context, this
channel has been exploited to learn high-value secrets like encryp-
tion keys [Zhang et al., 2012]. An otherwise isolated sender and
receiver share one or more processor caches, which reduce ac-
cess times to blocks of memory by keeping copies close to hand.
A channel exists when the sender can inﬂuence which of the re-
ceiver’s blocks are in the cache, since this affects the time it takes
the receiver to access its memory. The event being observed here
is the completion of a memory access by the receiver; the sender
inﬂuences how long this event takes to arrive.
To measure the time between events, the receiver needs a clock:
an independent event source. The observed channel is also a clock,
each observation constituting an event. A timing channel exists
between a sender and a receiver whenever the receiver has access
to two clocks, and the sender controls their relative rates [Wray,
1991].
uncorrelated noise
anticorrelated noise
)
b
(
e
s
i
o
n
d
e
t
c
e
j
n
I
16
12
8
4
0
0
2
4
6
8
10
12
Capacity (b)
Figure 2: (Anti-)correlated noise vs. channel capacity.
Mitigation strategies, or countermeasures, are techniques that
reduce information transmitted on a channel. Established strate-
gies fall into three categories: (i) restricting the receiver to a single
clock, (ii) limiting the sender’s inﬂuence over the rate of the re-
ceiver’s clocks (i.e. increasing determinism) and (iii) introducing
noise into these clocks to make it harder to recover the signal being
transmitted (as in fuzzy time [Hu, 1991]).
Introducing noise is inefﬁcient if high security is needed: Fig-
ure 2 plots the level required to reduce the capacity of a 12-bit chan-
nel to any desired level, if that noise is either uncorrelated (and uni-
formly distributed), or perfectly anti-correlated with the signal (i.e.
reducing it). While 12 b of anticorrelated noise closes the channel,
the level of uncorrelated noise required increases asymptotically as
we approach zero. Reducing the capacity by more than an order
of magnitude requires huge amounts of noise, severely degrading
overall system performance. The countermeasures we consider all
build on this insight.
As a program can always observe its own progress, it always has
access to one clock, its program counter (PC). Hence, restricting to
a single clock requires denying any access to wall-clock time and
ensuring that all observable events are synchronised to the PC, or
571ensuring that the PC is synchronised to wall-clock time.
Preemptive schedulers usually allocate processing time in ﬁxed
time slices. If the receiver can detect preemption events (e.g. via
a helper thread), it obtains enough wall-clock time information to
calibrate its PC clock, and thus time the channel events.
Instruction-based scheduling mitigates this channel by preempt-
ing not at ﬁxed intervals, but after some ﬁxed number of instruc-
tions. Stefan et al. [2013] explored this approach, and we cover it
in Section 5.3.
Cache partitioning [Liedtke et al., 1997] is a well-known and
recently-explored [Godfrey, 2013] countermeasure that ensures
that the sender cannot inﬂuence which of the receiver’s blocks are
in the cache, and thus cannot alter the time taken for the receiver to
access its memory. We cover this in Section 5.4.
We cannot deny wall-clock time to a remote attacker. We instead
rely on making receiver-observable events deterministic. We exam-
ine this case using a remote client, the receiver, interacting with a
server, who is the (unwitting) sender. Any variation in response
time creates a channel. We mitigate this by enforcing a minimum
bound on the server’s response time; ensuring that responses are
only released after some pre-determined interval, in order to imple-
ment a delay-based policy (e.g. [Askarov et al., 2010; Zhang et al.,
2011]). This is the subject of Section 6.
3. THREATS & COUNTERMEASURES
As described, we explore mitigations against several different
attacks, each with its own threat model. Across all scenarios we
assume an attacker who is trying to learn some secret information.
We make no assumptions about this secret—for instance, that it is
selected uniformly at random. We also assume an attacker with
arbitrarily high computational power. Our goal is to prevent the
attacker from learning the sender’s conﬁdential information.
The mitigations have in common that they are noiseless, i.e. they
attempt to reduce the signal on the channel rather than increasing
the noise, aiming to minimise performance impact. They are also
black box techniques, i.e. do not require modiﬁcations to or even an
understanding of the internals of applications: all are implemented
at the OS level.
3.1 Cache channel
As a local vulnerability we examine the cache-contention chan-
nel, which arises when sharing a memory subsystem between oth-
erwise isolated domains. Here the receiver attempts to obtain se-
crets from a malicious sender partition. We assume a single-core,
time-shared system, such as a multi-level secure (MLS) system or
cross-domain solution. We assume further that the system has been
conﬁgured appropriately so that no storage channels exist between
the sender and receiver, and no devices are shared between them
other than the CPU, bus and memory hierarchy (caches and main
memory). The absence of storage channels implies that no region
of physical memory is shared between the attacker and sender.
We assume a well-designed system with a minimal trusted com-
puting base (TCB). The TCB will not intentionally leak secrets,
but other components might. Under the classical distinction [Wray,
1991] between covert channels and side channels, in which the for-
mer involves intentional leakage while the latter is unintentional,
we assume that trusted components leak secrets only over side
channels, while untrusted ones also employ covert channels.
We use two countermeasures here: Instruction-based schedul-
ing (IBS) and cache colouring, both introduced above. The former
synchronises the clocks observable by the receiver, while the latter
eliminates contention on the cache (i.e. the signal). In addition to
the above assumptions, IBS requires that the receiver can be iso-
lated from any notion of real time (as would be provided by physi-
cal devices or network connectivity). It is therefore only applicable
in restricted circumstances.
3.2 Lucky Thirteen
As a remote vulnerability, in Section 6, we reproduce the distin-
guishing attack (“Lucky thirteen”) of AlFardan and Paterson [2013]
against DTLS, as implemented in OpenSSL version 1.0.1c, and
demonstrate that the current version (1.0.1e) is still vulnerable.
We mitigate this channel, with better performance and lower
overhead than the state of the art solution, using a black box tech-
nique: we employ real-time scheduling to precisely delay messages
and thus hide timing variation.
4. METHODOLOGY
We work from a large corpus of statistical observations. From
this we construct a channel matrix, and calculate summary mea-
sures, such as Shannon capacity, similarly to Gay et al. [2013].
Comparing the bare and the mitigated channels allows us to deter-
mine the effectiveness of a mitigation strategy.
We view the channel connecting a sender and a receiver as a
pipe, into which the sender places inputs, drawn from some set I,
and the receiver draws outputs, from some set O. For instance, in
the cache-contention channel, the sender might touch some subset
of its allocated memory, to ensure that a particular fraction of the
cache is ﬁlled with its modiﬁed data; while the receiver touches as
many lines as it can in some interval. The number of dirty lines
that must be cleaned to RAM affects the receiver’s progress. The
input i ∈ I is thus the number of lines touched by the sender, and
the output o ∈ O the number touched by the receiver, from which
it attempts to infer i.
4.1 The Channel Matrix
The channel matrix captures the end-to-end behaviour of a chan-
nel. It has a row for each output o ∈ O and a column for each
input i ∈ I. The value at position {i, o} gives the (conditional)
probability of the receiver seeing output o (e.g. touching o lines) if
the sender places input i into the channel (evicting i lines).
For example, Figure 1 is the channel matrix for the cache chan-
nel as measured on the Exynos4412 with no countermeasures. Each
point gives a conditional probability, with darker colours for higher
values, on a log scale. For instance, if the sender evicts 8,000 lines,
the receiver will touch around 20,000. Here, the output clearly
varies with the input (the more lines evicted, the fewer the receiver
touches), and the ﬁgure intuitively captures this correlation and thus
the existence of the channel.
Each channel matrix is built by testing all possible inputs, and
observing for each a large number, N, of outputs (the sample size).
Counting these gives a histogram that records for each output, o,
the number of times, ni,o, it was observed for each input, i. The
estimated conditional probability of seeing o given i, the cell {i, o},
is thus ni,o/N. Each column of the channel matrix in Figure 1, for
instance, consists of 1000 observations (sample size N = 1, 000).
We use a synthetic receiver to observe the channel. For the
cache-contention channel depicted in Figure 1, the receiver uses the
preemption tick to provide a regular sampling interval to measure
the number of lines it managed to touch. We assume a malicious
sender (see Section 3.1): we use a synthetic sender that varies its
cache footprint according to i, the value to transmit.
For the remote channel (Section 6), for which we assume non-
malicious (unintended) leakage, OpenSSL’s vulnerable DTLS im-
plementation forms the sender. The receiver in this case executes