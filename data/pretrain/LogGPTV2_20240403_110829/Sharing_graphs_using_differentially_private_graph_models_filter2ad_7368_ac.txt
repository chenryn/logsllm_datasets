 10
 1
 0.1
 1
 10
 100
 10
 100
Epsilon
(a) AS
Epsilon
(b) Russia
e
c
n
a
t
s
D
i
 1e+09
 1e+08
 1e+07
 1e+06
 100000
 10000
 1000
 100
 10
 1
 0.1
dK-PA
Ideal
 10
 100
 1
Epsilon
(c) WWW
Figure 3: The noise required for different privacy levels quantiﬁed as the Euclidean distance between a graph’s original and per-
turbed dK-2 series.
been used in prior graph mining studies [28]. The social graphs
were gathered using a snowball crawl of the Facebook regional net-
works [43], and show graph metrics highly consistent with Face-
book graphs generated using unbiased sampling techniques [21].
Table 1 lists the graphs used in our evaluation, which range from
14K nodes to 650K nodes.
We extract the dK-2-series for each graph, introduce noise using
the dK-PA strategy, then compute the Euclidean distance between
the perturbed dK-2-series and the original as a measure of the level
of graph structural error introduced. We computed results for all
graphs in Table 1, and they are consistent. For brevity, we limit
ourselves to report results only for the AS graph, the WWW graph,
and the Russia Facebook graph. We choose Russia to represent
our social graphs because its results are representative of the other
graphs, and its size does not result in extremely long run time for
our experiments.
Results.
Figure 3 shows that the dK-PA strategy produces a
large error for small values of  (i.e. strong privacy guarantees). We
compute the error as the Euclidean distance between the original
dK-2-series and the perturbed dK-2-series with dK-PA strategy.
As we mentioned, the low level of accuracy is due to the large noise
dK-PA injects into dK-2, resulting in a perturbed dK-2 that is
signiﬁcantly different from the original. The bright side is that the
dK-PA strategy is robust across different datasets, and the error
decreases exponentially as  grows, which is shown by the linear
correlation in the log-log scale plot of Figure 3.
The high error is largely due to the high sensitivity of our func-
tion dK-2. To understand the potential lower-bound on the error,
we imagine a scenario where if we had a function with sensitivity
of 1, then we could achieve much lower error, plotted in Figure 3
as the Ideal line. Note that this line is a hypothetical lower bound
that is only meant to demonstrate the impact of the dK function’s
sensitivity on the ﬁnal result. Indeed, Figure 3 shows that the loss
in accuracy of our model can largely be attributed to the sensitivity
of the dK-2 series.
4. PRIVACY VIA PARTITIONING
The results in the previous section demonstrate the loss of accu-
racy in the perturbed dK-2-series after adding noise to guarantee
-differential privacy. In this section we propose a novel algorithm
called Divide Randomize and Conquer (DRC) that enables more
granular control over the noise injected into the dK-2-series. This
qualiﬁes DRC to support -differential privacy while also allowing
for more accurate results. First, we discuss the design of DRC and
prove that it does guarantee -differential privacy. Next, we inves-
tigate the amount of error introduced with this approach, and show
that DRC requires signiﬁcantly less noise than dK-PA to achieve
an equal level of privacy. Finally, we propose an optimized ver-
sion of DRC, called LDRC, and empirically verify the improved
accuracy of our algorithms using measured graphs.
4.1 Divide Randomize and Conquer Algorithm
Our goal is to develop an improved privacy mechanism that sig-
niﬁcantly reduces the amount of noise that must be added to achieve
a given level of -privacy. While we cannot change the fact that
the sensitivity of dK-2 scales with dmax, our insight is to parti-
tion data in the dK-2-series into a set of small sub-series, then ap-
ply the perturbation independently to achieve -privacy within each
sub-series.
If we carefully perform the partitioning to group together tuples
with similar degree, we effectively reduce the value of dmax for
each of the vast majority of sub-series. This means we can achieve
-privacy on each sub-series for a fraction of the noise required
to achieve -privacy across the entire series. We will then prove
that -differential privacy holds across the entire dK-2-series if it
holds for each of the partitioned sub-series. Thus, we produce an
alternative algorithm that achieves the same level of privacy as dK-
PA, while introducing signiﬁcantly less noise.
We instantiate our ideas as the Divide Randomize and Conquer
algorithm (DRC). The core steps of DRC are:
ciﬁc properties;
1. Partition (Divide) the dK-2-series into sub-series with spe-
2. Inject noise into each sub-series (Randomize);
3. Conquer the perturbed sub-series into a single dK-2-series.
In the remainder of this section we discuss the partitioning step
of DRC. We ﬁrst deﬁne an ordering function on dK-2 to sort tu-
ples with similar sensitivity. The ordered dK-2 is then partitioned
into contiguous and mutually disjoint sub-series. We prove that the
properties of these sub-series lead to the deﬁnition of a novel sen-
sitivity function and consequently to a novel methodology to add
noise. Noise injection, conquering, and the resulting error analysis
are discussed in Section 4.2.
∂ ordering on dK-2.
The dK-2-series is sorted by group-
ing dK-tuples with numerically close pairs of degrees. In partic-
ular, the dK-tuples are sorted in the new dK-2 series, named β-
series, by iteratively selecting from the original series all the tuples
{dx, dy; k} with degrees (dx & dy) ≤ i, ∀ i ∈ [1, dmax]. Thus,
the β-series is simply the sorted list of dK-tuples that adhere to
the above inequality ordering. For example, the tuple {1, 2; k} is
86closer to {5, 5; k!} than to {1, 8; k!!}. We can formally describe
this transformation with the following function:
DEFINITION 3. Let ∂ be the sorting function on dK-2 which is
formally expressed as:
∂(i) = min
dx,dy ∈dK{max(dx, dy) ≥ max(dx", dy") = ∂(i − 1) }
Note that {dx, dy; k}) = the ﬁrst i−1 tuples. Thus, the ∂ function is
a transformation of dK-2 such that ∂ : $ → β where β identiﬁes
the ordered dK-2.
Partitioning the β-Series.
The β-series is partitioned into em
sub-series, with the ith named βi for i ∈ [1, em]. The partition of β
is based on two properties. First, the ∂ ordering has to be obeyed
and thus each partition can only acquire contiguous tuples in the
β-series. Second, each tuple can appear in one and only one sub-
series. Given the ∂ ordering and the above two rules we can guar-
antee mutually disjoint and contiguous sub-series βi. These two
constraints are fundamental to satisfying the sensitivity properties
we prove in the following Lemma 2 and Lemma 3.
Sensitivity of βi sub-series.
The sensitivity of each βi-series
can be studied following the same logic used to ﬁnd the sensitivity
of dK-2, by quantifying the maximum number of changes that may
occur in the βi-series due to an edge change in the graph G. Due
to the ∂ ordering imposed in each sub-series, we can show that the
maximum degree in each βi plays a fundamental role in bounding
its sensitivity.
LEMMA 2. The sensitivity Sβi of a sub-series βi with tuple de-
grees almost equal to dk + 1 is upper bounded by 4 · dk + 1.
The proof of this lemma is sketched because it follows the logic
of Lemma 1. Due to the proposed ∂ ordering, each sub-series i is
composed only of tuples where both degrees are less than or equal
to a particular integer d. The worst-case (i.e. the maximum number
of changes to the tuples in the same βi) occurs when the tuple with
degrees d − 1 are in the same sub-series. Therefore, the maximum
number of changes occur when a new edge is added between two
nodes (u, v) both with degree d − 1, after which both nodes u
and v have degree d. Adding a new edge between u and v causes
dk = d − 1 entries in βi to become invalid. Each invalid entry is
replaced with new entry of degree d. Thus, the upper bound on the
total number of changes is 2· dk deletions, 2· dk additions, and one
new edge, with the total being 4 · dk + 1.
Given the partitioning approach and the imposed ∂ ordering across
sub-series, we are able to exploit further properties on the βis-
series. In particular, the sensitivity of any βi is independent from
the location where the change occurs in the graph. Conversely, the
sensitivity of a particular partition is dependent on the tuple with
the highest degree values, as proved in Lemma 2. Therefore:
LEMMA 3. The sensitivity of any βi is independent by the sen-
sitivity of any other βj with i )= j.
PROOF. The proof proceeds by contradiction from the follow-
ing assumption:
the sensitivity of a βi is impacted by a change
occurring in a βj with i )= j. Without loss of generality, assume
i  ∈ βi and a node y
with corresponding tuples  ∈ βj. The maxi-
mum number of changes that can occur due to this event is bounded
by the degree values of x and y. Let d be the new degree of x. The
maximum number of tuples that can change in βi are d − 1 tuples
that get deleted and d that get added, which is < 2 · d. Symmet-
rically, let b be the new degree of y so the maximum number of
tuples that can change in βj is < 2 · b. Even if d and b are equal to
the maximum degree value dk within their sub-series, as demanded
in Lemma 2, the number of changes involved in each sub-series is
2 · dk < 4 · dk + 1 which means that the sensitivity of both βi and
βj are not mutually effected, which contradicts the hypothesis.
4.2 Theoretical Analysis
This section is devoted to the theoretical analysis of the privacy
and accuracy properties the DRC approach achieves. First, we
prove that -differential privacy can be applied to each sub-series
created during the partitioning phase of DRC. Next, we build on
this result to prove that the individual differentially private sub-
series’ can be reuniﬁed into a complete dK-2-series that is also
-differentially private. Lastly, we perform error analysis on DRC
and compare the results to dK-PA.
Analyzing -Privacy in βis.
each βi and prove that they satisfy -differential privacy.
THEOREM 2. For each cluster βi with i = 1, .., em, let bβi be a
novel privacy mechanism on βi such that bβi = βi + Lap(
 )|βi|.
Sβi
i derived from graphs G and G!
Then, for all sub-series βi and β!
that differ by at most one edge, bβi satisﬁes -differential privacy if:
We now quantify the privacy of
˛˛˛ ln
P r[bβi = s]
P r[bβ!
i = s]
˛˛˛ ≤ 
j=1
PROOF. Let m∗ be the the cardinality of cluster βi. Let G! be
a graph with at most one edge different from G. Let sj be the jth
item of the bβi-series, that is bβi[j] = sj. Using the conditional
probability on sj we can write:
m∗Y
=
P r[bβi[j] = sj|s1, ...sj−1]
P r[bβ!
i[j] = sj|s1, ...sj−1]
P r[bβi = s]
P r[bβ!
i = s]
Each item of the product has the ﬁrst j − 1 tuples of the bβi-
series ﬁxed. Each sj is the result of the Laplace noise that has
been calibrated for βi based on its sensitivity, as calculated using
in Lemma 2. The sensitivity of this function is derived under the
assumption that the two graphs have, at most, one edge difference.
Thus, the conditional probabilities are Laplacians, which allows us
to derive the following inequalities:
P r[bβi[j] = sj|s1, ...sj−1]
P r[bβ!
i[j] = sj|s1, ...sj−1]
Sβi
By deﬁnition bβi = βi + Lap(
 )|βi| and by Lemma 2 ||βi −
i||1 ≤ Sβi with Sβi ≤ 4dki + 1. Let σi be the scale parameter
β!
of the Laplacian noise applied in each cluster i, thus:
| cβi[j]−
σ
m∗Y
m∗Y
c
β"
i [j]|
j=1
j=1
≤
e
| cβi[j]−
σ
c
β"
i[j]|
c
β"
|| cβi−
i||1
σ
= e
m∗Y
j=1
e
|| cβi+Lap(
Sβi
c
β"
 )−
i−Lap(
σ
Sβi
 )||1
= e
Finally, by applying the logarithmic function the theorem state-
≤ e
= e
σ

||βi−β"
i||1
4dmi +1
4dmi +1
ment is proved.
Theorem 2 shows that adding noise does achieve provable -
differential privacy on each cluster. In particular, we prove that by
87dK-PA
DRC
LDRC
Ideal
e
c
n
a
t
s
D
i
 1e+09
 1e+08
 1e+07
 1e+06
 100000
 10000
 1000
 100
 10
 1
 0.1
 1
 10
 100
Epsilon
(a) AS
e
c
n
a
t
s
D
i
 1e+09
 1e+08
 1e+07
 1e+06
 100000
 10000
 1000
 100
 10
 1
 0.1
 1
dK-PA
DRC
LDRC
Ideal
dK-PA
DRC
LDRC
Ideal
e
c
n
a
t
s
D
i
 1e+09
 1e+08
 1e+07