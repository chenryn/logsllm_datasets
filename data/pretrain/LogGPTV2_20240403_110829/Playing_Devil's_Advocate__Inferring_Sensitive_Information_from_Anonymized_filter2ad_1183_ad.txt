### Examination of Anonymized Datasets

While the results for HTTP servers may not appear impressive, it is important to note that no level of deanonymization is expected from fully anonymized datasets. Additionally, any server providing unique public services, such as FTP or DNS, would likely yield similar deanonymization results to SMTP servers. Although these findings are concerning, we argue that a determined adversary, given sufficient time, could deanonymize even more servers.

Once deanonymization occurs, the published data can be used to characterize the services offered by the host. Furthermore, if the prefix-preserving anonymization were based on CryptoPAn rather than the Pang et al. model, the deanonymization would not only affect the specific host but also reduce the uncertainty about all other hosts in the dataset, potentially leading to the deanonymization of neighboring addresses (see Appendix A).

In addition to deanonymizing select hosts, we can also characterize the traffic present within various observation points. Table 6 provides a detailed characterization of protocols within select observation points across the three datasets, offering deeper insights into the presence of important servers and the general usage of these observation points.

### Mitigation Strategies

Undoubtedly, there are several mitigation strategies that publishing organizations can implement to thwart inference attacks. One simple strategy is to publish only anonymized NetFlow logs or to remove link layer headers from packet traces, thereby eliminating the hardware addresses of routing devices. Excluding ARP traffic can also make it more difficult to discover link layer topology information.

By remapping port numbers, publishing organizations can hinder an attacker's ability to directly infer the services offered within the private network and make the creation of behavioral profiles more challenging. However, methods do exist to determine the true service based on application layer protocol behavior, as discussed in [31, 9, 18, 16, 7]. Since behavioral profiling is less effective when similar profiles are shared among many hosts (e.g., HTTP vs. SMTP servers), removing hosts with unique behavior could improve the privacy of the dataset. Hiding the true identity of the publishing organization also makes it more difficult for an attacker to gather the necessary information to mount inference attacks. However, this raises the question of how difficult it would be for an attacker to still infer the publishing organization.

It is important to note that these mitigation strategies can significantly diminish the research value of the data. For example, header information and port numbers are crucial for various areas of network research. Removing unique hosts may dramatically affect the traffic characteristics within the dataset. Furthermore, concealing the identity of publishing organizations can complicate the verification of results obtained from the trace data.

### Non-Technical Privacy Protection

There are non-technical means to provide privacy protection for data publishers. One method, employed by data repositories such as Predict and CRAWDAD [23, 8], is to impose legal requirements that the data will be used appropriately and that adequate levels of protection will be put in place for accessing the data. Another possibility is to require that data remain only on secured servers to which researchers have remote access. Violations of these requirements, particularly the former, can be difficult to detect. An even more cumbersome approach is to require that analysis be performed by trusted individuals from the publishing organization itself, thereby preventing any direct access to the data by third parties. While this method is inefficient, it offers better privacy than current anonymization methodologies, though it may significantly impede many types of research.

### Conclusion and Future Work

In this paper, we present new algorithms for inferring sensitive information from network traces that have been anonymized using state-of-the-art techniques. Our work demonstrates that network topology information can be inferred as an artifact of usable network packet traces, and that the behaviors of hosts are an important piece of identifying information that can be leveraged to subvert an anonymization system. At the very least, our evaluation shows that selective recovery of sensitive information from anonymized network data is not as difficult as once thought [10, 19]. Moreover, obfuscating behavioral and network topology information is not a trivial task. Hence, although there are substantial benefits from releasing anonymized data, publishers of such data need to be more cognizant of the fine balance between the utility of the data and the privacy it provides.

Our results raise questions about what, if any, network trace data should be released for research. This is a policy decision that each network owner must make. The results reported in this paper should not be interpreted as an indication of our opinion on the propriety of releasing network data in any particular form. Rather, our goal has simply been to inform the ongoing debate over the release of network traffic for research purposes. We believe that the creation of any overarching policy should be formulated through the combined perspective of the network security research community as a whole.

On the technical front, our study underscores the need for a better understanding of the conditions under which a particular anonymization method (e.g., prefix-preserving anonymization for IP addresses) may provide an adequate privacy solution for a specific set of network traces. For instance, while this paper has shown that servers are at risk of deanonymization through behavioral profiling, it remains unclear to what extent the privacy of clients is threatened. If the lack of client privacy turns out to be a serious issue, then a prudent course of action is to re-examine which types of transformation are appropriate solutions to the problem. As part of future work, we intend to explore a formal framework for examining this question, and in particular, for expressing the privacy properties of anonymization techniques in general.

### Acknowledgments

The authors would like to thank Michael Bailey and Patrick McDaniel for their suggestions for improving an earlier draft of this work. We also thank the anonymous reviewers for their insightful comments. This work is supported in part by NSF Grant CNS-0546350.

### References

[References listed as provided]

### Appendix: Crypto-PAn Flaw Illustration

To illustrate the flaw in Crypto-PAn, consider the case where a single anonymized address \(a' = a'_1a'_2 \ldots a'_{n-1}a'_n\) has been deanonymized to reveal its true address \(a = a_1a_2 \ldots a_{n-1}a_n\). Because of the prefix-preserving nature of Crypto-PAn’s transformation, the attacker also learns the pseudonym for the address \(a^* = a_1a_2 \ldots a_{n-1}\bar{a}_n\). Since \(a\) and \(a^*\) share a prefix of length \(n-1\), the attacker knows that their pseudonyms, \(a'\) and \(a'^*\), must also share an \(n-1\) bit prefix. Therefore, the only valid pseudonym for \(a^*\) must be \(a'^* = a'_1a'_2 \ldots a'_{n-1}\bar{a}'_n\). In general, for any remaining anonymized host with pseudonym address \(b'\), the attacker can remove \(m+1\) bits of uncertainty about the host’s true address \(b\) by deanonymizing a host which shares an \(m\)-bit prefix with \(b\).

For concreteness, consider a simple example with \(n = 3\), given by the binary tree in Figure 2. Initially, the anonymization maintains 7 bits of uncertainty with regard to the permutation used to anonymize the addresses. In other words, there are 128 possible permutations that are allowed by the prefix-preserving anonymization, and each of those permutations is equally likely. Suppose that we are able to deanonymize the address \(011\), as shown in Figure 2. In this case, the bits represented by the shaded nodes are now compromised and therefore lose their uncertainty. The remaining, unknown bits provide 4 bits of uncertainty for this anonymization, or 16 valid permutations for the remaining addresses. In this example, a single deanonymization provides an 87% reduction in the anonymized address space. This reduction can lead to further deanonymization as the set of possible permutations remaining allows the attacker to better refine their search for public information and thereby deanonymize more hosts.

As can be seen by this simple example, within conserved anonymization spaces, a single deanonymization can be devastating to the CryptoPAn anonymization system. For instance, consider the application of CryptoPAn to the Johns Hopkins University trace given in Section 4. This trace contains a subnet with an address space of \(2^8\) and an associated anonymized address space with 255 bits of uncertainty. To deanonymize this entire space requires a significant number of individual deanonymizations, 128 to be exact. In practice, however, organizations frequently allocate addresses in contiguous fashion. This concentrates the density of hosts within a conserved subtree of the entire anonymization space, in essence reducing the entire tree with 255 bits of uncertainty to a substantially smaller subtree. These realistic scenarios underscore the danger of using the prefix-preserving anonymization methodology advocated by Fan et al. in CryptoPAn, and show that the methodology is certainly much more dangerous than the analysis in [10] suggests. Recent work by Brekne et al. takes advantage of this very weakness by using active probing attacks to deanonymize a small subset of hosts within anonymized datasets, which in turn leads to the complete deanonymization of all hosts within the dataset [4, 3].

We note that the approach of Pang et al. does not fall prey to this attack, as they instead use a customized prefix-preserving scheme that decouples the host and subnet portions of the IP address. Specifically, Pang et al. use CryptoPAn only to anonymize external addresses but perform a pseudo-random permutation on the subnet and host portions of internal addresses. This decoupling still allows for the compromised host’s subnet portion of the address to be deanonymized with the use of our attacks, but the other hosts’ bits retain their uncertainty, as do all other subnets within the dataset.