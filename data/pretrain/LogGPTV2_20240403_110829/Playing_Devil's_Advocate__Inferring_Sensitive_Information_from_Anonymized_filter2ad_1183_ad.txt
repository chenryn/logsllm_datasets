nets we examined. While the results for HTTP servers may
not seem impressive, consider that no level of deanonymiza-
tion is expected from the anonymized datasets. Also, con-
sider that any server providing unique public services, such
as FTP or DNS, would obtain similar deanonymization re-
sults to the SMTP servers. While these results are troubling,
we argue that a determined adversary, with the luxury of
time, would be able to deanonymize even more servers.
Once this deanonymization occurs, the published data
can be used to characterize the services offered by that
host. Moreover, if the preﬁx-preserving anonymization
were based on CryptoPAn, rather than the Pang et al.
model, these deanonymizations would not only affect the
deanonymized host, but would also reduce the uncertainty
about all other hosts in the dataset and deanonymize the
neighboring anonymized address (see Appendix A).
In addition to deanonymizing select hosts, we are able
10
to characterize the trafﬁc present within the various obser-
vation points. Table 6 characterizes the protocols within
select observation points in the three datasets and provides
deeper insight into the presence of important servers and the
general usage of the observation points.
trusted individuals from the publishing organization itself,
thereby preventing any direct access to the data by third par-
ties. While inefﬁcient, this method allows for better privacy
than is offered by anonymization methodologies currently
in use. That said, it may also signiﬁcantly impede many
types of research.
6 Mitigation
Undoubtedly, there are mitigation strategies that could
be implemented by publishing organizations to foil the in-
ference attacks demonstrated in this paper. A simple strat-
egy for preventing the creation of network topology maps
is simply to publish only anonymized NetFlow logs, or to
remove link layer headers from packet traces, thereby re-
moving the hardware addresses of routing devices. Addi-
tionally, the exclusion of ARP trafﬁc makes it more difﬁcult
to discover link layer topology information.
By remapping port numbers, publishing organizations
hinder the ability of an attacker to directly infer services
offered within the private network and makes the creation
of behavioral proﬁles more difﬁcult. Note, however, that
methods do exist to determine the true service based on the
application layer protocol behavior, e.g., [31, 9, 18, 16, 7].
Also, because behavioral proﬁling is less effective when
similar proﬁles are shared among a large number of hosts
(note, for example, the results for HTTP versus SMTP
servers),
it may be possible to improve the privacy of
the dataset by removing the hosts whose behavior is most
unique. Finally, hiding the true identity of the publishing
organization makes it more difﬁcult for an attacker to gather
the necessary information to mount the inference attacks
presented. However, this begs the question as to how dif-
ﬁcult it would be for an attacker to still infer the publishing
organization.
It must be noted, however, that these mitigation strate-
gies destroy the research value of the data to varying de-
grees. For instance, header information and port numbers
are important to several areas of network research. The re-
moval of unique hosts may dramatically affect trafﬁc char-
acteristics within the dataset. Furthermore, hiding the iden-
tity of publishing organizations can make veriﬁcation of re-
sults obtained from the trace data difﬁcult.
Of course,
there are other, non-technical, means of
providing privacy protection for data publishers. One
method—employed by data repositories such as Predict and
CRAWDAD [23, 8]—is to impose legal requirements that
the data will be used appropriately, and that adequate lev-
els of protection will be put in place for accessing the data.
Another possibility is to require that data remain only on
secured servers to which researchers have remote access.
Violations of these requirements, particularly the former,
can be difﬁcult to detect, however. An even more cumber-
some approach is to require that analysis be performed by
7 Conclusion and Future Work
In this paper we provide new algorithms for inferring
sensitive information from network traces that have been
anonymized using state-of-the-art techniques. Our work
shows that network topology information can be inferred
as an artifact of usable network packet traces, and that be-
haviors of hosts are an important piece of identifying infor-
mation that can be leveraged to subvert an anonymization
system. At the least, our evaluation shows that selective re-
covery of sensitive information from anonymized network
data is not as difﬁcult as once thought [10, 19]. Moreover,
obfuscating behavioral and network topology information
is not a trivial task. Hence, although there are substantial
beneﬁts from releasing anonymized data, publishers of such
data need to be more cognizant of the thin line between the
utility of the data and the privacy it provides.
Our results naturally raise questions as to what network
trace data, if any, should be released for research. This,
however, is a policy decision that we believe each network
owner must make for himself. The results reported in this
paper should not be construed as an indication of our opin-
ion on the propriety of releasing network data in any par-
ticular form. Rather, our goal has simply been to inform
the continuing debate over the release of network trafﬁc for
research purposes. It is our belief that the creation of any
overarching policy should be formulated through the com-
bined perspective of the network security research commu-
nity as a whole.
On the technical front, our study underscores the need
for a better understanding of the conditions under which
a particular anonymization method (e.g., preﬁx-preserving
anonymization for IP addresses) may provide an adequate
privacy solution for a particular set of network traces. For
instance, while this paper has shown that servers are at risk
of deanonymization through behavioral proﬁling, it remains
unclear to what extent the privacy of clients is threatened.
Indeed, if the lack of client privacy turns out to be a seri-
ous issue, then a prudent course of action is to re-examine
which types of transformation are appropriate solutions to
the problem. As part of future work, we intend to explore a
formal framework for examining this question, and in par-
ticular, for expressing the privacy properties of anonymiza-
tion techniques in general.
11
Acknowledgments
The authors would like to thank Michael Bailey and
Patrick McDaniel for their suggestions for improving an
earlier draft of this work. We also thank the anonymous
reviewers for their insightful comments. This work is sup-
ported in part by NSF Grant CNS-0546350.
References
[1] F. Baccelli and K. B. Kim. TCP Throughput Analysis Under
Transmission Error and Congestion Losses. In Proceedings
of IEEE INFOCOM, pages 2833–2843, March 2004.
[2] M. Bishop, B. Bhumiratana, R. Crawford, and K. Levitt.
How to Sanitize Data.
In Proceedings of the 13th IEEE
International Workshops on Enabling Technologies: Infras-
tructure for Collaborative Enterprises, pages 217–222, June
2004.
˚Arnes.
[3] T. Brekne and A.
Circumventing IP-Address
Pseudonymization. In Proceedings of the 3rd IASTED In-
ternational Conference on Communications and Computer
Networks, October 2005.
[4] T. Brekne, A. ˚Arnes, and A. Øslebø. Anonymization of IP
Trafﬁc Monitoring Data – Attacks on Two Preﬁx-preserving
Anonymization Schemes and Some Proposed Remedies. In
Proceedings of the Workshop on Privacy Enhancing Tech-
nologies, pages 179–196, May 2005.
[5] H. Chang, S. Jamin, Z. M. Mao, and W. Willinger. An Em-
pirical Approach to Modeling Inter-AS Trafﬁc Matrices. In
Proceedings of the ACM SIGCOMM Internet Measurement
Conference, October 2005.
[6] Cisco IOS NetFlow. http://www.cisco.com/go/
netflow.
[7] M. P. Collins and M. K. Reiter. Finding Peer-to-Peer File-
Sharing Using Coarse Network Behaviors. In Proceedings
of the 11th European Symposium on Research in Computer
Security, pages 1–17, September 2006.
[8] CRAWDAD: A Community Resource for Archiving Wire-
http://crawdad.cs.
less Data at Dartmouth.
dartmouth.edu.
[9] J. Early, C. Brodley, and C. Rosenberg. Behavioral authen-
tication of server ﬂows. In Proceedings of the 19th Annual
Computer Security Applications Conference, pages 46–55,
December 2003.
[10] J. Fan, J. Xu, M. H. Ammar, and S. B. Moon. Preﬁx-
preserving IP Address Anonymization: Measurement-
based Security Evaluation and a New Cryptography-based
Scheme. Computer Networks, 46(2):253–272, 2004.
[11] A. Gunnar, M. Johansson, and T. Telkamp. Trafﬁc Matrix
Estimation on a Large IP Backbone - A Comparison on Real
Data. In Proceedings of the ACM SIGCOMM Internet Mea-
surement Conference, pages 149–160, October 2004.
[12] P. Gupta and N. McKeown. Packet Classiﬁcation Using Hi-
erarchical Intelligent Cuttings. In Proceedings of Hot Inter-
connects VII, pages 147–160, 1999.
12
[13] S. Jaiswal, G.
Iannaccone, C. Diot,
J. Kurose, and
D. Towsley. Measurement and Classiﬁcation of Out-of-
Sequence Packets in a Tier-1 IP Backbone. In Proceedings
of IEEE INFOCOM, pages 1199–1209, April 2003.
Iannaccone, C. Diot,
J. Kurose, and
Inferring TCP Connection Characteristics
In Proceedings of IEEE
D. Towsley.
Through Passive Measurements.
INFOCOM, pages 1582–1592, March 2004.
[14] S. Jaiswal, G.
[15] H. Jiang and C. Dovrolis. Source-Level IP Packet Bursts:
Causes and Effects. In Proceedings of ACM SIGCOMM In-
ternet Measurement Conference, October 2003.
[16] T. Karagiannis, K. Papagiannaki, and M. Faloutsos. BLINC:
Multilevel Trafﬁc Classiﬁcation in the Dark. In Proceedings
of ACM SIGCOMM, pages 229–240, August 2005.
[17] P. McDaniel, S. Sen, O. Spatscheck, J. V. der Merwe,
W. Aiello, and C. Kalmanek. Enterprise Security: A Com-
munity of Interest Based Approach. In Proceedings of Net-
work and Distributed Systems Security, February 2006.
[18] A. W. Moore and D. Zuev. Internet Trafﬁc Classiﬁcation Us-
ing Bayesian Analysis Techniques. In Proceedings of ACM
SIGMETRICS, pages 50–60, June 2005.
[19] R. Pang, M. Allman, V. Paxson, and J. Lee. The Devil and
Packet Trace Anonymization. ACM Computer Communica-
tion Review, 36(1):29–38, January 2006.
[20] R. Pang and V. Paxson. A High-Level Environment for
Packet Trace Anonymization and Transformation. In Pro-
ceedings of SIGCOMM, pages 339–351, August 2003.
[21] K. Papagiannaki, N. Taft, and A. Lakhina. A Distributed
Approach to Measure IP Trafﬁc Matrices. In Proceedings
of the ACM SIGCOMM Internet Measurement Conference,
pages 161–174, October 2004.
[22] V. Paxson. Strategies for Sound Internet Measurements. In
Proceedings of the ACM SIGCOMM Internet Measurement
Conference, pages 263–271, October 2004.
[23] PREDICT: Protected Repository for the Defense of In-
http://www.
frastructure Against Cyber Threats.
predict.org.
[24] S. Singh, F. Baboescu, G. Varghese, and J. Wang. Packet
Classiﬁcation Using Multidimensional Cutting. In Proceed-
ings of ACM SIGCOMM, pages 213–224, August 2003.
[25] A. Slagell, J. Wang, and W. Yurcik.
Network Log
Anonymization: Application of Crypto-PAn to Cisco Net-
Flows. In Proceedings of NSF/AFRL Workshop on Security
Knowledge Management, September 2004.
[26] A. Slagell and W. Yurcik. Sharing Computer Network Logs
for Security and Privacy: A Motivation for New Methodolo-
gies of Anonymization. In Proceedings of SECOVAL: The
Workshop on the Value of Security through Collaboration,
pages 80–89, September 2005.
[27] TCPdPriv.
http://ita.ee.lbl.gov/html/
contrib/tcpdpriv.html.
[28] TCPurify.
http://irg.cs.ohiou.edu/
˜eblanton/tcpurify/.
[29] V.Paxson. Bro: A System for Detecting Network Intruders
in Real-Time. Computer Networks, 31(23-24):2435–2463,
December 1999.
[30] R. Wang, G. Pau, K. Yamada, M. Y. Sanadidi, and M. Gerla.
TCP Startup Performance in Large Bandwidth Delay Net-
works. In Proceedings of IEEE INFOCOM, pages 796–805,
March 2004.
then able to deanonymize the address 011, as shown in Fig-
ure 2. In this case, the bits represented by the shaded nodes
are now compromised and therefore lose their uncertainty.
The remaining, unknown bits provide 4 bits of uncertainty
for this anonymization, or 16 valid permutations for the re-
maining addresses. In this example, a single deanonymiza-
tion provides an 87% reduction in the anonymized address
space. This reduction can lead to further deanonymization
as the set of possible permutations remaining allows the at-
tacker to better reﬁne their search for public information and
thereby deanonymize more hosts.
As can be seen by this simple example, within conserved
anonymization spaces a single deanonymization can be dev-
astating to the CryptoPAn anonymization system. For in-
stance, consider the application of CryptoPAn to the Johns
Hopkins University trace given in Section 4. This trace con-
tains a subnet with an address space of 28 and an associated
anonymized address space with 255 bits of uncertainty. To
deanonymize this entire space requires a signiﬁcant number
of individual deanonymizations, 128 to be exact. In prac-
tice, however, organizations frequently allocate addresses
in contiguous fashion. This concentrates the density of
hosts within a conserved subtree of the entire anonymiza-
tion space, in essence reducing the entire tree with 255 bits
of uncertainty to a substantially smaller subtree. These re-
alistic scenarios underscore the danger of using the preﬁx-
preserving anonymization methodology advocated by Fan
in CryptoPAn, and shows that the methodology is
et al.
certainly much more dangerous than the analysis in [10]
suggests. Recent work by Brekne et al.
takes advantage
of this very weakness by using active probing attacks to
deanonymize a small subset of hosts within anonymized
datasets, which in turn leads to the complete deanonymiza-
tion of all hosts within the dataset [4, 3].
We note that the approach of Pang et al. does not fall
prey to this attack, as they instead use a customized preﬁx-
preserving scheme that decouples the host and subnet por-
tions of the IP address. Speciﬁcally, Pang et al. use Cryp-
toPAn only to anonymize external addresses, but performs
a pseudo-random permutation on the subnet and host por-
tions of internal addresses. This decoupling still allows for
the compromised host’s subnet portion of the address to be
deanonymized with the use of our attacks, but the other
hosts’ bits retain their uncertainty as do all other subnets
within the dataset.
[31] C. V. Wright, F. Monrose, and G. M. Masson. On Infer-
ring Application Protocol Behaviors in Encrypted Network
Trafﬁc.
Journal of Machine Learning Research, Special
Topic on Machine Learning for Computer Security, To ap-
pear, 2006.
[32] Y. Xiang, J.-C. Liu, K. G. Shin, and W. Zhao. On the Model-
ing and Optimization of Discontinuous Network Congestion
Control Systems. In Proceedings of IEEE INFOCOM, pages
2812–2820, March 2004.
[33] K. Xu, Z. Zhang, and S. Bhattacharyya. Proﬁling Internet
Backbone Trafﬁc: Behavior Models and Applications.
In
Proceedings of ACM SIGCOMM, pages 169–180, August
2005.
[34] Y. Zhang, M. Roughan, C. Lund, and D. Donoho. An
Information-Theoretic Approach to Trafﬁc Matrix Estima-
tion. In Proceedings of ACM SIGCOMM, pages 301–312,
August 2003.
A Crypto-PAn
1a(cid:48)
2. . .a(cid:48)
To illustrate the ﬂaw in Crypto-PAn, consider the case
n−1a(cid:48)
where a single anonymized address a(cid:48) = a(cid:48)
n
has been deanonymized to reveal its true address a =
a1a2. . .an−1an. Then, because of the preﬁx-preserving na-
ture of Crypto-PAn’s transformation, the attacker also learns
the pseudonym for the address a∗ = a1a2. . .an−1 ¯an. Be-
cause a and a∗ share a preﬁx of length n − 1, the attacker
knows that their pseudonyms, a(cid:48) and a∗(cid:48), must also share
an n − 1 bit preﬁx. Therefore the only valid pseudonym
for a∗ must be a∗(cid:48) = a(cid:48)
¯a(cid:48)
n. In general, for any
remaining anonymized host with pseudonym address b(cid:48), the
attacker can remove m + 1 bits of uncertainty about the
host’s true address b by deanonymizing a host which shares
an m-bit preﬁx with b.
2. . .a(cid:48)
1a(cid:48)
n−1
Figure 2. Binary tree with nodes indicating bits of the
anonymized address. Root indicates left-most bit, and shaded
nodes indicate compromised bits where the mapping to the
unanonymized address is known.
For concreteness, consider a simple example with n = 3,
given by the binary tree in Figure 2. At the onset, the
anonymization maintains 7 bits of uncertainty with regard
to the permutation used to anonymize the addresses.
In
other words, there are 128 possible permutations that are
allowed by the preﬁx-preserving anonymization, and each
of those permutations is equally likely. Suppose that we are
13
10111011110010101010011010000010Unknown bitsKnown bitsCompromisedaddressInferred bits010101Inferredaddress