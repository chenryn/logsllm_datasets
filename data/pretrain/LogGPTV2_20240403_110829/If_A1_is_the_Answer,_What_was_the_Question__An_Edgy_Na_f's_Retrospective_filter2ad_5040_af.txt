with  panelists  Peter  Neumann,  Gerry  Popek,  Pete 
Tasker, Steve Walker, and Clark Weissman [15]. 
features  and 
The  overall  set  of  metrics  divided  into four aspects 
of  assurance 
four  of  protection 
mechanism. These were displayed as sectors of a set of 
concentric circles wherein the center circle represented 
Null  Confidence,  and  containing  circles  exhibited 
greater assured protections. 
The decompositions were: 
1.  ASSURANCE FEATURES
a.  Hardware 
i.  Software Checks 
ii.  Hardware Fault Detection 
iii. Design Correctness Formally Verified 
iv. Fault Tolerant Hardware 
b.  Software 
i.  Formal Design Specifications 
ii.  Proven Design Specifications 
iii. Design Correctness Formally Verified 
iv. Verified Implementation 
c.  Development and Testing 
i.  Penetration Exercise 
ii.  Modern Programming Practices 
iii. Automated Testing 
d.  Operation and Maintenance 
i.  Configuration Management 
ii.  Reverification Aids 
iii. Read-Only Memory 
2.  PROTECTION MECHANISM
a.  Prevention 
i.  Data Security Enforcement 
ii.  System Integrity 
iii. Collusion Enforcement 
iv. Sophisticated Threat (Denial of Service) 
b.  Detection 
i.  Audit Recording 
ii.  Security Officer Aids 
iii. Detection Analysis 
c.  Authorization Granularity 
i.  Physical Devices 
ii.  Logical Devices 
iii. Data Values 
d.  Policy Interface 
i.  Passwords 
ii.  Labels and Access Control Lists 
iii. Security Administration Tools 
These  levels  within  these  eight  sectors  were  not 
directly  comparable  as  requirements.  Rather,  they 
illustrated growing degrees of confidence in a system’s 
security  that  would  be  gained  along  each  of  the 
measures  as  additional  requirements  were  satisfied 
moving outwards along the sector’s axis from the Null 
Confidence  center.  No  evaluation  methodology  was 
proposed. 
2.6.4. Air Force Summer Study. Following the Miami 
workshop,  a  month-long  Air  Force  Summer  Study  in 
Computer  Security  was  conducted  at  the  Draper  Labs 
in  Cambridge,  Massachusetts.  Evaluation  criteria  and 
methods  were  discussed  at  the  Summer  Study,  along 
with  additional  topics  in  database  security,  network 
security,  the  utility  of  formal  methods  and  other 
assurance  techniques. The Summer Study attracted the 
active  participation  of  security  researchers,  developers 
and  practitioners  from  the  United  States,  Canada,  the 
United Kingdom, and Germany. Although much of the 
Summer  Study  included  status  reports  on  a  variety  of 
projects,  it  was  mostly  conducted  as  a  workshop  in 
which  ideas  and  proposals  were  voiced  and  discussed 
at length.  
Several spirited discussions raised controversies that 
are  yet  to  be  resolved.  These  included:  whether  it  is 
possible  to  verify  the  security  of  a  system  built  of 
composed subsystems; whether it is possible to build a 
secure  multilevel  database  management  system  that 
offers “full functionality”; and whether it is possible to 
produce a “proof of correctness” for a system that will 
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:37:23 UTC from IEEE Xplore.  Restrictions apply. 
the 
be  accepted  as  proof  of  security  among 
mathematically  sophisticated  community  [11].  The 
database  management  security  presentations  and 
discussions  showed  major  problems  from  the  use  of 
inference  against  the  use  of  formulary-like  data-
dependant  access  control  policies.  Dennis  Tsichritsis 
presented  a  damning  indictment  against  least  privilege 
multilevel  database  management  systems,  such  as  the 
Hinke-Schaefer model maligning them as “strait-jacket 
DBMS”. 
Participants  in  the  evaluation  criteria  discussion 
included Jack Adams (IBM); H.O. Lubbes (NRL); Pete 
Tasker,  Stan  Ames  and  Grace  Nibaldi  (MITRE); 
Christian Jahl (IABG, Germany); Clark Weissman and 
me  (SDC).  The  results  of  this  set  of  discussions  were 
ripe for refinement. 
2.6.5.  The  Nibaldi  Report,  1979.  Steve  Walker,  now 
in the Office of the Secretary of Defense for C3I, tasked 
MITRE  to  elaborate  on  the  Lee  Panel’s  report’s 
Security  Metric.  Grace  Nibaldi  produced  a  MITRE 
technical  report  [20]  in  October  1979  in  which  seven 
levels of protection were stated. These were: 
0. No  Protection:  where 
there 
confidence 
information. 
in 
the  system’s  ability 
is  no  basis  for 
to  protect 
1. Limited Controlled Sharing: where recognition of 
some  attempt  to  control  access  is  given,  but  only 
limited confidence in the viability of the controls is 
indicated. 
2. Extensive  Mandatory  Security:  where  minimal 
requirements  on  the  protection  policy  must  be 
satisfied;  assurance 
is  derived  primarily  from 
attention to protection during the system design and 
extensive testing. 
3. Structured  Protection  Mechanism:  where 
additional  confidence  is  gained through methodical 
construction  of 
the  protection-related  software 
components  of  the  operating  system  (i.e.,  the  TCB 
implementation), 
programming 
techniques. 
and  modern 
4. Design  Correspondence:  formal  methods  are 
the  TCB 
the  design  of 
to  verify 
employed 
implementation. 
5. Implementation  Correspondence:  where  formal 
methods  are  employed  to  verify  the  software 
implementation of the design. 
6. Object  Code  Analysis:  where  object  code  is 
analyzed and the hardware support is strengthened. 
Significantly,  the  Nibaldi  report  opens  with  a  15-
page tutorial section describing and going into issues of 
“primary  factors”  (policy,  mechanism,  assurance)  and 
in 
is  presented 
“supporting  factors”  such  as  ease  of  use  and  overall 
functionality. Much of the lore characterizing the R&D 
community’s  state-of-the-art 
this 
section,  which  includes  nearly  a  page  on  denial  of 
service  considerations.  Additionally,  confinement, 
detection,  coding  and  design  methodologies,  auditing, 
and  recovery  are  presented  in  an  overview.  The 
Reference  Monitor  Concept  is  not  enunciated,  and  the 
term  TCB is used in lieu of security kernel throughout 
the  report,  and  thus  there  are  no  explicit  requirements 
for  minimization  of  either  size  or  complexity  of  the 
protection mechanism at the higher assurance levels. 
Each  of  the  six  protection  levels  subsumed  the 
requirements  of  the  prior  level  and  had  to  satisfy 
general  criteria  characterizing  attributes  of  Protection 
Policy,  Specific  Protection  Mechanisms, 
and 
Assurance.  In  addition,  a  section  was  provided  to 
address 
risk”  associated  with  a 
recommended 
deemed 
appropriate  for  the  system.  The  specific  criteria  are 
presented in descriptive, rather than prescriptive, terms 
based  on  the  tutorial’s  content.  For  example,  the 
treatment of storage channels from Level 4 reads: 
the  “residual 
environment 
operational 
A specific requirement of the system is that it be able 
to  audit  the  use  of  storage  channels.  These  channels 
might  be  detected  as  a  result  of 
the  formal 
verification  techniques  or  by  penetration  analysis; 
however,  they  may  not  be  easily  removed  without 
affecting the system in an adverse way. By imposing 
restrictions  on  the  way  resources  are  being  shared, 
the  system  may  no  longer  be  allowed  to  use  an 
optimal algorithm for resource utilization. The use of 
such  channels  can  be  detected  with  auditing 
mechanisms,  and  the  information  obtained  from  the 
auditing mechanisms can be analyzed later to find the 
source and seriousness of the channels’ exploitation. 
The  Nibaldi 
proposal 
included 
the 
then 
unachievable Level 6 criteria, which offered: 
…a  degree  of  confidence  which  is  only  imaginable 
from  today’s  technology.  Any  threats  at  this  level 
would  be  a  result  of  highly  improbable  hardware 
errors,  or,  more  likely,  a  failure  in  the  personnel, 
administrative,  physical,  or  communications  security 
provisions…. At level 6, formal analysis of the object 
code  produced  by 
required. 
Axiomatization of the underlying hardware base, and 
formal  verification  of  the  security-relevant  hardware 
mechanisms,  are  also  required.  It  is  recognized, 
however,  that  these  requirements  are  beyond  the 
anticipated  state-of-the-art  of  verification  in  the 
1980s…. 
the  compiler 
is 
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:37:23 UTC from IEEE Xplore.  Restrictions apply. 
From the Pentagon, Steve Walker had put together a 
few  assorted  teams  of  experts  from  academia  and 
industry  with  the  intention  of  providing  assistance  to 
vendors  who  were  interested  in  developing  trusted 
products that could be used by the DoD. Ted Lee and I 
participated  in  several  of  these  efforts  along  with  a 
seasoned  group  of  security  practitioners  like  Pete 
Tasker,  John  Woodward,  Anne-Marie  Claybrook, 
Susan  Rajunas,  and  Grace  Nibaldi  from  MITRE 
Bedford.  Under  nondisclosure  agreements,  the  teams 
were  also  performing  ad  hoc  product  “evaluations” 
using the Nibaldi draft criteria. 
One  of  the  products  under  consideration  didn’t 
appear to fit Nibaldi’s working criteria at all well. This 
was  Tymshare  Corporation’s  capability-based  Gnosis 
system.  Susan  Rajunas,  who  had  been  leading  the 
evaluation, was particularly articulate about the Gnosis 
design  and  strength  of  its  mechanisms.  But  there  were 
numerous open questions about the definition of secure 
state,  of  how  one  attained  an  initial  secure  state,  how 
individual  accountability  could  be  established  in  an 
environment  where  capabilities  were  inscrutable,  and 
where  possession  of  a  capability  could conceivably be 
used  by  a  Trojan  horse.  Rajunas  was  funded  to 
assemble a workshop to investigate assembling a set of 
interpreted  criteria  for  evaluating  a  trusted  capability 
base operating system.  
I  requested  that  Earl  Boebert,  who  led  a  project  to 
develop  a  system  based  on  PSOS,  the  Secure  Ada 
Target  (SAT),  write  a  paper  for  an  NCSC  Conference 
showing that multilevel security confinement could not 
be  assured  in  a  pure  capability  based  operating 
system.[4]  A  year  earlier,  Paul  Karger  had  written  a 
paper  [29]  on  a  design  that  augmented  capabilities  to 
overcome such intrinsic shortcomings.  
this 
time, 
About 
I  heard  Butler  Lampson’s 
observation:  “Capability  based  systems  are  the  way  of 
the future—and they always will be.” 
3. TCSEC publication 
In  February  1981,  the  Department  of  Defense 
Computer  Security  Evaluation  Center  (DOD/CSEC) 
was  authorized  under  Directive  5215.1  and  the  DoD 
Computer  Security  Center  (DOD/CSC)  was  formed  at 
the  National  Security  Agency  (NSA)  in  July  of  that 
year. Melville H. Klein and Colonel Roger Schell were 
designated  as  Director  and  Deputy  Director.  The 
Center  grew  from  the  DoD’s  Computer  Security 
Initiative.  The  DoD  was  aware  of  the  growing  cost  of 
procuring and maintaining its special-purpose computer 
systems—systems  that  became increasingly difficult to 
maintain as manufacturers discontinued hardware lines 
and  developers  moved  on  to  new  projects.  Over  time, 
internals  knowledge  about  these  systems  evaporated 
and,  critical  as  they  may  have  been  to  the  national 
security, they became fragile and unreliable. Hence, the 
Center  was  formed  to  implement  the  strategy  of 
encouraging  the  widespread  availability  of  trusted 
products  produced  and  maintained  by  system  vendors. 
These trusted products would be evaluated gratis by the 
Center  and  placed  on  an  Evaluated  Products  List  that 
could  be  used  by  vendors  in  their  advertising  and  by 
procurement officers in their purchase specifications. 
When  I  arrived  as  Chief  Scientist  early  in  April 
1982,  Dan  Edwards  was  directing  the  Standards  and 
Products  organization,  with  Mario  Tinto  responsible 
for  product  evaluations;  Steve  Barnett  directed  the 
Application Certifications organization. 
3.1. The evolution of TCSEC drafts 
Paragraphs 
Prior to my arrival at the Center, work had begun on 
transforming the Nibaldi proposals into draft evaluation 
criteria. 
selected 
requirements  had  been  written,  and  there  was  general 
agreement as to a general feeling of what was salutary 
and  what  was 
lacking  among  mechanisms  and 
assurance  techniques.  But,  at  best,  there  were  more 