5M. Ray, “Authentication Gap in TLS Renegotiation,” Extended Subset
(blog), 4 Nov 2009.
513
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:51:35 UTC from IEEE Xplore.  Restrictions apply. 
A. Certiﬁcation
A web certiﬁcate binds a public signing key to an ‘iden-
tity.’ The correctness of the binding is asserted through a
digital signature, by a CA implicitly expected to maintain
the accuracy of the binding over time. TLS enables client
software to establish a conﬁdential channel terminated by the
entity holding the private key associated with the certiﬁcate.
The essential attribute that all HTTPS server certiﬁcates
have is a domain name which the certiﬁcate holder controls.
This is placed in the commonName (CN) attribute under
Subject, unless one or more domains are indicated in the
subject alternative name ﬁeld in an X.509 extension. If an
entity requests a certiﬁcate for a domain name, the CA will
typically challenge the requester to demonstrate control over
the domain. Note that this implicitly assumes that domain
names are mapped to the correct webserver (IP address), a
mapping accomplished through DNS. Such certiﬁcates are
called domain validated (DV) certiﬁcates.
Issued certiﬁcates may include additional CA-veriﬁed
information, such as organization name and postal address.
Validation procedures have degraded over time, exempliﬁed
by more CAs using a completely automated process (e.g.,
automated DV certiﬁcates). In response, the CA/Browser
Forum established extended validation (EV) certiﬁcates and
guidelines for their issuance,6 including diligent human val-
idation of a site’s identity and business registration details.
Security Issues (Certiﬁcation)
Hostname Validation (CAs): Automated domain val-
idation services provided by a CA will typically send a
validation email to a ﬁxed email address associated with
the CN’s top-level domain (e.g., admin@domain) or one
taken from CN’s WhoIS record. Both mechanisms rely on
accurate domain information; thus any disruption to the CA’s
ability to receive accurate DNS records (e.g., DNS cache
poisoning [61], [94]) could result in an improperly issued
certiﬁcate. For email validation, CAs should also ensure the
email address is only accessible to the site administrator. For
example, a certiﬁcate for the login page of Microsoft’s public
webmail service, login.live.com (formally Hotmail),
was wrongfully issued by a CA that offered to validate
through PI:EMAIL, an email ad-
dress that was open to public registration [111].
Even with non-automated validation, an adversary may
employ social engineering. For example, in 2001, a CA
wrongfully issued two certiﬁcates to someone posing as a
current Microsoft employee.7
Hostname Validation (Clients): Although current
browser platforms validate that a received site certiﬁcate
6CA/Browser Forum: Guidelines For The Issuance And Management Of
Extended Validation Certiﬁcates (v1.4), 2012.
7Microsoft MS01-017: Erroneous VeriSign-Issued Digital Certiﬁcates
Pose Spooﬁng Hazard, 22 Mar 2001.
matches the hostname, some non-browser software had inad-
equate validation. Many mobile applications display HTTPS
content and one study found that 1074 of 13500 Android
apps did not validate the hostname (aside from other TLS
implementation ﬂaws) [42]. A concurrent study identiﬁed
the lack of hostname validation in cloud clients (Ama-
zon’s EC2 libraries), e-commerce backend systems (Paypal’s
SDK), online shopping carts, ad networks (AdMob), and
other non-browser software employing HTTPS [49].
Parsing attacks: Flaws relating to parsing enable im-
proper issuance (incorrect CA parsing) and validation (in-
correct browser parsing) of certiﬁcates. Certiﬁcate requests
containing a null character (Ø) in the CN can be misinter-
preted. For example, a CN of bank.comØevil.com was
validated by some CAs’ automated domain validation as
evil.com while browsers have been known to accept it
as a valid CN for bank.com [62], [71]. A dangerous vari-
ation is *Øevil.com, which grants a universal wildcard
certiﬁcate acceptable to older NSS-based browsers [71].
Some CAs and browsers have also inconsistently in-
terpreted the object IDs specifying which string is the
commonName:
for example, CN is identiﬁed by OID
2.5.4.3 but some browser parsers accepted 2.5.4.003 or
2.5.4.18446744073709551619 (64-bit uint overﬂow) as the
CN, while some CAs ignore them [62].
EV downgrading: Many of the problems associated
with automated domain validation are claimed to be thwarted
by EV certiﬁcates. However a site that holds an EV certiﬁ-
cate can be downgraded to normal HTTPS by a man-in-
the-middle (MITM) attack with a fraudulent DV certiﬁcate.
Furthermore, such an adversary can arrange for the EV cer-
tiﬁcate to be displayed through a “rebinding” attack [112],
[96] that is consistent with the browsers’ origin policy [55].
B. Anchoring Trust
Validating that a certiﬁcate request comes from the entity
speciﬁed in the SubjectName is an important CA func-
tion. As no one entity has universal control of all names-
paces, it is not clear who is best suited for such validation.
As a result, there exists a spectrum of CAs, with the majority
of site certiﬁcates being issued by commercial CAs with ties
to the security or domain registration industries.
Software vendors (e.g., Microsoft, Apple, Mozilla, Opera)
conﬁgure a default
list of self-signed CA certiﬁcates in
operating systems and/or browser as trust anchors. Each
HTTPS site whose site certiﬁcate the browser accepts is thus
de facto trusted by users because its certiﬁcate has been
vouched for (directly or indirectly) by at least one of the
trust anchors. Mozilla’s Firefox 15, for example, includes
∼150 trust anchors from ∼50 organizations. However since
CAs with trust anchors can issue certiﬁcates empowering
other organizations to act as a CA (see below), the number
of automatically trusted CAs is much larger. The SSL Ob-
servatory reports that between Microsoft’s Internet Explorer
514
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:51:35 UTC from IEEE Xplore.  Restrictions apply. 
and Mozilla’s Firefox, ∼1500 CA certiﬁcates from ∼650
organizations8 in ∼50 countries are browser-accepted [39].
On private networks, particularly in corporate environ-
ments, a root certiﬁcate for the organization may be con-
ﬁgured as a trust anchor on employees’ machines. The
organization can then proxy (i.e., MITM) HTTPS connec-
tions with middleware boxes speciﬁcally designed for this
task to perform content inspection. The corporation may
even be able to obtain a browser-accepted CA certiﬁcate
for doing this, although issuing such a certiﬁcate is against
CA policies. For example, Trustwave admitted to issuing
certiﬁcates for this purpose but later revoked them,9 while,
purportedly by accident, TURKTRUST issued certiﬁcates
that were discovered being used this way.10 The mobile
browser OperaMini openly proxies HTTPS connections in
this way to allow compression between the client and
proxy [83]. Proxies assume all responsibility for certiﬁcate
validation, with a recent study ﬁnding that many implemen-
tations had validation ﬂaws [59].
Security Issues (Anchoring Trust)
CA Compromise: Without further enhancement (i.e.,
without the primitives evaluated in Section V), any trusted
CA can issue a browser-acceptable certiﬁcate for any site.
Thus an adversary can target the weakest CA to obtain a
fraudulent certiﬁcate and, assuming clients would not notice
a different CA,
this certiﬁcate enables the adversary to
evade detection in a MITM attack. In 2011, two CAs were
compromised: Comodo11 and DigiNotar.12 In both cases,
certiﬁcates for high proﬁle sites were illegitimately obtained
and, in the second case, reportedly used in a MITM attack.13
Compelled Certiﬁcates: Concerns have also been raised
about the abilities of nation-states to compel certiﬁcates
from a browser-accepted CA [93]. Governmental entities
are often well-positioned to proxy (i.e., MITM) HTTPS
connections by controlling network infrastructure and/or
compelling ISPs. For example, reportedly, HTTPS connec-
tions to Facebook over multiple ISPs within Syria were
MITMed with a Facebook certiﬁcate issued by the Syrian
Telecom Ministry.14 In this case, the Ministry was not a
browser-acceptable CA, and so it is not an example of a
8The reported number of organizations may be inﬂated due to variation
in organization name (or division) across certiﬁcates. Also in some cases,
the issuing CA retains actual possession of the intermediate certiﬁcate.
9Bug 724929, Bugzilla@Mozilla, reported: 7 Feb 2012.
10A. Langley, “Enhancing digital certiﬁcate security,” Google Online
Security Blog, 3 Jan 2013.
11J. Appelbaum, “Detecting Certiﬁcate Authority compromises and web
browser collusion,” Tor Blog, 22 Mar 2011.
12“Black Tulip Report of the investigation into the DigiNotar Certiﬁcate
Authority breach,” Fox-IT (Tech. Report), 13 Aug 2012.
state compelled certiﬁcate, but one that demonstrates the
danger posed.
C. Transitivity of Trust
Given that trust anchors can issue intermediate CA certiﬁ-
cates (and intermediates can be enabled to do the same), a
site certiﬁcate is browser-acceptable if the browser can build
a chain of certiﬁcates that lead to a trust anchor. One study
found 20% of valid certiﬁcates required no intermediate and
38% used one [18].
The path validation algorithm is speciﬁed in RFC 5280 to
begin with the server certiﬁcate and build the path “forward”
to the trust anchor, although there are efﬁciencies to building
in reverse [40]. Certiﬁcate chains are subject to constraints.
Intermediate CA certiﬁcates must be authorized to be a CA
(CA:TRUE under basicConstraints). CA certiﬁcates
may also restrict the number of CAs that can precede it
(i.e., toward the leaf) in the chain (e.g., pathlen:0 un-
der basicConstraints means the CA cannot delegate
further CAs and can only sign leaf certiﬁcates).
Servers are mandated to present an entire chain, but in
practice, browsers may use a chain discovery mechanism
(e.g., AIA: Authority Information Access). Intermediate CAs
are invisible to client software until
their certiﬁcate is
encountered, and yet they are essentially as trusted as an
anchor. This makes it difﬁcult for users or OSs/browsers to
preemptively know about and remove unacceptable interme-
diate CA certiﬁcates. As above, while only ∼50 organiza-
tions have visible trust anchors, many more organizations
have acceptable intermediate CA certiﬁcates. Technically,
Ford, Marks and Spencer, and the US Dept. of Homeland
Security are authorized for issuing acceptable certiﬁcates for
any website [39].
Security Issues (Transitivity of Trust)
Basic Constraints: Certiﬁcate path validation must also
check the constraints during validation, in particular that
each intermediate CA certiﬁcate has CA:TRUE set under
basicConstraints. If this is not checked, a certiﬁcate
obtained for a webserver could issue browser-acceptable
certiﬁcates for any other website. Initially not checked by
Microsoft’s CryptoAPI,15 this has now been patched.16 A
decade later, the issue resurfaced in Apple’s iOS.17
D. Maintenance of Trust
Another important function of a CA is to terminate the
validity of a certiﬁcate prior to its preconﬁgured expira-
tion date upon becoming aware of certain circumstances,
e.g., mistaken issuance, site or CA compromise, afﬁliation
13C. Arthur, “Rogue web certiﬁcate could have been used to attack Iran
(online), 5 Apr 2002.
dissidents,” The Guardian, 30 Aug 2011.
14P. Eckersley, “A Syrian Man-In-The-Middle Attack against Facebook,”
16MS02-050: Microsoft certiﬁcate validation ﬂaw, 2002.
17CVE-2011-0228: iOS certiﬁcate chain validation issue in handling of
15M. Marlinspike, “Internet Explorer SSL Vulnerability,” thoughtcrime
EFF Deeplinks (blog), 5 May 2011.
X.509 certiﬁcates, 2011.
515
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:51:35 UTC from IEEE Xplore.  Restrictions apply. 
change, a superseding certiﬁcate, or cessation of the holder’s
operations [45]. Revocation status must also be available
through the issuing CA, i.e., by certiﬁcate revocation lists
(CRLs) or online certiﬁcate status checking protocol (OCSP)
responders. CRLs are signed by the CA’s key while OCSP
responses are produced by servers designated by the CA.
CAs often prefer OCSP responders as they can be updated
on-demand without use of the (generally ofﬂine) CA signing
key and due to response size.
In practice, some CA certiﬁcates do not include any re-
vocation information, and when OCSP responders are spec-
iﬁed, they are often unresponsive. Thus, current browsers
fail open, accepting certiﬁcates for which revocation in-
formation cannot be located (browsers should downgrade
all EV certiﬁcates to a regular certiﬁcate, or warn, as
responsive revocation is an EV requirement).18 In response
to the failings of revocation, some browsers (e.g., Chrome)
maintain an updatable certiﬁcate blacklist (see Section V-C).
While the mandatory expiration date ﬁeld provides an
eventual default form of revocation, many certiﬁcates are
valid for multiple years (the median lifetime varies across
measurements: 12 [86], 12–15 [54], or 24 [18] months).
Security Issues (Maintenance of Trust)
Blocking Revocation: If an adversary is able to obtain
a fraudulent certiﬁcate for a site which is subsequently
revoked, it may take several days for this information to be
available to clients, even with OCSP, due to caching [101].
Even then, the clients may not be able to reach an OCSP
responder or CRL distribution point. Further, a MITM
adversary could respond to a client’s request with an HTTP
error (e.g., error 500: internal server error) or OCSP error
(response status 3: try again later [71]); in this case, the
revoked certiﬁcate typically continues to be accepted.
Similarly, a MITM adversary could prevent a browser
blacklist from updating but this would require persistent
blocking—the OCSP check would only occur when the
client encounters the fraudulent certiﬁcate and the MITM
adversary is already in position. The CA’s CRL could have
been obtained by checking an unrelated certiﬁcate.
Ownership Transfer: Since TLS site certiﬁcates are
bound to a domain name, certiﬁcates should be revoked
when domain ownership expires or is transferred. This is
however not typically enforced. For example, Facebook (the
target of the Syrian MITM attack mentioned above) acquired
fb.com for $8.5M in 2010 but can have no assurance that the
previous owner does not have a valid unexpired certiﬁcate
for the site that could enable a MITM attack.19
E. Indication and Interpretation of Trust
Some HTTPS security protections rely on user due dili-
gence. Perhaps naively, users are expected to verify the
outcome of each connection attempt, typically indicated by
a visual cue in the browser window. More diligent users
may verify certiﬁcate details; e.g., that the subject name—
organization, address, country—matches their expectation.
Finally, the browser may require users to respond to warning
dialogues in some cases.
Browser Security Cues: Desktop browsers typically use
two primary cues to indicate a website is being accessed
over HTTPS: (1) the URL in the address bar begins with
https:// and (2) a lock icon is displayed somewhere
in the browser’s chrome (i.e., the boundary region of the
window populated by the browser itself). Typically, clicking
on the lock icon will display information about the certiﬁ-
cate. One impedance to better user understanding of browser
security indicators is the inconsistency of how cues are
implemented across browsers [19]. Guidelines for browser
cues have been published.20
One study used eyetracking to ﬁnd that of 16 primed
participants interacting with an HTTPS site, 11 viewed the
lock, 7 the https:// indicator, and only 2 interacted with
the lock to display certiﬁcate information [108]. Another
study found that 63 of 67 participants logged into a hypo-
thetical banking website with all HTTPS indicators removed,
suggesting that many did not notice the difference [90]
(although one researcher argues this is enlarged by ﬂaws in
the study21). The introduction of EV certiﬁcates added a new
desktop browser cue, typically inducing the colour green in
the address bar itself or its font. Today’s desktop browsers
also display the organization name from the certiﬁcate in
the address bar, alongside the URL. One study found that
of 28 users, the “less than 40%” who actually looked at
browser cues (measured via eyetracking) was slightly but
not signiﬁcantly more likely to interact with an EV site than
a DV (domain validated) site [92]. Aside from cues, some
users appear to simply assume a page is secure based on the
information being requested [46], [35].