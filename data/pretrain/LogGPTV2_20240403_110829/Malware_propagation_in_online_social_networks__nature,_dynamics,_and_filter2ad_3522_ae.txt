In a new set of experiments, we let k be chosen from
f1; 5; 25; 125; 625; 1000; 1500; 2000g and for each case we per-
form 200 sample runs. The user click probability is set to
be 0.5. The eﬀectiveness of the three sanitization schemes is
illustrated in Figure 14. We note that the scheme by active
neighbors performs slightly better than the one by edges,
especially when there are a signiﬁcant number of nodes re-
moved. When the number of removed nodes is less than 125,
these two schemes are almost equivalent because at most
one node diﬀers. As explained in Section 5.1, the number
of active neighbors is more important to malware propaga-
tion because it dictates the maximum number of neighbors
that a node can infect. Another interesting observation is
that sanitization by activities performs the worst among the
three schemes. This is not surprising because according to
Figure 7, nodes with a large number of activity events do
not necessarily have many neighbors, and the importance
of a node in spreading the malware highly depends on how
many active neighbors it has.
204
 0 50 100 150 200 250 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 5 10 15 20 25 30 0 50 100 150 200 250Number ofinfectionsRecovery probabilityRecoverydelayNumber ofinfections 0 500 1000 1500 2000 2500 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 5 10 15 20 25 30 0 500 1000 1500 2000 2500Number ofinfectionsRecovery probabilityRecoverydelayNumber ofinfections 0 1000 2000 3000 4000 5000 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 5 10 15 20 25 30 0 1000 2000 3000 4000 5000Number ofinfectionsRecovery probabilityRecoverydelayNumber ofinfections 0 2000 4000 6000 8000 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 5 10 15 20 25 30 0 2000 4000 6000 8000Number ofinfectionsRecovery probabilityRecoverydelayNumber ofinfections 0 50 100 150 200 250 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 5 10 15 20 25 30 0 50 100 150 200 250Number ofinfectionsRecovery probabilityRecoverydelayNumber ofinfections 0 500 1000 1500 2000 2500 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 5 10 15 20 25 30 0 500 1000 1500 2000 2500Number ofinfectionsRecovery probabilityRecoverydelayNumber ofinfections 0 1000 2000 3000 4000 5000 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 5 10 15 20 25 30 0 1000 2000 3000 4000 5000Number ofinfectionsRecovery probabilityRecoverydelayNumber ofinfections 0 1000 2000 3000 4000 5000 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 5 10 15 20 25 30 0 1000 2000 3000 4000 5000Number ofinfectionsRecovery probabilityRecoverydelayNumber ofinfections(1) Edges vs. active neighbors
(2) Edges vs. by activities
Figure 14: Number of infections under diﬀerent sanitization schemes
Figure 15:
Sizes of giant com-
ponents under preventive contain-
ment
From Figure 14, we also observe that in the range consid-
ered, the number of infections seems to decrease only linearly
with the number of nodes removed, regardless of the sani-
tization scheme. This is counterintuitive because one might
think that removing the top few connected nodes would slow
down malware propagation more signiﬁcantly than the other
nodes; if that were true, the curve would be sublinear. On
an encouraging note, selectively sanitizing the nodes with
the highest numbers of either edges or active neighbors can
slow down malware propagation signiﬁcantly. In [38, 27], it
has been observed that selective or targeted immunization
(which is similar to sanitization discussed here) is an eﬀec-
tive approach to stopping malware propagation in scale-free
networks. Our results conﬁrm that that conclusion holds
under realistic activity models for online social networks.
In the following discussion, we consider another defense
scheme called preventive containment. Its basic idea is that
we partition the network into a number of “islands” and san-
itize the messages that are delivered among these islands to
ensure that they are not malicious. Hence, malware start-
ing from a node inside an island is contained within that
island. For preventive containment to be eﬀective, we need
to ensure that the size of each island is small. To parti-
tion the BrightKite network, we use a hierarchical commu-
nity detection algorithm to produce a dendrogram, which
shows how nodes are clustered together to form communi-
ties. As nodes in the same community are supposed to be
highly clustered and nodes among diﬀerent communities are
only sparsely connected, our intuition is that removing those
inter-community edges would help break down the connec-
tivity of the whole graph.
We used the community structure detection algorithm by
greedy optimization of modularity in the igraph library [16],
whose implementation was based on the work in [5]. The
algorithm works in a bottom-up fashion: it starts with indi-
vidual nodes, forms small communities from them, and then
iteratively add edges between smaller communities to form
larger communities until the whole graph is generated. The
whole process produces a hierarchical dendrogram. Based
on this dendrogram, we remove edges in a top-down fashion
and in a reverse order until the whole graph becomes indi-
vidual nodes. We call an operation a procedure of removing
edges between two communities during this process.
After each operation, we measure the total number of
edges that have been removed and the size of the giant com-
ponent in the graph so far. We start from the giant compo-
nent of the BrightKite graph initially and the results are il-
lustrated in Figure 15 after each operation. Clearly, when we
keep removing edges from the graph, the size of the largest
component in the remaining graph decreases. The results,
however, cast a pessimistic note on the eﬀectiveness of pre-
ventive containment. For instance, in order to contain the
malware propagation within 52%, 26%, 20%, 15%, and 10%
of the nodes in the giant component of the BrightKite graph,
it is necessary for us to ensure the sanity of the messages on
12%, 20%, 23%, 53%, and 78% of the edges, respectively.
That is to say, to contain malware spreading within a small
number of nodes once it starts from even a single node, we
need to sanitize messages on a signiﬁcant number of edges.
8. SCOPE OF OUR WORK
In this work, we use trace-driven simulation to study mal-
ware propagation in online social networks. Our conclusions
can only be as accurate as their underlying assumptions. We
assume that each BrightKite user becomes active only after
she performs some activities visible to the system, such as
user checkin, location update, photo uploading, and note
posting. This may not be true because some users may re-
move their activity events on the same day before we had
a chance to download these events. Machines used by these
users may still get infected if they click on some malicious
URLs sent from their friends. Albeit such deleted events
are believed to be rare, the experiments in this work may
underestimate the malware propagation speed.
Another limitation is that we assume each account name
in the BrightKite dataset corresponds to a unique machine
owned by a BrightKite user. This may not be true because a
BrightKite user can have multiple accounts or use multiple
machines to access her account.
In the former case, our
simulation experiments would overestimate the number of
nodes in the social graph, while in the latter one, the number
of nodes in the experiments is underestimated.
Moreover, the user click probability in our experiments is
the same over all the users. This is not realistic given the
fact that diﬀerent online social network users typically have
diﬀerent awareness levels on malicious embedded URLs sent
from their friends. Also, the level of trust that an online
social network user gives to a message also depends on her
relationship with the sender. Hence, the response of an on-
line social network user to URLs embedded in the messages
is simpliﬁed in our simulation experiments.
Even with these limitations, our work still sheds light on
the characteristics of malware propagation in realistic online
social networks. The goal of this work is not to draw deﬁ-
nite conclusions on how fast a malware can propagate in a
real-world online social network. Given the high dynamics
of online social networks these days (e.g., increasing num-
ber of users), providing an exact answer to that question is
205
 0 2000 4000 6000 8000 10000 12000 14000 0 200 400 600 800 1000 1200 1400 1600 1800 2000Number of infectionsNumber of nodes removedAfter 1 week, by edgesAfter 1 week, by active neighborsAfter 1 month, by edgesAfter 1 month, by active neighborsAfter 6 months, by edgesAfter 6 months, by active neighbors 0 2000 4000 6000 8000 10000 12000 14000 0 200 400 600 800 1000 1200 1400 1600 1800 2000Number of infectionsNumber of nodes removedAfter 1 week, by edgesAfter 1 week, by activitiesAfter 1 month, by edgesAfter 1 month, by activitiesAfter 6 months, by edgesAfter 6 months, by activities 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 10000 20000 30000 40000 50000 60000 0 0.1 0.2 0.3 0.4 0.5 0.6Fraction of edges removedFraction of nodes in the giant componentReverse operation IDNumber of removed edgesSize of giant componentsurely beyond our scope. Instead, our aim is to investigate
the eﬀects of diﬀerent aspects of online social networks on
malware propagation, especially those due to user activities,
which were rarely studied in previous works.
9. CONCLUSIONS
Malware speciﬁcally targeting online social networks are
on the rise. In this work, we aim to study the characteris-
tics of malware propagation in online social networks. We
analyze a real-world location-based online social network, in-
cluding the social structure formed by its users and its user
activity patterns. We further use trace-driven simulation
to study the impact of initial infection, user click probabil-
ity, social structures, and user activity patterns on malware
propagation in online social networks, and oﬀer insights on
how to defend against malware attacks in such networks.
10. REFERENCES
[1] F. Benevenuto, T. Rodrigues, M. Cha, and
V. Almeida. Characterizing user behavior in online
social networks. Chicago, Illinois, USA, 2009.
[2] L. Briesemeister, P. Lincoln, and P. Porras. Epidemic
proﬁles and defense of scale-free networks. In
Proceedings of the 2003 ACM workshop on Rapid
malcode, Washington, DC, USA, 2003.
[3] http://www.brightkite.com/.
[4] http://www.caida.org.
[5] A. Clauset, M. E. J. Newman, and C. Moore. Finding
community structure in very large networks. Physical
Review E, 70(6), 2004.
[6] A. Clauset, C. R. Shalizi, and M. E. J. Newman.
Power-law distributions in empirical data.
arXiv:0706.1062, June 2007.
[7] http://www.theregister.co.uk/2010/06/01/
facebook_clickjacking_worm/.
[8] http://www.cert.org/advisories/CA-2001-19.html.
[9] Z. Dezs˝o and A. Barab´asi. Halting viruses in scale-free
networks. Physical Review E, 65(5):055103, May 2002.
[10] http:
//www.facebook.com/press/info.php?statistics.
[11] http:
//www.computerworld.com/s/article/9128842/
Koobface_worm_to_users_Be_my_Facebook_friend.
[12] M. R. Faghani and H. Saidi. Malware propagation in
online social networks. In Proceedings of the 4th IEEE
International Conference on Malicious and Unwanted
Software, Montreal, Canada, October 2009.
[13] http://www.gnip.org/.
[14] C. Griﬃn and R. Brooks. A note on the spread of
worms in scale-free networks. IEEE Transactions on
Systems, Man, and Cybernetics, Part B: Cybernetics,
36(1):198–202, Feb. 2006.
[15] L. Guo, E. Tan, S. Chen, X. Zhang, and Y. Zhao.
Analyzing patterns of user content generation in
online social networks. In Proceedings of the 15th
ACM SIGKDD international conference on Knowledge
discovery and data mining, Paris, France, 2009.
[16] http://igraph.sourceforge.net/.
[17] http://www.kaspersky.com/news?id=207575670.
[18] N. Li and G. Chen. Analysis of a location-based social
network. In Proceedings of the International
Symposium on Social Intelligence and Networking,
2009.
[19] http://www.pandasecurity.com/NR/rdonlyres/
BBB11FA2-10BD-435A-B936-5CD55C45E427/0/
Malwaretargetssocialnetworks.pdf.
[20] M. Mannan and P. C. van Oorschot. On instant
messaging worms, analysis and countermeasures. In
Proceedings of the 2005 ACM workshop on Rapid
malcode, Fairfax, VA, USA, 2005.
[21] http://www.bnonews.com/news/242.html.
[22] A. Mislove, M. Marcon, K. P. Gummadi, P. Druschel,
and B. Bhattacharjee. Measurement and analysis of
online social networks. In Proceedings of the 7th ACM
SIGCOMM conference on Internet measurement, 2007.
[23] C. Moore and M. E. J. Newman. Epidemics and
percolation in small-world networks. Physical Review
E, 61(5):5678–5682, May 2000.
[24] M. E. J. Newman, Stephanie Forrest, and Justin
Balthrop. Email networks and the spread of computer
viruses. Physical Review E, 66(3), 2002.
[25] http://en-us.nielsen.com/main/news/news_
releases/2009/september/nielsen_reports_17.
[26] http://www.statemaster.com/encyclopedia/Orkut.
[27] R. Pastor-Satorras and A. Vespignani. Immunization
of complex networks. Physical Review E, 65, 2002.
[28] R. P. Satorras and A. Vespignani. Epidemic spreading
in scale-free networks. Physical Review Letters,
86(14):3200–3203, Apr 2001.
[29] http://www.cert.org/advisories/CA-2003-04.html.
[30] http:
//news.cnet.com/8301-13577_3-10160850-36.html.
[31] Telo and A. Nunes. Epidemics in small world
networks. The European Physical Journal B -
Condensed Matter and Complex Systems,
50(1):205–208, March 2006.
[32] http:
//www.pcworld.com/article/162992/twitter_worm_
attack_continues_heres_how_to_keep_safe.html.
[33] D. J. Watts. Six Degrees: The Science of a Connected
Age. W. W. Norton & Company, 2003.
[34] D. J. Watts and S. Strogatz. Collective dynamics of
’small-world’ networks. Nature, 393:440–442, 1998.
[35] C. Wilson, B. Boe, A. Sala, K. P.N. Puttaswamy, and
B. Y. Zhao. User interactions in social networks and
their implications. In Proceedings of the 4th ACM
European conference on Computer systems,
Nuremberg, Germany, 2009.
[36] W. Xu, F. Zhang, and S. Zhu. Toward worm detection
in online social networks. In Proceedings of the 25th
Annual Computer Security Applications Conference
(ACSAC), 2010.
[37] G. Yan, Z. Xiao, and S. Eidenbenz. Catching instant
messaging worms with change-point detection
techniques. In Proceedings of the 1st Usenix Workshop
on Large-Scale Exploits and Emergent Threats, San
Francisco, California, 2008.
[38] C. C. Zou, D. F. Towsley, and W. Gong. Email worms
modeling and defense. In Proceedings of the
International Conference on Computer
Communications and Networks, 2004.
206