Since machine clears are hardly documented, we examined
all the performance counters for every Intel architecture and
found a number relevant counters (Table 1). Some counters
are present only in speciﬁc architectures. For example, the
page fault counter is available only on Goldmont Plus. How-
ever, thanks to the generic counter MACHINE_CLEARS.COUNT
it is always possible to count the overall number of machine
clears, regardless of the architecture. In the remainder of this
work, we will reverse engineer and analyze the causes of
machine clears by means of these six counters.
As a general observation, we note that the Floating Point
Assist and Page Fault counters immediately suggest that ma-
chine clears are also related to microcode assists and fault-
s/exceptions. In particular, further analysis shows that:
• Microcode assists trigger machine clears. The hardware
occasionally needs to resort to microcode to handle com-
plex events. Doing so requires ﬂushing all the pend-
ing instructions with a machine clear before handling
a microcode assist. Indeed, in our experiments, where
the OTHER_ASSISTS.ANY counter increased, we also ob-
served a matching increase in MACHINE_CLEARS.COUNT.
• Machine clears do not necessarily trigger microcode
assists. Not all machine clears are microcode as-
sisted, as some machine clear causes are handled
directly in silicon. Indeed, in our experiments, we
observed that SMC, MD, and MO machine clears
cause an increase of MACHINE_CLEARS.COUNT, but leave
OTHER_ASSISTS.ANY unaltered.
• An exception triggers a machine clear. When a fault
or exception is detected, the subsequent µOps must be
ﬂushed from the pipeline with a machine clear, as the
execution should resume at the exception handler. In-
deed, in our experiments, we observed an increase of
MACHINE_CLEARS.COUNT at each faulty instruction.
In this paper, we focus on the machine clear causes men-
tioned by the Intel documentation (Table 1), acknowledging
that undocumented causes may still exist (much like undocu-
mented x86 instructions [16]). We now ﬁrst examine the four
most relevant causes of machine clears (Self-Modifying Code
MC, Floating Point MC, Memory Ordering MC, and Memory
Disambiguation MC), then brieﬂy discuss the other cases.
5 Self-Modifying Code Machine Clear
In a Von Neumann architecture, stores may write instructions
as data and modify program code as it is being executed,
as long as the code pages are writable. This is commonly
referred to as Self-modifying Code (SMC).
Self-modifying code is problematic for the Instruction
Fetch Unit (IFU), which maintains high execution through-
put by aggressively prefetching the instructions it expects to
execute next and feeding them to the decode units. The CPU
speculatively fetches and decodes the instructions and feeds
them to the execution units, well ahead of retirement.
In case of a misprediction, the CPU ﬂushes the specula-
tively processed instructions and resumes execution at the cor-
rect target. The IFU’s aggressive prefetching ensures that the
ﬁrst-level instruction cache (L1i) is constantly ﬁlled with in-
structions which are either currently in (possibly speculative)
execution or about to be executed. As a result, a store instruc-
tion targeting code cached in L1i requires drastic measures—
as the associated cache lines should now be invalidated. More-
over, the target instructions do not even need to be part of the
actual execution: since a prefetch is sufﬁcient to bring them
into L1i, any write to prefetched instructions also invalidates
the prefetch queue. In other words, the problem occurs when
the code is already in L1i or the store is sufﬁciently close to
the target code to ensure the target is prefetched in L1i. This
behavior leads to a temporary desynchronization between the
code and data views of the CPU, transiently breaking the ar-
chitectural memory model (where L1d/L1i coherence ensures
consistent code/data views).
To reverse engineer this behavior, we use the analysis code
exempliﬁed by Listing 1. The store at line 15 overwrites code
already cached in L1i (lines 18-21), triggering a machine
clear. The machine clear needs to update the L1i cache (and
1454    30th USENIX Security Symposium
USENIX Association
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
related microarchitectural structures) by ﬂushing any stale
instruction(s), resuming execution at the last retired instruc-
tion, and then fetching the new instructions. To test for the
presence of a transient execution path, our analysis code im-
mediately executes lines 18-21 targeted by the store and jumps
to a spec_code gadget (lines 29-32) which ﬁlls a number of
cache lines in a (ﬂushed) buffer. Architecturally, this gad-
get should never be executed, as the store instruction should
nop out the branch at line 18. However, microarchitecturally,
we do observe multiple cache hits in the (reload) buffer us-
ing FLUSH + RELOAD, which conﬁrms the existence of a
pre-SMC-handling transient execution path executing stale
code and leaving observable traces in the cache. We observe
that the scheduling of the store instruction heavily affects
the length of the transient path. Indeed, we use different in-
structions (lines 5-8) to delay as much as possible the store
retirement, and thus the SMC detection. This suggests that the
root cause of the observed transient window might be the mi-
croarchitectural de-synchronization between the store buffer
(new code) and the instruction queue (stale code), yielding
transiently incoherent code/data views. We sampled machine
clear performance counters to conﬁrm the transient execution
window is caused by the SMC machine clear and not by other
events (e.g., memory disambiguation misprediction). Finally,
we repeated our experiments on uncached code memory and
could not observe any transient path. The counters revealed
one machine clear triggered for each executed instruction,
since the CPU has to pessimistically assume every fetched
instruction has potentially been overwritten. Additionally, we
have veriﬁed that SMC detection is performed on physical
addresses rather than virtual ones.
Cross-Modifying Code
Instead of modifying its own instructions, a thread running
on one core may also write data into the currently executing
code segment of a thread running on a different physical core.
Such Cross-Modifying Code (XMC) may be synchronous
(the executor thread waits for the writer thread to complete
before executing the new code) or asynchronous, with no
particular coordination between threads. To reverse engineer
the behavior, we distributed our analysis code across cores
and reproduced a signal on the reload buffer in both cases.
This conﬁrms a Cross-Modifying Code Machine Clear (XMC
machine clear) behaves similarly to a SMC machine clear
across cores, with a store on the writer core originating a
transient execution window on the executor core.
6 Floating Point Machine Clear
On Intel, when the Floating Point Unit (FPU) is unable to
produce results in the IEEE-754 [1] format directly, for in-
stance in the case of denormal operands or results [4, 17],
the CPU requires special handling to produce a correct re-
Listing 1 Self-Modifying Code Machine Clear analysis code
smc_snippet:
push r11
lea r11, [target] ; Load addr of target instr (line 17)
clflush [r11]
%rep 10
imul
%endrep
; These instructions serve as a delay
; for the store argument address. They
r11, 1 ; ensure that the execution window of
; spec_code is as long as possible.
;Code to write as data: 8 nops (overwriting lines 18-21)
mov
rax, 0x9090909090909090
;Store at target addr. Also: the last retired instr
;from which the execution will resume after the SMC MC
QWORD [r11], rax
mov
target:
;Target instruction to be modified
jmp spec_code
nop
nop
nop
;Architectural exit point of the function
pop r11
ret
;Code executed speculatively (flushed after SMC MC).
spec_code:
mov rax, [rdi+0x0]
mov rax, [rdi+0x400]
mov rax, [rdi+0x800]
mov rax, [rdi+0xc00]
; rdi: covert channel reload buffer
sult. According to an Intel patent [62], the denormalization
is indeed implemented as a microcode assist or an exception
handler since the corresponding hardware would be too com-
plex. In our experiments, we observed microcode assists on
all x87, SSE, and AVX instructions that perform mathematical
operations on denormal ﬂoating-point (FP) numbers. Incre-
ments of the FP_ASSIST.ANY, or MACHINE_CLEARS.COUNT
(or on older processors, MACHINE_CLEARS.FP_ASSIST) per-
formance counters conﬁrm such assists cause machine clears.
Since a machine clear implies a pipeline ﬂush, the as-
sisted FP operation will be squashed together with subse-
quent µOps. To reverse engineer the behavior, we used anal-
ysis code exempliﬁed by Algorithm 1. Our code relies on
a FLUSH + RELOAD [81] covert channel to observe the re-
sult of a ﬂoating-point operation at the byte granularity. In
our experiments, we observed two different hits in the reload
buffer for each byte, for the transient and architectural result,
respectively. The double-hit microarchitectural trace conﬁrms
that the transient (and wrong) value generated by the FPU
is used in subsequent µOps—as also exempliﬁed in Table 2.
Later, the CPU detects the error and triggers a machine clear
to ﬂush the wrongly executed path. The microcode assist then
corrects the result, while subsequent instructions are reissued.
While we could not ﬁnd any documentation on ﬂoating-
point assist handling (even in the patents), our experiments
revealed the following important properties. First, we veri-
ﬁed that many FP operations can trigger FP assists (i.e., add,
sub, mul, div and sqrt) across different extensions (i.e., x87,
SSE, and AVX). Second, the transient result is computed by
“blindly” executing the operation as if both operands and result
USENIX Association
30th USENIX Security Symposium    1455
Algorithm 1 Floating Point Machine Clear analysis (pseudo)
code. byte is used to extract the i-th byte of z
1: for i ← 1, 8 do
2:
3:
4:
5:
6: end for
ﬂush(reload_bu f )
z = x / y
reload_bu f [byte(z, i) * 1024]
reload(reload_bu f )
(cid:46) Any denormal FP operation
Representation
0x0010deadbeef1337
0x40f0000000000000
0x00000010deadbeef
0x3f10deadbeef1337
x
y
zarch
ztran
Value
2.34e-308
65536(cid:0)216(cid:1) N
3.57e-313
6.43e-05
D
N
Type Exp.
-1022
N
16
-1022
-14
Table 2: Architectural (zarch) and transient (ztran) results of
dividing x and y of Algorithm 1. N: Normal, D: Denormal
representations. The mantissa is in bold. A normal division by
216 leaves the mantissa untouched and subtracts 16 from the
exponent—the result of ztran where the exponent overﬂowed
from -1022 to -14
Figure 3: Transient execution due to invalid memory ordering
are normal numbers (see Table 2). Third, the detection of the
wrong computation occurs later in time, creating a transient
execution window. Finally, by performing multiple ﬂoating-
point operations together with the assisted one, we were able
to expand the size of the window, suggesting that detection is
delayed if the FPU is busy handling multiple operations.
7 Memory Ordering Machine Clear
The CPU initiates a memory ordering (MO) machine clear
when, upon receiving a snoop request, it is uncertain if mem-
ory ordering will be preserved [36]. Consider the program
Algorithm 2 Pseudo-code triggering a MO machine clear
Processor A
1: clﬂush(X)
2: unlock(lock)
3: r1 ← [X]
4: r2 ← [Y ]
5: reload(r2)
Processor B
1: wait(lock)
2: 1 → [Y ]
(cid:46) Make the load slow
(cid:46) Synchronize loads and stores
(cid:46) Synchronize loads and stores
(cid:46) For FLUSH + RELOAD
in Figure 3. Processor A loads X and Y, while processor B
performs two stores to the same locations. If the load of X
is slow due to a cache miss, the out-of-order CPU will issue
the next load (and subsequent operations) ahead of sched-
ule. Suppose that while the load of X is pending, proces-
sor B signals, through a snoop request, that the values of
X and Y have changed. In this scenario, the memory order-
ing is A1-B0-B1-A0, which is not allowed according to the
Total-Store-Order memory model. As two loads cannot be
reordered, r1=1 r2=0 is an illegal result. Thus, processor A
has no choice other than to ﬂush its pipeline and re-issue
the load of Y in the correct order. This MO machine clear
is needed for every inconsistent speculation on the memory
ordering—implementing speculation behavior originally pro-
posed by Gharachorloo et al. [27], with the advantage that
strict memory order principles can co-exist with aggressive
out-of-order scheduling.
Notice that, in the previous example, the store on X is
not even necessary to cause a memory ordering violation
since A1-B1-A0 is still an invalid order. Counterintuitively,
the memory ordering violation disappears if the load on X is
not performed, as A1-B0-B1 is a perfectly valid order.
To reverse engineer the memory ordering handling behav-
ior on Intel CPUs, we used analysis code exempliﬁed by Al-
gorithm 2. Our code mimics the scenario of Figure 3 with