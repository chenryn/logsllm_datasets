Section 5.2, we further validate the effectiveness and significance of
our proposed feature selection method SecCLS in building a more
secure classifier. We compare SecureDroid which applies SecCLS to
select features for each base classifier with ensemble of random
feature selection (denoted as ERFS) that uses random feature selec-
tion method to construct base classifiers [5, 19], in the settings of
under attacks and without attacks. As illustrated in Section 5.1.3,
since well-crafted (WC) attack is the most effective attack strategy
among those three, we evaluate the SecureDroid and ERFS under
such kind of attacks. The experimental results are shown in Table 3.
From Table 3, we can observe that, (1) Under attacks: ERFS can
somehow be resilient against the attack (with TPR of 85.63%) when
the evasion cost is small (δmax = 4.8, modifying 10 features). How-
ever, with the increasing evasion costs, the detection performance
of ERFS drops drastically (e.g., its TPR drops to 16.47% when the
evasion cost δmax is 25.2 corresponding to manipulating 50 fea-
tures). In contrast, SecureDroid using SecCLS for feature selection
can significantly enhance security, as its performance decreases
more elegantly against increasing evasion costs and its TPRs are
actually never lower than 80.00% with different evasion costs. The
reason behind this is that SecCLS integrated in SecureDroid reduces
Table 3: Comparison of SecureDroid with SecCLS and ERFS
with random feature selection against well-crafted attacks
(UnderAtt) and without attacks (NonAtt).
NonAtt UnderAtt [δmax (features modified)]
4.8(10) 9.0(20) 13.5(30) 19.2(40) 25.2(50)
TPR 0.9072 0.8563 0.5045 0.4326 0.2934 0.1647
ACC 0.9230 0.9354 0.7888 0.7559 0.6981 0.6509
F1
0.9072 0.9167 0.6647 0.5953 0.4465 0.2813
TPR 0.9566 0.9177 0.8323 0.8563 0.8308 0.8069
ACC 0.9634 0.9168 0.8665 0.8621 0.8019 0.8106
F1
0.9559 0.9015 0.8380 0.8375 0.7768 0.7795
ERFS
SecureDroid
the possibility of selecting those features attackers tend to manipu-
late, i.e., to achieve same attack utility, SecCLS will force attackers
to modify larger number of features compared with random feature
selection method. (2) Without attacks: SecureDroid also performs
better than ERFS in the absence of attacks (i.e., about 4-5% higher
detection accuracy). This is because, compared with ERFS which
randomly assigns equal probability for each feature being selected,
SecureDroid applying SecCLS method is capable to retain majority
of the features for each individual classifier and thus assure its
detection accuracy in the absence of attacks.
5.4 Comparisons of SecureDroid with Other
Alternative Defense Methods
In this set of experiments, we further examine the effectiveness
of SecureDroid against the adversarial attacks (i.e., well-crafted at-
tack as it shows most effective) by comparisons with other popular
defense methods, including (1) feature evenness (denoted as De-
fense1) which enables the Original-Classifier to learn more evenly-
distributed feature weights using the method proposed in [23]; (2)
classifier retraining (denoted as Defense2) which follows Stack-
elberg game theories [7, 8, 17, 34] and models the attack as a vector
θ to modify the training data set X where the Original-Classifier
is retrained [34, 38]; (3) classifier built on reduced feature set
(denoted as Defense3) which carefully selects a subset of features
based on the generalization capability of the Original-Classifier
and its security against data manipulation applying the method
proposed in [46]. The experimental results are reported in Figure 5.
(a) TPRs under attacks
(b) F1 measures under attacks
Figure 5: Comparisons of different defense methods.
From Figure 5, we can see that SecureDroid significantly out-
performs the other defense models (i.e., Defense1–3) against the
370well-crafted attacks. Although Defense2 (i.e., classifier retraining)
performs slightly better than SecureDroid when the evasion costs
δmax ∈ {4.8, 9.0} (i.e., modifying 10 and 20 features), the difference
is not statistically significant. In fact, the retrained model modi-
fies the training data distribution approximate to the testing space
through the attack model θ. After modifying a large number of
features in the malicious apps, the model tends to produce a distri-
bution that is very close to that of the benign apps. In this case, the
retrained model may not be able to differentiate benign and mali-
cious apps accurately. From Figure 5, we also observe that as the
evasion cost δmax increases, the performance of the retrained model
suffers a great drop-off. For Defense1 and Defense3, their perfor-
mances (TPRs and F1 measures in Figure 5) sharply degrade when
evasion cost increases. For Defense1, the weight evenness merely
exploits the information of the classifier’s feature weights while
ignoring manipulation costs of different features; for Defense3, the
model is built on a carefully selected feature subset, whose robust-
ness could be compromised when attackers manipulate a certain
number of these features.
5.5 Scalability Evaluation of SecureDroid
In this section, based on the second sample set with larger size
described in Section 5.1 which consists of 72, 891 apps (32, 443
malicious and 40, 448 benign), we systematically evaluate the per-
formance of our developed system SecureDroid, including scalability
and detection effectiveness. We first evaluate the training time of
SecureDroid with different sizes of the training sample sets. Figure 6
presents the scalability of our developed system. We can observe
that as the size of the training data set increases, the running time
for our detection system is quadratic to the number of training
samples. When dealing with more data, approximation or parallel
algorithms could be developed. Figure 7 shows the detection stabil-
ity of SecureDroid against the adversarial attacks (i.e., well-crafted
attacks) and in the absence of attacks, with different sizes of sample
sets. From the results, we can conclude that our developed system
SecureDroid can enhance security of machine learning based detec-
tion, and is feasible in practical use for Android malware detection
against adversarial attacks.
Figure 6: Scalability evalu-
ation of SecureDroid.
Figure 7: Stability evalua-
tion of SecureDroid.
6 RELATED WORK
In recent years, there are ample researches that show machine
learning-based systems can actively adjust their behaviors to com-
bat the adversarial attacks in some cybersecurity domains. In these
systems, the detection methods can be generally divided into four
categories: Stackelberg game theories [7, 8, 17, 34], feature op-
erations [14, 24, 46], retraining frameworks [15, 25, 38], and en-
semble classifier systems [5, 11, 23]. To apply Stackelberg game
theories, Bruckner et al. [7] first presented the interaction between
the learner and the adversary as a static game, and explored the
adversarial properties to find the equilibrate prediction model; they
then further simulated the interaction as a Stackelberg competition,
and derived an optimization problem to determine the solution of
this game [8]. Wang et al. [34] modeled the adversary action as it
controlling a vector α to modify the training data set X, and trans-
formed the classifier into a convex optimization problem. More
recently, feature operation methods have also been proposed to
counter some kinds of adversarial data manipulations, such as fea-
ture deletion [14], feature clustering [24], feature reduction [46],
etc. In addition, retraining frameworks are becoming more and
more widely applied to boost the resilience of learning algorithms
through: (1) adding adversarial samples to the training data that
evade the previously computed classifier [15, 25], and (2) manipu-
lating the training data distribution that its distribution is matched
to the test data [38]. Though these theories and approaches are
promising, most of them make strong assumptions about the struc-
ture of the data (e.g., adversarial samples) or the attack model that
are likely impractical for Android malware detection problems. To
improve the security of machine learning under generic settings,
some research efforts have been devoted to multiple classifier sys-
tems. Kolcz et al. [23] applied averaging method resting on random
subsets of reweighted features to produce a linear ensemble classi-
fier. Biggio et al. [5] built a multiple-classifier system to improve
the robustness of the classifier through bagging, and the random
subspace method. Debarr et al. [11] explored randomization to gen-
eralize learning model by randomly choosing dataset or features,
and estimated parameters that fit the data best. In these ensemble
learning systems, randomization is the main method for feature
selection.
Different from the existing works, in this paper, we present a
novel feature selection method for constructing more secure clas-
sifier by taking advantage of Android malware detection domain-
related knowledge, and then an ensemble learning approach is
further introduced to combine the classifiers built using the pro-
posed feature selection method to retain the detection accuracy.
The proposed method is independent from the skills and capabili-
ties of the attackers and can be readily applied in other malware
detection tasks.
7 CONCLUSION
In this paper, we explore the security of machine learning in An-
droid malware detection to understand how feature selection im-
pacts on the security of a learning-based classifier. Our study con-
siders different importances of the features associated with their
contributions to the classification problem and manipulation costs
to the adversarial attacks. We propose a novel feature selection
method SecCLS which reduces the possibility to select those fea-
tures attackers tend to manipulate and thus helps to construct more
secure classifier. To improve the system security while not com-
promising the detection accuracy, we further propose an ensemble
371learning approach SecENS by aggregating the individual classifiers
that are constructed using the proposed SecCLS. Accordingly, we
develop a system called SecureDroid which integrates both SecCLS
and SecENS to enhance security of machine learning-based Android
malware detection. Comprehensive experiments on the real sam-
ple collections from Comodo Cloud Security Center are conducted
to validate the effectiveness of SecureDroid. The results demon-
strate that our feature selection method SecCLS is more resilient
to disrupt the feature manipulations, and SecureDroid can improve
the security against the adversarial attacks even that attackers are
with different skills and capabilities or have different knowledge
about the targeted learning system. Our proposed secure-learning
paradigm can also be readily applied to other malware detection
tasks.
ACKNOWLEDGMENTS
The authors would also like to thank the anti-malware experts
of Comodo Security Lab for the data collection, as well as the
helpful discussions and supports. This work is supported by the
U.S. National Science Foundation under grant CNS-1618629 and
WVU Senate Grants for Research and Scholarship (R-16-043).
REFERENCES
[1] Mohammed S. Alam and Son T. Vuong. 2013. Random Forest Classification for
[4] Marco Barreno, Blaine Nelson, Russell Sears, Anthony D. Joseph, and J. D. Tygar.
[2] Android. 2017. Application Fundamentals. In https://developer.android.com/
[3] Marco Barreno, Blaine Nelson, Anthony D. Joseph, and J. D. Tygar. 2010. The
Detecting Android Malware. In GreenCom-iThings-CPSCom. 663–669.
guide/components/fundamentals.html.
security of machine learning. Machine Learning 81, 2 (2010), 121–148.
2006. Can machine learning be secure?. In ASIACCS ’06. 16–25.
[5] Battista Biggio, Giorgio Fumera, and Fabio Roli. 2010. Multiple Classifier Systems
for Robust Classifier Design in Adversarial Environments. International Journal
of Machine Learning and Cybernetics 1, 1 (2010), 27–41.
[6] Battista Biggio, Giorgio Fumera, and Fabio Roli. 2014. Security evaluation of
pattern classifiers under attack. IEEE Transactions on Knowledge and Data Engi-
neering 26, 4 (2014), 984–996.
[7] Michael Bruckner, Christian Kanzow, and Tobias Scheffer. 2012. Static prediction
games for adversarial learning problems. Journal of Machine Learning Research
13, 1 (2012), 2617–2654.
[8] Michael Bruckner and Tobias Scheffer. 2011. Stackelberg games for adversarial
prediction problems. In KDD ’11. 547–555.
[9] Lingwei Chen, William Hardy, Yanfang Ye, and Tao Li. 2015. Analyzing File-to-
File Relation Network in Malware Detection. In WISE ’15 International Conference
on Web Information Systems Engineering. 415–430.
[10] Lingwei Chen and Yanfang Ye. 2017. SecMD: Make Machine Learning More Secure
Against Adversarial Malware Attacks. In AI ’17 Australasian Joint Conference on
Artificial Intelligence. 76–89.
[11] Dave Debarr, Hao Sun, and Harry Wechsler. 2013. Adversarial Spam Detection
Using the Randomized Hough Transform-Support Vector Machine. In ICMLA
’13. 299–304.
[12] Thomas G. Dietterich. 2000. Ensemble methods in machine learning. Multiple
Classifier Systems 1 (2000), 1–15.
[13] Adrienne Porter Felt, Matthew Finifter, Erika Chin, Steve Hanna, and David
Wagner. 2011. A survey of mobile malware in the wild. In SPSM ’11. 3–14.
by Feature Deletion. In ICML ’06. 353–360.
Harnessing Adversarial Examples. In ICLR ’15.
[16] Haixiang Guo, Yijing Li, Yanan Li, Xiao Liu, and Jinling Li. 2016. BPSO-Adaboost-
KNN ensemble learning algorithm for multi-class imbalanced data classification.
Engineering Applications of Artificial Intelligence 49 (2016), 176–193.
[17] Nika Haghtalab, Fei Fang, Thanh H. Nguyen, Arunesh Sinha, Ariel D. Procaccia,
and Milind Tambe. 2016. Three Strategies to Success: Learning Adversary Models
in Security Games. In IJCAI’16. 308–314.
Techniques 3rd Edition. Morgan Kaufmann, Waltham, MA, USA.
Forests.
[18] Jiawei Han, Micheline Kamber, and Jian Pei. 2011. Data Mining: Concepts and
[19] Tin Kam Ho. 1998. The Random Subspace Method for Constructing Decision
IEEE Transactions on Pattern Analysis and Machine Intelligence 20, 8
[15] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining and
[14] Amir Globerson and Sam Roweis. 2006. Nightmare at Test Time: Robust Learning
(1998), 832–844.
[23] Aleksander Kolcz and Choon Hui Teo. 2009. Feature Weighting for Improved
[24] Bo Li and Yevgeniy Vorobeychik. 2014. Feature cross-substitution in adversarial
[20] Shifu Hou, Aaron Saas, Lifei Chen, and Yanfang Ye. 2016. Deep4MalDroid: A Deep
Learning Framework for Android Malware Detection Based on Linux Kernel
System Call Graphs. In WIW ’16.
[21] Shifu Hou, Aaron Saas, Yanfang Ye, and Lifei Chen. 2016. DroidDelver: An
Android Malware Detection System Using Deep Belief Network Based on API
Call Blocks. In WAIM ’16. 54–66.
[22] Shifu Hou, Yanfang Ye, Yangqiu Song, and Melih Abdulhayoglu. 2017. Hin-
Droid: An Intelligent Android Malware Detection System Based on Structured
Heterogeneous Information Network. In KDD ’17. 1507–1515.
Classifier Robustness. In CEAS ’09 Sixth conference on email and anti-spam.
classification. In NIPS’14. 2087–2095.
[25] Bo Li, Yevgeniy Vorobeychik, and Xinyun Chen. 2016. A General Retraining
Framework for Scalable Adversarial Classification. In NIPS 2016 Workshop on
Adversarial Training.
[26] Daniel Lowd and Christopher Meek. 2005. Adversarial Learning. In KDD ’05.
641–647.
[27] Nicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, and Ananthram Swami.
2016. Distillation as a Defense to Adversarial Perturbations against Deep Neural
Networks. In IEEE Symposium on Security and Privacy (SP). 582–597.
[28] Hanchuan Peng, Fuhui Long, and C. Ding. 2005. Feature selection based on mutual
information: Criteria of max-dependency, max-relevance, and min-redundancy.
IEEE TPAMI 27, 8 (2005), 1226–1238.
https://www.cnet.com/news/android-ios-combine-for-91-percent-of-market/.
under attack. In CIARP ’13. 1–8.
2017–2021. In http://www.idc.com/getdoc.jsp?containerId=US42366217.
.spreitzenbarth.de/android-malware/.
Classifier: A Case Study. In SP ’14. 197–211.
Adversarial Learning. In ICDM ’14. 1013–1018.
[32] Michael Spreitzenbarth. 2016. Current Android Malware. In https://forensics
[33] Nedim Šrndic and Pavel Laskov. 2014. Practical Evasion of a Learning-Based
[31] Anthony Scarsella and William Stofega. 2017. Worldwide Smartphone Forecast,
[34] Fei Wang, Wei Liu, and Sanjay Chawla. 2014. On Sparse Feature Attacks in
[30] Fabio Roli, Battista Biggio, and Giorgio Fumera. 2013. Pattern recognition systems
[29] Don Reisinger. 2013. Android, iOS combine for 91 percent of market. In
[35] Paul Wood. 2015. Internet Security Threat Report 2015. In Symantec, California.
[36] Dong-Jie Wu, Ching-Hao Mao, Te-En Wei, Hahn-Ming Lee, and Kuo-Ping Wu.
2012. DroidMat: Android Malware Detection through Manifest and API Calls
Tracing. In ASIAJCIS ’12 Proceedings of the 2012 Seventh Asia Joint Conference on
Information Security.
[37] Wen-Chieh Wu and Shih-Hao Hung. 2014. DroidDolphin: a dynamic Android
malware detection framework using big data and machine learning. In RACS
’14 Proceedings of the 2014 Conference on Research in Adaptive and Convergent
Systems.
[38] Yifan Wu, Tianshu Ren, and Lidan Mu. 2016. Importance Reweighting Using
Adversarial-Collaborative Training. In NIPS 2016 Workshop.
[39] Jianlin Xu, Yifan Yu, Zhen Chen, Bin Cao, Wenyu Dong, Yu Guo, and Junwei
Cao. 2013. MobSafe: cloud computing based forensic analysis for massive mobile
applications using data mining. Tsinghua Sci. Technol. 18, 4 (2013), 418–427.
[40] Chao Yang, Zhaoyan Xu, Guofei Gu, Vinod Yegneswaran, and Phillip Porras. 2014.
DroidMiner: Automated Mining and Characterization of Fine-grained Malicious
Behaviors in Android Applications. ESORICS European Symposium on Research
in Computer Security 8712 (2014), 163–182.
[41] Yanfang Ye, Lifei Chen, Dingding Wang, Tao Li, Qingshan Jiang, and Min Zhao.
2009. SBMDS: an interpretable string based malware detection system using
SVM ensemble with bagging. Journal in Computer Virology 5 (2009), 283–293.
[42] Yanfang Ye, Tao Li, Donald Adjeroh, and S Sitharama Iyengar. 2017. A Survey
on Malware Detection Using Data Mining Techniques. ACM Computing Surveys
(CSUR) 50, 3 (2017), 41.
[43] Yanfang Ye, Tao Li, Qingshan Jiang, Zhixue Han, and Li Wan. 2009. Intelligent File
Scoring System for Malware Detection from the Gray List. In KDD ’09. 1385–1394.
[44] Yanfang Ye, Tao Li, Shenghuo Zhu, Weiwei Zhuang, Egemen Tas, Umesh Gupta,
and Melih Abdulhayoglu. 2011. Combining File Content and File Relations for
Cloud Based Malware Detection. In KDD ’11 Proceedings of the 17th ACM SIGKDD
international conference on Knowledge discovery and data mining. 222–230.
[45] Zhenlong Yuan, Yongqiang Lu, Zhaoguo Wang, and Yibo Xue. 2014. Droid-Sec:
deep learning in android malware detection. In SIGCOMM ’14 Proceedings of the
2014 ACM conference on SIGCOMM. 371–372.
[46] Fei Zhang, Patrick P. K. Chan, Battista Biggio, Daniel S. Yeung, and Fabio Roli.
2015. Adversarial Feature Selection Against Evasion Attacks. IEEE Transactions
on Cybernetics 46, 3 (2015), 766–777.
[47] Min Zhao, Fangbin Ge, Tao Zhang, and Zhijian Yuan. 2011. AntiMalDroid: An
Efficient SVM-Based Malware Detection Framework for Android. In ICICA ’11
International Conference on Information Computing and Applications. 158–166.
372