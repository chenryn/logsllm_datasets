(CSUR), 23(1):5–48, 1991.
[16] I. Goodfellow, J. Shlens, and C. Szegedy. Explaining
In International
and harnessing adversarial examples.
Conference on Learning Representations (ICLR), 2015.
[17] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual
learning for image recognition. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR), pages 770–778, 2016.
[18] T. A. Henzinger, R. Jhala, R. Majumdar, and G. Sutre.
Lazy abstraction. ACM SIGPLAN Notices, 37(1):58–70,
2002.
[19] G. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-r. Mohamed,
N. Jaitly, A. Senior, V. Vanhoucke, P. Nguyen, T. N.
Sainath, et al. Deep neural networks for acoustic modeling
in speech recognition: The shared views of four research
groups. IEEE Signal Processing Magazine, 29(6):82–97,
2012.
[20] G. Huang, Z. Liu, K. Q. Weinberger, and L. van der
Maaten. Densely connected convolutional networks. In
Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), volume 1, page 3, 2017.
[21] X. Huang, M. Kwiatkowska, S. Wang, and M. Wu. Safety
veriﬁcation of deep neural networks.
In International
Conference on Computer Aided Veriﬁcation (CAV), pages
3–29. Springer, 2017.
[22] D. Ishii, K. Yoshizoe, and T. Suzumura. Scalable parallel
numerical constraint solver using global load balancing.
In Proceedings of the ACM SIGPLAN Workshop on X10,
pages 33–38. ACM, 2015.
[23] L. Jaulin and E. Walter. Guaranteed nonlinear parameter
estimation from bounded-error data via interval analysis.
Mathematics and Computers in Simulation, 35(2):123–
137, 1993.
[24] K. D. Julian, J. Lopez, J. S. Brush, M. P. Owen, and M. J.
Kochenderfer. Policy compression for aircraft collision
avoidance systems. In Digital Avionics Systems Confer-
ence (DASC), 2016 IEEE/AIAA 35th, pages 1–10. IEEE,
2016.
[25] G. Katz, C. Barrett, D. L. Dill, K. Julian, and M. J. Kochen-
derfer. Reluplex: An efﬁcient smt solver for verifying deep
neural networks. In International Conference on Computer
Aided Veriﬁcation (CAV), pages 97–117. Springer, 2017.
[26] R. B. Kearfott. Rigorous global search: continuous prob-
lems, volume 13. Springer Science & Business Media,
2013.
[27] R. B. Kearfott and M. Novoa III. Algorithm 681: Intbis, a
portable interval newton/bisection package. ACM Transac-
tions on Mathematical Software (TOMS), 16(2):152–157,
1990.
[28] M. J. Kochenderfer, J. E. Holland, and J. P. Chryssan-
thacopoulos. Next-generation airborne collision avoid-
ance system. Technical report, Massachusetts Institute of
Technology-Lincoln Laboratory Lexington United States,
2012.
[29] J. Z. Kolter and E. Wong. Provable defenses against adver-
sarial examples via the convex outer adversarial polytope.
arXiv preprint arXiv:1711.00851, 2017.
[30] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet
classiﬁcation with deep convolutional neural networks.
In Advances in Neural Information Processing Systems
(NIPS), pages 1097–1105, 2012.
[31] A. Kurakin, I. J. Goodfellow, and S. Bengio. Adversarial
machine learning at scale. In International Conference on
Learning Representations (ICLR), 2017.
[32] Y. Liu, X. Chen, C. Liu, and D. Song. Delving into trans-
ferable adversarial examples and black-box attacks. In
International Conference on Learning Representations
(ICLR), 2016.
[33] M. Marston and G. Baca. Acas-xu initial self-separation
ﬂight tests. NASA Technical Reports Server, 2015.
[34] R. Moore and W. Lodwick. Interval analysis and fuzzy set
theory. Fuzzy Sets and Systems, 135(1):5–9, 2003.
1612    27th USENIX Security Symposium
USENIX Association
[35] R. E. Moore. Interval arithmetic and automatic error anal-
ysis in digital computing. Technical report, Applied Math-
ematics and Statistics Laboratories Technical Report No.
25, Stanford University, 1962.
[36] R. E. Moore. Methods And Applications Of Interval Anal-
ysis, volume 2. Siam, 1979.
[37] S.-M. Moosavi-Dezfooli, A. Fawzi, and P. Frossard. Deep-
fool: a simple and accurate method to fool deep neural
networks.
In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition (CVPR), pages
2574–2582, 2016.
[38] V. Nair and G. E. Hinton. Rectiﬁed linear units improve
restricted boltzmann machines. In Proceedings of the 27th
International Conference on Machine Learning (ICML),
pages 807–814, 2010.
[39] A. Nguyen, J. Yosinski, and J. Clune. Deep neural net-
works are easily fooled: High conﬁdence predictions
for unrecognizable images. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR), pages 427–436, 2015.
[40] M. T. Notes. Airborne Collision Avoidance System X.
MIT Lincoln Laboratory, 2015.
[41] N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. B.
Celik, and A. Swami. Practical black-box attacks against
machine learning. In Proceedings of the 2017 ACM on
Asia Conference on Computer and Communications Secu-
rity, pages 506–519. ACM, 2017.
[42] K. Pei, Y. Cao, J. Yang, and S. Jana. Deepxplore: Au-
tomated whitebox testing of deep learning systems. In
Proceedings of the 26th Symposium on Operating Systems
Principles (SOSP), pages 1–18. ACM, 2017.
[43] K. Pei, Y. Cao, J. Yang, and S. Jana. Towards practical
veriﬁcation of machine learning: The case of computer
vision systems. arXiv preprint arXiv:1712.01785, 2017.
[44] A. Raghunathan, J. Steinhardt, and P. Liang. Certiﬁed
defenses against adversarial examples. In International
Conference on Learning Representations (ICLR), 2018.
[45] M. J. C. Ramon E. Moore, R. Baker Kearfott. Introduction
to Interval Analysis. SIAM, 2009.
[46] D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou,
A. Huang, A. Guez, T. Hubert, L. Baker, M. Lai, A. Bolton,
et al. Mastering the game of go without human knowledge.
Nature, 550(7676):354, 2017.
[47] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wo-
jna. Rethinking the inception architecture for computer vi-
sion. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition (CVPR), pages 2818–2826,
2016.
[48] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan,
I. Goodfellow, and R. Fergus.
Intriguing properties of
neural networks. In International Conference on Learning
Representations (ICLR), 2014.
[49] Y. Tian, K. Pei, S. Jana, and B. Ray. DeepTest: Automated
testing of deep-neural-network-driven autonomous cars.
In Proceedings of the 40th International Conference on
Software Engineering (ICSE), 2018.
[50] R. Vaidyanathan and M. El-Halwagi. Global optimiza-
tion of nonconvex nonlinear programs via interval analy-
sis. Computers & Chemical Engineering, 18(10):889–897,
1994.
[51] W. Xu, Y. Qi, and D. Evans. Automatically evading classi-
ﬁers. In Proceedings of Network and Distributed Systems
Symposium (NDSS), 2016.
A Appendix: Formal Deﬁnitions for ACAS
Xu Properties φ1 to φ15
Inputs. Inputs for each ACAS Xu DNN model are:
ρ: the distance between ownship and intruder;
θ: the heading direction angle of ownship relative to intruder;
ψ: heading direction angle of intruder relative to ownship;
vown: speed of ownshipe;
vint: speed of intruder;
Outputs. Outputs for each ACAS Xu DNN model are:
COC: Clear of Conﬂicts;
weak left: heading left with angle 1.5o/s;
weak right: heading right with angle 1.5o/s;
strong left: heading left with angle 3.0o/s;
strong right: heading right with angle 3.0o/s.
45 Models. There are 45 different models indexed by two extra
inputs aprev and τ, model_x_y means the model used when
aprev = x and τ = y :
aprev: previous action indexed as {COC, weak left, weak
right, strong left, strong right}.
τ: time until loss of vertical separation indexed as {0, 1, 5,
10, 20, 40, 60, 80, 100}
Property φ1: If the intruder is distant and is signiﬁcantly slower
than the ownship, the score of a COC advisory will always be
below a certain ﬁxed threshold.
Tested on: all 45 networks.
Input ranges: ρ ≥ 55947.691, vown ≥ 1145, vint ≤ 60.
Desired output: the output of COC is at most 1500.
Property φ2: If the intruder is distant and is signiﬁcantly slower
than the ownship, the score of a COC advisory will never be
maximal.
Tested on: model_x_y, x ≥ 2, except model_5_3 and
Input ranges: ρ ≥ 55947.691, vown ≥ 1145, vint ≤ 60.
Desired output: the score for COC is not the maximal score.
Property φ3: If the intruder is directly ahead and is moving
towards the ownship, the score for COC will not be minimal.
model_4_2
Tested on: all models except model_1_7, model_1_8 and
Input ranges: 1500 ≤ ρ ≤ 1800, −0.06 ≤ θ ≤ 0.06, ψ ≥
model_1_9
3.10, vown ≥ 980, vint ≥ 960.
Desired output: the score for COC is not the minimal score.
Property φ4: If the intruder is directly ahead and is moving
away from the ownship but at a lower speed than that of the
ownship, the score for COC will not be minimal.
Tested on: all models except model_1_7, model_1_8 and
Input ranges: 1500 ≤ ρ ≤ 1800, −0.06 ≤ θ ≤ 0.06, ψ = 0,
model_1_9
vown ≥ 1000, 700 ≤ vint ≤ 800.
Desired output: the score for COC is not the minimal score.
USENIX Association
27th USENIX Security Symposium    1613
Property φ5: If the intruder is near and approaching from the
left, the network advises â ˘AIJstrong rightâ ˘A˙I.
Tested on: model_1_1
Input ranges: 250 ≤ ρ ≤ 400, 0.2 ≤ θ ≤ 0.4, −3.141592 ≤
ψ ≤ −3.141592 + 0.005, 100 ≤ vown ≤ 400, 0 ≤ vint ≤ 400.
Desired output: the score for “strong right” is the minimal
score.
Property φ6: If the intruder is sufﬁciently far away, the network
advises COC.
Desired output: the score for COC is the minimal score.
Tested on: model_1_1
Input ranges: 12000 ≤ ρ ≤ 62000, (0.7 ≤ θ ≤ 3.141592)∪
(−3.141592 ≤ θ ≤ −0.7), −3.141592 ≤ ψ ≤ −3.141592 +
0.005, 100 ≤ vown ≤ 1200, 0 ≤ vint ≤ 1200.
Property φ7: If vertical separation is large, the network will
never advise a strong turn
Tested on: model_1_9
Input ranges: 0 ≤ ρ ≤ 60760, −3.141592 ≤ θ ≤ 3.141592,
−3.141592 ≤ ψ ≤ 3.141592, 100 ≤ vown ≤ 1200, 0 ≤ vint ≤
1200.
Desired output: the scores for “strong right” and “strong left”
are never the minimal scores.
Property φ8: For a large vertical separation and a previous
“weak left” advisory, the network will either output COC or
continue advising “weak left.”
Tested on: model_2_9
Input ranges: 0 ≤ ρ ≤ 60760, −3.141592 ≤ θ ≤ −0.75 ·
3.141592, −0.1 ≤ ψ ≤ 0.1, 600 ≤ vown ≤ 1200, 600 ≤ vint ≤
1200.
Desired output: the score for “weak left” is minimal or the
score for COC is minimal.
Property φ9: Even if the previous advisory was “weak right,”
the presence of a nearby intruder will cause the network to
output a “strong left” advisory instead.
Desired output: the score for “strong left” is minimal.
Tested on: model_3_3
Input ranges: 2000 ≤ ρ ≤ 7000, 0.7 ≤ θ ≤ 3.141592,
−3.141592 ≤ ψ ≤ −3.141592 + 0.01, 100 ≤ vown ≤ 150, 0 ≤
vint ≤ 150.
Property φ10: For a far away intruder, the network advises COC.
Tested on: model_4_5
Input ranges: 36000 ≤ ρ ≤ 60760, 0.7 ≤ θ ≤ 3.141592,
−3.141592 ≤ ψ ≤ −3.141592 + 0.01, 900 ≤ vown ≤ 1200,
600 ≤ vint ≤ 1200.
Property φ11: If the intruder is near and approaching from the
left but the vertical separation is comparably large, the network
still tend to advise “strong right” more than COC.
Desired output: the score for COC is minimal.
Tested on: model_1_1
Input ranges: 250 ≤ ρ ≤ 400, 0.2 ≤ θ ≤ 0.4, −3.141592 ≤
ψ ≤ −3.141592 + 0.005, 100 ≤ vown ≤ 400, 0 ≤ vint ≤ 400.
Desired output: the score for “strong right” is always smaller
than COC.
Property φ12: If the intruder is distant and is signiﬁcantly slower
than the ownship, the score of a COC advisory will be the
minimal.
Tested on: model_3_3
Input ranges: ρ ≥ 55947.691, vown ≥ 1145, vint ≤ 60.
Desired output: the score for COC is the minimal score.
Property φ13: For a far away intruder but the vertical distance
are small, the network always advises COC no matter the direc-
tions are.
Tested on: model_1_1
Input ranges: 60000 ≤ ρ ≤ 60760, −3.141592 ≤ θ ≤
3.141592, −3.141592 ≤ ψ ≤ 3.141592, 0 ≤ vown ≤ 360, 0 ≤
vint ≤ 360.
Property φ14: If the intruder is near and approaching from the
left and vertical distance is small, the network always advises
strong right no matter previous action is strong right or strong
left.
Desired output: the score for COC is the minimal.
Tested on: model_4_1, model_5_1
Input ranges: 250 ≤ ρ ≤ 400, 0.2 ≤ θ ≤ 0.4, −3.141592 ≤
ψ ≤ −3.141592 + 0.005, 100 ≤ vown ≤ 400, 0 ≤ vint ≤ 400.
Desired output: the score for “strong right” is always the
minimal.
Property φ15: If the intruder is near and approaching from the
right and vertical distance is small, the network always advises
strong left no matter previous action is strong right or strong
left.
Tested on: model_4_1, model_5_1
Input
250 ≤ ρ ≤ 400, −0.4 ≤ θ ≤ −0.2,
ranges:
−3.141592 ≤ ψ ≤ −3.141592 + 0.005, 100 ≤ vown ≤ 400,
0 ≤ vint ≤ 400.
Desired output:
the score for “strong left” is always the
Tested on: model_4_1
Input ranges: 400 ≤ ρ ≤ 10000, θ = 0.2, ψ = −3.141592 +
0.005, vown = 10, vint = 10.
Desired output: the score for “strong right” is the minimal.
Tested on: model_4_1
Input ranges: ρ = 400, −0.2 ≤ θ ≤ 0, ψ = −3.141592 +
0.005, vown = 1000, vint = 1000.
Desired output: the score for “strong right” is the minimal.
minimal.
Property S1:
Property S2:
Property S3:
Tested on: model_1_2
Input ranges: ρ = 400, −0.1 ≤ θ ≤ 0.1, ψ = −3.141592,
vown = 500, vint = 600.
Desired output: the score for “strong right” is the minimal.
1614    27th USENIX Security Symposium
USENIX Association