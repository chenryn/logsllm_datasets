distance classi(cid:2)er:
M ahdist(x; (cid:22)j(cid:6)) = (x (cid:0) (cid:22))T (cid:6)(cid:0)1(x (cid:0) (cid:22))
(6)
Here, (cid:22) is the 1-byte target distribution, and we set (cid:6) = 0:1I
where I is the identity matrix. Statistical IDS systems such as
PayL [41] employ the Mahalanobis distance classi(cid:2)er. We chose
our estimates in the same manner.
Figure 5(b) shows the engine’s blending attack converging on the
target distribution. The Y-axis shows the Mahalanobis distance as
a function of the size of the blending section. For each size, we
generate a new malcode sample with a blend section of that size.
Next, we (cid:2)ll the section with bytes generated using the method we
outlined at the start of this section, then calculate the 1-byte distri-
bution of the shellcode with these new bytes in place and (cid:2)nd the
Mahalanobis distance to the target distribution using Equation 6.
We see that a padding section of around 200 bytes is needed to
blend an executable shellcode sample generated from our engine
into the given target distribution, under our chosen threshold value.
In our example, we have given our engine the correct target distri-
bution. In practice, the target distribution will have to be estimated
in some way. We included this demo only to demonstrate the po-
tential of combining many different attack vectors into the same
engine. Our blending attack is not meant to be the most advanced;
we refer the reader to related work on this topic [17].
We could also make use of binary to text encryption to transform
the decoder portion of the shellcode into a string that consists of
only printable characters by using techniques such as the ones pro-
vided in ShellForge engine [6]. This technique could improve the
blending strength of the engine with relatively little implementa-
tion effort. In addition, there are other techniques that will allow
the shellcode survive sanitization functions such as to upper()
and to lower().
4. EXPLORING N-SPACE
We have so far focused our attention primarily on understanding
and extending existing engines and techniques. This section in-
vestigates the extent to which polymorphic code exists in n-space.
More speci(cid:2)cally, given n-space, we have 28n possible strings. We
want to explore the entirety of this space and (cid:2)nd all of the se-
quences that (cid:147)behave(cid:148) like polymorphic code. Since completing
this search is intractable for large n (e.g., n > 4), we restrict our
attention to byte strings of length 10 in order to make our search
feasible. From the structure of the decoder, we know that it must
contain two components: (1) a modi(cid:2)cation operation (e.g., add,
sub, xor, etc.), and (2) some form of a loop component e.g.,
jmpz, that sweeps the cipher across the payload. Figure 1 shows
that real full decoders are longer and more complex than these sim-
ple requirements. For example, they contain maintenance oper-
ations such as clearing registers, multiple cipher operations, and
some exotic code to calculate the location of the executable. We
believe, however, that our restrictions retain the most critical oper-
ations for examining decoding behavior.
Our restricted, 10-byte examination reduces the search space to
280 strings. This problem remains intractable if we plan to ex-
plore the space one unique string at a time. Starting at f0x00
0x00: : :0x00g, testing to see if it exhibits polymorphic behav-
ior, proceeding to f0x00 0x00: : :0x01g, testing that string, and
so on until we reach f0xFF 0xFF: : :0xFFg represents a signi(cid:2)-
cant dedication of time and resources with little reason to suggest
that such a complete procedure conveys substantially more mean-
ingful data than a more intelligent and judiciously directed search.
Instead, we make use of genetic algorithms [33] to perform the
search in a directed manner by choosing to explore areas were ex-
isting polymorphic code resides as a form of local search. To sat-
isfy these requirements, we de(cid:2)ne a function that accepts a string as
input and determines whether that string represents x86 code that
exhibits polymorphic behavior.
4.1 Decoder Detector
We designed our (cid:147)decoder detector(cid:148) and implemented it as a pro-
cess monitoring tool within the Valgrind emulation environment.
Valgrind’s [27] binary supervision enables us to add instrumenta-
tion to a process without modifying its source code or altering the
semantics of the process’s operations. Most importantly, Valgrind
provides support for examining memory accesses, thus allowing us
to track what parts of memory a process touches during execution.
Our tool detects (cid:147)self-modifying code,(cid:148) which we de(cid:2)ne as code
that modi(cid:2)es bytes within a small distance of itself. We restrict
our attention to instruction sequences that modify code within two
hundred bytes of itself in either direction in memory (cid:151) that is,
we sandwich the code within two NOP sleds of two hundred bytes
each. The GA-search framework compiles and executes a buffer
over(cid:3)ow exploit in the emulation environment and checks for any
polymorphic behavior.
The following polymorphic behaviors are of interest: we de-
(cid:2)ne self(cid:150)write as writing to a memory location within two hundred
bytes of the executing instruction. We de(cid:2)ne self(cid:150)modify as read-
ing from a memory location within two hundred bytes and then,
within the next four instructions, performing a write to the same lo-
cation, simulating the behavior of in-place modi(cid:2)cation operations
effected via instructions such as xor, add, sub. Of course,
some polymorphic techniques may not replace code in(cid:150)place, but
any such examples further saturate n-space.
4.2 Genetic Algorithms
Genetic algorithms is a classic optimization technique from AI
and have proved most useful in problems with a large search space
domain and where closed formed solutions are not available or di-
rectly optimizeable. Instead, various solutions are represented in
coded string form and evaluated. A function is used to determine
the (cid:147)(cid:2)tness(cid:148) of the string. GA algorithms combine (cid:2)t candidates to
produce new strings over a sequence of epochs. In each epoch, the
search evaluates a pool of strings, and the best strings are used to
produce the next generation according to some evolution strategy.
For a more detailed discussion, we refer the reader to [33].
The (cid:2)tness function used for our GA search framework is the
decoder detector described above. We score each self(cid:150)write op-
eration a 1 and each self(cid:150)modify operation a 3. The higher score
for the latter operation re(cid:3)ects our interest in identifying instruc-
tion sequences that represent the xor, add, sub-style decoder
behavior. The sum of the behavior scores of a 10-byte string de-
(cid:2)nes its (cid:2)tness. Any string with a non-zero score therefore exhibits
polymorphic behavior.
We relax our GA optimization constraint since we do not need to
(cid:2)nd the (cid:147)best(cid:148) decoder. Instead, we have a low limit for polymor-
phic behavior and will admit any string that passes that threshold
into the population. We used a dynamic threshold for minimum ac-
ceptable polymorphic behavior as 5% of the average polymorphic
score of the previously found sequences; we bootstrapped with an
overall minimum score of 6. The threshold was used in order to
ignore strings which performed very few self-modi(cid:2)cations; we
wanted to capture strings that exhibited a signi(cid:2)cant amount of
polymorphic behavior (i.e., it encapsulated some form of a loop
construct)4. We stored all unique strings that met the polymorphic
4We used a four second runtime limit in our Valgrind decoder de-
criteria in what we term the candidate decoder pool. We observed
that the average (cid:2)tness value reached into the hundreds after a few
hundred epochs.
Genetic algorithms perform intelligent searching by restricting
their attention to searching the space surrounding existing samples.
Therefore, this form of local search needs quality starting posi-
tions to achieve reasonable results. We seeded our search engine
with two decoder strings extracted from ShellForge [6] and roughly
45,000 strings from Metasploit [26] in order to obtain a good distri-
bution of starting positions. We implemented a standard GA-search
framework using some common evolution strategies, listed here:
1. Increment: The lowest signi(cid:2)cant byte is incremented by
one modulo 255, with carry. We use this technique after (cid:2)nd-
ing one decoder to then undertake a local search of the sur-
rounding space.
2. Mutate: A random number of bytes within the string are
changed randomly. Useful for similar reasons, except we
search in a less restricted neighborhood.
3. Block swap: A random block of bytes within one string
is randomly swapped with another random block from the
same string. This technique helps move blocks of instruc-
tions around.
4. Cross breed: A random block of bytes within one string
is randomly swapped with another random block from an-
other string. This technique helps combine different sets of
instructions.
5. Rotate: The elements of the string are rotated to the left
position-wise by some random amount with a wrap-around.
This is to put the same instructions in different order.
6. Pure random: A new purely random string is generated.
This adds variation to the pool and help prevent the search
from getting stuck on local max. It is used mainly to intro-
duce some entropy into the population and is not useful by
itself since the likelihood of (cid:2)nding executable x86 code with
self modi(cid:2)cation and an inner loop at random is low.
For each sequence, we automatically generate a new program that
writes the string into a character buffer between two NOP sleds of
200 bytes each. The program then redirects execution into that
buffer, effectively simulating a buffer over(cid:3)ow attack. We then
retrieve the (cid:2)tness score of that string from the decoder detector,
evaluate it, and continue with the search according to the process
described above. An alternative search procedure would parame-
terize the actual x86 instruction set into a genetic algorithm search
package and dynamically write decoders. This is the subject of our
ongoing work. This technique bears a strong similarity to work
done by Markatos et al. [31]. Whereas they implemented their tool
as a detector, dynamically (cid:2)ltering network content through the de-
tector to search for the presence of decryption engines, we use our
decoder detector in an of(cid:3)ine manner where we generate the strings
ourselves in order to precompute a set of byte strings that perform
self(cid:150)modi(cid:2)cation.
4.3 GA-Search results
This evaluation aims to assess the hypothesis that the class of
self-modifying code spans n-space where n is the length of the de-
coder sequence. Our GA-search framework found roughly two mil-
lion unique sequences after several weeks of searching and shows
no signs of diminishing returns. The results that we derive show
that the class of n-byte self-modifying code not only spans n-space
but saturates it as well.
tector tool as we periodically (cid:2)nd strings that perform in(cid:2)nite self
modifying loops.
VALGRIND(cid:13)
Decoder Detector(cid:13)
(Gets fitness score)(cid:13)
Sufficiently(cid:13)
fit?(cid:13)
YES(cid:13)
Insert into decoder(cid:13)
pool(cid:13)
NO(cid:13)
Select(cid:13)
Sequence(s)(cid:13)
Generate New(cid:13)
Sequence(cid:13)
Write test program(cid:13)
Jump execution(cid:13)
into buffer(cid:13)
Decoder(cid:13)
Pool(cid:13)
Evolution tactics(cid:13)
Mutate  - Cross Breed -(cid:13)
Increment - Block Rotate -(cid:13)
Pure Random(cid:13)
Figure 6: Decoder search engine (cid:3)ow chart. We construct our
library of decoders using a feedback loop that creates candidate de-
coders, con(cid:2)rms that they exhibit suf(cid:2)cient decoding behavior, and
generates more samples from them.
First let us look at the (rounded) mean and variances of the gener-
ated sample pool of 10-byte sequences, shown in decimal for each
reading:
Mean: f90,66,145,153,139,127,123,138,134,126g
Standard deviation: f72,71,86,78,80,84,86,82,75,76g
The mean exists near the center of n-space (in this case, n-space
is a vector of 10 entries each of value 128). The high variance
along each dimension shows that the samples are widely scattered.
Statistical IDS detectors typically operate under the assumption
14
12
10
8
6
4
2
0
0
GA samples, normalized mean 1−gram distrib
50
100
150
200
250
300
(a)
(b)
Figure 7: Results. (a) 1-gram distribution - note the uniform
byte distribution. (b) 3-gram scatter plot - each dot represents
a 3-gram, note the 3-space saturation.
that the class of malcode being modeled exhibit a certain n-gram
distribution. This (cid:147)byte-spectrum(cid:148) can be modeled and used to de-
sign a classi(cid:2)er to separate malcode from normal traf(cid:2)c (n = 1
in the case of PayL [40] and n = 3; 4; 5; 6; 7 in the case of Ana-
gram [21]).We examined our generated samples to see if such a
signal existed. For each sequence in our sample pool, we compute
the 1-byte distribution, then (cid:2)nd the average for all sequences, nor-
malized by dividing by the variances along each dimension, as we
did in Section 3. Figure 7(a) shows the average 1-bytes distribu-
tion. We can see that the sample pool contains no distinguishable
distribution but rather is closer to white noise (with the exception
of the fx00g and fxFFg values, which are likely to be padding
artifacts). For 3-space, Figure 7(b) shows the 3-gram scatter plot
of all 3-grams extracted from all the candidates in the pool. This
plot shows that, for 3-grams, the space is well saturated. Since it
is a subspace of 3-space, 2-space also saturated. The p-score of
these samples was close to 1:00. This result can be expected as
(cid:147)polymorphic code(cid:148) is less constrained than the full decoders we
have worked with in the previous sections. Nevertheless, our re-
sults show that there is a signi(cid:2)cant degree of variance in x86 code
that performs operations that we can associate with self(cid:150)decryption
routines.
4.4 Results Discussion
Our results show that the span of polymorphic code likely reaches
across n-space. The challenge of signature(cid:150)based detection is to
model a space on the order of O(28(cid:1)n) signatures to catch potential
attacks hidden by polymorphism. To cover thirty-byte decoders re-
quires O(2240) potential signatures, for comparison there exist an
estimated 280 atoms in the universe. We would much sooner run
out of atoms than attackers run out of decoders. Current signature
schemes work only because of advances in rapid isolation and gen-
eration of signatures. This strategy may work for the short term;
however, our work indicates that defenders cannot capture the ini-
tiative from the attacker under this reactive defense strategy. Some-
what troubling is the additional implication that regardless of what
a normal model of traf(cid:2)c for a particular site may be, there exists
a certain probability that a range of decoders would fall within the
span of that normal model because sequences which exhibit poly-
morphic behavior span most of n-space.
5. RELATED WORK