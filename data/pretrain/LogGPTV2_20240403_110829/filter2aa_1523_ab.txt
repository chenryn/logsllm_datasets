Overflows began to rule the day, and in the late 90’s a number of vulnerabilities were unearthed 
in network services, including Sendmail, mountd, portmap and Bind, and repositories of reusable 
exploit code like Rootshell.com and others became a source of working exploits for unpatched 
services for any administrator, pen-tester (and yes, attacker) with access to a Linux box and a 
compiler. 
While other classes of remotely exploitable bugs were of course found during this time and after, 
it’s fair to say that Crispin Cowan was accurate in 1998 when he referred to overflows as “the 
vulnerability of the decade”. In 2002, Gerhard Eschelbeck of Qualys predicted another ten years 
of overflows as the most common attack vector. Can we expect the same forecast in 2012? 
0x03: Fear sells. 
For the most part, the “decade of buffer overflows” did little to change the reactive 
approach to vulnerabilities systemic to our field. With some notable of exceptions, while 
exploitation of memory corruption vulnerabilities became incredibly refined (“Point. Click. Own.”), 
the burgeoning (now, leviathan) security industry as a whole either missed the point or, if you’re 
of a conspiratorial bent, chose to ignore it. 
Compromises became selling tools for firewall and IDS vendors, with mountains of security gear 
stacked like cordwood in front of organizations’ ballooning server farms, and these, along with 
the DMZ and screened subnet approach, allowed the damage from exploitation to be contained, 
if not prevented. 
Shawn Moyer :: (un)Smashing the Stack :: DefCon 0x0F :: Page 5 of 13 
Fortunes were made scanning for patchlevels, and alerting on ex post acto exploitation. 
Consultants built careers running vulnerability scanners, reformatting the results with their 
letterhead, and delivering the list of exploitable hosts (again, often due to memory corruption 
vulnerabilities in network services), along with a hefty invoice, to the CIO or CSO. 
f
The mass of the security industry simply adopted the same model it had already refined with 
antivirus – signatures for specific attacks, and databases of vulnerable version numbers, for sale 
on a subscription basis. None of this addressed the fundamental problem, but it was good 
business, and like antivirus, if an organization kept their signatures updated and dedicated an 
army of personnel to scan and patch, they could at least promise some semblance of safety.  
0x04: Yelling “theater” in a crowded fire. 
While the march of accelerated patch cycles and antvirus and IDS signature downloads 
prevailed, a small but vocal minority in the security community continued to search for other 
solutions to the memory corruption problem. 
Ultimately many of these approaches either failed or were proven incomplete, but over time, the 
push and pull of new countermeasures and novel ways to defeat them has refined these 
defenses enough that they can be considered sound as a stopgap that makes exploitation of 
vulnerable code more difficult, though of course not impossible.  
The refinement of memory corruption attacks and countermeasures shares a lot with the 
development of cryptosystems: an approach is proposed, and proven breakable, or trustworthy, 
over time. As we’ll see later, like cryptography, the weaknesses today seem to lie not in the 
defenses themselves, but in their implementation. Because so many different approaches have 
been tried, we’ll focus on those that are most mature and that ultimately gained some level of 
acceptance. 
0x05: Data is data, code is code, right? 
The concept is beguiling: in order for a stack-based overflow to overwrite a return 
pointer, a vulnerable buffer, normally reserved for data, must be stuffed with shellcode, and a 
pointer moved to return to the shellcode, which resides in a data segment. Since the code 
(sometimes called “text”) segment is where the actual instructions should reside on the stack, a 
stack-based overflow is by definition an unexpected behavior.  
So, why not just create a mechanism to flag stack memory as nonexecutable (data) or 
executable (code), and simply stop classic stack-based overflows entirely? In the POSIX 
specification, this means that a given memory page can be flagged as PROT_READ and 
PROT_EXEC, but not PROT_WRITE and PROT_EXEC, effectively segmenting data and code.  
SPARC and Alpha architectures have had this capability for some time, and Solaris from 2.6 on 
has supported globally disabling stack execution in hardware. 64-bit architectures have a 
substantially more granular paging implementation, which makes this possible much more 
trivially – this is what prompted AMD to resurrect an implementation of this in 2001 with their 
“NX” bit, referred to as “XD” (eXecute Disable) by Intel on EM64T. 
Shawn Moyer :: (un)Smashing the Stack :: DefCon 0x0F :: Page 6 of 13 
Software-based emulation on 32-bit architectures typically requires a “line in the sand” approach, 
where some memory range is used for data, and another for code. This is far less optimal, and 
may be possible to circumvent under specific conditions. With hardware-based nonexecutable 
stack features now widely available, this will become less of an issue over time, but for now, 
software emulation is better than no protection at all.  
Historically, execution on the stack had been expected in some applications – called trampolining, 
the somewhat cringeworthy process of constructing code on the fly on the stack can yield some 
performance and memory access benefits for nested functions. In the past, a nonexecutable 
stack has broken X11, Lisp, Emacs, and a handful of other applications. With the advent of wider 
adoption of NX, and “trampoline emulation” in software, this is no longer as much of an issue, 
though it delayed adoption for some time. 
Solar Designer built the first software noexec implementation for the Linux kernel, in 1997. When 
it was proposed for integration into the kernel mainline, it was refused for a number of reasons. 
Trampolines, and the work required to make them possible, was a large factor. In a related 
thread on disabling stack execution, Linus Torvalds also gave an example of a return-to-libc 
attack, and stated that a nonexecutable stack alone would not ultimately solve the problem. 
In short  anybody who thinks tha  the non-execu able stack gives them any real security 
is very very much living in a dream world. It may catch a few attacks for old binaries that 
have security problems, but the basic problem is that the binaries allow you to overwrite 
their stacks. And if they allow that, then they allow the above exploit.  
,
t
t
It probably takes all of five lines of changes to some existing exploit, and some random 
program to find out where in the address space the shared libraries tend to be loaded.  
Torvald’s answer was prescient, and in recent years the most common approach to defeating 
hardware and software non-executable stack has been return-to-libc. On Windows, Dave Maynor 
also found that overwriting an exception handler or targeting the heap was effective, and Krerk 
Piromposa and Richard Embody noted that a “Hannibal” attack, or multistage overflow, in which 
a pointer is overwritten to point to an arbitrary address, and then shellcode is written to the 
arbitrary address in the second stage, could succeed. In all of these cases, data segments on the 
stack were not replaced with code, and so the read-exec or read-write integrity remained intact. 
Still, Solar’s patch gained adoption among security-centric Linux distributions, and it offered some 
level of protection, if only by obscurity – most distributions of Linux had fully executable stacks, 
so typical exploits in wider use would fail on systems using the patchset. 
Over time, the inarguability of a simple protection against an entire class of overflow exploits led 
to the nonexecutable stack being ubiquitous. Today, WinXP SP2, 2003, and Vista have software-
based nonexecutable stacks and integrate with hardware protection on 64-bit platforms, as does 
Linux (via PaX or RedHat’s ExecShield), OpenBSD with W^X, and even (on Intel) MacOS X. 
Outside of the use of other classes of attacks, such as writing to the heap, or ret-to-libc, likely 
the key issue with stack protection on any platform is the ability to disable it at will. The 
mprotect() function on Linux / Unix and VirtualProtect() in Windows allow applications to ask for 
stack execution at runtime, and opt out of the security model. Microsoft’s .NET JIT compiler, 
Sun’s JRE, and other applications that compile code at run-time expect to create code on the 
stack, so these may become an area of greater scrutiny in the future.  
Shawn Moyer :: (un)Smashing the Stack :: DefCon 0x0F :: Page 7 of 13 
Certainly nonexecutable stacks are only a small part of the solution, and opt-out with mprotect() 
and VirtualProtect() give developers the ability to override them, but they are computationally 
inexpensive, and a worthy part of a larger approach. 
0x06: The canary in the coalmine. 
Crispin Cowan’s StackGuard, released in 1997, was the first foray into canary-based stack 
protection as a mechanism to prevent buffer overflows. The approach was simple: place a 
“canary” value into the stack for a given return address, via patches to GCC, in 
function_prologue. On function_epilogue, if a change to the canary value was detected, the 
canary checks called exit() and terminated the process.  
Cowan found that StackGuard was effective at defending against typical stack-based overflows in 
wide use at the time, either stopping them entirely, or creating a Denial of Service condition by 
causing the service to exit. 
After StackGuard’s initial release, Tim Newsham and Thomas Ptacek pointed out two issues in the 
implementation, less than 24 hours later. The problem was in the canary value’s lack of 
randomization. If a guessable or brute-forceable canary was the only protection in place, the 
defense was only as good as the canary. So, either guessing the canary, or finding a way to read 
the canary value from memory, would render the defense void. 
But even with a stronger canary value, the larger weakness of protecting only the return address 
remained. While the return address is one of the most effective and common targets in exploiting 
an overflow, it’s by no means the only one. Essentially, any other area in memory was 
unprotected, so as long as the canary was intact, the injected shellcode still ran.  
Originally introduced in Phrack 56 by HERT, an effective approach was demonstrated – writing 
“backward” in specific cases via an unbounded strcpy() could bypass the protection. The Phrack 
56 article also proved exploitability of the same weaknesses in the canary value Newsham and 
Ptacek had already pointed out. This led to the adoption of a more robust approach to the canary 
value, and an XOR’d canary of a random value and the return address was eventually adopted in 
future versions. Gerardo Richarte of Core Security also demonstrated that writes to the Global 
Offset Table, “after” the return address, as well as overwrites of frame pointers and local 
variables, would still lead to code execution. 
Hiroaki Etoh’s ProPolice built on StackGuard’s canary concept, but matured the approach much 
further, and created a full implementation that added canaries (Etoh prefers the term “guard 
instruments”) for all registers, including frame pointers and local variables, and also reordered 
data, arrays, and pointers on the stack to make overwriting them more difficult: if pointers and 
other likely targets are not near data in memory, it becomes much more difficult to overwrite a 
given buffer and move the pointer to the supplied shellcode. 
In 2004, Pete Silberman and Richard Johnson used John Wilander’s Attack Vector Test Platform 
to evaluate ProPolice and a number of other overflow protection methods, and found ProPolice 
effective at stopping 14 of the 20 attack vectors tested by AVTP. ProPolice’s primary weaknesses 
were in not protecting the heap and bss, and in not protecting smaller arrays or buffers. 
ProPolice was accepted for inclusion with GCC 4.1, and was included in OpenBSD and Ubuntu as 
a backport to GCC 3.x. With 4.1 integration, it’s now available in every major Linux and most 
Shawn Moyer :: (un)Smashing the Stack :: DefCon 0x0F :: Page 8 of 13 
Unix distributions, and each of the BSD’s. Microsoft also integrated a variant of XOR canaries and 
a limited level of stack reordering into WinXP SP2 and Windows 2003 and Vista. It’s extremely 
important to note that compiler flags for what protections are enabled need to be set to take 
advantage of ProPolice on any platform, and are generally not enabled by default. On Linux / 
Unix, the “—fstack-protector and –fstack-protector-all” flags must be set, and on Windows, 
applications need to be compiled with /GS to gain ProPolice-like functionality. 
0x07: /dev/random pitches in to help 
In 2001, the PaX team introduced ASLR, or address space layout randomization, as part 
of the PaX suite of security patches to the Linux kernel. ASLR in a number of forms was also 
introduced into OpenBSD around roughly the same time, and due to some contention in these 
two camps over a number of topics, it’s best to say that a bit of credit belongs to both, though 
I’m sure they shared a collective sigh when Microsoft introduced it five years later in Vista, to 
much fanfare and fawning in the IT press. 
In general, ASLR randomizes memory allocation so that a given application, kernel task or library 
will not be in the same address with (hopefully) any level of predictability. This aims to make 
reusable exploits tougher to develop, as addresses to be targeted for example in a return-to-libc 
attack, like the address of the system() call, will not be in the same location on multiple 
machines.  
Like attacks on TCP sessions with sequential ISN’s, which made IP spoofing relatively trivial, an 