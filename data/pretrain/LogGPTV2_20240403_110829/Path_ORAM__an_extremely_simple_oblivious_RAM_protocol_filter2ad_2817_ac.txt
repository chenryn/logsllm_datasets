Z log2 N transient storage for temporarily caching a path
fetched from the server during each ORAM access.
Our main theorem in Section 6 shows the probability of
stash overﬂow decreases exponentially with the stash size,
given that the bucket size Z is large enough. This theorem
is veriﬁed by experimental results as shown in Figure 3 and
Figure 2. In each experiment, the ORAM is initially empty.
We ﬁrst load N blocks into ORAM and then access each
block in a round-robin pattern. I.e., the access sequence is
{1, 2, . . . , N, 1, 2, . . . , N, 1, 2, . . .}. Section 6.3 shows this is
a worst-case access pattern in terms of stash occupancy for
Path ORAM. We simulate our Path ORAM for a single run
for about 250 billion accesses after doing 1 billion accesses for
warming-up the ORAM. It is well-known that if a stochastic
process is regenerative (empirically veriﬁed to be the case for
Path ORAM), the time average over a single run is equivalent
to the ensemble average over multiple runs (see Chapter 5
of [19]).
Figure 2 shows the minimum stash size to get a failure
probability less than 2−λ with λ being the security parameter
on the x-axis. In Table 3, we extrapolate those results for
realistic values of λ. The experiments show that the required
stash size grows linearly with the security parameter, which
is in accordance with the Main Theorem in Section 6 that
the failure probability decreases exponentially with the stash
size. Figure 3 shows the required stash size for a low failure
probability (2−λ) does not depend on N . This shows Path
ORAM has good scalability.
Though we can only prove the theorem for Z ≥ 6, in
practice, Z = 4 and Z = 5 also work well. Z = 3 behaves
relatively worse in terms of stash occupancy, and it is unclear
whether Z = 3 works.
We only provide experimental results for small security
parameters to show that the required stash size is O(λ) and
Figure 2: Empirical estimation of the required stash
size to achieve failure probability less than 2−λ where
λ is the security parameter. Measured for N = 216,
but as Figure 3 shows, the stash size does not de-
pend on N (at least for Z = 4). The measurements
represent a worst-case (in terms of stash size) ac-
cess pattern. The stash size does not include the
temporarily fetched path during Access.
Security Parameter (λ)
80
128
256
5
6
Bucket Size (Z)
4
Max Stash Size
89
147
303
63
105
218
53
89
186
Table 3: Required max stash size for large secu-
rity parameters. Shows the maximum stash size re-
quired such that the probability of exceeding the
stash size is less than 2−λ for a worst-case (in terms
of stash size) access pattern. Extrapolated based on
empirical results for λ ≤ 26. The stash size does not
include the temporarily fetched path during Access.
does not depend on N . Note that it is by deﬁnition infeasible
to simulate for practically adopted security parameters (e.g.,
λ = 128), since if we can simulate a failure in any reason-
able amount of time with such values, they would not be
considered secure.
A similar empirical analysis of the stash size (but with the
path included in the stash) was done by Maas et al. [24].
5.2 Bucket Load
Figure 4 gives the bucket load per level for Z ∈ {3, 4, 5}.
We prove in Section 6.3 that for Z ≥ 6, the expected usage
of a subtree T is close to the number of buckets in it. And
Figure 4 shows this also holds for 4 ≤ Z ≤ 5. For the levels
close to the root, the expected bucket load is indeed 1 block
(about 25% for Z = 4 and 20% for Z = 5). The fact that the
root bucket is seldom full indicates the stash is empty after
a path write-back most of the time. Leaves have slightly
heavier loads as blocks accumulate at the leaves of the tree.
Z = 3, however, exhibits a diﬀerent distribution of bucket
load (as mentioned in Section 5.1 and shown in Figure 2,
Z = 3 produces much larger stash sizes in practice).
304(a) Z=3
(b) Z=4
(c) Z=5
Figure 4: Average bucket load of each level for diﬀerent bucket sizes. The error bars represent the 1/4 and
3/4 quartiles. Measured for a worst-case (in terms of stash size) access pattern.
an empty ORAM; s completely deﬁnes all the randomness
needed to determine, for each block address a, its leaf label
and which bucket/stash stores the block that corresponds
to a. In particular the number of real blocks stored in the
buckets/stash can be reconstructed.
We assume an inﬁnite stash and in our analysis we investi-
gate the usage u(TL(Z)[s]) of the stash deﬁned as the number
of real blocks that are stored in the stash after a sequence
s of load/store operations. In practice the stash is limited
to some size R and Path-ORAM fails after a sequence s of
load/store operations if the stash needs more space: this
happens if and only if the usage of the inﬁnite stash is at
least u(TL(Z)[s]) > R.
Theorem 1
(Main). Let a be any sequence of block
addresses with a working set of size at most N . For a bucket
size Z = 7, tree depth L ≥ (cid:100)log N(cid:101) + 1 and stash size R,
the probability of a Path ORAM failure after a sequence of
load/store operations corresponding to a, is at most
P rob(u(TL(Z)[s]) > R|a(s) = a) ≤ 14 · 0.625R,
where the probability is over the coin ﬂips that determine x
and y in s = (a, x, y).
For Z = 6 and L ≥ (cid:100)log N(cid:101) + 3 we obtain the bound
370 · 0.667R.
As a corollary, for s load/store operations on N data blocks,
Path ORAM with client storage ≤ R blocks, server storage
28N blocks and bandwidth 14 log N blocks per load/store
operation, fails during one of the s load/store operations with
probability ≤ s · 14 · 0.625R. So, if we assume the number of
load/stores is equal to s = poly(N ), then, for a stash of size
O(log N )ω(1), the probability of Path ORAM failure during
one of the load/store operations is negligible in N .
Proof outline. The proof of the main theorem consists of
several steps: First, we introduce a second ORAM, called
∞-ORAM, together with an algorithm that post-processes
the stash and buckets of ∞-ORAM in such a way that if ∞-
ORAM gets accessed by a sequence s of load/store operations,
then post-processing leads to a distribution of real blocks
over buckets that is exactly the same as the distribution as
in Path ORAM after being accessed by s.
Second, we characterize the distributions of real blocks
over buckets in (a not post-processed) ∞-ORAM for which
Figure 3: The stash size to achieve failure proba-
bility less than 2−λ does not depend on N (Z = 4).
Measured for a worst-case (in terms of stash size)
access pattern. The stash size does not include the
temporarily fetched path during Access.
6. THEORETIC BOUNDS
In this section we will bound the probability that, after a
sequence of load/store operations, non-recursive Path-ORAM
exceeds its stash size: We will show that this probability
decreases exponentially in the size of the stash for a constant
bucket size.
By TL(Z) we denote a non-recursive Path-ORAM with
L+1 levels in which each bucket stores Z real/dummy blocks;
the root is at level 0 and the leafs are at level L.
We deﬁne a sequence of load/store operations s as a triple
(a, x, y) that contains (1) the sequence a = (aj)s
j=1 of block
addresses of blocks that are loaded/stored, (2) the sequence of
labels x = (Xj)s
j=1 as seen by the server, and (3) the sequence
y = (Yj)s
j=1 of remapped leaf labels. (a1, Y1, X1) corresponds
to the most recent load/store operation, (a2, Y2, X2) corre-
sponds to the next most recent load/store operation, etc.
The number of load/store operations is denoted by s = |s|.
The working set corresponding to a is deﬁned as the number
of distinct block addresses aj in a. We write a(s) = a.
By TL(Z)[s] we denote the distribution of real blocks in
TL(z) after a sequence s of load/store operations starting with
305post-processing leads to a stash usage > R. We show that the
stash usage after post-processing is > R if and only if there
exists a subtree T for which its ”usage” in ∞-ORAM is more
than its ”capacity”. This means that we can use the union
bound to upper bound P rob(TL(Z)[u(s)] > R|a(s) = a ) as
a sum of probabilities over subtrees.
Third, we analyze the usage of subtrees T . We show
how a mixture of a binomial and a geometric probability
distribution expresses the probability of the number of real
blocks that do not get evicted from T after a sequence s
of load/store operations. By using the Chernoﬀ bounding
technique we prove the main theorem.
6.1 ∞-ORAM
We deﬁne ∞-ORAM, denoted by RL(Z), as an ORAM
that exhibits the same tree structure as Path-ORAM with
L + 1 levels but where each bucket has an inﬁnite size. The
interface of RL(Z) operates as the interface of TL(∞) with
the following distinguishing exception: Each bucket in RL(Z)
is partially stored in server storage and partially stored in
the ORAM stash at the client; Z indicates the maximum
number of blocks in a bucket that can be stored in server
storage. If a bucket has more than Z real blocks, then the
additional blocks are stored in the ∞-ORAM stash.
We deﬁne post-processing3 G(RL(Z)[s]) as a Greedy al-
gorithm G that takes as input the state of RL(Z) after a
sequence s of load/store operations and repeats the following
strategy:
1. Select a block in the stash that was not selected before.
Suppose it has leaf label L and is stored in the bucket
at level h on the path from the root to leaf L.
2. Find the highest level i ≤ h such that the bucket at
level i on the path to leaf L stores  R after post-processing, we start by analyzing
distributions of blocks over subtrees: When we talk about
a subtree T , we always implicitly assume that it is rooted
at the root of the ORAM tree, i.e., T contains the root of
the ORAM tree and all its nodes are connected to this root.
We deﬁne n(T ) to be the total number of nodes in T . For
∞-ORAM we deﬁne the usage u(RL(Z)[s]; T ) of T after a
sequence s of load/store operations as the actual number of
real blocks that are stored in the buckets of T (in ∞-ORAM
blocks in a bucket are either in server storage or in the stash).
The following lemma characterizes the stash usage:
Lemma 2. The stash usage u(G(RL(Z)[s])) in post-processed
∞-ORAM is > R if and only if there exists a subtree T in
RL(Z) such that u(RL(Z)[s]; T ) > n(T )Z + R.
Proof: For a stash of size R, since post-processing can at
most store n(T )Z real blocks in T in server storage, we may
interpret n(T )Z +R as the capacity of T . Clearly, if the usage
of T is more than the capacity of T , then post-processing
leads to a stash usage of > R.
Suppose that u(G(RL(Z)[s])) > R. Deﬁne T as the union
of all paths from the root to a bucket b for which the buckets
along the path in G(RL(Z)[s]) each have Z real blocks stored
in server storage. Then, u(G(RL(Z)[s]); T ) > n(T )Z + R.
Also, if a real block in T or in the stash originated from
a bucket b, then the Greedy approach of post-processing
implies that the buckets on the path from where the block is
stored in T to bucket b each store Z real blocks, therefore,
b ∈ T . This shows that u(RL(Z)[s]; T ) ≥ u(G(RL(Z)[s]); T ),
which ﬁnishes the proof of the lemma.
306Let a be a sequence of block addresses. As a corollary to
Lemmas 1 and 2, we obtain
P rob(u(TL(Z)[s]) > R|a(s) = a)
= P rob(u(G(RL(Z)[s])) > R|a(s) = a)
= P rob(∃T u(RL(Z)[s]; T ) > n(T )Z + R|a(s) = a)
P rob(u(RL(Z)[s]; T ) > n(T )Z + R|a(s) = a),
≤ (cid:88)
T
where the inequality follows from the union bound. The
probabilities are over the coin ﬂips that determines s given
a(s) = a.
to the Catalan number Cn, which is ≤ 4n,
Since the number of ordered binary trees of size n is equal
P rob(u(TL(Z)[s]) > R|a(s) = a) ≤
(1)
P rob(u(RL(Z)[s]; T ) > nZ + R|a(s) = a).
4n max
T :n(T )=n
(cid:88)
n≥1
6.3 Chernoff Bound
We will upper bound the probability in the sum of the right-