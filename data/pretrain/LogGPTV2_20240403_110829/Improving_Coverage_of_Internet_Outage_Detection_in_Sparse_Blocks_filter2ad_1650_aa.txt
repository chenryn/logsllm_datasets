title:Improving Coverage of Internet Outage Detection in Sparse Blocks
author:Guillermo Baltra and
John S. Heidemann
Improving Coverage of Internet Outage
Detection in Sparse Blocks
Guillermo Baltra1,2(B) and John Heidemann1,2
1 University of Southern California, Los Angeles, CA 90089, USA
2 Information Sciences Institute, Marina del Rey, CA 90292, USA
{baltra,johnh}@isi.edu
Abstract. There is a growing interest in carefully observing the relia-
bility of the Internet’s edge. Outage information can inform our under-
standing of Internet reliability and planning, and it can help guide oper-
ations. Active outage detection methods provide results for more than
3M blocks, and passive methods more than 2M, but both are challenged
by sparse blocks where few addresses respond or send traﬃc. We propose
a new Full Block Scanning (FBS) algorithm to improve coverage for
active scanning by providing reliable results for sparse blocks by gath-
ering more information before making a decision. FBS identiﬁes sparse
blocks and takes additional time before making decisions about their
outages, thereby addressing previous concerns about false outages while
preserving strict limits on probe rates. We show that FBS can improve
coverage by correcting 1.2M blocks that would otherwise be too sparse to
correctly report, and potentially adding 1.7M additional blocks. FBS can
be applied retroactively to existing datasets to improve prior coverage
and accuracy.
1 Introduction
Internet reliability is of concern to all Internet users, and improving reliability is
the goal of industry and governments. Yet government intervention, operational
misconﬁguration, natural disasters, and even regular weather all cause network
outages that aﬀect many. The challenge of measuring outages has prompted a
number of approaches, including active measurements of weather-related behav-
ior [15], passive observation of government interference [4], active measurement of
most of the IPv4 Internet [12], passive observation from distributed probes [16],
analysis of CDN traﬃc [14], and statistical modeling of background radiation [6].
Broad coverage is an important goal of outage detection systems. Since out-
ages are rare, it is important to look everywhere. Active detection systems report
coverage for more than 3M /24 blocks [12], and passive systems using CDN
data report coverage for more than 2M blocks [14]. More specialized systems
focus coverage on areas with bad weather (ThunderPing [15]), or provide broad,
country-level or regional coverage, but perhaps without /24-level granularity
inside the regions (CAIDA darknet outage analysis [4] and Chocolatine [6]).
Although each of the systems provide broad coverage, each recognizes there are
c(cid:2) Springer Nature Switzerland AG 2020
A. Sperotto et al. (Eds.): PAM 2020, LNCS 12048, pp. 19–36, 2020.
https://doi.org/10.1007/978-3-030-44081-7_2
20
G. Baltra and J. Heidemann
Table 1. Coverage comparison in /24 blocks of diﬀerent measuring approaches.
Approach
Coverage
UCSD-NT
Darknet
3.2M observed [3]
Akamai
Passive/CDN
5.1M observed/2.3M trackable [14]
ThunderPing Active/addrs
10.8M US IP addresses [11]
Disco
TCP disconnections 10.5k [16]
Trinocular
Active/blocks
5.9M responsive/3.4M trackable [12]
portions of the Internet that it cannot measure because the signal it measures
is not strong enough. Systems typically detect and ignore areas where they have
insuﬃcient signal (in Trinocular, blocks with fewer than 15 addresses; in Thun-
derPing, events with fewer than 100 addresses in its region; the Akamai/MIT
system, blocks fewer than 40 active addresses; in Chocolatine, blocks with fewer
than 20 active IPs). Setting thresholds too high reduces coverage, yet setting
them too low risks false outages from misinterpreting a weak signal.
The ﬁrst contribution of our paper is two new algorithms: Full Block Scanning
(FBS), to improve coverage in outage detection with active probing, while retain-
ing accuracy and limits on probing rates (Sect. 3.1), and Lone-Address-Block
Recovery (LABR), to increase coverage by providing partial results blocks with
very few active addresses (Sect. 3.2). Our insight is to recognize that sparse blocks
signal outages more weakly than other blocks, and so they require more infor-
mation to make a decision. We chose to delay decisions until all block addresses
(the full block) have been observed, thus gathering more information while main-
taining limits on the probing rate. (An alternative we decline is to probe more
aggressively.) We evaluate FBS as an extension to Trinocular Sect. 4.2, but the
concept may apply to other outage detection systems.
Our second contribution is to show that FBS can increase coverage in two
ways (Sect. 4.5). First, it correctly handles 1.2M blocks that would otherwise be
too sparse to correctly report. Second, it allows addition of 1.7M sparse blocks
that were previously excluded as unmeasurable. Together, coverage for 2017q4
can be 5.7M blocks. Moreover, FBS improves accuracy by reducing the number of
false outage events seen in sparse blocks (Sect. 4.1). We conﬁrm that it addresses
most previously reported false outage events (Sect. 4.3).
The cost of FBS is reduced temporal precision, since it takes more time to
gather more information (assuming we hold the probe rate ﬁxed). We show that
this cost is limited (Sect. 4.4): FBS is required for about one-ﬁfth of blocks (only
sparse blocks, about 22% of all blocks). Timing for non-sparse majority of blocks
is unaﬀected, and 74% of recovered uptime for sparse blocks is within 22 min.
About 40% of accepted outages in sparse blocks are reported within 33 min, and
nearly all within 3.3 h. (Reanalysis of old data shows the same results for non-
sparse and recovered uptime, but requires twice the time for accepted outages.)
Finally, we examine false uptime by testing against a series of known outages
that aﬀected Iraq in February 2017.
Improving Coverage of Internet Outage Detection in Sparse Blocks
21
All of the datasets used in this paper that we created are available at no
cost [17]. Our work was IRB reviewed and identiﬁed as non-human subjects
research (USC IRB IIR00001648).
2 Challenges to Broad Coverage
Our goal is to detect Internet outages with broad coverage. Table 1 shows cov-
erage of several methods that have been published, showing that active probing
methods like Trinocular provide results for about 3.4M /24 blocks [12] and CDN-
based passive methods provide good but somewhat less coverage (2.3M blocks for
the Akamai/MIT system [14]). Passive methods with network telescopes provide
very broad coverage (3.2M blocks [3]), but less spatial precision (for example,
for entire countries, but not individual blocks in that country). Combinations
of methods will provide better coverage: Trinocular and the Akamai/MIT sys-
tem have a 1.6M blocks overlap, and unique contributions, each providing 1.9M
unique 0.7M, from [14]. However, Akamai/MIT data is not publicly available.
Here we examine how to improve coverage of active probing systems like
Trinocular. Trinocular gets results for 3.4M blocks, and another 2.5M blocks
have some response but are not considered “trackable” since they have too few
reliably responding addresses.
Our goal in this paper is to expand coverage by making these previously
untrackable blocks trackable. We face two problems: sparse blocks and lone
addresses, each described below. In the next section we describe two new algo-
rithms to make these blocks trackable: Full Block Scanning (FBS), which retains
spatial precision and limited probing rates, but loses some temporal precision;
and Lone Address Block Recovery (LABR), an approach that allows conﬁrma-
tion that lone-address blocks are up, although it cannot deﬁnitively identify
when they are down.
Other active probing systems that follow the Trinocular algorithms (such as
the active part of IODA [1]) might beneﬁt from solutions to these problems.
We seek algorithms that can reevaluate existing years of Trinocular data, so we
follow Trinocular’s use of IPv4 /24-preﬁx blocks and 11-min rounds.
2.1 Problem: Sparse Blocks
Sparse blocks limit coverage: active scanning requires responses, so we decline
to measure blocks with long-term sparsity, and we see a large number of false
outages in blocks that are not sparse long-term, but often are temporarily sparse.
Sparse blocks challenge accuracy because of a tension between the amount of
probing and likelihood of getting a response. To constrain traﬃc to each block,
and to track millions of blocks, Trinocular limits each block to 15 probes per
round. Limited probing can cause false outages in two ways: First, it may fail
to reach a deﬁnitive belief and mark the block as unknown. Alternatively, if the
block is usually responsive, a few non-responses may produce a down belief.
22
G. Baltra and J. Heidemann
Fig. 1. A sample block over time (columns). The bottom (d) shows individual address
as rows, with colored dots when the address responds to Trinocular. Bar (c) shows
Trinocular status (up, unknown, and down), bar (b) is Full Block Scanning, and the
top bar (a), Lone Address Block Recovery. (Color ﬁgure online)
As an example, Fig. 1 shows four diﬀerent levels of sparsity, (each starting
2017-10-06, 2017-10-27, 2017-11-14 and 2017-12-16) as (d) individual address
responses to Trinocular probes, and (c) Trinocular state inferences. As the block
gets denser, Trinocular improves its inference correctness.
Furthermore, every address in this block has responded in the past. But for
the ﬁrst three periods, only a few are actually used, making the block temporarily
sparse. For precision, we use deﬁnitions from [12]: E(b) are the addresses in
block b that have ever responded, and A(E(b)) is the long-term probability that
these addresses will respond. We also consider a short-term estimate, ˆA(E(b)).
Thus problematic blocks have low A(E(b)) or ˆA(E(b)). We provide further block
examples in Appendix A.
Prior systems sought to ﬁlter out these sparse blocks, both before and
after measurement. Trinocular marks very sparse blocks as untrackable (when
A(E(b)) < 0.10 or |E(b)| < 15). It also marked blocks as untrackable when
observed A doesn’t match predicted A [12], and later used an adaptive estimate
for A [13]. Trinocular notes that its unmeasurability test is not strict enough:
indeterminate belief can occur when the A(E(b)) < 0.3 and |E(b)| ≥ 15. Accord-
ingly, Richter’s use of Trinocular data dropped all blocks with 5 or more outages
in 3 months [14], based on our recommendation.
We consider blocks sparse when it is less than a threshold ( ˆAs(E(b)) <
Tsparse), where ˆAs(E(b) is a short-term estimate of the current availability of
Improving Coverage of Internet Outage Detection in Sparse Blocks
23
the block, and Tsparse is a threshold, currently 0.2. Blocks have frequent outages
(like Fig. 1) when they are sparse. We ﬁnd that 80% of blocks with 10 or more
down events are sparse, and yet sparse blocks represent only 22% of all blocks
(see CDFs in Appendix B).
2.2 Problem: Lone Addresses
The second challenge to coverage are blocks where only one or two addresses are
active—we call this problem lone address blocks. When a single address is active,
then lack of a response may be a network outage, but it may also be a reboot of a
single speciﬁc computer or other causes—the implication of non-response from a
single address is ambiguous. Trinocular has avoided blocks with few addresses as
untrackable (when |E(b)| < 15). ThunderPing [15] tracks individual addresses,
but recognizing the risk of decisions on single addresses, they typically probe
multiple targets per weather event [11].
An example block with a lone-address is in Fig. 1. Of the four phases of
use, the second phase, starting 2017-10-27, and for 18 days, only the .85 address
replies. Our goal is to handle this block correctly in both of its active states,
with many addresses and with a lone address.
3 Improving Outage Detection
3.1 Full Block Scanning for Sparse Blocks
The challenge of evaluating sparse blocks is that Trinocular makes decisions
on too little information, forcing a decision after 15 probes, each Trinocular
Round (TR, 11 min), even without reaching a deﬁnitive belief. We address this
problem with more information: we consider a Full Round (FR), combining
multiple TRs until all active addresses (all of E(b)) have been scanned. This
Full Block Scanning algorithm makes decisions only on complete information,
while retaining the promise of limiting scanning rate.
that cover all E(b) ever-active addresses of the block:
Formally, a Full Round ends at time t when the minimum N TRs before t
(cid:2)t
i=t−N (|T Ri|) ≥ |E(b)|.
Trinocular probes all addresses in E(b) in a pseudo-random sequence that is
ﬁxed once per quarter, so we can guarantee each address is probed when we count
enough addresses across sequential TRs. (Versions of Trinocular prior to 2020q1
reverse direction at end of sequence, reanalysis of data before this time must
sense 2|E(b)| addresses to guarantee observing each. We call this retrospective
version the 2FR version of FBS, and will use 1FR FBS for new data. They diﬀer
in temporal precision, see Sect. 4.4.)
Full Block Scanning (FBS) layers over Trinocular outage detection, re-
evaluating outages it reports and reverting some decisions. If the block is cur-
rently sparse ( ˆAs < Tsparse) and the most recent Full Round included a pos-
itive response, then we override the outage. That is, if there are any posi-
tive responses in the last Full Round F Rt, we convert any outages to up if
∀T Ri where i ∈ [t − N, t].
24
G. Baltra and J. Heidemann
s
The cost of FBS is that combining multiple TRs loses temporal precision, so
we use FBS only when it is required: for blocks that are currently sparse. A block
is currently sparse if the short-term running average of the response rate for the
block ˆA3F R
, computed over the last three F Rs, is below the sparse threshold
< Tsparse). (We choose three FRs to smooth ˆA from multiple estimates.)
( ˆA3F R
s
The reduction in temporal precision depends on how many addresses are
scanned in each TR and the size of FR (that is, E(b)). When FBS veriﬁes an
outage, we know the block was up at the last positive response, and we know
it is down after the full round of non-responses, so an outage could have begun
any time in between. We therefore select a start time as the time of the last
conﬁrmed down event (the ﬁrst known lit address, now down). That time has
uncertainty of the diﬀerence between the earliest possible start time and the
conﬁrmed start time. Theoretically, if all 256 addresses in a block are in use and
15 addresses are scanned each TR, a FR lasts 187 min. In practice, timing is
often better; we show empirical results in Sect. 4.4.
3.2 Lone-Address-Block Recovery
The FBS algorithm repairs any block with at least one responsive address in the
last FR, allowing us to extend coverage to many sparse blocks. However, when
a block has only a single active address, a non-reply may indicate an outage of
the network or a problem with that single host.
To avoid false down events resulting from non-outage problems with a lone
address, we deﬁne Lone-Address-Block Recovery (LABR). We accept up events,
but because outages are rare (much rarer than packet loss), we convert down
events to “unknown” for blocks with very few recently active addresses. We