# OCR Output
## Page 1
(C)1994-26295Bin器,类组糖否信息热术有限仓即而程距b低究流向为数据分析ri体齐通认作者:阮院书:9/ww.cnki.net 
作者简介:阮晓龙(1983-),男,CCF会员,河南中医药大学信息技术学院副教授,研究方向为互联网应用技术、网络测量;贺路路
收稿日期：2019-10-10
来越复杂,对实时性的要求越来越高[-]。针对传统日志分
0引言
志数据越来越多,日志处理工作量越来越大,处理方法越
故障排错、性能分析的重要途径。数据中心每天产生的I
运维的基础是海量日志数据分析，日志分析是日常运维
分析,从数据中找规律、找价值是智慧运维的核心。智慧
是运维发展的必然趋势。对数据中心海量运行数据进行
Key Words ELK; Kafka; log analysis ;big data ; streaming data
cessing.
Dd ep u s prp jo si Au saoe pue uuu e uado jo ssd  u ueznsia  pue hissnd so
and display the log data. The intelligent operation and maintenance data platform based on ELK solves the problems of log acquisition
regular expression is used to split the log data, and the split fields are stored in elastic search. Finally, Kibana is used to search, plot
sh ro nd r a un a u sn as pe anssad as ne e sod h pe 
Abstract: Intelligent operations and maintenance data analysis platform based on ELK is used to analyze the massive running data of
 Research and Implementation of Intelligent Operation and Data Big Data Analysis
第19卷第6期
让运维更智能、更高效是运维的首要需求,智慧运维
2020年6月
(1.河南中医药大学信息技术学院,河南郑州 450046;2.郑州祺石信息技术有限公司,河南郑州 450001)
中图分类号：TP319
DOI:10. 11907/rjdk. 192248
关键词:ELK;Kafka;日志分析;大数据;流式数据
问题,同时在数据处理上实现了接近1s的延迟搜索。
搜索、绘图和展示。使用基于ELK的智慧运维大数据平台解决了运维过程中日志采集、日志处理、日志可视化
利用正则表达式实现日志数据拆分,将拆分后的字段在Elasticsearch中存储,最终利用Kibana 对日志数据进行
摘要:基于ELK在智慧运维大数据分析平台实现海量数据分析,对ELK的部署结构进行优化,并在日志采集
基于ELK+Kafka的智慧运维大数据分析
(1. School of Information Technology,Henan University of Chinese Medicine, Zhenzhou 450046,China;
2. Zhengzhou Qishi Information Technology Co., Ltd.,Zhenzhou 450001, China）
Platform Based on ELK+Kafka
文献标识码:A
平台研究与实现
RUAN Xiao-long' ,HE Lu-lu²
阮晓龙',贺路路2
Software Guide
软件导刊
日
检索和展示的智慧运维大数据分析平台部署。
文基于 ELK Stack 技术,实现了对海量日志进行实时采集
数据可视化分析平台 Kibana 3 个开源软件的组合[1-1]。
及实现日志实时分析,使可视化展示分析成为可能。ELK
运维人员从 TB 甚至 PB 级的日志中获取所需关注的信息
领域出现了以 ELK Stack 为代表的实时日志分析平台[7-l
问题逐渐凸显。
析方法而言,日志获取难、分析耗时耗力、不易动态扩展等
文章编号：1672-7800(2020)006-0150-05
 随着分析技术及搜索技术的成熟与发展,在日志处理
Vol. 19 No. 6
Jun. 2020
本
---
## Page 2
P942020 China Academic Journal Electronic Publishing 
46112 0.075
进行调试,获取目标字段。
后期分析的重要指标;③利用 Grok Debugger 对编写的正
日志文本时一般按以下步骤进行解析：①对将要进行分
其它Web 服务日志
stash 的一个正则
过 Filter 实时解析和数据处理后通过 Output 进行输出。
集。采集的日志数据流通过 Logstash 中的 Input 流
Web 应用、数据存储以及各种AWS服务的日志数据
Logstash 支持各种输入选择,可以在同一时间从众多来源
获取数据,并对数据进行处理后发送到 Elasticsearch 服多
据收集引擎,具有实时管道功能,可以同时从多个数据
ticsearch 中的数据进行搜索、分析以及可视化展示。
工具,集成了 DSL 命令行、数据处理等插件,可以对 Elas-
系统,负责存储和搜索日志。Kibana 是大数据图形化展矛
输出至 Elasticsearch。Elasticsearch 是 ELK Stack 中的核
Stack 架构中,Logstash 或 Beats 作为日志采集器分布于
[0-9］+）\s +(?[0-9］+）\s +(?
(?[A-Z]+)\s+(?[VA-Za-z0-9\.]+)\s+(?
确
的
式,且其内置超过 120 种常用正则表达式。利用 Grok 处
捕捉事件,能够以连续的流式传输方式,实现日志、指
器中。
1.2
业务系统进行日志采集,将日志文本按照既定规则解析月
个完整的日志分析系统必不可少的组成部分。在EL
1.1
一
第6期
定利用 Grok 要将一条日志分为多少个字段,拆分字段是
日志进行解读,理解日志中每一个字段代表的含义
(?[0-9).]+)\s+(?[0-9}-]+\s[0-9\: ］+)\s+
根据日志字段含义,通过Grok 编写规则如下。
10.10.3.229 2019-08-05 16: 30: 58 GET /var/www/html 200
Logstash 拥不
 业务数据往往以各种各样的形式分散在不同系统中
日志采集是日志分析的基础,Logstash 是一个开源娄
ELK Stack 架构如图1 所示。
 数据采集、数据处理、数据存储、数据可视化展示是-
平台整体架
基于 ELK 智慧运维大数据分析平台
例如一条访问日志信息如下：
日志数据实时收集
有丰富的 Filter 插件,例如 Grok 是
志、MySQL 日志以及人为定义的日
表达式插件,用于处理 Syslog、Apache 
构
图1ELK Stack 架构
 Logstash
Elasticsearch
Kibana
阮晓龙,贺路路:基于ELK+Kafka 的智慧运维大数据分析平台研究与实现
Beats
--------
义
志
人，
分
Log
于
标
是
?
析
格
和
经
采
务
源
理
示
心
后
各
Hol
 Schema(定义表结构和设定字段类
型数据库 MySQL 进行对比如表 2 所示。
求
Rebalance 等操作,但不负责数据的索引和检索，一般负
心,可以集中存储数据。
较
较
角
PB
轻
务
服
16]
个成员,如表1所示。
不同的日志使用不同的采集器,目前 Beats 系列包含以下 7
E
.3
的分发、
大,对机器配置要求较高。
轻。数据节点负责集群中数据的索引和检索，一般压
色。主节只
服务器自身压力,并由 Logstash 进行数据处理。
系统部
务器的影响可忽略不计。
,在集群中节点
,因而占用的 CPU 和内存比 Logstash 少得多,其对业
Functionbeat
Heartbeat
Winlogbeal
采集器名和
UPDATE *FROM table:
SELECT * FROM table ..
为了更好地理解 Elasticsearch,将 Elasticsearch 与关系
Elasticsearch 在生产环境中一般以集群的形式存有
Elasticsearch 为
相比 Logstash,Beats 只负责采集数据而不处理数
Auditbeat
Packetbea
Metricbeat
日志数据存价
Filebeat
Beats 是 ELK Stack 的一系列数据采集器的总称,对于
拆分日志后的内容及格式如下：
至
"Url" : "/var/www/html"
"Method": "GET",
"User_ip":"10.10.3.229""
"Request_time" : "0.075",
"Request_send": "46112"
"Status":"200"
Column（列,属性）
Database(数据库）
更高娄
Index(索引）
表2
发、汇总等,增加客户端节点更多是为了负载均衡。
Table(表)
Row(行)
称
MySQL
2Elasticsearch 与关系型数据库 MySQL 对比
点负责集群中索引的创建、删除以及数
数量
监控用户的行为和系统进程,分析用户事件数据
轻量型网络数据包分析器,用于分析应用层协议
轻量型日志采集器，用于转发和汇总日志与文件
分
级
分为主节点、数据节点、客户端节点3禾
用于收集系统和服务指标。
的搜索引擎工具,作为 EIK Stack 的
开源、分布式、基于 Restful API、支
用于运行状态监测的轻量型采集器
表 1Beats 家族
6:
用于云端数据的无服务器采集器
。在实际应用环境中,推荐在
Mapping（如何建立索引、索引类型
，客户端节点负责来自不同
功能
Everything is indexed
PUThup:l
GET http://
Type(类型）
Query DSL
Index(索引）
Elasticsearch
等）
Field
例如CPU、内存
·151·
据
系
请
力
的
种
在
核
持
减
亦
务
拆
---
## Page 3
其命令如下：
下命令进行 JDK 压缩包解压,并将解压的目录重新命名，
2.1.1Java 环境安装
后开启相应端口。
部署时关闭 CentOS 7的防火墙以及 SELinux,待部署完成
org/downloads（推荐使用 bin 格式且为 Scala 2.12）。建议
Kafka 最新版本为 2.3.0,下载地址为 http://kafka.apache.
keeper/zookeeper-3.5.5/( 推荐使用 bin 格式的压缩包
为3.5.5，下载地址为https://www-us.apache.org/dist/zo0-
loads/jdk12-downloads-5295953.html。ZooKeeper 最新版
址
ZooKeeper 和 Kafka。目前 JDK 最新版本为 12.0.2,下载
2.1
2
用图表、表格及地图对数据进行多元化分析和呈现。
可以对 Elasticsearch 索引中的数据进行搜索、查看,同时利
台[18] ,它是 ElK Stack 成员之一,用作与 Elasticsearch 交互,
与沟通信息。Kibana 是一款开源的数据分析和可视化平
1.4日志数据可视化
为 https://www.oracle.com/technetwork/java/javase/down-
·152·
将 JDK 安装包上传到CentOS 7 相应目录下。通过如
 部署kafka 集群需要 3 个基础软件,分别为 Java 环境、
台部署
基
数据可视化主要借助于图形化手段,清晰有效地传达
Kafka 集群部署
ELK Stack 在实际生产环境中通常以集群的方式部
基于 ELK+Kafka的智慧运维大数据分析平
10.10.2.229
10.10.2.228
10.10.2.227
10.10.2.226
10.10.2.225
10.10.2.224
10.10.2.223
10.10.2.222
10.10.2.221
10.10.2.220
IP地址
Windos件集器
（运行状泰采集部用）
（安麦采集器文件）
核心
Heartbea
Auditbe
WinlogBe
Metricbet
Filebeat
8GB
内存
20GB+5TB
20GB+5TB
20GB+5TB
20GB+5TB
200GB
200GB
200GB
200GB
100GB
100GB
硬盘
图2ELK Stack部署架构
表2 服务器角色
软件导刊
成
在
本
地
操作系统
平
CentOS
CentOS
CentOS
CentOS
CentOS
CentOS 7
CentOS 7
CentOS 7
CentOS 7
CentOS 7
HoutaAThskeprki.net
中
录重新命名,其命令如下所示：
通
2.1.2
后的内容生效,命令如下：
VA_HOME/lib/dt.jar : $JAVA_HOME/ib/tools.jar
L
划
构使用10台服务器,拓扑结构如图2 所示。服务器功能
日志在处理前丢失。
防
消
据
的调优,同时包含数据采集、数据处理过程调优,因此在娄