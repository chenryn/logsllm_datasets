2. The first pool is copied to the next generation untouched.  Thus elitism is also 
operating at the pool level  
3. Randomly pick two parents and perform single point crossover.  The crossover 
point in a pool is the location that separates one set of sessions from another. 70% 
of the time we use only the top half of the sorted list to pick parents from.  30% of 
the time we chose from the entire list of pools.  
4. Create A’ from (A x B): 
5. Start in A.  Copy all of the sessions from A into A’ up until the cross point.  In 
pool B, advance to the session after the cross point.  From there, copy the 
remaining sessions into A’. 
6. If we have enough pools stop.  Else, 
7. Create B’ from (B x A) 
8. Start in B.  Copy all of the sessions from B into B’ up until the cross point.  In 
pool A, advance to the session after the cross point.  From there, copy the 
remaining sessions into B’. 
9. Repeat until our total number of pools (1st + new children) equals the number we 
started with. 
Pool Mutation 
As with session mutation, pool mutation does not modify the elite pool. The algorithm is 
(example in Figure 6): 
Figure 6: Pool Mutation 
1. 50% of time we add a session according to the new session initialization rules. 
2. 50% of the time we delete a session. 
3. If the sessions/pool are fixed, we do both. 
4. In all cases, we don’t disturb the first session. 
Running EFS 
From a high level, the protocol between EFS-GPF and EFS-PaiMei is as follows: 
GPF initialization/setup data  PaiMei 
Ready  PaiMei 
GPF {OK|ERR}  PaiMei 
When all of the sessions for a given generation have been played GPF contacts the 
database, calculates a fitness for each session (counts hits) and for each pool (distinct hits 
for all sessions within a pool), and breeds sessions and pools as indicated by the 
configuration options (See the description of Figure 8). 
Figures 7 and 8 show the EFS-GPF and EFS-PaiMei portions of EFS in action.  For the 
GUI portion we see: 
1. Two methods to choose an executable to stalk: 
a. The first is from a list of process identifications (PIDs).  Click the 
“Refresh Process List” to show running processes.  Click the process you 
wish to stalk. 
b. The second is by specifying the path to the executable with arguments.  
An example would be: “c:\textserver.exe” med 
2. We can choose to stalk functions (funcs) or basic blocks (BBs). 
3. The time to wait for each target process load defaults to 6 seconds, but could be 
much less (1 second) in many cases. 
4. Hits can be stored to the GPF or PaiMei sub-databases that are in the Mysql 
database.  PaiMei should be used for tests or creating filter tags, while GPF 
should be used for all EFS runs. 
5. After each session, or stalk, we can do nothing, detach from the process (and 
reattach for the next stalk), or terminate the process.  The same options are 
available if the process crashes.  
6. Use the PIDA Modules box for loading the .pida files.  These are derived from 
executables or dynamically linked libraries (.DLLs), and are used to set the 
breakpoints which enable the process stalking to occur.  One executable needs to 
be specified and as many .DLLs as desired.  (Note: Sometimes processes will 
include files called .api, .apl, etc which are really .DLLs and can be used here as 
well.) 
7. There is a dialog box under Connections to connect to the Mysql database.  
Proper installation and setup of EFS-PaiMei (database, etc.) is included in a 
document in the EFS source tree. 
8. The Data Sources box is the place to view target lists and to create filter tags.  
This is done to speed up EFS, by weeding out hits that are common to every 
session.  The process to create a filter tag is: 
a. Define a filter tag. (We called ours  
“ApplictionName_startup_conn_junk_disconn_shutdown”) 
b. Stalk with that tag and record to the PaiMei database 
c. Start the target application 
d. Using netcat, connect to the target application 
e. Send a few random characters 
f. Disconnect 
g. Shutdown the target application 
9. There is another dialog box that defines the GPF connection to EFS-PaiMei called 
Fuzzer Connect.   
a. The default port is 31338 (if you don’t get why that number, ask a hax0r).   
b. The general wait time describes how long each session has to complete 
before EFS will move on to the next session.  This is needed to coordinate 
the hit dumping to mysql after each session.  The default is .8 but for lean 
applications running around .2 should be fine.  For larger applications 
more time will be required for each session.  Tuning this number is the 
key to the speed that EFS will run at.  (For example: .4*100000=11hrs, 
.8*100000=22hrs, 1.6*100000=44hrs, etc) 
c. The “dump directory” defines a place for EFS to dump crash information 
should a robustness issue be found.  We typically create a directory of the 
structure “..\EFS_crash_data\application_name\number”.   
d. The number should coordinate to the GPF_ID for clarity and organization. 
Figure 7: The GUI portion of EFS 
For the GPF (command line) portion of EFS we have 32 options: 
1. –E indicates GPF is in the evolving mode.  GPF has other general purpose fuzzing 
modes which will not be detailed here. 
2. IP of Mysql db 
3. Username of Mysql db 
4. password for Mysql db 
5. GPF_ID 
6. Starting generation.  If a number other than zero is specified, a run is picked up 
where it left off.  This is helpful if EFS where to crash, hang, or quit. 
7. IP of GUI EFS 
8. Port of GUI EFS 
9. Stalk type.  Functions or basic blocks. 
10. Play mode.  Client indicates we connect to the target and server is the opposite. 
11. IP of target.  (Also IP of proxy in proxy mode.) 
12. Port of target. (Also port of proxy in proxy mode.) 
13. Source port to use. ‘?’ lets the OS choose. 
14. Protocol.  TCP or UDP 
15. Delay time in milliseconds between each leg of a session. 
16. Number of .01 seconds slots to wait while attempting to read data. 
17. Output verbosity. Low, med, or high. 
18. Output mode. Hex, ASCII, or auto. 
19. Number of pools. 
20. Number of sessions/pool. 
21. Is the number fixed or a max?  Fixed indicates it must be that number while max 
allows any number under that to valid as well. 
22. Legs/session 
23. Fixed or max 
24. Tokens/leg 
25. Fixed or max 
26. Total generations to run 
27. Generation at which to perform session mutation 
28. Generation at which to perform pool crossover 
29. Generation at which to perform pool mutation 
30. User definable function on outgoing sessions.  None indicates there isn’t one. 
31. Seed file name. 
32. Proxy mode.  Yes or no.  A proxy can be developed to all EFS to run against none 
network protocols such as internal RPC API calls, etc. 
33. (UPDATE: A 33rd was just added to control diversity.) 
Figure 8: The GPF UNIX command line portion of EFS 
Benchmarking 
The work in this section has become intense enough to warrant a whole new paper.  See 
Benchmarking Grey-box Robustness Testing Tools with an Analysis of the Evolutionary 
Fuzzing System (EFS) [15].  The topics in that paper include: 
• Attack surface example 
• Functions vs. basic blocks. 
• Learning a binary protocol 
• Pools vs. niching 
o EFS Fitness function updates to achieve greater diversity 
Test Case – Golden FTP server 
The first test target was the Golden FTP server (GFTP) [9]. It is a public domain ftp 
server GUI application for Windows that has been available since 2004. Analysis shows 
approximately 5100 functions in GFTP, of which about 1500 are concerned with the 
GUI/startup/shutdown/config file read/etc, leaving potentially 3500 functions available. 
However, the typical attack surface of a program is considerably smaller, often around 
10%.  We show more evidence of this in the benchmarking research. 
Three sets of experiments were run.  Each experiment was run 3 times on two separate 
machines (6 total runs/experiment).  The reason for two machines was two fold: time 
savings, as each complete run can take about 6hrs/100generations, and to be sure 
configurations issues were not present on any one machine.  Experiment 1 is 1 pool of 
100 sessions. Experiment 2, 4 pools each with 25 sessions. Experiment 3, 10 pools each 
with 10 sessions. All other parameters remain the same: target was Golden Ftp Server 
v1.92, 10 legs/session, 10 tokens/leg, 100 total generations, session mutation every 7 
generations, for multiple pool runs—pool crossover every 5 generations, and pool 
mutation every 9 generations.  For these experiments we used function hits as the code 
coverage metric.  The session, leg, and token sizes are fixed values. 
Results 
Figure 9 shows the average fitness for both pool and session runs, averaged over all the 
runs for each group. Figure 10 shows the best fitness for both pool and session, selected 
from the “best” run (that is, the best session of all the runs in the group, and the best pool 
of all the runs in the group). The first thing that Figure 9 shows us is that pools are more 
effective at covering code than any single session. Even the worst pool (1-pool) covers 
more code than the best session. Roughly speaking, the best pool covers around twice as 
much as the best session. The second observation that Figure 9 shows us is that multiple, 
interacting pools are more effective than a single large pool. Note that this is not just a 
conclusion about island-parallel evolutionary computation [11], since the interaction 
between pools is more frequent and of a very different nature than the occasional 
exchange of a small number of individuals as found in island parallelism. The pool 
interaction is more in line with a second-order evolutionary process, since we are 
evolving not only at the session level, but also at the pool level. While pool-1 starts out 
with better coverage, it converges to less and less coverage. Both 4-pool and 10-pool start 
out with less coverage, but have a positive fitness trajectory on average, and 4-pool 
nearly equals the original 1-pool performance by around generation 180 and appears to 
still be progressing. 
Figure 10 shows that, selecting for the best pool/session from all the runs (not the 
averages as in Figure 5), 4-pool does slightly outperform other approaches. That is, the 
best 4-pool run outperformed any other best pool, and greatly outperformed any best 
session.  
The information provided by Figures 11, 12, and 13 shows the following: First, they 
show the total number of crashes that occurred across all runs for 1-pool, 4-pool, and 10-
pool.  The numbers around the outside of the pie chart are the actual number of crashes 
that occurred for that piece, while the size of each pie chart piece indicates that crash’s 
relative frequency with respect to all crashes encountered.  Furthermore, the colors of 
each piece reflect the addresses in gftp.exe where the crashes occurred. Remember that 
the only measure of fitness that EFS uses is the amount of code covered, not the crashes. 
However, these crash numbers provide a kind of history of the breadth of search each 
experiment has developed. For example, all 3 experiments crashed predominantly at 
address 0x7C80CF60. However, 10-pool found a number of addresses that neither of the 
others did, for example the other 0x7C addresses. 
GFTP is an interesting (and obviously buggy) application.  In creates a new thread for 
each connection, and even if that thread crashes can keep processing the current session 
in a new thread.  This allows for multiple crashes/session, something that was not 
originally considered.  This accounts for the thousands of crashes observed.  Also, keep 
in mind these tests are done in a lab environment, not on productions systems.  Nothing 
was affected by our crashes, or could have caused them.  These tests were done in 
January 2007, and no ongoing effort against GFTP is in place to note rather or not these 
bugs have been patched.  Also, no time was spent attempting to develop exploits from the 
recorded crash data.  It is the authors’ opinion that such exploits could be developed but 
we would rather focus on continued development and testing of EFS. 
Figure 9: Average Fitness of pool and session over 6 runs 
Figure 10: Best of Pool and Session over 6 Runs 
Figure 11: 1-pool Crash Total (all runs) 
Figure 12: 4-pool Crash Total (all runs) 
Figure 13: 10-pool Crash Total (all runs) 
Conclusions and Future Work 
We have shown that EFS was able to learn a protocol and find bugs in real software using 
a grey-box evolutionary robustness testing technique.  Continuing research: 
• What is the probability to find various bug types as this is the final goal of this 
research 
o How does its performance compare with existing fuzzing technologies? 
o What bugs can be found and in what software? 
• Could this type of learning be important to other fields? 
• Is it possible to cover the entire attack surface with our approach?  How would 
one know, since we don’t have the source code?   
o Pools don’t seem to have completely covered the target interface, is their a 
niching or speciation approach we can design ? 
• Testing of clear text protocols was done, but is it also possible to learn more 
complex binary protocols?   
References 
[1] 
McMinn, P. “Search-based Software Test Data Generation: A Survey”. Software 
Testing, Verification & Reliability, Vol 14, Num 2, pp 105-156, 2004 
[2] 
Roper, M. “Computer aided software testing using genetic algorithms”, in 10th 
International Software Quality Week, San Francisco, 1997  
[3] 
Watkins, A., “The automatic generation of test data using genetic algorithms”, in 
Proceedings of the Fourth Software Quality Conference, pp 300-309, 1995 
[4] 
B.P. Miller, L. Fredriksen, and B. So, "An Empirical Study of the Reliability of 
UNIX Utilities", Communications of the ACM 33, 12 (December 1990). See also 
http://www.cs.wisc.edu/~bart/fuzz/ 
[5] 
P. McMinn and M. Holcombe, “Evolutionary Testing Using an Extended 
Chaining Approach”, ACM Evolutionary Computation, Pgs 41-64, Volume 14,  
Issue 1  (March 2006) 
[6] 
Stefan Wappler, Joachim Wegener: Evolutionary unit testing of object-oriented 
software using strongly-typed genetic programming. GECCO 2006: 1925-1932 
[7] 
Goldberg, David E. Genetic Algorithms in Search, Optimization and Machine 
Learning Addison-Wesley Pub. Co. 1989. ISBN: 0201157675 
[8] 
http://www.appliedsec.com/resources.html 
[9] 
http://www.goldenftpserver.com/ 
[10] 
Pedram Amini, PaiMei Reverse Engineering Framework, 
http://pedram.redhive.com/PaiMei/ 
[11] 
Cantu-Paz, E. “Efficient and Accurate Parallel Genetic Algorithms”, Kluwer 
Academic Publishers, 2000 
[12] 
Pargas, Harrold, & Peck. “Test-Data Generation Using Genetic Algorithms”, 
Journal of Software Testing, Verification and Reliability, 1999. 
[13] 
Wegener, Sthamer, & Baresel. “Application Fields for Evolutionary Testing”, 
EuroSTAR, 2001. 
[14] 
A mailing list dedicated to the discussion of fuzzing. 
PI:EMAIL 
[15] 
J. DeMott, “Benchmarking Grey-box Robustness Testing Tools with an Analysis 
of the Evolutionary Fuzzing System (EFS)”, continuing PhD research