Acknowledged
Submitted
Submitted
Submitted
Submitted
Patched
Won’t Fix
Patched
Submitted
Acknowledged
Acknowledged
Patched
Submitted
Patched
Patched
Submitted
Patched
Patched
-
Macro expansion
-
Inter-proc / Pattern
Indirect call
Indirect call
-
-
Unknown pattern
Inter-procedural
Inter-procedural
-
Loop / Pattern
Inter-procedural
Unknown pattern
-
-
-
Loop involvement
Unknown pattern
-
-
Unknown pattern
Patching Strategy
Incremental copy
Value override
Abort on change
Single-fetch
-
Single-fetch
-
Value override
-
Single-fetch
-
Single-fetch
Override
Single-fetch
-
Value override
Value override
Value override
Value override
Abort on change
Single-fetch
-
Value override
Single-fetch
TABLE II: A listing of double-fetch bugs found and reported. In the complication column, we anticipate the reasons why the bug cannot be
found by prior works. For 18 bugs that we submit patches for, we also list the strategy we use to ﬁx the bugs, which is discussed in detail
in §X. For the remaining six bugs, the patching is likely to require a lot of code refactoring and we are working with the kernel maintainers
to ﬁnalize a solution.
For example, in the tls_setsockopt case (Figure 2), a mali-
cious user process can bypass the TLS version checking (line 9)
by exploiting this double-fetch behavior although the intention
of the kernel developers is to reject such requests.
Denial-of-service (DoS). This exploitation typically occurs
when a memory operation, e.g., buffer allocation, memory
compare, string operations, etc, is affected by the double-fetch
procedure. For example, in the case of smb_strdupin (Figure 6),
it is incorrect to assume that the string copied in after the second
fetch is NULL-terminated and later applying the strlen on
the string is likely to cause an overread into invalid kernel
memory regions.
DEADLINE does not attempt to automatically reason about
the exploitability of double-fetch bugs for two reasons: 1)
Unlike memory errors that raise a deﬁnitive signal upon
exploitation, e.g., an invalid memory access causing a crash,
double-fetch bug exploitations do not usually raise such a signal
and might have to rely on manually deﬁned rules to measure
whether the exploit succeeds. 2) Even if we could deﬁne all the
exploitation rules, constructing them could still be a challenge,
as the exploitation point is usually far from to the bug point. In
the example shown in Figure 6, the exploitation point strlen is
two function calls away from the buggy function. In this case,
in order to construct an end-to-end exploit, DEADLINE needs
to symbolically execute the whole ioctl syscall, which would
take signiﬁcantly longer if ever possible. More importantly,
even if a double-fetch bug is not exploitable right now, it does
not mean that it will remain secure in the future. Careless code
updates can easily turn a non-exploitable double-fetch bug into
an exploitable one, as shown in the case of CVE-2016-5728.
X. MITIGATION
Based on our experience in patch creation and our communi-
cations with kernel maintainers, there are in general four ways
to patch a double-fetch bug.
Override with values from the ﬁrst fetch.
In this case, we
simply ignore the value copied in during the second fetch and
override it with the value from the ﬁrst fetch. An example is
shown in Figure 8, which is actually the patch to Figure 4. By
doing so, we ensure that both the control dependence and data
dependence established between these fetches are preserved.
Abort if changes are detected.
In this case, we add a sanity
check after the second fetch to ensure that the intended relation
between the two fetches is honored by the user process, as
shown in the example of Figure 9, which is actually the patch
to Figure 7.
Incremental fetch.
In this case, we intentionally skip the
bytes copied in during the ﬁrst fetch. In other words, we start
the second fetch from an offset equal to the length of the ﬁrst
fetch. An example is shown in Figure 10. By doing this, these
two fetches are now from non-overlapped userspace memory
regions and will never constitute a double-fetch bug.
Refactor into a single-fetch.
If there is only control depen-
dence between the two fetches, we could reduce this double-
fetch behavior into a single-fetch, as shown in the example
in Figure 11. This approach generally improves the performance
as we eliminate one fetch but might result in more lines of
code, as now we need to multiplex the if checks every time a
fetch occurs.
671
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:39:58 UTC from IEEE Xplore.  Restrictions apply. 
In principle, all these strategies have the same effect—
preventing a double-fetch bug from being exploited. However,
which strategy is taken for a speciﬁc double-fetch bug is usually
based on case-by-case considerations such as performance
concerns, number of lines changed, accordance with existing
sanity checks, and the maintainers’ personal preferences.
Besides, several bugs cannot be patched within 50 lines of
change due to the complications in current codebases. We are
working with the maintainers to ﬁnalize the patch.
Preventing exploits with transactional memory. As the
root cause of a double-fetch bug is the lack of atomicity
and consistency in userspace memory accesses across fetches,
transactional memory (e.g., Intel TSX) can be a generic solution.
Conceptually, one could mark transaction start before the ﬁrst
fetch and mark transaction end after the second fetch. If a
race condition occurs, the transaction will abort and the kernel
will be notiﬁed. DECAF [23] is a proof-of-concept based on
these insights. However, it over-simpliﬁes the kernel code by
failing to consider the cases of 1) false aborts due to large
memory access footprint (which is very likely for multi-reads),
2) multiple exit points in the syscall execution (e.g., returning
before second fetch), and 3) mixing of TSX-enabled and non-
TSX code (e.g., a function can be called within or without
a transactional context). Furthermore, DECAF still requires
the developers to manually inspect and instrument kernel
code. Therefore, to make the TSX-based solution practical,
these technical challenges should be addressed and automated
integration of TSX APIs and kernel code is necessary.
XI. DISCUSSION AND LIMITATIONS
A. Applying DEADLINE beyond kernels
It is worth-noting that double-fetch bugs are not speciﬁc
to kernels. In theory, it might exist in software systems in
which 1) the memory region is separated into sub-regions with
various levels of privilege and 2) multi-threading is supported.
Therefore, software systems beyond kernels such as Xen, SGX,
and even userspace programs like the Chrome browser are also
subject to double-fetch bugs.
To apply DEADLINE to these software systems, we need to
clearly identify the boundary of privileges and the interfaces
for transferring data from a low-privilege memory region to
a high-privilege memory region. That is, DEADLINE requires
pre-deﬁned “fetching” interfaces. Fortunately, we observed that
privileged software systems typically have limited interfaces
for fetching data from low-privilege to high-privilege memory
regions. This is arguably to better maintain the boundary of
separated regions. As such, we believe that it is feasible to
collect “fetching” interfaces with reasonable engineering effort.
B. Limitations of DEADLINE
We discuss the limitations of DEADLINE from three aspects:
1) which part of kernel source code DEADLINE cannot cover,
2) what kind of execution paths DEADLINE cannot construct
for multi-reads, and 3) when the symbolic checking for double-
fetch bugs fails.
Source code coverage. Although DEADLINE covers a major-
ity of kernel codebase, there are two cases DEADLINE currently
cannot handle:
1) Files not compilable under LLVM cannot be analyzed by
DEADLINE. For Linux 4.13.2, they include three ﬁlesystem
ﬁles and four driver ﬁles, which are likely to contain both
multi-reads and double-fetch bugs. We believe this will not
be addressed soon with the synergy between the kernel and
LLVM community.
2) Although DEADLINE enables all the conﬁg options during
compilation, DEADLINE certainly misses the code pieces that
are compiled when a CONFIG_* should be disabled. However,
a complete solution would require tweaking Y and N for over
10000 conﬁg items, which is unrealistic.
Path construction. DEADLINE aims to ﬁnd all execution
paths associated with a multi-read. However, due to the
complexity in kernel code, DEADLINE’s path construction has
three limitations:
1) DEADLINE enforces a limit (currently 4096) to the number
of execution paths constructed within an enclosing function.
Although in most of the cases there are less than 100 paths,
we did observe 17 functions that exceed this limit. Therefore,
DEADLINE could have missed double-fetch bugs should they
exists in those unconstructed paths.
2) DEADLINE also enforces a limit (currently 1) to the loop
unrolling, with the assumption that fetches in loops are usually
designed in an incremental manner. However, this assumption
might be wrong and the fetch inside the loop itself makes
a double-fetch bug when the loop is unrolled multiple times.
Furthermore, there could be cases when cross-loop double-fetch
bugs occur when a loop is unrolled to a speciﬁc time. Although
we believe both cases are rare, we cannot prove that they do
not exist in kernel.
3) If there is a branch inside a loop, DEADLINE picks only
one subpath to unroll the loop. However, there might be cases
when a double-fetch bug occurs when the subpaths are taken
in a speciﬁc order when unrolling the loop multiple times, e.g.,
the true branch is taken in the ﬁrst unrolling and the false
branch is taken in the second unrolling.
Symbolic checking. DEADLINE symbolic checker is limited
by how well we model complicated code pieces like assemblies
and library function calls as well as the assumptions in the
memory model.
1) DEADLINE ignores a majority of inline assemblies, i.e.,
assuming they have no impact on the symbolic checking. This
could lead to missing constraints or incomplete SR assignment,
especially when the assemblies issue memory operations. In
addition, for the library functions that we manually write
rules for, there might be imprecision. For example, we assume
that strnlen might return any value between 0 and the len
argument, but actually it is also constrained by the string buffer,
which we do not model in the rule.
2) DEADLINE’s empirical mapping from pointers to mem-
ory object might not reﬂect the actual situation. As shown
in Figure 5, if the function calling not_buggy1 already ensures
672
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:39:58 UTC from IEEE Xplore.  Restrictions apply. 
that utrp1 == uptr2, or the struct request is designed in
such a way that up->buf == up, then it would be wrong for
DEADLINE to treat them as non-buggy.
3) DEADLINE’s assumption about the enclosing function
might be incomplete. As shown in the “won’t ﬁx” case
ll_copy_user_md, it is possible that the information to assert
the relations established between the two fetches are passed
out of the enclosing function and re-checked elsewhere.
XII. RELATED WORK
Besides being closely related to the recent work on double-
fetch bug detection [9], [10], DEADLINE is also related to the
research on race condition detection and symbolic execution.
Race condition detection. A double-fetch bug is a special
type of race condition. Researchers have studied the generic
race condition problem extensively and proposed numerous
detection techniques, such as model checking [24], [25], type-
based systems [26], [27], and data-ﬂow analyses [25], [28],
[29]. These static methods are able to check all execution
paths with attractive efﬁciency but generally suffer from a high
false positive rate. In contrast, dynamic detection offers precise
detection but at the cost of performance and scalability. Much
work along the dynamic direction has focused on improving
the performance [30], [31], [32], [33].
Unfortunately, none of these techniques can be directly
applied to double-fetch bug detection. A prerequisite for these
methods is to have a complete view of the concurrently running
threads (either at source code level or instruction level), which
is not true for the double-fetch bug, as we have no information
on how the user threads might behave. Even when we manage
to incorporate the behaviors of user threads into the picture, a
race condition detected by these methods can only indicate the
existence of an overlapped-fetch and we still need to check
whether the overlapped-fetch turns into a double-fetch bug.
Symbolic execution for bug ﬁnding. With the recent
advances in SMT solvers [34], symbolic execution has proven
to be an effective technique in ﬁnding bugs in complex software
applications [13], [14], [15], [35], [36]. Recent research has
further made trade-offs between scalability and path coverage
of symbolic execution. A few symbolic execution techniques
are now able to analyze even OS kernels such as S2E [37]
and FuzzBALL [38], [39]. In particular, S2E employs selective
symbolic execution and relaxed execution consistency models
to signiﬁcantly improve the performance. A number of tools
(e.g., SymDrive [40], Stack Spraying [41], and CAB-Fuzz [42])
built on top of S2E have been designed to analyze kernel code
for various purposes.
DEADLINE also leverages the power of SMT solvers for
double-fetch bug detection and uses a similar way to collect
constraints and assign SR to variables as traditional symbolic
executors. However, DEADLINE can be differentiated from
them in two ways:
Path exploration strategy: DEADLINE performs path ex-
ploration ofﬂine and symbolically executes only within a
particular path instead of exploring paths online by forking
states whenever a conditional branch is encountered. This is
because, unlike traditional symbolic executors whose primary
goal is path discovery, DEADLINE is not bounded to execute
the instructions that are irrelevant to the cause of a double-
fetch bug, and DEADLINE takes full advantage of that by ﬁrst
ﬁltering out these irrelevant instructions and then constructing
paths that must go through at least two fetches and only checks
along these paths.
Memory model: DEADLINE extends the memory model used
in traditional symbolic executors in two aspects. 1) DEADLINE
adds an epoch number to a memory read when it crosses the
kernel-user boundary to denote that different userspace fetches
from the same address can be different, which is effectively
the root cause of a double-fetch bug. 2) Instead of assuming
a pointer can point to anywhere in the memory, DEADLINE
keeps a mapping of pointers to memory objects and uses this
to ﬁlter out multi-reads that are in fact unrelated fetches.
XIII. CONCLUSION
Detecting double-fetch bugs without a precise and formal
deﬁnition has led to a lot of false alerts where manual veriﬁ-
cation has to be involved to ﬁnd real double-fetch bugs from
the haystack of multi-reads. At the same time, oversimpliﬁed
assumptions about how a double-fetch bug might appear have
also caused true bugs to be missed.
To systematically approach double-fetch bug detection, we
ﬁrst formally model double-fetch bugs, which unambiguously
distinguishes double-fetch bugs from multi-reads in mathe-
matical notions Based on the formal model, we implement
DEADLINE, a static analysis system that automatically scans
though the kernel for both multi-read and double-fetch bug
detection. In particular, multi-read detection is done through
scalable and efﬁcient static program analysis techniques, while
the specialized symbolic checking engine vets each multi-read
by precisely checking whether it satisﬁes all the conditions in
the formal deﬁnition to become a double-fetch bug.
As a result, we found and reported 23 new bugs in the Linux
kernel and one new bug in the FreeBSD kernel, of which nine
have been patched and four acknowledged. This shows the
power of symbolic checking for ﬁnding complex logic bugs. In
addition, we summarized four generic strategies for patching
and preventing double-fetch bugs based on our experience in
patch creation and communication with the kernel maintainers.
XIV. ACKNOWLEDGMENT
We thank the anonymous reviewers for their helpful feedback.
This research was supported, in part, by the NSF under
award DGE-1500084, CNS-1563848, CNS-1704701, and CRI-
1629851, ONR under grants N00014-15-1-2162 and N00014-
17-1-2895, DARPA TC (No. DARPA FA8650-15-C-7556),
ETRI IITP/KEIT[B0101-17-0644], the German Ministry of
Education and Research (BMBF), and gifts from Facebook,
Mozilla and Intel.
REFERENCES
[1] N. Wilfahrt, “Dirty COW (CVE-2016-5195) is a privilege escalation
vulnerability in the Linux Kernel,” 2016, https://dirtycow.ninja/.
673
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:39:58 UTC from IEEE Xplore.  Restrictions apply. 
[2] S. Khandelwal, “11-Year Old Linux Kernel Local Privilege Escalation
Flaw Discovered,” 2017, http://thehackernews.com/2017/02/linux-kernel-
local-root.html.
[3] MITRE, “CVE-2017-2584,” 2017, https://cve.mitre.org/cgi-bin/cvename.
cgi?name=2017-2584.
[4] A. Konovalov, “Exploiting the Linux Kernel via Packet Sockets,”
2017, https://googleprojectzero.blogspot.com/2017/05/exploiting-linux-
kernel-via-packet.html.
[5] J. Edge, “Kernel Address Space Layout Randomization,” 2013, https:
//lwn.net/Articles/569635/.
[6] J. Criswell, N. Dautenhahn, and V. Adve, “KCoFI: Complete Control-
Flow Integrity for Commodity Operating System Kernels,” in Proceedings
of the 35th IEEE Symposium on Security and Privacy (Oakland), San
Jose, CA, May 2014.
[7] X. Ge, N. Talele, M. Payer, and T. Jaeger, “Fine-Grained Control-Flow
Integrity for Kernel Software,” in Proceedings of the 1st IEEE Euro-
pean Symposium on Security and Privacy (Euro S&P), SaarbrÃijcken,
Germany, Mar. 2016.