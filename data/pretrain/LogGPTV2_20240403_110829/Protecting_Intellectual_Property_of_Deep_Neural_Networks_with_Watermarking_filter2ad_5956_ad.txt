is also possible to learn the query patterns of such attacks to detect
them before stealing the models.
Evasion. Our watermarking framework consists of three com-
ponents: watermark generation, watermark embedding, and own-
ership verification. Only ownership verification component needs
to be done remotely, therefore, one way to evade our watermark-
ing framework is to prevent our queries to ownership verification.
Recently Meng et al. [39] proposed a framework named MagNet to
defend against adversarial queries. Specifically, MagNet trains mul-
tiple AutoEncoders with normal data to learn the representation
of normal data and then use those AutoEncoders as abnormal de-
tectors. The insights behind the MagNet is that adversary samples
usually have different distribution with normal samples. Therefore,
such defense techniques could also be used here to defend against
our ownership verification queries since our embedded watermarks
also show the difference with normal samples. However, the effec-
tiveness of MagNet depends on the normal examples for the training
of their detector networks. Insufficient normal examples will lead to
high false positives. In our case, we assume that plagiarizers do not
have a sufficient normal dataset to train such detectors, otherwise,
they can directly train the model by themselves without needs for
stealing the model.
7 RELATED WORK
Watermarking. Digital watermarking is the method to hide the
secret information into the digital media in order to protect the own-
ership of those media data. Many approaches have been proposed
to make the watermark to be efficient as well as robust to removal
attacks. Spatial domain digital watermarking algorithms have been
investigated in [7, 30, 36, 52]. They embed secrets by directly manip-
ulating pixels in an image. For example, the LSB (least significant
bit) [30, 36] of pixels is commonly used to embed secret. However,
such techniques are vulnerable to attacks and are sensitive to noise
and common signal processing. Compared to spatial-domain meth-
ods, frequency domain methods are more widely applied, which
embed the watermarks in the spectral coefficients of the image. The
most commonly used transforms are the Discrete Cosine Transform
(DCT) [25, 44], Discrete Fourier Transform (DFT) [42, 55], Discrete
Wavelet Transform (DWT) [9, 11, 31, 58] and the combination of
them [6, 38, 46]. In order to verify the ownership of protected me-
dia data, all existing watermarking algorithms require to directly
access those media data to extract the watermarks and verify the
ownership. However, in deep neural networks, we need to protect
DNN models rather than input media data, after training, usually
only the DNN model API is available for ownership verification.
Therefore, the existing digital watermarking algorithms cannot be
directly applied to protect DNN models.
Recently, Uchida et al. [54] proposed the first method for em-
bedding watermarks into deep neural networks. It embedded infor-
mation into the weights of the deep neuron network. Therefore, it
assumes that the stolen models can be locally accessible to extract
11
all the parameters, which is not practical, since most deep learn-
ing models are deployed as on-line service and it will be hard to
directly get access to model parameters especially for the stolen
models. Merrer et al. [40] proposed a zero-bit watermarking al-
gorithm that makes use of adversarial samples as watermarks to
verify the ownership of neural networks. Specifically they fine-tune
the DNN models to include certain true/false adversaries and use
the combination of such adversaries as keys K to verify the DNN
models. If the DNN models can return the pre-defined results to
these keys K, they can confirm the ownership of the DNN models.
However, such an algorithm has a vulnerability that each model
essentially has infinite such keys, therefore everyone can claim the
ownership of the DNN modesl with any K. For example, we can
generate a set of adversarial samples with any DNN model, and
then claim that those models belong to us since we can extract these
adversarial samples from those models. Different from these two
existing works, our framework can remotely verify the ownership
of DNN models and our embedded watermarks are unique to each
model. For example, for our W Mcontent watermark generation al-
gorithm, only the image with embedded content “Test” can trigger
the pre-defined output.
Deep neural network attack and defense. As deep neural
networks are being widely used, a variety of attacks have been
investigated on it. Fredrikson et al. [16] introduced the model in-
version attack that can recover images in the training dataset from
deep neural networks. As we have shown in our evaluation, our wa-
termarking framework is robust to such attacks. Tramer et al. [53]
introduced an attack to steal the general machine learning models.
Such attacks can be prevented by updating DNN APIs by not re-
turning confidence score and not responding to incomplete queries.
Shokri et al. [47] introduced membership inference attacks, which
can determine whether the given record was used as part of the
model’s training dataset or not. Such attack is not applicable for
inferring our watermarks since attackers need to know watermarks
first. [37] and [20] recently introduced deep neural network Tro-
janing attacks, which embed hidden malicious functionality into
neural networks. Similar to Trojans in software, such attacks could
be prevented by checking the model integrity. We have a different
threat model here and we focus on how to use watermarking to
protect the intellectual property of DNN models.
8 CONCLUSION
In this paper, we generalized the “digital watermarking” concept
for deep neural networks and proposed a general watermarking
framework to produce different watermarks, embed them into deep
neural networks, and remotely verify the ownership of DNN mod-
els based on the embedded watermarks. We formally define the
threat model of watermarking in deep neural networks to support
both white-box and black-box access. The key innovation of our
watermarking framework is that it can remotely verify the own-
ership of deep neural network services with few API queries. We
also perform a comprehensive evaluation with our watermarking
framework on two benchmark datasets. We demonstrate that our
framework can satisfy the general watermarking standard and is
robust to different counter-watermark attacks.
REFERENCES
[1] 2016. ImageNet. http://www.image-net.org/. (2016).
[2] 2017.
How Amazon, Google, Microsoft, And
IBM Sell
https://www.fastcompany.com/40474593/
AI
how-amazon-google-microsoft-and-ibm-sell-ai-as-a-service. (2017).
Service.
[3] 2017. Model Gallery. https://www.microsoft.com/en-us/cognitive-toolkit/
As
A
features/model-gallery/. (2017).
[4] 2017. The Value of Stolen Data on the Dark Web. https://darkwebnews.com/
dark-web/value-of-stolen-data-dark-web/. (2017).
[5] Martín Abadi et al. 2016. Tensorflow: Large-scale machine learning on heteroge-
[8] Sajid Anwar and Wonyong Sung. 2016. Compact Deep Convolutional Neural
neous distributed systems. In arXiv:1603.04467.
[6] Ali Al-Haj. 2007. Combined DWT-DCT Digital Image Watermarking. In Journal
of Computer Science.
[7] Mustafa Osman Ali, Elamir Abu Abaida Ali Osman, and Rameshwar Row. 2012. In-
visible Digital Image Watermarking in Spatial Domain with Random Localization.
In International Journal of Engineering and Innovative Technology.
Networks With Coarse Pruning. In arXiv:1610.09639.
[9] Mauro Barni, Franco Bartolini, and Alessandro Piva. 2001. Improved wavelet-
based watermarking through pixel-wise masking. In IEEE Transactions on Image
Processing.
[10] Nicholas Carlini and David Wagner. 2017. Towards Evaluating the Robustness of
Neural Networks. In IEEE Symposium on Security and Privacy (S&P ’17).
[11] Munesh Chandra and Shikha Pandey. 2010. A DWT domain visible watermarking
techniques for digital images. In International Conference On Electronics and
Information Engineering (ICEIE ’10).
[12] François Chollet. 2015. Keras. In https://github.com/fchollet/keras.
[13] Gregory Cohen, Saeed Afshar, Jonathan Tapson, and André van Schaik. 2017.
[20] Tianyu Gu, Brendan Dolan-Gavitt, and Siddharth Garg. 2017.
EMNIST: an extension of MNIST to handwritten letters.. In arXiv:1702.05373.
[14] Ingemar Cox, Matthew Miller, Jeffrey Bloom, Jessica Fridrich, and Ton Kalker.
2007. Digital Watermarking and Steganography. In Morgan Kaufmann Publishers
Inc.
[15] Y. Le Cun, I. Guyon, L. D. Jackel, D. Henderson, B. Boser, R. E. Howard, J. S. Denker,
W. Hubbard, and H. P. Graf. 1989. Handwritten digit recognition: applications of
neural network chips and automatic learning. In IEEE Communications Magazine.
[16] Matt Fredrikson, Somesh Jha, and Thomas Ristenpart. 2015. Model Inversion
Attacks that Exploit Confidence Information and Basic Countermeasures. In ACM
SIGSAC Conference on Computer and Communications Security.
[17] Yoav Goldberg. 2015. A primer on neural network models for natural language
processing. In Journal of Artificial Intelligence Research.
Press. http://www.deeplearningbook.org.
[18] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning. MIT
[19] Alex Graves, Abdel-rahman Mohamed, and Geoffrey E. Hinton. 2013. Speech
Recognition with Deep Recurrent Neural Networks. In IEEE International Confer-
ence on Acoustics, Speech and Signal Processing ( ICASSP ’13).
BadNets:
Identifying Vulnerabilities in the Machine Learning Model Supply Chain. In
arXiv:1708.06733.
[21] Song Han, Jeff Pool, John Tran, and William J. Dally. 2015. Learning both Weights
and Connections for Efficient Neural Networks. In Proceedings of Neural Infor-
mation Processing Systems(NIPS’15).
[22] Awni Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich
Elsen, Ryan Prenger, Sanjeev Satheesh, Shubho Sengupta, Adam Coates, and
Andrew Y. Ng. 2012. Deep Speech: Scaling up end-to-end speech recognition. In
arXiv:1412.5567.
In Proceedings of the IEEE.
[24] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep Residual
Learning for Image Recognition. In IEEE Conference on Computer Vision and
Pattern Recognition (CVPR ’16).
[25] J.R. Hernandez, M. Amado, and F. Perez-Gonzalez. 2000. DCT-domain water-
marking techniques for still images: detector performance analysis and a new
structure. In IEEE Transactions on Image Processing.
[26] Geoffrey Hinton, Li Deng, Dong Yu, George E. Dahl, Abdel rahman Mohamed,
Navdeep Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N.
Sainath, and Brian Kingsbury. 2012. Deep Neural Networks for Acoustic Modeling
in Speech Recognition: The Shared Views of Four Research Groups. In IEEE Signal
Processing Magazine.
[27] Briland Hitaj, Giuseppe Ateniese, and Ravi K ShethFernando Perez-Cruz. 2017.
Deep Models Under the GAN: Information Leakage from Collaborative Deep
Learning.. In ACM Conference on Computer and Communications Security.
Neural computation.
[29] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long,
Ross Girshick, Sergio Guadarrama, and Trevor Darrell. 2014. Caffe: Convolutional
Architecture for Fast Feature Embedding. arXiv preprint arXiv:1408.5093 (2014).
[23] Frank Hartung and Martin Kutter. 1999. Multimedia watermarking techniques.
[28] Sepp Hochreiter and Jurgen Schmidhuber. 1997. Long short-term memory. In
[30] Neil F. Johnson and Sushil Jajodia. 1998. Exploring Steganography: Seeing the
[31] Nikita Kashyap and G. R. SINHA. 2012.
[42] Shelby Pereira and Thierry Pun. 2000. Robust template matching for affine
Unseen. In IEEE Computer.
Image Watermarking Using 3-Level
Discrete Wavelet Transform (DWT). In International Journal of Modern Education
and Computer Science (IJMECS ’12).
[32] Alex Krizhevsky. 2009. Learning multiple layers of features from tiny images. In
Master’s thesis, Department of Computer Science, University of Toronto.
[33] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. 2012. ImageNet clas-
sification with deep convolutional neural networks. In Proceedings of the 25th
International Conference on Neural Information Processing Systems (NIPS ’12).
[34] Gerhard C. Langelaar, Iwan Setyawan, and Reginald L. Lagendijk. 2000. Water-
marking digital image and video data. A state-of-the-art overview. In IEEE Signal
Processing Magazine.
[35] Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. 1998. Gradient-
based learning applied to document recognition. In Proceedings of the IEEE.
[36] Yeuan-Kuen Lee, Graeme Bell, Shih-Yu Huang, Ran-Zan Wang, and Shyong-
Jian Shyu. 2009. An Advanced Least-Significant-Bit Embedding Scheme for
Steganographic Encoding. In Proceedings of the 3rd Pacific-Rim Symposium on
Image and Video Technology(PSIVT ’09).
[37] Yingqi Liu, Shiqing Ma, Yousra Aafer, Wen-Chuan Lee, Juan Zhai, Weihang Wang,
and Xiangyu Zhang. 2018. Trojaning Attack on Neural Networks. In Proceedings
of the Network and Distributed System Security Symposium (NDSS ’18).
[38] Jiansheng Mei, Sukang Li, and Xiaomei Tan. 2009. A Digital Watermarking
Algorithm Based On DCT and DWT. In Proceedings of the 2009 International
Symposium on Web Information Systems and Applications (WISA ’09).
[39] Dongyu Meng and Hao Chen. 2017. MagNet: a Two-Pronged Defense against
Adversarial Examples.. In ACM Conference on Computer and Communications
Security.
[40] Erwan Le Merrer, Patrick Perez, and Gilles Trédan. 2017. Adversarial Frontier
Stitching for Remote Neural Network Watermarking. In arXiv:1711.01894.
[41] Pavlo Molchanov, Stephen Tyree, Tero Karras, Timo Aila, and Jan Kautz. 2017.
Pruning Convolutional Neural Networks for Resource Efficient Inference. In
International Conference on Learning Representations (ICLR ’17).
resistant image watermarks. In IEEE Transactions on Image Processing.
[43] Nikiforos Pittaras, Foteini Markatopoulou, Vasileios Mezaris, and Ioannis Patras.
2017. Comparison of Fine-Tuning and Extension Strategies for Deep Convolu-
tional Neural Networks. In International Conference on Multimedia Modeling.
[44] A. Piva, M. Barni, E Bartolini, and V. Cappellini. 1997. DCT-based watermark
recovering without resorting to the uncorrupted original image. In International
Conference on Image Processing.
[45] Lalit Kumar Saini and Vishal Shrivastava. 2014. A Survey of Digital Watermarking
Techniques and its Applications. In International Journal of Computer Science
Trends and Technology (IJCST ’14).
[46] Ravi K Sheth and V. V. Nath. 2016. Secured digital image watermarking with
discrete cosine transform and discrete wavelet transform method. In International
Conference on Advances in Computing, Communication, and Automation.
[47] Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. 2017. Mem-
bership Inference Attacks Against Machine Learning Models. In IEEE Symposium
on Security and Privacy (S&P ’17).
[48] Karen Simonyan and Andrew Zisserman. 2015. Very Deep Convolutional Net-
works for Large-Scale Image Recognition. In International Conference on Learning
Representations (ICLR ’15).
[49] Suraj Srinivas and R. Venkatesh Babu. 2015. Data-free Parameter Pruning for
Deep Neural Networks. In BMVA Press.
data-embedding and watermarking technologies. In Proceedings of the IEEE.
cessing of Deep Neural Networks: A Tutorial and Survey. In arXiv:1703.09039.
[52] Jun Tian. 2003. Reversible Data Embedding Using a Difference Expansion. In
IEEE Transactions on Circuits and Systems for Video Technology.
[53] Florian Tramer, Fan Zhang, Ari Juels, Michael Reiter, and Thomas Ristenpart.
2016. Stealing Machine Learning Models via Prediction APIs. In Proceedings of
the 25th USENIX Security Symposium (Security ’16).
[54] Yusuke Uchida, Yuki Nagai, Shigeyuki Sakazawa, and Shin’ichi Satoh. 2017.
Embedding Watermarks into Deep Neural Networks. In Proceedings of the 2017
ACM on International Conference on Multimedia Retrieval (ICMR ’17).
[55] Matthieu Urvoy, Dalila Goudia, and Florent Autrusseau. 2014. Perceptual DFT Wa-
termarking With Improved Detection and Robustness to Geometrical Distortions.
In IEEE Transactions on Information Forensics and Security (TIFS ’14).
[56] Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson. 2014. How transferable
are features in deep neural networks?. In Neural Information Processing Systems.
[57] Matthew D Zeiler and Rob Fergus. 2014. Visualizing and understanding convolu-
tional networks. In European conference on computer vision. Springer, 818–833.
[58] Lijing Zhang and Aihua Li. 2009. Robust Watermarking Scheme Based on Sin-
gular Value of Decomposition in DWT Domain. In Asia-Pacific Conference on
Information Processing.
[51] Vivienne Sze, Yu-Hsin Chen, Tien-Ju Yang, and Joel Emer. 2017. Efficient Pro-
[50] Mitchell D. Swanson, Mei Kobayashi, and Ahmed H. Tewfik. 1988. Multimedia
12
A APPENDIX
A.1 DNN model architecture
Table 6 and Table 7 show the architecture and training parameters of DNN models for different datasets.
Table 6: Architecture of DNN models
CIFAR10
MNIST
32 filters (3 × 3)
32 filters (3 × 3)
64 filters (3 × 3)
64 filters (3 × 3)
2 × 2
64 filters (3 × 3)
64 filters (3 × 3)
128 filters (3 × 3)
128 filters (3 × 3)
2 × 2
Layer Type
Conv.ReLU
Conv.ReLU
Max Pooling
Conv.ReLU
Conv.ReLU
Max Pooling
Dense.ReLU
Dense.ReLU
Softmax
2 × 2
200
200
10
2 × 2
256
256
10
MNIST
SGD
Table 7: Training parameters for different models
Parameter
Optimization method
Loss function
Learning Rate
Batch Size
Epoch
Dropout Rate
Crossentropy Crossentropy
0.01
128
50
0.5
0.01
128
50
0.5
CIFAR10
SGD
(a) W Mcont ent watermark
(b) recover from image “automo-
bile”
(c) recover from blank image
(d) recover from random noise
(e) W Munr el at ed watermark
(f) recover from image “automo-
bile”
(g) recover from blank image
(h) recover from random noise
(i) W Mnoise watermark
(j) recover from image “automo-
bile”
(k) recover from blank image
(l) recover from random noise
Figure 9: Model inversion attacks on CIFAR10
13