The depicted numbers are given for the strictly alternating
IMCs (which comprises precisely what needs to be stored for
the corresponding CTMDP), and thus are differentiated in in-
teractive states/transitions and Markov states/transitions.
In
column 7 the time for the transformation (from uIMC to uCT-
MDP) is shown. We highlight, that the prototypical implemen-
tation of the transformation procedure works quite efﬁciently
also for large systems (N = 128).
In columns 8 and 9 we
collect statistics of the implementation of the reachability al-
gorithm. The runtime results for a time bound of 100h are
given in column 8 and the results for a time bound of 30000h
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007are shown in the column 9. In the last two columns we show
the required number of iterations taken by the reachability al-
gorithm in order to have a precision of 0.000001. Readers fa-
miliar with CTMC analysis time and space requirements will
appreciate the efﬁciency apparent in these ﬁgures, given that
we report about a JAVA prototype, and need to deal with non-
determinism.
Finally, we show in Figure 4 graphs for N = 4 and
N = 128 in which we compare the worst case probabili-
ties obtained by the CTMDP algorithm with the probabilities
obtained from CTMC analysis. As evident in the plot, the
CTMC analysis consistently overestimates the true probabil-
ities (computed with ETMCC, conﬁrmed with CADP). This is
quite remarkable, because the CTMDP algorithm accounts for
the worst-case. Nothing worse is possible in the model, and
we would thus expect, that this probability will be higher than
in a corresponding CTMC model of the system. This overes-
timation, which indicates a modeling ﬂaw in the CTMC ap-
proach, can be explained as follows. When replacing a nonde-
terministic selection by high rates, certain paths become pos-
sible (though with low probability), that in a nondeterministic
interpretation would be absent, and thus not contribute to the
reachability probability. Concretely, in the CTMC implemen-
tation, there are sometimes races between very high rates and
ordinary rates, which are entirely artiﬁcial and do not exist in
the more faithful interpretation we use.
6 Conclusion
This paper has introduced a compositional approach to the
generation of nondeterministic stochastic systems, and their
analysis. More precisly, the paper has made the following
contributions: (1) we have devised a sound compositional tra-
jectory to construct uniform interactive Markov Chains. This
model is transformed into a uniform continuous-time Markov
decision process, and this transformation is shown to preserve
path probability measures. (2) We have presented convincing
experimental results for the ﬁrst implementation of the uni-
form CTMDP analysis algorithm of [2].
(3) We have dis-
cussed that nondeterminism lets certain systems look differ-
ent, in particular the fault-tolerant workstation cluster exam-
ple. Surprisingly, the previous studies of this model overesti-
mated the worst-case reachability probabilities which we, for
the ﬁrst time, were able to compute accurately.
The experiments show that the transformation and the anal-
ysis algorithm scale very well. Especially compared to the
simpler CTMC case, the time and space requirements are of
similar order (for models of similar size). Even though our
prototypical JAVA implementation is performing remarkably
well on this example, we are currently porting the algorithm to
C++ in order to integrate it with the MRMC tool [20].
References
[1] R. B. Ash and C. A. Dol´eans-Dade. Probability & Mea-
sure Theory. Academic Press, second edition, 2000.
[2] C. Baier, B. R. Haverkort, H. Hermanns, and J.-P. Ka-
toen. Efﬁcient Computation of Time-Bounded Reacha-
bility Probabilities in Uniform Continuous-Time Markov
Decision Processes. Theor. Comput. Sci., 345(1):2–26,
2005.
[3] A. Bianco and L. de Alfaro. Model Checking of Prob-
abilistic and Nondeterministic Systems. FSTTCS, 15,
1995.
[4] E. B¨ode, M. Herbstritt, H. Hermanns S.
Johr,
T. Peikenkamp, R. Pulungan R. Wimmer, and B. Becker.
Compositional Performability Evaluation for Statemate.
In International Conference on Quantitative Evaluation
of Systems (QEST), pages 167–176. IEEE Computer So-
ciety, 2006.
[5] CADP.
Project Website,
Aug
2006.
http://www.inrialpes.fr/vasy/cadp/demos.html.
[6] M. Calder, V. Vyshemirsky, D. Gilbert, and R. Orton.
Analysis of signalling pathways using continuous time
Markov chains. Transactions on Computational Systems
Biology, 2006. To appear.
[7] R. Cleaveland, S. P. Iyer, and M. Narasimha. Probabilis-
tic temporal logics via the modal mu-calculus. Theor.
Comput. Sci., 342(2-3):316–350, 2005.
[8] L. de Alfaro. Stochastic Transition Systems. In Interna-
tional Conference on Concurrency Theory (CONCUR),
pages 423–438, 1998.
[9] B. L. Fox and P. W. Glynn. Computing Poisson prob-
abilities. Communications of the ACM, 31(4):440–445,
1988.
[10] G. Gallo, G. Longo, S. Pallottino, and S. Nguyen. Di-
rected hypergraphs and applications. Discrete Appl.
Math., 42(2-3):177–201, 1993.
[11] H. Garavel and H. Hermanns. On Combining Functional
Veriﬁcation and Performance Evaluation Using CADP.
In Formal Methods Europe (FME), pages 410–429, 2002.
[12] S. Graf, B. Steffen, and G. L¨uttgen. Compositional Min-
imisation of Finite State Systems Using Interface Speci-
ﬁcations. Formal Asp. Comput., 8(5):607–616, 1996.
[13] B.R. Haverkort, H. Hermanns, and J.-P. Katoen. On the
Use of Model Checking Techniques for Dependability
Evaluation. In Symposium on Reliable Distributed Sys-
tems (SRDS’00), pages 228–237. IEEE Computer Soci-
ety, 2000.
[14] H. Hermanns. Interactive Markov Chains and the Quest
for Quantiﬁed Quality, volume 2428 of LNCS. Springer,
2002.
[15] H. Hermanns and J.-P.Katoen. Automated compositional
Markov chain generation for a plain-old telephone sys-
tem. Science of Comp. Programming, 36:97–127, 2000.
[16] H. Hermanns and S. Johr. Uniformity by Construc-
tion in the Analysis of Nondeterministic Stochastic Sys-
tems, 2006. Long version of submission. Available at
http://depend.cs.uni-sb.de/˜johr/PDS/longV.pdf.
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007N
1
2
4
8
16
32
64
128
# States
Inter. Markov
81
205
621
2125
7821
29965
117261
463885
110
274
818
2770
10130
38674
151058
597010
# Transitions
Inter.
155
403
1235
4243
15635
59923
234515
927763
Markov
324
920
3000
10712
40344
156440
615960
2444312
Mem
14.2 KB
38.6 KB
122 KB
428 KB
1.56 MB
6.01 MB
23.6 MB
93.6 MB
Transf.
time (s)
5.37
4.32
5.25
5.83
6.61
9.44
20.58
57.31
Runtime (s)
# Iterations
100 h
0.01
0.01
0.04
0.13
0.52
3.23
37.42
557.52
30000 h
6.04
12.33
37.28
47.77
294.97
877.52
3044.72
20867.06
100 h
372
372
373
375
378
384
397
423
30000 h
62161
62284
62528
63016
63993
65945
69849
77651
Table 1. Model sizes, memory usage and runtime for strictly alternating IMCs
y
t
i
l
i
b
a
b
o
r
P
 0.5
 0.4
 0.3
 0.2
 0.1
 0
 0
N = 4
CTMDP
CTMC
 5000
 10000
 15000
 20000
 25000
 30000
Time Bounds
y
t
i
l
i
b
a
b
o
r
P
 0.35
 0.3
 0.25
 0.2
 0.15
 0.1
 0.05
 0
 0
N = 128
CTMDP
CTMC
 100
 200
 300
 400
 500
 600
 700
 800
 900
 1000
Time Bounds
Figure 4. Different probabilities
[17] H. Hermanns,
J.-P. Katoen,
J. Meyer-Kayser, and
M. Siegle. A tool for model-checking Markov chains.
Journal on Software Tools for Technology Transfer
(STTT), 4(2):153–172, 2003.
[18] A. Hinton, M. Kwiatkowska, G. Norman, and D. Parker.
PRISM: A Tool for Automatic Veriﬁcation of Probabilis-
tic Systems. In TACAS, pages 441–444. Springer, 2006.
[19] A. Jensen. Markoff Chains as an Aid in the Study
of Markoff Processes. Skandinavisk Aktuarietidsskrift,
pages 87–91, March 1953.
[20] J.-P. Katoen, M. Khattri, and I. S. Zapreev. A Markov
Reward Model Checker.
In Quantitative Evaluation of
Systems (QEST), pages 243–244. IEEE Computer Soci-
ety, 2005.
[21] J. G. Kemeny and J. L. Snell. Finite Markov Chains. Van
Nostrand, 1960.
[22] N.A. Lynch, I. Saias, and R. Segala. Proving Time
Bounds for Randomized Distributed Algorithms.
In
Symposium on the Principles of Distributed Computing,
pages 314–323, 1994.
[23] M. F. Neuts. Matrix-Geometric Solutions in Stochastic
Models: An Algorithmis Approach. Dover, 1981.
[24] A. Pogosyants, R. Segala, and N. A. Lynch. Veriﬁca-
tion of the Randomized Consensus Algorithm of Aspnes
and Herlihy: a Case Study. In Workshop on Distributed
Algorithms (WDAG’97), volume 1320, pages 111–125.
Springer-Verlag, 1997.
[25] M. L. Puterman. Markov Decision Processes: Discrete
Stochastic Dynamic Programming. Wiley, 1994.
[26] M. A. Salsburg, D. Lifka, and R. S. Mitchell. A Manage-
ment Framework For Petabyte-Scale Disk Storage. In Int.
CMG Conference, pages 767–782, 2005.
[27] R. Segala. Modeling and Veriﬁcation of Randomized
Distributed Real-Time Systems. PhD thesis, Department
of Electrical Engineering and Computer Science, MIT,
1995.
[28] R. Segala and N. Lynch. Probabilistic simulations for
probabilistic processes. Nordic Journal of Computing,
2(2):250–273, 1995.
[29] SVL.
Project Website,
2006.
http://www.inrialpes.fr/vasy/cadp/man/svl.html.
[30] R. J. van Glabbeek and W. P. Weijland. Branching
time and abstraction in bisimulation semantics. J. ACM,
43(3):555–600, 1996.
March
[31] N. Wolovick and S. Johr. A Characterization of Mean-
ingful Schedulers for Continuous-time Markov Decision
Processes.
In Formal Modeling and Analysis of Times
Systems (FORMATS), pages 352–367. Springer, 2006.
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007