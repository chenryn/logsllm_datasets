GS-satellite links:
• Hypatia supports multiple GSL (ground-satellite link) network
devices per satellite and GS. As default in our experiments,
we set one GSL network device for both satellites and ground
stations. Each network device can send packets to any other
GSL network device, as long as the forwarding plan allows
it. Additional connectivity restrictions can be imposed, e.g., to
restrict user terminals such that they can only connect to one
satellite at a time.
• Across satellites and ground stations, no connections interfere
with each other. While this is a strong assumption, Starlink and
Kuiper mention [47, 68] that frequency management will be
software-defined and done online to optimize towards this goal.
• Each GS can be configured to either: (a) connect to multiple
• Since many loss-free handoff techniques are known for other
mobile settings, when GS-Satellite connections are handed off,
there is no loss. Hypatia delivers in-flight packets from the now
out-of-reach satellite, while new packets stop arriving at it.
satellites; or (b) connect to its nearest satellite.
We make these simplifications, which relax practical constraints
and are favorable to LEO networks, for two reasons: (a) this frame-
work suffices to draw out many of the challenges; and (b) doing
anything else requires substantial design work that is not within
our scope, e.g., frequency management for this setting will likely
be studied extensively in future work, for which Hypatia can serve
as a vehicle.
Forwarding state: We compute the forwarding state of satellites
and ground stations at a configurable time granularity, with the
default being 100 ms. Note that this step converts what is necessarily
a continuous process of satellite motion into discrete intervals
where we check and update the forwarding state. In between these
intervals, the latencies are correctly calculated based on satellite
motion, but the paths being used may deviate from the shortest.
We discuss the implications of this experimentally in §5.3.
For every time interval, we use a networkx [58] module to gen-
erate the network graph, accounting for satellite positions and link
lengths between satellites and to ground stations. On this graph,
the forwarding state for each node can be calculated based on arbi-
trary routing strategies. Our current implementation simply uses
shortest-path routing, computed with the Floyd-Warshall algorithm.
The forwarding state changes are also added into ns-3’s discrete
event queue: at the first time the event fires, it reads new forward-
ing state into static routing table entries, and then adds the next
forwarding state change event at exactly the configured time in-
terval. Any routing strategy implementable with static routes can
be easily supported. This is also true for multi-path routing, but
obviously, would require additional logic to be implemented for
splitting traffic across these paths.
Fig. 2: Scalability. Running experiments resulting in a 9.2 Gbit/s
network-wide goodput with TCP for 1 second takes ∼555 seconds. UDP
simulations are faster, with 13.8 Gbit/s goodput in ∼269 seconds.
3.2 Running packet-level simulations
The packet-level simulator can be used to run simulations of LEO
satellite networks for arbitrary satellite trajectories, GS locations,
routing, congestion control, and queuing. While the generated TLEs
for satellites, and routing and forwarding states are pre-computed
and fed to the simulator, it is responsible for simulating the mobility
of satellites and thereby accounting for varying link latencies over
time. For this purpose, we adapt an available ns-3 satellite mobility
model [61]. While this model adds a 1-3 km error per day to satellite
trajectories, this can be ignored safely for simulations that simulate
less than a few hours, as the networking implications of these
distances are minimal.
3.3 Post-processing and visualizations
Hypatia’s ns-3 module can simulate both UDP and TCP traffic
and log the relevant metrics for each transport, including RTTs,
congestion window, and application level flow progress over time.
We use gnuplot to generate all plots included in this paper, and
Cesium for visualizations. Cesium is a general-purpose 3D mapping
library for Javascript. We extend it to render the following interac-
tive visualizations, writing python code that takes the outputs of
our simulations and generates the visual elements for Cesium to
render.
• The satellite trajectories over time.
• The ground observer view over time, showing the satellites
visible in the sky at different angles of elevation.
• Changes in end-end paths over time.
• Changes in link utilization and available bandwidth on an end-
end path over time.
3.4 Simulator scalability
We briefly assess the scale at which Hypatia can run simulations in
reasonable time. We use Kuiper’s K1 shell as the LEO network, and
the 100 most populous cities as the GSes. The traffic is a random
permutation between the GSes. We test both TCP and UDP traffic.
For TCP, each GS-pair sends each other a long running TCP flow,
and we calculate network-wide goodput as the total rate of all
acknowledged data, counting only packet payloads and excluding
headers. For UDP, each GS-pair sends each other constant-rate,
 1 10 100 1000 10000 100000 0.01 0.1 1 10 100Slowdown (real s / virtual s)Traﬃc goodput rate (Gbit/s)TCP workloadUDP workloadIMC ’20, October 27–29, 2020, Virtual Event, USA
Kassing and Bhattacherjee et al.
(a) Rio de Janeiro to St. Petersburg
(b) Manila to Dalian
(c) Istanbul to Nairobi
Fig. 3: RTT fluctuations. RTTs calculated by networkx and measured in our simulator using pings match closely, with the lines almost
entirely overlapping, as shown for 3 paths. The TCP per-packet RTTs are also shown, measured in the absence of any other traffic except the
source-destination pair. The queue size is 100 packets, i.e., approximately 1 BDP for 10 Mbps and 100 ms. Note: The last few pings’ RTT is shown
as 0 due to them not yet returning back in time to give a valid RTT measurement.
paced UDP traffic at the line rate, and goodput is calculated as the
total rate of network-wide payload arrivals. For both types of traffic,
to control the traffic rate of the simulation, we vary the line rate
of each network link, all assumed to be uniform; we test line rates
of 1, 10, 25, 100 and 250 Mbit/s, and 1 and 10 Gbit/s. We run the
simulations on a single core on a 2.26 Ghz Intel Xeon L5520.
We quantify ‘slowdown’: if Hypatia takes 𝑏 real seconds to
simulate 𝑎 virtual seconds, slowdown is 𝑏
𝑎 . The results, shown in
Fig. 2, allow an experimenter to directly answer the question: if
I want to run the system at 𝐶 Gbit/s goodput and obtain data for
𝑎 virtual seconds, how long will it take? If slowdown for 𝑥-axis
= 𝐶 is 𝑦, then the answer is 𝑦 · 𝑎 seconds. The results show that,
e.g., to simulate ∼10 Gbps network goodput for 10 virtual seconds,
Hypatia would need ∼33 minutes for UDP traffic and ∼100 minutes
for TCP. The goodput alone determines the slowdown 𝑏
𝑎 , implying
a simple trade-off: given a fixed real time budget, 𝑏, one can either
simulate at high goodput for a short virtual time, or simulate at
lower goodput for a longer virtual time. For the same experiment
setup in terms of a constellation and traffic matrix, setting the
line-rate of links allows control over goodput (up to a point; as
utilization increases, goodput plateaus even with increasing load).
The simulation is bottlenecked at per-packet event processing.
As satellite network paths often comprise a large number of hops,
each end-end packet delivery results in many more events than,
e.g., for a data center network simulation. The satellite network’s
scale is also not a significant factor, at least for tens of thousands
of satellites; the simulation setup costs, which increase with net-
work scale, are only incurred at the start, while the packet events
dominate the real time incurred for simulation.
We find that opportunities for speeding simulations up may be
limited. Beyond ns-3’s per-packet processing time, Hypatia only
adds a minor overhead for calculating the per-packet delay through
the mobility model. Forwarding tables are pre-computed, and MAC
tables are pre-filled to prevent ARP activity. We are exploring to
what extent ns-3’s distributed mode affords speedup, but for a
variety of use cases, Hypatia’s current simulation pace will suffice,
as our later analysis shows.
4 EXAMINING A FEW LEO PATHS
We first analyze connectivity between a few GS-pairs in depth to
give a view of how an end-end connection behaves.
4.1 RTT fluctuations
We examine how the end-end RTTs vary over time. These experi-
ments use the Kuiper K1 shell. We run the analysis for 200 seconds,
as for Kuiper-scale networks this is sufficient to show nearly the
full range of variations.
For each source-destination pair, 𝑠-𝑑, 𝑠 sends 𝑑 a ping every
1 ms, and logs the response time. We also compare the measured
RTTs to those generated using networkx computations for the same
end-points, and the same constellation. For these networkx computa-
tions, we use snapshots of the system every 100 ms, and compute the
shortest paths using the Floyd-Warshall algorithm. Analysis based
on such computations has already appeared in recent work [5, 29];
we use it both as a validation for some of our simulator’s satellite-
specific code, and to highlight and explain the subtle differences that
actual packets sometimes experience compared to paths computed
from a static snapshot.
Fig. 3 shows the results for three 𝑠-𝑑 pairs. The ping measure-
ments from Hypatia (‘Pings’) and the snapshot computations from
networkx (‘Computed’) match closely for most of the time. For in-
stance, in Fig. 3(a) at 𝑡 = 32.9 s the path changes, which causes the
RTT to rise from 96 ms to 111 ms. Occasionally, like in Fig. 3(c)
around 130 seconds, we see spikes in the ping RTT compared to
networkx. These spikes result from forwarding state changes across
the path: as a packet travels on what was the shortest path when it
departed the source, the packet arrives at some satellite no longer
on the new shortest path, as satellites have moved. This results
effectively in the packet having taken a detour compared to the
instant path computation in networkx.
The path from Rio de Janeiro to St. Petersburg sees a disruption
around 150 seconds into the simulation, shown as the shaded region
in all related plots. We found that for this period, St. Petersburg
does not have any visible Kuiper satellites at sufficiently high an-
gle of elevation, which, obviously, results in the satellite network
path being disconnected. For Kuiper, its other two shells do not
address this missing connectivity either; high-latitude cities like St.
Petersburg will not see continuous connectivity over Kuiper.
For the other two paths, there are smaller but still substantial
variations in the RTT over time. Across time, the Manila-Dalian
path has a minimum RTT of 25 ms and a maximum RTT of 48 ms,
thus changing by nearly 2×. For the Istanbul-Nairobi path, this RTT
range is 47-70 ms.
Exploring the “Internet from space” with Hypatia
IMC ’20, October 27–29, 2020, Virtual Event, USA
(a) Rio de Janeiro to St. Petersburg
(b) Manila to Dalian
(c) Istanbul to Nairobi
Fig. 4: TCP congestion window evolution. As expected, the congestion window typically fluctuates between the BDP and BDP plus queue size
(100 packets). However, in certain cases, when the RTT gets lower, reordering happens, and even though there is no loss, the congestion window is
still halved.
(a) NewReno causes high RTTs.
(b) Vegas decreases CWND on RTT increase.
(c) Vegas’ throughput collapses.
Fig. 5: Both loss- and delay-based CC suffer. As seen here for the connection from Rio de Janeiro to St. Petersburg, while loss-based congestion
control (NewReno) fills up queues, delay-based congestion control (Vegas) infers increasing delay as congestion and collapses in throughput. This
happens at 35 s, and from then on, throughput stays low for Vegas.
For real-time applications that care about jitter, these variations
could necessitate a somewhat large “jitter buffer” to store and de-
liver packets to the application at an even rate. The determining
latency in such cases will be the maximum latency of an end-end
connection over time.
Takeaway for applications: The maximum end-end RTT over
time can be much higher than the minimum, and will determine
the latency for jitter-sensitive applications.
4.2 Congestion control, absent congestion
We also explore how congestion control works on changing satellite
paths. For this, we first use a congestion-free setting: the measured
end-end connection is the only one sending traffic, with the rest of
the network being entirely empty.
Fig. 3 also includes the per-packet RTT observed by TCP (NewReno)
packets. This TCP observed RTT is calculated as the time difference
between sending a packet and receiving its ACK. As expected, TCP
continually fills and drains the buffer, thus increasing the RTT. To
make the simulations faster, the shown experiments use a 10 Mbps
line-rate. The buffers are sized to 100 packets, i.e., 1 bandwidth-
delay product (BDP) for 100 ms. With higher rate, we expect the
same trend, with a smaller increase in RTTs as queues drain faster.
Fig. 4 shows the TCP congestion window evolution for the same
3 connections over the same period. The instantaneous BDP, ag-
gregated with queue capacity, i.e., BDP+Q, is also shown at each
point in time – this is the maximum number of packets that can
be in-flight without drops (assuming there is one bottleneck). The
network device queue size, 𝑄, for both ISLs and GSLs is set to 100
packets. For the times when BDP+Q is stable, TCP, as expected,
repeatedly hits it, incurs a drop, cuts the rate, and ramps up again.
But the changes in RTT, and thus BDP+Q, result in TCP changing
its behavior. The disconnection event for St. Petersburg is evident
from Fig. 4(a), but additionally, we can see drops in the congestion
window for the other connections too, e.g., in Fig. 4(c), around 140 s,
TCP drops the congestion window because of packet reordering. At
this time, as the path is shortened by ∼16 ms, packets transmitted
later use the new shorter path, and arrive first at the destination.
The resulting duplicate ACKs are interpreted as loss by the sender.
The TCP RTT oscillations at the right end of Fig. 3(a) and 5(a) are
caused by delayed acknowledgements. We checked that disabling
delayed ACKs eliminates these, but does not change the rest of the
observed behavior, which is our focus.
TCP’s filling up of buffers and the resulting deterioration in
per-packet latency is a widely recognized problem [3, 11, 27]. For
LEO networks that promise low-latency operation, this is perhaps
even more undesirable. We thus also test delay-based transport