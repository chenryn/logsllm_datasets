### 4.3 Verifying Hindsight Results

As Hindsight is the first framework of its kind, there is no established method to verify its results other than through manual inspection. To facilitate this, we have enhanced our ABB testing logic to generate a comprehensive, analyst-friendly HTML file for each (APK, ABB) tuple. This HTML file includes:

1. All device screenshots generated and used during the ABB testing on the APK.
2. The vulnerability analysis results generated by Hindsight's ABB evaluation logic.

This HTML page is manually reviewed to determine if a human expert would agree with the automatically-generated vulnerability result. If not, a checkbox in the HTML file is marked to indicate that the result is "Not Accepted." All this information is then uploaded to a server and stored in a database to track verification results. This approach allowed us to efficiently review Hindsight's results when applied to 2,324 APKs and quantify its accuracy precisely.

For the current dataset, one round of verification took approximately 60 person-hours. The observed error rate is 1.5%, where the ABB evaluation logic makes incorrect judgments (both false positives and false negatives). Given the low fraction of "Not Accepted" results, we consider Hindsight's results generally reliable.

It is important to note that such manual verification is only necessary for debugging Hindsight and establishing the credibility of its implementation. It does not need to be repeated every time Hindsight is used.

### 5. Evaluation

Using Hindsight, we tested each of the 2,324 browser APKs, belonging to 128 distinct browser families, against the 27 attack building blocks (ABBs) presented in Section 2. Out of more than 62,000 vulnerability reports for different combinations of APKs and ABBs, Hindsight failed on 2,260 tests, resulting in an error rate (or uncertainty rate) of approximately 3.6%. This error rate includes the 1.5% error rate due to false positives/false negatives discussed in Section 4.3, as well as cases where the framework itself detects an error (e.g., browser crash or inability to find the URL bar). This covers 292 APKs, or less than 12.6%, which have at least one failed test. To account for this uncertainty, we present our results using both a lower bound (i.e., all ABBs marked as "Error" are, in reality, "Not Vulnerable") and an upper bound (i.e., all ABBs marked as "Error" are, in reality, "Vulnerable").

#### 5.1 General Findings

Overall, using Hindsight, we found that 2,292 out of the 2,324 evaluated APKs (98.6%) were vulnerable to at least one ABB. Figure 4 shows how the number of vulnerabilities grows with the fraction of tested browser APKs, indicating that 50% of APKs are vulnerable to more than 12 ABBs.

To understand which classes of ABBs are more successful, Figure 5 displays the vulnerability of browsers to the five different types of ABBs: Event Routing, URL, Address Bar, Security Indicators, and Content. A browser APK is marked vulnerable to a class of attacks if it is vulnerable to at least one ABB in that class. We found that even the least popular class of ABBs (Event Routing) affects more than 25% of the tested browser APKs, with the most popular classes (URL and Content) affecting almost 100% of the evaluated browsers. Additionally, APKs belonging to popular browsers are, in general, as vulnerable as the rest of the browsers, and our level of uncertainty (denoted via whiskers at the top of each bar) does not alter the observed vulnerability trends. Figure 6 presents the same information grouped by browser families. A browser family is marked vulnerable to a class of attacks if at least one of its APKs is vulnerable to at least one ABB in that class. We observe that:
- The latest versions of browser families are as vulnerable, if not more so, than older versions.
- The relative popularity of vulnerability classes remains the same for distinct APKs.
- Certain ABBs, such as those in the Address Bar class, affect fewer browser families than individual APKs.

The differences between Figures 5 and 6 arise because our 2,324 APKs are not uniformly distributed across the 128 browser families, leading to different patterns when quantifying vulnerabilities as a fraction of browser families versus APKs.

#### 5.2 Longitudinal Analysis

One of the main motivations for our research is the rapid upgrade cycle of modern browsers and its impact on vulnerability reports. Most apps, including browsers, are updated on a weekly or monthly basis, incorporating new features and bug fixes. As such, any security quantification obtained manually by past researchers [2, 3, 6, 30, 32] was already outdated by the time their research was published. Since Hindsight is an automated, browser-agnostic vulnerability testing framework, it allows us to obtain vulnerability reports for all the latest browser apps and study vulnerability trends over time.

Using years as our time granularity, we group APKs belonging to the same browser family (via their package names), order them according to their version numbers, and extract their release dates as described in Section 3.2.

Figure 7a shows how the average number of vulnerabilities for each browser APK varies from year to year, starting from 2011 (the year of our oldest APK) to 2016 (the year of our most recent APKs). We observe a wave-like pattern with decreases in 2012 and 2015 and increases in the remaining years. There has never been a year with browsers affected by, on average, fewer than 11 vulnerabilities, and there are more vulnerabilities in 2016 than in 2011 and 2012. The large difference between the upper and lower bounds in 2011 is due to unstable versions of browsers that crash often and unpredictably, combined with the small overall number of APKs for that year.

To quantify how popular browsers differ from the rest, Figure 7b shows the average number of vulnerabilities per year for six popular browsers. While the number of vulnerabilities is uniform when considering all browsers (ranging from 11.5 to 13.4), different browser families exhibit different trends. Firefox has been steadily decreasing in vulnerability since 2013, whereas families like Opera, Dolphin, and Chrome have been increasing. UC Browser exhibits a wave-like pattern and, on average, has the most vulnerabilities among popular browsers in 2016.

Table 6 shows the most popular ABBs for the tested APKs and browser families from 2011 through 2016. We see the evolution from 2011, where all evaluated APKs and browser families were vulnerable to thirteen different ABBs, to the remaining years, where different ABBs, such as #7, #9 (related to how a browser shows a long URL), and #25 (showing mixed-content images), emerge as the most potent. ABBs #7 and #9 are dangerous because they allow attackers to masquerade their websites as trustworthy brands, and ABB #25 can be used to steal session cookies that are not marked with HTTPOnly [40] and use them for session hijacking attacks [9, 36]. On a positive note, while most browsers used to execute JavaScript originating from a mixed inclusion from 2012 to 2014 (ABB #26), this behavior is becoming less common.

Lastly, Figure 8 shows how different classes of vulnerabilities have affected mobile browsers over the years. We see that, while most classes have had a fairly uniform effect on browser APKs, event routing has been increasing in popularity since 2014. Since Hindsight treats every browser as a black box, it cannot provide the reason why event-routing ABBs have become more applicable. Through manual investigation and experimentation, we concluded that one of the main reasons is a vulnerable behavior of the Chromium’s Touch Adjustment feature used in Android’s WebView with SDK version 23, affecting browsers using the embedded WebView component.

#### 5.3 Popularity versus Vulnerability

As described in Section 3.1, the 128 browser families evaluated in this paper range from Google Chrome, with more than a billion installations (Rank 1), to the Shark Browser, with less than 1,000 installations (Rank 13).

In Figure 9a, we explore the correlation between the ranking of each APK and its vulnerability to the five classes of ABBs. We find that the most popular browsers are not necessarily the most secure. In fact, browsers in the last three ranks of popularity (Ranks 10-13) exhibit significantly fewer vulnerabilities than more popular browsers. For example, upon manual inspection of the Shark browser (Rank 13), we found that it never shows a page’s title and always shows the URL bar, regardless of swiping, rotation, and page length. These design choices make the Shark browser not vulnerable to any ABBs in the Address Bar class.

Figure 9b focuses on the vulnerabilities exhibited by the APKs belonging to the six most popular browser families. We observe that 100% of the APKs in all six families have at least one vulnerability, with Chrome and Opera exhibiting similar vulnerability patterns. Firefox appears to be the most secure of the six browsers (confirming the time series presented earlier in Figure 7b), while, next to Firefox, UC Browser and Dolphin are the only browsers not vulnerable to the evaluated Event-Routing ABBs.

#### 5.4 HTTPS

In recent years, HTTPS adoption has increased, partly due to initiatives like Let’s Encrypt, which assists websites in obtaining free-of-charge certificates [25], and search engines using HTTPS as a positive ranking signal [7]. Modern desktop browsers also prioritize HTTPS. In this section, we analyze the evolution of vulnerability patterns for each of our 27 ABBs.

By analyzing the Yes/No results of our ABBs for each version of a given browser family, we discovered that most vulnerability patterns can be categorized into six types: i) always vulnerable (YES), ii) always safe (NO), iii) introduction of a new vulnerability (noYES), iv) removal of an existing vulnerability (yesNO), v) temporary vulnerability (noYESno), and vi) temporary safety (yesNOyes).

Figure 11 shows the distribution of these six patterns for each ABB number and class of vulnerabilities. For some vulnerability classes (like Event Routing and Address Bar), the distribution of patterns is similar across ABBs. Conversely, for vulnerabilities in the Security Indicators class, in addition to ABBs that covary (e.g., #20 and #23), we observe ABBs with clearly different patterns (e.g., #21 and #22). Our findings suggest that for vulnerabilities related to event routing and a browser’s address bar, the corresponding ABBs are interconnected and rely on a single cause (e.g., the handling of touch events and the automatic hiding of the address bar). This is promising because, if true, it allows multiple attacks to be stopped by a few secure design choices. However, this is not the case for ABBs related to Content, URL, and Security indicators, meaning that each vulnerability will likely require a different countermeasure.

Overall, Figure 11 highlights highly undesirable, from a security perspective, cases where YES and noYES patterns dominate, e.g., for ABBs #7, #9, #21, #22, and #25. We also find cases of temporary adoption of insecure features (noYESno) and regression from a secure version to a less secure one (yesNOyes). For example, the Dolphin Browser Express temporarily hid the address bar while the user was giving input, and Opera Mini temporarily showed a page’s title instead of its URL. The Dolphin browser temporarily showed the TLD+1 part of a domain when the URL was long but later reverted to showing the left-most part of a URL. Similarly, the ASUS browser temporarily stopped hiding its address bar when a user was scrolling a long page. These patterns highlight the trade-offs between security and usability, underscoring the need to educate both browser vendors and users about mobile web UI attacks and equip them with tools like Hindsight.