l
a
t
o
T
60000
50000
40000
30000
20000
10000
0
8192
16384 32768 65536 131072 262144
l
u
f
e
s
U
l
a
t
o
T
k
r
o
W
80000
60000
40000
20000
0
15
30
60
120
240
Checkpoint Interval (mins)
  processors = 8192
  processors = 32768
  processors = 131072
  processors = 16384
  processors = 65536
  processors = 262144
(b)
Useful Work Vs Checkpoint Interval for different 
MTTRs  (MTTF per node =1 yr, number of 
processors = 65536)
50000
40000
30000
20000
10000
0
k
r
o
W
l
u
f
e
s
U
l
a
t
o
T
15
30
60
120
240
k
r
o
W
l
u
f
e
s
U
l
a
t
o
T
Number of Processors
Checkpoint Interval (m ins)
MTTR (mins) =  10
MTTR (mins) =  40
MTTR (mins) =  20
MTTR (mins) =  80
 MTTR(mins) = 10
 MTTR(mins) = 20
 MTTR(mins) = 40
 MTTR(mins) = 80
(c)
Useful Work Vs Number of Processors for 
different checkpoint intervals (MTTF per 
node=1 yr, MTTR=10 mins)
(d)
Useful Work Vs Checkpoint Interval for different 
MTTFs (MTTR=10 mins, number of processors = 
65536)
80000
60000
40000
20000
0
l
u
f
e
s
U
l
a
t
o
T
k
r
o
W
60000
50000
40000
30000
20000
10000
0
8192
16384 32768 65536 131072 262144
Number of Processors
15
30
60
120
240
Checkpoint Interval (mins)
chkpt_interval (mins) =  15
chkpt_interval (mins) =  30
chkpt_interval (mins) =  60
chkpt_interval (mins) =  120
chkpt_interval (mins) =  240
(e)
 MTTFper node (yrs) =  1
 MTTFper node (yrs) =  4
 MTTFper node (yrs) =  16
 MTTFper node (yrs) =  2
 MTTFper node (yrs) =  8
(f) 
Variation of Total Useful Work with Number 
of Nodes, Number of Processors/Node = 32
Variation of Total Useful Work with Number 
of Nodes, Number of Processors / Node = 16
k
r
o
W
l
u
f
e
s
U
l
a
t
o
T
500000
400000
300000
200000
100000
0
8192
16384
32768
Numbe r of Node s
k
r
o
W
l
u
f
e
s
U
l
a
t
o
T
250000
200000
150000
100000
50000
0
8192
16384
32768
65536
Num ber of Node s
 MTTFper node(yrs) =  1
 MTTFper node(yrs) =  2
MTTF per node  (yrs) =  1
MTTF per node  (yrs) =  2
(g) 
(h) 
Figure 4: Sensitivity Study of the Base Model
Further,  the  total  useful  work  is  approximately  constant 
for  checkpoint  intervals  between  15  and  30  minutes  but  de-
creases sharply as the checkpoint interval is increased beyond 
30  minutes.  (For  an  MTTF  of  8  years,  the  total  useful  work 
only  decreases  from  43000  job  units4  to  40000  job  units 
when the checkpoint interval is increased from 15 minutes to 
4 One job unit is the amount of work done by a failure-free proces-
sor without checkpointing in unit time. 
30  minutes,  but  it  drops  to  30000 job  units  when  the  check-
point  interval  is  increased  to  60  minutes).  This  suggests  that 
current  checkpoint  intervals  in  the  granularity  of  hours  are 
not  appropriate  for  large-scale  systems  because  of  the  high 
system failure rate. Rather, the checkpoint intervals should be 
between 15 and 30 minutes.   
Useful work fraction. The discussion above only uses to-
tal  useful  work  as  the  performance  metric.  The  useful  work 
fraction  steadily  decreases  as  the  number  of  processors  in-
creases.  This  is  because  the  greater  number  of  processors 
does not contribute to the useful work fraction, and the failure 
effect  degrades  the  useful  work  fraction.  So,  even  when  the 
maximum total useful work is achieved at the optimum num-
ber  of  processors,  the  useful  work  fraction  is  still  small.  For 
example,  for  an  MTTF  of  1  year  per  node  in  Figure  4a,  the 
peak  of  total  useful  work  is  obtained  with  128K  processors, 
for  which 
is  only  about 
56000/131072=42.7%, i.e., over 50% of system time is spent 
in  handing  failures.  Thus,  the  overall  failure  rate  of  the  sys-
tem  must  substantially  decrease  for  the  useful  work  fraction 
to improve significantly.
the  useful  work 
fraction 
Effect of increasing the number of processors per node.
So far, we have assumed that each node has 8 processors and 
that the MTTF of a node is 1 year. In the future, advances in 
semiconductor and processor technology may allow 16 or 32 
processor cores to be integrated on a single node while main-
taining  the  same  MTTF  per  node  of  1  year.  We  studied  the 
variation of total useful work with the number of nodes when 
each  node  has  32  and  16  processors,  respectively  for  a 
per-node MTTF of 1 and 2 years. For a fair comparison, the 
number  of  processors  is  fixed  at  1000K.  The  results  are 
shown in Figure 4g and 4h and are summarized as follows: 
• The  optimum  number  of  processors  is  obtained  by 
multiplying the number of nodes by the number of processors 
per  node.  The  optimum  number  of  processors  is  now  in  the 
range of 500K to 1000K. 
• For a given MTTF, the optimum  number of nodes in-
creases  with  the  number  of  processors  per  node,  as  more 
compute power is provided at the same failure rate. 
• For  a  given  number  of  processors  per  node,  the  opti-
mum  number  of  nodes  increases  as  the  MTTF  increases  be-
cause the failure effect is less dominant 
This  reinforces  the  earlier  observation  that  integrating 
more  processors  per  node  and  maintaining  the  same  node 
failure  rate  increases  total  useful  work.  However,  the  useful 
work  fraction  remains  the  same  (still  less  than  50%),  as  it 
depends  only  on  the  system  failure  rate,  which  in  turn  de-
pends only on the number of nodes and the MTTF per node. 
Effect  of  failures  during  checkpointing/recovery.  We 
also  studied  the  effects  of  failures  during  checkpoint-
ing/recovery  on  system  performance.  We  observed  that  they 
do not exert as significant an effect on the useful  work  frac-
tion  as  do  failures  during  computation.  This  is  because  the 
duration of checkpointing/recovery is much smaller than that 
of  computation  and  hence  incurs  less  loss  of  useful  work. 
Detailed analysis of failures during checkpointing/recovery is 
not presented. 
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
For  the  remainder  of  Section  7,  we  assume  an  increased 
per-node  MTTF  of  3  years,  as  otherwise  the  failure  effects 
dominate the system performance for large numbers of nodes. 
An MTTF of 3 years corresponds to a per-processor MTTF of 
24 years  for our system consisting of 8-processors per node, 
which is close  to the 25-year  MTTF of IBM  mainframes re-
ported in the literature [22]. 
7.2 Effect of Coordination 
The  coordinated  checkpointing  protocol  requires  that  all 
the  compute  processors  arrive  at  a  safe  point  to  take  the 
checkpoint,  and  a  timeout  is  used  to  avoid  waiting  indefi-
nitely. This is not considered in the base model. This section 
first  investigates  the  pure  coordination  effect  without  the 
timeout  mechanism  or  failures  and  then  combines  them  into 
the study. Three main points are observed from the results: 
(cid:151) Coordination  does  not  affect  system  performance  sig-
nificantly,  as  the  coordination  effect  is  logarithmic  in  the 
number of compute processors (Figure 5) because we assume 
the  processors  have  identical  exponentially-distributed  qui-
esce times. So coordination scales well for practical systems. 
(cid:151) Combination of timeout and coordination behaves like 
a  probabilistic  checkpoint-abort.  Small  timeouts  (80s  or  less 
in  Figure  6)  hurt  the  useful  work  fraction,  whereas  large 
timeouts  (100s  or  larger)  do  not  significantly  degrade  the 
useful work fraction.   
(cid:151) As long as the coordination timeout is equal to or lar-
ger than a threshold value, the system performance is insen-
sitive  to  the  timeout  value.  The  threshold  value  is  fairly 
small for practical systems (100s in our experiment). 
Coordination  only. We  assume  that  all  the  processors 
have  identical,  exponentially  distributed  quiesce  times  with 
a  mean  of  MTTQ  (Mean  Time  To  Quiesce  per  processor). 
Figure 5 illustrates the pure coordination effect on the useful 
work  fraction  for  different  MTTQs.  Failures  and  timeouts 
are not considered. According to the figure, the coordination 
effects are logarithmic in the number of compute processors. 
This  is  because  an  identical  exponential  distribution  is  as-
sumed for each processor. Moreover, the rate of increase of 
coordination time (or overall quiesce time) is proportional to 
the  MTTQ,  and  the  coordination  effect  is  also  proportional 
to the checkpoint frequency (figures not shown here). 
Effects of failures and timeouts. Figure 6 shows the sys-
tem performance in the presence of  failures  with an MTTF 
of 3 years per node, checkpoint interval of 30 minutes, and 
MTTQ of 10 seconds. We use “no coordination” to indicate 
the  case  when  no  variation  in  the  quiesce  times  among  the 
compute processors is assumed and the quiesce time of the 
system as a  whole is exponentially distributed  with a  mean 
of 10 seconds. 
Figure  6  shows  that  the  coordination  without  a  timeout 
mechanism  does  not  significantly  degrade  system  perform-
ance, because the only additional overhead is the small coor-
dination time. If a timeout is applied, the master may time out 
before  the  coordination  is  completed  and  abort  the  check-
pointing.  Then,  if  a  failure  occurs  in  the  next  computation 
interval,  it  causes  the  computation  completed  in  the  last  in-
terval  to  be  lost.  So  the  combination  of  coordination  and 