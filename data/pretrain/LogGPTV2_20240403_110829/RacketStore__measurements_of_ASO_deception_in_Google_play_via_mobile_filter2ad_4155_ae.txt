the exposure of their personal information to threats. In § 6.4 we
show that workers expressed awareness and concern about mal-
ware apps. Further, to avoid detection, workers will be forced to
register fewer accounts and post fewer reviews for promoted apps
from these accounts. This can significantly reduce the amount of
fraud posted, thus reduce worker profits from ASO activities.
Recruitment Bias. We contacted ASO workers using Facebook
groups dedicated to product promotion, and recruited only those
who responded, were English speakers, and were willing to partici-
pate after approving the consent form. Our Instagram recruitment
process reached 61,748 Instagram users who speak English, are of
restricted age, show interests related to Android applications, and
were willing to participate after approving the consent form.
To reduce the impact of cultural factors in our analysis, we
have attempted to recruit both workers and regular users from
roughly the same regions. While the distribution of workers and
regular users is not uniform for most countries of our participants,
96% of the worker devices and 92% of the regular devices seem
to be (according to the unreliable IP-based geolocation) from the
geographically close Pakistan, India and Bangladesh.
We do not claim that our results generalize to all workers and
regular users, including from the same and other countries. Further,
workers accessible through other recruitment channels, e.g., [13]
may have different behaviors and strategies. A larger scale recruit-
ment process may identify further types of ASO workers and more
Figure 14: Top 10 most important features for the device clas-
sifier, measured by mean decrease in Gini. This suggests that
devices controlled by workers are distinguishable from reg-
ular devices on their total number of apps reviewed, percent-
age of apps used suspiciously, and number of stopped apps.
Figure 15: Scatterplot of 178 worker-controlled devices
(one dot per device): app suspiciousness vs. the number
of apps installed and reviewed from accounts registered
on the device. This reveals that classifiers can detect a
range of worker-controlled devices that includes promotion-
dedicated devices and devices with organic-indicative usage.
be used for personal purposes. The remaining 55 devices seem to
have been used exclusively for app promotion purposes: all their
apps have promotion-indicative behaviors, their median number of
Gmail accounts is 31 (M = 37.18, max = 114), and have a median of
23 stopped apps (M = 66.23).
We have manually investigated the devices with high but under
100% app suspiciousness, and confirmed that such devices are likely
to have installed and used apps for personal purposes. Examples
include train ticketing apps used at similar times over multiple days,
photo gallery apps used in alternation with video players, Samsung
pre-installed messaging (com.samsung.android.messaging) and
call (com.samsung.android.incallui) apps, and music apps such
as Google Play Music being used every day.
However, the classifiers were able to accurately detect even
worker-controlled devices with low app suspiciousness, that may
belong to novice workers.
9 DISCUSSION AND LIMITATIONS
Who Should Deploy RacketStore? The classifiers proposed in
§ 7 and 8 need more information than what is made publicly avail-
able by app stores (e.g., via the Google APIs). Thus, the classifiers
650
Related efforts also include extensive work to detect malware
Android apps, e.g., [29, 41, 54, 60, 61, 69–71, 95]. Notably, Yang et
al. [91] differentiate malware from benign apps based on the con-
texts that trigger security-sensitive behaviors. RacketStore detects
ASO-promoted apps and devices of workers based on the context
of the user interaction with them. While we seek to detect worker
interactions with apps, we note that ASO work has been shown to
be used to promote malware apps and improve their search rank,
thus increase their consumer appeal [68].
Our study of the fraud market for Google services is related to
other exploration of fraud markets [55, 74–76]. For instance, Dou et
al. [37] developed a honeypot app and collect data to detect fraudu-
lent bot-generated downloads. Mirian et al. [55] explore the market
for Gmail account hijacking by creating synthetic but realistic vic-
tim personas and hiring services to hack into such accounts, while
DeBlasio et al. [36] characterize the search engine fraud ecosys-
tem using ground truth data internal to the Bing search engine.
Stringhini et al. [74] studied Twitter follower markets by purchasing
followers from different merchants and used such ground truth to
discover patterns and detect market-controlled accounts in the wild.
In this paper we leverage our finding of an abundant fraud market
for Google services (i.e., review groups with tens of thousands of
members) to recruit hundreds of worker-controlled devices, study
their usage, and propose solutions to detect and distinguish them
from devices used for personal purposes.
11 CONCLUSIONS
In this paper we have developed RacketStore, the first platform to
collect detailed app and device usage information from the devices
of app search optimization workers and regular users of Google
Play services. We have presented empirical data from RacketStore
installs on 803 devices and from interviews with some of their own-
ers. We have developed a classifier to identify apps installed solely
to be promoted and we have shown that on our data, it achieves
an F1-measure that exceeds 99%. We have shown that features that
model the user interaction with a device can be used to detect even
organic devices with low levels of ASO work hidden among per-
sonal activities. Our techniques are resilient to worker strategy
modifications, that would impose high overhead on the operation
of their devices and the usage of the apps that they promote.
12 ACKNOWLEDGMENTS
This research was supported by NSF grants CNS-2013671 and CNS-
2114911, and CRDF grant G-202105-67826. This publication is based
on work supported by a grant from the U.S. Civilian Research &
Development Foundation (CRDF Global). Any opinions, findings
and conclusions or recommendations expressed in this material are
those of the author(s) and do not necessarily reflect the views of
CRDF Global.
diverse regular users. However, the data that we collected from 803
participant devices provides evidence on the ability of device and
app usage data to detect the devices controlled, and the reviews
posted by different types of workers.
Classifier Performance. Several machine learning algorithms
achieve an F1-measure that exceeds 99% for the app classification
problem (§ 7.2), while one algorithm achieved an F1-measure over
95% for the device classification problem (§ 8.2). The investigation
in § 6 provides an intuition for the ability of several features to
help classifiers distinguish between apps and devices used for per-
sonal purposes vs. ASO work. This suggests that these algorithms
did not overfit the data. Further, the success of these classifiers
suggests that standard ML algorithms are suitable and preferable
for these classification problems, where they can provide valuable
interpretation.
We acknowledge however that the relatively small and biased
data that we used to train the app and device classifiers (see recruit-
ment bias above) may lead to reduced applicability to data from
other ASO workers and regular users.
Influence of RacketStore on Participant Behaviors.
Knowledge of being monitored might have influenced participant
behaviors. We note however that all participants, including ASO
workers and regular users, installed the same version of RacketStore
and were provided with the same information before and during
the study. Further, our classifiers were able to distinguish between
apps and devices used by ASO workers and regular users, even if
ASO workers attempted to modify their behaviors during the study.
10 RELATED WORK
Farooqi et al. [38] studied the market of incentivized app install
platforms (IIP) through a honey app that collects the device id, the
list of installed apps and events such as opening the app and in-app
interaction. We leverage Farooqi et al. [38]’s finding of a lack of
interest in the app among the workers that installed it for money.
RacketStore extends Farooqi et al. [38]’s work by collecting and
analyzing additional key data that notably includes the list of user
accounts registered on the participant device, the reviews posted
from those accounts, and the foreground app at 5s intervals. This
data enables us to claim a first success in identifying organic ASO
activities. Further, our study involved diverse types of ASO workers
that we recruited from Facebook groups, and regular users that we
recruited using Instagram ads.
Our work is particularly relevant in light of findings that some
ASO workers have evolved strategies [67, 94] to evade detection
by both app stores and academic solutions, e.g., [27, 28, 32, 32,
35, 39, 40, 42, 44, 45, 48, 50, 51, 51–53, 53, 57–59, 72, 73, 78, 84–
89, 92, 92, 93]. For instance, Zheng et al. [94] report the emergence
of organic workers who attempt to mimic the behavior of real users.
Rahman et al. [67] provide insights from studied ASO workers, that
confirm the existence of organic workers in the wild. In this paper
we provide measurements from devices of ASO workers and regular
Android users. Our data suggests that the use of apps installed for
promotion differs from that of apps used for personal purposes.
Further, even organic workers tend to use their devices in a manner
that distinguishes them from regular users.
651
https://boostyourapps.org/.
//www.tensorflow.org/lite.
[4] [n. d.]. Deploy machine learning models on mobile and IoT devices. https:
[5] [n. d.]. Google Digital Wellbeing. https://wellbeing.google/tools/.
[6] [n. d.]. Google Play. https://play.google.com/store?hl=en.
[7] [n. d.]. MobiASO: Mobile App Marketing Agency. https://mobiaso.com/.
[8] [n. d.]. Number of Android apps on Google Play: 2,969,894. AppBrain, https:
//www.appbrain.com/stats/number-of-android-apps, month=.
[9] [n. d.]. Permissions Overview. https://bit.ly/2x4HKiW.
[10] [n. d.]. RacketStore Code. https://github.com/nestorghh/racketstore.
[11] [n. d.]. Ratings and Reviews on the Play Store. https://play.google.com/about/
REFERENCES
[1] [n. d.]. 15 U.S. Code § 45 - Unfair methods of competition unlawful; prevention by
Commission. Legal Information Institute, https://www.law.cornell.edu/uscode/
text/15/45.
[2] [n. d.]. Apple Media Services Terms and Conditions. https://www.apple.com/
legal/internet-services/itunes/us/terms.html.
[3] [n. d.]. Boostyourapps: Buy App Reviews and Get Installs and Rating for Free.
[12] [n. d.].
Retention Rate Meaning.
https://www.adjust.com/glossary/
[13] [n. d.]. TapJoy: Mobile Advertising and App Monetization Platform. https:
comment-posting-policy/.
retention-rate/.
//www.tapjoy.com/.
[14] [n. d.]. Untrue, misleading or unauthorized use of tests and testimonials. https:
//www.competitionbureau.gc.ca/eic/site/cb-bc.nsf/eng/00527.html.
[15] [n. d.]. VirusTotal. https://www.virustotal.com/gui/home.
[16] 2005. Directive 2005/29/EC of the European Parliament and of the Council.
Official Journal of the European Union, https://eur-lex.europa.eu/LexUriServ/
LexUriServ.do?uri=OJ:L:2005:149:0022:0039:en:PDF.
[17] 2012. Cell phone culture: How cultural differences affect mobile use. CNN
Business, https://www.cnn.com/2012/09/27/tech/mobile-culture-usage/.
[18] 2018. Freedom on the Net, Bangladesh. Freedom House, https://freedomhouse.
org/report/freedom-net/2018/bangladesh.
[20] 2018.
[19] 2018. Journalists, activists in Bangladesh arrested under ICT Act for posting on
social media. AccessNow, https://www.accessnow.org/bangladesh-ict-act/.
No Place for Criticism. Bangladesh Crackdown on Social Me-
dia Commentary. https://www.hrw.org/report/2018/05/09/no-place-criticism/
bangladesh-crackdown-social-media-commentary.
[21] 2020. AndroidID. , https://developer.android.com/reference/android/provider/
Settings.Secure.html#ANDROID_ID.
[22] 2020. Mobile Application Market Size, and Trends Analysis Report By Store Type
(Google Store, Apple Store), By Application (Gaming, Music and Entertainment,
Health and Fitness), By Region, And Segment Forecasts, 2020 - 2027. https:
//www.grandviewresearch.com/industry-analysis/mobile-application-market.
[23] 2020. Privacy, Security, and Deception. Developer Policy Center, https://play.
google.com/about/privacy-security-deception/user-data/.
[24] 2021. Mobile App Download and Usage Statistics (2021). BuildFire, https://
buildfire.com/app-statistics/.
[25] 2021. What is App Store Optimization? Ultimate Guide to ASO in 2021. App Radar,
https://appradar.com/academy/aso-basics/what-is-app-store-optimization-aso.
[26] Syed Ishtiaque Ahmed, Md. Romael Haque, Shion Guha, Md. Rashidujjaman Rifat,
and Nicola Dell. 2017. Privacy, Security, and Surveillance in the Global South: A
Study of Biometric Mobile SIM Registration in Bangladesh. In Proceedings of the
2017 CHI Conference on Human Factors in Computing Systems (CHI ’17). 906–918.
[27] Prudhvi Ratna Badri Satya, Kyumin Lee, Dongwon Lee, Thanh Tran, and Ja-
son (Jiasheng) Zhang. 2016. Uncovering Fake Likers in Online Social Networks.
In Proceedings of the 25th ACM International on Conference on Information and
Knowledge Management (CIKM ’16). Association for Computing Machinery, New
York, NY, USA, 2365–2370. https://doi.org/10.1145/2983323.2983695
[28] Alex Beutel, Wanhong Xu, Venkatesan Guruswami, Christopher Palow, and Chris-
tos Faloutsos. 2013. CopyCatch: Stopping Group Attacks by Spotting Lockstep
Behavior in Social Networks. In Proceedings of the 22nd International Conference
on World Wide Web (WWW ’13). Association for Computing Machinery, New
York, NY, USA, 119–130. https://doi.org/10.1145/2488388.2488400
[29] A. Bianchi, J. Corbetta, L. Invernizzi, Y. Fratantonio, C. Kruegel, and G. Vigna.
2015. What the App is That? Deception and Countermeasures in the Android
User Interface. In 2015 IEEE Symposium on Security and Privacy. 931–948. https:
//doi.org/10.1109/SP.2015.62
[30] Dearbhail Bracken-Roche, Emily Bell, Mary Ellen Macdonald, and Eric Racine.
2017. The concept of ‘vulnerability’in research ethics: an in-depth analysis of
policies and guidelines. Health research policy and systems 15, 1 (2017), 8.
[31] Leo Breiman. 2001. Random Forests. Mach. Learn. 45, 1 (2001), 5–32. https:
//doi.org/10.1023/A:1010933404324
[32] Qiang Cao, Xiaowei Yang, Jieqi Yu, and Christopher Palow. 2014. Uncovering
Large Groups of Active Malicious Accounts in Online Social Networks. In Pro-
ceedings of the 2014 ACM SIGSAC Conference on Computer and Communications
Security (CCS ’14). Association for Computing Machinery, New York, NY, USA,
477–488. https://doi.org/10.1145/2660267.2660269
[33] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer. 2002. SMOTE:
Synthetic Minority Over-sampling Technique. Journal of Artificial Intelligence
Research 16 (2002).
[34] Erika Chin, Adrienne Porter Felt, Vyas Sekar, and David Wagner. 2012. Mea-
suring User Confidence in Smartphone Security and Privacy. In Proceedings
of the Eighth Symposium on Usable Privacy and Security (SOUPS ’12). Asso-
ciation for Computing Machinery, New York, NY, USA, Article 1, 16 pages.
https://doi.org/10.1145/2335356.2335358
[35] Emiliano De Cristofaro, Arik Friedman, Guillaume Jourjon, Mohamed Ali Kaafar,
and M. Zubair Shafiq. 2014. Paying for Likes? Understanding Facebook Like Fraud
Using Honeypots. In Proceedings of the 2014 Conference on Internet Measurement
Conference (IMC ’14). Association for Computing Machinery, New York, NY, USA,
129–136. https://doi.org/10.1145/2663716.2663729
[36] Joe DeBlasio, Saikat Guha, Geoffrey M. Voelker, and Alex C. Snoeren. 2017.
Exploring the Dynamics of Search Advertiser Fraud. In Proceedings of the 2017
Internet Measurement Conference (IMC ’17). Association for Computing Machinery,
New York, NY, USA, 157–170. https://doi.org/10.1145/3131365.3131393
[37] Yingtong Dou, Weijian Li, Zhirong Liu, Zhenhua Dong, Jiebo Luo, and Philip S. Yu.
2019. Uncovering Download Fraud Activities in Mobile App Markets. In Proceed-
ings of the 2019 IEEE/ACM International Conference on Advances in Social Networks
Analysis and Mining (ASONAM ’19). Association for Computing Machinery, New
York, NY, USA, 671–678. https://doi.org/10.1145/3341161.3345306
[38] Shehroze Farooqi, Álvaro Feal, Tobias Lauinger, Damon McCoy, Zubair Shafiq,
and Narseo Vallina-Rodriguez. 2020. Understanding Incentivized Mobile App
Installs on Google Play Store. In Proceedings of the ACM Internet Measurement
Conference (IMC ’20). Association for Computing Machinery, New York, NY, USA,
696–709. https://doi.org/10.1145/3419394.3423662
[39] Amir Fayazi, Kyumin Lee, James Caverlee, and Anna Squicciarini. 2015. Uncov-
ering Crowdsourced Manipulation of Online Reviews. In Proceedings of the 38th
International ACM SIGIR Conference on Research and Development in Information