3.2 Spatial Anomography
Data elements in high dimensional data sets, such as the
link load observations, usually have dependencies. The in-
trinsic dependency structure among the data elements can
thus be exploited for ﬁltering anomalous behavior by dis-
covering data points that violate the normal dependency
structure.
In our context, the process of detecting such
data points can be performed by left-multiplication by a
transformation matrix T such that ˜B = T B. An exam-
ple of such an approach is a recent study by Lakhina et al.
[19], where Principal Component Analysis (PCA) is used
in ﬁnding dominant patterns. We describe this method, and
in particular its instantiation as a left-multiplication opera-
tion in the following section.
3.2.1 Spatial PCA
In [19], Lakhina et al. proposed a subspace analysis of link
trafﬁc for anomaly detection, which can be summarized as
follows.
1.
Identify a coordinate transformation of B such that the
link trafﬁc data under the new coordinate systems have
the greatest degree of variance along the ﬁrst axis, the
second greatest degree of variance along the second
axis, and so forth. These axes are called the principal
axes or principal components.
Recall that B = [b1 b2 · · · bt] is the collection of link
trafﬁc data at m links over t time intervals, where each
row i (1 ≤ i ≤ m) denotes the time series of the i-
th link and each column j (1 ≤ j ≤ t) represents an
instance of all the link loads at time interval j. The
principal components, v1, v2, ..., vm can be computed
iteratively as follows:
vk = argmax
kvk=1
BT −
BT vivT
i
v
The coordinate transformation matrix can thus be ob-
tained by arranging the principal components as rows
of a matrix P = [v1 v2...vm]T .
2. Divide the link trafﬁc space into the normal subspace
and the anomalous subspace. Lakhina et al. [19] devel-
oped a threshold-based separation method by examin-
ing the projection of the time series of link trafﬁc data
(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)
k−1X
i=1
!
(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)
on each principal axis in order. As soon as a projection
is found that contains a 3σ deviation from the mean,
that principal axis and all subsequent axes are assigned
to the anomalous subspace. All previous principal axis
are assigned to the normal subspace.
We use Pa = [vr vr+1...vm]T to denote the matrix of
the principal axes in the anomalous subspace, where vr
is the ﬁrst axis that fails to pass the threshold test.
a Pa.
3. The anomalous trafﬁc can now by extracted from link
load observation by ﬁrst projecting the data into the
anomalous subspace and then transforming it back, by
taking ˜B = (P T
a Pa)B, and so we obtain the transfor-
mation matrix T = P T
We call the above method spatial PCA because it ex-
ploits the correlation between trafﬁc on different links
(across space). Later in Section 3.3.4, we will describe
temporal PCA, which exploits temporal correlation by ap-
plying PCA to identify dominant patterns across time.
3.3 Temporal Anomography
The anomalous link trafﬁc can also be separated by per-
forming temporal analysis on the time series for each link.
Consider a set of link trafﬁc data over time t: B =
[b1 b2...bt]. The process of extracting anomalies by ex-
ploiting the temporal structure within the data points can
be modeled as a linear transformation of the time series:
˜b2...˜bt] = BT , where the transformation ma-
˜B = [˜b1
trix T can be either explicit or implicit.
In this paper,
we consider four types of temporal analysis: ARIMA,
Fourier, Wavelet, and PCA (for identifying dominant pat-
terns across time). Although it may not be obvious at ﬁrst
glance, all these methods indeed ﬁt in our framework of
linear matrix transformation, as we will see next.
3.3.1 ARIMA Modeling
Univariate time series. The Box-Jenkins methodology,
or AutoRegressive Integrated Moving Average (ARIMA)
modeling technique [2, 3], is a class of linear time-series
forecasting techniques that capture the linear dependency
of the future values on the past. It is able to model a wide
spectrum of time-series behavior, and has been extensively
used for anomaly detection in univariate time-series.
An ARIMA model includes three order parameters: the
autoregressive parameter (p), the number of differencing
passes (d), and the moving average parameter (q).
In
the notation introduced by Box and Jenkins, models are
summarized as ARIMA(p, d, q). A model described as
ARIMA(0, 1, 2) means that it contains p = 0 (zero) au-
toregressive parameters and q = 2 moving-average param-
eters which were computed for the time series after it was
differenced once (d = 1).
A general ARIMA model of order (p, d, q) can be ex-
pressed as:
zk −
pX
i=1
φi · zk−i = ek −
qX
j=1
θj · ek−i,
(5)
320
Internet Measurement Conference 2005 
USENIX Association
where zk is obtained by differencing the original time series
d times (when d ≥ 1) or by subtracting the mean from the
original time series (when d = 0), ek is the forecast error
at time k, φi (i = 1, ..., p) and θj (j = 1, ..., q) are the au-
toregression and moving-average coefﬁcients, respectively.
Many commonly used smoothing models are special in-
stances of ARIMA models. For example, the Exponen-
tially Weighted Moving Average (EWMA), is equivalent to
ARIMA(0, 1, 1); linear exponential smoothing, also known
as Holt-Winters, is equivalent to ARIMA(0, 2, 2). See [26]
for detailed equations for various smoothing models and
their equivalence with ARIMA models.
There are well known techniques for estimating the pa-
rameters p, d, q, φi and θj for a given time series [2, 3],
and given the parameters, the model is simply applied to
get ˆzk a prediction of zk (using for instance the Durbin-
Levinson algorithm [3]). The prediction errors are then
ek+1 = zk+1 − ˆzk+1, which then form our anomalous traf-
ﬁc (the trafﬁc which does not ﬁt the model). In practice the
parameters used in the ARIMA model are sometimes cho-
sen to meet particular goals intended by the implementor
(see [4] for some discussion of these choices), rather than
being estimated from the data set, because the parameters
of a data set may change over time. However, we prefer to
use adaptive techniques to overcome this problem.
If we consider the time series to be vectors of length t,
then the above results can be written in matrix form. Tak-
ing the measurements b = (b1, . . . , bt)T , we can obtain
the errors e = (e1, . . . , et)T , via right-multiplication by a
transformation matrix ˜bT = eT = bT T . Speciﬁcally, let I
denote the t × t identity matrix, 5 denote the “back shift”
matrix, and 11 denote the t × t unit matrix, i.e.,
6664
zT =
2
1 0 0...0 0
0 1 0...0 0
I =
· · ·
0 0 0...1 0
0 0 0...0 1
3
, 5 =
7775
2
6664
0 1 0...0 0
0 0 1...0 0
· · ·
0 0 0...0 1
0 0 0...0 0
3
7775
, 11 =
2
6664
1 1 1...1 1
1 1 1...1 1
· · ·
1 1 1...1 1
1 1 1...1 1
3
7775
.
The differencing result, z = [z1z2...zt]T , is then
bT (I − 5)d,
bT 11 = bT (cid:18)I −
bT −
1
t
11(cid:19) ,
1
t
for d ≥ 1,
for d = 0.
(6)
Equation (5) can be written in matrix notation as
pX
qX
zT −
φizT 5i = eT −
θj eT 5j,
i=1
j=1
or equivalently,
eT = zT  
I −
φi5i!
I −
pX
i=1
qX
j=1
−1
.
θj5j
Extending ARIMA based models to multivariate time se-
ries is straightforward. As noted earlier, we construct the
matrix B with the measurements at each time period bi as
its columns. Via the above transformations, we obtain
pX
i=1
I −
φi5i!
I −
qX
j=1
θj5j
−1
E = Z
.
(7)
ARIMA based anomography. Replacing Z by the matrix
form of (6), we see that E = BT is indeed a transforma-
tion given by right-multiplying B with a matrix T . In fact,
any linear ﬁltration of the elements of a time series can be
modeled by a right multiplying matrix transformation.
To get back to anomaly detection, we simply identify the
forecast errors as anomalous link trafﬁc, ˜B = E. That is,
trafﬁc behavior that cannot be well captured by the model
is considered anomalous.
3.3.2 Fourier Analysis
Fourier analysis [21] is the process of decomposing a com-
plex periodic waveform into a set of sinusoids with differ-
ent amplitudes, frequencies and phases. The sum of these
sinusoids can exactly match the original waveform. This
lossless transform presents a new perspective of the signal
under study (in the frequency domain), which has proved
useful in very many applications.
For a discrete-time signal x0, x1, . . . , xN −1, the Discrete
Fourier Transform (DFT) is deﬁned by
fn =
1
N
N −1X
k=0
xke−jk2πn/N ,
for 0 ≤ n ≤ N − 1,
where fn is a complex number that captures the ampli-
tude and phase of the signal at the n-th harmonic frequency
(with base frequency 1/N ). Note that for a real signal {fn}
is symmetric, i.e., fn = fN −1−n. Lower n corresponds to
a lower frequency component, with f0 being the DC com-
ponent, or the average of the input series, and fn with n
close to N/2 corresponding to high frequencies.
The Inverse Discrete Fourier Transform (IDFT) is used
to reconstruct the signal in the time domain by
N −1X
xn =
fkejk2πn/N ,
for 0 ≤ n ≤ N − 1.
k=0
An efﬁcient way to implement the DFT and IDFT
is through an algorithm called the Fast Fourier Trans-
form (FFT). The computational complexity of the FFT is
O(N log(N )).
FFT based anomography.
The idea of using the FFT
to extract anomalous link trafﬁc, ˜B is to ﬁlter out the low
frequency components in the link trafﬁc time series.
In
general, low frequency components capture the daily and
weekly trafﬁc patterns, while high frequency components
represent the sudden changes in trafﬁc behavior. Working
in the frequency domain provides us with the opportunity
to distinguish these two kinds of behaviors.
We summarize FFT based anomography as follows.
USENIX Association
Internet Measurement Conference 2005  
321
1. Transform link trafﬁc B into the frequency domain:
F = FFT(B): apply the FFT on each row of B. (Recall
that a row corresponds to the time series of trafﬁc data
on one link.) The result is the corresponding frequency
domain series, in each row of F .
i.e.
2. Remove low frequency components:
set Fi =
0, for i ∈ [1, c] ∪ [N − c, N ], where Fi is the i-th col-
umn of F and c is a cut-off frequency. (For example,
for the results presented in Section 6, we use 10-minute
aggregated link trafﬁc data of one week duration, and
c = d 10
60 N e, corresponding to a frequency of one cycle
per hour.)
3. Transform back into the time domain: i.e. we take ˜B =
IFFT(F ). The result is the high frequency components
in the trafﬁc data, which we will use as anomalous link
trafﬁc, ˜B.
The DFT and IDFT may be represented as right-matrix
products. In setting columns of F to zero, and performing
the IDFT we are taking a linear combination of the columns
of F , which in turn are a linear combination of those of B.
Hence, the overall process above can be modeled as a right-
multiplying matrix transformation ˜B = BT . Note also that
in thresholding at frequency c we preserve the symmetry of
F , and so although F may contain complex elements, the
resulting transform will be real.
3.3.3 Wavelet Analysis
Wavelets [7, 12, 21] are mathematical functions that cut up
data into different frequency components, and then study
each component with a resolution matched to its scale.
They provide a powerful means for isolating characteris-
tics of signals via a combined time-frequency representa-
tion and are often considered superior to traditional Fourier
methods especially in situations where the signal contains
transients, such as discontinuities and sharp spikes.
In [1], Barford et al. have developed a wavelet-based
algorithm for detecting anomalies in the link trafﬁc data.
It shares the same principle as the FFT based approaches
— exposing anomalies by ﬁltering low frequency compo-
nents. More speciﬁcally, it uses wavelets to decompose the
original signal into low-, mid-, and high-frequency compo-
nents and then detects anomalies by close examination of
the mid- and high-frequency components.
Below we compute ˜B as the high-frequency components
of link trafﬁc B. We can also compute ˜B as the mid-
frequency components of B in essentially the same way.
1. Use wavelets to decompose B into different frequency
levels: W = WAVEDEC(B), by applying a multi-level
1-D wavelet decomposition on each row of B. The re-
sult is a wavelet decomposition vector, which we save
as one row in matrix W . The wavelet we use is the