I have several groupby problems crop up regularly at work**, and almost always
have to write custom functions for operating on individual groups - which are
then very slow to execute.
Looking for solutions, I came across  
http://esantorella.com/2016/06/16/groupby/  
and the update  
https://github.com/esantorella/hdfe/blob/master/groupby.py
I had to adapt my function a little bit to be compatible with numpy- instead
of pandas-indexing, but in one case I tested today, this sped up my code by
_more than a factor 100_ , and this wasn't even for the full dataset. In fact
(for ~5mio rows), the pandas-native version didn't finish in 2h, whereas the
adaptation based on the code linked above ran in ~35sec.
It would be very nice if such optimisations would be taken care of directly by
pandas, instead of having to work around like this.
** one example among many: process data from source, deduplicate based on a
given signature, process further, keep deduplicated record. Updates to this
record need to recalculate any time one of the constituent records has changed