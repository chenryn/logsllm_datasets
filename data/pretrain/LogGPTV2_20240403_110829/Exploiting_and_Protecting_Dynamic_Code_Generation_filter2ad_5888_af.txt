### Overhead Comparison Between Free and Pinned Scheduling

The overhead observed under free scheduling is significantly higher compared to pinned scheduling. This discrepancy can be attributed to the fact that the two benchmarks in question are more reliant on data (memory) access. It is important to note that, unlike Strata, for the SDCG-ported V8, we not only shared the code cache but also the heaps used to store JavaScript objects. This sharing was done to facilitate the implementation of remote procedure calls (RPCs). In addition to the frequency of RPCs, this shared memory architecture is another contributing factor to the increased overhead observed when compared to the SDCG-ported Strata.

### Discussion

In this section, we will explore the limitations of our work and potential directions for future research.

#### A. Reliability of Race Conditions

Although we have demonstrated the feasibility of the attack in a single scenario, the dynamic translator can be invoked under various conditions, each with its own race condition window. Some operations, such as patching, can be executed quickly, while others may take longer. By carefully controlling the invocation of the translator, we can extend the race condition window, thereby making such attacks more reliable.

Additionally, operating system (OS) scheduling can influence the size of the attack window. For example, as discussed in Section III, the invocation of `mprotect` is likely to cause a significant delay, which can be exploited to increase the attack window.

### Hardware Awareness

Our current prototype implementations of SDCG are not hardware-aware. Different processors have varying shared cache architectures and cache management capabilities, which can affect cache synchronization between different threads. Specifically, in a multi-processor system, two cores may or may not share the same cache. As demonstrated, if the translator thread and the execution thread are scheduled to cores with different caches, the performance is significantly worse than when they are scheduled to cores with the same cache. To further reduce the overhead, we can assign processor affinity based on hardware features.

### Conclusion

In this paper, we highlighted that a code cache injection attack is a viable exploit technique capable of bypassing many state-of-the-art defense mechanisms. To counter this threat, we proposed SDCG, a new architecture that enforces a mandatory WâŠ•X policy. To demonstrate the feasibility and benefits of SDCG, we ported two software dynamic translators, Google V8 and Strata, to this new architecture. Our development experience showed that SDCG is easy to adopt, and our performance evaluation indicated that the overhead is minimal.

### Acknowledgements

The authors would like to thank the anonymous reviewers for their valuable feedback and our operations staff for their proofreading efforts. This work was supported in part by the National Science Foundation under Grants No. CNS-1017265, CNS-0831300, and CNS-1149051, by the Office of Naval Research under Grant No. N000140911042, by the Department of Homeland Security under contract No. N66001-12-C-0133, and by the United States Air Force under Contract No. FA8650-10-C-7025. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation, the Office of Naval Research, the Department of Homeland Security, or the United States Air Force.

### References

[References are listed as provided, without changes.]

This revised text aims to improve clarity, coherence, and professionalism, ensuring that the content is well-structured and easy to understand.