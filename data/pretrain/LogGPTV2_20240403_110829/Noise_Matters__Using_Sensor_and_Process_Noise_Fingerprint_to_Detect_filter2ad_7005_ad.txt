= (Cek + ηk) + β(Cek + ηk) + α, which can also
be represented as r∗
k
= (β + 1)(rk) + α. Using definition 1,
k
we can see that mean for such a residual vector is changed
to ¯r∗
2
r . It is
k
proved that if we use noise pattern in residual vector as a
fingerprint, any kind of sensor data injection attack can be
detected. This completes the proof.
■
= α + (β + 1)¯rk and variance S
r ∗ = (β + 1)2
2
= α + ¯rk.
S
k
4 EXPERIMENTATION SETUP AND
EVALUATION
4.1 Secure Water Treatment Testbed (SWaT)
The experiments are carried out in a state-of-the-art water treat-
ment testbed called SWaT [26]. A pictorial abstraction of the SWaT
testbed is shown in Figure 5. SWaT imitates the complete process
of a real water treatment plant and it produces 5 gallons/minute
filtered water.
4.2 Feature Extraction and Learning Phase on
Normal Data
After obtaining the system model for SWaT testbed and calculating
the residual vector for each sensor, the next step is to train a machine
learning algorithm to find out anomalies. We used LibSVM [9] to
classify the dataset into normal or anomalous behavior. To prepare
data for classification, we extract a set of eight features as shown
in Table 2 from the residual vector. These extracted features are
labeled with a sensor ID (ground truth). For each sensor, SVM is
used as a 2-class classifier by labeling the data from the rightful
sensor (ground truth) as 1 and 0 for rest of sensors. This way attacks
can be treated as kind of data from other class. A machine learning
model is trained on a normal dataset collected over a period of
seven days and validated the obtained machine learning model
using cross validation approach. Since attacked data is not available
beforehand, supervised learning could miss some of the attacks. To
deal with this problem, a one-class SVM classifier is used to train
the machine learning model on one class of normal data and in the
testing phase, anything else would be declared as an attack. Results
for these experiments are presented in the following section.
4.3 Results
Following research questions are formulated and answered in this
work.
based sensor fingerprint exist?
• RQ1: Proof of Fingerprint. Does sensor and process noise-
• RQ2: Attack Detection Delay. What is the right amount of
data to detect correct sensor ID with the highest accuracy?
• RQ3: How the amount of training and testing data affects
• RQ4: How well the proposed technique can detect network
sensor identification performance?
attacks on sensor measurements?
RQ1: Proof of fingerprint. Does sensor and process noise-based
sensor fingerprint exist? In Figure 6 we can see statistical features of
the residual vector for two sensors in stage 1 of SWaT testbed. We
observe that both the sensors can be uniquely identified based on
the noise profile contained in the residual vector. Figure 6 shows that
using the three features namely mean, variance and mean average
deviation can help us distinguish between two sensors. This visual
representation is proof of the existence of a noise-based fingerprint.
-5051015Residual Value00.20.40.60.811.21.41.61.8Residual PDF LIT101 = 2,=2 = 2,=4 = 2,=5 = 2,=10 = 0,=0 (No Attack)01234k (s)105-20246810121416Residual ValueResidual Value LIT101 = 2,=2 = 2,=4 = 2,=5 = 2,=10 = 0,=0 (No Attack)573Noise Matters
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Figure 5: Secure Water treatment testbed (SWaT): P1 though P6 indicate the six stages in the treatment process. Arrows denote
the flow of water and of chemicals at the dosing station.
Table 3: Different data chunk size and accuracy of the classifier. This experiment is to establish a trade off between classifier
accuracy and amount of data required to make a classification decision.
↓ Sample Size / Sensor →
60
120
250
500
2000
S1
S2
94.6%
S3
S4
S5
S6
S7
S8
S9
S10
S11
S12
S13
S14
S15
S16
S17
S18
96.5839% 94.6427%
95.9593% 94.5721% 94.6205% 94.5721% 100% 94.5721% 99.1053% 96.3729% 94.9045% 94.5721% 94.5721% 94.6189% 94.5721%
95.1097%
95.2125% 95.0253% 96.4684% 94.6821% 94.9547% 96.6162% 94.5721% 94.5721% 94.5721% 100% 94.5721% 98.8507% 97.2138% 95.5884% 94.5721% 94.5721% 95.8626% 94.5721%
94.5721% 94.5721% 97.0962% 94.7944%
95.2391% 95.4374% 96.6003% 94.8492% 96.4977% 96.8431% 94.5721% 94.5721% 94.5721% 100% 94.5721% 98.5122% 97.5922%
95.0856% 96.0438% 96.8309% 95.7221% 97.2827% 96.7693% 94.5722% 94.5722% 94.5722% 100% 94.5722%
95.64%
97.5877% 95.6689% 100% 94.5724% 96.1897% 97.8618% 96.3542% 94.4901% 96.6009% 98.1908% 96.9846%
96.3816% 96.2719% 95.9978% 95.0384% 96.1897% 95.7237%
97.8029% 97.5565% 94.5722% 94.8665% 97.9261%
93.423%
97.666%
94.545%
96.7%
Table 4: Different cross validation k. It does not matter how much data we use for training and testing, accuracy stays the
same.
↓ Sample Size / Sensor →
2
3
5
10
15
S1
S2
S3
S4
S5
S6
S7
S8
S9
S10
S11
S12
S13
S14
S15
S16
S17
S18
94.9218% 96.3108% 94.6378% 94.8907% 96.3781% 94.5721% 94.5721% 94.5721% 100% 94.5721% 98.8524% 96.9856% 95.5589% 94.5721% 94.5721% 95.8232% 94.5721%
95.201%
94.5721% 94.5721% 94.5721% 100% 94.5721% 98.8491% 97.1514% 95.5819% 94.5721% 94.5721% 95.8134% 94.5721%
95.1977% 94.9892%
95.2125% 95.0253% 96.4684% 94.6821% 94.9547% 96.6162% 94.5721% 94.5721% 94.5721% 100% 94.5721% 98.8507% 97.2138% 95.5884% 94.5721% 94.5721% 95.8626% 94.5721%
95.2272%
97.2532% 95.5934% 94.5721% 94.5721% 95.8478% 94.5721%
95.2289% 95.0729% 96.4619% 94.6904% 94.9875% 96.7016% 94.5721% 94.5738% 94.5721% 100% 94.5721% 98.8491% 97.2664% 95.5966% 94.5721% 94.5721% 95.8413% 94.5721%
94.9777% 96.6819% 94.5721% 94.5721% 94.5721% 100% 94.5721%
94.6657% 94.9202%
96.4816%
96.365%
95.063%
94.692%
98.854%
96.521%
However, to see the performance of the proposed technique, a
systematic analysis is carried out by using machine learning and a
complete feature set as shown in Table 3. For the classification, a
binary classifier is used by labeling data from the sensor of interest
as legitimate and data from the rest of all sensors as illegitimate.
This way during the testing phase, each sensor is tested against
data from all other sensors. Higher sensor identification accuracies
in Table 3 point to the existence of the noise-based fingerprint.
RQ2: Attack Detection Delay. What is the right amount of data to
detect correct sensor ID with the highest accuracy? To answer this
question, chunks of different data size are created for the whole
dataset. Data from each sensor is sampled at an interval of one
second. The idea is to have a chunk of time series big enough to
capture the dynamics of the process and small enough to reduce the
delay in the attack detection. Chunk size ranging from 60 readings
to 2000 readings is used. The empirical results are shown in Table 3.
It can be seen that for a chunk size of 60 readings, the classification
accuracy is slightly low. However, for higher chunk size accuracy
improves a bit but it means to wait more before making a decision
on the received data from a sensor. It is observed that 120 samples
Figure 6: Existence of Fingerprint.
-0.10.6-0.050.50Mean0.40.40.05Variance0.3Mean Average Deviation0.10.20.20.100S1: Flow Meter (FIT-101)S2: Level Sensor (LIT-101)574ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Chuadhry Mujeeb Ahmed, Jianying Zhou, and Aditya P. Mathur
are a good trade-off between accuracy and detection time (i.e. 120
seconds).
RQ3: How the amount of training and testing data affects sensor
identification performance? An important question is regarding the
amount of data needed for training and testing purpose. A cross
validation analysis is done to answer this question. For a k fold cross
validation on a dataset means, the whole data set would be divided
into k chunks of data, then k − 1 chunks are used for training and
one chunk for testing. For example for 5 fold cross validation, the
first 4 of 5 chunks would be used to train the classifier and the last
chunk to test the trained machine learning model and then other 4
chunks are used for training and rest one for testing. This procedure
is repeated for all chunks and average accuracy is reported. This
procedure for k fold cross validation shows how does the choice
of data range for training and testing make difference. For a k = 2,
means whole data set is divided into two chunks and each half is
used for training and testing. Similarly, a k = 15 means the whole
dataset is divided into 15 chunks and validation is done for each
chunk as explained above. Ideally, a classifier should be robust to
the size of the dataset used for training and testing. It should also
be independent of the fact that which dataset range in time series is
used for training and testing. Results in Table 4, point out that the
accuracy of our chosen classifier function does not depend on the
choice of size of the dataset. This gives a practical insight into the
case when limited data is available to train the machine learning
model. The high classification accuracy proves our hypothesis that
sensors can be uniquely identified using a combination of sensor
and process noise.
RQ4: How well the proposed technique can detect network attacks
on sensor measurements? Previous results demonstrate the ability
of the proposed technique to identify sensors uniquely based on
their noise fingerprints. This part is to evaluate the performance of
the noise fingerprinting technique as an attack detection technique.
A set of benchmark attacks are tested [10, 16]. Out of 41 attacks
in [16], 18 attacks are on sensors and therefore, chosen for this work.
A List of attacks and attack descriptions is provided in Table 6 in the
Appendix. The last column in Table 6 shows one-class SVM attack
detection accuracy for that particular attack. For each individual at-
tack and a chunk size of 250, it can be seen that one-class SVM could
detect all but 2 attacks. A pictorial example of an attack is shown in
Figure 7. Figure 7 shows an example of a level sensor at stage 1 (of
the SWaT testbed) under attack. On the right and left pane is the
zoomed-in plot. In Figure 7, the left pane shows a zoomed-in region
when the system is not under any attack. The rightmost pane shows
the zoomed-in residual vector during an attack execution period.
It can be observed that the residual significantly deviates from the
normal profiled noise pattern. This observation provides an intu-
ition for attack detection using the proposed technique. Apparently,
from the middle pane, visual inspection also means that one should
be able to detect all the attack points. However, to formally show
the performance of the attack detector, True Positive Rate (TPR:
meaning attacked data declared as an attack), and True Negative
Rate (TNR: attack-free data declared as normal) are used. The attack
detection results are shown in Table 5. For each sensor in the SWaT
testbed, attack sequences are shown. These attack sequences and
attacked dataset are obtained from already published benchmark
Figure 7: Attack executed on level sensor (LIT-101).
attacks [10, 16]. We can see a high TNR indicating successful attri-
bution of normal data but the TPR is slightly lower using multi-class
classification. The reason for the lower TPR is that for multi-class
supervised learning, there are no examples of attacked data before-
hand to train the classifier. However, the analysis is extended by
using a one-class SVM classifier for each sensor. For the case of a
one-class classifier, one just needs to have normal data for training
and during the testing phase, anything other than that single-class
is declared as an anomaly. It can be seen in Table 5 that the TPR has
increased significantly making it much easier to detect attacks but
it comes at the cost of a slightly lower TNR. It’s a trade-off between
higher TNR and TPR. To reduce false alarms, one can come up with
heuristics e.g. TNR below 85% would raise an alarm for an attack.
This kind of heuristic method can reduce the number of false alarms
while detecting attacks as the TPR is much higher when using the
one-class machine learning method. There is another interesting
observation. Since the proposed technique is based on a physical
system model, it exhibits a strong coupling between the inputs and
outputs of a system. If attacks are executed on level sensors, we
could see the effect on associated flow meters and vice versa. This
indicates the coupling between the laws of physics even though
the sensors are of different types. This observation means even if
the TPR rate is less than 100%, it could be aggregated (in a voting
manner) from coupled sensors and declare attacks if the aggregate
is higher than a learned threshold. We are able to detect most of the
sensor attacks from the reference literature [10, 16], indicating the
effectiveness of the proposed technique against a range of cyber
attack scenarios.
5 DISCUSSION
Scalability: A multitude of sensors is studied from a real water
treatment testbed. The high accuracy of sensor identification results
in Table 4 points towards the effectiveness of the technique for the
case of a number of processes and sensors. A total of 18 sensors
were available for experimentation in a sixstaдe water treatment
testbed. The problem is formulated as binary classification, by con-
sidering the legitimate sensor as (class 1) and rest of the 17 sensors
as illegitimate or compromised (class 2). The goal is to authenticate
data being received by a particular sensor. In a particular setting of
a SCADA system, the data stream is expected to be generated from
a particular sensor but the question is, can the integrity of the sensor
data be ensured? Ideally, a measurement from each sensor should be
575Noise Matters
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Table 5: Attack detection performance. Level sensors in different stages of SWaT are attacked with different attacker goals and
strategies as explained in Table 6. Flow meter at stage 1 and 3 are not attacked but from the residual vector of these sensors
it is possible to detect anomalies due to attack sequences on level sensors, that’s why for those sensors None is put in attack
sequence column. Detection is possible due to process coupling captured by system model. Average TPR and TNR are shown
for all attack sequences. MC-SVM := Multi-class SVM, OC-SVM := One-class SVM.
Atk. seq. a
Attacked b Detected c MC-SVM TNR MC-SVM TPR OC-SVM TNR OC-SVM TPR
8
3,21,30,33,36
Sensor
DPIT-301
LIT-101
FIT-101
LIT-301
FIT-301
LIT-401
FIT-401
None
7,16,26,32,41
None
25,27,31
10,11,39,40
8