title:When Good Components Go Bad: Formally Secure Compilation Despite Dynamic
Compromise
author:Carmine Abate and
Arthur Azevedo de Amorim and
Roberto Blanco and
Ana Nora Evans and
Guglielmo Fachini and
Catalin Hritcu and
Th&apos;eo Laurent and
Benjamin C. Pierce and
Marco Stronati and
Andrew Tolmach
When Good Components Go Bad
Formally Secure Compilation Despite Dynamic Compromise
Carmine Abate1 Arthur Azevedo de Amorim2
Roberto Blanco1 Ana Nora Evans3 Guglielmo Fachini4
Cătălin Hrit,cu1
Théo Laurent1
Benjamin C. Pierce5 Marco Stronati6
Jérémy Thibault1 Andrew Tolmach7
1Inria Paris
2Carnegie Mellon University 3University of Virginia
4Nozomi Networks
5University of Pennsylvania
6Nomadic Labs
7Portland State University
9
1
0
2
v
o
N
9
2
]
R
C
.
s
c
[
5
v
8
8
5
0
0
.
2
0
8
1
:
v
i
X
r
a
ABSTRACT
We propose a new formal criterion for evaluating secure compilation
schemes for unsafe languages, expressing end-to-end security guar-
antees for software components that may become compromised
after encountering undefined behavior—for example, by accessing
an array out of bounds.
Our criterion is the first to model dynamic compromise in a
system of mutually distrustful components with clearly specified
privileges. It articulates how each component should be protected
from all the others—in particular, from components that have en-
countered undefined behavior and become compromised. Each com-
ponent receives secure compilation guarantees—in particular, its
internal invariants are protected from compromised components—
up to the point when this component itself becomes compromised,
after which we assume an attacker can take complete control and
use this component’s privileges to attack other components. More
precisely, a secure compilation chain must ensure that a dynami-
cally compromised component cannot break the safety properties
of the system at the target level any more than an arbitrary attacker-
controlled component (with the same interface and privileges, but
without undefined behaviors) already could at the source level.
To illustrate the model, we construct a secure compilation chain
for a small unsafe language with buffers, procedures, and compo-
nents, targeting a simple abstract machine with built-in compart-
mentalization. We give a machine-checked proof in Coq that this
compiler satisfies our secure compilation criterion. Finally, we show
that the protection guarantees offered by the compartmentalized
abstract machine can be achieved at the machine-code level using
either software fault isolation or a tag-based reference monitor.
KEYWORDS
secure compilation; formal definition; low-level attacks; undefined
behavior; compartmentalization; mutually distrustful components;
dynamic compromise; software fault isolation; reference monitors;
safety properties; machine-checked proofs; testing; foundations
1 INTRODUCTION
Compartmentalization offers a strong, practical defense against a
range of devastating low-level attacks, such as control-flow hijacks
exploiting buffer overflows and other vulnerabilities in C, C++,
This work is licensed under a Creative Commons Attribution 4.0 International License.
Any updated versions will be made available at https://arxiv.org/abs/1802.00588
This work appeared at CCS ’18, October 15–19, 2018, Toronto, ON, Canada
© 2018–2019 Copyright held by the owner/author(s).
and other unsafe languages [19, 35, 84]. Widely deployed compart-
mentalization technologies include process-level privilege separa-
tion [19, 35, 49] (used in OpenSSH [69] and for sandboxing plugins
and tabs in web browsers [71]), software fault isolation [77, 82] (e.g.,
Google Native Client [87]), WebAssembly modules [36] in modern
web browsers, and hardware enclaves (e.g., Intel SGX [40]); many
more are on the drawing boards [15, 21, 74, 84]. These mechanisms
offer an attractive base for building more secure compilation chains
that mitigate low-level attacks [32, 35, 46, 67, 78–80]. In particular,
compartmentalization can be applied in unsafe low-level languages
to structure large, performance-critical applications into mutually
distrustful components that have clearly specified privileges and
interact via well-defined interfaces.
Intuitively, protecting each component from all the others should
bring strong security benefits, since a vulnerability in one compo-
nent need not compromise the security of the whole application.
Each component will be protected from all other components for
as long as it remains “good.” If, at some point, it encounters an in-
ternal vulnerability such as a buffer overflow, then, from this point
on, it is assumed to be compromised and under the control of the
attacker, potentially causing it to attack the remaining uncompro-
mised components. The main goal of this paper is to formalize this
dynamic-compromise intuition and precisely characterize what it
means for a compilation chain to be secure in this setting.
We want a characterization that supports source-level security
reasoning, allowing programmers to reason about the security prop-
erties of their code without knowing anything about the complex
internals of the compilation chain (compiler, linker, loader, run-
time system, system software, etc). What makes this particularly
challenging for C and C++ programs is that they may encounter
undefined behaviors—situations that have no source-level meaning
whatsoever. Compilers are allowed to assume that undefined be-
haviors never occur in programs, and they aggressively exploit this
assumption to produce the fastest possible code for well-defined
programs, in particular by avoiding the insertion of run-time checks.
For example, memory safety violations [16, 76] (e.g., accessing an
array out of bounds, or using a pointer after its memory region
has been freed) and type safety violations [28, 37] (e.g., invalid
unchecked casts)—cause real C compilers to produce code that be-
haves arbitrarily, often leading to exploitable vulnerabilities [39, 76].
Of course, not every undefined behavior is necessarily exploitable.
However, for the sake of strong security guarantees, we make a
worst-case assumption that any undefined behavior encountered
within a component can lead to its compromise. Indeed, in the
remainder of the paper we equate the notions of “encountering
undefined behavior” and “becoming compromised.”
When Good Components Go Bad
Abate et al.
While the dangers of memory safety and casting violations are
widely understood, the C and C++ standards [41] call out large
numbers of undefined behaviors [38, 51] that are less familiar, even
to experienced C/C++ developers [56, 83]. To minimize programmer
confusion and lower the risk of introducing security vulnerabilities,
real compilers generally give sane and predictable semantics to some
of these behaviors. For example, signed integer overflow is officially
an undefined behavior in standard C, but many compilers (at least
with certain flags set) guarantee that the result will be calculated
using wraparound arithmetic. Thus, for purposes of defining secure
compilation, the set of undefined behaviors is effectively defined
by the compiler at hand rather than by the standard.
The purpose of a compartmentalizing compilation chain is to
ensure that the arbitrary, potentially malicious, effects of undefined
behavior are limited to the component in which it occurs. For a
start, it should restrict the spatial scope of a compromise to the
component that encounters undefined behavior. Such compromised
components can only influence other components via controlled
interactions respecting their interfaces and the other abstractions of
the source language (e.g., the stack discipline on calls and returns).
Moreover, to model dynamic compromise and give each compo-
nent full guarantees as long as it has not yet encountered undefined
behavior, the temporal scope of compromise must also be restricted.
In particular, compiler optimizations should never cause the effects
of undefined behavior to show up before earlier “observable events”
such as system calls. Unlike the spatial restriction, which requires
some form of run-time enforcement in software or hardware, the
temporal restriction can be enforced just by foregoing certain ag-
gressive optimizations. For example, the temporal restriction (but
not the spatial one) is already enforced by the CompCert C com-
piler [58, 70], providing a significantly cleaner model of undefined
behavior than other C compilers [70].
We want a characterization that is formal—that brings mathe-
matical precision to the security guarantees and attacker model
of compartmentalizing compilation. This can serve both as a clear
specification for verified secure compilation chains and as useful
guidance for unverified ones. Moreover, we want the characteriza-
tion to provide source-level reasoning principles that can be used
to assess the security of compartmentalized applications. To make
this feasible in practice, the amount of source code to be verified
or audited has to be relatively small. So, while we can require de-
velopers to carefully analyze the privileges of each component and
the correctness of some very small pieces of security-critical code,
we cannot expect them to establish the full correctness—or even
absence of undefined behavior—for most of their components.
Our secure compilation criterion improves on the state of the art
in three important respects. First, our criterion applies to compart-
mentalized programs, while most existing formal criteria for secure
compilation are phrased in terms of protecting a single trusted pro-
gram from an untrusted context [2, 4, 5, 7–9, 31, 65]. Second, unlike
some recent criteria that do consider modular protection [25, 67],
our criterion applies to unsafe source languages with undefined
behaviors. And third, it considers a dynamic compromise model—
a critical advance over the recent proposal of Juglaret et al. [45],
which does consider components written in unsafe languages, but
which is limited to a static compromise model. This is a serious
limitation: components whose code contains any vulnerability that
might potentially manifest itself as undefined behavior are given no
guarantees whatsoever, irrespective of whether an attacker actually
exploits these vulnerabilities. Moreover, vulnerable components
lose all guarantees from the start of the execution—possibly long
before any actual compromise. Experience shows that large enough
C or C++ codebases essentially always contain vulnerabilities [76].
Thus, although static compromise models may be appropriate for
safe languages, they are not useful for unsafe low-level languages.
As we will see in §5, the limitation to static compromise scenar-
ios seems inescapable for previous techniques, which are all based
on the formal criterion of full abstraction [2]. To support dynamic
compromise scenarios, we take an unconventional approach, drop-
ping full abstraction and instead phrasing our criterion in terms of
preserving safety properties [54] in adversarial contexts [7], where,
formally, safety properties are predicates over execution traces that
are informative enough to detect the compromise of components
and to allow the execution to be “rewound” along the same trace.
Moving away from full abstraction also makes our criterion easier
to achieve efficiently in practice and to prove at scale.
Contributions. Our first contribution is Robustly Safe Compart-
mentalizing Compilation (RSCC), a new secure compilation criterion
articulating strong end-to-end security guarantees for components
written in unsafe languages with undefined behavior. This criterion
is the first to support dynamic compromise in a system of mutually
distrustful components with clearly specified privileges. We start by
illustrating the intuition, informal attacker model, and source-level
reasoning behind RSCC using a simple example application (§2).
Our second contribution is a formal presentation of RSCC. We
start from Robustly Safe Compilation (RSC, §3.1), a simple security
criterion recently introduced by Abate et al. [7], and extend this first
to dynamic compromise (RSCDC, §3.2), then mutually distrustful
components (RSCDC
MD, §3.3), and finally to the full definition of RSCC
(§3.4). We also give an effective and generic proof technique for
RSCC (§3.5): We start with a target-level execution and explain
any finite sequence of calls and returns in terms of the source
language by constructing a whole source program that produces
this prefix. Our novel proof architecture manages to achieve this
using only (mostly standard) simulation proofs, which is much
simpler and more scalable than previous proofs in this space [45].
One particularly important advantage is that it allows us to reuse
a whole-program compiler correctness result à la CompCert [58]
as a black box, avoiding the need to prove any other simulations
between the source and target languages.
Our third contribution is a proof-of-concept secure compilation
chain (§4) for a simple unsafe sequential language featuring buffers,
procedures, components, and a CompCert-like block-based memory
model [59] (§4.1). Our entire compilation chain is implemented in
the Coq proof assistant. The first step compiles our source language
to a simple low-level abstract machine with built-in compartmen-
talization (§4.2). We use the proof technique from §3.5 to construct
machine-checked proofs in Coq showing that this compiler satisfies
RSCC (§4.3). Finally, we describe two back ends for our compiler,
showing that the protection guarantees of the compartmentalized
abstract machine can be achieved at the lowest level using either
software fault isolation (SFI, §4.4) or a tag-based reference monitor
(§4.5). The tag-based back end, in particular, is novel, using linear
2
When Good Components Go Bad
Abate et al.
return capabilities to enforce a cross-component call/return disci-
pline. Neither back end has yet been formally verified, but we have
used property-based testing to gain confidence that the SFI back
end satisfies RSCDC
MD.
These contributions lay a solid foundation for future secure com-
pilation chains that could bring sound and practical compartmental-
ization to C, C++, and other unsafe low-level languages. We address
three fundamental questions: (1) What is the desired secure compila-
tion criterion and to what attacker model and source-level security
reasoning principles does it correspond? Answer: We propose the
RSCC criterion from §2-§3. (2) How can we effectively enforce secure
compilation? Answer: Various mechanisms are possible; the simple
compilation chain from §4 illustrates how either software fault
isolation or tagged-based reference monitoring can enforce RSCC.