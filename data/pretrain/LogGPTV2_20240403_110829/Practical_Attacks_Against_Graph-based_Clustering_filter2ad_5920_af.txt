0.48 to 0.26. The attacker needs to reduce the number of distinct
DGA domains from 618 to 160 to evade, but each domain can be
queried by all infected hosts. In comparison, when the SVD rank is
200, the minimum cost is 0.38. The attacker needs to further reduce
the number of distinct DGA domains to 60 to evade, with each
domain queried by all infected hosts. The attack graph density is re-
duced from 0.48 to 0.1, losing 79% ( 0.38
0.48) of queries to distinct DGA
domains. This means that tuning hyperparameters can increase
the small community attack cost and potentially render this attack
ineective.
Similarly, for node2vec, the minimum cost of a certain small com-
munity attack is higher than spectral clustering. We compute the
attacker graph density only for the white area in Figure 9 without
randomness, i.e., the rst column and bottom two rows. In contrast
to spectral clustering, node2vec requires a much higher minimum
cost for a guaranteed small community attack, which indicates that
node2vec is more resilient to this attack. The smallest communi-
ties in Figure 9 (i.e., the rst column and bottom two rows) are
likely undersampled, because choosing 15 walks per node and walk
length 20 using cluster validity in Section 5.1.3 prefers labeled DGA
communities that are relatively bigger, which makes few neighbor-
hood observations for extremely small islands insignicant, and
thus allows small community attacks. Note the randomness in the
remaining portion of the plot. Since node2vec uses the random
walk process to sample the neighborhoods of all nodes, there exists
randomness in the neighborhood observations. This shows that
the randomness inherent to node2vec makes the attacks succeed at
random in the remaining portion of Figure 9. This both suggests
a system like Pleiades would benet from node2vec to reduce the
guarantee of attacks, as well as allow a defender to identify if an
attacker is evading by chance encounters where the evasion fails
over time. While the minimum attack cost is the same with dierent
neighborhood sizes for a guaranteed successful attack, the attack
success rate changes. The neighborhood sizes 2, 4, and 6 have attack
success rate 65.16%, 60.65%, and 70.65% respectively (Figure 9). We
will discuss how we can use dierent hyperparameters to further
reduce the success rate of the small community attack in Section 6.2.
Session E4:  Adversarial Social NetworkingCCS’17, October 30-November 3, 2017, Dallas, TX, USA1136Model
Original
Model A
Model B
Model C
False Positive Rate
Pykspa Gimemo
0.29%
0.32%
0.39%
1.64%
1.62%
0.10%
1.17%
1.46%
Suppobox Murofet
0%
0%
0.30%
0%
0%
0.10%
1.23%
1.23%
Table 4: False Positive Rate for four DGA families before re-
training, and after retraining with three types of noise.
These costs further demonstrate node2vec’s superiority over spectral
clustering in resisting small community attacks.
6 DEFENSE
Since the noise injection attack and the small community attack
violate the fundamental assumptions used by graph clustering tech-
niques, it is very hard to completely eliminate the problem. In this
section, we propose two defense techniques that help Pleiades re-
tain its detection capabilities against the two attacks. The rst one
is to train the classier with noise, which remediates the noise
injection attack to some extent. The second one is to use the small
community attack as an adversarial guideline to choose better hy-
perparameters for graph embeddings, which increases the cost of
launching a successful small community attack.
6.1 Training Classier with Noise
By retraining the classier, it becomes more resistant to noise that
could be injected by the adversary in the unsupervised phase of
Pleiades. We used domains from the benign DGA to poison the clus-
ters of malicious DGAs. We retrained the classier using clusters
generated by the noise injection attack variant 1 (“Minimal Benign
DGA 1”, m = 1, Algorithm 1 in Section 5.2) from SVD, yielding
model A. We tested model A against the adversarial clusters gener-
ated by the same noise injection attack under community discovery
and node2vec. The rst two violins in Figure 6c show that model
A increases the overall predicted class probabilities compared to
the “After Attack” violins in Figure 6a. In community discovery, the
accuracy increased from 2% to 98%; and in node2vec, the accuracy
increased from 0.8% to 98%. To summarize, retraining with noisy
clusters containing a benign DGA from SVD can remediate the
same attack on community discovery and node2vec. We see this
same eect even when the noise levels are doubled (m = 2, Algo-
rithm 1 in Section 5.2). When models were trained with half the
noise (m = 1, Algorithm 1 in Section 5.2), they were able to more
accurately predict the correct label. Among them, only an average
of 7.3% clusters are predicted with the wrong labels, decreased from
100% before retraining.
In comparison with Figure 6a, the average prediction condence
increased signicantly. Before retraining, the average prediction
condence of “Minimal Benign DGA 2”, “Moderate 2”, and “Perfect
Long Tail 2” are 10%, 20%, and 20%. After retraining, they increased
to 70%, 90%, and 80%, respectively. The accuracy of the models
remain roughly the same before and after retraining. However,
retraining with noisy clusters increased the false positive rate in
most cases (Table 4).
It is important to note that this defense only trains the classier
with noise that has been witnessed. New noise will appear, but the
fundamental attack on the unsupervised component remains the
same. Therefore, defenders will be alerted by plumetting accuracies
in their models. Our defenses are simple and future work should
be done to make clustering systems more robust.
6.2 Improving Hyperparameter Selection
e
t
a
R
s
s
e
c
c
u
S
k
c
a
t
t
A
100%
75%
50%
25%
0%
●
●
●
●
●
●
35
100
Number of Eigenvalues
200
300
(a)
●
t
e
a
R
s
s
e
c
c
u
S
k
c
a
t
t
A
100%
75%
50%
25%
0%
●
●
●
●
●
●
●
●
●
5
15
10
Walk Length
(b)
20
Figure 11: Figure 11a: Using the small community attack to
choose the number of eigenvalues for SVD. Figure 11b: Using
the small community attack to choose the length of walk for
node2vec.
Small community attacks show that the traditional ways of choos-
ing hyperparameters (Section 5.1) is not enough when facing adver-
saries. Luckily, the small community attack can be used to choose
more resistant hyperparameters. We show that better selection can
reduce the number of successful small community attack instances
from our previous experiments.
We plot the successful attack rate under dierent number of
eigenvalues in Figure 11a. The successful attack rate decreases as
the number of eigenvalues computed increases, and the line plateaus
after 200 eigenvalues. It means that a defender running Pleiades
should select the rst 200 eigenvalues, instead of 35 indicated by
the scree plot in Figure 4. If we use the small community attack in
this way, we can choose better parameters for the system and also
know under which parameters the system is vulnerable.
Similarly, for node2vec, using the small community attack to
choose hyperparameters can reduce the attack success rate. The
Session E4:  Adversarial Social NetworkingCCS’17, October 30-November 3, 2017, Dallas, TX, USA1137cluster validity metrics suggest we choose neighborhood size six,
and walk length of 20. However, if we evaluate the graph clustering
using the success rate of the small community attack, these hyperpa-
rameters are not optimal. First, for the neighborhood size, Figure 9
shows that a smaller neighborhood size of four introduces a lower
attack success rate. Second, we plot the attack success rate under
dierent walk lengths in Figure 11b. This gure shows that a walk
length of 12 is preferred over 20, because the former allows 51.29%
attack success rate compared to 61.61% of the latter. In other words,
the smaller neighborhood size and shorter walk length can tolerate
the small community attack better, presumably because they do
not oversample larger communities with more distinct neighbor-
hood observations. In other words, smaller communities are not
undersampled. We recommend using the small community attack
success rate to evaluate the clustering hyperparameter selection, in
addition to traditional cluster validity indices.
7 DISCUSSION
We acknowledge that details surrounding the implementation of the
attacks are specic to Pleiades, however, the graph representation
suggests the attacks may work on other graph-based systems. In
this section, we briey discuss issues to consider to generalize the
attacks.
Nodes and edges can be trivially injected or removed in the graph
Pleiades uses, which are generated by malware resolving domain
names. In other security contexts, the set of injectable/removable
nodes varies. It is possible that some nodes and edges must exist in
order for certain attack actions to succeed. For example, a phishing
email using a malicious attachment requires at least the read system
call to successfully infect a host, which cannot be removed from
the system call graph. On the other hand, it can be dicult to add
certain nodes and edges. Therefore, in addition to the anomaly cost
(Section 5.2.4) and agility cost (Section 5.3.4), the action of graph
manipulation itself has costs depending on the data that underlies
the graph representation. This should be carefully considered when
generalizing the attacks to other systems and we leave this to be
future work. Tighter costs may exist, but our approaches point in a
promising direction.
8 CONCLUSIONS
We have demonstrated that generic attacks on graphs can break
a real-world system that uses several popular graph-based model-
ing techniques. These attacks can often be performed by limited
adversaries at low cost; however, simple defenses can reduce their
eectiveness or likelihood of success. To summarize how defenders
can improve their systems: hyperparameter selection should be
optimized for reducing the success rate of small community attacks,
and retraining can be used to lessen the impact of noise injection
attacks. Furthermore, state of the art graph embedding techniques
like node2vec appear to be more resistant against small commu-
nity attacks, which suggests Pleiades and other systems would be
harder to adversarially manipulate using node2vec over community
nding, or spectral methods (see Figure 9 vs. Figure 7).
9 ACKNOWLEDGMENTS
We thank our anonymous reviewers for their invaluable feedback,
and Dr. Rosa Romero-Gómez for her help in visualization. This
material is based upon work supported in part by the US Depart-
ment of Commerce grants no. 2106DEK and 2106DZD, National
Science Foundation (NSF) grant no. 2106DGX and Air Force Re-
search Laboratory/Defense Advanced Research Projects Agency
grant no. 2106DTX. Any opinions, ndings, and conclusions or
recommendations expressed in this material are those of the au-
thors and do not necessarily reect the views of the US Department
of Commerce, National Science Foundation, Air Force Research
Laboratory, or Defense Advanced Research Projects Agency.
REFERENCES
[1] Accessed in May 2017. Amazon Machine Learning. https://aws.amazon.com/
machine-learning. (Accessed in May 2017).
[2] Accessed in May 2017. BigML. https://bigml.com/. (Accessed in May 2017).
[3] Accessed in May 2017. Google Cloud Prediction API. https://cloud.google.com/
prediction/docs/. (Accessed in May 2017).
[4] Accessed in May 2017. IOC Bucket. https://www.iocbucket.com/. (Accessed in
[5] Accessed in May 2017. Microsoft Azure. https://azure.microsoft.com. (Accessed
May 2017).
in May 2017).
2017).
2017).
[6] Accessed in May 2017. OpenIOC DB. https://openiocdb.com/. (Accessed in May
[7] Accessed in May 2017. PredictionIO. http://prediction.io. (Accessed in May
[8] Manos Antonakakis, Roberto Perdisci, David Dagon, Wenke Lee, and Nick Feam-
ster. 2010. Building a Dynamic Reputation System for DNS. In USENIX security
symposium. 273–290.
[9] Manos Antonakakis, Roberto Perdisci, Yacin Nadji, Nikolaos Vasiloglou, Saeed
Abu-Nimeh, Wenke Lee, and David Dagon. 2012. From Throw-Away Trac to
Bots: Detecting the Rise of DGA-Based Malware. In Presented as part of the 21st
USENIX Security Symposium (USENIX Security 12). 491–506.
[10] Johannes Bader. 2017. Domain Generation Algorithms. https://github.com/
baderj/domain_generation_algorithms. (2017).
[11] Ulrich Bayer, Paolo Milani Comparetti, Clemens Hlauschek, Christopher Kruegel,
and Engin Kirda. 2009. Scalable, Behavior-Based Malware Clustering.. In NDSS,
Vol. 9. Citeseer, 8–11.
[12] Battista Biggio, Ignazio Pillai, Samuel Rota Bulò, Davide Ariu, Marcello Pelillo,
and Fabio Roli. 2013.
Is Data Clustering in Adversarial Settings Secure?. In
Proceedings of the 2013 ACM workshop on Articial intelligence and security. ACM,
87–98.
[13] Battista Biggio, Konrad Rieck, Davide Ariu, Christian Wressnegger, Igino Corona,
Giorgio Giacinto, and Fabio Roli. 2014. Poisoning Behavioral Malware Clustering.
In Proceedings of the 2014 Workshop on Articial Intelligent and Security Workshop.
ACM, 27–36.
[14] Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefeb-
vre. 2008. Fast Unfolding of Communities in Large Networks. Journal of statistical
mechanics: theory and experiment 2008, 10 (2008), P10008.
[15] Mark Braverman, Young Kun Ko, Aviad Rubinstein, and Omri Weinstein. 2017.
ETH hardness for densest-k-subgraph with perfect completeness. In Proceedings
of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms. SIAM,
1326–1341.
[16] Nicholas Carlini and David Wagner. 2017. Towards evaluating the robustness of
neural networks. In Security and Privacy (EuroS&P), 2017 IEEE European Sympo-
sium on. IEEE.
[17] Raymond B Cattell. 1966. The scree test for the number of factors. Multivariate
behavioral research 1, 2 (1966), 245–276.
[18] Duen Horng Polo Chau, Carey Nachenberg, Jerey Wilhelm, Adam Wright, and
Christos Faloutsos. 2011. Polonium: Tera-Scale Graph Mining and Inference for
Malware Detection. In Proceedings of the 2011 SIAM International Conference on
Data Mining. SIAM, 131–142.
[19] Yizheng Chen, Manos Antonakakis, Roberto Perdisci, Yacin Nadji, David Dagon,
and Wenke Lee. 2014. DNS Noise: Measuring the Pervasiveness of Disposable
Domains in Modern DNS Trac. In Dependable Systems and Networks (DSN),
2014 44th Annual IEEE/IFIP International Conference on. IEEE, 598–609.
[20] Yizheng Chen, Panagiotis Kintis, Manos Antonakakis, Yacin Nadji, David Dagon,
Wenke Lee, and Michael Farrell. 2016. Financial Lower Bounds of Online Adver-
tising Abuse. In Detection of Intrusions and Malware, and Vulnerability Assessment.
Springer, 231–254.
Session E4:  Adversarial Social NetworkingCCS’17, October 30-November 3, 2017, Dallas, TX, USA1138[21] Yizheng Chen, Yacin Nadji, Rosa Romero-Gómez, Manos Antonakakis, and David
Dagon. 2017. Measuring Network Reputation in the Ad-Bidding Process. In
International Conference on Detection of Intrusions and Malware, and Vulnerability
Assessment. Springer, 388–409.
[22] CYBERWARZONE. Accessed
30 Malicious
2017.
and Block Lists Providers
List
30-malicious-ip-list-and-block-lists-providers-2015/.
2017).
in May
2015.
IP
http://cyberwarzone.com/
in May
(Accessed
[23] Hermit Dave. Accessed in May 2017. Frequency Words in Subtitles. https://github.
com/hermitdave/FrequencyWords/tree/master/content/2016/en. (Accessed in
May 2017).
[24] Prahlad Fogla and Wenke Lee. 2006. Evading Network Anomaly Detection
Systems: Formal Reasoning and Practical Techniques. In Proceedings of the 13th
ACM conference on Computer and communications security. ACM, 59–68.
[25] Amir Globerson and Sam Roweis. 2006. Nightmare at Test Time: Robust Learning
by Feature Deletion. In Proceedings of the 23rd international conference on Machine
learning. ACM, 353–360.
[26] Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable Feature Learning for
Networks. In Proceedings of the 22nd ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining. ACM, 855–864.
[27] Shuang Hao, Nadeem Ahmed Syed, Nick Feamster, Alexander G Gray, and Sven
Krasser. 2009. Detecting Spammers with SNARE: Spatio-temporal Network-level
Automatic Reputation Engine. In USENIX Security Symposium, Vol. 9.
[28] Ling Huang, Anthony D Joseph, Blaine Nelson, Benjamin IP Rubinstein, and
JD Tygar. 2011. Adversarial Machine Learning. In Proceedings of the 4th ACM
workshop on Security and articial intelligence. ACM, 43–58.
[29] Luca Invernizzi, Stanislav Miskovic, Ruben Torres, Christopher Kruegel,
Sabyasachi Saha, Giovanni Vigna, Sung-Ju Lee, and Marco Mellia. 2014. Nazca:
Detecting Malware Distribution in Large-Scale Networks. In NDSS, Vol. 14. 23–26.
[30] Kurucz, Miklós and Benczúr, András A. 2010. Geographically Organized Small
Communities and the Hardness of Clustering Social Networks. In Data Mining
for Social Network Data. Springer.
[31] Kevin J Lang. 2005. Fixing Two Weaknesses of the Spectral Method. Advances in
Neural Information Processing Systems (2005).
[32] Angsheng Li and Pan Peng. 2012. The small-community phenomenon in net-
works. Mathematical Structures in Computer Science 22, 03 (2012), 373–407.
[33] Zhou Li and Alina Oprea. 2016. Operational Security Log Analytics for Enterprise
Breach Detection. In First IEEE Cybersecurity Development Conference (SecDev).
[34] Kun Liu and Evimaria Terzi. 2008. Towards identity anonymization on graphs.
In Proceedings of the 2008 ACM SIGMOD international conference on Management
of data. ACM, 93–106.
[35] Daniel Lowd and Christopher Meek. 2005. Adversarial Learning. In Proceedings
of the eleventh ACM SIGKDD international conference on Knowledge discovery in
data mining. ACM, 641–647.
[36] Daniel Lowd and Christopher Meek. 2005. Good Word Attacks on Statistical
Spam Filters. In CEAS.
[37] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Je Dean. 2013.
Distributed Representations of Words and Phrases and their Compositionality.
In Advances in neural information processing systems. 3111–3119.
[38] Yacin Nadji, Manos Antonakakis, Roberto Perdisci, David Dagon, and Wenke Lee.
2013. Beheading Hydras: Performing Eective Botnet Takedowns. In Proceedings
of the 2013 ACM SIGSAC conference on Computer & communications security. ACM,
121–132.
[39] Yacin Nadji, Manos Antonakakis, Roberto Perdisci, and Wenke Lee. 2013. Con-
nected Colors: Unveiling the Structure of Criminal Networks. In International
Workshop on Recent Advances in Intrusion Detection. Springer Berlin Heidelberg,
390–410.
[40] Terry Nelms, Roberto Perdisci, Manos Antonakakis, and Mustaque Ahamad. 2015.
WebWitness: Investigating, Categorizing, and Mitigating Malware Download
Paths.. In USENIX Security Symposium. 1025–1040.
[41] Terry Nelms, Roberto Perdisci, Manos Antonakakis, and Mustaque Ahamad.
2016. Towards Measuring and Mitigating Social Engineering Software Download