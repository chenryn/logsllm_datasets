which we assume is constant (it is typically small). Thus, the
end-to-end runtime to compute guess counts for a rule list is
When the last term is smaller than O(|rlist| · |wlist|)
and t is smaller than |rlist|, our method is faster. This
rough analysis is only meant to highlight the trade-offs in
our design and does not apply when rules are uninvertible.
Another inaccuracy comes from cases when guess_count
does more than a constant-time lookup in a table. For instance,
it may need to sum over the table. However, these operations
did not dominate processing in practice.
O(|rlist| + |wlist| · t + Σt
i=12|Gi|).
C. Putting it Together in a Guess-Number Calculator
We conclude by showing how to combine rule inversion
and guess counting to quickly compute a tight bound on the
number of guesses JtR issues before guessing a particular pass-
word. We deﬁne a function guess_number with signature:
num ← guess_number(rlist, cnts, pw).
Input rlist is a rule list, pw is a password for which we want
to compute the guess number, and cnts is a precomputed
array indexed by rules, populated with their guess counts:
cnts[rule] is the output of guess_count for that rule.
Following precomputation of cnts, guess_number is
easy to implement. It initializes num ← 0 and iterates over
rules in the order speciﬁed by rlist. For each rule, it uses
rule inversion to test if the rule guesses pw. If not, it adds the
corresponding guess count to num. If so, then we know the
guess number is between the current value of num and that
value plus the current rule’s guess count. We can either output
the range or estimate where in that range the guess occurs.
D. Hashcat Implementation
We implemented invert_rule for Hashcat with minor
modiﬁcations. Since Hashcat guesses in word-major order,
knowing which word guesses a password is more important
than knowing which rule does. For uninvertible rules, we
extend a C implementation of Hashcat’s rule engine [43] to
enumerate guesses. Hashcat’s guess_count differs greatly
from JtR, though, due to this ordering. Conceptually, Hashcat
ﬁrst applies all rules to the ﬁrst word. In practice, for I/O
efﬁciency it batches this process, taking A words and B rules
at a time. A and B are autotuned based on the hardware.
Because we need the number of guesses induced by
each word w when B rules are applied, our matrix-based
approach to JtR does not apply. We instead compute
the number of guesses induced by a word w using only
extract_features, creating one group per rule. We cre-
ate bit strings to determine whether or not a guess is made by
a rule, given a word. If the bit string is all 1s, then a guess
is made, and we increment a counter for the word: cwi. To
count the total guesses made by all rules in a batch, we sum
the guesses over those rules. Conceptually, this approach is
slower than for JtR. However, Hashcat’s standard mode does
not support rejection rules except in special cases [41], and
Hashcat does not support character classes (e.g., JtR’s ?d
representing any digit) except in hybrid mode. Thus, guess
counting is often trivial as each rule makes |wlist| guesses.
V. EVALUATION DATA SETS
a) Wordlists: While JtR and Hashcat
We analyze our techniques on three wordlists, six rule lists,
and six evaluation sets of passwords. We use these evaluation
sets alongside our analytical engine to tune the conﬁguration
(both order and completeness) of the rule lists and wordlists.
include sample
they are far smaller than those used in typical
wordlists,
attacks. Therefore, we selected three wordlists containing
password data and natural-language dictionaries that are more
typical of those used by experienced attackers [15]. XATO
is a set of 10 million passwords (5,189,378 unique entries)
sampled from thousands of leaked sets and released by a
security consultant in 2015 [44]. It has been used previously
in research [22]. PGS (19,436,159 entries) is a combina-
tion of passwords and dictionaries used in CMU’s Password
Guessability Service [8]. Lastly, LinkedIn is a set of pass-
words (60,169,992 unique entries) from the LinkedIn data
breach [45]. While hashes, not plaintext, were leaked, over
97% have been cracked. For XATO and LinkedIn, we took
the initial set, cleaned non-ASCII characters, and sorted them
by frequency, removing duplicates. PGS was already ordered.
b) Rule Lists: Since JtR and Hashcat do not use the
same rule language, we selected three typical rule lists for
three lists are for JtR. John (151 rules)
each. The ﬁrst
represents JtR’s default rules. SpiderLabs (5,146 rules) is a
version of a sample list KoreLogic released for a password-
cracking contest reordered by a human expert [16] in order
of anticipated effectiveness [18]. Megatron (15,329 rules)
combines the two sets of m3g9tr0n rules from Openwall [19].
The next three lists are for Hashcat, and all come with the
Hashcat software. Best64 (77 rules) functions as Hashcat’s
default best rules and was created and reﬁned in community
contests. T0XlC (4,085 rules) and Generated2 (65,117 rules)
are more extensive sets created by members of Team Hashcat.
c) Evaluation Sets: We evaluate our techniques on six
sets of passwords (Table II). We chose four sets that represent
password-composition policies and characteristics typically
seen in leaked password sets. We also chose to include one
(cid:20)(cid:25)(cid:24)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:40:17 UTC from IEEE Xplore.  Restrictions apply. 
Source
# Passwords
TABLE II: Description of evaluation sets.
Apparent Requirements
length ≥ 6 with letter & digit
length ≥ 6
length ≥ 6
length ≥ 6
length ≥ 8
length ≥ 6
13 million
500,000
800,000
2.2 million
6 million
70 million
000webhost [3]
Battleﬁeld Heroes [49]
Brazzers [50]
Clixsense [51]
CSDN [4]
Neopets [52]
set with a more strict composition policy (000webhost) and
one non-English, Chinese set (CSDN), whose characteristics
have been found to differ from English-language sets [46]. All
sets were leaked in plaintext except for Battleﬁeld Heroes, of
which over 99% has been cracked. Because UTF-8 support
in cracking software introduces subtleties [47] or is missing
entirely [48], we converted non-ASCII characters to ASCII.
Because cracking software limits the length of guesses, we re-
moved lines longer than 32 characters. This cleaning removed
at most 0.6% of passwords per set. We also removed lines
that did not comply with the composition policy, which may
be legacy accounts or errors. For all sets besides Neopets, this
removed under 2% of passwords. So sets would be of equal
size, we randomly sampled 25,000 passwords from each set.
VI. ETHICS
Our evaluation sets and some of our wordlists contain
passwords that were previously stolen and then leaked online.
Using this data raises ethical questions. We clean the data
of everything other than passwords, meaning that there is no
identifying information in the data we analyze. Furthermore,
these password lists are already available publicly online, so
the harm already caused to users is not exacerbated by our use
of the data. Lastly, the guess-number calculator we develop
(Section VII) enables real-time password checking, which we
anticipate will help users make more secure passwords.
Our techniques enable data-driven optimization of the order
and completeness of rule lists and wordlists (Sections VIII–
XI). While attackers could use our techniques to improve
attacks, we do not believe that releasing our tools substantially
advantages attackers. Members of the cracking community
have already invested massive amounts of computation in
developing and reﬁning their own rule lists and wordlists [38].
Experienced attackers’ curated lists are closely guarded se-
crets and are rarely shared publicly. In password-cracking
contests [17], prior academic evaluations [8], and media ar-
ticles [5], they substantially outperform lists released publicly.
While some attackers might beneﬁt from our tools, we expect
our tools primarily to better align the academic community’s
models with experts’ non-public lists and conﬁgurations.
VII. EVALUATION OF A GUESS-NUMBER CALCULATOR
As detailed in Section IV-B, our analytical tools can be
applied directly to generate a given password’s approximate
guess number (the number of guesses it would take that
approach in that conﬁguration to guess that password). Here,
we evaluate the proportion of rules in our six evaluation rule
lists that can be reasoned about analytically. We then present
TABLE III: Fraction of rule lists that are invertible/countable.
Brute-force
Enumerated
Invertible,
Uncountable
Invertible,
Countable
Rules
5,146
15,329
145
4,085
65,117
77
Rule List
John the Ripper
SpiderLabs
Megatron
John
Hashcat
T0XlC
Generated2
Best64
5,146 (100%)
14,840 ( 97%)
89 ( 61%)
3,980 ( 97%)
50,781 ( 78%)
62 ( 81%)
0 (0%)
467 (3%)
0 (0%)
0 (0%)
831 (1%)
0 (0%)
0 ( 0%)
22 ( 0%)
56 (39%)
105 ( 3%)
13,505 (21%)
15 (19%)
performance benchmarks showing orders-of-magnitude im-
provement in the time it takes to compute guess numbers for
common rule lists. With less than a day of pre-processing on
a commodity machine, we can generate guess numbers for a
given password in under one second for most lists we evaluate.
A. Breadth of Application
Rules that are both fully invertible and countable provide the
greatest beneﬁt for our approach because they can be analyzed
completely using our analytical tools, without enumerating
any guesses. Table III shows the fraction of each of our six
evaluation rule lists that are both invertible and countable. The
SpiderLabs rule list for JtR contains 5,146 rules, all of which
are both fully invertible and countable. Similarly, Megatron
contains 14,840 rules, of which over 97% are both fully invert-
ible and countable. These two large lists beneﬁt substantially
from our approach. John, however, contains only 145 rules,
and only 61% are both fully invertible and countable.
For Hashcat,
the T0XlC rule list contains 4,085 rules.
Because 97% of these are both invertible and countable, one
would again expect to see notable performance beneﬁts from
our analytical approach. In contrast, only 78% of the 65,117
Generated2 rules are both invertible and countable, and only
81% of the 77 Best64 rules are both invertible and countable,
so the beneﬁts of our analytical approach are more muted.
B. Performance Benchmarks
To gauge whether our analytical approach’s conceptual
advantages translate to reality, we benchmarked a Python im-
plementation of our approach and compared it with estimates
of naively enumerating guesses. We used a commodity server
with an Intel Core i7-4770 CPU (3.40GHz, 4 cores), 32 GB
of RAM, and 7200 RPM hard disks in RAID 1+0. We used
John the Ripper 1.8.0 and Hashcat v3.6.0. We calculated guess
numbers for all passwords in the 000webhost evaluation set
using a small (XATO) and a large (LinkedIn) wordlist.
We observed a performance beneﬁt of many orders of
magnitude for the JtR SpiderLabs rule list. Using the LinkedIn
wordlist,
this conﬁguration incurred a one-time cost of
16 hours of pre-processing. Subsequently, calculating a given
password’s guess number took 0.367 seconds on average, and
a maximum of 2.074 seconds. In contrast, enumerating the
3.01×1014 guesses this conﬁguration makes would have taken
approximately 4.7 years based on our benchmarked throughput
of ~12 million guesses per second piping JtR’s debug mode
(cid:20)(cid:25)(cid:25)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:40:17 UTC from IEEE Xplore.  Restrictions apply. 
TABLE IV: Performance comparison between naively enumerating guesses and our analytical approach. For enumeration, we
estimate the uncompressed size on disk for storing all guesses, as well as the time in seconds to pipe all guesses to stdout. For
the analytical approach, we present the pre-processing time (a one-time cost), as well as mean and max times for computing
a guess number in our tests. We also give the total size on disk of the auxiliary data, wordlist, and any enumerated guesses.
Rule List
SpiderLabs (JtR)
SpiderLabs (JtR)
Megatron (JtR)
Megatron (JtR)
John (JtR)
John (JtR)
T0XlC (HC)
T0XlC (HC)
generated2 (HC)
generated2 (HC)
Best64 (HC)
Best64 (HC)
Wordlist
LinkedIn
XATO
LinkedIn
XATO
LinkedIn
XATO
LinkedIn
XATO
LinkedIn
XATO
LinkedIn
XATO
# Guesses
3.01 × 1014
2.79 × 1013
7.27 × 1011
5.63 × 1010
3.57 × 1010
3.05 × 109
2.46 × 1011
2.12 × 1010
3.92 × 1012
3.38 × 1011
4.03 × 109
3.48 × 108
Size
3.3 PB
306.9 TB
8.0 TB
619.3 GB
392.7 GB
33.6 GB
2.7 TB
233.4 GB
43.2 TB
3.7 TB
44.4 GB
3.8 GB
Enumerating Guesses
Time (s)
1.51 × 108
1.39 × 107
3.64 × 105
2.82 × 104
1.78 × 104
1.53 × 103
2.46 × 104
2.12 × 103
3.92 × 105
3.38 × 104
4.03 × 102
3.48 × 101
Size
10.2 GB
4.9 GB
12.8 GB
1.1 GB
145.7 GB
12.9 GB
112.6 GB
8.7 GB
9.8 TB
754.1 GB
15.0 GB
1.2 GB
Our Analytical Approach
Pre-Processing (s) Mean Lookup (s) Max Lookup (s)
5.85 × 104
5.03 × 103
1.04 × 104
9.69 × 102
3.08 × 104
2.71 × 103
1.79 × 103
1.25 × 102
2.24 × 105
1.75 × 104
5.77 × 101
5.00 × 100
0.367
0.367
0.718
0.712
0.133
0.117
0.073
0.071
13.604
13.005
0.039
0.038
2.074
2.011
2.536
1.623
2.846
0.406
0.908
0.388
27.940
26.175
0.802
0.120
to stdout. While one could imagine enumerating guesses once,
writing them to disk, and sorting them to enable fast lookups,
doing so requires ~3.3 petabytes of disk (uncompressed).
We also observed performance beneﬁts, albeit smaller in
magnitude, for JtR’s Megatron rule lists and all three Hashcat
rule lists. Using the LinkedIn wordlist, our approach calculated
guess numbers in an average of 0.718 seconds for JtR’s
Megatron list and 0.073 seconds for Hashcat’s T0XlC list.
These approaches required pre-processing of 2.9 hours and
0.5 hours, respectively. This cost is amortized over looking
up guess numbers for many passwords. In contrast, writing
enumerated guesses to disk would require 8.0 terabytes and
2.7 terabytes (uncompressed), respectively. For fast lookups
in this naive approach, this data would also need to be sorted.
The beneﬁts of the analytical approach were not fully
universal, however. For the smallest JtR rule list (John), the
pre-processing time exceeded the time to enumerate (but not
sort) guesses. The analytical approach nonetheless enables fast
lookups (mean of 0.133 seconds for LinkedIn) with smaller
storage requirements. At a high level, the analytical approach
provided substantial performance beneﬁts for large rule lists in
which the vast majority of rules were invertible and countable,
particularly when paired with large wordlists.
Finally, our approach is highly accurate. We veriﬁed this
by randomly generating rules and comparing our analytical
evaluation to enumerated guesses, as detailed in Appendix B.
VIII. OPTIMIZATION 1: ORDERING RULE LISTS
to all words),
Because JtR generates guesses in rule-major order (ﬁrst
applying the ﬁrst rule in its rule list
the
order of rules is critical for JtR. Many publicly released
rule lists have been ordered through a combination of human
intuition [18] and empirical experiments [38] that are mostly
limited and undocumented. In such experiments, one collects
or creates large sets of rules, reordering the rules in descending
order of observed success against an evaluation set. Doing
so by enumerating guesses is highly time- and computation-
intensive. We use our novel analytical tools to do so efﬁciently.
TABLE V: Using the PGS wordlist, a comparison of the
original position of the ﬁrst 15 John rules (excluding guessing
words verbatim) and their position after reordering based on
000webhost (000wh), CSDN, and the four English-language
sets with identical password-composition policies (Others).
Original
000wh
CSDN
Others
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
93
9
4
94
5