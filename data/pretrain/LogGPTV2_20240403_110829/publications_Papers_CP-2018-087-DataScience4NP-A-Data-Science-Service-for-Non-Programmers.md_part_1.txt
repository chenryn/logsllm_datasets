DataScience4NP - A Data Science Service for
Non-Programmers
Bruno Leonel Lopes, Artur Pedroso, Jaime Correia, Filipe Araujo, Jorge
Cardoso, and Rui Pedro Paiva
CISUC, Dept. of Informatics Engineering, University of Coimbra, Portugal
{bllopes, apedroso}@student.dei.uc.pt
{jaimec, filipius, jcardoso, ruipedro}@dei.uc.pt
Abstract. With the emergence of Big Data, the scarcity of data scien-
tiststoanalyseallthedatabeingproducedindifferentdomainsbecame
evident. Moreover, the processing of such amounts of data also is chal-
lengingduetocurrenttechnologiesinuse.Withthisinmind,theData-
Science4NPaimstoexploretheuseofvisualprogrammingparadigmsto
enable non-programmers to be part of the data science workforce at a
faster pace and at the same time to provide a scalable data science ser-
vice.Byobservingthecommonprocessemployedbydatascientistsinthe
extraction of knowledge from data, which includes data insertion, pre-
processing, transformation, data mining and interpretation/evaluation
of results, we envisioned a system to perform all these steps without
requiring users to program. Thus, our solution aims to provide an in-
tuitiveuserinterfacewhereuserscanbuildpersonalizedsequentialdata
scienceworkflowsthatareconsequentlyprocessedbyaback-endservice.
The back-end service translates the received workflows to a lower-level
representation, enabling the execution of the translated tasks by sepa-
ratescalableanddistributeddatascienceservicesinparallel.Theentire
system is composed of different services containerized with Docker and
orchestrated with Kubernetes, allowing it to be easily deployed in dif-
ferent clusters. To evaluate our tool, and particularly to verify if the
concept we envisioned for the creation and execution of data science
tasks was intuitive, we conducted preliminary usability tests with two
different groups of people, where we observed a high level of user satis-
faction. Concluding, from the feedback obtained, it was clear that this
concept of sequential workflows would bring added value to both novice
and advanced data scientists.
Keywords: Data Science · Distributed systems · Cloud computing.
1 Introduction
Nowadays, large amounts of data are being produced from multiple sources.
However, not all these data can be analysed and some value might be conse-
quently lost. One particular challenge to performing data analysis is the lack of
data scientists, a resource in high demand these days [1–3]. Data scientists are
2 Lopes, Bruno Leonel et al.
a fundamental human resource for the extraction of knowledge from data due
to their data analysis and model creation skills. To overcome this issue more
data scientists need to be trained, which will take time due to the diversity of
knowledge areas that must be taught, where computer science is included [4].
Thus, by reducing computer science topics from the data scientists curriculum,
and providing means to create models without requiring users to use program-
ming languages, we can reduce the overall time required to train the new data
scientists. As such, we envisioned a software-as-a-service (SAAS) for data scien-
tists where it is possible to perform data mining experiments without requiring
programming skills from the users.
By visualizing the knowledge discovery process reported in [5], which is used
bymanydatascientists,wecreatedasystemthatenablestheapplicationofthis
process by allowing the construction of data science workflows composed by se-
quentialtasksthatgofromdatainsertiontointerpretation/evaluationofresults.
We enforce good practices of data mining, such as evaluation of models using
cross validation[17], nested cross validation, hold-out and train-validation-test
methods. We also enable the creation of multiple parallel models using different
parameters and features to select in the end the model that provides the best
results. All this functionalities are available from a browser, without requiring
users to install new software. The system follows a microservices architecture
and was already deployed on a kubernetes cluster to be tested.
To evaluate the acceptance of the concept provided in this software, we con-
ducted usability tests with a group of users familiar with data mining frame-
works, obtaining results that confirm our assumptions in relation to the envi-
sioned concept. We performed also a usability test with a group of students
without experience with such software tools but with background in statistics,
whom can also benefit with our software. We observed again an overall positive
user satisfaction in the last case.
The remaining document is organized as follows. In Section 2, we analyse
other related software tools. In Section 3, we describe the major requirements
of our software, its architecture and user interface. In Section 4, we present the
setupusedtoconducttheusabilitytests,andinSection5wepresentanddiscuss
the results acquired from the usability tests. Finally, in section 6 we draw the
main conclusions of this work and point out possible future research directions.
2 Related Work
Thedataminingprocessiscomposedofseveralsteps.Itstartswiththeinsertion
ofadatasetthatisprocessediterativelyuntila desiredresultisobtained andin
somecasesthefinalresultisamodelcreatedusingamachinelearningalgorithm.
A classifier is one type of model that is produced by supervised machine
learning algorithms. It receives typically a vector of discrete and/or continuous
feature values and outputs a single discrete value, the class [6].
To assess how the classifier will behave in the presence of new data, the user
must evaluate its performance, that is, its capacity to predict correct outputs
DataScience4NP - A Data Science Service for Non-Programmers 3
in the presence of new data. This assessment is properly performed by using
data that was not employed in the training phase, otherwise the evaluation
might be overly-optimistic [7]. Nonetheless it is not uncommon to see, even
in published articles, evaluations done with data already seen in the training
process, especially when data pre-processing/transformation precedes the use
of the final machine learning algorithm. Other common situation where overly-
optimistic results are verified occurs when parameter optimization is done. The
issues might be overcome by employing evaluation mechanisms such as nested
cross-validation [8].
Some applications that offer users the possibility to build data mining pro-
cesses without programming also lack in enforcing good data mining practices
to evaluate the produced models. Other applications provide correct evaluation
procedures by introducing some complexity to the user while building the data
science workflow. Next, we cite some of these applications.
AzureML [9], H2O.ai [10], Orange [11], Weka [12], and RapidMiner [13] are
systems/applicationsinproductionthatprovidevisualprogrammingparadigms
to help users building their models. Among these applications, AzureML is the
only one publicly deployed that can be accessed from a browser. H2O.ai is not
publicly deployed but can be installed in a cluster or locally and then used from
a browser. Weka and Orange are standalone solutions that must be installed
locally.RapidMineristheonlyapplicationamongthepreviousonesthatprovides
nested cross validation for parameter optimization, however it also needs to be
installed locally.
ClowdFlows [14], DAMIS [16], and Zorrilla, M. and Garc´ıa Saiz, D. [18] are
researchprojects.InClowdflowsandDAMISwerecreatedcloudsystemsthatal-
lowuserstodefinedatascienceworkflowsinabrowserusingvisualprogramming
paradigms. Clowdflows assumes some previous experience with tools like Weka,
Orange or Scikit-Learn [15]. In Zorrilla, M. and Garc´ıa Saiz, D. it was created
a system following a SOA architecture that allows users to extract knowledge
fromdatabyusingpredefinedtemplates.Insteadofallowinguserstocreatenew
models and evaluate them, the system just applies operations defined in pre-
defined templates to a user's dataset. None of the last three projects provide
nested cross validation.
Allthecitedapplicationsthatprovidethecreationofmodelsrequiretheuser
to build more complex workflows to create experiments where multiple features
and parameters are tested to produce the model with best performance. In our
system we will enforce the execution of this process with less complexity to the
user and using good data mining practices.
3 Implementation
Having in mind the limitations identified in related applications, presented in
the previous section, we focused in creating a prototype to overcome some of
these issues. In this section we proceed with a more detailed description of our
system.
4 Lopes, Bruno Leonel et al.
3.1 Requirements
The identification of issues in related applications gave us the following list of
main requirements to address in our solution:
– Provide an application with high usability standards for non-programmers
to execute data science tasks.
– Providedifferentdatapre-processing/transformationmethods,featureselec-
tion and machine learning algorithms.
– Allow the creation of models using different features and parameters to se-
lect the best configuration of features and parameters automatically in the
end. Here, good data mining practices are enforced, e.g., using nested cross
validation.
– Provideaccesstotheapplicationwithoutrequiringuserstoinstallitintheir
machines.
– Parallelize data science tasks when possible to get faster results.
– Provide a scalable system to support large numbers of users.
3.2 Architecture
To satisfy the previous requirements we envisioned a cloud application available
through the Internet that follows a microservices architecture and is depicted in
Fig. 1.
UI Service
Get app
Send request
APIGateway
User
Redirectrequest
Mongo Mongo Mongo Mongo
DB DB DB DB
Tasks Service User Service Workflows Service Datasets Service
Post/Get
Read and Write file
translated workflow
Get/Update
Data Science Service Conductor Service
task NFS
Read and Write file
Fig.1. System architecture.
DataScience4NP - A Data Science Service for Non-Programmers 5
Whenausercontactsoursystem,thefirstaccessisdirectedtotheUIService
thatprovidesawebapplicationwritteninReactJS,fromwhichfurtherrequests
are done to our API Gateway that redirects the requests to different services
accordingly.
TheTasksServicereturnsthedatasciencetasksthatcanbeusedbytheuser
to compose a sequential data science workflow. The User Service enables users
to login in the system with a username and a password and holds information
related to users. The Datasets Service stores uploaded datasets in a distributed
file system (an NFS server) and also returns data from the NFS according to
users requests. Then, we have the Workflows Service that translates sequential
workflows sent by users, which are composed of simple data science tasks, into
a representation that is understandable by Netflix Conductor [19]. The new
workflow representation is sent to the Conductor Service and becomes available
to be processed by different Data Science services. The Workflows Service is
also contacted to return the status of workflows sent by users. Finally, the Data
ScienceServiceisinrealitycomposedofmultiplefinegrainedservicesthatwork
on specific data science tasks present in the Conductor Service. These Data
ScienceServicessharefiles(e.g.,datasets,models)betweenthembywritingand
reading to/from the NFS.
The communications between all the services presented in the architecture
are performed using the HTTP protocol, mainly through REST APIs.
Datasetinput
SplitDataset
Train-Test
validation
procedure Feature scaling
FeatureScaling SVMcreation Featurescaling
SVMprediction
SVM
Calculateaccuracy
Accuracy
Fig.2. Example of a data science workflow translation.
To better understand how individual data science tasks are processed in the
system,inFig.2wepresentanexampleofatranslationfromasimplesequential
workflowsentbytheuser(ontheleft),toitsrepresentationinNetflixConductor
(on the right).
6 Lopes, Bruno Leonel et al.
In the sequential workflow, the user inserts the location of the dataset to
use. Then he specifies that the procedure might be evaluated using the hold out
/ train-test method. He also specifies that he wants to apply a feature scaling
operation, followed by the creation of a model using the SVM algorithm. In the
end, the user wants to check the accuracy of the model.
Upon receiving the workflow, the Workflows Service translates it to a repre-
sentation that is understandable by Netflix Conductor and sends such represen-
tation to the Conductor Service. It contains a Split Dataset task (split original
dataintrainandtestsets)thatisfollowedbyaFeaturescalingtask(appliedto
train set). The Feature scaling task precedes a fork that allows the execution of
an SVM creation task (applied to train set) and a Feature scaling task (applied
to test set) in parallel. The SVM prediction task (applied to test set using the
model created before) will only be able to execute after the previous two tasks
become completed. Finally, there exists a task to compute the accuracy of the
model.
By using the Netflix Conductor technology we can parallelize the tasks and
orchestrate Data Science services to work in the different tasks in parallel and
independently, following a competing consumers pattern [20]. The Data science
services will be able to scale independently according to the type of tasks that
require more workers.
The translation described before is simple, though when a user sends for
example a workflow containing a cross validation task to evaluate the model or
sendsaworkflowwithdifferentnumbersoffeaturesorparameterstoproducean