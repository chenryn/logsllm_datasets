### DataScience4NP: A Data Science Service for Non-Programmers

**Authors:**  
Bruno Leonel Lopes, Artur Pedroso, Jaime Correia, Filipe Araujo, Jorge Cardoso, and Rui Pedro Paiva  
**Affiliation:**  
CISUC, Department of Informatics Engineering, University of Coimbra, Portugal  
**Emails:**  
{bllopes, apedroso}@student.dei.uc.pt, {jaimec, filipius, jcardoso, ruipedro}@dei.uc.pt

#### Abstract
The rise of Big Data has highlighted the scarcity of data scientists capable of analyzing the vast amounts of data generated across various domains. Additionally, processing such large datasets is challenging due to the limitations of current technologies. To address these issues, DataScience4NP leverages visual programming paradigms to enable non-programmers to participate in data science activities more efficiently and provides a scalable data science service. By observing the common processes employed by data scientists—such as data insertion, preprocessing, transformation, data mining, and result interpretation—we designed a system that automates these steps without requiring users to write code. Our solution offers an intuitive user interface for building personalized, sequential data science workflows, which are then processed by a back-end service. The back-end translates these workflows into a lower-level representation, enabling their execution by scalable and distributed data science services in parallel. The entire system is containerized with Docker and orchestrated with Kubernetes, facilitating easy deployment in different clusters. Preliminary usability tests with two groups of users, including both novices and experienced data scientists, demonstrated high levels of user satisfaction, confirming the value of our approach.

**Keywords:** Data Science, Distributed Systems, Cloud Computing

#### 1. Introduction
In today's data-driven world, large volumes of data are being generated from multiple sources. However, not all of this data can be analyzed, leading to potential loss of valuable insights. One significant challenge in data analysis is the shortage of data scientists, who are in high demand [1–3]. Data scientists play a crucial role in extracting knowledge from data through their expertise in data analysis and model creation. Training more data scientists is a time-consuming process due to the diverse skill sets required, including computer science [4]. By reducing the emphasis on programming in the data scientist curriculum and providing tools that allow model creation without coding, we can expedite the training process. Therefore, we developed a software-as-a-service (SaaS) platform for data scientists that enables data mining experiments without requiring programming skills.

By examining the knowledge discovery process outlined in [5], which is widely used by data scientists, we created a system that allows users to construct data science workflows consisting of sequential tasks, from data insertion to result interpretation. We enforce best practices in data mining, such as cross-validation [17], nested cross-validation, hold-out, and train-validation-test methods. Users can create multiple parallel models with different parameters and features, ultimately selecting the best-performing model. All these functionalities are accessible via a web browser, eliminating the need for users to install additional software. The system follows a microservices architecture and has been deployed on a Kubernetes cluster for testing.

To evaluate the acceptance of our concept, we conducted usability tests with two groups: one familiar with data mining frameworks and another comprising students with a background in statistics but no experience with such tools. Both groups reported high levels of user satisfaction, validating our approach.

The rest of this document is organized as follows:
- **Section 2:** Analysis of related software tools.
- **Section 3:** Description of the major requirements, architecture, and user interface of our software.
- **Section 4:** Setup used for the usability tests.
- **Section 5:** Presentation and discussion of the results from the usability tests.
- **Section 6:** Conclusions and future research directions.

#### 2. Related Work
The data mining process involves several steps, starting with dataset insertion and iterative processing until the desired result is achieved. In some cases, the final result is a model created using a machine learning algorithm. A classifier, produced by supervised learning algorithms, takes a vector of discrete and/or continuous feature values and outputs a single discrete class [6].

To assess a classifier's performance, it must be evaluated using data not seen during the training phase to avoid overly optimistic results [7]. Common evaluation mechanisms include nested cross-validation [8].

Several applications offer visual programming paradigms for building data mining processes without programming, but they often lack enforcement of good data mining practices. Some of these applications include:

- **AzureML [9]:** Publicly accessible from a browser.
- **H2O.ai [10]:** Can be installed in a cluster or locally and accessed via a browser.
- **Orange [11] and Weka [12]:** Standalone solutions that require local installation.
- **RapidMiner [13]:** Provides nested cross-validation but requires local installation.

Research projects like ClowdFlows [14], DAMIS [16], and Zorrilla, M. and Garc´ıa Saiz, D. [18] also provide cloud-based systems for defining data science workflows. However, they either assume prior experience with specific tools or use predefined templates, limiting flexibility and not providing nested cross-validation.

Our system aims to simplify the creation of complex workflows while enforcing good data mining practices, making it more accessible to non-programmers.

#### 3. Implementation

##### 3.1 Requirements
Based on the limitations identified in related applications, we defined the following key requirements for our solution:

- **High Usability:** An application with high usability standards for non-programmers to execute data science tasks.
- **Data Preprocessing and Transformation:** Provide various data preprocessing, transformation, feature selection, and machine learning algorithms.
- **Model Creation:** Allow the creation of models using different features and parameters, automatically selecting the best configuration using good data mining practices like nested cross-validation.
- **Accessibility:** Accessible via a web browser without requiring local installation.
- **Parallelization:** Parallelize data science tasks to achieve faster results.
- **Scalability:** Support a large number of users with a scalable system.

##### 3.2 Architecture
To meet these requirements, we designed a cloud-based application with a microservices architecture, as shown in Figure 1.

![System Architecture](Fig.1. System architecture.)

When a user accesses our system, they first interact with the UI Service, which provides a web application written in ReactJS. Further requests are directed to the API Gateway, which routes them to the appropriate services.

- **Tasks Service:** Returns the available data science tasks for users to compose workflows.
- **User Service:** Manages user authentication and stores user information.
- **Datasets Service:** Stores and retrieves uploaded datasets using a distributed file system (NFS).
- **Workflows Service:** Translates user-defined sequential workflows into a format understandable by Netflix Conductor [19].
- **Conductor Service:** Orchestrates the execution of translated workflows by different Data Science services.
- **Data Science Services:** Fine-grained services that handle specific data science tasks, sharing files via NFS.

Communication between services is primarily via HTTP using REST APIs.

Figure 2 illustrates an example of how a simple sequential workflow is translated into a representation for Netflix Conductor.

![Workflow Translation Example](Fig.2. Example of a data science workflow translation.)

In this example, the user specifies the dataset location, evaluation method (hold-out/train-test), feature scaling, and SVM model creation. The workflow is then translated into a series of tasks, including dataset splitting, feature scaling, SVM model creation, and accuracy calculation. This translation allows for parallel execution of tasks, improving efficiency and scalability.

By leveraging Netflix Conductor, we can parallelize and orchestrate data science tasks, following a competing consumers pattern [20]. This ensures that the system can scale independently based on the type of tasks and the number of workers required.

This simple translation example demonstrates the system's ability to handle more complex workflows, such as those involving cross-validation or multiple feature and parameter configurations, ensuring optimal performance and ease of use for non-programmers.