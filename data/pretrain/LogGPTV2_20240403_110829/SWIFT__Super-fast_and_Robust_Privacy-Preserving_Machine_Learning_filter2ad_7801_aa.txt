title:SWIFT: Super-fast and Robust Privacy-Preserving Machine Learning
author:Nishat Koti and
Mahak Pancholi and
Arpita Patra and
Ajith Suresh
SWIFT: Super-fast and Robust Privacy-Preserving 
Machine Learning
Nishat Koti, Mahak Pancholi, Arpita Patra, and Ajith Suresh, 
Indian Institute of Science, Bangalore
https://www.usenix.org/conference/usenixsecurity21/presentation/koti
This paper is included in the Proceedings of the 30th USENIX Security Symposium.August 11–13, 2021978-1-939133-24-3Open access to the Proceedings of the 30th USENIX Security Symposium is sponsored by USENIX.SWIFT: Super-fast and Robust Privacy-Preserving Machine Learning
Nishat Koti
Indian Institute of Science
Mahak Pancholi
Indian Institute of Science
Ajith Suresh
Indian Institute of Science
Arpita Patra
Indian Institute of Science
Abstract
Performing machine learning (ML) computation on private
data while maintaining data privacy, aka Privacy-preserving
Machine Learning (PPML), is an emergent ﬁeld of research.
Recently, PPML has seen a visible shift towards the adoption
of the Secure Outsourced Computation (SOC) paradigm due
to the heavy computation that it entails. In the SOC paradigm,
computation is outsourced to a set of powerful and specially
equipped servers that provide service on a pay-per-use basis.
In this work, we propose SWIFT, a robust PPML framework
for a range of ML algorithms in SOC setting, that guarantees
output delivery to the users irrespective of any adversarial
behaviour. Robustness, a highly desirable feature, evokes user
participation without the fear of denial of service.
At the heart of our framework lies a highly-efﬁcient,
maliciously-secure, three-party computation (3PC) over rings
that provides guaranteed output delivery (GOD) in the honest-
majority setting. To the best of our knowledge, SWIFT is the
ﬁrst robust and efﬁcient PPML framework in the 3PC set-
ting. SWIFT is as fast as (and is strictly better in some cases
than) the best-known 3PC framework BLAZE (Patra et al.
NDSS’20), which only achieves fairness. We extend our 3PC
framework for four parties (4PC). In this regime, SWIFT is as
fast as the best known fair 4PC framework Trident (Chaudhari
et al. NDSS’20) and twice faster than the best-known robust
4PC framework FLASH (Byali et al. PETS’20).
We demonstrate our framework’s practical relevance by
benchmarking popular ML algorithms such as Logistic Re-
gression and deep Neural Networks such as VGG16 and
LeNet, both over a 64-bit ring in a WAN setting. For deep
NN, our results testify to our claims that we provide improved
security guarantee while incurring no additional overhead for
3PC and obtaining 2× improvement for 4PC.
1 Introduction
Privacy Preserving Machine Learning (PPML), a booming
ﬁeld of research, allows Machine Learning (ML) computa-
tions over private data of users while ensuring the privacy of
the data. PPML ﬁnds applications in sectors that deal with sen-
sitive/conﬁdential data, e.g. healthcare, ﬁnance, and in cases
where organisations are prohibited from sharing client infor-
mation due to privacy laws such as CCPA and GDPR. How-
ever, PPML solutions make the already computationally heavy
ML algorithms more compute-intensive. An average end-user
who lacks the infrastructure required to run these tasks prefers
to outsource the computation to a powerful set of specialized
cloud servers and leverage their services on a pay-per-use
basis. This is addressed by the Secure Outsourced Computa-
tion (SOC) paradigm, and thus is an apt ﬁt for the need of the
moment. Many recent works [11, 14, 15, 41, 43, 45, 48, 50, 55]
exploit Secure Multiparty Computation (MPC) techniques
to realize PPML in the SOC setting where the servers enact
the role of the parties. Informally, MPC enables n mutually
distrusting parties to compute a function over their private
inputs, while ensuring the privacy of the same against an
adversary controlling up to t parties. Both the training and
prediction phases of PPML can be realized in the SOC set-
ting. The common approach of outsourcing followed in the
PPML literature, as well as by our work, requires the users to
secret-share1 their inputs between the set of hired (untrusted)
servers, who jointly interact and compute the secret-shared
output, and reconstruct it towards the users.
In a bid to improve practical efﬁciency, many recent
works [5, 11, 14, 15, 19, 24–26, 33–35, 48] cast their protocols
into the preprocessing model wherein the input-independent
(yet function-dependent) phase computationally heavy tasks
are computed in advance, resulting in a fast online phase. This
paradigm suits scenario analogous to PPML setting, where
functions (ML algorithms) typically need to be evaluated a
large number of times, and the function description is known
beforehand. To further enhance practical efﬁciency by lever-
aging CPU optimizations, recent works [6, 20, 23, 25, 27]
propose MPC protocols that work over 32 or 64 bit rings.
Lastly, solutions for a small number of parties have re-
ceived a huge momentum due to the many cost-effective
1The threshold of the secret-sharing is decided based on the number of
corrupt servers so that privacy is preserved.
USENIX Association
30th USENIX Security Symposium    2651
customizations that they permit, for instance, a cheaper reali-
sation of multiplication through custom-made secret sharing
schemes [3, 4, 11, 14, 15, 48].
We now motivate the need for robustness aka guaranteed
output delivery (GOD) over fairness2, or even abort security3,
in the domain of PPML. Robustness provides the guarantee of
output delivery to all protocol participants, no matter how the
adversary misbehaves. Robustness is crucial for real-world
deployment and usage of PPML techniques. Consider the
following scenario wherein an ML model owner wishes to
provide inference service. The model owner shares the model
parameters between the servers, while the end-users share
their queries. A protocol that provides security with abort or
fairness will not sufﬁce as in both the cases a malicious adver-
sary can lead to the protocol aborting, resulting in the user not
obtaining the desired output. This leads to denial of service
and heavy economic losses for the service provider. For data
providers, as more training data leads to more accurate mod-
els, collaboratively building a model enables them to provide
better ML services, and consequently, attract more clients. A
robust framework encourages active involvement from multi-
ple data providers. Hence, for the seamless adoption of PPML
solutions in the real world, the robustness of the protocol is of
utmost importance. Several works [14,15,43,48,55] realizing
PPML via MPC settle for weaker guarantees such as abort
and fairness. Achieving the strongest notion of GOD without
degrading performance is an interesting goal which forms
the core focus of this work. The hall-mark result of [17] sug-
gests that an honest-majority amongst the servers is necessary
to achieve robustness. Consequent to the discussion above,
we focus on the honest-majority setting with a small set of
parties, especially 3 and 4 parties, both of which have drawn
enormous attention recently [3,4,8,9,11,13–15,30,44,46,48].
The 3/4-party setting enables simpler, more efﬁcient, and
customized secure protocols compared to the n-party setting.
Real-world MPC applications and frameworks such as the
Danish sugar beet auction [7] and Sharemind [6], have demon-
strated the practicality of 3-party protocols. Additionally, in
an outsourced setting, 3/4PC is useful and relevant even when
there are more parties. Speciﬁcally, here the entire computa-
tion is ofﬂoaded to 3/4 hired servers, after initial sharing of
inputs by the parties amongst the servers. This is precisely
what we (and some existing papers [11, 42, 48]) contemplate
as the setting for providing ML-as-a-service. Our protocols
work over rings, are cast in the preprocessing paradigm, and
achieve GOD.
Related Work We restrict the relevant work to a small num-
ber of parties and honest-majority, focusing ﬁrst on MPC,
followed by PPML. MPC protocols for a small population
can be cast into orthogonal domains of low latency proto-
cols [12, 13, 47], and high throughput protocols [1, 3, 4, 6, 9,
14, 16, 29, 30, 46, 48]. [4, 14] provide efﬁcient semi-honest
protocols wherein ASTRA [14] improved upon [4] by casting
the protocols in the preprocessing model and provided a fast
online phase. ASTRA further provided security with fairness
in the malicious setting with an improved online phase com-
pared to [3]. Later, a maliciously-secure 3PC protocol based
on distributed zero-knowledge techniques was proposed by
Boneh et al. [8] providing abort security. Further, building
on [8] and enhancing the security to GOD, Boyle et al. [9] pro-
posed a concretely efﬁcient 3PC protocol with an amortized
communication cost of 3 ﬁeld elements (can be extended
to work over rings) per multiplication gate. Concurrently,
BLAZE [48] provided a fair protocol in the preprocessing
model, which required communicating 3 ring elements in
each phase. However, BLAZE eliminated the reliance on the
computationally intensive distributed zero-knowledge system
(whose efﬁciency kicks in for large circuit or many multi-
plication gates) from the online phase and pushed it to the
preprocessing phase. This resulted in a faster online phase
compared to [9].
In the regime of 4PC, Gordon et al. [31] presented proto-
cols achieving abort security and GOD. However, [31] relied
on expensive public-key primitives and broadcast channels
to achieve GOD. Trident [15] improved over the abort proto-
col of [31], providing a fast online phase achieving security
with fairness, and presented a framework for mixed world
computations [27]. A robust 4PC protocol was provided in
FLASH [11], which requires communicating 6 ring elements,
each, in the preprocessing and online phases.
In many recent works [9,11,13], including this work, GOD
is achieved by having an honest party, identiﬁed as a trusted
third party (TTP), compute the function on the ‘clear’ inputs
of all the parties (in the case of a misbehaviour). The classical
security deﬁnition allows this leakage of inputs since the
selected TTP is honest. There has been a recent study on the
additional requirement of hiding the inputs from a quorum
of honest parties (treating them as semi-honest), termed as
Friends-and-Foes (FaF) security notion [2]. This is a stronger
security goal than the classical one. Recently, the work of
[22] attempts to offer a variant of GOD, referred to as private
robustness in 4PC setting. As per the authors, in a private
robust protocol, no single honest party learns the other honest
parties’ input. We want to point out that [22] does not achieve
FaF security notion [2], since an adversary can reveal its view
to an honest party, making it obtain the inputs of the other
honest parties. 4
In the PPML domain, MPC has been used for various
ML algorithms such as Decision Trees [40], Linear Regres-
sion [28, 51], k-means clustering [10, 32], SVM Classiﬁca-
tion [54, 57], Logistic Regression [53]. In the 3PC SOC set-
ting, the works of ABY3 [43] and SecureNN [55], provide
security with abort. This was followed by ASTRA [14], which
2This ensures either all parties or none learn the output.
3This may allow the corrupt parties alone to learn the output.
4Lastly, but importantly, the precise security notion achieved in [22] is
unclear due to the lack of formal details.
2652    30th USENIX Security Symposium
USENIX Association
improves upon ABY3 and achieves security with fairness. AS-
TRA presents primitives to build protocols for Linear Regres-
sion and Logistic Regression inference. Recently, BLAZE
improves over the efﬁciency of ASTRA and additionally tack-
les training for the above ML tasks, which requires building
additional PPML building blocks, such as truncation and bit
to arithmetic conversions. In the 4PC setting, the ﬁrst robust
framework for PPML was provided by FLASH [11] which
proposed efﬁcient building blocks for ML such as dot product,
truncation, MSB extraction, and bit conversion. The works
of [11,14,15,43,45,48,55] work over rings to garner practical
efﬁciency. In terms of efﬁciency, BLAZE and respectively
FLASH and Trident are the closest competitors of this work
in 3PC and 4PC settings. We now present our contributions
and compare them with these works.
1.1 Our Contributions
We propose, SWIFT [36], a robust maliciously-secure frame-
work for PPML in the SOC setting, with a set of 3 and 4
servers having an honest-majority. At the heart of our frame-
work lies highly-efﬁcient, maliciously-secure, 3PC and 4PC
over rings (both Z2(cid:96) and Z21) that provide GOD in the honest-
majority setting. We cast our protocols in the preprocessing
model, which helps obtain a fast online phase. As mentioned
earlier, the input-independent (yet function-dependent) com-
putations will be performed in the preprocessing phase.
To the best of our knowledge, SWIFT is the ﬁrst robust and
efﬁcient PPML framework in the 3PC setting and is as fast as
(and is strictly better in some cases than) the best known fair
3PC framework BLAZE [48]. We extend our 3PC framework
for 4 servers. In this regime, SWIFT is as fast as the best
known fair 4PC framework Trident [15] and twice faster than
best known robust 4PC framework FLASH [11]. We detail
our contributions next.
Robust 3/4PC frameworks The framework consists of a
range of primitives realized in a privacy-preserving way which
is ensured via running computation in a secret-shared fash-
ion. We use secret-sharing over both Z2(cid:96) and its special in-
stantiation Z21 and refer them as arithmetic and respectively
boolean sharing. Our framework consists of realizations for
all primitives needed for general MPC and PPML such as
multiplication, dot-product, truncation, bit extraction (given
arithmetic sharing of a value v, this is used to generate boolean
sharing of the most signiﬁcant bit (msb) of the value), bit to
arithmetic sharing conversion (converts the boolean sharing
of a single bit value to its arithmetic sharing), bit injection
(computes the arithmetic sharing of b· v, given the boolean
sharing of a bit b and the arithmetic sharing of a ring element
v) and above all, input sharing and output reconstruction in
the SOC setting. A highlight of our 3PC framework, which,
to the best of our knowledge is achieved for the ﬁrst time, is a
robust dot-product protocol whose (amortized) communica-
tion cost is independent of the vector size, which we obtain by
extending the techniques of [8, 9]. The performance compari-
son in terms of concrete cost for communication and rounds,
for PPML primitives in both 3PC and 4PC setting, appear
in Table 1. As claimed, SWIFT is on par with BLAZE for
most of the primitives (while improving security from fair
to GOD) and is strictly better than BLAZE in case of dot
product and dot product with truncation. For 4PC, SWIFT is
on par with Trident in most cases (and is slightly better for
dot product with truncation and bit injection), while it is dou-
bly faster than FLASH. Since BLAZE outperforms the 3PC
abort framework of ABY3 [43] while Trident outperforms the
known 4PC with abort [31], SWIFT attains robustness with
better cost than the know protocols with weaker guarantees.
No performance loss coupled with the strongest security guar-
antee makes our robust framework an opt choice for practical
applications including PPML.
Applications and Benchmarking We demonstrate the prac-
ticality of our protocols by benchmarking PPML, particu-
larly, Logistic Regression (training and inference) and popular
Neural Networks (inference) such as [45], LeNet [38] and
VGG16 [52] having millions of parameters. The NN training
requires mixed-world conversions [15,27,43], which we leave
as future work. Our PPML blocks can be used to perform
training and inference of Linear Regression, Support Vector
Machines, and Binarized Neural Networks (as demonstrated
in [11, 14, 15, 48]).
Comparisons and Differences with Prior Works To begin
with, we introduce a new primitive called Joint Message Pass-