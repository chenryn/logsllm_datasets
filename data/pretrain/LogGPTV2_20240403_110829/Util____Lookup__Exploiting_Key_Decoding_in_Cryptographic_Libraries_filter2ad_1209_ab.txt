SGX keeps track of all EPC memory pages including their expected
virtual address in the Enclave Page Cache Map (EPCM) [24].
2.2.2 Context switches. Programs running in Intel SGX are subject
to context switches as any other process. Since enclaves are iso-
lated from the remaining system, context switch require dedicated
instructions provided by SGX [24, 55]. After an enclave was created
with the ECREATE instruction, it can be entered with EENTER. In case
the processor is interrupted while in enclave mode, SGX ensures
that Asynchronous Enclave Exit (AEX) is executed, storing the
execution state to a secure area and cleaning up the registers. Ad-
ditionally, the instruction pointer is set to the Asynchronous Exit
handler Pointer (AEP), causing the system’s interrupt handler to
return to AEP when it finishes. Finally, ERESUME can be called from
the asynchronous exit handler to resume execution of the enclave.
2.2.3 Attacks on Intel SGX. Trusted execution environments like
Intel SGX feature an attacker model which assumes an untrusted OS,
and thus enables adversaries to tamper with all system resources
to extract information from isolated enclaves.
Amplifying side-channels with control over system events and
resources, such as page faults or interrupts, and using this to reduce
noise, is called a controlled-channel attack [80]. SGX-Step [20] intro-
duced a framework for controlled-channel attacks on SGX, which
was used in many subsequent attacks [3, 19, 21, 59]. It enables the
attacker to single step enclaves and to manipulate page table entries
in order to get insight into the control flow. Transient execution
attacks on SGX [18, 19, 22, 67, 71] have forced Intel to publish mi-
crocode and software mitigations. One countermeasure pushed via
microcode updates is to flush microarchitectural buffers such as the
L1 data cache upon enclave exit [39]. In addition, compilers now
insert fences in enclave code to prevent Spectre-like attacks. Fur-
thermore, disabling simultaneous multithreading is recommended
when executing enclaves. In addition to transient execution attacks
and controlled-channel attacks, other vulnerabilities were found
targeting e. g. the cache [25, 58] or the branch history [48].
2.3 RSA Key recovery
Recovering the complete RSA key from partial information has
been studied in numerous settings. In theory, it is sufficient to
store only one of the primes 𝑝 or 𝑞 as private key, but this is very
inefficient. To speed up the decryption of messages via the Chinese
Remainder Theorem (CRT), all of the values (𝑝, 𝑞, 𝑑, 𝑑𝑝, 𝑑𝑞, 𝑞−1
𝑝 )
are stored, where 𝑑𝑝 := 𝑑 (mod 𝑝 − 1), 𝑑𝑞 := 𝑑 (mod 𝑞 − 1), and
(𝑞−1
𝑝 · 𝑞) (mod 𝑝) = 1. Note that the knowledge of any single of
these variables is sufficient to reconstruct all other variables, given
the public key (𝑁 , 𝑒) [35].
There are roughly two kinds of partial information that are
obtained by side-channel attacks: consecutive information and non-
consecutive information. In the consecutive case, the attacker ob-
tains a few number of consecutive blocks of information about some
of the variables, e. g. the ⟨𝑝⟩/2 most significant bits of 𝑝, where ⟨𝑝⟩
is the encoding length of 𝑝, i. e. ⟨𝑝⟩ := ⌈log2(𝑝+1)⌉ or the ⟨𝑝⟩/4 most
significant bits of 𝑝 and the ⟨𝑝⟩/4 least significant bits of 𝑝. This
continuity gives a high amount of structured information, which
allows an attacker to mount attacks based on lattices. For the many
applications of this technique to reconstruct parts of the private
key, we refer to the surveys [12, 53, 72]. This technique was also
used in a recent work to recover RSA keys [60], where the authors
were able to obtain partial leakages of 𝑞 on consecutive positions
and could use this information to derive 𝑞 completely.
In the non-consecutive case, the information is widely spread
over the variables. A widely used algorithm for this case was pre-
sented by Heninger and Shacham and subsequently generalized by
Henecka et al. and Paterson et al. [34, 35, 65]. In a naive fashion, one
could try to construct a search tree that aims to test all possibilities
for the 6 different unknown variables, which gives a solution space
of 26𝑛. Whenever a candidate is encountered that does not fit to the
partial known information, we can prune this candidate. The main
idea of Heninger and Shacham is to use the different dependencies
between the variables to set up an equation system containing 4
equations and 5 variables, which drastically reduces the solution
Session 10A: Crypto, Symbols and Obfuscation CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2458space to 2𝑛. Given sufficient information from side-channel attacks
can then be used to further reduce this space. This approach was
used for many attacks, e. g. [11, 16, 31, 82]. In all variations of the
algorithm, the partial information contains information on a bit-
wise level, while our attack works on information about blocks of
bits. We thus adapt the algorithm of Heninger and Shacham to this
setting in Section 5.
3 EXPLOITING KEY DECODING
In this section we analyze possible leakages in the key decoding
routines of various cryptographic libraries. First, we describe the
Privacy-enhanced Electronic Mail (PEM) format, which is used for
storing and exchanging cryptographic material, and is supported
by many common cryptographic implementations. We use the Mi-
crowalk [78] framework to conduct a broad analysis of several
popular libraries, including OpenSSL [63], wolfSSL [79], NSS [62],
and Botan [15] in order to find and assess possible leakages in key
decoding. Microsoft CNG itself does not offer native key decoding,
and offloads this onto the user; however, its largely deprecated
predecessor Microsoft Crypto API [56] is still included in recent
Windows versions, and supports loading and storing PEM format-
ted keys. WolfSSL, RustSGX [69] and mbedTLS [54] offer native
SGX support, and with TaLoS [73] there also is an SGX mode for
OpenSSL. Finally, we analyze Microwalk’s findings and show that
lookup table (LUT)-based base64 decoding poses a significant and
widespread source of leakage, which we exploit to infer the entire
private key in Sections 4 and 5.
3.1 Storing Cryptographic Material
Storage formats for cryptographic data face several challenges:
The format should be standardized, such that it can be exchanged
between different implementations without compatibility issues.
Then, fingerprints of keys and certificates should be unambiguous,
i. e., there shouldn’t be two equivalent representations of the same
cryptographic entity. Finally, while not a hard requirement, the
format should be easily usable in practice, to allow transferring
cryptographic data without worrying about encoding issues.
3.1.1 PEM Format. To accomplish this, RSA private keys are com-
monly stored in PKCS #8 format [45], which is specified in Abstract
Syntax Notation One (ASN.1) interface description language [44]
and uses the Distinguished Encoding Rules (DER) encoding to gen-
erate a unique binary representation for cryptographic data. This
encoding is defined in such a way that it is ensured that the same
key material always yields the same binary data. Listing 9 in the
appendix shows an example 1024-bit RSA private key in ASN.1 for-
mat, encoded with DER. Data encoded with DER can be encrypted
using a symmetric algorithm and wrapped into another DER layer,
to protect it in case the key file gets stolen; however, for server de-
ployments, the same applies for the used passphrase, which usually
is stored next to the encrypted key file, limiting the security benefit.
For this reason, unencrypted key files are still prevalent.
Finally, in order to allow easy handling and transmission over
non-binary channels, the binary DER data is base64 encoded and
complemented with start and end markers, which denote the se-
mantics of the base64-encoded payload, and allow implementations
to easily determine the correct decoding technique. These markers
also allow to store multiple entities in one file, e. g. certificate files,
containing certificates of an entire chain. These files are usually
referred to as PEM format.
3.1.2 Encoded RSA Private Keys: An RSA private key typically
consists of the public parameters 𝑁 and 𝑒, as well as the private
parameter 𝑑. These values are sufficient for decrypting and signing
messages. For better performance, many implementations utilize
the CRT, which requires the primes 𝑝 and 𝑞, and parameters 𝑑𝑝 =
𝑑 mod (𝑝 − 1), 𝑑𝑞 = 𝑑 mod (𝑞 − 1) and 𝑞𝑖𝑛𝑣 = 𝑞−1 mod 𝑝.
3.2 Finding Leakages
3.2.1 Leakage Detection. In order to avoid time-consuming and
error-prone manual analysis, we utilized the Microwalk [78] frame-
work to automatically analyze the key decoding of several major
cryptographic libraries, and infer possibly interesting leakages. This
approach has the advantage that we can focus on the code sections
which actually do behave differently depending on the secret input
(and thus may leak), and it also finds very subtle leakages often
missed when doing manual analysis, but exploitable nonetheless.
Since Microwalk relies on dynamic instrumentation, we ran-
domly generated a set of 4,096 private key PEM files with slightly
varying parameter sizes, and traced the key decoding of each library.
We then instructed the analysis module to compute the amount of
leaked bits per memory accessing instruction. After Microwalk had
generated and analyzed the traces for each test case, we manually
removed false positives like subtle variations in the memory allo-
cator and reports relating to cryptographic operations, and sorted
the results by their estimated severity.
For OpenSSL, the resulting leakage candidates were all related
to decoding the private key. Functions prefixed with the string
EVP were assigned the highest possible leakage estimation: The
EVP_DecodeUpdate method does an initial scan of the entire input
string, in order to determine its length and remove invalid char-
acters, and then passes it to the EVP_DecodeBlock method, which
performs a LUT-based base64 decoding of the input. Another no-
table leakage is the BN_bin2bn function, which converts the decoded
key parameters into big number objects: It loops over the currently
processed parameter, and thus leaks its length. Detailed analysis re-
sults for OpenSSL are listed in Table 5 in the appendix. We continue
with explaining and discussing these leakages in detail.
3.3 Analysis of Key Decoding Techniques
3.3.1 Decoding of PEM Files. When loading the private key, cryp-
tographic libraries parse the PEM file, decode the base64 DER, and
convert the binary DER representation into an internal format. For
those libraries that employ a lookup table (LUT)-based approach,
we found that in each analyzed library this process leaks key infor-
mation for every base64 character, and thus every parameter stored
in the key file.
All libraries roughly follow the same high-level approach: First,
they parse the start/end markers to locate the base64-encoded pay-
load. Then, they decode each base64-character and reconstruct the
underlying binary data, while skipping invalid characters like line
breaks and spaces. Finally, the DER container is handed to the next
decoder stage, which parses the DER blocks following the ASN.1
specification, and initializes a corresponding private key object.
Session 10A: Crypto, Symbols and Obfuscation CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea24590x00 ffffffff ffffffff
0x08 ffe0f0ff fff1ffff # TAB LF CR
0x10 ffffffff ffffffff
0x18 ffffffff ffffffff
0x20 e0ffffff ffffffff # SPACE
0x28 ffffff3e fff2ff3f # + - /
0x30 34353637 38393 a3b # 0 1 2 3 4 5 6 7
0x38 3 c3dffff ff00ffff # 8 9 =
0x40 ff000102 03040506 # A B C D E F G
0x48 0708090 a 0 b0c0d0e # H I J K L M N O
0x50 0 f101112 13141516 # P Q R S T U V W
0x58 171819 ff ffffffff # X Y Z
0x60 ff1a1b1c 1 d1e1f20 # a b c d e f g
0x68 21222324 25262728 # h i j k l m n o
0x70 292 a2b2c 2 d2e2f30 # p q r s t u v w
0x78 313233 ff ffffffff # x y z
Figure 1: base64-decoding lookup table as present in the
OpenSSL binary. The comment column on the right lists the
ASCII representations of valid code points (non-0xFF bytes).
Leakages in base64 Decoding. In base64 encoding, the binary
3.3.2
data is divided into 6-bit chunks, interpreted as alphanumeric char-
acters, the plus sign or the slash, making up 64 distinct characters,
all from the ASCII character set.
For decoding, these characters are converted back into 6-bit
chunks, where each group of four chunks corresponds to 3 bytes of
binary data. While this conversion can be realized as a case decision,
most implementations rely on LUTs, where each ASCII character
maps to the corresponding 6-bit chunk (or an invalid value). Since
an ASCII-encoded character takes up 7 bits, the LUTs need to have
at least 128 entries. Listing 1 shows the decoding table used by
OpenSSL. Note that due to its length, the table takes up at least two
64-byte cache lines, which allows an attacker to infer a part of the
table index through a cache attack, as we will show in Section 4.
While all analyzed libraries use a LUT-based base64-decoding, the
exact implementations vary in detail: For example, OpenSSL and
NSS parse the base64 string twice, to handle invalid or white space
characters, and determine the length of the resulting decoded binary
string. This allows the attacker to do multiple measurements per
input, which reduces the measurement error.
Another difference between the libraries and even between dif-
ferent configurations of a single library is the alignment of the
base64 LUT. If a 128-byte LUT is aligned at a cache line boundary
(64 bytes), it takes up exactly two cache lines. As depicted in List-
ing 1, the LUT entries are not evenly distributed: Considering only
the base64 character set, the first half has 12 entries, while the sec-
ond half has 52, so observing an access to the first cache line yields
more information than an access to the second one. However, if
the LUT is aligned at 32 bytes, the entries are split over three cache
lines: The first one does not have any base64 entry, the second has
38, and the third has 26.
To measure the average information that is leaked by a LUT
access when observed at cache line level, we compare the number
of base64 entries per cache line. Let random variable 𝐵 denote the
64 possible base64 characters, where each character 𝑏 has the same
probability: Pr[𝐵 = 𝑏] =
1
64. Also, let random variable 𝐶 denote
the cache lines which contain a part of the LUT. The probability
that we observe a certain cache line 𝑐 is thus Pr[𝐶 = 𝑐], which
equals the fraction of base64 characters which map to this cache
line. Finally, Pr[𝐵 = 𝑏 | 𝐶 = 𝑐] denotes the probability of a certain
base64 character 𝑏 if we observed cache line 𝑐.
We can then compute the average information 𝐼(𝐵, 𝐶) = 𝐻(𝐵) −
𝐻(𝐵 | 𝐶) leaked by observing a cache line, where 𝐻 denotes the
Shannon-entropy. Table 1 shows the investigated libraries and the
expected leakage for base64 decoding.
2 and Pr[𝐵 = 𝑏 | 𝐶 = 𝑐] =
1
Note that the amount of leaked information depends on the
structure and the alignment of the LUT: If the LUT takes up two
cache lines and the base64 character entries are distributed evenly,
so Pr[𝐶 = 𝑐] =