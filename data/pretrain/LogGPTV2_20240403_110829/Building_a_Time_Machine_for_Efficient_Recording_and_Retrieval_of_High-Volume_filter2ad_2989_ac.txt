### Packet Capture and Classification

The capture unit receives packets from the network tap and forwards them to the classification unit. Using a connection tracking mechanism, it checks if the packet's connection has exceeded its configured cutoff value. If not, it identifies the associated storage container, which stores the packet in memory and indexes it for quick access. The packet is later moved to disk and eventually deleted. This process differs from the connection-level simulation model, where buffers act as caches that evict packets when full, rather than evicting entire connections at a specific time.

### Implementation Details

Our implementation uses the libpcap packet capture library [2], allowing users to specify a kernel-level BPF [4] capture filter to discard uninteresting traffic early. We collect and store each packet's full content and capture timestamp. The capture unit then passes the packet to classification routines, which divide the incoming packet stream into classes based on user-specified configurations. Each class definition includes a class name, a BPF filter to identify packets, a matching priority, and several storage parameters. For example:

```plaintext
class "telnet" { 
  filter "tcp port 22"; 
  precedence 50; 
  cutoff 10m; 
  mem 10m; 
  disk 10g; 
}
```

This defines a "telnet" class with a priority of 50, matching any traffic captured by the BPF filter "tcp port 22". A cutoff of 10 MB is applied, and an in-memory buffer of 10 MB and a disk budget of 10 GB are allocated. For each incoming packet, we look up the class associated with its connection in the connection tracking unit or, if it is a new connection, match the packet against all filters. If multiple filters match, the packet is assigned to the class with the highest priority. If no filter matches, the packet is discarded.

### Connection Tracking and Cutoffs

To track connection cutoffs, the Time Machine maintains state for all active connections in a hash table. If a newly arrived packet belongs to a connection that has exceeded the cutoff limit, it is discarded. We manage entries in the connection hash table using a user-configurable inactivity timeout, which is shorter for connections with only one packet, preventing the table from growing too large during scans or denial-of-service attacks.

### Storage Containers

For each class, the Time Machine maintains a storage container to buffer the packets. These containers consist of two ring buffers: one for RAM and one for disk. Users can configure the size of both buffers on a per-class basis. Packets evicted from the RAM buffer are moved to the disk buffer. The disk buffer is structured as a set of files, each of which can grow up to a configurable size (typically 10-100 MB). Once a file reaches this size, it is closed, and a new file is created. Packets are stored in libpcap format, enabling easy extraction of traces for analysis.

### Indexing and Retrieval

To enable quick access to packets, we maintain multiple indexes. The Time Machine supports any number of indexes over predefined protocol header fields, such as per-address, per-port, and per-connection-tuple indexes. Each index manages a list of time intervals for every unique key value observed in the protocol headers. These intervals provide information on the availability and starting timestamp of packets, facilitating fast retrieval. When a new packet is stored, each associated index is updated. If the packet's key is not in the index, a new entry is created with a zero-length time interval starting with the packet's timestamp. If an entry exists, it is updated by extending the time interval or starting a new one if the time difference exceeds a user-defined parameter. As interval entries age, they are migrated from in-memory structures to disk, similar to the migration of packets from RAM to disk. Users can also set an upper limit for the in-memory index data structure.

### Query Processing

The final part of the architecture concerns finding packets of interest in the archive. While brute-force methods (e.g., running tcpdump over all on-disk files) can be used, they are time-consuming and can affect Time Machine performance due to disk contention. We address this with a query-processing unit that provides a flexible language to express queries for subsets of packets. Each query consists of a logical combination of time ranges, keys, and an optional BPF filter. The query processor first looks up the appropriate time intervals for the specified key values in the indexing structures, trimming these to the query's time range. The logical OR of two keys is realized as the union of their intervals, and AND as the intersection. The resulting time intervals correspond to the time ranges in which the queried packets originally arrived. We then locate these intervals in the storage containers using binary search. Since the indexes are based on time intervals, they limit the amount of data to scan, reducing the search space. The last step involves scanning all packets in the identified time ranges, checking if they match the key and an additional BPF filter if provided, and writing the results to a tcpdump trace file on disk.

### Evaluation

To evaluate the Time Machine design, we ran an implementation at two sites. At LBNL, we used three classes, each with a 20 KB cutoff: TCP traffic (90 GB), UDP (30 GB), and Other (10 GB). Retention, the distance back in time to which we can travel, increased until the disk buffers were full, after which it correlated with incoming bandwidth and diurnal/weekly variations. The TCP buffer allowed retention of data for 3-5 days, matching predictions. On average, 98% of traffic was discarded, with the remainder imposing an average rate of 300 KB/s and a maximum rate of 2.6 MB/s on the storage system. Over two weeks, libpcap reported only 0.016% of packets dropped.

At MWN, preliminary tests showed that about 85% of traffic was discarded, with storage rates of 3.5 MB/s (average) and 13.9 MB/s (maximum). The higher volume of HTTP traffic, due to its less heavy-tailed nature, required more aggressive use of classification and cutoff mechanisms. The fractions of discarded traffic and storage rates matched our predictions well, and the connection tracking and indexing mechanisms handled real Internet traffic effectively.

### Summary

In this paper, we introduce the Time Machine for efficient network packet recording and retrieval. It can buffer several days of high-volume traffic using commodity hardware, providing an efficient query interface and automatic storage management. By leveraging the heavy-tailed nature of network traffic, we can record most connections while skipping the bulk of the total volume. We demonstrated the effectiveness of the approach through simulations and operational experience. A cutoff of 20 KB increases data availability from hours to days compared to brute-force bulk recording. In operational use, the Time Machine has already proven valuable by enabling the diagnosis of a break-in that standard bulk-recording missed. Future work will include adding a remote access interface for real-time queries by components like network intrusion detection systems.

### Acknowledgments

This work was supported by the National Science Foundation under grant STI-0334088 and by a grant from the Bavaria California Technology Center.

### References

[1] ANTONELLI, C., UNDY, M., AND HONEYMAN, P. The Packet Vault: Secure Storage of Network Data. In Proc. Workshop on Intrusion Detection and Network Monitoring (April 1999), pp. 103–110.
[2] LAWRENCE BERKELEY NATIONAL LABORATORY. tcpdump and libpcap. http://www.tcpdump.org/
[3] MCAFEE. McAfee Security Forensics. http://www.mcafeesecurity.com/us/products/mcafee/forensics/security_for%
ensics.htm
[4] MCCANNE, S., AND JACOBSON, V. The BSD Packet Filter: A New Architecture for User-level Packet Capture. In Proc. USENIX Winter 1993 Conference (January 1993), pp. 259–270.
[5] PAXSON, V. Bro: A system for detecting network intruders in real-time. Computer Networks 31, 23–24 (December 1999).
[6] PAXSON, V., AND FLOYD, S. Wide-Area Traffic: The Failure of Poisson Modeling. IEEE/ACM Transactions on Networking 3, 3 (June 1995), 226–224.
[7] WALLERICH, J., DREGER, H., FELDMANN, A., KRISHNAMURTHY, B., AND WILLINGER, W. A Methodology for Studying Persistency Aspects of Internet Flows. ACM SIGCOMM Computer Communication Review 35, 2 (April 2005), 23–36.