2. A way to obliviously produce biased coins
3. A method for reseting p’s expansion obliviously
Note that all of these must be achieved within a secure computation, which does not provide
many intuitive options for ﬁnishing random comparisons early while still being secure. We will
describe how to acquire (1) and (3) in two ways later in the section. For (2) and one of those
ways, we design oblivious data structures, which can store a number of coins at once, while
providing operations to push and pop coins obliviously.
2.1 Oblivous data structures
The notion of an oblivious data structure was introduced by Goldreich and Ostrovsky [GO96]
in the context of protecting the privacy of a CPU’s memory access pattern against an adversary
who can tap the memory channel bus. Subsequently several works have studied the overhead
tradeoﬀs involved in implementing such data structures. The classical notion of security for
oblivious data structures is stated in a RAM model and speciﬁed through the notion of a simulator
and indistinguishably of the traces resulting from any two sequence of operations.
Instead of considering arbitrary RAM datastructures, we only consider a pair of very limited
datastructures that support 1 and 2 operations. We only allow circuit-model implementations of
these operations, and then evaluate the AND-gate complexity of these circuits as our measure
of interest. This notion implies the standard simulator-based one for the limited scope and is
consequently much simpler.
A data structure D = (O; B, C) = D(O) is a tuple consisting of a sequence of bits B =
b1, . . . , bM , a set of bookkeeping bits C,3 and a ﬁxed set of operators O which act on B and C.
For the following let C = {c, r}, where c represents the current count of bits and r is a reset
ﬂag. We deﬁne three members (the ones relevant to our data structures) of the set of possible
operators O∗:
1. cpush(f, D, b): returns (B(cid:48) = (b, b1, . . . , bM−1), C(cid:48) = {c+1, r}) if f = 1 and (B, C) otherwise.
b represents the bit to be pushed.
2. creset(f, D): returns (B, C(cid:48) = {c, 1}) if f = 1 and (B, C) otherwise. In our construction,
r = 1 denotes the need for a reset.
3. rpop( ˆB,ˆc)(f, D): returns the bit ˆb1 and ( ˆB(cid:48) = (ˆb2, . . . , ˆbM , 0),
C(cid:48) = {ˆc − 1, 0}) if r = 1, b1 and (B(cid:48) = (b2, . . . , bM , 0), C(cid:48) = {c − 1, 0}) otherwise. Here
the values ˆB = (ˆb1, . . . , ˆbM ), ˆc are hard-coded values of the datastructure (typically, the
initialized values before any operations).
3Conceptually, the bits in C can be included in the sequence of bits, but we separate them for convenience.
6
c
r
s
1
2
3
count reset shift
data
data
data
2
1
1
2(cid:96)
2(cid:96)
2(cid:96)
Figure 1: Depiction of the recursive data structure at level (cid:96). The top row indicates how we name
each ﬁeld in the subsequent discussion. The bottom row indicates the ﬁeld size in bits. Each
level includes 4 bits of bookkeeping and 3 “buckets” that hold 2(cid:96) bits each. Our implementation
also includes a pointer to the next level for convenience, but this can be omitted if successive
levels are arranged in memory as an array.
These operations take a conditional ﬂag f as an input that determine whether the operation is
performed or not. In the case of rpop, f is ignored in favor of an internal bit in C.
We consider boolean circuits that implement these operations on D. However, instead of
requiring uniform circuits, we allow the circuit that implements the ith operation on D to depend
on i, i.e., the number of previous operations that have been applied to the data structure. The
circuit that implements an operation cannot, however, depend on the speciﬁc operations that
have been applied to D—only on the count. This extra ability allows scheduling “clean-up tasks”
that simplify the datastructure at periodic intervals that are independent of the data being stored.
We use the natural notion of correctness in which the circuit for each operation implements the
semantics deﬁned above.
Each of these circuits consist of boolean gates (and and xor), simple wires, and desigation
of each wire as an input wire, an ouptut wire, or an internal wire. We measure the complexity of
a circuit by counting the number of its and gates.
We now proceed to describe our implementations of this data structure.
Construction. We use two data structures, both of which are essentially constructed as in
Figure 1, and are hierarchical; level i of the structures contain a single bit to represent whether a
level needs to be reset, two bits which store a count of the number of elements at this level, 3
data slots each of size 2i bits, and ﬁnally a pointer to the next level of the data structure. The
pointer is for convenience of notation and can be omitted in implementation by arranging the
levels adjacent to one another in an array. The total capacity of the data structure is the sum of
the sizes of the data slots at all of the levels. This design is inspired by the stack construction
from [ZE13]. Our ﬁrst data structure, Dpop(Opop), is a data structure with Opop = {rpop, creset},
and follows Figure 1 precisely. Our second data structure is Dpush(Opush), with Opush = {cpush},
and it omits the reset bit from Figure 1.
All pushes and pops initially take place in level 0, but level 0 will become empty or full at
diﬀerent points during a sequence of stack operations. To address this, when level i is full it
shifts some of its contents to level i + 1 below, and when level i is empty, level i + 1 shifts its
contents to level i. To keep this operation oblivious, these shifts occur on a regular schedule: level
i checks if it needs to make a shift every 2i+1 operations of a given type (push or pop). Notice
this oblivious schedule ensures that overﬂows (or underﬂows) never occur except at possibly the
last level (where they are ignored in our case). Thus, we use a shift circuit every second time
a level is accessed, meaning shifts must be made not only when a level is empty/full but also
when it could be empty/full after the next operation of a given type. The advantage of this
7
shifting scheme is that, even though moving data twice as large is twice as expensive, level i + 1
is accessed half as often as level i, so all levels have the same amortized cost. This makes the
complexity per operation a favorable O(log n) for n element capacity, since a level 0 access has
constant gate count and there are O(log n) levels total.
In contrast to the implementation in [ZE13], our structures only support either push or pop
operations, but not both. As a result, it suﬃces to have only 3 buckets per level (instead of 5),
cutting down our gate count by a constant factor.
Oblivious Reset.
Intuitively, we will be using Dpop to store bits of the binary expansion of
some bias p and pop them oﬀ sequentially to give the functionality of (1). To achieve (3), we
add a secret reset bit to each level of the stack which determines whether the level will set its
slots to their original values of the datastructure before popping normally. After every oblivious
reset, we set the reset bit to 0. When we pop the next bit of p’s binary expansion and it is not
equal to the next random bit, we set the reset bit of each level to 1 so that the next pop will
start from the ﬁrst bit of p’s bias again.
Below we provide pseudo-code to more formally express the intuition above. We use the
notation mux(f, a0, a1) to represent a0 + f · (a0 + a1) where the operations are performed over
F2; in other words, this step returns af using |a0| AND gates. We show the pseudo-code for the
pop operation ﬁrst; the cpush operation is similar. The creset operation recursively sets the reset
ﬂag at each level of the hierarchy.
1: procedure rpop(f, stk)
2:
stk.{1, 2, 3, c} ← mux(stk.r, stk.{1, 2, 3, c},{ˆ1, ˆ2, ˆ3, ˆc})
stk.r ← 0
if stk.next (cid:54)= ⊥ then
if stk.s = 1 then
(cid:46) ret success bit s, data d
(cid:46) ˆx is reset value of x
(cid:46) always set reset bit to 0
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
?≤ 1)
c1 ← (stk.c
stk.1 ← mux(c1, stk.1, stk.3)
s, d ← rpop(c1, stk.next)
stk.{2, 3} ← mux(c1, stk.{2, 3}, d)
stk.c ← mux(c1, stk.c, stk.c + 2)
c2 ← (stk.c
stk.1 ← mux(c1 ∧ c2, stk.1, stk.2)
stk.2 ← mux(c1 ∧ c2, stk.2, stk.3)
stk.s ← 0
stk.s ← 1
?≡ 0 (mod 2))
else
end if
19:
18:
end if
s ← 1
(d, stk.c) ← mux(f, (d, stk.c), (stk.1, stk.c − 1))
stk.1 ← mux(f, stk.1, stk.2), stk.2 ← mux(f, stk.2, stk.3)
return (s, d)
22:
23: end procedure
20:
21:
(cid:46) conditional pop when using hierarchical construction
(cid:46) note f always 1 on ﬁrst level
8
1: procedure cpush(f, input, stk)
2:
if stk.next (cid:54)= ⊥ then
if stk.s = 1 then
?≥ 2)
c1 ← (stk.c
s(cid:48) ← mux(c1, 0, cpush(c1, stk.next))
stk.3 ← mux(s(cid:48), stk.3, stk.1)
stk.c ← mux(s(cid:48), stk.c, stk.c − 2)
stk.s ← 0
stk.s ← 1
else
end if
end if
s ← ¬(stk.c ?= 3)
for i = 1 to 3 do
stk.i ← mux(f ∧ (stk.c ?= 3 − i), stk.i, input)
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
end for
stk.c ← mux(f ∧ s, stk.c, stk.c + 1)
return s
18:
19: end procedure
1: procedure creset(f, stk)
stk.r ← mux(f, stk.r, 1)
2:
if stk.next (cid:54)= ⊥ then
creset(f, stk.next)
3:
4:
(cid:46) ret success bit s
(cid:46) check fullness
(cid:46) return nothing
end if
5:
6: end procedure
Analysis. We now state and prove the following theorem.
Theorem 2.1. Let data structure D have capacity n bits. The total number of and gates
required to implement n calls to pop, creset (respectively cpush) on D is Θ(n log n).
Consider a data structure that is designed to hold n bits. The ith level of the data structure
holds 3·2i bits, and therefore k = O(log n) levels are needed. Thus, it is easy to see that the creset
operation on such a data structure requires O(log n) AND gates to implement since it performs
one mux operation on a single bit per level. Each mux(·, a0, a1) operation can be implemented
using |a0| and gates.
The analysis of pop is slightly more complicated but also require O(n log n) and gates across
n operations. Let T (i) represent the number of and gates required to implement a call of pop
on level i of the hierarchy. When the shift bit at this level is 0, then only the and gates from the
mux operation in line 2 are required, and so T (i) = 3· 2i. When shift is odd, then lines 7,10,12,13
contribue another 3 · 2i + 2 gates, and the recursive call in line 8 contributes T (i + 1) gates. Over
a sequence of n operations, the n calls to hierarchy level 0 contribute n · T (0) gates. Half of these
calls require 3 · 20 gates, while the other n/2 calls require 3 · 20 + (3 · 20 + 3 + T (2)) gates. Of
9
these, n/4 terms of T (2) add 3· 21 gates, while the other n/4 contribute 3· 21 + (3· 21 + 3 + T (3)).
Expanding all such T () terms and collecting, the total number of and gates is
i=1
k(cid:88)
≤ k(cid:88)
≤ k(cid:88)
i=1
(cid:100)n/2i(cid:101) · 3 · 2i−1 + (cid:100)n/2i(cid:101)(3 · 2i + 3)
(cid:100)n/2i(cid:101)(cid:2)3 · 2i + 3 · 2i−1 + 3(cid:3)
5n = O(n log n)
An analysis of cpush is similar.
i=1
Discussion of Batching Parameters. Returning to the task of producing d biased coins of
the same bias, we arrive at the issue of when to stop pushing coins onto the push-only stack. To
use the least number of pushes, we could check if the stack is full before every push and stop