using the enumeration methods provided by the
CosDoc, PDDoc, and PDF_Consultant classes. JavaScript
code is first
tokenized by a lexer adapted from
SpiderMonkey and executed statement-by-statement with
AFExecuteThisScript method from AcroForm class. The
rest of the PDF-supported actions are launched with the
AVDocPerformAction method. The PDF processing func-
tions exposed to the AAR plugin can be hooked by the
simple JMP-Trampoline hot-patching technique as sum-
marized in [6].
5.2 External Behavior Tracer
As illustrated in §4.3, PLATPAL’s external behavior tracer
records syscall arguments and return values during docu-
ment execution. On Windows, the tracer is implemented
based on NtTrace [41]; on Mac, the tracer is a Dscript
utilizing the DTrace [9] mechanism available on BSD
systems. Both techniques are mature on respective plat-
forms and incur small execution overhead: 15% to 35%
compared to launching AAR without the tracer attached,
which helps to control the total execution time per docu-
ment. Constructing the high-level behaviors is performed
in a similar manner as Cuckoo guest agent [44].
In PLATPAL, syscall tracing starts only after the doc-
ument is opened by AAR. The AAR initialization pro-
cess is not traced (as AAR itself is not a malware) and
PLATPAL is free of the messy filesystem activities (e.g.,
loading libraries, initializing directory structures, etc) dur-
ing the start-up, leaving the execution trace in a very short
and clean state. In fact, a benign document typically has
around 20 entries of filesystem traces and no network ac-
tivities or external program launches. AAR uses a single
thread for loading and parsing the document and spawns
one helper thread during document rendering. Syscalls of
both threads are traced and compared.
To compare file paths, PLATPAL further aggregates and
labels filesystem operation traces into a few categories
that have mappings on both platforms, including AAR
program logic, AAR support file, AAR working caches,
system library/framework dependencies, system fonts,
and temporary files. Files outside these labels will go to
the unknown category and will be compared based on
filenames.
5.3 Automated Execution Sandbox
For PLATPAL, the purpose of having an automated exe-
cution sandbox is twofold: 1) to confine the malicious
activities within a proper boundary and 2) to provide a
clean execution environment for each document exami-
nation that is free from side effects by prior executions.
280    26th USENIX Security Symposium
USENIX Association
The virtual machine (VM) is initialized with a clean-slate
operating system and subsequently provisioned with the
necessary tools and settings, including AAR, the plugin,
and the syscall tracer. The memory and disk snapshot is
taken after the provision, and each subsequent document
execution restores the states from this snapshot. PLATPAL
uses VMware for the management of VMs and snapshots.
Workflow.
PLATPAL can be started like
PlatPal . After that, PLATPAL pop-
ulates a Windows VM and a Mac VM and restores the
memory and disk snapshots. The suspicious document is
then uploaded to these VMs and AAR is started with the
syscall tracer attached. After AAR is done with initial-
ization, the control is transferred to the plugin (internal
tracer), which opens the document for examination. Af-
ter the examination finishes (or AAR crashes), logs from
internal and external tracing are pulled from the respec-
tive VMs and compared on the host. PLATPAL reports
whether discrepancies are detected among these logs.
6 Evaluation
In this section, we validate the fundamental assumption
of PLATPAL: benign documents behave the same when
opened across different platforms, while maldocs behave
differently when doing exploitation on different platforms.
We also evaluate PLATPAL’s performance in terms of total
time taken to finish a complete analysis.
Experiment setup. The experiments were conducted on
a MacBook Pro (2016 model) with Intel Core i7 2.9GHz
CPU and 16GB RAM running macOS Sierra. One VM
is provisioned with Windows 7 Professional SP1 and the
other VM is provisioned with OSX Yosemite 10.10.1.
Each VM is further provisioned with 6 different versions
of AAR instances1 listed in Table 2. Each document
sample is forced to be closed after one minute execution.
6.1 Benign Samples
The benign sample set consists of three parts: 1000 sam-
ples are collected by searching Google with file type PDF
and no keywords. However, a majority of these samples
do not use features that are typically exploited by mal-
docs. For example, only 28 files contain embedded fonts
and 6 files contain JavaScript code. Therefore, we further
collected 30 samples from PDF learning sites2 that use ad-
vanced features in the PDF standard, including embedded
JavaScript (26 samples), AcroForm (17), self-defined font
(6), and 3D objects (2). All of the samples are submitted
1Previous versions of AAR can be obtained from ftp://ftp.
adobe.com/pub/adobe/reader
are mainly
samples
2The
pdfscripting.com and http://www.planetpdf.com/
obtained
from http://www.
to VirusTotal and scanned by 48 AV products and none of
them are flagged as malicious by any of the AV engine.
The samples are submitted to PLATPAL for analysis. In
particular, each document is opened by all six versions of
AAR instances on both platforms. This is to empirically
verify that all AAR reader instances do not introduce non-
determinism during the document executions. Pairwise
behavior comparison is conducted per AAR version and
no discrepancy is observed, for any AAR version tested.
More importantly, the experiment results support the first
part of PLATPAL’s assumption: benign documents behave
the same across platforms.
6.2 Maldoc Detection
The maldoc samples are all collected from VirusTotal.
In particular, we collected samples with identified CVE
numbers (i.e., the sample exploits a particular CVE) 3 as
of Dec. 31, 2016. As a prototype, we restrict the scope
by analyzing CVEs published after 2013 and further filter
the samples that are obviously mislabeled (e.g., a 2011
sample exploiting a 2016 CVE) or of wrong types (e.g.,
a zip file or an image file) and obtained a 320-sample
dataset.
The samples are submitted to PLATPAL for analysis.
In addition, we select the AAR versions that are most
popular based on the time when the CVE was published.
In other words, each exploit is a zero-day attack to the
AAR version tested. The per-CVE detection results are
presented in Table 2 and the breakdown in terms of which
behavior factor causes the discrepancy is listed in Table 3.
Interpretation. For any sample submitted to PLATPAL,
only three outcomes are possible:
1) Malicious: At least one behavioral discrepancy is
observed, including the case in which AAR crashes on
both platforms but the internal behavior is different, i.e.,
they crash at different PDF processing stages.
2) Suspicious: AAR crashes on both platforms but no
difference is observed in internal behaviors. Given that a
benign document has no reason to crash AAR, PLATPAL
considers these samples as suspicious.
3) Benign: No behavioral discrepancy can be observed
and AAR exits gracefully on both platforms.
Overall result. Out of 320 samples, PLATPAL detected
209 (65.3%) malicious samples, 34 (10.6%) suspicious
samples, and 77 (24.1%) benign samples.
Suspicious samples. Among the 34 suspicious samples,
we are able to confirm that 16 are PoC samples, including
7 released on Exploit-DB [19], 3 in public blogs, and 6 in-
ferred by their original filenames recorded by VirusTotal.
These samples are likely obtained by fuzzing and upon
3VirusTotal labels a sample with CVE number as long as one of the
hosted AV products flag the sample with the CVE label.
USENIX Association
26th USENIX Security Symposium    281
AAR
Version
DC.16.45
DC.16.45
DC.10.60
DC.10.60
DC.10.60
DC.10.60
11.0.10
11.0.10
11.0.10
11.0.00
11.0.00
10.1.4
10.1.4
10.1.4
10.1.0
10.1.0
CVE
2016-6946
2016-4204
2016-4119
2016-1091
2016-1077
2016-1046
2015-5097
2015-2426
2015-0090
2014-0521
2014-0495
2013-3353
2013-3346
2013-2729
2013-0640
2013-0641
Total
Num.
Samples
Result
Both crash
Divergence
51
78
1
63
1
4
4
14
1
2
2
16
7
23
30
23
8
7
0
6
0
0
0
6
0
0
0
4
0
3
0
0
40
37
1
31
1
4
4
8
1
2
2
10
7
19
22
20
320
34
209
Table 2: PLATPAL maldoc detection results grouped by CVE
number. Both crash means AAR crashes on both platforms
while executing the maldoc sample with no divergence on in-
ternal behaviors; Divergence means at least one behavioral dis-
crepancy (either internal or external) is observed.
execution, will simply crash AAR. We expect it to apply
to the rest of the suspicious samples as well.
Benign samples. We identified several reasons for the
failed detection of these samples.
1) The maldoc targets old and specific AAR versions.
Although a majority of maldoc samples exploit a wide
range of AAR versions, we do find samples that target
old AAR versions only, i.e., 9.X and 8.X, including 8
CVE-2013-0640 samples, 3 CVE-2013-0641 samples,
and 1 CVE-2013-2729 sample. We also found that 13
CVE-2016-4204 samples and 10 CVE-2016-1091 sam-
ples seems to be exploiting AAR version 11.0.X and the
exploits do not work on the AAR DC version used in the
experiment. This is based on manual inspection of the
JavaScript dump from these samples.
In total, they account for 36 out of the 77 samples
classified as benign. This is also shows the drawback of
PLATPAL, being a dynamic analysis approach, it requires
proper setup of the execution environment to entice the
malicious behaviors.
2) The maldoc sample could be mis-classified by AV
vendor on VirusTotal. This could be true for 11 CVE-
2016-4204 and 8 CVE-2016-1091 samples, as out of the
48 AV products hosted on VirusTotal, only one AV vendor
flags them as malicious. In total, this accounts for 19 out
of the 77 samples classified as benign.
3) The maldoc does not perform malicious activity.
Not all malicious activities in the maldoc can be triggered.
In particular, we observed two CVE-2013-3353 samples
attempted to connect to a C&C server in JavaScript but
did nothing afterwards because of the lack of responses,
which results in no divergences in execution trace.
In the end, for the rest of the samples classified as
benign (20 in total), we are unable to confirm a reason
why no behavioral discrepancies are observed. It could
be because of any of the aforementioned reasons (but
we are unable to confirm) and we do not preclude the
possibility that some samples could evade PLATPAL’s
detection. Given the scope and flexibility of PDF speci-
fication, it is possible that PLATPAL needs to hook more
functions (e.g., per glyph to host encoding transforma-
tion performed a font) to capture finer-grained internal
behaviors.
Behavior effectiveness. Table 3 also shows the effec-
tiveness of various behaviors in detecting maldocs.
1) By the first row, it is possible to have only external
behavior divergences, while internal behaviors are the
same (e.g., due to pure JavaScript attacks). By the first
column, it is also possible to have only internal behavior
divergences, while external behaviors are the same (due
to the powerful error-correction capability of AAR).
2) Crash/no crash is the most effective external indica-
tor, as memory-error exploitation is the dominating tech-
nique for maldoc attacks among the samples. JavaScript
execution is the most effective internal indicator, as al-
most all attacks involve JavaScript; even memory error
exploits use it to prepare the heap.
Pinpointing attacks by internal tracer. One supple-
mentary goal of the internal tracer is to provide insights
on which AAR component is exploited or where the attack
occurs given a maldoc sample. To evaluate how this goal
is achieved, we performed a cross-check on where the
internal behavior divergence occurs and the targeted AAR
component of each CVE4. The result is shown in Table 4.
In four out of 7 cases, PLATPAL’s internal tracer finds
divergence during the invocation of the vulnerable compo-
nents. In the CVE-2015-2426 case, since the vulnerable
component is a font library, the divergence is first detected
during the rendering process. In the CVE-2013-3346 case,
the vulnerable component (ToolButton callback) is trig-
gered through JavaScript code and hence, the first diver-
gence occurs in the script engine. In the CVE-2013-2729
case, although the bug is in the parser component, the
divergence is detected when the maldoc is playing heap
feng-shui to arrange heap objects.
Resilience against automated maldoc generation. We
test PLATPAL’s resilience against state-of-the-art maldoc