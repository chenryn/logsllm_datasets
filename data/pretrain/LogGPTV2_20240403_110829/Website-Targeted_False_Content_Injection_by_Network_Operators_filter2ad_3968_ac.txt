tiﬁcation values of the packets sent by the web server
are either monotonically increasing (when the counter
is global) or consecutively increasing (when there is a
counter per destination). In most of the injection events
we observed that the injecting entity made no attempt to
make the identiﬁcation value of the forged packet similar
to the identiﬁcation values of the other packets sent by
the server. In Appendix D we detail a few of the (failed)
attempts of the injecting entity to mimic the Identiﬁca-
tion ﬁeld of the legitimate packet it aims to displace.
We formulate the following rule to determine which
of the two raced packets is the forged one: the forged
packet is the one that has the largest absolute difference
between its identiﬁcation value and the average of the
identiﬁcation values of all the other packets (except the
raced one).
For all injection events, we manually identiﬁed the
forged packet according to its content and compared it to
the corresponding identiﬁcation that used the above rule.
The comparison reveals that the rule is accurate about
90% of the time. This is a fairly accurate measure con-
sidering that it is not based on the payload of the raced
packets.
IP TTL The IP TTL value in a received packet is de-
pendent on the initial value set by the sender and the
number of hops the packet has traversed so far. Thus, it
is unusual for packets of the same session to arrive at the
234  25th USENIX Security Symposium 
USENIX Association
8
client with different TTL values. Therefore, if the raced
packets have different TTL values we can use them to
distinguish between the two packets. From our observa-
tions, the injecting entity often made no attempt to make
the TTL value of the forged packet similar to the TTL
values of the other packets sent by the server. Similarly
to the case of the IP identiﬁcation rule above, we iden-
tify the forged packet using the following rule: the forged
packet is the one that has the largest absolute difference
between its TTL value and the average of TTL values of
all the other packets (except the raced one).
Manual analysis of the injection events reveals that the
TTL rule correctly identiﬁed the forged packet in 87% of
all injection events. The TTL rule concurs with the IP
identiﬁcation rule above in 84% of all injection events.
We thus conclude that the TTL and identiﬁcation val-
ues can serve to effectively distinguish the forged packet
from the valid packet.
We note that our ﬁnding that the TTL and Identiﬁca-
tion ﬁelds of the forged packets have abnormal values
generally agrees with ﬁndings on censorship-related in-
jections which also show that censoring entities do not
align the TTL and Identiﬁcation values with those of the
legitimate packets (e.g., [8]).
5.3 Timing Analysis
The race between the forged and legitimate packets can
also be characterized by the difference in their arrival
times. By arrival time we mean the time at which the
packet was captured by the monitoring system. Since
the system captures trafﬁc at the entrance to the edge
network close to the client, it is reasonable to assume
that these times are very close to the actual arrival times
at the end client. For each injection event we calculate
the difference between the arrival time of the legitimate
packet and the arrival time of the forged packet. A neg-
ative difference means that the forged packet “won” the
race, and a positive difference means that the legitimate
packet “won”. The histogram of the time differences of
all the injection events we observed are shown in Fig-
ure 4.
It is evident from Figure 4 that in most injection events
the forged packet wins the race.
In only 32% of the
events does the legitimate packet arrive ﬁrst. This re-
sult strengthens our initial assumption that the decision
to inject a forged packet is made according to the HTTP
request sent by the client. This means that the injecting
entity can send the forged packet well before the server
sends the legitimate packet, as the client’s request still
needs to travel to the server. Still, even in such a case,
in a non-negligible portion of events, the forged packet
loses the race. This may indicate injections that occurred
very close the server. Alternatively, it may indicate that
#
s
t
n
e
v
e
n
o
i
t
c
e
n
j
I
 250
 200
 150
 100
 50
 0
5
1
.
0
-
4
1
.
0
-
3
1
.
0
-
2
1
.
0
-
1
1
.
0
-
0
1
.
0
-
9
0
.
0
-
8
0
.
0
-
7
0
.
0
-
6
0
.
0
-
5
0
.
0
-
4
0
.
0
-
3
0
.
0
-
2
0
.
0
-
1
0
.
0
-
0
0
.
0
1
0
.
0
2
0
.
0
3
0
.
0
4
0
.
0
5
0
.
0
6
0
.
0
7
0
.
0
8
0
.
0
9
0
.
0
0
1
.
0
1
1
.
0
2
1
.
0
3
1
.
0
4
1
.
0
5
1
.
0
e
r
o
M
Time difference [sec]
Figure 4: Arrival time difference between the forged and
legitimate packets
in some cases the decision to inject the packet is made
at the time the response from the server is encountered.
In the latter case, the forged packet is at a distinct disad-
vantage as it starts the race lagging behind the legitimate
packet. In many cases in which the forged packet won
the race, the legitimate packet arrived very soon after, in
less than 10msec.
5.4 Repeatability
All injection groups were observed for only a short pe-
riod of time, usually one to three days, after which they
were not detected again by our monitoring system. A
few injection types were even encountered only once. No
long-term (3 days or more) injections were observed by
our monitoring system4.
We next tried to reproduce the injection events we ob-
served. This attempt was made several weeks after the
initial observations of the injections. For each injection
event we extracted the HTTP request that triggered the
injection. We then sent from the edge network in which
the injection originally occurred the same HTTP request
(following a proper TCP 3-way handshake) to the des-
tination web server. We sent each request 1000 times.
This is with the aim to reproduce the injections even if
they do not occur for every request. We captured the
resulting TCP sessions and searched for injections. We
were not able to reproduce any of the injection groups.
Following the initial publication of this work an effort
independent of our own to reproduce the injections had
more success [17]. The ’gpwa’ and ’hao’ injections were
successfully reproduced. However, the author of [17] has
4The only long-term injections we did observe were related to cen-
sorship and caching. These injections were the only ones we were able
to reproduce.
USENIX Association  
25th USENIX Security Symposium  235
9
From the above ﬁndings we surmise that,
not been able to reproduce those injections again in a sec-
ond attempt made a few weeks later. Moreover, when the
injections were observed by [17] they were not always
reliable. For one of the resolved IP addresses (for the
destination site’s domain name) the injections were ob-
served only 30% of the time (this information was given
to us via personal communication by the author of [17]).
in gen-
eral, injections by on-path entities may be intermittent;
namely, the injecting entity injects forged content to a
particular site for only a short period of time before mov-
ing on to other sites. Moreover, when an injector is active
for a web site it may target only a portion of the HTTP
requests. This might be motivated by the desire of the
injector to stay “under the radar”. It is plausible that in-
jecting forged content to a site for only a short period of
time might go unnoticed by the users and site owners, or
at least would not cause them to expend effort investigat-
ing the forged content’s origin.
The injections we found were triggered by an HTTP
request to speciﬁc resources which in most cases were
not the main page of the site. This leads us to assume that
an effort to actively seek other sites for possible injec-
tions may be computationally too expensive as we would
need the crawl those entire sites.
5.5 Who is Behind the Injections?
We ﬁnally turn our attention to the culprits behind these
injection events. In general, it is difﬁcult to unveil these
entities as there is no identifying information in the in-
jected content. Nonetheless, we can get indications as to
the identity of the injecting entities by trying to detect the
autonomous system from which the forged packet orig-
inated. We assume that the entity that operates this au-
tonomous system is the entity responsible for the injec-
tion.
Note that the analysis thus far shows strong indications
that the injections do not originate at the web servers
themselves. First, the injected responses had anomalous
IP ID and TTL values. To bring this about an inject-
ing rogue software on the end server would need to cir-
cumvent the standard TCP/IP stack as it sends packets.
While this is possible it would require the injecting soft-
ware elevated privileges and more complex logic to send
the injected responses. Such elevated privileges would
have also allowed the injector to block the valid response
and eliminate the possibility of a race altogether. Second,
most of the injected packets “win” the race. An attacker
injecting packets from the end server does not have a dis-
tinct advantage to win the race. Therefore it is reasonable
to assume that in such a case the race would have been
more even. Third, to the best of our knowledge there is
no malware that injects packets out-of-band. All known
malware that aim to alter trafﬁc on the machine they re-
side alter the the actual packets to be sent (usually by
simply injecting code to the sending process or hooking
the suitable system services).
We note that we ruled out the possibility that the edge
network operators serving the networks we monitored
are responsible for the injections. We veriﬁed this by
speaking directly with the network operators’ adminis-
trators and sharing with them the injections we found.
Since the injections were not reproducible during this
analysis, we cannot employ the oft-used traceroute-like
procedure to locate the injector [22, 8, 24]. In this proce-
dure the packet triggering the injection is repeatedly sent
with increasing TTL values until the forged response is
triggered, thereby revealing the location of the injector.
To identify the injecting entities we resort to the follow-
ing procedure:
1. Estimate the number of hops the forged packet tra-
versed: this estimation relies on the packet’s TTL
value. Speciﬁcally, it relies on there being a signiﬁ-
cant difference between the default initial TTL val-
ues set by the major operating systems [29]: in gen-
eral, the differences between those initial values are
larger than the length of most routes on the Internet.
The default initial TTL values of the major operat-
ing systems are 32, 64, 128 and 255. This means,
for example, that if a packet is received with a TTL
value of 57, the initial TTL value of that packet was
likely to be 64 and the number of hops traversed
was likely to be 7. If the estimated number of hops
is larger than 30 or smaller than 3 5, we assume the
estimation is incorrect and stop the analysis.
2. Identify the path from the destination server to the
client: the actual path from the server to the client
cannot be known without an agent in the server’s
network. Instead, we use the path from the client
to the server while assuming that the routing on this
path is symmetric. We identify the path from the
client to the server by using a ’traceroute’ tool. The
traceroute used a TCP syn packet with destination
port 80. We found that such a packet triggers re-
sponses from most routers and servers.
3. Infer the hop along the above path from which the
forged packet was injected: using the estimated
number of hops the forged packet traversed and the
estimated path it traversed, we can now infer the hop
on the path from which the packet was sent.
5Nearly all routes on the Internet are shorter than 30 hops [21]. Ad-
ditionally, it is very unlikely that the injecting third party resides less
than 3 hops away since the ﬁrst couple of hops reside within the edge
networks we were monitoring.
236  25th USENIX Security Symposium 
USENIX Association
10
Injection group
Web server’s
AS number
xunlei
szzhengan
taobao
uvclick
adcpc
server erased
GPWA
tupian
17816
4134
4837
38182
38182
4134
6943