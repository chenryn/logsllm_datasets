on events order, establishing that the right-hand expression is evaluated only
after that the left-hand expression turns true. The operator timer:interval
establishesthedurationofthetime-windowduringwhichtoobservethearriving
events (it starts after that the left-hand expression turns true). The value of the
counter is sent, along with the event name, to the Esper Runtime. Listing 1.3
shows the EPL translation of the rule Rule#1 in the multi-user case.
Listing 1.3. EPL rule in the multi-user scenario
@name(’Rule#1’) select * from pattern [every a = Event(name="
compute_reserve_block_device_name") -> (timer:interval(secondsToWait
seconds) and not b=Event(name="compute_attach_volume", countEvent = a.
countEvent))];
Every time the Esper Runtime observes an event  with its counter value, it waits for the receive of the event
 with the same counter value within a time win-
dow of secondsToWait seconds. If this condition is not verified, the approach
generates a failure detection message.
5 Preliminary Experiments
To preliminary evaluate our approach, we performed a campaign of fault injec-
tion experiments in the OpenStack platform. In our experiments, we targeted
OpenStack version 3.12.1 (release Pike), deployed on Intel Xeon servers (E5-
2630L v3 @ 1.80GHz) with 16 GB RAM, 150 GB of disk storage, and Linux
CentOS v7.0, connected through a Gigabit Ethernet LAN. In particular, our
tool [10] injected the following fault types:
– Throw exception: An exception is raised on a method call, according to
pre-defined, per-API list of exceptions;
– Wrong return value: A method returns an incorrect value. In particular,
the returned value is corrupted according to its data type (e.g., we replace
an object reference with a null reference, or replace an integer value with a
negative one);
– Wrongparametervalue:Amethodiscalledwithanincorrectinputparam-
eter. Input parameters are corrupted according to the data type, as for the
previous fault type;
– Delay: A method is blocked for a long time before returning a result to the
caller. This fault can trigger timeout mechanisms inside OpenStack or can
cause a stall.
Before every experiment, we clean-up any potential residual effect from the
previous experiment, in order to ensure that the potential failure is only due
to the current injected fault. To this end, we re-deploy the cloud management
system, remove all temporary files and processes, and restore the OpenStack
database to its initial state.
172 D. Cotroneo et al.
In-between calls to service APIs, our workload generator performs assertion
checks on the status of the virtual resources, in order to reveal failures of the
cloud management system. In particular, these checks assess the connectivity
of the instances through SSH and query the OpenStack API to ensure that
the status of the instances, volumes, and the network is consistent with the
expectation of the tests. In the context of our methodology, assertion checks
serve as ground truth about the occurrence of failures during the experiments
(i.e., a reference for evaluating the accuracy of the proposed approach).
Weevaluatedourapproachintermsofthefailure detection coverage (FDC),
definedasthenumberofexperimentsidentifiedasfailedoverthetotalnumberof
experimentsthatexperiencedafailure.Wefocusedonlyontheexperimentsthat
experiencedafailure,foratotalof481faultytraces,onepereachfault-injection
experiment.WedefineanexperimentasfailedifatleastoneAPIcallreturnsan
error (API error) or if there is at least one assertion check failure (assertion
check failure). Also, to evaluate the most interesting cases, we focused on the
experiments in which the target system was not able to timely notify the failure
(i.e., failure notified with a long delay or not notified at all), as described in our
previous work [12].
Thecoverageprovidedbyourruntimeverificationapproachiscomparedwith
the coverage provided by OpenStack API Errors by design. API Errors notifies
the users that the system is not able to perform a request, thus they work
as a failure detection mechanism. Table1 shows the FDC of both approaches
considering different failure cases (related to different operations). The results
show that our approach is able to identify a failure in the 79.38% of the fail-
ures,showingsignificantlybetterperformanceoftheOpenStackfailurecoverage
mechanism. In particular, the table highlights how our rules are able to iden-
tify failures that were never notified by the system (Instance Creation and SSH
Connection). The RV approach shows lower performance only in the Volume
Creation case failure: this suggests the need to add further monitoring rules or
to improve the existing ones for this specific case.
Table 1. Comparison with API errors coverage
Failure case OpenStack FDC % RV FDC %
Volume Creation 29.67 28.57
Volume Attachment 25.33 92.00
Volume Deletion 100 100
Instance Creation 0.00 90.96
SSH Connection 0.00 38.46
Total 23.96 79.38
We evaluated our approach also in a simulated multi-user scenario. To sim-
ulate concurrent requests, 10 traces (5 fault-free and 5 faulty) are “mixed-
together” by alternating the events of all the traces but without changing the
Towards Runtime Verification via Event Stream Processing 173
Table 2. Average FDC in the multi-user scenario
Failure case Avg FDC %
Volume Creation 32.00∓12.42
Volume Attachment 45.33∓13.82
Volume Deletion 36.00∓12.20
Total 37.78∓13.88
relativeorderoftheeventswithineverysingletrace.Thefaultytracesarerelated
to the same failure type (e.g., Volume Creation). For each failure type, we per-
formed the analysis 30 times by randomly choosing both the fault-free and the
faulty traces. Table2 shows the average FDC and the standard deviation of our
monitoring rules for all the failure volume cases. The preliminary results can be
considered promising. However, the high standard deviation indicates that the
average FDC is very sensitive to the randomity of the analyzed traces.
6 Conclusion and Future Work
In this paper, we propose an approach to runtime verification via stream pro-
cessing in cloud computing infrastructures. We applied the proposed approach
in the context of the OpenStack cloud computing platform, showing the feasi-
bility of the approach in a large and complex “off-the-shelf” distributed system.
We performed a preliminary evaluation of the approach in the context of the
fault-injection experiments. The approach shows promising results, both in the
single-user and simulated multi-user cases.
Future work includes the development of algorithms able to automatically
identify patterns using statistical analysis techniques, such as invariant analy-
sis. We also aim to conduct fault-injection campaigns by using a multi-tenant
workload in order to perform an evaluation in a real multi-user scenario and to
analyze the overhead introduced by the approach.
Acknowledgements. This work has been supported by the COSMIC project, U-
GOV 000010–PRD-2017-S-RUSSO 001 001.
References
1. Aguilera,M.K.,Mogul,J.C.,Wiener,J.L.,Reynolds,P.,Muthitacharoen,A.:Per-
formance debugging for distributed systems of black boxes. ACM SIGOPS Oper.
Syst. Rev. 37(5), 74–89 (2003)
2. Arlat,J.,Fabre,J.C.,Rodr´ıguez,M.:Dependabilityofcotsmicrokernel-basedsys-
tems. IEEE Trans. Comput. 51(2), 138–163 (2002)
3. Barham,P.,Isaacs,R.,Mortier,R.,Narayanan,D.:Magpie:onlinemodellingand
performance-aware systems. In: Proceedings of the HotOS, pp. 85–90 (2003)
174 D. Cotroneo et al.
4. Bartocci, E., Falcone, Y.: Lectures on Runtime Verification: Introductory and
AdvancedTopics,vol.10457.Springer,Cham(2018).https://doi.org/10.1007/978-
3-319-75632-5
5. Bianculli, D., Ghezzi, C., Pautasso, C., Senti, P.: Specification patterns from
research to industry: a case study in service-based applications. In: Proceedings
of the ICSE, pp. 968–976. IEEE (2012)
6. Blom,S.,vandePol,J.,Weber,M.:LTSmin:distributedandsymbolicreachability.
In:Touili,T.,Cook,B.,Jackson,P.(eds.)CAV2010.LNCS,vol.6174,pp.354–359.
Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-642-14295-6 31
7. Chen, F., Ro¸su, G.: Mop: an efficient and generic runtime verification frame-
work.In:Proceedingsofthe22ndAnnualACMSIGPLANConferenceonObject-
Oriented Programming Systems and Applications, pp. 569–588 (2007)
8. Chen,Y.Y.M.,Accardi,A.J.,Kiciman,E.,Patterson,D.A.,Fox,A.,Brewer,E.A.:
Path-based failure and evolution management. In: Proceedings of the NSDI, pp.
309–322 (2004)
9. Cimatti, A., et al.: NuSMV 2: an OpenSource tool for symbolic model checking.
In: Brinksma, E., Larsen, K.G. (eds.) CAV 2002. LNCS, vol. 2404, pp. 359–364.
Springer, Heidelberg (2002). https://doi.org/10.1007/3-540-45657-0 29
10. Cotroneo,D.,DeSimone,L.,Liguori,P.,Natella,R.:Profipy:programmablesoft-
ware fault injection as-a-service. In: 2020 50th Annual IEEE/IFIP International
Conference on Dependable Systems and Networks (DSN), pp. 364–372 (2020)
11. Cotroneo,D.,DeSimone,L.,Liguori,P.,Natella,R.,Bidokhti,N.:Enhancingfail-
ure propagation analysis in cloud computing systems. In: 2019 IEEE 30th Inter-
national Symposium on Software Reliability Engineering (ISSRE), pp. 139–150.
IEEE (2019)
12. Cotroneo,D.,DeSimone,L.,Liguori,P.,Natella,R.,Bidokhti,N.:Howbadcana
bugget?anempiricalanalysisofsoftwarefailuresintheopenstackcloudcomputing
platform. In: Proceedings of the ESEC/FSE, pp. 200–211 (2019)
13. Dang, L.M., Piran, M., Han, D., Min, K., Moon, H., et al.: A survey on internet
of things and cloud computing for healthcare. Electronics 8(7), 768 (2019)
14. Delgado,N.,Gates,A.Q.,Roach,S.:Ataxonomyandcatalogofruntimesoftware-
fault monitoring tools. IEEE Trans. Software Eng. 30(12), 859–872 (2004)
15. Denton, J.: Learning OpenStack Networking. Packt Publishing Ltd. (2015)
16. Dwyer,M.B.,Avrunin,G.S.,Corbett,J.C.:Patternsinpropertyspecificationsfor
finite-state verification. In: Proceedings of the ICSE, pp. 411–420 (1999)
17. Ernst, M.D., et al.: The daikon system for dynamic detection of likely invariants.
Sci. Comput. Program. 69(1–3), 35–45 (2007)
18. EsperTech: ESPER HomePage (2020). http://www.espertech.com/esper
19. EsperTech: Esper Reference (2020). http://esper.espertech.com/release-8.5.0/
reference-esper/html single/index.html
20. Grant, S., Cech, H., Beschastnikh, I.: Inferring and asserting distributed system
invariants. In: Proceedings of the ICSE, pp. 1149–1159 (2018)
21. Gu, J., Wang, L., Yang, Y., Li, Y.: Kerep: experience in extracting knowledge on
distributed system behavior through request execution path. In: Proceedings of
the ISSREW, pp. 30–35. IEEE (2018)
22. Holzmann, G.J.: The model checker spin. IEEE Trans. Software Eng. 23(5), 279–
295 (1997)
23. OpenStack: Tempest Testing Project (2018). https://docs.openstack.org/tempest
24. OpenStack: OpenStack HomePage (2020). https://www.openstack.org/
25. OpenStack: OSProfiler HomePage (2020). https://github.com/openstack/
osprofiler
Towards Runtime Verification via Event Stream Processing 175
26. OpenStack project: The OpenStack marketplace (2018). https://www.openstack.
org/marketplace/distros/
27. OpenStack project: User stories showing how the world #RunsOnOpenStack
(2018). https://www.openstack.org/user-stories/
28. Pnueli,A.:Thetemporallogicofprograms.In:ProceedingsoftheSFCS,pp.46–57.
IEEE (1977)
29. Power, A., Kotonya, G.: Providing fault tolerance via complex event processing
and machine learning for IoT systems. In: Proceedings of the IoT, pp. 1–7 (2019)
30. Rabiser,R.,Guinea,S.,Vierhauser,M.,Baresi,L.,Gru¨nbacher,P.:Acomparison
framework for runtime monitoring approaches. J. Syst. Software 125, 309–321
(2017)
31. Reynolds, P., Killian, C.E., Wiener, J.L., Mogul, J.C., Shah, M.A., Vahdat, A.:
PIP: detecting the unexpected in distributed systems. Proc. NSDI. 6, 9 (2006)
32. Solberg, M.: OpenStack for Architects. Packt Publishing (2017)
33. Wu, E., Diao, Y., Rizvi, S.: High-performance complex event processing over
streams. In: Proceedings of the SIGMOD/PODS, pp. 407–418 (2006)
34. Yabandeh, M., Anand, A., Canini, M., Kostic, D.: Finding almost-invariants in
distributed systems. In: Proceedings of the SRDS, pp. 177–182. IEEE (2011)
35. Yin,Z.,Yu,F.R.,Bu,S.,Han,Z.:Jointcloudandwirelessnetworksoperationsin
mobile cloud computing environments with telecom operator cloud. IEEE Trans.
Wirel. Commun 14(7), 4020–4033 (2015)
36. Zhou, J., Chen, Z., Wang, J., Zheng, Z., Dong, W.: A runtime verification based
trace-orientedmonitoringframeworkforcloudsystems.In:ProceedingsoftheISS-
REW, pp. 152–155. IEEE (2014)
Decentralized Federated Learning
Preserves Model and Data Privacy
B B
Thorsten Wittkopp( ) and Alexander Acker( )
Technische Universit¨at Berlin, Berlin, Germany
{t.wittkopp,alexander.acker}@tu-berlin.de
Abstract. The increasing complexity of IT systems requires solutions,
that support operations in case of failure. Therefore, Artificial Intelli-
genceforSystemOperations(AIOps)isafieldofresearchthatisbecom-
ingincreasinglyfocused,bothinacademiaandindustry.Oneofthemajor
issuesofthisareaisthelackofaccesstoadequatelylabeleddata,which
ismajorlyduetolegalprotectionregulationsorindustrialconfidentiality.
Methodstomitigatethisstirfromtheareaoffederatedlearning,whereby
no direct access to training data is required. Original approaches utilize
a central instance to perform the model synchronization by periodical
aggregationofallmodelparameters.However,therearemanyscenarios
where trained models cannot be published since its either confidential
knowledge or training data could be reconstructed from them. Further-
more the central instance needs to be trusted and is a single point of
failure. As a solution, we propose a fully decentralized approach, which
allowstoshareknowledgebetweentrainedmodels.Neitheroriginaltrain-
ingdatanormodelparametersneedtobetransmitted.Theconceptrelies
on teacher and student roles that are assigned to the models, whereby
students are trained on the output of their teachers via synthetically
generated input data. We conduct a case study on log anomaly detec-
tion. The results show that an untrained student model, trained on the
teachersoutputreachescomparableF1-scoresastheteacher.Inaddition,
we demonstrate that our method allows the synchronization of several
models trained on different distinct training data subsets.
· · ·
Keywords: AIOps Federated learning Knowledge representation
·
Anomaly detection Transfer learning
1 Introduction
IT systems are expanding rapidly to satisfy the increasing demand for a variety
of applications and services in areas such as content streaming, cloud comput-
ing or distributed storage. This entails an increasing number of interconnected
devices, large networks and growing data centres to provide the required infras-
tructure[1].Additionally,awarenessfordataprivacyandconfidentialityisrising
T. Wittkopp and A. Acker—Equal contribution.
(cid:2)c SpringerNatureSwitzerlandAG2021
H.Hacidetal.(Eds.):ICSOC2020Workshops,LNCS12632,pp.176–187,2021.
https://doi.org/10.1007/978-3-030-76352-7_20
Decentralized Federated Learning 177
especially in commercial industry. Big- and middle-sized companies are rely-
ing on private cloud, network and storage providers to deploy and maintain
according solutions. Except for severe problems that require local access, the
operation and maintenance is done remotely. Remote access together with the
growingsystemcomplexityputsextremepressureonhumanoperatorsespecially
whenproblemsoccur.Tomaintaincontrolandcomplywithdefinedservicelevel
agreements, operators are in need of assistance. Therefore, monitoring solutions
are combined with methods from machine learning (ML) and artificial intel-
ligence to support the operation and maintenance of those systems - usually
referred to as AIOps. Examples of concrete solutions are early detection of sys-
tem anomalies [2,3], root cause analysis [4], recommendation and automated
remediation [5].
The majority of ML and AI methods relies on training data. In case of
anomaly detection a common approach is to collect monitoring data such as
logs, traces or metrics during normal system operation and utilize them to