technical Audience. URL https://privacytools.seas.harvard.edu/files/privacytools/
files/pedagogical-document-dp_0.pdf.
[53] Kobbi Nissim and Alexandra Wood. 2018. Is privacy privacy? Philosophical Trans-
actions of the Royal Society A: Mathematical, Physical and Engineering Sciences
376, 2128 (2018), 20170358.
[54] Daniel L Oberski and Frauke Kreuter. 2020. Differential privacy and social science:
An urgent puzzle. Harvard Data Science Review 2, 1 (2020).
[55] Eyal Peer, Joachim Vosgerau, and Alessandro Acquisti. 2014. Reputation as a
sufficient condition for data quality on Amazon Mechanical Turk. Behavior
research methods 46, 4 (2014), 1023–1031.
[56] Elissa Redmiles. 2018. Net benefits: Digital inequities in social capital, privacy
preservation, and digital parenting practices of US social media users. In Pro-
ceedings of the International AAAI Conference on Web and Social Media, Vol. 12.
AAAI.
[57] Elissa M Redmiles, Yasemin Acar, Sascha Fahl, and Michelle L Mazurek. 2017. A
summary of survey methodology best practices for security and privacy researchers.
Technical Report.
[58] Elissa M Redmiles, Sean Kross, and Michelle L Mazurek. 2017. Where is the digital
divide? A survey of security, privacy, and socioeconomics. In Proceedings of the
2017 CHI Conference on Human Factors in Computing Systems. ACM, 931–936.
[59] Elissa M. Redmiles, Sean Kross, and Michelle L. Mazurek. 2019. How Well Do My
Results Generalize? Comparing Security and Privacy Survey Results from MTurk,
Web, and Telephone Samples. In 2019 IEEE Symposium on Security and Privacy.
IEEE Computer Society Press, 1326–1343. https://doi.org/10.1109/SP.2019.00014
[60] Christopher Riederer, Jake M Hofman, and Daniel G Goldstein. 2018. To put that
in perspective: Generating analogies that make numbers easier to understand. In
Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems.
ACM, 1–10.
[61] Norman Sadeh, Alessandro Acquisti, Travis D Breaux, Lorrie Faith Cranor, Alee-
cia M McDonald, Joel R Reidenberg, Noah A Smith, Fei Liu, N Cameron Rus-
sell, Florian Schaub, et al. 2013. The Usable Privacy Policy Project: Combining
Crowdsourcing. Machine Learning and Natural Language Processing to Semi-
Automatically Answer Those Privacy Questions Users Care About. Carnegie Mellon
University Technical Report CMU-ISR-13-119 (2013), 1–24.
[62] Florian Schaub, Rebecca Balebako, and Lorrie Faith Cranor. 2017. Designing
effective privacy notices and controls. IEEE Internet Computing (2017).
[63] Awanthika Senarath, Nalin AG Arachchilage, and Jill Slay. 2017. Designing
Privacy for You: A Practical Approach for User-Centric Privacy. In International
Conference on Human Aspects of Information Security, Privacy, and Trust. Springer,
Springer, 739–752.
Informed consent: Putting risks into
[64] Arun D Singh and John Paling. 1997.
perspective. Survey of Ophthalmology 42, 1 (1997), 83–86.
[65] Paul Slovik. 1987. Perception of risk. Science 236, 4799 (1987), 280–285.
[66] Sarah Spiekermann and Lorrie Faith Cranor. 2008. Engineering privacy. IEEE
[67] Differential Privacy Team. 2017.
https:
Transactions on Software Engineering 35, 1 (2008), 67–82.
Learning with Privacy at Scale.
//machinelearning.apple.com/research/learning-with-privacy-at-scale.
[68] Jessica Vitak, Yuting Liao, Priya Kumar, Michael Zimmer, and Katherine Kritikos.
2018. Privacy Attitudes and Data Valuation Among Fitness Tracker Users. In
Transforming Digital Worlds, Gobinda Chowdhury, Julie McLeod, Val Gillet, and
Peter Willett (Eds.). Springer International Publishing, Cham, 229–239.
[69] Aiping Xiong, Tianhao Wang, Ninghui Li, and Somesh Jha. 2020. Towards
Effective Differential Privacy Communication for Users’ Data Sharing Decision
and Comprehension. In 2020 IEEE Symposium on Security and Privacy. IEEE
Computer Society Press, 392–410. https://doi.org/10.1109/SP40000.2020.00088
Session 11C: Software Development and Analysis CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3050A COMPLETE SURVEY DESCRIPTIONS
For completeness, we include the language and flow of our two
surveys below. Demographics for the two samples are included in
Table 6.
A.1 Complete Description of Survey One
Respondents were randomized into either the salary scenario or
the medical scenario, described below.
Salary Scenario: Imagine that you work in the banking industry.
You are friends with a group of other people who work in banking
companies in your city. One of your friends is part of a transparency
initiative that is trying to publish general statistics about pay in
the banking industry. As part of this initiative, they have asked
everyone in the group to share their salaries and job titles using an
online web form on the initiative’s website.
Medical Scenario: Imagine that during your next doctor’s visit,
your primary care doctor informs you that they are part of a non-
profit organization trying to push the boundaries of medical re-
search. This non-profit is asking patients around the country to
share their medical records, which will be used to help medical
research on improving treatment options and patient care. Your
doctor, with your permission, can facilitate the non-profit getting
the information they need.
Questions: Answer options for each questions presented in <>.
Text differences between the two scenarios presented in italics
inside brackets.
– Which of the following would you want to know before deciding
whether or not to share your [salary/medical history]? Select as
many as apply.
– 
For each of the non-other options selected by the respondent,
they were shown one of the follow three options, selected indepen-
dently at random.
– [leak entity] will not learn your [salary/medical history].
– [leak entity] might learn your [salary/medical history]. The chance
this happens is about the same as the chance that your bank ac-
count will be compromised (accessed by a person who you did
not intend to gain access to) as part of a data breach in the next
year.
– [leak entity] might learn your [salary/medical history]. The chance
this happens is higher than the chance that your bank account
will be compromised (accessed by a person who you did not
intend to gain access to) as part of a breach in the next year.
Finally, respondents were asked:
– Would you be willing to share your [salary/medical record] with
the [initiative/non-profit]?
– [If Yes] Why would you be willing to share your [salary/medical
record]?
– [If No] Why would you not be willing to share your
[salary/medical record]?
– [If I’m not sure] Why are you unsure whether you would be will-
ing to share your [salary/medical record] with the [initiative/non-
profit]?
A.2 Complete Description of Survey Two
Respondents were randomized into either the salary scenario or the
medical scenario, described below. In both scenarios, respondents
were randomly shown a description of differential privacy, listed
after the scenarios.
Salary Scenario: Imagine that you work in the banking industry.
You are friends with a group of other people who work in banking
companies in your city. One of your friends is part of a transparency
initiative that is trying to publish general statistics about pay in
the banking industry. As part of this initiative, they have asked
everyone in the group to share their salaries and job titles using an
online web form on the initiative’s website. [description from the
list of differential privacy descriptions, shown below.]
In this survey we are going to ask you a series of questions about
a hypothetical scenario. Please do your best to imagine yourself
in this scenario and answer the questions as if you were actually
making the decisions about which you will be asked.
Medical Scenario: Imagine that during your next doctor’s visit,
your primary care doctor informs you that they are part of a non-
profit organization trying to push the boundaries of medical re-
search. This non-profit is asking patients around the country to
share their medical records, which will be used to help medical
research on improving treatment options and patient care. Your
doctor, with your permission, can facilitate the non-profit getting
the information they need. [description from the list of differential
privacy descriptions, shown below.]
In this survey we are going to ask you a series of questions about
a hypothetical scenario. Please do your best to imagine yourself
in this scenario and answer the questions as if you were actually
making the decisions about which you will be asked.
List of Differential Privacy Descriptions: Names of the descrip-
tion, shown in italics inside parenthesis, were not show to respon-
dents.
– (Control:) no additional text
– (Unsubstantial:) To reduce the intrusion into personal privacy,
your friend says they will use a technique called differential pri-
vacy. Differential privacy is the gold standard in data privacy and
protection and is widely recognized as the strongest guarantee
of privacy available.
– (Techniques:) To reduce the intrusion into personal privacy, your
friend says they will use a technique called differential privacy.
Differential Privacy injects statistical noise into collected data
Session 11C: Software Development and Analysis CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3051Age
Woman
Man
Black
White
Hispanic
Asian
Native American
Edu. High school or less
Edu. Some College
Edu. Bachelor’s or above
Income
Internet Skills (1-5)
Percent
-
42.92%
56.08%
12.00%
76.15%
7.48%
9.12%
1.64%
9.04%
23.60%
66.78%
-
-
Survey One (n=1,216)
Survey Two (n=1,208)
Mean
37.09
-
-
-
-
-
-
-
-
-
-
US$61.6K
2.19
Stdev
12.00
-
-
-
-
-
-
-
-
-
-
US$42.9K
.89
Percent
-
40.64%
58.36%
11.92%
76.98%
7.12%
7.53%
1.32%
9.10%
22.93%
67.54%
-
-
Table 6: Survey demographics.
Mean
37.39
-
-
-
-
-
-
-
-
-
-
US$61.5K
2.28
Stdev
11.16
-
-
-
-
-
-
-
-
-
-
US$41.3K
.86
in a way that protects privacy without significantly changing
conclusions.
– (Enables:) To reduce the intrusion into personal privacy, your
friend says they will use a technique called differential privacy.
Differential Privacy allows analysts to learn useful information
from large amounts of data without compromising an individual’s
privacy.
– (Trust:) To reduce the intrusion into personal privacy, your friend
says they will use a technique called differential privacy. Differ-
ential privacy is a novel, mathematical technique to preserve
privacy which is used by companies like Apple and Uber.
– (Risk:) To reduce the intrusion into personal privacy, your friend
says they will use a technique called differential privacy. Differ-
ential privacy protects a user’s identity and the specifics of their
data, meaning individuals incur almost no risk by joining the
dataset.
– (Technical:) To reduce the intrusion into personal privacy, your
friend says they will use a technique called differential privacy.
Differential privacy ensures that the removal or addition of a
single database item does not (substantially) affect the outcome
of any analysis. It follows that no risk is incurred by joining the
database, providing a mathematically rigorous means of coping
with the fact that distributional information may be disclosive.
Questions: Answer options for each questions presented in <>.
Text differences between the two scenarios presented in italics
inside brackets. The names of the data leaks used in the main body
of the text are shown in italics inside parenthesis and were not
shown to users.
– Would you be willing to share your [salary/medical record] with
the [initiative/non-profit]?
– [If Yes] Why would you be willing to share your [salary/medical
record]?
– [If No] Why would you not be willing to share your
[salary/medical record]?
– [If I’m not sure] Why are you unsure whether you would be will-
ing to share your [salary/medical record] with the [initiative/non-
profit]?
For each of the following statements, please indicate if you expect
the following to be true or false if you share your salary and job
title as part of this initiative.
– (Organization:) [My friend will not be able to learn my salary and
job title/The contents of my medical record will be stored only by
my doctor’s office, and will not be stored by the non-profit]
– (Hack:) A criminal or foreign government that hacks the [trans-
parency initiative/non-profit] could learn my [salary and job ti-
tle/medical history]
– (Law Enforcement:) A law enforcement organization could ac-
cess my [salary and job title/medical history] with a court order
requesting this data from the [transparency initiative/non-profit]
– (Data Analyst:) A data analyst working [on/for] the [salary trans-
parency initiative/non-profit] could learn my exact [salary and
job title/medical history]
– (Graphs:) Graphs or informational charts created using informa-
tion given to the [salary transparency initiative/non-profit] could
reveal my [salary and job title/medical history]
– (Share:) Data that the [salary transparency initiative/non-profit]
shares with other organizations doing [salary/medical] research
could reveal my [salary and job title/medical history]
Session 11C: Software Development and Analysis CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3052