### 授权使用说明
授权使用仅限于清华大学。下载时间为2021年3月20日09:57:38 UTC，来源为IEEE Xplore。适用相关限制。

### HTTP请求示例
```
GET /homepage?userid=5&popups=no HTTP/1.1
User-Agent: Mozilla/1.7
Accept: text/html
```

当接收到请求时，除了将请求放入动态请求队列之一外，头部解析线程还将进一步解析查询字符串 `userid=5&popups=no` 以及两个头部字段 `User-Agent` 和 `Accept`。这些头部和查询字符串将被解析成字典（也称为哈希表）。我们进行这些进一步的解析主要是因为不希望带有打开数据库连接的线程浪费时间做其他事情，而是专注于生成数据。对于静态请求，这不是问题，因此我们允许处理这些静态请求的线程解析它们的头部。

每个动态请求线程会将请求字符串映射到一个函数，并检查该函数的返回值是字符串还是待渲染的模板。如第3.1节所述，每个函数应返回一个未渲染的模板，我们执行此检查以确保向后兼容性，使未经修改的模板代码仍能在我们修改后的Web服务器上正确运行。如果函数返回字符串，则动态请求线程直接将字符串发送给客户端。如果函数返回模板，则动态请求线程将请求传递给模板渲染线程池。一旦某个模板渲染线程完成动态页面的渲染，它会测量输出的大小，从而能够适当地设置 `Content-Length` HTTP响应头。这是大多数现有的动态内容生成方法所无法实现的。模板渲染线程随后将响应传输给用户代理客户端。

### 请求调度策略
我们的请求调度方法使用两个线程池来处理动态请求：一个通用动态请求线程池和一个长时间动态请求线程池。我们将这两个池分别称为通用池和长时间池。长时间池仅处理需要较长时间才能完成的请求。我们使用两秒作为区分快速和长时间请求的临界点，这在我们的基准测试中是合适的。通用池处理快速和长时间的动态请求，而可以快速处理的请求总是由这个池来处理。由于我们的首要任务是确保快速请求不会因排队等待多个长时间请求而被阻塞，因此通用池的线程数是长时间池的四倍。

为了区分快速和长时间请求，我们跟踪每页生成数据所需的平均时间。具体来说，我们测量从获取请求到将其未渲染的模板放入模板渲染队列的时间成本。这为我们提供了执行数据库查询所需时间的准确度量。为了确保快速请求几乎总能立即得到处理，我们的Web服务器跟踪通用池中的空闲线程数量，记作 `t_spare`。同时，它不断更新保留用于快速请求的最小线程数，记作 `t_reserve`。`t_spare` 是反映Web服务器负载的测量值，而 `t_reserve` 是动态调整的值，反映了应该保留用于快速请求的目标线程数。

当 `t_spare` 大于 `t_reserve` 时，通用池中的空闲线程充足，可以处理一些长时间请求以及所有快速请求。当 `t_spare` 不大于 `t_reserve` 时，通用池中的空闲线程不足，应专门用于处理快速请求。因此，当头部解析线程接收到一个长时间请求时，如果 `t_spare` 大于 `t_reserve`，则将请求发送到通用池；否则，请求将被发送到长时间池。表1总结了头部解析线程分发动态请求的三条规则。

我们的Web服务器每秒检查并修改一次 `t_reserve` 以应对流量峰值。因为我们希望防止快速请求被长时间请求阻塞，所以在怀疑出现流量峰值时我们会增加 `t_reserve`。具体来说，每当 `t_spare` 低于 `t_reserve` 时，我们会将 `t_reserve` 增加差值，并加上 `t_spare` 低于配置的 `t_reserve` 最小值的部分（如果有）。我们降低 `t_reserve` 的速度较慢，以避免过早地假设流量峰值已经结束。当 `t_spare` 高于 `t_reserve` 时，我们将 `t_reserve` 减少一半的差值，但不低于配置的最小值。表2展示了在10秒内 `t_reserve` 与 `t_spare` 的动态变化情况，其中 `t_reserve` 的最小值配置为20。

直观地说，当流量峰值发生且通用池中的空闲线程变得稀缺时，我们会增加 `t_reserve`，以便更多的长时间动态请求可以被分配到长时间池，从而将通用池中的线程保留给快速请求。相反，当流量峰值趋于消失且通用池中的空闲线程变得充足时，我们减少 `t_reserve`，使得这些空闲线程也可以用于处理传入的长时间动态请求。

尽管我们有多个线程池用于处理动态请求，但我们只有一个线程池用于处理静态请求和一个线程池用于模板渲染。这是因为处理不同静态请求或渲染不同模板所需的时间差异远小于需要数据库查询的不同请求之间的时间差异。然而，在不同的基准测试或Web应用程序中，将这种技术应用于静态请求和模板渲染可能是值得的。

### 系统评估
在本节中，我们首先描述实验设置，包括使用Django Web模板实现的TPC-W基准测试和测试床配置。然后，我们展示实验结果。

#### 实验设置
我们采用TPC-W交易型Web电子商务基准测试[24]来评估提出的请求调度方法。TPC-W模拟了一个在线书店，支持多种活动，如多在线会话、动态页面生成和在线交易。它还指定了一个工作负载生成器，模拟许多客户访问网站的情况。该基准测试设计得非常好，特别是在网站处于高负载情况下，数据库访问成为瓶颈。不幸的是，现有的TPC-W实现都使用传统的动态Web内容生成技术。例如，威斯康星大学麦迪逊分校的PHARM团队[17]开发了TPC-W基准测试的Java Servlets实现，赖斯大学的一个团队[18]开发了PHP、Java Servlets和EJB的TPC-W基准测试实现。因此，我们必须从零开始使用现代Web模板技术实现TPC-W基准测试。我们选择了Django模板，它由CherryPy Web服务器支持，并被《华盛顿邮报》用于其大部分在线内容。

我们的TPC-W基准测试实现包括455行Python代码和704行模板代码（大部分是纯HTML）。值得注意的是，这个实现的代码行数不到PHARM团队的Java Servlets实现的四分之一。在图6所示的实验测试床上，三台计算机用于执行TPC-W基准测试。一台计算机用于运行MySQL 5.0数据库服务器，一台用于托管静态和动态内容的CherryPy Web服务器，一台用作工作负载生成器。每台计算机都有8个不同的3.7 GHz CPU，每个CPU有16 KB的L1缓存和2 MB的L2缓存。每台计算机都有8 GB的RAM，运行Linux内核版本2.6.18，并通过100 Mbps网络接口卡连接到同一局域网。每次实验的持续时间为一小时，测量间隔为50分钟。前五分钟的预热时间和最后五分钟的冷却时间不包括在内。TPC-W数据库配置为包含一百万本书、288万客户和259万本书订单。本文描述的所有实验运行都使用标准的“浏览混合”工作负载，每个模拟客户端在访问新页面之前的标准等待时间为0.7到7秒。工作负载生成器模拟400个客户端，以使Web服务器处于高负载状态。服务器的设置类似于生产环境，其中Web服务器和数据库服务器肯定在同一局域网上。当然，大多数客户端不会从同一个网络连接，因此此基准测试的传输时间远低于实际网站的传输时间。然而，这在这里不是问题，因为我们主要关注数据库查询响应时间的减少而不是传输延迟。

#### 实验结果
我们使用两个性能指标来比较我们提出的方案与传统的每请求一线程方案：Web交互响应时间和Web服务器吞吐量。在TPC-W中，Web交互是指模拟客户端与系统下服务器之间的完整通信周期。Web交互响应时间在客户端侧测量，计算从客户端发出Web交互请求的第一个字节到客户端接收到Web交互响应的最后一个字节所经过的时间。Web服务器吞吐量在服务器端测量，以每分钟完成的Web交互次数表示。

在本节的其余部分，我们使用术语“未修改的Web服务器”来指代传统的每请求一线程CherryPy Web服务器，在该服务器上运行未修改的Django Web模板TPC-W基准测试。我们使用术语“修改后的Web服务器”来指代我们提出的多线程池CherryPy Web服务器，在该服务器上运行修改后的Django Web模板TPC-W基准测试。

##### Web交互响应时间
表3列出了使用未修改和修改后的Web服务器运行基准测试的平均响应时间。在基准测试网站的14个页面中，有11个页面的提议方案显著缩短了Web交互响应时间。许多页面（如主页）的平均响应时间减少了两个数量级。一个缓慢的页面（TPC-W新产品）保持不变，一个页面（TPC-W执行搜索）响应时间略有增加，一个页面（TPC-W管理响应）明显变慢。修改后的Web服务器中极快和非常慢页面之间的性能差异部分是由于TPC-W基准测试本身。大多数查询要么是利用索引的选择语句，要么是插入新行的插入语句。即使在非常大的数据库上，这两种操作也不太慢；创建比当前数据库大十倍的数据库也不会导致快速查询显著变慢。在TPC-W基准测试的14个页面中，有10个页面由于上述原因本质上非常快（小于10秒），三个页面由于执行大量且非常复杂的查询而非常慢，最后一个页面由于对频繁使用的表进行更新而非常慢。最后一个页面是TPC-W管理响应页面，它是唯一一个在我们的修改后的Web服务器上经历显著减速的页面。为了执行更新，它必须获取数据库表上的锁，迫使它等待其他线程完成对该表的使用。讽刺的是，这个网页名称在修改后的Web服务器上响应时间更长，因为其他页面的效率更高，延长了获取表锁的等待时间。实际上，在服务器没有任何显著负载的情况下，这个页面相当快。一个缓慢的管理页面不像电子商务网站上可见的缓慢页面那样麻烦。付费客户可能会离开响应缓慢的网站，但这个问题并不存在于仅对管理员可见的页面。因此，修改后的服务器中最受影响的页面是对在线书店盈利能力影响最小的页面。

图7显示了这些慢查询对其他Web页面响应时间的影响，展示了未修改的Web服务器上的请求队列长度。显然，当短请求在队列中被长时间请求阻塞时，队列长度往往会非常长。相比之下，图8(a)和8(b)显示了修改后的Web服务器中与两个动态请求线程池相关的队列长度。一方面，由于在通用动态请求线程池中有预留的线程，短查询几乎可以立即执行。另一方面，由于通用池中的线程数量较多，可以处理更多的短请求，从而减少了长时间请求对短请求的影响。

### 总结
通过使用多线程池调度策略，我们的Web服务器能够显著提高响应时间，尤其是在处理大量并发请求时。虽然某些特定页面（如管理响应页面）在修改后的服务器上响应时间有所增加，但总体而言，系统性能得到了显著提升。这对于提高用户体验和系统吞吐量至关重要。