12-Apr-04
15,785,164
1,654,882
396,743
39,137
188,213
139,745
34,343
3,723
Table 1. Summary of the raw data
3 Background on used statistical methods
3.1 Self–similarity and long–range dependence
MB
transf.
34,485
13,785
10,138
311
Since in Web workload context we deal with time series, the
self–similarity is deﬁned as follows. Let X = {Xi, i ≥ 1} be a
stationary sequence. Let
X (m)
k =
1
m
km(cid:1)
i=(k−1)m+1
Xi,
k = 1, 2, . . .
(1)
be the corresponding aggregated sequence with level of aggrega-
tion m obtained by averaging non-overlapping blocks of size m.
Then, for all integers m, the following holds for a self–similar
process
X(t) d= m1−H X (m).
(2)
A stationary sequence is said to be exactly second–order self–
similar if m1−H X (m) has the same variance and autocorrelation
as X for all m. A stationary sequence is said to be asymptotically
second–order self–similar if m1−H X (m) has the same variance
and autocorrelation as X as m → ∞. Asymptotically second–
order self–similar processes are also called long–range depen-
dant processes. Long–range dependent processes are character-
ized by hyperbolically decaying autocorrelation function, that is,
r(k) ∼ k−β as k → ∞, where 0 < β < 1. Since β < 1, the sum
of the absolute values of the autocorrelation function approaches
inﬁnity, that is, the autocorrelation function is non-summable.
Simply put, long–range dependence describes the property that
the correlation structure of a time series is preserved irrespective
of time aggregation, that is, the autocorrelation function (ACF) is
the same in either course or ﬁne time scales.
A predominant way to quantify the self–similarity and long–
range dependence is through the Hurst exponent H. For a self–
similar process 0.5 < H < 1.0; as H increases from 0.5 to 1.0,
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Hill estimator [24] is an alternative approach for estimating
the tail index α of a semiparametric Pareto type model given by
(3). For the discussion that follows, let X1, X2, . . . , Xn denote
observed values of the random variable X and let X(1) ≥ X(2) ≥
. . . ≥ X(n) be the ordered statistics of the data set. The idea
behind the Hill estimator is to use only k upper-order statistics,
that is, to sample from the part of the distribution which looks
most Pareto-like. Therefore, we pick k < n and compute the Hill
estimator
Hk,n =
1
k
k(cid:1)
i=1
log X(i) − log X(k+1).
(5)
Thus, for each value of k we obtain an estimate of the tail index
parameter αk,n = 1/Hk,n. In practice, the estimates of the tail
index αk,n are plotted as a function of k, for the range of k-values.
A typical Hill plot varies considerably for small values of k, but
becomes more stable as more and more data points in the tail of
the distribution are included (often up to a cut-off value, to the left
of which (3) no longer holds). If the plot stabilizes to a constant
value one can infer the value of the tail index α. The absence of
such straight line behavior is a strong indication that the data are
not consistent with the heavy–tailed distribution (3).
4 Request–based analysis
In this section we ﬁrst examine whether the long–range de-
pendence (i.e., asymptotically second–order self–similarity) ap-
plies to the request arrival process and then formally test the as-
sumption for Poisson arrivals.
4.1 Number of requests per unit of time
Figure 2 shows the time series plot of the number of requests
per second for one week period for the WVU data set. As it can
be seen from Figure 3, the autocorrelation function is slowly de-
caying which indicates long–range dependence. Next, we esti-
mate the values of the Hurst exponent using the SELFIS tool [14].
These values are presented in Figure 4, with Web sites sorted by
the total number of requests in descending order.
Figure 2. Number of requests per second - WVU
As described in section 3.1, all Hurst exponent estimators as-
sume stationary time series, that is, the trend and periodicity can
obscure the analysis based on Hurst exponent. However, related
papers that studied self–similarity and long–range dependence of
Web trafﬁc either avoided dealing with non–stationarity of the
time series or ignored it. Thus, in [7] the authors concentrated
on individual hours from the request–based time series in order
to provide as nearly a stationary dataset as possible, thus avoid-
ing to deal with non-stationarity of the trafﬁc. A period of two
Figure 3. ACF for number of requests per second
- WVU
Figure 4. Hurst exponent for request per second
based on the raw data
weeks for two e–commerce sites was considered for the request–
based analysis presented in [21]. The existence of long–range
dependence was suggested based on the variance time plot, with-
out testing the stationarity of the time series, that is, ignoring the
trend and periodicity of the signal.
One of our goals is to study how non–stationarity of the traf-
ﬁc affects the estimates of the Hurst exponent, and consequently
the conclusions drawn about long–range dependence. We use the
Kwiatkowski-Phillips-Schmidt-Shin test [17] to test the null hy-
pothesis of stationarity against an alternative of a unit root which
means that time series is non-stationarity. According to this test
the request arrival processes (i.e., number of requests per second)
for all Web servers considered in this paper are non–stationary.
Therefore, we estimate and eliminate the trend and periodicity
from the request–based time series using the least square esti-
mation of trend, peridogram for ﬁnding the periodicity, and dif-
ferencing method for removing the seasonal component [4]. All
datasets considered in this paper had a slight trend component
and a 24 hour period corresponding to day/night change of traf-
ﬁc intensity. After removal of the trend and the seasonal com-
ponent, the Kwiatkowski-Phillips-Schmidt-Shin test [17] proved
that the time series is stationary. The autocorrelation function
of the stationary time series shown in Figure 5 still seams to
be non–summable, which is an indication of long–range depen-
dence. However, its value is lower than for the original (non-
stationary) time series, which indicates that not accounting for
the trend and periodicity leads to overestimating the long–range
dependence. To conﬁrm these ﬁndings formally, we estimate the
Hurst exponent for the stationary request–based time series. The
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
results are presented in Figure 6. The following observations can
be drawn from the estimates of the Hurst exponent based on the
raw data and stationary data: (1) The values of the Hurst expo-
nent based on the raw data, with a few exceptions, are higher
than the values based on the stationary time series. This proves
the fact that for accurate estimates of self–similarity and long–
range dependence the analysis must account for phenomena such
as trend and periodicity. (2) The values of the Hurst exponent
for all Web sites are higher than 0.5, which indicates that the
request arrival processes on a second time scale is asymptoti-
cally second–order self–similar (i.e., long–range dependent); the
degree of self–similarity increases with the workload intensity,
which is consistent with the observations made for the LAN traf-
ﬁc in [18] and for the Web trafﬁc in [7]. (3) The Hurst estimators
provide consistent estimates for all four Web servers, which is not
necessarily always the case [13]. (4) In most cases Abry-Veitch
method provides slightly higher value of H than Whittle method
which is consistent with the results presented in [13].
the estimates ˆH (m) of the Hurst exponent obtained from the ag-
gregated series X (m) using Whittle and Abry-Veitch methods for
the stationary request–based time series of the WVU server. The
upper and lower dotted lines are the limits of the 95% conﬁdence
intervals on H. These Figures show that for WVU dataset, the
values of ˆH (m) are relatively consistent as the aggregation level
is increased (i.e., ˆH (m) ∈ [0.768, 0.986] for Whittle method, and
ˆH (m) ∈ [0.748, 0.925] for Abry-Veitch method). The same holds
for the 95% conﬁdence interval bands, indicating a statistical ev-
idence for long–range dependence of the request arrival process.
The estimates of H for other sites, such as for example NASA-
Pub2, are even more stable and ﬂuctuate only slightly throughout
the aggregation levels (i.e., ˆH (m) ∈ [0.534, 0.606] for Whittle
method, and ˆH (m) ∈ [0.533, 0.688] for Abry-Veitch method).
Figure 7. Whittle estimates for stationary request–
based time series - WVU
Figure 5. ACF for number of requests per second
after removing the trend and periodicity - WVU
Figure 6. Hurst exponent for request per second
based on the stationary data
Since the mathematical deﬁnition of the long–range depen-
dence is asymptotic in nature, we next employ the Hurst exponent
estimators on aggregated time series [7], [18]. Each one week
dataset is aggregated at increasing levels m as described with
equation (1), and the estimators are applied to each m–aggregated
dataset2. As m increases, short–range dependencies are averaged
out of the dataset; if the value of H remains relatively constant,
we can be conﬁdent that it measures a true underlying level of
(asymptotic second–order) self–similarity. Figures 7 and 8 show
2As the aggregation level m increases the conﬁdence intervals tend to widen
since for larger m there are fewer observations in X (m).
Figure 8. Abry-Veitch estimates for stationary
request–based time series - WVU
4.2 Testing for Poisson arrivals at request level
In this subsection, we formally test whether the request ar-
rivals can be modelled with Poisson process for each of the Low,
Med, and High intervals. To test the two main characteristics of
the Poisson process – request inter–arrival times are independent
random variables which follow the exponential distribution - we
use the method proposed in [22].
Before the test for Poisson arrivals can be applied, the origi-
nal signal has to be processed due to the following reasons. (1)
The Web servers considered in this study have timestamps with
granularity of one second, which leads to multiple requests with
the same timestamp. Assumptions about how these requests are
distributed within a one second interval have to be made before
we can apply the test for Poisson arrivals. Since different assump-
tions may lead to different results [29], we use two distributions
for the request arrivals over the one second interval: uniform and
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
√
deterministic (i.e., requests evenly spread out over the one second
interval). (2) Since the request arrival rate varies during the four
hours intervals, testing for homogeneous Poisson model with a
ﬁxed rate is not appropriate. Therefore, we divide each of the
Low, Med and High four hour intervals into four 1-hour intervals
with approximately constant arrival rate. Then, we test each 1-
hour interval for independent and exponentially distributed inter–
arrival times.
Test for independent request inter–arrival times
For each 1-hour interval i (i = 1, 2, 3, 4), we compute its lag one
autocorrelation ρi. Let S be the random variable of number of
intervals having ρi less than 1.96/
ni, where ni is number of
samples in the ith interval. Then S follows the binomial distri-
bution B(4, 0.95). Suppose s is the observed value of S, then if
P (S = s) < 0.05, we conclude with 95% conﬁdence that the
inter-arrivals are not independent. We also apply one further test
for independent request inter–arrivals.
If the inter–arrivals are
truly independent, then their autocorrelation would be negative
with probability 0.5 and positive with probability 0.5. Let X be
the random variable of number of positive ρi’s, then X follows
the binomial distribution B(4, 0.95). Suppose x is the observed
value of X, then if P (X = x) < 2.5%, the inter–arrivals are
signiﬁcantly positively correlated. Similarly, let Y be the random
variable of number of negative ρi’s, and y is the observed value of
Y . Then if P (Y = y) < 2.5%, the inter–arrivals are signiﬁcantly
negatively correlated.
Test for exponentially distributed request inter–arrival times
Let the null hypothesis be H0 : F (x) = 1−e−ˆλx where ˆλ = 1/ ¯X
is estimated from the sample. To test the goodness of ﬁt for each
1-hour interval, we use the Anderson–Darling (A2) test [26] be-
cause it is generally much more powerful than either of better
known Kolmogorov–Smirnov or χ2 tests. A2 is an empirical dis-
tribution test which looks at the entire observed distribution and
it is particularly good for detecting deviations in the tail of a dis-
tribution.
The null hypothesis is rejected on an interval if the modiﬁed
test statistic A2(1+0.6/n) is greater than the critical value 1.341.
Let Z be the random variable of total number of intervals having
test statistic less than 1.341, then Z follows the binomial distri-
bution B(4, 0.95). Suppose z is the observed value of Z, then if
P (Z = z) < 0.05, we conclude with 95% conﬁdence that the
inter–arrivals are not exponential.
We repeat the same methods to test for independent and expo-
nentially distributed request inter–arrival times by dividing each
four hour period in 10-minute intervals. The results show that
the request arrivals do not follow the Poisson process with ﬁxed
1-hour or 10-minute rates for any of the considered Web sites.
These results are valid regardless of the assumption made about
the distribution of the request arrivals over one second (i.e., uni-
form and deterministic). Our results are in agreement with the
recent study which showed that the backbone Internet trafﬁc ex-
hibits long–range dependence at scales of seconds and above
[15]. The same study showed that the Internet trafﬁc can be well
represented by the Poisson model for sub–seconds time scales.
The granularity of the measurements in our datasets is one sec-
ond, which does not allow testing the Poisson assumption on the
ﬁner time scales.
In summary, the results presented in this section show that
Web workload at request level, similarly to LAN and WAN work-
load, is long–range dependant. These results are consistent with
earlier result for Web trafﬁc presented in [7]. In addition, we have
explicitly shown that the assumption that the request arrivals can
be modelled with Poisson process is not valid. This means that
several Web performance models which used queuing networks
[23], [25], [30] or layered queuing networks [8] are based on in-
correct assumptions and most likely provide misleading results.
5 Session–based analysis
In this section we study, in a rigorous statistical manner,
the session arrival process (i.e, inter–session characteristics) and
intra–session characteristics introduced in our earlier work [11].
It should be emphasized that the empirical studies which ad-
dressed Web sessions in the past were mainly focused on sim-
ple analysis and did not explore the long–range dependence and
heavy–tailed behavior.
5.1
Inter–session characteristics