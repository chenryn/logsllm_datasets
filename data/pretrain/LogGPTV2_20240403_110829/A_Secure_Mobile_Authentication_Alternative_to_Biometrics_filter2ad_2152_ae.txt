1
1
0
0
0
0
2
2
5
5
2
2
0
0
)
%
(
R
R
F
)
%
(
R
R
F
60
40
20
0
60
40
20
0
5
5
0
0
0
0
0
0
1
1
0
0
5
5
1
1
0
0
0
0
2
2
5
5
2
2
0
0
0
0
0
0
5
5
3
3
0
0
0
0
4
4
0
0
5
5
4
4
0
0
0
0
5
5
3
3
0
0
λ
(b)
0
0
0
0
0
0
5
5
3
3
0
0
0
0
4
4
0
0
5
5
4
4
0
0
0
0
5
5
3
3
λ
(d)
t
u
o
d
l
o
H
)
%
(
R
A
F
λ
(a)
λ
(c)
less than 0.67% and 0.17% respectively when using PCs with fea-
ture rank 200 − 400 and λ = 500.
Œe purpose of the LSH-based transformation is to encode the
feature vector of an image extracted by a DNN into a binary string.
Our conjecture is that larger lambda values extract more high qual-
ity information about the feature vectors, which in turn leads to
lower FAR and FRR. Œis is partly due to the random nature of the
LSH we used (see Figure 9), where roughly half of the bits among
diﬀerent images are diﬀerent, and images of the same object have a
smaller distance overall. Using more LSH bits reduces the variance
of the distance that was due to perturbations from using a random
projection, hence provides a beŠer separation between TP and FP
image comparisons.
7.2 Resilience to Illumination Changes
We evaluate the resilience of ai.lock to illumination changes us-
ing the 6,478,200 authentication samples of the illumination robust-
ness evaluation dataset (§ 6.2). While the FAR of the MLMS vari-
ant of ai.lock (for λ = 500 and t = 3) remains very small (0.006%),
its FRR increases to 16.9%. Decreasing the required matching seg-
ments count (t) to 2, reduces the FRR to 11.43%, which results in a
slightly higher FAR of 0.010%.
7.3 ai.lock Under Attack
Holdout dataset, real image attack. Œe performance over the
ai.lock holdout set is reported in Figure 5(d)-(f). As before, the
performance of all the ai.lock variants improves with the increase
in λ. In agreement with the results of the cross validation experi-
ments, we conclude that exploiting information from multiple In-
ception.v3 layers decreases the FRR, while using information from
multiple image segments decreases the FAR. In addition, the MLMS
ai.lock variant achieves the highest F1 score (97.21% for λ = 500).
Œe SLMS and MLMS schema consistently achieve the lowest FAR,
which is as low as 0% on the holdout dataset.
Synthetic image attack. We use the synthetic aŠack dataset DS1
of § 6.2 to evaluate the performance of SLSS ai.lock, using the
trained parameters of § 7.1. Table 5 shows the performance of
ai.lock in classifying these aŠack samples. Œe FAR decreases sig-
niﬁcantly with λ, and is as low as 0.00002% when λ = 500.
Œe proportion of the reference images that have been broken
at least once decreases signiﬁcantly by increasing λ: from 16.86%
to 0.79% (11 Nexus images) when λ is 150 and 500 respectively. A
majority of the broken references are broken only by a small num-
ber of candidate images: when λ = 500, only 2 of the 11 broken
images have been broken 5 times by the synthetic images in DS1.
Œe average number of trials until ﬁnding the ﬁrst matching syn-
thetic image, over the 11 broken reference images, is 31,800.
Vaccinated ai.lock. To further improve the ai.lock resistance to
synthetic image aŠacks, we use the synthetic image aŠack dataset
DS2 (see § 6.2) along with the ai.lock training dataset, to train
Figure 6: (a) Cross validation FAR, (b) Cross validation FRR ,
(c) Holdout FAR, and (d) Holdout FRR of SLSS ai.lock when
trained over the ai.lock and synthetic image attacks of DS2.
)
%
(
R
A
F
0.004
0.003
0.002
0.001
0.000
−0.001
0
5
0
0
1
0
5
1
0
0
2
0
5
2
λ
0
0
3
0
5
3
0
0
4
0
5
4
0
0
5
Trained on ai.lock dataset
Trained on ai.lock dataset
+ synthetic image attack
DS2 (Not PCA)
Figure 7: FAR of ai.lock on synthetic image attack, when
trained on the ai.lock dataset vs. when trained also on DS2.
‡e “vaccinated” ai.lock improves its resistance to the syn-
thetic image attack: the FAR drops by more than 74%, 51%
and 59% when λ is 50, 150 and 350 respectively.
ai.lock. Speciﬁcally, we divide the synthetic image aŠack dataset
DS2 into 5 folds and distribute them into the 5 training folds of the
ai.lock dataset. In other words, we train ai.lock on an additional
236 × 20,000 = 4,720,000 invalid authentication samples. Œe hold-
out set remains untouched and is used to evaluate the eﬀectiveness
of this approach. Œen, we train ai.lock with SLSS as before using
the cross validation experiment (see § 7.1).
We experimented with two cases. First, the invalid synthetic im-
age aŠack samples in DS2 contribute to both the PCA based feature
selection and the error tolerant threshold (τ ) discovery processes.
Second, those samples are only used in the process of discovering
τ . Figure 6 shows the cross validation FAR and FRR (a, b) as well as
the performance over the holdout set (c, d). In both experiments,
we observed a drop in the FAR of ai.lock, however, the FRR in-
creases. Œe FAR improvement is higher for the second case. We
conjecture that the inclusion of synthetic, not camera captured im-
ages, is misleading the PCA based feature selection module into
capturing irrelevant information.
We used the ai.lock trained on the synthetic image aŠack dataset
DS2 to evaluate its performance over the synthetic image aŠack
DS1. Figure 7 compares the performance of ai.lock when trained
9
λ
50
150
250
350
500
FAR×10+6
11.89
0.09
0.03
0.000
0.000
Table 6: SLSS ai.lock performance on the synthetic creden-
tial attack. ai.lock is unbreakable under 1.4 billion samples
of the synthetic credential attack: its FAR is 0 when λ ≥ 300.
λ
P1
P2
150
350
500
8.6e-1
2.8e-6
9.3e-1
9.1e-1
0.0
0.0
Table 7: Average probability of collision, for valid (P1) and in-
valid (P2) samples in the ai.lock holdout set, when the ai.lock
imageprint is considered as image hash value and at most
c = ⌊λ × (1 − τ )⌋ bits of error is allowed. In all cases, P1 > P2,
thus conclude that ai.lock is an LSIM function.
on the ai.lock dataset and when trained on the ai.lock and the syn-
thetic dataset DS2. Training also over synthetic image aŠack sam-
ples helps ai.lock to be more resilient to synthetic image aŠack,
especially for small values of λ.
Synthetic credential attack. Table 6 shows the FAR values for
ai.lock under the synthetic credential aŠack dataset described in
§ 6.2. For all values of λ greater than 300, the FAR of ai.lock is
equal to 0. Even for a λ of 50, the FAR is 11.89 × 10−4%. Œis is an
important result: even a powerful adversary who can create and
test synthetic credentials on a large scale, is unable to break the
ai.lock authentication.
7.4 Is ai.lock δ -LSIM?
We now evaluate if the basic ai.lock (SLSS) variant, with the param-
eters identiﬁed in § 7.1 preserves the similarity of the input space,
i.e., if it satisﬁes the LSIM properties (see Deﬁnition 3.1). We use
the ai.lock holdout set to evaluate the probability of obtaining the
same hash value for valid and invalid samples.
.
λ
Let πi and πj be the imageprints corresponding to two images
in the ai.lock holdout set. Let dH (πi , πj ) denote the Hamming dis-
tance and SH (πi , πj ) denote the normalized Hamming similarity of
these imageprints, i.e., SH (πi , πj ) = 1 −
dH (πi , πj )
Œe output of ai.lock can be considered either as a single bit or
a string of bits. In the former case, the imageprints consist of the
concatenation of the output of multiple hash functions, while in
the later case, the entire imageprint is assumed to be the ai.lock
hash value. In the following, we empirically evaluate the P1 and
P2 values (see Deﬁnition §3.1), for the case where the entire ai.lock
imageprint is considered as the hash value.
In Appendix C, we