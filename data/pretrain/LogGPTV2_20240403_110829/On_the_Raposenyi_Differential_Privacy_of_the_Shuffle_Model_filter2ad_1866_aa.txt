# On the Rényi Differential Privacy of the Shuffle Model

**Authors:**
- Antonious M. Girgis (UCLA)
- Deepesh Data (UCLA)
- Suhas Diggavi (UCLA)
- Ananda Theertha Suresh (Google)
- Peter Kairouz (Google)

## Abstract
This paper investigates the Rényi Differential Privacy (RDP) guarantees for general discrete local randomizers in the shuffle privacy model. In this model, each of the \( n \) clients randomizes its response using a local differentially private (LDP) mechanism, and the untrusted server receives a random permutation (shuffle) of the client responses without any association to individual clients. Our main contribution is the first direct RDP bounds for general discrete local randomization in the shuffle privacy model, and we introduce new analysis techniques that may be of independent interest. We demonstrate through numerical experiments that, for important regimes, our RDP bound, when composed, provides an 8× improvement in privacy guarantee over the state-of-the-art approximate Differential Privacy (DP) guarantee with standard composition. Additionally, combining our result with Poisson subsampling leads to at least a 10× improvement over subsampled approximate DP with standard composition.

## CCS Concepts
- **Security and privacy → Privacy-preserving protocols.**

## Keywords
- Differential privacy
- Rényi divergence
- Distributed learning
- Privacy amplification via shuffling
- Privacy composition

## ACM Reference Format
Antonious M. Girgis, Deepesh Data, Suhas Diggavi, Ananda Theertha Suresh, and Peter Kairouz. 2021. On the Rényi Differential Privacy of the Shuffle Model. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security (CCS '21), November 15–19, 2021, Virtual Event, Republic of Korea. ACM, New York, NY, USA, 21 pages. https://doi.org/10.1145/3460120.3484794

## 1 Introduction
Differential privacy (DP) [16] provides a principled and rigorous framework for data privacy by ensuring that the information leakage from the output of an algorithm is limited. A common approach to achieve DP is to randomize the output of the algorithm. Initially, DP was studied in a centralized setting, where the focus was on protecting data queries to a trusted server [16]. However, in distributed applications like federated learning [30], two key aspects must be considered: (i) data is held locally at clients and needs to be used for computation with an untrusted server, and (ii) repeated interactions are often required to build effective models (e.g., through distributed gradient descent).

To address the privacy of locally held data, the concept of local differential privacy (LDP) [15, 34] is more appropriate. In LDP, each client individually randomizes its interactions with the untrusted server. LDP mechanisms have been deployed by companies such as Google [23], Apple [29], and Microsoft [14]. However, LDP mechanisms often suffer from poor performance compared to centralized DP mechanisms, limiting their applicability [15, 31, 34].

To improve privacy-utility trade-offs, the shuffle model [7, 13, 22] has been proposed. In this model, each client sends its randomized interaction message to a secure shuffler, which randomly permutes all received messages before forwarding them to the server. This anonymization technique significantly enhances privacy-utility performance by amplifying LDP.

For repeated interactions, privacy composition [9] is essential. Composition theorems quantify the overall privacy budget under multiple iterations. Advanced composition theorems [19, 33] can be loose, so Abadi et al. [1] developed the "moments accountant" framework, providing tighter composition results. This framework uses Rényi Differential Privacy (RDP) [36] and maps it back to the DP guarantee [37], offering significant savings in the total privacy budget.

Analyzing the RDP of the shuffle model has several applications, including private statistics, mean estimation, federated learning, and distributed differentially private stochastic gradient descent (DPSGD). This leads to the central question of this paper: Can we develop strong RDP privacy guarantees for general local mechanisms in the shuffle privacy model?

## 2 Preliminaries and Problem Formulation
### 2.1 Privacy Definitions
We define the following privacy notions:
- **Local Differential Privacy (LDP) [34]:** A randomized mechanism \( R : X \to Y \) is said to be \( \epsilon_0 \)-LDP if for every pair of inputs \( d, d' \in X \),
  \[
  \Pr[R(d) \in S] \leq e^{\epsilon_0} \Pr[R(d') \in S] \quad \forall S \subseteq Y.
  \]

- **Central Differential Privacy (DP):** A mechanism \( M \) satisfies \( (\epsilon, \delta) \)-DP if for all neighboring datasets \( D \) and \( D' \) differing in one element,
  \[
  \Pr[M(D) \in S] \leq e^{\epsilon} \Pr[M(D') \in S] + \delta \quad \forall S \subseteq \text{Range}(M).
  \]

- **Rényi Differential Privacy (RDP) [36]:** A mechanism \( M \) satisfies \( (\alpha, \epsilon) \)-RDP if for all neighboring datasets \( D \) and \( D' \),
  \[
  D_\alpha(M(D) \| M(D')) \leq \epsilon,
  \]
  where \( D_\alpha \) is the Rényi divergence of order \( \alpha \).

### 2.2 Existing Results and Problem Formulation
We review existing results on RDP to DP conversion and RDP composition. Our goal is to derive RDP guarantees for general discrete local randomizers in the shuffle privacy model and compare these guarantees with state-of-the-art approximate DP guarantees.

## 3 Main Results
### 3.1 Upper Bounds on RDP
We provide two upper bounds on the RDP of the shuffle model. Given an arbitrary discrete local mechanism with \( \epsilon_0 \)-LDP, we derive an RDP guarantee as a function of \( \epsilon_0 \) and the number of users \( n \). This can be seen as an amplification by shuffling result, converting pure LDP to RDP.

### 3.2 Lower Bound on RDP
We also develop a lower bound for the RDP of the shuffle model and show that the gap between the upper and lower bounds is small for many parameter regimes of interest.

### 3.3 Proof Sketch
#### 3.3.1 Reduction to Special Structure
We reduce the problem of computing RDP for arbitrary pairs of neighboring datasets to computing RDP for special pairs of neighboring datasets. Specifically, we write the output distribution of the local randomizer as a mixture distribution and use this to concentrate the number of clients sampling according to a specific distribution.

#### 3.3.2 Analysis for Special Structure
For neighboring datasets with a special structure, we observe that the output distribution of the shuffling mechanism is multinomial. Using this, we show that the ratio of the distributions is a sub-Gaussian random variable, and we bound the moments of this variable to obtain an upper bound on the RDP.

## 4 Numerical Results
We present numerical results demonstrating the advantages of our RDP bounds over the state-of-the-art approximate DP guarantees. For example, with \( T = 10^5 \), \( \epsilon_0 = 0.5 \), and \( n = 10^6 \), our bound saves a factor of 8× compared to the state-of-the-art approximate DP guarantee combined with strong composition. Combining with Poisson subsampling, our result leads to at least a 10× improvement in privacy guarantee.

## 5 Full Proofs
The full proofs of our main results are provided in the following sections:
- **Section 5:** Reduction to the special case.
- **Section 6:** Proof for the special case.
- **Section 7:** Proof of both upper bounds.
- **Section 8:** Proof of the lower bound.

## 6 Conclusion
We conclude with a discussion of our results and potential future work. Omitted details from the proofs are provided in the appendices.