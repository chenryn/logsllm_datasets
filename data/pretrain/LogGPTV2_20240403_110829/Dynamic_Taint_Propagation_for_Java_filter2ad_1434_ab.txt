not properly validated, it could be used to construct 
a malicious SQL query. 
•  Cross-site  scripting  (also  called  output  attacks) 
[11]:  a  maliciously  crafted  URL  can 
insert 
executable  scriptable  content  into  a  dynamically 
generated webpage. Thus, a user may unknowingly 
execute scripts when she visits a URL given to her. 
This  script  could  leak  local  data,  or  redirect 
information  to  a  malicious  server  rather  than  the 
original  host  of  the  webpage.  Typically,  such 
malicious  URLs  are  found  in  spam  emails.  When 
clicked,  the  malicious  script  is  executed.  The 
underlying problem is that the URL, which is also a 
form  of  untrusted  user  input,  is  not  properly 
validated.  The  earlier  example  of  a  malicious 
message  on  a  web  forum  also  falls  under  this 
category. 
•  Hidden  Field  Tampering:  websites  often  use 
hidden  fields  to  communicate  persistent  session 
data  such  as  user  ID,  pricing  information  etc.  The 
problem is that very often the value of these hidden 
fields is not properly validated at the server end. If 
these fields are tampered with, they could be used 
for malicious purposes, such as buying items for a 
price other than that published, or forging identities. 
•  Cookie  Poisoning:  malicious  data  is  inserted  into 
cookies  that  are  used  by  the  web-application.  For 
example,  often  a  website  will  skip  authentication 
based  on  data  stored  in  a  cookie.  If  the  cookie  is 
modified,  it  could  be  used  to  present  a  forged 
identity to a website. 
Of the above attacks, command injection, field tampering and 
cookie  poisoning  are  attacks  on  the  hosting  server.  Cross  site 
scripting,  on  the  other  hand,  targets  clients  that  use  web-
applications.  Note  that  though  all  these  attacks  use  different 
avenues  of  attack,  the  root  cause  of  all  of  them  is  improperly 
validated user input.  
3. 
TAINTEDNESS 
DYNAMICALLY TRACKING 
In  order  to  track  tainted  user  input,  we  need  to  specify  the 
following: 
• 
• 
• 
Sources:  A  source  is  a  method  that  returns  user 
input.  Usually  these  are  methods  that  get  HTML 
form input, or read cookies stored on the client, or 
parse HTTP parameters. All strings emanating from 
sources must be marked tainted. 
Propagation:  Strings  from  sources  are  usually 
manipulated  to  form  other  strings  such  as  queries, 
or  scripts,  or  filesystem  paths.  Strings  that  are 
derived from tainted strings also need to be marked 
tainted. 
Sinks:  A  sink  is  a  method  that  consumes  input  or 
derivative of user input. This includes methods that 
execute some form of code (such as a script or SQL 
query), or methods that output data (such presenting 
a  new  HTML  page).  Tainted  strings  must  be 
prevented from being used as parameters to sinks. 
Sources  and  sinks  need  to  be  specified  once  per  library  or 
framework that a web application uses1. For our benchmarks, we 
needed to specify sources and sinks for the J2EE library. 
To track the taintedness of strings, we associated a taint flag 
with every string. This taint flag is set when a string is returned by 
a source method. We propagate this taint flag to strings that are 
derived  from 
through  operations  such  as 
concatenation, case conversion etc. 
tainted  strings 
1 We adopt the terms “source” and “sink” from [1].  
3.1 
UNTAINTING  
Once we have a mechanism to mark strings tainted, we also 
need  a  way  to  untaint  strings.  This  is  needed  because  in  the 
absence  of  a  way  to  untaint  strings,  all  strings  that  are  derived 
from  tainted  strings  will  still  be  marked  tainted.  This  includes 
• 
The weakest option is to let tainted data be used as 
an  argument  to  a  sink,  but  make  a  full  log  of  the 
arguments,  the  sink,  and  the  path  the  tainted  data 
took from source to sink. This seems insecure, but 
is  useful  when  auditing,  doing  penetration  testing, 
debugging, or if used in a honeypot. 
Unvalidated user-provided string
Unvalidated user-provided string
Unvalidated user-provided string
Tainted flag
Tainted flag
Tainted flag
Internet
Internet
Internet
Internet
Internet
Internet
“…where NAME=…”
“…where NAME=…”
“…where NAME=…”
true
true
true
“some string”
“some string”
“some string”
String.concat(_,_)
String.concat(_,_)
String.concat(_,_)
Concatenated string
Concatenated string
Concatenated string
true
true
true
String derived from 
String derived from 
String derived from 
tainted string is still 
tainted string is still 
tainted string is still 
tainted
tainted
tainted
String.match(_,_)
String.match(_,_)
String.match(_,_)
Result of regex match
Result of regex match
Result of regex match
false
false
false
Checked string is 
Checked string is 
Checked string is 
considered untainted
considered untainted
considered untainted
Figure 2: Overview of tainting and untainting 
strings  that  have  been  put  through  a  sanitizing  procedure  and 
should not be marked tainted anymore. 
The problem is to determine which procedures are sanitizing 
procedures. Since our technique applies transparently to existing 
Java  bytecode,  we  have  no  programmer  input  telling  us  which 
methods sanitize and validate user input. Thus, we have to use a 
heuristic to determine this. Choosing this heuristic is one of our 
major design decisions. 
We  assume  that  methods  of  java.lang.String  that 
perform  checking  and  matching  operations  are  used  to  untaint 
strings.  For  example,  a  tainted  string  that  is  passed  through  a 
regular  expression  match,  or  been  tested  for  the  presence  of  a 
particular character is not tainted anymore. Note that here we trust 
the  programmer  to  have  performed  a  meaningful  check  that 
accounts for all cases that might be exploitable in an attack. It is 
entirely  possible  that  the  programmer  wrote  a  faulty  input-
validation  routine  that  lets  through  user-input  strings  with 
malicious content in them. 
3.2 
DEALING WITH TAINT ERRORS 
A  taint  error  occurs  when  a  tainted  string  gets  used  as  an 
argument  for  a  sink  method.  When  this  happens,  we  could  take 
one of a number of actions: 
• 
Raise  a  Java  exception  indicating  a  runtime  taint 
error:  Since  this  is  an  exception  the  application  is 
unaware  of,  this  particular  exception  will  not  be 
caught,  but  if  the  application  has  a  mechanism  to 
deal  with  unknown  runtime  exceptions,  it  may  be 
able to recover. In any case, tainted data will not be 
allowed into a sink. 
• 
Abandon  the  particular  session  that  caused  a  taint 
error. 
4. 
IMPLEMENTATION AND RESULTS 
We  have  implemented  our  taint  propagation  scheme  for  the 
Java Virtual Machine, and tested it on a number of applications. 
Our  implementation  is  independent  of  the  particular  JVM  being 
used. We use bytecode instrumentation, and use Javassist [6] for 
this. 
Our implementation needs to do the following: 
• 
Specify sources and sinks. 
•  Mark strings emanating from sources as tainted. 
• 
Propagate taintedness of strings. 
•  Mark strings untainted according to our heuristic. 
•  Raise an exception when a tainted string is used as 
an argument to a sink method. 
The way we specify sources and sinks is straightforward. We 
simply list out every source method (say  Form.getValue()) 
in a text file, one per line. We do the same for sink methods. 
We instrument the java.lang.String class to propagate 
taintedness information, as well as untaint strings. Some methods 
are  instrumented  to  propagate  taintedness  of  strings,  whereas 
some others make strings untainted. This instrumentation is done 
once  off-line.  This  is  because  the  JVM  prohibits  the  load-time 
modification  of  system classes such as  java.lang.String. 
System  classes  must  be  loaded  by  the  primordial  system  class 
loader, while load-time instrumentation requires the installation of 
a custom class-loader.  
We instrument the java.lang.String class as follows: 
•  Add  a  boolean  field  to  the  class  that  indicates 
whether it is tainted or not 
• 
• 
Instrument all methods in the class that have some 
String  parameters  and  return  a  String,  so  that  the 
return  value  is  tainted  if  at  least  one  of  the 
parameters is tainted.  
The  above  is  done  for  all  but  a  number  of  string 
checking  and  matching  methods,  which  untaint 
data.  For  example,  foo.match(regex)  will 
untaint foo. 
Strings  are  immutable  in  Java.  The  java  compiler  compiles 
string  operations  such  as  concatenation  into  operations  on  the 
StringBuffer  class,  which  implements  mutable  strings.  For 
example, the expression 
string1 + string2 
will actually be compiled to 
(new  StringBuffer(string1)).append(string2) 
.toString() 
Because  of 
inter-conversion  between  Strings  and 
StringBuffers, 
the 
java.lang.StringBuffer  class  in  much  the  same  way  as 
the  java.lang.String  class,  by  adding  a  tainted  flag,  and 
modifying its methods to propagate taintedness.  
instrument 
this 
we 
also 
The StringBuilder class is also used internally to manipulate 
strings. It is like the StringBuffer class, except its methods are not 
thread-safe. We instrument the StringBuffer class too.  
All other classes are instrumented at load-time using a custom 
class loader, as follows: 
• 
• 
If  the  method  is  a  source:  we  mark  the  returned 
string tainted. 
If  the  method  is  a  sink:  we  check  if  any  of  its 
arguments  is  a  tainted  string.  If  so,  we  raise  an 
exception indicating a taint error. 
in 
Note  that  we  only  instrument  classes  that  have  sources  or 
sinks 
them,  and  not  all  classes.  Currently,  due  an 
incompatibility  between  the  class  loader  hierarchies  of  Javassist 
and  Tomcat  (the  servlet  container  that  executes  our  benchmark 
web applications), we are unable perform this instrumentation at 
the  time  of  class  loading.  Instead,  we  instrument  these  classes 
offline. 