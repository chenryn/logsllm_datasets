are as follows: First, they are designed with the objec-
tive of protecting the link privacy of graph data and no
dedicated node privacy protection techniques are consid-
ered. Second, to protect link privacy, the edges are per-
turbed in DP based schemes and random walk paths are
replaced by edges in the RW based scheme, both with
a nice theoretical privacy guarantee. However, after the
edge anonymization process, many data utilities, e.g., de-
gree, path length distribution, are still preserved. This
implies that, given an auxiliary graph, users are still de-
anonymizable based on several structural semantics un-
der DP and RW based schemes. Furthermore, as shown
by Narayanan et al. in [21], link privacy can be breached
after de-anonymizing the users in an anonymized graph
(we also employ the same approach to break users’ link
privacy [1]). Again, as we analyzed in Table 2, since DP
and RW based schemes cannot preserve data’s commu-
nity utility, they are resistant to NKA.
In summary, based on our analysis, state-of-the-art
anonymization schemes are still vulnerable to modern
DA attacks. The fundamental reasons are: ﬁrst, exist-
ing anonymization schemes only ensure that graph data
users are indistinguishable with respect to some struc-
tural semantics (properties). However, other structural
semantics, especially global ones, and the combinations
of multiple structural semantics can still enable effective
DA of users; and second, as one of the main objectives,
all the anonymization schemes try to preserve as much
data utility as possible. However, data utility from the
adversary’s perspective is equivalent to structural infor-
mation, which can be used along with an auxiliary graph
for conducting powerful DA attacks.
5 SecGraph
As we found when discussing existing anonymization
and DA techniques,
they all have limitations when
evaluating the techniques’ performance. For instance,
it
is still an open problem to understand the re-
sistance/vulnerability of state-of-the-art anonymization
schemes against modern DA attacks. To address this
open problem, we implement a Secure Graph data pub-
lishing/sharing (SecGraph) system.
310  24th USENIX Security Symposium 
USENIX Association
8
Raw Data(cid:25)
(cid:25)
(cid:25)n
(cid:25)o
(cid:25)i
(cid:25)t
(cid:25)a
(cid:25)u
(cid:25)l
(cid:25)a
(cid:25)v
E
Utility Module(cid:25)
(UM)(cid:25)
Anonymization(cid:25)
Module (AM)(cid:25)
De-Anonymization(cid:25)
Module (DM)(cid:25)
Anonymized(cid:25)
Data(cid:25)
Publishing(cid:25)
 Data(cid:25)
Figure 1: SecGraph: system overview.
5.1 System Overview
The overview of SecGraph is shown in Fig.1. SecGraph
consists of three main modules: Anonymization Module
(AM), Utility evaluation Module (UM), and DA evalua-
tion Module (DM). The main functions of each module
are brieﬂy summarized as follows.
AM: the main function of this module is to anonymize
raw graph data and generate anonymized data.
In this
module, we implement 11 state-of-the-art graph data
anonymization schemes, including EE based algorithms
[6], k-anonymity based algorithms and its variants [7–
11], aggregation/class/cluster based algorithms [12–14],
differential privacy based algorithms [15–17,19], and the
random walk based algorithm [20].
UM: in this module, we evaluate raw/anonymized
data’s utility with respect to the 12 graph utility metrics
and 7 application utility metrics as deﬁned in Section 2.2.
With the UM, we can determine whether the data to be
published/shared (e.g., the anonymized data) satisﬁes re-
quired utility requirements. We can also evaluate how an
anonymization algorithm preserves data utility.
DM: in this module, we implement 15 SDA algo-
rithms (all the existing SDA algorithms, to the best of
our knowledge). By this module, the security of data
to be published/shared can be evaluated with real-world
SDA attacks. More importantly, the effectiveness of an
anonymization algorithm can be examined by this mod-
ule, i.e., whether the anonymized data of an anonymiza-
tion algorithm is resistant to modern SDA attacks.
We make further remarks on SecGraph and its mod-
ules and functions as follows.
(a) From Fig.1, raw data can be published/shared in
multiple forms depending on the data owners’ require-
ments on the security/privacy and utility of the data to be
published. Each path in Fig.1 represents a data publish-
ing scenario. For instance, the path raw data → publish-
ing data means to publish the raw data directly. The path
raw data → AM → anonymized data → evaluation →
publishing data means that the raw data is anonymized
ﬁrst. Then, the anonymized data will be evaluated with
respect to utility and/or practical de-anonymizability be-
fore actual publishing. The anonymization and evalua-
tion process may be repeated several times until certain
security and utility requirements are met.
(b) To the best of our knowledge, SecGraph is
the ﬁrst implemented uniform secure graph data pub-
lishing system, which systematically and comprehen-
sively integrates state-of-the-art anonymization schemes,
DA schemes, and graph/application utility measure-
ments. The signiﬁcance of SecGraph to the graph data
anonymization and DA area lies in the following as-
pects. First, SecGraph enables data owners to conve-
niently and freely choose any modern anonymization al-
gorithm to anonymize their data. They can also em-
ploy different evaluation modules to examine whether
the anonymized data meets their security/privacy and
utility requirements. Second, SecGraph is a uniform
platform for testing and comparing different anonymiza-
tion and DA algorithms. Previously, due to the lack
of a uniform system, existing anonymization/DA algo-
rithms are often proposed and implemented on separate
platforms and different environments/settings. Conse-
quently, a number of implementation and evaluation dif-
ferences (e.g., particular assumptions, models, evalua-
tion datasets, programming, testing environments, pa-
rameter settings) limit researchers’ understanding of the
performance of existing anonymization and DA algo-
rithms in different scenarios. However, as a uniform plat-
form, SecGraph can reduce the evaluation bias caused by
implementation and testing differences as much as pos-
sible. Therefore, SecGraph allows data owners to choose
and compare the actual performance of different data
anonymization algorithms on their data and thus to make
the best decision. Additionally, SecGraph allows data
anonymization researchers to compare their anonymiza-
tion schemes to existing solutions as well as to exam-
ine their schemes’ resistance against modern DA attacks.
SecGraph also allows data DA researchers to evaluate
the performance of new DA attacks by de-anonymizing
the anonymized data of state-of-the-art anonymization
schemes. Therefore, SecGraph is helpful to both data
owners and researchers in conveniently applying exist-
ing schemes, comprehensively understanding existing al-
gorithms, and effectively developing new anonymiza-
tion/DA techniques.
(c) Besides providing a uniform platform, SecGraph
is an easily portable and extendable system. First, the al-
gorithms in SecGraph are implemented in Java and thus
it is system independent. Second, all the modules of
SecGraph are independent of each other, which means
that each module can work individually. Additionally,
as shown in Fig.1, multiple modules can also work to-
gether to perform data anonymization, utility evalua-
tion, and de-anonymizability evaluation. Third, all the
schemes/measurements within each module are indepen-
dent, which means that they can be implemented, evalu-
ated, and employed independently. Furthermore, newly
USENIX Association  
24th USENIX Security Symposium  311
9
developed anonymization/DA schemes and utility met-
rics can be easily integrated into SecGraph.
5.2 System Implementation
The implementation of SecGraph is as follows.
In the AM, we implement 11 algorithms, which cover
all the categories of state-of-the-art anonymization tech-
niques. Speciﬁcally, the implemented anonyzation algo-
rithms are naive ID removal, two EE based algorithms
Add/Del [6] and Switch [6], two k-anonymity based algo-
rithms k-DA [8] and k-iso [10], two cluster based algo-
rithms bounded t-means clustering [14] and union-split
clustering [14], three DP based algorithms Sala et al.’s
scheme [15], Proserpio et al.’s scheme [16,17], and Xiao
et al.’s scheme [19], and one RW based algorithm [20].
Note that, we do not implement all the algorithms dis-
cussed in Section 2.1 even though we cover all the cat-
egories. The implementation criteria includes represen-
tativeness, scalability, and practicality, which led us to
implement the latest, scalable, and practical schemes.
In the UM, we implemented the 12 graph utility met-
rics and 7 application utility metrics as discussed in Sec-
tion 2.2.
In the DM, we implement all the 15 SDA attacks dis-
cussed in Section 3.1. To the best of our knowledge,
these are all of the existing SDA attacks.
5.3 SecGraph-based Analysis
5.3.1 Primary Datasets
The employed datasets for evaluation are Enron, an email
network consisting of 36.7K users and .2M edges, and
Facebook, a Facebook friendship network in the New
Orleans area consisting of 63.7K users and .82M edges
[3, 4].
5.3.2 Anonymization vs Utility
In this subsection, we evaluate the utility performance
of anonymization algorithms. Due to the space limita-
tion, we do not show the evaluation results of all the
implemented algorithms. Particularly, we demonstrate
the results of Switch [6], k-DA [8], union-split cluster-
ing [14], the improved version of Sala et al.’s DP scheme
[15–17], and RW [20] which represent all the categories
of anonymization algorithms. The evaluation methodol-
ogy is that we ﬁrst anonymize the original graph by an
algorithm, and then measure how each data utility is pre-
served in the anonymized graph compared to the origi-
nal graph. Speciﬁcally, when measuring utilities Deg.,
JD, PL, LCC, CC, BC, NC, NR, Infe., RX, and RE, we
measure the cosine similarity between their distributions
in the anonymized and original graphs; when measuring
ED, GCC, and EV, we measure their ratios between the
anonymized and original graphs; and when measuring
MINS and CD, we measure their Jaccard similarity in
the anonymized and original graphs.
We demonstrate the results in Table 5. (more results
are available in [1]). The criteria for anonymization pa-
rameters settings are: (i) we follow the same/similar set-
tings as in the original works of these anonymization
schemes; and (ii) many data utilities can be preserved af-
ter anonymization. For the three graph utilities IM, SR,
and SD, we only test them on small graphs, and put the
results in [1]. We analyze the results in Table 5 as fol-
lows.
Generally, the evaluation results in Table 5 are consis-
tent with our analysis in Table 2. Most anonymization
algorithms can partially or conditionally preserve most
graph and application utilities. Therefore, most of the
anonymized data can be employed for graph analytics,
data mining tasks, and graph applications.
Among all the graph utilities, JD and GCC are the
most sensitive utilities to a graph’s structure change, and
thus they are the easiest ones to be destroyed by the
anonymization algorithms. This is because these two
utilities are very sensitive to edge changes. Even if the
degree distribution of the anonymized data remains the
same as the original data, the JD distribution and GCC
may change signiﬁcantly.
Compared to application utility, existing anonymiza-
tion algorithms are better at preserving graph utility. For
instance, most algorithms lost the RX utility and CD util-
ity. This is because most application utilities depend
on several graph utilities, e.g., the role of a user in RX
depends on that user’s degree, CC, BC, community at-
tributes, and other structural characteristics. Therefore,
application utilities are more easily affected than graph
utilities, i.e., application utilities are more sensitive to
graph’s structural changes.
No anonymization scheme is optimal in preserving ev-
ery data utility. For instance, Switch is better than k-DA
on preserving Deg. and JD while it is worse than k-DA
on preserving GCC and MINS, and DP is better than
RW on preserving LCC and GCC while it is worse than
RW on preserving Deg. Therefore, when choosing an
anonymization algorithm, it is better to take into account
the speciﬁc application. Furthermore, RW has the most
utility loss, e.g., GCC, RX, MINS, and CD, which is also
consistent with our analysis in Table 2. This is because
that the graph’s global structure is signiﬁcantly changed
in RW by replacing random walk paths with edges.
5.3.3 DA Evaluation
In this subsection, we evaluate the performance of mod-
ern DA attacks. As we analyzed before, BDK [26],
312  24th USENIX Security Symposium 
USENIX Association
10
Table 5: Utility analysis of anonymization techniques. k is the number of modiﬁed edges for Switch, and the
anonymization parameter for k-DA and Cluster, ε is the anonymization parameter for DP, t is the random walk step
for RW, m is the number of edges in the original graph, and D is the diameter of the original graph (D = 11 for Enron
and D = 6 for Facebook).
Enron
Facebook
1
5
2
Utility
1
50
5
50
5
1.02
50
5
50
300
50
2
300
50
D .05m .1m
1
1
.9988 .9166 .9990 .9934 .9617 .8616 .9871 .9964
Switch (vs. k) k-DA (vs. k) Cluster (vs. k) DP (vs. ε) RW (vs. t) Switch (vs. k) k-DA (vs. k) Cluster (vs. k) DP (vs. ε) RW (vs. t)
.05m .1m
D
1
Deg.
.9990 .9595 .9998 .9981 .9932 .9716 .9958 .9959
JD .8725 .8338 .8928 .4183 .8216 .7055 .8496 .7363 .6972 .6438 .9941 .9804 .9947 .7328 .9872 .9024 .9755 .8263 .9678 .9362
ED .9881 .9617 1.080 .9561 1.04
1.03 .9627 1.02 .9025 .9161 .8328 .9350 1.015 .9957 .9956 .9414 .9313 .9285 .8376
PL .9954 .9887 .9891 .8934 .9994 .9905 .9565 .9839 .9963 .9657 .9618 .9159 .9999 .9946 .9999
.9960 .9653 .9706 .8965
LCC .9830 .9631 .9972 .9809 .9966 .9797 .9528 .8328 .6785 .5985 .9204 .8303 .9998 .9983 .9968 .9947 .9793 .9437 .6239 .5543
GCC .8967 .8013 .9921 .9283 .9774 .9097 .7755 .4609 .3107 .5383 .5180 .2241 .9847 .9986 .9766 .9937 .9522 .8702 .2552 .0334
CC .9986 .9965 .9985 .9955 .9999 .9947 .9759 .9666 .9885 .9994
.9998
BC .9859 .9812 .9691 .9019 .9936 .9733 .8360 .7406 .9613 .9246 .9787 .9494 .9790 .9515 .9983 .9897 .9779 .9518 .9935 .9669
EV .9991 .9977 .9910 .8998 .9947 .9720 .9232 .8653 .9717 .9204 .9881 .9556 .9981 .9626 .9999 .9996 .9977 .9911 .9891 .9480
NC .9984 .9962 .9999 .9991 .9996 .9956 .9977 .9596 .9042 .9028 .9995 .9986
.9987 .9934 .9928 .9942
NR .9968 .9917 .9988 .9599 .9998 .9962 .9782 .8591 .9313 .8695 .9990 .9990 .9990 .9990 .9990 .9990 .9990 .9990 .9990 .9990
.9627 .9597 .9604 .9411 .9427 .9413 .9662 .9593 .9664 .9446 .9748 .9704 .9758 .9695 .9730 .9719 .9730 .9699 .9788 .9778
Infe.
PR .9980 .9962 .9848 .8934 .9997 .9974 .9801 .9000 .8925 .9942 .9866 .9825 .9878 .9610 .9900 .9907 .9875 .9691 .9869 .9810
HS .9991 .9977 .9910 .8998 .9947 .9720 .9232 .8653 .9717 .9204 .9326 .8780 .9711 .9789 .9648 .9625 .9626 .9322 .9283 .8655
AS .9991 .9977 .9910 .8998 .9947 .9720 .9232 .8653 .9717 .9204 .9920 .9656 .9946 .9498 .9978 .9986 .9970 .9965 .9943 .9594
RX .6575 .6009 .4561 .3173 .4512 .3685 .4196 .4116 .2955 .2680 .3494 .2608 .2974 .3139 .3902 .4652 .3483 .3134 .3250 .2772
RE .9997 .9997 .9999 .9954 .9999 .9996 .9994 .9985 .9994 .9990 .9999 .9997
.9996 .9999 .9997
MINS .7578 .6486 .9639 .9026 .9898 .9297 .7292 .3272 .1815 .1645 .6085 .4419 .9426 .9251 .9240 .9184 .8483 .7768 .2480 .1893
CD .6251 .5411 .8454 .5339 .6794 .6692 .5095 .1028 .2531 .0569 .3536 .1986 .5043 .5887 .8558 .8523 .5027 .3213 .2860 .1205
.9999
.9999
.9998
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
RST [5], and RSM [5] are not scalable/practical; NSR
[21] and DeA [25] are simpliﬁed versions of NS [2] and
ADA [25], respectively; and NKA [22] actually depends
on other attacks, e.g., NS. Therefore, here, we focus
on evaluating the seven general, practical, and scalable
DA attacks: NS [2], DV (we replace its seed identiﬁca-
tion phase with a scalable one) [5], PFG [23], YG [27],
ADA [25], KL [24], and JLSB [3]. Furthermore, PFG
and JLSB are seed-free and the other ﬁve attacks are
seed-based.
First, employing the same Enron and Facebook
datasets as before, we evaluate the DA performance of
the seven DA attacks. The evaluation methodology is
generally the same as in previous works [2, 3, 5, 22, 23,
25, 27]: we ﬁrst randomly sample two graphs with prob-
ability s from the original data as the anonymized graph
and auxiliary graph respectively, and then employ the
auxiliary graph to de-anonymize the anonymized graph.
Furthermore, for seed-based attacks, e.g., NS, DV, YG,
ADA, and KL, we feed them 50 pre-identiﬁed seed map-
pings. The DA performance of the evaluated attacks with
respect to different s is shown in Table 6. From Table 6,
we have the following observations.
With the increase of s, more users can be successfully
de-anonymized under each algorithm. The reason is ev-
ident. Since a large s implies that the anonymized graph
and the auxiliary graph are more structurally similar,
more accurate structural information can be employed by
all the SDA algorithms. Hence, better DA performance
can be achieved.
Generally, all the algorithms have their advantages in