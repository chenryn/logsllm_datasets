ternatively, A could also fabricate the context measurement
C∗
A by building a model of the context X by using several
earlier measurements CA made in the target context X.
In earlier works, context-based co-location veriﬁcation has
been based on direct measurements of contextual values
in diﬀerent modalities. For example, the acoustic environ-
ment [5, 15], ambient light [5], atmospheric gases, temper-
ature, humidity and air pressure [14], as well as WiFi [16],
569Bluetooth and GPS [15], have been investigated as modali-
ties for contextual proofs of presence.
In their recent work, Truong et al. have found that the
sets of WiFi and Bluetooth devices observed in a particular
context along with their received signal strengths provide
good performance in co-location veriﬁcation [15]. We there-
fore decided to investigate WiFi and Bluetooth as the basic
modalities for PoPs and tested whether PoPs based on Blue-
tooth or WiFi are vulnerable to the context guessing attack.
The authors of [15] kindly provided us the dataset they used
for their experiments so that we could make a direct com-
parison with their results. Note, however, that their usage
scenario relates to zero-interaction authentication (ZIA) set-
tings, where the attack model is diﬀerent: their co-location
veriﬁcation is intended to protect against relay attacks in
a setting where the prover and the veriﬁer can mutually
trust each other. In contrast, in our scenario the potential
attacker is a malicious prover, rather than the threat of a
relay attack.
3.1 Attack Implementation
In our implementation, V uses a classiﬁcation model to
distinguish between co-located and non-co-located context
measurements. V trains his classiﬁcation model with a be-
nign dataset containing examples of co-located and non-co-
located measurement pairs. To test the model’s performance
against context guessing attacks, we construct an attack
dataset where benign veriﬁer V measurements are paired
by measurements that could have been fabricated by A by
replaying all measurements from the same context that were
made 6 to 24 hours earlier.
From the measurement pairs, V calculates a set of fea-
tures that represent diﬀerent distance measures between the
measurements and combines them to feature vectors. Fea-
ture vectors calculated based on the benign dataset are used
to train the classiﬁcation model, whereas features from the
attack dataset are used as testing data to evaluate the classi-
ﬁer’s performance against the context guessing attack. The
classiﬁcation algorithm used is Multiboost in combination
with J48 Graft as the base learner. We used the Weka data
mining suite [6] to execute our experiments.
For training the classiﬁer we used the following features:
Feature 1
(Jaccard distance).
|CV ∩CP |(cid:88)
Feature 5
(Sum of squared rank differences).
ρδ(CV , CP ) =
(rank (mP
i ) − rank (mV
i ))2
(5)
i=1
i and
in CP and CV , respectively, sorted in ascending order.
i ) denote the ranks of mP
i ) and rank (mV
where rank (mP
mV
i
3.2 Datasets
To evaluate the feasibility of context guessing attacks,
we used two datasets: the zero-interaction authentication
dataset by Truong et al., and the ConXPoP dataset, which
we collected to test context guessing attacks and counter-
measures against it. The ZIA dataset was primarily used
to demonstrate the feasibility of the attack, whereas the
ConXPoP dataset contains more context modalities and an
explicit context labeling which we used to examine possible
countermeasures against the context guessing attack.
ZIA Dataset used in [15] contained measurements of the
MAC addresses of visible Bluetooth devices and WiFi access
points and their received signal strengths, simultaneously
collected from two devices. The dataset contained a total
of 2302 sample pairs, out of which 1140 were such that the
devices were co-located, and 1162 pairs were samples from
non-co-located devices. We used this dataset to derive fea-
tures to train the benign dataset for training the classiﬁca-
tion model of the veriﬁer V . As a baseline, we examined the
classiﬁer’s performance on the benign dataset using 10-fold
cross-validation, and could corroborate the results of [15],
obtaining a false positive (FP) rate of 2.5 % for Bluetooth
features and 1.6 % for WiFi features.
The attack dataset simulating context replay attacks was
constructed by remapping the experiments in ZIA dataset
by pairing measurements that were made in the same lo-
cation, but at diﬀerent times. The ZIA dataset contained
ground truth labels telling whether measurement pairs were
co-located or not, but the actual location in which the mea-
surements had been made was not included in the dataset.
Therefore we had to use the set of observed WiFi access
points associated with each measurement as representing the
location in which the measurement had been made.
To obtain a criterion by which to decide whether mea-
surements made at diﬀerent times were made at the same
location, we compared the co-located measurement pairs to
the non-co-located ones in the ZIA dataset and observed
that a Jaccard distance value of 0.9 for the sets of observed
WiFi devices provided a good separation between co-located
and non-co-located measurement pairs. We therefore con-
cluded that if the Jaccard distance of two measurements is
less than 0.9, we can assume that these measurements were
made in the same location.
We then paired each experiment measurement with such
measurements for which the Jaccard distance between the
sets of WiFi measurements was below 0.9, i.e., that were
made in the same location, but at a diﬀerent time.
ConXPoP Dataset data collection was done using a
purpose-built app running on Android smartphones given
out to study participants. The app continuously measured
contextual parameters and periodically uploaded them to a
server for oﬀ-line data analysis. The collected data included
link layer identiﬁers and observed signal strengths for WiFi
and Bluetooth devices in proximity (sampled once a minute),
(1)
(2)
(3)
Jδ(CV , CP ) = 1 − (cid:107)CV ∩ CP(cid:107)
(cid:107)CV ∪ CP(cid:107) ,
Feature 2
(Mean of Hamming distance).
i − mV
i |
i=1,2,...,n |mP
Hδ(CV , CP ) =
n
Feature 3
(Euclidean distance).
Eδ(CV , CP ) =
i − mV
i )2
(mP
i=1,2,...,n
(cid:80)
(cid:115) (cid:88)
(cid:80)
Feature 4
(Mean exponential of difference).
i=1,2,...,n e|mP
i −mV
i |
Ξδ(CV , CP ) =
i ∈ CV and mP
(4)
i ∈ CP denote the individual el-
where mV
ements of the context measurements of the veriﬁer V and
prover P , respectively.
n
570as well as a continuous trace of the ambient noise level and
luminosity, as observed by the smartphone’s sensors.
Participants included volunteers from the research lab staﬀ
sharing nearby oﬃces and visiting the same lunchtime res-
taurant. This enabled the participants to provide a rich
dataset of co-located measurements arising from natural ev-
eryday situations.
All participants were informed in writing about the pur-
pose, goals and content of the data collection campaign be-
forehand. Participants were free to stop or interrupt data
collection at any point by disabling the data collection app.
All participants were also given the possibility to revoke
their participation in the experiment by demanding the data
collected by them to be deleted.
Participants were asked to provide, via the user interface
of the app, information about particular contexts that they
were visiting (e.g., Home, Oﬃce, Restaurant, etc.)
and
which other participant devices were co-located with the
user’s own context collector device. Devices of other partic-
ipants were identiﬁed using easily recognizable nicknames.
Participants were asked to mark only such other devices as
co-located that were likely to be present in the same room
with the user for the following two minutes.
Furthermore, in order to obtain examples of co-located ob-
servations from contexts where typically only one test partic-
ipant is present (e.g. the test participants’ homes), each test
participant was provided with two context collector devices:
a main device and an “alter ego” device. By bringing the
alter ego device together with the main device to contexts
that no other test participants visited, users could provide
co-located context samples also from such contexts.
During a data collection period of 10 days, participants
generated a total of 5602 annotated co-located context mea-
surement pairs. Using these data, we constructed for each
participant a benign dataset and an attack dataset. The be-
nign dataset for training each user’s co-location classiﬁer was
constructed by pairing measurement pairs marked as being
co-located by the user or some other user with a roughly
equal amount of measurement pairs that were not marked
as co-located.
The attack dataset was constructed by letting one par-
ticipant at a time act as the veriﬁer V . For each veri-
ﬁer observation CV (t) made in a named context X (where
X ∈ {“Home”, “Oﬃce”, “Restaurant”}), potential attacker
observations CA(t − k) made in the same context X were
selected allowing all participants to take the role of the ma-
licious prover A. We selected k to be 6 to 24 hours.
3.3 Results
We evaluated both the ZIA dataset and the ConXPoP
dataset by training classiﬁers with the benign datasets and
using the attack datasets as testing datasets. As a baseline
to compare against, we used 10-fold cross-validation of the
training dataset. Table 1 shows the results.
The diﬀerences of the attack scenarios to the benign data-
set results are clear, showing the eﬀect of the context guess-
ing attack. For both ZIA and ConXPoP attack datasets, the
FP rate increases signiﬁcantly in comparison to the benign
dataset results. This diﬀerence is especially clear for the ZIA
dataset. For the ConXPoP dataset, the change is somewhat
smaller, due to the higher FP rate in the benign dataset.
This is caused by the more challenging experimental set-
up in comparison to the ZIA dataset. Whereas in the ZIA
Table 1: Results of the context guessing attacks
Dataset
BT
WiFi
BT+WiFi
FP Rate
ZIA benign
ConXPoP benign
ZIA attack
Increase in FP rate
ConXPoP attack
Increase in FP rate
11.0%
9.3%
2.5%
14.2%
35.1%
+32.6%
21.9%
23.5%
+7.7% +15.0% +14.2%
26.0 %
dataset, co-located and non-co-located samples were more
clearly separated from eachother, the ConXPoP set up was
more ambiguous. The criterion for co-location was that we
regard any devices in the same room to be co-located, other
devices not1. However, in the oﬃce context, test partici-
pants used oﬃce rooms next to one another, so that their
devices were not co-located according to the above crite-
rion, but still the devices shared some common WiFi and
Bluetooth environment. This makes it more diﬃcult for the
classiﬁer to make a clear distinction between co-located and
non-co-located observations, resulting in a higher False Pos-
itive rate also in the benign dataset.
However, we see that for both datasets, the context guess-
ing attack yields a False Positive rate of 22% to 35%2. This
gives an attacker a chance of at least one out of ﬁve to suc-
ceed in a context replay attack, showing that in settings
where the prover cannot be trusted by the veriﬁer, context
measurements alone cannot provide the basis for a reliable
proof of presence. The veriﬁer needs also to have the possi-
bility to assess how large the risk of a guessing attack asso-
ciated with a PoP is.
4. HARDENING CONTEXT-BASED PROOFS
We introduce two countermeasures for hardening context-
based proofs-of-presence against context guessing attacks.
The ﬁrst countermeasure aims at identifying such PoPs that
are potentially easy to guess. We do this by estimating the
entropy associated with a particular PoP. This estimation
is based on the notion of surprisal, i.e., the self-information
associated with a particular context observation of the ver-
iﬁer. The notion of surprisal is closely related to entropy
but with a diﬀerence: surprisal is the uncertainty associated
with the particular outcome of a random variable, whereas
entropy measures the average uncertainty associated with a
random variable.
In our case, we consider the observed context X of V
as a random variable OX taking particular measured con-
text observations CV as its value. The surprisal associated
with a context measurement CV is therefore a measure for
the uncertainty of that particular outcome of the random
variable. We utilize this and use surprisal-based ﬁltering to
dismiss such PoPs that can be potentially easily guessed by
the attacker A, as described below in Sect. 4.1.
1This criterion for co-location was selected, since for pro-
viding ground truth information, participants needed to be
able to visually observe any co-located persons and their
associated devices.
2We do not report the false positive rates for WiFi for the
ZIA dataset, since we use the WiFi observations in the at-
tack dataset as ground truth for identifying measurements
made in the same context.
571The other countermeasure we propose aims at increasing
the entropy of PoPs in order to make context guessing in-
feasible for the attacker. In contrast to earlier approaches
for co-location veriﬁcation [5, 13, 15, 16], where short mo-
mentary snapshots of the context were used to determine
co-location, we use a longitudinal approach. By observing
the context over a longer time period and observing changes
in the context’s ambient properties like luminosity and au-
dio, we aim at extracting suﬃcient entropy from the context
to make guessing of the context impractical. This approach
is explained in Sect. 4.2.
4.1 Surprisal Filtering
Surprisal ﬁltering is based on estimating how easy it would
be for A to fabricate a PoP C∗
A that is similar enough to V ’s
context measurement CV to be accepted as genuine. The
estimate is based on proﬁling V ’s contexts and utilising the
proﬁled information to estimate the occurrence probabilities
of individual context measurements CV in a context X. Our
intuition is that the lower the occurrence probability of a
context measurement C is, the more diﬃcult it is for an
attacker A to fabricate the measurement, even if he has
monitored the context X earlier. Based on the probability
estimate of the proof, V can then reject such proofs, for
which the risk of fabrication is high.
More formally, we deﬁne surprisal ﬁltering as a function
ς : C × X → {accept, reject}, where C denotes the domain of
context measurements and X the set of V ’s known contexts.
The surprisal ﬁltering function ς maps a context measure-
ment C ∈ C observed in a particular context X ∈ X to a
ﬁltering decision accept or reject based on the surprisal value
IX (C) of the measurement in V ’s context X:
IX (C) ≥ Ithr
otherwise
(cid:40)accept
ς(C, X) =
reject
(6)
We describe the calculation of the surprisal value IX (C) in
Sect. 4.1.1. The rationale for this defense is the following:
Information representing a context is of two types. Static
information, such as the link layer addresses of WiFi access
points in an oﬃce, has a high probability of appearing in
measurements taken in that context at any time. There-
fore, an attacker who has previously visited that context is
likely to be able to fabricate a context measurement con-
taining such static information even when he is not present