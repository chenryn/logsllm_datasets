title:Crash Data Collection: A Windows Case Study
author:Archana Ganapathi and
David A. Patterson
Crash Data Collection: A Windows Case Study 
Archana Ganapathi and David Patterson 
Computer Science Division, University of California at Berkeley 
{archanag,patterson}@cs.berkeley.edu
to 
in 
to 
analysis 
improve  service  availability.  Some 
companies  extend  their  analyses  to  client  sites  by 
gathering  failure  data  at  deployment  locations.  For 
example, Microsoft Corporation collects crash data for 
their Windows operating system as well as applications 
used  by  their  customers.  Unfortunately,  due  to  legal 
concerns, corporations such as Microsoft cannot share 
their  data  with  academic  research  groups.  Companies 
do not wish to reveal their internal vulnerabilities, nor 
can 
third  party  products’  potential 
weaknesses. Consequently, while abundant failure data 
is  generated  on  a  daily  basis,  very  little  is  readily 
sharable with the research community.  
they  share 
research  machines 
This  paper  discusses  data  collection  and  analysis 
pertaining 
the  EECS 
department at UC Berkeley. Since July 2004, over 200 
machines that run Windows XP SP1 are reporting their 
crashes  to  our  server.  These  machines  operate  within 
the same domain and are rather constrained in security 
and administration; this data set can be construed as an 
imprecise representative of typical Windows computer 
usage.  For  example,  users  of  these  machines  have  a 
level  of  computer  expertise  higher  than  average 
computer  users.  To  reduce  the  skew  introduced  by  a 
single data source, and to increase variability in usage 
profile, in future we wish to consider much larger and 
more diverse population.  
The  remainder  of  this  paper  is  organized  as 
follows. Section 2 surveys related work in failure data 
analysis. The data set, collection and analysis processes 
are  explained  in  section  3  while  section  4  discusses 
revelations from our study. Section 5 presents an open-
source  design  for  collecting  failure  data  and  our 
progress 
this  effort.  Section  6  concludes  by 
discussing the benefits of such an endeavor. 
2.  Related Research 
The  past  decade  has  produced  several  studies  in 
root-cause  analysis  for  Operating  Systems  (OS) 
ranging from Guardian OS and Tandem Non-Stop UX 
OS to VAX/VMS and Windows NT [6, 8, 10, 14, 15, 
16,  17].  In  this  progression,  our  study  of  Windows’ 
crash  data  gauges  the  evolution  of  PC  reliability.  We 
compare  these  results  with  similar  information  from 
earlier  systems.    Koopman  et  al.  [9]  test  operating 
systems  against 
is 
the  POSIX  spec.  Our  study 
in 
Abstract 
it 
Reliability 
is  a  rapidly  growing  concern 
in 
contemporary Personal Computer (PC) industry, both 
for computer users as  well as product developers. To 
improve  dependability, 
systems  designers  and 
programmers must consider failure and usage data for 
operating  systems  as  well  as  applications.  In  this 
paper, we discuss our experience with crash and usage 
data  collection  for  Windows  machines.  We  analyze 
results  based  on  crashes  in  the  UC  Berkeley  EECS 
department. 
1.  Introduction 
such  unconstrained 
troubleshoot  recurring  problems, 
Modern  operating  systems  serve  as  a  confluence 
of  a  variety  hardware  and  software  components. 
However, 
flexibility  allows 
complex,  unanticipated,  and  unsafe  interactions  that 
result in an unstable environment often frustrating the 
user.  To 
is 
beneficial  to  data-mine,  analyze  and  document  every 
interaction  for  erroneous  behaviors.  Failure  data 
collection provides insight into how computer systems 
software 
behave  under  varied  hardware 
configurations.  Common  misconceptions 
about 
Windows  are  rampant.  For  example,  we  often  hear 
people  exclaim,  “the  Windows  operating  system  is 
unreliable”.  Without  concrete  data,  it  is  difficult  to 
validate  or  refute  such  claims.  Our  study  attempts  to 
shed some light on the factors affecting Windows PC 
reliability.  
From  a  research  perspective, 
the  motivation 
behind  failure  data-mining  is  multi-fold.  First,  it 
reveals  dominant  failure  causes  of    popular  computer 
systems. In particular, it identifies products that cause 
the most user-frustration, thus rekindling our efforts to 
build stable, resilient systems. Furthermore, it enables 
product  evaluation  and  development  of  benchmarks 
that  rank  product  quality.  These  benchmarks  can 
influence design prototypes for reliable systems. Most 
importantly,  such  methodology  helps  formulate  and 
address research issues in computer system reliability. 
Within  the  realms  of  an  organization,  knowledge 
of  failure  data  can  improve  quality  of  service.  Often, 
corporations  collect  failure  data  to  evaluate  causes  of 
downtime.  In  addition,  they  perform  cost-benefit 
and 
complimentary to this work as we look at actual crash 
data that results in OS unreliability. 
frequently 
failing  hardware  component 
Recently,  Murphy  [12]  deduced 
that  display 
drivers were a dominant crash cause and memory is the 
most 
in 
Windows  XP  Machines.  We  expand  on  this  work, 
evaluating application crashes in addition to Operating 
System  crashes.  We  study  actual  crash  instances 
experienced  by  users  rather  than  injecting  artificial 
faults as in the case of fuzz testing [4]. This study of 
crash data differs from error log analysis work done by 
Kalakech et al. [7] in that we can determine the cause 
of crashes and not merely time and frequency.  
Several  researchers  have  provided  significant 
insights on benchmarking and failure data analysis [2, 
3,  13,  18].  Wilson  et  al.  [18]  suggest  evaluating  the 
relationship  between  failures  and  service  availability. 
Among  other  metrics,  when  evaluating  dependability, 
system  stability is a key concern. Ganapathi et al. [5] 
examine  Windows  XP  registry  problems  and  their 
effect on system stability. Levendel [11] suggests using 
the  catastrophic  nature  of  failures  to  evaluate  system 
stability.  Brown  et  al.  [2,3]  provide  a  practical 
perspective  on  system  dependability  by  incorporating 
users’  experience  in  benchmarks.  In  our  study  of 
crashes,  we  consider  these  factors  when  evaluating 
various applications.   
3.  Data Collection and Analysis Process 
Our  data  collection  and  analysis  methodology 
closely  follows  the  guidelines  provided  in  [12].    We 
first  define  several  terms  that  we  use  throughout  the 
paper: 
loop.  The  component 
•  Application  Crash  –  A  crash  occurring  in 
user-level,  caused  by  one  or  more  components 
(.exe/.dll files), requiring an application restart. 
•  Application  Hang  –  An  application  crash 
caused as a result of the user terminating a process 
that  is  potentially  deadlocked  or  running  an 
infinite 
file 
routing)  causing  the  loop/deadlock  cannot  be 
identified  if  the  user  intervenes  to  terminate  the 
process. 
•  OS  Crash  –  A  crash  occurring  in  kernel-
level,  caused  by  memory  corruption,  bad  drivers, 
faulting  system-level  routines.  OS  crash  includes 
bluescreen-generating  crashes,  which  require  a 
machine  reboot,  as  well  as  Windows  explorer 
crashes,  which  require  restarting  the  explorer 
process. 
(.exe/.dll 
To  collect  data,  we  use  Microsoft’s  Corporate  Error 
Reporting  software.  We  configure  a  server  with  a 
shared directory that can directly receive crash reports. 
Reporting  client  machines  require  no  additional 
software.  We  simply  modify  a  few  registry  entries  to 
redirect  crash  reports  to  our  server  in  place  of 
Microsoft.  Furthermore,  we  disable  the  prompt  that 
asks  users  whether  they  wish  to  send  a  crash  report. 
Thus,  we  are  guaranteed  to  receive  reports  for  all 
crashes  and  are  not  dependent  on  the  good  graces  of 
the user to send us crash data.  
publicly 
publicly 
available 
available 
(WinDbg), 
Upon  each  crash,  a  “minidump”  is  generated  to 
contain  a  snapshot  of  the  computer’s  state  during  the 
crash.  This  information  includes  a  list  containing  the 
name and timestamp of binaries that were loaded in the 
computer’s  memory at the time of crash, as  well as a 
brief stack trace. Upon receipt of crash dumps, they are 
parsed  using  Microsoft’s  “Debugging  Tools  for 
Windows” 
at  
http://www.microsoft.com/whdc/devtools/debugging/d
efault.mspx.  We  retrieve  debugging  symbols  from 
Microsoft’s 
server 
(http://www.microsoft.com/whdc/devtools/debugging/s
ymbolpkg.mspx). Parsing crash dumps using WinDbg 
reveals 
the  crash  was 
experienced  as  well  as  the  immediate  cause  of  the 
crash  via  an  error  code  of  the  crashing  routine.  The 
drawback  of  this  approach  is  that  we  rely  on  the 
completeness  and  accuracy  of  Microsoft’s  symbols. 
Due to legal reasons, Microsoft does not make 3rd party 
symbols  available  so  we  cannot  rely  on  our  current 
tools  to  provide  an  accurate  stack  trace  for  3rd  party 
applications;  the  issue  is  that  we  may  not  accurately 
identify  the  component  causing  the  application  crash 
even thought the application  that crashed is identified 
correctly. 
the  application 
in  which 
symbol 
is 
is 
to 
likely 
likely 
the  application 
Once  crash  dumps  are  run  through  WinDbg,  the 
importance  of  filtering  data  is  evident.  When  a 
computer  crashes, 
the  application  and/or  entire 
machine  is  rendered  unstable  for  sometime  during 
which  a  subsequent  crash 
to  occur. 
Specifically, 
if  a  particular  component  of  an 
application, such as a dynamic-link-library (.dll) file is 
corrupt, 
repeatedly 
reproduce  the  error.  It  is  inaccurate  to  double-count 
subsequent  crashes 
the  same 
instability  window.  To  avoid  clustering  unrelated 
events  while  capturing  all  related  crash  events,  we 
studied the number individual crash events forced into 
clusters using various temporal windows. A 10 minute 
window  seemed  most  appropriate  for  determining 
correlated  crashes  in  our  data  set;  Crash  events 
occurring  on  the  same  machine  within  10  minutes  of 
one  another  are  treated  as  a  single  event  in  our 
analysis.  Our  data  from  EECS  is  filtered  from  1954 
crash instances to 1546 data points. 
that  occur  within 
Several additional limitations are imposed on our 
analysis due to the inherent concern regarding privacy. 
Ideally,  to  embellish  our  analysis,  we  wish  to  know 
Crash % 
Usage % 
Figure 1: Crash Cause by Application 
Category. This table depicts the relative 
frequency of crashes caused by each category of 
applications and the relative time spent using 
each category of application (based on a user 
survey conducted in the EECS department at UC 
Berkeley).  
# Crashes 
562 
247 
155 
119 
91 
84 
53 
32 
31 
27 
17 
16 
15 
9 
8 
8 
Application Category 
web browsing  
38% 
unknown  
17% 
document preparation 
11% 
email  
8% 
scientific computing 
6% 
document viewer 
6% 
multimedia  
4% 
document archiving 
2% 
code development  
2% 
remote connection 
2% 
instant messaging  
1% 
i/o  
1% 
other 
1% 
security  
1% 
system management 
1% 
1% 
database  
precisely  the  duration  of  each  application  or  process  
and the associated resource consumption. A continuous 
profile  of  the  machine’s  evolution  is  another  feature 
absent  in  the  collected  data.  For  each  machine,  it  is 
useful to collect several performance metrics, expressly 
before and during the crash. For example, it is useful to 
know  the  system  uptime,  amount  of  free  space  and 
processor  queue  length.  Such  data  can  suggest  the 
sequence of events that lead to a crash and factors and 
processes 
the  failure  progression. 
Presently, as we rely on WinDbg to parse crash dumps, 
it  is  difficult  to  study  the  context  of  each  failure  as 
third  party  executable  images  are  encoded  not  to  be 
publicly  available.  Collecting  machine  metrics  and 
process  information  will  improve  the  accuracy  of  our 
analysis process.  
4.  Windows XP Analysis Results  
influence 
that 
The  long-term  goal  is  to  create  an  up-to-date 
repository of failure data from contemporary systems. 
A  goal  of  this  analysis  is  to  answer  understand  the 
behavior  of  Windows  operating  system  for 
the 
Berkeley  environment.  Below,  we  present  analysis 
results for data from the Berkeley EECS department. 
4.1 OS crashes are few but frustrating  
OS  crashes  are  more  frustrating  than  application 
crashes as they require the  user to kill and restart the 
explorer  process  at  a  minimum,  more  commonly 
forcing  a  full  machine  reboot.  Only  72  of  the  1546 
crashes  were  caused  by  the  OS  (these  OS  crashes 
include  bluescreen-generating  crashes  as  well  as 
Windows  explorer  crashes).  The  remaining  1474 
crashes  were  due  to  applications.  55  of  these  OS 
18% 
n/a 
22% 
24% 
7% 
8% 
6% 
n/a 
10% 
n/a 
n/a 
n/a 
1% 
n/a 
4% 
n/a 
crashes  were  caused  by  Windows  explorer.  The 
remaining  17  were  due  to  blue  screens  generated  by 
various drivers operating with kernel-level capabilities. 
These drivers were related to various components such 
as  display  monitors,  network  and  video  cards. 
However, we do not yet have a significant number of 
these  OS  crashes  to  evaluate  such  components.  We 
hope  to  collect  additional  OS  crashes  using  our  crash 
collection mechanism described in section 5. 
4.2 Web browsers crash more frequently than other 
types of  applications 
Application  crashes  are  more  frequent  than  OS 
crashes  but  can  usually  be  resolved  by  restarting  the 
crashing  application.  Figure  1  shows  a  distribution  of 
crashes  by  cause.  Web  browsers  cause  a  majority  of 
crashes in our dataset. This category includes Internet 
Explorer, Netscape, Mozilla and Firefox. Perhaps one 
explanation for such a large number of browser crashes 
is  that  plug-ins  running  inside  browsers  can  cause 
crashes and the analysis tools would blame the browser 
and  not  the  plug  in  for  generating  the  crash.  Other 
major  crash-contributing  categories  include  document 
preparation  software,  such  as  MS  Word,  Powerpoint, 
and  LaTeX  as  well  as  e-mail  software  such  as  MS 
Outlook and Eudora. While a few applications caused a 
majority  of  crashes  in  each  category,  it  is  unfair  to 
judge  the  quality  and/or  reliability  of  applications 
based  solely  on  crash  count.  Some  applications  are 
exercised  more  frequently.  For  example,  Windows 
Explorer  is  invoked  more  than  occasional  multimedia 
applications. A fair evaluation requires usage statistics 
in  addition  to  crash  data.  Furthermore,  such  usage 
statistics help us identify skews in data introduced by a 
restricted subset of users. 
Web Browsing Usage
Lynx, 2%
Mozilla, 15%
Firefox, 9%
Netscape, 20%
Internet 
Explorer, 54%
Web Browsing Crashes
Mozilla, 2% (14)
Firefox, 12% 
(69)
Netscape, 27% 