5 EVALUATION
We perform empirical evaluations on the benefits of SNAP on
fuzzing metrics and answer the following questions:
• Performance. How much performance cost needs to be paid for
• Accuracy. How well can SNAP preserve traces against other
approaches of comparable CPU cycles throughout the lifetime of
processes? (§5.3)
• Effectiveness. Can SNAP increase coverage for fuzzing in a
finite amount of time? How do branch records and branch pre-
dictions provide more context-sensitive semantics? (§5.4)
• Practicality. How easy is it to support various fuzzers on SNAP?
How much power and area overhead does the hardware modifi-
cation incur? (§5.5)
Figure 6: An example of data flow approximation between two runs
leveraging the branch predictions stored in LBQ.
Approximating data flow via branch prediction. Data flow
analysis has proved to be useful for fuzzers [12, 52, 60] to mu-
tate inputs more precisely (e.g., identify the input byte that affects
a certain data-dependent branch condition). However, recent re-
search [18] points out that traditional data-flow analysis requires
too much manual effort (e.g., interpreting each instruction with
custom taint propagation rules) and is slow, making fuzzing less
effective. Surprisingly, SNAP is able to provide an approximation of
data flow without paying extra performance overhead by leveraging
the branch prediction results in the LBQ. A typical branch predictor,
such as the one used in RISC-V BOOM [7] and shown in Figure 6, is
capable of learning long branch histories and predicts the current
branch decision (i.e., taken vs. not-taken) based on the matching
historical branch sequence. Conversely, given the prediction results
of the recorded branch sequence in the LBQ, SNAP is able to infer
a much longer branch history than the captured one. Therefore, if
a mutated input byte causes a change in the prediction result of a
certain branch, the branch condition is likely related to the input
offset, thus revealing dependency between them with near-zero
cost. Since most branch conditions are data-dependent [12, 18, 59],
the prediction result thus approximates the data flow from the input
to any variables that affect the branch decision. In Figure 6, even if
the coverage map and the immediate control-flow context remain
the same, the fuzzer can still rely on the approximated data flows to
mutate further for the sequence of interest (i.e., line 13 in Figure 1)
when it is not captured by the LBQ.
4.6 OS Support
Besides the hardware modification, kernel support is also critical
for SNAP to work as expected. We generalize it into three com-
ponents, including configuration interface, process management,
and memory sharing between kernel and userspace. Rather than
testing the validity of modified OS on the hardware directly, we also
provide the RISC-V hardware emulation via QEMU [4], allowing
easier debugging of the full system.
Configuration interface. Among the privilege levels enabled by
the standard RISC-V ISA [54], we define the newly added CSRs
(Table 2) in supervisor-mode (S-mode) with constraints to access
through the kernel. To configure the given hardware, SNAP pro-
vides custom and user-friendly system calls to trace a target pro-
gram by accessing the CSRs. For example, one can gather the last-
executed branches to debug a program near its crash site by en-
abling the branch record only. Others might request dedicated
fuzzing on specific code regions or program features by setting the
while(*cur != ‘\0’){switch(*cur) {case‘S’: ...case‘L’: ...case‘T’: ...}}HistoricalBranchSequencePCPredictionTable✓✓✓✓✓✓✓✓✓✗SLLTTXORPrediction ResultBranch PredictorBranch Sequence1st2ndInput1st2ndLBQSession 7B: FuzzingCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea222175 MHz
4MB
Clock
LLC
DRAM 16 GB DDR3
Front-end
Execution
Load-store unit
32KB, 8-way
64KB, 16-way
512KB, 8-way
L1-I cache
L1-D cache
L2 cache
8-wide fetch
16 RAS & 512 BTB entries
gshare branch predictor
3-wide decode/dispatch
96 ROB entries
100 int & 96 floating point registers
24 load queue & 24 store queue entries
24 BUQ & 32 LBQ entries
Table 3: Evaluated BOOM processor configuration.
5.1 Experimental setup
We prototype SNAP on Amazon EC2 F1 controlled by FireSim [39],
an open-source FPGA-accelerated full-system hardware simulation
platform. FireSim simulates RTL designs with cycle-accurate system
components by enabling FPGA-hosted peripherals and system-level
interface models, including a last-level cache (LLC) and a DDR3
memory [8]. We synthesize and operate the design of SNAP at the
default clock frequency of LargeBoomConfig, which is applicable
to existing CPU architectures without significant design changes.
While modern commercial CPUs tend to adopt a data cache (L1-D)
larger than the instruction cache (L1-I) for performance [30, 34, 35],
we mimic the setup with the default data cache size of 64 KB for
our evaluation. In general, the experiments are conducted under
Linux kernel v5.4.0 on f1.16xlarge instances with eight simulated
RISC-V BOOM cores, as configured in Table 3. Our modified hard-
ware implementation complies with the RISC-V standard and has
been tested with the official RISC-V verification suite. The area
and power overhead of the synthesized CPU with our modifica-
tion are measured by a commercial EDA tool, Synopsys Design
Compiler [56].
We evaluate SNAP on the industry-standardized SPEC CPU2006
benchmark suite to measure its tracing overhead. We use the refer-
ence (ref ) dataset on the 12 C/C++ benchmarks compilable by the
latest RISC-V toolchain. To profile the encoding collisions, we col-
lect full traces from the benchmark as the ground truth for uniquely
executed edges before comparing with the encoded bitmaps. In par-
ticular, we enable user emulation of QEMU v4.1.1 in nochain mode
to force the non-caching of translated blocks so that the entire exe-
cution trace of each run is emitted. Meanwhile, we test AFL’s run-
time coverage increase and throughput with Binutils v2.28 [21], a
real-world collection of binary tools that have been widely adopted
for fuzzing evaluation [27, 40]. In general, we fuzz each binary for
24 hours with the default corpus from AFL in one experimental run
and conduct five consecutive runs to average the statistical noise
in the observed data.
5.2 Tracing Overhead by SNAP
We measure the tracing overhead imposed by SNAP and source in-
strumentation (i.e., AFL-gcc3) across the SPEC benchmarks. Table 4
shows that SNAP incurs a barely 3.14% overhead with the default
cache size of 64 KB, significantly outperforming the comparable
software-based solution (599.77%). While we have excluded the
3We use AFL-gcc rather than AFL-clang because LLVM has compatibility issues in
compiling the SPEC benchmarks.
Name
perlbench
bzip2
gcc
mcf
gobmk
hmmer
sjeng
libquantum
h264ref
omnetpp
astar
xalancbmk
Mean
SNAP (%)
64 KB
4.28
2.21
5.11
1.54
5.25
0.60
0.68
0.67
0.27
5.55
0.30
11.26
3.14
128 KB
4.20
2.10
4.97
1.54
4.92
0.54
0.52
0.44
0.07
5.37
0.30
11.11
3.00
32 KB
7.63
2.32
7.85
1.75
16.92
0.72
7.29
0.80
10.37
13.88
0.37
21.24
7.59
AFL-gcc (%)
690.27
657.05
520.81
349.83
742.98
749.56
703.44
546.67
251.56
452.89
422.96
1109.24
599.77
Table 4: Tracing overhead from AFL source instrumentation and
SNAP with various L1-D cache sizes across the SPEC benchmarks.
Name
Agg. Rate (%)
perlbench
bzip2
gcc
mcf
gobmk
hmmer
sjeng
libquantum
h264ref
omnetpp
astar
xalancbmk
Mean
3.32
13.67
25.14
7.83
8.78
1.36
5.24
41.60
16.23
4.69
3.77
30.04
13.47
L1 Cache Hit Rate (%)
Base
97.82
91.80
68.53
44.45
95.51
95.80
98.44
53.97
96.67
82.10
87.39
82.94
82.95
SNAP
96.49
91.32
67.42
43.89
91.81
95.64
96.18
53.24
95.89
79.68
87.09
77.17
81.32
∆
-1.33
-0.47
-1.11
-0.56
-3.70
-0.17
-2.26
-0.73
-0.78
-2.42
-0.30
-5.77
-1.63
Table 5: Memory request aggregation rates and L1 cache hit rates
between the baseline and SNAP across the SPEC benchmarks.
numbers for DBI solutions (e.g., AFL QEMU mode), the resulting
overhead is expected to be much heavier than source instrumenta-
tion, as explained in §3. The near-zero tracing overhead of SNAP
results from its hardware design optimizations, including oppor-
tunistic bitmap update and memory request aggregation (§4.3).
Table 5 shows that the bitmap update requests have been reduced
by 13.47% on average thanks to aggregation. In the best case, the re-
duction rate can reach above 40%, which effectively mitigates cache
contention from frequent memory accesses (e.g., array iteration)
and avoids unnecessary power consumption.
Further investigation shows that the performance cost of SNAP
might also result from cache thrashing at the L1 cache level. In
general, applications with larger memory footprints are more likely
to be affected. Since bitmap updates by the BUQ are performed in
the cache shared with the program, cache lines of the program data
might get evicted when tracing is enabled, resulting in subsequent
cache misses. Note that this problem is faced by all existing fuzzers
that maintain a bitmap. For instance, Table 5 points out that gobmk
and xalancbmk both suffer from comparably higher overhead (≥ 5%)
caused by reduced cache hit rates of over 3.5%. The impact of cache
thrashing can also be tested by comparing the tracing overhead of
SNAP configured with different L1 D-cache sizes. Table 4 shows
that a larger cache exhibits fewer cache misses and can consistently
introduce lower tracing overhead across benchmarks. In particular,
the overhead can be reduced to 3% on average by increasing the
Session 7B: FuzzingCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2222(a) perlbench
(b) bzip2
(c) gcc
(d) mcf
(e) gobmk
(f) hmmer
(g) sjeng
(h) libquantum