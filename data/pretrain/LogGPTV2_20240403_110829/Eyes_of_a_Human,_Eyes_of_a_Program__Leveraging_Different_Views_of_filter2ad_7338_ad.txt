ﬂagged 1,833 pages as malicious. Based on manual analysis of these instances, we
conﬁrmed 1,746 cases as true positives (ﬁrst line): a signiﬁcant increase from the
95 detected by the content obfuscation heuristic (Table 2) and the 400 detected
by the seal-counterfeiting one; the remaining 87 ﬂagged pages were incorrect
4 If desired, each match mi could also be enlarged by a percentage to achieve extra
resiliency against the insertion of random “stopping” words in the middle of an
otherwise matching page section.
5 We used a procedure similar, in its principle, to the one employed in Section 4.5:
Pages from the Alexa feed were all marked as benign, then a well-scoring threshold
value was computed for each cluster. Again, those known-benign pages are used to
get a rough estimate of the amount of false positives that each given value would
cause. A linear search is then used, starting from a low threshold value and increasing
it until the false positive rate surpasses a certain percentage: 2%, in our case. We
protect from possible outliers in the Alexa feed by requiring the presence of at least
three of its samples before the search is terminated. While this procedure requires a
sizable number of benign samples, it is applicable in many cases: such samples are
easily gathered from widely-available rankings or website directories.
Eyes of a Human, Eyes of a Program
145
detections of benign pages (second line). As anticipated in Section 3, negatives
are expressed as conﬁdence intervals (lines three and four, and dependent scoring
values in the remaining lines).
Table 4. Performance of the proof-of-concept detector
True positives (ﬂagged, malicious)
False positives (ﬂagged, benign)
True negatives (not ﬂagged, benign)
False negatives (not ﬂagged, malicious)
Precision
Recall
F1 score
True positive rate
False positives rate
1, 746
87
47, 524 ± 192
643 ± 192
95.25%
73.08 ± 5.86%
82.69 ± 3.75%
73.08 ± 5.86%
0.18 ± 0.00%
True positives included pharmacy scams from several diﬀerent campaigns
or sellers and many fake-AV variants, underlining how the ﬁndings from these
heuristics generalize well and improve detection (most scam campaigns, for in-
stance, were not originally marked as suspicious or malicious by Wepawet). Ex-
amples of false negatives are posts on hijacked forums that contained relatively
little malicious content, or scams that signiﬁcantly diﬀered from the samples
found by our two simple heuristics. For cases where the samples were related
(although quite diﬀerent and possibly originating from diﬀerent criminal opera-
tions), our system showed excellent detection.
While not enough to create a complete security system, these results conﬁrm
our intuition that detection of this “view diﬀerence” (even in the two simple
heuristic forms we presented) can be a useful addition to many analyzers. As an
example, referring to Table 1, a honeyclient or exploit-based detector is unlikely
to catch the (otherwise very common) scam campaigns without a method such
as ours.
Finally, we note that even just removing content obfuscation and counterfeit
certiﬁcations from the fraudsters’ tool arsenal could be a desirable result in itself.
In fact, a general property of heuristic like ours is that they present attackers
with a problematic choice: from their point of view, if they choose to exploit the
diﬀerence between the two “worlds” of programs and humans they risk giving
away the nature of their operation (and possibly uncover other similar scams).
Presenting the same information to humans and programs, on the other hand,
will make it easy for security researchers to construct reliable signatures for the
malicious campaign and quickly reduce its impact.
7 Conclusions
In this paper we pointed out how the discrepancy between the understanding of
a human and a program can present both a danger (as a way for cybercriminals
146
J. Corbetta et al.
to escape analysis) and a maliciousness-detection opportunity at the same time.
We presented two heuristics that detect cases that exemplify this situation: one
directed toward textual content and one involving images, respectively counter-
ing the deception of static analyzers and of human beings.
Envisioning that these detection methods can complement existing detection
tools, we have implemented a proof-of-concept detector based exclusively on
these methods to discover online malicious pages. This tool alone was able to
achieve a 95% precision and a 73% recall in our dataset, and was able to discover
a high number of human-directed fraud pages that would otherwise be outside
the detection capabilities of most traditional malware analyzers.
Acknowledgments. We would like to thank Davide Paltrinieri for his help and
ABBYY for providing the OCR software.
This work was supported by the Oﬃce of Naval Research (ONR) under Grant
N000140911042, the Army Research Oﬃce (ARO) under grant W911NF0910553,
and Secure Business Austria. Any opinions, ﬁndings, and conclusions or recom-
mendations expressed in this publication are those of the authors and do not
necessarily reﬂect the views of the Oﬃce of Naval Research, the Army Research
Oﬃce, or Secure Business Austria.
References
1. Anderson, D.S., Fleizach, C., Savage, S., Voelker, G.M.: Spamscatter: Characteriz-
ing Internet Scam Hosting Infrastructure. In: Proceedings of the USENIX Security
Symposium (2007)
2. Barth, A., Caballero, J., Song, D.: Secure Content Sniﬃng for Web Browsers, or
How to Stop Papers from Reviewing Themselves. In: Proceedings of the 30th IEEE
Symposium on Security and Privacy. IEEE (2009)
3. Bate, R., Jin, G., Mathur, A.: In Whom We Trust: The Role of Certiﬁcation
Agencies in Online Drug Markets. NBER working paper 17955 (2012)
4. Bergholz, A., Paass, G., Reichartz, F., Strobel, S., Moens, M.F., Witten, B.: De-
tecting Known and New Salting Tricks in Unwanted Emails. In: Proceedings of the
Conference on Email and Anti-Spam, CEAS (2008)
5. Chou, N., Ledesma, R., Teraguchi, Y., Mitchell, J.C.: Client-side Defense Against
Web-Based Identity Theft. In: Proceedings of the Network and Distributed System
Security Symposium, NDSS (2004)
6. Cova, M., Kruegel, C., Vigna, G.: Detection and Analysis of Drive-by-download
Attacks and Malicious JavaScript code. In: Proceedings of the World Wide Web
Conference, WWW (2010)
7. Cova, M., Leita, C., Thonnard, O., Keromytis, A.D., Dacier, M.: An Analysis of
Rogue AV Campaigns. In: Jha, S., Sommer, R., Kreibich, C. (eds.) RAID 2010.
LNCS, vol. 6307, pp. 442–463. Springer, Heidelberg (2010)
8. Cunningham, P., Nowlan, N., Delany, S.J., Haahr, M.: A Case-Based Approach to
Spam Filtering that Can Track Concept Drift. Knowledge-Based Systems (2005)
9. Cutts, M.: Pagerank
sculpting
(2009),
http://www.mattcutts.com/blog/
pagerank-sculpting/
Eyes of a Human, Eyes of a Program
147
10. Fumera, G., Pillai, I., Roli, F.: Spam Filtering Based on the Analysis of Text
Information Embedded into Images. The Journal of Machine Learning Research 7,
2699–2720 (2006)
11. Garera, S., Provos, N., Chew, M., Rubin, A.D.: A Framework for Detection and
Measurement of Phishing Attacks. In: Proceedings of the ACM Workshop on Re-
curring Malcode, WORM (2007)
12. Google Inc.: Image publishing guidelines (2012), http://support.google.com/
webmasters/bin/answer.py?hl=en&answer=114016
13. Google Inc.: Making AJAX Applications Crawable (2014), https://developers.
google.com/webmasters/ajax-crawling/
14. Google
Inc.: Webmaster Guidelines
(2014),
http://support.google.com/
webmasters/bin/answer.py?hl=en&answer=35769#2
15. Hara, M., Yamada, A., Miyake, Y.: Visual Similarity-Based Phishing Detection
without Victim Site Information. In: Proceedings of the IEEE Symposium on Com-
putational Intelligence in Cyber Security (CICS), pp. 30–36. IEEE (March 2009)
16. Invernizzi, L., Benvenuti, S., Comparetti, P.M., Cova, M., Kruegel, C., Vigna, G.:
EVILSEED: A Guided Approach to Finding Malicious Web Pages. In: Proceedings
of the IEEE Symposium on Security and Privacy, S&P (2012)
17. Invernizzi, L., Miskovic, S., Torres, R., Saha, S., Lee, S.J., Mellia, M., Kruegel,
C., Vigna, G.: Nazca: Detecting Malware Distribution in Large-Scale Networks. In:
Proceedings of the Network and Distributed System Security Symposium, NDSS
(2014)
18. Kapravelos, A., Shoshitaishvili, Y., Cova, M., Kruegel, C., Vigna, G.: Revolver:
An Automated Approach to the Detection of Evasive Web-based Malware. In:
Proceedings of the USENIX Security Symposium (2013)
19. Kirda, E., Kruegel, C.: Protecting Users Against Phishing Attacks with AntiPhish.
In: Proceedings of the International Conference on Computer Software and Appli-
cations (COMPSAC), vol. 1, pp. 517–524. IEEE (2005)
20. Konte, M., Feamster, N., Jung, J.: Fast Flux Service Networks: Dynamics and
Roles in Hosting Online Scams. Tech. rep., Georgia Institute of Technology and
Intel Research (2008)
21. Lee, S., Kim, J.: WarningBird: Detecting Suspicious URLs in Twitter Stream. In:
Proceedings of the Network and Distributed System Security Symposium, NDSS
(2010)
22. Li, Z., Alrwais, S., Xie, Y., Yu, F., Wang, X.: Finding the Linchpins of the Dark
Web: A Study on Topologically Dedicated Hosts on Malicious Web Infrastruc-
tures. In: Proceedings of the IEEE Symposium on Security and Privacy (S&P), pp.
112–126 (May 2013)
23. Lin, E., Greenberg, S., Trotter, E., Ma, D., Aycock, J.: Does Domain Highlighting
Help People Identify Phishing Sites? In: Proceedings of the Conference on Human
Factors in Computing Systems (CHI), p. 2075. ACM Press, New York (2011)
24. Lu, L., Perdisci, R., Lee, W.: SURF: Detecting and Measuring Search Poisoning
Categories. In: Proceedings of the ACM Conference on Computer and Communi-
cations Security, CCS (2011)
25. Jung, J., Milito, R.A., Paxson, V.: On the Eﬀectiveness of Techniques to De-
tect Phishing Sites. In: H¨ammerli, B.M., Sommer, R. (eds.) DIMVA 2007. LNCS,
vol. 4579, pp. 20–39. Springer, Heidelberg (2007)
26. Mcgrath, D.K., Gupta, M.: Behind Phishing: An Examination of Phisher Modi
Operandi. In: Proceedings of the USENIX Workshop on Large-Scale Exploits and
Emergent Threats, LEET (2008)
148
J. Corbetta et al.
27. Medvet, E., Kirda, E., Kruegel, C.: Visual-Similarity-Based Phishing Detection. In:
Proceedings of the International Conference on Security and Privacy in Communi-
cation Networks (SecureComm), p. 1. ACM Press, New York (2008)
28. Microsoft Corp.: Bing Webmaster Guidelines (2014), http://www.bing.com/
webmaster/help/webmaster-guidelines-30fba23a
29. Neupane, A., Saxena, N., Kuruvilla, K., Georgescu, M., Kana, R.: Neural Signa-
tures of User-Centered Security: An fMRI Study of Phishing, and Malware Warn-
ings. In: Proceedings of the Network and Distributed System Security Symposium
(NDSS). pp. 1–16 (2014)
30. Ntoulas, A., Hall, B., Najork, M., Manasse, M., Fetterly, D.: Detecting Spam Web
Pages through Content Analysis. In: Proceedings of the International World Wide
Web Conference (WWW), pp. 83–92 (2006)
31. Prakash, P., Kumar, M., Kompella, R.R., Gupta, M.: PhishNet: Predictive Black-
listing to Detect Phishing Attacks. In: Proceedings of the IEEE International Con-
ference on Computer Communications (INFOCOM), pp. 1–5. IEEE (March 2010)
32. Rajab, M.A., Ballard, L., Marvrommatis, P., Provos, N., Zhao, X.: The Nocebo
Eﬀect on the Web: An Analysis of Fake Anti-Virus Distribution. In: Large-Scale
Exploits and Emergent Threats, LEET (2010)
33. Rosiello, A.P.E., Kirda, E., Kruegel, C., Ferrandi, F.: A Layout-Similarity-Based
Approach for Detecting Phishing Pages. In: Proceedings of the International Con-
ference on Security and Privacy in Communication Networks, SecureComm (2007)
34. Ruzzo, W., Tompa, M.: A Linear Time Algorithm for Finding All Maximal Scoring
Subsequences. In: Proceedings of the Seventh International Conference on Intelli-
gent Systems for Molecular Biology. AAAI (1999)
35. Seifert, C., Welch, I., Komisarczuk, P.: Identiﬁcation of Malicious Web Pages with
Static Heuristics. In: Proceedings of the Australasian Telecommunication Networks
and Applications Conference. IEEE (2008)
36. Sheng, S., Holbrook, M., Kumaraguru, P., Cranor, L., Downs, J.: Who Falls for
Phish? A Demographic Analysis of Phishing Susceptibility and Eﬀectiveness of
Interventions. In: Proceedings of the Conference on Human Factors in Computing
Systems (CHI), pp. 373–382 (2010)
37. Sheng, S., Magnien, B., Kumaraguru, P., Acquisti, A., Cranor, L.F., Hong, J.,
Nunge, E.: Anti-Phishing Phil: The Design and Evaluation of a Game That Teaches
People Not to Fall for Phish. In: Proceedings of the Symposium on Usable Privacy
and Security (SOUPS), pp. 88–99 (2007)
38. Sheng, S., Wardman, B., Warner, G., Cranor, L.F., Hong, J.: An Empirical Analysis
of Phishing Blacklists. In: Proceedings of the Conference on Email and Anti-Spam,
CEAS (2009)
39. Stone-Gross, B., Abman, R., Kemmerer, R., Kruegel, C., Steigerwald, D., Vigna,
G.: The Underground Economy of Fake Antivirus Software. In: Proceedings of the
Workshop on Economics of Information Security, WEIS (2011)
40. Stringhini, G., Kruegel, C., Vigna, G.: Shady Paths: Leveraging Surﬁng Crowds to
Detect Malicious Web Pages. In: Proceedings of the ACM Conference on Computer
and Communications Security, CCS (2013)
41. Symantec: Seal License Agreement (2014), https://www.symantec.com/content/
en/us/about/media/repository/norton-secured-seal-license-agreement.
pdf
42. Wang, D.Y., Savage, S., Voelker, G.M.: Cloak and Dagger: Dynamics of Web Search
Cloaking. In: Proceedings of the ACM Conference on Computer and Communica-
tions Security (CCS), pp. 477–489 (2011)
Eyes of a Human, Eyes of a Program
149
43. Wepawet, http://wepawet.cs.ucsb.edu
44. Whittaker, C., Ryner, B., Nazif, M.: Large-Scale Automatic Classiﬁcation of Phish-
ing Pages. In: Proceedings of the Network and Distributed System Security Sym-
posium, NDSS (2010)
45. Wu, M., Miller, R.C., Garﬁnkel, S.L.: Do Security Toolbars Actually Prevent Phish-
ing Attacks? In: Proceedings of the Conference on Human Factors in Computing
Systems (CHI), pp. 601–610 (2006)
46. Xiang, G., Hong, J., Rose, C.P., Cranor, L.: CANTINA+: A Feature-Rich Machine
Learning Framework for Detecting Phishing Web Sites. In: ACM Transactions on
Information and System Security, pp. 1–28 (2011)
47. Yandex, N.V.: Recommendations for webmasters - Common errors (2014), http://
help.yandex.com/webmaster/recommendations/frequent-mistakes.xml
48. Yandex, N.V.: Recommendations for webmasters - Using graphic elements (2014),
http://help.yandex.com/webmaster/recommendations/using-graphics.xml
49. Zauner, C.: Implementation and Benchmarking of Perceptual Image Hash Func-
tions. Master’s thesis, Upper Austria University of Applied Sciences, Hagenberg
Campus (2010)
50. Zhang, Y., Hong, J., Cranor, L.: CANTINA: A Content-Based Approach to De-
tecting Phishing Web Sites. In: Proceedings of the ACM Conference on Computer
and Communications Security, CCS (2007)