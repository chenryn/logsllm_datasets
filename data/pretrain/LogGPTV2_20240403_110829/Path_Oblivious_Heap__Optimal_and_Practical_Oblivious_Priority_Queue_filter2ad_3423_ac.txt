line of work.
B. Basic Operations
Throughout our construction, we assume that data contents
are either freshly re-encrypted or re-secret-shared when being
written to external memory (see also Remark 3).
Bucket operations. Henceforth we assume that each bucket
B supports two basic operations both of which can be imple-
mented obliviously in |B| = O(1) cost for non-root buckets
and in |Broot| cost cost for the root bucket — we will show
later that |Broot| must be super-logarithmic in the security
parameter for the failure probability to be negligibly small
for any polynomially bounded request sequence:
1) B.Add(k, v, ref): add the tuple (k, v, ref) to the bucket B
and throw an Overﬂow exception if unsuccessful. This
Authorized licensed use limited to: Auckland University of Technology. Downloaded on November 03,2020 at 00:37:42 UTC from IEEE Xplore.  Restrictions apply. 
846
can be accomplished obliviously through a linear scan of
the bucket, and writing the tuple to a dummy location.
For obliviousness, whenever a real element is encountered
during the scan, make a fake write, i.e., write the original
element back. If no dummy location was found during the
scan, throw an Overﬂow exception.
2) B.Del(ref): delete an element with the reference ref from
the bucket B if such an element exists. If such an element
exists, return the element; else return dummy. This can
be accomplished obliviously through a linear scan of the
bucket, writing the original element back if it does not have
the reference ref; otherwise replacing it with dummy.
Path operations. We will need two types of path operations.
Henceforth let P denote a path in the tree identiﬁed by the
leaf node’s index.
1) P.ReadNRm(ref). Read every bucket on the path P and
if an element of the reference ref exists, save its value in
the CPU’s local cache and remove it from the path. This
can be accomplished by scanning through every bucket
B on P from root to leaf and calling B.Del(ref).
2) P.Evict(). Eviction is an algorithm that works on a path,
and tries to move real elements on the path closer to the
leaf while respecting the path invariant. We shall review
Path ORAM’s eviction algorithm shortly below and this
is what we will adopt in our scheme too.
3) P.UpdateMin(). Whenever we operate on a path, the
subtree-mins on the path need to be updated using an
UpdateMin procedure. This procedure can be accom-
plished in time proportional to the path length as de-
scribed below: for every bucket B on path P from leaf to
root, recalculate its subtree-min by taking the minimum
of 1) the minimum element of the current bucket B; and
2) the subtree-mins of both children.
Background: review of Path ORAM’s eviction. As men-
tioned, P.Evict() is an eviction algorithm that operates on a
path. In Path ORAM [39], the eviction algorithm takes the
entire path and tries to pack the elements on the path as close
to the leaf as possible while respecting the path invariant of
every element.
To achieve this, the CPU can locally perform the following
is
algorithm after reading back the path, where the root
assumed to be at the smallest level of the path P, a slot L in
a bucket is said to be empty if the slot currently contains a
dummy element, and recall that each element’s position label
pos is encoded in the reference ref:
Path ORAM’s eviction algorithm [39]:
For bucket B ranging from the leaf to the root on P:
For every empty slot in L ∈ B:
If ∃ an element in P in a level smaller than B and
moreover this element can legitimately reside in B
based on its position label pos:
Move this element to this the slot L.
C. Heap Operations
We assume that
the priority queue maintains a counter
denoted τ that records the number of operations that have
been performed so far, i.e., this counter τ increments upon
every operation. At any point of time, if a bucket throws an
Overﬂow exception when trying to add an element, the entire
algorithm simply aborts with an Overﬂow exception.
Path Oblivious Heap:
• FindMin(): Let (k, v, ref) := the subtree-min of the root
bucket Broot and return (k, v, ref).
• Insert(k, v):
1}.
number of operations performed so far.
1) Choose a random position label pos $←{0, 1, . . . , N −
2) Call Broot.Add(k, v, (pos, τ )) where τ denotes the
3) Pick two random eviction paths P and P(cid:48) that are non-
overlapping except at the root — the two eviction paths
can be identiﬁed by the indices of the leaf nodes.
P(cid:48).Evict() and P(cid:48).UpdateMin().
and P.UpdateMin();
4) Call P.Evict()
then
call
5) Return the reference ref := (pos, τ ).
• Delete(ref) where ref := (pos, τ(cid:48)):
1) Let P denote the path from root
to the leaf node
2) Call P.ReadNRm(ref), P.Evict(), and P.UpdateMin().
• ExtractMin(): Let (k, v, ref) := FindMin() and call
identiﬁed by pos;
Delete(ref).
We shall prove the following theorem later in Appendix B.
Theorem 3 (Oblivious simulation of Fpq). Suppose that
every non-root bucket has capacity at least 5 and that the
root bucket’s capacity is denoted by |Broot|. The above PQ
algorithm is a (1 − )-oblivious simulation4 of Fpq for
 = T · e−Ω(|Broot|).
As a special case, suppose that all non-root buckets have
capacity 5 and the root bucket’s capacity |Broot| = ω(log λ),
then the resulting scheme realizes an oblivious priority queue
by Deﬁnition 1.
Proof. Deferred to Appendix B.
D. Asymptotical Efﬁciency
Clearly FindMin looks at only the root’s subtree-min
label, and moreover each Delete, Insert, and ExtractMin
request consumes path-length amount of bandwidth. Sup-
pose that the CPU locally stores the root bucket, then it is
not hard to see that to support each Delete, Insert, and
ExtractMin request, only O(log N ) entries of the priority
queue need to be transmitted.
Additionally relying on
Theorem 3 to parametrize the root bucket’s size, we can
4Although our earlier formal deﬁnition of oblivious simulation assumes that
the priority queue algorithm PQ does not know T upfront, it is easy to extend
the deﬁnition for a priority queue algorithm PQ that knows an upper bound
on T a-priori — basically, in RealPQ,A(1λ, N, T ), pass not only N to PQ
as input, but also T .
Authorized licensed use limited to: Auckland University of Technology. Downloaded on November 03,2020 at 00:37:42 UTC from IEEE Xplore.  Restrictions apply. 
847
now analyze the scheme’s efﬁciency and security tradeoff as
formally stated in the Theorem 4 below. Theorem 4 follows in
a somewhat straightforward fashion from Theorem 3 through
variable renaming and augmented with a simple performance
analysis — we present its proof nonetheless for completeness.
Theorem 4. Let N (λ) and T (λ) denote the a-priori upper
bound on the number of elements in the priority queue and
the maximum number of requests respectively. Let D := |k| +
|v| be the number of bits needed to represent an item of the
priority queue; let w be the bit-width of each memory word,
and let C := (cid:100)(D + log T )/w(cid:101).
There is a suitable constant c0 such that if we instantiate
the algorithm in Section III with the root bucket capacity being
|Broot| = c0 log 1
δ(λ) where 0 < δ(λ) < 1/T (λ), and a non-
root bucket capacity of 5, then the resulting scheme (1− T δ)-
obliviously simulates Fpq consuming O(C · (log N + log 1
δ ))
words of CPU private cache; and moreover it completes each
FindMin request in O(C) bandwidth, and supports each
Delete, Insert, and ExtractMin request consuming at
most O(C log N ) bandwidth, measured in the number of words
transmitted between CPU and memory.
Proof. Consider the algorithm presented in Section III that is
parametrized with N and T , a non-root bucket capacity of 5,
and the root’s capacity being |Broot| := c0 · log(1/δ) where c0
is a suitable constant such that the exp(−Ω(|Broot|)) failure
probability in Theorem 3 is at most δ. Now, the (1 − T δ)-
oblivious simulation claim follows directly from Theorem 3.
For the asymptotic performance claims, observe that each
FindMin request looks at only the root’s subtree-min label
and thus takes only O(C) time; and each Delete, Insert,
and ExtractMin request visits O(1) number of tree-paths
where the root may be permanently cached on the CPU side;
thus O(C log N ) bandwidth is required.
We want the failure probability to be negligibly small in λ
as long as T is polynomially bounded in λ. To achieve this we
can set the root bucket’s capacity to be super-logarithmic in λ
ensuring that the per-request failure probability is negligibly
small. We thus derive the following corollary.
Corollary 5 (Oblivious priority queue). Let C be deﬁned in
the same way as Theorem 4. For any arbitrarily small super-
constant function α(λ), for every T there exists an algorithm
that realizes an oblivious priority queue by Deﬁnition 1
supporting at most T requests, consuming O(C · (log N +
α(λ) log λ)) words of CPU private cache, and moreover
the algorithm completes each FindMin request in O(C)
bandwidth, and each Delete, Insert, and ExtractMin
request in O(C · log N ) bandwidth measured in number of
words transmitted between the CPU and memory.
Proof. Follows in a straightforward fashion from Theorem 4
by letting the root bucket capacity |B| = α(λ)·log λ. Now, for
T = poly(λ), the failure probability is bounded by poly(λ) ·
exp(−Ω(α(λ) log λ)) which is negligibly small in λ as long
as α(·) is super-constant.
E. The Case of Unknown T
So far we have assumed that we know the maximum number
of requests (denoted T ) a-priori since the scheme needs to
allocate enough space in each entry to store a timestamp of
log T bits. It is easy to remove this assumption and construct
an oblivious priority queue that only needs to know N a-priori
but not T . Recall that we needed the log2 T -bit timestamp
in the references only to serve as a unique identiﬁer of the
element. Based on this idea, we will leverage an oblivious
priority queue and an oblivious stack [44].
1) Primary PQ:
the primary PQ works just as before
except that the originally log2 T -bit τ is now replaced
with a log2 N-bit unique identiﬁer. We will leverage an
unconsumed-identiﬁer stack to ensure that every element
existing in PQ receives an unconsumed identifer τ.
2) Unconsumed-identiﬁer stack S: stores a list of uncon-
sumed identiﬁers5 from the domain {0, 1, . . . , N − 1}.
Initially, S is initialized to contain all of {0, 1, . . . , N−1}.
Now, for each PQ.Insert query, we call τ ← S.Pop
to obtain an unconsumed identiﬁer and τ will become part
of the reference for the element being inserted. Whenever
PQ.ExtractMin or PQ.Delete is called, let τ be part of
the reference for the element being extracted or deleted. We
now call S.Push(τ ) to return τ to the unconsumed pool.
In our unknown-T construction, the metadata stored in each
entry is now of O(log N ) bits rather than O(log T ) bits for
the earlier known-T case (note that in general, T ≥ N). We
thus obtain the following corollary where C is now redeﬁned
as C := (cid:100)(D + log N )/w(cid:101).
Corollary 6 (The case of unknown T ). Let D := |k| + |v| be
the number of bits needed to represent an item of the priority
queue; let w be the bit-width of each memory word, and let
C := (cid:100)(D + log N )/w(cid:101).
For any arbitrarily small super-constant
function α(λ),
there exists an algorithm that realizes an oblivious priority
queue by Deﬁnition 1 supporting an unbounded number of
requests, consuming O(C·(log N +α(λ) log λ)) words of CPU
private cache, and moreover the algorithm completes each
FindMin request in O(C) bandwidth, and each Delete,
Insert, and ExtractMin request in O(C·log N ) bandwidth
measured in number of words transmitted between the CPU
and memory.
Proof. We have described the construction in the paragraph
before this corollary, where every instance of known-T obliv-
ious priority queue adopted satisﬁes Corollary 5. The per-
formance analysis follows in a straightforward fashion by
observing that we can construct an oblivious stack (where
each element ﬁts in a single memory word) with O(log N )
bandwidth assuming O(log N + α(λ) log λ) words of CPU
private cache due to Wang et al. [44].
5In fact, for type-revealing security, even a non-oblivious stack would work.
For type-hiding security (see Appendix D), however, we would need an
oblivious stack that hides the type of operations.
Authorized licensed use limited to: Auckland University of Technology. Downloaded on November 03,2020 at 00:37:42 UTC from IEEE Xplore.  Restrictions apply. 
848
IV. THE CIRCUIT VARIANT: TIGHTER BOUNDS AND
APPLICATIONS IN MULTI-PARTY COMPUTATION
So far, we presented an oblivious heap construction instanti-
ated from the (non-recursive) Path ORAM [39]. The resulting
scheme (i.e., the Path-variant) requires that the CPU be able
to locally store and process path-length amount of data, i.e.,
a total of O(log N + log 1
δ ) of priority queue elements where
δ is the per-request failure probability (see Theorem 4). We
recommend the Path-variant for cloud outsourcing scenarios
since it
the client can store
O(1) tree-paths; and by making this assumption, every priority
queue request can be served in a single roundtrip.
is reasonable to assume that
The Path-variant, however, is not the best candidate for a
secure multi-party computation scenario. Suppose that each
priority queue entry ﬁts in a single memory word of w
bits, with the earlier Path-variant, each priority queue re-
quest is supported with a circuit of size O(wL log L) where
δ ) denotes the path length [42], [43].
L = O(log N + log 1
Speciﬁcally,
the circuit size is dominated by the eviction
circuit; and implementing Path ORAM’s eviction algorithm
as circuit requires oblivious sorting on the path as previous
works have shown [42], [43], resulting in a size-O(wL log L)
circuit.
In this section, we describe a Circuit-variant where the
eviction algorithm follows that of non-recursive Circuit
ORAM [42]. This variant overcomes the above two drawbacks
in exactly the same way how Circuit ORAM [42] overcomes
the drawbacks of Path ORAM [39]:
1) it reduces the CPU’s private cache to O(1) words; and