==== Kafka
准备工作
请将linux 64bit Heka升级至 3.1.0.10以上（包括3.1.0.10）
yottaWeb版本 v3.0.0.322以上（包括v3.0.0.322）
目前采用的 confluent-kafka-go 库仅支持 kafka 0.9 及以上版本。
Kafka 接入配置较为复杂，本节分别介绍几种常见场景下的配置。
===== 最简配置
最简单的需求场景下，kafka 集群无需认证，也不需要字段映射。配置流程如下：
1. 点击添加数据页面的Kafka标签，进入添加kafka数据源流程，即将Kafka的输出作为数据源采集。
2. Kafka右侧的配置项，其中带*号的为必填项。如果需要在采集kafka数据的同时还监控kafka的采集速度等指标，需要打开红框中的“采集offset数据”选项，同时配置上合适的采集间隔时间；紫色框部分表示为每个input配置多少协程，以及每个协程的管道容量，该配置在需要字段映射时候效果比较显著。配置完毕后，点击右上角的下一步进入检查页面。
+
image::images/agent-config-kafka1.png[]
+
3. 检查无误后，点击完成配置。
如果开启了采集 offset 数据，可以收到 consumer group消费topic的速度、offset信息(其中partition为-1时表示整个topic的信息)等监控指标数据，默认采用 appname 和 tag 均为 `kafka_offset_metric` 的标记。示例如下：
  {"groupId":"logriver","topic":"raw_message","partition":-1,"inOffset":2534746,"inSpeed":1.00,"outOffset":2534741,"outSpeed":0.00,"lag":5}
如果需要更细节的 topic 各 partition 监控指标，则需要另外通过 `KafkaMetricInput` 插件进行采集。配置示例：
[source,]
----
[kafka_metric_input_1]
   # 类型固定为此
   type = "KafkaMetricInput"
   appname = "heka"
   tag = "KafkaMetricInput"
   source = "kafka" # broker地址
   bootstrap_servers = "192.168.1.54:9092" # 消费组名，如果需要统计某个consumer group消费的topic的速度，offset # 需要配置为对应的consumer group,否则可以随意配置，但必须配置
   group_id = "logriver"
   # topic的所有partion的相关信息，最早、晚的offset和所属topic、broker等，详见数据格式
   count_partition = true
   # 某个consumer group消费的topic的速度、offset，该项指定哪些topic,不配置则不采集
   topics = ["raw_message"]
   # 采集间隔，单位：秒
   ticker_interval = 10
----
采集上来的数据示例如下：
  {"broker":{"address":"192.168.1.54:9092","id":10},"offset":{"newest":845146,"oldest":831794},"partition":{"error":{},"id":0,"isrs":[10],"leader":10,"replica":[10]},"replica":{"id":10,"insync_replica":true,"is_leader":true},"topic":{"name":"raw_message"}}
注意：初次尝试接入时，应选择"offset 策略"配置项为"earliest"，从 topic 的头部开始消费。否则默认的 latest 从尾部开始，如果当前 topic 没有新数据，会误报消费错误。
此外，配置"offset 策略"为"latest" 还存在丢数据的风险。当 topic 增加 partition 数量时，数量的实际增加到 kafka 发出 partition rebalance 事件之间有一定的时间间隔。因此，当 heka 监听到 partition rebalance 事件发生，开始消费新增 partition 时，如果是 latest offset 开始，之前这段时间间隔内写入的数据就无法正常消费采集。
===== 字段映射
字段映射功能是根据一个原始 JSON 按照特定规则变换出新的字符串或其他对象。目前支持映射的字段包括：
* context_id
* payload
* hostname
* ip
* appname
* timestamp
* tag
* source
其中采用映射时，appname、tag、hostname、 payload字段的值(原始值或者从json中映射值)均不能为空，其中hostname不配置时会自动采用本机的hostname，如果为空，则该条数据不采用映射。
例如，有以下JSON数据：
  {"key1":"value1","key2":{"key3":"value3"}}
下面为可设定的各种映射规则及对应的返回结果：
* $str(.) 表示将整个json本身作为string返回
* .key1 表示取json中的某个key1对应的value1，同样的.key2.key3表示取key3对应的value3(因为key3是key2的一个子对象，所以要列出key2才行)
* 'abc' 表示字面值
* $replace(.key1,'a','b') 该函数表示将第一个参数中的所有a替换成b,该表达结果为vblue1
* $if_then_else(param1, param2, param3) 该函数表示如果param1为真即返回param2，否则返回param3。
* param1 + param2 需要两个参数的类型一致，都为string时表示拼接，都为num类型时，表示相加。
* $str(param1) 表示将param1的值转为string返回,当param1的值为nil(不存在)时会返回“null"
* :.key1+.key2@abc  其中映射规则为.key1+.key2  默认值为abc（string类型).即以”:”打头表示开启字段映射(整个string只能包含一个”@”).第一个”:”到”@”之间为映射规则。”@”后到结尾为默认值(默认值目前解析为string类型)
当 Kafka 集群无需认证，但需要字段映射时，配置流程和最简配置类似，只需要在 appname、tag 配置项内按上述规则填写。其他字段则需点击"打开高级配置"，进行更多的字段映射配置。
需要注意的是，采用字段映射(只要有一个字段采用了映射)后,appname映射或者本身的值不能为空、tag映射的值或者本身的值不能为空、hostname映射的值不能为空，本身的值可以为空、payload映射的值或者本身的值不能为空(本身的值表示不配置映射时候采用的字符串)，如果不满足就采用不映射的方法解析，需要映射的字段用其默认值代替(@符号后面),其中payload、log_timestamp、context_id字段的默认值无效。
image::images/agent-config-kafka3.png[]
===== Kerberos 认证配置
如果 kafka 集群需要进行kerberos认证，需要进行下列准备工作。首先，请客户提供以下必要信息：
* krb5.conf: 此文件用于定位kdc服务器和realm
* principal/keytab文件: 相当于用户名和密码文件，由kadmin.local -q "ktadd -k /tmp/yl.keytab principal"
* servername: 来自于用户启动kafka的配置文件server.properties中的sasl.kerberos.service.name配置项
* kdc、kafka集群的相关host->ip映射
获得信息后，部署配置步骤如下：
. 把上述相关host->ip映射加到host文件中
. 安装相Kerberos关命令: yum install -y krb5-libs krb5-workstation
. 将krb5.conf放到/etc下
. 修改krb5.conf中的default_ccache_name的值为 FILE:/opt/krb5cc_%{uid}
. 验证kerberos认证：kinit -kt keytab文件 principal
** 没任何输出: 认证成功,使用klist能看到刚才认证的principal
** 报错: kinit: Keytab contains no suitable keys for PI:EMAIL while getting initial credentials
** 确认keytab文件和principal是正确对应的，且没有输出错误
** 报错: kinit: Cannot contact any KDC for realm 'EXAMPLE.COM' while getting initial credentials
** 确认kdc服务器的host->ip映射正确且已经加入hosts文件中
** 确认是否能ping通服务器
. 安装gssapi相关 yum install -y cyrus-sasl-gssapi
. 环境确认正常，启动heka
然后在最简配置基础上，点击需要的认证方式，填入对应的配置，如果有额外配置，在自定义配置中添加。
image::images/agent-config-kafka2.png[]
===== PLAIN 认证配置
PLAIN 认证方式支持明文密码和密文密码两种方式，界面配置上，要求采用密文密码。如果需要采用密文，请联系日志易技术支持人员索要 hekad/tool/password_generator 工具生成。
如果确系明文密码的，可以在高级配置中，修改 `sasl-encrypted_password` 配置项为 `sasl-password` 配置项并填入正确的密码。
===== 华为 IAM 认证配置
选择 HW-IAM 认证方式后，按照华为提供的 IAM 服务器地址、account@app_id、secret 等信息填写认证配置即可。
===== SCRAM 认证方式
先在界面上完成 SASL_PLAIN 认证方式配置，然后打开高级配置，找到对应的 CKafkaInput 配置段，修改如下：
* sasl-mechanisms所在行改为sasl-mechanisms="SCRAM-SHA-256"
* security-protocol所在行改为security-protocol="SASL_SSL"
上述两个配置的值并不是完全固定，具体应该同kafka server的配置一致，其中sasl-mechanisms对应kafka的sasl.mechanism.inter.broker.protocol；security-protocol对应kafka的security.inter.broker.protocol
===== OAUTHBEAR 认证方式
OAUTHBEAR认证方式较多，目前仅支持client credentials方式的认证，判断方法为客户其他方式的连接方式中往往只出现了以下元素
 kafka.sasl.mechanism=OAUTHBEARER
 unsecuredLoginStringClaim_sub
 xxx_secret
 xxx_url
在高级配置中找到对应的 CKafkaInput 配置段修改如下：
[source,]
----
[1_kafka_input.properties]
    sasl-mechanisms="OAUTHBEARER"
    security-protocol = "SASL_PLAINTEXT"
    sasl-oauthbearer-config="grant_type=client_credentials,client_id=tommy2,client_secret=tommy123456,token_url=http://localhost:4444/oauth2/token,scopes=openid offline offline_access,auth_style=in_header"
----
其中新增的 sasl-oauthbearer-config此配置中，包含多个key=value的配置，并且以`,`进行分隔，解释如下：
* grant_type=client_credentials：目前仅支持此方式
* client_id=tomy2: 值需要提供
* client_secret=tommy123456: 值需要提供，出于安全考虑，可以使用bin目录下的password_generator工具进行加密
* token_url=http://localhost:4444/oauth2/token：值需要提供
* scopes=openid offline offline_access：非必须，多个scope以空格进行分隔
* auth_style=in_header：值可以为in_header、in_params；如果不配置此，会进行自动探测
===== 拆分JSON数据
点击"打开高级配置"，在pay_load字段里面填写jsonpath，形如CUT[jsonpath]，如原始数据为：
[source,]
----
{
  "head": {
    "company": "colasoft",
    "endIndex": 4100,
    "netlinkId": 2,
    "serverIp": "10.87.25.106",
    "startIndex": 4000,
    "tableId": "tcp_flow",
    "taskName": "task1",
    "time": 1575524918,
    "totalCount": 6214
  },
  "records": [
    {
      "application_id": "WEB",
      "client_ip_addr": "117.84.91.70",
      "client_port": "63929",
      "client_total_byte": 168,
      "client_total_packet": 2,
      "flow_end_time": 1575524919,
      "flow_start_time": 1575524558,
      "protocol": "HTTPS",
      "server_ip_addr": "183.236.6.166",
      "server_port": "443",
      "server_total_byte": 160,
      "server_total_packet": 2
    },
  ]
}
----
如需将records字段拆分并发送，可以配置成：
image::images/kafka4.png[]
[NOTE]
====
如果需要使用该功能，则此时不再支持使用字段映射功能。
====
更多的jsonpath语法可以参考jsonpath的文档 。
=== 分组采集配置
之前章节讲述的单一数据采集源，需要开启日志易服务器推送数据到采集端的网络访问策略才能正常运转，在跨网络环境中很难满足。而单一数据源批量下发的功能，在集群扩缩容变动比较频繁的业务线上，也不能灵活运用。
日志易提供由采集端主动拉取配置的方式来同步数据源配置，并结合目前的 Agent 分组，来实现批量配置管理。
==== 分组配置使用限制
1. 由于 Agent 可以属于多个 Agent 分组，为防止不同 Agent 分组配置项的冲突，Agent 分组可以管理的采集配置项暂时只支持 文件和目录/Eventlog/脚本/Tcp/Udp/性能数据。
2. 单行日志最大长度，限速，压缩等单个 Agent 的全局配置不在 Agent 分组的采集配置项管理中提供。
3. 因各个平台支持插件细节有差别，不支持对包含不同平台 Agent 的 Agent 分组进行分组配置管理, 也不支持对尚未包含任何 Agent 的 Agent 分组进行分组配置，因此在进行 Agent 分组采集前，请先将同一平台的 Agent 归入同一分组。
==== 分组配置管理
在 Agent 列表页右上角点击"更多->分组配置"，进入 Agent 分组管理页面。在左侧组织结构树底部点击"新建Agent分组"，配置分组的名称、描述、资源标签和分组角色，点击"保存"，创建分组。
image::images/agentgroup-entrance.png[]
分组创建成功后，可以在基本配置Tab中更新分组的基本信息，点击右上角的跳转icon跳转到Agent管理页，点击删除icon删除该分组；也可以添加分组采集配置。
image::images/agentgroup-basic-conf.png[]
添加采集配置前需要返回Agent管理页向分组添加agent，再次进入分组管理页面选中分组，点击"添加"，在来源选择页面，选择要添加的数据源类型。Agent 分组采集配置的增删改流程和 Agent 单一数据源采集配置增删改类似，不再赘述。
与对单一数据源添加配置唯一不同的，Agent 分组配置的添加过程不支持“预览”功能。直接填入appname，tag，换行等必要配置信息后即可点击下一步。
image::images/agentgroup-add.png[]
采集配置完成后，返回Agent分组管理页面，选中分组，在采集配置Tab进行配置的查看，启用/禁用，编辑，删除操作。
image::images/agentgroup-page.png[]
[NOTE]
====
1. Agent 分组的采集配置是通过 Agent 心跳同步的，Agent 心跳默认频率是 1 分钟/次
2. Agent 分组的配置，在 Agent 配置详情页不会直接列出，但可以通过高级配置界面进行查看。详情页上，会高亮标记带有配置的分组名称，用户也可以点击跳转到对应的分组采集配置页：
+
image::images/agentgroup-highlight-in-agent-page.png[]
====