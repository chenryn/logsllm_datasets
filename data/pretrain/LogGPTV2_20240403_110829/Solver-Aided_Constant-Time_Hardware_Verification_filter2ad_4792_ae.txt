the counterexample. Since the total number of non-constant-time
variables is typically on the order of hundreds (e.g., the median
(and geomean) number of non-constant-time variables across all
benchmarks and iteration is 97 (94)), this dramatically reduces the
number of variables the developer has to inspect in order to under-
stand the violation. For the benchmarks that were variable time,
the counterexamples also precisely pinpointed where in the circuit
the constant-time property was violated. For example, in the FPU2
benchmark Xenon included the state register in its third iteration
counterexample. This register indicates when the FPU’s output is
ready. Inspecting the register’s blame-set (similar to the process de-
scribed in § 2.3) revealed that its value is set depending on whether
one of the operands to the division operation is NaN and thus the
FPU clearly leaks information about its operands.
Q2: Identifying Secrecy Assumptions. To assess the quality of
secrecy assumptions suggested by Xenon, we record the number
of suggestions that the user accepts (useful suggestions) and the
ratio of suggestions to the total number of secret variables the user
would otherwise have to inspect manually. We find that most (on
average 81.67%) of Xenon’s suggestions are useful, reported in the
Accept Ratio column of Table 1. Moreover, we observe that the
number of variables included in the counterexamples is relatively
small (Sugg Ratio column); on average, we only had to inspect
2.77% of the secret variables.
Q3: Verification Effort. Finally, as a rough measure of the overall
verification effort, we count the number of user interactions, i.e.,
the number of times we invoked Xenon after modifying our set of
secrecy assumptions. Verifying the largest benchmark from [50],
the Yarvi RISC-V core [6] took five invocations over several min-
utes. The final assumptions we arrived at were the same as the
assumptions manually identified by the authors of Iodine in [50];
they, however, took multiple days to identify these assumptions
and verify this core [61]. Verifying the SCARV core took thirty-four
iterations and roughly three hours; this core is considerably larger
(roughly 10×) than the Yarvi RISC-V core and, we think, beyond
what would possible with tools like Iodine, which rely on man-
ual annotations and error localization. Indeed, we found the error
localization and assumption inference to be especially useful in
narrowing our focus and understanding to small parts of the core
and avoid the need to understand complex implementation details
irrelevant to the analysis.
Q4: Scalability. To evaluate how module summaries affect the
scalability, we compare the time it takes to verify (or show variable-
time) a program with and without module summaries. Columns
Inlined and Modular of Table 1 give the run times of Xenon with
inlining (no summaries) and module summaries, respectively. On
the Iodine benchmarks (the first seven benchmarks), we observe
that module summaries don’t meaningfully speed up verification.
Indeed, on average, module summaries only reduce the size of
the query sent to our solver by roughly 5% on these benchmarks.
On the more complex AES-256 and SCARV benchmarks, however,
the benefits of module summaries become apparent. For AES-256,
using module summaries reduces the query size by 99.7%, from
391.3 MB to 1.2 MB, which, in turn, reduces the verification time by
three orders of magnitude—from six hours to three seconds. Module
summaries allow Xenon to exploit the core’s modular design, i.e.,
AES-256’s multiple and nested instantiations of the same modules
(see Figure 5). For SCARV, summaries reduce the query size by 41%
and speed up the verification time by 40%. Though this reduction
is not as dramatic as the AES-256 case, the speedup did improve
Xenon’s interactivity.
Q5: Reducing Verification Time. To determine whether Xenon
helps users find annotations more quickly, we recorded the number
of tasks that participants were able to correctly complete within
the 40 minutes timeframe. Column #Crt of Figure 13 summarizes
our results. Participants in the test group completed 2.6 tasks on
average, while participants in the control group were only able to
solve 1.4. Figure 10 shows the percentage of participants that were
able to find a correct set of assumptions, split by task. A little over
50% of control group participants were able to complete the first
task, while 75% were able to complete the second. In contrast, all
Session 2B: Formal Analysis and Verification CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea438Figure 10: Percentage of participants who were able to correctly
complete task.
Figure 11: Correctly completed tasks over time.
Figure 12: Solutions size for correctly completed tasks.
test-group users were able to correctly complete Task 1 and Task 2.
None of the control group users correctly finished the significantly
more difficult Task 3—verifying a full processor with a complex
assumption set—whereas 60% of test-group participants were able
to do so. We find these results encouraging, especially since our par-
ticipants were non-expert users—some only with cursory exposure
to hardware and RTL design.
Figure 11 shows the number of correctly completed tasks over
time, split by group. Test group users were able to finish simple
tasks more quickly and correctly solved more tasks over time.
Q6: Assumption Quality. To determine the quality of assump-
tions, we recorded how often a participant was able to finish a task
within time, but found an incorrect set of assumptions. While the
control group produced five incorrect solutions, the test group only
produced one. Figure 12 shows the average size of correct assump-
tion sets, per group. For tasks completed by both, the test-group
sizes were on average smaller. Though the sample size is small,
it’s clear that Xenon helps guide the user’s attention and avoid
incorrect assumptions.
7 CASE STUDY: VERIFYING SCARV
We now describe our experience verifying SCARV and discuss the
set of secrecy assumptions Xenon synthesized.
SCARV: Overview. SCARV is a 5-stage single-issue in-order CPU,
implementing the RISC-V 32-bit integer base architecture. SCARV is
side-channel hardened and explicitly designed to run cryptographic
code. It supports an external hardware random number generator
and implements fine-grained per-stage flushing of its processor
pipeline via an instruction set extension.
Finding Assumptions Modularly. To verify SCARV, we follow
Xenon’s modular philosophy: we start with modules that occur at
leaf-level in the instantiation-tree, that is, modules that have no
sub-modules of their own, and iteratively work our way up such
that in each stage, we already determined the assumptions for all
sub-modules. At each step, we prove that the current module is
unconditionally constant-time, where we set all module inputs as
sources and outputs as sinks. This keeps errors and assumptions lo-
cal: At every stage of the verification process, we only have to think
about the current module. But this approach has a downside. We
might end up with a set of assumptions that is unnecessarily restric-
tive. Our modular verification process ensures that all input/output
paths of all submodules are constant-time. But, to ensure constant-
time execution of the entire circuit, constant-time execution of only
a subset of modules and their respective input/output paths might
be required. Fortunately, we can use the assumptions found via our
modular verification process to bootstrap a search for a minimal
assumption set. As Xenon’s module summaries can express that a
module is constant-time only under certain conditions, and only for
a subset of input/paths, we can safely erase assumptions, as long as
Xenon can still prove the circuit to be constant time. Repeating this
process yields a minimal assumption set, which we now discuss.
Sources and Sinks. Xenon represents assumptions as yaml files
that are iteratively populated during verification. Figure 14 shows
assumptions for the top-level module of SCARV. Annotations src
and snk define sources and sinks, respectively. We choose all mod-
ule inputs as sources, and all module outputs as sinks. This captures
all relevant externally observable timing behaviors, including:
▶ The timing of signals interacting with both instruction and
data memory, including requests (Lines 5 and 8), acknowl-
edgments (Line 6), and strobe signals (Line 7),
▶ the timing of flush signals to external resources, such as
caches (Line 9), and
▶ the timing of requests to the external random number gener-
ator, such as request ready bit (Line 10) and accept response
bit (Line 11).
Secrecy Assumptions: External Devices. Annotation pub shows
the secrecy assumptions synthesized by Xenon. At top-level, these
assumptions concern external signals, hardware and interrupts.
They require, for example, the external reset signal (Line 14), con-
trol inputs from external devices like memory (Lines 16 to 19),
memory-mapped devices (Line 25), and the external random gener-
ator (Lines 21 to 23) to be public. The assumptions on memory are
justified as they do not concern caches. Finally, the assumptions re-
quire that traps (Line 27), interrupts from external devices (Lines 29
to 31), and software (Lines 37 and 38) do not depend on secrets.
Importantly, neither are all inputs public nor are assumptions
only placed on inputs. For example, Xenon doesn’t synthesize
assumptions requiring values read from data-memory (Line 2) or
the external random source (Line 3) to be public. Conversely, the
Completed0%25%50%75%100%Task 1Task 2Task 3Control TestTimeCompleted0510150102030ControlTestSolution Size024681012Task 1Task 2Task 3Control TestSession 2B: Formal Analysis and Verification CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea439Task 1 (ALU)
Time
Task 2 (FPU)
Time
Task 3 (RISC-V)
Task 1 (ALU)
Time
Crt
Time
Task 2 (FPU)
Task 3 (RISC-V)
2
2
5
21
9
7.80
7.92
7.80
7.92
𝜇
𝜎
𝜇∗
𝜎∗
Size
3
3
3
3
3
Crt
✓
✓
✓
✓
✓
3.00
0.00
3.00
0.00
-
-
-
-
Size
1
1
1
1
1
Crt
✓
✓
✓
✓
✓
1.00
0.00
1.00
0.00
-
-
-
-
Time
20
14
14
-
27
18.75
6.18
16.00
3.46
Size
10
11
10
-
10
Crt
✓
✓
✓
-
✗
10.25
0.50
10.33
0.58
-
-
-
-
3
1
18
10
4
7.20
6.91
7.20
6.91
#Crt
3
3
3
2
2
2.60
0.55
2.60
0.55
19
10
9
9
13
12.00
4.24
10.33
2.31
𝜇
𝜎
𝜇∗
𝜎∗
Size
2
2
3
5
3
3.00
1.22
3.67
1.15
✗
✗
✓
✓
✓
-
-
-
-
2
5
4
3
21
7.00
7.91
7.50
9.04
Size
1
3
1
2
1
Crt
✓
✗
✓
✓
✓
1.60
0.89