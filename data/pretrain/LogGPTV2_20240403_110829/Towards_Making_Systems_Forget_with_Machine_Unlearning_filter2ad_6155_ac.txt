x
i
∈X gm(xi, lx
))
i
x
i
where xi is a training data sample and lxi
its label. This
form encompasses many popular machine learning algorithms,
including linear regression, chi-squared test, and na¨ıve Bayes.
(cid:2)
With this form, unlearning is as follows. Let Gk be
). All Gks are saved together with the learned
gk(xi, lxi
(cid:2)
model. To unlearn a data sample xp, we compute G
k as
Gk − gk(xp, lxp
Learn(G1 − g1(xp, lxp
). The updated model is thus
), ..., Gm − gm(xp, lxp
), G2 − g2(xp, lxp
))
Unlearning on a non-adaptive SQ learning algorithm is
complete because this updated model is identical to
(cid:2)
(cid:2)
(cid:2)
Learn(
i(cid:3)=p g1(xi, lx
),
i
i(cid:3)=p g2(xi, lx
), ...,
i
i(cid:3)=p gm(xi, lx
))
i
the model computed by retraining on the training data exclud-
ing xp. For timeliness, it is also much faster than retraining
(cid:2)
k is easy: simply subtract gk(xp, lxp
)
because (1) computing G
from Gk and (2) there are only a constant number of summa-
tions Gk.
We now illustrate how to convert a non-adaptive SQ learn-
ing algorithm into this summation form using na¨ıve Bayes
as an example. Given a sample with features F1, F2,
...,
and Fk, na¨ıve Bayes classiﬁes the sample with label L if
P (L|F1, ..., Fk), the conditional probability of observing label
L on a training data sample with all these features, is bigger
than this conditional probability for any other label. This
conditional probability is computed using Equation 1.
(cid:3)k
(cid:3)k
i=0 P (Fi|L)
P (L|F1, ..., Fk) = P (L)
i=0 P (Fi)
(1)
We now convert each probability term P in this equation
into summations. Consider P (Fi|L) as an example. It
is
computed by taking (1) the number of training data samples
with feature Fi and label L, denoted NFi,L, and dividing by
(2) the number of training data samples with label L, denoted
NL. Each counter is essentially a very simple summation of
a function that returns 1 when a sample should be counted
and 0 otherwise. For instance, NL is the sum of an indicator
function gL(x, lx) that returns 1 when lx is L and 0 otherwise.
Similarly, all other probability terms are computed by dividing
the corresponding two counters. P (L) is the division of NL
over the total number of samples, denoted N. P (Fi) is the
division of the number of training data samples with the
feature Fi, denoted NFi, over N.
To unlearn a sample, we simply update these counters and
recompute the probabilities. For instance, suppose the training
sample to unlearn has label L and one feature Fj. After
unlearning, P (Fj|L) becomes NFj L−1
NL−1 , and all other P (Fi|L)s
−1
NL−1. P (L) becomes NL−1
N . P (Fj) becomes NFj
become NFi L
N−1 ,
and all other P (Fi)s become NFi
N−1.
B. Adaptive SQ Learning
An adaptive SQ learning algorithm issues its SQs iteratively
on the ﬂy, and later SQs may depend on results of earlier
ones. (Non-adaptive SQ learning is a special form of adaptive
SQ learning.) Operationally, adaptive SQ learning starts by
selecting an initial state s0, randomly or heuristically. At
state sj,
it determines the transformation functions in the
SQs based on the current state, sends the SQs to the oracle,
receives the results, and learns the next state sj+1. It then
repeats until the algorithm converges. During each iteration,
the current state sufﬁces for determining the transformation
functions because it can capture the entire history starting
from s0. We represent these functions in each state sj as
gsj ,1, gsj ,2, ..., gsj ,m. Now, the algorithm is in the following
form:
(cid:2)
(1) s0: initial state;
(2) sj+1 = Learn(
));
,
,m(xi, lx
∈X gs
x
j
i
i
(cid:2)
(cid:2)
∈X gs
j
,1(xi, lx
),
i
x
i
∈X gs
j
,2(xi, lx
),...
i
x
i
(3) Repeat (2) until the algorithm converges.
The number of iterations required for the algorithm to con-
verge depends on the algorithm,
the initial state selected,
and the training data. Typically the algorithm is designed to
robustly converge under many scenarios. This adaptive form
of SQ learning encompasses many popular machine learning
algorithms, including gradient descent, SVM, and k-means.
Unlearning this adaptive form is more changing than non-
adaptive because, even if we restart from the same initial state,
468468
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:45 UTC from IEEE Xplore.  Restrictions apply. 
if the training data sample to forget changes one iteration,
all subsequent iterations may deviate and require computing
from scratch. Fortunately, our insight is that, after removing a
sample, the previously converged state often becomes only
slightly out of convergence. Thus, unlearning can simply
“resume” the iterative learning algorithm from this state on
the updated training data set, and it should take much fewer
iterations to converge than restarting from the original or a
newly generated initial state.
Operationally, our adaptive unlearning approach works as
follows. Given the converged state S computed on the original
training data set, it removes the contributions of the sample
to forget from the summations that Learn uses to compute S,
similar to unlearning the non-adaptive form. Let the resultant
(cid:2) meets the algorithm’s
(cid:2). Then, it checks whether S
state be S
(cid:2) as the initial state and
convergence condition. If not, it sets S
runs the iterative learning algorithm until it converges.
We now discuss the completeness of our adaptive unlearning
approach in three scenarios. First, for algorithms such as SVM
that converge at only one state, our approach is complete
because the converged state computed from unlearning is the
same as that retrained from scratch. Second, for algorithms
such as k-means that converge at multiple possible states, our
(cid:2) is a possible initial state se-
approach is complete if the state S
lected by the algorithm (e.g., the algorithm selects initial state
(cid:2) is a possible
randomly). A proof sketch is as follows. Since S
initial state, there is one possible retraining process that starts
(cid:2) and reaches a new converged state. At every iteration
from S
of this retraining process, the new state computed by Learn is
identical to the state computed in the corresponding iteration in
unlearning. Thus, they must compute the same exact converged
state, satisfying the completeness goal (§III-A1). Third, our
(cid:2) cannot be a possible
approach may be incomplete if (a) S
initial state (e.g., the algorithm selects initial state using a
(cid:2)) or (b) the algorithm does
heuristic that happens to rule out S
not converge or converges at a state different than all possible
states retraining converges to. We expect these scenarios to be
rare because adaptive algorithms need to be robust anyway for
convergence during normal operations.
that
Our adaptive unlearning approach is also timely. The
speedup over retraining is twofold. First, unlearning is faster
at computing the summations if there are old results of
the summations to use. For example, it updates the state S
by removing contributions of the removed sample. Second,
unlearning starts from an almost-converged state, so it needs
fewer iterations to converge than retraining. In practice, we
expect
the majority of the speedup comes from the
reduced number of iterations. For instance, our evaluation
shows that, on average, PJScan retraining needs 42 iterations
while unlearning only 2.4, a speedup of over 17x (§IX).
The implication is that, in principle, our adaptive unlearn-
ing approach should speed up any robust iterative machine
learning algorithm, even if the algorithm does not follow SQ
learning. In practice, however, very few practical learning
algorithms cannot be converted to the adaptive SQ learning
form. Speciﬁcally, many machine learning problems can be
cast as optimization problems, potentially solvable using gra-
dient descent, an adaptive SQ learning algorithm. Thus, we
used adaptive SQ learning to represent the more general class
of iterative algorithms in our discussion.
Now, we illustrate how to convert an adaptive SQ learning
algorithm into the summation form using k-means clustering
as an example. K-means clustering starts from an initial set
of randomly selected cluster centers, c1, ..., ck, assigns each
data point to a cluster whose center has the shortest Euclidean
distance to the point, and then updates each ci based on the
mean value of all the data points in its cluster. It repeats this
assignment until the centers no longer change.
To support unlearning, we convert the calculation of each ci
into summations. Because k-means clustering is unsupervised,
labels are not involved in the following discussion. Let us
deﬁne gci,j(x) as a function that outputs x when the distance
between x and ci is minimum, and otherwise 0; and deﬁne
(cid:2)
(x) as a function that outputs 1 when the distance between
g
j
x and ci is minimum, and otherwise 0. Now, the new ci in
x∈X gci ,j (x)
the j + 1 iteration equals
(x).
(cid:2)
x∈X g
x∈X gci,j(x) and
To unlearn a sample xp, we update
(xp) from
x∈X g
the summations. Then, we continue the iteration process until
the algorithm converges.
(x) by subtracting gci,j(xp) and g
(cid:2)
ci,j
(cid:2)
ci,j
(cid:2)
(cid:2)
(cid:2)
(cid:3)
ci ,j
V. EVALUATION METHODOLOGY AND RESULT SUMMARY
To evaluate our unlearning approach, we chose four real-
world systems whose purposes range from recommendation to
malicious PDF detection. They include both open-source and
closed-source ones, covering six different learning algorithms.
We focused on real-world systems because they do not use just
the standard learning algorithms studied by Chu et al. [33] or
have just one learning stage [73]. We believe this diverse set
of programs serves as a representative benchmark suite for our
approach. We brieﬂy describe each evaluated system below.
• LensKit [39] is an open-source recommendation system
used by Confer (a conference recommendation website),
MovieLens (a movie recommendation website), and Book-
Lens (a book recommendation website). LensKit’s default
recommendation algorithm is a ﬂexible, fast item-item col-
laborative ﬁltering algorithm from Sarwar et al. [63] and
Deshpande et al [37]. This algorithm ﬁrst infers similarities
of every two items based their user ratings. Then, if a user
likes another item, it recommends the most similar items to
the user.
• Zozzle [35] is a closed-source JavaScript malware detec-
tor. Its learning has two stages: (1) a chi-squared test to
select features and (2) a na¨ıve Bayes classiﬁer to classify
JavaScript programs into malicious or benign. Its algo-
rithms have been adopted by Microsoft Bing [42]. Since
Zozzle is closed-source, we obtained an independent re-
implementation [21]. This re-implementation was also used
in our prior work [30].
• The system described in Gao et al. [46] is an open-source
OSN spam ﬁlter. It uses manually selected features and a
469469
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:45 UTC from IEEE Xplore.  Restrictions apply. 
TABLE I: Summary of Unlearning Results. Note that m is the number of items, n is the number of users, q is the number of features, N is
the size of training data set, p and l are numbers between 2 and 3, and k is a number between 0 and 1. See the next four sections for more
details on these symbols.
System Attack
Summation?
LensKit
Zozzle
OSNSF
PJScan
Old
New
New
New




Complete-
ness
100%
100%