:
DW[1,k,j,i]
AP[ib]
Sin
分布一个经过条状挖掘的循环
(0),
T*AP[ib];
i-ii+1;
T*(DW[1,k,j,i]+DW[1,k-1,j,i])...;
T*AP;
···，
AP[ib] ;
..AP[ib]-AM*D[ib,k-1] ...;
-ii+1;
(4).
（4),
(0)， s (1).
b)转换得到的顺序
Sn(5), sm(6), sm(7),
第11章
口
---
## Page 581
算法11.72
设备，比如第三层高速缓存或物理内存。
到最内层块中。
个语句，找出具有数据复用的外层并行循环的维度。
算法11.71在一个单处理器系统上优化数据局部性。
的并行性和局部性进行了优化。
11.10.4合成
4）对每个带有数据复用的外层并行循环，重复使用基本的交织方法，把一个迭代分块移动
算法11.71对一个单处理器系统的局部性进行了优化，而算法11.72 则对一个多处理器系统
并行性和局部性优化
输入：一个带有仿射数组访问的程序。
7）在必要的地方按照块的边长扩展标量或者数组。
输出：一个最大化并行性和数据局部性的等价程序。
6）对外层完全可交换循环嵌套结构进行分块，其目的是利用内存层次结构中的更高层存储
方法：执行下列步骤：
5）对位于那些带有复用的最内层的完全可交换循环中的维度的子集应用分块技术。
3）利用11.5节中描述的技术，确定可能共享相同数据或高速缓存线的迭代子空间。对于每
2）
方
输
输入：一个带有仿射数组访问的程序。
法：执行下列步骤：
出：一个最大化数据局部性的等价程序。
应用算法11.68 在可能的时候收缩数组。
应用算法11.64来优化计算结果的时间局部性
针对多处理器系统优化并行性和数据局部性。
图11-67对图11-23的代码进行分划、数组收缩和分块后所得的部分代码
for (i = i; i=2, k--）{
DW[1,2,j,i] = T*DW[1,2,j,i];
D[2,ib]
AP[ib]
[ib]
I :0=1) 
(i=0：
i<n;
.
第11章
口
---
## Page 583
11.11.4数据预取
可能需要一些额外的用于移动数据的指令。
重要的数字信号处理的算法，比如Viterbi 解码器和快速傅里叶变换。要利用 SIMD 指令的话，有
齐所有的数据。第二，一个循环的连续迭代所使用的数据可能不是连续的。这种例子包括很多
有附加的代码来计算边界上的元素。但是对于在多个数组上运算的循环，就有可能无法同时对
比如，它们可能要求将 256字节的 SIMD 运算分量放在为256 的倍数的地址上。如果源循环只在
起来。
置上运算的独立分划单元时，就对这些迭代进行条状挖掘，并把最内层循环中的运算交织
理器可以把 SIMD 和多指令发射结合起来以获取更好的性能。
们存放在宽寄存器中，并使用并行硬件来计算它们。很多媒体、图形和数字信号处理应用可以利
的结果都计算完成。不仅如此，在具有散播/收集(scatter/gather)硬件的先进计算机中，向量的元
向量的元素被串行获取，对不同元素的计算相互重叠。在先进的向量计算机中，向量运算可以
况下，
11.11.3向量和SIMD指令
利用所有的功能单元。
环因为计算量而受到制约。比较好的做法是把这些例子中的循环对融合到一起，以便同时充分
一个数据数组上运算，我们可以生成一个主循环来处理对齐的数据，而这个循环的前面和后面都
用
素
环短到可以充分利用硬件资源就足够了。
可以交换这两个循环，使得内层循环变成可并行化的，从而创造出更多的指令级并行化机会。
的环。假设一个程序有两个循环，其中的外层循环是可并行化的，而内层循环不可并行化。我们
改变最内层循环的组成，我们可以改进这些限制。
流水线化循环的性能受到两个因素的限制：先后关系约束中的环，以及对关键资源的使用。通过
11.11.2
的代码。
器可同时在其他数据上执行运算。在这些情况下，我们可以使用类似的技术来生成移动数据
目这些运算。低端媒体处理器只需要一次发射一个 SIMD 指令就可以获得指令级并行性。高端处
不要求是连续的，可以用一个下标向量确定这些元素该放在哪里。
起来：当生成结果向量的元素时，它们立刻被另一个向量指令的运算消耗掉，不需要等待所有
-个循环只使用加法器，而另一个只使用乘法器。假设一个循环因为内存而受到制约，另一个循
、我们也可以通过改进一个循环中资源使用的平衡性来放松因资源使用而引起的限制。假设
意，我们并不要求最内层循环的迭代之间一定是完全可并行化的。只要其依赖关系所确定的
并行性和局部性优化
生成 SIMD 指令有两个难点。首先，有些机器要求从内存中获取的 SIMD 数据是位对齐的。
 SIMD 及向量指令生成和数据局部性优化之间具有很多相似性。当我们找到在连续内存
SIMD 指令指定了对连续内存位置执行的相同运算。这些指令从内存中并行加载数据，把它
前面提到过，很多早期的超级计算机使用了向量指令。向量运算以流水线化的方式执行，
首先，我们可以使用循环转换来创立最内层的可并行化循环，从而完全消除先后关系约束
 我们也可以使翔仿射循环转换来优化多指令发送计算机的性能。10.5 节讨论过，--个软件
，发送一个指令可以对-一个数据向量的所有元素进行相同运算。
除了多指令问题之外，还有其他两种重要的指令级并行性：向量和 SIMD 运算。在这两种情
多指令发送处理器
567
有
该
---
## Page 584
11.12第11章总结
算的同时提前预取6个迭代。尾声部分没有预取指令，只是直接执行余下的迭代。
获取了前6个迭代中使用的数据，稳定状态循环在它进行计
在数据被使用的六个迭代之前预取数据。流水线的前言部分
存线发出一个预取指令。我们使用软件流水线化概念来保证
令的代码。
选代的执行时间。图11-68中显示了这个例子的使用预取指
的数据，而---个预取指令的延时大约等于上面的循环中六次
假设目标机器有一个预取指令。该指令可以一次预取两个字
例11.73
缓存了。
还需要使用的数据转移出高速缓存，而预取到的数据也可能会因此在使用之前就被调出高速
经在高速缓存中了。但是，我们不应该过早地发出预取指令。预取指令可能会把高速缓存中
存线发出---个预取指令。我们必须足够早地发出预取指令，以保证在使用这个数据时，它
令时，有两个重要问题需要考虑。如果将要访问连续的内存位置，我们只需要为每个高速缓
有在高速缓存中，期望能把它加载到高速缓存中。
用。数据预取指令被用来向处理器指明某些数据有可能很快就会被用到，因此如果它现在还没
内存中获取。为了隐藏内存访问的延时，预取指令（prefetch instruction）被很多高性能处理器采
我们把最内层的循环展开两次，使得可以为每个高速缓
 11.5 节中描述的复用分析可以用于估计什么时候可能发生高速缓存脱靶。当生成预取指
568
·Fourier-Motzkin 消除算法。对迭代空间的关键操作之一是把定义该空间的各个循环重新排
●数组的并行性和局部性。对于并行性和基于局部性的优化而言，最重要的机会来自于访
为一个多面体。而上面的问题可以被表示为一个特定的矩阵－向量方程是否具有位于该
的一个中心问题是确定两个数组访问之间是否具有数据依赖关系(也就是它们是否可能
数据依赖与数组访问。在为了并行性和局部性优化的目的而处理循环时，我们需要解决
一个给定变量的上下界替换成为关于这些界限的不等式。
列。这么做要求把一个多面体迭代空间投影到它的部分维度上。Fourier-Motzkin 算法把
多面体。
仿射情况下，各个循环下标的界限是较外层循环下标的线性函数，因此迭代空间是一个
点都是值的d元组，元组中的值对应于该嵌套循环结构运行时各个循环下标的取值。
迭代空间：一个具有d个循环的循环嵌套结构定义了一个d维的迭代空间。该空间中的
射的：这些数组下标的表达式是循环下标的线性函数。
仿射访问。几乎所有的并行化及数据局部性优化的理论和技术都假设对数组的访问是仿
性，高效使用缓存。
并且通常按照一个正则的模式访问数组元素。这些因素使程序可以获得很好的数据局部
问数组的循环。在这些循环中，对数组元素的各个访问之间的依赖关系通常是有限的,
for（i=O;
考虑下面的代码：
图11-68
for