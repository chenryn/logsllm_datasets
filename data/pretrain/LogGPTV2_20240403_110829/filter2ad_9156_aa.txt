# 零、前言
在社区看到了这篇日志分析的文章--[《Web日志安全分析浅谈》](https://xianzhi.aliyun.com/forum/topic/1121?accounttraceid=9ef7efd4-0316-406a-9129-88852da08abc
"《Web日志安全分析浅谈》")，文章整体写的非常棒，对日志分析的作用、难点、工程化建设和攻击溯源等方面进行了全面的描述。去年的毕设我也做了相关的研究，主要是去实现一个日志分析系统，算是一个更加的完整的工程化建设，这里把一些关键的过程与大家分享。
# 一、系统设计
在开发一个项目之前当然要先做好设计，明白自己想要的是一个什么系统，可以使用哪些技术、算法和硬件设备。我们分成功能设计、数据库设计、算法结构设计、硬件拓扑设计、前端界面设计、主框架设计6个部分。
## 1.1功能设计
系统应包括系统监控、用户管理（系统使用人员）、日志管理、实时分析、离线分析等功能，并为用户提供可视化的操作、分析与结果展示界面。功能结构图如图所示：  
## 1.2数据设计
系统使用MySQL数据库，库中需要建立logmanagement数据库，拥有user、offline、online三个数据表，分别为用户表、离线数据表、在线数据表。数据库中的数据表如下：  
offline数据表用于存储离线日志的分析结果，每一个上传的日志文件对应一条记录，包括名称、大小、类型、起止日期、访问量最高的前10个IP地址、访问量最高的前10个URL、10大攻击类型的攻击次数、以及攻击者和被攻击者的地理位置信息。数据表结构如下：  
online数据表用于存储实时分析的中间结果，数据表的结构如下：  
user表是管理员的用户表，用来存储管理员的个人信息。  
## 1.3算法结构设计
系统使用了三种机器学习算法进行恶意攻击的识别：逻辑回归、支持向量机和朴素贝叶斯。同时包含了传统的正则匹配算法，正则虽然无法识别未知攻击，但是在已知攻击的识别上误报率相对机器学习是比较低的。为了能够识别爆破、目录扫描等与时序有关的攻击，还应设计数值统计模块进行恶意ip访问频率的计算。此外，多种算法如何结合需要进行足够的实验，谁的权重（对结果的影响）更大？并行还是串行？本系统中对正则匹配、数值统计和机器学习（三种机器学习算法两两取交集，即实行投票机制，三种中两者检测出异常则认为异常）进行串行处理，得出一条日志的识别结果
--正常或恶意（具体到攻击类型），然后检测结果（而非日志）存储到数据库中，算法结构如图所示：  
## 1.4硬件拓扑设计
为了实现系统对日志的高效收集，使用了Flume框架；为了具有大数据的处理能力，使用了Spark和HDFS做计算和存储。其中Flume与HDFS是完美兼容的，可以很方便的实现实时日志收集。这几个框架都是分布式的，结构大概如下所示  
## 1.5前端界面设计
为了提供一个良好的用户交互性能，需要一个便捷的可视化界面，这里选用Flask框架开发一个Web管理平台，包含对服务器状态的监控、日志的管理以及分析结果的可视化等。
## 1.6主框架设计
主框架要能够说明系统的总体功能及数据流走向，其中，日志获取有两种途径，Web界面负责接收用户的离线上传，Flume负责实时获取；HDFS负责日志存储，自动将获取（离线和实时）的日志备份到各个节点上；Spark负责日志处理，运行特征匹配、数值统计和机器学习算法对其进行识别和分类；MySQL负责结果存储，根据日志获取途径，存储到不同的表中；Flask和Echarts负责界面展示与操作，使用多种图表样式，形象化地展示分析结果。如图所示：  
离线分析就是用户通过Web界面将文本日志文件上传进行分析，相对简单，实时分析就需要严格控制数据流的走向。这里就像一个生产者与消费者的模型，Flume不断收集日志（生产）存储到HDFS，Spark
Streaming不断的从HDFS读取日志（消费），实时结构如下：  
# 二、系统实现
## 2.1日志预处理
我们知道一条日志大概是这样的
    115.28.44.151 - - [28/Mar/2014:00:26:10 +0800] "GET /manager/html HTTP/1.1" 404 162 "-" "Mozilla/3.0 (compatible; Indy Library)"
字段含义为：远程IP - 用户名 时间 请求主体 响应码 请求字节 请求来源 客户端信息  
想要对日志进行识别分析，首先要对各字段进行提取，其中攻击识别主要依靠“请求主体”，我们可以如下正则进行提取
    log_Pattern = r'^(?P.*?) - (?P.*) \[(?P.*?)\] "(?P.*?)" '\
            '(?P.*?) (?P.*?) "(?P.*?)" "(?P.*?)"$'
## 2.2正则匹配
算法的匹配正则来自与网络和一些CMS厂商的的正则代码，经过多次修改测试可以识别常见的已知的Web攻击，包括SQL注入、XSS攻击、命令执行等常见Web漏洞。比如部分正则如下所示：
    self.SQL_pattern = """/select(\s)+|insert(\s)+|update(\s)+|(\s)+and(\s)+|(\s)+or(\s)+|delete(\s)+|\'|\/\*|\*|\.\.\/
            |\.\/|union(\s)+|into(\s)+|load_file(\s)+|outfile(\s)+"""
    self.Webshell_pattern = """(preg_replace.*\/e|`.*?\$.*?`|\bcreate_function\b|\bpassthru\b|\bshell_exec\b|\bexec\b|
            \bbase64_decode\b|\bedoced_46esab\b|\beval\b|\bsystem\b|\bproc_open\b|\bpopen\b|\bcurl_exec\b|\bcurl_multi_exec\b|
            \bparse_ini_file\b|\bshow_source\b|cmd\.exe|KAdot@ngs\.ru|小组专用大马|提权|木马|PHP\s?反弹|shell\s?加强版|
            WScript\.shell|PHP\s?Shell|Eval\sPHP\sCode|Udp1-fsockopen|xxddos|Send\sFlow|fsockopen\('(udp|tcp)|SYN\sFlood)|
            z0|z1|z2|z9|caidao"""
    self.XSS_pattern = """xss|javascript|vbscript|expression|applet|meta|xml|blink|link|style|script|embed|object|
            iframe|frame|frameset|ilayer|layer|bgsound|title|base|onabort|onactivate|onafterprint|onafterupdate|
            onbeforeactivate|onbeforecopy|onbeforecut|onbeforedeactivate|onbeforeeditfocus|onbeforepaste|onbeforeprint|
            onbeforeunload|onbeforeupdate|onblur|onbounce|oncellchange|onchange|onclick|oncontextmenu|oncontrolselect|
            oncopy|oncut|ondataavailable|ondatasetchanged|ondatasetcomplete|ondblclick|ondeactivate|ondrag|ondragend|
            ondragenter|ondragleave|ondragover|ondragstart|ondrop|onerror|onerrorupdate|onfilterchange|onfinish|onfocus|
            onfocusin|onfocusout|onhelp|onkeydown|onkeypress|onkeyup|onlayoutcomplete|onload|onlosecapture|onmousedown|
            onmouseenter|onmouseleave|onmousemove|onmouseout|onmouseover|onmouseup|onmousewheel|onmove|onmoveend|onmovestart|
            onpaste|onpropertychange|onreadystatechange|onreset|onresize|onresizeend|onresizestart|onrowenter|onrowexit|
            onrowsdelete|onrowsinserted|onscroll|onselect|onselectionchange|onselectstart|onstart|onstop|onsubmit|
            onunload(\s)+"""
所有的攻击类型如下所示  
## 2.3数值统计
在所采集海量日志文本中，包含了大量用户行为、交互IP、访问次数等信息，这些信息所表现出的统计特征可以明确地表达一个网络动作，而有些动作通过传统的规则匹配、黑白名单、策略控制等方式是很难发现的。比如在一段时间内访问目标网站的Agent连接数、不同域名下出现同一URL的次数、访问应答结果中非200的请求比例等，所有这些统计结果都表达了某种特定的网络行为，而这一行为如果符合网络攻击的行为，则通过数值统计的方法就能发现。比如下表中列举的常用的基于数值统计的方式发现潜在异常行为的一些统计方法。  
在实现中只进行了一定时间内某ip访问频率的计算
    def check(self,dataRDD,sc):
        """按分钟切割日志，以判断访问频率"""
        data_Memory = dataRDD.collect()
        start = data_Memory[0]
        temp_Time = time.strptime(start[2], "%d/%m/%Y:%H:%M:%S")
        start_Time = datetime.datetime(temp_Time[0],temp_Time[1],temp_Time[2],temp_Time[3],temp_Time[4],temp_Time[5])
        data_Min = [] #用来存储一分钟内切割的数据
        data_Result = []
        label = self.label
        for line in data_Memory:
            temp_Time = time.strptime(line[2], "%d/%m/%Y:%H:%M:%S")
            end_Time = datetime.datetime(temp_Time[0],temp_Time[1],temp_Time[2],temp_Time[3],temp_Time[4],temp_Time[5])
            if (end_Time-start_Time).seconds <= 10:
                data_Min.append(line)
            else:
                data_Result += label(data_Min)
                start_Time = end_Time
                data_Min = []
                data_Min.append(line)
        tempRDD = sc.parallelize(data_Result)
        return tempRDD
## 2.4特征向量
使用机器学习算法的前提是构造好的特征向量，日志的识别主要是针对日志记录中的request、referer和user-agent。request、referer都是URL路径，user-agent是浏览器名称，这三部分是用户可控且可能注入payload的地方。向量的构造方法主要参考[用机器学习玩转恶意URL检测](http://www.freebuf.com/articles/network/131279.html
"用机器学习玩转恶意URL检测")
和[基于机器学习的web异常检测](http://www.freebuf.com/articles/web/126543.html
"基于机器学习的web异常检测")，训练集分为两个部分，一个是恶意的在URL请求，主要收集于github中知名的payload仓库，大约有30000条数据，其中包括SQL注入、Traversal（目录遍历）、XSS（跨站脚本攻击）、LFI（本地文件包含）、XML注入、SSI注入、XPATH注入、Webshell攻击。恶意请求部分样例如下：  
二是正常的URL请求，测试部分包括日志中的request、referer和user-agent，其中request和referer的正常样本基本一致，都是URL请求地址，user-agent虽然并不是URL但在受到攻击时仍和request、referer这两处相似，都是注入相关漏洞的payload，所以这三处在分类的可以使用相同模型。其中正常的URL取自国外的日志网站SecRepo的正常Web日志，正常请求部分样例如下：  
User-agent是指了各大浏览器厂商正常的名称，训练集中正常请求部分样例如下：  