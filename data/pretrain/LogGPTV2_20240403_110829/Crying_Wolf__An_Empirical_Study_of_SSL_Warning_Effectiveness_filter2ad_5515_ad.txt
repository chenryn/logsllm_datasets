factors were determined by a single exit survey ques-
tion (e.g. gender, nationality). Technical sophistica-
tion was measured by a composite score of ﬁve ques-
tion, the same as in the online survey. Similarly, cy-
berthreat exposure was measured by asking partici-
pants if they have ever had any account information
stolen, found fraudulent transactions on bank state-
ments, had a social security number stolen, or if they
had ever been notiﬁed that personal information had
been stolen or compromised.
Our participants were technically sophisticated,
mostly male, and mostly foreign students. We had 68
male and only 32 female participants. All of our par-
ticipants were between the ages of 18–30, and all but
two were students. Sixty-nine participants were born
in India, 17 in the United States, and the remaining
were from Asia (10) and Europe (4). The average
tech score was 1.90, which is signiﬁcantly larger than
the 0.66 average among the survey respondents.
We do not have a large enough sample size to de-
termine whether age, profession, or nationality inﬂu-
enced participant behavior. In addition, our partici-
pants had so little cyberthreat exposure—83 partici-
pants answered aﬃrmatively to 0 out of 4 questions—
that we could not determine if exposure correlated
with our results. On the other hand, while our sam-
ple was large enough to observe behavioral diﬀerences
based on gender and technical sophistication if large
diﬀerences existed, we observed no statistical diﬀer-
ences in participant behavior based on those factors.
Finally, we found no statistical diﬀerence in behavior
based on task order in any of the conditions.
4.2.2 Eﬀect of Warning Design on Behavior
Our study focused on evaluating whether SSL warn-
ings eﬀectively prevent users from transmitting sen-
sitive information to suspicious websites, while allow-
ing them to continue in the event of a false positive.
We hypothesized that participants visiting the
bank website who see our redesigned warnings would
be signiﬁcantly more likely to discontinue than par-
ticipants who see the other warnings. We used a one-
tailed Fisher’s exact test to analyze our results. We
found that signiﬁcantly more participants obeyed our
single page warning than obeyed the FF2 and IE7
warnings (p < 0.0029 for both comparisons). Simi-
larly, our multi-page warning performed better than
the FF2 and IE7 warnings (p < 0.0324). However,
FF3 was equivalently preventative, and it was also
signiﬁcantly better than the FF2 and IE7 warnings
(p < 0.0155).
We also hypothesized that participants visiting the
library website who see our redesigned warning will
be signiﬁcantly more likely to continue than partic-
ipants who see the other warnings. In this case our
hypothesis turned out to be mostly false. Partici-
pants who viewed our multi-page warning were sig-
niﬁcantly more likely to use the library website than
participants who saw the FF3 warning (p < 0.0098).
However, users of our multi-page warning visited the
library website at an equal rate to users of the FF2
and IE7 warnings. Our single page warning was not
signiﬁcantly diﬀerent than any of the other warn-
ings. The FF3 warning caused signiﬁcantly more
participants to call the library than the FF2 warn-
ing (p < 0.0098) or the IE7 warning (p < 0.0016).
Two participants in the FF3 condition and one in
our multi-page warning condition thought the library
and bank servers were down or that we had blocked
their websites. One wrote in the exit survey “the
graphics made me feel the server was down” and an-
other wrote “I just saw the title and assumed that it
is just not working on this computer.” We suspect
that users confuse the warnings with a 404 or server
not found error, like the one shown in Figure 5. The
site. Because this warning took context into account
in determining severity, it appeared to be more se-
vere on the bank website. All 14 participants in our
study who heeded the library warning also heeded
the warning at the bank. An additional 18 partici-
pants heeded the bank warning and proceeded past
the library warning. Participants who viewed our
multi-page warning (p < 0.0098) and our single-page
warning (p < 0.0242) were signiﬁcantly more likely
to heed the warning at the bank than at the library.
We believe the behavior exhibited by users of our
single page warning can be explained both by its suc-
cess in raising awareness of risk and its clear com-
munication of what users should do in response to
the risk. When the 11 participants who heeded the
single-page bank warning were asked in the exit sur-
vey “Why did you choose to heed or ignore the warn-
ing?” 9 out of 11 speciﬁcally mentioned the security
of their information as the reason. In contrast only 2
participants in each of the FF2, FF3, and IE7 condi-
tions mentioned risk in response to the same question.
In addition, 10 of the 20 participants in our single-
page warning condition when asked, “What action(s)
did you think the warning at the bank wanted you to
take?” responded that it wanted them not to pro-
ceed. Only 3 FF2, 2 FF3, and 4 IE7 participants
answered the same way.
4.2.4 Impact of Reading and Understanding
In each of the ﬁrst two sections of the exit sur-
vey we asked participants if they “read the text
of the warning at the bank/library website.” At
the bank website, signiﬁcantly more people read our
multi-page warning than the FF2 (p < 0.0128), FF3
(p < 0.0018), or IE7 (p < 0.0052) warnings (Table 6).
There were no other signiﬁcant diﬀerences in reported
readership across conditions or tasks. We used a chi-
square test to see if there was a diﬀerence in how
reading aﬀected behavior. Among the participants
who did not read the warnings, FF2 and IE7 users
were signiﬁcantly more likely to log in to the bank
4 = 13.56, p < 0.009), whereas FF3 users
website (χ2
were signiﬁcantly less likely to log in to the library
website (χ2
4 = 18.38, p < 0.001).
The exit survey asked participants “what did
Figure 5: Screenshot of server not found error in FF3.
warnings have very similar layouts and coloring. The
yellow Larry icon in the FF3 warning (Figure 3) and
the ﬁrst page of our multi-page (Figure 4(a)) warning
is similar to the yellow triangle in Figure 5.
We took careful note of how participants in the
multi-page warning condition answered the question
“What type of website are you trying to visit?” pre-
sented to them on the ﬁrst page of the warning. Fif-
teen participants answered exactly as expected – they
selected “other” for the library and “bank or other
ﬁnancial institution” for the bank. The remaining
ﬁve participants exhibited noteworthy behaviors: one
participant did not answer the question for either
task, while three participants performed the library
task ﬁrst and appropriately answered “other,” but
also inaccurately answered “other” when visiting the
bank website. This is stark evidence of the ill-eﬀects
of warning habituation – these participants learned
how to ignore the warning in the library task and im-
mediately reapplied their knowledge to the bank task.
Finally, one participant ﬁrst performed the bank task
and correctly answered “bank or other ﬁnancial insti-
tution.” However, when she saw the second page of
the warning she clicked the back button and changed
her answer to “other.”
4.2.3 Risk Perception in Context
We hypothesized that participants who viewed our
multi-page warning would be more likely to obey
the warnings when they were visiting the bank web-
site than when they were visiting the library web-
Condition
Read
Didn’t Read
Logged In Called Logged In Called
Understood
Didn’t Understand
Logged In Called Logged In Called
FF2
FF3
IE7
Single-Page
Multi-Page
4
2
4
4
8
2
2
1
6
6
14
9
14
5
4
0
7
1
5
2
7
4
8
4
7
2
2
2
7
6
11
7
10
5
5
0
7
0
4
2
Table 6: Behavior in the bank task by reading, understanding, and condition.
you believe the warning at the bank/library website
meant?” Answers were entered into a free response
text box and we categorized the responses according
to whether or not they demonstrated understanding
of the warning, as we had done in the survey (Ta-
ble 6).
In particular, participants who wrote that
their connection may be compromised or that the
identity of the destination website could not be ver-
iﬁed were deemed to understand the warning. All
other responses were coded as not understanding the
meaning. There were no signiﬁcant diﬀerences in the
number of participants who understood the warnings
based on condition in either task. However, partici-
pants in the FF3 condition who did not understand
the warning were signiﬁcantly more likely to call than
users in the FF2 (p < 0.0078) and IE7 (p < 0.0188)
conditions. Seven of the 14 participants who did not
understand the FF3 warning called the bank. This
is evidence that the FF3 users may have been pre-
vented from visiting the websites because they did
not know how to override warnings, and not because
they understood the risks of proceeding.
One expects that participants who claimed to have
read the warnings would be more likely to understand
their meaning. When we combined the data from
just our two warnings, single-page and multi-page,
we found a statistically signiﬁcant correlation (p <
0.020). However, we do not have enough data to
determine whether there is a correlation for the three
native warnings (FF2, FF3, and IE7).
4.2.5 Other Observations
One worry for browser designers trying to design ef-
fective warnings is that they will cause users to switch
browsers, in favor of a browser that shows a less se-
Response FF2 FF3
Yes
No
Unknown
7
11
2
8
8
4
IE7
10
5
5
Single Multi
4
16
0
1
16
3
Table 7: Number of participants in each condition
who claimed to have seen the warning before at the
bank.
vere warning. In fact, during our study a few partic-
ipants who viewed our warnings or the FF3 warnings
asked or attempted to perform one of the tasks in
a diﬀerent browser. We directed them to continue
using the browser they had been using. No partici-
pants in the FF2 and IE7 conditions tried to switch
browsers. This indicates that complex warning de-
signs may cause a small number of users to switch
browsers. Therefore, for the sake of these users’ se-
curity, it may be best if all browsers converged on a
single warning design.
Among our strangest results were the answers to
the questions: “Before this study, had you ever seen
the warning you saw at the bank/library web site?”
(Table 7). A total of 30 participants said they had
seen the warning before at the bank website com-
pared to only 16 at the library website. In addition,
5 participants in the bank task thought they had seen
our warnings before. We do not think 30% of our par-
ticipants have been scammed by man-in-the-middle
attacks at their bank and we know for sure that the
5 participants had never seen our redesigned warn-
ings before. This is dramatic evidence of memory
problems, warning confusion, and general confusion
with regard to certiﬁcate errors. At the same time,
it is possible that the novelty of our new warnings
contributed to more participants reading them (and
consequently better understanding the risks of ignor-
ing them). None of the participants who viewed our
new warnings could have seen them before, while our
randomized condition assignments resulted in the two
Firefox conditions being assigned 27 participants who
were pre-existing Firefox users (68% of 40) and the
IE condition being assigned 6 participants who were
existing IE users (30% of 20). Thus, it is likely that
these 33 participants had already been exposed to
the warnings prior to our study, but among our sam-
ple population we observed no signiﬁcant diﬀerences
in behavior among them and the participants in the
IE and FF conditions who were accustomed to using
diﬀerent browsers.
In the exit survey we asked participants to use a
7-point Likert scale to report the inﬂuence of several
factors on their decision to heed or ignore the warn-
ings. The factors we included were: the text of the
warning, the colors of the warning, the choices that
the warning presented, the destination URL, and the
look and feel of the destination website. We expected
signiﬁcantly more participants to grade the color and
text of the website highly for our warnings. How-
ever, there was no statistically signiﬁcant diﬀerence
in participants’ responses based on condition.
5 Discussion
Our warnings somewhat improved user behavior, but
all warning strategies, including ours, leave too many
users vulnerable to man-in-the-middle attacks. The
ﬁve warnings we evaluated embodied three diﬀerent
strategies: explain the potential danger facing users,
make it diﬃcult for users to ignore, and ask a ques-
tion users can answer. The strategies have diﬀerences
that we will discuss later in this section. However, re-
gardless of how compelling or diﬃcult to ignore, users
think SSL warnings are of little consequence because
they see them at legitimate websites. Many users
have a completely backward understanding of the risk
of man-in-the-middle attacks and assume that they
are less likely to occur at trusted websites like those