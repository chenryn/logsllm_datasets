# Master’s Degree in Informatics Engineering
## Final Dissertation
### Observing and Controlling Performance in Microservices

**Author:**
André Pascoal Bento

**Supervisor:**
Prof. Filipe João Boavida Mendonça Machado Araújo

**Co-Supervisor:**
Prof. António Jorge Silva Cardoso

**July 2019**

---

## Abstract

Microservice-based software architectures are increasingly prevalent, and one type of data generated to maintain a history of the system's operations is called tracing data. Tracing can help Development and Operations (DevOps) teams identify issues such as latency and request workflows. However, analyzing this data is challenging due to its complexity, the vast amount of information, and the lack of appropriate tools. Consequently, it becomes difficult for DevOps to analyze system behavior and identify faulty services using tracing data. Current tools primarily focus on making the data more human-readable, but they do not provide effective filtering or analysis capabilities. This manual effort is a significant drawback, as it relies heavily on system administrators. This thesis presents a solution that uses tracing data to extract metrics from the service dependency graph, such as the number of incoming and outgoing calls per service and their corresponding average response times. The goal is to detect and identify faulty services within specific time frames. Additionally, the thesis covers a method for quality tracing analysis by checking the tracing structure against the OpenTracing specification and assessing the time coverage of tracing for specific services. To address the problem, we developed prototype tools to process tracing data and conducted experiments using data provided by Huawei. We anticipate that this proposed solution will lead to the development and integration of advanced tracing data analysis tools in existing distributed tracing systems.

**Keywords:**
Microservices, Cloud Computing, Observability, Monitoring, Tracing

---

## Resumo

A arquitetura de software baseada em microserviços está ganhando cada vez mais adesão, e um dos tipos de dados gerados para manter o histórico das operações do sistema é chamado de dados de rastreamento (tracing). O rastreamento pode ajudar equipes de Desenvolvimento e Operações (DevOps) a identificar problemas como latência e fluxos de trabalho de solicitações. No entanto, analisar esses dados é desafiador devido à sua complexidade, à abundância de informações e à falta de ferramentas adequadas. Consequentemente, torna-se difícil para os DevOps analisarem o comportamento do sistema e identificarem serviços com falhas usando dados de rastreamento. As ferramentas atuais focam principalmente em tornar os dados mais legíveis para humanos, mas não fornecem filtros eficazes ou capacidades de análise. Este esforço manual é uma grande desvantagem, pois depende fortemente dos administradores de sistemas. Nesta tese, apresentamos uma solução que utiliza dados de rastreamento para extrair métricas do grafo de dependências dos serviços, como o número de chamadas de entrada e saída por serviço e seus tempos de resposta médios correspondentes. O objetivo é detectar e identificar serviços com falhas dentro de intervalos de tempo específicos. Além disso, a tese aborda um método para análise de qualidade do rastreamento, verificando a estrutura de rastreamento contra a especificação OpenTracing e avaliando a cobertura temporal do rastreamento para serviços específicos. Para abordar o problema, desenvolvemos ferramentas protótipo para processar dados de rastreamento e realizamos experimentos usando dados fornecidos pela Huawei. Esperamos que esta proposta de solução leve ao desenvolvimento e integração de ferramentas avançadas de análise de dados de rastreamento em sistemas de rastreamento distribuído existentes.

**Palavras-Chave:**
Microserviços, Computação em Nuvem, Observabilidade, Monitorização, Rastreamento

---

## Acknowledgements

This work would not have been possible without the effort, help, and support of my family, colleagues, and friends. I would like to express my sincere thanks to all of them.

Firstly, I am deeply grateful to my mother and my entire family for their unwavering support throughout this long journey. They have always provided me with the most important and beautiful things in life: love and friendship.

Secondly, I would like to thank all the people directly involved in this project. To my supervisor, Professor Filipe Araújo, for his vast wisdom and experience; to my co-supervisor, Professor Jorge Cardoso, for his vision and guidance; and to Engineer Jaime Correia, who has extensive knowledge and enthusiasm in this field and provided invaluable assistance.

Thirdly, I would like to thank the Department of Informatics Engineering and the Centre for Informatics and Systems at the University of Coimbra for providing the resources and facilities necessary for this project.

Fourthly, I extend my gratitude to the Foundation for Science and Technology (FCT) for funding this project, to Huawei for providing the essential tracing data, and to the Portugal National Distributed Computing Infrastructure (INCD) for providing the hardware to run the experiments.

Finally, I would like to thank everyone who has contributed to my growth and success, even if not mentioned here.

---

## Contents

1. Introduction
   1.1 Context
   1.2 Motivation
   1.3 Goals
   1.4 Work Plan
   1.5 Research Contributions
   1.6 Document Structure

2. State of the Art
   2.1 Concepts
      2.1.1 Microservices
      2.1.2 Observability and Controlling Performance
      2.1.3 Distributed Tracing
      2.1.4 Graphs
      2.1.5 Time-Series
   2.2 Technologies
      2.2.1 Distributed Tracing Tools
      2.2.2 Graph Manipulation and Processing Tools
      2.2.3 Graph Database Tools
      2.2.4 Time-Series Database Tools
   2.3 Related Work
      2.3.1 Mastering AIOps
      2.3.2 Anomaly Detection using Zipkin Tracing Data
      2.3.3 Analysing Distributed Trace Data
      2.3.4 Research Possible Directions

3. Research Objectives and Approach
   3.1 Research Objectives
   3.2 Research Questions

4. Proposed Solution
   4.1 Functional Requirements
   4.2 Quality Attributes
   4.3 Technical Restrictions
   4.4 Architecture
      4.4.1 Context Diagram
      4.4.2 Container Diagram
      4.4.3 Component Diagram

5. Implementation Process
   5.1 Huawei Tracing Data Set
   5.2 OpenTracing Processor Component
   5.3 Data Analysis Component

6. Results, Analysis, and Limitations
   6.1 Anomaly Detection
   6.2 Trace Quality Analysis
   6.3 Limitations of OpenTracing Data

7. Conclusion and Future Work

---

## Acronyms

- API: Application Programming Interface
- CPU: Central Processing Unit
- CSV: Comma-separated values
- DEI: Department of Informatics Engineering
- DevOps: Development and Operations
- GDB: Graph Database
- HTTP: Hypertext Transfer Protocol
- JSON: JavaScript Object Notation
- OTP: OpenTracing Processor
- QA: Quality Attribute
- RPC: Remote Procedure Call
- TSDB: Time Series Database

---

## List of Figures

1.1 Proposed work plan for first and second semesters.
1.2 Real work plan for first semester.
1.3 Real and expected work plans for second semester.
2.1 Monolithic and Microservices architectural styles [10].
2.2 Sample trace over time.
2.3 Span Tree example.
2.4 Graphs types.
2.5 Service dependency graph.
2.6 Time-series: Annual mean sunspot numbers for 1760-1965 [25].
2.7 Anomaly detection in Time-Series [27].
2.8 Graph tools: Scalability vs. Algorithm implementation [35].
4.1 Proposed approach.
4.2 Quality Attribute (QA) utility tree.
4.3 Context diagram.
4.4 Container diagram.
4.5 Component diagram.
5.1 Trace file count for 2018-06-28.
5.2 Trace file count for 2018-06-29.
5.3 Service calls samples.
5.4 Service dependency variation samples.
5.5 Service average response time samples.
5.6 Service status code ratio samples.
5.7 Methods to handle missing data [67].
5.8 Trend and seasonality results.
5.9 Isolation Forests and OneClassSVM methods comparison [69].
5.10 Trace time coverage example.
6.1 Sample of detection, using multiple features, of “Anomalous” and “Non-Anomalous” time-frame regions for a service.
6.2 Comparison between “Anomalous” and “Non-Anomalous” service time-frame regions.
6.3 Comparison between “Anomalous” and “Non-Anomalous” service work-flow types.
6.4 Services coverability analysis.

---

## List of Tables

2.1 Distributed tracing tools comparison.
2.2 Graph manipulation and processing tools comparison.
2.3 Graph databases comparison.
2.4 Time-series databases comparison.
3.1 Final state questions groups.
4.1 Functional requirements specification.
4.2 Technical restrictions specification.
5.1 Huawei tracing data set provided for this research.
5.2 Span structure definition.
5.3 Relations between final research questions, functional requirements, and metrics.

---

## Chapter 1: Introduction

### 1.1 Context

### 1.2 Motivation

### 1.3 Goals

### 1.4 Work Plan

### 1.5 Research Contributions

### 1.6 Document Structure