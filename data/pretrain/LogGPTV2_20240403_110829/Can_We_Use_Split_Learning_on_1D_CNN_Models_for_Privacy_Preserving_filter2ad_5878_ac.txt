∂a(l) from the
server. When the client receives the gradient of ∂E
server, the backpropagation continues to the ﬁrst hidden layer.
2) Server.: The server continues forward propagation after
receiving activation from l-th layer. The server then calculates
the loss between the activated output from the last layer and
the label passed from the client. Let E denotes the loss
calculated from the loss function L. With E, the server starts
backpropagation until layer l + 1. The server ﬁnally sends
the gradient of the output to the client, which is
∂a(l) , to
make the client continues the backpropagation. The rest of the
denotations except E and L, are the same as used in Algorithm
1.
∂E
The training ﬂow between the client and the server is
illustrated in Fig. 6 and further detailed in Appendix A.
Fig. 6. Data ﬂow between the client and the server in Algorithm 1 and 2.
3) Inﬂuence on Performance: Based on the implementa-
tion above, we test the split learning on both 1D CNN model
architectures: two-layer model and three-layer model. We split
the former after two convolutional layers and latter after three
convolutional layers. To measure and compare the inﬂuence
of split learning on performance accurately, we initialize both
models before and after the split with the same set of weights.
Fig. 5 depicts the exact accuracy conversion of both models
before/after applying split. It is clear that the accuracy is the
same. In other words, our split learning implementation has
no noticeable impact on the performance of the models.
Summary: Split learning can be applied into 1D CNN without
the model classiﬁcation accuracy degradation as demonstrated
in Fig. 5. Therefore, RQ 1 can be is answered afﬁrmatively.
IV. PRIVACY LEAKAGE ANALYSIS
In this section, we propose a privacy assessment framework
under our identiﬁed threat model to answer the RQ 2: Can
split learning be used to protect privacy in sequential/time-
series data trained using 1D CNN?
This framework has three metrics: visual invertibility, dis-
tance correlation and Dynamic Time Warping. Based on
these metrics, we present our empirical results validated from
0100200300400Epoch70%80%90%100%AccuracyNon-splitTrainTest0100200300400Epoch70%80%90%100%SplitTrainTest0100200300400Epoch70%80%90%100%Non-splitTrainTest0100200300400Epoch70%80%90%100%SplitTrainTest(a)(b)(c)(d)1D CNN with 2 convolutional layers1D CNN with 3 convolutional layersConnectAcceptInitializeInitializeForwardPropagationForwardPropagationBackwardPropagationBackwardPropagationActivationGradientsClient -Algorithm 1Server -Algorithm 2123456789ConnectSynchroniseECGsystematic experiments to demonstrate that it is possible to re-
construct raw data from the activation of the intermediate split
layer, which indicates that our RQ 2 is answered unfavourably.
We ﬁrstly elaborate on the considered threat model.
A. Threat Model
We consider the server is an honest-but-curious single entity
adversary. It performs all
its operations as speciﬁed, but
curious about the raw data localized at the client. We assume
that the server has no access to the client’s device, and it
does not target attacks on those devices. Furthermore, the
server does not collude with any client. The server’s goal is
to reconstruct the raw data (e.g., the client’s medical data)
from the activated vector of the split layer, which is delivered
from the client during the forward propagation. We assume
that all participating clients are trusted, and they participate
in the learning process provided that the raw data always
remain within their custody. In the health domain, examples
of trusted clients are patients, hospitals, and (health) research
organizations.
B. Visual Invertibility
We ﬁrst visualize each channel of the split layer output as an
initial assessment to observe the possibility of reconstructing
the original ECG signals. The model batch size is 32 (i.e., the
number of ECG samples fed to the model) and uses 16 ﬁlters
to extract features. These ﬁlters produce the layer activation,
which is passed to the server from any split layer. Fig. 7
shows 5 different classes of original ECG samples on the top
row vs. the reconstructed version from 5 corresponding ﬁlters
activation after two layers on the bottom row. We can observe
that there is high similarity between them, which means the
possibility of signiﬁcant leakage.
Our framework goes further to generalise this observation
by measuring the correlations between the split layer activation
and original samples. To quantify our results, we employ two
other metrics: distance correlation and Dynamic Time Warping
as explained below.
Fig. 7. Visual invertibility. Top row shows raw input data. Bottom row shows
one of the channels in the output from the second convolutional layer.
6
C. Distance Correlation
In statistics, distance correlation is a measure of dependence
between two paired vectors of arbitrary dimensions. It is on the
scale of 0-to-1. Distance correlation of 0 refers to independent
vectors, whereas 1 means highly dependent and fully similar.
Distance correlation has already been used in the context of
deep learning to measure the autoencoder correlation [14]
and reconstruction of raw data from intermediate layers of
2D CNN [23]. Therefore, we apply distance correlation as a
measure to monitor the dependency between each channel of
split layer output and corresponding raw ECG signal.
The distance correlation of two random variables is assessed
by dividing their distance covariance by the product of their
distance standard deviations, given below (4) [24].
(cid:112)dVar(X) dVar(Y )
dCov(X, Y )
dCor(X, Y ) =
(4)
To get the distance correlation between raw input and the
split layer activation, we ﬁrstly pick 10K of ECG signals from
the dataset. Then we take the average of distance correlations
from 10K samples, which come between raw ECG signal and
split layer output channels. We call this, distance correlation
mean. Because the distance correlation measurement requires
two vectors with same dimension, we apply average down-
sampling on the original ECG signal, to adapt its size to
corresponding split layer output.
Fig. 8. Distance correlation and DTW between raw input and the activated
outputs after two and three 1D convolutional split layers, respectively. Each
dot represents the channel of the split layer output.
Fig. 8 (a) shows the distance correlation mean between 16
channels of the split layer activation and corresponding raw
data. We repeat these experiments after two and three convolu-
tional layers, respectively. Splitting after two layers, the results
suggest that the correlation of the top channels activation is
very high (0.89), which indicates high leakage and can be
exploited to reconstruct the raw data, as shown previously
in Fig. 7, visual invertibility. Similarly, some channels of the
activation after three layers exhibits high dependency, as well.
However, the correlation of the top channels is reduced by
(0.03); from (0.89) to (0.86) between splitting after 2 and 3
layers. This gives us intuition to increase the number of layers
as a mitigation strategy investigated in the next section.
D. Dynamic Time Warping (DTW)
To generalise our observations, we utilize another well-
known similarity measurement in time series analysis called
0641280.00.51.0N0641280.00.51.0L0641280.00.51.0R0641280.00.51.0A0641280.00.51.0V016320.00.81.6N016320.01.53.0L016320.00.81.6R016320.00.81.6A016320.81.2V23Number of 1D Conv. Layers0.20.40.60.81.0Distance Correlation23Number of 1D Conv. Layers010203040DTW(a)(b)LeastLeastMostMostDynamic Time Warping (DTW) [15]. DTW is an algorithm
that can accurately measure the similarity between two tem-
poral sequences, which may vary in speed. It is widely used
in speech recognition and signature recognition.
Given two time series X = (x1, x2, ..., xN ) and Y =
(y1, y2, ..., yM ), represented by a sequence of values, DTW al-
gorithm starts by constructing the distance matrix C ∈ RN×M
representing all pairwise distances between X and Y . This
distance matrix, also called as local cost matrix Cl, for the
alignment of two sequences X and Y is calculated as follows:
Cl ∈ RN×M : cij = (cid:107)xi − yj(cid:107) , i ∈ {1 . . N}, j ∈ {1 . . M}
(5)
Once the local cost matrix is constructed, the algorithm
explores the alignment path (or warping path), which runs
through the low-cost areas. The warping path which has the
lowest cost associated with alignment is called the optimal
warping path. The length of optimal warping path is ﬁnally
used as a measurement of the similarity between X and Y .
Zero-length optimal warping path refers to high similarity,
whereas increasing length of optimal warping path toward,
e.g., 1000 means higher dissimilarity. In this paper, we apply
DTW as a measure to monitor the similarity between each
split layer ﬁlter activation and corresponding raw ECG signal.
For the measurement, we go through the same process
mentioned in Section IV-C but with DTW, and we call
this, DTW mean. Unlike distance correlation, DTW can be
computed although two vectors have different sizes, so we do
not apply any downsampling on the original data in this case.
Fig. 8 (b) shows the mean of DTW between the intermediate
split layer of all 16 channels activation and corresponding
raw data. We also conduct this experiment with split layer
output at second and third convolutional layers, respectively.
Splitting after two layers, DTW indicates that the similarity of
the top channels activation, which also exhibits high leakage
and can be exploited to reconstruct the raw data as visually
shown previously in Fig 7. Similarly, the channels output after
three layers shows high similarity; Again, the top DTW mean
increases by 0.21; from 2.70 to 2.98 between splitting after
two and three layers. Furthermore, the lowest DTW mean
increases signiﬁcantly to more than 30, by adding one more
convolutional layer. This suggests that increasing the number
of layers may reduce the leakage.
Summary: Our leakage analysis framework to test our RQ 2
via three empirical (visual invertibility) and numerical metrics
(distance correlation and DTW) indicates that activated output
after two and three convolutional layers can be used to recon-
struct the raw data. In other words, sharing the intermediate
activation from these layers may result
in severe privacy
leakage. Therefore, RQ 2 is answered unfavourably.
V. MITIGATE THE SHORTCOMING?
To further answer our RQ 2, we investigate a number of
strategies which can be deployed in 1D CNN model to mitigate
the privacy leakage. Speciﬁcally, we apply and evaluate two
mitigation techniques to reduce potential privacy leakage by
i) adding more hidden layers before splitting and ii) applying
7
differential privacy on split layer activation before transmitting
them to the server. We measure the efﬁcacy of mitigation
techniques via both i) privacy leakage reduction using distance
correlation and DTW as well as ii) model accuracy after
applying mitigation techniques.
A. Adding More Hidden Layers
Speciﬁcally, we add more convolutional layers—ranging
from two to eight—to the client before the split layer. In other
words, the model architecture becomes more complex, given
the number of layers held by the server being constant. To
be consistent, the layers to be added use same conﬁguration
as illustrated in III-A2. Each additional convolutional layer
utilizes 16 ﬁlters whose size is 5. Zero padding is applied to
keep the size of output as a power of 2. Moreover, the size of
the ﬁlter used for each newly added hidden convolutional layer
is 5. Leaky ReLU is also selected for newly added layers. We
select activation function as Leaky ReLU, rather than ReLU,
to prevent the dying ReLU problem.
Distance Correlation Mean: Fig. 9 (a) shows the mean of
distance correlation between the intermediate split layer of all
16 channels output and corresponding raw data after second
to eighth convolutional layer. The correlation of each channel
is measured against the corresponding raw ECG signal and
represented as a dot in the ﬁgure. We then sort the distance
correlation mean in descending order on the Y-axis, where
distance correlation of 1 indicates a high risk of leakage, and
0 means low risk. It is clear from the top correlated ﬁlters
that there is a slight reduction in the distance correlation
from (0.89) to (0.69) as the number of hidden convolutional
layers increases; however, there is still some highly correlated
channels whose distance correlation means are above 0.5.
DTW Mean: Fig. 9 (b) further shows the mean of DTW
between the intermediate split layer of all 16 channels acti-
vation and corresponding raw data after second to the eighth
layer. The similarity of each ﬁlter is calculated against the
corresponding raw data ECG and represented as a dot in
the ﬁgure. We again grade the mean similarity in ascending
order from 0 as a high risk of leakage to 600+ as low
risk. It is clear from the channels that there is a signiﬁcant
dissimilarity improvement from zero(0) to (600+) of some
channels; However, DTW means of many other channels are
still close to zero, which indicate high leakage and can be
potentially exploited to reconstruct the raw ECG data.
Distribution: We further investigate the distribution of
distance correlation, as detailed in Fig. 11, which illustrates
two most correlated channels vs. two least correlated channels.
The distance correlation distribution is continuously reduced
but seems ineffective to protect the highly correlated channels.
Similarly, Fig. 12 presents DTW distribution of the most two
correlated channels vs. the least two correlated channels. The
least correlated shows clear improvements by e.g., 84 times;
however, DTW also emphasizes that increasing the number
of layers seems ineffective with the most highly correlated
channels i.e., improved only by 5 times.
8
Fig. 9. Mean of distance correlation and DTW calculated for each channel of the split layer output. Each dot represents the channel of the split layer output.
Thicker the color of dot, higher the similarity between the channel of the split layer output and corresponding raw data.
Fig. 10. Mean and standard deviation of test accuracy as incrementing the
number of convolutional layers from 2 to 8 for split learning.
B. Applying Differential Privacy on Split Layer
As the second mitigation technique, we apply differential
privacy on split layer ﬁlters activation before transmitting them
to the server. Differential privacy has already been widely used
in deep learning to protect privacy [25]. Given input space
X, output space Y , privacy parameter , and a randomisation
mechanism M. We say M : X → Y is -differentially private
if, for all neighbouring inputs X (cid:39) X
and all sets of outputs
S ⊆ Y satisfy the following:
(cid:48)
Pr [M(X) ∈ S] ≤ e × Pr [M(X(cid:48)) ∈ S]
the value of  determines the strength of pri-
Therefore,
vacy. Speciﬁcally, we employ the Laplace differential privacy
mechanism on the split
layer activation, which is widely
used for numerical data [26]. It adds noise from the Laplace
distribution, which can be expressed by a probability density
function. The level of noise relies on pre-determined  on a
scale of 10 (weakest privacy)-to-0 (strongest privacy where the
data cannot be used).
Distance Correlation Mean: Fig. 13 (a) shows the mean
of distance correlation between the intermediate split layer of
all 16 channels activation after applying different  levels of
differential privacy, and corresponding raw data. It is under
the expectation that the strongest differential privacy level of,