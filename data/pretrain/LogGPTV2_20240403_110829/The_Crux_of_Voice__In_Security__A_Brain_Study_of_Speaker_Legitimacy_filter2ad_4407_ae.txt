48.8 (10.7)
46.7 (10.1)
50.0 (11.3)
48.3 (11.1)
49.4 (10.3)
49.0 (12.6)
47.1 (9.5)
Rec
48.8 (10.9)
50.0 (11.9)
48.8 (12.1)
43.8 (11.2)
48.8 (11.1)
54.4 (12.4)
59.1 (13.5)
47.2 (12.9)
52.8 (11.4)
RandomTree
Logistic
J48
NaiveBayes
MultilayerPerceptron
LMT
SimpleLogistic
SMO
RandomForest
VIII. DISCUSSION AND FUTURE WORK
In this section, we summarize and discuss the main ﬁndings
from our work, outline the strengths/limitations of our study
and point to future work. Table X provides a summary of our
overall results.
Summary and Insights: The participants in our study showed
increased activation in dorsolateral prefrontal cortex, frontopo-
lar cortex and orbitofrontal gyrus,the areas associated with
decision-making, working memory, memory recall and trust
while deciding on the legitimacy of the voices of speakers
compared to the rest trials. They also showed activation in
superior temporal gyrus, which is the region that processes
the auditory signals. Overall, these results show that the users
were certainly putting a considerable effort in making real vs.
fake decisions as reﬂected by their brain activity in regions
correlated with higher order cognitive processing. However,
our behavioral results suggests that users were not doing well
in identifying original, morphed and different speakers’ voices.
Perhaps the poor behavioral result was because the participants
were unaware of the fact that the voices could be morphed (a
real-world attack scenario). Another reason could be that the
quality of voice morphing technology is very good in capturing
features of the original speaker/victim.
We also analyzed the differences in neural activities when
participants were listening to original voice and morphed voice
of a speaker. However, we did not see any statistically signif-
icant differences in the activations in brain areas reported in
previous real–fake studies [34]. Although the lack of statistical
difference does not necessarily mean that the differences do not
exist, our study conﬁrms that they may not be present always,
if at all present. Our task performance results also showed that
people were nearly as fallible to the morphed voice as they
were to the real voices. The results show that the human users
may be inherently incapable of distinguishing between real and
11
TABLE X.
RESULTS SUMMARY: NEURAL FINGERPRINTS OF SPEAKER LEGITIMACY DETECTION, AND CORRESPONDING TASK PERFORMANCE AND
MACHINE LEARNING (ML) RESULTS.
morphed voices. Consequently, they may need to rely on other
external mechanisms to help them perform this differentiation
(e.g., automated detection tools). Nevertheless, even current
voice biometric solutions have been shown vulnerable to voice
impersonation attacks [30].
In line to this, we built and tested an automated mechanism
to identify original and morphed voice extracting features from
neural data corresponding to each of the two types of voices.
We found that it could only predict the voice correctly with
the accuracy slightly better than random guessing. This shows
that both the explicit responses of the users and the implicit
activity of their brains are indicative that morphed voices are
nearly indistinguishable from the original voices. This neuro-
behavioral phenomenon serves to show that users would be
susceptible to voice imitation attacks based on off-the-shelf
voice morphing techniques. We believe this to be an important
ﬁnding given the already emergence of voice imitation attacks.
More advanced state-of-the-art voice modeling techniques than
the one we used in our study, such as those offered by Lyrebird
and Google WaveNet [29], [41], could make people even more
susceptible to voice imitation attacks.
This same ﬁnding also bears positive news in other do-
mains. The fact that “listeners” can not differentiate between
the original voice of a speaker from a morphed voice of the
same speaker, at both neural and behavioral level, seems to
suggest that current morphing technology may be ready to
serve those who have lost their voices.
In our study, the participants were not trained to look for
speciﬁc forms of fabrications in the fake voice samples. Such
an explicit training of users to detect fabrications could make
an impact on users’ ability to detect fabricated voices. Future
studies should be conducted to analyze the effect of such
training against users’ performance in identifying morphed
voices. This will be an interesting avenue for further research.
Study Strengths and Limitations:
In line with any other
study involving human subjects, our study had certain lim-
itations. The study was conducted in a lab setting. So, the
performance of the users might have been affected since they
might not have been concerned about the security risks. Even
though we tried to emulate a real-world scenario of computer
usage in a lab setting and used a light-weight fNIRS probe
caps designed for the comfort level, performing the task with
the headset on might have affected the performance of some
of the participants. In real-world voice impersonation attacks,
the participants are not explicitly told to identify the real and
fake voices of the speaker unlike our study. However, this
could actually be seen as a strength of our work. Our results
show that the participants were unable to detect these attacks
despite being asked explicitly, and hence the result in the
real-world attack may be even worse, where the users have
to make the decision implicitly. Also, the participants in our
study were mostly young, so the results of the study may not
represent the success rate of voice spooﬁng attacks against
older people or people with declination in hearing ability (the
attack success rates against such populations may actually
be higher in practice [16]). However, our sample size and
diversity is well-aligned with those of prior studies (e.g., [33],
[34]). Also, our participants belonged to the broader university
community, including students, employees, and others.
One limitation of our study pertains to the number of trials.
We asked the users to identify forty eight voice samples, each
presented for 16 seconds, in about thirty minutes of the study.
Although multiple long trials are a norm in neuroimaging
studies for desired statistical power [2], the users may not
have to face these many challenges in a short span of time in
real-life. Another limitation pertains to the fNIRS device we
used for the study. fNIRS captures the brain activities mostly
close to the cortex of the brain. So, it might have missed
the neural activities in the inner core of the brain. The users’
decision making process towards the end of 15 seconds might
also not be captured by fNIRS. It is an inherent limitation in
measuring the BOLD signal. Finally, the fact that the voices
of the speakers, Oprah and Freeman used in our study were
distinctive and familiar to the speakers, might have confounded
the neural activity in the frontal cortex. Future studies might
be needed to explore a more realistic task set-up. Nevertheless,
we believe that our work provides a sound ﬁrst study of vocal
security from a neuro-physiological perspective with important
take-aways and insights that future studies can build upon.
IX. CONCLUDING REMARKS
In this paper, we explored voice security through the lens
of neuroscience and neuroimaging, running an fNIRS study
of human-centered speaker legitimacy detection. We dissected
the brain processes that control people’s responses to a real
speaker’s voice, a different speaker’s voice, and a morphed
12
Task Condition Activation Regions Task  Result ML  Result Implications Voice Trial vs Rest Trial Original vs. Rest DPLFC;  FPD;  STG;  MTG; OFA N/A N/A Regions associated with working memory, decision-making, trust, familiarity, and voice processing are all activated during the experimental task.  Morphed vs. Rest DPLFC/ FPA; STG; MTG N/A N/A Different vs. Rest DPLFC; FPA; STG; MTG; OFA N/A N/A Speaker Legitimacy Detection Original vs. Morphed No difference 43% 53% Both users and their brains seem to fail at detecting voice morphing attacks Original vs. Different STG 55% N/A Brain differentiates original speaker and different speakers voice       voice. We showed that there are differences in neural activities
when users are listening to real vs. different speakers’ voices.
However, we did not notice signiﬁcant differences when users
were subject to real vs. morphed voices, irrespective of their
behavioral response. We believe that this key insight from our
work helps justify the users’ susceptibility to morphing attacks
as also demonstrated by our task performance results as well
as prior studies.
ACKNOWLEDGMENT
We would like to thank Micah Sherr (our shepherd) and
NDSS’19 anonymous reviewers for their constructive com-
ments and guidance. We are also grateful to Rajesh Kana,
Abhishek Anand, Maliheh Shirvanian and Kiavash Satvat for
critiquing previous drafts of the paper. This work has been
funded in part by a Department of Justice (DOJ) GRF-STEM
fellowship.
REFERENCES
[1] H. Abdi, “Holms sequential bonferroni procedure.”
[2] E. Amaro and G. J. Barker, “Study design in fmri: basic principles,”
Brain and cognition, vol. 60, no. 3, pp. 220–232, 2006.
[3] S. R. Arnott, C. A. Heywood, R. W. Kentridge, and M. A. Goodale,
“Voice recognition and the posterior cingulate: an fmri study of
prosopagnosia,” Journal of neuropsychology, vol. 2, no. 1, pp. 269–
286, 2008.
[4] X. Bai, L. Xing, N. Zhang, X. Wang, X. Liao, T. Li, and S. M.
Hu, “Staying secure and unprepared: Understanding and mitigating the
security risks of apple zeroconf,” in 2016 IEEE Symposium on Security
and Privacy (SP), May 2016, pp. 655–674.
J. V. Baldo and N. F. Dronkers, “The role of inferior parietal and inferior
frontal cortex in working memory.” Neuropsychology, vol. 20, no. 5, p.
529, 2006.
[5]
[6] P. Belin, R. J. Zatorre, P. Lafaille, P. Ahad, and B. Pike, “Voice-selective
areas in human auditory cortex,” Nature, vol. 403, no. 6767, pp. 309–
312, 2000.
[7] A. Bethmann, H. Scheich, and A. Brechmann, “The temporal lobes
differentiate between the voices of famous and unknown people: an
event-related fmri study on speaker recognition,” PloS one, vol. 7,
no. 10, p. e47626, 2012.
[8] Bonnie Brinton Anderson and C. Brock Kirwan and Jeffrey L. Jenkins
and David Eargle and Seth Howard and Anthony Vance, “How polymor-
phic warnings reduce habituation in the brain: Insights from an fMRI
study,” in ACM Conference on Human Factors in Computing Systems,
CHI, 2015.
[9] K. Brodmann, Vergleichende Lokalisationslehre der Grosshirnrinde in
ihren Prinzipien dargestellt auf Grund des Zellenbaues. Barth, 1909.
[10] S. C. Bunce, M. Izzetoglu, K. Izzetoglu, B. Onaral, and K. Pourrezaei,
“Functional near-infrared spectroscopy,” IEEE engineering in medicine
and biology magazine, vol. 25, no. 4, pp. 54–62, 2006.
[11] B. Chance, Z. Zhuang, C. UnAh, C. Alter, and L. Lipton, “Cognition-
activated low-frequency modulation of light absorption in human brain.”
Proceedings of the National Academy of Sciences, vol. 90, no. 8, pp.
3770–3774, 1993.
J. Cohen, “Statistical power analysis for the behavioral sciences (revised
ed.),” 1977.
[12]
[13] C. E. Curtis and M. D’Esposito, “Persistent activity in the prefrontal
cortex during working memory,” Trends in cognitive sciences, vol. 7,
no. 9, pp. 415–423, 2003.
[14] D. T. Delpy, M. Cope, P. van der Zee, S. Arridge, S. Wray, and J. Wyatt,
“Estimation of optical pathlength through tissue from direct time of
ﬂight measurement,” Physics in medicine and biology, vol. 33, no. 12,
p. 1433, 1988.
[15] A. Dimoka, “What does the brain tell us about trust and distrust?
evidence from a functional neuroimaging study,” Mis Quarterly, pp.
373–396, 2010.
[16]
[17]
[18]
J. R. Dubno, D. D. Dirks, and D. E. Morgan, “Effects of age and
mild hearing loss on speech recognition in noise,” The Journal of the
Acoustical Society of America, vol. 76, no. 1, pp. 87–96, 1984.
“Bellesouth: Facebook scammers use voice-imitation to prey on users
relatives.” http://bellesouthblogs.com/facebookscam/. , 2012, accessed:
5-12-2018.
“Festival,” http://www.cstr.ed.ac.uk/projects/festival/, 2017, accessed:
5-12-2018.
“Festvox,” http://festvox.org/, 2014, accessed:05-11-2018.
[19]
[20] E. Formisano, F. De Martino, M. Bonte, and R. Goebel, “” who” is
saying” what”? brain-based decoding of human voice and speech,”
Science, vol. 322, no. 5903, pp. 970–973, 2008.
“Grandparents
18156-205169–,00.html, 2017, accessed: 5-12-2018.
http://www.michigan.gov/ag/0,4534,7-164-
scam,”
[21]
[23]
[22] M. A. Hall, “Correlation-based feature selection for machine learning,”
Ph.D. dissertation, The University of Waikato, 1999.
“Hemodynamic response,” https://en.wikipedia.org, 2017, accessed: 5-
12-2018.
[24] L. M. Hirshﬁeld, R. Gulotta, S. Hirshﬁeld, S. Hincks, M. Russell,
R. Ward, T. Williams, and R. Jacob, “This is your brain on interfaces:
enhancing usability testing with functional near-infrared spectroscopy,”
in Proceedings of
the SIGCHI Conference on Human Factors in
Computing Systems. ACM, 2011, pp. 373–382.
[25] M. Huang, H. Bridge, M. J. Kemp, and A. J. Parker, “Human cortical
activity evoked by the assignment of authenticity when viewing works
of art,” Frontiers in human neuroscience, vol. 5, 2011.
[26] K. Izzetoglu, S. Bunce, B. Onaral, K. Pourrezaei, and B. Chance,
“Functional optical brain imaging using near-infrared during cognitive
tasks,” International Journal of human-computer interaction, vol. 17,
no. 2, pp. 211–227, 2004.
J. Le´on-Carri´on and U. Le´on-Dom´ınguez, “Functional near-infrared
spectroscopy (fnirs): principles and neuroscientiﬁc applications,” Neu-
roimaging methods. Rijeka, Croatia: InTech (2012): 47-74, 2012.
[27]
[28] K. Lewison and F. Corella, “Backing rich credentials with a blockchain
pki,” 2016.
“Lyrebird,” https://lyrebird.ai/, 2017, accessed: 5-12-2018.
[29]
[30] D. Mukhopadhyay, M. Shirvanian, and N. Saxena, “All your voices
are belong to us: Stealing voices to fool humans and machines,” in
European Symposium on Research in Computer Security.
Springer,
2015, pp. 599–621.
[31] K. Murphy and H. Garavan, “An empirical investigation into the number
of subjects required for an event-related fmri study,” Neuroimage,
vol. 22, no. 2, pp. 879–885, 2004.
[32] A. Neupane, M. L. Rahman, N. Saxena, and L. Hirshﬁeld, “A multi-
modal neuro-physiological study of phishing detection and malware
warnings,” in Proceedings of the 22nd ACM SIGSAC Conference on
Computer and Communications Security. ACM, 2015, pp. 479–491.
[33] A. Neupane, N. Saxena, and L. Hirshﬁeld, “Neural underpinnings
of website legitimacy and familiarity detection: An fnirs study,” in
Proceedings of the 26th International Conference on World Wide Web.
International World Wide Web Conferences Steering Committee, 2017,
pp. 1571–1580.
[34] A. Neupane, N. Saxena, K. Kuruvilla, M. Georgescu, and R. Kana,
“Neural signatures of user-centered security: An fMRI study of phish-
ing, and malware warnings,” in Proceedings of
the Network and
Distributed System Security Symposium (NDSS), 2014, pp. 1–16.
[35] M. Plichta, M. Herrmann, C. Baehne, A.-C. Ehlis, M. Richter, P. Pauli,
and A. Fallgatter, “Event-related functional near-infrared spectroscopy
(fnirs): are the measurements reliable?” Neuroimage, vol. 31, no. 1, pp.
116–124, 2006.
I. Released, “Ibm spss statistics for windows. 20.” Armonk, NY: IBM
Corp, 2013.
[36]
[37] B. R. Rosen, R. L. Buckner, and A. M. Dale, “Event-related functional
mri: past, present, and future,” Proceedings of the National Academy
of Sciences, vol. 95, no. 3, pp. 773–780, 1998.
[38] M. Shirvanian and N. Saxena, “Wiretapping via mimicry: short voice
imitation man-in-the-middle attacks on crypto phones,” in Proceedings
of the 2014 ACM SIGSAC Conference on Computer and Communica-
tions Security. ACM, 2014, pp. 868–879.
13
[39] D. Tsuzuki and I. Dan, “Spatial registration for functional near-infrared
spectroscopy: from channel position on the scalp to cortical location in
individual and group analyses,” Neuroimage, vol. 85, pp. 92–103, 2014.
[40] A. Villringer and B. Chance, “Non-invasive optical spectroscopy and
imaging of human brain function,” Trends in neurosciences, vol. 20,
no. 10, pp. 435–442, 1997.
“Google
wavenet,”
speech/docs/wavenet, 2017, accessed: 8-3-2018.
https://cloud.google.com/text-to-
[41]
[42] H. Ye and S. Young, “High quality voice morphing,” in Acoustics,
Speech, and Signal Processing, 2004. Proceedings.(ICASSP’04). IEEE
International Conference on, vol. 1.
IEEE, 2004, pp. I–9.
[43] R. J. Zatorre, A. C. Evans et al., “Lateralization of phonetic and pitch
discrimination in speech processing,” Science, vol. 256, no. 5058, p.
846, 1992.
14