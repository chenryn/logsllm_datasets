M1
R {0, 1}|M2|
r2
M3
...
Figure 3. Interaction between A and B com-
pared to interaction between A and a random
simulation R.
5. Security for Secret-Handshake Schemes
5.1. Deﬁnitions
Before deﬁning security for a secret-handshake scheme,
we ﬁrst introduce some auxiliary deﬁnitions.
Security Parameter:
All primitives discussed in this
paper take an implicit security parameter. Typically, this
is the length of the prime modulus used in cryptographic
operations (in our case, the length of q).
Informally, a function ε(t) is negligible when
Negligible:
ε(t) ≈ 0 for big enough t. Formally, a function ε(t) is negli-
gible in t if for all polynomials p(·), ε(t) ≤ 1/p(t) for sufﬁ-
ciently large t. When t is the security parameter, we simply
say ε is negligible.
Random Simulation: A random simulation R of a par-
ticipant in a protocol replaces all outgoing messages with
uniformly-random bit strings of the same length. (See Fig-
ure 3.)
Interaction: We denote by A.Handshake(A, B) an al-
teration of SHS.Handshake(A, B) by an adversarial player
A. The adversary may choose to respond differently than
is speciﬁed in the original protocol, and may choose to ter-
minate the protocol early. What each party learns may be
different than in the original secret-handshake protocol.
We say that A interacts with B when A.Handshake(A, B)
is executed. When A executes a handshake with a random
simulation, we write this as A.Handshake(A, R), and say
that A interacts with a random simulation.
Group Member Impersonation
To motivate the following deﬁnitions, consider an adversary
A that has as its goal to learn how to impersonate mem-
∗
. A interacts with players of the
bers of a certain group G
, and eventually picks a target user U
∗
that A is a member of G
system, corrupts some users, communicates with legitimate
∗
and
members of G
. Intu-
attempts to convince U
itively, if A does not obtain secrets for any other U ∈ G
∗
,
then it should remain unable to convince U
of its member-
∗
ship in G
∗
∗
∗
.
∗
An additional property we would like our scheme to have
is the ability to trace the user secrets a successful adversary
might be using. We wish to argue that if A is able to con-
that A ∈ G
∗
, then A must be using secrets obtained
vince U
by some user U ∈ G
∗
, and the transcript of A’s interaction
∗
with U
will allow an administrator to identify U. Conse-
quently, U may be placed on a revocation list to prevent the
adversary from further use of U’s stolen secrets. We model
this by saying there is an efﬁcient algorithm which, given
(but not necessar-
the transcript of A’s interaction with U
ily access to A’s internal state), extracts the identity of some
user U ∈ G
∗
whose secrets A has been using. This motivates
the deﬁnition of impostor tracing below.
∗
We deﬁne the Member Impersonation Game for a ran-
domized, polynomial-time adversary A:
Step 1: The adversary A interacts with users of its choice,
and obtains secrets for some users U
Step 2: A selects a target user U
∗ ∈ G
∗
; that is, A
attempts to construct the correct responses in the pro-
tocol SHS.Handshake(A,U
Step 3: A attempts to convince U
∗).
(cid:11)
that A ∈ G
∗
∗ (cid:17)∈ U
∗
.
(cid:11) ⊆ U.
satisfying U
We say that A wins the Member Impersonation Game if
∗ ∈
. We deﬁne A’s impersonation advantage AdvMIGA as
it engages correctly in SHS.Handshake(A,U
∗
G
the following quantity:
∗) when U
AdvMIGA := Pr[ A wins Member Impersonation Game ].
AdvMIGE
A := Pr[ A wins Member Impersonation Game
We will also consider A’s conditional advantage restricted
to the occurrence of event E:
(cid:1)(cid:1) E ].
These probabilities are taken over the randomness in the
algorithms SHS.∗, the coin ﬂips of A, and the coin ﬂips of
all participating users.
We are ready to deﬁne two notions of security using the
Member Impersonation Game.
Impersonation Resistance:
Suppose A never corrupts a
∗ = /0. The
∗
. Then U
member of the target group G
secret-handshake scheme SHS is said to ensure imperson-
∗=/0
(cid:11)∩G
ation resistance if AdvMIGU
A
is negligible for all A.
(cid:11) ∩ G
In other words, if an adversary never corrupts a member
of its target group, it has only a negligible chance of imper-
sonating as a member of the target group.
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
Let T be a transcript of the in-
. The secret-handshake scheme SHS
∗
Impersonator Tracing:
teraction of A and U
is said to permit impostor tracing when
(cid:11) ∩ G
(cid:1)(cid:1)Pr[SHS.TraceUser(T ) ∈ U
(cid:1)(cid:1)
∗]− AdvMIGA
is negligible for all A.
In other words, with success probability very close to
that of the adversary, an administrator can determine which
user’s secrets A has obtained to perform its impersonation.
Group Member Detection
.
∗
To motivate the following deﬁnitions, consider an adversary
A that has as its goal to learn how to identify members of a
∗
certain group G
. A interacts with players of the system,
corrupts some users, picks a target user U
, and attempts to
∗ ∈ G
∗
learn if U
Intuitively, if A does not obtain secrets for any other
U ∈ G
∗
, then it should remain clueless when detecting
∗ ∈ G
∗
. In other words, the ﬁnal interaction with
whether U
∗
should yield no new information to the adversary unless
U
∗
.
it has already obtained secrets from another member of G
To model this formally, we consider the behavior of an
adversary in an environment where it is either allowed to in-
or it is instead presented with
teract with its target user U
a random simulation, and asking it to tell the difference. An
and R quan-
adversary unable to distinguish between U
(let alone whether
titatively learns nothing new about U
∗ ∈ G
∗
). This motivates the deﬁnition of detection resis-
U
tance given below.
∗
∗
∗
An additional property we would like our scheme to have
is the ability to trace which user’s secrets a successful ad-
versary is using. We wish to argue that if A is able to distin-
∗ ∈ G
∗
, then A must have
guish between R and some user U
already corrupted some other user U ∈ G
∗
, and this U is re-
vealed by A. We model this by saying there is an efﬁcient
algorithm which, given transcripts of A’s interaction with
the system (but not necessarily access to A’s internal state),
extracts the identity of some user U ∈ G
∗
whose secrets A
has been using. This motivates the deﬁnition of detector
tracing below.
We deﬁne the Member Detection Game for a random-
ized, polynomial-time adversary A:
Step 1: The adversary A interacts with users of its choice,
. If b = 1, A interacts
(cid:11) ⊆ U.
and obtains secrets for some users U
∗ (cid:17)∈ U
(cid:11)
Step 2: A selects a target user U
Step 3: A random bit b ← {0,1} is ﬂipped.
Step 4: If b = 0, A interacts with U
∗
.
with a random simulation R.
∗
Step 5: The adversary outputs a guess b
for b.
We say that A wins the Member Detection Game when
∗ = b. We deﬁne A’s advantage AdvMDGA as the follow-
b
ing quantity:
AdvMDGA :=|Pr[A wins Member Detection Game]− 1/2| .
We will also consider A’s conditional advantage restricted
to the occurrence of event E:
(cid:1)(cid:1)Pr[ A wins MDG
(cid:1)(cid:1) .
(cid:1)(cid:1) E ]− 1/2
AdvMDGE
A :=
These probabilities are taken over the randomness in the
algorithms SHS.∗, the randomness of R, the coin ﬂips of
A, and the coin ﬂips of all participating users.
We are ready to deﬁne two notions of security using the
member detection game.
∗
Let GU∗ be the group to which
belongs, and suppose A never corrupts a member GU∗.
(cid:11) ∩ GU∗ = /0. The secret-handshake scheme SHS is
(cid:11)∩GU∗ =/0
is
Detection resistance:
U
Then U
said to ensure detection resistance if AdvMDGU
A
negligible for all A.
In other words, if an adversary never corrupts a member
of its target user’s group, it has only a negligible chance
of distinguishing the target user’s messages from random
strings.
∗
Detector tracing: Let T be a transcript of the interaction
belongs.
of A and U
The secret handshake scheme SHS is said to permit detector
tracing when
, and let GU∗ be the group to which U
∗
(cid:1)(cid:1)Pr[SHS.TraceUser(T ) ∈ U
(cid:11) ∩ GU∗]− AdvMDGA
(cid:1)(cid:1)
is negligible for all A.
In other words, with success probability very close to
that of the adversary, an administrator can determine which
user’s secrets A has obtained to perform its unauthorized
detection.
5.2. Security of the Pairing-Based Handshake
We claim that if the Bilinear Difﬁe-Hellman problem is
hard, the simple Pairing-Based Handshake Scheme outlined
in Section 4.2 provably satisﬁes the security properties out-
lined in the previous section. We provide the statements
of security here; the security analysis is outlined in the ap-
pendix.
With straightforward modiﬁcations to the security analy-
sis, analogous security properties can be deﬁned and shown
to hold for the secret-handshake scheme with roles outlined
in Section 4.3.
Hardness of BDH Problem: We say that the Bilinear
Difﬁe-Hellman Problem (BDH) is hard if, for all probabilis-
tic, polynomial-time algorithms B,
AdvBDHB := Pr[B(P, aP, bP, cP) = ˆe(P, P)abc]
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
is negligible in the security parameter. This probability is
taken over random choice of P ∈ G1 and a, b, c ∈ {1, . . . ,q}
where q is the order of G1.
We now state the security claims for the Pairing-Based
Handshake. We outline proofs of Theorems 1 and 4 in the
appendix. For this analysis we model the hash functions H2
and H1 as random oracles [4].
Let A be a probabilistic, polynomial time adversary. We
denote by QH2 the number of distinct queries A makes to
H2, and we denote by QH1 the number of distinct queries A
makes to H1. We write e ≈ 2.78 as the base of the natural
logarithm.
Theorem 1 Suppose A is a probabilistic, polynomial time
(PPT) adversary. There is an PPT algorithm B such that
(cid:11) ∩ G
∗ ]
· AdvBDHB + ε,
AdvMIGA ≤ Pr[ PBH.TraceUser(T ) ∈ U
+ e QH1QH2
where ε is negligible in the security parameter.