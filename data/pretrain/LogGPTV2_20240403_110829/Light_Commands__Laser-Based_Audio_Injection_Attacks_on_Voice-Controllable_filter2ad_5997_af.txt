### Non-MEMS Microphones
We empirically verify the effectiveness of our method using a Sanwa 400-MC010 Electret Condenser Microphone. We directed a (blue) laser beam through the microphone’s metallic mesh (see Figure 13, left). Using the same parameters as in Section 4.2 (e.g., IDC = 200 mA and Ipp = 150 mA), we played a chirp signal that linearly varied in frequency from 0 to 10 kHz over 5 seconds. The spectrogram of the audio recorded by the microphone, shown in Figure 13 (right), clearly displays repeated diagonal lines corresponding to the linear frequency sweep. This confirms that our results are applicable not only to MEMS microphones but also to electret condenser microphones.

### Countermeasures and Limitations

#### 7.1 Software-Based Approach
As discussed in Section 6.2, an additional layer of authentication can be effective in mitigating the attack. Alternatively, if the attacker cannot eavesdrop on the device’s response (e.g., because the device is located far away behind a closed window), having the voice-controlled (VC) system ask the user a simple, randomized question before command execution can prevent the attacker from successfully executing commands. However, adding an additional layer of interaction often reduces usability, which may limit user adoption.

Manufacturers can also use sensor fusion techniques [38] to detect light-based command injection. Voice assistants typically have multiple microphones, which should receive similar signals due to the omnidirectional nature of sound. When an attacker uses a single laser, only one microphone receives a signal while the others do not. Thus, manufacturers can mitigate the attack by comparing signals from multiple microphones and ignoring commands injected via a single laser. However, attackers can counter this by simultaneously injecting light into all the device’s microphones using multiple lasers or wide beams, as discussed in Section 6.5. Further research is needed to implement such defenses and investigate their security properties.

For sensor-rich devices like phones and tablets, sensor-based intrusion detection techniques [39] can potentially identify and block irregular command injections. We leave further exploration of this direction to future work.

#### 7.2 Hardware-Based Approach
One way to reduce the amount of light reaching the microphone’s diaphragm is to use a barrier or diffracting film that physically blocks straight light beams while allowing sound waves to pass. A literature review of proposed microphone designs revealed several such suggestions, mainly aimed at protecting microphones from sudden pressure spikes. For example, the designs in Figure 14 include a silicon plate or movable shutter, both of which eliminate the line of sight to the diaphragm [40]. It is crucial that such barriers are opaque to all light wavelengths, including infrared and ultraviolet, to prevent the attacker from using different colored light. Additionally, a light-blocking barrier can be implemented at the device level by placing a non-transparent cover over the microphone hole, thereby reducing the amount of light hitting the microphone.

#### 7.3 Limitations
**Hardware Limitations:**
As a light-based attack, LightCommands inherits the limitations of light-related physics. Specifically, it assumes a line-of-sight threat model and does not penetrate opaque obstacles, which might be penetrable to sound. While attacking fabric-covered devices (e.g., Google Home Mini) is sometimes possible, we believe that for fabric-covered microphones, the thickness of the cover can prevent successful attacks (e.g., in the case of Apple HomePods). Future work will analyze such scenarios.

Unlike sound, LightCommands require careful aiming and line-of-sight access. In our experiments, we partially overcame this limitation by using a telescope to remotely determine the assistant type and location of the microphones based on the device’s appearance.

While line-of-sight access is often available for smart speakers visible through windows, the situation is different for mobile devices like smartwatches, phones, and tablets. These devices are often mobile, requiring an attacker to quickly aim and inject commands. Combined with the precise aiming and higher laser power required, successful LightCommands attacks on such devices may be particularly challenging. Future work will systematically explore these devices.

**Liveness Test and Continuous Authentication:**
Unlike some other injection attacks, LightCommands’ threat model and lack of proper feedback channels make it difficult for the attacker to pass liveness checks or continuous authentication methods. These can range from asking the user simple questions before performing a command to using data from different microphones [41, 42, 43], sound reflections [44], or other sensors [45] to verify that the incoming commands were indeed spoken by a live human. Implementing such defenses in deployed VC systems is an area for future work.

### Conclusions and Future Work
In this paper, we presented LightCommands, an attack that uses light to inject commands into voice-controllable systems from large distances. To execute the attack, we transmit light modulated with an audio signal, which is converted back to audio within the microphone. We demonstrated LightCommands on many commercially-available voice-controllable systems, including those using Siri, Portal, Google Assistant, and Alexa, achieving successful command injections at distances of more than 100 meters, even through clear glass windows. We highlighted deficiencies in the security of voice-controllable systems, leading to additional compromises of third-party hardware such as locks and cars. A better understanding of the physics behind the attack will benefit both new attacks and countermeasures. For example, the same principle can be used to mount other acoustic injection attacks (e.g., on motion sensors) using light. Additionally, laser heating can be an effective way to inject false signals into sensors.

### Acknowledgments
We thank John Nees for advice on laser operation and laser optics. This research was funded by JSPS KAKENHI Grants #JP18K18047 and #JP18KK0312, DARPA and AFRL under contracts FA8750-19-C-0531 and HR001120C0087, NSF under grants CNS-1954712 and CNS-2031077, gifts from Intel, AMD, and Analog Devices, and an award from MCity at the University of Michigan.

### References
[References listed as in the original text]

---

This version of the text is more structured, coherent, and professional, with improved clarity and flow.