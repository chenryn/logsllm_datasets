以下是经过优化的文本，使其更加清晰、连贯和专业：

### 参考文献
1. **arXiv preprint arXiv:1701.00160, 2016.**
2. **Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.** Generative Adversarial Nets. In NIPS, pages 2672–2680, 2014.
3. **Palash Goyal and Emilio Ferrara.** Graph Embedding Techniques, Applications, and Performance: A Survey. Elsevier Knowledge-Based Systems, 151:78–94, 2018.
4. **Alex Graves.** Generating Sequences with Recurrent Neural Networks. arXiv preprint arXiv:1308.0850, 2013.
5. **Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C. Courville.** Improved Training of Wasserstein GANs. In NIPS, pages 5767–5777, 2017.
6. **Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.** Deep Residual Learning for Image Recognition. In CVPR, pages 770–778, 2016.
7. **Briland Hitaj, Paolo Gasti, Giuseppe Ateniese, and Fernando Perez-Cruz.** PassGAN: A Deep Learning Approach for Password Guessing. In ACNS, pages 217–237, 2019.
8. **Diederik P. Kingma and Max Welling.** Auto-encoding Variational Bayes. arXiv preprint arXiv:1312.6114, 2013.
9. **Yang Li and Tao Yang.** Word Embedding for Understanding Natural Language: A Survey. In Springer Guide to Big Data Applications, pages 83–104, 2018.
10. **Junyu Luo, Yong Xu, Chenwei Tang, and Jiancheng Lv.** Learning Inverse Mapping by Autoencoder-based Generative Adversarial Nets. In International Conference on Neural Information Processing, pages 207–216, Springer, 2017.
11. **Laurens van der Maaten and Geoffrey Hinton.** Visualizing Data using t-SNE. Journal of Machine Learning Research, 9:2579–2605, 2008.
12. **Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, and Brendan Frey.** Adversarial Auto-Encoders. arXiv preprint arXiv:1511.05644, 2015.
13. **Philip Marquardt, Arunabh Verma, Henry Carter, and Patrick Traynor.** (sp)iPhone: Decoding Vibrations From Nearby Keyboards Using Mobile Phone Accelerometers. In ACM CCS, pages 551–562, 2011.
14. **William Melicher, Blase Ur, Sean M. Segreti, Saranga Komanduri, Lujo Bauer, Nicolas Christin, and Lorrie Faith Cranor.** Fast, Lean, and Accurate: Modeling Password Guessability using Neural Networks. In USENIX Security Symposium, pages 175–191, 2016. GitHub Repo: <https://tinyurl.com/y9o7jdd8>.
15. **Shakir Mohamed and Balaji Lakshminarayanan.** Learning in Implicit Generative Models. arXiv preprint arXiv:1610.03483, 2016.
16. **Robert Morris and Ken Thompson.** Password Security: A Case History. Communications of the ACM, 22(11):594–597, 1979.
17. **Arvind Narayanan and Vitaly Shmatikov.** Fast Dictionary Attacks on Passwords using Time-space Tradeoff. In ACM CCS, pages 364–372, 2005.
18. **Bijeeta Pal, Tal Daniel, Rahul Chatterjee, and Thomas Ristenpart.** Beyond Credential Stuffing: Password Similarity Models using Neural Networks. In IEEE S&P, pages 1–18, 2019.
19. **Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei A. Efros.** Context Encoders: Feature Learning by Inpainting. In IEEE CVPR, pages 2536–2544, 2016.
20. **Alec Radford, Luke Metz, and Soumith Chintala.** Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. arXiv preprint arXiv:1511.06434, 2015.
21. **Masashi Sugiyama, Matthias Krauledat, and Klaus-Robert Müller.** Covariate Shift Adaptation by Importance Weighted Cross Validation. Journal of Machine Learning Research, 8(May):985–1005, 2007.
22. **Ilya Sutskever, James Martens, and Geoffrey E. Hinton.** Generating Text with Recurrent Neural Networks. In ICML, pages 1017–1024, 2011.
23. **Ilya Tolstikhin, Olivier Bousquet, Sylvain Gelly, and Bernhard Schölkopf.** Wasserstein Auto-Encoders. arXiv preprint arXiv:1711.01558, 2017.
24. **Blase Ur, Fumiko Noma, Jonathan Bees, Sean M. Segreti, Richard Shay, Lujo Bauer, Nicolas Christin, and Lorrie Faith Cranor.** I Added ‘!’ at the End to Make It Secure: Observing Password Creation in the Lab. In SOUPS, pages 123–140, 2015.
25. **Blase Ur, Sean M. Segreti, Lujo Bauer, Nicolas Christin, Lorrie Faith Cranor, Saranga Komanduri, Darya Kurilova, Michelle L. Mazurek, William Melicher, and Richard Shay.** Measuring Real-world Accuracies and Biases in Modeling Password Guessability. In USENIX Security Symposium, pages 463–481, 2015.
26. **Martin Vuagnoux and Sylvain Pasini.** Compromising Electromagnetic Emanations of Wired and Wireless Keyboards. In USENIX Security Symposium, pages 1–16, 2009.
27. **Ding Wang, Zijian Zhang, Ping Wang, Jeff Yan, and Xinyi Huang.** Targeted Online Password Guessing: An Underestimated Threat. In ACM CCS, pages 1242–1254, 2016.
28. **Matt Weir, Sudhir Aggarwal, Breno De Medeiros, and Bill Glodek.** Password Cracking using Probabilistic Context-free Grammars. In IEEE S&P, pages 391–405, 2009.
29. **Tom White.** Sampling Generative Networks. arXiv preprint arXiv:1609.04468, 2016.
30. **Roman V. Yampolskiy.** Analyzing User Password Selection Behavior for Reduction of Password Space. In ICCST, pages 109–115, 2006.

### 附录 A：通过归纳偏置诱导特定密码潜空间组织

在缺乏精确外部偏置的情况下，用于学习密码潜在表示的生成模型可以自由选择任意的空间排列。通常情况下，我们的生成器学习到的是最适合训练过程中极其通用的生成任务的潜在表示。然而，这可能不是最优的。例如，我们技术学习到的潜在空间倾向于将长度相似的密码保持得非常接近。这是因为密码的长度被建模为潜在表示中的一个核心解释因素 [18]。因此，不同长度的密码分布得较远，这对于 DPG 是有利的，但在其他情况下是不理想的。例如，生成共享特定子串但长度不同的密码可能是更好的选择。

幸运的是，在我们的框架内可以实现这种专业化。我们的深度学习方法具有高度的灵活性，可以通过在训练过程中注入归纳偏置来诱导特定的潜在空间组织。例如，对于 AE（见第 II-B2 节），我们可以通过在训练期间进行正则化来诱导潜在空间组织的结构偏好。具体来说，我们可以通过改变字符删除过程来减少基于长度的聚类现象。在正常情况下，我们通过训练自编码器重构人工损坏的密码来学习潜在表示，其中输入字符串中的每个字符都以一定的概率被删除。不同的是，我们可以删除从随机选择的起始位置 i 开始的 k 个连续字符。例如，当 k = 5 时，密码“jimmy1991”可以变成“jimm*****”（i = 4）或“*****991”（i = 0）。直观上，生成器将在同一位置收集共享共同子串的密码，而不管它们的长度如何。例如，给定损坏的密码“jimmy*****”，生成器应该能够恢复密码“jimmy”、“jimmyjimmy”和“jimmy123”，最终迫使它们的潜在表示彼此靠近。

作为示例，我们将使用不同方法训练的 CWAE 采样的密码进行比较，即使用第 II-B2 节中讨论的字符删除方法（这里称为 Simple）和上述的组删除方法（称为 Mask）。表 A.1 报告了两种 CWAE 围绕枢轴“iloveyou1”采样的密码。与 Simple 相比，Mask 模型采样的密码长度更异质，并且与枢轴的长度任意不同。

**表 A.1：使用不同正则化方法训练的两个 CWAE 围绕枢轴“iloveyou1”采样的密码**

| Simple       | Mask                    |
|--------------|-------------------------|
| iloveyou13   | iloveyou1234            |
| iloveyou12   | iloveyou14              |
| iloveYou1    | iloveyou12ao            |
| iLoveyou1    | iloveyou1222            |
| iloveyou*    | iloveyou17a             |
| Iloveyou1    | iloveyou12arham         |
| iloheyou1    | iloveyou14om            |
| ilOveyou1    | iloveyou123o            |
| iloveyou11a  | iloveyou1444            |
| iloveyou1a   | iloveyou12a4mom1        |

### 附录 B：猜测生成性能

为了完整性，我们报告了我们的方法与其他概率模型（即 OMEN 和 PCFG）的性能分析。我们排除了 FLA [42]，因为据我们所知，其枚举算法不能按顺序生成排序后的密码，即密码必须先预计算然后用于猜测攻击。此外，在我们的实验中，生成 10^10 个猜测需要超过两周的时间，使用的硬件是 NVIDIA Quadro P6000 和 Intel Xeon CPU E5645.12。

基准测试是在不考虑哈希计算延迟的情况下进行的；仅评估猜测生成的成本。但是，我们将猜测写入磁盘。对于每个测试工具，我们生成 10^8 个密码并收集所需的执行时间。然后，我们计算每秒生成的猜测数（g/s）。我们的实现有两个选项：（1）允许生成重复的猜测；（2）使用布隆过滤器从输出流中过滤重复的猜测。前一种选项适用于快速哈希函数，而后一种选项更适合慢速哈希函数。对于其他工具，我们使用默认设置进行评估。数据分别报告了 GAN 和 CWAE 模型的结果。我们在配备 NVIDIA V100s（32GB 设备内存）的 NVIDIA DGX2 机器上进行了测试。表 B.1 报告了收集的数据。

**表 B.1：性能分析收集的数据**

| 工具          | 生成速率 (g/s) |
|---------------|-----------------|
| OMEN          | 512820          |
| PCFG          | 114810          |
| GAN           | 303951          |
| GAN (过滤)    | 80321           |
| CWAE          | 237529          |
| CWAE (过滤)   | 64197           |

在测试的工具中，OMEN 是最快的。它确实带有 C 实现，而 PCFG 和我们的实现是用 Python 编写的。考虑到原始哈希值（即工作因子为 0），在相同的硬件设置下，hashcat 在单个 GPU 上每秒可以计算约 60000 个 bcrypt 哈希值。当使用快速哈希函数（如 SHA-3 512）时，这个数字变为 1894.5 Mg/s。考虑到一次 bcrypt 迭代作为安全密码存储的基线，所有测试工具都可以在使用暴力破解感知哈希算法时饱和哈希管道，但在使用快速哈希函数时会失败。重要的是要强调，使用快速哈希函数并不是存储密码的安全选择。

### 附录 C：学习 GAN 模型的逆映射

为了充分利用学习到的密码潜在表示的特性，我们需要一种有效探索潜在空间的方法。因此，我们的主要兴趣是理解观察数据（即密码）与其各自潜在表示之间的关系；特别是它们在潜在空间中的位置。直接建模这种关系的方法是学习生成器函数 G 的逆函数 G−1 : X → Z。GAN 默认不需要学习这些函数，因为这一要求被对抗性训练方法绕过了。为此，需要框架变体 [25], [26] 或额外的训练阶段 [38]。

为了避免对原始训练过程的任何不稳定源，我们选择在生成器训练完成后才学习逆映射。这是通过训练第三个编码器网络 E 来实现的，该网络与批评者具有相同的架构，除了输出层的大小。该网络被训练成同时将真实数据（即来自训练集的数据）和生成数据（即来自 G 的数据）映射到潜在空间。具体来说，E 的损失函数主要定义为数据空间上的两个循环重建误差之和。如下所示：

\[ L_0 = \mathbb{E}_z[d(G(z), G(E(G_t(z))))] \]
\[ L_1 = \mathbb{E}_x[d(x, G(E(x)))] \]

在公式 (C.1) 中，函数 d 是交叉熵，而 x 和 z 分别从训练集和先验潜在分布中采样。变量 t 在 L0 中指的是生成器最后一层 softmax 层的温度。在公式 (C.1) 中，如果没有明确指定生成器的温度，则假设它在训练过程中不会变化。这两个重建误差的组合旨在强制编码器学习一个能够正确反转真实和生成数据的一般函数。

正如第 II-B1 节所述，真实数据和生成数据（即离散数据和连续数据）表示之间的差异可能会对训练过程造成损害。为了解决这个问题，我们在训练过程中逐渐降低 L0 中的温度 t。这样做的目的是逐渐将生成数据的连续表示（即生成器的输出）塌缩到与真实数据（即来自数据集的数据）相同的离散表示。接下来，添加了一个额外的损失项，如公式 C.2 所示，强制编码器将数据空间映射到潜在空间中的密集区域（相对于先验潜在分布）。

\[ L_2 = \mathbb{E}_z[d(z, E(G(z)))] \]

我们编码器的最终损失函数如公式 C.3 所示。在编码器训练过程中，我们使用与生成器训练相同的训练集，但只考虑唯一的密码。

\[ L_E = \alpha L_0 + \beta L_1 + \gamma L_2 \]

我们使用的超参数信息列在表 C.1 中。

**表 C.1：用于训练编码器网络的超参数**

| 超参数               | 值       |
|----------------------|-----------|
| α                     | 0.2       |
| β                     | 0.2       |
| γ                     | 0.6       |
| 批量大小             | 64        |
| 学习率               | 0.001     |
| 优化器               | Adam      |
| 温度衰减步数         | 250000    |
| 温度限制             | 0.1       |
| 温度调度器           | 多项式    |
| 训练迭代次数         | 3 · 10^5  |

### 附录 D：DPG 超参数的影响

在本节中，我们简要讨论 DPG 的两个超参数对其攻击质量的影响。

图 D.1 描述了静态攻击、DPG（α = 15%）和无热启动的 DPG（α = 0%）之间的比较。这些结果证实了缺少热启动确实会影响并最终降低 DPG 的性能。

图 D.2 显示了不同 σ 值对 DPG 性能的影响。较小的 α 值产生更好的整体结果。这表明不必从 Zi 强制的密集区域采样太远，而是集中探索这些区域是有益的。这一观察结果与讨论的局部性质完全一致，进一步支持了推测的潜在空间捕获和转换整个密码分布的一般特征的能力。

**图 D.1：α 对 phpbb 测试集上 DPG 性能的影响**

**图 D.2：σ 对 phpbb 测试集上 DPG 性能的影响**

### 附录 E：CWAE 细节

我们构建了 CWAE 架构，利用了与 GAN 生成器相同的 resenet-like 结构，总结在表 E.1 中。表 E.2 报告了模型训练期间使用的超参数。在这里，λ 是分配给损失函数中潜在发散项的权重，即在我们的情况下是最大均值差异（MMD）。我们使用标准的 softmax-crossentropy 作为数据空间中的距离度量。参数 ε 控制训练期间使用的字符删除概率（参见第 II-B2 节）。有关更详细的信息，请参阅我们的项目页面（见可用性部分）。

**表 E.1：CWAE 架构方案**

| 编码器                                      | 解码器                                       |
|---------------------------------------------|----------------------------------------------|
| cov1d[5, 128, same, linear]                 | FullyConnected[MaxPasswordLength · 128, linear] |
| ResblockBottleneck1D[128, batchnorm=false]  | Reshape[MaxPasswordLength, 128]              |
| ResblockBottleneck1D[128, batchnorm=false]  | ResblockBottleneck1D[128, batchnorm=false]   |
| ResblockBottleneck1D[128, batchnorm=false]  | ResblockBottleneck1D[128, batchnorm=false]   |
| ResblockBottleneck1D[128, batchnorm=false]  | ResblockBottleneck1D[128, batchnorm=false]   |
| ResblockBottleneck1D[128, batchnorm=false]  | ResblockBottleneck1D[128, batchnorm=false]   |
| ResblockBottleneck1D[128, batchnorm=false]  | cov1d[1, AlphabetCardinality, same, linear]  |
| Reshape[-1]                                 |                                              |
| FullyConnected[128, linear]                 |                                              |

**表 E.2：用于训练 CWAE 的超参数**

| 超参数               | 值       |
|----------------------|-----------|
| λ                     | 8.0       |
| 批量大小             | 256       |
| 学习率               | 0.0001    |
| 优化器               | Adam      |
| 训练轮次             | 25        |
| ε                     | 5.0       |