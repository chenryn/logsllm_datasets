title:End-to-End Measurements of Email Spoofing Attacks
author:Hang Hu and
Gang Wang
End-to-End Measurements of  
Email Spoofing Attacks
Hang Hu and Gang Wang, Virginia Tech
https://www.usenix.org/conference/usenixsecurity18/presentation/hu
This paper is included in the Proceedings of the 
27th USENIX Security Symposium.
August 15–17, 2018 • Baltimore, MD, USA
ISBN 978-1-939133-04-5
Open access to the Proceedings of the 27th USENIX Security Symposium is sponsored by USENIX.End-to-End Measurements of Email Spooﬁng Attacks
Hang Hu
Virginia Tech
PI:EMAIL
Gang Wang
Virginia Tech
PI:EMAIL
Abstract
Spear phishing has been a persistent threat to users and
organizations, and yet email providers still face key chal-
lenges to authenticate incoming emails. As a result, at-
tackers can apply spooﬁng techniques to impersonate a
trusted entity to conduct highly deceptive phishing at-
tacks. In this work, we study email spooﬁng to answer
three key questions: (1) How do email providers detect
and handle forged emails? (2) Under what conditions can
forged emails penetrate the defense to reach user inbox?
(3) Once the forged email gets in, how email providers
warn users? Is the warning truly effective?
We answer these questions by conducting an end-to-
end measurement on 35 popular email providers and ex-
amining user reactions to spooﬁng through a real-world
spooﬁng/phishing test. Our key ﬁndings are three folds.
First, we observe that most email providers have the nec-
essary protocols to detect spooﬁng, but still allow forged
emails to reach the user inbox (e.g., Yahoo Mail, iCloud,
Gmail). Second, once a forged email gets in, most email
providers have no warning for users, particularly for mo-
bile email apps. Some providers (e.g., Gmail Inbox) even
have misleading UIs that make the forged email look au-
thentic. Third, a few email providers (9/35) have imple-
mented visual security indicators on unveriﬁed emails.
Our phishing experiment shows that security indicators
have a positive impact on reducing risky user actions,
but cannot eliminate the risk. Our study reveals a ma-
jor miscommunication between email providers and end-
users. Improvements at both ends (server-side protocols
and UIs) are needed to bridge the gap.
1
Introduction
Despite the recent development of the system and net-
work security, human factors still remain a weak link.
As a result, attackers increasingly rely on phishing tac-
tics to breach various target networks [62]. For example,
email phishing has involved in nearly half of the 2000+
reported security breaches in recent two years, causing a
leakage of billions of user records [4].
Email spooﬁng is a critical step in phishing, where
the attacker impersonates a trusted entity to gain the
victim’s trust. According to the recent report from the
Anti-Phishing Working Group (APWG), email spoof-
ing is widely in spear phishing attacks to target em-
ployees of various businesses [2]. Unfortunately, to-
day’s email transmission protocol (SMTP) has no built-
in mechanism to prevent spooﬁng [56].
It relies on
email providers to implement SMTP extensions such as
SPF [40], DKIM [19] and DMARC [50] to authenticate
the sender. Since implementing these extensions is vol-
untary, their adoption rate is far from satisfying. Real-
world measurements conducted in 2015 have shown that
among Alexa top 1 million domains, 40% have SPF, 1%
have DMARC, and even fewer are correctly/strictly con-
ﬁgured [23, 27].
The limited server-side protection is likely to put users
in a vulnerable position. Since not every sender domain
has adopted SPF/DKIM/DMARC, email providers still
face key challenges to reliably authenticate all the incom-
ing emails. When an email failed the authentication, it is
a “blackbox” process in terms of how email providers
handle this email. Would forged emails still be deliv-
ered to users? If so, how could users know the email is
questionable? Take Gmail for example, Gmail delivers
certain forged emails to the inbox and places a security
indicator on the sender icon (a red question mark, Fig-
ure 6(a)). We are curious about how a broader range of
email providers handle forged emails, and how much the
security indicators actually help to protect users.
In this paper, we describe our efforts and experience in
evaluating the real-world defenses against email spoof-
ing1. We answer the above questions through empiri-
cal end-to-end spooﬁng measurements, and a user study.
1Our study has been approved by our local IRB (IRB-17-397).
USENIX Association
27th USENIX Security Symposium    1095
First, we conduct measurements on how popular email
providers detect and handle forged emails. The key idea
is to treat each email provider as a blackbox and vary
the input (forged emails) to monitor the output (the re-
ceiver’s inbox). Our goal is to understand under what
conditions the forged/phishing emails are able to reach
the user inbox and what security indicators (if any) are
used to warn users. Second, to examine how users react
to spooﬁng emails and the impact of security indicators,
we conduct a real-world phishing test in a user study.
We have carefully applied “deception” to examine users’
natural reactions to the spooﬁng emails.
Measurements.
We start by scanning Alexa top 1
million hosts from February 2017 to January 2018. We
conﬁrm that the overall adoption rates of SMTP secu-
rity extensions are still low (SPF 44.9%, DMARC 5.1%).
This motivates us to examine how email providers handle
incoming emails that failed the authentication.
We conduct end-to-end spooﬁng experiments on 35
popular email providers used by billions of users. We
ﬁnd that forged emails can penetrate the majority of
email providers (34/35) including Gmail, Yahoo Mail
and Apple iCloud under proper conditions. Even if
the receiver performs all the authentication checks (SPF,
DKIM, DMARC), spooﬁng an unprotected domain or a
domain with “relaxed” DMARC policies can help the
forged email to reach the inbox. In addition, spooﬁng
an “existing contact” of the victim also helps the attacker
to penetrate email providers (e.g., Hotmail).
More surprisingly, while most providers allow forged
emails to get in, rarely do they warn users of the unver-
iﬁed sender. Only 9 of 35 providers have implemented
some security indicators: 8 providers have security in-
dicators on their web interface (e.g., Gmail) and only 4
providers (e.g., Naver) have the security indicators con-
sistently for the mobile apps. There is no security warn-
ing if a user uses a third-party email client such as Mi-
crosoft Outlook. Even worse, certain email providers
have misleading UI elements which help the attacker to
make forged emails look authentic. For example, when
attackers spoof an existing contact (or a user from the
same provider), 25 out of 35 providers will automatically
load the spoofed sender’s photo, a name card or the email
history along with the forged email. These UI designs are
supposed to improve the email usability, but in turn, help
the attacker to carry out the deception when the sender
address is actually spoofed.
Phishing Experiment.
While a handful of email
providers have implemented security indicators, the real
question is how effective they are. We answer this ques-
tion using a user study (N = 488) where participants ex-
amine spoofed phishing emails with or without security
indicators on the interface. This is a real-world phish-
ing test where deception is carefully applied such that
users examine the spoofed emails without knowing that
the email is part of an experiment (with IRB approval).
We debrief the users and obtain their consent after the
experiment.
Our result shows that security indicators have a pos-
itive impact on reducing risky user actions but cannot
eliminate the risk. When a security indicator is not pre-
sented (the controlled group), out of all the users that
opened the spoofed email, 48.9% of them eventually
clicked on the phishing URL in the email. For the other
group of users to whom we present the security indica-
tor, the corresponding click-through rate is slightly lower
(37.2%). The impact is consistently positive for users
of different demographics (age, gender, education level).
On the other hand, given the 37.2% click-through rate,
we argue that the security indicator cannot eliminate the
phishing risk. The server-side security protocols and the
user-end security indicators should be both improved to
maximize the impact.
Contributions. We have 3 key contributions:
• First, our end-to-end measurement provides new in-
sights into how email providers handle forged emails.
We reveal the trade-offs between email availability
and security made by different email providers
• Second, we are the ﬁrst to empirically analyze the
usage of security indicators on spoofed emails. We
show that most email providers not only lack the
necessary security indicators (particularly on mobile
apps), but also have misleading UIs that help the at-
tackers.
• Third, we conduct a real-world phishing test to eval-
uate the effectiveness of the security indicator. We
demonstrate the positive impact (and potential prob-
lems) of the security indicator and provide the initial
guidelines for improvement.
The quantitative result in this paper provides an end-
to-end view on how spoofed emails could penetrate ma-
jor email providers and all the way affect the end users.
We hope the results can draw more attention from the
community to promoting the adoption of SMTP security
extensions. In addition, we also seek to raise the atten-
tion of email providers to designing and deploying more
effective UI security indicators, particularly for the less
protected mobile email apps. We have communicated
the results with the Gmail team and offered suggestions
to improve the security indicators.
2 Background and Methodology
Today’s email system is built upon the SMTP protocol,
which was initially designed without security in mind.
1096    27th USENIX Security Symposium
USENIX Association
Figure 1: Email transmission from Alex to Bob.
Security extensions were introduced later to provide con-
ﬁdentiality, integrity, and authenticity. Below, we brieﬂy
introduce SMTP and related security extensions. Then
we introduce our research questions and methodology.
2.1 SMTP and Email Spooﬁng
Simple Mail Transfer Protocol (SMTP) is an Internet
standard for electronic mail transmission [56]. Figure 1
shows the three main steps to deliver an email message.
() Starting from the sender’s Mail User Agent (MUA),
the message is ﬁrst transmitted to the Mail Submission
Agent (MSA) of the sender’s service provider via STMP
or HTTP/HTTPS. () Then the sender’s Mail Transfer
Agent (MTA) sends the message to the receiver’s email
provider using SMTP. ( ) The message is then delivered
to the receiving user by the Mail Delivery Agent (MDA)
via Internet Message Access Protocol (IMAP), Post Of-
ﬁce Protocol (POP) or HTTP/HTTPS.
When initially designed, SMTP did not have any secu-
rity mechanisms to authenticate the sender identity. As
a result, attackers can easily craft a forged email to im-
personate/spoof an arbitrary sender address by modify-
ing the “MAIL FROM” ﬁeld in SMTP. Email spooﬁng is
a critical step in a phishing attack — by impersonating
a trusted entity as the email sender, the attacker has a
higher chance to gain the victim’s trust. In practice, at-
tackers usually exploit SMTP in step () by setting up
their own MTA servers.
Alternatively, an attacker may also exploit step ()
if a legitimate email service is not carefully conﬁgured.
For example, if a.com is conﬁgured as an open relay,
attacker can use a.com’s server and IP to send forged
emails that impersonate any email addresses.
2.2 Email Authentication
To defend against email spooﬁng attacks, various secu-
rity extensions have been proposed and standardized in-
cluding SPF, DKIM and DMARC. There are new proto-
cols such as BIMI and ARC that are built on top of SPF,
DKIM, and DMARC. In this paper, we primarily focus
on SPF, DKIM, and DMARC since they have some level
of adoption by email services in practice. BIMI and ARC
have not been fully standardized yet, and we will discuss
them later in §7.
SPF.
Sender Policy Framework (SPF) allows an email
service (or an organization) to publish a list of IPs that are
authorized to send emails for its domain (RFC7208 [40]).
For example, if a domain “a.com” published its SPF
record in the DNS, then the receiving email services can
check this record to match the sender IP with the sender
email address. In this way, only authorized IPs can send
emails as “a.com”. In addition, SPF allows the organiza-
tion to specify a policy regarding how the receiver should
handle the email that failed the authentication.
DKIM.
DomainKeys Identiﬁed Mail (DKIM) uses
the public-key based approach to authenticate the email
sender (RFC6376 [19]). The sender’s email service will
place a digital signature in the email header signed by the
private key associated to the sender’s domain. The re-
ceiving service can retrieve the sender’s public key from
DNS to verify the signature. In order to query a DKIM
public key from DNS, one not only needs the domain
name but also a selector (an attribute in the DKIM sig-
nature). Selectors are used to permit multiple keys un-
der the same domain for more a ﬁne-grained signatory
control. DKIM does not specify what actions that the
receiver should take if the authentication fails.
DMARC.
Domain-based Message Authentication,
Reporting and Conformance (DMARC) is built on top
of SPF and DKIM (RFC7489 [50]), and it is not a stan-
dalone protocol. DMARC allows the domain admin-
istrative owner to publish a policy to specify what ac-
tions the receiver should take when the incoming email
fails the SPF and DKIM check. In addition, DMARC
enables more systematic reporting from receivers to
senders. A domain’s DMARC record is available under
dmarc.domain.com in DNS.
2.3 Research Questions and Method
Despite the available security mechanisms, signiﬁcant
challenges remain when these mechanisms are not prop-
erly deployed in practice. Measurements conducted in
2015 show that the adoption rates of SMTP security ex-
tensions are far from satisfying [23, 27]. Among Alexa
top 1 million domains, only 40% have published an SPF
record, and only 1% have a DMARC policy. These re-
sults indicate a real challenge to protect users from email
spooﬁng. First, with a large number of domains not pub-
lishing an SPF/DKIM record, email providers cannot re-
liably detect incoming emails that spoof unprotected do-
mains. Second, even a domain is SPF/DKIM-protected,
the lack of (strict) DMARC policies puts the receiving
server in a difﬁcult position. It is not clear how the email
providers at the receiving end would handle unveriﬁed
emails. Existing works [23, 27] mainly focus on the au-
thentication protocols on the server-side. However, there
is still a big gap between the server-side detection and
the actual impact on users.
USENIX Association
27th USENIX Security Symposium    1097
MUAMUAMTAMDAMSAMTA123HTTPSMTPHTTPIMAPPOPSMTPa.comSender Serviceb.comReceiver ServiceAlexBobStatus
Total domains
w/ SPF
w/ valid SPF
Policy: soft fail
Policy: hard fail
Policy: neutral
Policy: pass
w/ DMARC
w/ valid DMARC
Policy: none
Policy: reject
Policy: quarantine
All Domain # (%)
1,000,000 (100%)
492,300 (49.2%)
448,741 (44.9%)
272,642 (27.3%)
125,245 (12.5%)
49,798 (5.0%)
1,056 (0.1%)
51,222 (5.1%)
50,619 (5.1%)
39,559 (4.0%)
6,016 (0.6%)
5,044 (0.5%)
MX Domain # (%)
792,556 (100%)
473,457 (59.7%)
430,504 (54.3%)
268,317 (33.9%)
112,415 (14.2%)
48,736 (6.1%)
1,036 (0.1%)
47,737 (6.0%)
47,159 (6.0%)
36,984 (4.7%)
5,225 (0.7%)
4,950 (0.6%)
Table 1: SPF/DMARC statistics of Alexa 1 million do-
mains. The data was collected in January 2018.
Our Questions.
Our study seeks to revisit the email
spooﬁng problem by answering three key questions. (1)
When email providers face uncertainty in authenticating
incoming emails, how would they handle the situation?
Under what conditions would forged emails be delivered
to the users? (2) Once forged emails reach the inbox,
what types of warning mechanisms (if any) are used to
notify users of the unveriﬁed sender address? (3) How
effective is the warning mechanism? Answering these
questions is critical to understanding the actual risks ex-
posed to users by spooﬁng attacks.
We answer question(1)–(2) through end-to-end spoof-
ing experiments (§3, §4 and §5). For a given email
provider, we treat it as a “blackbox”. By controlling the
input (e.g., forged emails) and monitoring the output (re-
ceiver’s inbox), we infer the decision-making process in-
side the blackbox. We answer question(3) by conducting
a large user study (§6). The idea is to let users read spoof-
ing/phishing emails with and without security indicators.
Ethics.
We have taken active steps to ensure re-
search ethics. Our measurement study only uses dedi-
cated email accounts owned by the authors and there is
no real user getting involved. In addition, to minimize
the impact on the target email services, we have care-
fully controlled the message sending rate (one message
every 10 minutes), which is no different than a regular
email user. For the user study that involves “deception”,
we worked closely with IRB for the experiment design.
More detailed ethical discussions are presented later.
3 Adoption of SMTP Extensions
The high-level goal of our measurement is to provide an
end-to-end view of email spooﬁng attacks against pop-
ular email providers. Before doing so, we ﬁrst exam-
ine the recent adoption rate of SMTP security extensions
compared with that of three years ago [23, 27]. This
helps to provide the context for the challenges that email
providers face to authenticate incoming emails.
Figure 2: The adoption rate of SPF and DMARC among
Alexa 1 million domains across three snapshots.
Scanning Alexa Top 1 Million Domains.
Email au-
thentication requires the sender domains to publish their
SPF/DKIM/DMARC records to DNS. To examine the
recent adoption rate of SPF and DMARC, we crawled
3 snapshots the DNS record for Alexa top 1 million