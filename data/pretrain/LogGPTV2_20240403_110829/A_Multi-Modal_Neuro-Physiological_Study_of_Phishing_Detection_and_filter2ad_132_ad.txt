ing at the login form had lower accuracy rates. We did not ﬁnd a
statistically signiﬁcant correlation of accuracy with gaze duration
in URL or logo regions.
Spearman’s correlation did not reveal signiﬁcant correlations be-
tween task performance & neural metrics, and between neural met-
rics & gaze metrics.
We next explored correlation between task performance & per-
sonality traits. Neupane et al. [26] showed that users’ individ-
ual personality traits might affect how they process security tasks.
They speciﬁcally showed that impulsive persons had lower activa-
tion in certain decision-making regions of their brains. However,
they did not report any direct signiﬁcant effect of users’ personality
traits on their task performance [26].
In our experiment, Spear-
man’s correlation revealed a medium, statistically signiﬁcant, pos-
itive relationship between participants’ ATTC personality scores
and their task accuracy (rcor = .477, p = .021). This correla-
tion remained statistically signiﬁcant even after applying Holm-
Bonferroni correction. BIS did not yield any statistically signiﬁcant
relationship, however. This means that attention control has a posi-
tive effect on the performance of the users in the phishing detection
task. Training to improve users’ attention level, along with educa-
tion, might therefore help them identify phishing attacks better (we
will discuss this aspect in Section 9).
7.2 Malware Warnings Experiment
To recall, in the malware warnings task, participants were ran-
domly exposed to malware warnings while reading abstracts of
news items. As in the phishing detection experiment, we analyzed
the neural data, gaze data, and task performance data collected dur-
ing the malware warnings experiment.
7.2.1 Neural Activity Results
We computed average WL, and average pfrENG, pfrDIS and
pfrSO, for the three trials – abstract, malware warning and full
news. Our results are summarized in Table 4.
Metric →
Trial ↓
Abstract
Warning
Full News
WL
µ (σ)
.65 (.08)
.69 (.09)
.67 (.11)
pfrENG
µ (σ)
.63 (.17)
.60 (.21)
.65 (.20)
pfrDIS
µ (σ)
.13 (.13)
.13 (.60)
.12 (.16)
pfrSO
µ (σ)
.22 (.14)
.25 (.17)
.22 (.16)
Table 4: Neural Results for Malware Warnings: Average cog-
nitive workload and average percentage frequency of engage-
ment, distraction and sleep onset.
From Table 4 (column 1), we observe that the average workload
values across abstract, warnings and full news trials are all high
(greater than .65). We also see a higher average workload in pro-
cessing warnings when compared to abstract and full news. The
Friedman test revealed a statistically signiﬁcant difference among
the mean workloads of the abstract, warning and full news trials (χ2
(2) = 6.0, p = .048). Further, upon using WSRT for pair-wise com-
parisons, we found a statistically signiﬁcant difference between the
warnings and abstracts trials (p=.005), with a medium effect size (r
= .41); the other two pairs of trials did not show up any statistically
signiﬁcant difference. This pairwise difference remained statisti-
cally signiﬁcant even when applying Holm-Bonferroni correction.
This demonstrates that our participants were possibly exerting
more effort on their memory and neural resources when subject to
warnings in contrast to reading casual abstracts.
Considering the cognitive state metrics (columns 2-4), we see
that the participants frequency of being engaged was high (at least
60% in all trials), and their frequency of being distracted or un-
der sleep onset was low (at most 25%). This suggests that the
participants were actively engaged, and less distracted or sleep-
prone, during the experiment, including warnings. The Friedman
test indicated the difference among the means of pfrENG, pfrDIS
and pfrSO as signiﬁcant (χ2(2) = 26.9, p<.0005). Upon perform-
ing pairwise comparisons between the means of the three metrics
across the warnings trials using WSRT, statistically signiﬁcant dif-
ferences were found between pfrENG and pfrDIS (p < .0005) with
486a large effect size (r = .59) , pfrENG with pfrSO (p < .0005) with
a large effect size (r =.51) and pfrDIS with pfrSO (p = .027) with a
medium effect size (r = .32). This pairwise difference, apart from
pfrDIS with pfrSO, remained statistically signiﬁcant even when ap-
plying Holm-Bonferroni correction.
This analysis demonstrates that, when processing warnings, par-
ticipants’ frequency of being in an engaged state was higher than
their frequency of being in the distracted state or sleep onset state.
The high task performance results (discussed later in this section)
conform to this high engagement level and high workload.
Last, we contrasted the different categories of trials (rows) with
respect to our cognitive state metrics (pfrENG, pfrDIS and pfrSO)
using the Friedman test. However, no signiﬁcant differences emerged.
7.2.2 Eye Gaze Results
Our primary goal of employing gaze tracking in the warnings
experiment was to determine if the participants actually read the
message embedded within the warning, or just ignore it.
To this end, we considered the “red dialog box” of the warning
page, called the warning area (see Appendix A), as our AOI, and
calculated the average number of ﬁxations (#ﬁx) and average gaze
duration (dur) inside it (just like the phishing detection task).
The participants spent almost 2.5s inside the warning area on
average (Table 5). This means that participants’ primary focus was
inside the warning dialog.
Metric →
Trial ↓
Warning
#ﬁx
µ (σ)
7.4 (2.67)
dur (ms)
µ (σ)
.63 (.17)
Table 5: Gaze Results for Malware Warnings: Average number
of ﬁxations and average total gaze duration
To further understand how users processed the warnings while fo-
cusing on the warning window, we plotted the ﬁxations in the ﬁrst
warning trial of all participants, in a scatterplot, overlaid on top of
the warning (shown in Figure 4). The scatterplot has more ﬁxa-
tion points in the middle of the plot, representing dense gaze points
inside the warning area. These dense gaze points show that partic-
ipants spent maximum percentage of their time inside the warning
area, spread consistently across the sentences/tabs in the warning
message. Furthermore, the ﬁxation points in the scatterplot are
ﬂowing along the sentences in the warning area (as shown by sam-
ple snapshots in Appendix D), representing the movement of gaze
points and demonstrating the “warning reading ﬂow”. This gaze
pattern analysis shows that participants were not just ﬁxating inside
the warning window but actually reading the warning message. A
similar pattern was observed across other warning trials. We also
calculated the correlation between the trial number and the number
of ﬁxations (time spent) within the warning area. We only found
a statistically signiﬁcant negative correlation corresponding to two
of our participants (r = -.661, p = .038,; and r = -.72, p = .019).
This suggests that these participants spent lesser time in process-
ing the warnings as the experiment proceeded. On average across
all participants, however, no statistically signiﬁcant correlation was
found.
To our knowledge, no prior study has looked at eye gaze analy-
sis in the context of warnings (malware or otherwise). Akhawe and
Felt [9] showed that people are likely to heed warnings based on
browser telemetry data. Neupane et al. [26], in their fMRI-based
malware experiment, showed activity in language comprehension
areas of the brain when subjects were exposed to warnings. We pre-
sented an analysis of the ﬂow of ﬁxation points over time, and val-
idated that users are in fact reading warnings, which may serve to
explain their high heeding rates and comprehension-relevant neural
activity [26].
Figure 4: The ﬂow of ﬁxation points over the 1st Warning trial
of all participants (others trials had a similar effect)
7.2.3 Task Performance Results
To measure the task performance in the warnings experiment, we
recorded the participants’ responses (and response time) when they
were subject to warnings. We were mainly interested in determin-
ing the rate at which the participants may ignore the warning - the
fraction of the time they hit the “Ignore this warning” button.
Metric →
Trial ↓
Warning
Ignoring Rate (%)
µ (σ)
14.10 (27.79)
Response Time (ms)
µ (σ)
2580 (655)
Table 6: Task Performance in Malware Warnings: Average
rate of ignoring warnings, and response time
Table 6 summarizes these results. We observe that almost 15%
of the time, participants ignored the warnings (i.e., they heeded
the warning almost 85% of the time). This result is well-aligned
with prior studies [17, 26]. Both these studies suggest that users
are highly likely to heed malware warning messages. The high
level of workload and engagement reﬂected in our neural analysis,
and the “reading effect” highlighted in our gaze analysis justify
participants’ heeding behavior.
Post-Test Questionnaire Analysis: Our post-experiment survey re-
sults further conﬁrm that our participants read the warnings. 84%
of them said they read the warnings. Following are a few excerpts
of what information they read in the warnings: “That the website
was a potential threat, if I wanted to continue”; “Possible danger
on the website”; “They asked if I wanted to “Get Me Out of Here!”
or ﬁgure out why the page I was visiting had been blocked.” 72% of
our participants reported that they had heard about malware attacks.
7.2.4 Correlations
Spearman’s correlation did not reveal statistically signiﬁcant cor-
relations between neural metrics, gaze metrics and task performance
(heeding rate). It did not reveal statistically signiﬁcant relationships
between personality scores and heeding warning rates.
8. SUMMARY AND KEY INSIGHTS
The primary ﬁndings and insights from our study, with respect to
our different dimensions, are itemized below. Whenever applica-
ble, our results are positioned with respect the prior results.
487Task Performance
Personality Traits
• The users fail to identify phishing websites more than 37%
of the time. This result is well-aligned with the results of
several prior studies (e.g., [17, 26]).
• The users are likely to heed warnings about 85% of the time.
This serves to further validate the results of two recent stud-
ies [9, 26].
Neural Activity
• The users’ exhibit a high cognitive load in the two security
tasks. The cognitive load in processing warnings is more
than the cognitive load in processing casual abstracts of news
articles. Moreover, users’ frequency of being in an “engaged”
state is more than their frequency of being in “distracted” and
“sleep-prone” states for both tasks. This means that users are
paying attention and making an active effort while perform-
ing these tasks (and not ignoring them). Although this level
of involvement translated into high heeding rates in the warn-
ings task, the phishing detection task accuracy is still quite
low (as listed above). This result is in line with the ﬁnd-
ings presented in [26], but is based on a complementary neu-
roimaging technique having high temporal resolution (EEG
vs. fMRI) and accomplished under a near ecologically valid
setting (e.g., out-scanner vs. in-scanner, sitting vs. supine).
• At a subconscious level, there might be hidden differences
in how users detect real and fake websites (in line with iden-
tifying real and fake paintings [22]). Real websites, which
possibly simulate a more trustworthy environment, may have
a higher frequency of engagement, and a lower frequency
of distraction, compared to fake websites. This means that
the computer system could use these subtle implicit cues to
determine whether the site is fake (even though users may
eventually fail to detect it).
Eye Gaze Patterns
• Eye gaze analysis in the phishing detection task shows that
users do not spend enough time looking at the key areas of
websites (less time on URL; more time on “login ﬁeld” or
“website logo”) for identifying its trustworthiness. A prior
work [37] made a similar conclusion regarding security indi-
cators in general, but did not provide any quantitative results.
The work of [10] provided a similar insight but in the context
of “single-sign-on” applications, not phishing detection.
• The correlation of gaze “ﬁxations” with phishing detection
accuracy shows that users who look longer at the login ﬁeld
are likely to have lower accuracy. Also, users who look
longer at the login ﬁeld are more likely to look longer at the
website logo (not an authentic indicator of the real website).
• Gaze pattern analysis of malware warnings shows that users
are ﬁxating inside the warning dialog and actually reading
the warnings (also reﬂected in their high task performance).
This is the ﬁrst work that shows the warning “reading ef-
fect”. Prior work [17, 26] showed that users heed warnings
(based on task performance data) and may trigger “language
comprehension” activity in their brains. Overall, our work
corroborates the previous ﬁndings demonstrating that users
(1) read (based on eye gaze analysis), (2) understand (based
on neural activity) and (3) heed (based on task performance)
warnings on a large majority of occasions.
• The difference in users’ personal characteristics can have an
effect on how well they perform in a security task. A user
with high attention control (measured via a simple question-
naire [16]) is more likely to identify the real and fake web-
sites correctly. Our study demonstrates a direct impact of
personality traits on security task performance. The work
of [26] showed a correlation between personality traits with
neural activity, not task performance. Beyond raising peo-
ple’s awareness to phishing attacks, interventional training
programs that can improve people’s attention control [4, 5,
15,35] may therefore help reduce the impact of these attacks.
9. DISCUSSION
Implications of Our Work: A broader implication of our work
is in leveraging real-time brain monitoring and eye tracking tech-
niques to inform the design of user-centered security systems. The
current user-centered security practices unconditionally rely upon
users’ input whether or not users pay attention. The use of real-
time “brain-eye” measures, we investigated in this paper, could be
used to build an automated mechanism where the system can de-
termine whether user’s response is reliable or not. For example, if
the gaze patterns show that the user did not sufﬁciently look at the
URL when connecting to a website, or did not read the message
provided by a warning, the user’s response would most likely not
be reliable. Similarly, if neural features show that the user was not
engaged, or was under a distracted state, when subject to a security
task, the user’s response may not be valid. In contrast, if eye gaze
dynamics show that the user reads the warning and neural activity
reveals that the user was highly engaged, a user’s response can be
deemed legitimate.
To formalize a bit, we are suggesting a mechanism based on real-
time neural and eye gaze data, that can detect whether users are in
an “attentive” or “inattentive” state, i.e., whether or not they are
performing the security task as stipulated. Such mechanisms can
be developed using machine learning techniques. “Fusing” neu-
ral and ocular features may provide a robust detection mechanism
(resulting in low error rates).
While traditional security approaches either rely on machines
alone or humans alone, what we are proposing is a hybrid approach
where machines and humans work in conjunction with each other,
possibly complementing each other’s strengths and weaknesses in
meaningful ways. This approach could be generally applicable
to many security applications including other warnings (e.g., SSL
warnings [34] or app permissions warnings [19]), user-aided de-
vice pairing [31], security and privacy indicators (e.g., webcam
lights [28]), and more.
Although the design and evaluation of such a mechanism re-
quires a comprehensive future investigation, we believe that our
work lays out the necessary foundation at least in the realm of
phishing detection and malware warnings. Given the rise of eye-
tracking and neuroimaging devices in the commercial sectors, such
as the adoption of eye-trackers in smart-glasses [7, 8] and gaming
BCI headsets [2, 6] it seems feasible that such a mechanism could
be used in practice once shown effective, especially in high-security
settings (such as defense applications).
A malicious application having access to brain-eye measures could
similarly be used for offensive purposes. For example, a user could
be attacked at an opportune moment, i.e., when he/she is in the
inattentive state as inferred by eye-brain features (e.g., when the
user is sleep-prone or otherwise distracted). Commercial BCI de-