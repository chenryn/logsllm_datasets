title:PyCRA: Physical Challenge-Response Authentication For Active Sensors
Under Spoofing Attacks
author:Yasser Shoukry and
Paul Martin and
Yair Yona and
Suhas N. Diggavi and
Mani B. Srivastava
PyCRA: Physical Challenge-Response Authentication
For Active Sensors Under Spooﬁng Attacks
Yasser Shoukry, Paul Martin, Yair Yona, Suhas Diggavi, and Mani Srivastava
Electrical Engineering Department, University of California at Los Angeles, USA
{yshoukry, pdmartin, yairyo99, suhasdiggavi,mbs}@ucla.edu
ABSTRACT
Embedded sensing systems are pervasively used in life- and security-
critical systems such as those found in airplanes, automobiles, and
healthcare. Traditional security mechanisms for these sensors focus
on data encryption and other post-processing techniques, but the
sensors themselves often remain vulnerable to attacks in the phys-
ical/analog domain. If an adversary manipulates a physical/analog
signal prior to digitization, no amount of digital security mecha-
nisms after the fact can help. Fortunately, nature imposes funda-
mental constraints on how these analog signals can behave. This
work presents PyCRA, a physical challenge-response authentica-
tion scheme designed to protect active sensing systems against phys-
ical attacks occurring in the analog domain. PyCRA provides se-
cure active sensing by continually challenging the surrounding en-
vironment via random but deliberate physical probes. By analyz-
ing the responses to these probes, the system is able to ensure that
the underlying physics involved are not violated, providing an au-
thentication mechanism that not only detects malicious attacks but
provides resilience against them. We demonstrate the effectiveness
of PyCRA in detecting and mitigating attacks through several case
studies using two sensing systems: (1) magnetic sensors like those
found on gear and wheel speed sensors in robotics and automo-
tive, and (2) commercial Radio Frequency Identiﬁcation (RFID)
tags used in many security-critical applications. In doing so, we
evaluate both the robustness and the limitations of the PyCRA se-
curity scheme, concluding by outlining practical considerations as
well as further applications for the proposed authentication mecha-
nism.
Categories and Subject Descriptors
C.2.0 [COMPUTER-COMMUNICATION NETWORKS]: Gen-
eral: Security and protection
General Terms
Security
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813679.
Keywords
Embedded Security; Active sensors; Challenge-response authenti-
cation; Spooﬁng attacks; Physical attacks
1.
INTRODUCTION
Recent decades have witnessed a proliferation in embedded sen-
sors for observing a variety of physical phenomena. Increased use
of these sensors in security- and life-critical applications has been
accompanied by a corresponding increase in attacks targeting sens-
ing software, hardware, and even physical, analog signals them-
selves. While considerable research has explored sensor security
from a system-level perspective—network redundancy, sensor fu-
sion, and the like—sensors themselves remain largely vulnerable to
attacks targeting analog signals prior to digitization. This vulnera-
bility can lead to catastrophic failures when a malicious third party
attempts to spoof the sensor [19, 14, 3, 33].
Several system-level sensor security schemes have been proposed
in the context of power grids. For example, Dorﬂer et al. have ex-
plored distributed cyber-physical attack detection in the context of
power networks [6, 30]. Similar ideas for providing system-level
security in smart grids can be found in [16, 18, 4, 22, 35]. Security
schemes in this vein include, among others, state-space and control-
theoretic approaches for detecting anomalous system behavior [7,
30]. One idea common to these efforts is that an inherent security
mechanism and robustness can be found in the physics governing
the dynamics of the system as a whole. For example, a mismatch
between the rate of change in a vehicle’s location as reported by
GPS and by the odometer sensor may indicate that one of these
two sensors is either faulty or under attack.
A complementary security mechanism can be found in the un-
derlying physics governing the sensor itself. If a sensor observes
an analog signal that appears to violate the physics governing the
sensing dynamics, the signal itself may be under attack, necessi-
tating security mechanisms at the analog signal level. To reduce
sensor-level vulnerabilities, engineers often place sensors in secure
or remote physical locations to preclude direct physical contact
with the sensing hardware. Additionally, the phenomenon being
sensed is often difﬁcult to access, whether prohibitively far away
or surrounded by protective material. In such scenarios, adversaries
have access only to the analog signal prior to it reaching the sensor,
and their attack must be carried out without direct access to any
hardware in the entire sensing path, from source to sink. Even with
these countermeasures in place, an adversary can still attack sen-
sors by manipulating the physical signals before their transduction
and subsequent digitization [19, 33]. Robust countermeasures for
such attacks must necessarily be carried out at the physical level
as well—once these signals have been sampled and digitized, no
amount of post-processing can repair the compromised sensor data.
1004Broadly speaking, sensors can be divided into two categories:
passive (those that sense pre-existing physical signals) and active
(those that perform some action to evoke and measure a physical
response from some measurable entity). Examples of passive sen-
sors include temperature, humidity, and ambient light, while active
sensors include ultrasound, laser scanners, and radar. Passive sen-
sors are largely naïve listening devices–they blindly relay informa-
tion to higher levels of software without regard for the integrity of
that information. Digital ﬁltering and other post-processing tech-
niques can be used to remove noise from passive sensors, but they
remain unable to combat attacks at the physical layer in any mean-
ingful way. On the other hand, active sensors introduce the possi-
bility for more advanced security measures. PyCRA is, at its core, a
method of ensuring the trustworthiness of information obtained by
active sensors by comparing their responses to a series of physical
queries or challenges. The driving concept behind PyCRA is that,
by periodically stimulating the environment with a known signal
and measuring the response, we can ensure that the signal measured
by the sensor is in accordance with the underlying sensing physics.
This periodic stimulation and subsequent behavioral analysis—the
physical challenge-response authentication, creating a secure active
sensing platform—is the main contribution of this work.
We demonstrate the effectiveness of PyCRA for three exemplary
cases: physical attack detection for magnetic encoders, physical at-
tack resilience for magnetic encoders, and passive eavesdropping
detection for RFID readers. Magnetic encoders are used in a wide
array of commercial and industrial applications and are representa-
tive of a large class of inductive active sensors. We demonstrate not
only how active spooﬁng attacks can be detected for these inductive
sensors but also how the effects of these attacks can be mitigated.
Eavesdropping detection on RFID readers serves to illustrate an
extension of PyCRA to enable detection of passive attacks. Our re-
sults from more than 90 experiments demonstrate that PyCRA can
accurately detect attacks in a variety of settings. We believe that
the methods demonstrated in this work can be applied to a broad
array of active sensors beyond those studied directly in this work,
including ultrasound, optical sensors, active radar, and more.
1.1 Contributions of PyCRA
In summary, the contributions described in this paper are three-
fold:
• We present a generalizable physical challenge-response au-
thentication scheme for active sensing subsystems.
• We introduce algorithms for detecting the presence of and
providing resilience against physical attacks when using phys-
ical challenge-response authentication.
• We demonstrate the effectiveness of PyCRA, our implemen-
tation of physical challenge-response authentication, against
several different attack types and for over 90 experiments
with three exemplary applications: (1) detection of active at-
tacks on magnetic encoders, (2) resilience against active at-
tacks on magnetic encoders, and (3) detecting passive eaves-
dropping attacks on RFID readers.
The rest of this paper is organized as follows. Section 2 outlines
the attacker model. Section 3 describes the basic operation of the
PyCRA authentication scheme for detecting active attacks. Section
4 outlines theoretical limitations of attackers on physical signals.
Section 5, 6, and 7 are devoted to the results of three case studies:
attack detection for magnetic encoders, attack detection for passive
eavesdropping on RFID readers, and attack resilience for magnetic
Figure 1: A typical active sensor architecture. The actuator gener-
ates an analog signal (energy) which is reﬂected by the measured
entity back to the sensor. The received analog signal is captured and
processed by the analog front-end. The signal is then converted to
a digital format which is processed once more (by the digital back-
end) before being sent to higher level software layers.
encoders. Finally, we offer a discussion and concluding thoughts
in Sections 8.1, 8.2 and 9.
2. ATTACKER MODEL
Before describing mechanisms by which we can detect and pre-
vent sensor attacks at the physical layer, we must differentiate be-
tween two broad categories of sensors—namely passive and active
sensors—and deﬁne what we mean by a physical attack.
2.1 Passive vs. Active Sensors
Sensors can be broadly classiﬁed as either passive or active based
on the source of energy being sensed. Passive sensors measure am-
bient energy. For example, temperature sensors like those found in
thermostats are considered passive, because they measure heat en-
ergy in the ambient environment. By contrast, active sensors probe
some physical entity with self-generated energy as shown in Fig-
ure 1. This energy is partially reﬂected back to the sensor where it
is measured and used to infer properties about some physical phe-
nomenon. Examples of active sensors include ultrasonic range ﬁnd-
ers (used in robotics), optical and magnetic encoders (used in au-
tomotive vehicles, industrial plants, & chemical reﬁneries), radar,
and even radio-frequency identiﬁcation (RFID) systems. In RFID,
a reader is used to generate electromagnetic waves which are then
used by wireless tags to transfer back their unique identiﬁer to the
reader.
In this paper, we focus on providing security for active sensors.
In particular, we leverage an active sensor’s ability to emit energy
in order to 1) provide detection of active attackers trying to spoof
the sensor, 2) mitigate the effects of active spooﬁng attacks and 3)
detect passive eavesdropping attacks attempting to listen to the in-
formation received by the sensor. In the following subsections, we
deﬁne what we mean by physical attacks on active sensors and out-
line the assumed properties and limitations of a potential adversary.
2.2 Deﬁning Physical Attacks
In this paper, a physical attack refers to a malicious alteration
of a physical, analog signal (e.g., magnetic waves, acoustic waves,
visible waves) prior to transduction and digitization by a sensor, as
shown in Figure 1.
2.3 Adversarial Goals
The adversary considered in this work has a number of goals
related to misinforming and misleading sensors. These goals are
summarized below.
G1 Concealment: An attacker does not want the presence of his
or her attack to be known.
If a sensor attack can be easily detected, preventative countermea-
sures like hardware redundancy and resilience at the system-level
can often be used to mitigate the damage done by the attack [7, 30].
Active SensorActuatorAnalog Front-End(sensing & (cid:31)ltering)Digitization(ADC)DigitalBack-EndSoftware LayersMeasured Entityphysical attackProbeResponse1005Figure 2: Examples of physical delays seen in typical sensing and
actuation hardware, including optical sensors (left) and electromag-
netic coupled (e.g., RFID) sensors (right). In each case, the mea-
sured analog signal (blue solid) lags behind the ideal, “logical” sig-
nal (red dashed), causing delays.
G2 Signal Injection: An attacker will attempt to trick the sen-
sor into thinking that a malicious, injected signal is the true
physical signal.
The primary goal of an attack is to replace the true physical sig-
nal that a sensor aims to sense with a malicious signal. In other
words, an adversary will attempt to “inject” a signal into the phys-
ical medium that the sensor is measuring in order to jam or spoof
the sensor.
G3 Signal Masking: An attacker will attempt to prevent the sen-
sor from being able to detect the true physical signal.
If the sensor is still capable of reliably discerning the correct sig-
nal from the malicious, injected signal, then the attack may not be
successful. Thus, the adversary aims not only to inject a signal but
also to mask the true signal, whether by overpowering, modifying,
or negating (canceling) it.
2.4 Assumptions about the Adversary
The physical attacks against sensors considered in this work op-
erate under four main assumptions:
A1 Non-invasiveness: Attacks are of a non-invasive nature—that
is, the attacker is not allowed direct access to the sensor
hardware. Additionally, the adversary does not have ac-
cess to the sensor ﬁrmware or software, whether directly or
through wired or wireless networking.
In most life- and safety-critical applications, engineers are careful
to ensure that sensors are not physically exposed and vulnerable to
direct tampering. For example:
• Sensors are often installed inside the body of a physically
secured infrastructure (e.g., sensors inside the body of an au-
tomotive system, moving UAV drones, etc.).
• For sensors which are physically accessible, existing tech-
niques in the literature demonstrate ways to implement tamper-
proof packaging to protect sensors from direct, physical mod-
iﬁcations [31, 17, 1].
• Numerous sensor systems have methods for detecting when
wires connecting their various sensors have been tampered