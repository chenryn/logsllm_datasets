next present the details of these two phases (Algorithm 1).
Phase 1: Noise calibration. The selection of noise magni-
tude is determined by optimizing the expected MAE deÔ¨Åned
in 4.3.1. Here we denote z = (z(1), . . . , z(c)) in which z(j) is
the magnitude of Laplace noise for category j. For simplic-
1
ity, we also denote zI = ( 1
z(c) ). Therefore, the noise
magnitude of Laplace noises on each category aggregate can
be determined via the following mathematical programming
(4.3):
z(1) , . . . ,
(cid:107)z(cid:107)1
minimize
subject to CzI ‚â§ 1, z, zI ‚â• 0
(4.3)
The objective in (4.3) is to minimize expected MAE of all
injected Laplace noises onto category aggregates since the
noise on each category aggregate has E[|Lap(z(j))|] = z(j)
and the injected noises are independent. The Ô¨Årst constraint
serves two purposes: First, it imposes the -diÔ¨Äerential pri-
vacy guarantee as later shown in privacy analysis (Theorem
2); Second, it captures the correlation between categories
from the public information that what categories each item
belongs to. The last two constraints ensure the non-negative
noise magnitude of z and zI.
As the formulation (4.3) is non-convex, we then transform
it into the convex programming (4.4) to obtain a global op-
timal solution. SpeciÔ¨Åcally, we regard both z and zI as free
variables. For the sake of clariÔ¨Åcation, we introduce two
more variables z1 = z, z2 = zI. Then, we add additional
constraints z1(j)z2(j) = 1 for each category j to ensure their
reciprocal relationship. Moreover, we further relax this con-
straint to z1z2
T ‚â• I.
(cid:107)z1(cid:107)1
minimize
subject to Cz2 ‚â§ 1, z1z2
T ‚â• I, z1, z2 ‚â• 0
(4.4)
In this phase, our data perturbation algorithm Ô¨Årst solves
the convex programming (4.4). Then, we set zI = z2 such
that the Ô¨Årst constraint in (4.4) is not violated; and set z by
letting each entry z(j) be the reciprocal of the jth entry in
zI. Thanks to the convexity property of (4.4), our optimized
noise calibration algorithm is guaranteed to outperform the
traditional Laplace mechanism.
Example 1. Figure 4 shows a running example that ex-
plains why our novel noise calibration approach (phase 1)
can always outperform the existing Laplace mechanism in
Theorem 1. In this tiny example, public set of items con-
tains Ô¨Åve items and their associated Ô¨Åve categories. A check
represents that an item belongs to this category (e.g., item
1 belongs to category 1,2,3). The row in gray shows our
novel category based sensitivity obtained by solving (4.4) with
 = 1. For a category associated with more items, the sen-
sitivity of this category intends to be larger since there is
higher probability that the aggregate of this category will be
aÔ¨Äected by adding or removing a single item. Therefore, the
last column of last two rows shows a better MAE error using
Input : private user data dr, item-category matrix C,
privacy budget 
Output: perturbed user‚Äôs data dp
// Phase 1: Noise calibration
1 Solve mathematical programming (4.4);
2 z ‚Üê reciprocal of each entry in zI;
3 Sample noises from Lap(z(j)) for each category j;
4 Set NA with each entry
N A(j) =(cid:80)
i‚ààI cij dr(i) + Lap(z(j));
// Phase 2: Data sanitization
5 Relax integral constraints in (4.5);
6 Solve the relaxed (4.5) by replacing dp with dr
7 foreach each element i in dr
8
Randomly select a number Œæ between 0 and 1;
dp(i) ‚Üê 1 if Œæ ‚â§ dr
p(i) and dp(i) ‚Üê 0 otherwise;
p do
9
p ‚àà [0, 1]n;
10 end
11 return dp;
Algorithm 1: S-DPDP Algorithm
our category based sensitivity via (4.4) than using traditional
global sensitivity.
Figure 4: Running Example of Noise Calibration
Phase 2: Data sanitization. This phase takes the above
noise magnitude vector output z as input and generates the
useful perturbed user data. We Ô¨Årst quantify the useful-
ness of perturbed data by minimizing the error between the
category aggregates on perturbed data and the noisy cat-
egory aggregates. SpeciÔ¨Åcally, we introduce two error vec-
tors l, r and consider the root mean square error (RMSE)
as 1
2. Then, we formulate the following optimization
formulation (4.5):
2(cid:107)l + r(cid:107)2
1
2(cid:107)l + r(cid:107)2
2
minimize
subject to NA ‚àí l ‚â§ CT dp ‚â§ NA + r, dp ‚àà {0, 1}n (4.5)
where NA is the noisy category aggregate vector in which
each entry N A(j) =(cid:80)
i‚ààI cijdr(i) + Lap(z(j)).
It is not hard to see that solving (4.5) is NP-hard by re-
ducing it from Exact Cover problem (The proof is similar
to that in [24] and omitted due to space limit). Therefore,
our data perturbation algorithm solves the relaxed formula-
p ‚àà [0, 1]n.
tion of (4.5) by replacing dp with dr
Then, we obtain dp by rounding each entry dr
p(i) to 1 with
probability dr
4.3.4 Theoretical Analysis
We theoretically analyze privacy and utility, as well as
p in which dr
p(i).
time complexity.
Privacy Analysis. We show the diÔ¨Äerential privacy guar-
antee of S-DPDP algorithm:
Theorem 2
(S-DPDP Privacy Analysis). S-DPDP al-
gorithm enjoys -diÔ¨Äerential privacy.
item/categorycategory 1category 2category 3category 4category 5MAEerror when privacy budget ùùê=ùüèitem 1item2item3item4item5Sensitivity3.612.363.342.361.382.61globalsensitivity equals to 3 for all categories3185(cid:89)
Proof. We observe that there is no privacy loss in phase
2 of S-DPDP algorithm as it is considered as post-processing
on diÔ¨Äerentially private category aggregates without the ac-
cess of user private data. Since any post-processing of the
answers cannot diminish this rigorous privacy guarantee ac-
cording to Hey et al. [12], we only need to focus on analyzing
the privacy guarantee in phase 1 of S-DPDP algorithm.
Let D1, D2 be neighboring datasets (i.e., d(D1, D2) = 1)
and f (Di) be the category aggregates of user‚Äôs private data
i). For any r = (r1, . . . , rc) ‚àà Range(S-DPDP),
Di (w.r.t. dr
we have the following analysis:
Pr[S-DPDP(D1)(j) = r(j)]
Pr[S-DPDP(D2)(j) = r(j)]
Pr[S-DPDP(D1) = r]
Pr[S-DPDP(D2) = r]
(cid:16) ‚àí(cid:88)
(cid:16) ‚àí max
j‚ààC
1
z(j)
=
j‚ààC
|fj(D1) ‚àí fj(D2)|(cid:17)
(cid:88)
1
‚â• exp
‚â• exp
d(D1,D2)=1
z(j)
j‚ààC
|fj(D1) ‚àí fj(D2)|(cid:17) ‚â• e
‚àí
The Ô¨Årst step holds due to the independently injected noises
on each category aggregate; the second step is derived from
the injected Laplace noises and triangle inequality; and the
last step holds from the Ô¨Årst constraint in (4.4), that is,
max
d(D1,D2)=1
z(j)
j‚ààC
1
|fj(D1) ‚àí fj(D2)| = max
i‚ààI
1
cij ‚â§ 
z(j)
j‚ààC
(cid:88)
(cid:88)
The proof is complete.
Utility Analysis. We show the utility bound of MAE
on category aggregates between raw and perturbed data:
Theorem 3
(S-DPDP Utility Analysis). The expected
MAE between raw and perturbed category aggregates (via S-
DPDP algorithm) is upper bounded by 2(cid:107)z(cid:107)1/c, where z is
the optimal solution of (4.4).
Proof. Let z(j), lj, rj be the jth entry in vectors z, l, r.
E[c ¬∑ MAE] = E
j=1
(cid:104) c(cid:88)
|Lap(z(j))|(cid:105)
(cid:105)
(cid:104)(cid:107)l + r(cid:107)1
‚â§ E
(cid:104) c(cid:88)
‚â§ c(cid:88)
j=1
j=1
= (cid:107)z(cid:107)1 + E
E[|Lap(z(j))|] + E
|CR(j) ‚àí CP (j)|(cid:105)
(cid:104) c(cid:88)
| max{lj, rj}|(cid:105)
(cid:104) c(cid:88)
(cid:105)
j=1
(lj + rj)
+ E
j=1
Then, let xj be the random variable representing noisy
aggregate on category j with probability density function
œÜ(xj). We analyze the bound of E
as follows:
E
¬∑¬∑¬∑
(cid:105)
(cid:104)(cid:107)l + r(cid:107)1
(cid:90)
(cid:104)(cid:107)l + r(cid:107)1|x1, . . . , xc
(cid:90) (cid:16) c(cid:88)
(cid:104)(cid:90)
(cid:104)
(cid:90)
(cid:90)
c(cid:88)
¬∑¬∑¬∑
(cid:104)
(cid:105)
j=1
E
E
lj + rj|xj
œÜ(xj)dxj
E
=
‚â§
=
(cid:105)
(cid:104)(cid:107)l + r(cid:107)1
(cid:105) c(cid:89)
(cid:105)(cid:17) c(cid:89)
(cid:105) ‚â§ c(cid:88)
j=1
j=1
j=1
j=1
lj + rj|x1, . . . , xc
œÜ(xj)dx1 ¬∑¬∑¬∑ dxc
œÜ(xj)dx1 ¬∑¬∑¬∑ dxc
|z(j)| = (cid:107)z(cid:107)1
(cid:104)
n(cid:88)
E
where the Ô¨Årst step derives from the law of total expectation;
the last step holds because for each category j ‚àà C, we have
the following inequality:
(cid:105)
(cid:104)
(cid:105)
lj + rj|x1, . . . , xc
= E
lj + rj|xj
=
|cijdr
p(i) ‚àí N A(j)|dr
p(i) ‚â§ |xj| = |zj|
i=1
where the last step holds from the fact that dr
the optimal solution to relaxed (4.4).
p(i) ‚â§ 1 and
Time Complexity Analysis. We analyze the time com-
plexity to phase 1 and 2 respectively. The time complex-
ity of phase 1 is determined by solving (4.4).
It is not
hard to see that both vector variables z1 and z2 have di-
mension c and there are n + 3c constraints. In practice, c
is equal to the number of categories from public informa-
tion, which is actually a constant. Therefore, according to
Megiddo [20], the time complexity of solving (4.4) is O(n).
In phase 2, we Ô¨Årst solve the relaxed (4.5), which is equiv-
alent to solving the non-negative least square programming
p ‚â• 0 that has been well studied in
1
literature [2] and will be shown in Section 6.2 with fast run-
ning time in practice. The last rounding phase takes another
O(n) time.
4.4 Design of Privacy QuantiÔ¨Åcation (C-5)
p ‚àí NA(cid:107)2
2(cid:107)CT dr
2, s.t. dr
In this subsection, we design the privacy quantiÔ¨Åcation
(C-5) component to quantify ‚ÄúPerturbed Release‚Äù level to a
privacy budget , which is used to feed into S-DPDP al-
gorithm in data perturbation component (C-4) discussed
above. SpeciÔ¨Åcally, we devise a novel Single Privacy Budget
QuantiÔ¨Åcation (S-PBQ) algorithm to select a privacy budget
 to optimize the utility of perturbed data.
The idea of S-PBQ algorithm is based on our observation
that the utility loss of perturbed data will not signiÔ¨Åcantly de-
crease any more when privacy budget  is larger than some
threshold. In detail, S-PBQ algorithm Ô¨Årst understands the
distribution of noise magnitude to each category aggregate
and then search the optimal privacy budget after which util-
ity loss can be negligible. Next, we discuss about the details
of these two phases in S-PBQ algorithm.
Phase 1: Noise magnitude determination. We follow the
idea of phase 1 in S-DPDP algorithm. The key tweak is
based on the following observation: when we replace  in
phase 1 of Algorithm 1 with an arbitrary constant Œ±, it is
easy to see that each entry in new solution z(cid:48) is propor-
tional to that in z obtained in phase 1 of Algorithm 1. The
proportionality constant is equal to 
plicity and then obtain z(cid:48)
ical programming similar as (4.4):
Therefore, in this phase, we consider using Œ± = 1 for sim-