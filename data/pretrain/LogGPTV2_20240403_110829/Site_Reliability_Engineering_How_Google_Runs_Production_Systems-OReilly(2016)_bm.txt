Timeline 5
2015-10-21 (all times UTC)Timeline 5
2015-10-21 (all times UTC)
• 14:51 News reports that a new Shakespearean sonnet has been discovered in a 	Delorean’s glove compartment
• 14:53 Traffic to Shakespeare search increases by 88x after post to /r/shakespeare points to Shakespeare search engine as place to find new sonnet (except we don’t have the sonnet yet)
• 14:54 OUTAGE BEGINS — Search backends start melting down under load• 14:55 docbrown receives pager storm, ManyHttp500s from all clusters
• 14:57 All traffic to Shakespeare search is failing: see 	
• 14:58 docbrown starts investigating, finds backend crash rate very high
• 15:01 INCIDENT BEGINS docbrown declares incident #465 due to cascading 	failure, coordination on #shakespeare, names jennifer incident commander• 15:02 someone coincidentally sends email to shakespeare-discuss@ re sonnet dis‐	covery, which happens to be at top of martym’s inbox
• 15:03 jennifer notifies shakespeare-incidents@ list of the incident
• 15:04 martym tracks down text of new sonnet and looks for documentation on 	corpus update
• 15:06 docbrown finds that crash symptoms identical across all tasks in all clus‐	ters, investigating cause based on application logs4 This section is really for near misses, e.g., “The goat teleporter was available for emergency use with other 	animals despite lack of certification.”
5 A “screenplay” of the incident; use the incident timeline from the Incident Management document to start 	filling in the postmortem’s timeline, then supplement with other relevant entries.
Example Postmortem  |  489Example Postmortem  |  489
• 15:07 martym finds documentation, starts prep work for corpus update
• 15:10 martym adds sonnet to Shakespeare’s known works, starts indexing job• 15:12 docbrown contacts clarac & agoogler (from Shakespeare dev team) to help 	with examining codebase for possible causes• 15:18 clarac finds smoking gun in logs pointing to file descriptor exhaustion, 	confirms against code that leak exists if term not in corpus is searched for• 15:20 martym’s index MapReduce job completes
• 15:21 jennifer and docbrown decide to increase instance count enough to drop 	load on instances that they’re able to do appreciable work before dying and being 	restarted• 15:23 docbrown load balances all traffic to USA-2 cluster, permitting instance 	count increase in other clusters without servers failing immediately
• 15:25 martym starts replicating new index to all clusters
• 15:28 docbrown starts 2x instance count increase
• 15:32 jennifer changes load balancing to increase traffic to nonsacrificial clusters• 15:33 tasks in nonsacrificial clusters start failing, same symptoms as before• 15:34 found order-of-magnitude error in whiteboard calculations for instance 	count increase• 15:36 jennifer reverts load balancing to resacrifice USA-2 cluster in preparation 	for additional global 5x instance count increase (to a total of 10x initial capacity)• 15:36 OUTAGE MITIGATED, updated index replicated to all clusters
• 15:39 docbrown starts second wave of instance count increase to 10x initial 	capacity• 15:41 jennifer reinstates load balancing across all clusters for 1% of traffic• 15:43 nonsacrificial clusters’ HTTP 500 rates at nominal rates, task failures inter‐	mittent at low levels
• 15:45 jennifer balances 10% of traffic across nonsacrificial clusters
• 15:47 nonsacrificial clusters’ HTTP 500 rates remain within SLO, no task failures 	observed
• 15:50 30% of traffic balanced across nonsacrificial clusters• 15:55 50% of traffic balanced across nonsacrificial clusters
• 16:00 OUTAGE ENDS, all traffic balanced across all clusters
• 16:30 INCIDENT ENDS, reached exit criterion of 30 minutes’ nominal 	performance
490  |  Appendix D: Example Postmortem
Supporting information: 6
• Monitoring dashboard,
6 Useful information, links, logs, screenshots, graphs, IRC logs, IM logs, etc.
Example Postmortem  |  491Example Postmortem  |  491
APPENDIX E Launch Coordination Checklist
This is Google’s original Launch Coordination Checklist, circa 2005, slightly abridged for brevity:
Architecture
• Architecture sketch, types of servers, types of requests from clients• Programmatic client requests
Machines and datacenters
• Machines and bandwidth, datacenters, N+2 redundancy, network QoS• New domain names, DNS load balancingVolume estimates, capacity, and performance
• HTTP traffic and bandwidth estimates, launch “spike,” traffic mix, 6 months out• Load test, end-to-end test, capacity per datacenter at max latency
• Impact on other services we care most about
• Storage capacity
System reliability and failover
• What happens when:
— Machine dies, rack fails, or cluster goes offline— Network fails between two datacenters493
• For each type of server that talks to other servers (its backends):
	— How to detect when backends die, and what to do when they die
	— How to terminate or restart without affecting clients or users
	— Load balancing, rate-limiting, timeout, retry and error handling behavior• Data backup/restore, disaster recovery
Monitoring and server managementMonitoring and server management
• Monitoring internal state, monitoring end-to-end behavior, managing alerts• Monitoring the monitoring
• Financially important alerts and logs
• Tips for running servers within cluster environment
• Don’t crash mail servers by sending yourself email alerts in your own server code
Security
• Security design review, security code audit, spam risk, authentication, SSL• Prelaunch visibility/access control, various types of blacklistsAutomation and manual tasks
• Methods and change control to update servers, data, and configs
• Release process, repeatable builds, canaries under live traffic, staged rollouts
Growth issues
• Spare capacity, 10x growth, growth alerts
• Scalability bottlenecks, linear scaling, scaling with hardware, changes needed• Caching, data sharding/resharding
External dependenciesExternal dependencies
• Third-party systems, monitoring, networking, traffic volume, launch spikes• Graceful degradation, how to avoid accidentally overrunning third-party services• Playing nice with syndicated partners, mail systems, services within Google
494  |  Appendix E: Launch Coordination Checklist
Schedule and rollout planning
• Hard deadlines, external events, Mondays or Fridays• Standard operating procedures for this service, for other services
Launch Coordination Checklist  |  495
APPENDIX F
Example Production Meeting Minutes
Date: 2015-10-23
Attendees: agoogler, clarac, docbrown, jennifer, martym
Announcements:
• Major outage (#465), blew through error budget
Previous Action Item Review
• Certify Goat Teleporter for use with cattle (bug 1011101)— Nonlinearities in mass acceleration now predictable, should be able to target 	accurately in a few days.
Outage Review
• New Sonnet (outage 465)
— 1.21B queries lost due to cascading failure after interaction between latent bug (leaked file descriptor on searches with no results) + not having new sonnet in corpus + unprecedented & unexpected traffic volume
— File descriptor leak bug fixed (bug 5554825) and deployed to prod— Looking into using flux capacitor for load balancing (bug 5554823) and using 	load shedding (bug 5554826) to prevent recurrence
— Annihilated availability error budget; pushes to prod frozen for 1 month unless docbrown can obtain exception on grounds that event was bizarre & unforeseeable (but consensus is that exception is unlikely)
497
Paging Events497
Paging Events