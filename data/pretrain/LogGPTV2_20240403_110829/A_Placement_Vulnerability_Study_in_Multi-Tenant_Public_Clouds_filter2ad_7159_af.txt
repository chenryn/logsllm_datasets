0
0
0
0
0
Figure 22: Launch strategy and co-residency detection execu-
tion times. The run conﬁgurations v× a indicates the number of
victims vs. number of attackers launched. The error bars show the
standard deviation across at least 7 runs.
Run
conﬁg.
10x10
10x20
10x30
20x20
20x30
30x30
Average Cost ($)
Maximum Cost ($)
GCE
0.137
0.370
1.049
0.770
1.482
1.866
EC2
0.260
0.520
0.780
0.520
1.560
1.560
Azure
0.494
1.171
2.754
2.235
3.792
5.304
GCE
0.140
0.412
1.088
1.595
1.581
2.433
EC2
0.260
0.520
1.560
1.040
1.560
1.560
Azure
0.819
1.358
3.257
3.255
4.420
7.965
Figure 23: Cost of running a launch strategy (in dollars). Max-
imum cost column refers to the maximum cost we incurred out
of all the runs for that particular conﬁguration and cloud provider.
The cost per hour of small instances at the time of this study were:
0.05, 0.026 and 0.06 dollars for GCE, EC2 and Azure, respec-
tively. The minimum and maximum costs are in bold.
any effect on the actual chance of co-residence, we believe
such placement behaviors (or the lack of) may affect VM
placement.
We also experimented with medium instances and suc-
cessfully placed few co-located VMs on both EC2 and
GCE by employing similar successful strategies learned
with small instances.
USENIX Association  
24th USENIX Security Symposium  925
Run Conﬁg.
Pr [ Ev
a > 0 ]
10x10
0.10
10x20
0.18
10x30
0.26
20x20
0.33
20x30
0.45
30x30
0.60
Figure 24: Probability of co-residency under the reference
placement policy.
5.6 Cost of Launch Strategies
Recall that the cost of a launch strategy from Section 3,
CS = a∗ P(atype)∗ Td(v,a). In order to calculate this cost,
we need Td(v,a) which is the time taken to detect co-
location with a attackers and v victims. Figure 22 shows
the average time taken to complete launching attacker in-
stances and complete co-residency detection for each run
conﬁguration. Here the measured co-residency detection is
the parallelized version discussed in Section 4.2 and also
includes time taken to detect co-residency within each ten-
ant account. Hence, for these reasons the time to detect
co-location is an upper bound for a realistic and highly op-
timized co-residency detection mechanism.
We calculate the cost of executing each launch strat-
egy under the three public clouds. The result is summa-
rized in Figure 23. Note that we only consider the cost in-
curred by the compute instances because the cost for other
resources such as network and storage, was insigniﬁcant.
Also note that EC2 bills every hour even if an instance runs
less than an hour [16], whereas GCE and Azure charge per
minute of instance activity. This difference is considered
in our cost calculation. Overall, the maximum cost we in-
curred was about $8 for running 30 VMs for 4 hours 25
minutes on Azure and a minimum of 14 cents on GCE for
running 10 VMs for 17 minutes. We incurred the highest
cost for all the launch strategies in Azure because of overall
higher cost per hour and partly due to longer tests due to
our co-residency detection methodology.
5.7 Summary of Placement Vulnerabilities
In this section, we return to the secure reference placement
policy introduced in Section 3 and use it to identify place-
ment vulnerabilities across all the three clouds. Recall that
the probability of at least one pair of co-residency under
this random placement policy is given by Pr [ Ev
a > 0 ] =
1− (1− v/N)a, where Ev
a is the random variable denoting
the number of co-location observed when placing a attacker
VMs among N = 1000 total machines where v machines
are already picked for the v victim VMs. First, we evaluate
this probability for various run conﬁgurations that we ex-
perimented with in the public clouds. The probabilities are
shown in Figure 24.
Recall that a launch strategy in a cloud implies a place-
ment vulnerability in that cloud’s placement policy if its
normalized success rate is greater than 1. The normalized
success rate of the strategy is the ratio of the chance of co-
location under that launch strategy to the probability of co-
location in the reference policy (Pr [ Ev
a > 0 ]). Below is a
list of selected launch strategies that escalate to placement
Strategy
S1 & S2
S3
S4(i)
S4(ii)
S5
v & a
10
30
20
20
20
a(cid:29)
688
227
105
342
110
Cost beneﬁt ($)
Normalized Success
113.87
32.75
4.36
53.76
4.83
10
1.67
2.67
3.03
1.48
Figure 25: Cost beneﬁt analysis. N = 1000, P(atype) = 0.026,
which is the cost per instance-hour on EC2 (the cheapest). For
simplicity Td(v,a) = (v∗ a)∗ 3.85, where 3.85 is fastest average
time to detect co-residency per instance-pair. Here, v × a is the
run conﬁguration of the strategy under test. Note that the cost
beneﬁt is the additional cost incurred under the reference policy,
hence is equal to cost incurred by a(cid:29) − a additional VMs.
vulnerabilities using our reference policy with their normal-
ized success rate in parenthesis.
(S1) In Azure, launch ten attacker VMs closely after the
victim VMs are launched (1.0/0.10).
(S2) In EC2 and GCE, if there are known victims in any of
the smaller datacenters, launch at least ten attacker VMs
with a non-zero delay (1.0/0.10).
(S3) In all three clouds, launch 30 attacker instances, either
with no delay (Azure) or one hour delay (EC2, GCE)
from victim launch, to get co-located with one of the 30
victim instances (1.00/0.60).
(S4) (i) In Amazon EC2, launch 20 attacker VMs with a
delay of 5 minutes or more after the victims are launched
(0.88/0.33). (ii) The optimal delay between victim and
attacker VM launches is around 4 hours for a 20x20 run
(1.00/0.33).
(S5) In Amazon EC2, launch the attacker VMs with 1 hour
after the victim VMs are launched where the time of day
falls in the early morning, i.e., 02:00 to 10:00hrs PST
(0.89/0.60).
Cost beneﬁt. Next, we quantify the cost beneﬁt of each
of these strategies over the reference policy. As the success
rate of any launch strategy on a vulnerable placement pol-
icy is greater than what is possible in the reference policy,
we need more attacker instances in the reference policy to
achieve the same success rate. We calculate this number
of attacker instances a(cid:29) using: a(cid:29) = ln(1−Sv
a)/ln(1− v/N),
where, Sv
a is the success rate of a strategy with run conﬁg-
uration of v× a. The result of this calculation is presented
in Figure 25. The result shows that the best strategy, S1 and
S2, on all three cloud providers is $114 cheaper than what
is possible in the reference policy.
It is also evident that these metrics enable evaluating and
comparing various launch strategies and their efﬁcacy on
various placement policies both on robust placements and
attack cost. For example, note that although the normal-
ized success rate of S3 is lower than S4, it has a higher cost
beneﬁt for the attacker.
926  24th USENIX Security Symposium 
USENIX Association
5.8 Limitations
Although we exhaustively experimented with a variety of
placement variables, the results have limitations. One ma-
jor limitation of this study is the number of placement vari-
ables and the set of values for the variables that we used to
experiment. For example, we limited our experiments with
only one instance type, one availability zone per region and
used only one account for the victim VMs. Although differ-
ent instance types may exhibit different placement behav-
ior, the presented results still holds strong for the chosen
instance type. The only caveat that may affect the results is
if the placement policy use user account ID for VM place-
ment decisions. Since, we experimented with only one vic-
tim account (separate from the designated attacker account)
across all providers, these results, in the worst case, may
have captured the placement behavior of an unlucky vic-
tim account that was subject to similar placement decisions
(and hence co-resident) as that of the VMs from the desig-
nated attacker account.
Even though we ran at least 190 runs per cloud provider
over a period of 3 months to increase statistical signiﬁcant
of our results, we were still limited to at most 9 runs per run
conﬁguration (with 3 runs per time of day). These limita-
tions have only minor bearing on the results presented, if at
all any, and the reported results are signiﬁcant and impact-
ful for cloud computing security research.
6 Related Work
VM placement vulnerability studies. Ristenpart et
al. [29] ﬁrst studied the placement vulnerability in public
clouds, which showed that a malicious cloud tenant may
place one of his VMs on the same machine as a target
VM with high probability. Placement vulnerabilities ex-
ploited in their study include publicly available mapping of
VM’s public/internal IP addresses, disclosure of Dom0 IP
addresses, and a shortcut communication path between co-
resident VMs. Their study was followed by Xu et al. [33]
and further extended by Herzberg et al. [25]. However, the
results of these studies have been outdated by the recent
development of cloud technologies, which is the main mo-
tivation of our work.
Concurrent with our work, Xu et al. [34] conducted a sys-
tematic measurement study of co-resident threats in Ama-
zon EC2. Their focus, however, is in-depth evaluation
of co-residency detection using network route traces and
quantiﬁcation of co-residence threats on older generation
instances with EC2’s classic networking (prior to Amazon
VPC). In contrast, we study placement vulnerabilities in the
context of VPC on EC2, as well as on Azure and GCE. The
two studies are mostly complementary and strengthen the
arguments made by each other.
New VM placement policies to defend against placement
attacks have been studied by Han et al. [23, 24] and Azar
et al. [18]. It is unclear, however, whether their proposed
policies work against the performance and reliability goals
of public cloud providers.
Co-residency detection techniques. Techniques for co-
residency detection have been studied in various contexts.
We categorize these techniques into one of the two classes:
side-channel approaches to detecting co-residency with un-
cooperative VMs and covert-channel approaches to detect-
ing co-residency with cooperative VMs.
Side-channels allow one party to exﬁltrate secret infor-
mation from another; therefore these approaches may be
adapted in practical placement attack scenarios with targets
not controlled by the attackers. Network round-trip timing
side-channel was used by Ristenpart et al. [29] to detect
co-residency. Zhang et al. [36] developed a system called
HomeAlone to enable VMs to detect third-party VMs us-
ing timing side-channels in the last level caches. Bates et
al. [19] proposed a side-channel for co-residency detection
by causing network trafﬁc congestion in the host NICs from
attacker-controlled VMs; the interference of target VM’s
performance, if the two VMs are co-resident, should be de-
tectable by remote clients. Kohno et al. [27] explored tech-
niques to ﬁngerprint remote machines using timestamps in
TCP or ICMP based network probes, although their ap-
proach was not designed for co-residency detection. How-
ever, none of these approaches works effectively in modern
cloud infrastructures.
Covert-channels on shared hardware components can
be used for co-residency detection when the pair of VMs
are cooperative. Coarse-grained covert-channels in CPU
caches and hard disk drives were used in Ristenpart et
al. [29] for co-residency conﬁrmation. Xu et al. [33] estab-
lished covert-channels in shared last level caches between
two colluding VMs in the public clouds. Wu el al. [32]
exploited memory bus as a covert-channel on modern x86
processors, in which the sender issues atomic operations
on memory blocks spanning multiple cache lines to cause
memory bus locking or similar effects on recent processors.
However, covert-channels proposed in the latter two studies
were not designed for co-residency detection, while those
developed in our work is tuned for such purposes.
7 Conclusion and Future Work
Multi-tenancy in public clouds enable co-residency attacks.
In this paper, we revisited the problem of placement —
can an attacker achieve co-location? — in modern public
clouds. We ﬁnd that while past techniques for verifying co-
location no longer work, insufﬁcient performance isolation
in hardware still allows detection of co-location. Further-
more, we show that in the three popular cloud providers
(EC2, GCE and Azure), achieving co-location is surpris-
ingly simple and cheap. It is even simpler and costs noth-
ing to achieve co-location in some PaaS clouds. Our results
demonstrate that even though cloud providers have massive
datacenters with numerous physical servers, the chances
USENIX Association  
24th USENIX Security Symposium  927
of co-location are far higher than expected. More work is
needed to achieve a better balance of efﬁciency and security
using smarter co-location-aware placement policies.
Acknowledgments
This work was funded by the National Science Founda-
tion under grants CNS-1330308, CNS-1546033 and CNS-
1065134. Swift has a signiﬁcant ﬁnancial interest in Mi-
crosoft Corp.
References
[1] Amazon ec2 instance store.
AWSEC2/latest/UserGuide/InstanceStorage.html.
http://docs.aws.amazon.com/
[2] Amazon elastic compute cloud. http://aws.amazon.com/ec2/.
[3] Apache libcloud. http://libcloud.apache.org/.
[4] Aws
http://aws.amazon.com/
beanstalk.
elastic
elasticbeanstalk/.
[5] Aws innovation at scale,
re:invent 2014, slide 9-10.
http:
//www.slideshare.net/AmazonWebServices/spot301-
aws-innovation-at-scale-aws-reinvent-2014.
[6] Google
compute
compute/.
engine.
https://cloud.google.com/
[7] Google compute engine – disks. https://cloud.google.com/
compute/docs/disks/.
[8] Google compute enginer autoscaler. http://cloud.google.com/
compute/docs/autoscaler/.
[9] Haproxy: The reliable, high performance tcp/http load balancer.
http://www.haproxy.org/.
[10] Heroku devcenter: Dynos and the dyno manager,
ip ad-
dresses. https://devcenter.heroku.com/articles/dynos#
ip-addresses.
[11] Intel
Ivy Bridge cache replacement policy.
http://blog.
stuffedcow.net/2013/01/ivb-cache-replacement/.
[12] Olio workload.
https://cwiki.apache.org/confluence/
display/OLIO/The+Workload.
[13] Rightscale. http://www.rightscale.com.
[14] Virtual machine and cloud service sizes for azure. https://msdn.
microsoft.com/en-us/library/azure/dn197896.aspx.
[15] Windows azure. http://www.windowsazure.com/.
[16] Amazon ec2 pricing, 2015.
http://aws.amazon.com/ec2/
pricing/.
[17] Amazon Web Services. Extend your it infrastructure with amazon
virtual private cloud. Technical report, Amazon, 2013.
[18] Y. Azar, S. Kamara, I. Menache, M. Raykova, and B. Shepard. Co-
location-resistant clouds. In In Proceedings of the ACM Workshop
on Cloud Computing Security, pages 9–20, 2014.
[19] A. Bates, B. Mood, J. Pletcher, H. Pruse, M. Valafar, and K. But-
ler. Detecting co-residency with active trafﬁc analysis techniques.
In Proceedings of the 2012 ACM Workshop on Cloud Computing
Security Workshop, pages 1–12. ACM, 2012.
[20] B. Beach. Virtual private cloud. In Pro Powershell for Amazon Web
Services, pages 67–88. Springer, 2014.
[21] B. Farley, A. Juels, V. Varadarajan, T. Ristenpart, K. D. Bowers,
and M. M. Swift. More for your money: Exploiting performance
heterogeneity in public clouds.
In Proceedings of the Third ACM
Symposium on Cloud Computing. ACM, 2012.
[22] M. Ferdman, A. Adileh, O. Kocberber, S. Volos, M. Alisafaee,
D. Jevdjic, C. Kaynak, A. D. Popescu, A. Ailamaki, and B. Falsaﬁ.
Clearing the clouds: a study of emerging scale-out workloads on
modern hardware. In Proceedings of the seventeenth international
conference on Architectural Support for Programming Languages
and Operating Systems. ACM, 2012.
[23] Y. Han, T. Alpcan, J. Chan, and C. Leckie. Security games for vir-
tual machine allocation in cloud computing. In Decision and Game
Theory for Security. Springer International Publishing, 2013.
[24] Y. Han, J. Chan, T. Alpcan, and C. Leckie. Virtual machine alloca-
tion policies against co-resident attacks in cloud computing. In IEEE
International Conference on Communications,, 2014.
[25] A. Herzberg, H. Shulman, J. Ullrich, and E. Weippl. Cloudoscopy:
Services discovery and topology mapping. In 2013 ACM Workshop
on Cloud Computing Security Workshop, pages 113–122, 2013.
[26] D. Kanter.
L3 cache and ring interconnect.
realworldtech.com/sandy-bridge/8/.
http://www.
[27] T. Kohno, A. Broido, and K. Claffy. Remote physical device ﬁnger-
printing. In Security and Privacy, 2005 IEEE Symposium on, pages
211–225. IEEE, 2005.
[28] D. Mosberger and T. Jin. httperfa tool for measuring web server
performance. ACM SIGMETRICS Performance Evaluation Review,
26(3):31–37, 1998.
[29] T. Ristenpart, E. Tromer, H. Shacham, and S. Savage. Hey, you, get
off of my cloud: Exploring information leakage in third-party com-
pute clouds. In Proceedings of the 16th ACM conference on Com-
puter and communications security, pages 199–212. ACM, 2009.
[30] V. Varadarajan, T. Kooburat, B. Farley, T. Ristenpart, and M. M.
Swift. Resource-freeing attacks: Improve your cloud performance
(at your neighbor’s expense). In Proceedings of the 2012 ACM con-
ference on Computer and communications security, pages 281–292.
ACM, 2012.
[31] L. Wang, A. Nappa, J. Caballero, T. Ristenpart, and A. Akella.
Whowas: A platform for measuring web deployments on IaaS
clouds.
In Proceedings of the 2014 Conference on Internet Mea-
surement Conference, pages 101–114. ACM, 2014.
[32] Z. Wu, Z. Xu, and H. Wang. Whispers in the hyper-space: High-
speed covert channel attacks in the cloud. In USENIX Security sym-
posium, pages 159–173, 2012.
[33] Y. Xu, M. Bailey, F. Jahanian, K. Joshi, M. Hiltunen, and R. Schlicht-
ing. An exploration of L2 cache covert channels in virtualized en-
vironments.
In Proceedings of the 3rd ACM workshop on Cloud
computing security workshop, pages 29–40. ACM, 2011.
[34] Z. Xu, H. Wang, and Z. Wu. A measurement study on co-residence
threat inside the cloud. In USENIX Security Symposium, 2015.
[35] Y. Yarom and K. Falkner. Flush+reload: A high resolution, low
noise, L3 cache side-channel attack. In 23rd USENIX Security Sym-
posium, pages 719–732. USENIX Association, 2014.
[36] Y. Zhang, A. Juels, A. Oprea, and M. K. Reiter. Homealone: Co-
residency detection in the cloud via side-channel analysis. In Pro-
ceedings of the 2011 IEEE Symposium on Security and Privacy,
pages 313–328. IEEE Computer Society, 2011.
[37] Y. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart. Cross-VM side
channels and their use to extract private keys. In Proceedings of the
2012 ACM conference on Computer and communications security,
pages 305–316. ACM, 2012.
[38] Y. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart. Cross-tenant
side-channel attacks in PaaS clouds.
In Proceedings of the 2014
ACM SIGSAC Conference on Computer and Communications Secu-
rity, pages 990–1003. ACM, 2014.
[39] F. Zhou, M. Goel, P. Desnoyers, and R. Sundaram. Scheduler vul-
nerabilities and attacks in cloud computing. CoRR, abs/1103.0759,
2011.
928  24th USENIX Security Symposium 
USENIX Association