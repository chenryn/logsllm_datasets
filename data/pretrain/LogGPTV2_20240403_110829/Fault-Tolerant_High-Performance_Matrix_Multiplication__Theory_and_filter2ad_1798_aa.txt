title:Fault-Tolerant High-Performance Matrix Multiplication: Theory and
Practice
author:John A. Gunnels and
Robert A. van de Geijn and
Daniel S. Katz and
Enrique S. Quintana-Ort&apos;ı
Fault-Tolerant  High-Performance  Matrix Multiplication: 
Theory and Practice* 
John A. Gunnels 
Department of  Computer Sciences 
The University of Texas at Austin 
Taylor Hall 2.124 
Austin, TX 78712 
gunnels @cs.utexas.edu 
Enrique S. Quintana-Orti 
Dept. de InformAtica 
Universidad Jaume I 
12080 Castellh 
Spain 
quintana@ inf.uji.es 
Daniel S. Katz 
Jet Propulsion Laboratory 
California Institute of Technology 
Pasadena, CA 9 1 109-8099 
PI:EMAIL 
Robert A. van de Geijn 
Department of Computer Sciences 
The University of Texas at Austin 
Taylor Hall 2.124 
Austin, TX 787 12 
rvdg @ cs.utexas.edu 
Abstract 
In  this  papel;  we  extend  the  theory  and  practice  re- 
garding  algorithmic fault-tolerant matrix-matrix  multipli- 
cation,  C  =  AB,  in a  number of  ways.  First,  we  pro- 
pose low-overhead methods for detecting errors introduced 
not only  in C but also in A and/or  B.  Second, we  show 
that, theoretically,  these  methods  will  detect all errors  as 
long  as only one entry  is  corrupted.  Third, we propose  a 
low-overhead roll-back approach to correct errors once de- 
tected.  Finally,  we give  a  high-petformance implementa- 
tion of matrix-matrix multiplication that incorporates these 
error detection  and correction methods.  Empirical  results 
demonstrate that these methods work well in practice while 
imposing an acceptable level of  overhead  relative  to high- 
pet$ormance  implementations without fault-tolerance. 
1  Introduction 
The  high-performance implementation  of  many  linear 
algebra  operations  depends  on  the  ability  to  cast  most 
'This  work was partially performed  at  the Jet  Propulsion  Laboratory, 
Califomia  Institute  of  Technology,  under  a  contract  with  the  National 
Aeronautics  and  Space  Administration.  The  work  was  funded  by  the 
Remote  Exploration  and  Experimentation  Project  (a  part  of  the  NASA 
High Performance  Computing  and  Communications  Program  funded by 
the NASA Office of Space Science). 
of  the  computation  in  terms  of  matrix-matrix  multiplica- 
tion [2, 3,6, 121. High-performance for matrix-matrix mul- 
tiplication  itself  results  from the fact  that the cost of mov- 
ing b  x b blocks  of the operands between  the layers of the 
memory hierarchy is proportional  to b2, while this cost can 
be amortized over O(b3) computations. These observations 
impact  algorithmic  fault-tolerance  for  linear  algebra  rou- 
tines  that  spend most  of  their  time  in  matrix-matrix mul- 
tiplication  in the following sense: 
0  If the matrix-matrix multiplication  kernel used is fault- 
tolerant, the entire operation is largely fault-tolerant. 
0  Ensuring the integrity of a b  x  b block of a matrix can 
be expected to cost O(b2) time.  This expense can be 
amortized over the  0 ( b 3 )  operations performed  with 
that data. 
Thus, not only is the availability of  a fault-tolerant  matrix- 
matrix  multiplication  an  important  first  step  towards  cre- 
ating fault-tolerant  linear  algebra libraries,  but  there is  an 
inherent  opportunity for adding  fault-tolerance  to  matrix- 
matrix multiplication  while retaining high-performance. 
The primary goal for our mechanism is to detect a maxi- 
mal fraction of errors while introducing minimal overhead. 
As argued in the previous paragraph, for the matrix product, 
with a cubic cost in floating-point  arithmetic operations, we 
can expect to pay  at  least a quadratic cost.  Thus, the  goal 
is to find a mechanism with a quadratic cost. We follow, in 
0-7695-1101-5\01 $10.00 0 2001 IEEE 
47 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:04:59 UTC from IEEE Xplore.  Restrictions apply. 
that sense, the technique described in  [ 13, 141. In those pa- 
pers, the correctness of C = AB is established by checking 
d  = Cw - ABw  for  a checksum vector w.  The matrix- 
matrix multiplication  is assumed to have been successful if 
d is of the order of the errors that could be introduced due 
to  the  use  of  finite  precision  arithmetic (round-off errors). 
This is  a  simple  application  of  Result-Checking  [15].  In 
this paper, we generalize this method to C t aAB + PC, 
the form of matrix-matrix  multiplication that  is part of the 
level 3 Basic Linear Algebra Subprograms (BLAS) [ 5 ] ,  and 
sharpen  the  theory  behind  the  method.  In  particular,  we 
show  that  to  guarantee  detection  of  a  single  error  intro- 
duced in  one of the matrices A, B ,  or C ,  one must check 
both d  = Cw - ABw and e  = v T C  - vTAB for check- 
sum  vectors  v  and  w. Finally,  we  show how  to  incorpo- 
rate the  techniques in  a high-performance  implementation 
of matrix-matrix multiplication. 
The methods we present are closely related to those de- 
scribed in  [ l l].  That paper proposes to augment matrices 
A, B ,  and C as 
A * 
&" ) 
(Here, both vT and w are checksum vectors.) By noting that 
in the absence of errors 
c*  =  ( v."c 
(w) 
) (  B  I  Bw  ) 
c* =  (*)  v c  v c w   = ( 
= 
= .4*B*, 
they show how a comparison of vTC with  vTAB and Cw 
with ABw can detect and correct errors introduced in  ma- 
trix C. 
On the surface, when comparing our methods to [ 111, it 
may appear that, from an implementation point of view, we 
simply perform the matrix multiplies separately rather than 
as part of augmented matrices. (This shows the simple con- 
nection between Result-Checking and the approach in [ 1 I].) 
However, our approach differs in a number of ways.  First, 
we go well beyond the approach in [ 111 by also developing 
a sound theory behind  the detection  of errors introduced in 
A  and  B.  Second,  by  adopting  the  techniques  developed 
in [ 141 we explicitly deal with the question of how to differ- 
entiate errors due to corruption from errors due to round-off. 
Third, we take a very different approach to the correction of 
detected  errors  by  using  a  roll-back  method.  Finally,  by 
adding fault-tolerance to a high-peqormance implementa- 
tion of matrix-matrix multiplication we verify that the theo- 
retical results can be  implemented without sacrificing high 
performance. 
The rest  of  the  paper  is  structured  as follows.  In  Sec- 
tion 2 we briefly  describe the intended domain of applica- 
tion for our methods. In Section 3 we expound upon our the- 
ory concerning the effects of the  introduction of one error 
in one of the matrices during a matrix-matrix multiplication. 
In  Section 4 we describe how to take the results from Sec- 
tion 3 from theory  to practice (although still at a high level 
of  abstraction).  A  working fault-tolerant  implementation 
of the matrix product based on a high-performance matrix- 
matrix multiplication implementation (ITXGEMM [8,9]) is 
subsequently given in  Section 5.  The experimental results 
in Section 6 reveal the low overhead introduced in the ma- 
trix  product by  our fault-detection  mechanism.  We briefly 
discuss  the  current  status  of  the  project  in  Section  7  and 
concluding remarks are given in Section 8. 
2  Target Application 
Within NASA's High Performance Computing and Com- 
munications Program, the Remote Exploration and Exper- 
imentation (REE) project  [ 11 at the Jet Propulsion Labora- 
tory aims to enable a new type of scientific investigation by 
taking commercial supercomputing technology  into space. 
Transferring such computational power to space will enable 
highly-autonomous,  flexible missions  with  substantial  on- 
board analysis capability, mitigating control latency issues 
due to fundamental light-time delays, as well  as inevitable 
bandwidth  limitations  in  the  link  between  spacecraft  and 
ground stations.  To  do this,  REE does  not  intend  to  de- 
velop  a  new  computational  platform,  but  rather  to  define 
and demonstrate a process for rapidly transferring commer- 
cial high-performance computing technology into ultra-low 
power, fault-tolerant architectures for space. 
The traditional method for protecting spacecraft compo- 
nents against faults caused  by  natural  galactic cosmic rays 
and energetic protons has been radiation-hardening.  How- 
ever, radiation-hardening  lowers the clock  speed and may 
increase the required power of a component.  Even  worse, 
the  time  needed  to design  and bring  a  radiation-hardened 
component into production  guarantees  that  it  will  be  out- 
dated  when  it  is  ready  for  use  in  space.  Furthermore,  the 
design and production expenses must be spread over a small 
number of  customers,  making the  per unit  cost very  high. 
Typically,  at  any  given  time,  radiation-hardened  compo- 
nents  have  a  p0wer:performance ratio  that  is  an  order  of 
magnitude lower, and a cost that  is several orders of mag- 
nitude  higher  than  contemporary commodity off-the-shelf 
(COTS) components. The REE project is therefore attempt- 
ing  to  use  COTS components in  space  and  handling,  via 
software, the faults that will occur. 
Most of the transient faults encountered due to radiation 
in space will be single event effects (SEES); their presence 
requires that the applications be self-checking, or tolerant of 
48 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:04:59 UTC from IEEE Xplore.  Restrictions apply. 
errors, as the first layer of fault-tolerance. Additional  soft- 
ware  layers  will  protect  against errors that  are not  caught 
by  the application  [4].  For example, one such layer would 
automatically restart programs which have crashed or hung. 
This works  in  conjunction with  self-checking routines:  if 
an error is detected, and the computation does not yield cor- 
rect results after a set number of retries,  the error handling 
scheme aborts the program so that it can be  automatically 
restarted. 
In  an  REE system, there will  be many places in  which 
SEEs can  cause errors.  Layers of memory  which  are off- 
processor (main  memory, L2 and L3 caches) can be made 
error detecting and  correcting, so that  faults  to these  lay- 
ers of memory  will  largely  be  screened.  Most  faults  will 
therefore  impact the microprocessor and its registers  or its 
L 1 cache. SEEs affecting data are particularly troublesome 
because  they  typically  have  fewer  obvious  consequences 
than  an SEE that  impacts code (e.g.  in  the LI  instruction 
cache) - the  latter  would  be  expected  to cause an excep- 
tion.  For this reason, this paper focuses on data corruption, 
specifically  in  those  components  which  are  on-processor 
(LI  cache,  registers)  which  cannot  be  protected  through 
hardware, because  while  the  REE Project  can modify  the 
off-processor memory system at relatively low cost, it can- 
not modify the processor. 
A  single  error  correction,  double  error  detection 
(SECDED)  Hamming  code  will  be  used  to  protect  off- 
processor  data.  This can be applied to cache lines of  data 
when  they  are  written  or checked when  they  are read.  In 
L2 and  L3 cache, if  the  fault rate  is sufficiently high,  it is 
possible to scrub data by using a background process on the 
processor to invalidate lines of data that have not been used 
in  some period  of  time,  though  the  REE Project  does not 
believe this will be necessary.  In main  memory, scrubbing 
will be required. This can either be implemented as a back- 
ground process (similar to that used for L2 and L3 cache), or 
in hardware, as an Field Programmable Gate Array (FPGA) 
or Application Specific Integrated Circuit (ASIC) that is on 
the memory bus. The rate of scrubbing can be tied to the the 
error detection  rate  in  order to keep the error rate roughly 
constant, for power efficiency. 
Due  to  the  nature  of  most  scientific  codes,  including 
the data processing  applications currently  being studied by 
REE,  much  of  their  time  is  spent  in  certain  common nu- 
merical subroutines - as much as 70% in one NGST (Next 
Generation Space Telescope,  the planned  successor to the 
Hubble Space Telescope) application, for example. Protect- 
ing these subroutines from faults provides one level of pro- 
tection  in  an  overall  software-implemented fault-tolerance 
scheme. 
3  Detecting Errors 
In  this  section we  develop a theoretical  foundation for 
error detection in the operation C ,  = AB where C, A, and 
B are m x n, m x k ,  and IC  x n, respectively. Here, we use 
partitionings of A and B by columns and rows, respectively: 
We also use two (possibly different) checksum vectors: 
For  simplicity,  we  first  assume that  exact arithmetic is 
employed and then  we discuss the  tolerance  threshold  for 
the case where round-off errors are present. 
3.1  Exact arithmetic 
Consider the operation C = AB and let C be the matrix 
computed when at most one element of any one of the three 
matrices  is corrupted during the computation. (We primar- 
ily  consider a  single corruption since most  errors will  be 
SEEs.)  In  other words, view  the  operation  as atomic and 
assume that before the computation one element of A or B 
is corrupted or after C = AB has been formed one element 
of C is corrupted. We can think of the error as a matrix of 
the form qeie:  added to one of the three matrices; here q is 
the magnitude of the error and e k  denotes the k-th  column 
of  the  identity  matrix.  The possible  computed results  are 
then given in Table  1 in the row labeled Y?.  Naturally, we 
wish to detect the instances in which F  = C - C is nonzero 
(or, in the presence of round-off error, “significant”).  Thus, 
we must compute or approximate the magnitude of F ,  e.g., 
as IIFllco, but we must do so without being able to form F .  
Moreover, relative to the cost of computing C, the compu- 
tation of the estimation of llFllm must be cheap. 
Right-sided error detection criterion 
Consider now the computation of  d  = Cw - Cw, where 
w is  a  vector  with  entries wi  =  1, i  =  1,. . .,n.  From 
Table  1  we  see that  if the  corruption  is  in  matrix  B  or C, 
lldllcr, = llFllm.  As we do not have C ,  but a possibly  cor- 
rupted approximation, C, we use A(Bw) instead of Cw in 
the computation of d; only three matrix-vector  multiplica- 
tions  are then required  to compute d.  These matrix-vector 
multiplications  are cheap relative to a matrix-matrix  multi- 
plication.  Computing d and its norm  is exactly  the proce- 
dure suggested in [ 141. 
49 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:04:59 UTC from IEEE Xplore.  Restrictions apply. 
Table 1. Some measurements and error detection criteria. 
or 
I I eT I I”  (=  I vi I I IF I I CO) 
,
~
~
~
~ w ~
However,  if  the  corruption  occurs  in  A,  lldllCO  = 
which  can  be  small  even  if  IIF1lm  is  large.  In 
~