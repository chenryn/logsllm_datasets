increases signiﬁcantly.
Nikravesh et al. [5] showed that network performance follows a daily pattern.
To prove that the event caused a performance degradation, we compare the
76
A. Fr¨ommgen et al.
Fig. 7. Comparison of the carriers for the HTTP measurements on Thursday.
results with all devices which where not at the venue (Fig. 6b) and those which
were not at the venue and were connected to WiFi (Fig. 6c). Here, the average
load time and the number of failures are both rather stable. We were surprised
that the number of successful requests dropped. We assume that many users who
were not at the venue stopped our app after recognizing that it was running.
Even before the performance at the venue decreases, the WiFi measurements
show a signiﬁcant lower average load time. This supports the results of existing
measurements [7]. Regarding the failure rate, Fig. 6d shows a peak failure rate
of nearly 40 % at the venue, whereas the WiFi measurements have a constantly
low failure rate. The reasons for the increased failure rate for devices not at the
venue require further investigation. The total number of requests increases after
midnight due to the continue tomorrow feature. This is not reﬂected in Fig. 6a,
as people left the venue earlier on Thursday.
To conclude, the comparison of the performance between participants at the
venue and those who were not at the venue proves that the event caused a high
performance degradation.
4.2 Carrier Analysis
Figure 7 shows the performance depending on the carrier on Thursday. The per-
formance of all carriers decreases during the event. However, the load time dis-
tribution diﬀers between the carriers (Fig. 7c). Even though Carrier 3 has the
lowest load times for the ﬁrst 50 % of all requests, it has a worse tail distrib-
ution than Carrier 1. Carrier 2 performs signiﬁcantly worse. The failure rates,
however, provide a diﬀerent view on the performance (Fig. 7d). Here, Carrier 1
Mobile Network Performance and Mobility During a Large Scale Event
77
Fig. 8. Impact of the network type on the HTTP performance.
Fig. 9. Used network types at the area.
nearly always has the highest failure rate, whereas Carrier 4 nearly always has
the lowest failure rate. Thus, the carrier with the lowest failure rate (Carrier 4)
has the second worst load time, whereas the carrier with the worst failure rate
(Carrier 1) has one of the best load times.
4.3 Network Type
Figure 8 shows the load times depending on the network type. As expected, the
network type has a huge inﬂuence on the performance. The LTE requests have
the lowest average load time and nearly no failed requests were reported. Between
20:00 and 22:30, however, the portion of participants using EDGE increased
(Fig. 9a), whereas LTE decreased. Thus, the overall performance degradation
might be partly caused by a lower portion of LTE connections.
78
A. Fr¨ommgen et al.
EDGE UMTS HSPA HSPA+ LTE
EGDE
UMTS
HSPA
HSPA+
LTE
70
21
52
45
82
76
198
101
24
58
34
75
67
293
70
(a) Transitions between network types.
(b) Signal strength map (darker:
higher signal strength).
Fig. 10. Network type and signal strength.
We assumed that an overloaded network causes many network type changes.
However, Fig. 9b shows that the network type does not change more often dur-
ing the event. The distribution of the actual transitions between network types
(Fig. 10a) shows that most transitions happen between HSPA and HSPA+.
Keeping in mind the bad performance of EDGE and UMTS, the transitions
to these two types imply a sudden performance degradation for the users. A
ﬁrst analysis how the signal strength (Fig. 10b) inﬂuences the performance did
not show any correlation. A more detailed investigation remains as future work.
4.4 Web Page Analysis
The performance of most web pages, as shown in Fig. 11a, follows the general
pattern of Fig. 6a. This supports the assumption that the ﬁrst network hops of
the client devices are overloaded. However, the page load time of the venue’s
page shows a sudden increase between midnight and 2 (Fig. 11b). We assume
that this is caused by the high load introduced by our measurements and the
high number of users at midnight.
Fig. 11. Diﬀerences between web pages regarding the page load time.
Mobile Network Performance and Mobility During a Large Scale Event
79
5 Additional Measurements
5.1 Active Measurement: DNS Lookup
In addition to the HTTP measurements, we tested the performance of DNS
during the event. Therefore, we actively executed 167,412 DNS lookups on the
smartphones. We used both popular domains and randomly generated domains
to investigate the impact of caching (mainly in the Android system). The ran-
domly generated domains often resolved to Navigation Help pages of the carriers
(e.g. 62.157.140.133 and 80.156.86.78 ). Figure 12a shows a CDF of all executed
DNS requests depending on the domain (existing, not existing) and the result
(successful, not successful). The successful requests for not existing domains
(Navigation Help resolutions) take at least 20 ms. Thus, 5 % of the not suc-
cessful requests for not existing domains already failed due to network failures.
Regarding the existing domains, it is surprising that even cached results take
up to 20 ms. For existing domains, more than 50 % of all failed requests fail in
the ﬁrst 20 ms. However, the tail of the failed requests for not existing domains is
the longest of all four. Figure 12b shows that the performance during the event
follows the same pattern as the HTTP requests. To investigate the impact of
the location on the performance, Fig. 13 shows the load time depending on the
location and the time. Even though there are diﬀerences between the locations,
we ﬁnd that at 21:00 the performance suﬀers all over the area.
Fig. 12. DNS measurement results.
5.2 Active Measurement: Traceroute
To allow correlations between the network performance and the paths in the net-
work, we executed 2202 trace routes to multiple domains. Figure 14a shows how
the path length diﬀers between the carriers. In our measurements, we observe
a longest path of 23 hops (Carrier 1), which occurs one time. For future work,
we will try to reenact results from other traceroute studies, such as Brownlee [2]
and Luckie et al. [4].
5.3 Passive Measurement: Traﬃc Stats
Beside the active measurements, we passively collected traﬃc statistics provided
by Android (Fig. 14). Except for the mobile received bytes, the metrics do not
80
A. Fr¨ommgen et al.
(a) 18:00
(b) 19:00
(c) 20:00
(d) 21:00
Fig. 13. DNS request time during the event (darker: slower)
Fig. 14. Traﬃc stats on Thursday.
signiﬁcantly change during the event. However, it is unclear why this metric
suddenly increases at midnight. In general, users downloaded 4 times more than
uploaded. This ﬁts with the average packet size, as transferred packets were not
ﬁlled. Even though these statistics include the induced traﬃc of our measure-
ments, these results do not correspond with recent measurements from other
papers. Erman et al. [3], for example, found that people uploaded as much data
as download during the Super Bowl event.
6 Related Work
Related work on large scale events concentrates on a single carrier or passive
measurements of users in the network infrastructure. Erman et al. [3] analyzed
the Super Bowl from AT&T’s perspective and provided a detailed analysis of
the performance and the user behavior. Shaﬁq et al. [6] describe provider obser-
vations of two crowded events. They present lower layer metrics, but provide
only limited insights into the actual performance available at the end device.
Additionally, they are restricted to the perspective of a few network operators.
Crowdsourcing approaches leverage users which support measurements.
Thus, they have access to details on the end device and are not restricted to
certain network operators. Nikravesh et al. [5], for example, evaluated a long
time crowdsourcing measurement. With samples from all over the world, they
provide valuable insights into the general network performance. Xu et al. [8] used
crowdsourcing to investigate a cellular network in Singapore.
Mobile Network Performance and Mobility During a Large Scale Event
81
Our work is the ﬁrst combining the beneﬁts of extensive crowdsourcing with
active measurements of a crowded event.
7 Discussion and Future Work
App-Based Crowdsourcing: Our measurement study shows that large crowd-
sourcing measurements are feasible. We convinced more than 1,000 users to
participate in our study. We noticed that people liked the idea to help us to
understand their performance issues. A small fraction of participants complained
(e.g., in the play store) about the increased data transmission and higher energy
consumption due to the app. Our measurement setup does not allow us to dis-
tinguish between the induced energy consumption of our app and a potentially
increased consumption due to the overloaded network. Future crowdsourcing
studies should explicitly consider this.
Measurement Results: The analysis of the movement patterns showed that
users moved even during crowded times. The Bluetooth beacon based location
service allowed us to trace users who did not provide GPS locations. We showed
that there is signiﬁcant performance degradation during the festival regarding
DNS and HTTP failures as well as increased load times. The performance degra-
dation diﬀers between network operators, network types, and locations. Carriers
with a low failure rate during the event had a higher average load time. We
currently investigate the underlying causes for these diﬀerences.
Future Work: The large data set allows to retrieve detailed movement models
for large scale events, analysis of dependencies between the signal strength and
the user density, and the evaluation of new technologies to deal with crowded
events. By making the data available to the community, we hope to encourage
others to conduct similar analysis.
Acknowledgements. This work has been funded by the German Research Founda-
tion (DFG) as part of projects A2, B2, B1 within the Collaborative Research Center
(CRC) 1053 – MAKI.
References
1. Cisco visual networking index: global mobile data traﬃc forecast update 2014–
2019 white paper (2015). http://www.cisco.com/c/en/us/solutions/collateral/
service-provider/visual-networking-index-vni/white paper c11-520862.html
2. Brownlee, N.: On searching for patterns in traceroute responses. In: Faloutsos,
M., Kuzmanovic, A. (eds.) PAM 2014. LNCS, vol. 8362, pp. 67–76. Springer,
Heidelberg (2014)
3. Erman, J., Ramakrishnan, K.K.: Understanding the super-sized traﬃc of the
super bowl. In: Proceedings of the 2013 Conference on Internet Measurement
Conference, pp. 353–360. ACM (2013)
82
A. Fr¨ommgen et al.
4. Luckie, M., et al.: A second look at detecting third-party addresses in traceroute
traces with the IP timestamp option. In: Faloutsos, M., Kuzmanovic, A. (eds.)
PAM 2014. LNCS, vol. 8362, pp. 46–55. Springer, Heidelberg (2014)
5. Nikravesh, A., Choﬀnes, D.R., Katz-Bassett, E., Mao, Z.M., Welsh, M.: Mobile
network performance from user devices: a longitudinal, multidimensional analysis.
In: Faloutsos, M., Kuzmanovic, A. (eds.) PAM 2014. LNCS, vol. 8362, pp. 12–22.
Springer, Heidelberg (2014)
6. Shaﬁq, M.Z., Ji, L., Liu, A.X., Pang, J., Venkataraman, S., Wang, J.: A ﬁrst look
at cellular network performance during crowded events. In: ACM SIGMETRICS
Performance Evaluation Review, vol. 41, pp. 17–28. ACM (2013)
7. Sommers, J., Barford, P.: Cell vs. Wiﬁ: on the performance of metro area mobile
connections. In: Proceedings of the 2012 ACM Conference on Internet Measure-
ment Conference, IMC 2012, pp. 301–314. ACM, New York (2012)
8. Xu, Y., Wang, Z., Leong, W.K., Leong, B.: An end-to-end measurement study
of modern cellular data networks. In: Faloutsos, M., Kuzmanovic, A. (eds.) PAM
2014. LNCS, vol. 8362, pp. 34–45. Springer, Heidelberg (2014)