Prprq „ exp
qpd, rq
2
If f is a k-sensitive function in d for any ﬁxed r P R, then
the exponential mechanism is pk, 0q-diﬀerentially private.
3.3 f-divergences
As we have seen, diﬀerential privacy is closely related to
function sensitivity. To verify diﬀerential privacy for the
result of probabilistic inferences, we will need to work with
several notions of distance between distributions. These
distances can be neatly described as f -divergences [13], a
rich class of metrics on probability distributions. Inspired by
the deﬁnition of relative entropy, f -divergences are deﬁned
by a convex function f . Formally:
Deﬁnition 3.6 (Csisz´ar and Shields [14]). Let fpxq be a
convex function deﬁned for x ą 0, with fp1q “ 0. Let µ1, µ2
ÿ
distributions over A. Then, the f -divergence of µ1 from µ2,
denoted ∆fpµ1 | µ2q is deﬁned as:
´
¯
∆fpµ1 | µ2q “
µ2paqf
aPA
µ1paq
µ2paq
f -diverg.
SDpxq
HDpxq
KLpxq
-Dpxq
1
fpxq
2 |x ´ 1|
2 p?
x ´ 1q2
x lnpxq ´ x ` 1
maxpx ´ e, 0q
1
Simpliﬁed form
¯
a
|µ1paq ´ µ2paq|
¯
µ2paq
µ1paq
µ2paq
´a
1
2
´
µ1paq ´
1
2
´
¯
µ1paq ln
µ1paq ´ eµ2paq, 0
max
2
aPA
aPA
ÿ
ÿ
ÿ
ÿ
aPA
aPA
Table 1: f -divergences for statistical distance (SD), Hellinger
distance (HD), KL divergence (KL), and -distance (-D)
´
¯
where we assume 0 ¨ fp 0
“ lim
tÑ0
0 ¨ f
a
0
´
¯
0q “ 0 and
t ¨ f
a
t
“ a lim
uÑ8
fpuq
u
´
¯
.
If ∆fpµ1 | µ2q ď δ we say that µ1 and µ2 are pf, δq-close.
Examples of f -divergences include KL-divergence, Hellinger
distance, and total variation distance. Moreover, Barthe and
Olmedo [2] showed how the -distance of Lemma 3.1 can
be seen as an f -divergence for diﬀerential privacy. These
f -divergences are summarized in Table 1. Notice that some
of the f -divergences in the table above are not symmetric. In
particular, this is the case for KL-divergence and -distance,
which we use to describe p, δq-diﬀerential privacy. We will
denote by F the class of functions meeting the requirements
of Deﬁnition 3.6.
Not only do f -divergences measure useful statistical quan-
tities, they also enjoy several properties that are useful for
formal veriﬁcation. (e.g. see [14]). A property that is worth
mentioning and that will be used implicitly in our example
is the following.
Theorem 3.1 (Data processing inequality). Let f P F,
µ1, µ2 be two distributions over A, and M be a function
(potentially randomized) mapping values in A to distributions
over B. Then, we have:
∆fpbind µ1 M, bind µ2 Mq ď ∆fpµ1, µ2q
Another important property for our framework is compo-
sition. As shown by Barthe and Olmedo [2] we can compose
f -divergences in an additive way. More speciﬁcally, they give
the following deﬁnition.
Deﬁnition 3.7 (Barthe and Olmedo [2]). Let f1, f2, f3 P F.
We say that pf1, f2q are f3 composable if and only if for every
A, B, two distributions µ1, µ2 over A, and two functions
M1, M2 mapping values in A to distributions over B we have
∆f3pbind µ1 M1, bind µ2 M2q ď
∆f1pµ1, µ2q ` sup
∆f2pM1 v, M2 vq
v
In particular, we have the following.
Lemma 3.4 (Barthe and Olmedo [2]).
‚ p1-D, 2-Dq are p1 ` 2q-DP composable.
‚ pSD, SDq are SD composable.
‚ pHD, HDq are HD composable.
‚ pKL, KLq are KL composable.
This form of composition will be internalized by the rela-
tional reﬁnement type system that we will present in § 5.
uniform : Drr0, 1ss
bernoulli : r0, 1s Ñ DrBs
beta : R` ˆ R` Ñ Drr0, 1ss
normal : R ˆ R` Ñ DrRs
lapMech : R` ˆ R Ñ MrRs
gaussMech : R` ˆ R Ñ MrRs
expMech : R ˆ ppD, Rq Ñ Rq ˆ D Ñ MrRs
Figure 2: Primitive distributions types.
4. PrivInfer
The main components of PrivInfer are a language that
permits to express Bayesian inference models and a type
system for reasoning in a relational way about programs
from the language.
4.1 The language
e
The language underlying PrivInfer is a probabilistic pro-
gramming extension of PCF that we will call PCFp. Ex-
pressions of PCFp are deﬁned by the following grammar
::“ x | c | e e | λx. e
|
|
|
|
|
letrec f x “ e | case e with rdi xi ñ eisi
return e | mlet x “ e in e
observe x ñ e in e | inferpeq | ranpeq
bernoullipeq | normalpe, eq | betape, eq | uniformpq
lapMechpe, eq | gaussMechpe, eq | expMechpe, e, eq
where c represents a constant from a set C and x a variable.
We will denote by PCFp (X ) the set of expression of PrivInfer
where the variables are taken from the set X .
simple types of the form
We will consider only expressions that are well typed using
τ, σ ::“ rτ | Mrrτs | MrDrrτss | Drrτs | τ Ñ σ
rτ
` | r0, 1s |rτ list.
where rτ are basic types. As usual a typing judgment is a
::“ ‚ | B | N | R | R` | R
judgment of the shape Γ $ e : τ where an environment Γ
is an assignment of types to variables. The simply typed
system of PrivInfer is an extension of the one in Barthe et al.
[6]; in Figure 1 we only present the rules speciﬁc to PrivInfer.
The syntax and types of PCFp extend the one of PCF by
means of several constructors. Basic types include the unit
type ‚ and types for booleans B and natural numbers N. We
also have types for real numbers R, positive real numbers R`,
positive real number plus inﬁnity R
and for real numbers in
the unit interval r0, 1s. Finally we have lists over basic types.
Simple types combines basic types using arrow types, a prob-
ability monad Mrrτs over the basic type rτ , and a type Drrτs
representing symbolic distributions over the basic typerτ . The
probabilistic monad Mrrτs that can be manipulated by the let-
probability monad can also be over symbolic distributions.
Probabilities (actual distributions) are encapsulated in the
binder mlet x “ e1 in e2 and by the unit return e. Symbolic
distributions are built using basic probabilistic primitives
like bernoullipeq for Bernoulli distributions, normalpe1, e2q for
normal distribution, etc. These primitives are assigned types
as described in Figure 2. For symbolic distributions we
also assume that we have an operation getParams to extract
the parameters. We also have primitives lapMechpe1, e2q,
gaussMechpe1, e2q and expMechpe1, e2, e3q that provide im-
plementations for the mechanism ensuring diﬀerential privacy
as described in § 3.2.
`
Γ $ e1 : MrT1s
Γ, x : T1 $ e2 : MrT2s
BindM
Γ $ mlet x “ e1 in e2 : MrT2s
Γ $ e1 : Mrrτs
Γ, x :rτ $ e2 : MrBs
Γ $ observe x ñ e2 in e1 : Mrrτs
UnitM
Γ $ e : Drrτs
Γ $ ranpeq : Mrrτs
Observe
Ran
Infer
Γ $ e : T
Γ $ return e : MrTs
Γ $ e : Mrrτs
Γ $ inferpeq : Drrτs
Figure 1: PCFp type system (selected rules)
Finally, we have three special constructs for representing
learning. The primitive observe x ñ e1 in e2 can be used to
describe conditional distributions. This is a functional version
of a similar primitive used in languages like Fun [24]. This
primitive takes two arguments, a prior e2 and a predicate e1
over x. The intended semantics is the one provided by Bayes’
theorem:
it ﬁlters the prior by means of the observation
provided by e1 and renormalize the obtained distribution
(see Section § 4.2 for more details). The primitives inferpeq
and ranpeq are used to transform symbolic distributions in
actual distributions and vice versa. In particular, inferpeq is
the main component performing probabilistic inference.
4.2 Denotational Semantics
set of discrete probabilities over τ , i.e.:
The semantics of PCFp is largely standard. Basic types
are interpreted in the corresponding sets, e.g. (cid:74)‚(cid:75) “ t‚u,
(cid:74)B(cid:75) “ ttrue, falseu,(cid:74)N(cid:75) “ t0, 1, 2, . . .u, etc. As usual, arrow
types(cid:74)τ Ñ σ(cid:75) are interpreted as set of functions(cid:74)τ(cid:75) Ñ(cid:74)σ(cid:75).
A monadic type Mrτs for τ P trτ , Drrτsu is interpreted as the
ÿ
(
(cid:74)Mrτs(cid:75) “
µ :(cid:74)τ(cid:75) Ñ R` | supppµq discrete^
xP(cid:74)τ(cid:75) µ x “ 1
Types of the shape Drrτs are interpreted in set of symbolic
(
bernoullipvq | v P r0, 1s
representations for distributions parametrized by values. As
an example, DrBs is interpreted as:
(cid:32)
(cid:32)
(cid:74)DrBs(cid:75) “
The interpretation of expressions is given as usual under a
validation θ which is a ﬁnite map from variables to values
in the interpretation of types. We will say that θ validates
of the expressions the interpretation is standard, we detail
the less standard interpretations in Figure 3. Probabilistic
expressions are interpreted into discrete probabilities. In
an environment Γ if @x : τ P Γ we have θpxq P(cid:74)τ(cid:75). For most
particular,(cid:74)return e(cid:75)θ is deﬁned as the Dirac distribution
returning(cid:74)e(cid:75)θ with probability one. The binding construct
mlet x “ e1 in e2 composes probabilities. The expression
observe x ñ t in u ﬁlters the distribution(cid:74)u(cid:75)θ using the pred-
icate x ñ t and rescales it in order to obtain a distribution.
The observe is the key component to have conditional distri-
butions and to update a prior using Bayes’ theorem. The
semantics of infer relies on a given algorithm3 AlgInf for in-
ference. We leave the algorithm unspeciﬁed because it is not
central to our veriﬁcation task. Symbolic distributions are
3In this work we consider only exact inference, and we leave
for future works to consider approximate inference. We also