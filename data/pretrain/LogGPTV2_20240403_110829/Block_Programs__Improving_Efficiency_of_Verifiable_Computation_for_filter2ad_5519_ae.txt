M : the number of input (or output) of one loop iteration
C: size of the circuit of the loop body
Figure 6: Comparison of Cost for Veri(cid:12)er in Each Instance
(Non-
(Amor-
V’s Cost
amortized)
V’s Cost
tized )
Task Computing
P:
Construct
proof
P: Issue responses
Zaatar
1:10h
Pinocchio
9:9ms
Our Algma
1281s + 7:70s
96:76h
164:3h
0:29s + 696:67s
160s
111:34h
160s
445:56h
160s
38:6ms + 381s
124:38h
N/A
158:8s + 895:5s
Map: 0:9ms
Div: 3(cid:22)s , 220-bit
Rand: 260ns, 220-bit
Oper:130(cid:22)s, 220-bit
(cid:26): 8
Dec: 170(cid:22)s , 220 bits
Exp: 118:3(cid:22)s, ﬁxed base,
optimized for twist curve
Mult: 320ns, 220-bit
Muex: 401:0(cid:22)s, 254-bit,
optimized for twist curve
(cid:26)lin: 20
Enc: 88(cid:22)s , 220 bits
aNote: we list the cost for both the ﬁrst layer and the
second layer in our design, connected by “+”.
Figure 7: An Loop Example and Its Cost
number of executions be K = 500. Let the width of the
inputs/outputs be M = 1000, the width of the extra inputs
for each execution Q = M 2, and the circuit size of the loop
body C = M 2. It is easy to see the polynomial that the cir-
cuit of each loop body computes is quadratic, thus D = 2.
We use published models ([24, 23]) and instantiate the costs
as in Figure 7. All the costs of basic operations are bor-
rowed from Zaatar [24] and Pinocchio [23]. We can see that,
for the amortized cost and the prover’s cost, our protocol is
far superior to the other two. This also implies that in our
protocol smaller breakeven batching size suﬃces to guaran-
tee that the average cost for veriﬁcation per instance is less
than re-computing.
6.3 Further Discussion
If we examine our protocol carefully, a natural question
will arise: why cannot the block be of size K0 · C such
that K0 ̸= 1? Moreover, if we group K0 successive loop
iterations into large blocks (K0 < K), then we can fur-
ther group several sequential big blocks into a bigger block.
The whole circuit can be viewed as a multiple-layer struc-
ture. More speciﬁcally, we can view the whole circuit as
one big block, which we call the ﬁrst layer block and de-
note by a function  (1) : FM +K·Q 7→ FM .
In the second
layer’s perspective, the circuit consists of K0 smaller blocks,
which we call the second layer block and denote by a func-
tion  (2) : FM +K·Q=K0 7→ FM , and so forth. In each layer,
several blocks constitute the circuit. The block in the l-th
) 7→ FM .
layer is denoted by a function  (l) : FM +K·Q=(Kl−1
The l-th layer block is composed of K0 lower layer blocks,
i.e. the l + 1 layer blocks. At the L-th layer, the last layer,
each of the blocks is equivalent to one loop iteration. Note
that the reduction of our veriﬁcation can go further recur-
sively in this multiple-layer view. According to our current
protocol, the correctness of computing  (1) is reduced to the
correctness of computing  (2). Similarly, the correctness of
computing  (2) is reduced to the correctness of computing
 (3). We can keep doing this until we meet the last layer.
0
At a ﬁrst glance, this recursive protocol seems promis-
ing. However, it is the ﬁrst layer that dominates the cost.
This implies that this method introduces high cost due to
the recursion. More speciﬁcally, if we have multiple-layer
blocks, then from  (1)(·) =  (2)( (2)(··· ( (2)(·))··· )), we
see the degree of the polynomial a block computes increases
exponentially. Simple analysis will show that the cost of the
ﬁrst layer dominates and therefore the cost for this recursive
method is proportional to O(DK ), which is much more than
our current protocol. Recall in our current protocol, the
block is one loop iteration. Thus, the degree of the poly-
nomial this block computes is D. This is also the reason
why sequential circuits – where the output of each gate is
an input to the next gate – is the worst-case scenario for
our protocol. Such circuits are better tackled with Zaatar,
Pinocchio, etc.
7. RELATED WORK
Extensive research has been motivated by the problem
of verifying computation, striving for verifying the result of
general computation. Verifying the result of general compu-
tation can be viewed as originating from similar but more
413abstract problems in the theory of computation, such as in-
teractive proof (IP) systems [18] and probabilistically check-
able proof (PCP) systems [1, 2]. Until recently, the security
community has been extending and reﬁning classical proof
systems, attempting to make theoretical cryptographic pro-
tocols practical.
Extending provides basic theoretical models and mean-
ingful tools for applications. Existing veriﬁable computation
schemes fall into three broad categories. The ﬁrst line of ver-
iﬁable computation systems [25, 26, 24, 31] is based on the
IKO argument system which is ﬁrst proposed by Ishai et al.
[19]. In these systems, the proof for the result correctness is
formulated into a linear PCP with a commitment which is
constructed in the pre-processing phase. This line of work
made PCP-based approaches more practical– very eﬃcient
if batching over a large number of computation instances,
while requiring only standard cryptographic assumptions.
Parno et al. start another line of work [24, 23, 7] which
is based on the recent ﬁnding of a new characterization of
the NP complexity class –QSPs/QAPs [16], such as Pinoc-
chio, which supports public veriﬁability and zero-knowledge.
Similarly, by compiling programs to an innovative circuit
representation [6], Ben-Sasson et al. provides another pub-
licly veriﬁable and zero-knowledge scheme BCGTV [7, 8].
Our work inherits the property of the linear-PCP style de-
signs and does not provide zero-knowledge, either. The only
work built on linear-PCP (like Pepper/Ginger/Zaatar) that
is known to support zero-knowledge proof is XAG [31].
Motivated by the delegation of computation (GKR [17]),
IP systems provides the third line of work to assure the
client that an untrusted prover has actually performed the
correct computation (CRR [12], CMT [14]). In this line of
work, Thaler also ﬁnds that circuits that satisfy a speciﬁc
condition can have much lower cost on the pre-processing
stage [28]. However, their circuits need to satisfy either a
so-called “regular” wiring pattern condition or the “data-
parallel” structure requirement (namely, a sub-computation
is applied independently to diﬀerent pieces of data). Besides,
Thaler’s work still has veriﬁer’s cost linear in the size of the
circuit. All GKR-style systems typically require far more
interaction, introducing much more bandwidth costs.
As an interesting hybrid-architecture protocol, Allspice
[29] integrates both Zaatar and CMT in such a way that
it automatically determines which one would be more eﬃ-
cient to verify the computation and runs the better of the
two. Another study [5] has been pursuing argument systems
that avoid a pre-processing phase for the veriﬁer. Those ar-
gument systems are based on short PCPs, and existing work
on this topic is still only theoretical.
Since state-of-the-art veriﬁcation protocols are based on
arithmetic circuit, the compiler which transforms the out-
source task (typically a program written in high level lan-
guages such as C) into a circuit representation plays a very
important role in this area. Zaatar’s and Pinocchio’s com-
pilers map a large class of computations into corresponding
arithmetic circuits, using special-purpose encodings. An-
other line of compilers, TinyRAM [7] and vnTinyRAM [8],
use an innovative technique [6] and compiles universally pro-
grams in C with the same number of executions to one same
circuit. This compiler has better performance for programs
consisting of lots of memory accesss and control ﬂow than
Zaatar’s and Pinocchio’s, while the compilers of Zaatar and
Pinocchio do better in programs which are close to “circuit”
forms [8]. Walﬁsh et al. evaluate these compilers in [30] and
claim TinyRAM’s circuit representation is orders of magni-
tude larger than the representation in Pinocchio and Zaatar.
8. CONCLUSIONS
This paper addresses two fundamental problems in the
veriﬁable computation (we focus on the veriﬁcation protocol
part which is right after circuit generation): 1) whether and
what computations can have lower amortized cost and proof
generation cost; 2) how to handle loops concisely after circuit
generation.
We give a ﬁrst-step answer by showing that for computa-
tion with loops, we can use Block Programs, our new theo-
retical result, to reduce the veriﬁer’s amortized cost to the
sum of two parts, one of which is merely veriﬁcation of one
loop iteration (which does not scale with the number of loop
repetitions) and the other is linear in the degree of the cir-
cuit of the loop body and the number of loop iterations.
From the theory of arithmetic circuit complexity, the degree
of most circuits will be far less than their size. Hence the
veriﬁer’s amortized costs in our design is far less than the
counterpart of existing algorithms, which are linear in the
size of the whole circuit. We also improve the prover’s cost
of proof generation from quasilinear in the size of the circuit
of the loop body to quasilinear in the degree of the circuit
of the loop body, attached with a cost of generating a proof
for one loop iteration, achieving great savings similarly.
For applications that require a large number of loop ex-
ecutions (which is common in not only compute-intensive
computations but also data-intensive computations such as
big data applications), and have loop bodies the degree of
which is far less than their size (from the theory of arithmetic
circuit complexity, this is nature: the degree of most circuits
will be far less than their size), our approach is expected to
perform better than existing veriﬁable computation proto-
cols. However, for “deep” loop bodies, in which the output of
each gate is an input to the next gate, standard algorithms
like Zaatar and Pinocchio would probably do better.
9. ACKNOWLEDGMENTS
We appreciate anonymous reviewers for valuable sugges-
tions and comments. This material is based upon work sup-
ported in part by the National Science Foundation under
Grant No. 1320351.
10. REFERENCES
[1] S. Arora and S. Safra. Probabilistic checking of proofs; a new
characterization of np. In Proceedings of the 33rd Annual
Symposium on Foundations of Computer Science, SFCS ’92,
pages 2–13, Washington, DC, USA, 1992.
[2] L. Babai, L. Fortnow, L. A. Levin, and M. Szegedy. Checking
computations in polylogarithmic time. In Proceedings of the
twenty-third annual ACM symposium on Theory of
computing, STOC ’91, pages 21–32, New York, NY, USA, 1991.
[3] M. Bellare, S. Goldwasser, C. Lund, and A. Russell. Eﬃcient
probabilistically checkable proofs and applications to
approximations. In Proceedings of the Twenty-(cid:12)fth Annual
ACM Symposium on Theory of Computing, STOC ’93, pages
294–304, New York, NY, USA, 1993. ACM.
[4] M. Bellare, M. Kiwi, and M. Sudan. Linearity testing in
characteristic two. IEEE Transactions on Information
Theory, 1996.
[5] E. Ben-Sasson, A. Chiesa, D. Genkin, and E. Tromer. On the
concrete-eﬃciency threshold of probabilistically-checkable
proofs. Electronic Colloquium on Computational Complexity
(ECCC), 19:45, 2012.
414[6] E. Ben-Sasson, A. Chiesa, D. Genkin, and E. Tromer. Fast
[27] A. Shpilka and A. Yehudayoﬀ. Arithmetic circuits: A survey of
reductions from rams to delegatable succinct constraint
satisfaction problems: extended abstract. In ITCS, pages
401–414, 2013.
[7] E. Ben-Sasson, A. Chiesa, D. Genkin, E. Tromer, and M. Virza.
SNARKs for C: Verifying program executions succinctly and in
zero knowledge. In Proceedings of the 33rd Annual
International Cryptology Conference, CRYPTO ’13, pages
90–108, 2013.
[8] E. Ben-Sasson, A. Chiesa, E. Tromer, and M. Virza. Succinct
non-interactive zero knowledge for a von neumann architecture.
In Proceedings of the 23rd USENIX Security Symposium, San
Diego, CA, USA, August 20-22, 2014., pages 781–796, 2014.
[9] N. Bitansky, A. Chiesa, Y. Ishai, O. Paneth, and R. Ostrovsky.
Succinct non-interactive arguments via linear interactive
proofs. In Proceedings of the 10th Theory of Cryptography
Conference on Theory of Cryptography, TCC’13, pages
315–333, Berlin, Heidelberg, 2013. Springer-Verlag.
[10] G. Brassard, D. Chaum, and C. Cr´epeau. Minimum disclosure
proofs of knowledge. J. Comput. Syst. Sci., 37(2):156–189,
1988.
[11] B. Braun, A. J. Feldman, Z. A. Ren, S. Setty, A. J. Blumberg,
and M. Walﬁsh. Verifying computations with state. In SOSP,
2013.
[12] R. Canetti, B. Riva, and G. N. Rothblum. Two 1-round
protocols for delegation of computation. Cryptology ePrint
Archive, Report 2011/518, 2011. http://eprint.iacr.org/.
[13] X. Chen, N. Kayal, and A. Wigderson. Partial Derivatives in
Arithmetic Complexity and Beyond (Foundations and
Trends(R) in Theoretical Computer Science). Now Publishers
Inc., Hanover, MA, USA, 2011.
[14] G. Cormode, M. Mitzenmacher, and J. Thaler. Practical
veriﬁed computation with streaming interactive proofs. In
Proceedings of the 3rd Innovations in Theoretical Computer
Science Conference, ITCS ’12, pages 90–112, New York, NY,
USA, 2012. ACM.
[15] R. Gennaro, C. Gentry, and B. Parno. Non-interactive
veriﬁable computing: outsourcing computation to untrusted
workers. In Proceedings of the 30th annual conference on
Advances in cryptology, CRYPTO’10, pages 465–482, Berlin,
Heidelberg, 2010. Springer-Verlag.
[16] R. Gennaro, C. Gentry, B. Parno, and M. Raykova. Quadratic
span programs and succinct nizks without pcps. In Proceedings
of the IACR Eurocrypt Conference, Eurocrypt 13, 2013.
[17] S. Goldwasser, Y. T. Kalai, and G. N. Rothblum. Delegating
computation: interactive proofs for muggles. In Proceedings of
the 40th annual ACM symposium on Theory of computing,
STOC ’08, pages 113–122, New York, NY, USA, 2008. ACM.
[18] S. Goldwasser, S. Micali, and C. Rackoﬀ. The knowledge
complexity of interactive proof systems. SIAM J. Comput.,
18(1):186–208, Feb. 1989.
[19] Y. Ishai, E. Kushilevitz, and R. Ostrovsky. Eﬃcient arguments
without short pcps. In Proceedings of the Twenty-Second
Annual IEEE Conference on Computational Complexity,
CCC ’07, pages 278–291, Washington, DC, USA, 2007.
[20] M. Karchmer and A. Wigderson. On span programs. In In
Proc. of the 8th IEEE Structure in Complexity Theory, pages
102–111. IEEE Computer Society Press, 1993.
[21] J. Kilian. A note on eﬃcient zero-knowledge proofs and
arguments (extended abstract). In Proceedings of the
twenty-fourth annual ACM symposium on Theory of
computing, STOC ’92, pages 723–732, New York, NY, USA.
[22] J. Kilian. Improved eﬃcient arguments (preliminary version).
In Proceedings of the 15th Annual International Cryptology
Conference on Advances in Cryptology, CRYPTO ’95, pages
311–324, London, UK, UK, 1995. Springer-Verlag.
[23] B. Parno, C. Gentry, J. Howell, and M. Raykova. Pinocchio:
nearly practical veriﬁable computation. In the IEEE
Symposium on Security and Privacy, IEEE S&P 13, 2013.
[24] S. Setty, B. Braun, V. Vu, A. J. Blumberg, B. Parno, and
M. Walﬁsh. Resolving the conﬂict between generality and
plausibility in veriﬁed computation. EuroSys ’13, 2013.
[25] S. Setty, R. McPherson, A. J. Blumberg, and M. Walﬁsh.
Making argument systems for outsourced computation practical
(sometimes). In NDSS, 2012.
[26] S. Setty, V. Vu, N. Panpalia, B. Braun, A. J. Blumberg, and
M. Walﬁsh. Taking proof-based veriﬁed computation a few
steps closer to practicality. In USENIX Security, 2012.
recent results and open questions. Found. Trends Theor.
Comput. Sci., 5:207–388, Mar. 2010.
[28] J. Thaler. Time-optimal interactive proofs for circuit
evaluation. In CRYPTO (2), pages 71–89, 2013.
[29] V. Vu, S. Setty, A. J. Blumberg, and M. Walﬁsh. A hybrid
architecture for interactive veriﬁable computation. In the IEEE
Symposium on Security and Privacy, IEEE S&P 13, 2013.
[30] M. Walﬁsh and A. J. Blumberg. Verifying computations
without reexecuting them: from theoretical possibility to
near-practicality. Electronic Colloquium on Computational
Complexity (ECCC), 20:165, 2013.
[31] G. Xu, G. Amariucai, and Y. Guan. Delegation of computation
with veriﬁcation outsourcing: Curious veriﬁers. In Proceedings