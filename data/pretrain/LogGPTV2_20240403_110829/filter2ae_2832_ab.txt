    #程序的入口main ，作用：防止在被其他文件导入时显示多余的程序主体部分。
    if __name__ == '__main__':
        #测试数据
        encrypt_decrypt('字符串')
第二个脚本：python2
    import base64
    s = "加密后的字符串"
    a = 0
    try:
     while True:
      s = base64.decodestring(s)
      a += 1
    except Exception:
     print s
     print a
## **4.MD5加密**
url：
使用md5在线解密
bighp
## **5.种族歧视**
url：
第一种方法：burp抓包
发现语言，因为这个网站只能让外国人进，所以把语言换成en-US
放包，得到`key is: *(TU687jksf6&*`
第二种方法：使用Python3脚本
    import urllib,urllib.request
    headers = {
            "Accept-Language": "en-US,en;q=0.9",
            'User-Agent': "HAHA"
        }
    def getpage(path):  # 抓取网页源代码
        # data = urllib.request.urlopen(path).read().decode("gbk", "ignore")  # 中文网页
        # return data
        request = urllib.request.Request(url=path, headers=headers)  # 冒充其他浏览器
        response = urllib.request.urlopen(request)  # 会话，打开网页
        data = response.read().decode("utf-8", "ignore")  # 读取网页并且编码
        return data
    print(getpage('http://lab1.xseclab.com/base1_0ef337f3afbe42d5619d7a36c19c20ab/index.php'))# 网址自行更换
## **6.HAHA浏览器**
url：
第一种方法：burp抓包
发现有浏览器信息，那我们把浏览器改成HAHA
放包，得到key is: meiyouHAHAliulanqi
第二种方法：使用Python3脚本
    import urllib,urllib.request
    headers = {
            "Accept-Language": "en-US,en;q=0.9",
            'User-Agent': "HAHA"
        }
    def getpage(path):  # 抓取网页源代码
        # data = urllib.request.urlopen(path).read().decode("gbk", "ignore")  # 中文网页
        # return data
        request = urllib.request.Request(url=path, headers=headers)  # 冒充其他浏览器
        response = urllib.request.urlopen(request)  # 会话，打开网页
        data = response.read().decode("utf-8", "ignore")  # 读取网页并且编码
        return data
    print(getpage('http://lab1.xseclab.com/base6_6082c908819e105c378eb93b6631c4d3/index.php'))# 网址自行更换
## **7.key究竟在哪里呢？**
第一种方法：右键审查元素，得到Key: kjh%#$#%FDjjj
第二种方法：burp抓包，发送到重放模块，点击go，得到Key: kjh%#$#%FDjjj
## **8.key又找不到了**
url：
点击到这里找key，抓包重放，得到./key_is_here _now_.php
访问
得到key: ohHTTP302dd
## **9.冒充登陆用户**
url：
第一种方法：burp抓包，cookie里的login参数改为1
得到key is: yescookieedit7823789KJ
第二种方法：使用python3脚本
    import urllib,urllib.request
    headers = {
            "Accept-Language": "en-US,en;q=0.9",
            'Cookie': "Login=1"
        }
    def getpage(path):  # 抓取网页源代码
        # data = urllib.request.urlopen(path).read().decode("gbk", "ignore")  # 中文网页
        # return data
        request = urllib.request.Request(url=path, headers=headers)  # 冒充其他浏览器
        response = urllib.request.urlopen(request)  # 会话，打开网页
        data = response.read().decode("utf-8", "ignore")  # 读取网页并且编码
        return data
    print(getpage('http://lab1.xseclab.com/base9_ab629d778e3a29540dfd60f2e548a5eb/index.php'))# 网址自行更换
## **10.比较数字大小**
url：
第一种方法，右键审查元素，前端验证，发现在框里最大长度是3，如图修改
输入9999，得到key is 768HKyu678567&*&K
第二种方法，burp抓包，直接输9999即可
## **11.本地的诱惑**
url：
第一种方法：审查元素，得到key is ^&*(UIHKJjkadshf
第二种方法，必须本地访问，burp抓包，在 Request 中加入请求头 X-Forwarded-For: 127.0.0.1 ，得到key is
^&*(UIHKJjkadshf
注：X-Forwarded-For:简称XFF头，它代表客户端，也就是HTTP的请求端真实的IP，只有在通过了HTTP
代理或者负载均衡服务器时才会添加该项。它不是RFC中定义的标准请求头信息，在squid缓存代理服务器开发文档中可以找到该项的详细介绍。标准格式如下：X-Forwarded-For: client1, proxy1, proxy2。
## **12.就不让你访问**
url：
查看robots.txt,
注：disallow 一般是用在robots.txt中的。表示禁止搜索引擎抓取。
Disallow，正是robots.txt文件中设置禁止搜索引擎收录哪些目录的一个词语。
访问
访问
得到right! key is UIJ%%IOOqweqwsdf
文笔生疏，措辞浅薄，望各位大佬不吝赐教，万分感谢。
免责声明：由于传播或利用此文所提供的信息、技术或方法而造成的任何直接或间接的后果及损失，均由使用者本人负责， 文章作者不为此承担任何责任。
转载声明：儒道易行
拥有对此文章的修改和解释权，如欲转载或传播此文章，必须保证此文章的完整性，包括版权声明等全部内容。未经作者允许，不得任意修改或者增减此文章的内容，不得以任何方式将其用于商业目的。