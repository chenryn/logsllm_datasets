Storage overhead. In order to understand the storage
overhead, we mirrored the existing agent integrations Python
package repository. Then, we inspected the package payloads
and the repository metadata to show the cost breakdown of
the repository as a whole. Table 2 depicts the cost breakdown
of the Datadog repository, as mirrored on February 8 of 2019.
Type
RSA 4096
DSA 1024 &
ed25519
optimized
total
Python
package metadata
0.83%
74.02%
74.48%
0.84%
TUF
5.51%
5.54%
in-toto
links
16.75%
16.35%
in-toto
Layout
2.89%
2.79%
79.56%
0.90%
5.92%
10.65%
2.97%
Table 2: Storage overhead breakdown for a in-toto enabled package
repository. All metadata is compressed using zlib.
Table 2 shows that in-toto takes up about 19% of the
total repository size, and thus makes it a feasible solution
in terms of storage overhead. In addition, compared to its
co-located security system TUF, the cost of using in-toto
is higher, with almost four times the metadata storage cost.
Further, the breakdown also indicates that the governing
factor for this storage overhead are the in-toto links, rather
than the layout ﬁle, with a layout being approximately 6 to
3 times smaller than the links (42 KB in comparison of the
148KB for all the link metadata).
There are two main reasons that drive this cost. First and
foremost, is the engineering decision to track all the ﬁles
within the pipeline (including Python metadata). Although
these are not required to be tracked with in-toto, for the
sake of security (as this type of metadata is being protected
by TUF), it eases the implementation at a manageable cost.
The second is that of signatures: the signatures used within
the Datadog deployment come from either 4096-bit openpgp
keys on a Yubikey, or 4096-bit PEM keys. These alone
account for almost half of the in-toto metadata size.
For this reason, it is possible to further reduce the size of
the metadata to 13% of the total repository size. Rows two
and three of Table 2 represent the repository overhead when
limiting the amount of ﬁles tracked to only Python sources
and packages and using a DSA1024 as the signing algorithm.
Network overhead. Similar to storage overhead, the network
overhead incurred by clients when installing any integration
is of utmost importance. To explore this cost, we investigate
the raw package sizes and contrast it with the size of the
package-speciﬁc metadata size. It is of note though, that
the size of in-toto metadata does not scale with the size
of the package, but rather the number of ﬁles inside of it.
This is because most of the metadata cost is taken by pieces
of link metadata, of which the biggest three ﬁelds are the
signature, expected_materials and expected_products.
Figure 5 shows both the distribution of package sizes and the
distribution of metadata sizes in increasing order.
Figure 5: Package and metadata size distribution. Error bars show packages
with the same number of ﬁles but different sizes.
In Figure 5 we can see that, for most packages, the
metadata size cost is below 44% of the package size. In fact
for the 90th percentile, the metadata cost approaches a costly
64%, to a worst case of 103%. However, upon inspecting
these cases, we found that the issue is that these are cases
in which link metadata is tracking ﬁles not contained in the
delivered product. Indeed, in-toto is tracking ﬁles, such as
test suites, ﬁxtures and even iconography that does not get
packaged on the integrations Python wheel. The worst case
scenario is in fact cisco_aci, which only packages 12 ﬁles
out of 316 contained in the tag step metadata.
1404    28th USENIX Security Symposium
USENIX Association
Veriﬁcation overhead. Finally, to draw insight from the
computation time required to verify each package, we ran
a series of micro-benchmarks on a laptop with an Intel
i7-6500U processor and 8GB of RAM. In this case, we ran an
iterated veriﬁcation routine with the packages already fetched
and instrumented the Datadog agent installer to measure the
installation time with and without in-toto veriﬁcation.
From this experiment, we conclude that in-toto veriﬁ-
cation adds less than 0.6 seconds on all cases. This is mostly
dominated by the signature veriﬁcation, and is thus bounded
by the number of links to verify (i.e., the number of steps
times the threshold).
7.2 Supply chain data breaches
We surveyed 30 major different supply chain breaches and
incidents occurring from January 2010 to January 2019 (this
list of historical attacks is included in Appendix B). These
historical incidents cover a variety of software products and
platforms, such as Apple’s Xcode [113], Android GTK [8],
MeDoc ﬁnancial software [35], Adobe updater [95], PHP
PEAR repository [33], and South Korean organizations [138].
Studying these historical attacks identiﬁed the type of
access that the attacker had (or was speculated to have)
and identiﬁed three categories:
the attacker had control
of infrastructure (but not functionary keys), the attacker
had control over part of the infrastructure or keys of a
speciﬁc functionary, and the attacker was able to control
the entire supply chain by compromising a project owner’s
infrastructure (including their signing key).
For the historical attacks in Appendix B, we determined
whether an attack used a compromised key, and then labeled
those attacks with “Key Compromise”. We also determined
the degree of access in the attack (all the way to the possible
step) and labeled each attack with an “Access Level” that
indicates the step in the chain where the attack took place.
We now analyze how these compromises could affect
the three supply chains where in-toto was deployed (as
described in Section 6). Our analysis indicates that the
majority of attacks (23 out of 30) took place without any
key compromise. In those cases, none of the three in-toto
deployments would have been affected since the client
inspection (as described in Sec. 4.3) could detect extraneous
artifacts or malicious delivered products.
Out of the 30 studied incidents, 7 involved a key compro-
mise. We summarize our analysis of these attacks in Table 3.
One attack, Keydnap [71], used a stolen Apple developer
certiﬁcate to sign the malicious software package. Therefore,
this attack would not have affected any in-toto deploy-
ments, because in-toto would detect that an unauthorized
functionary signed the link metadata. Another attack used the
developer’s ssh key to upload a malicious Python package
on PyPI [52]. All in-toto deployments could have detected
this attack since ﬁles extracted from the malicious package
would not exactly match the source code as the products of
the ﬁrst step in the supply chain.
The remaining ﬁve attacks involving a key compromise
were recent sophisticated incidents that affected many clients
Attack Name
Keydnap [71]
backdoored-pypi [52]
CCleaner Atatck [126]
RedHat breach [125]
*NotPetya [35]
Operation Red [138]
KingSlayer [118]
DD
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
RB
(cid:88)
(cid:88)
(cid:88)
(cid:88)



CN
(cid:88)
(cid:88)





Table 3: The impact of the historical attacks on the three in-toto
deployments: Datadog (DD), Reproducible Builds (RB), Cloud Native (CN).
Out of the 30 historical attacks, 23 did not involve a key compromise, so none
of the deployments would have been affected. This table shows the remaining
attacks which involved a key compromise. In one attack, marked with a star
(*), it is unknown if a key compromise took place. We assumed that was the
case. A (cid:88)indicates that the deployment could have detected the attack.
and companies. The CCleaner [126] and RedHat [125]
attacks are not effective against the Reproducible Builds
deployment (RB) and Datadog (DD), as the former imple-
ments a threshold mechanism in the build step and the latter
does not build binaries in their infrastructure. In a similar
ﬂavor, three attacks (Operation Red [138], NotPetya [35], and
KingSlayer [118]) would not affect the Datadog deployment,
as it implements a threshold mechanism in the packaging
step. The Cloud Native deployment, on the other hand,
would detect none of these ﬁve attacks, as it does not employ
thresholds. To conclude, the in-toto deployments would
detect most of the historical attacks based on the general
in-toto design principles. For those attacks that involve
key compromises, our analysis shows that in-toto’s use of
thresholds is an effective mechanism.
Key Takeaway. Cloud Native (83%) and reproducible
builds (90%) integrations of in-toto would prevent most
historical supply chain attacks. However, integration into a se-
cure update system as was done by Datadog (100%) provides
further protection.
8 Related Work
To the best of our knowledge, work that attempts to use an
automated tool to secure the supply chain is scarce. However,
there has been a general push to increase the security of
different aspects within the supply chain, as well as to tighten
the binding between neighboring processes within that chain.
In this section, we mention work relevant to supply chain
security, as some of it is crucial for the success of in-toto
as a framework. We also list work that can further increase
the security guarantees offered by in-toto.
Automated supply chain administration systems. Conﬁg-
uring and automating processes of the supply chain has been
widely studied. Works by Bégin et al. [45], Banzai et al., [43]
and Andreetto et al. [36] focus on designing supply chains
that automatically assign resources and designate parties
to take part in different processes to create a product. This
work is similar to in-toto in that it requires a supply chain
topology to carry out the work. However, none of these
projects were focused on security. Instead, they deal with
adaptability of resources and supply chain automation.
USENIX Association
28th USENIX Security Symposium    1405
Perhaps most closely related to in-toto is the Grafeas
API [9] released by Google. However, Grafeas’s focus is
on tracking and storing supply chain metadata rather than
security. Grafeas provides a centralized store for supply chain
metadata, which can be later queried by veriﬁcation tools such
as Google’s Binary Authorization [84]. Grafeas does not pro-
vide a mechanism to describe what steps should be performed,
validate performed steps, or even support cryptographic sig-
natures [1]. Finally, in-toto is architecture agnostic, while
Grafeas is mostly cloud-native; in-toto was geared to repre-
sent supply chains whether they are cloud-native, off-cloud or
hybrid-cloud. We are collaborating with the Grafeas team to
natively support in-toto link metadata within Grafeas [10].
Software supply chain security. In addition, many soft-
ware engineering practices have been introduced to
increase the security of the software development lifecycle
[42, 104, 105, 111, 116]. Additional work by Devanbu et
al. [67] has explored different techniques to “construct safe
software that inspires trust in hosts.” These techniques are
similar to in-toto in that they suggest releasing supply
chain information to the end users for veriﬁcation.
Though none of these proposals suggest an automated tool
to ensure the integrity of the supply chain, they do serve as
a helpful ﬁrst step in designing in-toto. As such, their prac-
tices could be used as templates for safe supply chain layouts.
Finally, there have been hints by the industry to support
features that could be provided by in-toto [90, 114, 145].
This includes providing certiﬁcates noting the presence of a
process within the supply chain and providing software trans-
parency through mechanisms such as reproducible builds.
Source control security. The source code repository is
usually the ﬁrst link in the supply chain. Early work in
this ﬁeld has explored the different security properties that
must be included in software conﬁguration management
tools [63]. Version control systems, such as Git, incorporate
protection mechanisms to ensure the integrity of the source
code repository, which include commit hash chaining and
signed commits [77, 78].
Buildsystem and veriﬁcation security. The ﬁeld of auto-
mated testing and continuous integration has also received
attention from researchers. Recently, self-hosted and public
automated testing and continuous integration systems have
become popular [54, 72, 137]. Work by Gruhn et al. [85] has
explored the security implications of malicious code running
on CI systems, showing that it is possible for attackers to
affect other projects being tested in the same server, or the
server itself. This work, and others [69] serve as a motivation
for in-toto’s threat model.
Further work by Hanawa et al. [87] explores different
techniques for automated testing in distributed systems. The
work is similar to in-toto in that it allocates hosts in the
cloud to automatically run tests for different environments
and platforms. However, in-toto requires such systems to
provide certiﬁcation (in the form of link metadata) that the
tests were run and the system was successful.
Subverting the development environment, including
subverting the compiler, can have a serious impact on the
software supply chain [135]. Techniques such as Wheeler’s
diverse double-compiling (DDC) [144] can be used to
mitigate such “trusting trust” attacks. In the context of
reproducible builds project, DDC can also be used for
multi-party veriﬁcation of compiler executables.
Verifying compilers, applications and kernels. Ongoing
work on verifying compilers, applications and kernels will
provide a robust framework for applications that fully comply
with their speciﬁcation [88, 98]. Such work is similar to
in-toto in that a speciﬁcation is provided for the compiler to
ensure that their products meet stated requirements. However,
in contrast to our work, most of this work is not intended
to secure the origin of such speciﬁcation, or to provide any
proof of the compilation’s results to steps further down the
supply chain. Needless to say, verifying compilers could be
part of a supply chain protected with in-toto.
Furthermore, work by Necula et al.
introduces proof-
carrying code [109,110], a concept that relies on the compiler
to accompany machine code with proof for veriﬁcation at
runtime. Adding to this, industry standards have included
machine code signing [40] to be veriﬁed at runtime. This
work is similar to in-toto in that compilers generate
information that will be veriﬁed by the end user upon runtime.
Although these techniques are more granular than in-toto’s
(runtime veriﬁcation vs veriﬁcation upon installation), they
do not aim to secure the totality of the supply chain.
Package management and software distribution security.
Work by Cappos et al. has been foundational to the design
of in-toto’s security mechanisms [46, 102, 121]. The
mechanisms used to secure package managers are similar to
in-toto in that they rely on key distribution and role sepa-
ration to provide security guarantees that degrade with partial
key compromise. However, unlike in-toto, these systems
are restricted to software updates, which limit their scope.
Concepts from this line of work could be overlaid on in-toto
to provide additional “last mile” guarantees for the resulting
product, such as package freshness or protection against de-
pendencies that are not packaged with the delivered product.
9 Conclusions and future work
In this paper, we have described many aspects of in-toto,
including its security properties, workﬂow and metadata.
We also explored and described several extensions and
implications of using in-toto in a number of real-world
applications. With this we have shown that protecting the
entirety of the supply chain is possible, and that it can be
done automatically by in-toto. Further, we showed that,
in a number of practical applications, in-toto is a practical
solution to many contemporary supply chain compromises.
Although plenty of work needs to be done in the context
of the in-toto framework (e.g., decreasing its storage cost),
tackling the ﬁrst major limitations of supply chain security
will increase the quality of software products. We expect
that, through continued interaction with the industry and
1406    28th USENIX Security Symposium
USENIX Association
elaborating on the framework, we can provide strong security
guarantees for future software users.
Acknowledgments
We would like to thank the USENIX reviewers and Luke
Valenta for reviewing this paper. We would also like to thank
Lukas Pühringer and Lois DeLong from the in-toto team;
Holger Levsen, Chris Lamb, kpcyrd, and Morten Linderud
from Reproducible Builds; the Datadog Agent Integrations
(especially Ofek Lev) and Product Security teams; as well
as Andrew Martin and Luke Bond from Control Plane for
their valuable work towards integrating in-toto in all these
communities. This research was supported by the NSF under