### Strategies and Deceptive Content Narratives in Phishing Attacks

While some attackers engage in targeted attacks, the majority employ non-personalized phishing strategies that can be readily applied across different organizations. Despite the apparent lack of sophistication in tailoring and targeting these attacks, 31% of the lateral phishers in our dataset exhibited sophisticated behavior aimed at increasing their success rate or masking their presence from the hijacked account's true owner. Additionally, over 80% of the attacks occurred during typical working hours, relative to the legitimate account’s historical emailing behavior. This suggests that the attackers either reside in a similar time zone as the accounts they hijack or make a concerted effort to operate during their victims' normal working hours.

Ultimately, our research provides the first large-scale insights into an emerging and widespread form of enterprise phishing attacks, and highlights techniques and future ideas for defending against this potent threat.

### Acknowledgements

We thank Itay Bleier, the anonymous reviewers, and our shepherd Gianluca Stringhini for their valuable feedback. This work was supported in part by the Hewlett Foundation through the Center for Long-Term Cybersecurity, NSF grants CNS-1237265 and CNS-1705050, an NSF GRFP Fellowship, the Irwin Mark and Joan Klein Jacobs Chair in Information and Computer Science (UCSD), generous gifts from Google and Facebook, a Facebook Fellowship, and operational support from the UCSD Center for Networked Systems.

### References

1. Saeed Abu-Nimeh, Dario Nappa, Xinlei Wang, and Suku Nair. A Comparison of Machine Learning Techniques for Phishing Detection. In Proc. of 2nd ACM eCrime, 2007.
2. Kevin Allix, Tegawendé F Bissyandé, Jacques Klein, and Yves Le Traon. Are Your Training Datasets Yet Relevant? In Proc. of 7th Springer ESSoS, 2015.
3. Andre Bergholz, Jeong Ho Chang, Gerhard Paaß, Frank Reichartz, and Siehyun Strobel. Improved Phishing Detection using Model-Based Features. In Proc. of 5th CEAS, 2008.
4. James Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization. JMLR, 13(Feb), 2012.
5. Steven Bird, Edward Loper, and Ewan Klein. Natural Language Toolkit. https://www.nltk.org/, 2019.
6. Elie Bursztein, Borbala Benko, Daniel Margolis, Tadek Pietraszek, Andy Archer, Allan Aquino, Andreas Pitsillidis, and Stefan Savage. Handcrafted Fraud and Extortion: Manual Account Hijacking in the Wild. In Proc. of 14th ACM IMC, 2014.
7. Asaf Cidon. Threat Spotlight: Office 365 Account Takeover — the New “Insider Threat”. https://blog.barracuda.com/2017/08/30/threat-spotlight-office-365-account-compromise-the-new-insider-threat/, Aug 2017.
8. Asaf Cidon, Lior Gavish, Itay Bleier, Nadia Korshun, Marco Schweighauser, and Alexey Tsitkin. High Precision Detection of Business Email Compromise. In Proc. of 28th Usenix Security, 2019.
9. DomainKeys Identified Mail. https://en.wikipedia.org/wiki/DomainKeys_Identified_Mail. Accessed: 2018-11-01.
10. Sevtap Duman, Kubra Kalkan-Cakmakci, Manuel Egele, William Robertson, and Engin Kirda. EmailProfiler: Spearphishing Filtering with Header and Stylometric Features of Emails. In Proc. of 40th IEEE COMPSAC, 2016.
11. Manuel Egele, Gianluca Stringhini, Christopher Kruegel, and Giovanni Vigna. COMPA: Detecting Compromised Accounts on Social Networks. In Proc. of 20th ISOC NDSS, 2013.
12. FBI. BUSINESS E-MAIL COMPROMISE THE 12 BILLION DOLLAR SCAM, Jul 2018. https://www.ic3.gov/media/2018/180712.aspx.
13. Ian Fette, Norman Sadeh, and Anthony Tomasic. Learning to Detect Phishing Emails. In Proc. of 16th ACM WWW, 2007.
14. Sujata Garera, Niels Provos, Monica Chew, and Aviel D Rubin. A Framework for Detection and Measurement of Phishing Attacks. In Proc. of 5th ACM WORM, 2007.
15. Hugo Gascon, Steffen Ullrich, Benjamin Stritter, and Konrad Rieck. Reading Between the Lines: Content-Agnostic Detection of Spear-Phishing Emails. In Proc. of 21st Springer RAID, 2018.
16. Google. Classification: ROC and AUC. https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc, 2019.
17. Grant Ho, Asaf Cidon, Lior Gavish, Marco Schweighauser, Vern Paxson, Stefan Savage, Geoffrey M. Voelker, and David Wagner. Detecting and Characterizing Lateral Phishing at Scale (Extended Report). In arxiv, 2019.
18. Grant Ho, Aashish Sharma, Mobin Javed, Vern Paxson, and David Wagner. Detecting Credential Spearphishing Attacks in Enterprise Settings. In Proc. of 26th USENIX Security, 2017.
19. Xuan Hu, Banghuai Li, Yang Zhang, Changling Zhou, and Hao Ma. Detecting Compromised Email Accounts from the Perspective of Graph Topology. In Proc. of 11th ACM CFI, 2016.
20. Dan Hubbard. Cisco Umbrella 1 Million. https://umbrella.cisco.com/blog/2016/12/14/cisco-umbrella-1-million/, Dec 2016.
21. Chris Kanich, Christian Kreibich, Kirill Levchenko, Brandon Enright, Geoffrey M Voelker, Vern Paxson, and Stefan Savage. Spamalytics: An Empirical Analysis of Spam Marketing Conversion. In Proc. of 15th ACM CCS, 2008.
22. Thomas Karagiannis and Milan Vojnovic. Email information flow in large-scale enterprises. Technical report, Microsoft Research, 2008.
23. Mahmoud Khonji, Youssef Iraqi, and Andrew Jones. Mitigation of spear phishing attacks: A content-based authorship identification framework. In Proc. of 6th IEEE ICITST, 2011.
24. FT Labs. A sobering day. https://labs.ft.com/2013/05/a-sobering-day/?mhq5j=e6, May 2013.
25. Stevens Le Blond, Cédric Gilbert, Utkarsh Upadhyay, Manuel Gomez Rodriguez, and David Choffnes. A Broad View of the Ecosystem of Socially Engineered Exploit Documents. In Proc. of 24th ISOC NDSS, 2017.
26. Stevens Le Blond, Adina Uritesc, Cédric Gilbert, Zheng Leong Chua, Prateek Saxena, and Engin Kirda. A Look at Targeted Attacks Through the Lens of an NGO. In Proc. of 23rd USENIX Security, 2014.
27. Mailgun Team. Talon. https://github.com/mailgun/talon, 2018.
28. William R Marczak, John Scott-Railton, Morgan Marquis-Boire, and Vern Paxson. When Governments Hack Opponents: A Look at Actors and Technology. In Proc. of 23rd USENIX Security, 2014.
29. Microsoft Graph: message resource type. https://developer.microsoft.com/en-us/graph/docs/api-reference/v1.0/resources/message. Accessed: 2018-11-01.
30. Microsoft. People overview - Outlook Web App. https://support.office.com/en-us/article/people-overview-outlook-web-app-5fe173cf-e620-4f62-9bf6-da5041f651bf. Accessed: 2018-11-01.
31. Brad Miller, Alex Kantchelian, Michael Carl Tschantz, Sadia Afroz, Rekha Bachwani, Riyaz Faizullabhoy, Ling Huang, Vaishaal Shankar, Tony Wu, George Yiu, et al. Reviewer Integration and Performance Measurement for Malware Detection. In Proc. of 13th Springer DIMVA, 2016.
32. Jeremiah Onaolapo, Enrico Mariconti, and Gianluca Stringhini. What Happens After You Are Pwnd: Understanding the Use of Leaked Webmail Credentials in the Wild. In Proc. of 16th ACM IMC, 2016.
33. J. Palme. Common Internet Message Headers. https://tools.ietf.org/html/rfc2076.
34. Feargus Pendlebury, Fabio Pierazzi, Roberto Jordaney, Johannes Kinder, and Lorenzo Cavallaro. Tesseract: Eliminating experimental bias in malware classification across space and time. In Proc. of 28th Usenix Security, 2019.
35. Kevin Poulsen. Google disrupts Chinese spear-phishing attack on senior U.S. officials. https://www.wired.com/2011/06/gmail-hack/, Jul 2011.
36. Steve Ragan. Office 365 phishing attacks create a sustained insider nightmare for IT. https://www.csoonline.com/article/3225469/office-365-phishing-attacks-create-a-sustained-insider-nightmare-for-it.html, Sep 2017.
37. Fahmida Y. Rashid. Don’t like Mondays? Neither do attackers. https://www.csoonline.com/article/3199997/don-t-like-mondays-neither-do-attackers.html, Aug 2017.
38. Retraining models on new data. https://docs.aws.amazon.com/machine-learning/latest/dg/retraining-models-on-new-data.html, 2019.
39. Jeff John Roberts. Homeland Security Chief Cites Phishing as Top Hacking Threat. http://fortune.com/2016/11/20/jeh-johnson-phishing/, Nov 2016.
40. Apache Spark. PySpark DecisionTreeClassificationModel v2.1.0. http://spark.apache.org/docs/2.1.0/api/python/pyspark.ml.html?highlight=featureimportance#pyspark.ml.classification.DecisionTreeClassificationModel.featureImportances.
41. Gianluca Stringhini and Olivier Thonnard. That Ain’t You: Blocking Spearphishing Through Behavioral Modeling. In Proc. of 12th Springer DIMVA, 2015.
42. Kurt Thomas, Frank Li, Chris Grier, and Vern Paxson. Consequences of Connectivity: Characterizing Account Hijacking on Twitter. In Proc. of 21st ACM CCS, 2014.
43. Lisa Vaas. How hackers broke into John Podesta, DNC Gmail accounts. https://nakedsecurity.sophos.com/2016/10/25/how-hackers-broke-into-john-podesta-dnc-gmail-accounts/, Oct 2016.
44. Colin Whittaker, Brian Ryner, and Marria Nazif. Large-Scale Automatic Classification of Phishing Pages. In Proc. of 17th ISOC NDSS, 2010.
45. Wikipedia. Random forest. https://en.wikipedia.org/wiki/Random_forest, 2019.
46. Kim Zetter. Researchers uncover RSA phishing attack, hiding in plain sight. https://www.wired.com/2011/08/how-rsa-got-hacked/, Aug 2011.
47. Mengchen Zhao, Bo An, and Christopher Kiekintveld. Optimizing Personalized Email Filtering Thresholds to Mitigate Sequential Spear Phishing Attacks. In Proc. of 13th AAAI, 2016.

### A. Detector Implementation and Evaluation Details

#### A.1 Labeling Phishing Emails

When manually labeling an email as phishing or benign, we examined five key pieces of information:
1. Whether the email was reported as a phishing incident.
2. The message content.
3. Any suspicious URLs flagged and whether their domains made sense in context.
4. The email’s recipients.
5. The sender's identity.

In most cases, these steps were sufficient to identify a phishing email. For example, an email about a "shared Office 365 document" sent to hundreds of unrelated recipients with a bit.ly shortened [non-Microsoft] domain, or an email describing an "account security problem" sent by a non-IT employee with an "account reset" URL pointing to an unrelated domain, would be labeled as phishing.

For more challenging cases, we analyzed all replies and forwards in the email chain. If the email received multiple replies or forwards expressing alarm or suspicion, or if the hijacked account eventually sent a reply denying the phishing email, it was labeled as phishing. Additionally, we visited the non-side-effect, suspicious URLs from a sample of the labeled phishing emails. All URLs led to either an interstitial warning page (e.g., Google SafeBrowsing) or a spoofed log-on page.

False positives were conservatively labeled as such. For instance, if the "suspicious URL" flagged by our detector occurred in the sender’s signature and linked to their personal website, the email was labeled as a false positive.

#### A.2 Model Tuning and Hyperparameters

Most machine learning models, including Random Forest, require setting various hyperparameters that govern the model’s training process. To determine the optimal set of hyperparameters for our classifier, we conducted a three-fold cross-validation grid search over all combinations of the following hyperparameters:

1. Number of trees: 50–500, in steps of 50 (i.e., 50, 100, 150, ..., 450, 500).
2. Maximum tree depth: 10–100, in steps of 10.
3. Minimum leaf size: 1, 2, 4, 8.
4. Downsampling ratio of (benign / attack) emails: 10, 50, 100, 200.

Given that our training dataset contained only a few dozen incidents, we used three folds to ensure that each fold in the cross-validation contained several attack instances. Our experiments used a Random Forest model with 64 trees, a maximum depth of 8, a minimum leaf size of 4 elements, and a downsampling of 200 benign emails per 1 attack email, as this configuration produced the highest AUC score. However, many hyperparameter combinations yielded similar results.