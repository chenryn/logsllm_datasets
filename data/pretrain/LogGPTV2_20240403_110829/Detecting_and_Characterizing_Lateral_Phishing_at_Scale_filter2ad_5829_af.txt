strategies and deceptive content narratives; while some at-
tackers engage in targeted attacks, most follow strategies that
employ non-personalized phishing attacks that can be readily
used across different organizations. Despite this apparent lack
of sophistication in tailoring and targeting their attacks, 31%
of our dataset’s lateral phishers engaged in some form of so-
phisticated behavior designed to increase their success rate or
mask their presence from the hijacked account’s true owner.
Additionally, over 80% of attacks occurred during a typical
working day and hour, relative to the legitimate account’s
historical emailing behavior; this suggests that these attackers
either reside within a similar timezone as the accounts they
hijack or make a concerted effort to operate during their vic-
tim’s normal hours. Ultimately, our work provides the ﬁrst
large-scale insights into an emerging, widespread form of
enterprise phishing attacks, and illuminates techniques and
future ideas for defending against this potent threat.
Acknowledgements
We thank Itay Bleier, the anonymous reviewers, and our shep-
herd Gianluca Stringhini for their valuable feedback. This
work was supported in part by the Hewlett Foundation through
the Center for Long-Term Cybersecurity, NSF grants CNS-
1237265 and CNS-1705050, an NSF GRFP Fellowship, the
Irwin Mark and Joan Klein Jacobs Chair in Information and
Computer Science (UCSD), by generous gifts from Google
and Facebook, a Facebook Fellowship, and operational sup-
port from the UCSD Center for Networked Systems.
References
[1] Saeed Abu-Nimeh, Dario Nappa, Xinlei Wang, and Suku
Nair. A Comparison of Machine Learning Techniques
for Phishing Detection. In Proc. of 2nd ACM eCrime,
2007.
USENIX Association
28th USENIX Security Symposium    1287
[2] Kevin Allix, Tegawendé F Bissyandé, Jacques Klein,
and Yves Le Traon. Are Your Training Datasets Yet
Relevant? In Proc. of 7th Springer ESSoS, 2015.
[3] Andre Bergholz, Jeong Ho Chang, Gerhard Paaß, Frank
Reichartz, and Siehyun Strobel.
Improved Phishing
Detection using Model-Based Features. In Proc. of 5th
CEAS, 2008.
[4] James Bergstra and Yoshua Bengio. Random search for
hyper-parameter optimization. JMLR, 13(Feb), 2012.
[5] Steven Bird, Edward Loper, and Ewan Klein. Natural
Language Toolkit. https://www.nltk.org/, 2019.
[6] Elie Bursztein, Borbala Benko, Daniel Margolis, Tadek
Pietraszek, Andy Archer, Allan Aquino, Andreas Pitsil-
lidis, and Stefan Savage. Handcrafted Fraud and Extor-
tion: Manual Account Hijacking in the Wild. In Proc.
of 14th ACM IMC, 2014.
[7] Asaf Cidon. Threat Spotlight: Ofﬁce 365 Account
https:
Takeover — the New “Insider Threat”.
//blog.barracuda.com/2017/08/30/threat-
spotlight-office-365-account-compromise-
the-new-insider-threat/, Aug 2017.
[8] Asaf Cidon, Lior Gavish, Itay Bleier, Nadia Korshun,
Marco Schweighauser, and Alexey Tsitkin. High Preci-
sion Detection of Business Email Compromise. In Proc.
of 28th Usenix Security, 2019.
[9] DomainKeys
Identiﬁed Mail.
https://en.
wikipedia.org/wiki/DomainKeys_Identified_
Mail. Accessed: 2018-11-01.
[10] Sevtap Duman, Kubra Kalkan-Cakmakci, Manuel Egele,
William Robertson, and Engin Kirda. EmailProﬁler:
Spearphishing Filtering with Header and Stylometric
Features of Emails. In Proc. of 40th IEEE COMPSAC,
2016.
[11] Manuel Egele, Gianluca Stringhini, Christopher Kruegel,
and Giovanni Vigna. COMPA: Detecting Compromised
Accounts on Social Networks. In Proc. of 20th ISOC
NDSS, 2013.
[12] FBI. BUSINESS E-MAIL COMPROMISE THE 12
BILLION DOLLAR SCAM, Jul 2018. https://www.
ic3.gov/media/2018/180712.aspx.
[13] Ian Fette, Norman Sadeh, and Anthony Tomasic. Learn-
ing to Detect Phishing Emails. In Proc. of 16th ACM
WWW, 2007.
[14] Sujata Garera, Niels Provos, Monica Chew, and Aviel D
Rubin. A Framework for Detection and Measurement
of Phishing Attacks. In Proc. of 5th ACM WORM, 2007.
[15] Hugo Gascon, Steffen Ullrich, Benjamin Stritter, and
Konrad Rieck. Reading Between the Lines: Content-
Agnostic Detection of Spear-Phishing Emails. In Proc.
of 21st Springer RAID, 2018.
[16] Google.
Classiﬁcation:
ROC and AUC.
https://developers.google.com/machine-
learning/crash-course/classification/roc-
and-auc, 2019.
[17] Grant Ho, Asaf Cidon, Lior Gavish, Marco
Schweighauser, Vern Paxson, Stefan Savage, Ge-
offrey M. Voelker, and David Wagner. Detecting and
Characterizing Lateral Phishing at Scale (Extended
Report). In arxiv, 2019.
[18] Grant Ho, Aashish Sharma, Mobin Javed, Vern Paxson,
and David Wagner. Detecting Credential Spearphishing
Attacks in Enterprise Settings. In Proc. of 26th USENIX
Security, 2017.
[19] Xuan Hu, Banghuai Li, Yang Zhang, Changling Zhou,
and Hao Ma. Detecting Compromised Email Accounts
from the Perspective of Graph Topology. In Proc. of
11th ACM CFI, 2016.
[20] Dan Hubbard. Cisco Umbrella 1 Million. https:
//umbrella.cisco.com/blog/2016/12/14/cisco-
umbrella-1-million/, Dec 2016.
[21] Chris Kanich, Christian Kreibich, Kirill Levchenko,
Brandon Enright, Geoffrey M Voelker, Vern Paxson,
and Stefan Savage. Spamalytics: An Empirical Analysis
of Spam Marketing Conversion. In Proc. of 15th ACM
CCS, 2008.
[22] Thomas Karagiannis and Milan Vojnovic. Email infor-
mation ﬂow in large-scale enterprises. Technical report,
Microsoft Research, 2008.
[23] Mahmoud Khonji, Youssef Iraqi, and Andrew Jones.
Mitigation of spear phishing attacks: A content-based
In Proc. of 6th
authorship identiﬁcation framework.
IEEE ICITST, 2011.
[24] FT Labs. A sobering day. https://labs.ft.com/
2013/05/a-sobering-day/?mhq5j=e6, May 2013.
[25] Stevens Le Blond, Cédric Gilbert, Utkarsh Upadhyay,
Manuel Gomez Rodriguez, and David Choffnes. A
Broad View of the Ecosystem of Socially Engineered
Exploit Documents. In Proc. of 24th ISOC NDSS, 2017.
[26] Stevens Le Blond, Adina Uritesc, Cédric Gilbert,
Zheng Leong Chua, Prateek Saxena, and Engin Kirda.
A Look at Targeted Attacks Through the Lense of an
NGO. In Proc. of 23rd USENIX Security, 2014.
1288    28th USENIX Security Symposium
USENIX Association
[27] Mailgun Team.
Talon.
mailgun/talon, 2018.
https://github.com/
[28] William R Marczak, John Scott-Railton, Morgan
Marquis-Boire, and Vern Paxson. When Governments
Hack Opponents: A Look at Actors and Technology. In
Proc. of 23rd USENIX Security, 2014.
[29] Microsoft Graph: message resource type.
https:
//developer.microsoft.com/en-us/graph/
docs/api-reference/v1.0/resources/message.
Accessed: 2018-11-01.
[30] Microsoft.
People overview - Outlook Web
https://support.office.com/en-
App.
us/article/people-overview-outlook-web-
app-5fe173cf-e620-4f62-9bf6-da5041f651bf.
Accessed: 2018-11-01.
[31] Brad Miller, Alex Kantchelian, Michael Carl Tschantz,
Sadia Afroz, Rekha Bachwani, Riyaz Faizullabhoy, Ling
Huang, Vaishaal Shankar, Tony Wu, George Yiu, et al.
Reviewer Integration and Performance Measurement for
Malware Detection. In Proc. of 13th Springer DIMVA,
2016.
[32] Jeremiah Onaolapo, Enrico Mariconti, and Gianluca
Stringhini. What Happens After You Are Pwnd: Under-
standing the Use of Leaked Webmail Credentials in the
Wild. In Proc. of 16th ACM IMC, 2016.
[33] J. Palme. Common Internet Message Headers. https:
//tools.ietf.org/html/rfc2076.
[34] Feargus Pendlebury, Fabio Pierazzi, Roberto Jordaney,
Johannes Kinder, and Lorenzo Cavallaro. Tesseract:
Eliminating experimental bias in malware classiﬁcation
across space and time. In Proc. of 28th Usenix Security,
2019.
[35] Kevin Poulsen. Google disrupts chinese spear-phishing
attack on senior u.s. ofﬁcials. https://www.wired.
com/2011/06/gmail-hack/, Jul 2011.
[36] Steve Ragan.
Ofﬁce 365 phishing attacks cre-
ate a sustained insider nightmare for it.
https:
//www.csoonline.com/article/3225469/office-
365-phishing-attacks-create-a-sustained-
insider-nightmare-for-it.html, Sep 2017.
[37] Fahmida Y. Rashid. Don’t like Mondays? Neither do
attackers. https://www.csoonline.com/article/
3199997/don-t-like-mondays-neither-do-
attackers.html, Aug 2017.
[38] Retraining models on new data.
https://docs.
aws.amazon.com/machine-learning/latest/dg/
retraining-models-on-new-data.html, 2019.
[39] Jeff John Roberts. Homeland Security Chief Cites Phish-
ing as Top Hacking Threat. http://fortune.com/
2016/11/20/jeh-johnson-phishing/, Nov 2016.
[40] Apache Spark.
PySpark DecisionTreeClassiﬁ-
http://spark.apache.
cationModel v2.1.0.
org/docs/2.1.0/api/python/pyspark.
ml.html?highlight=featureimportance#
pyspark.ml.classification.
DecisionTreeClassificationModel.
featureImportances.
[41] Gianluca Stringhini and Olivier Thonnard. That Ain’t
You: Blocking Spearphishing Through Behavioral Mod-
elling. In Proc. of 12th Springer DIMVA, 2015.
[42] Kurt Thomas, Frank Li, Chris Grier, and Vern Paxson.
Consequences of Connectivity: Characterizing Account
Hijacking on Twitter. In Proc. of 21st ACM CCS, 2014.
[43] Lisa Vaas. How hackers broke into John Podesta, DNC
Gmail accounts. https://nakedsecurity.sophos.
com/2016/10/25/how-hackers-broke-into-john-
podesta-dnc-gmail-accounts/, Oct 2016.
[44] Colin Whittaker, Brian Ryner, and Marria Nazif. Large-
Scale Automatic Classiﬁcation of Phishing Pages. In
Proc. of 17th ISOC NDSS, 2010.
[45] Wikipedia. Random forest. https://en.wikipedia.
org/wiki/Random_forest, 2019.
[46] Kim Zetter. Researchers uncover rsa phishing attack,
hiding in plain sight. https://www.wired.com/2011/
08/how-rsa-got-hacked/, Aug 2011.
[47] Mengchen Zhao, Bo An, and Christopher Kiekintveld.
Optimizing Personalized Email Filtering Thresholds to
Mitigate Sequential Spear Phishing Attacks. In Proc. of
13th AAAI, 2016.
A Detector Implementation and Evaluation
Details
A.1 Labeling Phishing Emails
Labeling an email as phishing or benign: When manually
labeling an email, we started by examining ﬁve pieces of in-
formation whether the email was a reported phishing incident,
the message content, the suspicious URL ﬂagged and if its
domain made sense in context, the email’s recipients, and
the sender. With the exception of a few incidents, we could
easily identify a phishing email from the above steps. For
example: an email about a “shared Ofﬁce 365 document” sent
to hundreds of unrelated recipients and whose document link
pointed to a bit.ly shortened [non-Microsoft] domain; or an
USENIX Association
28th USENIX Security Symposium    1289
A.2 Model Tuning and Hyperparameters
Most machine learning models, including Random Forest, re-
quire the user to set various (hyper)parameters that govern the
model’s training process. To determine the optimal set of hy-
perparameters for our classiﬁer, we followed machine learning
best practices by conducting a three-fold cross-validation grid
search over all combinations of the hyperparameters listed
below [4].
1. Number of trees: 50–500, in steps of 50 (i.e., 50, 100,
150, . . . , 450, 500)
2. Maximum tree depth: 10–100, in steps of 10
3. Minimum leaf size: 1, 2, 4, 8
4. Downsampling ratio of (benign / attack) emails: 10, 50,
100, 200
Because our training dataset contained only a few dozen in-
cidents, we used three folds to ensure that each fold in the
cross-validation contained several attack instances. Our ex-
periments used a Random Forest model with 64 trees, a max-
imum depth of 8, a minimum leaf size of 4 elements, and a
downsampling of 200 benign emails per 1 attack email, since
this conﬁguration produced the the highest AUC score [16].
But we note that many of the hyperparameter combinations
yielded similar results.
email describing an “account security problem” sent by a non-
IT employee, where the “account reset” URL pointed to an
unrelated domain. For the more difﬁcult cases, we analyzed
all replies and forwards in the email chain, and labeled the
email as phishing if it either received multiple replies / for-
wards that expressed alarm or suspicious, or if the hijacked
account eventually sent a reply saying that they did not send
the phishing email. Finally, as described in Section 3.3 we
visited the non-side-effect, suspicious URLs from a sample of
the labeled phishing emails; All of the URLs we visited led to
either an interstitial warning page (e.g.,, Google SafeBrows-
ing), or a spoofed log-on page. For the emails ﬂagged by our
detector, but which appeared benign based on examining all
the above information, we conservatively labeled them as
false positives. In many cases, false positives were readily
apparent; e.g., emails where the “suspicious URL” ﬂagged by
our detector occurred in the sender’s signature and linked to
their personal website.
Training exercises vs. actual phishing emails: In addition
to distinguishing between a false positive and an attack, we
checked to ensure that our lateral phishing incidents repre-
sented actual attacks, and not training exercises. First, based
on the lateral phishing emails’ headers, we veriﬁed that all
of the sending accounts were legitimate enterprise accounts.
Second, all but ﬁve of the attack accounts sent one or more
unrelated-to-phishing emails in the preceding month. These
two points gave us conﬁdence that the phishing emails came
from existing, legitimate accounts, and thus represented ac-
tual attacks; i.e., training exercises will not hijack an existing
account, due to the potential reputational harm this could in-
cur (and enterprise security teams we’ve previously engaged
with do not do this). Furthermore, none of our dataset’s lateral
phishing incidents are training exercises known to Barracuda,
and none of the lateral phishing URLs used domains of known
security companies.
1290    28th USENIX Security Symposium
USENIX Association