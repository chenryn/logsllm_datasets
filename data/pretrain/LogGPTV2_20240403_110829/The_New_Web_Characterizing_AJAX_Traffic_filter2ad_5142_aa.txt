# The New Web: Characterizing AJAX Traffic

## Authors
Fabian Schneider, Sachin Agarwal, Tansu Alpcan, and Anja Feldmann  
Deutsche Telekom Laboratories / Technische Universität Berlin  
10587 Berlin, Germany  
{fabian, anja}@net.t-labs.tu-berlin.de, {sachin.agarwal, tansu.alpcan}@telekom.de

## Abstract
The rapid rise of "Web 2.0" applications has introduced new HTTP traffic patterns that diverge from the traditional request-response model. Specifically, asynchronous pre-fetching of data to provide a seamless web browsing experience and the use of richer HTTP payloads (e.g., JavaScript libraries) in Web 2.0 applications result in larger, heavier, and more bursty traffic on underlying networks. This paper presents a traffic study of several Web 2.0 applications, including Google Maps, modern web-email, and social networking sites, and compares their traffic characteristics with conventional HTTP traffic. We highlight the key differences through statistical analysis, providing insights into the evolving nature of one of the most popular internet applications: the World Wide Web.

## 1. Introduction
The World Wide Web [1] is one of the most widely used applications on the Internet, primarily operating over the HTTP protocol. While HTTP (Hypertext Transfer Protocol) [2] serves as the session layer or messaging protocol for the Web, HTML (Hypertext Markup Language) describes the content and allows authors to link web pages through hyperlinks, an idea popularized by Tim Berners-Lee in the early 1990s. In its classical form, users navigate to other pages or access new data by clicking on hyperlinks or submitting web forms, resulting in the download of a new web page in response to each request.

The recent popularity of asynchronous communication-enabled websites has significantly shifted from the traditional HTTP request-response model. This asynchronous communication is commonly facilitated by AJAX (Asynchronous JavaScript and XML) [3], a set of technologies that allow web browsers to request data from servers without requiring human intervention, such as clicking a hyperlink or button. Consequently, HTTP requests are increasingly automated rather than user-generated. In this paper, we use AJAX and "Web 2.0" interchangeably to refer to web applications that employ this new paradigm.

Modern web pages often contain embedded request-response functions, including a JavaScript engine that automatically executes in the background to asynchronously pre-fetch large amounts of data from the server. This intelligent pre-fetching aims to mask the round-trip and transmission latency of Internet connections, providing a smoother web application experience. Figure 1 illustrates the differences between classical and AJAX-enabled web applications. The JavaScript engine builds a local pre-fetched cache based on user interactions with the web application and executes parts of the application logic in the client's browser instead of the web server. Prediction algorithms in automated pre-fetching schemes often result in significantly larger downloads compared to user-initiated browsing due to inaccurate guesses about which data to pre-fetch. Even when predictions are accurate, HTTP traffic inter-request times are no longer bounded by human response times (on the order of seconds) and may depend on the JavaScript code logic on the client machine.

Many popular web applications have adopted Web 2.0 technologies. One of the most prominent and early adopters of AJAX is Google Maps. Its success has encouraged the use of AJAX for building other interactive web applications. For example, many web email services have transitioned to Web 2.0 applications to rival the look and feel of desktop email clients. Additionally, some social networking sites use AJAX to offer rich and interactive user experiences. In this paper, we explore the traffic characteristics of the most popular representatives of these AJAX-based applications in our environment and compare them to overall HTTP traffic.

### 1.1 Related Work
A comprehensive overview of traditional Web protocols is provided in the book by Krishnamurthy and Rexford [1]. Early work on characterizing the effects of HTTP traffic and HTTP pre-fetching was done by Crovella [4], highlighting the benefits and drawbacks of pre-fetching HTTP data. This further underscores the importance of our analysis of Web 2.0 applications and their global impact on the Internet. There is extensive literature on Internet web caching, e.g., [5, 6, 7], but the primary motivation for using caching in these studies has been to reduce the overall download latency of popular websites, not to facilitate low-latency interactive Web 2.0 applications.

There are few studies focusing on the characteristics of AJAX-based traffic, although there are numerous discussions, blogs, and websites about the end-user perceived latency of AJAX-based applications (e.g., [8]). The novel aspect of our work is that we focus on the behavior of two large user populations and investigate multiple AJAX-enabled applications.

### 1.2 Contributions
In this paper, we highlight the changing characteristics of web traffic by comparing the traffic patterns of HTTP and Web 2.0 applications. We rely on several HTTP traces from large user populations in Munich, Germany, and Berkeley, USA, from which we extract popular AJAX application traffic.

Our statistical analysis of Web 2.0 traffic compared to all HTTP traffic extracted from the traces shows that the former's characteristics significantly differ from the latter's. Our work focuses on the number of transferred bytes, the number of HTTP requests issued, and the inter-request times. For example, Web 2.0 traffic has shorter inter-arrival times due to the underlying human-independent automated data pre-fetching schemes.

Our work complements the efforts of the web developer community towards a better understanding of Web 2.0 application characteristics. Some of our results may motivate developers to design web applications that are friendlier to the underlying network, for example, by reducing the number of automated HTTP requests when possible.

The rest of the paper is organized as follows. In Section 2, we provide a brief overview of the applications studied in this work and describe our data collection process. In Section 3, we present the results of our statistical analysis comparing AJAX traffic with HTTP traffic. Finally, we conclude in Section 4.

## 2. Methodology

### 2.1 Data Sets
We use packet-level traces collected from two independent networks: the Münchner Wissenschaftsnetz (MWN) in Germany and the Lawrence Berkeley National Laboratories (LBNL) in the USA. Both environments provide high-speed Internet connections to their users. The MWN provides a 10 Gbps link capacity to approximately 55,000 hosts at two major universities and several research institutes, transferring 3-6 TB per day. LBNL utilizes a 1 Gbps upstream link, transferring about 1.5 TB per day for roughly 13,000 hosts. Our analysis is based on three traces from network port 80 (the HTTP port). Two of these traces, MWN-05 and MWN-07, are from MWN, while one trace, LBNL-07, is from LBNL. Table 1 provides information about the traces, including size, duration, start dates, total number of HTTP requests, and the number of HTTP requests related to Google Maps.

We rely on packet-level traces of large user populations as they provide the most detailed data. From these traces, we reconstruct the HTTP request-response stream using Bro [10], a network intrusion detection system. Bro's policy script `http.bro` along with `http-reply.bro` and `http-header.bro` enables TCP stream re-assembly, basic HTTP analysis, and HTTP request-response analysis. We augmented the `http-header.bro` script to extract the times when HTTP requests were issued. The resulting output file contains one-line summaries of each HTTP request, including (TCP) Connection ID, number of requests in the connection, session ID, transferred bytes, three timestamps (request issued, cookie seen, request finished), requested hostname, prefix of the requested URL, and the HTTP status code for the request. Note that the number of transferred bytes does not include the HTTP header size. We only include requests for which we successfully record start and end times.

To determine the most popular AJAX-enabled Web 2.0 applications, we first identified the 500 most popular web servers in the MWN-07 data set. We then grouped these into multiple categories for better visualization. The first set of categories contained servers hosted by the two universities and other research institutes (MWN). The next categories included all requests related to advertisements (Ad Server) and news websites (News). Manual inspection showed that neither category contained many AJAX-related requests. Some of the services offered by Google, including Google Maps and Google Mail, use AJAX, while others like Google Search, Google Images, and Google Earth do not. Accordingly, we separated them into Google Maps, Google Mail, Google Earth, and all others (Google). Another popular web email service in Germany, GMX, is also AJAX-supported. Some categories include just a single popular site (Site 1, ..., Site 5), while others are well-known websites, e.g., eBay and MSN. Figure 2 shows a pie chart of the number of requests per category for the MWN-07 data set. We find that GMX is the most popular AJAX-based application with 2.27% of the requests, followed by Google Maps, which contributes 2.04%. Another AJAX-enabled social networking site is lokalisten.de with 1.4%. Although Google Mail only accounts for 0.65% of the requests, we include it as our fourth application since this gives us two AJAX-enabled mail applications by different providers. In terms of bytes, the contributions are smaller, e.g., Google Maps with 1.41%. But all of the applications considered in this paper are among the top 500. We refer to these as the "Selected-4" in subsequent discussions.

### 2.2 Google Maps Communication
Google Maps is one of the first web applications to popularize AJAX technology. Consequently, it is widely considered the canonical example of an AJAX application. AJAX uses the Document Object Model (DOM) [9] of the web browser, eliminating the need to reload the entire web page each time it is updated, thus increasing interactivity, speed, and usability.

Google Maps maintains multiple connections to different servers in the Internet that serve as back-ends for the application. All connections use HTTP as the session protocol and take advantage of advanced features of HTTP 1.1 [2], such as persistent HTTP connections for efficiency and pipelining to reduce latency, leading to multiple HTTP requests per TCP connection. In the context of Google Maps, most of these connections are used to fetch image tiles of the map. Other connections are used for control messages and the initial transfer of the AJAX application (JavaScript code), the transfer of GUI-related images, and user queries. The connections carrying tile images can be identified by the servers they connect to.

### 2.3 Application Characterization Methodology
In this section, we discuss how to extract application-specific data from our data sets. For brevity, we focus on Google Maps traffic.

One of the challenges of identifying Google Maps traffic is that Google offers all its services on the same back-end server infrastructure (e.g., Google Maps, Google Search, Google Video, etc.) and uses a uniform key for all services. Therefore, the browser can reuse existing TCP connections to Google servers to issue Google search queries, image or video queries, and Google Maps queries. Separating Google Maps traffic from other Google services requires some effort. Moreover, to capture the user's interaction with Google Maps, we are interested in the full set of HTTP requests within a Google Maps "session," meaning all requests issued when a user connects to maps.google.com and interacts with the application, e.g., by entering a location, moving the map, or switching the zoom level. Accordingly, we group these requests into a Google Maps "session."

To identify Google Maps-related requests among the large number of HTTP requests in our traces, we check if the hostname contains the string `maps.google`. To find the other requests by the same user, we take advantage of Google's own session-keeping mechanisms. Google uses cookies to mark all requests of a session by embedding a unique hash of its session ID. We use this ID as our session ID and gather all other requests of this Google Maps session using the session ID. Unfortunately, there may be additional requests to other Google services among the identified requests. We exclude these if they do not contain a Google Maps-specific URL prefix. We found that `/mt` (map), `/kh` (satellite), `/mld` (route planning), and `/mapstt` (traffic) are related to the kind of map requested. `/maps`, `/mapfiles`, and `/intl` are used for meta information. `/` and `favicon.ico` are not restricted to Google Maps use. A similar methodology is used for the other Selected-4 applications.

For comparison purposes, we also group requests of the complete HTTP traffic (ALL-HTTP), including requests of the Selected-4, into web sessions. In this case, we cannot take advantage of cookies yielding session identifiers. Therefore, we group those requests that come from the same client IP, go to the same server (IP) on the same server port. This aggregates connections from different client-side ports.

For both Selected-4 sessions and ALL-HTTP sessions, we use a timeout of 10 minutes. We compute per-connection and per-session statistics, including the number of transferred HTTP payload bytes, the number of requests, their durations, and inter-request times (IRTs) for the Selected-4 applications and ALL-HTTP traffic.

## 3. Characteristics of AJAX Traffic
In this section, we present the results of a statistical analysis of the characteristics of both ALL-HTTP and Selected-4 traffic. Almost all connections and sessions are usually comprised of multiple requests. However, we find significant differences in session characteristics, including session lifetimes, transferred bytes per session, the number of requests within sessions, and inter-arrival times of HTTP requests within sessions.

Most of the data is presented as probability density functions (PDFs), although complementary cumulative distribution functions (CCDFs) are also shown. To capture the multiple orders of magnitude in the data, we plot all CCDFs on a log-log scale and compute the PDFs of the logarithm of the data to use a logarithmic X-axis. Table 2 presents mean and median values.

In our analysis, we concentrate on the MWN-07 data set and use the MWN-05 and LBNL-07 data sets to highlight noticeable differences. Note that the 2005 data set was collected during Google Maps' beta testing phase.

Figure 3 shows the CCDF of the number of bytes transferred in a single HTTP connection for ALL-HTTP and all Selected-4 applications for the MWN-07 data set. ALL-HTTP connections are clearly consistent with a heavy-tailed distribution over several orders of magnitude, with a median of 332 bytes and a mean of 58 KB. Some connections are used to transfer a large number of bytes, e.g., due to downloading large image or video files embedded within a HTTP page, a big software package, or when HTTP is used as a transport protocol for P2P protocols, such as BitTorrent.

The tails of the AJAX-based Selected-4 applications are not as heavy. Yet, except for Google Mail, the curves lie on top of the ALL-HTTP traffic for most of the plot, which is reflected in the statistics as well, e.g., the median and mean for Google Maps are larger, i.e., 25 KB and 204 KB, respectively.

To further explore the differences in the body of the distribution, we show the PDF for Google Maps and Mail, as well as ALL-HTTP traffic, in Figure 4. In general, we note that the Selected-4 applications (e.g., Google Maps) transfer more bytes than ALL-HTTP connections. This is likely due to multiple larger image/JavaScript library transfers, such as when Google Maps users pan and zoom the map. Specifically, only 39.6% of the MWN-07 Google Maps connections comprise connections that transfer less than 10 KB, whereas 81.8% of the ALL-HTTP connections from MWN-07 transfer less than 10 KB. Similar observations hold for the LBNL-07 data set. Moreover, we note that the shape of the ALL-HTTP connection has not changed substantially over the years if compared with results from 1997 [11].

Google Mail differs and shows a clear spike for 3-byte requests. This is due to periodic server polling by the client-side AJAX engine of Google Mail. Once we move from HTTP connections to HTTP sessions (Figure 5), this artifact is removed, and the probability mass of all Selected-4 applications clearly lies to the right of that for ALL-HTTP traffic. This is reflected in the median but not in all means. However, recall that the mean is dominated by the very large transfers within the ALL-HTTP traffic.

Next, we examine the number of HTTP requests within a session. Figures 7 and 8 show the CCDF and PDF for ALL-HTTP and Selected-4 sessions in the MWN-07 data set. These figures highlight the "chatty" nature of the Selected-4 applications—on average, they issue many more requests than ALL-HTTP traffic, whose first fifty percent of the sessions are limited to 2 requests. Part of these additional requests are due to the Web 2.0 characteristics of the Selected-4 applications, while others are likely due to longer session durations. Interestingly, the PDF reveals that Google Maps issues more requests than the email or social networking applications. A likely explanation is that Google Maps implements pre-fetching more aggressively.

The typical duration of an ALL-HTTP session (Figure 6) is shorter than for AJAX-enabled applications. Half of the ALL-HTTP sessions last between 0.008 and 2.13 seconds (5% – 55% quantile across all sessions), while 50% of Google Maps sessions in the MWN-07 data set last between 13.04 seconds and 2 hours and 9 minutes (30% – 80% quantile across all sessions). On the other hand, the first period only accounts for 20.7% of the Google Maps sessions, while the second only accounts for 23.87% of the ALL-HTTP traffic. One reason for the longer session duration may be that these specific applications are able to keep the users' attention longer than a typical website. Overall, these characteristics indicate that AJAX-enabled applications last longer and are more active than ALL-HTTP sessions.

Finally, Figures 9 and 10 show the inter-request times between requests within a session.