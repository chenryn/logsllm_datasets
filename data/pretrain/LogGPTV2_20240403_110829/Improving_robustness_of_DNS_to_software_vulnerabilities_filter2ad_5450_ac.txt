bustness of clustering in adversarial settings.
CHAPTER 1
INTRODUCTION
Datasets are being generated at an unprecedented rate, which brings challenges to ana-
lyze them. Nowadays, large corporations collect and store Petabytes of data [1, 2]. With
smartphones and the internet-of-things devices generating a wide variety of new data, the
increase in dataset size is only going to become more signiﬁcant. Finding meaningful infor-
mation from massive amounts of data requires considerably more effort, especially when
the datasets are entirely or largely unlabeled.
Clustering is often the ﬁrst step taken in an effort to ﬁnd structure within unlabeled
datasets. Additionally, when there is a small set of available seed labels, clustering may
also be performed to propagate the labels. Repeating this process over time can help us
understand the evolution of threats. For example, clustering long-term datasets enables
botnet forensic analysis, provides early warning of new threats, and tracks the evolution
of security phenomena. Performing such an analytical process reliably requires solutions
for the challenge presented by noise. This noise can be inherent in the data, or injected by
adversaries. The ability to handle noise is thus essential to perform clustering at scale.
This thesis aims to improve the robustness of clustering against noise by analyzing DNS
graphs. We mine two types of DNS bipartite graphs: 1) the domain names resolution graph
that represents Internet hosting infrastructure, i.e., passive DNS datasets; and 2) the graph
of hosts querying domain names.
The ﬁrst goal of the thesis is to deal with the inherent noise in the dataset. For example,
in the passive DNS graph, domains can point to noisy internet infrastructure if the owners
decide to “park” them. In the graph of hosts querying domains, infected hosts carry out
a variety of benign activities, which adds noise to malicious behavior. We propose a new
clustering technique that is robust against inherent noise in the DNS graph.
1
We apply our novel technique to measure the impression fraud generated by the TDSS/TDL4
botnet. Impression fraud is a severe problem in the online advertising ecosystem, which
is a multi-billion dollar industry. While most efforts have been focused on remediating
click fraud, the online advertising industry has only just started to draft standards [3, 4]
for detecting fraudulent impressions. For defenders, impression fraud is a signiﬁcantly
harder problem to solve compared to click fraud. Therefore, conducting impression fraud
is a high-return and low-risk monetization method employed by attackers. Using our ro-
bust clustering technique, we are able to automatically measure the lower-bound loss of
advertisers caused by TDSS/TDL4, over four years of the botnet’s lifetime. In comparison,
related work either relies on manual effort undertaken by law enforcement [5, 6], or only
limits the study to small time periods such as two weeks [7].
Our TDSS/TDL4 study provides a vantage point of infected machines, which is outside
of the ad ecosystem. We also study the ad abuse that can be observed from within the
ad ecosystem, from the vantage point of Demand Side Platform (DSP) providers. Our
analysis shows that traditional blacklists can be used to understand malicious publishers
seen within the ad ecosystem. However, deploying blacklists is not sufﬁcient due to very
small overlap between blacklists and publishers. Since the few blacklisted publishers do
not associate with noisy hosting infrastructure on the DSP graph, we use a simple graph
connected component analysis to track malicious publishers. In addition, our measurement
results show that the behavior of blacklisted publishers differs signiﬁcantly from those that
have never been blacklisted. Therefore, building a reputation system is possible within the
ad ecosystem.
The second goal of the thesis is to make clustering systems more robust against ad-
versarial noise.
If a detection system is deployed, attackers will try to evade it. Many
researchers have shown that classiﬁers can be evaded [8, 9, 10, 11, 12, 13, 14, 15, 13, 16,
17, 18]. On the other hand, limited attention has been paid to adversarial clustering [19,
20]. We face the challenge that the result of clustering depends on all the data points being
2
clustered. By contrast, related work can compute classiﬁcation features directly from one
data point, e.g., image, PDF, phishing page, network packet, or exploit. Therefore, we have
to consider attackers with different knowledge levels in our threat model.
In adversarial settings, an attacker can either inject noise to existing clusters, or she can
move meaningful data points to noisy clusters. We propose two novel attacks that generate
the two types of adversarial noise. Furthermore, we analyze the cost of the attacks, and
present methods to increase the cost for the attackers to evade clustering. Our adversarial
clustering analysis can identify the weaknesses of a clustering system, which enables us to
improve the system for the defender.
1.1 Thesis Contributions
This thesis makes the following technical contributions:
• New Clustering Technique: We develop a spectral expansion technique that is ro-
bust against inherent noise in the data. Our technique can reliably extend the set of
botnet seed domains from a few days of ground truth to four years.
• New Measurement Results in DSP: Our measurement results show that malicious
ad campaigns have statistically signiﬁcant differences in trafﬁc and lookup patterns
from benign ones. These new ﬁndings suggest that reputation systems for advertise-
ment publishers are possible.
• New Adversarial Clustering Analysis: We present two novel attacks against graph-
based clustering, and two defense techniques that reduce the effectiveness of the
attacks. The attacks can be used to improve the robustness of the clustering system
against adversarial noise.
3
1.1.1 Financial Lower Bounds of Online Advertising Abuse
From the edge of the online ad ecosystem, we develop the Ad-abuse Analysis System
(A2S), which is able to analyze one of the most complex, sophisticated, and long-lived
botnets: TDSS/TDL4. The ad-abuse module of TDSS/TDL4 uses a server-side DGA algo-
rithm to generate related C&C domains. The malware does not contain the DGA algorithm,
but receives the domains in conﬁg ﬁles from the C&C server. The bots receive commands
to conduct ad abuse, which causes advertisers to lose money.
The goal of A2S is to estimate lower bounds of the advertisers’ ﬁnancial loss caused by
the botnet using data-driven approaches. With this knowledge, network operators, such as
large Internet Service Providers (ISPs), can design network policies to reduce both (1) the
economic gains for adversaries that monetize ads and (2) the overall impact a botnet may
have to the online ad ecosystem and the advertisers. We develop the spectral expansion
module in A2S to reliably extend the seed of ad-abuse C&C domains. After running the
spectral expansion algorithm 2,590 times, we increased the set of ad-abuse C&C domains
to almost four times the size of the seed set, with a very low (3 out of 838) false positive
rate.
Using four years of network datasets from one of the largest ISPs in North America, we
study: (1) the network infrastructure necessary to support the ad-abuse operation and (2)
the ﬁnancial model to estimate abuse the botnet inﬂicts on advertisers. Our major ﬁndings
include:
• Online advertisers lost at least US$346 million to TDSS/TDL4. This amount is based
solely on the actions of less than 15% of the botnet population. This translates to
more than US$340 thousand per day on average, and the abuse was mostly accom-
plished by impression fraud. It is worth noting that daily abuse levels are three times
of recent results reported for the ZeroAccess botnet [7] and as large as ten times of
the short-lived DNSChanger [21] botnet.
4
• With respect to the infrastructure that supported this botnet operation, adversaries
employed a level of network agility to achieve monetization similar to traditional
botnet C&C communication. At least 228 IP addresses and 863 domain names were
used to support the ad-abuse operation over four years. The domain names are avail-
able here [22].
1.1.2 Measuring Network Reputation in the Ad-Bidding Process
From within the online ad ecosystem, we investigate the potential of using public threat
data to measure and detect adware and malicious afﬁliate trafﬁc from the perspective of
Demand Side Platforms (DSP). A DSP facilitates ad bidding between ad exchanges and
advertisers. In summary, we found that:
• There are 13,324 (0.27%) known malicious domains generating bid request trafﬁc
through the ad exchanges in our datasets. On average, they generate 1.8% of the
overall bid requests daily, much less than previously published values [23, 24]. How-
ever, we can use public blacklists to identify 68.28% of domains before they appeared
in DSP trafﬁc. This suggests traditional sources of maliciousness are valuable, but
insufﬁcient to fully understand ad-abuse from the perspective of the DSPs.
• On average, blacklisted publisher domains tend to use more ad exchanges (average:
1.85) and reach more clients (average: 5109.47) compared to non-blacklisted do-
mains (average ad exchanges: 1.43, average hashed client IP addresses: 568.78).
This suggests that reputation systems for ad publishers are possible.
• Contrary to the observation of blacklisted publisher domains, malware domains use
a similar number of ad exchanges (average: 1.44), but are seen from more hashed
client IP addresses (average: 2310.75), compared to publisher domains that are never
queried by malware (average ad exchanges: 1.43, average hashed client IP addresses:
485.36).
5
Furthermore, we can use simple graph analysis and maliciousness heuristics to track
malicious infrastructure observed by ad exchanges. Among the campaigns ranked the high-
est (top 0.1%), we found new cases including PUP, DGAs and malware sites.
1.1.3 Adversarial Analysis of Graph-based Detection System
We present the ﬁrst practical attempt to attack graph-based modeling techniques in the con-
text of network security. To that end, we devise two novel attacks (namely, targeted noise
injection and small community attacks) against three commonly used graph clustering or
embedding techniques, namely; i) Community Discovery, ii) Singular Value Decomposi-
tion (SVD), and iii) node2vec. Using three different classes of real world datasets (a US
telecommunication dataset, a US university dataset and a threat feed) and after considering
three classes of adversaries (adversaries with minimal, moderate and perfect knowledge)
we mount these two new attacks against the graph modeling component of a state of the
art network detection system: speciﬁcally, Pleiades [25]. We use the classiﬁer model to
test whether and how likely each cluster belongs to the real DGA malware family, both be-
fore and after the attack. Then, we present the overall distribution of such predicted class
probabilities to evaluate the impact of the attacks.
The targeted noise injection attack injects vertices and edges to copy the graph structure
of the original signal, which forces noise into the resulting clusters. In minimal knowledge,
we create a DGA algorithm that can be classiﬁed as benign, effectively evading the classi-
ﬁer, to generate noisy domains for injection. In moderate knowledge, we use unpopular do-
mains from a different network as noise. In perfect knowledge, we use unpopular domains
from the same network trafﬁc as noise. While more knowledgeable attackers typically fare
better, we demonstrate that even minimal knowledge attackers are strong. Attackers with
no knowledge beyond their infections can render the predicted class probabilities of 84% of
the new clusters drops to zero. The attacks can be performed at a low cost to the adversary
by not appearing to be anomalous. The majority of hosts had little change in “suspicious-
6
ness”, whereas a small percentage of hosts increased their suspiciousness after the targeted
noise injection attacks.
Our small community attack abuses the known property of small communities in graphs
to subdivide and separate clusters into one or more unrelated clusters. Community discov-
ery is resistant to the small community attack due to the high costs it would cause the
attacker, however, spectral methods and node2vec are both vulnerable to the small commu-
nity attack. We measure the cost of attacks by the decrease in the attacker graph density.
Node2vec offers more adversarial resistance than SVD because the attack cost is higher.
We propose two defense techniques that could help Pleiades retain its detection capabil-
ities — with the respect of the two proposed attacks. The ﬁrst one is training the classiﬁer
with noise, which shows promise in remediating the noise injection attack to some extent.
The second one is using the small community attack as an adversarial guideline to choose
better hyperparamaters for graph embeddings, which can lower the attack success rate from
75% to 25%.
1.2 Dissertation Overview
In Chapter 2, we introduce different graph clustering methods that we will use in the the-
sis. We also describe the online advertising ecosystem and discuss the vantage points for
Chapter 3 and Chapter 4.
In the ﬁrst part of this dissertation (Chapter 3 and Chapter 4), we study impression fraud
from both outside and inside the online advertising ecosystem. Speciﬁcally, we propose a
new clustering technique to measure lower bound of advertiser’s loss due to impression
fraud generated by the botnet TDSS/TDL4, in Chapter 3. Our new technique generates
very low false positives, and thus can improve the robustness of clustering against inherent
noise in the data. In Chapter 4, we use clustering to track malicious publishers observed by
a DSP, and also perform measurement study for the publisher reputation. Our results point
to the direction of promising features for building a publisher reputation system.
7
In the second part of this dissertation (Chapter 5), we improve the robustness of clus-
tering against adversarial noise. We design and evaluate two novel graph attacks against
a state-of-the-art network-level, graph-based detection system. Our work highlights areas
in adversarial machine learning that have not yet been addressed, speciﬁcally: graph-based
clustering techniques, and a global feature space where realistic attackers without perfect
knowledge must be accounted for (by the defenders) in order to be practical. To conclude
the adversarial analysis, we propose two defense techniques that can improve the robust-
ness of the clustering system.
We conclude the thesis in Chapter 6. Section 6.1 summarizes the contributions. In
Section 6.2, we discuss additional attack cost for generalizing the adversarial analysis to
other datasets as future work.
8
CHAPTER 2
BACKGROUND
2.1 Graph Clustering Methods
Many security datasets can be represented as graphs. Clustering is a common task per-
formed to analyze these security graphs. The two basic assumptions employed by graph
clustering techniques are homophily and structural equivalence. The homophily assump-
tion is based on the notion that, “birds of a feather ﬂock together”. In other words, nodes
that associate with each other are more alike. The corresponding clustering methods have
been widely used in security applications. Community discovery identiﬁes criminal net-
works [26], spectral clustering on graphs discovers botnet infrastructure [25], hierarchi-
cal clustering identiﬁes similar malware samples [27, 28], and the associations in binary
download graph can group potential malware download events [29, 30]. On the other hand,
the structural equivalence assumption states that nodes with similar structural roles (e.g.,
sink nodes) should be in the same cluster, or, have similar graph embeddings. Newly de-
vised graph embedding methods (e.g., DeepWalk [31], node2vec [32]) balance homophily
and structural equivalence using node neighborhoods sampled by random walks. These
methods could further improve the state of the art in the application of graph clustering in
security research.
In this section, we explain graph clustering methods that will be used in the thesis.
2.1.1 Connected Component
In graph theory, within a connected component, any two vertices are connected, but there
are no paths connecting the vertices that are in different components. Breadth-First Search
and Depth-First Search algorithms can both compute the connected components of a graph.
9
We apply the connected component discovery in Chapter 4 to track malicious advertising
campaigns.
2.1.2 Community Detection
There are many ways to detect communities in a graph. Several techniques in this space rely
on a modularity metric to evaluate the quality of partitions, which measures the density of
links inside and outside communities. This allows an algorithm to optimize modularity for
community discovery communities. The Louvain algorithm [33] scales to large networks
with hundreds of millions of vertices. Communities are usually hierarchical [34, 35, 36];
however, ﬁnding sub-communities within communities is a known hard problem [37]. This
allows attackers to hide sub-communities in a “noisy” community by adding edges. We
evaluate the community detection algorithm in adversarial settings in Chapter 5.
2.1.3 Spectral Methods
In [38], Braverman et al. discuss several popular spectral clustering strategies. First, a sim-
ilarity matrix is used to represent the graph. Each row and each column represent a vertex
to be clustered, and the weight is a similarity score between the corresponding vertices.
After proper normalization, the matrix M is used as input to singular value decomposition
(SVD) of rank k, SV Dk(M ) = U ΣV ∗. When the resulting eigenvectors (e.g., vectors in
U) are further normalized, they can be used as an embedding in a euclidean space for learn-
ing tasks. In spectral methods, the hyperparameter k is usually chosen by ﬁrst evaluating
the scree plot of eigenvalues to identify the “elbow” where higher ranks have diminishing
returns of representing the input matrix. When the scree plot starts to plateau at the ith
eigenvalue, we set k = i [39, 40].
Spectral clustering with SVD is known to have limitations when clusters are imbal-
anced; this is due to either graphs being scale-free (power law distribution) [41], or when
small communities exist [42]. Unfortunately, both commonly occur in real-world data. In