hashing and veriﬁcation time.
6.1 Microbenchmarks
We performed a series of microbenchmarks on a single core of a 2.4 GHz Intel Xeon E5-2620 with
32 GB of RAM. The table below gives the time for individual operations on the ﬁelds and elliptic
curves used by Geppetto. The cost of multi-exponentiation and for SHA-256 is reported for each
254-bit word of input.
operation
ﬁeld addition
ﬁeld multiplication
multi-exponentiation
pairing
SHA-256
time
45.2 ns
316.7 ns
231.2 µs
0.7 ms
193.6 ns
6.2 Inner vs. Outer Encodings
We compare the asymptotic performance of inner and outer encodings and summarize the results
in Figure 1.
In our evaluation, we make a distinction between diﬀerent types of veriﬁer eﬀort, depending
on whether the veriﬁer’s input to the computation is passed by value or by reference via a hash
(referred to as an opaque hash for HP schemes in §3.2). In the ﬁgure, they are denoted as “Verify
I/O” and “Verify Intermediate Commitments”, respectively.
19
Generality
Verify
proof
Verify
I/O
HPinn (Ajtai)
Geppetto [20]
HPgen
HPgen (extract)
HP∗
Yes
No
Yes
Yes
Yes
12 pairings Ajtai(n) + 1 MultiExp
12 pairings
12 pairings
12 pairings
12 pairings
3n MultiExp
n MultiExp
n MultiExp
SHA(n) + n MulAdd +
16 pairings + 6 MultiExp
Verify
Prover
Interm. Commit Eﬀort
1 MultiExp
5 pairings
4 pairings
6 pairings
4 pairings
O(D log D)
O(d log d)
O(d log d) + 2n MultiExp
O(d log d) + 3n MultiExp
O(d log d) + 2n MultiExp
+ UHash(n)
Proof Size
(group elts.)
8
8
10
11
20
Figure 1: Asymptotic Performance. Comparison of our schemes and prior work. For our schemes, we
assume the use of our publicly veriﬁable XP1 scheme, and HP
is instantiated with HPgen. We use n for
the size of the inputs/outputs (I/O), d (cid:29) n for the degree of the QAP used for the outsourced computation,
and D = d + 350n. MultiExp is the cost of a multi-exponentiation, and MulAdd is the cost of a simple ﬁeld
multiplication and addition. Ajtai (x) and SHA(x) is the time needed to compute an Ajtai (resp. SHA-256)
hash on x words of input, and UHash(x) is O(x log x), i.e., the time necessary to compute and prove correct
a universal hash.
∗
When the veriﬁer’s input is passed by value, she (or someone she trusts) must directly handle
each I/O value, so the cost depends on the size, n, of the I/O. Note that for any particular veriﬁer,
such computation is required only once for a given I/O value, as the computed commitment (or
hash) can be reused in subsequent computations.
When a veriﬁer uses I/O values passed by reference, she veriﬁes a proof using a commitment
or hash of the I/O values without handling them directly. Since the commitment/hash values
are constant size, the veriﬁcation eﬀort is also constant. A veriﬁer may use I/O values passed by
reference when the corresponding hash comes from a trusted source (e.g., the veriﬁer herself), or
when it represents intermediate values in a computation (e.g., between mappers and reducers in
a MapReduce computation) where the veriﬁer merely needs to check the consistency of the I/O,
rather than the values themselves.
HPinn. We consider the construction HPinn given in Section 3.3 instantiated with Geppetto and
either SHA-1, SHA-256, or Ajtai’s [1] hash function. On the positive side, HPinn has the same
number of elements in the proof as Geppetto; its online veriﬁcation cost is the same as in Geppetto,
while oﬄine veriﬁcation consists of one hash computation plus a multi-exponentiation on a ﬁxed size
word. On the negative side, to support a relation R, HPinn forces Geppetto to work with a relation
R(cid:48) which (on top of encoding R) encodes hash computations. The latter adds signiﬁcantly to the
evaluation key size and the prover’s work, which scale linearly and quasilinearly respectively in the
number of quadratic equations needed to represent the computation. Concretely, Geppetto includes
libraries for veriﬁably computing SHA-1 and SHA-256 hashes. For each 254-bit I/O element, these
libraries require approximately 22,400 equations for SHA-1 or 35,000 for SHA-256. Similar libraries
for Ajtai require only 300–400 equations per word of input, but they increase the cost for the veriﬁer
and may not suﬃce for privacy applications that require stronger randomness properties from the
hash function [16].
Geppetto. Geppetto is an example of an outer encoding scheme which avoids the expenses
incurred by inner encodings. For example, compared with the hundreds or thousands of equations
used for inner encodings, Geppetto only adds one equation per word of input, and hence they
report improving prover performance by two orders of magnitude for processing I/Os [20]. However,
Geppetto’s approach requires the veriﬁer to compute commitments using a multi-exponentiation
(versus a hash in HPinn) that is linear in the I/O size. Furthermore, Geppetto must specify which
computations will be supported at setup time, before data is selected for said computations.
Our HPgen Scheme. Unlike Geppetto, which ﬁxes at setup which computations will be supported
for committed data, our HPgen scheme oﬀers full generality; i.e., data can be hashed completely
20
independently of the computations to be performed, and indeed, new and fully general computations
can be veriﬁed over previously hashed data.
HPgen’s new generality comes at a modest computational cost relative to Geppetto. In terms of
communication, HPgen proofs include two more elements (three with hash extractability); the eval-
uation key and the veriﬁcation key of every relation contain, respectively, 2n and 3 extra elements.
In terms of computation, our prover has to perform two additional n-way multi-exponentiations.
The veriﬁer’s online cost is the same as in Geppetto, whereas oﬄine veriﬁcation requires one
hash computation (i.e., one n-multi-exponentiation) plus four pairings.
If we wish to support
hash extractability, then this adds an additional group element to the proof, an additional multi-
exponentiation for the prover, and an additional pairing for the veriﬁer. Overall, the additional
burden (linear in the I/O size n) that HPgen adds relative to Geppetto is quite small, since both
the size of the evaluation key and the prover’s eﬀort are typically dominated by the complexity of
the outsourced computation, which, in most applications, is much larger than n.
Compared with inner encodings like HPinn, however, HPgen saves the prover signiﬁcant eﬀort.
Concretely, if we instantiate HPinn with Ajtai’s hash, then HPgen is 1, 400× faster per I/O word
(e.g., for n = 1, 000, HPinn takes 10 minutes while HPgen takes half a second), while for SHA-256,
the diﬀerence is closer to 140, 000× (e.g., HPinn takes 18 hours).
Our HP∗ Scheme: Outsourcing Hash Computations. Compared with HPgen, HP∗ drastically
improves the veriﬁer’s I/O processing time. For the veriﬁer, whereas HPgen required a multi-
exponentiation linear in the I/O, with HP∗, the linear costs consist of (1) a symmetric, fast SHA-256
hash computation to compute the key α; and (2) for each word, n additions and n−1 multiplications
over Zp. A conservative comparison based on the results from Section 6.1 shows that (2) is 654×
cheaper per I/O word than a multi-exponentiation, and that (1) using SHA-256 is even cheaper
than (2). Overall, compared with its current I/O processing, HP∗ thus reduces the linear costs of
the Geppetto veriﬁer by two orders of magnitude. As a concrete example, with n = 1, 000, 000,
HPgen takes 4 minutes to process the I/O, while HP∗ needs half a second. Compared with Pantry,
(2) takes one multiplication per word, which is also signiﬁcantly cheaper than computing Ajtai’s
algebraic hash function on each word. An additional beneﬁt of HP∗ is that the veriﬁer’s key becomes
constant size (a few group elements for encoding α and µ) rather than linear in n.
These beneﬁts come at a low cost: HP∗ increases the size of the proof from 11 to 20 elements. For
the prover, the proof cost increases by just 2n ﬁeld operations and a SHA-256 hash computation,
plus the cost of generating Πh, which only depends on n and is independent of the overall relation
to be proven.
6.3 Application Performance
To evaluate the impact of our schemes at the application level, we evaluated them on two applica-
tions.
Statistics has a data generator commit to n 64-bit words. Later, clients can outsource vari-
ous statistical calculations on that data; for example, we experiment with computing K-bucket
histograms.
DNA matching creates a commitment to a string of n nucleotides, against which a client can
then outsource queries, such as looking for a match for a length K substring.
The performance results for both applications appear in Figure 2. As expected, I/O veriﬁcation
in HPinn is more eﬃcient compared to the outer encodings schemes. Among outer encodings, our
HP∗ outperforms others as the size of the input grows and n multi-exponentiations start dominating
the cost of verifying hash outsourcing in HP∗. On the other hand, the outer encodings schemes are
more prover-friendly. In particular, the prover’s total eﬀort (I/O plus computation) is 1.02-2.3x
21
Verify proof Verify I/O Prover Eﬀort
Statistics (n = 256, K = 8)
HPinn (Ajtai)
Geppetto [20]
HPgen
HP
∗
Statistics (n = 1024, K = 8)
HPinn (Ajtai)
Geppetto [20]
HPgen
HP
∗
DNA Search (n = 600, K = 4)
HPinn (Ajtai)
Geppetto [20]
HPgen
HP
∗
DNA Search (n = 60, 000, K = 4)
HPinn (Ajtai)
Geppetto [20]
HPgen
HP
∗
17ms
17ms
17ms
17ms
17ms
17ms
17ms
17ms
17ms
17ms
17ms
17ms
17ms
17ms
17ms
17ms
0.070ms
1380ms
557ms
31ms
0.3ms
6,267ms
2,096ms
30ms
0.079ms
1611ms
574ms
31ms
6.4ms
46,980ms
15,636ms
104ms
117s
113s
114s
114s
2,100s
2,084s
2,085s
2,092s
13.64s
5.00s
5.01s
6.07s