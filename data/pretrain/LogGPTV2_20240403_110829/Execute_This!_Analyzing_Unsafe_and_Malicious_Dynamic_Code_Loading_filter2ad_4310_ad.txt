10 (20%)
11 (22%)
24 (48%)
31 (62%)
2 (4%)
0
0
7 (14%)
n/a
8 (16%)
When comparing the top 50 free applications from May
2012 (see Table II) with the top 50 free applications from
August 2013 (see Table III), we ﬁnd a disquieting tendency:
While only 3 out of the top 50 applications were vulnerable
in November 2012, the share has since increased to 8 out of
50 in August 2013. We conﬁrmed all vulnerabilities reported
by our tool for these two test sets by manual analysis. Further
manual analysis showed that the vulnerabilities are mostly due
to frameworks. For example, several of the top 50 applications
use frameworks that allow testers to install beta versions of the
containing applications. We found that the two frameworks
used by the top 50 applications from August 2013 both down-
load beta versions in the form of APKs to the device’s external
storage, from where the APKs are installed. Since external
storage is writable by any application with the appropriate
permission in Android, any application on the device could
replace the benign APK with malicious code.
The previous example illustrates an important property of
our results: Applications that our tool marks as vulnerable
contain vulnerable code, but the tool does not guarantee that
the code is executed on all devices and in the default conﬁgu-
ration of the application. In the previous example, a user must
participate in the developers’ beta-testing programs for the
applications to expose vulnerable behavior. Nevertheless, we
found sufﬁcient evidence that many applications are vulnerable
even in the default conﬁguration and on any device, as the two
sample exploits in Section V-B will show.
We manually analyzed some of the applications in the
current top 50 that use code-loading techniques but were not
ﬂagged as vulnerable by our tool (see Table III). The reason
is that the detection tool is rather conservative in classifying
applications as vulnerable, so that the reported numbers of
vulnerable applications can be interpreted as a lower bound.
Three of the manually analyzed applications make use of a
framework developed by the provider of a large application
store and manufacturer of Android devices. We found that the
applications contain stub code to load the framework, which
is installed as a separate application. The code identiﬁes the
application by its package name, which most likely makes
the applications vulnerable to an attack similar to the one
presented in Section V-B2, thus increasing the real number
of vulnerabilities above the conservative estimate of our tool.
B. Exploits against vulnerable applications
We now demonstrate how improper use of loading tech-
niques can make benign applications vulnerable to exploitation
by presenting attacks against vulnerable real-world applica-
tions (cf. the second attack scenario described in Section II-B).
We found the vulnerabilities using our automatic detection tool
during the study presented above.
1) Self-update of an advertisement framework: This is our
ﬁrst example of a code injection attack against a benign
application. The application in question – a game with a
number of installations between ﬁve and ten million according
to Google Play – includes an advertisement framework. This
framework has the capability to update itself via the Internet.
Whenever the application is started, it checks with the servers
of the framework developer whether a new version is available.
If this is the case, it downloads the new version and loads
it via DexClassLoader on subsequent application starts. The
connection between the application and the web server uses
HTTP instead of HTTPS. Since HTTP does not protect the
integrity of the transferred data nor authenticate its source, it
is possible to provide the application with a bogus update.
An attacker has several ways to mount an attack. She
tamper with the DNS resolution of the
can, for instance,
victim’s device (e.g., in an unencrypted WLAN) to redirect
the connection to a server she controls, or execute a man-in-
the-middle attack against the HTTP connection.
In our example exploit, we take over the connection and
serve the application a custom ﬁle instead of the expected
update. The application does not verify that the downloaded
code originates from a trustworthy source. It only receives
an MD5 hash from the update server along with the actual
update ﬁle in order to detect transmission errors. We provide
the application with a custom APK and the matching MD5
hash. The victim application does not detect the code injection
and loads our APK the next time it starts. The only requirement
for the malicious APK is that it contains a class with a speciﬁc
name deﬁning a certain method – both can be easily extracted
from the application’s Dalvik bytecode. As our APK meets
the requirements, the application now runs the code that we
injected, and we are free to use its permissions to our advantage
and access its internal data.
By design, our exploit works against any application that
uses the framework, and applications are vulnerable in the
default conﬁguration on every device with Internet access.
According to AppBrain, this framework is included in 0.78%
of all applications on Google Play and 3.21% of the top 500
applications [3]. It is likely that all those applications are
vulnerable.
We informed the company behind the advertisement frame-
work about the vulnerability in July 2013. They responded
within a few hours and acknowledged the severe security
issue. Moreover, they conﬁrmed that their framework is used
in more than 10,000 applications, putting millions of users
9
at risk. Within a few days, they published a new version of
their framework without the vulnerable update component. We
refrain from naming the framework or the company, because
it will take time for the patch to be included in the affected
applications and to be pushed to the users’ devices.
2) Bootstrapping mechanism of a shared framework: The
lack of veriﬁcation of loaded code is not only a problem when
downloading code from the Internet. In this next exploit, we
attack applications that load code locally and fail to verify
its integrity. The target application, downloaded from Google
Play, is based on a framework by a well-known company in
web and multimedia technologies.
The framework allows application developers to create
applications for several different platforms. The developer
essentially designs a Flash ﬁle, which the device-speciﬁc
framework runtime can execute on a variety of systems. The
Android version of the runtime is installed as a standalone
application that any application based on the framework has
to load at start-up. The code that loads the framework is
generated automatically for the application developer. It uses
createPackageContext (see Section III-A) with a hard-coded
package name to load the framework runtime into the current
application. However, the loading code does not verify the
integrity of the loaded application, so that any package with
the right name is accepted. This allows us to mount a code
injection attack as described below.
We install a custom application with the required package
name and the expected class on a test device. When we launch
an application based on the framework, it loads our application
(which it mistakes for the framework runtime) and executes
our code. Note that in order for the exploit to work, the
attacker has to be able to install an application on the device
before the user attempts to install the real framework runtime.
However, this application does not need any permissions at
all – the code “inherits” all permissions from the exploited
application, so that it is relatively easy for an attacker to lure
users into installing her malicious code. Again, veriﬁcation
of the integrity and authenticity of loaded code could have
avoided this attack.
In May 2013, the company that develops the framework an-
nounced that future versions will package the runtime directly
with each application rather than load it from a shared package,
so that this exploit will not work with applications based on
later versions of the framework. However, our exploit works
against any application that is built on top of the framework up
to the version that was published in June 2013. It can attack
those applications in their default conﬁguration. According to
AppBrain, the framework is used in 2.13% of all applications
on Google Play and 2.81% of the top 500 applications [3]. It
is likely that a large portion of the applications that use the
framework has not been updated to the latest version and is
thus vulnerable.
We notiﬁed the company in July 2013 and provided details
on the vulnerability we discovered. As of August 2013, we
have not received any response.
VI. DESIGN OF THE PROTECTION SYSTEM
In the previous sections, we described the problematic
behavior of loading code dynamically at runtime, the risks
Android device
download veriﬁcation results
download apps
Google Play
Amazon Appstore
Veriﬁcation 
provider A
Veriﬁcation 
provider B
check apps
Other stores...
Fig. 3. Overview of the infrastructure that we propose. The dashed parts are
our addition to the current system.
arising from it, and a tool that analyzes existing applications
for such behavior, detecting a large number of vulnerable
applications. We now focus on a possible solution. We start
with a high-level overview of the protection system before
examining details of the implementation.
A. High-level overview
In general, it is a bad decision to delegate responsibility
for system security to application developers if protection can
be implemented by the operating system itself. The protection
system that we propose adds a missing veriﬁcation mechanism
to Android, making it mandatory for all applications. Checking
the integrity of the code before executing it can mitigate all
attacks resulting from the ability to load external code. For
instance, the advertisement framework that we attacked (see
Section V-B1) could have used SSL to make sure that the
update originates from a trustworthy source and was not tam-
pered with by an attacker. Similarly, applications based on the
exploited multi-platform framework (see Section V-B2) could
check the integrity of the common framework application be-
fore executing its code, e.g., by means of signature veriﬁcation.
However, Android leaves the burden of implementing such
checks to the application or framework developer.
At its core, our modiﬁcation enforces that an authority
that
the user trusts approves every piece of code that an
application loads. We envision different application veriﬁers
that analyze applications, each according to a custom set of
criteria and with different algorithms. If an application veriﬁer
deems an application benign, it issues the equivalent of a
signature for the application and makes it accessible to the
public. Application veriﬁers are independent from application
stores – the store offers applications for download, while the
veriﬁer provides approvals for applications. Although store
providers are free to act as applications veriﬁers, this approach
has the advantage that there is no need for store providers to
change anything. We only add the veriﬁers to the ecosystem.
Fig. 3 illustrates the changes that we envision.
Users can choose which veriﬁers to trust. We see several
advantages in this design decision:
Different users may have different priorities, so application
veriﬁers can focus on different sets of criteria when analyzing
applications. For example, enterprises will employ different
evaluation criteria for applications on their employees’ devices
than home users do for their private phones or tablets. Users
get the freedom to choose veriﬁers according to their priorities.
Furthermore, users do not depend on a single veriﬁer, as
is the case in the iOS ecosystem (where devices can typically
only run software approved by Apple).
10
Finally, by decoupling application veriﬁcation from appli-
cation stores, we achieve the same level of security for all
applications regardless of the store distributing them. At the
moment, users of alternative stores to the one preferred by the
device manufacturer (usually Google Play) are inherently at
risk, because Android only distinguishes two modes: “allow
only applications from the preferred store” and “allow any
application” (the sideloading setting, as described in Sec-
tion II-A). This means that users of alternative stores have
no choice but to open their devices to all APKs, regardless
of their origin. On the other hand, our solution focuses on
individual binaries rather than stores, so that it protects users
of all available stores equally.
Note that the Java Virtual Machine (JVM), the standard
Java environment, uses its Security Manager to deal with the
tasks of authenticating and verifying untrusted code. Android,
in contrast, accomplishes most of the Security Manager’s tasks
(except code authentication and veriﬁcation) by means of its
permission system already. The JVM leverages signatures for
code veriﬁcation, which is similar in spirit to our approach.
The difference is that we trust code after a veriﬁcation check,
whereas the JVM trusts code if it originates from a developer
that presents a certiﬁcate.
We implemented our protection system as a modiﬁcation
to Android 4.3, the most recent version of Android at the time
of writing.
B. Detecting attempts to load code
Before we describe our implementation, we make the
following crucial observation: In a Java application, it is not
directly possible to execute externally loaded Java code. In
order to make it executable, applications have to ask the Java
runtime environment to load it (e.g., using a class loader).
This provides us with the unique opportunity to impose checks
on the code that is to be loaded, whereas in other scenarios,
such as raw machine code, we could easily miss the fact
that an application is loading code. Therefore, our system
is implemented as a modiﬁcation of the Dalvik VM,
the
component of Android that executes Java code. This means
that our protection system does not require changes to the
operating system as a whole and can be easily applied.
Whenever an application asks the Dalvik VM to load code,
we check the integrity of the code from within Dalvik (details
on the nature of our checks follow shortly). At ﬁrst glance, it
seems possible to implement the integrity checks at a higher
level in the system, e.g., as a modiﬁcation of the Java frame-
work that Dalvik provides to applications. However, the reason
for us to choose the lower level is reﬂection, a Java mechanism
for introspection: Reﬂection allows Android applications to
call any Java method irrespective of its protection attributes.
This would allow applications to escape our protection system
if we implemented it in Java. For example, imagine a Java
method that checks code integrity and subsequently calls the
(private) native method provided by Dalvik to load the code.
Then a malicious application could just call the native method
directly using reﬂection, thus circumventing the check. As a
result, we have to implement any checks in Dalvik’s native
code.
Similarly, one might argue that rooting the protection
scheme deeper in the Android system would constitute a
more comprehensive way to address the issue. However, we
refrained from doing so mainly for two reasons:
1)
2)
A separate branch of the Linux kernel is maintained
for each device, so that modiﬁcations to the kernel
are more difﬁcult to adopt on all devices than modi-
ﬁcations to higher levels of the Android system.
Our approach is based on a key property of Java, so
there is no need to work at a lower level than the
Java virtual machine. Doing so would only introduce
unnecessary complexity.
Since our system relies on the necessity to make code-
loading operations explicit in Java, native code imposes a
challenge. Native machine-code instructions, as opposed to
Java byte code, provide a variety of ways to execute additional
code or modify existing one. We cannot prohibit
the use
of native code, because applications use it legitimately, e.g.,
to accelerate computationally expensive tasks [1]. Zhou et
al. found in 2012 that 4.52% of applications from different
markets use native code [39]. However, applications always
start by executing Java code in the Dalvik VM. By hooking
the interface in Dalvik that applications have to use in order to
load native libraries, we can detect when an application tries
to execute native code. We enforce an integrity check on any
native code that the application tries to load.
It
is the responsibility of the veriﬁcation service that
approves an application to make sure that the application’s
native-code part does not load any additional code. Note that
this decision is much easier for the veriﬁcation service than it
would be for our protection system: Application developers can
provide veriﬁcation services with additional material to prove
that their native code does not load any additional external