is actually its release date. Security patch level of a ROM indicates that this
ROM has patched all the vulnerabilities released before this date.
4The patch release date for a CVE is its security patch level.
Figure 6: The unpatched ratio of all affected CVEs under
different CVSS scores (RQ1).
RQ2: Does the complexity of a security patch affect its
application ratio? We use the number of patch-affected lines
of a patch to represent its complexity. In this way, we correlate
the unpatched ratio of each CVE to its patch complexity,
which is depicted in Figure 7. We perform a t-test at a
signiﬁcance level of 0.05 to study the relationship between
the unpatched ratio and the patch complexity, and the result
shows that patch complexity does not signiﬁcantly affect its
application ratio.
RQ3: Does code customization affect patch application?
Third-party open-source code is typically customized before
it is used in a software product. To ﬁgure out whether code
customization becomes the obstacle to timely patching, we
thoroughly analyze the relationship between the degree of
code customization and the patched ratio. To measure the
degree of code customization, we use function-level code
similarity. To be speciﬁc, we leverage the tool introduced
5CVSS is a common way to assess vulnerability severity.
1158    29th USENIX Security Symposium
USENIX Association
1098765432CVSS Score020406080100Unpatched Ratio(%)the patch is released and the patch is applied. Based on a large
number of ROMs, we try to follow these steps to estimate
such lag. First, we count the collected images in our dataset
for each model and select the models with at least 10 images
to study. The reason is that more collected images for a model
help to track patch status more accurately. Second, we check
the patch status for all the images of the selected models and
select those CVEs which have been patched by at least one
image for each model. Finally, we calculate the patch lag for
a CVE on a model as the time span between the patch release
date of the CVE and the build time of the ﬁrst ROM to patch
this CVE of this model. Table 6 presents the average time for
the selected 99 models to patch its affected CVEs.
Figure 7: The correlation between unpatched ratio of all
affected CVEs with the complexity of their patches (RQ2).
# of Selected
Phone Models
Table 6: The average patch lag for different vendors.
Average Patch Lag
per Model (day)
-65 ∼ -21.47
38.16 ∼ 412
70.07 ∼ 449.25
85 ∼ 411
186.35 ∼ 194.58
62.71 ∼ 368.89
# of ROMs
per Model
20 ∼ 77
10 ∼ 54
10 ∼ 31
10 ∼ 29
10 ∼ 12
11 ∼ 24
Vendor
Google
Samsung
Xiaomi
Meizu
Vivo
Oppo
Huawei
12
16
33
25
2
10
1
10
65.55
Figure 8: The unpatched ratio for all ROM-CVE pairs under
different customization degrees (RQ3).
in §4.3 to calculate the centroid [19] similarity of patch-
related functions between the test target and reference ones in
AOSP. As shown in Figure 8, the unpatched ratio for patch-
related functions with no code customization (there are 50,082
functions whose similarity score is 1 to the reference one) is
signiﬁcantly lower (13.02% vs 26.92%) than those with code
customization (that is 44,212 functions). We also perform a
one-way analysis of variance [12] to verify the signiﬁcance
level of the difference between the unpatched ratio of
functions with and without customization, and observed the
p-value is 6.64e-285. Besides, we surprisingly observed that
the degree of code customization does not consistently affect
the patched ratio.
Findings: A large part of CVEs are not patched by every
ROM built after the patches are released. When exploring the
factors that affect the application ratio for a security patch,
it seems vulnerability severity and patch complexity are not
considered by vendors, but code customization is an obvious
obstacle for developers in applying patches.
5.2 The Lag of Applying Security Patches
RQ4: What is the average lag for different vendors to apply a
patch? It is well-known that security patches are not applied
by vendors timely, but it is difﬁcult to estimate the lag between
Findings: Google proactively patches its own devices even
before announcing the vulnerabilities to the public, while
third-party device manufacturers apply security patches
relatively slowly. Besides, the patch lags for different phone
models from the same vendor vary signiﬁcantly.
5.3 The Management of Security Patches
Vendors play an important role in applying security patches.
However, it is still unknown what difﬁculties do vendors
encounter when managing security patches. Therefore, we
explore the following two research questions.
RQ5: Do vendors patch vulnerabilities for one model
but ignore another? Since smartphone vendors usually
manufacture several phone models, it is quite a challenging
task for vendors to manage security patches among multiple
software product lines. Specially, we concern whether vendors
patch a known vulnerability for one model but ignore another.
To study this problem, we design the following experiment.
First, for each CVE and vendor, we select the ROM (marked
as ROM f irst) that is the ﬁrst to apply the patch in this vendor.
Second, for the same CVE and vendor, we select all models
different from the model of ROM f irst, which has a ROM not
applied the patch. At last, we ﬁnd all the models (called
Ill-managed Model) that have been forgotten by the vendor
to patch a vulnerability (called Ill-managed CVE) and this
vulnerability has already been applied to some other models
of the same vendor. As presented in Table 7, we ﬁnd that all
vendors (including Google) have ever patched a vulnerability
on one model but forgot to patch the same vulnerability on
USENIX Association
29th USENIX Security Symposium    1159
[0-10) [10,20) [20,30) [30,40)     >=40 Patch-affected Lines020406080100Unpatched Ratio(%)1(0.9,1)(0.8,0.9](0.7,0.8](0.6,0.7](0.5,0.6](0,0.5]Function Similarity Region010203040Unpatched Ratio(%)13.0221.0033.2529.2621.9644.0638.05another model. To further conﬁrm whether Google has made
mistakes in managing security patches, we manually check
the affected ROM images and ﬁnd that they indeed forgot to
apply the security patches.
Table 7: Results of how often do vendors patch a vulnerability
at a model while ignore another.
# of Ill-managed CVEs
# of Ill-managed Models
Vendor
Google
Samsung
Meizu
Xiaomi
Oppo
Vivo
Huawei
24
76
93
75
63
41
33
12
25
43
43
20
35
32
RQ6: Do vendors correctly set security patch level?
According to Android Security Bulletin, the security patch
level of a ROM indicates that the ROM has patched all the
vulnerabilities released before or equal to this level. Thus,
the security patch level set in a ROM is important for end-
users and security experts to assess its security. However, it is
unknown whether vendors correctly set security patch levels.
Based on the way they set security patch levels, we consider 3
kinds of ROMs: 1) Negligent ROM has some vulnerabilities at
a lower patch level unpatched; 2) Diligent ROM has patched
all the vulnerabilities before its declared patch level and does
not patch any vulnerability at a higher patch level; 3) Prudent
ROM not only patches all the vulnerabilities required by its
declared patch level, but also patches some vulnerabilities at
a higher patch level. We label all ROMs in the dataset based
on how vendors set the security patch level for them. We also
exclude 233 ROMs that have not set a security patch level.
The results are presented in Table 8. We surprisingly ﬁnd
that all vendors (including Google) have negligent ROMs. We
randomly select 30 negligent ROMs from all vendors to verify
the result and ﬁnd our tool report correct results.
Table 8: Results for ROMs labeled according to how their
vendors set security patch level.
Vendor
Google
Samsung
Meizu
Xiaomi
Oppo
Vivo
Huawei
# of
Negligent ROMs
# of
Diligent ROMs
# of
Prudent ROMs
112
376
412
448
173
139
89
182
12
6
2
19
2
0
185
66
5
8
24
6
2
Findings: Every vendor including Google inevitably makes
mistakes in managing patches among multiple phone models,
and over-claim the security patch level in some of their
devices. These facts indicate that patch presence test tools
such as BSCOUT is necessary to aid the management of
security patches.
5.4 Lessons Learned
Through our study, we ﬁnd that vulnerabilities inherited from
open-source projects are not actively patched by software
vendors. Speciﬁcally, a large fraction of executables remain
unpatched and other executables, although patched, usually
suffer a long patch lag. There may be software maintenance
issues inside each vendor because we ﬁnd they do not timely
sync security patches to all product lines and usually claim
a higher security patch level than the actual one. However,
we believe a fundamental cause behind these phenomenons is
the lack of transparency of the patch application status or, in
other words, there is no way for end-users, security companies,
administrators, etc. to easily, effectively and quantitatively
measure the patch application status of software. In this
way, reliable, ﬂexible and accurate patch presence tools (such
as BSCOUT) are needed to urge/motivate vendors to apply
security patches.
Since the resources that vendors could invest in applying
security patches are always limited, they are expected to
arrange the order of the patches to be applied in a rational
way. However, we ﬁnd no obvious clue that vendors do follow
some principles to prioritize the patching process in our
study. For example, the patched ratios for vulnerabilities with
high severity or low patch complexity are not signiﬁcantly
different from those of others. Meanwhile, we observe that
code customization is indeed an obstacle for vendors to apply
patches, i.e. the unpatched ratio for patch-related functions
with no customization is signiﬁcantly lower than those with
customization. Besides, even when the patch-related functions
are not customized, the unpatched ratio is still as high as
13.02%. These ﬁndings indicate that more techniques are
needed to help vendors apply patches, e.g. metrics to prioritize
patches, back-porting security patches to lower versions and
migrating security patches under code customization.
6 Limitations
BSCOUT simply ignores out-of-method changes when
performing a patch presence test. Therefore, it would fail
in extreme cases when patches only contain out-of-method
changes. This problem could be solved by enhancing
BSCOUT to also extract features from out-of-method changes.
We leave this optimization as our future work.
The current implementation of BSCOUT adopts a primi-
tive version of CRFs model to perform the learning-based
instruction segmentation. Although it achieves satisfying
performance, this part of the work could be further optimized
by systematically evaluating all kinds of models to determine
the best one.
Since BSCOUT does not know which patch lines are more
important than others, it has to consider each patch line as
equal importance. Besides, BSCOUT relies on users to provide
the correct patch for the test target to ﬁx the vulnerability.
1160    29th USENIX Security Symposium
USENIX Association
Otherwise, the patch presence result could not correctly reﬂect
the vulnerability patching status.
7 Related Work
The most related work can be categorized in three directions.
Patch Presence Test. FIBER is designed to perform
a patch presence test for C/C++ binaries. Since FIBER
leverages a small and localized patch snippet for exact
matching, it is hard to tolerate code customization (acknowl-
edged in §6.2 of FIBER [46]). However, we ﬁnd that code
customization is very common in our Dataset_ROM_GT
and Dataset_ROM_Large. Thus, simply applying FIBER in
these Android ROMs can not achieve satisfying performance
and can not facilitate a large-scale patch application study.
By leveraging the whole patch for patch presence testing,
BSCOUT is more resilient to code customization and achieves
remarkable accuracy.
SnoopSnitch [38] adopts a straightforward approach to
perform patch presence test on native code. In its design, it
enumerates all existing code commits and compilation options
to prepare a large set of reference images and use the patching
status of the most similar one to the testing target as the result.
It is quite similar to version pining tools that are evaluated in
§4.2. Obviously, this mechanism requires huge overhead in
reference set preparation, bears bad scalability in testing, and
is hard to tolerate code customization on the testing target.
Function-level similarity. The function-level similarity is
widely used to search known buggy/vulnerable functions in
a large codebase. Depending on different targets, existing
work could be further divided into two classes: source code-
level and binary-level. Source code-level work requires the
availability of source code and usually leverage different kinds
of source-level features to represent one function, such as
normalized source code [29], code tokens [25, 27, 32] and
parse trees [26]. This line of work differs from ours in that
we do not require the source code of the test target.
Binary-level work seeks more robust features for similarity
analysis. The similarity between control ﬂow graphs is used
by BinDiff [22] and BinSlayer [18] to search similar functions.
Rendezvous [28] improves this technique by considering
instruction mnemonics, control ﬂow sub-graphs, and data
constants. Cross-platform bug search is an appealing feature
that requires to lift binary signatures to platform-independent
representations. multi-MH [40] extracts high-level function
semantics using the I/O behaviors at basic block level, while
discovRE [43] transforms platform-dependent basic blocks
into platform-independent numeric features. To improve