修改output如下：
#### 7.3.8 重启服务随后检查报告
    systemctl restart logstash elasticsearch
现在你应该为Vulnwhisperer创建了一个新索引：
转到Index pattern，检查你的字段编号：
**Note：刷新index pattern以识别所有字段。**
最后，到Dashboards 并查看报告。这时，可视化页面应该没有任何错误。
现在，Nessus生成的所有.csv扩展名的报告都将自动发送到你的ELK Stack。因此，就可以在kibana仪表盘下对其进行可视化了。
## 0x08 事件管理
在本节中，我们把最难题的部分放在本节中。将介绍SOC的事件管理部分：我们已经使用了2种开源技术——TheHive和Cortex。
TheHive将用作我们项目的告警管理平台，该平台可以管理从创建到关闭的告警事件。同时，Cortex是与TheHive同一个团队开发的补充产品，使用“分析器（analyzers）”和“响应器（responders）”对数据进行补充。
本节内容分为以下几个部分：
  * TheHive和Cortex的安装和配置；
  * TheHive和Cortex仪表盘的演示；
  * 将Cortex与TheHive集成；
  * 安装MISP并将其与TheHive集成;
  * 排查：事件管理。
### 8.1 TheHive和Cortex的安装和配置
我们部署的版本是：TheHive 3.4.0-1和Cortex 3.0.1-1。
TheHive需要Elasticsearch才能运行。为此，我们选择使用docker-compose在Docker容器中一起启动它们。如果你不想使用Docker，也可以手动安装和配置Elasticsearch。
有关更多详细信息，参阅：
>  Project/TheHiveDocs/blob/master/installation/install-guide.md>
**None:** TheHive使用ElasticSearch来存储数据，两款软件使用的都是Java
VM。推荐使用8核的CPU、8GB内存和60GB硬盘存储的虚拟机，当然也可以直接使用相同配置的物理机进行部署。
我们使用以下 **docker-compose.yml** 文件在3个不同的容器中一起启动Elasticsearch，TheHive和Cortex：
    version: "2" 
    services: 
      elasticsearch: 
        image: elasticsearch:6.8.0 
        ports: 
          - "0.0.0.0:9200:9200" 
        environment: 
          - http.host=0.0.0.0 
          - cluster.name=hive 
          - thread_pool.index.queue_size=100000 
          - thread_pool.search.queue_size=100000 
          - thread_pool.bulk.queue_size=100000 
        ulimits: 
          nofile: 
            soft: 65536 
            hard: 65536 
      cortex: 
        image: thehiveproject/cortex:3.0.1 
        depends_on: 
          - elasticsearch 
        ports: 
          - "0.0.0.0:9001:9001" 
      thehive: 
        image: thehiveproject/thehive:3.4.0 
            depends_on: 
          - elasticsearch 
          - cortex 
        ports: 
          - "0.0.0.0:9000:9000" 
        command: --cortex-port 9001
复制粘贴保存到`docker-composer.yml`文件中，随后执行如下命令：
    sudo sysctl -w vm.max_map_count=524288
最后运行：
    docker-compose up
TheHive监听9000/tcp端口，Cortex监听9001/TCP端口。这些端口可以通过修改docker-compose文件来更改。
可以使用如下命令查看创建的容器：`docker ps –a`：
检查Elasticsearch是否可联通：
现在一切都已设置好，让我们看一下TheHive仪表板。
### 8.2 TheHive和Cortex仪表盘的演示
浏览器访问
**注意：** 如果要在云主机上安装，不要忘记为9000、9001和9200端口配置规则放开。
点击Update Database，并创建一个管理员用户：
使用该用户登录：
下图就是TheHive主要的Dashboard：
现在让我们检查下Cortex的Dashboard：
浏览器访问：
点击Update Database，并创建一个管理员用户登录（跟前文TheHive的步骤一样）。
Cortex的工作方式是，你当前的用户可以创建组织和用户，但是必须以组账户登录才能启用
和管理Analyzers(分析器)。
通过单击页面上的”+添加组织“按钮来创建新的组织：
现在切换到”用户“标签，随后点击”+添加用户“，将新用户分配给你创建的组织，并赋予他们组织管理员的角色。保存后，为刚创建的用户点击”新密码“，然后输入密码，点击Enter保存。现在，注销并以新用户身份重新登录。点击页面顶部的”Organization(组织)“选项：
现在，点击组织中的 **Analyzers** 选项卡（不是页面顶部的Analyzers）。如果Cortex正确配置了，应该就可以看到
Analyzers(分析器)。到今天为止，我有124个可用的Analyzers：
现在让我们启用某些Analyzers以供后续使用，保留默认设置。某些Analyzers需要API密钥，因此请确保在配置这些Analyzers时提供正确的信息。
### 8.3 将Cortex与TheHive集成
点击组织中的Users选项卡，然后创建一个新用户以与TheHive集成。这个用户应该有读和分析的角色。这次不为用户设置密码，而是单子”
**创建API密钥** “并复制密钥。现在回到终端，通知所有运行的容器，在主目录中创建一个文件，并命名为`application.conf`:
    cortex { 
      "CORTEX-SERVER-ID" { 
        # URL of the Cortex server 
        url = "http://172.18.0.3:9001" 
        # Key of the Cortex user, mandatory for Cortex 2 
        key = "nBqA7B6BYc1kHhgAXZOYoXjBnt5vlCgM" 
      } 
    }
url参数是 inspect `命令检索容器ip)，key参数是刚才创建的api密钥。保存该文件，随后修改`docker-compose.yml`文件，在TheHive的配置部分，添加：
    volumes:
    - /home/your_user/application.conf:/etc/thehive/application.conf
    ......
    command:
    --cortex-key (上一步使用的相同api_key )
保存文件并退出编辑器，随后再次运行`docker-compose up`。
在全部容器启动起来后，回到TheHive的dashboard，点击账户onglet下的”about“，应该可以看到与下图相同的信息：
现在，我们已成功将Cortex与TheHive集成在一起了。
### 8.4 安装MISP并将其与TheHive集成
#### 8.4.1 安装MISP
    1.sudo apt-get update -y && sudo apt-get upgrade -y
    2. sudo apt-get install mysql-client -y
    3.curl https://raw.githubusercontent.com/MISP/MISP/2.4/INSTALL/INSTALL.sh -o misp_install.sh
    4.chmod +x misp_install.sh
    4. ./misp_install.sh -A
当安装过程中询问baseurl 时，输入你的IP：
当询问创建一个“misp”用户时，输入“y”。
**PS：** 别忘记在你的机器上开启80和443端口。
安装完成后，浏览器访问
使用默认用户名密码登录（PI:EMAIL / admin），随后输入新密码用户更改默认密码。
**启用MISP集成** ：
浏览器访问MISP的web页面，点击管理 ->
添加用户，向用户发送电子邮件，例如：`PI:EMAIL`，随后将用户添加到 **ORGNAME** 组织，角色选择
**user** ，取消选中底部的所有复选框，复制用户的AuthKey。
随后转到 **Cortex > Organization > Analyzers**，在搜索框输入“misp”，启用 **“MISP_2_0”**
，为MISP服务器指定一个描述性名称，url框输入你的MISP
IP，key输入创建MISP用户的密钥（AuthKey），cert_check选择“False”：
现在，访问MISP的web页面 > Sync Actions > List
Feeds。找到一个你已经订阅的feeds，点击右边的放大镜按钮，在列表中选择一个ip并复制。
现在在Cortex中，点击” **+New Analysis** “，添加一个IP的数据类型，并粘贴刚才复制的IP。
选择 **The MISP_2_0 analyzer and run**
。在任务历史记录页面，点击”View“，你应该看到你复制的IP的列表名称以及该列表提供的其他信息。
可以进入TheHive，把这个IP作为一个观察点，进行测试。
### 8.5 排查：TheHive的事件管理
TheHive的核心结构就是排查事件。TheHive旨在使分析人员更轻松，并确保从事此工作的团队成员之间更好的理解。这是至关重要的，因为事件排查似乎大多数安全排查的核心结构，无论是查看告警、对恶意软件进行你想还是处理应急响应事件。
你可以在事件中添加标签以进行快速的搜索和过滤。还可以评估事件的严重性，跟踪TLP级别，这样可以帮助管理和促进数据共享。事件中的所有数据很容易从页面顶部的搜索栏中搜索出来。这样可以更轻松地确定你当前正在观察的活动是否存在于先前早期的事件中。
你也可以通过导入告警来创建事件。如果两个告警共享一个链接，可以选择将这个告警添加到现有的事件中，而不是生成一个新的事件。
事件创建完成后，可以开始为它设置tasks(任务)。tasks(任务)可以是任何东西，但我们建议用他们来跟踪排查事件问题。
此外，多个分析人员可以同时处理同一事件。例如，一个分析人员可能会处理恶意软件的分析，而另一个分析人员可能会在同事添加IOCs(失陷指标)后，立即在代理日志上跟踪C2
beacon活动。
**事件模板** ：
随着SOC的发展，定义处理手册变得至关重要，它可以帮助分析师一致地处理具有共同属性的排查。例如，在最初调查一系列的密码爆破登录失败行为或钓鱼邮件时，我们采取的排查步骤通常是类似的。如果能确定这些步骤，你就会有一个很好的开端来培训新的分析人员，并确保大多数调查是在一个平等的基础上开始的。TheHive提供了一个独特的事件模板系统，允许定义常见的排查步骤并预先填充事件的元数据和任务。
在上图的例子中，我们定义了一个与漏洞利用工具包活动有关的排查模板。现在，当我创建一个新事件时，我可以选择这个模板，你所看到的所有信息都会预先填充到事件的细节中。真正实用的是在事件发生之前自动创建一系列tasks(任务)的能力，这基本上就是为我们定制了操作处理手册，这样，就可以自动填充等待的任务队列，从而使其他分析人员能够直接介入排查，或开始完成控制和消除的任务。
此外，TheHive支持在事件的上下文中为有趣的可观察对象创建单独的条目。可观察的是任何有趣的数据工件。TheHive内置了几种常见的可观察类型：包括IP地址、域名、HTTP
URI等。当然，您还可以定义自己的类型，从而使该功能更加灵活使用。
跟踪观测值有很多好处，显而易见的一点是，你可以在后续的调查中搜索他们，以引入更多的来龙去脉。还可以将它们导出，以便以后导入黑名单、白名单或检测机制。最后，您可以使用内置的Cortex集成将观测值自动提交给任意数量的OSINT研究站点。这是一个非常简单的过程，并且仅需要您为将要使用的每个服务输入API密钥。一些现有的集成包括Passive
Total、Virus Total和Domain Tools。
准备好关闭事件时，请单击事件标题栏中的“关闭”按钮：
你还可以把事件的性质设为真阳性（true positive），假阳性（false positive）等等…
## 0x09 写在最后
原文链接：
文中当然有很多翻译不当、笔误的内容，欢迎读者指正。感谢。
* * *
****