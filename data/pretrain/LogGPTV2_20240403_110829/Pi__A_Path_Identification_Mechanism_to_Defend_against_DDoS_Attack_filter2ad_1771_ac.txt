Unlike the choice of n, the value for o, the number
of routers away from the victim at which we stop mark-
ing, is not a globally imposed constant. Rather, each
organization can decide what value is best for itself, and
conﬁgure the routers within its control accordingly. The
beneﬁt of choosing a large o value is that markings from
earlier in the path (closer to the attacker or user) will not
be overwritten by the routers close to the victim, which
presumably handle the majority of the victim’s trafﬁc
anyway. However, choosing a large o has a drawback as
well. By pushing the perimeter of non-marking routers
farther from the victim, the number of routers that mark
the packet is reduced accordingly. Thus, it is more likely
that randomized attacker initialized markings will re-
main in the packet, thus allowing an attacker to jump
between markings even when on the same path. These
two contrasting characteristics cause us to pick different
o values depending on the n value that is chosen. For
n = 1 we need 16 routers to completely overwrite any
attacker initialized data. Thus, we would like a small o
value, so that as many routers as possible will mark the
packet. We therefore choose o = 0 (where all routers,
except the victim itself, mark packets) for our tests with
n = 1. For n = 2, however, we would like as large an o
value as possible, since only 8 markings ﬁt into a single
packet and that is well short of the average path length
of 15 for our data sets. Unfortunately, it is difﬁcult to de-
termine exactly what a reasonable number of hops away
from a victim are still under that victim’s administration.
Therefore, we have chosen a value of o = 3, based on
limited data from several traceroutes that we have
performed to large web servers (like Amazon.com), for
testing under an n = 2 bit scheme.
6.2 DDoS Attack Model
In order for a DDoS victim to protect itself against
attack packets, it must have a way to differentiate them
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
7
from normal user packets. Recall that in Section 3 we
stated that such a method was required to identify the
packet markings that the victim will add to its attack
markings list. Once those markings are identiﬁed, it
is a simple matter to drop packets with the same mark-
ing by comparing incoming packet markings against the
markings in the attack list.
It is outside the scope of
this paper to deﬁne an algorithm for attack packet iden-
tiﬁcation (the reader is referred to [18] for a thorough
analysis of this problem). However, to incorporate the
use of this algorithm, we model our DDoS attack in
two phases.
learning phase,
all packets are assumed to be analyzed by the victim,
using the packet identiﬁcation function that determines
whether the packet is an attack packet or a legitimate
user’s packet. In other words, the victim is temporar-
ily given the power to differentiate between legitimate
users’ packets and attackers’ packets. The victim is thus
able to generate an attack markings list. In the second
phase, the attack phase, the victim is presumably no
longer able to apply its packet identiﬁcation function and
is forced to use the Pi ﬁlter based on the information it
has gathered in the learning phase.
In the ﬁrst phase, the
6.3 Experiment Design and Performance Met-
rics
For our experiments, we choose 5000 paths at ran-
dom from one of our Internet data sets to act as legiti-
mate users. We choose our attackers in the same way,
but with the constraint that no path be chosen as both a
user and an attacker. Each end-host at a path, whether
user or attacker, sends three packets to the victim server
in phase one of the attack, and three packets in phase two
of the attack. We choose a three packet learning phase
to illustrate how quickly Pi ﬁlters can react to DDoS at-
tacks. A longer learning phase (which would almost cer-
tainly be the case in a real deployment scenario) would
only improve performance further, because the victim
would have more packet markings on which to base its
ﬁltering decisions. As our performance metric, we cal-
culate the ratio of the number of attack packets accepted
by the victim to the total number of attack packets sent
(the attacker packet acceptance ratio) as well as the ratio
of the number of user packets accepted by the victim to
the total number of user packets sent.2 In some of our
results we show the acceptance ratio gap, which is sim-
ply the attacker packet acceptance subtracted from the
2The packet numbers used in our metrics are taken only from phase
two of the attack - after the attack packets have been identiﬁed. This
is a reasonable measurement of our scheme’s performance because
no DDoS protection mechanism that we are aware of can stop attack
packets before they are ﬁrst classiﬁed as such (Ingress ﬁltering, where
deployed, can stop attack packets with spoofed source IP addresses,
but still forces victims to identify malicious ﬂows from attackers using
legitimate source IP addresses).
If the victim server where to
user packet acceptance.
apply a completely random ﬁlter, then the user and at-
tacker packet acceptance ratios would be exactly equal,
so the acceptance ratio gap provides a metric that shows
how much better the Pi ﬁlter is performing compared to
no ﬁlter at all. Our results are presented in Figures 5
through 8 and discussed in the next two sections.
6.4 Results
In Figure 5 we see the n = 1 bit and n = 2 bit
schemes with a threshold of zero. These curves repre-
sent the strictest possible ﬁltering in the Pi scheme: a
single attack packet with a particular marking received
during the learning phase of the DDoS attack causes all
packets with that marking to be dropped during the at-
tack phase. The attack packet acceptance ratio is due
to attackers located near enough to the victim that the
random data that they initialize into the IP Identiﬁcation
ﬁeld of their packets is not completely overwritten, al-
lowing them to jump to markings that were not recorded
by the victim in the learning phase of the attack. Be-
cause the n = 1 bit scheme requires twice the number
of marking routers as the n = 2 bit scheme to overwrite
such random data, its attacker acceptance ratio is larger.
The downward slope exhibited for the user accep-
tance ratio, in both schemes, is due to the increasing
number of attacker markings that collide with user mark-
ings, causing them to be dropped. This is an example of
the marking saturation effect which we discuss in Sec-
tion 5.2. Surprisingly, marking saturation also affects
attackers as well as legitimate users, as exhibited by the
downward slope of the attacker acceptance ratios in Fig-
ures 5a and 5c. With a larger number of attackers, attack
packets begin interfering with each other, in the sense
that an attacker a may shift between four markings, two
of which another attacker, b, is also shifting between.
Because both a and b send packets in the learning phase,
it is more likely that the overlapping markings will be
received by the victim and added to the attacker mark-
ings list than it would be if only one of the attackers
is present. The downward slope is minimized for the
n = 2 bit scheme in Figures 5b and 5d because there
are fewer attackers that are close enough to the victim to
shift between markings.
In Figure 6 we show the effect of increasing the
threshold value to combat the marking saturation effect.
In this experiment, we set the threshold value to 50%,
where more than half of the packets arriving with a par-
ticular marking must be attack packets before the vic-
tim begins dropping all packets with that marking. Of
course, increasing the threshold value increases the over-
all number of packets accepted, which is reﬂected in the
higher acceptance ratios for both the users and attackers.
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
8
1
0.8
0.6
0.4
0.2
o
i
t
a
R
e
c
n
a
t
p
e
c
c
A
t
e
k
c
a
P
0
0
2000
1
0.8
0.6
0.4
0.2
o
i
t
a
R
e
c
n
a
t
p
e
c
c
A
t
e
k
c
a
P
0
0
2000
User Packets
Attacker Packets
1
0.8
0.6
0.4
0.2
o
i
t
a
R
e
c
n
a
t
p
e
c
c
A
t
e
k
c
a
P
8000
10000
0
0
2000
4000
6000
Number of Attackers
4000
6000
Number of Attackers
(a) n = 1, Internet Map
(b) n = 2, Internet Map
User Packets
Attacker Packets
1
0.8
0.6
0.4
0.2
o
i
t
a
R
e
c
n
a
t
p
e
c
c
A
t
e
k
c
a
P
8000
10000
0
0
2000
4000
6000
Number of Attackers
4000
6000
Number of Attackers
User Packets
Attacker Packets
8000
10000
User Packets
Attacker Packets
8000
10000
(c) n = 1, Skitter Map
(d) n = 2, Skitter Map
Figure 5. Pi Filtering with a 0% Threshold
From our results comparing the 0% and 50% thresh-
old values, we can conﬁrm the intuitive result that rais-
ing the threshold value can minimize the marking satura-
tion effect. With the 50% threshold, marking saturation
affects attackers and users equally because simply re-
ceiving an attack packet with a particular marking at the
victim no longer results in dropping all the users’ pack-
ets with that marking. This phenomenon is shown in
Figure 6 as the equal downward slope exhibited by both
the attacker and user packet acceptance ratios. What this
suggests is that victims may want to modify their thresh-
old ﬁlter values according to the severity of an attack. In
Figure 7 we plot the acceptance ratio gap for four differ-
ent threshold values. This ﬁgure shows which thresholds
should be used according to the severity of an attack.
As the number of attackers increases, higher threshold
values perform better than lower threshold values who’s
user acceptance ratios plummet because many markings
are ﬂagged as attack packets.
Overall, these results are promising, particularly for
the n = 2 bit scheme. Pi ﬁltering provides signiﬁ-
cant differentiation between user and attack packets af-
ter only a three packet learning phase, even when thou-
sands of attack paths are used. Pi ﬁltering with thresh-
olds provides an adjustable mechanism to defend against
attacks of varying severity. Finally, the behavior of the
Pi scheme is consistent across both the Skitter and Inter-
net Map datasets, which shows that Pi’s performance is
not limited to a single Internet topology.
6.5 Legacy Routers
Any proposed packet marking scheme must be robust
to the presence of legacy routers. In Pi marking, legacy
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
9
1
0.8
0.6
0.4
0.2
o
i
t
a
R
e
c
n
a
t
p
e
c
c
A
t
e
k
c
a
P
0
0
2000