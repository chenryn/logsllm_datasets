• As each divided short audio frame (e.g., 20 ms) further
contains multiple sampling points (e.g., 320), the obtained
δ is a set of values indicating the perturbations to be added
to the amplitude of each frame’s sampling points in I.
• To solve Eqn. (4), we need to know the working particulars
of the target SR for computing the exact loss (i.e., a white-
box attack). After δ is resolved, the adversarial example
I + δ can be inherently achieved [17].
With the preliminary information above,
the next section
reports our empirical understanding of the acoustic channel,
followed by the Metamorph design.
III. DESIGN
A. Understanding Over-the-Air Audio Transmission
When an attacker initializes an audio adversarial attack,
the audio clip ﬁrst goes through the transmitter’s loudspeaker,
then enters the air channel, and ﬁnally arrives at the victim’s
microphone, as shown in Figure 2. Overall, the adversarial
audio clip is affected by three factors: device distortion,
channel effect, and ambient noise. To survive the adversarial
examples from the over-the-air transmission, we need to ﬁrst
carefully understand the effects of these three factors.
3
attenuationreflectionAttackerVictim noisehardware heterogeneityAttacker Victim Figure 3: (a) Experiment setup in the anechoic chamber. (b)
Device frequency-selectivity curves from four receivers.
1) Device Distortion: Both the attacker loudspeaker and
the victim microphone introduce frequency-selectivity1 to the
transmitted audio signal, which can distort the audio adver-
sarial example and undermine this attack after the over-the-air
transmission. To separate the device frequency-selectivity and
focus on its effect, we setup a loudspeaker-microphone pair
in an anechoic chamber (avoiding noise and multi-path), as
Figure 3(a) shows. In practice, the attack can be initiated on
attacker’s own device (loudspeaker), hence the loudspeaker can
be selected with small device frequency-selectivity to avoid
an explicit compensation of transmitter’s hardware distortion
and facilitate the attack. Thus in Figure 3(a), we use a high-
end speaker HiVi M200MKIII [5] that has a relatively ﬂat
frequency response over the audible frequency band, to mini-
mize the effect of the transmitter and focus on the receiver’s
(victim device) frequency-selectivity. The speaker transmits a
swept sine wave [21] to multiple receivers at 0.5 m, ranging
from 20Hz to 20kHz, and we cut it up to 8 kHz to analyze the
frequency selectivity (SR, e.g., DeepSpeech, uses this range).
Figure 4: Character success rate (CSR) for the adversarial
examples transmitted in the anechoic chamber and ofﬁce.
Result. We plot the frequency response curve of each receiver
in Figure 3(b). We observe that
these frequency response
curves exhibit a similar proﬁle in 0–8 KHz frequency band.
This is understandable since the microphone on smart de-
vices is typically optimized for human speech, hence their
frequency response should be similar to each other. However,
due to the hardware heterogeneity, each curve exhibits different
frequency-selectivity details. For example, we observe 6 dB
frequency selectivity on 2–4 kHz frequency band for iPhone
8, while only 3 dB for SAMSUNG S7 is on the same
frequency band. We further transmit the adversarial examples
generated by Carlini et al. [17] in the chamber and observe that
the device frequency-selectivity alone could fail this attack2,
1Frequency-selectivity refers to the non-uniform frequency response across
the frequency band [38], e.g., 0–8 kHz in the audible band.
2The attack proposed in [17] is outlined in Section II-B.
4
Figure 5: Tx-Rx pairs in ofﬁce, corridor and home.
e.g., character success rate (CSR) is low in Figure 4 (“0.5
m, chamber”), and incorrect characters always exist in each
recognized transcript from all the receivers.
However, as depicted in Figure 3(b), the device frequency-
selectivity overall is not extremely strong (some characters are
still correct in Figure 4) and these frequency-selectivity curves
share many similarities. Moreover, device frequency-selectivity
is hardware’s inherent feature, not related to the transmission
distance. So the device frequency selectivity in principle can
be measured and compensated. In fact, with a proper design
(§III-B), this device effect can be implicitly considered when
we deal with the acoustic channel, which also causes frequency
selectivity. Since the channel’s effect varies over distance, we
next examine the acoustic channel.
2) Channel Effect: The impact of acoustic channel on the
transmitted signal is mainly from the attenuation and the multi-
path two aspects.
Attenuation. Attenuation leads to a signal strength reduction.
It would not undermine the adversarial attack, because the SR
system usually normalizes the amplitude of the input audio in
the MFCC feature extraction [51]. In our experiment, we have
also validated that when we scale the amplitude of an audio
input I + δ , the same transcript can be always obtained from
the speech recognition system.
Multi-path. Multi-path is environment-dependent. It also in-
troduces frequency-selectivity to the received signal due to
the constructive and destructive interference [55], and may
potentially impact the adversarial attack.
To understand the impact of mult-path in acoustic channels,
we setup a transmitter-receiver pair (e.g., M200MKIII loud-
speaker sends the swept sine wave to the smart phone receiver)
in three typical indoor attacking scenarios: an ofﬁce, a corridor
and a home apartment, as shown in Figure 5. We ﬁrst look at
channel state information (CSI) in these three environments
and plot the result in Figure 6(a)–(b). CSI is the frequency
domain response, which can unveil the frequency-selectivity
directly. Ideally, CSI can be accurately obtained by FFT (y(t))
FFT (x(t)),
where x(t) and y(t) are the transmitted and received signal,
respectively. However, as the acoustic signal will go through
the hardware (loudspeaker and the microphone) during trans-
mission, the frequency selectivity from the CSI measurement
is the combined one from both channel and device.
From Figure 6(a), we observe a moderate frequency se-
lectivity in ofﬁce, corridor and home environments when the
receiver is in close proximity to the transmitter, e.g., 0.5 m.
These three CSI curves exhibit a similar frequency selectivity.
 TransmitterReceiver(a)Anechoic Materials HIVI M200MK3 SpeakerSAMSUNG S7RulerOver-the-air Channel(b) Corridor HIVI M200MK3 SpeakerRulerSAMSUNG S7Over-the-air Channel(a) Office(c) Home HIVI M200MK3 SpeakerSAMSUNG S7Over-the-air Channelair audio adversarial attack. For long links, the multi-path ef-
fect becomes more signiﬁcant and unpredictable (environment
dependent). For short links, the multi-path effect itself may
not be very strong, but the tightly glued device frequency-
selectivity still affects. Fortunately, the hardware’s distortion on
audio signal will not change over distance and shares similar
frequency selectivity features (§III-A). The key inspiration
to us is hence that within a reasonable distance (before the
channel frequency selectivity dominates and causes the overall
signal distortion to become highly unpredictable), if we have a
chance to capture the core impact of the overall distortion from
both channel and device, we can pre-code it in the adversarial
example generation.
Although deriving a theoretical model to describe the feasi-
ble attack distance is still open, in this paper, we demonstrate
that the attacker can leverage learning algorithms to launch
the over-the-air adversarial attack within a reasonably long
distance, e.g., 6 m, that can achieve both a high successful
rate (§III-B) and a good audio quality (§III-C).
3) Ambient Noise: We ﬁnally investigate the impact of the
ambient noise on the adversarial attack. We collect three types
of typical background noises: ambient human voice, back-
ground music, and engine noise. We then tune the volume of
these three background noises to different levels and synthesize
them with the adversarial example. To avoid the frequency
selectivity introduced by the device hardware and the acoustic
channel, we feed these synthesized adversarial examples to the
speech recognition system directly.
Result. We vary the signal-to-noise ratio (SNR) from 14 to
28 dB in Figure 8(a) and calculate the character success rate
(CSR) for these three types of synthesized adversarial attacks.
We observe that when the SNR is reasonably large (noise is
small), e.g., > 26 dB (such as playing an adversarial example
(76 dBSPL) in a normal human conversation (40-50 dBSPL)
environment), the CSRs are all close to one for these three
synthesized adversarial examples. This is reasonable since the
weak noises are easily overwhelmed by the voice commands.
In §IV, we also have a similar observation from the real-world
attack. CSR decreases slightly as we tune up the volume of
the noise (a lower SNR). In particular we ﬁnd CSR with the
human voice noise drops rapidly as we slightly decrease the
SNR from 26 dB to 22 dB.
To understand the reason behind, we further plot
the
frequency spectrum of these three kinds of noises in Fig-
ure 8(b). Compared with the engine and background noises,
the human voice shows more signiﬁcant frequency selectivity,
and thus should have a higher impact on the adversarial attack.
However, as the attacker can decide when to launch the attack,
the loud noise can be avoided. Therefore, we mainly focus on
the frequency-selectivity introduced by the hardware and the
acoustic channel in the Metamorph design.
B. Practical Audio Adversarial Examples
From the empirical study, our key insight is to cope with
the frequency-selectivity introduced by both the device and
channel. The device frequency-selectivity is more predictable,
while the channel’s impact varies over distance. However,
even within a reasonable attacking distance (when the chan-
nel frequency-selectivity is moderate), it is still unfeasible
Figure 6: Frequency spectrum (a–b) and their channel impulse
responses (c–d) measured over both short and long acoustic
links in three typical indoor environment. We do not measure
long link channel at home due to the space limit.
To better understand this result, we plot the channel impulse
response (CIR3) of these three channels in Figure 6(c). All
these three CIR curves exhibit a huge power gap between the
line of sight (LOS) path and reﬂection paths, indicating that the
LOS path dominates the signal transmission over such short
acoustic links. This unequal power distribution over different
paths renders the superposition of multi-path signals resemble
to the LOS signal, as shown in Figure 7(a). Accordingly, the
channel along would not cause signiﬁcant frequency selectivity
over such short links. The slight CSR declination in Figure 4
(“0.5m, ofﬁce”) also conﬁrms this.
Figure 7: Superposition of multi-path signals in (a) short and
(b) long acoustic link settings.
As we expand the link distance, e.g., 8 m,
the CSI
proﬁles (we skip the long link setting at home due to the
space limitation) exhibit a stronger and dissimilar frequency
selectivity in Figure 6(b). We further plot their CIRs and
observe a decreased power gap between the LOS path and
reﬂection paths (Figure 6(d)). This result indicates that signals
propagate among these paths, when adding together, would
cause signiﬁcant frequency selectivity due to the constructive
and destructive interference, as shown in Figure 7(b). We
further play the adversarial examples generated by [17] in
the long acoustic link settings (8 m) and observe that these
adversarial attacks never succeed in Figure 4 (“8m, ofﬁce”).
Observation. Above results reveal that the frequency selec-
tivity due to channel fundamentally challenges the over-the-
3CIR is similar to the concept of room impulse response (RIR) in the audio
signal processing domain [13]. Both describe signal’s time domain response.
5
LOS signalReflection signal 1Reflection signal 2Superimposed signalIQLOS signalReflection signal 1Reflection signal 2Superimposed signalIQFigure 8: (a) Character success rate (CSR) in different noise
levels. (b) Frequency responses of three typical noises.
to enumerate all possible frequency-selectivity curves in the
adversarial example generation. Therefore, in Metamorph, we
will conduct a small set of prior frequency-selectivity mea-
surements and further leverage learning algorithms to extract
the core impact from these measurements, so that we can
factor it into the adversarial example generation, achieved by
a “generate-and-clean” two-phase design.
• In phase one (§III-B1), we generate an initial δ that mines
and considers the major impact of frequency selectivity from
these measurements conducted in different environments
with different devices. Of course, it may also preserve some
measurement-dependent features (to minimize the optimiza-
tion loss), still limiting the attack performance.
• In phase two (§III-B2), we further leverage learning algo-
rithms to clean δ by compensating the common device-
speciﬁc feature and also minimizing the unpredictable envi-
ronment dependent feature from these frequency selectivity
measures to further improve the attack performance.
1) Generating Initial Examples: Motivated by Expectation
Over Transformation (EOT) method invented by vision-based
adversarial attack [15], we introduce the following three steps
to generate the initial audio adversarial examples.
Step 1. When we transmit
the swept sine wave and
receive it over the air, the derived channel impulse response
(CIR) includes the frequency-selectivity from both device
and channel. Therefore, we can collect multiple (M) such
measurements from M sender-receiver transmission pairs with
different distances in arbitrary environments. To simplify this
measurement process and include more device heterogeneity,
we can directly leverage some public acoustic CIR datasets. We
utilize four such datasets, including AIR [28], MARDY [53],
REVERB [32] and RWCP [37], and adopt M as 370 in
our current design (the description of these datasets and our
conﬁguration is in §IV).
Step 2. Next we train δ by minimizing the following
optimization, subjected to M constraints SR(Hi(I + δ )) = T(cid:48),
where i = 0, . . . ,M. Mathematically, δ can be obtained by
extending the formulation in Eqn. (4) to:
1
= argminδ α · dBI(δ ) +
M ∑i L(SR(Hi(I + δ )),T(cid:48)),
where dBI(δ ) is the sound quality distortion in dB and L(·) in
the second line of Eqn. (5) is the CTC loss [23] to quantify the
difference between the target transcript T(cid:48) and SR’s recognition
result by taking Hi(I + δ ) as input. In Eqn. (5), the hyper-
parameter α trades off the audio quality and attack success.
The upper part (dashed box) of Figure 9 illustrates this
audio adversarial example generation procedure. The original
argminδ α · dBI(δ ) + Lctc,
(5)
Figure 9: Illustration of initial adversarial example generator
and the domain discriminator, where Lg represents all the loss
factors except the loss Ld from domain discriminator.
audio clip I and the perturbation δ (which is the variable to
be optimized) are processed by the M measurements of Hi(·).
The resulting audios Hi(I + δ ) are then passed to the neural
network of our attacking target DeepSpeech. DeepSpeech will
ﬁrst extract the MFCC feature of each audio input Hi(I + δ ),
denoted as Fi, based on which its recurrent neural network
(RNN) can recognize the transcript Ti for the current input
Hi(I + δ ). As stated in Eqn. (5), the loss function here is the
CTC loss Lctc, which quantiﬁes the distance between the target
transcript T(cid:48) and Ti, and the optimization of δ aims to minimize
the overall CTC loss cross all M audio Hi(I +δ ) inputs. Note
that in this process, only δ will be trained and DeepSpeech
already has a ﬁxed neural network. We use it for the calculation
of the CTC loss merely.
Step 3. After step 2, the composed audio I + δ is not
only an adversarial example. The obtained δ already considers
the future impact from the frequency-selectivity due to the
transmission. We can then play I + δ over the air to fool the
receiver’s SR at the new locations.
Result. With the primary design above, the generated ad-
versarial example has pre-coded the impact from frequency-
selectivity, it can thus potentially fool SR after the transmis-
sion. Figure 10(a) shows an encouraging result. TSR measures
the success rate of the entire transcript and we can see that the
adversarial examples generated by this initial design now can
survive after short-range over-the-air transmissions, e.g., < 1m.
However, TSR rapidly drops when the distance increases.
This is because the received signal suffers from frequency
selectivity that varies over different channels, while the limited
CIR datasets used for training fail to cover all channel con-
ditions. To better understand the performance achieved by the
initial design, in Figure 10(b), we also plot the success rate
of the recognized characters in the target transcript. Result
shows that when TSR dramatically decreases as the distance
varies from 1 m to 2 m, the character success rate (CSR)
remains relatively high, e.g., 0.9. Even the distance is 4 m,
CSR is still above 0.5, which indicates that most characters
can survive from the over-the-air transmission. However, due
to the more severe frequency selectivity over longer distances,
more characters in T(cid:48) fail to be recognized.
6
Adversarial Example GeneratorPerturbationᵟ LSTM⊕ Audio ClipI RNN (freezed)FMFCCLogits  ConcatBack PropagationDomain DiscriminatorFC LayersFC LayersH( )DeepSpeechFigure 10: Performance of initial adversarial example gen-