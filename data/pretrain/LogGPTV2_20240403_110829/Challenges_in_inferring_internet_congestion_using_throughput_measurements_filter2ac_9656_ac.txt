### 1. Introduction

Network performance can vary significantly across different geographical regions, leading to diverse performance characteristics. Routing policies and the varying vantage points of clients can result in significant differences in the number of measurements traversing different interconnects. However, aggregating measurements that cross different IP links between the same pair of routers may be acceptable, as load balancing generally ensures an even distribution of flows across parallel links. This highlights the importance of inferring the set of IP or router-level links that comprise the AS-level aggregation. Once all IP links traversed by measurements from a server AS to a client AS are identified, it is possible to separate the NDT (Network Diagnostic Tool) tests according to the IP link traversed and evaluate whether different IP links comprising an AS-level aggregate show similar behavior.

Unfortunately, the complexity of router-level interconnections may render path information from Paris traceroute insufficient to accurately identify the inter-domain connection between two networks. The MAP-IT algorithm could fail or produce incorrect inferences. Therefore, dedicated tools such as bdrmap [26], running on the server-side infrastructure, are necessary to map interdomain borders. These tools can utilize additional measurements beyond traceroutes (e.g., alias resolution) and traceroutes in both directions associated with an NDT test to accurately pinpoint the interdomain link traversed by each NDT test.

### 2. Placement of Testing Servers

The primary objective of placing servers for throughput testing is to minimize latency to the client (§ 2). We propose two additional considerations for using these measurement infrastructures to infer congestion on interdomain links:
1. Paths from within the access ISP to the test servers should cover as many interconnections of the access AS as possible.
2. Measured paths should be representative of paths that normal, user-generated traffic from the clients traverse.

We estimate, for two throughput-measurement platforms—M-Lab and Ookla’s Speedtest.net—the set of interdomain interconnections of an access network that are covered, i.e., whether a test to any server from that platform run from a client in the access network would traverse a given interdomain link of that access network.

### 3. Methodology to Assess Coverage

#### 3.1 Measuring Interdomain Connectivity of Access ISPs

To measure the coverage of interdomain interconnections of access ISPs that the currently deployed server-side measurement infrastructure can provide, we first need to identify the set of interdomain interconnections of those access ISPs. For this purpose, we use vantage points inside access ISPs to launch comprehensive topology measurements outward toward the whole Internet.

CAIDA operates a large measurement infrastructure consisting of more than a hundred Archipelago (Ark) [11] vantage points, many of which are hosted by access networks of interest. For this study, we employed 16 Ark vantage points (VPs) located in 9 access ISPs in the U.S.: 5 in Comcast, 3 in Time Warner Cable, 2 in Cox, and one each in Verizon, CenturyLink, Sonic, RCN, Frontier, and AT&T. These vantage points are located in 8 of the top 10 broadband access providers in the U.S.; we have at least one VP in each of the top 5 providers. We focused on VPs in the U.S. for two reasons: M-Lab’s focus is predominantly U.S.-centric, and recent disputes about congestion at interdomain links of access ISPs focused on U.S.-based access networks, with reports released by M-Lab [27] focusing on U.S.-based networks.

To compile the set of interdomain interconnections of a given access network visible from an Ark VP in that network, we utilized bdrmap [26], an algorithm that accurately infers all interdomain interconnections of a VP network visible from that VP (validated to over 90% accuracy on ground truth data). In the collection phase, bdrmap issues traceroutes from the VP toward every routed BGP prefix and performs alias resolution on IP addresses seen from that VP in the traceroutes. We performed the data collection for bdrmap from our set of VPs in January and February 2017. In the analysis phase, we ran bdrmap using the collected topology data along with AS-relationship inferences from CAIDA’s AS-rank algorithm for January 2017 [12], and a list of address blocks belonging to IXPs obtained from PeeringDB [34] and PCH [32]. bdrmap outputs a set of interdomain interconnections for each VP, i.e., a set of border routers and neighboring networks, annotated with the type of routing relationship (customer, provider, peer, or unknown) between the VP network and the neighbor.

Table 3 shows, for each Ark monitor from which we ran bdrmap, the number of interdomain interconnections discovered at the AS and router level. We also classify the AS interconnections as customer, provider, or peer using the aforementioned AS-relationship data. The data reveals the interconnection diversity in this set of access providers; some access providers such as AT&T, Verizon, Comcast, and CenturyLink also operate large transit networks with thousands of customers and tens of peers. More importantly, the data highlights the scale of interdomain interconnection between large access networks. The largest access networks have hundreds of interdomain interconnections at the router-level. Even a relatively small provider such as RCN has 87 interconnections at the AS-level and 101 at the router-level.

#### 3.2 Measuring the Coverage of Interdomain Links

To ascertain the set of interdomain links that were covered using the M-Lab or Speedtest.net servers, we performed traceroutes from each Ark VP toward each of the M-Lab and Speedtest.net servers. We use the output of bdrmap to identify the interdomain link, if any (at both the router and AS-level) traversed by the traceroute. If the traceroute from a VP to a testing server S traverses a router-level interdomain link r corresponding to the AS-level link A, then we classify AS A and the router-level interconnection r with AS A as covered by the server S.

#### 3.3 Measuring the Paths to Popular Web Content

We also wanted to ascertain the intersection between the interconnections that are covered using either the M-Lab or Speedtest.net server infrastructure, and those on the paths toward popular web content from each access ISP. For each domain in the Alexa top 500 U.S. sites [3], we scraped the default page and extracted all subdomains. We performed DNS lookups of those domains at the Ark VPs and used the resulting IP addresses to perform traceroutes to the web servers. We then used the output of bdrmap to identify the interdomain links traversed by these traceroutes.

### 4. Results

Table 3 provides statistics from our border identification process. We ran bdrmap in January-February 2017 on a wide variety of networks in terms of size. While each of the measured networks provides broadband access, several networks such as AT&T, Verizon, CenturyLink, and Comcast also provide transit, which is reflected in the large number of AS customers. From the point of view of congestion measurement, the number of peers (and particularly the number of router-level peer interconnections) is important.

[Insert Table 3 here]

### 5. Conclusion

The methodology and results presented in this paper highlight the importance of accurately mapping interdomain links and the coverage provided by different measurement infrastructures. By using tools like bdrmap and comprehensive traceroute data, we can better understand the interdomain connectivity of access ISPs and the paths taken by both measurement and regular user traffic. This information is crucial for identifying and mitigating congestion in interdomain links.