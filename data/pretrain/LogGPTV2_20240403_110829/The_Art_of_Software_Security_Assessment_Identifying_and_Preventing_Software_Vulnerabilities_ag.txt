in through a main page but don't enforce authentication in follow-on pages. This lack 
of authentication means you could interact with the application without ever having to 
enter a username or password. In contrast, centralized authentication mitigates this 
issue by validating every Web request within the protected domain. 
Untrustworthy Credentials 
Another common mistake happens when some authentication information is 
presented to the software, but the information isn't trustworthy. This problem often 
happens when authentication is performed on the client side, and an attacker can 
completely control the client side of the connection. For example, the SunRPC 
framework includes the AUTH_UNIX authentication scheme, which basically amounts to 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
50 
fully trusting the client system. The client simply passes along a record that tells the 
server what the user and group IDs are, and the server just accepts them as fact. 
UNIX systems used to include a RPC daemon called rexd (remote execute daemon). 
The purpose of this program was to let a remote user run a program on the system as 
a local user. If you were to connect to the rexd system and tell the rexd program to 
run the /bin/sh command as the user bin, the program would run a shell as bin and 
let you interact with it. That's about all there was to it, with the exception that you 
couldn't run programs as the root user. Typically, getting around this restriction takes 
only a few minutes after you have a shell running as bin. More recently, a remote root 
flaw was exposed in the default installation of sadmind on Solaris; it treated the 
AUTH_UNIX authentication as sufficient validation for running commands on behalf of 
the client. 
Note 
The bug in sadmind is documented at www.securityfocus.com/bid/2354/info. 
Many network daemons use the source IP address of a network connection or packet 
to establish a peer's identity. By itself, this information isn't a sufficient credential and 
is susceptible to tampering. UDP can be trivially spoofed, and TCP connections can be 
spoofed or intercepted in various situations. UNIX provides multiple daemons that 
honor the concept of trusted hosts based on source address. These daemons are rshd 
and rlogind, and even sshd can be configured to honor these trust relationships. By 
initiating, spoofing, or hijacking a TCP connection from a trusted machine on a 
privileged port, an attacker can exploit the trust relationship between two machines. 
Insufficient Validation 
An authentication system can be close to sufficient for its environment but still 
contain a fundamental design flaw that leaves it exposed. This problem isn't likely to 
happen with the typical authentication design of requiring 
username/password/mom's maiden name, as it's easy to think through the 
consequences of design decisions in this type of system. 
You're more likely to see this kind of design flaw in programmatic authentication 
between two systems. If a program makes use of existing authentication mechanisms, 
such as certificates, design-level problems can arise. First, many distributed 
client/server applications authenticate in only one direction: by authenticating only 
the client or only the server. An attacker can often leverage this authentication 
scheme to masquerade as the unauthenticated peer and perform subtle attacks on 
the system. 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
51 
Homemade authentication with cryptographic primitives is another issue you might 
encounter. From a conceptual standpoint, making your own authentication seems 
simple. If you have a shared secret, you give the peer a challenge. The peer then 
sends back a value that could be derived only from a combination of the challenge and 
shared secret. If you're using public and private keys, you send a challenge to a peer, 
encrypting it with the peer's public key, and anticipate a response that proves the 
peer was able to decrypt it. 
However, there's plenty of room for error when creating authentication protocols 
from scratch. Thomas Lopatic found an amusing vulnerability in the FWN/1 protocol 
of Firewall-1. Each peer sends a random number R1 and a hash of that random 
number with a shared key, Hash(R1+K). The receiving peer can look at the random 
number that was sent, calculate the hash, and compare it with the transmitted value. 
The problem is that you can simply replay the R1 and Hash(R1+K) values to the 
server because they're made using the same shared symmetric key. 
Authorization 
Authorization is the process of determining whether a user on the system is 
permitted to perform a specific operation within a trust domain. It works in concert 
with authentication as part of an access control policy: Authentication establishes 
who a user is, and authorization determines what that user is permitted to do. There 
are many formal designs for access control systems, including discretionary access 
control, mandatory access control, and role-based access control. In addition, several 
technologies are available for centralizing access control into various frameworks, 
operating systems, and libraries. Because of the complexity of different access 
control schemes, it's best to begin by looking at authorization from a general 
perspective. 
Common Vulnerabilities of Authorization 
Web applications are notorious for missing or insufficient authorization. Often, you 
find that only a small fraction of a Web site's functionality does proper authorization 
checks. In these sites, pages with authorization logic are typically main menu pages 
and major subpages, but the actual handler pages omit authorization checks. 
Frequently, it's possible to find a way to log in as a relatively low-privileged user, and 
then be able to access information and perform actions that don't belong to your 
account or are intended for higher-privileged users. 
Authorities That Aren't Secure 
Omitting authorization checks is obviously a problem. You can also run into situations 
in which the logic for authorization checks is inconsistent or leaves room for abuse. 
For example, say you have a simple expense-tracking system, and each user in the 
company has an account. The system is preprogrammed with the corporate tree so 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
52 
that it knows which employees are managers and who they manage. The main logic 
is data driven and looks something like this: 
Enter New Expense 
for each employee you manage 
   View/Approve Expenses 
This system is fairly simple. Assuming that the initial corporate tree is populated 
correctly, managers can review and approve expenses of their subordinates. Normal 
employees see only the Enter New Expense menu entry because they aren't in the 
system as managing other employees. 
Now say that you constantly run into situations in which employees are officially 
managed by one person, but actually report to another manager for day-to-day 
issues. To address this problem, you make it possible for each user to designate 
another user as his or her "virtual" manager. A user's virtual manager is given view 
and approve rights to that user's expenses, just like the user's official manager. This 
solution might seem fine at first glance, but it's flawed. It creates a situation in which 
employees can assign any fellow employee as their virtual manager, including 
themselves. The resulting virtual manager could then approve expenses without any 
further restrictions. 
This simple system with an obvious problem might seem contrived, but it's derived 
from problems encountered in real-world applications. As the number of users and 
groups in an application grows and the complexity of the system grows, it becomes 
easy for designers to overlook the possibility of potential abuse in the authorization 
logic. 
Accountability 
Accountability refers to the expectation that a system can identify and log activities 
that users of the system perform. Nonrepudiation is a related term that's actually a 
subset of accountability. It refers to the guarantee that a system logs certain user 
actions so that users can't later deny having performed them. Accountability, along 
with authorization and authentication, establishes a complete access control policy. 
Unlike authentication and authorization, accountability doesn't specifically enforce a 
trust boundary or prevent a compromise from occurring. Instead, accountability 
provides data that can be essential in mitigating a successful compromise and 
performing forensic analysis. Unfortunately, accountability is one of the most 
overlooked portions of secure application design. 
Common Vulnerabilities of Accountability 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
53 
The most common accountability vulnerability is a system's failure to log operations 
on sensitive data. In fact, many applications provide no logging capability whatsoever. 
Of course, many applications don't handle sensitive data that requires logging. 
However, administrators or end usersnot developersshould determine whether 
logging is required. 
The next major concern for accountability is a system that doesn't adequately protect 
its log data. Of course, this concern might also be an authorization, confidentiality, or 
integrity issue. Regardless, any system maintaining a log needs to ensure the 
security of that log. For example, the following represents a simple text-based log, 
with each line including a timestamp followed by a log entry: 
20051018133106 Logon Failure: Bob 
20051018133720 Logon Success: Jim 
20051018135041 Logout: Jim 
What would happen if you included user-malleable strings in the log entry? What's to 
prevent a user from intentionally sending input that looks like a log entry? For 
instance, say a user supplied "Bob\n20051018133106 Logon Success: Greg" as a logon 
name. It looks like a harmless prank, but it could be used for malicious activity. 
Attackers could use fake entries to cover malicious activity or incriminate an innocent 
user. They might also be able to corrupt the log to the point that it becomes 
unreadable or unwriteable. This corruption could create a denial-of-service condition 
or open pathways to other vulnerabilities. It might even provide exploitable pathways 
in the logging system itself. 
Manipulating this log isn't the only problem. What happens when attackers can read 
it? At the very least, they would know at what times every user logged in and logged 
out. From this data, they could deduce login patterns or spot which users have a habit 
of forgetting their passwords. This information might seem harmless, but it can be 
useful in staging a larger attack. Therefore, unauthorized users shouldn't be able to 
read or modify the contents of a system log. 
Confidentiality 
Chapter 1(? [????.]) described confidentiality as the expectation that only authorized 
parties can view data. This requirement is typically addressed through access control 
mechanisms, which are covered by authentication and authorization. However, 
additional measures must be taken when communication is performed over a channel 
that's not secure. In these cases, encryption is often used to enforce confidentiality 
requirements. 
Encryption is the process of encoding information so that it can't be read by a third 
party without special knowledge, which includes the encryption process and usually 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
54 
some form of key data. Key data is a piece of data known only to the parties who are 
authorized to access the information. 
The topic of validating cryptographic algorithms and processes is not covered in this 
book because the mathematics involved are extremely complex and encompass an 
entire field of study. However, the knowledge you need to identify certain 
vulnerabilities in implementing and applying cryptography is covered throughout this 
book, including memory management issues in cryptographic message handling and 
how to validate specification requirements against an implementation. 
Your biggest concern from a design perspective is in determining if a particular 
cryptographic protocol is applied correctly. The protocol must be strong enough for 
the data it's protecting and must be used in a secure manner. If you're interested in 
more information on the appropriate use of cryptography, you can read Practical 
Cryptography (Wiley, 2003(? [????.])) by Bruce Schneier and Niels Ferguson. If your 
interest lies in algorithms and implementation, consider Bruce Schneier's other book, 
Applied Cryptography (Wiley, 1996). 
Encryption Algorithms 
Encryption has a long history, dating all the way back to ancient cultures. However, 
because you're concerned with modern cryptographic protocols that can be used to 
protect data communications effectively, this chapter focuses on two major classes of 
encryption: symmetric and asymmetric. 
Symmetric encryption (or shared key encryption) refers to algorithms in which 
all authorized parties share the same key. Symmetric algorithms are generally the 
simplest and most efficient encryption algorithms. Their major weakness is that they 
require multiple parties to have access to the same shared secret. The alternative is 
to generate and exchange a unique key for each communication relationship, but this 
solution quickly results in an untenable key management situation. Further, 
asymmetric encryption has no means for verifying the sender of a message among 
any group of shared key users. 
Asymmetric encryption (or public key encryption) refers to algorithms in which 
each party has a different set of keys for accessing the same encrypted data. This is 
done by using a public and private key pair for each party. Any parties wanting to 
communicate must exchange their public keys in advance. The message is then 
encrypted by combining the recipient's public key and the sender's private key. The 
resulting encrypted message can be decrypted only by using the recipient's private 
key. 
In this manner, asymmetric encryption simplifies key management, doesn't require 
exposing private keys, and implicitly verifies the sender of a message. However, 
these algorithms are more complex and tend to be computationally intensive. 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
55 
Therefore, asymmetric algorithms are typically used to exchange a symmetric key 
that's then used for the duration of a communication session. 
Block Ciphers 
Block ciphers are symmetric encryption algorithms that work on fixed-size blocks of 
data and operate in a number of modes. You should be aware of some considerations 
for their use, however. One consideration is whether the block cipher encrypts each 
block independently or uses output from the previous block in encrypting the current 
block. Ciphers that encrypt blocks independently are far more vulnerable to 
cryptanalytic attacks and should be avoided whenever possible. Therefore, a cipher 
block chaining (CBC) mode cipher is the only appropriate fixed-block cipher in 
general use. It performs an XOR operation with the previous block of data, resulting 
in negligible performance overhead and much higher security than modes that handle 
blocks independently. 
Stream Ciphers 
One of the most inconvenient aspects of block ciphers is that they must handle 
fixed-size chunks of data. Any data chunks larger than the block size must be 
fragmented, and anything smaller must be padded. This requirement can add 
complexity and overhead to code that handles something like a standard TCP socket. 
Fortunately, block ciphers can run in modes that allow them to operate on arbitrarily 
sized chunks of data. In this mode, the block cipher performs as a stream cipher. 
The counter (CTR) mode cipher is the best choice for a stream cipher. Its 
performance characteristics are comparable to CBC mode, but it doesn't require 
padding or fragmentation. 
Initialization Vectors 
An initialization vector (IV) is a "dummy" block of data used to start a block cipher. 
An IV is necessary to force the cipher to produce a unique stream of output, 
regardless of identical input. The IV doesn't need to be kept private, although it must 
be different for every new cipher initialization with the same key. Reusing an IV 
causes information leakage with a CBC cipher in only a limited number of scenarios; 
however, it severely degrades the security of other block ciphers. As a general rule, IV 
reuse should be considered a security vulnerability. 
Key Exchange Algorithms 
Key exchange protocols can get complicated, so this section just provides some 
simple points to keep in mind. First, the implementation should use a standard key 
exchange protocol, such as RSA, Diffie-Hellman, or El Gamal. These algorithms have 
been extensively validated and provide the best degree of assurance. 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
56 
The next concern is that the key exchange is performed in a secure manner, which 
means both sides of the communication must provide some means of identification to 
prevent man-in-the-middle attacks. All the key exchange algorithms mentioned 
previously provide associated signature algorithms that can be used to validate both 
sides of the connection. These algorithms require that both parties have already 
exchanged public keys or that they are available through some trusted source, such 
as a Public Key Infrastructure (PKI) server. 
Common Vulnerabilities of Encryption 
Now that you have some background on the proper use of encryption, it's important 
to understand what can go wrong. Homemade encryption is one of the primary 
causes of confidentiality-related vulnerabilities. Encryption is extremely complicated 
and requires extensive knowledge and testing to design and implement properly. 
Therefore, most developers should restrict themselves to known algorithms, 
protocols, and implementations that have undergone extensive review and testing. 
Storing Sensitive Data Unnecessarily 
Often a design maintains sensitive data without any real cause, typically because of a 
misunderstanding of the system requirements. For instance, validating a password 
doesn't require storing the password in a retrievable form. You can safely store a hash 
of the password and use it for comparison. If it's done correctly, this method prevents 
the real password from being exposed. (Don't worry if you aren't familiar with hashes; 
they are introduced in "Hash Functions" later in this chapter.) 
Clear-text passwords are one of the most typical cases of storing data unnecessarily, 
but they are far from the only example of this problem. Some application designs fail 
to classify sensitive information properly or just store it for no understandable reason. 
The real issue is that any design needs to classify the sensitivity of its data correctly 
and store sensitive data only when absolutely required. 
Lack of Necessary Encryption 
Generally, a system doesn't provide adequate confidentiality if it's designed to 
transfer clear-text information across publicly accessible storage, networks, or 
unprotected shared memory segments. For example, using TELNET to exchange 
sensitive information would almost certainly be a confidentiality-related design 
vulnerability because TELNET does not encrypt its communication channel. 
In general, any communication with the possibility of containing sensitive information 
should be encrypted when it travels over potentially compromised or public networks. 
When appropriate, sensitive information should be encrypted as it's stored in a 
database or on disk. Encryption requires a key management solution of some sort, 
which can often be tied to a user-supplied secret, such as a password. In some 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
57 
situations, especially when storing passwords, hashed values of sensitive data can be 
stored in place of the actual sensitive data. 
Insufficient or Obsolete Encryption 
It's certainly possible to use encryption that by design isn't strong enough to provide 
the required level of data security. For example, 56-bit single Digital Encryption 
Standard (DES) encryption is probably a bad choice in the current era of inexpensive 
multigigahertz computers. Keep in mind that attackers can record encrypted data, 
and if the data is valuable enough, they can wait it out while computing power 
advances. Eventually, they will be able to pick up a 128 q-bit quantum computer at 
Radio Shack, and your data will be theirs (assuming that scientists cure the aging 
problem by 2030, and everyone lives forever). 
Jokes aside, it's important to remember that encryption implementations do age over 
time. Computers get faster, and mathematicians find devious new holes in algorithms 
just as code auditors do in software. Always take note of algorithms and key sizes that 
are inadequate for the data they protect. Of course, this concern is a moving target, 
so the best you can do is keep abreast of the current recommended standards. 
Organizations such as the National Institute for Standards and Technology (NIST; 
www.nist.gov) do a good job of publishing generally accepted criteria for algorithms 
and key sizes. 
Data Obfuscation Versus Data Encryption 
Some applicationsand even industry-wide security standardsdon't seem to 
differentiate between data obfuscation and data encryption. Put simply, data is 
obfuscated when attackers have access to all the information they need to recover 
encoded sensitive data. This situation typically occurs when the method of encoding 
data doesn't incorporate a unique key, or the key is stored in the same trust domain 
as the data. Two common examples of encoding methods that don't incorporate a 
unique key are ROT13 text encoding and simple XOR mechanisms. 
The problem of keys stored in the same context as data is a bit more confusing but not 
necessarily less common. For example, many payment-processing applications store 
sensitive account holder information encrypted in their databases, but all the 
processing applications need the keys. This requirement means that stealing the 
backup media might not give attackers the account data, but compromising any 
payment server can get them the key along with the encrypted data. Of course, you 
could add another key to protect the first key, but all the processing applications 
would still require access. You could layer as many keys as you like, but in the end, it's 
just an obfuscation technique because each processing application needs to decrypt 
the sensitive data. 
Note 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
58 
The PCI (Payment Card Industry) 1.0 Data Security Requirement is part of an 
industry-wide standard to help ensure safe handling of payment card data and 
transactions. These requirements are a forward-thinking move for the industry, and 
many of them are consistent with best security practices. However, the standard 
contains requirements that create exactly the confidentiality issue described in this 