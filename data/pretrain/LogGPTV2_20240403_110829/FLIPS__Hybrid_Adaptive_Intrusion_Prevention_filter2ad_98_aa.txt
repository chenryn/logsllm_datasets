title:FLIPS: Hybrid Adaptive Intrusion Prevention
author:Michael E. Locasto and
Ke Wang and
Angelos D. Keromytis and
Salvatore J. Stolfo
FLIPS: Hybrid Adaptive Intrusion Prevention
Michael E. Locasto, Ke Wang, Angelos D. Keromytis, and Salvatore J. Stolfo
Department of Computer Science, Columbia University,
1214 Amsterdam Avenue, Mailcode 0401,
New York, NY 10027
{locasto, kewang, angelos, sal}@cs.columbia.edu
+1 212 939 7177
Abstract. Intrusion detection systems are fundamentally passive and
fail–open. Because their primary task is classiﬁcation, they do noth-
ing to prevent an attack from succeeding. An intrusion prevention sys-
tem (IPS) adds protection mechanisms that provide fail–safe semantics,
automatic response capabilities, and adaptive enforcement. We present
FLIPS (Feedback Learning IPS), a hybrid approach to host security that
prevents binary code injection attacks. It incorporates three major com-
ponents: an anomaly-based classiﬁer, a signature-based ﬁltering scheme,
and a supervision framework that employs Instruction Set Randomiza-
tion (ISR). Since ISR prevents code injection attacks and can also pre-
cisely identify the injected code, we can tune the classiﬁer and the ﬁlter
via a learning mechanism based on this feedback. Capturing the injected
code allows FLIPS to construct signatures for zero-day exploits. The
ﬁlter can discard input that is anomalous or matches known malicious
input, eﬀectively protecting the application from additional instances of
an attack – even zero-day attacks or attacks that are metamorphic in
nature. FLIPS does not require a known user base and can be deployed
transparently to clients and with minimal impact on servers. We describe
a prototype that protects HTTP servers, but FLIPS can be applied to a
variety of server and client applications.
Keywords: Adaptive Response,
Tolerance.
Intrusion Prevention,
Intrusion
1 Introduction
One key problem for network defense systems is the inability to automatically
mount a reliable, targeted, and adaptive response [21]. This problem is magniﬁed
when exploits are delivered via previously unseen inputs. Network defense sys-
tems are usually composed of network-based IDS’s and packet ﬁltering ﬁrewalls.
These systems have shortcomings that make it diﬃcult for them to identify and
characterize new attacks and respond intelligently to them.
Since IDS’s passively classify information, they can enable but not enact a
response. Both signature-based and anomaly-based approaches to classiﬁcation
merely warn that an attack may have occurred. Attack prevention is a task often
A. Valdes and D. Zamboni (Eds.): RAID 2005, LNCS 3858, pp. 82–101, 2006.
c(cid:1) Springer-Verlag Berlin Heidelberg 2006
FLIPS: Hybrid Adaptive Intrusion Prevention
83
left to a ﬁrewall, and it is usually accomplished by string matching signatures of
known malicious content or dropping packets according to site policy. Of course,
successfully blocking the correct traﬃc requires a ﬂexible and well deﬁned policy.
Furthermore, signature matching large amounts of network traﬃc often requires
specialized hardware and presumes the existence of accurate signatures. In addi-
tion, encrypted and tunneled network traﬃc poses problems for both ﬁrewalls and
IDS’s. To compound these problems, since neither IDS’s or ﬁrewalls know for sure
how a packet is processed at an end host, they may make an incorrect decision [10].
These obstacles motivate the argument for placing protection mechanisms
closer to the end host (e.g., distributed ﬁrewalls [11]). This approach to system
security can beneﬁt not only enterprise-level networks, but home users as well.
The principle of “defense-in-depth” suggests that traditional perimeter defenses
like ﬁrewalls be augmented with host-based protection mechanisms. This pa-
per advocates one such system that employs a hybrid anomaly and signature
detection scheme to adaptively react to new exploits.
1.1 Hybrid Detection
In general, detection systems that rely solely on signatures cannot enable a de-
fense against previously unseen attacks. On the other hand, anomaly-based clas-
siﬁers can recognize new behavior, but are often unable to distinguish between
previously unseen “good” behavior and previously unseen “bad” behavior. This
blind spot usually results in a high false positive rate and requires that these
classiﬁers be extensively trained.
A hybrid approach to detection can provide the basis for an Intrusion Preven-
tion System (IPS): an automated response system capable of stopping an attack
from succeeding. The core of our hybrid system is an anomaly-based classiﬁer
that incorporates feedback to both tune its models and automatically gener-
ate signatures of known malicious behavior. Our anomaly detector is based on
PayL [38], but other classiﬁers can be used [17].
The biggest obstacle for a hybrid system is the source of the feedback informa-
tion. Ideally, it should be automated and transparent to users. For example, the
feedback to email spam classiﬁers may be a user hitting a button in their email
client that notiﬁes the mail server to reconsider an inappropriately classiﬁed
email as spam. This feedback loop is an example of supervised online learning
and distributes the burden of supervision to users of the system. The feedback
mechanism in our system facilitates unsupervised online learning. The source
of information is based on an x86 emulator, STEM [29], that is augmented to
protect processes with Instruction Set Randomization.
1.2 Instruction Set Randomization
ISR is the process of creating a unique execution environment to eﬀectively
negate the success of code-injection attacks. This unique environment is created
by performing some reversible transformation on the instruction set; the trans-
formation is driven by a random key for each executable. The binary is then
decoded during runtime with the appropriate key.
84
M.E. Locasto et al.
Since an attacker crafts an exploit to match some expected execution environ-
ment (e.g. x86 machine instructions) and the attacker cannot easily reproduce
the transformation for his exploit code, the injected exploit code will most likely
be invalid for the specialized execution environment. The mismatch between the
language of the exploit code and the language of the execution environment
causes the exploit to fail. Without knowledge of the key, otherwise valid (from
the attacker’s point of view) machine instructions resolve to invalid opcodes or
eventually crash the program by accessing illegal memory addresses. Previous
approaches to ISR [3] [12] have proved successful in defeating code injection at-
tacks. Such techniques are typically combined with address-space obfuscation [4]
to prevent “jump into libc” attacks.
Randomizing an instruction set requires that the execution environment pos-
sess the ability to de-randomize or decode the binary instruction stream during
runtime. For machine code, this requirement means that either the processor
hardware must contain the decoding logic or that the processor be emulated in
software. STEM minimizes the cost of executing in software by selectively em-
ulating parts of an application. During the application’s runtime, control can
freely switch between the real and the virtual processors. By carefully selecting
the pieces of the application that are emulated, it is possible to minimize the
runtime overhead of the emulation.
This practical form of ISR allows us to capture injected code and correlate it
with input that has been classiﬁed as anomalous. Barrantes et al. [3] show that
code injection attacks against protected binaries fail within a few bytes (two or
three instructions) of control ﬂow switching to the injected code. Therefore, the
code pointed to by the instruction pointer at the time the program halts is (with
a high probability) malicious code. We can extract this code and send it to our
ﬁlter to create a new signature and update our classiﬁer’s model.
1.3 Contributions
The main contribution of this paper is a complete system that uses information
conﬁrming an attack to assist a classiﬁer and update a signature-based ﬁlter.
Filtering strategies are rarely based solely on anomaly detection; anomaly-based
classiﬁers usually have a high false positive rate. However, when combined with
feedback information conﬁrming an attack, the initial classiﬁcation provided by
the anomaly detector can assist in creating a signature. This signature can then
be deployed to the ﬁlter to block further malicious input. It is important to
note that our protection mechanism catches the exploit code itself. Having the
exploit code allows very precise signature creation and tuning of the classiﬁer.
Furthermore, this signature can be exchanged with other instances of this system
via a centralized trusted third party or a peer-to-peer network. Such information
exchange [7], [14] can potentially inoculate the network against a zero-day worm
attack [1], [13], [18], [35].
We present the design of FLIPS, a host-based application-level ﬁrewall that
adapts to new malicious input. Our prototype implementation adjusts its
FLIPS: Hybrid Adaptive Intrusion Prevention
85
ﬁltering capability based on feedback from two sources: (a) an anomaly-based
classiﬁer [38] that is specialized to the content ﬂows for a speciﬁc host and (b) a
binary supervision framework [29] that prevents code-injection attacks via ISR
and captures injected code. The details of our design are presented in Section 3,
and we describe the prototype implementation of the system for an HTTP server
in Section 4. We discuss related work in Section 2, our experimental validation
of FLIPS in Section 5, directions for future research in Section 6, and conclude
the paper in Section 7.
2 Related Work
Augmenting detection systems with an adaptive response mechanism is an emerg-
ing area of research. Intrusion prevention, the design and selection of mechanisms
to automatically respond to network attacks, has recently received an amount
of attention that rivals its equally diﬃcult sibling intrusion detection. Response
systems vary from the low–tech (manually shut down misbehaving machines)
to the highly ambitious (on the ﬂy “vaccination”, validation, and replacement
of infected software). In the middle lies a wide variety of practical techniques,
promising technology, and nascent research.
The system proposed by Anagnostakis et al. [2] has many of the same goals
as FLIPS. However, there are a number of diﬀerences in architecture and imple-
mentation. Most importantly, our use of ISR allows FLIPS to detect and stop all
instances of code injection attacks, not just stack-based buﬀer overﬂows. Also,
FLIPS is meant to protect a single host without the need for a “shadow.”
Two other closely related systems are the network worm vaccine architecture
[28] and the HACQIT system [25]. More recently, researchers have investigated
transparently detecting malicious email attachments [27] with techniques similar
to ours and [28]. HACQIT employs a pair of servers in which the outputs of the
primary and secondary server are compared. If the outputs are diﬀerent, then a
failure has occurred. The HACQIT system then attempts to classify the input
that caused this error and generalize a rule for blocking it. The network and
email worm vaccine architectures propose the use of honeypot and auxiliary
servers, respectively, to provide supervised environments where malware can
infect instrumented instances of an application. The system can then construct
a ﬁx based on the observed infection vector and deploy the ﬁx to the production
server. In the case of the email worm vaccine, the email can be silently dropped,
stripped of the attachment, or rejected.
In contrast, FLIPS is meant to protect a single host without the need for
additional infrastructure. Since the system is modular, it is an implementation
choice whether or not to distribute the components across multiple machines.
FLIPS also precisely identiﬁes attack code by employing ISR. It does not need to
correlate input strings against other services or try to deduce where attack code
is placed inside a particular input request. In addition, our anomaly detection
component can construct models of both good and “bad” inputs to detect and
block slight variants of malicious input.
86
M.E. Locasto et al.
2.1 Code Injection and ISR
One of the major contributions of this work is the use of a practical form of ISR.
The basic premise of ISR [3] [12] is to prevent code injection attacks [23] from
succeeding by creating unique execution environments for individual processes.
Code injection is not limited to overﬂowing stack buﬀers or format strings. Other
injection vectors include web forms that allow arbitrary SQL expressions (a
solution to this problem using SQL randomization is proposed in [5]), CGI scripts
that invoke shell programs based on user input, and log ﬁles containing character
sequences capable of corrupting the terminal display.
Our x86 emulator STEM can selectively derandomize portions of an instruc-
tion stream, eﬀectively supporting two diﬀerent instruction sets at the same time.
Various processors support the ability to emulate or execute other instruction
sets. These abilities could conceivably be leveraged to provide hardware support
for ISR. For example, the Transmeta Crusoe chip1 employs a software layer for
interpreting code into its native instruction format. The PowerPC chip employs
“Mixed-Mode” execution2 for supporting the Motorola 68k instruction set. Like-
wise, the ARM chip can switch freely between executing its regular instruction
set and executing the Thumb instruction set. A processor that supports ISR
could use a similar capability to switch between executing regular machine in-
structions and randomized machine instructions. In fact, this is almost exactly
what STEM does in software. Having hardware support for ISR would obviate
the need for (along with the performance impact of) software-level ISR.
2.2 Anomaly Detection and Remediation
Anomaly-based classiﬁcation is a powerful method of detecting inputs that are
probably malicious. This conclusion is based on the assumption that malicious
inputs are rare in the normal operation of the system. However, since a sys-
tem can evolve over time, it is also likely that new non-malicious inputs will
be seen [9] [32]. Indeed, some work [16] has shown that it is possible to evade
anomaly-based classiﬁers. Therefore, anomaly-based detectors [38] [17] require
an additional source of information that can conﬁrm or reject the initial classiﬁ-
cation. Pietraszek [22] presents a method that uses supervised machine learning
to tune an alert classiﬁcation system based on observations of a human expert.
Sommer and Paxon [33] explore a related problem: how to augment signature-
based NIDS to make use of context when applying signatures.
FLIPS receives feedback from an emulator that monitors the execution of a
vulnerable application. If the emulator tries to execute injected code, it catches
the fault and notiﬁes the classiﬁer and ﬁlter. It can then terminate and restart
the process, or simulate an error return from the current function. While our
prototype system employs ISR, there are many other types of program super-
vision that can provide useful information. Each could be employed in parallel to
1
2
http://www.transmeta.com/crusoe/codemorphing.html
http://developer.apple.com/documentation/mac/runtimehtml/RTArch-75.html
FLIPS: Hybrid Adaptive Intrusion Prevention
87
gather as much information as possible. These approaches include input taint
tracking [36] [20], program shepherding [15], (a similar technique is proposed
in [24]) and compiler-inserted checks [31]. One advantage of FLIPS’s feedback
mechanism is that it can identify with high conﬁdence the binary code of the
attack. In an interesting approach to detection, Toth and Kruegel [37] and Stig
et al. [34]) consider the problem of ﬁnding x86 code in network packets.
Eﬀective remediation strategies remain a challenge. The typical response of
protection mechanisms has traditionally been to terminate the attacked pro-
cess. This approach is unappealing for a variety of reasons; to wit, the loss of
accumlated state is an overarching concern. Several other approaches are pos-
sible, including failure oblivious computing [26], STEM’s error virtualization
[29], DIRA’s rollback of memory updates [31], crash-only software [6], and data
structure repair [8]. Remediation strategies sometimes include the deployment
of ﬁrewall rules that block malicious input. The most common form of this strat-
egy is based on dropping packets from “malicious” hosts. Even with whitelists
to counter spooﬁng, this strategy is too coarse a mechanism. Our system allows
for the generation of very precise signatures because the actual exploit code can
be caught “in the act.”
Automatically creating reliable signatures of zero-day exploits is the focus of
intense research eﬀorts [13]. Signatures of viruses and other malware are cur-
rently produced by manual inspection of the malware source code. Involving
humans in the response loop dramatically lengthens response time and does
nothing to stop the initial infection. In addition, deployed signatures and IDS
rules do nothing to guard against new threats. Singh et al. describe the Early-
bird system for automatically generating worm signatures and provide a good
overview of the shortcomings of current approaches to signature generation [30].
3 FLIPS – A Learning Application Filter
While we describe our implementation of FLIPS in Section 4, this section pro-
vides an overview of the design space for a host-based intrusion prevention sys-
tem. The system is composed of a number of modules that provide ﬁltering,
classiﬁcation, supervision, and remediation services. We can use the metrics pro-