mance characteristics of generated paths and compare
them to their expected values.
7.2.1 Simulation-based Evaluation
Figure 2 shows the cumulative distribution of end-to-end
(e2e) latencies using our A3 implementation in simu-
lation mode with the WEIGHTED relay selection pol-
icy [36]. The x-axis of the graph plots the achieved
e2e latency, while the y-axis indicates the fraction of
paths that has at most that latency. As input to the trace-
driven simulator, we utilize the King dataset [17], a col-
lection of pairwise latencies collected from the Inter-
net using the King method [14]. As can be seen from
Figure 4. Achieved performance as mea-
sured by e2e RTT under simulation using
the King dataset with the CONSTRAINT relay
selection policy.
the ﬁgure, WEIGHTED reduces the e2e RTT of anony-
mous paths when compared to RANDOM. For exam-
ple, the median RTT of anonymous paths decreases 30%
from 261ms to 184ms when WEIGHTED is used. Sim-
ilarly, Figure 3 shows the achieved performance, mea-
sured as the e2e bandwidth of anonymous paths, using
various node-based relay selection policies. Paths were
constructed using bandwidth information retrieved from
Tor directory servers. As expected, the Tor routing pol-
icy produces paths with signiﬁcantly greater bandwidths
than random selection. The Snader-Borisov algorithm
achieves tunable performance results – as the value of
s increases, the effective e2e bandwidth of anonymous
paths also increases.
The performance of the anonymous paths shown in
Figures 2 and 3 can be validated by comparing against
results from previous studies [36] in which the relay
selection algorithms were hardcoded. Using A3, how-
ever, policies are concisely represented in a few lines of
A3LOG, and are provided to the Relay Selection Engine
during runtime.
Our novel CONSTRAINT algorithm allows applica-
tions to specify hard constraints on their anonymous
paths. The performance results for various e2e latency
constraints is shown in Figure 4. The graph plots the
percentage of anonymous paths whose e2e latency met
the constraint for both the CONSTRAINT and RANDOM
relay selection policies. The results from the uniform
selection policy serve as an approximation for the per-
centage of possible paths that meet the constraint, and
 0 20 40 60 80 100 150 200 250 300 350 400Percentage of paths meeting constraintConstraint: e2e RTT (ms)% of constraint paths% of random pathsFigure 2. Achieved performance as mea-
sured by e2e RTT under simulation using
the King dataset with the WEIGHTED relay
selection policy.
Figure 3. Achieved performance (log scale)
as measured by e2e bandwidth under sim-
ulation using bandwidths from the Tor di-
rectory server for various node-based relay
selection policies.
Figure 5. Node prevalences for latency
datasets
Figure 6. Node prevalences for band-
width datasets (log scale).
therefore indicate the difﬁculty of ﬁnding conforming
paths. Failure to meet the requirements speciﬁed by the
CONSTRAINT strategy are due to embedding errors in
the Vivaldi virtual coordinate system. That is, under-
estimations of network distances occasionally cause the
Relay Selection Engine to incorrectly believe that a non-
conforming path met the requirements of the policy.
When the constraint is lax and permits paths with e2e
latencies of up to 350ms, 74% and 94% of the paths gen-
erated using uniform and CONSTRAINT, respectively,
adhere to the requirement. Even for very stringent re-
quirements – e2e latencies of 150ms or less – 83% of
paths produced for the CONSTRAINT policy met the re-
quirement. In contrast, less than 9% of random paths
had latencies below the threshold.
In addition to enabling ﬂexible routing, A3 also
serves as a tool for protocol designers to empirically
measure some of the security characteristics of their al-
gorithms. New protocols may be quickly encoded in
A3LOG and tested on A3. The security of a given al-
 0 0.2 0.4 0.6 0.8 1 0 100 200 300 400 500 600 700 800Cumulative Fractione2e RTT (ms)RandomWeighted (s=3)Weighted (s=15) 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 16 32 64 128 256 512 1024Cumulative FractionBandwidth (KBps)RandomTorSnader-Borisov (s=3)Snader-Borisov (s=9)Snader-Borisov (s=15) 0 0.01 0.02 0.03 0.04 0.05 0.06Random Constraint (<400ms) Constraint (<350ms) Constraint (<300ms) Constraint (<250ms) Constraint (<200ms) Constraint (<150ms)Weighted (s=3)Weighted (s=9)Weighted (s=15)Range of Node Prevalences 0.0001 0.001 0.01 0.1 1RandomTorSnader-Borisov (s=3)Snader-Borisov (s=9)Snader-Borisov (s-15)Range of Node Prevalencesgorithm may be partly assessed by examining the dis-
tribution of relays’ node prevalences – the percentage
of anonymous paths for which a given relay is a par-
ticipant [36]. Comparing the node prevalences for var-
ious routing policies while keeping the network consis-
tent provides a straightforward means of determining
whether any particular relay is selected disproportion-
ately during relay selection. Figures 5 and 6 plot the
range of node prevalences for the previously described
relay policies under simulation. Of particular interest is
the maximum node prevalence – the percentage of paths
that include the most popular chosen relay. As demon-
strated in prior work [36], the node prevalences resulting
from link-based path selection (left) tend to be signiﬁ-
cantly lower than that of node-based selection.
7.2.2 PlanetLab Deployment
To evaluate the system’s performance on real-world net-
works, we installed A3 on approximately 110 geograph-
ically distributed hosts on the PlanetLab testbed.
PlanetLab Performance. Figure 7 shows the e2e path
performance results on PlanetLab for the RANDOM,
WEIGHTED, and CONSTRAINT strategies. Due to insta-
bility in the PlanetLab network, paths were abandoned
after a two second timeout, leading to a maximum RTT
of 2s. WEIGHTED (with s = 9) reduced the median
RTT of paths by 194ms (38%) as compared to random
selection. 69% of paths met the fairly stringent 400ms
requirement using the CONSTRAINT policy. By com-
parison, only 26% of random paths had e2e RTTs of less
than 400ms.
Information Provider Polling Frequency
In order to
produce paths that adhere to application policies, the
Routing Engine must rely on the data stored in the Local
Directory Cache. If the data is stale, then routing deci-
sions will be based on outdated information. However,
frequent polling of the Information Providers consumes
bandwidth both at relay nodes (whose resources may al-
ready be overburdened from forwarding trafﬁc) and at
the Providers. The rate at which information should be
refreshed is highly dependent upon the particular metric.
For example, bandwidth capacities may be fairly static,
whereas bandwidth utilization varies signiﬁcantly over
time.
To understand this tradeoff for our Network Coor-
dinate Information Provider, we examined the rate at
which coordinates changed under high degrees of churn.
Figure 8 (log scale on both axes) plots the rate of change
(as measured by the distance between successive coor-
dinate updates) on PlanetLab. Since relays operate in-
dependently and conduct coordinate updates at varying
times, results are grouped at one minute intervals, with
the 10th, 50th (median), and 90th percentiles plotted on
the graph. Initially, 90% of all relays join the network
at approximately the same time, resulting in substantial
coordinate movement early in the experiment. However,
the system quickly stabilizes– the median rate of change
decreases to less than 10ms within 10 minutes. Hence,
even in the near worst-case scenario in which all partic-
ipants join the network at once, the coordinate system
reaches equilibrium within approximately 10 minutes.
To model a more realistic scenario, the remaining
10% of PlanetLab nodes join the network after approx-
imately 30 minutes (indicated by arrows on the graph).
Immediately following the introduction of the new par-
ticipants, the median difference between coordinate up-
dates experiences a minor jump, but remains below 3ms.
Our results indicate that latency is fairly stable (at
least on PlanetLab), requiring infrequent coordinate up-
dates. Even when members of a large coalition of relays
join the network simultaneously, the effect on coordinate
stability is minor.
Processing Costs The Relay Selection Engine parses
and interprets A3LOG policies and uses the information
stored in the Local Directory Cache to generate con-
forming paths. The engine is implemented in C++ as an
extension to the P2 declarative networking system [19].
We observe in our simulations and PlanetLab exper-
iments that the time required to parse A3LOG scripts
(which occurs only when such scripts are loaded) and
produce paths is minimal. For example, when running
on PlanetLab with a heavy network load, the Relay Se-
lection Engine requires on average less than 200ms to
produce a path using the CONSTRAINT policy with mul-
tiple constraints.
7.3 Path Instantiation
Above, our evaluation validated the ﬂexibility of
A3LOG for supporting a wide range of relay selection
policies with low performance overhead. Next, we
benchmark the performance of declarative onion path
instantiation. As described in Section 6, the A3LOG im-
plementation of this protocol requires the use of secure
communication, as well as symmetric-key cryptographic
primitives and onion assembly. To isolate the effects of
CPU and communication overhead, we conducted our
evaluation in a local cluster in addition to the PlanetLab
testbed.
Figure 7. Achieved performance as mea-
sured by e2e RTT on PlanetLab.
Figure 8. Median, 10th, and 90th percentile
distances between coordinate updates on
PlanetLab (log scale).
Initially, 90% of all
relays join the network at approximately
the same time. Arrows indicate the point
at which the remaining relays join.
Path Length
Local Cluster
PlanetLab
2
3
4
5
102
146
192
244
1059 (853, 1459)
1342 (1120, 2862)
2202 (1311, 3402)
2215 (1602, 2564)
Table 2. Median Onion Routing path instan-
tiation time (in milliseconds) on our local
cluster and on PlanetLab. The values in
parentheses shows the 20th and 80th per-
centile times on PlanetLab.
Our local cluster consists of quad-core machines with
Intel Xeon 2.4GHz CPUs and 4GB RAM running Fe-
dora 10 with kernel version 2.6, which are intercon-
nected by Gigabit Ethernet. This setup allows us to iso-
late the computation overhead of onion routing in our
benchmark.
Table 2 (second column) shows the path instantiation
times (measured from the initiator creating the onion
to the establishment of the bidirectional onion path) as
the number of relays increases. For each relay size, we
measured 10 path instantiations and computed the me-
dian. We make the following two observations: First, as
expected, the path instantiation time increases linearly
with the number of relays. Second, the instantiation time
is within 244ms, even for up to 5 relay nodes, demon-
Figure
9. Distribution of bandwidth
throughput on PlanetLab using the DJ-
Anonymous application with a dual-
constraint selection policy.
strating the low overhead and efﬁciency of using A3LOG.
Table 2 (third column) shows a similar experimental
evaluation on the PlanetLab testbed, where we measure
the median path instantiation times as the number of re-
lays increases. We observe greater variability in path
instantiation times (as shown by the values in parenthe-
 0 0.2 0.4 0.6 0.8 1 0 200 400 600 800 1000 1200 1400 1600 1800 2000Cumulative Fractione2e RTT (ms)RandomWeighted (s=9)Constraint (< 400ms) 0.1 1 10 100 1000 10 100 1000Distance from previous coordinate (ms)Time (minutes)Median10%90% 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 5 10 15 20Cumulative FractionBandwidth (KBps)RandomDual-Constraintses denoting the 20th and 80th percentile) for the same
number of relays. We further observe that on PlanetLab,
the instantiation times are higher when the end-to-end
latency dominates other factors due to the high load and
network congestion observed on PlanetLab. Neverthe-
less, the majority of path instantiations complete within
2-3 seconds, even for many relays.
7.4 DJ-Anonymous A3 Audio Streamer
To illustrate how applications can leverage the ﬂex-
ibility provided by A3, we implemented a simple uni-
cast audio streamer which we call DJ-Anonymous. DJ-
Anonymous reads from an audio device at a ﬁxed rate
and transmits audio messages at regular intervals to the
receiver. DJ-Anonymous supports the transmission of
live audio and aims to minimize the latency and maxi-
mize the bandwidth of its chosen paths.
DJ-Anonymous uses a dual constraint policy in
which the e2e latency is capped at 400ms and the tol-
erable maximum CPU utilization of a relay is set at 30%
(as measured by CoMon [27]). Since rate limiting on
PlanetLab prevents accurate bandwidth measurements,
our policy does not include any bandwidth requirements.
The entire policy used by DJ-Anonymous may be ex-
pressed in just six lines of A3LOG.
In our experimental setup, each PlanetLab node runs
an instance of DJ-Anonymous, sending streams of data
to randomly selected PlanetLab destinations. Streams
are instantiated on average every two minutes (stream
start times are randomized between -20% and +20% to
avoid nodes functioning in lockstep) and persist for one
minute.
Initiators attempt to send 500 byte payloads
every 25ms, representing a maximum possible through-
put of 20KBps. Since we were not able (or willing) to
read from live audio sources on PlanetLab nodes, DJ-
Anonymous instances on PlanetLab read “audio” from
their /dev/zero devices.
Figure 9 shows the e2e bandwidth (as measured
by the receiver) achieved using DJ-Anonymous’ two-
constraint relay selection policy. For comparison, the
bandwidth that results from using random selection is
also plotted. Using our six-rule dual-constraint pol-
icy, DJ-Anonymous achieves a median throughput of
9.0KBps (sufﬁcient for G.711/PCM µ-law audio en-
coding), more than doubling the median bandwidth of
3.7KBps that results from random selection.
8 Conclusion
This paper presents Application-Aware Anonymity
(A3), an extensible anonymity framework that enables
senders to compactly specify policies for relay selec-
tion and path instantiation that meet their performance
and anonymity requirements. Unlike existing anonymity
networks in which modifying the relay selection and
path instantiation algorithms require changes to the
source code, A3 allows senders to customize the manner
in which paths are chosen and constructed at runtime.
A3 uses a declarative design in which senders specify
their routing requirements using the A3LOG policy lan-
guage. We demonstrate that A3 provides sufﬁcient ﬂex-
ibility to encode the relay selection algorithms used by
Tor [9], Snader and Borisov’s reﬁnement to Tor [40], and
link-based approaches [36] in only a few lines of A3LOG.
Results from simulations over trace-driven datasets and
our deployment on PlanetLab show that A3 produces
paths that conform to the speciﬁed policies with little
computational overhead.
In addition to providing ﬂexible relay selection, A3
also enables initiators to customize both the manner in
which anonymous paths are constructed as well as the
mechanisms used to transport data over such paths. For
example, we show how the Setup and Data Transmission
phases of Onion Routing [30] can be compactly speci-
ﬁed in A3LOG.
A3’s ﬂexibility has several advantages for anonymous
routing. First, it allows senders to construct policies that
meet their applications’ speciﬁc requirements. For ex-
ample, a real-time VoIP application may provide poli-
cies that enforce e2e latency constraints, whereas a ﬁle
sharing client may utilize a policy that favors bandwidth
over other performance indicators. Second, the ability to
rapidly deploy both relay selection and path instantiation
algorithms makes A3 a useful tool for protocol designers
and anonymity researchers. Finally, A3’s modular de-
sign and declarative techniques permit the system to be