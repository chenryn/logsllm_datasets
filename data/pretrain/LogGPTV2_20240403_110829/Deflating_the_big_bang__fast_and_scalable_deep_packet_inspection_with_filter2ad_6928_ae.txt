For comparison purposes, we also evaluate two other re-
cently proposed techniques, multiple DFAs (mDFAs) [37]
and D2FAs [20], which we brieﬂy described in Section 2.
We implemented the mDFA algorithm and supplied memory
ceilings ranging from 4K total states to 512K total states,
which produced groups of combined automata for each set-
ting. During runtime we matched mDFAs by modifying our
matching code to maintain multiple state pointers. For the
D2FA evaluation, we applied the D2FA edge compression al-
gorithm to each combined DFA in each mDFA group. The
D2FA proposal requires custom hardware to hash an input
symbol to the correct compressed transition entry. To adapt
to a software-based environment, we used a simple bitmap-
based structure to identify the next transition. This makes
the hash function as fast as possible (simulating the hard-
ware assist) with only a minor cost in memory usage.
Execution time tests were performed on 10 GB traces
captured on the link between a university campus and a
departmental network at varying times. We performed all
experiments on a 3.0 GHz Pentium 4 Linux workstation.
Runtime measurements were collected using cycle-accurate
performance counters and are reported as average cycles per
payload byte. During execution, each automaton is applied
only to packets belonging to its respective protocol.
Figure 9 gives space-time comparisons for each test set.
In all plots, the x-axis (processing time) and y-axis (mem-
ory usage) increase on a log scale. The dashed vertical line
gives the runtime for the largest subset of DFAs that we
could combine and ﬁt into memory. mDFAs trace out a
curve showing the trade-oﬀs between memory usage and pro-
cessing time. D2FAs build on mDFAs and follow a similar
curve with a reduced memory footprint. For XFAs, we plot
the combined automata along with the cumulative eﬀects
of each optimization, leading toward the lower left corner.
Optimization 1 exhibits the largest visible improvement. By
eliminating instructions on many states, both memory and
runtime are reduced by up to an order of magnitude.
In
general, the second optimization also achieves signiﬁcant re-
ductions, although here they are largely subsumed by op-
timization 1. Optimization 3 reduces memory but has a
negligible eﬀect on performance.
6.3 Per-ﬂow State
Table 3 depicts the per-ﬂow state for mDFAs/D2FAs at
various memory ceilings and for XFAs. mDFAs require a dis-
tinct current state pointer for each automaton in a group,
and D2FAs have these same requirements. We assume 2-
byte state pointers for 8K and 64K ceilings and 3-byte point-
ers for 512K ceilings. XFA per-ﬂow state contains a state
Rule set
Snort FTP
Snort SMTP
Snort HTTP
Cisco FTP
Cisco SMTP
Cisco HTTP
XFA
11
23
36
10
7
8
8K States
8
(4)
(11)
22
154
(77)
8
(4)
12
(6)
(23)
46
2
FA
mDFA/D
64K States
4
22
82
4
6
28
(2)
(11)
(41)
(2)
(3)
(14)
512K States
6
12
81
6
9
24
(2)
(4)
(27)
(2)
(3)
(8)
Table 3: Per-ﬂow state in bytes for XFAs and mD-
FAs at various memory ceilings. Parentheses hold
the number of mDFAs at each setting.
pointer along with all the variables that must be maintained.
We quantify this by adding a 2-byte state pointer to each of
the optimized variable memory entries (column 9) in Table 1.
Reductions in per-ﬂow state for XFAs are a direct result of
optimization 2. As Table 1 indicates, per-ﬂow state can be
reduced by up to a factor of six. In Table 3, per-ﬂow state
for XFAs is comparable to mDFAs in all cases. For large
test sets, XFA state can be much smaller, depending on the
mDFA memory ceiling.
7. MIGRATING TO HARDWARE
We present here a preliminary chip design that can per-
form signature matching at 10 Gbps using XFAs with up
to 24,576 states. The chip does not perform reassembly or
packet classiﬁcation, and it also uses techniques for com-
pressing the transition tables.
It has 8 packet processing
pipelines each consisting of three loosely coupled stages: a
DFA engine, a program lookup engine, and a processing el-
ement. We expect a clock speed close to 500MHz.
DFA engines consume one byte of input every two cy-
cles and use a shared multiport SRAM to store transition
tables. Each of the 220 entries of this SRAM stores a 15-
bit state identiﬁer. The DFA engines implement a table
compression algorithm based on ideas from the existing lit-
erature [4, 20, 21]. For brevity we omit the exact description
of the algorithm, but we note that for each payload byte,
the DFA engine performs a single access to the shared tran-
sition table, and up to two accesses to a private SRAM with
24,576 60-bit words.
Program lookup engines receive from their DFA engine
a sequence of states visited and produce a sequence of pro-
grams to be executed. Since most states have no programs
associated with them, the output of this engine includes only
the addresses of the non-empty programs, and it pairs with
each program the oﬀset in the input to which it corresponds.
Each engine uses a private SRAM with 24,576 15-bit words
representing the addresses of the program associated with
each state. At the output of each engine is a large queue of
up to 32 addresses which provides decoupling between the
DFA engines and the PEs.
Processing elements execute the programs associated
with the traversed states. These programs are stored in a
local 64KB instruction memory. For states whose programs
are identical, a single copy needs to be stored. While the
instruction memory of one processing element may not be
large enough to store the programs for XFAs for all pro-
tocols, it can easily store the programs for the largest one.
Hence each processing element can handle a subset of the
protocols we have signatures for. Each PE uses 32 16-bit
registers holding the variables. The instruction set does not
have memory access operations or branches. We use simple
predication to make instructions conditional. All instruc-
Cache for packets and per flow state
Chip for signature 
matching
Shared
transition
table
DFA
engine
…
DFA
engine
Processing
Prog
element
lookup
… …
Processing
Prog
element
lookup
S
c
h
e
d
u
l
e
r
Processing element
Queue of program 
addresses from 
lookup engine
…
Offset list
O
f
f
s
e
t
l
i
s
t
e
l
e
m
e
n
t
O
f
f
s
e
t
l
i
s
t
e
l
e
m
e
n
t
offset
addr
offset
addr
reset
set
offset
addr
Instruction fetch stage
Register file
did last instruction 
end program?
M
U
X
addr
of 
next 
instr
Instruction
memory
PC
D
e
c
o
d
e
/
r
e
g
.
r
e
a
d
s
t
a
g
e
E
x
e
c
u
t
e
/
r
e
g
.
w
r
i
t
e
s
t
a
g
e
Figure 10: Chip that can do signature matching at
10Gbps using XFAs.
tions are 2 bytes. The PE uses a simple 3-stage pipeline
with one instruction issue per cycle. The only unusual part
is the logic for determining the address of the instruction to
fetch.
It can be the next instruction, the ﬁrst instruction
of the next program in the queue, or the next program in
the oﬀset list. The oﬀset list is a chain of 8 elements that
maintain a sorted list with the oﬀsets in the input at which
various implicit counters ﬁre, together with the addresses of
the programs to be executed in response.
Switching between packets happens with the assis-
tance of the scheduler. For the DFA engine, the switch only
requires loading a new value for the current state. The pro-
cessing element needs to write out the dirty registers and the
oﬀset list into the cache line holding the per ﬂow state of the
old packet, and read in the registers and oﬀsets correspond-
ing to the next one. To avoid slowing the PE down, we use
two sets of registers and two oﬀset lists so that while the PE
is working with one packet, the variables for the previous
one can be written out and those for the next one read in.
A 256KB cache holds packets and their per ﬂow state.
We estimate the chip size by comparing against the Ni-
agara2 ﬂoorplan [23]. Our design uses 4.4MB total SRAM
compared to Niagara2’s 4MB of L2 cache. Our processing el-
ements are much simpler than Niagara2’s cores; it has many
components not needed in our design and is more complex.
Since Niagara2 uses 342mm2 in a 65nm technology, we es-
timate that our chip would use less than 200mm2.
8. CONCLUSION AND FUTURE WORK
The Big Bang Theory [13] asserts that a compact, highly
compressed mass exploded into a mostly empty universe,
leaving scattered pockets of organized matter. This is not
too dissimilar from combined DFAs, which experience ex-
plosive growth yet are full of redundancy. In this work, our
running hypothesis is that the systematic use of auxiliary
variables and optimizations provides a practical mechanism
for deﬂating explosive DFAs.
In this paper we presented a formal characterization of
state-space explosion and showed how auxiliary variables
can be used to eliminate it. We presented XFAs, a formal
model that extends standard DFAs with auxiliary variables
and instructions for manipulating them. We deﬁned opti-
mizations over this model that signiﬁcantly improve perfor-
mance and decrease per-ﬂow state.
Many research problems remain open. Our treatment
of state-space explosion is preliminary, and stronger results
may allow us to better predict and control it. A better un-
derstanding of the interplay between protocol parsing and
signature matching may yield simpler automata and better
performance. But, even with our current prototype, mea-
surements show large improvements over previous solutions.
We are optimistic that in the end, XFAs will yield a fast,
scalable mechanism for deep packet inspection.
Acknowledgments
This work is sponsored by NSF grants 0546585 and 0716538
and by a gift from the Cisco University Research Program
Fund at Silicon Valley Community Foundation. We thank
Karu Sankaralingam, George Varghese, and the anonymous
reviewers for suggestions that improved this paper.
9. REFERENCES
[1] A. V. Aho and M. Corasick. Eﬃcient string matching:
An aid to bibliographic search. In Communications of
the ACM, June 1975.
[2] T. Ball and S. Rajamani. The SLAM project:
Debugging system software via static analysis.
January 2002.
[3] M. Becchi and S. Cadambi. Memory-eﬃcient regular
expression search using state merging. In IEEE
Infocom 2007.
[4] M. Becchi and P. Crowley. An improved algorithm to
accelerate regular expression evaluation. In ANCS
2007.
[5] B. Brodie, R., and D. Taylor. A scalable architecture
for high-throughput regular-expression pattern
matching. SIGARCH Comput. Archit. News,
34(2):191–202, 2006.
[6] D. Brumley, J. Newsome, D. Song, H. Wang, and
S. Jha. Towards automatic generation of
vulnerability-based signatures. In IEEE Symposium on
Security and Privacy, May 2006.
[7] C. R. Clark and D. E. Schimmel. Scalable pattern
matching for high-speed networks. In IEEE FCCM,
April 2004.
[8] E. M. Clarke, O. Grumberg, and D. Peled. Model
Checking. The MIT Press, 1999.
[9] S. Crosby and D. Wallach. Denial of service via
algorithmic complexity attacks. In Usenix Security,
August 2003.
[10] S. Dharmapurikar and J. W. Lockwood. Fast and
scalable pattern matching for network intrusion
detection systems. IEEE Journal on Selected Areas in
Comm., 24(10):1781–1792, 2006.
[11] The Guardian. Trouble on the line. http://technology.
guardian.co.uk/weekly/story/0,,1747343,00.html,
2006.
[12] M. Handley, V. Paxson, and C. Kreibich. Network
intrusion detection: Evasion, traﬃc normalization,
and end-to-end protocol semantics. In Usenix Security,
August 2001.
[13] S. W. Hawking. A brief history of time. From the Big
Bang to Black Holes. Bantam Book, 1988.
[14] John L. Hennessy and David A. Patterson. Computer
Architecture: A Quantitative Approach, 2nd Edition.
Morgan Kaufmann, 1996.
[15] J. Hopcroft, R. Motwani, and J. Ullman. Introduction
to Automata Theory, Languages, and Computation.
Addison Wesley, 2006.
[16] Myles Jordan. Dealing with metamorphism. Virus
Bulletin Weekly, 2002.
[17] C. Kachris and S. Vassiliadis. Design of a web switch
in a reconﬁgurable platform. In ANCS 2006.
[18] P. Kapustka. Vonage complaining of VoIP blocking.
http://www.networkcomputing.com/channels/
networkinfrastructure/60400413, 2005.
[19] S. Kumar, B. Chandrasekaran, J. Turner, and
G. Varghese. Curing regular expressions matching
algorithms from insomnia, amnesia, and acalculia. In
ANCS 2007, pages 155–164.
[20] S. Kumar, S. Dharmapurikar, F. Yu, P. Crowley, and
J. Turner. Algorithms to accelerate multiple regular
expressions matching for deep packet inspection. In
ACM SIGCOMM, September 2006.
[21] S. Kumar, J. Turner, and J. Williams. Advanced
algorithms for fast and scalable deep packet
inspection. In ANCS 2006, pages 81–92.
[22] R. Liu, N. Huang, C. Chen, and C. Kao. A fast
string-matching algorithm for network processor-based
intrusion detection system. Trans. on Embedded
Computing Sys., 3(3):614–633, 2004.
[23] H. McGhan. Niagara 2 opens the ﬂoodgates. In
Microprocessor Report, November 2006.
[24] S. Muchnick. Advanced Compiler Design and
Implementation. Morgan Kaufmann, 1997.
[25] M. Neider. Deep packet inspection: A service
provider’s solution for secure VoIP. VoIP Magazine,
Oct 2005.
[26] V. Paxson. Bro: a system for detecting network
intruders in real-time. In Computer Networks,
volume 31, pages 2435–2463, 1999.
[27] T. Ptacek and T. Newsham. Insertion, evasion and
denial of service: Eluding network intrusion detection.
In Secure Networks, Inc., January 1998.
[28] M. Roesch. Snort - lightweight intrusion detection for
networks. In 13th Systems Administration Conference.
USENIX, 1999.
[29] U. Shankar and Vern Paxson. Active mapping:
Resisting nids evasion without altering traﬃc. In
IEEE Symp. on Security and Privacy, May 2003.
[30] R. Smith, C. Estan, and S. Jha. Backtracking
algorithmic complexity attacks against a NIDS. In
ACSAC 2006, pages 89–98.
[31] R. Smith, C. Estan, and S. Jha. XFA: Faster signature
matching with extended automata. In IEEE
Symposium on Security and Privacy, May 2008.
[32] R. Sommer and V. Paxson. Enhancing byte-level
network intrusion detection signatures with context.
In ACM CCS, Oct. 2003.
[33] I. Sourdis and D. Pnevmatikatos. Fast, large-scale
string match for a 10gbps fpga-based network
intrusion detection system. In Int. Conf. on Field
Programmable Logic and Applications, sep. 2003.
[34] L. Tan and T. Sherwood. A high throughput string
matching architecture for intrusion detection and
prevention. In ISCA, June 2005.
[35] N. Tuck, T. Sherwood, B. Calder, and G. Varghese.
Deterministic memory-eﬃcient string matching
algorithms for intrusion detection. In IEEE
INFOCOM 2004, pages 333–340.
[36] H. J. Wang, C. Guo, D. Simon, and A. Zugenmaier.
Shield: Vulnerability-driven network ﬁlters for
preventing known vulnerability exploits. In ACM
SIGCOMM, August 2004.
[37] F. Yu, Z. Chen, Y. Diao, T. V. Lakshman, and R. H.
Katz. Fast and memory-eﬃcient regular expression
matching for deep packet inspection. In ANCS 2006.