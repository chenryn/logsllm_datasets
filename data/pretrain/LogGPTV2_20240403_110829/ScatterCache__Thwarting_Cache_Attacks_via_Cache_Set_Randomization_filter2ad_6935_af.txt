.
5
3
1
1
5
.
5
3
1
6
4
.
8
5
5
4
.
8
5
2
9
.
6
5
5
7
.
9
5
8
.
9
5
7
.
9
5
2
9
.
0
2
4
9
.
0
2
7
8
.
0
2
4
1
.
5
1
2
8
.
4
1
5
1
6
8
.
5
4
6
8
.
5
4
6
8
.
5
4
6
8
.
5
4
6
8
.
5
4
6
8
.
5
4
6
0
.
6
3
8
0
.
6
3
4
0
.
6
3
2
0
.
6
3
2
0
.
6
3
4
0
.
6
3
3
8
.
9
5
1
.
0
6
4
.
7
5
8
1
.
0
6
8
2
.
0
6
2
.
0
6
composite
fft
sor monte carlo sparse
matmult
lu
Figure 11: Scimark2 score simulated with gem5.
100
50
0
BIP
LRU
Rand
SCv1
SCv2
Skewed
]
s
n
[
y
c
n
e
t
a
L
d
a
e
R
)
r
e
t
t
e
b
s
i
r
e
w
o
l
(
0.001
0.01
Access Size [MB]
0.1
1
10
Figure 12: Memory read latency, simulated with gem5, with
32 byte stride (i.e., one access per cache line).
set-associative caches only uses every 4th cache index, gives
high cache hit rates and low read latencies for larger memory
ranges due to less cache conﬂicts. This effect becomes visible
in Figure 13 as shift of the second step from 512 kB to 2 MB
for the skewed cache variants.
Finally, as last benchmark, MiBench has been evaluated
in small and large conﬁguration. The individual results are
visualized in Figure 14 and Figure 15 respectively. On aver-
age, the achieved performance results in MiBench are very
similar to the results from the GAP benchmark suite. Again,
caches with BIP and LRU replacement policy outperform the
conﬁgurations with random replacement policy by a few per-
cent. However, in some individual benchmarks (e.g., qsort in
small, jpeg in large), skewed cache architectures like SCAT-
TERCACHE outmatch the ﬁxed set appraoches.
In summary, our evaluations with gem5 in full system sim-
ulation mode show that the performance of SCATTERCACHE,
in terms of hit rate, is basically identical to contemporary
ﬁxed set-associative caches with random replacement policy.
Considering that we employ the same replacement strategy,
this is an absolutely satifying result by itself. Moreover, no
tests indicated any notable performance degradation and in
some tests SCATTERCACHE even outperformed BIP and LRU
replacement policies.
USENIX Association
28th USENIX Security Symposium    689
]
s
n
[
y
c
n
e
t
a
L
d
a
e
R
)
r
e
t
t
e
b
s
i
r
e
w
o
l
(
100
50
0
BIP
LRU
Rand
SCv1
SCv2
Skewed
0.001
0.01
Access Size [MB]
0.1
1
10
Figure 13: Memory read latency, simulated with gem5, with
128 byte stride (i.e., one access in every fourth cache line).
BIP
LRU
SCv1
SCv2
Skewed
]
%
[
∆
e
t
a
R
t
i
H
)
r
e
t
t
e
b
s
i
r
e
h
g
i
h
(
4
2
0
gsm
dijkstra
adpcm
FFT
CRC32
bitcount
basicmath
blowﬁsh
jpeg
lame
sha
mean
qsort
typeset
susan
rijndael
patricia
stringsearch
tiff2rgba
mad
tiff2bw
tiffdither
tiffmedian
Figure 14: Cache hit rate, simulated with gem5, for MiBench
in small conﬁguration compared to random replacement.
5.4 Cache Simulation and SPEC Results
Lastly, we evaluated the performance of SCATTERCACHE
using the SPEC CPU 2017 [66] benchmark with both the
“SPECspeed 2017 Integer” and “SPECspeed 2017 Floating
Point” suites. We performed all benchmarks in these suites
with the exception of gcc, wrf and cam4, as these failed to
compile on our system. Because these benchmarks are too
large to be run in full system simulation, we created a software
cache simulator, capable of simulating different cache models
and replacement policies. Even so, the benchmarks proved
to be too large to run in full, so we opted to run segments of
250 million instructions from each, following the methodol-
ogy of Qureshi et al. [56]. We made an effort to select parts
of the benchmarks that are representative of their respective
core workloads. To be able to run the benchmarks with our
simulator, we recorded a trace of all instruction addresses
and memory accesses with the Intel PIN Tool [33]. We then
replayed this access stream for different cache conﬁgurations.
The simulator implements the set-associative replacement
policies Pseudo-LRU (Tree-PLRU), LRU (ideal), BIP as de-
scribed in [56], and random replacement, as well as the two
BIP
LRU
SCv1
SCv2
Skewed
6
4
2
]