Pr[Lq = lq|Ki = ki] Pr[Ki = ki]
Pr[Lq = lq]
Pr[Lq = lq|Ki = ki]
max
ki
(cid:88)
lq
=
1
2n
In particular, using the expressions derived above, we get:
1
2n(q+1)
(cid:88)
(cid:88)
lq
1
2n(q+1)
lq
Succsc−kr−K0
Pq (K,K∗),A =
||C lKq DlMq−1 ··· C lK1 DlM0 C lK0||1
Succsc−kr−Kq
Pq (K,K∗),A =
||C lK0 DlM0 ··· C lKq−1 DlMq−1 C lKq ||1
(4)
(5)
Looking at these equations, we see that the success rate
strongly depends on the leakage function and probability dis-
tributions. For most leakage functions, analytical evaluation
seems diﬃcult when the number of rounds increases. In or-
der to illustrate the validity of our construction in the phys-
ical world, the next section consequently details this success
rate for certain practically relevant leakage functions.
PARTICULAR LEAKAGE FUNCTIONS
We ﬁrst show a context in which it is possible to derive
asymptotical upper bounds on the success rate, which is
enough to prove asymptotic security. Then, we consider two
leakage functions for which we provide a simulation-based
analysis. In particular, we selected:
1. A Hamming weight leakage function such that all the
leakages are of the form L(ki) = WH (ki). In this con-
text, we demonstrate that increasing the number of
observed rounds does not improve the success rate:
Succsc−kr−K0
Pq (K,K∗),A = Succsc−kr−K0
P1(K,K∗),A, for every q.
2. A (so-called) generalized Hamming weight leakage func-
tion, such that all the leakages are of the form: L(ki) =
WH (S(xi,[0···7]⊕ki,[0···7]))+R, where S is a known sub-
stitution box, e.g., the AES one, and R ∼ N (µ, σ2) is
a Gaussian distributed random noise with mean µ and
variance σ2. We note that for this example, only 8 key
bits are targeted (i.e. a typical S-box size).
5.2 Analysis of noisy leakages
The previous analysis can be easily extended to noisy leak-
ages by deﬁning the leakage vector as a sum of its determinis-
tic part and a random noise variable vector: Lq = Lqdet+R.
It directly yields:
Pr[Lq = lq|K0 = k0]
Pr[Lq = lq|Lqdet = lqdet] Pr[Lqdet = lqdet|K0 = k0]
Pr[R = lq − lqdet] Pr[Lqdet = lqdet|K0 = k0]
(cid:88)
=
lqdet
=
(cid:88)
lqdet
(cid:88)
(cid:88)
lKi ,det
If we deﬁne the noisy running matrix C lKi and noisy update
matrix DlMi as the noisy counterparts of AlKi and BlMi : 4
C lKi =
DlMi =
Pr[RKi = lKi − lKi,det] · AlKi,det
Pr[RMi = lMi − lMi,det] · BlMi,det
lMi,det
We then ﬁnd:
Pr[lq|k0] =
(1··· 1)C lKq DlMq−1 ··· C lK1 DlM0 C lK0
2nq
The expression above is similar to Equation (2). The equiva-
lent of Equation (3) can also be derived. Intuitively, C lKi (ki,
ki) contains the probabilities that a running key candidate
ki gives rise to an actual leakages lKi , and DlMi (ki, ki+1)
contains the probabilities that any consecutive running key
candidates ki, ki+1 give rise to an actual leakages lMi .
5.3 Generic expression for the success rate
From the above probabilities, it is straightforward to derive
a generic expression for the success rate of the Bayesian
adversary. For a given leakage value lq, its probability of
right guess for Ki is exactly maxki Pr[Ki = ki|Lq = lq], so
the success rate for Ki is:
Succsc−kr−Ki
Pr[Ki = ki|Lq = lq]
Pr[Lq = lq] · max
(cid:88)
Pq (K,K∗),A =
(cid:82)
lq
C lK = I2n and
lK
ki
(cid:82)
4 Again with
DlM = 1 .
lM
61
,
6. SECURITY ANALYSIS OF
3. A noisy identity leakage functions such that the leak-
ages are of the form: L(ki) = ki,[0···7] + R with R ∼
N (µ, σ2). It is potentially the most powerful type of
leakage function and typically relates to the context of
template attacks [5]. If the noise variance is null, its
success rate Succsc−kr−K0
Pq (K,K∗),A = 1, for every q.
6.1 Hamming weight leakages
In this ﬁrst section, we consider an example of leakage func-
tion for which the sums in Equations (4) and (5) can be
computed analytically. It yields the following statement:
Claim 2. In the setting of Section 4.2, the success rate
of a Bayesian side-channel adversary exploiting a Hamming
weight leakage function against our PRNG is independent of
the number of PRNG rounds q observed by the adversary.
lKi+1
n
Proof. We assume that all keys are bit strings of length n.
For each leakage values 0 ≤ lKi+1 , lMi ≤ n, let us deﬁne
the matrices Z lKi+1 ,lMi
:= AlKi+1 BlMi . Since Hamming
weight leakages are distributed as binomials, these matrices
Z lKi+1 ,lMi have C
non-zeros rows with the same Ham-
ming weight. Moreover, for every 0 ≤ l ≤ n, the Hamming
weight of each column of Z of which the index has Hamming
weight equal to l is the same, which we denote by hl
Z . We
now show by induction that Pr[Kq = kq|Lq = lq] = 1/C
lKq
n
if WH (kq) = lKq and 0 otherwise. Equivalently (by Bayes’
law), we show that Pr[Lq = lq|Kq = kq] = 2n · Pr[Lq =
or 0 depending if WH (kq) = lKq or not. The as-
lq]/C
sertion is trivial for q = 0. Using Equation (3), we compute:
lKq
n
Pr[Lq+1 = lq+1|Kq+1 = kq+1]
Z lKq+1 ,lMq (kq, kq+1) · Pr[Lq = lq|Kq = kq];
1
2n
(cid:88)
 Pr[Lq=lq]
lKq
n
kq
C
0
=
=
· h
lKq+1
Z
if WH (kq+1) = lKq+1
otherwise.
(cid:88)
(cid:88)
kq+1
Then, we have:
Pr[Lq+1 = lq+1] =
Pr[Lq+1 = lq+1|Kq+1 = kq+1]
=
kq+1|WH (kq+1)=lKq+1
lKq+1
Z
h
Pr[Lq = lq]
lKq
n
C
 C
0
=
lKq+1
n
Pr[Lq+1 = lq+1|Kq+1 = kq+1]
if WH (kq+1) = lKq+1 ;
otherwise.
The success rate can ﬁnally be computed as:
Succsc−kr−Kq
Pq (K,K∗),A =
Pr[Lq = lq] ·
(cid:88)
n(cid:88)
lkq =0
=
lq
Pr[LKq = lKq ] ·
max
kq
1
lkq
n
C
n(cid:88)
=
lkq =0
Pr[Kq = kq|Lq = lq]
1
2n =
n + 1
2n
62
This expression (that is also found in [17]) is independent of
q: it demonstrates that the success rate of the Bayesian ad-
versary does not increase if he gets more leakages. We note
that the result is quite intuitive:
if we know WH (k0) and
learn WH (k1) and WH (k0 ⊕ k1) for some random k1, the in-
formation we get about the value of k0 is null. Interestingly,
this conclusion does not depend on a divide-and-conquer
strategy (the complete n-bit key is targeted at once) nor
on the amount of randomness in the physical observations
(that are here considered noise-free). But it also holds if the
adversary receives the Hamming weight of b-bit parts of the
n-bit key. In the latter case, the success rate on this part of
the key would be turned into b+1
2b .
6.2 Generalized Hamming weight and
identity leakage functions
The previous section shows that for a Hamming weight leak-
age function, the success rate of a Bayesian side-channel ad-
versary against our PRNG is independent of the number of
PRNG rounds observed by the adversary. But this is not
generally true for other practical leakage functions. In this
section, we consequently intend to investigate other exam-
ples. Namely, we consider the previously deﬁned generalized
Hamming weight and a noisy identity leakage functions. As
already mentioned, a practical drawback of actual leakage
functions is that the sums in Equations (4) and (5) may
be hard to compute exhaustively. Therefore, as a ﬁrst step
towards the analysis of practical leakage functions, we ap-
proximate them by covering only a statistically meaningful
part of the sums. It yields the following statement:
Empirical claim 3. In the setting of Section 4.2, there
exists a value 0 < u < 1 such that the success rate of
a Bayesian side-channel adversary against one byte of our
PRNG key, exploiting a generalized Hamming weight or iden-
tity leakage function, both aﬀected by a suﬃcient amount of
noise in the physical observations, is bounded by u for any
number of PRNG rounds q observed by the adversary.
Contrary to the previous section, our analysis depends both
on the adversarial divide-and-conquer strategy (the claim
is stated for one byte of the PRNG key) and the amount
of noise in the leakages. Since this scenario is complex to
investigate analytically, we show empirical evidence that it
holds in the following simulation environment.
First, we consider an adversary who targets 8-bit key bytes.
As will be emphasized later on, secure implementations of
our PRNG also exist against more powerful adversaries (e.g.
targeting 16, 32, . . . -bit parts of the key).
Second, we simulated diﬀerent architectures for the PRNG:
1. An 8-bit architecture in which the adversary is pro-
vided with respectively WH (S(xi,[0···7] ⊕ ki,[0···7])) and
WH (mi,[0···7]) in the generalized Hamming weight case
and with ki,[0···7] and mi,[0···7]
in the identity leak-
age function case. The latter example gives rise to
a straightforward 100% success rate.
2. A 16-bit architecture in which the adversary is pro-
vided with respectively WH (S(xi,[0···7] ⊕ ki,[0···7])) +
R(8) and WH (mi,[0···7])+R(8) in the generalized Ham-
ming weight case and with ki,[0···7]+R(8) and mi,[0···7]+
Figure 5: Attack success rates: generalized Hamming weight and identity leakage functions.
R(8) in the identity leakage function case. In this con-
text R(8) represents the leakage of the 8 bits that are
not targeted by the adversary and consequently pro-
duce what is usually referred to as algorithmic noise.
3. A 32-bit architecture in which the adversary is pro-
vided with respectively WH (S(xi,[0···7] ⊕ ki,[0···7])) +
R(24) and WH (mi,[0···7]) + R(24) in the generalized
Hamming weight case and with ki,[0···7] + R(24) and
mi,[0···7] + R(24) in the identity leakage function case.
In this context R(24) represents the leakage of the 24
bits that are not targeted by the adversary.
4. 64-bit, 128-bit and 256-bit architectures that are de-
ﬁned following the same guidelines.
Since the PRNG inputs are not under control of the adver-
sary, it is not possible to switch the algorithmic noise source
oﬀ (e.g. by feeding the device with constant inputs). In our
simulations and for any b-bit architecture, we assumed the
leakage of the un-targeted b − 8 bits in the implementation
(i.e. the R(b−8) parameter) to be normally distributed with
mean b−8
4 . We note that there exist other
ways to introduce noise in the physical observations.
2 and variance b−8
For each selected architecture and leakage function, we gen-
erated 2000 random keys and computed the success rate
from their corresponding leakages for diﬀerent number of
PRNG rounds (from 1 to 20) with their 95% conﬁdence in-
tervals. The results are in Figure 5, from which we conclude: