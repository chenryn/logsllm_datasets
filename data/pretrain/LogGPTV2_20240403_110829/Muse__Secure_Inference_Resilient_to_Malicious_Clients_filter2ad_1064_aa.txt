title:Muse: Secure Inference Resilient to Malicious Clients
author:Ryan Lehmkuhl and
Pratyush Mishra and
Akshayaram Srinivasan and
Raluca Ada Popa
Muse: Secure Inference Resilient to Malicious Clients
Ryan Lehmkuhl and Pratyush Mishra, UC Berkeley; Akshayaram Srinivasan, 
Tata Institute of Fundamental Research; Raluca Ada Popa, UC Berkeley
https://www.usenix.org/conference/usenixsecurity21/presentation/lehmkuhl
This paper is included in the Proceedings of the 30th USENIX Security Symposium.August 11–13, 2021978-1-939133-24-3Open access to the Proceedings of the 30th USENIX Security Symposium is sponsored by USENIX.MUSE: Secure Inference Resilient to
Malicious Clients
Ryan Lehmkuhl
Pratyush Mishra
Akshayaram Srinivasan
Raluca Ada Popa
UC Berkeley
UC Berkeley
Tata Institute of Fundamental Research*
UC Berkeley
Abstract
The increasing adoption of machine learning inference in
applications has led to a corresponding increase in concerns
about the privacy guarantees offered by existing mechanisms
for inference. Such concerns have motivated the construction
of efﬁcient secure inference protocols that allow parties to per-
form inference without revealing their sensitive information.
Recently, there has been a proliferation of such proposals,
rapidly improving efﬁciency. However, most of these proto-
cols assume that the client is semi-honest, that is, the client
does not deviate from the protocol; yet in practice, clients are
many, have varying incentives, and can behave arbitrarily.
To demonstrate that a malicious client can completely break
the security of semi-honest protocols, we ﬁrst develop a new
model-extraction attack against many state-of-the-art secure
inference protocols. Our attack enables a malicious client to
learn model weights with 22×–312× fewer queries than the
best black-box model-extraction attack [Car+20] and scales
to much deeper networks.
Motivated by the severity of our attack, we design and
implement MUSE, an efﬁcient two-party secure inference
protocol resilient to malicious clients. MUSE introduces a
novel cryptographic protocol for conditional disclosure of
secrets to switch between authenticated additive secret shares
and garbled circuit labels, and an improved Beaver’s triple
generation procedure which is 8×–12.5× faster than existing
techniques.
These protocols allow MUSE to push a majority of its cryp-
tographic overhead into a preprocessing phase: compared to
the equivalent semi-honest protocol (which is close to state-of-
the-art), MUSE’s online phase is only 1.7×–2.2× slower and
uses 1.4× more communication. Overall, MUSE is 13.4×–
21× faster and uses 2×–3.6× less communication than exist-
ing secure inference protocols which defend against malicious
clients.
1 Introduction
The past few years have seen increasing deployment of neu-
ral network inference in popular applications such as image
classiﬁcation [Liu+17b] and voice assistants [Bar18]. How-
ever, the use of inference in such applications raises privacy
concerns: existing implementations either require clients to
send potentially sensitive data to remote servers for classiﬁ-
cation, or require the model owner to store their proprietary
*Work partially done while at UC Berkeley
Figure 1: MUSE’s system setup. Some of MUSE’s clients may be
malicious.
neural network model on the client’s device. Both of these
solutions are unsatisfactory: the former harms the privacy of
the client, while the latter can harm a business model or reveal
information about the training data and model weights.
To resolve this tension, the community has focused on
constructing specialized protocols for secure inference, as
we depict in Table 1. A secure inference protocol en-
ables users and model owners to interact so that the user
obtains the prediction result while ensuring that neither
party learns any other information about the user input or
the model weights. Many of these works implement these
guarantees using secure two-party computation [Gil+16;
Moh+17; Hes+17; Liu+17a; Bru+18; Cho+18; San+18;
Juv+18; Lou+19; Bou+18; Rou+18; Bal+19; Ria+19; Dat+19;
Mis+20; Rat+20]. However, as we can see from Table 1, all
of these two-party works assume that both the client and the
server follow the protocol rules, that is, they are semi-honest.
While it is common in the literature to assume a semi-
honest server, it is fundamentally less likely that all clients
will behave correctly. The server is hosted at a single service
provider, and existing cloud providers deploy competent in-
trusion detection systems, rigid access control, physical mea-
sures, and logging/tracking of the software installed [Goo17].
It is highly non-trivial to bypass these protections. Addition-
ally, if a service provider is caught acting maliciously, the
consequences may be dire due to public accountability.
In contrast, clients are many, run on a variety of setups
under the control of users, users have various motives, and
it sufﬁces for only a single one of them to misbehave. The
incentives for a client to cheat are high: service providers
expend vast amounts of effort and money to accumulate data,
USENIX Association
30th USENIX Security Symposium    2201
E CHET [Dat+19], CryptoDL [Hes+17], LoLa [Bru+18], TAPAS [San+18],
H
Faster CryptoNets [Cho+18], FHE-DiNN [Bou+18]
C DeepSecure [Rou+18], [Bal+19]
G
XONN [Ria+19]
d
e
x
i
M
SecureML [Moh+17]
Gazelle [Juv+18], MiniONN [Liu+17a], CrypTFlow2 [Rat+20]
DELPHI [Mis+20]
MUSE
d Chameleon [Ria+18]
ABY3 [Moh+18]
e
x
i
M
S SecureNN [Wag+19], Falcon [Wag+21], CrypTFlow [Kum+20]
S
C
P
2
C
P
3
vulnerable to
malicious clients
requires network 4
modiﬁcation
2
2
2
1
1
1
1,3
3
3
Table 1: Related work on secure convolutional neural network (CNN) inference. See Section 7 for more details. This
table compares specialized secure inference protocols, not generic frameworks for MPC. We compare against generic
frameworks in Section 6. HE = Homomorphic Encryption, GC = Garbled Circuits, SS = Secret Sharing.
Network modiﬁcations are optional 1See Section 2.1 2 See Remark 2.1 3Requires that two of the three parties act honestly
4Polynomial activations or binarized/discretized weights—may reduce network accuracy
clean it, design model architectures, and to train the ﬁnal
model. If a client wishes to obtain a similar model, it would
be much easier to steal the server’s than to try and train an
equivalent one; this makes model-extraction attacks attractive.
To illustrate the threat of a malicious client, in Section 2
we demonstrate a new model-extraction attack against semi-
honest secure inference protocols whereby a malicious client
can learn the server’s entire model in a number of infer-
ence queries linear in the number of parameters in a net-
work regardless of its depth. This attack outperforms the
best model-extraction attacks for plaintext inference by 22×–
312× [Jag+20; Car+20], and demonstrates that using semi-
honest secure inference protocols can signiﬁcantly amplify a
malicious client’s ability to steal a model.
A natural approach to defend against such an ampliﬁcation
is to leverage state-of-the-art generic secure computation tools
providing malicious security. This approach guarantees that if
either party acts maliciously, they will be caught and the pro-
tocol aborted, preserving privacy. However, such methods for
achieving malicious security add a large overhead due to the
use of heavy cryptographic primitives (e.g. zero-knowledge
proofs [Gol+89] or cut-and-choose [Lin+15; Zhu+16]). In
Section 6, we compare against such techniques.
To reduce this overhead, we propose MUSE, a secure infer-
ence protocol that works in the client-malicious threat model.
In this model, the server is presumed to behave semi-honestly,
but the client is allowed to deviate arbitrarily from the proto-
col description. As we will show in Section 6, working in this
model enables MUSE to achieve much better performance
than a fully malicious baseline.
Our contributions. To summarize, in this paper we make
the following contributions:
• We devise a novel model-extraction attack against secure
inference protocols that rely on additive secret sharing. This
attack allows a malicious client to perfectly extract all the
weights of a model with 22×–312× fewer queries than
the state-of-the-art [Car+20]. The complexity of our attack
depends only on the number of parameters, and not on other
factors like the depth of the network.
• We present MUSE1, an efﬁcient two-party cryptographic
inference protocol that is resilient to malicious clients. In de-
signing MUSE, we develop a novel protocol for conditional
disclosure of secrets to switch between authenticated addi-
tive secret shares and garbled circuit labels. Additionally,
we formulate new client-malicious techniques for triple
generation and input authentication in SPDZ-style MPC
frameworks which improve performance by up to 12.5×
and 37.8× respectively.
• Our implementation of MUSE is able to achieve an on-
line phase that is only 1.7×–2.2× slower and uses 1.4×
more communication than DELPHI [Mis+20], a recent pro-
tocol for semi-honest inference. When compared to fully-
malicious secure inference protocols, MUSE is 13.4×–21×
faster and uses 2×–3.5× less communication.
Remark 1.1. While MUSE’s online phase is competitive with
some of the best semi-honest protocols [Mis+20; Rat+20],
the communication cost of preprocessing is up to 10× higher
than in these semi-honest protocols. Hence, we view MUSE
as a ﬁrst step in constructing secure inference protocols that
achieve client-malicious security, and anticipate that future
works will rapidly lower this cost (the same has occurred
for semi-honest secure inference protocols). MUSE already
improves performance over current techniques for client-
malicious inference by 13.4×–21× (see Section 6.4).
We now give a high-level overview of our techniques.
1MUSE is an acronym for Malicious-User Secure Inference
2202    30th USENIX Security Symposium
USENIX Association
1.1 Our attack
What can a malicious client do? We start off by examining
the power of malicious clients in secure inference protocols
that rely on secret sharing. We noticed that many protocols
of interest, such as [Moh+17; Juv+18; Liu+17a; Mis+20;
Rat+20], have a similar structure, and we exploit this structure
in our attack. The structure is as follows. These protocols
“evaluate” the neural network in a layer-by-layer fashion, so
that at the end of each layer, the client and the server both
hold 2-out-of-2 secret shares of the output of that layer. At
the end of the protocol, the server sends its share of the ﬁnal
output to the client, who uses it to reconstruct the ﬁnal output.
Our attack relies on the following crucial observation:
because the shares at the end of a layer are not authenti-
cated, a malicious client can additively malleate them with-
out detection. In more detail, let (cid:104)m(cid:105)C be the client’s share,
and (cid:104)m(cid:105)S be the server’s share of a message m ∈ F, so that
(cid:104)m(cid:105)C +(cid:104)m(cid:105)S = m. Then, a malicious client can add an arbi-
trary shift r to a secret share to change the shared value from
m to m + r. In Section 2, we show how one can leverage this
malleability to learn the model weights.
1.2 Our protocol
We now explain how MUSE protects against malicious client
attacks. We begin by describing our starting point: the semi-
honest secure inference protocol DELPHI [Mis+20].
Starting point: DELPHI. We design MUSE by following the
paradigm laid out in DELPHI [Mis+20]: since a convolutional
neural network consists of alternating linear and non-linear
layers, one should use subprotocols that are efﬁcient for com-
puting each type of layer, and then translate the output of
one subprotocol to the input of the next. DELPHI instantiates
these subprotocols by using additive secret sharing to evalu-
ate linear layers, and garbled circuits to evaluate non-linear
layers.
Attempt 1: Preventing malleability via MACs. The key
insight in our attack in Sections 1.1 and 2 is that the client can
malleate shares without detection. To prevent this, one can
try to use standard techniques for authenticating the client’s
share via information-theoretic homomorphic message au-
thentication codes (MACs). This technique is employed by
the state-of-the-art protocols for malicious security [Kel+18;
Che+20; Esc+20]. However, applying this technique directly
to DELPHI runs into problems. For example, when switching
between secret shares and garbled circuits, the server must
ensure that the labels obtained by the client correspond to
the authenticated secret share, and not to a different share.
Doing this in a straightforward manner entails checking the
share’s MAC inside the garbled circuit, which is expensive.
Furthermore, this check would need to be done in the online
phase, which is undesirable.
Attempt 2: Separating authentication from computation.
To remedy this, we make the following observation: garbled
circuits already achieve malicious security against garbled
circuit evaluators (clients in our setting). This means that,
if we had a specialized protocol that could output labels for
the client’s secret shares only if the corresponding MACs
were valid, then we could compose this protocol with the
garbled circuits to achieve an end-to-end client-malicious
secure inference protocol.
In Section 5.1, we design exactly such a protocol for “condi-
tional disclosure of secrets” (CDS). Unfortunately, executing
our CDS protocol using existing frameworks for malicious
MPC [Kel+18] proves to be extremely expensive. To address
this, in Section 5.3 we devise a number of techniques to im-
prove [Kel+18] in the client-malicious setting, and use the
optimized framework to execute our CDS procedure. While
the resulting protocol is much more efﬁcient than checking
MACs inside garbled circuits, it still imposes a signiﬁcant
cost on the online phase.
Our ﬁnal protocol. To remedy this, our ﬁnal insight in
MUSE is that the secret shares and MACs that the client feeds
into the CDS protocol do not depend on the client’s input in
the online phase. This allows us to move the execution of the
CDS protocol entirely to the preprocessing phase, resulting
in an online phase that is almost identical to that of DELPHI.
To summarize, in order to defend against malicious clients
we ﬁrst enforce authentication for the linear layers by using
homomorphic MACs, then ensure that the client only receives
garbled circuit labels corresponding to these authenticated
shares via a novel CDS protocol, then develop new techniques
for efﬁciently executing the CDS protocol, and ﬁnally move
all these protocols to the preprocessing phase. For details, see
Section 5.
2 Attacks on semi-honest inference protocols
We now describe how a malicious client can leverage the addi-
tive malleability of additive secret shares to learn the weights
of a server’s convolutional neural network in semi-honest se-
cure inference protocols that rely on additive secret sharing.
We begin in Section 2.1 by describing the kinds of protocols
that are vulnerable to our attack. Then, in Section 2.2, we pro-
vide a detailed overview of our attack. Finally, in Section 2.3,
we discuss the theoretical and empirical query complexity
achieved by our attack.
2.1 Attack threat model
Our attack recovers the weights of neural networks consisting
of alternating linear (that is, fully-connected or convolutional)
and non-linear ReLU layers.2 Our attack works against semi-
honest secure inference protocols that have the following
properties: