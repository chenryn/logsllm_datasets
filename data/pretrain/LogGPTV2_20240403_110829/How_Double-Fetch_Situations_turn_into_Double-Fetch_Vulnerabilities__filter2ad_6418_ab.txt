return -EINVAL;
ucmsg = cmsg_compat_nxthdr(kmsg, ucmsg, ucmlen);
ucmsg = CMSG_COMPAT_FIRSTHDR(kmsg);
kcmsg->cmsg_len = tmp;
if(copy_from_user(CMSG_DATA(kcmsg),
Figure 2: Double-Fetch Vulnerability in Linux 2.6.9
as through a buﬀer overﬂow, causing privilege escala-
tion, information leakage or kernel crash.
In this paper, we investigate both harmful double
fetches and benign double fetches. Even though be-
nign double fetches are currently not vulnerable, some
of them can turn into harmful ones when the code is
changed or updated in the future (when the double-
fetched data is reused). Moreover, some benign double
fetches them can cause performance degradation when
one of the fetches is redundant (discussed in Section 5).
Double-fetch vulnerabilities occur not only in the
Windows kernel [14], but also in the Linux kernel. Fig-
ure 2 shows a double-fetch bug in Linux 2.6.9, which
was reported as CVE-2005-2490.
In ﬁle compat.c,
when the user-controlled content is copied to the ker-
the same user data is accessed
nel by sendmsg(),
twice without a sanity check at
the second time.
This can cause a kernel buﬀer overﬂow and there-
fore could lead to a privilege escalation. The func-
tion cmsghdr_from_user_compat_to_kern() works
in two steps: it ﬁrst examines the parameters in the ﬁrst
loop (line 151) and copies the data in the second loop
(line 184). However, only the ﬁrst fetch (line 152) of
ucmlen is checked (lines 156–161) before use, whereas
after the second fetch (line 185) there are no checks be-
Figure 3: Double Fetch with Transfer Functions
fore use, which may cause an overﬂow in the copy oper-
ation (line 195) that can be exploited to execute arbitrary
code by modifying the message.
Plenty of approaches have been proposed for data race
detection at memory access level. Static approaches ana-
lyze the program without running it [35, 28, 12, 6, 10, 19,
38]. However, their major disadvantage is that they gen-
erate a large number of false reports due to lack the full
execution context of the program. Dynamic approaches
execute the program to verify data races [31, 16, 15],
checking whether a race could cause a program failure
in executions. Dynamic approaches usually control the
active thread scheduler to trigger speciﬁc interleavings
to increase the probability of a bug manifestation [41].
Nevertheless, the runtime overhead is a severe problem
and testing of driver code requires the support of speciﬁc
hardware or a dedicated simulation. Unfortunately, none
of the existing data race detection approaches (whether
static or dynamic) can be applied to double-fetch bug de-
tection directly, for the following reasons:
(1) A double-fetch bug is caused by a race condition
between kernel and user space, which is diﬀerent from
a common data race because the race condition is sepa-
rated by the kernel and user space. For a data race, the
read and write operations exist in the same address space,
and most of the previous approaches detect data races by
identifying all read and write operations accessing the
same memory location. However, things are diﬀerent for
a double-fetch bug. The kernel only contains two reads
while the write resides in the user thread. Moreover, the
double-fetch bug exists if there is a possibility that the
kernel fetches and uses the same memory location twice,
as a malicious user process can speciﬁcally be designed
to write between the ﬁrst and second fetch.
(2) The involvement of the kernel makes a double-
fetch bug diﬀerent from a data race in the way of
accessing data.
In Linux, fetching data from user
space to kernel space relies on the speciﬁc parameters
passed to transfer functions (e.g., copy_from_user()
and get_user()) rather than dereferencing the user
pointer directly, which means the regular data race de-
tection approaches based on pointer dereference are not
applicable anymore.
4    26th USENIX Security Symposium
USENIX Association
preparedataclonesyscall1st fetch(copy)1st use(check)2nd fetch(copy)2nd use(real use)entryKernel SpaceUser Spacekernel copy #1kernel copy #2maliciousupdateuser datatime(3) Moreover, a double-fetch bug in Linux is more
complicated than a common data race or a double-fetch
bug in Windows. As shown in Figure 3, a double-fetch
bug in Linux requires a ﬁrst fetch that copies the data,
usually followed by a ﬁrst check or use of the copied
data, then a second fetch that copies the same data again,
and a second use of the same data. Although the dou-
ble fetch can be located by matching the patterns of fetch
operations, the use of the fetched data varies a lot. For
example, in addition to being used for validation, the ﬁrst
fetched value can be possibly copied to somewhere else
for later use, which means the ﬁrst use (or check) could
be temporally absent. Besides, the fetched value can be
passed as an argument to other functions for further use.
Therefore, in this paper, we deﬁne the use in a double
fetch to be a conditional check (read data for compar-
ison), an assignment to other variables, a function call
argument pass, or a computation using the fetched data.
We need to take into consideration these double fetch
characteristics.
For these reasons, identifying double-fetch bugs re-
quires a dedicated analysis and previous approaches are
either not applicable or not eﬀective.
Coccinelle’s
strategy for
2.4 Coccinelle
Coccinelle [17] is a program matching and transforma-
tion engine with a dedicated language SmPL (Seman-
tic Patch Language) for specifying desired matches and
transformations in C code. Coccinelle was initially tar-
geted for collateral evolution in Linux drivers, but now is
widely used for ﬁnding and ﬁxing bugs in systems code.
traversing control-ﬂow
graphs is based on temporal logic CTL (Computational
Tree Logic) [3], and the pattern matching implemented
on Coccinelle is path-sensitive, which achieves better
code coverage. Coccinelle is highly optimized to im-
prove performance when exhaustively traversing all the
execution paths. Besides, Coccinelle is insensitive to
newlines, spaces, comments, etc. Moreover, the pattern-
based analysis is applied directly to the source code,
therefore operations that are deﬁned as macros, such as
get_user() or __get_user(), will not be expanded
during the matching, which facilitates the detection of
double fetches based on the identiﬁcation of transfer
functions. Therefore, Coccinelle is a suitable tool for us
to carry out our study of double fetches based on pattern
matching.
3 Double Fetches in the Linux Kernel
In this paper, our study of double fetches in the Linux
kernel is divided into two phases. As shown in Figure 4,
in the ﬁrst phase, we analyze the Linux kernel with the
Figure 4: Overview of our Two-Phase Coccinelle-Based
Double-Fetch Situation Detection Process
Coccinelle engine using a basic double-fetch pattern that
identiﬁes when a function has multiple invocations of a
transfer function. Then we manually investigate the can-
didate ﬁles found by the pattern matching, to categorize
the scenarios in which a double fetch occurs and when
a double-fetch bug or vulnerability is prone to happen
based on the context information that is relevant to the
bug. In the second phase, based on the knowledge gained
from the manual analysis, we developed a more precise
analysis using the Coccinelle engine to systematically
detect double-fetch bugs and vulnerabilities throughout
the kernel, which we also used to additionally analyze
FreeBSD and Android.
3.1 Basic Pattern Matching Analysis
There are situations in which a double fetch is hard to
avoid, and there exist a large number of functions in the
Linux kernel that fetch the same data twice. According
to the deﬁnition, a double fetch can occur in the kernel
when the same user data is fetched twice within a short
interval. Therefore we can conclude a basic pattern that
we will use to match all the potential double-fetch sit-
uations. The pattern matches the situation in which a
kernel function is using transfer functions to fetch data
from same user memory region at least twice.
In the
case of the Linux kernel, the transfer functions to match
are mainly get_user() and copy_from_user() in all
their variants. The pattern allows the target of the copy
and the size of the copied data to be diﬀerent, but the
source of copy (the address in user space) must be the
same. As shown in Figure 4, we implemented the basic
pattern matching in the Coccinelle engine.
Our approach examines all source code ﬁles of the
Linux kernel and checks whether a kernel function con-
tains two or more invocations of transfer functions that
fetch data from the same user pointer. From the 39,906
Linux source ﬁles, 17,532 ﬁles belong to drivers (44%),
and 10,398 ﬁles belong to non-x86 hardware architec-
USENIX Association
26th USENIX Security Symposium    5
SourceFilesSourceFilesCoccinelleMatchingEngineSourceFilesCandidateFilesvoidfunction_name(*src){copy_from_user(dst1,src,len1)...copy_from_user(dst2,src,len2)}ManualAnalysisRule0:BasicpatternRule1:NopointerchangeRule2:PointeraliasingRule3:ExplicittypeconversionRule4:CombinationofelementfetchandpointerfetchRule5:LoopinvolvementBugDetailsCategorizationPhase1:BasicPatternPhase2:RefinedPatternSourceFilesDoubleFetchContextInformationTrigger&Consequencetures (26%) which cannot be analyzed with Jurczyk and
Coldwind’s x86-based technique. We manually analyzed
the matched kernel functions to infer knowledge on the
characteristics of double fetches, i.e., how the user data
is transferred to and used in the kernel, which helped us
to carry out a categorization of double-fetch situations,
as we discuss in Section 3.2. The manual analysis also
helped us reﬁne our pattern matching approach and more
precisely detect actual double-fetch bugs, as explained in
Section 3.3.
During the investigation, we noticed that there are
plenty of cases where the transfer functions fetch data
from diﬀerent addresses or from the same address but
with diﬀerent oﬀsets. For example, a kernel function
may fetch the elements of a speciﬁc structure separately
instead of copying the whole structure to the kernel. By
adding diﬀerent oﬀsets to the start address of that struc-
ture, the kernel fetches diﬀerent elements of the struc-
ture separately, which results in multiple fetches. An-
other common situation is adding a ﬁxed oﬀset to the
source pointer, so as to process a long message sepa-
rately, or just using self-increment (++) to process a mes-
sage automatically in a loop. All these cases are false
positives caused by the basic pattern matching, and 226
cases of our initial reports were identiﬁed as false posi-
tives, which have been automatically removed in our re-
ﬁned phase since they are not considered as double-fetch
situations and cannot cause a double-fetch bug because
every single piece of the message is only fetched once.
The ﬁrst phase of our study concentrates on the un-
derstanding of the contexts in which double fetches are
prone to happen, rather than on exhaustively ﬁnding po-
tential double-fetch bugs. Even though the analysis and
characterization is not fully automated, it only resulted
in 90 candidates that needed manual investigation, which
took only a few days to analyze them, making the needed
manual eﬀort of our approach acceptable.
3.2 Double Fetch Categorization
As we manually inspected the double fetch candidates,
we noticed that there are three common scenarios in
which double fetches are prone to happen, which we
categorized as type selection, size checking and shallow
copy. We now discuss these in detail.
Most of the time, copying data from the user space to
the kernel space is straightforward via a single invocation
of a transfer function. However, things get complicated
when the data has a variable type or a variable length,
depending on the data itself. Such data usually starts with
a header, followed by the data’s body. In the following,
we consider such data to be messages, as we empirically
found that variable data was often used by drivers to pass
messages to the hardware from user space.
Figure 5: How Message Structure Leads to Double
Fetches
Figure 5 illustrates the scenario: A message copied
from the user space to the kernel (driver) space usually
consists of two parts, the header and the body. The
header contains some meta information about the mes-
sage, such as an indicator of the message type or the
size of the message body. Since messages have diﬀer-
ent types and the message lengths may also vary, the
kernel usually fetches (copies) the header ﬁrst to decide
which buﬀer type needs to be created or how much space
needs to be allocated for the complete message. A sec-
ond fetch then copies the complete message into the al-
located buﬀer of the speciﬁed type or size. The sec-
ond fetch not only copies the body, but also copies the
complete message including the header which has been
fetched already. Because the header of the message is
fetched (copied) twice, a double-fetch situation arises.
The double-fetch situation turns into a double-fetch bug
when the size or type information from the second fetch
is used as the user may have changed the size or type
information between the two fetches.
If, for example,
the size information is used to control buﬀer access, the
double-fetch bug turns into a vulnerability.
The double-fetch situations where a message header is
copied twice could easily be avoided by only copying the
message body in the second fetch and then joining the
header with the body. However, copying the complete
message in the second step is more convenient, and there-
fore such a double-fetch situation occurs very often in the
Linux kernel. Moreover, large parts of the Linux kernel
are old, i.e., they have been developed before double-
fetch bugs were known or understood. Therefore, we
will discuss such double-fetch situations in the kernel in
6    26th USENIX Security Symposium
USENIX Association
Headerstructheader(*ptr){unsignedintsize;unsignedtype;...}hdr;UserMsgcontent*ptrcopy_from_user(hdr,ptr,sizeof(header));...buf=kalloc(hdr.size)...copy_from_user(buf,ptr,hdr.size);...SizeCheckingcopy_from_user(hdr,ptr,sizeof(header));switch(hdr.type){case1:copy_from_user()...case2:copy_from_user()...default:...}TypeSelectionmore detail and also highlight three cases we have found
during the manual analysis.
3.2.1 Type Selection
A common scenario in which double fetches occur is
when the message header is used for type selection. In
other words, the header of the message is fetched ﬁrst
to recognize the message type and then the whole mes-
sage is fetched and processed dependent on the identi-
ﬁed type. We have observed that it is very common in
the Linux kernel that one single function in a driver is
designed to handle multiple types of messages by using
a switch statement structure, in which each particular
message type is fetched and then processed. The result
of the ﬁrst fetch (the message type) is used in the switch
statement’s condition and in every case of the switch,
the message is then copied by a second fetch to a local
buﬀer of a speciﬁc type (and then processed).
Figure 6 shows an example of a double-fetch situ-
ation due to type selection in the ﬁle cxgb3_main.c,
part of a network driver. The function cxgb_exten-
sion_ioctl() ﬁrst fetches the type of the message
(a command for the attached hardware) into cmd from
the pointer into user space useraddr at line 2136.
It
then decides based on cmd which type the message
has (e.g., CHELSIP_SET_QSET_PARAMS, CHELSIP_-
SET_QSET_NUM or CHELSIO_SETMTUTAB) and copies the
complete message into the corresponding structure (of
type ch_qset_params, ch_reg, ch_mtus, ...). The type
of the message will be fetched a second time as part
of the whole message (lines 2149, 2292, 2355 respec-
tively). As long as the header part of the message is not
used again, the double fetch in this situation does not
cause a double-fetch bug. However, if the header part
(the type/command) of the second fetch would be used
again, problems could occur as a malicious user could
have changed the header between the two fetches. In the
case of cxgb_extension_ioctl(), a manual investi-
gation revealed no use of the type part in the buﬀers t,
edata, m, ... and the double-fetch situation here does not
cause a double-fetch vulnerability.
We found 11 occurrences of this double-fetch cate-
gory, 9 of them in drivers. None of the 11 occurrences
used the header part of the second fetch and therefore,
they were not causing double-fetch bugs.
3.2.2 Size Checking
Another common scenario occurs when the actual length
of the message can vary. In this scenario, the message
header is used to identify the size of the complete mes-
sage. The message header is copied to the kernel ﬁrst to
get the message size (ﬁrst fetch), check it for validity, and
2129 static int cxgb_extension_ioctl(struct net_device *dev,
void __user *useraddr)
2130 {
...
2133
...
2136
2137
2138
2139
2140
...
2143
...
2149
2150
2151
2152
...
2238
2239
...
2284
2285
...
2292
2293
2294
2295
2296
...
2313
2314
...
2345
2346
...
2355
2356
2357
2358
2359
2360
...
2369
2370