function collision.
In summary, we prevent malicious clients from causing
inconsistency using an access control policy framework to
limit data damage, non-repudiability of messages to prevent
cross-client impersonation, and an additional hash chain to
ensure clients agree on transaction commit/abort status.
6.2 Lowering transaction latency
We can reduce the number of network round trips required
for a transaction commit from two to one by eliminating
the commit messages Ci, as long as all clients have iden-
tical conﬂict detection logic. If we add another ﬁeld to Pi
indicating the last transaction the submitter has applied to
its local database copy before this attempted transaction,
other clients have enough information to determine the con-
ﬂict status of this transaction! Thus, the commit ﬂag in
Ci.commit is redundant, at the expense of performing the
conﬂict detection across all clients instead of just one.
The hash chain conﬁrmation Ci.pre-hashchain will need
to be placed in Pi, while adding another ﬁeld Ci.pre-
hashchain-location, since the submitter does not have
enough information to build the entire pre-commit hash
chain at this point. Thus, inconsistency checking is delayed
slightly, and it requires longer to detect malicious behav-
ior. Speciﬁcally, an inconsistency introduced due to server
misbehavior will be detected only once a client that has ap-
plied the inconsistent transaction has sent a later update out
to other clients who have seen a different transaction in that
slot. This guarantee about detecting server misbehavior is
similar to the guarantee about detecting client misbehavior
in Section 6.1.
In conclusion, a simple modiﬁcation to this protocol im-
proves transaction latency by eliminating the commit mes-
sage, at the expense of slightly more client computation
time and slightly weaker consistency guarantees.
6.3 Large databases
So far we have not discussed the issue of local space limi-
tations. We assumed up to now that clients can ﬁt the en-
tire database in local (volatile) storage, so that they can run
queries without any help from other parties. If this is not
the case, protocol extensions are necessary to allow clients
to run queries. We discuss several mechanisms below.
On-demand data. Clients can use a separate query
protocol to pull pieces of recent database snapshots from
other clients, or authenticated database snapshots directly
from the provider. This work-around has two drawbacks:
ﬁrst, access pattern privacy is forfeited if clients query the
provider directly for only portions of the database. Second,
performance suffers since sections of the database must
travel the network multiple times.
Large object references. If clients can ﬁt the database
except for a set of large objects, the client can fetch these
encrypted objects from the provider using a separate proto-
col. Access pattern privacy to these objects is lost, however
access pattern privacy to the database indexes is preserved.
In practice, privacy to the indexes is the most important part
of privacy, since the indexes are subject to the largest se-
mantic leaks, since positions within the index are correlated
to contents of the database itself. Thus, this technique offers
a useful privacy/storage tradeoff.
Performance will be mostly unharmed by the large object
references work-around, as long as the bulk of the transac-
tion processing work concerns only index data. The client’s
available storage is well suited for caching some of the most
popular items, so most objects will traverse the network
only a small number of times under most usage patterns.
This technique suggest a modiﬁcation to the transaction
protocol to improve performance, to surpass in some sce-
narios even the performance of the original model: for op-
erations on sets of large objects, clients announce the writes
in the transaction log, but include only a hash of the large
object content. This way, since the large object content is
excluded from the transaction log, clients will not download
the large objects at all, unless they are speciﬁcally needed
for a query.
The only modiﬁcation to the transaction protocol nec-
essary to perform this operation is that clients include the
object ID and a hash of the object content, as the content in
the transaction ﬁeld. Thus, the link (with a checksum and
version) to the object is the stored content in the log and
databases, and the object itself is an external entity. Clients
treat the external object as if the updates occur when the
link occurs in the transaction log, with naturally following
semantics for transaction aborts and so forth.
Large object references with PIR. A Private Informa-
tion Retrieval algorithm can be used to retrieve these large
objects without revealing which objects are being retrieved,
as long as the PIR algorithm does not reveal the size of the
object, or the size of the object is not unique enough to allow
an access pattern privacy-defeating correlation between the
objects. The advantage of the overall scheme in this context
is that access pattern privacy is preserved efﬁciently for the
bulk of the computation; when large objects are retrieved
(presumably less frequently), the more expensive PIR (such
as [68]) is employed to preserve access pattern privacy.
The key to the practicality of all of these alternatives is
that all the database indexes required to satisfy a particular
query can ﬁt simultaneously on a client, and that the client
has enough working memory to perform the necessary joins
efﬁciently. In practice we believe many databases are of a
suitable form, with the bulk of the space consumed by large
objects that do not need to be retrieved to compute joins.
6.4 Expiring Slots
There is a potential denial of service behavior if a client re-
serves a transaction slot but never commits; no transactions
past this slot will be applied. A potential solution is using
“mortal locks” that expire.
The following scenario outlines a method by which
clients can safely delete expired locks: a pre-transaction re-
served slot is only useful for a predetermined amount of
time, speciﬁed by the client as it reserves its slot (or set as
parameter). Clients timestamp the pre-transaction.
If this time has expired and the transaction is still in the
pre-transaction phase, any client is now allowed to abort
this transaction. The client desiring to abort the transaction
simply issues to the storage provider an abort entry for this
slot, which is then appended to the transaction log. The
provider ensures that only the abort or the commit are ap-
pended to the log. The provider decides race conditions, and
one of the operations will fail if both the abort and commit
are issued. Clients can guarantee consistent provider behav-
ior in fulﬁlling these new obligations, by using transaction
hash chains as before: if the (untrusted) provider ever ac-
cepts both the abort message and the commit for a particu-
lar transaction, it will be obvious from the conﬂicting hash
chains once the provider sends updates out (thus maintain-
ing fork consistency).
6.5 Vague Pre-commit
We describe an extension here that allows clients to issue
vague pre-commits, determining the ﬁnal transaction con-
tents only after their request slot has been reserved. This
technique allows improved performance in certain conﬂict-
heavy scenarios, by giving clients the ﬂexibility to choose
their transaction after they are informed of current opera-
tions. Clients might choose to modify their transaction to
avoid conﬂicts, as an example.
In the above described lock-free protocol, clients submit
a pre-commit indicating their pending transaction, then is-
sue a commit or abort on this transaction after checking for
conﬂicts. With an extension we can allow the commit ver-
sion of the transaction to differ from the pre-commit ver-
sion, adding the following ﬁeld to the commit message Ci:
description= The actual transaction to run (instead of the
Pi.description.
The only requirement added is that Ci.description be a
“subset” of Pi.description. That is, any conﬂict that the ﬁ-
nal commit Ci might cause with future transactions would
also be caused by the pre-commit Pi.description. With
this requirement enforced, all client behavior is identical to
what it would have been if the original Pi.description was
Ci.description, with the exception that there might be more
aborts than otherwise. This requirement is thus sufﬁcient to
ensure consistency when clients are honest. In the malicious
client scenario, it is additionally required that all clients can
determine whether any commit Ci.description is indeed a
subset of the pre-commit Pi.description, as they don’t trust
the issuer to make that declaration.
7 Implementation and Experiments
Strawman Implementation (ODP). We built a proof-of-
concept strawman implementation of the Outsourced Dura-
bility Protocol (ODP) using different components in Java,
Python and C. The implementation handles SQL queries
and relational data sets and runs on top of MySQL 5.0
[7], though with minor modiﬁcations we can support other
RDBMS’s. The protocol enables parties with low uptime
to keep databases synchronized through a single, untrusted
third party that has high uptime. Thus we allow safe out-
sourcing of both data backups and data synchronization
through an untrusted provider.
In our particular setup we aimed towards simplicity
rather than performance, giving each client application its
own connection to a single database in the client’s cluster.
These connections are ﬁltered through a proxy, which cap-
tures queries for our protocol to ensure proper propagation
and conﬂict avoidance. Each cluster runs a single process
that communicates with an untrusted service provider con-
duit through symmetric XML-RPC channels.
To ﬁlter queries we use MySQL Proxy [44], an open
source scriptable tool built by the creators of MySQL, al-
lowing capture and insertion of SQL queries and database
responses. This simple setup shows that we can deploy
quickly on existing systems while obtaining reasonable per-
formance; a tailored solution would improve overhead by
eliminating the numerous process forks, ﬁle writes, and
TCP connections initializations in every transaction in the
simple strawman implementation.
Strawman: Throughput Experiments. We performed
experiments aimed at understanding the throughput behav-
Query throughput vs latency
MySQL only
ODP
)
d
n
o
c
e
s
r
e
p
s
e
i
r
e
u
q
(
t
u
p
h
g
u
o
r
h
T
 1000
 100
 10
 1
 0.1
 1
 10
 100
Link latency (ms)
Figure 2. Query throughput in transactions
per second vs.
link latency, with log scale
axes. Both MySQL and ODP quickly converge
to a relationship inversely proportional to link
latency.
ior of our mechanisms. Given their network-dependent na-
ture we focused on understanding how network characteris-
tics impact performance.
The experimental setup consists of an (untrusted)
“server” and several “clients” connected directly through a
1Gbps router. The server is a Dell PowerEdge 2850 running
Centos 4.1 with 4 Dual core Xeons and 4GB RAM, The
clients were Lenovo Thinkpads with an Intel Pentium Core
2 Duo 1.8GHz CPU running Redhat Fedora 9, and Pentium
4 Redhat Fedora 8 desktop machines. We measured overall
throughput in a setting where the two clients simultaneously
issued transactions to the server running our ODP software,
connecting to a MySQL database through MySQL Proxy
[44]. As a baseline control setup we ran the same clients
connected directly to the server-hosted MySQL database.
We soon discovered that in this setup the 1GBps network
bandwidth is easily surpassing the processing ability of our
baseline, thus we focused mainly on understanding the be-
havior of ODP vs. baseline MySQL as a function of net-
work latency. To this end we modulated network latency
at the kernel level using the NetEm [36] network emulation
tool, which delays packets in the outgoing network queue1
Figure 2 shows the throughput in queries per second
obtained using a remote MySQL database with no server
guarantees, and the throughput obtained in our strawman
ODP implementation with full privacy and correctness as-
1Effective bandwidth was also slightly decreased by the latency, since
the TCP window sizes are ﬁxed.
surances. We vary link latency from 0.1ms to 100ms, sam-
pling at growing intervals to suit the log scale X axis.
From Strawman to Efﬁcient Prototype. The strawman
ODP implementation could support over 30 queries per sec-
ond with full assurances. We believe this throughput can be
increased by at least one order of magnitude by an industry
level prototype which would consider the following bottle-
necks of the strawman solution.
Multiple process forks. We used Java to manage all
the communication aspects, as its pre-existing constructs re-
duce coding and debugging time. Additionally, a C-based
Lex/Yacc parser was the most natural mechanism to detect
conﬂicts between SQL transactions. To obtain the most
functionality in the shortest amount of time, we decided
to launch a new Lex/Yacc based conﬂict detection process
from Java for every SQL statement. The result is that we
incur several process forks for each processed transaction,
launching both a shell and the parser once for each state-
ment in each transaction on each client. Additionally, the
conﬂict detection operates as a separate C-based executable.
While process forks themselves are relatively cheap, incur-
ring several in succession while the client waits for the com-
mit creates a low performance cap. We proﬁled the time
required to launch a shell and application at approximately
2ms – this accounts for a large portion of our overhead.
Synchronous client. The MySQL command line and
stdin piping was used as our application client. This in-
curs the full latency of each transaction as a transaction
throughput cap. Having two concurrent clients alleviates
this slightly, but issuing multiple simultaneous transactions
from each client would decrease the impact of latency on
throughput. Additionally, part of this beneﬁt can be re-
ceived by continuing each single-threaded client before the
commit has been applied – even at the risk of causing more
conﬂicts, e.g., by creating the possibility for client conﬂicts
with itself.
Multiple TCP connection setups.
Instead of reusing
client-server TCP connections, the strawman creates a new
connection on each request. Multiple requests are con-
structed per transaction. This design choice is a result of
the Java XMLRPC server we are building on; this slow-
down can be eliminating by choosing a different XMLRPC
implementation.
Java VM overhead. Choosing Java as the implementa-
tion language allowed quick prototyping. The disadvantage
is that the Java VM (even after just-in-time compilation) can
run many (I/O) tasks slower than a streamlined implemen-
tation compiled to machine byte code. MySQL, by compar-
ision, is implemented in C.
Lua scripting overhead. The MySQL Proxy allows the
capture of sessions without re-building a custom MySQL
listener. This allowed fast integration with MySQL-enabled
applications. The interface to MySQL proxy consists of a
Lua [44] script parsed at runtime. Application logic in this
Lua script runs considerably slower than it would if imple-