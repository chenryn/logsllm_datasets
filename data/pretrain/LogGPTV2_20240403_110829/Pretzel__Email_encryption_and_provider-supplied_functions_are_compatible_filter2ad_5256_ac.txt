classification. But adapting it to an end-to-end system for encrypted
email requires work. The main issue is costs. As examples, for
a spam classification model with N = 5M features, the protocol
consumes over 1 GB of client-side storage space; for topic extraction
with B = 2048 categories, it consumes over 150 ms of provider-side
cpu time and 8 MB in network transfers (§6). Another thing to
consider is the robustness of the guarantees.
This section describes Pretzel’s refinements, adjustments, and
modifications. The nature of the work varies from low-level cryp-
tographic optimizations, to architectural rearrangement, to applica-
tions of known ideas (in which case the work is demonstrating that
they are suitable here). We begin with refinements that are aimed
at reducing costs (§4.1–§4.3), the effects of which are summarized
in Figure 3; then we describe Pretzel’s robustness to misbehaving
parties (§4.4).
4.1 Replacing the cryptosystem
Both Pretzel and the baseline require additively homomorphic en-
cryption (Figure 2). The traditional choice for AHE—it is used in
prior works [19, 75, 100, 106]—is Paillier [99], which is based on
a longstanding number-theoretic presumed hardness assumption.
However, Paillier’s Dec takes hundreds of microseconds on a mod-
ern CPU, which contributes substantially to provider-side cpu time.
Instead, Pretzel turns to a cryptosystem based on the Ring-LWE
assumption [90], a relatively young assumption (which is usually
a disadvantage in cryptography) but one that has nonetheless re-
ceived a lot of recent attention [18, 34, 46, 91, 101, 105]. Specifically,
Pretzel incorporates the additively homomorphic cryptosystem of
Brakerski and Vaikuntanathan [34], as implemented and optimized
by Melchor et al. [20] in the XPIR system; we call this xpir-bv.
This change brings the cost of each invocation of Dec down by
over an order of magnitude, to scores of microseconds (§6), and
similarly with Enc. The gain is reflected in the cost model (Figure 3),
in replacing dpail with dxpir (likewise with epail and expir, etc.)
However, the change makes ciphertexts 64× larger: from 256 bytes
to 16 KB. Yet, this is not the disaster that it seems. Network costs
do increase (in Figure 2, step 2c), but by far less than 64×. Because
the domain of the encryption function (that is, the size of the plain-
text space) grows, one can tame what would otherwise be a large
increase in network and storage, and also gain further cpu savings.
We describe this next.
4In more detail, the AHE has public parameters which, if chosen adversely (non-
randomly) would undermine the expected usage. To get around this, Pretzel deter-
mines these parameters with Diffie-Hellman key exchange so that both parties inject
randomness into these parameters [48, 50, 94, 110].
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
T. Gupta et al.
Non-private
Baseline (§3.3)
N · βpail ·epail +Kcpu
Kcpu
N · βpail ·cpail +Knet
N · βpail ·cpail
N/A
N/A
N/A
N/A
L·h +L·B·g
N/A
szemail
Setup
Provider cpu time
Client cpu time
Network transfers
Client storage
Per-email
Provider cpu
Client cpu
Network
L = number of features in an email (§3.3)
B = number of categories in the model (§3.3)
szemail = size of an email
βpail := ⌈B/ppail⌉, βxpir := ⌈B/pxpir⌉
e = encryption cpu time in an AHE scheme
d = decryption cpu time in an AHE scheme
a = homomorphic addition cpu time in an AHE scheme (Fig. 2)
b = log L+bin +fin (§4.2)
fin = # of bits for the frequency of a feature in an email (§4.2)
xpir := ⌊B/pxpir⌋ +1/⌊pxpir/k⌋ where k = (B mod pxpir)
β′
β′′
xpir := βxpir (if spam) or B′ (if topics)
βpail ·dpail +B·yper-in
L· βpail ·apail +βpail ·epail +B·yper-in
szemail + βpail ·cpail +B·szper-in
Pretzel (§4.1–§4.3)
N′ · β′
Kcpu
N′ · β′
N′ · β′
xpir ·expir +Kcpu
xpir ·cxpir +Knet
xpir ·cxpir
xpir ·dxpir +B′ ·yper-in
β′′
L· βxpir ·axpir + (L+B′) ·s +β′′
xpir ·cxpir +B′ ·szper-in
szemail + β′′
xpir ·expir +B′ ·yper-in
h = cpu time to extract a feature and lookup its conditional probabilities
g = cpu time to add two probabilities
N = number of features in the model (§3.3)
p = # of b-bit probabilities packed in a ciphertext (§4.2)
Kcpu, Knet = constants for cpu and network costs (§3.3)
c = ciphertext size in an AHE scheme
yper-in, szper-in = Yao cpu time and network transfers per b-bit input (§3.2)
bin = # of bits to encode a model parameter (§4.2)
N′ = # of features selected after aggressive feature selection (§4.3) (N′ =N if spam)
B′ = # of candidate topics (≪ B) (§4.3) (B′ =B if spam)
s = “left-shift” cpu time in xpir-bv (§4.2)
Figure 3: Cost estimates for classification. Non-private refers to a system in which a provider locally classifies plaintext email. The baseline
is described in Section 3.3. Microbenchmarks are given in §6.
4.2 Packing in Pretzel
The basic idea is to represent multiple plaintext elements (for ex-
ample, model parameters) in a single ciphertext; this opportunity
exists because the domain of Enc is much larger than any single
element that needs to be encrypted. Using packing, one can reduce
the number of invocations of Enc and Dec in Figure 2, specifically
in step 1b, step 2b, and step 3. The consequence is a significant
reduction in resource consumption, specifically client storage for
spam filtering, and provider cpu time for topic extraction.
A common packing technique—it is used in GLLM [60], Pret-
zel’s baseline (§3.3), and the works that build on GLLM [19, 75]—
traverses each row in the matrix from left to right and encrypts
together sets of elements, while restricting the packing to be within
the given rows. Although better than no packing, this technique
does not always fully utilize the space in a ciphertext. For example,
when the number of elements in a matrix row is two (as in the
spam filtering application) and the number of elements that can be
packed together is 1024 (as in the xpir-bv ciphertexts), then 1022
“slots” remain unutilized.
Recent packing techniques, proposed in the context of aggre-
gation queries on encrypted databases [119] and homomorphic
evaluation of AES-128 encryption [59], address the limitation de-
scribed above, by packing across both columns and rows. These
techniques traverse the matrix in row-major order without restrict-
ing the packing to be within a row (see the rightmost matrix in
Figure 4), thereby utilizing the “empty slots” in a ciphertext.
Pretzel incorporates both types of techniques described above.
Below, we describe the relevant details on how and where these
techniques are incorporated.
Details. Let p be the number of elements that can be packed to-
gether in a ciphertext, and let b be the number of semantically
useful bits in a dot product output. Then, in step 1b in Figure 2,
Pretzel splits (not depicted in the figure) the matrix {(⃗vj, p(Cj ))}
into zero or more sets of p column vectors plus up to one set with
fewer than p vectors as depicted in Figure 4. For the sets with p
vectors, it packs together all p elements of a row [60]. For the last
set, it packs elements in row-major order under one constraint: ele-
ments in the same row of the matrix must not be put into different
ciphertexts [59, 119].
Then, to compute dot products (in step 2a in Figure 2) for all
columns except those in the rightmost matrix (Figure 4), Pretzel uses
the fact that that the elements that need to be added are aligned [60].
For example, if the elements in the first row (v1,1, . . . , v1,p) are
to be added to those in the second row (v2,1, . . . , v2,p), then the
ciphertext space operation applied to c1 = Enc(pk, v1,1∥ . . . ∥v1,p)
and c2 = Enc(pk, v2,1∥ . . . ∥v2,p) yields c3 = c1 · c2 = Enc(pk, v1,1 +
v2,1∥ . . . ∥v1,p + v2,p). For this to work, the individual sums (for
example, v1,p + v2,p) cannot overflow b bits.
For the columns that are in the rightmost matrix (Figure 4), Pret-
zel performs dot products by exploiting the homomorphism to
cyclically rotate the packed elements in a ciphertext [59]. For exam-
ple, assume c = Enc(pk, v1,1∥ . . . ∥v1,k∥v2,1∥ . . . ∥v2,k ) is a packed
ciphertext, where v1,1, . . . , v1,k are elements from the first row, and
v2,1, . . . , v2,k are from the second row. To add each v1,i with v2,i
for i ∈ {1, . . . , k}, one can left-shift elements in c by k positions
to get c′ = Enc(pk, v2,1∥ . . . ∥v2,k∥ . . .); this is done by applying
the “constant multiplication” operation (Figure 2, bullet 2), with
z = 2k·b. At this point, the rows are lined up, and one can operate
on c and c′ to add the plaintext elements.
We haven’t yet said how the values of p and b are determined.
Let G denote the number of bits in the domain of the encryption
algorithm Enc, bin denote the number of bits required to represent
an element that would be encrypted (a model parameter in our case),
Pretzel: Email encryption and provider-supplied functions are compatible
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
This step relies on a proprietary model and is done using secure
two-party machinery. Thus, the costs of the expensive part
of the protocol are now proportional to B′ rather than to B
(the gain is reflected in Figure 3, the last two columns of the
“per-email” rows).
For this arrangement to make sense, several requirements must
be met. First, the client needs to be able to perform the map in
step (i) locally. Here, Pretzel exploits an observation: topic lists (the
set S) are public today [8]. They have to be, so that advertisers can
target and users can set interests. Thus, a client can in principle
use some non-proprietary classifier for step (i). Pretzel is agnostic
about the source of this classifier; it could be supplied by the client,
the provider, or a third party.
Second, the arrangement needs to be accurate, which it is when
S′ contains S∗. Pretzel observes that although the classifier used
in step (i) would not be honed, it doesn’t need to be, because
it is performing a far coarser task than choosing a single topic.
Thus, in principle, the step (i) map might reliably produce accu-
rate outputs—meaning that the true topic, S∗, is among the B′
candidates—without much training, expertise, or other proprietary
input. Our experiments confirm that indeed the loss of end-to-end
accuracy is small (§6.2).
Finally, step (ii) must not reveal S′ to the provider, since that
would be more information than a single extracted topic. This rules
out instantiating step (ii) by naively applying the existing proto-
col (§3.3–§4.2), with S′ in place of S. Pretzel’s response is depicted
in Figure 5. There are some low-level details to handle because of
the interaction with packing (§4.2), but at a high level, this proto-
col works as follows. The provider supplies the entire proprietary
model (with all B topics); the client obtains B dot products, in en-
crypted form, via the inexpensive component of Yao+gllm (secure
dot product). The client then extracts and blinds the B′ dot products
that correspond to the candidate topics. The parties finish by using
Yao to privately identify the topic that produced the maximum.
Feature selection. Protocol storage is proportional to N (Figure 2,
“setup phase”). Pretzel’s response is the standard technique of fea-
ture selection [116]: incorporating into the model the features most
helpful for discrimination. This takes place in the “setup phase” of
the protocol (the number of rows in the provider’s matrix reduces
from N to N ′; for the resulting cost reductions, see the last two
columns of the “setup” rows in Figure 3). Of course, one presumes
that providers already prune their models; the proposal here is to
do so more aggressively. Section 6.2 shows that in return for large
drops in the number of considered features, the accuracy drops
only modestly. In fact, reductions of 75% in the number of features
is a plausible operating point.
Cost savings. Feature selection reduces client-storage costs by
a factor of N /N ′. For B = 2048, B′ = 20, and L = 692 (average
number of features per email in the authors’ emails), relative to the
protocol in §4.2, the provider cpu drops by 45×, client cpu drops
by 8.4×, and the network transfers drop by 20.4× (§6.2). Thus, the
aforementioned two orders of magnitude (above the non-private
version) becomes roughly 5×.
Figure 4: Packing in Pretzel. Light gray rectangles represent matrix
columns (⃗v1, . . . ,⃗vB); dark gray represent ciphertexts. The arrange-
ment in matrices with p columns follows GLLM [60]; the matrix
with < p columns follows Gentry et al. [59].
and fin denote the number of bits for the multiplier of an encrypted
element (frequency of a feature extracted from an email in our