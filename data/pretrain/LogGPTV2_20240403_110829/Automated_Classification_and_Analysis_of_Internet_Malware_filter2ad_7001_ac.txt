stantial. Therefore, we require an automated means of discovering where the
most important changes occur.
Table 8. The clusters generated via our technique for the malware listed in Table 6
Cluster Elements Overlap Example
67.86% scans 25
97.96% installs a cygwin rootkit
c1
C, D
c2 A, B
c3
c4
E, G, H 56.60% disables AV
F, I, J
53.59% IRC
To address this limitation, we adopt an “inconsistency” measure that is used
to compute the diﬀerence in magnitude between distances of clusters so that the
tree can be cut into distinct clusters. Clusters are constructed from the tree by
ﬁrst calculating the inconsistency coeﬃcient of each cluster, and then threshold-
ing based on the coeﬃcient. The inconsistency coeﬃcient characterizes each link
in a cluster tree by comparing its length with the average length of other links
at the same level of the hierarchy. The higher the value of this coeﬃcient, the
less similar are the objects connected by the link. The inconsistency coeﬃcient
calculation has one parameter, which is the depth below the level of the current
188
M. Bailey et al.
Inconsistency-based Tree Cutting
Normalized Compression Distance
Single-Linkage Hierarchical Clustering
3e+08
2.5e+08
2e+08
s
e
t
y
B
1.5e+08
1e+08
5e+07
100
10
1
0.1
0.01
0.001
s
d
n
o
c
e
S
Inconsistency-based Tree Cutting
Normalized Compression Distance
Single-Linkage Hierarchical Clustering
0
0
100
200
400
Number of Malware to Cluster
300
500
600
0.0001
0
100
200
400
Number of Malware to Cluster
300
500
600
Fig. 3. The memory and runtime required for performing clustering based on the num-
ber of malware clustered (for a variety of diﬀerent sized malware behaviors)
link to consider in the calculation. All the links at the current level in the hier-
archy, as well as links down to the given depth below the current level, are used
in the inconsistency calculation.
In Table 8 we see the result of the application of this approach to the exam-
ple malware in Table 6. The 10 unique pieces of malware generate four unique
clusters. Each cluster shows the elements in that cluster, the average number of
unique behaviors in common between the clusters, and an example of a high-level
behavior in common between each binary in the cluster. For example, cluster one
consists of C and D and represents two unique behaviors of mytob, a mass mail-
ing scanning worm. Five of the behaviors observed for C and D are identical
(e.g., scans port 25), but several others exhibit some behavioral polymorphism
(e.g., diﬀerent run on reboot registry entries). The other three clusters exhibit
similar expected results, with cluster two representing the cygwin backdoors,
cluster three the bancos variants, and cluster four a class of IRC backdoors.
4 Evaluation
To demonstrate the eﬀectiveness of behavioral clustering, we evaluate our tech-
nique on the large and small datasets discussed in section 2. We begin by demon-
strating the runtime performance and the eﬀects of various parameters on the
system. We then show the quality or goodness of the clusters generated by our
system by comparing existing AV groups (e.g., those labeled as SDBot) to our
clusters. Next we discuss our clusters in the context of our completeness, concise-
ness, and consistency criteria presented earlier. Finally, we illustrate the utility
of the clusters by answering relevant questions about the malware samples.
4.1 Performance and Parameterization
We now examine the memory usage and execution time for the hierarchical
clustering algorithm. To obtain these statistics, we take random sub-samples of
length between 1 to 526 samples from the small dataset. For each sub-sample,
Automated Classiﬁcation and Analysis of Internet Malware
189
s
r
e
t
s
u
l
C
f
o
r
e
b
m
u
N
325
300
275
250
225
200
175
150
125
100
75
50
25
0
0
Depth
1
2
4
6
8
10
12
14
10000
1000
100
10
1
Average Cluster Size
Number of Clusters
1
2
Inconsistency Threshold
3
4
0.1
0
0.5
1
1.5
Inconsistency
2
2.5
3
Fig. 4. On the left, the number of clusters generated for various values of the inconsis-
tency parameter and depth. On the right, the trade-oﬀ between the number of clusters,
the average cluster size, and the inconsistency value.
we analyze its run time and memory consumption by running ten trials for each.
The experiments were performed on a Dell PowerEdge 4600 with two Intel Xeon
MP CPUs (3.00GHz), 4 GB of DDR ECC RAM, 146G Cheetah Seagate drive
with an Adaptec 3960D Ultra160 SCSI adapter, running Fedora Core Linux.
We ﬁrst decompose the entire execution process into ﬁve logical steps: (1)
trace collection, (2) state change extraction, (3) NCD distance matrix compu-
tation: an O(N 2) operation, (4) clustering the distance matrix into a tree, (5)
cutting the tree into clusters. We focus on the latter three operations speciﬁc to
our algorithm for performance evaluation. Figure 3 shows the memory usage for
those three steps. As expected, computing NCD requires the most memory with
quadratic growth with an increasing number of malware for clustering. However,
clustering 500 malware samples requires less than 300MB of memory. The mem-
ory usage for the other two components grows at a much slower rate. Examining
the run-time in Figure 3 indicates that all three components can complete within
hundreds of seconds for clustering several hundred malware samples.
Phases 1-4 of the system operate without any parameters. However, the tree-
cutting algorithm of phase 5 has two parameters: the inconsistency measure and
the depth value. Intuitively, larger inconsistency measures lead to fewer clus-
ters and larger depth values for computing inconsistency result in more clusters.
Figure 4 illustrates the eﬀects of depth on the number of clusters produced
for the small dataset for various inconsistency values. Values of between 4-6
for the depth (the 3rd and 4th colored lines) appear to bound the knee of the
curve. In order to evaluate the eﬀect of inconsistency, we ﬁxed thedepth to 4
and evaluated the number of clusters versus the average size of the clusters for
various inconsistency values in the large dataset. The results of this analysis,
shown in Figure 4, show a smooth trade-oﬀ until an inconsistency value between
2.2 and 2.3, where the clusters quickly collapse into a single cluster. In order
to generate clusters that are as concise as possible without, losing important
190
M. Bailey et al.
feature information, the experiments in the next selection utilize values of depth
and inconsistency just at the knee of these curves. In this case, it is a depth
value of 4 and an inconsistency value of 2.22.
4.2 Comparing AV Groupings and Behavioral Clustering
To evaluate its eﬀectiveness, we applied our behavioral clustering algorithm on
the large dataset from Section 2. Our algorithm created 403 clusters from the
3,698 individual pieces of malware using parmeters discussed above. While it
is infeasible to list all the clusters here, a list of the clusters, the malware and
behaviors in each cluster, and their AV labels are available at
http://www.eecs.umich.edu/~mibailey/malware/.
As a ﬁrst approximation of the quality of the clusters produced, we returned
to our example in Section 2 and evaluated the clustering of various malware sam-
ples labeled as SDBot by the AV systems. Recall from our previous discussions
that various AV systems take diﬀering approaches to labeling malware—some
adopt a general approach with malware falling into a few broad categories and
others apply more speciﬁc, almost per sample, labels to each binary. We expect
that a behavior-based approach would separate out these more general classes if
their behavior diﬀers, and aggregate across the more speciﬁc classes if behaviors
are shared. Looking at these extremes in our sample, Symantec, who adopts
a more general approach, has two binaries identiﬁed as back-door.sdbot. They
were divided into separate clusters in our evaluation based on diﬀering processes
created, diﬀering back-door ports, diﬀering methods of process invocation or re-
boot, and the presence of AV avoidance in one of the samples. On the other
extreme, FProt, which has a high propensity to label each malware sample in-
dividually, had 47 samples that were identiﬁed as belonging to the sdbot family.
FProt provided 46 unique labels for these samples, nearly one unique label per
sample. In our clustering, these 46 unique labels were collapsed into 15 unique
clusters reﬂecting their overlap in behaviors. As we noted in Section 2, these
grouping have diﬀering semantics—both Symantec labels were also labled by
FProt as SDBot, but obviously not all FProt labels were identiﬁed as SDBot
by Symantec. Both of these extremes demonstrate the utility of our system in
moving toward a labeling scheme that is more concise, complete, and consistent.
4.3 Measuring the Completeness, Conciseness and Consistency
We previously examined how the clusters resulting from the application of our
algorithm to the large dataset compared to classiﬁcation of AV systems. In this
section, we examine more general characteristics of our clusters in an eﬀort
to demonstrate their quality. In particular, we demonstrate the completeness,
conciseness, and consistency of the generated clusters. Our analysis of these
properties, summarized in Table 9, are highlighted each in turn:
Completeness. To measure completeness, we examined the number of times
we created a meaningful label for a binary and compared this to the detection
rates of the various AV products. For AV software, “not detected” means no
Automated Classiﬁcation and Analysis of Internet Malware
191
Table 9. The completeness, conciseness, and consistency of the clusters created with
our algorithm on the large dataset as compared to various AV vendors
Completeness
Conciseness
Consistency
AV
Detected Not Detected % Detected Unique Clusters or Identical Behavior
Lables Families Labeled Identically
McAfee
F-Prot
ClamAV
2018
2958
2244
2960
Symantec
1904
Behavior 3387
Trend
1680
740
1454
738
1794
311
54.6%
80.0%
60.7%
80.0%
51.5%
91.6%
308
1544
1102
2034
125
403
84
194
119
137
107
403
47.2%
31.1%
34.9%
44.2%
68.2%
100%
signature matched, despite the up-to-date signature information. For behavioral
clustering, “not detected” means that we identiﬁed no behavior. A unique aspect
of this system is that our limiting factor is not whether we have seen a particular
binary before, as in a signature system, but whether we are able to extract
meaningful behavior. Any such behavior can be clustered in the context of any
number of previously observed malware instances and diﬀerentiated, although
this diﬀerentiation is clearly more valuable the more instances that are observed.
In our experiments, roughly 311 binaries exhibited no behavior. The root cause of
these errors, and a more complete discussion of the general limitations of dynamic
path exploration, is available in the Limitations section. A striking observation
from the table is that many AV software systems provide detection rates as low
as 51%, compared to around 91% using behavioral clustering. It should be noted
that these numbers are as much an indication of the mechanisms the vendors
use to collect malware as the AV systems themselves, since signature systems
can clearly only detect what they have seen before. While it would be unfair
to judge the detection rates based on previously unseen malware, we hesitate
to point out that our system for collection of these binaries is not unique. In