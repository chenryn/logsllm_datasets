These vibrations can be collected by an accelerometer (e.g.,
of a smartphone) and analyzed to determine pressed keys [18].
Analyzing movements of the user’s hands and ﬁngers on a
keyboard represents another way of recovering input. This
is possible by video-recording a typing user [4] or by using
WiFi signal ﬂuctuation on the user’s laptop [2].
3. SYSTEM AND THREAT MODELS
To identify precise attack scenarios, we begin by deﬁn-
ing the system model that serves as the base for S&T. Sec-
tion 3.1 describes our assumptions about the victim and the
attacker, and then carefully deﬁnes the problem of remote
keyboard acoustic eavesdropping. Section 3.2 then presents
some realistic attack scenarios and discusses them in relation
to the state-of-the-art.
3.1 System Model
The system model is depicted in Figure 1. We assume
that the victim has a desktop or a laptop computer with a
built-in or attached keyboard, i.e., not a smartphone or a
tablet-like device. Hereafter, it is referred to as target-device.
A genuine copy of some VoIP software is assumed to be
installed on target-device; this software is not compromised
in any way. Also, target-device is connected to the Internet
and engaged in a VoIP call with at least one party who plays
the role of the attacker.
Figure 1: System model.
The attacker is a malicious user who aims to learn some
private information about the victim. The attacker owns
and fully controls a computer that we refer to as attack-device,
which has a genuine (unmodiﬁed) version of the same VoIP
software as target-device. The attacker uses attack-device to
receive and record the victim’s acoustic emanations using
VoIP software. We assume that the attacker relies solely
on information provided by VoIP software. In other words,
during the attack, the attacker receives no additional acous-
tic information from the victim, besides what VoIP software
transmits to attack-device.
3.2 Threat Model
S&T attack transpires as follows: during a VoIP call be-
tween the victim and the attacker, the former types some-
thing on target-device, e.g., a text of an email message or a
password. We refer to this typed information as target-text.
Typing target-text causes acoustic emanations from target-
device’s keyboard, which are picked up by the target-device’s
microphone and faithfully transmitted to attack-device by
VoIP. The goal of the attacker is to learn target-text by taking
advantage of these emanations.
We make the following assumptions:
• As mentioned above, the attacker has no real-time
audio-related information beyond that provided by VoIP
software. Acoustic information can be degraded by
VoIP software by downsampling and mixing. In partic-
ular, without loss of generality, we assume that audio
is converted into a single (mono) signal, as is actually
the case with some VoIP software, such as Skype and
Google Hangouts.
• If the victim discloses some keyboard acoustic emana-
tions together with the corresponding plaintext – the
actual pressed keys (called ground truth) — the vol-
ume of this information is small, on the order of a chat
message or a short e-mail. We expect it to be no more
than a few hundred characters.
• target-text is very short (e.g., ≈ 10 characters) and ran-
dom, corresponding to an ideal password. This keeps
S&T attack as general as possible, since dictionary
words are a “special” case of random words, where op-
timization may be possible.
We now consider some realistic S&T attack scenarios. We
describe them starting with the more generous setting where
the attacker knows the victim’s typing style and keyboard
model, proceeding to the more challenging one where the
attacker has neither type of information.
1) Complete Profiling: In this scenario, the attacker
knows some of the victim’s keyboard acoustic emanations on
target-device, along with the ground truth for these emana-
tions. This might happen if the victim unwittingly provides
some text samples to the attacker during the VoIP call, e.g.,
sends chat messages, edits a shared document, or sends an
email message3. We refer to such disclosed emanations as
“labeled data”. To be realistic, the amount of labeled data
should be limited to a few samples for each character.
We refer to this as Complete Proﬁling scenario, since the
attacker has maximum information about the victim. It cor-
responds to attack scenarios used in prior supervised learn-
ing approaches [3, 11, 12, 19], with the diﬀerence that we
collect acoustic emanations using VoIP software, while oth-
ers collect emanations directly from microphones that are
physically near target-device.
3Ground truth could also be collected oﬄine, if the attacker
happened to be near the victim, at some point before or
after the actual attack. Note that this still does not require
physical proximity between the attacker and the victim in
real time.
InternetconnectionAttackerVictimTarget-deviceAttack-device7052) User Profiling:
In this scenario, we assume that
the attacker does not have any labeled data from the victim
on target-device. However, the attacker can collect training
data of the victim while the victim is using the same type of
device (including the keyboard) as target-device4. This can be
achieved via social engineering techniques or with the help
of an accomplice. We refer to this as User Proﬁling scenario,
since, unable to proﬁle target-device, the attacker proﬁles the
victim’s typing style on the same device type.
3) Model Profiling: This is the most challenging, though
the most realistic, scenario. The attacker has absolutely no
training data for the victim.The attacker and the victim are
engaged in a VoIP call and information that the attacker
obtains is limited to victim keyboard’s acoustic emanations.
The attacker’s initial goal is to determine what laptop
the victim is using. To do so, we assume that the attacker
maintains a database of sounds from previous attacks. If the
attacker already proﬁled the model of the current victim’s
target-device, it can use this information to mount the attack.
We refer to this as Model Proﬁling scenario, since although
the attacker can not proﬁle the current victim, it can still
proﬁle a device of the same model as target-device.
4. SKYPE & TYPE ATTACK
This section provides a detailed description of S&T attack.
Recall that all envisaged scenarios involve the attacker en-
gaged in a VoIP call with the victim. During the call, the
victim types something on target-device’s keyboard. S&T at-
tack proceeds as described below and illustrated in Figure 2.
2. Data classiﬁcation phase includes target-device classi-
ﬁcation and key classiﬁcation steps. Their execution
depends on the speciﬁc attack scenario:
– In Complete Proﬁling and User Proﬁling scenar-
ios, the attacker already proﬁled the victim, either on
target-device (Complete Proﬁling) or on a device of the
same model (User Proﬁling). The attacker uses this
data as a training set, and proceeds to classify target-
text. This case is indicated in Figure 2 by the path
where key classiﬁcation follows feature extraction.
– In Model Proﬁling scenario, since the attacker has no
knowledge of the victim’s typing style or target-device,
it begins by trying to identify target-device by classify-
ing its keyboard sounds. The attacker then proceeds
to classify target-text by using correct training data.
This case is indicated in Figure 2 by the path where
target-device classiﬁcation is the next step after feature
extraction.
Next, we describe these two phases in more detail.
4.1 Data Processing Phase
The main goal in this phase is to extract meaningful fea-
tures from acoustic information. The ﬁrst step is data seg-
mentation needed to isolate distinct keystroke sounds within
the recording. Subsequently, using these sound samples, we
build derived values (called features) that represent proper-
ties of acoustic information. This step is commonly referred
to as feature extraction.
4.1.1 Data Segmentation
We perform data segmentation according to the following
observation: the waveform of a keystroke sound presents
two distinct peaks, shown in Figure 3. These two peaks
correspond to the events of: (1) the ﬁnger pressing the key
– press peak, and (2) the ﬁnger releasing the key – release
peak. Similar to [3], we only use the press peak to segment
the data and ignore the release peak. This is because the
former is generally louder than the latter and is thus easier
to isolate, even in very noisy scenarios.
Figure 2: S&T attack steps.
First, the attacker receives and records acoustic emana-
tions of target-device’s keyboard over VoIP. One way to do so
is by channeling VoIP output to some local recording soft-
ware. Then, the actual attack involves two phases: (i) data
processing, and (ii) data classiﬁcation. Each phase involves
two steps:
1. Data processing includes data segmentation and fea-
ture extraction steps. They are performed in each of
the three attack scenarios deﬁned in Section 3.
4In case the target-device is a desktop, knowing the model of
the desktop does not necessarily mean knowing the type of
the keyboard. However, in mixed video/audio call the key-
board model might be visually determined, when the key-
board is placed in the visual range of the camera.
Figure 3: Waveform of the “A” key, recorded on an
Apple Macbook Pro 13” laptop.
To perform automatic isolation of keystrokes, we set up
a detection mechanism as follows: we ﬁrst normalize the
amplitude of the signal to have root mean square of 1. We
0900018000Samples-0.4-0.20.00.20.4AmplitudePresspeakReleasepeak706then sum up the FFT coeﬃcients over small windows of
10ms, to obtain the energy of each window. We detect a
press event when the energy of a window is above a certain
threshold, which is a tunable parameter. We then extract
the subsequent 100ms [5, 32] as the waveform of a given
keystroke event. If sounds of pressed keys are very closely
spaced, it is possible to extract a shorter waveform.
4.1.2 Feature Extraction
As features, we extract the mel-frequency cepstral coeﬃ-
cients (MFCC) [16]. These features capture statistical prop-
erties of the sound spectrum, which is the only information
that we can use. Indeed, due to the mono acoustic informa-
tion, it is impossible to set up an attack that requires stereo
audio and uses TDoA, such as [15, 28, 31]. Among possi-
ble statistical properties of the sound spectrum – including:
MFCC, FFT coeﬃcients, and cepstral coeﬃcients – we chose
MFCC which yielded the best results. To select the most
suitable property, we ran the following experiment:
Using a Logistic Regression classiﬁer we classiﬁed
a dataset with 10 samples for each of the 26 keys
corresponding to the letters of the English al-
phabet, in a 10-fold cross-validation scheme. We
then evaluated the accuracy of the classiﬁer with
various spectral features: FFT coeﬃcients, cep-
stral coeﬃcients, and MFCC.
We repeated this experiment with data from ﬁve users on
a Macbook Pro laptop. Accuracy results were: 90.61% (±
3.55%) for MFCC, 86.30% (± 6.34%) for FFT coeﬃcients,
and 51% (± 18.15%) for cepstral coeﬃcients. This shows
that MFCC oﬀers the best features. For MFCC experiments
we used parameters similar to those in [32]: a sliding window
of 10ms with a step size of 2.5ms, 32 ﬁlters in the mel scale
ﬁlterbank, and used the ﬁrst 32 MFCC.
4.2 Classiﬁcation Phase
In this phase, we apply a machine learning algorithm to
features extracted in the Data Processing phase, in order to
perform:
• Target-device classiﬁcation using all keystroke sound em-
• Key classiﬁcation of each single keyboard key of target-
device, by using sound emanations of the keystrokes.
anations that the attacker received.
Each classiﬁcation task is performed depending on the sce-
nario. In Complete Proﬁling and User Proﬁling scenarios,
the attacker already proﬁled the victim on target-device, or on
a device of the same model, respectively. Then, the attacker
loads correct training data and performs the key classiﬁca-
tion task, to understand target-text.
In contrast, in Model Proﬁling scenario, the attacker ﬁrst
performs target-device classiﬁcation task, in order to identify
the model. Next, the attacker loads correct training data,
and proceeds to the key classiﬁcation task.
The only viable machine learning approach for both the
key and target-device classiﬁcation tasks is a supervised learn-
ing technique. As discussed in Section 3.2, approaches that
require lots of data to cluster, such as [5], are incompatible
with our assumptions, because we might have only a small
amount of both training and testing data. Moreover, poten-
tial randomness of target-text makes it impossible to realize
constraint-based approaches, which would require target-text
to be a meaningful word, as in [32].
4.2.1 Target-device Classiﬁcation
We consider the task of target-device classiﬁcation as a mul-
ticlass classiﬁcation problem, where diﬀerent classes corre-
spond to diﬀerent target-device models known to the attacker.
More formally, we deﬁne the problem as follows:
We start with a number of samples s ∈ S, each
represented by its feature vector (cid:126)s, and generated
by the same target-device l of model ˜l, among a
set L of known target-device models. We want
to know which target-device model generated the
samples in S, by classifying every sample s, and
then taking the mode of these predictions.
To perform this classiﬁcation task, we use a k-nearest neigh-
bors (k-NN) classiﬁer with k = 10 neighbors, that outper-
formed other classiﬁers such as Random Forest and Logistic
Regression in our preliminary experiments.
4.2.2 Key Classiﬁcation
We consider key classiﬁcation to be a multiclass classiﬁca-
tion problem, where diﬀerent classes correspond to diﬀerent
keyboard keys. To evaluate the classiﬁer’s quality we use