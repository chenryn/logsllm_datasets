depth, are shown in Table 2, along with the fraction of the ASes
external to each warden that are not reachable via at least one clean
path. As can be seen, a ring at a depth of one is the smallest effec-
tive ring, with a size of 161 ASes. The following ring, at a depth of
two, jumps in size by a factor of more than 23, becoming untenable
in size. The ring at a depth of three is actually smaller, an artifact
of deﬁning ring membership by minimum depth, but as can be seen
in the right-hand column, if containment is not achieved at a depth
of two at the latest then the majority of the Internet is reachable.
While the depth one ring might look promising, it is important to
remember that it is comprised of ASes which have elected to di-
rectly conduct business with the warden. Providing sufﬁcient eco-
nomic incentives to take an action directly in opposition with their
customer’s wishes may be difﬁcult, considering that the warden can
provide incentives to these entities to not deploy decoy routers.
Since a depth one ring is challenging for economic reasons and a
depth three ring does not provide containment, clearly a depth two
ring is the only workable option for a deployment in a ring around
China. However, the depth two ring around China is 3,806 ASes
large—far too large to see a successful deployment. The smallest
depth two ring is around Syria, but even it contains 751 ASes. What
about a fractional deployment to the depth two rings? We used
our previous simulator to get some idea of the success of such a
fractional deployment. The fraction of ASes that are unreachable
via a clean path as a function of the fraction of the depth two ring
93Country
Ring Depth Ring Size
Size As Fraction of Remaining Transit ASes
Fraction of ASes Without Clean Paths
China
Australia
Iran
Syria
France
Venezuela
1
2
3
1
2
3
1
2
3
1
2
3
1
2
3
1
2
3
161
3806
1625
470
3619
1540
58
1967
3261
7
751
3969
553
3841
1344
22
1993
3176
2.84%
69.09%
95.42%
8.18%
68.59%
92.94%
1.02%
35.00%
89.27%
0.12%
13.26%
80.79%
9.50%
75.88%
94.05%
0.39%
35.29%
86.92%
100%
91.43%
2.25%
100%
78.04%
3.13%
100%
98.44%
16.67%
100%
99.86%
55.81%
100%
72.28%
2.18%
100%
99.40%
19.59%
Table 2: The size and containment of rings at various depths around the wardens.
receiving decoy routers can be seen in Figure 10. Again, in order
to cut off Egypt, Iran and Syria from half of the Internet, more then
70% of the depth two ring needs decoy routers, while China would
require more than 80%.
CN
AU
IR
SY
FR
VE
l
e
b
a
h
c
a
e
r
n
u
s
e
S
A
f
o
n
o
i
t
c
a
r
F
0
.
1
8
.
0
6
.
0
4
.
0
2
.
0
0
.
0
0.0
0.2
0.4
0.6
0.8
1.0
Fraction of depth 2 ring deploying
Figure 10: The fraction of all ASes unreachable from the wardens
via at least one clean path for various fractional deployments to a
depth two ring around the wardens.
Instead of ringing the source of trafﬁc, an alternative strategy
would be to ring popular destinations. For example, a ring could
be built around the Alexa top 100. This strategy runs into a sim-
ilar issue to that of the depth one ring around the warden: you
must directly incentivize people to do things against their economic
interests—in this case, the economic interests of the destinations.
There is relatively little the destinations have to gain by being ringed
with decoy routers, as they could lose customers in the warden’s
jurisdiction, and, consequently, revenue. This in turn would lead
these content providers to select upstream ISPs that did not deploy
decoy routers, making the deployment of decoy routers against the
economic interests of ISPs as well. We leave a full investigation
of these incentives to future work. There are two other compli-
cating factors with a solution centered around ringing destinations.
First, many popular destinations are not a single entity, but actually
a broad collection of data centers, usually backed by some form of
content distribution network, making containment of these desti-
nations challenging. Second, wardens, particularly China and Iran,
have shown a willingness in the past to disconnect themselves from
content providers who do not agree to play by their rules and in-
stead use homegrown solutions, meaning that the impact of such a
deployment on these wardens would be limited.
An alternative would be to ring a geographic location with de-
coy routers. If connectivity to this region is deemed critical, we
note that this can be defeated by tunneling TLS trafﬁc. The war-
den rents or constructs a small data center inside the ringed loca-
tion; once functional, all TLS connections bound for the region are
placed in an IPsec tunnel bound for the data center, where they are
unpacked and forwarded to the destination, using the correct source
IP address of the client. The destination forwards packets normally
to the client, but decoy routing systems are thwarted as the packets
from the client are wrapped with an additional layer of encryption
when they pass the decoy routers.
Timing. To prevent trafﬁc analysis, Wustrow et al. [27] suggest
having Telex perform trafﬁc shaping, attempting to mimic network
characteristics one would expect to see during a TLS connection.
While this might prevent traditional trafﬁc analysis from being done,
it will do little to prevent the timing analysis we discuss in Sec-
tion 5.2. The discrepancies that a warden is able to observe is due
to the underlying differences in AS-level paths being taken, result-
ing in the network latencies being considerably higher then one
would expect if the trafﬁc was actually going to the covert destina-
tion. This is near impossible for the decoy routing to mask, because
while the decoy router can increase latency by holding onto pack-
ets, there is no available method to decrease the latency which a
warden observes. Therefore, the only way to hide this side channel
is to try and make sure that the overt and covert destination have
statistically similar latencies.
However, this raises some additional problems that would have
to be ﬁxed. First, since clients using the system need to broadcast
to many different overt destinations, ensuring they traverse many
distinct paths in order to increase their likelihood of crossing a de-
coy router, selecting speciﬁc overt destinations ahead of time could
prove to be problematic. Furthermore, even if this was possible, by
linking the choice of overt destination to the covert destination, this
will reduce the anonymity of the covert destination that the user is
attempting to communicate with. Finally, for many covert destina-
tions there may not be any appropriate overt destination within the
94same distance from a decoy router; in this case such destinations are
effectively unreachable, defeating the purpose of providing general
Internet connectivity.
7. RELATED WORK
Several previous works have explored the impact of ISP-type ad-
versaries on anonymity schemes. Feamster and Dingledine [12] an-
alyzed the diversity of AS-level paths in anonymity networks, such
as Tor and Mixmaster, and showed how path asymmetry could lead
to poor location independence. Furthermore, Edman and Syver-
son [11] showed that even the large growth in the Tor network failed
to dramatically improve AS path diversity and systems had to be
aware of AS level adversaries and consciously make decisions with
AS-level information in mind. Murdoch et al. [21] examined how
even with high AS-level diversity in anonymity networks, many of
the packets will travel through a single physical Internet exchange
allowing a single entity to perform trafﬁc analysis, negating the
need for a global view. These types of studies highlight the impor-
tance of making sure anonymity systems take into account route
diversity and underscores the dangers of sometimes treating the In-
ternet as a black box.
As for the timing attacks, there has been much research con-
ducted on how trafﬁc analysis can be used on anonymity and other
similar systems. Back et al. [5] showed how many trafﬁc analysis
techniques, and in particular latency measurements, can be used to
ﬁngerprint nodes in the network. Hopper et al. [17] expand on this
and provide a formal framework on how an adversary can utilize
latency measurements in the Tor network to reduce the anonymity
of the client participating in the system. Several papers [22, 16, 10,
15] showed that by using more sophisticated ﬁngerprinting meth-
ods, adversaries are able to perform website ﬁngerprinting in the
Tor network to identify the end server that a user is communicating
with. These attacks are based on the size of downloaded ﬁles and
could potentially be combined with our timing attacks to yield even
more accurate identiﬁcation of covert destinations.
8. CONCLUSION
In this paper, we have introduced a novel adversary model for
decoy routing, the routing capable adversary, exploring the actual
routing capabilities that a warden has and the implications that
such an adversary has with respect to decoy routing. Speciﬁcally,
we showed how wardens can easily enumerate all deployed decoy
routers and use this information to successfully route around all
such routers. We explored, in depth, the intricacies of deployment
strategies and analyzed the effects they have with respect to the
enumeration attacks. In addition, we showed how a warden can run
multiple conﬁrmation attacks to detect when a client is participat-
ing in the system and not actually communicating with their overt
destination. Lastly, we showed that a warden can use ﬁngerprint-
ing techniques to expose the identity of the secret destination that a
client is communicating with through the decoy routing system.
These results show that small deployments can be trivially de-
feated, requiring larger deployments for decoy routing to be suc-
cessful. However, several of our conﬁrmation attacks still work,
even against very large deployments. This suggests that new ideas
will be needed before decoy routing can be deployed in a secure
and cost effective manner.
Acknowledgments This work was supported by NSF grant 0917154.
9. REFERENCES
[1] Knock Knock Knockin’ on Bridges’ Doors.
https://blog.torproject.org/blog/
knock-knock-knockin-bridges-doors.
[2] CAIDA AS relationship dataset.
http://www.caida.org/data/active/
as-relationships/index.xml.
[3] JAP: The JAP anonymity & privacy homepage.
http://www.anon-online.de.
[4] New blocking activity from iran, Sep, 14, 2011.
https://blog.torproject.org/blog/
iran-blocks-tor-tor-releases-same-day-fix.
[5] A. Back, U. Möller, and A. Stiglic. Trafﬁc analysis attacks
and trade-offs in anonymity providing systems. In
Proceedings of the 4th International Workshop on
Information Hiding, IHW ’01, pages 245–257.
Springer-Verlag, 2001.
[6] Berkman Center for Internet & Society. Mapping local
internet control. http://cyber.law.harvard.edu/
netmaps/geo_map_home.php.
[7] U. I. Corporation. Ultrasurf - proxy-based internet privacy
and security tools. http://ultrasurf.us.
[8] T. Dierks and E. Rescorla. The Transport Layer Security
(TLS) Protocol Version 1.2. RFC 5246 (Proposed Standard),
Aug. 2008. Updated by RFCs 5746, 5878, 6176.
[9] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The
second-generation onion router. In Proceedings of the 13th
conference on USENIX Security Symposium, pages 21–21.
USENIX Association, 2004.
[10] K. P. Dyer, S. E. Coull, T. Ristenpart, and T. Shrimpton.
Peek-a-boo, i still see you: Why efﬁcient trafﬁc analysis
countermeasures fail. In Proceedings of the 2012 IEEE
Symposium on Security and Privacy, May 2012.
[11] M. Edman and P. Syverson. As-awareness in tor path
selection. In Proceedings of the 16th ACM conference on
Computer and communications security, CCS ’09. ACM,
2009.
[12] N. Feamster and R. Dingledine. Location diversity in
anonymity networks. In Proceedings of the 2004 ACM
workshop on Privacy in the electronic society, WPES ’04,
2004.
[13] L. Gao and J. Rexford. Stable internet routing without global
coordination. IEEE/ACM Transactions on Networking
(TON), 9(6):681–692, 2001.
[14] Y. He, M. Faloutsos, and S. Krishnamurthy. Quantifying
routing asymmetry in the internet at the as level. In Global
Telecommunications Conference, 2004, volume 3 of
GLOBECOM ’04, pages 1474–1479. IEEE, 2004.
[15] D. Herrmann, R. Wendolsky, and H. Federrath. Website
ﬁngerprinting: attacking popular privacy enhancing
technologies with the multinomial naive-bayes classiﬁer. In
Proceedings of the 2009 ACM workshop on Cloud
computing security (CCSW ’09), pages 31–42, New York,
NY, USA, 2009. ACM.
[16] A. Hintz. Fingerprinting websites using trafﬁc analysis. In
R. Dingledine and P. Syverson, editors, Proceedings of
Privacy Enhancing Technologies workshop (PET 2002).
Springer-Verlag, LNCS 2482, April 2002.
[17] N. Hopper, E. Y. Vasserman, and E. Chan-tin. How much
anonymity does network latency leak. In Proceedings of the
14th ACM conference on Computer and communications
security, CCS ’07, 2007.
95[18] A. Houmansadr, G. T. Nguyen, M. Caesar, and N. Borisov.
[23] J. Postel. Transmission Control Protocol. RFC 793
Cirripede: circumvention infrastructure using router
redirection with plausible deniability. In Proceedings of the
18th ACM Conference on Computer and Communications
Security (CCS), 2011.
[19] J. Karlin, D. Ellard, A. W. Jackson, C. E. Jones, G. Lauer,
D. P. Mankins, and W. T. Strayer. Decoy routing: Toward
unblockable internet communication. In Proceedings of the
USENIX Workshop on Free and Open Communications on
the Internet (FOCI), 2011.
[20] Z. Mao, L. Qiu, J. Wang, and Y. Zhang. On as-level path
inference. In ACM SIGMETRICS Performance Evaluation
Review, volume 33, pages 339–349. ACM, 2005.
[21] S. J. Murdoch and P. Zieli´nski. Sampled trafﬁc analysis by
internet-exchange-level adversaries. In Proceedings of the
7th international conference on Privacy enhancing
technologies, PET’07, 2007.
[22] A. Panchenko, L. Niessen, A. Zinnen, and T. Engel. Website
ﬁngerprinting in onion routing based anonymization
networks. In Proceedings of the 10th annual ACM workshop
on Privacy in the electronic society, WPES ’11. ACM, 2011.
(Standard), Sept. 1981. Updated by RFCs 1122, 3168, 6093,
6528.
[24] J. Qiu and L. Gao. As path inference by exploiting known as
paths. In IEEE GLOBECOM, 2006.
[25] Y. Rekhter, T. Li, and S. Hares. A Border Gateway Protocol
4 (BGP-4). RFC 4271 (Draft Standard), Jan. 2006. Updated
by RFC 6286.
[26] E. Rosen and Y. Rekhter. BGP/MPLS IP Virtual Private
Networks (VPNs). RFC 4364 (Proposed Standard), Feb.
2006. Updated by RFCs 4577, 4684, 5462.
[27] E. Wustrow, S. Wolchok, I. Goldberg, and J. A. Halderman.
Telex: anticensorship in the network infrastructure. In
Proceedings of the 20th USENIX Conference on Security
(SEC), 2011.
96