title:A Multi-Sensor Model to Improve Automated Attack Detection
author:Magnus Almgren and
Ulf Lindqvist and
Erland Jonsson
A Multi-Sensor Model to Improve
Automated Attack Detection
Magnus Almgren1, Ulf Lindqvist2, and Erland Jonsson1
1 Department of Computer Science and Engineering
Chalmers University of Technology
SE-412 96 G¨oteborg, Sweden
2 Computer Science Laboratory
SRI International
333 Ravenswood Ave
Menlo Park, CA 94025, USA
Abstract. Most intrusion detection systems available today are using a
single audit source for detection, even though attacks have distinct mani-
festations in diﬀerent parts of the system. In this paper we investigate
how to use the alerts from several audit sources to improve the accuracy
of the intrusion detection system (IDS). Concentrating on web server at-
tacks, we design a theoretical model to automatically reason about alerts
from diﬀerent sensors, thereby also giving security operators a better un-
derstanding of possible attacks against their systems. Our model takes
sensor status and capability into account, and therefore enables reason-
ing about the absence of expected alerts. We require an explicit model
for each sensor in the system, which allows us to reason about the qual-
ity of information from each particular sensor and to resolve apparent
contradictions in a set of alerts.
Our model, which is built using Bayesian networks, needs some initial
parameter values that can be provided by the IDS operator. We apply
this model in two diﬀerent scenarios for web server security. The scenarios
show the importance of having a model that dynamically can adapt to
local transitional traﬃc conditions, such as encrypted requests, when
using conﬂicting evidence from sensors to reason about attacks.
Keywords: intrusion detection, alert reasoning.
1 Introduction
The accuracy of an intrusion detection system (IDS), meaning the degree to
which the security oﬃcer can trust the IDS to recognize attacks and at the same
time not produce false alarms, can be considered the most important property of
an IDS (a general deﬁnition of detector accuracy can be found in [19]). However,
many IDSs do not provide a very high degree of accuracy, because of two common
shortcomings. First, the IDS tends to rely on a single detection method applied to
a single audit source such as network packets, which is not suﬃcient to accurately
recognize all types of attacks. Second, many IDSs have a propensity for producing
R. Lippmann, E. Kirda, and A. Trachtenberg (Eds.): RAID 2008, LNCS 5230, pp. 291–310, 2008.
c(cid:2) Springer-Verlag Berlin Heidelberg 2008
292
M. Almgren, U. Lindqvist, and E. Jonsson
massive amounts of alerts, many of which are irrelevant or false. Over time, the
security oﬃcer monitoring the alerts from the IDS could learn which types of
alerts can be safely ignored, and even which combinations of alerts indicate a
more serious incident.
A signiﬁcant amount of research has been conducted to improve the accuracy
of IDSs. Some of that work has been focused on the implementation of detectors,
such as speed improvements or techniques to detect obfuscated attacks. Other
work has been focused on alert processing techniques in the form of alert aggre-
gation and correlation, such as root-cause analysis. Diversity has been proposed
as a principle to be adopted to improve detection coverage. One form of diversity
is to use a combination of detection techniques, for example, signature-based de-
tection combined with statistical anomaly detection. Another form of diversity
is to simultaneously use input from diﬀerent audit streams, for example, network
packets and application event logs.
While diversity is a promising approach to increasing IDS accuracy, comple-
mentary sensors are currently not widely developed or deployed. This happens
because without automated procedures to take advantage of multiple diverse
alert sources and make the correct inferences, the burden on the security oﬃcer
will increase rather than decrease, especially in the cases of conﬂicting sensor
reports. This paper proposes and investigates a model upon which such auto-
mated reasoning can be based, ultimately presenting the security oﬃcer with
actionable and highly accurate information about ongoing attacks, and reducing
the need for operator experience and expertise.
The model presented in this paper is applied to the output of traditional
correlators—we assume that these techniques preprocess the alert stream and
present us with an aggregated set of related alerts concerning an attack (see
Section 7 for a discussion of correlation techniques). We propose a model to
combine the alerts from several intrusion detection systems using diﬀerent audit
sources. We show how our model can resolve seemingly conﬂicting evidence about
possible attacks as well as properly account for transient failure modes of the
sensors in the system, such as the network IDS being blind when analyzing
encrypted traﬃc.
Our approach would beneﬁt from sensors having an intrinsic knowledge of
their own detection capability as well as having modes to speciﬁcally monitor
the outcomes of certain attacks. However, our approach also works with tra-
ditional sensors. By using correlated alerts as input, we beneﬁt from previous
research into correlation. As we present them with further reﬁned information,
the security oﬃcers can spend their time actively protecting the system instead
of trying to understand the mixed message from intrusion detection sensors.
The rest of the paper is organized as follows. In Section 2 we describe the
notation used in the paper and outline the problem we are investigating. We
then formally describe the assumptions and requirements we need before we
introduce our decision framework in Section 3. We use two scenarios to exemplify
the model, and these are presented in Section 4. The test bed and the experiments
A Multi-Sensor Model to Improve Automated Attack Detection
293
are described in Section 5. We summarize our ﬁndings in Section 6 and discuss
related work in Section 7. The paper is concluded in Section 9.
2 Theory
2.1 Notation
We use the term sensor to denote a component that monitors an event stream
(audit source) for indications of suspicious activity according to a detection algo-
rithm and produces alerts as a result. A simple IDS, such as a typical deployment
of the popular tool Snort, in most cases constitutes a single sensor. We therefore
use the terms sensor and IDS interchangeably in this paper. More advanced
IDS deployments could be composed of several sensors that feed into a common
alerting framework.
Let us assume that we use a set of intrusion detection sensors, S, to detect
attacks, and in particular the attack, A. A sensor Si may alert for ongoing
attacks but sometimes gives false alerts. We denote such alerts by Aai
j, where
each sensor may give several alerts for each attack (j-index). If Si is present in
the system and alerts for the attack A, we denote this by Si : Aai
j. For simplicity,
we are going to concentrate on a single attack in the discussion below, so the
index A is not shown explicitly. When the attack A does not trigger any alert
in the sensor Si, we denote this by Si : ¬Aai
j. To simplify
the discussion, we show only the missing alerts that are actually relevant for the
current situation. Finally, a sensor may temporarily be missing in a system or
a speciﬁc sensor may not work as intended. Following the same notation as for
alerts, we denote such a malfunctioning or missing sensor with ¬Si. Observing
this state directly is very diﬃcult in current intrusion detection systems, and
often we can only indirectly assume that a sensor is not working correctly. For
example, a heartbeat message may tell us that a network IDS is still running,
but if the traﬃc is encrypted, the sensor cannot properly analyze it.
j or simpler as Si : ¬ai
Following this notation, we have the four separate cases shown in Table 1.
Each alert for these cases may be true or false, but if the sensor is not working
(iii and iv) we treat all alerts as being false, as they would only coincidentally
be true. We consider case (iv) to be uncommon with more sophisticated sen-
sors, but if it happens the security oﬃcer will investigate the (false) alert and
discover the malfunctioning sensor. Finally, as the sensor status cannot directly
be observed, cases (i) and (iv) would look similar to a security operator without
further investigation, as would cases (ii) and (iii).
2.2 Example with Two Sensors
Now consider a particular system with two sensors S1 and S2, where each sensor
can output a single alert for the A-attack (we drop the j-index in this example).
294
M. Almgren, U. Lindqvist, and E. Jonsson
Table 1. The four possible sensor / alert states
(i)
Si: ai
j
(ii) Si:¬ai
j
(iii) ¬Si:¬ai
j
(iv) ¬Si: ai
j
Si is working correctly and outputs
j.
alert ai
Si is working correctly and has not
found any signs that warrant the
j.
output of alert ai
Si is not working correctly and does
j regardless of the
not output alert ai
attack status.
Si is not working correctly but still
outputs an alert regardless of the
attack status, for example, when
traﬃc is encrypted but happens to
contain a pattern that triggers the
j.
alert ai
Table 2. An example us-
ing two sensors with one
alert each
¬a1
a1
¬a1
a1
¬a2
a2
a2
¬a2
(2a)
(2b)
(2c)
(2d)
As hinted earlier, the sensor status is seldom directly measured, so with such a
setup only the four cases shown in Table 2 can be directly observed.
The interpretations of (2a) (i.e., the ﬁrst case in Table 2) and (2b) are straight-
forward. In the ﬁrst case, no sensor reports anything so we do not investigate
further. In the second case, both sensors warn for an attack and for that reason
it is worth investigating further. However, cases (2c) and (2d) are interesting,
as only one of the two sensors reports the possible ongoing attack. How should
these two cases be interpreted?
Clearly, we need more information to draw any conclusions for cases (2c) and
(2d). The burden of collecting this extra information, and using it to reason
about the attack status for these cases, has often fallen on the security operator.
In our opinion, many correlator techniques have so far taken a simpliﬁed but
safe view: if any sensor reports an attack, it should be treated as an attack, i.e.,
the security operator needs to investigate this issue manually. The problem we
are investigating is whether we can improve the automatic analysis and provide
a more reﬁned answer to the security operator. In the remainder of this section,
we describe some reasons for why traditional correlation technologies may have
used the simpliﬁed view described above. These reasons are used as a basis for
the discussion in Section 3, where we set up the necessary framework to provide a
model that aids the security operator by solving cases with seemingly conﬂicting
evidence.
2.3 The Problem of Conﬂicting Evidence
In Section 2.2, we showed the possible outputs of two sensors, which in cer-
tain cases may be conﬂicting. Here, we discuss how to interpret those cases of
A Multi-Sensor Model to Improve Automated Attack Detection
295
conﬂicting sensor output. This discussion serves as a background to understand
the requirements of our model that we introduce in Section 3.
No Complementary Sensors Deployed. First we note that in many typical
environments, cases (2c) and (2d) described above may not be very common,
because the same type of sensor is duplicated across the network to allow for
some partial redundancy in the monitoring capacity. For example, a company
may have two instances of Snort analyzing almost the same traﬃc. In this case,
the only reason the identical sensors would disagree is if one is broken. Thus,
the only recourse is to interpret both (2c) and (2d) as a sign of an attack. We
would like to point out that even though it may be common to have only one
type of sensor, research shows the beneﬁts of using several diﬀerent sensors for
attack detection ([3]).
Ambiguity between ‘No Attack’ and a Broken Sensor. Even when we
use diﬀerent types of sensors we are still faced with the problem of what a
missing alert means. The sensor state is often unknown, and as we showed in
Table 1, a sensor reporting no alert may signify one of two conditions: Si : ¬ai
or ¬Si : ¬ai. In the ﬁrst case, the sensor is working as intended and does not
detect any signs of an attack. In the second case, the sensor is broken, and for
that reason it cannot reliably detect attacks. Not only is it diﬃcult to determine
the stationary state of a sensor through direct observation, but the conditions for
when a sensor may detect attacks may also change dynamically; a network IDS
is blind to the single encrypted web request, or a request that is routed around
it, and so on. Not knowing the sensor state, the operator cannot conﬁdently
disregard an alert just because only one sensor produced it.
Detailed Sensor Alert Information Missing. Let us say that we do know
that both sensors are working as intended but they report conﬂicting evidence
as in (2c). Without any detailed information about the particulars of a sensor
and its proclivity to produce false alerts, one cannot automatically decide which
sensor to believe. One might not even know that a1 is missing in (2c). Unless we
have a sensor model, this decision must be left to the human operator.