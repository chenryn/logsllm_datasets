# A Multi-Sensor Model to Improve Automated Attack Detection

**Authors:**
- Magnus Almgren¹
- Ulf Lindqvist²
- Erland Jonsson¹

¹ Department of Computer Science and Engineering, Chalmers University of Technology, SE-412 96 Göteborg, Sweden  
² Computer Science Laboratory, SRI International, 333 Ravenswood Ave, Menlo Park, CA 94025, USA

## Abstract
Most current intrusion detection systems (IDSs) rely on a single audit source for detection, despite the fact that attacks can manifest differently across various parts of the system. This paper explores the use of alerts from multiple audit sources to enhance the accuracy of IDSs. Focusing on web server attacks, we develop a theoretical model that automatically reasons about alerts from different sensors, providing security operators with a better understanding of potential attacks. Our model considers sensor status and capability, enabling reasoning about the absence of expected alerts. We require an explicit model for each sensor, allowing us to assess the quality of information and resolve apparent contradictions in alert sets. The model, built using Bayesian networks, requires initial parameter values provided by the IDS operator. We apply this model in two scenarios for web server security, demonstrating the importance of a model that can dynamically adapt to local traffic conditions, such as encrypted requests, when using conflicting evidence from sensors to reason about attacks.

**Keywords:** intrusion detection, alert reasoning

## 1. Introduction
The accuracy of an intrusion detection system (IDS), defined as the degree to which the security officer can trust the IDS to recognize attacks while minimizing false alarms, is a critical property. However, many IDSs fall short in this regard due to two common issues: reliance on a single detection method applied to a single audit source, and a tendency to generate a large number of alerts, many of which are irrelevant or false. Over time, security officers may learn to filter out certain types of alerts and identify combinations that indicate serious incidents.

Significant research has been conducted to improve IDS accuracy, focusing on detector implementation, speed improvements, and techniques to detect obfuscated attacks. Alert processing techniques, such as aggregation and correlation, have also been explored. Diversity, including the use of multiple detection techniques and different audit streams, has been proposed to enhance detection coverage. However, complementary sensors are not widely developed or deployed because automated procedures to leverage multiple diverse alert sources and make correct inferences are lacking. This paper proposes a model for automated reasoning based on multiple sensors, ultimately presenting the security officer with actionable and highly accurate information about ongoing attacks, reducing the need for extensive operator experience and expertise.

Our model is applied to the output of traditional correlators, which preprocess the alert stream and present an aggregated set of related alerts concerning an attack. We propose a model to combine alerts from several IDSs using different audit sources, resolving conflicting evidence and accounting for transient failure modes of sensors, such as network IDSs being blind to encrypted traffic. Our approach benefits from sensors with intrinsic knowledge of their detection capabilities and specific monitoring modes, but it also works with traditional sensors. By using correlated alerts as input, we build on previous research into correlation, allowing security officers to focus on active protection rather than interpreting mixed messages from intrusion detection sensors.

The rest of the paper is organized as follows: Section 2 describes the notation and outlines the problem. Section 3 introduces our decision framework, followed by two exemplary scenarios in Section 4. Section 5 details the test bed and experiments, and Section 6 summarizes our findings. Section 7 discusses related work, and the paper concludes in Section 8.

## 2. Theory

### 2.1 Notation
We define a **sensor** as a component that monitors an event stream (audit source) for suspicious activity according to a detection algorithm and produces alerts. A simple IDS, like a typical Snort deployment, often constitutes a single sensor. More advanced IDS deployments may consist of multiple sensors feeding into a common alerting framework.

Assume we use a set of intrusion detection sensors, \( S \), to detect an attack, \( A \). Each sensor \( S_i \) may produce alerts \( A_{ai}^j \) for ongoing attacks, where \( j \) denotes the alert index. If \( S_i \) is present and alerts for attack \( A \), we denote this by \( S_i : A_{ai}^j \). If \( S_i \) does not trigger any alert for \( A \), we denote this by \( S_i : \neg A_{ai}^j \). For simplicity, we will focus on a single attack, so the index \( A \) is omitted. If a sensor is temporarily missing or malfunctioning, we denote this by \( \neg S_i \). Observing this state directly is challenging, and often we can only indirectly infer that a sensor is not working correctly.

Table 1 shows the four possible sensor/alert states:

| Case | Sensor State | Alert State |
|------|--------------|-------------|
| (i)  | \( S_i \)    | \( A_{ai}^j \) |
| (ii) | \( S_i \)    | \( \neg A_{ai}^j \) |
| (iii)| \( \neg S_i \) | \( \neg A_{ai}^j \) |
| (iv) | \( \neg S_i \) | \( A_{ai}^j \) |

### 2.2 Example with Two Sensors
Consider a system with two sensors, \( S_1 \) and \( S_2 \), each capable of outputting a single alert for the \( A \)-attack (dropping the \( j \)-index for simplicity). Table 2 shows the possible outcomes:

| \( S_1 \) | \( S_2 \) | Interpretation |
|----------|----------|----------------|
| \( \neg a_1 \) | \( \neg a_2 \) | No alerts, no investigation needed. |
| \( a_1 \) | \( a_2 \) | Both sensors report an attack, investigate further. |
| \( \neg a_1 \) | \( a_2 \) | Only one sensor reports an attack, ambiguous. |
| \( a_1 \) | \( \neg a_2 \) | Only one sensor reports an attack, ambiguous. |

Cases (2c) and (2d) are interesting because only one of the two sensors reports a possible ongoing attack. To draw conclusions, more information is needed, and the burden of collecting and using this information typically falls on the security operator.

### 2.3 The Problem of Conflicting Evidence
In Section 2.2, we showed the possible outputs of two sensors, which may be conflicting. Here, we discuss how to interpret these cases, providing a background for the requirements of our model introduced in Section 3.

#### No Complementary Sensors Deployed
In many environments, cases (2c) and (2d) may not be common because the same type of sensor is often duplicated across the network for redundancy. If identical sensors disagree, it usually indicates a broken sensor, leading to the interpretation that both (2c) and (2d) signify an attack. However, research supports the benefits of using different types of sensors for attack detection.

#### Ambiguity between 'No Attack' and a Broken Sensor
Even with different types of sensors, the meaning of a missing alert is ambiguous. A sensor reporting no alert could mean either that the sensor is working and detects no attack, or that the sensor is broken. Determining the sensor state is difficult, and conditions for detecting attacks can change dynamically. Without knowing the sensor state, the operator cannot confidently disregard an alert based on a single sensor's report.

#### Detailed Sensor Alert Information Missing
If both sensors are known to be working, but they report conflicting evidence, detailed information about each sensor's false alert rate is necessary to decide which sensor to believe. Without a sensor model, this decision must be left to the human operator.

## 3. Decision Framework
[This section will introduce the decision framework, including the Bayesian network model and the initial parameter values required.]

## 4. Scenarios
[This section will present two scenarios to exemplify the model.]

## 5. Test Bed and Experiments
[This section will describe the test bed and the experiments conducted.]

## 6. Findings
[This section will summarize the findings from the experiments.]

## 7. Related Work
[This section will discuss related work in the field of intrusion detection and alert correlation.]

## 8. Conclusion
[This section will conclude the paper, summarizing the contributions and future work.]

---

This revised version aims to provide a clear, coherent, and professional presentation of the research, making it easier for readers to follow and understand the key points.