"size":300000
"queryGranularity":
"numRows":5000000，
"intervals":[
"id":"some_id"
"type":“"none”
"2013-05-13T00:00:00.000Z/2013-05-14T00:00:00.000Z
"type":“FLOAT""
"list",
"none"}
查询Context，可以指定是否缓存查询结果等
示
true或false，
指定返回column的哪些属性，如size,intervals等
将多个 Segment 的元信息合并到一个返回结果中
list
可以指定哪些column在返回结果中呈现，可以填all,none,
描述
人
"columns":[]}
设置为true时，
，不过这些字段都不是必需的，简介如下：
是
否
否
是否必需
155
---
## Page 180
松、灵活地在Druid平台上进行数据探索。
句与SQL几乎一致，同时还支持开发者编写自己的聚合器。这些丰富的功能使得用户可以轻
6.10小结
156
Druid提供的查询方式非常丰富，几乎涵盖了OLAP查询的方方面面，并且很多查询语
dataSourceMetadata
"result"：[
"timestamp":"2013-05-09T18:24:00.000Z",
返回结果如下：
"dataSource":
"queryType"
"maxIngestedEventTime":"2013-05-09T18:24:09.007Z",
"sample_datasource"
"dataSourceMetadata""
Druid实时大数据分析原理与实践
---
## Page 181
druid.extensions.loadList=["druid-histogram"]
对于直方图模块，设置如下：
的一些功能。
稳定，可以放心使用。下面功能都是Druid未来发展的重要分析功能，是很多应用场景急需
perimentalFeature），有些功能尚未完成全面测试，但是其核心功能从实践效果来说还都非常
为了使用这些功能，有时候需要在配置文件中进行设置，让Druid装载这些模块。例如
本章介绍Druid的一些高级功能和特性，其中有些功能在开发过程中属于实验功能（Ex-
该设置需要应用在索引节点和查询节点的配置文件中。
·Kafka索引服务
·路由器（Router
·近似直方图和分位数
预估数据（DataSketch）
地理索引和查询
高级功能和特性
第
---
## Page 182
组在进行累加计算时容易丢失信息。例如，两个中位数的和的含义不明显，累加越多，越
规模和计算时间可以保证。最初的想法是保存双元组，但是这个双元
对需要索引的列，保持固定数量的双元组，表示该数据的分布情况。
的，因为数据存储和处理都会变成巨大的问题。
http://jmlr.org/papers/volume11/ben-haim10a/ben-haim10a.pdf
可以在性能和准确度之间进行取舍和平衡，该方案也支持百亿级以上的数据规模。请参考
性能。如果记录原始数据，将会极大地失去性能优势。
方案需要将原始值都记录下来。Druid的核心设计是通过预先聚合一些数据，大大提高访问
7.1.2实现原理
据分布的情况。
的访问响应时间小于1秒等。
用百分位数（Percentile）的指标统计，例如，有些网络服务的响应时间都需满足：保证99%
有名词，表示将数据按照大小排序，找到中间位置的那个数据。许多数据分析场景都需要使
变量的趋势。常用的有中位数、四分位数、百分位数等。中位数（Median）是一个统计学专
7.1.1
7.1
158
20101-01102:0002
2011-01-01702:00:00
201101-0001:0:00
2011-01-01101:00:002
timestamg
由于每一时间段的数据都已经聚合，如果像图7-1一样保存原始数据，则几乎是不可能
为了解决这个问题，Druid采用一种近似的计算方式来获得中位数、直方图等。使用者
分位数的计算通常涉及对原始数据进行排序，排序本身是比较容易并行化的，但是这种
直方图（Histogram）是一种统计报告图，由一系列高度不等的纵向条纹或线段表示数
分位数（Quantile）是指将一组数据按照一定方法分为几个等份的数值点，分析其数据
因此，如何减少每一区段的数量，就是分位数设计的核心挑战。
近似直方图（Approximate Histogram）
分位数和直方图
一般用横轴表示数据类型，用纵轴表示分布情况。
图7-1保持原始数据的简单方案（数据量巨大）
8194
mpressions
Druid实时大数据分析原理与实践
固定数量意味着数据
Druid的实现方式是：
7
lick
0 93,092,0.12
(0.07.034,122
50.0.5
prices
---
## Page 183
造每一区段的值的预估个数，就可以得到直方图和分位数，
重新计算值。
重心为0.62的有48个；重心为0.71的有83个等等，当有新的数据插入时，这些二元组也会
http://dl.acm.org/citation.cfm?id=1519389
双元组的实现。其中重心点的计算，是一种带权重的均值计算，有兴趣的同学，可以参考
失去了中位数的意义。在Druid的最后实现中，采用的是作为
第7章
20101-0020:00
2011-01-01102-0002
201-010100:00
20-01000:002
在计算直方图时，可以利用这些二元组进行近似计算。
预估的梯形如图7-4所示，其中包括预估的一些值。
比如第一行中AH_Prices列中，[(1,.16),(48,.62),(83,.71).]，表示值为0.16的有1个；
数据格式如图7-2所示。
高级功能和特性
Count
图7-3
直方图和分位数样例
Value
Male
USA
6194
1800
impressions
，如图7-3所示。
，具体过程是，
25
chicks
，根据这些二元组构
203)0.6(20.931
B112151014
0.16486（8371
159
---
## Page 184
个图使用了50个二元组；第三个图使用了200个二元组，精准性已经很不错了。
160
如图7-5所示是一个实际中的精确性分析例子，其中第一个图使用了5个二元组；第二
如下几个因素决定了预估的精准性。
·梯形构造的算法。
·数据分布的规律性
·二元组的最大数量。
Coun
图7-5使用了不同二元组的精确性分析例子
图7-4
预估的梯形图
S=
Druid实时大数据分析原理与实践
71
---
## Page 185
的分布式指标，例如百分位数、最大值、最小值等。
2.
聚合器。这种摄入聚合器只能用于数字的列值。这两种聚合器的区别如下：
3.
7.1.3
第7章
lowerLimit/upperLimit
numBuckets
resolution
属性
近似直方图的Post-Aggregator
查询
索引阶段
Post-Aggregator用于将近似直方图的概要数据转化成分段式直方图表示，并且计算不同
"upperLimit"
"lowerLimit"
在查询输人中必须指定“ApproxHistogramFold”聚合器，例子如下：
"resolution"
"fieldName":
"name"：
·ApproxHistogramFold
"numBuckets"
"type"
下面介绍直方图和分位数的具体使用。
如何使用
高级功能和特性
,
：
：,
：
低于下限和高于上限的数量将会保持
限制列值的范围，超出范围的值都被考虑成两个重心二元组，
桶的格式
是动态计算的，使用Post-Aggregator可以更加细粒度地控制
直方图的桶的个数，将所有数据分为多少个部分。桶的距离
重心二元组的数量；数量越多，精准度越高，查询速度越慢
描述
一如果数据行缺少此列值，这个值被认为是0。
一如果数据行缺少此列值，这个值将不加入计算（Ignored）。
-INF/+INF
50
默认值
---
## Page 186
内部具体大小取决于底层的数据内容。
162
"fieldName":
"name":,
"type" : “max",
返回近似直方图最大值。
"fieldName":
"name":,
"type"："“min"，
返回近似直方图最小值。
"offset":
"fieldName":""
"type":"buckets",
这个Post-Aggregator的功能是可以指定桶的开始大小、桶的步长大小和桶的个数。
"numBuckets":
"name":""
这个 Post-Aggregator的功能是可以指定相同大小的桶，只需要指定桶的数量就可以，桶
（4）最大Post-Aggregator
（3）最小Post-Aggregator
bucketSize":,
'name":
（2）自定义桶（buckets）Post-Aggregator
'type":
（1）相同桶（equalBuckets）Post-Aggregator
"equalBuckets"
Druid实时大数据分析原理与实践
---
## Page 187
功能，其实现是使用HyperLogLog算法。下面做一个简单的比较。
使用概率论方法对基数进行统计分析。在前面的章节中，我们谈到过HyperUnique Aggregator
法会对Segment索引列的每一段构造一个数据索引结构（元数据+Key-Value对）。ThetaSketch
据近似计算功能。DruidDataSketch能够实现快速的纬度基数运算，后面使用的ThetaSketch算
7.2.1
权衡。扩展的直方图还是可以方便地实现直方图和分位数的分析目标的。
库操作的分析实现起来就非常难了。为了实现这些功能，Druid不得不进行准确性和性能的
7.1.4
个输人。
第7章
由于Druid的数据在存储时进行了预聚合操作，因此对于Druid来说，
"probabilities" : [, , ... ]
"fieldName":,
"name":,
"type" : "quantiles",
多分位数用于计算多个分位数的 Post-Aggregator，其用法和单分位数类似，只是支持多
（6）多分位数Post-Aggregator
"probability"：
"fieldName":,
"name": ,
'type":"quantile",
指定分位数的结果。
（5）单分位数 Post-Aggregator
DataSketch Aggregator
数据Sketch
高级功能和特性
近似直方图小结
一些常见的数据
163
---
## Page 188
储数据，查询数据也会变慢。这需要使用者找到平衡。
druid.extensions.loadList=["druid-datasketches"]
件加上：
164
"type":"index"，
我们仍以用户行为数据摄取为案例，在摄取阶段，配置如下：
其中，size和结果的准确度有关，值越大，越准确。但是size值越大，就需要越多的存
"size":16384
"isInputThetaSketch":false,
"fieldName":
"name":,
"type":"thetaSketch"
在摄取时，需要指定SketchAggregator：
'spec":
下面举一个例子，查询既浏览了A商品又浏览了B商品的用户数是多少。
·DataSketch的精度高于HyperLoglog，并且可以灵活进行参数调整。
·DataSketch使用扩展插件实现，HyperUnique为内置功能。
·DataSketch 的基数运算比 HyperUnique丰富：支持集合的交、并、补运算。
不同之处：
两个功能的相同之处：都能实现基本的近似基数运算。
"dataSchema":
"dataSource":"dianshang_order"，
"parser":
'parseSpec":
"type":"string"
"format":"json"
"timestampSpec":
"column":"timestamp",
"format":"auto"
Druid 实时大数据分析原理与实践
---
## Page 189
第7章
高级功能和特性
"granularitySpec":{
'metricsSpec":[
intervals":[
"queryGranularity":"MINUTE"
"segmentGranularity":"HOUR"
"type":"uniform",
"2016-08-27/2016-08-28"
"type":"thetasketch",
"fieldName":"count"
"type":"longSu"
"dimensionsSpec":
"name":"theta_user_id",
"name":"count",
"dimensions":[
"spatialDimensions":[
"dimensionExclusions":[
"category"
"commodity"
"city",
"age"",
"event_name"
165
---