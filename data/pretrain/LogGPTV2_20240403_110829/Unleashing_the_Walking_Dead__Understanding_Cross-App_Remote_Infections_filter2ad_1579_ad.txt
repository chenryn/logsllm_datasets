and returns confirmed results: whatever we found will certainly be
an opportunity for a XAWI adversary. The challenge, however, is
how to find the right test cases to trigger the weaknesses. Our idea
is based upon the observations that most clues for constructing the
URL that can pass the app’s checks are out there in its code and
manifest. Actually, we found that even a simple yet systematic anal-
ysis of URL-related strings discovered from the app already leads
to the discovery of a large number of confirmed vulnerable apps,
7.4% among all popular apps we studied. Following we elaborate
on this technique.
Design. More specifically, the idea behind ViewFinder is to find
partial URLs or strings similar to URL components from the Intent
filter and the code of a public activity, for generating the test cases
(that is, Intents) most likely to navigate the activity’s WebView to
risky targets. This purpose is served by an ADB-based [13] fuzzer,
a simple app analyzer and a runtime monitor that instruments An-
droid APIs. The fuzzer receives from the analyzer clues gathered
from app data related to individual activities. These clues are con-
verted into Intents by the fuzzer to test the activities. As mentioned
earlier, all web-to-app invocations go through Intents: both explicit
and implicit schemes are translated to the Intents without the target
activity name, which rely on Intent filters to locate their recipients;
a deep link, however, provides an activity name used by an Intent
to directly trigger a specific activity. Our fuzzer directly generates
these two types of Intents, with or without activity names, to test
each app. This test is further helped by our instrumentation of
APIs, which enables the monitor to inject content into the calls
for extracting data from a test Intent. Also, to find out whether an
input successfully navigate a WebView, the monitor watches the
operations that load URLs to the instance.
URL-guided fuzz. For each app under the test, the app analyzer
first inspects its manifest file to identify public activities (e.g.,“export
ed=true”). Each of them are then evaluated by the fuzzer, through the
Intents with or without the activity name, depending on whether
the activity claims an Intent filter. The Intent filter has a data
field, including scheme, host, path and other attributes. These
attributes are set for capturing an Intent with a navigation request
(StartActivity) from a remote URL (scheme IPC or deep link),
when they are found in the data URI field in the Intent.
To fuzz an app, most importantly here is to construct the right
URI field. The field carries a URL, with a scheme (standard HTTP
“http(s)://” or customized one “fb://”), a domain, a path and parame-
ters (e.g., “?URL="). This field is automatically built by the fuzzer
based upon the clues collected from Intent filters and the app code,
as follows.
• Activity with Intent filter. For the activity opened through the
standard Android scheme IPC, it needs to claim an Intent filter.
To fuzz such an activity, the analyzer first attempts to pick up
data pieces from its Intent filter. Specifically, in the case that the
activity expects HTTP links, it will claim domain and path in the
filter, which the fuzzer can directly use to create a link (for the data
URI field), together with the target URL (e.g., “www.attack.com")
to be loaded into the WebView. As an example, for the activity
receiving a URL (through an Intent) with the scheme “http://”, host
“www.amazon.com/” and the path “abc", our fuzzer generates a link
“http://www.amazon.com/abc?url=www.attack.com” for the test.
If the monitor sees “http://www.attack.com” opened by the target
activity, ViewFinder reports that it is vulnerable.
More complicated is when an activity claims a customized scheme
(e.g., “fb://”), since the scheme can directly locate the activity and
therefore the OS does not need the domain and path information
in the Intent filter, and can leave the format checking to the app.
To generate the URI string for a test Intent, the fuzzer uses the
following strategies. It tries the test cases with the target URL di-
rectly attached to the scheme (e.g., “fb://www.attack.com”), and the
domain-like string discovered from the manifest (from “host” field in
the Intent filter), together with the standard redirection parameter
like ‘?url=” (e.g., “fb://www.facebook.com/?url=www.attack.com”).
Also, it leverages the discoveries made by the analyzer from the
app code. Specifically, the analyzer disassembles the app (through
apktool[22] in our implementation), collects all the strings from
the activity and identifies the URL components from them, particu-
larly the strings containing navigation parameters such as “?url=”,
“?redirection=”, “?uri=”, etc. These selected strings are then used
by the fuzzer to generate other test cases, together with the do-
mains found from the manifest, e.g., “pinterest://www.pinterest.
com/offsite/check?url=www.attack.com”.
• Activity without Intent filter. For the activity does not claim any
Intent filter (which is often reserved for use by local apps only), it
needs to be triggered by the Intent carrying its class name, together
with the right data URI. To find such a URI, the analyzer identifies
all URL-like strings from the app code, and picks out those not
using the HTTP scheme but having the navigation parameter fields
like “?url=” and “?uri=”. These strings are then used to fill the URI
field in a test Intent, with the navigation fields set to the target
domain (e.g., attack.com). Using the Intent generated in this way,
the fuzzer evaluates every public activity through ADB to find those
manipulatable from the remote.
Another test performed by the fuzzer is whether an activity di-
rectly reads from the data URI field or the extra field of an Intent
a URL for navigating its WebView. To this end, the fuzz sets the
URI to the target domain. The extra field, however, is more dif-
ficult to handle: the field is a collection of customized key-value
pairs. Without knowing the right key, we cannot put the target
URL at a right place. Our solution is to hook the Android system
function Intent.getStringExtra() for getting the values from
the extra field for the app under the test. The idea is that when the
app queries through the function, the monitor returns the target
URL (such as attack.com) and watches whether the URL redirects
the app’s WebView. To avoid the performance impact introduced
by frequent injections, we label each test Intent by adding a tag
to its extra field. During the fuzz, only when the monitor finds
Intent.getStringExtra() operating on the labeled Intent, will
it change the return value.
Our approach also utilizes known vulnerabilities to generate test
cases. For example, when the monitor observes that test URLs (e.g.,
amazon.com) are loaded but the redirection through parameters
Session D2:  Vulnerable Mobile AppsCCS’17, October 30-November 3, 2017, Dallas, TX, USA838like ?url= fails, ViewFinder automatically generates another sample
using a:PI:EMAIL:PI:EMAIL, based upon the inconsis-
tency problem (between Uri.getHost() and WebView) discussed
in Section 3.3. This strategy helps identify the apps with common
vulnerabilities.
Runtime monitor. In our implementation, we built the monitor
(for finding whether a test URL is loaded by a WebView instance) on
top of an open-source tool called Xposed [32]. To inspect URL load-
ing, ViewFinder hooks the API WebView.loadUrl() to intercept
the navigation operation. Also instrumented in our implementation
is Intent.getStringExtra(), through which ViewFinder changes
the return values for the queries on the extra field in an Intent.
Discussion. As mentioned earlier, ViewFinder does not introduce
any false positive: any flagged app is confirmed to be indeed prob-
lematic. On the other hand, as many other dynamic analyzers, there
is no guarantee whatsoever that we can identify all vulnerable apps
or all vulnerable activities in individual apps. Nevertheless, our
study shows that even this simple technique can easily find many
high-value targets for the remote adversary, making the case that
remote infections, cross-app collusion are not a fantasy but a real
threat. Further running the tool over thousands of most popular
apps, we demonstrate that the threat is pervasive and significant,
even based upon the low-end estimate made by this imperfect tool.
4.2 Findings
Setup. we collected 5,000 apps receiving URL schemes or Intents
from other apps (with at least one Intent-filter for schemes or the
attribute “android:exported" set to “true”) from Google Play top-
ranked apps, in October, 2016, covering 36 categories like “Social”,
“Communication” and “Tools”. Running ViewFinder to analyze all
these apps took 7 days on 3 Nexus 5. To validate the results, we
manually checked each of the detected apps, using the generated
schemes as inputs to confirm that the app can indeed be navigated
to the site under our control. No false positive was found. In the
meantime, due to the challenges in unguided manual analysis of
these complicated apps (16.7 MB on average), we did not have the
ground truth to understand the coverage of the scan. So, all the
findings reported here should only be considered as a lower limit
for the impact of the XAWI threat.
Landscape. Among the 5,000 apps, 372 of them (7.4%) were found
to contain the WebViews subject to remote infections. Besides Face-
book and Twitter (Section 3), other popular apps include TripAdvi-
sor, Google Drive and Yelp. Table 1 in Appendix presents the top
50 XAWI-susceptible apps, together with their Google-Play install
counts. As we can see here, each app has 46,195,505 installs on
average, which may affect hundreds of millions of users around the
world. Also, we found that most of these apps are newly updated:
84.2% apps are updated in year 2016. This indicates that the security
risk of XAWI has not yet come to the app vendors’ attention.
Attack opportunities. Our scan also brought to light the potential
attack opportunities exposed by these apps (Table 1). Particularly,
81.6% popular apps (e.g., Best Buy, WPS Office and Cymera) can
respond to remote commands while running in the background,
which enables the remote adversary to maintain a persistent control
on these apps, once their WebViews are contaminated. Also JS
interfaces, HTML5 supports and callbacks are found in Pinterest,
KaKaoTalk, Hola Launcher, etc. Further discovered in our study are
the apps that provide ideal materials for an RDP: 287 apps have
at least one vulnerable WebWiew without any address bar, 151
without any title and 80 apps can show a webpage in full screen. As
soon as these apps or their co-located apps are infected by XAWI,
they could be turned into building blocks for the RDP attack, for
displaying the fake UIs to impersonate the critical views of other
apps or their own. Examples of these apps including TouchPal
Keyboard, iQiyi and mjweather (see Table 1 in Appendix). Among
these apps, the WebViews in 162 of them can be triggered by HTTP
schemes, while the others need the activity names to invoke.
Taking a close look at the vulnerable apps, our studies brought
to light a few surprising findings. For example, we found that some
WebViews without JS interfaces and callbacks can still leak out
device information to a remote adversary. For instance, iQiyi, a
famous video-sharing app, a counterpart of YouTube in China, ex-
poses such information as DeviceID and locations by appending
them to any URL given by the remote adversary through an infected
WebView (e.g., https://attack.com/?deviceID=[deviceid]&platform=
[platform]&...&location=[location]). Also discovered is the vulnera-
ble WebView inside shared libraries. As an example, KaKao SDK,
a popular OAuth library in Koera, includes exposed WebViews,
making all the apps integrating it vulnerable. Examples include
com.kakao.taxi, com.ileon.melon and com.kalao.page, each
of which has 10,000,000 ∼ 50,000,000 installs. Other examples of
the new attack opportunities we found are presented in Appendix.
4.3 Mitigation
Mitigating the XAWI risk is challenging, due to the contention be-
tween the demand for convenient web-to-app interactions and the
need to properly control the use of these channels. Fundamentally,
only the app developer knows whether a cross-WebView naviga-
tion request is reasonable and whether the task other apps asking
her program to handle stays within the scope of the services she
intends to provide. Also the developer is at the best position to
balance her need for user retention with the safeguards put in place
against the abuse of her app’s capabilities. To mitigate the XAWI
attack, an app developer could keep his app’s WebView private,
enforce proper domain control on it, or notify user when "suspi-
cious" cross-app navigations (e.g., those without user-interactions)
happen. That being said, still there is an important role for the OS to
play, which is particularly important given that the developer-end
protection inevitably takes a longer time to deploy, with no guar-
antee to be respected by app vendors (especially when restrictions
on cross-app interactions may run against some of their business
interests). Therefore in this section, we present a simple, yet ef-
fective system-level solution, called NaviGuard, for mediating the
web-to-app channels.
NaviGuard. The idea of NaviGuard is to identify and control anoma-
lous cross-WebView navigation requests, making them more observ-
able to mobile users. Since it’s infeasible for attackers to program-
matically mimic touch event inside a WebView, our approach takes
a strategy that allows the requests with evidence of implicit user
consents (i.e., triggered by UI interactions) to silently go through,
notifies the users of those without such consents and blocks the re-
quests of high risks (e.g., those from background processes), which
Session D2:  Vulnerable Mobile AppsCCS’17, October 30-November 3, 2017, Dallas, TX, USA839reduces the burden on users when such channels are legitimately
used. This simple protection is shown to work effectively against
all the attacks we discovered.
Specifically, to control the channels, NaviGuard hooks Start-
Activity() to monitor when an activity is launched. When this
happens, our approach further determines whether the operation
(i.e., StartActivity()) comes from WebView and has been issued
by a foreground activity. To this end, we hook all JS interfaces
APIs (e.g., addJavascriptInterface) and WebView callbacks (e.g.,
setWebViewClient), since any Intent initiated from WebView has
to go through one of these two channels: Android default schemes
are handled by shouldOverrideUrlLoading in WebViewClient,
and deep links can be processed by any of these APIs, depending
on its implementation. To link the observed StartActivity() to a
specific WebView instance, NaviGuard records the thread ID and the
WebView ID for each JS interface and callback invocation in a table
and removes the IDs once the API call completes. Also stored at that
time is the state of the WebView’s activity, particularly whether
it is on the top (through the API Activity.isResumed()). When
an Intent and its StartActivity() event are observed, NaviGuard
looks up the table using the caller’s thread ID to find out whether
the call indeed comes from a WebView instance. If so, further we
check whether the instance (and its activity) runs in the foreground.
When this is not the case, NaviGuard immediately stops the launch
request from the background WebView, since the user cannot open
another activity by operating on a background WebView. Otherwise,
NaviGuard tries to link the current operation with a recent user
event (e.g., a click), and when the attempt fails, pops up a dialog
window to let the user confirm whether she wants the new activity
to be activated.
To establish a relation between a URL navigation request and
user actions, NaviGuard interposes on user-action related APIs such
as WebView.onTouchEvent() to obtain the WebView ID should a
touch event happen, and keeps the ID in the table. In the meantime,
when a StartActivity() event occurs, its hook also acquires the
caller’s WebView ID if the event is issued from a WebView, and
looks up the table to find whether a touch event is observed from
the same WebView, within a short period of time (1 second set for
our implementation). Alternatively, for Android 5.0 and later, we
can utilize the API WebResourceRequest.hasGesture() to deter-
mine the relation between a user’s gesture (like a click) and the
start of an activity. Note that although these approaches are still
subject to clickjacking [36], they make a XAWI attack more visible
to the user: even when the remote adversary manages to issue a
navigation request using an unrelated user click to infect another
app, he cannot command the infected WebView (now in the fore-
ground) to switch to the background through another navigation
request without triggering a user dialog. Another way to avoid user
interactions is using a whitelist of trusted websites. The developer
can include such a list in her app’s manifest. Whenever a navigation
is directed from any domain on the list, the request is allowed to
go through without asking the user.
Evaluation. To evaluate NaviGuard, we chose the 6 vulnerable
apps (i.e., Facebook, Twitter, Baidu, etc.) analyzed in Section 3 and
Appendix A, together with 44 apps randomly selected from all the
vulnerable apps reported by ViewFinder, and installed them on a
Nexus 5 device running a customized Android 4.4 with the Navi-
Guard enhancement. Then we utilized the ADB tool to inject the
infectious Intents found by ViewFinder from these apps, which
successfully navigated their unprotected WebViews to the sites un-
der our control. In this experiment, however, all these Intents were
either blocked (when they were issued from the background) or
caused an alert to be raised to get the user’s consent. This indicates
that no longer can such attacks go unnoticed to the user.
Also important here is the performance of the technique, which
should not cause too much delay when there is no infection at-
tempt going on. In our experiment, we ran Monkey, a UI exerciser
tool [15], to generate 10,000 random events towards 360 popular
apps (top 10 from each of 36 Google Play categories) in the presence
of NaviGuard, and then replay the same set of events to the same
apps without our protection. During the two tests, we measured
the delays introduced, denoted by t1 and t2, respectively for these
two settings, and further calculated the overhead ((t1 − t2)/t2). The
study shows that the overhead incurred is very low, around 0.5%.
We further evaluated the compatibility of our techniques with