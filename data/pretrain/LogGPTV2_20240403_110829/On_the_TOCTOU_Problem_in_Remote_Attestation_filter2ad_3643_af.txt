entirely in software. Security of software-based techniques relies on
a precise measurement timing, which is only applicable to settings
where the communication delay between Vrf and Prv is negligi-
ble and/or constant, e.g., communication between peripherals and
a host CPU. Thus, software-based RA is unsuitable for environ-
ments where RA must be performed over the internet. Whereas,
hybrid RA is particularly suitable for low-end embedded devices.
It provides the same security guarantees as hardware-based RA,
while minimizing modifications to underlying MCU hardware. Cur-
rent hybrid RA techniques [7–10, 14, 52] implement the integrity-
ensuring function (e.g., MAC) in software, and use trusted hardware
to control execution of this software, preventing any violations that
might cause RA security problems, e.g., gadget-based attacks [53]
or key leakage. This paper represents a paradigm shift of hybrid
RA, by having trusted hardware additionally provide some context
about Prv memory state.
– Temporal Aspects of RA: Besides TOCTOU, two other tempo-
ral aspects are essential for RA security: First, temporal consis-
tency [22] means guaranteeing that the RA result reflects an instan-
taneous snapshot of Prv attested memory at some point in time
during RA. Lack thereof allows self-relocating malware to escape
detection by copying and/or erasing itself during RA. Temporal
Session 11A: Attestation and Firmware Security CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2932consistency is achieved by enforcing atomic (uninterruptible) execu-
tion of attestation code, or by locking attested memory (i.e., making
it unmodifiable) during RA execution. Second, when RA is used on
safety-critical and/or real-time devices [38], atomicity requirement
might interfere with the real-time nature of Prv application. To
address this issues, SMARM [37] relaxes this requirement by using
probabilistic malware detection. Meanwhile, ERASMUS [12] and
SeED [26] are based on Prv self-measurements, in order to detect
transient malware that infects Prv and leaves before the next RA
instance. See Section 4.3 for further discussion on these types of
techniques. Atrium [35] deals with physical-hardware adversaries
that intercept instructions as they are fetched to the CPU during
attestation. Atrium refers to that issue as TOCTOU. Despite nomen-
clature, that issue is clearly different from RAT A goal.
– Formal Verification andRA: Formal verification provides signif-
icantly higher level of assurance, yielding provable security for pro-
tocol specifications and implementations thereof. Recently, several
efforts focused on formal verification of security-critical services
and systems [23, 54–58]. VRASED [10] realized a formally verified
RA architecture targeting low-end devices. Other formally verified
security services were obtained by extending VRASED to derive re-
mote proofs of software update, memory erasure and system-wide
MCU reset [1]. APEX [6] builds on top of VRASED to develop a
verified architecture for proofs of remote software execution on
low-end devices [6]. RATA also builds on top of VRASED, extend-
ing it to provide TOCTOU security while retaining original verified
guarantees. Relying on VRASED allows us to reason about RAT A
design and to formally verify its security properties. Nonetheless,
RAT A main concepts are applicable to other hybrid (and possibly
hardware-based, such as [20]) RA architectures.
10 CONCLUSIONS
In this paper, we design, prove security of, and formally verify
two designs (RAT AA and RAT AB) to secure RA against TOCTOU-
related attacks, which perform illegal binary modifications on a
low-end embedded system, in between successive RA instances.
RAT AA and RAT AB modules are formally specified and verified
using a model-checker. They are also composed with VRASED – a
verified RA architecture. We show that this composition is TOCTOU-
secure using a reduction-based cryptographic proof. Our evaluation
demonstrates that a TOCTOU-Secure design is affordable even for
cost-sensitive low-end embedded devices. Also, i n most cases, it
reduces RA time complexity from linear to constant, in the size of
the attested memory.
ACKNOWLEDGMENTS
This work was supported by funding from: the Semiconductor
Research Corporation (SRC) Contract 2019-TS-2907, NSF Awards
SATC-1956393 and CICI-1840197, a subcontract from Peraton (for-
merly Perspecta) Labs, as well as the Coordinating Center for Thai
Government Science and Technology Scholarship Students (CSTS),
National Science and Technology Development Agency (NSTDA).
REFERENCES
[1] I. De Oliveira Nunes, K. Eldefrawy, N. Rattanavipanon, and G. Tsudik, “Pure:
Using verified remote attestation to obtain proofs of update, reset and erasure in
low-end embedded systems,” in ICCAD, 2019.
[2] M. Ammar and B. Crispo, “Verify&revive: Secure detection and recovery of com-
promised low-end embedded devices,” in Annual Computer Security Applications
Conference, pp. 717–732, 2020.
[3] T. Abera, N. Asokan, L. Davi, J. Ekberg, T. Nyman, A. Paverd, A. Sadeghi, and
G. Tsudik, “C-FLAT: control-flow attestation for embedded systems software,” in
ACM CCS, pp. 743–754, ACM, 2016.
[4] I. De Oliveira Nunes, S. Jakkamsetti, and G. Tsudik, “Tiny-cfa: Minimalistic
control-flow attestation using verified proofs of execution,” in 2021 Design, Au-
tomation Test in Europe Conference Exhibition (DATE), pp. 641–646, IEEE, 2021.
[5] G. Dessouky, T. Abera, A. Ibrahim, and A.-R. Sadeghi, “Litehax: lightweight
hardware-assisted attestation of program execution,” in 2018 IEEE/ACM Interna-
tional Conference on Computer-Aided Design (ICCAD), pp. 1–8, IEEE, 2018.
[6] I. De Oliveira Nunes, K. Eldefrawy, N. Rattanavipanon, and G. Tsudik, “APEX: A
verified architecture for proofs of execution on remote devices under full software
compromise,” in 29th USENIX Security Symposium (USENIX Security 20), (Boston,
MA), USENIX Association, Aug. 2020.
[7] K. Eldefrawy, G. Tsudik, A. Francillon, and D. Perito, “SMART: Secure and minimal
[9] K. Eldefrawy, N. Rattanavipanon, and G. Tsudik, “HYDRA: hybrid design for
[8] P. Koeberl, S. Schulz, A.-R. Sadeghi, and V. Varadharajan, “TrustLite: A security
architecture for (establishing dynamic) root of trust,” in NDSS, 2012.
architecture for tiny embedded devices,” in EuroSys, 2014.
remote attestation (using a formally verified microkernel),” in Wisec, 2017.
[10] I. De Oliveira Nunes, K. Eldefrawy, N. Rattanavipanon, M. Steiner, and G. Tsudik,
“VRASED: A verified hardware/software co-design for remote attestation,” in
USENIX Security, 2019.
[11] Trusted Computing Group., “Trusted platform module (tpm),” 2017.
[12] X. Carpent, N. Rattanavipanon, and G. Tsudik, “ERASMUS: Efficient remote
[14] A. Francillon, Q. Nguyen, K. B. Rasmussen, and G. Tsudik, “A minimalist approach
[13] X. Carpent, K. ElDefrawy, N. Rattanavipanon, and G. Tsudik, “Lightweight swarm
attestation via self-measurement for unattended settings,” in DATE, 2018.
attestation: a tale of two lisa-s,” in ASIACCS, 2017.
to remote attestation,” in DATE, 2014.
[15] S. Bratus, N. D’Cunha, E. Sparks, and S. W. Smith, “Toctou, traps, and trusted
computing,” in International Conference on Trusted Computing, Springer, 2008.
ACM Computing Surveys (CSUR), vol. 49, no. 3, p. 51, 2016.
[17] M. Geden and K. Rasmussen, “Hardware-assisted remote runtime attestation
for critical embedded systems,” in 2019 17th International Conference on Privacy,
Security and Trust (PST), pp. 1–10, IEEE, 2019.
[18] I. De Oliveira Nunes, S. Jakkamsetti, N. Rattanavipanon, and G. Tsudik, “RATA
source code.” https://github.com/sprout-uci/RATA, 2021.
[16] R. V. Steiner and E. Lupu, “Attestation in wireless sensor networks: A survey,”
[25] S. Ravi, A. Raghunathan, and S. Chakradhar, “Tamper resistance mechanisms for
[23] J.-K. Zinzindohoué, K. Bhargavan, J. Protzenko, and B. Beurdouche, “Hacl*: A
[19] O. Girard, “openMSP430.” https://opencores.org/projects/openmsp430, 2009.
[20] J. Noorman, J. V. Bulck, J. T. Mühlberg, et al., “Sancus 2.0: A low-cost security
architecture for iot devices,” ACM Trans. Priv. Secur., vol. 20, no. 3, 2017.
[21] J. Noorman, P. Agten, W. Daniels, R. Strackx, A. V. Herrewege, C. Huygens, B. Pre-
neel, I. Verbauwhede, and F. Piessens, “Sancus: Low-cost trustworthy extensible
networked devices with a zero-software trusted computing base,” in USENIX
Security Symposium, pp. 479–494, USENIX Association, 2013.
[22] X. Carpent, K. Eldefrawy, N. Rattanavipanon, and G. Tsudik, “Temporal consis-
tency of integrity-ensuring computations and applications to embedded systems
security,” in ASIACCS, 2018.
verified modern cryptographic library,” in CCS, 2017.
[24] A. Cimatti, E. Clarke, E. Giunchiglia, F. Giunchiglia, M. Pistore, M. Roveri, R. Se-
bastiani, and A. Tacchella, “Nusmv 2: An opensource tool for symbolic model
checking,” in CAV, 2002.
secure embedded systems,” in VLSI Design, 2004.
[26] A. Ibrahim, A.-R. Sadeghi, and S. Zeitouni, “SeED: secure non-interactive attesta-
tion for embedded devices,” in ACM Conference on Security and Privacy in Wireless
and Mobile Networks (WiSec), 2017.
[27] F. M. Anwar and M. Srivastava, “Applications and challenges in securing time,”
in 12th USENIX Workshop on Cyber Security Experimentation and Test (CSET 19),
2019.
[28] R. Annessi, J. Fabini, and T. Zseby, “It’s about time: Securing broadcast time
synchronization with data origin authentication,” in 2017 26th International Con-
ference on Computer Communication and Networks (ICCCN), pp. 1–11, IEEE, 2017.
[29] L. Narula and T. E. Humphreys, “Requirements for secure clock synchronization,”
IEEE Journal of Selected Topics in Signal Processing, vol. 12, no. 4, pp. 749–762,
2018.
[30] X. Du and H.-H. Chen, “Security in wireless sensor networks,” IEEE Wireless
Communications, vol. 15, no. 4, pp. 60–66, 2008.
[31] S. Ganeriwal, S. Čapkun, C.-C. Han, and M. B. Srivastava, “Secure time synchro-
nization service for sensor networks,” in Proceedings of the 4th ACM workshop on
Wireless security, pp. 97–106, 2005.
[32] Y. Lindell and J. Katz, Introduction to modern cryptography, ch. 4.3, pp. 109–113.
Chapman and Hall/CRC, 2014.
Session 11A: Attestation and Firmware Security CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2933[33] A. Irfan, A. Cimatti, A. Griggio, M. Roveri, and R. Sebastiani, “Verilog2SMV: A tool
for word-level verification,” in Design, Automation & Test in Europe Conference &
Exhibition (DATE), 2016, 2016.
[34] T. Instruments, “Msp430 ultra-low-power sensing & measurement mcus.” http://
www.ti.com/microcontrollers/msp430-ultra-low-power-mcus/overview.html.
[35] S. Zeitouni, G. Dessouky, O. Arias, D. Sullivan, A. Ibrahim, Y. Jin, and A.-R.
Sadeghi, “Atrium: Runtime attestation resilient under memory attacks,” in Pro-
ceedings of the 36th International Conference on Computer-Aided Design, pp. 384–
391, IEEE Press, 2017.
[36] G. Dessouky, S. Zeitouni, T. Nyman, A. Paverd, L. Davi, P. Koeberl, N. Asokan,
and A.-R. Sadeghi, “Lo-fat: Low-overhead control flow attestation in hardware,”
in Proceedings of the 54th Annual Design Automation Conference 2017, p. 24, ACM,
2017.
[37] X. Carpent, N. Rattanavipanon, and G. Tsudik, “Remote attestation of iot devices
via SMARM: Shuffled measurements against roving malware,” in HOST, 2018.
[38] X. Carpent, K. Eldefrawy, N. Rattanavipanon, A.-R. Sadeghi, and G. Tsudik,
“Reconciling remote attestation and safety-critical operation on simple iot devices,”
in DAC, 2018.
[39] N. Asokan, F. Brasser, A. Ibrahim, A. Sadeghi, M. Schunter, G. Tsudik, and
C. Wachsmann, “SEDA: scalable embedded device attestation,” in ACM CCS,
pp. 964–975, ACM, 2015.
[40] M. Ambrosin, M. Conti, A. Ibrahim, G. Neven, A. Sadeghi, and M. Schunter,
“SANA: secure and scalable aggregate network attestation,” in ACM CCS, pp. 731–
742, ACM, 2016.
[41] A. Ibrahim, A. Sadeghi, G. Tsudik, and S. Zeitouni, “DARPA: device attestation
resilient to physical attacks,” in WISEC, pp. 171–182, ACM, 2016.
[42] F. Kohnhäuser, N. Büscher, S. Gabmeyer, and S. Katzenbeisser, “Scapi: a scalable
attestation protocol to detect software and physical attacks,” in Proceedings of the
10th ACM Conference on Security and Privacy in Wireless and Mobile Networks,
pp. 75–86, ACM, 2017.
[43] F. Kohnhäuser, N. Büscher, and S. Katzenbeisser, “Salad: Secure and lightweight
attestation of highly dynamic and disruptive networks,” in Proceedings of the
2018 on Asia Conference on Computer and Communications Security, pp. 329–342,
ACM, 2018.
[44] I. D. O. Nunes, G. Dessouky, A. Ibrahim, N. Rattanavipanon, A.-R. Sadeghi, and
G. Tsudik, “Towards systematic design of collective remote attestation protocols,”
in ICDCS, 2019.
[45] Z. Sun, B. Feng, L. Lu, and S. Jha, “Oat: Attesting operation integrity of embedded
devices,” in 2020 IEEE Symposium on Security and Privacy (SP), pp. 1433–1449,
IEEE, 2020.
[46] N. L. Petroni Jr, T. Fraser, J. Molina, and W. A. Arbaugh, “Copilot — A coprocessor-
based kernel runtime integrity monitor,” in USENIX Security Symposium, 2004.
[47] X. Kovah, C. Kallenberg, C. Weathers, A. Herzog, M. Albin, and J. Butterworth,
“New results for timing-based attestation,” in IEEE Symposium on Security and
Privacy, SP 2012, pp. 239–253, IEEE Computer Society, 2012.
[48] Intel, “Intel Software Guard Extensions (Intel SGX).” https://software.intel.com/
en-us/sgx.
[49] R. Kennell and L. H. Jamieson, “Establishing the genuinity of remote computer
[53] H. Shacham, “The geometry of innocent flesh on the bone: Return-into-libc
[52] F. Brasser, B. E. Mahjoub, A. Sadeghi, C. Wachsmann, and P. Koeberl, “Tytan:
systems,” in USENIX Security Symposium, 2003.
[50] A. Seshadri, A. Perrig, L. Van Doorn, and P. Khosla, “SWATT: Software-based
attestation for embedded devices,” in IEEE Symposium on Research in Security
and Privacy (S&P), (Oakland, California, USA), pp. 272–282, IEEE, 2004.
[51] A. Seshadri, M. Luk, E. Shi, A. Perrig, L. van Doorn, and P. Khosla, “Pioneer:
Verifying code integrity and enforcing untampered code execution on legacy
systems,” ACM SIGOPS Operating Systems Review, December 2005.
tiny trust anchor for tiny devices,” in DAC, pp. 34:1–34:6, ACM, 2015.
without function calls (on the x86),” in CCS ’07, 2007.
[54] C. Hawblitzel, J. Howell, J. R. Lorch, A. Narayan, B. Parno, D. Zhang, and B. Zill,
“Ironclad apps: End-to-end security via automated full-system verification.,” in
OSDI, 2014.
and security of OpenSSL HMAC,” in USENIX, 2015.
TLS with verified cryptographic security,” in IEEE S&P, 2013.
[57] X. Leroy, “Formal verification of a realistic compiler,” Communications of the
ACM, vol. 52, no. 7, 2009.
[58] G. Klein, K. Elphinstone, G. Heiser, J. Andronick, D. Cock, P. Derrin, D. Elkaduwe,
K. Engelhardt, R. Kolanski, M. Norrish, et al., “sel4: Formal verification of an os
kernel,” in SIGOPS, ACM, 2009.
[59] F. Brasser, K. B. Rasmussen, A. Sadeghi, and G. Tsudik, “Remote attestation for
low-end embedded devices: the prover’s perspective,” in DAC, ACM, 2016.
[60] H. Krawczyk and P. Eronen, “HMAC-based extract-and-expand key derivation
function (HKDF),” Internet Request for Comment RFC 5869, Internet Engineering
Task Force, May 2010.
[56] K. Bhargavan, C. Fournet, M. Kohlweiss, A. Pironti, and P.-Y. Strub, “Implementing
[55] L. Beringer, A. Petcher, Q. Y. Katherine, and A. W. Appel, “Verified correctness
APPENDIX
A VRF AUTHENTICATION DETAILS
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22