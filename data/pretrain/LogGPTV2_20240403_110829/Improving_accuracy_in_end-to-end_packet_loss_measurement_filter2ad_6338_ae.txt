the true values. Comparing the ZING results with BADABING, we
see that for the same trafﬁc conditions and probe rate, BADABING
reports loss frequency and duration estimates that are signiﬁcantly
closer to the true values.
7. USING BADABING IN PRACTICE
There are a number of important practical issues which must be
considered when using BADABING in the wide area:
• The tool requires the user to select values for p and N. Let us
assume for the sake of the current discussion that the num-
ber of loss events is stationary over time. (Note that we al-
low the duration of the loss events to vary in an almost ar-
bitrary way, and to change over time. One should keep in
mind that in our current formulation we estimate the aver-
age duration and not the distribution of the durations.) Let
lllll0.00.20.40.60.81.00.0000.0040.0080.012probe rate (p)loss frequencytrue loss frequencylalpha=0.05 (5 millisec.)alpha=0.10 (10 millisec.)alpha=0.20 (20 millisec.)lllll0.00.20.40.60.81.00.0000.0040.0080.012probe rate (p)loss frequencytrue loss frequencyltau=20 millisec.tau=40 millisec.tau=80 millisec.Table 8: Comparison of results for BADABING and ZING with
constant-bit rate (CBR) and Harpoon web-like trafﬁc. Probe
rates matched to p = 0.3 for BADABING (876 kb/s) with probe
packet sizes of 600 bytes. (BADABING results copied from row
2 of Tables 4 and 6.)
trafﬁc
scenario
CBR
Harpoon
web-like
tool
BADABING
BADABING
ZING
ZING
loss frequency
true
0.0069
0.0069
0.0011
0.0159
measured
0.0065
0.0041
0.0011
0.0019
loss duration
true (sec) measured (sec)
0.068
0.068
0.113
0.119
0.073
0.010
0.143
0.007
L be the mean number of loss events that occur over a unit
period of time. For example, if an average of 12 loss events
occur every minute, and our discretization unit is 5 millisec-
onds, then L = 12/(60× 200) = .001 (this is, of course, an
estimate of the true the value of L). With the stationarity as-
sumption on L, we expect the accuracy of our estimators to
depend on the product pNL, but not on the individual values
of p, N or L3. Speciﬁcally, a reliable approximation of the
standard deviation in our estimation of duration is given by:
StdDev(duration) ≈ 1√
pNL
Thus, the individual choice of p and N allow a trade off be-
tween timeliness of results and impact that the user is will-
ing to have on the link. Prior empirical studies can provide
initial estimates of L. An alternate design is to take mea-
surements continuously, and to report an when our validation
techniques conﬁrm that the estimation is robust. This can be
particularly useful in situations where p is set at low level.
In this case, while the measurement stream can be expected
to have little impact on other trafﬁc, it may have to run for
some time until a reliable estimate is obtained.
• Our estimation of duration is critically based on correct esti-
mation of the ratio B/M (cf. § 5). We estimate this ratio by
counting the occurrence rate of yi = 01, as well as the oc-
currence rate of yi = 10. The number B/M can be estimated
as the average of these two rates. The validation is done by
measuring the difference between these two rates. This dif-
ference is directly proportional to the expected standard devi-
ation of the above estimation. Similar remarks apply to other
validation tests we mention in both estimation algorithms.
• The recent study on packet loss via passive measurement re-
ported in [25] indicates that loss episodes in backbone links
can be very short-lived (e.g., on the order of several mi-
croseconds). The only condition for our tool to successfully
detect and estimate such short durations is for our discretiza-
tion of time to be ﬁner, even in a slight way, than the or-
der of duration we attempt to estimate. Such a requirement
may imply that commodity workstations cannot be used for
accurate active measurement of end-to-end loss characteris-
tics in some circumstances. A corollary to this is that ac-
tive measurements for loss in high bandwidth networks may
require high-performance, specialized systems that support
small time discretizations.
• Our classiﬁcation of whether a probe traversed a congested
path concerns not only whether the probe was lost, but how
3Note that estimators that average individual estimations of the du-
ration of each loss episode are not likely to perform that well at low
values of p.
long it was delayed. While an appropriate τ parameter ap-
pears to be dictated primarily by the value of p, it is not yet
clear how best to set α for an arbitrary path, when charac-
teristics such as the level of statistical multiplexing or the
physical path conﬁguration are unknown. Examination of
the sensitivity of τ and α in more complex environments is a
subject for future work.
• To accurately calculate end-to-end delay for inferring con-
gestion requires time synchronization of end hosts. While
we can trivially eliminate offset, clock skew is still a con-
cern. New on-line synchronization techniques such as re-
ported in [26] or even off line methods such as [38] could be
used effectively to address this issue.
8. SUMMARY, CONCLUSIONS AND
FUTURE WORK
The purpose of our study was to understand how to measure
end-to-end packet loss characteristics accurately with probes and
in a way that enables us to specify the impact on the bottleneck
queue. We began by evaluating the capabilities of simple Poisson-
modulated probing in a controlled laboratory environment consist-
ing of commodity end hosts and IP routers. We consider this testbed
ideal for loss measurement tool evaluation since it enables repeata-
bility, establishment of ground truth, and a range of trafﬁc condi-
tions under which to subject the tool. Our initial tests indicate that
simple Poisson probing is relatively ineffective at measuring loss
episode frequency or measuring loss episode duration, especially
when subjected to TCP (reactive) cross trafﬁc.
These experimental results led to our development of a probe
process that provides more accurate estimation of loss characteris-
tics than simple Poisson probing. The experimental design is con-
structed in such a way that the performance of the accompanying
estimators relies on the total number of probes that are sent, but
not on their sending rate. Moreover, simple techniques that allow
users to validate the measurement output are introduced. We im-
plemented this method in a new tool, BADABING, which we tested
in our laboratory. Our tests demonstrate that BADABING, in most
cases, accurately estimates loss frequencies and durations over a
range of cross trafﬁc conditions. For the same overall packet rate,
our results show that BADABING is signiﬁcantly more accurate than
Poisson probing for measuring loss episode characteristics.
While BADABING enables superior accuracy and a better under-
standing of link impact versus timeliness of measurement, there
is still room for improvement. For example, we have considered
adding adaptivity to our probe process model in a limited sense.
We are also considering alternative, parametric methods for infer-
ring loss characteristics from our probe process. Another task is
to estimate the variability of the estimates of congestion frequency
and duration themselves directly from the measured data, under a
minimal set of statistical assumptions on the congestion process.
Acknowledgments
We thank David Donoho for valuable discussions and the anony-
mous reviewers for their helpful comments. This work is supported
in part by NSF grant numbers CNS-0347252, ANI-0335234, and
CCR-0325653 and by Cisco Systems. Any opinions, ﬁndings, con-
clusions or recommendations expressed in this material are those
of the authors and do not necessarily reﬂect the views of the NSF
or of Cisco Systems.
9. REFERENCES
[1] The Wisconsin Advanced Internet Laboratory.
http://wail.cs.wisc.edu, 2005.
[2] A. Adams, J. Mahdavi, M. Mathis, and V. Paxson. Creating a
scalable architecture for Internet measurement. IEEE
Network, 1998.
[3] G. Almes, S. Kalidindi, and M. Zekauskas. A one way packet
loss metric for IPPM. IETF RFC 2680, September 1999.
[4] S. Alouf, P. Nain, and D. Towsley. Inferring network
characteristics via moment-based estimators. In Proceedings
of IEEE INFOCOM ’00, Tel Aviv, Israel, April 2000.
[5] G. Appenzeller, I. Keslassy, and N. McKeown. Sizing router
buffers. In Proceedings of ACM SIGCOMM ’04, Portland,
OR, 2004.
[6] P. Barford and J. Sommers. Comparing probe- and
router-based packet loss measurements. IEEE Internet
Computing, September/October 2004.
[7] P. Benko and A. Veres. A passive method for estimating
end-to-end TCP packet loss. In Proceedings of IEEE
Globecom ’02, Taipei, Taiwan, November 2002.
[8] J. Bolot. End-to-end packet delay and loss behavior in the
Internet. In Proceedings of ACM SIGCOMM ’93, San
Francisco, September 1993.
[9] S. Brumelle. On the relationship between customer and time
averages in queues. Journal of Applied Probability, 8, 1971.
[10] N. Cardwell, S. Savage, and T. Anderson. Modeling TCP
latency. In Proceedings of IEEE INFOCOM ’00, Tel-Aviv,
Israel, March 2000.
[11] M. Coates and R. Nowak. Network loss inference using
unicast end-to-end measurement. In Proceedings of ITC
Conference on IP Trafﬁc, Measurement and Modeling,
September 2000.
[12] N. Dufﬁeld, F. Lo Presti, V. Paxson, and D. Towsley.
Inferring link loss using striped unicast probes. In
Proceedings of IEEE INFOCOM ’01, Anchorage, Alaska,
April 2001.
[13] S. Floyd and V. Paxson. Difﬁculties in simulating the
Internet. IEEE/ACM Transactions on Networking, 9(4),
2001.
[14] C. Fraleigh, C. Diot, B. Lyles, S. Moon, P. Owezarski,
D. Papagiannaki, and F. Tobagi. Design and deployment of a
passive monitoring infrastructure. In Proceedings of Passive
and Active Measurement Workshop, Amsterdam, Holland,
April 2001.
[15] J. Hoe. Improving the start-up behavior of a congestion
control scheme for TCP. In Proceedings of ACM SIGCOMM
’96, Palo Alto, CA, August 1996.
[16] Merit Internet Performance Measurement and Analysis
Project. http://nic.merit.edu/ipma/, 1998.
[17] Internet Protocol Performance Metrics.
http://www.advanced.org/ippm/index.html, 1998.
[18] L. Le, J. Aikat, K. Jeffay, and F. Smith. The effects of active
queue management on web performance. In Proceedings of
ACM SIGCOMM, Karlsruhe, Germany, August 2003.
[19] W. Leland, M. Taqqu, W. Willinger, and D. Wilson. On the
self-similar nature of Ethernet trafﬁc (extended version).
IEEE/ACM Transactions on Networking, pages 2:1–15,
1994.
[20] J. Mahdavi, V. Paxson, A. Adams, and M. Mathis. Creating a
scalable architecture for Internet measurement. In
Proceedings of INET ’98, Geneva, Switzerland, July 1998.
[21] M. Mathis, J. Mahdavi, S. Floyd, and A. Romanow. TCP
selective acknowledgement options. IETF RFC 2018, 1996.
[22] M. Mathis, J. Semke, J. Mahdavi, and T. Ott. The
macroscopic behavior of the TCP congestion avoidance
algorithm. Computer Communications Review, 27(3), July
1997.
[23] NLANR Passive Measurement and Analysis (PMA).
http://pma.nlanr.net/, 2005.
[24] J. Padhye, V. Firoiu, D. Towsley, and J. Kurose. Modeling
TCP throughput: A simple model and its empirical
validation. In Proceedings of ACM SIGCOMM ’98,
Vancouver, Canada, September 1998.
[25] D. Papagiannaki, R. Cruz, and C. Diot. Network
performance monitoring at small time scales. In Proceedings
of ACM SIGCOMM Internet Measurement Conference ’03,
Miami, FL, October 2003.
[26] A. Pasztor and D. Veitch. PC based Precision timing without
GPS. In Proceedings of ACM SIGMETRICS, Marina Del
Ray, CA, June 2002.
[27] V. Paxson. End-to-end Internet packet dynamics. In
Proceedings of ACM SIGCOMM ’97, Cannes, France,
September 1997.
[28] V. Paxson. Strategies for sound Internet measurement. In
Proceedings of ACM SIGCOMM Internet Measurement
Conference ’04, Taormina, Italy, November 2004.
[29] K. Salamatian, B. Baynat, and T. Bugnazet. Cross trafﬁc
estimation by loss process analysis. In Proceedings of ITC
Specialist Seminar on Internet Trafﬁc Engineering and
Trafﬁc Management, Wurzburg, Germany, July 2003.
[30] S. Savage. Sting: A tool for measuring one way packet loss.
In Proceedings of IEEE INFOCOM ’00, Tel Aviv, Israel,
April 2000.
[31] J. Sommers and P. Barford. Self-conﬁguring network trafﬁc
generation. In Proceedings of ACM SIGCOMM Internet
Measurement Conference ’04, 2004.
[32] The DETER Testbed. http://www.isi.edu/deter/, 2005.
[33] A. Tirumala, F. Qin, J. Dugan, J. Ferguson, and K. Gibbs.
Iperf 1.7.0 – the TCP/UDP bandwidth measurement tool.
http://dast.nlanr.net/Projects/Iperf. 2005.
[34] C. Villamizar and C. Song. High Performance TCP in
ASNET. Computer Communications Review, 25(4),
December 1994.
[35] B. White, J. Lepreau, L. Stoller, R. Ricci, S. Guruprasad,
M. Newbold, M. Hibler, C. Barb, and A. Joglekar. An
integrated experimental environment for distributed systems
and networks. In Proceedings of 5th Symposium on
Operating Systems Design and Implementation (OSDI),
Boston, MA, December 2002.
[36] R. Wolff. Poisson arrivals see time averages. Operations
Research, 30(2), March-April 1982.
[37] M. Yajnik, S. Moon, J. Kurose, and D. Towsley.
Measurement and modeling of temporal dependence in
packet loss. In Proceedings of IEEE INFOCOM ’99, New
York, NY, March 1999.
[38] L. Zhang, Z. Liu, and C. Xia. Clock Synchronization
Algorithms for Network Measurements. In Proceedings of
IEEE Infocom, New York, NY, June 2002.
[39] Y. Zhang, N. Dufﬁeld, V. Paxson, and S. Shenker. On the
constancy of Internet path properties. In Proceedings of ACM
SIGCOMM Internet Measurement Workshop ’01, San
Francisco, November 2001.