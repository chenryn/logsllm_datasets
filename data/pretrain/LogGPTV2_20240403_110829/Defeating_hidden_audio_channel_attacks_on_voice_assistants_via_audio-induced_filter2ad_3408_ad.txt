### 5.4 Supervised Learning-based Method

To distinguish between human-issued and hidden voice commands, we leverage the unique vibration features of these commands. Several machine learning algorithms, including Simple Logistic, Support Vector Machine (SVM), Random Forest, and Random Tree, are employed as binary classifiers.

- **Simple Logistic**: This classifier is based on logistic regression and uses a logistic function to predict the type of voice command from the vibration features.
- **Support Vector Machine (SVM)**: SVM relies on a hyperplane to separate the input command sample space into two categories. The hyperplane is determined during the training phase using labeled voice commands from both types. We use Sequential Minimal Optimization (SMO) as the optimization algorithm in SVM.
- **Random Tree and Random Forest**: These classifiers are based on decision trees. Random Forest, in particular, addresses the over-fitting issue that can occur with single decision tree classifiers by aggregating multiple decision trees.

### 5.5 Unsupervised Learning-based Method

While supervised learning methods require large labeled datasets, unsupervised learning methods can identify inherent physical differences between hidden and normal voice commands without explicit labels. Specifically, we utilize k-means and k-medoids clustering methods.

### Experimental Setup

#### Frontend Playback Setups
- **Prototype on Raspberry Pi**: A prototype of the cloud service device is built using a Raspberry Pi (Model 3B Plus). The device is equipped with a three-axis accelerometer (SunFounder Digital ADXL345) attached to a common loudspeaker (Logitech S120). The accelerometer's sampling rate is set to 200 Hz.
- **Cloud Device Imitation**: Four types of smartphones are placed on a Marshall Stanmore loudspeaker, and their motion sensors are used to imitate the on-board motion sensor of the cloud service speaker.

#### Backend Playback Setups
- **Raspberry Pi Prototype**: The backend setup uses a Raspberry Pi (Model 3B Plus) with an attached accelerometer to record vibration signatures and detect hidden voice commands.
- **Smartphone Imitation**: Smartphones are placed on a loudspeaker to imitate the frontend playback on a standalone VCS device with an onboard motion sensor.

### Data Collection

We generated a set of benign commonly used voice commands using a Text To Speech (TTS) service [2] with five speaker models (three females and two males). The audio samples were sampled at 16 kHz. To generate hidden voice commands, we adjusted the MFCC parameters and tested the commands using Googleâ€™s Cloud Speech-to-Text service. Each command was played ten times, resulting in a total of 13,000 motion sensor data traces (6,500 from benign commands and 6,500 from hidden voice commands).

### 6.2 Performance of Recognizing Hidden Voice Commands

#### 6.2.1 Supervised Learning

Table 2 and Table 3 show the 10-fold cross-validation performance of our system in the frontend and backend setups. All four supervised learning methods (Simple Logistic, SMO, Random Forest, and Random Tree) efficiently differentiate between hidden and normal voice commands. Samsung Note 4, LG G3, and Nexus 6 achieved up to 100% accuracy, while Samsung S6 had a lower accuracy of 93.1% with Random Forest.

| **Classifier** | **Note 4** | **G3** | **Nexus 6** | **S6** |
|----------------|------------|--------|-------------|--------|
| **Simple Logistic** | 99.8% | 100% | 100% | 88.3% |
| **SMO** | 100% | 100% | 99.9% | 85.4% |
| **Random Forest** | 99.9% | 100% | 100% | 93.1% |
| **Random Tree** | 100% | 99.5% | 100% | 87.4% |

#### 6.2.2 Unsupervised Learning

Figure 13 shows the performance of k-means and k-medoids methods in distinguishing hidden voice commands. Both methods accurately identify hidden voice commands with similar accuracy across the four devices. Samsung Note 4, LG G3, and Nexus 6 achieved over 99.2% accuracy in the frontend setup and 100%, 98%, and 93% in the backend setup, respectively. Samsung S6 had lower accuracies of 85.7% and 79% in the frontend and backend setups, respectively.

### Partial Replay Performance

Tables 6 and 7 present the performance of partial replay (1s and 0.5s) in the frontend and backend setups using the k-means method. The system still identifies hidden voice commands with high accuracy, even with limited training data.

| **Replay Duration** | **Note 4** | **G3** | **Nexus 6** | **S6** |
|---------------------|------------|--------|-------------|--------|
| **Replay all** | 99.10% | 100% | 100% | 85.70% |
| **Replay 1s** | 100% | 89.10% | 99.90% | 85.60% |
| **Replay 0.5s** | 85.20% | 95.90% | 90.20% | 85% |

These results indicate that our system is robust and effective in identifying hidden voice commands, even under varying conditions and with limited training data.