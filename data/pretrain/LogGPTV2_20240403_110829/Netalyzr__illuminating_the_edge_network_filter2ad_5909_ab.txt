the back-end’s responses provide the baseline mean latency used
when estimating buffer sizing effects. The test next sends a train
of small UDP packets that elicit 1000-byte replies, with exponen-
tially ramping up (over 10 seconds) the volume in slow-start fash-
ion: for each packet received, the applet sends two more. In the
second half of the interval, the applet measures the sustained rate
at which it receives packets, as well as the average latency.
(It
also notes duplicated and reordered packets over the entire run.)
After waiting 5 seconds for queues to drain, it repeats with sizes
reversed, sending large packets to the server that trigger small re-
sponses. Note that most Java implementations will throttle sending
rates to ≤ 20 Mbps, imposing an upper bound on the speed we can
measure.4
IPv6 Adoption. To measure IPv6 connectivity we have to rely
on an approximation because neither our institution nor Amazon
EC2 supports IPv6. However, on JavaScript-enabled hosts the anal-
ysis page requests a small logo from ipv6.google.com, reach-
able only over IPv6. We report the outcome of this request to our
HTTP server. Since we cannot prevent this test from possibly fetch-
ing a cached image, we could overcount IPv6 connectivity if the
user’s system earlier requested the same resource (perhaps due to a
previous Netalyzr run from an IPv6-enabled network).
3.2 Service Reachability
To assess any restrictions the user’s connectivity may impose on
the types of services they can access, we attempt to connect to 25
well-known services along with a few additional ports on the back-
end. For 80/tcp and 53/udp connectivity, the applet speaks
proper HTTP and DNS, respectively. We test all other services
using our echo server protocol as described in Section 2.
In addition to detecting static blocking, these probes also al-
low us to measure the prevalence of proxying.
In the absence
of a proxy, our trafﬁc will ﬂow unaltered and the response will
include our public IP address as expected. On the other hand,
protocol-speciﬁc proxies will often transform the echo servers’
non-protocol-compliant responses into errors, or simply abort the
connection. For HTTP and DNS, we include both compliant and
non-compliant requests, which will likewise expose proxies. Fur-
ther protocol content such as banners or headers often conveys ad-
ditional information, such as whether a proxy resides on the end
host (e.g., as part of an AV system) or in the network.
3.3 DNS Measurements
Netalyzr performs extensive measurements of DNS behavior,
since DNS performance, manipulations, and subtle errors can have
a major impact on a user’s network experience. We implement
two levels of measurement, restricted and unrestricted. The former
complies with Java’s default same-origin policy, which for most
JVMs allows the lookup of arbitrary names but only ever returns
4 This is the only signiﬁcant performance limitation we faced using
Java compared with other programming languages.
the IP address of the origin server, or throws an exception if the
result is not the origin server’s address, while the latter (which runs
if the user trusts the applet) can look up arbitrary names, allowing
us to conduct much more comprehensive testing. Also, our DNS
authority server interprets requests for speciﬁc names as commands
telling it what sort of response to generate. We encode Boolean re-
sults by returning distinct IP addresses (or hostnames) to represent
true and false, with true corresponding to the origin server’s ad-
dress. For brevity in the following discussion, we abbreviate fully
qualiﬁed hostnames that we actually look up by only referring to
the part of the name relevant for a given test. The actual names
also have embedded in them the back-end node number. When we
employ a nonce value to ensure cache penetration, we refer using
“nonce” in the name.
Glue Policy. One important but subtle aspect of the DNS reso-
lution process concerns the acceptance and promotion of response
data in the Authoritative or Additional records of a response, com-
monly referred to as “glue” records. Acceptance of such records
can boost performance by avoiding future lookups, but also risks
cache poisoning attacks [5]. Assessing the acceptance of these
records is commonly referred to as “bailiwick checking,” but the
guidelines on the procedure allow latitude in how to conduct it [10].
Netalyzr leverages glue acceptance to enable tests of the DNS re-
solver itself.
We ﬁrst check acceptance of arbitrary A records in the Addi-
tional section by sending lookups of special names (made distinct
with nonces) that return particular additional A records. We then
look up those additional names directly to see whether the resolver
issues new queries for the names (which would return false when
those names are queried directly) or answers them from its cache
(returning true), indicating that the resolver accepted the glue. We
check for arbitrary glue records as well as for those that indicate
nameservers. We then likewise check for caching of Authority A
records. Finally, we check whether the server will automatically
follow CNAME aliases by returning one value for the alias in an
Additional record, but a different value for any query for the alias
made directly to our server.
DNS Server Identiﬁcation and Properties. We next probe
more general DNS properties, including resolver identity, IPv6 sup-
port, 0x20 support [7], respect for short TTLs, port randomization
for DNS requests, and whether the user’s NAT, if present, acts as a
DNS proxy on its external IP address.
When able to conduct unrestricted DNS measurements, we
identify the resolver’s IP address (as seen by our server)
by returning it
in an A record in response to a query for
server.nonce.netalyzr.edu. This represents the address
of the ﬁnal server sending the request, not necessarily the one
the client uses to generate the request. During our beta-testing
we changed the applet code to conduct this query multiple times
because we observed that some hosts will shift between DNS re-
solvers, and some DNS resolvers actually operate as clusters.
We test IPv6 AAAA support by resolving ipv6_set.nonce.
This test is slightly tricky because the resolver will often ﬁrst re-
quest an A record for the name prior to requesting a AAAA record.
Thus, the back-end server remembers whether it saw a AAAA
record and returns true/false indicating if it did in response to a
follow-on query that our client makes.
Queries for the name 0x20 return true if the capitalization in a
mix-cased request retains the original mix of casing.
If the DNS resolver accepts glue records for nameservers (NS
responses in Authority or Additional), we leverage this to check
whether the resolver respects short TTLs. Responses to the name
ttl0 or ttl1 place a glue record for return_false in the
249Authoritative section with a TTL of 0 or 1 seconds, respectively.
A subsequent fetch of return_false reveals whether the short
TTLs were respected. (We can’t simply use A records for this test
because both the browser and end host may cache these records
independently.)
We also use lookups of glue_ns.nonce to measure request
latency.
If the DNS resolver accepts glue records, it then also
looks up return_false.nonce to check the latency for a cached
lookup. We repeat this process ten times and report the mean
value to the server, and also validate that return_false.nonce
was fetched from the resolver’s cache rather than generating a new
lookup.
Finally, we test DNS port randomization. For unrestricted mea-
surements, we perform queries for port.nonce, which the server
answers by encoding in an A record the source port of the UDP
datagram that delivered the request. For restricted measurements,
the applet sends several queries for dns_rand_set and then
checks the result using a follow-on query that returns true if the
ports seen by our DNS server appeared non-monotone.
EDNS, DNSSEC, and actual DNS MTU. DNS resolvers can
advertise the ability to receive large responses using EDNS [25],
though they might not actually be capable of doing so. For exam-
ple, some ﬁrewalls will not pass IP fragments, creating a de-facto
DNS MTU of 1478 bytes for Ethernet framing. Other ﬁrewall de-
vices may block all DNS replies greater than 512 bytes under the
out-of-date assumption that DNS replies cannot be larger. While
today small replies predominate, a lack of support for large replies
poses a signiﬁcant concern for DNSSEC deployment.
We measure the prevalence of this limitation by issuing lookups
(i) to determine whether requests arrive indicating EDNS support,
(ii) to measure the DNS MTU (for unrestricted measurements), and
(iii) to check whether the resolver requests DNSSEC records. As
usual, the client returns the results for these via follow-on lookup
requests.
That a DNS resolver advertises (via EDNS) the ability to re-
ceive large responses does not guarantee that it can actually do
so. We test its ability by requesting names edns_medium and
edns_large, padded to 1300 and 1700 bytes, respectively. (We
pad the replies to those sizes by adding Additional CNAME records
that are removed by the user’s DNS resolver before being returned
to the client, so that this test only uses large packets on the path be-
tween our DNS authority and the DNS resolver.) Their arrival at the
client indicates the resolver can indeed receive larger DNS replies.
Later releases of the client also then employ binary search to de-
termine the actual maximum supported by the resolver (whether or
not it advertises EDNS).
NXDOMAIN Wildcarding. Some DNS operators conﬁgure
their resolvers to perform “NXDOMAIN wildcarding”, where they
rewrite hostname lookups that fail with a “no such domain” error to
instead return an A record for the IP address of a web server. The
presumption of such blanket rewriting is that the original lookup
reﬂected web surﬁng, and therefore returning the impostor address
will lead to the subsequent HTTP trafﬁc coming to the opera-
tor’s web server, which then typically offers suggestions related
to the presumed intended name. Such rewriting—often motivated
by selling advertisements on the landing page—corrupts the web
browsers’ URL auto-complete features, and, worse, breaks proto-
col semantics for any non-HTTP application looking a hostname.
If unrestricted, the applet checks for this behavior by querying
for a series of names in our own domain namespace, and which do
not exist. We ﬁrst look up www.nonce.com. If this yields an IP ad-
dress, we have detected NXDOMAIN wildcarding, and proceed to
probe the behavior in more detail, including simple transpositions
(www.yahoo.cmo), other top-level domains (www.nonce.org),
non-web domains (fubar.nonce.com), and a domain internal to
our site (nxdomain.netalyzr.edu). The applet also attempts
to contact the host returned for www.nonce.com on 80/tcp to
obtain the imposed web content, which we log.
DNS proxies, NATs, and Firewalls. Another set of DNS prob-
lems arise not due to ISP interference but misconﬁgured or mis-
guided NATs and ﬁrewalls. If the applet operates unrestrictedly,
it conducts the following tests to probe for these behaviors. First,
it measures DNS awareness and proxying. Our servers answer re-
quests for entropy.netalyzr.edu with a CNAME encoding
the response’s parameters, including the public address, UDP port,
DNS transaction ID, and presence of 0x20 encoding. The applet
sends such DNS requests directly to the back-end server, bypassing
the conﬁgured resolver. If it observes any change in the response
(e.g., a different transaction ID or public address), then we have
found in-path DNS proxying. The applet makes another request di-
rectly to the back-end server, now with deliberately invalid format,
to which our server generates a similarly broken reply. If blocked,
we have detected a DNS-aware middlebox that prohibits non-DNS
trafﬁc on 53/udp.
During beta-testing we added a series of tests for the presence of
DNS proxies in NAT devices. NATs often include such a proxy,
returning via DHCP its local address to clients as the DNS re-
solver location if the NAT has not yet itself acquired an external
DNS resolver.5 Upon detecting the presence of a NAT, the ap-
plet assumes the gateway’s local address is the a.b.c.1 address in
the same /24 as the local IP address and sends it a query for
entropy.netalyzr.edu. Any reply indicates with high prob-
ability that the NAT implements a DNS proxy. In addition, we can
observe to where it forwards the request based on the client IP ad-
dress seen by our server.
During our beta-testing we became aware of the possibility that
some in-gateway DNS resolvers act as open relays for the out-
side (i.e., for queries coming from external sources), enabling
ampliﬁcation attacks [19] and other mischief. We thus added a
test in which the the applet instructs the back-end measurement
server to send a UDP datagram containing a DNS request for
entropy.netalyzr.edu to the public IP address of the client
to see if it elicits a resulting response at our DNS server.
Name Lookup Test. Finally, if unrestricted the applet looks up
a list of 70+ common names, including major search engines, ad-
vertisement providers, ﬁnancial institutions, email providers, and
e-commerce sites. It uploads the results to our server, which then
performs reverse lookups on the resulting IP addresses to check the
forward lookups for consistency. This testing unearthed numerous
aberrations, as discussed below.
3.4 HTTP Proxying and Caching
For analyzing HTTP behavior, the applet employs two different
methods: using Java’s high-level API, or its low-level TCP sockets
(for which we implement our own HTTP logic). The ﬁrst allows
us to assess behavior imposed on the user by their browser (such
as proxy settings), while the latter reﬂects behavior imposed by
their access connectivity. (For the latter we take care to achieve
the same HTTP “personality” as the browser by having our server
mirror the browser’s HTTP request headers to the applet so it can
emulate them in subsequent low-level requests.)
In general, the
applet coordinates measurement tasks with the server using URL-
encoded commands that instruct the server to deliver speciﬁc kinds
of content (such as cache-sensitive images), report on properties of
5Once the NAT obtains its external DHCP lease, it then forwards
all DNS requests to the remote resolver.
250the request (e.g., speciﬁc header values), and establish and store
session state.
HTTP Proxy Detection. We detect HTTP proxy conﬁguration
settings by monitoring request and result headers, as well as the
server-perceived client address of a test connection. Differences
when using the high-level API versus the socket API indicate the
presence of a conﬁgured proxy. We ﬁrst send a low-level message
with speciﬁc headers to the web server. The server mirrors the
headers back to the applet, allowing the applet to conduct a com-
parison. Added, deleted, or modiﬁed headers ﬂag the presence of
an in-path proxy. To improve the detectability of such proxies, we
use eccentric capitalization of header names (e.g. User-AgEnt)
and observe whether these arrive with the same casing. We observe
that some proxies regenerate headers, which will change the case
of any header generated even if the value is unchanged. A sec-
ond test relies on sending an invalid request method (as opposed
to GET or POST). This can confuse proxies and cause them to ter-
minate the connection. A ﬁnal test sets the Host request header
to www.google.com instead of Netalyzr’s domain. Some prox-
ies use this header’s value to direct the outgoing connection [12],
which the applet detects by monitoring for unexpected content.
Caching policies, Content Transcoding, and File-type Block-
ing. We next test for in-network HTTP caching. For this testing,
our server provides two test images of identical size (67 KB) and di-
mensions (512·512 pixels), but each the color-inverse of the other.
Consecutive requests for the image result in alternating images re-
turned to the applet. We can thus reliably infer when the applet
receives a cached image based on the unchanged contents (or an
HTTP 304 status code, “Not Modiﬁed”). We conduct four such
request pairs, varying the cacheability of the images via various
request and response headers, and including a unique identiﬁer in
each request URL to ensure each session starts uncached.
The applet can also identify image transcoding or blocking by
comparing the received image’s size to the expected one.
Finally, we test for content-based ﬁltering. The applet downloads
(i) an innocuous Windows PE executable (notepad.exe), (ii) a small
MP3 ﬁle, (iii) a bencoded BitTorrent download ﬁle (for a Linux dis-
tribution’s DVD image), and (iv) the EICAR test “virus”,6 a benign
ﬁle that AV vendors recognize as malicious for testing purposes.
3.5 User Feedback
Because we cannot readily measure the physical context in
which the user runs Netalyzr, we include a small, optional ques-
tionnaire in the results page. Some 19% of the users provided feed-
back. Of those, 56% reported using a wired rather than a wireless
network; 16% reported running Netalyzr at work, 79% from home,
2% on public networks, and 2% on “other” networks.
3.6
Intentional Omissions
We considered several tests for inclusion but in the end decided
not to do so, for three main reasons.
First, some tests can result in potentially destructive or abusive
effects on network infrastructure, particularly if run frequently or
by multiple users. In this regard we decided against tests to mea-
sure the NAT’s connection table size (which could disrupt unrelated
network connections purged from the table), ﬁngerprint NAT and
access devices by connecting to internal administration interfaces
(which might expose sensitive information), general scanning ei-
ther locally or remotely, and sustained high-bandwidth tests (for
detecting BitTorrent throttling or other differential trafﬁc manage-
ment, for which alternative, bandwidth-intensive tests exist [9]).
6http://www.eicar.org/anti_virus_test_file.htm
Second, some tests can inﬂict potential long-term side-effects on
the users themselves. These could occur for technical reasons (e.g.,
we contribute towards possible upload/download volume caps) or
legal/political ones (e.g., tests that attempt to determine whether
access to certain sites suffer from censorship).
Finally, we do not store per-user HTTP tracking cookies in the
user’s browsers, since we do not aim to collect mobility proﬁles.
We do however employ user-invariant HTTP cookies to test for
modiﬁcations and to manage state machines in our testsuite.
4. DATA COLLECTION
We began running Netalyzr publicly in June 2009 and have kept
it available continuously. We initially offered the service as a “beta”
release (termed BETA), and for the most part did not change the op-
erational codebase until January 2010, when we rolled out a sub-
stantial set of adjustments and additional tests (RELEASE). These
comprise about 58% and 42% of the measurements, respectively.
Unless otherwise speciﬁed, discussion refers to the combination of
both datasets.
Website Operation. To date we have collected 130,436 sessions
from 99,513 public IP addresses. The peak rate of data acquisition
occurred during the June roll-out, with a maximum of 1,452 ses-
sions in one hour. This spike resulted from mention of our service
on several web sites. A similar but smaller spike occurred during
the January relaunch, resulting in a peak load of 373 sessions in
one hour.
Calibration. We emphasize the importance of capturing subtle
ﬂaws in the data and uncovering inconsistencies that would oth-