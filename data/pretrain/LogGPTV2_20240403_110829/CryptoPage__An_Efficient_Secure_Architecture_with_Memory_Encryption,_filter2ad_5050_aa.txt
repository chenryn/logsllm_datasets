title:CryptoPage: An Efficient Secure Architecture with Memory Encryption,
Integrity and Information Leakage Protection
author:Guillaume Duc and
Ronan Keryell
CryptoPage: an Efﬁcient Secure Architecture with Memory Encryption,
Integrity and Information Leakage Protection
Guillaume Duc, Ronan Keryell
ENST Bretagne
CS 83818, 29238 Brest Cedex 3, France
{Guillaume.Duc,Ronan.Keryell}@enst-bretagne.fr
Abstract
Several secure computing hardware architectures using
memory encryption and memory integrity checkers have
been proposed during the past few years to provide applica-
tions with a tamper resistant environment. Some solutions,
such as HIDE, have also been proposed to solve the problem
of information leakage on the address bus.
We propose the CRYPTOPAGE architecture which im-
plements memory encryption, memory integrity protection
checking and information leakage protection together with
a low performance penalty (3 % slowdown on average) by
combining the Counter Mode of operation, local authenti-
cation values and Merkle trees.
1. Introduction
Many computer applications need certain levels of se-
curity, conﬁdentiality and conﬁdence that are beyond the
scope of current architectures. Of course, there are many
cryptographic algorithms, network protocols, secure oper-
ating systems and some applications that use these methods,
but all of them rely on a strong hypothesis: the underlying
hardware itself needs to be secure. Indeed this critical hy-
pothesis is never veriﬁed, except for small applications that
can ﬁt onto a smartcard, for example.
During the last few years, several hardware architectures
(such as XOM [16, 17, 18], AEGIS [26, 27] and CRYP-
TOPAGE [12, 15, 6, 5]) have been proposed to provide com-
puter applications with a secure computing environment.
These architectures use memory encryption and memory in-
tegrity checking to guarantee that an attacker cannot disturb
the operation of a secure process, or can only obtain as lit-
tle information as possible about the code or the data ma-
nipulated by this process. These secure architectures try to
prevent, or at least detect, physical attacks against the com-
ponents of a computer (for example, the Microsoft X-BOX
video game console was attacked in [10] by snifﬁng the bus
of the processor with a logic analyzer) or logical attacks (for
example, the administrator of the machine tries to steal or
modify the code or the data of an application).
Such architectures can, for instance, be very useful in
distributed computing environments. Currently, companies
or research centers may be hesitant to use the computing
power provided by third-party computers they do not con-
trol on a grid, because they fear that the owners of these
computers might steal or modify the algorithms or the re-
sults of the distributed application. If each node of the grid
uses a secure computing architecture that guarantees the in-
tegrity and the conﬁdentiality of the distributed application
results, these security issues disappear.
However, as the address bus is not modiﬁed in these se-
cure architectures, the memory access patterns are accessi-
ble to the attacker. Zhuang et al.
in [30] show that these
memory access patterns can be sufﬁcient to identify certain
algorithms and so to obtain information about the code of a
secure application, in spite of the encryption.
To stop this information leakage, they present HIDE
(Hardware-support for leakage-Immune Dynamic Execu-
tion), an infrastructure for efﬁciently protecting information
leakage on the address bus [30]. However, the impact of
this infrastructure on encryption and memory checking is
not studied.
In this article we propose the CRYPTOPAGE extension
of the HIDE infrastructure to provide, in addition to the pro-
tection of the address bus, memory encryption and memory
checking. The novelty of this paper lies in this new way
to combine these mechanisms with a very low performance
overhead. We also describe how an untrusted operating sys-
tem can take part in some of these mechanisms to decrease
the hardware cost without compromising the security of the
architecture.
The rest of this paper is organized as follows: Section 2
describes our proposition for implementing memory en-
cryption and checking on the HIDE infrastructure; Section 3
presents information about the performance of this system
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006and Section 4 presents related work in this ﬁeld.
2. Architecture
In this section, we ﬁrst present the security objectives of
our architecture. Next, we summarize the key concepts of
the HIDE infrastructure required to understand our proposi-
tion and ﬁnally, we present our proposition to implement a
memory protection system on this infrastructure.
2.1. Objectives of the architecture
The objective of our architecture is to allow the execution
of secure processes. It must guarantee that these processes
possess the two following properties:
• conﬁdentiality: an attacker must obtain as little infor-
mation as possible about the code or the data manipu-
lated by the process;
• integrity: the proper execution of the process must not
be altered by an attack. If an attack is detected, the
processor must stop the program.
The processor must be able to execute secure processes
in parallel with other normal (non secure) processes with
an operating system adapted to the architecture but not nec-
essarily secure or trusted. One key hypothesis is that the
operating system itself does not need to be trusted. It may
be compromised, or at least, be too large to be bug-free.
We assume that everything outside the chip of the pro-
cessor (for instance the memory bus, the hard drive, the op-
erating system, etc.) is under the full control of an attacker.
For instance, he can inject bogus values in the memory,
modify the operating system to spy on processor registers
or to modify hardware contexts, etc.
However, the attacker cannot directly or indirectly probe
the inside of the processor. In particular, we consider that
timing attacks [13], differential power analysis (DPA [14])
attacks, etc. are avoided by other means beyond the scope of
this article. Moreover, we do not consider denial of service
attacks because they are unavoidable.
We want to protect the integrity and conﬁdentiality of a
secure application against hardware attacks but we do not
protect it against itself. If the secure application contains
security holes, they can be exploited to modify its behavior.
2.2. The plain HIDE infrastructure
Our proposition is based on the HIDE infrastructure so
we will brieﬂy summarize it here. The HIDE infrastruc-
ture, as described in [30], remembers the sequence of ad-
dresses accessed by the processor and permutes the mem-
ory space before an address recurs. More precisely, the pro-
tected memory space is divided into several chunks. This
protection is implemented by modifying the cache mecha-
nism of the processor. When a line that belongs to a pro-
tected chunk is read from memory (during a cache miss), it
is stored in the cache, as usual, but it is also locked. While
this line is locked, it cannot be replaced or written back to
memory. When a line needs to be ﬂushed because there is
no space left in the cache for a new line and all lines are
locked, a permutation of the chunk occurs.
During this permutation, all the lines belonging to the
chunk that is being permuted are read (from memory or
from the cache), then the addresses of these lines are per-
muted and the lines are unlocked and re-encrypted. So be-
tween each permutation, a line is written to memory and
read from memory only once. In addition, the re-encryption
of the lines prevents an attacker from guessing the new ad-
dress of a given line inside a chunk after a permutation.
With this mechanism, an attacker cannot learn that one line
has been read more than another nor can he ﬁnd interesting
memory access patterns at a grain ﬁner than the chunk size.
The current permutation table for a chunk is encrypted and
stored in memory.
To reduce the cost of the permutations, [30] proposes to
do the latter in the background. When the processor de-
tects that the cache (or one set of the cache, depending on
its structure) is almost full, it begins a background permu-
tation. With this mechanism, the performance penalty is
negligible (1.3 % according to [30]).
However, in [30], no information about memory encryp-
tion or memory protection is given. We now describe how
to use the property that a line is written to memory and read
from memory only once between each chunk memory space
permutation to implement a cheap encryption and memory
integrity checker on the HIDE infrastructure. First, we will
describe how the encryption and veriﬁcation are performed
on cache lines and then, how the page information is pro-
tected.
2.3. Encryption and veriﬁcation of cache
lines
In the rest of this section, we assume that the chunks used
by the HIDE infrastructure are the same as the pages used by
the virtual memory mechanism to simplify the explanation
but this assumption is not a requirement. We also introduce
some notations:
• (cid:1) is the concatenation of bit strings and ⊕ the bit-wise
exclusive or (XOR);
• La,c = L(0)
a,c(cid:1) . . .(cid:1)L(l−1)
: the content of the cache line
number a in the memory chunk c, divided into l blocks
of the size of an encryption block;
a,c
• EK(D): the result of the encryption of the data block
D with the symmetric key K;
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006Counter mode
R(cid:1)
c,p
a
0
R(cid:1)
c,p
a
1
Ke
AES
Ke
AES
PAD(0)
a,c
PAD(1)
a,c
L(0)
a,c
C(0)
a,c
L(1)
a,c
C(1)
a,c
Cache line
Encrypted line
CBC-MAC
Rc,p
a
Counter mode
R(cid:1)
c,p
a
0
R(cid:1)
c,p
a
1
Ke
AES
Ke
AES
PAD(0)
a,c
PAD(1)
a,c
H (2)
a,c
Decrypted line
Encrypted line
CBC-MAC
Rc,p
a
L(0)
a,c
C(0)
a,c
L(1)
a,c
C(1)
a,c
Km
AES
Km
AES
Km
AES
Km
AES
Km
AES
Km
AES
H (0)
a,c
H (1)
a,c
H (2)
a,c
H (0)
a,c
H (1)
a,c
H (2)
a,c
H (2)
a,c
= Integrity
result
Figure 1. The encryption process of a cache
line.
Figure 2. The decryption process of a cache
line.
• Ke and Km:
the symmetric keys used to encrypt
(and decrypt) the code and the data of a secure pro-
cess (Ke) and to compute the Message Authentication
Codes (MAC) used to authenticate the code and the data
of a process (Km). These keys are speciﬁc to a given
secure process and are securely stored in its hardware
context.
During each permutation of a given chunk, the processor
chooses two random numbers, Rc,p and R(cid:1)
c,p (where c is the
corresponding chunk and p the number of the permutation),
and stores them with the other information about the chunk
(such as the permutation table).
After permutation, when a cache line is being written
back to memory, the processor encrypts it, computes a MAC
and stores Ca,c(cid:1)Ha,c in memory with:
a,c(cid:1)· ··(cid:1)C (l−1)
a,c
(1)
PAD (i)
a,c
a,c(cid:1)C (1)
a,c ⊕ PAD (i)
c,p(cid:1)a(cid:1)i)
Ca,c = C (0)
a,c = L(i)
C (i)
a,c = EKe (R(cid:1)
Ha,c = H (l)
a,c
a,c = EKm (C (i−1)
H (i)
a,c = EKm (Rc,p(cid:1)a)
H (0)
a,c ⊕ H (i−1)
a,c
i ∈ [1, l − 1]
),
(2)
(3)
(4)
(5)
(6)
The cache line is encrypted using the counter mode [24]
(equation 2). The pads used depend on R(cid:1)
c,p and a (equa-
tion 3). Equations 4 to 6 deﬁne a CBC-MAC [23, 11]1 com-
puted over the encrypted cache line, Rc,p and the address a
of the cache line. The encryption mechanism is summarized
in Figure 1.
The counter mode is known to be secure against chosen-
plaintext attacks [2] on the condition that the counter is only
used once with the same encryption key. Indeed, if two lines
1We have chosen to use CBC-MAC because it is relatively fast and be-
cause the encryption and the integrity protection can use the same hard-
ware, but any other good MAC function can be used instead.
a,c = (La,c ⊕ PADa,c) ⊕ (L(cid:1)
La,c and L(cid:1)
a,c are encrypted using the same pad PADa,c, we
a,c ⊕
have the relation Ca,c ⊕ C(cid:1)
PADa,c) = La,c ⊕ L(cid:1)
a,c so we can obtain information about
the content of the two cache lines by simply comparing the
two encrypted cache lines. Between two permutations, the
cache line at the address a is encrypted only once, so the
c,p(cid:1)a(cid:1)i) is only used once, except if the same
pad EKe(R(cid:1)
random number R(cid:1)
c,p is chosen during two different permu-
tations.
If R(cid:1)
√
c,p is 119-bits long 2, the birthday paradox says that