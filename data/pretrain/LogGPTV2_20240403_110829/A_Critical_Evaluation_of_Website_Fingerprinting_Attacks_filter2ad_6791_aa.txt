title:A Critical Evaluation of Website Fingerprinting Attacks
author:Marc Ju&apos;arez and
Sadia Afroz and
Gunes Acar and
Claudia D&apos;ıaz and
Rachel Greenstadt
A Critical Evaluation of Website Fingerprinting Attacks
Marc Juarez1, Sadia Afroz2, Gunes Acar1, Claudia Diaz1, Rachel Greenstadt3
1KU Leuven, ESAT/COSIC and iMinds, Leuven, Belgium
{name.surname}@esat.kuleuven.be
2UC Berkeley
PI:EMAIL
3Drexel University
PI:EMAIL
ABSTRACT
Recent studies on Website Fingerprinting (WF) claim to
have found highly eﬀective attacks on Tor. However, these
studies make assumptions about user settings, adversary ca-
pabilities, and the nature of the Web that do not necessar-
ily hold in practical scenarios. The following study criti-
cally evaluates these assumptions by conducting the attack
where the assumptions do not hold. We show that certain
variables, for example, user’s browsing habits, diﬀerences in
location and version of Tor Browser Bundle, that are usually
omitted from the current WF model have a signiﬁcant im-
pact on the eﬃcacy of the attack. We also empirically show
how prior work succumbs to the base rate fallacy in the
open-world scenario. We address this problem by augment-
ing our classiﬁcation method with a veriﬁcation step. We
conclude that even though this approach reduces the num-
ber of false positives over 63%, it does not completely solve
the problem, which remains an open issue for WF attacks.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: Gen-
eral—Security and protection; K.4 [Computers and So-
ciety]: Public Policy Issues—Privacy
Keywords
Website ﬁngerprinting; Tor; privacy
1.
INTRODUCTION
Anonymous communication systems are designed to pro-
tect users from malicious websites and network eavesdrop-
pers by providing means to hide the content and metadata of
communications. The Onion Router (Tor), with about three
million daily users, is the most popular anonymous commu-
nication network.
It is specially designed for low-latency
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2957-6/14/11 ...$15.00.
http://dx.doi.org/10.1145/2660267.2660368.
applications such as web browsing [8, 29]. Tor routes con-
nections through three-hop circuits and encrypts the traﬃc
in layers using onion routing [10], so that none of the re-
lays can know both the origin and the destination of the
communication at the same time.
Although Tor hides the routing information and communi-
cation content, the analysis of the network traﬃc alone may
provide very rich information to an attacker with suﬃcient
capabilities. Using timing, frequency and length of the mes-
sages, an attacker can bypass otherwise very robust security
mechanisms and identify the communicating parties [7, 22].
Website Fingerprinting (WF) allows an adversary to learn
information about a user’s web browsing activity by recog-
nizing patterns in his traﬃc. The adversary in this attack
compares the network traces of Tor users to a set of pre-
recorded webpage ﬁngerprints to identify the page that is
being accessed. WF is diﬀerent from traﬃc correlation at-
tacks where the adversary has access to both entry and exit
nodes and matches the patterns in the incoming and outgo-
ing traﬃc to the Tor network [14]. WF is also diﬀerent from
deep packet inspection protocols and related traﬃc analysis
techniques that are used to censor Tor [13].
Several previous works demonstrate the eﬀectiveness of
WF attacks on Tor despite the encryption, padding and ap-
plication level defenses such as randomized pipelining [3, 11,
23, 26, 32]. Although we appreciate the importance, novelty
and scientiﬁc rigor of these studies, the assumptions they
made vastly simplify the problem and give unrealistic ad-
vantages to the adversary by either simplifying the world or
overestimating the adversary’s capabilities. Some of these
assumptions are challenging and hard to attain realistically
in practice [11]. For example, most current works implic-
itly/explicitly assume that the adversary and user both use
the same Tor Browser Bundle (TBB), visit the same local-
ized version of a limited set of pages/sites almost at the same
time (or a few days apart) by using only one tab browsing.
However, violating at least one of these assumptions can re-
duce the eﬃcacy of the attack signiﬁcantly to a point that
might not make WF a threat in the real world. The authors
of these studies aim to provide an upper bound for the eﬃ-
cacy of the attacks and argue that a particular attacker or
scenario might satisfy them. Also it has been argued that
in a real-world scenario, proposed countermeasures against
WF would actually be more eﬃcient than these studies have
estimated [25].
The goal of this study is to assess the practical feasibility
of WF attacks proposed in prior work. Our contributions
and their organization in the paper are as follows:
A critical evaluation of assumptions made by prior
WF studies: We provide an extensive model of the WF
attack, deﬁne the assumptions made by prior WF studies
on the adversary, the client-setting and the Web. We argue
that these assumptions are unrealistic because they are over-
simplifying the problem thus are unlikely to hold in practice
(Section 3).
An analysis of the variables that aﬀect the accuracy
of WF attacks: We pin down the variables that were omit-
ted from the models considered in previous work that have
an impact on the practical eﬀectiveness and feasibility of
the attacks (Section 4). We present the results of a set of
comparative experiments to evaluate the eﬀects of these vari-
ables on traﬃc traces and classiﬁer accuracy. We show that,
for some of the variables, the accuracy can drop up to 70%.
An approach to reduce false positive rates: We show
the eﬀect of false positives in an open-world of 35K webpages
and use Classify-Verify in the WF domain on the estimated
probabilities of the classiﬁer which reduces the number of
false positives over 63% (Section 5).
A model of the adversary’s cost: We model the cost
that an adversary would incur to maintain a successful WF
system (Section 6). We suspect that maintaining a perfect
WF system is costly as the adversary needs to collect infor-
mation about diﬀerent localized versions of the webpages,
user’s browsing settings and update the system over time to
recover from data staleness.
2. WEBSITE FINGERPRINTING
The main objective of an adversary in a typical WF sce-
nario is to identify which page the user is visiting. The ad-
versary may want to learn this information for surveillance
or intelligence purposes.
The WF attack is typically treated as a classiﬁcation prob-
lem, where classiﬁcation categories are webpages and obser-
vations are traﬃc traces. The adversary ﬁrst collects traﬃc
traces by visiting webpages and trains a supervised classiﬁer
using features such as the length, direction and inter-arrival
times of network packets.
Whenever a user visits a webpage over Tor, the adversary
records the network trace by, for instance, intercepting the
traﬃc locally (LAN), by having access to routers of the user’s
ISP, or by controlling an entry guard to the Tor network. He
then runs the classiﬁer on the intercepted network trace to
guess the site the user has visited.
The ﬁrst WF attacks were developed to identify pages
within a single website over SSL connections [4, 20].
In
2002, Sun et al. tackled the more challenging problem of
identifying individual pages within a set of websites [28]
which led to Hintz’s attack on an anonymizing web proxy
(SafeWeb) [12]. Many WF studies on one-hop proxy attacks
have followed [2, 9, 16, 18].
Herrmann et al. [11] deployed the ﬁrst WF attack on the
Tor anonymity network with only a 3% success rate for a
world of 775 pages. The attacks that followed signiﬁcantly
improved the accuracy: Shi and Matsuura obtained 50%
success rate for 20 pages [26]; Panchenko et al., obtained
54.61% accuracy using Herrmann’s dataset [23]; and, ﬁnally,
Cai et al. and Wang and Goldberg report success rates over
90% using edit-distance based classiﬁers on a world of 100
pages [3, 32].
3. MODEL
We model the WF adversary as passive and local : the ad-
versary is able to eavesdrop on the user’s traﬃc, but cannot
add, drop or modify packets. We also assume that the ad-
versary cannot decrypt the contents of the network packets,
as that would render WF attacks unnecessary.
Tor
Web
User
Figure 1: The basic WF targeted attack in Tor.
Figure 1 depicts the basic WF scenario: the attacker taps
the network between the victim and the Tor entry guard
and collects traﬃc traces, which he then compares against
his database of webpage ﬁngerprints. We make a distinction
between two types of attacks based on the number of users
targeted by the adversary and the resources at his disposal.
Targeted: In this attack, the adversary targets a speciﬁc
victim to retrieve his browsing activity. This allows the at-
tacker to train a classiﬁer under conditions similar to those
of the victim (see Figure 1), potentially increasing the suc-
cess of the attack. The adversary may have enough back-
ground knowledge about the user to reproduce his conﬁgu-
ration, or he could detect it from the observed traﬃc data.
In Section 6, we discuss how diﬃcult it is for the attacker to
discover properties about the user’s setting.
Non-targeted (dragnet surveillance): In this case, the
adversary targets a set of users instead of one. ISPs, Inter-
net exchanges and entry guard operators are in a position to
deploy this attack since they can intercept the network traf-
ﬁc of many users (see Figures 2a and 2b, respectively). The
attacker trains the classiﬁer on a speciﬁc setting and uses
the same classiﬁer on all communications that he observes.
Users
Tor
Web
Users
Tor
Web
ISP
Entry
(a) ISP level adversary.
(b) Malicious entry guard.
Figure 2: WF Non-targeted attacks in Tor.
3.1 Assumptions
We compiled the assumptions made in the literature of
WF attacks on Tor. We divided the basic model in three
parts: (i) Client-side, (ii) Adversary, and (iii) Web, and clas-
siﬁed the assumptions according to the part of the model
they relate to. We note that the assumptions are not mu-
tually exclusive and are open to other classiﬁcations. The
papers that explicitly mention these assumptions are listed
in Table 1.
Client-setting.
Closed-world: There are only k webpages that the user
may visit. This is a very strong assumption because k is al-
ways very small compared to the actual number of existing
webpages. Some authors have also evaluated their classiﬁers
in an open-world scenario [3, 23, 32], where there is a set of
k target pages being monitored but the user is allowed to
visit pages that are not in that set.
Browsing behaviour: The users follow a speciﬁc be-
haviour. For example: users browse the web sequentially,
one page after the other, having only a single tab open. Nev-
ertheless, real-world studies found that users tend to have
multiple open tabs or windows [21, 31], which allow them to
load several pages at once. Although we do not have access
to data collected from Tor users, it is safe to think that Tor
users exhibit this behavior since their connection is slower.
y
c
n
e
u
q
e
r
F
10
5
0
700
800
900
1000
1100
Total trace size (KBytes)
(a) Histogram of trace sizes
(b) Doodle and standard versions
Figure 3: Diﬀerent versions of the Google homepage and
corresponding histogram of trace sizes for 40 visits. The
histogram shows that the distributions of packet sizes are
signiﬁcantly diﬀerent for the same page visited on diﬀerent
dates.
Web.
Template websites: All websites are built using tem-
plates. Cai et al. used a Hidden Markov Model (HMM) to
leverage the link structure of websites for WF [3]. The au-
thors made this assumption in order to simplify their model
and reduce the number of states in the HMM.
There are further unrealistic assumptions about the Web
that are not explicit but that may improve the accuracy of
the WF attack. For instance, one recent study used localized
(German) versions of the webpages in order to avoid diﬀer-
ent language versions [32]. In our experiments, we observed
cases such as ask.com where the total trace size of the En-
glish version was about ﬁve times bigger than the German
version of the same webpage. Given that the language of
the webpage will be selected according to the Tor exit node,
assuming that users would visit the same local version is a
clear advantage to the adversary.
Even if we limit ourselves to localized versions of web-
pages, there are still other sources of dynamism such as bot
detection, changing graphics and third-party content. Fig-
ure 3a shows the histogram of sizes of 40 traces collected
from google.de between February 14-16. We observe a clear
distinction between two sets of trace sizes. The group on
the left corresponds to the page without a doodle (left in
Figure 3b). The group on the right with larger network foot-
print corresponds to the version with a special doodle for St.
Valentine’s day (right in Figure 3b). Note that Wang and
Goldberg concluded that sites that change in size are hard
to classify correctly [32].
Adversary.
Page load parsing: The adversary can detect the begin-
ning and the end of diﬀerent page loads in a traﬃc trace.
This has been shown to be a very hard task in the context
of session reconstruction from real-world network traﬃc [6].
No background traﬃc: The adversary can ﬁlter all back-
ground network traﬃc produced by other applications or
other connections going through the same Tor circuit. Tor is
increasingly used in settings where multiple applications or
complete operating system traﬃc is sent over the Tor net-
work1. In these cases, separating the browsing traﬃc from
the background traﬃc may present a nontrivial challenge to
the adversary.
Replicability: The adversary can train his classiﬁer un-
der the same conditions as the victim. For instance, the