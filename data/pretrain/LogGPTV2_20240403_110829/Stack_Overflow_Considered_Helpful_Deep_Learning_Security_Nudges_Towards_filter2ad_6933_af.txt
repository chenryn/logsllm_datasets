[23] LIU, B., LIN, J., AND SADEH, N. Reconciling mobile
app privacy and usability on smartphones: Could user
privacy proﬁles help? In International Conference on
World Wide Web (2014), pp. 201–212.
[24] MIYATO, T., MAEDA, S., KOYAMA, M., NAKAE, K.,
AND ISHII, S. Distributional smoothing by virtual ad-
versarial examples. CoRR abs/1507.00677 (2015).
[25] NGUYEN, D. C., WERMKE, D., ACAR, Y., BACKES,
M., WEIR, C., AND FAHL, S. A stitch in time: Sup-
porting Android developers in writing secure code. In
ACM Conference on Computer and Communications
Security (2017), pp. 1065–1077.
[26] OLIVEIRA, D. S., LIN, T., RAHMAN, M. S., AKE-
FIRAD, R., ELLIS, D., PEREZ, E., BOBHATE, R.,
DELONG, L. A., CAPPOS, J., AND BRUN, Y. API
Blindspots: Why experienced developers write vulner-
able code. In Symposium on Usable Privacy and Secu-
rity (2018), pp. 315–328.
[27] OLTROGGE, M., ACAR, Y., DECHAND, S., SMITH,
M., AND FAHL, S. To pin or not to pin – Helping
app developers bullet proof their TLS connections. In
USENIX Security Symposium (2015), pp. 239–254.
[33] XU, X., LIU, C., FENG, Q., YIN, H., SONG, L., AND
SONG, D. Neural network-based graph embedding
for cross-platform binary code similarity detection. In
ACM Conference on Computer & Communications Se-
curity (2017), pp. 363–376.
Appendix A: Additional Participant Data
Table 3 includes additional data about the 27 participants,
who completed the study.
We also conducted a series of statistical tests to verify that
the self-reported characteristics of the recruited participants
did not systematically vary across treatments. Indeed, using
the Mann-Whitney U Test, we found that participants did
not differ in their reported age across treatments (p = 0.79).
Applying Fisher’s Exact Test, we also observed the absence
of a statistically signiﬁcant difference for country of origin
(p = 0.809), gender (p = 0.551), level of education (p =
0.217), security knowledge/background (p = 0.124), and
professional programming experience (p = 0.315). Using
the Mann-Whitney U Test, we did not ﬁnd any statistically
signiﬁcant difference for years of experience with Java pro-
gramming (p = 0.422). We also did not ﬁnd any reportable
differences regarding participants’ awareness of encryption
ﬂaws (p = 0.363) using Fisher’s Exact Test. The percentage
of participants who had to program Java as primary activity
for their work (p = 1) or for whom writing Java code was
part of their primary job in the last 5 years (p = 0.696) also
did not differ across treatments (using Fisher’s Exact Test).
Appendix B: Detailed Regression Results
Based on the user study data and self-reported survey re-
sponses, we follow an ordinal (Logit link) regression ap-
354    28th USENIX Security Symposium
USENIX Association
proach, which is primarily focused on evaluating the effec-
tiveness of the nudge treatment.
First, we report a series of four models (M1 - M4) to eval-
uate whether the nudge treatment signiﬁcantly impacts the
functional correctness of the submitted programs for the ﬁve
different tasks (see Table 4). We iteratively add factors to
the regression model to also test whether programming ex-
pertise or security expertise positively impact the outcome
variable. Most importantly, as the nudge treatment is not
designed to address this aspect of programming, we did not
expect any signiﬁcantly positive effect.
Indeed, across all
model speciﬁcations that we tested, we did not observe any
signiﬁcant (positive or negative) effect. Regarding the dif-
ferent programming tasks, we found that the Cipher task
was associated with a signiﬁcantly increased likelihood of
being functionally correct (M2 - M4). Further, not being a
security professional (as reported by the participants) signif-
icantly impacts the likelihood that functional programs were
submitted in a negative fashion (M3 - M4). In contrast, a
higher degree of security knowledge (as reported by the par-
ticipants) did not signiﬁcantly impact the results (M4).
Note that the regression statistics for tasks IV and TLS are
identical as the aggregate results for functional correctness
happen to be the same (see Figure 7c).
FACTORS
Treatment: Nudge
Task: Cipher
M1
-0.460
(0.523)
-
Task: IV
Task: Key
Task: TLS
Not Professional
Sec. Knowledge
-
-
-
-
-
M2
-0.489
(0.544)
2.407*
(1.105)
1.224
(0.746)
0.892
(0.690)
1.224
(0.746)
-
-
M3
-0.263
(0.568)
2.539*
(1.125)
1.324
(0.775)
0.974
(0.72)
1.324
(0.775)
-1.701*
(0.679)
-
M4
-0.226
(0.605)
2.539*
(1.125)
1.324
(0.775)
0.974
(0.721)
1.324
(0.775)
-1.698*
(0.680)
-0.106
(0.605)
Table 4: Results for Ordinal Regression of Functional Cor-
rectness. Series of non-interaction models (M1 – M4) with
factors iteratively added. Signiﬁcant values are highlighted
in bold, and marked with: * p < 0.05. Standard errors are
included in parentheses. The baseline for Treatment is Con-
trol (i.e., the unmodiﬁed Stack Overﬂow), and the baseline
for Task is TM.
FACTORS
Treatment: Nudge
M1
0.920*
(0.388)
-
Mean = 22.93 Median = 22
Germany = 16
Male = 9
Highschool = 15 Bachelor = 8
Yes = 12
Yes = 10
No = 15
No = 17
Mean = 3.81
Median = 3
Yes = 17
Yes = 5
Yes = 12
No = 10
No = 21
No = 15
Age
Stddev = 3.9
Country of Origin
Gender
Achieved Level of Education
Professional at Programming
Security Background
Java Years Experience
Stddev = 2.304
Encryption Flaw Awareness
Java primary focus of job
No Data = 1
Java part of any job
Min = 19
Max = 38
Task: Cipher
Other = 11
Female = 18
Master = 3
Ph.D. = 0
Min = 1
Max = 8
Task: IV
Task: Key
Task: TLS
Not Professional
Sec. Knowledge
-
-
-
-
-
M2
1.018*
(0.426)
1.388
(0.745)
-0.963
(0.654)
0.224
(0.668)
-0.963
(0.654)
-
-
M3
1.113*
(0.438)
1.377
(0.754)
-1.001
(0.665)
0.200
(0.677)
-1.001
(0.665)
-0.702
(0.432)
-
M4
1.303**
(0.480)
1.405
(0.758)
-0.990
(0.668)
2.13
(0.679)
-0.990
(0.668)
-0.686
(0.434)
-0.517
(0.481)
Table 3: Detailed data about demographics of participants (N
= 27). One missing response for the question whether Java
is primary focus of current job.
Second, we report a series of four models (M1 - M4) to
evaluate whether the nudge treatment signiﬁcantly impacts
the security of the submitted programs for the ﬁve different
tasks (see Table 5). For consistency, we iteratively add the
same factors to the regression model to also test whether pro-
gramming expertise or security expertise positively impact
the outcome variable.
Most importantly, as the nudge treatment is designed to
improve the security of cryptography-related programming,
we did expect a signiﬁcantly positive effect. Indeed, across
all model speciﬁcations that we tested, we did observe a sig-
Table 5: Results for Ordinal Regression of Security. Se-
ries of non-interaction models (M1 – M4) with factors it-
eratively added. Signiﬁcant values are highlighted in bold,
and marked with: * p < 0.05 and ** p < 0.01. Standard
errors are included in parentheses. The baseline for Treat-
ment is Control (i.e., the unmodiﬁed Stack Overﬂow), and
the baseline for Task is TM.
niﬁcant and positive effect. Regarding the different program-
ming tasks, we did not ﬁnd that they signiﬁcantly differed
from each other regarding the security property (M2 - M4).
Being a security professional did not impact the security of
the submitted programs in a signiﬁcant way (M3 - M4). Per-
haps surprisingly, a higher degree of security knowledge (as
USENIX Association
28th USENIX Security Symposium    355
(b) Recommendation provided by the similarity and use case model.
(a) Security warning provided by the security and use case model
Figure 8: Security warning and recommendations provided by the similarity, use case and security model. The security model
predicted the usage pattern of setHostnameVeriﬁer as insecure. Further, it predicted its use case HNV, being able to select and
display the related security annotation under the insecure statement. Below the security warning the similarity, use case and
security model provide the ranked list of recommendations, that contains code examples with similar and secure patterns of
HNV. We display the recommended code example that appears when clicking on the ﬁrst link in (b).
reported by the participants) did not signiﬁcantly impact the
results either (M4).
We created regression models including further demo-
graphic and explanatory variables. However, none of them
had a signiﬁcant effect on the security of submitted solutions.
Appendix C: Pattern Annotation Tool
Our security annotations generally comply with rules and
annotation heuristics given by [12,13,17]. However, manual
analysis of patterns was not restricted to simple application
of these heuristics, but was based on detecting insecure pat-
terns in general. Whenever an unknown pattern has been
detected, both annotators discussed them until agreement on
a label. For example, [13] only reports empty trust manager
implementations, while many insecure TM patterns on Stack
Overﬂow are not empty, but provide insufﬁcient certiﬁcate
veriﬁcation (e. g., only validating that the certiﬁcate is not
expired).
To further speed up the labeling process and manage the
large amount of samples, we created a code annotation tool.
It automatically iterates through code snippets and displays
them to the user, using a source code editor. Seed state-
ments were already highlighted in order to allow the anno-
tator to detect relevant patterns quickly. The annotator was
able to assign labels (e. g., secure/insecure) to different key-
board buttons. While iterating through the seed statements,
the annotator would investigate the related pattern and label
it accordingly. Moreover, the annotator had the option to
add seed statements, that she wanted to have highlighted and
labeled. Whenever the annotator identiﬁed new patterns or
wanted to share and discuss a pattern, the related code snip-
pet was marked and other annotators were notiﬁed to com-
ment on it. After agreement, the pattern was labeled by the
initial annotator. Further, annotation heuristics obtained dur-
ing the discussion were shared among all annotators.
356    28th USENIX Security Symposium
USENIX Association