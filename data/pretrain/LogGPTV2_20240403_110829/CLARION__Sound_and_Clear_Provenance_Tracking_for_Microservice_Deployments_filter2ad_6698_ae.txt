the container is much larger. Since the namespace-unaware
system will fail to infer correct provenance inside containers,
4002    30th USENIX Security Symposium
USENIX Association
5.lstat6.readdockerdpid=21992.symlink(write)1.symlink(read)4.renameat(read) (RENAME_EXCHANGE)3.renameat(read)symlink_swappid=2230subtype:filepath:/var/lib/docker/overlay2/container_hash/merged/stash_pathctr_path: /stash_pathsubtype:filepath: /var/lib/docker/overlay2/container_hash/merged/totally_safe_pathctr_path: /totally_safe_pathHostContainer(a) without namespace/container awareness(b) with namespace/container awarenesssubtype:filepath:/subtype:filepath:/w00t_w00t_im_a_flag7.writesubtype:filepath:~/ex101/out5.lstat6.readdockerdpid=21992.symlink(write)4.renameat(read) (RENAME_EXCHANGE)3.renameat(read)1.symlink(read)symlink_swappid=2230subtype:filepath:/stash_pathsubtype:filepath: /totally_safe_pathHostsubtype:filepath:/subtype:filepath:/w00t_w00t_im_a_flag7.writesubtype:filepath:~/ex101/out1.execverktpid=26617ns_pid:a0ns_pid_for_cdr:a0ns_mnt:c0ns_net:d02.unsharenew_netinitpid=266173.unsharenew_nsinitpid=26617ns_net:d1initpid=26617ns_mnt:c15.clone4.execveld-linux-x86-64pid=26617ld-linuxpid=26654(call chroot)6.clonenew_pid7.execvesystemdpid=26655ctr_pid=1ns_pid:a1ns_pid_for_cdr:a1hellopid=26655ctr_pid=1ContainerContainer Initialization Host1.clonecontainerdpid=21456ns_pid:a0ns_pid_for_cdr:a0ns_mnt:c0ns_net:d02.clonecontainerd-shimpid=214653.clonerunCpid=21468runC[Parent]pid=214716.clone5.execverunC[Child]pid=21471runC[INIT]pid=21473unsharenew_pid|new_mnt|new_net7.clonerunC[INIT]pid=21473ns_pid_for_cdr:a1ns_mnt:c1ns_net:d18.execverunC[INIT]pid=21474ns_pid:a1(call pivot_root)hellopid=21474ctr_pid=1ContainerContainer Initialization HostThe overall overhead of CLARION consists of SPADE
overhead and CLARION’s (PID namespace, Netﬁlter) kernel
module overhead. By comparing values in the Base column
with CLARION’s overhead columns, we see that the major
overhead originates from Linux Audit as opposed to extra
modules introduced by CLARION.
5.3.3 Storage Overhead
We compare the size of raw logs collected by SPADE and
CLARION in the aforementioned microservice environment
with all 10 microservices. We collected logs for 24 hours and
the results are shown in Table 11. We see that the additional
storage overhead for CLARION is modest (under 5%) and
much lower than CamFlow.
6 Related Work
Container Security. With the growing popularity of
container-based virtualization, numerous security issues have
been identiﬁed in container orchestration systems [8,9,14,18].
The reasons for these security issues may be attributed to a
diverse set of ﬂaws in design assumptions. For instance, to
simplify support for ﬁle-system features like “bind mount”,
container engines, such as Docker do not enable the user
namespace by default because this leads to ﬁle access privi-
lege problems. But disabling the user namespace also implies
that the root user inside the container also becomes the root
user outside the container. In several aforementioned security
issues, attackers simply leverage this general vulnerability to
achieve privilege escalation on the host OS. Given the preva-
lence of such security issues, developing defensive technol-
ogy that supports security analysis in container environments
is crucial. This paper describes a ﬁrst step toward a robust
forensics analysis framework for containerized application
deployments.
Container Vulnerability Analysis. Many existing efforts
[37] have focused on the problem of container system vul-
nerability analysis. One line of work leverages traditional
static analysis techniques to perform compliance checking
on container images, such as those built with Docker. How-
ever, they do not protect the integrity of container instances at
runtime [33, 40]. Thus, contemporary container vulnerability
analysis tools are limited in their ability to conduct long-term
forensic analysis. Our study complements current container
vulnerability analytics by providing a dynamic analysis view
that leverages semantics-aware comprehension of attacks tar-
geting running containers.
Provenance Tracking and Causality Analysis. Provenance
tracking and causality analysis have played a vital role in
system forensics [31, 32, 34, 36]. These tools build prove-
nance/causal graphs by connecting system objects like pro-
cesses, ﬁles, and sockets by using low-level events, such as
system calls. When an attack entry point is identiﬁed, forward
and backward tracking along graphs can then be performed to
ﬁnd the attack-related subgraphs. These allow analysts to get
Figure 16: Initialization of a hello-world LXC container
the whole graph becomes more fractured as well. These re-
sults underscore how, especially in microservice scenarios,
namespace-unawareness can lead to signiﬁcant errors due to
both fragmentation and ambiguities.
5.3 Efﬁciency Evaluation
Our efﬁciency evaluation consists of two parts: runtime over-
head evaluation and storage overhead evaluation. We de-
ployed a microservice benchmark and conducted a perfor-
mance comparison between SPADE and CLARION.
5.3.1 Experiment Setup
The server machine we used has a conﬁguration of Xeon(R)
E5-4669 CPU and 256 GB memory. The microservice bench-
mark we selected a very popular microservice demo, Online
Boutique [10], provided by Google. It contains 10 representa-
tive microservices and a web-based e-commerce app in which
users can browse items, add them to the cart, and purchase
them (i.e., a typical use-case for modern microservices).
5.3.2 Runtime Overhead
To compute the runtime overhead, we started every microser-
vice independently 100 times and recorded the cumulative
time for those 100 microservice containers to be initialized.
First, we performed this process for each microservice with-
out any audit subsystem enabled to get a baseline. Next, we
repeated this evaluation with Linux Audit, SPADE, CLAR-
ION, CamFlow, and Linux Audit with SE-Linux labeling 6.
We summarize the detailed results in Table 10. The incre-
mental overhead is calculated by comparing CLARION’s
overhead with that of SPADE. The “overall overheads” are
based on comparison against the performance of the Base sys-
tem. We ﬁnd that the additional runtime overhead on SPADE
imposed by CLARION is under 5% which we consider to
be acceptable.
6Our objective is to obtain an estimate for Winnower’s computational
overhead. Unfortunately, because we do not have access to the Winnower
system, we use Linux Audit with namespace-aware audit rules and SE-Linux-
enabled Docker to obtain the results shown under SEL-Audit. We believe
SEL-Audit results can serve as a lower-bound estimate of Winnower’s com-
putational overhead as Winnower uses Linux Audit and relies on SE-Linux
labels. This does not measure the cost associated with Winnower’s graph
reduction or anomaly detection functionality.
USENIX Association
30th USENIX Security Symposium    4003
1.clonenew_pid|new_mntlxdpid=29746ns_pid:a0ns_pid_for_cdr:a0ns_mnt:c0ns_net:d02.unsharenew_netlxdpid=29484ctr_pid=1ns_pid:a1ns_pid_for_cdr:a1ns_mnt:c13.clonelxdpid=29484ctr_pid=1ns_net=d1(callpivot_root)4.execvelxdpid=29496ctr_pid=2hellopid=29496ctr_pid=2ContainerHostContainer Initialization Table 7: Provenance Graph Statistics Comparison (Docker)
Error Edges
Vertices
SPADE/CLARION
4236 / 4152
4759 / 4677
4673 / 4581
4473 / 4387
4737 / 4637
7467 / 7345
Edges
SPADE/CLARION
19056 / 19066
22856 / 22871
21024 / 21026
19371 / 19376
20780 / 20841
40711 / 40781
Components
SPADE/CLARION
22 / 22
23 / 22
28 / 25
24 / 21
26 / 21
32 / 26
23875 / 23233
119128 / 119372
49 / 31
Table 8: Provenance Graph Statistics Comparison (rkt)
Error Edges
Vertices
SPADE/CLARION
19047 / 19031
19348 / 19330
19441 / 19420
19600 / 19575
19666 / 19617
23761 / 23721
Edges
SPADE/CLARION
88022 / 88114
90471 / 90573
90798 / 90893
90029 / 90125
90885 / 91063
106599 / 106754
Components
SPADE/CLARION
28 / 27
26 / 26
28 / 28
27 / 25
34 / 28
40 / 33
Error Vertices
(lost/extra)
58 (8/50)
78 (18/60)
55 (2/53)
72 (9/63)
72 (18/54)
73 (19/54)
376 (135/241)
Error Vertices
(lost/extra)
80 (59/21)
171 (145/26)
99 (84/15)
138 (103/35)
85 (69/16)
101 (70/31)
900
1612
133
919
1558
1662
7492
10076
12540
10749
13334
10671
15272
Service
ubuntu
redis
jenkins
node
nginx
nginx
MT-4
nginx
MC-4
Service
ubuntu
redis
jenkins
node
nginx
nginx
MT-4
nginx
MC-4
828 (726/102)
65022
92962 / 93158
425550 / 426194
66 / 36
a clear understanding of the attack origin and its impact on the
system. Several prior efforts have proposed mechanisms that
seek to improve the quality of generated provenance/causal
graphs [31, 32, 36] in different ways. While some of these
attempt to mitigate the dependency explosion problem and
eliminate unrelated data [41], others focus on real-time and
scalable graph generation [34]. As described in Section 2,
systems such as Winnower [26] and CamFlow [39] also have
limitations. CamFlow has namespace awareness but not con-
tainer awareness (i.e., it only extracts namespace identiﬁers,
but does nothing to deal with container semantics or container
boundaries.) In contrast, Winnower is container-aware but not
namespace-aware. Although it uses SELinux label informa-
tion to assign docker container IDs for process, ﬁle, and socket
objects, those labels are not sufﬁcient to fully disambiguate
the effect of important syscalls like clone, fork. However,
since both Winnower and CLARION run on SPADE, the
two systems are complementary and could potentially be inte-
grated. Our work is also more general and agnostic to speciﬁc
container-management frameworks.
Alternative OS-level Virtualization Techniques. Multiple
OS-level virtualization techniques exist on other operating sys-
tem platforms. Among all those techniques, Solaris zones [11]
and FreeBSD jails [12] show considerable similarity to Linux
namespaces because both of them seek to provide isolation of
system resources virtualized by Linux namespaces, e.g., pro-
cess identiﬁers, ﬁlesystem and network stack, while sharing
the same underlying kernel. Although conceptually similar,
provenance effects from these techniques depend on multiple
factors including virtualized resources, OS platforms, audit
frameworks, etc. We provide a summary of our investigation
into BSD Jail and Solaris Zones in Section 3.1.
7 Conclusion
In this paper, we present a comprehensive analysis of the
soundness and clarity challenges introduced in data prove-
nance analysis by Linux namespaces and containerization.
Our analysis informed the development of CLARION, a
namespace-aware provenance tracking solution targeting
Linux container-based microservice deployments. Speciﬁ-
cally, we resolved the soundness challenges introduced in
each of the Linux namespaces affected by containeriza-
tion and developed abstraction patterns to clarify container-
speciﬁc semantics. We demonstrated the wide applicability
of our solution by illustrating the generation of namespace-
aware provenance graphs across multiple container engines.
Evaluation results on real-world microservice benchmarks
show that our solution is more effective than state-of-the-art
provenance-tracking techniques and introduces acceptable
additional overhead.
Acknowledgements
We thank our shepherd, Kevin Butler, and the anonymous
reviewers for their insightful comments and suggestions. This
work was sponsored in part by the U.S. Department of Home-
land Security (DHS) Science and Technology Directorate
under Contract HSHQDC-16-C-00034 and the National Sci-
ence Foundation under Grants 1514503 and 1547467. Any
opinions, ﬁndings, and conclusions or recommendations ex-
pressed in this material are those of the authors and do not
necessarily reﬂect the views of DHS or NSF and should not
be interpreted as necessarily representing the ofﬁcial policies
or endorsements, either expressed or implied, of DHS, NSF
or the U.S. government.
4004    30th USENIX Security Symposium
USENIX Association
Table 9: Provenance Graph Statistics Comparison (Mesos)
Error Edges
Error Vertices
(lost/extra)
10 (5/5)
30 (18/12)
267 (210/57)
21 (9/12)
23 (20/3)
23 (20/3)
241
3149
25453
1106
2389
2418
Vertices
SPADE/CLARION
28019 / 27932
19667 / 19574
34664 / 34560
4960 / 4864
5159 / 5067
5185 / 5093
Edges
SPADE/CLARION
76555 / 76561