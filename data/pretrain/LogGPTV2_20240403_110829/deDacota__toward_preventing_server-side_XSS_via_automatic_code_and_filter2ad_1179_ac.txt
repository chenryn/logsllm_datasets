6
7 var hashName = Hash ( Session [ " 7 " ]) + " . js " ;
8 W r i t e T o F i l e ( hashName , Session [ " 7 " ]) ;
9
10 w . Write ( "  " ) ;
11
12 w . Write ( " \ n
\ n  " ) ;
Listing 3: The result of the rewriting algorithm
applied to Listing 2. Speciﬁcally, here we show the
transformation of Lines 7–9 in Listing 2.
the web application dynamically generates JavaScript with
undecidable content, and that content is not properly sani-
tized inside the JavaScript code, an attacker can exploit this
bug to inject a malicious script. The approach discussed so
far does not mitigate this attack, because it simply moves
the vulnerable JavaScript to an external ﬁle.
To understand how dynamic JavaScript can result in a
vulnerability, consider our example application in Listing 2.
There is an XSS vulnerability on Line 8 because the User-
name variable is derived from the name parameter and output
directly to the user, without sanitization. An attacker could
exploit this vulnerability by setting the name parameter to
";alert(’xss’)//. This would cause the resulting inline
JavaScript to be the following, thus executing the attacker’s
JavaScript code:
Therefore, the code section of the application is dynami-
cally generated with untrusted input and even with the code
and data separated, there is still an XSS vulnerability.
We attempt to mitigate this problem, and therefore im-
prove the security of the application, in two ways. First, we
identify cases in which we can safely rewrite the application.
Second, we notify the developer when we make an inline to
external transformation that is potentially unsafe.
For the ﬁrst case, when the undetermined output is pro-
duced in certain JavaScript contexts, we can include it in a
safe fashion via sanitization. Speciﬁcally, during static anal-
ysis we pass the dynamic inline JavaScript to a JavaScript
parser. Then, we query the parser to determine the con-
texts in which the undetermined output (i.e., the * parts)
is used. Here, for context we are referring speciﬁcally to
the HTML parsing contexts described by Samuel et al. [38].
Possible contexts are JavaScript string, JavaScript numeric,
JavaScript regular expression, JavaScript variable, etc.
If
an undetermined output is in a string context, we sanitize
them in a way similar to how Blueprint [28] handles string
literals in JavaScript.
Like Blueprint, on the server side we encode the string
value and store the encoded data in JavaScript by embed-
ding a call to a decoding function. Then when the Java-
Script is executed on the client side, the decoding function
will decode the encoded data and return the string. Unlike
Blueprint, we do not require any developer annotations
because our static analysis can automatically identify which
JavaScript context an undetermined output is in.
4.6 Generality
While the description of our approach so far was speciﬁc
to ASP.NET Web Forms, the high-level idea of automati-
cally separating code and data in a legacy web application
can be generalized to any other web application frameworks
or templating languages. There are still challenges that re-
main to apply our approach to another language, or even
another template in the same language. The two main steps
of our approach that must be changed to accommodate a
diﬀerent language or templating language are: (1) under-
stand how the output is created by the web application and
(2) understand how to rewrite the web application. Only
the ﬁrst step aﬀects the analysis capability (as the rewriting
process is fairly straightforward).
To automatically separate the code and data of a diﬀer-
ent language or templating language, one must understand
how the language or template generates its output. After
that, one would need to implement a static analysis that
can create an approximation graph. For instance, in the de-
fault Ruby on Rails template, ERB, variables are passed to
the template either via a hash table or class instance vari-
ables [37]. Therefore, one could approximate the output of
an ERB template by statically tracking the variables added
to the hash table and class instance variables (using points-
to analysis). Once an approximation graph is created, de-
tecting inline JavaScript can be performed in the manner
previously described.
The main factor to aﬀect the success of applying our ap-
proach to another web application framework or templating
language is the precision of the static analysis, or in other
words, how precise and detailed the approximation graph
would be. The more dynamicism in the language or frame-
work, such as run-time code execution and dynamic method
invocation, the more diﬃcult the analysis will be. Simply,
the more of the control-ﬂow graph that we are able to de-
termine statically, the better our analysis will be. As an
example the default templating language in Django only al-
lows a subset of computation:
iterating over a collection
instead of arbitrary loops [12]. This restriction could make
the analysis easier and therefore the approximation graph
more precise.
5.
IMPLEMENTATION
We implemented the automated code and data separa-
tion approach described in Section 4 in a prototype called
deDacota. This prototype targets ASP.NET Web Forms
applications. ASP.NET is a widely used technology; of the
Quantcase top million websites on the Internet, 21.24% use
ASP.NET [8].
deDacota targets binary .NET applications. More pre-
cisely, it takes as input ASP.NET Web Forms binary web
applications, performs the three steps of our approach, and
outputs an ASP.NET binary that has all inline JavaScript
code converted into external JavaScript ﬁles. We operate
at the binary level because we must be able to analyze the
ASP.NET system libraries, which are only available in bi-
nary form.
We leverage the open-source Common Compiler Infras-
tructure (CCI) [32] for reading and analyzing the .NET
Common Language Runtime byte-code. CCI also has mod-
1210ules to extract basic blocks and to transform the code into
single static assignment (SSA) form. We also use CCI to
rewrite the .NET binaries.
For the static analysis engine, we leverage the points-to
analysis engine of KOP (also known as MAS) [10]. KOP was
originally written for the C programming language. There-
fore, we wrote (using CCI) a frontend that processes .NET
binaries and outputs the appropriate KOP points-to rules.
Then, after parsing these rules, the static analysis engine can
provide either alias analysis or points-to analysis. The KOP
points-to analysis is demand-driven, context-sensitive, ﬁeld-
sensitive, and, because of the CCI single static assignment,
partially ﬂow-sensitive.
An important point, in terms of scalability, is the demand-
driven ability of the static analysis engine. Speciﬁcally, we
will only explore those parts of the program graph that are
relevant to our analysis, in contrast to traditional data-ﬂow
techniques which track data dependencies across the entire
program. The demand-driven nature of the static analysis
engine oﬀers another scalability improvement, which is par-
allelism. Each analysis query is independent and, therefore,
can be run in parallel.
We also extend the KOP points-to analysis system to
model string concatenation. We do this by including spe-
cial edges in the program graph that indicate that a vari-
able is the result of the concatenation of two other vari-
ables. When computing the alias set of a variable, we ﬁrst
do so in the original way (ignoring any concatenation edges).
Then, for each variable in the alias set that has concatena-
tion edges, we compute the alias set for each of the two
variables involved in the concatenation operation. We con-
catenate strings in the two alias sets and add them to the
original alias set. The undecidable variables are tracked,
so that their concatenated result contains a wildcard. This
process is recursive, and handles arbitrary levels of concate-
nation.
ASP.NET uses the idea of reusable components, called
Controls. The idea is that a developer can write a con-
trol once and then include it in other pages, and even other
controls. This relationship of including one control inside
another creates a parent-child relationship between the con-
trols (the parent being the control that contains the child
control).
In an ASP.NET Web Form page, child controls are ﬁrst
added to the parent’s ChildControls collection, which is
similar to an array. Then, during rendering, a parent ren-
ders its child controls either by iterating over the ChildCon-
trols or by referencing a child control based on its index
in the ChildControls. Because the KOP points-to analysis
does not model the array relation, we cannot precisely de-
cide which child Control is being selected during rendering.
To handle this problem, we need to track the parent-child
relationships directly.
These parent-child relationships form a tree. Figure 3
shows the parent-child relationship of some of the user con-
trols of default.aspx in the application BlogEngine.NET
(one of the programs used in our evaluation). When build-
ing the control graph, we must statically recreate this tree.
To create this relationship statically, we take an approach
similar to approximating the HTML output. The entry func-
tion for an ASP.NET page is FrameworkInitialize, which is
similar to the main function for a C program. Starting from
this method, we create a control-ﬂow graph of all the calls
to AddParsedSubObject, which is the function that adds a
child control to a parent. This gives us the order of the
AddParsedSubObject calls. At each of the calls, we use the
points-to analysis to ﬁnd which control is the parent and
which is the child. This information, along with the order of
the calls to AddParsedSubObject, allows us to recreate the
parent-child control tree.
6. EVALUATION
There are three properties that we must look at to eval-
uate the eﬀectiveness of deDacota. First, do we prevent
XSS vulnerabilities in the data section of the application by
applying code and data separation? Second, do we correctly
separate the code and data of the application—that is, does
the rewriting preserve the application’s semantics? Third,
what is the impact on the application’s performance? To
evaluate the security of our approach, we look at ASP.NET
applications with known vulnerabilities. To evaluate the cor-
rectness of our rewriting procedure, we apply our approach
to applications that have developer-created integration tests.
Then, we carried out performance measurements to answer
the third question. Finally, we discuss the relation between
separating code and data in the output and sanitizing the
input.
6.1 Applications
We wish to evaluate deDacota on ASP.NET web ap-
plications that are real-world, are open-source, and contain
known vulnerabilities. Real-world applications are impor-
tant for showing that our approach works on real-world code,
open-source is important for other researchers to replicate
our results, and known-vulnerable is important because we
aim to automatically prevent these known vulnerabilities.
Unfortunately, there is no standard (or semi-standard)
ASP.NET web application benchmark that meets all three
requirements. Furthermore, ﬁnding these application proved
to be a challenge. Compared to other languages such as
PHP, there are fewer open-source ASP.NET applications (as
most ASP.NET applications tend to be proprietary). There-
fore, here we present a benchmark of six real-world, open-
source, ASP.NET applications, four of which are known-
vulnerable, one of which is intentionally vulnerable for edu-
cation, and one of which has a large developer-created test
suite.
Table 1 contains, for each application, the version of the
application used in our evaluation, the CVE number of the
vulnerability reported for the application, the number of
ASP.NET Web Form pages, and the number of developer-
written ASP.NET Controls. To provide an idea of the size
of the applications, we also show the number of lines of code
(LOC) of the ASP.NET controls (Web Forms and Controls)
and C# code.
The web applications BugTracker.NET [7], BlogEngine-
.NET [5], BlogSA.NET [6], and ScrewTurn Wiki [41] all
contain an XSS vulnerability as deﬁned in the associated
CVE.
WebGoat.NET [17] is an open-source ASP.NET applica-
tion that is intentionally vulnerable. The purpose is to pro-
vide a safe platform for interested parties to learn about web
security. Among the vulnerabilities present in the applica-
tion are two XSS vulnerabilities.
ChronoZoom Beta 3 [9], is an open-source HTML5 “in-
teractive timeline for all of history.” Parts are written in
1211default.aspx
SearchOnSearch
PostList
PostCalendar
InfoBox
SearchBox
menu
PostCalendar
PageList
RecentPosts
Figure 3: Control parent-child relationship between some of the controls in default.aspx from the application
BlogEngine.NET. The siblings are ordered from left to right in ﬁrst-added to last-added order.
Version
Application
BugTracker.NET 3.4.4
BlogEngine.NET 1.3
BlogSA.NET
ScrewTurn Wiki
WebGoat.NET
ChronoZoom
1.0 Beta 3
2.0.29
e9603b9d5f
Beta 3
Known Vulnerability # Web Forms # Controls ASP.NET LOC C# LOC Total LOC
35,674
CVE-2010-3266
29,512
CVE-2008-6476
6,994
CVE-2009-0814
12,155
CVE-2008-3483
11,993
2 Intentional
N/A
21,261
8,417
26,987
4,362
9,204
10,349
18,136
27,257
2,525
2,632
2,951
1,644
3,125
115
19