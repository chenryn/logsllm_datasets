rent compartment. If the current compartment is (A, J, S),
add jump target takes as input an address a ∈ A and modiﬁes
the current compartment to (A, J ∪ {a}, S); add store target
does the same thing for store targets. Note that although isolate
removes the child’s address space from the parent, it leaves the
store and jump targets of the parent unchanged, and these can
overlap with the child’s address space. Thus, the parent can
preserve access to an address in its child’s memory by calling
add jump target or add store target with that address before
invoking isolate.
In the initial conﬁguration of the abstract machine, all deﬁned
addresses lie in one big compartment and each monitor service
address has its own unique compartment (i.e., these locations
are special and live outside of addressable memory). The main
compartment has the addresses of the monitor services in its
set of jump targets, allowing it to call them; the monitor service
compartments have all deﬁned addresses in their set of jump
targets, allowing them to return to any address. Since, in order
to call a monitor service, its address must lie in the calling
compartment’s set of jump targets, a parent compartment can
choose to prevent a child it creates from calling speciﬁc services
by restricting the child’s jump table.
Before returning, each monitor service checks that the com-
partment it is returning to is the same as the one it was called
from. This detail is needed to prevent malicious use of monitor
services to change compartments: otherwise, calling a service
from the last address of a compartment would cause execution
to proceed from the ﬁrst address of a subsequent compartment,
even if the original compartment was not allowed to jump
there.
As a sanity check on the abstract machine, we prove that
it satisﬁes a compartmentalization property based on the in-
formal presentation by Wahbe et al. [32]. We ﬁrst prove that
the machine maintains invariants ensuring that each deﬁned
memory location lies in exactly one compartment. We use this
to prove that, on every step, (a) if the machine isn’t stuck, then
the new pc is either in the initial pc’s compartment or in its
set of jump targets; and (b) if a memory location was changed,
then its address was either in the initial pc’s compartment or
in its set of store targets.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:44 UTC from IEEE Xplore.  Restrictions apply. 
Symbolic Machine Our method for implementing this ab-
stract machine in terms of tags involves “dualizing” the rep-
resentation of compartments: rather than maintaining global
state recording which compartments exist and what memory
locations they are allowed to affect, we instead tag memory
locations to record which compartments are allowed to affect
them. Compartments are represented by unique ids, and the
extra state of the symbolic machine contains a monotonic
counter next for the next available compartment id.
For this policy, Tm contains triples (cid:17)c, I, W(cid:18), where c is
the id of the compartment to which a tagged memory location
belongs, I is the set of incoming compartment ids identifying
which other compartments are allowed to jump to this location,
and W is the set of writer ids identifying which other com-
partments are allowed to write to this location. Tpc contains
pairs (cid:17)F, c(cid:18), where the ﬂag F has the same role as on the
abstract machine and c is the id of the compartment from
which the previous instruction was executed. Since registers do
not play a role in this micro-policy, Tr contains just the dummy
value •. The extra state contains three tags, tI, tAJ, and tAS,
corresponding to the tags on the monitor services’ entry points
in the abstract machine. We cannot use the symbolic machine’s
monitor service tags, as those are immutable; the compartmen-
talization policy thus maintain its mutable monitor service tags
in the extra state. (This limitation is not fundamental, but does
not impact any other micro-policies.)
Here are a few of the symbolic rules (the rest are similar):
c = c(cid:3) ∨ (F = Jumped ∧ c ∈ I)
Nop : ((cid:17)F, c(cid:18),(cid:17)c(cid:3), I, W(cid:18),−,−,−) → ((cid:17)FallThrough, c(cid:3)(cid:18),−)
c = c(cid:3) ∨ (F = Jumped ∧ c ∈ I)
Jump : ((cid:17)F, c(cid:18),(cid:17)c(cid:3), I, W(cid:18),•,−,−) → ((cid:17)Jumped, c(cid:3)(cid:18),−)
c(cid:3) = c(cid:3)(cid:3) ∨ c(cid:3) ∈ W (cid:3)
c = c(cid:3) ∨ (F = Jumped ∧ c ∈ I)
Store :
((cid:17)F, c(cid:18),(cid:17)c(cid:3), I, W(cid:18),•,•,(cid:17)c(cid:3)(cid:3), I(cid:3), W (cid:3)(cid:18))
→ ((cid:17)FallThrough, c(cid:3)(cid:18),(cid:17)c(cid:3)(cid:3), I(cid:3), W (cid:3)(cid:18))
The ﬁrst side-condition on all the rules guarantees that all pc
changes are legal: c, taken from the pc tag, is the previously-
executing compartment; and c(cid:3), from the tag on the current
instruction, is the current compartment. An execution step
is allowed if it is in the same compartment (c = c(cid:3)), or if
it follows a jump from a permitted incoming compartment
(F = Jumped ∧ c ∈ I). Similarly, the extra side-condition for
Store checks that the write is to a location in the currently-
executing compartment (c(cid:3) = c(cid:3)(cid:3)) or to a location that accepts
the current compartment as a writer (c(cid:3) ∈ W (cid:3)).
From the rules, we can see that this encoding breaks up
the jump targets of each compartment, scattering the jumping
compartment’s id into the destination component in the tag
on each individual jump target; the store target are similarly
scattered across the writers component. The state maintained
in the pc tag corresponds exactly to the extra state maintained
by the abstract machine (i.e., F and prev), except that we use
a compartment id rather than an abstract compartment.
The monitor services must also be rephrased in terms of tags.
The add jump target service simply modiﬁes the tag on the
given address; if the previous tag was (cid:17)c, I, W(cid:18) and the current
compartment is c(cid:3), then the new tag will be (cid:17)c, I ∪ {c(cid:3)}, W(cid:18).
The add store target service is analogous. The isolate service
does four things: (1) It gets a fresh compartment id cnew (from
the counter, which it then increments). (2) It retags every
location in the new compartment’s address space, changing its
tag from (cid:17)c, I, W(cid:18) into (cid:17)cnew, I, W(cid:18). (3) It retags every location
in the new compartment’s set of jump targets, changing its
tag from (cid:17)cJ , IJ , WJ(cid:18) into (cid:17)cJ , IJ ∪ {cnew}, WJ(cid:18). (4) It retags
the new compartment’s set of store targets, changing each tag
from (cid:17)cS, IS, WS(cid:18) into (cid:17)cS, IS, WS ∪ {cnew}(cid:18).
Reﬁnement To prove that the symbolic compartmentalization
machine is correct, we prove backward simulation with respect
to the abstract compartmentalization machine:
Theorem 5.1 (1-backward SA-simulation). The symbolic com-
partmentalization machine backward-simulates the abstract
compartmentalization machine.
The bulk of the work in this proof lies in showing that
when we pass from a global set of compartment information
to our “dualized” tag-based approach, that we indeed retain
the same information: we must prove that the compartment
IDs are assigned consistently and that the jump targets/store
targets correspond to the incoming/writers. In other words, our
symbolic tags must “reﬁne” our abstract compartments. This
difﬁculty shows up for the monitor services in particular: since
the effects of the monitor services are speciﬁed in terms of the
abstract representation (e.g., add jump target must add a jump
target, but there is no such thing at the symbolic level), the proof
that the effects of the symbolic implementations on the tags do
in fact correspond to the more direct abstract implementations
is particularly complicated. For the single-instruction steps of
the symbolic machine, we are able to capture most of the tag-
based complexity in a single lemma proving that the standard
symbolic check (c = c(cid:3) ∨ (F = Jumped ∧ c ∈ I)), along with
well-formedness and reﬁnement constraints, sufﬁces to prove
that the standard abstract checks ((A, J, S) ∈ C, pc ∈ A, and
(A, J, S) = (Aprev, Jprev, Sprev) ∨ (F = Jumped ∧ pc ∈ Jprev))
hold for the corresponding compartment.
Related Work Fine-grained compartmentalization is usually
achieved by software fault isolation [33]. There are several
veriﬁed SFI systems, including ARMor [35], RockSalt [24], and
a portable one by Kroll et al. [18]. Our compartmentalization
model is based on Wahbe et al.’s original SFI work [32] but
differs from it in several ways. Most importantly, our monitor
is not based on binary rewriting, but instead uses the hardware/
software mechanism of the PUMP architecture. Our model
is also richer in that it provides a hierarchical compartment-
creation mechanism instead of a single trusted top-level pro-
gram that can spawn one level of untrusted plugins. While
Wahbe et al.’s model produces safe (intra-compartment) but
arbitrary effects on compartmentalization violations, we detect
such violations and halt the machine. One feature Wahbe et al.’s
model that we do not currently support is inter-compartment
820820
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:44 UTC from IEEE Xplore.  Restrictions apply. 
RPCs; we instead require programs to manually predeclare
inter-compartment calls and returns.
6 Control-Flow Integrity Micro-Policy
We next outline a micro-policy enforcing ﬁne-grained control-
ﬂow integrity (CFI) [1] as well as providing basic non-writable
code (NWC) and non-executable data (NXD) protection. It
dynamically enforces that all indirect control ﬂows (computed
jumps) adhere to a ﬁxed control ﬂow graph (CFG). (This CFG
might, for example, be obtained from a compiler.) This prevents
control-ﬂow-hijacking attacks, in which an attacker exploits a
low-level vulnerability to gain full control of a target program.
A more detailed description of this micropolicy is in §A.
Our main result is a proof that a variant of the CFI property
of Abadi et al. [1] holds for the symbolic machine when
instantiated with our CFI micro-policy. For this, we ﬁrst prove
that the CFI property is preserved by backward simulation.
We then use this preservation result to show that the symbolic
CFI machine has CFI, by proving that it simulates an abstract
machine that has CFI by construction. The CFI deﬁnition relies
on a formal overapproximation of the attacker’s capabilities,
allowing the attacker to change any data in the system except
for the code, the pc, and the tags (if the machine has them).
This models an attacker that can mount buffer-overﬂow attacks
but cannot subvert the monitor; this is a reasonable assumption
since we assume that any implementation of the monitor will
be able to protect its integrity. For the same reason we assume
that in monitor mode all control ﬂows are allowed. Since
we assume that monitor code is correct, we do not need to
dynamically enforce CFI there.
Abstract CFI Machine The abstract machine has separate
instruction and data memories; the instruction memory is ﬁxed
(NWC), and instructions are fetched only from this memory
(NXD). Indirect jumps are checked against an allowed set J of
source-target pairs; if the control ﬂow is invalid the machine
stops. The attacker can make arbitrary changes to the data
memory and registers at any time.
Symbolic CFI Machine At the symbolic level, code and data
are stored in the same memory, and we use tags to distinguish
between the two. Tags on memory are drawn from the set
Data | Code addr | Code ⊥ and for the pc from Code addr |
Code ⊥ (other registers are always tagged •). For the CFG
conformance checks, instructions that are the source or target
of indirect control ﬂows are tagged with Code addr, where
addr is the address of the instruction in memory. For example,
a Jump instruction stored at address 500 is tagged Code 500.
The CFI policy does not need to keep track of where other
instructions are located, so they are all tagged Code ⊥.
(This
keeps the number of distinct tags small, which would reduce
cache pressure when executing this micro-policy on the concrete
machine described in §8.) Only memory locations tagged Data
can be modiﬁed (NWC), and only instructions fetched from
locations tagged Code can be executed (NXD). The symbolic
rule for Store illustrates both these points:
Store : (Code ⊥, Code
,−,−, Data) → (Code ⊥, Data)
It requires the fetched Store instruction to be tagged Code and
the written location to be tagged Data. On the other hand, the
Jal instruction’s rule requires that the current instruction be
tagged Code src; it then copies Code src to the pc tag:
Jal : (Code ⊥, Code src,−,−,−) → (Code src,−)
Only on the next instruction do we get enough information
from the tags to check that the destination of the jump is
indeed allowed by J. For this we add a second rule for each
instruction, dealing with the case where it is the target of a
jump and thus the pc tag is Code src, e.g.:
(src, dst) ∈ J
Store : (Code src, Code dst,−,−, Data) → (Code ⊥, Data)
We add such rules even for jump instructions, since the target
of a computed jump can itself be another computed jump:
(src, dst-src) ∈ J
Jal : (Code src, Code dst-src,−,−,−) → (Code dst-src,−)
Proof Organization Our proofs are structured around a ge-
neric CFI preservation result that states that CFI is preserved
by backward simulation under some additional assumptions
(§A). As mentioned, we use this to transport the CFI property
from the abstract machine to the symbolic machine.
This approach allows us to structure our proofs in a modular
way. More importantly, the reusable nature of the preservation
theorem provides an easy way to transfer the CFI property
from the symbolic machine to a concrete machine that correctly
implements the CFI micro-policy while keeping most of the
reasoning about the properties of the micro-policy at a higher
level. We were able to do this and transport the CFI property
to the instance of the concrete machine presented in §8; details
are presented in §A.
Finally, we prove that the symbolic machine backward-
simulates the correct-by-construction abstract machine, which—
in combination with our CFI preservation result—proves the
correctness of the micro-policy.
Related Work Abadi et al. [1] proposed both the ﬁrst CFI
deﬁnition and a reasonably efﬁcient, though coarse-grained,
enforcement mechanism based on binary analysis and rewriting,
in which each node in the CFG is assigned to one of three
equivalence classes. This seminal work was extended in various
directions, often trading off precision for low overheads and
practicality [34]. However, recent attacks against coarse-grained
CFI [10], [14] have illustrated the security risks of imprecision.
This has spurred interest in ﬁne-grained CFI [8], [22], [28],
sometimes called complete or ideal CFI; however, this has been
deemed “very expensive” [14]. Several proposed hardware
mechanisms are directly targeted at speeding up CFI [5], [9];
here we achieve CFI using a generic hardware mechanism
in a formally veriﬁed way. The PUMP mechanism supports
ﬁne-grained CFI with modest runtime overhead [11]. Previous
821821
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:44 UTC from IEEE Xplore.  Restrictions apply. 
formal veriﬁcation efforts for CFI include ARMor [35] and
KCoFI [8]. Like most work on CFI, they use inline reference
monitoring [13]; their veriﬁcation targets a small-TCB compo-
nent which validates that the right checks were inserted in the
instrumented binary.
7 Memory Safety Micro-Policy
Last, we describe a micro-policy that enforces safe access to
heap-allocated data, by preventing both spatial safety violations
(e.g., accessing an array out of its bounds) and temporal
safety violations (e.g., referencing through a pointer after the
region has been freed). Such violations are a common source
of serious security vulnerabilities such as heap-based buffer
overﬂows, conﬁdential data leaks, and exploitable use-after-
free, and double-free bugs. The policy we study here only
guards heap-allocated data, for which calls to the malloc and
free monitor services tell us how to set up and tear down
memory regions; we leave stack allocation and C-like unboxed
structs as future work.
Abstract Machine The abstract machine presents a block-
based memory model to the programmer [4], [20]: it operates
on values that are either ordinary machine words w or pointers
p. A pointer is a pair (b, o) of a block identiﬁer b (drawn from
an inﬁnite set) and an offset o (a machine word). The memory
is a partial function from block identiﬁers to lists of values; its