[19] M. Green and G. Ateniese. Identity-based proxy
re-encryption. In Proc. of the 5th Int. Conf. on
Applied Cryptography and Network Security (ACNS),
pages 288–306. Springer, 2007.
[20] S. Hohenberger and A. Lysyanskaya. How to securely
outsource cryptographic computations. In Proc. of the
2nd Theory of Cryptography Conference (TCC), pages
264–282. Springer, 2005.
[21] G. Itkis. Handbook of Information Security, chapter
Forward Security: Adaptive Cryptography—Time
Evolution. John Wiley and Sons, 2006.
[22] A.-A. Ivan and Y. Dodis. Proxy cryptography
revisited. In Proc. of the 10th Network and Distributed
System Security Symposium (NDSS). The Internet
Society, 2003.
[23] S. Jarecki and X. Liu. Eﬃcient oblivious
pseudorandom function with applications to adaptive
ot and secure computation of set intersection. In Proc.
of the 6th Theory of Cryptography Conference (TCC),
pages 577–594. Springer-Verlag, 2009.
[24] S. Kamara, C. Papamanthou, and T. Roeder.
Dynamic searchable symmetric encryption. In Proc. of
the 19th Conf. on Computer and Comm. Security
(CCS), pages 965–976. ACM, 2012.
[25] B. Libert, K. G. Paterson, and E. A. Quaglia.
Anonymous broadcast encryption: Adaptive security
and eﬃcient constructions in the standard model. In
Proc. of the 15th Int. Conf. on Public Key
Cryptography (PKC), pages 206–224. Springer, 2012.
[26] M. Luby and J. Staddon. Combinatorial bounds for
broadcast encryption. In Proc. of the 17th Int. Conf.
on the Theory and Application of Cryptographic
Techniques (EUROCRYPT), pages 512–526. Springer,
1998.
[27] A. Lysyanskaya. Unique signatures and veriﬁable
random functions from the DH-DDH separation. In
Proc. of the 22nd Annual Conf. on Advances in
Cryptology (CRYPTO), pages 597–612. Springer, 2002.
[28] M. Mambo, K. Usuda, and E. Okamoto. Proxy
signatures for delegating signing operation. In Proc. of
the 3rd Conf. on Computer and Comm. Security
(CCS), pages 48–57. ACM, 1996.
[29] S. Micali, M. O. Rabin, and S. P. Vadhan. Veriﬁable
random functions. In Proc. of the 40th Annual
Symposium on Foundations of Computer Science
(FOCS), pages 120–130. IEEE, 1999.
[30] D. Molnar, A. Soppera, and D. Wagner. A scalable,
delegatable pseudonym protocol enabling ownership
transfer of RFID tags. In Proc. of the 12th Int.
Workshop on Selected Areas in Cryptography (SAC),
pages 276–290. Springer, 2006.
[31] D. Naor, M. Naor, and J. Lotspiech. Revocation and
tracing schemes for stateless receivers. In Proc. of the
21st Annual Conf. on Advances in Cryptology
(CRYPTO), pages 41–62. Springer, 2001.
[32] M. Naor and B. Pinkas. Eﬃcient trace and revoke
schemes. Int. J. Inf. Sec., 9(6):411–424, 2010.
to delegate and verify in public: veriﬁable
computation from attribute-based encryption. In Proc.
of the 9th Theory of Cryptography Conference (TCC),
pages 422–439. Springer, 2012.
| Pr[GA
SEC(1λ) = 1] − Pr[BR(·)(1λ) = 1]| ≤ (λ) .
APPENDIX
Proof of Lemma 4
By Lemma 3, it suﬃces to focus on the case that λγ < 2n−1.
This is deﬁnitely the interesting case, since 2n is normally
superpolynomial in λ. Let A be a preﬁx-only adversary
against BRC that makes at most q(λ) queries (including the
challenge) and d be the minimum integer that λγ < 2d.
We construct a PPT PRF distinguisher B that makes oracle
queries of ﬁxed size n(cid:48) = n − d ≥ 1. On input 1λ, B ﬂips a
coin b, invokes A and initializes a security game, itself being
the challenger. By the bound on the size of the ranges, all
queries of A have length greater than n(cid:48). Thus, for every
query xn−1 ··· xt, we have that t < d and B responds by
making a query xn−1 ··· xd, which is of length n(cid:48), receiving a
value y and answering to A as Gxt (··· (Gxd−1 (y))). When A
submits a challenge, B acts as a normal challenger according
to the coin ﬂip b utilizing its oracle to determine the value
up to level d as above. Finally, B returns 1 iﬀ A returns b.
Clearly, when B’s oracle is a PRF fk of length n(cid:48), B returns
1 iﬀ A wins, i.e Pr[GA
SEC(1λ) = 1] = Pr[Bfk(·)(1λ) = 1]. Since
fk is a PRF, we have that for some negligible function (·),
(1)
Consequently, we can construct a preﬁx-only adversary ˜A
against a BRC with depth d and maximum range size λγ as
follows: ˜A invokes A and chooses a random index j ∈ [q(λ)]
and q(λ) − 1 random values k1, . . . , kj−1, kj+1, . . . , kq(λ) ∈
{0, 1}λ. Index j reﬂects ˜A’s attempt to guess which of all of
possible diﬀerent preﬁxes of length n(cid:48) that will appear in A’s
queries will be the one that a prospective challenge query will
have. Then ˜A keeps count of the diﬀerent preﬁxes of length
n(cid:48) that gradually appear and reacts to a query xn−1 ··· xt
according to the following checks:
(i) xn−1 ··· xd is the i-th preﬁx and i (cid:54)= j: In this case, ˜A
responds with Gxt (··· (Gxd−1 (ki))).
(ii) xn−1 ··· xd is the j-th preﬁx: If all of the queries made
by A that have the j-th preﬁx, along with xn−1 ··· xt,
cover the whole subtree with root preﬁx xn−1 ··· xd,
Tj, then ˜A terminates the game with A and chooses a
leaf zd−1 ··· z0 of Tj that has not been covered by A’s
previous queries. It submits zd−1 ··· z0 as its challenge
and returns a random bit. Otherwise, ˜A makes query
xd−1 ··· xt and responds with the received value y.
(iii) t = 0 and xn−1 ··· x0 is A’s challenge: If xn−1 ··· xd is
not the j-th preﬁx, then ˜A terminates the game with
A, chooses a leaf zd−1 ··· z0 of Tj not yet covered by
A’s queries, submits zd−1 ··· z0 as its challenge and re-
turns a random bit. Otherwise, it submits challenge
xd−1 ··· x0, receives value y∗ and responds with y∗.
If ˜A does not terminate the security game with A, then
it returns A’s guess. By the choice of d, 2d−1 ≤ λγ < 2d,
hence Lemma 3 implies that ˜A has negligible distinguishing
advantage. Thus for some negligible function δ(·),
Pr[G ˜A
SEC(1λ) = 1] ≤ 1/2 + δ(λ) .
(2)
682
By the description of ˜A, the interaction between A and
B in the case that B’s oracle is random is fully simulated
by ˜A when the latter’s guess for the preﬁx of A’s challenge
is correct. Formally, let E be the event that ˜A guesses A’s
challenge. Then it holds that
Pr[BR(·)(1λ) = 1] = Pr[G ˜A
SEC(1λ) = 1|E] .
By the description of ˜A and (3), we have that
(3)
Pr[G ˜A
Pr[G ˜A
SEC(1λ) = 1 ∧ ¬E] = 1/2 · (1 − 1/q(λ)) and
SEC(1λ) = 1 ∧ E] = 1/q(λ) · Pr[BR(·)(1λ) = 1] ,
where we used that Pr[E] = 1/q(λ). Therefore,
Pr[G ˜A
so by applying (2) we get
SEC(1λ) = 1] = 1/2 + 1/q(λ)· (Pr[BR(·)(1λ) = 1]− 1/2) ,
Pr[BR(·)(1λ) = 1] ≤ 1/2 + q(λ) · δ(λ) .
(4)
Finally, by (1) and (4) we conclude that
Pr[GA
SEC(1λ) = 1] ≤ 1/2 + q(λ) · δ(λ) + (λ) =
= 1/2 + negl(λ) .
0 (1λ), . . . ,GA
Proof of Theorem 4
Let A be a PPT adversary that wins the union policy privacy
game with non-negligible distinguishing advantage α(·). Let
P0, P1 be the two challenge ranges and b the chosen random
bit, hence A receives the challenge trapdoor τb for Pb. De-
note each element of a decomposition D as (x, L) or (x, R),
if it is integer x and belongs to the leftmost or rightmost se-
quence of D respectively. Deﬁne the ordering <D over the el-
ements of D as follows: (x, L) <D (y, R) or (x, R) <D (y, L),
if x < y and (x, L) <D (x, R). We deﬁne a sequence of hy-
brid games GA
N (1λ), where N is the maximum
size of a trapdoor output by TURC. As shown in section
4.2, N = 2(cid:100)log(λγ + 2)(cid:101) − 1. The game Gi is executed
as the original game GA
UPP(1λ) during the pre-challenge and
the post-challenge phase. Assume the pairs of the challenge
trapdoor τb are arranged according to the ordering deter-
mined by the decomposition formed by the depths. The
only modiﬁcation in GA
i (1λ) is that in the ﬁrst i pairs of τb,
the partial PRF values are the same as τb’s, while all the
other elements are replaced by random values in {0, 1}λ. In
GA
0 (1λ), the challenge trapdoor consists of a number of pairs
of random values attached to certain integers, independently
of the choice of b. Therefore, Pr[GA
0 (1λ) = 1] = 1/2. Since
GA
N (1λ) is the union policy privacy game, it holds that
Pr[GA
N (1λ) = 1] − Pr[GA
0 (1λ) = 1] ≥ α(λ) .
Let Er be the event that the size of the challenge ranges
|AP0|, |AP1| that A submits is r. Then for some challenge
bit b ∈ {0, 1} and r ∈ [λγ]:
Pr[GA
which implies that there exists an i ∈ [λγ] such that
0 (1λ) = 1∧b∧Er] ≥ α(λ)/2λγ,
N (1λ) = 1∧b∧Er]−Pr[GA
Pr[GA
i (1λ) = 1 ∧ b ∧ Er]−
− Pr[GA
i−1(1λ) = 1 ∧ b ∧ Er] ≥ α(λ)/2N λγ .
(5)
We will show that for these ﬁxed b, r, i, we can construct an
adversary Ai for the security game of a BRC construction
683
SEC(1λ).
that has non-negligible winning advantage. The main idea is
that Ai invokes A and simulates either Gi or Gi−1 on selected
challenge Pb of size r depending on the value of the challenge
bit bi for the security game GAi
On input 1λ, Ai computes the uniform decomposition of
r, Ur, and arranges its elements according to <Ur . Let ui be
the integer that appears in the i-th element of Ur (trivially,
when r = 1 then ui = u1 = 0). The BRC that Ai attacks has
depth n−ui. Speciﬁcally, Ai invokes A and answers all of its
pre-challenge queries as follows: for each query xn−1 ··· xt,
if t ≥ ui, it just transfers the query, receives value y, and
responds with y. Otherwise, it makes query xn−1 ··· xui , re-
ceives value y, and responds with Gxt (··· (Gxui−1 (y))). In
the challenge phase, if |APb| (cid:54)= r, then Ai terminates the
game with A, chooses a valid random challenge, and returns
a random bit. Otherwise, it makes i−1 queries and computes
the <Ur -ﬁrst i−1 partial delegation keys y1, . . . , yi−1 of τb as
n−1 ··· x∗
in the pre-challenge phase, and sets the string x∗
ui
that corresponds to the i-th partial key as its challenge, re-
ceiving y∗. Note that since A is restricted from making
queries within AP0 ∪ AP1 , it makes no queries with preﬁx
n−1 ··· x∗
ui , thus Ai’s challenge is valid. It arranges the val-
x∗
ues y1, . . . , yi−1, y∗ according to the order that τb imposes
and “ﬁlls” the |Ur| − i remaining positions of an array like
trapdoor τb with |Ur| − i pairs consisting of random values
from {0, 1}λ along with the corresponding depths. It returns
τb to A and answers to A’s post-challenge queries as in the
pre-challenge phase. If A returns b, then Ai returns 1, or
else it returns a random bit.
SEC(1λ) = 1] = Pr[GAi
The probability that Ai wins the security game is
SEC(1λ) = 1 ∧ ¬Er]+
SEC(1λ) = 1 ∧ Er ∧ bi = 1]+
SEC(1λ) = 1 ∧ Er ∧ bi = 0] .
+ Pr[GAi
+ Pr[GAi
It holds that Pr[GAi
SEC(1λ) = 1 ∧ ¬Er] = 1/2 · (1 − Pr[Er]).
For the other two terms in the right part of (6), we observe
that when bi = 1, Ai simulates Gi when b and Er occur,
whereas when bi = 0, Ai simulates Gi−1 when b and Er
occur. Therefore, by the description of Ai we have that
Pr[GAi
SEC(1λ) = 1 ∧ Er ∧ bi = 1] =
Pr[GAi
(6)
= 1 · Pr[GA
i (1λ) = 1 ∧ b ∧ Er]+
+ 1/2 · Pr[GA
i (1λ) (cid:54)= 1 ∧ b ∧ Er] =
= 1/2 · Pr[b ∧ Er] + 1/2 · Pr[GA
i (1λ) = 1 ∧ b ∧ Er] ,
and
Pr[GAi
SEC(1λ) = 1 ∧ Er ∧ bi = 0] =
= 0 · Pr[GA
i−1(1λ) = 1 ∧ b ∧ Er]+
+ 1/2 · Pr[GA
i−1(1λ) (cid:54)= 1 ∧ b ∧ Er] =
= 1/2 · Pr[b ∧ Er] − 1/2 · Pr[GA
i−1(1λ) = 1 ∧ b ∧ Er].
By the independency of b and Er, we have that Pr[b∧ Er] =
1/2 · Pr[Er]. Thus, we evaluate Pr[GAi
SEC(1λ) = 1] according
to (6) as
Pr[GAi
i (1λ) = 1 ∧ b ∧ Er]−
SEC(1λ) = 1] = 1/2 + 1/2 · (Pr[GA
− Pr[GA
i−1(1λ) = 1 ∧ b ∧ Er]) .
Therefore by (5), Pr[GAi
which contradicts Theorem 3.
SEC(1λ) = 1] ≥ 1/2 + α(λ)/4N λγ,