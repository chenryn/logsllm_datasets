a fraudulent certificate for domain that it does not control. As a
result, the validation of control over the victim domain, during the
certificate issuance, is performed against a single attacker-selected
nameserver.
In this section we explain the server selection mechanism (Sec-
tion 2.1), and its implementation in the VAs of Let’s Encrypt (Section
2.2). Surprisingly, we show that off-path adversaries can influence
the server selection function at the VAs. To manipulate the server
selection we develop a server-elimination attack, forcing all the VAs
of Let’s Encrypt to query a nameserver of attacker’s choice (Section
2.3). Server-elimination attack not only reduces the entropy from
server selection, but also forces all the VAs to communicate with a
server of attacker’s choice.
Figure 1: Number of nameservers per domain.
2.1 Server Selection
Traditionally, there were up to 13 nameservers in each domain,
to fit DNS responses in 512 bytes UDP packet. After the adoption
of EDNS [RFC6891] [25] the limit on number of nameservers per
domain was removed, allowing each domain to configure arbitrary
number of nameservers. Our measurements show that on average
domains have more than 3 unique IP addresses and that there are
domains with more than 30 nameservers, Figure 1.
To ensure performance as well as to balance the load of queries
among the nameservers, the DNS resolver implementations use
different logic for selecting the nameservers in the target domain.
The implementations typically prefer most available servers with
low latency. To select the server the DNS resolver monitors the
performance of each nameserver in a domain and applies a compu-
tation over the responsiveness of individual nameservers as well as
the latency.
A number of studies explore the impact of DNS server selection
on load distribution [59, 61] and attempt to optimise performance
by only selecting fast nameservers and quickly reacting to changes
in nameserver performance [26]. Server selection also has implica-
tions for security of DNS, making it more difficult to launch cache
poisoning attacks since an off-path adversary cannot anticipate
which nameserver a target resolver will query [RFC5452] [34].
2.2 Analysis of Let’s Encrypt Server Selection
We perform an analysis of server selection behaviour of the VAs by
triggering queries to our domain and record the query behaviour
of the VAs. We then reproduce the same experiment in a lab envi-
ronment using popular DNS software and compare produced DNS
requests pattern to the one exhibited by the DNS software on the
051015202530Number of Nameservers0%20%40%60%80%100%CDFLet's EncryptAlexa Top-1MAllSession 5B: PKI and Access Control CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1423VAs of Let’s Encrypt. We then can determine the software used on
the VAs.
2.2.1 Experiment with Let’s Encrypt. We describe the setup, our
evaluation and the results.
Setup. In this experiment we use 20 domains that we registered.
We set up 5 nameservers, and configure each domain with these
5 nameservers. Each nameserver has 20 zonefiles, one for each
domain. The nameservers are placed in different regions: NS1 on our
AS 1, registered under RIPE NCC, NS2 on region USA west (Oregon),
NS3 on region USA west (north California), NS4 on region Canada
(central) and NS5 on region USA east (Ohio). The latencies between
the VAs of Let’s Encrypt to our nameservers ranges between 50ms
and 200ms. We set the TTL (Time to Live) of our nameservers to
10 seconds.
Evaluation. We use the Certbot to request certificates for our
20 domains and monitor the DNS requests received on our name-
servers. This causes the four VAs2 of Let’s Encrypt to issue DNS
lookups to our nameservers and then to perform validation against
our domains with DNS TXT/CAA. We repeat the evaluation 20
times, one iteration for each domain, and continually monitor the
requests from the VAs on our nameservers. The evaluation is carried
out in two phases. In the first phase we evaluate server selection
during normal conditions. In the second phase we introduce losses
and additional latency (between 300ms and 500ms) to responses of
some of the nameservers. We monitor the DNS requests from the
VAs on the nameservers. After the 20 iterations are concluded we
analyse the queries sent by each of the VAs to the nameservers in
our domains.
Results. Our findings are that the queries are distributed among
the nameservers independent of the geo-location and of the net-
work block on which the nameservers are placed. During the first
phase, each VA sends a query to each of the nameservers with
equal probability, and each of the nameservers receives roughly
an equivalent portion of the queries from each VA. During the sec-
ond phase, we observe that the VAs distribute the queries among
the nameservers which have latency below 400ms uniformly at
random. VAs avoid querying poor performing nameservers (with
latency above 400ms) as well as nameservers from which a VA ex-
perienced two-three consecutive packet losses. These nameservers
are avoided for more than 10 minutes. Afterwards, the VAs probe
the nameserver again to see if its performance improved. We also
find that the DNS software on the VAs of Let’s Encrypt imposes
an upper bound of 60 seconds on the cached records, irrespective
of the TTL on the DNS records that the nameservers return. This,
however, does not impact the time that the DNS software avoids
querying poorly performing nameservers, since this information is
stored in a different cache, called the infrastructure cache, as we
explain below.
2.2.2 Analysis on Experimental Platform. In this section we com-
pare the queries pattern in our experiment with Let’s Encrypt to
patterns generated by popular DNS software, to identify the soft-
ware used by Let’s Encrypt. We reproduce our experiments against
2Let’s Encrypt currently requires responses to only three out of four VAs for a DV and
lookup to be successful.
Let’s Encrypt described in Section 2.2.1 in a controlled environ-
ment using the DNS maze3 open-source platform, which offers a
reproducible test environment for DNS servers. We set up the name-
servers with the same zonefiles as we used in our experiment with
Let’s Encrypt. We also set up 4 DNS resolvers (that correspond to
the 4 VAs of Let’s Encrypt). We use network emulator4 to introduce
latencies and losses to responses from the nameservers (identical
to our experimental evaluation with Let’s Encrypt). During the
executions we run the same set of queries as we did against Let’s
Encrypt.
We execute the tests in an automated way, each time using
a different DNS resolver software on the VAs (using Knot, Bind,
Unbound, PowerDNS and MS DNS). The results are listed in Table
1. The query distribution, the blocking time, and the distribution
of queries to poorly performing nameservers provides a distinct
fingerprint allowing to identify the DNS resolver software. We
found that the Unbound DNS had the exact same pattern of queries
and server selection as those exhibited by the VAs of Let’s Encrypt.
DNS Software Query distribution to servers
Unbound
Knot
Bind
PowerDNS
Windows DNS
queries all 𝑛 servers with 35% queries to fastest server
& 10% to others
>95% queries to fastest server
& 1% to others
>97% queries to fastest server
& 1% to others
uniform query distribution
to available servers
Block % queries to
(min)
t.o. servers
15
1%
10
30
3
<1
5%
1%
1%
1%
Table 1: Server selection in popular DNS implementations.
2.2.3 Code Analysis of Unbound DNS. The server selection proce-
dure of Unbound DNS software is defined in function iter_server_selection
of iter_util.c. Unbound implements timeout management with
exponential backoff and keeps track of average and variance of the
response times. For selecting a nameserver, Unbound implements
an algorithm in [RFC2988]: it randomly selects any server whose
smoothed RTT is between the lowest one and the lowest one +
400ms. If a nameserver becomes unresponsive, a probing phase is
performed where a couple of queries probe that nameserver. If time-
out occurs, the nameserver is blocked for 900 seconds (infra-ttl)
and re-probed with one query after that time interval. We provide a
more detailed explanation of server selection in Appendix, Section
D.1, Figure 14.
2.3 Downgrade by Elimination
Our downgrade attack is carried out by reducing the number of
available servers each VA of Let’s Encrypt can query, leaving just a
single nameserver.
The attacker uses Certbot to request a certificate. This triggers
lookups from the DNS resolvers at the four VAs of Let’s Encrypt
to the nameservers in the target domain. The attacker causes the
requests to all the nameservers except one nameserver to timeout
- we explain how to do this in next Section. Following a timeout
3https://gitlab.nic.cz/knot/maze/
4NetEm tc qdisc.
Session 5B: PKI and Access Control CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1424the VAs go into exponential backoff, and the DNS requests are
retransmitted after RTO, i.e., 376ms. The attacker repeats the attack
every 376ms. After 2 consecutive losses the nameserver is moved to
infra_cache and its infra_ttl is set to 900sec. The attacker causes
the VAs to block the 𝑛−1 nameservers, and to only send the queries
to the one nameserver of attacker’s choice.
Challenge: how to hit the correct nameserver? Each time a VA sends
or resends a query the attacker does not know to which nameserver
the query is sent. Hence, the attacker needs to cause the queries
to 𝑛 − 1 nameservers to timeout, except the queries sent to the
one nameserver that the attacker wants the VAs to be forced to
select. After experiencing a timeout the VAs go into exponential
backoff, and will resend the queries after RTO5 (2·376ms in the case
of Let’s Encrypt); for detailed explanation of RTO see Appendix,
Section D.2. The strategy of the attacker is therefore to launch the
attack every RTO, in order to cause the queries to timeout every
RTO=376ms. This strategy always ‘hits’ the queries from all the
VAs, both from VAs that are in exponential backoff as well as from
VAs that are sending queries for the first time to a nameserver and
not as a result of a retry attempt.
Challenge: how many attack iterations required? How many times
should the attack be repeated to block 𝑛 − 1 servers and how many
queries are required until all the 𝑛−1 nameservers are removed from
the list of usable servers at all the VAs? To answer these questions
we analyse the query retransmission behaviour in Unbound, see
Appendix, Section D.2, Figure 15. We find that with a single query
the attacker can generate up to 32 timeouts, which result in 32
retries by the DNS software, and can be used to block 6 nameservers
in a domain. Since 95% of the domains have up to 6 nameservers,
a single query suffices to block nameservers of most domains. In
addition, since each VA sends at least two DNS requests (for TXT
and CAA records) during each certificate request invocation6, with
a single certificate request the attacker can block 12-13 nameservers
per domain. To block domains with more nameservers the attacker
can submit more certificate requests.
Challenge: how to cause responses to timeout? In the next section
we develop methodologies that enable even weak off-path attackers
to eliminate nameservers in domains during validation with Let’s
Encrypt. The idea is to make it appear as if the target server has poor
connectivity. In one methodology we use IP fragment reassembly
to cause mis-association of IP fragments [32, 55]. The resulting
(reassembled) UDP packet is discarded by the target resolver itself.
Nevertheless, this event is perceived as packet loss by the resolver.
In another methodology we use the rate-limiting of the nameservers,
to cause the query from the resolver to be filtered. We find both
these properties (fragmented DNS responses and rate limiting)
in 24.53% of Let’s Encrypt-certified domains. We also develop a
generic methodology, which does not assume any properties in the
nameservers nor domains. The idea is to send low rate bursts to
5The RTO is the timeout including the exponential backoff. It is used for server selection
and as a timeout for the transmitted request.
6Each VA can also send more queries and the exact upper bound of queries depends on
the responses from the nameservers. For instance, if the nameserver sends a response
with the NS type records with hostnames of the nameservers but without the A type
records. The resolver will issue a subsequent request for the A records with the IP
addresses of the nameservers.
cause packet loss at the router which requests of the target resolver
traverse.
3 SERVER-ELIMINATION METHODOLOGIES
Our key contribution in this section is a taxonomy of methodolo-
gies that we develop for off-path server elimination. These method-
ologies introduce packet losses on the communication between
the nameservers and the VAs. The lost packets signal to the DNS
software at the VA connectivity problems at the nameserver. The
nameserver is then blocked by the VA for 900 seconds. We use these
methodologies to launch downgrade attacks against Let’s Encrypt.
One methodology is generic and applies to any domain and all
nameservers without assuming any properties. The idea is to send
bursts to the router that connects the network of the nameserver to
the Internet. The traffic bursts never reach the nameserver network,
so the attack is stealthy and cannot be detected. We evaluated this
methodology ethically in a controlled environment that we set
up. The other two methodologies require less traffic but assume
that the nameservers in a domain have specific properties. One
methodology requires that the nameserver enforces rate limiting
on the inbound DNS requests. The other assumes that the responses
of the nameserver can be fragmented. We experimentally evaluated
these two methodologies against our dataset of domains and found
that they apply to 24% of Let’s Encrypt-certified domains and 20%
of 857K-top Alexa domains.
Since the evaluation is carried out against a large set of almost
2M domains, we automate it. This automated evaluation provides a
lower bound on the number of vulnerable domains, since it misses
out potentially vulnerable domains; we explain this in Section 3.6
below.
3.1 Dataset
Our dataset contains domains certified with Let’s Encrypt as well
as 1M-top Alexa domains; the dataset is listed in Table 2. Out of
1M-top Alexa domains only 857K domains were valid with respon-
sive nameservers. We use these 875K-top Alexa domains in the
rest of our work. In our study we use domains with Let’s Encrypt
certificates to infer the fraction of vulnerable customers of Let’s
Encrypt. We use the popular Alexa domains to infer the overall
attack surface of vulnerable domains. The Let’s Encrypt and Alexa
domains have only a small overlap of 12K domains.
Let’s Encrypt
Alexa
Total
#Domains
1,014,056
856,887
1,858,165
#Nameservers
98,502
171,656
227,734
#ASes Vuln.
24.53%
8,205
20.92%
15,899