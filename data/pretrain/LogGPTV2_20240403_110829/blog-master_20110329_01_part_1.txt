## TOAST,The Oversized-Attribute Storage Technique - 暨存储格式main, extended, external, plain介绍    
### 作者                           
digoal                            
### 日期                            
2011-03-29                                                    
### 标签                                                                                                                                            
PostgreSQL , toast , TOAST_TUPLE_THRESHOLD , 阈值 , 存储选项 , main , plain , external , extended  
----                            
## 背景         
PostgreSQL的数据类型有哪些存储格式？  
如何存储超过一个数据块大小的数据呢？  
## 正文  
toast直接翻译的话就是切片面包(sliced bread)的意思，PostgreSQL中TOAST是一个缩写，全称是The Oversized-Attribute Storage Technique，为什么会有OVERSIZED-ATTRIBUTE呢？  
原因很简单，因为在PostgreSQL,一条记录不能跨PAGE存储，跨越PAGE的话必须使用TOAST（即unaligned,与原表分开存储）存储。  
TOAST表不能独立创建，只有当普通表包含了main,extended或external存储格式的字段时，系统会自动创建一个和普通表关联的TOAST表。  
当一条记录(tuple)在存储时(如果压缩的话算压缩后的大小)大于TOAST_TUPLE_THRESHOLD(通常是2kB)这个值时，会存储到TOAST表。  
而此时在普通表的该字段处包含了一个指向TOAST的tableoid和chunk_id的数据，从而能够找到该字段的记录。  
TOAST和普通的TABLE存储不太一样，TOAST表一般包含如下字段 :   
```  
 tableoid  -- TOAST表的OID  
 cmax  
 xmax  
 cmin  
 xmin  
 ctid  
 chunk_id  -- 普通表通过TOAST pointer把一个被TOAST的列关联到这里  
 chunk_seq -- 同一个chunk_id如果大于TOAST_MAX_CHUNK_SIZE，将被切片存储。这里存储切片后的序号。  
 chunk_data -- 真实的数据  
chunk_id + chunk_seq = primary key  
```  
并不是所有的字段都可以使用TOAST来存储，在PostgreSQL中字段(field)类型有定长的如int4,int8等,也有变长的字段类型如varchar,text等，变长的数据类型最大可以存储1GB的数据，这个可以从PostgreSQL的源代码得到证实，变长字段最多可以选择使用32BIT的列头,预留2BIT作为FLAG，还有30BIT存储字段长度2^30刚好等于1GB。  
具体的代码后面会有解释。下面来看一下存储格式。  
对于定长的字段类型，存储格式如下：  
```  
PLAIN   
prevents either compression or out-of-line storage; furthermore it disables use of single-byte headers for varlena types. This is the only possible strategy for columns of non-TOAST-able data types.  
```  
对于变长的字段类型，除了可以使用PLAIN格式，还可以使用如下存储格式：  
```  
EXTENDED   
allows both compression and out-of-line storage.   
This is the default for most TOAST-able data types.   
Compression will be attempted first, then out-of-line storage if the row is still too big.  
EXTERNAL   
allows out-of-line storage but not compression.   
Use of EXTERNAL will make substring operations on wide text and bytea columns faster (at the penalty of increased storage space) because these operations are optimized to fetch only the required parts of the out-of-line value when it is not compressed.  
MAIN   
allows compression but not out-of-line storage.   
(Actually, out-of-line storage will still be performed for such columns, but only as a last resort when there is no other way to make the row small enough to fit on a page.)  
```  
例如我们来创建一个测试表：  
根据前面的介绍，TOAST表只在有变长字段，并且存储为main,extended或external时才会创建。  
```  
digoal=> create table tbl_user (id int);  -- 这样的表是没有TOAST的。  
digoal=> select relname,reltoastrelid from pg_class where relname='tbl_user';  
 relname  | reltoastrelid   
----------+---------------  
 tbl_user |             0  
```  
原因很简单，定长类型以PLAIN存储。  
当其中有一个字段存储格式为main时，系统字段创建了一个OID=2066068的TOAST表。  
```  
digoal=> \d+ tbl_user  
               Table "digoal.tbl_user"  
 Column |  Type   | Modifiers | Storage | Description   
--------+---------+-----------+---------+-------------  
 id     | integer |           | plain   |   
digoal=> create table tbl_user (id numeric);  
digoal=> \d+ tbl_user  
               Table "digoal.tbl_user"  
 Column |  Type   | Modifiers | Storage | Description   
--------+---------+-----------+---------+-------------  
 id     | numeric |           | main    |   
digoal=> select relname,reltoastrelid from pg_class where relname='tbl_user';  
 relname  | reltoastrelid   
----------+---------------  
 tbl_user |       2066068  
```  
如何查找关联的TOAST表？  
这个前面已经介绍了。根据reltoastrelid 就可以关联到toast表.  
```  
digoal=> select relname from pg_class where oid=2066068;  
     relname        
------------------  
 pg_toast_2066065  
```  
如何获得字段大小？  
```  
digoal=> create table tbl_article (id int,author name,title varchar(256),content text);  
digoal=> \d+ tbl_article   
                      Table "digoal.tbl_article"  
 Column  |          Type          | Modifiers | Storage  | Description   
---------+------------------------+-----------+----------+-------------  
 id      | integer                |           | plain    |   
 author  | name                   |           | plain    |   
 title   | character varying(256) |           | extended |   
 content | text                   |           | extended |   
digoal=> select relname,reltoastrelid from pg_class where relname='tbl_article';  
   relname   | reltoastrelid   
-------------+---------------  
 tbl_article |       2066074  
```  
下面来插入一条测试记录(你可以使用repeat, generate_series, random() md5等函数产生较大记录，或者使用大对象接口导入大文件产生大字段) :   
```  
insert into tbl_article (id,author,title,content) values (1,'digoal.zhou','test','51.2. Index Access Method FunctionsThe index construction and maintenance functions that an index access method must provide are:IndexBuildResult *ambuild (Relation heapRelation,         Relation indexRelation,         IndexInfo *indexInfo);Build a new index. The index relation has been physically created, but is empty. It must be filled in with whatever fixed data the access method requires, plus entries for all tuples already existing in the table. Ordinarily the ambuild function will call IndexBuildHeapScan() to scan the table for existing tuples and compute the keys that need to be inserted into the index. The function must return a pallocd struct containing statistics about the new index.boolaminsert (Relation indexRelation,          Datum *values,          bool *isnull,          ItemPointer heap_tid,          Relation heapRelation,          IndexUniqueCheck checkUnique);Insert a new tuple into an existing index. The values and isnull arrays give the key values to be indexed, and heap_tid is the TID to be indexed. If the access method supports unique indexes (its pg_am.amcanunique flag is true) then checkUnique indicates the type of uniqueness check to perform. This varies depending on whether the unique constraint is deferrable; see Section 51.5 for details. Normally the access method only needs the heapRelation parameter when performing uniqueness checking (since then it will have to look into the heap to verify tuple liveness).The functions Boolean result value is significant only when checkUnique is UNIQUE_CHECK_PARTIAL. In this case a TRUE result means the new entry is known unique, whereas FALSE means it might be non-unique (and a deferred uniqueness check must be scheduled). For other cases a constant FALSE result is recommended.Some indexes might not index all tuples. If the tuple is not to be indexed, aminsert should just return without doing anything.IndexBulkDeleteResult *ambulkdelete (IndexVacuumInfo *info,              IndexBulkDeleteResult *stats,              IndexBulkDeleteCallback callback,              void *callback_state);Delete tuple(s) from the index. This is a "bulk delete" operation that is intended to be implemented by scanning the whole index and checking each entry to see if it should be deleted. The passed-in callback function must be called, in the style callback(TID, callback_state) returns bool, to determine whether any particular index entry, as identified by its referenced TID, is to be deleted. Must return either NULL or a pallocd struct containing statistics about the effects of the deletion operation. It is OK to return NULL if no information needs to be passed on to amvacuumcleanup.Because of limited maintenance_work_mem, ambulkdelete might need to be called more than once when many tuples are to be deleted. The stats argument is the result of the previous call for this index (it is NULL for the first call within a VACUUM operation). This allows the AM to accumulate statistics across the whole operation. Typically, ambulkdelete will modify and return the same struct if the passed stats is not null.IndexBulkDeleteResult *amvacuumcleanup (IndexVacuumInfo *info,                 IndexBulkDeleteResult *stats);Clean up after a VACUUM operation (zero or more ambulkdelete calls). This does not have to do anything beyond returning index statistics, but it might perform bulk cleanup such as reclaiming empty index pages. stats is whatever the last ambulkdelete call returned, or NULL if ambulkdelete was not called because no tuples needed to be deleted. If the result is not NULL it must be a pallocd struct. The statistics it contains will be used to update pg_class, and will be reported by VACUUM if VERBOSE is given. It is OK to return NULL if the index was not changed at all during the VACUUM operation, but otherwise correct stats should be returned.As of PostgreSQL 8.4, amvacuumcleanup will also be called at completion of an ANALYZE operation. In this case stats is always NULL and any return value will be ignored. This case can be distinguished by checking info->analyze_only. It is recommended that the access method do nothing except post-insert cleanup in such a call, and that only in an autovacuum worker process.voidamcostestimate (PlannerInfo *root,                IndexOptInfo *index,                List *indexQuals,                RelOptInfo *outer_rel,                Cost *indexStartupCost,                Cost *indexTotalCost,                Selectivity *indexSelectivity,                double *indexCorrelation);Estimate the costs of an index scan. This function is described fully in Section 51.6, below.bytea *amoptions (ArrayType *reloptions,           bool validate);');  
```  
```  
digoal=> select oid,relname,reltoastrelid from pg_class where relname='tbl_article';  
   oid   |   relname   | reltoastrelid   
---------+-------------+---------------  
 2066071 | tbl_article |       2066074  
digoal=> select pg_relation_size(2066071);  
 pg_relation_size   
             8192  
digoal=> select pg_relation_size(2066074);  
 pg_relation_size   
             8192  
```  
注意到，此时已经使用了TOAST，下面来从COLUMN_SIZE来证实一下（2485>TOAST_TUPLE_THRESHOLD 2KB）  
```  
digoal=> select pg_column_size(id),pg_column_size(author),pg_column_size(title),pg_column_size(content) from tbl_article;  
 pg_column_size | pg_column_size | pg_column_size | pg_column_size   
----------------+----------------+----------------+----------------  
              4 |             64 |              5 |           2485  
```  
换插一条比较短的记录，看看是否会用到TOAST？  
```  
digoal=> truncate table tbl_article;  
digoal=> select pg_relation_size(2066074);  
 pg_relation_size   
                0  
digoal=> select pg_relation_size(2066071);  
 pg_relation_size   
                0  
digoal=> insert into tbl_article (id,author,title,content) values (1,'digoal.zhou','test','test');  
digoal=> select pg_relation_size(2066071);  
 pg_relation_size   
             8192  
digoal=> select pg_relation_size(2066074);  
 pg_relation_size   
                0  
```  
很明显，TOAST未被使用，因为此时没有一个变长字段的长度超过2kB。  
```  
digoal=> select pg_column_size(id),pg_column_size(author),pg_column_size(title),pg_column_size(content) from tbl_article;  
 pg_column_size | pg_column_size | pg_column_size | pg_column_size   
----------------+----------------+----------------+----------------  
              4 |             64 |              5 |              5  
pg_column_size : bytes required to store the value, perhaps with compression  
```  
测试超长字段索引 :   
```  
insert into tbl_article (id,author,title,content) values (1,'digoal.zhou','test','此处省略1W字');  
digoal=> select pg_column_size(id),pg_column_size(author),pg_column_size(title),pg_column_size(content) from tbl_article;  
 pg_column_size | pg_column_size | pg_column_size | pg_column_size   
----------------+----------------+----------------+----------------  
              4 |             64 |              5 |              5  
              4 |             64 |              5 |           5075  
digoal=> create index idx_content on tbl_article (content);  
ERROR:  index row size 5088 exceeds maximum 2712 for index "idx_content"  
HINT:  Values larger than 1/3 of a buffer page cannot be indexed.  
Consider a function index of an MD5 hash of the value, or use full text indexing.  
```  
索引无法在超长字段上创建，有两处函数会报这个错。  
src/backend/access/nbtree/nbtsort.c  
src/backend/access/nbtree/nbtinsert.c  
```  
        /*  
         * Check whether the item can fit on a btree page at all. (Eventually, we  
         * ought to try to apply TOAST methods if not.) We actually need to be  
         * able to fit three items on every page, so restrict any one item to 1/3  
         * the per-page available space. Note that at this point, itupsz doesn't  
         * include the ItemId.  
         *  
         * NOTE: similar code appears in _bt_insertonpg() to defend against  
         * oversize items being inserted into an already-existing index. But  
         * during creation of an index, we don't go through there.  
         */  
        if (itupsz > BTMaxItemSize(npage))  
                ereport(ERROR,  
                                (errcode(ERRCODE_PROGRAM_LIMIT_EXCEEDED),  
                        errmsg("index row size %zu exceeds maximum %zu for index \"%s\"",  
                                   itupsz, BTMaxItemSize(npage),  
                                   RelationGetRelationName(wstate->index)),  
                errhint("Values larger than 1/3 of a buffer page cannot be indexed.\n"  
                                "Consider a function index of an MD5 hash of the value, "  
                                "or use full text indexing."),  
                                 errtableconstraint(wstate->heap,  
                                                                        RelationGetRelationName(wstate->index))));  
```  
BTREE索引长度限制，约为BLOCK_SIZE的1/3：  
src/include/access/nbtree.h  
```  
/*  