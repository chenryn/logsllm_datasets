### 优化后的文本

#### 数据摘要
- (96/3, 202.203/16): 5.4 (0/2, 202.203/16): 5.6
- (112/4, 202.192/12): 5.2 (64/2, 202.192/12): 9.0
- (0/1, 203.179.128/20): 6.0 (128/2, 202.203/16): 5.5
- (192/4, 202/8): 5.1 (*, 202.192/12): 25.5
- (16/4, 202/7): 5.4 (128/1, 202.128/9): 10.6
- (64/2, 202/7): 15.5 (128/1, 202/7): 17.7
- (163.229/16, 0/1): 6.0 (144/4, 128/1): 5.3
- (128/2, 96/3): 5.0 (128/3, 0/1): 5.3 (160/3, 128/1): 7.0
- (128/2, 0/2): 5.7 (128/2, 0/1): 11.4
- (128/1, 160/6): 5.0 (192/4, 128/2): 5.2
- (0/1, 128/2): 22.7 (*, 128/3): 7.1
- (202/7, 0/2): 5.4 (192/8, 128/1): 5.6 (202/8, 0/1): 5.7
- (202/7, 128/1): 6.0 (192/3, 200/5): 10.5
- (128/1, 112/6): 5.1 (112/5, 128/1): 21.8 (200/5, *): 17.0
- (192/4, 128/1): 13.6 (128/1, 16/4): 6.2 (*, 200/5): 42.4
- (64/3, 128/1): 6.0 (96/3, 128/1): 29.7
- (128/1, 64/2): 10.4 (0/1, 128/1): 46.7 (128/1, *): 53.3
- (*, 128/1): 78.3
- 6.7
- 5.2
- 33.1

#### 方法比较
SS方法由于其重叠汇总规则，报告了更多的HHH（共52个），导致总数量膨胀至6.84。尽管两种方法在定义（排序和汇总规则）上有所不同，但结果是可比的。两种方法在(1)-(9)项中具有相同的HHH，唯一的例外是(7)项，由于不同的汇总规则而有不同的百分比。仅由SS找到的HHH列在RLS对应祖先下的最右侧列中。在仅由SS发现的40个HHH中，35个属于区域(I)，4个属于区域(II)，1个属于区域(III)。大多数这些HHH具有非常短的前缀长度，对操作目的没有提供太多信息。尽管一些具有较长前缀，但由于重叠规则的双重计数，它们的相关（更具代表性的）HHH可以在RLS输出中找到（例如(8)对于(0/1, 203.179.128/20)）。总体而言，捕获重要的HHH对聚合顺序或汇总规则的细微差异不敏感。SS的重叠规则为逐位聚合生成冗长且重复的摘要，而RLS的简洁紧凑报告更好地满足了流量监控和异常检测的需求。

#### 性能比较
最后，我们在标准台式PC上（配备4核CPU（Intel Core-i7 3770K 3.5GHz）和16GB DRAM）比较了RLS和SS在字节级（5×5）和位级（33×33）聚合中的CPU时间和内存使用情况（见图5）。所有情况下，CPU时间随输入大小线性增长。对于RLS，字节级和位级之间的差异小于两倍，而对于SS则为70倍。RLS在字节级聚合上比SS快约两倍，在位级聚合上快约100倍。RLS可以处理超过每秒2M数据包的位级聚合，相当于10Gbps的平均数据包大小为512字节。RLS的内存使用量与输入大小成正比，因为它是一种非流算法，从缓冲所有输入开始，而SS使用固定大小的内存。然而，对于现代PC来说，几GB的内存使用量不是问题，如果需要，可以通过缩短聚合周期并重新聚合结果来生成摘要报告（如第5.3节所述）。

#### 实现
本节简要介绍与算法相关的实现。我们开发了一个基于HHH的流量监控工具agurim [12]，自2013年以来一直在监控WIDE [22]骨干网流量。Agurim广泛使用重新聚合。初步聚合通过高效处理原始流量数据（如pcap、NetFlow和sFlow）创建一个基本的聚合流列表。二次聚合对其自身的（初步和二次）输出进行重新聚合，以更新更粗略的小时和日记录。为了可视化时间序列，选择具有适当时间粒度的记录，并进一步重新聚合。用户可以在Web用户界面上根据流量体积或数据包计数、地址或协议属性，以及不同的时间和空间粒度动态切换视图。此外，我们还公开了匿名数据集，以便网络社区更广泛地访问骨干网流量 [3]。

#### IPv6和端口聚合
IPv6地址的低64位用于接口ID，因此不在[65, 127]范围内的部分不会被聚合。对于端口，虽然某些应用程序使用特定端口范围，但它们很少出现且通常被噪声淹没，因此我们只使用通配符进行聚合。

#### 两级HHH
在网络环境中，有两个层面是有意义的：一个是地址对，另一个是端口对。尽管HHH算法可以扩展到四个维度，但搜索空间随着维度呈指数增长。因此，agurim采用两级二维HHH：第一级为主属性对（源-目的地址），第二级为子属性对（源-目的端口）下的主属性对。Agurim允许交换主属性和子属性，以实现协议-端口视图，其中首先按端口对聚合流量，然后在每个端口对内按地址对聚合。

#### 协议特定启发式
RLS允许通过限制递归深度来控制部分层次结构的聚合粒度。利用协议特定知识，我们添加了启发式方法，以抑制对操作不太有用的条目并生成简洁的摘要。对于IPv4，当前缀长度小于16时，将粒度从д = 1减少到д = 8，以避免产生短前缀长度的HHH。类似地，对于IPv6，当前缀长度小于32时，将粒度减少到д = 16。此外，前缀长度...

#### 在线处理
我们的初衷是将RLS用于agurim的二次聚合，其输入数量有限。然而，我们发现RLS足够快，可以用于初步聚合，并且使用相同的算法使代码更简单，输出更一致。对于在线处理，我们采用多线程和双缓冲技术来利用多核CPU；一个线程不断读取原始输入，在聚合周期结束时切换输入缓冲区，并唤醒另一个线程，该线程聚合缓冲区中的输入并生成摘要报告。

目前agurim的瓶颈不是聚合算法，而是维护输入的成本。我们使用哈希表来跟踪输入数据包的5元组。哈希表越大，搜索成本越高。为了控制哈希表中的输入数量并减少内存使用，用户可以选择设置聚合周期为总结周期的一部分。然后，输入数据在较短的周期内（例如每3秒）进行聚合，并通过重新聚合中间结果在较长的周期内（例如每30秒）生成摘要。同样的技术也用于DoS防护；当缓存的数据包数量超过预定义限制时，会触发早期聚合。

#### 结论
本文介绍了一种新的高效HHH算法。我们的关键见解是重新审视常用的HHH定义，并应用Z-ordering以利用递归分区算法。Z-order使排序与层次结构中的祖先-后代关系一致，并将HHH问题转化为四叉树的空间划分。所提出的算法生成简洁紧凑的摘要，捕捉HHH，满足我们的操作需求，并在位级聚合上比现有方法快几个数量级。

这项工作是我们为流量监控和网络研究提供实用工具和数据集的持续努力的一部分。所提出的算法已集成到我们的流量监控工具中，并用于实际操作。该工具的源代码连同自2013年起的开放纵向数据集可在网页上浏览 [4]。

#### 致谢
感谢Midori Kato和Arthur Carcano对agurim开发的贡献，感谢Yuji Sekiya和Ryo Nakamura的操作支持。我们还要感谢Kensuke Fukuda、Romain Fontugne、匿名IMC审稿人以及我们的指导者John Byers对论文的宝贵反馈和评论。

更多详细信息，请参阅 http://mawi.wide.ad.jp/~agurim/about.html。

#### 图5: 性能比较：RLS vs. SS
(a) CPU时间
(b) 内存使用

#### 参考文献
[此处列出参考文献]

---

希望这能帮助你更清晰、连贯和专业地表达你的内容。如果有任何进一步的修改需求，请告诉我！