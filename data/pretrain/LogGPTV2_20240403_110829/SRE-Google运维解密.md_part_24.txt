<103
---
## Page 132
105
104
监控
在应急事件处理中，由于压力很大，很多情况下人们急于解决问题，会绕开必要的流程。
在第12章中，我们提供了一套结构化方案来解决问题的第一步：找到问题所在。
和团队相关的。但是如何有效地应对紧急问题的方法论是每个团队都适用的。
导向其他没有问题的任务实例等手段暂时缓解问题。解决方案的细节肯定是和每个服务
题一次性修复好，而可以靠降低系统准确度、关闭一些不重要的功能，或者将用户流量
一旦SRE发现了系统中存在的问题，要如何解决呢？正确的解决方案不一定是当场把问
细解释我们是如何平衡on-call轮值与其他工作的。
可以找到一种方式使得值班不再必要，SRE肯定会第一时间采用。在第11章中，将详
经常参与轮值有助于每一个SRE了解和熟悉大型分布式计算系统的失败模式。如果我们
SRE并不是为了on-call值班而值班，on-call值班只是我们实现服务目标的一种工具。
应急事件处理
之前发现系统中存在的问题。在第10章将讨论有关警报系统的设计哲学和工具。
周全的监控体系就如同蒙着眼睛狂奔。作为一个合格的系统运维人员，我们需要在用户
离开了监控系统，我们就没有能力辨别一个服务是不是在正常提供服务。没有一套设计
图川I-1：服务可靠度层级模型
事后总结/问题根源分析
应急事件处理
测试+发布
容量规划
软件开发
产品设计
监控
---
## Page 133
和部署一个跨数据中心的定时任务系统的。
的新说法），例如全球分布式定时任务系统。在第24章中，我们描述了SRE是如何设计
在第23章中，我们解释了Google许多系统的核心组件一
Google SRE模型的要点之一就是SRE一半的精力都花在设计和开发大规模软件系统上。
软件研发
最后，在第22章中，我们讨论了如何从系统设计层面与战术层面应对“连锁故障”。
在第18章中，我们给出了一个具体的工具开发实践案例。SRE利用Google 内部工具
容量规划
过增加测试，保证软件在发布到生产环境中时不会出现某些类型的问题。在第17章中
当我们发现经常出现问题的组件或者流程时，下一步就是如何避免它再次发生故障。通
测试
用该系统跟踪最近发生的生产事故、原因以及解决的具体过程。
第16章，在这个基础上，我们简要描述了一个内部工具，事故跟踪系统。SRE团队使
才能有效了解到在一次事故中哪些地方出现了问题（以及哪些地方做得非常好）。
第15章，描述了如何建立起“无指责”、“对事不对人”的团队文化，只有做到这一步，
下面两章详细描述了这个主题。
样的问题简直太无聊了。事实上，这个理念是SRE和传统运维团队理念中最大的不同点。
我们的目标是接收警报，然后人工解决新的、
事后总结和问题根源分析
以缓解整个部门由生产事故带来的压力。
在第13章和第14章中，我们讨论了如何通过合理的流程有效地减小事故的影响范围，
详细描述了数据中心中的负载均衡体系是保障服务可靠度的关键。
19章中，我们讨论了用户请求是如何发送到数据中心的。在第20章和第21章中，我们
容量规划后，我们还需要保证合理的负载均衡体制能够正确地使用这些服务容量。在第
Auxon,
详细描述了相关的最佳实践。
自动化进行服务容量规划。
、有挑战性的服务问题。反复不断地修复同
“分布式共识”系统（Paxos
106
---
## Page 134
容量规划，有时候经常被说成是一种通过大量神奇的表格进行的黑魔法。但是通过文献
在一篇ACM论文中（参见文献[Kril12]），我们解释了Google是如何通过全公司的灾难
难演习）是非常困难的。如果测试的方法不对，甚至会对整个服务的可靠性带来影响。
如前文所述，有效的测试（这里的测试同时指软件层面的测试，也指流程、组织上的灾
扩展阅读
好的用户体验的。
们解释了Google是如何改进产品设计，以确保全球用户在产品上线第一天起就拥有最
最后，在第27章中，
产品设计
安全地读取回来。
在第26章中，我们详细描述了数据一致性的重要性，如何确保之前存储的数据可以被
数据处理系统。不同的系统架构可带来不同的新奇与反直觉的挑战。
第25章描述了批量数据处理系统的几种形态：从定时运行的MapReduce程序，到实时
网络设计的时候，可以试验一下这种方式。
在逐步将有高权限的内网验证替换为使用用户设备和用户身份验证。当读者进行下一个
最终，文献[War14]描述了Google的一种新的网络安全方法论。通过这项计划，我们正
见未来的能力。
[Hix15a]中的这篇文章，我们详细描述了正确地进行容量规划并不一定需要用水晶球预
演习来确保公司可以在大型灾难发生时正常工作的。
，我们描述了处于整个可靠度金字塔模型顶端的产品设计理念。我
---
## Page 135
译注1寻呼机Pager，最原始的报警通知设备。
时间分布情况）。这类更高级的抽象指标可以帮助我们寻找导致延迟长尾效应的问题所
均响应时间），还需要分析更高抽象级别的指标（例如整个欧洲地区Web服务器的响应
监控一个大型系统本身是一项非常具有挑战性的工作：
期负责保障Google生产环境的运维，对支撑监控系统的基础设施非常了解。
不管一个服务目前是否由SRE运维，该服务都应该建立起对应的监控系统。SRE由于长
6章）。
应对紧急情况。同时，监控数据也可以用来确保服务质量与产品目标保持一致（参见第
可缺少的部分。服务运维人员依靠监控数据对服务的情况做出理性判断，用科学的方法
监控，处于整个生产环境需求金字塔模型的最底层。监控是运营一个可靠的稳定服务不
·大型系统中组件数量特别多，分析工作繁杂繁重。
让查询来得更猛烈些吧，让寻呼机详注！永远保持沉默！
）监控系统本身的维护要求必须非常低。
基于时间序列数据进行有效报警
作者：JamieWilkinson
编辑：Kavita Guliani
第10章
-SRE谚语
107
---
## Page 136
109
108
作为报警规则的计算元素。
为数据收集过程不再是一个短暂的一次性过程，所有收集回来的数据历史都可以被用来
收集回来的数据同时用来渲染图表和报警。报警规则用简单的数学表达式形式表达。因
Borgmon不使用特定的脚本来判断系统是否正常工作，而是依靠一种标准数据分析模型
造了一个新的监控系统，Borgmon。
在Google的任务管理系统Borg（参见文献[ver15]）2003年面世之后不久，工程师就创
Borgmon的起源
用该语言将数据转化为图表和报警取代了以前的探针脚本。
信息作为监控系统的首要任务，同时发展了一种丰富的时间序列信息操作语言，通过使
且报警）与图形化趋势展示的模型已经演变为一个新模型。这个新模型将收集时间序列
Google的监控系统经过10年的发展，从传统的探针模型（使用脚本测试，检查回复并
可以追踪到某个具体组件。
况。监控系统应该主要从高级服务质量目标层面进行报警，但是也应该保持足够的粒度
关注其中使用的无数个小组件，而是应该自动汇总所有的信息，自动抛弃其中的异常情
的系统使其能够更好地应对所依赖系统的故障。一个大型系统不应该要求运维人员持续
警发生的次数太频繁，没有任何可操作性。我们采用的是另外一套方法：设计我们运维
在我们这种系统部署规模下，任何一个单机问题的报警都没有任何意义，因为这样的报
6
关“白盒监控”和“黑盒监控”的对比）。
的子进程以及建立特殊的网络连接。我们将这种监控称之为白盒监控（参见第6章，有
进行报警。这就使得批量、大规模、低成本的数据收集变得可能，而且不需要执行复杂
望借助这些工具，读者可以自行试验、部署本章内描述的一些想法。
的规则计算语法时。变量收集和规则计算的理念在所有这些项目中都很类似。
据报警理念类似的系统。Prometheus注1与Borgmon十分类似，尤其是当你对比其中
Riemann、
近年来，
一定想知道在Google外部如何使用它呢？
这一章描述了Google内部使用了10年的监控工具的架构和编程接口。但是读者们
Prometheus是一个开源时间序列数据库，
第10章
：Heka、Bosun、Prometheus 都是开源软件中与 Borgmon 基于时间序列数
监控系统也经历了一次类似神武纪生物系统大爆炸的爆发式增长
基于时间序列数据进行有效报警
Google之外的时间序列监控系统
详细信息请参见http://prometheus.i。
---
## Page 137
需要人工重新修改在Borgmon规则中的定义）。在实际使用中，我们开发了一个工具，
护相关改动（很容易发生的情况就是应用程序删除了某些指标，或者改变了具体含义，
种妥协。监控指标的定义与Borgmon中对监控指标的使用分离意味着需要有人小心地维
别低，这对SRE和软件研发部门来说都是好事。但是，这同时也是对可维护性做出的一
不难看出，采用这种无格式的文本形式作为监控的接口使得增加新监控点的门槛变得特
增加一个监控指标只需要在具体服务程序中增加一行代码声明。
http_responsesmap:code200:25404:0500:12
500响应。
增加标签（label）。例如下面这个例子，展示了25个HTTP200响应，以及12个HTTP
格式是空格分隔的键值对。随后，又增加了一种Map格式，允许应用程序在键值对上
/varz这个HTTP接口只是用文本方式每行一个地列出应用中所暴露的全部监控变量值
应用软件的监控埋点
一些部署规模非常大的服务甚至在集群内部部署了一些专门收集信息的Borgmon实例
内再运行两个对等的Borgmon实例。
信息。一般来说，运维团队在每个集群中会运行一个Borgmon实例，在全球范围（global）
署模型类似的层级体系。这样我们就可以逐级汇总监控指标，同时在每一级抛弃无用的
errors_total 12
http_requests37
%curlhttp://webserver:80/varz
看webserver的所有监控指标，可以使用如下命令：
一次HTTP请求，我们就可以收集到一个监控对象的所有监控指标。例如，如果想要查
为了更好地进行批量收集工作，我们为监控指标制定了一个标准格式。利用对varz注2的
系统的调整。
从而可以保障运维服务人员有精力和资源应对服务规模的扩大以及部署变更带来的监控
这些功能满足了第6章提到的简单性要求。它们使得整个监控系统的运行维护成本很低，
译
scraper),
3
2Google是美国公司，所以varz的发音是“var-zee”
运行在某一个集群（物理）中，如果只运行一个，可能会受到单点故障的影响。
这些实例用于收集信息，而集群实例则用于汇总。
这和sheep一
译注2
通常运行两个对等的实例是因为全球实例（逻辑）也要
一样
应用软件的监控埋点