∗
])].
∗
]);
The protocol run is accepted by the parties, if the agreements suc-
ceed.
The POR Protocol.
In the OPOR model, the auditor A and the provider S run a
POR protocol to convince the auditor that M∗ is still retrievable
from S. The input of A is the tag τA given by Store, and the input
of the provider S is the stored copy of the ﬁle M∗. Similar to the
traditional POR model, on the auditor’s side (who plays the role
of the veriﬁer), the output contains one binary value decA which
expresses whether the auditor accepts the POR or not. In addition,
the POR protocol will produce a log ﬁle Λ. It holds that:
] −→ [A : Λ, decA]
[A : τA; S : M
POR :
∗
The protocol run is accepted by the auditor if decA = TRUE.
The CheckLog Algorithm.
In an OPOR, the POR protocol only convinces A that M∗ is
still retrievable. The CheckLog protocol enables U to audit the
auditor. CheckLog is a deterministic algorithm which takes as input
the veriﬁcation key τU and a log ﬁle Λ and outputs a binary variable
decΛ which is either TRUE or FALSE, indicating whether the log
ﬁle is correct. Formally:
decΛ := CheckLog(τU , Λ).
The ProveLog Algorithm.
ProveLog is a deterministic algorithm which complements the
CheckLog procedure to ensure the correctness of the auditor in
case of conﬂicts. In fact, if the CheckLog algorithm provides cer-
tainty about the correctness of the auditor, ProveLog is not neces-
sary. Otherwise, ProveLog can without doubt prove or disprove the
honesty of A as it has access to the secret information of A. The
algorithm ProveLog takes as input the tag τA of the auditor and
a log ﬁle Λ and outputs a binary variable deccorr
Λ which is either
TRUE or FALSE, indicating whether the POR protocol run that
produced the log ﬁle has been correctly executed by the auditor.
Formally:
deccorr
Λ
:= ProveLog(τA, Λ).
Correctness.
The deﬁnition of correctness requires that if all parties are hon-
est, then the auditor always, i.e., with probability 1, accepts at the
end of each POR protocol run and likewise the user at the end of
each CheckLog protocol run. This should hold for any choice of
key pairs and for any ﬁle M ∈ {0, 1}∗. Likewise, if the POR pro-
tocol has been executed correctly by the auditor based on τA and
yielded an output Λ, then the output of ProveLog(τA, Λ) should
be TRUE with probability 1.
2.3 Security Model
In the following, we explain how security is deﬁned within the
OPOR model. We do not consider conﬁdentiality of the ﬁle M, but
assume that the user encrypts the ﬁle prior to the start the OPOR
protocol. In OPOR, we extend the attacker model of traditional
POR which only considers malicious service providers, and we as-
sume that any subset of parties can be corrupted.
To deﬁne the soundness of an OPOR scheme, we adapt and ex-
tend the existing POR security models of [24, 35]. In [24, 35], se-
curity is formalized using the notion of an extractor algorithm, that
is able to extract the ﬁle in interaction with the adversary. This
proves the following statement: if the prover convinces the veriﬁer
with a sufﬁcient level of probability then the ﬁle is actually stored.
As already elaborated, the notion of extractability is not sufﬁcient
to capture security in OPOR schemes. In addition, an OPOR also
should provide security to the auditor A, who is taking over guaran-
tees about the service quality of S. In contrast to the POR security
models, this is especially important in situations where something
went wrong, e.g., the ﬁle has been lost. Consequently, we split the
deﬁnition of soundness into two parts: soundness if no honest party
aborts (we call this ε-extractability) and soundness for the case that
one honest party aborted (what we refer to as (δ1, δ2)-liability).
Extractability. We start by describing the case where none of the
honest parties aborts. More precisely, the honest parties interact
with malicious parties. Recall that the ProveLog procedure is only
invoked if one of the parties aborted and hence does not contribute
to the notion of extractability. Consider the following experiment
between an adversary who corrupted the parties speciﬁed in C (cid:40)
{U,A,S} and an environment.
1. Initially, the environment runs the Setup protocol on behalf
of all parties and generates the public and private keys. All
public keys and the secret keys of the corrupted parties C are
given to the adversary.
2. The environment plays the roles of the honest parties and the
adversary simulates the roles of the corrupted parties. The
adversary is allowed to request executions of Store for any
ﬁle M ∈ {0, 1}∗. Likewise, he can request the execution
of POR or CheckLog for any stored ﬁle, that is for any ﬁle
that has been input to a previous Store execution.
In the
protocols, the environment will play the role of honest parties
and the adversary the role of the corrupted parties C. The
adversary learns only the output provided to corrupted parties
and whether the honest party accepted.
3. Finally, the adversary outputs a ﬁle M to challenge the envi-
ronment with and the description of a machine implementing
the role of the malicious parties for this ﬁle.
Observe that this game differs from the game described in tradi-
tional POR models in several aspects. First, it inherently incorpo-
rates the fact that several parties can be compromised and that the
attacker can initiate also other protocols. Second, the output is not a
description of an attacker for a ﬁle that has been stored already but
for a ﬁle that should be stored. In other words, this game also cov-
ers the case that an attacker tries to cheat during the Store protocol
already.
An attacker is ε-admissible if the probability that none of the
honest parties aborts is at least ε. Here, the probability is over the
coins of the honest and malicious parties. For the deﬁnition of se-
curity, we adopt the concept of extractors. An extractor algorithm
Extr takes the values of the honest parties, e.g., their private keys
and tokens, and the description of a machine implementing the role
of the malicious parties in the OPOR system. The algorithm’s out-
put is a ﬁle M ∈ {0, 1}∗. Note that Extr is given non-black-box
access to the machine implementing the corrupted parties and can,
in particular, rewind them.
DEFINITION 1. We say that an OPOR scheme is ε-extractable
with respect to a set of corrupted parties C if there exists an extrac-
tion algorithm such that, for any algorithm corrupting the parties in
C and playing the aforementioned game, outputs an ε-admissible
attacker Z, the following holds:
for any honest party that has
an agreement for some ﬁle M∗, the extraction algorithm recovers
M∗—except possibly with negligible probability.
Naturally, if S is honest, Extr has the providers view as input
and can trivially extract M∗ already from its input. For the other
two parties, the notion adapts the notion of extractability.
Liability. Next, we address the security deﬁnition for the case that
one honest party aborts. Let us a call an auditor who generated
all values occurring in the protocols (including the generation of
τA during Setup and the creation of the challenges during POR)
according to the protocol speciﬁcations as well-behaving. If an au-
ditor is not well-behaving, he is misbehaving. We want that any
well-behaving auditor can prove that the log ﬁles are correct with
a high probability while a misbehaving auditor should achieve this
with a certain (preferably small) probability only. As this notion is
motivated by potential legal issues between the user and the audi-
tor, liability is only deﬁned with respect to a set of corrupted parties
that does not include the user and the auditor. We formalize this as
follows:
DEFINITION 2. We say that an OPOR scheme is (δ1, δ2)-liable
with respect to a set of corrupted parties C with {U,A} (cid:54)⊆ C if the
following holds. Let Z be an algorithm that corrupts the parties
in C and plays the aforementioned game. Let M denote a ﬁle that
has been the input to one Setup execution and let τA denote the
output for the auditor of this Store execution and L be the set of all
log ﬁles which have been created afterwards based on the outputs
of these speciﬁc Store execution. Then, it holds for any randomly
selected log ﬁle Λ ∈ L that Pr[ProveLog(τA, Λ)] = TRUE] ≥ δ1
if the auditor has been well-behaving in the protocol executions
associated to M and Pr[ProveLog(τA, Λ)] = TRUE] ≤ δ2 if the
auditor has been misbehaving.
Relation to the POR Model of Shacham and Waters. The pro-
posed OPOR extends the POR model in [35]. In particular, any
POR scheme Π with two parties, a veriﬁer and a prover, can be
expressed as an OPOR scheme Π(cid:48) where the user and the audi-
tor emulate the same party, namely the veriﬁer, while the service
provider plays the role of the prover. If Π is ε-sound within the
POR model, then Π(cid:48) provides ε-extractability within the OPOR
model if only the service provider is corrupted. Note, however,
that since Π does not specify a ProveLog procedure, liability is not
automatically ensured in Π.
3. FORTRESS: AN EFFICIENT OPOR
In this section, we introduce and detail an efﬁcient instantiation
of OPOR. We analyze the security of our instantiation according
to the model outlined in Section 2.
3.1 Overview
Fortress builds upon the private-key unbounded1 POR scheme
of [35] (that we shortly call PSW in the sequel) which minimizes
bandwidth overhead, and maximizes performance/scalability. We
chose to rely on SW-POR as a starting point for Fortress (instead
of any other POR or PDP) based on two properties that are exhib-
ited by the SW-POR and that facilitated the transformation into an
OPOR: (i) since the setup phase uses only algebraic operations, the
correctness of the setup parameters can be shown via a standard
zero knowledge proof, and (ii) the produced proofs are also ho-
momorphic, allowing the user to batch the veriﬁcation of several
proofs. We however expect that other POR/PDP schemes can be
transformed into OPOR as well and leave it as an interesting ques-
tion for future research. Note that a straightforward approach to
achieve an OPOR would be to simply let the auditor instantiate all
protocol parameters (e.g., secret keys, veriﬁcation tags, etc.), and
conduct the PSW regularly with the service provider. In the pres-
ence of a malicious service provider, this approach would inherit
the same security guarantees as already proven for PSW. However,
this straightforward solution does not protect against a malicious
user, and/or a malicious auditor. In fact, to transform a secure POR
into a secure OPOR, we argue that a number of challenges need to
be addressed:
Malicious Auditor. Existing POR rely on the assumption that the
veriﬁer is honest. As such, these POR cannot be directly
ported to an OPOR setting, where the auditor might deviate
from the protocol, and/or collude with the service provider.
For example, a malicious auditor may share the secret key
with the service provider so that both can produce correct
POR without having to store the ﬁle at all. In fact, the re-
quirement of security against malicious auditors is often one
of the main reasons why existing private-veriﬁable schemes
cannot be outsourced by simply handing the secrets to the
auditor (see Appendix B for some examples).
Auditing the Auditor. Although users should not be involved in
verifying the retrievability of their ﬁles, OPOR should en-
able users to audit the auditors. Clearly, for an OPOR scheme
to be effective, such an audit should be much less frequent
and considerably more efﬁcient than the act of verifying the
ﬁles stored at the cloud. Note, however, that verifying the
POR response typically requires the knowledge of the secret
keys; if these keys are known to the user, a malicious user
could reveal this key to a malicious service provider. Hence,
one requires that the auditor can be audited to some extent—
without revealing his secret keys.
Auditor Liability. Since the auditors want to minimize their lia-
bility, an OPOR scheme should (i) protect the auditors from
1For practical purposes, an OPOR scheme should support an un-
bounded number of queries by an external auditor – without the
need for user interaction.
malicious users, and (ii) enable auditors to attest to any party
that they did their work correctly, in case of dispute or litiga-
tion. This entire process should be efﬁcient, and should scale
with the number of the auditor customers.
Parameter Generation. A POR depends on several parameters.
To achieve auditor liability, an auditor needs to be able to
convincingly prove later on that these parameters have been
constructed correctly—even if the ﬁle is no longer present.
Challenge Sampling. In the third phase of a POR, the veriﬁer is
typically required to construct a number of challenges (e.g.,
some randomly sampled ﬁeld elements as in PSW). Clearly,
these challenges cannot depend only on any of the involved
three parties (the cloud, the user, and the auditor) since they
might be malicious; note that interactive sampling among
two parties would not solve this problem (since any two par-
ties might collude), and would require user interaction. This
problem is further exacerbated by the fact that the challenges
cannot be pre-deﬁned, e.g., by agreeing some seed of a pseudo-
random bit generator since a malicious auditor might pre-
share all the challenges to be queried with a malicious provider.
Indeed, the latter can then compute the necessary replies to
those challenges and delete the ﬁle, while answering cor-
rectly to all POR.
The core idea in Fortress (see Figure 1) to overcome the ﬁrst two
challenges is to require that the auditor conducts two POR in par-
allel with the service provider: one POR which can be veriﬁed by
the auditor himself, and another one which can optionally be veri-
ﬁed by the user (who has the right cryptographic keys). Upon the
completion of each POR, the auditor logs the responses of the ser-
vice provider, and the parameters used to conduct the two POR
(e.g., block indices used at challenge). This second POR protects
on the one hand against malicious auditor/service provider and al-
lows for auditing the auditor. Here, Fortress enables the user to
efﬁciently verify in a single batch a number of conducted POR
to verify the work of the auditor. This minimizes communication
overhead while achieving the same level of security and efﬁciency
as in PSW.
However, an auditor could still cheat, e.g., by using wrong pa-
rameters or by biasing the challenge sampling process according
to some strategy. To ensure correct parameter generation, Fortress
relies on a sub-protocol which guarantees that the parameters com-
puted by the auditor in the beginning have been correctly generated
without revealing his secret parameters.
Moreover, to ensure a truly (pseudo-)random sampling of the
challenges, Fortress exploits the fact that any randomized algorithm
can be rewritten as a deterministic algorithm where the random bits
are provided as additional input. The idea is to deprive the audi-
tor from the right to sample these random bits and to extract them
from an external source. To this end, Fortress leverages function-
ality from Bitcoin in order to provide a time-dependent source of