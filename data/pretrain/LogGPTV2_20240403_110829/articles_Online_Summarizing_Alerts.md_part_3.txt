Theword-embedding-basedapproachsimplysumsupembedding ğ’Šğ’Š ğ’Šğ’Š
ğ’—ğ’—ğ’ğ’ğ’Šğ’Š ğ’–ğ’–ğ’ğ’ğ’Šğ’Š
resultsofwordsinanalert,neglectingvaryingcontributionsof
words to the overall semantics. The topic-distillation-based ap- CBOW IDF
proachonlydistillsthegeneraltopicofthealert,whicharetoo
crudetocapturedistinctivesemanticdetails.
Torepresentthealertsemanticinformation,weproposeASR alert content words
(AlertSemanticsRepresentation),whichextractsthecompletealert ğ‘¾ğ‘¾ğ’Šğ’Š
semanticsbasedontherespectivesemanticcontributionofeach Figure3:Theprocessofrepresentingthesemanticinforma-
wordinthealertcontent.Forwordsinthealertcontent,ASRfirst tionofthealert.
minesthecontextualinformationofeachword,andthencalculates
thecontributionofeachwordtotheoverallalertsemantics.Finally,
ASRaggregatesthecontextualinformationofalertwordsaccording Inthetrainingstage,weseparatelytrainCBOWandIDFby
totheircontributionstotheoverallalertsemantics.Therefore,the contents in history alerts. Then, as shown in Figure 3, we can
keyissueishowtominethecontextualinformationofthealert straightforwardlyextractthesemanticrepresentationforanalert.
ICSEâ€™22,May21â€“29,2022,Pittsburgh,PA,USA JiaChen,PengWang,andWeiWang
Foreachwordinthealert,ğ‘’ ğ‘– (1â‰¤ğ‘– â‰¤ğ‘›),wegetthecontextualin- resultofğ¹ ğ‘–,Equation(3)measuresthedifferencebetweenğ¹ ğ‘–â€²andğ¹Ë† ğ‘–.
formationofthewordbyCBOW,denotedasğ‘£ğ‘– ğ‘— (1â‰¤ ğ‘— â‰¤ğ‘™ ğ‘–),andthe Aftertraining,theresultofthehiddenlayerintheneuralnetwork,
semanticcontributionofthewordbyIDF,denotedasğ‘¢ğ‘– ğ‘—.Itshould denotedasğ‘ ğ‘–,isabletoreservethecommonbehaviorinformation
benotethatinordertoensure(cid:205)ğ‘™ ğ‘—ğ‘– =1ğ‘¢ğ‘– ğ‘— =1,ğ‘¢ğ‘– ğ‘—isnormalized.Atlast, betweentheoccurrencesseriesofğ‘’ ğ‘– anditscorrelatedalerts.
accordingtoEquation(1),wecanaggregatethesemanticsofwords (cid:213)ğ‘ğ‘–
inthealertcontenttoobtainthecompletesemanticrepresentation ğ¹Ë† ğ‘– = ğ¹ ğ‘Ÿğ‘– (2)
ğ‘—
ofthealert,denotedasğ‘  ğ‘–. ğ‘—=1
ğ‘›
=(cid:213)ğ‘™ğ‘– ğ¿ ğ´ğµğ‘… =âˆ’(cid:213) ğ‘–=1ğ‘™ğ‘œğ‘”( 1+ğ‘’ğ‘¥ğ‘(1 ğ‘–)) (3)
ğ‘  ğ‘– (ğ‘£ğ‘– ğ‘— Â·ğ‘¢ğ‘– ğ‘—) (1) âˆ’ğ¹ ğ‘–â€²Â·ğ¹Ë†
ğ‘—=1
6 ALERTCORRELATION
5.2 BehaviorRepresentation
WithASRandABR,wecanrepresentthesemanticinformation
Inadditiontosemantics,alertsbelongingtothesamesystemfailure andthebehaviorinformationofthealert,respectively.Wethus
usuallyalsohavecommonbehaviorinformation.Miningfrequent proposeamodel,ACT(AlertCorrelaTion),tomeasurethecorre-
patternsisawidelyusedapproachtocapturebehaviorcorrelations lationbetweenalertsbyaggregatingthesemanticandbehavior
betweenalerts[10,12,28].Becausefrequentpatternsindicateco- representationsofthealert.BeforeformallyintroducingACT,letâ€™s
occurrencecorrelationsbetweenalerts.Inpractice,however,some consideramotivatingquestion,fortwoalertsğ‘’ 1andğ‘’ 2,whenboth
alerttypeshavequitelowfrequenciestowhichfrequentpattern theirsemanticandbehaviorrepresentationsaresingle-dimensional,
miningapproachisnotapplicable. howtodetermineiftheyarecorrelated.Generally,forthesemantic
Torepresentthealertbehaviorinformation,weproposeABR representationsofğ‘’ 1andğ‘’ 2,thedifferencebetweenthemshouldbe
(AlertBehaviorRepresentation),whichforthefirsttimelearnsthe lessthanathreshold,andthesameistrueforthebehaviorrepresen-
commonalitybetweenalertoccurrenceseries.ABRisinspiredby tations.Formally,wedefineasimpleauxiliaryfunction,ğ‘“ ğ‘‘ğ‘–ğ‘ (ğ‘¥,ğ‘¦,ğ‘§),
thewordembeddingmodel,Skip-Gram[19].Skip-Gramcaptures inEquation(4),whichfirstcalculatesthesquaredifferencebetween
the common semantics between a target word and its adjacent ğ‘¥ andğ‘¦,andmeasurethedifferencebetweenthesquaredifference
wordsviaashallowneuralnetwork,whichconvertstheencod- andğ‘§.Therefore,ifğ‘’ 1andğ‘’ 2arecorrelated,bothğ‘“ ğ‘‘ğ‘–ğ‘ (ğ‘  1,ğ‘  2,ğ‘¡â„ğ‘Ÿğ‘‘ 1)
ingofthetargetwordtotheencodingofitsadjacentwordsina andğ‘“ ğ‘‘ğ‘–ğ‘ (ğ‘ 1,ğ‘ 2,ğ‘¡â„ğ‘Ÿğ‘‘ 2)arepositive,whereğ‘¡â„ğ‘Ÿğ‘‘ 1andğ‘¡â„ğ‘Ÿğ‘‘ 2arethe
linearfashion.Similarly,asshowninFigure4,ABRtrainsashal- thresholdsforthesemanticdifferenceandthebehaviordifference,
lowneuralnetworktoconvertstheoccurrenceseriesofatarget respectively.Identically,toensureğ‘’ 1andğ‘’ 2arecorrelated,wecan
alerttotheoccurrenceseriesofitscorrelatedalerts.Asaresult, getğ‘Ÿğ‘’ğ‘™ğ‘¢(ğ‘“ ğ‘‘ğ‘–ğ‘ (ğ‘  1,ğ‘  2,ğ‘¡â„ğ‘Ÿğ‘‘ 1))Ã—ğ‘Ÿğ‘’ğ‘™ğ‘¢(ğ‘“ ğ‘‘ğ‘–ğ‘ (ğ‘ 1,ğ‘ 2,ğ‘¡â„ğ‘Ÿğ‘‘ 2)) >0.
thetrainedneuralnetworkcancapturetheunderlyingcommon
behaviorinformationbetweenalerts. ğ‘“ ğ‘‘ğ‘–ğ‘ (ğ‘¥,ğ‘¦,ğ‘§)=ğ‘§âˆ’(ğ‘¥âˆ’ğ‘¦)2 (4)
ACT,showninFigure5,isageneralizationoftheabovemoti-
hidden layer
vatingexampleinamulti-dimensionalsituation.Fortwoalerts,
ğ‘’ ğ‘– andğ‘’ ğ‘— (1 â‰¤ğ‘–,ğ‘— â‰¤ğ‘›),inspiredbytheaboveexample,ACTfirst
calculatesthesquaredifferencebetweeneachdimensionofeach
ğ’Šğ’Š
ğ‘­ğ‘­ğ’“ğ’“ğ‘·ğ‘· typeofalertrepresentations.Forthesemanticrepresentation,the
SUM ğ‘­ğ‘­ğ’“ğ’“. .ğ‘·ğ‘·ğ’Šğ’Š r re es su ul lt ti is sd de en no ot te ed da as sğ‘  ğ‘ğ‘– ğ‘–, ,ğ‘— ğ‘—, .a In nd abfo or vt eh ee xb ae mh pa lv ei ,o ğ‘“r ğ‘‘r ğ‘–ğ‘ e (p ğ‘ r 1e ,s ğ‘ e 2n ,ğ‘¡t â„a ğ‘Ÿti ğ‘‘o 1n ), at nh de
.
ğ‘­ğ‘­ğ’Šğ’Š ğ’ƒğ’ƒğ’Šğ’Š ğ‘­ğ‘­ğ’Šğ’Š
ğ‘“ ğ‘‘ğ‘–ğ‘ (ğ‘ 1,ğ‘ 2,ğ‘¡â„ğ‘Ÿğ‘‘ 2)actuallycanberegardedastwolineartransfor-
mationofsquaredifferencesbetweeneachtypeofalertrepresenta-
ğ’Šğ’Š
ğ‘­ğ‘­ğ’“ğ’“ğ’„ğ’„ğ’Šğ’Š tions,whereğ‘¡â„ğ‘Ÿğ‘‘ 1andğ‘¡â„ğ‘Ÿğ‘‘ 2arebiases.Thus,ACTcorrespondingly
performslineartransformationonğ‘  ğ‘–,ğ‘— andğ‘ ğ‘–,ğ‘—,respectively.Inad-
Figure4:Theprocessofrepresentingthebehaviorinforma- dition,sinceğ‘Ÿğ‘’ğ‘™ğ‘¢(ğ‘“ ğ‘‘ğ‘–ğ‘ (ğ‘  1,ğ‘  2,ğ‘¡â„ğ‘Ÿğ‘‘ 1))Ã—ğ‘Ÿğ‘’ğ‘™ğ‘¢(ğ‘“ ğ‘‘ğ‘–ğ‘ (ğ‘ 1,ğ‘ 2,ğ‘¡â„ğ‘Ÿğ‘‘ 2)) >0
tionofthealert. whenğ‘’ 1andğ‘’ 2arecorrelated,ACTsimilarlyactivatesthetrans-
formationresultsbyğ‘Ÿğ‘’ğ‘™ğ‘¢ function,andthenaggregatesthetwo
typesofalertrepresentationsbyelement-wiseproduct.Afterfur-
To train ABR in the training stage, for each history alert,ğ‘’ ğ‘– thertransformationanddimensionreduction,ACTfinallypresents
(1â‰¤ğ‘– â‰¤ğ‘›),byEquation(2),weaggregatetheoccurrenceseriesof thecorrelationdegreebetweenğ‘’ ğ‘– andğ‘’ ğ‘—,ğ‘ƒË† ğ‘–,ğ‘— = [ğ‘Ë†ğ‘–,ğ‘—,ğ‘Ë†ğ‘–,ğ‘— ]âŠ¤.ğ‘ƒË† ğ‘–,ğ‘—
a cole nr tt as inco sr tr he ela bt ee hd at vo ioğ‘’ rğ‘–, ina fn od rmde an tio ot ne oth fğ‘’e ğ‘–r ae nsu dl ğ¹t ğ‘–a cs oğ¹Ë† nğ‘– t. aT inh su ts h, esi bn ec he ağ¹ vğ‘– isatwo-dimensionalvector,inwhichğ‘Ë†ğ‘– 1,ğ‘— isthepr1 obab2
Ë† - ilitythat
thetwoalertsarecorrelated,andğ‘Ë†ğ‘– 2,ğ‘—
iorinformationofitscorrelatedalerts,thecommonalitybetween istheprobabilitythatthe
ğ¹ ğ‘– andğ¹Ë† ğ‘– representsthesamebehaviorinformationbetweenğ‘’ ğ‘– twoalertsareuncorrelated.Thesumofğ‘Ë†ğ‘–,ğ‘— andğ‘Ë†ğ‘–,ğ‘— is1,whichis
1 2
anditscorrelatedalerts.Specifically,asshowninFigure4,wetry ensuredbytheğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ function.
to transform ğ¹ ğ‘– to ğ¹Ë† ğ‘– by a neuralnetwork, whoseloss function TotrainACTinthetrainingstage,forahistoryalert,ğ‘’ ğ‘– (1 â‰¤
isdefinedinEquation(3).InEquation(3),ğ¹ ğ‘–â€²isthetransformed ğ‘– â‰¤ğ‘›),previousalertsduring[ğ‘¡ ğ‘– âˆ’ğ‘¤,ğ‘¡ ğ‘–]canbedividedintotwo
OnlineSummarizingAlertsthroughSemanticandBehaviorInformation ICSEâ€™22,May21â€“29,2022,Pittsburgh,PA,USA
Figure5:ThestructureofACT.
groups,correlatedalertstoğ‘’ ğ‘–,denotedasğ‘… ğ‘– (|ğ‘… ğ‘–| = ğ‘ ğ‘–),andre- incident 1 incident 2
maininguncorrelatedalerts,denotedasğ» ğ‘– (|ğ» ğ‘–| =ğ‘œ ğ‘–).Then,the
realrelationshipbetweentwoalerts,ğ‘’ ğ‘– andğ‘’ ğ‘— (1â‰¤ ğ‘— â‰¤ğ‘›),isfor-
mallydefinedasğ‘ƒ ğ‘–,ğ‘— = [1,0]âŠ¤ifğ‘’ ğ‘– andğ‘’ ğ‘— arecorrelated,otherwise
ğ‘ƒ ğ‘–,ğ‘— = [0,1]âŠ¤.Finally,weadoptEquation(5),whichmeasuresthe ğ’˜ğ’˜ newly reported alert
differencebetweenthedeterminationofACTandthegroundtruth,
ğ’†ğ’†ğ’’ğ’’ğ’Šğ’Š ğ’†ğ’†ğ’Šğ’Š time
asthelossfunctionofACT.
add to incident 2
ğ‘› Figure6:Theprocessofalertsummarizing.
1(cid:213)(cid:104)1 (cid:213)
ğ¿ ğ´ğ¶ğ‘‡ = ğ‘› ğ‘ (ğ‘ƒË† ğ‘–,ğ‘— âˆ’ğ‘ƒ ğ‘–,ğ‘—)2
ğ‘–
ğ‘–=1 ğ‘’ğ‘—âˆˆğ‘…ğ‘–
(5)
1 (cid:213) (cid:105)
+ (ğ‘ƒË† ğ‘–,ğ‘— âˆ’ğ‘ƒ ğ‘–,ğ‘—)2
ğ‘œ
ğ‘–
ğ‘’ğ‘—âˆˆğ»ğ‘– 8 EVALUATION
Toevaluatetheeffectivenessofourapproaches,weexploitreal-
7 ONLINESUMMARIZING worlddatasetsfromtwolargecommercialbankstoaddressthe
Inthetrainingstage,allmodelsforalertrepresentationandalert followingresearchquestions:
correlationarewelltrainedoffline.Therefore,inonlinesumma-
r reiz pi on rg tes dta ag le e, rf to ,ğ‘’r ğ‘—t ,h ie nn thew el ty imr eep wo ir nte dd owal ,e [r ğ‘¡t ğ‘–, âˆ’ğ‘’ ğ‘–, ğ‘¤a ,n ğ‘–d ],th we ep cr ae nvi eo au ss ill yy â€¢ R RQ Q1 2: :H Ho ow wd do oe es sO thA eS sap mer pfo lerm grain nusu lam rim tya ğ›¼riz inin Ag Bal Rer at ffs?
ğ‘¡ â€¢ ectthe
summarizingperformance?
representtheirsemanticinformationandbehaviorinformationby
â€¢ RQ3:Howdoesthesamplelengthğ›½inABRaffectthesum-
ASRandABR,respectively.Then,accordingtoACT,wecanobtain
marizingperformance?
thecorrelationdegreebetweenthetwoalertsstraightforwardly,
which is defined asğ‘ƒË† ğ‘–,ğ‘— = [ğ‘Ë†ğ‘–,ğ‘—,ğ‘Ë†ğ‘–,ğ‘— ]. Specifically,ğ‘Ë†ğ‘–,ğ‘— indicates â€¢ RQ4:Howdoesthetimewindowğ‘¤ inonlinesummarizing
1 2 1 affectthesummarizingperformance?
theprobabilitythatthealertsarecorrelated,andğ‘Ë†ğ‘–,ğ‘—
indicatesthe
2
probabilitythatthealertsareuncorrelated.Ifğ‘Ë†ğ‘– 1,ğ‘— > ğ‘Ë†ğ‘– 2,ğ‘— ,ğ‘’ ğ‘– and 8.1 Datasets
ğ‘’ ğ‘— maybelongtothesamesystemfailure.Therefore,weusethe
Equation(6)tofindthealertmostcorrelatedtoğ‘’ ğ‘–during[ğ‘¡ ğ‘–âˆ’ğ‘¤,ğ‘¡ ğ‘–]. Weconductexperimentsonreal-worldalertsfromtwolargecom-
mercial banks, A and B. As shown in Table 2, alerts of Bank A
andBankBhavedifferentcharacteristics.Thedefinitionofthe
ğ‘ ğ‘– =argmax(ğ‘Ë†ğ‘–,ğ‘— |ğ‘Ë†ğ‘–,ğ‘— >ğ‘Ë†ğ‘–,ğ‘— âˆ§(ğ‘¡ ğ‘– âˆ’ğ‘¡ ğ‘—) â‰¤ğ‘¤) (6) alertinBankAisnotstrictlystandardized,thustherearethou-
1 1 2
1â‰¤ğ‘—<ğ‘–
sandsofalerttypesinitsdataset.InBankB,thedefinitionofthe
alertisquiterigorous,thusBankBhasamuchsmallernumber
Then,asshowninFigure6,ifğ‘ ğ‘–exists,weaddğ‘’ ğ‘–intotheincidentof ofalerttypesthanBankA.Duetotheinformationprivacy,we
ğ‘’ ğ‘ğ‘–.Otherwise,weformanewincidentforğ‘’ ğ‘–.Suchstrategyavoids canonlysharethealertdatasetofBankB,whichisavailableat
modifyingpreviousalertsandensuresthateachalertisprocessed https://doi.org/10.5281/zenodo.5336985,inwhichallsensitivein-
onlyonceintheonlinesummarizingstage. formationisanonymized.
ICSEâ€™22,May21â€“29,2022,Pittsburgh,PA,USA JiaChen,PengWang,andWeiWang
Table2:DetailsofExperimentalDatasets InLDA,thenumberoftopicsissetto9.FortheCBOWmodelin
ASRandWord2Vec,thesizeofthewordembeddingis512andthe
Datasets TimeSpan #Alerts #AlertTypes epochissetto100.ForABR,thesizeofthebehaviorrepresentation
is600,thesamplegranularityfortheoccurrenceseries,ğ›¼,isset
BankA 2018/11/23âˆ¼2019/02/02 50947 2794 to1minute,thesamplelengthfortheoccurrenceseries,ğ›½,isset
BankB 2019/03/01âˆ¼2020/08/06 500000 51
to6hoursforBankAand13hoursforBankB,andtheepoch
issetto5.ForACT,inLinearTransformation,thefirstlayerhas
8.2 Baselines 50neurons,andthesecondlayerhas30neurons.InDimension
Reduction,thefirstlayerhas20neurons,andthesecondlayerhas2
AsshowninTable3,wecompareourapproacheswithsevenap- fixedneurons.TheepochofACTissetto60.Thewindowsize,ğ‘¤,in
proaches,SeqKrimp,GoKrimp,CSC,SWIFT,Jaccard,Word2Vec,
onlinesummarizing,issetto5minutes.Forapproachesthatrequire
andLDA.SeqKrimp,GoKrimp,CSC,andSWIFTareallfrequent