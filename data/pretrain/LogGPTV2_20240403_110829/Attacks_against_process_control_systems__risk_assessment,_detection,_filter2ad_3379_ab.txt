able to withstand attacks, or that reconﬁgure their operations
based on detected attacks. There is previous work on safety
and fault diagnosis; however, as we explain in this paper,
these systems are not enough for detecting deception attacks
launched by an intelligent attacker with knowledge on how
to evade fault detection methods used by the system.
In the next sections we describe our ideas, experiments, and re-
sults for (1) risk-assessment, (2) false-data-injection detection, and
(3) automatic attack-response in process control systems. In each
section we ﬁrst present a general theory for approaching the topic,
and then for experimental validation, we implement our ideas to the
model of a chemical reactor process.
4. RISK ASSESSMENT
Risk management is the process of shifting the odds in your favor
by ﬁnding among all possible alternatives, the one that minimizes
the impact of uncertain events.
Probably the best well known risk metric is the average loss
Rµ = E[L] ≈ i Lipi, where Li is the loss if event i occurs,
358
and pi is the probability that event i occurs. Other risk metrics try
to get more information about the probability distribution of the
losses, and not only its mean value (Rµ). For example the variance
of the losses Rχ = E[L2] − Rµ is very useful in ﬁnance since it
gives more information to risk averse individuals. This is particu-
larly important if the average loss is computed for a large period of
time (e.g. annually). If the loss is considered every time there is a
computer event then we believe the average loss by itself provides
enough risk information to make a rational decision.
In this paper we focus on attacks on sensor networks and the
effects they have on the process control system. Therefore pi de-
notes the likelihood that an attacker will compromise sensor i, and
Li denotes the losses associated with that particular compromise.
To simplify our presentation we assume that pi is the same for all
sensors, therefore our focus in the remaining of this section is to
estimate the potential losses Li. The results can then be used to
identify high priority sensors and to invest a given security budget
in the most cost-effective way.
4.1 Attack models
We consider the case when the state of the system is measured
by a sensor network of p sensors with measurement vector y(k) =
{y1(k), . . . , yp(k)}, where yi(k) denotes the measurement by sen-
sor i at time k. All sensors have a dynamic range that deﬁnes
the domain of yi for all k. That is, all sensors have deﬁned mini-
mum and maximum values ∀k, yi(k) ∈ [ymin
]. Let Yi =
[ymin
]. We assume each sensor has a unique identity pro-
tected by a cryptographic key.
, ymax
i
, ymax
i
i
i
Let ˜y(k) ∈ Rp denote the received measurements by the con-
troller at time k. Based on these measurements the control sys-
tem deﬁnes control actions to maintain certain operational goals. If
some of the sensors are under attack, ˜y(k) may be different from
the real measurement y(k); however, we assume that the attacked
signals ˜yi(k) also lie within Yi (signals outside this range can be
easily detected by fault-tolerant algorithms).
Let Ka = {ks, . . . , ke} represent the attack duration; between
the start time ks and stop time ke of an attack. A general model for
the observed signal is the following:
˜yi(k) =  yi(k)
ai(k)
for k /∈ Ka
for k ∈ Ka, ai(k) ∈ Yi
where ai(k) is the attack signal. This general sensor attack model
can be used to represent integrity attacks and DoS attacks. In
an integrity attack we assume that if attackers have compromised
a sensor, then they can inject any arbitrary value, therefore in this
case, ai(k) is some arbitrary non-zero value.
In a DoS attack, the controller will notice the lack of new mea-
surements and will react accordingly. An intuitive response for a
controller to implement against a DoS attack is to use the last sig-
nal received: ai(k) = yi(ks), where yi(ks) is the last measure-
ment received before the DoS attack starts.
4.2 Experiments
To test our attacks, we use the Tennessee-Eastman process con-
trol system (TE-PCS) model and the associated multi-loop PI con-
trol law as proposed by Ricker [49]. We brieﬂy describe the process
architecture and the control loops in Figure 1. The original process
model is implemented in FORTRAN and the PI control law is im-
plemented in MATLAB. We use this code for our study.
The chemical process consists of an irreversible reaction which
occurs in the vapour phase inside a reactor of ﬁxed volume V of
122 (m3). Two non-condensible reactants A and C react in the
When u3 saturates, the loop−4 controller uses u1 to control the
pressure P . The controllers for all four loops in ﬁgure 1 are pro-
portional integral (PI) controllers.
In steady-state operation, the production rate F4 is 100 kmol h−1,
the pressure P is 2700 KP a and the fraction of A in the purge is
47 mol%.
We study the security issues of control systems by experiment-
ing and simulating cyber attacks on sensor signals in the TE-PCS
model. Because operating the chemical reactor with a pressure
larger than 3000 kPa is unsafe (it may lead to an explosion or dam-
age of the equipment) We.assume that that the goal of the attacker
is to raise the pressure level of the tank to a value larger than 3000
kPa. We model an attacker that only has access to a single sensor at
a given time. We also assume Li > Lj, when an attack i can drive
the system to an unsafe state and an attack j cannot, and Li = Lj
if both attacks i and j either do not drive the system to an unsafe
state, or both can compromise the safety of the sytem.
Figure 1: Architecture of the Simpliﬁed TE Plant.
presence of an inert B to form a non-volatile liquid product D:
A + C B−→ D.
The feed stream 1 contains A, C and trace of B; feed stream 2 is
pure A; stream 3 is the purge containing vapours of A, B, C; and
stream 4 is the exit for liquid product D. The measured ﬂow rates
of stream i is denoted by Fi (kmol h−1). The control objectives
are
- Regulate F4, the rate of production of the product D, at a
(kmol h−1),
set-point F sp
4
- Maintain P , the operating pressure of the reactor, below the
shut-down limit of 3000 kP a as dictated safety considera-
tions,
- Minimize C, the operating cost measured in (kmol-of-product).
The cost depends linearly on the purge loss of A and C rel-
ative to the production rate of D. The cost considerations
dictate that the pressure be maintained as close as possible to
3000 kP a.
The production rate of D, denoted by rD (kmol h−1) is
rD = k0yv1
A3yv2
C3P v3,
where yA3 and yC3 denote the respective fractions of A and C in
the purge and v1, v2, v3 are given constants.
There are four input variables (or command signals) available to
achieve the above control objectives. The ﬁrst three input variables,
denoted as u1, u2 and u3, trigger the actuators that can change
the positions of the respective valves. The fourth input variable,
denoted as u4, is the set point for the proportional controller for the
liquid inventory. The input variables as used by the controller in
the following way:
• Production rate y4 = F4 is controlled using Feed 1 (u1) by
loop−1 controller,
• Pressure y5 = P is controlled using the purge rate (u3) by
loop−2 controller,
• Partial pressure of product A in the purge y7 = yA3 is con-
trolled using Feed 2 (u3) by loop−3 controller,
From the experimental results, we found that the most effective
of these attacks were max/min attacks (i.e., when ai(k) = ymin
or
ai(k) = ymax
). However, not all of the max/min attacks were able
to drive the pressure to unsafe levels. We now summarize some of
the results.
j
i
• By attacking the sensors, a controller is expected to respond
with incorrect control signals since it receives wrong infor-
mation from the compromised sensors. For example, by forg-
ing y7 as ymax
from t = 0 to 30, the controller believes there
is a large amount of component A in the tank.
7
y
5
y
7
)
a
P
k
(
e
r
u
s
s
e
r
P
3000
2900
2800
2700
2600
2500
2400
0
)
%
l
o
m
(
e
g
r
u
p
n
i
A
f
o
t
n
u
o
m
A
120
100
80
60
40
0
 ˜y7
y7
10
20
30
40
Time (hour)
10
20
30
40
Time (hour)
Figure 2: Integrity attack ymax
remains in a safe state for attacks on y7.
7
from t = 0 to 30. The system
From the experiments, we found that the plant system can go
back to the steady state after the attack ﬁnishes, as illustrated
in Fig 2. Furthermore, the pressure in the main tank never
reaches 3000 kPa. In general we found that the plant is very
resilient to attacks on y7 and y4. Attacks in the limit of the
sensing range (ymin and ymax) were the more damaging,
but they did not force the system into an unsafe state.
• By launching attack ymin
5
the controller turns down the purge
valve to increase the pressure and prevent the liquid products
from accumulating. We can see that the real pressure of the
tank (y5 in Fig 3(a)) keeps increasing past 3000 kPa and the
system operates in an unsafe state. In this experiment, it takes
about 20 hours (t = 10 to t = 30) to shut down (or cause
an explosion to) the plant. This long delay in causing an
effective attack may give defenders the advantage: for phys-
ical processes with slow-dynamics, it is possible that human
system operators may have enough time to observe unusual
phenomenon and take proper actions against the attack.
• We found out that in general DoS attacks do not affect the
plant. We ran the plant 20 times for 40 hours each and for
a DoS attack lasting 20 hours the pressure in the tank never
exceeded 2900kPa.
359
3500
3000
2500
2000
1500
1000
500
)
a
P
k
(
e
r
u
s
s
e
r
P
0
0
y
5
˜y5
y5
2760
X: 28.6
Y: 3002
10
20
30
40
Time (hour)
9(a)
)
a
P
k
(
e
r
u
s
s
e
r
P
2740
2720
2700
2680
0
y
5
˜y5
y5
10
20
30
40
Time (hour)
9(b)
Figure 3: Safety can be breached by compromising sensor y5
(3(a)). DoS attacks, on the other hand, do not cause any damage
(and they are easy to detect.) (3(b)).
We conclude that if the plant operator wants to prevent an attack
from making the system operate in an unsafe state, it should priori-
tize defenses against integrity attacks rather than on DoS attacks. If
the plant operator only has enough budget to deploy advanced se-
curity mechanisms for one sensor (e.g., tamper resistance, or TPM
chips), y5 should be the priority.
5. DETECTION OF ATTACKS
Detecting attacks to control systems can be formulated as an
anomaly-based intrusion detection problem [50]. One big differ-
ence in control systems compared to traditional IT systems, is that
instead of creating models of network trafﬁc or software behavior,
we can use a representative model of the physical system.
The intuition behind this approach is the following: if we know
how the output sequence of the physical system, y(k), should react
to the control input sequence, u(k), then any attack to the sensor
data can be potentially detected by comparing the expected output
ˆy(k) with the received (and possibly compromised) signal ˜y(k).
Depending on the quality of our estimate ˆy(k) we may have some
false alarms. We revisit this problem in the next section.
To formalize the anomaly detection problem, we need (1) a model
of the behavior of the physical system, and (2) an anomaly de-
tection algorithm. In section 5.1 we discuss our choice of linear
models as an approximation of the behavior of the physical system.
In section 5.2, we describe change detection theory and the detec-
tion algorithm we use–a nonparametric cumulative sum (CUSUM)
statistic.
5.1 Linear Model
To develop accurate control algorithms, control engineers often
construct a representative model that captures the behavior of the
physical system in order to predict how the system will react to a
given control signal. A process model can be derived from ﬁrst
principles (a model based on the fundamental laws of physics) or
from empirical input and output data (a model obtained by simu-
lating the process inputs with a carefully designed test sequence).
It is also very common to use a combination of these two mod-
els; for example, ﬁrst-principle models are typically calibrated by
using process test data to estimate key parameters. Likewise, em-
pirical models are often adjusted to account for known process
physics [51, 52].
For highly safety-critical applications, such as the aerospace in-
dustry, it is technically and economically feasible to develop accu-