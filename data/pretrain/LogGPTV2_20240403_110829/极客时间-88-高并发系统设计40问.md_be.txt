# 加餐 \| 数据的迁移应该如何做？你好，我是唐扬。 在"数据库优化方案（二）：写入数据量增加时，如何实现分库分表？"中我曾经提到，由于 MySQL 不像MongoDB 那样支持数据的 Auto Sharding（自动分片），所以无论是将 MySQL单库拆分成多个数据库，还是由于数据存储的瓶颈，不得不将多个数据库拆分成更多的数据库时，你都要考虑如何做数据的迁移。 其实，在实际工作中，不只是对数据库拆分时会做数据迁移，**很多场景都需要你给出数据迁移的方案，**比如说某一天，你的老板想要将应用从自建机房迁移到云上，那么你就要考虑将所有自建机房中的数据，包括MySQL，Redis，消息队列等组件中的数据，全部迁移到云上，这无论对哪种规模的公司来说都是一项浩瀚的工程，所以你需要在迁移之前，准备完善的迁移方案。 "数据的迁移"的问题比较重要，也比较繁琐，也是开发和运维同学关注的重点。在课程更新的过程中，我看到有很多同学，比如\@每天晒白牙，@枫叶11，@撒旦的堕落等等，在留言区询问如何做数据迁移，所以我策划了一期加餐，准备从数据库迁移和缓存迁移两个方面，带你掌握数据迁移的方法，也带你了解数据迁移过程中，需要注意的关键点，尽量让你避免踩坑。 如何平滑地迁移数据库中的数据你可能会认为：数据迁移无非是将数据从一个数据库拷贝到另一个数据库，可以通过MySQL 主从同步的方式做到准实时的数据拷贝；也可以通过 mysqldump工具将源库的数据导出，再导入到新库，**这有什么复杂的呢？** 其实，这两种方式只能支持单库到单库的迁移，无法支持单库到多库多表的场景。而且即便是单库到单库的迁移，迁移过程也需要满足以下几个目标： 1.  迁移应该是在线的迁移，也就是在迁移的同时还会有数据的写入；        2.  数据应该保证完整性，也就是说在迁移之后需要保证新的库和旧的库的数据是一致的；        3.  迁移的过程需要做到可以回滚，这样一旦迁移的过程中出现问题，可以立刻回滚到源库，不会对系统的可用性造成影响。        如果你使用 Binlog同步的方式，在同步完成后再修改代码，将主库修改为新的数据库，这样就不满足可回滚的要求，一旦迁移后发现问题，由于已经有增量的数据写入了新库而没有写入旧库，不可能再将数据库改成旧库。 一般来说，我们有两种方案可以做数据库的迁移。 "双写"方案第一种方案我称之为双写，其实说起来也很简单，它可以分为以下几个步骤： 1.将新的库配置为源库的从库，用来同步数据；如果需要将数据同步到多库多表，那么可以使用一些第三方工具获取Binlog 的增量日志（比如开源工具Canal），在获取增量日志之后就可以按照分库分表的逻辑写入到新的库表中了。 2.同时，我们需要改造业务代码，在数据写入的时候，不仅要写入旧库，也要写入新库。当然，基于性能的考虑，我们可以异步地写入新库，只要保证旧库写入成功即可。**但是，我们需要注意的是，**需要将写入新库失败的数据记录在单独的日志中，这样方便后续对这些数据补写，保证新库和旧库的数据一致性。 3.然后，我们就可以开始校验数据了。由于数据库中数据量很大，做全量的数据校验不太现实。你可以抽取部分数据，具体数据量依据总体数据量而定，只要保证这些数据是一致的就可以。 4.如果一切顺利，我们就可以将读流量切换到新库了。由于担心一次切换全量读流量可能会对系统产生未知的影响，所以这里**最好采用灰度的方式来切换，**比如开始切换 10% 的流量，如果没有问题再切换到 50%的流量，最后再切换到 100%。 5.由于有双写的存在，所以在切换的过程中出现任何的问题，都可以将读写流量随时切换到旧库去，保障系统的性能。 6.在观察了几天发现数据的迁移没有问题之后，就可以将数据库的双写改造成只写新库，数据的迁移也就完成了。 ![](Images/f6298668dc5eb59bece4192b33800e74.png)savepage-src="https://static001.geekbang.org/resource/image/ad/30/ad9a4aa37afc39ebe0c91144d5ef7630.jpg"}**其中，最容易出问题的步骤就是数据校验的工作，**所以，我建议你在未开始迁移数据之前先写好数据校验的工具或者脚本，在测试环境上测试充分之后，再开始正式的数据迁移。 如果是将数据从自建机房迁移到云上，你也可以使用这个方案，**只是你需要考虑的一个重要的因素是：**自建机房到云上的专线的带宽和延迟，你需要尽量减少跨专线的读操作，所以在切换读流量的时候，你需要保证自建机房的应用服务器读取本机房的数据库，云上的应用服务器读取云上的数据库。这样在完成迁移之前，只要将自建机房的应用服务器停掉，并且将写入流量都切到新库就可以了。 ![](Images/1f5971f763d78dae9216d541e525baeb.png)savepage-src="https://static001.geekbang.org/resource/image/b8/54/b88aefdb07049f2019c922cdb9cb3154.jpg"}这种方案是一种比较通用的方案，无论是迁移 MySQL 中的数据，还是迁移Redis中的数据，甚至迁移消息队列都可以使用这种方式，**你在实际的工作中可以直接拿来使用。** 这种方式的**好处是：**迁移的过程可以随时回滚，将迁移的风险降到了最低。**劣势是：**时间周期比较长，应用有改造的成本。 级联同步方案这种方案也比较简单，比较适合数据从自建机房向云上迁移的场景。因为迁移上云，最担心云上的环境和自建机房的环境不一致，会导致数据库在云上运行时，因为参数配置或者硬件环境不同出现问题。 所以，我们会在自建机房准备一个备库，在云上环境上准备一个新库，通过级联同步的方式在自建机房留下一个可回滚的数据库，具体的步骤如下： 1.先将新库配置为旧库的从库，用作数据同步； 2.再将一个备库配置为新库的从库，用作数据的备份； 3.等到三个库的写入一致后，将数据库的读流量切换到新库； 4.然后暂停应用的写入，将业务的写入流量切换到新库（由于这里需要暂停应用的写入，所以需要安排在业务的低峰期）。 ![](Images/3966a362c933343381a2f1612ae37b8c.png)savepage-src="https://static001.geekbang.org/resource/image/3a/2b/3a2e08181177529c3229c789c2081b2b.jpg"}**这种方案的回滚方案也比较简单，**可以先将读流量切换到备库，再暂停应用的写入，将写流量切换到备库，这样所有的流量都切换到了备库，也就是又回到了自建机房的环境，就可以认为已经回滚了。 ![](Images/890f5138a59795e97e16b4642bb66a9e.png)savepage-src="https://static001.geekbang.org/resource/image/ad/b9/ada8866fda3c3264f495c97c6214ebb9.jpg"}上面的级联迁移方案可以应用在，将 MySQL从自建机房迁移到云上的场景，也可以应用在将 Redis从自建机房迁移到云上的场景，**如果你有类似的需求可以直接拿来应用。** 这种方案**优势是**简单易实施，在业务上基本没有改造的成本；**缺点是**在切写的时候需要短暂的停止写入，对于业务来说是有损的，不过如果在业务低峰期来执行切写，可以将对业务的影响降至最低。 数据迁移时如何预热缓存另外，在从自建机房向云上迁移数据时，我们也需要考虑缓存的迁移方案是怎样的。那么你可能会说：缓存本来就是作为一个中间的存储而存在的，我只需要在云上部署一个空的缓存节点，云上的请求也会穿透到云上的数据库，然后回种缓存，对于业务是没有影响的。 你说的没错，但是你还需要考虑的是缓存的命中率。 如果你部署一个空的缓存，那么所有的请求就都穿透到数据库，数据库可能因为承受不了这么大的压力而宕机，这样你的服务就会不可用了。**所以，缓存迁移的重点是保持缓存的热度。** 刚刚我提到，Redis的数据迁移可以使用双写的方案或者级联同步的方案，所以在这里我就不考虑Redis 缓存的同步了，而是以 Memcached为例来说明。 使用副本组预热缓存在"缓存的使用姿势（二）：缓存如何做到高可用？slate-object="inline""中，我曾经提到，为了保证缓存的可用性，我们可以部署多个副本组来尽量将请求阻挡在数据库层之上。 数据的写入流程是写入 Master、Slave和所有的副本组，而在读取数据的时候，会先读副本组的数据，如果读取不到再到Master 和 Slave里面加载数据，再写入到副本组中。**那么，我们就可以在云上部署一个副本组，**这样，云上的应用服务器读取云上的副本组，如果副本组没有查询到数据，就可以从自建机房部署的主从缓存上加载数据，回种到云上的副本组上。 ![](Images/6770d6ffff1b41a923902b5594cd0ad2.png)savepage-src="https://static001.geekbang.org/resource/image/ab/c6/abc0b5e4c80097d8e02000b30e7ea9c6.jpg"}当云上部署的副本组足够热之后，也就是缓存的命中率达到至少90%，就可以将云机房上的缓存服务器的主从都指向这个副本组，这时迁移也就完成了。 **这种方式足够简单，不过有一个致命的问题是：**如果云上的请求穿透云上的副本组，到达自建机房的主从缓存时，这个过程是需要跨越专线的。 这不仅会占用较多专线的带宽，同时专线的延迟相比于缓存的读取时间是比较大的，一般，即使是本地的不同机房之间的延迟也会达到2ms～3ms，那么，一次前端请求可能会访问十几次甚至几十次的缓存，一次请求就会平白增加几十毫秒甚至过百毫秒的延迟，会极大地影响接口的响应时间，因此在实际项目中我们很少使用这种方案。 **但是，这种方案给了我们思路，**让我们可以通过方案的设计在系统运行中自动完成缓存的预热，所以，我们对副本组的方案做了一些改造，以尽量减少对专线带宽的占用。 改造副本组方案预热缓存改造后的方案对读写缓存的方式进行改造，步骤是这样的： 1. 在云上部署多组 mc的副本组，自建机房在接收到写入请求时，会优先写入自建机房的缓存节点，异步写入云上部署的mc 节点； 2. 在处理自建机房的读请求时，会指定一定的流量，比如10%，优先走云上的缓存节点，这样虽然也会走专线穿透回自建机房的缓存节点，但是流量是可控的； 3. 当云上缓存节点的命中率达到 90%以上时，就可以在云上部署应用服务器，让云上的应用服务器完全走云上的缓存节点就可以了。 ![](Images/1e05a50c26bf582b83f8562309989244.png)savepage-src="https://static001.geekbang.org/resource/image/7f/f4/7f41a529a322e396232ac7963ec082f4.jpg"}使用了这种方式，我们可以实现缓存数据的迁移，又可以尽量控制专线的带宽和请求的延迟情况，**你也可以直接在项目中使用。** 课程小结以上我提到的数据迁移的方案，都是我在实际项目中，经常用到的、经受过实战考验的方案，希望你能通过这节课的学习，将这些方案运用到你的项目中，解决实际的问题。与此同时，我想再次跟你强调一下本节课的重点内容： 1.  双写的方案是数据库、Redis    迁移的通用方案，        **你可以在实际工作中直接加以使用。**        双写方案中最重要的，是通过数据校验来保证数据的一致性，这样就可以在迁移过程中随时回滚；        2.  如果你需要将自建机房的数据迁移到云上，那么也可以考虑        **使用级联复制的方案，**        这种方案会造成数据的短暂停写，需要在业务低峰期执行；        3.  缓存的迁移重点，是保证云上缓存的命中率，你可以        **使用改进版的副本组方式来迁移，**        在缓存写入的时候，异步写入云上的副本组，在读取时放少量流量到云上副本组，从而又可以迁移部分数据到云上副本组，又能尽量减少穿透给自建机房造成专线延迟的问题。        **如果你作为项目的负责人，**那么在迁移的过程中，你一定要制定周密的计划：如果是数据库的迁移，那么数据的校验应该是你最需要花费时间来解决的问题。 如果是自建机房迁移到云上，那么专线的带宽一定是你迁移过程中的一个瓶颈点，你需要在迁移之前梳理清楚，有哪些调用需要经过专线，占用带宽的情况是怎样的，带宽的延时是否能够满足要求。你的方案中也需要尽量做到在迁移过程中，同机房的服务，调用同机房的缓存和数据库，尽量减少对于专线带宽资源的占用。 思考时间结合实际工作的经验，你可以和我分享一下，你在做数据迁移的时候都采用了哪些方案吗？这些方案你觉得它的优势和劣势分别是什么呢？ 最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。 ![](Images/5cef34b7fbf24f9dd9c2c4c485c9dd17.png)savepage-src="https://static001.geekbang.org/resource/image/72/1a/72b203e2c1ec97d268a5eead610bf71a.jpg"}
# 17 \| 消息队列：秒杀时如何处理每秒上万次的下单请求？你好，我是唐扬。在课程一开始，我就带你了解了高并发系统设计的三个目标：性能、可用性和可扩展性，而在提升系统性能方面，我们一直关注的是系统的查询性能。也用了很多的篇幅去讲解数据库的分布式改造，各类缓存的原理和使用技巧。**究其原因在于，**我们遇到的大部分场景都是读多写少，**尤其是在一个系统的初级阶段。**比如说，一个社区的系统初期一定是只有少量的种子用户在生产内容，而大部分的用户都在"围观"别人在说什么。此时，整体的流量比较小，而写流量可能只占整体流量的百分之一，那么即使整体的QPS 到了 10000 次 / 秒，写请求也只是到了每秒 100次，如果要对写请求做性能优化，它的性价比确实不太高。但是，随着业务的发展，你可能会遇到一些存在**高并发写请求的场景，其中秒杀抢购就是最典型的场景。**假设你的商城策划了一期秒杀活动，活动在第五天的 00:00开始，仅限前 200 名，那么秒杀即将开始时，后台会显示用户正在疯狂地刷新APP或者浏览器来保证自己能够尽量早的看到商品。这时，你面对的依旧是读请求过高，**那么应对的措施有哪些呢？**因为用户查询的是少量的商品数据，属于查询的热点数据，你可以采用缓存策略，将请求尽量挡在上层的缓存中，能被静态化的数据，比如说商城里的图片和视频数据，尽量做到静态化，这样就可以命中CDN 节点缓存，减少 Web 服务器的查询量和带宽负担。Web 服务器比如 Nginx可以直接访问分布式缓存节点，这样可以避免请求到达 Tomcat等业务服务器。当然，你可以加上一些限流的策略，比如，对于短时间之内来自某一个用户、某一个IP或者某一台设备的重复请求做丢弃处理。通过这几种方式，你发现自己可以将请求尽量挡在数据库之外了。稍微缓解了读请求之后，00:00分秒杀活动准时开始，用户瞬间向电商系统请求生成订单，扣减库存，用户的这些写操作都是不经过缓存直达数据库的。1秒钟之内，有 1万个数据库连接同时达到，系统的数据库濒临崩溃，寻找能够应对如此高并发的写请求方案迫在眉睫。这时你想到了消息队列。我所理解的消息队列关于消息队列是什么，你可能有所了解了，所以有关它的概念讲解，就不是本节课的重点，这里只聊聊我自己对消息队列的看法。在我历年的工作经历中，我一直把消息队列看作暂时存储数据的一个容器，认为消息队列是一个平衡低速系统和高速系统处理任务时间差的工具，**我给你举个形象的例子。**比方说，古代的臣子经常去朝见皇上陈述一些国家大事，等着皇上拍板做决策。但是大臣很多，如果同时去找皇上，你说一句我说一句，皇上肯定会崩溃。后来变成臣子到了午门之后要原地等着皇上将他们一个一个地召见进大殿商议国事，这样就可以缓解皇上处理事情的压力了。你可以把午门看作一个暂时容纳臣子的容器，也就是我们所说的消息队列。其实，你在一些组件中都会看到消息队列的影子：1.  在 Java    线程池中我们就会使用一个队列来暂时存储提交的任务，等待有空闲的线程处理这些任务；        2.  操作系统中，中断的下半部分也会使用工作队列来实现延后执行；        3.  我们在实现一个 RPC    框架时，也会将从网络上接收到的请求写到队列里，再启动若干个工作线程来处理。        4.  ......        总之，队列是在系统设计时一种常见的组件。那么我们如何用消息队列解决秒杀场景下的问题呢？接下来，我们来结合具体的例子来看看消息队列在秒杀场景下起到的作用。削去秒杀场景下的峰值写流量刚才提到，在秒杀场景下，短时间之内数据库的写流量会很高，那么依照我们以前的思路应该对数据做分库分表。如果已经做了分库分表，那么就需要扩展更多的数据库来应对更高的写流量。但是无论是分库分表，还是扩充更多的数据库，都会比较复杂，原因是你需要将数据库中的数据做迁移，这个时间就要按天甚至按周来计算了。而在秒杀场景下，高并发的写请求并不是持续的，也不是经常发生的，而只有在秒杀活动开始后的几秒或者十几秒时间内才会存在。为了应对这十几秒的瞬间写高峰，就要花费几天甚至几周的时间来扩容数据库，再在秒杀之后花费几天的时间来做缩容，**这无疑是得不偿失的。****所以，我们的思路是：**将秒杀请求暂存在消息队列中，然后业务服务器会响应用户"秒杀结果正在计算中"，释放了系统资源之后再处理其它用户的请求。我们会在后台启动若干个队列处理程序，消费消息队列中的消息，再执行校验库存、下单等逻辑。因为只有有限个队列处理线程在执行，所以落入后端数据库上的并发请求是有限的。而请求是可以在消息队列中被短暂地堆积，当库存被消耗完之后，消息队列中堆积的请求就可以被丢弃了。![](Images/8e47f6b99498fc220e1a8636c5fff1a0.png)savepage-src="https://static001.geekbang.org/resource/image/de/ad/de0a7a65a0bf51e1463d40d666a034ad.jpg"}这就是消息队列在秒杀系统中最主要的作用：**削峰填谷，**也就是说它可以削平短暂的流量高峰，虽说堆积会造成请求被短暂延迟处理，但是只要我们时刻监控消息队列中的堆积长度，在堆积量超过一定量时，增加队列处理机数量，来提升消息的处理能力就好了，而且秒杀的用户对于短暂延迟知晓秒杀的结果，也是有一定容忍度的。**这里需要注意一下，**我所说的是"短暂"延迟，如果长时间没有给用户公示秒杀结果，那么用户可能就会怀疑你的秒杀活动有猫腻了。所以，在使用消息队列应对流量峰值时，需要对队列处理的时间、前端写入流量的大小，数据库处理能力做好评估，然后根据不同的量级来决定部署多少台队列处理程序。比如你的秒杀商品有 1000 件，处理一次购买请求的时间是500ms，那么总共就需要 500s 的时间。这时，你部署 10个队列处理程序，那么秒杀请求的处理时间就是 50s，也就是说用户需要等待 50s才可以看到秒杀的结果，这是可以接受的。这时会并发 10个请求到达数据库，并不会对数据库造成很大的压力。通过异步处理简化秒杀请求中的业务流程其实，在大量的写请求"攻击"你的电商系统的时候，消息队列除了发挥主要的削峰填谷的作用之外，还可以实现**异步处理**来简化秒杀请求中的业务流程，提升系统的性能。你想，在刚才提到的秒杀场景下，我们在处理购买请求时，需要500ms。这时，你分析了一下整个的购买流程，发现**这里面会有主要的业务逻辑，也会有次要的业务逻辑：**比如说，主要的流程是生成订单、扣减库存；次要的流程可能是我们在下单购买成功之后会给用户发放优惠券，会增加用户的积分。假如发放优惠券的耗时是 50ms，增加用户积分的耗时也是50ms，那么如果我们将发放优惠券、增加积分的操作放在另外一个队列处理机中执行，那么整个流程就缩短到了400ms，性能提升了 20%，处理这 1000 件商品的时间就变成了400s。如果我们还是希望能在 50s 之内看到秒杀结果的话，只需要部署 8个队列程序就好了。经过将一些业务流程异步处理之后，我们的秒杀系统部署结构也会有所改变：![](Images/19d6e17a802f23d3aacc2559beb34046.png)savepage-src="https://static001.geekbang.org/resource/image/3b/aa/3b19c4b5e93eeb32fd9665e330e6efaa.jpg"}解耦实现秒杀系统模块之间松耦合除了异步处理和削峰填谷以外，消息队列在秒杀系统中起到的另一个作用是解耦合。比如数据团队对你说，在秒杀活动之后想要统计活动的数据，借此来分析活动商品的受欢迎程度、购买者人群的特点以及用户对于秒杀互动的满意程度等等指标。而我们需要将大量的数据发送给数据团队，那么要怎么做呢？**一个思路是：**可以使用 HTTP 或者 RPC的方式来同步地调用，也就是数据团队这边提供一个接口，我们实时将秒杀的数据推送给它，**但是这样调用会有两个问题：**1.  整体系统的耦合性比较强，当数据团队的接口发生故障时，会影响到秒杀系统的可用性。        2.  当数据系统需要新的字段，就要变更接口的参数，那么秒杀系统也要随着一起变更。        这时，我们可以考虑使用消息队列降低业务系统和数据系统的直接耦合度。秒杀系统产生一条购买数据后，我们可以先把全部数据发送给消息队列，然后数据团队再订阅这个消息队列的话题，这样它们就可以接收到数据，然后再做过滤和处理了。秒杀系统在这样解耦合之后，数据系统的故障就不会影响到秒杀系统了，同时，当数据系统需要新的字段时，只需要解析消息队列中的消息，拿到需要的数据就好了。![](Images/13ff361bb2d4ac77f57f87f11de3767f.png)savepage-src="https://static001.geekbang.org/resource/image/6e/f6/6e096e287f2c418f663ab201f435a5f6.jpg"}**异步处理、解耦合和削峰填谷**是消息队列在秒杀系统设计中起到的主要作用，其中，异步处理可以简化业务流程中的步骤，提升系统性能；削峰填谷可以削去到达秒杀系统的峰值流量，让业务逻辑的处理更加缓和；解耦合可以将秒杀系统和数据系统解耦开，这样两个系统的任何变更都不会影响到另一个系统，如果你的系统想要提升写入性能，实现系统的低耦合，想要抵挡高并发的写流量，那么你就可以考虑使用消息队列来完成。课程小结本节课，我结合自己的实际经验，主要带你了解了，消息队列在高并发系统设计中起到的作用，以及一些注意事项，你需要了解的重点如下：1.  削峰填谷是消息队列最主要的作用，但是会造成请求处理的延迟。        2.  异步处理是提升系统性能的神器，但是你需要分清同步流程和异步流程的边界，同时消息存在着丢失的风险，我们需要考虑如何确保消息一定到达。        3.  解耦合可以提升你的整体系统的鲁棒性。        当然，你要知道，在使用消息队列之后虽然可以解决现有的问题，但是系统的复杂度也会上升。比如上面提到的业务流程中，同步流程和异步流程的边界在哪里？消息是否会丢失，是否会重复？请求的延迟如何能够减少？消息接收的顺序是否会影响到业务流程的正常执行？如果消息处理流程失败了之后是否需要补发？**这些问题都是我们需要考虑的。**我会利用接下来的两节课，针对最主要的两个问题来讲讲解决思路：一个是如何处理消息的丢失和重复，另一个是如何减少消息的延迟。引入了消息队列的同时也会引入了新的问题，需要新的方案来解决，这就是系统设计的挑战，也是系统设计独有的魅力，而我们也会在这些挑战中不断提升技术能力和系统设计能力。思考时间在今天的课程中，我提到了消息队列在高并发系统设计中起到的作用。那么你在开发过程中会在什么样的场景下使用消息队列呢？欢迎在留言区与我分享你的经验。最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。![](Images/5cef34b7fbf24f9dd9c2c4c485c9dd17.png)savepage-src="https://static001.geekbang.org/resource/image/72/1a/72b203e2c1ec97d268a5eead610bf71a.jpg"}