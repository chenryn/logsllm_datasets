# 24 \| C10K问题：高并发模型设计你好，我是盛延敏，这里是网络编程实战第 24 讲，欢迎回来。在性能篇的前 4 讲里，我们陆续讲解了 select、poll、epoll 等几种 I/O多路复用技术，以及非阻塞 I/O模型，为高性能网络编程提供了必要的知识储备。这一讲里，我们了解一下历史上有名的C10K 问题，并借着 C10K 问题系统地梳理一下高性能网络编程的方法论。
## C10K 问题随着互联网的蓬勃发展，一个非常重要的问题摆在计算机工业界面前。这个问题就是如何使用最低的成本满足高性能和高并发的需求。这个问题在过去可能不是一个严重的问题，但是在2000年前后，互联网用户的人数井喷，如果说之前单机服务的用户数量还保持在一个比较低的水平，比如说只有上百个用户，那么在互联网逐渐普及的情况下，服务于成千上万个用户就将是非常普遍的情形，在这种情形下，如果还按照之前单机的玩法，成本就将超过人们想象，只有超级有钱的大玩家才可以继续下去。于是，C10K 问题应运而生。C10K 问题是这样的：如何在一台物理机上同时服务10000 个用户？这里 C 表示并发，10K 等于10000。得益于操作系统、编程语言的发展，在现在的条件下，普通用户使用 JavaNetty、Libevent 等框架或库就可以轻轻松松写出支持并发超过 10000的服务器端程序，甚至于经过优化之后可以达到十万，乃至百万的并发，但在二十年前，突破C10K 问题可费了不少的心思，是一个了不起的突破。``{=html}C10K 问题是由一个叫 Dan Kegel的工程师提出并总结归纳的，你可以通过访问[http://www.kegel.com/c10k.html](http://%20%3Ca%20href=){http:=""www.kegel.com="" c10k.html=""}\"\> 这个页面来获得最新有关这方面的信息。
## 操作系统层面C10K 问题本质上是一个操作系统问题，要在一台主机上同时支持 1万个连接，意味着什么呢? 需要考虑哪些方面？
### 文件句柄首先，通过前面的介绍，我们知道每个客户连接都代表一个文件描述符，一旦文件描述符不够用了，新的连接就会被放弃，产生如下的错误：    Socket/File:Can't open so many files在 Linux下，单个进程打开的文件句柄数是有限制的，没有经过修改的值一般都是 1024。    $ulimit -n1024这意味着最多可以服务的连接数上限只能是1024。不过，我们可以对这个值进行修改，比如用 root 权限修改/etc/sysctl.conf 文件，使得系统可用支持 10000 个描述符上限。    fs.file-max = 10000net.ipv4.ip_conntrack_max = 10000net.ipv4.netfilter.ip_conntrack_max = 10000
### 系统内存每个 TCP连接占用的资源可不止一个连接套接字这么简单，在前面的章节中，我们多少接触到了类似发送缓冲区、接收缓冲区这些概念。每个TCP 连接都需要占用一定的发送缓冲区和接收缓冲区。我在文稿里放了一段 shell 代码，分别显示了在 Linux 4.4.0下发送缓冲区和接收缓冲区的值。    $cat   /proc/sys/net/ipv4/tcp_wmem4096163844194304$ cat   /proc/sys/net/ipv4/tcp_rmem4096873806291456这三个值分别表示了最小分配值、默认分配值和最大分配值。按照默认分配值计算，一万个连接需要的内存消耗为：    发送缓冲区： 16384*10000/8 = 20M bytes接收缓冲区： 87380*10000/8 = 110M bytes当然，我们的应用程序本身也需要一定的缓冲区来进行数据的收发，为了方便，我们假设每个连接需要128K 的缓冲区，那么 1 万个链接就需要大约 1.2G 的应用层缓冲。这样，我们可以得出大致的结论，支持 1万个并发连接，内存并不是一个巨大的瓶颈。
### 网络带宽假设 1 万个连接，每个连接每秒传输大约 1KB 的数据，那么带宽需要 10000 x1KB/s x8 = 80Mbps。这在今天的动辄万兆网卡的时代简直小菜一碟。
## C10K 问题解决之道通过前面我们对操作系统层面的资源分析，可以得出一个结论，在系统资源层面，C10K问题是可以解决的。但是，能解决并不意味着可以很好地解决。我们知道，在网络编程中，涉及到频繁的用户态 -内核态数据拷贝，设计不够好的程序可能在低并发的情况下工作良好，一旦到了高并发情形，其性能可能呈现出指数级别的损失。举一个例子，如果没有考虑好 C10K 问题，一个基于 select的经典程序可能在一台服务器上可以很好处理 1000 的并发用户，但是在性能 2倍的服务器上，却往往并不能很好地处理 2000 的并发用户。要想解决 C10K 问题，就需要从两个层面上来统筹考虑。第一个层面，应用程序如何和操作系统配合，感知 I/O事件发生，并调度处理在上万个套接字上的 I/O 操作？前面讲过的阻塞I/O、非阻塞 I/O 讨论的就是这方面的问题。第二个层面，应用程序如何分配进程、线程资源来服务上万个连接？这在接下来会详细讨论。这两个层面的组合就形成了解决 C10K 问题的几种解法方案，下面我们一起来看。
### 阻塞 I/O + 进程这种方式最为简单直接，每个连接通过 fork派生一个子进程进行处理，因为一个独立的子进程负责处理了该连接所有的I/O，所以即便是阻塞 I/O，多个连接之间也不会互相影响。这个方法虽然简单，但是效率不高，扩展性差，资源占用率高。下面的伪代码描述了使用阻塞 I/O，为每个连接 fork 一个进程的做法：    do{   accept connections   fork for conneced connection fd   process_run(fd)}虽然这个方式比较传统，但是可以很好地帮我们理解父子进程、僵尸进程等，我们将在下一讲中详细讲一下如何使用这个技术设计一个服务器端程序。
### 阻塞 I/O + 线程进程模型占用的资源太大，幸运的是，还有一种轻量级的资源模型，这就是线程。通过为每个连接调用 pthread_create创建一个单独的线程，也可以达到上面使用进程的效果。    do{   accept connections   pthread_create for conneced connection fd   thread_run(fd)}while(true)因为线程的创建是比较消耗资源的，况且不是每个连接在每个时刻都需要服务，因此，我们可以预先通过创建一个线程池，并在多个连接中复用线程池来获得某种效率上的提升。    create thread pooldo{   accept connections   get connection fd   push_queue(fd)}while(true)我将在第 26 讲中详细讲解这部分内容。
### 非阻塞 I/O + readiness notification + 单线程应用程序其实可以采取轮询的方式来对保存的套接字集合进行挨个询问，从而找出需要进行I/O 处理的套接字，像文稿中给出的伪码一样，其中 is_readble 和is_writeable 可以通过对套接字调用 read 或 write 操作来判断。    for fd in fdset{   if(is_readable(fd) == true){     handle_read(fd)   }else if(is_writeable(fd)==true){     handle_write(fd)   }}但这个方法有一个问题，如果这个 fdset有一万个之多，每次循环判断都会消耗大量的 CPU时间，而且极有可能在一个循环之内，没有任何一个套接字准备好可读，或者可写。既然这样，CPU的消耗太大，那么干脆让操作系统来告诉我们哪个套接字可以读，哪个套接字可以写。在这个结果发生之前，我们把CPU 的控制权交出去，让操作系统来把宝贵的 CPU时间调度给那些需要的进程，这就是 select、poll 这样的 I/O 分发技术。于是，程序就长成了这样：    do {    poller.dispatch()    for fd in registered_fdset{         if(is_readable(fd) == true){           handle_read(fd)         }else if(is_writeable(fd)==true){           handle_write(fd)     }}while(ture)第 27 讲中，我将会讨论这样的技术实现。但是，这样的方法需要每次 dispatch之后，对所有注册的套接字进行逐个排查，效率并不是最高的。如果 dispatch调用返回之后只提供有 I/O 事件或者 I/O变化的套接字，这样排查的效率不就高很多了么？这就是前面我们讲到的 epoll设计。于是，基于 epoll 的程序就长成了这样：    do {    poller.dispatch()    for fd_event in active_event_set{         if(is_readable_event(fd_event) == true){           handle_read(fd_event)         }else if(is_writeable_event(fd_event)==true){           handle_write(fd_event)     }}while(ture)Linux 是互联网的基石，epoll 也就成为了解决 C10K 问题的钥匙。FreeBSD 上的kqueue，Windows 上的 IOCP，Solaris 上的/dev/poll，这些不同的操作系统提供的功能都是为了解决 C10K 问题。