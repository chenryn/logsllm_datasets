### Close-Disabled Variants

In an initial pilot of a spoofed User Account Control (UAC) window, we inadvertently activated the 'Yes' button, which submits the credentials, without waiting for the user to enter their username and password. Previous research [19] suggests that users often ignore most of a warning and jump straight to their options. Many participants saw the "Yes" button and pressed it without entering any credentials. From this early mistake, we hypothesized that participants might be more likely to enter their credentials if the option to dismiss the spoofed window was deactivated.

We paired each of the above treatments with a second treatment in which the 'Cancel' or 'No' button was removed, and the window close box (the 'X' at the top right in Windows) was disabled. These treatments are labeled with the suffix '-D' and are otherwise identical to their non-suffixed counterparts.

### CredUI-D*

The final treatment, CredUI-D*, was exactly the same as CredUI-D, except that participants were not asked to maximize their browsers at the start of the study. We included this treatment to determine if it was necessary for attackers who wanted to spoof an OS window to first trick users into maximizing their browser windows.

### Figure 4: Participant Responses to Multiple-Answer Question

Participants who did not enter any passwords were asked a multiple-answer question. Participants who selected the third option from the top were categorized as 'wise' to the attack; the others were categorized as 'oblivious'.

## 4. Results

Our results reveal that spoofing attacks are effective, with 18% of participants across all treatment groups providing what they later admitted were valid login credentials for their device. These participants were classified as compromised. For reasons discussed in Section 4.2, 6% of participants were unexposed, meaning they did not see the spoofed password-entry window.

We asked those participants who did not enter a password to indicate which, if any, factors contributed to their decision not to enter their password. As shown in Figure 4, 48% of those we asked reported that they thought the password-entry window was trying to steal their passwords, and we classified them as wise to the attack. 36% did not provide this factor and were classified as oblivious.

### 4.1 Participants

We conducted our experiment between January 25 and February 5, 2012, and collected results for a total of 504 participants. An additional 28 participants were recruited but never visited the confederate gaming website. We also excluded 15 participants who, despite our instructions, responded to the survey from outside the United States.

To identify participants who may not have made conscientious attempts to read and answer questions, we included a multiple-choice question that any participant should have been able to answer correctly: "The power switch on a computer is used to...?" This approach was inspired by Downs et al. [8]. All but two participants answered this question correctly, suggesting that the majority of participants in our results made a conscientious attempt to read and answer our survey.

Participants were an average of 28 years old (σ = 9.6 years), 55% were male, and 78% were Caucasian. The top two reported occupations were 'student' (33%) and 'unemployed' (13%). To gauge their level of expertise, we asked five technical questions on topics such as encryption and web security. No participant answered all questions correctly, 11% were able to answer four out of five questions correctly, and 54% answered one or no questions correctly. 28% reported knowledge of at least one computer programming language. Finally, participants took an average of 17 minutes and 23 seconds (σ = 18 minutes and 15 seconds) to complete the study.

### Figure 5: Attack Efficacy

Compromised participants entered their username and password and later admitted that these were valid login credentials for their device. Participants wise to the attack did not admit to entering valid login credentials and checked the box labeled "I thought that the password-entry window was trying to steal my password." Participants categorized as 'oblivious' were not wise to the attack but did not fall victim because they had other reasons for not wanting to enter their passwords. Unexposed participants may not have seen the credential-entry window (e.g., because they closed the install window presented prior to the credential-entry window in condition MacOS1). With the exception of CredUI-D*, all treatment groups shown above correspond to the merge of the corresponding cancel-enabled and cancel-disabled pair. Disaggregated data can be found in Table 2. The choice of treatment, as shown above, had a statistically significant effect on the outcome.

### 4.2 Attack Efficacy

Of the pool of 504 participants in all treatment groups of our experiment, 142 (29%) entered one or more characters into a spoofed password field. Recall that we used two separate questions to try to compel participants to admit the truth if they had entered their genuine credentials. Of the 142 participants who entered a value into the password field, 38 (27%, or 8% of the total participant pool) denied that the text they had typed was their genuine device password and, in response to the second question, consented for us to see what they had typed. Another 9 (6% of the participants who typed a password, or 2% of the total participant pool) denied that the password was genuine but refused to consent for us to see it. The remaining 95 participants (67% of participants who typed a password, or 18% of the total participant pool) admitted to typing their genuine credentials, and all but one did so by answering 'yes' to the first of the two questions. (Note, however, that participants may have revised their answer to the first question after seeing the second question.)

The results of each attack are presented in Figure 5, and the disaggregated numbers are presented in Table 2. Our research questions led us to two hypothesis tests: one to determine if close-disabled treatments performed better than their close-enabled peers and one to determine if browser-maximization had an impact on our results. In our analysis, we use χ2 tests to indicate the statistical likelihood that differences between treatment groups were the result of chance. We applied eight tests and corrected for multiple testing using the Bonferroni method, assuming α = .00625 in place of α = .05.

In both UAC treatments, the close-disabled treatment pair had a higher compromise rate than a close-enabled treatment pair. In aggregate, the five paired close-disabled treatments had compromise rates (43/215, 20%) slightly higher than their close-enabled peers (43/237, 18%). However, the differences in attack efficacy between conditions with enabled and disabled cancel buttons were not statistically significant (χ2(4) = 1.34, p = 0.855).

To highlight changes between the fundamental designs, we merged close-enabled and close-disabled treatment groups together in Figure 5 (disabling close boxes did not appear to have a significant effect and was applied with equal frequency to each of the fundamental designs). Over the remaining six treatment groups, we found that the choice of treatment group had a significant effect (after correcting for multiple testing) on both the fraction of participants categorized as compromised (χ2(5) = 31.13, p < 0.001) and the fraction categorized as wise (χ2(5) = 24.71, p < 0.001).

Some participants were unexposed to the spoofed password-entry window because they closed the browser tab before the credential-entry window could appear. Those in the MacOS1 treatments may have aborted installation when the spoofed installation-description dialog was displayed (Figure 3), which came before the credential-entry step.

In every group, at least one participant provided credentials that they later admitted were genuine. For the Windows treatments, the compromise rates in Figure 5 fall between 15% and 35%, with the maximum compromise rate only 2.31× greater than the minimum—a relatively tight range given the sample sizes involved. When combined, participants in all the UAC attack treatment groups had a higher compromise rate (57/192, 29.7%) than those in the two CredUI attack treatments (17/93, 18.3%), though not significant when correcting for multiple testing (χ2(1) = 4.24, p = 0.039).

Many participants who were not compromised may still have been fooled, trusting that the credential-entry window was genuine but failing to enter their credentials due to a lack of motivation. More participants refused to enter their credentials because they were concerned that "the software I was being asked to install could harm my computer or steal my information" (209/356, 58.7%) than because they were afraid to enter their credentials (173/356, 48.6%). Similarly, more participants withheld their credentials not because they detected the spoofing attack, but because they were not motivated to install new software (80/356, 22.5%). Furthermore, a relatively high proportion of participants across all treatments (180/356, 50.6%) volunteered that they did not enter their credentials because they did not know what credentials to enter.

A greater proportion of participants in the two CredUI treatments were wise to the attack (51/93, 54.8%) than those in the four UAC treatments (67/192, 34.8%, χ2(1) = 10.27, p = 0.001, significant when corrected for multiple testing).

A disproportionately small fraction of participants were compromised by the MacOS2 treatments (4/92, 4.4%), which did not spoof an installation-description window before the credential-entry window, and a disproportionately large fraction were wise to it (40/92, 43.5%). In contrast, the MacOS1 treatments did present an installation-description window, giving participants who did not want to install QuickTime an opportunity to abandon the process before seeing the credential-entry window, so 26% of participants were not exposed to it (hence unexposed). Even accounting for those unexposed, more participants were compromised by the treatments that included the spoofed installation-description window (8/101, 7.9%) than without it (4/92, 4.4%).

While the aggregate compromise rates for participants in the Mac OS treatments were lower than for the Windows treatments, it would be premature to conclude that Mac OS users are less vulnerable to spoofing; we put more effort into tuning our Windows attacks and the treatments targeted different software to install (Silverlight vs. QuickTime). Even when we did present an installation-description dialog, we skipped a number of steps in the installation ritual.

The difference between the rates at which participants in the Mac OS treatments were wise to spoofing (63/167, 37.7%) and those in the Windows UAC treatment groups (67/192, 34.9%) were well within the margin of error (χ2(1) = 0.31, p = 0.578).

The CredUI-D* treatment, in which participants were not asked to maximize the browser window at the start of the survey, did no worse than the identical treatment in which participants were asked to do so (CredUI-D). Of those in the CredUI-D* treatment, our instrumentation indicates that 78% already had their browser sized to consume at least 80% of the screen's area. It’s possible that convincing users to maximize browser windows may raise more suspicions than it dispels.

In future experiments, we may consider removing the window-maximization step, though we cannot say with confidence that this will increase attack efficacy. UAC windows are bigger than CredUI windows, and therefore, failing to maximize a small browser window might be more likely to cause a user to become wise to a UAC-based attack than a CredUI-based attack. While we believe that convincing users to maximize their browser windows in advance of an attack poses little challenge to social engineers, our data suggest that doing so may be unnecessary.

Finally, after we disclosed the deception to our participants, we asked them whether they "knew that the password-entry window was actually mimicked by the website, and not a real password request from [their] operating system." The answers to this question ranged from "I was completely sure that the password entry wasn’t real" to "I never suspected." While no 'compromised' participants reported being completely sure about the deception, between 16% and 25% of participants who were not 'compromised' reported that they were sure of the deception.

### 4.3 Drop-Out Rates

During the study, 136 participants began answering the survey but dropped out before finishing. We have only partial information about who these participants were and what they did, but our instrumentation allowed us to know at what point they dropped out of the study. Out of the 136 participants who did not complete the study, 6 were from outside the United States and would not have been included if they finished. 18 participants dropped during the consent form (i.e., they did not reach the first game), 56 dropped during the first game (they did not see the second game), 23 dropped during the second game, and 33 dropped during the third game. Out of these 33, two participants skipped all the games (they checked the "I could not play this game" checkboxes), 25 evaluated two games and dropped during the third game (we don’t have evidence that these participants visited the gaming website or saw our spoofed dialog), and finally 6 participants reached the third game, saw our simulated dialog, and interacted with it. Two of them did not enter a password, returned to our survey, answered a few more questions, and then dropped out; three of them entered a password and never returned to the survey; and finally, one last participant entered a password, returned to the survey, said that their password was real, and then dropped out. We included these last 6 participants in our analyses reported above.

### 4.4 Reasons for Suspecting Spoofing

We asked participants with suspicions to explain them to us. For many participants, especially Mac OS users, the empty username field was a source of suspicion. If an attacker can obtain the user’s username, the credibility of that spoofed window, and the compromise rate, would likely rise.

Some participants found ways to test whether the spoofed credential-entry window was real, sometimes using techniques we had not anticipated. One Mac OS participant used Exposé, which reveals the set of OS-level windows, to see that the credential-entry window was only present within the browser. Other Mac OS participants noticed that we had failed to center the spoofed dialog on their screens and knew that the genuine dialog is centered. Some participants in the Windows UAC treatment group were familiar with UAC and knew their computers were configured such that they would not request a password to complete an elevation. In the words of a participant, "When I installed Silverlight before, it didn’t ask for a password." Similarly, other participants were aware that their account did not have administrator rights. In the words of another participant, "Microsoft Silverlight is not installed on my computer, and I am not the 'Administrator' of this computer, so I did not know the password. If I had known the password, I probably would have entered it."