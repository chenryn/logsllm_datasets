Close-disabled variants
In a pilot of a spoofed UAC window we mistakenly acti-
vated the ‘Yes’ button, which submits the credentials, with-
out waiting for the user to enter characters into the username
and password ﬁeld. Prior research suggests [19] that users
will often ignore most of a warning and jump straight to
their options. Many participants saw the “Yes” button and
pressed it without entering any credentials. From this early
mistake, we hypothesized that participants might be more
likely to enter their credentials if the option to dismiss the
spoofed window was deactivated.
We paired each of the above treatments with a second
treatment in which the ‘cancel’ or ‘no’ button was removed
and the window close box (the ‘X’ at the top right in Win-
dows) was disabled. These treatments are labeled with the
suﬃx ‘-D,’ and are otherwise identical to their suﬃxless
counterparts.
CredUI-D*
The ﬁnal treatment, CredUI-D*, was exactly the same as
CredUI-D, except that participants were not asked to max-
imize their browsers at the start of the study. We included
this treatment to determine if it was really necessary for at-
tackers who wanted to spoof an OS window to ﬁrst trick
users into maximizing their browser windows.
Figure 4: Participants who did not enter any passwords were
asked the multiple-answer question above. Participants who
picked the third option from top were categorized as ‘wise’
to the attack; the others were categorized as ‘oblivious’.
4. RESULTS
Our results reveal that spooﬁng attacks are eﬀective, with
18% of participants over all treatment groups providing what
they would later admit were valid login credentials for their
device. These participants were classiﬁed as compromised.
For reasons discussed in Section 4.2, 6% of participants were
unexposed, not seeing the spoofed password-entry window.
We asked those participants who did not enter a password
to indicate which, if any, factors contributed to their decision
not to enter their password. As shown in Figure 4, 48% of
those we asked reported that they thought the password-
entry window was trying to steal their passwords, and we
classiﬁed them as wise to the attack. 36% did not provide
this factor and were classiﬁed as oblivious.
4.1 Participants
We ran our experiment between January 25 and February
5 2012, and collected results for a total of 504 participants.
Not included are an additional 28 participants who were re-
cruited but never visited the confederate gaming website.
We also did not include 15 participants who, despite our in-
structions, responded to the survey from outside the United
States.
To identify participants who may not have made consci-
entious attempts to read and answer questions, we included
a multiple-choice question that any participant should have
been able to answer correctly: “The power switch on a com-
?” This approach was inspired by Downs
puter is used to
et al. [8]. All but two participants answered this question
correctly, suggesting that the majority of participants in our
results made a conscientious attempt to read and answer our
survey.
Participants were an average of 28 years old (σ =9.6 years),
55% were male, and 78% were caucasian. The top two re-
ported occupations were ‘student’ (33%) and ‘unemployed’
(13%). To gauge their level of expertise, we asked ﬁve tech-
nical questions on topics such as encryption and web secu-
rity. No participant answered all questions correctly, 11%
were able to answer correctly 4 out of 5 questions, and 54%
answered one or no questions correctly. 28% reported knowl-
edge of at least one computer programming language. Fi-
nally, participants took an average of 17 min 23 secs (σ =18
min 15 secs) to complete the study.
370Figure 5: Attack eﬃcacy. Compromised participants entered username and password and later admitted that these were valid
login credentials for their device. Participants wise to the attack didn’t admit to entering valid login credentials, and checked
the box labeled “I thought that the password-entry window was trying to steal my password.” Participants categorized
as ‘oblivious’ were not wise to the attack, but did not fall victim because they had other reasons for not wanting to enter
their passwords. Unexposed participants may have not seen the credential-entry window (e.g. because they closed the install
window presented prior to the credential-entry window in condition MacOS1). With the exception of CredUI-D*, all treatment
groups shown above correspond to the merge of the corresponding cancel-enabled and cancel-disabled pair. Disaggregated
data can be found in Table 2. The choice of treatment, as shown above, had a statistically signiﬁcant eﬀect on the outcome.
4.2 Attack efﬁcacy
Of the pool of 504 participants in all treatment groups of
our experiment, 142 (29%) entered one or more characters
into a spoofed password ﬁeld. Recall that we used two sep-
arate questions to try to compel participants to admit the
truth if they had entered their genuine credentials. Of the
142 participants who entered a value into the password ﬁeld,
38 (27%, or 8% of the total participant pool) denied that the
text that they had typed was their genuine device password
and, in response to the second question, consented for us to
see what they had typed. Another 9 (6% of the participants
who typed a password, or 2% of the total participant pool)
denied that the password was genuine, but refused to con-
sent for us to see it. The remaining 95 participants (67%
of participants who typed a password, or 18% of the total
participant pool) admitted to typing their genuine creden-
tials, and all but one did so by answering ‘yes’ to ﬁrst of
the two questions. (Note, however, that participants may
have revised their answer to the ﬁrst question after seeing
the second question.)
The results of each attack are presented in Figure 5, and
the disaggregated numbers are presented in Table 2. Our
research questions led us to two hypothesis tests, one to de-
termine if close-disabled treatments performed better than
their close-enabled peers and one to determine if browser-
maximization had an impact on our results. In our analysis
we use χ2 tests to indicate the statistical likelihood that dif-
ferences between treatment groups were the result of chance.
We applied eight tests, and corrected for multiple testing us-
ing the Bonferroni method, assuming α = .00625 in place of
α = .05.
In both UAC treatments, the close-disabled treatment
pair had a higher compromise rate than a close-enabled
treatment pair. In aggregate, the ﬁve paired close-disabled
treatments had compromise rates (43/215, 20%) slightly
higher than their close-enabled peers (43/237, 18%). How-
ever, the diﬀerences in attack eﬃcacy between conditions
with enabled and disabled cancel buttons were not statisti-
cally signiﬁcant (χ2(4) = 1.34, p = 0.855).
To highlight changes between the fundamental designs,
we merge close-enabled and close-disabled treatment groups
together in Figure 5 (disabling close boxes did not appear
to have a signiﬁcant eﬀect, and was applied with equal fre-
quency to each of the fundamental designs). Over the re-
maining six treatment groups, we found that the choice of
treatment group had a signiﬁcant eﬀect (after correcting for
multiple testing) on both the fraction of participants cate-
gorized as compromised (χ2(5) = 31.13, p < 0.001) and the
fraction categorized as wise (χ2(5) = 24.71, p < 0.001).
Some participants were unexposed to the spoofed password-
entry window because they closed the browser tab before
the credential-entry window could appear. Those in the
MacOS1 treatments may have aborted installation when the
spoofed installation-description dialog was displayed (Fig-
ure 3), which came before the credential-entry step.
In every group, at least one participant provided creden-
tials that they later admitted were genuine. For the Win-
dows treatments, the compromise rates in Figure 5 fall be-
tween 15% and 35%, with the maximum compromise rate
only 2.31× greater than the minimum—a relatively tight
range given the sample sizes involved. When combined,
participants in all the UAC attack treatment groups had
a higher compromise rate (57/192, 29.7%) than those in
the two CredUI attack treatments (17/93, 18.3%), though
not signiﬁcant when correcting for multiple testing (χ2(1) =
4.24, p = 0.039).
Many participants who were not compromised may still
have been fooled, trusting that the credential-entry window
was genuine but failing to enter their credentials due to a
lack of motivation. More participants refused to enter their
credentials because they were concerned that “the software
I was being asked to install could harm my computer or
steal my information” (209/356, 58.7%) than because they
were afraid to enter their credentials (173/356, 48.6%). Sim-
ilarly, more participants withheld their credentials not be-
cause they detected the spooﬁng attack, but because they
were not motivated to install new software (80/356, 22.5%).
Furthermore, a relatively high proportion of participants
across all treatments (180/356, 50.6%) volunteered that they
did not enter their credentials because they did not know
what credentials to enter.
A greater proportion of participants in the two CredUI
treatments were wise to the attack (51/93, 54.8%) than
those in the four UAC treatments (67/192, 34.8%, χ2(1) =
37110.27, p = 0.001, signiﬁcant when corrected for multiple
testing.)
A disproportionately small fraction of participants were
compromised by the MacOS2 treatments (4/92, 4.4%), which
did not spoof an installation-description window before the
credential-entry window, and a disproportionately large frac-
tion were wise to it (40/92, 43.5%). In contrast, the MacOS1
treatments did present an installation-description window.
This presented participants who did not want to install Quick-
Time an opportunity to abandon the process before seeing
the credential-entry window, so 26% of participants were
not exposed to it (hence unexposed ). Even accounting for
those unexposed, more participants were compromised by
the treatments that included the spoofed installation-description
window (8/101, 7.9%) than without it (4/92, 4.4%).
While the aggregate compromise rates for participants in
the Mac OS treatments were lower than for the Windows
treatments, it would be premature to conclude that Mac OS
users are less vulnerable to spooﬁng; we put more eﬀort into
tuning our Windows attacks and the treatments targeted dif-
ferent software to install (Silverlight vs. QuickTime). Even
when we did present an installation-description dialog, we
skipped a number of steps in the installation ritual.
The diﬀerence between the rates at which participants
in the Mac OS treatments were wise to spooﬁng (63/167,
37.7%) and those in the Windows UAC treatment groups
(67/192, 34.9%) were well within the margin of error (χ2(1) =
0.31, p = 0.578).
The CredUI-D* treatment, in which participants were not
asked to maximize the browser window at the start of the
survey, did no worse than the identical treatment in which
participants were asked to do so (CredUI-D). Of those in the
CredUI-D* treatment, our instrumentation indicates that
78% already had their browser sized to consume at least 80%
of the screen’s area. It’s possible that convincing users to
maximize browser windows may raise more suspicions than
it dispels.
In future experiments we may consider remov-
ing the window-maximization step, though we cannot say
with conﬁdence that this will increase attack eﬃcacy. UAC
windows are bigger than CredUI windows, and, therefore,
failing to maximize a small browser window might be more
likely to cause a user to become wise to a UAC-based attack
than a CredUI-based attack. While we believe that convinc-
ing users to maximize their browser windows in advance of
an attack poses little challenge to social engineers, our data
suggests that doing so may be unnecessary.
Finally, after we disclosed the deception to our partici-
pants, we asked them whether they “know that the password-
entry window was actually mimicked by the website, and not
a real password request from [their] operating system.” The
answers to this question ranged from ‘I was completely sure
that the password entry wasn’t real’ to ‘I never suspected’.
While no ‘compromised’ participants reported to be com-
pletely sure about the deception, between 16% and 25% of
participants who were not ‘compromised’ reported that they
were sure of the deception.
4.3 Drop-out rates
During the study, 136 participants began answering the
survey but dropped out before ﬁnishing. We have only par-
tial information about who these participants were and what
they did, but our instrumentation allowed us to know at
what point they dropped out of the study. Out of the 136
participants who did not complete the study, 6 were from
outside the United States and would not have been included
if they ﬁnished. 18 participants dropped during the consent
form (that is, they did not reach the ﬁrst game), 56 dropped
during the ﬁrst game (they did not see the second game),
23 dropped during the second game, and 33 dropped during
the third game. Out of these 33, two participants skipped
all the games (they checked the “I could not play this game”
checkboxes), 25 evaluated two games and dropped during
the third game (we don’t have evidence that these partici-
pants visited the gaming website or saw our spoofed dialog),
and ﬁnally 6 participants reached the third game, saw our
simulated dialog and interacted with it. Two of them did
not enter a password, returned to our survey, answered a
few more questions, and then dropped out; three of them
entered a password and never returned to the survey; and
ﬁnally one last participant entered a password, returned to
the survey, said that his or her password was real, and then
dropped out. We included these last 6 participants in our
analyses reported above.
4.4 Reasons for suspecting spooﬁng
We asked participants with suspicions to explain them to
us. For many participants, especially Mac OS users, the
empty username ﬁeld was a source of suspicion. If an at-
tacker can obtain the user’s username, the credibility of that
spoofed window, and the compromise rate, would likely rise.
Some participants found ways to test whether the spoofed
credential-entry window was real, sometimes using techniques
we had not anticipated. One Mac OS participant used Ex-
pos´e, which reveals the set of OS-level windows, to see that
the credential-entry window was only present within the
browser. Other Mac OS participants noticed that we had
failed to center the spoofed dialog on their screens and knew
that the genuine dialog is centered. Some participants in the
Windows UAC treatment group were familiar with UAC and
knew their computers were conﬁgured such that they would
not request a password to complete an elevation.
In the
words of a participant, “when i installed silverlight before it
didn’t ask for a password.” Similarly, other participants were
aware that their account did not have administrator rights.
In the words of another participant, “Microsoft Silverlight is
not installed on my computer, and I am not the ‘Adminis-
trator’ of this computer so I did not know the password. If
I had known the password, I probably would have entered it