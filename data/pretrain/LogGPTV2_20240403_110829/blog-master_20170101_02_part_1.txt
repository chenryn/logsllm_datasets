## ApsaraDB的左右互搏(PgSQL+HybridDB+OSS) - 解决OLTP+OLAP混合需求
##### [TAG 15](../class/15.md)
### 作者                                                                                                         
digoal                                                                                                          
### 日期                                                                                                        
2017-01-01                  
### 标签                                                                                                        
PostgreSQL , HybridDB , HTAP , OLTP , OLAP , 混合场景 , Oracle , 企业痛点 , 数据库痛点                                                     
----                                                                                                        
## 背景    
随着IT行业在更多的传统行业渗透，我们正逐步的在进入DT时代，让数据发挥价值是企业的真正需求，否则就是一堆废的并且还持续消耗企业人力，财力的数据。    
传统企业可能并不像互联网企业一样，有大量的开发人员、有大量的技术储备，通常还是以购买IT软件，或者以外包的形式在存在。    
数据的核心 - 数据库，很多传统的行业还在使用传统的数据库。    
但是随着IT向更多行业的渗透，数据类型越来越丰富（诸如人像、X光片、声波、指纹、DNA、化学分子、图谱数据、GIS、三维、多维 等等。。。），数据越来越多，怎么处理好这些数据，怎么让数据发挥价值，已经变成了对IT行业，对数据库的挑战。    
对于互联网行业来说，可能对传统行业的业务并不熟悉，或者说互联网那一套技术虽然在互联网中能很好的运转，但是到了传统行业可不一定，比如说用于科研、军工的GIS，和互联网常见的需求就完全不一样。    
除了对数据库功能方面的挑战，还有一方面的挑战来自性能方面，随着数据的爆炸，分析型的需求越来越难以满足，主要体现在数据的处理速度方面，而常见的hadoop生态中的处理方式需要消耗大量的开发人员，同时并不能很好的支持品种繁多的数据类型，即使GIS可能也无法很好的支持，更别说诸如人像、X光片、声波、指纹、DNA、化学分子、图谱数据、GIS、三维、多维 等等。    
那么我们有什么好的方法来应对这些用户的痛处呢？    
## 传统的业务场景分析    
传统行业以Oracle数据库为例，系统具备以下特点    
### 1. 可靠性    
通过REDO日志提供可靠保障。    
支持同步和异步模式，同步模式可以做到已提交的事务不丢失。    
异步模式不保证已提交的事务不丢失，不保证一致性。适用于对可靠性和一致性都没有要求，但是对性能有要求的场景。    
![pic](20170101_02_pic_001.jpg)    
### 2. 高可用    
通常支持三种高可用的架构。  
通过主备模式(data guard)以及集群套件提供高可用支持    
通过共享存储，RAC集群套件提供高可用支持, 注意应用连接设计时，不同的INSTANCE连接的应用应该访问不同的数据块，否则可能会因为GC锁带来性能严重下降。    
通过共享存储，主机集群套件提供高可用支持    
![pic](20170101_02_pic_002.jpg)    
### 3. 容灾    
通过存储层远程增量镜像提供异地容灾    
通过主备模式以及增量复制提供异地容灾    
![pic](20170101_02_pic_003.jpg)    
### 4. 备份恢复    
通过归档和基础备份提供在线备份以及时间点恢复功能    
![pic](20170101_02_pic_004.jpg)    
### 5. 性能诊断    
AWR报告，通常包括    
TOP SQL、wait event stats、io time、db time    
### 6. 功能    
PL/SQL编程，C嵌入式SQL，SQL:2011标准    
#### 数据库编程    
许多传统企业，会使用PL/SQL开发语言，编写大量的存储过程、函数，处理复杂并且对一致性有强要求的业务逻辑。比如账务系统。  
支持C嵌入式开发    
#### SQL兼容性    
SQL: 2013    
GIS    
多种索引支持    
数据类型丰富    
#### 语法例子    
with, connect by, grouping set, rollup, cube    
许多内置的函数、操作符、聚合函数、窗口函数等    
SQL HINT、物化视图、RLS（行安全策略）    
### 7. 扩展性    
通过RAC和共享存储，扩展主机的方式扩展，支持CPU并行计算    
注意应用连接设计时，不同的INSTANCE连接的应用应该访问不同的数据块，否则可能会因为GC锁带来性能严重下降。    
![pic](20170101_02_pic_005.jpg)    
12c开始支持sharding。  
### 8. 多租户隔离    
比如Oracle 12C提出的PDB    
![pic](20170101_02_pic_006.jpg)    
### 9. 价格    
通常按核收费，按特性收费，LICENSE 昂贵    
## 用户痛点分析    
不管是传统企业，还是互联网企业，随着用户数据量的增长，数据库的处理能力逐渐成为瓶颈。    
### 1. 数据库的计算能力    
以ORACLE为例，传统的非MPP架构数据库，在执行大数据量运算时，受制于硬件限制，对于OLAP场景显得很吃力。    
### 2. 数据挖掘分析能力    
以ORACLE为例，传统的数据库没有机器学习套件，即使有，也受制于它的架构，无法发挥应对数据挖掘分析需求。    
### 3. 扩展能力    
RAC的扩展能力受到共享存储的限制，存储容易成为瓶颈    
RAC的模式下面，必须确保APP不会跨实例访问相同的数据块，否则GC锁冲突严重，性能比单节点下面明显。    
### 4. 可编程能力    
支持的服务端编程语言仅PL/SQL, C。    
不支持高级的类型扩展，函数扩展，OP扩展，索引扩展。    
不适合企业快速发展的IT需求。    
### 5. 价格    
昂贵    
## DT时代企业对数据的处理需求    
除了对数据库基本的增删改查需求，备份恢复容灾需求外。企业对数据处理的要求越来越高。    
比如很多时候，用户可能要实时的对数据进行清洗、分析、或者根据数据触发事件。    
随着更多的业务接入IT系统，用户需要存储越来越多的非结构化的数据、贴近实际需求的数据（比如人像、化学分子式、X光片、基因串、等等现实世界的数据属性），很多数据库在这种情况下显得力不从心，只能靠应用程序来处理，由于数据离计算单元越来越远，效率变得低下。    
![pic](20170101_02_pic_007.jpg)     
总结起来，DT时代对数据处理的需求可以归为几类:  
1\. 流式计算  
2\. 传统OLTP需求  
3\. 离线分析  
4\. 在线分析  
5\. 图计算  
细分后，你会发现IT架构越来越庞大，已经不是单一产品能解决的问题了。  
数据类型也可以进一步的细分：  
1\. 数值、字符串、字节流、数组、分词、等常用类型  
2\. 文本  
3\. 图片、视频、等多媒体数据  
4\. 行业强相关数据，例如基因串、DNA、天文、地理、化学分子等。  
## 阿里云ApsaraDB OLTP+OLAP 解决方案剖析    
![pic](20170101_02_pic_008.jpg)     
### 1. 通过以下PostgreSQL特性，可以支持OLTP + 本地的10TB量级OLAP需求。    
1\. LLVM   
llvm其实在分析场景用得比较多，但是在传统数据库中引入LLVM的不是很常见，特别是开源领域，目前能看到的有PostgreSQL。  
在重计算的SQL场景中，需要对大批量的数据进行运算，比如过滤数据，从代码层面来讲涉及到函数外的调用(get row后，需要对其进行filter涉及表达式的function调用)，interpretation耗费较大，通过profileing可以发现瓶颈出现在filter节点。  
针对性优化手段是尽量的减少函数切换，使用LLVM的接口可以帮你将这个部分的代码重新生成，在一个函数内完成所有的运算。  
2\. CPU并行计算  
搞Oracle的同学应该不陌生，调动多个CPU处理一个SQL请求。  
目前支持的场景包括全表扫描，JOIN，聚合，索引扫描。正在加入更多NODE的支持。  
3\. 向量运算与瓦片式存储、列存储插件  
传统的QUERY执行器在处理表达式时，是一行一行的处理模式。    
比如在处理(x+y)这个表达式时，首先读取一条记录的X值，然后读取这条记录的Y值，然后执行+操作符。然后将结果返回给上层node。    
然而，向量化执行器，一个操作符可以处理多个值，比如(x+y) ，x, y并不是scalar值，而是一批值的向量，向量化执行的结果也不是scalar值，而是向量。    
向量化执行模型的会引入一定的解释和函数调用overhead，但是对于OLAP场景的大批量数据处理，这个overhead可以忽略。    
既然向量化执行倾向于每次处理大批量的数据，那么在数据存放方面，也需要注意，比如OLAP经常需要对单列进行处理，使用列存储可以更好的和向量化执行模型结合起来。  
PostgreSQL 使用向量计算结合瓦片式存储后，TPC-H的Q1和Q6可以得到验证，性能有了10倍的提升。  
4\. GPU\FPGA加速  
PostgreSQL开放了 custom scan的编程接口，社区内有使用这个接口支持GPU或者FPGA来加速运算的插件，在OLAP场景，性能提升非常明显。  
5\. 聚合算子复用    
在统计学中，大多数的统计算法的中间结果都是可以共用的，例如sum,avg; 方差,相关性,count,sum等运算;      
PostgreSQL 很好的抓住了这样的特征，对初始条件一致，中间算法一致的聚合函数，在同一个分组中数据只需要计算一遍，大大降低了CPU的开销，提高了统计效率。    
6\. BRIN索引接口    
BRIN在流式数据，时序数据的检索中起到了巨大的作用，使用很小的索引就可以帮助用户快速的检索线性相关性很好的字段。   
### 2. 通过插件支持更多的业务数据类型需求    
比如JSONB、图片、人像、化学分子式、基因串、GIS、路由等。     
### 3. 流式数据处理方法    
使用PostgreSQL数据库的衍生产品-pipelineDB，可以与kafka, jstrom, PostgreSQL无缝结合，以及标准的SQL接口，兼容PostgreSQL.     
达到了单机（32C）每秒百万条记录的运算能力，除了支持简单的聚合，使用pipelinedb作为流计算引擎，依靠PG本身的特性和功能，可以支持更丰富的数据类型和处理逻辑。  
简化开发工作量，同时满足更多场景的需求，比如物联网的用户端、工厂等小型接入点，无法部署大量的jstrom集群，使用单台pipelinedb更加适合。  
### 4. PB级的分析、挖掘需求    
HybridDB基于开源的MPP数据库GPDB打造，继承了许多GPDB的特点，同时结合阿里云的云上组件，新增了一些功能。    
支持弹性的增加节点，扩容时按表分区粒度进行，因此不堵塞其他表分区的读写     
支持SQL标准以及诸多OLAP特性，    
支持行列混合存储、多级分区、块级压缩、多节点并行计算、多节点数据并行导入、    
支持丰富的数据类型，包括JSON、GIS、全文检索、语感、以及常见的文本、数值类型。    
支持MADLib机器学习库，有上百种常见的挖掘算法，通过SQL调用UDF训练数据集即可，结合MPP实现了多节点并行的挖掘需求    