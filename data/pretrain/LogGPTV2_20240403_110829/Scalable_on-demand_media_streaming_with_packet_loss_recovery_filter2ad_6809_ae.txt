when classes are in session at the University of Wisconsin.
Clients can request the videos, pause, resume, fast-forward,
rewind, and jump to special markers in the content, at arbi-
4These results are obtained from simulations under Poisson
request arrivals, although as reported in [12], qualitatively
very similar results are obtained for a heavy-tailed distribu-
tion of interrequest times modelled by a Pareto distribution.
All results in the ﬁgure have 95% conﬁdence intervals that
are within 5% of the reported values.
i
t
h
d
w
d
n
a
B
r
e
v
r
e
S
d
e
r
i
u
q
e
R
20
15
10
5
0
1
n=1.25
n=1.39
n=1.67
n=2.22
Lower Bound
10
100
1000
Client Request Rate, N
Figure 10: RBS Performance (10% Packet Loss)
trary points in time. The implementation has demonstrated
that bandwidth skimming (1) is simple to implement, partic-
ularly for the closest target (CT) variant of the protocol [11],
(2) is easily extended to support client interactive requests,
and (3) can be designed with almost no client feedback for
eﬀecting the stream merging. Extensions to implement the
RBS protocol are in progress.
6. CONCLUSIONS
This paper has addressed the design of scalable and reli-
able on-demand delivery of streaming media. New Reliable
Periodic Broadcast (RPB) protocols and Reliable Bandwidth
Skimming (RBS) protocols were developed and evaluated.
The evaluation of the protocols relied in part on simple lower
bounds on required server bandwidth for any protocol that
provides uninterrupted playback when average packet loss
rate is bounded by p. One of the bounds assumes the server
provides immediate service to each client; the other assumes
the server serves an unlimited number of clients with a spec-
iﬁed maximum client start up delay. Each of the new pro-
tocols nearly achieves the applicable lower bound, and thus
achieves nearly the best possible scalability.
On-going research includes experimental evaluation of the
new RPB and RBS protocols, developing congestion con-
trol strategies for RPB and RBS systems, developing RPB
and RBS protocols for VBR content that has not been fully
smoothed, developing RPB systems that have diﬀerent loss
protection for diﬀerent layers in a layered media stream, and
quantifying required server bandwidth for RBS systems that
have speciﬁed frequencies and types of interactive requests.
7. ACKNOWLEDGMENTS
We would like to thank John Zahorjan for early technical
discussions on this topic. We also thank Jussara Almeida,
Paul Barford, and the anonymous SIGCOMM 2001 referees
for comments that improved the paper presentation.
8. REFERENCES
[1] C. C. Aggarwal, J. L. Wolf, and P. S. Yu, “A
Permutation Based Pyramid Broadcasting Scheme for
Video On -Demand Systems”, Proc. IEEE ICMCS
’96, Hiroshima, Japan, June 1996.
[2] J. M. Almeida, J. Krueger, D. L. Eager, and M. K.
Vernon, “Analysis of Educational Media Server
Workloads”, Proc. NOSSDAV ’01, Port Jeﬀerson, NY,
June 2001.
[3] Y. Birk and R. Mondri, “Tailored Transmissions for
Eﬃcient Near-Video-On-Demand Service”, Proc.
IEEE ICMCS ’99, Florence, Italy, June 1999.
[4] J. C. Bolot, S. Parisis, and D. Towsley, “Adaptive
FEC-Based Error Control for Internet Telephony”,
Proc. IEEE Infocom ’99, New York, NY, March 1999.
[5] J. Byers, M. Luby, M. Mitzenmacher and A. Rege, “A
Digital Fountain Approach to Reliable Distribution of
Bulk Data”, Proc. ACM Sigcomm ’98, Vancouver,
Canada, Sept. 1998.
[6] Y. Cai, K. A. Hua, and K. Vu, “Optimizing Patching
Performance”, Proc. MMCN ’99, San Jose, CA, Jan.
1999.
[7] G. Carle and E. W. Biersack, “Survey of Error
Recovery Techniques for IP-based Audio-Visual
Multicast Applications”, IEEE Network, Vol. 11, No.
6, Nov./Dec. 1997.
[8] S. W. Carter and D. D. E. Long, “Improving
Video-on-Demand Server Eﬃciency Through Stream
Tapping”, Proc. ICCCN ’97, Las Vegas, Sept. 1997.
[9] P. A. Chou, A. E. Mohr, A. Wang, and S. Mehrotra,
“FEC and Pseudo-ARQ for Receiver-driven Layered
Multicast of Audio and Video”, Proc. IEEE Data
Compression Conf., Snowbird, UT, March 2000.
[10] D. L. Eager, M. K. Vernon, and J. Zahorjan,
“Minimizing Bandwidth Requirements for
On-Demand Data Delivery”, IEEE Trans. on
Knowledge and Data Engineering, Sept./Oct. 2001.
(Earlier version appears in Proc. MIS ’99.)
[11] D. L. Eager, M. K. Vernon, and J. Zahorjan,
“Optimal and Eﬃcient Merging Schedules for
Video-on-Demand Servers”, Proc. ACM Multimedia
’99, Orlando, FL, Nov. 1999.
[19] W. Jiang and H. Schulzrinne, “Modeling of Packet
Loss and Delay and their Eﬀect on Real-Time
Multimedia Service Quality”, Proc. NOSSDAV ’00,
Chapel Hill, NC, June 2000.
[20] L. Juhn and L. Tseng, “Fast Data Broadcasting and
Receiving Scheme for Popular Video Service”, IEEE
Trans. on Broadcasting, Vol. 44, No. 1, March 1998.
[21] X. Li, M. H. Ammar, and S. Paul, “Video Multicast
over the Internet”, IEEE Network, Vol. 13, No. 2,
March/April 1999.
[22] X. Li, S. Paul, P. Pancha, and M. Ammar, “Layered
Video Multicast with Retransmission (LVMR):
Evaluation of Error Recovery Schemes”, Proc.
NOSSDAV ’97, St. Louis, MO, May 1997.
[23] J. Nonnenmacher, E. W. Biersack, and D. Towsley,
“Parity-Based Loss Recovery for Reliable Multicast
Transmission”, IEEE/ACM Trans. on Networking,
Vol. 6, No. 4, Aug. 1998.
[24] J. Nonnenmacher, M. Lacher, M. Jung, G. Carl, and
E. W. Biersack, “How Bad is Reliable Multicast
Without Local Recovery?”, Proc. IEEE Infocom ’98,
San Francisco, CA, April 1998.
[25] J. Paris, S. W. Carter, and D. E. Long, “Eﬃcient
Broadcasting Protocols for Video on Demand”, Proc.
MASCOTS ’98, Montreal, Canada, July 1998.
[26] C. Perkins, O. Hodson, and V. Hardman, “A Survey
of Packet Loss Recovery Techniques for Streaming
Audio”, IEEE Network, Vol. 12, No. 5, Sept./Oct.
1998.
[27] L. Rizzo, “Eﬀective Erasure Codes for Reliable
Computer Communication Protocols”, Computer
Communication Review, Vol. 27, No. 2, April 1997.
[28] L. Rizzo and L. Vicisano, “A Reliable Multicast Data
Distribution Protocol Based on Software FEC
Techniques”, Proc. HPCS ’97, Greece, June 1997.
[12] D. L. Eager, M. K. Vernon, and J. Zahorjan,
[29] S. Sen, L. Gao, J. Rexford, and D. Towsley, “Optimal
“Bandwidth Skimming: A Technique for
Cost-Eﬀective Video-on-Demand”, Proc. MMCN ’00,
San Jose, CA, Jan. 2000.
Patching Schemes for Eﬃcient Multimedia
Streaming”, Proc. NOSSDAV ’99, Basking Ridge, NJ,
June 1999.
[13] S. Floyd, V. Jacobson, C. G. Liu, S. McCanne, and L.
[30] W. Tan and A. Zakhor, “Multicast Transmission of
Zhang, “A Reliable Multicast Framework for
Light-weight Sessions and Application Level Framing”,
Proc. ACM Sigcomm ’95, Cambridge, MA, Aug. 1995.
[14] L. Gao, J. Kurose, and D. Towsley, “Eﬃcient Schemes
for Broadcasting Popular Videos”, Proc. NOSSDAV
’98, Cambridge, UK, July 1998.
[15] L. Gao and D. Towsley, “Supplying Instantaneous
Video-on-Demand Systems Using Controlled
Multicast”, Proc. IEEE ICMCS ’99, Florence, Italy,
June 1999.
[16] A. Hu, “Video-on-Demand Broadcasting Protocols: A
Comprehensive Study”, Proc. IEEE Infocom ’01,
Anchorage, AK, April 2001.
[17] K.A. Hua and S. Sheu, “Skyscraper Broadcasting: A
New Broadcasting Scheme for Metropolitan
Video-on-Demand Systems”, Proc. ACM Sigcomm
’97, Cannes, France, Sept. 1997.
[18] K. A. Hua, Y. Cai, and S. Sheu, “Patching: A
Multicast Technique for True Video-On-Demand
Services”, Proc. ACM Multimedia ’98, Bristol, U.K.,
Sept. 1998.
Scalable Video using Receiver-driven Hierarchical
FEC”, Packet Video Workshop, New York, NY, April
1999.
[31] L. Vicisano, L. Rizzo, and J. Crowcroft, “TCP-like
Congestion Control for Layered Video Multicast Data
Transfer”, Proc. IEEE Infocom ’98, San Francisco,
CA, April 1998.
[32] S. Viswanathan and T. Imielinski, “Metropolitan Area
Video-on-Demand Service using Pyramid
Broadcasting”, Multimedia Systems, Vol. 4, No. 4,
Aug. 1996.
[33] R. Yavatkar, J. Griﬀoen, and M. Sudan, “A Reliable
Dissemination Protocol for Interactive Collaborative
Applications”, Proc. ACM Multimedia ’95, San
Francisco, CA, Nov. 1995.
[34] X. R. Xu, A. C. Myers, H. Zhang, and R. Yavatkar,
“Resilient Multicast Support for Continuous-Media
Applications”, Proc. NOSSDAV ’97, St. Louis, MO,
May 1997.
APPENDIX
A. MULTICAST RETRANSMISSIONS
This appendix derives a lower bound on the required server
bandwidth when retransmissions are multicast, under the
assumption that packet losses at each client are independent
and occur with probability p. In an actual system there may
be some correlation among the packet losses experienced at
diﬀerent clients due to shared links in the transmission paths
to these clients. Simple models of plausible correlation struc-
tures may be analyzed using a similar approach as described
below for independent packet losses.
As in the analysis for the case of no packet loss reviewed
in Section 2.3, consider a small portion of the object at some
arbitrary time oﬀset x. For an arbitrary client request that
arrives at time t, this portion of the object must be delivered
no later than time t + x. Thus, there is a “sharing window”
of duration at most x over which a multicast of this portion
may be fruitfully received by new clients.
A lower bound on the required server bandwidth can be
obtained by (a) assuming that closely spaced retransmis-
sions experience the same (rather than correlated) loss prob-
ability, and (b) neglecting the impact of the time required
for retransmissions on the scheduling of “fresh” (i.e., not re-
transmissions owing to packet loss) multicasts and the size
of the sharing window. In the absence of precisely simulta-
neous client requests, there is only one client for which any
particular multicast of the portion at time oﬀset x is “just
in time”. Under the assumption of uncorrelated loss prob-
abilities, the number of transmissions required to achieve
successful delivery to this client is equal to n with probabil-
ity p(n−1)(1−p), and has average value
1
1−p . The probability
s that some other client that is listening to these transmis-
sions successfully receives the data is given by
∞(cid:7)
n=1
s =
p(n−1)
(1 − p)(1 − pn
) =
1
1 + p
.
(11)
If one of these clients does not successfully receive the data,
another “fresh” multicast must be scheduled. The required
server bandwidth is minimized if this new multicast is sched-
uled so as to achieve “just in time” delivery to the earliest
such client.
Thus, each fresh multicast of the portion at time oﬀset
1
x incurs on average
1−p transmissions. Furthermore, not
all clients listening to these transmissions may successfully
receive the data, and so the minimal average frequency with
which these multicasts must be scheduled is increased in
comparison to the case of no packet loss. This minimal fre-
quency is identical to the average throughput of a system in
which “customers” (representing fresh multicasts and their
associated sharing windows) arrive and reside in the sys-
tem for constant time duration x. Arrivals occur at rate λ
when there are no customers present in the system, at rate
λ∗ (1− s) when there is one customer present in the system,
at rate λ ∗ (1 − s)
when there are two customers present in
the system, and so on.
2
The average throughput in this system is identical to that
in a similar system, but with exponentially distributed cus-
tomer residence times of mean duration x. The average
throughput can therefore be computed numerically as the
solution of an inﬁnite state one-dimensional Markov chain
with transition rate from state i to i + 1 of λ ∗ (1 − s)
and
from state i + 1 to i of i+1
x , for all i ≥ 0. A lower bound
i
on required server bandwidth can then be (numerically) ob-
tained by dividing the object into arbitrarily small portions,
and summing over all portions, the size of the portion times
1
1−p times the throughput computed from the Markov chain
analysis for the corresponding time oﬀset x.
B. ASYMPTOTIC ANALYSIS OF RPB
The results presented in Figure 6 suggest that as the param-
eters n and s of the new periodic broadcast protocols are
increased, the start-up delay approaches that of the lower
bound. The following asymptotic analysis of the segment
size progression supports this result.
Fix n, and let s and K/s grow large, so that each segment
becomes inﬁnitesimally small in length and delivery rate,
and so that the start-up delay approaches zero. Further, let
n ’th segment (0  1. From this geometric progres-
sion we can conclude that if the ﬁrst segment is normalized
to length 1, then the sum of the lengths of all K segments
with this normalization is asymptotically O(ebn K
s ). Thus,
since the start-up delay d is equal to a times the length
of the ﬁrst segment, and using n = sr, we have that d is
O(ae−brK ). Solving for the server bandwidth rK yields a
required server bandwidth of
1
b
For large n, 1
ln(
1
d ) + lower order terms
(16)
b tends to a. If a is chosen equal to 1
1−p (the
smallest a for which full recovery from loss can be possible
without extra delay at the clients, given loss rate p), we
obtain a required server bandwidth that is asymptotically
the same as the lower bound given in equation (4).
Interestingly, for a = 1 (i.e., the no packet loss case),
and general n, we get b = 1 − e−bn, implying that 1
b is
identical to the constant ηn, deﬁned in [10]. This implies
that the asymptotic required server bandwidth for general
n (and large s), in this no packet loss case, is identical to
the conjectured asymptotic lower bound on required server
bandwidth for general n from [10].