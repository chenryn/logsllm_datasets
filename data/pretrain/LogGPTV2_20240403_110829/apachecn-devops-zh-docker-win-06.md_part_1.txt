# 六、使用 Docker 组合组织分布式解决方案
发货软件是 Docker 平台不可或缺的一部分。Docker Hub 上的官方存储库使得使用久经考验的组件设计分布式解决方案变得容易。在前一章中，我向您展示了如何将这些组件集成到您自己的解决方案中，采用容器优先的设计方法。最终的结果是一个具有几个移动部分的分布式解决方案。在本章中，您将学习如何使用 Docker Compose 将所有这些移动部件组织成一个单元。
Docker Compose 是 Docker 公司的另一个开源产品，它扩展了 Docker 生态系统。Docker **命令行界面** ( **CLI** )和 Docker API 处理单个资源，如映像和容器。Docker Compose 在更高的层次上工作，提供服务和应用。*应用*是由一个或多个服务组成的单一单元，这些服务在运行时作为容器部署。您可以使用 Docker Compose 来定义应用的所有资源—服务、网络、卷和其他 Docker 对象—以及它们之间的依赖关系。
Docker 编写了两个部分。设计时元素使用 YAML 规范在标记文件中捕获应用定义，在运行时 Docker Compose 可以从 YAML 文件管理应用。我们将在本章中讨论这两个问题:
*   使用 Docker 编写定义应用
*   使用 Docker 编写管理应用
*   配置应用环境
Docker Compose is installed as part of Docker Desktop on Windows. If you install Docker on Windows Server using the PowerShell installer, that doesn't give you Docker Compose. You can download it from the releases on GitHub at `docker/compose`.
# 技术要求
您将需要在更新为 18.09 的 Windows 10 或 Windows Server 2019 上运行 Docker 来完成示例。本章代码见[https://github . com/six eyes/docker-on-window/tree/第二版/ch06](https://github.com/sixeyed/docker-on-windows/tree/second-edition/ch06) 。
# 使用 Docker 编写定义应用
Docker 编写文件格式非常简单。YAML 是一种人类可读的标记语言，编写文件规范使用与 Docker CLI 相同的选项名称来捕获您的应用配置。在撰写文件中，您可以定义组成应用的服务、网络和卷。网络和卷与 Docker 引擎使用的概念相同。服务是对容器的抽象。
一个*容器*是一个组件的单个实例，它可以是从网络应用到消息处理器的任何东西。一个服务可以是在不同容器中运行的同一个组件的多个实例，所有实例都使用相同的 Docker 映像和相同的运行时选项。您可以在用于 web 应用的服务中有三个容器，在用于消息处理程序的服务中有两个容器:
![](img/350dcfa9-dead-4008-84d7-0c4d7e999a8e.png)
一个*服务*就像一个模板，用一个已知的配置从一个映像运行一个容器。使用服务，您可以扩展应用的组件—从同一个映像运行多个容器，并将它们作为一个单元进行配置和管理。服务不在独立的 Docker 引擎中使用，但它们在 Docker Compose 中使用，并且还与在 Docker Swarm 模式下运行的一组 Docker 引擎一起使用(我将在下一章中介绍， [【第 7 章】](07.html)*使用 Docker Swarm* 编排分布式解决方案。
Docker 为服务提供了可发现性，就像它为容器提供服务一样。消费者通过名称访问服务，Docker 可以在服务中的多个容器之间对请求进行负载平衡。服务中的实例数量对消费者来说是透明的；它们总是引用服务名，流量总是被 Docker 定向到单个容器。
在这一章中，我将使用 Docker Compose 来组织我在前一章中构建的分布式解决方案，用一个可靠的、生产就绪的 Docker Compose 文件来替换脆弱的`docker container run` PowerShell 脚本。
# 捕获服务定义
可以在合成文件中以任何顺序定义服务。为了更容易阅读，我更喜欢从最简单的服务开始，这些服务没有依赖关系——**基础设施组件**，例如消息队列、反向代理和数据库。
Docker Compose 文件按惯例称为`docker-compose.yml`，它们以 API 版本的显式语句开始；最新的是 3.7 版本。应用资源在顶层定义—这是一个模板合成文件，包含服务、网络和卷的部分:
```
 version: '3.7'
  services:
    ...
  networks:
    ...
  volumes:
    ...
```
The Docker Compose specification is documented at the Docker website at [https://docs.docker.com/compose/compose-file/](https://docs.docker.com/compose/compose-file/). This lists the full specification for all supported versions, and the changes between the versions.
所有资源都需要一个唯一的名称，这个名称就是资源引用其他资源的方式。服务可能依赖于网络、卷和其他服务，这些都是通过名称捕获的。每个资源的配置都在自己的部分，可用的属性与 Docker CLI 中相应的`create`命令大致相同，例如`docker network create`和`docker volume create`。
在本章中，我将为分布式 NerdDinner 应用构建一个组合文件，并向您展示如何使用 Docker 组合来管理应用。我将首先从公共服务开始编写我的文件。
# 定义基础设施服务
我拥有的最简单的服务是消息队列 **NATS** ，它没有依赖关系。每个服务都需要一个名称和映像名称来启动容器。可选地，您可以包括您将在`docker container run`中使用的参数。对于 NATS 消息队列，我添加了一个网络名称，这意味着为该服务创建的任何容器都将连接到`nd-net`网络:
```
message-queue:
  image: dockeronwindows/ch05-nats:2e
 networks:
    - nd-net 
```
在这个服务定义中，我拥有启动消息队列容器所需的所有参数:
*   `message-queue`是服务的名称。这成为其他服务访问 NATS 的域名系统入口。
*   `image`是启动容器的映像的全名。在这种情况下，它是我的 Windows Server 2019 版本的 Docker Hub 官方 NATS 映像，但是您也可以通过在映像名称中包含注册表域来使用私有注册表中的映像。
*   `networks`是容器启动时要连接的网络列表。该服务连接到一个名为`nd-net`的网络。这将是一个 Docker 网络，用于该应用中的所有服务。稍后在 Docker Compose 文件中，我将明确捕获网络的细节。
I haven't published any ports for the NATS service. The message queue is only used internally by other containers. Within a Docker network, containers can access ports on other containers without them being published to the host. This keeps the message queue secure, as it is only accessible through the Docker platform by other containers in the same network. No external server and no applications running on the server can access the message queue.
# 弹性搜索
下一个基础设施服务是 **Elasticsearch** ，它也不依赖于其他服务。它将由消息处理程序使用，该程序也使用 NATS 消息队列，因此我需要将所有这些服务加入同一个 Docker 网络。对于 Elasticsearch，我还想限制它使用的内存量，并为数据使用一个卷，以便将数据存储在容器之外:
```
 elasticsearch:
   image: sixeyed/elasticsearch:5.6.11-windowsservercore-ltsc2019
 environment: 
     - ES_JAVA_OPTS=-Xms512m -Xmx512m
   volumes:
     - es-data:C:\data
   networks:
     - nd-net
```
这里，`elasticsearch`是服务的名称，`sixeyed/elasticsearch`是映像的名称，这是我在 Docker Hub 上的公共映像。我正在将服务连接到同一个`nd-net`网络，并且我还将一个卷装载到容器中的已知位置。当 Elasticsearch 将数据写入容器上的`C:\data`时，它实际上会存储在一个卷中。
就像网络一样，卷是 Docker Compose 文件中的一流资源。对于弹性搜索，我正在将一个名为`es-data`的卷映射到容器中的数据位置。稍后我将在合成文件中指定如何创建`es-data`卷。
# 特拉菲克
接下来是反向代理，Traefik。代理在创建容器时根据标签构建其路由规则，因此它需要连接到 Docker API:
```
reverse-proxy:
  image: sixeyed/traefik:v1.7.8-windowsservercore-ltsc2019
  command: --docker --docker.endpoint=npipe:////./pipe/docker_engine --api
 ports:
    - "80:80"
 - "8080:8080"
  volumes:
    - type: npipe
      source: \\.\pipe\docker_engine
      target: \\.\pipe\docker_engine 
  networks:
    - nd-net
```
Traefik 容器发布到主机上的端口`80`，连接到应用网络，并为 Docker API 命名的管道使用一个卷。这些是我用`docker container run`启动 Traefik 时使用的相同选项；通常，您可以将运行命令复制到 Docker Compose 文件中。
在 Docker Compose 中，端口发布与运行容器时相同。您可以指定要发布到哪个容器端口以及应该发布到哪个主机端口，因此 Docker 会将传入的主机流量路由到该容器。`ports`部分允许多个映射，如果您有特定要求，您可以选择指定 TCP 或 UDP 协议。
I'm also publishing port `8080` and using the `--api` flag in the Traefik configuration. This gives me access to Traefik's dashboard, where I can see all the routing rules Traefik has configured. This is useful in non-production environments, to check your proxy rules are correct, but this is not something you want exposed publicly in production.
Docker Compose 也支持扩展定义，我将它用于`volume`规范。我没有使用单行来定义卷装载，而是将卷的类型、源和目标分成了不同的行。这是可选的，但它使文件更容易阅读。
# 马纳人
**Kibana** 是第一个依赖其他服务的服务——它需要运行 Elasticsearch，以便能够连接到数据库。Docker Compose 没有给出任何关于它创建容器的顺序的保证，所以如果您在服务之间有一个启动依赖，您需要在服务定义中捕获它:
```
kibana:
  image: sixeyed/kibana:5.6.11-windowsservercore-ltsc2019
  labels:
    - "traefik.frontend.rule=Host:kibana.nerddinner.local"
  depends_on:
    - elasticsearch
  networks:
    - nd-net
```
`depends_on`属性展示了如何捕获服务之间的依赖关系。在这种情况下，Kibana 依赖于 Elasticsearch，因此 Docker 将在启动`kibana`服务之前确保`elasticsearch`服务已启动并运行。
Capturing dependencies like this is fine for running distributed applications on a single machine, but it doesn't scale. When you're running in a cluster you want the orchestrator to manage distributing the workload. It can't do that effectively if you have explicit dependencies, because it needs to make sure all the containers running the dependent service are healthy before it starts the consuming containers. There are better ways of managing dependencies that we'll see when we look at Docker Swarm.
基巴纳将由特拉菲克代理，但特拉菲克不需要在基巴纳之前运行。当 Traefik 启动时，它会从 Docker API 中获取一个正在运行的容器列表，以构建其初始路由映射。然后，它从 Docker 订阅事件流，以便在创建或移除容器时更新路由规则。因此，Traefik 可以在 web 容器之前或之后启动。
`kibana`服务的容器也连接到应用网络。在另一种配置中，我可以有单独的后端和前端网络。所有基础设施服务将连接到后端网络，面向公众的服务将连接到后端和前端网络。这两个都是 Docker 网络，但是将它们分开可以让我灵活地以不同的方式配置网络。
# 配置应用服务
到目前为止，我指定的基础设施服务不需要太多的应用级配置。我已经用网络、卷和端口配置了容器和 Docker 平台之间的集成点，但是应用使用构建在每个 Docker 映像中的配置。
基巴纳映像按照惯例使用主机名`elasticsearch`连接到弹性搜索，这是我在 Docker Compose 文件中使用的支持该惯例的服务名。Docker 平台会将任何到`elasticsearch`主机名的请求路由到服务，如果有多个容器运行该服务，则在容器之间进行负载平衡，因此 Kibana 将能够在预期的域名找到 Elasticsearch。
我的自定义应用需要指定配置设置，我可以使用环境变量将这些设置包含在合成文件中。在组合文件中为服务定义环境变量会为运行该服务的每个容器设置这些环境变量。
索引晚餐消息处理程序服务订阅 NATS 消息队列并在 Elasticsearch 中插入文档，因此它需要连接到同一个 Docker 网络，并且它也依赖于这些服务。我可以在合成文件中捕获这些依赖关系，并为应用指定配置:
```
nerd-dinner-index-handler:
  image: dockeronwindows/ch05-nerd-dinner-index-handler:2e
  environment:
    - Elasticsearch:Url=http://elasticsearch:9200
    - MessageQueue:Url=nats://message-queue:4222
  depends_on:
    - elasticsearch
    - message-queue
  networks:
    - nd-net
```
这里，我使用`environment`部分来指定两个环境变量——每个变量都有一个键值对——来配置消息队列和弹性搜索的 URL。这些实际上是烘焙到消息处理程序映像中的默认值，所以我不需要将它们包含在合成文件中，但是显式设置它们会很有用。
You can think of the Compose file as the complete deployment guide for the distributed solution. If you explicitly specify the environment values, it makes it clear what configuration options are available, at the cost of making your Compose file less manageable.
对于简单的应用设置，以纯文本形式存储配置变量是可以的，但是对于敏感值，使用单独的环境文件更好，这是我在上一章中使用的方法。撰写文件格式也支持这一点。对于数据库服务，我可以使用环境文件作为管理员密码，用`env-file`属性指定:
```
nerd-dinner-db: