With data flow linearization (DFL), we devise a new abstraction for
controlling the data access patterns influenced by secret data, so that
arbitrarily different (secret) inputs will lead to the same observable
program behavior for an attacker. As we discuss in our security
evaluation of §5, this design hardens against side-channel attacks
that prior solutions cannot handle and it does not suffer from leaks
through data-flow invariants and memory safety violations as we
saw for such solutions in §2. Furthermore, thanks to its combination
with points-to analysis, DFL is the first solution that does not place
restrictions on pointer and object types, supporting for instance
pointer-to-pointer casts that occur in real-world crypto code.
DFL: For every program point that performs a memory load or store
operation, DFL obliviously accesses all the locations that the original
program can possibly reference for any initial input.
To support this invariant we conduct a context-sensitive, field-
sensitive points-to analysis (described in §4.4.2) to build DFL meta-
data for each use of a pointer expression in a sensitive load or store
instruction. Such metadata describes the portions of the object(s)
that the expression may reference each time the program evalu-
ates it. We assume that only program-allocated memory can hold
secret-dependent data (external library calls cannot leak from §3).
For dynamic storage, that is stack- and heap-allocated objects,
we instrument the involved allocation sites in the program to keep
track at run time of the object instances currently stemming from
an allocation site of interest to DFL (rightmost part of Figure 1).
DFL uses indirection around incoming pointer values: it obliv-
iously accesses all the candidate object portions identified by the
Session 3A: Side Channel CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea720typedef struct dfl_obj_list {
struct dfl_obj_list * next ;
struct dfl_obj_list * prev ;
struct dfl_obj_list ** head_ptr ;
unsigned long magic ;
unsigned char data [];
// for fast removal from list
// to distinguish DFL heap objects
// contents of program object
} dfl_obj_list_t ;
Figure 4: In-band metadata for data flow linearization.
points-to analysis, and retrieves or modifies the memory value only
within the object instance (if any) corresponding to the incoming
pointer value. We apply DFL to every memory load or store made
in a code region linearized by CFL (where the operation will see
an incoming ⊥ value when on a decoy path), and to memory op-
erations that are outside input-dependent control flows but still
secret-sensitive (e.g., array accesses with input-dependent index).
Unlike prior solutions, we do not need a shadow location for
decoy paths (accessing it would leak the nature of such paths, §2),
nor we let rogue pointers concur to memory accesses. Our design
makes data accesses oblivious to secret dependencies and to the
nature of control paths, and preserves memory safety in the process.
4.3.1 Load and Store Wrappers. For the linearization of the data
flow of accessed locations, we use ct_load and ct_store primi-
tives for DFL indirection and resort to different implementations
optimized for the storage type and the size of the object instances
to stride obliviously. As we discussed when presenting the CFL
stage, we accompany each use of a pointer expression in a load or
store with DFL metadata specific to the program point.
DFL metadata capture at compilation time the points-to infor-
mation for all the allocation sites of possibly referenced objects.
The analysis comprises stack allocations, objects in global memory,
and heap allocation operations. For each site, we use field-accurate
information to limit striding only to portions of an object, which
as a whole may hold thousands of bytes in real-world code.
Depending on the scenario, the user can choose the granular-
ity λ at which memory accesses should become oblivious to an
adversary. One may only worry about cache attacks (λ = 64) if,
say, only cross-core (cache) attacks are to be mitigated (e.g., with
cloud vendors preventing core co-location across security domains
by construction [5]). Or one may worry about arbitrary attacks if,
say, core colocation across security domains is possible and attack
vectors like MemJam (λ = 4) are at reach of the attacker.
Our wrapper implementations stride an object portion with a
pointer expression incremented by λ bytes every time and which
may match the incoming p input pointer from the program at most
once. Depending on the object portion size, DFL picks between stan-
dard AVX instructions for striding, AVX2/AVX512 gather-scatter
sequences to load many cache lines at once followed by custom
selection masks, and a cmov-based sequence that we devise to avoid
the AVX setup latency for small objects (details in Appendix C).
The DFL load and store wrappers inspect all the allocation sites
from the metadata. For global storage only a single object instance
exists; for stack and heap objects the instances may change during
the execution, and the wrappers inspect the run-time metadata that
the transformed program maintains (using doubly linked lists and
optimizations that we describe in the next sections).
For a load operation, DFL strides all the object instances that the
program point may reference and conditionally selects the value
from the object portion matching the desired address. For decoy
paths, no match is found and ct_load returns a default value.
For a store operation, DFL breaks it into a load followed by a store.
The rationale is to write to every plausible program point’s target,
or the adversary may discover a secret-dependent write destination.
For every object portion identified by DFL store metadata, we read
the current value and replace it with the contents for the store only
when the location matches its target, otherwise we write the current
value back to memory. Decoy paths “refresh” the contents of each
object; real paths do the same for all but the one they modify.
4.3.2 Object Lifetime. DFL metadata supplied at memory oper-
ations identify objects based on their allocation site and charac-
teristics. While global storage is visible for the entire execution,
stack and heap locations have a variable lifetime, and we need to
maintain run-time metadata for their allocation sites.
We observe that real-world crypto code frequently allocates large
structures on the stack and pointers seen at memory operations
may reference more than one such structure. At the LLVM IR level,
stack-allocated variables take the form of alloca instructions that
return a pointer to one or more elements of the desired type. The
compiler automatically releases such storage on function return.
We interpose on alloca to wrap the object with in-band meta-
data information depicted in Figure 4. Essentially, we prepend the
originally allocated element with fields that optimize DFL opera-
tions and preserve stack alignment: the program element becomes
the last field of a variable-sized dfl_obj_list_t structure. Then,
we assign the virtual register meant to contain the v pointer from
alloca with the address of v.data (32-byte offset on x64).
This transformation is simple when operating at the compiler
IR level: unlike binary rewriting scenarios [25], the compiler is free
to modify the stack layout while preserving program semantics,
including well-behaved pointer arithmetics. Upon alloca interpo-
sition, we make the program update the run-time allocation site
information and a symmetric operation happens on function exit.
Heap variables see a similar treatment. We interpose on allo-
cation operations to widen and prepend the desired object with
in-band metadata, with the address of v.data returned to the pro-
gram instead of the allocation base v. The v.magic field is pivotal
for handling free() operations efficiently: when interposing on
them, we may witness a dfl_obj_list_t structure or a “standard”
object from other program parts. We needed an efficient means to
distinguish the two cases, as free() operations take the allocation
base as input: for DFL objects we have to subtract 32 from the
input pointer argument. We leverage the fact that allocators like
the standard libc allocator ptmalloc prepend objects with at least
one pointer-sized field. Hence accessing a heap pointer p as p − 8
is valid: for DFL objects it would be the address of the magic field
and we check its peculiar value to identify them.
4.3.3 Optimizations. One advantage of performing DFL at com-
piler IR level is that we can further optimize both the data layout
to ease metadata retrieval and the insertion of our DFL wrappers.
We identify functions that do not take part in recursive patterns
and promote to global variables their stack allocations that sen-
sitive accesses may reference. The promotion is sound as such a
function can see only one active stack frame instance at a time.
The promotion saves DFL the overhead of run-time bookkeeping,
Session 3A: Side Channel CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea721with faster metadata retrieval for memory operations as we discuss
next. To identify functions apt for promotion, we analyze the call
graph of the program (made only of direct calls after IR normaliza-
tion) to identify strongly connected components from recursion
patterns [83] and exclude functions taking part in them.
We also partially inline DFL handlers, as object allocation sites
are statically known from points-to analysis. For global storage, we
also hard-code the involved address and striding information. For
instance, a load operation from address ptr becomes in pseudo-code:
res = 0
res |= dfl_glob_load(ptr, glob1, stride_offset_g1, stride_size_g1)
res |= dfl_glob_load(ptr, glob2, stride_offset_g2, stride_size_g2)
res |= dfl_load(ptr, objs_as1, stride_offset_as1, stride_size_as2)
res |= dfl_load(ptr, objs_as2, stride_offset_as2, stride_size_as2)
res |= dfl_load(ptr, objs_as3, stride_offset_as2, stride_size_as2).
This is because the oracle determined that ptr may reference
(portions of) global storage glob1, glob2 or objects from allocation
sites as1, as2, as3, where objs_asi is the pointer to the data structure
(a doubly linked list of objects, as with AS2 in Figure 1) maintained
at run time for the allocation site (§4.3.2). With the OR operations
we perform value selection, as each dfl_ helper returns 0 unless the
intended location ptr is met during striding. In other words, instead
of maintaining points-to sets for memory operations as data, we
inline their contents for performance (saving on retrieval time) and
leave the LLVM optimizer free to perform further inlining of dfl_
helpers code. The treatment of store operations is analogous.
Finally, we devise an effective (§7) striding optimization for loops.
We encountered several loops where the induction variable flows in
a pointer expression used to access an object, and from an analysis
of its value (based on LLVM’s scalar evolution) we could determine
an invariant: the loop would be touching all the portions that require
DFL striding and a distinct portion at each iteration. In other words,
the code is “naturally” striding the object: we can avoid adding DFL
striding and thus save on n(n − 1) unnecessary accesses.
4.4 Support Analyses
The compatibility of Constantine with real-world code stems also
from two “oracles” as we tailor robust implementations of main-
stream program analysis techniques to our context: an information
flow tracking technique to identify program portions affected by a
secret and a points-to analysis that we enhance with context sensi-
tivity to obtain points-to sets as accurate as possible.
Identifying Sensitive Program Portions. Control and data flow
4.4.1
linearization need to be applied only to regions affected by secret
data, as protecting non-leaky code only hampers performance.
We assume the user has at their disposal a profiling suite to
exercise the alternative control and data flow paths of the crypto
functionality they seek to protect. Developers can resort to existing
test suites for libraries, actual workloads, or program testing tools
(e.g. generic [27] or specialized [34] fuzzers) to build one.
We then use DataFlowSanitizer (DFSan), a dynamic information
flow tracking solution for LLVM, to profile the normalized IR of
§4.2.2 over the profiling suite. DFSan comes with taint propaga-
tion rules for virtual registers and program memory and with APIs
to define taint source and sink points. We write taint source con-
figurations to automatically taint data that a program reads via
I/O functions (e.g., a key file) and use as sink points conditionals,
memory load/store operations, and div/rem instructions in the nor-
malized IR. In the DFSan-transformed IR we then encode rules in
the spirit of FlowTracker [55] to handle implicit flows among vir-
tual registers, leaving those possibly taking place through memory
to complementary tools like FTI [30].
We aggregate DFSan outputs to build a set of branches and
memory accesses that are secret-dependent, feeding it to CFL and
DFL. As we mentioned in §4.2, CFL will then push the hardening
process to nested flows, linearizing their control and data flows.
During the execution of the profiling suite we also profile loop trip
counts that we later use as initial predictions for CFL (§4.2.4).
4.4.2 Points-to Analysis. Points-to analyses [60] determine the
potential targets of pointers in a program. Nowadays they are
available off-the-shelf in many compilation systems, with inclusion-
based approaches in Andersen style [9] typically giving the most
accurate results. In Constantine, we extend the Andersen-style
analysis of the popular SVF library for LLVM [68]. For each pointer
usage in the program, we use this analysis to build the points-to
set of objects that it may reference at run time. Typically, points-
to analyses collapse object instances from a dynamic allocation
site into an abstract single object. Hence, points-to sets contain
information on object allocation sites and static storage locations.
Points-to analyses are sound. However, they may overapproxi-
mate sets by including objects that the program would never access
at run time. In a lively area of research, many solutions feature
inclusion-based analyses as the approach is more accurate than
the alternative, faster unification-based one [64]. Inclusion-based
analyses could give even more accurate results if they were to scale
to context sensitivity, i.e., they do not distinguish the uses of pointer
expressions (and thus potentially involved objects) from different
execution contexts. The context is typically intended as call-site
sensitivity, while for object-oriented managed languages other defi-
nitions exist [47, 61]. To optimize the performance of DFL, we need
as accurate points-to sets as possible, so in Constantine we try to
restore context sensitivity in an effective manner for a sufficiently
large codebase such as the one of a real-world crypto library.
Aggressive Cloning. We use function cloning to turn a context-
insensitive analysis in a context-sensitive one. A calling context [23]
can be modeled as an acyclic path on the call graph and one can cre-
ate a function clone for every distinct calling context encountered
during a graph walk. This approach can immediately spin out of
control, as the number of acyclic paths is often intractable [24, 79].
Our scenario however is special, as we may clone only the func-
tions identified as secret-dependent by the other oracle, along with
their callees, recursively. We thus explore aggressive cloning along
the maximal subtrees of the call graph having a sensitive function
as root. The rationale is that we need maximum precision along
the program regions that are secret-dependent, while we can settle
for context-insensitive results for the remainder of the program,
which normally dominates the codebase size.
Aggressive cloning turns out to be a key performance enabler,
making DFL practical and saving on important overheads. As we
discuss in §7, for wolfSSL we obtain points-to sets that are ~6x
smaller than the default ones of SVF and very close to the run-
time optimum. The price that we trade for such performance is an
increase in code size: this choice is common in much compiler re-
Session 3A: Side Channel CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea722search, both in static [51] and dynamic [18] compilation settings, for
lucrative optimizations such as value and type-based specialization.
Refined Field Sensitivity. A field-sensitive analysis can distinguish
which portions of an object a pointer may reference. Real-world
crypto code uses many-field, nested data structures of hundreds
or thousands of bytes, and a load/store operation in the program
typically references only a limited portion from them. Field-accurate
information can make DFL striding cheaper: this factor motivated
our practical enhancements to the field-sensitive part of SVF.
The reference implementation fails to recover field-precise in-
formation for about nine-tenths of the wolfSSL accesses that un-
dergo DFL, especially when pointer arithmetics and optimizations
are involved. We delay the moment when SVF falls back to field-
insensitive abstract objects and try to reverse-engineer the structure
of the addressing so to fit it into static type declarations of portions
of the whole object. Our techniques are inspired by duck typing
from compiler research; we cover them in Appendix D. Thanks to
these refinements, we could recover field-sensitive information for
pointers for 90% of the sensitive accesses in our case study.
Indirect Calls. Points-to analysis also reveals possible targets
for indirect calls [68]. We use this information during IR normal-
ization when promoting them to if-series of guarded direct calls
(§4.2.2), so to remove leaks from variable targets. We refine the can-
didates found by SVF at call sites by matching function prototype
information and eliminating unfeasible targets. Indirect call target
information is also necessary for the aggressive cloning strategy.
4.5 Discussion
Constantine implements a compiler-based solution for eliminat-
ing microarchitectural side channels while coping with the needs of
real-word code. We chose LLVM for its popularity and the availabil-
ity of mature information-flow and points-to analyses. Nonetheless,
our transformations are general and could be applied to other com-
pilation toolchains. Similarly, we focus on x86/x64 architectures,
but multiplexing conditional-assignment and SIMD striding instruc-
tions exist for others as well (e.g. ARM SVE [66] , RISC-V “V” [4]).
Moreover, operating at the compiler IR level allows us to effi-
ciently add a level of indirection, with taken unleashing the opti-
mizer and with DFL making memory accesses oblivious to incoming
pointers. In addition, aggressive function cloning allows us to trans-
form the codebase and unveil a significantly more accurate number
of objects to stride. The IR also retains type information that we
can leverage to support field sensitivity and refine striding.
The just-in-time strategy to linearize secret-dependent unbounded
control flows (loops) allows us to dodge intractability with high
bounds and code bloat with tractable instances [62]. For points-to
set identification and indirect call promotion, our analyses yield
very accurate results (i.e., closely matching the run-time accesses)
on the programs we consider. We leave the exploration of a just-
in-time flavor for them to future work, which may be helpful in
non-cryptographic applications.
The main shortcoming of operating at the IR level is the inability
to handle inline assembly sequences found in some crypto libraries.
While snippets that break constant-time invariants are uncom-
mon, they still need special handling, for instance with annotations
or lifting. Verification-oriented lifting [54], in particular, seems a
promising avenue as it can provide formally verified C equivalent
representations that we could use during IR normalization.
As the programs we study do not exercise them, for space lim-
itations we omit the treatment of recursion and multithreading.
Appendix E details the required implementation extensions.
5 SECURITY ANALYSIS
This section presents a security analysis of our transformations.
We start by arguing that instrumented programs are semantically
correct and induce secret-oblivious code and data access traces.
We then discuss how our design emerges unscathed by traditional
passive and active attacks and examine the residual attack surface.
Correctness and Obliviousness. Correctness follows directly from
our design, as all our transformations are semantics-preserving. In
short, for control flows, real paths perform all and only the com-
putations the original program would make. For data flows, values
from decoy paths cannot flow into real paths and correctness prop-
erties such as memory safety are preserved. Appendix F provides
informal proofs for these claims.