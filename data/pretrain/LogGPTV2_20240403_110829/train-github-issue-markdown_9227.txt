I am currently working on an IBM POWER9 Series cluster and have encountered some challenges while performing Fast Fourier Transforms (FFT) using PyTorch. Specifically, I need to transfer the data to the GPU for the FFT computation and then transfer it back to the CPU, which results in a poor user experience. This issue is particularly problematic when the related code is called within a `DataLoader`, as it forces me to disable multi-worker loading to prevent errors.

Here is an example of the code that triggers the error:

```python
import torch

x = torch.randn(10, 10, 2)
torch.fft(x, 1)
```

The error message I receive is as follows:

```
Traceback (most recent call last):
  File "", line 1, in 
RuntimeError: fft: ATen not compiled with MKL support
```

This indicates that the ATen library, which PyTorch relies on for tensor operations, was not compiled with Intel's Math Kernel Library (MKL) support, which is necessary for efficient FFT computations on the CPU.