### Clickstream Analysis for Detecting Suspicious Accounts

#### Data Collection and Training
We utilized clickstream data from 10,000 users, including 8,000 randomly selected users and 2,000 previously identified as suspicious by the security team. These clickstreams were collected between January 17–27, 2013. Additionally, 500 verified honest users, manually confirmed by Renren’s security team, served as seed data. After training our system, we classified clickstreams from 1 million random users (collected in early February 2013) to identify normal or suspicious activity. Our system successfully identified 22,000 potential Sybil accounts, which are now under investigation by the security team.

#### Feedback and New Attack Detection
While corporate privacy policies prevented Renren from sharing detailed results, their feedback was highly positive. They noted that our system detected a new type of attack involving a large cluster of users focusing on photo sharing. Manual inspection revealed that these photos contained embedded text promoting spam for clothing and shoe brands. Traditional text analysis-based spam detectors and URL blacklists failed to catch this new attack, but our system identified it immediately.

#### Figures and Analysis
- **Figure 17**: Detection accuracy versus the number of seeds.
- **Figure 18**: Detection accuracy versus the Normal-Sybil ratio.
- **Figure 19**: Clicks per day by outlier normal users.

#### LinkedIn Case Study
LinkedIn’s security team used our software to analyze the clickstreams of 40,000 users, including 36,000 randomly sampled and 4,000 previously identified as suspicious. The feedback was again very positive, though precise statistics were not provided. Our system confirmed that approximately 1,700 of the 4,000 suspicious accounts are likely Sybils and detected an additional 200 previously unknown Sybils.

A closer examination of the data showed that many undetected accounts had borderline characteristics, such as unusual names, occupational specialties, or suspicious URLs in their profiles. This highlights the importance of using behavior models in conjunction with existing profile analysis tools and spam detectors.

#### Ongoing Collaboration
The security teams at both Renren and LinkedIn were pleased with the initial results. We plan to continue collaborating with both organizations to improve our system and implement it in production environments.

### Limits of Sybil Detection
In the worst-case scenario, attackers with full knowledge of real user clickstream patterns can mimic these behaviors to evade detection. To avoid detection, Sybils must limit their activities to those consistent with normal users. We can estimate the maximum malicious activity a Sybil could perform without being caught by studying the most aberrant behavior within "normal" clusters.

#### Outlier Behavior
We calibrated our system to produce clusters with a false positive rate of less than 1% using Hybrid/5gram+count and K = 100. In this configuration, the detector outputs 40 Sybil and 60 normal clusters. We identified the two farthest outliers in each normal cluster and plotted the clicks per day for three activities: sending friend requests, posting status updates/wall messages, and viewing user profiles. As shown in Figure 19, 99% of outliers generate ≤10 clicks per day in the target activities, with the vast majority generating <2 clicks per day. These tight bounds significantly increase the cost for attackers, as they need more Sybils to maintain the same level of spam generation capacity.

### Related Work
#### Sybil Detection on OSNs
Studies have shown that Sybils are responsible for significant amounts of spam on platforms like Facebook, Twitter, and Renren. Various systems have been proposed, including social graph-based approaches and machine learning techniques. However, recent studies have highlighted the limitations of these methods, particularly in detecting Sybils that blend into the social graph.

#### Web Usage Mining
Researchers have studied web usage patterns for over a decade, focusing on session-level analysis, clustering, Markov Chain models, and tree-based models. While most literature characterizes normal user behavior, there is limited work on using clickstreams for anomaly detection. Our approach leverages clickstream models to detect malicious users, which has been validated on ground-truth data and has already identified new types of image-spam attacks on Renren.

### Conclusion
To our knowledge, this is the first work to leverage clickstream models for detecting malicious users in online social networks. Our results show that we can build an accurate Sybil detector by identifying and clustering similar clickstreams. Our system has been validated on ground-truth data and has already detected new types of image-spam attacks on Renren. We believe clickstream models can be a powerful technique for user profiling in various contexts, and we are currently exploring ways to extend these models to detect malicious crowdsourcing workers and forged online product and travel reviews.

### IRB Protocol
This work was conducted under an approved IRB protocol. All data was anonymized by Renren before use, and the clickstreams are old enough that the events they describe are no longer accessible via the current website. Experiments on recent user data were conducted on-site at Renren and LinkedIn, and all results remain on-site.

### Acknowledgments
We thank the anonymous reviewers for their feedback, Yanjie Liang (Renren), and David Freeman (LinkedIn) for their assistance in experiments. This work is supported in part by NSF grants CNS-1224100 and IIS-0916307, and DARPA GRAPHS (BAA-12-01). Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies.