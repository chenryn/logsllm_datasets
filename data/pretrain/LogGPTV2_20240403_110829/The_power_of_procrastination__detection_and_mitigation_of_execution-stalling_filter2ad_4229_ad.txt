sible paths that lead to errors (shown in the last row of Table 1).
We handle inconsistent variables as discussed in the previous sec-
tion, but the program might still show undesired behavior (such
as premature program exits or exceptions). The reason is that the
program could be forced down an error path that does not refer-
ence any tainted variable modiﬁed in the loop, but simply performs
some clean-up activities and then raises an exception. A prominent
example are the checks that are introduced by Microsoft’s compiler
to guard the return addresses on the stack against overﬂow corrup-
tion. As a result, when HASTEN encounters as exit point the condi-
tional branch that checks for stack corruption and forces execution
down this path, the program terminates with an exception (see the
next Section 8 for a discussion on how this can be addressed). Of
course, we discard all added behaviors that are due to exceptions
(such as the start of the debugger).
Overall, HASTEN detected the use of inconsistent variables dur-
ing 780 analysis runs in active mode. In 778 cases, INSPECTOR
needed to be invoked once, for two runs, two invocations were nec-
essary.
Discussion. Table 1 demonstrates that HASTEN was able to reveal
interesting added behavior for 1,552 (1,003 + 549) samples, using
the average improvement metrics. This number increases to 3,275
when considering the optimistic measure for additional behavior
(as shown in Table 4). This behavior relates to signiﬁcant activity,
such as ﬁle system accesses or network trafﬁc. Our numbers show
that HASTEN successfully found additional behavior in 24.5% (or
52.5%, when using the optimistic metrics) of the 6,237 samples
that contain some kind of loop that delays progress in a sandbox.
The failure to expose additional behavior for the remaining samples
has several reasons: Most often, some necessary resource (e.g., a
command and control server) was no longer available, thus, the
malware stopped its execution. In other cases, HASTEN switched
292Passive
Description
Table 1: Additional behavior observed in Hasten (using average improvement).
Active
% # AV families
−
231
22.3%
105
79
14.6%
4.4%
31
51
10.5%
41
3.6%
52
7.5%
11.2%
72
66.5%
174
63
11.2%
% # AV families
−
319
26.6%
119
113
25.2%
11.8%
52
15
0.6%
55
13.2%
82
14.9%
38.4%
128
35.0%
225
0
0.0%
Runs total
Added behavior (any activity)
- Added ﬁle activity
- Added network activity
- Added GUI activity
- Added process activity
- Added registry activity
Ignored (possibly random) activity
No new behavior
- Exception cases
# samples
2,467
549
359
108
260
90
184
276
1,642
277
# samples
3,770
1,003
949
444
24
499
561
1,447
1,320
0
into passive mode towards the end of the analysis timeframe, and
a timeout was encountered before additional behaviors could be
exposed. Finally, in some cases, HASTEN selected an error path
that lead to premature program termination.
We also wanted to understand in more detail the nature of the
stalling code introduced by malware authors. To this end, we fo-
cused our attention on the 1,552 samples that revealed added behav-
ior. While it is difﬁcult to determine with certainty that a particular
piece of code has been deliberately inserted by a malware author
to prevent dynamic analysis, we checked for the presence of many
repeated calls to API functions that serve no apparent purpose. In
particular, during manual analysis of a few samples, we observed
repeated calls to GetTickCount and GetCommandLine. We
then checked the prevalence of these calls in the execution traces of
the 1,552 samples. We found that more than a third of the sam-
ples (543) invoked one of these two functions more than 5,000
times inside a loop.
Even when considering the entire data set of 29,102 malware
programs, a surprisingly large number of samples contains stalling
code. This demonstrates that execution stalling is not a purely the-
oretical problem. Instead, a non-trivial fraction of malware in the
wild already includes such evasive techniques. Thus, it is crucial
that sandboxes are improved to handle this threat.
8. DISCUSSION AND LIMITATIONS
As mentioned previously, the ﬁght against malicious code is an
arms race, and malware authors always strive to improve their pro-
grams to resist new analysis and detection approaches. In this sec-
tion, we discuss the robustness of our approach and possible, future
improvements to further harden our techniques.
Malware authors can target each of the three modes of HAS-
TEN: First, the stalling loop could be crafted so that it delays the
execution of malicious activity in the sandbox without triggering
any of the detectors in monitoring mode. To this end, a malware
process would have to issue successful system calls with a fre-
quency and diversity similar to non-stalling programs. To counter
such mimicry attacks, we can add additional detectors that measure
progress in different ways. For example, we could count, for each
time interval, the number of distinct basic blocks that a program ex-
ecutes or the number of new (never before executed) basic blocks
that Qemu, our system emulator, has to translate. For stalling code,
we expect both values to be low. Moreover, we could opportunisti-
cally (and randomly) switch to passive mode every once in a while,
even when no detector has raised an alert.
Likewise, it is possible that long-lasting operations (e.g., the de-
cryption of large ﬁles) trigger one of our heuristics. Internally, we
refer to this as accidental stalling code, since the malware author
does not do this deliberately. This is similar to opportunistically
switching to passive mode and introduces only a minor perfor-
mance hit.
Passive mode is more difﬁcult to exploit for the attacker. While
we reduce the amount of information that is logged, we are careful
to preserve all security-relevant information. To this end, we only
whitelist code regions (basic blocks) that have previously been ex-
ecuted by the malware. For example, consider a malware author
who puts a piece of malicious code into the body of a stalling loop
and guards this code with a conditional branch. When the passive
mode recognizes the stalling loop, it will only whitelist the part of
the loop that has been executed before. The malicious code region,
on the other hand, will be excluded from reduced logging. More-
over, certain security-critical system calls are always recorded.
The active mode seems most vulnerable to attacks since it mod-
iﬁes the normal ﬂow of program execution, and, thus, could leave
the program in an inconsistent state or force it along an impossi-
ble path. HASTEN addresses the problem of inconsistent program
state by tracking the variables (memory locations) that stalling code
modiﬁes. Moreover, through taint analysis, all variables derived
from these memory locations are tracked as well. Whenever the
malware process attempts to check or use a potentially inconsistent
variable, its execution is suspended. Then, the system generates a
slice that will efﬁciently compute the variable’s correct value, and
this value is provided to the program before it is allowed to con-
tinue. Of course, a malware author can force our system to extract
and execute slices. However, as described in more detail in [18], the
slices that INSPECTOR generates are small, stand-alone executables
(gadgets) that can be executed directly on a native host. Moreover,
slice generation is fast. Thus, the stalling code will be run almost
as fast as on a native (victim) machine.
An important limitation is our current, simple technique to deter-
mine all variables (memory locations) that stalling code can write
to. Since this technique uses only dynamic information, it might
miss certain locations. One way to address this problem is to in-
corporate static analysis to identify and taint such variables. This
analysis can be conservative, as “over-tainting” can only result in
unnecessary calls to INSPECTOR but will not cause incorrect pro-
gram executions. Furthermore, it is possible that INSPECTOR can-
not extract a proper slice to compute a needed value. This is less of
a concern, as our previous work has shown that the tool is able to
extract meaningful slices from real-world malware programs that
span multiple functions and that contain non-trivial memory ac-
cesses. Also, INSPECTOR will report the failure to extract a slice,
allowing further manual inspection.
An attacker could also try to force HASTEN to skip a stalling loop
that contains malicious code (and thus, fail to observe malicious
activity). This is difﬁcult for the attacker because all conditional
293branches that exit any whitelisted stalling code region are possible
exit points. In particular, when there is previously non-executed,
malicious code inside a stalling loop, the branch that guards this
malicious code is considered as a possible exit point (in addition
to the loop exit). Recall that we only whitelist code that was pre-
viously executed; this implies that we will not whitelist the entire
body of a stalling loop when there are paths through this loop that
were not executed before.
In our current prototype, we force the program execution out of a
stalling region through the ﬁrst exit point that is encountered. This
has two drawbacks. First, we might skip malicious code inside the
loop (when the wrong exit point is chosen). Second, it is possi-
ble that HASTEN picks an incorrect (infeasible) loop exit path that
later results in a program exception (as mentioned in the previous
section, an example are error paths). To tackle these problems, we
can leverage the fact that our system has full control over the anal-
ysis environment. More precisely, we can create a snapshot of the
CPU and the memory before any active modiﬁcation to the pro-
gram’s control ﬂow. This way, HASTEN can later revert to previ-
ous snapshots and explore multiple exit paths in a more systematic
fashion. This is similar in spirit to a multi-path exploration of the
binary [21].
9. RELATED WORK
The idea of detecting and evading dynamic malware analyzers
is not new. In the past, malware authors have introduced checks,
so-called red pills, to detect execution inside a virtualized environ-
ment [13, 24]. Other work has proposed techniques to detect exe-
cution in system emulators, such as Qemu [20, 22, 23]. Yet other
research [1, 7] has discussed practical ﬁngerprinting techniques to
recognize public, dynamic malware analyzers (e.g., ANUBIS [2],
CWSANDBOX [3], JOEBOX, etc.). Fingerprinting a malware anal-
ysis system is particularly easy when the system provides a public
interface that accepts submissions from anywhere.
To mitigate the problem of checks that detect malware analyzers,
researchers have proposed transparent analysis environments [11,
12]. These systems leverage novel virtualization features of mod-
ern processors to implement a minimalistic hypervisor. This makes
it more difﬁcult to reveal the presence of the analysis platform.
Others have focused on the detection of differences between the
execution of a program in a virtual or emulated platform, and on
real hardware [6, 17]. The basic intuition is that any difference
between the executions in two different environments (using deter-
ministic replay) must be due to checks in a sample. If one can de-
termine that a sample is trying to evade analysis, the evasive check
can either be removed, or the sample can be marked for manual
inspection.
Finally, checks that detect the analysis environment can also be
bypassed by systems that perform multi-path exploration [9, 21,
28]. The idea is to ﬁrst identify conditional branches that depend
on some input read from the program’s environment (ﬁle system,
registry, network, ...). Once such a branch (check) is found, both
alternative execution branches can be explored. When the system
explores the branch that is different from the the current program
execution, care must be taken to keep the program state consistent.
In a related approach [10], the authors try to identify behaviors that
are triggered by timer events.
The crucial difference between previous research and this work
is that previous techniques focused on the detection and mitigation
of evasive checks. Such checks are inserted by malware authors to
identify dynamic analysis environments and, subsequently, change
the behavior of their programs. In this paper, we present the ﬁrst
solution to the growing problem of dynamically analyzing malware
samples that include stalling code. Stalling code does not use any
checks, and it does not alter the ﬂow of execution of the malware
program in a dynamic analysis environment. As a result, transpar-
ent platforms or systems that detect and remove evasive checks are
ineffective.
10. CONCLUSIONS
As new malware analysis solutions are introduced, attackers re-
act by adapting their malicious code to evade detection and analy-
sis. One recent form of evasion code for dynamic analysis systems
is stalling code. In this paper, we present the ﬁrst approach to de-
tect and mitigate malicious stalling code, and to ensure forward
progress within the amount of time allocated for the analysis of a
sample. Our results show that HASTEN works well in practice, and
is able to reveal additional behaviors in real-world malware sam-
ples that contain stalling code.
11. ACKNOWLEDGEMENTS
The research leading to these results has received funding from
the European Union Seventh Framework Programme under grant
agreement n. 257007 (SysSec), the Austrian Research Promotion
Agency (FFG) under grant 820854 (TRUDIE), the NSF under grant
CNS-1116777, the ONR under grant N000140911042, and the Na-
tional Science Foundation (NSF) under grants CNS-0845559 and
CNS-0905537. We also acknowledge Secure Business Austria for
their support.
This publication reﬂects the views only of the authors, and the
funding agencies cannot be held responsible for any use which may
be made of the information contained therein.
12. REFERENCES
[1] Forum Posting - Detection of Sandboxes.
http://www.opensc.ws/snippets/3558-
detect-5-different-sandboxes.html, 2009.
[2] http://anubis.iseclab.org, 2010.
[3] http://www.cwsandbox.org, 2010.
[4] http://www.norman.com/enterprise/all_
products/malware_analyzer/norman_
sandbox_analyzer/en, 2010.
[5] http://msdn.microsoft.com/en-us/library/
ms724408%28VS.85%29.aspx, 2010.
[6] BALZAROTTI, D., COVA, M., KARLBERGER, C.,
KRUEGEL, C., KIRDA, E., AND VIGNA, G. Efﬁcient
Detection of Split Personalities in Malware. In Network and
Distributed System Security Symposium (NDSS) (2010).
[7] BAYER, U., HABIBI, I., BALZAROTTI, D., KIRDA, E.,