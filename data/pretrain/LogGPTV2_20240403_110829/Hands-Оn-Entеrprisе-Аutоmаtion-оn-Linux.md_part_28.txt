login_password: "{{ mariadb_root_password }}"
Again, this code is quite self-explanatory—however, note here too that running this task a
second time will also yield an error, this time because on the second run, these privileges
will not exist because we deleted them on the first run. Thus, this is almost certainly a role
to run once only—or where careful consideration must be applied to the code and the error
handling logic.
We now add a task to delete the anonymous user accounts, as follows:
- name: Delete anonymous MariaDB user
mysql_user:
user: ""
host: "{{ item }}"
state: absent
login_user: root
login_password: "{{ mariadb_root_password }}"
loop:
- "{{ ansible_fqdn }}"
- localhost
[ 298 ]
Database Management Chapter 11
You will see the use of a loop here—this is used to remove both the local and remote
privileges within a single task. Finally, we remove the test database, which is redundant
in most enterprise scenarios, by running the following code:
- name: Delete the test database
mysql_db:
db: test
state: absent
login_user: root
login_password: "{{ mariadb_root_password }}"
With the role fully complete, we can run it in the usual manner, and secure our newly
installed database. The output should look something like this:
[ 299 ]
Database Management Chapter 11
With these two roles and some input from Chapter 7, Configuration Management with
Ansible, we have successfully installed, configured, and secured a MariaDB database on
CentOS. This is, obviously, a very specific example—however, if you were to perform this
on Ubuntu, the process would be very similar. The differences would be the following:
The apt module would be used in place of the yum module in all tasks.
Package names would have to be changed for Ubuntu.
Defining the repository source would be performed under /etc/apt rather than
/etc/yum.repos.d, with the file format adjusted accordingly.
Configuration paths may be different for MariaDB on Ubuntu.
Ubuntu normally uses ufw instead of firewalld—by default, you might find
that ufw is disabled, so, this step could be skipped.
With these changes taken into account, the preceding process can be very quickly adapted
for Ubuntu (or, indeed, any other platform, provided the appropriate changes are made).
Once the packages are installed and configured, as the modules such as mysql_user and
mysql_db are cross-platform, they will work equally well on all supported platforms.
So far in this book, we have focused very heavily on MariaDB—this is not because of any
inherent bias toward this database, nor indeed should it be inferred as any
recommendation. It has simply been chosen as a relevant example and built upon
throughout the text. Before we proceed to look at the process of loading data or schemes
into a newly installed database, we will take a brief look in the next section at how to apply
the processes we have learned so far to another popular Linux database—PostgreSQL.
Installing PostgreSQL Server with Ansible
In this section, we will demonstrate how the principles and high-level processes we have
looked at so far for MariaDB on CentOS can be applied to another platform. Taking a high-
level view, these processes can be applied to almost any database and Linux platform, with
the proper attention to detail. Here, we will install PostgreSQL Server onto Ubuntu Server,
and then secure it by setting the root password—essentially, analogous to the process we
have performed in the preceding section.
[ 300 ]
Database Management Chapter 11
Let us get started by creating a role called installpostgres. In this role we will again
define a template for the package downloads from the official PostgreSQL sources, this
time—of course—tailoring it to the fact that we're using Ubuntu Server, and not CentOS.
The following code shows the template file—note that this is specific for Ubuntu Server
18.04 LTS—codename bionic:
deb http://apt.postgresql.org/pub/repos/apt/ bionic-pgdg main
As before, once our package sources are defined, we can proceed to create the tasks that
will install the database. In the case of Ubuntu, we must add the package-signing key
manually to the apt keyring, in addition to copying the preceding template into place.
Thus, our tasks within the role begin, as follows:
---
- name: Populate PostgreSQL apt template on target host
template:
src: templates/pgdg.list.j2
dest: /etc/apt/sources.list.d/pgdg.list
owner: root
group: root
mode: '0644'
We could also use apt_repository here, but, for consistency with the previous MariaDB
example, we are using template. Both will achieve the same end result.
When the template package is in place, we must then add the package-signing key to
apt's keyring, as follows:
- name: Add key for PostgreSQL packages
apt_key:
url: https://www.postgresql.org/media/keys/ACCC4CF8.asc
state: present
The postgresql-11 and other supporting packages are then installed (as per the
documentation at https:/​/​www.​postgresql.​org/​download/​linux/​ubuntu/​), as follows:
- name: Install PostgreSQL 11 packages
apt:
name:
- postgresql-11
- postgresql-client-11
state: latest
update_cache: yes
[ 301 ]
Database Management Chapter 11
As our default Ubuntu Server install is not running a firewall, the final task in this
playbook is to start the service, and ensure it starts at boot time, as follows:
- name: Ensure PostgreSQL service is installed and started at boot time
service:
name: postgresql
state: started
enabled: yes
Running this should yield output similar to the following:
By default, out-of-the-box installation of PostgreSQL is much more secure than MariaDB.
Without additional configuration, no remote logins are allowed at all, and although no
password is set for the superuser account, it can only be accessed on the local machine from
the postgres user account. Similarly, there is no test database to drop.
Thus, although the high-level process is the same, you must be aware of the nuances of
both the database server you are using and the underlying operating system.
[ 302 ]
Database Management Chapter 11
By way of example and to complete this section, let's create a database called production,
and an associated user called produser who will be given access to it. Although
technically, this overlaps with the next section on loading initial data, it is provided here to
be analogous to the preceding section on MariaDB, and to demonstrate how to use the
native Ansible modules for PostgreSQL.
1. Let's create a role called setuppostgres, and start by defining a task to install
the Ubuntu package necessary to support the Ansible PostgreSQL modules, as
follows:
---
- name: Install PostgreSQL Ansible support packages
apt:
name: python-psycopg2
state: latest
2. After this, we add a task to create the database (this is a very simple
example—you will want to tailor it to your exact requirements), as follows:
- name: Create production database
postgresql_db:
name: production
state: present
become_user: postgres
3. Notice how we leverage the local postgres account on the target machine for
database superuser access with the become_user statement. Next, we'll add the
user, and give them privileges on this database, as follows:
- name: Add produser account to database
postgresql_user:
db: production
name: produser
password: securepw
priv: ALL
state: present
become_user: postgres
As usual, you would not just specify the password in plaintext like this—this has
been done here for simplicity. As usual, substitute appropriate data for variables,
and if those variables are sensitive, either encrypt them at rest using Ansible
Vault or prompt the user for them when the playbook is run.
[ 303 ]
Database Management Chapter 11
4. Now, to get PostgreSQL to listen for remote connections for this user, we need to
perform two more actions. We need to add a line to pg_hba.conf, to tell
PostgreSQL to allow the user we just created to access this database from the
appropriate network—the following example is shown, but be sure to tailor it to
your network and requirements:
- name: Grant produser access to the production database over the
local network
postgresql_pg_hba:
dest: /etc/postgresql/11/main/pg_hba.conf
contype: host
users: produser
source: 192.168.81.0/24
databases: production
method: md5
5. We must also change the listen_addresses parameter in the
postgresql.conf file, which defaults to local connections only. The exact
location of this file will vary depending on your operating system and version of
PostgreSQL—the following example shown is suitable for our install of
PostgreSQL 11 on Ubuntu Server 18.04:
- name: Ensure PostgreSQL is listening for remote connections
lineinfile:
dest: /etc/postgresql/11/main/postgresql.conf
regexp: '^listen_addresses ='
line: listen_addresses = '*'
notify: Restart PostgreSQL
6. Observant readers will have noticed the use of handlers here too—the
postgresql service must be restarted to pick up any changes to this file.
However, this should only be performed when the file is changed, and hence we
make use of handlers. Our handlers/main.yml file will look like this:
---
- name: Restart PostgreSQL
service:
name: postgresql
state: restarted
[ 304 ]
Database Management Chapter 11
7. With our playbook assembled, we can now run it, and the output should look
something like the following screenshot:
Although this example is not strictly the same as the replication of the
mysql_secure_installation tool in the previous section, it does show how to use
native Ansible modules to configure and secure a PostgreSQL database and shows how
Ansible can powerfully assist you in setting up and securing new database servers. These
principles can be applied to just about any database server that is compatible with Linux,
though the modules available for each database will vary. A full list of modules can be
found here: https:/​/​docs.​ansible.​com/​ansible/​latest/​modules/​list_​of_​database_
modules.​html
Now that we have looked at the process of installing a database server, in the next section,
we will build on our installation work, to load initial data and schemas.
[ 305 ]
Database Management Chapter 11
Importing and exporting data
No database is complete simply by installing the software and configuring it—often, there
is a very important intermediate stage, which involves loading an initial dataset. This might
be a backup from a previous database, a sanitized dataset for testing purposes, or, simply, a
schema into which application data can be loaded.
Although Ansible has modules for a limited set of database functions, the functionality here
is not as complete as that for other automation tasks. The most complete support offered for
a database by Ansible is for PostgreSQL—with lesser support for some other databases.
Through some clever use of the shell module, any manual task that you can perform on
the command line can be replicated into an Ansible task. It is up to you to apply logic to the
tasks to handle errors or conditions where, for example, a database already exists, and we
shall see an example of this in the next section.
In the next section, we will look at how you could use Ansible to automate the task of
loading a sample database into a MariaDB database.
Automating MariaDB data loading with Ansible
MariaDB is a good choice for this chapter because it offers a middle-of-the-road view when
it comes to database management with Ansible. There is some native module support in
Ansible, but this is not complete for all tasks you might want to execute. As a result, we will
develop the following example, which automates the loading of a sample set of data, using
just the shell Ansible modules. We will then develop this to show how it would be
completed with the mysql_db module, to provide you with a direct comparison between
the two automation techniques.
Note that the following examples performed using the shell module
could be adapted for almost any database you can manage from the
command line, and so it is hoped these will provide you with a valuable
reference for automating your database management tasks.
[ 306 ]
Database Management Chapter 11
In terms of example databases, we will work with the publicly available Employees sample
database, as this is available to everyone reading this book. You can, of course, choose your
own set of data to work with—however, it is, as ever, hoped that this following practical
example will teach you the skills you need to load data into your newly installed database
with Ansible:
1. To start with, let's create a role called loadmariadb. Into the roles directory
structure, create a directory called files/, and clone the employees sample
database. This is publicly available on GitHub, and, at the time of writing, could
be cloned using the following command:
$ git clone https://github.com/datacharmer/test_db.git
2. From here, we create a tasks/ directory within the role and write the code for
our role tasks themselves. To start with, we need to copy the database files across
to our database server, by running the following code:
---
- name: Copy sample database to server
copy:
src: "{{ item }}"
dest: /tmp/
loop:
- files/test_db/employees.sql
- files/test_db/load_departments.dump
- files/test_db/load_employees.dump
- files/test_db/load_dept_emp.dump
- files/test_db/load_dept_manager.dump
- files/test_db/load_titles.dump
- files/test_db/load_salaries1.dump
- files/test_db/load_salaries2.dump
- files/test_db/load_salaries3.dump
- files/test_db/show_elapsed.sql
3. Once the data files are copied to the server, it is simply a matter of loading them
into the database. However, as there is no module for this task, we must revert to
a shell command to handle this, as shown in the following code block:
- name: Load sample data into database
shell: "mysql -u root --password={{ mariadb_root_password }} <
/tmp/employees.sql"
args:
chdir: /tmp
[ 307 ]
Database Management Chapter 11
4. The role tasks are simplicity themselves—however, before we can run the
playbook, we need to set the mariadb_root_password variable, ideally in a
vault, but for simplicity in this book, we will put it in a plaintext vars file in the
role. The file vars/main.yml should look like this:
---
mariadb_root_password: "securepw"
As you will have spotted, this playbook assumes that you already installed and
configured MariaDB in a previous role—the password used in the preceding code
block is that set in the previous section when we installed MariaDB and secured it
using Ansible.
5. Running the playbook should yield results like this:
Here, we have not only loaded a sample schema, but also sample data, into our database. In
your enterprise, you could choose to perform either of these tasks in isolation, as required.
[ 308 ]
Database Management Chapter 11
You will probably have spotted that this playbook is extremely dangerous. As we discussed
previously, the issue with using the shell module in Ansible playbooks is that the results
of the task will vary as the shell command is always run, whether it needs running or not.
Thus, if you ran this playbook against a server with an existing database called employees,
it would overwrite all the data in it with the sample data! Contrast this with the copy
module, which only copies the files if they do not already exist on the receiving end.
Given the lack of native database modules at the time of writing, we need to devise a more
intelligent way of running this command. Here, we can make use of some of the clever
error handling built into Ansible.
The shell module assumes that the command it is running has run successfully if it
returns exit code zero. This results in the task returning the changed status we saw in this
playbook run. However, if the exit code is not zero, the shell module will instead return a
status of failed.
We can take advantage of this knowledge, and couple it with a useful MariaDB command
that will return a zero exit code if the database we query exists, and non-zero if it doesn't.
See the following screenshot for an example:
[ 309 ]
Database Management Chapter 11