# 16 \| Java JIT编译器（四）：Graal的后端是如何工作的？你好，我是宫文学。前面两讲中，我介绍了 Sea of Nodes 类型的 HIR，以及基于 HIR的各种分析处理，这可以看做是编译器的中端。可编译器最终还是要生成机器码的。那么，这个过程是怎么实现的呢？与硬件架构相关的LIR是什么样子的呢？指令选择是怎么做的呢？这一讲，我就带你了解 Graal编译器的后端功能，回答以上这些问题，破除你对后端处理过程的神秘感。首先，我们来直观地了解一下后端处理的流程。后端的处理流程在 [第 14讲  slate-object="inline"中，我们在运行 Java示例程序的时候（比如`atLeastTen()`方法），使用了"`-Dgraal.Dump=:5`"的选项，这个选项会 dump出整个编译过程最详细的信息。对于 HIR 的处理过程，程序会通过网络端口，dump 到 IdealGraphVisualizer里面。而后端的处理过程，缺省则会 dump到工作目录下的一个"`graal_dumps`"子目录下。你可以用文本编辑器打开查看里面的信息。    //至少返回10    public int atLeastTen(int a){        if (a ' test] ':' [TYPE_COMMENT] func_body_suite    //语句    simple_stmt: small_stmt (';' small_stmt)* [';'] NEWLINE    small_stmt: (expr_stmt | del_stmt | pass_stmt | flow_stmt |                 import_stmt | global_stmt | nonlocal_stmt | assert_stmt)通过阅读规则文件，你可以精确地了解 Python的语法规则。**这个规则文件是给谁用的呢？****实际上 Python的编译器本身并不使用它，它是给一个****pgen** 的工具程序（Parser/pgenslate-object="inline"）使用的。这个程序能够基于语法规则生成**解析表**（ParseTable），供语法分析程序使用。有很多工具能帮助你生成语法解析器，包括yacc（GNU 版本是 bison）、ANTLR等。 有了 pgen 这个工具，你就可以通过修改规则文件来修改 Python语言的语法，比如，你可以把函数声明中的关键字"def"换成"function"，这样你就可以用新的语法来声明函数。pgen 能给你生成新的语法解析器。parser.c的注释中讲解了它的工作原理。它是把 EBNF 转化成一个 NFA，然后再把这个 NFA转换成 DFA。基于这个 DFA，在读取 Token的时候，编译器就知道如何做状态迁移，并生成解析树。这个过程你听上去是不是有点熟悉？实际上，我们在第 2 讲slate-object="inline"讨论正则表达式工具的时候，就曾经把正则表达式转化成了 NFA和DFA。基于这个技术，我们既可以做词法解析，也可以做语法解析。实际上，Python 用的是 LL(1) 算法。我们来回忆一下 LL(1)算法的特点slate-object="inline"：**针对每条语法规则，最多预读一个Token，编译器就可以知道该选择哪个产生式。**这其实就是一个 DFA，从一条语法规则，根据读入的Token，迁移到下一条语法规则。我们通过一个例子来看一下 Python的语法分析特点，这里采用的是我们熟悉的一个语法规则：    add: mul ('+' mul)*     mul: pri ('*' pri)*     pri: IntLiteral | '(' add ')'我把这些语法规则对应的 DFA画了出来。你会看到，它跟采用递归下降算法的思路是一样的，只不过换了种表达方式。![](Images/3d6ff0c63c335fe0e18ea97807a0c347.png)savepage-src="https://static001.geekbang.org/resource/image/de/06/def9c3178ca00a1ebc5471b4a74acb06.jpg"}add: mul (\'+\' mul)\*对应的DFA![](Images/5b829e1a047f6b54e206343be9b9846f.png)savepage-src="https://static001.geekbang.org/resource/image/f6/0d/f6b24be02983c724b945e8a1674yya0d.jpg"}mul: pri (\'\*\' pri)\*对应的DFA![](Images/75d34b95c0a0a576d258e3acc98cf216.png)savepage-src="https://static001.geekbang.org/resource/image/d0/1d/d0a8af5d54571f07b6df4eb965031e1d.jpg"}pri: IntLiteral \| \'(\' add \')\'对应的DFA不过，跟手写的递归下降算法为解析每个语法规则写一个函数不同，parser.c用了一个通用的函数去解析所有的语法规则，它所依据的就是为每个规则所生成的DFA。 主要的实现逻辑是在 parser.c 的 PyParser_AddToken()函数里，你可以跟踪它的实现过程。为了便于你理解，我模仿 Python编译器，用上面的文法规则解析了一下"`2+3*4+5`"，并把整个解析过程画成图。在解析的过程，我用了一个栈作为一个工作区，来保存当前解析过程中使用的DFA。 **第 1 步，匹配 add 规则。**把 add 对应的 DFA 压到栈里，此时该 DFA 处于状态0。这时候预读了一个 Token，是字面量2。 ![](Images/867c69312344cdacf8c2de303b151fef.png)savepage-src="https://static001.geekbang.org/resource/image/2a/54/2a9318064fa07108f5484235fb824454.jpg"}**第 2 步，根据 add 的 DFA，走 mul-1 这条边，去匹配 mul规则。** 这时把 mul对应的 DFA入栈。在示意图中，栈是从上往下延伸的。![](Images/ae6f578f7d0052fcf96694983c9fb2bc.png)savepage-src="https://static001.geekbang.org/resource/image/6d/59/6d3222404b30yy08d29943a321e6ac59.jpg"}**第 3 步，根据 mul 的 DFA，走 pri-1 这条边，去匹配 pri规则。** 这时把 pri对应的 DFA 入栈。![](Images/62d5a9f14f9e3e28df1bbb2503ffc89e.png)savepage-src="https://static001.geekbang.org/resource/image/78/77/78fca50b5a414fbf74f6229aa4c0a877.jpg"}**第 4 步，根据 pri 的 DFA，因为预读的 Token 是字面量2，所以移进这个字面量，并迁移到状态 3。同时，为字面量 2建立解析树的节点。**这个时候，又会预读下一个Token，`'+'`号。![](Images/bdb9f451b9ba44b583d18c798d1f39f8.png)savepage-src="https://static001.geekbang.org/resource/image/4a/ff/4a2daba678f9f8fe476e94403267d2ff.jpg"}**第 5 步，从栈里弹出 pri 的 DFA，并建立 pri节点。**因为成功匹配了一个 pri，所以 mul 的 DFA 迁移到状态1。 ![](Images/e692025a4570afd8182192eba1acaf9e.png)savepage-src="https://static001.geekbang.org/resource/image/5a/41/5a204c08609187584d88894b5388d741.jpg"}**第 6 步，因为目前预读的 Token是** `'+'`**号，所以mul 规则匹配完毕，把它的 DFA也从栈里弹出**。而 add 对应的 DFA 也迁移到了状态1。 ![](Images/be29c549c3747defac156e798fa20ee1.png)savepage-src="https://static001.geekbang.org/resource/image/a6/a6/a6a49e70fa5216f0cc516981978a5fa6.jpg"}**第 7 步，移进**`'+'`**号，把 add 的 DFA 迁移到状态 2，预读了下一个Token：字面量 3**。这个 Token 是在 mul 的 First 集合中的，所以就走 mul-2边，去匹配一个 mul。![](Images/de2053bb883e1fb2f4f62b07a35c2806.png)savepage-src="https://static001.geekbang.org/resource/image/8f/3c/8f446e247ecab4e9224f59130de4013c.jpg"}按照这个思路继续做解析，直到最后，可以得到完整的解析树：![](Images/13845b86347e6ec2cd65d5745d7b11b9.png)savepage-src="https://static001.geekbang.org/resource/image/be/b5/be5cd83e4c545a9d29c4f41a13fae5b5.jpg"}总结起来，Python编译器采用了一个通用的语法分析程序，以一个栈作为辅助的数据结构，来完成各个语法规则的解析工作。当前正在解析的语法规则对应的DFA，位于栈顶。一旦当前的语法规则匹配完毕，那语法分析程序就可以把这个DFA弹出，退回到上一级的语法规则。所以说，语法解析器生成工具，会基于不同的语法规则来生成不同的DFA，但语法解析程序是不变的。这样，你随意修改语法规则，都能够成功解析。上面我直观地给你解读了一下解析过程。你可以用 GDB 来跟踪一下PyParser_AddToken()函数，从而了解得更具体。你在这个函数里，还能够看到像下面这样的语句，这是对外输出调试信息。    D(printf(" Push '%s'\n", d1->d_name));   //把某DFA入栈你还可以用"-d"参数运行 python，然后在 REPL里输入程序，这样它就能打印出这些调试信息，包括什么时候把 DFA入栈、什么时候出栈，等等。我截取了一部分输出信息，你可以看一下。![](Images/a006240808ffe21081675f94760e2fa4.png)savepage-src="https://static001.geekbang.org/resource/image/d6/f1/d6e523e506687846f7d13a1eaff211f1.jpg"}在 Python 的语法规则里，arith_expr 指的是加减法的表达式，term指的是乘除法的表达式，atom指的是基础表达式。这套词汇也经常被用于语法规则中，你可以熟悉起来。好了，现在你已经知道了语法解析的过程。不过你可能注意到了，上面的语法解析过程形成的结果，我没有叫做是AST，而是叫做**解析树**（ParseTree）。看到这里，你可能会产生疑问：**解析源代码不就会产生 AST吗？怎么这里是生成一个叫做解析树的东西？什么是解析树，它跟 AST有啥区别？**别着急，下面我就来为你揭晓答案。解析树和 AST 的区别解析树又可以叫做 **CST**（Concret Syntax Tree，具体语法树），与AST（抽象语法树）是相对的：一个具体，一个抽象。它俩的区别在于：**CST 精确地反映了语法规则的推导过程，而 AST则更准确地表达了程序的结构。如果说 CST 是"形似"，那么 AST就是"神似"。**你可以看看在前面的这个例子中，所形成的 CST的特点。 ![](Images/13845b86347e6ec2cd65d5745d7b11b9.png)savepage-src="https://static001.geekbang.org/resource/image/be/b5/be5cd83e4c545a9d29c4f41a13fae5b5.jpg"}首先，加法是个二元运算符，但在这里 add节点下面对应了两个加法运算符，跟原来加法的语义不符。第二，很多节点都只有一个父节点，这个其实可以省略，让树结构更简洁。所以，我们期待的 AST其实是这样的：![](Images/05ecc866ac46a1f88d3658c0e7f52a31.png)savepage-src="https://static001.geekbang.org/resource/image/7a/ce/7aa1ea17abafdba3f0cd68f6d14b6ace.jpg"}这就是 CST 和 AST 的区别。理解了这个知识点以后，我们拿 Python 实际的 CST 和 AST来做一下对比。在 Python的命令行中，输入下面的命令：    >>> from pprint import pprint    >>> import parser    >>> cst = parser.expr('2+3+4')  //对加法表达式做解析    >>> pprint(parser.st2list(cst)) //以美观的方式打印输出CST你会得到这样的输出结果：![](Images/98d09648ad78275f27925b417375309f.png)savepage-src="https://static001.geekbang.org/resource/image/50/6f/508d14e74211a1a0bbf6e8c0b282b76f.jpg"}这是用缩进的方式显示了 CST 的树状结构，其中的数字是符号和 Token的编号。你可以从 Token的字典（dict）里把它查出来，从而以更加直观的方式显示CST。 我们借助一个 lex 函数来做美化的工作。现在再显示一下CST，就更直观了：![](Images/d6b55a00788e0194fb62ae21f014987e.png)savepage-src="https://static001.geekbang.org/resource/image/10/fe/104aa190ab9a4c118d1fb5a73187fafe.jpg"}**那么，Python 把 CST 转换成AST，会是什么样子呢？**你可以在命令行敲入下面的代码，来显示AST。它虽然是以文本格式显示的，但你能发现它是一个树状结构。这个树状结构就很简洁：![](Images/985e4003badaed05c24739c62aac1860.png)savepage-src="https://static001.geekbang.org/resource/image/22/bd/2232eb547e255f88e5d867ec147867bd.jpg"}如果你嫌这样不够直观，还可以用另一个工具"instaviz"，在命令行窗口用pip 命令安装 instaviz 模块，以图形化的方式更直观地来显示 AST。instaviz是"Instant Visualization"（立即可视化）的意思，它能够图形化显示AST。     $ pip install instaviz然后启动Python，并敲入下面的代码：![](Images/297889cdf3b7dba2136acc66eb9ebab3.png)savepage-src="https://static001.geekbang.org/resource/image/41/fb/41808237c525885d28534fc9514329fb.jpg"}instaviz 会启动一个 Web 服务器，你可以在浏览器里通过http://localhost:8080 来访问它，里面有图形化的 AST。你可以看到，这个 AST比起 CST 来，确实简洁太多了。![](Images/98308269a869fb2a63787fdb140797ac.png)savepage-src="https://static001.geekbang.org/resource/image/e1/bf/e1700c27cec63f492f5cdb68809d42bf.jpg"}点击代表"`2+3*4+5`"表达式的节点，你可以看到这棵子树的各个节点的属性信息：![](Images/411d84112f40aa18848545b58be333b1.png)savepage-src="https://static001.geekbang.org/resource/image/28/c5/28ab9da7c9c4cd005d13fca4d44e69c5.jpg"}总结起来，在编译器里，我们经常需要把源代码转变成 CST，然后再转换成AST。生成 CST 是为了方便编译器的解析过程。而转换成 AST后，会让树结构更加精简，并且在语义上更符合语言原本的定义。**那么，Python 是如何把 CST 转换成 AST的呢？**这个过程分为两步。**首先，Python 采用了一种叫做 ASDL 的语言，来定义了 AST的结构。**ASDL是"抽象语法定义语言（Abstract SyntaxDefinition Language）"的缩写，它可以用于描述编译器中的 IR以及其他树状的数据结构。你可能不熟悉 ASDL，但可能了解 XML 和 JSON 的Schema，你可以通过 Schema 来定义 XML 和 JSON 的合法的结构。另外还有DTD、EBNF等，它们的作用都是差不多的。这个定义文件是 Parser/Python.asdl。CPython编译器中包含了两个程序（Parser/asdl.py 和 Parser/asdl_c.py）来解析 ASDL文件，并生成 AST 的数据结构。最后的结果在 Include/Python-ast.h文件中。 到这里，你可能会有疑问：**这个 ASDL 文件及解析程序不就是生成了 AST的数据结构吗？为什么不手工设计这些数据结构呢？有必要采用一种专门的 DSL来做这件事情吗？**确实如此。Java 语言的AST，只是采用了手工设计的数据结构，也没有专门用一个 DSL来生成。 但 Python 这样做确实有它的好处。上一讲我们说过，Python的编译器有多种语言的实现，因此基于统一的 ASDL文件，我们就可以精准地生成不同语言下的 AST的数据结构。在有了 AST 的数据结构以后，**第二步，是把 CST 转换成 AST，这个工作是在 Python/ast.c中实现的，入口函数是PyAST_FromNode()。**这个算法是手写的，并没有办法自动生成。课程小结今天这一讲，我们开启了对 Python编译器的探究。我想给你强调下面几个关键要点：1.  **非自举**        。CPython 的编译器是用 C 语言编写的，而不是用 Python    语言本身。编译器和核心库采用 C    语言会让它性能更高，并且更容易与各种二进制工具集成。        2.  **善用 GDB**        。使用 GDB 可以跟踪 CPython    编译器的执行过程，加深对它的内部机制的理解，加快研究的速度。        3.  **编译器生成工具 pgen**        。pgen    能够根据语法规则生成解析表，让修改语法的过程变得更加容易。        4.  **基于 DFA    的语法解析过程**        。基于 pgen 生成的解析表，通过 DFA    驱动完成语法解析过程，整个执行过程跟递归下降算法的原理相同，但只需要一个通用的解析程序即可。        5.  **从 CST 到 AST**        。语法分析首先生成 CST，接着生成 AST。CST    准确反映了语法推导的过程，但会比较啰嗦，并且可能不符合语义。AST    同样反映了程序的结构，但更简洁，并且支持准确的语义。        本讲的思维导图我也放在这里了，供你参考：![](Images/bcd6345cea1815fa0f6515882cad210e.png)savepage-src="https://static001.geekbang.org/resource/image/1e/34/1e11c1bb92669152c725a35c919b4534.jpg"}一课一思这一讲我们提到，Python的词法分析器没有区分标识符和关键字，但这样为什么没有影响到 Python的语法分析的功能呢？你可以结合语法规则文件和对语法解析过程的理解，谈谈你的看法。如果你能在源代码里找到确定的答案，那就更好了！欢迎你在留言区中分享你的见解，也欢迎你把今天的内容分享给更多的朋友，我们下一讲再见。参考资料GDB 的安装和配置：参考这篇文章slate-object="inline"。