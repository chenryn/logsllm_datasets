# Bootstrapping Privacy Compliance in Big Data Systems

**Authors:**
- Shayak Sen
- Saikat Guha
- Anupam Datta
- Sriram K. Rajamani
- Janice Y. Tsai
- Jeannette M. Wing

**Affiliations:**
- *Carnegie Mellon University, Pittsburgh, USA*
  - Shayak Sen, Anupam Datta
  - {shayaks, danupam}@cmu.edu
- *Microsoft Research, Bangalore, India*
  - Saikat Guha, Sriram K. Rajamani
  - {saikat, sriram}@microsoft.com
- *Microsoft Research, Redmond, USA*
  - Janice Tsai, Jeannette M. Wing
  - {jatsai, wing}@microsoft.com

**Abstract:**
With the rapid growth of cloud services that collect and use user data to offer personalized experiences, ensuring compliance with privacy policies has become a critical business imperative for building user trust. However, most current compliance efforts in the industry rely on manual review processes and audits, which are resource-intensive and lack comprehensive coverage. In this paper, we present our experience in building and operating a system to automate privacy policy compliance checking in Bing. The system's design is centered around two key components: (a) LEGALEASE, a language for specifying privacy policies that impose restrictions on how user data is handled; and (b) GROK, a data inventory for Map-Reduce-like big data systems that tracks the flow of user data among programs. GROK maps code-level schema elements to datatypes in LEGALEASE, effectively annotating existing programs with information flow types with minimal human input. This reduces compliance checking to an information flow analysis of big data systems. Our system, developed by a small team, checks the compliance of millions of lines of ever-changing source code written by several thousand developers on a daily basis.

## 1. Introduction

Web service companies such as Facebook, Google, and Microsoft, which use personal information for various functions, are expected to comply with their declared privacy policies. In the United States, companies are legally required to disclose their data collection and use practices, and the Federal Trade Commission (FTC) enforces compliance by imposing penalties on companies that violate their stated policies [1], [2], [3]. In practice, these legal requirements translate into companies creating review processes and conducting internal audits to ensure compliance [4], [5]. Manual reviews and audits, however, are time-consuming, resource-intensive, and often lack comprehensive coverage, leading to instances where internal processes fail to catch policy violations [6].

In this paper, we take the first steps toward automating the compliance checking of large-scale Map-Reduce-like big data systems with privacy policies that restrict the flow of personal information. Our deployed prototype significantly reduces compliance checking time and improves coverage across the data analytics pipeline of Bing. Additionally, the human resource requirements are minimal, with the prototype being run by a small team and scaling to the needs of several thousand developers working on Bing.

### 1.1 Current Compliance Workflows

To understand the challenges of automating privacy compliance in a large company, it is essential to examine the division of labor and responsibilities in current compliance workflows [4], [5]. Privacy policies are typically crafted by lawyers in a corporate legal team to adhere to all applicable laws and regulations worldwide. Due to the rapid changes in product features and internal processes, these policies are specified using high-level concepts that may not directly map to the products they govern. For example, a policy might refer to "IP Address," but the product may have thousands of data stores and processes that produce and consume this data, all of which must comply with the policy. The task of interpreting the policy for individual products falls to privacy champions embedded in product groups. These champions review product features at various stages of development, providing specific requirements to the development teams to ensure compliance. Periodically, the compliance team audits development teams to ensure that these requirements are met.

We illustrate this process with a running example. Consider a policy clause that states, "full IP address will not be used for advertising." During a meeting, the privacy champion learns that the development team uses the IP address to infer the user's location, which is used as a bid modifier in the auction. The privacy champion points out that this program is not compliant and suggests truncating the IP address to meet the policy. The development team then modifies the code to truncate the IP address. Later, the advertising abuse detection team may need to use the IP address, resulting in a policy exception with additional restrictions, such as "IP address may be used for detecting abuse, but it will not be combined with account information." The entire process (Fig. 1, left panel) is highly manual, involving multiple meetings and communications between different groups, which can be time-consuming and inefficient.

### 1.2 Our Contributions

Our central contribution is a workflow for privacy compliance in big data systems, specifically targeting large codebases written in languages that support the Map-Reduce programming model [7], [8], [9]. This focus allows us to apply our workflow to industrial-scale data processing applications, such as the data analytics backend of Bing, Microsoft’s web search engine [10]. Our workflow leverages three key technical contributions:

1. **LEGALEASE**: A usable, expressive, and enforceable privacy policy language designed for policy authors and privacy champions.
2. **GROK**: A self-bootstrapping data inventory mapper that maps low-level data types in code to high-level policy concepts, bridging the gap between product development and policy making.
3. **Scalable Implementation**: An automated compliance checking system for Bing that scales to tens of millions of lines of source code and tens of millions of files.

## 2. Motivating Example

To highlight the salient features of our programming model and typical privacy policies, we use an example. Consider a policy clause that states, "full IP address will not be used for advertising." The privacy champion learns that the development team uses the IP address to infer the user's location, which is used as a bid modifier in the auction. The privacy champion points out that this program is not compliant and suggests truncating the IP address to meet the policy. The development team then modifies the code to truncate the IP address. Later, the advertising abuse detection team may need to use the IP address, resulting in a policy exception with additional restrictions, such as "IP address may be used for detecting abuse, but it will not be combined with account information."

The data dependence graph (Fig. 2) provides a useful starting point for conducting information flow analysis. Nodes in the graph represent data stores, processes, and humans, while directed edges represent data flowing from one node to another. Programs are labeled with their purpose, and source data files are labeled with the type of data they hold. Given these labels, additional labels can be computed using static data flow analysis. For example, if Job 1 and Job 2 read File A, which holds data of type IPAddress, both jobs acquire the datatype label IPAddress. Similarly, if File C is derived from File A and holds truncated IP addresses, it acquires the label IPAddress:Truncated. Checking non-interference involves verifying whether there exists a path from restricted data to the program in the data dependence graph. For the search engine we analyze, the data dependence graph does not come with these kinds of labels. Bootstrapping these labels without significant human effort is a central challenge addressed by GROK.

## 3. Policy Specification Language

### 3.1 Design Goals

LEGALEASE is designed to be usable by individuals with no training in formal logic, while being sufficiently expressive to encode current privacy policies. The primary design criteria are:

- **Usability**: Policy clauses in LEGALEASE are structured similarly to clauses in the English language policy. This correspondence is important because different sub-teams own different portions of the policy.
- **Expressiveness**: LEGALEASE should be able to capture real privacy policies of industrial-scale systems, such as Bing and Google.
- **Compositional Reasoning**: The semantics of policies in LEGALEASE are compositional, allowing reasoning about a policy to be reduced to reasoning about its parts. This form of compositionality is useful because the effect of adding a new clause to a complex policy is locally contained.

### 3.2 Syntax and Semantics

LEGALEASE enforces syntactic restrictions to ensure that encoded policy clauses are structured similarly to policy texts. Building on prior work on a first-order privacy logic [11], policy clauses in LEGALEASE allow or deny certain types of information flows and are refined through exceptions. This structure of nested allow-deny rules appears in many practical privacy policies, including HIPAA and GLBA. 

To validate the usability of LEGALEASE, we conducted a user study among policy writers and privacy champions within Microsoft. We also encoded Bing and Google’s privacy policies regarding data usage on their servers to demonstrate that LEGALEASE retains enough expressiveness to capture real privacy policies of industrial-scale systems.

## 4. GROK Mapper

### 4.1 Design Goals

GROK is a data inventory for Map-Reduce-like big data systems. It maps every dynamic schema element (e.g., members of a tuple passed between mappers and reducers) to datatypes in LEGALEASE. The primary design criteria for this inventory are:

- **Bootstrapping with Minimal Developer Effort**: GROK should be bootstrapped with minimal developer effort.
- **Exhaustive and Up-to-Date Information**: The inventory should reflect exhaustive and up-to-date information about all data in the Map-Reduce-like system.
- **Verification and Updating**: It should be easy to verify and update the mapping from schema elements to LEGALEASE datatypes.

### 4.2 System Design

The inventory mappings combine information from various sources, each with its own characteristic coverage and quality. For example, syntactic analysis of source code (e.g., applying pattern-matching to column names) has high coverage but low confidence, whereas explicit annotations added by developers have high confidence but low coverage. Section IV details the design of the system, and Section V presents how the automated policy checker performs conservative analysis while minimizing false positives over imperfect mappings.

By using automated data-inventory mapping and adding precise semantics to the policy specification, we reduce time-consuming meetings by decoupling the interactions between the various groups. Meetings are needed only when our automated privacy compliance checker (conservatively) detects potentially sensitive scenarios, and are hence more focused, especially on actionable items (dotted lines in Fig. 1).

### 4.3 Scale

Our scalability criteria include:

- **Data Volume**: The amount of data over which we perform automated privacy compliance checking.
- **Time**: The time taken to perform the checking.
- **Human Resources**: The number of people resources needed for the entire effort.

Our deployed system scales to tens of millions of lines of source code written by several thousand developers, storing data in tens of millions of files containing over a hundred million schema elements, a substantial fraction of which is changing or added on a day-to-day basis. Our data inventory takes twenty minutes (daily), and evaluating the complete LEGALEASE encoding of Bing’s privacy policy over the entire data takes ten minutes. The entire effort was bootstrapped from scratch by a team of five people.

## 5. Conclusion

In this paper, we presented our experience in building and operating a system to automate privacy policy compliance checking in Bing. The system's design is centered around LEGALEASE, a language for specifying privacy policies, and GROK, a data inventory for tracking the flow of user data. Our system, developed by a small team, checks the compliance of millions of lines of ever-changing source code written by several thousand developers on a daily basis. This approach significantly reduces compliance checking time and improves coverage, while minimizing the need for human resources.