title:Bootstrapping Privacy Compliance in Big Data Systems
author:Shayak Sen and
Saikat Guha and
Anupam Datta and
Sriram K. Rajamani and
Janice Y. Tsai and
Jeannette M. Wing
2014 IEEE Symposium on Security and Privacy
Bootstrapping Privacy Compliance
in Big Data Systems
Shayak Sen∗, Saikat Guha†, Anupam Datta∗, Sriram K. Rajamani†, Janice Tsai‡ and Jeannette M. Wing‡
∗Carnegie Mellon University, Pittsburgh, USA
{shayaks,danupam}@cmu.edu
†Microsoft Research, Bangalore, India
{saikat,sriram}@microsoft.com
‡Microsoft Research, Redmond, USA
{jatsai,wing}@microsoft.com
Abstract—With the rapid increase in cloud services collecting
and using user data to offer personalized experiences, ensuring
that these services comply with their privacy policies has become
a business imperative for building user trust. However, most
compliance efforts in industry today rely on manual review
processes and audits designed to safeguard user data, and
therefore are resource intensive and lack coverage. In this paper,
we present our experience building and operating a system to
automate privacy policy compliance checking in Bing. Central
to the design of the system are (a) LEGALEASE—a language that
allows speciﬁcation of privacy policies that impose restrictions
on how user data is handled; and (b) GROK—a data inventory
for Map-Reduce-like big data systems that tracks how user data
ﬂows among programs. GROK maps code-level schema elements
to datatypes in LEGALEASE,
in essence, annotating existing
programs with information ﬂow types with minimal human input.
Compliance checking is thus reduced to information ﬂow analysis
of big data systems. The system, bootstrapped by a small team,
checks compliance daily of millions of lines of ever-changing
source code written by several thousand developers.
I. INTRODUCTION
Web services companies, such as Facebook, Google, and
Microsoft, that use personal information of users for var-
ious functions are expected to comply with their declared
privacy policies. Companies in the US are legally required
to disclose their data collection and use practices, and the
US Federal Trade Commission (FTC) has the mandate to
enforce compliance, which it exercises by imposing penalties
on companies found to violate their own stated policies [1],
[2], [3]. In practice,
these legal requirements translate to
companies creating review processes and conducting internal
audits to ensure compliance [4], [5]. Manual reviews and
audits are time-consuming, resource-intensive, lack coverage,
and, thus, inherently do not scale well in large companies;
indeed, there have been cases where internal processes have
not caught policy violations [6]. In this paper we take the
ﬁrst steps toward automated checking of large-scale Map-
Reduce-like big data systems for compliance with privacy
policies that restrict how various types of personal information
ﬂow through these systems. Our deployed prototype reduces
compliance checking time and improves coverage by orders of
magnitude, across the data analytics pipeline of Bing. Further,
the human resources needs are small — the prototype is run
Fig. 1. Privacy Compliance Workﬂow. Manual reviews and audits are highly
time-consuming, and resource-intensive. By encoding policy in LEGALEASE
using the GROK data inventory, we decouple interactions so policy speciﬁca-
tion, interpretation, product development, and continuous auditing can proceed
in parallel.
by a small team, and scales to the needs of several thousands
of developers working on Bing.
To contextualize the challenges in performing automated
privacy compliance checking in a large company with tens
of thousands of employees, it is useful to understand the
division of labor and responsibilities in current compliance
workﬂows [4], [5]. Privacy policies are typically crafted by
lawyers in a corporate legal team to adhere to all applicable
laws and regulations worldwide. Due to the rapid change
in product features and internal processes, these policies are
necessarily speciﬁed using high-level policy concepts that may
not cleanly map to the products that are expected to comply
with them. For instance, a policy may refer to “IP Address”
which is a high-level policy concept, and the product may
have thousands of data stores where data derived from the
“IP Address” is stored (and called with different names) and
several thousand processes that produce and consume this
data, all of which have to comply with policy. The task of
interpreting the policy as applicable to individual products
then falls to the tens of privacy champions embedded in
product groups. Privacy champions review product features
at various stages of the development process, offering speciﬁc
requirements to the development teams to ensure compliance
© 2014, Shayak Sen. Under license to IEEE.
DOI 10.1109/SP.2014.28
327
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:58:21 UTC from IEEE Xplore.  Restrictions apply. 
with policy. The code produced by the development team is
expected to adhere to these requirements. Periodically, the
compliance team audits development teams to ensure that the
requirements are met.
We illustrate this process with a running example we use
throughout this paper. Let us assume that we are interested
in checking compliance for an illustrative policy clause that
promises “full IP address will not be used for advertising.”.
The privacy champion reviewing the algorithm design for, say
online advertisement auctions, may learn in a meeting with
the development team that they use the IP address to infer the
user’s location, which is used as a bid-modiﬁer in the auction.
The privacy champion may point out that this program is not
compliant with the above policy and suggest to the develop-
ment team to truncate the IP address by dropping the last octet
to comply with the policy, without signiﬁcantly degrading the
accuracy of the location inference. The development team then
modiﬁes the code to truncate the IP address. Periodically,
the audit team may ask the development team whether the
truncation code is still in place. Later, the advertising abuse
detection team may need to use the IP address. This may
result in a policy exception, but may come with a different
set of restrictions, e.g., "IP address may be used for detecting
abuse. In such cases it will not be combined with account
information." The entire process (Fig. 1 left panel) is highly
manual, with each step sometimes taking weeks to identify the
right people to talk to and multiple meetings between different
groups (lawyers, champions, developers, auditors) that may as
well be communicating in different languages.
Our central contribution is a workﬂow for privacy compli-
ance in big data systems. Speciﬁcally, we target privacy com-
pliance of large codebases written in languages that support
the Map-Reduce programming model [7], [8], [9]. This focus
enables us to apply our workﬂow to current industrial-scale
data processing applications, in particular the data analytics
backend of Bing, Microsoft’s web search engine [10]. This
workﬂow leverages our three key technical contributions: (1)
a language LEGALEASE for stating privacy policies, which is
usable by policy authors and privacy policy champions, but has
precise semantics and enables automated checking for compli-
ance, (2) a self-bootstrapping data inventory mapper GROK,
which maps low level data types in code to high-level policy
concepts, and bridges the world of product development with
the world of policy makers, and (3) a scalable implementation
of automated compliance checking for Bing. We describe each
of these parts below.
The LEGALEASE language. LEGALEASE is an usable, expres-
sive, and enforceable privacy policy language. The primary
design criteria for this language were that it (a) be usable by
the policy authors and privacy champions; (b) be expressive
enough to capture real privacy policies of industrial-scale sys-
tems, e.g., Bing; (c) and should allow compositional reasoning
on policies.
As the intended users for LEGALEASE are policy au-
thors and privacy champions with limited training in for-
mal languages, enabling usability is essential. To this end,
LEGALEASE enforces syntactic restrictions ensuring that en-
coded policy clauses are structured very similarly to policy
texts. Speciﬁcally, building on prior work on a ﬁrst order
privacy logic [11], policy clauses in LEGALEASE allow (resp.
deny) certain types of information ﬂows and are reﬁned
through exceptions that deny (resp. allow) some sub-types of
the governed information ﬂow types. This structure of nested
allow-deny rules appears in many practical privacy policies,
including privacy laws such the Health Insurance Portability
and Accountability Act (HIPAA) and the Gramm-Leach-Bliley
Act (GLBA) (as observed in prior work [11]), as well as
privacy policies for Bing and Google. A distinctive feature of
LEGALEASE (and a point of contrast from prior work based
on ﬁrst-order logic and ﬁrst order-temporal logic [12], [11])
is that the semantics of policies is compositional: reasoning
about a policy is reduced to reasoning about its parts. This
form of compositionality is useful because the effect of adding
a new clause to a complex policy is locally contained (an ex-
ception only reﬁnes its immediately enclosing policy clause).
Section III presents the detailed design of the language. To
validate the usability of LEGALEASE by its intended users,
we conduct a user study among policy writers and privacy
champions within Microsoft. On the other hand, by encoding
Bing and Google’s privacy policies regarding data usage on
their servers, we demonstrate that LEGALEASE retains enough
expressiveness to capture real privacy policies of industrial-
scale systems. Section VI presents the results of the usability
study and the encoding of Bing and Google’s privacy policies.
The GROK mapper. GROK is a data-inventory for Map-
Reduce-like big data systems. It maps every dynamic schema-
element (e.g., members of a tuple passed between mappers
and reducers) to datatypes in LEGALEASE. This inventory can
be viewed as a mechanism for annotating existing programs
written in languages like Hive [7], Dremel [8], or Scope [9]
with the information ﬂow types (datatypes) in LEGALEASE.
Our primary design criteria for this inventory were that it
(a) be bootstrapped with minimal developer effort; (b) reﬂect
exhaustive and up-to-date information about all data in the
Map-Reduce-like system; and (c) make it easy to verify (and
update) the mapping from schema-elements to LEGALEASE
datatypes. The inventory mappings combine information from
a number of different sources each of which has its own char-
acteristic coverage and quality. For instance, syntactic analysis
of source code (e.g., applying pattern-matching to column
names) has high coverage but low conﬁdence, whereas explicit
annotations added by developers has high conﬁdence but low
coverage. Section IV details the design of the system, and
Section V presents how the automated policy checker performs
conservative analysis while minimizing false positives over
imperfect mappings.
By using automated data-inventory mapping and adding
precise semantics to the policy speciﬁcation, we reduce time-
consuming meetings by decoupling the interactions between
the various groups so policy speciﬁcation, policy interpreta-
328
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:58:21 UTC from IEEE Xplore.  Restrictions apply. 
restrictions (e.g., requiring that only speciﬁc product team
members should use certain types of user data). While our pol-
icy language is designed in a general form enabling domain-
speciﬁc instantiations with different kinds of restrictions, our
evaluation of Bing is done with an instantiation that has
exactly these three restrictions—purpose, role, and storage—
on ﬂow of various types of personal information. We interpret
information ﬂow in the sense of non-interference [13], i.e.,
data not supposed to ﬂow to a program should not affect the
output of the program.
The data dependence graph depicted for the example in
Fig. 2 provides a useful starting point to conduct the infor-
mation ﬂow analysis. Nodes in the graph are data stores,
processes, and humans. Directed edges represent data ﬂowing
from one node to another. To begin,
let us assume that
programs are labeled with their purpose. For example, Job
1 is for the purpose of AbuseDetect. Furthermore,
let us
also assume that the source data ﬁles are labeled with the
type of data they hold. For example, File A holds data
of type IPAddress. Given these labels, additional labels can
be computed using a simple static dataﬂow analysis. For
example, Job 1 and Job 2 both acquire the datatype label
IPAddress since they read File A; File C (and hence Job
3) acquires the datatype label IPAddress:Truncated. Given a
labeled data dependence graph, a conservative way of checking
non-interference is to check whether there exists a path from
restricted data to the program in the data dependence graph.
In a programming language such as C or Java, this approach
may lead to unmanagable overtainting. Fortunately, the data
analytics programs we analyze are written in a restricted
programming model without global state and with very limited
control ﬂow based on data. Therefore, we follow precisely this
approach. Languages like Hive [7], Dremel [8], or Scope [9]
that are used to write big data pipelines in enterprises adhere
to this programming model (Section IV provides additional
details). Note, that for the search engine that we analyze, the
data dependence graph does not come with these kinds of
labels. Bootstrapping these labels without signiﬁcant human
effort is a central challenge addressed by GROK (Section IV).
III. POLICY SPECIFICATION LANGUAGE
We present the design goals for LEGALEASE, the language
syntax and formal semantics, as well a set of illustrative policy
examples.
A. Design Goals
As mentioned, we intend legal teams and privacy champions
to encode policy in LEGALEASE. Therefore, our primary goal
is usability by individuals with typically no training in ﬁrst-
order or temporal logic, while being sufﬁciently expressive for
encoding current policies.
a) Usability: Policy clauses in LEGALEASE are struc-
tured very similarly to clauses in the English language policy.
This correspondence is important because no single individual
in a large company is responsible for all policy clauses;
different sub-teams own different portions of the policy and
Fig. 2. Example scenario showing a partially-labeled data dependency graph
between three ﬁles and programs.
tion, product development, and continuous auditing can pro-
ceed in parallel. Since we use automation to bridge code-level
details to policy concepts, meetings are needed only when our
automated privacy compliance checker (conservatively) detects
potentially sensitive scenarios, and are hence more focused,
especially on actionable items (dotted lines in Fig. 1).
Scale. Our scalability criteria are in (a) the amount of data over
which we perform automated privacy compliance checking;
(b) the time we take to do so; and (c) the number of people
resources needed for the entire effort. As we quantify in
Section VI, our deployed system scales to tens of millions
of lines of source code written by several thousand developers
storing data in tens of millions of ﬁles containing over hundred
million schema-elements, of which a substantial fraction is
changing or added on a day-to-day basis. Our data inventory
takes twenty minutes (daily), and evaluating the complete
LEGALEASE encoding of Bing’s privacy policy over the entire
data takes ten minutes. The entire effort was bootstrapped from
scratch by a team of ﬁve people.
II. MOTIVATING EXAMPLE
In this section, we use an example to highlight salient fea-
tures of our programming model and typical privacy policies
that these programs have to respect. These features motivate
the design of our privacy policy language LEGALEASE de-
scribed in Section III, the data inventory GROK described in
Section IV, and provide intuition on how privacy compliance