lists are generated using data from a 5-day window prior
to the prediction window. For all blacklists, the num-
ber of hits decreases along time. The HPB maintains an
advantage over the entire duration of the prediction win-
dow. From this plot, we also see that the blacklists need
to be refreshed frequently. In particular, there may be an
almost 30% hit drop when the HPB is more than a week
old.
The right panel of Figure 13 plots hit-number medians
for four HPBs. These HPBs are generated in a slightly
different way from the HPBs we used so far. In previ-
ous experiments, to generate an HPB, we produce the
correlation matrix from a set of attack reports. Then the
sources in the same set of reports are selected into HPBs
based on their relevance.
In this experiment, we con-
struct the correlation matrix using reports from training
windows of size 2, 5, 7, and 10 days. Then the sources
that are in the reports within the 5-day window right be-
fore the prediction (test) window are picked based on
their relevance. In this formulation, we exclude sources
that appear only in reports from distant history; we view
their extended silence to represent a signiﬁcant loss in
relevance. The remainder of the test is performed in the
same way as the previous experiments, i.e., the hit counts
are obtained in the following 5-day prediction window.
The experiment result shows that there is a slight in-
crease in the hit counts going from a 2-day training win-
dow to a 5-day training window. The hit counts then
remain roughly the same for the other training-window
size. This indicates that for most of the contributors, the
correlation matrix can be quite stable over time.
Figure 12: Hit Rates of HPB, GWOL, and LWOL with
Different Lengths
Although the hit rate for the shorter lists is higher, the
number of hits are larger for the longer lists. This is so
for all three types of blacklists. It shows that the longer
the list is, the more entries on the list are wasted (in the
5 An Example Blacklisting Service
In mid 2007, we deployed an initial prototype imple-
mentation of the HPB system, providing a subset of the
features described in this paper. This initial deploy-
ment was packaged as a free Internet blacklisting ser-
vice for DShield log contributors [22,23]. HPB blacklists
USENIX Association  
17th USENIX Security Symposium 
119
s
t
n
u
o
C
t
i
H
f
o
n
a
d
e
M
i
60
50
40
30
20
10
0
GWOL
LWOL
HPB
s
t
n
u
o
C
t
i
H
f
o
n
a
d
e
M
i
140
130
120
110
100
90
5
10
15
Day in Prediction Window
2
4
6
8
10
Training Window Size (days)
Figure 13: Effect of Training Window and Prediction Window Size on HPB’s hit count
are constructed for all contributors daily, and each con-
tributor can download her individual HPB through her
DShield website account. To date, we have had a rela-
tive small pool of HPB downloaders (roughly 70 users
over the most 3 months). We now describe several as-
pects of ﬁelding a practical and scalable implementation
of an HPB system based on our initial deployment expe-
riences. We present an assessment of the algorithm com-
plexity, the DShield service implementation, and discuss
some open questions raised from the open release of our
service.
5.1 Algorithm Complexity
Because HPBs are constructed from a relatively high-
volume corpus of security logs, our system must be pre-
pared to process well over 100M log entries per day
to process entries over the current 5-day training win-
dow. The bottleneck of the system is the relevance rank-
ing. Therefore, our complexity discussion focuses on the
ranking algorithm. There is always an amount of com-
plexity that is linear to the size of the alert data. That is,
let N(data) be the number of alerts in the data collec-
tion; we have a minimum complexity of O(N(data)).
Our discussion will focus on other complexities incurred
by the algorithm besides this linear-time requirement.
We denote by N(s) and N(v) the number of sources
in the data collection and the number of contributors to
the repository respectively. In practice, one can expect
N(v) to be in the order of thousands while N(s) is much
larger, typically in the tens of millions. We obtain W
and bs by going through the repository and doing simple
accounting. The adjacency matrix W requires the most
work to construct. To obtain this matrix, we record ev-
ery overlapped attack while going through the alert data
and then perform standardization. The latter steps re-
quire us to go through the whole matrix, which results in
O(N(v)2) complexity.
Besides going through the data,
time-
consuming step in the relevance estimate process is the
computation that solves the linear equations in Equa-
the most
tion 3. At ﬁrst glance, because for each source s, we
have a linear system determined by Equation 3, it seems
that we need to solve N(s) linear systems. This can
be expensive as N(s) is very large. Further investi-
gation shows that while bs is different per source s,
the (I − W)−1 part of the solution to Equation 3 is
the same for all s. Therefore, we need to compute it
only once, which requires O(N(v)3) time by brute force
or O(N(v)2.376) using more sophisticated methods [5].
Because bs is sparse, once we have (I − W)−1, the to-
tal time to obtain the ranking scores for all the sources
and all the contributors is O(N(v) · N(data)). Assum-
ing N(v)2 is much smaller than N(data), the total com-
plexity to make relevance ranking is O(N(v)·N(data)).
For a data set that contains a billion records contributed
by a thousand sensors, generating a thousand rankings
requires only several trillion operations (additions and
multiplications). This can be easily handled by modern
In fact, in our experiments, with N(data)
computers.
in the high tens of millions and N(v) on the order of
one thousand, it takes less than 30 minutes to generate
all contributor blacklists on an Intel Xeon 3.6 GHz ma-
chine.
5.2 The DShield Implementation
The pragmatics of deploying an HPB service through the
DShield website are straightforward. DShield log con-
tributors are already provided private web accounts in
order to review their reports. However, to ease the auto-
matic retrieval of HPBs, users are not required to log in
via DShield’s standard web account procedure. Instead,
contributors wishing to access their individual HPBs can
create account-speciﬁc hexadecimal tokens, and can then
append this token to the HPB URL. This token has a
number of advantages, particularly for developing and
maintaining automated HPB retrieval scripts. That is, a
user account password may be changed regularly, but the
retrieval token (and script) will remain unaffected.
To provide further protection of the integrity and con-
ﬁdentiality of an HPB the user may also pull the HPB via
120 
17th USENIX Security Symposium 
USENIX Association
# DShield Customized Blocklist
# created 2007-01-19 12:13:14 UTC
# for userid 11111
# some rights reserved, DShield Inc., Creative Commons Share Alike License
# License and Usage Info: http://www.dshield.org/blocklist.html
1.1.1.1
2.2.2.2
# End of list
test network
another test.
255.255.255.0
255.255.255.0
This network does not exist
Figure 14: A Sample Blocklist from DShield Implementation
https. A detached PGP signature can be retrieved in case
https is not available or not considered a sufﬁcient proof
of authenticity.
HPBs are distributed using a simple tab-delimited for-
mat. The ﬁrst column identiﬁes the network address.
The second column provides the netmask. Additional
columns are used to provide more information about the
respective offender, such as the name of the network and
country of origin (or type of attacks seen). These ad-
ditional columns are intended for human review of the
HPB. Comments may be added to the blocklist. All com-
ments start with a # mark. A sample blocklist is shown
in Figure 14.
5.3 Gaming the System
As we have made efforts to implement, test, and adver-
tise early versions of the HPB system, several open ques-
tions have been raised regarding the ability of adversaries
to game the HPB system. That is, can an attacker con-
tribute data to DShield with the intention of manipulating
HPB production in ways that negatively harm HPB qual-
ity? Let us consider several questions that arise from the
fact that HPBs are derived from volunteer sources, which
may include dishonest contributors that are actively try-
ing to harm or negatively manipulate HPB results.
Can an attacker cause a consumer to incorporate an
unsuspecting victim address into a third party’s HPB?
Let us assume that attacker A participates as one or more
DShield contributors (A might register multiple IDs) and
knows that consumer C is also a DShield contributor and
an active HPB user. Furthermore, A would like to cause
address B to be inserted into consumer C’s HPB. There
are two potential strategies A can pursue to achieve this
goal. First, A can spoof attacks as address B, directing
these attacks to other contributors that are highly corre-
lated with A. However, C’s correlated contributor set is
neither readily available to A (unless A is a DShield in-
sider) or necessarily stable over time. More plausibly, A
could artiﬁcially cause his own contributor IDs to report
the same attacks as C. He can do this by attacking C with
a set of spoofed addresses, and then reporting similarly
spoofed logs from his contributor IDs. Once a sufﬁcient
set of attack logs with identical spoofed attackers is re-
ported by C and A, C could then positively inﬂuence the
likelihood that address B will be inserted into A’s HPB.
While this is a possible threat, we also observe that simi-
lar attacks can be launched against GWOL and more triv-
ially against LWOL. Furthermore, in the case of GWOL,
B will be inserted in all consumers’ GWOLs, whereas
A must launch this attack individually against each HPB
consumer.
Can an attacker cause his own address to be excluded
from a speciﬁc third-party HPB? Let us assume that A
would like to guarantee that address B will not appear in
C’s HPB. This is very difﬁcult for A to guarantee. While
A may cause artiﬁcial alignment between his and C’s
logs using the alert spooﬁng method discussed above, A
cannot control what other addresses may also align with
C. If B attacks other contributors that are aligned with
C, B has the potential to enter C’s HPB.
Can an attacker fully prevent or poison all HPB pro-
duction? In short, yes. Data poisoning is a fundamental
threat that arises in all volunteer contributor-based data
centers, and is an inherently difﬁcult threat to overcome.
However, DShield does occasionally experience, and in-
corporate countermeasures for issues such as accidental
ﬂooding and sensor misconﬁguration. DDoS threats also
arise and are dealt with by DShield case by case.
HPB generation could also be speciﬁcally targeted by
a malicious contributor that attempts to artiﬁcially inﬂate
the number of attacker or victim addresses, which will in-
crease the values of s or v, as described in our complexity
analysis, Section 5.1. However, to sufﬁciently prohibit
HPB production, the contributor would necessarily pro-
duce highly anomalous volumes of attackers (or sources)
that would likely allow us to identify and (temporarily)
ﬁlter this contributor.
6 Conclusion
In this paper, we introduced a new system to generate
blacklists for contributors to a large-scale security-log
sharing infrastructure. The system employs a link anal-
ysis method similar to Google’s PageRank for black-
list formulation.
It also integrates substantive log pre-
USENIX Association  
17th USENIX Security Symposium 
121
[10] KATTI, S., KRISHNAMURTHY, B., AND KATABI, D. Collab-
orating against common enemies.
In Proceedings of the ACM
SIGCOMM/USENIX Internet Measurement Conference (October
2005).
[11] KIM, H.-A., AND KARP, B. Autograph: Toward automated,
distributed worm signature detection. In USENIX Security Sym-
posium (2004), pp. 271–286.
[12] LOCASTO, M., PAREKH, J., KEROMYTIS, A., AND STOLFO,
S. Towards collaborative security and P2P intrusion detection. In
Proceedings of the 2005 IEEE Workshop on Information Assur-
ance and Security (June 2005).
[13] M.GORI, AND PUCCI, A. Itemrank: A random-walk based scor-
ing algorithm for recommender engines. In Proceedings of the
International Joint Conference on Artiﬁcial Intelligence (January
2007).
[14] PORRAS, P., BRIESEMEISTER, L., SKINNER, K., LEVITT, K.,
ROWE, J., AND TING, Y. A hybrid quarantine defense. In Pro-
ceedings of the 2004 ACM Workshop on Rapid Malcode (WORM)
(October 2004).
[15] RUOMING, P., YEGNESWARAN, V., BARFORD, P., PAXSON,
V., AND PETERSON, L. Characteristics of internet background
radiation. In Proceedings of ACM SIGCOMM/USENIX Internet
Measurement Conference (October 2004).
[16] THOMAS, R. Bogon dotted decimal list v3.9. http://www.
cymru.com/Documents/bogon-dd.hml, October 2007.
[17] ULLRICH, J. DShield global worst offender list. https://
feeds.dshield.org/block.txt.
[18] VIXIE, P., AND RAND, D. Mail abuse prevention system
(MAPS). http://www.mail-abuse.com, 1997.
[19] WISSNER-GROSS, A. D. Preparation of topical readings lists
from the link structure of Wikipedia.
In Proceedings of the
IEEE International Conference on Advanced Learning Technol-
ogy (July 2006).
[20] YEGNESWARAN, V., BARFORD, P., AND ULLRICH, J. Internet
intrusions: global characteristics and prevalence. In Proceedings
of ACM SIGMETRICS (June 2003).
[21] YEGNESWARAN, V., PORRAS, P., SAIDI, H., SHARIF, M., AND
NARAYANAN, A. The Cyber-TA compendium honeynet page.
http://www.cyber-ta.org/Honeynet.
[22] ZHANG,
J.
J., PORRAS, P., AND ULLRICH,
The
DSHIELD highly predictive blacklisting service. http://
www.dshield.org/hpbinfo.html.
[23] ZHANG, J., PORRAS, P., AND ULLRICH, J. A new service for
increasing the effectiveness of network address blacklists. In Pro-
ceedings of the 3rd Workshop of Steps to Reduce Unwanted Traf-
ﬁc on the Internet (June 2007).
[24] ZHANG, J., PORRAS, P., AND ULLRICH, J. Gaussian process
learning for cyber-attack early warning. to appear in Proceedings
of SIAM Conference on data mining (2008).
ﬁltering and a severity metric that captures the degree to
which an attacker’s alert patterns match those of com-
mon malware-propagation behavior. Experimenting on
a large corpus of real DShield data, we demonstrate that
our blacklists have higher attacker hit rates, better new
attacker prediction quality, and long-term performance
stability.
In April of 2007, we released a highly predictive
blacklist service at DShield.org. We view this service
as a ﬁrst experimental step toward a new direction of
high-quality blacklist generation. We also believe that
this service offers a new argument to help motivate the
ﬁeld of secure collaborative data sharing. In particular,
it demonstrates that people who collaborate in blacklist
formulation can share a greater understanding of attack
source histories, and thereby derive more informed ﬁlter-
ing policies. As future work, we will continue to evolve
the HPB blacklisting system as our experience grows
through managing the blacklist service.
7 Acknowledgments
This material is based upon work supported through the
U.S. Army Research Ofﬁce under the Cyber-TA Re-
search Grant No. W911NF-06-1-0316.
References
[1] ANAGNOSTAKIS, K. G., GREENWALD, M. B., IOANNIDIS, S.,
KEROMYTIS, A. D., AND LI, D. A cooperative immunization
system for an untrusting Internet.
In Proceedings of the 11th
IEEE International Conference on Networks (ICON’03) (Octo-
ber 2003).
[2] BRIN, S., AND PAGE, L. The anatomy of a large-scale hypertex-
tual Web search engine. Computer Networks and ISDN Systems
30, 1-7 (1998), 107–117.
[3] CAI, M., HWANG, K., KWOK, Y., SONG, S., AND CHEN, Y.
IEEE Security and
Collaborative Internet worm containment.
Privacy Magazine 3, 3 (May/June 2005), 25–33.
[4] CHEN, Z., AND JI, C. Optimal worm-scanning method using
vulnerable-host distributions.
International Journal of Security
and Networks (IJSN) Special Issue on Computer & Network Se-
curity 2, 1 (2007).
[5] COPPERSMITH, D., AND WINOGRAD, S. Matrix multiplication
via arithmetic progressions. Journal of Symbolic Computation 9
(1990), 251–280.
[6] HUMPHRYS, M. The Internet in the 1980s. http://www.
computing.dcu.ie/˜humphrys/net.80s.html,
2007.
[7] INCORPORATED, G.
List of blacklists.
http:
//directory.google.com/Top/Computers/
Internet/Abuse/Spam/Blacklist%s/, 2007.
[8] INCORPORATED, G.
Live-feed anti-phishing blacklist.
http://sb.google.com/safebrowsing/update?
version=goog-black-url:1:1, 2007.
[9] JUNG, J., PAXSON, V., BERGER, A. W., AND BALAKRISH-
NAN, H. Fast portscan detection using sequential hypothesis test-
ing. In IEEE Symposium on Security and Privacy 2004 (Oakland,
CA, May 2004).
122 
17th USENIX Security Symposium 
USENIX Association