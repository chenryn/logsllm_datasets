those columns; it lets you group all rows that match those field together. Then the
grouped values get aggregated via an aggregation function, like count, sum, avg, min or
max so that one single value for that group is produced. This can be useful when you
want to do things like computing the average number of readings per day, or the sum of
the customers in each state. If the GROUP BY clause is specified, the query is always an
aggregate query, even if no aggregations are present in the select list. DuckDB has a
handy extension that lets you group your query by all columns that are not part of an
aggregate function, GROUP BY ALL. Figure 3.2 demonstrates how a selection of rows is
grouped by the column year and the results of applying the aggregates count, avg and
min and max to it.
Figure 3.2 Grouping a dataset by year
© Manning Publications Co. To comment go to liveBook
44
There are many aggregate functions to choose from. In addition to the above, which are
pretty standard, here are some that we think are often helpful:
list to aggregate all values of each group into a list structure
any_value picks any value from a non-grouping column
first or last to pick the first or the last value from a non-grouping
column if the result is ordered
arg_max and arg_min solve the common task of finding the value of an
expression in the row having a maximum or minimum value
Bit operations working on sets, such as bit_and, bit_or and bit_xor
Plus an exhaustive set of statistical aggregates ranging from median,
quantile computation to computing covariance and general regressions
The full list is here https://duckdb. org/docs/ sql/aggregates With that knowledge, let’s
see what we can do with our dataset.
Let’s pick up the prices example we started to use in section The SELECT and FROM
clauses. First, we added the WHERE clause to find prices in a year. While that was
interesting, how about finding out the minimum and maximum prices per year?
We will use the min and max aggregates grouped by the year in which the prices have
been valid to find out the highest and lowest prices in the years from 2019 to 2020. The
valid_from column is a date, we are only interested in the year. The date_part
function can extract that. If used without an alias, the resulting column would be named
date_part('year', valid_from). This does not read nicely, and it is also cumbersome
to refer to. Therefore, the AS keyword is used to introduce the alias year. DuckDB allows
us to refer to such an alias in the GROUP BY clause, which is different to the SQL
standard and very helpful. The year becomes the grouping key by specifying it in the
GROUP BY clause and its distinct values will define the buckets for which the minimum
and maximum values of the column we chose should be computed.
Listing 3.11 Grouped aggregates
SELECT date_part('year', valid_from) AS year,
min(value) AS minimum_price, -- #1
max(value) AS maximum_price
FROM prices
WHERE year BETWEEN 2019 AND 2020
GROUP BY year -- #2
ORDER BY year;
#1 You can have as many aggregate functions in the SELECT clause as you want
#2 Note how we can reuse the alias we gave in the SELECT clause in the GROUP BY clause.
The result of this query is shown below:
© Manning Publications Co. To comment go to liveBook
45
┌───────┬───────────────┬───────────────┐
│ year │ minimum_price │ maximum_price │
│ int64 │ decimal(5,2) │ decimal(5,2) │
├───────┼───────────────┼───────────────┤
│ 2019 │ 9.97 │ 11.47 │
│ 2020 │ 8.60 │ 9.87 │
└───────┴───────────────┴───────────────┘
TIP DuckDB offers choice when dealing with date parts. You can use the generic date_part
function like we did and specify the part as parameter. There are identifiers for all relevant parts
such as 'day', 'hour','minute' and many more. All of them exist also as dedicated
functions, so in listing 3.11 we could have used year(valid_from), too. The generic function
is helpful when the part is derived from other expressions in the statement or when you try to
write portable SQL. The dedicated functions are easier to read.
THE VALUES CLAUSE
The VALUES clause is used to specify a fixed number of rows. We have seen it already
while inserting data, which is a quite common use case. It is however much more
versatile in DuckDB than in some other databases, as it can be used as a stand-alone
statement and as part of the FROM clause too, with any number of rows and columns.
There are a couple of scenarios in which this is handy, for example providing seed data
for conditions.
Here’s how to define a single row with two columns like with a simple VALUES (1,2):
┌───────┬───────┐
│ col0 │ col1 │
│ int32 │ int32 │
├───────┼───────┤
│ 1 │ 2 │
└───────┴───────┘
Take note that multiple rows can be generated by just enumerating multiple tuples:
VALUES (1,2), (3,4), you don’t need to wrap them in additional parenthesis.
© Manning Publications Co. To comment go to liveBook
46
┌───────┬───────┐
│ col0 │ col1 │
│ int32 │ int32 │
├───────┼───────┤
│ 1 │ 2 │
│ 3 │ 4 │
└───────┴───────┘
If you do however, such as in VALUES ((1,2), (3,4)); you will create a single row
with two columns each containing a structured type:
┌────────────────────────────────┬────────────────────────────────┐
│ col0 │ col1 │
│ struct(v1 integer, v2 integer) │ struct(v1 integer, v2 integer) │
├────────────────────────────────┼────────────────────────────────┤
│ {'v1': 1, 'v2': 2} │ {'v1': 3, 'v2': 4} │
└────────────────────────────────┴────────────────────────────────┘
When used in a from clause the resulting types can be named, together with their
columns. We will make use of that in the next section while discussing joining logic. The
following snippet defines two rows with 3 columns within the VALUES clause and creates a
named type that holds the column names. The name of the type is arbitrary, we just
picked t.
SELECT *
FROM (VALUES
(1, 'Row 1', now()),
(2, 'Row 2', now())
) t(id, name, arbitrary_column_name);
The resulting virtual table looks like this:
┌───────┬─────────┬────────────────────────────┐
│ id │ name │ arbitrary_column_name │
│ int32 │ varchar │ timestamp with time zone │
├───────┼─────────┼────────────────────────────┤
│ 1 │ Row 1 │ 2023-06-02 13:44:30.309+02 │
│ 2 │ Row 2 │ 2023-06-02 13:44:30.309+02 │
└───────┴─────────┴────────────────────────────┘
© Manning Publications Co. To comment go to liveBook
47
THE JOIN CLAUSE
While you can get away without using a JOIN clause when analyzing single Parquet or
CSV files, you should not skip this section: Joins are a fundamental relational operation
used to connect two tables or relations. The relations are referred to as the left and right
sides of the join with the left side of the join being the table listed first. This connection
represents a new relation combining previously unconnected information, thus providing
new insights.
In essence a join creates matching pairs of rows from both sides of the join. The
matching is usually based on a key-column in the left table being equal to a column in
the right table. Foreign key constraints are not required for joining tables together. We
prefer the SQL standard definition of joins based on the JOIN .. USING over JOIN ..
ON clauses as you’ll see in the following examples and throughout the rest of the book.
Nevertheless, joins can be expressed by just enumerating the tables in the FROM clause
and comparing the key columns in the WHERE clause.
NOTE We are not using Venn diagrams for explaining joins because join-operations are not pure
set operations, for which Venn diagrams would be a great choice. SQL does know set operations
such as UNION, INTERSECT and EXCEPT—and DuckDB supports all of them. Joins on the other
hand are all based on a cartesian product in relational algebra, or in simple terms: They are all
based on joining everything with everything else, and then filter things out. In essence, all
different joins can be derived from the CROSS JOIN. The inner join filters then on some
condition, and a left or right outer join adds a union to it, but that’s all there is than to set-based
operations in joins.
In the following examples, we will use the VALUES clause to define virtual tables with a
fixed number of rows with a given set of values. These sets are helpful to understand the
joining logic as you will see both the sources and the resulting rows in the example.
Usually you will find yourself joining different tables together, such as the power readings
and the prices in our example.
The simplest way of joining is an INNER JOIN, which also happens to be the default.
An inner join matches all rows from the left-hand side to rows from the right-hand side
that have a column with the same value.
© Manning Publications Co. To comment go to liveBook
48
Figure 3.3 The inner join only matching pairs with equal keys
If both relations have a column with the sam e name, the USING clause can be used to
specify that. The USING clause will look up the specified columns in both relations and
work the same way as specifying them yourself via the ON clause (ON tab1.col =
tab2.col).
Listing 3.12 Using an inner join
SELECT *
FROM
(VALUES (1, 'a1'),
(2, 'a2'),
(3, 'a3')) l(id, nameA)
JOIN
(VALUES (1, 'b1'),
(2, 'b2'),
(4, 'b4')) r(id, nameB)
USING (id); -- #1
#1 This is equivalent to ON r1.id = r2.id
The result will look like this:
┌───────┬─────────┬─────────┐
│ id │ nameA │ nameB │
│ int32 │ varchar │ varchar │
├───────┼─────────┼─────────┤
│ 1 │ a1 │ b1 │
│ 2 │ a2 │ b2 │
└───────┴─────────┴─────────┘
© Manning Publications Co. To comment go to liveBook
49
An outer join on the other hand supplements NULL values for rows on the specified side
of the relation that have no matching entry on the other. Think of several power
producing systems in your database: for some you might have stored additional vendor
information in another table, for some you don’t. You would use an outer join when
tasked with "give me a list of all systems with the optional vendor or an empty column if
there’s no such vendor." Listing 3.13 uses a LEFT OUTER JOIN so that all rows of the left
relations are included and supplemented with NULL values for rows that don’t have a
match.
Listing 3.13 Using a left outer join
SELECT *
FROM
(VALUES (1, 'a1'),
(2, 'a2'),
(3, 'a3')) l(id, nameA)
LEFT OUTER JOIN
(VALUES (1, 'b1'),
(2, 'b2'),
(4, 'b4')) r(id, nameB)
USING (id)
ORDER BY id;
Joining the virtual tables from listing 3.13 with a LEFT OUTER JOIN results in:
┌───────┬─────────┬─────────┐
│ id │ nameA │ nameB │
│ int32 │ varchar │ varchar │
├───────┼─────────┼─────────┤
│ 1 │ a1 │ b1 │
│ 2 │ a2 │ b2 │
│ 3 │ a3 │ │
└───────┴─────────┴─────────┘
All rows from the left-hand side have been included and for a3 a NULL value has been
joined. Try changing the outer join from LEFT to RIGHT and observe which values are
now included. Both LEFT and RIGHT outer join will return 3 rows in total. For getting back
4 rows you must use a full outer join as shown below:
© Manning Publications Co. To comment go to liveBook
50
Listing 3.14 Using a full outer join
SELECT *
FROM
(VALUES (1, 'a1'),
(2, 'a2'),
(3, 'a3')) l(id, nameA)
FULL OUTER JOIN
(VALUES (1, 'b1'),
(2, 'b2'),
(4, 'b4')) r(id, nameB)
USING (id)
ORDER BY id;
Four rows will be returned, with two NULL values, once for nameA and once for nameB:
┌───────┬─────────┬─────────┐
│ id │ nameA │ nameB │
│ int32 │ varchar │ varchar │
├───────┼─────────┼─────────┤
│ 1 │ a1 │ b1 │
│ 2 │ a2 │ b2 │
│ 3 │ a3 │ │
│ 4 │ │ b4 │
└───────┴─────────┴─────────┘
Figure 3.4 represents both the left outer join, the full outer join that we had in code
before plus the right outer join for comparison, too:
© Manning Publications Co. To comment go to liveBook
51
Figure 3.4 Types of outer joins
While an outer join gives you always the r ows an inner join would give, it would be
wrong to suggest always using outer joins. An inner join will filter out rows that have no
matching data in the other table, which is often a requirement. An outer join will usually
be appropriate when you want to enrich required data with optional data.
The above example applies the USING clause for the join conditions as both tables
have an id column. In our example we defined an id column in the systems table and
the foreign key column in readings as system_id. We therefore must use the ON
clause. When joined on that column, the join will always produce a matching row, as the
join column (id) is the column referenced by the foreign key we defined on system_id.
That means there can’t be any row in the readings table without a matching entry in the
systems table:
SELECT name, count(*) as number_of_readings
FROM readings JOIN systems ON id = system_id
GROUP BY name;
NOTE A cartesian product is a mathematical term. It describes the list of all ordered pairs that
you can produce from two sets of elements by combining each element from the first set with
each element of the second set. The size of a cartesian product is equal to the product of the
sizes of each set.
© Manning Publications Co. To comment go to liveBook
52
There are more join types, such as the CROSS JOIN, which creates a Cartesian product
of all tuples, and the ASOF ("as of"), that will come in handy when dealing with the prices
having a restricted validity for example: the ASOF join allows to match rows from one
table with rows from another table based on temporal validity (or as a matter of fact with
anything that has an inequality condition ( or >=)). You will read about the ASOF
join in chapter 4.8 in detail.
TIP You are building data pipelines around CSV files and often have data split across several files
with one common column per file. What if you wanted to reduce these files to exactly one file
without duplicating the common column? That’s easy to achieve with an inner join and the COPY
TO command. The latter takes any relation and copies it to a file using the specified format:
console
duckdb -c "COPY (SELECT * FROM 'production.csv' JOIN 'consumption.csv'
➥ USING (ts) JOIN 'export.csv' USING (ts) JOIN 'import.csv' USING (ts) )
➥ TO '/dev/stdout' (HEADER)"
This command will join 4 csv files on a shared column ts, keep only one copy of the shared
column in the SELECT * statement and copy the result to standard out.
We’d like to end this section with some sort of warning. In our examples for inner and
outer joins we only discussed what happens when a value of a key-column is not found
in one of the other tables. But what happens when one of the join columns contains the
same value multiple times, either in one of the join tables or in both? Let’s find out. The
value 2 for the id column appears twice in the left table and the value 3 twice in the
right table.
© Manning Publications Co. To comment go to liveBook
53
Listing 3.15 An inner join between tables with duplicate key columns
SELECT *
FROM
(VALUES (1, 'a1'),
(2, 'a2'),
(2, 'a2'),
(3, 'a3')) l(id, nameA)
JOIN