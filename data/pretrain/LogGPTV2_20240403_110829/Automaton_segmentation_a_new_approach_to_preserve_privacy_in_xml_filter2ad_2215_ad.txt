potential risk if others know that the particular data server
192.168.0.3 holds “Abacavir” information.
In our PPIB
framework, the broker only knows user identity, but not the
query itself. The root coordinator knows the query, but not
the user identity or query location. Other coordinators know
only partial contents of the query, but not the user identity
or query location. The leaf coordinator knows where the
data is located, but it has no hint about the query, i.e., it
knows “where”, but not “what”. We can further examine
this example according to Figure 4. As a conclusion, note
that all of user, data, and metadata privacies are protected
2
in our proposed PPIB framework.
5. PPIB MAINTENANCE
Besides routine key management, P P IB maintenance is
evoked (1) when a brokering component joins/leaves the sys-
tem, (2) when a data server joins/leaves, and (3) when an
access control rule is added/removed. In this section, we de-
scribe of system maintenance procedures in these scenarios.
In previous sections, we implicitly assume that there exists
a system administrator, who decides issues like automaton
segmentation granularity and site distribution. Now we for-
mally introduce it as administrator node, which has the high-
est trust and security level and oversees the whole overlay
network. Administrator is needed only when initiating the
overlay or when maintenance requests are received. There-
fore, the administrator node is not always active.
A. When Brokering Component Joins/Leaves. Bro-
kering components include brokers and coordinators. Be-
fore joining, it sends a request to the administrator node
(through an existing peer) to wake it up. The administrator
checks the security and trust level of the peer, observes the
load of all brokers/coordinators in the network, and assigns
a role to the new peer. If it is a coordinator, usually, exist-
ing sites are moved or replicated to the new host (refer to
Section 4.2 for site replication). If the new peer is a bro-
ker, it simply replicates an existing broker. Finally, the ad-
ministrator broadcasts the newcomer to the super node and
other related peers. For instance, if the newcomer replicates
a root-coordinator, its address is sent to related brokers.
When a peer wants to leave the network, it calls up the
administrator with the request. Based on the load of this
peer and availability of replications, the administrator could
drop the hosted sites, or move some sites to another coor-
dinator. The administrator also informs the super node as
well as related peers (e.g. coordinators whose dummy accept
states point to the leaving coordinator).
Moreover, to avoid unexpected failures of coordinators,
the administrator routinely checks their status. If a coordi-
nator fails, the administrator assigns its task to others and
re-routes the related peers. The administrator also balances
workload by managing site replications.
B. When Data Server or Object Joins/Leaves. Data
location information tells how data is distributed over data
servers. When a data server or a data object is added or
removed, an update message is created and sent to the ad-
ministrator for authentication. The message is in the form of
msg(DSAddr, XP ath, +/−), where DSAddr is the address
of the data server, XP ath is an XPath expression that refers
data objects, and +/− denotes add or removal, respectively.
When a data server/object is removed from the network,
administrator ﬁrst processes the msg.XP ath through the
automaton to locate related leaf-coordinators, and removes
the corresponding indexing rules from them. If a leaf-coordinator
does not carry any indexing rule after removal, the corre-
sponding path (from the root-coordinator to the particular
leaf) is examined and the sites who does not carry any other
rules are suspended.
Example 5. For the coordinator network shown in Figure
4, if we remove data server 192.168.0.5 with the following
message:
msg(192.168.0.5, /site/categories/category/name, -)
then, indexing rule at Site 4 is ﬁrst removed. Moreover, sites
2, 3, and 4 are suspended since they are not leading to any
2
data.
When a data server/object is added to DIBS, the ad-
ministrator locates related leaf-coordinators by processing
msg.XP ath through the automata, and assigns msg.DSAddr
to them. If the new data server/object aﬀects a suspended
branch of the coordinator network, the branch is then acti-
vated.
C. When ACR is Added/Removed. Whenever a data
owner wants to change access control policy, he sends an
updating request to the administrator: msg ac(ACR, +/−).
When a new access control rule is added to the system, it is
sent to the root-coordinator. The XPath expression of the
rule go through the automaton until no exact match is found
at a certain state. The administrator creates new automaton
states for the remaining segments of the new rule. The newly
constructed automaton segments are then distributed to the
coordinator network. Moreover, related indexing rules are
identiﬁed and attached to the new leaf-coordinator. The
removal of an access control rule also starts from the leaf-
coordinator, and goes backward until it reaches a site which
also holds keywords from other rules.
6. PRIVACY AND SECURITY ANALYSIS
In this section, we consider four types of attackers in an
DIBS, and estimate possible damage that the attackers can
do to hurt user privacy, data privacy, or metadata privacy.
In general, there are various types of attackers. Considering
their roles, we can categorize them as malicious insiders and
ambitious outsiders; considering their capabilities, as eaves-
droppers and power attackers that can compromise any bro-
kering component; considering their working mode, as single
attackers or collusive attackers. In this work, we propose a
taxonomy of four distinct types of attackers, which covers
all aforementioned types of attackers.
A. Local Eavesdropper
A local eavesdropper is an attacker who can observe all
communication to and from the user side. Once an end
user initiates an inquire or receives requested data, the lo-
cal eavesdropper can seize the outgoing and incoming pack-
ets. However, it can only learn the location of local broker
from the captured packets since the content is encrypted.
Although local brokers are exposed to this kind of eaves-
droppers, as a gateway of DIBS system, it prevents further
probing of the entire DIBS. Although the disclosed broker lo-
cation information can be used to launch DoS attack against
local brokers, a backup broker and some recovery mecha-
nisms can easily defend this type of attacks. As a conclusion,
an outside attacker who is not powerful enough to compro-
mise brokering components in the system is less harmful to
system security and privacy.
B. Global Eavesdropper
A global eavesdropper is an attacker who observes the
traﬃc in the entire network.
It watches brokers and co-
ordinators gossip, so it is capable to infer the locations of
local brokers and root-coordinators. This is because the as-
surance of the connections between user and broker, and be-
tween broker and root-coordinator. However, from the later-
on communication, the eavesdropper cannot distinguish the
coordinators and the data servers. Therefore, the major
threat from a global eavesdropper is the disclosure of broker
and root-coordinator location, which makes them targets of
further DoS attack.
Privacy Type 
User Location 
Query Content 
Local 
Eavesdropper 
Global 
Eavesdropper 
Exposed 
Protected 
Exposed 
Protected 
Malicious 
Broker 
Exposed 
Protected 
Access Control Policy 
Protected 
Protected 
Protected 
Index Information 
Protected 
Protected 
Protected 
Data Object 
Distribution 
Data Server Location 
Components exposed 
to DoS attacks  
Protected 
Protected 
Brokers 
Protected 
Protected 
Beyond Suspicion
Brokers and the 
root-coordinator 
Protected 
Root-
coordinator
Collusive 
Coordinators 
Protected 
Only if root-coordinator 
is corrupted 
Only if all the 
coordinators collusively 
collaborate 
Protected 
Only if all the 
coordinators collusively 
collaborate 
Only if leaf-coordinators 
are corrupted 
Data server if leaf-
coordinators are 
corrupted 
Figure 5: The possible privacy exposure caused by
four types of attackers.
C. Malicious Broker
A malicious broker deviates from the prescribed protocol
and discloses sensitive information. It is obvious that a cor-
rupted broker endangers user location privacy but not the
privacy of query content. Moreover, since the broker knows
the root-coordinator locations, the threat is the disclosure
of root-coordinator location and potential DoS attack.
D. Collusive Coordinators
Collusive coordinators deviate from the prescribed proto-
col and disclose sensitive information.
Consider a set of collusive (corrupted) coordinators in the
coordinator tree framework. Even though each coordina-
tor can observe traﬃc on a path routed through it, noth-
ing will be exposed to a single coordinator because (1) the
sender viewable to it is always a brokering component; (2)
the content of the query is incomplete due to query segment
encryption; (3) the ACR and indexing information are also
incomplete due to automaton segmentation; (4) the receiver
viewable to it is likely to be another coordinator. However,
privacy vulnerability exists if a coordinator makes reason-
able inference from additional knowledge. For instance, if a
leaf-coordinator knows how PPIB mechanism works, it can
assure its identity (by checking the automaton it holds) and
ﬁnd out the destinations attached to this automaton are of
some data servers. Another example is that one coordinator
can compare the segment of ACR it holds with the open
schemas and make reasonable inference about its position
in the coordinator tree. However, inference made by one
coordinator may be vague and even misleading.
Finally, we summarize the possible privacy exposure in Fig-
ure 5.
7. PERFORMANCE ANALYSIS
In this section, we analyze the performance of proposed
PPIB system using end-to-end query processing time and
system scalability.
In our experiments, coordinators are
coded in Java (JDK 5.0) and results are collected from coor-
dinators running on a Windows desktop (3.4G CPU). We use
the XMark [23] XML document and DTD, which is wildly
used in the research community. As a good imitation of real
world applications, the XMark simulates an online auction
scenario.
7.1 End-to-End Query Processing Time
End-to-end query processing time is deﬁned as the time
elapsed from the point when query arrives at the broker until
to the point when safe answers are returned to the user. We
X: Number of keywords at a query broker; Y: Time (ms)
(cid:19)(cid:17)(cid:19)(cid:20)(cid:19)
(cid:19)(cid:17)(cid:19)(cid:19)(cid:27)
(cid:19)(cid:17)(cid:19)(cid:19)(cid:25)
(cid:19)(cid:17)(cid:19)(cid:19)(cid:23)
(cid:19)(cid:17)(cid:19)(cid:19)(cid:21)
(cid:19)(cid:17)(cid:19)(cid:19)(cid:19)
(cid:52)(cid:88)(cid:72)(cid:85)(cid:92)(cid:3)(cid:37)(cid:85)(cid:82)(cid:78)(cid:72)(cid:85)(cid:76)(cid:81)(cid:74)
(cid:36)(cid:86)(cid:92)(cid:80)(cid:80)(cid:72)(cid:87)(cid:85)(cid:76)(cid:70)(cid:3)(cid:40)(cid:81)(cid:70)(cid:85)(cid:92)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)
(cid:54)(cid:92)(cid:80)(cid:80)(cid:72)(cid:87)(cid:85)(cid:76)(cid:70)(cid:3)(cid:40)(cid:81)(cid:70)(cid:85)(cid:92)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)
(cid:21)(cid:17)(cid:24)(cid:19)
(cid:21)(cid:17)(cid:19)(cid:19)
(cid:20)(cid:17)(cid:24)(cid:19)
(cid:20)(cid:17)(cid:19)(cid:19)
(cid:19)(cid:17)(cid:24)(cid:19)
(cid:19)(cid:17)(cid:19)(cid:19)
(cid:20)
(cid:21)
(cid:22)
(cid:23)
(cid:24)
(cid:20)
(cid:21)
(cid:22)
(cid:23)
(cid:24)
(a)Average
time at a coordinator.
query
brokering
(b)Average symmetric and asym-
metric encryption time.
Figure 6: Average query processing time at a coor-
dinator (TC ).
consider the following four components: (1) average query
brokering time at each broker/coordinator (TC ); (2) average
network transmission latency between broker/coordinators
(TN ); (3) average query evaluation time at data server(s)
(TE); and (4) average backward data transmission latency
(Tbackward).
Query evaluation time highly depends on XML databases
system, size of XML documents, and types of XML queries.
Once these parameters are set in the experiments, TE will
remain the same (at seconds level [14]). Similarly, the same
query set and ACR set will create the same safe query set,
and the same data result will be generated by data servers.
As a result, TE and Tbackward are not aﬀected by the broker-
coordinator overlay network. We only need to calculate and
compare the total forward query processing time (Tf orward)
as Tf orward = TC × NHOP + TN × (NHOP + 1). It is obvious
that Tf orward is only aﬀected by TC , TN , and the average
number of hops in query brokering, NHOP .
Average query processing time at a coordinator: Query
processing time at each broker/coordinator (TC ) consists of:
(1) access control enforcement and locating next coordinator
(Query brokering); (2) generating a key and encrypting the
processed query segment (Symmetric encryption); and (3)
encrypting the symmetric key with the public key created
by super node (Asymmetric encryption).
To examine TC , we manually generate ﬁve sets of access
control rules. Access control rules of each set are partitioned
into segments (keywords), which are assigned to coordina-
tors. From set 1 to set 5, the number of keywords held by
one coordinator increases from 1 to 5. We also generate 1000
synthetic XPath queries, and use Triple DES for symmetric
encryption and RSA for asymmetric encryption. Figure 6(a)
shows that query brokering time is at milliseconds level, and
increases linearly with the number of keywords at a site. Fig-
ure 6(b) shows that symmetric and asymmetric encryption
time is at seconds level, and asymmetric encryption time
dominates the total query processing time at a coordinator.
As a result, average (TC ) is about 1.9 ms. Query processing
time at brokers and leaf-coordinators are shorter but still in
the same level. For simplicity, we adopt the same value (i.e.
1.9 ms) for the average query processing time at brokers and
coordinators.
Average network transmission latency: We adopt av-
erage Internet traﬃc latency 100 ms as a reasonable esti-
mation of TN [1], instead of using data collected from our
gigabyte Ethernet.
Average number of hops in query processing: We con-
sider the case in which a query Q is accepted or rewritten
by n ACRs {R1, ..., Rn} into the union of n safe sub-queries
X: number of access control rules; Y: number of coordinators.
(cid:22)(cid:19)(cid:19)
(cid:22)(cid:19)(cid:19)
(cid:24)(cid:19)
(cid:27)(cid:28)
(cid:20)(cid:21)(cid:23)
(cid:20)(cid:24)(cid:24)
(cid:20)(cid:28)(cid:24)
(cid:21)(cid:19)(cid:26)
(cid:21)(cid:20)(cid:27)
(cid:21)(cid:22)(cid:24)
(cid:21)(cid:24)(cid:19)
(cid:21)(cid:25)(cid:28)
(cid:21)(cid:24)(cid:19)
(cid:21)(cid:19)(cid:19)
(cid:20)(cid:24)(cid:19)
(cid:20)(cid:19)(cid:19)
(cid:24)(cid:19)
(cid:19)
(cid:21)(cid:19)
(cid:23)(cid:19)
(cid:25)(cid:19)
(cid:27)(cid:19)
(cid:20)(cid:19)(cid:19)
(cid:20)(cid:21)(cid:19)
(cid:20)(cid:23)(cid:19)
(cid:20)(cid:25)(cid:19)
(cid:20)(cid:27)(cid:19)
(cid:21)(cid:19)(cid:19)
(cid:21)(cid:24)(cid:19)
(cid:21)(cid:19)(cid:19)
(cid:20)(cid:24)(cid:19)
(cid:20)(cid:19)(cid:19)
(cid:24)(cid:19)
(cid:19)
(cid:19)
(cid:24)(cid:19)
(cid:20)(cid:19)(cid:19)
(cid:20)(cid:24)(cid:19)
(cid:21)(cid:19)(cid:19)
(cid:19)
(cid:24)(cid:19)