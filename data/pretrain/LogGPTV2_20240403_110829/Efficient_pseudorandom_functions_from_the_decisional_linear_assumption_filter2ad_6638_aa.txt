title:Efficient pseudorandom functions from the decisional linear assumption
and weaker variants
author:Allison B. Lewko and
Brent Waters
Eﬃcient Pseudorandom Functions From the
Decisional Linear Assumption and Weaker
Variants
Allison B. Lewko ∗
Brent Waters †
University of Texas at Austin
University of Texas at Austin
Abstract
In this paper, we generalize Naor and Reingold’s construction of pseudorandom
functions under the DDH Assumption to yield a construction of pseudorandom
functions under the decisional k-Linear Assumption, for each k ≥ 1. The deci-
sional Linear Assumption was ﬁrst introduced by Boneh, Boyen, and Shacham as
an alternative assumption for settings where the DDH problem is easy, such as bi-
linear groups. This assumption can be generalized to obtain the decisional k-Linear
Assumptions. Shacham and Hofheinz and Kiltz showed that the decisional (k + 1)-
Linear problem is hard for generic groups even when the decisional k-Linear problem
is easy. It is thus desirable to have constructions of cryptographic primitives based
on the decisional k-Linear Assumption instead of DDH. Not surprisingly, one must
pay a small price for added security: as k increases, our constructed functions be-
come slightly less eﬃcient to compute and the key size increases (quadratically in
k).
1
Introduction
Pseudorandom functions were ﬁrst deﬁned by Goldreich, Goldwasser, and Micali
[14]. Informally, a pseudorandom function ensemble is a collection of functions that
can be eﬃciently sampled and computed, but cannot be distinguished from random
functions by a polynomial time adversary with only black-box access. We will
give a formal deﬁnition in the next section. These cryptographic primitives have
many applications (e.g.
[3, 7, 12, 13, 20, 25, 28]). For example, a pseudorandom
function is often substituted for a truly random function in an application where
true randomness would be unacceptably ineﬃcient. In private-key cryptography, a
relatively short description of a pseudorandom function can be used as a private key,
allowing parties who share this private key to send encrypted messages or verify
each other’s knowledge of the shared secret without needing to reveal the secret
itself. For applications of pseudorandom functions in private-key cryptography, see
e.g.
[7, 13, 20]. Pseudorandom functions are also used in public-key cryptography
[3, 12]), learning theory (e.g.
(e.g.
[25]).
[28]), and complexity theory (e.g.
∗Supported by National Defense Science and Engineering Graduate Fellowship.
†Supported by NSF CNS-0716199, Air Force Oﬃce of Scientiﬁc Research (AFO SR) under the MURI
award for “Collaborative policies and assured information sharing” (Project PRESIDIO).
1
Motivation These numerous applications make it desirable to have construc-
tions of pseudorandom functions which are both eﬃcient enough to be implemented
in practice and based on well-established assumptions. Goldreich, Goldwasser, and
Micali gave the ﬁrst construction of a pseudorandom function ensemble, known
as the GGM-Construction [14]. This construction relied only on pseudorandom
generators, which can be built from any one-way function (as shown in [15]). In
[23], Noar and Reingold gave two constructions of pseudorandom functions which
are much more eﬃcient to compute than the GGM functions. One construction
was based on the Decisional Diﬃe-Hellman Assumption (DDH) and the other was
based on the assumption that factoring Blum integers is hard. (See section 2 for
the deﬁnition of the DDH Assumption.)
The DDH Assumption is a commonly used assumption with several attractive
Its applications include the Diﬃe-Hellman key-exchange protocol (the
qualities.
context in which DDH was introduced)
[10], ElGamal encryption [11], Cramer-
Shoup CCA-secure public key encryption [8], undeniable signatures [6], veriﬁable
secret sharing [27], and many others. Naor and Reingold gave a reduction between
the worst-case and the average-case DDH problem, showing that it is either hard
on average or easy even in the worst case.
Though such a reduction gives credence to the belief that the DDH Assumption
holds in groups where it is not known to be easy on average, there are groups
where the DDH Assumption fails. Most notably, the DDH problem is easy in
bilinear groups.
In [21], Menezes, Okamoto, and Vanstone showed that there
are subexponential attacks on the discrete log problem in certain elliptic curve
groups (supersingular curves) which had been previously been suggested for use in
cryptographic systems. This example shows that even well-established assumptions
can be found to have surprising weaknesses in certain implementations. Developing
cryptographic primitives and systems based on progressively weaker assumptions is
therefore advantageous because it provides some protection against future advances
in cryptanalysis.
There is evidence that groups exist in which the DDH problem is easy but the
CDH problem (Computational Diﬃe-Hellman) is hard [17]. In such groups, we
might still rely on the diﬃculty of computing discrete logarithms, but we must
avoid the DDH Assumption. One alternative is the decisional Linear Assumption,
introduced by Boneh, Boyen, and Shacham [5]. This assumption can be generalized
to yield the decisional k-Linear Assumptions, which we will refer to simply as the
k-Linear Assumptions for brevity. A gap variant of the k-Linear Assumptions was
ﬁrst proposed by Kiltz in [18]. The form we will use was given independently in
Shacham [26] and Hofheinz and Kiltz [16]. The 1-Linear Assumption is DDH, and
the 2-Linear Assumption is the Linear Assumption from [5]. Both [16, 26] note
that the (k+1)-Linear Assumption holds in a generic group even when the k-Linear
problem is easy and give constructions of chosen-ciphertext secure cryptosystems
based on the k-Linear Assumption for any positive integer k.
Our Contribution We generalize the construction of Naor and Reingold to
yield pseudorandom function ensembles based on the Linear and k-Linear Assump-
tions. We thus achieve added security, and we do so with relatively little cost in
eﬃciency. It is not too diﬃcult to see that a change to the Naor-Reingold construc-
tion is necessary if the DDH problem is easy. The Naor-Reingold construction maps
an n-bit string x = (x1, . . . , xn) into a cyclic group G of prime order p generated by
2
g. A pseudorandom function f is speciﬁed by the group G, g, p, and n + 1 values
in Zp denoted by a0, a1, . . . , an. Naor and Reingold deﬁne:
(cid:81)
fG,p,g,a0,...,an(x) = (ga0)
xi=1 ai.
(1)
If we have access to an algorithm A that solves the DDH problem with non-
negligible advantage, then we can distinguish such an f from a truly random func-
tion with non-negligible advantage as follows. We query f on four inputs and obtain
responses:
f(1, 1, . . . , 1, 1) = B1,
f(0, 0, . . . , 0, 1) = B3,
f(1, 1, . . . , 1, 0) = B2,
f(0, 0, . . . , 0, 0) = B4.
If f is a Naor-Reingold pseudorandom function with key {G, p, g, a0, . . . , an}, then
B1 = ga0a1...an, B2 = ga0a1...an−1, B3 = ga0an, and B4 = ga0. We set ˜g = B4, ˜ga =
B3, ˜gb = B2, and T = B1.
If f is pseudorandom, then ˜g = ga0, a = an, b =
a1 . . . an−1, and T = ˜gab. If f is truly random, then T is uniformly random. Hence,
when ˜g, ˜ga, ˜gb, T are given to A as input, the output of A can be used to distinguish
whether f is pseudorandom or truly random with non-negligible advantage.
Our generalized construction and the proof of its security diﬀer from the Naor-
Reingold version in two primary ways. First, the additional complexity required
to accommodate the weaker assumptions means that our functions can no longer
be described by closed-form formulas like (1). Nonetheless, the additional cost in
computational eﬃciency is rather small. Second, the Linear Assumption cannot be
embedded into our construction as directly as the DDH Assumption is embedded
in Naor-Reingold, so we must use two separate instantiations of the hybrid tech-
nique to prove the pseudorandomness of our construction instead of just one. More
speciﬁcally, the Naor-Reingold construction relies on a pseudorandom generator
that doubles its input and arises very naturally from the DDH Assumption. Ob-
taining a suitable pseudorandom generator that doubles its input from the Linear
Assumption is more diﬃcult, and requires use of the hybrid technique. We discuss
this issue in more detail in section 3.
Other Related Work In practice, ad hoc designs of cryptographic primitives
are often substituted for constructions which are proven to be secure under standard
assumptions. This may yield greater eﬃciency, but it has been shown to be very
dangerous. The potential for compromising vulnerabilities in ad hoc designs further
motivates our search for eﬃcient constructions of cryptographic primitives with
accompanying proofs of security under weak assumptions. Collision attacks against
commonly used hash functions like MD5, SHA-0, and SHA-1 have recently been
demonstrated [4, 29]. There is also an ad hoc design of pseudorandom functions,
known as TLS, that uses both SHA-1 and MD5 [9]. This design is intended to
be secure if both SHA-1 and MD5 are secure, but this is not rigorously proven
and it may be that both of these hash functions are vulnerable. Bellare, Canetti,
and Krawczyk give two constructions, NMAC and HMAC, which are proven to be
secure under the assumption that the underlying hash function is suitably secure
[2], but it may still be the case that an ad hoc hash function chosen for a practical
implementation has previously unknown weaknesses.
To implement our construction in practice, one must balance eﬃciency with
security in the choice of the group where the k-Linear Assumption will be relied
3
upon. One usually chooses the security parameters based on the best known attacks.
In particular, if one chooses two large primes p and q such that p divides q − 1,
we can work in a subgroup of order p in Z∗
q. The known attacks on the discrete
logarithm problem in this case include Shanks’ baby-step giant-step algorithm [19]
√
and Pollard’s rho method [24], both of which take O(
p) time. There is also the
√
index calculus algorithm [1], which runs in time O
. This is a
subexponential attack, but still not polynomial time. These known attacks mean
that if we want roughly 80 bits of security in this group, we need to set the size of
p to at least 160 bits and the size of q to at least 1024 bits.
log q log log q)(cid:17)
(cid:16)
2O(
Naor and Reingold additionally show that the algebraic simplicity of their con-
struction implies that interactive zero-knowledge proofs can be given for statements
of the form “y = fs(x)” and “y (cid:54)= fs(x)” once the party computing the pseudo-
random function fs has committed to the key s [23]. Micali, Rabin, and Vadhan
deﬁne and construct veriﬁable random functions [22], which have an even stronger
property: the proofs of statements “y = fs(x)” do not require interaction or a
trusted shared random string. We will not be concerned with such properties for
our construction, as our primary goals are computational eﬃciency and heightened
security.
Organization In the next section, we formally deﬁne pseudorandom functions
and the k-Linear Assumptions. We also establish a basic property shared by these
assumptions that will be useful to us. In section 3, we give our construction based
on the Linear Assumption (the case k = 2) and prove it is pseudorandom.
In
section 4, we generalize our construction to hold under the k-Linear Assumption
for each positive integer k and summarize the generalized proof. In section 5, we
summarize the important properties of our pseudorandom functions and analyze
their performance.
2 Background
2.1 Formal Deﬁnition of Pseudorandom Functions
We give the deﬁnition that is provided in [23]:
Deﬁnition 1 (eﬃciently computable pseudorandom function ensemble) Let {An, Bn}
be a sequence of domains and ranges and let F = {Fn}n∈N be a function ensemble
where each Fn is a random variable taking values in the set of functions from An
to Bn. Then F is an eﬃciently computable pseudorandom function ensemble if it
satisﬁes the following two conditions:
for every probabilistic polynomial time oracle machine M, every constant
1.
c > 0, and all but ﬁnitely many n’s,
(cid:12)(cid:12)P r[MFn(1n) = 1] − P r[MRn(1n) = 1](cid:12)(cid:12) <
1
nc ,
where Rn is uniformly distributed over the set of all functions from An to Bn,
2. there exist probabilistic polynomial time algorithms I and V and a mapping
φ from strings to functions such that φ(I(1n)) and Fn are identically distributed (so
Fn can be eﬃciently sampled) and V(i, x) = (φ(i))(x) (the sampled function can be
eﬃciently computed).
4
We note that oracle machine M in requirement 1 can know the description of
the pseudorandom function ensemble, just not the key of the particular function it
is querying.
2.2 The Decisional k-Linear Assumptions
We deﬁne the Linear problem in a cyclic group G of prime order p: given
0 ∈ G, distinguish whether r0 = r1 + r2 or is random. The
g0, g1, g2, gr1
assumption is that no polynomial time algorithm can distinguish between these
two cases of r0 with non-negligible advantage. More formally,
1 , gr2
2 , gr0
Deﬁnition 2 Linear problem in G: given g0, g1, g2, gr1
if r0 = r1 + r2 and “no” otherwise.
1 , gr2
2 , gr0
0 ∈ G, output “yes”
The advantage of an algorithm A in deciding the Linear problem is deﬁned to
be:
AdvA =
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) P r[A(g0, g1, g2, gr1
−P r[A(g0, g1, g2, gr1
(We use the notation g0, g1, g2
G uniformly randomly.)
1 , gr2
0
2 , gr1+r2
2 , gr0
) = yes : g0, g1, g2
0 ) = yes : g0, g1, g2
1 , gr2
R←− G to convey that these elements are chosen from
R←− G, r1, r2
R←− G, r1, r2, r0
R←− Zp]
R←− Zp]
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) .
Deﬁnition 3 Linear Assumption in G: no polynomial time algorithm can achieve