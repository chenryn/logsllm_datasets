ﬁc. We introduce a low rate broadcast stream of 100 Kb/s. Notice
that in the no EtherFuse case, response times suffer substantially
due to packet loss because of network saturation. This is because
the broadcast packets get trapped in the loop leading to conges-
)
s
(
i
e
m
T
e
s
n
o
p
s
e
R
 20
 15
 10
 5
 0
Response Time
Without EtherFuse
)
s
(
i
e
m
T
e
s
n
o
p
s
e
R
 0
 5
 10
 15
 20
 25
 30
 35
 40
Time (s)
(a) Without EtherFuse
 20
 15
 10
 5
 0
Response Time
With EtherFuse
 0
 5
 10
 15
 20
 25
 30
 35
 40
Time (s)
(b) With EtherFuse
Figure 14: Timeline of response times of HTTP requests generated every tenth
of a second under a count to inﬁnity induced temporary forwarding loop. Count
to inﬁnity starts at t=10. A background broadcast trafﬁc of 100 Kb/s is injected
into the network.
tion. Also note that some web requests suffer from a 21 second
response time. This is due to three consecutive packet drops in the
connection phase leading to 3 exponential backoffs. When using
the EtherFuse, it quickly detects both the count to inﬁnity and the
forwarding loop and cuts the loop to recover from this failure.
To further understand the scenario, Table 3 shows the number
of duplicate packets detected in the network. Note that a massive
amount of duplicate packets are detected when there is background
broadcast trafﬁc and in the absence of the EtherFuse.
6.2.3 Impact on FTP
Table 4 shows the transfer times for a 400MB ﬁle over FTP when
having a count to inﬁnity induced forwarding loop. We note that
when background broadcast trafﬁc exists and in the absence of an
EtherFuse many duplicate packets persist in the network as quanti-
ﬁed in Table 5.
The main reason for the very long transfer time when the Ether-
Fuse is not used is forwarding table pollution. Forwarding table
pollution causes the FTP client to be cut off from the network for
an extended period of time. In this case the pollution is very long
lasting because it is caused by an acknowledgment by the client to
a data packet sent by the server. The client then waits for the rest
of the data packets to arrive for the rest of the ﬁle, but the server’s
packets cannot get through because of the forwarding table pollu-
tion. This causes TCP at the server to keep backing off. The prob-
lem only gets ﬁxed later when the ARP cache entry for the FTP
client expires at the FTP server forcing the server to send an ARP
request for the client. Since ARP request packets are broadcast
packets, they get ﬂooded through the network and are not affected
by forwarding tables. When the ARP request reaches the client, it
makes the client send back an ARP reply which ﬁxes the pollution
and restores the connectivity to the client. When using the Ether-
Fuse, this problem does not take place because after the EtherFuse
detects and cuts the loop, it send the topology change message forc-
ing bridges to ﬂush their forwarding tables, including the polluted
entries.
EtherFuse
No EtherFuse
Broadcast No Broadcast
9
57481
1
2
EtherFuse
No EtherFuse
Loop/Broadcast
3
65578
Loop/No Broadcast
1
19
Table 3: Number of duplicate frames detected in the network for the HTTP
workload in the event of having a forwarding loop.
Table 5: Number of duplicate frames detected in the network for the FTP
workload in event of having a forwarding loop.
Broadcast No Broadcast
No failure
Failure with EtherFuse
Failure without EtherFuse
37.2s
141s
35.9s
36s
140s
Table 4: Transfer times or a 400MB ﬁle over FTP.
6.3 Effects of Multiple Forwarding Loops
Multiple forwarding loops can occur due to the MaxAge induced
forwarding loops as presented Section 2.2.2, or having two or more
simultaneous failures of the failure types discussed in Section 2.2.
In this section we choose the MaxAge induced forwarding loops
as an example of multiple forwarding loops. To demonstrate the
seriousness of having multiple forwarding loops, we construct an
experiment using the network topology shown in Figure 7(b) that
uses the STP protocol. We use a value of 2 for the MaxAge of the
bridges in the network. This value is outside the prescribed range
stated in the IEEE speciﬁcation, but we use it so that we can gener-
ate the forwarding loops using only a few Emulab nodes. We con-
nect an end host to B3 that sends a single broadcast packet. Then
we measured the number of duplicate packets observed in the net-
work every millisecond. We repeated this experiment twice, once
with the EtherFuse, and another without. In the later case we see in
Figure 15 that the packets exponentially proliferate until they sat-
urate the network. This is because the CPUs of the Emulab nodes
running network elements are saturated due to the processing of all
the duplicate packets. When the EtherFuse is used we notice that
the duplicates are eliminated from the network in 3 milliseconds.
Roughly, one millisecond is spent on detecting duplicate packets,
another millisecond for sending and receiving a probe, then another
millisecond for the in transit duplicates to drain after the loop has
been cut.
In summary, multiple forwarding loops can quickly render the
network unusable due to exponential proliferation of duplicates.
The EtherFuse is highly effective at detecting and correcting the
problems.
6.4 Discussion
The EtherFuse is very effective at reducing the effects of a for-
warding loop. Between the onset of a forwarding loop and its de-
tection, the network may suffer from a very brief period of packet
duplication. However, the EtherFuse is able to quickly stop packet
duplication before it escalates into network congestion and packet
loss. These beneﬁts are achieved without changing the spanning
tree protocols.
In contrast, while the EtherFuse is able to mitigate the effects
of the count to inﬁnity by reducing the spanning tree convergence
time, the effects of the EtherFuse on count to inﬁnity are not as im-
mediate as for forwarding loops. The EtherFuse’s ability to quickly
end the count to inﬁnity is constrained by the rate limit on BPDU
transmission in the spanning tree protocols. Solutions that change
the spanning tree protocols can eliminate the count to inﬁnity and
achieve much faster convergence. For example, in all of the sce-
narios discussed in Section 6.1.2, RSTP with Epochs [11] is able to
converge in one round-trip time across the network.
Packet Prolifertion Timeline
Without EtherFuse
With EtherFuse
 60
 50
 40
 30
 20
 10
 0
s
t
e
k
c
a
P
e
a
c
t
i
l
p
u
D
 0
 10
 20
 30
 40
 50
 60
 70
 80
Time (ms)
Figure 15: Timeline of number of duplicate packets observed by a network
monitor after the formation of two forwarding loops and injecting an ARP re-
quest into the network.
7. RELATED WORK
The focus of this work is on mitigating the effects of Ethernet
failures without changing the existing Ethernet infrastructure, in-
cluding software, hardware, and protocols. In contrast, most previ-
ous work has focused on changing Ethernet’s protocols to improve
its scalability and performance. However, some hardware vendors
employ techniques that try to enhance Ethernet’s reliability.
Cisco employs two techniques to guard against forwarding loops,
Loop Guard and the Unidirectional Link Detection (UDLD) proto-
col. None of these techniques is a part of the standard spanning
tree protocols. Thus, not all vendors have these techniques imple-
mented in their switches. Even Cisco does not have them imple-
mented in all of their switches [6, 9]. Also, all those techniques
require manual conﬁguration which is error prone. For example
both techniques are disabled by default on Cisco switches, so they
need to be enabled ﬁrst. Hence, having a single switch in the net-
work that does not have or does not enable those features can leave
the whole network vulnerable. This is because a single blocked
port, erroneously transitioning to the forwarding state can make
a forwarding loop that can render the whole network unavailable.
Moreover, each of those techniques is limited in scope to a spe-
ciﬁc problem, so having one technique does not eliminate the need
for the other. Finally, some kinds of forwarding loops can not be
handled by any of those techniques, like the MaxAge induced for-
warding loops and count to inﬁnity induced forwarding loops.
The Loop Guard technique protects a network from BPDU loss
induced forwarding loops.
It prevents a blocked port from erro-
neously transitioning to the forwarding state when the port stops
receiving BPDUs. Other than the shortcomings of this technique
listed above, Loop Guard only works on point-to-point links. Thus,
networks with shared links can be vulnerable to having forwarding
loops even if the Loop Guard is used.
To guard against broadcast storms, broadcast ﬁlters are used in
some Ethernet switches to suppress broadcast trafﬁc to a certain
level [4]. However, broadcast suppression suppresses broadcast
packets indiscriminately once it reaches its maximum allowable
level of broadcast trafﬁc during a particular interval. Hence, du-
plicate broadcast packets may be allowed to get through before this
cap is reached, saturating the ﬁlter, and then after the cap is reached
legitimate broadcast trafﬁc may get dropped.
UDLD is used to detect failures in which bidirectional links be-
come unidirectional. The UDLD protocol disables the link to ap-
pear as if it is disconnected as the spanning tree protocol does not
handle unidirectional links. UDLD relies on ports on both ends of
a link exchanging keep-alive messages periodically. Missing keep-
alive messages from one direction signal a failure in that direction.
The inter-keep-alive message interval is manually conﬁgured by
the network administrator. Again, other than the general shortcom-
ings listed above this technique has a set of its own shortcomings.
First, it needs ports on both ends of a link to support the UDLD
protocol. Second, the keep-alive messages can get dropped in case
of network congestion which can mislead the protocol to think that
the link has failed.
Myers et al. [18] argued that the scalability of Ethernet is severely
limited because of its broadcast service model. In order to scale
Ethernet to a much larger size, they proposed the elimination of
the broadcast service from Ethernet and its replacement with a new
control plane that does not perform packet forwarding based on
a spanning tree and provides a separate directory service for ser-
vice discovery. Perlman [19] also argued that Ethernet has poor
scalability and performance and proposed Rbridges to replace the
current Ethernet protocols. Routing in Rbridges is based on a link
state protocol to achieve efﬁcient routing. Rbridges also encapsu-
late layer 2 trafﬁc in an additional header that includes a TTL ﬁeld
to guard against problems from forwarding loops.
Several other previous works have addressed the inefﬁciency of
spanning tree routing in Ethernet. SmartBridges [20] offers optimal
routing using source speciﬁc spanning trees. LSOM [13] proposes
using link state routing for Ethernet as well. Viking [21] delivers
data over multiple spanning trees to improve network reliability and
throughput.
RSTP with Epochs [11] modiﬁes RSTP to eliminate the count
to inﬁnity problem and consequently eliminates count to inﬁnity
induced forwarding loops. That work studies the cause of count to
inﬁnity and the convergence time of RSTP and RSTP with Epochs
in simulations. However, it does not consider the impact of the
count to inﬁnity problem on end-to-end application performance,
nor does it consider other protocol vulnerabilities presented in this
paper.
8. CONCLUSIONS
Although Ethernet is a pervasive technology, we have shown that
it can suffer from serious problems due to simple local failures.
These problems include extended periods of network-wide heavy
packet loss, and in some cases complete network meltdowns. To
address these problems, we introduced the EtherFuse, a new device
that is backward compatible and requires no change to the existing
hardware, software, or protocols. We implemented a prototype of
the EtherFuse and used this prototype to demonstrate the effective-
ness of the EtherFuse.
We have shown that the EtherFuse is very effective at reduc-
ing the effects of a forwarding loop. Between the onset of a for-
warding loop and its detection, the network may suffer from a very
brief period of packet duplication. However, the EtherFuse is able
to quickly stop packet duplication before it escalates into network
congestion and packet loss. The EtherFuse is also able to mitigate
the effects of the count to inﬁnity by reducing the spanning tree
convergence time. However, the impact of the EtherFuse on count
to inﬁnity is limited by the design of the spanning tree protocols.
Nevertheless, EtherFuse is able to provide its beneﬁts in a way that
is fully backward compatible.
9. REFERENCES
[1] Emulab - network emulation testbed. At
http://www.emulab.net.
[2] A. Barnard. Got paper? Beth Israel Deaconess copes with a
massive computer crash. Boston Globe, November 26, 2002.
[3] Beth Israel Deaconess Medical Center. Network Outage
Information. At
http://home.caregroup.org/templatesnew/
departments/BID/network_outage/.
[4] Cisco Systems, Inc. Conﬁguring Broadcast Suppression. At
http://www.cisco.com/univercd/cc/td/doc/
product/lan/cat6000/sw_8_5/confg_gd/
bcastsup.htm.
[5] Cisco Systems, Inc. Internet Protocol Multicast. At
http://www.cisco.com/univercd/cc/td/doc/
cisintwk/ito_doc/ipmulti.htm.
[6] Cisco Systems, Inc. Spanning-Tree Protocol Enhancements
using Loop Guard and BPDU Skew Detection Features. At
www.cisco.com/warp/public/473/84.html.
[7] Cisco Systems, Inc. Spanning Tree Protocol Problems and
Related Design Considerations. At
http://www.cisco.com/warp/public/473/16.html.
[8] Cisco Systems, Inc. Troubleshooting Transparent Bridging
Environments. At
www.cisco.com/warp/public/112/chapter20.pdf.
[9] Cisco Systems, Inc. Understanding and Conﬁguring the
Unidirectional Link Detection Protocol Feature. At
www.cisco.com/warp/public/473/77.html.
[10] Cisco Systems, Inc. Understanding Rapid Spanning Tree
Protocol (802.1w). At
http://www.cisco.com/warp/public/473/146.html.
[11] K. Elmeleegy, A. L. Cox, and T. S. E. Ng. On
Count-to-Inﬁnity Induced Forwarding Loops in Ethernet
Networks. In IEEE Infocom 2006, Apr. 2006.
[12] K. Elmeleegy, A. L. Cox, and T. S. E. Ng. Supplemental
Note on Count-to-Inﬁnity Induced Forwarding Loops in
Ethernet Networks. Technical Report TR06-878, Department
of Computer Science, Rice University, 2006.
[13] R. Garcia, J. Duato, and F. Silla. LSOM: A link state
protocol over mac addresses for metropolitan backbones
using optical ethernet switches. In Second IEEE
International Symposium on Network Computing and
Apllications (NCA ’03), Apr. 2003.
M. Newbold, M. Hibler, C. Barb, and A. Joglekar. An
Integrated Experimental Environment for Distributed
Systems and Networks. In Proceedings of the Fifth
Symposium on Operating Systems Design and
Implementation (OSDI’02), Dec. 2002.
[14] E. Kohler, R. Morris, B. Chen, J. Jannotti, , and M. F.
Kaashoek. The Click modular router. ACM Transactions on
Computer Systems, 18(3):263–297, August 2000.
[15] LAN/MAN Standards Committee of the IEEE Computer
Society. IEEE Standard for Local and metropolitan area
networks: Virtual Bridged Local Area Networks, 2003.
[16] LAN/MAN Standards Committee of the IEEE Computer
Society. IEEE Standard for Local and metropolitan area
networks: Media Access Control (MAC) Bridges - 802.1D,
2004.
[17] A. Myers and T. S. E. Ng. Bridgesim - bridge simulator.
Version 0.03 is available from the author’s web site,
http://www.cs.cmu.edu/˜acm/bridgesim/, May 2005.
[18] A. Myers, T. S. E. Ng, and H. Zhang. Rethinking the Service
Model: Scaling Ethernet to a Million Nodes. In Third
Workshop on Hot Topics in networks (HotNets-III), Mar.
2004.
[19] R. Perlman. Rbridges: Transparent routing. In IEEE Infocom
2004, Mar. 2004.
[20] T. L. Rodeheffer, C. A. Thekkath, and D. C. Anderson.
SmartBridge:A scalable bridge architecture. In ACM
SIGCOMM 2000, Aug. 2000.
[21] S. Sharma, K. Gopalan, S. Nanda, and T. Chiueh. Viking: A
multi-spanning-tree Ethernet architecture for metropolitan
area and cluster networks. In IEEE Infocom 2004, Mar. 2004.
[22] B. White, J. Lepreau, L. Stoller, R. Ricci, S. Guruprasad,