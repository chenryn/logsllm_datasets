watchdog W who tests the subverted implementations, by comparing them with the speciÔ¨Åcation of
the algorithms. The adversary ‚Äúwins‚Äù if she can manufacture implementations so that she can win
the security game and‚Äîat the same time‚Äîevade the detection of W. One can arrive at a variety of
diÔ¨Äerent deÔ¨Ånitions based on the order of quantiÔ¨Åcation for W and A, how exactly W is permitted
to test the implementations, and whether W is given any further information (such as a transcript
of the security game). We refer to [RTYZ15] for detailed discussion.
In this paper we will adopt the strongest of the deÔ¨Ånitions of [RTYZ15] (which gives the
watchdog the least power): in their terminology, we will consider a universal and oÔ¨Ñine watchdog.
In such a deÔ¨Ånition, the watchdog only tests the implementation once with only oracle access. In
particular, W has no access to the actual communications during the security game. Moreover, the
description of the watchdog is quantiÔ¨Åed before the adversary.2 (Thus, security for a particular
primitive requires that there is a single watchdog that can protect against all possible adversaries.)
To formalize the notion that the adversary cannot learn unintended information from an
implementation, we adapt the surveillance game from [BPR14] (which was deÔ¨Åned for symmetric
key encryption): speciÔ¨Åcally, we compare the information leaked by the implementation with that
leaked by the speciÔ¨Åcation (or, equivalently, an honest implementation).
DeÔ¨Åning stego-freeness. We now formally deÔ¨Åne stego-freeness for any (randomized) algorithm
G under subversion. Following the basic kleptographic models described above, the adversary A
prepares a (potentially subverted) implementation Gimpl of the algorithm G; we let Gspec denote the
speciÔ¨Åcation of the algorithm. The goal of the adversary is to utilize Gimpl to leak secret information
exclusively to her via the outputs that Gimpl produces (as in the discussion above). Stego-freeness
means either the adversary A cannot learn any extra information from the outputs of Gimpl (in
comparison with that of Gspec), or the subversion can be detected by the watchdog W (using oracle
2This is stronger than most of the deÔ¨Ånitions in the literature. The closest one is [DFP15]; however, their watchdog
has to take the transcript between C and A as inputs which implicitly implies the dependence of the running time on A.
6
access to Gimpl)‚Äîthis is characterized by the detection advantage DetW,A below. Depending on
how communication is generated and whether the randomized algorithm can takes rich inputs,
we have a variety of deÔ¨Ånitions; we begin with the following elementary version for randomized
algorithms‚Äîsuch as key generation‚Äîthat rely only on a length parameter rather than inputs
drawn from a large space.
DeÔ¨Ånition 2.1 (stego-free, basic form). Consider a (randomized) algorithm G with speciÔ¨Åcation Gspec.
We say such Gspec is stego-free in the oÔ¨Ñine watchdog model if there exists a ppt watchdog W so that
for any ppt adversary A playing the following game (see Fig. 2), it satisÔ¨Åes that either
AdvA is negligible,
or DetW,A is non-negligible
where
AdvA(1Œª) = |Pr[bC = 1]‚àí 1/2|
and DetW,A(1Œª) =
(cid:12)(cid:12)(cid:12)Pr[W Gimpl(1Œª) = 1]‚àí Pr[Pr[W Gspec(1Œª) = 1]
(cid:12)(cid:12)(cid:12) .
A(1Œª)
A(1Œª)
test phase
W(1Œª)
bW ‚Üê W Gimpl(1Œª)  Gimpl
execute phase
C(1Œª)
Œ≤ ‚Üê {impl,spec}
for i = 1 to q
yi ‚Üê GŒ≤(1Œª)
bC := 1 if Œ≤ = Œ≤
bC := 0 otherwise

1q
y1, . . . , yq -
(cid:48)
Œ≤
(cid:48) 
Figure 2: A game for stego-freeness.
Note that the deÔ¨Ånition requires only non-negligible detection probability on the part of the
watchdog. Note that detection probabilities can be directly ampliÔ¨Åed by repetition.3
Remark 2.2. Our constructions actually satisfy a stronger condition that directly relates the advantage
to the detection probability. The deÔ¨Ånition above demands the asymptotic guarantee that either AdvA is
negligible or DetW,A is non-negligible. This can be strengthened to demand that for every adversary A
there is a polynomial s(Œª) (with no constant term, so that s(0) = 0) so that s(AdvA(1Œª)) ‚â§ DetW,A(1Œª).
Observe that an oÔ¨Ñine watchdog can ensure that the implementation of a deterministic algorithm
disagrees with its speciÔ¨Åcation with negligible probability when inputs are drawn from a public
input distribution. Throughout, we use the term ‚Äúpublic‚Äù distribution to refer to any eÔ¨Éciently
sampleable source that the watchdog can construct, perhaps using Fispec and Fiimpl.
3Trivial ampliÔ¨Åcation transforms a gap of  to 1‚àí Œ¥ with k = 
‚àí1) repetitions. As the watchdog‚Äôs running time
is Ô¨Åxed independent of the adversary, however, ampliÔ¨Åcation cannot be adapted to a particular non-negligible function.
If the watchdog is permitted a number of samples that depends on the adversary, then one can amplify non-negligible
detection probability to 1‚àí o(1) for an inÔ¨Ånite set of inputs.
‚àí1 log(Œ¥
7
Lemma 2.3 ([RTYZ15]). Consider an adversarial implementation Œ†impl := (F1impl, . . . ,Fkimpl) of a speciÔ¨Å-
cation Œ†spec = (F1spec, . . . ,Fkspec), where F1, . . . ,Fk are deterministic algorithms. Additionally, for each secu-
impl(x) (cid:44)
rity parameter Œª, public input distributions X1
spec(x) : x ‚Üê Xj
Œª] is non-negligible, this can be detected by a ppt oÔ¨Ñine watchdog with non-negligible
Fj
probability.
Œª are deÔ¨Åned respectively. If ‚àÉj ‚àà [k],Pr[Fj
Œª, . . . , Xk
More general deÔ¨Ånitions of stego-freeness. In the above game, G only takes as input a Ô¨Åxed
security parameter (often ignored later in the paper); this deÔ¨Ånition can capture algorithms
like randomness generation and key generation when we instantiate G to be the corresponding
functionality. Besides the security parameter, we can consider algorithms which take richer inputs.
Such extensions will be important for our applications, and can signiÔ¨Åcantly complicate the task of
destroying an embedded steganographic channel. One note is that for input taken from a small
domain, (for example, {0,1}), we simply allow the adversary to query the evaluation on all inputs.
Beyond the previous cases, we may consider algorithms taking inputs from a large domain. The
most straightforward adaptation permits the adversary to sample Gimpl(1Œª, xi) at inputs xi of her
choice. However, this model suÔ¨Äers from a crippling ‚Äúinput trigger‚Äù attack [DFP15] (where the
adversary hides some secret information at a particular ‚Äútrigger‚Äù location x which can be impossible
for an oÔ¨Ñine watchdog to detect); we discuss this in detail later. However, there is a compromise
setting that captures many cases of actual interest and permits strong feasibility results. In this
setting we permit the adversary to determine inputs to a randomized algorithm G by specifying a
randomized input generator IG: The input generator may be an arbitrary ppt algorithm with the
condition that given 1Œª it produces (typically random) outputs of length exactly Œª. This implicitly
deÔ¨Ånes the randomized algorithm G(1Œª,IG(1Œª)). In our setting, the watchdog is provided (oracle
access) to IG, which it may use during its testing of G. Note that IG is not part of the speciÔ¨Åcation of
G, but rather chosen by the adversary during the security game; thus there is no reason to consider
subversion of IG. Revisiting the security game in this new setting, challenges {yi} are generated by
Ô¨Årst sampling mi ‚Üê IG(1Œª), and then obtaining yi ‚Üê GŒ≤(1Œª, mi) by calling GŒ≤ using inputs 1Œª and
mi. Note that the adversary could use IG to produce some speciÔ¨Åc input ‚Äútriggers‚Äù where Gimpl
deviates from Gspec. This more general notion of stego-freeness (with a ‚Äúpublic‚Äù input distribution)
captures algorithms that take the output of other algorithms as input, which will be critical when
we reason about amalgamation of algorithms. See Figure 3 below for a uniÔ¨Åed game, where the
algorithm may take both types of inputs.
DeÔ¨Ånition 2.4 (stego-free, general form). We say that a randomized algorithm G is stego-free if it
satisÔ¨Åes DeÔ¨Ånition 2.1 with the security game of Figure 3. Note that the ppt input generator IG may be
determined by the adversary during the game.
Which of the deÔ¨Ånitions (2.1 or 2.4) is appropriate for a given randomized algorithm can be
determined from context, depending on whether an input generator is speciÔ¨Åed.
As mentioned above, an even stronger deÔ¨Ånition is obtained by permitting the adversary to
simply choose the input mi for each yi directly. This notion reÔ¨Çects stego-freeness for algorithms
with adversarially chosen inputs. Such a subverted implementation may have a hidden ‚Äútrigger‚Äù
that was randomly drawn during the (adversarial) manufacturing process and can permit the
adversary to easily win the stego-freeness distinguishing game. In fact, such a trigger attack
does not even require that G be randomized: for example, consider the algorithm Gspec(1Œª, x) := x,
8
test phase
W(1Œª)
bW ‚Üê W Gimpl,IG(1Œª)
 Gimpl,IG
execute phase
A
A(1Œª)
C
Œ≤ ‚Üê {impl,spec}
for i = 1 to q
mi ‚Üê IG(1Œª)
yi = GŒ≤(1Œª, mi)
(cid:48)
bC := 1 if Œ≤ = Œ≤
bC := 0 otherwise

1q
{yi}i‚àà[q] -
(cid:48)

Œ≤
Figure 3: The stego-freeness game with input distribution {1Œª}√ó IG.
deÔ¨Åned for x ‚àà {0,1}Œª. The adversary then uniformly draws z ‚Üê {0,1}Œª and deÔ¨Ånes
0Œª
x
Gimpl(1Œª, x) =
if x = z,
otherwise.
As the placement of the trigger (z) is random, the watchdog cannot detect disagreement between
Gimpl and Gspec, while the adversary can distinguish these algorithms easily by querying z. In a
practical setting, an algorithm with such an input trigger can leak arbitrary private data to an
adversary in a way undetectable to an oÔ¨Ñine watchdog. This was formally demonstrated in [DFP15]
and called an ‚Äúinput-triggered subversion attack.‚Äù Nevertheless, we will discuss in Section 4.1
a method for sidestepping this impossibility with only an oÔ¨Ñine watchdog by assuming some
minimum trusted operations, such as ‚Äúone trusted addition.‚Äù4
These deÔ¨Ånitions of stego-freeness are suÔ¨Écient for capturing most of the interesting use cases
we will require (e.g., reÔ¨Çecting key generation and encryption).
Remark 2.5. Following Lemma 2.3, observe that if Gspec is deterministic, an oÔ¨Ñine watchdog can ensure
that inconsistencies (Gspec(x) (cid:44) Gimpl(x)) occur with only negligible probability when inputs are sampled
from the input distribution IG (by drawing and testing a sample). In particular, deterministic algorithms
with a public input distribution satisfy stego-freeness in a straightforward fashion.
Discussions about stego-freeness and steganography. We emphasize two properties of these deÔ¨Å-
nitions. First, if a proposed speciÔ¨Åcation satisÔ¨Åes such deÔ¨Ånitions, direct use of the implementation‚Äî
rather than the speciÔ¨Åcation‚Äîpreserves the typical security guarantees originally possessed by the
4All previous works either simply assume it won‚Äôt happen (the decryptability assumption) or employ an omniscient
watchdog who has access to the transcript between the challenger C and the adversary A, (and the secret key of C).
9
speciÔ¨Åcation. This enables us to provide fairly modular security proofs by designing speciÔ¨Åcations
for each algorithm with stego-freeness.
The second, and more critical, issue pertains to the feasibility of achieving these notions of stego-
freeness: in particular, at Ô¨Årst glance they appear hopeless. It is known that general steganography
is always possible over a channel with suÔ¨Écient entropy [Sim83, Sim86, HLv02]. This implies
that the subverted algorithm Gimpl can always produce a sequence of messages that enable the
adversary to retrieve secret data from the (public) outputs y1, . . . , yq. In particular, as shown by
Bellare, Paterson, Rogaway in the seminal result [BPR14], a subverted randomized encryption
algorithm can generate ciphertexts so that the adversary can recover the secret key bit-by-bit from
the sequence of ciphertexts. Moreover, the distribution of these subverted ciphertexts is statistically
close to the natural, unsubverted ciphertext distribution. To make matters worse, such attacks can
be launched even if the subverted implementations are stateless [BJK15]. As a simple example
of such subversion in our setting, consider the algorithm Gspec(1Œª) which outputs a uniformly
random element of {0,1}Œª. Consider then the subverted implementation Gzimpl(1Œª) whose behavior
is determined by a uniformly random string z ‚Üê {0,1}Œª chosen by the adversary: the algorithm
Gzimpl(1Œª) outputs a uniformly random element of the set
H = {w ‚àà {0,1}Œª | lsb(Fz(w)) = 0} ,
where lsb(x) denotes the least-signiÔ¨Åcant bit of x and Fz(¬∑) denotes a pseudorandom function (PRF)
with key z. (Note that elements of H can be drawn by rejection sampling.) Of course, it is easy
for the adversary to distinguish Gimpl from Gspec (as Gimpl only outputs strings with a particular
property that is easily testable by the adversary who has z). On the other hand, no watchdog can
distinguish these algorithms without breaking the PRF. This suggests that if the user makes only
black-box use of the subverted implementation of randomized algorithms, it is hopeless to achieve
stego-freeness. This motivates the following non-black-box model.
The split-program methodology and trusted amalgamation. To overcome the steganographic
attacks discussed above, we propose a slightly modiÔ¨Åed model which permits the speciÔ¨Åcation of
an algorithm to be split into several components. In this split-program model, each component of
the implementation is exposed to the watchdog to check, while the challenger will amalgamate
the components to yield the fully functional implementation. Of course, the implementation of
each component is still presented by the adversary. We permit decomposition into only a constant
number of components (independent of input length), with the demand that the desired algorithm
can furthermore be expressed as the composition of a constant number of the components. Note
that such a ‚Äúsplit-program‚Äù presentation of an algorithm rules out any gate-by-gate treatment, as
the model permits only a constant number of compositions. Intuitively, this simple non-black-
box presentation of a randomized algorithm not only provides more opportunity to enforce the
malicious implementation to follow a certain pattern, but also enables the watchdog to do more
delicate checking on the inner structure.
One example of this framework is the simple split-program method proposed in [RTYZ15] to
study certain randomized algorithms: they begin by specifying a (general) randomized algorithm
G as a pair (RG,dG) where RG is the randomness generation algorithm, responsible for generating a
uniform random string of appropriate length, and dG is a deterministic algorithm that takes the
input to the original randomized algorithm G and the random coins produced by RG to produce
the Ô¨Ånal output. They then add to this speciÔ¨Åcation a third deterministic algorithm Œ¶ which acts
as a kind of ‚Äúimmunization function‚Äù for the random bits generated by RG. SpeciÔ¨Åcally, given the
10
implementations (RGimpl, dGimpl, Œ¶impl), the challenger amalgamates them by Ô¨Årst querying r0 ‚Üê
RGimpl, ‚Äúsanitizing‚Äù this randomness by passing it into Œ¶impl to receive r ‚Üê Œ¶impl(r0) and, Ô¨Ånally,
running y ‚Üê dGimpl(r). They show that in several contexts such an ‚Äúimmunization‚Äù can preserve
security even under subversion. We remark that a simple decomposition and amalgamation of this
form cannot destroy steganography in general, and we show an explicit attack in this model; see
Sec. 3.1.
To reÔ¨Çect such trusted amalgamation in our security model, we permit the challenger to carry
out (a constant number of) compositions without molestation; that is, the notion of ‚Äúcomposition‚Äù is
protected from adversarial subversion. This can be inferred from the deÔ¨Ånition of the speciÔ¨Åcation,
and it is implicit in the security games deÔ¨Åned, e.g., in Figure 11, and in Figure 12, in the appendix.
As mentioned above, the split-program method proposed in [RTYZ15] permitted them to
establish security (in the kleptographic model) for speciÔ¨Åc cryptographic primitives. In this paper,
we will show that this general methodology has remarkable power against subversion: by further
decomposition and amalgamation, we show it is possible to generically destroy steganographic
channels. This provides us a family of tools for developing kleptographically-secure cryptography
without abandoning randomized algorithms.
Stateful algorithms. As discussed above, steganographic attacks can be launched even if the
implementation is stateless. To simply our presentation, most of our discussion adopts this
stateless assumption. However, adaptations of our techniques can provide security even for stateful
implementations (in the sense that each functionality maintains internal state). These ampliÔ¨Åed
results require a slightly stronger watchdog (whose running time can depend on the adverary) and
more detailed control of the subverted algorithm to ensure that they receive inputs from public
distributions. See Remark 3.2 in Sec. 3.2 for more discussion.
3 Eliminating Subliminal Channels in Randomized Algorithms
In this section, we will present our main result: provable destruction of any subliminal channels in
subverted implementations of randomized algorithms.
First, we motivate our new constructions by showing that the steganographic attacks of [BPR14,
BJK15] can still be carried out in the simple split-program model introduced by [RTYZ15]. The
attack succeeds even if the associated ‚Äúimmunizing function‚Äù Œ¶ is a trusted hash function modeled
as a random oracle. This indicates that some stronger form of immunization is necessary for