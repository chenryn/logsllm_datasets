X ; when taken over a
range of quantiles, it allows us to estimate the cumulative
distribution FX (x) = P(X ≤ x).
in Figure 4
using an example: Figure 4a shows n = 3 synthetic distri-
butions where the upward arrows point to the (cid:98)F−1
Xi values
from network i at quantile y = .5, and Figure 4b shows the
mean of those values as the estimator µ. The example applies
analogously when estimating each (cid:98)F−1
Computing Conﬁdence Intervals: We quantify the preci-
sion of our estimator µ using CIs. To compute the CIs, we ﬁrst
quantify the measurement error associated with the empirical
samples. This will often be negligible, but a possible source
of nontrivial measurement error is resolution error; that is, if
We visualize the process of estimating F−1
X
taking the mean over the n distributions estimated above:
Second, we similarly estimate F−1
X
i=1(cid:98)µi(y)
over all networks by
mi ∑mi
Xi j (y)
Xi .
(1)
(2)
(a)
(b)
Figure 4: A synthetic example of estimating the cumulative distribu-
tion of a random variable X (e.g., time to last byte). (a) The mean in
Equation 2 and standard deviation in Equation 4 are computed over
the n = 3 values at each quantile. (b) The estimated true distribution
from Equation 2 is shown with conﬁdence intervals from Equation 5.
the empirical results are reported to a resolution of r (e.g.,
r√12, and
0.01 s), the resolution error for each sample will be
i at quantile y is ζi = r√12mi
. Next, we quantify the sampling
error associated with the estimates from Equations 1 and 2.
the resolution error ζi for the empirical mean(cid:98)µi(y) of network
The error associated with(cid:98)µi for network i at quantile y is:
where(cid:98)σi(y) =(cid:113) 1
i is the stan-
dard deviation over the mi empirical values at quantile y (in-
cluding the measurement error) and t is the t-value from
the Student’s t-distribution at conﬁdence level α with mi − 1
degrees of freedom [25, §10.5.1].(cid:98)εi(y) accounts for the sam-
pling error and estimated true variance of the underlying dis-
tribution at y. The error associated with µ at quantile y is:
(cid:98)εi(y) =(cid:98)σi(y)·t/(cid:112)mi − 1
j=1((cid:101)F−1
Xi j (y)−(cid:98)µi(y))2 + ζ2
mi ∑mi
(3)
i=1((cid:98)F−1
where σ(y) =(cid:113) 1
ε(y) = δ(y) + σ(y)·t/√n− 1
n ∑n
(4)
Xi (y)− µ(y))2 is the standard de-
viation over the n estimated inverse distribution values at
quantile y, and δ(y) = 1
over all n sampled networks. ε(y) accounts for the sampling
error introduced in the Tor network model generation and
in the simulations. We can then deﬁne the CI at quantile y
as the interval that contains the true value from the inverse
distribution F−1
i=1(cid:98)εi(y) is the mean error from(cid:98)µi
n ∑n
X (y) with probability α:
µ(y)− ε(y) ≤ F−1
X (y) ≤ µ(y) + ε(y)
(5)
The width of the interval is 2· ε(y), which we visualize at
y = .5 with the downward arrows and over all quantiles with
the shaded region in Figure 4b.
5.2 Discussion
Number of Samples Per Simulation: Recall that we collect
νi j empirical samples of the random variable X from simu-
lation j in network i. If we increase νi j (e.g., by running the
simulation for a longer period of time), this will result in a
“tighter” empirical distribution (cid:101)Ei j(X) that will more closely
resemble the probability distribution (cid:98)Pi(X). However, from
USENIX Association
30th USENIX Security Symposium    3423
0102030RandomVariableX0.000.250.500.751.00EmpiricalCDFbF−1Xi(.5)bF−1Xi(.5)bF−1Xi(.5)bFX1bFX2bFX3010203040RandomVariableX0.000.250.500.751.00EstimatedTrueCDFµ(.5)µ(.5)−(.5)µ(.5)+(.5)µ≈F−1XCIFigure 5: The width of the 95% CI (on the log-scale y-axis) can
be signiﬁcantly reduced by more than an order of magnitude after
running experiments in fewer than 10 independently sampled Tor
networks (when σ is normally distributed according to N (1,1)).
than to gather additional samples from the same simulation.
Number of Simulations Per Network: Additional simula-
tions in network i will provide us with additional empirical dis-
Equation 1 we can see that (cid:101)Ei j(X) only contributes a single
value to the computation of(cid:98)µi for each quantile. Therefore,
once we have enough samples so that (cid:101)Ei j(X) reasonably ap-
proximates (cid:98)Pi(X), it is more useful to run new simulations
tributions (cid:101)Ei∗(X), which will enable us to obtain a better esti-
mate of(cid:98)Pi(X). Moreover, it will also increase the precision of
the CI by reducing(cid:98)εi in Equation 3: increasing the number of
(cid:101)Ei∗(X) values at each quantile will decrease the standard devi-
ation(cid:98)σi (if the values are normally distributed) and the t-value
creasing the square root component (in the denominator of(cid:98)εi).
additional estimated(cid:98)Pi(X) distributions, which will enable us
tional (cid:98)Pi(X) estimates will increase CI precision by reducing
Number of Sampled Networks: Additional simulations in
independently sampled Tor networks will provide us with
to obtain a better estimate of P(X). Similarly as above, addi-
(by increasing the number of degrees of freedom) while in-
ε in Equation 4: the standard deviation σ and the t-value will
decrease while the square root component will increase.
To give a concrete example, suppose σ is normally dis-
tributed according to N (1,1). The width of the resulting CI
for each number of sampled networks n ∈ [2,100] at quantiles
y ∈ {0.5,0.9,0.99} (i.e., P50, P90, and P99, respectively) is
shown in Figure 5. Notice that the y-axis is drawn at log-
scale, and shows that the width of the CI can be signiﬁcantly
reduced by more than an order of magnitude after running
experiments in even just a small number of sampled networks.
Additionally, we can see that the main improvement in conﬁ-
dence results from the ﬁrst ten or so sampled networks, after
which we observe relatively diminishing returns.
Scale: Another important factor to consider is the network
scale 0 250M monthly active users [56]), and many important re-
search problems must be considered before such a deployment
could occur [66]. For example, deploying Tor more widely
could add enough load to the network that it reduces perfor-
mance to the extent that some users are dissuaded from using
it [18] while reducing anonymity for those that remain [1].
There has been little work in understanding the perfor-
mance effects of increasing Tor network load as representa-
tive of the signiﬁcant change in Tor usage that would likely
occur in a wider deployment. Previous work that considered
variable load did so primarily to showcase a new simulation
tool [29] or to inform the design of a particular performance-
enhancing algorithm [33, 37] rather than for the purpose of
understanding network growth and scalability [44]. Moreover,
previous studies of the effects of load on performance lack
analyses of the statistical signiﬁcance of the reported results,
raising questions as to their practical meaning.
Guided by the foundations that we set out in this paper, we
explore the performance effects of a sudden rise in Tor usage
that could result from, e.g., a Mozilla deployment of Tor. In
particular, we demonstrate the use of our methodologies with
an example study of this simple hypothesis: increasing the to-
tal user trafﬁc load in Tor by 20% will reduce the performance
of existing clients by increasing their download times and
download error rates. To study this hypothesis, we conduct
a total of 420 simulations in independently sampled Tor net-
works across three network scale factors and two trafﬁc load
factors; we measure relevant performance properties and con-
duct a statistical analysis of the results following our method-
ology in §5. Our study demonstrates how to use our contribu-
tions to conduct statistically valid Tor performance research.
6.2 Experiment Setup
Experiments and Simulations: We refer to an experiment
as a unique pair of network scale s and load (cid:96) conﬁgurations,
and a simulation as a particular execution of an experiment
conﬁguration. We study our hypothesis with a set of 6 experi-
ments; for each experiment, we run multiple simulations in
independent Tor networks so that we can quantify the statisti-
cal signiﬁcance of the results following our guidance from §5.
Tor Network Scale and Load: The Tor network scales that a
researcher can consider are typically dependent on the amount
of RAM to which they have access. Although we were able
to run a 100% Tor network for our evaluation in §4, we do
not expect that access to a machine with 4 TiB of RAM, as
was required to run the simulation, will be common. Because
it will be more informative, we focus our study on multiple
1%
1%
35 GiB
50 GiB
355 GiB
416 GiB
100%
120%
100%
120%
100%
120%
4.8 hours
6.7 hours
Table 4: Tor usage and performance experiments in Shadow
RAM/Sim† Run Time/Sim‡
Scale s Load (cid:96) Sims n CPU(cid:63)
4×8
4×8
4×8
4×8
8×8
8×8
4 days, 21 hours
5 days, 22 hours
(cid:63) 4×8-core Intel Xeon E5 @3.3 GHz; 8×8-core Intel Xeon E5 @2.7 GHz.
† The median of the per-simulation max RAM usage over all simulations.
‡ The median of the per-simulation run time over all simulations.
Table 5: Network composition in each simulation(cid:63)
19.4 hours
23.4 hours
10%
10%
30%
30%
1.07 TiB
1.25 TiB
100
100
100
100
10
10
Scale s DirAuth Guard Middle Exit E+G† Markov Perf‡ Server
1%
10%
30%
3
3
3
20
204
612
4
40
4
36
361
44
1,086 118 129
100
792
2,376
8
79
238
10