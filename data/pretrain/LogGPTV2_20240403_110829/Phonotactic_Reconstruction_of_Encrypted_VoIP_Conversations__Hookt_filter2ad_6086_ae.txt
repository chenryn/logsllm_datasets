estimates for each word in a given hypothesized transcript as
our conﬁdence value for that hypothesis. Analysis indicates
that
this conﬁdence measure correlates (see Figure 13)
with the maximum METEOR score obtained from the 10
best hypotheses output by the word-level language model
(Stage ). This implies that, given a set of training data
such as the TIMIT dataset, an adversary can determine an
appropriate threshold for the calculated conﬁdence values
to suit her preference as to the balance between precision
and recall in the hypothesized transcripts. The results in
Figure 14 provide one such analysis under the content-
dependent model. We note that the threshold reduces the set
of hypotheses to a subset with improved METEOR scores.
15
NewEnglandNorthernNorthMidlandSouthMidlandSouthernNewYorkCityWesternArmyBrat0.00.20.40.60.81.0METEORScoreNewEnglandNorthernNorthMidlandSouthMidlandSouthernNewYorkCityWesternArmyBrat0.00.20.40.60.81.0METEORScoreFigure 12. The top 10% of METEOR scores for hypothesized transcripts under the content-independent assumption.
Figure 14. METEOR scores for hypothesized transcripts for sentence SA2 with conﬁdence values above the threshold of .90 for each dialect in the
TIMIT dataset. The number of transcripts with conﬁdence values above the threshold compared to the total for each dialect is shown in parentheses.
words for which we have high conﬁdence. Preliminary
results indicate that such “masking” may provide beneﬁts
to interpretation, for example, outputting ‘nonproﬁt (cid:63) all
(cid:63) (cid:63) raisers’ instead of ‘nonproﬁt organizations all swiftly
fairy raisers’ as the hypothesis for ‘nonproﬁt organizations
have frequent fund raisers’. We forego such analysis at this
time since the METEOR metric does not allow for unknown
words—an automated method of evaluating such hypotheses
is necessary before we can make any claims.
B. Discussion & Mitigation
We note, like other work in this area (e.g., [2, 37, 41, 55,
56]), that we assume each packet contains a single frame.
However, some recently designed codecs, such as Skype’s
new codec (dubbed SILK), can vary the number of frames
per packet based on network conditions. It therefore remains
to be seen if the approach outlined herein can be adapted to
that setting; exploring that, however, requires a substantial
data collection effort that is beyond the scope of this work.
Further, our experiments assume that packets are observed
in correct order and are not fragmented or combined, i.e.,
the adversary can observe packets at the level of the local
network (e.g., between VoIP endpoint and hub or PBX) or
can perform IP defragmentation or TCP stream reassembly.
The inherently limited ﬁdelity of the channel, however,
suggests that our technique would be robust to reasonable
noise in the form of packet reordering and fragmentation.
Lastly, a knee-jerk reaction to thwarting this and other
aforementioned threats to VoIP is to simply use constant
bit-rate codecs or block ciphers. However, variable bit-
rate encoded audio encrypted under a block cipher with a
Figure 13. Scatter plot of METEOR scores against our conﬁdence values
(Pearson’s r-value of 0.43).
Unfortunately, the correlation of this particular conﬁdence
metric does not extend well
to the content-independent
model. However, we note that there are many other methods
to measure conﬁdence which an adversary could leverage,
including those based on the posteriors output by the classi-
ﬁcation stage, the likelihoods given by the language models,
and ex post facto analysis of the well-formedness (in terms
of syntax, i.e., grammar) of the hypotheses. We hope to
explore these strategies in the near future.
In closing, we note that one could also apply the notion
of conﬁdence values to interpreting the results at the word,
rather than the sentence, level. In particular, we could ﬁlter
our hypotheses at the word-level by only outputting those
16
NewEnglandNorthernNorthMidlandSouthMidlandSouthernNewYorkCityWesternArmyBrat0.00.20.40.60.81.0METEORScoreNewEngland(37/49)Northern(73/102)NorthMidland(85/102)SouthMidland(70/100)Southern(65/98)NewYorkCity(39/46)Western(81/100)ArmyBrat(24/33)0.00.20.40.60.81.0METEORScore0.760.780.800.820.840.860.880.900.920.94ConﬁdenceValue0.00.10.20.30.40.50.60.70.8METEORScoresmall block size is theoretically vulnerable to our attack.
Packet sizes in that scenario still correlate with input signals,
albeit at a reduced ﬁdelity; thus relatively large block sizes
are necessary to ensure privacy. For this reason, the use
of constant bit-rate codecs is important to consider as an
alternative to simple block ciphers for VoIP, since such
codecs might improve call quality given a relatively large
ﬁxed packet size. Another alternative might even be to drop
or pad packets [19, 27, 57], though, in that case, the effect on
perceived call quality is unclear. We note, however, that VoIP
providers have made no move to employ any such measures:
Skype’s SILK, for instance, is a VBR codec. Similarly, one
of the leading proposals for 4G, the LTE Advanced standard,
speciﬁes a VBR codec for audio [1] and the use of SRTP
to secure voice data channels.
VII. CONCLUSION
In this paper, we explore the ability of an adversary to
reconstruct parts of encrypted VoIP conversations. Specif-
ically, we propose an approach for outputting a hypoth-
esized transcript of a conversation, based on segmenting
the sequence of observed packets sizes into subsequences
corresponding to the likely phonemes they encode. These
phoneme sequences are then mapped to candidate words,
after which we incorporate word and part-of-speech based
language models to choose the best candidates using contex-
tual information from the hypothesized sentence as a whole.
Our results show that the quality of the recovered transcripts
is far better in many cases than one would expect. While the
generalized performance is not as strong as we would have
liked, we believe the results still raise cause for concern:
in particular, one would hope that such recovery would not
be at all possible since VoIP audio is encrypted precisely to
prevent such breaches of privacy. It is our belief that with
advances in computational linguistics, reconstructions of the
type presented here will only improve. Our hope is that this
work stimulates discussion within the broader community
on ways to design more secure, yet efﬁcient, techniques for
preserving the conﬁdentiality of VoIP conversations.
VIII. ACKNOWLEDGEMENTS
We thank the anonymous reviewers for their insightful
comments. We also thank Elliot Moreton of the Department
of Linguistics at UNC-Chapel Hill for helpful suggestions.
This work is supported in part by NSF grants CCF-1017318
and CNS-0852649.
REFERENCES
[1] 3GPP. Extended adaptive multi-rate wideband (AMR-WB+)
codec. Technical Report 26.290, 3rd Generation Partnership
Project (3GPP), 2009.
[2] M. Backes, G. Doychev, M. D¨urmuth, and B. K¨opf. Speaker
recognition in encrypted voice streams. In Proc. 15th Euro-
pean Symposium on Research in Computer Security, pages
508–523, 2010.
17
[6] A. L. Berger, S. A. D. Pietra, and V. J. D. Pietra. A
maximum entropy approach to natural language processing.
Computational Linguistics, 22:39–71, 1996.
[7] L. Bernaille and R. Teixeira. Early recognition of encrypted
applications. In PAM, pages 165–175, 2007.
[3] M. Baugher, D. McGrew, M. Naslund, E. Carrara, and K. Nor-
rman. The secure real-time transport protocol (SRTP). RFC
3711, Internet Engineering Task Force, 2004.
[4] L. E. Baum, T. Petrie, G. Soules, and N. Weiss. A max-
imization technique occurring in the statistical analysis of
probabilistic functions of Markov chains. The Annals of
Mathematical Statistics, 41(1):164–171, 1970.
[5] D. Beeferman, A. Berger, and J. Lafferty. Statistical models
for text segmentation. Mach. Learn., 34(1-3), 1999.
[8] D. Blanchard, J. Heinz, and R. Golinkoff. Modeling the
contribution of phonotactic cues to the problem of word
segmentation. The Journal of Child Language, 37(3):487–
511, 2010.
[9] H. Bortfeld, J. Morgan, R. Golinkoff, and K. Rathbun.
Mommy and me: Familiar names help launch babies into
speech-stream segmentation. Psychological Science, 16:298–
304, 2005.
[10] S. Chen, R. Wang, X. Wang, and K. Zhang. Side-channel
leaks in web applications: A reality today, a challenge to-
morrow. In Proceedings of the IEEE Symposium on Security
and Privacy, pages 191–206, 2010.
[11] R. A. Cole and J. Jakimik. A Model of Speech Perception,
chapter 6, pages 133–163. Lawrence Erlbaum Associates,
1980.
[12] M. Crotti, M. Dusi, F. Gringoli, and L. Salgarelli. Trafﬁc
classiﬁcation through simple statistical ﬁngerprinting. SIG-
COMM Comput. Commun. Rev., 37(1):5–16, 2007.
[13] M. Denkowski and A. Lavie. Choosing the right evaluation
for machine translation: an examination of annotator and
automatic metric performance on human judgment tasks. In
Proceedings of AMTA, 2010.
[14] M. Denkowski, A. Agarwal, S. Banerjee, and A. Lavie. The
METEOR MT Evaluation System, Version 1.2. Carnegie
Mellon University, Pittsburgh, PA, 2010.
[15] B. Dupasquier, S. Burschka, K. McLaughlin, and S. Sezer.
Analysis of information leakage from encrypted Skype con-
International Journal of Information Security,
versations.
pages 1–13, 2010.
[16] R. Durbin, S. Eddy, A. Grogh, and G. Mitchison. Biological
Sequence Analysis: Probabilistic Models of Proteins and
Nucleic Acids. Cambridge University Press, 1998.
[17] M. Dusi, M. Crotti, F. Gringoli, and L. Salgarelli. Detection of
encrypted tunnels across network boundaries. In ICC, pages
1738–1744, 2008.
[18] A. Esposito and G. Aversano. Text independent methods for
In Nonlinear Speech Modeling and
speech segmentation.
Applications, volume 3445 of Lecture Notes in Computer
Science, pages 261–290. Springer, 2005.
[19] P. Fogla, M. Sharif, R. Perdisci, O. Kolesnikov, and W. Lee.
Polymorphic blending attacks. In Proceedings of the USENIX
Security Symposium, pages 241–256, 2006.
[20] W. N. Francis and H. Kucera. Brown corpus manual. Tech-
nical report, Department of Linguistics, Brown University,
1979.
[21] J. S. Garofolo, L. F. Lamel, W. M. Fisher, J. G. Fiscus, D. S.
Pallett, N. L. Dahlgren, and V. Zue. TIMIT acoustic-phonetic
continuous speech corpus, 1993.
[22] D. Gildea and D. Jurasky. Learning bias and phonological-
rule induction. Computational Linguistics, 22(4):497–530,
[23] M. Halle. Knowledge unlearned and untaught: What speakers
know about the sounds of their language. Linguistic Theory
and Psychological Reality, pages 294–303, 1978.
[24] J. Harrington, G. Watson, and M. Cooper. Word boundary
identiﬁcation from phoneme sequence constraints in auto-
In Computational
matic continuous speech recognition.
linguistics - Volume 1, pages 225–230, 1988.
[25] B. Hayes and C. Wilson. A maximum entropy model of
phonotactics and phonotactic learning. Linguistic Inquiry, 39
(3):379–440, 2008.
[26] Y. Hifny and S. Renals. Speech recognition using augmented
IEEE Transactions on Audio,
conditional random ﬁelds.
Speech, and Language Processing, 17(2):354 –365, 2009.
[27] A. Iacovazzi and A. Baiocchi. Optimum packet
length
In 22nd International Teletrafﬁc Congress (ITC),
masking.
pages 1–8, 2010.
[28] E. T. Jaynes.
Information theory and statistical mechanics.
Phys. Rev., 106(4):620–630, May 1957.
[29] F. Jelinek.
Statistical Methods for Speech Recognition.
Massachusetts Institute of Technology, 1997.
[30] D. Jurafsky and J. H. Martin. Speech and Language Pro-
cessing: An Introduction to Natural Language Processing,
Computational Linguistics, and Speech Recognition. Prentice
Hall, 2008.
[31] T. Karagiannis, K. Papagiannaki, and M. Faloutsos. BLINC:
multilevel trafﬁc classiﬁcation in the dark. SIGCOMM Com-
put. Commun. Rev., 35(4):229–240, 2005.
[32] T. Kempton and R. K. Moore. Language identiﬁcation:
Insights from the classiﬁcation of hand annotated phone
transcripts. In Speaker and Language Recognition Workshop,
Jan. 2008.
[33] A. D. Keromytis. A survey of Voice over IP security
research. In Proceedings of the 5th International Conference
on Information Systems Security, pages 1–18, 2009.
[34] A. Lavie.
Evaluating the output of machine translation
systems. AMTA Tutorial, 2010.
[35] A. Lavie and M. J. Denkowski.
The METEOR metric
for automatic evaluation of machine translation. Machine
Translation, 23:105–115, September 2009.
[36] K.-F. Lee and H.-W. Hon. Speaker-independent phoneme
recognition using hidden Markov models. The Journal of
the Acoustical Society of America, 84(S1):62, 1988.
[37] T. Leila and R. Bettati. Privacy of encrypted Voice-over-
IP. In Proceedings of the IEEE International Conference on
Systems, Man and Cybernetics, pages 3063 –3068, 2007.
[38] M. Liberatore and B. N. Levine.
Inferring the source
the
of encrypted HTTP connections.
ACM Conference on Computer and Communications Security,
pages 255–263, 2006.
In Proceedings of
[39] D. C. Liu, J. Nocedal, and D. C. On the limited memory
BFGS method for large scale optimization. Mathematical
Programming, 45:503–528, 1989.
[40] E. Loper and S. Bird. NLTK: The natural language toolkit,
1996.
May 2002.
[41] Y. Lu. On trafﬁc analysis attacks to encrypted VoIP calls.
Master’s thesis, Cleveland State University, Fenn College of
Engineering, 2009.
[42] G. Maiolini, A. Baiocchi, A. Iacovazzi, and A. Rizzi. Real
time identiﬁcation of SSH encrypted application ﬂows by
the
using cluster analysis techniques.
International IFIP-TC 6 Networking Conference, pages 182–
194, 2009.
In Proceedings of
[43] A. McGregor, M. Hall, P. Lorier, and J. Brunskill. Flow
clustering using machine learning techniques. In PAM, pages
205–214, 2004.
[44] I. Mporas, T. Ganchev, and N. Fakotakis.
Speech seg-
mentation using regression fusion of boundary predictions.
Computer Speech & Language, 24(2):273–288, 2010.
[45] M. Oakes. Computer estimation of vocabulary in protolan-
guage from word lists in four daughter languages. Journal of
Quantitative Linguistics, 7(3):233–243, 2000.
[46] A. Ratnaparkhi. A maximum entropy model for part-of-
speech tagging. In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, pages 133–142,
1996.
[47] W. D. Raymond, M. Pitt, K. Johnson, E. Hume, M. Makashay,
R. Dautricourt, and C. Hilts. An analysis of transcription
consistency in spontaneous speech from the Buckeye corpus.
In Proceedings of the International Conference on Spoken
Language Processing, 2002.
[48] T. S. Saponas, J. Lester, C. Hartung, S. Agarwal, and
T. Kohno. Devices that tell on you: privacy trends in con-
sumer ubiquitous computing. In Proceedings of the USENIX
Security Symposium, pages 1–16, 2007.
[49] M. R. Schroeder and B. S. Atal. Code-excited linear pre-
diction (CELP): High-quality speech at very low bit rates.
In Proceedings of
the IEEE International Conference on
Acoustics, Speech, and Signal Processing, volume 10, pages
937–940, April 1985.
[50] D. X. Song, D. Wagner, and X. Tian. Timing analysis of
keystrokes and timing attacks on SSH. In Proceedings of the
USENIX Security Symposium, pages 25–25, 2001.
[51] A. Stolcke.
SRILM – an extensible language modeling
toolkit. In Proceedings of the ICSLP, volume 2, pages 901–
904, 2002.
[52] Q. Sun, D. R. Simon, Y.-M. Wang, W. Russell, V. N. Pad-
manabhan, and L. Qiu. Statistical identiﬁcation of encrypted
web browsing trafﬁc. In Proceedings of the IEEE Symposium
on Security and Privacy, 2002.
[53] J.-M. Valin. The Speex codec manual, 2007.
[54] C. V. Wright, F. Monrose, and G. M. Masson. On inferring
application protocol behaviors in encrypted network trafﬁc.
Journal of Machine Learning Research, 6:2745–2769, 2006.
[55] C. V. Wright, L. Ballard, F. Monrose, and G. M. Masson.
Language identiﬁcation of encrypted VoIP trafﬁc: Alejandra
y Roberto or Alice and Bob? In Proceedings of the USENIX
Security Symposium, 2007.
[56] C. V. Wright, L. Ballard, S. E. Coull, F. Monrose, and G. M.
Masson. Spot me if you can: Uncovering spoken phrases in
In Proceedings of the IEEE
encrypted VoIP conversations.
Symposium on Security and Privacy, 2008.
[57] C. V. Wright, S. E. Coull, and F. Monrose. Trafﬁc morphing:
An efﬁcient defense against statistical trafﬁc analysis.
In
Proceedings of the Network and Distributed System Security
Symposium, 2009.
[58] J. Zobel and P. Dart. Finding approximate matches in large
lexicons. Software—Practice and Experience, 25(3):331–345,
1995.
[59] J. Zobel and P. Dart.
Fnetik: An integrated system for
phonetic matching, 1996. RMIT, Technical Report 96-6.
18