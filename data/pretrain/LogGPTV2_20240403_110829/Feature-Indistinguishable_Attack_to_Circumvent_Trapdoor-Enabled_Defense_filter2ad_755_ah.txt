### Trapdoor and Input Image Merging

The pixel value ratio for the trapdoor trigger and the input image is set to 0.1:0.9 when merging them to generate a contaminated image. These trapdoor settings are summarized in Table 15.

### YouTube Face Dataset

The YouTube Face dataset features larger image sizes and more categories compared to other datasets. The trapdoor parameters have been slightly adjusted to fit the characteristics of this dataset:
- A single 42 × 42 pattern placed at the bottom-right corner, or
- Five 21 × 21 patterns placed randomly across the entire image.
- The injection ratio is set to 0.01 for a single trapdoor and 0.5 for multiple trapdoors.
- In both cases, the merge transparency is set to 0.2.

### ROC Curves for TeD and P-TeD

Figure 2 presents the ROC curves for TeD and P-TeD in defending against single-category attacks. The top row shows results for TeD, and the bottom row for P-TeD. The columns, from left to right, represent the datasets MNIST, CIFAR10, GTSRB, and YouTube Face.

### TeD - Single & All Categories (5% FPR of Others)

In evaluating the attack performance of baseline attacks PGD and C&W against the trapdoored defense, we found that some detection rates for PGD and C&W were significantly lower than those reported in [51] (see Section 6.2). The authors of TeD do not clearly describe how their false positive rate (FPR) is calculated in [51]. By examining their released code [50], we discovered that the FPR is calculated using benign non-target samples to determine the detection threshold \( \phi_t \) at 5% FPR. This can lead to a high FPR for benign target samples, as explained below and confirmed by our experimental results.

#### Bug in Released Code

We believe it is a bug to use benign non-target examples to calculate FPR in the released code [50]. When a trapdoored model is used to protect a specific category \( C_t \), TeD should only be used to determine if an input is benign or adversarial when the input is classified into \( C_t \). It should not be used to detect inputs classified into other categories. Only samples classified into the protected category matter. Since trapdoored samples and benign target samples are classified into \( C_t \), while benign non-target samples are classified into other categories, benign non-target samples should have lower cosine similarity values with the trapdoor signature (the average of feature vectors of trapdoored samples) than benign target samples. This means that the detection threshold \( \phi_t \) determined by 5% FPR of benign non-target samples would be lower than it should be, leading to many benign target samples being falsely detected. Our experimental results show that all benign target samples on GTSRB are classified as adversarial, resulting in a 100% FPR for benign target samples. In this case, FIA cannot craft any adversarial examples because it cannot find any negative examples in the preparation phase to determine proper targets and boundaries.

#### Experimental Results

For completeness, we report the attack performance of our FIA, PGD, and C&W for this setting, although such a detection setting is practically useless due to its high FPR for benign target samples. Table 16 shows the detection rates of TeD protecting single and all categories on the four datasets when the detection threshold \( \phi_t \) is determined to be 5% FPR of benign non-target samples. We also report the corresponding FPRs of benign target samples. The detection rate for FIA on GTSRB is marked as N/A since all benign target samples are detected (i.e., 100% FPR).

From Table 16, we observe that the trapdoored defense has a very high detection rate for both PGD and C&W, which aligns with the results reported in [51], but a very low detection rate for adversarial examples crafted with FIA.

### ROC Curves of TeD and P-TeD

To further compare the detection performance of TeD and P-TeD on FIA, PGD, and C&W, we report the ROC curves and AUC scores for TeD and P-TeD to defend a single category in Figure 2. P-TeD has very high AUC scores for both PGD and C&W, at or above 0.97, on all tested datasets. TeD has high AUC scores for both PGD and C&W on MNIST and CIFAR10, at or above 0.93. However, the AUC score of TeD for C&W on GTSRB is 0.43, much lower than on other datasets. Further investigation reveals that the cosine similarity distribution of adversarial examples with the trapdoor signature and that of benign target samples with the trapdoor signature overlaps significantly on GTSRB. Using the projected signature significantly boosts the AUC score of C&W on GTSRB to 0.98 for P-TeD. Both TeD and P-TeD have low AUC scores for FIA, all at or below 0.37. FIA's AUC scores on MNIST and YouTube Face are higher than on the other two datasets, indicating that it is more difficult for FIA to craft adversarial examples on these datasets. Relaxing the bounds can improve FIA's performance, but at the cost of noisier adversarial examples.

### Perceptual Quality of Adversarial Examples Crafted with FIA

Figure 3 compares the perceptual quality of adversarial examples crafted with FIA on TeD-protected models and PGD on clean models for different datasets. The same bound is used for FIA and PGD on each dataset. Adversarial examples crafted with FIA generally look better than those crafted with PGD.