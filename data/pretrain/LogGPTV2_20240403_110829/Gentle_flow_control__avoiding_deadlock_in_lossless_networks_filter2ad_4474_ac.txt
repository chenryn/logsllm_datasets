of buffer-based/time-based GFC are explicitly presented.
5.1 Buffer-based GFC
Message Generator. PFC has implemented the Message Generator
module to generate PAUSE/RESUME messages. We can reutilize
this module and only change (1) the trigger for generating a new
feedback message and (2) the information carried in the message.
In buffer-based GFC, we add multiple thresholds (rather than two
in PFC) to implement the multi-stage rate control. The threshold
values are determined according to Equation (5). Once the queue
length changes across a threshold, Message Generator is triggered
to generate a feedback message.
The feedback message should be modified to carry the stage in-
formation. The original PFC message type is given in Figure 7. The
Class-Enable Vector (CEV) represents on which priority this mes-
sage takes effect. Time[0] ∼ Time[7] are used to store the duration
of PAUSE. In our implementation, we modify Time[0] ∼ Time[7]
to encode the stage information. Since we only need to carry the
stage information of queue length, so a two-byte field is enough.
Rate Adjuster. When receiving a feedback message, Rate Adjuster
extracts the queue length information and calculates the sending
rate accordingly. Feedback message generated by buffer-based Mes-
sage Generator contains the queue length stage information, which
can be directly mapped to the sending rate. Since the mapping
function is a step function, Rate Adjuster can directly use an array
to store the mapping relationship. This implementation consumes
80
QueuelengthRate0B1B2BmC(R0)R1R2C(R0)Stage 0Stage 1Stage 2B0DstMACSrcMAC88080101CEVTime[0]Time[1]Time[7]PadCRC6B6B2B2B2B2B2B2B28B4BGentle Flow Control: Avoiding Deadlock in Lossless Networks
SIGCOMM ’19, August 19–23, 2019, Beijing, China
Rr
(Rl , Rr , and Rc) and adding some auxiliary processes. Rl records
the packet transmission time. Rr works for storing the assigned
queue rate. Rc runs as a countdown timer. Each time a packet is
completely sent, the corresponding transmission time is recorded
in Rl . Rc is set to (C−Rr)
Rl and starts to count down. When Rc > 0,
this queue cannot send packets. After Rc counts down to zero, this
queue is allowed to send a new packet. This processing logic can be
implemented with small overhead. Furthermore, since 10Gbps ports
usually run at a clock rate of 833MHz [8], the counting down of
Rc can be implemented at the granularity of 1.2ns, which provides
sufficient accuracy for our rate limiting.
(2) The number of required Rate Limiters is limited. In com-
modity switches, each port usually contains 8 (or less) priority
queues [22, 25, 28, 40]. Considering a 24-port switch, it requires
192 Rate Limiters at most. Furthermore, less priorities are em-
ployed for lossless traffic in actual deployments. For example, in
RoCE, only two or three priorities are supported by commodity
switches [22, 25], which makes the number of required Rate Lim-
iters decrease to 72. On the other hand, in SENIC [47], 1000 high-
accuracy 10Gbps rate limiters are implemented on programmable
hardware by just consuming 30KB SRAM resources (0.1%). So the
overhead introduced by implementing rate limiters is affordable.
5.4 Parameter Settings
We first give the detailed calculation of τ, which is the founda-
tion of determining parameters in mapping functions. Then the
parameter settings in buffer-based/time-based GFC are illustrated,
respectively.
The elements of τ. Both Theorem 4.1 and 5.1 tell that τ plays an
important role in determining parameters in GFC mapping function.
The following part presents all constituent parts of τ in practice.
(1) When the receiver is ready to emit a feedback message, this
message cannot interrupt on-going packet transmission on
the port. In the worst case, this message will be delayed for
MT U
, where MTU is the maximum transmission unit.
C
(2) Transmitting packets through the wire needs the time tw .
On the wire, data travels at the speed of about 2 × 108m/s.
So transmitting a packet for 100m takes about 512ns.
(3) Then this feedback message arrives at the sender side. It
takes tr for the sender to process this message. The length
of tr depends on the implementation of processing logic and
the upper limit is 3µs [10].
(4) After processing the feedback message, the sender changes
the output rate accordingly. However, this modification can
only be done when no packet is transmitting on the port. In
the worst case, it needs to wait for another MT U
C
make this change reflecting on the input rate.
(5) Finally, the opposite transmission latency tw is needed to
.
By adding all these elements together, the value of τ can be upper
bounded by Equation (6).
τ ≤ 2MTU
(6)
Assume that C = 10/40/100Gbps and tw = 1µs. In CEE, the
MTU = 1.5KB, so the worst-case τ is 7.4/5.6/5.2µs, respectively.
+ 2tw + tr
C
Figure 8: The event sequence in the receiver side of time-
based GFC.
few storage resources and eliminates rate calculations. Then Rate
Adjuster updates Rate Limiter in the corresponding egress queue
to conduct rate modification. The detailed implementation of Rate
Limiter is presented in Section 5.3.
5.2 Time-based GFC
Message Generator. Notice that in CBFC, downstream switch port
generates feedback messages periodically. This mechanism can also
achieve the goal of limiting feedback frequency. So it is reserved in
time-based GFC. Furthermore, in CBFC, feedback messages already
carry the remaining buffer information (credit), which is enough
for GFC. So we can directly reuse this Message Generator without
any modification.
Rate Adjuster. Messages sent from Message Generator are trig-
gered by time rather than stage boundaries, which means the de-
duced multi-stage mapping function is no longer appropriate in
this scenario. We work out a new mapping function in time-based
Rate Adjuster based on the conceptual design (Section 4.1).
Assume the feedback period is T , the time sequences of sending
messages and updating input rate are shown in Figure 8. At the
end of the nth round, Message Generator sends back a message
carrying current credit information. At present, the input port
receives packets at the rate calculated in the (n − 1)th round. It
takes τ for the new feedback message to take effect. Then the input
rate changes to the new rate calculated in the nth round, and this
rate will remain unchanged in the next T interval. The introduction
of T will blunt the control of sending rate. In order to avoid hold
and wait in this scenario, we give Theorem 5.1 to determine the
bound of B0. Appendix B gives the detailed proof.
Theorem 5.1. In time-based GFC, if B0 ≤ Bm − ((cid:113) τ
+ 1)2
CT ,
T
hold and wait can be avoided.
Under the guidance of Theorem 5.1, the mapping function can
be determined. Once Rate Adjuster receives a feedback message, it
extracts FCCL and calculates out the remaining buffer size (FCCL−
FCT BS). Then the corresponding sending rate is calculated through
the mapping function and Rate Limiter is updated accordingly.
5.3 Rate Limiter
In GFC, each queue needs an independent Rate Limiter to determine
when to send the next packet. Actually, many network equipment
manufactures (e.g., Cisco, Juniper Networks and Mellanox) already
support this feature in their commercial off-the-shelf switches [11,
34, 39]. Even implementing GFC Rate Limiters from scratch, it only
introduces small overhead.
(1) Implementing one GFC Rate Limiter occupies few resources.
Rate Limiter can be implemented by employing three registers
81
TimeReceiversideSending messageRate changingT (n-1)TnT(n+1)TSIGCOMM ’19, August 19–23, 2019, Beijing, China
Kun Qian, Wenxue Cheng, Tong Zhang, Fengyuan Ren
(a) PFC
(b) Buffer-based GFC
(a) CBFC
(b) Time-based GFC
Figure 9: The experiment results of PFC and buffer-based
GFC.
Figure 10: The experiment results of CBFC and time-based
GFC.
The MTU in InfiniBand is 4KB, so the worst-case τ is 11.4/6.6/5.6µs,
respectively.
Parameters in buffer-based GFC. In buffer-based GFC, two
parameters (Bm and B1) need to be determined. All other parame-
ters can be uniquely deduced. Since the buffer space (Bm, B) would
never be used in practice, Bm can be set to B for fully utilizing
buffer resource. We directly set B1 (rather than B0) here because in
multi-stage mapping function the mapped rate of stage 0 is equal
to the link capacity C. The constraint of B1 is that B1 ≤ Bm − 2Cτ.
Once the physical network is built up completely, the values of Bm,
C and τ are determined (in commodity 10/40/100Gbps network,
2Cτ ≤ 18.5/56/130KB, respectively). Corresponding parameters of
stage k (1 ≤ k ≤ N) can be calculated as follows: Rk = 1
2k C and
Bk = Bm − 1
2k−1 (Bm − B1). The total stage number N should make
BN − BN−1 ≤ 8b. Considering C = 10/40/100Gbps, N = 16/18/20,
respectively.
Parameters in time-based GFC. In time-based GFC, three pa-
rameters (T , Bm and B0) need to be configured. Similarly, Bm is set
equal to B. The setting of feedback period T concerns a trade-off
between buffer and bandwidth. A small T decreases the required
buffer size, but increases the overhead on bandwidth, while a large T
leads to the opposite case. In CBFC, the recommended value of T is
the time required to trasmit 65535B data quantity [40]. This recom-
mended value can be followed in time-based GFC. According to The-
CT (in commod-
CT ≤ 140.8/191.4/271KB,
orem 5.1, Equation (2) and (4), B0 ≤ Bm −((cid:113) τ
ity 10/40/100Gbps network, ((cid:113) τ
+ 1)2
T
+1)2
T
respectively).
hosts. Since existing commodity switches do not provide interface
to modify inbuilt flow control mechanisms, we leverage software
switch to customize flow control mechanisms. Three servers, each
equipped with dual Intel Xeon E5-2620 v3 CPUs (6 cores, 2.4GHz),
are used to build software switches. Each server is plugged with 2
dual-port Intel 82599 10G NICs. So each server can work as a four-
port switch. DPDK [30] is employed to deliver received data directly
to user space. The basic L2 switch is built based on the reference
test-pipeline project [31]. To achieve line-rate sending/receiving
at 10Gbps, each RX/TX module is implemented on an individual
core. Forwarding module runs on a separate core and a hash table
in address-port mapping is used to reduce the lookup delay. We im-
plement buffer-based/time-based GFC based on this basic software
switch platform. For comparison, we implement PFC according
to IEEE 802.1Qbb [27] and CBFC according to InfiniBand Speci-
fication [4]. Although the testbed is built based on Ethernet, the
physical layer media hardly affects the process and performance of
layer-2 flow control. Therefore this testbed is capable of evaluating
above flow control mechanisms.
Parameter configurations: The input buffer size is 1MB. Through
our measurement, the worst-case value of τ is 90µs. Here τ is a
few times larger than the value in the commodity switch because
of software implementation. In PFC, XOF F is set to 800KB and
XON is 797KB. In buffer-based GFC, B1 is set to 750KB. In CBFC,
the feedback period is 52.4µs. In time-based GFC, the period re-
mains unchanged and B0 is 492KB. In experiments, all servers start
together and generate packets at line rate.
6 EVALUATION
In this section, we evaluate GFC with testbed experiments as well as
large-scale simulations. Our testbed experiments verify that buffer-
based/time-based GFC can control the sending rate elaborately
and eventually avoid deadlock. The detailed packet-level simula-
tions confirm that GFC schemes can take good effect and introduce
negligible side-effects in practical network scenarios.
6.1 Experiments
We build up the experiment topology as shown in Figure 1(a). Em-
ploying GFC schemes in this typical deadlock-prone network, we
can verify the effectiveness of GFC.
6.1.1 Testbed implementation. In the testbed, three servers, each
equipped with single Intel i7-4700 CPU (4 cores, 3.4GHz), act as
6.1.2 Results. Both PFC and CBFC trap into deadlock. Tracing
the evolutions of input rate and queue length of the switch port
connecting to H1 as a representative (the states of other ports are
similar), the results are shown in Figure 9(a) and Figure 10(a). In
both experiments, it takes some time to fill up the ingress queue.
However, owing to the intrinsic pausing/resuming behavior pattern,
network falls into deadlock finally.
When employing GFC schemes, network deadlock is avoided.
The corresponding results are shown in Figure 9(b) and Figure 10(b).
In buffer-based GFC, the queue length first climbs up to 884KB,
which triggers H1 to transiently decrease the output rate to 2.5Gbps.
Then the queue length drops back to 840KB. The overshoot is
noticeable. However, under the adjustment of mapping function,
the queue length comes back to the expected status quickly and
then keeps steady.
82
 0 200 400 600 800 1000 0 1000 2000 3000 4000 0 2 4 6 8 10Length (KB)Rate (Gbps)Time (us)Exp. queue lengthExp. input rateSim. queue lengthSim. input rate 0 200 400 600 800 1000 0 1000 2000 3000 4000 5000 0 2 4 6 8 10Length (KB)Rate (Gbps)Time (us)Exp. queue lengthExp. input rateSim. queue lengthSim. input rate 0 200 400 600 800 1000 0 1000 2000 3000 4000 0 2 4 6 8 10Length (KB)Rate (Gbps)Time (us)Exp. queue lengthExp. input rateSim. queue lengthSim. input rate 0 200 400 600 800 1000 0 1000 2000 3000 4000 0 2 4 6 8 10Length (KB)Rate (Gbps)Time (us)Exp. queue lengthExp. input rateSim. queue lengthSim. input rateGentle Flow Control: Avoiding Deadlock in Lossless Networks
SIGCOMM ’19, August 19–23, 2019, Beijing, China
Figure 11: Fat-tree topology (k = 4) with three failed links
(represented with dash lines).
Figure 14: Victim flow.
(a) Buffer-based GFC
(b) Time-based GFC
network scenario as in testbed experiments is used to validate our
simulator. Then, a practical 3-layer network deadlock case is built
to evaluate the performance of GFC schemes. Finally, we randomly
generate large-scale network scenarios that are prone to deadlock
to test the comprehensive performance of GFC.
(a) PFC
(b) Buffer-based GFC
Figure 12: The simulation results of PFC and buffer-based
GFC.
(a) CBFC
(b) Time-based GFC
Figure 13: The simulation results of CBFC and time-based
GFC.
As shown in Figure 10(b), in time-based GFC, after the initial
fluctuation, the queue length stabilizes at 745KB and the input
rate maintains at 5Gbps as well. In time-based GFC, the sending
rate changes after each feedback period and gradually converges
to the steady state. So the evolution of sending rate is smoother
compared with that in buffer-based GFC, which can only switch
rate among predefined stages. Notice that there is slight overshoot
in time-based GFC experiment. There are two main reasons: (1) The
τ value considered in parameter configuration is a worst-case value,
which can be rarely reached in practice. (2) The deduced bound
of B0 in time-based GFC is relatively slack, thus abundant buffer
space is reserved to make the rate adjusting process much more
smoothly. Small overshoot is actually a good property in practical
deployment.
6.2 Simulations
We leverage OMNET++ [45], a packet-level simulation platform, to
build our simulator. Both PFC and CBFC are implemented according
to corresponding standards [4, 27], respectively. First the same
83
6.2.1
Simulator verification. To validate our simulator, we first
build up the same 3-switch deadlock scenario shown in Figure 1(a),
and use the same parameter settings in above experiments. The
results are also presented in Figure 9 and Figure 10. In all four
simulations, the main conclusions remain consistent: both PFC
and CBFC fall into deadlock and GFC schemes eliminate it. Since