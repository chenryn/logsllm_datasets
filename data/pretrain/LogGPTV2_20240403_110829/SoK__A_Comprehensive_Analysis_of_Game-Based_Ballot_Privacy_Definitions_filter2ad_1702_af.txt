impact
One of our ﬁndings is that a good ballot privacy deﬁnition
must restrict
the class of revote policies allowed. This is
because the algorithms implementing a revote policy might
need the secret key as an input — some voting schemes,
such as JCJ/Civitas, need the election secret key to implement
revote. This opens the door to intentionally leaky revote
policies, which could use this secret key to gain information
on voters’ votes.
In Civitas [30], ballots with invalid credentials are removed
based on a plaintext-equivalence test that uses some trapdoor
unavailable to the ballot privacy attacker. This can be captured
in a strongly consistent way by including this operation in
ρ. Given a ballot b that contains a vote v and a credential
cred, the Extract function should return both cred and v.
Then ρ should remove any vote that corresponds to an invalid
credential.
509509
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:30 UTC from IEEE Xplore.  Restrictions apply. 
Other schemes also require the election secret key to be
able to clean the ballots. Sometimes, (part of) the private key
is needed to determine the validity of ciphertexts, e.g., when
Cramer-Shoup encryption is used [36]. This can be captured by
having Extract performing the appropriate tests. In some other
cases, e.g., in mixnet-based schemes, the validity of ballots
can only be determined even later, after full decryption. We
also include this cleaning operation in ρ: whenever ρ sees an
invalid vote v, then this vote shall be removed. In this way,
Tally remains strongly consistent.
V. A SIMULATION-BASED MODEL OF BALLOT PRIVACY
In this section we deﬁne an ideal functionality for voting
protocols, in the spirit of Groth [13] and de Marneffe et
al. [14], but handling voters that submit multiple votes. The
inspection of this functionality should make it obvious to the
reader that, if a trusted party were available to provide its
service, then we would have a voting system offering all
expected privacy guarantees and that all adversaries against
that functionality are harmless.
We show that any voting scheme satisfying BPRIV and
strong consistency offers at least as much7 privacy guarantees
as this ideal functionality. This will be demonstrated using
the traditional real-world/ideal world paradigm: we show that
anything that can be done by an adversary against the voting
protocol can also be done by an adversary interacting with the
ideal functionality. Since we know that any adversary against
the ideal functionality is harmless, this shows that the real
protocol adversary must be harmless too. Our treatment leaves
out many technical details of the execution model and focuses
on the crucial part. We expect that it could be cast formally in
traditional security frameworks in which universal composition
theorems hold, even though we are not concerned with any
such composition result here.
We start by describing our ideal world setting, then the real
world one, and eventually show the implications of our game-
based security deﬁnitions.
A. An ideal functionality for voting
identities I and a result function ρ : (I × V)
functionality has a simple behavior:
We describe an ideal voting functionality for a set of
∗ → R. This
1) It ﬁrst expects to receive one or more votes, both from
honest and from corrupted voters. Every time a vote is
received, the identity of the voter and the vote content
are stored, and the functionality lets the adversary know
who submitted a vote (but not the content of the vote,
of course). This captures the idea that submitting a vote
is a public action but could be relaxed in settings where
voting would be private (though this usually has a cost
in terms of eligibility veriﬁability.)
7Actually, BPRIV, strong correctness, and strong consistency are a strictly
stronger condition than securely realising our ideal functionality. Essentially,
these conditions deﬁne one particular simulator that work for the simulation-
based deﬁnition. The converse implication is not necessarily true.
2) When it receives the order to tally,
the functionality
evaluates the ρ function on the sequence of pairs of
identities and votes that it has received, and sends the
result to the adversary.
Following the traditional ideal world/real world terminol-
ogy, we give the control of the honest voters to an entity called
the environment, which submits honest votes of its choice
directly to the functionality. This single entity coordinating the
honest voters ensures that security will be satisﬁed whoever
the honest votes are and whatever distribution they follow.
The ideal-world adversary, which we also call the simulator
(following the tradition), can also submit arbitrary votes to
the functionality, on behalf of (maybe temporarily) corrupted
voters. Furthermore, this simulator can receive arbitrary infor-
mation from the environment. This captures information that
the adversary could obtain about the honest votes externally
from the voting protocol (e.g., through polls,
. . . ). It also
interacts with the environment as part of its adversarial be-
havior, reporting its achievements. Eventually, the environment
outputs a single bit that expresses whether or not it feels that
it is interacting in the ideal-wold we just described. If the
environment can notice that it is not running in this ideal world
when it is actually running with a real protocol, then the real
world protocol will be claimed to be insecure.
Deﬁnition 10: The functionality Fvoting(ρ), interacting with
an environment E and an adversary S, proceeds as follows:
1) On input vote(id, v) from E or S, store (id, v) and send
ack(id) to S.
2) On input tally from S, return to both E and S the result
of the function ρ applied on the sequence of (id, v) pairs
received, then halt.
This functionality has clear privacy properties: it reveals
who votes, and the result of the election, but nothing more.
Furthermore, the votes from the simulator are sent to the
functionality in complete independence of the honest votes
from the environment unless the environment itself tipped the
simulator in the ﬁrst place (which cannot be prevented by
any voting system): the functionality does not give S any
information related to the honest votes before it provides the
election result. This seems to be the best we can hope for in
terms of privacy of votes.
The full process in which an environment E, an adversary
S and an ideal functionality Fvoting(ρ) interact, returning the
single output bit β produced by the environment, is written
β ← idealexec(E(cid:10)S(cid:10)Fvoting(ρ)).
B. The real protocol execution
real world, we
scheme
V = (GlobalSetup, Setup, Vote, Valid, Publish, Tally, Verify)
played by a set of honest voters, an adversary A who can
take control of voters, a honest administrator, and an honest
ballot box. A global setup might be available to all these
parties, e.g., under the form of a random oracle or a common
random string, as provided by GlobalSetup. These three
voting
have
In
the
a
510510
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:30 UTC from IEEE Xplore.  Restrictions apply. 
honest elements, i.e. the administrator, the ballot box and the
global setup, can be seen as incorruptible ideal functionalities,
and we say that a protocol running in the presence of these
three functionalities runs in the ABG-hybrid model. If they
are not readily available, these functionalities can be securely
implemented using lower-level protocols, which are kept out
of our model here. For instance, one would typically have
multiple administrators running a threshold scheme in a real
election.
As in the ideal world,
there is an environment E who
commands the election: it asks the administrator to setup the
election, provides voting instructions to the honest voters, asks
to read the ballot box, and can also have arbitrary interactions
with A.
An execution of the scheme V in interaction with environ-
ment E and adversary A works as follows.
1) At ﬁrst, and if there is a global setup, E sends a
globalsetup.init command in order to initialize the
setup that is available to everyone.
2) E sends a setup command to the administrator, who
sends the election public key pk to everyone.
3) The ballot box creates an empty BB and can have two
types of interaction:
a) It can receive a ballot(b) command. In this case, it
runs Valid(BB, b) and, if successful, appends b to BB.
b) It can receive a publish command, on which returns
Publish(BB) to the party that issued that command.
4) The following commands can be issued in arbitrary
sequence.
a) E can send vote instructions vote(id, v) to honest
voters, who compute a ballot b = Vote(id, v) and send
ballot(b) to the ballot box.
b) Possibly in coordination with E, the adversary A can
submit arbitrary ballot(b) commands to the ballot
box on behalf of dishonest voters.
c) Anyone can send publish queries to BB.
5) At some point, the adversary sends tally to the ballot
box. The content of BB is then sent to the administrator
who, using the secret key sk, runs Tally on the ballots
and sends the result r and proof Π to the adversary.
The scheduling mechanism we use can be seen as token
passing with the environment as master scheduler: E is active
ﬁrst and, every time a command is issued to a party, this party
gets the token. When a party halts, E gets the token back, until
it sends its output bit which halts the entire system.
The full process in which an environment E and an adver-
sary A run in an execution of a voting scheme V as described
above, returning the single output bit β produced by E, is
written β ← realexec(E(cid:10)A(cid:10)V).
C. Secure implementation
The following deﬁnition captures the idea that a secure
protocol should not leak more information than whatever is
leaked in the ideal world.
511511
Deﬁnition 11: We say that scheme V securely implements
functionality Fvoting(ρ) in the ABG-hybrid model if for any
real adversary A there exists an ideal adversary S such that for
any environment E the distribution idealexec(E||S||Fvoting(ρ))
is computationally indistinguishable from realexec(E||A||V).
The following theorem establishes that correctness, ballot
privacy, and strong consistency for the voting scheme are suf-
ﬁcient conditions to ensure that its associated voting protocol
is secure in the sense deﬁned above.
Theorem 12: If a voting scheme V for result function ρ is
strongly correct, strongly consistent, and ballot private, then
the protocol for V securely implements Fvoting(ρ) in the ABG-
hybrid model.
Proof: We prove the stronger statement that there is a
simulator, with black-box access to the adversary, which works
for any (adversary, environment) pair. We proceed by “game
hopping”.
1) Game 0: is described by realexec(E||A||V).
2) Game 1: is a modiﬁed version of Game 0:
• The board that the adversary sees contains ballots to some
∗ ∈ V instead of the honest voters’ votes.
ﬁxed vote v
• The election result is obtained from the tally of a ballot
box containing ballots for the real votes (which is hidden
from the adversary).
• The auxiliary data are faked, using SimProof as deﬁned
from the BPRIV property.
The reader can immediately observe the close correspon-
dence between the changes made to Game 0 and the guarantees
offered by the BPRIV deﬁnition. Indeed, we show that Game
0 and Game 1 cannot be distinguished, unless the underlying
voting scheme is not BPRIV secure.
We now give a more detailed description of Game 1 and
sketch the proof for the above statement. The initialization step
in Game 1 includes, besides the steps in the intialization of
Game 0, the initialization of the fake board BB1. In the case
of a global setup, a simulated global setup SimGlobalSetup is
produced and add added on BB1: we formally add:
BB1 ← []; SimGlobalSetup ← SimGlobalSetup.init
to the initialization step in Game 0, and the adversary gets
access to SimGlobalSetup.
Next, a setup command is issued to the administrator, and
the adversary gets access to pk.
queries as in Game 0. These are answered as follows:
The adversary and the environment E are allowed the same
• on vote(id, v) ∈ (I × V) from E:
b0 ← Vote(id, v); b1 ← Vote(id, v
∗
then BB0 ← BB0(cid:10)b0, BB1 ← BB1(cid:10)b1.
• on ballot(b) ∈ ({0, 1}∗
if Valid(BB1, b) then BB0 ← BB0(cid:10)b and BB1 ← BB1(cid:10)b.
• on read from A:
); if Valid(BB1, b1)
) from A:
return Publish(BB1) to the adversary.
• on tally from A:
run (r, Π) ← Tally(sk, BB0), Π1 ← SimProof(r, BB1);
return (r, Π1) to the adversary and halt.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:30 UTC from IEEE Xplore.  Restrictions apply. 
We write realexec(cid:3)
execution (which is also the output of Game 1).
(E||A||V) for the output of A in the above
We claim that for any adversary A and environment E,
the distance between the outputs of the games Game 0 and
Game 1, is at most the advantage of some adversary B against
BPRIV security of V.
Let D be a distinguisher (for the outputs of realexec and
realexec(cid:3)
). Adversary B against BPRIV uses D and operates as
follows. B runs E and A internally and answers their queries
as follows.
• on vote(id, v) ∈ I × V from E: adversary B sets v0 ← v
and v1 ← v
∗ and submits (id, v0, v1) to its own OvoteLR
oracle.
• on ballot(b) from A: adversary B issues b to its own
Ocast oracle.
• on read from A: adversary B queries Oboard and
forwards the result to A.
• on tally from A: adversary B queries Otally and
forwards the result to A.
• queries issued by A to his global setup are forwarded by
B to his own global setup; the answers are sent to A.
When E stops, B runs D on the local output of E and
outputs whatever D outputs. When B is in the BPRIV game
with β = 0 the view that B provides to A and the E is as in
realexec(E||A||V). At the same time, if β = 1, then the view
(E||A||V). It fol-
of A and E is the one they have in realexec(cid:3)
lows that whenever D successfully distinguishes between the
outputs of these two games, then B successfully distinguishes
the corresponding experiments Expbpriv,0A,V
and Expbpriv,1A,V .
3) Game 2: We introduce the next game in order to
establish a set of invariants that hold for the execution above;
these will serve as stepping stone to identify and argue about
the properties of the simulator S.
Recall that, in Game 1, ballot box BB0 contains the real
ballots submitted (by the adversary and the honest parties)
and ballot box BB1 contains only fake ballots. In this game
we introduce a third box BB2 which contains a list (id, v) of
the actual votes cast by the users. The ballot box is initially
empty and is updated when ballots are submitted. Speciﬁcally,
we modify the way queries vote(id, v) and ballot(b) are
processed in Game 1, as follows (to ease readability we
underline the parts added in Game 2):