title:Classifiers Unclassified: An Efficient Approach to Revealing IP
Traffic Classification Rules
author:Fangfan Li and
Arash Molavi Kakhki and
David R. Choffnes and
Phillipa Gill and
Alan Mislove
Classiﬁers Unclassiﬁed: An Efﬁcient Approach
to Revealing IP Trafﬁc Classiﬁcation Rules
Fangfan Li∗ Arash Molavi Kakhki∗ David Choffnes∗ Phillipa Gill† Alan Mislove∗
∗Northeastern University
†Stony Brook University
ABSTRACT
A variety of network management practices, from band-
width management to zero-rating, use policies that ap-
ply selectively to diﬀerent categories of Internet traf-
ﬁc (e.g., video, P2P, VoIP). These policies are imple-
mented by middleboxes that must, in real time, assign
traﬃc to a category using a classiﬁer. Despite their im-
portant implications for network management, billing,
and net neutrality, little is known about classiﬁer imple-
mentations because middlebox vendors use proprietary,
closed-source hardware and software.
In this paper, we develop a general, eﬃcient method-
ology for revealing classiﬁers’ matching rules without
needing to explore all permutations of ﬂow sizes and
contents in our testbed environment. We then use it
to explore implementations of two other carrier-grade
middleboxes (one of which is currently deployed in T-
Mobile). Using packet traces from more than 1,000,000
requests from 300 users, we ﬁnd that all the devices we
test use simple keyword-based matching rules on the
ﬁrst two packets of HTTP/S traﬃc and small fractions
of payload contents instead of stateful matching rules
during an entire ﬂow. Our analysis shows that diﬀerent
vendors use diﬀerent matching rules, but all generally
focus on a small number of HTTP, TLS, or content
headers. Last, we explore the potential for misclassiﬁ-
cation based on observed matching rules and discuss im-
plications for subversion and net neutrality violations.
1.
INTRODUCTION
Today’s IP networks commonly use middleboxes to
perform management tasks that include bandwidth
management [6], protecting users from malicious traf-
ﬁc [11], performance optimization [18, 20], and zero-
rating [3]. While previous work has revealed the ex-
Permission to make digital or hard copies of all or part of this work for personal
or classroom use is granted without fee provided that copies are not made or
distributed for proﬁt or commercial advantage and that copies bear this notice
and the full citation on the ﬁrst page. Copyrights for components of this work
owned by others than the author(s) must be honored. Abstracting with credit is
permitted. To copy otherwise, or republish, to post on servers or to redistribute to
lists, requires prior speciﬁc permission and/or a fee. Request permissions from
permissions@acm.org.
IMC 2016, November 14 - 16, 2016, Santa Monica, CA, USA
c(cid:13) 2016 Copyright held by the owner/author(s). Publication rights licensed to
ACM. ISBN 978-1-4503-4526-2/16/11. . . $15.00
DOI: http://dx.doi.org/10.1145/2987443.2987464
istence of middleboxes and their policies using black-
box methods [2, 5, 7, 10, 12–14, 16, 17, 19, 21, 22], there is
little work that investigates how these middleboxes de-
termine which traﬃc is subject to a policy. In this work,
we present the ﬁrst general approach for doing so, and
use this to characterize three carrier-grade middleboxes.
To facilitate network management, numerous ven-
dors provide middleboxes that allow operators to spec-
ify high-level policies for traﬃc management (e.g., block
malicious traﬃc, prioritize VoIP) without needing to
know the details of how to implement them.
In gen-
eral, these policies include a match rule (or classiﬁca-
tion rule) that identiﬁes a class of traﬃc, and an action
that speciﬁes what should be done to this class of traf-
ﬁc. An important challenge for any middlebox is how
to develop matching rules that reliably identify a traﬃc
class—often in real time so that it can apply a policy
to it. While certain types of classiﬁcation are straight-
forward (e.g., identifying DNS traﬃc), accurately clas-
sifying traﬃc into classes such as video, voice, and Web
is challenging due to confounding factors such as SSL
encryption, ubiquitous HTTP transport, and the ab-
sence of standard content encodings. Because these de-
vices are expensive, sold under restrictive license agree-
ments, and deployed in ways that are not transparent
to users or researchers, little is known about how mid-
dlebox classiﬁers work and their implications.
In this paper, we are the ﬁrst to identify and char-
acterize the classiﬁcation rules for HTTP(S) traﬃc im-
plemented in today’s carrier-grade middleboxes. This
allows us to understand how rules are deployed, their
impact on topics such as network neutrality, and how
they can be subverted. Further, our general algorithm
for identifying classiﬁcation rules can facilitate auditing
and analysis of future middleboxes and their policies by
users, policymakers, and regulators. Our key contribu-
tions follow.
First, we develop a general methodology for identify-
ing the matching rules used by a classiﬁer. To address
the potential combinatorial explosion of tests required
to uncover them, we propose the notion of Franken-
Flows, i.e., ﬂows combining features of multiple, dif-
ferent packet traces generated by applications that are
239subject to classiﬁcation. Doing so allows us to focus
only on traﬃc that is likely to trigger matching rules.
Second, we conduct a detailed study of the classiﬁca-
tion rules used by devices in a controlled setting and in
the wild. These include a carrier-grade packet shaper
and an IPS device in our lab, as well as a third sys-
tem that enforces T-Mobile’s BingeOn service. Through
traﬃc-replay and analysis, we ﬁnd that the devices all
analyze a small number of TCP, HTTP, and TLS ﬁelds
(e.g., Host and SNI) to classify network traﬃc in our
test suite, and do not use a ﬁxed set of ports and IP
addresses.
Third, we ﬁnd that the devices use simple text-based
matching in HTTP and TLS ﬁelds,
indicating that
their accuracy is limited by the speciﬁcity of the string-
matching patterns that they use to match in HTTP
headers or TLS handshakes. We show that these strings
can lead to misclassiﬁcation, both in terms of false pos-
itives and false negatives.
Fourth, we ﬁnd that the devices exhibit a “match-
and-forget” policy where an entire ﬂow is classiﬁed by
the ﬁrst rule that matches, even if later packets match a
diﬀerent rule that would lead to more accurate classiﬁ-
cation. Further, when keywords for multiple classes ap-
pear in the same ﬁeld in the same packet (e.g., the Host
header contains facebook.youtube.com), the devices
assign it to a single class using deterministic matching-
rule priorities. These simple matching priorities are eas-
ily exploited to allow one class of traﬃc to masquerade
as another and thus evade or subvert network policies.
2. METHODOLOGY
Our approach for identifying middlebox classiﬁcation
rules is to use a device under our control as ground truth
for developing and validating our detection methodol-
ogy, then to use our methodology to study other middle-
boxes. Similar to our previous work [9], we use an air-
gapped testbed consisting of a client, server, and a mid-
dlebox between them (Fig. 1). In contrast to our prior
work, which focused on identifying when diﬀerentiation
occurs (e.g., shaping), this study focuses on identifying
precisely what content in network traﬃc triggers clas-
siﬁcation that may lead to diﬀerentiation. The server
also spoofs as an Internet gateway, allowing us to use
arbitrary IP addresses in our traﬃc and capture all com-
munication from all devices in the testbed.
The middleboxes in our possession allow us to log
in, but do not reveal the exact classiﬁcation rules that
they use. However, we can access a user interface that
indicates in real time the class of traﬃc for each ﬂow
that traverses it. This allows us to test hypotheses for
classiﬁcation rules, by sending carefully crafted traﬃc
through the device to see how it is classiﬁed.
A na¨ıve approach to hypothesis testing is to try ev-
ery combination of packet sizes and packet payloads to
determine which ones trigger classiﬁcation. However,
Figure 1: Testbed for controlled experiments with classi-
ﬁers.
this is infeasible due to combinatorial explosion in the
number of tests required to complete the analysis.
Instead, we leverage the fact that 1) a set of tar-
geted applications potentially detected by the device
is known a priori,1 and 2) application-generated traf-
ﬁc already contains content that triggers rules. Using
the ﬁrst observation, we focus only on traﬃc from ap-
plications that are likely to be classiﬁed. The second
observation allows us to use application-generated traf-
ﬁc as baseline that we then modify to eﬃciently search
for the exact properties that trigger classiﬁcation. Note
that this approach extends to devices in our testbed and
those in the wild, so long as we have both the network
traﬃc trace to test, and a way to tell that traﬃc has
been classiﬁed (e.g., rate limiting or zero-rating).
2.1 Dataset
Our approach requires us
to send application-
generated traﬃc through our testbed. While this may
sound trivial, most interesting applications are closed-
source and often require interaction with third-party
servers to run; as a result, they cannot run in our air-
gapped testbed. Instead, we use the record/replay sys-
tem developed by Molavi et al. [9], which allows us to
replay arbitrary network traces gathered from applica-
tions outside our testbed.
To obtain a set of applications representative of those
users interact with, we leverage data from the ReCon
project [15], which boasts more than 300 users of iOS
and Android devices.2 This provides us with 1,179,618
HTTP GET requests, in which there are 20,129 unique
host headers, 8,701 unique User-Agent strings, and 685
distinct Content-Type headers [1]. We also extracted
1,727 unique Server Name Indication (SNI) ﬁelds from
51,985 HTTPS TLS handshakes.
Note that we only collect TCP traﬃc in our dataset,
as the vast majority of ﬂows and applications in our
dataset use HTTP/S. Understanding UDP-based clas-
siﬁcation is part of ongoing work.
2.2 Identifying Matching Fields
The ﬁrst step in understanding matching rules is de-
termining which portions of network ﬂows contain con-
tent that matches. Instead of permuting each bit in a
1In our testbed, we have ground truth information about all appli-
cations the device claims to identify. Outside of our testbed, the
applications may be ones that an ISP publicly admits to target-
ing (e.g., T-Mobile’s Binge On) or those that an observer simply
suspects are targeted.
2This data is collected as part of ReCon’s IRB-approved study.
Replay clientReplay serverTrafﬁc classiﬁerRouterGatewayClassiﬁcation results240network ﬂow to observe its eﬀect on classiﬁcation, we
take a more eﬃcient approach that exploits the fact that
our recorded traﬃc already matches rules.
In the base case (nothing is known about matching
rules), we conduct a binary search where we replace half
of the ﬂow with random bytes and observe its eﬀect on
classiﬁcation. Our assumption is that random bytes
are very unlikely to match any classiﬁcation rules.3 If
the traﬃc is no longer classiﬁed as the recorded appli-
cation, we then identify a more speciﬁc region in which
the method will be applied on—namely, the half of bytes
that triggered the change. To do this, we ﬁrst revert the
bytes in that region back to their original content, then
repeat the process of changing one half of the bytes at
a time in that region. If both halves triggered a change,
then we identify both halves as triggering the matching
rules. Once we identify portions of network ﬂows that
trigger matching rules, we conduct more extensive tests
by modifying each byte of a packet, one at a time, until
we ﬁnd the set of bytes that aﬀect classiﬁcation. These
bytes comprise the ﬁeld(s) used for matching. We
intentionally avoid exhaustively evaluating all combi-
nations of bits, as this is combinatorially infeasible to
test at scale and is not the goal of our study.
Using this approach, we found that our packet-
shaping device uses HTTP and TLS-handshake ﬁelds
in their matching rules, and only for the ﬁrst packet in
each direction.4 With this observation, we can more ef-
ﬁciently identify matching ﬁelds by using the known
structure of HTTP and TLS packets and permuting
only the corresponding ﬁelds. For example, when run-
ning this test on Netﬂix traﬃc, we ﬁnd that the Host
header triggers classiﬁcation. For Pandora, we ﬁnd that
the User-Agent ﬁeld is used. In addition, we omit any
portion of network traﬃc that does not trigger classiﬁ-
cation, leading to substantially shorter replays.
2.3 Revealing Classiﬁcation Rules
After identifying regions of network traﬃc that trig-
ger matching rules, our next step is identifying the spe-
ciﬁc matching rule. For this work, we assume that
matching rules take the form of regular expressions.
While matching rules in general could be arbitrary and
not based on text, our extensive analysis of three devices
found no counterexamples to our assumption. Without
loss of generality, we make an additional simplifying as-
sumption that matching rules take the form of one or
more basic regular expressions. While we could adapt
our methodology to reveal more complex and diverse
matching rules, we found no need to based on the three
devices we tested with HTTP/S traﬃc.
3We validated this assumption by running 1,000 ﬂows, each with
diﬀerent random bytes (from 100 to 1000 bytes) on port 80, all
of which were classiﬁed as the same generic “HTTP” class.
4To validate this, we tried splitting the ﬁrst packet into two pack-
ets, each with diﬀerent subsets of bytes, and found that only the
ﬁrst packet was ever used for classiﬁcation.
Algorithm 1 Isolating ﬁelds used in matching rules.