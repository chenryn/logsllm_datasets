title:CASTLE: CA signing in a touch-less environment
author:Stephanos Matsumoto and
Samuel Steffen and
Adrian Perrig
CASTLE: CA Signing in a Touch-Less Environment
Stephanos Matsumoto†‡
Samuel Steffen‡
Adrian Perrig‡
PI:EMAIL
PI:EMAIL
PI:EMAIL
†Carnegie Mellon University
Pittsburgh, PA, USA
‡ETH Zurich
Zurich, Switzerland
ABSTRACT
With the emergence of secure network protocols that rely on public-
key certiﬁcation, such as DNSSEC, BGPSEC, and future Internet
architectures, ISPs and domain administrators not specialized in
certiﬁcation have been thrust into certiﬁcate-signing roles. These
so-called conscripted CAs sign a low volume of certiﬁcates, but still
face the same challenges that plague modern CAs: private signing
key security, administrator authentication, and personnel and key
management. We propose CA Signing in a Touch-Less Environ-
ment (CASTLE), an air-gapped and completely touchless system to
enable low-volume, high-security certiﬁcate signing in conscripted
CAs. We demonstrate that CASTLE’s layered, defense-in-depth
approach is technically and practically feasible, and that CASTLE
empowers conscripted CAs to overcome challenges that even pro-
fessional CAs struggle with.
1.
INTRODUCTION
Public-Key Infrastructures (PKIs) in the current Internet provide
certiﬁcates, which bind public keys to information such as DNS
names, routing identiﬁers, or organizational identities. These cer-
tiﬁcates are issued by Certiﬁcate Authorities (CAs), whose public
keys are known and trusted by their relying parties. CAs are re-
sponsible for issuing certiﬁcates with the correct information and
for protecting their private signing keys.
While most CAs operate as business entities dedicated to certiﬁ-
cate issuance and maintenance, they are not the only entities that
issue certiﬁcates. For example, corporations use internal CAs and
certiﬁcates as part of an enterprise PKI. In some future Internet ar-
chitectures, ISPs and domains have CA responsibilities thrust upon
them [10, 16, 24]. Finally, technologies such as DNS Security Ex-
tensions (DNSSEC) are causing entities such as the operators of
ccTLDs to take on CA roles. Like full-time CAs, these conscripted
CAs sign certiﬁcates, but at a much lower volume than dedicated
CAs.
Moreover, even traditional CAs, who specialize in the business
of signing certiﬁcates, face operational challenges in their signature
process. In 2013, TURKTRUST accidentally issued several certiﬁ-
cates that endowed the holders with CA authority, allowing those
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
ACSAC ’16, December 05 - 09, 2016, Los Angeles, CA, USA
c(cid:2) 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ISBN 978-1-4503-4771-6/16/12. . . $15.00
DOI: http://dx.doi.org/10.1145/2991079.2991115
certiﬁcate holders to issue fraudulent certiﬁcates for Google [13].
In 2015, Symantec (the largest CA today) issued unauthorized cer-
tiﬁcates for organizations such as Google and Opera for test pur-
poses without the knowledge of these organizations [22]. These
CAs are thus failing to carefully check the certiﬁcates that they are
issuing.
The storage of private signing keys is also a challenge, even for
traditional CAs. Virtually all CAs protect their private signing keys
through the use of Hardware Security Modules (HSMs), leveraging
hardware-based protection to prevent the private key from falling
into the wrong hands. They are used to protect high-value keys such
as the DNSSEC root key [3, 21]. However, HSMs are not a cure-all
solution for private key storage, as they can be circumvented by ex-
ploiting misconﬁgurations or software ﬂaws, or by compromising
authentication that enables HSM functionality [9, 23]. CA-grade
HSMs can also cost upwards of tens of thousands of dollars [21],
and create vendor lock-in due to proprietary, closed-source tech-
nologies that make switching to a new solution difﬁcult.
Another challenge is the protection of the private signing keys
against potentially malicious administrators, who may attempt to
use these keys for nefarious purposes. For example, in 2015, a
Chinese CA’s private signing key was installed in a proxy, allowing
the proxy to sign arbitrary certiﬁcates and mount on-the-ﬂy man-
in-the-middle (MitM) attacks [14]. While there may be legitimate
reasons to allow administrator access to the private key storage,
such as to back up or update the private key, we observe the need
to enable useful management without unnecessarily exposing the
private key to possibly adversarial administrators.
These challenges motivate the core questions of this paper. How
can we encourage conscripted CAs to carefully check the certiﬁ-
cates they sign? How can we protect the private keys used for sign-
ing certiﬁcates? How can we simplify management functions such
as private key backup for these entities? Most importantly, if tradi-
tional CAs struggle to perform these operations securely, how can
we make it easier for these non-specialized entities to do so?
In addressing the above questions, we speciﬁcally focus on con-
scripted CA organizations, which we characterize as having four
important attributes: (1) a lack of specialized operations and ad-
ministrators for CA functions, (2) a low issuance volume (on the
order of one per week), (3) a reluctance to HSMs due to cost and
vendor lock-in concerns, and (4) facilities and infrastructure to sup-
port physical security. To our knowledge, no current solution is
well-suited to this class of CAs.
To address the problems of securing certiﬁcate signatures, pri-
vate key storage, and key management in conscripted CAs, we
propose CA Signing in a Touch-Less Environment (CASTLE), a
CA signing system aimed at entities that sign a low volume of
certiﬁcates. CASTLE leverages trusted computing on commodity
546hardware, highly restricted input/output (I/O) channels, and multi-
administrator management protocols.
CASTLE takes a layered, defense-in-depth approach to secur-
ing certiﬁcate signing. The signing machine leverages a trusted
platform module (TPM) to protect the private keys from the un-
trusted OS. Moreover, the signing machine is air-gapped, encased
in a glass box, and completely touchless to thwart physical tamper-
ing. The signing protocol itself authenticates administrators via a
PIN on a mobile device and strong one-time authentication proto-
cols that prevent adversaries from authorizing certiﬁcate signatures
Finally, a threshold protocol secures logging, key backup, and ad-
ministrator management.
In summary, we make the following contributions:
• We design a CA application that leverages trusted comput-
ing, physical isolation, strong authentication, and distributed
management to hinder adversaries.
• We develop protocols for logging, log auditing, key backup
and rollover, and administrator management, secured by a
quorum of honest administrators.
• We implement and analyze a proof-of-concept prototype of
CASTLE and demonstrate that our system is both technically
and practically viable.
2. BACKGROUND
In this section, we provide a brief overview on trusted comput-
ing, with a particular emphasis on the Flicker trusted computing
infrastructure used in CASTLE.
The goal of trusted computing is to enable the veriﬁcation of
software that has executed on a machine. It enables “trusted” pieces
of software to prove their integrity to a local or remote veriﬁer, a
process called attestation. Trusted computing also allows trusted
software to make use of sealed storage, encrypting data such that
only the same software can decrypt the data.
Trusted computing can be implemented based on the trusted plat-
form module (TPM) [1], a commodity chip present in many sys-
tems. In particular, the TPM maintains a set of platform conﬁgu-
ration registers (PCRs), which store information of what code the
system has loaded and executed. Before the CPU executes code,
the TPM ﬁrst measures or hashes the code, and then extends the
code into a PCR by hashing the current contents of the PCR along
with the measurement of the code. A PCR thus represents a chain
of measurements.
Such a chain can be used in the trusted boot process [1], which
leverages the BIOS as a static root of trust. Beginning with the
BIOS, each module measures the next module in the boot process
and extends it into the PCR to create a proof of what modules have
been loaded and executed. By contrast, a dynamic root of trust
provides a special CPU instruction to clear a set of PCRs and a
extend particular code block (called the secure loader block (SLB)
in Intel TXT [5]) into a PCR, allowing the late launch of code that
can be veriﬁed without measuring the entire boot process.
A TPM can also make use of sealed storage, in which it encrypts
data using a public key such that it can only be decrypted if the PCR
conﬁguration matches given values. The corresponding private key
used for decryption never leaves the TPM. Sealing data can be used
to make data accessible only to a trusted application. A TPM also
has a small amount of non-volatile RAM (NVRAM), which can be
used to store data on the TPM itself while protecting the data from
applications with incorrect PCR values.
The Intel Software Guard Extensions (SGX) [8] are a relatively
new technology in trusted computing allowing the creation of en-
claves, a region of memory containing private data and/or code.
These enclaves are created by a special CPU instruction, and their
run-time memory is encrypted and integrity-protected. The CPU
protects the data and execution of an enclave from the operating
system and privileged processes such as a hypervisor, as well as
from direct memory accesses. At the moment, SGX is a relatively
new technology and only available on a limited subset of Intel pro-
cessors. However, we envision using SGX in upcoming versions of
CASTLE.
Flicker [15] is a trusted execution infrastructure that can execute
small blocks of code called Pieces of Application Logic (PALs) in
late-launch sessions. While executing a Flicker session, the OS is
suspended to isolate the PAL from the OS and other applications.
The attestation process allows veriﬁcation of a PAL’s integrity after
a Flicker session. All memory used by the PAL is erased after a
session and an all-zeroes hash is extended into the PCRs to prevent
the data from being accessed further. The PAL output is transferred
to the application that called the session.
The PAL is highly restricted in its operation. For example it
cannot access any I/O devices (except a serial port for debugging)
and cannot make use of dynamically linked libraries. However, by
assembling all the security-critical logic of an application into a
Flicker PAL, the trusted computing base (TCB) of a system can be
minimized. In order to keep the TCB of CASTLE small, we make
use of Flicker in the system architecture.
3. PROBLEM DEFINITION
In this paper, we address the problem of providing a secure CA
signing solution for low-volume conscripted CAs for whom certiﬁ-
cate signing is not a primary business. In this section, we deﬁne the
problem in detail, including the desired properties and our adver-
sary model.
3.1 Desired Properties
The primary function of our system is to sign certiﬁcates.
In
doing so, the system must authenticate administrators and generate
signatures on certiﬁcates deemed to be authorized by an adminis-
trator. A secondary function of our system is to provide additional
functions to manage the system operation. These functions include
initializing the system, enrolling or removing administrators, log-
ging past actions such as processed Certiﬁcate Signing Requests
(CSRs), and backing up and restoring system information.
In providing the above functions, we aim to achieve several prop-
erties in our system:
1. Security. An adversary as described below cannot obtain an
unauthorized certiﬁcate.
2. Efﬁciency. Interactions with the signer machine (in particu-
lar, the number of messages sent) should be minimal.
3. Auditability. All system actions should be logged. The log
should be reviewable by those auditing the system, and be
resistant to tampering.
4. Cost-effectiveness. The system should be of minimal cost;
in particular, the cost should be at the level of a commodity
PC system.
3.2 Assumptions and Adversary Model
Our adversary’s goal is to undetectably obtain an unauthorized
signature on a certiﬁcate. The adversary may attempt to achieve
this goal by gaining access to the private signing key, compromis-
ing the certiﬁcate issuance process itself, or by leveraging one or
more malicious administrators.
We assume that the adversary can control up to k − 1 out of m
administrators or their personal veriﬁer devices during a certiﬁcate
signing session. The adversary can also control all components of
the signing machine, (including the operating system and applica-
547Management
Authentication
Isolation
Hardware
(TPM)
Administrators
Verifiers
. . .
. . .
(secure facilities, touchless signer)
(certificate signature process)
(logging, add/remove admins, backup/restore)
Figure 1: Defense-in-depth layers of CASTLE.
tions) except the CPU, TPM, the LPC bus connecting the CPU and
TPM, and the memory bus on the signing machine. For manage-
ment functions such as adding administrators, we assume that the
adversary can control at most u− 1 administrators or veriﬁer de-
vices (where u ≥ k), as well as the signing machine as described
above.
In both scenarios, the compromised veriﬁer devices can
send or display arbitrary information during operation, and com-
promised administrators can carry out the protocol steps incorrectly
and use their administrator credentials to the adversary’s goal.
We assume that the adversary cannot break cryptographic prim-
itives, i.e., public or symmetric-key cryptography or cryptographic
hash functions, and that the software libraries, in particular, those
used for processing QR codes and certiﬁcates, are free of exploitable
bugs. We also assume that software updates are not necessary for
the air-gapped component of our system.
We further assume that the conscripted CA has the means to
provide and enforce physical security measures, such as security
guards, surveillance cameras, restricted areas, and employee access
codes. Because even conscripted CAs have facilities and resources
to physically protect (particularly in enterprise environments), such
as access-controlled server rooms, we ﬁnd our assumptions regard-
ing physical security to be realizable in practice.
4. CASTLE ARCHITECTURE
We now provide an overview of the CASTLE architecture. We
begin by describing our multi-layer approach to securing certiﬁcate
signatures and our architectural components. We then describe how
the design of CASTLE provides security at each layer.
4.1 Security Layers
To secure certiﬁcate signing, CASTLE employs a four-layer de-
fense (shown in Figure 1) as follows:
1. The hardware layer protects sensitive data such as the pri-
vate signing key on the signing machine even from an ad-
versary who may have compromised the machine itself. This
layer consists of the TPM and hardware security mechanisms
for the CPU.
2. The isolation layer protects the signing machine from be-
ing tampered with, both physically and at the software level.
This layer consists of several forms of isolation, including
the use of touchless input, air gapping, and secure physical
facilities.
3. The authentication layer prevents the signing machine from
generating signatures without the necessary authentication
and authorization. This layer consists of the certiﬁcate sig-
nature process, described in more detail in Section 5.
Signer
Webcam/Monitor
Front end
application
OS
Disk
PAL
Flicker core
Sealed system data
(e.g. private signing key)
TPM
CPU/chipset
Figure 2: CASTLE architecture. The TCB is shown in gray and
in the signer is bounded by dashed lines. Gray stripes indicate
partially-trusted entities.
4. The management layer protects management functions, en-
suring that adversaries cannot enroll themselves as adminis-
trators or gain access to private keys via the backup process.
This layer consists of the log and the protocols for manage-
ment operations, described in more detail in Section 6.
4.2 Architectural Components
As Figure 2 shows, the CASTLE architecture includes adminis-
trators, veriﬁers, and a signer machine.
An administrator interacts with CASTLE’s devices in order to
authenticate to the signer (see below) and authorize the signature of
a certiﬁcate. Administrators also interact with each other to carry
out management functions. Each administrator has a unique index
i in the set of administrators and a public key Ki.