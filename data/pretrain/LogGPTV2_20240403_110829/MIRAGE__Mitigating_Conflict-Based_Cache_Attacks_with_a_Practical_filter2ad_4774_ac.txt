4.3 Analytical Model for Bucket Spills
To estimate the probability of bucket spills analytically, we
start by modeling the behavior of our buckets and balls system
in a spill-free scenario (assuming unlimited capacity buckets).
We model the bucket-state, i.e. the number of balls in a bucket,
as a Birth-Death chain [27], a type of Markov chain where
the state-variable (number of balls in a bucket) only increases
or decreases by 1 at a time due to birth or death events (ball
insertion or deletions), as shown in Figure 8.
We use a classic result for Birth-Death chains, that in the
steady-state, the probability of each state converges to a steady
value and the net rate of conversion between any two states
becomes zero. Applying this result to our model in Figure 8,
we can equate the probability of a bucket with N balls tran-
sitioning to N+1 balls and vice-versa to get Equation 1. The
terminology used in our model is shown in Table 3.
To calculate Pr (N + 1 → N), we note that a bucket with
N+1 balls transitions to N balls only on a ball removal. As
a random ball is selected for removal from all the balls, the
probability that a ball in a bucket with N + 1 balls is selected
for removal equals the fraction of balls in such buckets. If the
number of buckets equals Btot and the number of balls is btot,
the probability of a bucket with N + 1 balls losing a ball (i.e.
the fraction of balls in such buckets), is given by Equation 3.
Pr (n = N + 1)∗ Btot ∗ (N + 1)
Pr (N + 1 → N) =
Combining Equation 1, 2, and 3, and placing Btot /btot =
1/8, (the number of buckets/balls) we get the probability of a
bucket with N+1 balls, as given by Equations 4 and 5.
btot
(3)
Pr(n=N +1)=
8
N +1 ∗
=
8
N +1 ∗
(cid:18)
2
Pr(n=N)
(cid:19) (4)
(cid:19) (5)
(cid:18)
+2∗Pr(n=N)∗Pr(n>N)
2
+2∗Pr(n=N)
Pr(n=N)
−2∗Pr(n=N)∗Pr(n≤N)
USENIX Association
30th USENIX Security Symposium    1385
 N balls N + 1balls N - 1balls N + 2ballsPr(N+1→N)Pr(N→N+1)As n grows, Pr (n = N) → 0 and Pr (n > N) (cid:28) Pr (n = N)
given our empirical observation that these probabilities reduce
super-exponentially. Using these conditions Equation 4 can
be simpliﬁed to Equation 6 for larger n.
Pr (n = N + 1) =
8
N + 1 ∗ Pr (n = N)
2
(6)
From our simulation of 10 trillion balls, we obtain proba-
bility of a bucket with no balls as Probs (n = 0) = 4× 10−6.
Using this value in Equation 5, we recursively calculate
Prest (n = N + 1) for N ∈ [1,10] and then use Equation 6 for
N ∈ [11,14], when the probabilities become less than 0.01.
Figure 9 shows the empirically observed (Probs) and analyti-
cally estimated (Prest) probability of a bucket having N balls.
Prest matches Probs for all available data-points.
Figure 9: Probability of a Bucket having N balls – Estimated
analytically (Prest) and Observed (Probs)
Figure 9 shows that the probability of a set having N lines
decreases double-exponentially beyond 8 lines per set (the
average number of data-lines per set). For N = 13 / 14 / 15,
the probability reaches 10−9 / 10−17 / 10−35. This behavior
is due to two reasons – (a) for a set to get to N+1 lines, a
new line must map to two sets with at least N lines; (b) a
set with a higher number of lines is more likely lose a line
due to random global eviction. Using these probabilities, we
estimate the frequency of SAE in the next section.
4.4 Analytical Results for Frequency of Spills
For a bucket of capacity W, the spill-probability (without
relocation) is the probability that a bucket with W balls
gets to W + 1 balls. By setting N = W in Equation 2 and
Pr (n > W ) = 0, we get the spill-probability as Equation 7.
2
Prspill = Pr (W → W + 1) = Pr (n = W )
(7)
Figure 10 shows the frequency of bucket-spills (SAE) esti-
mated by using Prest (n = W ), from Figure 9, in Equation 7.
The estimated values (Balls/Spillest) closely match the empir-
ically observed values (Balls/Spillobs) from Section 4.2. As
the number of tags per set, i.e. bucket-capacity (W ) increases,
the rate of SAE, i.e. the frequency of bucket-spills shows
Figure 10: Frequency of bucket-spill, as bucket-capacity
varies – both analytically estimated (Balls/Spillest) and empir-
ically observed (Balls/Spillobs) results are shown.
a double-exponential reduction (which means the exponent
itself is increasing exponentially). The probability of a spill
with x extra ways is of the form P(2x); therefore with 5-6 extra
ways, we get an extremely small probability of spill as the
exponent term reaches 32 – 64. For W = 12 / 13 / 14, an SAE
occurs every 108 / 1016 / 1034 line installs. Thus, the default
Mirage design with 14-ways per set, with a rate of one SAE in
1034 line installs (i.e. once in 1017 years), effectively provides
the security of a fully associative cache.
5 Protecting against Shared-Memory Attacks
Thus far, we have focused primarily on attacks that cause
eviction via set conﬂicts and without any shared data be-
tween the victim and the attacker. If there is shared-memory
between the victim and the attacker, attacks such as Flush
+Reload [63], Flush+Flush [19], Invalidate+Transfer [23],
Flush+Prefetch [18], Thrash+Reload [46], Evict+Reload [20],
etc. are possible, where an attacker evicts the shared line from
the cache using clﬂush instruction or cache-thrashing [46]
or by accessing the line’s eviction-set [20], and issues sub-
sequent loads or ﬂushes [19] to the line while measuring its
latency to monitor victim accesses to that line. We describe
how Mirage is protected against these attacks based on the
type of shared memory being attacked.
Shared Read-only Memory: Attacks on shared read-only
memory addresses are prevented in Mirage by placing dis-
trusting programs (victim and attacker) in different security
domains and maintaining duplicate copies of shared lines in
the cache for each security domain. Such duplication ensures
that a load on a shared-address from one domain does not
hit on the copy of another domain (similarly ﬂush from one
domain does not evict another’s copy) and has been used in
several prior secure cache works [12, 26, 57]. For example,
Scatter-Cache (SCv1) [57] uses Security-Domain-ID (SDID)
concatenated with the physical line-address as input to the set
index derivation function (IDF), allowing a shared address to
map to different sets for different domains and get duplicated.
Mirage uses an IDF construction identical to Scatter-Cache
SCv1 and similarly duplicates shared lines across domains.
1386    30th USENIX Security Symposium
USENIX Association
0246810121416Number of Balls (N) in a Bucket10010−510−1010−1510−2010−2510−3010−35Pr.(Bucket with N balls)PrestProbs89101112131415Bucket Capacity (W)100105101010151020102510301035Ball Throws Per SpillBalls/SpillestBalls/SpillobsHowever, we observe that relying on the IDF to create du-
plicate copies has a weakness: it can allow a shared-memory
address in two different SDIDs to map to the same set in
a skew with a small probability (1/number-o f -sets), which
can result in a single copy of the line. To guarantee duplicate
copies of a line across domains even in this scenario, Mirage
stores the SDID of the domain installing the line along with
the tag of the line, so that a load (or a ﬂush) of a domain hits
on (or evicts) a cache line only if the SDID matches along
with the tag-match. Mirage stores 8-bit SDID supporting up
to 256 security domains (similar to DAWG [26]), which adds
<3% LLC storage overhead; however more or fewer SDID
can be supported without any limitations in Mirage.
Shared Writable Memory: It is infeasible to duplicate
shared writeable memory across domains, as such a design
is incompatible with cache-coherence protocols [26, 57]. To
avoid attacks on such memory, we require that writable shared-
memory is not used for any sensitive computations and only
used for data-transfers incapable of leaking information.
6 Discussion
6.1 Requirements on Randomizing Function
The randomizing function used to map addresses to cache
sets in each skew is critical in ensuring balanced availability
of invalid tags across sets and eliminating SAE. We use a
cryptographic function (computed with a secret key in hard-
ware), so that an adversary cannot arbitrarily target speciﬁc
sets. This is also robust to shortcut attacks [37], which can
exploit vulnerabilities in the algorithm to deterministically
engineer collisions. Furthermore, the random-mapping for
each skew must be mutually independent to ensure effective
load-balancing and minimize naturally occurring collisions,
as required by power-of-2-choices hashing [33]. We satisfy
both requirements using a cryptographic hash function con-
structed using the PRINCE cipher, using separate keys for
each skew. Other ciphers and cryptographic hashes that satisfy
these requirements may also be used to implement Mirage.
6.2 Key Management in Mirage
The secret keys used in Mirage for the randomizing set-index
derivation function are stored in hardware and not visible to
any software including the OS. As no information about the
mapping function leaks in the absence of SAE in Mirage, by
default Mirage does not require continuous key-refreshes like
CEASER / CEASER-S [39, 40] or keys to be provisioned per
domain like Scatter-Cache [57]). We recommend that the keys
used in Mirage be generated at boot-time within the cache con-
troller (using a hardware-based secure pseudorandom number
generator), with the capability to refresh the keys in the event
of any key or mapping leakage. For example, all prior ran-
domized cache designs become vulnerable to conﬂict-based
attacks if the adversary guesses the key via brute-force (1 in
264 chance) or if the mappings leak via attacks unknown at
the time of designing the defense, as they have no means of
detecting such a breakdown in security. On the other hand,
Mirage has the capability to automatically detect a breach in
security via even hypothetical future attacks, as any subse-
quent conﬂict-based attack requires the orchestration of SAE,
which do not occur in Mirage under normal operation. If mul-
tiple SAE are encountered indicating that the mapping is no
longer secret, Mirage can adapt by transparently refreshing its
keys (followed by a cache ﬂush) to ensure continued security.
6.3 Security for Sliced LLC Designs
Recent Intel CPUs have LLCs that consist of multiple smaller
physical entities called slices (each a few MBs in size), with
separate tag-store and data-store structures for each slice. In
such designs, Mirage can be implemented at the granularity
of a slice (with per-slice keys) and can guarantee global evic-
tions within each slice. We analyzed the rate of SAE for an
implementation of Mirage per 2MB slice (2048 sets, as used
in Intel CPUs) with the tag-store per slice having 2 skews and
14-ways per skew and observed it to be one SAE in 2× 1017
years, whereas a monolithic 16MB Mirage provides a rate of
once in 5× 1017 years. Thus, both designs (monolithic and
per-slice) provide protection for a similar order of magnitude
(and well beyond the system lifetime).
6.4 Security as Baseline Associativity Varies
The rate of SAE strongly depends on the number of ways
provisioned in the tag-store. Table 4 shows the rate of SAE
for a 16MB LLC, as the baseline associativity varies from
8 ways – 32 ways. As the baseline associativity varies, with
just 1 extra way per skew, the different conﬁgurations have an
SAE every 13 – 14 installs. However, adding each extra way
squares the rate successively as per Equation 7. Following the
double-exponential curve of Figure 10, the rate of an SAE
goes beyond once in 1012 years (well beyond system lifetime)
for all three conﬁgurations within 5–6 extra ways.
Table 4: Cacheline installs Per SAE in Mirage as the baseline
associativity of the LLC tag-store varies
8-ways
LLC Associativity
1 extra way/skew
13 (< 20ns)
5 extra ways/skew 1021 (104 yrs)
6 extra ways/skew 1043 (1026 yrs)
16-ways (default)
32-ways
14 (< 20ns)
1016 (2 yrs)
1034 (1017 yrs)
14 (< 20ns)
1014 (3 days)
1029 (1012 yrs)
Implications for Other Cache Attacks
6.5
Replacement Policy Attacks: Reload+Refresh [11] attack
exploited the LLC replacement policy to inﬂuence eviction-
decisions within a set, and enable a side-channel stealth-
USENIX Association
30th USENIX Security Symposium    1387
ier than Prime+Probe or Flush+Reload. Mirage guarantees
global evictions with random replacement, that has no access-
dependent state. This ensures that an adversary cannot in-
ﬂuence the replacement decisions via its accesses, making
Mirage immune to any such replacement policy attacks.
Cache-Occupancy Attacks: Mirage prevents an adversary
that observes an eviction from gaining any information about
the address of an installed line. However, the fact that an
eviction occurred continues to be observable, similar to prior
works such as Scatter-Cache [57] and HybCache [12]. Conse-
quently, Mirage and these prior works, are vulnerable to at-
tacks that monitor the cache-occupancy of a victim by measur-
ing the number of evictions, like a recent attack [49] that used
cache-occupancy as a signature for website-ﬁngerprinting.
The only known way to effectively mitigate such attacks is
static partitioning of the cache space. In fact, Mirage can
potentially provide a substrate for global partitioning of the
data-store that is more efﬁcient than the current way/set parti-
tioning solutions to mitigate such attacks. We leave the study
extending Mirage to support global partitions for future work.
7 Mirage with Cuckoo-Relocation
The default design for Mirage consists of 6 extra ways / skew
(75% extra tags) that avoids SAE for well beyond the system
lifetime. If Mirage is implemented with fewer extra tags (e.g.
4 extra ways/skew or 50% extra tags), it can encounter SAE
as frequently as once in 0.16 seconds. To avoid an SAE even
if only 50% extra tags are provisioned in Mirage, we propose
an extension of Mirage that relocates conﬂicting lines to alter-
native sets in the other skew, much like Cuckoo Hashing [36].
We call this extension Cuckoo-Relocation.
7.1 Design of Cuckoo-Relocation
We explain the design of Cuckoo-Relocation using an ex-
ample shown in Figure 11. An SAE is required when an
incoming line (Line Z) gets mapped in both skews to sets that
have no invalid tags (Figure 11(a)). To avoid an SAE, we need
an invalid tag in either of these sets. To create such an invalid
tag, we randomly select a candidate line (Figure 11(b)) from
either of these sets and relocate it to its alternative location in
the other skew. If this candidate maps to a set with an invalid
tag in the other skew, the relocation leaves behind an invalid
tag in the original set, in which the line to be installed can
be accommodated without an SAE, as shown in Figure 11(c).
If the relocation fails as the alternative set is full, it can be
attempted again with successive candidates till a certain num-
ber of maximum tries, after which an SAE is incurred. For
Mirage with 50% extra tags, an SAE is infrequent even with-
out relocation (less than once in 100 million installs). So in
the scenario where an SAE is required, it is likely that other
sets have invalid tags and relocation succeeds.
Figure 11: Cuckoo Relocation, a technique to avoid an SAE
if Mirage is implemented with 50% extra tags.
7.2 Results: Impact of Relocation on SAE
For Mirage with 50% extra tags, the chance that a relocation
fails is approximately p = 1/sets per skew. This is because,
at the time of an SAE (happens once in 100 million installs),
it is likely that the only full sets are the ones that are currently
indexed (i.e. only 1 set per skew is full). For relocation to
fail for a candidate, the chance that its alternative set is full is
hence approximately p = 1/sets per skew. After n relocation
attempts, the chance that all relocation attempts fail and an
SAE is incurred, is approximately pn.
Table 5 shows the rate of SAE for Mirage with 50% extra