a(clf) =
is a(clf)
1
(cid:111)
2468102030405060708090100position of correct answerfraction of experiments [%]  SWLDAbLogRegbLogReg passive userrandom guess2468102030405060708090100position of correct answerfraction of experiments [%]  SWLDAbLogRegbLogReg passive userrandom guess24681012142030405060708090100position of correct answerfraction of experiments [%]  SWLDAbLogRegbLogReg passive userrandom guess246810122030405060708090100position of correct answerfraction of experiments [%]  SWLDAbLogRegbLogReg passive userrandom guess2468102030405060708090100position of correct answerfraction of experiments [%]  SWLDAbLogRegrandom guess2468102030405060708090100position of correct answerfraction of experiments [%]  SWLDAbLogRegbLogReg passive userrandom guessk ) := p(X = a(clf)
k |a(clf)) be the probability that
p(a(clf)
the classiﬁer ranks the correct answer at position k ∈ K.
Please note that the p(X = a(clf)
k ) that we will use are
empirical relative frequencies obtained from the exper-
iments instead of true probability distributions. Using
these probabilities, the empirical Shannon entropy is
H(X|a(clf)) = − K(cid:88)
(cid:16)
(cid:17)
p(a(clf)
k ) log2
p(a(clf)
k )
(5)
k=1
In case of the random attack, the position of the cor-
rect answer is uniformly distributed, which results in the
said entropy H(X|a(rand)) = log2(K).
In case of at-
tacking with a classiﬁer, the attacker would pick a1, the
answer ranked highest, to maximize his success. As our
empirical results, depicted in Figure 9, suggest, the rank-
ings are not fully reliable, i.e. the answer ranked highest
is not always the correct answer. However, the ranking
statistics provide a new non-uniform distribution over the
set of possible answers. For instance, we know that for
bLogReg the empirical probability that the ﬁrst-ranked
location is the correct one is p(X = a(bLogReg)
) = 0.2,
the probability of the second-ranked answer to be correct
is also p(X = a(bLogReg)
) = 0.2, and so on.
1
The redistributed success probabilities reduce the en-
tropy of the guessing experiment. We take the random
guess attack as the baseline and compare the entropies
of all other attacks against its entropy H(X|a(rand)). We
evaluate to what extent a generic classiﬁer clf reduces the
entropy relative to H(X|a(rand)). The relative reduction
of entropy with respect to the random guess attack (in %)
is then:
2
r(clf)
:= 100
= 100
(cid:18)
H(X|a(rand)) − H(X|a(clf))
H(X|a(rand))
1 − H(X|a(clf))
(cid:19)
log2(K)
(6)
A perfect classiﬁer always has the correct answer at
the ﬁrst position, resulting in zero entropy and a relative
reduction r of 100%. A poor classiﬁer provides a uni-
form distribution of the position of the correct rank. As a
consequence, its entropy would be maximal and the rel-
ative reduction r would be 0%. The entropy difference
directly measures the information leaked by an attack.
Thereby, comparing the classiﬁer entropies in a relative
way enables one to compare results over different exper-
iments with different numbers of possible answers.
We report the relative reduction of entropy for each
experimental setting and for each classiﬁer in Figure 10.
As one can see, the reduction approximately ranges from
15% to 40% for SWLDA and from 7% to 18% for the
two bLogReg variants. Please note that the plot does not
report the result of the classiﬁer that has been trained on
11
the people experiment for this very experiment, as this
entropy reduction merely refers to the training error of
the classiﬁer and provides no information on how well
the classiﬁer generalizes to unseen data.
Figure 10: Relative reduction of entropy with respect to
the random guess attack. The scale reaches from 0% (no
advantage over random guessing) to 100% (correct an-
swer always found). Please note that ’bLogReg, passive’
has been trained on the people experiment. We do not re-
port its score on this experiment, as it refers to the train-
ing error.
For most scenarios,
the information leaked corre-
sponds to approximately 10% to 20% for the best clas-
siﬁer SWLDA with peaks for maps (32%) and month
(43%). The average information leak over all classiﬁers
in the maps experiment stands out compared to the other
result. The reason for this is that the maps experiment is
a counting experiment, in which the users were asked to
count the number of occurrences of the target stimulus.
This experiment was included to underline the improve-
ment in accuracy with a cooperative user.
Using Prior Knowledge to Improve Accuracy For
some secrets there exist global statistics that can improve
the success chances of the attack. For instance, often the
distribution of customers of different banks in a popula-
tion is approximately known. Also there might be prior
knowledge about the area someone lives in. We did not
include such prior knowledge in our experiments. How-
ever, such information could improve both the random
guess as well as the classiﬁer guesses. Prior probabili-
ties could be included to Bayesian classiﬁers or could be
used for heuristically post-processing classiﬁer output.
For some experiments such as the PINs and the month
of birth, the possible answers are approximately uni-
formly distributed, such that prior knowledge would pro-
vide no information. For other experiments prior knowl-
edge might simply be unavailable and thus can not be
used for more sophisticated models.
01020304050mapspinatmdebitmonthpeopleReduction of entropy relative to random guess [%]  SWLDAbLogRegbLogreg, passive6 Related work
In this section, we overview related papers that use EEG
signals in security-relevant applications.
EEG-based identiﬁcation and authentication EEG
signal has successfully been used for user identiﬁcation
(selecting the user identity out of a set of identities) and
user authentication (verifying if a claimed user identity
is true).
In [30], the authors provide an overview of
cognitive biometrics, an emerging research area that in-
vestigates how different biosignals can be used for the
purpose of authentication and identiﬁcation. The au-
thors cover recent papers on biometrics based on EEG,
the electrocardiogram (ECG), and the skin conductance,
also called electrodermal response (EDR). An identiﬁ-
cation mechanism based on the alpha rhythm has been
proposed in [29]. The mechanism uses convex polygon
intersections to map new observations to a user iden-
tity. The authors report a high true positive rate of 95 %
and a true negative rate of 87 % for experiments on 79
users. In method proposed in [23] uses Gaussian mixture
models for user authentication. The authors test their
method with different authentication protocols and report
that with increasing temporal distance from the sign-up
phase, the accuracy degrades. Using a sign-up phase
over several days improves the accuracy.
In [36] the
authors describe pass-thoughts, another authentication
mechanism that instead of typing a password requires the
user to think of a password. The idea is very similar to
the conventional P300-Speller scenario we mentioned in
Section 2. A matrix containing characters is shown to a
user and he focuses on the characters required to spell
the password. This way, many shoulder-surﬁng attacks
could be avoided. The main drawback of this authenti-
cation method (also mentioned by the authors) is a very
low throughput rate of the spelling, which is ≈ 5 char-
acters per minute for the 90% accuracy. Another prob-
lem is that the user gets no feedback until the complete
passphrase is spelled, and hence the whole process must
be repeated if a single character is wrongly classiﬁed.
More recently, in [15], the authors introduce a key-
generation technique resistant against coercion attacks.
The idea is to incorporate the user’s emotional status
through skin conductance measurements into the cryp-
tographic key generation. This way, the generated keys
contain a dynamic component that can detect whether a
user is forced to grant an access to the system. Skin con-
ductance is used as an indicator of the person’s overall
arousal state, i.e., the skin conductance of the victim in
a stressful scenario signiﬁcantly changes compared to a
situation when the keys were generated.
Another highly related work to ours is described in
[37]. The authors exploit an ERP called N400 to detect
if a person is actively thinking about a certain stimuli
without explicitly looking at it. In contrast to the P300
which is related to attention, the N400 has been associ-
ated with semantic processing of words. For example,
in an experiment where subjects are shown incongruent
sentences like “I drink coffee with milk and socks”, the
amplitude of the N400 would be maximal at the last (in-
correct) word. This phenomenon is then used to detect
which out of several possible objects the user is actively
thinking of. While this paper is not focusing on security
issues but rather on assisting a user in efﬁcient search,
the N400 could serve as another attack vector for similar
attacks as those described in this work.
While all listed contributions support our belief that
such devices may be used in everyday tasks, they fol-
low an orthogonal approach by considering how to assist
users in various tasks like, for instance, authentication.
Contrary to that, our objective is to turn the table and
to demonstrate that such technology might create signif-
icant threats to the security and privacy of the users.
Guilty-Knowledge Test The most closely related
work on EEG signals addresses using P300 in lie de-
tection, particularly in the so-called Guilty-Knowledge
Test (GKT) [3]. The operating hypothesis of the GKT is
that familiar items will evoke different responses when
viewed in the context of similar unfamiliar items. It has
been shown that the P300 can be used as a discriminative
feature in detecting whether or not the relevant informa-
tion is stored in the subject’s memory. For this reason,
a GKT based on the P300 has a promising use within
interrogation protocols that enable detection of poten-
tial criminal details held by the suspect, although some
data suggest low detection rates [13]. In contrast, recent
GKT experiments based on the P300 have reported de-
tection accuracies as high as 86% [1]. Of course, as with
the polygraph-based GKT, the P300-GKT is vulnerable
to speciﬁc countermeasures, but to a much lesser extent
[33, 34].
Such applications in interrogation protocols have quite
a number of differences from our work. For instance, we
concentrate on consumer-grade devices that have con-
siderably lower signal-to-noise ratios, therefore are more
difﬁcult to analyze. The largest difference between our
approach and in the GTK is the attacker model. While
the GKT-interrogator has full control over the BCI user,
in that he can can attach high-precision electrodes in a
supportive way and force user to collaborate, our attacker
must use the low-cost gaming device selected and at-
tached by the user herself. This makes our attack consid-
erably harder. Moreover, while the GTK victim clearly
knows that she is interrogated and can prepare for that,
in our case the user does not know that she is attacked.
This might increase the validity of revealed information.
12
7 Discussion and Future Directions
In this section we discuss possible ways to defend against
the investigated attacks and describe potential future di-
rections.
Conscious Defenses Users of the BCI devices could
actively try to hinder probing by, for instance, concen-
trating on non-target stimuli. To give a concrete exam-
ple, users could count the number of occurrences of an
unfamiliar face in our people experiment. The effec-
tiveness of such defensive techniques has been tested in
the context of guilty knowledge tests, however, there is
no deﬁnitive conclusion on whether efforts to conceal
knowledge are effective [35] or ineffective [8]. It is im-
portant to notice that, as we mentioned before, our sce-
nario differs considerably from the GKT scenario. In our
case, we assume that the EEG application has control
of the user input for extended periods of time and that
it conceals the attack in the normal interaction with the
application. It would be difﬁcult to imagine a realistic
scenario in which a concerned user could try to conceal
information from the EEG application for extended peri-
ods of normal usage.
An alternative to limiting the scope of the attacks pre-
sented in this paper is not to expose the raw data from
EEG devices to third-party applications. In this model,
the EEG vendor would create a restricted API that could
only access certain features of the EEG signal. For ex-
ample, applications could be restricted to accessing only
movement related information (reﬂected in the spectral
power). On the other hand, this poses higher perfor-
mance demands on the device and limits the potential of
developing third-party software.
Another possible way to deal with leaking informa-
tion through the P300 signal would be adding noise to
the EEG raw data before making it available to the appli-
cations that must use it. However, it would be difﬁcult to
strike a balance between the security of such an approach
and the drawbacks in terms of decrease in accuracy of le-
gitimate applications.
Future Directions The overall success of these attacks
highly depends on the user’s attention to the stimuli.
Hence, there are still many open questions concerning
the trade-off between obtrusiveness (in order to increase
the user’s attention during the classiﬁcation task) and
concealment to avoid the discovery of the attacker’s true
intentions. As part of our future work we intend to ex-
plore this trade-off in more detail. Speciﬁcally, by ask-
ing what is the impact of an uncooperative user who at-
tempts to “lie” during the attack, e.g., similar to guilty-
knowledge test settings? How can these attacks be made
more stealthy, i.e., to what extent can they be integrated
into some benign everyday tasks, games, or videos? How
effective is the social engineering approach? For exam-
ple, by offering fake monetary awards or by simply con-
fusing the user (such as asking him to verify whether his
PIN is truly random and telling him to count the number
of the PIN occurrences).
8 Conclusion
The broad ﬁeld of possible applications and the techno-
logical progress of EEG-based BCI devices indicate that
their pervasiveness in our everyday lives will increase.
In this paper, we focus on the possibility of turning this
technology against the privacy of its users. We believe
that this is an important ﬁrst step in understanding the