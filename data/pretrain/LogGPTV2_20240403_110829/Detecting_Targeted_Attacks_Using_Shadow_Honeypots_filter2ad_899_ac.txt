use pmalloc() once for each previously-static buffer. Gen-
erally, however, this allocation needs to be done each time
the function is invoked.
Any overﬂow (or underﬂow) on a buffer allocated via
pmalloc() will cause the process to receive a Segmenta-
tion Violation (SEGV) signal, which is caught by a sig-
nal handler we have added to the source code in main().
The signal handler simply notiﬁes the operating system to
abort all state changes made by the process while process-
ing this request. To do this, we added a new system call
to the operating system, transaction(). This is condition-
ally (as directed by the shadow enable() macro) invoked
at three locations in the code:
• Inside the main processing loop, prior to the begin-
ning of handling of a new request, to indicate to the
operating system that a new transaction has begun.
The operating system makes a backup of all memory
page permissions, and marks all heap memory pages
as read-only. As the process executes and modiﬁes
these pages, the operating system maintains a copy
of the original page and allocates a new page (which
is given the permissions the original page had from
the backup) for the process to use, in exactly the
same way copy-on-write works in modern operating
system. Both copies of the page are maintained until
transaction() is called again, as we describe below.
This call to transaction() must be placed manually
by the programmer or system designer.
• Inside the main processing loop, immediately after
the end of handling a request, to indicate to the oper-
ating system that a transaction has successfully com-
pleted. The operating system then discards all origi-
nal copies of memory pages that have been modiﬁed
during processing this request. This call to transac-
tion() must also be placed manually.
• Inside the signal handler that is installed automati-
cally by our tool, to indicate to the operating system
that an exception (attack) has been detected. The
operating system then discards all modiﬁed memory
pages by restoring the original pages.
Although we have not implemented this, a similar
mechanism can be built around the ﬁlesystem by using a
private copy of the buffer cache for the process executing
in shadow mode. The only difﬁculty arises when the pro-
cess must itself communicate with another process while
servicing a request; unless the second process is also in-
cluded in the transaction deﬁnition (which may be impos-
sible, if it is a remote process on another system), overall
system state may change without the ability to roll it back.
For example, this may happen when a web server com-
municates with a remote back-end database. Our system
does not currently address this, i.e., we assume that any
such state changes are benign or irrelevant (e.g., a DNS
query). Speciﬁcally for the case of a back-end database,
these inherently support the concept of a transaction roll-
back, so it is possible to undo any changes.
The signal handler may also notify external logic to
indicate that an attack associated with a particular input
from a speciﬁc source has been detected. The external
USENIX Association
14th USENIX Security Symposium
135
logic may then instantiate a ﬁlter, either based on the net-
work source of the request or the contents of the pay-
load [52].
4 Experimental Evaluation
We have tested our shadow honeypot implementation
against a number of exploits, including a recent Mozilla
PNG bug and several Apache-speciﬁc exploits.
In this
section, we report on performance benchmarks that illus-
trate the efﬁcacy of our implementation.
First, we measure the cost of instantiating and op-
erating shadow instances of speciﬁc services using the
Apache web server and the Mozilla Firefox web browser.
Second, we evaluate the ﬁltering and anomaly detec-
tion components, and determine the throughput of the
IXP1200-based load balancer as well as the cost of run-
ning the detection heuristics. Third, we look at the false
positive rates and the trade-offs associated with detec-
tion performance. Based on these results, we determine
how to tune the anomaly detection heuristics in order to
increase detection performance while not exceeding the
budget alloted by the shadow services.
4.1 Performance of shadow services
Apache To determine the workload capacity of the
shadow honeypot environment, we used DYBOC on the
Apache web server, version 2.0.49. Apache was chosen
due to its popularity and source-code availability. Ba-
sic Apache functionality was tested, omitting additional
modules. The tests were conducted on a PC with a 2GHz
Intel P4 processor and 1GB of RAM, running Debian
Linux (2.6.5-1 kernel).
We used ApacheBench [4], a complete benchmarking
and regression testing suite. Examination of application
response is preferable to explicit measurements in the
case of complex systems, as we seek to understand the
effect on overall system performance.
Figure 7 illustrates the requests per second that Apache
can handle. There is a 20.1% overhead for the patched
version of Apache over the original, which is expected
since the majority of the patched buffers belong to utility
functions that are not heavily used. This result is an indi-
cation of the worst-case analysis, since all the protection
ﬂags were enabled; although the performance penalty is
high, it is not outright prohibitive for some applications.
For the instrumentation of a single buffer and a vulnera-
ble function that is invoked once per HTTP transaction,
the overhead is 1.18%.
Of further interest is the increase in memory require-
ments for the patched version. A naive implementation of
pmalloc() would require two additional memory pages for
each transformed buffer. Full transformation of Apache
translates into 297 buffers that are allocated with pmal-
loc(), adding an overhead of 2.3MB if all of these buffers
are invoked simultaneously during program execution.
When protecting malloc()’ed buffers, the amount of re-
quired memory can skyrocket.
To avoid this overhead, we use an mmap() based allo-
cator. The two guard pages are mmap’ed write-protected
from /dev/zero, without requiring additional physical
memory to be allocated.
Instead, the overhead of our
mechanism is 2 page-table entries (PTEs) per allocated
buffer, plus one ﬁle descriptor (for /dev/zero) per pro-
gram. As most modern processors use an MMU cache
for frequently used PTEs, and since the guard pages are
only accessed when a fault occurs, we expect their impact
on performance to be small.
Mozilla Firefox For the evaluation of the client case,
we used the Mozilla Firefox browser. For the initial vali-
dation tests, we back-ported the recently reported libpng
vulnerability [7] that enables arbitrary code execution if
Firefox (or any application using libpng) attempts to dis-
play a specially crafted PNG image. Interestingly, this ex-
ample mirrors a recent vulnerability of Internet Explorer,
and JPEG image handling [6], which again enabled ar-
bitrary code execution when displaying specially crafted
images.
In the tightly-coupled scenario, the protected version of
the application shares the address space with the unmodi-
ﬁed version. This is achieved by transforming the original
source code with our DYBOC tool. Suspicious requests
are tagged by the ADS so that they are processed by the
protected version of the code as discussed in Section 3.2.
For the loosely-coupled case, when the AD component
marks a request for processing on the shadow honeypot,
we launch the instrumented version of Firefox to replay
the request. The browser is conﬁgured to use a null X
server as provided by Xvfb. All requests are handled by
a transparent proxy that redirects these requests to an in-
ternal Web server. The Web server then responds with
the objects served by the original server, as captured in
the original session. The workload that the shadow hon-
eypot can process in the case of Firefox is determined by
how many responses per second a browser can process
and how many different browser versions can be checked.
Our measurements show that a single instance of Fire-
fox can handle about one request per second with restart-
ing after processing each response. Doing this only after
136
14th USENIX Security Symposium
USENIX Association
Figure 7: Apache benchmark results.
Figure 8: Normalized Mozilla Firefox benchmark results
using modiﬁed version of i-Bench.
detecting a successful attack improves the result to about
four requests per second. By restarting, we avoid the ac-
cumulation of various pop-ups and other side-effects. Un-
like the server scenario, instrumenting the browser does
not seem to have any signiﬁcant impact on performance.
If that was the case, we could have used the rollback
mechanism discussed previously to reduce the cost of
launching new instances of the browser.
We further evaluate the performance implications of
fully instrumenting a web browser.
These observa-
tions apply to both loosely-coupled and tightly-coupled
shadow honeypots. Web browsing performance was mea-
sured using a Mozilla Firefox 1.0 browser to run a bench-
mark based on the i-Bench benchmark suite [1]. i-Bench
is a comprehensive, cross-platform benchmark that tests
the performance and capability of Web clients. Speciﬁ-
cally, we use a variant of the benchmark that allows for
scrolling of a web page and uses cookies to store the load
times for each page. Scrolling is performed in order to
render the whole page, providing a pessimistic emula-
tion of a typical attack. The benchmark consists of a
sequence of 10 web pages containing a mix of text and
graphics; the benchmark was ran using both the scrolling
option and the standard page load mechanisms. For the
standard page load conﬁguration, the performance degra-
dation for instrumentation was 35%. For the scrolling
conﬁguration, where in addition to the page load time,
the time taken to scroll through the page is recorded, the
overhead was 50%. The results follow our intuition as
more calls to malloc are required to fully render the page.
Figure 8 illustrates the normalized performance results.
It should be noted that depending on the browser imple-
mentation (whether the entire page is rendered on page
load) mechanisms such at the automatic scrolling need to
be implemented in order to protected against targeted at-
tacks. Attackers may hide malicious code in unrendered
parts of a page or in javascript code activated by user-
guided pointer movement.
Popularity of different mozilla versions
)
s
t
s
e
u
q
e
R
(
y
t
i
r
a
u
p
o
P
l
 600000
 500000
 400000
 300000
 200000
 100000
 0
2
1
4
1
2
8
9
0
1
2
1
1
3
1
4
1
2
3
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
9
2
9
4
4
9
9
0
0
0
1
2
1
3
1
4
4
4
b
4
.
5
.
1
a
5
6
.
1
a
6
7
1
2
3
5
.
.
.
.
.
1
7
7
7
7
b
7
.
.
.
.
.
.
.
.
.
.
.
.
.
0
9
0
9
9
0
0
1
1
1
.
1
.
1
.
.
.
.
1
1
1
1
1
.
.
.
1
1
1
1
1
1
.
0
.
.
0
0
Mozilla version
2
a
8
3
a
8
4
a
8
5
a
8
6
a
8
.
.
.
.
.
1
1
1
1
1
b
8
.
1
Figure 9: Popularity of different Mozilla versions, as mea-
sured in the logs of CIS Department Web server at the Uni-
versity of Pennsylvania.
How many different browser versions would have to be
checked by the system? Figure 9 presents some statistics
concerning different browser versions of Mozilla. The