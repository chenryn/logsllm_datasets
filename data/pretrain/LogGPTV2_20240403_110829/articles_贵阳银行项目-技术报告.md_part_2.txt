    learning的分类器。
-   在线检测部分，对实时日志进行解析并提取特征，然后使用在离线学习部分学习到的日志分类器判断日志是否异常。其中，基于单词频率和位置构建词袋模型特征向量以及基于PU
    learning训练分类器如下所示：
![](media/image7.png){width="5.9375in" height="1.2708333333333333in"}
### 功能目标 {#功能目标 .样式-标题-3Heading-3-Char1Heading-3-Char-Char-Char-Char-Charh3-C...11}
## 建立贵阳银行全行数据统一采集和管理体系 {#建立贵阳银行全行数据统一采集和管理体系 .样式5}
将三类可观测性数据统一采集***，***通过三种形式的组合使用产生丰富的观察数据。
-   日志（Logging）：日志展现的是应用运行而产生的事件或者程序在执行的过程中产生的记录，日志可以详细解释系统的运行状态，但是存储和查询需要消耗大量的资源。
-   指标（Metrics）：指标是一种聚合数值，其存储空间小，便于观察系统的状态和趋势，但对于问题定位缺乏细节展示。这个时候使用多维数据结构能增强对于细节的表现力。例如统计一个服务的的平均耗时、请求量等。
-   链路跟踪（Tracing）：尽管日志记录了各个事件的细节，可在分布式系统中，日志仍旧存在不足之处。日志记录的事件是孤立的，但是在实际的分布式系统中，不同组件中发生的事件往往存在因果关系。链路跟踪解决了这一问题，通过SpanID等标记可重新构造出事件的完整事件链路以及因果关系。技术人员可以借此了解网格内服务的依赖和调用流程，构建整个网格的服务拓扑并轻松分析出请求中出现的异常点。
数据采集范围包括但不限于:
> 基础资源：包含云,主机,容器,网络,采集的对象包含指标(实时状态,多维统计),日志(运行日志,出错日志)；
>
> 中间件：包含数据库,消息队列,应用容器,存储,日志等,采集数据范围包括日志(运行日志,出错日志),指标(实时状态,多维统计),链路(延迟,通讯量,错误率,饱和度)；
>
> 前端组件：包含H5,ios,android,小程序等,采集范围包括指标(实时状态,多维统计),链路(延迟,通讯量,错误率,饱和度),日志(运行日志,出错日志)；
>
> 后端组件：包含java python nodejs c#
> go等,采集范围包括指标(实时状态,多维统计),链路(延迟,通讯量,错误率,饱和度),日志(运行日志,出错日志)。
>
> 数据统一采集后，使用统一的数据模型进行处理，然后存储在分析平台。
## 建立基于机器学习算法的集中式告警体系 {#建立基于机器学习算法的集中式告警体系 .样式5}
> 利用AI技术，自动将产生根本原因相同的告警合并为同一故障，自动分析出故障原因和影响，帮助用户快速解决问题
>
> 通过统一的数据模型构建拓扑图，通过算法在拓扑图上找出根因，自动将相同根本原因产生的告警合并一个故障，自动分析出故障原因和影响，帮助运维人员快速解决问题
> 。
## 建立全维度系统监控与分析机制 {#建立全维度系统监控与分析机制 .样式5}
## 从业务-服务\--设备\--指标四层维度对应用系统进行分析 {#从业务-服务--设备--指标四层维度对应用系统进行分析 .list-paragraph .样式5}
-   业务：从业务维度梳理系统当前状态，展示业务概况、业务详情，用户可以通过观察到的异常趋势深入探究业务详情，并通过业务拓扑图发现调用服务之间的关系与具体状态。业务拓扑同时支持历史回溯、服务详情、接口详情、查看具体异常请求等功能，帮助用户快速完成溯源分析。
-   服务：从服务维度梳理系统当前状态，从指标趋势和接口分析展示服务概况、服务详情，同时支持下钻到关联设备及调用链信息。
-   设备：蜂窝状视图让设备关键信息一目了然，点击详情进一步了解设备的相关信息、性能指标和相关服务。
-   调用链：提供链路追踪查询功能，用户可以使用业务，服务，接口，Local
    IP，Remote
    IP，traceID，耗时，请求结果等多种字段对调用链进行过滤。调用链详情展示每个请求的耗时，并能快速跳转至具体日志。
-   指标探索：用户无需使用SPL编程语言，利用分析区即可完成对指标时序数据的分析与可视化，支持聚合、时移及拆分，获得更深入的分析图表。
    通过全维度的数据汇总信息完成应用性能监控、基础设施监控、问题日志快速检索及指标探索等功能。
##  {#section-3 .list-paragraph .样式5}
### 非功能目标 {#非功能目标 .样式-标题-3Heading-3-Char1Heading-3-Char-Char-Char-Char-Charh3-C...11}
1.  *可灵活配置*
*可以通过灵活配置，调整业务处理流程，以适应业务需求的变化；也可以通过配置组合已有的业务实现过程，完成新提出的业务请求的处理。*
2.  便于扩展
系统提供的灵活方便的扩展接口，以便将来实现新的业务请求处理。对系统的扩展应尽可能的减小代码开发量。
3.  技术上开放、标准
采用标准的、开放的开发技术。
4.  性能上稳定、可靠、高效
系统能够保证实时交易和批量大数据处理同时处理，系统能实现，同时保证7\*24\*365不间断高效运转。
5.  负载均衡
采用索引集群和资源管理集群等技术，自动实现系统的负载均衡。
### 系统性能 {#系统性能 .样式-标题-3Heading-3-Char1Heading-3-Char-Char-Char-Char-Charh3-C...11}
### 通过系统上线以来运行情况的跟踪，系统运行稳定，性能良好，各项指标均已达到原来的设计目标，下面是对可观测性应用智能分析平台在大批量数据处理性能的情况的统计结果。 {#通过系统上线以来运行情况的跟踪系统运行稳定性能良好各项指标均已达到原来的设计目标下面是对可观测性应用智能分析平台在大批量数据处理性能的情况的统计结果 .list-paragraph .样式-标题-3Heading-3-Char1Heading-3-Char-Char-Char-Char-Charh3-C...11}
6.1 beaver存储服务器
系统资源占用随工作时间呈规律性变化，忙时主要分布在9:15-11:30和13:00-15:00,占用率大体在20%\~90%之间。对比各阶段上线后的资源占用情况，存储服务器资源占用没有发生明显变化，因此，当前配置能满足全国上线后的业务需求。
应用服务器：
三台应用服务器部署采用集群部署方式。
spl服务器的资源占用主要集中在9：00\~11：00，以及14：00\~17：00，CPU占用率在20%以下，峰值时（10：00左右）可达90%
。
logriver服务器的资源占用主要集中在9：00\~11：00，以及14：00\~17：00，CPU占用率在10%\~20%左右
。
6.2 指标训练与检测能力
  20210601\~20210701平均 20210601\~20210701峰值
10:00 14:00 16:00 10:00 14:00 16:00
kafka消息生产量 100W/s 70W/s 50W/s 110W/s 100W/s 80W/s
KPIMonitor训练解析量 100W/s 70w 50w/s 150W/s 120W/s 100w/s
根据业务统计，系统每秒消息的吞吐量平均达到100万条，峰值可达到150万条；
6.3 搜索查找效率分析
  20211101\~20211201平均 20221101\~20211201峰值
10:00 14:00 16:00 10:00 14:00 16:00
搜索次数 1120 285 692 2350 859 1156
搜索平均耗时 5.3s 3.4s 3.6s 30s 30s 30s
根据业务统计，索引大小2TB时，查询时延3-9秒；一般日志搜索平均耗时300毫秒左右。
### 系统效能 {#系统效能 .样式-标题-3Heading-3-Char1Heading-3-Char-Char-Char-Char-Charh3-C...11}
## **满足银行运维稳健支撑业务的战略需求** {#满足银行运维稳健支撑业务的战略需求 .样式7}
可观测性应用智能分析平台建立了统一的数据监控观测体系，从业务-服务-设备-指标的多维视角，全面观测系统状况，实现主动预防型监控，聚合细微预警事件，大大提前发现异常事件的时间点，及时准确地判断异常的时点和位置，满足了互联网交易模式下的极致服务体验要求。
## **打破数据壁垒、完成数据流通** {#打破数据壁垒完成数据流通 .样式7}
可观测性应用智能分析平台将可观测性中的三大支柱日志、指标数据、链路追踪三大数据种类统一收集，并将业务数据和运维数据互为联通，打破数据壁垒、联通部门竖井。
通过对海量监控数据的汇总，分析，归纳，统计，形成一个可观测性应用智能分析平台的可视化页面，实现应用性能监测、智能告警、快速排障等场景运用的最大价值输出。
## **数据与人工智能算法的有效结合** {#数据与人工智能算法的有效结合 .样式7}
成熟的算法很难在实际运维工作中直接应用产生收益较高运维场景。ARIMA模型以数据平稳性为前提，可捕捉线性关系，不适用于数据波动性大的指标场景；Holt-winter及ETS簇模型，可捕获数据的周期性、趋势性、季节性特征，但在非周期性数据上效果不佳。
可观测性应用智能分析平台利用自身对运维数据的了解，将算法与数据有效结合，反向梳理运维数据可能存在的几种特征，依据历史数据特征进行波形聚类，形成为数据变化趋势具有明显相似性的"周期型"数据、区间内数据相对平稳的"阶梯型"数据及无规律的随机"波动型"数据三大类。根据数据特征，寻找和适配对应的算法，并通过实际运维反馈，持续适配和优化。
排错（归并技术和归并策略）：在当前复杂的应用架构中，各个应用之间的交互频繁，互相依赖，通常一个小故障就会触发大规模告警风暴，运维人员将收到大量的告警信息。大量无效的、无需处理的告警会导致运维人员会使运维人员放松警惕，也无法从告警中找到有效信息，因此需要通过告警智能归并、降噪，提升告警质量，甄别有效告警。
告警归并技术和归并策略将相似的异常、可能属于同一问题导致的异常等等进行合并，整合成更简洁、指向性更强的告警，避免当问题大量爆发时对运维人员的消息轰炸，也有助于快速找出问题所在。