title:Don't Mind the Gap: Bridging Network-wide Objectives and Device-level
Configurations
author:Ryan Beckett and
Ratul Mahajan and
Todd D. Millstein and
Jitendra Padhye and
David Walker
Don’t Mind the Gap: Bridging Network-wide
Objectives and Device-level Conﬁgurations
Ryan Beckett
Princeton
Ratul Mahajan
Microsoft
Todd Millstein
UCLA
Jitendra Padhye
Microsoft
David Walker
Princeton
Abstract— We develop Propane, a language and com-
piler to help network operators with a challenging, error-
prone task—bridging the gap between network-wide rout-
ing objectives and low-level conﬁgurations of devices that
run complex, distributed protocols. The language allows op-
erators to specify their objectives naturally, using high-level
constraints on both the shape and relative preference of traf-
ﬁc paths. The compiler automatically translates these speci-
ﬁcations to router-level BGP conﬁgurations, using an effec-
tive intermediate representation that compactly encodes the
ﬂow of routing information along policy-compliant paths. It
guarantees that the compiled conﬁgurations correctly imple-
ment the speciﬁed policy under all possible combinations
of failures. We show that Propane can effectively express
the policies of datacenter and backbone networks of a large
cloud provider; and despite its strong guarantees, our com-
piler scales to networks with hundreds or thousands of routers.
CCS Concepts
• Networks → Network control algorithms; Network relia-
bility; Network management; • Software and its engineering
→ Automated static analysis; Domain speciﬁc languages
Keywords
Propane; Domain-speciﬁc Language; BGP; Synthesis; Com-
pilation; Fault Tolerance; Distributed Systems
1.
INTRODUCTION
It is well known that conﬁguring networks is error prone
and that such errors can lead to disruptive downtimes [22,
10, 12, 16]. For instance, a recent misconﬁguration led to
an hour-long, nation-wide outage for Time Warner’s back-
bone network [4]; and a major BGP-related incident makes
international news every few months [6].
A fundamental reason for the prevalence of misconﬁgura-
tions is the semantic mismatch between the intended high-
level policies and the low-level conﬁgurations. Many poli-
cies involve network-wide properties—prefer a certain neigh-
Permission to make digital or hard copies of all or part of this work for personal
or classroom use is granted without fee provided that copies are not made or
distributed for proﬁt or commercial advantage and that copies bear this notice
and the full citation on the ﬁrst page. Copyrights for components of this work
owned by others than ACM must be honored. Abstracting with credit is per-
mitted. To copy otherwise, or republish, to post on servers or to redistribute to
lists, requires prior speciﬁc permission and/or a fee. Request permissions from
permissions@acm.org.
SIGCOMM ’16, August 22-26, 2016, Florianopolis , Brazil
c(cid:13) 2016 ACM. ISBN 978-1-4503-4193-6/16/08. . . $15.00
DOI: http://dx.doi.org/10.1145/2934872.2934909
328
bor, never announce a particular destination externally, use a
particular path only if another fails—but conﬁgurations de-
scribe the behavior of individual devices. Operators must
manually decompose network-wide policy into device be-
haviors, such that policy-compliant behavior results from the
distributed interactions of these devices. Policy-compliance
must be ensured not only under normal circumstances but
also during failures. The need to reason about all possible
failures exacerbates the challenge for network operators. As
a result, conﬁgurations that work correctly in failure-free
environments have nonetheless been found to violate key
network-wide properties when failures occur [12].
To reduce conﬁguration errors, operators are increasingly
adopting an approach in which common tasks are captured
as parameterized templates [18, 31]. While templates help
ensure certain kinds of consistency across devices, they do
not provide fundamentally different abstractions from exist-
ing conﬁguration languages or bridge the semantic divide
between network-wide policies and device-level conﬁgura-
tion. Thus, they still require operators to manually decom-
pose policies into device behaviors.
The centralized control planes of SDN, however, are not a
panacea. First, while many SDN programming systems [13]
provide effective intra-domain routing abstractions, letting
users specify paths within their network, they fail to provide
a coherent means to specify inter-domain routes. Second,
centralized control planes require careful design and engi-
neering to be robust to failures—one must ensure that all de-
vices can communicate with the controller at all times, even
under arbitrary failure combinations. Even ignoring failures,
it is necessary for the control system to scale to meet the de-
mands of large or geographically-distributed networks, and
to react quickly to environmental changes. For this chal-
lenge, researchers are exploring multi-controller systems with
As a complementary approach, conﬁguration analysis tools
can help reduce misconﬁgurations by checking if low-level
conﬁgurations match high-level policy [12, 10]. However,
such tools cannot help operators with the challenging task of
generating conﬁgurations in the ﬁrst place.
Software-deﬁned networking (SDN) and its abstractions
are, in part, the research community’s response to the difﬁ-
culty of maintaining policy compliance through distributed
device interactions [8]. Instead of organizing networks around
a distributed collection of devices that compute forwarding
tables through mutual interactions, the devices are told how
to forward packets by a centralized controller. The controller
is responsible for ensuring that the paths taken are compliant
with operator speciﬁcations.
interacting controllers, thus bringing back distributed control
planes [23, 5] and their current programming difﬁculties.
Hence, in this paper, we have two central goals:
1. Design a new, high-level language with natural abstrac-
tions for expressing intra-domain routing, inter-domain
routing and routing alternatives in case of failures.
2. Deﬁne algorithms for compiling these speciﬁcations
into conﬁgurations for devices running standard dis-
tributed control plane algorithms, while ensuring cor-
rect behavior independent of the number of faults.
To achieve the ﬁrst goal, we borrow the idea of using reg-
ular expressions to specify network paths from recent high-
level SDN languages such as FatTire [29], Merlin [30], and
NetKAT [3]. However, our design also contains several key
departures from existing languages. The most important one
is semantic: the paths speciﬁed can extend from outside the
operator’s network to inside the network, across several de-
vices internally, and then out again. This design choice al-
lows users to specify preferences about both external and in-
ternal routes in the exact same way. In addition, we augment
the algebra of regular expressions to support a notion of pref-
erences and provide a semantics in terms of sets of ranked
paths. The preferences indicate fail-over behaviors: among
all speciﬁed paths that are still available, the system guar-
antees that the distributed implementation will always use
the highest-ranked ones. Although we target a distributed
implementation, the language is more general and could po-
tentially be used in an SDN context.
To achieve the second goal, we develop program analysis
and compilation algorithms that translate the regular poli-
cies to a graph-based intermediate representation and from
there to per-device BGP conﬁgurations, which include var-
ious ﬁlters and preferences that govern BGP behavior. We
target BGP for pragmatic reasons: it is a highly ﬂexible rout-
ing protocol, it is an industry standard, and many networks
use it internally as well as externally. Despite the advent
of SDN, many networks will continue to use BGP for the
foreseeable future due to existing infrastructure investments,
the difﬁculty of transitioning to SDN, and the scalability and
fault-tolerance advantages of a distributed control plane.
The BGP conﬁgurations produced by our compiler are
guaranteed to be policy-compliant in the face of arbitrary
failures.1 This guarantee does not mean that the implemen-
tation is always able to send trafﬁc to its ultimate destination
(e.g., in the case of a network partition), but rather that it
always respects the centralized policy, which may include
dropping trafﬁc when there is no route. In this way, we pro-
vide network operators with a strong guarantee that is oth-
erwise impossible to achieve today. However, some poli-
cies simply cannot be implemented correctly in BGP in the
presence of arbitrary failures. We develop new algorithms
to detect such policies and report our ﬁndings to the opera-
tors, so they may ﬁx the policy speciﬁcation at compile time
1We assume that BGP is the only routing protocol running
in the network or the other protocols are correctly conﬁgured
and do not have adverse interactions with BGP [17, 11].
329
rather than experience undesirable behavior after the conﬁg-
urations are deployed.
We have implemented our language and compiler in a sys-
tem called Propane. To evaluate it, we use it to specify
real policies for datacenter and backbone networks. We ﬁnd
that our language expresses such policies easily, and that the
compiler scales to topologies with hundreds or thousands of
routers, compiling in under 9 minutes in all cases.
2. BACKGROUND ON BGP
BGP is a path-vector routing protocol that connects au-
tonomous systems (ASes). An AS has one or more routers
managed by the same administrative entity. ASes exchange
routing announcements with their neighbors. Each announce-
ment has a destination IP preﬁx and some attributes (see be-
low), and it indicates that the sending AS is willing to carry
trafﬁc destined to that preﬁx from the receiving AS. Traf-
ﬁc ﬂows in the opposite direction, from announcement re-
ceivers to senders.
When a route announcement is received by an AS, it is
processed by custom import ﬁlters that may drop the an-
nouncement or modify some attributes. If multiple announce-
ments for the same preﬁx survive import ﬁlters, the router
selects the best one based on local policy (see below). This
route is then used to send trafﬁc to the destination.
It is
also advertised to the neighbors, after processing through
neighbor-speciﬁc export ﬁlters that may stop the announce-
ment or modify some attributes.
All routing announcements are accompanied by an AS-
path attribute that reﬂects the sequence of ASes that the an-
nouncement has traversed thus far. While the AS-path at-
tribute has a global meaning, some attributes are meaning-
ful only within an AS or between neighboring ASes. One
such attribute is a list of community strings. ASes use such
strings to associate network-speciﬁc information with partic-
ular routes (e.g., “entered on West Coast”) and then use the
information later in the routing process. Communities are
also used to signal to neighbors how they should handle an
announcement (e.g., do not export it further). Another non-
global attribute is the multi-exit discriminator (MED). It is
used when an AS has multiple links to a neighboring AS. Its
(numeric) values signal to the neighbor how this AS prefers
to receive trafﬁc among those links.
The route selection process assigns a local preference to
each route that survives the import ﬁlters. Routes with higher
local preference are preferred. Among routes with the same
local preference, other factors such as AS path length, MEDs,
and internal routing cost, are considered in order. Because
it is considered ﬁrst during route selection, local preference
is highly inﬂuential, and ASes may assign this preference
based on any aspect of the route. A common practice is
to assign it based on the commercial relationship with the
neighbor. For instance, an AS may prefer in order customer
ASes (which pay money), peer ASes (with free exchange of
trafﬁc), and provider ASes (which charge money for trafﬁc).
The combination of arbitrary import and export ﬁlters and
route selection policies at individual routers make BGP a
Figure 1: Creating router-level policies is difﬁcult.
highly ﬂexible routing protocol. That ﬂexibility, however,
comes at the cost of it being difﬁcult to conﬁgure correctly.
When conﬁguring BGP, network operators assume that neigh-
boring ASes correctly implement BGP and honor contracts
for MEDs and communities. Propane makes the same as-
sumption when deriving BGP conﬁgurations for a network.
3. MOTIVATION
When generating BGP conﬁgurations, whether manually
or aided by templates, the operators face the challenge of de-
composing network-wide policies into correct device-level
policies. This decomposition is not always straightforward
and ensuring policy-compliance is tricky, especially in the
face of failures. In this section, we illustrate this difﬁculty
using two examples based on policies that we have seen in
practice. The next section shows how Propane allows oper-
ators to express these policies naturally.
3.1 Example 1: The backbone
Consider the backbone network in Figure 1. It has three
neighbors, a customer Cust, a peer Peer, and a provider
Prov. The policy of this network is shown on the right. It
prefers that trafﬁc leave the network through neighbors in
a certain order (P1) and does not want to act as a transit
between Peer and Prov (P2). It prefers to exchange trafﬁc
with Cust over R1 rather than R2 because R1 is cheaper (P3).
To guard against another AS "hijacking" preﬁxes owned by
Cust, the network only sends trafﬁc to a neighbor if Cust is
on the AS path (P4). Finally, to guard against Cust acciden-
tally becoming a transit for Prov, it does not use Cust for
trafﬁc that will later traverse Prov (P5).
To implement policy P1, the operators must compute and
assign local preferences such that preferences at Cust-facing
interfaces > Peer-facing interfaces > Prov-facing inter-
faces. At the same time, to satisfy P3, the preference at
R2’s Cust-facing interface should be lower than that at R1.
Implementing P3 will also require MEDs to be appropri-
ately conﬁgured on R1 and R2. To implement P2, the op-
erators can assign communities that indicate where a cer-
tain routing announcement entered the network. Then, R4
must be conﬁgured to not announce to Peer routes that have
communities that correspond to the R2-Prov link but to an-
nounce routes with communities for the R2-Cust and R1-
Cust links. A similar type of policy must be conﬁgured for
R2 as well. Finally, to implement P4 and P5, the operators
will have to compute and conﬁgure appropriate preﬁx- and
AS-path-based import and export ﬁlters at each router.
Clearly, it is difﬁcult to correctly conﬁgure even this small
example network manually; correctly conﬁguring real, larger
Figure 2: Policy-compliance under failures is difﬁcult.
networks can quickly become a nightmare. Such networks
have hundreds of neighbors spanning multiple commercial-
relationship classes, differing numbers of links to each neigh-
bor, along with several neighbor- or preﬁx-based exceptions
to the default behavior. A large AS with many peers in dif-
ferent geographic locations may be faced with complex chal-
lenges such as keeping trafﬁc within national boundaries.
Templates help to an extent by keeping preference and com-
munity values consistent across routers, but operators must
still do much of the conceptually difﬁcult work manually.
3.2 Example 2: The datacenter
While conﬁguring policies for a fully functional network
is difﬁcult, ensuring policy compliance in the face of fail-
ures can be almost impossible. Consider the datacenter net-
work in Figure 2 with routers organized as a fat tree and run-
ning BGP.2 The network has two clusters, one with services
that should be reachable globally and one with services that
should be accessible only internally. This policy is enabled
by using non-overlapping address space in the two clusters
and ensuring that only the address space for the global ser-
vices is announced externally. Further, to reduce the number
of preﬁxes that are announced externally, the global space is
aggregated into a less-speciﬁc preﬁx PG. The semantics of
aggregation is that the aggregate preﬁx is announced as long
as the router has a path to at least one sub-preﬁx.
The operator may implement the policy by having X and
Y: i) not export externally what they hear from G and H,
routers that belong to the local services cluster; and ii) ex-
port externally what they hear from routers C and D and ag-
gregate to PG if an announcement is subset of PG. This im-