and S[iCDF, s, ts] :: Value a. Symbolic dataset D represents
concrete datasets arising from data transformations. A symbolic
value S[iCDF, s, ts] represents concrete values with tags ts
and a iCDF which is computed assuming a noise scale s. Tags
are used to detect the provenance of symbolic values and when
they arise from different noisy sources.
Function accuracy takes queries that produce a result
of type Value a. Such queries are essentially built by
performing data aggregation queries (e.g., dpCount) preceded
by a (possibly empty) sequence of other primitives like data
transformations6. Figure 6 and 7 show the interesting parts
of our analysis—Appendix C shows the calculation of norms
and thus we skip them here for brevity. Given a well-typed
query q :: Query (Value a), accuracy q = iCDF where
q (cid:5) S[iCDF, s, ts] for some s and ts. The rules in Figure 6
are mainly split into two cases: considering data aggregation
queries and sequences of primitives glued together with (>>=).
The symbolic interpretation of dpCount is captured by
rule DPCOUNT—see Figure 6a. This rule populates the iCDF
of the return symbolic value with the corresponding error
5 There are perhaps other ways to compute the Chernoff bound for the sum
of independent Laplace distributions, changing this equation in DPella does
not require major work.
6We ignore the case of return val :: Query (Value a) since the deﬁnition
of accuracy is trivial for such case.
dataset :: Data s r
DPCOUNT
iCDF = λβ → log(
dpCount  dataset (cid:5) S[iCDF, s · 1

β ) · s · 1
1

t fresh
,{t}]
(a) DP-queries
SEQ-TRANS
k D (cid:6)∗
next
next (cid:5) S[iCDF, s, ts]
transform >>= k (cid:5) S[iCDF, s, ts]
SEQ-QUERY
k (S[iCDFq, sq, tsq]) (cid:6)∗
query (cid:5) S[iCDFq, sq, tsq]
query >>= k (cid:5) S[iCDF, s, ts]
next
next (cid:5) S[iCDF, s, ts]
SEQ-PART
(b) Sequential traversal
(m j D (cid:6)∗
nextj)j∈dom(m)
(nextj (cid:5) S[iCDFj, sj, tsj])j∈dom(m)
m’ = (j (cid:6)→ S[iCDFj, sj, tsj])j∈dom(m)
next (cid:5) S[iCDF, s, ts]
k m’ (cid:6)∗
next
dpPart sel dataset m >>= k (cid:5) S[iCDF, s, ts]
(c) Accuracy calculation when partitioning data
Fig. 6: Accuracy analysis implemented by accuracy
calculations for Laplace as presented in Deﬁnition A.1 (with
the scale adjusted with the accumulated stability). Observe
that it extracts the stability information from the type of
the considered dataset (ds :: Data s r) and attaches a fresh
tag indicating an independently generated noisy value. The
symbolic interpretation of dpSum and dpAvg proceeds similarly
to dpCount and we thus omit them for brevity. We also omit
the symbolic interpretation of dpMax for brevity—readers can
refer to Appendix D for details.
To symbolically interpret a sequence of primitives, the
analysis gets further split into two cases depending if the ﬁrst
operation to interpret is a transformation or an aggregation,
respectively—see Figure 6b. Rule SEQ-TRANS considers the
former, where transform can be any of the transformation
operations in Figure 3. It simply uses the symbolic value D to
pass it to the continuation k. It can happen that k D does not
match (yet) any part of DPella’s API required for our analysis
to continue7. However, the EDSL nature of DPella makes
Haskell’s to reduce k D to the next primitive to be considered,
which we capture as k D (cid:6)∗
next—and we know that it will
occur thanks to type preservation. We represent (cid:6) ((cid:6)∗) to
pure reduction(s) in the host language like function application,
pair projections, list comprehension, etc. The analysis then
continues symbolically interpreting the next yield instruction.
Rule SEQ-QUERY computes the corresponding symbolic value
for the aggregation query. The symbolic value is then passed
to the continuation, and the analysis continues with the next
7For instance, k D = (λx → dpCount 1 x) D, and thus ((λx →
dpCount 1 x) D) (cid:6)∗
dpCount 1 D.
Authorized licensed use limited to: Carleton University. Downloaded on August 06,2020 at 17:57:38 UTC from IEEE Xplore.  Restrictions apply. 
419
UNION-BOUND
vj = S[iCDFj, sj, tsj]
αj = iCDFj(
b
n )
iCDF = λβ → n(cid:2)
αj
j=1
ub [v1, v2, ..., vn ] (cid:6) iCDF
j=1 s2
j
ν = max{
} + 0.0001
CHERNOFF-BOUND
vj = S[iCDFj, sj, tsj]
vM = max {sj}j=1...n
(cid:3)
(cid:3)(cid:4)n
ln 2
(cid:3)
, vM
β
iCDF = λβ → ν ·
8 ln 2
β
cb [v1, v2, ..., vn ] (cid:6) iCDF
(∃j · tsj = ∅) ∨ (cid:5)
ADD-UNION
add [v1, v2, ..., vn ] (cid:6) S[ub [v1, v2, ..., vn ], 0,∅]
j=1...n tsj (cid:10)= ∅
ADD-CHERNOFF-UNION
j=1...n tsj = ∅
vj = S[iCDFj, sj, tsj]
iCDF = λβ → min (ub [v1, v2, ..., vn ] β) (cb [v1, v2, ..., vn ] β)
(∀j · tsj (cid:10)= ∅)
add [v1, v2, ..., vn ] (cid:6) S[iCDF, 0,∅]
(cid:5)
Fig. 7: Calculation of concentration bounds
yield instruction.
s
k
(Data
Rule SEQ-PART shows the symbolic interpretation of
r →
dpPart. The argument m :: Map
Query (Value a)) describes the queries to execute once given
the corresponding bins. Since these queries produce values,
we need to symbolically interpret each of them to obtain their
accuracy estimations. The rule applies each of those queries
to a symbolic dataset (m j D)8. The symbolic values yield
by each bin are collected into the mapping m’, which is then
passed to continuation k in order to continue the analysis on
the next yield instruction.
Figure 7 shows the part of our analysis responsible to apply
concentration bounds. Rules UNION-BOUND and CHERNOFF-
BOUND deﬁne pure functions (reduction (cid:6)) which produce
the concentration bounds as described in Deﬁnitions IV.2 and
IV.3, respectively. We deﬁne the function add based on two
cases. Rule ADD-UNION produces a symbolic value with a
iCDF generated by the union bound (ub [v1, v2, ..., vn ]). The
symbolic value is tainted, which is denoted by the empty
tags (∅). The scale 0 denotes that the scale of the noise and
its distribution is unknown—adding Laplace distributions do
not yield a Laplace distribution. (However, the situation is
different with Gaussians where the analysis keeps the scale
of the noise and taint tags—see Appendix E for details.)
This rule gets exercised when either the list of symbolic
values contains a tainted one (∃j · tsj = ∅) or have not
k=1...n tsj (cid:11)= ∅). Differently,
been independently generated (
ADD-CHERNOFF-UNION produces a symbolic value with a
iCDF which chooses the minimum error estimation between
union and Chernoff bound for a given β—sometimes union
(cid:6)
8For simplicity, we assume that maps are implemented as functions
bound provides tighter estimations when aggregating few noisy-
values (recall Figure 5). This rule triggers when all the values
are untainted (∀j · tsj (cid:11)= ∅) and independently generated
(cid:6)
j=1...n tsj = ∅). At a ﬁrst glance, one could believe that
(
it would be enough to use the scale of the noise to track when
values are untainted, i.e., if the scale is different from 0, then the
value is untainted. Unfortunately, this design choice is unsound:
it will classify adding a variable twice as an independent
sum: do x ← dpCount  ds; return (add [x, x]). It is also
possible to consider various ways to add symbolic values to
boost accuracy. We could easily write a pre-processing function
which, for instance, ﬁrstly partitions the arguments into subset
of independently generated values, applies add to them (thus
triggering ADD-CHERNOFF-UNION), and ﬁnally applies add
to the obtained results (thus triggering ADD-UNION). The
implementation of DPella enables to write such functions in a
few lines of code.
V. CASE STUDIES
Application
CDFs [28]
Term
frequency [2]
Network
analysis [28]
Cumulative
sums [29]
Range queries via Identity,
Histograms [31], and
Wavelet [32]
Category
PINQ-like
Counting
queries
cdf2,
Programs
cdf1,
cdfSmart
queryFreq,
queriesFreq
packetSize,
portSize
cumulSum1
cumulSum2
cumulSumSmart
i_n
h_n
y_n
TABLE I: Implemented literature examples
In this section, we will discuss the advantages and limitations
of our programming framework. Moreover, we will go in-
depth into using DPella to analyze the interplay of privacy and
accuracy parameters in hierarchical histograms.
A. DPella expressiveness
First, we start by exploring the expressiveness of DPella. For
this, we have built several analyses found in the DP literature—
see Table I—which we classify into two categories, PINQ-like
queries and counting queries. The former class allows us to
compare DPella expressivity with the one of PINQ, while the
latter with APEx.
PINQ-like queries: We have implemented most of PINQ’s
examples [2, 28], such as, different versions of CDFs (sequen-
tial, parallel, and hybrid) and network tracing-like analyses
(such as determining the frequency a term or several terms
have been searched by the users, and computing port’s and
packets’ size distribution); additionally, we considered analyses
of cumulative sums [29]—which are queries that share some
commonalities with CDFs. The interest over differentially
private CDFs and cumulative partial sums applications rely on
the existing several approaches to inject noise, such choices
will directly impact the accuracy of our results, and therefore,
Authorized licensed use limited to: Carleton University. Downloaded on August 06,2020 at 17:57:38 UTC from IEEE Xplore.  Restrictions apply. 
420
are ideal to be tested and analyzed in DPella. The structures of
these examples follow closely the ones of the CDFs presented
in previous sections, which are straightforward implementations.
DPella supports these queries naturally since its expressiveness
relies on its primitives and, by construction, they follow PINQ’s
ones very closely. However, as stated in previous sections, our
framework goes a step further and exposes to data analysts
the accuracy bound achieved by the speciﬁc implementation.
This feature allows data analyst to reason about accuracy of
the results—without actually executing the query—by varying
i) the strategy of the implementation ii) the parameters of
the query. For instance, in Section II, we have shown how an
analyst can inspect the error of a sequential and parallel strategy
to compute the CDF of packet lengths. Furthermore, the data
analyst can take advantage of DPella being an embedded DSL
and write a Haskell function that takes any of the approaches
(cdf1 or cdf2) and varies epsilon aiming to certain error
tolerance (for a ﬁxed conﬁdence interval), or vice versa. Such
a function can be as simple as a brute force analysis or as
complex as an heuristic algorithm.
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
Fig. 8: WR4
1 0 0 0
1 1 0 0
1 1 1 0
1 1 1 1
0 1 0 0
0 1 1 0
0 1 1 1
0 0 1 0
0 0 1 1
0 0 0 1
Counting queries: To compare our ap-
proach with the tool APEx [18], we consider
range queries analyses—an speciﬁc subclass
of counting queries. APEx uses the matrix
mechanism [30] to compute counting queries.
This algorithm answers a set of linear queries
(called the workload) by calibrating the
noise to speciﬁc properties of the workload
while preserving differential privacy. More
in detail, the matrix mechanism uses some
query strategies as an intermediate device to
answer a workload; returning a DP version
of the query strategies (obtained using the Laplace or Gaussian
mechanism), from which noisy answers of the workload are
derived. The matrix mechanism achieves an almost optimal
error on counting queries. To achieve such error, the algorithm
uses several non-trivial
transformations which cannot be
implemented easily in terms of other components. APEx
implements it as a black-box and we could do the same in
DPella (see Section VI). Instead, in this section we show
how DPella can be directly used to answer sets of counting
queries using some of the ideas behind the design of the matrix
mechanism, and how these answers improve with respect to
answering the queries naively, thanks to the use of partition
and the Chernoff bound.
⎤
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
d
n
u
o
B
t
h
g
R
i
1
64
128
192
256
320
384
448
512
  1
Error
120
90
60
30
 64
128
192
256