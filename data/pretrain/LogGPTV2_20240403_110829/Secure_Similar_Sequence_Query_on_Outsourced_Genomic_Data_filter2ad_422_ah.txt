Springer, 313–331.
[18] Yan Huang, David Evans, Jonathan Katz, and Lior Malka. 2011. Faster Secure
Two-Party Computation Using Garbled Circuits.. In USENIX Security Symposium,
Vol. 201.
[19] Mathias Humbert, Erman Ayday, Jean-Pierre Hubaux, and Amalio Telenti. 2013.
Addressing the concerns of the lacks family: quantification of kin genomic privacy.
In Proceedings of the 2013 ACM SIGSAC conference on Computer & communications
security. ACM, 1141–1152.
[20] Yuval Ishai, Joe Kilian, Kobbi Nissim, and Erez Petrank. 2003. Extending Oblivious
Transfers Efficiently.. In Crypto, Vol. 2729. Springer, 145–161.
[21] Neda Jahanshad, Priya Rajagopalan, Xue Hua, Derrek P Hibar, Talia M Nir,
Arthur W Toga, Clifford R Jack, Andrew J Saykin, Robert C Green, Michael W
Weiner, et al. 2013. Genome-wide scan of healthy human connectome discovers
SPON1 gene variant influencing dementia severity. Proceedings of the National
Academy of Sciences 110, 12 (2013), 4768–4773.
[22] Somesh Jha, Louis Kruger, and Vitaly Shmatikov. 2008. Towards practical privacy
for genomic computation. In Security and Privacy, 2008. SP 2008. IEEE Symposium
on. IEEE, 216–230.
[23] Miran Kim and Kristin Lauter. 2015. Private genome analysis through homomor-
phic encryption. BMC medical informatics and decision making 15, 5 (2015).
[24] Vladimir Kolesnikov and Thomas Schneider. 2008. Improved garbled circuit:
Free XOR gates and applications. Automata, Languages and Programming (2008),
486–498.
[25] Yehuda Lindell and Benny Pinkas. 2009. A proof of security of Yao’s protocol for
two-party computation. Journal of Cryptology 22, 2 (2009), 161–188.
[26] An Liu, Kai Zhengy, Lu Liz, Guanfeng Liu, Lei Zhao, and Xiaofang Zhou. 2015.
Efficient secure similarity computation on encrypted trajectory data. In Data
Engineering (ICDE), 2015 IEEE 31st International Conference on. IEEE, 66–77.
[27] Md Safiur Rahman Mahdi, Mohammad Zahidul Hasan, and Noman Mohammed.
2017. Secure Sequence Similarity Search on Encrypted Genomic Data. In Con-
nected Health: Applications, Systems and Engineering Technologies (CHASE), 2017
IEEE/ACM International Conference on. IEEE, 205–213.
[28] P. Mohassel and Y. Zhang. 2017. SecureML: A System for Scalable Privacy-
Preserving Machine Learning. In 2017 IEEE Symposium on Security and Privacy
(SP). 19–38. https://doi.org/10.1109/SP.2017.12
[29] Cancer Genome Atlas Network et al. 2012. Comprehensive molecular portraits
of human breast tumours. Nature 490, 7418 (2012), 61–70.
[30] Anna Olivieri, Carlo Sidore, and et al. 2017. Mitogenome diversity in Sardinians:
a genetic window onto an island’s past. Molecular biology and evolution 34, 5
(2017), 1230–1239.
[31] Pascal Paillier et al. 1999. Public-key cryptosystems based on composite degree
residuosity classes. In Eurocrypt, Vol. 99. Springer, 223–238.
[32] Suyash S Shringarpure and Carlos D Bustamante. 2015. Privacy risks from
genomic data-sharing beacons. The American Journal of Human Genetics 97, 5
(2015), 631–646.
[33] Wenhai Sun, Ning Zhang, Wenjing Lou, and Y Thomas Hou. 2017. When gene
meets cloud: Enabling scalable and efficient range query on encrypted genomic
data. In INFOCOM 2017. IEEE, 1–9.
[34] Bing Wang, Wei Song, Wenjing Lou, and Y Thomas Hou. 2017. Privacy-preserving
pattern matching over encrypted genetic data in cloud computing. In INFOCOM
2017-IEEE Conference on Computer Communications, IEEE. IEEE, 1–9.
[35] Shuang Wang, Xiaoqian Jiang, Haixu Tang, Xiaofeng Wang, Diyue Bu, Knox
Carey, Stephanie OM Dyke, Dov Fox, Chao Jiang, Kristin Lauter, et al. 2017. A
community effort to protect genomic data sharing, collaboration and outsourcing.
npj Genomic Medicine 2, 1 (2017), 33.
[36] Xiao Shaun Wang, Yan Huang, Yongan Zhao, Haixu Tang, XiaoFeng Wang, and
Diyue Bu. 2015. Efficient genome-wide, privacy-preserving similar patient query
based on private edit distance. In Proceedings of the 22nd ACM SIGSAC Conference
on Computer and Communications Security. ACM, 492–503.
[37] Jun Zhou, Zhenfu Cao, and Xiaolei Dong. 2016. PPOPM: more efficient privacy
preserving outsourced pattern matching. In European Symposium on Research in
Computer Security. Springer, 135–153.
[38] Ruiyu Zhu and Yan Huang. 2017. Efficient privacy-preserving general edit distance
and beyond. Technical Report. Cryptology ePrint Archive, Report 2017/683, 2017.
http://eprint. iacr. org/2017/683 10 April 2017, date last accessed.
This  is  an  author-produced,  peer-reviewed  version  of  this  article.  The  final,  definitive  version  of  this  document  can  be  found  online  at  ASIACCS  '18:
Proceedings of the 2018 on Asia Conference on Computer and Communications Security, published by Association for Computing Machinery. Copyright
restrictions may apply. doi: 10.1145/3196494.3196535
A WAGNER-FISHER ALGORITHM
Algorithm 9 shows how to compute edit distance by Wagner-Fisher
algorithm. The edit distance between two strings X = [a1, a2, . . . ,
an1
] is given by dn1,n2 , calculated by the
following recurrence:
] and Y = [b1, b2, . . . , bn2
⎧⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎩
di, j =
0
min
⎧⎪⎪⎪⎨
⎪⎪⎪⎩
di −1, j + cdel
di, j−1 + cins
di −1, j−1 + csub
if i == 0 or j == 0
otherwise
(4)
where cins , cdel , csub correspond to the cost of single-character
insert, delete, and substitute. For the edit distance, cins ← 1, cdel ←
1, csub ← (ai == bj )?0 : 1. It is clear from Equation 4 that the edit
distance calculation is transformed into the process of filling an
(n1 + 1) × (n2 + 1) table with each element di, j . The full dynamic
programming table can be constructed in O(n1n2) time. Once the
table is filled, it is easy to trace on the optimal path. That is, the index
in Algorithm 9 reveals optimal conversion path from an original
sequence to a new one. Figure 5 shows an example of edit distance
computation. The lower-right element d4,5=2 is the final result and
the dotted line represents one of the optimal paths.
(cid:38) (cid:55) (cid:36) (cid:42) (cid:36)
(cid:24)
(cid:20)
(cid:23)
(cid:20)
(cid:23)
(cid:21)
(cid:22)
(cid:22)
(cid:21)
(cid:23)
(cid:21)
(cid:21)
(cid:20)
(cid:21)
(cid:22)
(cid:22)
(cid:21)
(cid:21)
(cid:21)
(cid:21)
(cid:23)
(cid:22)
(cid:22)
(cid:21)
(cid:22)
(cid:19)
(cid:36) (cid:20)
(cid:55) (cid:21)
(cid:42) (cid:22)
(cid:36) (cid:23)
Figure 5: Example of edit distance computation (The lower-
right element d4,5 = 2 is the final result and the dotted line
represents one of the optimal paths).
}
di,0 ← i.
} and Y = {b1, b2, . . . , bn2
Algorithm 9 Edit Distance Computation
Input: X = {a1, a2, . . . , an1
Output: dn1,n2
1: for 0 ≤ i ≤ n1 do
2:
3: for 0 ≤ j ≤ n2 do
4:
5: cdel ← 1, cins ← 1.
6: for 1 ≤ i ≤ n1,1 ≤ j ≤ n2 do
csub ← (ai == bj )?0 : 1.
7:
di, j = min(di −1, j + cd e l ,di, j −1 + ci ns ,di −1, j −1 + csub ).
d0, j ← j.
8:
9: return dn1,n2
B THE SECURITY ANALYSIS
Suppose that a two-party protocol P asks A to compute the func-
tion f A (x, y), and asks B to compute f B (x, y), where x, y are the
inputs of A and B, respectively. The view of A (resp. B) during an
execution of P on (x, y), denoted view A (x, y) (resp. view B (x, y)),
is (x, r A, m1, · · · , mt ) (resp. (y, r B, m1, · · · , mt )), where r A (resp.
r B) represents randomness of A (resp. B) and mi represents the
i-th message passed between the parties. Also let O A (x, y) and
O B (x, y) denote A’s (resp. B’s) output. We say that protocol P is
secure against semi-honest adversaries if there exist probabilistic
polynomial time (PPT) simulators S1 and S2 such that:
(S1(x, f A (x, y)), f (x, y))
(S2(y, f B (x, y)), f (x, y))
c
≡ (view A (x, y), O(x, y))
c
≡ (view B (x, y), O(x, y))
(6)
c
≡ denotes computational indistinguishability. More details
(5)
where
can be found in [15].
We assume that the secure computation primitives (described in
Section 2.2) involved in our protocols are secure under semi-honest
model [15], and Paillier cryptosystem with distributed decryption
is semantically secure. The formal security proofs of them can be
found in [4, 17]. In addition, we note that ADD-CMP and EQ-ADD
are direct applications of Yao’s garbled circuits, whose security
proof can be found in [25]. Next, we prove the following theorem
under the above security assumptions.
B.1 Security Analysis of Sub-protocols
We first prove the security of all our sub-protocols. Then we will
employ composition theory to prove that our SSQ-I and SSQ-II are
secure.
Theorem B.1. If Paillier cryptosystem with distributed decryption
(short as PCDD) [17] is semantically secure, then the offline phase
of secure shuffling (short as SSF_off) protocol is secure under the
semi-honest adversaries model.
Proof. The correctness is easy to see, just by inspecting the
output result is shuffled from [−u1 − v1, · · · , −un − vn ] by the
permutation function π (π (cid:9)(·)). Recall that the function of SSF_off
is that A selects a set of random integers u1, · · · , un , B selects a set
of random integers v1, · · · , vn and then B outputs a set of shuffled
values [−uπ (π (cid:9)(1)) − vπ (π (cid:9)(1)), . . . , −uπ (π (cid:9)(n)) − vπ (π (cid:9)(n))]. As for
security, we construct simulators in two distinct cases as SSF_off
protocol is asymmetric for two parties. Case 1: A is corrupted by
an adversary. We construct a simulator S1 to simulate A’s view.
For A receives L1 = [Epk (uπ (cid:9)(1) +vπ (cid:9)(1) +rπ (cid:9)(1)), . . . , Epk (uπ (cid:9)(n) +
vπ (cid:9)(n) + rπ (cid:9)(n))] from B in the real world, S1 randomly picks a set
of integers α1, · · · , αn from ZN and encrypts them by PCDD to
get L(cid:9)
= [Epk (α1), · · · , Epk (αn )]. Then, any PPT adversary cannot
1
distinguish the simulator’s encryption of the random integers (L(cid:9)
1)
from B’s encryption of the correct computation (L1) due to the
semantical security of PCDD. For the output of this protocol in the
real world [−uπ (π (cid:9)(1)) − vπ (π (cid:9)(1)), . . . , −uπ (π (cid:9)(n)) − vπ (π (cid:9)(n))], it is
clearly computational indistinguishable from the output of SSF_off ’
function. In addition, all the values in L1 and the real output are
irrelevant, and all the values in L(cid:9)
1 and the function output are
also irrelevant, so these values are computational indistinguishable.
Therefore, Equation 5 clearly holds. Case 2: B is corrupted by an
adversary. We construct a simulator S2 to simulate the message
sent by A. For B receives L0 = [Epk (u1 + r1), . . . , Epk (un + rn )]
from A, S2 randomly picks a set of integers β1, · · · , βn from ZN
and encrypts them by PCDD to get L(cid:9)
= [Epk (β1), · · · , Epk (βn )].
0
For B receives L2 from A, S2 randomly picks a set of integers
γ1, · · · , γn from ZN , then encrypts them by PCDD to get L(cid:9)
2. Any
PPT adversary who can distinguish between interaction with A
This  is  an  author-produced,  peer-reviewed  version  of  this  article.  The  final,  definitive  version  of  this  document  can  be  found  online  at  ASIACCS  '18:
Proceedings of the 2018 on Asia Conference on Computer and Communications Security, published by Association for Computing Machinery. Copyright
restrictions may apply. doi: 10.1145/3196494.3196535
, L(cid:9)
(i.e., L0, L2) and interaction with S2 (i.e., L(cid:9)
2) can be used to break
0
the semantical security of PCDD. In addition, all the above values
are selected independently. Thus, no such adversary exists, which
means Equation 6 holds. Putting the above results together, we
can claim that SSF_off is secure under the semi-honest adversary
(cid:2)
model.
Theorem B.2. The online phase of secure shuffling (short as SSF_on)
protocol is secure under the semi-honest adversaries model.
Proof. The proof of Theorem B.2 is similar to that of Theorem
B.1. Due to space limitation, we only describe the outline of our
proof: the function of SSF_on is that A and B input a secret sharing
(cid:9)(cid:5).
sequence (cid:4)x(cid:5), then A outputs a share of the shuffled sequence (cid:4)x
The exchanged messages L4 = [(cid:4)x1(cid:5) A +u1, . . . , (cid:4)xn (cid:5) A +un ] can be
simulated by randomly choosing L(cid:9)
2(cid:2) and
4
L5 = [xπ (cid:9)(1) + uπ (cid:9)(1) + vπ (cid:9)(1), . . . , xπ (cid:9)(n) + uπ (cid:9)(n) + vπ (cid:9)(n)] can be
simulated by randomly choosing L(cid:9)
2(cid:2) . So we
5
can claim that SSF_on is secure under the semi-honest adversaries
model. Please see the technical report [8] for the detailed proof. (cid:2)
= [β1, · · · , βn ] from Z
= [r1, · · · , rn ] from Z
Theorem B.3. If SSF protocol and ADD-CMP are secure under the
semi-honest adversaries model, then SBC protocol is secure under the
semi-honest adversaries model.
(cid:4) A
(cid:4) A ,
(cid:4) A
(cid:4) B ,
(cid:4) A ,
] to A and [
(cid:3)
xπ (π (cid:9)(2))
(cid:3)
xπ (π (cid:9)(2))
(cid:3)
xπ (π (cid:9)(2))
(cid:3)
xπ (π (cid:9)(1))
(cid:3)
xπ (π (cid:9)(1))
(cid:4) B
Proof. The correctness is easy to see by inspecting the out-
put (cid:4)y(cid:5) is actually assigned according to the relationship between
x1 and x2. As for security, we present the security proof in a hy-
brid model [15] where A and B have access to a trusted party
(TP) which can realize the function of SSF protocol and ADD-
CMP. A and B call TP to run the function of SSF protocol with
(cid:4) B
(cid:3)
input [(cid:4)x1(cid:5) , (cid:4)x2(cid:5)] for outputting the random permutation result
xπ (π (cid:9)(1))