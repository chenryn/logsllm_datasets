title:Foundations of Measurement Theory Applied to the Evaluation of Dependability
Attributes
author:Andrea Bondavalli and
Andrea Ceccarelli and
Lorenzo Falai and
Michele Vadursi
Foundations of measurement theory applied
to the evaluation of dependability attributes
Andrea Bondavalli,
Andrea Ceccarelli, Lorenzo Falai
University of Florence
Viale Morgagni 65, I-50134 Firenze, Italy
{bondavalli; falai}@uniﬁ.it
PI:EMAILﬁ.it
Michele Vadursi
Department of Technologies
University of Naples “Parthenope”
Via Medina 40, I-80133 Naples, Italy
PI:EMAIL
Abstract
Increasing interest is being paid to quantitative evalu-
ation based on measurements of dependability attributes
and metrics of computer systems and infrastructures. De-
spite measurands are generally sensibly identiﬁed, differ-
ent approaches make it difﬁcult to compare different re-
sults. Moreover, measurement tools are seldom recognized
for what they are: measuring instruments.
In this paper,
many measurement tools, present in the literature, are criti-
cally evaluated at the light of metrology concepts and rules.
With no claim of being exhaustive, the paper i) investigates
if and how deeply such tools have been validated in accor-
dance to measurement theory, and ii) tries to evaluate (if
possible) their measurement properties. The intention is to
take advantage of knowledge available in a recognized dis-
cipline such as metrology and to propose criteria and in-
dicators taken from such discipline to improve the quality
of measurements performed in evaluation of dependability
attributes.
1
Introduction
The key role of computing systems and networks in a
variety of high-valued and critical applications justiﬁes the
need for reliably and quantitatively assessing their charac-
teristics. The quantitative evaluation of performance and of
dependability-related attributes is an important activity of
fault forecasting [1], since it aims at probabilistically esti-
mating the adequacy of a system with respect to the require-
ments given in its speciﬁcation. Quantitative system assess-
ment can be performed using several approaches, generally
classiﬁed into three categories: analytic, simulative and ex-
perimental. Each of these approaches shows different pecu-
liarities, which determine the suitableness of the method for
the analysis of a speciﬁc system aspect. The most appropri-
ate method for quantitative assessment depends on the com-
plexity of the system, the development stage of the system,
the speciﬁc aspects to be studied, the attributes to be evalu-
ated, the accuracy required, and the resources available for
the study.
Analytic and simulative approaches are generally efﬁ-
cient and timely, and they have proven to be useful and
versatile in all the phases of the system life cycle. Ana-
lytic approach is usually cheap for manufacturers. The ac-
curacy of the results obtained through an analytic approach
is strongly dependent on the accuracy of the values assigned
to the model parameters and on how realistic the assump-
tions the system model is based on are. The simulative ap-
proach is one of the most commonly used approaches for
quantitative evaluation in practice; similarly to the analytic
approach, the accuracy of the obtained evaluation depends
on the accuracy of the assumptions made for the system to
be analyzed as well as on the behavior of the simulation
environment, and on the simulation parameters.
In the last years, increasing interest is being paid to the
quantitative evaluation based on measurements, with spe-
cial attention to evaluation of Quality of Service (QoS) met-
rics of systems and infrastructures. Experimental measure-
ment is an attractive option for assessing an existing system
or prototype. It allows monitoring the real execution of a
system to obtain highly accurate measurements of the sys-
tem in execution in its real usage environment. When pre-
senting the results achieved in the experiments, the related
authors usually choose parameters and indicators that ap-
pear sensible and represent the typical metrics of interests
for dependability. In other words, the measurands are gen-
erally correctly and sensibly identiﬁed. It has to be noted,
however, that the approach followed to quantitatively assess
algorithms and systems is not univocal. It generally varies
from a paper to another, making comparison among differ-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:37:28 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007ent results quite difﬁcult, if not meaningless. Moreover, the
attention is usually devoted only to the output, intended as
the numerical results provided by the tool, whereas little or
no attention is devoted to the (quantitative) evaluation of the
quality of the measurement. This is probably a consequence
of the fact that measurement tools designed and utilized to
evaluate dependability attributes of computer systems and
algorithms are seldom recognized for what they really are:
measuring instruments. Hence, they are not characterized
as they should, in terms of their metrological properties and
parameters. Some important characteristics are not made
explicit as they should, and remain hidden. The need for a
common roadmap to follow when characterizing a measure-
ment tool and the results it provides is becoming more and
more urgent, as this would help a more rigorous treatment
and fair comparison of the behavior of different tools.
As modern science is based on experimental evidence
[2], the science of measurement, i.e. modern metrology,
which traces its roots back to the French Revolution and
even before [3], has nowadays reached an adequate level of
maturity and has proved very useful in the application to
several ﬁelds of science. In particular, it has developed the-
ories as well as good practice rules to properly make mea-
surements and evaluate measurement results, and to cor-
rectly characterize measuring instruments and assess their
characteristics.
In the paper, computer systems and infrastructures are
looked at with the eye of the metrologist, with the intention
of highlighting the peculiarities of such modern systems,
with particular regard to the quantitative assessment of de-
pendability and QoS metrics in accordance to measurement
theory. The intention is to propose a methodology based
on criteria and indicators that are the foundations of a rec-
ognized discipline like metrology in order to compare the
results of different measurement tools, which should now
be seen as measuring instruments in all respects.
The paper is organized as follows.
In Section 2, fun-
damentals of measurement theory are introduced, and the
main metrological properties that should be analyzed to
characterize measurement results and assess the charac-
teristics of a measurement instrument are stressed. Sec-
tion 3 proposes a classiﬁcation of computer systems, from
a metrological point of view, and singles out the most im-
portant properties to be evaluated for tools and, in general,
for experimental campaigns of computing systems. In Sec-
tion 4 a number of well-known measurement tools, which
are currently present in computer science literature and are
used with success, are taken into consideration and critically
evaluated along the lines traced by metrology concepts and
rules. Without expecting to be exhaustive, the idea is to in-
vestigate if and how deeply such tools have been validated
in accordance to measurement theory, and try to evaluate
(if possible) their properties. Finally, concluding remarks
follow in Section 5.
2 Fundamentals of measurement theory for
the characterization of measurement sys-
tems
In this Section we give deﬁnitions and we describe fun-
damental concepts related to characterize measurement sys-
tems and methods according to metrological criteria. A
complete digest of metrological terms and concepts can be
found in [4].
Measuring a quantity (namely the measurand) consists
in quantitatively characterizing it. The procedure adopted
to associate quantitative information to the measurand is
called measurement. The measurement result is expressed
in terms of a measured quantity value and a related mea-
surement uncertainty.
Accuracy is a concept that is often badly used; in metrol-
ogy it must be intended only in a qualitative way. It was
formerly deﬁned as the difference between the measure and
the true value of the measurand. As it is now commonly
accepted that the true value of the measurand can not be ex-
actly known, the qualitative concept of accuracy represents
closeness of the measure to the best available estimate of
the measurand value.
Uncertainty, on the contrary, provides quantitative in-
formation on the dispersion of the quantity values that could
be reasonably attributed to the measurand. Uncertainty has
to be included as part of the measurement result and repre-
sents an estimate of the degree of knowledge of the mea-
surand.
It has to be evaluated according to conventional
procedures, and is usually expressed in terms of a conﬁ-
dence interval, that is a range of values where the measur-
and value is likely to fall. The probability that the measur-
and value falls inside the conﬁdence interval is named con-
ﬁdence level. Uncertainty can also be expressed in terms of
relative uncertainty, which is the ratio of uncertainty to the
absolute value of the estimate of the measurand.
Indirect measurements are performed when the measur-
and value is not measured directly, but it is rather deter-
mined from direct measurements of other quantities, each
of which is affected by uncertainty. Uncertainly of indi-
rect measures can be obtained in principle following sev-
eral ways. To give answer to the need for a univocal way
of evaluating uncertainty, which offers the opportunity of
comparing results from different methods and instruments,
the Guide to the expression of Uncertainty in Measurements
(GUM) has been published in 1993, and amended in 1995
[5], after years of discussions within, but not limited to, the
scientiﬁc community. Actually, since then, some supple-
ments to the GUM are being discussed, and some questions
are still open (e.g. alternative ways of evaluating uncer-
tainty in indirect measurements in particular cases).
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:37:28 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007According to the GUM, standard uncertainty, usually
indicated as u, that is uncertainty expressed as a standard
deviation, can be evaluated in two ways: i) statistically, as
an estimate of the standard deviation of the mean of a set
of independent observations, or ii) on the basis of a scien-
tiﬁc judgement using all the relevant information available,
which can include previous measurement data, knowledge
of the behavior and property of relevant materials and in-
struments, manufacturer’s speciﬁcations, data provided in
calibration and other reports, and uncertainties assigned to
reference data taken from handbooks. This second way of
evaluating uncertainty can be as reliable as the ﬁrst, espe-
cially when the independent observations are very few.
Uncertainty evaluation becomes more critical for mea-
surand estimated through indirect measurements. Speciﬁ-
cally, let Y be the measurand, which is determined through
N other quantities X1, X2, ..., XN , according to the func-
tional relation
Y = f(X1, X2, ..., XN )
(1)
which is also called measurement equation. An estimate
of Y , denoted by y, is achieved from (1) using input esti-
mates x1, x2, ..., xN for the values of the N input quantities
X1, X2, ..., XN , that is
y = f(x1, x2, ..., xN )
(2)
First of all, the standard uncertainty (i.e. the uncertainty
expressed as a standard deviation) u(xi) of each estimate xi
(i = 1, ..N) involved in the measurement function has to be
evaluated. Then, we have to compose such standard uncer-
tainty to obtain the combined standard uncertainty uc(y);
according to [5]:
vuut NX
i=1
(cid:18) ∂f
(cid:19)2
∂xi
uc(y) =
u2(xi)
(3)
are equal to ∂f
∂Xi
where the partial derivatives ∂f
evalu-
∂xi
ated in Xi = xi. Equation (3), referred to as the law of
propagation of uncertainty, is based on a ﬁrst order Taylor’s
approximation of (1). Actually, equation (3) is the simpli-
ﬁed form to be used when the estimates xi can be assumed
to be not correlated. Otherwise, a further sum involving the
estimated covariances associated with each pair (xi, xj) is
needed under the square root in (3).
Singling out the most signiﬁcant quantities of inﬂuence
is important when we have to characterize a measurement
system. These are the quantities that are not object of the
measurement, but whose variation determines a modiﬁca-
tion in the relationship between measurand and instrument’s
output. Their presence can signiﬁcantly degrade the mea-
sure, as they can represent a major cause of uncertainty.
With regard to this, selectivity of a measurement system
corresponds to its insensitiveness to quantities of inﬂuence.
In other words, the less variable are measurement system’s
outputs due to the variability of the quantities of inﬂuence,
the more selective is the system.
Resolution is the ability of a measuring system to re-
solve among different states of a measurand. It is the small-
est variation of the measurand that can be appreciated, i.e.
that determines a perceptible variation of the instrument’s
output.
Repeatability is the property of a measuring system to
provide closely similar indications in the short period, for
replicated measurements performed i) independently on the
same measurand through the same measurement procedure,
ii) by the same operator, and iii) in the same place and en-
vironmental conditions.
Stability is deﬁned as the property of a measuring sys-
tem to provide closely similar indications in a deﬁned time
period, for measurements performed independently on the
same measurand through the same measurement procedure
and under the same conditions for the quantities of inﬂu-
ence.
To characterize a measurement system, and draw a com-
prehensive comparison with alternative systems, some other
indicators should also be taken into account, such as mea-
suring interval, measurement time and intrusiveness.
The measuring interval of a measurement system is the