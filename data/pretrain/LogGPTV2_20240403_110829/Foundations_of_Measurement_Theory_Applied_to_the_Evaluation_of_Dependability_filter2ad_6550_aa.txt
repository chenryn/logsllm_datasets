# Title: Foundations of Measurement Theory Applied to the Evaluation of Dependability Attributes

## Authors:
- Andrea Bondavalli
- Andrea Ceccarelli
- Lorenzo Falai
- Michele Vadursi

### Affiliations:
- **University of Florence**
  - Viale Morgagni 65, I-50134 Firenze, Italy
  - {bondavalli; falai}@unifi.it
- **Department of Technologies, University of Naples “Parthenope”**
  - Via Medina 40, I-80133 Naples, Italy
  - michele.vadursi@uniparthenope.it

## Abstract
There is a growing interest in the quantitative evaluation of dependability attributes and metrics for computer systems and infrastructures. Despite the generally sensible identification of measurands, different approaches make it challenging to compare results. Additionally, measurement tools are often not recognized as measuring instruments, leading to a lack of proper characterization. This paper critically evaluates several measurement tools using metrology concepts and rules. It investigates the validation of these tools according to measurement theory and assesses their measurement properties. The aim is to leverage the established principles of metrology to improve the quality of measurements in the evaluation of dependability attributes.

## 1. Introduction
The critical role of computing systems and networks in various high-valued and critical applications necessitates reliable and quantitative assessment of their characteristics. Quantitative evaluation of performance and dependability-related attributes is crucial for fault forecasting, as it aims to probabilistically estimate a system's adequacy relative to its specified requirements. Several approaches can be used for quantitative system assessment, typically classified into three categories: analytic, simulative, and experimental. The choice of the most appropriate method depends on factors such as system complexity, development stage, specific aspects to be studied, required accuracy, and available resources.

Analytic and simulative approaches are generally efficient and timely, proving useful and versatile throughout the system life cycle. The accuracy of results from analytic methods is highly dependent on the accuracy of model parameters and the realism of underlying assumptions. Simulative approaches, while also widely used, have similar dependencies on the accuracy of assumptions and the behavior of the simulation environment.

In recent years, there has been increasing interest in quantitative evaluation based on measurements, particularly for Quality of Service (QoS) metrics. Experimental measurement is an attractive option for assessing existing systems or prototypes, allowing for highly accurate measurements in real usage environments. However, the lack of a standardized approach makes comparing results across different studies difficult. Moreover, the focus is often on the numerical results rather than the quality of the measurement, which is problematic since measurement tools are seldom recognized as measuring instruments. This leads to a lack of proper characterization in terms of metrological properties and parameters.

Modern metrology, rooted in the French Revolution and earlier, has reached a mature level and is valuable in various scientific fields. It provides theories and good practices for making and evaluating measurements, characterizing instruments, and assessing their characteristics. This paper applies metrological principles to the evaluation of dependability and QoS metrics in computer systems and infrastructures, proposing a methodology based on metrological criteria and indicators to compare the results of different measurement tools.

## 2. Fundamentals of Measurement Theory for the Characterization of Measurement Systems
This section introduces fundamental concepts and definitions related to the characterization of measurement systems according to metrological criteria. A comprehensive overview of metrological terms and concepts can be found in [4].

**Measurement** involves quantitatively characterizing a quantity (measurand). The result is expressed as a measured quantity value and a related measurement uncertainty.

**Accuracy** is a qualitative concept that represents the closeness of the measure to the best available estimate of the measurand value. 

**Uncertainty** provides quantitative information on the dispersion of the quantity values that could reasonably be attributed to the measurand. It is evaluated according to conventional procedures and is usually expressed as a confidence interval, indicating the range within which the measurand value is likely to fall. The probability that the measurand value falls within this interval is called the confidence level. Uncertainty can also be expressed as relative uncertainty, which is the ratio of uncertainty to the absolute value of the measurand estimate.

**Indirect measurements** are performed when the measurand value is determined from direct measurements of other quantities, each affected by uncertainty. The Guide to the Expression of Uncertainty in Measurement (GUM) [5] provides a univocal way to evaluate uncertainty, allowing for the comparison of results from different methods and instruments. According to the GUM, standard uncertainty (u) can be evaluated statistically or based on scientific judgment using all relevant information.

For indirect measurements, the combined standard uncertainty \( u_c(y) \) is calculated using the law of propagation of uncertainty, based on a first-order Taylor approximation. This equation is simplified when the estimates are assumed to be uncorrelated. Otherwise, a further sum involving the estimated covariances is needed.

**Selectivity** is the insensitivity of a measurement system to quantities of influence, which are not the object of the measurement but can affect the relationship between the measurand and the instrument's output. High selectivity indicates that the system's outputs are less variable due to the variability of these quantities.

**Resolution** is the ability of a measuring system to resolve among different states of a measurand, representing the smallest variation that can be detected.

**Repeatability** is the property of a measuring system to provide closely similar indications in the short term for replicated measurements under the same conditions.

**Stability** is the property of a measuring system to provide closely similar indications over a defined time period under the same conditions.

To comprehensively characterize a measurement system and compare it with alternatives, additional indicators such as measuring interval, measurement time, and intrusiveness should be considered.

## 3. Metrological Classification of Computer Systems
This section proposes a classification of computer systems from a metrological perspective, identifying the most important properties to be evaluated for tools and experimental campaigns. Key properties include accuracy, uncertainty, selectivity, resolution, repeatability, and stability.

## 4. Critical Evaluation of Measurement Tools
This section critically evaluates several well-known measurement tools used in computer science literature. The evaluation is based on metrological concepts and rules, investigating the validation of these tools according to measurement theory and assessing their properties.

## 5. Conclusions
The paper concludes by summarizing the key findings and highlighting the importance of applying metrological principles to the evaluation of dependability attributes in computer systems. The proposed methodology aims to improve the quality and comparability of measurement results, ensuring that measurement tools are properly characterized and validated.