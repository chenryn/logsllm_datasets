title:SpyProxy: Execution-based Detection of Malicious Web Content
author:Alexander Moshchuk and
Tanya Bragin and
Damien Deville and
Steven D. Gribble and
Henry M. Levy
SpyProxy: Execution-based Detection of Malicious Web Content
Alexander Moshchuk, Tanya Bragin, Damien Deville,
Steven D. Gribble, and Henry M. Levy
Department of Computer Science & Engineering
University of Washington
{anm, tbragin, damien, gribble, levy}@cs.washington.edu
Abstract
This paper explores the use of execution-based Web
content analysis to protect users from Internet-borne
malware. Many anti-malware tools use signatures to
identify malware infections on a user’s PC. In contrast,
our approach is to render and observe active Web con-
tent in a disposable virtual machine before it reaches the
user’s browser, identifying and blocking pages whose be-
havior is suspicious. Execution-based analysis can de-
fend against undiscovered threats and zero-day attacks.
However, our approach faces challenges, such as achiev-
ing good interactive performance, and limitations, such
as defending against malicious Web content that contains
non-determinism.
To evaluate the potential for our execution-based
technique, we designed,
implemented, and measured
a new proxy-based anti-malware tool called SpyProxy.
SpyProxy intercepts and evaluates Web content in tran-
sit from Web servers to the browser. We present the
architecture and design of our SpyProxy prototype, fo-
cusing in particular on the optimizations we developed
to make on-the-ﬂy execution-based analysis practical.
We demonstrate that with careful attention to design, an
execution-based proxy such as ours can be effective at
detecting and blocking many of today’s attacks while
adding only small amounts of latency to the browsing ex-
perience. Our evaluation shows that SpyProxy detected
every malware threat to which it was exposed, while
adding only 600 milliseconds of latency to the start of
page rendering for typical content.
1
Introduction
Web content is undergoing a signiﬁcant transforma-
tion. Early Web pages contained simple, passive con-
tent, while modern Web pages are increasingly active,
containing embedded code such as ActiveX components,
JavaScript, or Flash that executes in the user’s browser.
Active content enables a new class of highly interactive
applications, such as integrated satellite photo/mapping
systems. Unfortunately,
it also leads to new secu-
rity threats, such as “drive-by-downloads” that exploit
browser ﬂaws to install malware on the user’s PC.
This paper explores a new execution-based approach
to combating Web-borne malware. In this approach we
render and execute Web content in a disposable, iso-
lated execution environment before it reaches the user’s
browser. By observing the side-effects of the execution,
we can detect malicious behavior in advance in a safe
environment. This technique has signiﬁcant advantages:
because it is based on behavior rather than signatures,
it can detect threats that have not been seen previously
(e.g., zero-day attacks). However, it raises several cru-
cial questions as well. First, can execution-based analy-
sis successfully detect today’s malware threats? Second,
can the analysis be performed without harming browser
responsiveness? Third, what are the limitations of this
approach, in particular in the face of complex, adversar-
ial scripts that contain non-determinism?
Our goal is to demonstrate the potential for execution-
based tools that protect users from malicious content as
they browse the Web. To do this, we designed, proto-
typed, and evaluated a new anti-malware service called
SpyProxy. SpyProxy is implemented as an extended Web
proxy: it intercepts users’ Web requests, downloads con-
tent on their behalf, and evaluates its safety before re-
turning it to the users. If the content is unsafe, the proxy
blocks it, shielding users from the threat. Our intention
is not to replace other anti-malware tools, but to add a
new weapon to the user’s arsenal; SpyProxy is comple-
mentary to existing anti-malware solutions.
SpyProxy combines two key techniques. First, it ex-
ecutes Web content on-the-ﬂy in a disposable virtual
machine,
identifying and blocking malware before it
reaches the user’s browser.
In contrast, many existing
tools attempt to remove malware after it is already in-
stalled. Second, it monitors the executing Web content
by looking for suspicious “trigger” events (such as reg-
istry writes or process creation) that indicate potentially
malicious activity [28]. Our analysis is therefore based
on behavior rather than signatures.
SpyProxy can in principle function either as a service
deployed in the network infrastructure or as a client-side
protection tool. While each has its merits, we focus in
this paper on the network service, because it is more
challenging to construct efﬁciently. In particular, we de-
scribe a set of performance optimizations that are neces-
sary to meet our goals.
In experiments with clients fetching malicious Web
content, SpyProxy detected every threat, some of which
were missed by other anti-spyware systems. Our eval-
uation shows that with careful implementation, the per-
formance impact of an execution-based malware detector
can be reduced to the point where it has negligible effect
on a user’s browsing experience. Despite the use of a
“heavyweight” Internet proxy and virtual machine tech-
niques for content checking, we introduce an average de-
lay of only 600 milliseconds to the start of rendering in
the client browser. This is small considering the amount
of work performed and relative to the many seconds re-
quired to fully render a page.
The remainder of the paper proceeds as follows. Sec-
tion 2 presents the architecture and implementation of
SpyProxy, our prototype proxy-based malware defense
system. Section 3 describes the performance optimiza-
tions that we used to achieve acceptable latency.
In
section 4 we evaluate the effectiveness and performance
of our SpyProxy prototype. Section 5 discusses related
work and we conclude in Section 6.
2 Architecture and Implementation
This section describes SpyProxy—an execution-
based proxy system that protects clients from malicious,
active Web objects. We begin our discussion by plac-
ing SpyProxy in the context of existing malware defenses
and outlining a set of design goals. We next describe the
architecture of SpyProxy and the main challenges and
limitations of our approach.
2.1 Defending Against Modern Web Threats
Over the past several years, attackers have routinely
exploited vulnerabilities in today’s Web browsers to in-
fect users with malicious code such as spyware. Our
crawler-based study of Web content in October 2005
found that a surprisingly large fraction of pages con-
tained drive-by-download attacks [28]. A drive-by-
download attack installs spyware when a user simply vis-
its a malicious Web page.
Many defenses have been built to address this prob-
lem, but none are perfect. For example, many users in-
stall commercial anti-spyware or anti-virus tools, which
are typically signature-based. Many of these tools look
only for malware that is already installed, attempting the
difﬁcult operation of removing it after the fact. Firewall-
based network detectors can ﬁlter out some well-known
and popular attacks, but they typically rely on static scan-
ning to detect exploits, limiting their effectiveness. They
also require deployment of hardware devices at organi-
zational boundaries, excluding the majority of household
users. Alternatively, users can examine blacklists or pub-
lic warning services such as SiteAdvisor [41] or Stop-
Badware [43] before visiting a Web site, but this can be
less reliable [5, 44].
None of these defenses can stop zero-day attacks
based on previously unseen threats. Furthermore, sig-
nature databases struggle to keep up with the rising
number of malware variants [9]. As a result, many of
today’s signature-based tools fail to protect users ade-
quately from malicious code on the Web.
2.2 Design Goals
SpyProxy is a new defense tool that is designed for to-
day’s Web threats. It strives to keep Web browsing con-
venient while providing on-the-ﬂy protection from ma-
licious Web content, including zero-day attacks. Our
SpyProxy architecture has three high-level goals:
1. Safety.
SpyProxy should protect clients from
harm by preventing malicious content from reach-
ing client browsers.
2. Responsiveness. The use of SpyProxy should not
impair the interactive feel and responsiveness of the
user’s browsing experience.
3. Transparency. The existence and operation of
SpyProxy should be relatively invisible and com-
patible with existing content-delivery infrastructure
(both browsers and servers).
Providing safety while maintaining responsiveness is
challenging. To achieve both, SpyProxy uses several
content analysis techniques and performance-enhancing
optimizations that we next describe.
2.3 Proxy-based Architecture
Figure 1 shows the architecture of a simpliﬁed ver-
sion of SpyProxy. Key components include the client
browser, SpyProxy, and remote Web servers. When the
client browser issues a new request to a Web server, the
request ﬁrst ﬂows through SpyProxy where it is checked
for safety.
When a user requests a Web page, the browser soft-
ware generates an HTTP request that SpyProxy must in-
tercept. Proxies typically use one of two methods for
this: browser conﬁguration (specifying an HTTP proxy)
or network-level forwarding that transparently redirects
HTTP requests to a proxy. Our prototype system cur-
rently relies on manual browser conﬁguration.
ﬁrst through the front end and then through the locally
running Squid Web cache. Routing it through the front
end facilitates optimizations that we will describe in Sec-
tion 3. Routing the request through Squid lets us reduce
interactions with the remote Web server.
The browser in the VM worker retrieves and renders
the full Web page, including the root page and all embed-
ded content. Once the full page has been rendered, the
VM worker informs the front end as to whether it has de-
tected suspicious activity; this is done by observing the
behavior of the page during rendering, as described be-
low. If so, the front end notiﬁes the browser that the page
is unsafe.
If not, the front end releases the main Web
page to the client browser, which subsequently fetches
and downloads any embedded objects (Figure 1(c)).
2.3.1 Static Analysis of Web Content
On receiving content from the Internet, the SpyProxy
front end ﬁrst performs a rudimentary form of static anal-
ysis, as previously noted. The goal of static analysis is
simple: if we can verify that a page is safe, we can pass
it directly to the client without a sophisticated and costly
VM-based check. If static analysis were our only check-
ing technique, our analysis tool would need to be com-
plex and complete. However, static analysis is just a per-
formance optimization. Content that can be analyzed and
determined to be safe is passed directly to the client; con-
tent that cannot is passed to a VM worker for additional
processing.
Our static analyzer is conservative. If it cannot iden-
tify or process an object, it declares it to be potentially
unsafe and submits it to a VM worker for examination.
For example, our analyzer currently handles normal and
chunked content encodings, but not compressed content.
Future improvements to the analyzer could reduce the
number of pages forwarded to the VM worker and there-
fore increase performance.
When the analyzer examines a Web page, it tries to
determine whether the page is active or passive. Ac-
tive pages include executable content, such as ActiveX,
JavaScript, and other code; passive pages contain no such
interpreted or executable code. Pages that contain active
content must be analyzed dynamically.
It is possible for seemingly passive content to com-
promise the user’s system if the renderer has security
holes. Such ﬂaws have occurred in the past in both the
JPEG and PNG image libraries. For this reason, we con-
sider any non-HTML content types to be unsafe and send
them for dynamic processing. In principle, a browser’s
HTML processor could have vulnerabilities in it as well;
it is possible to conﬁgure SpyProxy to disable all static
checking if this is a concern.
We validated the potential beneﬁts of static checking
with a small measurement study, where we collected a
Figure 1: SpyProxy architecture. (a) A client browser re-
quests a Web page; the proxy front end intercepts the request,
retrieves the root page, and statically analyzes it for safety. (b)
If the root page cannot be declared safe statically, the front end
forwards the URL to a VM worker. A browser in the VM down-
loads and renders the page content. All HTTP transfers ﬂow
through the proxy front end and a Squid cache. (c) If the page
is safe, the VM notiﬁes the front end, and the page content is
released to the client browser from the Squid cache. Note that
if the page has been cached and was previously determined to
be safe, the front end forwards it directly to the client.
The SpyProxy front end module receives clients’
HTTP requests and coordinates their processing, as
shown in Figure 1(a). First, it fetches the root page us-
ing a cache module (we use Squid in our prototype).
If the cache misses, it fetches the data from the Web,
caching it if possible and then returning it to the front
end. Second, the front end statically analyzes the page
(described below) to determine whether it is safe. If safe,
the proxy front end releases the root page content to the
client browser, and the client downloads and renders it
and any associated embedded objects.
If the page cannot be declared safe statically, the front
end sends the page’s URL to a virtual machine (VM)
worker for dynamic analysis (Figure 1(b)). The worker
directs a browser running in its VM to fetch the requested
URL, ultimately causing it to generate a set of HTTP
requests for the root page and any embedded objects.
We conﬁgure the VM’s browser to route these requests
clientbrowserproxyfront endVMworkerWebSquidWeb cacheURLURLSpyProxyclientbrowserproxyfront endVMworkerWebSquidWeb cacheSpyProxyVMworkerSpyProxysafeproxyfront endWebSquidWeb cacheclientbrowser(a)(b)(c)rootpageURLrootpage17-hour trace of Web requests generated by the user pop-
ulation in our department. We saw that 54.8% of HTML
pages transferred contain passive content. Thus, there
can be signiﬁcant beneﬁt in identifying these pages and
avoiding our VM-based check for them.