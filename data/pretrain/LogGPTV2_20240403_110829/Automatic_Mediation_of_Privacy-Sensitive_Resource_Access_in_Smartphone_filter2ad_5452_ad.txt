the root: set υ[n] to true if the υ value is true for
all of n’s children.
The ﬁnal result is computed by running all three
steps in order and examining the result at the root
of the spanning tree.
4.3 Runtime Considerations
While much of the focus of this paper is on statically
locating placement points, choosing the right kind of
runtime instrumentation presents some interesting
challenges. We need to ensure that we are not go-
ing to induce double-prompting, as discussed in Sec-
tion 3. To do so, we maintain a “sticky” app-global
setting value in the app’s isolated storage, as illus-
trated by the following example for the ﬁne-grained
GPS location resource type:
1
2
3
4
5
6
7
8
9
10
11
12
var setting = IsolatedStorageSettings.
get_ApplicationSettings().
get_Item("UserLocationSettings");
if (setting == null){
int result = MessageBox.Show(
"Is it okay to access your fine-grained GPS location?",
"Allow "+Assembly.GetExecutingAssembly().FullName()+
" to access and use your location.",
1);
{
settings.set_Item("UserLocationSettings",
(result == 1) ? "Y" : "N");
4Note that to maximize backward placement opportuni-
ties, for all unreachable nodes, we set υ[n] to true, as shown
in Figure 9. This is because the presence of dead code should
not prevent prompt placement.
USENIX Association  
22nd USENIX Security Symposium  123
for all c ∈ children(n) do
Traverse(c)
1: function Traverse(n)
2:
3:
4: end for
5: υ[n] ← true
6:
if n (cid:29)∈ G.Background ∧ n (cid:29)∈
G.Libraries return
7:
for all c ∈ children(n) do
8:
if ¬υ[c] then
9:
υ[n] ← false
10:
return
11:
12:
end if
13: end for
14: end function
15:
1: function Collect(n)
for all c ∈ children(n) do
2:
if ¬υ[c] then
3:
υ[n] ← false
4:
return
5:
6:
end if
7: end for
8:
9: υ[n] ← true
10: end function
if ¬υ[n] then
crossEdges← CrossEdges(n)
if |crossEdges| > 0 then
υ[n] ← true
for all (cid:25)n(cid:31) → n(cid:23) ∈ crossEdges do
if ¬υ[n(cid:31)] then
υ[n] ← false
break
end if
end for
1: function PatchUp(n)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17: end if
18: end function
for all c ∈ children(n) do
PatchUp(c)
end for
end if
Step 1: Traverse
Step 2: Patch-up
Step 3: Collect
Figure 14: Three-stage backward placement algorithm explained in Section 4.2.
13
14
15
16
17
18
}
}else{
if(setting.ToString().Equals("Y")){
// proceed with the prompt
}
}
Because the prompt remains sticky application-wide
and persists across application invocations, even if
we conservatively insert an extra prompt, we will
only show it at most once per app.
5 Evaluation
We have analyzed 100 WP 7 apps from the WP
Store to collect our results. To make the analysis
more meaningful, we have selected only apps with
LOCATION and NETWORKING capabilities. Such apps
constitute about a ﬁfth of a larger set of about 2,000,
from which we drew our 100
app sample. The
goal of our evaluation is to understand how fre-
quently prompts are omitted and to attempt to in-
sert prompts in a fully automatic manner.
Characterizing the input: We ﬁrst present some
aggregate statistics of the analysis results in Fig-
ure 15. WP applications are quite substantial in size,
constituting about 3,528 methods on average. This
is in part because they rely (and therefore recursively
include within their call graph) large libraries, some
of which are part of the operating system SDK, and
others are included .NET libraries. The average size
for our apps is 7.3 MB; many consist of dozens of
DLLs.
We
in the
quently.
functionality, and many request
shown
fre-
These libraries provide advertising
location data.
discovered
inlined ﬁgure are
included most
libraries
that
the
Count
Component
42
13
10
10
10
8
7
5
5
5
SOMAWP7
NetDragon.PandaReader
EchoEchoBackgroundAgent
Utilities
BMSApp
MobFox.Ads.LocationAware
XIMAD Ad Client
EchoEcho
DirectRemote
DCMetroApp
About
7% of
all methods are
contained in back-
ground tasks or
libraries,
which
presents a signif-
icant
challenge
for prompt place-
ment.
Out of
these, most are in
fact in third-party libraries. Recall that we do not
want to place prompts in libraries. To recognize
third-party libraries in our experiments, we used a
list of 100 common advertising libraries, identiﬁed by
the DLL in which they are contained; these include
AdRotator.dll,
Microsoft.Advertising.Mobile.dll,
MobFox.Ads.LocationAware.dll,
FlurryWP7SDK.dll,
Inneractive.Nokia.Ad.dll,
adMob7.dll,
Photobucket.Ads.dll and many others. Our analysis
is parameterized with respect to this list. Frame-
works such as these may access GPS location deep
within library code, making prompt placement
analysis particularly diﬃcult.
MoAds.dll,
Our analysis represents each application as 13,330
nodes on average. Out of these, about 12% are con-
sidered to be anticipating by our analysis. In other
words, about 88% of nodes are not eligible prompt
placement points.
all
apps,
The last section of Figure 15 describes the re-
applications.
source accesses found in these 100
Across
there
are 227 resource accesses we
analyze. Overall, apps have
an average of 2.27 resource
accesses, with a maximum
of 9 for one of the apps. The ﬁgure shown inline
in this paragraph shows how frequent individual
Location
Contacts
Calendar
95.15%
4.41%
0.44%
124  22nd USENIX Security Symposium 
USENIX Association
apps analyzed
processed methods
background/library methods
library methods
nodes
anticipating
accesses
accesses in background/library methods
100
352,816
26,033
25,898
1,333,056
171,253
227
78
Figure 15: Apps analyzed: summary of input statistics.
succeeded
failed
succeeded unique
failed unique
dominator-based succeeded
na¨ıve
backward succeeded
regular
dead code
backward placements
depth exceeded
202
19
143
7
150
143
56
150
2,094
(40,270, 56)
15
Figure 16: Prompt placement: summary of results of
applying analysis to 100 apps.
resource types are. We ﬁnd that the majority of
sensitive resource accesses are to GPS location
data, with occasional accesses to user contacts and
calendar.
Inserting prompts:
Figure 16 provides statis-
tics describing the prompt placement process. Over-
all, our two-prong strategy of dominator-based and
backward placement succeeds in about 91% of all
cases. However, it is important to observe that many
cases, including challenging resource accesses deep
in library code, are shared by many applications.
To avoid double-counting, we show the number of
unique placement attempts that have succeeded and
failed. Considering these numbers of unique ac-
cesses, we are able to successfully place prompts
app loading
call graph construction
placement graph construction
anticipating computation
ﬁnding missing prompts
prompt insertion, per app
dominator-based, per access
backward, per access
Average
Max #
1,779
18,152
15,103
158
123
942
0.05
1,366
24,585
147,287
293,480
3826
100
100
100
86
649
100
70,228
1
49,277
103
221
71
Figure 17: Timing, in ms. All measurements are per
app, unless stated otherwise.
in 95% of cases (143 out of 150), a higher success
percentage. Several other lessons can be drawn from
the rest of the table:
• When dominator-based placement succeeds, it
is usually immediate (95% of all dominator-
based successes are na¨ıve successes).
• Backward placement is helpful for cases where
dominator-based placement fails.
However,
some of these cases are still too hard, leading
to 7 unique failures.
Timing: Figure 17 provides a summary of tim-
ing information for our analysis. For each mea-
surement, we provide the average timing across 100
apps, the maximum observed time and the num-
ber of observations. Each measurement in given
in ms. Overall, the most time goes into initial pro-
cessing of the application, which involves reading
it from disk, constructing a representation of the
app’s assemblies in memory (1.7 seconds on aver-
age), traversing it to create a call graph and control
ﬂow graphs (CFGs) (18 seconds on average), dom-
inator calculation, and reachability calculation, re-
sulting in a graph suitable for analysis. Computing
anticipating nodes only takes 158 ms on average.
Finding missing prompts takes about 123 ms on
average, in part because many instructions need to
be examined in search of existing prompts. Prompt
insertion, on average, is fast, only about .9 seconds
per application. Dominance-based placement is vir-
tually instantaneous. Backward placement is slower,
at 1.3 seconds per resource access, raising the aver-
age. Based on these performance numbers, we are
optimistic that prompt insertion can be done entirely
automatically over a large number of applications.
6 Discussion
We have selected static analysis as a method of