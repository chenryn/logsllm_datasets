based on MPX and MPK). Specifically, attacks can leverage
system calls to indirectly access the isolated memory region
because OS kernels have the privilege to access the entire
user space, and their code are not constrained by the address-
based and domain-based methods. For example, by specifying
the buffer address as the address of the isolated memory,
write(fd, buf, count) can read the data in the isolated
memory and write it to the file associated with fd which
can be stdout. Therefore, an attacker could launch the data-
only attacks to modify the second parameter of write to leak
the sensitive data in the isolated memory without hijacking
the control flow. Similarity, read(fd, buf, count) can be
exploited to overwrite the isolate memory by altering buf.
To address this problem, we collect all system calls that take
a memory address and a count as parameters. In the kernel
module, SEIMI dynamically checks the specified address and
the count to make sure that the specified memory range has
no overlapping with the isolated memory region; otherwise,
SEIMI immediately returns an error in the system call.
Interrupts and exceptions handling. During the execution
of the target process in SEIMI, all interrupts and exceptions
will trigger the VM exits that should be handled in SEIMI.
To realize this, SEIMI configures VMCS, so that, when an
interrupt/exception occurs, the control flow will transfer to the
SEIMI module. Then, SEIMI vectors the interrupt/exception
through the interrupt descriptor table, performs the permission
check of the target gate, and calls the corresponding handler.
Since the target process runs in ring 0, the U/S bit in the
error_code of the exception is 0 instead of 1. To ensure that
the exception handler in the kernel can handle this exception
correctly, we set the U/S bit to 1. After the handler returns, the
module executes the VMRESUME to return to the VMX non-root
mode. Note that the fault address of the page fault exception in
the isolated S-page region should be relocated to the isolated
U-page region because there is no mapping in the isolated
S-page region of the host page table, and the kernel can not
handle the exception in this region.
Linux signal handling. SEIMI naturally supports Linux
signals; it processes signals when the control flow is transferred
to the VMX non-root mode from the VMX root mode.
Specifically, the module checks the signal queue by calling the
signal_pending() function in the kernel before returning to
the VMX non-root mode. If a signal is in the queue, the module
calls the do_signal() to save the interrupted context and
switches to the context of the signal handler. After that, it sets
the new context to the VCPU, and returns to the VMX non-root
mode to execute the handler. When the handler returns, it will
be trapped into the SEIMI module through the sigreturn().
The module restores the previously saved context to the VCPU,
and then returns to the VMX non-root mode and continues.
V. IMPLEMENTATION
A. SEIMI APIs and Usage
Users can allocate and free a continuous isolated mem-
ory region by using void *sa_alloc(size_t length,
bool need_ro, long *offset) and bool sa_free(void
*addr, size_t length). If the argument need_ro is false,
sa_alloc() will only allocate an isolated U-page region, and
return the base address. If need_ro is true, it will also allocate
an isolated S-page region which is shared with the isolated
U-page region. The offset value from the isolated S-page region
to the isolated U-page region will be returned via argument
offset. Assuming that the address of sensitive data in the
isolated U-page region is addr, its address in the isolated S-
page region is addr+off. Therefore, the defense can read the
content of this sensitive data through addr+off, even if SMAP
is enabled. The program can use asm("stac\n") to disable
SMAP before accessing the isolated memory region, and use
asm("clac\n") after accessing. Since SEIMI supports all
POSIX APIs, programmers can use the Linux APIs as usual.
Given the code, SEIMI will then compile and link it into an
executable file with SEIMI’s library. In order to run the target
application in the VMX non-root mode, users should load the
kernel module of SEIMI and specify the target application
8
before running it. When the kernel module is launched, it
enables VT-x for all cores and places the current system in the
VMX root mode immediately.
B. The Start and Exit of the Target Process
Process start. Since all user applications in Linux start via the
execve() system call, the SEIMI module intercepts execve
and checks its parameters to monitor the start of the target
process by using the ftrace framework. For other processes,
the SEIMI module will deliver them to the kernel to start in
the default way—ring 3 of the VMX root mode. Upon the
start of the target process, the module first invokes the original
handler of this system call in kernel to initialize the process, and
then creates a VCPU structure (i.e., VMCS) for this process
and uses the context of the target process to initialize this
VCPU. VCPU contains the initial context when the process is
running in ring 0 of the VMX non-root mode, where the %RIP
stores the entry of the target process, and the RPL fields of
the segment selector %CS and the %SS are set to 0. Next, the
module executes the VMLAUNCH instruction to place the target
process into the VMX non-root mode. Since the RPL field of
%CS is 0, the target process will enter into ring 0.
Process exit.
the target pro-
cess,
the SEIMI module also intercepts the kernel API,
do_group_exit(). Once the exit event occurs, the module
will force the target process to exit and free the VCPU structure.
Supporting multi-threading. For multi-threaded and multi-
process applications, the SEIMI module also intercepts the
clone() system call to create and initialize a VCPU for the
child thread or process, and then places them into the VMX
non-root mode. The module also intercepts the kernel API
do_exit() to monitor the exit of the child thread or process.
Defeating the concurrent attacks. SEIMI defeats concurrent
attacks, because SEIMI creates a new VCPU for a child thread
or process, and each VCPU has independent guest registers
(including the RFLAGS register). Hence, disabling SMAP by
setting the AC flag in RFLAGS in one thread is only effective
in the current thread, but not in other threads. The thread-
independent feature also ensures that it is safe even if a VM
exit event occurred when SMAP is disabled. Furthermore, the
AC flag in the newly created VCPU is forced to be cleared
(i.e., SMAP is enabled by default).
the exit of
To monitor
C. Realizing the Secure Memory Management
The memory management component is critical to ensuring
the security of SEIMI. In §IV-A, we have introduced the
design of memory management in SEIMI. In this subsection,
we will detail some important implementation details.
Avoiding overlaps in the 254th and 255th entries of
PML4’. In order to avoid the application using the isolated
memory region, the SEIMI module prevents the stack and
ld.so from being allocated in this region by intercepting the
load_elf_binary function in the kernel and modifying the
mmap_base of this process. Since users may use the mmap()
system call to allocate a memory region at a fixed address, the
9
module also verify this system call to avoid allocating memory
in the isolated memory region.
Handling VSYSCALL. To speed up the system calls such
as gettimeofday(), Linux provides virtual system calls
(VSYSCALL) by mapping a 4KB code page called the
VSYSCALL page at the fixed address 0xFFFFFFFFFF600000.
When an application invokes these three system calls, it directly
calls the corresponding functions in this VSYSCALL page.
Since the address of the VSYSCALL page exceeds the user
space, the 511th entry of the PML4’ page is required, and the
511th entry of PML4’ points to the three level page table pages—
PDPT’, PD’, and PT’—created specifically for referencing the
VSYSCALL page. This page is set to the S-page. The reason
why the 511th entry is not copied from the PML4 page is that
there are also some pages of the kernel mapped in this entry.
Tracking updates of the PML4 page. At runtime, the kernel
may update (e.g., updating the mapping) the PML4 page in the
host page table, which requires the copied the PML4’ page in
the guest page table to be synchronized with PML4. To track
such updates, the module sets the PML4 page as read-only. This
way, any attempts to write the page will trigger page faults and
thus be intercepted by SEIMI. The interception is realized by
modifying the interrupt descriptor table (IDT). Upon
a write event, the module emulates the execution of the fault
instruction and synchronizes the PML4’ page. Since PML4 is
the page root of the page table, the kernel rarely modifies it.
Therefore, such synchronization incurs a negligible overhead.
Avoiding accessing the kernel by exploiting the TLB.
Although the kernel space is not mapped in the target process,
the target process could still access some kernel pages. This
is because some address mappings of the kernel (i.e., some
S-pages in the kernel) are residual in TLB, and these S-pages
can be accessed by the target process due to running in the S-
mode. An intuitive approach is to flush TLB during the context
switch between the target process (guest) and the kernel (host).
But it will incur high performance overhead. The Virtual
Processor Identifier (VPID) is intended for avoiding such
TLB flushing. This is done by assigning an unique VPID for
each guest VM and the host, and they can only access their own
TLB entries which are grouped by VPID. In SEIMI, each target
process (guest VM) and the kernel (host) are assigned an unique
VPID. Moreover, to synchronize the guest TLB with the page
table, SEIMI also intercepts page-table updates by using the
mmu_notifier mechanism and invalidates the corresponding
mappings in the TLB entries of the target process.
Handling API requests. Upon the call of sa_alloc(),
SEIMI will call do_mmap() in the kernel with the MAP_FIXED
flag to allocate a readable and writable virtual memory space as
the isolated U-page region in the 255th entry of the PML4’ page.
When the parameter need_ro is true, the SEIMI module will
modify the PML4’ page to make the 256th and 255th entries
point to the same PDPT page, and the 254th entry is set to the
read-only user mode entry. This way, the isolated S-page region
and the isolated U-page region differ by 512GB. Otherwise, if
need_ro is false, the SEIMI module does not modify the
254th entry, and this entry does not reference to any PDPT
page. Upon the call of sa_free(), the module will call the
do_munmap() in the kernel to free the memory region.
VI. EVALUATION
In §IV and §V, we have identified and addressed the security
threats of placing the user code in a privileged mode. Therefore,
by design, SEIMI does not introduce new security problems.
So in this section, we focus on the performance evaluation
of SEIMI. We implemented SEIMI on Ubuntu 18.04 (Kernel
4.20.3) that runs on a 2.10 GHz Intel(R) Xeon(R) Gold 6130
CPU with 32 cores and 32GB RAM.
Defenses Configuration. To evaluate the practicality and
performance of SEIMI, we adopted four IH-based defenses,
OCFI [39], ShadowStack (SS for short) [40], CPI [31], and
ASLR-Guard (AG for short) [35], and applied SEIMI to protect
their secret data, i.e., OCFI’s BLT, SS’s shadow stack, CPI’s
safe region, and AG’s safe-vault. For comparison, we also
implemented the MPX-based and MPK-based schemes for these
defenses. For SS, we adopted the compact register scheme [40]
and reserved the %R15 register in LLVM and glibc library. For
CPI, we used the optimized version of ERIM [47].
Microbenchmarks. Compared with the MPX-based scheme
and MPK-based scheme, SEIMI requires that all kernel
accesses trigger VM exits. We used lmbench [37] (v.3.0-a9)
to measure the overheads imposed by SEIMI on basic kernel
operations. To avoid mixing the overhead of domain-switching
(enable/disable SMAP), we run lmbench directly on SEIMI
to only evaluate the overhead on kernel operations.
Macrobenchmarks. To evaluate and compare the performance
of three isolation mechanisms, we chose the CPU-intensive
benchmarks, i.e., the SPEC CPU2006 C/C++ benchmarks. We
compiled them at the O2 optimization level with the link-
time optimization, and ran them with the ref dataset. We used
the four defenses, OCFI, SS, CPI, and AG, to protect each
benchmark. For each combination of benchmark and defense,
we conducted experiments for four cases: (1) protected only
by the IH-based defense, (2) protected by the MPX-based
defenses, (3) protected by the MPK-based defenses, and (4)
protected by the SEIMI-based defenses. The baseline does not
enforce any protection.
Real-world applications. Microbenchmarks and macrobench-
marks are incomplete indicators of system performance for
real workloads. To evaluate SEIMI’s robustness and impact
on real world applications, we chose 12 popular applications
used in desktop and server. They fall in three categories:
web servers, databases, and JavaScript engines. For web
servers, we use Nginx-1.4.0, Apache-2.4.38, Lighttpd-1.4
and Openlitespeed-1.4.51. For databases, we use MySQL-
5.5.14, SQLite-3.7.5, Redis-3.2.6, and Memcached-1.5.10. For
Javescript engines, we use ChakraCore (release-1.11), V8
(release-8.0), JavaScriptCore (v.251703), and SpiderMonkey
(v.59.0a1.0). Similar to macrobenchmarks, we also conduct
experiments with the four defenses and four protection cases.
10
TABLE III: Latency on process-related kernel operations (in µs);
smaller is better.
Config
open select signal signal
null null
call
0.21 0.26 0.57 1.23 5.35
0.71 0.82 1.33 2.58 6.11
sh
exec
proc
proc
870
2162
Native
SEIMI
1029 2368
Slowdown 2.4X 2.2X 1.3X 1.1X 14% 1.9X 2.1X 30.4% 18.3% 9.5%
fork
I/O stat close TCP install handle proc
355
463
0.99
3.02
0.27
0.79
A. Microbenchmarks Evaluation
Table III shows the complete test results for process-related
latency reported by lmbench, including system calls, select()
on TCP sockets, signal installation and handling, and process
creation (e.g., fork() and exec()), etc. The results show that
SEIMI incurs an overhead of 68.37% (geomean) for all test
cases. In particular, it incurs a significant overhead in handling
lightweight system calls and signals (bold font in the table).
This is in fact expected—the lightweight system call tests
(such as null call) are mainly used to test the latency of
trapping user-space program into the kernel. For example, null
call only calls getppid() which involves very little kernel
operation in a loop. In contrast, hypercalls are more expensive