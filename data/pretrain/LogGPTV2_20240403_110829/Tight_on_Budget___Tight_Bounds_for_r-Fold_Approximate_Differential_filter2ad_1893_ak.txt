T1 (ε), δlow
where δ(ε) is the tight δ as deﬁned in Lemma 1.
δlow(ε) ≤ δ(ε) ≤ δup(ε),
Proof. Lemma 1 shows that A and B are tightly (ε, δ(ε))-diﬀerentially private for
(cid:32)(cid:88)
(cid:88)
x∈U
x∈U
δ(ε) = max
(cid:33)
max (PA(x) − eεPB(x), 0) ,
max (PB(x) − eεPA(x), 0)
and Lemma 13 proves that δ(ε) ≤ δTA||B (ε) holds true (for any composition tree T and thus in particular
for TA||B).
B||A follows
Next, we show that δlow ≤ δ(ε). We show the computation for δlow
A||B, the computation for δlow
analogously:
(cid:19)(cid:19)
(cid:19)
C
TA||B
(x)
(cid:18)
+ ˜(cid:96)TA||B (i)
f i + ˜(cid:96)
(cid:18) PA(x)
(cid:18) PA(x)
f i +
PA(x) − eε
PB(x) −
PA(x)
f ιT (x)
(cid:19)(cid:19)
i∈{jε,...,n}
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
x∈U
δlow
A||B =
Lemma 8=
Lemma 11=
=
≤
≤
(cid:18)
max
0,BTA||B (i) − eε
BTA||B (i)
f i
(cid:18)
0,
0,
0,
(cid:88)
max
(cid:88)
(cid:88)
(cid:88)
max
PA(x) − eε
i∈{jε,...,n}
x∈U ,ιT (x)=i
i∈{−n,...,n,∞}
x∈U ,ιT (x)=i
max
i∈{jε,...,n}
PA(x) − eεPB(x)
x∈U ,ιT (x)=i
max (0, PA(x) − eεPB(x))
i∈{jε,...,n}
x∈U ,ιT (x)=i
max (0, PA(x) − eεPB(x))
(cid:88)
δlow
A||B ≤
max (0, PA(x) − eεPB(x)) ≤ δ(ε).
x∈U
Hence, we conclude that
the computation for δlow
B||A follows analogously, ending with δlow
B||A ≤
33
(cid:80)
x∈U
max (0, PB(x) − eεPA(x)) ≤ δ(ε).
As a result, the bounds calculated by privacy buckets constitute a sound over- and under-approximation
of the precise diﬀerential privacy values. As discussed in Section 2, such pairs of distributions can be used
to calculate diﬀerential privacy in a variety of applications. These worst-case distributions exist, e.g., in
the presence of worst-case inputs that are independent of the random coins used by the mechanism in the
previous rounds.
Deﬁnition 11 (Worst-case inputs). Inputs x0, x1 are worst-case inputs for a given sensitivity s and a
mechanism M if ∀S, Pr[M (x0) ∈ S] ≤ eε Pr[M (x1) ∈ S] + δ, implies M is (ε, δ)-ADP for all inputs with a
sensitivity of at most s.
These worst-case inputs commonly exist when diﬀerential privacy is applied (see Section 2.1) and they
enable us to directly derive the relevant distributions.
As a corollary to Theorem 2, we see that we can compute upper and lower bounds for a sequence of
privacy-enhancing mechanisms, where each of the mechanisms may be diﬀerent from the others (but known
in advance; see below for adaptive composition).
Corollary 1. Let M1, . . . , Mr be privacy-enhancing mechanisms for which there exist worst-case inputs
(x0,1, x1,1), . . . (x0,r, x1,r). Let Mi(b) be the output distribution of the mechanism Mi on input xb,i. Let T1
i=1 Mi(1) as in Deﬁnition 10. Then for every
T2 (ε)(cid:1), A and B are (ε, δup(ε))-
T1 (ε), δlow
i=1 Mi(0) and(cid:81)r
and T2 be a pair of composition trees over(cid:81)r
ε ≥ 0 and with δup(ε) = max (δT1 (ε), δT2 (ε)) and δlow(ε) = min(cid:0)δlow
distributions (cid:81)r
ADP and δlow(ε) ≤ δ(ε) ≤ δup(ε), where δ(ε) is the tight δ as deﬁned in Lemma 1.
Proof. Consider the reduction that replaces all inputs of the attacker that have a sensitivity of s with
the worst case inputs ((x0,1, x1,1), . . . , (x0,r, x1,r)) for sensitivity s. Theorem 2 gives a bound for product
i=1 Mi(x1,i). By the deﬁnition of worst-case inputs, we know that the
i=1 Mi(x0,i) and (cid:81)r
result holds for any other sequence of inputs ((x(cid:48)0,1, x(cid:48)1,1), . . . , (x(cid:48)0,r, x(cid:48)1,r)).
Heterogenous adaptive r-fold composition Bounds for (heterogenous) adaptive r-fold composition
classically only restrict mechanisms to the class of all (ε, δ)-ADP mechanisms. Thus, by choosing worst-
case mechanisms Mε,δ (see Section 2) for each step, we get a bound on for heterogeneous adaptive r-fold
composition as in [14].
When the class of mechanisms is restricted further, e.g., the structure of the mechanisms is partially
known, we suggest to derive (and prove sound) tighter worst-case mechanisms or distributions for which we
can then give signiﬁcantly better results.
4.6 Implementation
We implemented the computation of the upper and lower bounds δup(ε) and δlow(ε) from Theorem 2, and
our implementation has been re-implemented by David Sommer in Python in 405 LoC.8 Given a bucket
factor and a number of buckets n, the implementation constructs privacy buckets from any given histogram
/ distribution with a limed number of events. For Laplacian noise and Gaussian noise we have implemented
special constructors that create privacy buckets for those distributions. Our implementation adaptively
decides whether or not to perform the s-operation, i.e., to rebase the factor depending on whether the bucket
with index ∞ would otherwise grow too much. Empirically, we found that an increase of weight of the ∞
bucket by more than a factor of 2.2 is a good indicator that squaring should be performed. Additionally, we
include a parameter free infty budget that disables squaring as long as the B(∞) is below this parameter,
which is important for cases where B(∞) is initially zero or very small.
The complexity of our algorithm is dominated by the evaluation of the composition nodes, which requires
a constant amount of convolutions per node. Convolutions can be done in O(n log n) steps (using FFT-
convolution), for n buckets. The implementation does not use FFT-convolutions, due to numerical challenges,
and needs O(n2) steps. For computing r-fold ADP O(log r) composition computations are necessary, totalling
O(log r · n log n), for r-fold ADP with n privacy buckets and O(log r · n2) in the prototype.
On a Lenovo ThinkPad X250 (2.6 GHz Intel Core i5 with and 8 GB RAM) computing 218 = 262, 144 com-
positions with 100, 000 buckets took around 3 minutes and 57 seconds by using repeated squaring (13 seconds
8The
implementation
is
available
here, which
includes
an FAQ about
further
practical
aspects
[19]:
https://github.com/dabingo/privacybuckets
34
per composition operation): we compose the bucket distribution with itself in each round, thus calculating
2r compositions in r composition steps. For 10, 000 buckets we achieve tight bounds for 29 compositions and
only need 1.2 seconds, i.e., 0.13 seconds per composition operation. The implementation adaptively decides
whether or not to perform the squaring operation if B(∞) would otherwise grow signiﬁcantly, as described
in Figure 10.
5 Evaluation and comparison
We compute results for several distributions (modeling the Laplacian mechanism, the Gauss mechanism, real-
world leakage data from CoverUp [24], the randomized response, and the stochastic gradient descent mech-
anism [1]) and compare our results with bounds from previous work, such as Kairouz, Oh and Viswanath’s
composition theorem and methods based on R´enyi divergence.
We consider the following other bounds in our evaluation: Kairouz, Oh and Viswanath’s composition
theorem [14] (KOV), the moments accountant [1] (MA), which derives exactly the same bounds as R´enyi
diﬀerential privacy [20], and concentrated diﬀerential privacy [7, 2].
In these evaluations, we illustrate two advantages of our approach: (i) (ε, δ)-graphs for a ﬁxed number of
compositions highlight that we achieve signiﬁcantly reduced δ-bounds for very small eε; (ii) plots about eε-
bounds for a ﬁxed bound on δ but a growing number of compositions illustrate that we achieve signiﬁcantly
reduced eε-bounds.
We now discuss how to embed the mechanisms into our buckets and then visualize the diﬀerence between
the diﬀerent bounds in one (ε, δ)-graph each. Each such graph shows which values for δ can be achieved for
a given value of  after a number of compositions.
5.1 Embedding the Laplace mechanism
We analyze the Laplace mechanism, the classical mechanism to achieve DP, by comparing two distributions
of Laplace noise with means 0 and 1 respectively. This case corresponds to many applications of the Laplace
mechanism for DP, such as counting queries for databases with sensitivity 1. We choose in our case study
a Laplace distribution with mean µ = 0 and scale factor γ = 200, denoted as LP(µ, γ). As a result, an
attacker either makes observations from LP(0, 200) or from LP(1, 200) (as the sensitivity is 1). We consider
truncated Laplace distributions, since that corresponds closer to real-world applications. If not mentioned
otherwise, we truncate at µ − 2500 and µ + 2500.
We want to give strong evidence that both Kairouz et al.’s composition theorem and our privacy buckets
are tight for the bounds of the Laplace mechanism. As a consequence, we carefully embed the Laplace
mechanism in a way that has a small discretization error. The bucket method introduced in Deﬁnition 7
iterates over all atomic events in the support of the distributions. For modeling the Laplace distribution,
or rather, two Laplace distributions A and B, we consider the quotients of the probability mass functions
and integrate distribution A over the range of events that fall into each bucket: for B(i) we integrate over
all events x such that f i  µ2, the right bucket border rbb(i) is the x such that
e(2x−µ1−µ2)ε =f i = e(iε/gr) =: ej
⇔ (2x − µ1 − µ2)ε =j
⇔ (2x − µ1 − µ2) =j/ε
⇔ 2x =µ1 + µ2 + j/ε
⇔ x =(µ1 + µ2 + j/ε)/2
(iε/gr)
⇔ x =(µ1 + µ2 +
⇔ x =(µ1 + µ2 + i/gr)/2
=⇒ rbb(i) =1/2(µ1 + µ2 + i/gr)
ε
)/2
=⇒ rbb(i − 1) =1/2(µ1 + µ2 + i/gr − 1/gr)
=rbb(i) − 1/(2gr)
=lbb(i)
For µ1 < µ2, the right bucket border rbb(i) is the x such that
e(−2x+µ1+µ2)ε =f i = e(iε/gr) =: ej
⇔ (−2x + µ1 + µ2)ε =j
⇔ (−2x + µ1 + µ2) =j/ε
⇔ 2x =µ1 + µ2 − j/ε
⇔ x =(µ1 + µ2 − j/ε)/2
(iε/gr)
⇔ x =(µ1 + µ2 −
⇔ x =(µ1 + µ2 − i/gr)/2
=⇒ rbb(i) =1/2(µ1 + µ2 − i/gr)
ε
)/2
=⇒ rbb(i − 1) =1/2(µ1 + µ2 − i/gr + 1/gr)
=rbb(i) + 1/(2gr)
=lbb(i)
As a result, the bucket i has the value(cid:82) rbb(i)
We compute the error correction term as (cid:96)(i) :=(cid:82) rbb(i)
Laplace(µ1, 1/) and to B(i) we add (cid:82) ∞
(cid:82) rbb(−i)
virtual error from this term.
lbb(i)
(cid:16)
lbb(i) Laplace(µ1, 1/).
B(x) − A(x)
f i
For the buckets with index ±i s.t. f i = eε we integrate over the respective remaining areas B(−i) =
rbb(i) Laplace(µ1, 1/). As we chose f to ﬁt eε the events in
−∞
these regions exactly have the respective quotient of the bucket and we don’t have errors for these integrals.
Consequently, the error terms for bucket B(−i) are zero and the error terms for bucket B(i) are composed