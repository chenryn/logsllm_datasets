title:Robust Adversarial Attacks Against DNN-Based Wireless Communication
Systems
author:Alireza Bahramali and
Milad Nasr and
Amir Houmansadr and
Dennis Goeckel and
Don Towsley
Robust Adversarial Attacks Against
DNN-Based Wireless Communication Systems
Alireza Bahramali
Milad Nasr
University of Massachusetts Amherst
University of Massachusetts Amherst
University of Massachusetts Amherst
PI:EMAIL
PI:EMAIL
Amir Houmansadr
PI:EMAIL
Dennis Goeckel
Don Towsley
University of Massachusetts Amherst
University of Massachusetts Amherst
PI:EMAIL
PI:EMAIL
ABSTRACT
There is significant enthusiasm for the employment of Deep Neural
Networks (DNNs) for important tasks in major wireless commu-
nication systems: channel estimation and decoding in orthogonal
frequency division multiplexing (OFDM) systems, end-to-end au-
toencoder system design, radio signal classification, and signal
authentication. Unfortunately, DNNs can be susceptible to adver-
sarial examples, potentially making such wireless systems fragile
and vulnerable to attack. In this work, by designing robust adver-
sarial examples that meet key criteria, we perform a comprehensive
study of the threats facing DNN-based wireless systems.
We model the problem of adversarial wireless perturbations as an
optimization problem that incorporates domain constraints specific
to different wireless systems. This allows us to generate wireless
adversarial perturbations that can be applied to wireless signals
on-the-fly (i.e., with no need to know the target signals a priori),
are undetectable from natural wireless noise, and are robust against
removal. We show that even in the presence of significant defense
mechanisms deployed by the communicating parties, our attack
performs significantly better compared to existing attacks against
DNN-based wireless systems. In particular, the results demonstrate
that even when employing well-considered defenses, DNN-based
wireless communication systems are vulnerable to adversarial at-
tacks and call into question the employment of DNNs for a number
of tasks in robust wireless communication.
CCS CONCEPTS
• Security and privacy → Mobile and wireless security.
KEYWORDS
Wireless Communication Systems; Adversarial Examples; Universal
Perturbations; Deep Neural Networks
ACM Reference Format:
Alireza Bahramali, Milad Nasr, Amir Houmansadr, Dennis Goeckel, and Don
Towsley. 2021. Robust Adversarial Attacks Against DNN-Based Wireless
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea
© 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-8454-4/21/11...$15.00
https://doi.org/10.1145/3460120.3484777
Communication Systems. In Proceedings of the 2021 ACM SIGSAC Conference
on Computer and Communications Security (CCS ’21), November 15–19, 2021,
Virtual Event, Republic of Korea. ACM, New York, NY, USA, 15 pages. https:
//doi.org/10.1145/3460120.3484777
1 INTRODUCTION
Deep Neural Networks (DNNs) are becoming central to various
key wireless communication systems, thanks to their promising
performances, and their computational efficiency. In particular,
the wireless community has leveraged DNNs in state-of-the-art
autoencoder wireless communication systems [18, 21, 29, 33, 34,
37], modulation recognition (radio signal classification) [31, 38, 39,
41, 48], and OFDM channel estimation and signal detection [49,
50]. Such wireless systems are crucial to various applications; for
example, OFDM is a popular modulation scheme that has been
widely used in many existing standards, such as 4G LTE and the
IEEE 802.11 family [20, 22], and new standards such as 5G [9].
Unfortunately, whereas there is significant enthusiasm for the
employment of DNNs [6], such emerging DNN-based wireless sys-
tems face a security threat: DNNs are known to be susceptible to
adversarial examples [11, 17, 32], i.e., small perturbations added to
the inputs of a DNN causing it to misclassify the perturbed inputs;
consequently, DNN-based wireless communication systems are also
susceptible to such attacks, which may impact the security (e.g., cor-
rectness, availability) of such systems. And, due to the penetration
of these techniques in both contemporary military and commercial
systems, the cost could be devastating. For example, robust attacks
on modulation classification could compromise the performance
of commercial software-defined radios or the ability of a military
system to detect, intercept, and/or jam an enemy [10]. Importantly,
particularly if the attack on the modulation classifier is undetectable
as for our scheme proposed here, such a compromise can impact
important tactical decisions based on enemy status. In the multitude
of systems where OFDM plays a key role, an unexpected high bit-
error-rate at the receiver due to adversarial perturbations can cause
significant disruption; for example, the impact on the performance
of the 4G Internet, which is tuned carefully at multiple levels to
anticipate users’ performance based on system state measurements,
would be significant.
In this paper, by first identifying key criteria of an
Our work:
effective adversarial attack and then designing based on such, we
perform the first comprehensive study of the effect of adversarial
examples against DNN-based wireless systems. In this setting, the
goal of an attacker is to transmit a well-crafted perturbation signal
Session 1B: Attacks and Robustness CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea126over a channel so that the underlying DNN-based wireless system
(e.g., a radio signal classifier) fails and misclassifies the perturbed
signals. Note that while there exists a large body of work on adver-
sarial examples against image classification tasks, e.g., FGSM [17],
such works cannot be trivially applied to the setting of wireless
systems where the input signals to be perturbed are unknown to the
adversary. Recent work [1, 12, 23, 24, 42–44] has aimed at imple-
menting adversarial examples on wireless systems; however, none
of them are practical as they ignore domain constraints of wireless
systems.
Therefore, in this work we present a systematic and generic mech-
anism for generating adversarial examples against DNN-based wire-
less systems, with the goal of generating adversarial perturbations
that satisfy the domain constraints of wireless systems. Specifically,
we present a generic framework that models the problem as an
optimization problem and incorporates domain constraints spe-
cific to target wireless systems. We particularly enforce three key
constraints in generating wireless adversarial examples: first, they
should be input-agnostic meaning that the attacker generates the
perturbation signal without any knowledge about the incoming
(unknown) input wireless signals. This is essential as, unlike tra-
ditional targets of adversarial examples (e.g., image classification
tasks), in DNN-based wireless systems the signal to be perturbed
is not known a priori to the adversary. We particularly build on
Universal Adversarial Perturbations (UAPs) [32], a recent adver-
sarial perturbation approach that is input-agnostic. Second, the
perturbation should be undetectable in that one should not be
able to distinguish between a generated adversarial perturbation
and natural noise expected from the wireless channel; otherwise,
a defender can design a classifier to identify (then, remove) the
adversarial perturbations based on the perturbation’s power or
statistical behavior. Finally, the wireless perturbations need to be
robust against countermeasures meaning that the defender (e.g.,
a wireless decoder) should not be able to remove the perturbation
from the received signal. Our framework is generic and can be
used to enforce other domain constraints needed for a target wire-
less application, e.g., we also need to design in the presence of an
unknown phase rotation between the attacker and the receiver.
Below, we describe how we enforce each of the three key wireless
domain constraints through our generic optimization problem.
Generating input-agnostic perturbations. We model the prob-
lem of adversarial wireless perturbations as an optimization prob-
lem, and solve it to produce a perturbation generator model (PGM)
able to generate an extremely large number of input-agnostic ad-
versarial examples vectors (i.e., UAPs) for the target wireless appli-
cation. Therefore, instead of applying a single UAP vector (that can
be easily identified and removed as we show through experiments),
in our setting the attacker picks and applies a random UAP adver-
sarial example from a very large set of available UAPs produced by
our PGM. We also show that our PGM is effective in a black-box
scenario where the attacker generates adversarial perturbations
based on a DNN substitute model and uses them to attack the orig-
inal wireless DNN model. Our experiments demonstrate that our
techniques outperform state-of-the-art adversarial attack works - es-
pecially in the presence of defense mechanisms. Note that recent
works [12, 42] also use a DNN model to generate perturbations;
however, they do not provide undetectability and robustness for
perturbations, and they only consider a white-box scenario where
the adversary is aware of the target wireless DNN model.
Undetectability. We tailor our PGM to each target wireless com-
munication system by enforcing constraints specific to such sys-
tems, with the goal of making the attack undetectable. In particu-
lar, we use generative adversarial networks (GAN) to enforce an
undetectability constraint on the UAPs generated by our PGM,
and constrain them to follow a Gaussian distribution, which is
the expected noise distribution for additive white Gaussian noise
(AWGN) wireless channels. We show that by using such an unde-
tectability constraint, the PGM can completely fool a discriminator
function, i.e., a DNN classifier that tries to distinguish between
adversarial perturbations and natural Gaussian noise. Based on
our experiments, enforcing our undetectability constraint can de-
crease the 𝑓 1_𝑠𝑐𝑜𝑟𝑒 of the discriminator from 0.99 to 0.6 (where an
𝑓 1_𝑠𝑐𝑜𝑟𝑒 = 0.5 is the best undetectability as it represents random
guessing) with only a slight degradation in the performance of our
attack. The score can be further decreased at the cost of further
attack performance degradation.
Robustness. We also enforce a robustness constraint on the UAPs
generated by our PGM. This constraint aims at maximizing the
distances between different UAPs generated by our PGM; this is
because if the UAPs are similar, as we show, an adversary can
remove their effect with the knowledge of as little as a single pilot
UAP vector. We analyze the robustness of our attack in different
scenarios (Adversarial Training and Perturbation Subtraction) based
on different amounts of knowledge available to the defender, and
show that it provides high robustness against defense techniques;
by contrast, we show that a single vector UAP, as proposed in
previous work [43, 44], can be trivially detected and removed. Our
analysis suggests that even if a defender has knowledge about the
structure of our PGM, she will not able to mitigate the effects of
the attack.
Evaluation on major wireless systems. We have implemented
and evaluated our attacks on three classes of DNN-based wireless
systems, specifically, autoencoder communication systems [18, 21,
29, 33, 34, 37], radio signal classification [31, 38, 39, 41, 48], and
OFDM channel estimation and signal detection [49, 50]. We show
that for all three applications, our attack is highly effective in corrupt-
ing the functionality of the underlying wireless systems, and at the
same time offers strong undetectability and robustness.
We also propose two countermeasures, Adversarial Training
and Perturbation Subtraction, based on the knowledge of a defender
about the attack. We evaluate the performance of our attack and
the single vector UAP attack against our own countermeasures as
well as an existing countermeasure from the literature [23] called
randomized smoothing. Our results show that our attack provides
higher robustness against these countermeasures than previous ad-
versarial attacks such as the single vector UAP attack. For instance,
for the autoencoder communication system, in the presence of an
adversarial training defense, our attack can increase the block-error
rate (BLER) by four orders of magnitude with a perturbation-to-
signal ratio (PSR) of −6𝑑𝐵. However, with a similar PSR, the single
vector UAP attack [43, 44] is ineffective in the presence of the same
Session 1B: Attacks and Robustness CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea127defense mechanism. Similarly, in the OFDM application, our at-
tack results in a 9X increase in bit error rate while the impact of a
single vector UAP is negligible. Furthermore, our attack is robust
to the presence of a perturbation subtraction defense (as will be
introduced), e.g., in the modulation recognition task, our attack
reduces classification accuracy from 0.69 to 0.23 despite the defense
mechanism (by contrast, the single UAP attack is not effective as it
reduces accuracy from 0.69 to only 0.67).
In summary, we make the following major contributions:
• We propose an input-agnostic, undetectable, and robust ad-
versarial attack against DNN-based wireless communication
systems. We show that our attack is more effective than pre-
vious attacks; in particular, our results indicate that our PGM
attack is more robust than using a single vector UAP attack
against different countermeasures.
• We evaluate our attack against three classes of wireless sys-
tems by performing extensive experiments, hence showing
that our PGM attack is not specific to a DNN-based wire-
less application and can be generalized to any DNN-based
wireless application system.
• To our knowledge, we are the first to apply adversarial at-
tacks against DNN-based OFDM channel estimation and
signal detection systems, which comprise the physical layer
in contemporary WiFi and cellular systems.
• We propose different countermeasure techniques and eval-
uate the robustness of the target wireless systems against
adversarial attacks. We also compare the robustness of our
attack to previous adversarial attacks in wireless systems
and show that our attack is more robust against different
countermeasures than previous attacks that are based on a