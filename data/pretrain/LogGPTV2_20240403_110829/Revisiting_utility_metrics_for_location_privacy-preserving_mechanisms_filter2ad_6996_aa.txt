title:Revisiting utility metrics for location privacy-preserving mechanisms
author:Virat Shejwalkar and
Amir Houmansadr and
Hossein Pishro-Nik and
Dennis Goeckel
Revisiting Utility Metrics for Location
Privacy-Preserving Mechanisms
Virat Shejwalkar
Information and Computer Science
University of Massachusetts, Amherst
PI:EMAIL
Hossein Pishro-Nik
Electrical and Computer Engineering
University of Massachusetts, Amherst
PI:EMAIL
Amir Houmansadr
Information and Computer Science
University of Massachusetts, Amherst
PI:EMAIL
Dennis Goeckel
Electrical and Computer Engineering
University of Massachusetts, Amherst
PI:EMAIL
ABSTRACT
The literature has extensively studied various location privacy-
preserving mechanisms (LPPMs) in order to improve the location
privacy of the users of location-based services (LBSes). Such privacy,
however, comes at the cost of degrading the utility of the under-
lying LBSes. The main body of previous work has used a generic
distance-only based metric to quantify the quality loss incurred
while employing LPPMs. In this paper, we argue that using such
generic utility metrics misleads the design and evaluation of LPPMs,
since generic utility metrics do not capture the actual utility per-
ceived by the users. We demonstrate this for ride-hailing services,
a popular class of LBS with complex utility behavior. Specifically,
we design a privacy-preserving ride-hailing service, called PRide,
and demonstrate the significant distinction between its generic and
tailored metrics. Through various experiments we show the sig-
nificant implications of using generic utility metrics in the design
and evaluation of LPPMs. Our work concludes that LPPM design
and evaluation should use utility metrics that are tailored to the
individual LBSes.
CCS CONCEPTS
• Security and privacy → Privacy-preserving protocols; Us-
ability in security and privacy; Social network security and pri-
vacy; Pseudonymity, anonymity and untraceability.
KEYWORDS
Location Privacy-Preserving Mechanisms, Location Based Services,
Utility Metrics, Ride Hailing Services
ACM Reference Format:
Virat Shejwalkar, Amir Houmansadr, Hossein Pishro-Nik, and Dennis Goeckel.
2019. Revisiting Utility Metrics for Location Privacy-Preserving Mechanisms.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
© 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-7628-0/19/12...$15.00
https://doi.org/10.1145/3359789.3359829
In 2019 Annual Computer Security Applications Conference (ACSAC ’19), De-
cember 9–13, 2019, San Juan, PR, USA. ACM, New York, NY, USA, 15 pages.
https://doi.org/10.1145/3359789.3359829
1 INTRODUCTION
Various location-based services (LBS) require their users’ location
information to operate. Such LBSes range from ride-hailing services
like Uber to fitness applications like FitBit to recommendation sys-
tems like Yelp. Unfortunately, the platforms hosting such LBSes, e.g.,
cellphone operating systems, share fine-grained locations of users,
which, in many cases, are more accurate than what is required by
the LBSes to operate. For instance, a typical weather app LBS gets
access to users’ accurate locations, although it can function prop-
erly even with less accurate location information. To address this,
the research community has investigated various location-privacy
preserving mechanisms (LPPMs) [1, 5, 18, 20, 21], which aim to
constrain the location information revealed to LBSes. The common
techniques deployed by existing LPPMs are anonymization and
obfuscation techniques, for instance location truncation, cloaking,
generalization, and additive noise [1, 6, 13, 20, 27].
LPPM techniques improve privacy by trading off the utility of
the underlying LBSes. For instance, a point of interest (POI) search
LBS is likely to produce less useful recommendations when pro-
vided with inaccurate user locations. Previous work has used dif-
ferent metrics to quantify the impact of LPPMs on the privacy
and utility of LBS services. Specifically, privacy has been quan-
tified with metrics such as adversarial inference error [27], geo-
indistinguishability [1], k-anonymity [13], conditional entropy [20],
mutual information [18], and plausible deniability [3]. On the other
hand, previous work has mainly used a generic, distance-based met-
rics to quantify the impact of LPPMs on utility. Such generic metrics
measure the distance, e.g., Euclidean or squared Euclidean distance,
between the real and obfuscated locations. The use of this distance-
based utility metric is motivated by the intuition that the perfor-
mance of an LBS is highly correlated with obfuscation amplitudes,
e.g., increasing the obfuscation distance in a POI search LBS will
degrade its utility by decreasing the quality of its recommenda-
tions [10].
In this paper, we challenge the community’s common use of a
generic distance-based utility metric in designing and evaluating
LPPMs. We argue that a generic distance-only-based utility metric
does not capture the actual utility perceived by users of the underly-
ing LBSes; this leads to LPPM designs being suboptimal with respect
to the perceived utility. Therefore, we argue for using application-
tailored utility metrics as opposed to generic (distance-only-based)
utility metrics. An application-tailored utility metric (simply called
tailored metric) aims at capturing the in-the-wild utility perceived
by LBS users, and therefore is defined differently for different LBS
systems. For instance, the tailored utility metric of a ride-hailing
service like Uber should capture the time it takes for a rider to com-
plete a ride, and the tailored utility metric of a fitness application
should capture the burned calories (among other things); for both
of these applications, distance is one of the features contributing
to the perceived utility, but is not the only feature (as in generic
utility metrics).
We demonstrate the implications of using tailored versus generic
utility metrics by focusing on ride-hailing services (RHS). We choose
RHS due to the complexity of their perceived utility, which can
better demonstrate the distinction between tailored and generic
utility metrics. However, our conclusions apply to any LBS with
a utility metric/s that depends on parameters more than just the
distance between real and obfuscated locations. We design a privacy-
preserving RHS, called PRide, and define tailored and generic utility
metrics for it. Our tailored metric captures the total time for ride
completion and accounts for factors including surge pricing, be-
haviour and distribution of drivers.
A challenge to evaluating tailored metrics is the lack of public
real-world LBS data (e.g., ride-hailing services do not make riding
traces available to the public due to privacy and IP reasons). To
overcome this challenge, we build an RHS emulator RHSE, which
synthesizes RHS data and can be adjusted to various RHS envi-
ronments and emulate different types of RHSes. We use our RHSE
emulator to study multiple RHS environments for PRide, and com-
pare the implications of tailored versus generic utility losses using
state-of-the-art LPPM techniques [1, 5]. Our evaluations demon-
strate that the utilities quantified using tailored and generic metrics
are significantly different; therefore, using different utility metrics
to deign LPPMs (i.e., optimizing privacy for a target utility or vice-
versa) will result in substantially different LPPM parameters. We
also show that using generic versus tailored metrics significantly
impacts the outputs of the state-of-the-art utility improvement tech-
niques, and that different utility losses associated with a given LBS
should be combined according to user preferences for the utility
improvement to be more effective and user-centric. To summarize,
we make the following contributions:
• We demonstrate that the generic distance-only based metric,
commonly used by the community to evaluate and design
LPPMs, offers an incorrect perception of the actual utility
perceived by users in practice. We therefore argue for the
need to derive and use tailored utility metrics in the design,
evaluation, and comparison of LPPM techniques for LBS
services.
• We choose ride-hailing services to demonstrate the impli-
cations of generic versus tailored utility metrics, due to the
complex nature of utility in such services. Towards this,
we design a privacy-preserving ride-hailing protocol called
PRide, discuss its privacy guarantees, and define a tailored
utility metric for it.
• To overcome the lack of public real-world RHS data, we im-
plement an RHS emulator, RHSE, that can emulate different
RHS systems and environments.
• We perform extensive evaluations using our emulation of
PRide. We demonstrate that the generic utility metric does
not capture various important parameters of PRide that
contribute to its in-the-wild utility; this motivates the need
for tailored utility metrics in the design and evaluation of
LPPMs.
Organization. The rest of this paper is organized as follows: § 2
reviews privacy and utility loss metrics from the previous literature
and § 3 describes preliminaries. § 4 details the privacy preserving
RHS, PRide, used to demonstrate our claims. § 5 details the RHS
emulator, RHSE, built for data synthesis. § 6 details experiments on
PRide data synthesized using RHSE along with results and their
implications. § 6.6 introduces comprehensive utility loss and details
its effects on the utility improvement techniques. We conclude the
work in § 7.
2 RELATED WORK AND MOTIVATION
We briefly review the privacy and quality loss (QL) metrics proposed
in the literature. We use the term quality loss to quantify utility
degradation.
Various metrics have been proposed to quantify privacy improve-
ments of LPPMs. Gruteser et al. [13] propose k-anonymity which
provides privacy by adding a user’s location to a set of other (k − 1)
users’ locations. Shokri et al. [27] argue that the privacy of a user
is the inference error of the adversary, and propose adversarial
inference error as the privacy metric. Oya et al. in [20] propose
conditional entropy as a complementary metric to adversarial infer-
ence error to narrow the spectrum of optimal mechanisms for given
QL expectation. Andres et al. [1] propose Geo-indistinguishability
based on differential privacy [5, 10, 20, 21]. Similar to the differential
privacy, it abstracts from the prior of the adversary and is robust
with respect to composition. Due to the simplicity and theoretical
guarantees of attaining privacy by adding Laplacian noise, Geo-
indistinguishability is widely adopted by many tools, viz. Location
Guard [1], LP-Guarding [12], and LP-Doctor [11].
Unlike privacy metrics, only a few QL metrics are proposed,
which are variants of the Euclidean distance metric. Andres et al. [1]
quantify QL of POI search LBS using (C, radI )-accuracy but without
capturing the user preferences which can significantly affect QL
improvement techniques [5] as we show in § 6.6. Chatzikokolakis
et al. [5] propose a QL improvement by remapping obfuscated
locations and evaluate using Euclidean distance as a QL metric. We
provide empirical evidence that remapping using one QL metric
can prove suboptimal towards other viable QLes in an LBS(§ A.2.2).
Given the Euclidean distance-based QL constraints, Shokri et al. [28]
construct the optimal LPPM against an optimal inference attack
adversary. Oya et al. [20] consider average and worst case Euclidean
distance as QL metrics.
Only a few works explicitly consider factors affecting the QL of
specific applications to evaluate LPPMs. Micinski et al. [17] study
POI search LBSes using three metrics namely, edit distance between
the lists, overlap between retrieved results and the additional dis-
tance required to reach the closest entry on the list. Bilogrevic
Table 1: Privacy and quality loss metrics used in previous location privacy research
Previous work
Shokri [27]
Andres [1]
Chatzikokolakis [5]
Bilogrevic [2]
Application
None
POI retrieval
Check-ins
Check-ins
Shokri [28]
Fawaz [12]
Micinski [17]
Pham [22, 23]
Oya[20]
None
POI, Healthcare
POI retrieval
RHS
None
LPPM
Cloaking, precision reduction
Laplace noise
Laplace noise
Semantic/geographical
obfuscation
Cloaking, precision reduction
Laplace noise,
precision reduction
Cloaking
Cloaking
Laplace noise
Privacy metric
Adversarial inference
Differential privacy
Differential privacy
None
QL metric
None
Squared Euclidean
Euclidean
Check-in motivations
Adversarial inference
Differential privacy
Euclidean
User survey
None
N/A
Differential privacy,
conditional entropy
Retrieved sets’ overlap
N/A
Average Euclidean,
worst case Euclidean
et al. [2] introduce perceived utility metric for check-in services
based on different categories of motivations. However, the QL met-
rics considered will fail in the case of continuous LBS such as
RHS because applying semantic obfuscation has no effect on the
QLes encountered commonly in continuous LBS. Hence, evaluat-
ing LPPMs for continuous LBS vs for static/one-time LBS, such as
POI search, is different from the point of view of QL metrics. The
work in [2] is based on a user survey which is a gruesome task;
therefore, such works need to devise QLes tailored to applications
and release them to the community for further research. Oya et
al. [21] reconsider privacy vs QL trade-offs of LPPMs that guarantee