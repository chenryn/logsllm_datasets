called same-time OPE security, which requires that an
adversary can learn the order only for items that are stored in
the application at the same time. This deﬁnition is stronger
than IND-OCPA, and we show how an extension of mOPE
achieves this stronger deﬁnition.
Since none of the prior schemes achieve the ideal IND-
OCPA goal, they put forward a variety of alternative security
deﬁnitions. For example, Boldyreva et al. [6] deﬁne the
notion of a random order-preserving function (ROPF), and
construct an OPE scheme that is indistinguishable from a
ROPF, which we will call BCLO [6]. Yum et al. [40] improve
the performance of BCLO. It was subsequently shown that
the ROPF deﬁnition inherently reveals more than order—in
fact, at least half of the plaintext bits [7, 24, 25].
Other schemes either provide weaker security deﬁnitions
by making assumptions about attacks, which are unlikely to
hold in practice, or do not provide a security deﬁnition or
guarantees at all [1–3, 20, 21, 23, 26, 27, 30, 38, 39, 39, 40].
For example, Xiao et al. deﬁne IND-OLCPA security by
requiring that the adversary learns the encryptions only for
“nearby” values [39], although it is unclear how a practical
system would enforce this. Other security deﬁnitions assume
that adversaries are restricted to a speciﬁc attack strategy, or
that they do not have any additional side information about
the values being encrypted, which is similarly hard to ensure
in practice. Thus, while such schemes make the job of the
adversary more difﬁcult, the level of security they provide is
hard to quantify, and many of them allow an adversary to
extract a signiﬁcant amount of information on top of order.
To understand how an adversary can learn additional
information from schemes without rigorous guarantees,
consider the scheme of Liu and Wang [26], which works
as follows. The secret key consists of two integers a and b
and the encryption of a value v is av + b + noise, for some
randomly chosen noise ∈ {0, . . . ,a − 1}, small enough to
preserve order. Note that a and b are the same across all
encryptions. Intuitively, this scheme is insecure because a
and b are a one-time pad that is being reused many times.
To attack Liu and Wang’s scheme, suppose an attacker
obtains two pairs of plaintexts and ciphertexts: c1 is the
encryption of 0 (i.e., c1 = b + n1 for some noise n1), and
c2 is the encryption of k, where k is some large value (i.e.,
c2 = ak + b + n2). By computing the difference between c2
and c1, the attacker obtains c2 − c1 = ak + n2 − n1, and since
0 ≤ n1,n2  32, the client requests the right
child of the root from the server, and the server responds with
x27716c, which the client decrypts to 69. Finally, the client
requests the left child of the last node requested, and the
server responds that there is no such child. This means that
the client can insert a new node in this position, containing
the DET encryption of 55. Note that, crucially, the client told
the server only order information (namely, if the value being
encoded is to the left or to the right of another value), and
thus this interaction does not reveal anything else besides
the order. Fig. 3 provides the general algorithm.
Binary encoding. So what is the OPE encoding of the
newly inserted value 55? Observe that the path from the root
466466
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:52:32 UTC from IEEE Xplore.  Restrictions apply. 
c(cid:7) at the root of the OPE tree.
Algorithm 1 (OPE Tree traversal for a value v).
1: Cl ↔ Ser: The client asks the server for the ciphertext
2: Cl: The client decrypts c(cid:7) and obtains v(cid:7).
3: Cl → Ser: If v  v(cid:7),
the client tells the server “right”.
4: Ser: The server returns the next ciphertext c(cid:7)(cid:7) based
on the client’s information, and goes back to step 2.
5: Ser, Cl: The algorithm stops when v is found, or
when the server arrives at an empty spot in the tree.
The outcome of the algorithm is the resulting pointer
in the OPE Tree, the path in the OPE Tree from the
root, and whether v was found.
Figure 3. OPE Tree traversal algorithm. The text in blue indicates at which
party each piece of computation happens (Cl or Ser).
down to the node indicates the relative order of the node
with respect to the other tree nodes. If we label each left
edge with a “0” bit and each right edge with a “1” bit, we
can represent the path to a node from the root using the
bitwise concatenation of labels from the corresponding tree
edges. For example, the path for the value 10 is (binary)
00, which is decimal 0; the path of 25 is (binary) 01, which
is decimal 1; and the path of 55 is (binary) 10, which is
decimal 2. We can see that these values preserve the order of
the plaintexts. One has to be careful about nodes higher in
the tree. For example, the path of 32 (the root) is the empty
string. The empty string is not larger than 0 and smaller than
2. Therefore, we pad all paths to the same length (e.g., 32
or 64 bits in practice) by deﬁning the OPE encoding of a
value as follows:
OPE encoding = [path]10 . . .0,
(1)
where there are as many zero bits as necessary to pad the
value to a desired ciphertext size m. For example, if m = 3
as in Fig. 2, the encoding of the root value 32 is decimal
4, the encoding of 10 is decimal 1 and the encoding of 55
is decimal 5. We can see that the order of encodings is
preserved for all values.
Tree balancing. To ensure that OPE encodings do not grow
too large, mOPE must maintain a logarithmic tree height,
which requires occasional balancing operations. For example,
in a B-tree, if a node contains too many items, the node
gets split into two nodes and the parent node receives an
additional child. If the parent node also contains too many
items, the split propagates upward.
Tree balancing is precisely what mutates the OPE encoding:
after a rebalancing, a node may move to a different part of
the tree, thus changing its path in the tree. As we show
later in §V, any OPE scheme without mutation must have
infeasibly long OPE encodings, and we can see how mOPE’s
mutation ensures that OPE encodings stay short.
After balancing the OPE Tree, the OPE server must update
any server-side storage containing OPE encodings (e.g.,
update the relevant values in a database). This is why it
is important for the OPE server to be co-located with the
system using our OPE scheme.
Locating and modifying previously stored encodings can
also require a signiﬁcant amount of time. In §VIII we present
a technique called a transformation summary that allows
us to concisely describe tree rebalancing operations with a
short O(logn) summary, and to precisely scope the range of
affected encoding values, so that encoding updates can be
performed efﬁciently in one pass over the affected range of
values.
Amortized cost. The client work in this protocol is O(logn),
where n is the total number of values encoded, and the order-
preserving encoding similarly requires just O(logn) bits. This
is because the tree has logarithmic height. Furthermore, the
client need not be involved in rebalancing: even though
the server does not know the underlying plaintext values,
the server can perform tree rebalancing without any client
involvement, because it needs to know only order information,
which is already available from the tree on the server.
Let us now examine the server-side cost of updating
encodings. Traditional logarithmic cost bounds for trees (such
as a B-tree) are computed by considering only the number
of nodes touched during a balance. However, the number of
affected ciphertexts is the number of children in the subtrees
of nodes moved during a balancing operation, which can be
asymptotically larger. For example, if one node moves higher
up in the tree, only a few nodes may be touched by this
rebalancing operation, but all the children of this node change
their OPE encodings. In theory, a scapegoat tree provides
O(logn) cost in this model. However, in practice we use a B-
tree, even though they have non-logarithmic worst-case cost,
because their actual cost in our experiments was less than
the cost of scapegoat trees, and few ciphertexts are updated
on average (§X). We recommend scapegoat trees be used
only when embedding our scheme in theoretical schemes
with constraints on server-side asymptotic performance.
Stale encodings. Tree rebalancings pose another challenge
because an OPE encoding of a particular value can become
stale. Consider a situation where an application ﬁrst obtains
an OPE encoding of some value, by invoking the OPE client,
and then performs more work, which causes inserts and tree
rebalancings at the server. The rebalancing operations can
cause the application’s original OPE encoding to become
stale, meaning that the encoding no longer corresponds to
the value’s position in the tree. If the application were to
use a stale encoding, it could obtain incorrect results.
To prevent staleness, we introduce a mapping at the server
called the OPE Table, as shown in Fig. 2. Whenever a new