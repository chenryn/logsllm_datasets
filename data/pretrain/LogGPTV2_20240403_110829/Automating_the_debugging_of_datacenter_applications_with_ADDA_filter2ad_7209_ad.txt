Naive approach
 3
 6
# Clients
 9
Fig. 5: Recording overhead in Hypertable with varying
number of clients.
2) Log Size: ADDA has low logging rates. Fig. 6
shows ADDA’s log size for a Memcached workload,
while varying the total input size read from persistent
storage. The naive approach also records internal inputs
(inputs exchanged between recorded nodes), therefore
it produces an order of magnitude larger logs. For both
systems, the log size increases linearly with the input
size, yet the slope is larger for the naive approach.
Memcached is designed so that server instances do not
communicate with each other, otherwise the log size
for the naive approach would increase even more, while
ADDA does not record this communication.
]
B
G
i
[
e
z
s
g
o
L
 40
 35
 30
 25
 20
 15
 10
 5
 0
 500
Log size vs. input size for Memcached
ADDA
Naive approach
 1000
 1500
 2000
 2500
 3000
 3500
Total input size [MB]
Fig. 6: Log size for recording a Memcached workload
with varying input size from persistent storage. ADDA
has 10× smaller logs compared to the naive approach.
Hypertable exhibits a similar behavior (Fig. 7). We
expect these results to improve even more with a simple
optimization: our current DPS prototype allocates a
static 15KB entry (or a multiple of this size, if needed)
for recording the meta-data associated with an I/O
system call. However, a single 15KB entry is typically
too large: for Hypertable, log entries are dominated by
zeros, which we could compress to 100× smaller size.
By adding support for variable entry sizes, we expect
ADDA’s logging rates to improve substantially.
Log size vs. input size for Hypertable
ADDA
Naive approach
]
B
G
[
i
e
z
s
g
o
L
 18
 16
 14
 12
 10
 8
 6
 4
 2
 0
 200
 400
 600
 800
 1000  1200  1400  1600
Total input size [MB]
Fig. 7: Log size for recording a Hypertable workload
while varying the input size from persistent storage.
3) Performance for Multi-Processors: To validate
that our assumption about applying CREW selectively
to control plane components (i.e., the Hypertable master
and lock server) holds (§III-B), we enabled CREW
in the experiment in Fig. 5. Thus, the control plane
components were allowed to take advantage of both
CPUs of their machines. ADDA had the same overhead
compared to the baseline, showing that using CREW
for the control plane components in Hypertable does
not slow down the execution even when the system is
under heavy load. This is conﬁrmed by the small rate
of CREW faults (at most 150 faults / sec) for each of
these components.
To validate that CREW imposes a high overhead for
the data plane components of the system, we recorded
also the Hypertable data plane components (the range
servers) using CREW and observed overheads larger
than 400%.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:58:57 UTC from IEEE Xplore.  Restrictions apply. 
These experiments conﬁrm our design choice to turn
on CREW for the control plane components is likely to
impose low overhead, while having CREW turned on
all the time for data plane components is not practical
for production use. However, this assumption may not
hold for all datacenter applications and we are in the
process of evaluating this further.
C. Replay
Replay is serial, therefore replay overhead is ex-
pected to be proportional with the number of recorded
nodes. For replaying a Memcached workload similar to
the one in the previous experiments with 3 nodes (one
server and 2 clients), replay was 2.46× slower than the
original recorded run. We also replayed a Hypertable
workload similar to the previous experiments. The Hy-
pertable setup consisted of a lock server, a master server,
2 range servers, and 3 clients. The replay was 2.7×
slower than the original run. In both experiments, all
inputs were recorded due to a bug that prevented us from
doing the replay with REPLAYNET. Only these two
experiments were done without REPLAYNET. However,
we observed that, typically for these applications, replay
overhead using REPLAYNET is similar to the replay
overhead of the naive approach. In both these exper-
iments the replay was not n× slower (where n
is
the total number of nodes), because replay can fast-
forward the execution of some instructions by elimi-
nating “dead cycles”. For instance, operations such as
sleep or blocking I/O can complete faster during replay.
In real setups, such dead cycles may also arise from
multiple applications sharing the same node.
VI. RELATED WORK
Classic single node replay systems such as Instant
Replay [19], VMWare [6], and SMP-ReVirt [7] may
be adapted for large-scale distributed operation. Never-
theless, they are unsuitable for the datacenter, because
they record all inbound disk and network trafﬁc. The
ensuing logging rates not only incur throughput losses
but also call for additional storage infrastructure (e.g., an
additional large scale distributed ﬁle system). Moreover,
systems like WiDS [4] and Friday [2] provide dis-
tributed replay but have high overhead for data-intensive
applications.
Several relaxed-deterministic replay systems (e.g.,
PRES [8] and ReSpec [9]) and hardware and/or
compiler-assisted systems
(e.g., Capo [11], Core-
Det [26]) support efﬁcient recording of multi-core pro-
grams. But, like classic systems, they still incur high
record rates on network and disk-intensive distributed
systems such as datacenter systems.
R2 [12] provides an API and annotation mechanism
with which developers may select the application code
to be recorded and replayed. R2 could be used to
record just control plane inputs,
thus incurring low
recording overheads. However, the annotations require
considerable developer effort to manually identify the
components that need to be recorded. On the other hand,
ADDA makes this selection automatically based on the
data-rate heuristic.
is more efﬁcient
MPIWiz [27] is a hybrid deterministic replay system
that exploits the trafﬁc patterns of MPI applications
to reduce recording overhead by identifying subgroups
of MPI processes for which it
to
record all communication messages vs. the order of the
exchanged messages. First, MPIWiz addresses MPI ap-
plications, while ADDA targets datacenter applications.
Second, MPIWiz does not handle non-determinism
caused by data races and assumes shared memory non-
determinism is due only to the order of MPI calls.
ADDA is more general and captures all sources of non-
determinism, including data races. Third, MPIWiz de-
cides to record all communication data at the granularity
of a process group, while ADDA does it per network
channel, using the control/data plane separation.
Replay-debugging systems such as SherLog [28]
and ESD [10] can efﬁciently replay single-node ap-
plications while recording very little information, or
no information at all. These systems use inference to
recompute missing runtime information. However, they
were not designed for recording distributed systems,
much less so datacenter applications. Even for single
node replay, these systems have to reason about an
exponential number of program paths, which limits their
ability to replay at the scale of the datacenter.
VII. DISCUSSION
For the systems that do not meet our assump-
tions,
the runtime overhead may be deemed to be
too high for production use. For such cases, ADDA is
still useful during development. Our evaluation shows
runtime overhead ranging between 10% to 65% (§V).
We are not aware of any other record-replay system
that has lower overhead for data-intensive datacenter
applications. We see opportunities for several simple
engineering optimizations and hope that a production-
grade implementation of ADDA can reduce the overhead
to under 10% for an important subset of the datacenter
applications and workloads.
Not all applications may meet our two main as-
sumptions about the control/data plane separation and
the persistence of external inputs (§II). For instance the
running time of a parallel scientiﬁc application may
be dominated by the control plane code. Moreover,
a datacenter application may not store external inputs
(such as data acquired by a telescope) to append-
only storage simply because of the sheer size of the
inputs. On the one hand, for these applications, ADDA’s
overhead may be unacceptably high. On the other hand,
several applications in addition to the applications we
evaluated (§V), such as, Hadoop [15], Cassandra [17],
CloudStore [14], and applications that process click
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:58:57 UTC from IEEE Xplore.  Restrictions apply. 
streams (in which the initial inputs are logged for audit
purposes) do meet ADDA’s assumptions. Moreover, the
external inputs to MapReduce jobs are typically stored
in HDFS, which is append-only storage. This represents
an important subset of datacenter applications.
Reduced-scale replay (§III-C) is useful in several
common cases. For instance, there are cases in which
the original machines are not available for replay any-
more (e.g., machines may be down due to hardware
failures, or the cluster may be loaded with another job).
We designed reduced-scale replay for these cases.
If ADDA does to record an un-synthesizable source
of non-determinism (e.g., a data race in the data-
plane), the replay might diverge from the recording.
ADDA detects divergences by checking that the delivery
point of asynchronous events (i.e., the triple ) is the same during record and replay.
ADDA supports
recording of multiple multi-
processor nodes, but does not yet support multi-
processor replay. We plan to add this in future work.
Replaying CREW events is done in other systems [7]
and is not challenging if all CREW events are recorded.
However,
if ADDA missed the recording of CREW
events (e.g., due to misclassifying control plane code as
data plane code), this could lead to divergence during
replay, therefore replay may not be possible. In this case,
ADDA could use inference-based techniques [8], at the
expense of longer replay time.
VIII. CONCLUSION
We presented ADDA, a replay-debugging system
for data-intensive datacenter applications. To reduce
recording overhead, ADDA leverages two important ob-
servations: that the “control plane” and “data plane” of
datacenter applications can be identiﬁed and recorded
with different determinism guarantees and that external
inputs are typically persisted in append-only storage for
an important class of datacenter applications. ADDA has
low runtime overhead and logging rates, and determinis-
tically replays real-world failures in popular datacenter
applications. To achieve this, ADDA records with high
accuracy the control plane of a datacenter application
and does not record intermediate data that it can synthe-
size during replay, starting from the application’s exter-
nal inputs. Moreover ADDA can perform reduced-scale
replay and run sophisticated analyses during replay.
REFERENCES
[1] K. M. Chandy and L. Lamport, “Distributed snapshots: deter-
mining global states of distributed systems,” ACM Transactions
on Computer Systems, vol. 3, no. 1, 1985.
[2] D. Geels, G. Altekar, P. Maniatis, T. Roscoe, and I. Stoica,
“Friday: Global comprehension for distributed replay,” in Symp.
on Networked Systems Design and Implementation, 2007.
[3] G. Altekar and I. Stoica, “Focus replay debugging effort on
the control plane,” in Workshop on Hot Topics in Dependable
Systems, 2010.
[4] X. Liu, W. Lin, A. Pan, and Z. Zhang, “Wids checker: Com-
bating bugs in distributed systems,” in Symp. on Networked
Systems Design and Implementation, 2007.
[5] S. Bhansali, W.-K. Chen, S. de Jong, A. Edwards, R. Mur-
ray, M. Drini´c, D. Mihoˇcka, and J. Chau, “Framework for
instruction-level tracing and analysis of program executions,”
in Intl. Conf. on Virtual Execution Environments, 2006.
“VMware
ance:
http://www.vmware.com/resources/techresources/10058.
toler-
performance,”
vSphere
Architecture
[6]
4
and
fault
[7] G. W. Dunlap, D. G. Lucchetti, M. A. Fetterman, and P. M.
Chen, “Execution replay of multiprocessor virtual machines,”
in Intl. Conf. on Virtual Execution Environments, 2008.
[8] S. Park, W. Xiong, Z. Yin, R. Kaushik, K. H. Lee, S. Lu, and
Y. Zhou, “PRES: Probabilistic replay with execution sketching
on multiprocessors,” in Symp. on Operating Systems Principles,
2009.
[9] D. Lee, B. Wester, K. Veeraraghavan, S. Narayanasamy, P. M.
Chen, and J. Flinn, “Online multiprocessor replay via specula-
tion and external determinism,” in Intl. Conf. on Architectural
Support for Programming Languages and Operating Systems,
2010.
[10] C. Zamﬁr and G. Candea, “Execution synthesis: A technique
for automated debugging,” in ACM SIGOPS/EuroSys European
Conf. on Computer Systems, 2010.
[11] P. Montesinos, M. Hicks, S. T. King, and J. Torrellas, “Capo:
a software-hardware interface for practical deterministic mul-
tiprocessor replay,” in Intl. Conf. on Architectural Support for
Programming Languages and Operating Systems, 2009.
[12] Z. Guo, X. Wang, J. Tang, X. Liu, Z. Xu, M. Wu, M. F.
Kaashoek, and Z. Zhang, “R2: An application-level kernel for
record and replay,” in Symp. on Operating Systems Design and
Implementation, 2008.
[13] C. Zamﬁr, G. Altekar, G. Candea, and I. Stoica, “Debug
determinism: the sweet spot for replay-based debugging,” in
Workshop on Hot Topics in Operating Systems, 2011.
“Cloudstore,” http://kosmosfs.sourceforge.net.
“Hadoop,” http://hadoop.apache.org/.
“Memcached,” http://www.memcached.org/.
“Cassandra,” http://cassandra.apache.org.
“Hypertable,” http://www.hypertable.org.
[14]
[15]
[16]
[17]
[18]
[19] T. J. LeBlanc and J. M. Mellor-Crummey, “Debugging parallel
programs with instant replay,” IEEE Trans. Computers, vol. 36,
no. 4, pp. 471–482, 1987.
“LibVEX,” http://valgrind.org/.
“Hypertable,” http://www.hypertable.org/.
[20]
[21]
[22] F. Chang, J. Dean, S. Ghemawat, W. Hsieh, D. Wallach,
M. Burrows, T. Chandra, A. Fikes, and R. Gruber, “Bigtable: A
distributed storage system for structured data,” USENIX Annual
Technical Conf., 2006.
“Hypertable issue 63,” http://code.google.com/p/hypertable/issues/.
[23]
[24] R. Nikolaev and G. Back, “Perfctr-xen: a framework for
performance counter virtualization,” in Intl. Conf. on Virtual
Execution Environments, 2011.
[25] D. Beaver, S. Kumar, H. C. Li, J. Sobel, and P. Vajgel, “Finding
a needle in haystack: Facebook’s photo storage,” in Symp. on
Operating Systems Design and Implementation, 2010.
[26] T. Bergan, O. Anderson, J. Devietti, L. Ceze, and D. Grossman,
“Coredet: A compiler and runtime system for determinis-
tic multithreaded execution,” in Intl. Conf. on Architectural
Support for Programming Languages and Operating Systems,
2010.
[27] Xue, “MPIWiz: Subgroup reproducible replay of MPI ap-
plications,” in Symp. on Principles and Practice of Parallel
Programming, 2009.
[28] D. Yuan, H. Mai, W. Xiong, L. Tan, Y. Zhou, and S. Pasupathy,
“SherLog: error diagnosis by connecting clues from run-time
logs,” in Intl. Conf. on Architectural Support for Programming
Languages and Operating Systems, 2010.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:58:57 UTC from IEEE Xplore.  Restrictions apply.