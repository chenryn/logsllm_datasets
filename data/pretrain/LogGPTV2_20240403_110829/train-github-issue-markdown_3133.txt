# Checklist
  * I have verified that the issue exists against the `master` branch of Celery.
  * This has already been asked to the discussion group first.
  * I have read the relevant section in the  
contribution guide  
on reporting bugs.
  * I have checked the issues list  
for similar or identical bug reports.
  * I have checked the pull requests list  
for existing proposed fixes.
  * I have checked the commit log  
to find out if the bug was already fixed in the master branch.
  * I have included all related issues and possible duplicate issues  
in this issue (If there are none, check this box anyway).
## Mandatory Debugging Information
  * I have included the output of `celery -A proj report` in the issue.  
(if you are not able to do this, then at least specify the Celery  
version affected).
  * I have verified that the issue exists against the `master` branch of Celery.
  * I have included the contents of `pip freeze` in the issue.
  * I have included all the versions of all the external dependencies required  
to reproduce this bug.
## Optional Debugging Information
  * I have tried reproducing the issue on more than one Python version  
and/or implementation.
  * I have tried reproducing the issue on more than one message broker and/or  
result backend.
  * I have tried reproducing the issue on more than one version of the message  
broker and/or result backend.
  * I have tried reproducing the issue on more than one operating system.
  * I have tried reproducing the issue on more than one workers pool.
  * I have tried reproducing the issue with autoscaling, retries,  
ETA/Countdown & rate limits disabled.
  * I have tried reproducing the issue after downgrading  
and/or upgrading Celery and its dependencies.
## Related Issues and Possible Duplicates
#### Related Issues
  * None
#### Possible Duplicates
  * None
# Expected Behavior
The `celery_worker` pytest fixture should either wait until all enqueued tasks
are processed before stopping the worker or, alternatively, it should raise an
exception if the worker fails to terminate within the defined timeout
(currently hardcoded to 10s).
# Actual Behavior
If, when the cleanup code of the `celery_worker` pytest fixture is called, the
worker is still executing tasks, and those tasks take longer than 10s to
terminate, the worker thread is left in running state and the worker will
never be stopped, causing the pytest process to never exit.
# Additional information
The code around
celery/celery/contrib/testing/worker.py
Line 133 in 7288147
|  t.join(10)  
---|---  
waits for the thread to exit with a timeout of 10 seconds, but the status of
the thread once the threading API `.join` method returns is not checked,
potentially leaving the thread running.
Because of the thread status not being checked (and the `.join()` method not
raising exceptions on timeout), the execution proceeds cleanly, by resetting
the `should_terminate` state variable back to `None`, causing the worker
thread to stay alive even after it completed all the enqueued tasks.
At a minimum, the fixture should raise an exception if the worker is still
alive once the timeout is expired, letting the developer know about the issue
and letting him make sure that all tasks have been processed before exiting
the test and letting pytest invoke the teardown code. An additional
improvement would be to let the timeout be overridable e.g. via another
fixture as done for celery_worker_parameters or to let the developer indicate
that the worker should wait until the current/all pending tasks have been
completed before exiting via a more robust method.