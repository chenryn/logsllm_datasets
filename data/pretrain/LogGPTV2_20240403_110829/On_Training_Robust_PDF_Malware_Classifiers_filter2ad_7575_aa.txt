title:On Training Robust PDF Malware Classifiers
author:Yizheng Chen and
Shiqi Wang and
Dongdong She and
Suman Jana
On Training Robust PDF Malware Classifiers
Yizheng Chen, Shiqi Wang, Dongdong She, and Suman Jana, Columbia University
https://www.usenix.org/conference/usenixsecurity20/presentation/chen-yizheng
This paper is included in the Proceedings of the 29th USENIX Security Symposium.August 12–14, 2020978-1-939133-17-5Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.On Training Robust PDF Malware Classiﬁers
Yizheng Chen, Shiqi Wang, Dongdong She, and Suman Jana
Columbia University
Abstract
Although state-of-the-art PDF malware classiﬁers can be
trained with almost perfect test accuracy (99%) and extremely
low false positive rate (under 0.1%),it has been shown that even
a simple adversary can evade them. A practically useful mal-
ware classiﬁer must be robust against evasion attacks. However,
achieving such robustness is an extremely challenging task.
In this paper, we take the ﬁrst steps towards training robust
PDF malware classiﬁers with veriﬁable robustness properties.
For instance, a robustness property can enforce that no matter
how many pages from benign documents are inserted into a
PDF malware, the classiﬁer must still classify it as malicious.
We demonstrate how the worst-case behavior of a malware
classiﬁer with respect to speciﬁc robustness properties can
be formally veriﬁed. Furthermore, we ﬁnd that training
classiﬁers that satisfy formally veriﬁed robustness properties
can increase the evasion cost of unbounded (i.e., not bounded
by the robustness properties) attackers by eliminating simple
evasion attacks.
Speciﬁcally, we propose a new distance metric that operates
on the PDF tree structure and specify two classes of robustness
properties including subtree insertions and deletions. We uti-
lize state-of-the-art veriﬁably robust training method to build
robust PDF malware classiﬁers. Our results show that, we can
achieve 92.27% average veriﬁed robust accuracy over three
properties, while maintaining 99.74% accuracy and 0.56%
false positive rate. With simple robustness properties, our ro-
bust model maintains 7% higher robust accuracy than all the
baseline models against unrestricted whitebox attacks. More-
over, the state-of-the-art and new adaptive evolutionary attack-
ers need up to 10 times larger L0 feature distance and 21 times
more PDF basic mutations (e.g., inserting and deleting objects)
to evade our robust model than the baselines.
1 Introduction
Machine learning classiﬁers have long been used for many
important security problems such as malware detection, spam
ﬁltering, and online fraud detection. One of the most ubiqui-
tous applications is to detect PDF malware, which is a very
popular infection vector for both large-scale mass and targeted
attacks. Many prior research projects have demonstrated
that machine-learning-based PDF malware classiﬁers can
achieve almost perfect test accuracy (99%) with extremely low
false positive rate (under 0.1%) [47, 48]. Nonetheless, all the
state-of-the-art classiﬁers, including the proprietary ones used
by popular services like Gmail, can be evaded by trivial trans-
formations over the PDFs, such as adding invisible document
metadata, deleting the length indicator of the exploit payload,
or simply increasing the length of the document [5, 36, 61].
Since any security-relevant application of machine learning
classiﬁers must deal with adaptive adversaries, it is fundamen-
tally insufﬁcient to evaluate security classiﬁers by measuring
the accuracy and false positive rate. Despite the abundance
of available metrics given by well-established theoretical
results in machine learning [7], none of them are suitable
to measure the robustness of the classiﬁers under adaptive
attackers. In order to be practically useful, a malware classiﬁer
must be demonstrated to be secure against different types of
adaptive attacks. For example, a sample robustness property
might require that no matter how many pages from benign
documents are inserted into a PDF malware, the classiﬁer still
must classify the modiﬁed malware as malicious. Similarly,
deletion of any non-functional objects in the PDF must not
result in a benign classiﬁcation.
Ideally, a classiﬁer should be sound with regard to a
robustness property. That is, the robustness property can
be formally veriﬁed to get strict bounds on the worst-case
behavior of the classiﬁer. If a classiﬁer satisﬁes the robustness
property, the strongest possible attacker bounded by the
speciﬁcation of the property, i.e., bounded attacker, will not
be able to violate the property, no matter how powerful the
attacker is or whatever adaptive strategy she follows. For
example, even for a perfect knowledge attacker, any creative
way of inserting pages from the most-benign documents to the
malware can be veriﬁed to keep the malicious classiﬁcation.
If we train classiﬁers to be veriﬁably robust against building
block attacks, we can raise the bar for more sophisticated at-
tacks to succeed. Essentially, the attacker is solving a search
problem to ﬁnd an evasive PDF malware. She starts from a
malicious PDF, performs a series of manipulations to the PDF,
and eventually arrives at a solution that makes the PDF vari-
ant classiﬁed as benign without affecting its maliciousness.
To maintain malicious functionality, the PDF variant needs to
have the correct syntax and correct semantics. Therefore, ma-
nipulations from different attacks can be decomposed to many
building block operations in the parsed PDF tree. By training
building block robustness properties, we eliminate simple and
USENIX Association
29th USENIX Security Symposium    2343
easy evasions, which increases the search cost for attackers.
In this paper, we take the ﬁrst steps towards training a PDF
malware classiﬁer with veriﬁable robustness properties, and
we demonstrate that such classiﬁers also increase the attack
cost even for the attackers not bounded by these properties.
We address several challenges in building robust PDF mal-
ware classiﬁers. First, previous work has shown that retraining
the malware classiﬁer with adversarial instances drastically
increases the false positive rate [1, 28]. Since veriﬁably robust
training is strictly a harder problem to solve than adversarially
robust training without any veriﬁable bound, it is challenging to
specify robustness properties that do not increase false positive
rates yet still increase the cost for the attackers. To this end, we
propose a new distance metric for the structured PDF trees. Us-
ing a small distance for the robustness properties maintains low
false positive rate. Second, popular model choices for PDF mal-
ware classiﬁers are not suitable forrobust training. Forexample,
adversarially robust training over a random forest model re-
quires manual adjustment to the complexity of trees to maintain
acceptable accuracy [33]. Therefore, we choose a neural net-
work model to leverage state-of-the-art veriﬁably robust train-
ing schemes. Third, to evaluate our defense, we compare the
robustness of our models against twelve different baseline mod-
els using seven attacks. We implement ﬁve attacks unrestricted
by robustness properties, including feature-space attacks as
well as application-space attacks that generate actual evasive
PDF malware. In particular, we develop adaptive attacks to tar-
get the trained robustness properties based on EvadeML [61].
We use these attacks to quantify the increase in the unbounded
attacker cost caused by the veriﬁable robust training.
Using our new distance metric for the PDF tree structure, we
specify two classes of robustness properties, subtree deletion
properties and subtree insertion properties. The properties
allow any possible attacks involving deletion/insertion
up to a bounded number of subtrees under the PDF root.
For example, when choosing to delete /Root/Metadata
subtree containing children /Root/Metadata/Length and
/Root/Metadata/Type, the attacker can delete either one
of the children, both children, or the whole subtree. Note
that even at the subtree distance one, the properties include
a large number of possible model inputs. For example, subtree
insertion property bounds the attacker to any one of the 42
subtrees under the PDF root. Among them, /Root/Pages
alone includes 21,195 different input features for the classiﬁer.
This overapproximates attacker’s actions, and includes even
unknown attacks. We train seven veriﬁably robust models with
different robustness properties, utilizing symbolic interval
analysis [55, 56]. We measure the veriﬁed robust accuracy
(VRA) for a test set of 3,416 PDF malware. The VRA
represents the percentage of test samples that are veriﬁably
robust against the strongest bounded attacker. Although
adversarially robust training is known to achieve strong
robustness against a speciﬁc type of attacker, the gradient
attacker [39], our veriﬁably trained models can obtain superior
veriﬁable robustness against all possible bounded attackers
while keeping high test accuracies and low false positive rates.
Perhaps even more importantly, we show that a veriﬁably
robust classiﬁer with two proposed robustness properties can
already increase the cost for the unbounded attacker. We eval-
uate our model against two unrestricted whitebox attacks and
three unrestricted blackbox attacks. In the whitebox setting,our
robust model maintains 7% higher estimated robust accuracy
(deﬁned in Section 2.3.4) against the unrestricted gradient at-
tack and the Mixed Integer Linear Program (MILP) attack than
the baseline models. In the blackbox setting, the enhanced evo-
lutionary attack needs up to 3.6 times larger L0 distance and 21
times more PDF mutations (described in Section 4.5.1 and 4.7)
to evade our model compared to the baselines. Even the
adaptive evolutionary attack needs 10 times larger L0 distance
and 3.7 times more PDF mutations to evade our robust model.
In addition, we achieve 2% higher ERA than the strongest base-
line model against the reverse mimicry attack. The results show
that training veriﬁably robust PDF malware classiﬁers even for
carefully chosen simple robustness properties can effectively
increase the bar for the attacker to solve the evasion problem.
As defenders, making all evasion attacks on malware classi-
ﬁers computationally infeasible is an extremely hard problem.
However, our work shows a very promising direction to in-
crease the cost of an attacker by training malware classﬁers that
are veriﬁably robust against different simple robustness proper-
ties. We can potentially further increase the robustness of PDF
malware classiﬁer by specifying more complex robustness
properties. Our key contributions are summarized as follows.
• We are the ﬁrst to evaluate and train veriﬁable robustness
properties of PDF malware classiﬁers. We propose a new dis-
tance metric to bound the robustness properties in the PDF
tree structure. We specify two essential robustness proper-
ties as building blocks to compose more powerful properties.
• We train veriﬁably robust PDF malware classiﬁer models.
We thoroughly evaluate the robustness against twelve
baseline models, using state-of-the-art measures including
estimated robust accuracy (ERA) under gradient attacks
and veriﬁed robust accuracy (VRA) against any bounded
adaptive attacker. We can achieve 92.27% average VRA
over three robustness properties while maintaining 99.74%
test accuracy and 0.56% false positive rate.
• We can increase the bar for unrestricted attackers to evade
our veriﬁably robust model. Our model achieves 7% higher
ERA against the unrestricted gradient attacker up to 200,000
iterations than all the baselines. The state-of-the-art and new
adaptive evolutionary attackers need up to 10 times larger
L0 feature distance and 21 times more PDF manipulations
to evade our robust model.
2 Background
In this section, we present an overview of the PDF format
and PDF malware. Then, we introduce the features used by
2344    29th USENIX Security Symposium
USENIX Association
1 0 obj >
/Pages 3 0 R
/Type /Catalog
>> endobj
3 0 obj > endobj
2 0 obj > stream
…
endstream
endobj
4 0 obj > endobj
trailer
>
/Root
/Type
/OpenAction
/Pages
/JS
Exploit
/Filter
/FlateDecode
/S
/Javascript
/Length
16973
/Kids
/Type
/Page
/Catalog
/Count
/Type
1
/Pages
/Root/OpenAction
/Root/OpenAction/JS
/Root/OpenAction/JS/Filter
/Root/OpenAction/JS/Length
/Root/OpenAction/S
/Root/Pages
/Root/Pages/Count
/Root/Pages/Kids
/Root/Pages/Kids/Type
/Root/Pages/Type
/Root/Type
(a) Example objects in a PDF malware.
Figure 1: The objects and trailer, parsed PDF tree structure, and extracted Hidost features from an example PDF malware.
(b) The tree structure of a PDF malware.
(c) Hidost features.
PDF malware classiﬁers and two main classes of attacks that
evade them. At last, we describe the robust training techniques.
2.1 PDF Malware
The Portable Document Format (PDF) contains four sec-
tions: header, body, cross-reference table, and trailer. The
header identiﬁes the ﬁle format, version, and a magic number.
The body consists of various types of objects, including arrays,
name trees, dictionaries, etc. For example, Figure 1a shows
four PDF objects and the trailer from a PDF malware. The
trailer identiﬁes the entrance to parse the ﬁle, along with the
cross-reference table size. Here, the entrance is the root object
1 0 obj, where the object number is 1 and the object version
is 0, and R means indirect reference. The cross-reference table
indexes all object locations in the ﬁle. Starting from the root
object, a parser resolves referred objects either using the cross-
reference table or scanning the PDF to get the object locations.
The four objects in this ﬁle are dictionaries, indicated by > symbols and enclosed by obj and endobj keywords.
The dictionary object is a collection of key/value pairs. Each
key is a name object, and the value can be any object. The
root object 1 0 obj has a special type, /Catalog, and the
value of the key /OpenAction is another dictionary object.
Within /OpenAction, the object containing the JavaScript
exploit is referred to as 2 0 R. The exploit object contains a
stream that can be decoded using the /Filter indicator, and
a length ﬁeld for the stream. The exploit is executed when
the ﬁle is opened. There is generally discrepancy between the
parser implementation and actual ﬁle format speciﬁcation. For
example, many PDF readers do not need the correct length
ﬁeld to decode the stream, and malware authors can delete the
ﬁeld to evade the classiﬁer. The rest of the PDF contains object
3 and 4 that refer to each other. The PDF structure forms a tree,
by taking the shortest path to objects via references (Figure 1b).
PDF malware exploits the vulnerabilities in the PDF reader
in order to transfer execution control, e.g., to run shellcode or
drop additional binary. PDF malware authors employ various
techniques to evade the detection, e.g., add content from
legitimate documents, crash the PDF reader, and obfuscate the
PDF content. Making PDF malware classiﬁer robust against
trivial manipulation remains a hard problem. For example,
increasing the length of the ﬁle to be 7,050,000 bytes can
evade the Gmail PDF malware scanner [5].
2.2 PDF Malware Classiﬁers
In this section, we discuss two open-source PDF malware
classiﬁers that have attracted considerable evasion effort in
the security community, PDFrate [47] and Hidost [48].
2.2.1 PDFrate
PDFrate [47] uses a total of 202 features including counts
for various keywords and certain ﬁelds in the PDF. For
example, number of characters in the author ﬁeld, number
of “endobj” keyword, sum of all pixels in all the images, and
number of JavaScript markers, etc. The classiﬁer is a Random
Forest, with 99% accuracy and 0.2% false positive rate over
the Contagio malware dataset [4].
Simple manipulation of the PDF ﬁle can result in very
big changes in the feature values of PDFrate. For instance,
inserting pages from a benign document to the PDF malware
can increase the page count feature alone to be as big as the
maximal integer value, which also affects many other counts.
If a bounded manipulation in the PDF cannot tightly bound
the feature input to the classiﬁer, these features are not suitable
for veriﬁably robust training.
2.2.2 Hidost
Hidost [48] uses Bag-of-Path features extracted from
the parsed tree structure of the PDF. It obtains the shortest
structural path to each object, including terminals and non-
terminals in the tree, and uses binary counts for these paths
as features. In the paper, the authors used only those paths that
appeared in at least 1,000 ﬁles in the corpus, which reduced the
number of paths from 9 million to 6,087. Hidost was evaluated
on a decision tree model and a SVM model. Both models have
99.8% accuracy and less than 0.06% false positive rate
The binary Bag-of-Path features are able to bound the input
to the classiﬁer, given certain attack properties. For example,
in our dataset, if we insert anything under the /Pages subtree,
only up to 1,195 features will be ﬂipped from 0 to 1, resulting
in a tight input bound to the classiﬁer. Therefore, in this paper,
we choose to use Hidost features to build our robust PDF
malware classiﬁer.
2.2.3 Automatically Evading Malware Classiﬁers
Several automated attacks have successfully evaded PDF
malware classiﬁers, under different threat models.
USENIX Association
29th USENIX Security Symposium    2345
White-box Attacks. White-box attackers are assumed to
have perfect knowledge. They can launch precise attacks
targeting the exact model being trained, e.g., gradient-based
attack [11,36]. For instance, in the white-box setting, the Gradi-
ent Descent and Kernel Density Estimation (GD-KDE) attack
can be launched against the SVM version of PDFrate [36]. In
addition, [28] uses an approach to only add features, in order
to preserve existing malicious functionality of adversarial
malware examples [8]. The drawback of such white-box
gradient-based attacks is that the evasion instances are found in
the feature space, so they do not generate actual PDF malware.
Black-box Attacks. The threat models of black-box attacks