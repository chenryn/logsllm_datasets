⽹易云原⽣⽇志平台的架构演进与实践
傅轶 ｜ ⽹易
01
云原⽣最初的探索
Operator化的⽇志采集
02
进⼊深⽔区
⼤规模场景下的困境与挑战
03
新的征程
开源Loggie的现在与未来
1.
云原⽣最初的探索
Operator化的⽇志采集
混乱与秩序
➤ 混乱的主机时代 ➤ 上云/云原⽣化
云原⽣的⽇志是什么样❓
• 采集Agent: Filebeat/Logstash/Flume/Rsyslog
• 中转：Kafka/Logstash/Flink
• 存储：Elasticsearch
• 配置下发：⼿动/各种配置中⼼
不同部⻔⽇志选型、架构各异 公司内基于轻⾈的容器化、云原⽣化进程
Kubernetes下的⽇志采集难题
➤
和主机⽇志的差异
动态迁移 ⽇志存储多样性 Kubernetes元信息
容器的⽇志存储与表现⽅式有 查询⽇志时，需要根据
Pod会主动或者被动的迁移，
很多不同的类型 namespace、pod、container、
频繁的销毁、创建
例如stdout、hostPath、 node，甚⾄包括容器的环境变
⽆法⼈为下发⽇志采集配置
emptyDir、pv等 量、label等维度来检索、过滤
容器⽇志采集常⻅思路
➤
只采集标准输出
• 挂载stdout路径、path通配
• ⼀些Agent实现了watch
Kubernetes，注⼊
Namespace/Pod等元信息
符合云原⽣12要素，但是不适合复杂业务，难以推⼴
容器⽇志采集常⻅思路
➤ Agent⽇志路径全局挂载
• emptyDir
• hostPath (K8s1.15以上可使
⽤subPathExpr路径隔离)
• pv
⽆Kubernetes元信息注⼊
⽆法针对服务级别单独配置
容器⽇志采集常⻅思路
➤ Sidecar⽅式
• 每个业务Pod增加⼀个⽇志采集
Agent sidecar
• 挂载相同的empty/hostPath..
• Agent挂载配置⽂件configMap
侵⼊性较强；资源占⽤较多
➤ 其他 • eg: 增加⼀个sidecar将业务⽇志⽂件转换成⾃身容器的stdout，采集stdout⽇志
轻⾈⽇志服务v1.0
➤ Sidecar⽅式和DaemonSet选择
资源占⽤ 侵⼊性 稳定性 隔离性 性能
节点⽇志都由同⼀个 节点⽇志量⼤时可能出
DaemonSet 每个节点⼀个，较⼩ 基本⽆侵⼊ 不影响业务Pod
Agent采集，较差 现瓶颈
Agent OOM等会影响业务Pod； Agent只采集所在Pod 只采集所在Pod，出现
Sidecar 每个Pod⼀个，较⼤ Pod部署侵⼊
数量多影响下游组件 ⽇志，较好 瓶颈概率较⼩
Tips
优先使⽤DaemonSet的⽅式采集⽇志，如果某个服务⽇志量特别⼤，
可以单独使⽤Sidecar的⽅式采集⽇志
轻⾈⽇志服务v1.0
➤
适配云原⽣的核⼼架构设计
⾃研Ripple + 开源⽇志采集Agent Filebeat
解决了开源Agent在Kubernetes环境下的
不⾜：
• 基于CRD⽇志配置指定Pods
• ⾃动感知Pod⽣命周期
•
⾃动添加服务元信息
• ⽀持采集⽇志盘hostPath/emptyDir/
Pv/docker rootfs
轻⾈⽇志服务v1.0
➤
在严选 ➤
被集团绝⼤多数部⻔使⽤
…
2.
进⼊深⽔区
⼤规模场景下的困境与挑战
进⼊深⽔区，远⽐表⾯复杂
采集
查询 ⼈⾁运维越来越多
冰⼭⼀⻆
排障痛苦 功能开发难以扩展
ETL
性能不⾜
超⼤规模
难以⽀撑更⼤规模
客户场景复杂 稳定性
Filebeat单个队列问题
➤
在严选的隐患：隔离性不⾜
问题
Flume中转机⼀个队列发⽣堵塞，会导致某节点发送到
该中转机的Filebeat全部发送⽇志失败
尝试
将Filebeat改造成多队列，试图增强隔离机制
隐患
Filebeat先天架构的不⾜，引⼊很多workaround的改动，
导致代码不便维护，存在oom等隐患
Filebeat只⽀持⼀个Output
➤
扩展受限
需求
客户需要发送⽇志到两个Kafka集群，存储不同类型的⽇志
避免单个Kafka集群的性能瓶颈
临时⽅案
❓
Filebeat只⽀持单个output，只能⼀个节点部署多个Agent
后果
引⼊⼤量运维维护成本，资源占⽤增多，⽔平扩展麻烦
Filebeat不适合做中转机
•
中转
•
聚合
•
解析
•
切分
…
➤
⽬前⽅案
A. Logstash B. Flink
● Logstash性能较弱 ● ⼤部分场景只需要简单的⽇志切分
● 语⾔栈不统⼀，引⼊另外服务，增加维护成本 ● 要求有配套的运维、监控、排障能⼒
● ⼿动配置 ● 依赖流式处理平台
可观测性/稳定性不⾜
排障痛苦
• ⽇志为什么没有采集?
metrics不⾜
❓
•
⽇志采集查询有延迟
•
⽇志为什么丢了？ 指标割裂，和服务⽆关联
•
快速增⻓的⽇志占据满了磁盘
⽆Prometheus格式
…
突发预警不够
可观测性/稳定性不⾜
➤
举例：幽灵⽂件 现象
传媒线上集群节点磁盘使⽤率⼀直在增⻓，90%+报
警，但是⽂件实际占⽤不多
原因
⽇志滚动会删除⽂件，但是由于下游Kafka吞吐不够，导
致Filebeat继续保持⽂件句柄fd，发送⽇志⽂件，确保⽇
志⽂件不丢失；
但被删除的⽂件仍然占据了磁盘空间；
反思
● 没有⽇志输⼊指标
Filebeat核⼼监控指标不够，影响稳定性 ● 没有发送延迟指标
● 没有堆积指标
…
性能不够
问题
⽹关节点单台审计⽇志量⼤，Filebeat⽆法及时发
送，导致消费端⽆法实时处理和展示数据
尝试优化
配置调优，换独⽴SSD Kafka集群，
仍然⽆法超过80MB/s
如果配置发送数据压缩，会导致CPU 1000%+
其他的开源项⽬能否解决这些问题？
➤
对⽐
基于Golang， 基于C，资源
基于JRuby， 基于Java，⽐ 基于Ruby，
资源占⽤较 占⽤⼩，性能