### 网易云原生日志平台的架构演进与实践
作者：傅轶 | 网易

#### 1. 云原生最初的探索：Operator化的日志采集

**混乱与秩序**
- **混乱的主机时代** ➤ **上云/云原生化**

**云原生的日志是什么样的？**
- **采集Agent**: Filebeat, Logstash, Flume, Rsyslog
- **中转**: Kafka, Logstash, Flink
- **存储**: Elasticsearch
- **配置下发**: 手动或通过各种配置中心

不同部门的日志选型和架构各异。随着公司内部基于轻舟的容器化、云原生化进程推进，Kubernetes下的日志采集面临新的挑战。

**Kubernetes下的日志采集难题**
- **与主机日志的差异**:
  - 动态迁移
  - 日志存储多样性
  - Kubernetes元信息

**容器的日志存储与表现方式**
- 容器的日志存储类型多样，如stdout, hostPath, emptyDir, PV等。
- 查询日志时，需要根据namespace, pod, container, node, 甚至包括容器的环境变量、标签等维度进行检索和过滤。

**容器日志采集常见思路**
- **只采集标准输出**:
  - 挂载stdout路径并使用通配符
  - 一些Agent实现了watch机制，并注入Namespace/Pod等元信息
  - 符合云原生12要素，但不适合复杂业务，难以推广

- **全局挂载Agent日志路径**:
  - 使用emptyDir, hostPath (K8s 1.15以上可使用subPathExpr路径隔离), 或PV
  - 无Kubernetes元信息注入，无法针对服务级别单独配置

- **Sidecar方式**:
  - 每个业务Pod增加一个日志采集Agent sidecar
  - 挂载相同的emptyDir/hostPath，并使用configMap配置
  - 侵入性强，资源占用较多

- **其他方法**:
  - 增加一个sidecar将业务日志文件转换为自身容器的stdout，再采集stdout日志

**轻舟日志服务v1.0**
- **选择Sidecar方式和DaemonSet**:
  - **DaemonSet**:
    - 每个节点一个，资源占用较小
    - 基本无侵入性
    - 不影响业务Pod
    - 节点日志量大时可能出现瓶颈
  - **Sidecar**:
    - 每个Pod一个，资源占用较大
    - Pod部署侵入性较强
    - 只采集所在Pod的日志，性能较好
  - **建议**:
    - 优先使用DaemonSet的方式采集日志
    - 如果某个服务日志量特别大，可以单独使用Sidecar的方式采集日志

- **适配云原生的核心架构设计**:
  - 自研Ripple + 开源日志采集Agent Filebeat
  - 解决了开源Agent在Kubernetes环境下的不足：
    - 基于CRD日志配置指定Pods
    - 自动感知Pod生命周期
    - 自动添加服务元信息
    - 支持采集日志盘hostPath/emptyDir/PV/docker rootfs

- **在严选的应用**:
  - 被集团绝大多数部门使用

#### 2. 进入深水区：大规模场景下的困境与挑战

**进入深水区，远比表面复杂**
- **采集**:
  - 排障痛苦
  - 功能开发难以扩展
  - 性能不足
  - 难以支撑更大规模
  - 客户场景复杂
  - 稳定性问题

**Filebeat单个队列问题**
- **隐患**:
  - 在严选中，Flume中转机一个队列发生堵塞会导致某节点发送到该中转机的所有Filebeat发送日志失败
  - 尝试将Filebeat改造成多队列以增强隔离机制
  - 引入大量workaround改动，导致代码不便维护，存在OOM等隐患

**Filebeat只支持一个Output**
- **需求**:
  - 客户需要发送日志到两个Kafka集群，存储不同类型的日志
  - 避免单个Kafka集群的性能瓶颈
- **临时方案**:
  - 每个节点部署多个Agent
  - 引入大量运维维护成本，资源占用增多，水平扩展麻烦

**目前方案**
- **Logstash**:
  - 性能较弱
  - 语言栈不统一，引入额外服务，增加维护成本
  - 手动配置
  - 依赖流式处理平台
- **Flink**:
  - 大部分场景只需要简单的日志切分
  - 需要配套的运维、监控、排障能力

**可观测性/稳定性不足**
- **问题**:
  - 日志为什么没有采集？
  - 日志采集查询有延迟
  - 日志为什么丢了？
  - 快速增长的日志占据满了磁盘
  - 指标割裂，和服务无关联
  - 无Prometheus格式
  - 突发预警不够

**举例：幽灵文件**
- **现象**:
  - 传媒线上集群节点磁盘使用率一直在增长，达到90%+报警，但实际文件占用不多
- **原因**:
  - 日志滚动会删除文件，但由于下游Kafka吞吐不够，Filebeat继续保持文件句柄fd，确保日志文件不丢失
  - 被删除的文件仍然占据了磁盘空间
- **反思**:
  - 缺乏日志输入指标
  - Filebeat核心监控指标不够，影响稳定性
  - 缺乏发送延迟指标
  - 缺乏堆积指标

**性能不够**
- **问题**:
  - 网关节点单台审计日志量大，Filebeat无法及时发送，导致消费端无法实时处理和展示数据
- **尝试优化**:
  - 配置调优，换独立SSD Kafka集群
  - 仍然无法超过80MB/s
  - 配置发送数据压缩会导致CPU 1000%+

**其他开源项目能否解决这些问题？**
- **对比**:
  - **Golang**: 资源占用较小，性能较好
  - **C**: 资源占用小，性能高
  - **JRuby**: 资源占用较大
  - **Java**: 比较稳定
  - **Ruby**: 资源占用较大

通过这些对比和优化措施，网易云原生日志平台逐步解决了大规模场景下的诸多挑战，提高了系统的稳定性和性能。