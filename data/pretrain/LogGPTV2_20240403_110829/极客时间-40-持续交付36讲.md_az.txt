## 两大利器之一 Mock我先来说说什么是 Mock：> 如果某个对象在测试过程中依赖于另一个复杂对象，而这个复杂对象又很难被从测试过程中剥离出来，那么就可以利用> Mock 去模拟并代替这个复杂对象。听起来是不是有点抽象？下面这张图就是 Mock定义的一个具象化展示，我们一起来看看吧。![](Images/d5832da4911197e8a83ff9b35b780ff5.png){savepage-src="https://static001.geekbang.org/resource/image/e2/9f/e2e79f8ec5f10e7ef3b3c84c8781d39f.png"}```{=html}```图 1 测试过程中，被测对象的外部依赖情况展示```{=html}```在测试过程中，你可能会遇到这样的情况。你要测试某个方法和对象，而这个被测方法和对象依赖了外部的一些对象或者操作，比如：读写数据库、依赖另外一个对象的实体；依赖另一个外部服务的数据返回。而实际的测试过程很难实现这三种情况，比如：单元测试环境与数据库的网络不通；依赖的对象接口还没有升级到兼容版本；依赖的外部服务属于其他团队，你没有办法部署等等。那么，这时，你就可以利用 Mock技术去模拟这些外部依赖，完成自己的测试工作。Mock因为这样的模拟能力，为测试和持续交付带来的价值，可以总结为以下三点：1.  **使测试用例更独立、更解耦**。利用 Mock    技术，无论是单体应用，还是分布式架构，都可以保证测试用例完全独立运行，而且还能保证测试用例的可迁移性和高稳定性。为什么呢？\    因为足够独立，测试用例无论在哪里运行，都可以保证预期结果；而由于不再依赖于外部的任何条件，使得测试用例也不再受到外部的干扰，稳定性也必然得到提升。2.  **提升测试用例的执行速度**。由于 Mock    技术只是对实际操作或对象的模拟，所以运行返回非常快。特别是对于一些数据库操作，或者复杂事务的处理，可以明显缩短整个测试用来的执行时间。\    这样做最直接的好处就是，可以加快测试用例的执行，从而快速得到测试结果，提升整个持续交付流程的效率。3.  **提高测试用例准备的效率**。因为 Mock    技术可以实现对外部依赖的完全可控，所以测试人员在编写测试用例时，无需再去特别考虑依赖端的情况了，只要按照既定方式设计用例就可以了。那么，如何在测试中使用 Mock 技术呢？目前，市场上有很多不同的 Mock框架，你可以根据自己的情况进行选择。主要的应用场景可以分为两类：基于对象和类的Mock，基于微服务的 Mock。**第一，基于对象和类的 Mock**基于对象和类的 Mock，我比较推荐使用的框架是 Mockito 或者 EasyMock。Mockito 或者 EasyMock 这两个框架的实现原理，都是在运行时，为每一个被Mock 的对象或类动态生成一个代理对象，由这个代理对象返回预先设计的结果。这类框架非常适合模拟 DAO层的数据操作和复杂逻辑，所以它们往往只能用于单元测试阶段。而到了集成测试阶段，你需要模拟一个外部依赖服务时，就需要基于微服务的Mock 粉墨登场了。**第二，基于微服务的 Mock**基于微服务的 Mock，我个人比较推荐的框架是 Weir Mock 和 MockServer。这两个框架，都可以很好地模拟 API、http 形式的对象。从编写测试代码的角度看，Weir Mock 和 Mock Server 这两种测试框架实现 Mock的方式基本一致：1.  标记被代理的类或对象，或声明被代理的服务；2.  通过 Mock 框架定制代理的行为；3.  调用代理，从而获得预期的结果。可见，这两种 Mock 框架，都很容易被上手使用。**第三，携程的 Mock Service 实践**在携程，我们一次集成测试，可能依赖的外部服务和数据服务会有几百个，而这几百个服务中很多都属于基础服务，都有被Mock 的价值。所以，携程借鉴了 Mock Server 的想法，在整个测试环境中构建了一套 MockService：所有服务的请求，都会优先通过这套系统；同时，所有服务的返回也会被拦截。这套Mock Service 看起来就像是一个巨大的代理，代理了所有请求。那么，测试人员只要去配置自己的哪些请求需要被 Mock Service代理就可以了，如果请求的入参相同，且 Mock Service中存在该请求曾经的返回，则直接被代理。反之，则透传到真正的服务。虽然这会增加性能开销，但是对于整体的回归测试来说，价值巨大，而且方便好用、无需编码。Mock技术，通过模拟，绕过了实际的数据调用和服务调用问题，横在我们面前的"三座大山"中的其中两座，测试数据的准备和清理、分布式系统的依赖算是铲平了。但是如何解决"第三座大山"呢，即如何做到模拟用户真正的操作行为呢？
## 两大利器之二"回放"技术**要做到和实际用户操作一致，最好的方法就是记录实际用户在生产环境的操作，然后在测试环境中回放。**当然，我们要记录的并不是用户在客户端的操作过程，而是用户产生的最终请求。这样做，我们就能规避掉客户端产生的干扰，直接对功能进行测试了。**首先，我们一起来看一下如何把用户的请求记录下来。**这里我们需要明确一个前提原则，即：我们并不需要记录所有用户的请求，只要抽样即可，这样既可以保持用例的新鲜度，又可以减少成本。我们在携程有两种方案来拦截记录用户操作：-   第一种方案是，在统一的 SLB    上做统一的拦截和复制转发处理。这个方案的好处是，管理统一，实现难度也不算太大。但问题是，SLB    毕竟是生产主路径上的处理服务，一不小心，就可能影响本身的路由服务，形成故障。所以，我们有了第二种替换方案。-   第二种方案是，在集群中扩容一台服务器，在该服务器上启动一个软交换，由该软交换负责复制和转发用户请求，而真正的用户请求，仍旧由该服务器进行处理。\    这个方案比第一种方案稍微复杂了一些，但在云计算的支持下，却显得更经济。你可以按需扩容服务器来获取抽样结果，记录结束后释放该服务器资源。这个过程中，你也不需要进行过多的配置操作，就和正常的扩容配置一样，减少了风险。这样，我们就完成了用户行为的拦截记录。而用户行为记录的保存格式，你也可以根据要使用的的回放工具来决定。**然后，我们再一起看看回放的多样性。**因为回放过程完全由我们来控制，所以除了正常的原样回放外，我们还可以利用回放过程达到更多的目的。我们既可以按照正常的时间间隔，按照记录进行顺序回放；也可以压缩回放时间，形成一定的压力，进行回放，达到压力测试的目的。而且，如果可以对记录的请求数据做到更精细的管理，我们还可以对回放进一步抽样和删选，比如只回放符合条件的某些请求等等，找出边界用例，利用这些用例完成系统的容错性和兼容性测试。当然，你如果希望做到回放的精细管理，那我的建议是根据你的实际业务特性自研回放工具。自研回放工具的整体思路其实非常简单，就是读取拦截的访问记录、模拟实际协议、进行再次访问。当然，你还可以给它加上更多额外的功能，比如数据筛选、异常处理、循环重复等等。现在，利用"回放"技术，我们也顺利翻越了最后"一座山"，实现了用户行为的高度仿真。
## 总结我以提出问题 - 分析问题 - 解决问题的思路，和你展开了今天的分享内容。首先，我和你分享了自动化回归测试会遇到的三个难题：测试数据的准备和清理、分布式系统的依赖，以及测试用例的高度仿真。我们可以利用 Mock技术（即通过代理的方式模拟被依赖的对象、方法或服务的技术），通过不同的框架，解决自动化回归测试的前两个问题：-   基于对象和类的 Mock，解决一个应用内部依赖的问题；-   基于微服务的 Mock，解决应用与应用之间外部依赖的问题。然后，我和你分享了携程的"回放技术"，即先通过虚拟交换机，复制和记录生产用户的实际请求，在测试时"回放"这些真实操作，以达到更逼真地模拟用户行为的目的，从而解决了自动化回归测试遇到的第三个问题。所以，利用 Mock和"回放"技术，我们能够提高自动化回归测试的效率和准确度，从而使整个持续交付过程更顺滑，自动化程度更高。
## 思考题你所在的公司，有没有合理的回归测试过程？如果没有，是为什么呢，遇到了什么困难？通过我今天分享的内容，你将如何去优化这个回归测试的过程呢？感谢你的收听，欢迎你给我留言。![](Images/69e5b7a8ed8eecd006aa3ce5f76f78af.png){savepage-src="https://static001.geekbang.org/resource/image/55/0a/55b7b7cb930ca733523be64e3a720d0a.jpg"}
# 28 \| 持续交付为什么要平台化设计？你好，我是王潇俊。今天我和你分享的主题是：持续交付为什么要平台化设计？专栏内容已经更新一大半了，我和你也基本上已经逐个聊透了持续交付最核心的五大部分内容，包括：配置管理、环境管理、构建集成、发布及监控、测试管理。理解了这五大部分基本内容，你也就已经基本掌握了持续交付的核心内容，以及整个闭环流程了。我猜想你可能已经开始尝试在团队内部署一套持续交付体系了，在部署的过程中又碰到了一些问题：比如，是否要为不同的语言栈建立不同的构建和发布通道；又比如，我还滞留在手工准备环境的阶段，无法有效自动化，应该怎么办。要解决这些问题，你就需要达到一个更高的高度了，即以平台化的思维来看待持续交付。那么从今天开始，我们就一起来聊聊持续交付平台化的话题吧。
## 什么是平台化"平台化"这个词，你应该已经听到过很多次了吧。特别是互联网领域，我们都爱谈论平台化。那么，"平台化"到底是什么意思呢？其实，早在 20 世纪 70年代，欧洲的军工企业就开始利用平台化的思维设计产品了。当时的设计人员发现，如果分别研制装甲车、坦克和迫击炮的底盘，时间和金钱成本的消耗巨大。因为这些武器的底盘型号不同，所以它们所需要的模具、零件也就不同，除了要分别设计、制造、测试、生产外，还要花费巨额成本建设不同的生产流水线，而且各底盘的保养和使用方式不同，需要进行不同的人员培训。可想而知，这样分别设计的成本是巨大的。``{=html}所以，这些军工企业们就决定要采用一个通用的底盘设计，然后在通用底盘上安装不同的炮管和武器，达到个性化的需求。之后，这种平台化的设计和制造方法，在航空制造业和汽车制造业得到了广泛运用，获得了极大的成功，并一直被沿用至今。而，**互联网又再次给"平台化"插上了新的翅膀。互联网厂商平台化的玩法，往往是指自己搭台子，让其他人唱戏**。也就是说，由互联网厂商自己提供一些基础保障能力，建立必要的标准，从而形成底层支撑平台；而由其他供应商或用户利用这个底层平台提供的服务，自己完成具体业务、功能流程设计，从而达到千人千面的个性化服务能力。互联网厂商的这种做法，就使得企业的服务能力被放大到了极致。
## 持续交付为什么要实现平台化？持续交付要做到平台化的原因，主要可以归结为以下三方面。1.  **随着软件技术的发展，任何企业最终都将面临多技术栈的现实**。不同的技术栈，就意味着不同的标准、不同的工具、不同的方式，所以我们就必须要通过合理的持续交付平台，去解决不同技术栈的适配工作。2.  **随着持续交付业务的发展，团队会越来越庞大，分工也会越来越明细**。这就要求持续交付体系能够支持更大规模的并发处理操作，同时还要不断地提升效率。更重要的是，当持续交付成为企业研发的生命线时，它必须做到高可用，否则一旦停产，整个研发就停产了。3.  **随着持续交付技术本身的发展，还会不断引入新的工具，或新的流程方法**。如果我们的持续交付体系不能做到快速适应、局部改造、高可扩展的话，那它自身的发展与优化将会面临严峻的挑战。以上三个方面的原因，决定了我们需要打造一套高可用、可扩展的持续交付平台。
## 持续交付平台的设计在前面的几个系列中，我分享了很多与持续交付的选型、实践与做法相关的内容。那么，在持续交付平台化的系列中，我会和你一起去整合前面看似零散的内容。为此，我总结了实现持续交付平台化的 7 个步骤，也可以说是 7个方法论，通过对这 7 个步骤的思考，你将清楚，要构建一套持续交付平台：1.  具体需要做哪些工作；2.  资源有限时，如何取舍；3.  最重要的任务是什么；4.  外部对你的限制和帮助有哪些。希望通过我的总结，结合之前的分享，你能把持续交付的各个阶段串联起来，形成自己的平台化思路。**第一步，确定模块及其范围**交付流水线的概念，我已经在专栏第一篇文章[《持续交付到底有什么价值》](https://time.geekbang.org/column/article/10334)中介绍过了。如果你记不太清楚了，可以再回顾一下这篇文章的内容。持续交付平台的工作流程基本就是根据这个流水线确定的，即：由编码开始，经过集成编译，再部署到相应环境，进行测试，最后发布到生产环境的过程。持续交付平台最终将完成这个端到端的过程，那么流水线的每一步都可以认为是一个模块。由此，整个平台的核心模块就是：代码管理、集成编译、环境管理、发布部署。这四个模块是持续交付平台中最核心，最容易做到内聚和解耦的模块。每个核心模块的周围，又围绕着各种子模块，比如：-   代码管理模块，往往会和代码审核、静态扫描和分支管理等模块相联系；-   集成编译模块，也会与依赖管理、单元测试、加密打包等模块相生相随的；-   环境管理模块，离不开配置管理、路由管理等模块；-   发布部署模块，还需要监控模块和流控模块的支持。![](Images/0819c0617d23294b72c8e38fb59c3a24.png){savepage-src="https://static001.geekbang.org/resource/image/67/a4/67f87e8bcde185a9b4ca84f612100aa4.png"}```{=html}```图 1 持续交付平台核心模块```{=html}```这样，如上图所示，根据交付流程划分完模块后，整个持续交付平台所要涵盖的大致范围也就确定了。**第二步，学会做减法**好的产品，都需要不断地做减法，持续交付平台也是如此。我们已经在第一步罗列了需要完成的模块，但很显然，不可能一下子完成所有的这些模块设计和开发a。所以，持续交付平台设计的第二步，就如何抓住最核心的内容。正如我在第一篇文章[《持续交付到底有什么价值》](https://time.geekbang.org/column/article/10334)中所说，并不是只有完整的端到端自动化才叫"持续交付"，代码管理，集成编译，环境管理、发布部署这四大核心模块，其实就是一个交付的闭环，只是交付的内容不同，但这些交付都是可测的、可评定的，所以并不是半成品。因此，**我们就可以考虑挑选最为重要或最为急迫的模块，优先加以实施。甚至，你可以优先实现这四个模块中的一个，先解决一部分问题。这样做减法的方式，我们称为横向缩小范围。****另外一种做减法的方式是减少纵向的深度**。也就是优先支持单一的技术栈，或特定的、比较简单的场景，比如先搞定组织内的单体应用。通过做减法先完成这个平台最核心模块的方式，可以控制平台的初建成本，而且效果也比较容易预期。比如，携程就是优先完成了发布部署模块，再逐步向持续交付的上游拓展。而对于后续要做加法的事情，可以以后或者由其他团队慢慢补上，这才是平台的意义。**第三步，制定标准****研发任何系统，首先要记住一句话："标准先行"。**我们谈到标准时，往往会涉及很多方面，比如：对外衔接的标准、对内沟通的标准；质量的标准，速度的标准等等。而**对持续交付平台的设计来说，最重要的标准是定义各个模块交付产物的标准。**-   比如，代码管理模块，最终的交付产物到底是什么，形式又是什么：是一个代码包，还是    git 仓库地址；-   又比如，发布部署模块，到底执行的是怎样的过程：重启应用是使用线程回收机制，还是进程重启机制；只有制定了标准，其他团队或者其他系统才能有据可依地逐步加载到这个平台之上。不同的组织和企业，标准和规范的内容要求不一样。所以，我无法一一列举这些标准和规范，但是你一定要清楚，这是重中之重的一个步骤。**第四步，选择合适的驱动器**所谓驱动器，就是用来驱动整个持续交付流水线的引擎。不同规模的团队，适合的驱动器不同：-   中小规模的团队，我推荐使用开源的系统做驱动器，比如使用 Jenkins    作为驱动器（当然 Jenkins 还有资源调度和编排能力）。-   较大规模的团队，或者业务比较复杂的情况下，我建议自行研发驱动器，以适应自身组织的特殊需求。\    当然，我并不是说自行研发驱动器肯定就比 Jenkins    这样的系统要好。但是，后者更注重普适性，而前者则可以根据自身业务情况进行取舍，甚至不需要考虑流水线的可配置性，直接使用状态机写死流程。这样的好处是掌控力强，修改简单，且不易出错。-   如果是更大规模的团队，我的建议是把驱动器与功能模块同等看待，将流水线驱动看做是平台的一个抽象功能，既可以驱动    CI 或 CD    功能，也可以驱动其他的任务；其他模块提供的服务都是这个驱动服务可以执行的具体实现而已。\    在复杂情况下，"人"才是最好的驱动器，可以做出最正确的判断。有些特殊的复杂场景，机械的驱动器程序已经无法解决，需要人工介入。所以通过驱动服务，既可以驱动自动化任务，同时又可以驱动"人"，才能保证最优的结果。**第五步，抽象公共能力**既然我们要设计一个平台，自然就要把很多公共功能抽象到平台层处理。需要抽象的公共功能，主要包括：1.  账户与权限，包括单点登录，以及鉴权、授权体系等等；2.  用户行为日志，即任何行动都要能够被追溯；3.  消息通知，即提供统一的通知能力；4.  安全与故障处理，即系统级的防护能力和故障降级。持续交付平台的设计，除了要抽象这些公共功能外，还需要考虑打通上下游系统的问题，比如需要从CMDB 获取服务器信息，从应用中心获取应用信息等等。**第六步，考虑用户入口**完成了持续交付平台内部功能的设计后，就要考虑用户入口的问题了。用户入口，是提供一个统一的站点、使用命令行格式、使用 IDE插件，还是直接使用 Jenkins系统作为与用户交互的界面，可以根据团队的资源、能力等实际情况进行选择。通常情况下，我会比较建议为持续交付独立形成一个Portal，这样不会受到其他系统的限制，你可以根据自己的设计更好地完成用户引导和使用体验的设想。**第七步，聚力而成**通过上面这六步，我们已经初步完成了持续交付平台的设计，之后就是如何实现的问题了。**其实，如何实现持续交付的平台化，主要看你的决心和实践。但一定要记住，如果你决定要实施一个持续交付的平台，那就一定要学会运用团队的力量。**比如，架构同学，一定能够在制定规范和架构方面给你建议和帮助；而运维同学，肯定在环境治理和部署方面比你更有经验。所以，你要做的是搭好平台，利用团队优势共同建设持续交付体系。以上的内容，就是搭建一套持续交付平台最关键的七个步骤了。这里，我们可以用一张图片，表示这个持续交付平台的大致架构。![](Images/81f1af41ef389aa6f72bd216a6cf86bb.png){savepage-src="https://static001.geekbang.org/resource/image/ab/84/ab0cfb98c7b61e7b310dfc8a18616284.png"}```{=html}```图 2 持续交付平台的大致架构```{=html}```