needed. We outline the updated backwards-selection algorithm
in Appendix B. In recent research, Vila et al. [42] provide an
optimized algorithm to reduce eviction sets to minimal eviction
sets. Applying the new algorithm could further improve the
performance of the backwards-selection.
Optimization 4 Our ﬁnal optimization introduces a clean-
up step. After successfully building an eviction set for one
cache set, we iterate over the whole pool of addresses to
ﬁnd other addresses that also map to this same cache set.
Either they were not part of S in the ﬁrst place, or they were
redundant in S and can be removed from the minimal eviction
set. This clean-up step helps to shrink the pool of addresses
considered by the forward-selection algorithm (and the rest of
the pipeline) for the subsequent cache sets.
Resilience Our experiments employ multiple strategies to cope
with network noise, network queuing, and the side effects of
Fig. 4: Memorygram of DDIO-ways experiment. Darker colors imply
faster, and lighter colors imply slower access times. From left to
right, we increase the number of n addresses written before reading
all addresses back (between 0 and 20). The latencies correspond to
read access times.
1 MB sized chunks. In order to allocate a large enough memory
region to build an eviction set, we allocate multiple 1 MB
sized key-value items. Once the objects are allocated, they can
be accessed at arbitrary offsets with basic one-sided RDMA
operations.
One challenge in building the eviction sets is that we have
no knowledge of the virtual or physical addresses of the
RDMA memory region on the remote machine. However, we
can control our accesses through an offset relative to a base,
combined with the knowledge that allocated memory chunks
are page aligned. Oren et al. [14] engineered a non-canonical
PRIME+PROBE for a similar problem when they attacked
the LLC from JavaScript. We base our approach on their
algorithm, with the caveat that we must address challenges
resulting from running the algorithm over the network. These
challenges include resilience against timing shifts caused by
network variance, and the involvement of a second machine
in the measuring process. Moreover, read and write operations
over the network are orders of magnitude slower than run
locally.
The broader idea of the algorithm [14] is to use a set S
of page-aligned addresses, all with the same offset from the
page start, and a candidate address x. The set is initially quite
large so that it naturally forms an eviction set for address x.
The algorithm then reduces the set by iteratively removing
addresses and checking whether the set still forms an eviction
set. Using this backwards-selection strategy,
the algorithm
creates a minimal eviction set of size equal to the number
of cache ways. After ﬁnding one eviction set for the given
offset within a page, the algorithm can build eviction sets for
the rest of the offsets. With a page size of 4KB and a cache
line size of 64B, this yields an additional 63 eviction sets.
Our ﬁrst naïve approach used multiple rounds to measure
whether the set S still forms an eviction set, to account for the
measurement noise over the network. However, this made the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:37:59 UTC from IEEE Xplore.  Restrictions apply. 
25
We can see that network latency has a direct inﬂuence on
the time it takes to proﬁle the whole LLC. Furthermore, the
performance of the algorithm increased when fewer addresses
were in the pool. This speedup is due to the clean-up step
where addresses that belong to the same cache set are removed
from the pool, thus reducing the search space of the algorithm
over time. The shown latencies are reported by the ib_read_lat
latency benchmark. The standard deviation of the latencies of
the three cluster machine combinations was between 0.08μs
and 0.10μs. The standard deviation of the latencies for the
Intel Xeon Silver 4110 cluster was 0.11μs. In the trace of the
Xeon Silver, we can also observe a sanity check failing at
around minute three, at which point the algorithm recovers by
restarting the current proﬁling round. To verify the correctness
of the eviction set, we implemented a veriﬁcation procedure
that tests every eviction set against other addresses that are
mapped to the same cache set, in order to check whether they
are evicted. Furthermore, we test the eviction sets against each
other to verify their uniqueness.
To conclude, we have shown that it is possible to create an
eviction set for the DDIO cache lines in a data center topology
in under 6 minutes.
VII. COVERT CHANNEL
In this section, we present two cooperative DDIO-based
attacks. In the ﬁrst scenario, we build a covert channel between
two clients that are not on the same network but can send pack-
ets to a shared server. In the second scenario, we build a covert
channel between a client and a sandboxed process on a server.
We use the high-bandwidth covert channel protocol from Lui
et al. [9], originally used to send data between two virtual
machines running on the same physical machine. Similar to
our covert channel, Maurice et al. [44] describe a cross-core
covert channel between processes and Oren et al. [14] describe
a covert channel built from JavaScript. Further, Maurice et
al. [45] developed a robust and error-free covert channel
protocol, which was used to transmit an SSH connection
between two virtual machines. We present an adversarial
network-based keystroke timing attack in Section VIII.
A. Covert Channel Between Network Clients
In the ﬁrst scenario, the two clients send RDMA pack-
ets to the target server, but they do not share a common
RDMA memory region (i.e., cannot communicate directly).
Furthermore, the clients are not able to communicate with
each other directly over the network. Such a scenario could
be enforced by having two different physical networks or a
logical separation between networks. From Section VI, we
know that we can measure the cache activities of the whole
DDIO portion of the LLC. This means we can also measure
the activity of another client over the network in the LLC.
Thus, in a cooperative setting, two clients can communicate
by sending packets to different offsets in their respective
RDMA buffers, while the other client detects which offset
was activated by the other client’s packet. In our unidirectional
covert channel, the ﬁrst step in establishing communication is
Fig. 5: Cumulative cache set proﬁling evaluation with different
machine combinations in a data center.
the measurement machine itself. First, we use multiple mea-
surement rounds and take the median latency measurement.
This simple yet effective approach signiﬁcantly improves the
stability of building the eviction sets. The number of rounds
is a trade-off between performance and reliability, and can
be adjusted to the noise factors in different environments.
However, note that we can only use this approach if we control
the operation we want to measure. This is the case when
building eviction sets, but as we will see later, it is not the
case for keystroke detection.
Second, as shown in Section V, DDIO reads do not cause
cache allocations if they are served from main memory.
Therefore, we know a priori that a DDIO read does not change
the state of the LLC. We can use this behavior to our advantage
by reading the same address multiple times consecutively and
taking the median latency of these micro rounds. Such micro
rounds are especially useful when complete rounds are not
possible.
Finally,
(forward-selection,
backward-selection, and clean-up) have multiple built-in sanity
checks. In case a test fails, the pipeline either goes back to
the previous stage or completely restarts the proﬁling for this
cache set.
stages
the
three different
B. Evaluation
We evaluated the remote eviction set building algorithm on
the DAS-5 cluster [43]. This allowed us to test the algorithm
with machine pairs that have different latencies, depending on
where they are located in the data center and with different
number of switch hops. All machines have the same processor
(Intel Xeon E5-2630 v3) and machine conﬁgurations. Fur-
thermore, we evaluated the algorithm on a second Intel Xeon
Silver 4110 cluster to show the generality of our attack. We
used an initial pool of 5,000 page-aligned addresses to build
the eviction set. We proﬁled a total of 16,384 cache sets (256
colors, 4KB page size).
As shown in Figure 5, the total proﬁling time was between
3 minutes and 19 seconds, and 5 minutes and 52 seconds.
26
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:37:59 UTC from IEEE Xplore.  Restrictions apply. 
ally.
B. Covert Channel to Sandboxed Process
In this scenario, we have a sandboxed process on the server
that has no access to any networking capabilities. However,
the sandboxed process can still write to the LLC. To build
a covert channel, we observe that this scenario is similar to
the previous one, except that the sandboxed process is the
sender and the client is the receiver. The difference with the
covert channel between the two network clients is that memory
accesses by the sandboxed process do not necessarily spill into
the receiver-visible LLC portion dedicated to DDIO.
In our setting, the DDIO region of the LLC consists of two
cache lines (2 ways in the LLC). Thus, to ensure a successful
transmission, the sandboxed process must write n − 1 cache
lines in an n-way set associative LLC, guaranteeing that the
write is visible in the DDIO region. In a non-inclusive LLC,
the process must also consider the L2 cache, since the L2
must be ﬁlled before data is written into the LLC. Regardless
of whether the LLC is inclusive, the sandboxed process must
ﬁrst create an LLC eviction set, following strategies form prior
work [7, 14]. Once eviction sets are found for 64 different
cache sets, the covert channel can be built similarly to the
case with two network clients, the main difference being that
instead of one write per cache set, the sandboxed process must
write the entire eviction set per targeted cache set. The receiver
can then use PRIME+PROBE to monitor these evictions from
the network.
Results Similar to our covert channel between network clients,
the transmission rounds are loosely synchronized with a pre-
deﬁned time window. Also similarly, the covert channel band-
width is limited by how fast a receiving client can check the
64 cache sets. Hence, even though the sender must issue more
write operations compared to the previous covert channel,
these operations are done natively on the CPU, making them
much faster than the receiver’s network-based operations. As a
result, the bandwidth for the sandboxed process covert channel
is the same as for the network to network covert channel.
VIII. NETWORK-BASED KEYSTROKE ATTACKS
In this section, we present results from an adversarial
setting. We measure keystroke timings on an SSH connection
from a victim to reconstruct sensitive (typed) data. Our goal
here is not to improve upon the existing body of keystroke at-
tack literature, but rather demonstrate our cache measurements
are sufﬁciently accurate to implement practical, adversarial
timing attacks.
On a high level, our attack works as follows. The attacker
controls a machine that has an RDMA link to an application
server as illustrated in Figure 2. The attacker uses remote
PRIME+PROBE to detect network activity in the LLC. A user
then opens an interactive SSH session to the application server
from a different machine. In an interactive SSH session, each
keystroke is sent in a separate packet. The attacker is able
to recover the inter-packet times from the cache using the
ring buffer location and map them to keystrokes. As we will
Fig. 6: Evaluation of the covert channel between two network clients.
We compare the peak bit rate versus the resulting error bit rate.
to agree on which cache sets will be used for the transmission.
The sender chooses a page-aligned memory location and then
uses the cache sets that cover that location for communication.
To synchronize, the sender then iterates over all successive
cache sets in the page and sends packets (using RDMA writes)
to these cache sets in a distinct pattern over a long period of
time.
The receiver iterates over all proﬁled cache sets to detect
the pattern. This allows the receiver to ﬁnd the 64 cache sets
(i.e., a page) that cover a page with the same color as the
sender’s page. The two parties have now agreed on 64 shared
cache sets on the server. Therefore, in every round, the sender
can transmit 64 bits by either activating or not activating
each of the 64 cache sets. In order to loosely synchronize
the measurements, we use the approach from Lui et al. [9].
The sender transmits the current round of information multiple
times over a predeﬁned amount of time. The receiver measures
the cache activity for the same amount of time and therefore
knows when a transaction round is completed. The time the
receiver needs to PRIME+PROBE 64 cache sets is the minimum
time window for each round.
Results The appropriate time window for the covert channel
depends on the time in which the receiver can launch at least
one PRIME+PROBE iteration. In our test networks [43], the
smallest possible time window which reliably allowed the
receiver to ﬁnish its operation within the window is 0.44 ms.
This translates to a peak bandwidth of 145.45 Kb/s. Under
this condition, we have an error rate of 9.43%. We evaluated
multiple time windows up to a conservative choice of 4 ms
(16 Kb/s). In a longer window, the receiver can launch multiple
PRIME+PROBE iterations. Therefore, the receiver gains more
data points, which results in a lower error rate. At the 4 ms
window, we measured an error rate of 0.20%. Figure 6
illustrates our experiments with different time window sizes.
Note that this simple covert channel protocol has no built-in
reliability; if more reliability (i.e., redundancy) is needed, then
the bandwidth of the covert channel will decrease proportion-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:37:59 UTC from IEEE Xplore.  Restrictions apply. 
27
As most modern operating systems have a default network
ring buffer size of 512–4096 entries, the staircase pattern still
emerges, but covers multiple pages. As the pattern is cyclic,
the attacker can reconstruct all possible locations of the ring
buffers and predict where to expect the next cache activity.
Modern NICs and operating systems often support multiple
RX and TX queues, and use mechanisms such as receive-side
scaling (RSS) to distribute packets over different queues on
the receiving side, according to a hash over the packet data.
Speciﬁcally, the hash function is typically a ﬁve-tuple input
hash over the source IP address, source port, destination IP
address, destination port, and the protocol. By changing the
source port and protocol, an attacker can map all different
queues with the proﬁling method mentioned above. For sim-
plicity, but without loss of generality, we illustrate the attack
on a system that has one RX queue enabled and a ring buffer
that resides within one page, i.e., 128 entries.
B. Tracking the Ring Buffer
Once we have determined the page containing the ring
buffer, we want to track the exact movements of the ring buffer
to leak incoming inter-packet times. One challenge is that
when we see an activation of a cache set, we cannot be sure
whether this was due to the ring buffer or due to other cache
activity. Furthermore, one observed activity of the ring buffer
can mean that one or two packets were received, since both
subsequent packets activate the same cache set. Lastly, unlike
in cooperative attacks, we cannot use multiple measurement
rounds because the location of the ring buffer may change
between measurements.
To overcome these challenges, we designed a two-stage
pipeline to extract inter-packet times. An online tracker is
in charge of following the Ethernet NIC ring buffer during
the measurements, and sends Ethernet probing packets to
continuously conﬁrm its position in the cache, determined by
sending the RDMA cache PRIME+PROBE packets. The ofﬂine
extractor takes the data produced by the tracker and uses it to
compute the likeliest occurrences of client Ethernet network
packets (non-probing packets, more speciﬁcally, client SSH
packets). The following two paragraphs detail how these two
algorithms are designed.
Online tracking Repeatedly checking all 64 eviction sets is
too slow to measure unsynchronized network packets. Thus,
we reduce the number of eviction sets measured at the same
time by forming a window w of measurements and shifting
w according to the current position of the ring buffer pointer.
One of the challenges with this approach is deciding when
to shift the window in order to follow the head of the ring
buffer. To solve this challenge, we send packets from the
attacker machine between measurement rounds. These packets
guarantee ring buffer advancement and corresponding cache
miss. If the online tracker does not observe this, we know
that we must adjust the position of the window w. At a
high level, the online tracking algorithm works as follows.
First, we have to determine the current position pos of the
ring buffer. We do this by sending many network packets in
Fig. 7: Memorygram of
ring buffer experiment with remote
PRIME+PROBE. Darker colors imply faster and lighter colors imply
slower access times. In every round we send two network packets.
We can see that the ring buffer moves forward each round.
show in this section, such an attack can be launched with
a single trace of sensitive data. After launching a remote
PRIME+PROBE to measure LLC activity, a successful attack
requires the following steps:
1) Locate the network ring buffers of the RX-Queues.
2) Track the RX head to recover incoming packet times.
3) Use machine learning to map times to keystrokes.
A. Locating Ring Buffers in the LLC
A ring buffer is a circular data structure that facilitates
processes in reading and writing data asynchronously. In the
case of networking, ring buffers are used as a queue between
the NIC and the operating system. The ring buffer does not
hold packet data directly, but rather pointers to the actual
packet data structure (socket kernel buffers). Modern operating
systems often have distinct queues (ring buffers) for receiving
(RX) and sending (TX) packets. The network ring buffers
are often allocated over multiple differently colored pages,
which should prevent the ring buffer from self-evicting from
the cache. Our experiments show that the ring buffer accesses
leave a very distinct pattern in a memorygram. Speciﬁcally,
two consecutive incoming packets activate the same eviction
set, the next two packets then activate the next eviction set,
and so on. As a result, for multiple consecutive packets, a
staircase-like pattern becomes visible in the memorygram, as