USENIX Association
27th USENIX Security Symposium    993
Crucially, in contrast to all previously published SGX
side-channel attacks [17,39,45,51,57,58,60] and existing
Spectre-style speculative execution attacks [7, 49] against
SGX enclaves, Foreshadow does not require any side-
channel vulnerabilities, code gadgets, or even knowledge
of the victim enclave’s code. In particular, our attack is
immune to all currently proposed side-channel mitigations
for SGX [8, 9, 18, 52–54], as well as countermeasures for
speculative execution attacks [31, 32]. In fact, as long as
secrets reside in the enclave’s address space, our attack
does not even require the victim enclave’s execution.
Breaking SGX Conﬁdentiality. The Intel SGX doc-
umentation unequivocally states that “enclave memory
cannot be read or written from outside the enclave regard-
less of current privilege level and CPU mode (ring3/user-
mode, ring0/kernel- mode, SMM, VMM, or another en-
clave)” [28]. As Foreshadow compromises conﬁdentiality
of production enclave memory, this security objective of
Intel SGX is clearly broken.
Our basic attack requires enclave secrets to be residing
in the L1 data cache. We show how unprivileged adver-
saries can preemptively or concurrently extract secrets
as they are brought into the L1 data cache when execut-
ing the victim enclave. For root adversaries, we further-
more contribute an innovative technique that leverages
SGX’s paging instructions to prefetch arbitrary enclave
memory into the L1 data cache without even requiring
the victim enclave’s cooperation. When combined with
a state-of-the-art enclave execution control framework,
such as SGX-Step [57], our root attack can essentially
dump the entire memory and register contents of a victim
enclave at any point in its execution.
Breaking SGX Sealing and Attestation. The SGX de-
sign allows enclaves to “request a secure assertion from
the platform of the enclave’s identity [and] bind enclave
ephemeral data to the assertion” [2]. While we cannot
break integrity of enclaved data directly, we do leverage
Foreshadow to extract enclave sealing and report keys.
The former compromises the conﬁdentiality and integrity
of sealed secrets directly, whereas the latter can be used to
forge false local attestation reports. Our attack on Intel’s
trusted quoting enclave for remote attestation furthermore
completely collapses conﬁdentiality plus integrity guaran-
tees for remote computations and secret provisioning.
2.3 Microarchitectural x86 Organization
Instruction Pipeline. For a complex instruction set,
such as Intel x86 [10, 27], individual instructions are ﬁrst
split into smaller micro-operations (µops) during the de-
code stage. Micro-operation decoding simpliﬁes proces-
sor design: only actual µops need to be implemented in
hardware, not the entire rich instruction set. In addition
it enables hardware vendors to patch processors when a
ﬂaw is found. In case of Intel SGX, this may lead to an
increased CPU security version number.
Micro-operations furthermore enable superscalar pro-
cessor optimization techniques stemming from a reduced
instruction set philosophy. An execution pipeline im-
proves throughput by parallelizing three main stages.
First, a fetch-decode unit loads an instruction from main
memory and translates it into the corresponding µop se-
ries. To minimize pipeline stalls from program branches,
the processor’s branch predictor will try to predict the
outcome of conditional jumps when fetching the next
instruction in the program stream. Secondly, individual
µops are scheduled to available execution units, which
may be duplicated to further increase parallelism. To max-
imize the use of available execution units, simultaneous
multithreading (Intel HyperThreading) technology can
furthermore interleave the execution of multiple indepen-
dent instruction streams from different logical processors
executing on the same physical CPU core. Finally, dur-
ing the instruction retirement stage, µop results are com-
mitted to the architecturally visible machine state (i.e.,
register and memory contents).
Out-of-Order and Speculative Execution. As an im-
portant optimization technique, the processor may choose
to not execute sequential micro-operations as provided
by the in-order instruction stream. Instead, µops are exe-
cuted out-of-order, as soon as the required execution unit
plus any source operands become available. Following
Tomasulo’s algorithm [55], µops are dynamically sched-
uled, e.g., using reservation stations, and await the avail-
ability of their input operands before they are executed.
After completing µop execution, intermediate results are
buffered, e.g., in a Reorder Buffer (ROB), and committed
to architectural state only upon instruction retirement.
To yield correct architectural behavior, however, the
processor should ensure that µops are retired according
to the intended in-order instruction stream. Out-of-order
execution therefore necessitates a roll-back mechanism
that ﬂushes the pipeline and ROB to discard uncommitted
µop results. Generally, such speculatively executed µops
are to be dropped by the CPU in two different scenarios.
First, after realizing an execution path has been mispre-
dicted by the branch predictor, the processor ﬂushes µop
results from the incorrect path and starts executing the
correct execution path. Second, hardware exceptions and
interrupts are guaranteed to be “always taken in the ‘in-
order’ instruction stream” [27], which implies that all
transient µop results originating from out-of-order in-
structions following the faulting instruction should be
rolled-back as well.
994    27th USENIX Security Symposium
USENIX Association
CPU Cache Organization. To speed up repeated code
and data memory accesses, modern Intel processors [27]
feature a dedicated L1 and L2 cache per physical CPU
(shared among logical HyperThreading cores), plus a
single last-level L3 cache shared among all physical cores.
The unit of cache organization is called a cache line and
measures 64 bytes. In multi-way, set-associative caches,
a cache line is located by ﬁrst using the lower bits of the
(physical) memory address to locate the corresponding
cache set, and thereafter using a tag to uniquely identify
the desired cache line within that set.
Since CPU caches introduce a measurable timing differ-
ence for DRAM memory accesses, they have been studied
extensively in side-channel analysis research [16].
2.4 Transient Execution Attacks
The aforementioned in-order instruction retirement en-
sures functional correctness: the CPU’s architectural state
(memory and register ﬁle contents) shall be consistent
with the intended program behavior. Nevertheless, the
CPU’s microarchitectural state (e.g., internal caches) can
still be affected by µops that were speculatively exe-
cuted and afterwards discarded. Recent concurrent re-
search [15, 24, 36, 40, 42] on transient execution attacks
shows how an adversary can abuse such subtle microarchi-
tectural side-effects to breach memory isolation barriers.
A ﬁrst type of Spectre [36] attacks exploit the CPU’s
branch prediction machinery to trick a victim protection
domain into speculatively executing instructions out of
its intended execution path. By “poisoning” the shared
branch predictor resource, an attacker is able to steer
the victim program’s execution into transient instruction
sequences that dereference memory locations the victim
is authorized to access but the attacker not. A second type
of attacks, including Meltdown [40] and Foreshadow,
exploit a more crucial ﬂaw in modern Intel processors.
Namely, that there exists a small time window in which
the results of unauthorized memory accesses are available
to the out-of-order execution, before the processor issues
a fault and rolls back any speculatively executed µops. As
such, Meltdown represents a critical race condition inside
the CPU, which enables an attacker to transiently execute
instructions that access unauthorized memory locations.
Essentially, transient execution allows an attacker to
perform secret-dependent computations whose direct ar-
chitectural effects are later discarded. In order to actually
extract secrets, a “covert channel” should therefore be es-
tablished to bring information into the architectural state.
That is, the transient instructions have to deliberately alter
the shared microarchitectural state so as to transfer/leak
secret values. The CPU cache constitutes one such reli-
able covert channel; Meltdown-type vulnerabilities have
therefore also been dubbed “rogue data cache loads” [24].
Figure 1: Rogue data cache loads can be leveraged to leak
sensitive data from more privileged security layers.
Figure 1 illustrates a toy example scenario where an
attacker extracts one bit of information across privilege
levels. In the ﬁrst step, an attacker attempts to read data
from a more privileged protection layer, eventually caus-
ing a fault to be issued and the execution of an exception
handler. But, a small attack window exists where attack-
ers can execute instructions based on the actual data read,
and encode secrets in the CPU cache. The example uses a
reliable FLUSH+RELOAD [61] covert channel, where the
transient instruction sequence loads a predetermined “or-
acle” memory location into the cache, dependent on the
least signiﬁcant bit of the kernel data just read. When the
processor catches up and eventually issues the fault, a pre-
viously registered user-level exception handler is called.
This marks the beginning of the second step, where the ad-
versary receives the secret bit by carefully measuring the
amount of time it takes to reload the oracle memory slot.
3 The Foreshadow Attack
In contrast to Meltdown [40], Foreshadow targets en-
claves operating within an untrusted context. As such,
adversaries have many more possibilities to execute the
attack. However, as explained below and further explored
in Appendix A, targeting enclaved execution also presents
substantial challenges, for SGX’s modiﬁed memory ac-
cess and non-terminating fault semantics reﬂect extensive
microarchitectural changes that affect transient execution.
We ﬁrst present our basic approach for reading cached
enclave secrets from the unprivileged host process, and
thereafter elaborate on various optimization techniques
to increase the bandwidth and success rate of our attack
for unprivileged as well as root adversaries. Next, we
explain how to reliably bring secrets in the L1 cache by
executing the victim enclave. Particularly, we explain
how to precisely interrupt enclaves and extract CPU reg-
ister contents, and we introduce a stealthy Foreshadow
attack variant that gathers secrets in real-time — with-
out interrupting the victim enclave. We ﬁnally contribute
an innovative kernel-level attack technique that brings
secrets in the L1 cache without even executing the victim.
USENIX Association
27th USENIX Security Symposium    995
Figure 2: Basic overview of the Foreshadow attack to extract a single byte from an SGX enclave.
3.1 The Basic Foreshadow Attack
The basic Foreshadow attack extracts a single byte from
an SGX enclave in three distinct phases, visualized in
Fig. 2. As part of the attack preparation, the untrusted
enclave host application should ﬁrst allocate an “oracle
buffer” 1 of 256 slots, each measuring 4 KiB in size (in
order to avoid false positives from unintentionally acti-
vating the processor’s cache line prefetcher [26, 40]). In
Phase I of the attack, plaintext enclave data is brought into
the CPU cache. Next, Phase II dereferences the enclave
secret and speculatively executes the transient instruction
sequence, which loads a secret-dependent oracle buffer
entry into the cache. Finally, Phase III acts as the re-
ceiving end of the FLUSH+RELOAD covert channel and
reloads the oracle buffer slots to establish the secret byte.
Phase I: Caching Enclave Secrets.
In contrast to pre-
vious research [15, 24, 40] on exploiting Meltdown-type
vulnerabilities to read kernel memory, we found consis-
tently that enclave secrets never reach the transient out-of-
order execution stage in Phase II when they are not already
residing in the L1 cache. A prerequisite for any successful
transient extraction therefore is to bring enclave secrets
into the L1 cache. As we noticed that the untrusted ap-
plication cannot simply prefetch [20] enclave memory
directly, the ﬁrst phase of the basic Foreshadow attack
executes the victim enclave 2 in order to cache plaintext
secrets. For now, we assume the secret we wish to ex-
tract resides in the L1 cache after the enclaved execution.
We elaborate on this assumption in Sections 3.3 and 3.4
for interrupt-driven and HyperThreading-based attacks
respectively. Section 3.5 thereafter explains how root ad-
versaries can bring secrets in the L1 cache without even
executing the victim enclave.
Note that, while Meltdown has reportedly been success-
fully applied to read uncached kernel data directly from
DRAM, Intel’s ofﬁcial analysis report clariﬁes that “on
some implementations such a speculative operation will
only pass data on to subsequent operations if the data is
resident in the lowest level data cache (L1)” [29]. We sus-
pect that SGX’s modiﬁed memory access semantics bring
about fundamental differences at the microarchitectural
level, such that the CPU’s access control logic does not
pass the results of unauthorized enclave memory loads
unless they can be served from the L1 cache. Intel con-
ﬁrmed this hypothesis, ofﬁcially referring to Foreshadow
as an “L1 Terminal Fault” attack. We furthermore pro-
vide experimental evidence in Appendix A, showing that
Foreshadow can indeed transiently compute on kernel
data in the L2 cache, but decisively not on enclave secrets
residing in the L2 cache.
Regarding Intel SGX’s hardware-level memory encryp-
tion [21], it should be noted that the MEE security perime-
ter encompasses the processor package, including the
entire CPU cache hierarchy. That is, enclave secrets al-
ways reside as plaintext inside the caches and are only
encrypted/decrypted as they move to/from DRAM. Practi-
cally, this means that transient instructions can in principle
compute on plaintext enclave secrets as long as they are
cached. As such, the MEE hardware unit does not impose
any fundamental limitations on the Foreshadow attack,
and is assuredly not the cause for the observation that we
cannot read enclave secrets residing in the L2 cache.
Phase II: Transient Execution.
In the second phase,
we dereference secret_ptr and execute the transient
instruction sequence. In contrast to previous transient
execution attacks [15, 24, 29, 40] that result in a page
fault after accessing kernel space, however, dereferencing
unauthorized enclave memory does not produce a page
fault. Instead, abort page semantics [28] apply and the
data read is silently replaced with the dummy value −1.
As such, in the absence of an exception, the race condition
does not apply and any (transient) instructions following
the rogue data fetch will never see the actual enclave
secret, but rather the abort page value.
Foreshadow overcomes this challenge by taking advan-
tage of previous research results on page table-based en-
claved execution attacks [58, 60]. Intel SGX implements
an additional layer of hardware-enforced isolation on top
of the legacy page table-based virtual memory protection
mechanism. That is, abort page semantics apply only
after the legacy page table permission check succeeded
without issuing a page fault.1 This property effectively
1 Alternatively, as a result of SGX’s additional EPCM checks [27],
rogue virtual-to-physical mappings also result in page fault behavior
996    27th USENIX Security Symposium
USENIX Association
enables the unprivileged host process to impose strictly
more restrictive permissions on enclave memory. In our
running example, we proceed by revoking 3 all access
permissions to the enclave page we wish to read:
1 mprotect( secret_ptr &~0xﬀf, 0x1000, PROT_NONE );
We veriﬁed that the above mprotect system call sim-
ply clears the “present” bit in the corresponding page table
entry, such that any access to this page now (eventually)
leads to a fault. This observation yields an important side
result, in that previous Meltdown attacks [15, 24, 29, 40]
focussed exclusively on reading kernel memory pages.
Intel’s analysis of speculative execution vulnerabilities
hence explicitly mentions that rogue data cache loads
only apply “to regions of memory designated supervisor-
only by the page tables; not memory designated as not
present” [29]. This is not in agreement with our ﬁndings.
As explained above, any enclave entry/exit event
ﬂushes the entire TLB on that logical processor. In our
running example, this means that accessing the oracle
slots in the transient execution will result in an expensive
page table walk. As this takes considerable time, the size
of the attack window will be exceeded and no secrets can