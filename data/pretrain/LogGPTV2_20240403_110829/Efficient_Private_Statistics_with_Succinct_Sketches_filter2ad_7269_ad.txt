using the Count-Min Sketch. We perform the prediction over a
subset of 12 consecutive epochs having the maximum number
of reported locations, giving the past 24 hours observations
as input to the EWMA algorithm. Figure 8 plots the Mean
Absolute Error (MAE) in the prediction compared to the
ground truth over the most 100 popular cells, considering
different values of α,
i.e., EWMA’s smoothing coefﬁcient
(cf. Section II-E). The plot shows that, in almost all slots,
lower values of α lead to more accurate results.
We then perform the prediction over the approximate heat
maps, i.e., using the sketches. We focus on the same time
slot, and ﬁx α = 0.1. Figure 9 shows the error introduced
by the Count-Min Sketch in the prediction, for each time
slot considered, with respect to the prediction based on the
“real” heat maps. We observe that this error, while ﬂuctuating,
is appreciably low for every prediction, thus conﬁrming the
9
generating a group of order q. Choose a random private
key x ∈ Zq, deﬁne the public key as pk = g1
x, and output
public parameters (E, g1, g2, pk ) and private key x.
2) Encrypt(m, pk ): The message m is encrypted by comput-
m),
ing two elliptic curve points as (A, B) := (g1
where r ∈ Zq is selected at random. The ciphertext is
thus the tuple of points (A, B).
3) Decrypt(A, B, x): Decryption is performed by computing
the element BA−x = g2
m. We can achieve constant
time decryption by pre-computing a table of discrete
logarithms which is then used to recover m from g2
m
(this solution is practical for small values of m).
r, pk rg2
most d, since each HSDir contribution increases by at most
1 in at most d values into the d · w Count Sketch table.
Therefore, we can achieve -differential privacy if we add, to
each decrypted value, noise from a Laplace distribution with
mean zero and variance ξ · d/, where ξ is the number of
decrypted intermediate results and  the differential privacy
parameter. However, doing so may result in the divide-and-
conquer algorithm mis-estimating the range in which the
median lies, and results in further mistakes in the ﬁnal median
estimate. (As discussed in Section II-C, although we use 
to denote a parameter for both Count Sketch and differential
privacy, it is clear from the context which one it relates to.)
AH-ECC is additively homomorphic since an element-wise
multiplication of ciphertexts yields an encryption of their sum.
B. Implementation and Evaluation
Setup. Our system relies on a set of authorities that can jointly
decrypt a ciphertext from the AH-ECC additively homomor-
phic public-key cryptosystem. During setup, each authority
generates their public and private key and a group public key
is computed by multiplying all the authorities’ public keys.
Note that we operate in a distributed system setting (i.e., the
Tor network), therefore, similar to PrivEx [32], one can easily
instantiate decryption authorities.
Protocol. Using Count Sketch, we can collect a number of
private readings from Hidden Service Directories (HSDir), and
compute an approximation of the median. Each HSDir builds
a Count Sketch, inserts its private values into it, encrypts it,
and sends it to the authorities. These aggregate all sketches
by homomorphically adding them element-wise, yielding an
encrypted sketch summarizing the set of all HSDir values.
Once the authorities have computed the aggregate sketch,
an interactive divide-and-conquer algorithm is applied to es-
timate the median given the range of its possible values is
known. At each iteration, the number of sample values in the
range is known, starting with the full range and all values
received. The range is then halved and the sum of all elements
falling in the ﬁrst half of the range is jointly decrypted. If the
median falls within ﬁrst half of the range it is retained for
the next iteration, otherwise the second half of the range is
considered at the next iteration. The process stops once the
range is a single element. Following the master theorem [21],
we know that this process converges in O(log n) steps, for n
elements in the domain of the values/median. Due to frequency
estimations for the ranges using Count Sketches that provide
noisy estimates, we expect this median to be close, but possibly
not exactly the same as the true sample median, depending on
the Count Sketch parameters δ and .
Output Privacy. Note that this process is not “perfectly”
private in a traditional secure computation setting, as the
volume of reported values falling within the intermediate
ranges considered is leaked. This may be dealt with in two
ways: (1) the leakage may be considered acceptable and
the algorithm run as described, or (2) the technique can be
enhanced to provide differential privacy by adding noise to
each intermediate value.
We implement and evaluate the proposed scheme aiming
to: (i) estimate the trade-off between size of the sketch and the
accuracy of the median computation, (ii) evaluate the cost of
cryptographic computation and communication overheads, and
(iii) assess the trade-off between the accuracy of the median
and the quality of protection that may be achieved through the
differentially private mechanism.
For our evaluation, we instantiate AH-ECC using the NIST-
P224 curve as provided by the OpenSSL library and its
optimizations by K¨asper [46]. Our implementation of the cryp-
tographic core of the private median scheme amounts to 300
lines of Python code using the petlib OpenSSL wrapper10, and
another 350 lines of Python include unit tests and measurement
code. All experiments have been performed on a Xubuntu
Trusty (Ubuntu 14.04.2 LTS) Linux VM, running on a 64 bit
Windows 7 host (CPU i7-4700MQ, 2.4Ghz, 16GB RAM). Our
Python implementation is easily pluggable as part of the Tor
infrastructure and does not require changes within the Tor (C-
based) core functionalities.
We ﬁrst illustrate the performance and accuracy of es-
timating the median using this technique with both sketch
parameters  and δ equal to either 0.25 or 0.05 against the
London Atlas Dataset11 in Table II (see Appendix). The error
rate is computed as the absolute value of difference between
the estimated and true median divided by the true median.
Further results are presented on an experimental setup that
uses as a reference problem the median estimation in a set of
1,200 sample values, drawn from a mixture distribution: 1,000
values from a Normal distribution with mean 300 and variance
25, and 200 values drawn from a Normal distribution with
mean 500 and variance 200. This reference problem closely
matches the settings of the Tor project both in terms of the
range of vales (assumed to be within [0, 1000]) and the number
of samples [32].
Quality vs. Size. Figure 10 illustrates the trade-off between
the quality of the estimation of the median algorithm and the
size overhead of the Count Sketch. The size overhead (green
slim line) is computed as the number of encrypted elements
in the sketch as compared with the number of elements in the
range of the median (1,000 for our reference problem). The
estimation accuracy (blue broader line) is represented as the
fraction of the absolute deviation of the estimate from the real
Differentially Private Estimates. The sensitivity [31] of the
estimates in any range of values using the Count Sketch is at
10https://github.com/gdanezis/petlib
11http://data.london.gov.uk/dataset/ward-proﬁles-and-atlas
10
Figure 10: Count Sketch size versus estimation quality.
Figure 11: Quality versus differential privacy protection.
value over the real sample median (light blue region represents
the standard deviation of the mean over 40 experiments for
each datapoint). Thus both qualities can be represented as
percentages.
The trade off between the size of the sketch and the
accuracy of the estimate is evident: as the sketch size reaches
a smaller fraction of the total possible number of values, the
error becomes larger than the range of the median. Thus, Count
Sketch with parameters , δ < 0.025 are unnecessary, since
they do not lead to a reduction of the information that needs
to be transmitted from each client to the authorities; conversely,
for 0.15 < , δ the estimate of the median deviates by more
than 20% of its true value making it highly unreliable.
For all subsequent experiments, we consider a Count
Sketch with values  = δ = 0.05, leading to d = 3 and
w = 55. As outlined in Figure 10, this represents a good
trade-off between the size of the Count Sketch (16.5% of
transmitting all values) and the error.
True Size and Performance. When implemented using NIST-
P224 curves, the reference Count Sketch may be serialized in
10,898 bytes. Each Count Sketch takes 0.001 sec to encrypt
at each HSDir, and it takes 1.456 seconds to aggregate 1,200
sketches at each authority (0.001 sec per sketch). As expected,
from the range of the reference problem, 10 decryption it-
erations are sufﬁcient to converge to the median (therefore
ξ = 10). The number of homomorphic additions for each
decryption round is linear in the range of the median and their
total computational cost is the same order of magnitude as
a full Count Sketch encryption. It is clear from these ﬁgures
that the computational overhead of the proposed technique is
eminently practical, and the bandwidth overhead acceptable.
Quality vs. Differential Privacy Protection. Figure 11 il-
lustrates the trade-off between the quality of the median
estimation and the quality of differential privacy protection.
The x-axis represents the  parameter of the differentially
private system, and the y-axis the absolute error between
the estimate and the true sample median. Differential privacy
with parameter  = 0.5 can be provided without signiﬁcantly
affecting the quality of the median estimate. However, for
 < 0.5 the volume of the error grows exponentially (note the
log scale of the x-axis). While the exact value of a meaningful
 parameter is often debated in the literature, we conclude that
the mechanism only provides a limited degree of protection,
and no ability to readily tune up protection: utility degrades
very rapidly as the security parameter  decreases.
VI. RELATED WORK
This section reviews prior work on privacy-preserving
techniques applied to data aggregation, recommender systems,
machine learning, participatory sensing, as well as efﬁcient
data structures for succinct representation.
A. Privacy-Preserving Aggregation
Kursawe et al. [47] introduce a few cryptographic con-
structions to aggregate energy consumptions in the context
of smart metering, relying on Difﬁe-Hellman, bilinear maps,
and a “low overhead” protocol where meters’ encryption keys
sum up to zero. Our schemes for the private recommender
system (Section III) and location prediction (Section IV) rely
on a protocol inspired by [47]’s “low overhead” protocol, but
perform private aggregation using succinct data representation
rather than the raw inputs. Using Count-Min Sketch [22], we
reduce computation and communication overhead incurred by
each user from linear to logarithmic in the size of the input.
We also show how to recover from node failures, i.e., in our
schemes, the aggregator can still retrieve the statistics (and
train models) even when a subset of users go ofﬂine or fail to
report data.
Castelluccia et al.
[13] propose a new homomorphic
encryption to allow intermediate wireless sensor nodes to
aggregate encrypted data gathered from other nodes. Shi et
al. [61] combine private aggregation with differential privacy
supporting the aggregation of encrypted perturbed readings
reported by the meters. Individual amounts of random noise
cancel each other out during aggregation, except for a spe-
ciﬁc amount that guarantees computational differential privacy.
Their protocol is also so that encryption keys sum up to zero
but, unlike ours, requires solving a discrete logarithm and the
presence of a trusted dealer. Jawurek et al. [45] propose a
privacy-friendly aggregation scheme with robustness against
missing user inputs, by including additional authorities that
11
0.50.350.250.150.10.050.0250.01(epsilon, delta) parameter of Count-Sketch020406080100120140%Median Estimation - Error vs. SizeError (%)Size (%)Inf105.01.00.50.10.050.01Differential Privacy parameter (epsilon)101102103Absolute Error (mean & std. of mean)Median Estimation - Quality vs. Protectionfacilitate the protocol but do not learn any secrets or inputs.
However, at least one of the authorities has to be honest,
i.e., if all collude, the protocol does not provide any privacy
guarantee. Chan et al. [15] also provides fault tolerance by
extending [61]’s protocol, however, with a poly-logarithmic
penalty. Additional, more loosely related, private aggregation
schemes include [9, 13, 33].
A combination of homomorphic encryption and differential
privacy has been explored by Chen et al. [19], allowing third
parties to gather web analytics. Users encrypt their data using
the data aggregator public key and send them to a proxy,
who adds noise to the ciphertexts and forwards the results to
the data aggregator. The latter computes the aggregates after
decrypting each individual contribution. However, this scheme
introduces a large overhead both in terms of communication
(one KB per single bit of user data) and computation (one
public key operation per single bit). In the same line of
work, Akkus et al. [4] propose a system providing differential
privacy guarantees. Their scheme scales better than [19] as it
requires users to encrypt fewer bits per query, but still relies
on expensive public-key crypto operations. In [18], the authors
propose a scheme based on a similar trust model as [19]
but with an enhanced scalability by using simple exclusive-or
(XOR) operations rather than public key operations. However,
their proposal still relies on honest-but-curious servers that do
not collude with each other.
Erlingsson et al. [34] introduce RAPPOR, which enables
the collection of browser statistics on values and strings
provided by a large number of clients (e.g. homepage settings,
running processes, etc.),
including categories, frequencies,
and histograms. RAPPOR supports privacy-preserving data-
collection mechanism by relying on randomized responses
via input perturbation, aiming to guarantee local differential
privacy for individual reports. This, however, requires millions
of users in order to obtain approximate answers to queries.
Finally, Elahi et al. [32] present a protocol for privately
computing mean statistics on Tor trafﬁc. They introduce two
ad-hoc protocols relying, respectively, on secret sharing and
distributed decryption. By contrast, our application for gath-
ering private statistics for Tor enables the computation of the
median statistics on trafﬁc generated by Tor hidden services
– which constituted an open problem [39] – by relying on
additively homomorphic encryption and differential privacy.
B. Privacy-preserving Recommender Systems
McSherry and Mironov [51] propose a privacy-preserving
recommender system that relies on trusted computing, while
Ciss´ee and Albayrak [20] use differential privacy to add
privacy guarantees to a few algorithms presented during the
Netﬂix Prize competition. Our private recommender system
differs from theirs as we do not rely on trusted computing or
differential privacy, but leverage a privacy-friendly aggregation
cryptographic protocol and Count-Min Sketch.
Homomorphic encryption based techniques have also been
used to perform other machine learning operations on en-
crypted data, including matrix factorization [56], linear classi-
ﬁers [11, 40], and decision trees [12]. Building a cloud-based
model from multiple user datasets has been also addressed
in [49], which explores the feasibility of Fully Homomorphic
Encryption (FHE) based techniques. However, at the moment,
FHE operations are still prohibitively expensive.
C. Participatory Sensing
Mood et al. [54] propose a privacy-preserving participa-
tory sensing application which allows users to locate nearby
friends without disclosing exact locations, via secure function
evaluation [65], but do not address the problem of scaling
to large streams/number of users. De Cristofaro and Sori-
ente [27] introduce a privacy-enhanced distributed querying
infrastructure for participatory and urban sensing systems.
Work in [24] and [43] provide either k-anonymity [63] and
l-diversity [50] to guarantee anonymity of users through Mix
Network techniques [17]. However, their techniques are not
provably-secure and they only provide partial conﬁdentiality.
Then, [36] suggest data perturbation in a known community
for computing statistics and protecting anonymity. Trusted
Platform Modules (TPMs) are instead used in [37] and [29] to
protect integrity and authenticity of user contents.
In a way, we also address the problem of participatory
sensing privacy by proposing a scalable and provable secure
technique for collecting user-generated streams of data involv-
ing a large number of users.
D. Privacy and Succinct Data Representation
Mir et al. [52] present an efﬁcient scheme guaranteeing
differential privacy of data analyses (even when the internal
memory of the algorithm may be compromised), using a
data structure similar to the Count-Min Sketch to estimate
heavy hitters. Work in [14, 42] address the problem of ﬁnding
heavy hitters’ histograms while preserving privacy using a
differentially private protocol. Then, [6] addresses the case
where individual users randomize their own data and then send
differentially private reports to an untrusted server handling
reports aggregation. Other proposals combine differential pri-
vacy and Count-Min Sketch to obtain aggregate information
about vehicle trafﬁc [53] as well as summaries of sparse
databases [23].
Ashok et al. [5] present a privacy-preserving protocol for
computing the set-union cardinality among several parties
using Bloom ﬁlters [10]. However, their proposal is insecure,
as shown by [64], who also introduces a novel Bloom ﬁlter
based protocol for set-union and set-intersection cardinality.
Lin et al. [48] improve the performance of [55]’s protocol
for private proximity testing by reducing the problem to