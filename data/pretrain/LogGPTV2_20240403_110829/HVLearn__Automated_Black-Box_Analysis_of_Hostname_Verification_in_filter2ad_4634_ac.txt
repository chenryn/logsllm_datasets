veriﬁcation implementations under test using HVLearn. Next,
we compute the product DFA for all the inferred models. The
product DFA accepts the intersection of the regular languages
of each DFA. We compute the product DFA using standard
automata algorithms [60]. The inferred formal speciﬁcation for
our set of implementations is represented by the product DFA
of each DFA model. This product DFA can be then converted
back to a regular expression to improve readability.
Finally, we would like to point out that computing the
intersection of k DFAs have a worst case time complexity
of O(nk) where n is the number of states in each DFA [55].
However, in our case, the inferred DFAs are mostly similar
and thus, the product construction is very efﬁcient because
intersecting two DFAs is not adding a signiﬁcant number of
states in the resulting product DFA. We provide more evidence
supporting this hypothesis in Section V.
V. EVALUATION
The main goals of our evaluation of HVLearn to answer
the following questions: (i) how effective HVLearn is in
ﬁnding RFC violations in real-world hostname veriﬁcation
implementations? (ii) How much do our optimizations help
in improving the performance of HVLearn? (iii) how does
HVLearn perform compare to existing black-box or coverage-
guided gray-box techniques (iv) can HVLearn infer backward-
compatible speciﬁcations from the inferred DFAs of real-world
hostname veriﬁcation implementations.
A. Hostname veriﬁcation test subjects
We use HVLearn to test hostname veriﬁcation imple-
mentations in six popular open-source SSL/TLS implemen-
tations, namely OpenSSL, GnuTLS, MbedTLS (PolarSSL),
MatrixSSL, JSSE, and CPython SSL, as well as in two popular
SSL/TLS applications: cURL and HttpClient. Note that as
several libraries like OpenSSL versions prior to 1.0.1 do not
provide support for hostname veriﬁcation and leave it up to
the application developer to implement it. Therefore, applica-
tions like cURL/HttpClient that support different libraries are
often forced to write their own implementations of hostname
veriﬁcation.
Among the libraries that support hostname veriﬁcation,
some like OpenSSL provide separate API functions for match-
ing each type of identiﬁer (i.e., domain name, IP addresses,
email, etc.) and leave it up to application to select the appro-
priate one depending on the setting. In contrast, others like
MatrixSSL combine all supported types of identiﬁers in one
function and ﬁgure out the appropriate by inspecting the input
string. Table I shows the hostname veriﬁcation function/class
names for all implementations that we tested and the types of
identiﬁer(s) that each of them supports. The last column shows
physical source lines of code (SLOC) for each host matching
function/class as reported by the SLOCCount [14] tool. Note
that the shown SLOC only count the parts of the code that
perform hostname matching.
B. Finding RFC violations with HVLearn
We use HVLearn to produce DFA models for each distinct
certiﬁcate template corresponding to different patterns from
the RFCs. Afterward, we detect potentially buggy behavior
by both performing differential testing of output DFAs as
well as checking individual DFAs for violations of regular-
expression-based rules that we created manually as described
in Section IV-E.
Table II presents the results of our experiments. We eval-
uated a diverse set of rules from four different RFCs [16],
[17], [21], [24]. We found that every rule that we tested is
violated by at least one implementation, while on average each
implementation is violating three RFC rules. Several of these
violations have severe security implications (e.g., mishandling
wildcard characters in international domain names, confusing
IP addresses as domain names etc.). We describe these cases
along with their security implications in detail in Section VI.
528
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:20:25 UTC from IEEE Xplore.  Restrictions apply. 
HOSTNAME VERIFICATION FUNCTIONS (ALONG WITH THE TYPES OF
SUPPORTED IDENTIFIERS) IN SSL/TLS LIBRARIES AND APPLICATIONS
TABLE I
or vagueness in the speciﬁcation itself. Our analysis suggests
that both cases are present in practice.
SSL/TLS
Libs/Apps
OpenSSL
OpenSSL
GnuTLS
Version Supported Hostname Matching
Identiﬁer(s) Function/Class Name
Approx.
SLOC
–
–
(cid:2) 1.0.1
(cid:3) 1.0.2 CN/DNS X509 check host
X509 check ip
X509 check ip asc
X509 check email
EMAIL
IP
IP
3.5.3 CN/DNS/IP gnutls x509 crt check hostname,
gnutls x509 crt check hostname2
gnutls x509 crt check email
EMAIL
–
314
308
417
314
195
149
193
130
202
59
257
300
MbedTLS
2.3.0
CN/DNS mbedtls x509 crt verify,
mbedtls x509 crt verify with proﬁle
MatrixSSL
3.8.4 CN/DNS/IP/ matrixValidateCerts
EMAIL
JSSE
CN/DNS/IP HostnameChecker
CPython SSL 3.5.2 CN/DNS/IP match hostname
1.8
HttpClient
cURL
4.5.2 CN/DNS/IP DefaultHostnameVeriﬁer
7.50.3 CN/DNS/IP verifyhost,
Curl verifyhost
Note that
the library with the most violations is JSSE
(four violations), while HttpClient is the application with the
most violations (ﬁve violations). OpenSSL, MbedTLS, and
CPython SSL only have two violations each, having common
the violation of matching invalid hostnames. The interested
reader can ﬁnd an extended description of our results in the
Appendix (Table VIII).
C. Comparing unique differences between DFA models
In order to evaluate the discrepancies between all differ-
ent hostname veriﬁcation implementations, we computed the
number of differences for each pair of hostname veriﬁcation
implementations in our test set. Recall that for two given DFA
models we deﬁne the number of differences as the number of
simple paths in the product DFA which lead to a different
output being produced by the two models [33].
Table III presents the results of our experiment. For exam-
ple, OpenSSL and GnuTLS have 95 discrepancies in total. This
is obtained by summing up the number of unique paths that are
different between the inferred DFAs for each common name
in Table VIII. Note that all pairs of implementations contain
a large number of unique cases under which they produce a
different output. As seen in Table III, each pair of tested im-
plementation has 127 unique differences on average between
them. We note that some differences only imply ambiguous
RFC rules while some reveal the potential invalid hostnames
or RFC violation bugs. The interested reader can ﬁnd a more
detailed list of the unique strings that each implementation
is accepting in Table VIII in the Appendix. In any case,
we ﬁnd the fact that all implementations of such a security
critical component of the SSL/TLS protocol present such a
larger number of discrepancies to be an alarming issue since
it signiﬁes either a poor implementation of the speciﬁcation
D. Comparing code coverage of HVLearn and black/gray-box
fuzzing
In order to compare HVLearn’s effectiveness in ﬁnding
bugs with that of black/gray-box fuzzing, we investigate the
following research question:
RQ.1: How HVLearn’s code coverage differ from black/gray-
box fuzzing techniques?
We compare the code coverage of the tested hostname veri-
ﬁcation implementations achieved by HVLearn and two other
techniques, black-box fuzzing, and coverage-guided gray-box
fuzzing. We describe our testing setup brieﬂy below.
HVLearn: HVLearn leverages automata learning that invokes
the hostname veriﬁcation matching routine with a predeﬁned
certiﬁcate template and alphabet set. HVLearn adaptively
reﬁnes a DFA corresponding to the test hostname veriﬁcation
implementation by querying the implementation with new
hostname strings. We measure the code coverage achieved
during the learning process until it ﬁnishes. We also monitor
the total number of queries N Q, which comes from both the
membership and the equivalence queries.
Black-box fuzzing: With the same alphabet and certiﬁcate
template used by HVLearn, we randomly generate N Q strings
and query the target SSL/TLS hostname veriﬁcation function
with the same certiﬁcate template. Note that the black-box
fuzzer generates independent random strings without any sort
of guidance.
Coverage-guided gray-box
fuzzing: Unlike black-box
fuzzing, coverage-guided gray-box fuzzing tries to generate
more interesting inputs by using evolutionary techniques to
the input generation process. In each generation, a new batch
of inputs are generated from the previous generation through
mutation/cross-over and only the inputs that increase code
coverage are kept for further changes. Coverage-guided gray-
box fuzzing is a popular technique for ﬁnding bugs in large
real-world programs [6], [11].
To make it a fair comparison with HVLearn, we imple-
mented our own coverage-guided gray-box fuzzer as existing
tools like AFL do not provide an easy way of restricting
the mutation outputs within a given alphabet. With the same
alphabet set, we initialize the fuzzer with a set of strings of
varying lengths as the seeds maintained in a queue Q. The
seeds are then used by the fuzzer to query the target hostname
veriﬁcation implementation. After ﬁnishing querying, using
the seeds, the fuzzer gets the string S = dequeue(Q). It
(cid:2). Then
randomly mutates one character within S and obtains S
to query the target. If the mutated
it uses the mutated S
(cid:2) increased code coverage, we store it in the queue for
string S
, Q). Otherwise, we throw
further mutation, i.e., enqueue(S
it away. The fuzzer is thus guided to always mutate on the
strings that have better code coverage. The fuzzer iteratively
performs this enqueue/dequeue operations for N Q rounds,
and we obtain the ﬁnal code coverage COVrandmu of each
(cid:2)
(cid:2)
529
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:20:25 UTC from IEEE Xplore.  Restrictions apply. 
A SUMMARY OF RFC VIOLATIONS AND DISCREPANT BEHAVIORS FOUND BY HVLEARN IN THE TESTED SSL/TLS LIBRARIES AND APPLICATIONS
TABLE II
L
S
S
n
e
p
O
S
L
T
u
n
G
S
L
T
d
e
b
M
L
S
S
x
i
r
t
a
M
E
S
S
J
t
n
e
i
l
C
p
t
t
H
*
t
n
e
i
l
C
p
t
t
H
L
R
U
c
L
S
S
n
o
h
t
y
P
C






–






–






–






–
RFC Violations
Invalid hostname character
Only alphanumeric and ‘-’ matches in hostname
Case-insensitive hostname
Match CN in case-insensitive manner
Wildcard
Not attempt to match wildcard not in left-most label (CN/DNS: aaa.*.aaa)
IDN and wildcard
Not attempt to match wildcard fragment in IDN (xn--a*.aaa)
Common name and subjectAltName
No CN checked when DNS presents
No CN checked when any SAN ID presents
Email-based certiﬁcate
Case-sensitive on local-part of email attribute in SAN
IP address-based certiﬁcate
Not attempt to match IP address with DNS (DNS: 1.1.1.1)
Discrepancies
Wildcard
Attempt to match wildcard with empty label (hostname: .aaa.aaa with CN/DNS: *.aaa.aaa)
Attempt to match wildcard in public sufﬁx (CN/DNS: *.co.uk)
Embedded NULL character
Allowed NULL character in CN
Allowed NULL character in SAN
Match NULL character hostname: b.b\0.a.a, CN/DNS: b.b\0.a.a
Other invalid hostname
Partially match sufﬁx (hostname: .a with CN/DNS: a.a, a.a.a)
Match trailing dot (hostname: aaa.aaa with CN/DNS: aaa.aaa)
RFC
1035
5280, 6125
6125
6125
6125
6125
5280
1123
–
6125
–
–
–
1035
–





–

–



























–
–





























–