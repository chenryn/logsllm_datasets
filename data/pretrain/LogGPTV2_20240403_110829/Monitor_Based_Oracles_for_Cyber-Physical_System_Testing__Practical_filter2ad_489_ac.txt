S
S
S
V
S
V
V
V
V
V
V
6
V
V
V
V
S
S
S
S
V
V
V
S
S
S
S
S
V
V
V
V
S
S
S
S
V
S
S
S
S
V
V
S
target vehicle. This is an obviously dangerous situation (the
ACC feature causing a crash during target following). The
same problem can be caused by an incorrectly negative
relative velocity, which is a situation caught by Rule #6. The
feature does have enough information to protect against these
two signals being inconsistent and causing a failure by check-
ing the consistency between the change of TargetRange
and TargetRelVel. It just doesn’t do the checking.
Some violations turned out to be overly strict rules, but
sometimes a violation that is primarily a too-strict rule can
also detect a valid transient violation. Most violations of Rule
#5 were due to control system overshoot from negative to a
single-cycle positive acceleration when brakes were released,
which might be considered acceptable. But there were also
transient violations of this rule caused by an injected fault
turning the ACC feature on that caused a one cycle blip
of positive RequestedDecel. While one cycle of bad
requested deceleration may be tolerated in an operational
vehicle, it is worth noting such anomalies in test data, because
they can provide a clue to a potential latent bug that will
have more severe effects in difﬁcult-to-test corner cases. Such
violations can be hard to detect without a tool such as a
runtime monitor, since the vehicle may appear to behave
properly from a driver’s point of view during these ﬂeeting
152152152
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:20:37 UTC from IEEE Xplore.  Restrictions apply. 
problems.
A. Real Vehicle Logs
We also analyzed log data from a prototype vehicle that
implemented the functions in the HIL simulation. These logs
were of normal operation, not robustness testing, covering a
couple hours of vehicle operation for representative driving
scenarios. Data was limited due to the experiments being
of lower priority than vehicle development work on the
limited resource of a single available test vehicle at an
industry partner facility. No safety problems were detected
in the vehicle logs we had available. However, results did
correspond to observations made on non-faulty HIL test
results.
The same rules checked on the simulator were checked
against the real vehicle logs, and similar system dynamics
were found. Rules #0, 1, 5 and 6 were not violated in
the vehicle logs. Rules #2, 3, and 4 had some violations,
but upon further examination they were determined to be
reasonable violations (i.e., overly strict rules). Rule #2 does
not gracefully handle small headway gaps and acceleration
that can occur during overtaking (passing) or a vehicle cutting
in, and Rules #3 and #4 are not fair to the real dynamics of
the system where torque request increases do not necessarily
imply system intent (e.g., starting up a hill torque must
increase to maintain constant vehicle speed). The identiﬁed
violations included negligibly sized increases as well as
extremely short transient increases. These results lead to our
identifying intent approximation as a challenge, as discussed
below.
V. DISCUSSION
In the process of building the monitor, writing the speci-
ﬁcation, and performing testing we ran into issues that on
further inspection lead to deeper research questions. We
identiﬁed three major research challenges:
Intent Approximation: How do we approximate or rep-
resent a desired system intent based on the available
observable system properties?
Speciﬁcation Languages: What language features are nec-
essary for efﬁciently specifying the desired system prop-
erties?
System Mapping: How do we map the target system onto
the monitor’s assumed model of the system?
We also discuss how generalizable we believe these in-
sights are to other systems and some issues regarding the
passive observability of a target system.
A. Intent Approximation
The viability of a black box, external runtime monitor
rests upon the assumption that some portion of the desired
speciﬁcation can be directly checked from the observable
state of the system. The obvious concern is that not enough
data such as vehicle speed or steering commands will be
153153153
available for monitoring. As it turns out, automotive networks
have plenty of such data available due to their use of a
distributed system architecture that broadcasts such data on a
CAN bus. However, a more subtle problem with observability
emerged in the course of doing this work in the form of the
intent estimation problem. This is the question of how to
represent a feature’s intent to perform some high-level action
based on some set of lower level properties [6]. This problem
has been explored in many areas including defense aerospace
[11], unmanned undersea vehicles [5] and automobile driver
intent [12].
We would expect the intent estimation problem to be easier
when performing white-box rather than black box testing,
since being able to directly see how a system’s input affects
its output would help understand system intent. But since
source code doesn’t necessarily explicitly encode intent it is
unclear how much system access affects intent estimation.
In these experiments we used an increase in FSRACC
requested torque as an estimation for the FSRACC intending
to accelerate the vehicle. While this is a somewhat causal re-
lationship (increasing engine torque should generally increase
vehicle speed), torque requests depend upon a host of factors
such as road conditions and grade, and can be differentiated
by factors such as duration and amplitude of the increase.
Based on this example, we expect that designers who wish
to employ an external monitor will face a tradeoff between
carefully architecting selected internal system information
that reveals intent vs. building somewhat more complicated
monitors that decipher intent based on observable informa-
tion. (It is easy to say that intent should always be broadcast,
but that may not be feasible for system integrators purchasing
off-the-shelf components from multiple outside vendors.)
In order to be able to tune these approximations, designers
must be able to evaluate a given violation and decide whether
the violation was real or not. This may be non-trivial on some
systems, especially if a part of the reason for the use of a
monitor is to help developers understand the test traces. In
our case, we took into account the intensity and duration
of the violations, as well as the apparent cause to make a
decision on whether a violation was a safety problem or not.
A monitor used as a test oracle for safety rules can provide
evidence for a system safety case [1] that the system did
in fact pass the executed tests. For this type of use we
want to have no false negatives (i.e. the estimation catches
every violation of the intended high level rule) to allow the
testing results to be used as strong evidence. If having no
false negatives is impossible or it results in an unmanageable
amount of false positives, using an intent estimation that
reports some false negatives is still more useful as part of
a comprehensive safety approach than not checking at all.
(Detecting even a single safety violation provides useful
evidence that the system is unsafe.)
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:20:37 UTC from IEEE Xplore.  Restrictions apply. 
B. Speciﬁcation Languages
We have designed our monitor to use a simpliﬁed temporal
logic combined with state machines. Most existing monitor
technologies use some form of logic [4] or a domain speciﬁc
language that matches the implementation [16]. Logic-like
languages are promising, but some researchers use a form of
state machine to encode modal system state or to reduce the
complexity of temporal operators in logic. For example, we
avoid nesting of temporal operators by using state machines
when needed, and that proved useful in this work.
The trade-off between simplicity and expressiveness in
monitor logic is important because it affects the efﬁciency
of the monitor, and the ultimate goal for this type of system
is to operate with the system being monitored in real time. It
is not yet clear what degree of expressiveness is required
to monitor typical safety properties on real systems. The
speciﬁcation rules that we used in this work are relatively
simple, yet they did identify system faults under robustness
testing. So it may be that relatively simple logic languages
which only provide a subset of the usual temporal logic
functions sufﬁce for runtime CPS monitoring. There are
additional complexity trade-offs between the speciﬁcation
notation and in the system-to-monitor mapping (discussed
below).
C. Monitor Rule to System Mapping
A major challenge is that of mapping the real system to
an abstracted model at run-time that provides the system
state information for the monitor to check. There are many
different existing monitoring techniques that each have their
own unique model of a system. Here we generally discuss
issues related to external monitors such as ours. Inline
monitors (i.e. monitors that exist within the system code,
which are beyond the scope of this work) may have fewer
mapping issues because they are more directly integrated into
the system, but it would be no surprise if they have similar
tradeoffs.
Our monitor is designed around the use of a set of network
messages representing system state.
1) Multiple Sampling Periods: In the vehicle we tested
there are two relevant message periods, with some messages
being updated four times slower than most others. At ﬁrst
we simply assumed that these slower values stayed constant
between updates. But, dealing with values across multiple
timesteps required more care, because a slowly sampled value
that is in fact increasing would appear to be unchanging for
several cycles while the faster samples were being checked.
As an example, to see if the FSRACC feature was re-
questing increasing torque, we would calculate the difference
of the previous and current RequestedTorque value.
However, if the held value is used in a monitor that updates
four times between every RequestedTorque update, the
torque would appear to be constant for three samples out
of four due to the repetition of the most recent sampled
value being held. Additionally, jitter would sometimes cause
slower-period messages to be delayed, resulting in ﬁve faster
frequency message updates occuring between the slower
message updates. Once recognized, it was relatively simple
to work around these problems in an ad hoc manner. But,
the observation remains that runtime monitoring that involves
data sampled at different periods can be tricky, and a runtime
monitoring architecture should have a uniformly applied
mechanism to deal with that issue.
2) Discrete Value Jumps: Another network value issue
that we came across was ensuring that rules could handle
message transitions from non-active to active. Some mes-
sages in a system, such as TargetRange can perform
large discrete jumps when they are activated even though
they represent continuous physical properties. As an example,
TargetRange is 0 when there is no target being tracked,
but once a target is found this value will immediately jump
to the actual range. This was noticed for rules that checked
if the ACC would command control when the change in
TargetRange did not agree with sign of TargetRelVel.
So while these values should always agree in a non-fault
condition, there is one situation where they may not: when a
vehicle comes into sensor view the relative velocity may be
correctly reported as negative, but the ﬁrst change in range
seen is necessarily positive (change from zero to the actual
positive range). Delaying the check of such a rule until after
the activation (allowing the “change” variable to initialize
before testing) avoids this problem.
Other message or rule types may also have initialization
issues, such as rules that rely on an integrator or running
average of a value. A general observation is that run-time
monitors should have a uniform way of “warming up”
monitors for data that changes state abruptly, especially when
changing from invalid to valid, to avoid false alarms.
3) System vs. Model: Even though a HIL simulation is
supposed to be of high ﬁdelity, we found a signiﬁcant
difference in that the HIL platform performed strong type
checking of fault-injected values, prohibiting things such as
out-of-range enumerated values. This limited the amount of
fault injection possible compared to what might be done
on a complete vehicle (which we were not permitted to do
robustness testing on). As a result, robustness testing of the
HIL platform likely missed problems that would be expected
to be present in the real system, which does not have such
type checking. For this reason it can be important to do
runtime monitoring on the actual vehicle even if HIL testing
ﬁnds no problems, especially if robustness testing results are
desired on the real vehicle.
D. Observability and Generalizability
The most limiting factor for a passive monitor targeting
a speciﬁc system is how much system state is observable
passively (without invasive instrumentation). For our target
application (modern automobiles) and other similar systems
154154154
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:20:37 UTC from IEEE Xplore.  Restrictions apply. 
(autonomous ground vehicles) there is a useful though not
complete set of observable state available to be passively
monitored due to the prevailing architecture where system
state is broadcast between distributed system nodes on a
single or small number of bus networks. While there are
likely some systems which require instrumentation to reveal
system state, we expect that there is a non-negligible class of
systems that have similar architectures to automobiles. This is
likely since high criticality systems tend to be distributed or
have visible communication between replicated components.
If a system is distributed, then some amount of useful state
will be observable as the distributed nodes must communicate
their state to each other. Whether this communicated state is
enough to allow monitoring useful system properties is left to
be seen in other systems, but for automobiles it does appear
to be the case.
Whether the insights and results we have seen here are
generalizable to other systems hinges essentially on whether
other systems can be monitored in a similar manner. While it
is unclear how many other classes of systems lend themselves
to passive monitoring, at worst the explained methods and
insights are applicable to other autonomous ground systems
which are becoming increasingly important. We expect that
other types of systems are similar, though some may require
different levels of instrumentation. Intent approximation and
mapping systems onto their abstract models are problems that
will exist in some degree for any practical formal veriﬁcation
techniques for the foreseeable future.
VI. CONCLUSION
Automated testing of complex safety-critical systems is
an important method to increase the number of tests that
can be completed, but an automated analysis of such test
results is not necessarily easy. Runtime monitors can be used
to create partial test oracles for critical system properties,
such as system-level safety rules. Isolated, external runtime
modules are especially attractive, but pose some potential
challenges.
We showed the feasibility of a bolt-on monitor by imple-
menting a passive network monitor (using log analysis) to
check a HIL simulated vehicle provided by an automobile
manufacturer. Despite not having source code access and
working only with existing network signals, a practical
monitor was developed with a half-dozen rules that identiﬁed
system faults under robustness testing of a HIL system.
This illustrates the possibility of expanding the use of this
approach in testing key properties of CPS designs.
The experience revealed a number of challenges remaining
to further advance this approach, including: approximating
system intent based on limited system state observability,
how to best balance complexity vs. expressiveness and scope
of the speciﬁcation language used to deﬁne the monitored
properties, how to warm up monitoring of system variable
state after mode change discontinuities, and managing the
differences between simulation and real vehicles when con-
ducting such tests.
ACKNOWLEDGMENT
This research was funded in part by General Motors
through the GM-Carnegie Mellon Vehicular Information
Technology Collaborative Research Lab.
REFERENCES
[1] Bishop, P., Bloomﬁeld, R.: A methodology for safety case develop-
ment. In: SAFETY-CRITICAL SYSTEMS SYMPOSIUM, BIRMING-
HAM, UK, FEB 1998. Springer-Verlag, ISBN 3-540-76189-6 (1998),
[2] Bosch, R.: CAN speciﬁcation version 2.0 (Sep 1991)
[3] Corporation, M.S.: Carsim overview (November 2013)
[4] Delgado, N., Gates, A., Roach, S.: A taxonomy and catalog of
runtime software-fault monitoring tools. Software Engineering, IEEE
Transactions on 30(12), 859 – 872 (dec 2004)
[5] Fong, E.H.L.: Maritime intent estimation and the detection of unknown
obstacles. Master’s thesis, MIT (2004), http://hdl.handle.net/1721.1/
30279
[6] Foo, P.H., Ng, G.W., Ng, K.H., Yang, R.: Application of intent
inference for surveillance and conformance monitoring to aid human
cognition. In: Information Fusion, 2007 10th International Conference
on. pp. 1–8 (2007)
[7] Goodloe, A., Pike, L.: Monitoring distributed real-time systems:
a survey and future directions
(July
2010), http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.159.
4769\&amp;rep=rep1\&amp;type=pdf,
(NASA/CR-2010-216724)
[8] ISO: ISO/DIS 26262 - Road vehicles – Functional safety. Tech. rep.,
Geneva, Switzerland (November 2011)
[9] Koopman, P., Devale, K., Devale, J.: Interface Robustness Testing:
Experience and Lessons Learned from the Ballista Project, pp. 201–
226. John Wiley & Sons, Inc. (2008)
[10] Koymans, R.: Specifying real-time properties with metric temporal
logic. Real-Time Syst. 2, 255–299 (October 1990),
[11] Lee, K., Lunas, J.: Hybrid model for intent estimation. In: Information
Fusion, 2003. Proceedings of the Sixth International Conference of.
vol. 2, pp. 1215–1222 (2003)
[12] Lefevre, S., Ibanez-Guzman, J., Laugier, C.: Context-based estimation
of driver intent at road intersections. In: Computational Intelligence in
Vehicles and Transportation Systems (CIVTS), 2011 IEEE Symposium
on. pp. 67–72 (2011)
[13] Leucker, M., Schallhart, C.: A brief account of runtime veriﬁcation.
Journal of Logic and Algebraic Programming 78(5), 293 – 303 (2009),
the 1st Workshop on Formal Languages and Analysis of Contract-
Oriented Software (FLACOS’07)
[14] Pellizzoni, R., Meredith, P., Caccamo, M., Rosu, G.: Hardware Run-
time Monitoring for Dependable COTS-Based Real-Time Embedded
Systems. 2008 Real-Time Systems Symposium pp. 481–491 (Nov
2008),
[15] Pike, L.: Copilot: Monitoring embedded systems. Tech. Rep.
Langley
Center
http://ntrs.nasa.gov/search.jsp?
NASA/CR-2012-217329,
(January
R=20120001989&hterms=pike+goodloe&qs=Ntx%3Dmode%
2520matchallpartial%2520%26Ntk%3DAll%26N%3D0%26Ntt%
3Dpike%2520goodloe
NASA
at
Research
available
2012),
[16] Pike, L., Goodloe, A., Morisset, R.: Copilot: A Hard Real-Time
Runtime Monitor. In: 1st International Conference on Runtime Ver-
iﬁcation. No. Rv (2010), http://www.cs.indiana.edu/\∼{}lepike/pubs/
pike-rv2010.pdf
[17] Ver´ıssimo, P.E.: Travelling through wormholes: A new look at dis-
tributed systems models. SIGACT News 37(1), 66–81 (Mar 2006),
[18] Weyuker, E.J.: On testing non-testable programs. The Computer Jour-
nal 25(4), 465–470 (1982),
155155155
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:20:37 UTC from IEEE Xplore.  Restrictions apply.