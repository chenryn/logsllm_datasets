### Macro for Generating Correct Symbol Suffix

A macro was used to generate the correct symbol suffix for a policy being compiled for a host in one of the four quads. The correct quad was computed from the hostname of the target host, but it could be manually adjusted for cross-compilation. For example, the port binding for the heartbeat service of the downstream controller (DC), a DPASA component, was specified with:

```python
defport(dc_heartbeat_port_t, udp, Qx(dc_heartbeat_port__1))
```

Finally, the Makefile for the SELinux policy was modified to include a target to regenerate the m4 macros from the correct master configuration source as needed.

### SELinux Policy Details

The DPASA SELinux policies employ 5 roles, 500-600 types, and 32,000-35,000 rules, depending on the jobs performed by the host. The number of rules required to address a given policy goal is reduced by using SELinux attributes to label equivalence classes of objects, such as hosts. For instance, all hosts in the client network are labeled as "client node type," and policies that apply to any client node can refer to this type instead of each individual client. For reference, a client node with only the baseline SELinux policy (stock policy from Gentoo with standard extensions to handle X) contains 425 types and 30,107 rules.

### Validation of SELinux Policies

The SELinux policies were empirically validated through the correct operation of the JBI. The primary priority was to ensure that the JBI worked as expected. SELinux alerts observed during functional testing were manually converted into additional policy rules, which granted the process the minimal permission required for correct operation. Since permissions were added only as required, we had confidence that DPASA reasonably followed the principle of least privilege. Unfortunately, the compressed development schedule for this project left no time to explore the analysis tools provided by the SELinux community. Employing a formal model analysis tool ([5, 22, 12]) would have provided additional assurance that the SELinux policies correctly protected the DPASA applications.

### CSA Policy

Because CSA and SELinux policies were complementary technologies at the same defense layer, they should have been logically identical. However, the two tools differed significantly in their conceptual models. Additionally, CSA lacked any facility, even an implicit one like SELinux’s text-based configuration files, to integrate with other tools. As a result, we could not integrate CSA with either SELinux or the DPASA properties infrastructure (see Section 3).

While the SELinux policies, which were fully integrated with the properties infrastructure, satisfied the DPASA communication requirements (see Figure 3), CSA, due to concerns about divergence with SELinux, ADF, and JVM (all coordinated by the properties infrastructure), satisfied only a subset of those requirements.

To satisfy all requirements, we would have needed to duplicate the properties infrastructure within CSA. However, the system was still under development as CSA policies were being written, so there was a real risk of divergence. For each CSA-protected host, we opted instead to specify the other hosts with which it was permitted to communicate and to restrict that communication to authorized protocols (i.e., TCP and UDP). We did not specify specific network services (e.g., Alerts or RmiReg). As the system development stabilized, these services could be added; however, ongoing maintenance remained a concern.

In total, eleven policies were defined: one for each Solaris or Windows host, except that the ADF Policy Servers (Windows) shared a policy. The typical Unix policy contained approximately 13 allow rules, 8 deny rules, and 8 monitoring rules (detection only). The typical Windows policy contained approximately 24 allow rules, 18 deny rules, and 7 monitoring rules.

Like SELinux, CSA policies were validated through the correct operation of the JBI. Unlike SELinux, CSA offered the ability to generate an easy-to-read summary of each host’s policy. CSA’s strategy of allowing what is not explicitly denied made careful review even more critical. We first denied everything (e.g., all network access), then specified only authorized accesses (e.g., the remote hosts and protocols authorized for communication).

### Host Layer Policy

Initially, ADF policies were translated automatically from JVM policies. For the few non-Java components, either "fake" JVM policies were created, or the component’s ADF policy was specified directly. However, the JVM policy could not support the translation without annotation. For example, JVM policies do not distinguish between TCP and UDP protocols and do not, by default, identify the local host or the ephemeral port (if any). This information was added as a comment to each connect authorization in the JVM policy listings, as shown below, which describes a UDP connection from 192.168.4.162 on port 5701 to 192.168.4.170 on port 9901.

```java
permission java.net.SocketPermission "192.168.4.170:9901", "connect";
// 192.168.4.162,Heartbeats,UDP,5701
```

The JVM policies were then processed to create a single, intermediate specification containing entries of the form:

```
source IP, source port, destination IP, destination port, protocol, service
```

where `source IP` and `destination IP` are standard numeric IPv4 host addresses, `source port` and `destination port` represent TCP or UDP ports or port ranges, `protocol` is any valid Internet protocol, and `service` is a character string by which to identify the network service implied by the other fields in this entry. These entries, when combined with the non-JVM entries, constituted the complete connection specification from which all ADF policies were generated.

Unfortunately, there were two critical shortcomings with translating ADF policy automatically from JVM policy. First, the "fake" JVM policies were not vetted adequately, as they were never actually used to enforce Java process behavior, and numerous errors were encountered when ADF enforced the incorrect rules resulting from these policies. Second, the generated ADF policies eventually violated design constraints for ADF, exceeding the maximum ADF policy size and requiring more VPG keys to be assigned to a host than its NIC could support. We considered developing a tool to perform the required optimizations but decided against it due to its limited utility to DPASA.

However, while we determined that the connection specification should not be generated automatically from the JVM policies, there was still much value in creating it. The connection specification served several useful purposes: (a) it was a single source from which all ADF policies could be generated; (b) it was used to generate a graphical depiction of each policy, similar to Figure 3; and (c) it was used to validate authorized communications against independent network scans. We changed our strategy to maintain a "permanent" connection specification so that only valid ADF XML would be generated, but we continued to perform an automatic translation of JVM policy into temporary specifications for policy discovery.

ADF policy was generated per host. A connection statement such as:

```
host A, 1024-65535, host B, 80, TCP, web
```

really implies two ADF policies: one for host A and one for host B. In this case, the ADF policy for host A would allow it to send TCP 80 packets to host B encrypted using the VPG key for B and receive replies to those requests encrypted with its own VPG key. The ADF policy for host B would allow it to receive TCP 80 packets from host A encrypted with its own VPG key and send responses to A encrypted with the VPG key for A. By generating both policies from a single statement, we ensured consistency between the two policies, which is particularly critical for successful VPG communication.

Once all VPG policy rules were generated, the rules for a given host were collected, ordered for optimal evaluation (ingress filtering then egress filtering for better performance against network attacks), and then translated into XML, imported into the ADF Policy Server, and distributed to the host. In total, 28 ADF policies were generated (some hosts were grouped under a common policy) with an average of 21 rules per policy, or just over 600 rules total. Because the translation routines were demonstrated to be trustworthy enough to generate correct ADF XML from a well-formed connection statement, policy debugging was done mainly by analyzing the connection specification itself, rather than by examining the ADF XML output. This simplified ADF VPG policy debugging for developers unfamiliar with ADF.

To further facilitate developer validation of the ADF VPG policies, we developed scripts to convert the high-level connection statements into dot diagrams, such as the one illustrated in Figure 3. The dot diagrams provide no more information than the connection specification itself, but the data is presented in a visually pleasing form.

Finally, we compared the permissions granted in ADF’s connection specification against network scans to detect policy misconfigurations, which, according to The CERT Guide to System and Network Security Practices [4], are the most common cause of firewall breaches. Typical policy audits for border firewalls are performed with scanning hosts placed on each side of the firewall under test. However, no clear boundary exists for distributed firewalls. With them, the visible policy is the union of both the sender and receiver rule sets, thus the communications allowed to/from a host will be dependent on the network perspective. To complete a full, thorough audit, the network scan must be initiated from each host to every other host. This captures the combined effect of the egress filtering on the sending host and the ingress filtering on the receiving host. If desired, extra hosts with no egress filtering could be added to the scan to find errors masked by egress filters.

The primary goal of our network scan tool was to 1) detect unauthorized communication paths and 2) detect unnecessary communication paths that exist in the system. The scans were coordinated via SSH on a separate DPASA control network (used for development purposes only), so no reconfiguration of ADF itself was required to support the scan. Each scan was performed by nmap, with the central controller receiving the results in standard nmap XML format. Each file contained all live hosts found during the scan and the state of the ports on those hosts. The state of the ports was classified as: open (responded with TCP SYN-ACK or UDP data), closed (responded with TCP RST or ICMP Port Unreachable), or filtered (no response).

If there were no misconfigurations, all ports should return filtered except those that were explicitly allowed in the connection specification. After all the host scans were performed, the results were combined to create the global network view. This process was straightforward and achieved with a Python script. The final result was an XML file containing a list of each communication path found in the system. Using XSLT to transform this output, the results were compared automatically with the ADF connection specification to discover misconfigurations and unnecessary communication paths.

The scan did detect extra communication paths that were not authorized within the ADF connection specification, but further examination revealed that the ADF policies themselves had been manually edited to authorize these paths. This finding underscores the importance of independent testing, as the connection specification did not reflect the true protection profile.

### Lessons Learned

Our hybrid policy construction approach worked well because policies could be developed independently and simultaneously by various authors, which was particularly important given DPASA’s compressed development schedule. Since the policy authors were geographically dispersed, the coordination required for a master policy specification would have been difficult. Additionally, it was not necessary for all authors to develop expertise on all technologies. The approach of starting with a minimal policy and adding to it, as operational failures (due to policy) were observed, helped to minimize concerns about unnecessary privileges, as discussed at the end of Section 6. While it is possible that some functional behaviors could have been improved, the overall approach was effective.