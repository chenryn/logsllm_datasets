发微博YF核心
在运维工作中告警因为维度多，绝对数量可能很大，但关联到的“事件”却是有限的。以
图10-6展示了一个按照功能聚合后的事件告警页面。
将告警聚合成关联“事件”
图10-6按照功能聚合后的事件告警页面（对一些内部信息做了处理）
是否赞过YF
转发微博TC核心
仅供非商业用途或交流学习使用
仅供非商业用途或交流学习使用
100%
009
第10章数据聚合与关联技术
评论内容土城ACTION
查看微博内容YF
189
---
## Page 216
精神上产生疲惫，以至于最终对真正的告警不再敏感（警报疲劳)。
不需要人工干预的、自愈性事件，效果就不太好了。过多过于频繁的误报，会使运维值班人员
10.2.2
的事件，
原形式提交给管理员，供管理员自行处理。
件，则说明这些告警之间的相似性不高或者相似性高的告警不多，对这些数据将不作处理，留
允许经过 max_gen 次概化，如果经过 max_gen 次概化，仍然不能满足数量大于 min_count 的条
论对排查问题毫无帮助)；如果参数值太小，则一个原始告警可以匹配多个事件。
参数值太大，则会聚合掉一些根本原因而导致结果太过抽象和概化（比如微博有问题，这个结
数，即同类告警最少发生多少次才会被聚合，一旦发生告警，就需要仔细选择这个参数：如果
信息，从而导致结果毫无意义2。
0
上面介绍的聚类算法，可以有效地减少告警数量，但对于由网络抖动、流量峰值等引发的
从结果来看，经过AOI算法聚合后，应该已经消除了大部分噪音，让运维人员只关注重要
为了避免出现这样的情况，改进的AOI算法引入了min_count（最小的聚类事件数量）参
AOI算法也存在很明显的不足，其中之一便是过于抽象（或者叫概化），可能会损失太多的
，不被各类噪音所干扰。
智能运维：从0搭建大规模分布式 AIOps 系统
减少误报：告警分类
队列堆积/
队列服务池
数据库慢
YF机房
仅供非商业用途或交流学习使用
图10-7AOI算法示意图
仅供非商业用途或交流学习使用
依赖资源池
机房
能异常
YF机房发微博功
服务
---
## Page 217
和随机森林（RF）等，有时候我们可能需要不同的算法交叉验证学习效果，如图10-8所示。
可以由人工构建，也可以由机器学习技术自动构建。
员来选择一
需要有一些已标注的数据作为训练样本。通常我们会提供一个告警结果页面，供开发和运维人
要算法，分类方法是一种对离散型随机变量建模或预测的监督学习算法，有监督的学习意味着
优化)，然后模型对新接收的告警数据进行分类，是否会减少误报的概率呢？
alert
关于告警收敛的整体流程如图10-9所示。
兼
分类算法有K近邻（KNN）、贝叶斯分类器（NB）、Logistic回归（LR）、支持向量机（SVM）
下面介绍一种基于告警分类器的减少误报的方法。“分类”是人工智能和机器学习领域的重
如果通过机器学习技术对一组已知的告警数据进行训练学习,生成分类模型（会不断调整、
一处理、忽略、误报等选项可以将告警数据标签化，然后建立训练样本。分类器既
alert
+
背景知识
规则参数
分类器
图10-9告警收敛的整体流程图
图10-8
聚类
仅供非商业用途或交流学习使用
自适应告警分类器的实现
今
仅供非商业用途或交流学习使用
机器学习
更新规则
Yes
处理
分类器
No
第10章数据聚合与关联技术
反馈
人工审核
训练样本
删除
标注
191
---
## Page 218
例属于离线数据关联，即需要关联的多个数据都已经存在。而在监控系统中，经常遇到的情况
费意愿，需要进一步挖掘。
户量最大，贡献度最高。从潜在的客户留存角度来分析，可以看出客户id为11363的客户有消
20170127)，共贡献了212.70元的消费金额。从用户的地域分布角度来分析，可以得出上海用
构
库中的join 操作就是数据关联的典型案例。
则无法把数据完全加载到内存中进行计算。
还可以通过写简单的程序在笔记本电脑上进行数据关联处理，但是当数据量达到百亿级别时，
据量小的情况下很容易快速实现数据关联。比如数据分析师通过Excel就可以进行数据关联，
32367
客户id
了实现上述业务或者需求，需要通过关联很多数据维度来计算。对于当代的计算机来说，在数
应地变得复杂，各行各业都在从数据中寻找业务的增长点、用户的画像以及更智能的推荐。为
32365
32362
订单id
10.3
20170128
20170126
192
20170127
20170125
在实际中数据关联会非常复杂，可能涉及多种数据源，甚至是异构数据的关联。上面的案
数据关联一般指根据一定的规则和关联关系连接各类数据以便形成新的数据，MySQL 数据
当我们分析客户订单分布时，
如表10-1所示是订单表（orders）的表结构，
在大数据时代，金融、互联网、自动化等方向的数据量爆炸性激增，同时数据的维度也相
智能运维：从O 搭建大规模分布式AIOps系统
数据关联
王五
李四
张三
昵称
23610
32367
11363
32367
客户id
wangwu
lisi
zhangsan
用户名
表10-2
802.74
112.02
230.23
100.68
订单金额（元）
表10-1
，就需要将这两个表进行数据关联。
180xxx
152xxx
135xxx
手机号
仅供非商业用途或交流学习使用
仅供非商业用途或交流学习使用
客户表（customer）的表结构
订单表（orders）的表结构
上海
深圳
北京
所在地
待支付
完成
取消
完成
订单状态
如表10-2所示是客户表（customer）的表结
2017-01-04 22:32:36
2017-01-03 10:12:45
下单时间
2017-01-02 08:02:19
2017-01-0118:32:20
wangwu@xxx
lisi@xxx
zhangsan@xxx
邮箱
备注
备注
---
## Page 219
当互动数据到达时再到HBase 中查询，并写入新的互动数据，得到的最终数据则关联上了曝光
等信息的签名串）进行关联。由于曝光数据早于互动数据到达，因此先将曝光数据写入HBase，
带来数据缺失问题。对于这种情况，通常的解决方案是借助外存。
可能会导致实时计算引擎内存溢出，同时当应用程序意外终止后，可能导致因内存数据丢失而
条数据，为了进行数据关联，就需要将这部分数据进行缓存。由于大量的数据被缓存到内存，
然而，在一定时间范围内进入实时计算引擎的数据量通常相对较大，比如1分钟可能有上千万
10.4.1
定，
离线数据处理已经无法满足要求。
10.4
是实时数据关联，下一节我们将结合微博广告的具体案例来探讨如何进行实时数据关联。
对于关联数据到达时间不一致的情况，要提高数据关联的准确性，就需要先到的数据等待。
，理论上实时数据很难做到百分之百的关联。目前实时数据关联存在以下问题。
从图10-10可以看出，曝光数据和互动数据按mark_id（唯一标识广告，同时含有广告出价
例如广告互动、负反馈等数据总体会晚于曝光数据到达，由于实时数据到达的时间点不确
对实时性要求高的如广告 CTR 预估、运维监控、广告投放效果评估等产品需求来说,Hadoop
数据关联整体架构示意图如图10-10所示。
〇实时计算引擎不适合缓存大量的数据集。实时计算引擎基本都是采用内存计算的，为
〇关联数据到达时间不一致。数据到达时间不一致，导致其中一部分先到的数据需要等
溢出。
存中等待。在进入实时计算引擎的数据QPS 较大的情况下，很容易造成计算引擎内存
了提高实时计算的性能和效率，在需要关联的数据没有到达之前，部分数据需要在内
数据关联，减少不必要的数据检索，是一个巨大的挑战。
数据在亿级别，而对应的广告互动的数据可能在千万级别，这对于有效、快速地进行
关联数据严重倾斜。需要进行数据关联的数据量相差甚远，
性。
待，数据等待的时间长短、实时计算的时间窗口大小都会直接影响到数据关联的准确
实时数据关联案例
设计方案
仅供非商业用途或交流学习使用
第10章数据聚合与关联技术
，例如微博某广告产品曝光
193
---
## Page 220
可以缓存1分钟的互动数据，然后再查询存储在 HBase 上的曝光数据，而不是对每一条互动数
度的数据缓存，以减小对 HBase 的查询压力。比如，在进行广告曝光数据和互动数据关联时，
实时集群的要求，至少无法满足实时计算引擎每次的查询要求。通过分析 Redis、HBase 的优缺
相对于磁盘来说，消耗的资源较为昂贵，如果把上十亿、百亿级别的数据存储到Redis上，对
ClickHouse等可以选择。经过以上分析可知，Redis虽然查询性能较好，但它是基于内存存储的，
数据存储在 Hadoop 分布式文件系统上，支持海量的数据存储，数据存储在磁盘上。
询需求。
持数据落地，可以做到数据保障。Redis 经常被用于缓存数据，其在性能上满足大规模数据的查
和互动。这里使用Kafka作为数据中转的消息队列。
点，最终我们选择了 HBase 作为实时数据关联的存储和查询引擎。
于公司来说则成本较高；而 HBase 虽然拥有海量的存储，写吞吐量高，但其查询性能不能满足
194
在实际过程中，我们会综合使用缓存和外部存储方案，在计算节点上使用内存进行一定程
外部存储选型是基于公司现有的存储所做的选择，除了Redis、HBase，还有 MongoDB
其次可以选择HBase。HBase分布式存储的写吞吐量高，查询响应耗时在50毫秒左右。HBase
1．外部存储选型（Redis、HBase）
智能运维：从0搭建大规模分布式AIOps系统
Search
Write
互动
关联曝光
HBase
Search
HBase
持久化
图10-10
数据关联
仅供非商业用途或交流学习使用
持久化曝光日志拓扑
数据关联整体架构示意图
志mark_id
志markid
解析曝光日
解析互动日
JStorm
曝光互动关联拓扑
—Kafka spout
Kafka
Kafka
数据缓存
Kafka
---
## Page 221