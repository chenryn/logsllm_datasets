title:The Spy in the Sandbox: Practical Cache Attacks in JavaScript and
their Implications
author:Yossef Oren and
Vasileios P. Kemerlis and
Simha Sethumadhavan and
Angelos D. Keromytis
The Spy in the Sandbox: Practical Cache Attacks in
JavaScript and their Implications
Yossef Oren Vasileios P. Kemerlis Simha Sethumadhavan Angelos D. Keromytis
Columbia University
Department of Computer Science
{yos, vpk, simha, angelos}@cs.columbia.edu
ABSTRACT
We present a micro-architectural side-channel attack that
runs entirely in the browser. In contrast to previous work in
this genre, our attack does not require the attacker to install
software on the victim’s machine; to facilitate the attack,
the victim needs only to browse to an untrusted webpage
that contains attacker-controlled content. This makes our
attack model highly scalable, and extremely relevant and
practical to today’s Web, as most desktop browsers currently
used to access the Internet are aﬀected by such side channel
threats. Our attack, which is an extension to the last-level
cache attacks of Liu et al. [14], allows a remote adversary
to recover information belonging to other processes, users,
and even virtual machines running on the same physical host
with the victim web browser.
We describe the fundamentals behind our attack, and
evaluate its performance characteristics.
In addition, we
show how it can be used to compromise user privacy in a
common setting, letting an attacker spy after a victim that
uses private browsing. Defending against this side channel
is possible, but the required countermeasures can exact an
impractical cost on benign uses of the browser.
Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection—in-
formation ﬂow controls; K.6 [Management of Comput-
ing and Information Systems]: Miscellaneous—security
General Terms
Languages, Measurement, Security
Keywords
side-channel attacks; cache-timing attacks; JavaScript-based
cache attacks; covert channel; user tracking
Publication rights licensed to ACM. ACM acknowledges that this contribution was au-
thored or co-authored by an employee, contractor or afﬁliate of the United States gov-
ernment. As such, the United States Government retains a nonexclusive, royalty-free
right to publish or reproduce this article, or to allow others to do so, for Government
purposes only.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813708.
1.
INTRODUCTION
Side-channel analysis is a powerful cryptanalytic technique.
It allows attackers to extract information hidden inside a
device, by analyzing the physical signals (e.g., power, heat)
that the device emits as it performs a secure computation [15].
Allegedly used by the intelligence community as early as
in WWII, and ﬁrst discussed in an academic context by
Kocher in 1996 [13], side-channel analysis has been shown
to be eﬀective in a plethora of real-world systems, ranging
from car immobilizers to high-security cryptographic copro-
cessors [6,20]. A particular kind of side-channel attacks that
are relevant to personal computers are cache attacks, which
exploit the use of cache memory as a shared resource be-
tween diﬀerent processes to disclose information [9, 19].
Even though the eﬀectiveness of side-channel attacks is
established without question, their application to practical
settings is debatable, with the main limiting factor being the
attack model they assume; excluding network-based timing
attacks [4], most side-channel attacks require an attacker in
“close proximity” to the victim. Cache attacks, in particular,
assume that the attacker is capable of executing binary code
on the victim’s machine. While this assumption holds true
for IaaS environments, like Amazon’s cloud platform, where
multiple parties may share a common physical machine, it
is less relevant in other settings.
In this paper, we challenge this limiting assumption by
presenting a successful cache attack that assumes a far more
relaxed and practical attacker model. Speciﬁcally, in our
model, the victim merely has to access a website owned by
the attacker. Despite this minimal model, we show how the
attacker can launch an attack in a practical time frame and
extract meaningful information from the victim’s machine.
Keeping in tune with this computing setting, we choose not
to focus on cryptographic key recovery, but rather on track-
ing user behaviour. The attacks described herein are highly
practical: (a.) practical in the assumptions and limitations
they cast upon the attacker, (b.) practical in the time they
take to run, and (c.) practical in terms of the beneﬁt they
deliver to the attacker.
For our attack we assume that the victim is using a com-
puter powered by a late-model Intel processor. In addition,
we assume that the victim is accessing the web through a
browser with comprehensive HTML5 support. As we show
in Section 6.1, this covers the vast majority of personal com-
puters connected to the Internet. The victim is coerced to
view a webpage containing an attacker-controlled element,
like an advertisement, while the attack code itself, which we
describe in more detail in Section 3, executes a JavaScript-
1406based cache attack, which lets the attacker track accesses
to the victim’s last-level cache over time. Since this single
cache is shared by all CPU cores, this access information can
provide the attacker with a detailed knowledge regarding the
user and system under attack.
Crafting a last-level cache attack that can be launched
over the web using JavaScript is quite challenging; JavaScript
code cannot load shared libraries or execute native code.
More importantly, it is forced to make timing measurements
using scripting language function calls instead of high-ﬁdelity
timing instructions. Despite these challenges, we success-
fully extended cache attacks to the web environment:
• We present a novel method for creating a non-canonical
eviction set for the last-level cache. In contrast to the
recent work by Liu et al. [14], our method does not
require system support for large pages, and therefore,
it can immediately be applied to a wider variety of
systems. More importantly, we show that our method
runs in a practical time frame.
• We demonstrate a last-level cache attack using Java-
Script code only. We evaluate its performance using a
covert channel method, both among diﬀerent processes
running on the same machine and between a VM client
and its host. The nominal capacity of the JavaScript-
based channel is in the order of hundreds of Kbit/s,
comparable to that of native code approaches [14].
• We show how cache-based attacks can be used to track
the behaviour of users. Speciﬁcally, we present a simple
classiﬁer-based attack that lets a malicious webpage
spy on the user’s browsing activity, detecting the use
of common websites with an accuracy of over 80%.
Remarkably, it is even possible to spy on the private
browsing session of a completely diﬀerent browser.
2. BACKGROUND AND RELATED WORK
2.1 Memory Hierarchy of Intel CPUs
Modern computer systems incorporate high-speed CPUs
and a large amount of lower-speed RAM. To bridge the per-
formance gap between these two components, they make
use of cache memory: a type of memory that is smaller but
faster than RAM (in terms of access time). Cache memory
contains a subset of the RAM’s contents recently accessed by
the CPU, and is typically arranged in a cache hierarchy—
series of progressively larger and slower memory elements
are placed in various levels between the CPU and RAM.
Figure 1 shows the cache hierarchy of Intel Haswell CPUs,
incorporating a small, fast level 1 (L1) cache, a slightly larger
level 2 (L2) cache, and ﬁnally, a larger level 3 (L3) cache,
which in turn is connected to RAM. Whenever the CPU
wishes to access physical memory, the respective address is
ﬁrst searched for in the cache hierarchy, saving the lengthy
round-trip to RAM. If the CPU requires an element that is
not currently in the cache, an event known as a cache miss,
one of the elements currently residing in the cache is evicted
to make room for this new element. The decision of which
element to evict in the event of a cache miss is made by
a heuristic algorithm that has changed between processor
generations (see Section 6.2).
Figure 1: Cache memory hierarchy of Intel CPUs
(based on Ivy Bridge Core i5-3470).
Intel’s cache micro-architecture is inclusive: all elements
in the L1 cache exist in the L2 and L3 caches. Conversely,
if a memory element is evicted from the L3 cache, it is also
immediately evicted from the L2 and L1 cache. It should
be noted that the AMD cache micro-architecture is exclu-
sive, and thus, the attacks described in this paper are not
immediately applicable to that platform.
In this work, we focus on the L3 cache, commonly referred
to as the last-level cache (LLC). The LLC is shared among
all cores, threads, processes, and even virtual machines run-
ning on a certain CPU chip, regardless of protection rings
or other isolation mechanisms. On Intel CPUs, the LLC is
divided into several slices: each core of the CPU is directly
connected to one of these cache slices, but can also access
all other slices by using a ring bus interconnection.
Due to the relatively large size of the LLC, it is not eﬃ-
cient to search its entire contents whenever the CPU accesses
the RAM. Instead, the LLC is further divided into cache
sets, each covering a ﬁxed subset of the physical memory
space. Each of these cache sets contains several cache lines.
For example, the Intel Core i7-4960HQ processor, belonging
to the Haswell family, includes 8192 (213) cache sets, each
of which is 12-way associative. This means that every cache
set can hold 12 lines of 64 (26) bytes each, giving a total
cache size of 8192x12x64=6MB. When the CPU needs to
check whether a given physical address is present in the L3
cache, it calculates which cache set is responsible for this
address, and then only checks the cache lines correspond-
ing to this set. As a consequence, a cache miss event for
a physical address will result in the eviction of only one of
the relatively small amount of lines sharing its cache set, a
fact we make great use of in our attack. The method by
which 64-bit physical addresses are mapped into 12-bit or
13-bit cache set indices is undocumented and varies among
processor generations, as we discuss in Section 6.2.
32KBL1 D−CacheL2 Unified Cache256KB32KBL1 I−Cache32KBL1 D−CacheCore 3L1 I−Cache32KBL2 Unified Cache256KBCore 1L3 Shared Cache6MB32KBL1 D−CacheL2 Unified Cache256KB32KBL1 I−Cache32KBL1 D−CacheL2 Unified Cache256KB32KBL1 I−CacheCore 0Core 2CPU1407In the case of Sandy Bridge, this mapping was reverse-
engineered by Hund et al. [10], where they showed that of
the 64 physical address bits, bits 5 to 0 are ignored, bits 16
to 6 are taken directly as the lower 11 bits of the set index,
and bits 63 to 17 are hashed to form the slice index, a 2-bit
(in the case of quad-core) or 1-bit (in the case of dual-core)
value assigning each cache set to a particular LLC slice.
In addition to the above, modern computers typically sup-
port virtual memory, restricting user processes from having
direct access to the system’s RAM. Instead, these processes
are allocated virtual memory pages. The ﬁrst time a page
is accessed by an executing process, the Operating System
(OS) dynamically associates the page with a page frame in
RAM. The Memory Management Unit (MMU) is in charge
of mapping the virtual memory accesses made by diﬀerent
processes to accesses in physical memory. The size of pages
and page frames in most Intel processors is typically set
to 4KB1, and both pages and page frames are page-aligned
(i.e., the starting address of each page is a multiple of the
page size). This means that the lower 12 bits of any virtual
address and its corresponding physical address are generally
identical, another fact we use in our attack.
2.2 Cache Attacks
The cache attack is a well-known representative of the gen-
eral class of micro-architectural side-channel attacks, which
are deﬁned by Acii¸cmez [1] as attacks that “exploit deeper
processor ingredients below the trust architecture bound-
ary” to recover secrets from various secure systems. Cache
attacks make use of the fact that—regardless of higher-level
security mechanisms, like protection rings, virtual memory,
hypervisors, and sandboxing—secure and insecure processes
can interact through their shared use of the cache. This
allows an attacker to craft a “spy” program that can make
inferences about the internal state of a secure process. First
identiﬁed by Hu [9], several results have shown how the cache
side-channel can be used to recover AES keys [3, 19], RSA
keys [21], or even allow one virtual machine to compromise
another virtual machine running on the same host [24].
Our attack is modeled after the Prime+Probe method,
which was ﬁrst described by Osvik et al. [19] in the context
of the L1 cache, and later extended by Liu et al. [14] to last-
level caches on systems with large pages enabled.
In this
work, we further extend this attack to last-level caches in
the more common case of 4KB-sized pages.
In general, the Prime+Probe attack follows a four-step
pattern. In the ﬁrst step, the attacker creates one or more
eviction sets. An eviction set is a sequence of memory ad-
dresses that are all mapped by the CPU into the same cache
set. The Prime+Probe attack also assumes that the victim
code uses this cache set for its own code or data. In the sec-
ond step, the attacker primes the cache set by accessing the
eviction set in an appropriate way. This forces the eviction
of the victim’s data or instructions from the cache set and
brings it to a known state. In the third step, the attacker
triggers the victim process, or passively waits for it to exe-
cute. During this execution step, the victim may potentially
utilise the cache and evict some of the attacker’s elements
from the cache set. In the fourth step, the attacker probes
the cache set by accessing the eviction set again.
12MB and 1GB pages are also supported in newer CPUs.
A probe step with a low access latency suggests that the
attacker’s eviction set is still in the cache. Conversely, a
higher access latency suggests that the victim’s code made
use of the cache set and evicted some of the attacker’s mem-
ory elements. The attacker thus learns about the victim’s
internal state. The actual timing measurement is carried out
by using the (unprivileged) instruction rdtsc, which pro-
vides a high-ﬁdelity measurement of the CPU cycle count.
Iterating over the eviction set in the probing phase forces the
cache set yet again into an attacker-controlled state, thus
preparing for the next round of measurements.
3. PRIME+PROBE IN JAVASCRIPT
JavaScript is a dynamically typed, object-based scripting
language with runtime evaluation that powers the client side
of the modern web. Websites deliver JavaScript programs
to the browser, which in turn are (typically) compiled and
optimized using a Just-In-Time (JIT) mechanism.
The core functionality of the JavaScript language is de-
ﬁned in the standard ECMA-262 [5]. The language standard
is complemented by a large set of application programming
interfaces (APIs) deﬁned by the World Wide Web Consor-
tium [27], which make the language practical for developing
web content. The JavaScript API set is constantly evolving,
and browser vendors add support for new APIs over time
according to their own development schedules. Two speciﬁc
APIs that are of use to us in this work are the Typed Array
Speciﬁcation [7], which allows eﬃcient access to unstruc-
tured binary data, and the High Resolution Time API [16],
which provides JavaScript with submillisecond time mea-
surements. As we show in Section 6.1, the vast majority of
Web browsers that are in use today support both APIs.
By default, browsers will automatically execute every Java-
Script program delivered to them by a webpage. To limit
the potential damage of this property, JavaScript code runs
in a sandboxed environment—code delivered via JavaScript
has severely restricted access to the system. For example, it
cannot open ﬁles, even for reading, without the permission
of the user. Also, it cannot execute native code or load na-
tive code libraries. Most importantly, JavaScript code has
no notion of pointers. Thus, it is impossible to determine
the virtual address of a JavaScript variable.
Methodology. The four steps involved in a successful
Prime+Probe attack (see Section 2.2) are the following:
(a.) creating an eviction set for one or more relevant cache
sets; (b.) priming the cache set; (c.) triggering the victim
operation; (d.) probing the cache set again. Each of these
steps must be implemented in JavaScript and overcome the
unique limitations of the web environment.
3.1 Creating an Eviction Set
In the ﬁrst step of a Prime+Probe attack the attacker
creates an eviction set for a cache set whose activity should
be tracked [14]. This eviction set consists of a sequence
of variables (data) that are all mapped by the CPU into a
cache set that is also used by the victim process. We ﬁrst
show how we create an eviction set for an arbitrary cache
set, and later address the problem of ﬁnding which cache set
is particularly interesting from the attacker’s perspective.
1408Set assignments for variables in the LLC are made by