### An Engineering Leader’s Guide to OpenTelemetry

**Daniel “Spoons” Spoonhower**  
CTO and Co-founder, Lightstep

#### Introduction
Effective decision-making in engineering is fundamentally dependent on having the right data. Without accurate and relevant data, it's impossible to understand the current state of your systems or the impact of past decisions. This is particularly critical for modern software applications, where change is constant—whether it's changes in user behavior, infrastructure, or the application itself.

#### The Importance of Telemetry
User-facing performance data is among the most crucial information you can collect about an application. Users expect applications (on mobile or desktop) to be responsive and error-free. If they are not, users will likely switch to a competitor. This typically involves measuring metrics such as latency, errors, and key conversions.

Equally important is the data that describes the internal workings of the application and the infrastructure it runs on. This data helps engineers and developers improve user experience and manage costs. It includes measuring latency and error rates, and mapping these metrics to individual services, software components, or even code paths. This enables a deeper understanding of the relationship between causes and effects.

Regardless of the languages, frameworks, tools, or vendors you use, the importance of this telemetry remains constant. In fact, as your architecture and tools evolve, good telemetry becomes even more essential.

#### Autonomy and Global Visibility
Engineering organizations are increasingly giving teams more autonomy in choosing technologies, tools, and work cadences. However, this autonomy does not negate the need for a global view of the application. Good telemetry allows you to reconstruct and compare transactions as experienced by users, regardless of the technologies or processes used by different teams.

The best way for engineering leaders to drive consistent and scalable choices is to provide a "paved road" with a set of frameworks and tools that make it easy to do the right thing while still allowing for some flexibility. However, without standards for interoperability, especially in the context of telemetry, this can lead to high communication overhead and suboptimal outcomes.

OpenTelemetry provides both the components for this paved road and the standards to ensure that divergent choices do not fragment decision-making processes. In this guide, we will discuss the importance of telemetry in applications, how recent technological and organizational changes have amplified its significance, and why an open, vendor-neutral approach is critical. We will also make the case for why OpenTelemetry is the best choice for organizations adopting modern development technologies, tools, and practices.

#### Why Should You Care About Telemetry?
Telemetry refers to the data used to monitor applications, encompassing logs, time series metrics, and distributed traces. While metrics and logs have been around for a long time, traces have recently become more important as organizations adopt microservices and other loosely coupled architectures.

- **Metrics**: These are statistics about performance, usually stored and rendered as time series. For example, tracking median request latency over time. Metrics are excellent for showing when behavior has changed and scale well.
- **Logs**: These are records of individual events, often including a timestamp and a string of text. Ideally, logs have more structure to enable sophisticated analysis and efficient searches.
- **Distributed Traces**: These are the newest type of telemetry, consisting of a series of events about a user request as it is handled by different services. Traces help you find every event within a distributed transaction and understand performance variations.

Decoupling the generation of telemetry from the tools used to analyze it is crucial for two reasons:
1. Different teams may need different analyses and may choose different tools, especially in DevOps environments.
2. Siloing different types of telemetry limits the analyses that those tools can perform, leading to fragmented and less effective decision-making.

#### Telemetry vs. Observability
Telemetry is related to but distinct from observability. While telemetry is the data collected, observability is the ability to connect cause and effect in a distributed system. Observability tools help you understand what internal changes have led to changes in user-visible performance or resource consumption.

While metrics, logs, and traces are necessary for observability, they are not sufficient. You also need tools to analyze and visualize this data to derive value from it.

#### OpenTelemetry: A Unified Solution
OpenTelemetry addresses these challenges by defining the interface between the application and the tools used to monitor and observe it. It provides APIs and SDKs for logs, metrics, and traces, ensuring a consistent way to handle all three types of telemetry. OpenTelemetry supports popular languages like Java, C#, Go, JavaScript, Python, PHP, Rust, and C++.

OpenTelemetry also defines standards for how telemetry is sent over the network and how context is propagated within an application. It offers components like exporters and collectors to make it easy to get up and running quickly. By using OpenTelemetry, you ensure a consistent, global view of the application and prevent telemetry from being siloed according to legacy approaches.

#### Why Choose Vendor-Neutral Telemetry?
As DevOps teams take on more responsibility for production systems, they need to learn and implement new tools. One of the biggest costs associated with new monitoring and observability tools is instrumenting the application to generate telemetry and building a pipeline to ship that data for analysis.

New datastores and developments in machine learning will offer more efficient and valuable ways to store and analyze telemetry. Decoupling telemetry from specific vendors ensures that any investments in telemetry will have a longer lifespan and help unlock new value more easily.

When adopting a new tool, there are typically two types of engineering changes required:
1. Instrumentation: Changes to the application's source code or configuration.
2. Data Pipeline: Setting up the infrastructure to convey telemetry from the application to the systems that will store and analyze it.

Integrating your application with OpenTelemetry future-proofs your organization against changes in how telemetry is stored and analyzed, providing the flexibility to adopt new tools when and how it’s right for your teams.

#### Why Should OpenTelemetry Be Your Standard?
OpenTelemetry is a great way to combine different types of telemetry from across your application and protect your organization from future vendor changes. The APIs, wire formats, and other standards set by OpenTelemetry have been carefully designed by industry experts. Additionally, its permissive licenses make it compatible with other open-source projects, which is likely already part of your application.

Your platform team should focus on integrating observability into other tools, such as source code repositories or CI/CD pipelines, rather than reinventing the wheel for telemetry collection.

#### Conclusion
At Lightstep, we strive to ensure that organizations make the best choices for their needs. We recommend adopting OpenTelemetry as part of projects to modernize how applications are monitored and observed. OpenTelemetry is a low-risk way to ensure that your organization can get the most value from observability tools today and in the future.

Understanding the performance of the application as a whole is essential, and combining different types of telemetry (metrics, logs, and traces) is key to deriving insights quickly. As your organization adopts DevOps practices, setting standards will become increasingly important to avoid miscommunication and redundant work.

OpenTelemetry provides a cost-effective and scalable way for your platform and infrastructure teams to support the rest of the organization while enforcing these standards. By using an expert-built abstraction layer compatible with other open-source components, your platform team can focus on customizations with a higher return on investment for your organization, application, and users.

#### About Lightstep
Lightstep’s mission is to deliver confidence at scale for those who develop, operate, and rely on today’s powerful software applications. Our products leverage distributed tracing technology, initially developed by a Lightstep co-founder at Google, to offer best-of-breed observability to organizations adopting microservices or serverless at scale. Lightstep is backed by Redpoint, Sequoia, Altimeter Capital, Cowboy Ventures, and Harrison Metal, and is headquartered in San Francisco, CA. For more information, visit [Lightstep.com](https://lightstep.com) or follow [@LightstepHQ](https://twitter.com/LightstepHQ).

#### Get Lightstep for Free
Sign up for our free Community plan, drop by our office hours, or schedule a demo with our team.

©2020 Lightstep, Inc.