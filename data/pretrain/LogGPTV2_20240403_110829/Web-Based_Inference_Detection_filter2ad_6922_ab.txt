learn from
that the document pertains to an individ-
ual characterized by the keywords “Saudi”, “magnate”,
“half-brothers”, “Yemen”, etc. We learn from
that
these keywords are closely associated with “Osama Bin
Laden”. If we combine these two sources of information,
we learn that the statement S is true with high probabil-
ity.
It is critical to understand Diff(C,R) prior to pub-
of private documents, to en-
lishing the collection
C
does not allow for un-
sure that the publication of
C
wanted inferences. The owner of
may choose to with-
hold from publication parts or all of the documents in
the collection based on an assessment of the difference
Diff(C,R). Sometimes, the set of sensitive knowledge
K∗
that should not be leaked is explicitly speciﬁed. In
this case, the inference control problem consists more
precisely of ensuring that the intersection Diff(C,R) ∩
K∗
R
C
is empty.
3.1 Basic Approach
C
R
In this work, we consider the case in which
can be any
arbitrary collection of documents. In particular, contrary
to prior work on inference control in databases, we do
not restrict ourselves to private documents formatted ac-
cording to a well-deﬁned structure. We assume that the
collection
of public documents consists of all publicly
available documents, and that the public Web serves as a
good proxy for this collection. Our generic approach to
inference detection is based on the following two steps:
1. UNDERSTANDING THE CONTENT OF THE DOCU-
. We employ
MENTS IN THE PRIVATE COLLECTION
automated content analysis in order to efﬁciently extract
keywords that capture the content of the document in the
collection
. A wide array of NLP tools are possible for
this process, ranging from simple text extraction to deep
linguistic analysis. For the proof-of-concept demonstra-
tions described in section 5, we employ keyword selec-
tion via a “term frequency - inverse document frequency”
(TF.IDF) calculation, but we note that a deeper linguistic
analysis may produce better results.
2.
EFFICIENTLY DETERMINING THE INFERENCES
THAT CAN BE DRAWN FROM THE COMBINATION OF
C
. We issue search queries for documents that
AND
R
C
C
match subsets of the keywords extracted in step 1, within
a reference corpus (such as the public Web) that encap-
sulates as much of relevant public knowledge as possi-
ble. Our tools then parse the documents returned by the
search queries for keywords not present in the original
private data. These additional keywords allow us to au-
tomatically estimate the likelihood of certain inferences.
Potentially dangerous inferences are ﬂagged for manual
review.
3.2
Inference Detection Algorithm
In this section, we give a generic description of our infer-
ence detection algorithm. This description emphasizes
conceptual understanding. Speciﬁc instantiations of the
inference detection algorithms, tailored to two particular
applications, are given in section 5. These instantiations
do not realize the full complexity of this general algo-
rithm partly for efﬁciency reasons and partly because of
the attributes of the application. We start with a descrip-
tion of the inputs, outputs and parameters of our generic
algorithm.
C =
INPUTS: A private collection of documents
{C1, . . . , Cn}
R
and a list of sensitive keywords K∗
that represent sen-
sitive knowledge.
L
of inferences that can be drawn from
OUTPUT: A list
R
C
. Each inference is of the form:
and
the union of
(W1, . . . , Wk) ⇒ K
, a collection of reference documents
∗
0 ,
C
C
0 ⊆ K∗
, and K∗
where W1, . . . , Wk are keywords extracted from docu-
is a subset of sensitive key-
ments in
words. The inference (W1, . . . , Wk) ⇒ K∗
0 , indicates
that the keywords (W1, . . . , Wk), found in the collection
R
C
, together with the knowledge present in
allow for
inference of the sensitive keywords K∗
0. The algorithm
returns an empty list if it fails to detect any sensitive in-
ference.
PARAMETERS: The algorithm is parameterized by a
value α that controls the depth of the NLP analysis of
, by two values β and γ that control
the documents in
the search depth for documents in
that are related to
C
, and ﬁnally by a value δ that controls the depth of the
NLP analysis of the documents retrieved by the search
algorithm. The values α, β, γ and δ are all positive in-
tegers. They can be tuned to achieve different trade-offs
between the running time of the algorithm and the com-
pleteness and quality of inference detection.
C
. Our basic
UNDERSTANDING THE DOCUMENTS IN
algorithm uses TF.IDF (term frequency - inverse docu-
ment frequency, see [28] and section 5.1) to extract from
the top α keywords
each document Ci in the collection
R
C
74
16th USENIX Security Symposium
USENIX Association
L
i=1Si.
that are most representative of Ci. Let Si denote the set
of the top α keywords extracted from document Ci, and
let S = ∪n
INFERENCE DETECTION. The list
tially empty. We consider in turn every subset
|S0| ≤ β. For every such subset
S
of size
(W1, . . . , Wk), with k ≤ β, we do the following:
1. We use a search engine to retrieve from the collec-
of reference documents the top γ documents
of inferences is ini-
S0 ⊆
S0 =
tion
that contain all the keywords W1, . . . , Wk.
R
2. With TF.IDF, we extract the top δ keywords from
this collection of γ documents. Note that these key-
words are extracted from the aggregate collection of
γ documents (as if all these documents were con-
catenated into a single large document), not from
each individual document.
3. Let K∗
from step 2 with the set K∗
If K∗
0 is non-empty, we add to
K∗
0.
0 denote the intersection of the δ keywords
of sensitive keywords.
C0 ⇒
L
the inference
The algorithm outputs the list
and terminates.
L
3.3 Variants of the Algorithm
C
and the reference collection
The algorithm of section 3.2 can be tailored to a variety
of applications. Two such applications are discussed in
exhaustive detail in section 5. Here, we discuss brieﬂy
other possible variants of the basic algorithm.
DETECTING ALL INFERENCES.
In some applications,
the set of sensitive knowledge K∗
may not be known or
may not be speciﬁed. Instead, the goal is to identify all
possible inferences that arise from knowledge of the col-
R
lection of documents
.
A simple variation of the algorithm given in 3.2 handles
this case. In step 3 of the inference detection phase, we
record all inferences instead of only inferences that in-
volve keywords in K∗
. Note that this is equivalent to
assuming that the set K∗
of sensitive knowledge consists
of all knowledge. The algorithm may also track the num-
ber of occurrences of each inference, so that the list
can
be sorted from most to least frequent inference.
ALTERNATIVE
SENSITIVE
KNOWLEDGE. The algorithm of section 3.2 assumes
that the sensitive knowledge K∗
is given as a set of
keywords. Other representations of sensitive knowledge
are possible. In some applications for example, sensitive
knowledge may consist of a topic (e.g.
alcoholism,
or sexually transmitted diseases) instead of a list of
keywords. To handle this case, we need a pre-processing
step which converts a sensitive topic into a list of
REPRESENTATION
L
OF
sensitive keywords. One way of doing so is to issue a
search query for documents in the reference collection
R
then use TF.IDF
to extract from these documents an expanded set of
sensitive keywords.
that contain the sensitive topic,
4 Example Applications
This section describes a wide array of potential applica-
tions for Web-based inference detection. All these appli-
cations are based on the fundamental algorithm of sec-
tion 3. The ﬁrst two applications are the subjects of the
experiments described in detail in section 5. Experiment-
ing with other applications will be the subject of future
work.
REDACTION OF MEDICAL RECORDS. Medical records
are often released to third parties such as insurance com-
panies, research institutions or legal counsel in the case
of malpractice lawsuits. State and federal legislation
mandates the redaction of sensitive information from
medical records prior to release. For example, all ref-
erences to drugs and alcohol, mental health and HIV sta-
tus must typically be redacted. This redaction task is far
more complex than it may initially appear. Extensive and
up-to-date knowledge of diseases and drugs is required to
detect all clues and combinations of clues that may allow
for inference of sensitive information. Since this medical
information is readily available on public websites, the
process of redacting sensitive information from medical
records can be partially automated with Web-based infer-
ence control. Section 5.3 reports on our experiments with
Web-based inference detection for medical redaction.
PRESERVING INDIVIDUAL ANONYMITY.
Intelligence
and other governmental agencies are often forced by law
(such as the Freedom of Information Act) to release pub-
licly documents that pertain to a particular individual or
group of individuals. To protect the privacy of those con-
cerned, the documents must be released in a form that
does not allow for unique identiﬁcation. This problem is
notoriously difﬁcult, because seemingly innocuous infor-
mation may allow for unique identiﬁcation, as illustrated
by the poorly redacted Osama Bin Laden biography [8]
discussed in the introduction. Web-based inference con-
trol is perfectly suited to the detection of indirect infer-
ences based on publicly available data. Our tools can
be used to determine how much information can be re-
leased about a person, entity or event while preserving k-
anonymity, i.e. ensuring that it remains hidden in a group
of like-entities of size at least k, and cannot be identiﬁed
any more precisely within the group. Section 5.2 reports
on our experiments with Web-based inference detection
for preserving individual anonymity.
USENIX Association
16th USENIX Security Symposium
75
FORMULATION OF REDACTION RULES. Our Web-based
inference detection tools can also be used to pre-compute
a set of redaction rules that is later applied to a collection
of private documents. For a large collection of private
documents, pre-computing redaction rules may be more
efﬁcient than using Web-based inference detection to an-
alyze each and every document. In 1995 for example,
executive order 12958 mandated the declassiﬁcation of
large amounts of government data [9] (hundreds of mil-
lions of pages). Sensitive portions of documents were to
be redacted prior to declassiﬁcation. The redaction rules
were exceedingly complex and formulating them was
reportedly nearly as time-consuming as applying them.
Web-based inference detection is an appealing approach
to automatically expand a small set of seed redaction
rules. For example, assuming that the keyword “mis-
sile” is sensitive, web-based inference detection could
automatically retrieve other keywords related to missiles
(e.g. “guidance system”, “ballistics”, “solid fuel”) and
add them to the redaction rule.
PUBLIC IMAGE CONTROL. This application considers
the problem of verifying that a document conforms to
the intentions of its author, and does not accidentally re-
veal private information or information that could eas-
ily be misinterpreted or understood in the wrong con-
text. This application, unlike others, does not assume
that the set of unwanted inferences is known or explic-
itly deﬁned.
Instead, the goal of this application is to
design a broad, general-purpose tool that helps contex-
tualize information and may draw an author’s attention
to a broad array of potentially unwanted inferences. For
example, Web-based inference detection could alert the
author of a blog to the fact that a particular posting con-
tains a combination of keywords that will make the blog
appear prominently in the results of some search query.
This problem is related to other approaches to public im-
age management, such as [13, 31]. Few technical details
have been published about these other approaches, but
they do not appear focused on inference detection and
control.
LEAK DETECTION. This application helps a data owner
avoid accidental releases of information that was not pre-
viously public. In this application of Web-based infer-
ence control, the set of sensitive knowledge K∗
consists
of all information that was not previously public. In other
words, the release of private data should not add anything
to public knowledge. This application may have helped
prevent, for example, a recent incident in which Google
accidentally released conﬁdential ﬁnancial information
in the notes of a PowerPoint presentation distributed to
ﬁnancial analysts [22].
5 Experiments
Our experiments focus on exploring the ﬁrst two pri-
vacy monitor applications of section 4: redaction of med-
ical records and preserving individual anonymity.
In
testing these ideas, we faced two main challenges that
constrained our experimental design. First, and most
challenging, was designing relevant experiments that we
could execute given available data. The second, more