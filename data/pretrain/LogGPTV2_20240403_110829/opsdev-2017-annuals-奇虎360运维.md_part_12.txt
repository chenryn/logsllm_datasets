## Page 92
https://opsdev.cn/post/timeseries_anomaly_detection.html
本文链接：
致 CPU 报警。
可以看一下。报警自发现：这个就是找到问题的根源，比如 CPU 报警，可以通过查看 top 来找到是什么进程导
A：先说异常检测吧，最近看到一个开源技术估计对你们有帮助：Skyline timeseries 异常判定算法，有兴趣
Q：报警自发现和异常检测，我们也很感兴趣，请问能简单介绍下思路吗？
以取最小值，是让筛选条件设置得宽松一些，让更多的值通过此条件。
A：我们取过去一段时间内数据的平均值、最大值以及最小值，然后取 max-avg 和 avg-min 的最小值。之所 
Q：你们的动态阈值选择的方法挺巧妙的，能不能再详细介绍一下该方法？
面对面：
要具体的分析，才能将理论应用于实践。
的场景，需要去不断丰富算法，才能达到比较好的效果。所谓，理论结合实际，具体的问题需
 2. http://chuansong.me/n/2032667
1. https:/jiroujuan.wordpress.com/2013/10/09/skyline-anomalous-detect-algorithms/ 
参考文献：
这篇博客介绍了我们在LVS 异常检测中使用的方法，
输入数据
机器学习－时间序列异常检测机制的研究
也许这些方法还不够你解决所面临
5
一扫查看文章详情
---
## Page 93
程遗留的问题。除此之外，我们还需要面临下面问题的挑战：
TensorFlow on Kubernetes 的设计目标
统一调度和管理系统。
Google 开源的容器集群管理系统，在 tf1.6 版本加入 GPU 管理后，已经成为很好的 tf任务的
netes，yarn 是 hadoop 生态中的资源管理系统，而 kubernetes（以下简称k8s）作为
管理和跟踪等问题。目前，社区中有多种开源项目可以解决类似的问题，比如 yarn，kuber-
GPU负载不均衡；
概念，做到资源的有效隔离成为比较重要的问题；
的时候，我们或多或少将面临以下问题：
台，提供强大的算法模型，被越来越多的开发者使用。但在使用的过程中，尤其是GPU 集群
ITENSORFLOW ON KUBERNETES
，能自动生成 clusterspec 信息；
88Tensorflow on Kubernetes － 机器学习
我们将TensorFlow 引l入k8s，可以利用其本身的机制解决资源隔离，GPU调度以及进 
I Aug. 26th 2017 BY 籍鑫璞
为了解决上面的问题，我们开发了 TensorFlow on Kubernetes 系统。
·训练数据、训练模型以及日志不会因为容器销毁而丢失，可以统一保存;
·分布式的tf程序不再需要手动配置 clusterspec 信息，只需要指定 worker 和 ps 的数目
·支持单机和分布式的 TensorFlow 任务；
因此，我们需要一个集群调度和管理系统，可以解决 GPU调度、资源隔离、统一的作业
·缺乏 GPU调度，f 通过指定 GPU的编号来实现 GPU 的调度，这样容易造成集群的
Tensorflow 作为深度学习领域逐渐成熟的项目，以其支持多种开发语言，支持多种异构平
·训练日志保存、查看不方便；
·训练的数据分发以及训练模型保存，都需要人工介入；
·进程遗留问题，tf的分布式模式 ps 服务器会出现tf进程遗留问题；
---
## Page 94
但是它也有下拉代码和数据需要时间的缺点。综合考虑后，我们采取第三种方式。
client 模块
spec 模块负责自动生成 clusterspec 信息，减少人工干预。
布式模式来执行任务。需要注意的是，在分布式模式中会涉及到生成clusterspec 信息，auto-
的任务；如果 type 选择的是 distribute（分布式模式），对应的是 tf 的分布式任务，则按照分
模式），对应的是tf 中的单机任务，则按照按照用户提交的配额来启动container 并完成最终
任务的类型（单机模式和分布式模式）来确定接下来的流程：如果 type 选择的是 single（单机
TensorFlow on Kubernetes 架构
个模块。client 模块负责接收用户创建任务的请求，并将任务发送给 task 模块。task 模块根据
TensorFlow on Kubernetes 包含三个主要的部分，分别是 client，task 和 autospec 三
前两种方式不太适合用户经常修改代码的场景，最后一种场景可以解决修改代码的问题,
·从存储系统中获取代码和数据；
·将代码和数据通过卷的形式挂载到容器中;
·将代码和数据做成新的镜像；
在容器中执行任务的时候，我们可以通过三种方式获取执行任务的代码和训练需要的数据
tshell
接下来将对三个模块进行重点介绍。
下面是 TensorFlow on Kubernetes 的架构图:
(web、 shell)
Client
作业提交
Container
启动single模式的job
Task
Container
发送分布式任务→
机器学习－Tensorflow on Kubernetes
Container
Autospec
上报信息
Containe
89
---
## Page 95
麻烦。如何解决 clusterspec，成为了一个必须要解决的问题。
负责启动 tf任务，最后将日志和模型文件上传到 s3 里，完成一次f 单机任务。
container 里面主要做了两件事情，initcontainer 负责从 s3 中下载事先上传好的文件，container
client 模块
一个 ps 和两个 worker，我们先需要手动配置 ps 和 worker，才能开始任务。这样必然会带来一些
保存共享的参数，还有一种是worker，负责计算任务。
job 由好多个task 组成，task 分为两种，一种是PS（Parameter server），即参数服务器，用来
上。TF cluster 通过 tf.train.ClusterSpec 函数建立一个 cluster，每个 cluster 包含若干个 job。
flow 的分布式并行基于 gRPC 框架，client 负责建立 Session，将计算图的任务下发到 TF cluster
来将配额信息、s3 地址信息以及执行模式填好后，执行 send_task.py 我们就可以提交一次任务。
GPU个数（默认不提供），当然也可以按照我们提供的初始配额来调度任务。比如，按照下面格式
cifar10-multiGPU.tar.gz 并上传到 s3 后，就可以提交任务。
字叫 cifar10-multiGPU，将代码打包放到 code 下面，将训练数据放到 data 下面。最后打包成
90 Tensorflow on Kubernetes －机器学习
我们在执行分布式任务的时候，需要指定 clusterspec 信息，如下面的任务，执行该任务需要
对于分布式模式，
分布式模式
对于单机模式，task 模块的任务比较简单，直接调用 python 的 client 接口启动 container。
单机模式
在提交任务的时候，需要指定提前预估一下执行任务需要的配额：CPU核数、内存大小以及
提交任务
我们做了一个 tshell客户端，方便用户将代码和程序进行打包和上传。比如给自己的任务起名
python send_task.py\
-d cifar10_multi_gpu_train.py 
#执行任务的主程序名
-f tf-test:cifar10-multigpu:cifar10-multigpu.tar.gz \
#s3的路径（bucket:key:file）
-m 10240Mi
-tsingle\
#执行模式：single（单机模式）、distribute（分布式模式）
2
，情况要稍微复杂些。下面先简单介绍一下 tensforlow 分布式框架。tensor-
#gpu个数
#cpu核数
#f任务名
#内存大小
---
## Page 96
信息后，生成 clusterspec，发送给相应的 container。下面是 autospec 模块的工作流程图:
且不能实现自动化，我们引l入autospec 模型很好的解决此类问题。
clusterspec 信息，模型的情况下，clusterspec 信息是通过手动配置，这种方式比较麻烦，而
数信息，worker执行任务，并定期将参数发送给worker。要执行分布式任务，涉及到生成
Autospec 模块
，才能真正启动任务。所以分布式模式要做两件事情：
 Autospec 模块只有一个用途，就是在执行分布式任务时，从 container 中收集IP 和 Port
tf 分布式模式的 node 按照角色分为 ps（负责收集参数信息）和 worker，ps 负责收集参
·通知 am 模块收集此次任务 container 的信息后生成 clusterspec;
·按照 yaml 文件启动 container;
所以在提交分布式任务的时候，task 需要 autospec 模块的帮助，收集 container 的IP 后
task_index=1 
python distributed.py
# worker02服务器执行：
worker_hosts=ip2,ip3:2222
python distributed.py --ps_hosts=ip1:2222 -
# worker01服务器执行：
worker_
worker_hosts=ip2:2222,ip3:2222 --job_name=ps --task_index=0
# ps服务器执行：
_hosts=ip2:2222,ip3:2222 --job_name=worker --
tensorflow:Session
0000
RPC
ob0:
Wo
 --ps_hosts=ip1:2222 --
 --job_name=worker --task_index=0
100
000
W
机器学习 － Tensorflow on Kubernetes
△Wn-1
6
---
## Page 97
我们前期的探索，后面还有许多东西需要完善。
比如：web 端提交任务以及查看运行状况和作业的日志，支持 GPU的亲和性等等，总之，这只是
后期目标
存。我们接下来分单机和分布式两种模式来说明 Container 的设计思想。
点，在 poststart 做一些数据获取的工作，而在 prestop 阶段负责将训练产生的模型和日志进行保
前做一些初始化的工作，而 prestop 负责在容器销毁之前做一些备份之类的工作。我们利用了此特
此特征，将 container 都设置为 job 类型。k8s 中设计了一种 hook：poststart 负责在容器启动之
Container 设计
92
至此，我们已经介绍了 TensorFlow on Kubernetes 的主要流程。还有许多需要完善的地方,
tf任务比较符合 k8s 中 kind 为 job 的任务，每次执行完成以后这个容器会被销毁。我们利用了
Tensorflow on Kubernetes－机器学习
Autospec
1.上报信息一
发
送clusterspec
一
Container
Container
Container
Container
worker1
workero
ps1
pso
TF任务
TF任务
TF任务
---
## Page 98
https://opsdev.cn/post/TensorFlow-on-Kubernetes-introduction.html 
本文链接：
A:k8s 中的 pod 只能单独使用一块卡，pod 间不能共用 GPU卡，这也许是一个优化的地方。
Q：k8s 在 GPU方面的调度是如何的?
2.相比于yarn，k8s对于资源的管控会更有优势；
1.微服务是现在发展的趋势，而 k8s 作为容器服务的天然调度系统，有 yarn 无法比拟的优势；
A：我觉得优势主要体现在以下几个方面：
Q：相比于 yarn，tf 任务在 Kubernetes 有什么优势？
面对面：
机器学习－ Tensorflow on Kubernetes
-扫查看文章详情
93
口
---
## Page 99
智能预测与处理系统
及时了解机器的运行状况，最大化机器资源的利用率。
机器资源。
能够帮助运维人员去更快地排查报警，它还是一个对机器各个维度进行检测的系统，能够优化
项的报警并提前处理预测的报警，最大程度减少报警次数；它是一个关联不同报警项的系统，
不够的。而且这种被动式的触发报警很多时候需要人工去处理。
wonder 来监控系统的状态。但是随着业务量的增加，通过设置单纯的阈值来监控报警是远远
I360DOCTORSTRANGE
94360DoctorStrange－机器学习
我们提出来DoctorStrange，
Mar. 10th 2017 BY 籍鑫璞
我们对监控项的历史数据进行分析后就会发现，有些监控项的历史趋势的增长（或下降
首先介绍智能预测与处理系统，然后介绍报警关联分析，最后引入机器健康度的概念，来
下面我们将分三个部分对该系统进行介绍：
为了保证360公司内部的私有云平台的稳定性和可靠性，我们部门开发了监控系统一-
监控系统
采集监控项历史数据
预测趋势
建立模型
它是一个智能的预测和处理系统，
预测
自动处理
通知机制
通知机制
能够提前预测出一些监控
自动化处理
通知处理
处理
---
## Page 100
及一些归档的日志文件。虽然我们有一定的目录规范和定期的日志轮转，但是因为有些程序编
以根据自己的意愿选择处理类型：一种是自动处理，一种是通知邮件。
我们的模型能够获得比较好的效果。
果。可以发现我们的模型预测准确率能够达到100%，报警减少率能够达到70%左右，这说明
来两个概念来说明效果：
模型阶数。
为平稳序列，而 p 和 q 可以使用 AIC 或者 BIC 准则来得到使 AIC 或者 BIC 信息量达到最小的
容量进行预测分析。