# Title: @spam: The Underground on 140 Characters or Less
# Authors:
- Chris Grier†
- Kurt Thomas∗
- Vern Paxson†
- Michael Zhang†

† University of California, Berkeley  
∗ University of Illinois, Champaign-Urbana

Email: {grier, vern, mczhang}@cs.berkeley.edu

## Abstract
In this study, we present a comprehensive analysis of spam on Twitter. Our findings indicate that 8% of 25 million URLs posted on the platform are linked to phishing, malware, and scams listed on popular blacklists. We examine the accounts responsible for spamming and find evidence suggesting that these activities often originate from previously legitimate accounts that have been compromised. By analyzing click-through data, we assess the effectiveness of spammers' use of unique Twitter features and their impact on the success of spam. Our results show that Twitter is an effective platform for directing users to spam pages, with a click-through rate of 0.13%, significantly higher than the rates reported for email spam. We group spam URLs into campaigns and identify trends that distinguish phishing, malware, and spam, providing insights into the techniques used to attract users.

Given the lack of spam filtering on Twitter, we evaluate the potential of using URL blacklists to mitigate the spread of spam. Our analysis reveals that blacklists are too slow in identifying new threats, allowing over 90% of visitors to access a page before it is blacklisted. Even if blacklist delays were reduced, the use of URL shortening services by spammers for obfuscation negates the potential benefits unless more sophisticated spam filtering tools are developed.

## Categories and Subject Descriptors
K.4.1 [Public Policy Issues]: ABUSE AND CRIME INVOLVING COMPUTERS

## General Terms
Security, Measurement

## Acknowledgments
This research was partially supported by the NSF under Grants 0433702, CNS-0905631, and CNS-0831535, and by ONR under MURI Grant N000140911081.

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.

CCS'10, October 4–8, 2010, Chicago, Illinois, USA.
Copyright 2010 ACM 978-1-4503-0244-9/10/10 ...$10.00.

## 1. Introduction
Over the past few years, Twitter has grown to include 106 million users who post over one billion times per month [16]. As celebrities like Oprah, Ashton Kutcher, and Justin Bieber attract large followings, spammers have adapted their tactics to target Twitter with scams, malware, and phishing attacks [3]. Promising great diets and more friends, or simply stealing accounts, spam has become a pervasive problem on the platform [8].

Notable attacks on Twitter include brute force guessing of weak passwords, leading to the exploitation of compromised accounts to advertise diet pills [26]. Phishing is also a significant concern, prompting Twitter to redesign its private messaging system to mitigate such attacks [7]. Despite Twitter's efforts to notify users and stop phishing, spammers continue to create and compromise accounts, sending messages to trick users into clicking on harmful links.

Despite the increase in unsolicited messages, Twitter currently lacks a robust filtering mechanism to prevent spam, except for malware, which is blocked using Google’s Safebrowsing API [4]. Instead, Twitter uses heuristics to quantify spamming activity, such as excessive account creation or friend requests [22]. Using these methods and user reports, the site suspends offending accounts, removing their presence and associated messages from the platform.

In this paper, we present our findings from a large-scale effort to characterize spam on Twitter. After collecting a month-long sample of Twitter data, we analyzed over 400 million public tweets and crawled 25 million unique URLs. Using various URL blacklists, we identified over 2 million URLs directing users to scams, malware, and phishing sites—approximately 8% of all links posted on Twitter. We break down the techniques employed by spammers to entice Twitter users to click on links. By studying the accounts involved, we found that spammers primarily abuse compromised accounts rather than those created solely for spamming, which are less prevalent.

Using click-through data from spam URLs, we examined the success of Twitter spam in attracting over 1.6 million users to visit spam web pages. We found that the success of spam is directly tied to having a large audience and a variety of accounts to spam from, while certain Twitter-specific features also help increase user traffic. Overall, we found that 0.13% of messages advertised on Twitter are clicked, almost two orders of magnitude higher than email spam [11].

Given the absence of spam filtering on Twitter, we evaluated whether URL blacklists could significantly reduce the spread of spam. By measuring the time between a blacklist flagging a spam URL and its appearance on Twitter, we found that blacklists lag behind, with most spam messages appearing 4–20 days before the URLs are flagged. Over 90% of visits to spam URLs occur within the first two days of posting, indicating that blacklist lag-time is too long to protect a significant number of users. We also examined how spammers can use URL shortening services to evade blacklists, a current challenge for Twitter's malware detection.

In summary, the contributions of this paper are:
- A detailed analysis of tweets containing over 2 million distinct URLs pointing to blacklisted scams, phishing, and malware.
- An assessment of the click-through rate for spam on Twitter, finding that 0.13% of users exposed to spam URLs click through to the spam website.
- Identification of diverse spam campaigns exploiting a range of Twitter features to attract audiences, including large-scale phishing attacks and targeted scams.
- An evaluation of the performance of blacklists as a filter for URLs posted on Twitter, finding that they are currently too slow to stop harmful links from receiving thousands of clicks.
- Techniques to identify and analyze two types of spamming accounts on Twitter: those created primarily for spamming and accounts compromised by spammers.

The remainder of the paper is organized as follows: Section 2 provides a brief background on spam and an overview of Twitter. Section 3 describes the data we collected, and Section 4 discusses trends in spam tweets, the users who send them, and the click-through rate for URLs in tweets. Section 5 examines techniques for grouping spam into campaigns and examples of successful campaigns. Section 6 presents our evaluation of blacklists, followed by conclusions in Section 7.

## 2. Background
Email spam has been extensively studied, with research focusing on identification, characterization, and prevention. Common techniques for filtering email spam include IP blacklisting [18], domain and URL blacklisting [23, 25, 27], and content-based filtering [19]. More advanced approaches infer the templates used by bots to send spam and use these templates as filters [17]. Like many commercial solutions, we use publicly available URL and domain blacklists to identify spam on Twitter, leaving the exploration of classification techniques for future work.

Researchers have also sought to understand the internal workings of botnets, which are responsible for much of email spam [10], to measure the success of spam in attracting customers. In Spamalytics, the authors infiltrated the Storm botnet and altered the emails being sent, directly measuring the conversion and click-through rates of campaigns executed by the Storm botnet [11]. As Twitter is a new medium for spam, we investigate the click-through rate for spam tweets and offer a comparison to email spam. Currently, we are limited to observing click-through rates and cannot determine the final conversion rate for Twitter spam.

The infrastructure used to host spam websites has also been a subject of interest. Anderson et al. explored the overlap in infrastructure and common hosting arrangements for spam campaigns [1]. Wang et al. focused on the redirection chains used by spammers to increase traffic through search engine optimization [24]. As we will show, redirection services play a role in spam on Twitter and are used in the majority of spam messages. However, the recent adoption of URL shortening services on Twitter changes the landscape of interest.

Twitter has recently been the focus of much research, but we are the first to examine spam and underground behaviors on the platform. The most relevant work by Kwak et al. examines the structure of social connections on Twitter and the propagation of trends [12], but does not address the thriving spam ecosystem. In addition to studying the social graph, recent work on social network spam uses machine learning to classify spam tweets [13], determine Twitter influence [2], and classify spam MySpace profiles [9].

While traditional email spam requires access to bulk lists of email addresses, social network spam requires the generation or subversion of user accounts with access to large groups of friends and social circles. Without these relationships, messages cannot be propagated. The challenge of a successful spam campaign on Twitter is twofold: obtaining enough accounts to carry out the campaign before they are suspended, and having enough fresh URLs to evade heuristic detection for repeatedly posting the same link. Before exploring the scope of spam activity on Twitter, we provide a brief overview of how Twitter operates and the features spammers can exploit.

### 2.1 Anatomy of a Twitter Spammer
A typical Twitter profile consists of three components: tweets, followers, and friends.

- **Tweets**: A tweet is a status update, limited to 140 characters. This restriction limits the amount of information spammers can embed in a single tweet and the text available for spam filtering. URL shortening services are commonly used to facilitate the posting of URLs, providing redirection from a short URL (around 20 characters) to an arbitrary URL.

- **Followers**: An account's followers are the users who receive the account's tweets. For spammers, the challenge is to build a large following, allowing them to advertise a single tweet to thousands of users. Users must subscribe as a follower to receive tweets; spammers cannot force their messages on other users.

- **Friends**: Relationships on Twitter are not bidirectional. Friends are the set of users an account subscribes to in order to receive their status updates. For spammers, having friends provides no benefit in generating traffic. However, spammers will befriend multiple victims in the hope that some will reciprocate, opening a channel for communication.

### 2.2 Twitter Features
In addition to the basic components of a Twitter profile, several features can be used to target specific users or reach a wider audience, including mentions, retweets, and hashtags.

- **Mentions (@username)**: To address a particular user, @username is included in a tweet, referencing the user directly. For users with public timelines, mentions appear in their timeline regardless of whether they follow the sender. This allows users to quickly identify tweets directed at them, though they are still broadcast to the sender's followers.

- **Retweets (RT @username)**: Retweets on Twitter are a form of attribution, where RT @username or via @username denote that the tweet originally appeared on another user's profile. Retweets build on the authority of another user and are used to increase the visibility of a tweet.

- **Hashtags (#topic)**: Hashtags allow tweets to be tagged with arbitrary topics. If enough users pick up on a topic, it will appear in the list of trending topics, allowing tweets to be syndicated to all of Twitter. Spammers can latch onto trending topics to inject unsolicited messages into the feed.

### 2.3 Presenting Tweets to Users
Each Twitter user is provided with a customized timeline of tweets generated from content posted by friends. When viewing a friend's message on the Twitter web page, a single tweet contains the tweet text, the friend's name and icon, the time posted, geolocation data, and the application used to post the tweet. If a link is posted, these attributes are the only information available for the user to decide whether to click the link. Simply visiting a website can lead to the installation of malware, making this a potentially dangerous situation.

## 3. Data Collection
Understanding spam behavior on Twitter requires a large-scale, real-time framework for detecting and tracking spam accounts. In this section, we describe the development of our Twitter monitoring infrastructure and the use of URL blacklists to identify spam. Our infrastructure focuses on analyzing the techniques employed by spammers to generate click traffic and attract an audience, as well as tracking the use of obfuscation and redirects to mask potentially suspicious web pages.

We monitor three categories of spam: malware, phishing, and scams. A spam URL is classified as malware if the page hosts malicious software or attempts to exploit a user's browser. Phishing pages include any website attempting to solicit a user's account credentials, many of which specifically target Twitter credentials. Scams are defined as any website advertising pharmaceuticals, software, adult content, and other solicitations.

### 3.1 Twitter Monitoring
To measure the pervasiveness of spam, we developed a Twitter monitoring framework that taps into Twitter's Streaming API and collects approximately seven million tweets per day over the course of one month. We collect data from two separate streams: one targets a random sample of Twitter activity, while the second specifically targets tweets containing URLs. The random sample is used to generate statistics about the fraction of URLs in tweets and general Twitter trends, while the URL stream is used for all other measurements.

Once a tweet appears in the URL stream, we isolate the associated URL and use a custom web crawler to follow the URL through HTTP status codes and META tag redirects until reaching the final landing page at a rate of roughly ten landing pages per second. JavaScript and Flash are not handled due to the volume of traffic and the complexity required to instrument these redirects. While crawling URLs, each redirect is logged, allowing us to analyze the frequency of cross-domain and local redirects and remove any URL obfuscation that masks the domain of the final landing page. We record the number of redirects and the URLs in each sequence.

### 3.2 Blacklist Detection
To automatically identify spam, we use blacklists to flag known spam URLs and domains. We regularly check every landing page's URL in our dataset against three blacklists: Google Safebrowsing, URIBL, and Joewein [6, 23, 25]. Each landing page must be rechecked multiple times since blacklists may be slow to update in response to new spam sites. URLs and domains blacklisted by Google indicate the presence of phishing or malware, while URIBL and Joewein specifically target domains present in spam email and are used by anti-spam software to classify email messages. Once a landing page is retroactively marked as spam, we analyze the associated spam tweets and users involved in the spam operation. We found that URIBL and Joewein include domains that are not exclusively hosting spam; we created a whitelist for popular domains that appear on these blacklists and verified that they primarily host non-spam content.

### 3.3 Data Summary
[Summary of the data collected and key findings would be added here.]