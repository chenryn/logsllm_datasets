title:Secure, Precise, and Fast Floating-Point Operations on x86 Processors
author:Ashay Rane and
Calvin Lin and
Mohit Tiwari
Secure, Precise, and Fast Floating-Point  
Operations on x86 Processors
Ashay Rane, Calvin Lin, and Mohit Tiwari, The University of Texas at Austin
 https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/rane
This paper is included in the Proceedings of the 25th USENIX Security SymposiumAugust 10–12, 2016 • Austin, TXISBN 978-1-931971-32-4Open access to the Proceedings of the 25th USENIX Security Symposium is sponsored by USENIX Secure, Precise, and Fast
Floating-Point Operations on x86 Processors
Ashay Rane, Calvin Lin
Department of Computer Science
The University of Texas at Austin
{ashay, lin} @cs.utexas.edu
Mohit Tiwari
Dept. of Electrical and Computer Engineering
The University of Texas at Austin
PI:EMAIL
Abstract
Floating-point computations introduce several side chan-
nels. This paper describes the ﬁrst solution that closes
these side channels while preserving the precision of
non-secure executions. Our solution exploits micro-
architectural features of the x86 architecture along with
novel compilation techniques to provide low overhead.
Because of the details of x86 execution, the evaluation
of ﬂoating-point side channel defenses is quite involved,
but we show that our solution is secure, precise, and fast.
Our solution closes more side channels than any prior so-
lution. Despite the added security, our solution does not
compromise on the precision of the ﬂoating-point oper-
ations. Finally, for a set of microkernels, our solution is
an order of magnitude more efﬁcient than the previous
solution.
1
Introduction
To secure our computer systems, considerable effort has
been devoted to techniques such as encryption, access
control, and information ﬂow analysis. Unfortunately,
these mechanisms can often be subverted through the use
of side channels, in which an adversary, with the knowl-
edge of the program, monitors the program’s execution
to infer secret values. These side channels are signiﬁ-
cant because they have been used to discover encryption
keys in AES [26], RSA [27], and the Difﬁe-Hellman key
exchange protocol [14], thereby rendering these sophis-
ticated schemes useless.
Numerous side channels exist, including instruction
and data caches [27, 26], branch predictors [2], mem-
ory usage [12, 35], execution time [31, 4], heat [22],
power [15], and electromagnetic radiation [9], but one
particularly insidious side channel arises from the exe-
cution of variable-latency ﬂoating-point instructions [3,
10], in which an instruction’s latency varies widely de-
pending on its operands, as shown in Table 1.
Zero Normal
7
11
Subnormal
153
Inﬁnity NaN
7
7
Table 1: Latency (in cycles) of the SQRTSS instruction for
various operands.
Both x861 and ARM2 provide variable-latency
ﬂoating-point instructions. This variable latency stems
from the desire to have graceful ﬂoating-point arithmetic
behavior, which, as we explain in Section 3, requires the
use of so-called subnormal values [8], which are pro-
cessed using special algorithms. Since subnormal values
are rare, hardware vendors typically support such values
in microcode, so as not to slow down the common case.
The resulting difference in instruction latency creates a
timing side channel, which has been used to infer cross-
origin data in browsers and to break differential privacy
guarantees of a remote database [3].
However, variable latency ﬂoating-point instructions
represent only a part of the problem, since higher level
ﬂoating-point operations, such as sine and cosine, are
typically implemented in software. Thus, the implemen-
tation of these ﬂoating-point operations can leak secret
information through other side channels as well. De-
pending on the secret values, programs can throw excep-
tions, thereby leaking the presence of abnormal inputs
through termination. Programs can also contain condi-
tional branches, which can leak secrets through the in-
struction pointer, branch predictor, or memory access
count. Finally, programs that index into lookup tables
can leak secrets through the memory address trace.
To prevent information leaks in both ﬂoating-point in-
structions and ﬂoating-point software, a strong solution
should ensure at least four key properties, which cor-
respond to the side channels that we discussed above:
1http://www.agner.org/optimize/instruction tables.pdf
2http://infocenter.arm.com/help/index.jsp?topic=/com.
arm.doc.ddi0344k/ch16s07s01.html
USENIX Association  
25th USENIX Security Symposium  71
(1) ﬁxed-time operations that are independent of secret
values, (2) disabled exceptions, (3) sequential control
ﬂow, and (4) uniform data accesses that are independent
of the value of secret variables. Previous solutions [3, 5]
are inadequate because they do not ensure all four prop-
erties, are slow, are orders of magnitude less precise, or
are difﬁcult to implement.
This paper presents a novel solution that closes side
channels arising from both hardware and software im-
plementations of ﬂoating point operations, providing all
four properties mentioned above. Our compiler-based
solution has two components.
The ﬁrst component creates building blocks of ele-
mentary ﬂoating-point operations for instructions that are
natively supported by the hardware (addition, subtrac-
tion, multiplication, division, square root, and type con-
version). Our solution leverages unused SIMD lanes so
that fast operations on normal operands are accompanied
by slower dummy computations on subnormal operands,
yielding a consistent yet low instruction latency for all
types of operands.
The second component is a software library of higher-
level ﬂoating-point operations like sine and cosine.
The key to creating this second component is a new
code transformation that produces ﬁxed-latency func-
tions through normalized control ﬂows and data access
patterns. Code generated by our compiler closes digital
side-channels, which have been deﬁned to be those side
channels that carry information over discrete bits [28].
Whereas previous work in closing digital side channels
employs a runtime system [28], our solution shifts much
of the work to compile time, yielding a signiﬁcantly
smaller runtime overhead.
This paper makes the following contributions:
1. We present a novel compiler-based system, called
Escort, for closing digital side channels that arise
from the processing of ﬂoating-point instructions.
2. Secure: We demonstrate that our solution is secure
not just against timing but also against digital side
channels. We demonstrate Escort’s capabilities by
defeating a machine-learning side-channel attack,
by defending against a timing attack on the Firefox
web browser, by conducting extensive performance
measurements on an x86 processor, and by verify-
ing our solution’s code using typing rules.
3. Precise: We show that Escort provides precision
that is identical to that of the standard C math li-
brary. By contrast, the previous solution’s precision
is off by several million ﬂoating-point values.
4. Fast: We show that our solution is fast. On a
set of micro-benchmarks that exercise elementary
ﬂoating-point operations, Escort is 16× faster than
the previous solution [3].
5. As an ancillary contribution, we introduce a
methodology for evaluating the precision and se-
curity of ﬂoating-point operations, which is fraught
with subtleties.
The rest of this paper is organized as follows. Sec-
tion 2 describes our threat model, related work, and sys-
tem guarantees. We provide background in Section 3 be-
fore presenting our solution in Section 4. We evaluate
our solution in Sections 5–7 . Finally, we conclude in
Section 8.
2 Threat Model and Related Work
This section begins by describing our threat model,
which shapes our subsequent discussion of related work
and of Escort’s security guarantees.
Threat Model. Our goal is to prevent secret ﬂoating-
point operands from leaking to untrusted principals that
either read digital signals from the processor’s pins or
that are co-resident processes.
We assume that the adversary is either an external en-
tity that monitors observation-based side channels (e.g.
time [14], memory address trace [11], or the /proc
pseudo-ﬁlesystem [12]) or a co-resident process/VM that
monitors contention-based side channels (e.g. cache [27]
or branch predictor state [2]).
For off-chip observation-based channels, we assume
that the processor resides in a sealed and tamper-proof
chip that prevents the adversary from measuring physi-
cal side channels like heat, power, electromagnetic radi-
ation, etc. We assume that the CPU encrypts data trans-
ferred to and from DRAM. All components other than
the processor are untrusted, and we assume that the ad-
versary can observe and tamper with any digital signal.
For on-chip contention-based channels, we assume that
the OS is trusted and does not leak the victim process’s
secret information. We also assume that the adversary
cannot observe or change the victim process’s register
contents. Our trusted computing base includes the com-
pilation toolchain.
Side-Channel Defenses. Decades of prior research
have produced numerous defenses against side channels,
the vast majority of which close only a limited number
of side channels with a single solution. For instance,
numerous solutions exist that close only the cache side
channel [6, 36, 39, 37, 16] or only the address-trace
side channel [33, 20, 32, 29]. Raccoon [28] is the ﬁrst
solution that closes a broad class of side channels—in
72  25th USENIX Security Symposium 
USENIX Association
particular, the set of digital side channels—with a sin-
gle solution. Similar to Raccoon, Escort also closes
digital side channels with a single solution, but unlike
Raccoon, Escort focuses on closing ﬂoating-point digi-
tal side channels, which can arise from variable latency
ﬂoating-point instructions and from software implemen-
tations of ﬂoating-point libraries, in which points-to set
sizes are typically small. Given Escort’s narrower focus
on ﬂoating-point computations, Escort is faster than Rac-
coon by an order of magnitude.
Timing Side-Channel Defenses. Prior
defenses
against timing side-channel attacks utilize new algo-
rithms [30], compilers [23], runtime systems [21], or
secure processors [18]. However, these solutions only
address one source of timing variations—either those
stem from the choice of the algorithm [31] or those
that stem from the microarchitectural design [10]. By
contrast, Escort closes timing variations from both
sources.
Floating-Point Side-Channel Defenses. Andrysco et
al. [3] present libfixedtimefixedpoint (FTFP), the
ﬁrst software solution for closing the ﬂoating-point tim-
ing channel. FTFP has some weaknesses, as we now
discuss, but the main contribution of their paper is the
demonstration of the signiﬁcance of this side channel,
as they use variable-latency ﬂoating-point operations to
break a browser’s same-origin policy and to break dif-
ferential privacy guarantees of remote databases. FTFP
is a ﬁxed-point library that consists of 19 hand-written
functions that each operates in ﬁxed time, independent
of its inputs. FTFP is slow, it is imprecise, and it ex-
poses secrets through other side channels, such as the
cache side channel or the address trace side channel.
Cleemput et al. [5] introduce compiler transformations
that convert variable-timing code into ﬁxed-timing code.
Their technique requires extensive manual intervention,
applies only to the division operation, and provides weak
security guarantees. Both solutions require manual con-
struction of ﬁxed-time code—a cumbersome process that
makes it difﬁcult to support a large number of operations.
By contrast, Escort implements a ﬁxed-time ﬂoating-
point library, while preventing information leaks through
timing as well as digital side channels. Escort includes a
compiler that we have used to automate the transforma-
tion of 112 ﬂoating-point functions in the Musl standard
C library, a POSIX-compliant C library. Escort also pro-
vides precision identical to the standard C library.
Escort’s Guarantees. Escort rejects programs that
contain unsupported features—I/O operations and recur-
sive function calls. Unlike prior work [18, 28], Escort
does transform loops that leak information through trip
counts. Escort is unable to handle programs contain-
ing irreducible control ﬂow graphs (CFGs), but standard
compiler transformations [24] can transform irreducible
CFGs into reducible CFGs. Escort assumes that the in-
put program does not use vector instructions, does not
exhibit undeﬁned behavior, does not terminate abnor-
mally through exceptions, and is free of race conditions.
Given a program that abides by these limitations, Es-
cort guarantees that the transformed code produces iden-
tical results as the original program, does not leak se-
crets through timing or digital side channels, and that the
transformed code does not terminate abnormally.
3 Background
The variable latency of ﬂoating-point instructions creates
security vulnerabilities. In this section, we explain sub-
normal numbers, which are the cause of the variable la-
tency, and we explain the difﬁculty of ﬁxing the resulting
vulnerability. We also explain how the Unit of Least Pre-
cision (ULP) can be used to quantify the precision of our
and competing solutions.
Next smallest
positive number
Next smallest
positive number
Large gap
10-38
0
. . .
Small gap
10-45
Smallest
positive
number
. . .
Equal gaps
   10-45
0
Smallest
positive
number
(a) Without subnormal values.
(b) With subnormal values.
Figure 1: Impact of allowing subnormal numbers. With-
out subnormal values, there exists a much larger gap be-
tween zero and the smallest positive number than be-
tween the ﬁrst two smallest positive numbers. With sub-
normal numbers, the values are more equally spaced.
(The ﬁgure is not drawn to scale.)
3.1 Subnormal Numbers
Subnormal numbers have tiny exponents, which result
in ﬂoating-point values that are extremely close to zero:
10−45 < |x| < 10−38 for single-precision numbers and
10−324 < |x| < 10−308 for double-precision numbers.
Subnormal values extend the range of ﬂoating-point
numbers that can be represented, but more importantly,
they enable gradual underﬂow—the property that as
ﬂoating-point numbers approach zero along the number
scale, the difference between successive ﬂoating-point
numbers does not increase3. Figures 1a and 1b show the
3https://www.cs.berkeley.edu/∼wkahan/ARITH 17U.pdf
USENIX Association  
25th USENIX Security Symposium  73
differences between zero and the two smallest positive
ﬂoating-point numbers. With subnormal numbers, the
gap between any two consecutive ﬂoating-point values is
never larger than the values themselves, thus exhibiting
Gradual Underﬂow. Subnormal numbers are indispens-
able because gradual underﬂow is required for reliable
equation solving and convergence acceleration [8, 13].
To avoid the added hardware complexity of supporting
subnormal numbers, which occur infrequently, vendors
typically process subnormal values in microcode, which
is orders of magnitude slower than hardwired logic.
The resulting difference in latencies creates a security
vulnerability. An adversary that can measure the latency
of a ﬂoating-point instruction can make reasonable esti-
mates about the operand type, potentially inferring secret
values using the timing channel. While subnormal values
occur infrequently in typical program execution, an ad-
versary can deliberately induce subnormal values in the
application’s inputs to enable subnormal operand timing
attacks.
3.2 Floating-Point Error Measurement
Unlike real (inﬁnite precision) numbers, ﬂoating-point
numbers use a limited number of bits to store values,