sent by the TCP connection from the server to the user, and ùëä is
the initial congestion window size in bytes [19, 35]. Although ùëä
is set by the server, Microsoft and a majority of web pages [66]
set this value to approximately 15 kB so we use this value. We
do not consider QUIC or persistent connections across pages in
detail here, but larger initial windows will result in fewer RTTs.
We test mostly landing pages, for which persistent connections
are uncommon. Moreover, such considerations likely would not
change our qualitative conclusions about how users experience
CDN latency.
We make the following assumptions to establish a lower bound
on ùëÅ : (1) we do not account for connections limited by the receive
window or the application, as the RTT-based congestion window
limitation we calculate is still a lower bound, (2) TCP is always in
slow start mode, which implies the window size doubles each RTT
and serves as a lower bound on the actual behavior of Microsoft‚Äôs
standard CUBIC implementation, and (3) all TCP and TLS hand-
shakes after the first do not incur additional RTTs (i.e., they are
executed in parallel to other requests).
Modern browsers can open many TCP connections in parallel,
to speed up page loads. Summing up RTTs across parallel connec-
tions could therefore drastically overestimate the number of RTTs
experienced users. To determine the connections over which to
accumulate RTTs, we first start by only considering the connec-
tion with the most data. We then iteratively add connections in
size-order (largest to smallest) that do not overlap temporally with
other connections for which we have accumulated RTTs. The ‚Äòdata
size‚Äô of a connection may represent one or more application-layer
objects.
We load nine web pages owned by Microsoft, twenty times for
each page. We choose popular pages hosted on Microsoft‚Äôs CDN
with dynamic content suggested to us by a CDN operator. We use
Selenium and Chrome to open web pages and use Tshark [24] to
capture TCP packets during the page load. When the browser‚Äôs
loadEventEnd event fires, the whole page has loaded, including
all dependent resources such as stylesheets and images [59]. So, to
calculate the total data size for each connection, we use the ACK
value in the last packet sent to the server before loadEventEnd
minus the SEQ value in the first packet received from the server.
We then calculate the number of RTTs using Equation (4), and add
a final two RTTs for TCP and TLS handshakes. We find only a few
percent of CDN web pages are loaded within 10 RTTs, and 90% of
all page loads are loaded within 20 RTTs, so 10 RTTs is a reasonable
lower bound.
D LATENCY MEASUREMENTS AT A
RECURSIVE RESOLVER
To obtain a local perspective of how users experience root DNS
latency, we use packet traces from ISI. Here, we characterize DNS
and root DNS latencies users experience at the resolver, along with
a useful visualization of how inconsequential root DNS latency is
for users at this resolver. This analysis complements our global
view of how users interact with the root DNS in Section 4.3, as it
demonstrates how often everyday users might send queries to the
root relative to other DNS queries.
Figure 12: CDF of user DNS query latencies seen at a recursive resolve
at ISI, over the course of one year. Latencies are measured from the
timestamp when the recursive resolver receives a client query to the
timestamp when the recursive sends a response to that client query.
The sub-millisecond latency for more than half of queries suggests
most queries to this recursive are served by the local cache.
Figure 12 shows the latencies of all queries seen at the recur-
sive resolver over one year, where latencies are measured from the
timestamp when the recursive resolver receives a client query to the
timestamp when the recursive sends a response to that client query.
Latencies are divided into (roughly) 3 regions: sub-millisecond la-
tency, low latency (millisecond - tens of milliseconds), and high
latency (hundreds of milliseconds). The first region corresponds to
cached queries, so roughly half of queries are (probably) cached.
The second region corresponds to DNS resolutions for which the
resolving server was geographically close. Finally, the third region
likely corresponds to queries that had to travel to distant servers,
or required a few rounds of recursion to fully resolve the domain.
10‚àí210‚àí1100101102103104105Latency (ms)0.00.20.40.60.81.0CDF of QueriesSIGCOMM ‚Äô21, August 23‚Äì27, 2021, Virtual Event, USA
Chrome. While loading web pages, we collect network packets on
port 53 using Tshark [24].
For these page loads, we observe 69,215 DNS A & AAAA-type
requests generated by the recursive resolver. 3,137 of these requests
are sent to root servers, and 2,950 of these root DNS queries are
redundant. Over 70% of redundant requests are AAAA-type. After
investigating the cause of these redundant queries, we find over 90%
of these redundant requests follow a similar pattern. This pattern
is illustrated by the example in Table 5.
In Table 5, we show queries the recursive resolver makes when
a user queries for the A record of bidder.criteo.com. In step 1, the
recursive resolver receives a DNS query from a client. According
to TTL heuristics, the COM A record is in the cache. In step 3, the
TLD server responds with records of authoritative nameservers for
‚Äúcriteo.com‚Äù. Then, the recursive chooses one of them to issue the
following request to. However, for some reason (e.g., packet loss),
the recursive resolver does not get a response from the nameserver
in step 4. Hence, the resolver uses another nameserver in step 5,
which it learned in step 3. At the same time, as seen in step 6 to
11, the recursive sends (redundant) DNS requests to root servers,
querying the AAAA-type records for these nameservers. These re-
quests are redundant since the AAAA record for COM was received
less than two days ago.
From the pattern demonstrated in Table 5, we hypothesize that
redundant requests to the root servers will be generated for certain
records when the following conditions are met.
(1) A query from the recursive resolver to an authoritative name-
server times-out.
(2) The record queried for by the resolver to the root DNS server
was not included in the Additional Records section of the
TLD‚Äôs response.
The second condition is also why we were seeing more AAAA-
type redundant requests, because usually there are more A-type
records in the Additional Records section than AAAA-type records.
To see how much traffic is caused by our hypothesis in a real
scenario, we analyze packet captures on a recursive resolver (BIND
9.11.17) serving users at ISI. To keep consistent with the other
analysis we do on this dataset (¬ß4), we use packet captures from
2018. 79.8% of requests to roots are redundant and in the pattern
we described. The other 20.2% consists of necessary requests and
requests for which we have no hypothesis as to how they were
generated. We contacted developers at BIND, who said this may be
a bug.
Software behavior as described here can lead to orders of magni-
tude more root DNS requests than would be necessary if recursives
queried for the record once per TTL. As demonstrated in Figure 3,
focusing on reducing the number of these queries could both im-
prove user experience and reduce load on the root server.
F VISUALIZATION OF MICROSOFT CDN
PERFORMANCE
In Section 2.2 we show the rings of a large anycast CDN and how
users are distributed with respect to those rings. This visualization
does not include any information about latency, so we provide one
here. In Figure 14 we show front-ends in R110, and associated la-
tency users experience to R110 in each region. Transparent circles
Figure 13: Root DNS latency for queries made by users of ISI recursive
resolver during 2018. This plot demonstrates the benefits of caching
and high TTLs of TLD records ‚Äì fewer than 1% of queries generate a
root request, and fewer than 0.1% incur latencies greater than 100 ms.
User queries that did not generate a query to a root server were given
a latency of 0.
The sub-millisecond latency for more than half of queries suggests
most queries to this recursive are served by the local cache. These
latencies are similar to those presented in previous work that also
studied a recursive resolver serving a small user population [18].
Queries in the second and third regions include queries that did
not query the root (since those records were cached) but did query
other parts of the DNS hierarchy.
As discussed in Section 4, root DNS queries make up a small
fraction of all queries shown in Figure 12. To visualize just how
small this fraction is, Figure 13 shows a CDF of root DNS latency
experienced for queries over 2018. Requests that do not generate
a query to a root server are counted as having a root latency of
0. Figure 13 demonstrates the benefits of shared caches and high
TTLs of TLD records ‚Äì fewer than 1% of queries generate a root
request, and fewer than 0.1% incur latencies greater than 100 ms.
E CASE STUDY: REDUNDANT ROOT DNS
QUERIES
When we investigate the traffic from a recursive resolver to the
root servers in Section 4, we see as many as 900 queries to the root
server in a day for the COM NS record. Given the 2 day TTL of
this record, this query frequency is unexpectedly large. This large
frequency motivated us to analyze why these requests to roots
occurred. We consider a request to the root to be redundant if a
query for the same record occurred less than 1 TTL ago. Prior work
has investigated redundant requests to root servers as well, and
our analysis can be considered complementary since we discover
different reasons for redundant requests [28].
To observe these redundant requests in a controlled environment,
we deploy a BIND instance (the resolver in Section 2.1 runs BIND
v9.11.17) locally and enable cache and recursion. We do not actually
look up the cache of the local BIND instance to see which records
are in it. Instead, we save the TTL of the record and the timestamp
at which we receive the record to know if the record should be in
BIND‚Äôs cache. We use BIND version 9.11.18 and 9.16.1. Because
9.16.1 is one of the newest releases and 9.11.18 is a release from
several years ago, we can assume that pathological behavior is
common in all versions between these two releases. After deploying
the instance, we simulate user behavior by opening the top-1000
web pages according to GTmetrix [33] using Selenium and headless
050100150200250300350Root DNS Latency (ms)0.00.90.990.9990.99990.999990.999999CDF of QueriesSIGCOMM ‚Äô21, August 23‚Äì27, 2021, Virtual Event, USA
Table 5: Redundant root DNS requests. The last five requests to J root are redundant which may be caused by an unanswered request in step 4.
Step Relative
Timestamp (second)
0.00000
1
2
0.01589
bidder.criteo.com A
bidder.criteo.com A
resolver
192.42.93.30 (g.gtld)
From
client
resolver
To
Query name
Query type Response
3
4
5
6
7
8
9
10
11
0.02366
0.02387
0.82473
0.82555
0.82563
0.82577
0.82584
0.82592
0.82620
192.42.93.30 (g.gtld)
resolver
bidder.criteo.com A
resolver
resolver
resolver
resolver
resolver
resolver
resolver
resolver
74.119.119.1 (ns25.criteo.com)
182.161.73.4 (ns28.criteo.com)
192.58.128.30 (j.root)
192.58.128.30 (j.root)
192.58.128.30 (j.root)
192.58.128.30 (j.root)
192.58.128.30 (j.root)
192.58.128.30 (j.root)
bidder.criteo.com A
bidder.criteo.com A
ns22.criteo.com
ns23.criteo.com
ns27.criteo.com
ns25.criteo.com
ns26.criteo.com
ns28.criteo.com
AAAA
AAAA
AAAA
AAAA
AAAA
AAAA
ns23.criteo.com ns22.criteo.com
ns25.criteo.com ns26.criteo.com
ns27.criteo.com ns28.criteo.com.
Figure 14: A visualization of front-ends in R110 (purple Xs), and user populations (transparent circles). User populations are colored according
to the relative latency they experience and have size proportional to user population. Red corresponds to high latency, and green corresponds
to low latency. Latency generally gets lower the closer users are to a front-end, and front-ends are concentrated around large user populations.
represent user populations and their radii are proportional to the
user population. Population circles are colored according to average
median latency users in the metro experience to R110 ‚Äì red indi-
cates higher latency while green indicates lower latency. Latency
generally gets lower the closer users are to a front-end. The CDN
has focused on deploying front-ends near large user populations,
which has driven latencies quite low for nearly all users.
0.00.20.40.60.81.0Latency (relative)