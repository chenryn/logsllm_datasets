names could be generated from the regular expression
(/|[a-zA-Z0-9])+, i.e., a series of alphanumeric
characters interspersed with path separators. The gen-
erating grammar for an attribute, however, is unknown,
and thus it is necessary to construct a reasonable approx-
imation for the true grammar. This is accomplished dur-
ing the learning phase by considering the observed at-
tribute values as the output of a probabilistic grammar,
which is a grammar that assigns probabilities to each of
its productions. The probabilistic grammar captures the
notion that some strings are more likely to be produced
than others, and should correspond to the set of exam-
ples gathered during the learning phase.
The construction of such a grammar is accomplished
by the application of the algorithm described in [17].
This algorithm ﬁrst constructs a nondeterministic ﬁnite
automaton (NFA) that exactly reﬂects the input data, and
then gradually merges states until a reasonable gener-
alization from the starting grammar is found, at which
point state merging terminates. The goal is to ﬁnd a mid-
dle ground between the over-simpliﬁed starting gram-
mar, which is only able to derive the learned input, and
an over-generalized grammar which is capable of pro-
ducing all possible strings (in which case all structural
information has been lost). The resulting NFA asso-
ciates probability values with each of the symbols emit-
ted and the transitions taken between states, with the
probability of a single path through the automaton be-
ing the product of those probabilities.
During the detection phase, the probability that an
observed attribute value has been generated from the
true generating grammar for that attribute is calculated
as the product of the probabilities for the symbols emit-
ted and transitions taken along a path through the NFA.
If no path is possible, the observed value cannot be de-
rived from the probabilistic grammar, and a probability
of 0 is returned.
4.4. Token Finder
The token ﬁnder model depends on the observation
that some attributes expect values drawn from a lim-
ited set of constants, such as ﬂags or indices. Thus, this
model detects when an attacker attempts to use these at-
tributes to pass values not contained in the legal set to the
application. During the learning phase, the set of unique
values for a given attribute are recorded. If the size of
this set grows proportionally to the total number of ob-
served instances of the attribute, the expected values for
the attribute are assumed to be random. Otherwise, the
model assumes that the attribute expects an enumeration
of values. During the detection phase, if the attribute has
been determined to accept an enumeration of values, ob-
served attribute values are tested for membership in the
set recorded during the learning phase. If the observed
value is present, then the model assumes that the value is
innocuous. Otherwise, the observed value is considered
anomalous.
5. Anomaly Generalization
Anomaly generalization is the process of transform-
ing the parameters of a detected anomaly into an ab-
stract model that will be used to match similar anoma-
lies, where the similarity metric is model-dependent.
More precisely, when one or more of the attribute val-
ues of a web request are detected as anomalous by one or
more models, the detection parameters for the attributes
and models involved are “relaxed” and composed in an
anomaly signature that identiﬁes possible variations of
an attack. For example, if the attribute itemid of the
purchase web application shown in Figure 1 is de-
tected as anomalous because of its character distribu-
tion, then the generalization process will create an ab-
stract model that matches character distributions for the
itemid attribute that are somewhat similar to the one
that triggered the anomaly.
Note that the generalization process and the genera-
tion of anomaly signatures is not driven by examples of
known attacks, but by the relaxation of the parameters
used by the anomaly models. Therefore, these anomaly
signatures are not derived from (or associated with) a
speciﬁc exploitation technique.
The following sections describe the details of how
our system generalizes anomalies detected by each of
the models discussed in Section 4, and how these gener-
alized anomaly signatures are used during the anomaly
aggregation phase.
5.1. Attribute Length
The attribute length model stores the approximate
length distribution of an attribute derived during the
learning phase as a sample mean µ and variance σ2.
When the length of a given attribute value is detected
as anomalous, the values of µ and σ2 for that attribute
are extracted from the model. These parameters are then
used to create an anomaly signature, which determines
whether lengths for the same attribute value are similarly
anomalous.
To this end, we introduce a similarity operator
ψattrlen (lobsv, lorig) where
ψattrlen ≡
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
σ2
(lobsv − µ)2 −
σ2
(lorig − µ)2
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
< dattr
This operator is adapted from the Chebyshev inequal-
ity test and is used during the anomaly aggregation phase
to determine whether the anomaly score of an observed
attribute length lobsv falls within some conﬁgurable dis-
tance dattr from the anomaly score of the anomalous
attribute length lorig that was originally used to generate
the anomaly signature.
5.2. Character Distribution
The character distribution model stores the ideal-
ized character distribution (ICD) of an application’s
attribute, and then, during the detection phase, it ap-
plies the Pearson χ2-test to determine the normality of
an attribute’s character distribution. If the distribution
is ﬂagged as anomalous, the parameters that are neces-
sary to create the generalized anomaly signature are ex-
tracted in one of two ways, depending on the nature of
the anomaly.
1. If the observed character distribution exhibits a
sharp drop-off, which indicates the dominance
of a small number of characters, a conﬁgurable
number of the character values that dominate
the distribution are used to construct the gener-
alized signature. More formally, the set C =
{(c1, f1) , (c2, f2) , . . . , (cm, fm)} is constructed,
where ci is the ith dominating character value, fi
is the corresponding relative frequency, and C is
the set of m dominating character values and fre-
quency pairs extracted from the model. During
the anomaly aggregation phase phase, the similar-
ity of an observed character distribution with re-
spect to the original anomalous character distribu-
tion is tested by analyzing the intersection between
Cobsv and Corig, where Cobsv is the set of domi-
nating characters from the observed attribute value
and Corig is the corresponding set from the original
anomalous value. If Cobsv ∩ Corig 6= ∅, we intro-
duce a similarity operator ψcdist (fobsv,i, forig,j)
where
ψcdist ≡ |fobsv,i − forig,j| < dcdist
and
(cobsv,i, fobsv,i) , (corig,j, forig,j) ∈ Cobsv ∩Corig,
cobsv,i = corig,j
Here, dcdist is a conﬁgurable distance threshold.
Thus, two dominating character sets are consid-
ered similar if at least one character value is present
in their intersection and the corresponding relative
frequencies are within a conﬁgurable distance from
each other.
2. If the character distribution of the anomalous at-
tribute is close to the uniform distribution, the sim-
ilarity operator becomes a test for a nearly random
character distribution. This is implemented by cal-
culating the maximum distance between any pair
of frequency values from the sets Cobsv and Corig,
and by testing whether this distance is less than a
conﬁgurable threshold d. Formally, ∀ 0 ≤ i, j ≤ m
ψcdist ≡ max (|fobsv,i − forig,j|) < dcdist
Note that these two different techniques are neces-
sary to accommodate common attacks (such as injection
of binary code and directory traversal attacks), which
manifest themselves as a character distribution anomaly
but with very different characteristics.
5.3. Structural Inference
The structural inference model uses the examples ob-
served in the training phase to construct a probabilistic
grammar that approximates the actual grammar for the
values of an application’s attribute.
If an attribute value observed during the detection
phase is determined to be anomalous by the model, the
generalization process extracts the preﬁx of the violat-
ing string up to and including the ﬁrst character that vi-
olates the attribute’s grammar. The use of the offending
string’s preﬁx as a base for generalizing the attack is mo-
tivated by the observation that repeated attacks against
the same web application often exhibit similar preﬁxes
in the URLs or paths used as values in that attribute of
the application.
The preﬁx string is translated into a string of char-
acter classes. More precisely, all lowercase alphabetic
characters are mapped into “a,” all uppercase alphabetic
characters are mapped into “A,” all numeric characters
map to “0,” and all other characters remain unchanged.
Then, to test the similarity of a subsequent observed
value with respect to the translated anomalous string,
called sorig, a similar translation is performed on the ob-
served value, which becomes sobsv. The two normalized
values are then compared for equality. Formally, we in-
troduce the similarity operator ψstructure (sobsv, sorig)
such that ∀ 0 ≤ i ≤ m where m = |sorig|,
ψstructure (sobsv, sorig) ≡ sobsv,i = sorig,i
For example, consider the value of the attribute
In this case,
itemid in the last line of Figure 1.
the structural inference model detects a violation in the
structure of the attribute value because, during the train-
ing phase, the model learned that an item identiﬁer is
composed of alphanumeric characters only. Therefore,
the generalization process creates an anomaly signature
based on the grammar [a|0]+;, because the charac-
ter “;” is the ﬁrst character that violated the attribute
grammar derived during the training phase. Further at-
tempts to use the “;” character to perform an attack will
be classiﬁed as similar anomalies.
5.4. Token Finder
During the detection phase, the token ﬁnder tests an
observed attribute value lorig for membership in the set
T , where T is the set of tokens recorded during the learn-
ing phase for that attribute (if the set of all values for that
attribute was determined to be an enumeration).
During the detection phase, if the token ﬁnder model
determines that an attribute value is anomalous, the set
of allowable values T for that attribute is extracted from
the model. Then, during the aggregation phase, a subse-
quent observed attribute value lobsv is detected as simi-
lar to the original anomalous value lorig, if the observed
value is not a member of the enumeration T and it is lex-
icographically similar to the original anomalous value.
Formally, given a function lex that determines lexi-
cographic similarity, we introduce the similarity opera-
tor ψtoken (lobsv) where
ψtoken ≡ lex(lorig, lobsv)
Note that the function lex can be tuned to achieve
different levels of sensitivity to variations in the values
of anomalous tokens. For instance, lex may use Ham-
ming or Levenshtein distances to determine string equal-
ity. Additionally, type inference may be performed on
the collection and an appropriate lex function selected.
In the degenerate case, lex always returns true and the
resulting anomaly signature would simply group anoma-
lies that represent attribute values not contained in the
original enumeration.
In the current implementation,
however, lex is a simple string equality test.
For example, in the web application shown in Fig-
ure 1, the cc attribute always has values drawn from the
set of credit card types {mastercard, visa, amex}.
If an exploit uses an anomalous value for this attribute,
the corresponding anomaly signature will identify iden-
tical violations of the attribute value.
6. Attack Class Inference
Anomaly detection is able to detect unknown attacks
but it is not able to provide a concrete explanation of
what the attack represents with respect to the target ap-
plication. This is a general limitation of anomaly de-
tection approaches and often confuses system adminis-
trators when they have to analyze alerts that state only
that some attribute of a web request did not match one
or more of the previously established proﬁles. We ob-
served that certain well-known classes of attacks violate
anomaly models in a consistent way. Therefore, when-
ever such violations are detected, heuristics can be used
to attempt to infer the type of an attack and provide use-
ful hints to the system administrator.
Our system includes an attack class inference compo-
nent that utilizes ad hoc heuristics to determine the class
of an attack when certain types of anomalies are de-
tected. The selection of which heuristics to apply as well
as how each is applied is inﬂuenced by the type and pa-
rameters of the anomaly detected. Our system currently
incorporates heuristics for four major classes of web-
based attacks: directory traversals, cross-site scripting,
SQL injection, and buffer overﬂows.
As noted in Section 1, the attack class inference pro-
cess is different from the matching of “traditional” intru-
sion detection signatures (e.g., a Snort signature that de-
tects buffer overﬂow attacks). The reason is that the at-
tack class inference process is applied only to attributes
that have already been identiﬁed as anomalous, while
“traditional” signatures are applied to the entire event
being analyzed. As a consequence, the attack class in-
ference technique can be more abstract (and less precise)
without incurring the risk of classifying benign portions
of an event as malicious. Note that the attack class in-
ference is performed in addition to (and independent of)
the derivation of a generalized anomaly signature, and
does not always produce a valid classiﬁcation.
In the following, we describe how attack classes are
identiﬁed for the four classes of attacks currently sup-
ported.
6.1. Directory Traversal
Directory traversal attacks are essentially attempts to
gain unauthorized access to ﬁles that are not intended
to be accessed by a web application or web server by
traversing across the directory tree using .. and / es-
capes. These attacks are somewhat unique in that a
small set of characters is involved in their execution,
namely “.” and “/”. Accordingly, the heuristics for
detecting directory traversals are only activated if either
the character distribution returns a dominating charac-
ter set C where C ∩ {., /} 6= ∅, or if the structural in-
ference model returns a violating character-compressed
string with a ﬁnal underivable character of “.” or “/.”
To infer the presence of a directory traversal attack, the
heuristic scans the anomalous attribute value for a sub-
string derivable by the regular grammar represented by
(/|\.\.)+.
For example, suppose that the purchase web ap-
plication of Figure 1 is invoked with an itemid
value of “cat ../../../../../etc/shadow”.
In this case, the character distribution model identiﬁes
an anomalous number of “.” and “/” characters, and,
in addition, the structural model detects a violation of
the attribute structure. As a consequence, the direc-
tory traversal attack class inference heuristics are ap-
plied to the anomalous attribute value. The heuristics
determine that the attribute matches the regular expres-
sion (/|\.\.)+, and the attack is identiﬁed as a direc-
tory traversal attack.
This information is added to the generalized sig-
nature associated with the anomalous event, and this
anomalous event, as well as further similar anomalous
events, are presented to the system administrator as a
group of anomalies labeled as directory traversal attacks.
6.2. Cross-site Scripting
Cross-site scripting attacks allow a malicious user
to execute arbitrary code on a client-side machine by
injecting malicious code, such as a JavaScript script,
into a web document (e.g., storing JavaScript code in
a database ﬁeld) such that the code is unwittingly served
to other clients. These attacks generally consist of frag-
ments of client-side browser scripting languages. Be-
cause of the insertion of speciﬁc HTML tags and the use
of code-like content, this type of attack often results in a
violation of the structural inference, character distribu-
tion, and token ﬁnder models.
Consequently, the cross-site scripting heuristics are
applied to an anomalous attribute value if any of these
models are involved in the initial detection step. The
heuristics currently used for this class include a set of
scans for common syntactic elements of the JavaScript
language or HTML fragments (e.g., script or left or
right angle brackets used to delimit HTML tags).
6.3. SQL Injection
SQL injection attacks consist of unauthorized mod-
iﬁcations to SQL queries, usually by escaping an input
to a query parameter that allows the attacker to execute
arbitrary SQL commands. Because of the insertion of
these escape characters, SQL injection attacks generally
result in the violation of the structure of an attribute.
Thus, the heuristics speciﬁc to SQL injection are
activated if the structural inference model detects an
anomaly. The heuristics themselves perform a set of
scans over the attribute value for common SQL lan-
guage keywords and syntactic elements (e.g., SELECT,
INSERT, UPDATE, DELETE, ’, or --).
6.4. Buﬀer Overﬂows
Buffer overﬂow attacks, which encompass attacks
such as stack smashing, heap smashing, data modiﬁ-
cation, and others, typically involve sending a large
amount of data that overﬂows the allocated buffer, al-
lowing the attacker to overwrite return addresses, data or
function pointers, or otherwise overwrite sensitive vari-
ables with attacker-controlled data. Buffer overﬂow at-
tacks against web applications typically manifest them-
selves as attribute values that deviate dramatically from
established proﬁles of normalcy. Thus, the heuristics for
inferring the presence of a buffer overﬂow attack will
be activated if any of the character distribution, struc-
tural inference, or attribute length models report an at-
tribute as anomalous. The heuristics in the current sys-
tem perform a simple scan over the attribute string for
binary values (i.e., ASCII values greater than 0x80),
which are typical of basic buffer overﬂow attacks. More
sophisticated classiﬁcation techniques could be substi-