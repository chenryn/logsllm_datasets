title:AntiFuzz: Impeding Fuzzing Audits of Binary Executables
author:Emre G&quot;uler and
Cornelius Aschermann and
Ali Abbasi and
Thorsten Holz
AntiFuzz: Impeding Fuzzing Audits of 
Binary Executables
Emre Güler, Cornelius Aschermann, Ali Abbasi, and Thorsten Holz, 
Ruhr-Universität Bochum
https://www.usenix.org/conference/usenixsecurity19/presentation/guler
This paper is included in the Proceedings of the 28th USENIX Security Symposium.August 14–16, 2019 • Santa Clara, CA, USA978-1-939133-06-9Open access to the Proceedings of the 28th USENIX Security Symposium is sponsored by USENIX.ANTIFUZZ: Impeding Fuzzing Audits of Binary Executables
Emre Güler, Cornelius Aschermann, Ali Abbasi, and Thorsten Holz
Ruhr-Universität Bochum
Abstract
A general defense strategy in computer security is to increase
the cost of successful attacks in both computational resources
as well as human time. In the area of binary security, this is
commonly done by using obfuscation methods to hinder re-
verse engineering and the search for software vulnerabilities.
However, recent trends in automated bug ﬁnding changed the
modus operandi. Nowadays it is very common for bugs to
be found by various fuzzing tools. Due to ever-increasing
amounts of automation and research on better fuzzing strate-
gies, large-scale, dragnet-style fuzzing of many hundreds of
targets becomes viable. As we show, current obfuscation tech-
niques are aimed at increasing the cost of human understand-
ing and do little to slow down fuzzing.
In this paper, we introduce several techniques to protect
a binary executable against an analysis with automated bug
ﬁnding approaches that are based on fuzzing, symbolic/con-
colic execution, and taint-assisted fuzzing (commonly known
as hybrid fuzzing). More speciﬁcally, we perform a system-
atic analysis of the fundamental assumptions of bug ﬁnding
tools and develop general countermeasures for each assump-
tion. Note that these techniques are not designed to target
speciﬁc implementations of fuzzing tools, but address gen-
eral assumptions that bug ﬁnding tools necessarily depend on.
Our evaluation demonstrates that these techniques effectively
impede fuzzing audits, while introducing a negligible per-
formance overhead. Just as obfuscation techniques increase
the amount of human labor needed to ﬁnd a vulnerability,
our techniques render automated fuzzing-based approaches
futile.
1 Introduction
In recent years, fuzzing has proven a highly successful tech-
nique to uncover bugs in software in an automated way. In-
spired by the large number of bugs found by fuzzers such as
AFL [56], research recently focused heavily on improving
the state-of-the-art in fuzzing techniques [10, 11, 22, 44, 54].
Previously, it was paramount to manually remove checksums
and similar roadblocks from the fuzzing targets. Addition-
ally, fuzzers typically required large, exhaustive seed cor-
pora or a precise description of the input format in form of a
grammar. In a push towards a greater degree of automation,
research recently focused on avoiding these common road-
blocks [14, 39, 44, 45, 48, 54]. This push toward automation
greatly simpliﬁes the usage of these tools. One can argue that,
for the attacker, using a fuzzer is as easy as it is for the de-
fender. In fact, recently the Fuzzing Ex Machina (FExM) [49]
project managed to reduce the overhead of running fuzzers to
a degree where they managed to fuzz the top 500 packages
from the Arch Linux User Repository with no manual effort
in seed selection or similar issues. This two day effort yielded
crashes in 29 of the most popular packages of Arch Linux. It
stands to reason that this kind of indiscriminate, dragnet-style
searching for software bugs will become more prevalent in
the future.
While the developers of a software system should typi-
cally thoroughly fuzz test every type of software, in practice
they may want to maintain an asymmetric cost advantage.
More speciﬁcally, it should be easier for the maintainers of
a software project to fuzz their own software than for at-
tackers. This can be achieved by adding mechanisms to the
software such that the ﬁnal binary executable is protected
against fuzzing: the maintainers can then build an internal
version that can be tested thoroughly, while an attacker can
only access the protected binary which prohibits automated
tests. In the past, similar asymmetric advantages in analysis
and bug ﬁnding were introduced by obfuscation techniques.
As we demonstrate, even very high levels of obfuscation will
typically result only in a meager slowdown of current fuzzing
techniques. This is due to the fact that obfuscation typically
aims at protecting against program understanding and formal
reasoning. On the other hand, fuzzers typically do not perform
a signiﬁcant amount of reasoning over the behaviour of the
program. On the downside, these heavy obfuscation mech-
anisms will often incur a signiﬁcant runtime overhead [19].
USENIX Association
28th USENIX Security Symposium    1931
How software can be protected against fuzzing in an efﬁcient
and effective way is an open problem.
In this paper, we tackle this challenge and present several
general methods to impede large scale, automated fuzzing au-
dit of binary executables. We present several techniques that
can be added during the compilation phase of a given software
project such that the resulting binary executable withstands
fuzzing and signiﬁcantly hampers automated analysis. Our
methods are based on a systematic analysis of 19 current
bug ﬁnding tools with respect to their underlying assump-
tions. Note that we use the terms “fuzzer” and “bug ﬁnding
tool” interchangeably to describe all kinds of tools that are
analyzing programs to produce crashing inputs as opposed
to static analysis tools and linters. We ﬁnd that all of them
rely on at least one of the following four basic assumptions:
(i) coverage yields relevant feedback, (ii) crashes can be de-
tected, (iii) many executions per second are achievable, and
(iv) constraints are solvable with symbolic execution. Based
on these insights, we develop fuzzing countermeasures and
implement a lightweight protection scheme in the form of a
conﬁgurable, auto-generated single C header ﬁle that devel-
opers can add to their application to impede fuzzers. For the
evaluated programs, we had to change on average 29 lines of
code, which took less than ten minutes. With these changes,
attackers now need to spend a signiﬁcant amount of time
to manually remove these anti-fuzzing mechanisms from a
protected binary executable (typically magniﬁed by common
obfuscation techniques on top), greatly increasing the cost
of ﬁnding bugs as an attacker. Defenders, on the other hand,
can still trivially fuzz the unmodiﬁed version of their software
with no additional cost. Thus, only unwanted and unknown
attackers are at a disadvantage.
We implemented a prototype of the proposed methods in
a tool called ANTIFUZZ. We demonstrate in several exper-
iments the effectiveness of our approach by showing that
state-of-the-art fuzzers cannot ﬁnd bugs in binary executables
protected with ANTIFUZZ anymore. Moreover, we ﬁnd that
our approach introduces no observable, statistically signiﬁcant
performance overhead in the SPEC benchmark suite.
Contributions
lowing contributions:
In summary, in this paper we make the fol-
• We present a survey of techniques employed by current
fuzzers and systematically analyze the basic assumptions
they make. We ﬁnd that different fuzzing approaches rely
on at least one of the fundamental assumptions which
we identify.
• We demonstrate how small changes to a program nul-
lify the main advantages of fuzzing by systematically
violating the fundamental prerequisites. As a result, it
becomes signiﬁcantly harder (if not impossible with cur-
rent approaches) to ﬁnd bugs in a protected program
without manual removal of our anti-fuzzing methods.
• We implemented our anti-fuzzing techniques in a tool
called ANTIFUZZ that adds fuzzing countermeasures
during the compilation phase. Our evaluation with sev-
eral different programs shows that with a negligible per-
formance overhead, ANTIFUZZ hardens a target binary
executable such that none of the tested fuzzers are able
to ﬁnd any bugs.
To foster research on this topic, we release our implemen-
tation and the data sets used as part of the evaluation at
https://github.com/RUB-SysSec/antifuzz.
2 Technical Background
Fuzzing (formerly known as random testing) has been around
since at least 1981 [20]. In the beginning, fuzzers would
simply try to execute programs with random inputs. While
executing, the fuzzer observes the behavior of the program
under test: if the program crashes, the fuzzer managed to
ﬁnd a bug and the input is stored for further evaluation. Even
though this technique is surprisingly simple—particularly
when compared to static program analysis techniques—with a
sufﬁcient number of executions per second it has been helpful
at ﬁnding bugs in complex, real-world software in the past.
In recent years, the computer security community paid
much more attention to improving the performance and scal-
ability of fuzzing. For example, the OSS-FUZZ project has
been fuzzing many highly-relevant pieces of software 24/7
since 2016 and exposed thousands of bugs [1]. FEXM autom-
atized large parts of the setup and the authors were able to
fuzz the top 500 packages from the Arch Linux User Repos-
itory [49]. To improve the usability of fuzzers in such sce-
narios, the biggest focus of the research community is to
automatically overcome hard-to-fuzz code constructs that pre-
vious methods could not successfully solve with the goal
of reaching deeper parts of the code. Particularly, common
program analysis techniques were applied to the problem
of fuzzing. For example, symbolic execution and its some-
what more scalable derivative concolic execution was used
to overcome hard branches and trigger bugs that are only
trigger-able by rare conditions [25–27, 31, 42, 48, 50, 54].
Other fuzzers use taint tracing to reduce the search space
to mutations that actually inﬂuence interesting parts of the
program [14,23,31,42,45]. A complementary line of work fo-
cused on improving the fuzzing process itself without falling
back to (often costly) program analysis techniques. Many
techniques propose improvements to the way AFL instru-
ments the target [2, 22, 29, 47], or how inputs are scheduled
and mutated [10, 11, 13, 46, 52]. Some methods go as far as
removing hard parts from the target [44, 50]. Lastly, the ef-
fectiveness of machine learning models for efﬁcient input
generation was evaluated [9, 28, 32].
Generally speaking, existing methods for fuzzing can be
categorized into the following three different categories based
1932    28th USENIX Security Symposium
USENIX Association
on the techniques employed, which we explain in more detail
in the following.
2.1 Blind Fuzzers
The oldest class of fuzzers are so-called blind fuzzers. Such
fuzzers have to overcome the problem that random inputs
will not exercise any interesting code within a given software.
Two approaches were commonly applied: mutational fuzzing
and generational fuzzing.
Mutational fuzzers require a good corpus of inputs to mu-
tate. Generally, mutational fuzzers do not know which code re-
gions depend on the input ﬁle and which inputs are necessary
to reach more code regions. Instead, these fuzzers introduce
some random mutations to the ﬁle and can only detect if the
program has crashed or not. Mutational fuzzers need seed ﬁles
that cover large parts of interesting code as they are unable to
uncover new code effectively. In the past, these fuzzers were
quite successful at uncovering bugs [33]. However, they typi-
cally need to perform a large number of executions per second
to work properly. An example of mutational-only fuzzers are
ZZUF [5] and RADAMSA [33].
The second approach is generational fuzzing: fuzzers which
employ this technique need a formal speciﬁcation to deﬁne
the input format. Based on this speciﬁcation, the fuzzer is able
to produce many semi-valid inputs. This has the advantage
that the fuzzer does not need to learn how to generate well-
formed input ﬁles. However, manual human effort is necessary
to create these deﬁnitions (e.g., a grammar that describes
the input format). This task becomes hard for complex or
unknown formats and the speciﬁcation could still end up
lacking certain features. The additional need for a formal
speciﬁcation makes this approach much less useful for large-
scale bug hunting with little human interaction. An example
of a generational fuzzer is PEACH [3].
In summary, the only thing a blind fuzzer is able to observe
is whether its input led to a crash of the program or not. There-
fore, these techniques have no indicator of their progress in
exploring the programs state space and thus (especially in the
case of mutational fuzzers), they are mostly limited to simple
bugs even with non-empty and well-formed seed ﬁles.
2.2 Coverage-guided Fuzzers
To improve the performance of the mutational fuzzers, Za-
lewski introduced an efﬁcient way to measure coverage-
feedback of an application [56]. This led to a signiﬁcant
amount of research on coverage-guided fuzzers. These fuzzers
typically use a feedback mechanism to receive information on
how an input has affected the program under test. The key idea
here is that this mechanism gives means by which to judge an
input: Which (new) code regions were visited and how often?
In contrast, a blind fuzzer introduces random mutations to the
input without knowing how those mutations affect the pro-
gram. It effectively relies on pure chance for ﬁnding crashing
inputs, while a coverage-guided fuzzer could mutate the same
input ﬁle iteratively to increase the code coverage and thus get
closer to new regions where a crash could happen. Examples
of coverage-based fuzzers are AFL [56], HONGGFUZZ [4],
ANGORA [14], T-FUZZ [44], KAFL [47], REDQUEEN [8]
and VUZZER [45]. These fuzzers use multiple ways to obtain
coverage feedback:
Static Instrumentation: One of the fastest methods for
obtaining code coverage is static compile time coverage
(widely used by tools such as AFL, ANGORA, LIBFUZZER,
and HONGGFUZZ). In this case, the compiler adds special
code at the start of each basic block that stores the coverage
information. From a defender’s point of view, this kind of in-
strumentation is not relevant, as we assume that the attackers
do not have access to the source code.
Dynamic Binary Instrumentation (DBI): If only a bi-
nary executable is available, fuzzer typically use dynamic
binary instrumentation (DBI) to obtain coverage information.
This is done by adding the relevant code at runtime. Examples
of this approach are VUZZER and STEELIX [39], which both
use PIN-based [40] instrumentation, and AFL which has mul-
tiple forks using QEMU, PIN, DYNAMORIO, or DYNINST
for DBI. Fuzzers like DRILLER [48] and T-FUZZ use AFL
under the hood and typically rely on the QEMU-based instru-
mentation.
Hardware Supported Tracing: Modern CPUs support
various forms of hardware tracing. For Intel processors, two
technologies can be used: Last Branch Record and Intel-PT.
HONGGFUZZ is able to utilize both techniques, while fuzzers
like KAFL only support Intel-PT.
2.2.1 Using Coverage Information:
Different fuzzers tend to use the coverage feedback obtained
in different ways. To illustrate these differences, we select
two well-known coverage-guided fuzzers; namely AFL and
VUZZER. We then describe how these fuzzers are using cover-
age information internally. It is worth noting that by choosing
AFL, we are basically covering the way various other fuzzers
such as T-FUZZ, ANGORA, KAFL, STEELIX, DRILLER, LIB-
FUZZER, WINAFL, AFLFAST [11], and COLLAFL [22]
are using coverage information. All of these fuzzers (except
ANGORA) use the same underlying technique for leveraging
coverage information. In contrast to AFL, no other fuzzer
followed the path of VUZZER in coverage information usage.
However, due to the unique usage of coverage information in
VUZZER, we describe it as well.
AFL A key factor behind the success of AFL is an efﬁ-
cient, approximate representation of the code coverage. To
reduce the memory footprint, AFL maps each basic block
transition (edge) to one index in a ﬁxed size array referred
to as the “bitmap”. Upon encountering a basic block transi-
USENIX Association
28th USENIX Security Symposium    1933
and AFL. Unlike AFL, VUZZER extracts the exact basic
block coverage (instead of the bitmap) and enriches the feed-
back mechanism with additional data. For example, VUZZER