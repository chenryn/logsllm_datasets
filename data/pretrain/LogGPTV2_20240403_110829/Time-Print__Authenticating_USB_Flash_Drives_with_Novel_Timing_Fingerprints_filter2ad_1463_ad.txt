We ﬁrst examine the accuracy for identifying a random
(unknown) USB device of a brand different from approved
devices. For instance, a system administrator would like to
prevent a dropped device attack where a careless employee
plugs in a malicious unauthorized device. While Figure 2 (in
Section 2) shows that this timing-based ﬁngerprint has the
potential to be very effective, here we quantitatively evaluate
all devices listed in Table I.
Approach. To accomplish this task, we expect that Time-
Print trained on a speciﬁc device should always accept that
device while rejecting all other devices with different models
and brands. Thus, we design a single-class classiﬁcation system
using the K-Means algorithm. The one class classiﬁcation
system creates clusters of samples from the approved device
and draws a decision boundary to reject any readings from
devices of other brands or models.
Particularly, K-Means requires that each data sample is
presented as a 1D feature list. K-Means utilizes this feature
list and a distance metric to calculate a sample to sample
distance by examining the features of each sample, and groups
the samples into clusters. Once the algorithm converges, we
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:34:15 UTC from IEEE Xplore.  Restrictions apply. 
1009
Training Devices
Generic
SanDisk
Cruzer Blade
Samsung
Bar Plus
SanDisk
Ultra
Overall, these results show that Time-Print can accurately
distinguish unknown devices with different brands and models
from legitimate devices.
s
e
c
i
v
e
D
g
n
i
t
s
e
T
Generic
SanDisk
Cruzer Blade
Samsung
Bar Plus
SanDisk
Ultra
Other USB2
Other USB3
99.9%
0.0
0.0
0.0
0.0
0.0
0.0
98.8%
0.0
0.0
0.0
0.0
0.0
0.0
99.7%
0.0
0.0
0.0
0.0
0.0
0.0
99.9%
0.0
0.0
TABLE II: Percentage of samples accepted when trained for
each device model.
calculate the distance of each training sample to its closest
cluster. The maximum distance value is then used to set a
decision boundary. In our case, for a ﬁngerprint to be accepted
by the clustering algorithm, it must be within the decision
boundary of one of the pre-trained clusters. We ﬁrst preprocess
each sample into different chunks by separating each reading
based on the size and location offset of the measurement.
With the size and locations grouped, we calculate the mean of
each group, generating a 1D feature list for each sample, as
illustrated in the upper part of Figure 5.
Training and testing. We train our one-class classiﬁer on
four types of devices: (1) the Generic Drives (10 devices),
Samsung Bar Plus (4 devices), SanDisk Ultra (10 devices),
and SanDisk Cruzer Blade devices (10 devices). We then test
the classiﬁer against all other devices listed in Table I. For
clarity of presenting the results, we group all extra devices
with the USB 3.X protocol into a set called ‘other USB3’, and
all extra devices with the USB 2.0 protocol into a set called
‘other USB2’.
For example, to test the accuracy for the Generic Drives,
we have four sessions (80 ﬁngerprints in total) of data for all
ten devices in this model. For Generic Drive #1, we train the
classiﬁer using three sessions of data and test the classiﬁer
using the remaining one session of data, and the data from
all other devices from different brands/models. We repeat the
experiment for each Generic device and report the average
accuracy.
Accuracy. The results are presented in Table II, showing
very high accuracy: an average true accept rate of 99.5% while
rejecting all drives of different models and brands (i.e., zero
false accept rate). As mentioned in the threat model, Time-Print
is mainly designed for use in a high-security system. Such
a system should always reject unknown models to minimize
security risks. While the true accept rate of 99.5% may still
reject a legitimate device, with a very small chance, for the
ﬁrst trial, the user can simply re-plugin the USB drive and
re-authenticate with the system. The probability of being
rejected twice in a row is only 0.0025%. In other words, the
probability of a legitimate device being accepted after two
trials is 99.9975%, which is very close to one.
B. Scenario ❷: Same Brand Device Identiﬁcation
The second scenario requires Time-Print to identify unseen
devices of the same brand and model, which is a much more
difﬁcult task as all devices share the same design.
Approach. To this end, we utilize a 2-D convolutional
neural network for the classiﬁcation task. As our task is not
to locate the best possible network for classiﬁcation but to
demonstrate that ﬁngerprinting a USB mass storage device is
possible, we adopt a standard classiﬁcation network design.
For reference, our network architecture is provided in Table VI
in the Appendix.
For preprocessing, similarly to Scenario ❶, we separate the
raw timing information by size and location. As the script
contains six possible locations and three possible sizes, the
separation procedure produces 18 distinct collections of timing
data for each ﬁngerprint gathered.
To utilize these values within a neural network, we transform
their raw format (a collection of numbers ranging from one to
ten million) to a value range that works for neural networks
(e.g. 0 to 1). Especially, we convert the data from each group
to a histogram, with all data being scaled by the group global
minimum and maximum values, from the entire training set.
Such a method creates a ﬁne-grained representation of the
signal. This also makes sense as large reads take much longer
to complete than short reads, and a full ranged histogram would
contain a large amount of unimportant zero values. To ensure
experimental integrity, the individual minimum and maximum
ranges are recorded and used to process the testing set.
Each histogram can be represented as a 1D vector of
measurement frequency, and the histograms for all groups
can be concatenated together to create a 2D input vector to the
classiﬁcation network. This process is illustrated in the lower
part of Figure 5. Another advantage of the histogram and neural
network combination is that the network can rapidly be tuned
to work for different drives, since the number of histogram
bins, readings per size and location, or input trace can easily be
adjusted while maintaining a consistent preprocessing pipeline.
Training and testing. To achieve accurate identiﬁcation,
system administrators can purchase multiple devices from
the same brand and model to serve as ‘malicious’ devices
to train the classiﬁer. We emulate this scenario by examining
the SanDisk Cruzer Blade, SanDisk Ultra, and the Generic
drives. We have 10 devices for each model. Among the 10
devices, for training, one device is selected as the ‘legitimate’
drive, and 8 of the remaining 9 devices are chosen as ‘malicious’
drives; then the last is used as the ‘unseen’3 device for testing
purposes. During training, we use 60 samples of each drive
involved. During testing, we utilize the remaining 20 samples of
each ‘legitimate’ drive and 20 samples of each ‘unseen’ drive.
3The ‘unseen’ device is equivalent to an attacker’s ‘malicious’ device, and
we use a different term to differentiate the malicious device in testing from
those used in training.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:34:15 UTC from IEEE Xplore.  Restrictions apply. 
1010
Generic
TAR
TRR
SanDisk
Cruzer Blade
TAR
TRR
SanDisk
Ultra
TAR
TRR
Raw
92.2% 93.8% 96.5% 89.2% 97.6% 90.6%
Augment
97.3% 91.7% 98.0% 93.5% 98.7% 91.4%
Device Name (# of Devices)
Classiﬁcation Accuracy
SanDisk Cruzer Blade (10)
Generic Drive (10)
SanDisk Ultra (10)
Samsung Bar Plus (4)
98.6%
99.1%
98.7%
98.4%
TABLE III: Average True Accept Rate (TAR) and True Reject
Rate (TRR) for same model device identiﬁcation.
TABLE IV: Classiﬁcation accuracy for each drive type in
Scenario ❸.
To ensure fairness and remove any inﬂuence of randomness,
we test all 90 possible combinations (10 possible ‘legitimate’
drives × 9 possible ‘unseen’ drives) and cross-validate each
by rotating the samples utilized for training and testing.
Accuracy. Table III presents the results, showing a com-
pelling average true accept rate (TAR) of 95.4% and an average
true reject rate (TRR) of 91.2%.
After investigating the false acceptances, we ﬁnd that most
false acceptances occur in pairs. We realize that the problem of
classifying an unknown drive is likely to beneﬁt from synthetic
data. Augmenting the training set with random variations (in an
attempt to simulate more unknown devices), or with samples
from more ‘malicious’ devices may better solidify the decision
boundary of the network, leading to higher overall accuracy.
We also augment the samples of the ‘legitimate’ drives, albeit
with much smaller perturbations, to increase the true accept rate.
We randomly select samples from the training set and perturb
them with noise. This augmentation procedure improves the
results, increasing the overall average accuracy to 95%. More
speciﬁcally, the average true accept rate increases to 98.0%,
and the average true reject rate increases to 92.2%.
Overall, these results indicate that our approach has enough
information to uniquely ﬁngerprint USB drives and that Time-
Print can even detect unseen devices of the exact same brand
and model.
C. Scenario ❸: Auditing / Classiﬁcation
We ﬁnally evaluate the effectiveness of Time-Print on the
auditing scenario, in which a system administrator needs to
determine exactly which device had ﬁles copied to/from it (to
track/identify an insider threat). We evaluate the accuracy for
Time-Print to uniquely identify a single device from a pool of
devices that are authorized for use.
We employ a network with a similar architecture to the
one employed in Scenario ❷ and shown in Table VI of the
Appendix. Since the goal is to identify each individual drive,
we modify the ﬁnal output layer of the network to contain the
same number of neurons as devices that we attempt to classify.
We utilize the same histogram transformation from Scenario ❷,
where each sample is separated by size and location and then
converted to a histogram for utilization in the neural network.
Similarly to Scenario ❷, we train and test (with cross-
validation) a classiﬁer for each model (i.e., only drives in one
model are trained and tested), as we expect that an organization
that adopts a device authentication system like Time-Print will
limit the usage of USB drives to a particular model. Our
classiﬁcation results are listed in Table IV for the SanDisk
Cruzer Blade, Generic, SanDisk Ultra, and Samsung Bar Plus
devices. We can see that Time-Print achieves accuracy above
98.4% for varied devices, including those from some of the best
selling manufacturers (SanDisk and Samsung). Furthermore,
the data for SanDisk and the Generic devices demonstrates that
the variability between drives is rich enough to create distinct
classiﬁcation boundaries among different drives. Finally, this
data shows that USB ﬁngerprinting is not limited to a single
manufacturer or USB protocol. In short, Time-Print is able to
ﬁngerprint a USB drive within the same brand and model for
accurate classiﬁcation.
VII. PRACTICALITY OF TIME-PRINT
With the viability of ﬁngerprinting USB mass storage devices
demonstrated, we further examine the practicality of Time-
Print in multiple aspects, including the latency of ﬁngerprint
acquisition, the impact of host system hardware variations on
ﬁngerprint accuracy, device usage, location accesses, whether
just the ﬂash controller itself can be utilized for ﬁngerprinting,
and how Time-Print might be deployed in the real world.
A. System Latency
The time to acquire the USB ﬁngerprint varies depending
upon the number of reads and the protocol used by the device
(e.g., USB 2.0 or 3.0). We measure the time required to capture
the ﬁngerprint from a SanDisk Cruzer Blade USB 2.0 device
and a SanDisk Ultra USB 3.0 device. The time cost of achieving
the results in Section VI is an average of 11 seconds on the
USB 2.0 drive and 6 seconds on a USB 3.0 drive, respectively.
The time difference is expected as the components of the USB
3.0 drives are faster to support the enhanced speed of the
protocol.
On the other hand, intuitively, fewer extra reads in the driver
should save time, but degrade the identiﬁcation accuracy. We
further evaluate how the number of observed reads affects the
accuracy of Time-Print by truncating the gathered samples
and examining the accuracy in Scenario ❸ with the SanDisk
Blade and Ultra devices. The results are presented in Figures 6
and 7. Both ﬁgures show that the accuracy decreases by at
least a full percentage point when the number of samples is
halved. The degradation continues gradually on the USB 2.0
device (down to 95% accuracy when 30x fewer samples are
taken) and more steeply on the USB 3.0 device (reducing to
90% accuracy when 30x fewer samples are taken). Overall,
even with 10x fewer samples being used, Time-Print can still
achieve more than 94.5% accuracy while reducing the latency
to only about 1 second, since the time required to acquire a
ﬁngerprint scales linearly with the number of extra reads.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:34:15 UTC from IEEE Xplore.  Restrictions apply. 
1011
Processor
Training System
Testing System
Intel Xeon E5507
4C/4T @ 2.27 GHz
Intel Xeon W3550
4C/8T @ 3.06 GHz
Motherboard
Dell 09KPNV
Dell 0XPDFK
RAM
2x2GB
1x8GB
USB Controller
Intel 82801JI
Intel 82801JI
TABLE V: System conﬁgurations for cross host investigation.
host port and (2) another Amazon Basics USB-A 3.1 10-Port
Hub is used to test the accuracy of these conﬁgurations with
the classiﬁer and training data of Scenario ❸. We observe that
utilizing a different host port or a different hub slightly reduces
the accuracy from 99% to about 95% for the Generic devices