then the attacker can choose: (1) to vote, in which case it
allocates all of its votes to its own fork, (2) to publish blocks,
in which case the transitions mimic those in the selﬁsh mining
setting, or (3) to wait and continue mining without taking any
publicly-facing actions. While the attacker is waiting, honest
validators can vote for a checkpoint. In practice, validators
will not vote simultaneously; we model this heterogeneity by
staggering the honest votes according to a random process. In
a given time slot, with probability pvote the honest parties
randomly choose a longest chain to vote for. We allocate
to this longest chain a proportion of honest votes equal to
min(max(X,0),1− β− vh), where X ∼ N (0.1,0.05), vh is the
total proportion of votes already allocated by the honest parties,
and β is the proportion of total votes available that are under
the control of the attacker. In other words, we choose a random
fraction of the remaining, uncast honest votes and allocate them
to the checkpoint on the current longest chain. The random
vote allocation distribution reﬂects the non-uniformity of block
propagation in the blockchain. With probability 1− pvote, a
block is generated by a miner and the block structure changes
according to the selﬁsh mining setting. The voting process is
active at the beginning of any epoch. It becomes inactive if (1)
one checkpoint receives more than 2/3 of the votes (2) one
chain containing a checkpoint becomes the canonical chain
through selﬁsh mining transitions—for instance, if the attacker
chooses to adopt the honest chain.
Block rewards are calculated as follows: miners get one unit
of reward for every block that ends up on the canonical chain.
Voting rewards are calculated (roughly) as in Casper FFG,
with the validator deposit Dv scaled appropriately to reﬂect
the ratio of real-world deposit magnitudes to block rewards.
The differences between our modeling assumptions and the full
scheme are detailed in Appendix D.
Results. As the agent’s voting and mining power increases,
SquirRL learns to exploit the penalty for incorrect voting to
12
0.0000.0330.0660.0990.1320.1650.1980.2310.2640.2970.330Attacker's Mining Power  / Voting Power 0.000.050.100.150.200.250.300.350.40Relative RewardHonestSM1+Honest VotingOSM+Honest VotingSquirRL0.260.280.300.320.340.260.280.300.320.340.360.380.0000.0330.0660.0990.1320.1650.1980.2310.2640.2970.330Attacker's Mining Power  / Voting Power 0.00.10.20.30.4Voting Reward FractionHonestSM1+Honest VotingOSM+Honest VotingSquirRL0.10.20.30.40.50.60.70.8P2's Hash Power m20.0000.0250.0500.0750.1000.1250.1500.1750.200Infiltrating hashrateRL-x1NE-x1RL-x2NE-x2penalize the honest party. A common attack strategy discovered
by SquirRL is as follows. First, the SquirRL agent accumulates
and hides two checkpoints, c(cid:48) → c(cid:48)(cid:48), through selﬁsh mining.
When the honest party releases a checkpoint c, the agent
immediately releases c(cid:48) and triggers a competing voting process.
The agent then waits until the honest checkpoint c accumulates
close to (but not above) 1/3 votes. The agent then releases
c(cid:48)(cid:48), causing checkpoint c(cid:48) to be included in a longer chain
than c. The remaining voters will vote for c(cid:48) according to the
voting rule and c(cid:48) will be justiﬁed. The honest voters for c are
penalized, amplifying the agent’s relative reward.
Figure 8 shows the total relative rewards accumulated by an
agent with the same fraction in mining hash power and voting
pool deposit. We vary this fraction up to 1/3 because Casper
FFG is not secure above 1/3 adversarial voting power, but honest
voting is shown to be a Nash equilibrium for agents with < 1/3
voting power in [12].2 We observe that this attack allows the
agent to amplify its rewards more than selﬁsh mining alone.
Figure 9 illustrates dramatic gains in relative voting reward, up
to 30% over honest rewards.
This attack raises an important practical concern. The
interest rate associated with voting rewards in Casper is close
to extrinsic interest rates (e.g. the stock market). Hence, if an
adversary is able to drive down an honest participant’s rewards,
honest voters may leave the voting pool, making it easier for an
adversary to control more than 1/3 of the voting power. Hence,
this attack can actually affect the integrity of the ﬁnalization
mechanism itself. An important
implication of this case
study is that system designers should consider how incentive
mechanisms compose with other incentive mechanisms. That
is, Casper FFG in isolation is not vulnerable to these attacks. It
is only by combining mining incentives with the Casper FFG
voting protocol that we observe this vulnerability.
B. Block Withholding Attacks
We explore a second case study in which agents perform
block withholding attacks [18], [25], [36], [42], [55], an attack
observed in practice (see, e.g., [68]). In block withholding
attacks, a mining pool inﬁltrates miners into opponent pools to
diminish their revenue and gain a competitive advantage. The
attacking pool deploys mining resources in a target pool and
submits partial solutions, i.e., proofs of work, to earn rewards. If
the attacking pool mines a block in the target pool, it withholds
it. The target pool thus loses block rewards and revenue relative
to its hash power declines.
In prior work, Eyal [18] showed that for two competing
mining pools, there is a (unique) Nash equilibrium where each
pool assigns a fraction of its resources to inﬁltrate and sabotage
the other. SquirRL automatically learns pool strategies that
converge to the same revenues as predicted by that equilibrium.
We adopt the same model as in Eyal [18]. In the two-
party version of this model, strategic mining pools P1 and P2
each possess “loyal” miners with hash rates of m1 and m2,
respectively, 0 ≤ m1 + m2 ≤ 1. The remaining miners mine on
their own, not forming or joining a pool. A miner loyal to pool
Pi may either mine honestly in Pi or inﬁltrate P3−i, as dictated
2This result considers Casper FFG voters in isolation, without accounting
for the possibility of an agent’s concurrent mining activity.
by Pi. When an inﬁltrating miner loyal to Pi generates a partial
block reward, the reward is relayed to Pi and split among all
registered miners in Pi, as well as the miners who are loyal to
Pi but currently inﬁltrating P3−i. The goal is to maximize the
revenue of each miner, normalized by the revenue when there
is no block withholding attack.
Denote the hash power of miners loyal to Pi and inﬁltrating
P3−i by xi. Thus 0 ≤ xi ≤ mi. We set up the two-agent RL
experiment using the reward functions deﬁned in [18]. Each
agent is assigned a mining hash power mi and aims to maximize
its reward by choosing xi, the hash power inﬁltrated into the
other pool, from a continuous action space [0,mi]. The reward
to be optimized is the immediate normalized revenue (again, as
deﬁned in [18]). There is no state transition in this environment:
the game has episode length 1. Two agents take turns to adapt
their strategies given the best strategy the other agent learned
in the last episode. We trained the model using PPO because
it is suitable for the multi-agent setting, as mentioned before,
and supports continuous action spaces.
For reproducibility, our setting of hyperparameters in PPO
and training results are speciﬁed as follows. We set the clipping
parameter ε to 0.1, with a linear learning rate schedule decaying
from 10−5 to 10−7. The entropy coefﬁcient β is set to 0.01
initially and decays to β ← β(1 − timestep/schedule) every
training step, with schedule set to 109. After 106 episodes,
both the strategies and rewards converge to those in the Nash
equilibrium speciﬁed in [18], to within 0.01. The detailed
policies and revenues are plotted in ﬁgs. 10 and 11 respectively.
Related work in [25] uses RL, speciﬁcally a policy gradient
based learning method [9], to study block withholding among
multiple agents in a setting with dynamic hash rates. A
limitation of that work is that it uses a discrete action space,
not a continuous one. One interesting feature is its inclusion of
a probabilistic model of migration of unafﬁliated (free agent)
miners to the most successful pools, an extension of the model
in [36]. Unfortunately, this model is rather artiﬁcial, with no
grounding in empirical study, so we chose not to duplicate it.
VIII. RELATED WORK
A number of recent works have analyzed direct attacks on
and economic ﬂaws in cryptocurrency protocols.
(1) Selﬁsh Mining. The concept of selﬁsh mining was introduced
by Eyal and Sirer in [19], and a large body of resulting
work has sought to reﬁne related mining models and compute
protocol security thresholds in a selﬁsh mining context [48],
[51], [54], [56]. Much of this work (including [56]) uses
MDP solving to compute optimal selﬁsh mining strategies.
These exact solutions are less robust to unexpected, real-time
changes in honest hashpower than our RL-based approach.
An enhanced model with two selﬁsh agents and one honest
agent is considered in [5], but this work does not consider the
presence of multiple rational actors in the network, which
is more realistic for a cryptocurrency mining setting. Our
techniques allow for reasoning about more realistic models
at the expense of theoretical guarantees.
(2) General Mining Attacks. A wide range of work has also
focused on potential mining attacks besides selﬁsh mining. One
example is difﬁculty attacks [23], [47], in which miners can
13
proﬁtably manipulate a chain’s difﬁculty by secretly raising
difﬁculty on their own private chain [4], switching between com-
peting currencies secured by the same mining hardware [47], or
pausing mining activities around difﬁculty adjustment time [23].
This can discourage mining altogether [30]. We leave the
analysis of such attacks to future work.
Attacks involving miner manipulation of user transactions,
via censorship or reordering, are surveyed in [29]. Many
such attacks have been shown in theory, allowing miners to
double-spend user funds or proﬁt from incorrect assumptions in
second-layer applications [8], [40], [46]. Such attacks have been
observed in practice [15], [17] and can be performed without
hashpower by bribing existing miners [46], [69]. Because these
attacks yield direct revenue for miners, they can almost certainly
be used to subsidize a successful mining attack as described
in our work, lowering the required hashpower threshold.
Lastly, attacks against miners are possible at the network
layer. One example is DoS attacks on mining pools, which
have been observed in practice [71] and which more often
affect larger pools [28]. Another is eclipse attacks [14], [62],
[63], which can ensure a node is connected to only attackers
and is applied to blockchain systems in [27], [44]. It has
shown that such attacks can interact with selﬁsh mining to
increase efﬁcacy [48], and routing-based eclipse attacks have
been observed in blockchains [65].
(3) RL, MDPs, and Computer Security. Our work focuses in
part on analyzing multi-agent games with DRL. Littman [41]
ﬁrst proposes the use of RL to extend MDP analysis to multi-
agent games. Recent work (e.g., [59], [73], [80]) has applied
this technique to cybersecurity actors, analyzing meta-games
between attackers and defenders. Our work extends this style
of analysis into a setting where multiple “attackers" compete to
maximize their own proﬁt share. Unlike in traditional security,
our setting is not mutually exclusive (multiple attackers can
proﬁt), and requires attackers to continually respond to each
others’ actions. This greatly increases strategy space complexity
in a way likely inherent to the open participation of most
cryptocurrency protocols.
IX. CONCLUSION
In this work, we propose SquirRL, a deep RL-based
framework to automate vulnerability detection in blockchain
incentive mechanisms. We have shown that SquirRL can
approximate known theoretical results regarding attacks on
blockchain incentive mechanisms. It can also handle challenging
settings such as multiple agents or continuous state spaces.
SquirRL cannot prove the security of a mechanism, but it can
serve as a “quick-and-dirty" tool for protocol designers to gain
intuition in cases where theoretical analysis is infeasible. Future
work may also illuminate new uses, including other classes of
incentive-based attacks, e.g., time-bandit attacks [15].
ACKNOWLEDGMENTS
We thank Alistair Stewart, Fatemeh Shirazi, and Alfonso
Cevallos for helpful conversations that inspired our experiments
on composed mechanisms. We thank Ren Zhang and our
anonymous reviewers for their helpful feedback. This work was
partially supported by the Army Research Ofﬁce under grant
W911NF-18-1-0332-(73198-NS), the National Science Founda-
tion under grants CCF-1705007, CNS-1564102, CNS-1704615,
CNS-1933655, CA-2040675, the Initiative for Cryptocurrencies
and Contracts (IC3), and the Ripple Foundation.
REFERENCES
[1] Aws now offers nvidia quadro virtual workstations for ec2 g4 instances
at no additional cost. https://aws.amazon.com/about-aws/whats-new/
2020/01/aws-now-offers-nvidia-quadro-virtual-workstations-for-ec2-
g4-instances-at-no-additional-cost/, January 2020.
Accessed on
November 13, 2020.
[2] The best crypto mining pools 2020. https://miningpools.com/, November
2020. Accessed on November 12, 2020.
[3] Alekh Agarwal, Sham M. Kakade, Jason D. Lee, and Gaurav Mahajan.
On the theory of policy gradient methods: Optimality, approximation,
and distribution shift, 2019.
[4] Lear Bahack. Theoretical Bitcoin attacks with less than half of the
computational power (draft). arXiv preprint arXiv:1312.7013, 2013.
[5] Qianlan Bai, Xinyan Zhou, Xing Wang, Yuedong Xu, Xin Wang, and
Qingsheng Kong. A deep dive into blockchain selﬁsh mining. arXiv
preprint arXiv:1811.08263, 2018.
[6] Bowen Baker, Ingmar Kanitscheider, Todor Markov, Yi Wu, Glenn Powell,
Bob McGrew, and Igor Mordatch. Emergent tool use from multi-agent
autocurricula, 2019.
[7] Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung,
Przemysław D˛ebiak, Christy Dennison, David Farhi, Quirin Fischer,
Shariq Hashme, Chris Hesse, et al. Dota 2 with large scale deep
reinforcement learning. arXiv preprint arXiv:1912.06680, 2019.
Joseph Bonneau. Why buy when you can rent? In FC, pages 19–26.
Springer, 2016.
[8]
[9] Michael Bowling and Manuela Veloso. Scalable learning in stochastic
games. In AAAI, pages 11–18, 2002.
[10] Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider,
John Schulman, Jie Tang, and Wojciech Zaremba. OpenAI gym, 2016.
[11] Vitalik Buterin and Virgil Grifﬁth. Casper the friendly ﬁnality gadget.
arXiv preprint arXiv:1710.09437, 2017.
[12] Vitalik Buterin, Daniël Reijsbergen, Stefanos Leonardos, and Georgios
Piliouras. Incentives in ethereum’s hybrid casper protocol. In ICBC,
pages 236–244. IEEE, 2019.
[13] Miles Carlsten, Harry Kalodner, S Matthew Weinberg, and Arvind
Narayanan. On the instability of Bitcoin without the block reward.
In CCS, pages 154–167. ACM, 2016.
[14] Miguel Castro, Peter Druschel, Ayalvadi Ganesh, Antony Rowstron,
and Dan S Wallach. Secure routing for structured peer-to-peer overlay
networks. OSR, 36(SI):299–314, 2002.
[15] Philip Daian, Steven Goldfeder, Tyler Kell, Yunqi Li, Xueyuan Zhao, Iddo
Bentov, Lorenz Breidenbach, and Ari Juels. Flash boys 2.0: Frontrun-
ning, transaction reordering, and consensus instability in decentralized
exchanges. arXiv preprint arXiv:1904.05234, 2019.
[16] Christian Decker and Roger Wattenhofer. Information propagation in
the bitcoin network. In P2P, pages 1–10. IEEE, 2013.
[17] Shayan Eskandari, Seyedehmahsa Moosavi, and Jeremy Clark. Sok:
[18]
[19]
Transparent dishonesty: front-running attacks on blockchain. 2019.
Ittay Eyal. The miner’s dilemma. In S&P, pages 89–103. IEEE, 2015.
Ittay Eyal and Emin Gün Sirer. Majority is not enough: Bitcoin mining
is vulnerable. CACM, 61(7):95–102, 2018.
[20] Serge Fehr and Chen Yuan. Towards optimal robust secret sharing with
security against a rushing adversary. Cryptology ePrint Archive, Report
2019/246, 2019. https://eprint.iacr.org/2019/246.