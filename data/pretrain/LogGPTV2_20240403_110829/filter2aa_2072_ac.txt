are selected using the podSelector and/or the 
namespaceSelector options. An example 
network policy is shown in Appendix E: Example 
network policy. Network policy formatting may 
differ depending on the container network interface 
(CNI) plugin used for the cluster. Administrators should use a default policy selecting all 
Pods to deny all ingress and egress traffic and ensure any unselected Pods are 
isolated. Additional policies could then relax these restrictions for permissible 
connections. 
External IP addresses can be used in ingress and egress policies using ipBlock, but 
different CNI plugins, cloud providers, or service implementations may affect the order 
of NetworkPolicy processing and the rewriting of addresses within the cluster. 
Resource policies 
In addition to network policies, LimitRange and ResourceQuota are two policies that can 
limit resource usage for namespaces or nodes. A LimitRange policy constrains 
individual resources per Pod or container within a particular namespace, e.g., by 
enforcing maximum compute and storage resources. Only one LimitRange constraint 
can be created per namespace as shown in the example YAML file of Appendix F: 
Example LimitRange. Kubernetes 1.10 and newer supports LimitRange by default. 
Unlike LimitRange policies that apply to each Pod or container individually, 
ResourceQuotas are restrictions placed on the aggregate resource usage for an entire 
Network Policies Checklist 
 Use CNI plugin that supports 
NetworkPolicy API 
 Create policies that select Pods using 
podSelector and/or the 
namespaceSelector 
 Use a default policy to deny all ingress 
and egress traffic. Ensures unselected 
Pods are isolated to all namespaces 
except kube-system 
 Use LimitRange and ResourceQuota 
policies to limit resources on a 
namespace or Pod level 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
15 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
namespace, such as limits placed on total CPU and memory usage. If a user tries to 
create a Pod that violates a LimitRange or ResourceQuota policy, the Pod creation fails. 
An example ResourceQuota policy is shown in Appendix G: Example 
ResourceQuota. 
Control plane hardening 
The control plane is the core of Kubernetes and gives 
users the ability to view containers, schedule new Pods, 
read Secrets, and execute commands in the cluster. 
Because of these sensitive capabilities, the control 
plane should be highly protected. In addition to secure 
configurations such as TLS encryption, RBAC, and a 
strong authentication method, network separation can 
help prevent unauthorized users from accessing the 
control plane. The Kubernetes API server runs on ports 
6443 and 8080, which should be protected by a firewall 
to accept only expected traffic. Port 8080, by default, is 
accessible without TLS encryption from the local 
machine, and the request bypasses authentication and authorization modules. The 
insecure port can be disabled using the API server flag --insecure-port=0. The 
Kubernetes API server should not be exposed to the Internet or an untrusted network. 
Network policies can be applied to the kube-system namespace to limit internet access 
to the kube-system. If a default deny policy is implemented to all namespaces, the 
kube-system namespace must still be able to communicate with other control plane 
segments and worker nodes. 
The following table lists the control plane ports and services: 
Table II: Control plane ports 
Protocol 
Direction 
Port Range 
Purpose 
TCP 
Inbound 
6443 or 8080 if not disabled 
Kubernetes API server 
TCP 
Inbound 
2379-2380 
etcd server client API 
TCP 
Inbound 
10250 
kubelet API 
TCP 
Inbound 
10251 
kube-scheduler 
TCP 
Inbound 
10252 
kube-controller-manager 
TCP 
Inbound 
10258 
cloud-controller-manager (optional) 
Steps to secure the control plane 
1. Set up TLS encryption 
2. Set up strong authentication 
methods 
3. Disable access to internet and 
unnecessary, or untrusted networks  
4. Use RBAC policies to restrict 
access 
5. Secure the etcd datastore with 
authentication and RBAC policies 
6. Protect kubeconfig files from 
unauthorized modifications 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
16 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
Etcd 
The etcd backend database stores state information and cluster Secrets. It is a critical 
control plane component, and gaining write access to etcd could give a cyber actor root 
access to the entire cluster. Etcd should only be accessed through the API server where 
the cluster’s authentication method and RBAC policies can restrict users. The etcd data 
store can run on a separate control plane node allowing a firewall to limit access to only 
the API servers. Administrators should set 
up TLS certificates to enforce HTTPS 
communication between the etcd server 
and API servers. The etcd server should be 
configured to only trust certificates 
assigned to API servers.  
Kubeconfig Files 
The kubeconfig files contain sensitive 
information about clusters, users, 
namespaces, and authentication mechanisms. Kubectl uses the configuration files 
stored in the $HOME/.kube directory on the worker node and control plane local 
machines. Cyber actors can exploit access to this configuration directory to gain access 
to and modify configurations or credentials to further compromise the cluster. The 
configuration files should be protected from unintended changes, and unauthenticated 
non-root users should be blocked from accessing the files. 
Worker node segmentation 
A worker node can be a virtual or physical machine, depending on the cluster’s 
implementation. Because nodes run the microservices and host the web applications for 
the cluster, they are often the target of exploits. If a node becomes compromised, an 
administrator should proactively limit the attack surface by separating the worker nodes 
from other network segments that do not need to communicate with the worker nodes or 
Kubernetes services. A firewall can be used to separate internal network segments from 
the external facing worker nodes or the entire Kubernetes service depending on the 
network. Examples of services that may need to be separated from the possible attack 
surface of the worker nodes are confidential databases or internal services that would 
not need to be internet accessible.  
The following table lists the worker node ports and services: 
The etcd backend database 
is a critical control plane 
component and the most 
important piece to secure 
within the cluster. 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
17 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
Table III: Worker node ports 
Protocol 
Direction 
Port Range 
Purpose 
TCP 
Inbound 
10250 
kubelet API 
TCP 
Inbound 
30000-32767 
NodePort Services 
Encryption 
Administrators should configure all traffic in the Kubernetes cluster—including between 
components, nodes, and the control plane—to use TLS 1.2 or 1.3 encryption. 
Encryption can be set up during installation or afterward using TLS bootstrapping, 
detailed in the Kubernetes documentation, to create and distribute certificates to nodes. 
For all methods, certificates must be distributed amongst nodes to communicate 
securely. 
Secrets 
Kubernetes Secrets maintain sensitive information, such as passwords, OAuth tokens, 
and SSH keys. Storing sensitive information in Secrets provides greater access control 
than storing passwords or tokens in YAML files, container images, or environment 
variables. By default, Kubernetes stores Secrets as unencrypted base64-encoded 
strings that can be retrieved by anyone with API access. Access can be restricted by 
applying RBAC policies to the secrets resource. 
Secrets can be encrypted by configuring data-at-rest encryption on the API server or by 
using an external Key Management Service (KMS), which may be available through a 
cloud provider. To enable Secret data-at-rest encryption using the API server, 
administrators should change the kube-apiserver manifest file to execute using the 
--encryption-provider-config argument. An example encryption-
provider-config file is shown in Appendix 
H: Example encryption. Using a KMS 
provider prevents the raw encryption key from 
being stored on the local disk. To encrypt 
Secrets with a KMS provider, the 
encryption-provider-config file should 
specify the KMS provider as shown in 
Appendix I: Example KMS configuration.  
By default, Secrets are 
stored as unencrypted 
base64-encoded strings and 
can be retrieved by anyone 
with API access. 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
18 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
After applying the encryption-provider-config file, administrators should run the 
following command to read and encrypt all Secrets:  
kubectl get secrets --all-namespaces -o json | kubectl replace -f - 
Protecting sensitive cloud infrastructure 
Kubernetes is often deployed on virtual machines in a cloud environment. As such, 
administrators should carefully consider the attack surface of the virtual machines on 
which the Kubernetes worker nodes are running. In many cases, Pods running on these 
virtual machines have access to sensitive cloud metadata services on a non-routable 
address. These metadata services provide cyber actors with information about the cloud 
infrastructure and possibly even short-lived credentials for cloud resources. Cyber 
actors abuse these metadata services for privilege escalation [5]. Kubernetes 
administrators should prevent Pods from accessing cloud metadata services by using 
network policies or through the cloud configuration policy. Because these services vary 
based on the cloud provider, administrators should follow vendor guidance to harden 
these access vectors.  
▲Return to Contents 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
19 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
Authentication and authorization 
Authentication and authorization are the primary mechanisms to restrict access to 
cluster resources. Cyber actors can scan for well-known Kubernetes ports and access 
the cluster’s database or make API calls without being authenticated if the cluster is 
misconfigured. User authentication is not a built-in feature of Kubernetes. However, 
several methods exist for administrators to add authentication to a cluster. 
Authentication 
Kubernetes clusters have two types of users: service accounts and normal user 
accounts. Service accounts handle API requests on behalf of Pods. Authentication is 
typically managed automatically by Kubernetes through the ServiceAccount Admission 
Controller using bearer tokens. The bearer tokens are mounted into Pods at well-known 
locations and can be used from outside the cluster if the tokens are left unsecured. 
Because of this, access to Pod Secrets should be restricted to those with a need to view 
them using Kubernetes RBAC. For normal users and admin accounts, there is no 
automatic authentication method for users. Administrators must add an authentication 
method to the cluster to implement authentication and authorization mechanisms. 
Kubernetes assumes that a cluster-independent service manages user authentication.  
The Kubernetes documentation lists several ways to implement user authentication 
including client certificates, bearer tokens, authentication plugins, and other 
authentication protocols. At least one user authentication method should be 
implemented. When multiple authentication methods are implemented, the first module 
to successfully authenticate the request 
short-circuits the evaluation. Administrators 
should not use weak methods such as static 
password files. Weak authentication 
methods could allow cyber actors to 
authenticate as legitimate users.  
Anonymous requests are requests that are 
rejected by other configured authentication 
methods and are not tied to any individual 
user or Pod. In a server set up for token authentication with anonymous requests 
enabled, a request without a token present would be performed as an anonymous 
Administrators must add an 
authentication method to 
the cluster to implement 
authentication and 
authorization mechanisms. 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
20 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
request. In Kubernetes 1.6 and newer, anonymous requests are enabled by default. 
When RBAC is enabled, anonymous requests require explicit authorization of the 
system:anonymous user or system:unauthenticated group. Anonymous 
requests should be disabled by passing the --anonymous-auth=false option to the 
API server. Leaving anonymous requests enabled could allow a cyber actor to access 
cluster resources without authentication. 
Role-based access control  
RBAC is one method to control access to cluster resources based on the roles of 
individuals within an organization. RBAC is enabled by default in Kubernetes version 
1.6 and newer. To check if RBAC is enabled in a cluster using kubectl, execute 
kubectl api-version. The API version for .rbac.authorization.k8s.io/v1 
should be listed if enabled. Cloud Kubernetes services may have a different way of 
checking whether RBAC is enabled for the cluster. If RBAC is not enabled, start the API 
server with the --authorization-mode flag in the following command: 
kube-apiserver --authorization-mode=RBAC 
Leaving authorization-mode flags, such as AlwaysAllow, in place allows all 
authorization requests, effectively disabling all authorization and limiting the ability to 
enforce least privilege for access. 
Two types of permissions can be set: Roles and ClusterRoles. Roles set permissions 
for particular namespaces, whereas ClusterRoles set permissions across all cluster 
resources regardless of namespace. Roles and ClusterRoles can only be used to add 
permissions. There are no deny rules. If a cluster is configured to use RBAC and 
anonymous access is disabled, the Kubernetes API server will deny permissions not 
explicitly allowed. An example RBAC Role is shown in Appendix J: Example pod-
reader RBAC Role. 
A Role or ClusterRole defines a permission but does not tie the permission to a user. 
RoleBindings and ClusterRoleBindings are used to tie a Role or ClusterRole to a user, 
group, or service account. RoleBindings grant permissions in Roles or ClusterRoles to 
users, groups, or service accounts in a defined namespace. ClusterRoles are created 
independent of namespaces and can then be granted to individuals using a RoleBinding 
to limit the namespace scope. ClusterRoleBindings grant users, groups, or service 
accounts ClusterRoles across all cluster resources. An example RBAC RoleBinding and 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
21 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
ClusterRoleBinding is shown in Appendix K: Example RBAC RoleBinding and 
ClusterRoleBinding. 
To create or update Roles and ClusterRoles, a user must have the permissions 
contained in the new role at the same scope or possess explicit permission to perform 
the escalate verb on the Roles or ClusterRoles resources in the 
rbac.authorization.k8s.io API group. After a binding is created, the Role or 
ClusterRole is immutable. The binding must be deleted to change a role. 
Privileges assigned to users, groups, and service accounts should follow the principle of 
least privilege, giving only required permissions to resources. Users or user groups can 
be limited to particular namespaces where required resources reside. By default, a 
service account is created for each namespace for Pods to access the Kubernetes API. 
RBAC policies can be used to specify allowed actions from the service accounts in each 
namespace. Access to the Kubernetes API is limited by creating an RBAC Role or 
ClusterRole with the appropriate API request verb and desired resource on which the 
action can be applied. Tools exist that can help audit RBAC policies by printing users, 
groups, and service accounts with their associated assigned Roles and ClusterRoles. 
▲Return to Contents 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
22 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
Log auditing 
Logs capture activity in the cluster. Auditing logs is necessary, not only for ensuring that 
services are operating and configured as intended, but also for ensuring the security of 
the system. Systematic audit requirements mandate consistent and thorough checks of 
security settings to help identify compromises. Kubernetes is capable of capturing audit 
logs for cluster actions and monitoring basic CPU and memory usage information; 
however, it does not natively provide in-depth monitoring or alerting services.  
Logging 
System administrators running applications within Kubernetes should establish an 
effective logging, monitoring, and alerting system for their environment. Logging 
Kubernetes events alone is not enough to provide a full picture of the actions occurring 
on the system. Logging should also be performed at the host level, application level, 
and on the cloud if applicable. These logs can then be correlated with any external 