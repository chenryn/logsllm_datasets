phone numbers were provided to us by our service provider,
Bandwidth Inc. In this paper, we refer to these phone numbers
as inbound lines 2. Such a setup allows us to conduct con-
trolled experiments, collect data, and characterize the phone
calls.
We explain key design decisions of the deployment, con-
ﬁguration, testing and operation of our honeypot.
On-premises deployment: A local deployment of our honey-
pot provided ﬁne-grained control over its design and ensured
that we stored all the sensitive data on servers we own.
2Inbound lines : A set of virtual VoIP phone lines and not physical PSTN
lines.
USENIX Association
29th USENIX Security Symposium    399
Phone Numbers: We worked with a telecommunication ser-
vice provider who owned the phone numbers used in our
experiments. We built our honeypot using Asterisk 3, which is
an open-source software implementation of a Private Branch
Exchange (PBX). With a setup like an enterprise VoIP con-
sumer, our honeypot received and processed phone calls.
Conﬁguring the Call Processing System: Like routing ta-
bles and routes of a router, the dial-plan and dial-rules of a
PBX determine how it handles a phone call. By developing
appropriate dial-plans, our honeypot automatically answers
and records calls made to one set of lines, while the honeypot
rejects any calls made to a different set of inbound lines.
Reliability of the Call Processing System: We used over
66,000 inbound lines for our experiments. With 66,000 con-
ﬁguration entries, Asterisk exhibited inconsistent behavior
resulting in frequent crashes. After many iterations, we es-
timated that a single Asterisk instance can handle approxi-
mately 15,000 unique dial-plan entries under realistic load
of phone calls. To operate a stable honeypot, we reduced
the dial-plan’s size by reusing dial-plan subroutines for each
experiment and automating dial-plan generation.
3.2 History of Inbound Lines
The total number of inbound lines terminated on our honeypot
varied at different stages of our study because our service
provider dynamically added inbound lines to our honeypot.
We kept track of any additional inbound lines added to our
honeypot through periodic snapshots and updates to a local
database. We account for this incremental addition of numbers
to our honeypot throughout our experiments and normalize
our measurements when appropriate. Based on the history of
the inbound lines, we categorize them into two types:
Abuse Numbers: As reported by our service provider, abuse
phone numbers had a history of abuse. Some of these numbers
were returned by their previous owners due to high volume
of unsolicited calls. This pool also included phone numbers
previously used by spammers and robocallers to generate
unsolicited phone calls. Abuse numbers are an invaluable
resource for our honeypot because these numbers were owned
by adversaries in the past or were victims of high volume of
unsolicited calls. We started with 6,754 abuse numbers at the
beginning of our study and obtained additional abuse numbers
in April 2019, resulting in a total of 9,071 abuse numbers.
Clean Numbers: A set of phone numbers owned by our ser-
vice provider which were intended for distribution among new
users. This pool contained a combination of numbers which
were newly procured by our service provider and numbers
which were rotated from prior customers. These numbers
did not have a reported abuse history. We obtained a total of
57,535 such clean phone numbers at the end of July 2019.
A combination of clean and abuse numbers allowed us to
systematically measure and report our observations of the two
3https://www.asterisk.org
Figure 1: Honeypot Architecture and Data Collection Flow
extremes of the phone network. To the best of our knowl-
edge, we are the ﬁrst to develop a comprehensive telephony
honeypot with both clean and abuse numbers.
No Seeding: Throughout our study, we do not seed either the
clean or the abuse numbers on any online portals, forums,
denylists or mobile apps which claim to block robocalls. By
deﬁnition, the calls collected and processed in our experiments
were unsolicited calls. We did not initiate any outbound calls
using any inbound lines.
3.3 Call Meta-data and Call Audio Collection
After designing and deploying our honeypot, we collect the
call meta-data, which includes Call Detail Record (CDR) and
SIP header logs. From CDR logs, we extracted the calling
number, CNAM, called numbers, timestamp and optional call
duration, if the honeypot answers the call. From SIP logs we
get P-Asserted-Identity, a SIP header ﬁeld which can contain
different identiﬁcation information.
Call audio is essential to characterize different spam and
robocalling campaigns in the telephone network. To obtain
a representative sample of call audio content, we initially
selected 3,000 random lines from our pool. We refer to this
set of lines as Recording Lines 1 (RL1). We setup the dial-
plan and conﬁgure our honeypot to answer any unsolicited
call made to these 3,000 numbers and play a recording after a
delay of 2 seconds. We use a default Asterisk audio recording
as the source for the audio prompt, which says “Hello” in a
female voice with an American accent.
On 21st December 2019, we analyzed the data collected
thus far and identiﬁed the inbound lines which received an
average of one or more calls per day. A total of 2,949 inbound
lines met this criteria. We assign these inbound lines to a new
Asterisk PBX and conﬁgure it to ring for 10 seconds before
answering every call made to these lines. We call this set of
lines as Recording Lines 2 (RL2).
We conﬁgure our honeypot to record any unsolicited call
made to an inbound line which belongs to Recording Lines 1
or 2. The honeypot records and stores every call as three sep-
arate audio streams — incoming (calling party to the honey-
pot), outgoing (honeypot to the calling party) and a combined
recording. Separate recording streams allowed us to prevent
issues caused by overlapping speech signals or locally gener-
ated noise or audio. We ensured that multiple simultaneous
400    29th USENIX Security Symposium
USENIX Association
calls made to the same inbound line generated separate record-
ing ﬁles with appropriate timestamps. Finally, we rejected
any unsolicited call made to a non-recording inbound line
with a 403 Forbidden SIP response code. We observed that
certain SIP clients which initiate unsolicited calls retry calls
multiple times when they receive a rejection from the called
side. To address this, we identify and remove any duplicate
calls which have the same calling and called number within a
30 second window. We do not consider these duplicate calls
in any results in this paper.
A majority of service providers allow callers to mask their
details by dialing with a preﬁx. In the United States, most
subscribers can preﬁx the called number with *67 to ensure
that the called party does not see the calling part’s caller ID.
By doing so, the caller ID shown to the user changes from
the actual caller ID to a string like “Restricted”, “Private” or
“Anonymous”. In our honeypot, we observed that there were
multiple instances where the actual caller ID was replaced
with string like “Restricted”, “Private” or “Anonymous”. We
conﬁrmed that our service provider’s system was not manip-
ulating the caller ID and instead, in some cases the actual
caller ID was transparently passed from upstream service
providers to our honeypot in the “P-Asserted-Identity” SIP
header. Since neither us nor our service provider had control
over caller ID information, we do not have caller ID infor-
mation in the “P-Asserted-Identity” SIP header for all calls.
Also, one of the key limitations of telephone networks is the
lack of end-to-end caller authentication. Thus, the attested
caller ID propagates across different boundaries in the phone
network on best effort basis. Due to this, we do not assume
that the caller ID information is complete or accurate.
While our study lasted over 11 months, Table 1 in the Ap-
pendix shows the exact dates when RL1 and RL2 were setup
to collect call audio, maintenance downtime, power outage
and the duration of t-test discussed later in Section 4.3.
3.4 Ethical and Legal Considerations
Our university’s Institutional Review Board (IRB), our univer-
sity’s ofﬁce of general counsel, and our provider reviewed and
approved our experiments. We understand that our research
may involve human subjects even though our main intention
is to study automated phone calls. It is possible for a live
human to call one of our inbound lines due to mis-dialing or
while trying to reach the previous owner of the numbers. As
responsible researchers, we take all the necessary actions to
ensure that our research is within the legal and ethical bound-
aries. Before the start of our research, we ensured that we
were compliant with ethical and legal restrictions imposed by
the university, our state and the federal laws of United States.
Speciﬁcally, we sought the approval of our IRB to address the
ethical considerations of our study. We also worked closely
with our university’s Ofﬁce of General Counsel to make sure
that our actions are within the bounds of state laws of our
state and the federal laws of United States.
Throughout our study, we ensured that our actions do not in-
ﬂict harm to human subjects. We worked closely with our IRB
before the start of our research to describe our experiments
and the associated limitations. As part of this review process,
we submitted a detailed report to our IRB. As explained in
Section 3, our principal data collection methodology is to wait
for the arrival of calls on the inbound lines owned by us. Our
methods are similar to research studies that perform public
observation of humans, except that we observe the behavior
of humans in a virtual environment. In such a setting, we are
neither targeting nor recruiting participants to take part in our
study. We do not reach out to any participants. We strictly
refrain from advertising the phone numbers of our inbound
lines in spam portals, social media or through any other mech-
anisms. We do not initiate any outgoing calls to any phone
numbers throughout our study. After a thorough review of our
proposal, the above facts were carefully considered and the
IRB determined that our research was exempt from further re-
view on the basis that effectively, we are performing a public
observation study.
In the United States, call audio is considered private in-
formation. Thus, recording a phone conversation is strictly
regulated by state and federal laws. Our honeypot was setup
in a state where single party consent is sufﬁcient to record
phone calls. In situations where a phone call spans across
one or more state boundaries, federal law takes precedence
over the state law. Federal law also mandates that at least a
single party needs to consent for the phone call to be legally
recorded. Throughout our study, all the calls that we recorded
were made to the inbound lines we owned. Furthermore, we
terminated these inbound lines on the Asterisk PBX which
we operated. Since we explicitly consent to being recorded,
we satisﬁed the single party consent requirement.
Many robocallers or spam campaigns make automated
phone calls based on a “hitlist”, which is a list of active phone
numbers maintained and sold by third parties. As a result,
the campaigns attempt to reach large groups of unknown
recipients, seldom with the intention of reaching a known
individual. Since these campaigns make unsolicited phone
calls to unknown parties, it is reasonable to assume that the
callers do not consider the call content especially private or
sensitive. Not obtaining explicit consent of the caller (live
human or automated call) prior to being recorded does not
affect their rights or welfare. This is because the caller does
not have a reasonable expectation that their calls are not be-
ing recorded. Further, these callers do not have a reasonable
privacy expectation since they make unsolicited phone calls
to a vast number of users.
The goal of our study is to develop a deeper understanding
of the adversaries who operate in the telephone network, and
not to identify details about individuals or speciﬁc callers
from the data available in our honeypot. We designed our
USENIX Association
29th USENIX Security Symposium    401
experiments to limit the recording duration to 60 seconds.
There are possibilities where a non-adversarial caller may
make a phone call to one of the inbound lines conﬁgured for
recording. By capping the recording duration to 60 seconds
and by gracefully terminating the call at the 60 second mark,
we minimize the amount of data gathered in such scenarios.
Industry Robocall Blocking Data
3.5
To evaluate our methodology in Section 5, we use a second
corpus of phone calls provided to us by a company that builds
services to help block robocalls. This data set consisted of the
audio recording of the call, calling party number, timestamp
of the call and the transcript of the call. Since we did not
collect the data directly, we do not know the exact setup of
the honeypot used for data collection or transcription.
4 Individual Call Characterization
In this section, we provide an overview of the data collected
throughout our experiments. We delve into the temporal char-
acteristics of call volume and highlight operational character-
istics of unsolicited calls. We develop a method to identify
and characterize high call-volume events. We statistically
evaluate the effects of answering a phone call on the number
of unsolicited calls received per inbound line. Next, we pro-
pose a heuristic to identify voicemail spam calls. We share
a detailed analysis of caller ID spooﬁng in the wild and dis-
cuss how unsolicited callers reuse Caller ID Name (CNAM).
We develop and apply a heuristic to identify wangiri scam
and estimate the scale of wangiri scam observed in our hon-
eypot. Finally, we delve into the characteristics of the call
audio which sets the foundation for the subsequent section on
campaign identiﬁcation.
Finding 1: Unsolicited phone calls are rampant in the United
States. Using the telephony honeypot described in Section 3,
we collect 1,481,201 unsolicited phone calls over a span of
11 months, without seeding our phone numbers to any source.
We observed an average of 4,137.43 unsolicited calls per
day, across all the inbound lines used in our honeypot. Each
inbound line received an average of 0.12 call per day, which
translates to one call every 8.42 days.
Throughout our study, we track the state of clean and abuse
lines assigned to our honeypot, since these were dynamically
added to our honeypot by our provider. We owned a total of
66,606 unique inbound lines of which 57,535 were clean lines
and 9,071 were abuse lines, as explained in Section 3.2.
Finding 2: Clean Numbers received 77.83% of all unsolicited
calls in our honeypot without any form of seeding. Among
all the inbound lines, 87.08% (57,535) were clean inbound
lines and 12.92% (9,071) were abuse inbound lines. The clean
inbound lines with no history of abuse received an average of
0.11 call per day per inbound line, which translates to one call
every 9.35 days. The abuse inbound lines received an average
of 0.11 call per day per inbound line, which translates to one
call every 9.44 days. The scale of our ﬁndings shows that it is
not necessary for a phone number to have a prior history of
abuse calls in order to receive unsolicited phone calls.
Finding 3: 75.10% of clean lines and 100% of abuse lines
received at least one unsolicited phone call during our study.
We found that only a small fraction (24.90 %) of all the clean
numbers never received an unsolicited call during our study.
It took an average of 8.01 weeks for an inbound line to receive
the ﬁrst unsolicited call after being added to our honeypot.
Since calls arrive into a honeypot at a fairly low rate, only
a fraction of these calls actually contain audio. This justiﬁes
our design decision of having adding a very large set of num-
bers as inputs to our honeypot. In particular, this shows that
prior research [6, 16, 17] which relied on only a few hundred
inbound lines was ultimately unlikely to see large portions of
the problem.
4.1 Temporal Characteristics
The normalized daily call volumes per line over the 11 month
study period is shown in Figure 2. We observed outliers that
caused a spike in call volume during April of 2019, which we
characterize in detail in Section 4.2.
Finding 4: We observed a stationary call volume of unso-
licited calls over our study period. Since our study spanned
11 months, we were able to observe the cumulative call vol-
ume on both clean and abuse numbers over extended period