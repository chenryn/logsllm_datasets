In our implementation we cur-
rently use an abductive constraint logic programming proof
procedure found in [34].
(ii) Illustration of trace abduction. One of the scenarios we
have been using concerns a natural disaster rescue, in which
a team of medics must react to injuries incurred by people
caught in an earthquake. We will show a sample analysis,
together with the diagnostic information which our proto-
type system provides. Here is a small subset of the policies,
in natural language and then in our policy representation
language:
[Nobody may move a patient with spinal injuries]
denied(Sub, Tar, move(L), T ) ←
holdsAt(is injured(Tar, spinal), T ).
(9)
[Medics are allowed to move a patient with a spinal
injury if they are on a spine board.]
permitted(M, Tar, move(L), T ) ←
holdsAt(is injured(Tar, spinal), T ),
(10)
holdsAt(on spine board(Tar), T ).
[Injuries who are located in a house at risk of collapse
must be moved to hospital within 10 mins by a medic]
obl(M, Tar, move(hosp), Ts, Te, Ts) ←
Te = Ts + 10, holdsAt(at(Tar, H), Ts),
holdsAt(at risk(H), Ts), happens(ﬁnd(X, Tar), Ts),
holdsAt(is injured(Tar, InjuryType), Ts).
(11)
In addition to policies such as these, the example domain
also includes formulas which describe the eﬀects of actions,
expressed in the EC formalism described in Section 3.4.
They specify under what circumstances a house is at risk
of collapsing, how this can cause injuries to individuals, the
remedial actions medics can take to treat injuries, and so
on. We do not present these details here.
Even with the few simple policies presented above, a num-
ber of interesting analyses are possible. Are there situations
in which a medic has an obligation which it would be impos-
sible to fulﬁl, because of the presence of a conﬂicting autho-
rization policy? There are several diﬀerent interpretations
of this query, one of which is the following:
obl(Sub, Tar, Act, Ts, Te, Tinit)
∧ not cease obl(Sub, Tar, Act, Tinit, Ts, Te, T )
(12)
∧ denied(Sub, Tar, Act, T ) ∧ Ts < T.
If there are values of the unbound variables which makes
the above conjunction true, this means there is a time at
which an obligation is binding on a Sub, but at which there
is a negative authorization policy, stating that the Sub will
be denied access to perform the action. This query can be
solved in our framework by the abductive algorithm; one of
the answers returned shows the following groundings for the
variables in (12).
obl(medic, alice, move(hosp), 1, 1, 11)
∧ not cease obl(medic, alice, move(hosp), 1, 1, 11, 2),
∧ denied(medic, alice, move(hosp), 2) ∧ 1 < 2.
(13)
The abduced atoms, the union of the sets ∆D and ∆π, were:
{ initially(at risk(house3)), initially(at(alice, street)),
happens(walk(alice, house3), 0),
happens(injure(alice, spinal), 1) }
(14)
These atoms represent a series of events and actions in the
system, together with system’s initial conﬁguration, which
will lead to the presence of the modality conﬂict represented
by (13). They show that if alice is initially in the street, then
walks to house3 —which is at risk of collapse—and subse-
quently has a spinal injury, there will be an obligation on
the medics to move her back to the hospital, but a denial of
permission to make that movement.
Policy authors can look at this output and take necessary
actions. One response might be to introduce exceptions to
the policy rule (9) in order to avoid the modality conﬂict, but
for the purpose of illustrating another capability of our anal-
ysis framework, we consider a diﬀerent possibility. Our pre-
vious experience developing policy analysis tools has shown
that it is possible to build interfaces that hide much of the
formal representations, presenting information in a format
less expert users can understand.
(iii) Constrained search and multiple solutions. Suppose
the policy author, familiar with some details of the system
which is being controlled by the policy, notes that the sample
trace above, which gives rise to a modality conﬂict of the
kind queried, has the event
happens(injure(alice, spinal), 1)
It may be that this event would never occur in the real
system—let us say e.g. that it is known that alice had been
outﬁtted with a specially-reinforced protective suit for the
exploration of dangerous buildings. The system model, as
an abstraction of the real world, might not contain this in-
formation, but the policy author is aware of it. In this cir-
cumstance, our analysis system allows its user to modify the
original query (12), to introduce a constraint stating that
alice is not injured. The modiﬁed query would be:
obl(Sub, Tar, Act, Ts, Te, Tinit)
∧ not cease obl(Sub, Tar, Act, Tinit, Ts, Te, T )
∧ denied(Sub, Tar, Act, T ) ∧ Ts < T
(15)
∧ not holdsAt(injure(alice, spinal), T )
This includes the relevant constraint, as the ﬁnal literal. Its
inclusion prevents the ﬁrst solution, the abduced atoms (14),
from being found by our analysis procedure; alternative solu-
tions are explored, such as that represented by the following
sample sets of abduced atoms. First:
{ initially(at risk(house3)), initially(at(bob, street)),
happens(walk(bob, house3), 0),
happens(injure(bob, spinal), 1) }
(16)
This solution has ignored alice, and suggested that bob may
ﬁnd himself in the same situation as that represented in (14).
Another solution:
{ initially(at risk(house3)), initially(at(bob, street)),
initially(at(alice, street)), initially(injured(bob, leg break)),
happens(carry(alice, bob, house3), 0),
happens(injure(bob, spinal), 1) }
(17)
This is a diﬀerent analytic trace: both alice and bob are in
the street to start with, and bob has a leg injury. At time 0,
alice carries bob to the house which is at risk, whereupon
bob is spinally injured, and our modality conﬂict arises.
(iv) Separation of Duty. Separation of duty has been
mentioned several times in previous sections. Checking for
properties related to it follows the same pattern as for other
properties. For example, violations of dynamic SoD can be
checked with:
model(P ∪ ∆D ∪ ∆π) |=
∃T (permitted(sub, roles, activate(role a), T )
∧ permitted(sub, roles, activate(role b), T ))
This query states that there is a time at which sub is per-
mitted both to activate role A, and role B.
(v) Coverage gaps. We can also—as mentioned in the
introduction—perform coverage analysis, in which a policy
is checked, against the background of a particular system,
to see whether there are system traces in which a request
for action is not governed by policy decisions. Coverage
gap analysis has two types: the ﬁrst involves checking the
explicit policy rules for gaps, without taking into account
the default logic of the policy regulation rules; the second
adds the policy regulation rules. We make remarks on each
kind below.
The ﬁrst kind of coverage gap analysis considers situa-
tions in which a request for the performance of an action is
received, but there is no explicit permission or denial implied
by the authorization policy rules of the system. This form
of analysis can be performed using a query of this form:
model(P ∪ ∆D ∪ ∆π) |=
∃Sub, Tar, Act, T (req(Sub, Tar, Act, T )
∧ ¬permitted(Sub, Tar, Act, T )
∧ ¬denied(Sub, Tar, Act, T ))
As with the modality conﬂict analysis above, diagnostic trace
information is supplied.
Any action to be performed on a person who is explicitly
stated not to have a spinal injury, for example, will not be
covered by the set {(9), (10), (11)}; a query of, say:
req(Sub, Tar, triage, T ) ∧ not permitted(Sub, Tar, triage, T )
∧ not denied(Sub, Tar, triage, T )
(18)
∧ not holdsAt(is injured(Tar, spinal), T )
ﬁnds many answers, depending on the number of subjects
and targets in the domain.
This kind of coverage analysis concerns the absence of
what we might call explicit authorization decisions for a re-
quest for action: the case where there is no positive or nega-
tive authorization policy rule covering the case in question.
Whether or not an action is enforced by the PEP follow-
ing a request, however, is decided in our framework by the
conjunction of these authorization rules and the rules gov-
erning default availability, which have do in their head (see
Section 3.2). Thus, a situation may arise in which, whilst
there is no decision on an access request explicitly forced by
the authorization rules, the request is still allowed or denied,
because of the presence of a policy regulation rule such as:
do(Sub, Tar, Act, T ) ← not denied(Sub, Tar, Act, T ).
This leads us, therefore, to the second general type of cover-
age gap analysis: that which asks for requests which would
be allowed, but not as a result of the explicit authorization
policies, but merely as a consequence of the default permis-
sions of the system. These cases can be found by a query
such as:
req(Sub, Tar, Act, T ) ∧ not permitted(Sub, Tar, Act, T )
∧ do(Sub, Tar, Act, T ).
Again, this general form of query can be made speciﬁc to
individual users or actions, or types of users and actions.
(vi) Behavioural simulation. Note that to some degree
the example query (18) mixes coverage gap analysis with
behavioural simulation. In the latter, a typical query would
involve inputting a series of events and requests for a system
and analysing, deductively, what permissions were granted,
and what the resulting system state is. In query (18), we
specify properties of the system trace by including
not holdsAt(is injured(Tar, spinal), T )
excluding some system traces but allowing others.
A more straightforward example of behavioural simulation
is shown by considering the sample trace of do atoms given
towards the end of Section 3.4, in which an administrator
Alice assigns a number of users and permissions to roles.
Given that simulation of the behaviour of the system, a user
can query whether, for instance, Nurse Duckett is permitted
to perform an initial examination of a patient at time 2:
permitted(duckett, P, initialExamine, 2).
This would be answered negatively; although the permis-
sion for initial examinations has been assigned to the role
of medical aid by time 2, Nurse Duckett has not yet been
given the role. If the same query is posed after the system
has further evolved—say, at time 5—then the authorization
would be granted.
(vii) Policy comparison. In this form of analysis, we check
to see whether one policy is included in another, whether one
implies another, or they are equivalent, etc.
Our analysis framework allows us to test for these inclu-
sions, enabling an engineer who modiﬁes a policy to prove
whether his modiﬁcations would have an eﬀect, and whether
any added elements are, in fact, redundant. Suppose, for ex-
ample, that the current policy set is {(9), (10), (11)}, as in
our running example, and let us say that the proposed new
positive authorization rule is
[Patients in category ‘z’ are allowed to be moved]
permitted(M, Tar, move(L), T ) ←
holdsAt(category(Tar, z), T ).
(19)
Suppose the domain is such that a person is classiﬁed as
in category z if and only if they have a spinal injury. For
example, the domain description may contain the following:
initiates(injure(Tar, spinal), is injured(Tar, spinal), T ).
initiates(injure(Tar, spinal), category(Tar, z), T ).
terminates(cure(Tar, spinal), is injured(Tar, spinal), T ).
terminates(cure(Tar, spinal), category(Tar, z), T ).
In this case, adding the rule (19) to the policy would have
no eﬀect. If Π2 denotes the policy set {(9), (10), (11)}, and
Π1 denotes the set {(9), (10), (11), (19)}, with D being the
full version of our system description, including the initiates
and terminates rules above, then we would receive a positive
answer to the query Π1 ⊆D Π2, indicating that relative to
the particular system description, the rule (19) is redundant.
(Π1 ⊆D Π2 means that, given a domain description D, for
all system traces, permissions, denials, or obligations implied
by the policy Π1 are also implied by the policy Π2.)
One way of checking whether Π1 ⊆D Π2 is to relativize
the policy representation languages, so that the state regu-
latory predicates receive a subscript. Policies from Π1 would
then be written using permitted1, obl1, and so on; and poli-
cies from Π2 would be written using permitted2, obl2, etc.
Clauses which are common to all domain descriptions or se-
curity policies, such as the EC axioms or the rules giving
the meaning of fulﬁlled and violated ((1) and (2)), would
be replaced by two versions: one containing the subscript 1
on the state regulatory predicates, and one containing the
subscript 2. If the three queries:
permitted1(Sub, Tar, Act, T )
∧ not permitted2(Sub, Tar, Act, T ),
denied1(Sub, Tar, Act, T ) ∧ not denied2(Sub, Tar, Act, T ),
obl1(Sub, Tar, Act, Ts, Te, T )
∧ not obl2(Sub, Tar, Act, Ts, Te, T )
each returned no answers, given a domain description D,
this would be a proof that Π1 ⊆D Π2.
Further, as with previous forms of policy analysis, the
queries can be made as general or speciﬁc as the analysis
task demands. It is possible to ask, for instance, whether
a policy Π1 extends the obligations of users on the medical
team to move patients, compared to policy Π2, by a query
such as:
obl1(Sub, Tar, move(L), Ts, Te, T )
∧ not obl2(Sub, Tar, move(L), Ts, Te, T )
∧ not holdsAt(team(Sub, medical), T )
Further examples and system traces can be found on the
website for the implementation.
4.2
Implementation
A prototype implementation of our formal analysis frame-
work is freely available to download.6 The implementation
uses the open-source abductive constraint logic program-
ming ASystem [34]. Tests have enabled us to ﬁnd modality
conﬂicts, coverage problems, and other interesting proper-
ties of policies in conjunction with system descriptions, such
as those earlier in this section.
The ASystem is based on ﬁnite domains. For this reason,
we adapted our axioms to work on an integer base for Time,