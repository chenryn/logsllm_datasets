example, auditd records system call names issued by
speciﬁed processes, opening the log ﬁle without O_APPEND.
If this daemon is put into restartable candidates, we cannot
use them for a restartable image. To consistently run such
a daemon after a phase-based reboot, we carefully avoid
putting it in restartable candidates. We need to conﬁgure the
daemon to start after the phase-based reboot. If a user wants
to skip the boot phase of such a daemon, he or she has to
redesign the daemon to be phase-based reboot-aware. In this
case, we add O_APPEND to the open argument.
C. Recovery from Kernel Failures
To conﬁrm that the phase-based reboot can successfully
recover from kernel failures, we synthetically injected faults
into the running kernel. We measured the rate of successful
recovery from the kernel crashes, which were caused a
total of 200 times. To inject transient failures to our kernel,
we used the fault injection mechanism originally developed
at the University of Michigan. This mechanism has been
used in other studies [9], [10], [11]. Each fault changes
a single integer value on the kernel stack of a random
thread, or a single instruction, or instruction operand in
the kernel code. This emulates many common errors, such
as stack corruption, uninitialized variables, incorrect testing
conditions, incorrect function parameters, and wild writes.
We assigned 1.7 GB of memory to the guest domain.
The experimental results demonstrated that the phase-
based reboot successfully recovered from all the injected
kernel failures. Because the phase-based reboot completely
destroys the crashed memory state and constructs a fresh
state from the restartable image, the kernel failures do not
affect the phase-based reboot procedure. For example, when
the fault injection tool changed values in the stack memory
region to incorrect values and led to kernel stop error, the
phase-based reboot overwrote the memory image of the
crashed VM with the restartable image, and then the crashed
VM continued providing services. In this experiment, the
fault injection tool never injected faults that were not tran-
sient, such as a fault that writes incorrect values to the disks.
Although such kernel failures happen in the real world, they
are out of the scope of the phase-based reboot; The target
failures of the phase-based reboot are transient failures that
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:15:28 UTC from IEEE Xplore.  Restrictions apply. 
177RESTARTABLE POINTS WHEN EXECUTING PHASE-BASED REBOOT AFTER COMPLETING THE EMULATION
Table III
VM
Point A
Point B
Point C
Point D
FrontVM
AppVM
DBVM
OK
OK
OK
OK
OK
OK
OK
OK
OK
OK
OK
OK
Point E
OK
OK
/var/log/mysqld.log
/var/lib/mysql/ib_logfile
RESTARTABLE POINTS WHEN EXECUTING PHASE-BASED REBOOT DURING THE EMULATION
Table IV
VM
Point A
Point B
Point C
Point D
FrontVM
AppVM
DBVM
OK
OK
OK
OK
OK
OK
OK
OK
OK
OK
OK
OK
Point E
Depends
Depends
(/etc/httpd/logs/error_log)
(/etc/httpd/logs/error_log)
/var/log/mysqld.log
/var/lib/mysql/ib_logfile
can be recovered by a normal OS reboot.
VII. RELATED WORK
Various approaches have been proposed to reduce the
downtime stemming from a whole program restart. Microre-
boot [12] achieves ﬁne-grained software reboots. To enable
a microreboot, the target application is divided into small
independent software components which become units for
a reboot. If rebooting a small component cannot recover
from a failure, a bigger component will be rebooted. The
work aims at application-level failures, and thus, it cannot
shorten the reboot time for recovery from kernel failures.
Also, the microreboot is complementary notion to the phase-
based reboot. We can say that
the microreboot focuses
on “components” of software systems. We beneﬁt from
this when a reboot of small components recovers from
failures. On the other hand, the phase-based reboot focuses
on “phases” of software systems. We beneﬁt from this in
cases where we have to reboot larger components such as
OS kernels, which take a long time to restart.
Kexec [13] and Fast Reboot [14] allow us to quickly start
up a kernel. When they are invoked on a running kernel,
another kernel boots without any hardware reset. Since these
mechanisms require kernel support, they cannot be used
when the kernel is stopped due to kernel failures. The phase-
based reboot can work even when the kernel has crashed.
Different approaches have been proposed to recover from
kernel failures. Otherworld [9] reboots the kernel without
clobbering the state of the running applications. After the
kernel crashes and is rebooted, Otherworld restores the
application memory spaces, open ﬁles, and other resources.
However, the downtime of Otherworld is reported to be
about 1 minute. To restart
the service quickly, we use
both Otherworld and our method as the situation demands.
We should use Otherworld if the running states of the
applications are critical for recovery. On the other hand, we
should use the phase-based reboot if the running states of
applications are not critical.
Akeso [15] is a kernel-level mechanism that is request-
oriented in the sense that it handles the recovery at the re-
quest level such as system calls or interrupts. When a failure
occurs in the kernel, Akeso rolls back the kernel state to
the beginning of the function and makes the function return
an error. However, it requires a complicated annotation in
various places within the kernel code along with the context.
Writing a correct annotation requires accurate knowledge of
the kernel and is a laborious and error-prone task. The phase-
based reboot does not require any annotation and is basically
complementary to kernel-level mechanisms; the phase-based
reboot can quickly rejuvenate them to achieve more reliable
services.
Previous studies have focused on a kernel component.
Nooks [10], [16] pushes a device driver into a lightweight
protection domain and transparently recovers device drivers
when they fail. LeVasseur et al. proposed an approach to
isolating device drivers using dedicated VMs [17] to limit
the drivers’ crash inﬂuence. Membrane [18] is a kernel-level
mechanism to make ﬁle systems restartable. It periodically
saves checkpoints of ﬁle system states. If the ﬁle system
fails, Membrane restores the ﬁle system state from the recent
checkpoint and consistently and transparently updates the
stateful information to applications. These approaches focus
on certain kernel components’ failures, but the phase-based
reboot focuses on failures in any kernel component.
Some previous studies have made better use of virtual-
ization to improve the reliability of the system. Bresoud
and Schneider proposed a hypervisor-based approach to
implementing a fault-tolerant system [19]. It replicates the
state of a system remotely and recovers from failures in
a failover manner. Remus [20] is a failover mechanism that
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:15:28 UTC from IEEE Xplore.  Restrictions apply. 
178uses VMM. Remus replicates snapshots of an entire running
OS instance between a pair of physical machines. These
failover approaches basically focus on hardware failures,
while the phase-based reboot focuses on software failures
in the kernel.
CuriOS [21] recovers failed services transparently to
clients in a microkernel OS. CuriOS stores client-speciﬁc
states in client-associated but client-inaccessible memory.
When OS system servers fail, the servers use the preserved
client states to restart without affecting the clients. Vino [22]
provides a mechanism to recover from extension failures
without rebooting the OS. Vino encapsulates extensions in a
transaction to spontaneously abort them and clean up their
states. These can run on a microkernel or special formed
kernel, while the phase-based reboot is suited to commodity
OSes such as Linux.
Approaches to improving the reliability of applications
and virtual machine monitors have also been proposed.
Many techniques target application failures. Examples of
these techniques are checkpoint-restarting methods [23],
protecting the system from code injection attacks [24],
[25], diagnosing failures and patching online [26], [27],
and changing application execution environments [28].
Roothammer [29] achieves a fast VMM rejuvenation by
preserving the running VMs in memory while rebooting the
VMM. These approaches are complementary to the phase-
based reboot, whose target is kernel failures.
The phase-based reboot is also complementary to other
techniques in OS error detection sensors such as an SVA
runtime mechanism [30] and software guards used in the XFI
system [31]. These sensors can reduce our reboot recovery
latency.
VIII. CONCLUSION
We proposed a “phase-based” reboot that shortens the
downtime of reboot-based recovery. The key idea is to divide
a boot sequence into phases. The phase-based reboot reuses a
system state in the previous boot if the next boot reproduces
the same state. By doing so, it skips some phases of a
time-consuming boot sequence that reproduces the same
states as in the previous boot. A prototype of the phase-
based reboot was implemented on Xen 3.4.1 running para-
virtualized Linux 2.6.18. Experimental results showed that
the prototype successfully recovered from kernel failures
inserted by a kernel fault injector, and its downtime was
34.3 to 93.6 % shorter than that of the normal reboot-based
recovery.
REFERENCES
[1] N. Palix, G. Thomas, S. Saha, C. Calv´es, J. Lawall, and
G. Muller, “Faults in Linux: Ten Years Later,” in Proceed-
ings of the ACM International Conference on Architectural
Support for Programming Languages and Operating Systems
(ASPLOS ’11), Mar. 2011, pp. 305–318.
[2] R. C. Baumann, “Soft errors in commercial semiconductor
technology: overview and scaling trends,” IEEE 2002 Relia-
bility Physics Tutorial Notes, Reliability Fundamental, 2002.
[3] C. S. Advisory, “Cisco catalyst memory leak vulnerability.
ID:13618,” 2001.
[4] V. Castelli, R. E. Harper, P. Heidelberger, S. W. Hunter,
K. S. Trivedi, K. Vaidyanathan, and W. P. Zeggert, “Proactive
Management of Software Aging,” IBM Journal of Research
and Development, vol. 45, no. 2, pp. 311–332, 2001.
[5] C. A. Waldspurger, “Memory Resource Management
in
VMware ESX Server,” in Proceedings of the 5th USENIX
Symposium on Operating System Design and Implementation
(OSDI ’02), Dec. 2002, pp. 181–194.
[6] RUBiS:
Rice
University
bidding
system,
http://rubis.objectweb.org/.
[7] eBay.com, http://www.ebay.com/.
[8] Amazon.com, Amazon Elastic Compute Cloud (Amazon
EC2), http://aws.amazon.com/ec2/.
[9] A. Depoutovitch and M. Stumm, “Otherworld - Giving
Applications a Change to Servive OS Kernel Crashes,” in
Proceedings of the 5th European Conference on Computer
Systems (EuroSys ’10), Apr. 2010, pp. 181–194.
[10] M. M. Swift, B. N. Bershad, and H. M. Levy, “Improving
the Reliability of Commodity Operating Systems,” in Proc. of
the 19th ACM Simp. on Operating Systems Principles (SOSP
’03), Oct. 2003, pp. 207–222.
[11] W. T. Ng and P. M. Chen, “The Systematic Improvement of
Fault Tolerance in the Rio File Cache,” in Proceedings of the
1999 Symposium on Fault-Tolerant Computing (FTCS ’99),
Jun. 1999, pp. 76–83.
[12] G. Candea, S. Kawamoto, Y. Fujiki, G. Friedman, and A. Fox,
“Microreboot - a technique for cheap recovery,” in Proc. of
the 6th USENIX Simp. on Operating Systems Design and
Implementation (OSDI ’04), Dec. 2004, pp. 31–44.
[13] “Reboot
linux
http://www.ibm.com/developerworks/linux/library/l-
kexec.html.
faster
using
kexec,”
Re-
[14] Sun
boot
2008,
http://dlc.sun.com/osol/docs/content/SYSADV1/ghsut.html/.
Microsystems,
on
x86
“Using
Fast
Platform,”
the
[15] A. Lenharth, V. Adve, and S. T. King, “Recovery domains:
An organizing principle for recoverable operating systems,”
in Proceedings of the 14th ACM International Conference
on Architectural Support for Programming Languages and
Operating Systems (ASPLOS ’09), Mar. 2009, pp. 49–60.
[16] M. M. Swift, M. Annamalai, B. N. Bershad, and H. M. Levy,
“Recoverying device drivers,” in Proc. of the 6th USENIX
Simp. on Operating Systems Design and Implementation
(OSDI ’04), Dec. 2004, pp. 1–16.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:15:28 UTC from IEEE Xplore.  Restrictions apply. 
179[29] K. Kourai and S. Chiba, “A Fast Rejuvenation Technique for
Server Consolidation with Virtual Machines,” in Proc. of the
37th Annual IEEE/IFIP International Conf. on Dependable
Systems and Networks (DSN ’07), Jun. 2007, pp. 245–255.
[30] J. Criswell, A. Lenharth, D. Dhurjati, and V. Adve, “Secure
virtual architecture: A safe execution environment for com-
modity operating systems,” in Proc. of the 21st ACM Simp. on
Operating Systems Principles (SOSP ’07), 2007, pp. 31–44.
[31]
´Ulfar Erlingsson and Mart´ın and Santa Cruz and Mihai Budiu
and George C. Necula, “XFI: Software Guards for System
Address Spaces,” in Proc. of
the 7th USENIX Simp. on
Operating Systems Design and Implementation (OSDI ’06),
Nov. 2006, pp. 75–88.
[17] J. LeVasseur, V. Uhlig, J. Stoess, and S. G¨atz, “Unmodiﬁed
Device Driver Reuse and Improved System Dependability via
Virtual Machines,” in Proc. of the 6th USENIX Simp. on
Operating Systems Design and Implementation (OSDI ’04),
Dec. 2004, pp. 17–30.
[18] S. Sundararaman, S. Subramanian, A. Rajimwale, A. C.
Arpaci-Dusseau, R. H. Arpaci-Dusseau, and M. M. Swift,
“Membrane: Operating System Support for Restartable File
Systems,” in Proceedings of the 8th USENIX Conference on
File and Storage Technologies (FAST ’10), Feb. 2010, pp.
281–294.
[19] T. C. Bressoud and F. B. Schneider, “Hypervisor-based Fault-
tolerance,” in Proc. of the 15th ACM Simp. on Operating
Systems Principles (SOSP ’95), Dec. 1995, pp. 1–11.
[20] B. Cully, G. Lefebvre, D. Meyer, M. Feeley, N. Hutchinson,
and A. Warﬁeld, “Remus: High Availability via Asynchronous
Virtual Machine Replication,” in Proceedings of
the 5th
USENIX Symposium on Networked Systems Design and im-
plementation (NSDI ’08), Apr. 2008, pp. 161–174.
[21] F. M. David, E. M. Chan, J. C. Carlyle, and R. H. Campbell,
“CuriOS: Improving Reliability through Operating System
Structure,” in Proceedings of the 8th USENIX Symposium on
Operating Systems Design and Implementation (OSDI ’08),
Dec. 2008, pp. 59–72.
[22] M. I. Seltzer, Y. Endo, C. Small, and K. A. Smith, “Dealing
With Disaster: Surviving Misbehaved Kernel Extensions,” in
Proceedings of the 2nd USENIX Symposium on Operating
Systems Design and Implementation (OSDI ’96), Oct. 1996,
pp. 213–227.
[23] E. N. M. Elnozahy, L. Alvisi, Y.-M. Wang, and D. B. Johnson,
“A survey of rollback-recovery protocols in message-passing
systems,” ACM Computer Surveys, vol. 34, no. 3, pp. 375–
408, Sep. 2002.
[24] J.
extention
for
Etoh.,
applications
stack-smashing
http://www.trl.ibm.com/projects/security/ssp.
“Gcc
from
protecting
attacks,”
[25] P. Team, “Address
space layout
http://pax.grsecuirty.net/docs/aslr.txt.
randomization,” 2003,
[26] Q. Gao, W. Zhang, Y. Tang, and F. Qin, “First-aid: Surviving
and preventing memory management bugs during production
runs,” in Proc. of the 4th ACM European Conf. on Computer
Systems (EuroSys ’09), Apr. 2009, pp. 159–172.
[27] S. Sidiroglou, O. Laadan, C. R. Perez, N. Viennot, J. Nieh,
and A. D. Keromytis, “ASSURE: Automatic Software Self-
healing Using REscue points,” in Proceedings of the 14th
ACM International Conference on Architectural Support for
Programming Languages and Operating Systems (ASPLOS
’09), Mar. 2009, pp. 37–48.
[28] F. Qin, J. Tucek, J. Sundaresan, and Y. Zhou, “Rx: Treating
Bugs As Allergies - A Safe Method to Survive Software
Failures,” in Proc. of the 20th ACM Simp. on Operating
Systems Principles (SOSP ’05), Oct. 2005, pp. 235–248.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:15:28 UTC from IEEE Xplore.  Restrictions apply. 
180