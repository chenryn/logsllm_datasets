the child process and transfer the address to absolute
address. After the monitoring process sets up the per-
formance events and trace buffers, it resumes the child.
Afterwards, the two processes can run simultaneously
without any synchronization until next time the child
calls exec, so that the monitoring process has a chance
to run for security check at
the critical point. The
monitoring process and the application processes are
binded on different cores on multicore hardware, for
the purpose of further reducing interference between the
two. When the application processes further forks other
children process, the monitoring process can automati-
cally monitor them as well.
When the application starts to run, the BTS counter
generates trace of branch and writes the trace directly
into a memory buffer. Once the buffer is nearly full,
the kernel will copy the trace to user space, and the
monitoring process will start to diagnose. This batching
mode signiﬁcantly reduces the performance overhead
compared with per-sample check mode. Meanwhile,
when the application processes is trying to invoke
sensitive system calls (e.g. execve which is usually used
by a shellcode), the monitoring process will suspend
the application processes and resume it after the check.
This prevents the application processes from running
out-of-sync, which may cause harmful effects to the
system being made by attacks. The suspend time of
application processes is small since the diagnose process
is simple and effective that only utilizes a little CPU
during execution.
Once a CFI violation is detected,
the monitoring
process can take different actions according to different
requirement of applications. It may immediately kill the
application processes or email the administrator, or both.
It can also store the recent branch trace for post-attack
analysis. The administrator can know the process of the
attacking by diagnosing the trace to malicious code and
further ﬁx the vulnerability of the application.
5. Experimental Setup
All evaluations were performed on an Intel Core i5
processor with 4 cores. Each core is with 32k L1
instruction and L1 data cache and a 256K L2 data cache.
The four cores share an 6 MB L3 cache. The machine
has 2BG 1066MHz main memory, a 500GB sataII disk
of 7200 rpm, and a 100Mbps NIC. The operating system
is a Debian-6 with kernel version 2.6.34.
5.1. Security Analysis
We use several real-world applications as well as
two demo programs with the dangling pointer and
integer overﬂow vulnerabilities to evaluate the detection
ability of CFIMon, which is shown in Table 2. For
these applications with different vulnerabilities, we used
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:49:22 UTC from IEEE Xplore.  Restrictions apply. 
Application
Reference
Description
Vulnerability
Samba-3.0.21
Squid-2.5.STABLE1
GPSd-2.7
Wu-ftpd-2.6.0
Wu-ftpd-2.4.2
Bug1
Bug2
CVE-2007-2446
CVE-2004-0541
CVE-2004-1388
CVE-2000-0573
CVE-1999-0368
Demo
Demo
ﬁle and print server
cache proxy
gps device agent
ftp server
ftp server
dangling pointer
integer overﬂow
heap overﬂow
stack overﬂow
format string vul.
format string vul.
stack overﬂow
bug test program
bug test program
Injected
√
√
√
√
√
√
√
√
√
√
√
√
√
√
Attack Means
Ret-to-libc
Ret-oriented
×
√
×
×
√
√
√
TABLE 2. Security vulnerabilities for evaluation, which are exploited using three means of attacks:
code-injection (Injected), return-to-libc (Ret-to-libc) and return-oriented programming (Ret-oriented).
three types of attacks to exploit them, namely code-
injection attacks (Injected), return-to-libc attack (Ret-to-
libc) and return-oriented programming (Ret-oriented).
For Samba, GPSd and Wu-ftpd-2.6.0, as we cannot
overﬂow the stack to construct a return stack with
instruction addresses, we failed to exploit the vulner-
abilities in the three applications using return-oriented
programming. For all these attacks, we set the window
size as 20, and tolerant at most 3 suspicious branches
within the window. Evaluation for Code-Injection
Attacks: To effectively and reliably attack these appli-
cations using code-injection and ﬁnally transfer control
to injected code, we use the metasploit framework [24]
to generate nop-sled before the injected code. We attack
each application with injected code ﬁve times to test the
false negatives. As expected, all attacks are detected by
CFIMon in the evaluation and CFIMon detects these
attacks at the ﬁrst time an abnormal performance sample
is generated. During this evaluation, we simply report a
security alarm upon the detection of attacks.
Evaluation for Return-to-libc Attacks: All vulnera-
bilities that can be attacked with code-injection can also
be attacked with the return-to-libc attack. Similar to our
evaluation on code-injection attacks, CFIMon success-
fully detects all these attacks without experiencing false
negatives.
Evaluation for Return-oriented Programming At-
tacks: Similar to other evaluation, CFIMon successfully
detects all these attacks without experiencing false neg-
atives. Return-oriented programming attacks have the
following features: it uses return to organize logic and
heavily use “unintended instruction sequence” to form
code gadgets. It violates the rules of CFIMon which
enforces that the target address of a return instruction
must be the one next to a call. Even if the start address
of the ﬁrst gadget happens to be the legal target, it is
hard to make all the gadget legal. Such attacks are hard
to be applied on applications using heap overﬂow or
format string vulnerability, because we cannot modify
the stack top pointer(e.g. %esp) to our supplied return
addresses stack.
Evaluation for Jump-oriented Programming At-
tacks: The jump-oriented programming attack is similar
with return-oriented programming except it uses jump
to organize the malicious code gadgets. We didn’t make
a jump-oriented programming attack on real application.
However, we argue that since this kind of attack relies
heavily on “unintended instruction sequence”, it is likely
to issue an invalid jump instruction, which will be
captured by the CFIMon. Even if it uses all legal jump,
the branches will be marked as suspicious for their
rareness, and an alarm will be reported accordingly.
Evaluation for False Positives: We run several
typical server daemons (e.g., squid, sshd) using CFIMon
in our daily use,
to evaluate the false positives in
CFIMon. We check the log every day to see if there
are any false alarms in daily use. With several days
of monitoring, we experience no false positive in our
daily use. Thus, CFIMon could be practically used for
real-world applications in off-the-shell systems with few
false positives.
Samples
Corresponding Calls
b7e6b837->b7e6b12f
b7e6b67d->b7e6b06a
b7e6b0f3->b7effc32
b7effc97->b7effcde
b7effd60->b80ce000
process complete pdu->process request pdu
process request pdu->free pipe context
free pipe context->talloc free children
talloc free children->talloc free
talloc free->shellcode(destructor)
TABLE 3. The results of post-attack diagnosis of
code-injection attack for Samba Server
Post-Attack Diagnosis: We also use Samba Server
to demonstrate the post-attack diagnosis ability of CFI-
Mon. As shown in Table 3, CFIMon dumps the per-
formance samples with abnormal control ﬂow when
a code-injection attack is detected. By analyzing the
back traces of the attack, we can easily ﬁnd that when
calling “destructor” function pointer in “talloc free’, the
shellcode is invoked. Virtually, CFIMon can back trace
as far as the dumped samples can reach. Here only
ﬁve function records are presented which is enough for
understanding the attack.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:49:22 UTC from IEEE Xplore.  Restrictions apply. 
Application
Apache
Description
A widely used web server
Exim
Memcached
Wu-ftpd
A mail transfer agent
An object caching server
A widely used FTP server
Performance Matrix
Throughput of get/put
Latency of get
Mails per second
Throughput of values get by key
Throughput
Parameters
4 clients put 64KB ﬁles and get 1MB ﬁle
Latency of 4 clients getting 1MB ﬁle
Send 1MB mails
Use trace of Facebook
Client gets 700MB ﬁle from the server
TABLE 4. Different types of real-world applications for benchmarking
5.2. Performance Evaluation
In this section, we quantitatively evaluate the perfor-
mance of CFIMon using several real-world applications,
which many attacks target at.
Benchmark Selection: To show CFIMon can be
applied to a variety of applications with practical perfor-
mance, we choose different types of server applications,
as shown in Table 4. These applications can be divided
into two categories: 1) widely-used server side applica-
tions, including Apache Web Server, wu-ftpd and Exim
Mail Server [25]; 2) emerging applications including
Memcached [26], which is a distributed memory ob-
ject caching system widely used in many productions
systems in companies such as Facebook, Google and
Yahoo!.
Performance Results: We evaluate these benchmarks
by different performance matrix as shown in Table 4.
Figure 4 shows the relative performance overhead for
these applications, from the ﬁgure, we can see that
CFIMon incurs modest performance overhead, with
only 6.1% on average, ranging from 2.3% to 8.4%. We
also compare the overhead of CFIMon with pure BTS
(trace recording only). The overhead of pure BTS is
5.2%, which takes 86% of all the overhead of CFIMon.
The result means that CFIMon can be applied to some
real-world server applications on off-the-shell systems
in daily use.
Figure 5 shows the overhead of CFIMon when clients
get/put ﬁles of different size from/to an Apache server.
The performance overhead is less than 5% when the
ﬁle size is larger than 2MB, but increases as the ﬁle
getting smaller. This is because when the ﬁle is large,
the server is I/O-bound. But for small-size ﬁle,
the
server consumes more CPU. The throughput of apache-
put and apache-get are 42% and 15% of the original
run when the ﬁle size is 1KB, respectively. We further
broke down the overhead and found that in this case,
97% of the overhead came from the BTS itself, because
of the frequent memory write of trace buffer.
Memory Overhead: The ret set, call set and
train set of target addresses are organized in the form
of hash table. The size of the tables is quite small:
in Apache, the sum size of both is only a little more
than 200KB. Thus the memory overhead incurred by
)
%
(
d
a
e
h
r
e
v
O
e
c
n
a
m
r
o
f
r
e
P
 20
 15
 10
 5
 0
Pure BTS
CFIMon
a
p
ach
a
p
ach
a
p
ach
e-g
et
e-p
ut
e-late
cach
e
d
ncy
m
e
m
exim
w
u-ftp
d
Fig. 4. Performance overhead of CFIMon
)
I
/
R
O
S
T
B
(
t
u
p
h
g
u
o
r
h
T
 1
 0.8
 0.6
 0.4
 0.2
 0
GET
PUT
 1
 2
 4
 8
 16
 32
 64
 128
 256
 512  1024  2048  4096  8192
File Data Size (Kbytes)
Fig. 5. Performance overhead in Apache
CFIMon is negligible.
6. Implications on Hardware Enhancement
According to our experience, existing performance