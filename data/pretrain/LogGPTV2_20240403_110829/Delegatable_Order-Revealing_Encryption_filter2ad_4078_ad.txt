nels additionally to messages, then any protocol can open a
channel for each operation. Thus, we do not allow channels
for all protocols in our analysis.
Also, as noted by the authors, if L = n for 0 <  < 1, then
the amortized costs become O (1). While this is true, in our
analysis the choice of L depends on the storage volume block
size for I/O optimizations, instead of the client’s volatile
storage capacity. Thus, the costs remain logarithmic.
Search bandwidth depends heavily on the current state
of the tree. When the tree is completely unsorted (the ﬁrst
query), all elements of the tree will be transferred to split the
large root, then possibly internal node will have to be split
requiring sending of N
When the tree is completely sorted (after a large number
of uniform queries), the bandwidth will be similar to that
of a standard B+ tree — O (L logL N + r). The average
case is hard to compute; however, authors prove an upper
bound on bandwidth after n insertions and m queries —
O (mL logL n + n logL m + n logL(lg n)).
L elements, and so on, thus O (N + r).
POPE tree is not optimized for I/O the way B-tree is.
Search complexity is hard to analyze as is bandwidth com-
plexity. In the worst-case (ﬁrst query), all blocks need to be
(cid:1). In the best-case all nodes occupy ex-
(cid:1). The average case is in between and
accessed O(cid:0) N
tree O(cid:0)logL
actly one block and I/O complexity is the same as with B+
B + r
matters get worse as the node is not guaranteed to occupy
a single block due to the buﬀers of arbitrary size.
B
N
B + r
B
Client’s persistent storage is negligibly small — it stores
the encryption key. Volatile storage is bounded by L.
For practitioners we present a number of things to con-
sider. Buﬀer within one node is unsorted, so in the worst-
case, L-sized chunks remain unordered. Due to this prop-
erty, the query result may contain up to 2(L − 1) extra en-
tries, which the client will have to discard from the response.
The ﬁrst query after a large number of insertions will re-
sult in client sorting the whole N elements, and thus, POPE
has diﬀerent performance for cold and warm start. Also,
even to navigate an already structured tree, the server has
to send to the client the whole L elements and ask where to
go on all levels.
Furthermore, [58] does not stress the fact that after al-
ternating insertions and queries, it may happen that some
intermediate buﬀers are not empty, thus returning buﬀers
Table 3: Simulation results for protocols’ performance values
Protocol
I/O requests (result included)
Communication per operation (result excluded)
Volume (messages)
Size (bytes)
Construction
Query
Construction Query
Construction
Query
B+ tree w. ORE
Kerschbaum [41]
POPE [58] warm
POPE [58] cold
Logarithmic-BRC [20]
ORAM
3
494
1
—
31
44
7
300
2175
40
185
2
40
2
1
143
2
86
914
497722
2
490
177
671
32
—
342
1453
43331
9056644
391
18254
62662
between endpoints must include intermediate buﬀers as well.
The consequence is that the whole subtree is traversed be-
tween paths to endpoints, unlike the B+ tree case where only
leaves are involved.
Finally, POPE tree is not optimized for I/O operations.
Even if L is chosen so that the node ﬁts in the block, only
leaves and only after some number of searches will optimally
ﬁt in blocks. Arbitrary sized buﬀers of intermediate nodes
and the lack of underﬂow requirement do not allow for I/O
optimization.
4.4 Logarithmic-BRC
Demertzis et al. [20] introduced a novel protocol called
“Logarithmic-BRC” whose I/O complexity depends only on
the result size, regardless of the database size. The core
primitive for their construction is a Searchable Symmetric
Encryption (SSE) scheme. An SSE scheme is a server-client
protocol in which the server stores a specially encrypted
keywords-to-documents map, and a client can query doc-
uments with keywords while the server learns neither key-
words nor the documents. Note that the map stores short
document identiﬁers instead of the actual documents, and
we will use the term “documents” to mean “document iden-
tiﬁers” or “record IDs” in this section.
The construction treats record values as documents and
index ranges as keywords so that records can be retrieved
by the ranges that include them. Speciﬁcally, a client builds
a virtual binary tree over the domain of indices and assigns
each record a set of keywords, which is the path from that
record to the root. This way, the root keyword is associated
with all documents and the leaf keyword is associated with
only one record.
Upon query, a client computes a cover — a set of nodes
whose sub-trees cover the requested range. A client sends
these keywords to the SSE server, which returns encrypted
documents — result values. Of the several covering tech-
niques suggested in the protocol [20] we have chosen the
Best Range Cover (BRC), because it results in fewest nodes
and does not return false-positives. Kiayias et al. [42] have
proven that the worst-case number of nodes for domain of
size N is O (log N ) and presented an eﬃcient BRC algo-
rithm.
Security. In a snapshot setting, this construction’s security
is that of the SSE. We have used [14] and [13] SSE schemes;
their leakage in a snapshot setting is the database size and at
most some initialization parameters. Thus, the security of
these schemes is high enough to call them fully hiding in our
setting. Additional access pattern leakage comes up during
queries; exact implications of this leakage remain an open
research problem but it is known that it can be harmful [38].
4.4.1 Analysis and implementation challenges
Communication involves a client sending at worst log2 N
keywords and server responding with the exact result.
For each keyword in the query set, server will query the
SSE scheme, which will return r documents. Therefore,
server’s I/O complexity is that of SSE.
Demertzis et al. [20] have used [14] SSE scheme in their im-
plementation, but we have found it slow it terms of I/O. In-
stead, we have implemented an improved scheme [13], which
directly addresses I/O optimization.
Both SSE schemes’ I/O complexity is linear with the re-
sult size r.
[13] scheme makes at most one I/O per result
document in the worst-case and there are extensions to sig-
niﬁcantly improve I/O complexity. We have implemented
the pack extension, which packs documents in blocks to ﬁt
the I/O pages. We note that this extension can dramatically
reduce the I/Os (see Section 5.3.3 and Figure 4a).
Logarithmic-BRC is very scalable as its performance does
not depend on total data size and only degrades with the
result size. Storage overhead, however, is signiﬁcant. Each
record is associated with the whole path in the binary tree —
log2 N nodes (keywords). The storage complexity is there-
fore O (N log N ), and the overhead is then a factor of log N .
Updates, while addressed in the original protocol, are not
very practical in this construction. Authors suggest using
bulk-loading for updates, maintaining merge trees, and re-
quiring the client to do a merge once in a while. The I/O
complexity of such approach is unclear. In our implementa-
tion we perform the construction stage only in batch mode,
and thus do not include it in the analysis. We also emphasize
that the update routine was not implemented for evaluation
in the original paper.
4.5 The two extremes
To put the aforementioned protocols in a context we intro-
duce the baselines — an eﬃcient and insecure construction
we will refer to as no encryption and maximal security pro-
tocol we refer to as ORAM.
4.5.1 No encryption
This protocol is a regular B+ tree [3] without any ORE
in it. It is the construction one can expect to see in almost
any general-purpose database.
In terms of security it provides no guarantees — all data
is in the clear. In terms of eﬃciency it is optimal. B+ tree
data structure is optimal in I/O usage, indices inside nodes
are smallest possible (integers) and there is no overhead in
comparing elements inside the nodes as opposed to working
with ORE ciphertexts.
4.5.2 ORAM
Oblivious RAM (ORAM) is a construction that addition-
ally to semantic security of a snapshot setting (see Section 2)
provably hides the access pattern — a sequence of reads
and writes to particular memory locations. With ORAM
an adversary would not be able to recognize a series of ac-
cesses to the same location and will not diﬀerentiate reads
versus writes. ORAM was introduced by Goldreich and Os-
trovsky [25] who also proved its lower bound (strengthened
in [45]) — logarithmic overhead per request. A number of
eﬃcient ORAM constructions were designed (see [17] for a
good survey) and we use the state-of-the-art construction,
PathORAM [61].
A generic ORAM server responds to read and write re-
quests for a particular address. In our baseline protocol we
store B+ tree nodes in ORAM. A client works with the tree
as it normally would except each time it needs to access a
node, it communicates with ORAM.
In terms of security this protocol is fully hiding in the
snapshot model and provably hides the access pattern. We
note that one can improve security even further by adding
noise to the result obscuring communication volume. We
also note that a practitioner can use a similar protocol with
ORAM replaced with a trivial data store and have the tree
nodes encrypted.
It would be fully hiding in a snapshot
setting, but we prefer the baseline that covers more than
only the snapshot model.
In terms of performance this construction incurs some no-
ticeable overhead. Regardless of speciﬁc ORAM being used,
each access incurs at least logarithmic overhead according to
lower bounds [25]. Combined with logarithmic complexity
of the B+ tree itself, the complexity, both I/O and com-
munication, is O(cid:0)log2 N(cid:1). We found that PathORAM has
good I/O performance, as its internal tree structure trans-
lates into good cache aﬃnity. Unlike in other protocols in
our benchmark, ORAM client does most of the computa-
tional work. While the server only makes I/O requests, the
client handles encryption, shuﬄing, and request logic.
We present this protocol as a baseline solution in terms
of security over eﬃciency. We have not implemented stand-
alone PathORAM, but rather a simulator which correctly
reports I/O, communication and primitive usage. Surpris-
ingly, we found that ORAM protocol’s overhead, although
higher than in ORE-based protocols, is in-line with the most
secure protocols in our benchmark.
5. EVALUATION
All experiments were conducted on a single machine. We
use macOS 10.14.2 with 8-Core 3.2GHz Intel Xeon W pro-
cessor, 32 GB DDR4 ECC main memory and 1 TB SSD
disk. The main code is written in C# and runs on .NET
Core 2.1.3.
Interactive website
Additionally to making our source code, compiled binaries
and Docker images available, we want to let researchers
interactively run small-sized simulations. We host a web-
site [7] where one can select a protocol (including baselines,
Table 4: Simulation results for ORE primitive usage
Scheme
BCLO [8]
CLWW [18]
Lewi-Wu [46]
CLOZ [15]
Encryption Comparison
Size (bits)
41 HG
32 PRF
32 PRP
160 PRF
64 Hash
32 PRF
32 PPH
1 PRP
none
none
64
64
9 Hash
2816
1046 PPH
4096
FH-OPE [39]
1 Traversal
1 Traversal
86842
CLOZ and both SSE schemes), cache size and policy and
I/O page parameter; supply one’s own data and query sets,
and run the simulations. Simulations are run one at a time
and usually complete within seconds. The user is then able