title:Mitigating data leakage by protecting memory-resident sensitive data
author:Tapti Palit and
Fabian Monrose and
Michalis Polychronakis
Mitigating Data Leakage by Protecting Memory-resident
Sensitive Data
Tapti Palit
Stony Brook University
PI:EMAIL
Fabian Monrose
UNC Chapel Hill
PI:EMAIL
Michalis Polychronakis
Stony Brook University
PI:EMAIL
ABSTRACT
Gaining reliable arbitrary code execution through the exploita-
tion of memory corruption vulnerabilities is becoming increasingly
more difficult in the face of modern exploit mitigations. Facing this
challenge, adversaries have started shifting their attention to data
leakage attacks, which can lead to equally damaging outcomes,
such as the disclosure of private keys or other sensitive data.
In this work, we present a compiler-level defense against data
leakage attacks for user-space applications. Our approach strikes
a balance between the manual effort required to protect sensitive
application data, and the performance overhead of achieving strong
data confidentiality. To that end, we require developers to simply
annotate those variables holding sensitive data, after which our
framework automatically transforms only the fraction of the entire
program code that is related to sensitive data operations. We imple-
mented this approach by extending the LLVM compiler, and used
it to protect memory-resident private keys in the MbedTLS server,
ssh-agent, and a Libsodium-based file signing program, as well as
user passwords for Lighttpd and Memcached. Our results demon-
strate the feasibility and practicality of our technique: a modest
runtime overhead (e.g., 13% throughput reduction for MbedTLS)
that is on par with, or better than, existing state-of-the-art memory
safety approaches for selective data protection.
CCS CONCEPTS
• Security and privacy → Software security engineering.
KEYWORDS
Software Security, Data Leakage Attacks, Data Confidentiality, Side
Channel Attacks
ACM Reference Format:
Tapti Palit, Fabian Monrose, and Michalis Polychronakis. 2019. Mitigating
Data Leakage by Protecting Memory-resident Sensitive Data. In 2019 Annual
Computer Security Applications Conference (ACSAC ’19), December 9–13, 2019,
San Juan, PR, USA. ACM, New York, NY, USA, 14 pages. https://doi.org/
10.1145/3359789.3359815
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-7628-0/19/12...$15.00
https://doi.org/10.1145/3359789.3359815
1 INTRODUCTION
The continuous deployment of exploit mitigation technologies has
made vulnerability exploitation much more challenging than it
was only a decade ago [87]. It is all too telling that contestants of
the first Pwn2Own competition were individual researchers who
discovered vulnerabilities and wrote reliable exploits in a matter
of hours [37], while the winners of recent contests comprised sev-
eral teams, many of whom worked for months to develop a single
exploit [38]. Besides the widespread adoption of non-executable
memory pages [71] and address space layout randomization [70],
the principle of least privilege is better enforced in user accounts
and system services, compilers apply more protections against
buffer overflows, sandboxing is increasingly used in applications
that render untrusted input, and control flow integrity [10] and
other exploit mitigations have become commonplace in commodity
operating systems [1, 4, 31, 69, 87]. Additionally, realizing the impor-
tance of (and demand for) efficient exploit mitigations, CPU vendors
have begun providing primitives that facilitate the development of
lightweight and effective mitigations [19].
That said, the increasing complexity of reliably achieving ar-
bitrary code execution, along with high-profile incidents of data
leakage vulnerabilities (such as Heartbleed [3]), has prompted a
renewed interest into data-only attacks [35, 60, 74, 81], which were
first introduced more than a decade ago [29]. For instance, armed
with an arbitrary memory access capability, adversaries can simply
focus on leaking a user’s HTTP session cookies for cloud storage,
email, e-commerce, and other online services [74].
With the emergence of data-only attacks, protecting the data of
a process, in addition to its code, is of paramount importance. To
date, memory safety [12, 13, 27, 43, 64, 65], data flow integrity [28],
data space randomization [24], privilege separation [26, 73], en-
claves [42], and sandboxing [34, 45, 86, 91] have been proposed as
solutions for protecting in-process data from corruption or illegal
access. In practice, however, their deployment for the protection of
end-user applications has been limited, due to either their high run-
time overhead, or the significant code restructuring effort required.
To complicate matters even more, the recent spate of microarchitec-
tural attacks that leak secrets via side channels (e.g., Spectre [44],
RIDL [84], and Fallout [59]) has aptly shown that existing in-process
memory isolation technologies are not adequate for preventing sen-
sitive data leakage.
In this paper, we propose a practical approach for countering
data leakage attacks against user-space applications. The core idea
stems from the observation that, depending on the application, some
data is more critical than others. By focusing only on a subset of
data, we can achieve a low-enough runtime overhead by amortizing
the cost of the protection mechanism, while offering strong data
confidentiality. Sensitive data is always kept encrypted in memory,
and is decrypted only while being loaded into registers for carrying
out computations. Similarly, the secret key state used to encrypt
and decrypt sensitive data is always stored only in registers, and in
particular in the AVX2 [9] registers that have been available since
2013 (introduced in the Intel Haswell architecture). Consequently,
even if attackers can repeatedly read arbitrary memory (e.g., by
exercising an arbitrary read primitive through malicious JavaScript
code), any leaked sensitive data will always be encrypted.
We implemented our solution on top of the LLVM compiler, and
rely on whole-program pointer and data flow analysis at the LLVM-
IR level to pinpoint all the code points that access sensitive data, and
instrument them appropriately. A core design goal is to minimize
the effort needed to protect an application, by requiring developers
to just annotate only any initial sensitive data or data sources (e.g.,
cryptographic keys, passwords, HTTP session cookies) without the
need for further source code modifications. Sensitive data is often
not heavily propagated, thus limiting the performance overhead
associated with cryptographic operations. As such, we can protect
sensitive data with limited program instrumentation.
We empirically assess the practicality of our technique using a
set of microbenchmarks and real applications. Our results show
that the runtime overhead is modest (e.g., 13% throughput reduc-
tion for the MbedTLS SSL server when protecting its private key),
achieving performance that is on par with or better than existing
state-of-the-art memory safety approaches for selective data pro-
tection [27]. An additional benefit compared to existing memory
safety and data isolation approaches is that it offers protection
against recent microarchitectural attacks that rely on speculative
execution [44], as any leaked data always remain encrypted. At the
same time, our work highlights important challenges in the front
of whole-program fine-grained pointer analysis that leave room for
significant improvement once resolved.
Our work makes the following main contributions:
• We propose a compiler-level defense against sensitive data leak-
age attacks for user-space applications. Using whole-program
pointer and data flow analysis, our technique instruments only
the fraction of the program code needed to keep sensitive data
always encrypted in memory.
• An implementation on top of LLVM that requires only minimal
developer intervention in the form of simple code annotations
to protect the confidentiality of sensitive application data.
• An in-depth assessment that shows that we can achieve our
• An evaluation against a publicly available Spectre proof-of-
concept attack, which demonstrates how our approach protects
sensitive data against microarchitectural side-channel attacks.
goals with modest runtime overhead.
2 BACKGROUND AND MOTIVATION
After a decade-long hiatus since the introduction of data-only at-
tacks [29], several advancements that demonstrate their power have
been brought to light [35, 40, 41, 60, 61, 74, 81]. These works take
advantage of memory disclosure vulnerabilities to access arbitrary
memory and subsequently provide adversaries with powerful ca-
pabilities [15, 22, 46, 48, 52, 77]. Heartbleed [3] is a recent example
that demonstrates how the ability to read arbitrary memory can be
used to leak sensitive application data, such as private keys.
To protect sensitive in-memory data from leakage, it is thus im-
portant to consider the adversarial capabilities enabled by memory
disclosure vulnerabilities, especially when combined with scripting
support [74]. Unfortunately, application sandboxing protections
(or sandboxing policies enforced through SFI [86], XFI [34], or data
sandboxing [91]) cannot protect against these attacks, as data leak-
age still occurs within the enforced boundaries. On the other hand,
stricter data isolation policies, such as data flow integrity (DFI) [28]
do protect against data-only attacks, but incur a prohibitively high
runtime overhead (e.g., 104% for the SPEC benchmarks).
Another mitigation against data-only attacks is to change the rep-
resentation of in-memory data, by always keeping it transformed
and restoring its original representation only when it needs to take
part in some computation. As an initial exploration of this idea,
Bhatkar and Sekar [24] proposed an approach for XOR-ing data
objects with a random per-object “key” that is kept alongside each
object in memory. Under the stronger disclosure-aided exploitation
threat model, however, this form of data space randomization does
not offer adequate protection, as the key cannot be kept secret.
Moreover, the runtime overhead—due to the necessity of XOR op-
erations before and after each and every memory access to each
and every object—is prohibitively high.
In this work, we revisit the idea of data space randomization,
but with the goal of achieving stronger protection even under arbi-
trary memory read capabilities. As simple XOR-ing can be defeated
by comparing known data with its transformed version, we use
stronger encryption without introducing substantial computational
overhead [58]. To that end, we leverage the AES-NI instruction set
extensions for hardware-accelerated AES computations, along with
the AVX2 [9] registers for storing the expanded round keys for each
AES operation.
In comparison to existing memory safety and data flow integrity
approaches, which instrument the entire program to prevent ar-
bitrary access to the protected data, our sensitive data protection
approach instruments only the fraction of instructions involved
in sensitive data flows and operations, and ignores the rest of the
memory-related instructions—these may still illegally access the
protected data, but only in its encrypted form.
In comparison to existing approaches based on privilege sepa-
ration [26, 73], hardware-based protection [36, 62, 85] or enclave
solutions like SGX [17, 25, 53, 76, 82], our approach does not require
any code refactoring or rewriting, besides a simple annotation of
existing data variables or data sources.
3 THREAT MODEL
We consider the broad class of memory disclosure or corruption
vulnerabilities that give adversaries the capability to read (i.e., leak)
arbitrary user-space memory. We assume that due to the nature of
the vulnerability (e.g., as was the case with Heartbleed [3]), or due
to the deployment of exploit mitigation mechanisms, immediate
arbitrary code execution is not possible, and thus the adversary is
constrained in mounting some form of data-leakage attack. The
attack may be facilitated by the execution of malicious script code
that leverages the disclosure vulnerability to repeatedly access arbi-
trary memory [74]. Because adversaries do not have arbitrary code
execution capabilities, however, they cannot disclose the sensitive
data and the expanded round keys stored in registers.
Although the end goal of some advanced data-only attacks is to
modify configuration or control data [35, 61], our approach is tai-
lored to defending against data leakage attacks, which still comprise
an important sub-class of data-only attacks [3, 74]. In this work, we
focus on maintaining the confidentiality of sensitive data, but the
integrity of such data may not be fully protected. Specifically, the
encryption scheme we utilize offers some level of protection against
data modification attacks, but cannot prevent certain attacks that
rely on replacing data with other already encrypted values. We
discuss in detail such attacks, along with the challenges of fully
guaranteeing data integrity, in Section 7.
We focus on the protection of user-space applications, and thus
assume that adversaries do not have access to any kernel-level
code or data. Nonetheless, we assume that the attacker can perform
cold boot attacks. Because all sensitive data is present in RAM
in encrypted form, and the secret round keys are present only
in registers, the attacker can not recover the plaintext by simply
reading the physical memory.
With respect to the recent wave of CPU side channel attacks
that allow arbitrary memory access from user space, our solution
does not protect against Meltdown [54], as protecting kernel at-
tacks is out of scope. However, it does offer effective protection
against Spectre [44] and similar microarchitectural attacks based
on speculative execution. Spectre attacks leak arbitrary data that
has been loaded into the cache within the scope of a user-space
process. Thus, these attacks will access protected data only in its
AES-encrypted form.
4 DESIGN
The proposed approach aims to strike a balance between the manual
effort required to enable the protection of sensitive application data,
and the performance overhead of the data protection mechanism
itself. Existing application-level isolation technologies such as priv-
ilege separation [26, 73], enclaves [42], and sandboxing [34, 86, 91],
have a relatively low performance impact, but require an immense
code refactoring effort. As part of this process, one must identify
and move the sensitive data (and all associated critical-path code)
into the protected domain, and implement appropriate interfaces
with the rest of the application code.
By contrast, we merely require developers to annotate sensi-
tive data in the source code, without requiring any further code
modifications. Before any computation is performed, the data is
first decrypted and stored in a register, which is the only location