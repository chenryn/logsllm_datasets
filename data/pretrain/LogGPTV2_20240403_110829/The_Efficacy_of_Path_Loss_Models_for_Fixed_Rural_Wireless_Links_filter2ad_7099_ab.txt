o
a
t
a
h
g
t
a
.
g
n
i
r
r
e
h
0
0
0
2
t
m
i
m
e
t
m
t
i
5
2
r
u
t
i
2
5
4
r
u
t
i
i
n
a
r
r
e
t
.
u
t
i
a
t
a
h
.
l
a
r
u
r
i
a
u
s
y
a
r
o
w
t
Fig. 2. Overall model performance as described by (residual) root mean squared error
(RMSE) and spread-corrected RMSE (SC-RMSE). Spread corrected error is adjusted
(reduced) by the expected measurement spread on a given link.
In this work, we pay little attention to these coverage requirements because we
observe that they are not largely followed in the literature (the Longley-Rice
Irregular Terrain model, in particular, is frequently used well outside of its in-
tended coverage). In this study both appropriate and “inappropriate” models
are given an equal chance at making predictions for our network. We have no
starting bias about which should perform best.
5 Results
Pr = Pt + Gt(θ) + Gr(φ) − ˆL
To obtain results, we ask each model to oﬀer a prediction of median path loss for
each link in our network. The model produces an estimate of the loss ˆL which we
combine with known values to calculate the predicted received signal strength
Pr:
(2)
Where Gt is the antenna gain of the transmitter in the azimuthal direction
(θ) of the receiver and Gr is the antenna gain of the receiver in the azimuthal
direction (φ) of the transmitter. These gains are drawn from measured antenna
patterns (one for each type of antenna)[2]. The transmit power (Pt) is set to
18 dBm for all nodes, which is the maximum transmit power of the Atheros
radios our nodes use. For a given link, we calculate the median received signal
strength value across all measurements ( ¯Pr). Then, the prediction error, , is the
diﬀerence between the prediction and the median measured value:  = ¯Pr − Pr.
Some models come with tunable parameters of varying esotericism. For these
models, we try a range of reasonable parameter values without bias towards
which we expect to be best. To conserve space, in the following discussion and
ﬁgures we show results from only the 27 best performing models/conﬁgurations.
Figure 2 provides the overall performance of each algorithm in terms of
its RMSE. To account for underlying variance in the measurements, we use
a “spread corrected” RMSE (ˆ) where the link’s measured standard deviation
(¯σ) is subtracted from the prediction error: ˆ = || − ¯σ. This corrected RMSE
48
C. Phillips et al.
Model Performance for All Links
% Links This Model is Best
% Links This Model is within one Standard Dev of Oracle
% Links This Model is within Two Standard Devs of Oracle
)
%
(
s
k
n
L
i
f
o
t
n
e
c
r
e
P
25
20
15
10
5
0
i
n
o
t
r
e
b
0
0
2
k
o
o
r
b
e
s
a
l
i
t
s
u
q
m
o
b
l
m
1
3
2
t
s
o
c
s
n
o
s
d
v
a
d
i
L
M
H
a
z
u
o
s
e
d
l
3
3
c
c
e
s
d
r
a
w
d
e
i
l
g
e
a
g
e
c
r
e
2
s
i
i
r
f
n
e
e
r
g
0
1
e
g
d
e
t
a
l
f
i
l
g
e
.
m
a
t
a
h
e
g
d
e
t
a
l
f
.
m
a
t
a
h
m
a
d
e
.
e
g
d
e
t
a
l
f
.
m
a
a
h
t
Model Name
m
a
d
e
.
o
a
t
a
h
c
f
.
o
a
t
a
h
g
t
a
.
g
n
i
r
r
e
h
0
0
0
2
t
m
i
m
e
t
m
t
i
5
2
r
u
t
i
2
5
4
r
u
t
i
i
n
a
r
r
e
t
.
u
t
i
a
t
a
h
.
l
a
r
u
r
i
a
u
s
y
a
r
o
w
t
Fig. 3. Competitive and Individual Performance. Competetive performance is the per-
centage of links a given model is the best predictor for. Individual performance is the
percentage of links a model makes a prediction within one (or two) standard deviations
of the correct value.
gives an idea of error in excess of expected variance due to temporal variation
(i.e., fast-fading and intrinsic/diurnal periodicity)2. As we can see, the best per-
forming models achieve an RMSE on the order of 15 dB. The best models are
the Alsebrook model (with its terrain roughness parameter set to 200m) at just
under 18 dB RMSE (16.7 dB when corrected), and the Flat-Edge model (with
10 “buildings” presumed) at 16.5 dB RMSE (15.3 dB when corrected)3.
Figure 3 provides two domain-oriented metrics that describe models’ com-
petitive and individual “goodness”. The competitive metric is the percentage of
links that a given model produces the best prediction for (and hence sums to
100). We can see that no given model dominates the competition—the honor
of best prediction is spread fairly evenly among half a dozen models that each
achieve the best prediction between 10 and 15 percent of the time. The other
metric is an individualistic deﬁnition of success—the percentage of links a given
model’s prediction is within the expected spread (measurement standard devi-
ation). The best performing models are “correct” 10% of the time using this
metric. If we lower the bar to making a prediction within two standard devi-
ations of the measured median value, the best performing models (Egli, Friis
(with α = 2), Flat-Edge, ITM, ITU Terrain, and Two-Ray) achieve between 10
and 15% correct.
Figure 4 plots our next metric: ability to order links. In some applications
it may be suﬃcient for a propagation model to order two or more links by
strength. In this scenario, we imagine that the predicted path loss isn’t itself
expected to be absolutely correct, but instead simply a relational performance
compared to other links in the same network. In this ﬁgure, we plot Spearman’s
non-parametric rank order coeﬃcient ρ for each model. For this metric, a value of
2 Although we are careful to correct for this measurement variation, it is on the whole
rather small: 1.31 dB median standard deviation and 1.67 dB at the third quantile.
3 Some models perform substantially better when we consider only the fraction of
cases that are in their intended coverage. The ITM, for instance, has a competitive
spread-corrected RMSE of 17.3 dB when only error-free predictions are considered.
On The Eﬃcacy of Path Loss Models
49
Rank Correlation for All Links and All Models
’
o
h
r
s
n
a
m
r
a
e
p
S
0.45
0.40
0.35
0.30
0.25
0.20
2
s
i
i
r
f
5
2
r
u
t
i
2
5
4
r
u
t
i
L
M
H
a
z
u
o
s
e
d
0
0
2
k
o
o
r
b
e
s
a
l
c
f
.
o
a
t
a
h
i
l
g
e
0
0
0
2
t
m
i
0
1
e
g
d
e
t
a
l
f
s
n
o
s
d
v
a
d
i
n
e
e
r
g
m
1
3
2
t
s
o
c
i
a
u