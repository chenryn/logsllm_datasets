max
(MB)
3.7
24.4
18.7
22.9
2,147
25.7
4.9
24.9
5,010
143
Table 6: HTTP content types by byte counts (in GB), as well as
mean (in KB) and max (in MB) object sizes.
in EC2, and nearly 100% of the HTTP ﬂows in Azure; a long tail
follows for both clouds (CDF excluded for brevity).
Flow sizes and durations generally appear to ﬁt heavy-tailed dis-
tributions (we omit durations in Figure 3 for brevity); similar prop-
erties have been observed for ﬂows in other networking contexts
(e.g., in data centers [21]). We note interesting differences between
HTTP and HTTPS: in particular, HTTPS ﬂows are larger and last
longer than HTTP ﬂows across both EC2 and Azure (e.g., median
sizes for EC2 are 10K and 2K, respectively). This is expected given
our observation that a large percentage of HTTPS trafﬁc is from ﬁle
storage services. In both cases, we see large ﬂows that are more
than a few MB in size and long ﬂows that last for a few hours.
Content types. We next look at the types of content served by web-
facing cloud tenants. We use Bro to extract the Content-Type and
Content-Length ﬁelds from replies in HTTP ﬂows. Unfortunately,
we cannot extract these details for HTTPS ﬂows because the HTTP
headers are encrypted. The top content types, by byte count, for
HTTP ﬂows are shown in Table 6, along with the mean and max
content sizes. About half of all content is html or plain text, and
these type of objects are generally smaller in size. The majority of
the remaining content is a mixture of images, Flash, generic binary
data (i.e., octet-stream), PDFs, and XML; these objects are gener-
ally much larger. This suggests that EC2 and Azure HTTP trafﬁc
is primarily conveying web sites, and not (say) for ﬁle transfer. We
see that some objects can be very large in size; e.g., we see binaries
that are 5GB in size, and even some plain text ﬁles that are as large
as 24MB.
Summary and Implications. We ﬁnd that most ﬂows arise from
the top few domains. A majority of the ﬂows are short, and HTTPS
ﬂows are generally larger in size and last longer than their HTTP
counterparts. Most web services appear to be using the cloud to
serve html or plain text content. These observations have impli-
cations for content delivery systems targeted toward cloud-resident
services. For instance, the predominance of plain text and HTML
trafﬁc (as opposed to compressed images, binaries, videos, etc.)
points to the fact that compression could be employed to save WAN
bandwidth and improve content delivery latency [18].
4. TENANTS’ DEPLOYMENT POSTURE
In this section, we attempt to understand how tenants use the
cloud for deploying their front ends. We start by analyzing the de-
ployment patterns employed by cloud-using (sub)domains. We ﬁrst
focus on the four patterns identiﬁed in Figure 1. We then quantify
how many, and which, regions and availability zones are leveraged
by cloud-using (sub)domains’ front ends.
4.1 Deployment Patterns
In this section, we use the DNS records from our Alexa sub-
domains dataset and a variety of heuristics to detect and quantify
usage of the deployment patterns outlined in Figure 1. Speciﬁ-
cally, we estimate the use of virtual machines (VMs), platform-as-
a-service (PaaS) environments, load balancers, content-distribution
networks (CDNs), and domain name servers within the front ends
of web services hosted in both EC2 and Azure. In general, we dis-
cuss EC2 and Azure separately because of differences in the cloud
architectures.
(a) Virtual machine instances
(b) Physical ELB instances
Figure 4: CDFs for the # of feature instances per subdomain (only
includes subdomains which use the feature).
Figure 5: CDF of the # of DNS servers used per subdomain.
VM front end in EC2. Each VM instance in an IaaS cloud com-
bines a set of virtual resources (CPU core(s), memory, local stor-
age, and network bandwidth) whose capacity depends on the in-
stance type. In EC2 each instance is assigned an internal IP address
within a region-speciﬁc private network; EC2 tenants may option-
ally assign a public (i.e., Internet-routable) IP address to a VM.
We identify usage of VMs as directly-reachable web service front
ends—i.e., deployment pattern P1 (Figure 1a)—by examining if
the DNS query for an EC2-using subdomain directly returns an IP
address (instead of a CNAME), which we then associate with a VM
instance. We ﬁnd that 505,578 (72%) EC2-using subdomains lever-
age front end VMs. Figure 4a shows a CDF of the number of front
end VM instances used by each EC2-using subdomain; this CDF
only includes subdomains which use front end VMs. We observe
that about half of such subdomains use 2 front end VMs and 15%
use 3 or more front end VMs.
Aggregating by domain, we ﬁnd that 52% of EC2-using domains
have at least one subdomain which uses at least one front end VM.
If we sum the number of front end VMs used across all subdomains
of a given domain, we ﬁnd that 10% of domains which use front end
VMs in EC2 use 3 or more front end VMs in total.
PaaS front end in EC2. PaaS systems offer a hosted environ-
ment for deploying web applications, avoiding the need for ten-
ants to manage low-level system details. PaaS systems are fre-
quently built atop existing IaaS infrastructure: e.g., Amazon’s Elas-
tic Beanstalk [5] and Heroku [14] both run atop EC2. A Beanstalk
environment always includes an Amazon Elastic Load Balancer
(ELB) instance (discussed in more detail below), reﬂecting deploy-
ment pattern P2 (Figure 1b, replace VMs with PaaS nodes). A
Heroku environment may or may not include an ELB, reﬂecting
usage of deployment patterns P2 or P3 (Figure 1), respectively.
We say that a subdomain uses Beanstalk or Heroku if the subdo-
main’s DNS record has a CNAME that (i) includes ‘elasticbeanstalk’
or any of ‘heroku.com’, ‘herokuapp’, ‘herokucom’, and ‘herokussl’
and (ii) resolves to an IP in EC2’s public IP address range. In the
case of Heroku without ELB, the IPs to which the CNAME resolves
represent PaaS nodes; we associate these IPs with the subdomain
whose DNS record contains the corresponding CNAME.
A total of 201,666 (28%) EC2-using subdomains in our Alexa
subdomains dataset contain a CNAME in their DNS record. Ap-
plying the above ﬁlters for PaaS, we ﬁnd that 60,273 (8%) EC2-
using subdomains use a front end PaaS environment in EC2. Of
these, over 97% (59,991) are using Heroku; only 3% use Elastic
Beanstalk. Amazon always includes an ELB in a Beanstalk envi-
ronment, but Heroku only sometimes leverages ELBs—only 3% of
subdomains (1,850) which use Heroku also use ELB. We therefore
conclude that, in the case of EC2, PaaS systems are predominantly
used according to deployment pattern P3 (Figure 1c).
We now focus on the 58,141 (59,991 - 1,850) subdomains that
use Heroku without ELB. We ﬁnd that these are associated with
just 94 unique IPs. Although we have no insight into the number of
worker instances used by Heroku, this shows that Heroku is multi-
plexing PaaS functionality among a relatively large number of sub-
domains: in particular, we ﬁnd that about one-third of subdomains
using Heroku share the CNAME ‘proxy.heroku.com’.
Load balancer front end in EC2. Load balancers divide trafﬁc
among a set of “worker” VMs or PaaS nodes, as reﬂected in de-
ployment pattern P2 (Figure 1b). Amazon Elastic Load Balancers
(ELBs) [13] are Amazon-managed HTTP proxies. An EC2 tenant
requests an ELB in a speciﬁc region and subsequently associates
VM instances, in one or more zones, with this ELB. The ELB auto-
matically round-robins requests among zones and among the VMs
in each zone. In fact, trafﬁc is routed to zone-speciﬁc ELB proxies
by rotating the order of ELB proxy IPs in DNS replies. ELB can
also be used with PaaS, as discussed above.
When a subdomain uses an ELB, the subdomain’s DNS record
contains a CNAME ending in ‘elb.amazonaws.com’; the CNAMEs
resolve to IP addresses for one or more ELB proxies. We identify
ELB-using subdomains in our Alexa subdomains dataset based on
the presence of such CNAMEs; we refer to each distinct CNAME
as a “logical ELB instance”. We also associate with the subdomain
the IPs of the speciﬁc ELB proxies to which the CNAME resolves;
we refer to these as “physical ELB instances”.
We ﬁnd that 27,154 (4%) EC2-using subdomains use ELB as
their front end. Of the subdomains that use ELB, 280 (1%) use
it in the context of Elastic Beanstalk and 1,850 (6.8%) use it with
Heroku. Aggregating by domain, we ﬁnd that 9,851 (26%) EC2-
using domains use front end ELB(s).
Across all ELB-using subdomains, we observe 15,703 physical
ELB instances (i.e., distinct IPs associated with ELB CNAMEs).
Hence, while each subdomain has its own logical ELB(s), the phys-
ical ELB proxies that perform the actual load balancing appear to
be shared across multiple, even unrelated, subdomains. In particu-
lar, we analyzed the number of subdomains per physical ELB and
found that ≈4% of the physical ELB instances are shared by 10 or
more subdomains.
Figure 4b shows a CDF of the number of physical ELB instances
associated with each subdomain; this CDF only includes subdo-
mains which use ELB. We observe that about 95% of ELB-using
subdomains are associated with 5 or fewer physical ELB instances.
A few ELB-using subdomains (e.g., dl.outbrain.com and m.netﬂix.
com) use many physical ELB instances: 58 and 90, respectively.
Front ends in Azure. Azure’s architecture differs from EC2 inso-
far as clients cannot distinguish whether a web service uses a VM,
PaaS, or load balancer front end. In Azure, VMs and PaaS environ-
ments are both encompassed within logical “Cloud Services” (CS).
An individual CS may contain (i) a single VM, (ii) a collection of
related VMs, or (iii) a PaaS environment. Each CS is assigned a
unique DNS name ending with ‘cloudapp.net’ and a correspond-
ing public IP address. Trafﬁc sent to this public IP goes through
a transparent proxy—which performs NAT and, optionally, load
balancing—before directing trafﬁc to a VM or PaaS node. Thus,
a CS may reﬂect deployment patterns P1, P2 (with VMs or PaaS
nodes), or P3 (Figure 1), all of which appear the same from a client
perspective.
We examine the DNS records for Azure-using subdomains in the
Alexa subdomains dataset to identify subdomains which use a CS
(i.e., VM, PaaS, or load balancer) front end.
If the DNS query
for an Azure-using subdomain either directly returns an IP address
or returns a CNAME ending in ‘cloudapp.net’, then we say the
subdomain uses a CS front end. We associate the directly returned
IP or the CNAME, and its corresponding IP, with a CS instance.
A total of 1,153 (17%) Azure-using subdomains directly resolve
to an IP address and 5,404 (82%) Azure-using subdomains contain
a CNAME in their DNS record. Applying the above ﬁlters for CS,
we ﬁnd that 4,581 (70%) Azure-using subdomains use a CS front
end. Aggregating by domain, we ﬁnd that 57% of Azure-using
domains have at least one subdomain which uses a CS front end.
Azure also offers a unique feature (which has no parallel in EC2)
for load balancing across front ends: Azure Trafﬁc Manager (TM)
[9] uses DNS to direct trafﬁc to different CSs, which may be spread
across multiple regions. TM can, based on a tenant’s preference,
do performance-based load balancing (ﬁnding the CS closest to
the client), failover load balancing (picking the next active CS), or
simple round-robin load balancing. When a subdomain uses TM,
its DNS record contains a CNAME ending in ‘trafﬁcmanager.net’,
similar to ELB. However, TM performs all load balancing using
DNS—unlike ELB which uses a combination of DNS and physi-
cal proxies—so TM CNAMEs resolve directly to a CNAME for a
speciﬁc CS (e.g., ‘abc.cloudapp.net’). We ﬁnd that only 100 (2%)
Azure-using subdomains (corresponding to 52 domains) use TM.
The aforementioned CNAME-based ﬁlters for ELB, Beanstalk,
Heroku, CS, and TM were not applicable to 116,323 (16%) EC2-
using subdomains, and 1,938 (30%) Azure-using subdomains. We
are investigating techniques to understand the deployment patterns
underlying these subdomains.
Content distribution networks. We now focus on the use of CDNs,
which we illustrated in deployment pattern P4 (Figure 1d). Note
that CDNs can be employed alongside any of the other three de-
ployment patterns.
Both Microsoft and Amazon run their own CDNs, which we fo-
cus on studying. Amazon’s CloudFront CDN [3] uses a different
public IP address range than the rest of EC2. Hence, we determine
if a subdomain uses CloudFront by observing if its DNS records
contain one or more IPs in CloudFront’s IP range. Azure’s CDN [7]
uses the same IP address ranges as other parts of Azure, so we de-
tect whether a subdomain uses the Azure CDN based on whether a
subdomain’s DNS records contain CNAMEs with ‘msecnd.net’.
We ﬁnd 7,622 subdomains (corresponding to 5,988 domains) use
CloudFront and 68 subdomains (corresponding to 54 domains) use
Azure’s CDN. Despite the much smaller number of domains using
Azure’s CDN, there is still a signiﬁcant volume of trafﬁc associated
with msecnd.net in our packet capture dataset (Table 5). Azure’s
CDN is clearly being used within some Microsoft properties, per-
haps to host embedded content or cookies.
Domain name servers. The ﬁrst step in accessing a cloud-resident
service is to resolve its name (Figure 1). In what follows, we exam-
ine cloud-resident subdomain’s use of DNS, focusing on the extent
to which they rely on cloud providers for DNS services as well.
We identifed the “location” of a cloud-using subdomain’s au-
thoritative name server(s) as follows: For each DNS record associ-
ated with a given subdomain in our Alexa subdomains dataset, we
extract all the domains speciﬁed in the NS records. We then per-
formed a DNS lookup on each of these domains from 50 globally-
distributed PlanetLab nodes. We ﬂushed and reset the cache of
Cloud
Feature
VM
ELB
EC2
BeanStalk (w/ ELB)
Heroku (w/ ELB
Heroku (no ELB)
Azure
CS
TM
9.9K (25.9%)
# Domains # Subdomains # Inst.
19.9K (52.5%) 505.6K (71.5%) 28.3K
27.1K (3.8%) 15.7K
455
2.4K
94
790
78
188 (0.5%) 280 (< 0.01%)
1.9K (0.3%)
622 (1.6%)
58.1K (8.2%)
1.3K (3.5%)
4.5K (68.3%)
863 (37.0%)
52 (2.2%)
100 (1.5%)
Table 7: Summary of cloud feature usage.
Rank
Domain
# Cloud
ELB Use
Subdom VM PaaS ELB IPs CDN
Front-end
9
13
29
35
36
38
42
47
48
51
amazon.com
linkedin.com
163.com
pinterest.com
fc2.com
conduit.com
ask.com
apple.com
imdb.com
hao123.com
2
3
4
18
14
1
1
1
2
1
0
0
0
4
10
0
1
1
0
0
1
1
0
0
0
1
0
0
0
0
2
1
0
0
4
1
0
0
0
0
27
1
0
0
68
3
0
0
0
0
0
0
4*
0
0
0
0
0
1
1*
Table 8: Cloud feature usage for the highest ranked EC2-using do-
mains (* indicates use of a CDN other than CloudFront).
the local resolver between each DNS lookup, and we added the
‘norecurse’ ﬂag to each DNS query to minimize the inﬂuence of
caching. We compare the resulting IP addresses to the public IP
address ranges for EC2, CloudFront, and Azure.
We observe a total of 23,111 name servers supporting the 713K
cloud-using subdomains in our Alexa subdomains dataset. Many
subdomains use the same name servers, leading to a smaller set
of name servers than subdomains. Figure 5 shows a CDF for the
number of name servers used by each cloud-using subdomain; we
observe that nearly 80% of subdomains use 3 to 10 name servers.
We categorize the name servers as follows: 2,062 were hosted in
CloudFront, which appears to host Amazon’s route53 DNS service
as many of these name servers had ‘route53’ in their domain name;
1,239 were running inside EC2 VM instances; 22 were hosted in-
side Azure VM instances or Azure CS; and 19,788 were hosted
outside any of EC2, CloudFront, or Azure;
The above analyses are summarized in Table 7 which shows
how many (sub)domains in our Alexa subdomains dataset use each
cloud feature. We also show the number of instances (identiﬁed by
IP address) of that feature.
Analysis of top domains. As notable exemplars, Table 8 gives a
detailed breakdown of the cloud feature usage of the most popu-
lar (according to Alexa rankings) EC2-using domains. We observe