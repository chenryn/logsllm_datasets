pick 5 website domains from each Alexa Toplist of the associated Top-Level
Domain (.us, .de, .co.uk, etc.), resulting in 50 region-focused domains. Note
that sampling the entire 1M domains does not improve representativeness, since
we repeat the measurements over a period of one week and expect records to be
cached. Also, the known instability of the Alexa Toplist [33] does not substan-
tially inﬂuence our measurements: We construct the list of overall 200 domains
196
T. V. Doan et al.
Table 1. Overview of measured resolvers together with the number of failed requests,
total requests, and failure rates for both Do53 and DoT. Failure rates for DoT are higher
compared to Do53 for each resolver, with failure rates also being lower for public DNS
services than local resolvers. Highlighted cells are referred to in Sect. 4.
(from July 01, 2019) to investigate whether there are larger diﬀerences between
bins of more popular and less popular domains, or in terms of Top-Level Domain
(TLD) and probe location. However, we do not ﬁnd any signiﬁcant deviations in
terms of response times, neither regarding popularity rank nor TLD. Thus, we
do not further distinguish between individual domains in the analysis.
With this experiment setup, we collect measurements for around 90M DNS
requests from home probes in total (see Table 1).
4 Reliability
We investigate the reliability of Do53 and DoT by analyzing the failure rate,
which we deﬁne as the relative number of failed queries to the total number of
queries. A query is deﬁned as failed if the domain lookup could not be sent to the
resolver or the probe did not receive a response; in both cases, the RIPE Atlas
API will return an error. Table 1 shows the overall failure rate, as well as the
failure rate by resolver, for both Do53 and DoT. Note that we exclude 33 probes
which failed nearly all of their DoT measurements (see error analysis below)
from all following analyses. Further, only 2,718 probes of the 3.2k home probes
successfully receive a Do53 response from local resolvers, i.e., the remaining
Measuring DNS over TLS from the Edge
197
probes cannot resolve a domain using a local resolver (but can with a public
resolver). Considering DoT, we ﬁnd that only 13 probes receive responses from
their local resolver via DoT, which means that DoT is only supported by 0.4%
of the local resolvers. We exclusively see these DoT-supporting local resolvers
(discussed in more detail in Sect. 5) in EU (11 probes) and NA (2 probes). As
such, we separate the queries to local resolvers (by probes with and without
DoT-supported local resolvers) in Table 1 and this subsection.
Overall Failure Rates. The overall failure rate for Do53 is 7.9%, with individ-
ual failure rates of 0.8–1.5% for most resolvers, whereas the overall failure rate
for DoT is much higher at 22.9%, i.e., a diﬀerence of 15.0% points (p.p.). How-
ever, the total failure rates are heavily inﬂuenced by a few resolvers exhibiting
particularly high failure rates of close to 100%: For instance, 98.2% of the Do53
requests to Neustar UltraRecursive fail, accounting for 76.4% of the Do53 failure
rate in total. For DoT, UncensoredDNS accounts for 84.7% of all DoT failures
with an individual failure rate of 97.2%; local resolvers with DoT support have
an overall DoT failure rate of 39.4%.
Individually, the Do53 failure rate is between 0.8% and 2.5% for all public
resolvers when disregarding Neustar. Local resolvers encounter failures in 11.2%
of the cases instead (7.2% for probes with DoT-supported local resolvers).
We observe an inﬂation of failure rates when moving from Do53 to DoT
for all DoT resolvers: Inﬂations range from 0.4 and 0.5 p.p. for Google and
Cloudﬂare, over 1.5 p.p. for Quad9 and 9.4 p.p. for CleanBrowsing, to 95.7 p.p.
for UncensoredDNS; local resolvers with DoT support show an inﬂation toward
the higher end with 32.2 p.p. Overall, these numbers suggest that DoT support
on the paths is still experimental and, therefore, varying concerning reliability.
Error Analysis. Regarding the respective error messages, we ﬁnd that most
failures are attributed to timeouts (5 s), socket errors, and connect() errors (con-
nection refused/reset, network unreachable). For Do53, nearly all failed requests
toward Neustar (>99.9%) are due to timeouts. DoT measurements show a sig-
niﬁcant amount of TUCONNECT errors, which are exclusive to DoT and suggest
TLS negotiation errors. To further investigate this, we count the number of
TUCONNECT errors for each combination of probe and public resolver; we exclude
UncensoredDNS from this analysis due to its high failure rate overall (which
indicates server-side issues). For all combinations of 3.2k probes × 4 resolvers,
we ﬁnd repeated TUCONNECT errors for 33 probes across all resolvers where the
probes fail nearly all scheduled 1.4k DoT measurements (200 domains × 7 days).
This indicates blackholing of DoT packets closer to these probe (home router
or in the ISP network). Although the number of aﬀected probes is negligible
(≈1%), we have excluded the aﬀected 33 probes from the previous and following
analyses. We further investigate TUCONNECT errors and ﬁnd a higher number of
probes failing nearly all DoT measurements for Cloudﬂare in particular, which
aﬀects 99 probes. The diﬀerential of 66 probes between these two groups show
no errors for the other resolvers, suggesting DoT blackholing closer to Cloudﬂare
198
T. V. Doan et al.
Fig. 1. Failure rates of resolvers by continent for Do53 (top) and DoT (bottom). Each
cell represents the failure rate based on all failures relative to all queries for the speciﬁc
resolver and continent. Most failure rates for Do53 are between 0.3–3%, whereas DoT
failure rates are generally higher and more varying.
anycast instances that serve these probes, which in return causes a higher failure
rate compared to other resolvers. CleanBrowsing, on the other hand, shows a
similar failure rate regarding TUCONNECT errors as Google or Quad9; the majority
of CleanBrowsing’s overall DoT failures (10.3%) stem from timeouts instead.
The inﬂated failure rates for DoT in comparison with Do53 are less surprising,
as DoT was only standardized in 2016 [19]: As such, DoT likely still faces issues
with middleboxes along the path [16,29], which intervene with DoT packets
(TCP/853) and result in timeouts.
Regional Comparison. To identify regional diﬀerences, Fig. 1 depicts the
failure rates of Do53 (top) and DoT (bottom) by resolver and continent. Most
resolvers exhibit similar Do53 failure rates across all continents, in the range
of roughly 0.3–3%. Local resolvers show signiﬁcantly higher failure rates (5.7–
13.6%), which means that RIPE Atlas probes have less success in resolving
domain names when using their local resolver (regardless of DoT support). Thus,
Do53 resolutions are more reliable with public resolvers compared to local ones
concerning RIPE Atlas measurements. Nevertheless, we ﬁnd similarly high values
for OpenNIC in SA (11.3%), and Cloudﬂare in AF (6.8%) and SA (10.3%). As
mentioned, Neustar represents an outlier, as measurements fail in nearly all
cases (95.6–98.9%). Probes in Oceania (OC) have the lowest failure rates for all
resolvers when comparing diﬀerent continents, with most resolvers having failure
rates of at most 0.5%.
Measuring DNS over TLS from the Edge
199
Fig. 2. Histograms of response time ratios (DoT to Do53) per probe for each resolver.
The vertical dashed line represents the ratio of 4 RTTs for DoT (TCP handshake +
TLS handshake + DNS lookup) to 1 RTT of Do53 (DNS lookup).
Regarding DoT, Google and Quad9 exhibit the lowest failure rates across
all continents (<5% in most continents), although still higher than their respec-
tive Do53 failure rates. On the other hand, Cloudﬂare and CleanBrowsing show
higher failure rates, especially in AF (9.8% and 31.1%) and SA (11.6% and 7.4%),
with CleanBrowsing having a high failure rate in EU (12.8%) as well. Queries
to UncensoredDNS fail in nearly all cases (92.7–99.1%). As multiple public DoT
resolvers (even those with otherwise reliable services in other continents) have
higher failure rates in AF and SA, these regions may be aﬀected more heavily by
ossiﬁcation in terms of middleboxes. Local resolvers with DoT support also show
high failure rates, with 40.3% in EU, and 33.3% in NA. In total, this indicates
that the DoT reliability is highly dependent on the geographical location as well
as the chosen DNS service.
5 Response Times
We aggregate the measurements by grouping distinct tuples of probe and resolver
and, for each group, determine the 5th percentile in terms of response time (i.e.,
one value for each probe-resolver tuple across all measurements). We choose
5th percentiles to limit the analysis to responses for cached records, as those
accumulate at the lower end of the distribution and represent best-case scenarios.
Background. Before discussing response times of the measurements, we elab-
orate on a technical limitation regarding DoT: By design, a DoT client would
ﬁrst establish a TCP connection and TLS session with the recursive resolver,
then keep this session alive to reuse it for resolutions of multiple domains. Thus,
the added delay due to the TCP and TLS handshake RTTs only apply once for
200
T. V. Doan et al.
Fig. 3. CDF of resolver response time for successful Do53 (left) and DoT (right)
requests (5th percentiles per probe). While most Do53 responses arrive within roughly
100 ms, the majority of DoT responses require more than 100 ms to return.
as long as the connection and session stay alive. For RIPE Atlas probes, how-
ever, DoT measurements do not keep the connection/session alive in between
diﬀerent measurements, which means that the additional RTTs required for the
TCP and TLS handshakes apply to every DoT measurement. We contacted the
RIPE Atlas support regarding speciﬁc protocol details: RIPE Atlas probes do
not use TCP Fast Open or other extensions, so establishing the TCP connec-
tion will add 1 RTT to the response time. Further, probes typically use TLS 1.2
(2 additional RTTs), though some probes may use TLS 1.3 (1 additional RTT);
however, the DoT measurement results do unfortunately not provide any infor-
mation about the used TLS version for validation. As such, DoT measurements
include 3 additional RTTs (2 in the best case) on top of the DNS lookup (1
RTT).
Considering we focus on cached responses (5th percentiles, see above) exclu-
sively in this section, we argue that the lookup times are negligibly small (since
results are simply returned from the cache). Thus, the response times largely con-
sist of the RTTs between probe and resolver. Consequently, Do53 measurements
resemble roughly 1 RTT, which we consider as the baseline RTT (cf. overall
response times below), whereas DoT measurements resemble roughly 4 RTTs
in total, plus time for connection/session management and processing on both
probe and resolver. For approximation, we calculate the ratio between the 5th
percentiles of the DoT and Do53 response times per probe for each resolver,
shown in Fig. 2; the vertical dashed lines represent the outlined ratio of 4 RTTs
to 1 RTT (i.e., DoT to Do53).
The minimum ratio across all resolvers is 3.11, which suggests usage of
TLS 1.3 in these cases (1 RTT less than with TLS 1.2). Yet, these cases are rare
(only four probe-resolver pairs), as the median ratio among the public resolvers is
10.5 (25th percentile 7.5); this suggests that besides the approx. 4 RTTs required
for the handshakes, most samples require at least around 4 more RTTs for pro-
cessing of the DoT request on probe and resolver side. However, this processing
Measuring DNS over TLS from the Edge
201
Fig. 4. Medians of the 5th percentile response times by continent and resolver for Do53
(top) and DoT (bottom). Do53 response times are mostly below 20–40 ms for most
resolvers, whereas DoT response times are between roughly 120–180 ms instead.
overhead for DoT measurements cannot be accurately determined, as probes
record the total response time only and, therefore, do not allow separation of
diﬀerent steps during the DoT lookup. Nevertheless, note that the handshake
RTTs still account for a large fraction of the measured DoT response times over-
all. Recall that only 13 probes leverage DoT-supporting local resolvers, most of
which have ratios toward the higher end (see Fig. 2, bottom right) due to very
low Do53 response times (<10 ms) and likely early-stage DoT implementations.