*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
24
-
!
-
!
!
!
!
!
!
-
!
-
-
!
-
-
!
!
-
-
!
!
!
!
!
!
!
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
25
+
*
+
*
+
+
*
+
*
*
+
+
*
+
+
+
+
+
*
+
*
*
*
*
+
*
+
*
*
+
*
+
+
+
+
*
*
*
*
+
*
*
*
*
*
*
*
+
*
*
26
+
+
!
+
+
+
+
+
*
+
+
!
+
+
+
+
+
+
!
+
*
+
*
*
+
+
+
+
+
+
+
+
+
+
*
*
+
+
*
*
*
*
*
*
*
*
+
*
*
*
27
+
*
+
*
*
*
+
+
*
*
*
+
*
+
+
+
+
!
+
+
*
+
*
*
*
+
+
+
+
*
*
+
+
+
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
28
*
+
*
*
*
+
+
+
+
*
+
*
+
+
*
*
+
+
+
*
+
+
*
*
*
*
*
+
*
*
+
*
*
+
*
*
+
+
*
*
*
*
*
*
*
*
*
*
*
*
29
*
*
!
-
*
-
-
!
*
*
-
*
*
*
!
*
*
!
*
+
*
*
*
*
-
+
+
*
*
-
*
*
!
*
-
*
*
*
*
-
*
*
*
*
*
*
*
*
*
*
30
*
*
*
*
*
-
*
*
*
*
+
*
*
*
*
*
*
+
*
+
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
!
*
*
*
+
*
*
*
*
*
*
*
*
*
*
Table 6: Transition in classiﬁcations of nonself blocks between truncated and enriched command line data. For example, the
+ in column 2 of row 1 indicates that masquerader 2 was missed in victim 1’s truncated data, but correctly detected in the
enriched data. Key:
(!) miss to miss.
(+) miss to hit;
(-) hit to miss;
(*) hit to hit;
masquerader 2 was detected in 26 more instances, and mas-
queraders 16 and 26 were detected in 30 more instances. All
of the misses for these three masqueraders were missed in
both the truncated and enriched conditions. All of the tran-
sitions were from miss to hit, and none of the transitions
were from hit to miss. Masqueraders 7 and 24 experienced
the largest numbers of hit-to-miss transitions. The next few
subsections brieﬂy discuss selected pathological cases to il-
lustrate their causal behaviors; unfortunately, not all of the
interesting cases can be discussed here, due to space limita-
tions.
6.4 Masquerader 02 revealed by unusual ﬂags
Masquerader 2 experienced 26 miss-to-hit transitions
and no hit-to-miss transitions. Enriching the data caused
this masquerader to go from an 18% detection rate across 50
victims to a 70% detection rate due to the masquerader’s use
of an unusual command-line ﬂag. Most victims regularly
use the commands ls (list ﬁles) and cat (view ﬁles). Through
enrichment, ls became ls -al (list detailed info about all ﬁles)
and cat became cat -n (view ﬁles and add line numbering).
These ﬂags are unusual, and naive Bayes noticed this. En-
richment allows unusual behavior in the injection to be seen
by naive Bayes, which is precisely the intention of using en-
riched data. The truncated and enriched blocks of data that
revealed the masquerader are shown in Table 7.
6.5 Novel commands conceal Masquerader 07
Masquerader 7 experienced 35 miss-to-hit transitions
and no hit-to-miss transitions. Enrichment causes this mas-
querader to go from a 70% detection rate to a 0% detec-
tion rate. The truncated rlogin command (remote login) en-
riches to rlogin /usr/ucb/rlogin -8 (an alias of rlogin, the -8
means to enable the 8th bit (parity bit) in the network con-
nection). The enriched form of the command was not seen
in the training data. Naive Bayes treats never-before-seen-
commands as more likely to be self than non-self, because
of the higher command-frequency ratio in the nonself data
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:03:06 UTC from IEEE Xplore.  Restrictions apply. 
Truncated
ls
cat
sc
a5
a5
a5
mail
ftp
cat
mail
Enriched
ls -al
cat -n
sc -D -o
a5
a5
a5
mail
ftp
cat
mail
Table 7: Masquerader 2, revealed by unusual ﬂags.
as opposed to the self data; that is, the probability of oc-
currence is lower in the nonself data. Because 80% of the
enriched block was never-before-seen, the block was classi-
ﬁed as self. This kind of behavior, typical of naive Bayes, is
vulnerable to exploitation by a clever masquerader to elude
detection. Note that masquerader 24’s similar outcome can
be explained by the same mechanism. See Table 8.
Truncated
rlogin
rlogin
rlogin
rlogin
rlogin
mail
rlogin
rlogin
mail
rlogin
Enriched
rlogin /usr/ucb/rlogin -8
rlogin /usr/ucb/rlogin -8
rlogin /usr/ucb/rlogin -8
rlogin /usr/ucb/rlogin -8
rlogin /usr/ucb/rlogin -8
mail
rlogin /usr/ucb/rlogin -8
rlogin /usr/ucb/rlogin -8
mail
rlogin /usr/ucb/rlogin -8
Table 8: Masquerader 7, concealed by novel commands.
6.6 Simplistic commands reveal Masquerader 16.
Masquerader 16 experienced 30 miss-to-hit transitions
and no hit-to-miss transitions. Enrichment moves the 24%
detection rate to 84%. Yet, enrichment did not reveal any-
thing new about the masquerader’s command line. This is
not an error, because the masquerader’s behavior is too sim-
ple for most victims. Most victims have ls (list ﬁles) aliased
to use some set of preferred ﬂags. The lack of these ﬂags re-
veals the masquerader to naive Bayes. Counter-intuitively,
enrichment can help even when it may not reveal anything
new about the injection. Because the truncated and enriched
data in this case are the same (the differences were in the
training data, not the test data), they are not shown.
6.7 Masquerader 26 revealed by printer choice
Masquerader 26 experienced 30 miss-to-hit transitions
and no hit-to-miss transitions. A 34% detection rate in the
truncated data turned into a 94% detection rate through en-
richment. The lpq command (used to check the print queue
length) became lpq -Palw2 through enrichment (check
queue on printer named alw2). Many victims check print
queues, so lpq is not suspicious. Different victims use
different printers, however, and the alw2 speciﬁcation, re-
vealed through enrichment, is suspicious. In this example,
naive Bayes learns indicators of victim preferences (e.g.,
preferred printers). See Table 9.
Truncated
ptroff
lpq
lpq
ptroff
lpq
e
e
lpq
ptroff
lpq
Enriched
ptroff /userc/offstaff/group.bin/lwpp
lpq -Palw2
lpq -Palw2
ptroff /userc/offstaff/group.bin/lwpp
lpq -Palw2
e emacs
e emacs
lpq -Palw2
ptroff /userc/offstaff/group.bin/lwpp
lpq -Palw2
Table 9: Masquerader 26, revealed through choice of
printer.
7 Discussion
The hypothesis that enriched command-line data can en-
hance detection of masqueraders has been conﬁrmed. The
use of enriched data:
(cid:0) Increased hits by 15.79%
(cid:0) Reduced misses by 38.53%
(cid:0) Increased false alarms from 4.7% to 5.7%
(cid:0) Reduced equal-basis cost of error by 30.02%
The study improved hit rates to 82.1%, which is
a 32.2% increase over the previous best masquerade-
detection achievement [8], and more than 100% improve-
ment over the best of the results from [12]. This was ac-
complished using the same number of masquerade victims
(50) as in these two previous studies, but with 5 times less
training data, and 10 times less information at each decision
point (block size of only 10 commands).
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:03:06 UTC from IEEE Xplore.  Restrictions apply. 
Some general observations can be made on the basis
of the selected examinations of conspicuous masqueraders.
The detector is able to learn subtle user idiosyncrasies that
exist in real data, and it can leverage that knowledge in de-
tecting masqueraders who don’t share those idiosyncrasies
(e.g., a victim uses “ls” less often than the attacker does).
Because of the mathematics of the naive Bayes detector,
it is easy to understand why the detector makes the deci-
sions it makes; and, unlike neural nets, its internals are ac-
cessible and can be brought out to ancillary processes such
as alarm mitigators, displaying evidence to operators. The
detector is amenable to ﬁne-grained analysis; that is, one
can determine the exact elements of the attacker and victim
environments that inﬂuence hits, misses and false alarms,
hence providing a better comprehension of coverage. The
detector works reasonably well on small block sizes (10
commands).
A point worth noting is the vulnerability of the system
in respect of unique, previously unseen masquerader com-
mand lines. A block containing a high proportion of (or
nothing but) previously unseen commands will have an ex-
ceedingly low probability of having been generated by ei-
ther the model of self or the model of non-self. However,
due to the larger amount of data in the non-self model, the
probability of nonself will be even lower than that of self,
and since classiﬁcation is done on the basis of the ratio of
self to nonself, an intruder issuing such a block of com-
mands may beat the detector (depending upon the thresh-
old). One solution to this would be a two-tiered threshold-
ing system, in which an absolute limit on the likelihood of
self is applied as a primary ﬁlter, before the ratio test. Toler-
ance of previously unseen commands is important, because
the data show a pronounced tendency for users to embark
on sudden spurts of new command usage.
8 Conclusion
This work represents an advance over previous
masquerade-detection research, both in terms of improved
detection statistics, as well as in achieving an understand-
ing of what works and what doesn’t work, and why. There
is now at least some comprehension of the conditions that
lead the detector to failure. Possibly through design diver-
sity (multiple diverse detectors), there will be ways to com-
pensate for these failures, now that at least some details of
these failure characteristics are now known in some detail.
9 Acknowledgements
The Defense Advanced Research Projects Agency
(DARPA) supported this work under contracts F30602-99-
2-0537 and F30602-00-2-0528; thanks to Cathy McCollum
for encouraging this research. Tahlia Townsend (now at
Yale University) performed the initial data analyses. Kevin
Killourhy helped with data management and analysis. Imre
Kondor (now at Columbia University) helped with a visu-
alization system for interpreting naive Bayes classiﬁcation
results. This study would not have been possible without
Saul Greenberg’s gracious contribution of his data.
References
[1] P. Domingos and M. Pazzani. Beyond independence: condi-
tions for the optimality of the simple Bayesian classiﬁer. In
L. Saitta, editor, 13th International Conference on Machine
Learning (ICML-96), pages 105–112, 03-06 July 1996, Bari,
Italy. Morgan Kaufmann, San Francisco, California, 1996.
[2] M. Fan. Massive identity theft alleged: Credit fraud affects
30,000, authorities say. San Jose Mercury News, San Jose,
California, 26 November 2002.
[3] S. Greenberg. Using Unix: Collected traces of 168 users.
Technical report 88/333/45, Department of Computer Sci-
ence, University of Calgary, Calgary, Canada. 1988.
[4] V. Loeb. Spy case prompts computer search. Washington
Post, 05 March 2001, page A01.
[5] T. F. Lunt. A survey of intrusion-detection techniques. Com-
puters & Security, 12(4):405–418, June 1993.
[6] T. F. Lunt and R. Jagannathan. A prototype real-time
intrusion-detection expert system. In IEEE Symposium on
Security and Privacy, pages 59–66, 18-21 April 1988, Oak-
land, California. IEEE Computer Society Press, Washing-
ton, DC, 1988.
[7] C. D. Manning and H. Schutze. Foundations of Statistical
Natural Language Processing. MIT Press, Cambridge, Mas-
sachusetts, 1999. Fourth printing, 2001.
[8] R. A. Maxion and T. N. Townsend. Masquerade detection
using truncated command lines. In International Conference
on Dependable Systems & Networks, pages 219–228, 23-26
June 2002, Washington, DC, IEEE Computer Society, Los
Alamitos, California, 2002. .
[9] R. A. Maxion and T. N. Townsend. Masquerade detection
augmented with error analysis. IEEE Transactions on Reli-
ability, In press, 2003.
[10] A. McCallum and K. Nigam. A comparison of event mod-
els for naive bayes text classiﬁcation. In Learning for Text
Categorization, papers from the 1998 AAAI Workshop, 27
July 1998, Madison, Wisconsin, pages 41–48. Published
as AAAI Technical Report WS-98-05, AAAI Press, Menlo
Park, California, 1998.
[11] T. M. Mitchell. Machine Learning. McGraw-Hill, Boston,
Massachusetts, 1997.
[12] M. Schonlau, W. DuMouchel, W.-H. Ju, A. F. Karr,
M. Theus, and Y. Vardi. Computer intrusion: Detecting mas-
querades. Statistical Science, 16(1):58–74, February 2001.
[13] E. D. Shaw, K. G. Ruby and J. M. Post. The insider threat
to information systems: The psychology of the dangerous
insider. Security Awareness Bulletin, 2-98, Department of
Defense Security Institute, Richmond, Virginia. September
1998.
[14] J. Swets and R. Pickett. Evaluation of Diagnostic Systems:
Methods from Signal Detection Theory. Academic Press,
New York, 1992.
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:03:06 UTC from IEEE Xplore.  Restrictions apply.