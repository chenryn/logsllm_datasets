we leverage PM to create a sensitive, low-integrity domain to collect
such untrusted inputs and an insensitive high-integrity domain to
guard itself from those untrusted inputs. When some low-integrity
information is sent to the high-integrity domain, that information
must be declassified (i.e., endorsed) in the high-integrity domain.
To guide PM to generate such partitions, we target noninter-
ference, which has two implications for partitioning. First, low-
integrity domains should have minimal code size. We want to min-
imize the amount of code that can be directly influenced by low-
integrity data. Second, the quantity of information conveyed from
the low-integrity domain to the high-integrity domain should be
minimized to reduce the amount of data to endorse or filter. We
note that the data may convey between domains directly, via RPCs,
and through indirect channels, such as the file system. The former
is controlled by where we place partition boundaries. The latter
is controlled by the least privilege permissions needed to execute
the partitions correctly. Ideally, the partitioning creates RPCs that
convey minimal information, and least privilege permissions that
do not require the high-integrity domain to use any data written to
the file system.
As the low-integrity domain cannot be entrusted with any se-
cret data, we prohibit any partition that enables the low-integrity
domain to access secret data from the high-integrity domain or the
file system.
High-secrecy domains. The purpose of high-secrecy domains
is to provide access to program secrets; so the security goal is to
prevent leakage of such secrets from the program, even if part of
the program comes under attacker control. Thus, we leverage PM
to create a sensitive, high-secrecy domain to access secrets and an
insensitive low-secrecy domain that must not have access to secret
information. The high-secrecy domain must declassify any data to
be sent via RPC to the low-secrecy one.
To guide the use of PM to generate such partitions, we again
target noninterference, which aims to ensure that any low-secrecy
programs will produce the same (low) outputs regardless of the high-
secrecy data processing. Thus, we aim to minimize the information
flow from the high-secrecy to the low-secrecy domain to reduce
the amount of data that must be declassified. The partitioning
boundary defines where the sensitive partition must declassify
data. In addition, if the sensitive partition outputs the secret data
to external resources, such as the file system, that partition must
also declassify that data. Ideally, secret data is not output to the file
system.
In order to protect the use of high-secrecy data, the integrity of
the high-secrecy domain must be protected. We should aim to mini-
mize the amount of low-integrity data received by the high-integrity
(and high-secrecy) domains. However, in this case, the partitioning
is to protect the high-secrecy and high-integrity functions, not to
protect the program at large from functions that receive untrusted
inputs. Thus, from a Clark-Wilson perspective, it is best to minimize
the amount of code performing security-critical functionality to
reduce its attack surface.
6.1 Definition of metrics
We define a set of metrics for quantifying the quality of a partition
in terms its security and performance. Based on the discussion
above, we introduce two metrics for measuring the security impact
of a partition: (1) the amount of sensitive information that flows
from the sensitive to the insensitive domain and (2) the percentage
of sensitive code. For performance, we define metrics to estimate
the performance overhead created by the partition using: (1) the
frequency of context switches (i.e., the frequency of domain cross-
ings between the two domains) and (2) the pointer complexity of
the interface between the two domains (i.e., the amount of data
conveyed on domain crossings).
An edge is annotated with information-flow measurements. Re-
call that an edge e represents a call relation between a caller and
a callee. For information flow, two weights are added to an edge:
for an edge e that represents calls from f1 to f2, fflow(e) is the
Session 5A: Software SecurityCCS ’19, November 11–15, 2019, London, United Kingdom1028amount of sensitive information, measured in the number of bits,
in the arguments passed from f1 to f2; and bflow(e) is the amount
of sensitive information in return values from f2 to f1. We will
later discuss how PM uses a dynamic information-flow tracker to
measure fflow(e) and bflow(e). Then the total amount of sensitive
information flow from the sensitive to the insensitive domain is the
sum of forward flows on forward boundary edges and backward
flows on backward boundary edges:

Definition 6.1 (Sensitive information flow).

Flow(S,T ) =
fflow(e) +
bflow(e).
e ∈FB
e ∈BB
Each vertex is annotated with the code size of the corresponding
function. We write sz(v) for the code size of the function represented
by vertex v. Therefore, the total code size of the sensitive domain in
a partition P = (S,T ) is defined as the sum of the sizes of functions
in the domain:
Definition 6.2 (Sensitive code percentage).


SCode(S,T ) = (
sz(v))/(
sz(v)).
v ∈S
v ∈S ∪T
An edge from f1 to f2 is also annotated with a weight af(e)
(abbreviation for access frequency) for measuring the frequency of
calls of f2 by f1. When e is a boundary edge, af(e) corresponds to
the frequency of context switches caused by realizing e as an RPC.
Then the total frequency of context switches caused by a partition
is the sum of access frequency on boundary edges:
Definition 6.3 (Context switch frequency).

CSwitch(S,T ) =
af(e).
e ∈FB∪BB
We also propose a metric for the cost per switch. However, esti-
mating that cost accurately is difficult because it depends on what
data is passed and how the context switch is implemented. RPCs
are implemented by marshalling the arguments from the caller to
the callee, who unmarshalls these values, executes the operation,
and performs the reverse process for return values. While data of
non-pointer types can be automatically marshalled, more cost is
incurred when marshalling C/C++ style pointer data. For example,
PtrSplit [15] tracks the buffer bounds of pointers at runtime and
copies the underlying buffers during marshalling, causing more data
to cross the boundary. In addition, pointers to user-defined types
may further reference pointers to other types, possibly necessitat-
ing a “deep copy” to convey the necessary data between domains.
Alternatively, one may employ the opaque-pointer approach (e.g.,
used in [2]); however, passing multi-level pointers across the parti-
tion boundary opaquely creates frequent domain crossings, since
each time an opaque pointer is used the pointer has to be passed
back to the sender for processing. Therefore, in either deep copying
or opaque pointers, pointer types create significant cost. Given the
lack of analyses to estimate RPC overhead accurately at present,
we propose a coarse estimate of this overhead based on the pointer
complexity of the type signature of the callee function. In this paper,
the pointer complexity of a type is defined by the level of pointers
in the type. For example, the pointer complexity of a base type like
int is 0, the complexity of int** is 2, and the complexity of the
type of pointers to structs with a two-level pointer field is 3.
Given an edge e from f1 to f2 in the call graph, we use plevel(e)
for the sum of pointer complexity of the argument and return types
of f2. Then the pointer complexity is defined as the sum of type
complexity of all boundary edges:

Definition 6.4 (Pointer complexity).
Cplx(S,T ) =
plevel(e).
e ∈FB∪BB
6.2 Alternative metrics
We next briefly discuss alternatives to our proposed metrics and
how PM could be changed to incorporate those metrics.
For software-security metrics, we emphasize that the research is
lacking, and there are no generally agreed-upon metrics for mea-
suring software security. One possibility is to measure the number
of past known vulnerabilities that can be mitigated through parti-
tioning. We did not use this because this metric reflects only the
past and does not consider unknown vulnerabilities. Another pos-
sibility is to measure the attack surface after partitioning, but how
to perform such a measurement is an open question. For perfor-
mance metrics, there are many other alternatives. In addition to
context-switch frequency and pointer complexity, one can dynami-
cally measure the amount of data passed for a cross-boundary call
or return, or statically compute the type complexity of parameters
(not just for pointers). In this paper, we do not attempt to design
new metrics, but reuse existing metrics and we find that the metrics
we propose are reasonable proxies of security and performance. A
follow-up study can investigate which metrics are most appropriate
by evaluating metrics on a larger number of benchmarks.
We note that PM is set up in a way that enables users to switch
to other metrics without changing its optimization framework for
finding the best partition according to a user-specified goal. A
new metric can be added as long as measurements at the PDG
node/edge level can be performed and the computation of going
from node/edge level measurements to partition-level measure-
ments can be encoded in IP. We believe most metrics satisfy these
requirements. As an example, for the number of past-known vul-
nerabilities, we can annotate each function node with the number
of vulnerabilities that have been discovered in that function; the
number of vulnerabilities mitigated through isolating an untrusted
domain is just the sum of numbers on the function nodes in the
domain, which can be easily encoded in IP.
7 IMPLEMENTATION
The prototype implementation of PM is implemented with the
help of several tools, including LLVM3, Flowcheck [18], Intel’s Pin
tool [17], and lp_solve [1]. We first explain the toolchain’s input
and output, followed by a discussion of how each component is
implemented.
Tool input and output. At a high level, PM’s implementation
takes two pieces of input from the user: (1) source code plus user
annotations about what sensitive functions and globals are; (2)
metric budgets and the optimization goal.
3Our original implementation was on LLVM 3.5; we recently migrated the PDG-
construction part to LLVM 5.0 and open sourced it (https://bitbucket.org/psu_soslab/
pdg-llvm5.0/src/pdg_plugin/). Other parts of the tool are being migrated to LLVM 5.0
and will be released when mature.
Session 5A: Software SecurityCCS ’19, November 11–15, 2019, London, United Kingdom1029For the first input, the user uses C attributes to make explicit what
sensitive functions/variables are. The following example shows how
to specify auth2 as a sensitive function:
int (__attribute__((annotate("sensitive"))) auth2)
(char* userpwd, char* fn) { ... }
The second piece of input is metric budgets and the optimization
goal. Budgets are in the form of (bc , bf , bs , bx ), where bc is the bud-
get for the sensitive-code percentage, bf the budget for the amount
of sensitive information flow, bs the budget for the frequency of
context switches, and bx the pointer-complexity budget. A user
can allow some metrics have an unlimited budget, in which case _
is used for those metrics. Furthermore, the user specifies a metric
as the target metric to minimize; in notation, a “*” symbol is put
after the budget to indicate that it is the target metric. As an ex-
∗, _, _) means that the budget for the sensitive code
ample, (10%, 2
percentage is 10%, the budget for sensitive information flow is 2 bits,
budgets for the context-switch frequency and pointer complexity
are unlimited, and the goal is to minimize the amount of sensitive
information flow.
With this input, PM then computes a partition in the form of a
set of functions and globals that should stay in the sensitive domain;
the rest of the code stays in the insensitive domain.
To evaluate the quality of a partition and be able to compare
different ways of partitioning for the same application, we over-
load the notation to also use a quadruple for the quality scores
of a partition: (c, f , s, x), where c is the sensitive-code percentage
of the partition, f the amount of sensitive information flow, s the
frequency of context switches, and x the pointer complexity. We
added a feature to PM that takes a partition of a program as input
and outputs its quality quadruple according to the program’s an-
notated PDG. This feature is useful when users want to use some
initial partition’s quality scores as a starting point to find better
partitions.
LLVM passes. Clang is used to compile the input program’s source
code into LLVM IR code. The source code is assumed to include user
annotations about where sensitive data is. PM adds LLVM passes at
the IR level for PDG construction and performing measurements on
code size and pointer complexity. Our PDG construction reuses our
previous work [15], which allows modular PDG construction and
relies on only local but not global pointer analysis. LLVM passes
are also added to count the code sizes of functions and compute the
pointer complexity for the types of functions and global variables.
These measurements are then added to the PDG as weights.
Measuring information flow. PM measures sensitive informa-
tion flow at the function level, in particular, during function calls
and returns and between functions and globals. For this step, the
input is a piece of sensitive information. The output is forward
information flow fflow(e) and backward information flow bflow(e)
for each edge in the input program’s PDG. For instance, if f1 calls
f2 just once and passes a 32-bit secret password, the amount of
forward flow is 32 bits; if f2 returns the comparison result between
the password and a constant, the amount of backward flow is just
1 bit.
PM adapts Flowcheck [18] for measuring information flow; as
far as we know, it is the only publicly available tool that produces
quantitative information flow for realistic programs. It relies on
dynamic analysis to track sensitive information flow at runtime
for a particular input and uses a max-flow algorithm to quantify
the amount of flow. Measuring information flow becomes feasible
on a single run, with the downside that measurements may not
apply to other runs. However, Flowcheck is designed to measure
information flow between input and output at the level of a whole
program, while PM needs to measure information flow at the func-
tion level. Appendix C presents in detail how PM adapts Flowcheck
for function-level measurement of information flow and how it
aggregates information flow over multiple runs. We next give a
brief account.
Flowcheck is adapted to measure three kinds of information
flow at the function level: explicit, implicit, and potential flows. For
explicit flows, when a function gets called with some arguments,
it measures how much sensitive information is stored in the argu-
ments and how much in the function’s return value. For implicit
flows, when a function contains a conditional jump that depends
on sensitive information, it tracks that one bit of flow and propa-
gates it interprocedurally to the function’s callers. Potential flows
happen when pointers to sensitive buffers are passed interprocedu-
rally. Even if the callee function’s current code does not access the
underlying buffers, by our attack model an attacker may change
the callee’s computation (e.g., via return-oriented programming)
to access those buffers, after the callee has been taken over by the
attacker. Therefore, in our context, it is important to measure poten-
tial damage the attacker can cause by getting hold of capabilities to
access sensitive data and we call it potential flows. Note that this
kind of information flow is typically not considered in information-
flow literature since in that setting code is assumed to not change
dynamically.
Measuring context-switch frequency. To determine the context-
switch frequency when a call edge or a data-flow edge in the PDG
becomes a boundary edge after partitioning, PM uses Intel’s Pin
tool [17] to profile program execution. During the execution of a
program, our Pin-based tool produces a logfile that records caller-
callee pairs of function calls, pairs of global variables and functions
when functions read from or write to global variables. Using the
logfile, PM computes the number of times a particular call site
executes. If function f1 can call f2 at multiple call sites, the call
times for all call sites are summed into a total call time from f1 to
f2. Similarly, PM computes the number of times a global variable is
read or written by a function. Then, we divide the access amount
with the execution time to compute the frequency. Finally, average
frequencies over multiple runs are used as af(e) in the PDG.
Integer programming solving. Given a PDG annotated with
weights, PM converts it into an integer-programming problem fol-
lowing Appendix B. During implementation, we discovered that
currently popular RPC libraries (e.g., Sun RPC and Google’s gRPC)
do not support bidirectional control transfers. An example is when
function f1 in domain 1 calls function д in domain 2 and function
д in turn calls back function f2 in domain 1 (e.g., via a function
pointer). Due to this limitation, we add further constraints to our IP
model so that only single-directional RPC is allowed.4 In detail, the
4ntirpc claims to have bidirectional RPC support, but their developers told us that the
implementation was “sketchy” in private emails; when it becomes mature, we should
Session 5A: Software SecurityCCS ’19, November 11–15, 2019, London, United Kingdom1030new constraints allow only edges from the insensitive domain to
the sensitive domain to appear on the RPC boundary; any function
that the sensitive domain invokes (e.g., through callbacks) has to
stay or replicated in the sensitive domain. The sensitive domain