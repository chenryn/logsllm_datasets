through the di(cid:29)erent properties and sketch a proof for them.
For Property P0, the unforgeability of the signature scheme and
the collision resistance of H(), ensure that the additional data (pa-
rameters and timestamps) and the hash chain output are unforge-
able. The unforgeability of the hash chain inputs, namely the Merkle
hashes, reduces to the collision resistance of H(). Given all these,
the CES-Unforgeability is satis(cid:27)ed for each records according to
the proof provided by Steinfeld et al. [39] as records are almost
identical to documents and as the di(cid:29)erences are irrelevant for the
proof.
For Property P1 we need to prove that the commitments do not
leak any information and that the TLS tra(cid:28)c secret is not revealed,
which together with the adversarial network capabilities would dis-
close hidden data. The hiding property of C() is su(cid:28)cient for the
(cid:27)rst part given that the salts are pseudorandom and independent.
Salts are pseudorandom due to the properties of E() and indepen-
dent as for each record they are derived from an independent salt
secret. The TLS tra(cid:28)c secret is not leaked as it is only input to E(),
which due to its properties does not leak it.
7
A hidden chunk is observable due to the de(cid:27)nition of a record and
its length is known due its position, the chunk size and the record
size. If the (cid:27)rst record of a conversation is not included the proof
must start with a hash chain node of the type H(0x1,hci−1,hi )
instead of H(0x1,h0), which together satis(cid:27)es property P2.
As the records include originator information that is unforge-
able due to P0, P3 is satis(cid:27)ed. And as the timestamps are likewise
unforgeable and are taken at the beginning and the end of the ev-
idence window, tight bounds can be provided on the generator’s
time, ful(cid:27)lling P4.
5 IMPLEMENTATION AND EVALUATION
In this section we describe our TLS-N implementation, its deploy-
ment and its evaluation using real-world as well as synthetic tra(cid:28)c.
5.1 Implementation
For the purposes of our implementation, we extend the Network
Security Services (NSS) library [32] provided by the Mozilla Founda-
tion. We chose the NSS library for its support of TLS 1.3 and because
it can be used on the client side, e.g. in Mozilla Firefox, and on the
server side, e.g. through the mod_nss Apache module [18, 19]. We
implement TLS-N as an extension in NSS and deploy it in a real-
world setting using an adapted version of mod_nss and Apache
running on an Amazon EC2 node.
We extend TLS so that the requester application can enable the
TLS-N extension. The peers negotiate the usage of TLS-N during the
handshake. We use a 16-byte salt size, in order to preserve the 128-
bit con(cid:27)dentiality protection of TLS [11]. Unless otherwise stated,
we also use a 16-byte chunk size, as Figure 4b shows that it provides
a good trade-o(cid:29) between granularity and e(cid:28)ciency. For H() our
implementation uses the hash function of the chosen cipher suite
and for E() we use the HKDF-Expand-Label function with speci(cid:27)c
labels for salt secret and salt tree generation. HKDF-Expand-Label
is already used for these properties [38]. As nonce for the salt secret
generation, we use the TLS per-record nonce, which is guaranteed
to be unique in combination with the tra(cid:28)c secret [38]. For C() we
use the same function as for H(), as we assume that modern hash
functions with su(cid:28)ciently large salts provide a hiding commitment.
To reduce the proof size we use TLS certi(cid:27)cates using elliptic curve
cryptography, namely secp256r1. Overall, we completely reuse
cryptographic primitives that are already present in TLS.
Our extension then constructs a proof according to the settings
of the requester application, which provides regular expressions for
sensitive content that is then hidden in the proof. Finally, the proof is
returned to the requester application. The requester application can
store the proof and send it to veri(cid:27)ers. Veri(cid:27)ers can use our library
extension to determine the validity of a proof, which includes the
necessary salt tree and Merkle tree computations as well as the
signature check and the veri(cid:27)cation of the included certi(cid:27)cate chain.
5.2 Blockchain Implementation and
Evaluation
To show that the proof veri(cid:27)cation can be performed by a blockchain-
based smart contract, we provide an Ethereum [43] implementation
of the proof veri(cid:27)cation procedure. The smart contract parses the
(a) Proof generation and proof veri(cid:27)cation
times for random, simulated TLS sessions.
Such proofs without hidden data are the
worst case for the proof veri(cid:27)cation. We ob-
serve a linear scaling for both times. Each
result is averaged over 20 repetitions.
(b) Average processing time for one record
depending on its size. Time includes build-
ing salt and Merkle tree. Chunk-granularity
with sizes ranging from 8 to 64 bytes is com-
pared to record-level granularity. 16 KB is
the largest NSS-supported record size.
(c) Average time from sending one HTTP
request until the requested (cid:27)le is received
with and without our TLS-N extension run-
ning on an Apache webserver. We (cid:27)nd that
TLS-N is usable, even for bigger (cid:27)les. Each
result is averaged over 100 measurements.
Figure 4: Performance Evaluation for our implemented extension of TLS-N on client and server side.
proof, computes the salt tree and Merkle tree, and performs a sig-
nature veri(cid:27)cation.
Table 2 shows the respective gas costs in ether and USD (at the
time of writing), depending on the conversation size (the cumula-
tive length of all records) and the elliptic curve used in the evidence
signature. We also show the basic gas cost that results from the
size of a transaction [43]. We show two elliptic curves, because no
elliptic curve is supported by both TLS [38] and Ethereum (TLS
supports secp256r1 while Ethereum uses secp256k1). The costs dif-
fer greatly for the signature schemes, because Ethereum’s support
for secp256k1 [5]. We had to implement veri(cid:27)cation for secp256r1
on top of Ethereum, resulting in a veri(cid:27)cation cost around 1.2 mil-
lion gas. Overall, we observe, that the proof validation costs are
dominated by the basic gas cost and cost for signature veri(cid:27)cation,
whereas our design only adds a marginal cost.
Another issue is the certi(cid:27)cate chain veri(cid:27)cation within the
blockchain. To the best of our knowledge there is no blockchain-
based system to verify TLS signatures based on the web-PKI. We
therefore suggests that the verifying smart contract knows the
generator’s (e.g. the content provider’s) public key so that it can
omit the certi(cid:27)cate chain veri(cid:27)cation. Once the smart contract
has veri(cid:27)ed the proof, it knows that the conversation is authentic
and can act immediately, e.g. perform a matching payout, save the
content or save a content hash in order to avoid future veri(cid:27)cations.
Given our smart contract implementation, TLS-N allows to con-
nect web-based content from any TLS-N-enabled content provider
such that any smart contract can operate on the provided, non-
repudiable data. Note that the requester is not required to be trusted,
and as such any requester can submit a TLS-N proof to the smart
contract.
5.3 Evaluation
In the following we evaluate the performance of our implemented
TLS extension using real world examples and synthetic examples
to test its scalability, as shown in Table 3 and Figure 4.
8
secp256r1
secp256k1
secp256r1
secp256k1
Conversation Size
1 KB
119,758
Basic Gas
Total Gas
Ether
USD
s
t
s
o
C
1,284,723
0.0257
2.0381
131,286
0.0026
0.2083
10 KB
737,159
1,938,872
0.0388
3.0758
782,219
0.0156
1.2409
Table 2: Gas costs for validating public, record-level proofs
within our Ethereum smart contract based on the conversa-
tion size and the elliptic curve. The basic gas cost is intrinsic
for a transaction of that size. Gas and ether prices taken as
of May 1st 2017.
5.3.1 Real-world Examples. We evaluate the performance of
TLS-N for real-world examples by replaying recorded HTTP con-
nections of web services, such as the Twitter API, Facebook API,
YAHOO! API and a Google Search (cf. Table 3). Since the network
latency is irrelevant for the proof size and the processing times, we
locally replay the recorded tra(cid:28)c between a Lenovo X220 laptop
and a server with an Intel Core i7.
We (cid:27)rst study the time we deem most critical, the server’s pro-
cessing time during the TLS connection. For conversation sizes
below 6 KB the server has a total processing time of less than
3.5 ms. After processing all the records during the connection, the
server’s the (cid:27)nal step of the evidence generation is independent of
the conversation size. For chunk-level proofs, we (cid:27)lter all cookies,
passwords and authentication tokens, but we also show an un(cid:27)l-
tered record-level proof, namely archiving a Wikipedia page, which
is signi(cid:27)cantly more e(cid:28)cient given the conversation size.
5.3.2 Performance Projections. In Figure 4a, we study the scala-
bility of proof generation and veri(cid:27)cation using synthetically gen-
erated proofs. For each size, we create random conversations con-
sisting of 2000-byte records. We observe that the proof generation
and veri(cid:27)cation times scale linearly in the conversation size. Re-
garding the proof veri(cid:27)cation, Figure 4a shows the worst-case sce-
nario, as the proofs contain no hidden data and as such all salt and
0246810ConversationSizeofSession(MB)010002000300040005000Time(ms)ProofGeneration:Chunk-level(16B)ProofVeriﬁcation:Chunk-level(16B)ProofGeneration:Record-levelProofVeriﬁcation:Record-level0246810121416RecordLength(KB)0246810121416Time(ms)Chunk-level(8B)Chunk-level(16B)Chunk-level(32B)Chunk-level(64B)Record-level10B100B1KB10KB100KB1MB10MBSizeofRequestedFile100101102103Time(ms)TLS-NEnabledTLS-NDisabledOverheadUse Case
Twitter API
Facebook API
YAHOO! API
Oanda API
Google Search*
Wikipedia Archive
Conver-
sation
Size (B)
5,320
3,187
2,038
935
549,530
585,136
Number
of
Records
3
4
4
2
424
218
Online
TLS-N
Processing
Time (ms)
3.223
2.041
1.376
0.662
283.162
11.418
Server side during TLS session
Upon Request
Client side, O(cid:31)ine
Evidence
Size (B)
84
84
84
84
84
84
Evidence
Generation
Time (ms)
0.404
0.394
0.395
0.397
0.398
0.339
Proof
Type
Chunk
Chunk
Chunk
Chunk
Chunk
Record
Proof
Size+ (B)
5,668
3,629
2,676
1,414
552,180
589,924
Proof
Generation
Time (ms)
9.491
8.410
8.721
6.320
357.411
20.949
Proof
Veri(cid:27)cation
Time (ms)
10.345
9.734
10.032
8.767
231.934
20.662
Hidden Data,
e.g., cookies
(B)
348
224
182
161
10,001
0
Table 3: Use case evaluation: For each use case we give its sizes, total, server-side processing time during the session, the evi-
dence generation time (performed upon request) and the client-side times for proof generation and veri(cid:27)cation. We highlight
the only additional latency during the TLS session. Times are averaged over 20 repetitions. When applicable, the chunk size
was 16 B. *The Google Search includes many records due to auto-completion.+ The proof size includes the conversation size.
Merkle tree nodes have to be computed. We observe that proofs
with record-level granularity are signi(cid:27)cantly e(cid:28)cient, as Merkle
and salt trees only have a single node.
In Figure 4b, we (cid:27)nd that server processing times scale linearly
in the record size. We plot the average server side processing time
for a single record depending on the record length and the chunk
size. Bigger chunk sizes require less computation, but have a coarse-
grained privacy protection. Along this trend, record-level granular-
ity is by far the most e(cid:28)cient solution.
5.3.3 Latency Overhead. To estimate the real-world overhead
of a complete HTTP request, we measure the overhead of our im-
plementation on the latency of HTTP requests to an Apache server
running on an Amazon AWS c4.large instance. In each request, the
client requests a (cid:27)le of a size between 10 and 107 bytes (in powers
of 10). For each (cid:27)le size, the average time from sending the request
until the (cid:27)le is received is plotted in Figure 4c. Again, we use a
chunk size of 16 B. We observe that as long as the whole (cid:27)le can
be sent in a single record (i.e. its size is smaller than 16 KB), the
latency of TLS 1.3 without TLS-N remains below 10 milliseconds.
For larger (cid:27)les the overhead increases but remains below one sec-
ond for 10MB (cid:27)les. Even though our implementation is neither
optimized or parallelized, i.e. the overhead could still be reduced,
the overhead appears tolerable. Additionally, recall that this was
achieved with a relatively small chunk size of 16 B.
6 SOLUTION SPACE AND RELATED WORK
In the following we summarize existing solutions and their limita-
tions, provide insights on possible strawman solutions and com-
pare their applicability to the use-cases from Section 2 and which
properties they satisfy.
6.1 Related Approaches
In this section, we overview related approaches to our design.
Content Extraction Signatures [39] aim to solve a similar prob-
lem. Given a signed document, di(cid:29)erent parts can be extracted
while the signature remains valid and is still veri(cid:27)able by third
parties. Content Extraction Signatures consist of a “PseudoRandom
Generator with Seed Extraction” corresponding to our salt tree and
use merkle trees based on commitments. As they are only designed
for a single document, the document length is included in the signa-
ture. We include the record length and the originator information
in the Merkle root node.
Redactable Signatures [22] as proposed by Johnson et al., are also
design-related. Their GGM tree [14] corresponds to our salt tree and