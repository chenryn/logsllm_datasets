| 理 |基于激活和权重幅度的混合减枝方案 |果 |据集 |
剪枝耗时下降
Prompt构建和自动优化
Prompt很大程度上直接决定LLM输出结果
优化前
优化后
	严谨的Prompt很大程度上反人性 
需要一个使用自然随意的语言输入, 仍能保持良好效果的技术
提示工程: 提前预设效果最佳的Prompt模板 	零样本提示 	小样本提示
北京是否比上海大?
示例: 武汉面积8000平方公 
里; 
天津面积1.2万平方公里; 武汉
比天津小里; 
天津面积1.2万平方公里; 武汉
比天津小
问题: 北京是否比上海大?
思维链提示(CoT) 	生成知识提示
示例: 如果提出比较类问题,可 分步骤思考, 示例1/2/3…
问题: 北京是否比上海大? 让我
们分步骤思考并保证答案正确
示例1….
示例2….
请根据示例, 先生成相关背景知 识, 再回答问题: 北京 vs 上海
自动化提示工程: 通过模型自动构建最佳Prompt
| 专用模型 | Prompt1 | 分类模型 | 无需 | LLM |
|---|---|---|---|---|
| 专用模型 |Prompt1 |分类模型 |优化 |LLM |
需优
| 使用大量指令训练集训练一个专 | Prompt2 | 分类模型 | 化 | 专用优化模型 |
|---|---|---|---|---|
| 用模型, 然后使用分类模型决定 |Prompt2 |分类模型 |化 |专用优化模型 || Prompt是否需要优化 |Prompt2 |分类模型 |化 |优化后的Prompt |
LLM
| APO | 原始Prompt | 调用LLM输出结果 | 如果结果不满意, |
|---|---|---|---|
| APO |原始Prompt |调用LLM输出结果 |给出期望结果或改 |
| 让大模型自主生成最佳效果 | 利用建议改写原始 | 自动优化Prompt提 | 进方向提示 |
|---|---|---|---|
| (Automatic Prompt  |利用建议改写原始 |自动优化Prompt提 |自动分析结果不正 |
| (Automatic Prompt  |Prompt |自动优化Prompt提 |自动分析结果不正 |
| Optimization) |Prompt |自动优化Prompt提 |自动分析结果不正 || Optimization) |自动评估优秀 |自动优化Prompt提 |自动分析结果不正 |
| Optimization) |Prompt并提供建议 |供多个候选项 |确的原因 |
上下文长度扩展
	长上下文增强场景、挑战与技术原理 
很多大模型的输入只有2K至3K token, 对大模型应用造成局限
典型场景 	技术方案
输入超长
•长文摘要
•长文问答
•多轮对话记忆召回
•提示中的指令或人设要求描述比较复杂•提示中因为包含了多个较长的fewshot
•DQA场景中为了召回更多参考片段
输出超长
•希望生成一篇3万字的小说文章
外挂方案
• NBCE, langchain(mapReduce, Refine)
外推方案
• 直接外推
• 相对位置编码+ALiBi
内插方案
• ROPE+PI
核函数方案
• NTK-aware Scaled RoPE• ROPE+PI
核函数方案
• NTK-aware Scaled RoPE
优化资源方案
• Sparse Attention
• Flash Attention
长上下文推理时扩展：LangChain
1 阅读理解问答：1.1 向量数据库检索 2 长文档摘要：
2.1 mapreduce
2.2 refine
长上下文推理时扩展：NBCE
Context1是切分 
的第一段文档
Context2是切分 
的第二段文档
…
…
Prompt是固定的问 
题
直观理解：最终的回答是考虑了各
个文档上条件概率最大的输出
推理时扩展的NTK 和训练时扩展的Position Interpolation
假设我们有一个0~999的整数n要作为条件输入到模型中，那么要以哪种方式比较好呢？
•	将0~999归一化到 0~1，但是模型不容易分辨0.001的微小差异•	将0~999归一化到 0~1，但是模型不容易分辨0.001的微小差异
•	可以增加维度，同时缩小每个维度的范围。比如759 用十进制表示为 [7,5,9]的三维向量，对模型很友好！如果来了个新需求，将n上限增加到2000以内，那么该如何处理呢？
直接外推 线性内插（PositionInterpolation） 进制转换（NTK）
| • | 由于某些维度的训练数 | • | 将2000压缩到999以内。例如n=1749时，可 | • | n原来用β进制表示为d/2位数 |
|---|---|---|---|---|---|
| • |由于某些维度的训练数 |• |以转换为n/2=874.5。 |• |如果要扩大k倍表示范围，那么进制至少 |
| • |据不充分，所以直接进 |• |以转换为n/2=874.5。 |• |如果要扩大k倍表示范围，那么进制至少 || • |据不充分，所以直接进 |• |因为位置编码下，相对大小（或许说序信息） |要扩大成β*(k2/d)进制 |要扩大成β*(k2/d)进制 |
| • |行外推通常会导致模型 |• |因为位置编码下，相对大小（或许说序信息） |要扩大成β*(k2/d)进制 |要扩大成β*(k2/d)进制 |
| • |行外推通常会导致模型 |• |更加重要，换句话说模型只需要知道874.5比 |要扩大成β*(k2/d)进制 |要扩大成β*(k2/d)进制 |
| • |的性能严重下降。 |• |更加重要，换句话说模型只需要知道874.5比 |要扩大成β*(k2/d)进制 |要扩大成β*(k2/d)进制 |
| • |的性能严重下降。 |• |874大就行了，模型有一定的泛化能力。 |要扩大成β*(k2/d)进制 |要扩大成β*(k2/d)进制 || • |需要进行再训练。 |• |874大就行了，模型有一定的泛化能力。 |要扩大成β*(k2/d)进制 |要扩大成β*(k2/d)进制 |
| • |需要进行再训练。 |• |缺点是最后一个维度更加“拥挤”，原本相邻 |原始位置编码中β=10000 2/d，扩大k倍后 |原始位置编码中β=10000 2/d，扩大k倍后 |
| • |需要进行再训练。 |• |数字的差距为1，现在是0.5。少量微调效果更 |原始位置编码中β=10000 2/d，扩大k倍后 |原始位置编码中β=10000 2/d，扩大k倍后 |
| • |需要进行再训练。 |• |数字的差距为1，现在是0.5。少量微调效果更 |则β修改为(10000k) 2/d |则β修改为(10000k) 2/d |
| • |需要进行再训练。 |• |好。 |则β修改为(10000k) 2/d |则β修改为(10000k) 2/d |未来展望
百模大战与投资风向
• 百模大战与融资风向
来源：Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond；https://www.newcomer.co/p/14-charts-that-tell-the-story-of 
技术趋势
基座大模型不再稀缺 行业大模型短期内涌现 LMOps工具将更加重要
| • | 越来越多的高质量开源模型将 | • | 具备行业特色的行业大模型会 | • | 伴随行业大模型的兴起,  |
|---|---|---|---|---|---|
| • |充斥市场 |• |在近期内大规模出现 |• |LMOps工具/平台将变得更加 |
重要
| • | 缺乏特色的开源模型会快速退 | • | 超强的基础大模型出现后, 会抑 | • | 虽然基础模型能力持续增强, 但 ||---|---|---|---|---|---|
| • |出市场 |• |制行业大模型的发展 |• |虽然基础模型能力持续增强, 但 |
| • |市场焦点会转移到新一代大模 |• |行业数据价值缩减, 但依然可用 |• |对模型使用成本的削减, 以及大 |
| • |市场焦点会转移到新一代大模 |• |行业数据价值缩减, 但依然可用 |• |模型快速落地应用, 依然是一个 |
| • |型的竞争上(多模态, 更智能) |• |于新一代基础大模型的调优或 |• |长期话题 |
外挂知识库
扫码关注“百度智能云技术站”
获取更多大模型相关技术分享