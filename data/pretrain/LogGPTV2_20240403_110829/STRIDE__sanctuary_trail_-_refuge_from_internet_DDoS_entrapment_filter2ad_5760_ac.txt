TDC.
 End-to-end path selection: When an endhost src in
ADS attempts to make a connection to another endhost dst
in ADD, src contacts ADS for path resolution.
In turn,
ADS requests the Path Server in the TDC for a list of static
paths to dst, and the server returns down-paths. As a result,
the ADS can select an up-path (from itself to its TDC) and
a down-path (from the TDC to ADD), and splice them to
form an end-to-end path.
A successful DDoS attack
Path Server availability.
against Path Servers would disable end-to-end path estab-
lishment in STRIDE. Such an attack can be prevented in
two ways: (1) the TDC can detect the origin of attack traf-
ﬁc against Path Servers and throttle their traﬃc, and (2) the
bandwidth-guaranteed static paths can be used to contact a
Path Server.
If ADS keeps on selecting paths
Path selection policy.
based on the highest available bandwidth, it may end up
selecting a single best path for all the source endhosts (be-
sides src), eventually congesting this path. To resolve this
issue, endpoint ADs in STRIDE perform probabilistic path
selection as follows: the endpoint AD selects a path with
probability proportional to the path bandwidth guarantees.
With this policy, the endpoint ADs are more likely to select
uncongested paths and reduce the average number of trials.
We evaluate a speciﬁc instance of this policy in Section 7.
Private paths. We introduce the notion of private paths,
Table 1: Guarantees of dynamic channel setup delay and
bandwidth for diﬀerent types of end-to-end channels.
Up-path Down-path
Delay
Bandwidth guaranteed?
Static
Static
Static
Static (private) Constant
Static (public)
Best-eﬀort
Linear
Linear



which endpoint ADs can use to provide guaranteed down-
paths to preferred endhosts. In a nutshell, an endpoint AD
keeps a subset of half-paths as private and provides them to
its destination endhosts such that they can selectively pro-
vide them to preferred sources. We deﬁne private services
to be provided by those servers that can predict future cus-
tomers (e.g., premium customers on Amazon). A private
server providing access to a closed community can provide
guaranteed connection setup to community members with
private down-paths as follows: a destination can selectively
disclose its private down-paths to preferred sources. The
private paths can be distributed via OOB channels or by
uploading encrypted private paths to a Path Server. As a
result, a valued customer of Amazon, for example, can ob-
tain a bandwidth-guaranteed static down-paths for sending
dynamic channel setup requests to Amazon.
5.3 Dynamic Channel Setup
Using a (BE, static, or hybrid) channel, src sends dy-
namic channel setup requests to establish an end-to-end dy-
namic channel. With such an end-to-end dynamic channel,
STRIDE can provide bandwidth guarantees to short-term,
high-bandwidth dynamic ﬂows. Note that src can send any
types of packets on the end-to-end channel, but we focus on
the discussion of sending dynamic channel setup requests,
as it is a part of our DDoS defense mechanism.
 Dynamic-channel setup request: After selecting an
end-to-end channel in step , a source endhost can send
a dynamic channel setup request for guaranteed dynamic-
bandwidth allocation. Table 1 describes guarantees of dy-
namic channel setup delay and bandwidth for diﬀerent types
of end-to-end channels.
A request header carries two additional indicators that
enable congested intermediate ADs to eﬃciently control link
bandwidth:
• Overuse bit: A source AD sets an overuse bit of a packet
on a static up-path in case its endhost is sending packets
more than the reserved static-class bandwidth of the up-
path.
• Congestion bit: Any AD that experiences link congestion
sets a congestion bit in BE packets.
Traﬃc priority of requests. When an AD receives
more packets than what its outgoing links can aﬀord, the AD
has to discard some of them while maintaining the static-
class bandwidth guarantee. Based on where the congestion
occurs, we discuss diﬀerent techniques to prioritize packets.
• Host contention at source ADs: Static bandwidth con-
tention may occur on the source AD’s outgoing links.
Each AD can have a diﬀerent way to resolve contention.
For example, it can adopt a payment-based scheme: each
client informs its host AD how much it is willing to pay
for using a static up-path, and the endpoint AD can ar-
range based on some objectives (e.g., maximize the AD’s
revenue) [23]. For ease of analysis, we consider per-host
fair share within an endpoint AD.
420Priority
Table 2: Traﬃc priority of dynamic channel setup requests
on the down-paths that experience link congestion.
How requests arrived
Within allocated static BW
On uncongested BE link
Beyond allocated static BW
Up-path
Bits set
-
-
Static
BE
Static
BE
1
2
3
4
5
Overuse
Congest On congested BE link
Outside TD
-
From outside TD
• Link congestion on up-paths: During link congestion, each
source domain obtains a weighted fair share of the avail-
able (unallocated, or allocated but unused) static band-
width. A weighted fair share is proportional to the source
domain’s static allocation on the congested link. Hence,
static packets with the overuse bit would be transmitted
on the static channel up to the weighted fair share, and
packets beyond the share are converted into BE packets
to compete with the standard BE traﬃc.
• Link congestion on down-paths: STRIDE assigns priority
levels to the packets such that low priority packets are
dropped ﬁrst in the case of congestion. Table 2 summa-
rizes the priority levels ordered from the highest to the
lowest.
This priority applies to both static and BE classes. If the
congestion persists within the ﬁrst-priority traﬃc, the con-
gested link assigns to it a weighted fair share of the available
static-class bandwidth proportional to each destination do-
main’s static allocation.
Recall
Determine reservable dynamic bandwidth.
that the dynamic bandwidth class has deﬁned bandwidth
sub-classes, such as 512 Kbps, 1 Mbps, 2 Mbps, etc., and
each dynamic channel is associated with a given sub-class.
Intuitively, to provide precise bandwidth guarantees for es-
tablished ﬂows, we have to ensure that every STRIDE-
protected request packet can be oﬀered suﬃcient dynamic
bandwidth (e.g., at least 512 Kbps). Ideally, we would like to
provide guaranteed ﬂow bandwidth to every request packet
traversing static channels, as Table 1 shows.
One key challenge here is how to ﬂexibly determine the
amount of reservable dynamic bandwidth for such requests.
To address this challenge, STRIDE limits the rate of the dy-
namic channel setup requests (thus the dynamic allocation)
within the static class to be proportional to the static allo-
cation. For example, if each dynamic channel is guaranteed
10 units per second and expires in 2 seconds, and the rate
limit is 3 requests per second, then the dynamic-class link
bandwidth should be greater than 10·2·3 units per second to
accommodate the worst case where all requests arrive using
the static class.
The AD assigns the smallest sub-class to the initial re-
quest and ﬂexibly upgrades to a higher sub-class for the
subsequent requests for the allocation renewal if the link is
not congested. In the case of link congestion on the up-path
(down-path), each source (destination) domain obtains a
weighted fair share of the available dynamic-class bandwidth
that is proportional to the source’s (destination’s) static al-
location on the congested link.
Each AD on the path (including the destination AD) ei-
ther approves the requested dynamic bandwidth, or indi-
cates the maximum available bandwidth (which is at most
the available bandwidth indicated by the previous AD).
 Dynamic-class bandwidth allocation: Through a
dynamic-channel setup request, a destination endhost can
discover the bottleneck link(s) and the available dynamic-
class bandwidth along the path. The destination constructs
a reply packet, which carries (1) reserved dynamic-class
bandwidth of this ﬂow, (2) opaque ﬁelds (which include a
dynamic ﬂow capability), and (3) expiration time which in-
dicates the lifetime of the guaranteed dynamic bandwidth.
The destination also indicates which AD-to-AD link(s) is the
bottleneck for determining the bandwidth reservation.
As the packet travels back to the source, ADs update
their dynamic bandwidth allocation and opaque ﬁelds to
accurately reﬂect the available bandwidth and reduce the
potential waste of bandwidth. If the allocated end-to-end
dynamic bandwidth does not meet the source’s need (e.g.,
determined by an application service), the source may select
an alternative path. Furthermore, the source can make an
informed decision to avoid the bottleneck link when selecting
an alternative path.
Capability update. A source can renew the short-term
dynamic capability while communicating with the destina-
tion as follows: the sender sets a renewal bit in the header of
the capability-protected dynamic-class packets. If the des-
tination renews, the source AD invalidates the old dynamic
capability (e.g., by keeping track of the latest capability for
each ﬂow and rejecting packets carrying old capabilities) to
prevent misuse.
 Guaranteed data transmission: Upon receiving a dy-
namic capability (step ), src can use the end-to-end dy-
namic channel for guaranteed data transmission. Src can
also ﬂexibly choose other types of end-to-end channels for
diﬀerent guarantees.
For per-ﬂow bandwidth guarantees, end-
Regulation.
point ADs monitor per-ﬂow data usage and regulate poten-
tial violation. For example, every endpoint AD ensures that
the overuse bit is set in data packets whose ﬂow rate exceeds
the allocated value. ADs are responsible to drop some of the
data packets with the overuse bit to resolve link congestion.
For example, similar to the static channel regulation, the AD
can drop packets that are beyond the weighted fair share of
the source or the destination. In addition, intermediate ADs
and the TDC can perform both real-time probabilistic mon-
itoring and oﬄine traﬃc analysis to identify misbehaving
endpoint ADs that fail to regulate their clients. TDCs and
ADs also monitor per-TD bandwidth usage of dynamic-class
traﬃc at each interface at the TD boundary to isolate attack
traﬃc from other TDs.
6. BANDWIDTH GUARANTEE ANALYSIS
We ﬁrst show that STRIDE achieves domain-based guar-
antees for communication between the source (ADsrc) and
the destination (ADdst) domains within a TD; speciﬁcally,
we analyze what domain-based guarantees ADsrc can ob-
tain using diﬀerent types of channels. We then discuss how
an endpoint AD can divide such domain-based guarantees
among its endhosts.
In Theorem 1, we show that by leveraging private
down-paths, ADsrc and ADdst can establish bandwidth-
guaranteed static channels for congestion-free communica-
tion. Let ui and di be ADi’s total static up-path and down-
path bandwidth allocations, respectively, where 1 ≤ i ≤ m
and m is the number of ADs. Since each AD is expected to
assess its bandwidth requirement of static half-paths based
on its contractual agreements with human subscribers, ui
and di are constant irrespective of the number of ADs or the
power of the botnet (which consists of compromised endhost
421machines). We denote dp(i, j) to be the total bandwidth of
ADj’s private down-paths known only to ADi.
Theorem 1. For private communication (using private
static down-paths), ADsrc can successfully send packets to
ADdst at rate rp = min{usrc, dp(src, dst)} without experi-
encing congestion on any intermediate links.
The ﬁrst domain-based guarantee is
Proof sketch:
straightforward. Since TDC is congestion-free (as described
in Section 3.2), ADsrc can establish end-to-end congestion-
free channels by splicing its static up-paths and ADdst’s pri-
vate static down-paths. The sending rate of the resulting
channels is dominated by the bottleneck bandwidth, which
is the minimum of usrc and dp(src, dst). Both usrc and
dp(src, dst) are independent of the botnet and other ADs’
allocations.
Note that rp is a lower-bound guarantee of the sending
rate, and the congestion-free property ensures that packets,
such as connection setup requests, can be delivered at the
ﬁrst trial.
In Theorem 2, we show that ADsrc can obtain a weaker
guarantee (which depends on the static allocations of other
ADs) when using public static down-paths.
Let U =
Pm
i=1 ui, and U (i) be the total static up-path bandwidth ac-
tivated by ADs that desire to communicate with ADi. Let
bdst be the minimum cut of ADdst’s BE-class bandwidth on
the down-paths.
U ).
U (dst) + bdst
Theorem 2. For public communication (using uncon-
cealed static down-paths), ADsrc can successfully send pack-
ets to ADdst at an average rate r = usrc( ddst
Sources that desire to communicate with
Proof sketch:
ADdst compete for the limited bandwidth of static down-
paths, ddst. Sources do not need to compete with packets to
other destinations on congested links because STRIDE per-
forms weighted fair sharing on the static down-paths. To
obtain the highest traﬃc priority and increase the chance
of successful delivery, each source sends packets with no
overuse bit on its static up-paths at full speed, resulting
in U (dst)-amount of high-priority traﬃc to ADdst. Hence,
ADsrc with usrc static allocation can send packets through
static down-paths at rate usrc·ddst
(e.g., bit/s) on average.
U (dst)
A similar result can be shown for the case where sources
compete for the BE bandwidth on the congested links (bdst).
Since the BE class is shared, in the worst case ADsrc has to
compete with traﬃc between all ADs in the TD, resulting
in a sending rate usrc·bdst
. Hence, the average waiting time
before successfully delivering a packet of size w is w
r . The
waiting time for using the static channel and the static+BE
channel is linear to U (dst) and U , respectively.
U
Theorem 3 shows that ADsrc can obtain a lower-bound
guarantee on the dynamic allocations to ADdst. Let γ be
the ratio of the dynamic-class bandwidth to the static-class
bandwidth, and we assume γ is the same for every link for
ease of description. ∆(i, j) is the guaranteed dynamic-class
bandwidth that ADi would like to allocate for communica-
tion with ADj.
Theorem 3. For dynamic channels, STRIDE guaran-
tees min{∆(src, dst), ∆(dst, src)} amount of dynamic-class
bandwidth for the ﬂow aggregate between ADsrc and ADdst,
where Pm
i=1 ∆(dst, i) ≤ γ ·ddst.
Proof sketch: Because STRIDE performs weighted fair
sharing within the dynamic class based on the static alloca-
tion, the ﬂow aggregates from ADsrc and to ADdst are guar-
i=1 ∆(src, i) ≤ γ ·usrc and Pm
anteed to have γ · usrc and γ · ddst bandwidth, respectively.
Endpoint ADs can then freely divide the guaranteed band-
width to ﬂow aggregates going to/from diﬀerent ADs.
src and d′
Each endpoint AD
Splitting guaranteed bandwidth.
decides how to divide its bandwidth guarantees among its
endhosts based on its local policy. For example, a simple
policy would be to split the static allocation based on per-
host fair share. Suppose the sender and the receiver obtain