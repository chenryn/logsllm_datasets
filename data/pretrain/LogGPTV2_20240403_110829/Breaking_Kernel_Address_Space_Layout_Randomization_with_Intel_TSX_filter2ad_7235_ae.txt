reading mapped (M) and unmapped (U) pages, and jumping
into executable (X), non-executable (NX), and unmapped (U)
pages. Tracepoints are data TLB loads/misses, instruction TLB
loads/misses, L1 instruction cache misses, and L1 data cache
load/misses. Reading of U page generated data TLB misses and
jumping into NX page or U page generated instruction TLB
loads or misses. The remaining tracepoints were similar to each
other.
Figure 8: Simplified Intel Skylake architecture including
pipeline and cache hierarchy. We omitted L2, last level, and any
other page table caches for simplicity. Each M, U, X, and NX in-
dicates the locations where access violation checks are checked
according to our measurements. Note that decoded icache,
which caches decoded micro-ops, is inside L1 icache [31].
(5–21). This was because DrK had better accuracy than
the prior attack and DrK was able to use not only size
signatures but also executable mapping status.
5
In-depth Analysis of DrK
In this section we figure out what causes DrK observe
timing differences. Since the internal characteristics of In-
tel processors are barely documented, we first take a look
into detailed measurements on hardware events during
the DrK attack using the hardware performance counter
(HPC) (§5.1). Then, we analyzed the measurement results
to figure out what causes the time difference between
mapped and unmapped pages (§5.2) and between exe-
cutable and non-executable pages (§5.3), in accordance
with a simplified Intel CPU architecture diagram (Fig-
ure 8).
11
5.1 Measuring Hardware Events
We probed a memory page 1,000,000 times while mea-
suring hardware events using the HPC. We tested the
following five of memory probings:
1. read a mapped kernel page
2. read an unmapped kernel page
3. jump into an executable kernel page
4. jump into a non-executable kernel page
5. jump into an unmapped kernel page.
On probing, we set tracepoints to measure:
1. dTLB-loads: the total number of attempts to load
data translation lookaside buffer (dTLB), including
cache hit on dTLB.
2. dTLB-load-misses: the number of failed attempts to
load dTLB; cache miss on dTLB.
3. iTLB-loads: the total number of attempts to load in-
struction TLB (iTLB), including cache hit on iTLB.
4. iTLB-load-misses: the number of failed attempts to
load iTLB; cache miss on iTLB.
5. L1-icache-load-misses: the number of failed at-
tempts to load L1 instruction cache (icache), cache
miss on icache.
6. L1-dcache-loads: the total number of attempts to
load L1 data cache (dcache), including dcache hit.
7. L1-dcache-load-misses: the number of failed at-
tempts to load L1 dcache; dcache miss.
Note that we were unable to measure L1-icache-loads
because all CPUs supporting TSX we had (listed in Ta-
ble 3) did not support the counter for it. Table 6 summa-
rizes the results measured in the Linux machine with Intel
Core i7-6700K (Skylake) 4.0 GHz CPU.
5.2 Mapped versus Unmapped Pages
We conjecture that dTLB makes timings for mapped
and unmapped kernel pages differently, by its different
caching behavior on page mappings. As introduced in §3
and §4, a TSX abort handler for a violation of reading
mapped kernel memory (M) was called faster than that for
a violation of reading unmapped kernel memory (U). We
believe that the timing difference is originated by dTLB
hit on accessing a mapped memory (fast), and dTLB miss
for an unmapped memory (slow).
Table 6 supports this hypothesis: while reading an un-
mapped (U) page generated a lot of (over two millions)
dTLB misses (dTLB-load-misses, marked in red), access-
ing on a mapped page (M) was not. The counter shows
that the access to a mapped kernel memory is cached in
dTLB, and in subsequent probing, the page privilege is
checked with just accessing on dTLB. This results faster
determination of page fault exception. In contrast, the
access to an unmapped kernel memory is not cached,
ExecutionUnitInstructionSchedulerFetchDecodeMemoryUnitDecodedicacheL1 icacheL1 iTLBL2 TLBL1 dcacheL1 dTLBL2cacheMemory(page table)XNXMUbecause it has no corresponding physical address to be
cached in dTLB. After suffering dTLB-miss, the probing
should wait until the processor seek the page table entry
then figuring out the page fault exception. Thus, a read
attempt to an unmapped page took longer time for raising
the page fault exception (and calling TSX abort handler).
We note that this explanation corresponded to Hund et
al. [28]’s finding.
case that other cores have updated the permission on the
page table. Walking through the page table resulted as
the page is non-executable, then the processor generates
a page fault exception.
U page takes the same path as the mapped versus un-
mapped case. After the iTLB miss, the processor walks
through the page table, figures out the address is not
mapped, and generates a page fault.
5.3 Executable
Pages
versus Non-executable
6 Potential Countermeasures
We conjecture that decoded icache is the hardware com-
ponents that handle executable and non-executable kernel
pages differently, as shown in timing differences. In the
DrK attack, timing of probing executable (X) page was
measured as faster than that of non-executable (NX) page.
While it could be thought as caching in iTLB would gen-
erate such timing difference, nonetheless, it is not true.
Table 6 supports the hypothesis as follows.
iTLB is not the origin.
Unlike the result on
mapped/unmapped pages, jumping into X did not gener-
ate any additional iTLB loads (590 in iTLB-loads on 1 M
accesses). This means that iTLB hit did not even happen
on the probing. Moreover, although iTLB actually hits on
probing NX page, the timing of NX page is not as fast as
X. Further, although probing on U page generates many
iTLB misses, the timing of NX page and U was the same
(see Table 3). This proves that iTLB is not the origin of
the timing channel.
Decoded icache for faster timing on X. Table 6 also
implies that, unlike executing NX and U, probing on X
did not need to translate the virtual address to the phys-
ical address to fetch instructions. From the observation,
we come up with a hypothesis that decoded icache is the
origin of the timing channel; decoded icache is the place
in which fetched and decoded micro-ops are cached (Fig-
ure 8). On probing an executable memory page, once the
page is cached (in iTLB) and decoded, the processor no
longer needs to translate the address. Instead, it directly
fetches instructions from the decoded icache, however, the
actual execution fails due to the access violation. Since
the probing only plays with cached data, the exception is
generated relatively faster than probing other page map-
pings.
Page walk for NX and U. We conjecture that page faults
for NX and U pages are generated when the processor
finished the page table walk, since their timings are the
same (Table 3). For a non-executable (NX) page, we
hypothesize the flow as follows. Although the translation
is cached in iTLB, the cached page table entry is marked
as non-executable. Due to this mismatch, the processor is
required to resolve the latest page table entry. Since there
is no coherency mechanism in TLB [25], there could be a
We discuss potential countermeasures against the DrK
attack. In summary, we see there are no effective counter-
measures that can prevent DrK without hurting usability
and performance.
6.1 Eliminating Timing Channel
One of the most fundamental countermeasures against
DrK is eliminating any timing differences when probing
the kernel addresses at the user-level execution. When the
Intel CPU handles exceptions for unprivileged accesses,
it takes different hardware paths according to whether
the accessed memory region is executable, mapped, or
unmapped. §5 shows our measurements about the dif-
ferences in terms of the loads and misses of cache and
TLB.
Hardware modification. One possible way to flatten
the timing differences is modifying the hardware. For
example, we can change the CPU to not cache unprivi-
leged accesses to kernel addresses, which makes every
unprivileged memory access take the same hardware path.
Any timing channel attacks, including DrK and Hund et
al. [28], cannot observe timing differences and would
therefore fail. However, since this solution demands hard-
ware modifications, it cannot protect already deployed
CPUs from DrK.
Kernel page table separation. Another countermeasure
against DrK is separating the kernel page table from a user
page table. If no kernel memory is mapped into a user
page table, DrK would have no chance to break KASLR.
However, the kernel address space is mapped into a user
page table to minimize the execution overhead of privi-
leged instructions (e.g., system call). Without this, the
system would need to flush TLBs whenever a user process
invokes a system call, which would significantly reduce
the overall system performance [6, 28]. For example, Xen
uses separated page tables for kernel and user processes
when a guest machine is a 64-bit para-virtualized machine
(PVM), but this degrades system performance such that
the 64-bit PVM is not recommended [47] for use. There-
fore, It is impractical to adopt this countermeasure due to
performance degradation.
12
6.2 Monitoring Hardware Events
Modern CPUs provide HPC interfaces to monitor hard-
ware events that occur inside a CPU, such as the num-
bers of retired instructions, taken branches, and cache
loads/misses. Although the OS cannot observe any page
faults while being attacked by DrK, it can infer whether
DrK is being performed by using the hardware event in-
formation. For example, we identified that during the
DrK attack, a CPU generates lots of loads/misses on
both TLBs and the L1 i-cache (see Table 6). Further,
the HPC provides information about the number of trans-
actional aborts (tx-abort) generated by a CPU. This num-
ber would be large when the system is under attack by
DrK because each memory probing generates an abort.
However, monitoring hardware events has limitations
to detect DrK in terms of accuracy and performance. First,
a benign program can show a similar behavior with DrK
when it randomly accesses different memory regions or
heavily uses TSX. Further, DrK can cloak its behavior
by decreasing the frequency of memory probing. Thus,
the system cannot avoid false detection problems. Next,
monitoring all processes of the OS is unrealistic due to
the overhead of checking HPC: about 20% performance
overhead [60]. System-wide monitoring could reduce
the overhead, but, in that case, it is difficult to determine
which process engages in suspicious behavior.
6.3 Live Re-randomization and Fine-
grained KASLR
One possible approach to cope with DrK is to use fine-
grained ASLR and live re-randomization [23]. They not
only adjust the base addresses of kernel code and mod-
ules, but also randomize all kernel code, static data, stack,
dynamic data, and modules while re-randomizing them
periodically.
However, as shown in Table 4, DrK only took around
0.5 seconds in Linux for detecting full page mappings
with 100% of accuracy. Moreover, to detect a single
module not the whole space, the attack can be more faster
(proportional to the scan size). This implies that the OS
needs to re-randomize its address space more than once
per each second, which is problematic due to performance
overhead.
6.4 Other Countermeasures
Lastly, we introduce a few mechanisms that can prevent
or mitigate DrK, but these are less practical.
Disabling TSX. The strongest countermeasure against
DrK, though a naïve one, is disabling TSX. As a CPU
manufacturer, Intel can disable the feature via a microcode
update or product line change. In fact, Intel had already
disabled TSX of the Haswell CPU due to its hardware
bug (Erratum HSD136 in [30]). However, this solution
is problematic because TSX is already widely used; e.g.,
glibc uses TSX in its pthread library for synchronization
and Java uses TSX for thread scheduling [35, 46].
Different caching policy. TSX only works with mem-
ory regions configured as write-back ([31, §15.3.8.2]),
which is a default configuration due to its efficiency. On
our experiment, we observed a few (288 pages among
26,066 pages in Windows) memory pages in driver area
configured as write-through or uncacheable and DrK mis-
judged them as unmapped pages. Although those pages
are not belong to any kernel drivers, (i.e., it does not af-
fect on the accuracy evaluation) this implies that if an OS
makes the entire kernel memory either write-through or
uncachable, it can be secure against DrK. However, this
configuration is impractical, as it results in huge perfor-
mance degradation [6].
Noisy timer. Finally, a noisy timer or coarse-grained
timer is a well-known countermeasure against timing at-
tacks. The system can add some noise when returning a
timer value or prevent a user program from using a fine-
grained timer (e.g., rdtsc). However, the noisy timer is
just a work-around such that it cannot completely pre-
vent DrK. Also, many benign programs need to use fine-
grained timer, e.g., to precisely measure performance.
7 Discussions
Limitations. DrK has some limitations. First, DrK
always treats uncachable, write-through, and paged-out
memory regions as unmapped. DrK relies on Intel TSX,
which only works with memory pages configured as write-
back ([31, §15.3.8.2]). Thus, it cannot probe memory
pages configured as uncachable or write-through; its ac-
cess to such memory pages always aborts. DrK also treats
swapped-out pages as unmapped because access to such
pages generates a page fault which aborts the transaction
([31, §15.3.8.2]).
However, we did not observe write-through pages for
code and data area of kernel and drivers, in both Linux
and Windows, because write-through pages are slower
than write-back pages. Due to the performance issues,
kernel developers would not use the write-through pages
in general. Further, most of the important kernel pages,
such as kernel text, data, and drivers, are frequently used,
so they are usually kept in memory (i.e., not paged out).
Therefore, these limitations are negligible.
Breaking “security by memory obscurity”. DrK can
also be applied to launch an undetectable, crash-resistant
memory mapping probing [21]. Some system protec-
tion mechanisms, such as CPI [36], ASLR-Guard [40],
and Kenali [54], assume a secret memory location that
the attacker cannot know to store sensitive information
13
for integrity protection. However, using DrK, such an
assumption could be broken if such a secret address is
not selected carefully, because the DrK attack can fully
search for the address space without any crash. We plan
to figure out how we can use DrK to break such protection
mechanisms.
8 Related Work
In this section, we provide a comprehensive landscape of
past research related to the DrK attack.
Endless war in ASLR. Since the most modern OSes
adapt W⊕X and ASLR to prevent code injection and
code reuse attacks [12, 49, 51, 52], attackers and de-
fenders continuously find new attacks to break ASLR
and develop countermeasures against them. Researchers
find that many ASLR implementations are insecure be-
cause they do not fully randomize address spaces (e.g.,
shared libraries without ASLR and fixed memory allo-
cation) and do not provide enough entropy (e.g., lim-
ited mapping range and large alignment size) to avoid
performance degradation. These make the ASLR im-
plementations vulnerable to prediction and brute-force
attacks [9, 12, 18, 51, 52]. To prevent such attacks,
researchers propose fine-grained ASLR technologies
that randomize the location of functions [7, 34], basic
blocks [59], and even instructions and registers [27, 48].
On the other hand, researchers also discover that even
fine-grained ASLR can be broken by information leak
vulnerabilities [50, 55], since they let attackers know de-
randomized addresses. By using it, Snow et al. [53]
break the fine-grained ASLR. To mitigate such an at-
tack, three kinds of schemes have been proposed: (1)
dynamic (re-)randomization [4, 8, 16, 22, 23, 39] to
make leaked information useless, (2) execution-only mem-
ory [3, 11, 15] and destructive code read [56] to prevent
attackers from reading any code gadgets, and (3) pointer
integrity [14, 36, 40] to prevent code pointer manipula-
tion.
In addition, researchers recently found that memory
de-duplication can be used to break ASLR without infor-
mation leak vulnerabilities [5, 10].
Timing attacks against KASLR. Hund et al. [28]
present a timing side channel attack against kernel space
ASLR, which is the work most relevant to DrK. The main
advantage of these timing attacks over the previous ASLR
attacks is that they neither relies on weak implementations
of ASLR nor information leak vulnerabilities.