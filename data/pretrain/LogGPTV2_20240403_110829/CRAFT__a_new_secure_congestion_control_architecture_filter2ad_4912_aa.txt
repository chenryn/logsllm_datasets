title:CRAFT: a new secure congestion control architecture
author:Dongho Kim and
Jerry T. Chiang and
Yih-Chun Hu and
Adrian Perrig and
P. R. Kumar
CRAFT: A New Secure Congestion Control Architecture
Dongho Kim †, Jerry T. Chiang †, Yih-Chun Hu †, Adrian Perrig ‡, and P. R. Kumar †
†Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, IL, USA
‡Department of Electrical and Computer Engineering, Carnegie Mellon University, PA, USA
†{dkim99,chiang2,yihchun,prkumar}@illinois.edu, ‡PI:EMAIL
ABSTRACT
Congestion control algorithms seek to optimally utilize network re-
sources by allocating a certain rate for each user. However, mali-
cious clients can disregard the congestion control algorithms im-
plemented at the clients and induce congestion at bottleneck links.
Thus, in an adversarial environment, the network must enforce the
congestion control algorithm in order to attain the optimal network
utilization offered by the algorithm.
Prior work protects only a single link incident on the enforce-
ment router, neglecting damage inﬂicted upon other downstream
links. We present CRAFT, a capability-based scheme to secure all
downstream links of a deploying router. Our goal is to enforce a
network-wide congestion control algorithm on all ﬂows. As a ref-
erence design, we develop techniques to enforce the TCP conges-
tion control. Our design regulates all ﬂows to share bandwidth re-
sources in a TCP-fair manner by emulating the TCP state machine
in a CRAFT router. As a result, once a ﬂow passes a single CRAFT
router, it is TCP-fair on all downstream links of that router.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: General—Secu-
rity and protection
General Terms
Security
Keywords
TCP, Congestion Control
1.
INTRODUCTION
The congestion control problem of fairly distributing network
resources among users is a long-standing problem in networking
research community. While most work in congestion control as-
sumes that all entities follow the rules speciﬁed by a congestion
control algorithm, some work has also considered an adversarial
environment where a misbehaving user deviates from the speciﬁed
rule [10, 11], thereby gaining network resource allocation that ex-
ceeds his fair share or suppressing the network resource allocated
to others.
Some work adopts a reactive approach to defend against misbe-
having users. Floyd et al. [4] use a TCP throughput equation to
determine the proper throughput for a ﬂow and categorize any ﬂow
Copyright is held by the author/owner(s).
CCS’10, October 4–8, 2010, Chicago, Illinois, USA.
ACM 978-1-4503-0244-9/10/10.
FA
L1
N flows
Bottleneck point
RD,1
L2
RL,1
L3
L5
RL,2
L4
L6
2N flows
RL,3
Figure 1: An example that illustrates single-link protection is
insufﬁcient for protecting downstream links.
using more than its fair throughput as “not TCP friendly”. Sto-
ica et al. [12] estimate the rate of a ﬂow and assign that ﬂow a fair
share of a link according to the estimated rate. In contrast to the
protocols proposed by Floyd et al. and Stoica et al., fair queue-
ing [3] is a preventive approach where a router allocates a ﬁxed
amount of bandwidth to a ﬂow or the aggregate of several ﬂows
when that router experiences congestion.
Problem. We consider the purpose of these schemes to be fair
sharing of network bandwidth. One might view congestion con-
trol as a scheme that rate-limits trafﬁc before congestion happens
to avoid wasting network bandwidth. The fairness of congestion
control algorithm can be formalized using an optimization frame-
work [7]. In this context, past work for securing fair rate allocation
provides desirable properties for the fair sharing of the link immedi-
ately behind a deployed router. However, these schemes have a lim-
itation in early phases of deployment where some routers may not
have yet deployed the scheme. In such situations, the link behind a
legacy router can be prone to congestion. Since different links have
a different number of traversing ﬂows and different amount of link
bandwidth, the fair share on a deployed link is not necessarily the
fair share on a downstream legacy link. This limitation motivates
us to study a minimal deployment scheme that securely provides
fair sharing of downstream links.
Illustration. We illustrate how a single-link protection mecha-
nism is not sufﬁcient to enforce that every ﬂow in the network fairly
shares network bandwidth at its bottleneck link. Figure 1 shows a
network in which all links have the same link capacity and some
routers do not deploy any protection mechanism. In this example,
we use the concept of fairness as equal share of bandwidth. Let
there be a ﬂow that traverses multiple links together with different
number of ﬂows at each link. The bandwidth-fair rate of a ﬂow
traversing a link is simply the bandwidth of the link divided by the
number of ﬂows sharing the link. In this example network, ﬂow FA
and N other ﬂows traverse router RD,1 that deploys a single-link
N +1 of the
protection mechanism, enforcing that each ﬂow gets
link capacity. That is, FA shares link L2 with N other ﬂows in a
bandwidth-fair manner. Suppose FA’s destination is different from
1
705that of the other N ﬂows; then FA, but not any of the N other ﬂows,
would traverse the legacy router RL,2. This legacy router does not
employ any fairness-guaranteeing schemes. If 2N other ﬂows also
traverse through the router RL,2, FA could obtain roughly twice as
much bandwidth as each of the other 2N ﬂows could.
Challenge. One possible solution of this problem is letting a de-
ployed router obtain information about the status of a bottleneck
link and adjust ﬂow rates accordingly. However, it is difﬁcult to es-
timate the proper fair share of bottleneck link bandwidth. Though
the router incident to a bottleneck link can deliver enough infor-
mation for a deployed router to adjust ﬂow rates, this approach re-
quires the router incident to the bottleneck link to do some work.
In other words, it still requires some level of deployment.
Our approach. To provide network-wide protection against mis-
behaving ﬂows, we securely enforce TCP behavior by emulating
the TCP state machine of each ﬂow. The rationale behind enforcing
TCP is that TCP is an end-to-end protocol that provides network-
wide fair rate. Since TCP is end-to-end, it treats the network as
a black box and does not require any information about the fair
share of a bottleneck link. Different from our example, our goal
of enforcing TCP fairness is not to assign equal rates since TCP
rate of each ﬂow depends on several factors, such as round trip
time. There is theoretical work [9] that analyzes the fairness of TCP
using optimization-based framework and obtains a utility function
optimized by TCP.
In our poster, we present CRAFT (Capability-based Regulation
of All Flows and Trafﬁc), a secure congestion control architecture
that provides network-wide fairness in a partially-deployed net-
work.
2. PROTOCOL
In this section, we present how a CRAFT router can securely
emulate the TCP state machine of a traversing ﬂow. To better un-
derstand the concept of our approach, we ﬁrst present a strawman
design. Our strawman design illustrates a method that emulates the
TCP congestion control protocol [1] with high overhead in an ide-
alized environment where all packets reach the destination in order.
We provide careful treatment on how CRAFT relaxes these limita-
tions in Section 2.2.
Emulated 
TCP state 
Congestion 
window
Cf,i
5. Forward
Cf,i
6. Verify
Pf,i
2. Receive
Sender
CRAFT Router
Legacy Router
Receiver
4. Receive
1. Generate
Cf,i
Pf,i
3. Calculate
Cf,i
Figure 2: Capability-based enforcement of TCP congestion
control algorithm. A CRAFT router generates a pre-capability
(Pf,i) for a packet (i) of a ﬂow (f ). After the receiver gets the
pre-capability, the receiver calculates and forwards a new ca-
pability (Cf,i) to the sender. The sender includes received ca-
pability to the CRAFT router in a future packet.
dom Value back to the sender along with the TCP acknowledgment.
The next time the sender wishes to send a packet to the receiver, the
sender includes in the packet the Random Value he received that
was embedded in the acknowledgment of the previous packet.
Since we assumed that the path from the sender to the receiver
does not change, the data packet including the Random Value will
reach the strawman router. The strawman router then veriﬁes that
the Random Value included in the packet is the same as that stored
in the router. Since the Random Value is generated by the straw-
man router, a matching pair of Random Values in the packet and in