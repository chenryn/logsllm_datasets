ta(ad) for each of their daughter agents ad. They use this
vector in accordance with the EigenTrust algorithm [7] to
compute a global trust value tad for each daughter agent.
5. Discussion
Penny inhibits the spread of low-integrity data (e.g., mal-
ware) by maintaining a centralized integrity label for each
object shared over the network. Agents wishing to avoid
such data can therefore consult each object‚Äôs integrity la-
bel before downloading it. Thus, the problem of restraining
the spread of malware over a Penny network reduces to the
problem of efÔ¨Åciently maintaining and reporting accurate
integrity labels.
Label retrieval is efÔ¨Åcient in Penny, requiring approxi-
mately the same number of messages as object lookup in a
Chord network. An agent can retrieve any object‚Äôs integrity
label by sending a single request message, which gets for-
warded at most O(log N +k) times throughout the network.
The request solicits O(k) response messages, which are
aggregated to compute the centralized integrity label (see
Equation 1).
An object‚Äôs centralized integrity label is determined by
the votes of other agents in the network (see Equation 4).
Votes are weighted by the reputation of each voter so that
the votes of agents who are widely regarded as trustworthy
are more inÔ¨Çuential than the votes of those who are not.
This makes it difÔ¨Åcult for a malicious agent to attach a high-
integrity label to low-integrity data.
In order for such an
attack to succeed, malicious agents must collectively have
such good reputations that they outweigh the votes of all
asvr

areq


public key request
akh ,(cid:104)id o, isvr (o), csvr (o), Ksvr(cid:105)Kkh
asm
-
Kkh
key svr , tsvr ,
(cid:104)id o, isvr (o), csvr (o), Ksvr(cid:105)Kkh
Figure 4. Publish protocol.
id o
akh
--
key svr1 ,Ksvr1, key svr2 , ...
ikh(o), ckh(o),
key svr ,(cid:104)id o(cid:105)Ksvr
key svr , ‚àÜtreq(asvr )
asm
-
-
areq ,(cid:104)id o(cid:105)Ksvr
data o
akh
--
-
asvr
-
Figure 5. Request protocol.
other voters. Penny uses the EigenTrust algorithm [7] to
track agent reputations and to prevent malicious agents from
accruing good reputations.
Penny employs both secure hashing and replication to
protect against malicious key-holders and score-managers
who might falsify an object‚Äôs centralized integrity labels or
an agent‚Äôs centralized trust value. Use of a secure hash
function for identiÔ¨Åer assignment ensures that agents can-
not dictate the set of objects and agents for which they serve
as key-holders and score-managers. By ensuring that there
exist at least k key-holders and score-managers for every
key-range, Penny prevents any one agent from subverting
the reputation of any object or agent. At least k/2 agents
in a neighborhood must be malicious in order to subvert a
reputation.
Malicious peers cannot elevate their own reputations by
switching IP addresses or creating false network accounts
because, as in EigenTrust, all agent and object reputations
start at zero in Penny. A peer or object acquires a positive
reputation only by participating in positive transactions with
other peers. Peers with established reputations then report
positive feedback for those transactions, elevating the new
peer‚Äôs reputation.1 Changing IP addresses or creating a new
account therefore never results in an increase to the peer‚Äôs
reputation.
The protocol described in ¬ß4.3 also enforces a notion of
object ownership privacy by separating information linking
1This obviously means that if all peers in the network have reputation
zero, no reputations can be elevated. To prevent this, a root set of network
founders start with reputation 1 at network initialization.
322322
a server to the objects it owns. SpeciÔ¨Åcally, key-holders for
an object learn only the keys of servers who own the object
but not the identiÔ¨Åers themselves, whereas score-managers
learn the identities of the servers but not the identiÔ¨Åers of
the objects they own. A malicious score-manager asm and a
malicious key-holder akh can cooperate to learn that a par-
ticular server asvr owns a particular object o, but only if
key svr ‚àà kr(asm) and key o ‚àà kr(akh) both hold, which is
unlikely when the size of a malicious collective is not sig-
niÔ¨Åcant relative to the size of the network.
Key-holders and score-managers can, of course, learn
ownership information through guessing attacks, but this is
prohibitively expensive when the space of object and agent
identiÔ¨Åers is large. For example, a malicious agent am
can discover if a particular object o is served by any agent
for which am serves as score-manager by requesting id o
and comparing the key-holders‚Äô responses against its list of
daughter agents. However, am cannot easily produce a list
of all objects served by any of its daughter agents because
to do so it would have to search the entire space of object
identiÔ¨Åers. Likewise, am can discover if a particular server
asvr owns any object for which am serves as key-holder. To
do so, am computes key svr and searches for that key in its
list of keys of servers that own am‚Äôs daughter objects. How-
ever, am cannot easily produce a list of all servers that own
any given object because it would have to search the entire
space of server identiÔ¨Åers.
In addition to integrity labels, Penny also maintains cen-
tralized conÔ¨Ådentiality labels for objects. Agents can use
these labels as a basis for selectively serving data to other
peers‚Äîpossibly based on the requester‚Äôs trust level or other
credentials. However, to enforce stronger conÔ¨Ådentiality
policies, such as mandatory access control policies that pro-
hibit low-trust agents from obtaining high-conÔ¨Ådentiality
data, agents need a means to detect conÔ¨Ådentiality viola-
tions and report them to the trust management system. This
is necessary to force a misbehaving agent‚Äôs trust value to
decrease, preventing future violations. Detecting conÔ¨Åden-
tiality violations is a challenging research problem, and is
discussed in ¬ß6 as part of future work.
6. Conclusion and Future Work
Penny combines reputation-based trust management
(based on EigenTrust [7]), distributed hash tables (based on
Chord [9]), and anonymizing tunnels (based on Tarzan [22,
23]) to support secure integrity and conÔ¨Ådentiality label-
ing of shared data as well as ownership privacy for object
servers. The protocol enforces these security guarantees in
an efÔ¨Åcient manner that avoids broadcast messages or large-
scale polling of peers. Object lookup can be performed with
O(log N + k) messages, where N is the number of agents
in the network and k is a constant that controls how much
replication is used to protect against malicious agents.
We are in the process of implementing Penny client soft-
ware in Java. This ongoing research is aimed at evaluating
Penny in a practical setting to verify that the network struc-
ture is (i) efÔ¨Åcient enough to handle realistic P2P network
trafÔ¨Åc, and (ii) robust enough to prevent malicious collec-
tives from subverting integrity labels, conÔ¨Ådentiality labels,
and trust values.
Future research should also consider how to enforce var-
ious information Ô¨Çow and access control policies based on
Penny‚Äôs integrity and conÔ¨Ådentiality labeling system. For
example, Penny‚Äôs publish and request protocols might be
augmented with security checks that block the dissemina-
tion of objects whose integrity labels lie below a certain
threshold. This would have the effect of censoring known
malware from the network.
One might also enforce a corresponding conÔ¨Ådentiality
policy that prohibits low-trust agents from obtaining high-
conÔ¨Ådentiality data, but this is a more difÔ¨Åcult research
challenge.
In order to prevent future conÔ¨Ådentiality vio-
lations, the trust management system must be informed of
past conÔ¨Ådentiality violations. It is unclear how to ensure
that past conÔ¨Ådentiality violations get reported, since typi-
cally the only witnesses of these violations are the malicious
agents involved in leaking the data. Enforcing strong con-
Ô¨Ådentiality policies in P2P networks therefore remains an
interesting open problem.
Our analysis did not consider attacks upon the P2P net-
work overlay itself, such as denial of service, message mis-
routing, message tampering, or trafÔ¨Åc pattern analysis. Us-
ing trust values to change the routing structure (so as to
avoid routing messages through malicious agents) is an in-
teresting and active area of research that might address these
vulnerabilities. In addition, our network remains vulnerable
to certain Sybil attacks [24], wherein an individual mali-
cious agent masquerades as many different agents with dif-
ferent identiÔ¨Åers in an effort to control a large percentage
of the identiÔ¨Åer space, or to cast multiple votes. Future
work should investigate augmenting the EigenTrust algo-
rithm with IP address clustering and other techniques aimed
at identifying malicious collectives that are actually com-
prised of many pseudonyms of a single peer.
Finally, Penny is one contribution to the larger research
question of how to combine anonymity with reputation-
based trust management. Anonymity and reputation-based
trust are often at odds because it is difÔ¨Åcult to divulge an
agent‚Äôs reputation without also divulging its identity. Penny
illustrates one way to communicate and evaluate the repu-
tation of an agent without fully disclosing its identity; how-
ever, divulging the agent‚Äôs reputation might in some cases
reduce the anonymity of a transaction (e.g., in cases where
the attacker is powerful enough to search the space of all
agent reputations in the network for a match). Development
of more general-purpose algorithms for evaluating the trust-
worthiness of a message-sender without knowing its iden-
tity would allow P2P networks to safely enforce stronger
privacy policies in decentralized settings.
References
[1] Napster. http://www.napster.com
[2] Gnutella. http://www.gnutella.com
[3] KaZaA. http://www.kazaa.com
[4] Limewire. http://www.limewire.com
[5] Shin, S., Jung, J., Balakrishnan, H.:
Malware
prevalence in the KaZaA Ô¨Åle-sharing network.
In:
Proc. 6th ACM SIGCOMM Internet Measurement
Conf. (IMC‚Äô06), Rio de Janeiro, Brazil (October
2006) 333‚Äì338
[6] Kalafut, A., Acharya, A., Gupta, M.: A study of mal-
ware in peer-to-peer networks.
In: Proc. 6th ACM
SIGCOMM Internet Measurement Conf. (IMC‚Äô06),
Rio de Janeiro, Brazil (October 2006) 327‚Äì332
[7] Kamvar, S.D., Schlosser, M.T., Garcia-Molina, H.:
The EigenTrust algorithm for reputation management
in P2P networks. In: Proc. 12th Int. World Wide Web
Conf. (WWW‚Äô03), Budapest, Hungary (May 2003)
640‚Äì651
323323
[17] Gupta, M., Judge, P., Ammar, M.H.: A reputation
system for peer-to-peer networks. In: Proc. 13th ACM
Int. Workshop on Network and Op. Sys. Support for
Digital Audio and Video (NOSSDAV‚Äô03), Monterey,
California (June 2003) 144‚Äì152
[18] Blaze, M., Feigenbaum, J., Strauss, M.: Compli-
ance checking in the PolicyMaker trust management
system.
In: Proc. 2nd Int. Financial Cryptography
Conf. (FC‚Äô98), Anguilla, British West Indies (Febru-
ary 1998) 254‚Äì274
[19] Marsh, S.: Formalising Trust as a Computational Con-
cept. PhD thesis, University of Stirling, Scotland, UK
(April 1994)
[20] Sabater, J., Sierra, C.: Reputation and social network
analysis in multi-agent systems.
In: Proc. 1st ACM
Int. Joint Conf. on Autonomous Agents and Multia-
gent Sys. (AAMAS‚Äô02), Bologna, Italy (July 2002)
475‚Äì482
[21] Pujol, J.M., Sang¬®uesa, R., Delgado, J.:
Ex-
tracting reputation in multi-agent systems by means
of social network topology.
In: Proc. 1st ACM
Int. Joint Conf. on Autonomous Agents and Multia-
gent Sys. (AAMAS‚Äô02), Bologna, Italy (July 2002)
467‚Äì474
[22] Freedman, M.J., Sit, E., Cates, J., Morris, R.:
In-
troducing Tarzan, a peer-to-peer anonymizing net-
work layer.
In: Proc. 1st Int. Conf. on Peer-to-peer
Sys. (IPTPS‚Äô02), Cambridge, Massachusetts (March
2002) 121‚Äì129
[23] Freedman, M.J., Morris, R.:
Tarzan: A peer-to-
peer anonymizing network layer. In: Proc. 9th ACM
Conf. on Comp. and Comm. Sec. (CCS‚Äô02), Washing-
ton, DC (November 2002) 193‚Äì206
[24] Douceur, J.R.:
In: Proc. 1st
Int. Workshop on Peer-to-peer Sys. (IPTPS‚Äô02), Cam-
bridge, MA (March 2002) 251‚Äì260
The Sybil attack.
[8] Damiani, E., di Vimercati, S.D.C., Paraboschi, S.,
Samarati, P., Violante, F.: A reputation-based ap-
proach for choosing reliable resources in peer-to-peer
networks.
In: Proc. 9th ACM Conf. on Comp. and
Comm. Sec. (CCS‚Äô02), Washington, DC (November
2002) 207‚Äì216
[9] Stoica,
Chord:
I., Morris, R., Karger, D., Kaashoek,
M.F., Balakrishnan, H.:
A scal-
able peer-to-peer lookup service for internet ap-
plications.
In: Proc. ACM Conf. on Applica-
tions, Technologies, Architectures, and Protocols for
Comp. Comm. (SIGCOMM‚Äô01), San Diego, Califor-
nia (August 2001) 149‚Äì160
[10] Ratnasamy, S., Francis, P., Handley, M., Karp,
R., Schenker, S.: A scalable, content-addressable
network.
Proc. ACM Conf. on Applica-
tions, Technologies, Architectures, and Protocols for
Comp. Comm. (SIGCOMM‚Äô01), San Diego, Califor-
nia (August 2001) 161‚Äì172
In:
[11] Rowstron, A., Druschel, P.:
Pastry: Scalable,
decentralized object location and routing for large-
scale peer-to-peer systems.
In: Proc. IFIP/ACM
Int. Conf. on Distributed Sys. Platforms (Middleware
‚Äô01), Heidelberg, Germany (November 2001) 329‚Äì
350
[12] Zhao, B.Y., Huang, L., Stribling, J., Rhea, S.C.,
Joseph, A.D., Kubiatowicz, J.D.: Tapestry: A resilient
global-scale overlay for service deployment.
IEEE
J. on Selected Areas in Comm. (JSAC‚Äô04) 22(1) (Jan-
uary 2004) 41‚Äì53
[13] Aberer, K., Despotovic, Z.: Managing trust in a
peer-2-peer information system. In: Proc. 10th ACM
Int. Conf. on Information and Knowledge Manage-
ment (CIKM‚Äô01), New York (November 2001) 310‚Äì
317
[14] Zacharia, G., Maes, P.: Trust management through
reputation mechanisms. Applied ArtiÔ¨Åcial Intelli-
gence 14(9) (October 2000) 881‚Äì907
[15] Xiong, L., Liu, L.:
Supporting
reputation-based trust in peer-to-peer communities.
IEEE Trans. on Knowledge and Data Engineering
(TKDE‚Äô04) 16(7) (July 2004) 843‚Äì857
PeerTrust:
[16] Lee, S., Sherwood, R., Bhattacharjee, B.:
Co-
operative peer groups in NICE.
In: Proc. 22nd
Annual
the IEEE Comp. and
Comm. Soc. (INFOCOM‚Äô03), San Francisco, Califor-
nia (April 2003) 1272‚Äì1282
Joint Conf. of
324324