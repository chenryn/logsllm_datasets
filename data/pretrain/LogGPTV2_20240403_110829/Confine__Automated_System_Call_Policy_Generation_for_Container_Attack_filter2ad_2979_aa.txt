title:Confine: Automated System Call Policy Generation for Container Attack
Surface Reduction
author:Seyedhamed Ghavamnia and
Tapti Palit and
Azzedine Benameur and
Michalis Polychronakis
Conﬁne: Automated System Call Policy Generation
for Container Attack Surface Reduction
Seyedhamed Ghavamnia
Stony Brook University
Tapti Palit
Stony Brook University
Azzedine Benameur
Cloudhawk.io
Michalis Polychronakis
Stony Brook University
Abstract
Reducing the attack surface of the OS kernel is a promising
defense-in-depth approach for mitigating the fragile isola-
tion guarantees of container environments. In contrast to
hypervisor-based systems, malicious containers can exploit
vulnerabilities in the underlying kernel to fully compromise
the host and all other containers running on it. Previous con-
tainer attack surface reduction efforts have relied on dynamic
analysis and training using realistic workloads to limit the
set of system calls exposed to containers. These approaches,
however, do not capture exhaustively all the code that can
potentially be needed by future workloads or rare runtime
conditions, and are thus not appropriate as a generic solution.
Aiming to provide a practical solution for the protection
of arbitrary containers, in this paper we present a generic
approach for the automated generation of restrictive system
call policies for Docker containers. Our system, named
Conﬁne, uses static code analysis to inspect the containerized
application and all its dependencies, identify the superset of
system calls required for the correct operation of the container,
and generate a corresponding Seccomp system call policy
that can be readily enforced while loading the container.
The results of our experimental evaluation with 150 publicly
available Docker images show that Conﬁne can successfully
reduce their attack surface by disabling 145 or more system
calls (out of 326) for more than half of the containers, which
neutralizes 51 previously disclosed kernel vulnerabilities.
1
Introduction
The convenience of running containers and managing
them through orchestrators, such as Kubernetes [13], has
popularized their use by developers and organizations, as they
provide both lower cost and increased ﬂexibility. In contrast
to virtual machines, which run their own operating system
(OS), multiple tenants can launch containers on top of the
same OS kernel of the host. This makes containers more
lightweight compared to VMs, and thus allows for running
a higher number of instances on the same hardware [30].
The performance gains of containers, however, come to the
expense of weaker isolation compared to VMs. Isolation be-
tween containers running on the same host is enforced purely in
software by the underlying OS kernel. Therefore, adversaries
who have access to a container on a third-party host can exploit
kernel vulnerabilities to escalate their privileges and fully com-
promise the host (and all the other containers running on it).
The trusted computing base in container environments
essentially comprises the entire kernel, and thus all its
entry points become part of the attack surface exposed to
potentially malicious containers. Despite the use of strict
software isolation mechanisms provided by the OS, such as
capabilities [1] and namespaces [18], a malicious tenant can
leverage kernel vulnerabilities to bypass them. For example, a
vulnerability in the waitid system call [6] allowed malicious
users to run a privilege escalation attack [70] and escape the
container to gain access to the host.
At the same time, the code base of the Linux kernel has
been expanding to support new features, protocols, and
hardware. The increase in the number of exposed system calls
throughout the years is indicative of the kernel’s code “bloat.”
The ﬁrst version of the Linux kernel (released in 1991) had
just 126 system calls, whereas version 4.15.0-76 (released
in 2018) supports 326 system calls. As shown in previous
works [40, 50, 51, 80], different applications use disparate
kernel features, leaving the rest unused—and available to be
exploited by attackers. Kurmus et al. [50] showed that each
new kernel function is an entry point to accessing a large part of
the whole kernel code, which leads to attack surface expansion.
As a countermeasure to the ever expanding code base
of modern software, attack surface reduction techniques
have recently started gaining traction. The main idea behind
these techniques is to identify and remove (or neutralize)
code which, although is part of the program, it is either
i) completely inaccessible (e.g., non-imported functions from
shared libraries), or ii) not needed for a given workload or
conﬁguration. A wide range of previous works have applied
this concept at different levels, including removing unused
functions from shared libraries [56, 58, 66] or even removing
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    443
whole unneeded libraries [47]; tailoring kernel code based on
application requirements [50, 80]; or limiting system calls for
containers [8, 68, 69, 75]. In fact, one of the suggestions in the
NIST container security guidelines [59] is to reduce the attack
surface by limiting the functionality available to containers.
Despite their diverse nature, a common underlying
challenge shared by all these approaches is how to accurately
identify and maximize the code that can be safely removed.
On one end of the spectrum, works based on static code
analysis follow a more conservative approach, and opt for
maintaining compatibility in the expense of not removing
all the code that is actually unneeded (i.e., “remove what
is not needed”). In contrast, some works rely on dynamic
analysis and training [8, 50, 68, 69, 75, 80] to exercise the
system using realistic workloads, and identify the actual code
that was executed while discarding the rest (i.e., “keep what
is needed”). For a given workload, this approach maximizes
the code that can be removed, but as we show in Section 4, it
does not capture exhaustively all the code that can potentially
be needed by different workloads—let alone parts of code that
are executed rarely, such as error handling routines.
Given that previous efforts in the area of attack surface
reduction for container environments have focused on dynamic
analysis [8, 68, 69, 75], in this work we aim to provide a more
generic and practical solution that can be readily applied for
the protection of any container without the need for training.
To that end, we present an automated technique for generating
restrictive system call policies for arbitrary containers, and
limiting the exposed interface of the underlying kernel that can
be abused. By relying on static code analysis, our approach
inspects all execution paths of the containerized application
and all its dependencies, and identiﬁes the superset of system
calls required for the correct operation of the container.
Our fully automated system, named Conﬁne, takes a
container image as its input and generates a customized system
call policy. Containers, once initialized, run a single applica-
tion for their entire execution time. We use dynamic analysis
to capture all binary executables that might be invoked during
container initialization. This initial limited dynamic analysis
phase does not depend on the availability of any workloads,
and just pinpoints the set of executables that are invoked in the
container, which are then statically analyzed. We have chosen
Docker as the main supported type of container images, as it is
the most widely used open-source containerization technology.
We experimentally evaluated our prototype with a set of
150 publicly available Docker images, and demonstrate its
effectiveness in deriving strict system call policies without
breaking functionality. In particular, for about half of the
containers, Conﬁne disables 145 or more system calls (out
of 326), while at least 100 or more system calls are disabled
in the worst case and 219 in the best case. This is in stark
contrast to Docker’s default list of 49 (plus four partially)
disabled system calls. More importantly, disabling these
system calls effectively neutralizes 51 previously disclosed
kernel vulnerabilities, in addition to the 25 vulnerabilities
mitigated by Docker’s default Seccomp policy.
The main contributions of our work include:
• We propose a generic approach for the automated
generation of restrictive, ready-to-use Seccomp system
call policies for arbitrary containers, without depending
on the availability of source code for the majority of the
target programs.
• We performed a thorough analysis of Linux kernel
CVEs, mapping them to functions in the kernel code. We
identiﬁed which system calls can be used to exploit each
CVE, and used this mapping as the basis for evaluating
the effectiveness of our approach.
• We examined more than 200 of the most popular publicly
available Docker images from Docker Hub [7] and
present an analysis of their characteristics.
• We experimentally evaluated our system with the above
images and demonstrate its effectiveness in generating
restrictive system call policies, which neutralize 51
previously disclosed kernel vulnerabilities.
Our Conﬁne prototype is publicly available as an open-source
project from https://github.com/shamedgh/confine.
2 Background
The attack surface of the OS kernel used by containers can be
reduced by restricting the set of system calls available to each
container. In this section, we describe how Linux containers
provide isolation to different “containerized” processes, and
how SECure COMPuting with ﬁlters (Seccomp BPF) [23] can
be used to reduce the kernel code exposed to containers.
2.1 Linux Containers
Linux containers are an OS-level virtualization approach,
which can be used to execute multiple userlands on top of
the same kernel. The Linux kernel uses Capabilities [1],
Namespaces [18] and Control Groups (cgroups) [3] to provide
isolation among different containers.
Namespaces are a kernel feature that virtualizes global
system resources (speciﬁcally: mount points, process IDs,
network devices and network stacks, IPC objects, hostnames,
user and group IDs, and cgroups), providing the “illusion” of
exclusive use of these resources to processes within the same
namespace. Control Groups allow processes to be organized
into hierarchical groups, whose usage of various types of
resources (e.g., CPU time, memory, disk space, disk and net-
work I/O) can be limited, accounted, or prioritized accordingly.
Containers use cgroups to provide “fair” usage of resources.
Docker [7] is a platform that employs the software-as-a-
service and platform-as-a-service models for developing,
444    23rd International Symposium on Research in Attacks, Intrusions and Defenses
USENIX Association
deploying, and running containers. Every Docker container
launched is based on a Docker image, which is a ﬁle built in lay-
ers, encapsulating the entire environment (including a whole
Linux distribution, libraries, and support utilities) required to
execute the containerized application(s). The speciﬁcation of
the Docker image is described in a text ﬁle, called Dockerﬁle.
The Dockerﬁle essentially contains all the commands required
to assemble the respective image. Docker uses Linux names-
paces and cgroups to provide isolation between containers.
Docker Hub [7] is a central repository of both community-
based and ofﬁcial Docker images, which has drastically
popularized container use among system administrators. More
importantly, by building streamlined services with a minimal
code base, Docker has enabled corporations to increasingly
switch to the use of microservices. Each microservice can
be conﬁgured as a Docker image once, and then multiple
instances of it can be launched.
2.2 Seccomp BPF
User-space applications communicate with the OS kernel
through the provided set of system calls , i.e., a pre-deﬁned
API that allows access to speciﬁc kernel functionalities
programmatically. More importantly, however, applications
typically need only a subset of the available system calls to
function properly, i.e., most applications do not make use of
all the provided system calls.
Nevertheless, although a program may not use all of the
provided system calls, the complete set is available to all
processes. This modus operandi has two issues: (1) a compro-
mised application may use additional system calls (from what
the author of the application originally intended) to carry out
malicious operations that require access to system resources
(e.g., ﬁlesystem, network) that the application never meant
to access; and (2) a malicious (or compromised) application
may invoke unused system calls to exploit underlying kernel
vulnerabilities (typically related to the implementation of a
given system call) for privilege escalation [45, 46], thereby
gaining access to every process and container on the host.
Seccomp BPF [23] is a mechanism for restricting the set
of system calls that are accessible by a given application.
Speciﬁcally, Seccomp BPF uses the Berkeley Packet Filter
language [55] for allowing developers to write arbitrary pro-
grams that act as system call ﬁlters, i.e., BPF programs that
inspect the system call number (as well as argument values, if
needed) and allow, log, or deny the execution of the respective
system call. Docker containers can be executed with Seccomp
BPF proﬁles, allowing users to provide allow/deny lists of per-
mitted/prohibited system calls. The speciﬁed allow/deny list is
applied to the entire process namespace, limiting all processes
executed inside the respective container. We use this mecha-
nism to reduce the kernel code available to each container.
Figure 1: Example of control ﬂow in Nginx that is missed by
dynamic analysis. Ovals represent functions, while rectangles
represent basic blocks. Dashed branches and blocks are not
executed during training.
3 Threat Model
We consider a local adversary who has full access to a container
running on a third-party host. This access may be granted either
legitimately (e.g., as a regular user of a cloud service), or as a
result of compromising a vulnerable process running on the
container. Potential victims include the OS kernel of the host,
as well as any other containers running on it. We speciﬁcally
focus on preventing the attacker from escaping a container—
preventing the exploitation of an application running on a
container is not the focus of our work. Any exploit mitigations
and defenses deployed on the host or individual containers are
orthogonal to our approach, as it does not rely on any additional
protection mechanisms being in place at user or kernel space.
Conﬁne limits the set of system calls an attacker can invoke.
In case of vulnerability exploitation, this means that exploit
code (e.g., shellcode or ROP payload) or malicious programs
run by the attacker will have more limited capabilities, as
they cannot rely on system calls that are not needed by the
container. More importantly, by preventing access to less
frequently used and less tested system calls—the kernel
code of which may contain vulnerabilities that can lead to
privilege escalation [53]—an attacker cannot trigger those
vulnerabilities to compromise the kernel, as the respective
system calls cannot be invoked in the ﬁrst place.
4 The Need for Static Analysis
Previous works [8, 68, 69, 75] have used dynamic analysis to
derive the list of system calls used by a container. However,
dynamic analysis is not sound, and thus can miss system
calls along execution paths that were not exercised during
the training phase. To demonstrate this issue, we manually
analyzed Nginx and discovered three examples of system calls
that would be missed if only dynamic analysis were used. For
our evaluation, we use Nginx with the Cache Management
and Auto Index features enabled.
Nginx spawns a separate cache-manager process to handle
cache management. This process clears the older cached
ﬁles when the cache is full using the unlink system call.
Dynamically analyzing Nginx would capture the initialization
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    445
FBB1:call @ngx_shmtx_lockTBB2:icmpcache_size, limitjgeBB4BB4:call @ngx_http_file_cache_forced_expireBB3:call @ngx_time_updatejmpBB5ngx_http_file_cache_managerfunction cfgngx_http_file_cache_forced_expirengx_http_file_cache_deleteunlinkunlink system callof the cache-manager process, but would likely fail to capture
the deletion of older cached ﬁles, and therefore fail to capture
the use of the unlink system call. As the unlink system call
is not invoked anywhere else during the normal execution of
the program, relying on training alone would cause it to be
marked as unused. Moreover, extending the training phase
for a longer duration would not solve the problem because the
deletion of older ﬁles is triggered only when the cache is full.
Training would need to request enough new ﬁles to ﬁll up the
cache. Correctly setting up the training process to handle such
situations is thus challenging. Figure 1 shows the parts of the
control ﬂow that are not discovered during training.
Another example of failure to capture a system call is
the use of lstat when displaying directory listings. Apart
from this functionality, lstat is not used in any other part
of Nginx. As listing a directory is usually triggered by users
who manually type a URL, and not by following any existing
URL on a website, it is unlikely that a training-based approach
would be able to capture this system call.
In yet another case, the Nginx binary can be updated with
a newer version without dropping client connections. The
system calls getsockopt and getsockname are used to hand
over the existing socket connections to the new process, and
are not used anywhere else in the code, making it challenging
for dynamic analysis to discover them.
The above examples are indicative of the trade off between
fragility and overapproximation faced by dynamic and static
analysis. Relying on dynamic analysis alone would require the
training to be comprehensive enough to anticipate and capture
all above corner cases. In contrast, static analysis results are
guaranteed to be sound, but may include system calls that are
never invoked by certain workloads. As we aim for a practical
and generic solution, we opt for using static analysis to capture