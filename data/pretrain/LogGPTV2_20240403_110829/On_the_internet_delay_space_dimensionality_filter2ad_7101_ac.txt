performance.
A beneﬁt of this approach is that, if successful, it actu-
ally recovers the coordinates of the original points (up to
translations and rotations).
However, it also has many drawbacks: ﬁrst, embedding
algorithms are slow, even for relatively small values of d.
Second, ﬁnding an embedding that minimizes distortion is
Figure 2: Percentiles of relative errors produced by
Vivaldi using diﬀerent values of d.
computationally intractable in the worst case [9]. Last but
not least, if the measured distances reﬂect a metric other
than the Euclidean distance (e.g., the hyperbolic metric or
the Manhattan metric), the algorithm may fail to ﬁnd a
low-distortion embedding in any dimension.
Moreover, by attempting to ﬁt the distances precisely, the
algorithm may produce a high-dimensional embedding with
lots of unnecessary empty space, obscuring the fact that the
points of the embedding really lie in a lower dimensional
subset of that space. For example, if a point set X were lo-
cated on a hilly terrain instead of a ﬂat plane, the algorithm
would output an embedding using 3 dimensions despite the
fact that all of the data lies along a 2-dimensional surface in
3-space.
Finally, the embedding may fail to reveal lower dimen-
sional substructures which constitute important features of
the distance matrix. For example, suppose that the entries
of the distance matrix are estimates of the time required
to walk between various locations in an oﬃce building with
several ﬂoors. The geometry of the oﬃce building can be
most accurately modeled as a small number of 2-dimensional
pieces (the ﬂoors) with a small number of “gateways” (the
stairwells) connecting these pieces together. Embedding the
distance matrix accurately in a Euclidean space would re-
quire at least 3 dimensions — probably more, since shortest
paths in the oﬃce building are very diﬀerent from shortest
paths in 3-space — obscuring the inherent 2-dimensionality
of the oﬃce building’s ﬂoor plan. Like the oﬃce building, the
Internet delay space is also composed of smaller pieces (au-
tonomous systems) which meet only at prescribed gateways
(customer-provider and peering links). When representing
the geometry of the Internet delay space, one should not
choose a representation which obscures this intricate struc-
ture.
For purposes of estimating the dimensionality of a point
set there are several other, more lightweight, ways of deﬁn-
ing dimensionality using structural properties of the distance
matrix itself. These estimates can be done without mak-
ing reference to an outside “host metric”, such as Euclidean
space, and without computing coordinates to represent its
points.
 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 19D8D7D6D5D4D3D2D1DRelative ErrorDimensionalityPercentile Relative Error versus Dimensionality80%65%50%35%(a) Unit Square, D2 ≈ 2
(b) Meridian matrix, D2 = 1.78
(c) MIT King Matrix, D2 = 1.97
Figure 3: Correlation fractal dimension, D2, of a) a set of 2500 random points in a unit square, and the
Internet delay space as represented by b) the Meridian matrix and c) the MIT King matrix.
These methods also capture the eﬀects of the intricate
patterns mentioned above. We next introduce these deﬁni-
tions of dimensionality, explaining the applicability of each
and their degree of accuracy for the solution to the problem
introduced in the beginning of this section. Although the
following notions of dimensionality were introduced in the
theory of metric spaces (which assumes the triangle inequal-
ity), all of them have the desirable property that they are
applicable even in datasets (like ours) which contain triangle
inequality violations, often yielding meaningful results.
4.2 Correlation Dimension
Suppose we pick a random point x ∈ X and a radius r, and
we count the number of other points whose distance from x is
at most r. If the points are random samples from a bounded
region in the plane, then the expected number of such points
in a region is proportional to its area. Hence the number of
points within distance r of x should be proportional to r2.
For the same reason, in d dimensions, the number of points
would be proportional to rd. Hence, upon plotting the radius
r against the number of pairs whose distance is at most
r in logscale (which we denote as the pair-count plot), for
special point sets which produce a straight line over a given
range of interest (i.e., exhibit power-law behavior), we can
interpret the exponent of the power-law d (i.e., the slope of
the line) as reﬂecting the underlying d-dimensionality of the
dataset. We refer to d as the pair-count exponent [7], which
corresponds to the correlation fractal dimension, D2 [34],
further discussed in Section 4.2.1.
Figure 3(a) illustrates the pair-count plot of a set of 2500
random points in a unit square surface. Notice the presence
of a power-law that persists over three decimal orders of
magnitude. Notice further that the exponent of this power-
law is almost exactly equal to the dimension of the space
from which points were sampled, in accord with the theo-
retical prediction sketched above. In fact, for all “Euclidean
objects”, i.e., distance matrices obtained from uniformly-
random point clouds in Euclidean d-space, the fractal di-
mension matches the Euclidean dimension.
Figures 3(b) and 3(c) present the pair-count plot of the
Internet delay space as represented in the Meridian and MIT
King datasets respectively.
The ﬁrst striking feature of these plots is a power-law that
persists roughly over two orders of magnitude, i.e., from 3ms
to 100ms. (Note that this range of latencies includes almost
every Internet route that is not trans-oceanic.) As a re-
sult, the Internet delay space exhibits the desirable property
that it can be measured by fractal measures of dimensional-
ity (see Section 4.2.1). The second unexpected observation
is that the magnitude of its dimensionality is less than 2,
represented by the pair-count exponents D2 = 1.782 and
D2 = 1.975 in the Meridian and MIT King dataset respec-
tively. The estimation of these values contains errors to a
degree that would not aﬀect the conclusions derived in this
work. These dimensionality values are much smaller than
the embedding dimension indicates (i.e., between 4 to 7 di-
mensions), suggesting a diﬀerent geometric picture of the
structure of the Internet delay space. Sections 4.3.2 and
5.2 discuss the reasons for this discrepancy. Finally, the
power-law behavior, including the dimensionality value, is
consistent across random subsets of the data, as discussed
in Section 5.2.
The fractal measures can help us understand the weak-
nesses of embedding algorithms by showing how they af-
fect the properties of the original delay space. Accordingly,
upon computing the pair-count plot of the embedded net-
work produced by Vivaldi in 7 dimensions, we can observe
how the resulting coordinate space does not preserve the ge-
ometric properties of the original delay space and suﬀers a
major dimensionality inﬂation. Figure 4(a) shows the result-
ing pair-count plot of the delay matrix reconstructed from
the 7-space coordinates. Notice that the curve has a con-
cave shape, thereby deviating from the power-law behavior
of the original space. Moreover, the best eﬀort to measure
its dimensionality, by ﬁnding the best straight line ﬁt to the
curve, results in a pair-count exponent of value 5.46.
Although the Internet hosts live in a sphere that can be de-
scribed by two coordinates in spherical space, the values near
2, which the fractal measures revealed for the delay space di-
mensionality, are not a reﬂection of the 2-dimensional struc-
ture of a sphere’s surface. This phenomenon would be fur-
ther explored in Section 5.1.
(a) Pair-Count of Meridian Embedded
(b) Hausdorﬀ dimension, D0 = 1.51
(c) PCA, DP CA = 42.66%
Figure 4: Measures of dimensionality applied to the Meridian matrix: a) pair-count plot of the embedded
Meridian data into 7-Euclidean space, b) the Hausdorﬀ dimension computed by the greedy set cover plot,
and c) Principal Component Analysis (PCA) applied to the Meridian matrix.
4.2.1 Fractal dimensions
The previous section introduced a measure of dimension-
ality which was based on measuring the exponent of a power-
law arising in distance data. In general, this power-law does
not necessarily arise and, when it does, it need not have an
integer exponent. Point sets whose pair-count plots display
a power-law are called fractals.
The correlation dimension is just an example from among
an inﬁnite family of fractal dimensions Dq, indexed by a
non-negative number q. Formally, if µ is a fractal measure
on a set Y and A1, A2, . . . , AN is a partition of Y into pieces
of diameter less than r, with µ(Ai) = pi for i = 1, 2, . . . , N ,
then4
“PN
”
Dq(Y ) =
log
1
q − 1
lim
r→0
i=1 pq
i
log r
.
(1)
The correlation dimension corresponds to the fractal di-
mension D2. Among these dimensions, only the ﬁrst three
can be eﬃciently measured in practice.
Fractals may arise by applying recursive constructions in
which a self-similar point set is composed of ﬁnitely many
pieces, each of which is a scaled-down copy of the entire
point set. If one samples a large number of points uniformly
at random on such a perfect inﬁnite fractal, and measures
any of the fractal dimensions (e.g., for all q), they must
coincide. For example, if a point set is made up of 2p pieces,
each of which is a copy of the entire set scaled down by
2k, then all its fractal dimensions equal p/k. However, if
the data is non-uniformly distributed inside the fractal, one
gets a fractal measure or multifractal — a fractal together
with a probability measure expressing the density of points
at diﬀerent locations.
Despite this recursive deﬁnition, the most surprising ex-
amples of fractal behavior are non-recursive structures com-
monly found in nature. Some examples are snowﬂakes, coast-
lines and the surface of the human brain [34]. The question
4The case q = 1 is exceptional. In equation (1) when q = 1,
one uses the log of the entropy of the distribution {pi} in
the numerator and drops the constant 1/(q − 1) out front.
of exactly what features of the Internet delay space lead to
its fractal behavior is still elusive. In the search for these
properties, we discovered some hints that are discussed in
Section 5.2. However, this question is currently a subject of
our ongoing work.
4.3 Other dimensionality measures
In this section, we introduce another instance of fractal di-
mension, namely Hausdorﬀ dimension (D0) and two dimen-
sionality reduction techniques, namely Principal Component
Analysis (PCA) and Isomap, explaining the relevance of
each of them to this work.
4.3.1 Hausdorff dimension
Consider partitioning a point set X into low-diameter sub-
sets. If X lies in a bounded region of the plane, then for every
r > 0 it can be partitioned into O(1/r2) subsets of diame-
ter less than 2r, for example using grid cells of side length
r. The analogous low-diameter covering in dimension d uses
O(1/rd) subsets. Even if we are given only the distance
matrix — so that it is infeasible to identify the partition
into grid cells — a partition into low-diameter sets can still
be constructed by considering the collection of all radius-
r balls and selecting a sub-collection using the greedy set
cover algorithm. For d-dimensional Euclidean objects the
cardinality of this greedy covering will also be O(1/rd) with
high probability, though it is less obvious than in the case
of the grid-cell covering.
This suggests deﬁning N (r) to be the minimum size of a
partition of X into pieces of diameter less than 2r, and plot-
ting r against N (r) in logscale. For d-dimensional Euclidean
objects we have seen that this will lead to a line of slope −d.
For any distance matrix, if a power-law with exponent −d
is present over a given range of interest, we refer to d as
the Hausdorﬀ fractal dimension [34], or D0, from the fractal
deﬁnition presented in Section 4.2.1, Equation 1.
Figure 4(b) presents the measure of D0 for the Internet
delay space as represented in the Meridian matrix. Similarly
to the pair-count plot, we observe the presence of a power-
law with exponent −1.51.
   1   2   3   4   5   6   7   8   9  100102030405060708090100Principal ComponentVariance Explained (%)0%10%20%30%40%50%60%70%80%90%100%(a) Correlation dimension, D2 = 0.90
(b) Hausdorﬀ dimension, D0 = 0.89
(c) Diameter-based Cluster
Figure 5: Dimensionality of the distance space based on great circle distances via a) the correlation dimension
and b) The Hausdorﬀ dimension. c) The correlation dimension of one of the latency-based clusters.
While D2 encompasses the geometric structure of the de-
lay space and also the spatial distribution of points, D0 in-
cludes only the former notion [7, 34]. Nevertheless, we in-
troduce D0 for two main reasons. First, it exhibits the same
power-law behavior displayed by D2 when applied to the
delay space as represented by the datasets considered (al-
beit with a diﬀerent power-law exponent). This observation
reinforces the fractal behavior of the delay space. Second,
D0 behaves similarly to D2 when measuring networks that
possess diﬀerent intrinsic dimensionality values. Section 5.2
presents this behavior in greater detail.
Finally, a number of algorithms are known to run eﬃ-
ciently on metric spaces that possess some form of bounded
doubling dimension [15]. In general, that is to say that every
ball of radius R in the metric can be covered by at most 2d
balls of radius R/2. Similarly to the Hausdorﬀ dimension, a
d-dimensional metric space has doubling dimension approx-
imately d. While the doubling dimension has convenient
algorithmic properties, it is diﬃcult to precisely determine
the doubling dimension of a dataset. (See [21] for an ex-
ample of this process.) The diﬃculty arises because, unlike
the correlation or Hausdorﬀ dimension which are statisti-
cally robust against perturbing a few entries of the distance
matrix, the doubling dimension is very sensitive to outliers
as it involves taking the maximum covering number over all
balls in the entire metric space.
4.3.2 Principal component analysis
PCA is the main technique adopted in previous work to
characterize the Internet delay space dimensionality [12, 22,
39].
In our experiments we have applied PCA directly to
the distance matrix. This is similar to the analysis applied
in [39], where the method was justiﬁed with the additional
observation that the columns of the distance matrix itself
represent the coordinates for a particular embedding of the