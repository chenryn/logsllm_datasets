### Data Encapsulation and Transmission

The origin-gateway machine delegates the management of TCP segments to one of the CDN-on-Demand managers, identified by their unique addresses. This process involves queuing TCP segments until a total of \( m \) segments are aggregated for encapsulation. The method then encodes these \( m \) segments into \( n \) frames, which are subsequently transmitted as UDP packets. Each UDP packet includes an identifier that marks the segments as being encoded together.

### Decoding and Data Recovery

The decoding process captures tunneled traffic as it arrives (UDP traffic to the tunnel’s service port). It queues the incoming packets until at least \( m \) out of the \( n \) packets with the same identifier are received, enabling data recovery. The method then decodes the data, reconstructs the underlying TCP communication, discards the UDP packets, and inserts the recovered TCP segments into the TCP/IP stack for further processing.

### Client-to-Server Mapping in CDN-on-Demand

Each client connects to the most responsive proxy in its region. To facilitate this, the RootJS module integrates a 'proxy-selection' feature that periodically retrieves the list of all active proxies in the client’s geographic region. The RootJS fetches the list of available proxies from the CDN's domain, such as `https://site-cdn.com/proxy-list`. If CDN-on-Demand is inactive, the domain is mapped to the content-origin’s IP address, and the origin-gateway provides an empty list. In this case, the RootJS bypasses the clientless secure-objects mechanism and loads content directly from the origin at `site.com` over a secure connection. If CDN-on-Demand is active, the authoritative DNS servers map `site-cdn.com` to a nearby proxy. The client receives a proxy-list object from the proxy, containing the addresses of available proxy web-servers. The resource-manager updates the proxy-list when it deploys or decommissions a proxy. Note that the private TLS key for `site-cdn.com` is shared with the CDN, unlike the key for `site.com`.

The RootJS evaluates the response time provided by each proxy in the list by sending a short HEAD request for a test object and measuring the response time. The RootJS then uses the first responding proxy, caching the selection for future connections and periodically refreshing it by repeating the selection process.

### Proxy Selection and Placement

#### A. Mapping Clients to Web-Servers

Efficient mapping between clients and proxies is crucial for reducing latency, a key benefit of CDNs. In the client-to-server mapping process, illustrated in Figure 12, CDN-on-Demand manages the placement of proxy instances. The resource-manager monitors the utility of proxy machines in each region using cloud-provider APIs, which provide access to metrics such as CPU and network usage. The number of proxies in a region is adjusted when the utility crosses a high/low threshold. The resource-manager executes the placement procedure to find the best cloud for hosting an additional proxy or to remove a proxy. For scale-up, the procedure evaluates the expected utility and computes the utility/cost ratio; if the ratio is below a threshold, the proxy is not added.

#### B. Placement Procedure

The placement procedure for scale-up involves temporarily powering on one machine on each cloud for a brief evaluation period (one minute in our implementation). These candidate machines are not active proxies but are used for comparison. After evaluation, each candidate machine either becomes an active proxy or is turned off. The cost of deploying candidate machines for evaluation is low, measured at less than $0.0001 per step in our deployment.

During the evaluation, active CDN proxies distribute the addresses of candidate machines to their clients, with each client receiving one address. Let \( C_m \) denote the set of clients participating in the evaluation of machine \( m \). Each client \( c \) compares the response time of the candidate machine \( m \) against the response time of the proxy it currently uses. The client reports the potential improvement \( \delta(c, m) \geq 0 \), which is the difference in response time (or zero if \( m \) has a longer response time). The resource-manager collects these reports and evaluates the average improvement in response time for each candidate machine, up to a maximum improvement \( \delta_{\text{MAX}} \), to prevent disproportionate influence from a few values.

\[
\Delta(m) = \frac{\sum_{c \in C_m} \min \{\delta_{\text{MAX}}, \delta(c, m)\}}{|C_m|} \quad (\forall m, \Delta(m) \geq 0)
\]

The resource-manager deploys a new proxy on the machine that provides the highest improvement in response time, provided that the improvement exceeds a minimum threshold, and powers off all other candidate machines.

### Implementation and Evaluation

In this section, we evaluate the performance and cost of a prototype implementation of CDN-on-Demand deployed over two commercial clouds. The source code is available at [https://autocdn.org](https://autocdn.org).

#### A. Setup

We deployed CDN-on-Demand over EC2 and GCE IaaS clouds with two managers (one as a backup). The managers were implemented in Python, configured to use EC2 and GCE APIs to manage Squid HTTP proxy (v3.5) instances. The content-origin server runs Nginx (v1.9), and the origin-gateway is implemented by Python applications on a Linux machine (Ubuntu Server 14.04.2). To simulate geographically diverse clients, we deployed 8,000 clients over Planet-Lab machines located on different continents, with each machine running 16 clients. Each client repeatedly connects to CDN-on-Demand and downloads a 50KB image from the hosted website. The website's content is cached by the proxies and managers for one minute, after which they request fresh content from the content-origin.

#### B. Performance Evaluation

Figure 13 illustrates the dynamic scaling of CDN-on-Demand, adapting to changes in traffic volumes, client distribution, and server failures. We conducted experiments over 70 minutes, introducing events every three minutes and measuring system performance. We started with the system serving clients directly from the content-origin, with minimal costs. To test resistance to flash crowds, we doubled the number of clients six times, from 128 to 8,192. CDN-on-Demand quickly detected the load and scaled up, deploying up to 15 servers during peak load. We also initiated a bandwidth DoS attack on the content-origin's link, using 256 Planet-Lab machines to send UDP traffic at full speed. The system automatically established loss-resilient tunnels, and we observed only a small effect on the average download rate. We then simulated an IaaS provider failure by abruptly powering off all proxies in one data center, causing a temporary decrease in the average transmission rate, followed by automatic recovery. Finally, we reduced the number of connected clients back to 128, triggering the scale-down procedure and observing a decrease in utility costs without affecting transmission rates.

Figure 14 illustrates the geographic distribution of clients and proxies, showing the system snapshot 24 minutes into the experiment, with 5 proxies serving 512 clients. The map highlights the geographic coverage and shows that isolated clients connect to distant proxies, indicating that deploying additional proxies near these clients would not significantly improve performance.

#### C. Pricing: Survey and Comparison

We evaluated the cost of CDN-on-Demand in typical scenarios and compared it with commercial CDNs. Commercial providers offer various pricing plans, some with fixed prices and others with optional premium services like DoS protection. The cost varies based on the geographic location of deployed servers and connecting clients. CDN-on-Demand leverages flexible IaaS clouds to deploy proxies only when needed, incurring negligible costs under normal conditions.

**Methodology:** We collected pricing data from several popular commercial CDNs and compared the costs of egress traffic, fixed monthly fees, and traffic filtering. We estimated the cost of operating CDN-on-Demand, including the cost of operating cloud machines (managers and proxies). Under normal conditions, the cost is very low. We evaluated the service cost per month for a small/medium HTTPS website requiring SSL/TLS support and defenses against DoS attacks, serving 1TB of data to legitimate clients. We considered two scenarios: (1) a benign month without flash-crowds or DoS attacks, and (2) a month with DoS floods or flash crowds occurring 5% of the time. We studied these scenarios using EC2 and GCE, and ProﬁtBricks and VirtualServer.

**Cost Comparison:** Our survey, illustrated in Table I and Figure 2, shows that CDN-on-Demand’s cost in benign months is only a few USD and at least one order of magnitude lower than commercial CDN services. When handling flash crowds and DDoS attacks, CDN-on-Demand’s cost is 5.8 times lower than the next commercial CDN service when deployed on popular IaaS clouds (EC2 and GCE) or 12 times lower when deployed over less popular ones (ProﬁtBricks and VirtualServer). Some CDN providers advertise free DoS protection, but there are complaints about limited effectiveness. Akamai, a popular provider, refuses service to smaller websites, which are the focus of this paper.

### Related Works

We survey previous works related to the CDN-on-Demand architecture, focusing on (1) serving web clients and (2) managing and optimizing CDN resources.