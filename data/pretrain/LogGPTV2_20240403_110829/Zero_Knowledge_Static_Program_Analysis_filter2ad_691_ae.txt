call, the return value is passed back from callee’s variable scope.
Algorithm 1 works on flows and transfer functions, so it is still
possible to use it for inter-procedural analysis as long as the control
flows introduced by function calls and the corresponding transfer
functions are properly designed.
To properly modify the control flows, a few additional structural
instructions are added to the program. At the definition of a func-
tion 𝑝, an instruction 𝑖𝑛𝑖𝑡(𝑝) is used to mark the beginning of a
function, and an instruction 𝑓 𝑖𝑛𝑎𝑙(𝑝) is used to mark the end. When
calling function 𝑝, the call statement is split into two statements, i.e.
𝑒𝑛𝑡𝑒𝑟(𝑝) and 𝑒𝑥𝑖𝑡(𝑝). Three additional flows between these instruc-
tions are added to deal with function calls, i.e. 𝑒𝑛𝑡𝑒𝑟(𝑝) → 𝑖𝑛𝑖𝑡(𝑝),
𝑓 𝑖𝑛𝑎𝑙(𝑝) → 𝑒𝑥𝑖𝑡(𝑝), and 𝑒𝑛𝑡𝑒𝑟(𝑝) → 𝑒𝑥𝑖𝑡(𝑝). To ensure that argu-
ments and return values are passed properly, the transfer functions
located at the entrance and exit of function calls pass in the argu-
ments and pass out the return value, respectively.3
4.2 Modifications to Our zkAI Scheme
To incorporate the changes of the inter-procedural abstract interpre-
tation above, we modify our programming language, and address
several critical challenges in this section.
Modification to the programming language. First, we add func-
tion calls to our programming language, as shown in Figure 3. This
is a natural extension of the original programming language in Fig-
ure 1. Now a program consists of several function definitions, and
each function definition has multiple arguments and statements.
For the statements, we introduce another type of function calls in
addition to the original statements of assignment, branch and loop.
With the inclusion of function definitions and calls to this language,
we can conduct an inter-procedural analysis.
Challenges. This additional statement of functions introduces
several challenges to our zero-knowledge abstract interpretation
scheme. The key reason is that each statement can have more than
two variables as the function arguments, and there can be more
than two flows going in to and out of a line because of function
calls. One could set an upper bound on these and use the same
zero-knowledge abstract interpretation in Section 3, but it would in-
troduce an multiplicative overhead of the upper bound. Instead, we
present several techniques to reduce the inter-procedural analysis
on programs with function calls to a circuit of the optimal size.
3We focus on context insensitive analysis in this paper since it is the most common
design used in large-scale analysis tools, but our techniques can be extended to support
context sensitive analysis.
Session 11B: Zero Knowledge II CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2959Output (data[𝑝𝑡]).
Algorithm 2 Access Linked List
Input: The linked list represented by arrays head, next, data. A node 𝑛𝑑
Output: data[𝑛] for all nodes 𝑛 in the list of 𝑛𝑑.
1: for (𝑝𝑡 = head[𝑛𝑑]; 𝑝𝑡 ≠ NULL; 𝑝𝑡 = next[𝑝𝑡]) do
2:
3: return
Program Representation. We think of a function as a fragment of
code. To represent a function definition, we store the start and end
line number of the function. Besides, we also store the number and
the type of the function arguments. We store all these information
in a function definition table.
Then we deal with the statements of function calls. The arith-
metic representation in Section 3.1 is efficient for intra-procedural
analysis due to the bounded number of fields required to repre-
sent a statement. However, this is not the case for inter-procedural
analysis because a ‘function call’ statement requires as many fields
as the number of function arguments. As a result, if we use the
same arithmetic representation as in Section 3.1, every statement
will have the same number of fields as the function with the most
arguments, which leads to a large overhead in practice.
Our solution is to create a ‘function call’ table which contains
the arguments of ‘function call’ statements. Then, in the original
‘statement’ table, an additional index to the ‘function call’ table
is added. This construction frees normal statements from dummy
fields. Since circuits do not naturally support indexing, we add
another memory checking whenever accessing these arguments.
Representing the control flow graph as a linked list. With the
function calls, each line of code can have more than two incoming or
outgoing flows. Thus if we still represent the control flow graph as a
matrix, the size would be 𝑛 by the maximum number of flows from
any line. Instead, we propose an approach to simulate the linked
list in circuits efficiently using techniques of memory checking.
We construct 3 arrays: head, next and data. head is an array of
size 𝑛 and the 𝑙-th element stores the index of the start of the list for
𝑙 in next and data. next and data are of size 𝑚. data[𝑝𝑡] stores the
data (flow) at a node pointed by an index 𝑝𝑡, and next[𝑝𝑡] stores the
index of its next node as in a linked list. We use a special character
(e.g., −1 in the field) to denote the end of the list (NULL). With
these three arrays, we can traverse the linked list using the simple
algorithm in Algorithm 2. To validate the traversal in a circuit, we
ask the prover to provide the expected 𝑝𝑡 and 𝑑𝑎𝑡𝑎[𝑝𝑡] in each
iteration of Algorithm 2, and check their consistency with array
next and data using the memory checking technique in Section 3.2.
For our zero-knowledge abstract interpretation scheme, as shown
in Figure 2, we traverse the CFG with all lines to compute all flows
and compare it with the flows computed from the program. The
size of the circuit above doing so is 𝑂(𝑚). In addition, during the
worklist algorithm, we fetch all the flows from 𝑙′ in each iteration of
Algorithm 1, and the circuit size for the linked list operations above
is optimal (the total number of flows in the worklist algorithm).
Loop Merge. With this linked-list representation of the control
flow graph, the only remaining challenge is the worklist algorithm.
In particular, since the number of flows from a line 𝑙′ is not a
constant anymore, the number of iterations in the loop of step 7
varies in every iteration of the outer loop. Compiling the algorithm
Algorithm 3 Verification of the Worklist Algorithm
Input: A program 𝑝, transfer function A𝑝,𝑙 , lattice val♯, initial state 𝑊𝑖𝑛𝑖𝑡 ,
and final state 𝑊𝑓 𝑖𝑛𝑎𝑙 of the worklist.
Output: Abstract state at each line {𝑠𝑙 }𝑛.
1: Init 𝑠𝑙 (𝑥) = ⊥val♯ for all 𝑙 and 𝑥.
2: The first 𝑚 flows in 𝑊𝑓 𝑖𝑛𝑎𝑙 is the same as 𝑊𝑖𝑛𝑖𝑡 .
3: for 𝑖 = 1 → |𝑊𝑓 𝑖𝑛𝑎𝑙 | do
(𝑙, 𝑙′) = 𝑊𝑓 𝑖𝑛𝑎𝑙 [𝑖]
4:
𝑙 (𝑠𝑙) /⊑ 𝑠𝑙′ then
if 𝑓 ′
5:
𝑠𝑙′ = 𝑠𝑙′ ⊔ A𝑝,𝑙 (𝑠𝑙)
6:
need_update[𝑖] = True
7:
8:
else
need_update[𝑖] = False
9:
10: 𝑡 = 𝑚 + 1
11: for 𝑖 = 1 → |𝑊𝑓 𝑖𝑛𝑎𝑙 | do
12:
13:
14:
15:
16:
for (𝑝𝑡 = head[𝑙′]; 𝑝𝑡 ≠ NULL; 𝑝𝑡 = next[𝑝𝑡]) do
Check 𝑊𝑓 𝑖𝑛𝑎𝑙 [𝑡] = data[𝑝𝑡].
𝑡 = 𝑡 + 1
(𝑙, 𝑙′) = 𝑊𝑓 𝑖𝑛𝑎𝑙 [𝑖]
if need_update[𝑖] then
if need_update[𝑖] and 𝑝𝑡 ≠ NULL then
Algorithm 4 Loop Merged of Algorithm 3 step 10-16
1: 𝑡 = 𝑚 + 1
2: 𝑖 = 1
3: (𝑙, 𝑙′) = 𝑊𝑓 𝑖𝑛𝑎𝑙 [𝑖]
4: 𝑝𝑡 = head[𝑙′]
5: while 𝑖 ≤ |𝑊𝑓 𝑖𝑛𝑎𝑙 | or 𝑝𝑡 ≠ NULL do
6:
Check 𝑊𝑓 𝑖𝑛𝑎𝑙 [𝑡] = data[𝑝𝑡]
7:
𝑡 = 𝑡 + 1
8:
𝑝𝑡 = next[𝑝𝑡]
9:
10:
𝑖 = 𝑖 + 1
11:
(𝑙, 𝑙′) = 𝑊𝑓 𝑖𝑛𝑎𝑙 [𝑖]
12:
𝑝𝑡 = head[𝑙′]
13:
naively to a circuit will again introduce an overhead of the maxi-
mum possible number of flows in every iteration. In order to solve
this problem, we borrow an idea named flattening from prior work
in zero-knowledge [66] which merges two (or more) loops into one,
and we can bound the number of iterations of the outer loop.
else
To better illustrate the problem and the solution, we first rewrite
Algorithm 1 to Algorithm 3 which verifies the worklist algorithm
instead of computing it. Note that the algorithm takes the entire
final state of the worklist after all iterations as an input provided by
the prover. It checks that the first 𝑚 flows are correctly initialized
to 𝑊𝑖𝑛𝑖𝑡, all flows of the program, then checks that the remaining
flows are pushed into the queue properly. Step 1-9 are almost the
same as step 1-6 in Algorithm 1 computing the transfer function,
compare and join operations, and we introduce an additional array
need_update for the sole purpose of explaining the challenge. In
step 10-16, the algorithm is checking that for each flow 𝑙′ in the
worklist, the following flows are pushed to the queue. It accesses
the flows from 𝑙′ using a linked list as shown in Algorithm 2. It
is not hard to see that the checks in Algorithm 3 pass as long as
𝑊𝑓 𝑖𝑛𝑎𝑙 is correctly computed by Algorithm 1.
Now the problem happens in step 10-16 of Algorithm 3. The size
of the outer loop is pre-defined, but the number of iterations of
the inner loop in step 14 varies, and implementing the algorithm
Session 11B: Zero Knowledge II CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2960(𝑙, 𝑙′) = 𝑊 .𝑝𝑜𝑝()
if A𝑝,𝑙 (𝑠𝑙) /⊑ 𝑠𝑙′ then
return invalid
Algorithm 5 Checking the Validity of a Solution
Input: A program 𝑝, control flow graph CFG𝑝, transfer function A𝑝,𝑙 , and
lattice val♯, an abstract environment {𝑠𝑙 }𝑛
𝑙=1.
Output: valid or invalid
1: Init queue: 𝑊 := {(𝑙, 𝑙′) | 𝑙′ ∈ CFG𝑝 (𝑙)}.
2: while 𝑊 ≠ ∅ do
3:
4:
5:
6: return valid
naively as a circuit introduces a high overhead as explained above.
To solve this problem, we change step 10-16 to Algorithm 4. In
Algorithm 4, both conditions on need_update[𝑖] and 𝑝 are merged
into a single loop, and the updates on 𝑖, 𝑡 and 𝑝 are all processed in
the loop. The total number of iterations for the large loop in step
5 is pre-defined, i.e. 2|𝑊𝑓 𝑖𝑛𝑎𝑙| − 𝑚. Implementing the algorithm as
a circuit preserves the number of iterations. The only overhead is
that in each iteration, the circuit executes statements in both step
6-9 and step 10-13, which slightly increases the size per iteration.
In addition to the worklist algorithm, in our scheme we also apply
the loop merge technique to check the consistency of the control
flow graph (computing all the flows from the secret program) with
the optimal circuit size. The algorithm is more straight forward
than the worklist algorithm and we omit the details here.
Complexity. With these modifications, the size of our circuit for
inter-procedure analysis remains 𝑂(𝑇 · 𝑣 + 𝑇 log𝑇), where 𝑣 now
denotes the maximum number of variables in any functions of
the program (we view the main program also as a function). The
concrete size of the circuit for the inter-procedure analysis is larger
compared to the intra-procedure analysis, as there are additional
computations of loop merge, linked list operations and copying
states of variables when entering to and exiting from functions.
5 PROVING ABSENCE OF BUGS
As mentioned in Section 2.2, when the prover wants to prove the
absence of bugs in the secret program, it suffices for the prover
to present any fix point of the abstract interpretation. The veri-
fier validates that it is indeed a solution, instead of validating the
whole computation of the worklist algorithm. Here we present the
algorithm of the validation in Algorithm 5.
As shown in the algorithm, it is enough to check that for every
flow (𝑙, 𝑙′), the state 𝑠∗
𝑙 = A𝑝,𝑙 (𝑠𝑙) is always ‘smaller than’ 𝑠𝑙′ in the
partial ordering of the lattice. The algorithm does not update the
states iteratively, thus no new flow is pushed into the queue 𝑊 , as
in Algorithm 1. When implementing Algorithm 5 in circuits, the
queue is static and we do not need to support the push operation
using the loop merge technique. We also do not have the join
operation anymore, but in practice the overhead of join after the
compare operation is small. However, for inter-procedure analysis
with function calls, we still need to represent the CFG as a linked list
and check its consistency with the program using the techniques in
Section 4. The total size of the circuit becomes 𝑂(𝑚 · 𝑣 + 𝑚 log 𝑚).
6 IMPLEMENTATION AND EVALUATIONS
We implement our zero-knowledge abstract interpretation scheme
and present the experimental results in this section.
Software. The schemes are implemented in C++. There are around
2, 500 lines of code for our frontend to compile the analyses to a