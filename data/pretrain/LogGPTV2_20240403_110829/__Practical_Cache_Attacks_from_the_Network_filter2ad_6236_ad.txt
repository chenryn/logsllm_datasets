can be seen in Figure 7.
To locate the ring buffers in the remote LLC, we ﬁrst build
the remote eviction set as described in Section VI. Next, we
launch a PRIME+PROBE variant, where we send two network
packets to the server after each prime, and then immediately
measure the latency with the probe step. For each of the 256
proﬁled colors, we execute the PRIME+PROBE 512 times, for
a total of 1024 packets per color. After ﬁnishing all rounds,
we ﬁnd the distinct staircase pattern in one of the pages. With
an RX queue length of 128, the pattern repeats eight times, as
shown in Figure 7.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:37:59 UTC from IEEE Xplore.  Restrictions apply. 
28
an initial PRIME+PROBE phase. We stop once we have high
conﬁdence that the algorithm detected the correct current ring
buffer position.
Next, the online tracker uses its knowledge of pos to prime
the eviction sets around pos in a window of size w. In our
tests, we chose w = 10 for a good trade-off between measuring
speed and reliability. We now probe until the algorithm detects
a cache activation in the window w, at which point we
save the measurements and begin another priming round. We
periodically synchronize by sending a packet after priming
the cache. After each synchronization, the algorithm sends a
network packet to conﬁrm that we register the cache activation
as expected. For these experiments, we require a latency
threshold to differentiate between packets that cause a cache
hit versus the ones that cause a cache miss. We ﬁnd that we
need to maintain this threshold dynamically, as it can slightly
drift on the victim machine for unspeciﬁed reasons (likely
due to power management). In addition to our measurements
of ring buffer activity, we save all conﬁrmed and missed
synchronization points to aid in the ofﬂine analysis phase
described next. We provide pseudocode detailing the online
tracker’s behavior in Appendix C.
Ofﬂine extraction The goal of the ofﬂine extractor phase is
to compute at which time steps the victim machine received
packets that were not probes sent by the attacker. To this end,
the ofﬂine extractor receives cacheline latency measurements,
and the state of the online tracker at each measurement point.
The online tracker only records a timestep when it estimates
that there is a cacheline miss observed anywhere among the
measurements, regardless of whether it was caused by a probe
or not.
The ofﬂine extractor examines the cacheline latency mea-
surements and reconstructs the ring buffer accesses. The
extractor can rely on the known times of the probing packets
which serve as a baseline score for the extractor. We compute
the corresponding ring buffer progression that
this arrival
pattern produces. We score this guess by summing up all
measurement
latencies that, according to this progression,
should be cache misses. We clamp latencies below the 10th
percentile and above the 99th percentile to limit the effect of
outliers.
We try to enhance our most basic guess by greedily inserting
one extra arrived packet in any timestep, starting at 0. If any
of these insertions result in a better scoring guess than the
current one, we adopt this new pattern of packet arrivals. If
our new packet was inserted in step N, we try to insert another
packet starting at N (not 0), and only adopt the new guess if
there is an improvement, and we repeat this until we cannot
improve the guess further. The output of the extractor is a
list of timestamps of possible packets that were sent by other
clients.
In the last step, we ﬁlter network packets that are most
likely SSH packets. This step is done by a heuristic, as we do
not have any header packet information to distinguish an SSH
packet form other network packets. The idea of the heuristic
is that after a keystroke is transmitted, the client will send
an ACK packet. This heuristic works on an idle network.
However, this is also an inherent limitation of network-based
attacks. If there is more network trafﬁc, i.e., packets arriving
close together, our algorithm is not able to distinguish them
from SSH packets.
C. Keystroke Prediction
In the previous section, we described how an attacker
could measure the cache activity related to the ring buffer
and then extract possible SSH packets. The next step is
to predict keystrokes from the extracted inter-packet times.
Song et al. [47] pioneered the recovery of keystrokes from
interactive SSH sessions. In their work,
they showed the
feasibility of such an attack when capturing SSH packets
on a network tap. For this purpose, they used bigrams and
a Hidden Markov Model (HMM) to guess typed passwords.
The challenge with password datasets is that it is unethical to
collect real passwords from users. This would leave the option
to let users type a predetermined set of passwords. However,
real passwords typing underlies a unique typing frequency
which is hard to approximate when users are not trained to
type these passwords frequently and over a longer time period.
Furthermore, such a dataset would need hundreds of different
passwords for a fair evaluation. Similar to more recent work
in the area [23, 48], we decided to use word guessing to show
an attacker can successfully perform keystroke prediction from
the cache measurements.
In order to facilitate reproducibility and comparability, we
used a publicly available dataset [49]. The dataset consists of
twenty subjects typing free and transcribed text. We extracted
words from the free typing sessions with only lowercase
characters. The ﬁltered dataset contained a total of 4,574
unique words, on average 228.7 unique words per subject. We
split the dataset in training and test set for each user. For each
word that was typed multiple times, we split the dataset in a
2:1 ratio between training and test set. We ensure, that a word
trace that is in the test set has at least one other trace of the
same word in the training set. Furthermore, we also kept word
traces in the training set that only occurred once. On average,
the training set consists of 376.25 word traces and the test set
of 121 traces per user. As we will show later, it is crucial to
evaluate a dataset with a sufﬁciently large word corpus.
To predict words, we used the k-nearest neighbor’s algo-
rithm (k-NN), similar to recent work on microarchitectural
attacks [23]. The k-NN algorithm classiﬁes an unseen sample
by looking at the k nearest neighbors by using a distance met-
ric. In our experiments we used k = 15 and uniform weights.
This simple approach is a good match to classify keystroke
sequences, as we expect users to type words similarly every
time. However, users still have a certain degree of variance
in their typing, which makes keystroke timing recovery chal-
lenging. Prior keystroke timing attacks [47, 48, 50, 51, 52, 53]
have also experimented with more sophisticated methods like
HMMs, support-vector machines, and neural networks to map
keystrokes to characters, words, or users. We focus on a
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:37:59 UTC from IEEE Xplore.  Restrictions apply. 
29
TABLE II: SSH packet recovery quality for different intervals based
on tcpdump (Network) data and cache activity (Cache) data.
Source
tcpdump
DDIO
0.05s Interval
TP
1.00
.85
FP
.00
.04
FN
.00
.11
0.01s Interval
TP
1.00
.70
FP
.00
.04
FN
.00
.26
0.001s Interval
FN
TP
.06
.93
.49
.46
FP
.00
.04
Fig. 9: Successful extraction of the packet times from the cache
measurements of the word "because" typed by subject s033.
set up tcpdump. It is important to note that we only trace the
words once and use the resulting data in our classiﬁcation.
Evaluation of SSH packet recovery We evaluated the work
of the online tracker and ofﬂine extractor over the entire test
set of twenty subjects. We deﬁne a predicted packet as True
Positive (TP) if the packet is within an interval I of the
SSH keystroke packet. A False negative is registered if no
predicted packet is within interval I of a SSH keystroke. If
the signal extraction predicts more packets than there were
emitted, these are counted as False Positive (FP). Similarly,
if multiple packets are predicted for one keystroke only, one
results in a TP and the rest are FPs. We evaluated the extraction
on three different intervals I. Table II presents our results. For
I = 0.05s, we can extract the SSH keystroke packets with a TP
rate of 84.72% (and 11% FN rate). When reducing the interval
I, the number of FNs increases. With I = 0.001s, the TP rate
is still at nearly 50%. Zhang et al. [48] established the ballpark
ﬁgure of I = 0.001s as sufﬁcient for successful keystroke
attacks. For comparison, the table also shows the results of
extracting the SSH packets and their times from tcpdump.
These (ideal) results serve as a baseline for packets delayed
over the network and thus no longer within the interval I.
Figure 8 shows the absolute difference between the SSH
keystrokes emission time and all the correctly predicted SSH
packets within I = 0.001. As we can see,
the correctly
classiﬁed packets from the cache have a higher inner quartile
range compared to the packets captured with tcpdump. In
general, this shows that we can extract incoming packet times
with only slight time differences compared to the baseline
and tcpdump. However, the challenge is to correctly extract
the packets from the cache measurements in the ﬁrst place.
To give an intuition about a successful SSH packet recovery,
we show a trace for the word "because" in Figure 9. In this
case, the recovered SSH packets are almost perfectly aligned
with the original emission of the keystrokes. Such alignment
is possible in low-latency networks. Otherwise, the network
and cache data would be shifted according to the transmission
time. As we are displaying the data points over a resolution
of 1.2 seconds, the small perturbations of the measurements
cannot be seen.
End-to-End Evaluation To perform an end-to-end accuracy
evaluation, we now take the predicted packets from cache
activity and feed them into the k-NN model that was trained
on the keyboard training data. We chose this setting as an
attacker might have access to a dataset of keystrokes, but
Fig. 8: Absolute difference between the SSH keystrokes emission
time and all the correctly predicted SSH packets within I = 0.001.
simple k-NN baseline here and expect that, by applying a
more sophisticated method, the accuracy of our predictions
can further be increased.
D. Evaluation
We evaluated NetCAT on the Intel Xeon Silver 4110 cluster
with three machines shown in Figure 2. The attacker can send
packets to the NIC to which the victim machine is connected.
This allows the attacker to send synchronization packets, as
previously described. The victim starts an SSH connection to
the application server and then starts typing the words from
the test set. We use expect, which is a programmable interface
to interact with interactive programs, to replay the words in
the SSH session by using the key-down-to-key-down times
from the dataset [49]. This approach allows us to replicate
our experiments with different settings and environmental
factors. The online tracker measures the cache activity over
7 seconds. The expect program starts to replay the words
within such capturing window. Note that the exact start time
is not fed into the tracking or extraction algorithms. Besides
measuring the cache activity, we also capture the incoming
network trafﬁc on the application server with tcpdump. While
the tcpdump baseline assumes a strong attacker model which
requires physical access to the server (i.e., a network tap),
these traces allow us to make a side-by-side comparison of
the classiﬁer on keyboard key-down-to-key-down times, the
actual network packet interarrival times (through tcpdump),
and data recovered from the cache activity.
We have a total of 2,420 test word traces. The total capturing
of the training data takes ~6h. This time includes measuring
the cache for each word during 7 seconds plus some time to
30
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:37:59 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 10: Classiﬁer accuracy and Top-10 accuracy for the raw keyboard
data, the data extracted from tcpdump, and the data from the cache
measurements over all subjects.
Fig. 11: Variance of the classiﬁer’s accuracy when changing the
number of unique words for test and training set over all subjects.
cannot replay them on the target network topology. To put
the evaluation results of the classiﬁer into perspective, we
summarize the accuracy and Top-10 accuracy for the keyboard
data, the data extracted from tcpdump, and the data from the
cache measurements in Figure 10. We can see that, even on the
keyboard data, the accuracy of the k-NN model is below 40%
which tells us that accurately predicting the true words in this
dataset is challenging. Therefore, we used the common Top-10
accuracy metric to show that predicting the right word within
a limited number of guesses (10) can be achieved accurately
with 85.75%.
When comparing the Top-10 accuracy based on the network
data with the raw keyboard data, we can see a signiﬁcant
accuracy drop. Comparing these results with the 93.48% true
positive rate on a 0.001s interval in Table II, we can see
that even slight perturbations in the interleaving times can
mislead the classiﬁer trained on raw keyboard data. This makes
predicting the right words more challenging for imperfect SSH
packet recovery as in the case of the cache measurements.
However, on average over all users, the classiﬁer predicts the
right word within its ﬁrst ten guesses (Top-10 accuracy) in
58.95% of the words. Encouragingly, this is only roughly
15% lower than the performance of tcpdump classiﬁcation.
For 50% of the words, the attacker is able to guess the word
with 7.85 guesses (median distance). On average over all users
and words, the guessing distance is 20.89. On average we have
228.7 words per user. Therefore, a random guesser would have
an average distance of 114.35 words. We conclude that the
signal of our cache measurement is strong enough to launch a
successful keystroke timing attack via remote PRIME+PROBE.
The full test scores for each test data source and subject can
be found in Appendix D.
To analyze the impact of the word corpus on the classiﬁer,
we changed the number of unique words used for training and
testing. On every round we choose x words at random from
the user speciﬁc corpus and then increases x by ten for the
next round. The unique words do not necessary increase by
ten as we have different word corpus sizes per subject. As
shown in Figure 11, with less unique words the classiﬁer has
a much higher accuracy than with the total number of unique
words in the original dataset [49]. Furthermore, the variance of
accuracy is quite signiﬁcant over a lower number of words and
ﬂattens around 170 average unique words per subject. These
observations can be made for all the three different testing
data sources. One drawback of using a high number of unique
words is that our training data set is relatively small, i.e., most
of the words in the training set only have one user trace. A
dataset with many repetitions per word, a large enough word
corpus, and a sufﬁcient number of test subjects would naturally
improve the accuracy of predictions.
IX. GENERALIZATION
We now discuss how, in future work, NetCAT-like attacks
may be generalized beyond our proof-of-concept scenarios.
PCIe to CPU attacks As discussed, DDIO’s write allocation
limitation prevents an attacker from building eviction sets for
the full LLC, making it challenging to directly leak informa-
tion from the host CPU. To accomplish such an information
leak, we believe we can leverage server software running on
the victim. For example, the AnC [13] attack can potentially
be launched over the network. Given a read primitive with
arbitrary offset, such as Redis [54] would give, an attacker
might generate an access pattern that would ﬂush a TLB
set and translation caches as reverse engineered by [3, 55].
The attacker would then dereference a target virtual address,
guaranteed to generate a pagetable walk with virtual address-
dependent offsets. If this experiment is repeated often enough
with the same offsets (modulo page size), the evictions will
eventually reach the DDIO level and the signal will become
observable by NetCAT. Similarly, we expect that when certain
Spectre [16] gadgets are dereferenced repeatedly with the same
offsets (modulo page size), they will cause visible evictions at
the DDIO level and allow secrets to be revealed remotely, just
as local spectre attacks can.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:37:59 UTC from IEEE Xplore.  Restrictions apply. 
31
A further challenge is the resolution time by which we can
measure changes in the cache. The eviction set of one cache
set in the DDIO context contains two addresses. Therefore
continuous probing of one cache set requires two one-sided
RDMA reads. The ib_read_lat latency benchmark measured
an average latency between our Intel Xeon Silver 4110 cluster
of 1,550 ns for single a read. In our experiments, we time
both read operations together, which results in less overhead
than single timed operations. On average we can proﬁle one
eviction set with a resolution of 2892 ns on the Intel Xeon
Silver 4110 cluster (99th percentile: 3066 ns, SD: 115 ns).
The resolution time is bounded by the network round trip time