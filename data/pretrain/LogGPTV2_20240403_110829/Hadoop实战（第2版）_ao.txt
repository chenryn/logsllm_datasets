world 1
5.1.2 设计思路
这个应用实例的解决方案很直接，就是将文件内容切分成单词，然后将所有相同的单词聚集在一起，最后计算单词出现的次数并输出。根据MapReduce并行程序设计原则可知，解决方案中的内容切分步骤和数据不相关，可以并行化处理，每个获得原始数据的机器只要将输入数据切分成单词就可以了。所以可以在Map阶段完成单词切分任务。另外，相同单词的频数计算也可以并行化处理。由实例要求来看，不同单词之间的频数不相关，所以可以将相同的单词交给一台机器来计算频数，然后输出最终结果。这个过程可以在Reduce阶段完成。至于将中间结果根据不同单词分组再分发给Reduce机器，这正好是MapReduce过程中的shuffle能够完成的。至此，这个实例的MapReduce程序就设计出来了。Map阶段完成由输入数据到单词切分的工作，shuffle阶段完成相同单词的聚集和分发工作（这个过程是MapReduce的默认过程，不用具体配置），Reduce阶段负责接收所有单词并计算其频数。MapReduce中传递的数据都是＜key, value＞形式的，并且shuffle排序聚集分发都是按照key值进行的，因此将Map的输出设计成由word作为key、1作为value的形式，这表示单词word出现了一次（Map的输入采用Hadoop默认的输入方式：文件的一行作为value，行号作为key）。Reduce的输入为Map输出聚集后的结果，即＜key, value-list＞，具体到这个实例就是＜word，{1，1，1，1……}＞，Reduce的输出会设计成与Map输出相同的形式，只是后面的数字不再固定是1，而是具体算出的word所对应的频数。下面给出笔者实验的WordCount代码。
5.1.3 程序代码
WordCount代码如下：
package cn.edu.ruc.cloudcomputing.book.chapter05；
import java.io.IOException；
import java.util.StringTokenizer；
import org.apache.hadoop.conf.Configuration；
import org.apache.hadoop.fs.Path；
import org.apache.hadoop.io.IntWritable；
import org.apache.hadoop.io.Text；
import org.apache.hadoop.mapreduce.Job；
import org.apache.hadoop.mapreduce.Mapper；
import org.apache.hadoop.mapreduce.Reducer；
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat；
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat；
import org.apache.hadoop.util.GenericOptionsParser；
public class WordCount{
//继承Mapper接口，设置map的输入类型为＜Object, Text＞
//输出类型为＜Text, IntWritable＞
public static class TokenizerMapper
extends Mapper＜Object, Text, Text, IntWritable＞{
//one表示单词出现一次
private final static IntWritable one=new IntWritable（1）；
//word用于存储切下的单词
private Text word=new Text（）；
public void map（Object key, Text value, Context context）throws IOException，
InterruptedException{
StringTokenizer itr=new StringTokenizer（value.toString（））；//对输入的行切词
while（itr.hasMoreTokens（））{
word.set（itr.nextToken（））；//切下的单词存入word
context.write（word, one）；
}
}
}
//继承Reducer接口，设置Reduce的输入类型为＜Text, IntWritable＞
//输出类型为＜Text, IntWritable＞
public static class IntSumReducer extends Reducer＜Text, IntWritable, Text, IntWritable＞{
//result记录单词的频数
private IntWritable result=new IntWritable（）；
public void reduce（Text key, Iterable＜IntWritable＞values, Context context）
throws IOException, InterruptedException{
int sum=0；
//对获取的＜key, value-list＞计算value的和
for（IntWritable val：values）{
sum+=val.get（）；
}
//将频数设置到result中
result.set（sum）；
//收集结果
context.write（key, result）；
}
}
public static void main（String[]args）throws Exception{
Configuration conf=new Configuration（）；
//检查运行命令
String[]otherArgs=new GenericOptionsParser（conf, args）.getRemainingArgs（）；
if（otherArgs.length！=2）{
System.err.println（"Usage：wordcount＜in＞＜out＞"）；
System.exit（2）；
}
//配置作业名
Job job=new Job（conf，"word count"）；
//配置作业的各个类
job.setJarByClass（WordCount.class）；
job.setMapperClass（TokenizerMapper.class）；
job.setCombinerClass（IntSumReducer.class）；
job.setReducerClass（IntSumReducer.class）；
job.setOutputKeyClass（Text.class）；
job.setOutputValueClass（IntWritable.class）；
FileInputFormat.addInputPath（job, new Path（otherArgs[0]））；
FileOutputFormat.setOutputPath（job, new Path（otherArgs[1]））；
System.exit（job.waitForCompletion（true）?0：1）；
}
}
5.1.4 代码解读
WordCount程序在Map阶段接收输入的＜key, value＞（key是当前输入的行号，value是对应行的内容），然后对此行内容进行切词，每切下一个词就将其组织成＜word，1＞的形式输出，表示word出现了一次。
在Reduce阶段，TaskTracker会接收到＜word，{1，1，1，1……}＞形式的数据，也就是特定单词及其出现次数的情况，其中“1”表示word的频数。所以Reduce每接受一个＜word，{1，1，1，1……}＞，就会在word的频数上加1，最后组织成＜word, sum＞的形式直接输出。
5.1.5 程序执行
运行条件：将WordCount.java文件放在Hadoop安装目录下，并在目录下创建输入目录input，目录下有输入文件file1、file2。其中：
file1的内容是：
hello world
file2的内容是：
hello hadoop
hello mapreduce
准备好之后在命令行输入命令运行。下面对执行的命令进行介绍。
1）在集群上创建输入文件夹：
bin/hadoop fs-mkdir wordcount_input
2）上传本地目录input下前四个字符为file的文件到集群上的input目录下：
bin/hadoop fs-put input/file*wordcount_input
3）编译WordCount.java程序，将结果放入当前目录的WordCount目录下：
javac-classpath hadoop-1.0.1-core.jar：lib/commons-cli-1.2.jar-d WordCount WordCount.java
4）将编译结果打成Jar包：
jar-cvf wordcount.jar-C WordCount.
5）在集群上运行WordCount程序，以input目录作为输入目录，output目录作为输出目录：
bin/hadoop jar wordcount.jar WordCount wordcount_input wordcount_output
6）查看输出结果：
bin/hadoop fs-cat wordcount_output/part-r-00000
5.1.6 代码结果
运行结果如下：
hadoop 1
hello 3
mapreduce 1
world 1
5.1.7 代码数据流
WordCount程序是最简单也是最具代表性的MapReduce框架程序，下面再基于上例给出MapReduce程序执行过程中详细的数据流。
首先在MapReduce程序启动阶段，JobTracker先将Job的输入文件分割到每个Map Task上。假设现在有两个Map Task，一个Map Task一个文件。
接下来MapReduce启动Job，每个Map Task在启动之后会接收到自己所分配的输入数据，针对此例（采用默认的输入方式，每一次读入一行，key为行首在文件中的偏移量，value为行字符串内容），两个Map Task的输入数据如下：
＜0，"hello world"＞
＜0，"hello hadoop"＞
＜14，"hello mapreduce"＞
Map函数会对输入内容进行词分割，然后输出每个单词和其频次。第一个Map Task的Map输出如下：
＜"hello"，1＞
＜"world"，1＞
第二个Map Task的Map输出如下：
＜"hello"，1＞
＜"hadoop"，1＞
＜"hello"，1＞
＜"mapreduce"，1＞
由于在本例中设置了Combiner的类为Reduce的class，所以每个Map Task将输出发送到Reduce时，会先执行一次Combiner。这里的Combiner相当于将结果先局部进行合并，这样能够降低网络压力，提高效率。执行Combiner之后两个Map Task的输出如下：
Map Task1
＜"hello"，1＞
＜"world"，1＞
Map Task2
＜"hello"，2＞
＜"hadoop"，1＞
＜"mapreduce"，1＞
接下来是MapReduce的shuffle过程，对Map的输出进行排序合并，并根据Reduce数量对Map的输出进行分割，将结果交给对应的Reduce。经过shuffle过程的输出也就是Reduce的输入如下：
＜"hadoop"，1＞
＜"hello"，＜1，2＞＞
＜"mapreduce"，1＞
＜"world"，1＞
Reduce接收到如上的输入之后，对每个＜key, value-list＞进行处理，计算每个单词也就是key的出现总数。最后输出单词和对应的频数，形成整个MapReduce的输出，内容如下：
＜"hadoop"，1＞
＜"hello"，3＞
＜"mapreduce"，1＞
＜"world"，1＞
WordCount虽然简单，但具有代表性，也在一定程度上反映了MapReduce设计的初衷—对日志文件的分析。希望这里的详细分析能对大家有所帮助。
5.2 数据去重
数据去重这个实例主要是为了让读者掌握并利用并行化思想对数据进行有意义的筛选。统计大数据集上的数据种类个数、从网站日志中计算访问地等这些看似庞杂的任务都会涉及数据去重。下面就进入这个实例的MapReduce程序设计。
 5.2.1 实例描述
对数据文件中的数据进行去重。数据文件中的每行都是一个数据。
样例输入：