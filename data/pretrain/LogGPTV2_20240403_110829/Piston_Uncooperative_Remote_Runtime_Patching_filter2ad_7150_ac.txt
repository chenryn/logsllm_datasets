program. Other data, such as globals, heap data which is not freed
inside of the function, and return values may influence the remainder
of the program and are not considered scratch space.
Piston determines the successful completion of the hijacked func-
tion during the dynamic analysis of the offline exploitation trace. At
the exploitation point, the corrupted data range is marked as tainted,
and the taint is tracked through the remainder of the function. If any
branch is influenced by tainted data or if tainted data is written out-
side of the scratch space, then the function is considered to have not
completed successfully. We filter out the restoration of callee-saved
registers at the end of the function, as these are considered part of the
state of the caller and will be restored later.
4.2.2 Checking for Repeatability. When Piston is unable to
prove that the hijacked function completed successfully, it will check
if its execution can simply be repeated after the remote process is
patched. The hijacked function can be safely restarted if all of the
inputs (i.e., values the function reads from memory or registers) to
the interrupted invocation can be recovered. If these inputs can be re-
covered, the hijacked function can be re-executed in the same context
as its interrupted invocation and will carry out the same actions.
Piston groups the inputs that a function receives into three cat-
egories: local state data, which is passed to the hijacked function
on the stack or in registers, global state data, which is retrieved by
the hijacked function from the heap or global memory, and environ-
ment inputs, which are retrieved through system calls. The hijacked
function is considered repeatable if these conditions hold:
Local state data is recoverable. Arguments on the stack, which might
be clobbered during the overwrite itself or by actions taken by the
hijacked function after exploitation, must be recoverable, as must
arguments passed to the function through registers. This recovery
is explained in Section 4.3.
Global state data is recoverable. All data in registers and memory
that the hijacked function reads must be recoverable. This means
that the hijacked function cannot irrecoverably overwrite its inputs.
System calls are repeatable. The system calls invoked out by the
hijacked function must be repeatable. System calls that cannot
simply be re-executed, such as unlink (since, after the first call,
the file will no longer exist), violate this condition.
The first condition will be checked during the caller state recovery
step. To check the latter two conditions, Piston collects a list of all
memory accesses and system calls in the exploitation trace, which
can then be checked for any violations to the repeatability conditions.
To detect changes to the global state, the list is analyzed to build a
set of any potentially corrupted global state by the original run of the
hijacked function. After this, the list is analyzed again to see if any of
the corrupted global state can be used as an input to the repeated invo-
cation of the hijacked function. Conceptually, this happens when the
hijacked function reads in some global value before writing to it (for
example, incrementing a global counter). The second invocation will
use the value corrupted by the first, resulting in an inconsistency in
execution between the interrupted invocation and repeated invocation
of the hijacked function.
Piston will attempt to undo simple global changes where no deref-
erence of data takes place. We use under-constrained symbolic exe-
cution (UCSE), an extension of dynamic symbolic execution that en-
ables the analysis of functions without the requirement of context [41].
UCSE works by identifying memory dereferences of pointers that are
unknown due to missing context (for example, a pointer that would
have been passed as an argument) and performs on-demand memory
initialization to allow the analysis to continue.
Piston explores the hijacked function with UCSE, ignoring the
context from the exploitation trace to avoid under-approximating the
remote state. If UCSE can determine how a global value will change
during execution of the hijacked function, then Piston can recover
the value automatically. Note that, like other techniques based on
symbolic execution, UCSE can succumb to path explosion. When
this occurs, Piston will be unable to automatically recover changes
to global state. If any changes to global state are detected that Piston
is unable to recover, analyst will be required to provide a rollback
routine to undo the effects of the interrupted execution.
After checking for changes to the global state, Piston carries out an
analysis of system calls. Specifically, it checks for system calls that
might not be repeatable. For example, if the interrupted and repeated
invocation of the hijacked function both try to unlink the same
file, an inconsistency between their executions will arise. Because
Piston does not have a complete model of all system calls, it presents
these lists to the analyst for review. If any system calls are deemed not
repeatable, then the analyst must provide a rollback routine to undo
the effects of the system calls.
4.3 Caller State Recovery
Regardless of whether the hijacked function has successfully run or
needs to be restarted, the state of the caller function must be recovered.
Although the general problem of restoring registers and memory to
the state of the execution before the overflow is undecidable, we have
found that there is often enough data remaining to recover the orig-
inal state. Our key insight is that, due to the way programmers write
source code and compilers compile it, the stack frame and registers of
a function often contain redundant data, which can be used to restore
the corrupted data. In our case, this means that the value of a corrupted
stack variable or register can often be determined as some equation
of other stack or register values.
1 mov
[ ebp+ var_14 ]
2 mov
[ ebp+ va r_ 8 ]
3 sub
4 mov
5 c a l l
eax ,
edx ,
eax , edx
[ ebp+var_3C ] , eax
h i j a c k e d _ f u n c ( )
Listing 1: An example showing where stack variables have
redundant information.
146Before delving into Piston’s approach to state recovery, we provide
and briefly discuss an example of such redundancy in Listing 1. As-
sume the programs instruction pointer is currently at line 5. The stack
variable var_3C is redundant since it can be computed from the
other stack variables, specifically, var_3C = var_14 - var_8.
Thus, if the overflow clobbers var_3C, it can be recovered from
var_14 and var_8.
4.3.1 Data Filtering. Before recovering corrupted state, Piston
must identify what state needs to be recovered. If the hijacked func-
tion completed successfully, we must restore any stack variables or
registers that were corrupted by the exploit and will be used later in the
caller function. Additionally, if the hijacked function was interrupted,
we must also restore all of the arguments (on the stack and in registers)
that are passed to the hijacked function.
As described in Section 4.1, Piston identifies the range of registers
and stack variables that were clobbered by the exploit. In fact, not all
of these values must be recovered. For example, if a callee-saved reg-
ister is written to immediately after the hijacked function returns, its
value after exploitation, whether or not it was corrupted, is irrelevant,
and there is no need to restore it. Piston identifies these cases by com-
puting the control flow graph of the hijacked function and identifying
accesses to stack variables and registers. Then a dependency analysis
is run on the control flow graph to check if any path exists where a
corrupted register or stack variable is read before it is overwritten. If
no such path exists, Piston marks the register or stack variables as
unused and filters it from further state recovery steps.
One caveat must be mentioned for stack values. In some cases, the
caller function might pass a pointer to the stack as an argument to the
hijacked function. Normally, this happens when a buffer or structure
resides on the stack and must be used by the hijacked functions. If
the hijacked function performs complex operations on this pointer
(such as passing it into other functions or system calls), Piston’s static
analysis is unable to safely recover these effects. Piston makes the
assumption that the passed-in pointer points to the beginning of the
structure and assumes that the hijacked function may have corrupted
anything on the stack after this pointer.
At the end of this step, Piston has a recovery set of the registers
and stack values that must be recovered before the caller function can
resume execution.
4.3.2 Data Recovery. Piston recovers state data by analyzing
two locations in the caller function: the function prologue and the
hijacked function call site.
Generally, functions will initialize several registers in the prologue
and use them for the remainder of the function. This is especially true
for registers such as the base pointer (i.e., ebp on x86), which are
typically set at the beginning of a function. The values of registers that
are set in this way can often be determined by analyzing the prologue
of a function. Likewise, the caller function prepares the call-site of
the hijacked function by copying its arguments into argument stack
variables and registers. Most of the time, these arguments are passed
by value and are drawn from other parts of the state, creating data
redundancy that can be leveraged to restore their values when they
are corrupted by the exploit.
To avoid under-approximations, Piston does not reuse the exploita-
tion trace in the data recovery step. The control-flow path from the
trace may differ from the one that will be executed on the remote
server. For example, the remote server may have internal state such
as a linked list, which will result in a different control flow than the
one in the concrete trace.
To recover data, Piston will analyze two locations with symbolic
execution. The first is the start of the caller function up until the first
branch. The second location is the callsite of the hijacked function,
starting at the earliest basic block from which there is only one path
that reaches the call.
Piston analyzes these locations with under-constrained symbolic
execution and extracts the relationships between data that must be
recovered and the uncorrupted data currently existing in the state. We
represent these relationships as equations that produce the recovered
values of corrupted data when provided the values of the uncorrupted
data. These equations are then examined to verify that all values in
the recovery set can be recovered from existing data in the stack.
For example, in Listing 1, when Piston symbolically analyzes
the callsite of the hijacked function it will generate a constraint that
var_3C = var_14 - var_8. If Piston determines that var_3C
will be overwritten, but not var_14 or var_8 then it will determine
that var_3C is recoverable.
If all values in the recovery set can be recovered from existing data
on the stack, Piston saves this set of equations as the repair routine.
Otherwise, Piston requires the analyst to provide a partial repair rou-
tine that recovers corrupted values that are still missing. The repair
routine will be executed after the remote process is patched and before
it is restarted, as explained in Section 5.
5 REMOTE PATCHING
Until this point, Piston’s analysis has been offline: no connection to
the remote process has been made. This section describes how Piston
uses the provided exploit specification to achieve code execution in
the remote process, and applies the results of the offline analyses to
repair, patch, and resume the remote process.
The astute reader will recall that, in the previous analyses, Piston re-
covered the following information for use during the remote patching:
Patch set. In Section 3, we described how Piston identified the set
of patches to apply to the remote process to turn it into a functional
copy of the replacement binary.
Rollback routine. We introduced in Section 4.2 Piston’s strategy for
undoing the effects of the hijacked function, if it is determined to
have been interrupted by the exploit.
Repair routine. Piston’s approach to creating a routine to repair the
remote process state after exploitation is detailed in Section 4.3.
While generating this information is complex, the rest of the pro-
cess is straightforward. Piston executes the following steps, in order:
(1) First, Piston launches the exploit against the remote process. The
exploit hijacks the control flow of the remote process and loads a
first-stage payload, provided by Piston, which facilitates the execu-
tion of the rest of the repair and patching tasks. We call this payload
the patching stub.
(2) Next, Piston transfers the repair routine to the patching stub. The
patching stub executes the repair routine to repair the damage done
by the exploit to the remote process state.
(3) If, during the prior offline analysis, Piston determined that the ex-
ploit caused an interruption of the hijacked function (i.e., it did not
terminate successfully), Piston transfers the rollback routine to its
147patching stub and executes it to undo the effects of the hijacked
function. As discussed in Section 4.2, in this case, the hijacked
function will be restarted after the patching process is complete.
(4) Piston transfers the patch set to the patching stub. The patching stub
applies this patch set to the remote process, transforming it into a
program that is functionally equivalent to the replacement binary.
(5) Finally, the patching stub returns control to the remote process.
If the hijacked function completed successfully, it simply returns
to the instruction, inside the caller function, after the call to the
hijacked function. Otherwise, control flow returns to the beginning
of the hijacked function.
After these steps are completed the remote process has been hot-
patched. The remote host is now effectively running the replacement
binary, and this has been done without restarting the entire process
or performing any permanent changes.
The rest of this section will discuss other minor points relating to
Piston’s remote patching step.
5.1 Exploit Requirements
Piston has very simple requirements for the provided exploit spec-
ification. In short, the specification must describe an exploit that
achieves code execution and loads Piston’s patching stub. As dis-
cussed throughout the paper, if this exploit uses a stack-based buffer
overflow to achieve code execution, Piston can often carry out the rest
of its work automatically. Otherwise, the user must also provide the
rollback and repair routines.
5.2 Optional Patch Testing
Piston supports an optional patch testing step between the offline anal-
yses and the actual remote patching described earlier in this section. If
the analyst provides a test case to verify that the process has been prop-
erly patched, Piston carries out a test run against a locally-executed
copy of the original binary. After patching this local process, Piston
verifies that the test case passes when run against it. While this is a very
straightforward concept, we found that it greatly eased cases when
rollback and repair functions had to be provided manually by the user.
5.3 Persistence
Piston is meant to patch the running process ephemerally (i.e., with-
out making any actual changes to the filesystem or firmware). While
Piston can, during the patching process, execute a user-provided per-
sistence routine to persist its changes (for example, by overwriting
the original binary on disk), this is not Piston’s standard use-case. In
fact, we expect that, generally, the process that Piston patches will
not have the proper access to write to its original binary on-disk. For
example, server processes on Linux almost never have write permis-
sions to their own binaries, and Piston would be running with the
same permissions as the server process while patching it.
To patch forking services, Piston would need to apply the patch to
the parent process. There are no theoretical limitations which prevent
Piston from attaching to, and patching, a parent of the exploited pro-
cess, granted that our exploited process has permissions to attach to a
parent and in addition, that the underlying operating system supports
process tracing.
Ephemeral patching itself is a very powerful technique, even with-
out the ability to commit the changes to disk. In Section 6, we show-
case how to quickly patch a security flaw in a web server to which the
analyst may not have access. That application of Piston does not need
to be persistent to be useful. Furthermore, other hot-patching systems
such as PatchDroid choose to only patch ephemerally [31].
6 EVALUATION
We evaluate Piston in two ways. First, we test its ability to recover
the program state after a stack buffer overflow on all of the applicable
binaries from the Cyber Grand Challenge Qualifying Event (CQE).
For all CQE binaries with stack buffer overflows, we test if Piston can
recover enough state in the caller function, such that the state can be
completely restored after an exploit achieves arbitrary code execution.
Then, we test Piston’s patching functionality on five of those binaries
as well as a real-world binary, NGINX 1.4.0 (which is vulnerable to
CVE-2013-2028) by creating exploits and using Piston to apply the
patch, recover state, and resume execution.
6.1 Dataset
We chose targets for Piston that would allow us evaluate Piston’s
state recovery methodology. We use binaries from the Cyber Grand
Challenge because these represent a large number of binaries con-
taining a wide variety of functionality. Additionally, CGC binaries