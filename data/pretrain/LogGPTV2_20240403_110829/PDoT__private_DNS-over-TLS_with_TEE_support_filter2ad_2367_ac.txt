the TEE is a challenge because the RecRes cannot communicate
with the outside world. We address this issue by having a process
running outside the TEE, as described in Section 5.1. This process
forwards packets from the client to TEE through ECALLs and sends
packets received from TEE via OCALLs. However, this processes
might redirect the packet to a malicious process or simply drop it.
We discuss this issue in Section 6.1. Another function unavailable
within TEE is forking a process. PDoT uses pthreads instead of
forking to run multiple tasks concurrently in a TEE.
Limited TEE Memory. We use several techniques to address
this challenge. First, we ensure no other enclaves (other than the
quoting enclave) run on RecRes machine. This allows PDoT to use
all available EPC memory. Second, we fix the number of Query-
Handler threads in order to save space. This is possible because of
dis-association of QueryHandler and ClientReader/Writer threads.
OCALL and ECALL Overhead. ECALLs and OCALLs intro-
duce overhead and therefore should be avoided as much as possible.
For example, all threads mentioned in the previous section must
wait until they receive the following information: for ClientReader
thread – DNS query from the client, for QueryProcessor thread –
query from inQueryList, and for ClientWriter thread – response
from outQueryList. PDoT was implemented so that these threads
wait inside the enclave. If we were to wait outside the enclave, we
would have to use an ECALL to enter the enclave each time the
thread proceeds.
6 EVALUATION
6.1 Security Analysis
This section describes how query privacy (Requirement R1) is
achieved, with respect to the two types of adversaries, per Sec-
tion 3.1.
Malicious RecRes operator. Recall that a malicious RecRes
operator controls the machine that runs PDoT RecRes. It cannot
obtain the query from intercepted packets since they flow over
the encrypted TLS channel. Also, because the local TLS endpoint
resides inside the RecRes enclave, the malicious operator cannot
retrieve the query from the enclave, as it does not have access to
the protected memory region.
However, a malicious RecRes operator may attempt to connect
the socket to a malicious TLS server that resides in either: 1) an
untrusted region, or 2) a separate enclave that the operator itself
created. If the operator can trick the client into establishing a TLS
connection with the malicious TLS server, the adversary can obtain
the plaintext DNS queries. For case (1), the verification step at the
client side fails because the TLS server certificate does not include
any attestation information. For case (2), the malicious enclave
might receive a legitimate attestation verification report, attesta-
tion verification report signature, and attestation report signing
certificate from IAS. However, that report would contain a different
MRENCLAVE value, which would be rejected by the client. To con-
vince the client to establish a connection with PDoT RecRes, the
adversary has no choice except to run the code of PDoT RecRes.
Therefore, in both cases, the adversary cannot trick the client into
establishing a TLS connection with a TLS server other than the one
running a PDoT RecRes.
Network Adversary. Recall that this adversary captures all
packets to/from PDoT. It cannot obtain the plaintext queries since
they flow over the TLS tunnel. The only information it can obtain
from packets includes cleartext header fields, such as source and
destination IP addresses. This information, coupled with a timing
attack, might let the adversary correlate a packet sent from the
client with a packet sent to an NS. The consequent amount of
privacy leakage is discussed in Section 7.1
6.2 Deployability
Section 5 shows how PDoT clients do not need special hardware,
and require only minor software modifications (Requirement R2).
To aid deployability, PDoT also provides several configurable pa-
rameters, including: the number of QueryHandle threads (to adjust
throughput), the amount of memory dedicated to each thread (to
serve clients that send a lot of queries at a given time), and the time-
out of QueryHandle threads (to adjust the time for a QueryHandle
thread to acquire a resource). Another consideration is incremental
deployment, where some clients may request DNS-over-TLS with-
out supporting PDoT. PDoT can handle this situation by having
its TLS certificate also signed by a trusted root CA, since legacy
clients will ignore PDoT-specific attestation information.
On the client side, an ideal deployment scenario would be for
browser or OS vendors to update their client stubs to support PDoT.
The same way that browser vendors currently include and maintain
a list of trusted root CA certificates in their browsers, they could
include and periodically update a list of trustworthy MRENCLAVE
values for PDoT resolvers. This could all be done transparently to
end users. As with root CA certificates, expert users can manually
add/remove trusted MRENCLAVE values for their own systems. In
practice, there are only a handful of recursive resolver software
implementations. Thus, even allowing for multiple versions of each,
the list of trusted MRENCLAVE values would be orders of magni-
tude smaller than the list of public keys of every trusted resolver,
as would be required for standard DNS-over-TLS.
6.3 Performance Evaluation
We ran PDoT on a low-cost Intel NUC consisting of an Intel Pentium
Silver J5005 CPU with 128 MB of EPC memory and 4 GB of RAM.
We used Ubuntu 16.04 and the Intel SGX SDK version 2.2. We
configured our RecRes to support up to 50 concurrent clients and
process queries using 30 QueryHandle threads. For comparison, we
performed the same benchmarks using Unbound [23], a popular
open source RecRes.
PDoT: Private DNS-over-TLS with TEE Support
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
(a) Latency of PDoT and Unbound (Cold Start)
(b) Latency of PDoT and Unbound (Warm Start)
Figure 4: Latency comparison of PDoT and Unbound
Latency Evaluation. The objective of our latency evaluation is
6.3.1
to assess overhead introduced by running RecRes inside an enclave.
To do so, we measure the time to resolve a DNS query using PDoT
and compare with Unbound. To meet requirement R3, PDoT should
not incur a significant increase in latency compared to Unbound.
Experimental Setup. The client and RecRes ran on the same
physical machine to remove network delay. We conducted the
experiment using PDoT and Unbound as the RecRes, and Stubby
as the client. We measured latency under two different scenarios:
cold start and warm start. In the former, the client sets up a new
TLS connection every time it sends a query to the RecRes. In the
warm start scenario, the client sets up one TLS connection with the
RecRes at the beginning, and reuses it throughout the experiment.
In other words, the cold start measurements also include the time
required to establish the TLS connection. In this experiment, the
caching mechanisms of both PDoT and Unbound were disabled.
We created a python program to feed DNS queries to the client.
The program sends 100 queries sequentially for ten different do-
mains. That is, the program waits for an answer to the previous
query before sending the next query. We used the top ten domains
of the Majestic Million domain list [26].
The python program measures the time between sending the
query and receiving an answer. For the cold start experiment, we
spawned a new Stubby client and established a new TLS connection
for each query. In the warm start scenario, we first established the
TLS connection by sending a query for another domain (not in the
top ten), but did not include this in the timing measurement.
Note that the numeric latency values are specific to our experi-
mental setup because they depend on network bandwidth of our
RecRes, and latency between the latter and relevant NS-s. The im-
portant aspect of this experiment is the ratio between the latencies
of PDoT and Unbound. Therefore it is not meaningful to compute
average latency over a large set of domains. Instead, we took mul-
tiple measurements for each of a small set of domains (e.g., 100
measurements for each of 10 domains) so as to analyse the range
of response latencies for each domain.
Results and observations. Results of latency measurements
are are shown in Figure 4. Red boxes show latency of PDoT and
the blue boxes – of Unbound. In these plots, boxes span from the
lower to upper quartile values of collected data. Whiskers span
from the highest datum within the 1.5 interquartile range (IQR) of
the upper quartile to the lowest datum within the 1.5 IQR of the
lower quartile. Median values are shown as black horizontal lines
inside the boxes.
For the cold-start case in Figure 4a, although Unbound is typically
faster than our proof-of-concept PDoT implementation, the range
of latencies is similar. For 7 out of 10 domains, the upper whisker
of PDoT was lower than that of Unbound. Overall, PDoT shows
an average 22% overhead compared to Unbound in the cold-start
setting.
For the warm-start case in Figure 4b, the median latency is lower
across the board compared to the cold-start setting because the TLS
tunnel has already been established. In this setting, PDoT shows
an average of 9% overhead compared to Unbound. In practice, once
the client has established a connection to RecRes, it will maintain
this connection; thus, the vast majority of queries will see only the
warm-start latency.
6.3.2 Throughput evaluation. The objective of throughput evalu-
ation is to measure the rate at which the RecRes can sustainably
respond to queries. PDoT’s throughput should be close to that of
Unbound to satisfy requirement R4.
Experiment setup. The client and RecRes were run on different
machines, so that the RecRes could use all available resources of a
single machine. This is representative of a local RecRes running in
a small network (e.g., a coffee shop WiFi network). We conducted
this experiment using the same two RecRes-s as in the latency
experiment. Stubby was configured to reuse TLS connections. To
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
Yoshimichi Nakatsuka, Andrew Paverd, and Gene Tsudik
(a) Throughput for 1 client
(b) Throughput for 2 clients
(c) Throughput for 3 clients
(d) Throughput for 4 clients
(e) Throughput for 5 clients
(f) Throughput for 10 clients
(g) Throughput for 15 clients
(h) Throughput for 20 clients
(i) Throughput for 25 clients
Figure 5: Throughput comparison of PDoT (red) and Unbound (blue)
simulate a small to medium-scale network, we varied the number of
concurrent clients between 1 and 25 and adjusted the query arrival
rate from 5 to 100 queries per second. Query rates were uniformly
distributed among the clients, e.g., for an overall rate of 100 queries
per second with 10 clients, each client sends 10 queries per second.
To eliminate any variability in resolving the query, all queries were
for the domain google.com. We maintained constant query rate
for one minute. Caching mechanisms of both PDoT and Unbound
were disabled.
Results and observations. Results of throughput experiments
are shown in Figure 5. Each graph corresponds to a different number
of clients. Horizontal axis shows different query rates and vertical
axis shows the range of response latencies for each query rate.
Measurement are plotted using the same box plot arrangement as
in latency evaluation. Blue boxes show results for Unbound and
red boxes – for PDoT.
If queries arrive faster than RecRes can process them, they start
clogging the queue, and the latency of each successive response
increases as the queue grows. In this case, the average latency
continues to increase indefinitely until queries begin to timeout or
RecRes runs out of memory. We view this rate of query arrival as
unsustainable. On the other hand, if RecRes can sustain the rate
of query arrival, average response latency would remain roughly
constant irrespective of how long RecRes runs. For this experiment,
we define a sustainable rate of query arrival as the one for which
the average response latency is constant over time, and below
one second – well below a typical DNS client timeout. Figure 5
only shows cases where query arrival rate is sustainable for the
respective RecRes. In other words, the presence of a box in Figure 5
shows that the RecRes can achieve that level of throughput.
Surprisingly, we observed that Unbound cannot handle query
rates exceeding 10 queries per second per client, i.e., its maximum
sustainable rate was 10n queries per second distributed among
n clients. This is because Unbound’s design only uses one query
processing thread per client. In contrast, PDoT handled more than
PDoT: Private DNS-over-TLS with TEE Support
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
(a) 10 domains in cache
(b) 100 domains in cache
(c) 1000 domains in cache
Figure 6: Latency comparison of PDoT (red) and Unbound (blue) with different number of domains in cache
100 queries per second in all cases because its design uses a separate
pool of QueryHandle threads.
Overall, Figure 5 confirms that our proof-of-concept implemen-
tation achieves at least the same throughput as Unbound across
the range of clients and query arrival rates, and can achieve higher
throughput when the number of clients is low. Although Unbound
again achieves slightly lower latency, this is consistent with our
latency measurements in Section 6.3.1 and is likely due to the fact
that Unbound is an optimized production-grade RecRes.
6.3.3 Caching evaluation. We evaluated performance of both re-
solvers with caching enabled; Unbound with its default caching
behavior, and PDoT with our simple proof-of-concept cache.
Experiment setup. The experimental setup is similar to that of
the latency evaluation described earlier. We pre-populated resolvers’
caches with varying numbers of domains and measured response
latency for a representative set of 10 popular domains.
Results and observations. As shown in Figure 6, Unbound
serves responses from cache with a consistent latency irrespective
of the number of entries in the cache. Although PDoT achieves
lower average latencies when the cache is relatively empty, it has
higher variability than Unbound. This is probably due to the com-
bination of our unoptimized caching implementation and latency
of accessing enclave memory. Nevertheless, Figure 6 shows that –
even with the memory limitations of current hardware enclaves –
PDoT can still benefit from caching a small number of domains.
7 DISCUSSION
7.1 Information Revealed by IP Addresses
Even if the connections between the client, RecRes, and NS-s are
encrypted using TLS, some information is still leaked. The most
prominent and obvious is source/destination IP addresses. The
network adversary described in Section 3.1 can combine these
cleartext IP addresses with packet timing information in order
to correlate packets sent from client to RecRes with subsequent
packets sent from RecRes to NS.
Armed with this information, the adversary can narrow down
the client’s domain name query to one of the records that could
be served by that specific ANS. Assuming the ANS can serve R
domain names, the adversary has a 1/R probability of guessing
which domain name the user queried. When R > 1, we call this
a privacy-preserving ANS. This prompts two questions: 1) what
percentage of domains can be answered by a privacy-preserving
ANS; and 2) what is the typical size of anonymity set (R) provided
by a privacy-preserving ANS?
To answer these questions, we designed a scheme to collect
records stored in various ANS-s. We sent DNS queries for 1,000,000