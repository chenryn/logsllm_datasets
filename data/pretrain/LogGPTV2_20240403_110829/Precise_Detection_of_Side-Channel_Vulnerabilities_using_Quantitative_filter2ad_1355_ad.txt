corresponding variables.
Method invocation. Since the simplified language from Section 4
did not allow function calls, we only described an intraprocedural
version of the QCHL verifier. We currently perform interprocedural
analysis by function inlining, which is performed as a preprocess-
ing step at the internal IR level before the analysis takes place.
Since the QCHL verifier only needs to analyze hot spots (which
typically constitute a small fraction of the program), we do not
find inlining to be a major scalability bottleneck. However, since
recursive procedures cannot be handled using function inlining, our
current implementation requires models for recursive procedures
that correspond to hot spots.
Virtual calls and instanceof encoding. The result of certain opera-
tions in the Java language, such as virtual calls and the instanceof
operator, depends on the runtime values of their operands. To
faithfully model those operations , we encode the type of each al-
location site as one of its field, and we transform virtual calls and
instanceof to a series of if statements that branch on this field. For
example, if variable a may point to either allocation A1 of type T1
or allocation A2 of type T2, then the polymorphic call site a.foo()
will be modeled as:
if (a. type == T1 )
(( T1 )a). foo () ;
else if (a. type == T2 )
(( T2 )a). foo () ;
We handle the instanceof operator in a similar way.
6 EVALUATION
In this section, we describe our evaluation of Themis on a set of
security-critical Java applications. Our evaluation is designed to
answer the following research questions:
Q1. How does Themis compare with state-of-the-art tools for
side channel detection in terms of accuracy and scalability?
Q2. Is Themis able to detect known vulnerabilities in real-world
Java applications, and can Themis verify their repaired ver-
sions?
Q3. Is Themis useful for detecting zero-day vulnerabilities from
the real world?
In what follows, we describe a series of experiments that are
designed to answer the above questions. All experiments are con-
ducted on an Intel Xeon(R) computer with an E5-1620 v3 CPU and
64G of memory running on Ubuntu 16.04.
6.1 Comparison Against Blazer
To evaluate how competitive Themis is with existing tools, we
compare Themis against Blazer [8], a state-of-the-art tool for de-
tecting timing side channels in Java bytecode. Blazer is a static
analyzer that uses a novel decomposition technique for proving
non-interference properties. Since the Blazer tool is not publicly
available, we compare Themis against Blazer on the same 22 bench-
marks that are used to evaluate Blazer in their PLDI’17 paper [8].
These benchmarks include a combination of challenge problems
from the DARPA STAC program, classic examples from previous
literature[33, 46, 55], and some microbenchmarks constructed by
Version
Safe
Unsafe
Safe
Safe
Unsafe
Safe
Unsafe
Safe
Unsafe
Benchmark
MicroBench
array
array
loopAndbranch
loopAndbranch Unsafe
nosecret
notaint
sanity
sanity
straightline
straightline
STAC
modPow1
modPow1
modPow2
modPow2
passwordEq
passwordEq
Literature
k96
k96
gpt14
gpt14
login
login
Safe
Unsafe
Safe
Unsafe
Safe
Unsafe
Safe
Unsafe
Safe
Unsafe
Safe
Unsafe
Size
Time (s)
Blazer Themis
16
14
15
15
7
9
10
9
7
7
18
58
20
106
16
15
17
15
15
26
16
11
1.60
0.16
0.23
0.65
0.35
0.28
0.63
0.30
0.21
22.20
1.47
218.54
1.62
7813.68
2.70
1.30
0.70
1.29
1.43
219.30
1.77
1.79
0.28
0.23
0.33
0.16
0.20
0.12
0.41
0.17
0.49
5.30
0.61
14.16
0.75
141.36
1.10
0.39
0.61
0.54
0.46
1.25
0.54
0.70
Figure 8: Comparison between Themis and Blazer.
the developers of Blazer. Since Blazer verifies standard non-
interference (rather than our proposed ϵ-bounded variant), we set
the value of ϵ to be 0 when running Themis.
We summarize the results of our comparison against Blazer
in Table 8. 3 One of the key points here is that Themis is able
to automatically verify all 25 programs from the Blazer data set.
Moreover, we see that Themis is consistently faster than Blazer
except for a few benchmarks that take a very short time to analyze.
On average, Themis takes a median of 7.73 seconds to verify a
benchmark, whereas the median running time of Blazer is 376.92
seconds.
6.2 Detection of Known Vulnerabilities
To demonstrate that Themis can be used to detect non-trivial vulner-
abilities in real-world Java programs, we further evaluate Themis
on security-sensitive Java frameworks. The benchmarks we collect
come from the following sources:
(1) Response-size side-channel benchmarks from existing
publication [73]4.
3 The Blazer paper reports two sets of numbers for running time, namely time for
safety verification alone, and time including attack specification search. Since Themis
does not perform the latter, we only compare time for safety verification. For the
“Size” column in the table, we use the original metric from Blazer, which indicates
the number of basic blocks.
4We are only able to obtain the source codes for 2 of 3 benchmarks mentioned in the
paper.
Session D3:  Logical Side ChannelsCCS’17, October 30-November 3, 2017, Dallas, TX, USA883Time (s)
Version
Safe
Unsafe
Safe
Safe
Unsafe
Safe
Unsafe
Safe
Unsafe
Safe
Unsafe
Safe
Unsafe
Safe
Unsafe
Safe
Unsafe
Unsafe
Unsafe
LOC
1630
1602
633
619
208
180
12221
12173
2667
2619
19564
19413
1978
1900
7106
6977
7735
7660
175
232
Benchmark
1.70
Spring-Security
1.09
Spring-Security
1.27
JDK7-MsgDigest
1.33
JDK6-MsgDigest Unsafe
1.79
Picketbox
1.55
Picketbox
9.93
Tomcat
8.64
Tomcat
2.50
Jetty
2.07
Jetty
37.99
orientdb
38.09
orientdb
3.97
pac4j
1.85
pac4j
9.12
boot-auth
8.31
boot-auth
22.22
tourPlanner
22.01
tourPlanner
1.165
Dyna_table
Advanced_table
2.01
Figure 9: Evaluation on existing vulnerabilities. A check-
mark (!) indicates that Themis gives the correct result,
while ✗ indicates a false positive.
ϵ = 64
LOC’
41
!
32
!
30
!
27
!
73
!
65
!
100 !
96
!