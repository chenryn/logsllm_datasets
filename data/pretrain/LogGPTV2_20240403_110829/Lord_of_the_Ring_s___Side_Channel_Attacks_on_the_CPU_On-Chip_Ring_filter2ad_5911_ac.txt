target LLC slice5 (hit ﬂow 1: core→slice, request); upon re-
ceipt of such packet, the slice retrieves the requested cache
line; ﬁnally, it sends back to the core a global observation
(GO) message followed by the two data packets of the cache
line (hit ﬂow 2: slice→core, data and acknowledge).
6. The ring interconnect is divided into four independent
and functionally separated rings. A clean LLC load uses
the request ring, the acknowledge ring and the data ring.
Importantly, however, our data shows that performing loads
in the same direction and sharing a segment of the ring inter-
connect with the receiver is not a sufﬁcient condition for the
sender to create contention on the ring interconnect.
First, the receiver does not see any contention if its trafﬁc
envelops the sender’s trafﬁc of the ring interconnect (i.e.,
Rc  Rs)∧ (Sc  Rc)∧
(cid:2)(Ss ∈ A)∧ (Rs ∈ A)∨ (Ss ∈ B)∧ (Rs ∈ B)(cid:3)∨
(cid:2)(Sc ∈ A)∧ (Rc ∈ A)∨ (Sc ∈ B)∧ (Rc ∈ B)(cid:3)(cid:9)∨
(Rc > Rs)∧(cid:8)(Sc > Rc)∧ (Ss  Rs)∧
(1)
Observations When the Sender Misses in the LLC We
now report our observations on the results of our second ex-
periment (shown in Figure 11), when the sender misses in the
LLC. Note that the receiver’s loads still hit in the LLC.
First, we still observe the same slice contention behavior
that we observed when the sender hits in the LLC. This is
because, even when the requested cache line is not present in
Ss, load requests still need to travel from Sc to Ss ﬁrst [47] and
thus still contribute to ﬁlling up the LLC slice’s request queue
creating delays [76]. Additionally, the sender’s requests (miss
ﬂow 1: core→slice, request) still contend with the receiver’s
core→slice request trafﬁc when Rc, Rs, Sc and Ss meet the
previous conditions for request ring contention.
10. Load requests that cannot be satisﬁed by the LLC
still travel through their target LLC slice.
Second, Intel notes that in the event of a cache miss, the
LLC slice forwards the request to the system agent (SA)
over the same request ring (same request ring lane in our
terminology) from which the request arrived [76]. That is,
LLC miss transactions include a second request ﬂow from Ss
to the SA (miss ﬂow 2: slice→SA, request). Our data supports
the existence of this ﬂow. We observe contention when the
receiver’s loads travel from right to left (Rc > Rs), Ss > Rc,
and the sender and the receiver share the respective lane (Rs is
in the same cluster as Ss). For example, when Rc = 5, Rs = 2
USENIX Association
30th USENIX Security Symposium    651
(Rs ∈ B) and Ss = 6 (Ss ∈ B) the sender’s requests from Ss
to the SA contend with the receiver’s requests from Rc to
Rs. One subtle implication of this fact is that the SA behaves
differently than the other ring agent types (slices and cores) in
that it can receive request trafﬁc on either lane of the request
ring. We ﬁnd that Ss simply forwards the request (as new
trafﬁc) to the SA on the same lane on which it received it
from Sc, subject to the usual arbitration rules.
We make two additional observations: i) The amount of
contention caused by the slice→SA ﬂow is smaller than the
one caused by the core→slice ﬂow. We do not have a hypoth-
esis for why this is the case. ii) In the special case Ss = Rc
(Ss = 5 in our example) there is slightly less contention than
in the cases where Ss > Rc. This may be because, when asked
to inject new trafﬁc by both its core and its slice, the ring
stop adopts a round-robin policy rather than prioritizing either
party. Intel uses such a protocol in a recent patent [75].
11. In case of a miss, an LLC slice forwards the request
(as new trafﬁc) to the system agent on the same lane in
which it arrived. When both a slice and its home core are
trying to inject request trafﬁc into the same lane, their
ring stop adopts a fair, round-robin arbitration policy.
To our knowledge, no complete information has been dis-
closed on the subsequent steps of an LLC miss transaction.
We report here our informed hypothesis. In addition to for-
warding the request to the SA, slice Ss also responds to the
requesting core Sc with a response packet through the ac-
knowledge ring (miss ﬂow 3: slice→core, acknowledge). Af-
ter receiving the request from Ss, the SA retrieves the data
and sends it to the requesting core Sc preceded by a GO mes-
sage (miss ﬂow 4: SA→core, data and acknowledge). The
transaction completes when Sc receives the requested data.
To maintain inclusiv-
ity, the SA also sends
a separate copy of the
data to Ss through the
data ring (miss ﬂow 5:
SA→slice, data). We
summarize the ﬁve
ﬂows discussed in this
part in Figure 4.
Figure 4: Flows of an LLC miss.
The existence of miss ﬂow 4 (SA→core, data/acknowledge)
is supported by the presence of contention when the receiver’s
loads travel from right to left (Rc > Rs), with Sc > Rs, and
share the respective data/acknowledge ring lanes with the
sender. For example, there is contention when Rc = 7 (Rc ∈ A),
Rs = 2, Sc = 3 (Sc ∈ A) and Ss = 4. Recall from Figure 1 that
the SA sits on the leftmost ring stop, which implies that trafﬁc
injected by the SA always has priority over the receiver’s
trafﬁc injected by Rs. To corroborate our hypothesis that the
SA serves data/acknowledge trafﬁc directly to Sc (and not
through Ss), we time the load latency of a single LLC miss of
the sender with varying Sc and ﬁxed Ss = 7. If our hypothesis
held, we would expect a constant latency, because regardless
of Sc the transaction would need to travel from Sc to ring stop
7, from ring stop 7 to the SA, and from the SA to Sc, which
is the same distance regardless of Sc; otherwise we would
expect to see a decreasing latency as Sc increases. We measure
a ﬁxed latency (248±3 cycles), conﬁrming our hypothesis.
12. The system agent supplies data and global observa-
tion messages directly to the core that issued the load.
The existence of miss ﬂow 3 (slice→core, acknowledge) is
supported by the presence of contention in the cases where
we previously observed data/acknowledge ring contention
with a sender that hits in the LLC. For example, we observe
contention when Rc = 2 (Rc ∈ B), Rs = 6, Sc = 5 (Sc ∈ B) and
Ss = 7. However, when the sender misses in the LLC, no data
trafﬁc is sent by Ss to Sc (since we saw that data is served to the
core directly by the SA). The contention we observe must then
be due to Ss injecting trafﬁc into the acknowledge ring. Indeed,
the amount of contention caused by this acknowledge-only
ﬂow is both smaller than the one caused by data/acknowledge
ﬂows and equivalent to the one caused by the core→slice
request ﬂow, suggesting that, similarly to the request ﬂow,
miss ﬂow 3 may occupy a single slot on its ring. An Intel
patent suggests that miss ﬂow 3 may consist of an “LLCMiss”
message transmitted by Ss to Sc when the request misses in the
LLC [97]. The only remaining question (which we currently
cannot answer) is when miss ﬂow 3 occurs: when the miss is
detected or when the data is reﬁlled—but both options would
cause the same contention.
13. In the event of a miss, the LLC slice that misses still
sends a response packet through the acknowledge ring
back to the requesting core.
Finally, the existence of miss ﬂow 5 (SA→slice, data) is
supported by the presence of contention when the receiver’s
loads travel from right to left (Rc > Rs), with Ss > Rs, and
share the respective lane with the sender. However, we ﬁnd
a subtle difference in the contention rules of the SA→slice
trafﬁc. Unlike the SA→core case, where receiver and sender
contend due to trafﬁc of the same type (data and acknowl-
edge) being destined to agents of the same type (cores), we
now have receiver’s and sender’s ﬂows of the same type (data)
destined to agents of different types (cores and slices, respec-
tively). In the former case, we saw that the receiver ﬂow and
the sender ﬂow share the lane if their destination ring agents
are in the same cluster. In the latter case (which occurs only
in this scenario), we observe that the two ﬂows share the lane
if their destination ring agents are in different clusters. This
suggests that, as we summarize in Table 1, the lanes used to
communicate to different clusters may be ﬂipped depending
on the destination agent type. We make two additional obser-
vations about miss ﬂow 5. First, we believe that the SA→slice
652    30th USENIX Security Symposium
USENIX Association
CoreSliceSystemAgent1Request3Acknowledge5Data2Request4Data +AcknowledgeTable 1: Mapping to the ring lane used to send trafﬁc to
different agents over any of the four rings.
Destination
Ring Agent Type