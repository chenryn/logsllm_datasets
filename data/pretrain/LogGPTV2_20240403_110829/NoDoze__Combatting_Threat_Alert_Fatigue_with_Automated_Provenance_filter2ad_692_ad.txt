code. For a given a time period, this module counts the number
of events that have happened in an enterprise network, then
stores these counts in an external database. During runtime,
NODOZE queries this database to calculate event frequencies.
Users of NODOZE can periodically run this module to up-
date the enterprise-wide event frequencies. To remove non-
deterministic and instance speciﬁc information in each event’s
SRC and DST entities such as timestamp and process id, we
abstract/remove such ﬁelds before storing these events. Our
abstraction rules for each of the entity types are similar to
previous works [36], [49] with some changes to ﬁt our analysis:
– Merge Similar Sockets Connection. Socket connections go-
ing out
to same address from the same process vertex
have multiple vertices in the raw dependency graphs. We
merge such socket connections into a single vertex. From
the perspective of alert event causality analysis, this does
not affect correctness but saves NODOZE’s time during
dependency path generation.
– Process Entity. We remove all the information in the process
entities except the process path, commandline arguments
and gid (group identiﬁcation number).
– File Entity. We remove the inode and timestamps ﬁelds from
the ﬁle entities while abstract ﬁle paths by removing user
speciﬁc details. For example, /home/user/mediaplayer will be
changed to /home/*/mediaplayer.
– Socket Entity. Each socket connection entity has two ad-
dresses i.e. source ip and destination ip each with port
number. connection is outgoing we remove the source IP
and its port which is chosen randomly by the machine when
initiating the connection. If the connection is incoming we
the remove destination IP and its port. The end result is that
external IP of the connection is preserved while the internal
address is abstracted.
The ﬁnal equations to calculate the frequencies of an event
Ei = which are used in transition
probability matrix generation (Eq. 1) are as follows:
hosts(cid:88)
hosts(cid:88)
F req(Ei) =
h
F reqsrc rel(Ei) =
checkEvent(SRCi, DSTi, RELi, h, t)
checkEvent(SRCi, ∗, RELi, h, t)
(7)
(8)
h
where hosts are hosts in the enterprise environment while
checkEvent function returns the number of times event Ei
has occurred on the host. We only count event Ei once in
time window t for a host to prevent poisoning attacks [42].
Note that in our experiments t is set to stable window size
(discussed in §VI-C) which is 1 day. Finally, in Eq. 8 “∗”
means any DST entity.
B. Alert Triage and Graph Generation
We implemented NODOZE’s network diffusion algorithm
and concise alert dependency graph generation in 9K lines of
Java code. We also implemented several optimizations such as
an event frequency cache to minimize the NODOZE overhead.
We implement a basic dependency graph generator that,
given an event parses the audit logs from Linux and Windows
stored in PostgreSQL and generates the dependency graph on-
the-ﬂy. We also introduced several summarization techniques
that make a graph more suitable for NODOZE analysis without
affecting the correctness of causality analysis:
– Merge Transient Processes. There are processes in the
provenance graph whose sole purpose is to create another
process. We merge such processes into one node since
this does not affect our analysis. Consider the dependency
graph in Fig. 2a, IExplorer.exe process entity spawns an-
other IExplorer.exe process entity. We merge these two
IExplorer.exe process entities together.
9
C. Visualization Module
We have built a front-end which helps cyber analysts
to visualize NODOZE’s concise dependency graphs. We use
GraphViz [33] to generate causal graph in a dot format and
then convert the dot ﬁle into html format. Cyber analysts can
use these html-based graphs to visualize the most anomalous
dependency paths with their anomaly scores.
VIII. EVALUATION
In this section, we focus on evaluating the efﬁcacy of
NODOZE as an automatic threat alert triage and investigation
system in an enterprise setting. In particular, we investigated
the following research questions (RQs):
RQ1 How accurate is NODOZE over existing TDS? (§VIII-C)
RQ2 How much can NODOZE reduce the dependency graph
of a true alert without sacriﬁcing the vital information
needed for investigation? (§VIII-D)
RQ3 How much of investigator’s time can NODOZE save
when used in an enterprise setting? (§VIII-E)
RQ4 What is the runtime overhead of NODOZE? (§VIII-F)
A. Experiment Setup
We monitored and collected OS-level system events and
threat alerts at NEC Labs America. In total, we monitored
191 hosts (51 Linux and 140 Windows OS) for 5 days which
were used daily for product development, research and admin-
istration at NEC Labs America. During this time span, we also
simulated 50 attacks which include 10 real-world APT attacks
and 40 recent malwares downloaded from VirusTotal [19]. A
short description of each APT attack with generated threat alert
is shown in Table II.
We deployed NODOZE on a server with Intel®Core(TM)
i7-6700 CPU @ 3.40GHz and 32 GB memory running Ubuntu
16.04 OS. We used the baseline TDS [8] to generate threat
alerts. In summary, our experiment contains 400 GB of system
monitoring data with around 1 billion OS-level log events
and 364 threat alerts. The Event Frequency Database in our
experiments was populated using 10 days of OS-level system
events. Note that our evaluation dataset of 364 labeled alert
scenarios was generated after the event frequency database was
populated.
B. Baseline TDS
The baseline TDS we used to generate threat event alerts
is a commercial tool [8]. Details regarding anomaly detection
models used in this tool can be found here [31]. At a very high
level, this TDS applies an embedding based technique to detect
anomalies. It ﬁrst embeds security events as vectors. Then, it
models the likelihood of each event based on the embedding
vectors. Finally, it detects the events with low likelihood as
anomalies.
TABLE II: Real-world attack scenarios with short descriptions and generated threat alerts by underlying TDS.
Attacks
Short Description
WannaCry [18]
Phishing Email [16]
Data Theft [49]
ShellShock [13]
Netcat Backdoor [17]
Cheating Student [51]
Passing the Hash [7]
wget-gcc [67]
passwd-gzip-scp [67]
VPNFilter [20]
Motivating example discussed in §II
A malicious Trojan was downloaded as an Outlook attachment and the enclosed macro was triggered
by Excel to create a fake java.exe, and the malicious java.exe further SQL exploited a vulnerable
server to start cmd.exe in order to create an info-stealer
An attacker downloaded a malicious bash script on the data server and used it to exﬁltrate all the
conﬁdential documents on the server.
An attacker utilized an Apache server to trigger the Shellshock vulnerability in Bash multiple times.
An attack downloaded the netcat utility and used it to open a Backdoor, from which a Persistent
Netcat port scanner was then downloaded and executed using PowerShell
A student downloaded midterm scores from Apache and uploaded a modiﬁed version.
An attack connected to Windows domain Controller using PsExec and run credential dumper (e.g.,
gsecdump.exe).
Malicious source ﬁles were downloaded and then compiled.
An attack stole user account information from passwd ﬁle, compressed it using gzip and transferred
the data to a remote machine
An attacker used known vulnerabilities [13] to penetrate into an IoT device and overwrite system ﬁles
for persistence. It then connected to outside to connect to C2 host and download attack modules.
True Threat Alert
See §II
C. Improvement Over Existing TDS
The ﬁrst research question of our evaluation is how much
NODOZE improves the accuracy of existing TDS [31], [43],
[29], [60] which are based on heuristics and single event
matching rules. To answer this question, we used NODOZE
along with the baseline TDS [8]. In our experiment, we used
the baseline TDS to monitor the system activities of the
enterprise for anomalies and generate threat alerts. We then
manually labeled these alerts as true positives and false posi-
tives and use them as the ground truth to evaluate NODOZE.
Lastly, we used NODOZE to automatically label the alerts and
compared the results with the ground truth.
In our experiments, the baseline TDS generated a total of
364 alerts (50 true alerts and 314 false alarms). The detection
accuracy of NODOZE is measured using true positive rate
(TPR) and false positive rate (FPR). Intuitively, the FPR mea-
sures the total number of false alerts that were categorized as
true attacks by NODOZE. By adjusting the decision threshold
τd, NODOZE can achieve different TPR and FPR as shown in
the ROC graph in Fig. 5. When the threshold is set to detect
100% of true positives, NODOZE has a 16% FPR. In other
words, NODOZE can reduce the number of false alerts of the
baseline TDS by more than 84% while maintaining the same
capability to detect real attacks. Fig. 6 shows the cumulative
distribution function for ranked true and false alerts based
on aggregate anomaly scores. The decision threshold (shown
with red line), when set to 100% of true positives, removes
the large portion of false alerts because the true positives are
substantially ranked higher than false alerts.
D. Accuracy of Capturing Attack Scenarios
To answer RQ2, we used NODOZE to capture the attack
scenarios of 10 APT attacks from their complex provenance
graphs. We evaluate NODOZE on the APT attacks because
we know the precise ground truth dependency graphs of the
attacks. The results are summarized in Table III. The duration
columns represent the time taken in seconds by underlying
provenance tracker to generate a complete dependency graph
and time taken by NODOZE to run its analysis and generate a
concise graph.
Fig. 5: ROC curve for our experiments using NODOZE along with
TDS.
Fig. 6: CDF for ranked true and false alerts based on aggregate
anomaly score.
Our experiment shows that our system accurately extracts
the APT attack scenarios from the complex provenance graphs
generated by the underlying provenance tracker. NODOZE can
reduce the size of the provenance graph by two orders of
magnitude. Such a reduction may substantially reduce the work
load of cyber analyst when investigating the threat alerts and
planning incident responses.
We also measured the completeness of the NODOZE
generated dependency graph for each attack. We measured
completeness in terms of two metrics: control dependency
(CD) and data dependency (DD) (discussed in §V) with their
true positive (TP) and false positive (FP) rates. Intuitively, the
TP means the number of truly attack related edges present
10
0.00.20.40.60.81.0False Positive Rate (FPR)0.00.20.40.60.81.0True Positive Rate (TPR)ROC curve (AUC = 0.95) 0 0.2 0.4 0.6 0.8 1 50 100 150 200 250CDFRankingTrue AlertsFalse AlertsThresholdTABLE III: Comparison of dependency graphs generated by NODOZE against prior tools [26], [41]. Completeness means how much our
graph able to capture the attack dependency graph in terms of CD and DD with their true positive (TP) and false positive (FP) rates.
Attacks
WannaCry
Phishing Email
Data Theft
ShellShock
Netcat Backdoor
Cheating Student
Passing the Hash
wget-gcc
passwd-gzip-scp
VPNFilter
Baseline Prov. Tracker
NODOZE
NODOZE Completeness
Dur.(s)
#Ver.
#Edg.
Size(KB)
Dur.(s)
#Ver.
#Edg.
Size(KB)
CD(TP)
CF(FP)
DD(TP)
DD(FP)
94.0
63.0
73.0
31.0
62.0
50.0
53.0
63.0
68.0
20.0
5948
2095
5364
2794
2914
1217
848
8323
8066
2639
8712
6002
23825
4031
6158
22647
1026
8679
15318
9774
3,320
3,984
2,208
3,776
1,968
784
560
168
5,168
1,000
18.0
10.0
41.0
8.0
14.0
10.0
11.0
9.0