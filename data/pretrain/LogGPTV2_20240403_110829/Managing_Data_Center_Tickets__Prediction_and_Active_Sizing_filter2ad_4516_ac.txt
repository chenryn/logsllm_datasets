3) Inter- v.s. Intra-Resource Models: We compare the ef-
fectiveness of the proposed inter-resource models, i.e., com-
bining CPU and RAM as predictors, against the intra-resource
models, in which CPU and RAM are treated separately. In
Figure 7, we summarize the prediction errors and reduction
in the original demand series. Inter-resource models can not
only reach a lower prediction error but also a higher reduction
in the number of demand series, than intra-CPU and intra-
RAM models. We present the results in box plots. In terms of
average APEs of prediction for CBC(DTW), the inter model
is around 20%(28%), whereas the intra-CPU and intra-RAM
are 21%(26%) and 23%(31%). Again, these results are in
good agreement with our observation in Section II that inter
resource correlation is higher than intra-CPU and intra-RAM
correlations. In terms of the average number series in the
signature set for CBC(DTW), the inter model uses roughly
66%(26%) of the original series, while intra-CPU and intra-
RAM can use up to 81%(41%), 90%(45%) compared with the
original set. Overall, the inter model can greatly beneﬁt from
the correlation across co-located resources.
3APE is deﬁned as AP E =
|Actual−F itting|
Actual
340
IV. VIRTUAL RESOURCE RESIZING
Being able to accurately predict future usage enables the
very ﬁrst step to actively manage usage-related tickets. Having
future usage knowledge, it is possible to develop a virtual
resource resizing policy that can effectively reduce the number
of usage tickets. The monitoring systems in modern data
centers track the resource usages at discrete windows, e.g.,
15 minutes, termed as the ticketing window, and compare
them with ticket
thresholds to determine whether a ticket
needs to be issued or not. To avoid incurring overreaction to
transient loads, we set the resizing window to be greater than
the ticketing window. For the data centers considered here,
ticket resolution occurs within a day of the ticket being issued,
so setting the resizing window to one day is a reasonable
assumption. This implies that the prediction horizon of the
demand series needs to be also one day. Note that past work
has shown that the accuracy of prediction decreases as the
prediction horizon increases [7], so setting the prediction
window to such a high value makes ATM more conservative
than it can actually be. During each resizing window, ATM
devises and actuates the virtual resource allocation of co-
located VMs on boxes. The objective is to ﬁnd optimal sizes
for co-located VMs to achieve the lowest number of tickets,
subject to various resource constraints at boxes. The resources
considered are: virtual CPU measured in GHz and virtual
RAM measured in GB.
There exist a large body of virtual resource allocation
studies aiming to satisfy various performance targets, e.g.,
user response time, system utilization, and fairness. Max-
min fairness [16], [17] is one of the most applied allocation
policies that tries to guarantee the performance of small VMs,
given the assumption of known demands. Our resizing problem
can be viewed similarly but with the objective to minimize
the occurrences of target utilization threshold violations. We
develop a resizing algorithm based on a rigorous optimization
formulation, which is later transformed into a multi-choice
knapsack problem (MCKP) with tunable discretization pa-
rameters. The introduction of such discretization parameters
enables us to reduce the complexity and increase the safety
margin in resource allocation. In contrast to spatial-temporal
prediction models, the resizing algorithm treats CPU and RAM
separately due to separate constraints on each resource. Hence
for simplicity, in the following we redeﬁne the index i in Di
to be the index of a VM rather than the index of a speciﬁc
resource on a VM.
A. Ticket Optimization Formulation
We formally introduce the problem, including notations and
constraints, for resizing all co-located VMs on a single box.
The foremost important constraint is that the summation of
allocated virtual resources should be less than or equal to
i Ci ≤ C, where
the total available virtual resource, i.e.,
Ci denotes the virtual capacity allocated to VM i, and C is
the total available virtual capacity at the box. The decision
variable is Ci and needs to be determined at the beginning of
the resizing horizon.
(cid:2)
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:17:56 UTC from IEEE Xplore.  Restrictions apply. 
The prediction module provides all demand series values
for the entire resizing window, equal to T ticketing windows,
for VM i, Di = {Di,1, . . . Di,T}. We introduce an indicator
variable, Ii,t, when Ii,t = 1 a usage ticket occurs to VM i
at ticketing window t, because the demand exceeds a certain
threshold of the capacity, say, αCi (e.g., α = 0.6); otherwise
Ii,t = 0. We aim to minimize the total number of tickets
occurring on all co-located VMs during the resizing window.
t Ii,t. In
Thus, we can write the objective function as
summary, we can deﬁne the ticketing optimization problem
as:
(cid:2)
(cid:2)
i
(R) min
s.t.
(cid:3)
(cid:3)
i
(cid:3)
Ii,t
Ci ≤ C
t
i
Di,t − αCi ≤ Di,tIi,j
Ii,t ∈ {0, 1}
(4)
(5)
(6)
(7)
Constraint (6) ensures that Ii,t = 1, when the demand
threshold, αCi; otherwise the objective
exceeds the ticket
function drives Ii,t to zero. The problem R is a classical mixed
integer linear programming (MILP), whose complexity greatly
depends on the number of integer variables, i.e., the indicator
variables Ii,t in our case. The number of indicator variables
for each box is thus the product of the number of ticketing
windows, T , and the number of VMs, M.
Lemma 4.1: For VM i,
1) Resizing Algorithm: Instead of resorting to a standard
MILP solvers, such as CPLEX [18], we transform the original
problem into a multi-choice knapsack problem by Lemma 4.1:
the optimal size for each VM must be equal to one of the
demand values in Di or 0. The advantages of transforming
the original problem into a MCKP are twofold: (i) there exist
a large number of efﬁcient algorithms for MCKP and (ii) it
allows for a reduction of the number of integer variables. We
elaborate on the second point after formally introducing the
transformation of the original optimization problem to MCKP.
the optimal size Ci∗ ∈ Di ∪
{0}, Di = {Di,1, Di,2 . . . Di,T}.
Proof: If there exists an optimal solution (Ci∗) for each
VM (i) for the resizing problem, Ci∗ has to be in one of
the three ranges: [0, min{Di}), [min{Di}, max{Di}), and
[max{Di}, +∞). If Ci∗ is less than min{Di}, we argue
that Ci∗ could be set to 0 and the objective function stays
unchanged while the constraints are not violated. Similarly, it
is proven that if Ci∗ is not less than max{Di}, Ci∗ can be set
to max{Di}. If Ci∗ is in [min{Di}, max{Di}), sort Di in a
descend = {O1, O2, ..., Op, Op+1, ...}.
descending order as Di
Following the same reasoning, it is possible to determine that
∃ q, Ci∗ ∈ [Oq, Oq+1). In addition, setting Ci∗ equal to Oq,
the minimum objective function can be obtained without any
constraint violation. Hence the optimal size Ci∗ is either in
Di or 0.
Based on Lemma 4.1, we can transform the original for-
mulation into a multi-choice knapsack problem, whose com-
plexity can be further simpliﬁed by reducing the number of
341
indicator variables. We ﬁrst introduce a reduced demand set
with 0 added, denoted as D(cid:2)
i, containing the unique values
i,v+1 ≤ D(cid:2)
of the original demands in decreasing order, D(cid:2)
i,v.
According to Lemma 4.1, one of them is the optimal capacity.
We note that D(cid:2)
i,v is not the same as Di,t. The following small
example illustrates the difference. Given a speciﬁc demand
series Di = {30, 30, 40, 40, 23, 25, 60, 60, 60, 60}, its reduced
i = {60, 40, 30, 25, 23, 0} containing only the
series is D(cid:2)
unique values plus 0 in descending order.
We introduce a new binary variable Yi,v, denoting that
the unique value D(cid:2)
i,v is chosen to be the capacity for VM
i. The next step to reduce the problem into MCKP is to
deﬁne the number of tickets, denoted Pi,v, seen by VM i
when the value of D(cid:2)
i,v is chosen as capacity, i.e., Yi,v = 1.
Following the previous example of reduced demand set, we
show an example of ticket calculation. Let us assume the
current capacity is 70 and the ticketing threshold for issuing
usage tickets is 60%. We thus know that demands greater
than 70 × 60% = 42 at any ticketing window will result into
tickets. We can then obtain Pi = {0, 4, 6, 8, 9, 10}. Due to
the decreasing order of D(cid:2)
i, Pi has an increasing order, i.e.,
Pi,v+1 ≥ Pi,v. The total number of tickets for a box can thus
v Yi,vPi,v and the resource constraint of
be written as
(cid:2)
the total capacity as
i,v ≤ C.
v Yi,vD(cid:2)
(cid:2)
(cid:2)
(cid:2)
In summary, we reach a multi-choice knapsack problem,
where items (in the original knapsack problem) are divided
into subgroups and exactly one item needs to be selected
from each group. Putting our problem into the context of
multi-choice problem, we have M groups of VM demands
and we need to choose exactly one demand from each group
as their capacity. The decision variables are Yi,v denoting that
a particular demand is chosen as the size for VM i, where
i ∈ [1, M ] and that the number of tickets, Pi,v, can be seen
as “weights”. The transformed ticket reduction problem is:
i
i
(cid:2)) min
(R
s.t.
(cid:3)
(cid:3)
i
(cid:3)
v
(cid:3)
Yi,vPi,v
Yi,vD(cid:2)
i,v ≤ C
i
(cid:3)
v
Yi,v = 1
Yi,v ∈ {0, 1}
v
(8)
(9)
(10)
The formulation of problem R
(11)
(cid:2) enables the introduction
of a tunable parameter, ε, which decides the discretization
of demand values. We illustrate this point using the running
example of original series Di and its reduced series D(cid:2)
i. The
original formulation R has 11 integer variables (including
(cid:2) has only 6
the 0), whereas the transformed problem R
integer variables. One can even further decrease the number
of binary variables in Pi by discretizing the demand values,
such as rounding off the ﬁrst digit. For example using D(cid:2)
i =
{60, 40, 30, 0}, where 23 and 25 are rounded up to 30. Another
point worth mentioning is that we need to update the number
of corresponding tickets too, i.e., Pi = {0, 4, 6, 10}. Rounding
up demands makes the resizing algorithm more aggressive in
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:17:56 UTC from IEEE Xplore.  Restrictions apply. 
allocating resources. Consequently, we formally introduce a
discretization factor, ε, which further reduces the complexity
and provides a safety margin for resource allocation. We note
that ε is only applied on the predicted series. In summary, the
initial step computes D(cid:2)
i from Di using ε, and calculates their
corresponding tickets, Pi for all co-located VMs i.
To solve the MCKP problem, we resort to the so-called
minimal algorithm [19]. We illustrate the general
idea in
the context of our resizing problem. The algorithm chooses
capacity candidates for each VM and shufﬂes around the
capacity across VMs, comparing to the available capacity and
marginal ticket reductions. For all VMs, it chooses capacity
candidates that can incur a minimum number of tickets, i.e.,
starts from the maximum values in D(cid:2)
i. When there is no
sufﬁcient capacity to achieve such allocations for all VMs,
the priority is given to the VM having the lowest marginal
ticket reduction values (MTRV). MTRV represents the addi-
tional ticket increment when reducing one unit of capacity
provisioning. Its formal deﬁnition is:
Pi,o − Pi,o−1
i,o−1 − D(cid:2)
D(cid:2)
i,o
M T RV =
,
(12)
where o denotes the index of candidates in D(cid:2)
i. The VM with
the lowest MTRV is always chosen to reduce the capacity
provision from its current candidate value to the next one in
D(cid:2)
i. Note that as D(cid:2)
i is in decreasing order, the next candidate
immediately implies a capacity reduction. Once the candidate
list is updated, the same process continues until the sum of all
candidates is less or equal to the available capacity.
For a practical implementation, in addition to the constraint
of total available capacity, it is also imperative to consider
the lower and upper bounds of capacity. In order to avoid
spillovers of unﬁnished demands from previous ticketing win-
dows, we impose a lower bound on the VM capacity size, such
that its peak usage before resizing is satisﬁed. Moreover, as
any VM is not able to use more resources than the available
resource amount of the underlying physical box, we introduce
the allocation upper bound based on the box resource capacity.
We can easily incorporate such lower and upper bounds into
our resizing algorithm by limiting the values in D(cid:2)
i for each
VM i.
B. Results on Usage Ticket Reduction
Prior to moving on to the evaluation of the full-ﬂedged
ATM, i.e., the combination of spatial-temporal prediction and
resizing policy, we ﬁrst show how effective the proposed resiz-
ing algorithm is against existing resource allocation heuristics.
For a fair comparison, the demand inputs are based on the
original dataset described in Section II, instead of prediction.
We implement the max-min fairness algorithm [16] and a
“stingy” algorithm which only allocates the capacity according
to the lower bound, i.e., the maximum demand regardless of
the ticket threshold, often used in practice. In contrast, the
max-min algorithm starts to allocate to all VMs the demand
of the smallest VM, considering its ticket
threshold, and
342
)
%
(
s
t
e
k
c
T
n
i
i
n
o
i
t
c
u
d
e
R
100
80
60
40
20
0
-20
-40
-60
-80
-100
ATM w/o Discretizing
ATM w/ Discretizing
Stingy Algorithm
Max-min Fainess Algorithm
CPU
RAM
Fig. 8: Ticket reduction for CPU and RAM: comparing ATM,
max-min fairness, and stingy algorithms.
continues onto VMs in the increasing order of their demands
until all capacity is exhausted.
Here, we evaluate the data of April 3, 2015 across all
6K boxes and set the threshold to trigger usage tickets to
60%: i.e., every 15-minute ticketing window the monitoring
system checks if the average usage of CPU or RAM of each
VM exceeds the 60% of the allocated capacity. Figure 8
summarizes the mean ticket reduction (in percent) and its
standard deviation, when applying the proposed ATM resizing,
max-min fairness, and stingy algorithms. As expected, the
stingy algorithm is completely unaware of the ticket threshold.
On average it achieves a ticket reduction of 54% and 15%
for CPU and RAM, respectively. Max-min fairness reduces
the tickets by around 70% for both CPU and RAM. This
is still roughly 30% worse than the ATM resizing results.
Due to the nature of favoring small VMs, large VMs can
be severely punished under max-min fairness resulting in no
ticket reduction and explains the high standard deviation under
max-min fairness.
As a pleasant surprise, our resizing algorithm does excep-
tionally well. It achieves 95% and 96% usage ticket reductions
for CPU and RAM, respectively, a remarkable improvement
for both performance and cost. This is also attributed to
the fact that the systems of the original traces are equipped
with abundant resources, i.e., typically data centers are lowly
utilized [5]. By simply shufﬂing resources across co-located
VMs, we are able to achieve signiﬁcant performance gain.
Moreover, we also eliminate the overhead of inspecting and
resolving a large number of usage tickets, a process that is
known to be expensive.
C. Actuation of Virtual Capacity
Cloud data center tenants are typically charged by the
amount of virtual resources, for example, the number of virtual
cores. Consequently, any practical sizing policy should adhere
to such a constraint, due to accounting and ﬁnancial concerns.
Therefore, to enforce the virtual capacity limits decided in our
algorithm, we use the control groups (cgroups) feature of the
Linux kernel [20]. Cgroups allow to limit, account for, and
isolate resources usages of groups of processes. By placing
the processes and threads relating to each VM in a separate
cgroup, we can dynamically change the resource usage limits
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:17:56 UTC from IEEE Xplore.  Restrictions apply. 
for each VM. To simplify the cgroups conﬁguration, we expose
the resource limits through a web-based API by running a
small daemon at each hypervisor. The advantage of cgroups
over directly modifying the allocated virtual VM resources is
that the latter typically requires a restart of the guest OS while
the former can be changed on-the-ﬂy without disrupting the
VM operation. Moreover, cgroups offer a ﬁner-grained CPU