[706] write B:/etc/shadow+
[706] link B:/etc/shadow+ to B:/etc/shadow
[706] unlink B:/etc/shadow+
A similar backdoor technique is to open a port which listens for
connections and provides the attacker with a remote shell. This ap-
proach is used by many pieces of malware, including the Plupii
and Millen worms. Our experiment shows that the provenance
record includes the shell’s network communication as well as the
attacker’s activity:
[744] exec B:/bin/bash -i
[744] socksend B:173
[744] sockrecv unknown
[744] socksend B:173
[751] exec B:/bin/cat /etc/shadow
[751] read B:/etc/shadow
[751] socksend B:173
[744] socksend B:173
[744] sockrecv unknown
[744] socksend B:173
[744] link (new) to B:/testfile
[744] write B:/testfile
Here, the attacker uses the remote shell to view /etc/shadow and
to write a new ﬁle in the root directory. Since the attacker’s sys-
tem is unlikely to be running a trusted instance of Hi-Fi, we see
“unknown” socket entries, which indicate data received from an
unprovenanced host. Remote shells can also be implemented as
“reverse shells,” which connect from the infected host back to the
attacker. Our tests on a reverse shell, such as the one in the Jac.8759
virus, show results identical to a normal shell.
6.1.3 Exﬁltration
Another common payload activity is data exﬁltration, where the
malware reads information from a ﬁle containing password hashes,
credit card numbers, or other sensitive information and sends this
information to the attacker. Our simulation for this behavior reads
the /etc/shadow ﬁle and forwards it in one of two ways. In the
ﬁrst test, we upload the ﬁle to a web server using HTTP, and in the
second, we write it directly to a remote port. Both methods result
in the same log entries:
266[85f] read B:/etc/shadow
[85f] socksend B:1ae
Emailing the information to the attacker, as is done by the Adore
worm, would create a similar record.
6.1.4
Spread
Our experiment also models three different mechanisms used by
malware to spread to newly infected hosts. The ﬁrst and simplest is
used when the entire payload can be sent using the initial exploit.
In this case, there does not need to be a separate dropper, and the
resulting provenance log is the following (indentation is used to
distinguish the two hosts):
[807] read A:/home/evil/payload
[807] socksend A:153
[684] sockrecv A:153
[684] write B:/tmp/payload
The payload is then executed, and the malicious behavior it imple-
ments appears in subsequent log entries.
Another mechanism, used by the Plupii and Sorso worms, is to
fetch the payload from a remote web server. We assume the web
server is unprovenanced, so the log once again contains “unknown”
entries:
[7ff] read A:/home/evil/dropper
[7ff] socksend A:15b
[685] sockrecv A:15b
[685] write B:/tmp/dropper
[6ef] socksend B:149
[6ef] sockrecv unknown
[6ef] write B:/tmp/payload
If the web server were a provenanced host, this log would con-
tain host and socket IDs in the sockrecv entry corresponding to a
socksend on the server.
Finally, to illustrate the spread of malware across several hosts,
we tested a “relay” dropper which uses a randomly-chosen port
to transfer the payload from each infected host to the next. The
combined log of our three hosts shows this process:
[83f] read A:/home/evil/dropper
[83f] socksend A:159
[691] sockrecv A:159
[691] write B:/tmp/dropper
[6f5] exec B:/tmp/dropper
[844] read A:/home/evil/payload
[844] socksend A:15b
[6fc] sockrecv A:15b
[6fc] write B:/tmp/payload
[74e] read B:/tmp/dropper
[74e] socksend B:169
[682] sockrecv B:169
[682] write C:/tmp/dropper
[6e6] exec C:/tmp/dropper
[750] read B:/tmp/payload
[750] socksend B:16b
[6ed] sockrecv B:16b
[6ed] write C:/tmp/payload
Here we can see the attacker transferring both the dropper and the
payload to the ﬁrst victim using two different sockets. This victim
then sends the dropper and the payload to the next host in the same
fashion.
6.1.5 Full Simulation
For a comprehensive test, we use our tool to implement a full
simulation of the Linux Adore worm according to Symantec’s de-
scription. Our provenance record captures the entire life cycle of
the worm:
System call Baseline With Hi-Fi Overhead
open
close
read
write
creat
rename
unlink
clone
execve
13.8
10.6
13.7
21.4
24.1
19.8
36.4
74.6
150.3
13.8
10.7
14.6
21.3
24.4
20.0
36.7
74.0
155.1
0.0%
1.0%
6.2%
-0.2%
1.1%
0.9%
0.7%
-0.7%
3.2%
Table 2: Mean execution time for system calls (μs)
• The compromised daemon downloading and extracting the
payload tarball
• Execution of start.sh, which activates the payload
• Replacement of the ps binary with a trojaned version, and
copying the original ps to /usr/bin/adore
• Installation of a cron job which kills the worm
• Replacement of klogd with a backdoor shell
• Emailing of the /etc/shadow ﬁle, process list, and network
information to the attacker
• Infection of the next victim
We also successfully capture a sample backdoor session, in which
the attacker views a user’s command-line history and downloads an
updated payload.
6.2 Performance
In addition to showing that Hi-Fi records malicious activity, we
also wish to show that it does so without signiﬁcantly degrading
system performance. To this end, we benchmark a system running
a stock Arch Linux kernel (version 3.2.13), then benchmark the
same system with Hi-Fi compiled in. Our test system has two 2.30-
GHz quad-core AMD Opteron processors, 16GB of RAM, and two
73GB hard disks in a RAID 0 array.
We ﬁrst evaluate performance overhead at the system-call level
using microbenchmarks. LMbench is frequently used for Linux
microbenchmarks, but our initial results from this tool were incon-
sistent. Instead, we create a small program which exercises the ma-
jor ﬁle and process operations. We then use the strace utility to
measure the time spent in various system calls over a large number
of executions of this program. The results of these benchmarks are
summarized in Table 2. For the system calls measured, the over-
head is at most 6.2%, with most calls within 1% of the baseline.
To demonstrate the overall impact on system performance, we
also run two macrobenchmarks customarily used in provenance
system evaluation: a Linux kernel build, which evaluates a typical
combination of process execution and ﬁle manipulation; and Post-
Mark [11], which speciﬁcally stresses ﬁlesystem and disk trans-
actions. We generate statistics from multiple executions of each
benchmark using the Phoronix Test Suite utility [17]. With an un-
modiﬁed kernel, our test system takes an average of 107 seconds
to run the kernel-build benchmark. With Hi-Fi, this increases to
110 seconds, showing an overhead of only 2.8%. Performance on
disk-heavy operations is unchanged, as PostMark achieves 2,083
transactions per second in both cases.
2677. CONCLUSION
We have presented Hi-Fi, a system which applies the reference
monitor concept to collect a high-ﬁdelity provenance record suit-
able for security applications. We show that this record can be
used to observe the behavior of malware, not only within a single
host, but also across multiple provenanced hosts. Furthermore, we
demonstrate that our implementation imposes less than 3% over-
head on representative workloads and a similarly small overhead in
system-call microbenchmarks.
We believe that Hi-Fi will provide a solid platform for future
provenance research. For example, we do not explore options for
working with provenance data after it is collected, but the modu-
lar design of Hi-Fi will make it simple to evaluate many different
approaches to processing, storage, and querying. We have shown
that complete system-level and socket provenance can provide deep
insight into the design, performance, and security of systems and
networks, and we believe that many other signiﬁcant discoveries
are yet to be made in this area.
Acknowledgements
This work is supported by the National Science Foundation under
awards HECURA-0937944 and CNS-1118046.
8. REFERENCES
[1] J. P. Anderson. Computer security technology planning
study. Technical Report ESD-TR-73-51, AFSC, Hanscom
AFB, Bedford, MA, Oct. 1972. AD-758 206, ESD/AFSC.
[2] U. Braun, S. Garﬁnkel, D. Holland, K. Muniswamy-Reddy,
and M. Seltzer. Issues in automatic provenance collection. In
Proceedings of the 2006 International Provenance and
Annotation Workshop, pages 171–183, 2006.
[3] A. Edwards, T. Jaeger, and X. Zhang. Runtime veriﬁcation of
authorization hook placement for the Linux Security
Modules framework. In V. Atluri, editor, ACM Conference
on Computer and Communications Security, pages 225–234.
ACM, 2002.
[4] Filesystem in userspace. http://fuse.sourceforge.net.
[5] V. Ganapathy, T. Jaeger, and S. Jha. Automatic placement of
authorization hooks in the Linux Security Modules
framework. In V. Atluri, C. Meadows, and A. Juels, editors,
ACM Conference on Computer and Communications
Security, pages 330–339. ACM, 2005.
[6] D. Garg, L. Jia, and A. Datta. Policy auditing over
incomplete logs: theory, implementation and applications. In
Proceedings of the 18th ACM conference on Computer and
Communications Security, CCS ’11, pages 151–162, New
York, NY, USA, 2011. ACM.
[7] A. Goel, K. Farhadi, K. Po, and W.-c. Feng. Reconstructing
system state for intrusion analysis. SIGOPS Oper. Syst. Rev.,
42(3):21–28, Apr. 2008.
[8] A. Goel, W.-C. Feng, D. Maier, and J. Walpole. Forensix: a
robust, high-performance reconstruction system. In
Distributed Computing Systems Workshops, 2005. 25th IEEE
International Conference on, pages 155–162, june 2005.
[9] R. Ikeda and J. Widom. Panda: A system for provenance and
data. IEEE Data Engineering Bulletin, September 2010.
[10] S. N. Jones, C. R. Strong, D. D. Long, and E. L. Miller.
Tracking emigrant data via transient provenance. In Third
Workshop on the Theory and Practice of Provenance.
USENIX, June 2011.
[11] J. Katcher. Postmark: a new ﬁle system benchmark. Network
Appliance Tech Report TR3022, Oct. 1997.
[12] L. Lamport. Time, clocks, and the ordering of events in a
distributed system. Communications of the ACM,
21(7):558–565, July 1978.
[13] Metasploit Project. http://www.metasploit.com.
[14] L. Moreau, B. Clifford, J. Freire, J. Futrelle, Y. Gil, P. T.
Groth, N. Kwasnikowska, S. Miles, P. Missier, J. Myers,
B. Plale, Y. Simmhan, E. G. Stephan, and J. V. den Bussche.
The Open Provenance Model core speciﬁcation (v1.1).
Future Generation Comp. Syst., 27(6):743–756, 2011.
[15] K. Muniswamy-Reddy, J. Barillari, U. Braun, D. Holland,
D. Maclean, M. Seltzer, and S. Holland. Layering in
provenance-aware storage systems. In Proceedings of the
2009 USENIX Annual Technical Conference, San Diego, CA,
2009.
[16] K. Muniswamy-Reddy and D. Holland. Causality-based
versioning. ACM Transactions on Storage (TOS), 5(4):13,
2009.
[17] Phoronix Test Suite. http://phoronix-test-suite.com.
[18] C. F. Reilly and J. F. Naughton. Transparently gathering
provenance with provenance aware Condor. In First
workshop on theory and practice of provenance, TAPP’09,
pages 13:1–13:10, Berkeley, CA, USA, 2009. USENIX
Association.
[19] C. Sar and P. Cao. Lineage ﬁle system. Online at
http://crypto.stanford.edu/cao/lineage.html, 2005.
[20] R. Sion. Strong worm. In Proceedings of the 2008 The 28th
International Conference on Distributed Computing Systems,
2008.
[21] R. P. Spillane, R. Sears, C. Yalamanchili, S. Gaikwad,
M. Chinni, and E. Zadok. Story Book: An efﬁcient extensible
provenance framework. In J. Cheney, editor, Workshop on
the Theory and Practice of Provenance. USENIX, 2009.
[22] S. Sundararaman, G. Sivathanu, and E. Zadok. Selective
versioning in a secure disk system. In Proceedings of the
17th conference on Security symposium, 2008.
[23] Symantec Security Response.
http://www.symantec.com/security_response.
[24] L. Tan, X. Zhang, X. Ma, W. Xiong, and Y. Zhou. AutoISES:
Automatically inferring security speciﬁcation and detecting
violations. In P. C. van Oorschot, editor, USENIX Security
Symposium, pages 379–394. USENIX Association, July
2008.
[25] J. Widom. Trio: A system for integrated management of
data, accuracy, and lineage. In CIDR, pages 262–276, 2005.
[26] C. Wright, C. Cowan, S. Smalley, J. Morris, and
G. Kroah-Hartman. Linux Security Modules: General
security support for the Linux kernel. In USENIX, editor,
Proceedings of the 11th USENIX Security Symposium 2002,
August 5–9, 2002, San Francisco, CA, pages 17–31.
USENIX, 2002.
[27] T. Zanussi, K. Yaghmour, R. Wisniewski, R. Moore, and
M. Dagenais. relayfs: An efﬁcient uniﬁed approach for
transmitting data from kernel to user space. In Proceedings
of the 2003 Linux Symposium, Ottawa, ON, Canada, pages
494–506, July 2003.
[28] X. Zhang, A. Edwards, and T. Jaeger. Using CQUAL for
static analysis of authorization hook placement. In D. Boneh,
editor, USENIX Security Symposium, pages 33–48. USENIX,
2002.
268