title:How Resilient are Distributed f Fault/Intrusion-Tolerant Systems?
author:Paulo Sousa and
Nuno Ferreira Neves and
Paulo Ver&apos;ıssimo
How Resilient are Distributed f Fault/Intrusion-Tolerant Systems?∗
Paulo Sousa, Nuno Ferreira Neves and Paulo Ver´ıssimo
University of Lisboa, Portugal
{pjsousa, nuno, pjv}@di.fc.ul.pt
Abstract
Fault-tolerant protocols, asynchronous and synchronous
alike, make stationary fault assumptions: only a fraction f
of the total n nodes may fail. Whilst a synchronous proto-
col is expected to have a bounded execution time, an asyn-
chronous one may execute for an arbitrary amount of time,
possibly sufﬁcient for f + 1 nodes to fail. This can com-
promise the safety of the protocol and ultimately the safety
of the system. Recent papers propose asynchronous proto-
cols that can tolerate any number of faults over the lifetime
of the system, provided that at most f nodes become faulty
during a given interval. This is achieved through the so-
called proactive recovery, which consists of periodically re-
juvenating the system. Proactive recovery in asynchronous
systems, though a major breakthrough, has some limita-
tions which had not been identiﬁed before. In this paper,
we introduce a system model expressive enough to repre-
sent these problems which remained in oblivion with the
classical models. We introduce the predicate exhaustion-
safe, meaning freedom from exhaustion-failures. Based on
it, we predict the extent to which fault/intrusion-tolerant
distributed systems (synchronous and asynchronous) can
be made to work correctly. Namely, our model predicts
the impossibility of guaranteeing correct behavior of asyn-
chronous proactive recovery systems as exist today. To
prove our point, we give an example of how these problems
impact an existing fault/intrusion-tolerant distributed sys-
tem, the CODEX system, and having identiﬁed the problem,
we suggest one (certainly not the only) way to tackle it.
1 Introduction
Nowadays, and more than ever before, system de-
pendability is an important subject because computers are
pervading our lives and environment, creating an ever-
increasing dependence on their correct operation. All else
∗This work was partially supported by the FCT, through the Large-
Scale Informatic Systems Laboratory (LaSIGE).
being equal, the dependability or trustworthiness of a sys-
tem is inversely proportional to the number and strength
of the assumptions made about the environment where the
former executes. This applies to any type of assumptions,
namely timing and fault assumptions.
Synchronous
timing
systems make
assumptions,
if a
whereas asynchronous ones do not. For instance,
protocol assumes the timely delivery of messages by the
environment, then its correctness can be compromised by
overload or unexpected delays. These are timing faults, that
is, violations of those assumptions. The absence of timing
assumptions about the operating environment renders the
system immune to timing faults.
In reality, timing faults
do not exist in an asynchronous system, and this reduction
in the fault space makes the former potentially more trust-
worthy. For this reason, a large number of researchers have
concentrated their efforts in designing and implementing
systems under the asynchronous model.
Fault assumptions are the postulates underlying the de-
the type(s) of faults, and
sign of fault-tolerant systems:
their number (f). The type of faults inﬂuences the archi-
tectural and algorithmic aspects of the design, and there are
known classiﬁcations deﬁning different degrees of severity
in distributed systems, according to the way an interaction
is affected (e.g., crash, omission, byzantine, etc.), or to the
way a fault is produced (e.g., accidental or malicious, like
vulnerability, attack, intrusion, etc.). The number estab-
lishes, in abstract, a notion of resilience (to f faults occur-
ring). As such, current fault-tolerant system models feature
a set of synchrony assumptions (or the absence thereof), and
pairs (cid:2)type, number(cid:3) of fault assumptions (e.g., f omission
faults; f compromised/failed hosts).
However, a fundamental goal when conceiving a depend-
able system is to guarantee that during system execution the
actual number of faults never exceeds the maximum num-
ber f of tolerated ones. In practical terms, one would like
to anticipate the maximum number of faults bound to occur
during the system execution, call it Nf , so that it is designed
to tolerate f ≥ Nf faults. As we will show, the difﬁculty
of achieving this objective varies not only with the type of
faults but also with the synchrony assumptions. Moreover,
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:09:59 UTC from IEEE Xplore.  Restrictions apply. 
the system models in current use obscure part of these difﬁ-
culties, because they are not expressive enough.
Before delving into the formal embodiment of our the-
ory, we give the intuition of the problem. Consider a sys-
tem where only accidental faults are assumed to exist. If it
is synchronous, then one can bound its execution. In conse-
quence, one can forecast the maximum possible number of
accidents (faults) that can occur during the bounded execu-
tion time, say Nf . That is, given an abstract f fault-tolerant
design, there is a justiﬁable expectation that, in a real sys-
tem based on it, the maximum number of tolerated faults is
never exceeded. This can be done by providing the system
with enough redundancy to meet f ≥ Nf
1. If the system
is asynchronous, then its execution time has not a known
bound – it can have an arbitrary ﬁnite value. Then, given
an abstract f fault-tolerant design, it becomes mathemati-
cally infeasible to justify the expectation that the maximum
number of tolerated faults is never exceeded, since the max-
imum possible number of faults that can occur during the
unbounded execution time is also unbounded. One can at
best work under a partially-synchronous framework where
an execution time bound can be predicted with some high
probability, and forecast the maximum possible number of
faults that can occur during that estimated execution time.
Consider now a system where arbitrary faults of mali-
cious nature can happen. One of the biggest differences
between malicious and accidental faults is related with their
probability distribution. Although one can calculate with
great accuracy the probability of accidents happening, the
same calculation is much more complex and/or less accu-
rate for intentional actions perpetrated by malicious intelli-
gence. In the case of a synchronous system with bounded
execution time,
the same strategy applied to accidental
faults can be followed here, except that: care must be taken
to ensure an adequate coverage of the estimation of the
number of faults during the execution time. If the system
is asynchronous, the already difﬁcult problem of prediction
of the distribution of malicious faults is ampliﬁed by the ab-
sence of an execution time bound, which again, renders the
problem unsolvable, in theory.
An intuition about these problems motivated the ground-
breaking research of recent years around proactive recovery
which made possible the appearance of asynchronous pro-
tocols and systems [3, 20, 2, 13] that allegedly can tolerate
any number of faults over the lifetime of the system, pro-
vided that fewer than a subset of the nodes become faulty
within a supposedly bounded small window of vulnerabil-
ity. This is achieved through the use of proactive recovery
protocols that regularly rejuvenate the system.
However, having presented our conjecture that the prob-
1Just for the sake of example: in an algorithm design where f = N−1
3 ,
for N processes, then in the system design, given Nf , N would have to be
N ≥ 3Nf + 1.
lem of guaranteeing that the actual number of faults in a
system never exceeds the maximum number f of toler-
ated ones, has a certain hardness for synchronous systems
subjected to malicious faults, and is unsolvable for asyn-
chronous systems, we may ask: How would this be possible
with ‘asynchronous’ proactive recovery?
This is what we are going to discuss in the remainder of
the paper. Firstly, in Section 2, we recall a concept well-
known in classical fault-tolerant hardware design, spare ex-
haustion, and generalize it to resource exhaustion, the situ-
ation when a system no longer has the necessary resources
to execute correctly (computing power, bandwidth, repli-
cas, etc.). We propose to augment system models with the
notion of the evolution of environmental resources along
the timeline of system execution. Furthermore, we intro-
duce the predicate exhaustion-safe, meaning freedom from
exhaustion-failures. Based on it,
in Section 3, we in-
troduce precise criteria to describe the resilience of fault
and/or intrusion-tolerant distributed systems under diverse
synchrony assumptions, and we discuss the extent to which
systems (synchronous and asynchronous) can be made to
work correctly.
Our ﬁndings reveal problems that remained in oblivion
with the classical models, leading to potentially incorrect
behavior of systems otherwise apparently correct. Proac-
tive recovery, though a major breakthrough, has some lim-
itations when used in the context of asynchronous systems.
Namely, some proactive recovery protocols depend on hid-
den timing assumptions which are not represented in the
models used.
In fact, our model predicts the impossibil-
ity of guaranteeing correct behavior of asynchronous proac-
tive recovery systems as exist today. To prove our point, in
Section 4, we give an example of how these problems im-
pact an existing fault/intrusion-tolerant distributed system,
the CODEX system, and having identiﬁed the problem, we
suggest one (certainly not the only) way to tackle it. Sec-
tion 5 concludes the paper and presents future work.
2 Physical System Model
2.1 Additional insight into system correctness
Distributed systems are usually dependent on a set of
protocols. Protocol correctness is thus vital to guarantee
system correctness. The process of building correct proto-
cols is composed by many steps, from the algorithmic spec-
iﬁcation until its implementation and testing. We highlight
the following:
1. assessing, at algorithm design time, if the algorithm
underpinning the protocol is correct in an abstract
computational system;
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:09:59 UTC from IEEE Xplore.  Restrictions apply. 
2. assessing, at system design time, if the protocol will
execute correctly in a concrete computational system;
2.2 The model
3. assessing, at implementation time, if the protocol is
correctly implemented and then verifying at run time,
if the protocol executes according to its speciﬁcation.
This paper is a contribution to steps 1 and 2. Typically, a
computational system is deﬁned by a set of assumptions re-
garding aspects like the processing power, the type of faults
that can happen, the synchrony of the execution, etc. These
assumptions are in fact an abstraction of the actual resources
the protocol needs to work correctly (e.g., when a protocol
assumes that messages are delivered within a known bound,
it is in fact assuming that the network will have certain char-
acteristics such as bandwidth and latency). The violation of
these resource assumptions may affect the safety or live-
ness of the protocols and hence of the system. We propose
to augment system models with the notion of the evolution
of environmental resources along the timeline of system ex-
ecution and its consequent impact on system assumptions.
In this paper we are precisely concerned with the event
of ‘violation of any of the resource assumptions’, which
we call resource exhaustion, and on the conditions for its
avoidance. We start by giving a name to failures caused by
resource exhaustion.
Deﬁnition 2.1. An exhaustion-failure is a failure that re-
sults from accidental or provoked resource exhaustion.
Our goal is to prevent exhaustion-failures from happen-
ing. Therefore, we deﬁne exhaustion-safety in the following
manner.
Deﬁnition 2.2. Exhaustion-safety is the ability of a system
to ensure that exhaustion-failures do not happen.
Consequently, an exhaustion-safe system is deﬁned in
the following way.
Deﬁnition 2.3. A system is said to be exhaustion-safe if it
satisﬁes the exhaustion-safety property.
We argue that a system, namely a distributed system, in
order to be dependable, has to satisfy the exhaustion-safety
property. In other words, a dependable distributed system
must be exhaustion-safe.
In the remainder of the paper, we are going to assess
how an f fault/intrusion-tolerant distributed system be-
haves with regard to exhaustion-safety, for different combi-
nations of synchronous/asynchronous timing and acciden-
tal/malicious faults. We will consider schemes where the
system starts with a number of components, and continues
to provide correct responses as long as sufﬁcient compo-
nents exist.
Our main goal
is to formally reason about how
exhaustion-safety may be affected by different combina-
tions of timing and fault assumptions. So, we need to con-
ceive a model in which exhaustion-safety can be formally
deﬁned. This model has to take in account the relevant sys-
tem resources and their evolution with time. For this reason,
and short of a better name, we called it a Physical System
Model (P SM, for short).
Our model considers systems that have a certain mission.
Thus, the execution of this type of systems is composed
of various processing steps needed for fulﬁlling the system
mission (e.g., protocol executions). We deﬁne three events
regarding the system execution: start, termination and ex-
haustion. Only the start event is mandatory to happen: we
cannot talk of a system execution if the system does not
start executing. The termination and exhaustion events may
or may not happen. More importantly, the causal relation
between them is crucial to assess system exhaustion-safety.
We now formally deﬁne P SM.
Deﬁnition 2.4. Let A be a system. An A execution is de-
ﬁned by a triple:
A = (cid:2)Atstart