indicators are
the domain is
d(v(cid:96)) (cid:55)→ 0
d(v7) (cid:55)→ 1,
(for 1 ≤ (cid:96) ≤ 6)
d(v8) (cid:55)→ 1.
The assignments to the embedding indicators for F (a)
are
f1(v7, zjReceiver) (cid:55)→ 1, f1(v8, zjService) (cid:55)→ 1
f1(v7, w) (cid:55)→ 0
f1(v8, w) (cid:55)→ 0
f1(v(cid:96), w) (cid:55)→ 0
(for w (cid:54)= zjReceiver)
(for w (cid:54)= zjService)
(for 1 ≤ (cid:96) ≤ 6 and w ∈ V1)
1
The assignments to the control-ﬂow indicators are
x0(v7, v8) (cid:55)→ 1, x0(v(cid:96), v(cid:96)(cid:48)) (cid:55)→ 0 (for ((cid:96), (cid:96)(cid:48)) (cid:54)= (7, 8)).
1
If instead the candidate embedding of the signature S1 into
(also described in Example 2), then
the sample G1 were F (b)
the assignments to the embedding indicators would become
f1(v8, GameAct) (cid:55)→ 1
f1(v7, zjReceiver) (cid:55)→ 1,
f1(v7, w) (cid:55)→ 0
f1(v8, w) (cid:55)→ 0
f1(v(cid:96), w) (cid:55)→ 0
(for w (cid:54)= zjReceiver)
(for w (cid:54)= GameAct)
(for 1 ≤ (cid:96) ≤ 6 and w ∈ V1),
and assignments to the remaining free variables would be
unchanged.
B. Encoding of Common Subgraph
We now describe how to encode the requirement
that
(V0, X0, Y0) should be a common subgraph of all the samples.
Recall from earlier that the common subgraph requirement
corresponds to our hard constraints.
• Constant domain. For every v ∈ V , the domain of Fi is
(cid:40)
the same for each i:(cid:94)
(cid:41)
(cid:95)
w∈Vi
d(v) =
fi(v, w)
i
Here, the conjunction over i states that d(v) should be
assigned to true if v is in the domain of the embedding
Fi. Therefore, this constraint ensures that each v is either
in the domain of Fi for every i, or not in the domain of
Fi for any i.
• Function property. For every v ∈ V and w, w(cid:48) ∈ Vi
where w (cid:54)= w(cid:48), Fi cannot map v to both w and w(cid:48).
(¬fi(v, w)) ∨ (¬fi(v, w(cid:48))).
• One-to-one. For every v, v(cid:48) ∈ V where v (cid:54)= v(cid:48) and w ∈
Vi:
(¬fi(v, w)) ∨ (¬fi(v(cid:48), w)).
• Type preserving. For every v ∈ V , w ∈ Vi, and r ∈ T ,
we have:
fi(v, w) ⇒ (t0(v, r) = ti(w, r)).
• Control-ﬂow preserving. For every v, v(cid:48) ∈ V and
fi(v, w) ∧ fi(v(cid:48), w(cid:48)) ∧ x0(v, v(cid:48)) ⇒ xi(w, w(cid:48)).
• Metadata preserving. For every v, v(cid:48) ∈ V and d ∈ D,
w, w(cid:48) ∈ Vi:
we have:
fi(v, w) ∧ fi(v, w(cid:48)) ∧ y0(v, v(cid:48), d) ⇒ yi(w, w(cid:48), d).
• No spurious control-ﬂow. For every v, v(cid:48) ∈ V , the edges
X0 are a subset of V0 × V0:
x0(v, v(cid:48)) ⇒ d(v), x0(v, v(cid:48)) ⇒ d(v(cid:48))
• No spurious metadata. For every v, v(cid:48) ∈ V and d ∈ D,
the metadata Y0 are a subset of V0 × V0 × D:
y0(v, v(cid:48), d) ⇒ d(v), y0(v, v(cid:48), d) ⇒ d(v(cid:48))
Example 5: Consider the ICCGs for the samples G1 and
G2 from the GoldDream family shown in Figure 1, along with
the candidate signature S1. In Example 4 we described the
constants in our MaxSAT encoding of the signature synthesis
problem, as well as the assignments to free variables corre-
sponding to the candidate signature S1 together with candidate
embeddings F (a)
and either F (a)
or F (b)
1 .
1
2
1
Recall that F (a)
satisﬁes the properties described in Sec-
tion IV (as does F (a)
), whereas F (b)
is neither type preserving
nor edge preserving. In particular, the candidate embedding
F (b)
has corresponding free variable assignments
1
2
1
x0(v7, v8) (cid:55)→ 1, f1(v7, zjReceiver) (cid:55)→ 1,
f1(v8, GameAct) (cid:55)→ 1.
These assignments violate the type preservation constraint
f1(v8, GameAct)
⇒ (t0(v8, activity) = t1(GameAct, activity))
because one of these subterms t0(v8, activity) = 0 but
t1(GameAct, activity) = 1, so F (b)
does not satisfy the
type preservation constraints. In addition, these assignments
violate the control-ﬂow preservation constraint
1
f1(v7, zjReceiver) ∧ f1(v8, GameAct) ∧ x0(v7, v8)
⇒ x1(zjReceiver, GameAct)
since the constant x1(zjReceiver, GameAct) = 0, so F (b)
is not control-ﬂow preserving.
1
On the other hand, it is not difﬁcult to verify that the
candidate signature S1 together with the candidate embeddings
F (a)
correspond to an assignment that satisﬁes the
constraints described above.
and F (a)
1
2
C. Encoding of Maximally Suspicious
cious requirement, which is that
(V0, X0, Y0) has a maximal suspiciousness |X0| +(cid:80)
Now, we describe how to encode the maximally suspi-
the synthesized signature
wy,
where the weight wy indicates the relative importance of
metadata edge y (as described in Section V). In particular,
we maximize the objective
x0(v, v(cid:48)) +
w(v,v(cid:48),d)y0(v, v(cid:48), d).
(cid:88)
(cid:88)
(cid:88)
O =
y∈Y0
v,v(cid:48)∈V
v,v(cid:48)∈V
d∈D
To choose the weights wy, we use the frequency of the
metadata in benign samples to assign weights to different kinds
of metadata. In particular, we deﬁne wy to be:
wy =
#{benign apps} + 1
#{benign apps containing y} + 1
In other words, wy is the inverse frequency with which
metadata edge y occurs in benign samples, computed on a
large corpus of benign apps (we add one to avoid division
by zero). The intuition is that metadata edges in the malware
samples that rarely occur in benign apps are more likely to
correspond to malicious behaviors.
However, some kinds of behaviors in Y0 are strictly more
dangerous than others. In particular, according to previous
literature [3, 7], suspicious intent ﬁlters are far more likely
to indicate malicious behavior than API calls, which are in
turn much more suspect than data-ﬂows:
intent ﬁlters > API calls > data-ﬂows.
Rather than simply optimizing the weighted sum, we ﬁrst
prefer signatures that have the highest weighted sum restricted
to intent ﬁlters, regardless of other metadata. Ties are broken
by the weighted sum restricted to suspicious API calls, and
further ties are broken by the weighted sum restricted to data-
ﬂows. The number of edges in X0 is considered last, since it is
already indirectly optimized by the other objectives. To incor-
porate this strict ordering on different kinds of metadata, we
group the sums in the objective according to the different kinds
of metadata and then encode the objective as a lexicographical
optimization problem in the MaxSAT solver [18].
VII. APPROXIMATE SIGNATURE MATCHING
In addition to making semantic malware detection fully
automatic, another beneﬁt of our signature inference algorithm
is that it enables approximate signature matching. Suppose we
are given an app A, and we want to determine if A is an
instance of malware family F. Even if A does not exactly
match F’s signature, we might want to determine if A exhibits
a high degree of similarity with other instances of F. This
problem, which we refer to as approximate matching, is useful
both for detecting zero-day malware and also for mitigating
behavioral obfuscation. This section explains how we leverage
signature inference for approximate signature matching.
To perform approximate matching between an app A and
a malware family F with signature SF , we ﬁrst assume that A
and SF belong to the same malware family. We then compute
a new signature S that captures the common behavior of A
and all instances of F. If SF and S are “similar” (see below),
there is a high probability that A is an obfuscated instance of
malware family F.
To understand how we measure similarity, note that S is
always a subgraph of SF ; hence, we can measure similarity
in terms of number of nodes and edges that are removed from
SF to form S. Speciﬁcally, given signature S, let f (S) be a
function that measures the size of S as a weighted sum of
the number of nodes and edges in S. Then, given app A and
family F with signature SF , we deﬁne the similarity metric
as follows:
7
δ(A,F) =
f (INFERSIGNATURE(A,SF ))
f (SF )
Hence, if δ(A,F) is sufﬁciently high, then A is more likely to
be an instance of family F. As we show in Section IX, approx-
imate matching using this similarity metric between signatures
makes ASTROID more resilient to behavioral obfuscation.
Zero-day malware detection. We can also use approximate
signature matching to detect zero-day malware. Suppose we
have a database of signatures for existing malware families
F1, . . . ,Fn, and suppose that an app A does not match any
of them. Now, to determine whether A belongs to a new
(unknown) malware family, we compute δ(A,Fi) for each
1 ≤ i ≤ n and report A as malware if δ(A,Fi) exceeds a
certain cutoff value for some malware family Fi. We explain
how we pick this cutoff value in Section VIII.
VIII.
IMPLEMENTATION
We have implemented the proposed technique in a tool
called ASTROID for inferring semantic malware signatures for
Android. Our implementation consists of about 7,000 lines of
Java code and uses the OPEN-WBO MaxSAT solver [19].
Our implementation builds on top of APPOSCOPY [2] for
statically constructing ICCGs and taint ﬂows of Android apps.
Speciﬁcally, APPOSCOPY implements a ﬁeld- and context-
sensitive pointer analysis and constructs a precise callgraph
by simultaneously reﬁning the targets of virtual method calls
and points-to sets. For context-sensitivity, APPOSCOPY uses
the hybrid approach proposed in [20]. Speciﬁcally, it uses call-
site sensitivity for static method calls and object-sensitivity for
virtual method calls. To scale in large apps, APPOSCOPY also
leverages the EXPLORER [21] tool to construct ICCGs in a
demand-driven manner. APPOSCOPY’s average static analysis
time for constructing an ICCG is 87 seconds for an app from
the Android Genome benchmarks and 126 seconds for an app
from Google Play, including analysis time for all third-party
libraries. Unlike DroidSafe [22] which analyzes the source
code of Android framework directly, APPOSCOPY uses about
1,210 manually-written models for classes that are relevant to
its underlying taint analysis.
Once a signature for a given malware family is generated,
ASTROID can perform both exact matching (described in
Section IV) as well as approximate matching (described in
Section VII). Our implementation of the approximate matching
algorithm differs slightly from the description in Section VII;
in particular, we use the transitive closure of the control-ﬂow
edges in the ICCG (computed in a preprocessing step) rather
than the original ICCG control-ﬂow edges; this modiﬁcation
increases the resilience of ASTROID against obfuscations that
introduce dummy components.
We use approximate matching both to detect obfuscated
apps and to detect zero-day malware. Recall from Section VII
that our approximate matching algorithm uses a cutoff value
for how high the similarity metric must to count as a match.
We choose a cutoff of 0.5 for zero-day malware, and a stricter
cutoff of 0.8 for obfuscated malware. In other words, an app
with a similarity score = 1.0 is ﬂagged as an unobfuscated
instance of a known malware family, an app with similarity
score > 0.8 is ﬂagged as an obfuscated instance of a known
1
0.9
0.8
0.7
0.6
0.5
e
t
a
r
e
v
i
t
i
s
o
p
e
u
r
T
0.01
0.02
0.03
0.04
0.05
False positive rate
Fig. 2: Effect of varying cutoff values on false positives and
false negatives for zero-day malware detection
malware family, and an app with similarity score > 0.5 is
ﬂagged as a possible zero-day malware.
We describe our methodology for choosing the similarity
metric cutoff for zero-day malware detection; the cutoff for
obfuscated malware is chosen similarly. We use the Android
Malware Genome Project as a training set. For each family F
in the Android Malware Genome Project, we omit the signature
for F from ASTROID’s database of signatures (so samples
in F appear as zero-day malware to ASTROID). Then, we
use the remaining signatures in the database to try and detect
samples in F using our zero-day malware detection algorithm
in Section VII, using each cutoff value 0.6382, 0.5834, 0.5832,
0.4927, and 0.4505 (selected by manually binning the data).
For each cutoff value and each F, we compute the true
positive rate (i.e., the fraction of samples in F that ASTROID
detects); then, for each cutoff value, we take the weighted
average over families F to obtain an overall true positive rate
for that cutoff value. Finally, we select the largest possible