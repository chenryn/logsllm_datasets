pgbench -M prepared -n -r -f ./test.sql -P 1 -c 45 -j 45 -T 30  
progress: 1.0 s, 8624.2 tps, lat 4.604 ms stddev 7.918  
progress: 2.0 s, 19089.2 tps, lat 2.042 ms stddev 0.521  
progress: 3.0 s, 19272.3 tps, lat 2.022 ms stddev 0.579  
progress: 4.0 s, 19403.2 tps, lat 2.008 ms stddev 0.470  
progress: 5.0 s, 19129.1 tps, lat 2.037 ms stddev 0.485  
progress: 6.0 s, 19166.5 tps, lat 2.033 ms stddev 0.476  
progress: 7.0 s, 19490.7 tps, lat 1.999 ms stddev 0.455  
progress: 8.0 s, 19135.0 tps, lat 2.037 ms stddev 1.044  
progress: 9.0 s, 19213.7 tps, lat 2.029 ms stddev 0.529  
progress: 10.0 s, 19217.0 tps, lat 2.027 ms stddev 0.788  
......  
```  
测试基于主键的更新  
```  
vi test.sql  
\setrandom id 0 32000000  
select update_pk(:id);  
pgbench -M prepared -n -r -f ./test.sql -P 1 -c 45 -j 45 -T 30  
progress: 1.0 s, 3490.1 tps, lat 11.086 ms stddev 11.913  
progress: 2.0 s, 5397.6 tps, lat 7.047 ms stddev 9.854  
progress: 15.6 s, 97.1 tps, lat 26.561 ms stddev 523.168  
progress: 15.6 s, 4886.8 tps, lat 8266.126 ms stddev 6532.652  
progress: 15.6 s, 9123.2 tps, lat 2978.012 ms stddev 5564.965  
progress: 15.7 s, 4682.6 tps, lat 4.406 ms stddev 3.083  
progress: 15.7 s, 6713.8 tps, lat 5.121 ms stddev 4.762  
progress: 15.7 s, 4390.4 tps, lat 8.206 ms stddev 8.209  
progress: 15.7 s, 9268.3 tps, lat 7.934 ms stddev 7.146  
progress: 15.7 s, 6483.0 tps, lat 5.530 ms stddev 6.171  
progress: 15.7 s, 11795.5 tps, lat 7.822 ms stddev 8.948  
progress: 15.7 s, 9453.8 tps, lat 3.019 ms stddev 2.223  
progress: 15.7 s, 10840.1 tps, lat 3.939 ms stddev 3.238  
progress: 15.7 s, 4992.6 tps, lat 6.111 ms stddev 7.013  
......  
```  
测试基于主键的查询+更新+插入：  
```  
vi test.sql  
\setrandom id 0 32000000  
select query_update_insert(:id);  
pgbench -M prepared -n -r -f ./test.sql -P 1 -c 45 -j 45 -T 30  
progress: 1.0 s, 4175.8 tps, lat 10.137 ms stddev 14.241  
progress: 2.0 s, 7094.9 tps, lat 5.901 ms stddev 9.459  
progress: 16.6 s, 236.7 tps, lat 87.273 ms stddev 1079.575  
progress: 16.6 s, 8608.3 tps, lat 4727.488 ms stddev 6682.745  
progress: 16.6 s, 10468.6 tps, lat 2716.975 ms stddev 5595.314  
progress: 16.7 s, 14217.1 tps, lat 2218.013 ms stddev 5155.964  
progress: 16.7 s, 10531.9 tps, lat 3.388 ms stddev 2.354  
progress: 16.7 s, 8932.4 tps, lat 3.128 ms stddev 1.638  
progress: 16.7 s, 9434.0 tps, lat 3.413 ms stddev 2.440  
progress: 16.7 s, 8694.5 tps, lat 4.435 ms stddev 4.919  
progress: 16.7 s, 9926.1 tps, lat 4.536 ms stddev 5.436  
progress: 16.7 s, 10110.3 tps, lat 4.008 ms stddev 3.918  
progress: 16.7 s, 8655.8 tps, lat 4.170 ms stddev 5.261  
progress: 16.7 s, 8436.7 tps, lat 2.633 ms stddev 1.674  
progress: 16.7 s, 7747.6 tps, lat 3.145 ms stddev 2.134  
progress: 16.7 s, 6092.3 tps, lat 7.418 ms stddev 9.344  
......  
```  
测试聚合  
```  
postgres=# select sum(cnt) from (select cnt from dy('select count(*) from digoal.login_log') as t(cnt int8)) t;  
   sum     
---------  
 7445856  
(1 row)  
Time: 53.389 ms  
postgres=# select sum(cnt) from (select cnt from dy('select count(*) from digoal.userinfo') as t(cnt int8)) t;  
   sum      
----------  
 32000001  
(1 row)  
Time: 196.146 ms  
```  
测试run on any  
```  
vi test.sql  
\setrandom id 0 32000000  
select query_smalltbl(:id);  
pgbench -M prepared -n -r -f ./test.sql -P 1 -c 45 -j 45 -T 30  
progress: 1.0 s, 12066.0 tps, lat 3.342 ms stddev 5.300  
progress: 2.0 s, 20631.4 tps, lat 1.937 ms stddev 0.712  
progress: 3.0 s, 20776.5 tps, lat 1.924 ms stddev 0.584  
progress: 4.0 s, 20498.0 tps, lat 1.950 ms stddev 0.828  
progress: 5.0 s, 20785.4 tps, lat 1.923 ms stddev 0.490  
progress: 6.0 s, 20200.4 tps, lat 1.979 ms stddev 1.027  
progress: 7.0 s, 20957.9 tps, lat 1.907 ms stddev 0.460  
progress: 8.0 s, 21111.2 tps, lat 1.893 ms stddev 0.452  
progress: 9.0 s, 20940.5 tps, lat 1.908 ms stddev 0.461  
progress: 10.0 s, 20540.5 tps, lat 1.946 ms stddev 0.673  
```  
对比6400万数据在单一节点的性能提升，因为单节点下6400万数据已经远超出内存，同时RDS限制了IOPS，所以单节点下6400万数据的性能是很差的。  
下篇再提供单RDS下的数据。  
问题：（注意，以下这些问题现在阿里云RDS PG已经解决了，以下是公测时遇到的问题。）  
1\. 偶尔会遇到中间件这层连接不通的问题(内网，不是外网)，再次执行又能通讯。例如:  
```  
ERROR:  could not establish connection  
DETAIL:  could not connect to server: Connection timed out  
        Is the server running on host "xxxx.pg.rds.aliyuncs.com" (100.99.xxx.xxx) and accepting  
        TCP/IP connections on port 3433?  
Client 30 aborted in state 1: ERROR:  PL/Proxy function public.query_pk(1): [db1] PQconnectPoll: could not connect to server: Connection timed out  
        Is the server running on host "xxxx.pg.rds.aliyuncs.com" (100.98.xxx.xxx) and accepting  
        TCP/IP connections on port 3433?  
```  
2\. 超时, 通过增加集群连接参数 keepalives_idle=30 keepalives_interval=10 keepalives_count=10  
```  
ERROR:  PL/Proxy function public.dy_generate_test_ddl(0): [db11] PQconsumeInput: server closed the connection unexpectedly  
        This probably means the server terminated abnormally  
        before or while processing the request.  
```  
3\. 尊敬的用户，您的RDS（实例名：rdxxxxxxx1，连接地址：）发生主备切换，请将您的应用程序重连，确保使用正常，如果您的应用程序有自动重连机制请忽略此邮件，谢谢。  
不知道是不是因为负载引起的切换，如果是的话，可能主机并未按照负载峰值来估算跑多少实例，导致超跑了。  
另外一种原因可能是超资源使用被主动KILL了？（这样就有点暴力了）  
不管怎么样，个人认为只有故障才是切换的理由。  
4\. 因为RDS限制了最大连接数是100，而且还为超级用户保留了5个连接，然后我这里每个RDS上有两个数据节点库，所以在使用plproxy 测试时，最多能用的连接数是95/2=47.5。  
超出将报错如下：  
```  
Client 46 aborted in state 1: ERROR:  PL/Proxy function public.query_pk(1): [db4] PQconnectPoll: FATAL:  remaining connection slots are reserved for non-replication superuser connections  
```  
所以我这里测试只用45个连接，实际上对单个库，如果响应较慢，那么同一时间最多可能会用掉90个连接。  
5\. 本次测试更新性能的硬伤是在RDS的 IOPS和shared_buffers上，如果要上比较高并发的带数据更新需求的业务，建议购买足够的IOPS和内存的RDS，以获得好的性能。以下是一台性能较好的服务器下的benchmark数据，仅供参考：  
http://blog.163.com/digoal@126/blog/static/163877040201541104656600/  
http://blog.163.com/digoal@126/blog/static/16387704020154431045764/  
阿里云RDS监控平台的数据，我的控制台只有5个实例，不过基本上已经能够反映所有实例的情况了：  
单个实例的数据基本上在shared buffer中，所以数据盘的IOPS是很小的。  
![pic](20151220_02_pic_003.png)  
测试写，更新时xlog的IOPS很高，基本已经到大顶峰，但是使用了异步提交，所以影响较小。  
![pic](20151220_02_pic_004.png)  
单个实例在500MB左右。   
![pic](20151220_02_pic_005.png)  
## 参考  
1\. http://git.postgresql.org/gitweb/?p=plproxy.git;a=summary  
2\. http://blog.163.com/digoal@126/blog/static/163877040201541104656600/  
3\. http://blog.163.com/digoal@126/blog/static/16387704020154431045764/  
4\. http://blog.163.com/digoal@126/blog/static/1638770402015599230431/  
5\. http://blog.163.com/digoal@126/blog/static/1638770402013102242543765/  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")