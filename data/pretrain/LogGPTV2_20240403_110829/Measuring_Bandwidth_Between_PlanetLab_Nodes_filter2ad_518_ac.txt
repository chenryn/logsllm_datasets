299
86
70
48
13
21.94
45.23
13.01
10.59
7.26
1.97
i
h
t
d
w
d
n
a
b
e
v
i
t
a
e
R
l
45
40
35
30
25
20
15
10
5
0
0
70
60
50
40
30
20
10
i
h
t
d
w
d
n
a
b
e
v
i
t
a
e
R
l
50
100
150
Node ID
(a) Set 1.
200
250
300
0
0
20
40
60
80
100
Node ID
120
140
160
180
Fig. 4. Bandwidth/delay correlation
(b) Set 2.
latency values easily in hand, if there is any relationship or trend between latency and
bandwidth, we can scalably estimate network bandwidth without excessive bandwidth
probing. That is the main motivation of this trend analysis. Note also that using capacity,
instead of available bandwidth, is more appropriate as the values of available bandwidth
vary with time, and unless the measurement of bandwidth and latency are done at the
same period, the analysis could be meaningless.
For the latency measurement, we initially used the all pair ping data.2 However, due
to some missing ping data, there was little overlap between the available ping data and
collected bandwidth measurement. Hence we also used the RTT measurements from
pathrate. The resulting trends from ping and RTT measures from pathrate are quite
similar, and hence we only present the results based upon the pathrate RTT latency.
We used two metrics for studying the bandwidth and latency correlation. The ﬁrst
metric, called relative bandwidth correlation metric, captures the ratio of maximum
bandwidth path and bandwidth to the closest node. For a given host (nodei), using the
2 We obtain this from http://www.pdos.lcs.mit.edu/˜strib/pl_app/
302
S.-J. Lee et al.
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
F
D
C
0
0
5
10
20
15
30
Relative bandwidth
25
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
F
D
C
35
40
45
0
0
10
20
30
Relative bandwidth
40
50
60
70
(a) Set 1.
(b) Set 2.
Fig. 5. Cumulative distribution function of bandwidth/delay correlation
latency data, we ﬁnd the host that has the minimum latency (nodeminLat). Similarly,
using the capacity measurements, we ﬁnd the host that provides the maximum bandwidth
(nodemaxBW ). The relative bandwidth correlation penalty metric for nodei is then
deﬁned as the ratio of the maximum bandwidth (BWi,maxBW ) and the bandwidth from
nodei to nodeminLat (BWi,minLat). This metric takes values greater than or equal to
1.0. The closer this metric is to 1.0, we consider the correlation between latency and
bandwidth to be stronger. We plot this metric and its cumulative distribution in Figures 4
and 5.
We see from the ﬁgure that latency and bandwidth are surprisingly quite correlated,
especially in the second set. On further analysis with the CDF for the ﬁrst set, we notice
that for about 40% of the nodes, the bandwidth to the closest node is roughly 40% smaller
than the actual maximum bandwidth. Our preliminary investigations reveal one of the
primary reasons for this behavior is the imposed bandwidth limit. In some cases, the
capacities to even the nearby nodes are quite less than the maximum bandwidth as they
have bandwidth limits. For instance, in the Set 1, in lots of cases the node with highest
capacity is planetlab1.ls.ﬁ.upm.es which did not have any imposed bandwidth limit.
For the second set on the other hand, we see that about 90% of the closest nodes has the
capacity that is nearly equal to the maximum bandwidth. We must remember however,
that the roundtrip time measurement was performed by pathrate itself. Tools such as
Netvigator [26] that perform network distance estimation typically uses traceroute or
ping, and those tools may return different values. We can further test the correlation
between bandwidth and latency using these tools.
We also used the Spearman rank correlation coefﬁcient [13], which is commonly
used instead of the Pearson’s correlation coefﬁcient, when the two sets of data come
from different distributions. In Figure 6, we rank all the node pairs based on both band-
width and latency. We plot the bandwidth rank versus the latency rank. If there is good
correlation, we expect the points to be clustered along the y = x diagonal line. How-
ever, using the Spearman coefﬁcient we did not ﬁnd any such correlation. The value of
Measuring Bandwidth Between PlanetLab Nodes
303
t
k
n
a
R
h
d
w
d
n
a
B
i
12000
10000
8000
6000
4000
2000
0
0
2000
4000
6000
8000
Latency Rank
x 104
2.5
k
n
a
R
h
t
d
w
d
n
a
B
i
2
1.5
1
0.5
10000
12000
0
0
0.5
1
1.5
Latency Rank
2
2.5
x 104
(a) Set 1.
(b) Set 2.
Fig. 6. Bandwidth/delay correlation using rank correlation
Spearman coefﬁcient for sets 1 and 2 are 0.027 and 0.138 respectively based on the data
presented in these ﬁgures. We believe that the degree of rank-order correlation is higher
between closeby nodes and it decreases as distance between nodes increases. Hence, the
low value of Spearman
might be due to its computation over all the possible
nodes. We plan to evaluate other rank-order correlation coefﬁcients in this context.
coefﬁcient
3
Summary and Conclusions
In this paper, we presented a large scale measurement study of end-to-end capacity of
paths between PlanetLab nodes. Our contributions are two-fold in that in addition to
presenting the analysis of the data we collected from two sets of experiments, we also
described the issues with the deployment of a number of bandwidth measurement tools
on the PlanetLab platform. The measurement work is ongoing, but even with the data
we have collected so far, there are a number of interesting conclusions one can draw.
Foremost, we veriﬁed our intuition that network paths connecting PlanetLab nodes are
highly heterogeneous in the capacity values and in planning PlanetLab experiments, one
needs to take this into account. The capacity of paths may have an order of magnitude
difference even when they are sourced from the same node and similarly for the same
receiver. Paths between two nodes do not necessarily show capacity symmetry.According
to PlanetLab policy, bandwidth limits on outgoing trafﬁc have been implemented. But
we observed violations of the policy, which could have been due to the inaccuracy of the
tool itself and we are investigating this further. In attempting to draw insights for scalable
bandwidth estimation, we studied the correlation between latency and bandwidth of a
path. Our preliminary results are promising and we plan to investigate this further.
One of our future work includes modifying the SProbe tool to keep attempting
measurements until a valid estimate is made. We can then measure the bandwidth to
nodes outside PlanetLab as SProbe does not require user access to destination hosts.
304
S.-J. Lee et al.
We also plan to periodically measure the all pair bandwidth between planet-lab hosts
and make it available to public. Although there exists a running service that measures
bandwidth between PlanetLab nodes,3 it uses Iperf [25] that measures achievable TCP
throughput, which is not necessarily raw capacity or available bandwidth.
References
1. A. Akella, S. Seshan, and A. Shaikh, “An empirical evaluation of wide-area Internet bottle-
necks,” in Proceedings of the ACM IMC 2003, Miami, FL, October 2003.
2. S. Banerjee, M. Pias, and T. Grifﬁn, “The interdomain connectivity of planetlab nodes,” in
Proceedings of the PAM 2004, Sophia-Antipolis, France, April 2004.
3. R. L. Carter and M. E. Crovella, “Server selection using dynamic path characterization in
wide-area networks,” in Proceedings of the IEEE INFOCOM’97, Kobe, Japan, April 1997.
4. C. Dovrolis, P. Ramanathan, and D. Moore, “What do packet dispersion techniques measure?”
in Proceedings of the IEEE INFOCOM 2001, Anchorage, AK, April 2001.
5. A. B. Downey, “Using pathchar to estimate Internet link characteristics,” in Proceedings of
the ACM SIGCOMM’99, Cambridge, MA, September 1999.
6. N. Hu, L. Li, Z. M. Mao, P. Steenkiste, and J. Wang, “Locating internet bottlenecks: Al-
gorithms, measurements, and implications,” in Proceedings of the ACM SIGCOMM 2004,
Portland, OR, August 2004.
7. N. Hu and P. Steenkiste, “Evaluation and characterization of available bandwidth probing
techniques,” IEEE J. Select. Areas Commun., vol. 21, no. 6, August 2003.
8. M. Jain and C. Dovrolis, “Pathload: A measurement tool for end-to-end available bandwidth,”
in Proceedings of the PAM 2002, Fort Collins, CO, March 2002.
9. ——, “Ten fallacies and pitfalls on end-to-end available bandwidth estimation,” in Proceed-
ings of the ACM IMC 2004, Taormina, Italy, October 2004.
10. V. Jocobson. pathchar: A tool to infer characteristics of internet paths. [Online]. Available:
ftp://ftp.ee.lbl.gov/pathchar
11. R. Kapoor, L.-J. Chen, L. Lao, M. Gerla, and M.Y. Sanadidi, “CapProbe:A simple and accurate
capacity estimation technique,” in Proceedings of the ACM SIGCOMM 2004, Portland, OR,
August 2004.
12. S. Katti, D. Kitabi, C. Blake, E. Kohler, and J. Strauss, “MultiQ: Automated detection of
multiple bottleneck capacities along a path,” in Proceedings of the ACM IMC 2004, Taormina,
Italy, October 2004.
13. E. L. Lehmann and H. J. M. D’Abrera, Nonparametrics: Statistical Methods Based on Ranks,
rev. ed. Prentice-Hall, 1998.
14. B. A. Mah. pchar: A tool for measuring internet path characteristics. [Online]. Available:
http://www.kitchenlab.org/www/bmah/Software/pchar
15. F. Montesino-Pouzols, “Comparative analysis of active bandwidth estimation tools,” in Pro-
ceedings of the PAM 2004, Sophia-Antipolis, France, April 2004.
16. J. Navratil and R. L. Cottrell, “ABwE: A practical approach to available bandwidth estima-
tion,” in Proceedings of the PAM 2003, La Jolla, CA, April 2003.
17. T. S. E. Ng and H. Zhang, “Predicting Internet network distance with coordinates-based
approaches,” in Proceedings of the IEEE INFOCOM 2002, New York, NY, June 2002.
18. R. Prasad, C. Dovrolis, M. Murray, and kc claffy, “Bandwidth estimation: Metrics, measure-
ment techniques, and tools,” IEEE Network, vol. 17, no. 6, pp. 27–35, November/December
2003.
3 http://www.planet-lab.org/logs/iperf/
Measuring Bandwidth Between PlanetLab Nodes
305
19. V. Ribeiro, R. Riedi, R. Baraniuk, J. Navratil, and L. Cottrell, “pathChirp: Efﬁcient available
bandwidth estimation for network paths,” in Proceedings of the PAM 2003, La Jolla, CA,
April 2003.
20. V. J. Ribeiro, R. H. Riedi, and R. G. Baraniuk, “Locating available bandwidth bottlenecks,”
IEEE Internet Comput., vol. 8, no. 6, pp. 34–41, September/October 2004.
21. S. Saroiu. SProbe: A fast
tool for measuring bottleneck bandwidth in uncooperative
environments. [Online]. Available: http://sprobe.cs.washington.edu/
22. S. Saroiu, P. K. Gummadi, and S. D. Gribble, “SProbe: Another tool for measuring bottleneck
bandwidth,” in Work-in-Progress Report at the USITS 2001, San Francisco, CA, March 2001.
23. N. Spring, D. Wetherall, and T. Anderson. Scriptroute: A facility for distributed internet
debugging and measurement. [Online]. Available: http://www.scriptroute.org
24. J. Strauss, D. Katabi, and F. Kaashoek, “A measurement study of available bandwidth esti-
mation tools,” in Proceedings of the ACM IMC 2003, Miami, FL, October 2003.
25. A. Tirumala, F. Qin, J. Dugan, J. Ferguson, and K. Gibbs. Iperf: The TCP/UDP bandwidth
measurement tool. [Online]. Available: http://dast.nlanr.net/Projects/Iperf/
26. Z. Xu, P. Sharma, S.-J. Lee, and S. Banerjee, “Netvigator: Scalable network proximity esti-
mation,” HP Laboratories, Tech. Rep., 2005.