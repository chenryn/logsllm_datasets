tasks ()
segments (S)
frequency ()
 (cheater caught)
5
5
5
5
10
10
4
4
4
4
9
9
5
10
10
20
10
10
1
1
.2
.2
1
.2
0.9222
0.9939
0.64
0.8704
0.8926
0.36
Table 3. Redundancy factors for various  values.

0.1
= 1.05
0.2
1.11
0.3
1.18
0.4
1.25

0.1
= 1.03
0.2
1.06
0.3
1.09
0.4
1.13
 = 1
0.5
1.33
 = 2
0.5
1.17
0.6
1.43
0.7
1.54
0.8
1.67
0.9
1.82
1.0
2.0
0.6
1.23
0.7
1.29
0.8
1.38
0.9
1.52
1.0
2.0
Table 3 shows the redundancy factors required for  = 1
and  = 2 with various  values.
The primary advantage of this strategy is that far fewer
task compute cycles are required than for simple redun-
dancy. Similar to our seeding strategy for non-sequential
tasks (except Monte Carlo simulations), there is no need
for the supervisor to precompute any values. The method
is also collusion resistant (unless a supervisor is unfortu-
nate enough to select a group consisting entirely of collud-
ing nodes) because the returned results are permuted and
reassigned. In addition, the method is tunable — a super-
visor can set security levels by varying the redundancy fac-
tor. Finally, the technique can be applied to non-sequential
computations as well.
The primary disadvantage of the scheme is an increased
workload for the supervisor, who experiences an increase in
both coordination and communication costs due to the node
synchronization requirements. The need for synchroniza-
tion also increases the time cost of a computation, which
can be especially expensive if many of the volunteer PCs
are connected to the Internet via modems or operate spo-
radically because owners use the machines for their own
purposes. As more PC owners move to high speed 24/7
connectivity, synchronization costs will likely be less of an
issue (e.g., jobs can be run late at night). From a security
standpoint, the strategy does not protect well against a ma-
licious adversary who decides to cheat just once. More-
over, the amount of damage a cheater can do is magniﬁed,
because incorrect results that are not caught become input
values in subsequent segments of the computation.
5. Related work
The present problem relates to the validation of code
execution, so its historical roots lie in the areas of result-
checking and self-correcting programs. Wasserman and
Blum [22] provide an excellent survey of the results in this
area. While of theoretical interest, it is not directly appli-
cable here because much of the work is limited to speciﬁc
arithmetic functions, and checking is limited to verifying
function behavior on a single input, rather than on all inputs.
Result checkers for general computations remain elusive.
Several recent implementations of distributed computing
platforms address the general issues of fault-tolerance [2, 3,
4, 6, 14, 17], but assume a fault model in which errors that
occur are not the result of malicious intent. The solutions
presented are typically a combination of redundancy with
voting and spot checking. In a preliminary investigation of
the problem of fault-tolerant distributed computing, Minsky
et al. [12] found that replication and voting schemes alone
are not sufﬁcient for solving the problem. They assert that
cryptographic support is required as well, but only sketch
the methods they envision for solving this.
There have been a number of efforts aimed at protecting
mobile agents from malicious hosts. Vigna [21] proposes
using cryptographic traces to detect tampering with agents.
Speciﬁcally, an untrusted host that is providing the execu-
tion environment for a mobile agent is required to generate,
and for a short while store, a trace of the agent execution.
Upon completion of the execution, the untrusted host re-
turns a hash of the trace, and if requested by the originating
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
host, the complete trace. This of course means that veriﬁca-
tion of the correct execution is provided by having the code
executed twice, once on the trusted node, and once on the
untrusted node. In addition, as Vigna notes, even if traces
are compressed, they can be huge. While there are mech-
anisms that can be used to decrease the size of traces, the
communication overhead remains far too great to be practi-
cal for a metacomputation.
Sanders and Tschudin [16] discuss the idea of provid-
ing security for mobile agents by computing with encrypted
functions [1, 15]. The idea is to use an encryption function
E to encrypt the code for a procedure , obtaining a sec-
ond function E that provides little information about .
An untrusted second party then executes E on a given
input x and returns the result, which is then decrypted to
obtain x. The difﬁculty here lies in creating encryp-
tion functions that map executable procedures to executable
procedures. There are other requirements for E, including
resistance to chosen plaintext attacks, ciphertext only at-
tacks, and other attacks. Abadi and Feigenbaum [1] present
an encryption function for a general boolean circuit, but
their method requires a great deal of interaction between
the communicating parties. Sanders and Tschudin add the
constraint that the encryption function should not be inter-
active, since frequent communication between an agent and
the server from which it originated effectively eliminates
the beneﬁts gained from agent autonomy. The methods they
present apply to procedures that evaluate restricted classes
of polynomials and rational functions. Because no methods
are presented for more general procedures, however, and
because it is not even known whether such encryption func-
tions exist, their methods, though interesting, present prac-
tical difﬁculties.
In addition to the work of Golle and Mironov [9], two
other works focus speciﬁcally on the issue of securing dis-
tributed metacomputations. Golle and Stubblebine [10]
present a security based administrative framework for com-
mercial distributed computations. Their method, like those
presented here, relies on selective redundancy to increase
the probability that a cheater is detected. They provide
increased ﬂexibility, however, by varying the distributions
that dictate the application of redundancy. Efﬁcacy is mea-
sured by ﬁrst developing a game theoretic model based on
estimates of the participant’s utility of disrupting the com-
putation and cost of being caught defecting, and then deter-
mining distribution parameters that guarantee that, for every
participant involved, the expected value of defecting from
the computation is less than or equal to zero. The differ-
ences between their methods and those presented here lie in
the particulars of how redundancy is applied and with the
granularity of redundancy.
Monrose, Wyckoff, and Rubin [13] deal with the prob-
lem of guaranteeing that a host participates in the compu-
tation, assuming that their goal is to maximize their proﬁt
by minimizing resources. The method involves recording
traces of task execution. Speciﬁcally, task code is instru-
mented at compile-time so that it produces checkable state
points that constitute a proof of execution. On completion
of the task, the participant sends results and the proof to
a veriﬁer, which then runs a portion of the execution and
checks it against the returned state checkpoints. However,
this approach requires the undesirable need to recompute
results.
6. Conclusions
We have presented two strategies for hardening large
scale distributed computations against malicious behavior
by participating hosts. The ﬁrst, applicable to many non-
sequential computations (such as optimization problems),
requires seeding task data with ringers in a manner that pre-
vents participants from being able to distinguish the ringers
from genuinely signiﬁcant results. The second strategy, ap-
plicable to sequential computations (such as GIMPS), ad-
vocates sharing the work of computing  tasks among
 >  nodes. Relative to an unmodiﬁed task, a small
increase is incurred in the average execution time of a task
modiﬁed to execute with our strategies. However, the over-
all computing costs are signiﬁcantly decreased compared to
redundantly assigning entire tasks. In addition, both strate-
gies provide supervisors protection against participants who
fail to complete assigned tasks, and provide a measure of
assurance of the validity of returned results.
Acknowledgments
We would like to thank the anonymous reviewers whose
comments helped us in preparing the ﬁnal version of the
paper.
References
[1] M. Abadi and J. Feigenbaum. Secure circuit evaluation: A
protocol based on hiding information from an oracle. Jour-
nal of Cryptology, 2(1):1–12, 1990.
[2] J. Baldeschwieler, R. Blumofe, and E. Brewer. Atlas: An
infrastructure for global computing. In Proceedings of the
Seventh ACM SIGOPS European Workshop on System Sup-
port for Worldwide Applications, 1996.
[3] A. Baratloo, M. Karaul, Z. M. Kedem, and P. Wyckoff.
Charlotte: Metacomputing on the web. In Proc. of the 9th
Int’l Conf. on Parallel and Distributed Computing Systems
(PDCS-96), 1996.
[4] T. Brecht, H. Sandhu, M. Shan, and J. Talbot. Paraweb: To-
wards world-wide supercomputing.
In Proceedings of the
Seventh ACM SIGOPS European Workshop on System Sup-
port for Worldwide Applications, 1996.
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
[5] J. Bruce. A really trivial proof of the Lucas-Lehmer test.
American Mathematical Monthly, 100:370–371, 1993.
[6] P. Capello, B. Christiansen, M.
Ionescu, M. Neary,
K. Schauser, and D. Wu.
Javelin: Internet-based parallel
computing using Java. Concurrency: Practice and Experi-
ence, 9(11):1139–1160, 1997.
[7] The Folding@home Project. Stanford University.
http://www.stanford.edu/group/pandegroup/cosm/.
[8] The Great Internet Mersenne Prime Search.
http://www.mersenne.org/prime.htm.
[9] P. Golle and I. Mironov. Uncheatable distributed computa-
tions. In Proceedings of the RSA Conference 2001, Cryptog-
raphers’ Track, pages 425–441, San Francisco, CA, 2001.
Springer.
[10] P. Golle and S. Stubblebine. Secure distributed computing
in a commercial environment. 2001.
http://crypto.stanford.edu/(cid:24)pgolle/papers/payout.html.
[11] A. Law and W. Kelton. Simulation Modeling and Analysis.
McGraw-Hill, 3rd edition, 2000.
[12] Y. Minsky, R. van Renesse, F. Schneider, and S. Stoller.
Cryptographic support for fault-tolerant distributed comput-
ing. In Seventh ACM SIGOPS European Workshop, pages
109–114, Connemara, Ireland, 1996.
[13] F. Monrose, P. Wyckoff, and A. Rubin. Distributed execu-
tion with remote audit.
In Proceedings of the 1999 ISOC
Network and Distributed System Security Symposium, pages
103–113, 1999.
[14] N. Nisan, S. London, O. Regev, and N. Camiel. Glob-
ally distributed computing over the internet—the Popcorn
project. In Proceedings of the International Conference on
Distributed Computing Systems, pages 592–601, Amster-
dam, Netherlands, May 1998.
[15] R. Rivest, L. Adleman, and M. Dertouzos. On data banks
In R. D. Millo, D. Dobkin,
and privacy homomorphisms.
A. Jones, and R. Lipton, editors, Foundations of Secure
Computation, pages 169–179. Academic Press, New York,
1978.
[16] T. Sander and C. F. Tschudin. Protecting Mobile Agents
Against Malicious Hosts. In G. Vigna, editor, Mobile Agent
Security, pages 44–60. Springer-Verlag: Heidelberg, Ger-
many, 1998.
[17] L. Sarmenta and S. Hirano. Bayanihan: Building and study-
ing web-based volunteer computing systems using java. Fu-
ture Generation Computer Systems, 15(5/6), 1999.
[18] The Search for Extraterrestrial Intelligence project. Univer-
sity of California, Berkeley.
http://setiathome.berkeley.edu/.
[19] T. Stein. A cycle built for few. In Red Herring magazine,
December 2000.
[20] P. Syverson. Weakly secret bit commitment: Applications
to lotteries and fair exchange. In PCSFW: Proceedings of
The 11th Computer Security Foundations Workshop. IEEE
Computer Society Press, 1998.
[21] G. Vigna. Cryptographic Traces for Mobile Agents.
In
G. Vigna, editor, Mobile Agent Security, pages 137–153.
Springer-Verlag: Heidelberg, Germany, 1998.
[22] H. Wasserman and M. Blum. Software reliability via run-
time result-checking. Journal of the ACM, 44(6):826–849,
1997.
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE