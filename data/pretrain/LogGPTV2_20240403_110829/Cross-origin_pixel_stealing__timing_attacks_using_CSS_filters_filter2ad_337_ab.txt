### CSS Filter-Based Timing Attacks

#### CSS Blur Filter
```css
.filter {
    -webkit-filter: blur(10px);
    -moz-filter: blur(10px);
}
```

#### JavaScript Function to Toggle the Filter
```javascript
function alternate() {
    $("#attack-iframe").toggleClass("filter");
}

setInterval(alternate, time);
```

#### Firefox Compatibility
We discovered that this attack also works in Firefox by using an SVG image blur effect instead of a WebKit filter. Firefox allows users to apply SVG filters to DOM elements. As with most web timing attacks, the timing data is an approximation of the true runtime of a process. Our attack is less noisy than typical web application timing attacks [4] because there is no network latency or packet loss involved.

The results in Figure 3 show how the relative size of a page can be determined using CSS default filters. Notice that the page when the user is logged in produces a different average framerate compared to the homepage when the user is not logged in, due to differences in their DOM trees.

### Pixel Stealing with CSS Filters

#### General Technique
Next, we describe a general technique that can be used to read a field of arbitrary pixels from the user’s browser window. We fill the screen with a single color and examine how the browser window's average framerate changes by reading it with `requestAnimationFrame`.

#### Focusing on a Single Pixel without Anti-Aliasing
We found that enlarging the pixel to the size of the user’s screen exaggerates timing differences. This section describes our technique.

##### HTML and CSS for Enlarging a Single Pixel
```css
#malicious-iframe {
    overflow: hidden;
    width: 1px;
    height: 1px;
    margin-top: 0px;
    margin-left: 0px;
}

#pixel-container {
    top: calc(50% - 1px);
    left: calc(50% - 1px);
    width: 1px;
    height: 1px;
}

#pixel-container-container {
    width: 999px;
    height: 999px;
    -webkit-filter: custom(url(enlarge.vs) mix(url(enlarge.fs)), 44);
}
```

We position the iframe inside a div with the class `#pixel-container`. This div is centered inside its parent element, `#pixel-container-container`, which defines a CSS filter that scales the pixel-sized iframe to a much larger size. The width and height are odd-valued to ensure that the single-pixel iframe is centered.

#### Pixel Stealing Attack
We use the above mechanism to traverse a bitmap of pixels by setting `margin-top` and `margin-left` in the malicious iframe. Our attack performs arbitrary transformations on the scaled pixel, determines the average framerate during the transformations, and interprets the resulting value for each pixel. The steps of the attack are as follows:

1. **Expand a Single Pixel**: The attacker builds a mechanism that can expand a pixel to the size of the user agent’s screen.
2. **Frame the Victim Page**: The attacker frames a website that has neglected to use X-Frame-Options.
3. **Victim Visits Malicious Page**: The victim visits the attacker’s malicious web page and is tricked into remaining on the page for the duration of the attack.
4. **Traverse the Page**: In the attack, a malicious website may want to traverse each pixel in a target region of the intended website or in a target region of its source code. An arbitrary transformation is repeatedly performed on each pixel.
5. **Capture Average Framerate**: `requestAnimationFrame` determines the average framerate on the browser window for each target pixel.
6. **Interpret Data**: An array of pixel measurements is sent to the attacker’s server to be interpreted.

Collecting and interpreting pixel data turned out to be an interesting problem. The most successful attempt involved writing code with a jQuery UI slider to change the threshold that separates black and white pixels. A script was written to interpret the pixel data by deciding what thresholds should be used to distinguish black and white pixel framerates. Using a canvas element, we could visually examine the pixel values.

### Results
We initially tested our pixel stealing idea by running black and white pixels through shaders with arbitrary transformation matrices. Our intuition was that if there existed two colors that could create distinct timing channels, black and white would be the most likely candidates. Our intuition proved correct.

A proof-of-concept attack involved recreating a 10x10 bitmap of black and white pixels to determine the timing consistencies of a user’s device. A higher percentage of correctly-guessed pixels implies a more vulnerable user agent. Results from this initial test indicated that stealing cross-origin pixels could be achieved with high enough accuracy to make pixel stealing attacks practical. We conducted tests that measured each pixel’s color for 4, 12, and 20 seconds, and the results are shown in Figure 5. Compare our results with the actual bitmap in (d).

In this test, we counted the number of pixels that were guessed correctly out of 100. If our attack was returning random values, we would expect about 50 pixels to be correct regardless of time spent per pixel. The chance that exactly half of the pixels are guessed correctly is 50%. The chance that more than 60% of a bitmap’s pixels are chosen correctly on any given test is just 6%. Figure 4 shows accuracy for various devices. Half of the setups we tried were vulnerable.

### Possible Attack Scenarios in Practice
Once a bitmap of pixel colors can be determined over HTTPS, attack possibilities are endless. The most interesting attack we implemented involves stealing tokens of cross-origin text. We were able to read a fake token that we retrieved across origins. This token was stolen from a machine with an AMD Radeon HD 6770 and Intel Core i7.

We also used our pixel stealing attack to implement history sniffing. Until recently, a user’s history could be determined by simply adding a link to a page and determining its color by calling `getComputedStyle()` since visited links have different colors than non-visited links. Browsers now lie if this function is called on a link.

The following attack can be used to determine whether or not a user has visited a particular website:

1. **Victim Visits Malicious Page**: The malicious page initializes with a block of ASCII text (e.g., ASCII value 219) that hrefs to a website known to not exist.
2. **Link is Expanded**: A pixel from the link is expanded to the size of the user’s screen.
3. **Data is Collected**: The malicious web page allows a sufficient amount of time to pass while measuring the page framerate using `requestAnimationFrame`.
4. **Process is Repeated**: Steps 2-4 are repeated two more times. The first is for this page, which will return results for a URL that we know the user has visited. The second is for a URL we are curious about.
5. **Data is Analyzed**: We can determine if the user visited the victim URL by comparing it with the framerate of our two test URLs.

By using the pixel stealing technique described above, it is possible to determine whether or not a user has visited a website by analyzing a single pixel.

### Complications and Solutions
We found that the best results can be obtained when the input pixel field is restricted to black and white only. We combined several filter effects to achieve a close estimate of a black and white transform. We ended up using the following filter combination:

```css
.black-and-white {
    -webkit-filter: saturate(0%) grayscale(100%) brightness(69%) contrast(100%);
}
```

Notice in Figure 7 that without the use of these filter effects, non-black pixels are usually interpreted as white. This sample of cross-origin HTML text is easily recognized as the letter “h” in Figure 7, but without default filters, many letters with curves such as “S” and “R” were nearly impossible to read.

A final challenge we faced with this attack was finding a reasonable amount of time to spend on each pixel. It is important that all pixels are read before the user closes their browser window. To get a better understanding of the accuracy achieved as a result of various amounts of time spent per pixel on several graphics cards, see Figure 4. While history sniffing or stealing small text tokens is possible in practice, stealing medium-sized images or large tokens may not be.

### Conditions for Attack Failure
We determined that running shaders in background tabs produces undesirable performance and will cause an attack to fail. Running the attack in a background window will have the same performance results as an attack in the foreground. Running the attack on a div or iframe element whose opacity equals 0.0 will not work, but covering it with another DOM does work.

### Conclusion
This paper demonstrates that timing attacks using CSS filters can reveal sensitive information such as text tokens. Our work uses both default and custom filters to exploit timing channels in rendering engines of various browsers. A paper that cites the original version of this paper shows that the timing attacks can also be performed with SVG filters [17].

An easy solution would be to place shaders and filters under the restrictions of the Same-Origin Policy, but this would entirely defeat the purpose of these features. This would also likely be covering up a larger problem that is present across multiple browsers. Creating awareness in the security community seems like the best way to proceed.

### Acknowledgements
We would like to thank Eric Chen and Lin-Shung Huang for their guidance and support to our research.

### References
[1] Adobe. CSS Shaders. <http://www.adobe.com/devnet/html5/articles/css-shaders.html>
[2] A. Barth. Adam Barth’s Proposal. <http://www.schemehostport.com/2011/12/timing-attacks-on-css-shaders.html>
[3] A. Barth, C. Jackson, C. Reis, and T. Team. The Security Architecture of the Chromium Browser, 2008.
[4] A. Bortz and D. Boneh. Exposing Private Information by Timing Web Applications. In Proceedings of the 16th International Conference on World Wide Web, pages 621–628. ACM, 2007.
[5] Chromium. GPU Command Buffer. <http://www.chromium.org/developers/design-documents/gpu-command-buffer>
[6] Chromium. Graphics and Skia. <http://www.chromium.org/developers/design-documents/graphics-and-skia>
[7] CMU. Spatial Data Structures. <http://www.cs.cmu.edu/afs/cs/academic/class/15462-f12/www/lec_slides/lec13.pdf>
[8] R. Crawfis. Mozilla `window.requestAnimationFrame`. <https://developer.mozilla.org/en-US/docs/DOM/window.requestAnimationFrame>
[9] A. Deveria. Can I Use CSS Filter Effects? <http://caniuse.com/css-filters>
[10] E. W. Felten and M. A. Schneider. Timing Attacks on Web Privacy. In Proceedings of the 7th ACM Conference on Computer and Communications Security, pages 25–32. ACM, 2000.
[11] HTML5Rocks. Catch-all for HTML5 Rocks Website. <http://updates.html5rocks.com>
[12] R. Hudea, R. Cabanier, and V. Hardy. Enriching the Web with CSS Filters.
[13] C. Jackson, A. Bortz, D. Boneh, and J. C. Mitchell. Protecting Browser State from Web Privacy Attacks. In Proceedings of the 15th International Conference on World Wide Web, pages 737–744. ACM, 2006.
[14] P. C. Kocher. Timing Attacks on Implementations of Diffie-Hellman, RSA, DSS, and Other Systems. In Advances in Cryptology—CRYPTO’96, pages 104–113. Springer, 1996.
[15] V. Kokkevis. GPU Accelerated Compositing in Chrome. <http://www.chromium.org/developers/design-documents/gpu-accelerated-compositing-in-chrome>
[16] I. LiTH. Painter’s Algorithm. <http://www.computer-graphics.se/TSBK07-files/PDF12/6b.pdf>
[17] P. Stone. Pixel Perfect Timing Attacks with HTML5. <http://www.contextis.com/files/Browser_Timing_Attacks.pdf>
[18] W3. CSS Shader Proposal. <https://dvcs.w3.org/hg/FXTF/raw-file/tip/custom/index.html>
[19] W3. Shader Security. <http://www.w3.org/Graphics/fx/wiki/CSS_Shaders_Security>
[20] Webkit. Accelerated Rendering and Compositing. <http://trac.webkit.org/wiki/Accelerated%20rendering%20and%20compositing>
[21] Z. Weinberg, E. Y. Chen, P. R. Jayaraman, and C. Jackson. I Still Know What You Visited Last Summer: Leaking Browsing History via User Interaction and Side Channel Attacks. In Security and Privacy (SP), 2011 IEEE Symposium on, pages 147–161. IEEE, 2011.
[22] S. White. Accelerated CSS Filters Landed in Chromium. <http://blog.chromium.org/2012/06/accelerated-css-filters-landed-in.html>