. filter {
- w e b k i t - f i l t e r : blur (10 px ) ;
- m o z - f i l t e r : blur (10 px ) ;
}
f u n c t i o n a l t e r n a t e () {
$ ( " # a t t a c k - i f r a m e " )
. t o g g l e C l a s s ( " filter " ) ;
}
s e t I n t e r v a l ( alternate , time ) ;
1
2
3
4
5
6
7
8
9
10
11
12
13
14
We found that this attack also works in Firefox by using
an svg-image-blur eﬀect instead of webkit-ﬁlter, since Firefox
allows a user to apply SVG ﬁlters to DOM elements. As with
most web timing attacks, timing data is an approximation of
the true runtime of a process. Our attack is less noisy than
typical web application timing attack[4] though, since there
is no network latency or packet-loss involved.
The results in Figure 3 show how the relative size of a
page can be determined with CSS default ﬁlters. Notice
that the page when the user is logged in produces a diﬀerent
average framerate than the homepage when the user is not
logged in because their DOM trees are diﬀerent.
3.3 Pixel Stealing with CSS ﬁlters
Next we describe a general technique that we have discov-
ered can be used to read a ﬁeld of arbitrary pixels from the
user’s browser window. We ﬁll the screen with a single color
and examine the way in which the browser window’s average
framerate changes by reading it with requestAnimationFrame.
1058Figure 4: Using the same test that produced the bitmaps shown in Figure 5, we determined how accuracy
diﬀered across diﬀerent devices.
3.3.1 Focusing on a Single Pixel without anti-aliasing
We found that enlarging the pixel to the size of the user’s
screen exaggerated timing diﬀerences. This section describes
our technique.
to a borderless iframe. The iframe contains the webpage un-
der attack. By setting margin-left and margin-top to values
less than or equal to zero, diﬀerent oﬀsets onto the victim
page can be achieved.
Listing 4: Enlarging a single pixel
# m a l i c i o u s - i f r a m e {
o v e r f l o w : hidden;
width: 1 px;
height: 1 px;
m a r g i n - t o p : 0 px;
m a r g i n - l e f t : 0 px;
}
# p i x e l - c o n t a i n e r {
top: calc (50% - 1 px ) ;
left: calc (50% - 1 px ) ;
width: 1 px;
height: 1 px;
}
# p i x e l - c o n t a i n e r - c o n t a i n e r {
width: 999 px;
height: 999 px;
- w e b k i t - f i l t e r : custom ( url ( e n l a r g e . v s )
mix ( url ( e n l a r g e . f s ) ) , 4 4) ;
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
Next we position the iframe inside a div of class #pixel-
container. This div is centered inside its parent element,
#pixel-container-container. This class deﬁnes a CSS ﬁlter
that scales the pixel-sized iframe to a much bigger size. The
width and height are odd-valued to ensure that the single-
pixel iframe will be in the center.
3.3.2 Pixel Stealing
We use the above mechanism to traverse a bitmap of pix-
els by setting margin-top and margin-left in the malicious
iframe. Our attack performs arbitrary transformations on
the scaled pixel, determines the average framerate during the
transformations, and interprets the the resulting value for
each pixel. A pixel stealing attack occurs in the following way:
1. Expand a single pixel. The attacker builds a mech-
anism that can expand a pixel to the size of the user
agent’s screen.
2. Victim page is framed. The attacker frames a web-
site that has neglected to use X-Frame-Options.
To enlarge a pixel to the size of the screen without anti-
aliasing, we ﬁrst apply the style rules for #malicious-iframe
3. Vicitm visits malicious page. A victim user visits
the attacker’s malicious web page, and is tricked into
1059remaining on the page for the duration of the attack.
4. Page is traversed. In an attack, a malicious website
may want to traverse each pixel in a target region of the
intended website or in a target region of its source code.
An arbitrary transformation is repeatedly performed
on each pixel.
5. Average framerate is captured. RequestAnima-
tionFrame determines the average framerate on the
browser window for each target pixel.
6. Data is interpreted. An array of pixel measurements
are sent to the attacker’s server to be interpreted.
Collecting and interpreting pixel data turned out to be an
interesting problem by itself, and we tried several methods
that helped us understand the set of values returned by the
attack. The most successful attempt involved writing code
with a JQueryUI slider that could change the threshold that
separated black and white pixels, however writing a script
to interpret the pixel data for us proved to be more than
suﬃcient. The script interpreted values by deciding what
thresholds should be used to distinguish black and white
pixel framerates. Using a canvas element we could visually
examine the pixel values.
3.3.3 Our Results
We initially tested our pixel stealing idea by running black
and white pixels through shaders with arbitrary transforma-
tion matrices. Our intuition was if there existed two colors
that could create distinct timing channels, black and white
would be the most likely candidates. Our intuition turned
out to be correct.
A proof-of-concept attack involved recreating a 10 × 10
bitmap of black and white pixels to determine the timing
consistencies of a user’s device. A higher percent of correctly-
guessed pixels implies a more vulnerable user agent. Results
from this initial test indicated that stealing cross-origin pixels
could be achieved with high enough accuracy to make pixel
stealing attacks practical. We conducted tests that measured
each pixel’s color for 4, 12, and 20 seconds, and the results
are shown in Figure 5. Compare our results with the actual
bitmap in (d).
In this test, we counted the number of pixels that were
guessed correctly out of 100. If our attack was returning
random values, we would expect about 50 pixels to be correct
regardless of time spent per pixel. The chance that exactly
half of the pixels are guessed correctly is 50%. The chance
that more than 60% of a bitmap’s pixels are chosen correctly
on any given test is just 6%. Figure 4 shows accuracy for
various devices. Half of the setups we tried were vulnerable.
3.3.4 Possible Attack Scenarios in Practice
Once a bitmap of pixel colors can be determined over https,
attack possibilities are endless. The most interesting attack
we implemented involves stealing tokens of cross-origin text.
We were able to read a fake token that we retrieved across
origins. This token was stolen from a machine with an AMD
Radeon HD 6770 and Intel Core i7:
We also used our pixel stealing attack to implement history
sniﬃng. Until recently, a user’s history could be determined
(a) 4 secs
(b) 12 secs
(c) 20 secs
(d) original
Figure 5: The original pixel stealing tests (a), (b),
and (c) show how accuracy improves as the amount
of time (4, 12, and 20 seconds respectively) spent per
pixel is increased. (d) shows the original bitmap.
by simply adding a link to a page and determining its color
by calling getComputedStyle()[13] since visited links have
diﬀerent colors than non-visited links. Browsers will now lie
[21] if this function is called on a link.
The following attack can be used to determine whether or
not a user has visited a particular website:
1. Victim visits malicious page. The malicious page
initializes with a block of ascii text (say, ascii value
219) that hrefs to a website that is known to not exist.
2. Link is expanded. A pixel from the link is expanded
to the size of the user’s screen.
3. Data is collected. The malicious web page allows a
suﬃcient amount of time to pass while measuring the
page framerate using requestAnimationFrame.
4. Process is repeated. Steps 2-4 are repeated two
more times. The ﬁrst is for this page, which will return
results for a URL that we know the user has visited.
The second is for a URL we are curious about.
5. Data is analyzed. We can determine if the user vis-
ited the victim URL by comparing it with the framerate
of our two test URLs.
By using the pixel stealing technique described above, it
is possible to determine whether or not a user has visited a
website by analyzing a single pixel.
3.3.5 Complications and Solutions
We have found that the best results can be obtained when
the input pixel ﬁeld is restricted to black and white only. We
combined several ﬁlter eﬀects to achieve a close estimate of a
black and white transform. We ended up using the following
ﬁlter combination:
1060(a) Original Text
(b) Text after applying ﬁlters
(c) Stolen Text
Figure 6: (a) shows the original bitmap of anti-aliased pixels in Google Chrome for a text token. We applied
ﬁlters to approximate a black and white version of the token, shown in (b). Finally, (c) shows the cross-origin
token of text that we stole with our timing attack.
Listing 5: Filter eﬀects to achieve a close estimate
of a black and white transform
1
2
3
4
5
6
. b l a c k - a n d - w h i t e {
- w e b k i t - f i l t e r : s a t u r a t e (0%)
g r a y s c a l e (100%)
b r i g h t n e s s (69%)
c o n t r a s t (100%) ;
}
Notice in Figure 7 that without the use of these ﬁlter
eﬀects, non-black pixels are usually interpreted as white.
This sample of cross-origin HTML text is easily recognized
as the letter “h” in Figure 7, but without default ﬁlters,
many letters with curves such as “S” and “R” were nearly
impossible to read.
A ﬁnal challenge we faced with this attack was ﬁnding
a reasonable amount of time to spend on each pixel. It is
important that all pixels are read before the user closes his
or her browser window. To get a better understanding of
the accuracy achieved as a result of various amounts of time
spent per pixel on several graphics cards, see Figure 4. While
history sniﬃng or stealing small text tokens is possible in
practice, stealing medium-sized images or large tokens may
not be.
Under what conditions do the attacks fail? We determined
that running shaders in background tabs produces undesir-
able performance, and will cause an attack to fail. Running
the attack in a background window will have the same per-
formance results and an attack in the foreground. Running
the attack on a div or iframe element whose opacity equals
0.0 will not work, but covering it with another DOM does
work.
Figure 7: Attempts to read text without converting
to black and white made letter curvature diﬃcult to
capture.
work uses both default and custom ﬁlters to exploit timing
channels in rendering engines of various browsers. A paper
that cites the original version of this paper shows that the
timing attacks can also be performed with SVG ﬁlters [17].
An easy solution would be to simply place shaders and
ﬁlters under the restrictions of the Same-Origin Policy, but
this would entirely defeat the purpose of these features. This
would also likely be covering up a larger problem that is
present across multiple browsers. Creating awareness in the
security community seems like the best way to proceed.
4. CONCLUSIONS AND FUTURE WORK
In this paper we show that timing attacks using CSS ﬁlters
can reveal sensitive information such as text tokens. Our
5. ACKNOWLEDGEMENTS
We would like to thank Eric Chen and Lin-Shung Huang
for their guidance and support to our research.
10616. REFERENCES
[1] Adobe. Css shaders.
http://www.adobe.com/devnet/html5/articles/css-
shaders.html.
[2] A. Barth. Adam barth’s proposal.
http://www.schemehostport.com/2011/12/timing-
attacks-on-css-shaders.html.
[3] A. Barth, C. Jackson, C. Reis, and T. Team. The
security architecture of the chromium browser, 2008.
[4] A. Bortz and D. Boneh. Exposing private information
by timing web applications. In Proceedings of the 16th
international conference on World Wide Web, pages
621–628. ACM, 2007.
[5] Chromium. Gpu command buﬀer.
http://www.chromium.org/developers/design-
documents/gpu-command-buffer.
[6] Chromium. Graphics and skia.
http://www.chromium.org/developers/design-
documents/graphics-and-skia.
[7] CMU. Spatial data structures.
http://www.cs.cmu.edu/afs/cs/academic/class/
15462-f12/www/lec_slides/lec13.pdf.
[8] R. Crawﬁs. Mozilla window.requestanimationframe.
https://developer.mozilla.org/en-
US/docs/DOM/window.requestAnimationFrame.
[9] A. Deveria. Can i use css ﬁlter eﬀects?
http://caniuse.com/css-filters.
[10] E. W. Felten and M. A. Schneider. Timing attacks on
web privacy. In Proceedings of the 7th ACM conference
on Computer and communications security, pages
25–32. ACM, 2000.
[11] HTML5Rocks. Catch-all for html5 rocks website.
http://updates.html5rocks.com.
[12] R. Hudea, R. Cabanier, and V. Hardy.
enriching the web with css ﬁlters.
[13] C. Jackson, A. Bortz, D. Boneh, and J. C. Mitchell.
Protecting browser state from web privacy attacks. In
Proceedings of the 15th international conference on
World Wide Web, pages 737–744. ACM, 2006.
[14] P. C. Kocher. Timing attacks on implementations of
diﬃe-hellman, rsa, dss, and other systems. In Advances
in Cryptology—CRYPTO’96, pages 104–113. Springer,
1996.
[15] V. Kokkevis. Gpu accelerated compositing in chrome.
http://www.chromium.org/developers/design-
documents/gpu-accelerated-compositing-in-
chrome.
[16] I. LiTH. Painter’s algorithm. http://www.computer-
graphics.se/TSBK07-files/PDF12/6b.pdf.
[17] P. Stone. Pixel perfect timing attacks with html5.
http://www.contextis.com/files/Browser_Timing_
Attacks.pdf.
[18] W3. Css shader proposal.
https://dvcs.w3.org/hg/FXTF/raw-
file/tip/custom/index.html.
[19] W3. Shader security. http://www.w3.org/Graphics/
fx/wiki/CSS_Shaders_Security.
[20] Webkit. Accelerated rendering and compositing.
http://trac.webkit.org/wiki/Accelerated%
20rendering%20and%20compositing.
[21] Z. Weinberg, E. Y. Chen, P. R. Jayaraman, and
C. Jackson. I still know what you visited last summer:
Leaking browsing history via user interaction and side
channel attacks. In Security and Privacy (SP), 2011
IEEE Symposium on, pages 147–161. IEEE, 2011.
[22] S. White. Accelerated css ﬁlters landed in chromium.
http://blog.chromium.org/2012/06/accelerated-
css-filters-landed-in.html.
1062