1. Determine if the virtual machine responds to pings.
2. Check that the program is still accepting connections on port
31337.
3. Check for the existence of the ﬁle written by the application
(using the VMware Tools API).
If all tests pass, then φ returns true, indicating that the modiﬁca-
tion was accomplished without harming OS or program function-
ality. If instead φ returns false, then the OS has crashed or some
aspect of the program associated with our EPROCESS instance has
stopped functioning. This latter case indicates that the OS will not
accept arbitrary values for the ﬁeld, and provides evidence that we
can safely build a signature based on the ﬁeld.
5.2 Signature Generation and Evaluation
Finally, we generated a signature using the method described in
Section 4.3. The features chosen were the 15 most robust, as mea-
sured by the tests done during the fuzzing stage. For each of these
ﬁelds, we extracted from our corpus of memory images (our train-
ing set) a list of the values it contained for all processes found in
the image. The four images in the training set were not infected
by malware, and were taken from systems running the 32-bit ver-
sion of Windows XP, Service Pack 2. Processes were located in the
memory image by walking the operating system’s process list; in
the absence of maliciously hidden processes, this serves as “ground
truth” for the list of valid process data structures. We then used our
signature generator to ﬁnd constraints on the observed values. The
signature generator outputs a plugin for Volatility that can be used
to search for a data structure matching the constraints found in a
memory image.
The generated scan plugin was used to search for processes in
a number of memory images. For this purpose, we used two im-
ages provided by the NIST Computer Forensic Reference Data Sets
(CFReDS) project [27] and a paused virtual machine on which a
process had been hidden by our own custom rootkit. The num-
ber of false positives and negatives were measured for each test
572Field
ThreadListHead.Blink
Pcb.Header.Type
Pcb.Header.Size
WorkingSetLock.Header.Type
WorkingSetLock.Header.Size
AddressCreationLock.Header.Type
AddressCreationLock.Header.Size
Used by
Volatility (psscan2)
PTFinder
PTFinder
PTFinder
PTFinder
PTFinder
PTFinder
Table 2: Fields zeroed by our modiﬁed FU Rootkit, along with
the scanners that depend on that ﬁeld.
image, and compared against two existing signature-based tools,
PTFinder [36] and Volatility’s psscan2 module.1
Our custom malware, which is a slightly modiﬁed version of the
FU Rootkit [7], hides processes using DKOM (as in the original
FU), and additionally attempts to evade known process signatures
by zeroing non-essential ﬁelds in the process data structure. The
ﬁelds modiﬁed, shown in Table 2, were chosen by ﬁnding those
ﬁelds that were used by common scanners but that our initial struc-
ture proﬁling indicated were unused by the OS.
6. RESULTS
The experimental results are given below. We describe the out-
come of proﬁling twenty different applications and present the re-
sults of the fuzzing stage. These features are used by the signature
generator to ﬁnd constraints and create a new process scan module
for Volatility. Finally, we compare the accuracy of our scanner with
other popular scanners.
Throughout, we also consider what our results tell us about the
features used by another popular signature (PTFinder’s signature
for EPROCESS). We ﬁnd that after fuzzing and proﬁling, only two
of its nine features are resistant to evasion; the remaining invariants
are not sufﬁcient to avoid matching random portions of memory.
6.1 Proﬁling
After proﬁling the twenty applications described in Section 5.1,
we can conﬁrm our hypothesis that some ﬁelds are accessed only
rarely, if ever. Of the 221 ﬁelds in the EPROCESS data structure, 32
were never accessed during the execution of the proﬁled programs.
At the other extreme, 72 were accessed for every application and
are thus strong candidates for a process signature. In between are
117 ﬁelds that were accessed by some programs, but not others;
Figure 6(a) gives a histogram detailing precisely how many pro-
grams accessed each ﬁeld.
Included in the 32 ﬁelds that were never accessed are three of
the nine used by PTFinder to locate processes in memory dumps; a
further four are only accessed by a subset of the programs proﬁled
(the proﬁling results for the ﬁelds used by PTFinder are shown in
Figure 6(b)). Because the signature used in PTFinder is conjunctive
(all of its constraints must be met in order to report a match), and
the attacker has complete control over three of the ﬁelds used in
the signature, we can conclude that this signature can be trivially
evaded. The features chosen by PTFinder’s author did not corre-
spond to those used by the OS, demonstrating that human judgment
may not be sufﬁcient to determine what ﬁelds are appropriate for
use in data structure signatures.
9 1Note that Volatility also includes a process scanner called
psscan. This scanner uses the same constraints as PTFinder, and
hence is vulnerable to the same evasions, so we do not consider it
here.
Field
ActiveProcessLinks.Flink
Pcb.DirectoryTableBase[0]
Pcb.ThreadListHead.Flink
Token.Value
Token.Object
VadHint
UniqueProcessId
Z R P A Total
20
5
5
20
20
5
18
5
16
5
12
5
1
12
5
5
5
5
5
5
5
5
5
5
5
5
2
5
5
5
5
3
1
0
1
Table 3: Selected EPROCESS ﬁelds and the results of fuzzing
them. The values indicate the number of times a given test
caused φ to return false, indicating that the OS or program
had stopped working correctly. The columns indicate number
of OS crashes when testing with the Zero, Random, Random
Primitive, and Random Aggregate patterns.
6.2 Fuzzing
We then took the 72 ﬁelds identiﬁed as always accessed during
the proﬁling stage and fuzzed them using the four different data
patterns (zero, random, random primitive, and random aggregate),
modifying each ﬁeld with each pattern ﬁve times, for a total of
1,440 distinct tests. The overall number of failed tests for each
ﬁeld is shown in Figure 7. However, this does not provide a full
picture of the fuzzing results, as it is also important to note which
data patterns caused the OS to fail. It may be acceptable to use a
ﬁeld in a signature even if it is possible to write zeroes to that ﬁeld,
for example, because the constraint could include zero as a special
case. We have, therefore, included several sample ﬁelds in Table 3,
in order to give an idea of what the result data looks like.
We ﬁnd, as expected, that there are many “essential” ﬁelds upon
which we may base our signature. Five ﬁelds failed every attempt
at manipulation, and a further 12 failed more than half of the tests
(i.e., more than 10). This will give us a set of robust features that is
large enough to ensure that the number of false positives found by
the signature is minimized.
As in the proﬁling stage, we also note that these results give us
a very strong indication of what ﬁelds not to choose. Of the 72
ﬁelds from proﬁling, 29 passed every test (their modiﬁcation did
not result in any loss of functionality); these, again, would be a
poor basis for a signature as their values can be controlled by an
attacker.
6.3 Signature Accuracy
With a list of robust features in hand, we used our signature gen-
erator to ﬁnd constraints on the values of each feature. The ﬁeld
values were collected from 184 processes across the four images in
our training set and constraints were inferred using the templates
described in Section 5.2, producing the constraints shown in Ta-
ble 4. The signature generator produced a plugin for Volatility that
uses the constraints found to search for EPROCESS instances in
memory images.
We then evaluated the accuracy of three process scanners: our
own automatically generated scanner, Volatility’s psscan2 mod-
ule, and PTFinder [36]. Using each scanner, we searched for in-
stances of the EPROCESS data structure in the three memory im-
ages listed in Section 5.2. The output of each tool was compared
against the OS’s list of running processes (found by walking the
linked list of process data structures using Volatility’s pslist
module). In the case of the non-NIST image, we also checked for
the presence of our hidden process, which was not visible in the
standard OS process list.
We found that all three scanners had equal detection performance
5739(a) Number of proﬁled programs in which EPROCESS ﬁelds were accessed. Only ﬁelds accessed by all 20 programs provide the
strongest assurance for use in a signature.
9(b) Access prevalence of ﬁelds used by PTFinder’s EPROCESS signature. Note that the signature relies on ﬁeld values never used
by the OS, so an attacker can safely change these values to evade the signature.
Figure 6: Access prevalence for EPROCESS for proﬁled applications.
Figure 7: Fuzzing results for EPROCESS. The y-axis represents the total number of tests for which φ returned false, indicating that
the process was no longer functioning correctly. Higher bars indicate stronger features.
on the NIST images and found every process data structure with
no false positives. However, only our own scanner was able to
detect the hidden process in the third image, demonstrating that an
attacker could potentially evade both psscan2 and PTFinder with
minimal effort. We believe our signature will also prove resistant
to evasion against real-world attackers, as the features it uses are
demonstrably difﬁcult for an attacker to alter.
Aside from the active processes in the images, we also noted
some discrepancies between the three scanners with respect to ter-
minated processes whose EPROCESS structure was still in memory
and had not yet been overwritten. Although PTFinder and psscan2
were vulnerable to the evasion by our custom malware, they also
found these terminated processes, which our scanner missed.
As terminated processes could be of forensic interest, we checked
whether there was some subset of our “robust” features that would
ﬁnd such processes without introducing false positives. By mod-
ifying our scanner to report the result of each constraint for the
terminated processes, we found that Windows appears to zero the
Unused 5 10 15 20 0 50 100 150 200Access PrevalenceField NumberUnusedby OSUnused 5 10 15 20 0 50 100 150 200Access PrevalenceField NumberUnusedby OSUnusedNot tested 5 10 15 20 0 50 100 150 200Number of FailuresField NumberFuzzing Results for EPROCESSUnusedby OS574Field
Pcb.ReadyListHead.Flink
Pcb.ThreadListHead.Flink
WorkingSetLock.Count
Vm.VmWorkingSetList
VadRoot
Token.Value
AddressCreationLock.Count
VadHint
Token.Object
QuotaBlock
ObjectTable
GrantedAccess
ActiveProcessLinks.Flink
Peb
Pcb.DirectoryTableBase.0
Constraint
val & 0x80000000 == 0x80000000 && val % 0x8 == 0
val & 0x80000000 == 0x80000000 && val % 0x8 == 0
val == 1 && val & 0x1 == 0x1
val & 0xc0003000 == 0xc0003000 && val % 0x1000 == 0
val == 0 || (val & 0x80000000 == 0x80000000 && val % 0x8 == 0)
val & 0xe0000000 == 0xe0000000
val == 1 && val & 0x1 == 0x1
val == 0 || (val & 0x80000000 == 0x80000000 && val % 0x8 == 0)
val & 0xe0000000 == 0xe0000000
val & 0x80000000 == 0x80000000 && val % 0x8 == 0
val == 0 || (val & 0xe0000000 == 0xe0000000 && val % 0x8 == 0)
val & 0x1f07fb == 0x1f07fb
val & 0x80000000 == 0x80000000 && val % 0x8 == 0
val == 0 || (val & 0x7ffd0000 == 0x7ffd0000 && val % 0x1000 == 0)
val % 0x20 == 0
Table 4: Constraints found for “robust” ﬁelds in the EPROCESS data structure. The operators shown have the same meaning as
in C; % stands for the mod operation, and & represents bitwise AND. && and || are the boolean operators for “and” and “or”,
respectively.
Token.Object and Token.Value ﬁelds, which refer to the
process’s security token, when the process exits. Once we removed