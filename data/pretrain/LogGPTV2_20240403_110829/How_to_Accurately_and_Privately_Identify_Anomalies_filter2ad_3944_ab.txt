each record in the data for private AId. All the green (nor-
mal) points in (d) are at the same level as all the points in (e).
2 PRELIMINARIES AND NOTATION
Database: We consider a database as a multiset of elements from
a set X, which is the set of possible values of records. In a database,
we assume each record is associated with a distinct individual. We
represent a database x as a histogram in D = {y ∈ NX : ||y||1  0, a mech-
anism M with domain D is ε-differentially private if for every
x, y ∈ D such that ||x − y||1 ≤ 1, and every R ⊆ Ranдe (M ),
P (M (x ) ∈ R) ≤ eε P (M (y) ∈ R) .
We implicitly assume that the R’s are chosen such that the events
“M (x ) ∈ R” are measurable.
(cid:80)
Anomalies: For any database x, record i ∈ X, r ≥ 0, and a
xj, and
distance function d : X × X → R≥0, Bx (i, r ) =
define (β, r )-anomaly as follows.
j∈X:d (i, j )≤r
Definition 2.2 ((β, r )-anomaly [35]). For a given database x and
record i, we say i is a (β, r )-anomaly in the database x if i is present
in x, i.e. xi > 0, and there are at most β records in x that are within
distance r from i, i.e. Bx (i, r ) ≤ β.
Session 3E: Privacy IICCS ’19, November 11–15, 2019, London, United Kingdom721(a)
(b)
(c)
Figure 3: (a)-(c), the plot is for the same data. The two axes
give the coordinate of a point (record). The color gives the
level of privacy, i.e. the value e−ε , for 0.25-SP AIQ for every
record (the data was generated using generated using the dis-
tribution given in Figure 2). (a), k = 1. (b), k = 7. (c), k = 14.
Whenever we refer to a (β, r )-anomaly, we assume there is an
arbitrary distance function d over X × X.
Anomaly identification: Let us now introduce the important
and related notion of anomaly identification function, д : X × D →
{0, 1}, such that for a given anomaly definition, every record i ∈
X and database x ∈ D, д(i, x ) = 1 if and only if i is present
in x as an anomalous record (note that no change is made to x).
This formulation is extensible to the case where the database over
which anomaly identification is performed is considered to include
the record for which anomaly identification is desired. Here, the
anomaly identification for a record i over a data x can be computed
over the database that consists of all the records in x as well as the
record i
1.
Private anomaly identification query (AIQ):. Here, all the
private mechanisms we consider have domain D. Thus, we will
consider the anomaly identification query to be for a fixed record.
We will specify this by the pair (i, д), where i is a record and д an
anomaly identification function. Now a private anomaly identifi-
cation mechanism, M : D → {0, 1}, for a fixed AIQ, (i, д), can be
represented by its distribution, where for every x, P (M (x ) = д(i, x ))
is the probability the M output correctly, and P (M (x ) (cid:44) д(i, x )) is
the probability that M errs on x.
3 SENSITIVE PRIVACY
Our notion of sensitive privacy requires privacy protection of every
record that may be normal under a small change in the database.
1Note that alternatively one could have defined д without predicating on the existence
of i in x. By dropping the predicate on the existence of i, we in effect blur the distinction
between the notion of a void spot (that in a different database could have been occupied
by a record) in the database and the notion of an anomaly.
We use the notion of normality property p to identify the normal
records that exist in the database. Formally, for a given definition of
anomaly, a normality property, p : X × D → {0, 1}, is such that for
every record i and database x, p(i, x ) = 1 if and only if i is present
in x as a normal record. Note that the normality property is not the
negation of anomaly identification function because for the absent
records p = 0 (same as those which do not satisfy the property). We
formalize the notion of small change in the database as the addition
or removal of k records from the database. We consider this change
to be typical and want to protect the privacy of every record that
may become normal under this small change in the database.
We now formalize the key notion of sensitive record. For a fixed
normality property, all the records whose privacy must be protected
are termed as sensitive records.
Definition 3.1 (sensitive record). For k ≥ 1 and a normality prop-
erty p, we say a record i is k-sensitive with respect to a database x
if, for a database y, ||x − y||1 ≤ k and p(i, y) = 1.
Next, we give a couple of definitions of the graphs we consider
here. A neighborhood graph, G = (D, E), is a simple graph such
that for every x and y in D, (x, y) ∈ E ⇐⇒ ||x − y||1 = 1. One
of the important notions in this work is k-sensitive neighborhood
graph, GS = (D, E′), for k ≥ 1 and a normality property, which
is a subgraph of the neighborhood graph, G = (D, E), such that
for every (x, y) ∈ E, (x, y) ∈ E′ ⇐⇒ for some i ∈ X, |xi −
yi| = 1 and i is k-sensitive with respect to x or y. Further, the two
databases connected by an edge in a (sensitive) neighborhood graph
are called neighbors. With this, we can state the notion of sensitive
privacy. Note that the k-sensitive neighborhood graph is tied to the
normality property, and hence, the anomaly definition.
Definition 3.2 (sensitive privacy). For ε > 0, k ≥ 1, and normality
property, a mechanism M with domain D is (ε, k )-sensitively pri-
vate if for every two neighboring databases x and y in k-sensitive
neighborhood graph, and every R ⊆ Ranдe (M ),
P (M (x ) ∈ R) ≤eε P (M (y) ∈ R)
We omit k when it is clear from the context. The above condition
necessitates that for every two neighbors, any test (i.e., event) one
may be concerned about, should occur with “almost the same prob-
ability”, that is, the presence or the absence of a sensitive record
should not affect the likelihood of occurrence of any event. Here,
“almost the same probability” means that the above probabilities
are within a multiplicative factor eε . The guarantees provided by
sensitive privacy are similar to that of differential privacy. Sensitive
privacy guarantees that given the output of the private mecha-
nism, an adversary cannot infer the presence or the absence of
a sensitive record. Thus for neighboring databases in a sensitive
neighborhood graph (GS ), the guarantee is exactly the same as
in differential privacy. If x and y differ by one record, which is
not sensitive, then they are not neighbors in GS , and the guar-
antee provided by sensitive privacy is weaker2 than differential
privacy, nevertheless, has the same form. So, intuitively, if we only
consider the databases, where all the records are sensitive, then
differential privacy and sensitive privacy provide exactly the same
2“Weaker” means that every mechanism which is ε-DP is also ε-SP, but in general not
the other way around.
Session 3E: Privacy IICCS ’19, November 11–15, 2019, London, United Kingdom722guarantee. In general, every (ε, k )-SP mechanism M for GS satisfies
P (M (x ) ∈ R) ≤ P (M (y) ∈ R)eεdGS (x,y ) for every x, y and R, where
is the shortest path length metric over GS .
dGS
Similar to differential privacy, ε is the privacy parameter: the
lower its value, the higher the privacy guarantee. The parameter k
,which is associated with the sensitive neighborhood graph, pro-
vides a way to quantify what is deemed as a small change in the
database, which varies from field to field, but nevertheless in many
common cases can be quantified over an appropriate metric space.3.
When we increase the value of k, we move the boundary between
what is considered sensitive and what is non-sensitive (Figure 3,
where the plots are similar to the ones given in Figure 2d for the
same parameter values but for varying k): higher the value of k,
the more records are considered sensitive, and therefore, must be
protected. This is due to the fact that, for any k ≥ 1, if a record is
k-sensitive with respect to a database x, it is also (k + 1)-sensitive
with respect to x. For example, with respect to a database x, a 2-
sensitive record, may not be 1-sensitive, but a 1-sensitive record
will also be 2-sensitive.
3.1 Composition
Our formalization of sensitive privacy enjoys the important proper-
ties of composition and post-processing [18], which a good privacy
definition should have [32]. Hence, we can quantify how much
privacy may be lost (in terms of the value of ε) if one asks mul-
tiple queries or post-processes the result of a private mechanism.
Here, we recall that sensitive privacy is defined with respect to the
k-sensitive neighborhood graph for the privacy parameter ε. Thus,
the privacy composes with respect to both, the privacy parameter
(i.e. ε) and the sensitive neighborhood graph.
Sequential composition provides the privacy guarantee over mul-
tiple queries over the same database, where the same record(s) in
the database may be used to answer more than one query. Consider
two mechanisms M1 : D → R, which is ε1-sensitively private for k1-
sensitive neighborhood graph GS1 = (D, E1), and M2 : D×R → R′,
which is ε2-sensitively private for k2-sensitive neighborhood graph
GS2 = (D, E2), with independent sources of randomness. Recall
that for a private mechanisms for AIQ, (i, д), is fixed; thus M1 and
M2 may correspond to different records and anomaly identification
function. Now, M2 (x, M1 (x )) (for every database x) is (ε1 + ε2)-
sensitively private for GS = (D, E1∩ E2) (Claim 3). One application
of this is that for a fixed GS , even performing multiple queries in-
teractively will lead to at most a linear loss (in terms of ε) in privacy
in the number of queries—in an interactive query over a database
x, one firstly gets the answer of M1, i.e., M1(x ), and based on the
answer, one selects M2 and gets its answer. Furthermore, for a fixed
normality property, if k1 ≤ k2 then GS1 is a subgraph of GS2, then
M2 is (ε1 + ε2)-sensitively private for GS1.
Parallel composition deals with multiple queries, each of which
only uses non-overlapping partition of the database. Let X = Y1∪Y2
such that Y1 ∩ Y2 = ∅. Now, consider M1 and M2, each with do-
main D, that are respectively ε1-sensitively private for GS1 and ε2-
sensitively private for GS2, where GS1 is a subgraph of GS2. Further,
3The metric space we are using for anomaly identification has a rather complicated
structure, but it is induced by formalizing our intuition for sensitive records.
M1 and M2 only depend on their randomness (each with its indepen-
dent source) and records in Y1 and Y2 respectively. In this setting, a
mechanism M (x ) = (M1(x ), M2 (x )) is max(ε1, ε2)-sensitively pri-
vate for GS1, or in general case for sensitive neighborhood graph
(D, E1 ∩ E2) (Claim 4), where E1 and E2 are the sets of edges for
GS1 and GS2 respectively.
We also remark that privacy is maintained under post-processing.
Example: Consider composition for sensitive privacy for the
case of multiple (β, r )-AIQs. Let us say we answer anomaly iden-
tification queries for records i1, i2, . . . , in respectively for (β1, r1),
(β2, r2), . . . ,(βn, rn ) anomalies over the database x, while providing
sensitive privacy. Let the mechanism for answering (βt , rt )-AIQ
for it be εt -SP for kt -sensitive neighborhood graph corresponding
to (βt , rt )-anomaly, and assume it depends on the partition of the
database that contains the records within distance rt of it (because
it suffices to compute (βt , rt )-AIQ) and its independent source of
randomness. Let k = min(k1, . . . , kn ), β = max(β1, . . . , βn ), and
r = min(r1, . . . , rn ). In this case, the sensitive privacy guarantee for
answering all of the queries is mε for k-sensitive neighborhood graph
corresponding to (β, r )-anomaly, where m is the maximum number
of it ’s that are within any ball of radius max(r1, . . . , rn ) (Claim 5).
Thus, from the above, it follows that if we fix β, r and k and allow
a querier to ask m many (β′, r )-AIQ’s (each may have a different
value for β′) such that β′ ≤ β, then we can answer all of the queries
with sensitive privacy mε in the worst case for k-sensitive neighbor
for to (β, r )-anomaly. The same is true if the queries are for (β, r′)
with r′ ≥ r. Furthermore, for fixed β, r and k, answering (β, r )-AIQ
for i and i′ such that d (i, i′) > 2r still maintains (ε, k )-SP. One may
employ this to query adaptively to carry out the analysis while
providing sensitive privacy guarantees over analysis as a whole.
4 PRIVACY MECHANISM CONSTRUCTIONS
In this section we will show how to construct a private mechanisms
for (β, r )-anomaly identification. Specifically, (i) we will give an
SP mechanism that errs with exponentially small probability on
most of the typical inputs (Theorem 4.6), (ii) we will provide a
DP mechanism construction for (β, r )-AIQ, which we will prove is
optimal (Theorem 4.4), (iii) we will present a compiler construction
that can compile a “bad” DP mechanism for AIQ to a “good” SP
mechanism (Theorem 4.7) – here good and bad are indicative of
utility. We will use these mechanism to evaluate the performance
of our method over real world and synthetic datasets.
Recall that a privacy mechanism, M : D → {0, 1}, for a fixed
AIQ, (i, д), will output the labels of i for the given database, where
д is an anomaly identification function and i is a record. The
sensitive privacy requires that the shorter the distance between
any two databases, x and y, in the sensitive neighborhood graph
(GS ), the closer the probabilities of any output (R) of the mech-
anism M corresponding to the two databases should be, that is,
−ε dGS (x,y ) ≤ P(M (x ) = R)/P(M (y) = R) ≤ eε dGS (x,y ). Thus,
e
for an x, the greater is the distance to the closest y such that
д(i, x ) (cid:44) д(i, y), the higher accuracy a private mechanism can
achieve on the input x for answering д(i, x ). We capture this metric-
based property by the minimum discrepant distance (mdd) function.
Session 3E: Privacy IICCS ’19, November 11–15, 2019, London, United Kingdom723Figure 4: Sensitive neighborhood graph. A simple example of a 1-sensitive neighborhood graph, GS , with X = {1, 2, 3, 4, 5}, ℓ1-
metric over X × X, and (β = 3, r = 1)-anomaly. Note that GS is an undirected graph; arrowheads indicates the record is added
at the end node; the color of the edge corresponds (as per the given color code) to the value of the record added. Further, each
database x is represented as a 5-tuple with xi for i ∈ X representing the number of records in x that have value i.
Fix an anomaly identification function д. For a given sensitive neigh-
borhood graph GS , ∆GS
mdd-function, and in most realistic settings, the size of X is large,
and the sensitive neighborhood graph is quite complex.
is mdd-function, if for every i and x,
∆GS (i, x ) =
min
y∈D:д(i,y )(cid:44)д(i,x )
dGS (x, y)
(1)
A simple and efficient mechanism for anomaly identification that
is both accurate and sensitively private can be given if д and the
(the corresponding mdd-function) can be computed efficiently.
∆GS
However, computing the mdd-function efficiently for an arbitrary
anomaly definition is a non-trivial task. This is because the metric,
, which gives rise to the metric-based property captured by
dGS
the mdd-function, is induced by (a) the definition of anomaly (e.g.