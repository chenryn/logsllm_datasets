title:Can You Trust Your Encrypted Cloud?: An Assessment of SpiderOakONE's
Security
author:Anders P. K. Dalskov and
Claudio Orlandi
Can You Trust Your Encrypted Cloud?
An Assessment of SpiderOakONE’s Security
Anders P. K. Dalskov, Claudio Orlandi
Aarhus University, Aarhus, Denmark
January 11, 2018
Abstract
This paper presents an independent security review of a popular en-
crypted cloud storage service (ECS) SpiderOakONE. Contrary to previous
work analyzing similar programs, we formally deﬁne a minimal security
requirements for conﬁdentiality in ECS which takes into account the pos-
sibility that the ECS actively turns against its users in an attempt to
break the conﬁdentiality of the users’ data.
Our analysis uncovered several serious issues, which either directly or
indirectly damage the conﬁdentiality of a user’s ﬁles, therefore breaking
the claimed Zero- or No-Knowledge property (e.g., the claim that even
the ECS itself cannot access the users’ data). After responsibly disclosing
the issues we found to SpiderOak, most have been ﬁxed.
Introduction
1
More and more users worldwide choose to store their data using cloud storage
services such as Dropbox, Google Drive, Microsoft Azure, etc. (Dropbox alone
recently celebrated reaching half a billion users.1) These services give users
a transparent way to share their data between multiple devices, they allow to
share ﬁles between users, and provide a relatively cheap way for keeping personal
backups in the cloud.
Unfortunately, “classic” cloud storage solutions provide little or no guarantee
about the conﬁdentiality of the data that the users choose to store in the cloud.
While most of these services guarantee that the data is encrypted in transit
to protect against a network eavesdropper, no mechanism prevents the storage
provider itself from accessing the users’ data. (In fact, the economic viability of
some of these systems relies on being able to identify multiple copies of the same
data being stored, and thus being able to implement deduplication techniques.
However, using de-duplication might allow attackers to learn information about
1https://blogs.dropbox.com/dropbox/2016/03/500-million/ (all links last retrieved on
December 20th 2017)
1
other users’ data. See [19] for a description of the problem and [18, 25] for some
cryptographic solutions which allow to perform de-duplication in a secure way.)
Moreover, data that is being stored unencrypted is more vulnerable to data
breaches, whether that be from a malicious outsider, malicious insider or gov-
ernment sponsored actor. (According to [15], of the 1792 breaches in 2016 only
75, or 4.2%, used encryption in part or full.)
All of these factors lead to an increased interest in password-encrypted cloud
storage services that oﬀer to store the user’s data in an encrypted format, in
such a way that even the service provider themselves cannot access the users’
data. This is a very useful property, which has an important impact against
several interesting threat models: if the service provider is technically unable to
access the user’s data, the provider cannot be coerced (e.g., by law enforcement)
to reveal the content of the user’s encrypted storage; also, since the users’ data
is only stored in encrypted format (and the password is unknown to the server),
even if someone could gain access to the cloud storage system, this would not
help in compromising the users’ data.
SpiderOak 2 is among the most popular encrypted cloud storage services
oﬀering end-to-end encrypted cloud storage. SpiderOak received popular at-
tention after being endorsed by Edward Snowden as a secure alternative to
Dropbox [27], and has received positive reviews by the EFF [14]. SpiderOak in
particular marketed their product using the term Zero-Knowledge (now replaced
by No-Knowledge [31]), capturing the property that even SpiderOak themselves
have no way of accessing the content of the encrypted users’ storage.
In a nutshell, virtually every encrypted cloud storage, including SpiderOak,
stores the users’ data encrypted under a user chosen password. Therefore,
whether this No-Knowledge property holds ultimately relies on two factors:
1. The user must choose a strong password; and
2. The user’s password must never leave the client’s software.
Much has been written about the (in)ability of users to choose strong pass-
words (e.g., [7]), so we will not address this threat further in this paper. What
is perhaps more interesting, from a technical point of view, is to look at the
service provider’s choices in protocol design and software implementation to
ensure that no one, not even the service provider itself, can extract the user’s
password from the client software. SpiderOak is very explicit about this: for
instance, users attempting to login using the web interface (which would reveal
the password to the server) are required to acknowledge the following message3:
I understand that for complete ’Zero-Knowledge’ privacy, I should
only access data through the SpiderOak desktop application.
2https://spideroak.com/
3https://spideroak.com/browse/login/storage
2
1.1 Contributions and Paper Organization
The main contribution of this paper is to present an independent security review
of the SpiderOakONE client software with the goal of examining the Zero- or
No-Knowledge claim from the perspective of a malicious service provider. We
believe that independent security reviews of real world systems is very important
towards the goal of improving user’s privacy.
In Section 2 we provide a simple and formal deﬁnition of what kind of ba-
sic conﬁdentiality should be provided by a password-encrypted cloud storage
service. We believe that our deﬁnition represents the minimal guarantees that
such a service should provide, and we argue for why this is the case. To the best
of our knowledge, this is the ﬁrst such deﬁnition, since neither SpiderOak, nor
other password-encrypted cloud storage services have ever provided formal def-
initions of which security guarantees they provide (in particular, only intuitive,
high-level and therefore ambiguous descriptions of what Zero- or No-Knowledge
means could be found): therefore, we believe that our deﬁnition can be used as
a benchmark in future analysis of other password-encrypted services and will
have a tangible and concrete eﬀect in practice on the design of such services.
As an example of this, we note that SpiderOak published a piece on this more
comprehensive threat model [34], partially inspired by our work.
In Section 3 we describe how SpiderOakONE is implemented, what systems
it runs on and what version we analysed. We then describe how the applica-
tion was reverse engineered and analysed. This description comprises both the
implementation and how the client application was reverse engineered, as well
as the choice of protocols and primitives. We show that decompilation is fairly
easy and that therefore future audits can be preformed without access to the
source code.
Since SpiderOak provides only a very superﬁcial description of its application
(cf. their whitepaper [33]), our description ﬁlls this hole and could serve as a
stepping stone for in-depth analysis of the application’s mode of operation in
the future.
Our main results can be found in Section 4, where a series of attacks that
can be carried out against SpiderOak users in our threat model are presented.
We stress that these attacks are not possible just because of implementation
“bugs”, but because of the design choices made in the development of the system.
Therefore, these attacks teach us what threats and pitfalls should be avoided
and should serve as motivation for careful vetting of applications that make
strong claims with regard to security—not just for their users but also for their
developers.
We hope that the attacks we present will motivate more research into the
security encrypted cloud storage application, when the ECS is considered as
potentially malicious. In particular, just like SpiderOak claims4 that only the
4https://support.spideroak.com/hc/en-us/articles/115001855103-No-Knowledge-
Explained
3
user can read their ﬁles, so does e.g., Tresorit5 and LastPass6.
Responsible Disclosure We have communicated our ﬁndings to the security
team of SpiderOak on April 5th, 2017. On June 5th 2017 SpiderOak released a
new version of the software which resolves most of the issues described in this
paper. SpiderOak notiﬁed their users by email and released a blog post about
this [35]. We ﬁnd it commendable that SpiderOak has reacted so swiftly to the
issues we found.
1.2 Related Work
Previous analysis’ of SpiderOakONE has focused on its shared directory func-
tionality (i.e., ShareRooms) and only in the presence of an external attacker.
In [6] Bharagavan and Delignat-Lavaud demonstrate a Cross Site Request Forgery
attack on the ShareRoom functionality due to a lax cross-origin policy. Bansel
et al. later provide a formal modelling of this attack using ProVerif in [2]. Wilson
and Ateniese show in [39] that the ShareRoom functionality reveals the shared
ﬁles to the server, in addition to the intended recipient. Our work shows that,
in addition to the shared ﬁles being readable by the server, some ﬁles that are
not shared (i.e., not part of the directory being shared) might also be revealed.
Several attacks against Cloud Storage Services that use deduplication was
described in [19] and [29]. However, SpiderOak does not do deduplication [33]
(see also Section 3.4).
Password managers can be seen as a special case of encrypted cloud storage
applications. In this direction, Li et al. conducted in [28] a security analysis of
ﬁve popular web-based password managers and found in four out of ﬁve cases
that attackers could learn arbitrary credentials.
In [3] Belenko and Sklyarov
show that mobile password managers often provide little or no protection.
In the context of ECS in general: Virvisil et al. [38] provide a brief survey of
challenges and solutions for secure cloud storage. An extensive survey of some
cloud storage application can be found in [8]. The description we provide of
SpiderOakONE (Section 3 and the Appendix) can be seen as complementary to
this previous work.
Kamara et el. provide in [23] a description of how to build ECS using stan-
dard cryptographic tools. Like us, they assume that the client is trusted, while
the server is not. A similar assumption exists in [37] (so called “internal adver-
saries” in their work).
2 Security Model
In this section we provide a formal deﬁnition capturing a basic conﬁdential-
ity security requirement for ﬁles stored on a password-encrypted cloud storage
5https://tresorit.com/security
6https://lastpass.com/whylastpass_technology.php
4
service (or PECS for short). The deﬁnition is designed to capture the mini-
mal security guarantees that a PECS should provide, and we believe it can be
used as a simple benchmark against which other PECS can be tested. The def-
inition does not attempt to capture every possible security requirements for a
PECS: in particular, the deﬁnition does not capture hiding the access pattern
(which could be achieved using tools such as Oblivious RAM [17, 36]), nor does
it capture retriviability (which could be addressed using proofs of retrievabil-
ity [21, 36]), integrity, or several other properties which could be desirable in an
PECS context.
The deﬁnition will follow the standard game-based approach typically used
in cryptography, and will resemble the common notion of CCA security, and the
way we deal with password encrypted data is inspired by [5, 40].
In our abstraction we model a PECS as a pair of interactive systems Cli, Ser
which can run a number of diﬀerent subprotocols (described below). We use
the standard notation (oC; oS) ← π(iC; iS) to denote an interactive protocol
between Cli and Ser, where (iC, oC) represent the input and output of Cli, and
(iS, oS) represent the input and output of Ser. We denote by ⊥ an empty
input/output.
Server Init: The function st0 ← Init() is used to initialize the server state.
All other subprotocols will take as input the current state of the server
sti and output an updated state sti+1 (as a notational convenience, we
assume that the state contains the complete view of the server in each
subprotocol and that sti+1 ⊇ sti i.e., no information is ever erased from
the server’s state);
Password Registration: Running (pw; sti+1) ← πreg(κ; sti) the client can reg-
ister a password of strength κ on the server; After this step the server’s
state contains a hashed version of the password h = H c(pw), where c spec-
iﬁes the number of iterations of the hash function/random oracle H. The
password registration command can be issued multiple times, to capture
the fact that a user might want to change password during the lifetime of
the system.
File Storage: Running (⊥; sti+1) ← πsto(pw, f, id; sti) a client can store a ﬁle
f with identiﬁer id using the current password pw on the server;
Other Commands: Depending on the speciﬁc PECS system, a number of
other commands will be implemented using sub-protocols (oC; oS) ←
πcmd(pw, id1, . . . , id(cid:96); sti) which take as input the current client’s password
and zero or more ﬁle id’s. As a result the server state might be updated.
We divide the commands in non-revealing commands πnrc, capturing the
fact that these commands should not reveal any information about the
content of the ﬁles to the server, and in revealing commands πrev, captur-
ing the fact that when using these commands the server is allowed to learn
the content of the involved ﬁles. Examples of common non-revealing com-
mands include client authentication (login), retrieving a ﬁle at the client
5
side, and moving or deleting a ﬁle at the server side; examples of common
revealing commands include public sharing or declassifying of a ﬁle.
We are now ready to present a security experiment, modeled as a game be-
tween the client and the adversary, capturing the desired security requirements.
For simplicity we present the game with a single Cli, but the deﬁnition could be
easily extended to deal with the more realistic setting in which multiple clients
interact with the same encrypted cloud storage PECS.
Conﬁdentiality Experiment for PECS
1. st0 ← Init();
2. (pw; st1) ← πreg(κ; st0);
3. The adversary A on input the server state st1 adaptively chooses a series
of commands to be executed (password registration, store, other revealing
or non-revealing commands), specifying the input of the client in every
subprotocol. More precisely, the adversary can specify a command cmd
and the corresponding inputs and (oC; oS) ← πcmd(pw, iC; iS) will be exe-
cuted with the current password. [Optional for future secrecy: every time
a new password is registered, the old password leaks to A];
4. At some point A outputs (f0, f1, id∗) where f0, f1 are two ﬁles of equal
length;
5. One of the two ﬁles (chosen at random) is now stored on the server i.e.,
b ← {0, 1}, and (⊥; sti+1) ← πsto(pw, fb, id∗; sti);
6. A continues issuing commands to be executed as in step (3), but is now
prevented from running any revealing command on id∗ [Optional for future
secrecy: when new passwords are registered, the old password does not
leak to A];
7. A outputs a guess b(cid:48).
Deﬁnition 1 (Conﬁdentiality of Password-Encrypted Cloud Storage). We say
that a PECS satisﬁes ﬁle conﬁdentiality if no PPT adversary A making at most
q queries to the random oracle can win in the above conﬁdentiality experiment
with probability more than
1
2
+
q
c2κ
(plus a negligible factor in the computational security parameter k). In addition
we say a PECS satisﬁes future secrecy if the above holds even when old passwords
are leaked to A in step 3 of the experiment.
Some remarks about our deﬁnition are in order at this point: as already
stated, our deﬁnition only attempts at capturing a minimal conﬁdentiality re-
quirement for the stored data, and does not capture many other desirable secu-
rity properties (integrity, retrievability, hiding the access pattern, etc.). Since
6
q
our deﬁnition also allows for revealing commands, our deﬁnition capture the
intuitive requirement that declassifying (e.g., sharing publicly) one or more ﬁles
should not impact the security of the other ﬁles stored at the server. We dis-
tinguish between a passive A that only chooses the scheduling and the inputs
of the commands to be executed, and an active A that in addition can specify
arbitrarily corrupted behaviour for the server (but not for the client) in the sub-
protocols. We use the RO model to be able to better quantify the probability