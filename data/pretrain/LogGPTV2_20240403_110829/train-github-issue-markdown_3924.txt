 _Please make sure that this is a bug. As per ourGitHub Policy, we only
address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template_
**System information**
  * Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
  * OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
  * Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Internal Android 8.1 board
  * TensorFlow installed from (source or binary): source
  * TensorFlow version (use command below): 1.13.1
  * Python version: 2.7
  * Bazel version (if compiling from source): 0.22.0
  * GCC/Compiler version (if compiling from source):
  * CUDA/cuDNN version:
  * GPU model and memory: Mali-T864 GPU
You can collect some of this information using our environment capture  
script  
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c "import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"` 2\. TF 2.0: `python -c
"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"`
**Describe the current behavior**
I wrote a simple demo using tflite opengles delegate to run deeplab models
from model zoo.
I have tried your hosted model deeplabv3_mv2_257_gpu.tflite, It works perfect
on my device on CPU and Opengles delegate.
However, when I tried the deeplab mode with xception65 , The tflite perform
differently on CPU and Opengles delegate. My input layer is sub_7, output
layer is ResizeBilinear_3.
Here is my result:  
test image:  
![two_human](https://user-
images.githubusercontent.com/43549654/59234008-b852b600-8b9f-11e9-8ce2-703664cadcf4.png)
result from CPU (correct):  
![hp_nonflatten_cpu](https://user-
images.githubusercontent.com/43549654/59234023-d02a3a00-8b9f-11e9-98f0-f17874fca671.png)
result from opengles delegate:  
![hp_flatten2_gpu](https://user-
images.githubusercontent.com/43549654/59234034-dc15fc00-8b9f-11e9-9982-008d9f5064fa.png)
I believed that this issue is related to the operations(BATCH_TO_SPACE_ND,
SPACE_TO_BATCH_ND) that opengles not supporting thus fallback to CPU. Another
issue of mine described more detail.
Flatten the unsupported ops using graph_transforms also failed. It gives me
the same inaccurate result or shows message like:  
`INFO: Initialized TensorFlow Lite runtime. INFO: Created TensorFlow Lite
delegate for GPU. ERROR: TfLiteGpuDelegate Prepare: Program is not properly
linked: L0005 The number of compute uniform components (1261) is greater than
the maximum number allowed (1024). ERROR: Node number 199 (TfLiteGpuDelegate)
failed to prepare. ERROR: Node number 199 (TfLiteGpuDelegate) failed to
prepare. `
**Describe the expected behavior**  
all models work as good as your hosted model
**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to
generate the problem.
**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and
files should be attached.