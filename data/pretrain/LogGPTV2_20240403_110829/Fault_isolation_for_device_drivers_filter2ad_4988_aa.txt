title:Fault isolation for device drivers
author:Jorrit N. Herder and
Herbert Bos and
Ben Gras and
Philip Homburg and
Andrew S. Tanenbaum
Fault Isolation for Device Drivers
Jorrit N. Herder, Herbert Bos, Ben Gras, Philip Homburg, and Andrew S. Tanenbaum
Dept. of Computer Science, VU University Amsterdam, The Netherlands
E-mail: {jnherder, herbertb, beng, philip, ast}@cs.vu.nl
Abstract
This work explores the principles and practice of
isolating low-level device drivers in order to improve OS
dependability.
In particular, we explore the operations
drivers can perform and how fault propagation in the event
a bug is triggered can be prevented. We have prototyped
our ideas in an open-source multiserver OS (MINIX 3) that
isolates drivers by strictly enforcing least authority and
iteratively reﬁned our isolation techniques using a prag-
matic approach based on extensive software-implemented
fault-injection (SWIFI) testing. In the end, out of 3,400,000
common faults injected randomly into 4 different Ethernet
drivers using both programmed I/O and DMA, no fault was
able to break our protection mechanisms and crash the OS.
In total, we experienced only one hang, but this appears to
be caused by buggy hardware.
Keywords: Operating Systems, Device Drivers, Bugs,
Dependability, Fault Isolation, SWIFI Testing
“Have no fear of perfection—you’ll never reach it.”
Salvador Dal´ı (1904–1989)
1
INTRODUCTION
Despite recent research advances, commodity operating
systems still fail to meet public demand for dependabil-
ity. Studies seem to indicate that unplanned downtime is
mainly due to faulty system software [13, 37]. A survey
across many languages found well-written software to have
6 faults/KLoC; with 1 fault/KLoC as a lower bound when
using the best techniques [16]. In line with this estimate,
FreeBSD reportedly has 3.35 post-release faults/KLoC [5],
even though this project has strict testing rules and anyone
is able to inspect the source code.
It is now beyond a doubt that extensions, such as de-
vice drivers, are responsible for the majority of OS crashes.
Even though extensions typically comprise up to two-thirds
of the OS code base, they are generally provided by un-
trusted third parties and have a reported error rate of 3–
7 times higher than other code [3]. Indeed, Windows XP
crash dumps showed that 65–83% of all crashes can be at-
tributed to extensions and drivers in particular [10, 26].
The reason that these crashes can occur is the close inte-
gration of (untrusted) extensions with the (trusted) core ker-
nel. This violates the principle of least authority by grant-
ing excessive power to potentially buggy components. As a
consequence, a malfunctioning device driver can, for exam-
ple, wipe out kernel data structures or overwrite servers and
drivers. Not surprisingly, memory corruption was found to
be one of the main OS crash causes [35].
Fixing buggy drivers is infeasible since conﬁgurations
are continuously changing with, for example, 88 new
drivers per day in 2004 [26]. On top of this, maintainability
of existing drivers is hard due to changing kernel interfaces
and growth of the code base [29]. Our analysis of the Linux
2.6 kernel shows a sustained growth in LoC of about 5.5%
every 6 months, as shown in Fig. 1. Over the past 4.5 years,
the kernel has grown 49.2% and now surpasses 5.1M lines
of executable code—largely due to device drivers, compris-
ing 57.6% of the kernel or 3.0M lines of code.
While there is a consensus that drivers need to be iso-
lated, e.g. [19, 20, 21, 36], the issue to be addressed in each
approach is “Who can do what and how can this be done
safely?” We strongly believe that least authority should be
the guiding principle in any dependable design. “Every pro-
gram . . . should operate using the least set of privileges nec-
essary to complete its job. Primarily, this principle limits the
damage that can result from an accident or error. It also re-
duces the number of potential interactions among privileged
programs . . . so that unintentional, unwanted, or improper
uses of privilege are less likely to occur [31].”
Other
Net
Fs
Drivers
Arch
)
C
o
L
(
e
d
o
C
e
b
a
t
u
c
e
x
E
l
f
o
s
e
n
L
i
5000000
4000000
3000000
2000000
1000000
0
1
8 
D
1
6 J
u
2
4 
D
1
0
1
1
1
0
1
5 J
8 J
a
5 J
0 J
a
0 J
9 J
a
3 J
e
c 0
3
n 0
4
e
c 0
4
ul 0
5
n 0
6
ul 0
6
n 0
7
ul 0
7
n 0
8
ul 0
8
Figure 1: Growth of the Linux 2.6 kernel since its release.
1.1 Contribution and Paper Outline
2 RELATED WORK
In contrast to earlier work [17], this study addresses the
fundamental issue of fault isolation for device drivers. The
main contributions are (i) a classiﬁcation of driver opera-
tions that are root causes of fault propagation, and (ii) a set
of isolation techniques to curtail these powers in the face of
bugs. We believe this analysis as well as the isolation tech-
niques proposed to be an important result for any effort to
isolate faults in drivers, in any OS. A secondary contribution
consists of the full integration of our isolation techniques in
a freely available open-source OS, MINIX 3.
MINIX 3 strictly adheres to least authority. As a base-
line, each driver is run in a separate user-mode UNIX pro-
cess with a private (IO)MMU-protected address space. This
takes away all privileges and renders each driver harmless.
Next, because this protection is too coarse-grained, we have
provided various ﬁne-grained mechanisms to grant selective
access to resources needed by the driver to do its job. Differ-
ent per-driver policies can be deﬁned by the administrator.
The kernel and trusted OS servers act as a reference moni-
tor and mediate all accesses to privileged resources such as
CPU, device I/O, memory, and system services. This design
is illustrated in Fig. 2.
Rather than proving isolation formally [7], we have taken
a pragmatic, empirical approach and iteratively reﬁned our
isolation techniques using software-implemented fault in-
jection (SWIFI). After several design iterations, MINIX 3 is
now able to withstand millions of faults representative for
system code. Even though we injected 3,400,000 faults, not
a single fault was able to break the driver’s isolation or cor-
rupt other parts of the OS. We did experience one hang, but
this appears to be caused by buggy hardware.
This paper continues as follows. First, we relate our
work to other approaches (Sec 2) and discuss assumptions
and limitations (Sec. 3). Next, we introduce isolation tech-
niques based on a classiﬁcation of privileged driver oper-
ations (Sec. 4) and illustrate our ideas with a case study
(Sec. 5). Then, we describe the experimental setup (Sec. 6)
and the results of our SWIFI tests (Sec 7). Finally, we dis-
cuss lessons learned (Sec. 8) and conclude (Sec. 9).
S
O
r
e
v
r
e
s
i
t
l
u
M
Super User
Grant Selective Access
User Space
Unprivileged Processes
Kernel Space
Mediate Resource Access
Hardware
Enforce Protection Domains
Isolation
Policy
Driver
Manager
Store
Privileges
(IO)MMU
Tables
Isolated
Driver
Verify
Access
I/O
Device
Figure 2: MINIX 3 isolates drivers in unprivileged processes.
Several other approaches that try to improve dependabil-
ity by isolating drivers have been proposed recently. Below
we survey four different approaches in a spectrum ranging
from legacy to novel isolation techniques.
First, wrapping and interposition are used to run safely
untrusted drivers inside the OS kernel.
For example,
Nooks [36] combines in-kernel wrapping and hardware-
enforced protection domains to trap common faults and per-
mit recovery. SafeDrive [38] uses wrappers to enforce type-
safety constraints and system invariants for extensions writ-
ten in C. Software fault isolation (SFI) as in VINO [32] in-
struments driver binaries and uses sandboxing to prevent
memory references outside their logical protection domain.
XFI [8] combines static veriﬁcation with run-time guards
for memory access control and system state integrity.
Second, virtualization can be used to run services in sep-
arate hardware-enforced protection domains. Examples of
virtual machine (VM) approaches include VMware [34] and
Xen [9]. However, running the entire OS in one virtual ma-
chine is not enough, since driver faults can still propagate
and crash the core OS. Instead, a multiserver-like approach
is required whereby each driver runs in a paravirtualized
OS in a dedicated VM [21]. The client OS runs in a sepa-
rate VM and typically accesses its devices by issuing virtual
interrupts to the driver OS. This breaks VM isolation by in-
troducing new, ad-hoc communication channels.
Third, language-based protection and formal veriﬁcation
can also be used to isolate drivers. For example, OKE [1]
uses a customized Cyclone compiler to instrument an ex-
tension’s object code according to a policy corresponding
to the user’s privileges. Singularity [19] combines type-safe
languages with protocol veriﬁcation and seals processes af-
ter loading. The seL4 project [7] aims at a formally ver-
iﬁed microkernel by mapping the design onto a provably
correct implementation. Devil [24] is a device IDL that en-
ables consistency checking and low-level code generation.
Dingo [30] simpliﬁes interaction between drivers and the
OS by reducing concurrency and formalizing protocols.
Finally, multiserver systems like MINIX 3 encapsulate
untrusted drivers in user-mode processes with a private
address space.
For example, Mach [12] experimented
with user-mode drivers directly linked into the application.
L4Linux [14] runs drivers in a paravirtualized Linux server.
SawMill Linux [11] is multiserver OS, but focuses on per-
formance rather than driver isolation. NIZZA [15] supports
safe reuse of legacy extensions for security-sensitive appli-
cations. In recent years, user-mode drivers were also used in
commodity systems such as Linux [20] and Windows [25],
but we are not aware of efforts to isolate drivers based on
least authority and believe that these systems could beneﬁt
from the ideas presented in this work.
3 ASSUMPTIONS AND LIMITATIONS
4 ENFORCING LEAST AUTHORITY
In our research, we explore the limits on software iso-
lation, rather than proposing hardware changes. Unfortu-
nately, older PC hardware has various shortcomings that
make it virtually impossible to build a system where drivers
run in full isolation. However, now that modern hardware
with support for isolating drivers is increasingly common—
although sometimes not yet perfect—we believe the time
has come to revisit design choices made in the past. For ex-
ample, the following three hardware improvements enable
building more dependable operating systems:
(1) To start with, older PCs have no means to protect
against memory corruption by unauthorized direct memory
access (DMA). Our solution is to rely on IOMMU support.
Like a traditional MMU, which provides memory protec-
tion for CPU-visible addresses, the IOMMU provides mem-
ory protection for device-visible addresses. If a driver wants
to use DMA, a trusted party validates the request and me-
diates setting up the IOMMU tables for the driver’s device.
We have used AMD’s Device Exclusion Vector (DEV), but
IOMMUs are now common on many platforms.
(2) Furthermore,
the PCI standard mandates shared,
level-triggered IRQ lines that lead to inter-driver depen-
dencies, since a driver that fails to acknowledge a device-
speciﬁc interrupt may block an IRQ line that is shared with
other devices. We avoided this problem by using dedicated
IRQ lines, but the PCI Express (PCI-E) bus provides a struc-
tural solution based on virtual message-signaled interrupts
that can be made unique for each device.
(3) Finally, all PCI devices on the standard PCI bus talk
over the same communication channel, which may lead to
conﬂicts. PCI-E uses a point-to-point bus design so that
devices can be properly isolated. However, hardware limi-
tations still exist, as PCI-E is known to be still susceptible
to PCI-bus hangs if a malfunctioning device claims an I/O
request but never puts the completion signal on the bus.
In addition to improved hardware dependability, perfor-
mance has increased to the point where software techniques
that previously were infeasible or too costly have become
practical. We build on the premise that computing power
is no longer a scarce resource (which is generally true on
desktops nowadays) and that most end users would be will-
ing sacriﬁce some performance for improved dependabil-