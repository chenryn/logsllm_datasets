### Performance Analysis and Improvements

#### Receive Time Metrics
The average time to receive all `get()` calls was 44 milliseconds, with the 95th percentile being 151 milliseconds. A significant portion of this overhead could be mitigated by implementing in-network isolation of control plane messages [21].

#### Trace-Driven Simulation
We compared the performance of inter-coflow scheduling against per-flow fairness and prioritization schemes using simulations. In the absence of coordination overheads, the improvements were notably higher (Figure 9). The average and 95th percentile completion times (CCTs) improved by 3.66× and 2.77× over per-flow fairness, and by 5.53× and 5.8× over per-flow prioritization.

**Figure 10: [EC2] Percentage of coflows meeting deadlines using Varys compared to per-flow fairness. Increased deadlines improve performance.**

It is important to note that the comparative improvements for bin-1 relative to other bins are significantly larger in the simulation due to the absence of scheduler coordination overheads. The absolute values of improvements in Figure 9 are higher than those in Figure 7. Key factors contributing to this phenomenon include instant scheduling, zero-latency setup/cleanup/update of coflows, and perfectly timed flow arrivals (i.e., coflows are READY to be scheduled upon arrival) in the simulation. Without these overheads, as shown in Figure 8b, Varys outperforms per-flow schemes even for sub-second coflows.

#### Per-Flow Prioritization
Figure 9 highlights that per-flow prioritization mechanisms perform even worse (by 1.52×) than per-flow fairness provided by TCP when optimizing CCTs. This is primarily due to indiscriminate interleaving across coflows. While all flows make some progress using flow-level fairness, per-flow prioritization favors only the small flows, regardless of the progress of their parent coflows. However, per-flow prioritization is still 1.08× faster than per-flow fairness in terms of the average flow completion time (FCT). Figure 8b presents the distribution of CCTs using per-flow prioritization compared to other approaches.

#### Optimality
While finding the optimal schedule is infeasible, we estimated possible improvements by comparing against an offline 2-approximation combinatorial ordering heuristic for coflows without coupled resources [30]. The average CCT did not change using the combinatorial approach. For bin-1 to bin-4, the changes were 1.14×, 0.96×, 1.46×, and 0.92×, respectively.

### Varys's Performance for Deadline-Sensitive Coflows

Inter-coflow scheduling allowed almost twice as many coflows to complete within their deadlines in EC2 experiments (Figure 10). Specifically, 57% of coflows met their deadlines using Varys, compared to 30% using the default mechanism. Coflows across different bins experienced similar results, which is expected since Varys does not differentiate between coflows when optimizing for deadlines.

Recall that the original trace did not contain coflow-specific deadlines, so we introduced them based on the minimum CCT of coflows (§7.1). Therefore, we did not expect a 100% admission rate. However, a quarter of the admitted coflows failed to meet their deadlines, likely due to the lack of network support in estimating utilizations and enforcing Varys-determined allocations. Varys admitted more coflows than it should have, causing some to miss their deadlines and affecting others. Trace-driven simulations shed more light on this issue.

To understand how far off the failed coflows were, we analyzed if they could complete with slightly longer deadlines. After doubling the deadlines, we found that almost 94% of the admitted coflows succeeded using Varys.

**Figure 11: [Simulation] More coflows meet deadlines using inter-coflow scheduling than using per-flow fairness and prioritization schemes.**

In trace-driven simulations, for the default case (x=1), Varys admitted 75% of the coflows, and all of them met their deadlines (Figure 11). Note that the admission rate is lower than in our experiments. Prioritization schemes fared better than per-flow fairness, unlike when the objective was minimizing CCT: 59% of coflows completed within their deadlines compared to 52% using fair sharing.

As we varied the deadlines of all coflows by changing x from 0.1 to 10, the comparative performance of all approaches remained almost the same, and performance across bins was consistent.

#### Reservation Schemes
Since the impact of admission control is similar to reserving resources, we compared Varys's performance with that of the Virtual Cluster (VC) abstraction [11], where all machines can communicate at the same maximum rate through a virtual non-blocking switch. The VC abstraction admitted and completed slightly fewer coflows (73%) than Varys (75%), as reservation using VCs is more conservative.

### Impact of Preemption

While minimizing CCT, preemption-based mechanisms can starve certain coflows when the system is overloaded. Varys takes precautions (§5.3.4) to avoid such scenarios. As expected, we did not observe any perpetual starvation during experiments or simulations.

Processing coflows in their arrival order (i.e., FIFO) avoids starvation [15]. However, simulations confirmed that head-of-line blocking significantly hurts performance, especially for short coflows in bin-1 and bin-3. We found that processing coflows in the FIFO order can result in 24.64×, 5.44×, 34.2×, and 5.03× slower completion times for bin-1 to bin-4. The average (95th percentile) CCT became 5.65× (7.7×) slower than using Varys.

### Impact on Network Utilization

To understand Varys's impact on network utilization, we compared the ratios of makespans in the original workload and those in Table 5. Given a fixed workload, a change in makespan indicates a change in aggregate network utilization.

We did not observe significant changes in makespan in our EC2 experiments. The exact factors of improvement were 1.02×, 1.06×, 1.01×, 0.97×, and 1.03× for the five workloads. This is expected because while Varys is not work-conserving at every point in time, its overall utilization is the same as non-coflow approaches. Makespans for both per-flow fairness and coflow-enabled schedules were the same in the trace-driven simulation.

### Impact of Coflow Mix

To explore the impact of changes in the coflow mix, we selected four extreme hours (Table 5) from the trace and performed hour-long experiments on EC2. These hours were chosen based on the high percentage of certain types of coflows (e.g., narrow ones in Mix-N) during those periods.

**Figure 12: [EC2] Improvements in the average CCT using coflows for different coflow mixes from Table 5.**

Figure 12 shows that the average CCT improves irrespective of the mix, albeit in varying degrees. Observations made earlier (§7.2) still hold for each mix. However, identifying the exact reasons for different levels of improvements is difficult due to the online nature of the experiments. The overall degree of improvement depends on the instantaneous interplay of concurrent coflows. We also did not observe any clear correlation between the number of coflows or workload size and corresponding improvements.

### Impact of Cluster/Network Load

So far, we have evaluated Varys's improvements in online settings, where the number of concurrent coflows varied over time. To better understand the impact of network load, we used the same coflow mix as the original trace but varied the number of concurrent coflows in an offline setting. We see in Figure 13 that Varys's improvements increase with increased concurrency: per-flow mechanisms fall increasingly further behind as they ignore the structures of more coflows. Additionally, flow-level fairness consistently outperforms per-flow prioritization mechanisms in terms of the average CCT.

**Figure 13: [Simulation] Improvements in the average CCT for varying numbers of concurrent coflows.**

**Figure 14: [Simulation] Changes in the percentage of coflows meeting deadlines for varying numbers of concurrent coflows.**

For deadline-sensitive coflows, we performed a similar analysis. Because Varys's performance depends on the arrival order, we randomized the coflow order across runs and present their average in Figure 14. We observe that as the number of coexisting coflows increases, a large number of coflows (37% for 100 concurrent coflows) meet their deadlines using Varys; per-flow mechanisms completely stop working even before. Additionally, per-flow prioritization outperforms (however, the extent of this outperformance is not specified).