0.277
44
-0.305
0.056
40
1
44
-1.133
0.388
44
Security Classes
44
3
1.66
Security Classes
0.058
0.709
44
-0.70
0.653
44
-0.313
0.050
40
-0.133
0.388
44
1
44
Table 5: Correlations among the variables used in the analysis. The highlighted correlations are considered signiﬁcant.
Figure 3: Mean percent accuracy for information conditions
across all scenario types.
spondent thought that explicitly asking about vulnerabilities while
they worked on the scenarios changed their mindset towards secu-
rity. The Degree variable indicates whether the respondent has a
4-year college degree in CS or related major. Security Classes in-
dicates whether the respondent has ever taken security courses or
training. Table 3 illustrates the descriptive statistics for these vari-
ables.
5.1.2 Result Interpretation
Because the accuracy for each response was graded by two sep-
arate experimenters, accuracy result was averaged across the two
scores. For each subject, mean accuracy data was obtained for each
of the six scenarios and subsequently averaged across all subjects.
Two one-way ANOVAs revealed signiﬁcant effects across the three
levels of information (F (2, 36) = 11.84, M Se = 0.30, p <0 .05)
and the six scenario types (F (5, 80) = 7.80, M Se = 0.23, p <
0.05).
With regard to the levels of information: Follow-up t-tests,
which compares the means between the controlled, implicit, and
explicit information conditions, revealed that subjects were signif-
icantly less accurate in controlled condition (M = 0.31) than in
implicit (M = 0.90) and explicit (M = 1.10) conditions (t(18) =
3.43, SE = 0.17, p < 0.05; t(19) = 5.86, SE = 0.14, p <
0.05). As shown in Figure 3, these ﬁndings suggest that prompt-
ing developers to think about how other developers could encounter
Figure 4: Mean percent accuracy for all scenario types across
levels of information conditions.
Control Priming Explicit Total
Non-security related
Security related
Total
6
2
8
6
4
10
0
4
4
12
10
22
Table 6: Questionnaire breakdown into security and non-
security questions.
potential vulnerabilities with a particular snippet of code increases
the likelihood that they will recognize the security ﬂaw.
With regard to the types of vulnerability scenarios: Follow-
up t-tests revealed that subjects were most accurate in identify-
ing the SQL injection vulnerability (M = 1.27) and least ac-
curate in identifying the SSL Python vulnerability (M = 0.37)
(t(17) = 4.54, SE = 0.19, p <0 .05). As shown in Figure
4, these results suggest that the nature of the scenarios themselves
may have a correlation with cognitive blind-spots. To further in-
vestigate how previous knowledge and experience may inﬂuence
subjects’ response accuracy, a correlation analysis revealed that the
number of vulnerabilities reported as familiar to subjects was posi-
tively correlated with higher accuracy (r(47) = 0.4, p < 0.05).
Because familiarity is linked to experience, we conducted a cor-
relation analysis on the dimensions of subjects’ experience, includ-
ing their occupation, whether or not they had a degree in com-
puter science, and whether or not they had taken computer security
courses and the number of known vulnerabilities. Results revealed
(cid:22)(cid:19)(cid:19)
Figure 5: Participant’s score distribution.
that the number of known vulnerabilities was moderately corre-
lated with having taken computer security classes (r(47) = 0.27,
p <0 .05). These results indicate that developers are more likely
to ﬁnd security-related blind-spots if they have been formally ed-
ucated on security related issues. Table 5 presents the correlations
among the variables and shows how the score obtained by a re-
spondent is highly correlated with whether they took some security
training or courses.
5.2 Results of Experiment Manipulation
The debrief open-ended questions asked participants how the
manipulation used in the experiment worked and its effects on how
well the participants answered the security-related questions. Table
6 details how each questionnaire was graded. Each questionnaire
contained 22 questions where 12 (54%) were not security related
and 10 (45%) were security related. The non-security questions
were warm-up questions or questions used to aid in the psycholog-
ical manipulation. Two questions in the explicit condition were
open-ended and were not graded (Why do you think developers
have problems pinpointing this particular problem?). Thus, the
maximum score a respondent could obtain was 40. Figure 5 shows
the distribution of participants scores.
5.2.1 Familiarity with Vulnerabilities
The debrief questions also asked the respondents whether they
were familiar with the vulnerabilities exercised in the study and
Figure 6 summarizes their answers. The goal of these questions
Figure 6: Participant’s familiarity with vulnerabilities exer-
cised in the questionnaire.
was to manually correlate a respondent score on a scenario with
the familiarity they reported for the exercised vulnerability. For ex-
ample, how the participants that declared knowledge of the SQL
injection vulnerability scored on the scenario that exercised this
vulnerability? Were they able to correlate the scenario with the
vulnerability? In other words, were they able to apply their pre-
vious knowledge about the vulnerability at the time they needed?
When given the chance to improve the code containing the corre-
sponding vulnerability did they remove the vulnerability? Table 7
summarize this analysis.
The results in Table 7 show that many developers who were fa-
miliar with the exercised vulnerabilities had difﬁculties correlating
the information about them to the current programming scenario or
failed to ﬁx vulnerable code when given an opportunity. For ex-
ample, 53% of the participants knew a particular vulnerability but
did not correlate it to working scenario. This is because the needed
security information or the security thinking was not included in
their heuristics at the moment.
5.2.2 Effectiveness of Psychological Manipulation
Despite the familiarity with vulnerabilities is weakly correlated
to secure programming, the results in Table 8 show that when primed
about the possibility of ﬁnding vulnerabilities developers changed
their mindset towards security. In particular, 83% of the partici-
pants stated that explicitly mentioning vulnerabilities changed their
programming approach and security-mindset. Table 8 shows the ef-
fectiveness of the manipulation and the use of priming can change
a developer’s approach to coding. This is an encouraging result.
Knew vulnerability but did not correlate it to working scenario
25 (53%)
Frequency
Knew vulnerability but did not remove it from code when given
a chance
17 (36%)
Overlooked Vulnerabilities
Brute force (17 instances - 68%)
SQL injection (6 instances - 24%)
Buffer overﬂow (5 instances - 20%)
XSS (4 instances - 20%)
TOCTTOU (3 instances - 12%)
Python SSL (2 instances - 8%)
Buffer overﬂow (7 instances - 41%)
SQL injection (7 instances - 41%)
Brute force, TOCTTOU and Python SSL (1
instance each - 0.05%)
Table 7: Vulnerability knowledge and the application of this knowledge when needed it.
Suspecting of ﬁnding vulnerabilities
Asking about unexpected results cued to think about vulnerabilities
Explicitly mentioning vulnerabilities changed your approach to a security-mindset
Yes
15 (32%)
28 (60%)
39 (83%)
No
30 (64%)
19 (40%)
5 (10.6%)
Maybe/Unsure
2 (0.04%)
0 (0%)
3 (6.4%)
Table 8: Effectiveness of the psychological manipulation and priming to change developer’s approach to security.
(cid:22)(cid:19)(cid:20)
Theme
Mentioned by
developers
1) Speciﬁcally mention vulnerabilities
changed developer approach
39 (83%)
2) Priming about security changes
developer’s mindset
28 (60%)
3) Security is not a priority /
Developer’s mindset does not include
security
23 (48%)
4) Developers assume common cases
16 (34%)
5) Security thinking requires cognitive
effort
14 (30%)
6) Developers trust APIs
14 (30%)
7) For certain tasks or CS ﬁelds,
security is not an issue
6 (13%)
8) Economic incentives
9) Security education
6 (13%)
6 (13%)
Representative Quotes
"it it put me in the mindset that this code would be very easy to inﬁltrate"
"Until the words vulnerability and/or security were used, I had not thought
of security risks yet"
"Yes, I expected to due to the power of suggestion"
"Once we were looking for unexpected results, I immediately started thinking
of what a dumb and/or malicious user would attempt to do with the program"
"Developers usually focus in delivering functional requirements"
"I generally don’t look for vulnerabilities in code"
"developers look for the most immediate solution to the current problem they
are facing, such as copying one buffer to a second, and run with whatever
solution Google brings them ﬁrst"
"We usually try to solve the problem for a set of inputs, not for all possible
inputs."
"Developers seem to be constantly reminded of the fact that users are "dum-
mies" and any mistake they can make, they will make, etc. However, we do
not tend to think of the user as evil"
"It’s hard to understand the fact that the user input can directly affect the
execution of the code, changing what it was supposed to do to something
else."
"Remembering to sanitize input is tedious"
"In general, security and vulnerability problems are hard to ﬁnd"
"It’s not straightforward that misusing strcpy can lead to very serious prob-
lems. Since it’s part of the standard library, developers will assume it’s ok to
use. It’s not called unsafe_strcpy or anything, so it’s not immediately clear
that that problem is there"
"normally people expects that an ofﬁcial library does not have this kind of
vulnerability as default.
"The security check made prior to accessing the ﬁle gives a false impres-
sion that the any non-permitted users will be denied access upfront. [For
TOCTTOU scenario]"
"In terms of academic AI code, security is really not an issue"
"But I don’t do a lot of network programming so I feel like it matters a bit
less [likely to think about security in the future]"
"yes [i would think about security in the future], if the app is going to be
exposed to general public. no , for internal apps, running inside a ﬁrewall."
"The reward for making a code safer is not easily seen by others and may
come only on the long run, when the code needs less maintenance."
"there’s the economic side. Developers are measured and paid for the fea-
tures delivered without functionality bugs"
"When we are aware of a vulnerability it starts to be a part of our checklist"
Table 9: Open-ended answers analysis - Coding.
5.3 Coding
Coding is a technique used in qualitative analysis studies in the
social, behavioral and economic sciences for analysis of data. The
main idea of coding is to associate what the respondent said in an
interview or survey with a set of themes, concepts or categories
[24]. Coding is done while reading the transcripts or an interview
or the contents of an online survey. A code is a word or a short
phrase that captures a datum’s primary content or essence [25].
In this study the respondents’ comments and answers to open-
ended questions were coded according to seven themes. Table 9
shows the themes with the percentage of developers that mentioned
the theme and some representative quotes from different develop-
ers.
6. DISCUSSION
The results of this study corroborated our hypothesis that secu-
rity is not part of the heuristics used by developers in their daily
programming tasks. Humans have a short working memory, and
can only keep a limited number of mental elements readily avail-
able at any time [26]. For a variety of reasons, security information
is generally not included among these elements. Developers mostly
focus on functionality requirements and performance. Developers
are trained, evaluated and paid for delivering feature-rich software
with good performance levels. They do not see an economic incen-
tive for squeezing security thinking into their working memories
and producing safe code. Developers and managers see this issue
as a zero-sum game, and time spent on "quality" will adversely af-
fect function points1, deadlines, timetables and budgets.
Also, developers usually assume common cases for the inputs a
piece of code will receive and the possible states the program can
reach. Vulnerabilities lie in uncommon cases overlooked by the de-
velopers and exploited by a clever adversary. Attackers make un-
common code paths happen, whereas system designers focus on the
common code paths that they know about and are often not aware
of the attack code path until the carefully crafted input is presented
to them. Static analysis methods, such as Denning’s lattice model
[27], overcome this limitation by analyzing all possible code paths.
This can be effective (despite being formally undecidable in the
general case), but have limitations on the type of programs they
can be applied and the type of vulnerabilities they can pinpoint.
Developers’ failure to address uncommon information ﬂows is
also caused by the complexity of fault analysis. Therefore, security
thinking requires signiﬁcant cognitive effort, while people use as
little effort as necessary to solve a problem [13].
This study also shows that developers tend to blindly trust code
from a reputable source, e.g., API code. Given the way humans
think and use shortcuts, simply assuming the correctness of third
party code from a reputable source simpliﬁes developers heuristics
and their cognitive efforts to do their work. This also has to do
with attribution, as if anything goes wrong, developers are not to be
blamed as they were just using a well-known API or component.
To make matters worse, our society provides perverse economic
incentives for a market of insecure software. As discussed by Ross
Anderson in his classic ACSAC 2001 paper [28], the party who is in
1A unit of measurement of the amount of functionality an informa-
tion system (as a product) provides to a user.
(cid:22)(cid:19)(cid:21)
a position to protect a system is not the party that suffers the results
of security failure. The computer software and systems market is
not regulated: they select software and systems that reach the user
as quickly and as feature-rich as possible. Moreover, information
warfare also plays a role because the same software system that
can leave millions of people vulnerable to attacks can be leveraged
by national states to conduct cyber warfare and espionage. Finally,
Anderson argues that it is much easier to attack than to defend [28].
This shows that there is not a "silver bullet" to solve the technical,
economical, legal problems, and psychological challenges of vul-
nerable software as it involves.
6.1 Recommendations for Developers
In spite of the above, from a Psychology viewpoint, this paper
advocates that security information should reach users when
they need it, on the spot, and not the other way around.
It
is commonly assumed that developers should educate themselves
about security and then apply the acquired knowledge when needed.
However, this assumption goes against how the human brain nat-
urally behaves. Our security solutions would be most effective if
they leveraged how humans think. This study showed how priming
security information when developers need it, on the spot, changed
their approach towards security and adapted them to include secu-
rity thinking in their repertoire of heuristics.
This is not an argument against previous and general security ed-
ucation. On the contrary, security education is essential and the re-
sults of this study showed that participants who had previous secu-
rity training performed better in the security-related questions than
participants that have never looked for security information. Bring-
ing security information to developers and not expecting them to
look for it, as advocated here, will streamline the process of re-
trieving previously acquired security information. The results of
this study also showed that many developers who were familiar
with the exercised vulnerabilities had difﬁculties correlating the in-
formation about them to the current programming scenario or failed
to ﬁx vulnerable code when given an opportunity. This is because
the needed security information or the security thinking was not in-
cluded in their heuristics at the moment. However, when primed
about the possibility of ﬁnding vulnerabilities developers changed
their mindset towards security.
Given the importance of security in matters, such as cyber crime,
cyber warfare and privacy, we recommend that systems and soft-
ware that interface with the developer (IDEs, text editors, browsers,