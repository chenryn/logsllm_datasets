this completed in sub-second time intervals.
DETECTION: This attack involves a compromised for-
warding device that either generates, misroutes or replays
packet(s). These anomalies can be easily detected using
the trajectory-based attack detection algorithms presented
in §6. Compared to SPHINX, WedgeTail does not rely on
any administrator deﬁned policies for detection of a Network
DoS attack.
II. Network-to-Host DoS: Here, one or more forward-
ing devices send a large amount of traﬃc to the host network
causing a DoS. This may bring down a host machine in ex-
treme cases, and when dealing with mission critical systems,
the impact would be catastrophic. Existing controllers do
not have any detection mechanism against this attack.
DETECTION: Malicious forwarding device(s) may gen-
erate, replay or misroute packets towards a network host to
cause a DoS attack. The result of the aforementioned actions
is having unexpected trajectories in the network, which are
automatically detected by WedgeTail. However, unless there
are administrator-deﬁned policies for each host, SPHINX
is unable to detect Network-to-Host DoS. Furthermore, the
number of policies to be processed in real-time will be a fac-
tor of the total number of hosts and forwarding devices. The
performance of SPHINX when processing such large number
of policies is unknown. Moreover, even with such policies in
place, the attack may go undetected as the downlink to host
may not reach any suspicious threshold (note that in most
cases this attack adds a negligible processing overhead to
the compromised forwarding device(s) and may also have a
negligible impact on the bandwidth).
III. TCAM Exhaustion: TCAM is a fast associative
memory used to store ﬂow rules. Malicious hosts may send
arbitrary traﬃc and force the controller into installing a
large number of ﬂow rules, thereby exhausting the switch’s
TCAM. As also discussed in 3, this may result in signiﬁcant
latency or packet drops. None of the controllers tested can
detect nor prevent attacks such as TCAM Exhaustion.
DETECTION: Attacks similar to III results in packet
delay or drop, which will result in anomalies between ex-
pected and actual trajectories and are detected by Wed-
geTail. SPHINX has a totally diﬀerent approach for de-
tecting such attacks. The latter checks for F LOW M OD
messages sent by the controller and detects a threat if the
rate continues to be high over time. While both approaches
will lead to detecting the threat, with SPHINX, the con-
troller messages may not violate the administrator deﬁned
policies and still cause the switch to fail (e.g.
the switch
may be already experiencing a load higher than usual that
is not covered in the policy description). In such cases, the
attack will not be detected by SPHINX.
IV. Forwarding device Blackhole: In this case, ﬂow
path ends abruptly, and the traﬃc cannot be routed to
the destination. A forwarding device either drops or de-
lays packet forwarding to launch this attack. We installed
malicious rules on switches in networks, and none of the
controllers had any mechanism to prevent nor detect them.
V. ARP Poisoning: Malicious network hosts can spoof
physical hosts by forging ARP requests and fool the con-
troller to install malicious ﬂow rules to divert traﬃc. This
may be used for eavesdropping or in other cases to mount
IP slicing attacks and creating network loops. We replicated
the attack with the exact similar setup used in [11] and we
also report that all of the tested controllers are vulnerable
to it. Note that ARP poisoning corrupts the physical topo-
logical state. We discuss how WedgeTail detects attacks
targeting the logical topological state in §10.
DETECTION: There are no network policies that a
forged ARP request violates in a network. However, the ac-
856tual path that a packet traveling from hosts to the controller
takes is visible to WedgeTail. Hence, ARP requests with an
anomalous trajectory (i.e. originated from hosts rather than
forwarding devices) can be monitored and blocked before
poisoning the network. SPHINX is also capable of detecting
this attack either using its ﬂow graph feature (which binds
MAC-IP) or using administrator deﬁned detection policies.
VI. Controller DoS: With OpenFlow, a packet that
does not match any of the currently installed ﬂow rules of
a forwarding device is buﬀered, and an associated OFPT
PACKET IN message containing the data packet’s header
ﬁelds is forwarded to the controller. When a controller re-
ceives a large number of new packet ﬂows within a short
period, its buﬀer is ﬁlled up and has to forward complete
packets to the controller. This causes heavy computational
load on the controller, and it may bring it down altogether.
We used Cbench [7] and ﬂooded the controller with a high
throughput of P ACKET IN messages to analyze the con-
trollers’ performance. Similar to [11], we report that all
except Floodlight exhibited this attack. However, while
Floodlight throttles the incoming OpenFlow messages from
switches as a prevention mechanism, the connection of the
switches with the controller is broken when a large number
of switches attempt to connect with it.
DETECTION: A compromised forwarding devices may
execute this attack by either replaying packets or generating
packets destined to the controller. If there are an abnormal
number of trajectories between a forwarding device and a
controller in a snapshot taken from the network, then Wed-
geTail will detect a threat and can react as per the policies
deﬁned by its administrator – note that WedgeTail may com-
pute the threshold number of trajectories over time period
∆τ by itself or, the administrator could custom deﬁne this.
SPHINX detects a controller DoS by observing the ﬂow-level
metadata and computing the rate of PACKET IN messages,
which is compared with the administrator-deﬁned policies.
Compared to SPHINX, WedgeTail also has the advantage
of computing the aggregated ﬂow heading to the controller
rather than each individual link.
9.3 Attack Implantations
As mentioned, WedgeTail successfully detected all of the
attacks implemented in §9.2. However, to cover all of the
malicious actions speciﬁed in §3 and perform extended per-
formance analysis, we wrote scripts to implant 500 synthetic
malicious threats in our simulated networks. The resulting
malicious forwarding devices maliciously processed: 1. All
packets on all ports in approx. 30% of all attacks, 2. A
subset of packets on a speciﬁc port in approx. 19% of all
attacks, 3. A subset of packets on a speciﬁc port in approx.
19% of all attacks, 4. Packets pertaining to a speciﬁc port
in approx. 25% of all attacks, 5. A subset of packets per-
taining to a speciﬁc port in approx. 15% of all attacks, 6.
Packets destined to the control plane in approx. 11% of all
attacks.
Malicious Actions: We used custom scripts to ran-
domly introduce synthetic malicious forwarding devices in
our networks. The resulting forwarding devices maliciously
replayed packets (40% of all attacks), dropped packets (30%),
misrouted packets (5%), generated packets (10%), and de-
layed packets (15%). A packet replay may be used in a range
of threats (e.g. surveillance, DDoS, etc.) and is less likely
to be detected compared to packet drops – i.e. traﬃc not
reaching the destination is presumably much more notice-
able. Hence, this distribution of attacks is deemed to be
reasonable.
Compound Attacks: We deﬁne compound attacks as
those involving more than one malicious forwarding device.
For example, a surveillance attack may involve more than
one malicious forwarding device (see Figure 1). Compound
attacks are challenging for solutions such as SPHINX as
compromised forwarding devices may intelligently install cus-
tom rules and avoid reporting to the controller thus aiming
to conceal their maliciousness. This is less of an issue for
WedgeTail’s detection engine as any custom rule not match-
ing those set by the control plane will eventually result in
deviation of actual trajectories from expected ones, and this
will trigger an alarm. We report that in our simulations a
total of 108 attacks involved more than one malicious for-
warding devices. Speciﬁcally, 35% of these involved four ma-
licious forwarding devices, 25% six forwarding device, 40%
nine forwarding devices. In real-world scenarios, an attacker
who has taken over nine forwarding devices of a network is a
strong adversary. Speciﬁcally, in AARNet Setup this means
that the 75% of forwarding devices are compromised (this is
a condition not supported by [11] requiring the majority of
forwarding devices to be non-malicious).
9.4 Accuracy & Detection Time
We measured WedgeTail’s detection accuracy in respect
to A) Successful detection rate against attacks implanted in
our simulated networks, B) Successful detection rate under
network congestion leading to packet loss C) Successful ap-
plication of pre-deﬁned policies against malicious forwarding
devices.
For A, we implanted attacks as speciﬁed in §9.3 over our
simulated networks. We then used WedgeTail to measure
the absolute time taken to detect the faults. The detection
time is deﬁned as the time taken to raise an alarm from
the instant a malicious packet is routed over the network
by a forwarding device. We report that all of the 500 at-
tacks implanted in the networks were successfully detected
by WedgeTail. The distribution of attacks over the net-
works was as following: 50 were over AARNet Setup, 250
over Zib54 Setup and 200 over Sprint Setup. Essentially,
AARNet Setup was part of our feasibility study stage and
Zib54, and Sprint Setups serve to prove the practicality of
WedgeTail in real-world. We illustrate the detection time of
50 attacks separately over network AARNet Setup, B and
C in Figure 5, 7 and 6, respectively. The average detection
time over AARNet Setup is about 54 second with a stan-
dard deviation of 12 seconds. For Zib54 Setup, the average
detection time is about 705 second with a standard devia-
tion of 80 seconds. For Sprint Setup, the average detection
time is 5600 second with a standard 730 second. Moreover,
the average detection times were not aﬀected in the presence
of Compound Attacks (see §9.3). The latter is, in fact, ex-
pected given that the detection algorithm entails analyzing
each and every forwarding device and the response engine is
not triggered until the end of a full scan.
The aforementioned performance metrics show that Wed-
geTail’s detection time scales well as the network size in-
creases. The detection time of attacks over network snap-
shots is also acceptable. In other words, for a network ad-
ministrator to be able to detect and locate malicious for-
warding device after about 90 minutes without deﬁning any
policies or manual investigation is quite satisfactory.
857Detection
Accuracy
Delay
3 minutes
5 minutes
10 minutes
98.83
99.17
99.38
False
Positive
False
Negative
3
3
8
0.76
0.69
0.48
Table 3: Overall detection results of attacks in the presence of packet
drops due to congestion.
For B, we added random congestion to the simulated net-
works, which resulted in packet drops at various points in
the simulated networks. The dropped rate varied as 0, 0.005,
0.0075, 0.01, 0.015 and 0.02 of the 1K TCP ﬂows sent over
the simulated networks. Table 2 shows the overall detection
results after detection delays of 3, 5 and 10 minutes – Wed-
geTail attack detection is started after the detection delay
time. Note that we added multiple bottlenecks throughout
the networks. The results prove that packet loss due to
congestion is not a prohibitive factor for our system. Wed-
geTail is now only able to distinguish between packet drops
due to congestion and maliciousness. We acknowledge that
we have not measured the impact of congestion on successful
malicious forwarding device localization and we leave further
investigation for our future work.
Regarding C, we report that WedgeTail has matched poli-
cies with the threats and applied the actions speciﬁed in the
policies for all attacks.
9.5 Performance Analysis
In this section, we report on some of the main performance
metrics of WedgeTail. Thereafter, we compare WedgeTail’s
performance with related work.
1. Target Identiﬁcation: Figure 8 illustrated the target
identiﬁcation time with respect to the number of forwarding
devices that exist in networks. The algorithm takes approx.
18 seconds to identify the target forwarding devices in AAR-
Net Setup with 400 trajectories. This number increases to
up to 12 minutes for Sprint Setup, where there are approx.
640000 trajectories.
2. Network Replica: We calculated the replication de-
lays after 500 instances of updates in the original network,
and we observed an upper bound of approx. 15 seconds. To
the best of our knowledge, this is the ﬁrst system to main-
tain a virtual network replica both of the control plane and
data plane in SDNs.
3. Response Policy Matching: As shown in Figure
10, we observe that the average policy matching time as we
increase WedgeTail’s administrator deﬁned policies from 0
to 1000 is approximately 120 milliseconds. Note that un-
like SPHINX, WedgeTail’s policies are used by its response
engine only.
4. Resource Utilization: We observe WedgeTail reaches
a maximum CPU usage of approx. 15% and memory us-
age of approx. 18%. The CPU usage is mainly associated
with target identiﬁcation and packet tracking components
of WedgeTail.
5. User Perceived Latencies: WedgeTail is not a real-
time system, and it has no implication for the network users
when detecting threats. Comparatively, however, SPHINX
adds overhead to the network and causes delays. Given the
various advantages of WedgeTail compared to SPHINX in
detection and prevention, we consider this a bonus feature
for our system.
Comparison with Related Work: We discuss the rea-
sons as to why WedgeTail is non-comparable to network
troubleshooting solutions in §10. However, to put Wed-
geTail’s performance into perspective we report on the per-
formance metrics of Anteater [28], which takes a snapshot
of forwarding tables and analyze them for errors, and Net-
Plumber [18] that extends HSA into a real-time veriﬁcation
solution. Anteater has been tested on a 178 router topol-
ogy and takes more than 5 minutes to just check for loops.
NetPlumber may take up to 10 minutes to verify network
correctness after a given rule change. Comparatively, Wed-
geTail investigates for every instance of malicious action and
does more than just evaluating rule sets (e.g.
identifying
scanning targets, tracking packets as they traverse the net-
work, maintaining a network replica to remove trust from
forwarding devices, etc.) with a reasonably added overhead.