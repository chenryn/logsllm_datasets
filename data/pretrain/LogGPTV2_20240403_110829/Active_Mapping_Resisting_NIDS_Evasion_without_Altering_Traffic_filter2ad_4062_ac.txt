Currently, we have implemented network topology
and service discovery as well as the speciﬁc tests de-
scribed in Section 3.2.
We modiﬁed the Bro NIDS [Pa98] to use Active
Mapping proﬁles to properly interpret trafﬁc. (We note
that this integration may be done with any NIDS which
does TCP/IP stream reconstruction, since it will include
all the necessary decision points.) The integration was
straightforward; a few hundred lines of C++ code were
needed. The performance impact of the modiﬁcations is
discussed in the following section.
5 Experiments and Results
5.1 Observed Active Mapping Proﬁles
We ran the prototype Active Mapper at the Lawrence
Berkeley National Laboratory. The exact number of ac-
tive hosts during our scan is not known, but was esti-
mated based on other scans to be around 6,700. We ob-
tained nontrivial, consistent data (identical results over
three trials for something other than the hostname) for
just over 4,800 hosts. Many of the IPs for which we
did not obtain results are in DHCP blocks (hosts may
not always be present); in addition, many users employ
host-based ﬁrewalls which would prevent our scanning.
We are currently working on getting more precise data
here (we note that ﬁrewalls are likely to prevent the at-
tacks the NIDS is looking for in any case!). It is signiﬁ-
cant that we obtained results for virtually every machine
for which OS data were known; presumably most other
machines are more transient or are ﬁrewalled enough to
stop OS detection. We present Active Mapping proﬁles
by operating system in Figure 4. Some tests did not yield
results due to services’ being protected with TCP Wrap-
pers. We expect this limitation can be overcome in prac-
tice by adding the mapping machine to the hosts’ ACLs
as needed.
The amount of observed diversity in policy is remark-
able, given that we only ran ﬁve tests. While hosts with a
given operating system version exhibited the same poli-
cies, it is interesting note how policies changed for dif-
ferent versions of the same operating system. Linux in
particular seems to have undergone a number of pol-
icy changes, even during minor revisions of the kernel.
We also note that individual users can alter policies by
installing “hardening” or other patches. It is precisely
this diversity (borne out by our experiments) that under-
scores the need to disambiguate trafﬁc destined for each
host based its particular observed policy.6
For 173 hosts, we were unable to get results that were
consistent (deﬁned as getting identical results for three
trials). This is less surprising, perhaps, in light of the fact
that all but 29 of them were found to be printers, routers,
or scanners; many of the remaining 29 had unknown
operating systems. Furthermore, all but 36 of the 173
hosts gave consistent results for the trials which com-
pleted, but had one or more trials which did not com-
plete. This could be due to congestion. In all, only 10
machines which were not known to be special-purpose
devices yielded results with conﬂicting answers.
5.2 Stability of Results
We performed another mapping of the hosts at LBNL
about 5 months after the original study whose results are
presented above. The goal was to see what the “churn
rate” was like, i.e., how many IP addresses had come and
gone and whether or not proﬁles had stayed constant.
Ideally, one might perform such an analysis a smaller
time scales.
First, let us examine the differences between the sets
of IP addresses in the two runs. In the original mapping,
4,882 hosts provided nontrivial, consistent results; in the
second mapping 4,733 hosts did so. 1,122 IPs were in
the ﬁrst set, but not the second; of these 880 were in
DHCP blocks. 973 IPs were in the second set but not
the ﬁrst; 669 were in DHCP blocks. The large fraction in
DHCP blocks is important because the set of machines
in these blocks may have “IP churn” without “machine
churn”, which is more signiﬁcant for us, since it seems
feasible to inform the NIDS about DHCP lease updates.
We estimate the “machine churn” in DHCP blocks by
comparing the distributions of proﬁles among the DHCP
machines. As we can see from Figure 5, the distribution
is relatively stable; thus we expect that machine churn
should be manageable.
6We note that a ﬁrst-order approximation might be obtained by us-
ing known OS version information with a lookup table; it may even
make sense to run Active Mapping and then infer the OS from its re-
sults. We plan to investigate this relationship in the future.
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
9
IP Frag
TCP Seg RST in wnd RST outside wnd
OS
AIX 2
AIX 4.3 8.9.3
Cisco IOS
FreeBSD
BSD
BSD
Last
BSD
HP JetDirect (printer)
BSD-right
HP-UX B.10.20
HP-UX 11.00
IRIX 4.0.5F
IRIX 6.2
IRIX 6.3
IRIX64 6.4
Linux 2.2.10
Linux 2.2.14-5.0
Linux 2.2.16-3
Linux 2.2.19-6.2.10smp
Linux 2.4.7-10
Linux 2.4.9-31SGI XFS 1.0.2smp
Linux 2.4 (RedHat 7.1-7.3)
MacOS (version unknown)
netapp unknown
netapp unknown
NCD Thin Clients (no services exported)
OpenBSD (version unknown)
OpenBSD (version unknown)
OpenVMS 7.1
OS/2 (version unknown)
OS/2 (version unknown)
OSF1 V3.0
OSF1 V3.2
OSF1 V4.0,5.0,5.1
SunOS 4.1.4
SunOS 5.5.1,5.6,5.7,5.8
Tektronix Phaser Printer (unknown model)
Tektronix Phaser Printer (unknown model)
Tru64 Unix V5.0A,V5.1
Vax/VMS
Windows (95/98/NT4/W2K/XP)
BSD
First
BSD
BSD
BSD
BSD
linux
linux
linux
linux
linux
linux
linux
First
No result
No result
BSD
linux
linux
BSD
BSD
No result
BSD
BSD
BSD
BSD
First
Last
First
BSD
BSD
First
BSD
BSD
BSD
BSD
BSD
BSD
BSD
No result
No result
BSD
BSD
No result
BSD
BSD
BSD
BSD
BSD
BSD
BSD
No result
No result
No result
BSD
BSD
BSD
No result
No result
BSD
No result
BSD
BSD
Last
No result
BSD
BSD
BSD
BSD
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
No
Yes
No
No
Yes
Yes
Yes
Yes
No
Yes
No
No
No
No
No
No
Yes
No
No
No
No
No
No
No
No
No
No
No
Yes
No
No
No result
No result
Yes
No
Yes
Yes
No
Yes
Yes
Yes
Yes
Yes
No
Yes
Yes
Yes
Yes
No
No
No
Yes
No
No
No
No
No
No
No
Yes
No
No
No
Figure 4. Selected Observed Active Mapping Proﬁles. Active Mapping proﬁles observed, by operat-
ing system of the host. Tests reported correspond to those described in section 3.2. Operating
system data were not available for all mapping hosts, so the above table is not complete with
respect to our test set; in some cases, version numbers were not known. Some entries with
identical results across many versions of an OS have been summarized in one line; some very
similar OS versions with identical results have been omitted for brevity. A value of “No Result”
is due mostly to the use of TCP Wrappers; in some cases the mapped host did not support
the service required to perform mapping. Since every machine accepted a RST in sequence,
results for that test are not given.
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
10
Original Mapping
Second Mapping
in user time increases at the rate of somewhat less than
two seconds per host being mapped. As a result, paral-
lelism was limited, allowing steady-state rates of about
5 seconds per active host on the full-site mapping with
thousands of hosts. We expect that this ﬁgure could be
improved considerably with a better implementation.
5.4 Mapping Trafﬁc
We measured bidirectional network trafﬁc generated
during mapping. During a scan of a subnet with 101 live
hosts, we recorded statistics (taken over three trials) re-
lating to the number of bytes and packets generated by
scanning, both to and from the mapper. The results are in
Figure 6. ICMP packets were due to ICMP service dis-
covery, PMTU and hop count determination, and some
IP mappings. TCP packets were due to TCP service dis-
covery, PMTU and hop count determination (if ICMP
was not supported), and TCP mappings.
Total bytes
Total packets
ICMP packets
TCP packets
Packets/sec.
Bytes/sec.
Total
1.9MB  49KB
32,893  345
21,763  2
10,588  7
3.3  0.0
191  5
Per host
19KB
326
215
105
Figure 6. Trafﬁc generated by mapping 101
hosts on a single subnet. Three trials were
conducted.
5.5 NIDS Integration Tests
We modiﬁed the Bro NIDS by adding support for
disambiguation based on Active Mapping proﬁles; we
stress that the choice of NIDS was for convenience since
our techniques would apply equally to any TCP/IP-
analyzing NIDS. Our goals in testing were twofold: ﬁrst,
to ensure that using Active Mapping would indeed re-
sult in correct interpretation of network trafﬁc; second,
to check that using Active Mapping would not incur any
signiﬁcant runtime cost. Accordingly, we ran two set of
tests: ﬁrst, a synthetic test with ambiguous trafﬁc; sec-
ond, a comparison of the original and Active Mapping-
modiﬁed NIDS on real-world traces.
(We expect that
results would be substantially the same with any other
NIDS integration.)
i
s
e
n
h
c
a
m
f
o
r
e
b
m
u
N
 1600
 1400
 1200
 1000
 800
 600
 400