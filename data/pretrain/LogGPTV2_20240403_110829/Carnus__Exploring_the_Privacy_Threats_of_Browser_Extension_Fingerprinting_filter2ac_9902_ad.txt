10,620
10,620
10,459
8,646
102,482
Note: We convert
to absolute numbers when the original work reports
percentages. *Estimation based on detectable changes to DOM tree; signatures
were not created or tested. **Number estimated by authors since the presented
attack relies on random UUIDs which have not been deployed by Chrome yet.
intra-communication we detect 450; the number of extensions
that cannot be detected by other means is 181 and 105
respectively. The number of extensions that can be detected
by each one of the four techniques are summarized in Table I.
While our two new communication-based techniques detect a
smaller number of extensions, this is because such behavior
is less common among extensions and not due to limitations
of our ﬁngerprint-generation process. Furthermore, these two
techniques are able to detect extensions that are not detectable
by previously known techniques.
Next, in Table II we compare to prior work and ﬁnd that
our system has created the largest set of detectable extensions
to date. Most of these studies [24], [44], [46], [47] focused on
detecting extensions through exposed WARs (either directly or
through some indirect/side channel) – we statically analyzed
over 102K extensions to create the most complete collection
of Chrome extension WAR ﬁngerprints. More importantly, we
create the ﬁrst collection of automatically generated behavioral
extension ﬁngerprints, which enable our novel analysis and
evaluation of their deployment in a realistic setting.
Figure 2 presents the number of installations for the
102,482 extensions in our collection. Around 43% of the
extensions have more than 100 installations, while around
20% of them have been installed more than 1000 times. In
Figure 3 we compare the detectability of extensions with their
popularity. We calculate their relative popularity based on the
9
number of installations of each extension and ﬁnd that there is
a clear correlation, as more popular extensions have a higher
likelihood of being detectable by Carnus.
Furthermore, for the extensions that modify the page’s
contents, we ﬁnd that 5,119 out of the 5,793 (88.36%) exten-
sions always perform the same modiﬁcations (i.e., they have a
single behavioral ﬁngerprint). For the extensions that exhibit
more than one behaviors, we ﬁnd that 177 (3.05%) have two
different ﬁngerprints (i.e., the three runs produce two identical
ﬁngerprints and one that is different from the other two) and
497 (8.57%) extensions that have three different ﬁngerprints.
Figure 4 presents the size of the behavioral ﬁngerprints of the
extensions in our dataset. For the extensions that have more
than one ﬁngerprints, in Figure 4 we consider the extension’s
ﬁngerprint with the largest size. We ﬁnd that more than half
of the extensions (54.6%) have a small ﬁngerprint (up to
10 terms), revealing that extensions typically do not heavily
modify pages. Around 26% have ﬁngerprints of 10 to 50
terms, while 19.5% have ﬁngerprints larger than 50. Finally,
less than 4% of the ﬁngerprints contain more than 1K terms;
these extensions inject entire scripts, like extension UUID:
ohahllgiabjaoigichmmfljhkcfikeof, or CSS ﬁles, like
UUID: ngkinkknobojamikjhodnojnpkbgpddp.
Practical extension enumeration. While detecting a stan-
dalone extension is a fairly straightforward task, we are also
interested in evaluating our system’s extension enumeration
capabilities when multiple extensions are simultaneously in-
stalled, as would be the case in a realistic scenario. We setup
an experiment where our system randomly selects and installs
K ﬁngerprintable extensions from our dataset and visits our
honeysite. We only use ﬁngerprintable extensions since non-
ﬁngerprintable extensions do not affect detection or interfere
with other extensions in any way, and using them would
artiﬁcially boost our true positive rate. As such, this experi-
ment truly explores the challenge of extension enumeration in
practical settings, and is the ﬁrst to shed light on the intricacies
of behavioral-based extension ﬁngerprinting.
Table III presents the results of this experiment; we cal-
culate scores over 100 independent runs for each size of K,
where in each run K extensions are randomly installed. TP
refers to correctly detected extensions, FP denotes extensions
incorrectly detected as installed, and FN is installed extensions
that our system could not detect. Since Carnus can detect more
extensions than those that are actually installed, the TP+FP
020406080100100101102103104105106107Extensions (CDF)Installations 0 5 10 15 20 25 30 35 401-10K10K-20K20K-30K30K-40K40K-50K50K-60K60K-70K70K-80K80K-90K90K-103KDetectable (%)Popularity (based on installations)020406080100100101102103104Extensions (CDF)Fingerprint sizeTABLE III: Carnus’ accuracy in multi-extension environments.
TP (%)
FP (%)
FN (%)
F1 (%)
2
97.5
0.5
2.5
98.5
3
97
4
3
96.5
4
98
7.25
2
95.5
5
98.6
5.4
1.4
96.7
6
98.5
6.2
1.5
96.3
7
97.6
6.7
2.4
95.5
8
98.9
3.4
1.1
97.8
9
97.5
7
2.4
95.4
10
98.9
2.5
1.1
98.2
percentages can add up to more than 100%, e.g., if the user
has 4 extensions installed but our system returns 5 detected
extensions. An important detail is that certain extensions have
the same functionality, perform the same modiﬁcations and
have identical ﬁngerprints. This can occur because developers
publish multiple instantiations of the same extension (e.g., in
different languages). For example, the extensions “TinyFilter
PRO”, “Tiny WebFilter” and “WebFilter FREE” are offered by
the same developer and have the same functionality. Similarly,
extensions like ad-blockers exhibit essentially the same func-
tionality can be indistinguishable. We ﬁnd that 349 extensions
are affected by such ambiguous ﬁngerprints, which is less
than 5.5% of the extensions that are ﬁngerprintable through
our behavioral techniques. In the table we do not count the
additional labels of extensions with identical ﬁngerprints as
false positives. For instance, in the aforementioned example,
the three identical extensions will be considered as one label
when calculating the FP rate.
As shown in Table III, our system correctly identiﬁes ∼97-
99% of the installed extensions in all cases, indicating the
consistent accuracy of our system. The extensions that Carnus
misses (i.e., FN: ∼1-3%) are extensions that perform new
modiﬁcations for which we do not have a ﬁngerprint or are the
result of extension co-interference. After analyzing our results
we found that the main reason behind these false negatives is
the co-interference between the installed extensions, where the
modiﬁcations of one extension can affect the modiﬁcations of
the other. This co-interference can also cause false positives,
as the combined effect of multiple extensions can result in
matching the ﬁngerprint of an extension that is not installed
in the user’s browser. Another reason for false positives is
that Carnus allows certain mismatches when comparing ﬁnger-
prints, which can lead to misclassifying extensions that have
similar ﬁngerprints and whose differences fall within the range
of allowed mismatches. The FP rate is less consistent, with an
average of 4.77% across all values of K. If we do include
the labels of multiple identical extensions as false positives
(e.g., in the previous example 2 of the 3 identical extensions
would count towards the false positives) our average FP rate
across all sizes of K becomes 8.1%. Nevertheless, despite the
challenging nature of behavior-based ﬁngerprinting in practice,
our system is highly accurate with an F1 score of 95.4-98.5%.
Countermeasure effects. Trickel et al. [55] recently pro-
posed CloakX as a defense against extension ﬁngerprinting.
While their approach is obviously not effective against our
inter- and intra-communication ﬁngerprints, we want to quan-
tify its effectiveness against our other behavior-based ﬁnger-
prints that fall within their threat model. In that work, they sep-
arate behavior-based ﬁngerprints into two different categories,
namely anchorprints and structureprints. However, since our
behavior-based ﬁngerprints cover both of their categories, for
ease of presentation we will continue to refer to them as
behavior-based ﬁngerprints. We refer the reader to their paper
for the full details behind their proposed countermeasure but, in
a nutshell, their system randomizes the values of ID and class
attributes to prevent behavior-based detection. They also inject
random tags, attributes, and custom attributes into each page,
and randomize the path of web-accessible resources. As such,
we analyze our behavioral ﬁngerprints and quantify the effect
of their proposed countermeasure on our system.
Since CloakX randomizes ID and class attributes, we ﬁrst
quantify the effect of removing all such ID and class element
additions from the behavioral ﬁngerprints. We ﬁnd that the
ﬁngerprints of 2,790 (48.16%) extensions do not rely on such
elements and are thus not affected by the proposed defense.
Out of the remaining ﬁngerprints, we ﬁnd that 751 (12.96%)
are affected in a way that would prevent uniquely identifying
the extensions. When we also consider our communication-
based ﬁngerprints, 51 of these 751 extensions can be identiﬁed.
Thus, 5,093 (87.92%) extensions are not affected by this
countermeasure.
To prevent WAR-based detection CloakX replaces exten-
sions’ WAR paths with a randomized value. While this coun-
termeasure is effective against WAR-based detection, it does
not affect our behavior-based detection. When a WAR URL
(i.e., chrome-extension:///) is included
in the extension’s behavioral ﬁngerprint, CloakX can only
randomize the resource’s path and not the UUID. Thus, we can
discard the randomized path from the behavioral ﬁngerprint,
as shown in the last example in Listing 5, and the ﬁngerprint
will still be unique among all our behavioral ﬁngerprints.
Regarding the effect of tags and attributes being randomly
added by CloakX, this can be counteracted using Carnus’s
mechanism for detecting and removing dynamic content from
the ﬁngerprints. Speciﬁcally, by visiting our honeysite multiple
times during the ﬁngerprint generation, our system can detect
which added terms remain the same across visits and which
ones change. For the extensions that have only one behavioral
ﬁngerprint in our database3 Carnus can safely ﬁlter out the
randomly added artifacts, without affecting the extensions’
ﬁngerprints. To that end, from the 5,093 extensions that our
system can identify after removing the ﬁngerprints with ID
and class attributes, we end up with 4,800 extensions that
have only one ﬁngerprint in our database (313 of them were
re-written to remove dynamic parts of partially matching
terms). From the 293 extensions that have ﬁngerprints that
could potentially be affected by CloakX randomly adding
tags and attributes, 250 do not have any communication-based
ﬁngerprints. Even though the random tags added by CloakX
to the ﬁngerprints of these 250 extensions can most likely be
identiﬁed and removed with a sufﬁcient number of visits to our
honeysite, in the worst case scenario where our system is not
able to remove the added tags and attributes for any of these
250 extensions, 4,843 out of the 5,793 (83.6%) extensions that
have behavioral ﬁngerprints will remain unaffected. Overall,
Carnus will be able to uniquely identify 83.6% - 87.92% of
the extensions that have behavioral ﬁngerprints even if CloakX
is deployed.
3This includes extensions that always perform the same modiﬁcations, and
extensions with ﬁngerprints that differ only because of partially matching
terms, which our system re-writes into a single ﬁngerprint after discarding the
dynamic part of the partially matching terms, as explained in Section III-B.
10
System performance. As discussed in Section III, during
the ﬁngerprint generation phase our system visits our honeysite
with a single extension installed and captures all the modiﬁca-
tions, message exchanges, and resource fetching conducted by
the extension. Carnus waits for 15 seconds before capturing the
contents of the page and generating the behavioral ﬁngerprints,
so as to allow enough time for all the modiﬁcations to take
place and the external resources to be fetched. The processing
for generating the ﬁngerprints (i.e., constructing the sets of
added and removed terms) takes less than 1 second. Since
each extension needs to be dynamically analyzed 3 times, we
parallelize 3 different browser instances and the overall time
that is spent for exercising each extension during the dynamic
analysis phase does not exceed 16 seconds. This process is
performed once per extension and only repeated if a newer
version of an extension is released; given the low overhead it
is more than suitable for practical large scale deployment.
A more critical dimension of a ﬁngerprinting system’s
performance is the time required for the extension detection
phase. During our implementation, our goal was to minimize
the overhead that our system imposes on the client side and,
thus, minimize the time a user needs to stay on our website for
Carnus to detect her installed extension. For this, we ofﬂoad
all the processing for behavior-based detection to the server,
which includes matching the modiﬁcation and communication
signatures with the stored extensions’ ﬁngerprints etc. The
JavaScript code in our page that is responsible for the WAR-
based detection, obviously, needs to run on the client side.
To assess this aspect of our performance, we conduct exper-
iments using an off-the-shelf commodity desktop machine with
a Quad Core Intel i7-7700 and 32GB of RAM. Speciﬁcally, we
automate a browser instance that has 4 extensions installed to
visit our honeypage. We then measure the time that is required
for processing to complete both on the client and server side.
We run this experiment 300 times with a different set of 4
randomly-selected extensions installed each time. The client
side processing requires 8.77 seconds on average (stdev: 0.39),
with a median value of 8.58 seconds. The server only requires
3.62 seconds on average (stdev: 1.83), with a median of 2.94
seconds. In other words, since the backend processing is not
dependent on the user remaining on the page, Carnus requires
the user to stay on our honeysite for less than 10 seconds to
successfully detect the installed extensions. This highlights the
efﬁciency of our attack and its practicality in deployment in
realistic scenarios. To examine whether the number of installed
extensions affects the processing time that is required, we
repeat the experiment with 5 extensions being installed, and
ﬁnd that the average duration remains essentially the same.
VI. EXPERIMENTAL EVALUATION: INFERENCE
While extension enumeration can be used as part of the
browser ﬁngerprinting process, the set of detected extensions
can also be used to infer sensitive information about that
user, which could enable or facilitate a wide range of privacy-
invasive practices, from government surveillance of religious
minorities [7] to tailored advertising that
targets sensitive
topics [16], [34] (e.g., health issues).
Extension classiﬁcation. The ﬁrst phase of our inference
attack uses Google’s Natural Language API for identifying the
Fig. 5: Categories of extensions that reveal personal and
potentially sensitive information.
categories that better describe each extension. This allows us to
classify 20,409 of the extensions in our dataset; the remaining
9,019 extensions could not be assigned to any category, mainly
due to them having a very short description text.
As one might expect, the most popular category is that
of Computing (subclasses: Multimedia, Programming, Internet
Software, etc.) with 7,652 extensions. The next most popular
category is related to Social Networks with 4,977. While such
categories do not reveal any information that is interesting