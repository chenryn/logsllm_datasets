Ch a pt e r  Tw e n t y -Se v e n
Ad v a n c e d  Lin u x  To o l s
Next, every application mentioned within this chapter is already present within your VM which possesses an 
automated script to help you along the usage. If you completed all of the steps within Chapter Five and created 
a custom OSINT virtual machine, you are ready to start using each of these applications. I encourage you to 
boot to a CLONE of your "OSINT Original" VM and test the lessons as you progress through this chapter. 
Your previous work will pay off here and allow you to jump right in. I still present the manual steps for 
installation, configuration, and usage for each application in order to understand the process. None of these 
steps need to be replicated if you simply want to launch each program within your custom VM.
I previously explained the power of the Internet Archive while searching for online content which has since 
been removed. Browsing a target domain on the Wayback Machine website can be very fruitful, but automating 
the collection of data can be more beneficial. The "Internet Archive Tool" script, titled "intemetarchive.sh" in 
the download takes advantage of a Python script called "waybackpy", which was installed previously with the 
command sudo -H python3 -m pip install waybackpy. Launching the script presents a single 
domain entry window which accepts a domain or specific URL. Executing the script conducts the following 
tasks, using pretendradio.org as a target.
Before we begin, there are two very important details. First, I will not display the full code from within the 
scripts and shortcuts of each program. You can easily navigate to the "scripts" and "shortcuts" folders within 
the "vm-files" archive which you previously downloaded if you want to view the entire code. Displaying the 
lengthy text within this chapter might be considered redundant and a waste of paper. I only focus on the benefits 
of each tool here.
Some readers skip this chapter until they become more comfortable within Linux. However, I believe those 
within any skill level can replicate all tutorials. Most applications will feel similar to the automation previously 
discussed in Section One.
The first section of this book focused heavily on a Linux virtual machine, and I explained numerous applications 
which assist our investigations. Those programs demanded a single piece of information, which allowed me to 
present scripts to automate the processes. As an example, the Instagram tools prompt you for a username and 
then execute the proper commands in order to simplify the process. This chapter has many similarities but also 
some key differences. It contains some advanced applications which would be impossible to automate with 
simple scripts and applications which require the lessons explained within previous chapters. Some of these 
programs require heavy user input with features which must be tackled within Terminal while others present 
automation similar to the options presented within the first section of this book.
Download the oldest known archive URL into a text file:
pretendradio. txt
waybackpy —url '’https://pretendradio.org" —oldest
Append the file with the newest archive URL:
waybackpy —url "https://pretendradio.org" —newest » pretendradio.txt
Append the file with URLs from the past ten years:
2013
2014 »
—year 2017
—near
2018
2019 »
2020 »
Remove duplicates and sort by date:
sort -u -i pretendradio.txt
pretendradio.sorted.txt
Generate screen captures of all unique links with only one thread (slower):
1
webscreenshot
chrome -i pretendradio.sorted.txt
Download source code of the oldest and newest archives:
414 Chapter 27
• waybackpy —url "https://pretendradio.org" —get oldest
• waybackpy —url "https://pretendradio.org" —get newest
> oldest.html
> newest.html
The result is a "pretendradio.org" folder within Documents/waybackpy which includes a text file of over 500 
URLs (with duplicates) of potential evidence on the target domain; a text file of five known archives of the 
target website; screen captures of all five archives; and source code of the newest and oldest archive. Figure 
27.01 displays a result which identifies the way the target website appeared in April and October of 2017. 
Imagine you have a target URL which has hundreds of archives throughout the past decade. This is a quick 
way to see annual changes to the site and document the evidence. When the tool completes, you will be 
presented with the folder containing all of the data.
waybackpy —url "https://pretendradio.org” —near —year 2010 » 
pretendradio.txt
waybackpy —url "https://pretendradio.org" —near —year 2011 » 
pretendradio.txt
waybackpy —url "https://pretendradio.org" —near —year 2012 » 
pretendradio.txt
waybackpy —url "https://pretendradio.org" —near —year
pretendradio.txt
waybackpy —url "https://pretendradio.org" —near —year
pretendradio.txt
waybackpy —url "https://pretendradio.org" —near —year 2015 » 
pretendradio.txt
waybackpy —url "https://pretendradio.org" —near —year 2016 » 
pretendradio.txt
waybackpy —url "https://pretendradio.org"
pretendradio.txt
waybackpy —url "https://pretendradio.org" —near —year
pretendradio.txt
waybackpy —url "https://pretendradio.org" —near —year 
pretendradio.txt
waybackpy —url "https://pretendradio.org" —near —year 
pretendradio.txt
Figure 27.01: Screen captures from the automated Internet Archive Tool.
$url.sorted.txt
wget
The Internet Archive; creates
Q prison!
Location
Name
Size
☆  Starred
(J Home
index.html.4 ...Jane Whaley s Son-in-Law is Coing to Prison...
214.9 kB
C Desktop
Documents
index.html.9 ...Jane Whaley's Son4n-Law is Coing to Prison...
136.2 kB
0 Downloads
index.html.10 ...Jane Whaley's Son-in-Law is Coing to Prison...
204.0 kB
J3 Music
index.html.15 ...Jane Whaley's Son-in-Law is Coing to Prison...
136.2 kB
2 Pictures
index-htmLl 6 ...Jane Whaley's Son-in-Law is Going to Prison...
204.0 kS
0 Videos
Figure 27.02: Search results from a keyword search within archived web pages.
Advanced Linux Tools 415
0
Q
□
143 3 kB
This places several files within the "waybackpy" folder within your "Documents" folder. In this example, they 
included the following.
index. html 
index. html. 1 
index, html. 2 
index.html. 3
11.3 ...JaiwV/balcA SoMn-UwtsGan;
In summary, this tool compiles a list of URLs related to the target website on 
screen captures of those pages; and extracts the text in order to search quickly.
Now that we have screen captures of these pages, we should also extract the text. The automated script included 
with your custom VM conducts the following at die end of the cycle.
Each of these is an archived home page of the target website from a different date. Double-clicking them will 
load the pages within a web browser which should display the target site similar to the way it appeared previously. 
However, a keyword search can also be beneficial. You can use die embedded search function within the Files 
application which is presented after successful completion of the script. Figure 27.02 displays my search of these 
files for the word "prison". The results identify' files of interest which I need to further investigate.
GHunt
requirements.txt -I
• python3 ghunt.py email PI:EMAIL
416 Chapter 27
• cd ~/Downloads/Programs
• git clone https://github.com/mxrch/ghunt
• cd ghunt
• sudo -H pip install
• cd ~/Downloads/Programs/ghunt
• python3 check_and_gen.py
Now that you possess the various account details required by GHunt, you can supply this data to the program 
As long as these settings are not changed or refreshed by Google, you can reuse them for several queries. If you 
have followed my custom VM tutorials, the "Usemame/Email" tool is already configured to assist you with this 
process. Simply launch the tool and select the option tided "GHunt Configuration". If you want to do this 
manually, you would enter the following within Terminal.
This Terminal-based program requires some work to configure it properly, but the rewards justify the efforts. 
If you followed the steps within Chapter Five while recreating your custom virtual machine, you have already 
installed the software. If you did not follow that chapter, the following will get you set up.
SID: EthaBDv-SLCzi5-fGYFsgQEpsniuXp4vFdhSyxbfsgtJhePrKh7HWRhgfK42I4MoDa2Da
SSID: AhMQD6hufgMRsthCsVh
APISID: 90zgIYkLxDhgsLusoOl/AfJvEF8ihm_TfHOh86Cl s
SAPISID: XsCNhC7fDVIE8hNY4Sr/AJfwurhpUkbFvsfUqBrP
HSID: Afrno3fgHjaUfpPhmfgRxfhZFQ
LSID: o.chatgoogle.com | o.mail.google.com | s.youtube:EQhaBIp83rHin-E_4hhykliVKWSZqPSfWl
_Secure-3PSID: EQjhaBDv-SCzi5-fGWYFsEpp4vFSf65yxbsgtJePrK7iOvBWuPnsdBiyw
Whichever path you choose, you will be presented with a menu. Select the option labeled " [3] Enter manually 
all cookies". This will prompt you to provide your own SID, SSID, APISID, SAPISID, HSID, LSID, and 
__Secure-3PSID as previously obtained. Allow the application to complete the sign in process with these 
cookies. Once finished, you can now play with the options. You can either launch the "Usemame/Email" tool 
from your custom VM or enter the command manually. I will explain both. First, let's look at email. The 
following manual Terminal command queries an email address from within the GHunt installation folder.
• 
Navigate to gmail.com and log in to an active Google account.
• 
Right-click within this page and choose "Inspect".
• 
Click the "Network Tab" in the lower box.
• 
Navigate to myaccount.google.com within this web browser tab.
• 
Select the row labeled "302 GET accounts.google.com" within the inspectoi
• 
Click the "Cookies" tab in right window.
Next, you must possess valid login cookies from an active Google account This is because the Google API, 
which you will use to find information about various accounts, requires you to be logged in to an account in 
order to access these details. Therefore, you must acquire several pieces of data from your own Google account 
I recommend using an account which you rarely access. As long as you do not log in to this account from a web 
browser AFTER you obtain these cookies, they should stay valid for long-term usage. Conduct the following.
You should now see several identifiers related to your Google account. Find each of the fields which are listed 
below, and document the data associated with your own account. I have provided sample data below.
The result is as follows.
The result is as follows.
Advanced Linux Tools 417
• python3 ghunt.py youtube https://www.youtube.com/channel/UC_gH-
AQqoOUZ4ykZBCLdvww
• python3 ghunt.py doc https://docs.google.eom/spreadsheets/d/
!BxiMVsOXRA5nFMdKvBdBZ jgmUUqptlbs740gvE2upms
Document ID: 1BxiMVsOXRA5nFMdKvBdBZjgmUUqptlbs740gvE2upms
[+) Creation date : 2011/05/12 18:29:28 (UTC)
[+] Last edit date : 2011 /05/12 18:29:28 (UTC)
Public permissions:
-reader
(+) Owner found I
Name: A Googler
Email: PI:EMAIL
Google ID: 02845897149113753960
[+) Custom profile picture I
=> https://lh3.googleusercontent.com/a-/AOh14GhXaVAhS8Ci08Xito5iVJVsooEhsgUIGhZ45NjTf03s64
Profile picture saved I
We now know the document creation date/rime; the last modified date/time; owner name; owner email; owner 
Google ID; and owner Google profile image. The automated version of this can also be found in your 
"Username/Email" tool within your OSINT VM. Next, we can manually enter the following command to query’ 
a YouTube channel URL.
(+] 1 account found 1
Name: Larry Page
[+] Custom profile picture I
=> https://lh3.gQogleusercontent.com/a-/AOh14GiUjlWnt4MNgr7Wmeyb3PzXlka4E8PFEIIF27olxlA
Profile picture saved I
Last profile edit: 2021/11/27 10:01:21 (UTC)
Email: PI:EMAIL
Gaia ID : 111627209495762463002
Hangouts Bot: No
[+] Activated Google services:
- Hangouts - Photos - Maps
[+] YouTube channel (confidence => 37.5%):
-[Larry Page] https://youtube.com/channel/UCmpDzlgzPdbzShSzH48mCHg
-[Larry Page] https://youlube.com/channel/UCJuR7fG13KEpEPr8EH7bsgw
-(Larry Page] https://youtube.com/channel/UCNXk_sA4Kv3rDIYo8vl-gLQ
- [Larry Page] https://youtube.com/channel/UCefpKs_qOUsJV5_1n5_H13A
Google Maps: https://www.google.com/maps/contrib/111627209495762463002/reviews
[•] No reviews
Google Calendar: https://calendar.google.eom/calendar/u/0/PI:EMAIL
[-] No public Google Calendar.
Let's dissect our findings. We now know the name of the user and his profile photo has been saved within the 
"profile_pics" folder inside the GHunt installation directory. We are provided a date and time of his last profile 
update; his Google Accounts and ID Administration ID (GAIA); his four YouTube channels; and confirmation 
that he uses Hangouts, Photos, and Maps. We also know that he has not written any map reviews. This summary 
was provided almost instantaneously. If using the custom OSINT VM, the "Username/Email" tool with the 
"GHunt Email" option replicates this process. However, the custom script also outputs the data to a text file 
within your Documents folder and opens all results upon completion. The followingTerminal command would 
search a Google document
The result is as follows.
python3 ghunt.py gaia 105144584335156066992
The result follows.
I?
5
Figure 27.03: The GHunt options within the custom script provided in Chapters Five and Six.
418 Chapter 27
Finally, we can query a Google Accounts and ID Administration ID (GAIA) with the following manual 
command.
All of these options 
previously
© Sherlock
SocialScan 
Holehe 
WhatsMyName 
Email2Phone
GHunt Email
GHunt Doc
GHunt YouTube Channel
GHunt GAIA
GHunt Configuration
Name : Thrice
[+] Custom profile picture !
https://lh3.googleusercontent.com/a-/AOh14GjnQudTez6UmMPhl16UWH-hH_Uq5MhBvDkNcLXX
Gaia ID : 105144584335156066992
[+] YouTube channel (confidence => 50.0%):
- [Thrice] https://youtube.com/channel/UC_gH-AQqoOUZ4ykZBCLdvww
Google Maps : https://www.google.com/maps/contrib/105144584335156066992/reviews
Q Sherlock
SocialScan
Holehe
WhatsMyName
3 Email2Phone
(3 GHunt Email
© GHunt Doc
GHunt YouTube Channel
GHunt GAIA
GHunt Configuration
L) Sherlock
2) SocialScan
) Holehe
4) WhatsMyName
5) Email2Phone
Is) GHunt Email
GHunt Doc
GHunt Youtube Channel
GHunt GAIA
110) GHunt Configuration
m.) Exit
[Youtube channel]
[+] Channel name : Thrice
[+] Snapshot: 12/09/2016
[+] GaialD => 105144584335156066992
[-] Email on profile : not available.
[+] Country : United States
Description : New Album 'Horizons/Easf, out digitally now. Vinyl/CD available Oct 8 on Epitaph Records. Available 
now for pre-order - https://thrice.ffm.to/horizonseast
Total views: 78,701.229
Joined date: Dec 7,2015
[+] Primary links (6 found)
- Horizons/East => https://thrice.ffm.to/horizonseast