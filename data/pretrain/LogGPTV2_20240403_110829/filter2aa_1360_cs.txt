### Chapter Twenty-Seven: Advanced Linux Tools

In this chapter, we will explore advanced Linux tools that are already pre-installed in your virtual machine (VM). These tools come with automated scripts to facilitate their usage. If you have completed the steps in Chapter Five and created a custom OSINT (Open-Source Intelligence) VM, you are ready to start using these applications. I recommend booting a clone of your "OSINT Original" VM to test the lessons as you progress through this chapter. This will allow you to leverage your previous work and dive right in.

I will provide manual installation, configuration, and usage steps for each application to help you understand the process. However, if you are using the custom VM, you do not need to replicate these steps; you can simply launch each program.

#### The Power of the Internet Archive

In earlier chapters, I discussed the power of the Internet Archive for finding online content that has since been removed. Browsing a target domain on the Wayback Machine website can be very fruitful, but automating the collection of data can be even more beneficial. The "Internet Archive Tool" script, named `internetarchive.sh` in the download, utilizes a Python script called `waybackpy`, which was installed previously with the command:

```bash
sudo -H python3 -m pip install waybackpy
```

To use the script, follow these steps:

1. Launch the script, which will prompt you to enter a domain or specific URL.
2. Execute the script to perform the following tasks, using `pretendradio.org` as an example:

   ```bash
   # Download the oldest known archive URL into a text file
   waybackpy --url "https://pretendradio.org" --oldest > pretendradio.txt

   # Append the file with the newest archive URL
   waybackpy --url "https://pretendradio.org" --newest >> pretendradio.txt

   # Append the file with URLs from the past ten years
   for year in {2013..2022}; do
       waybackpy --url "https://pretendradio.org" --near --year $year >> pretendradio.txt
   done

   # Remove duplicates and sort by date
   sort -u -i pretendradio.txt > pretendradio.sorted.txt

   # Generate screen captures of all unique links with only one thread (slower)
   webscreenshot chrome -i pretendradio.sorted.txt

   # Download source code of the oldest and newest archives
   waybackpy --url "https://pretendradio.org" --get oldest > oldest.html
   waybackpy --url "https://pretendradio.org" --get newest > newest.html
   ```

The result is a `pretendradio.org` folder within `Documents/waybackpy` that includes:
- A text file with over 500 URLs (including duplicates) of potential evidence on the target domain.
- A text file with five known archives of the target website.
- Screen captures of all five archives.
- Source code of the newest and oldest archives.

Figure 27.01 shows a result that identifies how the target website appeared in April and October of 2017. This method is useful for quickly seeing annual changes to a site and documenting the evidence.

#### GHunt

GHunt is a powerful tool for extracting information from Google accounts. If you followed the steps in Chapter Five, GHunt is already installed in your custom VM. If not, you can set it up with the following commands:

```bash
cd ~/Downloads/Programs
git clone https://github.com/mxrch/ghunt
cd ghunt
sudo -H pip install -r requirements.txt
python3 check_and_gen.py
```

To configure GHunt, you need valid login cookies from an active Google account. Follow these steps to obtain the necessary cookies:

1. Navigate to `gmail.com` and log in to an active Google account.
2. Right-click on the page and select "Inspect."
3. Click the "Network" tab in the lower box.
4. Navigate to `myaccount.google.com` within the same browser tab.
5. Select the row labeled "302 GET accounts.google.com" in the inspector.
6. Click the "Cookies" tab in the right window.

Document the following fields related to your Google account:

- SID
- SSID
- APISID
- SAPISID
- HSID
- LSID
- __Secure-3PSID

Once you have the cookies, you can use GHunt to query various Google services. For example:

```bash
# Query an email address
python3 ghunt.py email PI:EMAIL

# Query a YouTube channel
python3 ghunt.py youtube https://www.youtube.com/channel/UC_gH-AQqoOUZ4ykZBCLdvww

# Query a Google document
python3 ghunt.py doc https://docs.google.com/spreadsheets/d/1BxiMVsOXRA5nFMdKvBdBZjgmUUqptlbs740gvE2upms

# Query a GAIA ID
python3 ghunt.py gaia 105144584335156066992
```

The results will provide detailed information about the queried account, including creation dates, last edit dates, owner details, and more.

Figure 27.03 shows the GHunt options available in the custom script provided in Chapters Five and Six.

### Summary

This chapter covers advanced Linux tools that can be used for OSINT. The tools include the Internet Archive Tool and GHunt, both of which are pre-installed in your custom VM. By leveraging these tools, you can efficiently collect and analyze data from the Internet Archive and Google accounts.