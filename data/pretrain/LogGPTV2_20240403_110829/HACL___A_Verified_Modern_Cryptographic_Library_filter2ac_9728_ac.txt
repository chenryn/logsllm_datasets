ble to these works, but these efforts have the advantage of being
able to tackle legacy hand-optimized code, whereas we focus on
synthesizing efficient C code from our own implementations.
4 VERIFYING HIGH-PERFORMANCE
VECTORIZED IMPLEMENTATIONS
In the previous section, we saw how we can implement crypto-
graphic primitives in Low∗ by closely following their high-level F∗
specification. By including a few straight-forward optimizations,
we can already generate C code that is as fast as hand-written C ref-
erence implementations for these primitives. However, the record-
breaking state-of-the-art assembly implementations for these primi-
tives can be several times faster than such naive C implementations,
primarily because they rely on modern hardware features that are
not available on all platforms and are hence not part of standard
portable C. In particular, the fastest implementations of all the prim-
itives considered in this paper make use of vector instructions that
are available on modern Intel and ARM platforms.
Intel architectures have supported 128-bit registers since 1999,
and, through a series of instruction sets (SSE, SSE2, SSSE3, AVX,
AVX2, AVX512), have provided more and more sophisticated in-
structions to perform on 128, 256, and now 512-bit registers, treated
as vectors of 8, 16, 32, or 64-bit integers. ARM recently introduced
the NEON instruction set in 2009 that provides 128-bit vector oper-
ations. So, on platforms that support 128-bit vectors, a single vector
instruction can add 4 32-bit integers using a special vector pro-
cessing unit. This does not strictly translate to a 4x speedup, since
vector units have their own overheads, but can significantly boost
val uint32x4: Type0
val to_seq: uint32x4 → GTot (s:seq uint32){length s = 4}
val load32x4: x0:uint32_s → x1:uint32_s →
x2:uint32_s → x3:uint32_s →
Tot (r:uint32x4{to_seq r = createL [x0;x1;x2;x3]})
val ( + ) : x:uint32x4 → y:uint32x4 →
val shuffle_right: s:uint32x4 → n:uint32{to_int r >,<<<) are lifted to uint32x4,
and interpreted as the corresponding point-wise operations over
sequences of integers. In addition, the interface provides vector-
specific operations like load32x4 to load vectors, and shuffle_right,
which allows the integers in a vector to be permuted.
We provide C implementations of this interface for Intel SSE3
and ARM NEON platforms. Figure 6 shows a fragment of the Intel
library relying on GCC compiler intrinsics. This C code is not
verified, it is trusted. Hence, it is important to minimize the code
in such libraries, and to carefully review them to make sure that
their implementation matches their assumed specification in F∗.
However, once we have this F∗ interface and its C implementation
for some platform, we can build and verify vectorized cryptographic
implementations in Low∗.
4.2 Verified Vectorized ChaCha20
The ChaCha20 stream cipher was designed by D. Bernstein [15]
and standardized as an IETF RFC [1]. It is widely recommended as
an alternative to AES in Internet protocols. For example, ChaCha20
is one of the two encryption algorithms (other than AES) included
in TLS 1.3 [4]. The NaCl API includes Salsa20, which differs a little
from ChaCha20 [15] but for the purposes of verification, these
differences are irrelevant; we implemented both in HACL∗.
Figure 7 depicts a fragment of our RFC-based F∗ specification of
ChaCha20. ChaCha20 maintains an internal state that consists of 16
32-bit integers interpreted as a 4x4 matrix. This state is initialized
type state = m:seq uint32x4{length m = 4}
type idx = n:nat{n < 4}
let line (a:idx) (b:idx) (d:idx) (s:uint32{to_int s < 32}) (m:state) =
let ma = m.[a] in let mb = m.[b] in let md = m.[d] in
let ma = ma + mb in
let md = (md ^ ma) <<< s in
let m = m.[a] ← ma in
let m = m.[d] ← md in m
let column_round m =
let m = line 0 1 3 16ul m in
let m = line 2 3 1 12ul m in
let m = line 0 1 3 8ul m in
let m = line 2 3 1 7ul m in m
Figure 8: F∗ specification for 128-bit vectorized ChaCha20
Operators are defined over vector of 32-bit integers: see Figure 5.
using the encryption key, nonce, and the initial counter (typically
0). Starting from this initial state, ChaCha20 generates a sequence
of states, one for each counter value. Each state is serialized as a key
block and XORed with the corresponding plaintext (or ciphertext)
block to obtain the ciphertext (or plaintext). To generate a key block,
ChaCha20 shuffles the input state 20 times, with 10 column rounds
and 10 diagonal rounds. Figure 7 shows the computation for each
column round.
As we did for SHA-256, we wrote a reference stateful implemen-
tation for ChaCha20 and proved that it conforms to the RFC-based
specification. The generated code takes 6.26 cycles/byte to encrypt
data on 64-bit Intel platforms; this is as fast as the unvectorized C
implementations in popular libraries like OpenSSL and Libsodium,
but is far slower than vectorized implementations. Indeed, previous
work (see [18, 28]) has identified two inherent forms of parallelism
in ChaCha20 that lend themselves to efficient vector implementa-
tions:
Line-level Parallelism: The computations in each column
and diagonal round can be reorganized to perform 4 line
shufflings in parallel.
Block-level Parallelism: Since each block is independent,
multiple blocks can be computed in parallel.
We are inspired by a 128-bit vector implementation in SUPER-
COP due to Ted Krovetz, which is written in C using compiler in-
trinsics for ARM and Intel platforms, and reimplement it in HACL∗.
Krovetz exploits line-level parallelism by storing the state in 4 vec-
tors, resulting in 4 vector operations per column-round, compared
to 16 integer operations in unvectorized code. Diagonal rounds are
a little more expensive (9 vector operations), since the state vectors
have to be reorganized before and after the 3 line operations. Next,
Krovetz exploits block-level parallelism and the fact that modern
processors have multiple vector units (typically 3 on Intel platforms
and 2 on ARM) to process multiple interleaving block computa-
tions at the same time. Finally, Krovetz vectorizes the XOR step
for encryption/decryption by loading and processing 128 bits of
plaintext/ciphertext at once. All these strategies requires significant
refactoring of the source code, so it becomes important to verify
that the code is still correct with respect to the ChaCha20 RFC.
We write a second F∗ specification for vectorized ChaCha20
that incorporates these changes to the core algorithm. The portion
of this spec up to the column round is shown in Figure 8. We
modify the state to store four vectors, and rearrange the line and
column_round using vector operations. We then prove that the
new column_round function has the same functional behavior as
the RFC-based column_round function from Figure 7. Building up
from this proof, we show that the vectorized specification for full
ChaCha20 computes the same function as the original spec.
Finally, we implement a stateful implementation of vectorized
ChaCha20 in Low∗ and prove that it conforms to our vectorized
specification. (As usual, we also prove that our code is memory safe
and secret independent.) This completes the proof for our vector-
ized ChaCha20, which we believe is the first verified vectorized
implementation for any cryptographic primitive.
When compiled to C and linked with our C library for uint32x4,
our vectorized ChaCha20 implementation has the same perfor-
mance as Krovetz’s implementation on both Intel and ARM plat-
forms. This makes our implementation the 8th fastest in the SU-
PERCOP benchmark on Intel processors, and the 2nd fastest on
ARM. As we did with Krovetz, we believe we can adapt and verify
the implementation techniques of faster C implementations and
match their performance.
5 VERIFYING SECRET INDEPENDENT
MODULAR BIGNUM ARITHMETIC
Asymmetric cryptographic algorithms commonly rely on prime-
field arithmetic, that is, addition and multiplication modulo a prime
p in Zp. In HACL∗, the Poly1305, Curve25519, and Ed25519 al-
gorithms all compute on various prime fields. The mathematical
specification for these field operations is very simple; §2 shows the
6-line F∗ spec for the Poly1305 field.
For security, the primes used by cryptographic algorithms need
to be quite large, which means that elements of the field cannot
be represented by machine integers, and instead need to be en-
coded as bignums, that is, arrays of integers. Consequently, bignum
arithmetic becomes a performance bottleneck for these algorithms.
Furthermore, well known bignum implementation tricks that work
well for numerical computations are not really suitable for cryp-
tographic code since they may leak secrets. For example, when
multiplying two bignums, a generic bignum library may shortcut
the computation and return zero if one of the arguments is zero. In
a crypto algorithm, however, the time taken by such optimizations
may leak the value of a key. Implementing an efficient and secure
generic modulus function is particularly hard. Consequently, cryp-
tographic implementations are often faced with a trade-off between
efficient field arithmetic and side-channel resistance.
5.1 Efficient Bignum Libraries for Poly1305,
Curve25519, and Ed25519
For algorithms like RSA that use large and unpredictable primes,
implementations often choose to forego any side-channel resistance.
However, for modern fixed-prime primitives like Poly1305 and
Curve25519, it is possible to choose the shape of the prime carefully
so that field arithmetic can be both efficient and secret independent.
For instance, given a fixed Mersenne prime of the form 2n − 1, the
modulo operation is easy to implement: all the bits beyond n-th bit
can be repeatedly lopped off and added to the low n bits, until the
result is an n bit value. Computing the modulo for the Poly1305
prime 2130 − 5 or Curve25519 2255 − 19 in constant time is similar.
Once a suitable prime is picked, the main implementation choice
is whether to represent the field elements as packed bignums, where
each array element (called a limb) is completely filled, or to use an
unpacked representation, where the limbs are only partially filled.
For example, in the Poly1305 field, elements are 130-bit values and
can be stored in 3 64-bit integers. The little-endian packed layout
of these elements would be 64bits|64bits|2bits, whereas a more
evenly distributed unpacked layout is 44bits |44bits |42bits. The
main advantage of the unpacked layout is that when performing
several additions in a sequence, we can delay the carry propagation,
since the limbs will not overflow. In the packed representation,
we must propagate carries after each addition. Optimizing carry
propagation by making it conditional on overflow would not be
safe, since it would expose a timing side-channel. Indeed, most
efficient 64-bit implementations of Poly1305 and Curve25519 use
unpacked representations; Poly1305 uses the 44-44-42 layout on
64-bit platforms and 5 26-bit limbs on 32-bit platforms; Curve25519
and Ed25519 use 5 limbs of 51-bits each or 10 limbs of 25.5 bits each.
In summary, efficient implementations of Poly1305, Curve25519,
and Ed25519 use prime-specific computations and different un-
packed bignum representations for different platforms. Consequently,
each of their implementations contains its own bignum library
which must be independently verified. In particular, previous proofs
of bignum arithmetic in Poly1305 [23] and Curve25519 [25] are
implementation-specific and cannot be reused for other platforms
or other implementations. In contrast, Zinzindohoue et al. [37] de-
velop a generic verified bignum library in OCaml that can be used
in multiple cryptographic algorithms. The cost of this genericity is
significantly reduced performance. In the rest of this section, we
present a novel approach that allows us to share verified bignum
code across primitives and platforms, at no cost to performance.
5.2 Verifying a Generic Bignum Library
In HACL∗, we uniformly adopt unpacked representations for our
bignums. We define an evaluation function eval that maps a bignum
to the mathematical integer it represents. This function is paramet-
ric over the base of the unpacked layout: for example, our Poly1305
elements are in base 244, which means that a bignum b represents
the integer eval(b) = b[0] + 244 ∗ b[1] + 288 ∗ b[2].
We observe that, except for modulo, all the bignum operations
needed by our primitives are independent of the prime. Further-
more, generic bignum operations, such as addition, do not them-
selves depend on the specific unpacked representation; they only
rely on having enough remaining space so that limbs do not over-
flow. Using these observations, we implement and verify a generic
bignum library that includes modular addition, subtraction, mul-
tiplication, and inverse, and whose proofs do not depend on the
prime or the unpacked representation. Each generic operation is
parametric over the number of limbs in the bignum and requires as
a pre-condition that each limb has enough spare room to avoid over-
flow. To satisfy these preconditions in a cryptographic primitive
like Poly1305, the implementation must carefully interleave carry
propagation steps and modular reduction with generic operations.
The only part of the bignum library that depends on the prime is
the modular reduction, and this must be implemented and verified
anew for each new prime. All other functions in the bignum library
are written and verified just once. When compiling the code to
C, the prime-specific code and the representation constants (e.g.
the number of limbs, the evaluation base etc.) are inlined into the
generic bignum code, yielding an automatically specialized bignum
library in C for each primitive. As a result, our generated field
arithmetic code is as efficient as the custom bignum libraries for
each primitive. Hence, we are able to find a balance between generic
code for verification and specialized code for efficiency. We are
able to reuse more than half of the field arithmetic code between
Poly1305, Curve25519, and Ed25519. We could share even more of
the code if we specialized our bignum library for pseudo-Mersenne
primes. For primes which shapes do not enable optimized modulo
computations, we also implement and verify a generic modulo
function based on Barrett reduction, which we use in the Ed25519
signature algorithm.
5.3 Preventing Bugs, Enabling Optimizations
When programming with unpacked bignums, carry propagation
and modular reduction are the most expensive operations. Con-
sequently, this style encourages programmers to find clever ways
of delaying these expensive operation until they become neces-
sary. Some implementations break long carry chains into shorter
sequences that can be executed in parallel and then merged. These
low-level optimizations are error-prone and require careful anal-
ysis. In particular, carry propagation bugs are the leading func-
tional correctness flaws in OpenSSL crypto, with two recent bugs
in Poly1305 [11, 22], and two others in Montgomery multiplication
(CVE-2017-3732, CVE-2016-7055). A carry propagation bug was
also found in TweetNaCl [19].
Our Curve25519 implementation is closely inspired by Adam
Langley’s donna_c64 64-bit implementation, which is widely used
and considered the state-of-the-art C implementation. In 2014, Lan-
gley reported a bug in this implementation 2: the implementation
incorrectly skipped a necessary modular reduction step. In response,
Langley explored the use of formal methods to prove the absence of
such bugs, but gave up after failing to prove even modular addition
using existing tools. This paper presents the first complete proof of
a C implementation of Curve25519, including all its field arithmetic.
In particular, our proofs guarantee the absence of carry propagation
bugs in Poly1305, Curve25519, and Ed25519.
A surprising benefit of formal verification is that it sometimes
identifies potential optimizations. When verifying Curve25519, we
observed that donna_c64 was too conservative in certain cases.
Each multiplication and squaring operation had an unnecessary
extra carry step, which over the whole Curve25519 scalar multipli-
cation totaled to about 3400 extra cycles on 64-bit Intel processors.
We removed these redundant carries in our code and proved that it
was still correct. Consequently, the Curve25519 C code generated
from HACL∗ is slightly (about 2.2%) faster than donna_c64 making
it the fastest C implementation that we know of.
2https://www.imperialviolet.org/2014/09/07/provers.html
let prime = pow2 255 − 19
type felem = e:int{0 ≤ e ∧ e < prime}
type serialized_point = b:seq uint8{length b = 32}
type proj_point = | Proj: x:felem → z:felem → proj_point
let decodePoint (u:serialized_point) =
(little_endian u % pow2 255) % prime
let encodePoint (p:proj_point) =
let x = fmul p.x (p.z ∗∗ (prime − 2)) in
little_bytes 32ul x
Figure 9: F∗ specification of Curve25519 point format.
Operators are over integers (field elements); fmul is the field multi-