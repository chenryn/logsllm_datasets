ity recognition. In addition, the authors assume that the starting
frame used by the API is known to the attacker, which in real-
time applications is not deterministic (and thus, is unknown).
Wei et al. [54] attack the video recognition system by adding
perturbations only on the ﬁrst few consecutive frames in a
video clip. However, unlike our attack, these attacks do not
work on practical real-time video classiﬁcation systems when
the boundaries of video clips are not known.
GANs or generative adversarial networks have been em-
ployed by Goodfellow et al. [10] and Radford et al. [38]
in generating natural images. Mopuri et al. [32] extend a
GAN architecture to train a generator to model universal
perturbations for images. Their objective was to explore the
space of the distribution of universal adversarial perturbations
in the image space. We signiﬁcantly extend the generative
framework introduced by Mopuri et al. [32]. In addition,
unlike their work which focused on generating adversarial
perturbations for images, our study focuses on the generation
of effective perturbations to attack videos.
The feasibility of adversarial attacks against other types of
learning systems including face-recognition systems [28], [39],
[40], voice recognition systems [5] and malware classiﬁcation
systems [12], has been studied. However, these studies do not
account for the unique input characteristics that are present in
real-time video activity recognition systems.
X. CONCLUSIONS
In this paper, we investigate the problem of generating
adversarial samples for attacking video classiﬁcation systems.
We identify three key challenges that will need to be addressed
in order to generate such samples namely, generating perturba-
tions in real-time, making the perturbations stealthy and deal-
ing with the intedeterminism of video clip boundaries that are
input to a real-time video classiﬁer. We exploit recent advances
in generative models, extending them signiﬁcantly to solve
these challenges and generate very potent adversarial samples
against video classiﬁcation systems. We perform extensive
experiments on two different datasets one of which captures
coarse-grained actions (e.g., applying make up) while the other
captures ﬁne-grained actions (hand gestures). We demonstrate
that our approaches are extremely potent, achieving around 80
% attack success rates in both cases. We also discuss possible
defenses that we propose to investigate in future work.
ACKNOWLEDGMENTS
We would like to thank the anonymous reviewers for their
valuable feedback on this paper. This work was partially sup-
ported by the U.S. Army Research Laboratory Cyber Security
Collaborative Research Alliance under Cooperative Agreement
Number W911NF-13-2-0045. The views and conclusions con-
tained in this document are those of the authors, and should
not be interpreted as representing the ofﬁcial policies, either
expressed or implied, of the Army Research Laboratory or
the U.S. Government. The U.S. Government is authorized to
re-produce and distribute reprints for Government purposes,
notwithstanding any copyright notation hereon.
REFERENCES
[1] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin,
S. Ghemawat, G. Irving, M. Isard et al., “Tensorﬂow: A system for
large-scale machine learning.” in OSDI, vol. 16, 2016, pp. 265–283.
[2] B. Biggio, I. Corona, D. Maiorca, B. Nelson, N. ˇSrndi´c, P. Laskov,
G. Giacinto, and F. Roli, “Evasion attacks against machine learning
at test time,” in Joint European conference on machine learning and
knowledge discovery in databases. Springer, 2013, pp. 387–402.
[3] B. Biggio, G. Fumera, and F. Roli, “Pattern recognition systems under
attack: Design issues and research challenges,” International Journal
of Pattern Recognition and Artiﬁcial Intelligence, vol. 28, no. 07, p.
1460002, 2014.
[4] D. S. Biggs, “3d deconvolution microscopy,” Current Protocols in
Cytometry, pp. 12–19, 2010.
[6]
[5] N. Carlini, P. Mishra, T. Vaidya, Y. Zhang, M. Sherr, C. Shields,
D. Wagner, and W. Zhou, “Hidden voice commands.” in USENIX
Security Symposium, 2016, pp. 513–530.
J. Carreira and A. Zisserman, “Quo vadis, action recognition? a new
model and the kinetics dataset,” in 2017 IEEE Conference on Computer
Vision and Pattern Recognition (CVPR).
IEEE, 2017, pp. 4724–4733.
J. Dataset, “Humans performing pre-deﬁned hand actions,” https://20bn.
com/datasets/jester, 2016, [Online; accessed 30-April-2018].
[7]
[8] S. R. Fanello, I. Gori, G. Metta, and F. Odone, “One-shot learning
for real-time action recognition,” in Iberian Conference on Pattern
Recognition and Image Analysis. Springer, 2013, pp. 31–40.
[10]
[9] H. Foroughi, B. S. Aski, and H. Pourreza, “Intelligent video surveil-
lance for monitoring fall detection of elderly in home environments,”
in Computer and Information Technology, 2008. ICCIT 2008. 11th
International Conference on.
I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,
S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,” in
Advances in neural information processing systems, 2014, pp. 2672–
2680.
I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing
adversarial examples (2014),” arXiv preprint arXiv:1412.6572.
IEEE, 2008, pp. 219–224.
[11]
[12] K. Grosse, N. Papernot, P. Manoharan, M. Backes, and P. McDaniel,
“Adversarial perturbations against deep neural networks for malware
classiﬁcation,” arXiv preprint arXiv:1606.04435, 2016.
J. Gu, Z. Wang, J. Kuen, L. Ma, A. Shahroudy, B. Shuai, T. Liu,
X. Wang, G. Wang, J. Cai et al., “Recent advances in convolutional
neural networks,” Pattern Recognition, 2017.
[13]
14
[14] S. Herath, M. Harandi, and F. Porikli, “Going deeper into action
recognition: A survey,” Image and vision computing, vol. 60, pp. 4–
21, 2017.
[15] H. Hosseini, B. Xiao, A. Clark, and R. Poovendran, “Attacking auto-
matic video analysis algorithms: A case study of google cloud video
intelligence api,” in Proceedings of the 2017 on Multimedia Privacy
and Security. ACM, 2017, pp. 21–32.
[16] L. Huang, A. D. Joseph, B. Nelson, B. I. Rubinstein, and J. Tygar, “Ad-
versarial machine learning,” in Proceedings of the 4th ACM workshop
on Security and artiﬁcial intelligence. ACM, 2011, pp. 43–58.
[17] X. Huang, Y. Li, O. Poursaeed, J. Hopcroft, and S. Belongie, “Stacked
generative adversarial networks,” in IEEE Conference on Computer
Vision and Pattern Recognition (CVPR), vol. 2, 2017, p. 4.
[18] S. Ioffe and C. Szegedy, “Batch normalization: Accelerating deep
network training by reducing internal covariate shift,” arXiv preprint
arXiv:1502.03167, 2015.
[19] B. L. Kalman and S. C. Kwasny, “Why tanh: choosing a sigmoidal
function,” in Neural Networks, 1992. IJCNN., International Joint Con-
ference on, vol. 4.
IEEE, 1992, pp. 578–581.
[20] A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar, and
L. Fei-Fei, “Large-scale video classiﬁcation with convolutional neural
networks,” in Proceedings of the IEEE conference on Computer Vision
and Pattern Recognition, 2014, pp. 1725–1732.
[21] H. Kataoka, Y. Satoh, Y. Aoki, S. Oikawa, and Y. Matsui, “Temporal and
ﬁne-grained pedestrian action recognition on driving recorder database,”
Sensors, vol. 18, no. 2, p. 627, 2018.
[22] H. Kataoka, T. Suzuki, S. Oikawa, Y. Matsui, and Y. Satoh, “Drive
video analysis for the detection of trafﬁc near-miss incidents,” arXiv
preprint arXiv:1804.02555, 2018.
[23] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
arXiv preprint arXiv:1412.6980, 2014.
[24] A. Kurakin, I. Goodfellow, and S. Bengio, “Adversarial machine learn-
ing at scale,” arXiv preprint arXiv:1611.01236, 2016.
[25] K. Lab, “Man-in-the-middle attack on video surveillance systems,”
https://securelist.com/does-cctv-put-the-public-at-risk-of-cyberattack/
70008/, Defcon,2014, [Online; accessed 30-April-2018].
[26] R. Longadge and S. Dongre, “Class imbalance problem in data mining
review,” arXiv preprint arXiv:1305.1707, 2013.
[27] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, “Towards
deep learning models resistant to adversarial attacks,” arXiv preprint
arXiv:1706.06083, 2017.
[28] M. McCoyd and D. Wagner, “Spooﬁng 2d face detection: Machines see
people who aren’t there,” arXiv preprint arXiv:1608.02128, 2016.
[29] S.-M. Moosavi-Dezfooli, A. Fawzi, O. Fawzi, and P. Frossard, “Univer-
sal adversarial perturbations,” in Computer Vision and Pattern Recog-
nition (CVPR), 2017 IEEE Conference on.
IEEE, 2017, pp. 86–94.
[30] S. M. Moosavi Dezfooli, A. Fawzi, and P. Frossard, “Deepfool: a simple
and accurate method to fool deep neural networks,” in Proceedings of
2016 IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), no. EPFL-CONF-218057, 2016.
[31] K. R. Mopuri, U. Garg, and R. V. Babu, “Fast feature fool: A data
independent approach to universal adversarial perturbations,” arXiv
preprint arXiv:1707.05572, 2017.
[32] K. R. Mopuri, U. Ojha, U. Garg, and R. V. Babu, “Nag: Network for
adversary generation,” arXiv preprint arXiv:1712.03390, 2017.
[33] V. Nair and G. E. Hinton, “Rectiﬁed linear units improve restricted
boltzmann machines,” in Proceedings of the 27th international confer-
ence on machine learning (ICML-10), 2010, pp. 807–814.
[37] R. Planinc, A. Chaaraoui, M. Kampel, and F. Flrez-Revuelta, “Computer
vision for active and assisted living,” pp. 57–79, 01 2016.
[38] A. Radford, L. Metz, and S. Chintala, “Unsupervised representation
learning with deep convolutional generative adversarial networks,”
arXiv preprint arXiv:1511.06434, 2015.
[39] M. Sharif, S. Bhagavatula, L. Bauer, and M. K. Reiter, “Accessorize to
a crime: Real and stealthy attacks on state-of-the-art face recognition,”
in Proceedings of the 2016 ACM SIGSAC Conference on Computer and
Communications Security. ACM, 2016, pp. 1528–1540.
[40] ——, “Adversarial generative nets: Neural network attacks on state-of-
the-art face recognition,” arXiv preprint arXiv:1801.00349, 2017.
[41] K. Soomro, A. R. Zamir, and M. Shah, “Ucf101: A dataset of
101 human actions classes from videos in the wild,” arXiv preprint
arXiv:1212.0402, 2012.
[42] W. Sultani, C. Chen, and M. Shah, “Real-world anomaly detection in
surveillance videos,” arXiv preprint arXiv:1801.04264, 2018.
[43] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfel-
low, and R. Fergus, “Intriguing properties of neural networks,” arXiv
preprint arXiv:1312.6199, 2013.
[44] C. Tensorﬂow, “C3D Implementation,” https://github.com/hx173149/
C3D-tensorﬂow.git, 2016, [Online; accessed 30-April-2018].
[45] F. Tram`er, A. Kurakin, N. Papernot, D. Boneh, and P. McDaniel,
“Ensemble adversarial training: Attacks and defenses,” arXiv preprint
arXiv:1705.07204, 2017.
[46] D. Tran, L. Bourdev, R. Fergus, L. Torresani, and M. Paluri, “Learning
spatiotemporal features with 3d convolutional networks,” in Computer
Vision (ICCV), 2015 IEEE International Conference on.
IEEE, 2015,
pp. 4489–4497.
[47] V. Tripathi, A. Mittal, D. Gangodkar, and V. Kanth, “Real time security
framework for detecting abnormal events at atm installations,” Journal
of Real-Time Image Processing, pp. 1–11, 2016.
[48] G. Varol, I. Laptev, and C. Schmid, “Long-term temporal convolutions
for action recognition,” IEEE transactions on pattern analysis and
machine intelligence, 2017.
[49] U. C. Vision, “Case Study: Elementary Scholl in Taiwai,” https://news.
umbocv.com/case-study-taiwan-elementary-school-13fa14cdb167.
[50] ——, “Umbo Customer Case Study NCHU,” https://news.umbocv.com/
umbo-customer-case-study-nchu-687356292f43.
[51] ——,
CBS
umbos-smart-city-featured-on-cbs-sacramento-26f839415c51.
on
https://news.umbocv.com/
Sacramento,”
“Umbo’s
Featured
Smart
City
[52] ——, “Case Studies,” https://news.umbocv.com/case-studies/home,
2016, [Online; accessed 30-April-2018].
[53] C. Vondrick, H. Pirsiavash, and A. Torralba, “Generating videos with
scene dynamics,” in Advances In Neural Information Processing Sys-
tems, 2016, pp. 613–621.
[54] X. Wei, J. Zhu, and H. Su, “Sparse adversarial perturbations for videos,”
arXiv preprint arXiv:1803.02536, 2018.
[55] W. Xu, D. Evans, and Y. Qi, “Feature squeezing: Detecting adversarial
examples in deep neural networks,” arXiv preprint arXiv:1704.01155,
2017.
[56] ——, “Feature squeezing mitigates and detects carlini/wagner adversar-
ial examples,” arXiv preprint arXiv:1705.10686, 2017.
[57] M. D. Zeiler, “Adadelta: an adaptive learning rate method,” arXiv
preprint arXiv:1212.5701, 2012.
[34] Z.
on
Net,
“Surveillance
with
in-
fected
https://www.zdnet.com/article/
amazon-surveillance-cameras-infected-with-malware/, ZD Net,2016,
[Online; accessed 30-April-2018].
malware,”
Amazon
cameras
sold
[35] N. Papernot, N. Carlini,
I. Goodfellow, R. Feinman, F. Faghri,
A. Matyasko, K. Hambardzumyan, Y.-L. Juang, A. Kurakin, R. Sheats-
ley et al., “cleverhans v2. 0.0: an adversarial machine learning library,”
arXiv preprint arXiv:1610.00768, 2016.
[36] N. Papernot, P. McDaniel, and I. Goodfellow, “Transferability in ma-
chine learning: from phenomena to black-box attacks using adversarial
samples,” arXiv preprint arXiv:1605.07277, 2016.
15