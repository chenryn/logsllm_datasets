i ∈ [1, 3]
i = 1 + 2 ×
w#
1 −
) + R−1
i
4.2 Label driven attribute weight
We define the second function to compute weights using ground
truth fraud labels of past orders. These weights are computed in
order to satisfy two requirements for our method: R3 maximizing
clustered fraud and R2 minimizing cluster impurity.
(2)
Simpson index [45]. It is defined as λi(c) =cardi
We start by clustering a set of orders using default attribute
weights (wi = 1) using Hamming distance. We obtain clusters of
three types: (a) pure clusters cf containing only frauds, (b) pure
clusters cl containing only legitimate orders and (c) mixed cluster
cm. cm clusters violate R2 and their number must be minimized.
cf clusters contribute to R3 and their number must be maximized.
We aim to emphasize the importance of attributes that help gen-
erating cf clusters and de-emphasize the importance of attributes
that do not by scaling their weight accordingly. The higher the
weight, the more important the attribute. We compute the contri-
bution of an attribute ai towards generating a cluster c using the
p2
j , where pj
is the probability of encountering the attribute value vj in c: the
ratio of elements having vj for ai. High Simpson index indicates
that a low number of different values v is present in the cluster.
This means ai has significantly contributed towards generating this
cluster.
Using the Simpson index we define two metrics Advf /l in Eq. (3)
and Advp/m(ai) in Eq. (4). Advf /l(ai) measures the advantage of
the attribute ai in generating pure fraudulent clusters cf rather than
pure legitimate clusters cl . Advp/m(ai) quantifies the advantage
of the attribute ai in generating pure clusters cf and cl instead
of mixed clusters cm. High Advf /l helps achieving R3 and a high
Advp/m helps achieving R2. The normalization term normadv(ai)
ensures that Advf /l(ai) + Advp/m(ai) ∈ [0, 2] which allows us to
keep the final weight in the range [1, 3]
j=1
Advf /l(ai) =
λi(cf ) − λi(cl)
normadv(ai)
(3)
λi(cf ) + λi(cl) − 2 × λi(cm)
Advp/m(ai) =
(4)
We compute our label driven weights using both these advan-
2 × normadv(ai)
tages as follows:
w
∗
i ∈ [1, 3]
∗
i = 1 + Advf /l(ai) + Advp/m(ai), w
(5)
5 PERFORMANCE METRICS AND DATASETS
We discussed that RecAgglo meets R1 by design. We empirically
evaluate the remaining requirements R2 (minimize cluster impu-
rity), R3 (maximize clustered fraud) and R4 (minimize execution
time).
5.1 Performance metrics
We evaluate R2 by computing the cluster impurity measure I, which
is used to evaluate the quality of a clustering [16]. We give the label
of the majority class to each cluster and all samples that do not
belong to this class are counted as the impurity. For a clustering
containing k clusters of sizes s1, . . . , sk and the sizes of the majority
class in each clusters m1, . . . , mk, the impurity index is defined as:
k
(6)
6
k
k
i =1(si − mi)
=
i =1(si − mi)
I =
i =1 si
n
We evaluate R3 by calculating the clustered fraud rate (CFR)
which is the ratio of clustered frauds to the total number of frauds.
For the count of frauds in each cluster f1, . . . , fk and the total
number of frauds F, CFR is defined as:
i =1(fi)
(7)
We evaluate R4 by measuring the computation time t of the
k
CFR =
F
clustering for the given dataset.
Our objectives are to minimize the impurity I and computation
time t while maximizing the CFR.
5.2 Datasets
We use several datasets composed of real fraud and legitimate
orders placed on the Zalando website in 2017 and 2018. Zalando
receives on average 29 million orders per quarter [52]. Our ground
truth fraud labels are obtained based on actual payment status of
the order 12 weeks after it is placed. Orders without a label are
considered legitimate.
The datasets presented in the following are sampled from the
original order data. They differ in size and ratio of legitimate to
fraudulent orders. We use them for different experiments that we
describe as follows.
Small datasets with artificial distribution. We sample two small
datasets TrainF-15K and TestF-15K that are used for selecting hy-
perparamters of agglomerative clustering (Sect. 6) and for compar-
ing the performance of several categorical clustering techniques
(Sect. 7.3) respectively. These sets are small enough for most cate-
gorical clustering techniques to run in a reasonable amount of time
(<10 hours). Also, they contain enough frauds to generate many
fraudulent clusters that we can use to compute sensible impurity
I and CFR metrics. Frauds are artificially over-sampled (1 fraud /
2 legitimate) compared to a real-world distribution. Each dataset
consists of 10 disjoint subsets, each composed of 10,000 legitimate
orders and 5,000 frauds.
Large datasets with artificial distribution. We sample two larger
datasets TrainG-30K and TrainG-100K that are used for selecting
hyperparamters of RecAgglo (Sect. 7.1). These also have an artifi-
cial distribution where frauds are over-sampled compared to the
real-world distribution. The imbalance is larger and more realistic
in these datasets though (1 fraud / 5 legitimate and 1 fraud / 19 legit-
imate). TrainG-30K consists of 10 disjoint subsets, each composed
of 25,000 legitimate orders and 5,000 frauds. TrainG-100K consists
of 5 disjoint subsets, each composed of 95,000 legitimate and 5,000
fraud. The composition of datasets with artificial distribution is
presented in detail in App. B.
Real-world datasets. Finally, we select real-world datasets that
will be used to evaluate the actual effectiveness of RecAgglo at clus-
tering fraud in Sect. 8. These datasets consist of all Zalando Fashion
Store orders placed between April 1st and May 5th 2018 (35 days)
in Germany (DE-real), Switzerland (CH-real), the Netherlands (NL-
real), Belgium (BE-real) and France (FR-real). These datasets contain
more than 6 million orders in total, with a realistic fraud/legitimate
order ratio (well below 1% before fraud cancellation).
Each of these datasets is complemented with a background
dataset containing only frauds placed between January 1st and
March 31st 2018 (90 days). These datasets are respectively named
DE-bg, CH-bg, NL-bg, FR-bg BE-bg.
Figure 2: Average weights of five at-
tribute categories using cardinality and
label driven weights. Shipping and
billing attributes are the most impor-
tant in generating clusters.
Figure 3: Simpson index λ for 13 at-
tributes providing the best advantage
in generating fraudulent and pure clus-
ters. Billing, shipping and payment at-
tributes provide the best advantage.
Figure 4: Increase in Impurity and CFR
with dmax for three attribute weight-
ing strategies. A fine-grained choice of
Impurity/CFR tradeoff is possible using
cardinality and label driven weights.
i and label driven weights w∗
6 WEIGHTING STRATEGIES EVALUATION
Agglomerative clustering is the basis for RecAgglo. It uses three
hyperparameters: a distance metric, a linkage method and the max-
imum distance for cluster fusion dmax . Recall that we selected
Hamming as a distance metric because of its low computation cost.
We selected the single linkage method based on evaluation described
in App. C.1. We want to select the optimal weighting strategy and
a distance dmax which minimize the impurity I and maximize the
CFR. We compare the default weighting strategy (wi = 1) to the
cardinality w#
i we introduced in Sect. 4.
6.1 Weight computation
We select a random sample of 2M orders placed in France in 2017
to compute our cardinality driven weights using Eq. (2). In this
subset, we obtain a minimum inverse normalized richness index
min(R−1
) = 1.606 for one of the attributes in the Acust category.
i
It means that the same value repeats less than twice (on average)
for over 2M samples. On the other hand, we obtained max(R−1
) =
i
1, 000, 000 for one of the attributes in Adel meaning it has only
two possible values. These statistics highlight the imbalance in the
cardinality of attributes representing orders (C1), which justifies
cardinality based weighting strategy. We computed the value for
median(R−1
) = 149 that we use to calculate the weights of all 37
i
attributes.
R−1
i
149 + R−1
i
w#i = 1 + 2 × (1 −
)
We start by clustering each set TrainF-15K-i using agglomerative
clustering and default weights wi = 1 to compute our label driven
weights. We select the maximum distance for cluster fusion dmax =
0.56, which generates a clustering with impurity I = 0.095 and
CFR = 0.719 (App. C.1). The majority of fraud is clustered (72%)
and there is a significant number of mixed clusters as depicted by
the high impurity (9.5%). We compute the Simpson index λi for
each attribute ai in each generated cluster. We aggregate these
results to compute the mean λi for pure fraudulent clusters (cf ),
pure legitimate clusters (cf ) and mixed clusters (cm). Using these
statistics we compute our advantage metrics (Eq. (3) and (4)) and
by extension our final label driven weights.
6.2 Attribute importance
Figure 2 depicts the average cardinality and label driven weights
of attributes in each category: Acust , Adel , Apay, Aship and Abill .
Despite the different rationale and implementation for our two
weighting strategies, we see they give similar high and low weights
to the same attributes. Attributes in Aship and Abill have the largest
weights according to both strategies. These attributes differ between
customers (Aship) and between orders (Abill ), which explains their
high cardinality and their large cardinality driven weights.
Figure 3 depicts the averaged Simpson index for the 13 attributes
providing the highest advantage. We observe that Abill attributes
give the best advantage for generating fraudulent rather than legit-
imate clusters (higher Simpson index in pure fraudulent clusters).
Aship attributes also provide a small advantage towards that goal,
while Apay and Acust do not. Different values of the Simpson index
depict the advantage of each attribute and are captured by our label
driven features. It can be seen that Aship and Abill attributes have
the highest weights (Fig. 2). On the other hand, all 13 attributes con-
tribute to generating pure clusters (lower Simpson index for mixed
clusters). Acust and Adel contribute the least to our advantages and
they have the lowest weight in Fig. 2.
High Simpson index values for Abill and Aship attributes indi-
cate that fraudulent orders have more similar billing and shipping
information than legitimate orders. On the other hand, there is no
significant difference for Acust and Apay attributes. These results
might indicate that fraudsters tend to use several user accounts and
payment methods with similar billing and shipping information.
Consequently, our generated clusters have characteristics that are
typically associated with fraud campaigns as presented in Sect. 2.2.
6.3 Weighting strategies performance
We clustered the 10 TrainF-15K-i datasets using default attribute
weights, cardinality and label driven weights. Each weighting strat-
egy provides a similar I/CFR tradeoff that is detailed in App. C.2.
7
Nevertheless, label driven weights provide a slightly better CFR
than other strategies for the same impurity value and we select
it for the remaining experiments. A more interesting property of
cardinality and label driven weights can be observed in Fig. 4. Both
these strategies offer a smoother increase of impurity and CFR while
varying dmax . In contrast, default weights have abrupt changes
and long plateaus providing the same performance. In this setting
it is difficult to select an optimal dmax that provides desired im-
purity and CFR values. Cardinality and label driven weights can
be used to effectively fine-tune dmax in order to achieve desired
performance characteristics. Using Fig. 4, we select dmax = 0.5
with label driven weights, which results in an average impurity
I = 0.012 for a CFR = 0.52. With this value, impurity remains low
(about 1%) while more than half of the frauds are clustered.
Hamming distance with label driven weights, single linkage
and distance dmax = 0.5 are used in RecAgglo in all following
experiments.
7 RECAGGLO PERFORMANCE EVALUATION
We evaluate the performance of RecAgglo in terms of impurity,
CFR and computation time when clustering real online orders. We
compare this performance to several state-of-the-art categorical
clustering techniques to show RecAgglo is best suited for this task.
7.1 Hyperparameter setting
RecAgglo requires defining δa and SampleClust requires defin-
ing ρs and ρmc (cf. Sect. 3). We compute optimal hyperparameter
values with the primary goal of minimizing computation time and
the secondary goals of minimizing impurity I and maximizing CFR.
We set δa = 1, 000 with computation time being the only consider-
ation in mind. Agglomerative clustering takes 25s to process 1,000
samples. Consequently, this is an upper bound for the computation
time of AggloClust in RecAgglo. The upper bound for the fall
back agglomerative clustering is given for 4, 000 (4 × δa) elements
to cluster and takes 388s.
We perform a grid search over ρs = {0.25, 0.5, 1, 2} and ρmc =
{1.01, 1.5, 2, 3, 4, 6, 10} to select hyperparameter values for Sam-
pleClust. We run RecAgglo with every hyperparameter combina-
tion on TrainG-30K (10 runs) and TrainG-100K (5 runs) computing I,
CFR and computation time t. A detailed analysis of the grid search
results on TrainG-30K is presented in App.C.3. It shows that a too
low ρmc value (e.g., 1.01) or a high ρs value significantly increases
the computation time of RecAgglo. We selected ρs = 0.5 and
ρmc = 6 as these hyperparamters provide the best tradeoff with
t = 4, 110s, CFR = 34.0% and I = 3.0% on TrainG-100K. The sample
size for sampling is 0.5 × √
n and the maximum number of clusters
to generate is maxclust = n/6.
7.2 Experimental setup
We use four categorical clustering algorithms to compare the per-
formance of RecAgglo: AggloClust, SampleClust, Kmodes and
ROCK. We ran experiments on a consumer grade laptop with 8GB
of RAM and Intel Core i5 (2.7GHz) processor. We already presented
AggloClust and SampleClust in Sect. 3.1.
Kmodes [22] is an extension of the Kmeans algorithm for cat-
egorical data. It starts by selecting k random points as starting
Table 1: Impurity, CFR, and computation time for 4 categori-
cal clustering algorithms. Results are averaged over 10 runs
on TestF-15K (15,000 samples). *: results for ROCK are com-
puted on 5,000 randomly picked samples. RecAgglo gener-
ates the clusters with the lowest impurity in a short time.
Algorithm
RecAggloδmax =0.5
AggloClustδmax =0.5
SampleClustδmax =0.5, ρs =0.5
SampleClustδmax =0.6, ρs =0.5
SampleClustδmax =0.6, ρs =2
Kmodesk =1,000
Kmodesk =5,000
Kmodesk =12,000
*ROCKθ =0.55,t =0.45
*ROCKθ =0.45,t =0.40