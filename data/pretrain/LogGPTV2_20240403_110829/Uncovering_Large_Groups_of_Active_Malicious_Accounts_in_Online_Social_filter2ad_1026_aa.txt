title:Uncovering Large Groups of Active Malicious Accounts in Online Social
Networks
author:Qiang Cao and
Xiaowei Yang and
Jieqi Yu and
Christopher Palow
Uncovering Large Groups of Active Malicious Accounts in
Online Social Networks
Qiang Cao
Xiaowei Yang
Jieqi Yu
Christopher Palow
Duke University
{qiangcao, xwy}@cs.duke.edu
Facebook Inc.
{jieqi, cpalow}@fb.com
ABSTRACT
The success of online social networks has attracted a constant in-
terest in attacking and exploiting them. Attackers usually control
malicious accounts, including both fake and compromised real user
accounts, to launch attack campaigns such as social spam, malware
distribution, and online rating distortion.
To defend against these attacks, we design and implement a ma-
licious account detection system called SynchroTrap. We observe
that malicious accounts usually perform loosely synchronized ac-
tions in a variety of social network context. Our system clusters
user accounts according to the similarity of their actions and uncov-
ers large groups of malicious accounts that act similarly at around
the same time for a sustained period of time. We implement Syn-
chroTrap as an incremental processing system on Hadoop and Gi-
raph so that it can process the massive user activity data in a large
online social network efﬁciently. We have deployed our system in
ﬁve applications at Facebook and Instagram. SynchroTrap was able
to unveil more than two million malicious accounts and 1156 large
attack campaigns within one month.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: General—Secu-
rity and protection; K.6.5 [Management of Computing and In-
formation Systems]: Security and protection
General Terms
Security, Design
Keywords
Malicious account detection; scalable clustering system; online so-
cial networks
1.
INTRODUCTION
Online social networks (OSNs) such as Facebook, Google+, Twit-
ter, or Instagram are popular targets for cyber attacks. By creating
fake accounts [19, 44] or compromising existing user accounts [10,
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage, and that copies bear this notice and the full ci-
tation on the ﬁrst page. Copyrights for third-party components of this work must be
honored. For all other uses, contact the owner/author(s). Copyright is held by the
author/owner(s).
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
ACM 978-1-4503-2957-6/14/11.
http://dx.doi.org/10.1145/2660267.2660269.
25], attackers can use online social networks to propagate spam
messages, spread malware, launch social engineering attacks, or
manipulate online voting results.
Much of the previous work in defending against these attacks [1–
3,35] aims to directly identify the fake or compromised accounts an
attacker controls. There exist two broad approaches. One approach
is to use an account’s social network connectivity [19, 41, 45, 46]
to infer whether it is fake or not. This approach can help un-
cover fake accounts that have few connections to the real social
network, but cannot reliably identify compromised real user ac-
counts or well-maintained fake accounts that have acquired many
social connections [44]. Another approach, widely adopted in prac-
tice [20, 35, 47], is to build machine learning classiﬁers to infer
malicious (fake or compromised) accounts. This approach can ef-
fectively classify those malicious accounts with a set of known ma-
licious features, but may miss many malicious accounts with un-
known features.
Motivated by the above challenges, Wang et al. [42] and Beutel
et al. [16] have explored a new approach to uncover malicious ac-
counts. They analyzed the aggregate behavioral patterns of social
network accounts to distinguish malicious accounts from legitimate
ones. In particular, Wang et al. analyzed how the http requests from
fake accounts differ from those from real user accounts and used
this feature to identify fake accounts. Beutel et al. showed that
malicious accounts tend to post fake likes to fraudulent Facebook
pages at roughly the same time, and designed CopyCatch to detect
such synchronized posts.
This work advances the state of the art of using aggregate behav-
ioral patterns to uncover malicious accounts. Motivated by Copy-
Catch, we show that malicious accounts tend to act together in a
variety of social network context. In addition to posting fake likes,
they may log on, install social network applications, upload spam
photos, and so on in a loosely synchronized manner (§ 2).
We then present SynchroTrap, a system that can uncover large
groups of malicious accounts that act in loose synchrony. We face
a number of unique challenges in designing SynchroTrap (§ 3) and
these challenges set SynchroTrap apart from previous work in this
area, i.e., CopyCatch and Clickstream [42]. First, unlike Copy-
Catch, we aim to detect loosely synchronized behavior for a broad
range of social network applications. Therefore, we cannot make
the assumption that a user can perform a malicious action only
once, i.e., a user can like a speciﬁc page only once. This differ-
ence in goals has greatly increased the algorithmic complexity of
SynchroTrap (§ 4 and § 9).
Second, detecting the actions from malicious accounts is a chal-
lenging anomaly detection problem. Malicious actions constitute
only a small fraction of the total user actions. For instance, Face-
book has more than 600 million daily active users [8] and they per-
form billions of actions everyday [34]. In contrast, the number of
malicious accounts involved in an attack campaign is often on the
order of thousands. How can we accurately detect such a weak sig-
nal from a large amount of noisy data? Third, we aim to deploy
our system on real-world online social networks such as Facebook.
Therefore, our detection algorithm must be able to process a few
terabytes of data on a daily basis, while many of the off-the-shelf
anomaly detection algorithms [26] or previous work, such as Click-
stream, do not scale to data of this size.
We have developed several simple but pragmatic techniques to
address the above design challenges. First, we model the malicious
account detection problem as a clustering problem (§ 3.1). We
compare pairwise user actions over a certain time period and group
those users who take similar actions at roughly the same time into
clusters, and mark a cluster whose size exceeds a tunable thresh-
old as malicious. This is because we observe from a real social
network that legitimate social network users take diverse actions
over time (§ 2). Second, to make the clustering algorithm compu-
tationally tractable, we further use an attacker’s network resource
constraint, e.g., the number of IP addresses under his control, or the
attacker’s target, e.g., a fraudulent Instagram account, to reduce the
pairwise comparison to be per IP address and/or per targeted object,
depending on the speciﬁc application context. Finally, we partition
user action data into small daily or hourly chunks. We design al-
gorithms to aggregate the comparison results between those small
chunks to detect malicious actions over a longer period such as a
week (§ 4.5). This technique enables us to implement SynchroTrap
in an incremental-processing fashion, making it practically deploy-
able at large online social networks.
We have deployed SynchroTrap at Facebook and Instagram for
over ten months (§ 7). In a detailed study of one-month data (§ 8.1),
we observe that it uncovered more than two million malicious ac-
counts and 1156 malicious campaigns. We have randomly sampled
a subset of malicious accounts SynchroTrap caught, and asked se-
curity specialists to inspect the accuracy of the results. The manual
inspection suggests that our system achieves a precision higher than
99%. During the course of its deployment, SynchroTrap on aver-
age catches ∼274K malicious accounts per week. We have also
evaluated the performance of SynchroTrap on a 200-machine clus-
ter at Facebook. The performance results show that our system is
able to process Facebook and Instagram’s user data. It takes a few
hours for SynchroTrap to process the daily data and ∼15 hours to
process a weekly aggregation job.
Admittedly, strategic attackers may attempt to spread the actions
of malicious accounts to evade SynchroTrap’s detection. We ana-
lyze SynchroTrap’s security guarantee and show that SynchroTrap
can effectively limit the rate of malicious actions an attacker per-
forms, even if the attacker controls an unlimited number of ma-
licious accounts (§ 6). In addition, we provide a set of parame-
ters that operators can tune to achieve a desirable trade-off between
false positives and false negatives. With a strict setting, Synchro-
Trap yields a near-zero false positive rate.
In summary, this work makes the following main contributions:
• We observe that malicious accounts tend to act together in a vari-
ety of social network context (§ 2).
• We have designed, implemented, and deployed SynchroTrap. Our
design addresses several practical challenges of using loosely syn-
chronized actions to uncover malicious social network accounts,
including how to detect such behavior in a variety of social net-
work applications, and among large and noisy data sets (§ 4).
• We present a preliminary analysis of the characteristics of the
detected malicious accounts. This analysis may provide insight for
other feature-based malicious account detection systems (§ 8).
400 
300 
200 
100 
D
I
t
n
u
o
c
c
A
0 
0
400 
300 
200 
100 
D
I
t
n
u
o
c
c
A
0 
0
24 48 72 96 120 144 168
Time (hours)
(a) Synchronized attack
24 48 72 96 120 144 168
Time (hours)
(b) Normal
Figure 1: An example of malicious photo uploads in Facebook.
The x-axis shows the time when an account uploads a photo,
and the y-axis is the account’s ID. A dot (x, y) in the ﬁgure
shows that an account with ID y uploads a photo at time x.
The color of a dot encodes the IP address of the action. Photo
uploads of the same color come from the same IP address.
2. MOTIVATING EXAMPLES
In this section, we examine two real-world attack examples that
motivate SynchroTrap’s design. Beutel et al. [16] observe that ma-
licious accounts post fake likes at around the same time. These two
additional examples show that: a) this attack pattern also appears in
other social network applications such as Instagram following, and
b) malicious accounts not only act together but often from a limited
set of IP addresses.
2.1 Malicious Facebook photo uploads
Figure 1 compares the photo-uploading activities of malicious
users to those of normal users at Facebook. Figure 1(a) plots the
photo uploads with timestamps from a group of 450 malicious ac-
counts over a week. Facebook caught those accounts because they
promoted diet pills by uploading spam photos. We can see that
those accounts use a few IP addresses to upload many spam pho-
tos. The horizontal color stripes indicate that they switch among a
small set of IP addresses during the one-week period.
Figure 1(b) shows the photo uploads of 450 randomly chosen
accounts which have never been ﬂagged as malicious. We refer to
those users as normal users. As can be seen, the actions are much
more spread out in time and come from a much more diverse set of
IP addresses.
2.2 Inﬂating followers on Instagram
Malicious users in Instagram follow target users to inﬂate the
number of their followers. Figure 2 compares user-following activ-
ities between 1,000 malicious users and 1,000 normal users. The
malicious accounts are sampled from an attack campaign involving
7K accounts.
We can see in Figure 2(a) that those malicious accounts are coor-
dinated to follow a target set of users in batches. The entire group
of accounts show a salient on-off action pattern. During the active
periods, they follow the same set of users at around the same time.
In contrast, normal users exhibit diverse user-following behavior.
As shown in Figure 2(b), little perceivable correlation can be found
among the user-following sequences of normal users.
1000 
800 
600 
400 
200 
D
I
t
n
u
o
c
c
A
0 
0
1000 
800 
600 
400 
200 
D
I
t
n
u
o
c
c
A
0 
0
24 48 72 96 120 144 168
Time (hours)
(a) Synchronized attack
24 48 72 96 120 144 168
Time (hours)
(b) Normal
Figure 2: An example in Instagram user following. The x-axis
is the timestamp of an account’s following action and the y-
axis is an account’s ID. A dot (x, y) shows that an account y
follows a targeted account at time x. The color of a dot encodes
the followed account’s ID. Actions of the same color follow the
same account.
2.3 Economic constraints of attackers
In this subsection, we speculate why various social network at-
tacks tend to happen in loose synchrony. We believe that this is
partly due to the economic constraints on the attacker side.
Cost on computing and operating resources. Attackers have
limited physical computing resources. Although they can purchase
or compromise machines (e.g., botnets), or even rent from cloud
computing services, such resources incur ﬁnancial cost. Further-
more, those computing resources have limited operating time. This
is because an infected machine may go ofﬂine, recover, or even be
quarantined at any time [32, 48], and that a machine rental is usu-
ally charged based on the consumed computing utility [4]. Another
operating cost is the human labor to fabricate fake or compromise
real accounts, and to maintain and manage the accounts. Under
these operating constraints, an attacker often controls his malicious
accounts from a set of machines within a limited time.
Revenue from missions with strict requirements. OSN attackers
are often deeply rooted in the underground markets, e.g., BlackHat-
World and Freelancer [33,36,37]. Most of their missions are driven
by customer demands with speciﬁc requirements. Usually the ob-
jective of a campaign is to achieve prevalence in OSNs. There-
fore, the mission requirements often include the level of prevalence
that a customer pursues and a strict deadline by which the mission
must be accomplished. For example, many social-networking tasks
in Freelancer solicit X Facebook friends/likes within Y days [33].
Similar tasks target other social network missions, such as follow-
ings, posts, reviews, etc. These underground tasks with strict time
requirements force attackers to target certain aspects of a victim’s
service and to act in advance of the mission deadlines.
We call the constraints of limited computing and operating re-
sources as resource constraints, and the constraints of strict re-
quirements on an attacker’s missions as mission constraints. Our
understanding of these economic constraints and their subsequent
manifestation on the activities of controlled accounts helps us di-
rectly attack the weak spot of attackers, making it hard for them to
evade detection.
3. SYSTEM OVERVIEW
3.1 High-level system architecture
SynchroTrap is a generic and scalable framework that can ef-
fectively throttle large groups of malicious accounts in OSNs. The
main idea of SynchroTrap is to use clustering analysis [26] to detect
the loosely synchronized actions from malicious accounts at scale.
In particular, it measures pairwise user behavior similarity and then
uses a hierarchical clustering algorithm [26] to group users with
similar behavior over an extended period of time together.
3.2 Challenges
We face a number of challenges in making SynchroTrap a prac-
tical solution for large-scale OSNs.
Scalability: A main challenge originates from the enormous scale
of today’s OSNs. First, the large volume of user activity data leads
to a low signal-to-noise ratio, making it hard to achieve high detec-
tion accuracy. For example, Facebook has more than 600 million
daily active users [8], while the number of malicious accounts in-
volved in an attack campaign is often on the order of thousands.
As a result, approaches (e.g., clickstream analysis [42]) that use
holistic comparison of all user activities may yield low accuracy.
In response to this challenge, we partition user actions by OSN ap-
plications and detect on a per-application basis (§ 4.1). We further
partition user actions by their associated target or source objects,
such as IP addresses, followee IDs, and page IDs, to capture the
constraints of an attacker (§ 4.2).
Second, the sheer volume of activity data prohibits a practical
implementation that can cope with generic actions. Large and com-
plex batch computations at Facebook-scale services are prohibitive
due to their requirements on hardware capacity (e.g., memory).
Such computations make resource sharing difﬁcult and failure re-
covery costly. To handle massive user activities at Facebook-scale