图1-5段缺射机制
分段的方法基本解决了上面提到的3个问题中的第一个和第三个。首先它做到了地址隔
离，因为程序A和程序B被映射到了两块不同的物理空间区城，它们之间没有任何重叠，
如果程序A访问虚拟空间的地址超出了0x00A00000这个范围，那么硬件就会判断这是一个
非法的访问，拒绝这个地址请求，并将这个请求报告给操作系统或监控程序，由它来决定如
何处理。再者，对于每个程序来说，无论它们被分配到物理地址的哪一个区域，对于程序来
说都是透明的，它们不需要关心物理地址的变化，它们只需要按烈从地址0x00000000到
0x00A00000来编写程序、放置变量，所以程序不再需要重定位。
程序员的自我修养一链接、装载与库
---
## Page 40
1.5内存不够怎么办
但是分段的这种方法还是没有解决我们的第二个问题，即内存使用效率的间题。分段对
内存区域的映射还是按照程序为单位，如果内存不足，被换入换出到磁盘的都是整个程序，
这样势必会造成大量的磁盘访问操作，从面严重影响速度，这种方法还是显得粗糙，粒度比
较大。事实上，根据程序的局部性原理，当一个程序在运行时，在某个时闻段内，它只是频
繁地用到了一小部分数据，也就是说，程序的很多数据其实在一个时间段内都是不会被用到
的。人们很自然地想到了更小粒度的内存分割和映射的方法，使得程序的局部性原理得到充
分的利用，大大提高了内存的使用率。这种方法就是分页（Paging）。
1.5.3分页（Paging）
分页的基本方法是把地址空间人为地等分成固定大小的页，每一页的大小由硬件决定，
或硬件支持多种大小的页，由操作系统选择决定页的大小.比如IntelPentium系列处理器支持
4KB或4MB的页大小，那么操作系统可以选择每页大小为4KB，也可以选择每页大小为4MB，
但是在同一时刻只能选择一种大小，所以对整个系统来说，页就是因定大小的，目前几乎所
有的PC上的操作系统都使用4KB大小的页，我们使用的PC机是32位的虚拟地址空间，也
就是4GB，那么按4KB每页分的话，总共有1048576个页。物理空间也是同样的分法。
下面我们来看一个简单的例子，如图1-6所示，每个虚拟空间有8页，每页大小为1KB，
那么虚拟地址空间就是8KB。我们假设该计算机有13条地址线，即拥有2^13的物理寻址
能力，那么理论上物理空间可以多达8KB。但是出于种种原因，购买内存的资金不够，只
买得起6KB的内存，所以物理空间其实真正有效的只是前6KB。
那么，当我们把进程的虚拟地址空间按页分割，把常用的数据和代码页装载到内存中，
把不常用的代码和数据保存在磁盘里，当需要用到的时候再把它从磁盘里取出来即可。以图
1-6为例，我们假设有两个进程Processl和Process2，它们进程中的部分虚拟页面被映射到
了物理页面，比如VPO、VP1和VP7 映射到PP0、PP2 和PP3：面有部分页面却在磁盘中，
比如VP2 和VP3位于磁盘的DP0 和 DP1中：另外还有一些页面如VP4、VP5 和VP6可能
尚未被用到或访问到，它们暂时处于未使用的状态。在这里，我们把虚拟空间的页就叫虚拟
页（VP，Virtual Page），把物理内存中的页叫做物理页（PP，Physical Page），把磁盘中
的页叫做磁盘页（DP，DiskPage）。图中的线表示映射关系，我们可以看到虚拟空间的有
些页被映射到同一个物理页，这样就可以实现内存共享。
图1-6中Process1的VP2和VP3不在内存中，但是当进程需要用到这两个页的时候，
硬件会捕获到这个消息，就是所调的页错误（PageFaut），然后操作系统接管进程，负责
将VP2和VP3从磁盘中读出来并且装入内存，然后将内存中的这两个页与VP2和VP3之
间建立映射关系，以页为单位来存取和交换这些数据非常方便，硬件本身就支持这种以页为
单位的操作方式。
程序员的自我修养一链接、装载与库
---
## Page 41
18
第1章温故而知新
VP7
PP7
VP7
VP6
PP6
VP6
VP5
PP5
VP5
VP4
PP4
VP4
Disk
VP3
PP3
VP3
VP2
PP2
VP2
DP1
VP1
PP1
VP1
DP0
VP0
PP0
VP0
Process 1
Physical
Process 2
Virtual Space
Aowen
Virtual Space
图1-6进程虚拟空间、物理空间和磁盘之间的页映射关系
保护也是页映射的目的之一，简单地说就是每个页可以设置权限属性，谁可以修改，谁
可以访问等，面只有操作系统有权限修改这些属性，那么操作系统就可以做到保护自己和保
护进程。对于保护，我们这里只是简单介绍，详细的介绍和为什么要保护我们将会在本书的
第2部分再介绍。
虚拟存储的实现需要依靠硬件的支持，对于不同的CPU米说是不同的。但是几乎所有
的硬件都采用一个叫MMU（Memory ManagementUnit）的部件来进行页映射，如图1-7
所示。
CPU
Virtual
MMU
Physical
+
Address
Physical
Address
Memory
图1-7虚拟地址到物理地址的转换
在页映射模式下，CPU发出的是Virtual Address，即我们的程序看到的是虚拟地址，经
过MMU 转换以后就变成了Physical Address。一般MMU都集成在CPU内部了，不会以独
立的部件存在。
程序员的自我修养—链接、装载与库
---
## Page 42
1.6众人拾柴火超高
1.6众人拾柴火焰高
1.6.1
线程基础
现代软件系统中，除了进程之外，线程也是一个十分重要的概念。特别是随若CPU频
率增长开始出现停滞，而开始向多核方向发展。多线程，作为实现软件并发执行的一个重要
的方法，也开始具有越米越重要的地位。我们将在这一节回顾线程相关的内容，包括线程的
概念、线程的调度、线程安全、用户线程与内核线程之间的映射关系、虽然线程相关的概念
与本书的内容并不是十分相关，但是我们相信深刻地理解线程对于更加深入地理解装载、动
态链接和运行库，特别是运行库与多线程相关部分的内容会有很大的帮助。
什么是线程
线程（Thread），有时被称为轻量级进程（LightweightProcess,LWP），是程序执行流
的最小单元。一个标准的线程由线程ID、当前指令指针（PC）、寄存器集合和堆栈组成。通
常意义上，一个进程由一个到多个线程组成，各个线程之间共享程序的内存空间（包括代码
段、数据段、堆等）及一些进程级的资源（如打开文件和信号）.一个经典的线程与进程的
关系如图1-8所示。
代码数据进程空间打开文件
寄存器
寄存器
寄存器
栈
栈
栈
MainThread
Thread2
图1-8进程内的线程
大多数软件应用中，线程的数量都不止一个。多个线程可以互不干找地并发执行，并共
享进程的全局变量和堆的数据。那么，多个线程与单线程的进程相比，又有哪些优势呢？通
常来说，使用多线程的原因有如下几点。
程序员的自我修养一链接、装载与库
---
## Page 43
20
第1章湿故而知新
某个操作可能会陷入长时间等待，等待的线程会进入睡眠状态，无法继续执行。多线
程执行可以有效利用等待的时间。典型的例子是等待网络响成，这可能要花费数秒甚
至数十秒。
某个操作（常常是计算）会消耗大量的时间，如果只有一个线程，程序和用户之间的
交互会中断，多线程可以让一个线程负责交互，另一个线程负责计算。
·程序逻辑本身就要求并发操作，例如-一个多端下载软件（例如Bittomrent）。
·多CPU或多核计算机（基本就是未来的主流计算机），本身具备同时执行多个线程的
能力，因此单线程程序无法全面地发挥计算机的全部计算能力。
·相对于多进程应用，多线程在数据共享方面效率要高很多。
线程的访问权限
线程的访问非常自由，它可以访间进程内存里的所有数据，甚至包括其他线程的堆栈（如
果它知道其他线程的堆栈地址，那么这就是很少见的情况），但实际运用中线程也拥有自己
的私有存储空间，包括以下儿方面。
·栈（尽管并非完全无法被其他线程访问，但一般情况下仍然可以认为是私有的数据）。
·线程局部存储（Thread Local Storage.TLS）。线程局部存储是某些操作系统为线程单独
提供的私有空间，但通常只具有很有限的容量。
·寄存器（包括PC寄存器），寄存器是执行流的基本数据，因此为线程私有。
从C程序员的角度来看，数据在线程之间是否私有如表1-1所示。
表1-1
线程私有
线程之间共享（进程所有）
局部变量
全局变量
函数的参数
堆上的数据
TLS 数据
函数里的静态交量
程序代码，任何线程都有权利读取并执行任何代码
打开的文件，A线程打开的文件可以由B线程读写
线程调度与优先级
不论是在多处理器的计算机上还是在单处理器的计算机上，线程总是“并发”执行的。
当线程数量小于等于处理器数量时（并且操作系统支持多处理器），线程的并发是真正的并
发，不同的线程运行在不同的处理器上，被此之间互不相干，但对于线程数量大于处理器数
量的情况，线程的并发会受到一些阻码，因为此时至少有一个处理器会运行多个线程。
程序员的自我修养一链接、装载与库
---
## Page 44
1.6众人拾柴火焰高
21
在单处理器对应多线程的情况下，并发是一种模拟出米的状态，操作系统会让这些多线
程程序轮流执行，每次仅执行一小段时间（通常是儿十到儿百毫秒），这样每个线程就“看
起来”在同时执行。这样的一个不断在处理器上切换不网的线程的行为称之为线程调度
（Thread Schedule）。在线程调度中，线程通常拥有至少三种状态，分别是：
·运行（Running）：此时线程正在执行。
就绪（Ready）：此时线程可以立刻运行，但CPU已经被占用。
·等待（Waiting）：此时线程正在等待某一事件（通常是I/O或同步）发生，无法执行。
处于运行中线程拥有一段可以执行的时间，这段时间称为时间片（Time Slice），当时
间片用尽的时候，该进程将进入就绪状态。如果在时间片用尽之前进程就开始等待某事件，
那么它将进入等待状态，每当一个线程离开运行状态时，调度系统就会选择一个其他的就绪
线程继续执行，在一个处于等待状态的线程所等待的事件发生之后，该线程将进入就绪状态。
这3个状态的转移如图1-9所示。
无运行线程，且本线程被选中
Buuuny
Ready
时间片用尽
开始等特
等待结束
图1-9线程状态切换
线程调度自多任务操作系统问世以来就不断地被提出不同的方案和算法。现在主流的调
度方式尽管各不相同，但都带有优先级调度（Priority Schedule）和轮转法（RoundRobin）
的痕迹。所谓轮转法，即是之前提到的让各个线程轮流执行一小段时间的方法。这决定了线
程之间交错执行的特点。而优先级调度则决定了线程按照什么顺序轮流执行。在具有优先级
调度的系统中，线程都拥有各自的线程优先级（ThreadPriority）。具有高优先级的线程会更
早地执行，而低优先级的线程常常要等待到系统中已经没有高优先级的可执行的线程存在时
才能够执行。在Windows中，可以通过使用：
BOOL WINAPI SetThreadPriority (HANDLE hThread, int nPriority) :
来设置线程的优先级，而Linux下与线程相关的操作可以通过pthread库来实现。
在Windows和Linux中，线程的优先级不仅可以由用户手动设置，系统还会根据不同
程序员的自我修养一链接、装载与库
---
## Page 45
22
第1章温故而知新
线程的表现自动调整优先级，以使得调度更有效率。例如通常情况下，频繁地进入等待状态
（进入等待状态，会放弃之后仍然可占用的时间份额）的线程（例如处理VO的线程）比频
繁进行大量计算、以至于每次都要把时间片全部用尽的线程要受欢迎得多，其实道理很简单，
频繁等待的线程通常只占用很少的时间，CPU也喜欢先握软柿子。我们一般把频繁等待的
线程称之为IO密集型线程（IOBoundThread），面把很少等待的线程称为CPU密集型线
程（CPU BoundThread）。IO密集型线程总是比CPU密集型线程容易得到优先级的提升。
在优先级调度下，存在一种饿死（Starvation）的现象，一个线程被饿死，是说它的优
先级较低，在它执行之前，总是有较高优先级的线程试围执行，因此这个低优先级线程始终
无法执行。当一个CPU密集型的线程获得较高的优先级时，许多低优先级的进程就很可能
饿死。而一个高优先级的IO密集型线程由于大部分时间都处于等待状态，因此相对不容易
造成其他线程饿死。为了避免饿死现象，调度系统常常会逐步提升那些等待了过长时间的得
不到执行的线程的优先级。在这样的手段下，一个线程只要等待足够长的时间，其优先级
定会提高到足够让它执行的程度。
让我们总结一下，在优先级调度的环境下，线程的优先级改变一般有三种方式。
·用户指定优先级。
·
根据进入等待状态的频繁程度提升或降低优先级。
·长时间得不到执行面被提升优先级。
可抢占线程和不可抢占线程
我们之前讨论的线程调度有一个特点，那就是线程在用尽时间片之后会被强制刺夺继续
执行的权利，而进入就绪状态，这个过程叫做抢占（Preemption），即之后执行的别的线程
抢占了当前线程。在早期的一些系统（例如 Windows3.1）里，线程是不可抢占的。线程必
须手动发出一个放弃执行的命令，才能让其他的线程得到执行，在这样的调度模型下，线程
必须主动进入就绪状态，而不是靠时间片用尽来被强制进入，如果线程始终拒绝进入就绪状
态，并且也不进行任何的等待操作，那么其他的线程将水远无法执行。在不可抢占线程中，
线程主动放弃执行无非两种情况。
·当线程试图等待某事件时（VO等）。