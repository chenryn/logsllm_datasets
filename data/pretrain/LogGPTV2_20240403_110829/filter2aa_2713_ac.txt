H(X, Y) =
ij
p(xi, yj) · log2
1
p(xi, yj)
Independence
H(X, Y) = H(X)+H(Y) if and only if X and Y are independent.
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Dependence
Independent variables X and Y:
Knowing X tells us nothing about Y
No matter what x we ﬁx, the histogram of Y’s values
co-occurring with that x will be the same shape
H(X, Y) = H(X) + H(Y)
Dependent X and Y:
Knowing X tells us something about Y (and vice versa)
Histograms of ys co-occurring with a ﬁxed x have different
shapes
H(X, Y) < H(X) + H(Y)
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Dependence
Independent variables X and Y:
Knowing X tells us nothing about Y
No matter what x we ﬁx, the histogram of Y’s values
co-occurring with that x will be the same shape
H(X, Y) = H(X) + H(Y)
Dependent X and Y:
Knowing X tells us something about Y (and vice versa)
Histograms of ys co-occurring with a ﬁxed x have different
shapes
H(X, Y) < H(X) + H(Y)
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Dependence
Independent variables X and Y:
Knowing X tells us nothing about Y
No matter what x we ﬁx, the histogram of Y’s values
co-occurring with that x will be the same shape
H(X, Y) = H(X) + H(Y)
Dependent X and Y:
Knowing X tells us something about Y (and vice versa)
Histograms of ys co-occurring with a ﬁxed x have different
shapes
H(X, Y) < H(X) + H(Y)
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Dependence
Independent variables X and Y:
Knowing X tells us nothing about Y
No matter what x we ﬁx, the histogram of Y’s values
co-occurring with that x will be the same shape
H(X, Y) = H(X) + H(Y)
Dependent X and Y:
Knowing X tells us something about Y (and vice versa)
Histograms of ys co-occurring with a ﬁxed x have different
shapes
H(X, Y) < H(X) + H(Y)
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Dependence
Independent variables X and Y:
Knowing X tells us nothing about Y
No matter what x we ﬁx, the histogram of Y’s values
co-occurring with that x will be the same shape
H(X, Y) = H(X) + H(Y)
Dependent X and Y:
Knowing X tells us something about Y (and vice versa)
Histograms of ys co-occurring with a ﬁxed x have different
shapes
H(X, Y) < H(X) + H(Y)
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Dependence
Independent variables X and Y:
Knowing X tells us nothing about Y
No matter what x we ﬁx, the histogram of Y’s values
co-occurring with that x will be the same shape
H(X, Y) = H(X) + H(Y)
Dependent X and Y:
Knowing X tells us something about Y (and vice versa)
Histograms of ys co-occurring with a ﬁxed x have different
shapes
H(X, Y) < H(X) + H(Y)
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Outline
1
Log browsing moves
Pipes and tables
Trees are better than pipes and tables!
2
Data organization
Trying to deﬁne the browsing problem
Entropy
Measuring co-dependence
Mutual Information
The tree building algorithm
3
Examples
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Mutual Information
Deﬁnition
Conditional entropy of Y given X
H(Y|X) = H(X, Y) − H(X)
Uncertainty about Y left once we know X.
Deﬁnition
Mutual information of two variables X and Y
I(X; Y) = H(X) + H(Y) − H(X, Y)
Reduction in uncertainty about X once we
know Y and vice versa.
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Mutual Information
Deﬁnition
Conditional entropy of Y given X
H(Y|X) = H(X, Y) − H(X)
Uncertainty about Y left once we know X.
Deﬁnition
Mutual information of two variables X and Y
I(X; Y) = H(X) + H(Y) − H(X, Y)
Reduction in uncertainty about X once we
know Y and vice versa.
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Histograms 3d: Feature pairs, Port scan
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Histograms 3d: Feature pairs, Port scan
H(Y|X)=0.76
H(Y|X)=2.216
H(Y|X)=0.39
H(Y|X)=3.35
Pick me!
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Snort port scan alerts
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Snort port scan alerts
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Snort port scan alerts
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Outline
1
Log browsing moves
Pipes and tables
Trees are better than pipes and tables!
2
Data organization
Trying to deﬁne the browsing problem
Entropy
Measuring co-dependence
Mutual Information
The tree building algorithm
3
Examples
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Building a data view
1
Pick the feature with lowest non-zero
entropy (“simplest histogram”)
2
Split all records on its distinct values
3
Order other features by the strength
of their dependence with with the
ﬁrst feature (conditional entropy or
mutual information)
4
Use this order to label groups
5
Repeat with next feature in (1)
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Building a data view
1
Pick the feature with lowest non-zero
entropy (“simplest histogram”)
2
Split all records on its distinct values
3
Order other features by the strength
of their dependence with with the
ﬁrst feature (conditional entropy or
mutual information)
4
Use this order to label groups
5
Repeat with next feature in (1)
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Building a data view
1
Pick the feature with lowest non-zero
entropy (“simplest histogram”)
2
Split all records on its distinct values
3
Order other features by the strength
of their dependence with with the
ﬁrst feature (conditional entropy or
mutual information)
4
Use this order to label groups
5
Repeat with next feature in (1)
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Building a data view
1
Pick the feature with lowest non-zero
entropy (“simplest histogram”)
2
Split all records on its distinct values
3
Order other features by the strength
of their dependence with with the
ﬁrst feature (conditional entropy or
mutual information)
4
Use this order to label groups
5
Repeat with next feature in (1)
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Building a data view
1
Pick the feature with lowest non-zero
entropy (“simplest histogram”)
2
Split all records on its distinct values
3
Order other features by the strength
of their dependence with with the
ﬁrst feature (conditional entropy or
mutual information)
4
Use this order to label groups
5
Repeat with next feature in (1)
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Snort port scan alerts
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Snort port scan alerts
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Snort port scan alerts
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Quick pair summary
One ISP, 617 lines, 2 users, one tends to mistype.
11 lines of screen space.
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Quick pair summary
One ISP, 617 lines, 2 users, one tends to mistype.
11 lines of screen space.
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Novelty changes the order
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Looking at Root-Fu captures
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Looking at Root-Fu captures
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Comparing 2nd order uncertainties
1
2
3
Compare uncertainties in each
Protocol group:
1
Destination: H = 2.9999
2
Source: H = 2.8368
3
Info: H = 2.4957
“Start with the simpler view”
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Comparing 2nd order uncertainties
1
2
3
Compare uncertainties in each
Protocol group:
1
Destination: H = 2.9999
2
Source: H = 2.8368
3
Info: H = 2.4957
“Start with the simpler view”
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Looking at Root-Fu captures
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Looking at Root-Fu captures
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Looking at Root-Fu captures
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Screenshots (1)
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Screenshots (2)
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Screenshots (3)
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Research links
Research on using entropy and related measures for network
anomaly detection:
Information-Theoretic Measures for Anomaly Detection,
Wenke Lee & Dong Xiang, 2001
Characterization of network-wide anomalies in trafﬁc ﬂows,
Anukool Lakhina, Mark Crovella & Christiphe Diot, 2004
Detecting Anomalies in Network Trafﬁc Using Maximum
Entropy Estimation, Yu Gu, Andrew McCallum & Don
Towsley, 2005
...
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Summary
Information theory provides useful heuristics for:
summarizing log data in medium size batches,
choosing data views that show off interesting features of a
particular batch,
ﬁnding good starting points for analysis.
Helpful even with simplest data organization tricks.
In one sentence
H(X), H(X|Y), I(X; Y), . . . :
parts of a complete analysis kit!
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Summary
Information theory provides useful heuristics for:
summarizing log data in medium size batches,
choosing data views that show off interesting features of a
particular batch,
ﬁnding good starting points for analysis.
Helpful even with simplest data organization tricks.
In one sentence
H(X), H(X|Y), I(X; Y), . . . :
parts of a complete analysis kit!
Sergey Bratus
Entropy tricks for browsing logs and packet captures
Log browsing moves
Data organization
Examples
Source code and docs
For source code (GPL), documentation, and technical reports:
http://kerf.cs.dartmouth.edu
Sergey Bratus
Entropy tricks for browsing logs and packet captures