labeling security bugs. Interestingly, when the AUC of a model
covering both features increased, an Exniffer feature is included in
the top five features. For the V8 model, the AUC is boosted from 0.89
to 0.91, and the top fifth feature includes an Exniffer feature, F13:
Memory operand is Null. Also, the AUC of the SpiderMonkey model
is slightly boosted from 0.93±0.03 to 0.93±0.02, and the top second
feature includes F34: Resume Flag. Meanwhile, in Chakra, the AUC
of the combination system is not boosted, and the top five features
consist of only CRScope features. This result demonstrates that
Exniffer provides complementary features for CRScope to improve.
Case Study. Listings 1 and 2 show Chakra PoC code snippets that
invoke a security bug and a non-security bug, respectively. The
following table shows two feature vectors representing two Chakra
crash instances obtained by executing Listings 1 and 2. Each row
represents one crash instance with two vector representations; the
first one is from CRScope and the other one is encoded according
to the method used by Exniffer.
CRScope
6, 0.101488, 4, 0., 0, ...
4, 0., 4, 0.243038, 0, ...
Exniffer
1, 2, 3, 4, 6, 8, 9, 5, 11, 16, 20, 18, 19, 23, 24, 27, 29, 34, 42
1, 2, 3, 4, 6, 8, 9, 5, 11, 16, 20, 18, 19, 23, 24, 27, 29, 34, 42
The CRScope feature dimension is 100, which is a spare vector
with most element values are zero. On the other hand, the length of
the Exniffer feature is 44, and the listed features are set to 1. When
only considering Exniffer features, they are identical, although their
corresponding PoC code completely differ. However, one of them
represents the crash due to a security bug, and the other represents
the crash due to a non-security bug. It is clear that Exniffer gives
the same label to these two bugs. On the other hand, CRScope
correctly labels the first bug as a security bug, and the other as
a non-security bug because we encode each vector element with
a numeric (quantitative) value, not a binary value, providing the
models with more flexibility in classifying security bugs.
7 RELATED WORK
There are a limited number of previous studies on predicting ex-
ploitability [23, 60, 66] and prioritizing bugs by analyzing call
stacks [6, 32, 64] or descriptions [2, 9, 31] in bug reports. No previ-
ous work addresses predicting security-related bugs solely from an
observed JS engine crash. Predicting security-related bugs in a JS
engine is not straightforward. In practice, classifying a reported bug
requires domain expertise because of the complexity and enormous
size of state-of-the-art JS engines. To our best knowledge, CRScope
is the first tool to classify security-related bugs from crash-dumps
by building machine learning models from the past verdicts of JS
engine developers.
7.1 Crash Analyses
Gustavo et al. proposed VDiscover [23] to predict the exploitability
of a given test using machine learning. They leveraged static and
dynamic call sequences to the standard C library. Because their
approach uses a single static call sequence for each binary, the
static feature of VDiscover is not directly applicable for training
each JS engine that emits different crash-dump files for various
Session 9: FuzzingAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand655JS inputs. They also required instrumenting a target binary and
its dynamically linked libraries to extract dynamic call sequences,
resulting in significant overheads for large software such as JS
engines.
Exniffer [60] also classifies the exploitability of a given core-
dump by using machine learning models, similar to the approach
used by CRScope. Exniffer extracts a set of features from core-dump
files and run-time information by leveraging hardware-assisted
monitoring such as Last Branch Record (LBR) register [24]. In con-
trast to monitoring execution traces, LBR does not impede any
real-time performance. However, it has a limited window size for
tracing executed instructions, and requires an Intel processor with
LBR supports. Without LBR support, an LBR simulator is required,
which brings inevitable performance overhead. The total number
of features used in Exniffer was 51, which is seven times larger than
the number of features used in CRScope. This difference comes
from the method used to vectorize each feature, not from a limited
feature scope of CRScope. Exniffer encodes every feature value as
binary number, thereby increasing feature vector dimensions.
ExploiMeter [66] uses fuzzing and machine learning techniques
to evaluate software exploitability. It also uses static features from
ELF executables extracted using hexdump, objdump, ldd, and read-
elf utilities. Although ExploiMeter uses dynamic fuzzing tests to
update the prior beliefs on exploitability, the dataset is labeled using
!exploitable, which is shown to be less accurate than Exniffer.
RETracer [5] is another study that identifies functions to blame
for an observed crash. It analyzes program semantics extracted from
memory dumps. It performs backward and forward taint analyses,
then identifies blamed functions from backward data flow graphs.
Although this work was deployed on Windows Error Reporting
(WER), it focused on the Windows platform running on x86 and
x86-64 architectures. Also, they did not consider whether a given
crash is due to a security bug or not.
The representative difference of CRScope from the previous
studies is that we classify security bugs, not exploitable bugs, and
target JS engines, which are larger and more sophisticated than the
common software projects that the previous studies were evaluated
on. Furthermore, CRScope uses only crash dumps which are trivial
to obtain.
ranked list sorting the functions by their suspicious scores helps
to locate a faulty function. These approaches using stack traces
are simple and bring almost no overhead; however, they are not
effective for newly added functions.
Descriptions. In [2, 9], Gegick et al. and Behl et al. proposed ap-
proaches that apply text mining on natural-language descriptions
of bug reports to train a statistical model for classifying a bug report
as either a security bug report or a non-security bug report. Kanwal
and Maqbool developed a recommender which automatically prior-
itizes new bug reports using machine learning [31]. They used the
categorical and text attributes of a bug report as training features.
The former included, for example, component, severity, platform,
operating system, bug lifetime, developer, and the latter included
the summary and description. Some research introduced machine
learning approaches to detect duplicate bug reports [28, 52, 59] and
other presented machine learning approaches to recommend bugs
that the developer should work on [1, 29, 50]. Although the previ-
ous research used bug reports from large-scale software projects
such as Eclipse, Cisco, and Mozilla, their main limitation is that
they require well-written bug reports created by the bug reporters.
8 CONCLUSION
We designed and implemented CRScope to classify whether a given
crash-dump is security-related. Specifically, it checks whether the
PoC code snippets causing JS engine crashes trigger its inherent se-
curity bugs. We also demonstrated that prior approaches, including
Exploitable and AddressSanitizer, are unfit for classifying security
bugs in JS engines.
CRScope leverages a machine learning classifier trained on past
verdicts by domain experts. Rather than using arbitrarily selected
general features, we feed the model with engine-specific local fea-
tures, which reflect the historical context in which each JS engine
crashed. We then let CRScope select the best features for rendering
correct verdicts.
When evaluated on 339 bugs and their 766 crashes, CRScope
achieved 0.85, 0.89, and 0.93 AUCs for Chakra, V8, and SpiderMon-
key, respectively; it outperforms all tools including Exniffer from
the previous studies in all cases. The experimental results demon-
strate its practical utility. We invite further research by releasing
the ground truth dataset and the source code of CRScope.
7.2 Bug Report Analyses
Classifying bug reports is important for the BTSs of software projects
like browsers to prioritize bugs, detect duplicates, and assign devel-
opers. Various research efforts have been devoted to triaging bug
reports in BTSs.
Stack Traces. This line of work [6, 32, 64] presented a method for
prioritizing crashes using stack traces, although no consideration
was given to whether the crash was exploitable or security-related.
Kim et al. [32] predicted whether a crash will be frequent (top
crash) or not (bottom crash). They extracted crash stack traces and
functions to train their model. Dang et al. [6] improved existing
Microsoft Windows Error Reporting (WER) by proposing a novel
bucketing method based on the Position Dependent Model (PDM),
which is a similarity measure for call stacks. CrashLocator [64] re-
covers approximate crash traces via stack expansions and computes
the suspicious scores for each function in the recovered traces. A
ACKNOWLEDGMENTS
The authors would like to thank the anonymous reviewers for their
concrete feedback. This work was supported by National Research
Foundation of Korea (NRF) Grant No.: 2017R1C1B5073934 and by
the Naver corporation.
REFERENCES
[1] John Anvik and Gail C Murphy. 2011. Reducing the effort of bug report triage: Rec-
ommenders for development-oriented decisions. ACM Transactions on Software
Engineering and Methodology (TOSEM) 20, 3 (2011), 10.
[2] Diksha Behl, Sahil Handa, and Anuja Arora. 2014. A bug mining tool to identify
and analyze security bugs using naive bayes and tf-idf. In Optimization, Reliabilty,
and Information Technology (ICROIT), 2014 International Conference on. IEEE,
294–299.
[3] Jacob Benesty, Jingdong Chen, Yiteng Huang, and Israel Cohen. 2009. Pearson
Correlation Coefficient. In Noise Reduction in Speech Processing. Springer, 1–4.
[4] Lars Buitinck, Gilles Louppe, Mathieu Blondel, Fabian Pedregosa, Andreas
Mueller, Olivier Grisel, Vlad Niculae, Peter Prettenhofer, Alexandre Gramfort,
Session 9: FuzzingAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand656[36] Microsoft. 2019. EdgeHTML issue tracker. https://developer.microsoft.com/
en-us/microsoft-edge/platform/issues/.
[37] Microsoft. 2019. Microsoft ChakraCore.
ChakraCore.
https://github.com/Microsoft/
[38] Microsoft. 2019. Microsoft Edge on Windows Insider Preview Bounty Program.
https://www.microsoft.com/en-us/msrc/bounty-edge.
[39] MITRE. 2018. Common Weakness Enumeration. https://cwe.mitre.org/.
[40] MITRE. 2019. CWE-762. https://cwe.mitre.org/data/definitions/762.html.
[41] Mozilla. [n. d.]. Mozilla Bug Bounty Program. https://www.mozilla.org/en-US/
security/bug-bounty/.
[42] Mozilla. [n. d.]. Mozilla Client Bug Bounty Program. https://www.mozilla.org/
en-US/security/client-bug-bounty/.
[43] Mozilla. 2017. Mozilla Bug 1344415. https://bugzilla.mozilla.org/show_bug.cgi?
[8] Jonathan Foote. 2018. GDB ‘exploitable’ plugin. https://github.com/jfoote/
[44] Mozilla. 2018. Mozilla Bug 1493900. https://bugzilla.mozilla.org/show_bug.cgi?
[12] Google. 2018. Chromium Issue 386988. https://bugs.chromium.org/p/chromium/
security/known-vulnerabilities/firefox/.
[18] Google. 2019. Chrome Reward Program Rules. https://www.google.com/about/
08/02/introducing-jsfunfuzz/.
Jaques Grobler, Robert Layton, Jake VanderPlas, Arnaud Joly, Brian Holt, and Gaël
Varoquaux. 2013. API design for machine learning software: experiences from
the scikit-learn project. In ECML PKDD Workshop: Languages for Data Mining
and Machine Learning. 108–122.
[5] Weidong Cui, Marcus Peinado, Sang Kil Cha, Yanick Fratantonio, and Vasileios P
Kemerlis. 2016. RETracer: triaging crashes by reverse execution from partial
memory dumps. In Proceedings of the 38th International Conference on Software
Engineering. ACM, 820–831.
[6] Yingnong Dang, Rongxin Wu, Hongyu Zhang, Dongmei Zhang, and Peter Nobel.
2012. ReBucket: a method for clustering duplicate crash reports based on call
stack similarity. In Software Engineering (ICSE), 2012 34th International Conference
on. IEEE, 1084–1093.
[7] CVE Details. 2019. Vulnerability Statistics Of Chrome. https://www.cvedetails.
com/product/15031/Google-Chrome.html?vendor_id=1224.
exploitable.
[9] Michael Gegick, Pete Rotella, and Tao Xie. 2010. Identifying security bug reports
via text mining: An industrial case study. In Mining software repositories (MSR),
2010 7th IEEE working conference on. IEEE, 11–20.
[10] Google. 2016. Chromium Issue 388665. https://bugs.chromium.org/p/chromium/
[11] Google. 2016. Chromium Issue 595834. https://bugs.chromium.org/p/chromium/
issues/detail?id=388665.
issues/detail?id=595834.
issues/detail?id=386988.
issues/detail?id=610600.
issues/detail?id=718858.
issues/detail?id=729991.
issues/detail?id=733549.
[13] Google. 2018. Chromium Issue 610600. https://bugs.chromium.org/p/chromium/
[14] Google. 2018. Chromium Issue 718858. https://bugs.chromium.org/p/chromium/
[15] Google. 2018. Chromium Issue 729991. https://bugs.chromium.org/p/chromium/
[16] Google. 2018. Chromium Issue 733549. https://bugs.chromium.org/p/chromium/
[17] Google. 2018. Reporting Security Bugs. https://dev.chromium.org/Home/
chromium-security/reporting-security-bugs.
appsecurity/chrome-rewards/.
[19] Google. 2019. Chromium Issues. https://bugs.chromium.org/p/chromium/.
[20] Google. 2019. ClusterFuzz. https://github.com/google/clusterfuzz.
[21] Google. 2019. ClusterFuzz Crash type. https://google.github.io/clusterfuzz/
reference/glossary.
[22] Google. 2019. Google V8. https://chromium.googlesource.com/v8/v8/.
[23] Gustavo Grieco, Guillermo Luis Grinblat, Lucas Uzal, Sanjay Rawat, Josselin
Feist, and Laurent Mounier. 2016. Toward large-scale vulnerability discovery
using machine learning. In Proceedings of the Sixth ACM Conference on Data and
Application Security and Privacy. ACM, 85–96.
[24] Part Guide. 2016. Intel 64 and IA-32 architectures software developer’s manual.
Volume 3 (3A, 3B, 3C & 3D): System Programming Guide (2016).
[25] Mark Andrew. Hall. 1999. Correlation-Based Feature Selection for Machine
[26] Choongwoo Han. 2019. Case Study of JavaScript Engine Vulnerabilities. https:
Learning. (1999).
//github.com/tunz/js-vuln-db.
[27] Christian Holler, Kim Herzig, and Andreas Zeller. 2012. Fuzzing with Code
Fragments. In USENIX Security Symposium. 445–458.
[28] Nicholas Jalbert and Westley Weimer. 2008. Automated duplicate detection for
bug tracking systems. In Dependable Systems and Networks With FTCS and DCC,
2008. DSN 2008. IEEE International Conference on. IEEE, 52–61.
[29] Gaeul Jeong, Sunghun Kim, and Thomas Zimmermann. 2009. Improving bug
triage with bug tossing graphs. In Proceedings of the the 7th joint meeting of the
European software engineering conference and the ACM SIGSOFT symposium on
The foundations of software engineering. ACM, 111–120.
[30] Jeffrey D. Ullman Jure Leskovec, Anand Rajaraman. 2014. Mining of Massive
Datasets. http://infolab.stanford.edu/~ullman/mmds/book.pdf.
[31] Jaweria Kanwal and Onaiza Maqbool. 2012. Bug prioritization to facilitate bug
report triage. Journal of Computer Science and Technology 27, 2 (2012), 397–412.
[32] Dongsun Kim, Xinming Wang, Sunghun Kim, Andreas Zeller, Shing-Chi Cheung,
and Sooyong Park. 2011. Which crashes should i fix first?: Predicting top crashes
at an early stage to prioritize debugging efforts. IEEE Transactions on Software
Engineering 37, 3 (2011), 430–447.
[33] Kaspersky Lab. 2018. Attacks leveraging exploits for Microsoft Office grew
fourfold in early 2018. https://www.kaspersky.com/about/press-releases/2018_
microsoft-office-exploits.
[34] Guillaume Lemaître, Fernando Nogueira, and Christos K. Aridas. 2017.
Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets
in Machine Learning. Journal of Machine Learning Research 18, 17 (2017), 1–5.
http://jmlr.org/papers/v18/16-365.html
[35] Microsoft. 2014. Definition of a Security Vulnerability. https://docs.microsoft.
com/en-us/previous-versions/tn-archive/cc751383(v=technet.10).
id=1344415.
id=1493900.
id=1493903.
[45] Mozilla. 2018. Mozilla Bug 1493903. https://bugzilla.mozilla.org/show_bug.cgi?
[46] Mozilla. 2019. Bugzilla. https://bugzilla.mozilla.org/.
[47] Mozilla. 2019. Exploitable crashes. https://developer.mozilla.org/en-US/docs/
Mozilla/Security/Exploitable_crashes.
[48] Mozilla. 2019. Mozilla SpiderMonkey. https://github.com/mozilla/gecko-dev.
[49] Mozilla. 2019. Security Advisories for Firefox. https://www.mozilla.org/en-US/
[50] G Murphy and D Cubranic. 2004. Automatic bug triage using text categorization.
In Proceedings of the Sixteenth International Conference on Software Engineering &
Knowledge Engineering. Citeseer.
[51] Stephan Neuhaus, Thomas Zimmermann, Christian Holler, and Andreas Zeller.
2007. Predicting vulnerable software components. In Proceedings of the 14th ACM
conference on Computer and communications security. ACM, 529–540.
[52] Anh Tuan Nguyen, Tung Thanh Nguyen, Tien N Nguyen, David Lo, and Cheng-
nian Sun. 2012. Duplicate bug report detection with a combination of information
retrieval and topic modeling. In Proceedings of the 27th IEEE/ACM International
Conference on Automated Software Engineering. ACM, 70–79.
[53] Jesse Ruderman. 2007. Introducing jsfunfuzz. http://www.squarefree.com/2007/
[54] Adrian Schroter, Adrian Schröter, Nicolas Bettenburg, and Rahul Premraj. 2010.
Do stack traces help developers fix bugs?. In 2010 7th IEEE Working Conference
on Mining Software Repositories (MSR 2010). IEEE, 118–121.
[55] Offensive Security. 2019. Exploit Database. https://www.exploit-db.com/.
[56] Konstantin Serebryany, Derek Bruening, Alexander Potapenko, and Dmitriy
Vyukov. 2012. AddressSanitizer: A Fast Address Sanity Checker. In USENIX
Annual Technical Conference. 309–318.
[57] Internet World Stats. 2019.
INTERNET USAGE STATISTICS. https://www.
[58] ChakraCore team. 2019. ChakraCore Roadmap. https://github.com/Microsoft/
internetworldstats.com/stats.htm.
ChakraCore/wiki/Roadmap.
[59] Yuan Tian, Chengnian Sun, and David Lo. 2012. Improved duplicate bug report
identification. In Software Maintenance and Reengineering (CSMR), 2012 16th
European Conference on. IEEE, 385–390.
[60] Shubham Tripathi, Gustavo Grieco, and Sanjay Rawat. 2017. Exniffer: Learning
to Prioritize Crashes by Assessing the Exploitability from Memory Dump. In
Asia-Pacific Software Engineering Conference (APSEC), 2017 24th. IEEE, 239–248.
[61] Spandan Veggalam, Sanjay Rawat, Istvan Haller, and Herbert Bos. 2016. Ifuzzer:
An evolutionary interpreter fuzzer using genetic programming. In European
Symposium on Research in Computer Security. Springer, 581–601.
[62] W3Techs. 2019. Usage of JavaScript for websites.
https://w3techs.com/
technologies/details/cp-javascript/all/all.
[63] Webkit. 2019. Webkit JavaScriptCore. https://git.webkit.org/.
[64] Rongxin Wu, Hongyu Zhang, Shing-Chi Cheung, and Sunghun Kim. 2014.
CrashLocator: locating crashing faults based on crash stacks. In Proceedings
of the 2014 International Symposium on Software Testing and Analysis. ACM,
204–214.
[65] Jun Xu, Dongliang Mu, Ping Chen, Xinyu Xing, Pei Wang, and Peng Liu. 2016.
Credal: Towards locating a memory corruption vulnerability with your core
dump. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and
Communications Security. ACM, 529–540.
[66] Guanhua Yan, Junchen Lu, Zhan Shu, and Yunus Kucuk. 2017. Exploitmeter:
Combining fuzzing with machine learning for automated evaluation of software
exploitability. In 2017 IEEE Symposium on Privacy-Aware Computing (PAC). IEEE,
164–175.
[67] ZERODIUM. 2019. ZERODIUM Exploit Acquisition Program. https://zerodium.
com/program.html.
[68] Boyou Zhou, Anmol Gupta, Rasoul Jahanshahi, Manuel Egele, and Ajay Joshi.
2018. Hardware Performance Counters Can Detect Malware: Myth or Fact?. In
Proceedings of the 2018 on Asia Conference on Computer and Communications
Security. ACM, 457–468.
Session 9: FuzzingAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand657