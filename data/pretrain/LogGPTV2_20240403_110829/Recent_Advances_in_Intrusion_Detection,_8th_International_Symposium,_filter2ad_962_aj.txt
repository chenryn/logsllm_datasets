### DNS-Based Rate Limiting Mechanism

When a destination IP lacks a prior DNS translation, it is added to the current time interval's bucket, and the packet is delayed. Each bucket can hold up to \( q \) distinct IPs. Once a bucket is full, new connection requests are placed into the subsequent bucket, creating a cascading effect. Requests in the \( i \)-th bucket are delayed until the beginning of the \( (i+1) \)-th time interval. The \( n \)-th bucket, which is the last in the sequence, has no overflow bucket. When it is full, new TCP SYN packets without DNS translations are dropped. After \( n \times t \) time periods, another set of \( n \) buckets is reinstated for the next \( n \times t \) time period. This algorithm allows a maximum of \( q \) distinct IPs (without DNS translations) per time interval \( t \), and packets (if not dropped) are delayed by at most \( n \times t \).

The concept of buckets provides an abstraction that enables administrators to define rules such as "Permit 10 new flows every 30 seconds, dropping anything over 120 seconds." This example translates to 4 buckets (with \( t = 30 \) seconds and \( q = 10 \)). Expressing rate limiting rules in this manner is more intuitive and easier than characterizing network traffic in terms of working sets or connection failure rates.

This scheme can be implemented at the host level or at the edge router of a network. A host-level implementation requires maintaining DNS-related statistics on each host, while an edge-router-based implementation would require the border router to keep a shadow DNS cache for the entire network.

In our study, we tested DNS-based rate limiting (DNS RL) both at the host level and at the edge, using DNS server cache information and all DNS traffic recorded at the network border. Specifically, we mirrored the DNS cache (including all TTLs) at the edge and updated the cache as new DNS queries and replies were recorded. Traffic to destination addresses with unexpired DNS records is allowed through, while all others are delayed.

### Analysis

The critical parameters for the cascading-bucket scheme are the rate limit, which is determined by the values of \( q \) (the size of each bucket), \( t \) (the time interval), and \( n \) (the number of buckets). To simplify our analysis, we varied the value of \( q \) while keeping \( n \) and \( t \) constant. Additionally, the value of \( n \times t \) was set to 120 seconds to model the TCP timeout period. This scheme allows a certain number of untranslated IP connections to exit the network, accommodating legitimate direct-IP connections. In our data set, we observed some direct server-to-server communication and direct-IP connections due to peer-to-peer, streaming audio, and passive FTP traffic. These were the main causes of false positives. Maintaining a whitelist to allow legitimate direct-IP connections can further reduce false positives, but a comprehensive whitelist for an open network may not be feasible, as noted in [22].

#### Host-Level DNS Throttling

We first analyzed the host-level DNS throttling scheme. For this, we maintained a set of cascading buckets for each host. Figures 8(a) and 8(b) show the false positive and false negative rates for infected hosts, with daily error rates averaged over all infected hosts. Figure 8(c) plots the analogous false positive rates for normal hosts. Table 5 presents the delay statistics for a normal host, and Table 6 shows the worst-case delay statistics for an infected host.

**Table 5: DNS RL Delay Statistics for a Normal Host (3-Hour Period)**

| Delay Amount | Number of Flows |
|--------------|-----------------|
| No delay     | 2136            |
| 1 - 10 sec   | 8               |
| > 10 sec     | 0               |
| **Total**    | **2144**        |

**Table 6: DNS RL Delay Statistics for an Infected Host (3-Hour Period)**

| Delay Amount | Benign | Malicious |
|--------------|--------|-----------|
| No delay     | 1      | 1         |
| 1 - 30 sec   | 34     | 2         |
| 31 - 60 sec  | 35     | 12        |
| 61 - 100 sec | 40     | 11        |
| > 100 sec    | 4903   | 172       |
| Dropped      | 112862 | 1007      |
| **Total**    | **11785** | **806**  |

**Observations:**
- Host-level DNS throttling significantly outperforms other mechanisms. The average false positive rates range from 0.1% to 1.7%, with corresponding false negative rates between 0.1% to 3.2%, both significantly lower than the error statistics of other mechanisms.
- Applications experiencing false positives tend to be those outside the security policies of an enterprise network (e.g., peer-to-peer applications), whose disruption is generally considered non-critical.
- DNS RL delayed only 8 total flows for a normal host, compared to 385 flows using Williamson’s method. All delays were less than 10 seconds, which is not significant.
- During the peak infection period, DNS RL dropped approximately 17% of the host’s benign traffic, compared to over 90% when using Williamson’s method. DNS RL also delays fewer flows for normal hosts.
- Nearly all delayed malicious flows were subjected to the maximum allowed delay, and over 95% of the malicious flows were dropped.
- During the Blaster outbreak, on average, 97% of worm traffic was rate-limited—approximately 82% dropped and 18% delayed with an average delay of one minute each.

#### Edge Router DNS Throttling

Figures 8(d) and 8(e) show the false positive and false negative rates for edge router DNS throttling. The data in these graphs are daily error rates averaged over all hosts.

**Figure 8: Results for DNS-Based End Host RL**

- **(a) FP for DNS-based RL (Infected Clients)**
- **(b) FN for DNS-based RL (Infected Clients)**
- **(c) FP for DNS-based RL (Normal Clients)**
- **(d) Flows Dropped / Delayed**

These results demonstrate the effectiveness of the DNS-based rate limiting mechanism in controlling network traffic and mitigating the impact of malicious activities.