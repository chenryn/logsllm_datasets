DDoS AttackerSYN ﬂoodingHTTP requestNormal ClientPOX ControllerS/W OF Switch(Avant-Guard)Web Server419(A) Traditional SDN switch
(B) AVANT-GUARD SDN switch
(C) Off-ASIC implementation
Figure 11: Hardware architectural designs of (A) Traditional SDN switch (B) SDN switch with connection migration and actuating
triggers and (C) SDN switch with connection migration and actuating triggers off-ASIC
Item
Original
AVANT-GUARD
Case
w/o DDoS
w/ DDoS
w/o DDoS
w/ DDoS
Response Time Overhead
0.3917 s
∞
0.3990 s
0.4001 s
-
∞
1.86 %
2.1 %
Table 2: Average response time of each test case (Overhead
means the percentage of additional response time compared
with the Original - w/o DDoS case)
server under two situations: with and without background TCP
SYN ﬂoods in this OpenFlow network). The attacker generates
1,000 connection attempts per second to the server, and we repeat
this over 500 seconds to measure the average response time.
Figure 13: Percentage of successfully delivered packets to the
web server from benign clients
That is the data plane will receive many TCP SYN packets that
it will report to the control plane, which also receives the same
number of requests from the attack. Currently, OpenFlow does not
provide any way to reduce this effect.
With an AVANT-GUARD application, because the data plane au-
tomatically responds to all TCP SYN packets without high over-
head, the data plane need not handle (i.e., forward or drop packets)
all attack packets. In addition, the control plane only receives the
requests for a successfully established TCP connection. Thus, the
control plane does not suffer from network saturation attacks, and
the application can easily detect such attacks. In this case, AVANT-
GUARD makes the control plane and the SDN network more re-
silient and scalable.
5.1.2 Network Scanning Attack
Example Scenario: We test how our system defends a network
from a network scan attack, and the test environment is shown in
Figure 14. In this test, we use Nmap [24] to vertically scans all
network ports of a ﬁle server (10.0.0.2) that only opens network
port 10000.
The test result showing the average response time is summarized
in Table 2. The normal client can retrieve the web page in 0.4 sec-
onds, but it does not get any response during a background TCP
SYN ﬂood attack due to the effect of control/data plane saturation
mentioned earlier. However, AVANT-GUARD can effectively de-
fend the network from this attack, enabling the normal client to re-
trieve the webpage without any problem, because our data plane au-
tomatically and transparently classiﬁes and removes the malicious
TCP connection attempts. Our system introduces only a negligible
delay overhead (around 2.1%) for the normal client, even during
severe saturation attacks.
We also measure the overhead of connection migration on nor-
mal TCP connections during normal network operations (i.e., with-
out attacks) using the same experimental setup shown in Figure 12.
From Table 2, we can see that the overhead caused by connection
migration on normal TCP connections is minimal (1.86 %).
To further show the effect of saturation attacks on normal trafﬁc
in detail, we vary the packet-sending rate of the network saturation
attack from 0 to 800 per second, and we send the requests from
10 benign clients to a target web server at the same time. The test
results are shown in Figure 13, and we can easily observe that re-
quests from benign clients are hardly delivered to the web server
when the network saturation attack happens using the unmodiﬁed
OpenFlow switch (nearly 0% when the ﬂooding attack sends more
than 100 packets per second). However, with AVANT-GUARD, all
requests from benign clients are delivered to the web server, even
while the network is under a severe network saturation attack.
Implementation Comparison: To detect TCP SYN ﬂood at-
tacks with an OpenFlow application, the application typically must
be aware of the TCP session information (e.g., whether or not a
TCP connection is successful). However, this session management
will cause control ﬂow saturation issues that we discussed earlier.
Figure 14: Environment for network scan attack scenario
HeaderParserExact Match LookupWildcard LookupArbiterPacket EditorSRAMTCAMPacket InInput ArbiterPacket OutCPUDRAMASICCountersCountersModiﬁedHeaderParserExact Match LookupWildcard LookupModiﬁedArbiterPacket Editor(Connection Handler)SRAMTCAMPacket InInput ArbiterPacket OutCPUDRAMASICCountersCountersACK/SEQDeltaACK/SEQDeltaOptionsOptionsConditionConditionTCAMSRAMModiﬁedHeaderParserExact Match LookupWildcard LookupModiﬁedArbiterPacket Editor(Connection Handler)SRAMTCAMPacket InInput ArbiterPacket OutCPUDRAMASICCountersCountersACK/SEQDeltaACK/SEQDeltaOptionsConditionConditionOptionsFlow Rule0100200300400500600700800900020406080100120Attack rate (PPS)Delivered rate (%)  OpenFlowAvant−GuardScan attackerFile serveropen: 10000Scan whole portswith Nmap10.0.0.110.0.0.2POX ControllerS/W OF Switch(Avant-Guard)420If we employ AVANT-GUARD, the data plane automatically main-
tains the information on the TCP connection attempts in the access
table and reports session information to the control plane, which
can easily detect scan attempts by applying a simple threshold-
based scan-detection algorithm. Here, we write a simple security
application for detection of a network scan attack that regards a re-
mote host as a scanner if it initiates ﬁve failed TCP connection at-
tempts. This application only needs to ask the data plane to report
the information on the TCP connection attempts; it does not itself
need to maintain TCP sessions. The detection result is marked with
a red rectangle in Figure 15.
Figure 15: Network scan-detection result
Implementation Comparison: To detect a TCP scanning attack
with an OpenFlow application, we need to check whether each TCP
session is successful at the application layer. However, this check
requires that the application manages each TCP ﬂow making it vul-
nerable to control ﬂow saturation attacks. If we implement the same
application with AVANT-GUARD, it only needs to periodically read
the access table to collect TCP session information.
In addition to this, we can implement the whitehole function with
AVANT-GUARD easily. The whitehole function provided by our
system can be easily observed by looking at Nmap scan results. In
the absence of our approach, Nmap can successfully scan the ﬁle
server, and ﬁnds that network port 10000 is open, as shown in Fig-
ure 16. Figure 17 shows the scan results of Nmap when applying
our system (the network environment is the same as in Figure 14).
Although the ﬁle server only opens port 10000, Nmap thinks that
all network ports are open.
Figure 16: Nmap scan result without AVANT-GUARD
5.1.3 Network Intrusion Attack
Example Scenario: We set up an attack scenario as shown in
Figure 18, and in this case, an attacker (10.0.0.1) sends an RPC
buffer overﬂow attack to another host in the network (10.0.0.2).
Here we assume two things: (i) the control plane already requested
the data plane to deliver packet payloads delivered to 10.0.0.2 and
(ii) a security application has a signature for the attack.
In this
test scenario, the application uses snort rules to detect malicious
payloads. The result is shown in Figure 19, where we ﬁnd that the
security application accurately detects the attack (red rectangle in
Figure).
Figure 17: Nmap scan result with AVANT-GUARD - Whitehole
Figure 18: Network intrusion attack scenario
Implementation Comparison: An attacker can send malicious
contents (e.g., exploits) to infect a target victim. To date, many
approaches for detecting network intrusions have been proposed,
and most of them rely on deep packet inspection to identify known
attack patterns. However, an OpenFlow control plane (and appli-
cations) cannot see all network packet payloads. This is because
OpenFlow was originally designed to handle mostly layer 2/3 net-
work trafﬁc. The data plane only reports network header informa-
tion to the control plane, and if there is a matching ﬂow rule in the
ﬂow table, the data plane does not even report header information
to the control plane.
The actuating trigger module of AVANT-GUARD provides a new
capability that can deliver a packet payload to the control plane
(i.e., condition for packet payload). In this case, the AVANT-GUARD
application simply deﬁnes a condition involving header ﬁelds (e.g.,
source or destination IP) that it wants to investigate and then for-
wards these criteria to the switch. The switch will report every
packet payload that matches the condition to the application.
5.2 Overhead Measurement
When we measure the performance overhead of AVANT-GUARD,
we use the same test environment as in Figure 12.
Figure 19: Network intrusion detection based on simple pay-
load inspection
network intrusion attackerFile serversend malicious content10.0.0.110.0.0.2POX ControllerS/W OF Switch(Avant-Guard)421Figure 20: Breakdown of connection establishment delays
in OpenFlow
Figure 21: Breakdown of connection establishment delays
in AVANT-GUARD
5.2.1 Connection Migration
To understand the overhead of connection migration at the micro
level, we analyze the internal operations for establishing a TCP ses-
sion in two cases: (i) using the software OF switch reference imple-
mentation and (ii) using the AVANT-GUARD extension. Figures 20
and 21 illustrate the breakdown of connection-establishment de-
lays in the two systems, respectively.
In the case of a typical OF switch, the delay in establishing a new
TCP session for which there is no ﬂow rule can be broken down into
seven components that start with the switch receiving a TCP SYN
packets and end with the transmission of the ACK packet to the
target server: (i) lookup a ﬂow table and forward (TL1); (ii) ask the
control plane for a ﬂow rule and receive the rule (PD2) - (processing
time in the control plane (PR1) is not included); (iii) insert a ﬂow
rule and forward (FO1); (iv) receive a SYN/ACK packet (PD3);
(v) forward a packet based on the ﬂow rule (FO1); (vi) receive an
ACK packet (PD1); and (vii) lookup a table and forward (TL1).
In the case of AVANT-GUARD, the breakdown is a little differ-
ent because the data plane automatically responds with SYN/ACK
packet. With AVANT-GUARD the eight operations include:
(i)
lookup a ﬂow table and forward (TL1); (ii) generate a SYN/ACK
packet (TR1); (iii) receive an ACK packet (PD1); (iv) lookup the
ﬂow table (TL1); (v) ask the control plane to get a permission for
migration and receive the rule for migration (PD2) - (processing
time in the control plane (PR1) is not included); (vi) forward a SYN
packet to a target host (FO1); (vii) receive a SYN/ACK packet
(PD3); and (viii) generate an ACK packet and send it (TR2).
We summarize the delay breakdown in the two cases as follows:
• OpenFlow case = TL1 + PD2 + FO1 + PD3 + FO1 + PD1 +
• AVANT-GUARD case = TL1 + TR1 + PD1 + TL1 + PD2 +
TL1
FO1 + PD3 + TR2
We instrumented the software switch to measure the respective
delay of each component and illustrate them in Figures 22 and 23.
To get these results, we initiated many TCP connection attempts
to a switch and then used the average values from our measure-
ments. The average connection establishment delay in the OF soft-
ware switch case is 1608.6 us; for AVANT-GUARD the average is
1618.74 us. Thus, the overhead of connection migration is 0.626%,
which is very small.
However, the delays here are dominated by the propagation de-
lay. If we remove PD1, PD2, and PD3 from the above measure-
ments, the original S/W OF switch incurs a composite delay of 32.4
us, and AVANT-GUARD incurs a delay of 42.54 us. In this case, the
overhead is 23.84%, which is somewhat more substantial, but still
not prohibitive.
5.2.2 Actuating Triggers
To estimate the overhead of actuating triggers, we measure the
time to check each condition (e.g., trafﬁc-rate based condition) and
to activate a ﬂow rule. Our results are summarized in Table 3.
For the trafﬁc-rate based condition, we simply deﬁne a condition
that checks if the PPS of a ﬂow is greater than 100. We see that
the overhead for each condition is relatively small (even nearly 0
in the case of payload-based condition). In comparison with the
elapsed time for connection migration, condition checks only in-
volve around 1.6% of overhead.
Item
Trafﬁc-rate based condition
Payload-based condition
Rule activation
time
0.322 us
≈ 0 us
1.697 us
Table 3: Time for checking each condition
The time for activating a ﬂow rule based on a condition includes
the time for checking the trafﬁc-rate based condition and the time
for looking up a ﬂow table. In our measurement, it is 1.697 us. This
time is signiﬁcantly less than typical propagation delay between the
data plane and the control plane (i.e., PD2). In our setup, the time
for PD2 is 459.81 us, and the time for activating a ﬂow rule is just
0.36% of PD2. Thus, we can say that our approach signiﬁcantly
reduces the time for threat reaction/mitigation. For example, if a