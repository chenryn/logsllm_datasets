环节。下面将分别针对这5个环节进行逐一分析。
因此我们将小明的需求拆解成日常变更、网络及架构、软件安装、软件配置、节点管理5个
着项目的成败、项目实施的进展，以及后续的扩展性。可见需求分析在任何地方都很关键，
期显得尤为重要，它完成的好坏直接影响着软件开发的质量与进度，而在运维领域直接关系
11.2场景需求分析
以 www 用户及组运行。Nginx 所产生的日志，每天凌晨进行压缩处理保证磁盘有足够的空闲空间。
件的配置不同而变化，这样能大大提升服务器的承载，提升利用率。为提升安全性，Nginx要求
有新增虚拟主机则应能在短时间内生效。考虑成本节约，希望在部署时Nginx 配置文件能根据硬
种，并且服务器硬件配置不统一。
布在天津网通和广州电信两个运营商所在地。服务器操作系统类型有Centos 和FreeBSD 两
11.1
出发，结合 Puppet 快速完成大型方案的部署。
司的青睐。因此我们将选用Nginx 作为大规则集群部署方案的软件，从多个角度与实用方面
它既有出色的 Web 表现，也有杰出的代理功能，近几年已经赢得大多数系统管理员及各大公
作为系统管理员需要不断关注软件漏洞、新软件特性，因此需要对软件进行定期升级。
首先我们需要对小明的需求进行分析，接着再做规划与实施。需求分析在软件开发的前
为应对公司的业务需求，系统管理员小明要求自己：能快速变更Nginx 的配置文件，比如若
系统管理员小明需要为公司的100 多台 Web 服务器安装应用管理软件Nginx。服务器分
在当前 Web Server、透明代理等诸多软件满天下的时代，Nginx 无疑是个全能型选手，
应用场景
大规模 Nginx 集群部署方案
第11章
---
## Page 57
Puppet Master 主机，为扩展 Puppet Master 提供了便利。
进行分地域解析，每台 Puppet Master 采用同相的安装与配置方法，通过 DNS 轮到不同的
Master，前端采用Nginx 或 Apache 做代理，即两个 IDC 各部署一组服务器。详细配置可参
达到一定规模。为缓解单台及管理机 Puppet Master的压力，可以在两个 IDC 上各部署多台
一个机房出现故障时，另一个机房勉强能用。两个机房之间的解析和调度可以依赖 DNS 划
网络。再加上各运营商之间的计费方式不同，导致不同运营商之间网络有所延迟，不同的接
互通设备，通过这些互联互通设备与其他运营商进行流量互访，各运营商再建立自己的核心
上。中国的网络结构可以简要概括为：以北京、上海、广州为超级核心，各运营商建立互联
果将中心端部署在天津网通节点会导致广州电信客户端请求延时，大部分资源将消耗在网络
11.2.2
通过逐步操作完成需求，进而使大家熟练掌握 Puppet 相关资源的用法。
reload 动作。在虚拟主机比较多且大部分虚拟主机配置不相同时，建议采用一个虚拟机一个
采用 define 或虚拟资源进行虚拟主机的配置管理。每次更新时采用 notify 触发 exec 资源执行
软件仓库进行软件包管理。尽管搭建软件仓库会带来一定的维护成本，但它的好处还是很明
基于公司内部使用，我们可以自己搭建DNS 服务器，也可以采用目前非常稳定的DNSPod
分两个view 来解决。跨运营商的 Puppet 架构图如图 11-1 所示。
推荐在网通和电信各部署一组管理机。尽管这样会带来成本的增加，但做到了异地容灾，
一组管理机。如果选择 BGP 机房则当 BGP 机房出现故障时，将成为架构的单点，因此笔者
人层依路由的跳数和其他影响的不同而导致延迟与丢包各有所不同。
文件的方式。如果每个虚拟主机的配置文件都相同，可以定义好固定的模板生成。
主机就在主机目录生成相应虚拟主机配置文件，采用File 资源同步此目录完成更新。也可以
显的，比如可用性、扩展性、速度都能得到保障。
析的日常变更可以概括为如下两大类：
小明同时还要分析定期增加虚拟主机、新服务器上线部署、服务器下线等变更。因此小明分
为实现负载均衡，另一种较好的方式是采用 DNS 轮循。目前 DNS 应用已经非常成熟
部署两组管理机带来的是难度系数的增加（认证颁发管理、report 的配置），服务器也会
为避免网络质量对整体架构的影响，需要考虑选择 BGP 机房或者在网通和电信各部署
由于服务器分属天津网通和广州电信。跨运营商网络质量存在极其不稳定的因素，如
配置变更可以采用 Puppet file 文件资源同步虚拟主机目录的方式进行。每增加一个虚拟
 这里需要读者熟悉 Puppet 的资源用法，这样才能灵活运用。不熟悉也没有关系，笔者将
对于这两种不同的方案，读者可以根据自己的环境进行选择。
软件安装与升级可以采用 package 资源进行管理，如果有更严格的控制，可以自己搭建
配置变更
口软件升级
网络及架构分析
一
第11章大规模Nginx集群部署方案·179
四
---
## Page 58
180第三部分实战篇
系统变量时采用 facter 命令获取到的系统变量进行配置。Nginx 系统进程数可以使用 ERB 模
11.2.4
调用 yum，在FreeBSD上会调用 port。
称相同，因此可以不采用条件语句。直接采用系统自带的软件安装命令，Puppet 在Centos 会
$operatingsystem，即操作系统类型进行软件安装。Nginx 在 Centos 与 FreeBSD 中的软件包名
不统一时软件仓库维护复杂，不但要维护多个软件包，并且依赖性处理起来比较棘手。
库，用来管理所有软件包及其依赖。这样做还可以提升软件包部署速度。缺点就是操作系统
EPEL 源找得到。如果涉及过多的软件或软件版本则需要自行控制，可以在本地搭建软件仓
11.2.3
为达到设备利用率最大化，运行用户的安全限制，在 nginx 配置文件 nginx.conf 中配置
软件安装时可以采用系统自带的软件包管理进行安装。一般软件包都能从官方源或
客户端软件安装时采用 Puppet 的 package 资源，通过 case 或 selection 条件语句确定
缺点是多系统维护复杂。
口开发软件包统一管理。
灰度发布，回滚便捷：
部署快；
口管理方便；
具体优点如下：
下面介绍一下自建软件源的优缺点。
软件配置分析
DNS RR
软件安装分析
网通集群
电信集群
图 11-1跨运营商的 Puppet 架构部署示意图
Puppet
Puppet
—--------
Puppet Master
Puppet Master
Puppet Master
Puppet Master
----
一
一
with hostname
with hostname
 ctc groups
 cnc groups
Puppet Agent
Puppet Agent
Puppet Agent
Puppet Agent
1
---
## Page 59
查找不到客户端，无法实现客户端的管理。因此我们需要将这些都在系统安装时进行集成。
众所周知，要使用 Puppet 必须先安装客户端程序、配置好主机名、完成认证，否则服务端将
官方网站：https://fedorahosted.org/cobbler/。
络安装环境的Linux 安装服务器，可以为数量众多的Linux 服务自动化执行任务。Cobbler 的
DHCP、DNS 和Kickstart 服务管理，以及 yum 仓库管理。Cobbler 的目的是为了实现快速网
11.3.1
11.3
节点的全局定义。在配置变量时可以区别运营商，因此可以采用正则匹配相同运营商的主机。
的主机名解析到网通管理机，将电信的主机名解析到电信管理机。主机名采用如下规范：
11.2.5节点管理分析
影响所有配置文件，也方便系统管理员排查。
样规范的好处就是将主配置文件与虚拟主机文件分开，并且一个虚拟主机配置文件错误不会
nginx.conf追加 server 的方式进行配置。笔者推荐采用 include 虚拟主机的方式进行管理，这
源与 cron 资源创建定时任务。虚拟主机的配置可以采用目录的方式进行推送，也可以采用
板中的配置。由于需要对日志进行切割处理，所以需要利用 File 资
利用 Cobbler 可以进行操作系统定制化，将 Puppet Agent 软件包集成在操作系统当中。
服务器操作系统的安装可以利用 Cobbler 进行。Cobbler 是一个集成工具，集成了 PXE、
详情可参考第 8 章。
 考虑到服务器数量比较多，所有主机名统一采用 DNS 进行管理。划分两个view 将网通
mkdir /etc/puppet/manifests/nodes/{cnc,ctc}
节点管理所有主机名时分两个节点目录：
例如：
运营商简称．地区·角色·服务名．IP地址·域名
口采用 Puppetlabs 上提供的开源模块，该模块采用 default 的方式实现虚拟主机的管理。
编写模块可采用在 nginx.conf中包含虚拟主机目录的方式进行虚拟主机管理，对File
我们将讲解如何通过编写模块和使用开源模块两种方法实现Nginx 软件部署需求。
ctc.gz.web.nginx.ip.domain.com
cnc.tj.web.nginx.ip.domain.com
资源同步目录进行更新。每次更新时采用 notify 触发 exec 资源执行 reload 动作。
系统安装
合理规划
第11章大规模Nginx集群部署方案·181
---
## Page 60
182第三部分实战篇
图 11-2 所示的规划。
所有的客户端情况，需要配置报告系统。Puppet 服务器的目录按编写 nginx 模块的形式进行
MCollective，详见第 20 章。为避免执行kick 时全网资源全部更新，需要配置标签。要掌握
认证，需要配置自动认证，
为如下几大类。
样做的目的有多个，而更多的是出于便捷性管理、安全等角度的考虑。系统初始化可以归类
11.3.3
11.3.2
上正在运行的命令运行相关的软件或工具来实现。
以通过 Python 组合 expect 完成主机名配置和 Puppet 客户端的安装，或者使用最熟悉的、
来完成。
行 puppet agent 命令完成认证。
制化程序通过后台 API 获取该主机信息，进行主机名配置及 Puppet 客户端程序安装。最后运
配置好该服务器的角色、SN 号、主机名等信息。当服务器使用Cobbler 安装完并启动时，定
结合所有的需求，经过深入的分析，需要对 Puppet 的部署进行合理规划。为解决快速
当服务器操作系统安装完成后，要想使用系统提供的服务还需要进行系统的初始化。这
如果并没有实现 Cobbler 和系统定制化，却想要将现有的服务器加入 Puppet 管理时，可
这时一台服务器就已经加入到我们的管理队列当中。剩下的所有事件都可以交给 Puppet
这些我们可以直接使用官方 Forge 提供的模块 erwbgy-system 和 puppetlabs-frewall 来实现。
口登录配置：sshd。
口安全配置：iptables。
口用户管理：user、group。
口系统配置：ntp、
部署规划
系统初始化
tagmail.conf
puppet.conf
fileserver.conf
autosign.conf
auth.conf
limits、sysconfig、sysctl.
，当有紧急更新时需要使用kick 命令，在 Puppet 3.x 中建议采用
图 11-2Puppet Master 目录结构规划图
vhost.b.conf
vhost.a.conf
files/nginx/vhost
1
1
/etc/puppet
manifests
 site.pp
nodes.pp
templates
manifests
nginx.conf.erb
modules/nginx
init.pp
---
## Page 61
如下：
装，再采用 createrepo 创建软件仓库。这样能有效解决软件包依赖的问题。详细配置过程
downloadonly软件（downloadonly为Yum 的插件，默认不安装）只下载软件包，并不安
建议搭建自己的软件仓库。我们安装的Nginx 来源于官网或 epel源，因此可以使用 yum
每个虚拟主机一个配置文件模式，或者使用官方 nginx 模块进行 Nginx 安装与配置。
在进行 Puppet Master 主配置时配置自动认证、权限等，最后创建 nginx 模块，虚拟主机采用
始。我们将配置自己的软件仓库进行软件管理，并采用 yumrepo 资源指定到自己的软件源。
11.4
决定采用 Puppet Master 部署的数量。
11.4.1
赖于服务器硬件配置及资源依赖等多方面因素。我们可以以此为参照，根据实际环境需求来
Master服务器在采用Web 替代 WEBRick 的情况下将支持500 台左右的客户端。当然这也依
11.3.4关注点
目的是便于统一管理。读者可以根据自己的特征选择自己的统一管理模式。
搭建自己的软件仓库，进行软件包自定义、升级、控制等。当服务器具有一定规模时
本节都以Centos5.464bit 为例进行讲解。
在完成整体规划后，就可以按规划的方案来实施了。实施主要从前期准备搭建环境开
如果按照官方语言风格及笔者的建议编写模块，或采用官方提供的模块，则单台 Puppet
我们再来思考一下系统管理员小明还有哪些关注点，或者说需要思考哪些问题:
 nginx 模块的虚拟主机文件也可以统一放在 modules/nginx/files 中。使用统一文件目录的
利用 Puppet environment 多环境配置，实现灰度发布（参考第 4章）。
触发客户端更新时，采用分组分批次进行，避免 Puppet Master 压力过大而崩溃。
通过 Puppet 控制台进行性能分析，优化 Puppet 资源（参考第6章)。
采用分布式架构(参考第15章)。
部署 Puppet控制台，用于查看客户端部署情况(参考第18 章)。
相关问题对应的策略为：
如何实现灰度发布？
服务部署情况，及是否部署成功？
紧急触发客户端更新时，
系统性能的瓶颈有哪些？
单个Master支持多少客户端请求？什么时候需要扩容？
系统是否支持扩展？
前期准备：创建软件仓库
实施步骤
，服务端是否能支撑？
第11章大规模Nginx集群部署方案·183
---
## Page 62
234·第四部分进阶篇
8140 端口并处理客户端请求、file 文件以及已验证的客户端请求；将编译部分代理转发到后
Puppet 原生态的 WEBRick 以提升 Mater 吞吐性能。在管理机上启动 WebServer 以负责监听
要讲的就是单台 Puppet Master 的扩展。采用最常用的 Web 服务器 Apache 或 Nginx 来代替
15.2
及效率。
及丢包。选择最好的节点进行 Master 部署，以保证连接至该 Master 节点的可靠性、稳定性
的事情啊。为避免这种情况，我们需要在各大运营端节点部署 Puppet Master，以保证效率。
又一个环节，扩容了一切能扩容的，最终会发现因为网络瓶颈而无法完成部署，这是多么可悲
这话一点也不为过。我们每天都在努力奋斗，处理着各种网络带来的问题。当我们优化了一个
15.1.4网路的瓶颈
在 File 资源上。为此在第 16 章将重点讲解 File 资源的优化。
而导致处理时间过长，影响效率。据笔者观察，很多Puppet 环境中 60%左右的效率都消耗
的 File 资源外，还有 ERB 模板文件，也有目录同步等，因此会造成 Puppet Master 瓶颈，进
15.1.3文件的瓶颈
案可以实现：
大时，Puppet CA 也会成为瓶颈，但 Puppet CA 的负载总体不如 Master大，扩展时有两种方
会到 Puppet Master 上验证一次该客户端是否已授权，否则将会拒绝该请求。当服务器规模较
15.1.2认证的瓶颈
当做 Puppet Master 完成近千台 Hadoop 集群的管理。
依赖于服务器的硬件配置、资源的类型和数量、文件资源的数量。目前也有人拿一台虚拟机
容。在通常情况下，单台 Puppet Master 在使用 WEBRick 启用时能支持百台规模。当然这也
CPU 与内存的消耗。我们可以通过判定 Puppet Master 编译清单时长来决定是否需要进行扩
 Puppet Master 架构扩展可以从单台扩展、集群架构、分布式三个方面进行。我们首先
而在选择部署 Master 节点时，可以采用开源的 smokeping 来采集各节点之间的网络延迟
中国的网络可以说是全世界最复杂的，“搞定了中国网络，就等于征服了全世界的网络”,
 Puppet 只是配置管理工具，有些读者会使用 Puppet下发大量文件，除了应用软件配置
每台 Master 都接受CA 请求，实时同步证书目录，并指定某台机器作为颁发证书服务器。
Puppet 管理所有客户端都是采用颁发证书的方式进行的，并且每次客户端发起请求时都
两种方法各有优缺点，但都能完成扩展需求。
独立CA 服务器，只处理CA请求，采用另一台机器进行CA 热备。
架构扩展之单台Puppet Master
---
## Page 63
支持 SSL，具体如下：
可以继续使用 Nginx 作为前端，
模式，以实现更高的并发与处理能力。值得注意的是，Puppet 3.0已取消 Mongrel，但我们仍
优于 Apahce。Mongrel可以启用多个Master 实例，解决 WEBRick 只需使用一个进程多线程
15.2.1 Nginx+Mongrel模式
简要说明其安装、配置过程。
扩展架构单台可以承载大概500个节点。
个 Master 实例。Mongrel与 Passenger有着一定的差异，但 Mongrel 将会被淘汰。采用 Web 
我们将以 Puppet 2.7 Centos 5.4 X86_64 为例讲解此模式的安装、配置过程。
 推荐使用 Nginx 的理由是它比 Apahce 并发能力更强、处理文件效率更高、转发请求也
S
$ cd /usr/local/src
采用源码包安装 Nginx。从 Nginx 官网（http://nginx.org/）下载Nginx 源码包并手动编译
$ sudo yum -y install ruby-develpcre pcre-devel openssl zlib nginx
安装 Nginx 的方法如下：
1）安装 Nginx 和 Mongrel。
如上三种扩展模式的架构示意如图 15-1所示。
Nginx+Passenger
 Apache+Passenger
UF
 Nginx+Mongrel
目前比较流行的 Web 代码组合模式有：
cd nginx-1.3.11
wget http://nginx.org/download/nginx-1.3.11.tar.gz
….
Agent2
Agent1
图15-1Puppet 单台扩展WebServer 的代理架构示意
https
，详情请参考15.2.3节。为照顾还在使用老版本的读者，这里
8140
http
第15章Puppet 架构扩展与分布式·235
Master+CA
Master+CA
Master+CA
---
## Page 64
236·第四部分进阶
SUBJECT"
Mongrel 模式：