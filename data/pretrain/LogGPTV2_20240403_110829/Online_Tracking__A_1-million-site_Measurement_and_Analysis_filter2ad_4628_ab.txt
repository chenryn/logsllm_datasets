to provide statistical conﬁdence of their targeting inferences 
[28]. 
Many  other  practices  that  raise  privacy  or  ethical  con­
cerns  have  been  studied:  price  discrimination,  where  a  site 
shows  diﬀerent  prices  to  diﬀerent  consumers  for  the  same 
product [19, 63]; steering, a gentler form of price discrimina­
tion where a product search shows diﬀerently-priced results 
for  diﬀerent  users  [32];  and  the  ﬁlter  bubble,  the  supposed 
eﬀect  that  occurs  when  online  information  systems  person­
alize what is shown to a user based on what the user viewed 
in the past [65]. 
Web  security  measurement.  Web security studies  of­
ten  use  similar  methods  as  web  privacy  measurement,  and 
the  boundary  is  not  always  clear.  Yue  and  Wang  modiﬁed 
the Firefox browser source code in order to perform a mea­
surement of insecure Javascript implementations on the web 
[67].  Headless browsers have been used in many web security 
measurements, for example:  to measure the amount of third-
party  Javascript  inclusions  across  many  popular  sites  and 
the  vulnerabilities  that  arise  from  how  the  script  is  embed­
ded [40], to measure the presence of security seals on the top 
1 million sites [62], and to study stand-alone password gener­
ators and meters on the web [60].  Several studies have used 
Selenium-based frameworks, including:  to measure and cat­
egorize  malicious  advertisements  displayed  while  browsing 
popular  sites  [68],  to  measure  the  presence  of  malware  and 
other vulnerabilities on live streaming websites [46], to study 
HSTS deployment [21], to measure ad-injecting browser ex­
tensions  [66],  and  to  emulate  users  browsing  malicious  web 
shells  with  the  goal  of  detecting  client-side  homephoning 
[55].  Other  studies  have  analyzed  Flash  and  Javascript  el­
ements  of  webpages  to  measure  security  vulnerabilities  and 
error-prone implementations [42, 61]. 
3.  MEASUREMENT PLATFORM 
An  infrastructure  for  automated  web  privacy  measure­
ment has three components:  simulating users, recording ob­
servations  (response  metadata,  cookies,  behavior  of  scripts, 
etc.),  and  analysis.  We  set  out  to  build  a  platform  that 
can  automate  the  ﬁrst  two  components  and  can  ease  the 
researcher’s  analysis  task.  We  sought  to  make  OpenWPM 
Figure 1:  High-level overview of OpenWPM 
The  task  manager  monitors  browser  managers,  which  con­
vert  high-level  commands  into  automated  browser  actions. 
The  data  aggregator  receives  and  pre-processes  data  from 
instrumentation. 
general, modular, and scalable enough to support essentially 
any privacy measurement. 
OpenWPM  is  open  source  and  has  already  been  used  for 
measurement  by  several  published  studies.  Section  3.4  in 
the supplementary materials examines the advanced features 
used  by  each  study.  In  this  paper  we  present,  for  the  ﬁrst 
time, the design and evaluation of the platform and highlight 
its strengths through several new measurements. 
3.1  Design Motivations 
OpenWPM builds on similar technologies as many previ­
ous platforms, but has several key design diﬀerences to sup­
ports  modular,  comprehensive,  and  maintainable  measure­
ment.  Our  platform  supports  stateful  measurements  while 
FPDetective  [2]  does  not.  Stateful  measurements  are  im­
portant  for  studying  the  tracking  ecosystem.  Ad  auctions 
may vary based on cookie data.  A stateless browser always 
appears to be a new user, which skews cookie syncing mea­
surements.  In  addition  to  cookie  syncing  studied  in  this 
paper,  stateful  measurements  have  allowed  our  platform  to 
be used to study cookie respawning [1] and replicate realistic 
user proﬁles [14]. 
Many past platforms rely on native instrumentation code 
[39, 52, 2], which have a high maintenance cost and, in some 
cases  a  high  cost-per-API  monitored.  In  our  platform,  the 
cost  of  monitoring  new  APIs  is  minimal  (Section  3.3)  and 
APIs  can  be  enabled  or  disabled  in  the  add-on  without  re­
compiling the browser or rendering engine.  This allows us to 
monitor  a larger number of APIs.  Native  codebase changes 
in other platforms require constant merges as the upstream 
codebase  evolves  and  complete  rewrites  to  support  alterna­
tive browsers. 
3.2  Design and Implementation 
We  divided  our  browser  automation  and  data  collection 
infrastructure  into  three  main  modules:  browser  managers 
which act as an abstraction layer for automating individual 
browser  instances,  a  user-facing  task  manager  which  serves 
to  distribute  commands  to  browser  managers,  and  a  data 
aggregator, which acts as an abstraction layer for browser in­
strumentation.  The researcher interacts with the task man­
ager  via  an  extensible,  high-level,  domain-speciﬁc  language 
for crawling and controlling the browser instance.  The entire 
platform is built using Python and Python libraries. 
TaskManagerDataAggregatorWWWSeleniumBrowserManagerBrowser...BrowserManagerBrowserBrowserManagerBrowserInstrumentation LayerAnalysisScriptsSeleniumSeleniumBrowser driver:  Providing realism and support for 
web  technologies.  We considered a variety of  choices  to 
drive measurements, i.e., to instruct the browser to visit a set 
of pages (and possibly to perform a set of actions on each). 
The two main categories to choose from are lightweight browsers 
like  PhantomJS  (an  implementation  of  WebKit),  and  full-
ﬂedged  browsers  like  Firefox  and  Chrome.  We  chose  to  use 
Selenium,  a  cross-platform  web  driver  for  Firefox,  Chrome, 
Internet  Explorer,  and  PhantomJS.  We  currently  use  Sele­
nium  to  drive  Firefox,  but  Selenium’s  support  for  multiple 
browsers makes it easy to transition to others in the future. 
By using a consumer browser, all technologies that a typ­
ical  user  would  have  access  to  (e.g.,  HTML5  storage  op­
tions, Adobe Flash) are also supported by measurement in­
stances.  The alternative, PhantomJS, does not support We­
bGL, HTML5 Audio and Video, CSS 3-D, and browser plu­
gins (like Flash), making it impossible to run measurements 
on the use of these technologies [45]. 
In retrospect this has proved to be a sound choice.  With­
out full support for new web technologies we would not have 
been  able  to  discover  and  measure  the  use  of  the  Audio-
Context  API  for  device  ﬁngerprinting  as  discussed  in  Sec­
tion 6.4. 
Finally  the  use  of  real  browsers  also  allows  us  to  test  the 
eﬀects  of  consumer  browser  extensions.  We  support  run­
ning  measurements  with  extensions  such  as  Ghostery  and 
HTTPS Everywhere as well as enabling Firefox privacy set­
tings such third-party cookie blocking and the new Tracking 
Protection feature.  New extensions can easily be supported 
with  only  a  few  extra  lines  of  code  (Section  3.3).  See  Sec­
tion  5.3  and  Section  5.5  for  analyses  of  measurements  run 
with these browser settings. 
Browser  managers:  Providing  stability.  During  the 
course  of  a  long  measurement,  a  variety  of  unpredictable 
events  such  as  page  timeouts  or  browser  crashes  could  halt 
the measurement’s progress or cause data loss or corruption. 
A  key  disadvantage  of  Selenium  is  that  it  frequently  hangs 
indeﬁnitely due to its blocking API [50], as it was designed to 
be a tool for webmasters to test their own sites rather than 
an  engine  for  large-scale  measurements.  Browser  managers 
provide  an  abstraction  layer  around  Selenium,  isolating  it 
from the rest of the components. 
Each  browser  manager  instantiates  a  Selenium  instance 
with  a  speciﬁed  conﬁguration  of  preferences,  such  as  block­
ing third-party cookies.  It is responsible for converting high-
level  platform  commands  (e.g.  visiting  a  site)  into  speciﬁc 
Selenium subroutines.  It encapsulates per-browser state, en­
abling  recovery  from  browser  failures.  To  isolate  failures, 
each browser manager runs as a separate process. 
We support launching measurement instances in a “head­
less” container,  by  using  the  pyvirtualdisplay  library  to  in­
terface with Xvfb, which draws the graphical interface of the 
browser to a virtual frame buﬀer. 
Task  manager:  Providing  scalability  and  abstrac­
tion.  The task manager provides a scriptable command-line 
interface  for  controlling  multiple  browsers  simultaneously. 
Commands  can  be  distributed  to  browsers  either  synchro­
nized  or  ﬁrst-come-ﬁrst-serve.  Each  command  is  launched 
in a per-browser command execution thread. 
The command-execution  thread handles  errors in  its  cor­
responding  browser  manager  automatically.  If  the  browser 
manager  crashes,  times  out,  or  exceeds  memory  limits,  the 
thread  enters  a  crash  recovery  routine.  In  this  routine,  the 
manager archives the current browser proﬁle, kills all current 
processes, and loads the archive (which includes cookies and 
history) into a fresh browser with the same conﬁguration. 
Data Aggregator:  Providing repeatability.  Repeata­
bility can be achieved logging data in a standardized format, 
so research groups can easily share scripts and data.  We ag­
gregate data from all instrumentation components in a cen­
tral  and  structured  location.  The  data  aggregator  receives 
data  during  the  measurement,  manipulates  it  as  necessary, 
and  saves  it  on  disk  keyed  back  to  a  speciﬁc  page  visit  and 
browser.  The  aggregator  exists  within  its  own  process,  and 
is  accessed  through  a  socket  interface  which  can  easily  be 
connected  to  from  any  number  of  browser  managers  or  in­
strumentation processes. 
We currently support two data aggregators:  a structured 
SQLite  aggregator  for  storing  relational  data  and  a  Lev­
elDB  aggregator  for  storing  compressed  web  content.  The 
SQLite  aggregator  stores  the  majority  of  the  measurement 
data,  including  data  from  both  the  proxy  and  the  exten­
sion (described below).  The LevelDB aggregator is designed 
to  store  de-duplicated  web  content,  such  as  Javascript  or 
HTML ﬁles.  The aggregator checks if a hash of the content 
is present in the database, and if not compresses the content 
and adds it to the database. 
Instrumentation:  Supporting  comprehensive  and 
reusable  measurement.  We  provide  the  researcher  with 
data access at several points:  (1) raw data on disk, (2) at the 
network level with an HTTP proxy, and (3) at the Javascript 
level with a Firefox extension.  This provides nearly full cov­
erage  of  a  browser’s  interaction  with  the  web  and  the  sys­
tem.  Each  level  of  instrumentation  keys  data  with  the  top 
level  site  being  visited  and  the  current  browser  id,  making 
it  possible  to  combine  measurement  data  from  multiple  in­
strumentation sources for each page visit. 
Disk  Access  —  We  include  instrumentation  that  collects 
changes to Flash LSOs and the Firefox cookie database after 
each page visit.  This allows a researcher to determine which 
domains  are  setting  Flash  cookies,  and  to  record  access  to 
cookies in the absence of other instrumentation 
HTTP  Data  —  After  examining  several  Python  HTTP 
proxies, we chose to use Mitmproxy6  to record all HTTP Re­
quest and Response headers.  We generate and load a certiﬁ­
cate into Firefox to capture HTTPS data alongside HTTP. 
Additionally,  we  use  the  HTTP  proxy  to  dump  the  con­
tent of any Javascript ﬁle requested during a page visit.  We 
use both Content-Type and ﬁle extension checking to detect 
scripts in the proxy.  Once detected, a script is decompressed 
(if necessary) and hashed.  The hash and content are sent to 
the LevelDBAggregator for de-duplication. 
Javascript  Access  —  We  provide  the  researcher  with  a 
Javascript  interface  to  pages  visited  through  a  Firefox  ex­
tension.  Our extension expands on the work of Fourthparty 
[33].  In  particular,  we  utilize  Fourthparty’s  Javascript  in­
strumentation,  which  deﬁnes  custom  getters  and  setters  on 
the  window.navigator  and  window.screen  interfaces7 .  We 
updated and extended this functionality to record access to 
the  prototypes  of  the  Storage,  HTMLCanvasElement,  Can­
vasRenderingContext2D,  RTCPeerConntection,  AudioCon­
text  objects,  as  well  as  the  prototypes  of  several  children 
6https://mitmproxy.org/
7In  the  latest  public  version  of  Fourthparty  (May  2015),
this instrumentation is not functional due to API changes.
of  AudioNode.  This  records  the  setting  and  getting  of  all 
object properties and calls of all object methods for any ob­
ject  built  from  these  prototypes.  Alongside  this,  we  record 
the new property values set and the arguments to all method 
calls.  Everything is logged directly to the SQLite aggregator 
In  addition  to  recording  access  to  instrumented  objects, 
we  record  the  URL  of  the  script  responsible  for  the  prop­
erty  or  method  access.  To  do  so,  we  throw  an  Error  and 
parse  the  stack  trace  after  each  call  or  property  intercept. 
This  method  is  successful  for  99.9%  of  Javascript  ﬁles  we 
encountered, and even works for Javascript ﬁles which have 
been miniﬁed or obfuscated with eval.  A minor limitation is 
that the function calls of a script which gets passed into the 
eval method of a second script will have their URL labeled 
as  the  second  script.  This  method  is  adapted  with  minor 
modiﬁcations from the Privacy Badger Firefox Extension8 . 
In  an  adversarial  situation,  a  script  could  disable  our  in­
strumentation before ﬁngerprinting a user by overriding ac­
cess  to  getters  and  setters  for  each  instrumented  object. 
However,  this  would  be  detectable  since  we  would  observe 
access to the define{G,S}etter or lookup{G,S}etter meth­
ods  for  the  object  in  question  and  could  investigate  the 
cause.  In  our  1  million  site  measurement,  we  only  observe 
script access to getters or setters for HTMLCanvasElement and 
CanvasRenderingContext2D  interfaces.  All  of  these  are  be­
nign accesses from 47 scripts total, with the majority related 
to an HTML canvas graphics library. 
Example  workﬂow. 
1.	 The  researcher  issues  a  command  to  the  task  manager 
and speciﬁes that it should synchronously execute on all 
browser managers. 
2.	 The  task  manager  checks  all  of  the  command  execution 
threads and blocks until all browsers are available to ex­
ecute a new command. 