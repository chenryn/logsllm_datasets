节省时间
的门槛。
支持的服务，这些服务就不能长久运行，因为它们很久之前就超越了人工操作所能管理
定义的原因。）Google拥有大量的自动化系统；在很多情况下，没有自动化参与我们所
时自动化程序可以最终使一个坏的情况变得更糟，但是这恰恰是将这种程序的范围明确
人间歇性地手动按一个叫“允许系统继续运行”的按钮是没有任何意义的。（确实，有
例如，故障转移或流量调整对于一个特定的应用程序来说可以被很好地定义，要求一个
在基础设施中，SRE自动化系统应用广泛。这是因为人类通常不能像机器一样快速反应
行动速度更快
可观看XKCD动画：http://xkcd.com/1205/。
第7章
世界。”
眼泪养活机器。这就像是一个没有特效但是充满了愤怒的系统管理员的Matrix
系统维护。如果我们要雇佣人来做这项工作，就像是在用人类的鲜血、汗水和
“如果我们持续产生不可自动化的流程和解决方案，我们就继续需要人来进行
JosephBironas，负责Google数据中心集群上线流程的SRE，有力地提出：
Google的自动化系统的演进
---
## Page 105
在推送之后消失一半的情况，因此我们会针对这种粗粒度的差异报警。但对于SRE而言，
施的数据的质量。这条分界线并不是完全清晰的一—例如，我们会非常关注某个数据集
然而，在Google SRE内部，我们主要负责运维基础设施，而不是管理那些穿过基础设
在Google内部，上述所有使用案例都有，甚至更多。
GoogleSRE的自动化使用案例
这个列表基本上可以无限扩展。
正如我们之前暗示的，自动化有许多用例。下面是一个非详尽的例子列表：
观点中，自动化是“元软件”，也就是操作其他软件的软件。
管写这些代码的动机以及最终产生的解决方案本身往往区别很大。更广泛地说，在这一
在运维行业中，自动化这个术语一般用来指代通过编写代码来解决各种各样的问题。尽
自动化的应用案例
位置上。我们认为这个以平台为基础的方法对于可管理性和可扩展性是非常有必要的。
在可能的情况下都选择了创建平台，或者是将我们自己“定位”在未来可以创建平台的
也是我们在Google的范围内付诸行动取得了广泛的成功的一种观点。一般来说，我们
为了长久运行，也不是为自动化而设计的。前面一段阐述了对我们的观点的最大化情况
向于在一个特定的时间开发自动化系统。我们的一些基本系统由快速原型开始，并不是
变通。将每个系统的每一个组件都自动化是不合适的，同时不是所有人都有能力或者倾
当然，尽管Google在思想上倾向于尽可能使用机器管理机器，但实际情况需要一定的
味着我们的使命“在生产环境中拥有产品”要更加容易，因为我们控制了全部的技术栈。
（参见文献[Pot16]），几乎所有SRE接触的系统的源代码都是多多少少可用的。这也意
障碍，随后坚决地进行了自动化系统管理本身的开发。鉴于Google管理其源代码的方式
为这样可以产生具有长期价值的API。我们花了很多时间来克服自动化系统管理的各种
己的API。虽然购买某一特定任务的软件会更便宜，但我们仍倾向于选择自主开发，因
Google通常可以避免这些情况发生。Google为那些供应商没有提供API的系统构建了自
·创建用户账户。
一种特殊情况的运行时配置更改：依赖关系的更改。
运行时配置的更改。
新软件版本的发布。
软件或硬件安装的准备和退役过程。
某个服务在某个集群中的上线和下线过程。
自动化的应用案例
71
---
## Page 106
64
注5当然，不是每个需要管理的系统都提供了可调用管理API—
最终是在核心系统之外维护的，因此经常受到“代码腐烂”（bitrot）的影响。也就是说
这里提供了一个更详细的例子，Google的集群上线系统自动化经常出现问题，因为这些
更高（尽管这样的效率提升很有价值），而是因为设计中将胶合逻辑排除在外了。这样
胶合逻辑的系统要比有一个依赖外部的胶合逻辑的系统更好，不仅仅是因为内部化效率
自动化分类的层次结构
署的语言。后者往往比前者更加通用，更符合通用平台。然而，我们生产环境的复杂性
对高层次实体建模的通用部署工具，另外一些则类似于在非常抽象的层次上描述服务部
SRE在自动化领域有一系列设计哲学和产品，它们中的一些类似于一种不会特别详细地
都不会这样做。
拟这些结果，大部分模型都会中止并要求人工干预。而那些真正糟糕的自动化系统甚至
或者推送了但是没有启动，或者启动了但是无法验证。没有几个抽象模型能够成功地模
使系统进入不一致的状态；视具体情况不同，新的二进制文件可能安装了，但没有推送
集群网络中途可能会发生故障；物理机可能发生故障；与集群管理层的通信可能会失败
的；该集群最终会全部变成新版本，或者全部维持旧版本。然而，现实中的行为很复杂
一致地出现故障。例如，我们经常假设，将一个新的二进制文件发布到集群中是原子性
理和进行逻辑推理，但当你遇到一个“有漏洞的抽象”时，就会系统地、重复地甚至不
作可以直接操作服务或者其他高级对象。这里的妥协十分经典：高层次的抽象更容易管
供了POSIX级别的接口，理论上在系统API层面上提供了一个基本上是无限的扩展范
方法，主要区别在于对帮助进行自动化的组件的抽象层次不同。Perl这种完整的语言提
广泛使用的工具有Puppet、Chef、cfengine，甚至Perl都提供了自动化完成特定任务的
管理自动化，同时关注的重点不同（我们接下来将会对此进行讨论）。
即使如此，SRE的自动化努力也与其他组织所做的差距并不大。SRE使用不同的工具来
自动化管理系统的生命周期，而非系统内部的数据：例如，部署新的群集服务。
具体修改系统中一些账户的某个子集的属性是相当罕见的。因此，自动化的情境通常是
系统集群上线一
做需要将胶合逻辑的具体用例一
虽然所有这些自动化步骤都是有价值的，
有时意味着前者是更容易采用的选择。
行CLI，或者执行自动化的网站单击。
第7章
Google的自动化系统的演进
一用某种方法在应用程序中直接处理。
一一般来说是对系统的直接操作，例如添加账户或执行
，同时自动化平台本身也是很有价值的。在一个
一这要求我们必须采用某种工具，例如执
---
## Page 107
流程中消除。
下面让我们使用内部案例研究来详细描述上文提到的这些要点。第一个案例研究的是如
前，对一个变更很小或者通过基本的重启+检查就可以完成的流程进行人工监督是毫无
存在一比如，对上游的Chubby服务器的变更，使访问更可靠的一个Bigtable客户端
域的变更。在Google这种高度集中的专有生产环境下，有大量的跨特定服务范围的变更
同时，相对于在特定系统相关配置上变更的自动化，另外一种自动化是面向整个生产领
避免的。
SRE讨厌手动操作，所以我们尽力创造不需要他们的系统。然而，有时手动操作是不可
5）不需要任何自动化的系统
4）
3）外部维护的通用的自动化系统
2）外部维护的系统特定的自动化系统
意义的。
库的功能开关的变更等一—这些变更也需要安全地管理，在必要的情况下进行回退。当
1）没有自动化
甚至更长时间才发生一次，导致每次执行都不一致。
因为反馈的周期很长。集群故障转移自动化是一个经典例子：故障转移可能每隔几个月
署的要求。其次，关键性的，但是不经常执行的，以至于很难测试的自动化系统尤其脆弱，
失败。产品的研发人员会一
系统和核心系统）更紧密地连接起来的努力常常会由于两个团队不一致的优先级定义而
当基本系统变化的时候，
数据库注意到问题发生，在无须人工干预的情况下进行故障转移。
内部维护的系统特定的自动化
数据库自己发布故障转移脚本。
SRE将数据库支持添加到了每个人都在使用的“通用故障转移”脚本中。
SRE 在他或她的主目录中保存了一份故障转移脚本。
手动将数据库主进程在多个位置之间转移。
，上线自动化系统没有随之改变。尝试将两者（集群上线自动化
—不能说不合理的——抵制对每一次改动都进行一次测试部
自动化的演进遵循以下路径：
自动化的应用案例
65
---
## Page 108
66
动化进行快速恢复的模式。
施以避免进行故障转移的模式转化为拥抱失败，承认故障是不可避免的，并因此通过自
随着决策者的诞生，MySQLOnBorg（MOB）最终变成了现实。我们从不断优化基础设
95%的时间内用小于30s的时间完成计划内和计划外的MySQL数据库故障转移流程。
2009年，广告SRE完成了自动故障切换后台程序，称为“决策者”。决策者程序可以在
流程。
因此，
故障转移。这一因素，加上系统中分片数量庞大的因素，意味着：
需要进行内核升级而重启，我们每周都需要在正常的物理机故障率之外进行一些无关的
部运行的任务，通常的移动频率达到了每周一次或两次。这样的频率对数据库的副本来
个严重的新增困难。Borg的一个核心操作特点就是它的任务可以自动地移动：Borg内
2008年年底，我们成功地在Borg上部署了一个原型实例。然而不幸的是，这带来了一
我们希望这种迁移会带来两点主要益处：
“低挂的果实”。然而，随着日常工作变得越来越容易，SRE团队成员开始考虑下一级的
动化。我们认为广告数据库已经管理得很好了，已经摘到了优化和规模方面的大部分的
年，我们认为广告数据库基本是在一种成熟的和可管理的状态下运行的。例如，我们已
数据显然需要很高的可靠性，一个SRE团队负责管理那些基础设施。从2005年到2008
很长一段时间以来，Google的广告产品将数据存储于一个MySQL数据库中。因为广告
让自己脱离工作：自动化所有的东西
当时，主实例故障转移过程每次需要30~90分钟。由于我们在共享的机器上运行，同时
说是可以接受的，对于主实例则不可接受。
·手动故障转移将消耗大量的人力时间，并且在最好条件下也只能给我们99%的
·彻底消除对物理机／数据库副本的维护：Borg会自动安装新任务，或者重启出问
我们唯一的选择是自动进行故障转移。实际上，我们不仅仅需要自动化故障转移
流程达到这一目标是不可能的。
资源。
将多个MySQL实例安装在同一台物理机上：利用容器化可以更好地利用计算机
为了满足错误预算，每个故障转移的停机时间要小于30s。优化依赖人为操作的
可用性，这样比产品的实际业务需要低很多。
题的任务。
第7章Google的自动化系统的演进
---
## Page 109
算子系统当时正在全力开发中，所以每周都会增加新的功能开关、组件和优化。
第4步和第6步是极为复杂的。虽然基本的服务，如DNS是相对简单的，但存储和计<76
为使一个集群达到可用状态所需采取的步骤如下：
息，这个任务似乎是一个自然的和有效的培训工具。
集群上线的频率相同。因为在新集群中启动新的服务能够让新员工接触到服务内部的信
十年前，集群基础设施SRE团队似乎每隔几个月都要雇用新人。事实上，大约与我们新
舒缓疼痛：将自动化应用到集群上线中
一个例子来自于集群基础设施组，描述了一些进行全自动化时可能遇到的更困难的权衡。
该例子描述了通过额外努力构建一个平台，而不是仅仅取代现有的手动流程的好处。下
解放了近60%的硬件资源，团队的硬件资源和工程资源都非常充足。
在同样的机器上运行多个MySQL实例，从而提高了硬件利用率。总的看来，我们最终
在硬件资源方面也有了改进。迁移到MoB的过程中释放了大量的资源，因为我们可以
了近95%。有人可能会说，我们已经成功地自动将自己从这项工作中自动化出来了。同时，
最终，我们能够将数据库结构的变更也自动化了，这导致广告数据库的总运维成本下降
这些改进有一个连锁效应：节省的时间越多，优化和自动化其他烦琐工作的时间就越多
这一新的自动化的主要好处是，我们有更多的空闲时间花在改进基础设施的其他部分上
所以单个数据库任务中断不再给任何人发出紧急报警。
我们的团队在无聊的运维任务上花费的时间下降了95%。整个故障转移过程是自动化的，
而，与决策者一起迁移到MoB上的益处对这些成本来说是很值得的。迁移到MoB之后，
种改变意味着我们要定制类似JDBC这样的软件，以便对我们的故障环境更加宽容。然
由于MySQL开发世界中的常态是假设MySQL实例是整个技术栈中最稳定的成分，这
用，但是这也带来了它自己的一套成本，所有的应用程序都必须增加很多错误处理逻辑。
虽然通过自动化，我们可以在一个每周强制两次重启的世界里仍然保证MySQL的高可