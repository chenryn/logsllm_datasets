### Proceedings of the International Conference on Dependable Systems and Networks (DSN’02)
**0-7695-1597-5/02 $17.00 © 2002 IEEE**
**Authorized licensed use limited to: Tsinghua University. Downloaded on March 19, 2021 at 04:10:11 UTC from IEEE Xplore. Restrictions apply.**

### Curiosity Propagation
Curiosity propagates upstream as follows: A tick becomes anti-curious (A) only if all downstream streams propagate A to it. The A tick can then be propagated up to the predecessor node (if a filter) or to all predecessor nodes (if a merge). A C tick propagates to the predecessor node of a filter edge. It propagates to those predecessors of a merge edge that have Q ticks.

### 3. Algorithm and Implementation
In this section, we describe the Guaranteed Delivery (GD) protocol as implemented in Gryphon. The GD protocol follows the abstract model outlined in the previous section and is used in the studies presented in the next section. The model is simplified by eliminating merges, resulting in a knowledge graph that is a forest consisting of spanning trees, each rooted at one of the pubends.

#### Virtual Brokers and Physical Topology
Virtual brokers are mapped onto collections of broker machines called cells. Virtual brokers that host pubends (pubend hosting brokers or PHBs) and subend hosting brokers (SHBs) each map to a cell consisting of a single physical broker machine. Intermediate virtual brokers may map to a cell consisting of multiple physical brokers. For example, Figure 3 shows the virtual and physical topology for the failure injection tests in Section 4, which includes a single PHB, two intermediate virtual brokers, and five SHBs. Intermediate virtual brokers IB1 and IB2 correspond to cells containing the physical broker pairs b1-b2 and b3-b4, respectively. A virtual link in the virtual topology corresponds to a link-bundle or fat link, containing multiple connections. These multiple brokers and connections are used to share load and provide rapid backup in case of failure. The physical brokers within a cell maintain connections with each other, so if one physical broker loses connectivity to a downstream cell, it can route messages via another broker in its cell that has not lost connectivity.

#### 3.1 Knowledge and Curiosity Propagation in a Broker
Since there are no merges, each broker needs to maintain an input stream data structure `istream[P]` for each pubend P and a set of output stream data structures `ostream[P, c]` for each downstream cell c receiving messages from P. These structures are connected by filter edges. Each physical broker in a cell contains a replica of these structures, although the different brokers may have different states of knowledge about the different ticks.

**Propagating Knowledge:**
Knowledge is propagated downstream using knowledge messages. A knowledge message can be either a data message (F*Q*F*DF*Q*) or a silence message (F*Q*F*Q*). Both types of messages encode a prefix of "past" ticks whose values are known to be not needed. Data messages include a D tick "payload" bracketed by silence, while silence messages represent a range of F ticks.

We distinguish between two kinds of knowledge messages:
1. **First-time messages:** First-time data messages are sent to all downstream nodes that match the filters. First-time silence messages are only sent to a downstream stream if there is at least one C tick value in the corresponding `ostream` that overlaps with the silence ticks. A first-time data message can be transformed into a first-time silence message if the D tick is filtered out.
2. **Retransmitted messages:** These can originate at the pubend or at an intermediate broker. They are only sent down paths that have expressed curiosity for some ticks in the message (where the `ostream` curiosity for that tick is specifically C). A D tick in a retransmitted message is transformed into a Q (i.e., removed from the message) if the downstream cell is not curious for the D tick (but is curious for some of the F ticks in the message).

**Propagation and Interaction of A, F Ticks:**
Ticks with value A are propagated upstream using ack messages. These messages contain a single timestamp T to encode a range of ticks. An ack message sent from s2 to b1 with timestamp T changes all ticks [0, T] in `ostream[P, s2]` into A. When the tick value at tick t in all `ostream[P, c]` turns into A, the corresponding tick value in `istream[P]` is also turned into A, triggering an ack message to be propagated upstream towards P.

Whenever a knowledge tick in any stream is F, its curiosity is changed to A. Hence, D ticks that have been filtered (turned into F) at an intermediate broker can be immediately acknowledged by it, without waiting for the F to propagate to downstream subends.

**Propagation and Consolidation of C Ticks:**
Curiosity is propagated upstream using nack messages originating at the subend. Each nack message encodes a contiguous range of C ticks. When a nack message is received at a broker, it tries to satisfy the nack using information in its output stream. For instance, suppose b1 receives a nack from stream `istream[P]` in cell s2. The broker first checks which ticks in the nack range are F or D in `ostream[P, s2]`. These ticks can be satisfied locally. Knowledge messages corresponding to the satisfied ticks are then sent downstream. All unsatisfied ticks are changed to C in both `ostream[s2]` and `istream`. Nacks are consolidated by this process because a nack message is propagated upstream only if some C tick accumulated in `istream` was not already C (meaning that a nack must have been sent earlier).

Nacks are repeated if not satisfied within a certain time interval. The repetition interval (nack repetition threshold) is estimated in a manner similar to how TCP estimates the retransmission timeout value (RTO) [7]. The system is configured with a minimum repetition interval. To ensure that C ticks repeated by the same subend are not blocked by the nack consolidation behavior described above, the C ticks in an `istream` are forgotten after the minimum repetition interval so that nacks appear "fresh."

**Propagation through Link Bundles:**
Consider a message being routed from p1 towards its downstream neighbor IB1. The link is chosen by hashing the pubend ID associated with the source pubend of this knowledge tree onto one of the available links. In this example, whenever both links p1-b1 and p1-b2 are operational, messages from about half the pubends hosted by p1 will flow to IB1 along p1-b1, and half along p1-b2. Suppose the path p1-b1 is chosen, and then the path b1-s1 is broken. In that case, b1 will route messages towards s1 "sideways" via its cell neighbor b2. Periodic link status messages are exchanged between brokers so that this sideways routing is only transient, after which the messages will switch from the p1-b1 to the p1-b2 path. Note that during an interval of no failures or recoveries, successive messages from the same pubend in p1 will flow on the same path towards the downstream subscribers. Ack and nack messages sent upstream through a link bundle are sent to whichever physical broker in the cell last sent a downstream message from the relevant pubend; if this information is lost, the messages are sent to all physical brokers in the upstream cell.

#### 3.2 Failures and Liveness
Broker and link failures lead to message loss, causing subends to see gaps in their knowledge stream. A gap is a sequence of Q ticks between non-Q ticks. There are two extreme approaches to resolving these gaps, both involving retransmission of messages:
1. **Subend-driven liveness:** This is mainly based on two liveness parameters: Gap Curiosity Threshold (GCT) and Nack Repetition Threshold (NRT). The NRT parameter is estimated by the subend based on the round-trip response to previous nacks, and exponential backoff is used to handle pubends that are down. When a gap is created in the knowledge stream, the subend starts the GCT timer for the Q ticks in the gap and sends a nack after the timer expires, if the Q ticks have not already been satisfied. Nacks for these Q ticks are repeated every NRT interval until they are satisfied. An additional parameter, Delay Curiosity Threshold (DCT), is important to guard against the loss of the latest message when no pubend-driven liveness is in use. The subend initiates a nack if its doubt horizon trails real time by more than the DCT.
2. **Pubend-driven liveness:** This is based on one parameter, the Ack Expected Threshold (AET). The pubend expects all ticks that are more than AET interval before the current time to be acknowledged. If they are not, it sends an `AckExpected` message with a timestamp T equal to the current time minus AET. The message flows down on all paths that have not acknowledged up to T. A subend receiving this message will immediately nack all ticks up to T that are Q in its knowledge stream.

In our experiments, we typically run with low GCT and NRT values, a higher AET, and an infinite DCT. Hence, we use a mixture of both liveness approaches, with subend-driven liveness dominating.

### 4. Experimental Results
Two sets of experiments were performed to demonstrate the overhead of the Guaranteed Delivery (GD) protocol and its behavior in the presence of faults. The machines used for the experiments are dedicated 6-processor PowerPC machines running AIX 4.3 with 3072 MB of memory. Each machine has two network interfaces: a gigabit Ethernet PCI adapter and a 100 Mbps Ethernet PCI adapter. The broker code is written in Java and was run using IBM's JRE 1.3.

#### 4.1 Comparison of Guaranteed Delivery and Best-effort Protocols
These experiments measure the failure-free overhead of the GD protocol using two metrics: (1) mean CPU utilization, and (2) median latency from publishers to subscribers. The best-effort delivery protocol used for comparison does not perform any knowledge accumulation, curiosity propagation, message logging, or retransmission, and only sends downstream D tick messages. A two-broker asymmetric configuration is used for the experiments. Publishing clients are connected to one broker, the pubend hosting broker (PHB), while subscribing clients are connected to the second broker, the subend hosting broker (SHB). The latency seen by the subscribing clients connected to the SHB is called remote latency. For measuring local latency, a subscribing client is connected to the PHB.

The input message rate is 2000 messages/s, and each published message is 250 bytes long. Each subscriber receives 2 msgs/s on a dedicated TCP connection to the SHB. The subscribers connect to the SHB through the gigabit network since the fan-out of the SHB is quite high (up to 32000 msgs/s on 16000 connections). The broker-to-broker connection is on the 100 Mbps link.

Figure 4 shows the variation in CPU utilization at the brokers while varying the number of subscribing clients. The CPU utilization at the subend hosting broker increases with the number of subscribing clients, and the utilization when running the guaranteed delivery (GD) protocol is higher than running best-effort delivery of messages. The difference between the GD protocol cost and the best-effort protocol cost does not increase with the number of subscribers and stays constant at less than 4%. This is because our implementation optimizes the GD stream state needed by each subend by consolidating it across all subends at the same SHB. The figure also shows that the CPU utilization at the PHB does not increase with the number of subscribers connected to the SHB. The CPU overhead for GD (with respect to best-effort) at the PHB, about 8%, is more than that at the SHB, due to the overhead of logging.

Figure 5 shows how the local and remote latency vary with the number of subscribing clients. The local latency does not show an increasing trend with the number of subscribers, since the subscribers are at the SHB, while the endpoints for the local latency are on the PHB. As expected, the remote latency increases with the number of subscribers for both GD and best-effort. However, the difference between GD and best-effort remains approximately constant with an increasing number of subscribers. This latency difference of about 100ms is due to the delay introduced by the logging of guaranteed messages at the PHB. This constant difference is observed in both the local and remote latencies.

#### 4.2 Failure Injection Results
These tests measure the system fluctuation and recovery in the presence of faults. We measure the system dynamics under two types of faults: broker crash and link failure.

**Experimental Setup:**
We configured a network of 10 brokers in 8 cells as shown in Figure 3. Broker p1 is designated as the pubend hosting broker. There are 4 intermediate brokers, b1-4, with b1-2 in one intermediate cell and b3-4 in another. Each of the intermediate brokers has a direct link to the pubend hosting broker. There are 5 subend hosting brokers s1-5, with s1 and s2 linked to cell IB1 and s3-5 linked to cell IB2. Broker p1 hosts 4 pubends, each of which is receiving and logging 25 msgs/s (each message is 100 bytes) from a publisher, for a total input rate of 100 msgs/s. This low rate is used to observe system dynamics without hitting any processing capacity constraints at brokers. The filters at intermediate brokers allow all messages through. All these tests use the following liveness parameters: GCT=200ms, NRT=600ms, AET=10s, DCT=infinity.

**Metrics:**
Three metrics are used: (1) end-to-end message latency, (2) number of nacks sent, and (3) nack range sent. The nack range metric counts the number of time ticks (in milliseconds) that are nacked. For example, since each pubend is publishing about 25 msgs/s, consecutive messages from a pubend are about 40ms apart. A nack range of 800ms would mean that about 800/40=20 messages are nacked. The nack metrics are measured at subend and intermediate brokers to check for nack consolidation.

**Failures Injected:**
We present results from three kinds of failures: (1) link failure of b1-s1, (2) crash failure of b1, and (3) crash failure of p1. We repeatedly injected each kind of failure. We did not average data over multiple instances but chose to display a modal instance to preserve details of dynamic behavior.

Crash failures were injected by killing the broker process, and link failures by closing the TCP connection. We observed that since queueing of messages inside a broker was rare, failures injected in this simple manner were immediately detected by adjacent brokers, and caused messages to be immediately switched to a different path. Therefore, many such failures did not result in even a single message loss! In practice, it is likely that many failures are not detected immediately by adjacent brokers. We therefore revised our failure injection to include two steps: (1) the link or broker to be failed was stalled for about 2-3 seconds during which it accepted data but did not forward it, (2) then it was failed. This caused about 2-3 seconds of data messages to be lost.

**Results for b1-s1 Failure:**
Figure 6 shows the behavior of the system when the link b1-s1 is failed for 10 seconds, for a pubend whose messages were flowing on p1-b1 before the failure. The latency in s1, nacks sent by s1, and latency in s2 are shown. The latency in s1 increases significantly during the failure, and nacks are sent by s1 to request missing messages. The latency in s2, which is not directly affected by the b1-s1 link failure, remains relatively stable.

**Latency in s1:**
- The latency in s1 increases significantly during the 10-second failure period.
- After the failure, the latency gradually returns to normal as the system recovers and missing messages are retransmitted.

**Nacks Sent by s1:**
- The number of nacks sent by s1 spikes during the failure period as it requests missing messages.
- The nack range sent also increases, indicating that a large number of messages are being requested.

**Latency in s2:**
- The latency in s2 remains relatively stable, as it is not directly affected by the b1-s1 link failure.

### Conclusion
The experiments demonstrate the effectiveness of the Guaranteed Delivery (GD) protocol in maintaining message delivery even in the presence of failures. The protocol introduces a small but manageable overhead in terms of CPU utilization and latency compared to a best-effort approach. The system's ability to quickly detect and recover from failures, combined with the use of liveness parameters, ensures reliable and efficient message delivery.