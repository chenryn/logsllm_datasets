title:Hermes Attack: Steal DNN Models with Lossless Inference Accuracy
author:Yuankun Zhu and
Yueqiang Cheng and
Husheng Zhou and
Yantao Lu
Hermes Attack: Steal DNN Models with 
Lossless Inference Accuracy
Yuankun Zhu, The University of Texas at Dallas; Yueqiang Cheng, Baidu Security; 
Husheng Zhou, VMware; Yantao Lu, Syracuse University
https://www.usenix.org/conference/usenixsecurity21/presentation/zhu
This paper is included in the Proceedings of the 30th USENIX Security Symposium.August 11–13, 2021978-1-939133-24-3Open access to the Proceedings of the 30th USENIX Security Symposium is sponsored by USENIX.Hermes Attack: Steal DNN Models with Lossless Inference Accuracy
Yuankun Zhu∗
The University of Texas at Dallas
PI:EMAIL
Yueqiang Cheng*
Baidu Security
PI:EMAIL
Yantao Lu
Syracuse University
PI:EMAIL
Husheng Zhou
VMware
PI:EMAIL
Abstract
1
Introduction
Deep Neural Network (DNN) models become one of the
most valuable enterprise assets due to their critical roles in all
aspects of applications. With the trend of privatization deploy-
ment of DNN models, the data leakage of the DNN models is
becoming increasingly severe and widespread. All existing
model-extraction attacks can only leak parts of targeted DNN
models with low accuracy or high overhead. In this paper,
we ﬁrst identify a new attack surface – unencrypted PCIe
trafﬁc, to leak DNN models. Based on this new attack surface,
we propose a novel model-extraction attack, namely Hermes
Attack1, which is the ﬁrst attack to fully steal the whole vic-
tim DNN model. The stolen DNN models have the same
hyper-parameters, parameters, and semantically identical ar-
chitecture as the original ones. It is challenging due to the
closed-source CUDA runtime, driver, and GPU internals, as
well as the undocumented data structures and the loss of some
critical semantics in the PCIe trafﬁc. Additionally, there are
millions of PCIe packets with numerous noises and chaos or-
ders. Our Hermes Attack addresses these issues by massive re-
verse engineering efforts and reliable semantic reconstruction,
as well as skillful packet selection and order correction. We
implement a prototype of the Hermes Attack, and evaluate two
sequential DNN models (i.e., MINIST and VGG) and one non-
sequential DNN model (i.e., ResNet) on three NVIDIA GPU
platforms, i.e., NVIDIA Geforce GT 730, NVIDIA Geforce
GTX 1080 Ti, and NVIDIA Geforce RTX 2080 Ti. The
evaluation results indicate that our scheme can efﬁciently
and completely reconstruct ALL of them by making infer-
ences on any one image. Evaluated with Cifar10 test dataset
that contains 10,000 images, the experiment results show that
the stolen models have the same inference accuracy as the
original ones (i.e., lossless inference accuracy).
∗This work was mainly done during the internship at Baidu.
1Hermes is the master of thieves and the god of stealth [54].
Nowadays, Deep Neural Networks (DNNs) have been widely
applied in numerous applications from various aspects, such
as Computer Vision [9, 57], Speech Recognization [20, 22],
Natural Language Processing [11], and Autonomous Driv-
ing, such as Autoware [28], Baidu Appolo [3], Tesla Au-
topilot [49], Waymo [52]. These applications indicate the
principle role of DNNs in both industry and academic ar-
eas. Compared to other machine learning technologies, DNN
stands out for its human-competitive accuracy in cognitive
computing tasks, and capabilities in prediction tasks [35, 45].
The accuracy of a DNN model is highly dependent on in-
ternal architecture, hyperparameters, and parameters, which
are typically trained from a TB datasets [16, 56] with high
training costs. For instance, renting a v2 Tensor processing
unit (TPU) in the cloud is $4.5 per hour, and one full training
process would cost $400K or higher [17, 42]. Therefore, the
importance of protecting DNN models is self-evident.
Over the last few years, privatization deployments [2, 26]
are becoming a popular trending for giant AI providers.
The AI providers have private high-quality DNN models,
and would like to sell them to other companies, organiza-
tions and governments with a license fee, e.g., million dol-
lars per year. This privatization-deployment situation fur-
ther exacerbates the risk of model leakage. There have
been many DNN extraction works proposed in the litera-
ture [18,23,24,38,46,50,51,53,55,58]. All of them use either
a search or prediction method to recover DNN models. For the
search based schemes [24, 58], they can only obtain existing
models but not customized models. Besides, the performance
of their searching processes is particularly low. The predic-
tion based schemes [18, 23, 55] result in a signiﬁcant drop in
inference accuracy. Most importantly, all of these attacks are
not able to reconstruct the whole DNN model. Thus, until
now, most people still have the illusion that the model is safe
enough or at least the leakage is limited and acceptable.
In this paper, we ﬁrst observed that the attacker in the model
privatization deployment has physical access to GPU devices,
USENIX Association
30th USENIX Security Symposium    1973
making the PCIe bus between the host machine and the GPU
devices become a new attack surface. Even if the host system
and the GPU are well protected individually (e.g, using Intel
SGX protect DNN model on the host and never sharing GPU
with others), the attacker still has the chance to snoop the
unencrypted PCIe trafﬁc to extract DNN models. Based on
this critical observation, we propose a novel black-box attack,
named Hermes Attack, to entirely steal the whole DNN model,
including the architecture, hyper-parameters, and parameters.
It is challenging to fully reconstruct DNN models from
PCIe trafﬁc even if we can intercept and log all PCIe packets
due to the following three aspects. First, the CUDA runtime,
GPU driver, and GPU internals are all closed source, and the
critical data structures are undocumented. The limited pub-
lic information makes the reconstruction extremely difﬁcult.
Second, some critical model information, such as the informa-
tion about layer type, is lost in the PCIe trafﬁc. Without this
critical information, we cannot fully reconstruct the whole
DNN model. At last, there are millions of PCIe packets with
numerous noises and chaos orders. Based on our experiments,
only 1% to 2% of all captured PCIe packets are useful for our
model extraction work.
To address the above challenges, we design our Hermes
Attack into two phases: ofﬂine phase and online phase. The
main purpose of the ofﬂine phase is to gain domain knowl-
edge that is not publicly available. Speciﬁcally, we recover
the critical data structures, e.g., GPU command headers, us-
ing a large number of reverse engineering efforts to address
challenge 1. We address challenge 2 based on a key obser-
vation: each layer has its own corresponding unique GPU
kernel. Thus, we identify the mapping relationship between
the kernel (binaries) and the layer type in the ofﬂine phase
with known layer type and selected white-box models. We put
all these pair information into a database, which will beneﬁt
the runtime reconstruction. In the online phase, we run the
victim model and collect the PCIe packets. By leveraging the
PCIe speciﬁcation and the pre-collected knowledge in the
database, we correct the packet orders, ﬁlter noises, and fully
reconstruct the whole DNN model, to address challenge 3.
To demonstrate the practicality and the effectiveness of
Hermes Attack, we implement it on three real-world GPU
platforms, i.e., NVIDIA Geforce GT 730, NVIDIA Geforce
GTX 1080 Ti, and NVIDIA Geforce RTX 2080 Ti. The
PCIe snooping device is Teledyne LeCroy Summit T3-16
PCIe Express Protocol Analyzer [33]. We choose two sequen-
tial DNN models - MNIST [36] and VGG [47], and one non-
sequential model - ResNet [21]. These three pre-trained vic-
tim models are used for interference by Keras framework [29]
with Tensorﬂow [1] as the backbone. The attack experiments
indicate that Hermes Attack is effective and efﬁcient: (1) ran-
domly given one image, we can completely reconstruct the
whole victim model within 5 – 17 minutes; and (2) the recon-
structed models have the same hyper-parameters, parameters,
and semantically identical architecture as the original ones.
In the inference accuracy experiments, we test each recon-
structed model with 10,000 images from public available test
datasets [31,36]. The results show that the reconstructed mod-
els have exactly the same accuracy as the original ones (i.e.,
lossless inference accuracy).
Contributions. In summary, we make the following contri-
butions in this paper:
• We are the ﬁrst to identify the PCIe bus as a new attack
surface to steal DNN models in the model-privatization
deployments, e.g., smart IoT, autonomous driving and
surveillance devices.
• We propose a novel Hermes Attack, which is the ﬁrst
black-box attack to fully reconstruct the whole DNN
models. None of the existing model extraction attacks
can achieve this.
• We disclose a large number of reverse engineering details
in reconstructing architectures, hyper-parameters, and
parameters, beneﬁting the whole community.
• We have demonstrated the Hermes Attack on three real-
world GPU platforms with sequential and non-sequential
models. The results indicate that the Hermes Attack can
handle MNIST, VGG and ResNet DNN models and the
reconstructed models have the same inference accuracy
as the original ones.
2 Background
2.1 DNN Background
Deep Neural network (DNN) is a sub-area of machine learn-
ing in artiﬁcial intelligence that deals with algorithms inspired
from the biological structure and functioning of a brain. DNN
is used to model both linear and non-linear relationships be-
tween the input x and the output y, learning to approximate
an unknown function f (x) = y. A DNN model is represented
as a hierarchical organization of connected layers with a cer-
tain level of complexity between the input data and resultant
output. DNNs are used in two phases, i.e., training and in-
ference. The training process is computationally heavy and
needs a large amount of data. With a series of feed-forward
matrix computations on given input data, the resultant output
is computed through a loss function against ground truth. The
weights of the network are updated accordingly based on error
back-propagation. The training is done once passing through
all of the training samples. The inference is the phase in which
a trained model is used to infer real-world data. Terminologies
used in the rest of this paper are described as follows.
Architecture: Neural network architecture consists of a num-
ber of layers, types/dimensions for each layer, and connection
topology among layers. The connections between layers can
be either sequential or non-sequential. Sequential connection
1974    30th USENIX Security Symposium
USENIX Association
Figure 1: Typical DNN System Stack. DNNs are usually
implemented with deep learning frameworks, e.g., Tensor-
ﬂow, Pytorch, and Caffe. These frameworks invoke the GPU
runtime frontend like CUDA by calling APIs. The runtime
frontend converts these APIs to GPU commands and sends
them to the runtime backend, which then sends the received
commands to the device driver through ioctl. The device
driver submits these commands to GPU hardware via PCIe.
means layers are stacked and every layer take the only output
of the previous layer as the input. Non-sequential connection
denotes the model may include shortcuts, branches, or shared
layers [29, 58].
Hyper-parameters: Hyper-parameters are the parameters
used to control the training process, which do not belong to
the trained model and cannot be estimated from training data.
There are many hyper-parameters such as learning rate, regu-
larization factors, momentum coefﬁcients, number of epochs,
batch size, etc.
Parameters: Parameters are conﬁguration variables of the
trained model, whose values are derived via training. Model
parameters includes weights and bias in DNNs. Throughout
the paper, when we mention “parameters”, we mean DNN
model parameters instead of “arguments”.
2.2 GPU Working Mechanism
Adding sufﬁcient DNN layers to guarantee high inference
accuracy may easily explode the computation demand [15].
Currently, major DNN frameworks mainly rely on employing
GPUs to satisfy the need, since GPUs enable orders of mag-
nitude acceleration and more energy-efﬁcient execution for
many DNN related computations. According to their archi-
tecture, modern GPUs can be divided into integrated GPUs
that lie on the same die of CPUs and discrete GPUs which
are connected to CPU via PCIe. Integrated GPUs are more
energy-efﬁcient but less powerful, which is often seen in em-
bedded systems and mobile devices. In this paper, we focus
on discrete GPUs since they dominate the markets of AI and
machine learning for their computation powers. Some termi-
nologies used in this paper are described as follows.
CUDA is a parallel computing architecture provided by
NVIDIA for GPUs [37], which includes compilers, user space
Figure 2: Example of Memory Read Request TLP. The Tag
ﬁeld can be used to identify the corresponding completion
TLP. The address ﬁeld is the targeted reading address.
Figure 3: Example of Completion TLP. The Tag ﬁeld can be
used to identify the corresponding request TLP. The payload
ﬁeld includes the reading data from the targeted address.
libraries, and kernel space drivers. Employing CUDA for a
very simple GPU accelerated program usually involves three
procedures: copying input data from main memory to GPU
memory, launching computations on GPU, and transferring
back the resultant output from GPU memory to main memory.
Kernel is a piece of code that is compiled into hardware-
speciﬁc executable and runs on GPU hardware to do the
actual computation. Throughout the paper, when we men-
tion “kernel” we mean “GPU kernel” instead of OS kernel.
In CUDA, kernels are compiled by nvcc compiler [12] into
CUDA Fatbin and embedded into a dedicated section of host
executable ﬁle. During runtime, sets of GPU instructions are
loaded onto GPU and launched when speciﬁc CUDA APIs
are called (e.g., cudaLaunchKernel).
Commands are encoded using distinct instruction sets with
kernels, which are used to control data copy, kernel launch,
initialization, synchronization, etc. In this paper, we use “GPU
command” to indicate a set of GPU hardware instructions that
complete an atomic CUDA operation. Each GPU command
consists of two parts: the header and the data. The header
contains the type of this command and the data size. The data
ﬁeld comprises values passed to this command. We named
the data movement command as D command and the kernel
launch command as K command in the rest of the paper.
GPU Accelerated DNN Platform is depicted as Figure 1,
which includes DNN frameworks, user space libraries, kernel
space drivers, and the hardware. High level computation tasks
of DNN are ﬁnally converted to low level PCIe packets, which
is the attack surface we are targeting in this paper.
2.3 PCIe Protocol
PCIe is a high-speed motherboard interface for I/O devices,
such as graphics cards, SSDs, Wi-Fi, etc. The communica-
tion of PCIe takes the form of packets transmitted over these
USENIX Association
30th USENIX Security Symposium    1975
DNNsTensorﬂowOpenCLCUDAPytorchGPURuntime BackendDevice DriverioctlPCIe TrafﬁcGPU Commands......GPU APIsvia an unencrypted PCIe connection. We assume the host and
the GPU device are well protected individually, e.g., AI mod-
els are protected with existing software-hardening techniques
on the host side, such as secure boot, full disk encryption,
and trusted execution environment (e.g., Intel SGX [14]). It
leaves the PCIe bus as a new attack surface for attackers. This
assumption is reasonable in the privatization deployment en-
vironments because: (1) attackers (e.g., insiders within the
third-party company) have the motivation to extract the AI
model for saving the per-year license fee, and (2) attackers
have physical access to the host machine, and thus they can
install a PCIe bus snooping device (e.g., PCIe protocol ana-
lyzer) between the host and GPU to monitor and log the PCIe
trafﬁc. The victim model is considered a black-box. The vic-
tim can be either an existing model or a customized model. It
can be implemented with arbitrary deep learning frameworks.
Challenges. It is challenging to fully reconstruct DNN mod-
els from PCIe trafﬁc even if we can intercept and log all PCIe
packets. We summarize the challenges as follows:
1. Closed-source Code and Undocumented Data Struc-
tures. The CUDA runtime, driver, and NVIDIA GPU
hardware are all closed-source, and the critical data struc-
tures involved in data transfer and GPU kernel launch
are undocumented. The closed-source code and per-
architecture instruction set make fully disassembling
impractical. Moreover, GPU kernels and commands are
encoded with different instruction sets, making reverse
engineering more difﬁcult.
2. Semantic Loss in PCIe Trafﬁc. Some critical seman-
tic information of a DNN model is lost at the level of
PCIe trafﬁc. For instance, DNN layer types can not be
obtained directly from PCIe trafﬁc because it is resolved
on the CPU side. The loss of critical information makes
it challenging to recover the whole model fully.
3. PCIe Packets with Numerous Noises and Chaotic Or-
ders. There are millions of packets generated for a sin-
gle image inference, in which only 1% to 2% are useful
for our DNN model reconstruction. The rest “noises”
packets should be carefully eliminated. Moreover, nu-
merous completion packets, which indicate operation
completion, often arrive out-of-order compared to DNN
level semantics, due to the CUDA features that pipeline