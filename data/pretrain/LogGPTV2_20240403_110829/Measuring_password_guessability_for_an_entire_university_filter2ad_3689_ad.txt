0.049
0.931
0.530†
0.051
1.033
0.002
0.055
0.844
0.079†
0.046
0.922
0.048 <0.001
0.825
0.049 <0.001
1.182
0.004 <0.001
1.032
0.027 <0.001
0.896
0.035 <0.001
0.789
0.216†
0.036
1.046
0.688†
0.073
1.030
0.004
0.076
1.249
0.071†
0.074
1.143
0.026 <0.001
0.864
0.001
0.051
0.849
0.638†
1.019
0.041
1.002 <0.001 <0.001
0.005
0.111
0.733
0.134 <0.001
0.542
0.106 <0.001
0.590
0.300 <0.001
0.353
0.640†
0.293
0.872
0.306†
0.307
0.730
0.545†
0.341
1.230
0.552†
1.253
0.379
0.282†
0.559
0.548
0.048
0.547
0.306
Table 3: Final Cox regression results for all participants, in-
cluding composition factors, with interactions.
Interaction
effects, shown in parentheses,
indicate that combination of
two factors is associated with stronger (negative coefﬁcient) or
weaker (positive coefﬁcient) passwords than would be expected
simply from adding the individual effects of the two factors.
58% as likely to be guessed. Each additional login during the mea-
surement period is associated with an estimated increase in the like-
lihood of guessing of 0.026%. Though this effect is statistically sig-
niﬁcant, we consider the effect size to be negligible. No signiﬁcant
interactions between factors were found in the ﬁnal model.
Notable behavioral factors that do not appear in the ﬁnal regres-
sion include median time between login events, wired login rate (as
opposed to wireless), and non-web authentication rate (e.g., using
an email client to retrieve email without using the web interface).
4.2.4 Model 4: Survey participants
Among survey participants, we ﬁnd correlations between pass-
word strength and responses to questions about compliance strate-
gies and user sentiment during creation. As before, college also
appears in the ﬁnal model.
Factor
login count
password fail rate
gender (male)
engineering
humanities
public policy
science
other
computer science
business
Coef.
<0.001
-0.543
0.078
-0.273
-0.107
0.079
-0.325
-0.103
-0.459
0.185
Exp(coef)
SE
p-value
1.000 <0.001 <0.001
0.116 <0.001
0.581
0.005
0.027
0.925
0.048 <0.001
0.761
0.048
0.054
0.898
0.176†
0.058
1.082
0.062 <0.001
0.722
0.051†
0.902
0.053
0.055 <0.001
0.632
0.054 <0.001
1.203
Table 4: Final Cox regression results for personnel with con-
sistent passwords, using a model with no interactions. For an
explanation, see Table 1.
Factor
annoying
substituted numbers
gender (male)
engineering
humanities
public policy
science
other
computer science
business
Coef.
0.375
-0.624
-0.199
0.523
0.435
1.000
0.432
0.654
0.681
1.039
Exp(coef)
1.455
0.536
0.820
1.693
1.545
2.719
1.541
1.922
1.976
2.826
SE
0.116
0.198
0.120
0.342
0.367
0.394
0.416
0.334
0.351
0.376
p-value
0.001
0.002
0.098†
0.124†
0.235†
0.011
0.299†
0.051†
0.052†
0.006
Table 5: Final Cox regression results for survey participants.
For an explanation, see Table 1.
Perhaps unsurprisingly, users who report that complying with
the university’s password policy was annoying have weaker pass-
words, 46% more likely to be guessed than those who do not report
annoyance. This suggests that password policies that annoy users
may be counterproductive. Users who substitute numbers for some
of the letters in a word or name, by contrast, make passwords only
54% as likely to be guessed. We do not know whether or not these
are typical “l33t” substitutions. Figures 4-5 illustrate these ﬁndings
and full details appear in Table 5. For this subpopulation, there are
not enough data points for a model with interaction to be valid.
Factors that do not appear in the ﬁnal model include responses
that complying with the password policy was difﬁcult or fun; about
twice as many users (302) agreed that it was annoying as agreed
that it was difﬁcult (162), and only 74 users found it fun. In ad-
dition, self-reported storage and the reason why the password was
changed are not signiﬁcant factors.
5. COMPARING REAL AND SIMULATED
PASSWORD SETS
Acquiring high-quality password data for research is difﬁcult,
and may come with signiﬁcant limitations on analyses. As a re-
sult, it is important to understand to what extent passwords col-
lected in other settings — e.g., from data breaches or online studies
— resemble high-value passwords in the wild. In this section, we
examine in detail similarities and differences between the various
password sets to which we have access. We ﬁrst compare guess-
ability, then examine other properties related to password compo-
sition. Overall, across several measures, passwords from online
studies are consistently similar to the real, high-value CMU pass-
words. In contrast, passwords leaked from other sources prove to
be close matches in some cases and by some metrics but highly
dissimilar in others.
180at a constant rate across the entire curve. Table 6 shows percent-
ages guessed at several guessing thresholds, as well as results of the
G1 signiﬁcance test. In this table, differences in p-values indicate
relative similarity to CMUactive; smaller p-values indicate greater
divergence. Figure 6 shows guessability results for both attackers.
Online studies. Overall, the online studies provide more con-
sistently similar matches to the CMU passwords than the leaked
sets do. For both attackers, the CMUactive passwords are weaker
than MTcomp8 and stronger than MTsim, but closer to MTcomp8.
While the MTsim passwords were restricted to exactly match CMU
policy, the MTcomp8 passwords were collected under a policy that,
while similar, includes a notably harder dictionary check. As a re-
sult, it is unsurprising that MTcomp8 might produce more guess-
resistant passwords. In fact, instrumentation from the MTurk stud-
ies shows that more than twice as many MTcomp8 participants as
MTsim participants failed the dictionary check at least once during
password creation (35% to 14%), suggesting the harder dictionary
check did make an important difference.
The real CMUactive passwords were produced under the easier
dictionary check, but they more closely resemble MTcomp8 than
MTsim. We hypothesize that deployed passwords are harder to
guess than the simulated version because online studies can only
partially reproduce the effort users make to create strong passwords
for high-value accounts.
Cracked password sets. As might be expected, cracked pass-
word sets provide especially poor points of comparison. Because
they consist of a subset of the original data that was easiest to
crack, they are guessed much more quickly than the CMU pass-
words, with 62% (SFcomp8) and 79% (Gcomp8) guessed before
the cutoff.
Plaintext leaked password sets. The three plaintext leaked pass-
word sets are a more complicated case. Although the RYcomp8
subset appears highly similar to the CMU passwords under both
attackers, CSDNcomp8 is only similar for the public attacker, and
Ycomp8 is far off under both. Subsetted passwords from Ycomp8
and CSDNcomp8 are harder to guess than CMU passwords created
under the same policy, which agrees with a previous ﬁnding [30].
Although this pattern does not hold for RYcomp8, it is important to
note that there is much more RockYou data than data for any other
set available in the training data. This advantage may partially com-
pensate for subsets otherwise tending to be harder to guess.
To further examine our hypothesis that online studies provide a
reasonably good proxy for real passwords, we obtain CMUactive
guess numbers for two additional attackers: one trained on Public
plus 3,000 CMUactive passwords, and another trained on Public
plus 3,000 MTsim passwords. The distribution of guess numbers in
the two data sets is not signiﬁcantly different (G1, uncorrected p =
0.583). This suggests that using MTsim passwords for cracking
CMUactive passwords is a viable strategy. These results are shown
in Figure 7.
5.2 Comparing other password properties
In addition to guessability, we compare several other proper-
ties of our data sets, including mean password length and quan-
tity of characters per password from various character classes. We
also consider estimated entropy, calculated as described in prior
work [31]. For length, composition, and entropy, we can also com-
pute conﬁdence intervals using the statistical technique known as
bootstrapping. Speciﬁcally, we use the “basic” bootstrap technique
as identiﬁed by Davison and Hinkley [12].
We also compare the diversity of password structures, which
correspond to high-level representations of passwords in the Weir
grammar [56]. For example, the structure of “PassW0rd!” is “UL-
Figure 4: The percentage of passwords guessed after a given
number of guesses (shown in log scale), by whether the user
found password-creation annoying.
Figure 5: The percentage of passwords guessed after a given
number of guesses (shown in log scale), by whether the user
created the password by substituting numbers into a word.
5.1 Comparing guessability
We compare password sets primarily using guessability results.
First, we calculate guess numbers for two attackers. The limited-
knowledge attacker trains on publicly available data:
the Public
set described in Section 4.1. The extensive-knowledge attacker
trains on the same public data, plus 20,000 CMUactive and 15,000
CMUinactive passwords. In each case, all data sources are weighted
equally during training. Because these trainings are optimized for
guessing passwords under the comprehensive policy, we cannot
use this approach to compare university passwords to MTbasic8,
MTbasic16, or MTdictionary8. We do compare CMUactive pass-
words to the other comprehensive-policy conditions: MTsim and
MTcomp8 (online studies), RYcomp8, Ycomp8, and CSDNcomp8
(leaked plaintext sets), and Gcomp8 and SFcomp8 (leaked cracked
sets). In all cases, we calculate and compare guess numbers only
for passwords that are not used in training.
After calculating guess numbers, we compare guessability across
password sets using another technique from the survival analysis
literature: the Peto-Peto generalization of the Wilcoxon test [40],
also known as a Gρ test with ρ = 1 [20]. This test is designed
to compare two survival data sets under the null hypothesis that
both data sets were drawn from the same distribution. It has the
additional property of weighting differences in early parts of the
curve more heavily than later parts. As passwords are guessed and
the population dwindles, the power of the test decreases. Unlike
Cox regression, it does not assume that differences should occur
100%90%80%70%60%50%40%30%20%10%0%AnnoyingNot annoyingGuess numberPercent guessed1E41E71E101E13100%90%80%70%60%50%40%30%20%10%0%Guess numberPercent guessed1E41E71E101E13Didn’t   substitute   numbersSubstituted   numbers181Attacker
public
knowledgeable
Password set
CMUactive
MTsim†
MTcomp8†
RYcomp8†
Ycomp8
CSDNcomp8†
SFcomp8
Gcomp8
CMUactive
MTsim
MTcomp8 †
RYcomp8 †
Ycomp8
CSDNcomp8
SFcomp8
Gcomp8
N 1 E6
0.1