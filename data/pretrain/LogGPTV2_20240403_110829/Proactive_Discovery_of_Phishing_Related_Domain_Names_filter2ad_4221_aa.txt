title:Proactive Discovery of Phishing Related Domain Names
author:Samuel Marchal and
J&apos;erôme François and
Radu State and
Thomas Engel
Proactive Discovery of Phishing Related Domain Names
Samuel Marchal, Jérôme François, Radu State, Thomas Engel
To cite this version:
Samuel Marchal, Jérôme François, Radu State, Thomas Engel. Proactive Discovery of Phishing Re-
lated Domain Names. Research in Attacks, Intrusions, and Defenses, Sep 2012, Amsterdam, Nether-
lands. pp.190-209, 10.1007/978-3-642-33338-5_10. hal-00748808
HAL Id: hal-00748808
https://hal.archives-ouvertes.fr/hal-00748808
Submitted on 6 Nov 2012
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Proactive Discovery of Phishing Related Domain
Names
Samuel Marchal, J´erˆome Fran¸cois, Radu State, and Thomas Engel
SnT - University of Luxembourg, Luxembourg,
PI:EMAIL
Abstract. Phishing is an important security issue to the Internet, which
has a signiﬁcant economic impact. The main solution to counteract this
threat is currently reactive blacklisting; however, as phishing attacks are
mainly performed over short periods of time, reactive methods are too
slow. As a result, new approaches to early identify malicious websites
are needed. In this paper a new proactive discovery of phishing related
domain names is introduced. We mainly focus on the automated detec-
tion of possible domain registrations for malicious activities. We leverage
techniques coming from natural language modelling in order to build pro-
active blacklists. The entries in this list are built using language models
and vocabularies encountered in phishing related activities - ”secure”,
”banking”, brand names, etc. Once a pro-active blacklist is created, on-
going and daily monitoring of only these domains can lead to the eﬃcient
detection of phishing web sites.
Keywords: phishing, blacklisting, DNS probing, natural language
1
Introduction
The usage of e-commerce, e-banking and other e-services is already current prac-
tice in the life of modern Internet users. These services handle personal and con-
ﬁdential user data (login, password, account number, credit card number, etc.)
that is very sensitive. As a result, threats emerged for which attackers attempt
to steal this data and use it for lucrative purposes. An example of these threats is
phishing, a criminal mechanism employing both technical subterfuge and social
engineering to abuse the naivety of uninformed users. Phishing mainly targets
(75%) ﬁnancial and payment activities and its cost is estimated to many billion
of dollars per year1.
Phishing attacks leverage some techniques such as e-mail spooﬁng or DNS
cache poisoning to misdirect users to fake websites. Attackers also plant crime-
ware directly onto legitimate web server to steal users data. However, the two
last techniques require to penetrate web servers or change registration in DNS
server, which might be diﬃcult. Most often, phishers try to lure Internet users by
having them clicking on a rogue link. This link seemed to be trustworthy because
it contained a brand name or some keywords such as secure or protection.
1 http://www.brandprotect.com/resources/phishing.pdf, accessed on 04/04/12
2
Samuel Marchal, J´erˆome Fran¸cois, Radu State, and Thomas Engel
Current protecting approaches rely on URL blacklists being integrated in
client web browsers. This prevents users from browsing malicious URLs. Google
Safe Browsing2 or Microsoft Smart Screen3 are two examples and their eﬃ-
ciency has been proved in [14]. However, as reported in [21], the average uptime
of phishing attacks is around 2 days and the median uptime is only 12 hours. Due
to this very short lifetime, reactive blacklisting is too slow to eﬃciently protect
users from phishing; hence, proactive techniques must be developed. The previ-
ous report also points out that some phishing attacks involve URLs containing
unique number in order to track targeted victims. The only common point be-
tween these unique URLs remains their domain name; as a result domain name
blacklisting should be more eﬃcient and useful than URL blacklisting. More-
over, it emphasizes that one maliciously registered domain name is often used
in multiple phishing attacks and that each of them use thousands of individual
URLs. As a result, the identiﬁcation of only one phishing domain name can lead
to protect Internet users from tens of thousand malicious URLs.
According to recent reports [21, 1] from the Anti Phishing Working Group
(APWG), the number of phishing attacks is fast growing. Between the ﬁrst half
of 2010 and the ﬁrst half of 2011 the number of phishing attacks raised from
48,244 to 115,472 and the number of dedicated registered domains from 4,755
to 14,650. These domains are qualiﬁed as maliciously registered domains by
the APWG. These counts highlight the trend that attackers prefer to use more
and more their own maliciously registered domains rather than hacked named
domains for phishing purposes. Moreover, observations reveal that malicious do-
main names and particularly phishing ones are meaningful and composed of
several words to obfuscate URLs. Attackers insert some brands or keywords
that are buried in the main domain name to lure victims, as for instance in
protectionmicrosoftxpscanner.com, google-banking.com or domainsecurenethp.com.
As a result, this paper focuses on the identiﬁcation of such phishing domain
names that are used in URL obfuscation techniques.
This paper introduces a pro-active domain monitoring scheme that generates
a list of potential domain names to track in order to identify new phishing activ-
ities. The creation of the list leverages domain name features to build a natural
language model using Markov chains combined with semantic associations. We
evaluate and compare these features using real malicious and legitimate datasets
before testing the ability of our approach to pro-actively discover new phishing
related domains.
The rest of this paper is organized as follows: Section 2 describes the design
of the architecture and the steps to follow to generate malicious domain names.
Section 3 introduces the datasets used for the validation and experimentation.
In section 4, diﬀerences between malicious and legitimate domains are analyzed
and domain name generation is tested in some real case studies. Finally, related
2 http://code.google.com/apis/safebrowsing/, accessed on 04/04/12
3 http://windows.microsoft.com/en-US/internet-explorer/products/ie-
9/features/smartscreen-ﬁlter, accessed on 04/04/12
Proactive Discovery of Phishing Related Domain Names
3
work is discussed in section 5. We conclude in section 6 and point out the further
research to be done.
2 Modeling a Phisher’s language
Phishers are human and will generate names for their domains using some sim-
ple patterns. They will use names that are similar to legitimate domain names,
append some other words that come from a target vocabulary and leverage some
domain speciﬁc knowledge and expertise. Thus, we argue that pro-active mon-
itoring can emulate this process and generate potential domains to be tracked
permanently. This tracking can be done on a daily basis and thus detect new
phishing sites. This requires however to generate domain names that are or will
be involved in phishing activities. These names follow a model build on statis-
tical features. The domain names considered in our work are composed of two
parts, the top level domain (TLD) and the second level domain also called main
domain. In this approach, the TLD can be either only one level domain ”.com”
or more ”.org.br”, we refer to Public Suﬃx List4 to identify this part of the
URL and the main domain is considered as the label preceding the TLD. For
the rest of the paper these domains (main domain + TLD) will be called two-
level-domains. Assuming a dataset containing domain names and URLs such
as:
• www.bbc.co.uk
• wwwen.uni.lu/snt/
• secan-lab.uni.lu/index.php?option=com user&view=login
Features are extracted only from the two-level-domains, which are respectively
bbc.co.uk, with bbc the main domain and co.uk the TLD, for the ﬁrst one
and uni.lu for the two others, with uni the main domain and lu the TLD. The
domain names generated are also two-level-domains.
2.1 Architecture
An overview of our approach is illustrated in Figure 1 where the main input
is a list of known domains related to malicious activities. Based on that, the
ﬁrst stage (1) decomposes the name and extracts two main parts: the TLD
and the main domain. Then, each of these two is divided into words (2). For
TLD, a simple split regarding the dot character is suﬃcient but for the second,
a real word segmentation is required to catch meaningful words. As illustrated
here with a small example, macromediasetup.com/dl.exe, the following words are
extracted:
• TLD: com
• main domain: macro, media, set, up
4 http://publicsuﬃx.org, accessed on 08/03/12
4
Samuel Marchal, J´erˆome Fran¸cois, Radu State, and Thomas Engel
Fig. 1. Proactive Malicious Domain Name Discovery – Overview
These features are then used to build a model (3) by computing statistics,
as for example the length distribution of the main domain in words as well as a
Markov chain for representing probabilistic word transitions. The statistics and
Markov chain model are computed for each level. Next, this model is combined
(4) with semantic extensions. This leads to generating similar words (only for
the main domain) and a list of potential malicious domain is built. These latter
are checked online (5) for potential phishing activities. The online validation is
not described in this paper, but can be done with various techniques: signature-
based approach, honeypots, manual analysis, etc. Hence, our experiments are
based on publicly available blacklists for cross-validation (see section 3).
2.2 Features extraction
Features : Given a set of two-level-domains as D = {d1, ...., dp}, a set of words
as W = {w1; ....; wp} and a set of domain levels L = {l1; l2} where l1 is the TLD
and l2 is the main domain, we deﬁne:
• #lenl,n the number of domains d ∈ D having the lth level (l ∈ L) composed
of n words
• #wordl,w the number of domains d ∈ D containing the word w ∈ W at the
level l ∈ L
• #f isrtwordl,w the number of domains d ∈ D having the lth level (l ∈ L)
starting with the word w ∈ W
• #biwordsl,w1,w2 the number of domains d ∈ D containing the consecutive
words w1 and w2 ((w1, w2) ∈ W 2) at the level l ∈ L
The following list groups the features extracted from a list of domains or
URLs :
• distlenl,n: the distribution of the length n ∈ N expressed in word for a level
l ∈ L and deﬁned as:
distlenl,n =
#lenl,n
Pi∈N #lenl,i
(1)
NameStatisticssetupxpMarkovChains+(1)(4)(5)NameDecompositonTLD list:com, lu, fr, de, org...Malicous domains(blacklists,honeypots,malware analysis...)WordSplitterDISCODomain checkerPotential MaliciousDomain Listmacromediasetup.com/dl.exemacromediasetup,com|macro|media|set|up|, |com|Feature extractionModel(2)(3)Blacklist(6)Proactive Discovery of Phishing Related Domain Names
5
• distwordl,w: the distribution of the number of occurrences of a word w ∈ W
at the level l ∈ L and deﬁned as:
distwordl,w =
#wordl,w
Pi∈W #wordl,i
• distf irstwordl,w: the distribution of the number of occurrences of a word
w ∈ W as ﬁrst word for the level l ∈ L and deﬁned as:
(2)
(3)
(4)
• distbiwordsl,w1,w2 : the distribution of the number of occurrences of a word
w2 ∈ W following the word w1 ∈ W for the level l ∈ L and deﬁned as:
distf irstwordl,w =
distbiwordsl,w1,w2 =
#f isrtwordl,w
Pi∈W #f isrtwordl,i
#biwordsl,w1,w2
Pi∈W #biwordsl,w1,i
Word extraction : The main domain of DNS names can be composed of several
words like computeraskmore or cloud-anti-malware. Using a list of separat-
ing characters, as for instance “-” is too restrictive. We have thus used a word
segmentation method, similar to the one described in [22]. The process is recur-
sive by successively dividing the label in 2 parts that give the best combination,
i.e. with the maximum probability, of the ﬁrst word and the remaining part.
Therefore, a label l is divided in 2 parts for each position i and the probability
is computed:
P (l, i) = Pword(pre(l, i))P (post(l, i))
(5)
where pre(l, i) returns the substring of l composed of the ﬁrst i characters and
sub(l, i) of the remaining part. Pword(w) returns the probability of having the
word W equivalent to its frequency in a database of text samples.
TLDs are split in diﬀerent labels using the separating character ”.”.
2.3 Domain names generation model
The generator designed for domain generation is mainly based on an n-gram
model. Coming from natural language processing an n-gram is a sequence of
n consecutive grams. These grams are usually characters, but in our approach,
grams are words. We especially focus on bigrams of words that are called biwords.
These couples of words are further used to build a Markov chain through which
two-level-domains are generated.
Markov Chain : A Markov chain is a mathematical system that undergoes
transitions from one state to another. Each possible transition between two states
can be taken with a transition probability. Two Markov chains are deﬁned in the
domain generation model, one for each level, l1 and l2. The states of the Markov
chains are deﬁned as the words w ∈ W and the probability of transition between
6
Samuel Marchal, J´erˆome Fran¸cois, Radu State, and Thomas Engel
two words w1 and w2 for the level l ∈ {1; 2} is given by distbiwordsl,w1,w2 . A
part of a created Markov chain is given in Table 1 for some transitions, and
the associated probabilities, starting from the word pay. In order to generate
new names the Markov chain is completed with additional transitions that have
never been observed - this technique is called additive smoothing or Laplace
smoothing. For each state s, a small probability (0.05) is assigned for transitions
to all the words that have been observed at the level l and for which s does
not have any transition yet. This probability is shared between the words of the
level l according to the distribution distwordl,w. The same method is applied for
states s that do not have any existing transitions. In this case, their transitions
follow the probability given by the distribution distwordl,w.
Transition per
z
Probability 0.13 0.1 0.06 0.06
0.03
0.03
for secure bucks bill process pay account soft page ...
0.03 0.03 ...
0.06 0.03
0.03
Table 1. Example of Markov chain transitions for the state pay
For two-level-domains generation, the ﬁrst state is randomly initialized us-
ing distf irstwordl,w, the number of transitions that must be completed in the
Markov chain is randomly determined using distlenl,n. Given these two param-
eters by applying n steps from word w in the Markov chain, a label is generated
for the level l.
Semantic Exploration : The words composing the main domains of diﬀer-
ent malicious domains often belong to the one or more shared semantic ﬁelds.
Given some malicious domain names such as xpantiviruslocal.com, xpantivirus-
planeta.com, xpantivirusmundo.com and xpantivirusterra.com, it clearly appears
that they are related. Applying the word extraction process, from all of these do-
mains, the words ”xp”, ”anti” and ”virus” will be extracted and the four words
”local”, ”planeta”, ”mundo” and ”terra” will be extracted from each of them.
These four words are closely related, particularly the three last ones. As a result,
given one of these domains, the remaining three could be found as well. However,
even if this intuitive conclusion is obvious for human, it is more complicated to
implement it in an automatic system.
For this purpose, DISCO [12] is leveraged, a tool based on eﬃcient and accu-
rate techniques to automatically give a score of relatedness between two words.
To calculate this score, called similarity, DISCO deﬁnes a sliding window of four
words. This window is applied to the content of a dictionary such as Wikipedia5
and the metric kw, r, w′k is calculated as the number of times that the word w′
occur r words after the word w in the window, therefore r ∈ {−3; 3} \ {0}. Table
2 highlights an example of the calculation of kw, r, w′k for two sample pieces of
text. Afterwards the mutual information between w and w′, I(w, r, w′) is deﬁned
as:
(6)
I(w, r, w′) = log
(kw, r, w′k − 0.95) × k∗, r, ∗k
kw, r, ∗k × k∗, r, w′k
5 http://www.wikipedia.org, accessed on 04/04/12
Proactive Discovery of Phishing Related Domain Names
7
Finally, the similarity sim(w1, w2) between two words w1 and w2 is given by the
formulae:
sim(w1, w2) = P(r,w)∈T (w1)∩T (w2) I(w1, r, w) + I(w2, r, w)
P(r,w)∈T (w1) I(w1, r, w) +P(r,w)∈T (w2) I(w2, r, w)
(7)
where T (w) is all the pairs (r, w′) | I(w, r, w′) > 0.
Using this measure and given a word w1, DISCO returns the x most related
words ordered by their respective similarity score sim(w1, w2). Based on the
words extracted from the main domain, DISCO is used to compose new labels
for the main domain.
-2
client
client
0
+1 +2
+3
-1
uses
services of the platform
position -3
sample 1 a
sample 2 the platform provides services to the
||services, −3, a|| = 1
||services, −2, client|| = 1
||services, −1, uses|| = 1
||services, 1, of || = 1
||services,2,the|| = 2
||services, 3, platf orm|| = 1
||services, −3, the|| = 1
||services, −2, platf orm|| = 1
||services, −1, provides|| = 1
||services, 1, to|| = 1