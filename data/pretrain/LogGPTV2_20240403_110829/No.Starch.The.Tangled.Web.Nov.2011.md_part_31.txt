practical attack on Firefox along these lines in 2007.)3
In response to the attacks on security dialogs, a variety of security
delayshave been implemented in the past few years, requiring anywhere
from 500milliseconds to 5 seconds between the dialog coming into focus
and any dangerous buttons being enabled for user input. But such delays do
222 Chapter 14
not sit well with browser UI designers: They hate them, feeling that the prod-
uct should be as responsive as possible and that annoying the user with non-
clickable buttons or countdowns is a significant usability issue. Some have even
pushed to remove existing timeouts from legacy UIs.* HTML5 geolocation-
sharing prompts are impacted by this view. Many browsers are not protected
against the attack on this UI in any significant way.4
To further complicate the picture, browser-level user interfaces are not
the only concern for UI-timing attacks. The security- or privacy-sensitive func-
tionality of many trusted websites can also be attacked, and fixing that prob-
lem is a lot harder than adding delay timers on a handful of known
dangerous system-level UIs.
NOTE Millisecond-level click or keypress hijacking aside, it has been repeatedly demonstrated
that with minimal and seemingly innocuous conditioning, healthy and focused test
subjects can be reliably tricked into ignoring even very prominent and unusual visual
stimuli. The infamous Invisible Gorilla experiment,5 shown in Figure 14-5, is a partic-
ularly well-known example of this. Almost all viewers watching a clip prepared by the
researchers fail to notice a plainly visible gorilla in a crowd. The corollary is that even
savvy users can be conditioned to ignore cues such as changes to the address bar or to
SSL indicators in the browser—a very disconcerting thought. The only reason why we
are not trying to solve this problem today is that few exploit writers are behavioral scien-
tists. But if you are a high-profile target, this seems like a risky bet.
Figure 14-5: A single frame from the Invisible Gorilla experiment, courtesy
ofDaniel Simons6 (http://dansimons.com/). When asked to view this video
and count the number of times the players pass the basketball, most view-
ers fail to notice a person in a gorilla suit casually strolling across the room
halfway through the clip. Really! Go to http://theinvisiblegorilla.com/
videos.html and try it on a friend.
* See, for example, Mozilla bug 561177, where one of the Firefox UI engineers proposed the
removal of a security delay from the plug-in installation prompt.
Dealing with Rogue Scripts 223
Security Engineering Cheat Sheet
When Permitting User-Created  Gadgets on Your Site
 Don’t do so unless you are prepared to live with the consequences. You can’t reliably
prevent a malicious gadget from launching DoS attacks on your users. Any such gadget
will also be able to bring up various obscure dialogs that, as a rule, will not distinguish
between your top-level page and the domain the gadget is hosted in.
When Building Security-Sensitive UIs
 Because of the risk of UI race conditions, avoid situations where a vital setting can be
changed with a single keypress or a single click. Require at least two operations (such
asselecting a checkbox and then clicking Save). If single-click actions are unavoidable,
consider examining other signals. For example, was the mouse pointer in the current
window 500 milliseconds ago?
224 Chapter 14
E X T R I N S I C S I T E P R I V I L E G E S
To wrap up the discussion of all the noteworthy browser
security features, we’ll look at a handful of mechanisms
that grant special privileges to sites hand-picked by the
user or hardcoded by the authors of the browser itself.
The approach taken in these cases is in stark contrast to
the schemes we have discussed previously, all of which
rely on a fairly sensible examination of intrinsic properties of the displayed
content. Normally, the implementation would have us look at the source of
the document, the context it is displayed in, or the nature of the operation
that the document is attempting to perform, but barring the outcome of these
checks, the browser would never give preferential treatment to a single other-
wise unremarkable origin.
Per-site privileges violate this principle of impartiality in a fairly brutal
way, for reasons ranging from questionable to—more commonly—just utili-
tarian. There are compelling usability reasons to bring certain inherently
dangerous features to the browser world, but there is no good way to
programmatically decide which web applications are trustworthy enough to
be given access to them. Delegating this task to a human being may be the
best thing we can do.*
Naturally, the creation of a caste of privileged applications can be very
problematic because the boundaries between any two web applications are
not particularly well defined to begin with, making it difficult to contain the
permissions precisely. And because the already imperfect boundaries apply
only to certain cross-site interactions, vulnerabilities such as XSS or XSRF may
further contribute to the misery. In the end, a significant disconnect may
develop between the intent of a per-site permission and the actual conse-
quences of such a grant.
Browser- and Plug-in-Managed Site Permissions
When balancing security, privacy, and usability, browser vendors sometimes
find themselves between a rock and a hard place. Some proposed features
seem essential to the continued growth of the Web but are simply too dan-
gerous to be made available to every website on the Internet. Examples of
such problematic mechanisms include giving access tovideo camera or micro-
phone feeds,† allowing websites to query for user geolocation data,‡ installing
browser extensions or themes, or opening desktop notifications.
As a work-around for this problem, vendors require the user to approve
the application’s request in order for it to be allowed to access a privileged API.
On the first attempt to use restricted functionality, the user is typically pro-
vided with a visual cue (ranging from an icon to a modal prompt) and given
three choices: ignore the request, permit it once, or permanently authorize
the requesting site to access the API. Of these choices, the last one is the most
interesting: If selected, all future access from a matching host will be auto-
matically approved, sometimes without any further visual indication.
NOTE Most whitelists look only at the hostname, and not at the protocol or port. Any entry on
these lists will therefore match more than one SOP origin. In particular, authorizing
https://fuzzybunnies.com/ to access your camera may also authorize the non-
encrypted site at http://fuzzybunnies.com/ to do the same.
Granting websites access to privacy- or security-sensitive features should
be done with care, because, as noted earlier, the implications of doing so
extend beyond merely trusting the authors of the whitelisted application.
* It is fair to complain that browsers do not do much to equip users with affirmative signals about
the trustworthiness of a visited site, even though many robust indicators may plausibly be arrived
at in an automated way. Blacklist-driven attempts to block known malicious sites exist, but given
the negligible cost of registering a new domain (or compromising a random existing one), these
approaches are arguably of less value.
† This functionality is currently supported only by plug-ins, such as Adobe Flash, but on track to
become a part of HTML5.
‡ This API derives user location from parameters such as the current IP address, the list of
nearby wireless networks or cell towers, or the data supplied by a hardware GPS receiver. With
the exception of GPS data, it may be necessary to consult an external service provider to map
these inputs to physical coordinates.
226 Chapter 15
Permission is granted to any content executed in the matching origin, regard-
less of how the payload got there, greatly amplifying the impact of simple (and,
in the long run, inevitable) implementation bugs. A script injection vulnera-
bility in a privileged origin no longer merely exposes the data stored within
the application but may also leak client-originating sensitive data feeds.
Hardcoded Domains
In addition to the list of user-authorized privileged domains, some browsers
or browser plug-ins come with a list of vendor-selected sites or SOP origins
that are given substantial privileges to reconfigure or update portions of the
browser or the operating system. Some of the most prominent examples of
this trend include update.microsoft.com, which is recognized by ActiveX con-
trols that ship with Microsoft Windows and is allowed to install software
updates; addons.mozilla.org and chrome.google.com, recognized by their corre-
sponding browsers and given special privileges to install extensions or themes;
or www.macromedia.com, which is allowed to reconfigure Adobe Flash.
The designs of these mechanisms vary and, as a rule, are not documented
in a satisfactory way. Some features require second-level verification, such as
a cryptographic signature or user consent, but others do not. Broadly speak-
ing, the proliferation of such privileged domains is troubling, because it is
clear that they will not be immune to the usual security problems that plague
the rest of the modern Web. Case in point: http://xssed.com/ lists six publicly
reported XSS vulnerabilities in addons.mozilla.org.1
Form-Based Password Managers
Surprised? Don’t be. Mentioning password managers may seem out of place,
but it is very useful to consider this technology as an indirect form of a site-
bound privilege. Before we explain, let’s briefly review why password manage-
ment is implemented in modern browsers to begin with and how it actually
operates.
The answer to the first question is fairly simple: Today, almost every
major website requires, or at least strongly encourages, all visitors to open an
account. Logging in is typically necessary in order to customize the appear-
ance of the site and is a prerequisite for interacting with other registered
users. Unfortunately, these site-specific authentication systems are not syn-
chronized (save for several limited-scale “federated login” experiments, such
as OpenID),2 and they effectively force the general population to create and
memorize several dozen robust passwords, one for every destination fre-
quented. This approach is difficult to sustain and leads to rampant and dan-
gerous password reuse; that’s where browser vendors decided to step in.
Form-based password managers are an inelegant but pragmatic solution
to the problem of coping with the proliferation of per-site credentials. They
apply simple heuristics to detect the submission of normal-looking login
forms (the browser looks for an  field and then perhaps
examines the names of form fields for strings such as user and pass). When a
suitable form is detected, the browser will offer to save the associated login
Extrinsic Site Privileges 227
information in a persistent store on the hard drive,* and if the user consents,
it will then automatically retrieve and paste this data into matching forms
encountered later on. In Firefox, Chrome, and Safari, the process of retriev-
ing a stored password is automatic; in Internet Explorer and Opera, an addi-
tional user gesture may be required to confirm the intent.
The design of password managers is fragile but has one clear benefit:
Itworks right away even without official support (or, for that matter, informed
consent) from any websites. Web applications that are unhappy about this
feature may opt out by appending a poorly named autocomplete=off parameter
to the offending password field,† but beyond that, the process is almost com-
pletely seamless.
The primary way that every in-browser password manager protects stored
data is by tying the credentials to the SOP origin where they were originally
entered—paying close attention to the hostname, protocol, and port. Some
browsers also consider secondary indicators, such as the ordering or naming
of form fields, the URL path to the form, or the address to which the creden-
tials are sent. (As we know from Chapter 9, such scoping measures are not
particularly useful from the security standpoint due to the operation of the
same-origin policy.)
In browsers that autocomplete login forms without the need for human
interaction, it is sensible to look at the mechanism as a form of a privileged
API: Any content executing in the appropriate origin will be able to request
browser-stored credentials by constructing a believable-looking form and
then waiting for it to be automatically populated with login data. In order to
read back this information, the script merely needs to examine the value
property of the DOM element associated with the password field.
NOTE Removing the ability to inspect values of password fields may seem like a simple way to
improve the scheme, but it is not a very good one. The data could still be stolen by, say,
waiting for password autocompletion, changing the data submission method from
POST to GET, and then calling submit() on the login form. These steps would result
in navigation to a page that has the password plainly visible in the location.search
string. (Plus, many web applications have legitimate uses for reading back these fields
on the client side, for example, to advise on password strength.)
As should be clear, the most serious risk associated with password managers
is the amplification of XSS bugs. In web applications that use httponly cookies,
asuccessful exploitation of an XSS flaw may give the attacker only transient
access to a user’s account, but if the same vulnerability can be leveraged to
steal a user’s password, the consequences are more dire and longer-lived.‡
* This data may be stored on disk as a plaintext representation, a naïvely obfuscated string, or a
properly encrypted value protected with a “master” password that needs to be entered before-
hand. All three methods are comparably vulnerable to determined attackers with access to the
local system, but the plaintext approach is sometimes frowned upon, as it is more exposed to
nosy but nontechnical users.
† Despite the name, this stops the browser from recording the password and not just from
autocompleting it.
‡ Such consequences may extend beyond the affected application: Even with password managers
in place, password reuse is a common, unfortunate trend.
228 Chapter 15
More obscure side effects are possible, too. For example, any application that
allows users to construct custom form-based surveys must carefully restrict the
layout of the generated forms or risk doubling as apassword-harvesting tool.
Internet Explorer’s Zone Model
Internet Explorer’s zone model3 is a proprietary attempt to reconcile the dif-
ferent security requirements that users (or system administrators) may have
for different types of web applications, for example, a banking page and an
online game. Microsoft’s approach is to establish several predefined classes
of websites—known as zones—each with its own set of configurable security
permissions. The five supported zones are these:
 My computer (aka local machine) This hidden zone is used for all local
file: resources (with one exception—more about it soon). The user can-
not add or remove any elements from this set and cannot change its
security settings through the normal user interface. Administrators and
developers can modify the registry or use urlmon.dll hooks to override
settings, however.
 Local intranet This zone is meant to include trusted applications on a
user’s local network. By default, local intranet enjoys many problematic
privileges, such as unrestricted access to the system clipboard, the ability
to open windows without an address bar, or the ability to bypass the usual
frame navigation security checks (the descendant policy, outlined in
Chapter 11). Members of this set are detected automatically using several
configurable heuristics, and they may include destinations with non–fully
qualified hostnames, addresses on the HTTP proxy exemption list,* or
remote file: URLs accessed over SMB. Manual inclusion of sites in this
zone is also possible (in addition to or instead of the built-in heuristics).
NOTE The local intranet zone makes an implicit connection between a local net-
work and a trusted environment. This connection is often dubious in the
modern-day environment, especially given the prevalence of public Inter-
net access over unencrypted Wi-Fi: Other uses of the network are not any
more trustworthy than a random website hosted across the globe.
 Trusted sites These are nominally empty zones roughly equivalent to
local intranet in terms of their security settings but managed solely by the
user. Autodetection heuristics are unavailable, and all entries have to be
created by hand.
 Restricted sites In these nominally empty zones, the user may add
“untrusted” destinations. The default settings for these zones remove
many rudimentary and generally harmless capabilities from the loaded
content (for example, Refresh headers will not work) while offering lim-
ited security benefits.
* In configurations where a proxy is required to access protected internal systems but not
required to access the Internet, these may have the unintended and scary effect of classifying
theentire Web as a local network.
Extrinsic Site Privileges 229
The practicality of this zone seems unclear. Because of the need to
whitelist every untrusted site, the zone obviously can’t be relied upon as
an alternative to browsing the Internet with sensible default settings for
previously unseen destinations.
 Internet This is a default zone for sites not included in any of the
remaining categories. Its default settings match the general browser
security model baseline discussed previously in this book.
The concept of zones, coupled with some of their security controls, seems to
be a step in the right direction. For example, it allows system administrators to
fine-tune the permissions for file: documents without affecting the security
or convenience of normal browsing—or to prohibit Internet sites from navi-
gating to local, corporate systems (using the setting named “Websites in less
privileged web content zone can navigate into this zone”). Unfortunately, the
actual implementation of the zone model is muddied by a lack of focus, and
in practice, it is misused more often than it is genuinely benefited from.
The first problem evident to anyone trying to master the zone mecha-
nism is its obtuse terminology and the almost-comical complexity of many
ofthe settings. Every zone comes with over 100 checkboxes; some of these
will alter the browser security model profoundly, while others have no secu-
rity consequences whatsoever. (The aforementioned Refresh setting is one
example of a security no-op; the ability to disable form submission is another.)
These two classes of settings are not distinguished in any clear way, and many
are nearly impossible to comprehend at a glance. For example, the option
“Binary and script behaviors” can be set to “enable” or “disable,” but the help
subsystem offers no information about what either setting will actually do.
The only explanation is provided in the official developer documentation
posted on Microsoft’s site—but even this document can confuse.4 See for
yourself:
Internet Explorer contains dynamic binary behaviors: components
that encapsulate specific functionality for HTML elements to which
they were attached. These binary behaviors are not controlled by
any Internet Explorer security setting, allowing them to work on
Web pages in the Restricted Sites zone. In Windows Server 2003
Service Pack 1, there is a new Internet Explorer security setting for
binary behaviors. This new setting disables binary behaviors in the
Restricted Sites zone by default. In combination with the Local
Machine Lockdown security feature, it also requires administrative
approval for binary behaviors to run in the Local Machine zone by
default. This new binary behaviors security setting provides a general
mitigation to vulnerabilities in Internet Explorer binary behaviors.
There are many similar cases of settings that require a substantial effort
to understand. For example, it is unlikely that even the most seasoned admin-
istrators will understand the implications of tweaking settings named “Access
data sources across domains” or “Navigate windows and frames across differ-
ent domains”. All this confusion has an interesting consequence: Trusted
parties unintentionally dispense dubious advice. For example, Charles Schwab,
a prominent investment bank, tells customers to disable the frame navigation
230 Chapter 15