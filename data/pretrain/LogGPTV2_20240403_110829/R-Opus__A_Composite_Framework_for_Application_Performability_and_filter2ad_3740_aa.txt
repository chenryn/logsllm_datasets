title:R-Opus: A Composite Framework for Application Performability and
QoS in Shared Resource Pools
author:Ludmila Cherkasova and
Jerome A. Rolia
R-Opus: A Composite Framework for Application
Performability and QoS in Shared Resource Pools
Ludmila Cherkasova
Hewlett-Packard Labs
Palo Alto, CA, USA, 94302
Email: PI:EMAIL
Jerome Rolia
Hewlett-Packard Labs
Palo Alto, CA, USA, 94302
Email: PI:EMAIL
Abstract— We consider shared resource pool management
taking into account per-application quality of service (QoS)
requirements and server failures. Application QoS requirements
are deﬁned by complementary speciﬁcations for acceptable and
time-limited degraded performance. Furthermore, a requirement
speciﬁcation is provided for both the normal case and for the case
where an application server fails in the pool. Independently, the
resource pool operator provides a resource access QoS commit-
ment for two classes of service (CoS). These govern statistical
multiplexing within the pool. A QoS translation automatically
maps application demands onto the resource pool’s CoS to
best enable sharing. A workload placement service consolidates
applications to a small number of servers while satisfying
application QoS requirements. The service reports whether a
spare server is needed or how applications affected by a single
failure can operate according to failure QoS constraints using
remaining servers until the failure can be repaired. A case study
demonstrates the approach.
I. INTRODUCTION
Many enterprises are beginning to exploit
large shared
resource pools in data center environments to lower their
infrastructure and management costs. These environments may
have tens, hundreds, or even thousands of server resources.
Capacity management for resource pools decides how many
resources are needed to support a given set of application
workloads, which applications must be assigned to each re-
source, and per-application scheduling parameters that ensure
appropriate sharing and isolation for the applications. Capacity
management is a challenging task for shared environments
that currently requires signiﬁcant manual effort and tends to
over-provision resources. This article describes our approach
to automate the steps of a capacity self-management system
that best matches resource supply with demand.
Resource pools are collections of resources, such as clusters
of servers or racks of blade servers, which offer shared
access to computing capacity. Virtualization and automation
technologies support the lifecycle management (e.g., creation,
destruction, migration) of resource containers (e.g., virtual ma-
chines, virtual disks [19], [3], [5], [18]). Workload managers
for resources [9], [8], [6] provide containers with time-varying
access to shares of resource capacity. Application workloads
are associated with the containers; the containers are then
assigned to resources in the pool. In this paper we assume
that each container supports exactly one workload.
Applications can make complex demands on such pools. For
example, many enterprise applications operate continuously,
have unique time-varying demands, and have performance-
oriented Quality of Service (QoS) objectives. Resource pool
operators must decide which workloads share speciﬁc re-
sources and how workload managers should be conﬁgured
to support each application. This is a challenge because (i)
the capacity of resource pools are generally overbooked (i.e.,
the sum of per-application peak demands are greater than
the capacity of the pool), (ii) because different applications
can have different QoS requirements that are affected by the
applications’ ability to obtain capacity when needed, and (iii)
because such pools may incur resource failures – resource pool
operators must have a plan to deal with failures and ensure
that their service level agreements remain satisﬁed.
To address these challenges, we propose to replace the stan-
dard capacity management process with a framework named
R-Opus that supports capacity-as-a-service utilities using re-
source pools of servers. R-Opus is a composite framework
with several features that include:
• independently speciﬁed per-application QoS requirements
for normal and failure modes;
• resource pool QoS commitments expressed for classes of
service (CoS);
• QoS translation that maps application resource demands
to resource workload manager allocation priorities that
implement resource pool CoS; and
• a workload placement service for normal and failure
modes.
Application QoS requirements are deﬁned by complementary
speciﬁcations for acceptable and time-limited degraded per-
formance and are speciﬁed for normal and failure modes.
Resource pool QoS commitments quantify the likelihood that
a resource container will receive a unit of capacity when
required. QoS commitments are expressed for each CoS. Each
CoS is associated with a workload manager allocation priority.
The workload placement service consolidates applications to
a small number of resources while satisfying normal and
then failure mode application QoS requirements. The service
reports whether a spare server is needed in case of a single
node failure.
Section II explains our approach to capacity management
for resource pools in more detail. Section III deﬁnes appli-
cation QoS requirements for normal and failure modes. Sec-
tion IV introduces resource pool QoS commitments. Section V
presents methods for automatic QoS translation. The workload
placement service is introduced and explained in Section VI.
A case study is presented in Section VII. Related work is
discussed in Section VIII; summary and concluding remarks
are given in Section IX.
II. CAPACITY MANAGEMENT AND RESOURCE POOLS
This section provides an introduction to resource pool ca-
pacity management. We give an overview of capacity manage-
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:28:03 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 1. Capacity Management Activities and Time Scales.
ment activities, their corresponding timescales, and describe
resource workload managers and the workload placement
service in more detail. We then describe R-Opus and how
it exploits workload managers and the workload placement
service to support per-application QoS requirements.
Figure 1 illustrates capacity management activities for re-
source pools and their different timescales. Long term man-
agement corresponds to capacity planning; the goal here is
to decide when additional capacity is needed for a pool so
that a procurement process can be initiated. Over a medium
timescale (e.g., weeks to months), groups of resource con-
tainers are chosen that are expected to share resources well.
Each group is then assigned to corresponding resources.
Assignments may be adjusted periodically as service levels
are evaluated or as circumstances change (e.g., new appli-
cations must be supported; servers are upgraded, added, or
removed). Once resource containers are assigned to a resource,
a workload manager for the resource [9], [8] adjusts workload
capacity allocations over short
timescales based on time-
varying workload demand. Finally, resource schedulers operate
at the time-slice (sub-second) granularity according to these
allocations. Adjustments to allocations in response to changing
workloads can greatly increase the efﬁciency of the resource
pool while providing a degree of performance isolation for the
containers.
We now describe resource workload managers in more
detail. A workload manager monitors its workload demands
and dynamically adjusts the allocation of capacity (e.g., CPU)
to the workloads, aiming to provide each with access only
to the capacity it needs. When a workload demand increases,
its allocation increases; similarly, when a workload demand
decreases, its allocation decreases. Such managers can control
the relationship between demand and allocation using a burst
factor; a workload resource allocation is determined periodi-
cally by the product of some real value (the burst factor) and its
recent demand. For example, if the measured utilization over
the previous 5 minutes is 66% of 3 CPUs, then the demand is
2 CPU. A burst factor of 2 would cause an allocation in the
next 5 minute interval of 4 CPUs. In this way, a burst factor
guides the application towards a utilization of allocation of
burst factor. In other words, even though the application’s
allocation may vary over time its utilization of allocation
remains somewhat consistent.
1
The burst factor addresses the issue that allocations are
adjusted using utilization measurements. Utilization measure-
ments over any interval are mean values that hide the bursts of
demand within the interval. The product of mean demand for
an interval and this burst factor estimates the true demand of
Fig. 2. R-Opus.
the application at short time scales and is used for the purpose
of allocation. In general, the greater the workload variation
and client population, the greater the potential for bursts in
demand, the greater the need for a larger allocation relative
to mean demand (i.e., utilization), and hence the greater the
need for a larger burst factor.
We assume that the workload manager implements two
allocation priorities that correspond to the resource pool CoS.
Demands associated with the higher priority are allocated ca-
pacity ﬁrst; they correspond to the higher CoS. Any remaining
capacity is then allocated to satisfy lower priority demands;
this is the lower CoS. R-Opus uses these CoS along with
workload placement to manage application QoS.
The workload placement service employs a trace-based ap-
proach to model the sharing of resource capacity for resource
pools [12]. Each application workload is characterized using
several weeks to several months of demand observations (e.g.,
with one observation every ﬁve minutes) for capacity attributes
such as CPU, memory, and disk and network input-output. The
general idea behind trace-based methods is that traces capture
past demands and that future demands will be roughly similar.
We simulate the assignment of multiple application workloads
to a resource and estimate the resulting resource access QoS
that is provided. Placements are found that satisfy resource
access QoS commitments for the historical data. We assume
the resource access QoS will be similar in the near future.
Though we expect demands to change, for most applications
they are likely to change slowly (e.g., over several months).
By working with recent data, we can adapt to such a slow
change. Signiﬁcant changes in demand, due for instance to
changes in business processes or application functionality, are
best forecast by business units; they need to be communicated
to the operators of the resource pool so that their impact can
be reﬂected in the corresponding traces.
Figure 2 illustrates the R-Opus approach to capacity man-
agement for resource pools as supported by such workload
managers and a workload placement service:
• A resource pool operator decides on resource access QoS
commitments for two classes of services for resources in
the resource pool [12]. These speciﬁcations express the
likelihood that a unit of capacity will be available when
needed.
• For each application workload, the application owner
speciﬁes its application’s workload QoS requirement as
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:28:03 UTC from IEEE Xplore.  Restrictions apply. 
an acceptable range for the burst factor. The range corre-
sponds to low and high utilization of allocation targets for
the application. Furthermore, the application is permit-
ted time-limited and bounded performance degradation
beyond the range, e.g., a service level degradation, to
account for spikes in demand that the application owner
does not want to affect capacity sizing.
• A QoS translation takes the independently speciﬁed ap-
plication QoS requirements and the resource access QoS
commitments as input and maps the application’s work-
load demands to allocations for the workload manager’s
two allocation priorities in a manner that assures the
application QoS requirement will be satisﬁed as long as
the resource pool offers the per-CoS QoS it commits to.
• Finally, over the medium term, the workload placement
service [12], [15] assigns application workload resource
containers to resources in the pool in a manner expected
to satisfy the resource access QoS commitments for the
two resource CoS in the pool.
The overall approach assumes that the analysis of application
behaviour as described in the traces is representative of future
behaviour. We rely on historical data to forecast whether
certain applications can co-exist on a resource while satisfying
QoS requirements [12].
III. APPLICATION QOS REQUIREMENTS
The relationship between acceptable application QoS and
system resource usage is complex. We employ an empirical
approach that aims to ﬁnd an acceptable range for the burst
factor that relates workload demand to a scheduled allocation
for CPU capacity. A stress testing exercise is used to submit
a representative workload to the application in a controlled
environment [10]. Within the controlled environment, we
vary the burst factor that governs the relationship between
application demand and allocation. First, we search for the
value of the burst factor that gives the responsiveness required
by application users (i.e., good but not better than necessary).
Next, we search for the value of the burst factor that offers
adequate responsiveness (i.e., a worse responsiveness would
not be acceptable to the application users). These deﬁne
an acceptable range of operation for the application on the
resource and give a preferred range for the utilization of the
allocation for a given application. Similarly, these values can
be chosen or reﬁned in operational environments.
More formally, each QoS requirement has a goal and
constraints with respect to a range of utilization of allocation:
• U low - deﬁnes a utilization of allocation of that supports
ideal application performance 1;
• U high - represents a threshold on utilization of allocation
beyond which the application performance would be
undesirable to users;
• U degr - deﬁnes another threshold on utilization of allo-
cation that can be used for coping with infrequent high
bursts in demand. Typically, these occasional bursts of
demand should not be used for determining the overall
application’s capacity requirements, since they might lead
1Clearly, the utilization of allocation lower than U low also supports the
ideal application performance, however at a price of underutilized (over-
allocated) resources. We use
U low as a burst factor for determining the
relationship between the demand and the required ideal allocation.
1
to signiﬁcant over provisioning and increased conﬁgura-
tion cost.
An application owner can specify application QoS by stating
his/her requirement of acceptable and degraded application
performance. The owner speciﬁes application QoS for two
modes of operation: i) normal mode that means that all planned
resources are available; ii) failure mode that corresponds to the
case of 1-node failure (note that this scenario can be extended
to multiple node failures).
• acceptable performance: for at least M % of measure-
ments, utilization of allocation U alloc should be within
the desirable range, i.e., U low ≤ U alloc ≤ U high;
• degraded application performance: for the remaining
measurements M degr = 100% − M% the utilization
of allocation should not exceed U degr, i.e., U high <
U alloc ≤ U degr. Moreover, T degr speciﬁes the maximum
contiguous time 2 when measured utilization of allocation
U alloc may exceed U high.
A time-limited degradation T degr value relates the speciﬁca-
tion to user experience. While application users may tolerate
intermittent poor performance, e.g., for 5-10 minutes, but
sustained poor performance typically leads to user complaints.
We further bound the utilization of allocation for times of
non-compliance to U degr < 1 to ensure that, in our model,
demands are satisﬁed within their measurement interval.
Consider the following application QoS requirement. Let
U low = 0.5, U high = 0.66, M degr = 3%, U degr = 0.9,
and T degr = 30 minutes. This states that based on the past
history of application demands, we need to tailor the resource
allocation schema for this application to permit no more than
M degr = 3% of measurements in the trace to have utilization
of allocation above U high = 66%. Additionally, these observa-
tions must not have value greater than U degr = 90% and must
not exceed U high = 0.66 for more than T degr = 30 minutes
at a time.
Historical demand values are transformed to time-varying
allocation requirements for the pool using these utilization
of allocation values. The M degr and T degr terms affect the
maximum allocation value for the application.
IV. RESOURCE POOL QOS COMMITMENTS
The resource access QoS commitments speciﬁed by the
resource pool operator govern the degree of overbooking in
the resource pool. We assume that the ﬁrst class of service
offers guaranteed service. For each resource, the workload
placement service ensures that the sum of the per application
peak allocations associated with this higher class of service
does not exceed the capacity of the resource. The second
class of service offers a lower QoS. It is associated with a
resource access probability, θ, that expresses the probability
that a unit of resource capacity will be available for allo-
cation when needed. The workload placement service ﬁnds
workload placements such that both constraints are satisﬁed.
Thus it manages overbooking for each resource (i.e., statistical
multiplexing).
A formal deﬁnition for a resource access probability θ is
as follows. Let C be the number of workload traces under
2An additional constraint on the number of degraded epochs per time pe-
riod, e.g., per day or week, is a useful enhancement. To simplify presentation
we do not consider it in this paper.
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:28:03 UTC from IEEE Xplore.  Restrictions apply. 
consideration. Each trace has W weeks of observations with
T observations per day as measured every m minutes. Without
loss of generality, we use the notion of a week as a timescale
for service level agreements. Time of day captures the diurnal
nature of interactive enterprise workloads (e.g., those used
directly by end users). Other time scales and patterns can also
be used. Each of the T times of day, e.g., 8:00am to 8:05am,
is referred to as a slot. For 5 minute measurement intervals
we have T = 288 slots per day. We denote each slot using an
index 1 ≤ t ≤ T . Each day x of the seven days of the week
has an observation for each slot t. Each observation has an
allocation value for each of the capacity attributes considered
in the analysis. Without loss of generality, consider one class
of service and one attribute that has a capacity limit of L units
of demand. Let Aw,x,t be the sum of the allocations upon the
attribute by the C workloads for week w, day x and slot t.
We deﬁne the measured value for θ as follows.