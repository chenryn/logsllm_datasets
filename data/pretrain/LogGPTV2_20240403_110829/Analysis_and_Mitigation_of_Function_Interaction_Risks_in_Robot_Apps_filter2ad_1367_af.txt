are dozens of nodes in a typical robot app, these nodes work in a
parallel multi-flow mode. To achieve real time, typically each data
flow includes fewer than 10 nodes. So we consider the overhead
of end-to-end latency within 10 coordination nodes. As shown in
Figure 11, the extra latency incurred by 10 coordination nodes is
around 5ms. This is trivial even for the autonomous driving app
with the strongest real-time constraint: according to the industry
standards published by Mobileye [73] and design specifications
from Udacity [14], the latency for processing tragic condition in
an autonomous driving app should be within 100 ms, which is far
larger than the overhead of coordination nodes.
7 CASE STUDIES IN THE REAL WORLD
To demonstrate the practicality of the considered threats and pro-
posed solution, we implement and evaluate several scenarios in a
11
123456789100246CN NumberLatency(ms)RAID ’21, October 6–8, 2021, San Sebastian, Spain
Yuan Xu, Tianwei Zhang and Yungang Bao
physical device, i.e., Turtlebot3. Figure 12 shows our settings and
real-world environment. The Turtlebot3 is an open-source mobile
base equipped with a Raspberry Pi PI:EMAIL, 1 GB memory
and a 360 Laser Distance Sensor (LDS), running ubuntu 16.04 and
ROS kinetic. It is connected to a server (Intel i7 PI:EMAIL with
16GB of RAM) for computation offloading and mission launching.
7.1 Attack Method
We develop two normal tools /tb3_safe_control and tb3_monitor
to monitor and control the robot’s movement. We insert some ma-
licious codes in these tools which send wrong control commands.
The /tb3_safe_control provides commands for safe teleoper-
ation with different input devices. It use LaserScan information
to estimated the distance between the robot and obstacles, and
stop the robot’s movement within a customized safe distance. The
tb3_monitor package provides commands to monitor nodes’ in-
formation and robot’s states in real time. We encapsulate these
tools into two ROS packages and successfully upload them to the
ROS platform as a developer. This validates our threat model that an
adversary can easily share malicious packages in the ROS platform.
Next, we download these two packages as another developer, and
implement them on the Turtlebot device. Below we describe the
malicious behaviors and how our system can mitigate them with
three cases. To avoid raising ethical concerns, we add an extra trig-
ger such that the attacks happen only when the MAC address of
the robot matches a predefined one. This ensures that the malicious
package will not affect normal users.
Figure 13 illustrates the attack and its consequences. The mali-
cious code of GR attack is added in the /tb3_safe_control pack-
age. The malicious codes of RSR and MSR attack are all hidden in
the tb3_monitor package. It’s worth noting that we add specific
triggering logics (Lines 2) in each attack to avoid raising ethical
concerns. The triggering condition is the success match between
the default MAC address and local host MAC address. Since the
MAC address is unique of different devices, the malicious codes can
only work in our robotic devices. Moreover, we set time matching
process to make the attack launch at specific time, other than at
the beginning. This can make attacks more hidden.
Figure 13(a) shows the related code snippets in the GR attack.The
gr_attack function is invoked by a callback function of LaserScan
Topic. In each iteration, the function starts by searching the gr-
related vulnerable node, i.e. ‘move_base’. If exists, it means the
move-related control topic ‘cmd_vel’ exists and the robot is exe-
cuting a navigation task with a great probability. Thus, we send a
Twist-type move command with -0.2 z-axis angular velocity to the
victim topic. This would lead to the robot suddenly turn right and
crash to the obstacles while navigating in a collision-free path.
Figure 13(b) and (c) present the malicious code snippets in the
RSR and MSR attack respectively. Both rsr_attack and msr_attack
functions are invoked while each traversal of all topics of one node.
Specifically, once the ‘control/max_vel’ topic exists, the malicious
process would send a max velocity control command with 2 m/s to
the victim topic. Similarly, if the ‘move_base_simple/goal’ topic
exists, a goal with a malicious location will be launched to the victim
topic and the robot would move to the dangerous destination.
7.2 Evaluation Results
GR Case. The /tb3_safe_control node generates malicious ve-
locity commands during the robot’s navigation at certain moments.
In Figure 12a, the robot plans a straight route in the corridor. During
its movement, the /move_base node computes the real-time veloc-
ity and publishes it to the /cmd_vel topic to drive the robot to the
destination. Due to the shared state between these two nodes, the
malicious node compromises the robot and creates a crash through
publishing continuous “turn right” commands to the shared topic.
In RTron, the developer can choose Preemption policy in the GRCN
and set different priorities to each flow at development stage. Since
this operation is offline, the overhead can be ignored. Then the mali-
cious node is not able to interrupt the normal navigation behaviors
in this case.
MSR Case. The tb3_monitor node sends malicious goal com-
mands during the robot’s navigation at certain moments. As shown
in Figure 12b, it generates a wrong destination in an unstable area
far away from the wireless access point. As part of the compu-
tations is offloaded to the remote server, the robot running into
this area will lose network connection, and malfunction. In our
experiment, after the destination is changed, the robot navigates
into the unstable area and finally stops under the poor network
condition. In RTron, the developer can use position from the /odom
topic to implement a function node to check whether the robot
moves in the unstable area. This node is connected with MSRCN
and marked as an eflow. In this way, any suspicious destination
within the unstable area would be blocked. End user can choose
Block policy in the MSRCN and set different parameters to each
flow at runtime. Since this one-time action is taken when launching
the robot app, the potential overhead does not matter.
RSR case. Considering the potential physical damages caused by
vehicle’s high speeds, the RSR case is implemented in the simulator.
The tb3_monitor node sends malicious max velocity configuring
commands druing the robot’s navigation at specific moments. It
increases the max velocity value through publishing the malicious
messages to the /control_max_vel topic. In Figure 14, the initial
max velocity is 0.22m/s and the robot moves safely. At one moment,
this value is increased to 2m/s. Then the robot moves too fast to
detect the obstacle and a collision occurs. In RTron, we choose
Constrain policy in the RSRCN and set 0.22 to the vflow. In this
way, the max velocity of the robot is fixed at 0.22m/s and cannot
be changed by the attacker.
8 RELATED WORKS
Robotic Security. Existing research on robotic security has mainly
focused on traditional security issues in robot systems, e.g., network
communication [52, 54, 80], denial-of-service attacks [50] and soft-
ware vulnerabilities [57–59, 63, 69]. In addition, adversaries can also
spoof the sensory data ([40, 47, 68, 72, 74, 75, 77, 79, 81, 82, 84, 87]),
fake the actuator signals [46], or tamper with the micro-controller
input [69].
In this paper, we focus on a new type of security issue in robot
apps, caused by malicious interactions. We are the first to demon-
strate the feasibility and severity of this threat, as well as a possible
defense solution against it.
12
Analysis and Mitigation of Function Interaction Risks
in Robot Apps
RAID ’21, October 6–8, 2021, San Sebastian, Spain
Figure 12: GR and MSR experiments on turtlebot3.
i f mac == HOST_MAC :
i f
1 def g r _ a t t a c k ( ) :
2
3
4
5
6
7
cur_time_min == 15 and
n o d e _ e x i s t ( ' move_base ' ) :
t w i s t = Twist ( )
t w i s t . l i n e a r . x = t w i s t . l i n e a r . y
= t w i s t . l i n e a r . z = 0 . 0
. y = 0 . 0
t w i s t . angular . x = t w i s t . angular
t w i s t . angular . z = −0.2
gr_atk_pub = rospy . P u b l i s h (
' cmd_vel ' , Twist ,
q ueu e_ si ze =10)
gr_atk_pub . p u b l i s h ( t w i s t )
8
9
10
11
12
r s r _ a t t a c k ( ) :
i f mac == HOST_MAC :
1 def
2
3
4
i f
:
cur_time_min == 30 and
t o p i c _ e x i s t ( ' c o n t r o l / max_vel ' )
5
6
7
8
9
10
11
12
max_vel = F l o a t 6 4 ( )
max_vel . data = 2
r s r_ a t k _ p ub = rospy . P u b l i s h e r (
' c o n t r o l / max_vel ' , Flo at64 ,
q ueu e_ si ze =1)
r s r_ a t k _ p ub . p u b l i s h ( max_vel )
i f mac == HOST_MAC :
1 def msr_attack ( ) :
2
3
4
i f
cur_time_min == 45 and
t o p i c _ e x i s t ( ' move_base_simple /
goal ' ) :
5
6
7
8
9
10
11
12
13
14
goal = PoseStamped ( )
goal . header . stamp = now ( )
goal . header . frame_id = " map "
goal . pose . p o s i t i o n = MAL_LOC
msr_atk_pub = rospy . P u b l i s h e r (
' move_base_simple / goal ' ,
PoseStamped , q ue ue _s iz e =1)
msr_atk_pub . p u b l i s h ( goal )
(a) Malicious codes of GR attack
(b) Malicious codes of RSR attack
(c) Malicious codes of MSR attack
Figure 13: Malicious codes in our tb3_safe_teleop and tb3_monitor packages.
due to data competition and mobility. (3) For risk mitigation, dif-
ferent from the simple “allow/block” policy adopted in IoT works,
coordination of each type of risks needs a set of different config-
urable policies to mitigate malicious function interactions. All these
distinct features of robot apps require new studies about the risk
analysis and mitigation solutions, as we present in this paper.
9 DISCUSSION AND FUTURE WORK
Graph-based Analysis Scheme. We build graphs to analyze the
interaction risks in robot apps. This graph-based analysis technique
has been used in other appified platforms (e.g., smartphone, IoT and
SDN) to identify potential malicious interaction as well. However,
the potential risks in those platforms are different from robot apps.
In smartphones, attacks occur when the users make uninformed
decisions during app installation, or grant wrong resource requests
without considering the contextual information at runtime [34]. In
SDN, one unprivileged app can trick another privileged app through
the shared control plane [35]. This is similar to GR in robot apps
that one node manipulates the shared states (i.e. topic) to attack the
other. In IoT platforms, the malicious interaction leverages physical
channels to indirectly launch attacks [53]. However, different from
RSR and MSR, the IoT devices do not have the mobility feature,
and the usage scenario is usually restricted (e.g., smart home). In
summary, the malicious interactions in robot apps are more complex
and diverse, adding new challenges for risk analysis.
Policy Design. The security policies in robot apps are different
from those in other domains (e.g., smartphone, IoT and SDN) from
Figure 14: RSR experiment on Turtlebot3 in the simulation.
Interaction Risk Mitigation. Prior works studied the interaction
risks in IoT apps [39, 41, 42, 45, 53, 60, 61, 67, 83, 88]. Users adopt
operation rules following the “If-This-Then-That” (IFTTT) trigger-
action programming paradigm [66, 86] to express automation be-
haviors among IoT devices. These methods translate the rules to
the interaction graph, and verify if conflicts or policy violations
can occur between interactions.
There are three major differences between the interaction risks
of robot apps and IoT apps. (1) For interaction modeling, robot apps
not only inherit all the interactions from IoT apps, but also enjoy
robot-specific ones, e.g., direct interactions via sharing internal
states, indirect interactions caused by mobility. Robot apps need to
cooperate with multiple functions, and require more complicated
rules than the IFTTT model in IoT apps. (2) For risk identification,
IoT apps are implemented by verifying if the interaction between
different rules violates user-defined policies. However, robot apps
have not only such risks (MSR), but also new ones (GR and RSR)
13
Turtlebot3Turtlebot3/move_base: Straight/teleop_twist_keyboard: Turn RightGR NodesPub Topic Name/move_base/cmd_vel/tb3_safe_control/cmd_velGRCN PolicyPreemptionGRCN FlowsParameterflow12flow21(a) GR CaseTurtlebot3UnstableAreaMSR NodesPub Topic Name[Event] /turtlebot3_core/odom[Action] /tb3_monitor/move_base_simple/goalMSRCN PolicyBlockMSRCN FlowsParametereflow1aflow0(b) MSR CaseWireless Access PointUnstableAreaGhost DestOriginalDestinationTurtlebot3RSR NodesPub Topic Name[Max_vel] /tb3_monitor/control_max_vel[Image] /move_base/detect/objectsRSRCN PolicyConstrainRSRCN FlowsParametervflow0.22Turtlebot3/control/max_vel: 0.22m/scollision/control/max_vel: 2m/sRAID ’21, October 6–8, 2021, San Sebastian, Spain
Yuan Xu, Tianwei Zhang and Yungang Bao
two perspectives. First, we adopt distributed coordination nodes for
policy enforcement, rather than centralized permission-based sys-
tems in other domains. This is because the centralized master-based
robot system has been replaced by the distributed P2P system in
the ROS2 due to its single-point-of-failure and real-time constraints.
Second, the policy responses in other platforms are mainly block,
warn or none. This is also applied to the MSR in robot apps. How-
ever, they cannot handle the malicious flows in GR and RSR. New
actions (e.g., coordinating execution order of each flow, adjusting
the data of specific flows) are needed.
As we discuss in § 6.2, there are some regularities to select poli-
cies based on the risk type and domain type of the coordination
node. Thus, while processing a new robot applications, these rules
can help developers to design correct polices for GRCN and pa-
rameters for GRCN and RSRCN. For other polices and parameters,
developers can use our identified information to provide end users
a detailed policy selection instruction. Since the number of RSRCN
and MSRCN is limited, this is not a hard work.