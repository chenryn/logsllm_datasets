searching algorithms onto this table, which always streams the
whole table and avoids a data-dependent access. In summary,
using ORAM-based access, OBLIVIATE will access multiple
blocks belonging to different files and the adversary monitoring
side-channels will remain unaware about the file that was
actually accessed.
OBLIVIATE allows the ORAM tree structure to be config-
urable by the application developer. The application developer
can specify the number of leaf K which determines the number
of files in T1, i.e., tier-1 tree in OBLIVIATE’s ORAM. As each
file is read into T1, OBLIVIATE sets the default data block size D
to be used as 4KB. The value of D is also configurable by the
program developer through separately defined API. As noted,
the value of D is important in minimizing performance overheads
since we would like to access just a single path per read or
write request. The number of Position Maps for the ORAM
8
…79886outputPosition Map…79886InputPosition MapGetting the position of a blockUpdating the position of a block(a) Reading Position Map(b) Updating Position Mapabcdeabcde…realrealdummydummydummyoutputStash…realrealdummydummydummyInputStashAn output block returned to read()An input block from write()(a) Output block(b) Input blockserver storage is always K+1 since we have a Position Map
for each of the K ORAMs and one position map serves as the
filemap mentioned previously.
ORAM Server Placement. A naive solution is to place the
ORAM server within the enclave memory (i.e., EPC), because
this may easily leverage the security guarantee of Intel SGX.
More specifically, since all data stored in EPC is automatically
encrypted by SGX’s memory encryption engine, this design
does not need to employ an additional encryption scheme
as required in the traditional ORAM protocol. However, we
observe this would not a good design choice due to the hardware
resource constraints imposed by SGX. SGX only allows 128 MB
physical memory space for EPC. If an enclave requires more
than 128 MB, the Intel SGX kernel driver [2] can swap-in and
-out memory pages to extend the memory space for the enclave.
The problem is, however, this swap-in and -out forces two
expensive context switches (i.e., from the enclave to the kernel,
and then vice-versa), degrading the performance of an enclave
application as noted by [7, 32].
In order to avoid this issue, OBLIVIATE places the ORAM
server in non-EPC memory with a general encryption scheme.
Because non-EPC memory can be directly accessed from the
enclave execution context (i.e., the ORAM client execution
context), OBLIVIATE encrypts the data blocks through hardware
accelerated AES scheme [37] supported in the x86 architecture.
The above mentioned implementation of AES is constant-time
and therefore side-channel resistant. OBLIVIATE also maintains
a Merkle Hash Tree [27] in order to verify the integrity and
freshness of encrypted data outside the EPC.
To maintain the server storage in a memory friendly format,
OBLIVIATE constructs an array-like structure according to the
pre-configured parameters for the ORAM server structure.
Within this array, each node in tier-1 is placed next to
each other. The nodes further contain smaller ORAM trees
(tier-2 file oram trees). Because the ORAM tree structure
in OBLIVIATE is a complete binary tree, this not only offers
compact representations of the tree but also efficient indexing
of the tree node (i.e., O(1)).
Asynchronous ORAM Server Update. As OBLIVIATE
moves to deploy a filesystem based on ORAM operations, we
observe there is an opportunity to make systematic performance
optimizations. To be more specific, from ORAM’s operational
perspective, both read and write can be divided into three
phases: (a) reading the required ORAM path, (b) processing
the stash, and (c) writing back the ORAM path. Once the
ORAM client completes (a) and (b), the required block has
already been fetched and securely processed.
Therefore, OBLIVIATE does not need to wait until the
completion of phase (c) in order to complete the filesystem
operation and consequently resume the application. Instead,
OBLIVIATE immediately performs the read/write operation
based on the block present in the stash, and employs a separate
worker thread to complete (c) in the background. This offers
an opportunity for OBLIVIATE to leverage the CPU cyles in
an application, which are not related to filesystem operations.
During this period of time, OBLIVIATE can parallelize the
write back to the ORAM path. In §VIII, we provide more
evaluation results of how this optimization technique can
improve performance of real-world applications.
As a result of the design decisions mentioned in this
subsection, OBLIVIATE achieves a performance within 1.5×-
2× of the in-memory filesystem while providing complete
security. §VIII-B provides a more complete breakdown of the
performance benefits achieved through these decisions.
C. Supporting Filesystem Syscall Compatibility
OBLIVIATE supports most of the native filesystem syscalls,
i.e., read, write, close, etc., without requiring any changes
in the enclave application layer. The rest of this section
describes how we provide such compatibility by orchestrating
OBLIVIATE’s client and server storage. It is worth noting
that one restriction of OBLIVIATE is that it does not provide
concurrent access to files over the lifetime of an enclave
application. While this does not introduce security issues, this
can be still considered as OBLIVIATE’s limitation in terms of
functionality, one that we intend to achieve as part of future
work.
Initializing File System. OBLIVIATE initializes all required
data structures, including the client and server storage, before
an enclave application starts execution (i.e., during the loading
time of filesystem library). The configurable parameters such
as number of files K and data-block size D are established using
a manifest file agreed to by the application enclave. Since
these parameters are not security-sensitive for OBLIVIATE,
the manifest file can exist in plaintext. During initialization,
OBLIVIATE creates the client storage (i.e., position maps and
stashes) and server storage (i.e., OBLIVARRAY) according to
the list of provided files. As noted in §VI-B1, this information
is necessary to prevent the untrusted kernel from finding out
which file is currently being accessed by the enclave application.
OBLIVIATE populates the server storage using data from
non-empty files it reads in. Here, it is worth mentioning that we
assume the data is integrity-protected using custom encryption
which can only be decrypted by the secret key within the SGX
enclave. More specifically, OBLIVIATE reads the data in each
regular file per data size, and writes them to the server storage.
This data population is also achieved obliviously. To do so,
we again use cmov to stream through the server storage and
write data blocks at random locations. We present evaluation
in §VIII-B regarding the latency that data population incurs.
open(). The operational semantics of open is to return the file
descriptor based on the provided file path, associated flags and
mode. This file descriptor facilitates all following file system
operations such as read and write. In order to create the file
descriptor, OBLIVIATE first obliviously locates the data block
in the first-tier of the ORAM tree structure (i.e., T1) using the
given filename (i.e., using the filename table in §VI-B2). If the
filename does not exist and O_CREAT is specified, OBLIVIATE
assigns new (empty) block in T1 and adds it to the filename
table with the corresponding filename. It should be noted here
that we over-provision T1 with more leaf than required to
provide support for extra files on-the-fly. Lastly, OBLIVIATE
creates a file descriptor structure, and returns the reference (i.e.,
the file descriptor number) to the enclave application.
read() and write(). For read and write, OBLIVIATE utilizes
read and write operations defined in the ORAM protocol. Using
the parameters of these syscalls including the file descriptor,
9
OBLIVIATE first obtains the block-id in the first-tier of the
ORAM tree structure, T1. Then, OBLIVIATE performs ORAM-
based access (i.e., read from the path to leaf) recursively along
T1-T2 to get to the required block. This process essentially
involves updating both client and server storage multiple times,
but it is secure against page based side channel attacks since
we recursively apply ORAM protocols on each tier.
fsync(). OBLIVIATE also supports fsync requested by the
enclave application. In order to preserve which parts of the
applications have been written to, we simply write-back the
whole file. OBLIVIATE always writes back into the regular
linux file type to support compatibility with other systems or
applications.
close(). close closes a file descriptor, which may or may
not flush the data buffers. This deferred flush does not cause
a consistency issue in the traditional OS, because the OS
implements a global buffer and all file accesses are always
performed using this un-flushed buffer. In the current version of
OBLIVIATE, a final write-back is performed when the library
enclave is terminated. OBLIVIATE can support an encryption
such that written-back files retain their data confidentiality.
OBLIVIATE simply uses the hardware sealing key provide by
SGX as a key for the encryption.
Other syscalls. Based on above four syscall implementations,
we have added most of basic file system related syscalls,
including read, readv, pread, preadv, write, writev, pwrite,
pwritev, lseek, access, stat, etc. We believe the above
syscalls are elemental functions, especially with respect to
securing the file access information, and we were able to run
realistic real-world applications including SQLite. We leave
the implementation of the rest as our future work.
VII.
IMPLEMENTATION
In this section, we describe implementation details of
OBLIVIATE. On the whole, OBLIVIATE’s filesystem library
is implemented on Intel SGX SDK [5], an open-source devel-
opment environment provided by Intel to develop SGX appli-
cations. In terms of implementation complexity, OBLIVIATE’s
trusted service library consists of around 1987 lines of code
whereas the untrusted service consists of 454 lines of code.
At the application enclave side, we modify Graphene’s LibOS
in order to establish the communication channel and exitless
message queues. In total, this required around 685 lines of code
addition to Graphene’s LibOS. It should be mentioned here
that Graphene’s LibOS is just one of the example LibOS that
can be used with OBLIVIATE. Depending on the application,
the developer can choose more TCB-friendly solutions such as
Panoply [44] or even Intel SGX SDK [5].
As dictated by OBLIVIATE’s ORAM tree structure (§VI-B2),
the client storage (position maps and stashes) are stored in an
enclave memory. OBLIVIATE implements and maintains these
data structures in its OBLIVSHIM, which is as an interface
within the trusted service. OBLIVIATE’s trusted service main-
tains the server storage outside the EPC but within the confines
of its application boundary. The test applications, running with
Graphene’s LibOS, direct all syscalls to the trusted service of
OBLIVIATE. At the time of open, the trusted service creates
and maintains the complete file handling information including
Attack
Syscall
Attacking Vectors
File and File-offset
PF/Cache
File-offset
PF/Cache
File
Defense Mechanism of OBLIVIATE
FS metadata in enclave (§VI-C)
ORAM operations (§VI-B2)
Two-tiered ORAM tree (§VI-B2)
PF/Cache
Block-id from position map
Data oblivious schemes (§VI-B1)
PF/Cache
Real/dummy block from stash
Data oblivious schemes (§VI-B1)
TABLE II: A list of attack vectors and their corresponding defense
mechanisms of OBLIVIATE.
file descriptors, file offsets, etc. The trusted service provides
seamless transition from the application’s perspective onto the
server storage.
VIII. EVALUATION
In this section, we begin with a security analysis of
OBLIVIATE. Next, we provide a detailed performance bench-
marking using both benchmarking tools and real-world appli-
cations.
Experimental Setup. All our evaluations were performed on
Intel(R) Core(TM) i7-6600U CPU @ 2.60GHz (Skylake with
4 MB cache) with 16 GB RAM (128 MB for EPC). We ran Ubuntu
16.04 with Linux 4.4.0.59 64-bit. The applications running on
OBLIVIATE employ Graphene LibOS to run but as mentioned
before, OBLIVIATE only uses the Intel SGX SDK [5].
Reference Filesystems. Since porting applications on SGX
without a LibOS is challenging, we do not port applications
into a naive SGX FS (refer §III-A) but present results based
on our experimentation with native (non-SGX) FS (labeled as
Native FS). To gauge the performance of in-memory SGX-
based FS (refer §III-B), we developed a reference in-memory
file system based on Graphene’s LibOS [48] (labeled as In-
memory FS). The hybrid SGX-based file system (refer §III-C)
is the defacto file system used by Graphene LibOS [47, 48]
(labeled as Hybrid FS).
A. Security Evaluation
In order to ascertain the protection of OBLIVIATE against
the side-channel attacks (mentioned in §IV), we provide an
in-depth security analysis followed by experimental evaluation.
Security Analysis. Table II provides a brief overview of
possible attack vectors against OBLIVIATE and the defense
that OBLIVIATE provides to mitigate these attacks. Since all
metadata and file buffer handling is performed by OBLIVIATE
within the enclave, syscall snooping attacks do not leak any
information. The key challenge is how to mitigate the risk of
page fault based and cache-based attacks on OBLIVIATE. As
far as these attacks on the file are concerned, OBLIVIATE’s
security guarantees stem from the security guarantees of ORAM.
ORAM ensures that, regardless of access semantics, each access
exhibits a different memory access traces to an attacker. Because
this is the underlying assumption for both page fault and cache
based attacks, OBLIVIATE is provably secure against these. For
example, consider a victim enclave attempting to access a file
at an offset X twice. An in-memory filesystem would exhibit
the same memory access patterns both times whereas ORAM
10
16M
128M
512M
1G
Open
Populate
Write-back
3,145
1,990
2,967
7,200
5,100
4,900
14,765
7,878
10,907
21,624
12,323
16,635
TABLE III: Performance of open and write-back operations in
OBLIVIATE (in milli-seconds): Open captures the complete time that
it takes to open the file, populate data from original file and allocate
space for Position Map and Stash; Populate is the taken time to
write real blocks to the server storage; Write-back corresponds to