reporting the location of its PoIs. To explore how close two PoIs
can be introduced, CE-Prec chooses a starting point (e.g. (1.0, 1.0))
Figure 1: IIV Analysis Framework.
attempts by manually interacting with the services’ companion
mobile apps, but this would be both tiresome and impractical for
a large number of test inputs. To make things worse, we do not
have white box access to the MCSs and hence we cannot trivially
determine if a service performs input validation.
To overcome these challenges, we present an analysis framework
which can aid with the characterization of the IIV attack surface of
MCSs (Figure 1). While it still requires some manual effort such as
identifying the right APIs (for spoofing network requests) or the
right UI elements (for dynamic execution method), our framework
can significantly speed up the analysis process compared to a com-
pletely manual analysis because it supports range and constraint,
and semantic input exploration strategies, which drive a set of input
injection methods. These methods are designed to quickly identify
the attack surface of a service by fast repeated injections to the ser-
vice compared to a completely manual attacker who has to navigate
the whole application UI by hand for each injected value. Moreover,
since we only have blackbox access to the services, we need a way
to verify the success of an injection attempt. To address this, we
introduce in our framework feedback monitoring mechanisms. Next
we elaborate on each of the framework’s main components.
3.2 Input Exploration Strategies.
Our framework can leverage a wide range of input exploration
strategies. These provide the inputs to be used by the injection
methods. These strategies are also dynamically informed through
feedback monitoring. For our analyses we devised and implemented
three types of strategies supporting range and constraint, and se-
mantic analysis: numeric value exploration strategies, a GPS coordi-
nates exploration strategies and a social post generation strategies.
Numeric Value Exploration (NVE) Strategies. Exploring nu-
meric values, (these can correspond to distance, speed, prices, etc.)
is tedious when performed manually, and in some cases tempo-
rally prohibitive. For example, the range of 32-bit integer values is
−(231 − 1) ≤ x ≤ 231 − 1. A brute force approach is also imprac-
tical. Firstly, most services, to deal with denial of service attacks
and to reduce the load on the server-side, rate limit the requests
made by clients. For example Strava (see Section 4) only allows 50
POST requests per account per day. Some of them (see Section 5)
even blacklist offending clients. Secondly, some experiments (see
946ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Khan, et al.
and explores all combinations of values (0–9) for the rightmost
decimal place for longitude and latitude for a total of 100 injections.
If a failure follows a successful injection (too close to the previous
injection), we reduce the number of decimal points and repeat.
Social Post Generation Strategies. Some services allow their
participants to share semantically meaningful information (see
Section 8). This information is communicated in the form of posts
which can support both text and images. To better understand the
extend of the effectiveness of the semantic validation employed
by such services we devise three fake post generation strategies.
These are designed to explore a target service’s level of semantic
validation: no validation; general natural language understanding;
natural understanding relevant to the service.
• Random Sentence Generation (RSG). The first strategy aims to
explore whether the service accepts any text input without any
semantic validation. To verify that, we generate sentences made of
words randomly sampled from the English dictionary. The sentence
length can be determined by computing the average number of
words in genuine posts collected from the target service.
• Sentence Generation with Pre-trained GPT-2 (SGP). The second
strategy tests posts of semantically similar topics as the extracted
posts and a category label under which they are published or organ-
ised on the service. To do so, SGP leverages the pre-trained model
GPT-2, a state-of-the-art transformer-based model [43] to generate
the text. The model takes keywords as prompts that it will then
complete given its language model. The keywords are selected as
the most common words in a set of genuine posts for each category.
Those keywords also become the title of the posts. For the ones
that get rejected by the service, SGP uses them again but this time
it augments the text with an image. In the first attempt, SGP uses
an image irrelevant to all categories. It then uses the rejected posts
a second time but this time it augments the generated text with a
semantically relevant image. To select relevant images, SGP extracts
the most significant entity from our fake text using Google Cloud
Natural Language API [20] and searches for an image with the
entity as a keyword using “Google Images Download” [18]. It then
selects the first search result as the image to use in the post. Lastly,
SGP uses text+image-accepted posts again but this time augmented
with an image that is irrelevant to all categories.
• Sentence Generation with Adapted GPT-2 (SGA). The third strategy
tests more relevant posts generated by fine-tuning the model [19]
on the set of collected genuine posts. The prompts given to the
model now become the category of posts that are to be generated.
Similarly with the SGP approach, SGA repeats the generated posts
with and without the irrelevant and relevant image.
3.3 Input Injection Methods
MCS companion apps, collect data through sensors and from their
users inputting data in the apps’ UI. This data is then communicated
to the remote services through Internet-exposed APIs. We implement
three methods each targeting in aiding the IIV analysis through each
of those interfaces: the Sensor Spoofing Method facilitates sensor
input analysis; the Dynamic Execution Method facilitates UI input
analysis; and the Network Request Spoofing Method which facilitates
the analysis of inputs directly through the network.
Spoofing Network Requests. For some apps, we need to analyze
their network traffic to extract target requests that can be spoofed
for injecting data to the MCS or to monitor its response. In all
cases, the communication between the app and the service is en-
crypted, hence common tools such as Wireshark will not help. To
address this we use a man-in-the-middle (MITM) proxy and install
its CA certificate on a mobile device. Normally this would have had
been enough to enable observing the target apps traffic in plain-
text but some apps are using mitigation strategies against MITM
attempts and in particular a technique called certificate pinning.
This configures the client app to accept connections only with the
legitimate server. Thus the app under analysis would reject the
proxy certificate. To mitigate this, we use dynamic instrumenta-
tion to target and overload the SSL context initialization function
(SSLContext.init) of the target app at runtime so that it uses the
proxy’s certificate and effectively bypassing the app’s certificate
pinning. Our current implementation uses an extended version of
the Android Frida framework [15] to facilitate the dynamic instru-
mentation. With this setup, we can now run the target app and
monitor the network requests it makes and the service’s responses.
All networking information is logged. This allowed us to reverse
engineer the network-exposed APIs of the target services, which
are filtered to select the ones to be targeted for injection and re-
sponse monitoring. Lastly, we developed a network request spoofer,
which spoofs network requests to the given APIs, emulating the
mobile device, target app, and a user of the service.
Dynamic Execution Method. In some cases, injection experi-
ments require dynamic execution of the apps. Performing this
manually for a large number of input trials might be prohibitively
cumbersome. To address this we use a dynamic execution (DEM)
method powered by record and replay tools to facilitate UI naviga-
tion and interaction. In particular, we employ tools that can monitor
unique IDs of Android app UI elements the user interacts with dur-
ing recording. When an app’s layout is dynamically rendered, the
DEM recorder parses the hierarchy tree of the layout and with
the help of the analyst identifies the IDs corresponding to the UI
elements of interest. Note that it is not mandatory for UI elements
to have IDs or even if they do they are not necessarily unique. To
address this, the DEM recorder also records auxiliary information
related to the UI element of interest such as its position within the
hierarchy tree, the element’s class, and any textual information
(e.g. strings associated with text labels of the element) semantically
describing the element. During replay, a DEM replay component
leverages the android debug bridge to install and launch the app un-
der analysis on an emulator or real device. It then uses the recorded
UI elements’ information and their logical order of execution to
generate UI interaction commands sent through adb to the app.
Like before, if there is a conflict of IDs or absence of them, the DEM
replay looks for semantic hints using regular expressions or exact
matching on strings, class names, and position within the hierarchy
tree to determine which element to emulate an interaction with.
Our current implementation of the tools employed in the DEM
method use extended versions of the Android UIAutomator [5]
during recording and the Appium framework [14] during replay.
Spoofing Sensors. In other cases, we have to spoof sensor mea-
surements. For example, the transportation service Transit, tracks
947Characterizing Improper Input Validation Vulnerabilities of Mobile Crowdsourcing Services
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
bus rides, during which it continuously reports the GPS coordi-
nates of the host device. Manual attacks [45] are possible, yet not
scalable. To address this, we develop a sensor spoofing module that
can be configured to provide fake GPS measurements to a target
device. The module uses the Genymotion shell connected to ex-
ecute commands on a Genymotion Android device emulator [9].
We implement a scheduler which uses the command gps setstatus
enabled to enable GPS readings from the shell. Then it invokes the
sensor spoofing module which uses the gps setlatitude and gps set-
longitude commands to update the GPS coordinates of the emulator
according to a time series of GPS values provided by the scheduler.
The scheduler generates the time series based on different speeds
of movement we want to target (see Section 6).
3.4 Feedback Monitoring.
Since we only have blackbox access to the services, we need a way
to verify the success of an injection attempt. To address this, our
framework uses feedback monitoring mechanisms. We leverage the
fact that most of these services need to provide real-time feedback
to their participants through their mobile apps. Thus, on every in-
put injection attempt, we take feedback from the service through (a)
secondary spoofed network requests, (b) through the UI of the pri-
mary injection device—adversary’s simulated vantage point, or (c)
through secondary observer devices registered to the service with
a different account—safely simulating victim participants. When
feasible, feedback is observed manually. Otherwise, it is facilitated
by our DEM recorder and our MITM tools.
3.5 Analysis Methodology
To better understand the extend of IIV vulnerabilities we focus our
analysis on selected high-profile MCSs spanning various applica-
tion domains. We regard a MCS to be high-profile if it has a wide
userbase and/or it is developed by mature developers/companies.
We choose such MCSs since if they exhibit any IIV vulnerabilities
these would have the potential to affect a large number of users. At
the same time, we expect such MCSs to have a higher responsibility
and the resources to deploy security measures.
To identify representative cases, we searched for relevant apps
using crowdsourcing related keywords on online search engines.
We augment the results by crawling 3259 top free apps from all
Google Play categories. This yielded a total of 3295 relevant apps.
Two researchers then manually and independently rated each app
as either “mobile crowdsourcing” (n=112) app or “other”, resolving
conflicts with a discussion. Subsequently, the relevant apps were
categorized based on their application domain. We identified five
domains: Fitness Activity Services, Pricing Services, Transportation
Services, Location-Based Services and Safety Services. Then, we
cherrypicked at least one representative and previously unexplored
high-profile case for our analysis, resulting in a list of 10 apps
(Table 6 in Appendix B). For each of the cases, we leverage our
framework to characterize their IIV attack surface. Sections 4, 5,
6, 7 and 8 present our characterization experiments and results on
Fitness Activity Services, Pricing Services, Transportation Services,
Location-Based Services and Safety Services respectively.
4 FITNESS ACTIVITY SERVICES
Several MCSs collect fitness information from their participants for
better health and wellness insights. For example, Strava Labs [8]
leverages the large user base of Strava, a service that tracks exercise
activities. Moreover, the information collected is used to enable so-
cial features such as competing with other participants on local and
global challenges. Winners are incentivized with small motivating
rewards. Here we explore how an adversary can poison the data
collected by such popular services, namely, Strava (Section 4), Fitbit
(Appx. A) and Map My Run (Appx. B) and fake a number of activi-
ties, including running, swimming, and cycling, with superhuman
performance in terms of distance covered and speed achieved, al-
lowing them to win challenges and rewards. All experiments below
are launched through spoofed networked requests.
Strava Overview. Strava [7] allows its users to report a number
of physical activities, such as running, cycling, and swimming.
Its Android app is installed by more than 10,000,000 users. For
each of the activities supported, users can report the date and time
duration of the activity and distance covered among others. Using
a fake account, we were able to fake a running activity covering
50,000 km in 3.5 hours which corresponds to a speed of 14,285
km/h . This constitutes a 98.4% increase on the world record for
the fastest aircraft—7,200km/h . To better understand the extent of
these attacks on Strava we design a set of systematic experiments.
Experiment Design. Using our MITM proxy testbed (see Sec-
tion 3) we observed that the Strava app uses a POST request to
submit a new activity to the remote service. The request is bundled
with the activity data in JSON format which can include the activity
date, duration, distance covered, and a description. We run our
experiments by spoofing network requests from a fake account ID
which is created when we create a fake athlete’s profile. In each
trial we use the numeric value exploration strategy ( 3.2) to check
the range of successful injection attacks in terms of distance values
and duration values. Both values are integers. We select the initial
value in the exploration to be 0. To study the effect of different
types of activities in the input validation we repeat the experiment
for 3 types of activities: running, cycling, and swimming.
To detect whether an injection is successful, we leverage another
network API. We observe that Strava responds to a GET request, with
the stored statistics of a specific athlete. Thus, issuing this request
using our fake athlete’s account ID, allow us to check whether the
previous injected value was accepted and stored in our profile by
the service. In doing the experiments we found that Strava only
accepts 50 posts by an athlete per day, irrespective of the activity
posted. After that, it ignores all posts. To overcome this, we spread
our experiments across multiple days.
Results. Firstly we observe that all three exercise types share the
same input domain range boundaries namely (0 to 31,622,400 sec.
and 0 to 50,000,000 meters)— at least they do not accept negative
values. Unequivocally, these boundaries for duration and distance
allow for implausible values. The maximum boundary for the dura-
tion (31,622,400 s) corresponds to a run activity which “took” 8784
hours or 1 year to complete. Considering that the equatorial circum-
ference of the Earth is 40,075 km, a maximum distance of 50,000 km
would correspond to running around the Earth 1.25 times. In terms
948ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Khan, et al.
of the maximum distance an athlete can accumulate, we found this
to have no input range restrictions as Strava accepts 4,294,967,295
meters, which is equivalent to the maximum value an unsigned
32-bit integer can have (232).
An adversary can select values from this range that look plausible
but still unequivocally perform better than the top athletes to fake
activities and finish first on any challenge leaderboard and claim