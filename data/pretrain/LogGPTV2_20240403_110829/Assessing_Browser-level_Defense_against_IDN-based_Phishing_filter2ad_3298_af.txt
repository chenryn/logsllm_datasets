### References

1. **Analysis of the New TLD Land Rush**  
   In: Proc. of IMC, 2015.

2. **Tristan Halvorson, Kirill Levchenko, Stefan Savage, and Geoffrey M. Voelker**  
   *Xxxtortion? Inferring Registration Intent in the .xxx TLD*  
   In: Proc. of WWW, 2014.

3. **Xiao Han, Nizar Kheir, and Davide Balzarotti**  
   *Phisheye: Live Monitoring of Sandboxed Phishing Kits*  
   In: Proc. of CCS, 2016.

4. **D.J. Hauser and N. Schwarz**  
   *Attentive Turkers: MTurk Participants Perform Better on Online Attention Checks than Do Subject Pool Participants*  
   *Behavior Research Methods*, 48:400–407, 2016.

5. **Grant Ho, Aashish Sharma, Mobin Javed, Vern Paxson, and David Wagner**  
   *Detecting Credential Spearphishing in Enterprise Settings*  
   In: Proc. of USENIX Security, 2017.

6. **Tobias Holgers, David E. Watson, and Steven D. Gribble**  
   *Cutting Through the Confusion: A Measurement Study of Homograph Attacks*  
   In: Proc. of USENIX ATC, 2006.

7. **Jason Hong**  
   *The State of Phishing Attacks*  
   *Communications of the ACM*, 55(1), 2012.

8. **Hang Hu and Gang Wang**  
   *End-to-End Measurements of Email Spoofing Attacks*  
   In: Proc. of USENIX Security, 2018.

9. **IETF.org**  
   *Internationalizing Domain Names in Applications (IDNA)*, 2003.  
   [https://tools.ietf.org/html/rfc3490](https://tools.ietf.org/html/rfc3490)

10. **Panagiotis Kintis, Najmeh Miramirkhani, Charles Lever, Yizheng Chen, Rosa Romero-Gómez, Nikolaos Pitropakis, Nick Nikiforakis, and Manos Antonakakis**  
    *Hiding in Plain Sight: A Longitudinal Study of Combosquatting Abuse*  
    In: Proc. of CCS, 2017.

11. **Maciej Korczynski, Maarten Wullink, Samaneh Tajalizadehkhoob, Giovane C. M. Moura, Arman Noroozian, Drew Bagley, and Cristian Hesselman**  
    *Cybercrime After the Sunrise: A Statistical Analysis of DNS Abuse in New gTLDs*  
    In: Proc. of Asia CCS, 2018.

12. **Viktor Krammer**  
    *Phishing Defense Against IDN Address Spoofing Attacks*  
    In: Proc. of PST, 2006.

13. **Brian Krebs**  
    *It’s Way Too Easy to Get a .gov Domain Name*  
    [https://krebsonsecurity.com/2019/11/its-way-too-easy-to-get-a-gov-domain-name/](https://krebsonsecurity.com/2019/11/its-way-too-easy-to-get-a-gov-domain-name/), 2019.

14. **Ponnurangam Kumaraguru, Yong Rhee, Alessandro Acquisti, Lorrie Faith Cranor, Jason Hong, and Elizabeth Nunge**  
    *Protecting People from Phishing: The Design and Evaluation of an Embedded Training Email System*  
    In: Proc. of CHI, 2007.

15. **LambdaTest**  
    *LambdaTest: Cross Browser Testing Cloud*  
    [https://www.lambdatest.com/](https://www.lambdatest.com/), 2020.

16. **Victor Le Pochat, Tom Van Goethem, and Wouter Joosen**  
    *Funny Accents: Exploring Genuine Interest in Internationalized Domain Names*  
    In: Proc. of PAM, 2019.

17. **Eric Lin, Saul Greenberg, Eileah Trotter, David Ma, and John Aycock**  
    *Does Domain Highlighting Help People Identify Phishing Sites?*  
    In: Proc. of CHI, 2011.

18. **Baojun Liu, Chaoyi Lu, Zhou Li, Ying Liu, Hai-Xin Duan, Shuang Hao, and Zaifeng Zhang**  
    *A Reexamination of Internationalized Domain Names: The Good, the Bad and the Ugly*  
    In: Proc. of DSN, 2018.

19. **Meng Luo, Pierre Laperdrix, Nima Honarmand, and Nick Nikiforakis**  
    *Time Does Not Heal All Wounds: A Longitudinal Analysis of Security-Mechanism Support in Mobile Browsers*  
    In: Proc. of NDSS, 2019.

20. **Meng Luo, Oleksii Starov, Nima Honarmand, and Nick Nikiforakis**  
    *Hindsight: Understanding the Evolution of UI Vulnerabilities in Mobile Browsers*  
    In: Proc. of CCS, 2017.

21. **D. Kevin McGrath and Minaxi Gupta**  
    *Behind Phishing: An Examination of Phisher Modus Operandi*  
    In: Proc. of LEET, 2008.

22. **Microsoft**  
    *Changes to IDN in IE7 to Now Allow Mixing of Scripts*  
    [https://docs.microsoft.com/en-us/archive/blogs/ie/changes-to-idn-in-ie7-to](https://docs.microsoft.com/en-us/archive/blogs/ie/changes-to-idn-in-ie7-to), 2006.

23. **Microsoft**  
    *Lifecycle FAQ - Internet Explorer and Edge*  
    [https://docs.microsoft.com/en-us/lifecycle/faq/internet-explorer-microsoft-edge](https://docs.microsoft.com/en-us/lifecycle/faq/internet-explorer-microsoft-edge), 2016.

24. **Paul Mockapetris**  
    *Domain Names - Concepts and Facilities*  
    RFC 1034, 1987.  
    [https://tools.ietf.org/html/rfc1034](https://tools.ietf.org/html/rfc1034)

25. **Tyler Moore and Benjamin Edelman**  
    *Measuring the Perpetrators and Funders of Typosquatting*  
    In: International Conference on Financial Cryptography and Data Security, 2010.

26. **Mozilla**  
    *Firefox IDN Display Algorithm*  
    [https://wiki.mozilla.org/IDN_Display_Algorithm](https://wiki.mozilla.org/IDN_Display_Algorithm), 2017.

27. **NetMarketShare**  
    *Browser Market Share*  
    [https://netmarketshare.com/browser-market-share.aspx](https://netmarketshare.com/browser-market-share.aspx), 2020.

28. **Nick Nikiforakis, Steven Van Acker, Wannes Meert, Lieven Desmet, Frank Piessens, and Wouter Joosen**  
    *Bitsquatting: Exploiting Bit-Flips for Fun, or Profit?*  
    In: Proc. of WWW, 2013.

29. **Adam Oest, Yenganeh Safaei, Penghui Zhang, Brad Wardman, Kevin Tyers, Yan Shoshitaishvili, Adam Doupé, and Gail-Joon Ahn**  
    *Phishtime: Continuous Longitudinal Measurement of the Effectiveness of Anti-Phishing Blacklists*  
    In: Proc. of USENIX Security, 2020.

30. **Adam Oest, Penghui Zhang, Brad Wardman, Eric Nunes, Jakub Burgis, Ali Zand, Kurt Thomas, Adam Doupé, and Gail-Joon Ahn**  
    *Sunrise to Sunset: Analyzing the End-to-End Life Cycle and Effectiveness of Phishing Attacks at Scale*  
    In: Proc. of USENIX Security, 2020.

31. **Peng Peng, Chao Xu, Luke Quinn, Hang Hu, Bimal Viswanath, and Gang Wang**  
    *What Happens After You Leak Your Password: Understanding Credential Sharing on Phishing Sites*  
    In: Proc. of Asia CCS, 2019.

32. **Peng Peng, Limin Yang, Linhai Song, and Gang Wang**  
    *Opening the Blackbox of VirusTotal: Analyzing Online Phishing Scan Engines*  
    In: Proc. of IMC, 2019.

33. **Shahrooz Pouryousef, Muhammad Daniyal Dar, Suleman Ahmad, Phillipa Gill, and Rishab Nithyanand**  
    *Extortion or Expansion? An Investigation into the Costs and Consequences of ICANN’s gTLD Experiments*  
    In: Proc. of PAM, 2020.

34. **Pawan Prakash, Manish Kumar, Ramana Rao Kompella, and Minaxi Gupta**  
    *Phishnet: Predictive Blacklisting to Detect Phishing Attacks*  
    In: Proc. of INFOCOM, 2010.

35. **F. Quinkert, T. Lauinger, W. Robertson, E. Kirda, and T. Holz**  
    *It’s Not What It Looks Like: Measuring Attacks and Defensive Registrations of Homograph Domains*  
    In: Proc. of CNS, 2019.

36. **Anirudh Ramachandran, Nick Feamster, and Santosh Vempala**  
    *Filtering Spam with Behavioral Blacklisting*  
    In: Proc. of CCS, 2007.

37. **P. Resnick and P. Hoffman**  
    *Mapping Characters for Internationalized Domain Names in Applications (IDNA)*  
    RFC 5895, 2008.  
    [https://tools.ietf.org/html/rfc5895](https://tools.ietf.org/html/rfc5895)

38. **Joshua Reynolds, Deepak Kumar, Zane Ma, Rohan Subramanian, Meishan Wu, Martin Shelton, Joshua Mason, Emily Stark, and Michael Bailey**  
    *Measuring Identity Confusion with Uniform Resource Locators*  
    In: Proc. of CHI, 2020.

39. **Richard Roberts, Yaelle Goldschlag, Rachel Walter, Taejoong Chung, Alan Mislove, and Dave Levin**  
    *You Are Who You Appear to Be: A Longitudinal Study of Domain Impersonation in TLS Certificates*  
    In: Proc. of CCS, 2019.

40. **Stuart Schechter, Rachna Dhamija, Andy Ozment, and Ian C. Fischer**  
    *The Emperor’s New Security Indicators: An Evaluation of Website Authentication and the Effect of Role Playing on Usability Studies*  
    In: Proc. of IEEE SP, 2007.

41. **StatCounter**  
    *Browser Market Share Worldwide*  
    [https://gs.statcounter.com/browser-market-share](https://gs.statcounter.com/browser-market-share), 2020.

42. **Hiroaki Suzuki, Daiki Chiba, Yoshiro Yoneya, Tatsuya Mori, and Shigeki Goto**  
    *ShamFinder: An Automated Framework for Detecting IDN Homographs*  
    In: Proc. of IMC, 2019.

43. **Janos Szurdi, Balazs Kocso, Gabor Cseh, Jonathan Spring, Mark Felegyhazi, and Chris Kanich**  
    *The Long "Taile" of Typosquatting Domain Names*  
    In: Proc. of USENIX Security, 2014.

44. **Christopher Thompson, Martin Shelton, Emily Stark, Maximilian Walker, Emily Schechter, and Adrienne Porter Felt**  
    *The Web’s Identity Crisis: Understanding the Effectiveness of Website Identity Indicators*  
    In: Proc. of USENIX Security, 2019.

45. **Ke Tian, Steve T. K. Jan, Hang Hu, Danfeng Yao, and Gang Wang**  
    *Needle in a Haystack: Tracking Down Elite Phishing Domains in the Wild*  
    In: Proc. of IMC, 2018.

46. **Unicode.org**  
    *Unicode Confusables*  
    [https://www.unicode.org/Public/security/8.0.0/confusables.txt](https://www.unicode.org/Public/security/8.0.0/confusables.txt), 2015.

47. **Unicode.org**  
    *Unicode 13.0.0*  
    [https://unicode.org/versions/Unicode13.0.0/](https://unicode.org/versions/Unicode13.0.0/), 2020.

48. **Amber van der Heijden and Luca Allodi**  
    *Cognitive Triaging of Phishing Attacks*  
    In: Proc. of USENIX Security, 2019.

49. **Javier Vargas, Alejandro Correa Bahnsen, Sergio Villegas, and Daniel Ingevaldson**  
    *Knowing Your Enemies: Leveraging Data Analysis to Expose Phishing Patterns Against a Major US Financial Institution*  
    In: Proc. of eCrime, 2016.

50. **W3Counter**  
    *Browser & Platform Market Share*  
    [https://www.w3counter.com/globalstats.php](https://www.w3counter.com/globalstats.php), 2020.

51. **Jingguo Wang, Tejaswini Herath, Rui Chen, Arun Vishwanath, and H. Raghav Rao**  
    *Phishing Susceptibility: An Investigation into the Processing of a Targeted Spear Phishing Email*  
    *IEEE Transactions on Professional Communication*, 55(4):345–362, 2012.

52. **Colin Whittaker, Brian Ryner, and Marria Nazif**  
    *Large-Scale Automatic Classification of Phishing Pages*  
    In: Proc. of NDSS, 2010.

53. **Yue Zhang, Serge Egelman, Lorrie Cranor, and Jason Hong**  
    *Phinding Phish: Evaluating Anti-Phishing Tools*  
    In: Proc. of NDSS, 2007.

54. **Yue Zhang, Jason I. Hong, and Lorrie F. Cranor**  
    *Cantina: A Content-Based Approach to Detecting Phishing Web Sites*  
    In: Proc. of WWW, 2007.

55. **Xudong Zheng**  
    *Phishing with Unicode Domains*  
    [https://www.xudongz.com/blog/2017/idn-phishing/](https://www.xudongz.com/blog/2017/idn-phishing/), 2017.

### Appendix-A: Pilot Studies

To explore the design space, we conducted four pilot studies to experiment with different design choices, as shown in Table 9. We framed the questions slightly differently in each pilot study to prime users to focus on the domain names. Below, we use `bankofamerica.com` as an example website.

#### Pilot Study 1
- **Question**: "Is the domain name shown in the browser address bar `bankofamerica.com`?"
- **Priming**: Medium
- **Answer Type**: Binary (Yes/No) plus "I can’t tell"
- **Error Rate**:
  - Real: 8.75%
  - IDN-Block: 46.25%
  - IDN-Pass: 31.07%
- **Number of Participants**: 20 (600 answers)

#### Pilot Study 2
- **Question**: "Is the domain name shown in the browser address bar `bankofamerica.com`?"
- **Priming**: Medium
- **Answer Type**: 5-point Likert scale ("Very confident it is" to "Very confident it is not")
- **Error Rate**:
  - Real: 1.98%*
  - IDN-Block: 16.67%
  - IDN-Pass: 8.75%*
  - Note: For the Likert scale, the first two points were considered as "Yes."
- **Number of Participants**: 19 (570 answers)

#### Pilot Study 3
- **Question**: "Is the website the real `bankofamerica.com`?"
- **Priming**: Light
- **Answer Type**: Binary (Yes/No) plus "I can’t tell"
- **Error Rate**:
  - Real: 53.29%*
  - IDN-Block: 55.56%
  - IDN-Pass: 22.5%
- **Number of Participants**: 18 (540 answers)

#### Pilot Study 4
- **Question**: "Is `bankofamerl,ca.com` the same as `bankofamerica.com`?"
- **Priming**: Heavy
- **Answer Type**: Binary (Yes/No) plus "I can’t tell"
- **Error Rate**:
  - Real: 39.85%*
  - IDN-Block: 50.79%
  - IDN-Pass: 16.43%
- **Number of Participants**: 20 (600 answers)

### Website Selection

We selected diverse websites from five common categories: "Shopping," "Banking," "Social Networking," "Education," and "Government & Military." For each category, we selected two sets of domains: popular and unpopular. The popular domains were randomly selected from the Chromium top domain list (3 domains per set). In total, we selected 5 × 2 × 3 = 30 domain names.

For each target domain, we generated two homograph IDNs: one that can be blocked by the latest Chrome (IDN-Block) and one that can bypass Chrome’s policy (IDN-Pass). Thus, for each target domain, we had three choices: IDN-Block, IDN-Pass, and the real domain name.

### Pilot Study Results

In April 2020, we conducted the four pilot studies on MTurk. Each participant examined 30 websites. For each website, we randomly chose to display the real, IDN-Block, or IDN-Pass domain name. Each participant could only participate in one of the pilot studies and for only once. Each participant was compensated $1 for their time.

To attract serious workers on MTurk, we used commonly applied filters: we recruited U.S. workers who have an approval rate greater than 90% and have completed more than 50 approved tasks. For each pilot study, we recruited 18–20 participants. In total, we had 77 participants with 2,310 answers (domain names).

In Table 9, we show the error rate for the questions in each study. More specifically, if participants answered "Yes," it means they believed the site was the real site. As such, for real websites, answering "Yes" is correct; for IDN websites, answering "Yes" is incorrect.

Across the four studies, we have two consistent observations:
1. Participants performed well when presented with the real domain names. Across the four pilot studies, users’ error rates are between 1.98% to 16.67%.
2. When displaying homograph IDNs (either IDN-Block or IDN-Pass), there was a large percentage of wrong answers (i.e., a high error rate). For example, when showing IDN-pass, 16.43% – 50.79% of the times users mistook it as the real domain name.

After comparing the results of the pilot studies, we decided to choose the setting of Pilot-1 as our main study for the following reasons:
1. Comparing Pilot-1 and Pilot-2, we did not observe a need to use a 5-point Likert scale as the trend was the same for both conditions, and using the Likert scale can complicate the tasks. Instead, a binary answer (plus "I can’t tell") can reduce the ambiguity.
2. Pilot-3 did not prime users to check the domain names in the address bar. Table 9 shows users were more likely to make mistakes as expected (a lower bound of detection rate). Given that our goal was to test the impact of homograph IDNs, we wanted to examine whether people can identify homograph IDNs when they looked at the domain names. As such, the setting of Pilot-3 was not adopted.
3. Pilot-4 represented the other extreme by over-priming users: forcing users to compare the displayed domain names with the real domain names. Table 9 shows that users had a lower error rate as expected (performance upper bound). However, Pilot-4’s setting is too unrealistic as we cannot expect users to do this when browsing the Internet.

### Appendix-B: Main Study Information

Table 10 shows the demographic information of participants.

| Demographics | Categories | Number of Participants |
|--------------|------------|------------------------|
| **Gender**   | Male       | 139                    |
|              | Female     | 78                     |
| **Age**      | 18-29      | 75                     |
|              | 30-39      | 83                     |
|              | 40-49      | 36                     |
|              | 50 or above| 23                     |
| **Education Level** | High school graduate or less | 18 |
|              | Some college or two-year associate degree | 42 |
|              | Bachelor’s degree | 114 |
|              | Some graduate school | 11 |
|              | Master’s or professional degree | 29 |
|              | Ph.D. | 3 |
| **Browser Use History** | Less than a year | 2 |
|              | 1-3 years | 8 |
|              | 3-5 years | 25 |
|              | More than 5 years | 182 |
| **Computing Background** | Yes | 81 |
|              | No | 130 |
|              | Prefer not to answer | 6 |

*Note: We only include participants who passed the attention check.