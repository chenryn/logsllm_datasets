if(cid:80)m
j=1 µ (xji, usi) = 0
otherwise
(4)
where ¯xi is the mean of the observed values of xi, and mjsi
is calculated as:
mjsi = µ(xji, usi) ∗ xji
(5)
INPUT: Minority training dataset S+ ; majority training
1:
dataset S−; number of non-spam samples to be removed l ;
2: OUTPUT: Re-balanced training dataset.
3: Randomly select l samples from S−, denote the new majority
class as S−
4: S+
B(S+
5: The re-balanced training dataset is: Sn = S+
n
n = Bootstrap examples from S+, s.t (cid:12)(cid:12)S+
n ,(cid:12)(cid:12)S+
(cid:12)(cid:12) = (cid:12)(cid:12)S−
(cid:83) S−
(cid:12)(cid:12) =(cid:12)(cid:12)S−
n = R(S−, l).
(cid:12)(cid:12), S+
(cid:12)(cid:12));
n =
n .
n
n
n
n
Algorithm 1 summarise the spam sample generation process
for fuzzy-based distribution. The synthetic spam samples
are generated in the way of feature by feature, so they keep
very good independence.
3.3 Ensemble with Asymmetric Sampling
In this section, a new asymmetric sampling technique is
proposed to create balanced training data for training a sin-
gle classiﬁer. We apply the under-sampling strategy to the
non-spam class, which randomly remove some samples from
the non-spam class. We apply the over-sampling strategy
to the spam class, which randomly reduplicate the spam
samples. This asymmetric sampling technique can eﬀec-
tively combine the advantages of under-sampling and over-
sampling. Algorithm 2 describes the details of asymmetric
sampling.
Furthermore, we combine asymmetric sampling and boot-
strap to implement an ensemble classiﬁer. As shown in Al-
gorithm 3, we ﬁrst delete l non-spam samples and obtain
samples equals the number of non-spam samples. Finally,
with the ensemble classiﬁers, we apply the majority voting
rule to do the decision making.
Its merits lie in neither
requiring any complex knowledge nor any priori knowledge
[27].
This new detection method uses two diﬀerent training
datasets for ensemble learning.
• One is the original training dataset.
• In the other training dataset, the spam class includes
the original spam samples and the synthetics spam
samples generated by fuzzy-based redistribution.
The ensemble with asymmetric sampling process is conduced
on both of the training datasets. All twitter classiﬁers from
the two training datasets are combined to make the ﬁnal
decision. Our empirical study shows this new method can
eﬀectively address the problem of a small number of imbal-
anced training data.
4. PERFORMANCE EVALUATION
To evaluate the new detection method, we carried out a
number of experiments on a real-world twitter dataset. This
section reports the experiments and results.
S (F ID)
n = B(cid:0)S (F ID)+
(cid:12)(cid:12) =(cid:12)(cid:12)S (F ID)
S (F ID)+
where(cid:12)(cid:12)S (F ID)+
n
−
−
n = R(cid:0)S
, l(cid:1) .
n ,(cid:12)(cid:12)S (F ID)+
(cid:12)(cid:12) =(cid:12)(cid:12)S (F ID)
(cid:12)(cid:12)(cid:1)
(cid:12)(cid:12) means the number of spam
−
n
n
−
n
Then, we make use of bootstrap method to extract the same
number of spam samples as non-spam samples,
4Algorithm 3: New Detection Method
TRAINING
INPUT: Minority training dataset S+ ; majority training
1:
dataset S−; number of non-spam samples to be removed l; size of
ensemble N , C4.5 classiﬁer I.
2: OUTPUT: Ensemble classiﬁerC∗.
3: S(F ID)+
4: for n = 1 to N .
5: S (F ID)+
S (F ID)−
n = F IDoS(S+, 2 ×(cid:12)(cid:12)S+(cid:12)(cid:12));
n ,(cid:12)(cid:12)S (F ID)+
n = B(cid:0)S (F ID)+
n = R(cid:0)S−, l(cid:1).
6:Cn = I(cid:0)S (F ID)+
(cid:1).
−(cid:12)(cid:12)),
+(cid:12)(cid:12) =(cid:12)(cid:12)Sn
+,(cid:12)(cid:12)Sn
(cid:12)(cid:12) =(cid:12)(cid:12)S (F ID)−
n , S (F ID)−
n
(cid:12)(cid:12)(cid:1),
n
n
7: end for
8: for n = N + 1 to 2N .
+ = B(Sn
9: Sn
S−
n = R(S−, l).
10:Cn = I(S+
11: end for
12: C∗ = {Cn, 1 < n < 2N}.
TESTING
n , S−
n ).
1: INPUT:Test data point z.
13: OUTPUT: Class prediction for z.
14: for n = 1to 2N .
15: calculate Cn(z).
16: end for
17: C∗(z) = Aggregation {Cn(z), 1 < n < 2N}.
4.1 Experiment Setup
We ﬁrst introduce the experiment setup for the empirical
study, which includes ground-truth dataset, basic classiﬁers
and performance metrics.
4.1.1 10-day ground-truth dataset
In this work, we used Twitter’s Streaming API to collect
tweets with RULs in a period of 10 consecutive days [11]. Al-
though it is possible to send spam without embedding URLs
on Twitter, the majority of the spam contains RULs [28]. It
is worth mentioning that we have inspected thousands of
spam tweets by hand and only ﬁnd a few tweets that with-
out URLs which could be considered as spam. With the
help of internal tools provided by Trend Micro [11], we to-
tally labelled over 600 million tweets to create the 10-day
ground-truth dataset for the research of spam detection.
Feature extraction is a key component in machine learn-
ing based classiﬁcation tasks [11]. Some studies [1], [12], [18]
have applied a few features which make use of historical in-
formation of a user, such as tweets that the user sent in a pe-
riod of time. While these features may be more discrimina-
tive, it is not possible to collect them due to the restrictions
of Twitter’s API. Other researchers [22], [23] applied some
social graph based features, which are hard to be evaded.
Nevertheless, It is signiﬁcantly expensive to collect those
features, as they cannot be calculated until the social graph
is formed. Thus, those expensive features are not suitable
for real-time detection, despite that they have more discrim-
inative power in separating spammers and legitimate users.
The longer time a spam tweet exists, the more chance it can
be exposure to victims. Thus, it is very important to detect
spam tweets as early as possible. To reduce the loss caused
by spam, real-time detection is in demand. Consequently, we
only focus on extracting light-weight features which can be
used for timely detection. These features can be straight-
forwardly extracted from the collected tweets’ JSON data
structure with little computation. Table 1 summarised the
12 features used in this study.
4.1.2 Base Classiﬁers
In order to examine the eﬀectiveness of the new detection
Table 1: Lightweight Statistical Features
Description
Feature name
The age (days) of an account since its creation
account age
The number of followers of this twitter user
no follower
The number of followings/friends of the user
no following
The number of favorites this user received
no user favorite
The number of lists this twitter user added
no list
The number of tweets this twitter user sent
no tweet
The number of retweets this tweet
no retweet
no hashtag
The number of hashtags included in this tweet
no user mention The number of user mentions included in tweet
no URL
no char
no digits
The number of URLs included in this tweet
The number of characters in this tweet
The number of digits in this tweet
method, a large number of experiments have been conducted
using kNN, SVM, (Support Vector Ma-chines), Naive Bayes,
LDA (Linear Discriminant Analysis), C4.5 Decision Trees
and Random Forest [29], [30]. We found that random for-
est (RF) and C4.5 achieved outstanding performance com-
pared with other classiﬁers. Therefore, we only compare our
method with RF and C4.5 in this paper.
We reported the average of 10 runs of each experiment in
which the datasets are randomly partitioned into the train-
ing data and the testing data. In each experiment, the im-
balance ratio is ﬁxed to 10 and the original training data
contains 1,000 spam tweets and 10,000 non-spam tweets.
The whole dataset is divided to two part, one for generat-
ing training data and the other for generating testing data.
For testing data, we used two settings. In the ﬁrst case, the
rate of spam to non-spam is 10. For example, the testing
data have 500 spam samples and 5,000 non-spam samples.
In the second case, the rate of spam to non-spam is 100.
For example, the testing data includes 100 spam tweets and
100000 non-spam tweets. The diﬀerent settings can help us
simulate diﬀerent real-world scenarios and evaluate the new
method more eﬀectively.
4.1.3 Performance metric
In the experiments, we employed Accuracy (Acc), detec-
tion rate (DR) and Area under the ROC curve (AUC) to
evaluate the performance of the classiﬁers. AUC, which is
not sensitive to the distribution between the majority and
minority classes, can sort models by overall performance.
AUC is often used in models assessment. We used the spam
class as the positive class and the non-spam class as the
negative class. The confusion matrix values are true posi-
tive (TP), false positive (FP), true negative (TN), and false
negative (FN). The following formulas are used to calculate
the metrics.
Acc =
T P + T N
T P + T N + F P + F N
DR =
T P
T P + F N
AU C =
1 + T P
T P +F N + F P
F P +T N
2
(6)
(7)
(8)
Moreover, we used one-factor ANOVA [32] to conduct a
qualitative analysis of the new detection method. The sta-
tistically signiﬁcant level is set at α = 0.05 for all perfor-
mance measures. The ANOVA hypothesis is that there is
no signiﬁcantly diﬀerence for detection techniques in terms
5Figure 4: Impact of twitter spam drift
of AUC. The alternative hypothesis is that at least one is
signiﬁcant diﬀerent. Once the ANOVA results were statisti-
cally signiﬁcant, we performed Tukey’s Honestly Signiﬁcant
Diﬀerence (HSD) test, which indicated the diﬀerent levels of
the resampling techniques’ performance. For Tukey’s HSD
test, we use letter ‘A’ for the ﬁrst class performance, ‘B’
for the second class performance and ‘C’ for the third class
performance.
4.2 Results and Discussion
We report four sets of experimental results here.
• Section 4.2.1 reports the impact of twitter spam drift.
• Section 4.2.2 reports the overall performance through
ANOVA and HSD testing.
• Sections 4.2.3 and 4.2.4 report the day-based detection
performance with the diﬀerent test settings.
Impact of twitter spam drift
4.2.1
Figure 4 illustrates the impact of Twitter spam drift prob-
lem. Precisely, ‘RF model based on day1 data’ means we
used the tweets’ data collected on the ‘ﬁrst day’ to train a
classiﬁcation model and made use of it for 10 days Twitter
spam detection. ‘RF model based on real-time data’ means
we build a classiﬁcation models every day. We used a part
of the same day’s tweets data for classiﬁer training and used
the classiﬁers only on that day to detect Twitter spam. The
same operation was for C4.5.
In the ﬁgure, we can see that the classiﬁers created using
the same day tweets data exhibit outstanding performance,
while the performance of classiﬁers built of using the ‘ﬁrst
day’ tweets data decreased dramatically. For example, the
detection rate of C4.5 with the ﬁrst day training data is
about 0.57 for the ﬁrst day testing data. The detection rate
decreases to only 0.4 for the 6th day testing data.
If we
used the 6th day training data, the detection rate achieved
to 0.65. The diﬀerence is huge. For example, the AUC of RF
for ﬁrst day training and ﬁrst day testing is about 0.77. If we
used the 10th day data for testing, the AUC dramatically
reduced to 0.55. However, for the same day training and
testing, the AUC of RF is up to 0.82 on the 10th day.
The results show the impact of twitter spam drift to de-
tection is very big. Twitter spam drift can aﬀect the spam
detection accuracy and the robustness of the detectors. The
results also suggest the potential solution is to train a twitter
spam detector for each day.
4.2.2 Overall detection performance
Table 2 reports the ANOVA model results for C4.5, RF
01234567891011Day0.10.20.30.40.50.60.7Detection RateRF model based on day1 data C4.5 model based on day1 dataRF model based on real time data C4.5 model based on real time data01234567891011Day0.50.550.60.650.70.750.80.85AUC RF model based on day1 dataC4.5 model based on day1 dataRF model based on real time dataC4.5 model based on real time data6Table 2: ANOVA models for AUC
SoS
MS
F-statistic
Dataset DoF
Day1
Day2
Day 3
Day 4
Day 5
Day 6
Day 7
Day 8
Day 9
Day 10
2
2
2
2
2
2
2
2
2
2
0.0442
0.0282
0.0373
0.0523
0.0347
0.0126
0.0290
0.0318
0.0156
0.0118
0.0220
0.0141
0.0187
0.0261
0.0174
0.0063