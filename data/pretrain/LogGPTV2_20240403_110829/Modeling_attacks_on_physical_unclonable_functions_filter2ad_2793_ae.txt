3
c
/
)
(18)
for some constant 0 < c < 1.
7. RING OSCILLATOR PUFS
7.1 Possible Attacks
There are several strategies to attack a RO-PUF. The
most straightforward attempt is a simple read out of all
CRPs. This is easy, since there are just k(k − 1)/2 = O(k2)
CRPs of interest, given k ring oscillators.
If Eve is able to choose the CRPs adaptively, she can
employ a standard sorting algorithm to sort the RO-PUF’s
frequencies (f1, . . . , fk) in ascending order. This strategy
Method No. of
Oscill.
Pred. Rate
average
CRPs
QS
256
512
1024
99% 99.9% 14,060
99% 99.9% 36,062
99% 99.9% 83,941
28,891
103,986
345,834
Figure 7: Results of 10 trials per data point with
ES for diﬀerent lengths of FF Arbiter PUFs and the
hyperbola ﬁt. HW (cid:3).
Table 8: Quick Sort applied to the Ring Oscillator
PUF. The given CRPs are averaged over 40 trials.
We used HW (cid:3).
246No. of
ML
Bit
Prediction
XORs/Loops Method
Length
Arbiter PUF
XOR Arbiter PUF
Lightweight PUF
FF Arbiter PUF
—
5
5
8
LR
LR
LR
ES
128
128
128
128
Rate
99.9%
99.0%
99.0%
99.0%
CRPs
(×103)
39.2
500
1000
50
Training
Time
2.10 sec
16:36 hrs
267 days
3:15 hrs
Table 9: Some of our main results.
subsequently allows her to predict all outputs with 100%
correctness, without knowing the exact frequencies fi them-
selves. The time and CRP complexities of the respective
sorting algorithms are well known [27]; for example, there
are several algorithms with average- and even worst-case
CRP complexity of NCRP = O(k · log k). Their running
times are also low-degree polynomial.
The most interesting case for our investigations is when
Eve cannot adaptively choose the CRPs she obtains, but still
wants to achieve optimal prediction rates. This case occurs
in practice whenever Eve obtains her CRPs from protocol
eavesdropping, for example. We carried out experiments for
this case, in which we applied Quick Sort (QS) to randomly
drawn CRPs. The results are shown in Table 8. The esti-
mated required number of CRPs is given by
NCRP ≈ k(k − 1)(1 − 2)
2 + (k − 1)
,
(19)
and the training times are low-degree polynomial. Eqn. 19
quantiﬁes limited-count authentication capabilities of RO-
PUFs.
8. SUMMARY AND DISCUSSION
Summary.
We investigated the resilience of currently published elec-
trical Strong PUFs against modeling attacks. To that end,
we applied various machine learning techniques to challenge-
response data generated pseudo-randomly via an additive
delay model. Some of our main results are summarized in
Table 9.
We found that all examined Strong PUF candidates un-
der a given size could be machine learned with success rates
above their in-silicon stability. The attacks require a number
of CRPs that grows only linearly or log-linearly in the inter-
nal parameters of the PUFs, such as their number of stages,
XORs, feed-forward loops or ring oscillators. Apart from
XOR Arbiter PUFs and Lightweight PUFs (whose training
times grew quasi-exponentially in their number of XORs for
large bitlengths k and small to medium number of XORs
l), the training times of the applied machine learning algo-
rithms are low-degree polynomial, too.
While we have presented results only on pseudo-random
CRP data generated in the additive delay model, exper-
iments with silicon implementations [17] [28] have shown
that the additive delay model achieves very high accuracy.
We also showed that the stability of our results against ran-
dom errors in the CRP data is high. Our approach is hence
robust against some inaccuracies in the model and against
measurement noise. In our opinion, it will transfer to the
case where CRP data is collected from silicon PUF chips.
Our results prohibit the use of the broken architectures as
Strong PUFs or in Strong-PUF based protocols. Under the
assumption that digital signals can be probed, they also af-
fect the applicability of the cryptanalyzed PUFs as building
blocks in Controlled PUFs and Weak PUFs.
Discussion.
Two straightforward, but biased interpretations of our
results would be the following:
(i) All Strong PUFs are
insecure.
(ii) The long-term security of electrical Strong
PUFs can be restored trivially, for example by increasing
the PUF’s size. Both views are simplistic, and the truth is
more involved.
Starting with (i), our current attacks are indeed suﬃcient
to break most implemented PUFs. But there are several
ways how PUF designers can ﬁght back in future implemen-
tations. First, increasing the bitlength k in an XOR Arbiter
PUF or Lightweight Secure PUF with l XORs increases the
eﬀort of the presented attacks methods as a polynomial func-
tion of k with exponent l (in approximation for large k and
small or medium l). At the same time, it does not worsen
the PUF’s stability [28]. For now, one could therefore dis-
able attacks through choosing a strongly increased value of k
and a value of l that corresponds to the stability limit of such
a construction. For example, an XOR Arbiter PUF with 8
XORs and bitlength of 512 is implementable by standard
fabrication processes [28], but is currently beyond the reach
of our attacks. Similar considerations hold for Lightweight
PUFs of these sizes. Secondly, new design elements may
raise the attacker’s complexity further, for example adding
nonlinearity (such as AND and OR gates that correspond
to MAX and MIN operators [17]). Combinations of Feed-
Forward and XOR architectures could be hard to machine
learn too, partly because they seem susceptible only to dif-
ferent and mutually-exclusive ML techniques.
Moving away from delay-based PUFs, the exploitation of
the dynamic characteristics of current and voltage seems
promising, for example in analog circuits [29]. Also special
PUFs with a very high information content (so-called SHIC
PUFs [30, 31, 32]) could be an option, but only in such appli-
cations where their slow read-out speed and their compara-
tively large area consumption are no too strong drawbacks.
Their promise is that they are naturally immune against
modeling attacks, since all of their CRPs are information-
theoretically independent. Finally, optical Strong PUFs, for
example systems based on light scattering and interference
phenomena [1], show strong potential in creating high input-
output complexity.
Regarding view (ii), PUFs are diﬀerent from classical cryp-
toschemes like RSA in the sense that increasing their size
often likewise decreases their input-output stability. For ex-
ample, raising the number of XORs in an XOR Arbiter PUF
has an exponentially strong eﬀect both on the attacker’s
complexity and on the instability of the PUF. We are yet
unable to ﬁnd parameters that increase the attacker’s ef-
247fort exponentially while aﬀecting the PUF’s stability merely
polynomially. Nevertheless, one practically viable possibil-
ity is to increase the bitlength of XOR Arbiter PUFs, as
discussed above. Future work will have to show whether the
described large polynomial growth can persist in the long
term, or whether its high degree can be diminished by fur-
ther analysis.
Future Work.
The upcoming years will presumably witness an intense
competition between codemakers and codebreakers in the
area of Strong PUFs. Similar to the design of classical cryp-
toprimitives, for example stream ciphers, this process can
be expected to converge at some point to solutions that are
resilient against the known attacks.
For PUF designers, it may be interesting to investigate
some of the concepts that we mentioned above. For PUF
breakers, a worthwhile starting point is to improve the at-
tacks presented in this paper through optimized implemen-
tations and new ML methods. Another, qualitatively new
path is to combine modeling attacks with information ob-
tained from direct physical PUF measurements or from side
channels. For example, applying the same challenge multi-
ple times gives an indication of the noise level of a response
bit. It enables conclusions about the absolute value of the
ﬁnal runtime diﬀerence in the PUF. Such side channel infor-
mation can conceivably improve the success and convergence
rates of ML methods, though we have not exploited this in
this paper.
Acknowledgements
This work was partly supported by the Physical Cryptogra-
phy Project of the Technische Universit¨at M¨unchen.
9. REFERENCES
[1] R. Pappu, B. Recht, J. Taylor, and N. Gershenfeld.
Physical one-way functions. Science, 297(5589):2026,
2002.
[2] B. Gassend, D. Clarke, M. Van Dijk, and S. Devadas.
Silicon physical random functions. In Proceedings of
the 9th ACM Conference on Computer and
Communications Security, page 160. ACM, 2002.
[3] Blaise Gassend, Dwaine Clarke, Marten van Dijk, and
Srinivas Devadas. Controlled physical random
functions. In Proceedings of 18th Annual Computer
Security Applications Conference, Silver Spring, MD,
December 2002.
[4] J. Guajardo, S. Kumar, G.J. Schrijen, and P. Tuyls.
FPGA intrinsic PUFs and their use for IP protection.
Cryptographic Hardware and Embedded Systems-CHES
2007, pages 63–80, 2007.
Alessandro Acquisti, Sean W. Smith, and
Ahmad-Reza Sadeghi, editors, TRUST, volume 6101
of Lecture Notes in Computer Science, pages 430–440.
Springer, 2010.
[9] G.E. Suh and S. Devadas. Physical unclonable
functions for device authentication and secret key
generation. Proceedings of the 44th annual Design
Automation Conference, page 14, 2007.
[10] M. Majzoobi, F. Koushanfar, and M. Potkonjak.
Lightweight secure pufs. In Proceedings of the 2008
IEEE/ACM International Conference on
Computer-Aided Design, pages 670–673. IEEE Press,
2008.
[11] B. Gassend, D. Lim, D. Clarke, M. Van Dijk, and
S. Devadas. Identiﬁcation and authentication of
integrated circuits. Concurrency and Computation:
Practice & Experience, 16(11):1077–1098, 2004.
[12] J.W. Lee, D. Lim, B. Gassend, G.E. Suh,
M. Van Dijk, and S. Devadas. A technique to build a
secret key in integrated circuits for identiﬁcation and
authentication applications. In Proceedings of the
IEEE VLSI Circuits Symposium, pages 176–179, 2004.
[13] D. Lim, J.W. Lee, B. Gassend, G.E. Suh,
M. Van Dijk, and S. Devadas. Extracting secret keys
from integrated circuits. IEEE Transactions on Very
Large Scale Integration Systems, 13(10):1200, 2005.
[14] Daniel E. Holcomb, Wayne P. Burleson, and Kevin Fu.
Initial sram state as a ﬁngerprint and source of true
random numbers for rﬁd tags. In In Proceedings of the
Conference on RFID Security, 2007.
[15] S.S. Kumar, J. Guajardo, R. Maes, G.J. Schrijen, and
P. Tuyls. Extended abstract: The butterﬂy PUF
protecting IP on every FPGA. In IEEE International
Workshop on Hardware-Oriented Security and Trust,
2008. HOST 2008, pages 67–70, 2008.
[16] P. Tuyls, G.J. Schrijen, B. ˇSkori´c, J. van Geloven,
N. Verhaegh, and R. Wolters. Read-proof hardware
from protective coatings. Cryptographic Hardware and
Embedded Systems-CHES 2006, pages 369–383, 2006.
[17] Daihyun Lim. Extracting Secret Keys from Integrated
Circuits. Msc thesis, MIT, 2004.
[18] Erdin¸c ¨Ozt¨urk, Ghaith Hammouri, and Berk Sunar.
Towards robust low cost authentication for pervasive
devices. In PerCom, pages 170–178. IEEE Computer
Society, 2008.
[19] M. Majzoobi, F. Koushanfar, and M. Potkonjak.
Testing techniques for hardware security. In
Proceedings of the International Test Conference
(ITC), pages 1–10, 2008.
[20] Jan S¨olter. Cryptanalysis of Electrical PUFs via
Machine Learning Algorithms. Msc thesis, Technische
Universit¨at M¨unchen, 2009.
[5] B.L.P. Gassend. Physical random functions. Msc
[21] C.M. Bishop et al. Pattern recognition and machine
thesis, MIT, 2003.
learning. Springer New York:, 2006.
[6] R. Pappu. Physical One-Way Functions. Phd thesis,
[22] M. Riedmiller and H. Braun. A direct adaptive
MIT, 2001.
[7] P. Tuyls and B. Skoric. Strong Authentication with
PUFs. In: Security, Privacy and Trust in Modern
Data Management, M. Petkovic, W. Jonker (Eds.),
Springer, 2007.
[8] Ulrich R¨uhrmair. Oblivious transfer based on physical
unclonable functions (extended abstract). In
method for faster backpropagation learning: The
RPROP algorithm. In Proceedings of the IEEE
international conference on neural networks, volume
1993, pages 586–591. San Francisco: IEEE, 1993.
[23] http://www.pcp.in.tum.de/code/lr.zip, 2010.
[24] T. B¨ack. Evolutionary algorithms in theory and
248practice: evolution strategies, evolutionary
programming, genetic algorithms. Oxford University
Press, USA, 1996.
[25] H.P.P. Schwefel. Evolution and Optimum Seeking: The
Sixth Generation. John Wiley & Sons, Inc. New York,
NY, USA, 1993.
[26] T. Schaul, J. Bayer, D. Wierstra, Y. Sun, M. Felder,
F. Sehnke, T. R¨uckstieß, and J. Schmidhuber.
PyBrain. Journal of Machine Learning Research,
1:999–1000, 2010.
[27] C.H. Papadimitriou. Computational complexity. John
Wiley and Sons Ltd., 2003.
[28] S. Devadas. Physical unclonable functions and secure
processors. In Workshop on Cryptographic Hardware
and Embedded Systems (CHES 2009), September 2009.
[29] G. Csaba, X. Ju, Z. Ma, Q. Chen, W. Porod,
J. Schmidhuber, U. Schlichtmann, P. Lugli, and
U. R¨uhrmair. Application of mismatched cellular
nonlinear networks for physical cryptography. In 12th
IEEE CNNA - International Workshop on Cellular
Nanoscale Networks and their Applications. Berkeley,
CA, USA, February 3 - 5 2010.
[30] U. R¨uhrmair, C. Jaeger, M. Bator, M. Stutzmann,
P. Lugli, and G. Csaba. Applications of high-capacity
crossbar memories in cryptography. To appear in
IEEE Transactions on Nanotechnology, 2010.
[31] U. R¨uhrmair, C. Jaeger, C. Hilgers, M. Algasinger,
G. Csaba, and M. Stutzmann. Security applications of
diodes with unique current-voltage characteristics. In
Lecture Notes in Computer Science, volume 6052,
Tenerife (Spain), January 25 - 28 2010. 14th
International Conference on Financial Cryptography
and Data Security, Springer.
[32] C. Jaeger, M. Algasinger, U. R¨uhrmair, G. Csaba, and
M. Stutzmann. Random p-n-junctions for physical
cryptography. Applied Physics Letters, 96(172103),
2010.
249