TrueAlerts
ex(cid:1)ltration
co m m and-and-control
execution
persistence
discovery
credential-access
Fig. 14: Number of matched MITRE ATT&CK tactics during our
evaluation.
Figure 14 shows the tactics to which the alerting techniques
in our data belong. During evaluation, we observed 10 out of
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:41:13 UTC from IEEE Xplore.  Restrictions apply. 
1186
the 12 tactics deﬁned by MITRE ATT&CK. As is evident
from the graph, there are certain tactics, such as “Exﬁltration”
and “Defense Evasion”, are more false-positive prone. Others,
such as “Discovery”, still have many false alarms, but have a
more balanced distribution.
]
l
d
e
a
c
s
-
g
o
l
[

t
n
u
o
C
Edges
Vertices
1x107
1x106
100000
10000
1000
Hosts
Fig. 15: Number of vertices and edges in the provenance graph for
each of 34 hosts in our evaluation.
Figure 15 shows the number of vertices and edges in prove-
nance graph database for each of 34 hosts in our evaluation.
We see that all hosts have a similar number of edges and
vertices except for two hosts. From these two hosts, we had
only few hours worth of logs.
APPENDIX B
GRAPH REDUCTION ALGORITHM
We describe two rules for alert correlation preserving graph
reduction in Section VI. Here we present our efﬁcient graph
reduction algorithm that removes edges and vertices from the
graph according to those two rules.
Function REDUCEGRAPH in Figure 16 is the main function
that takes the input provenance graph G and deletes edges and
vertices from G. We loop over each edge e in G and extract
actor vertex vproc which is always a process vertex and target
vertex vtarget which can be either a process or an object vertex.
First of all we check that if edge e is an alert event. If e is
an alert event then we ignore this edge. Then, we check that
if vtarget is a registry type because we do not delete registry
events during our reduction as we discussed in Section VI.
if there are any outgoing or in-
Then, we check that
going edges of vtarget
that are alert events (Function
CHECKALERTINOUT in Figure 16). If there is an alert event
then we continue to next edge because this vtarget with edge
e cannot be deleted to preserve alert correlations.
After that we check that if vtarget is a process type vertex.
In which case, we apply Rule#2 described in Section VI where
we check that if vtarget is terminated. If it is not terminated
we do not delete vtarget vertex and corresponding edge e and
continue to next edge from G. After that we check if vtarget
is a registry type vertex then we do not remove that vertex.
Then, we check that vtarget is a network type vertex and the
outgoing IP address is an internal IP address that belongs to
other host within the enterprise. If that is the case then we do
not remove such vertex. The reason why we do not remove
such network vertices is described in Section VII.
For our underlying EDR, there are certain events that will
not be part of any TPG because these events do not generate
information ﬂow between alerts. For example, our underlying
EDR only tracks Module read operation for performance
purposes. Since, it does not capture write operation there will
be no information ﬂow from one process to another process
using module vertex. Similarly, connections made outside the
enterprise network also do not generate information ﬂow to
another machine in the enterprise network. We simply remove
these events during our graph generation without losing any
alert connectivity information. Function CHECKSAFETORE-
MOVE in Figure 16 handles these cases.
After we have performed above-mentioned checks, we add
current edge in a Hashmap P rocM ap. In this hashmap, key is
an actor process vertex vproc and value is a priority queue of
edges that are directly connected to the vproc. The priority is
based on descending order of timestamps present on edges. We
use this hashmap to reduce the number of calls on backward
tracing on target vertices of edges. The key idea is that we poll
an edge elatest from priority queue which will return the latest
happened edge (event) from the buffer. We then call backward
tracing function on target vertex vtarget from that edge elatest.
If we do not ﬁnd any alert in the backward trace of vtarget then
we can safely remove all the edges in the priority queue of
key vertex vproc since their backward trace will also not have
any alerts. Function CHECKALERTBACKTRACE and Function
BACKWARDDFS in Figure 16 performs backward tracing on
input vertex.
One precondition to performing above optimization is that
we need to ensure that
target vertices in the buffer have
incoming edges from the same key vertex vproc (Function
CheckAllInSame in Figure 16). If this condition is not true
we have to perform backward tracing on that target vertex
because there can be another path besides vproc which can
lead to alert. After deleting the edges from graph, we delete
all the vertices that now have no incoming or outgoing edges
using Function DeleteIsolatedVertices.
APPENDIX C
ADDITIONAL EXPERIMENTAL RESULTS
Table I summarizes the ranking of top 16 threat scoring
TPGs out of total 681 TPGs in our evaluation. This list
contains all the 5 truly malicious TPGs that are present in our
evaluation. In this table, the ﬁrst column represents the root
vertex ID given by RapSheet. Recall that TPG is identiﬁed
by the IIP root vertex. The second column shows where the
TPG was a false alarm or truly malicious. The third column
shows the threat score given by RapSheet to the TPG. The
fourth column shows the number of threat alerts present in
the corresponding TPG. Finally, the ﬁfth column represents
the longest ordered sub-sequence extracted by RapSheet from
the TPG that gave the highest threat score.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:41:13 UTC from IEEE Xplore.  Restrictions apply. 
1187
1: function REDUCEGRAPH(G )
2:
P rocM ap ← {}, hashmap from vertex to timestamp-based priority queue of
edges connected to vertex
for all e : E do
type ← GetType(e)
vproc ← GetProcVertex(e), get process vertex
vtarget ← GetTargetVertex(e), get target vertex
t ← GetTime(e), return timestamp on edge
// From Rule No. 1 & 2
if type is an alert event then
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:
35:
36:
37:
38:
39:
40:
41:
42:
43:
44:
45:
46:
continue
// From Rule No. 1 & 2
if CHECKALERTINOUT(vtarget) then
continue
// From Rule No. 2
if vtarget is a process and vtarget not terminated then
continue
// Exception that we described in Section VI
if vtarget ∈ registry then
continue
// Do not remove connections made to hosts within enterprise
if vtarget ∈ network and has an internal IP address then
if CHECKSAFETOREMOVE(vtarget, type) then
continue
DeleteEdge(G, e)
continue
for all vproc, queue ← P rocM ap.entries do
P rocM ap.put(vproc, queue.push(e))
fsame ← F alse, ﬂag to show edges coming in from same process
ff lush ← F alse, ﬂag to remove rest of queue without backtracking
while queue (cid:5)= ∅ do
elatest ← queue.pop()
vtarget ← GetTargetVertex(elatest)
fsame ← CheckAllInSame(vproc, vtarget)
if fsame then
continue
if not ff lush and CHECKALERTBACKTRACE(vtarget, t) then
ff lush ← T rue
DeleteEdge(G, elatest)
else
if CHECKALERTBACKTRACE(vtarget, t) then
continue
DeleteEdge(G, elatest)
// Deletes vertices from G that have no incoming or outgoing edges
DeleteIsolatedVertices(G)
// Return skeleton graph
return G
return T rue
47: function CHECKSAFETOREMOVE(vtarget, type)
48:
49:
50:
51:
52:
53:
if vtarget ∈ module or kernel then
if vtarget ∈ network and has an external IP address then
if type ∈ F ileDelete then
return T rue
return T rue
for all einout : getInOutEdges(vtarget) do
54: function CHECKALERTINOUT(vtarget)
55:
56:
57:
58:
if einout is an alert event then
return F alse
return T rue
59: function CHECKALERTBACKTRACE(v,t)
Seen ← ∅, set of seen vertices during traversal
60:
d ← 0, current depth in DFS traversal
61:
62:
return BACKWARDDFS(v, d, t, seen)
f lag = F alse, return ﬂag true if we see an alert during traversal
if d ≥ maxdepth then
return f lag
return T rue
// returns edges going out of the given vertex
edgesout ← getOutEdges(v)
// ﬁlter edges which happened before given time
edgesout ← FilterAfter(outedges, t)
for all edgeout : edgesout do
if edgeout is an alert event then
63: function BACKWARDDFS(v,d,t,seen)
64:
65:
66:
67:
68:
69:
70:
71:
72:
73:
74:
75:
76:
77:
78:
79:
80:
81:
82:
83:
84:
85:
86:
87:
88:
89:
90:
for all edgein : edgesin do
tin ← GetTime(edgein)
// Returns tail of directed edge
vout ← GetOutVertex(edgein)
if vout /∈ seen then
if edgein is an alert event then
// returns edges going in the given vertex
edgesin ← getInEdges(v)
// ﬁlter edges which happened before given time
edgesin ← FilterAfter(inedges, t)
for all edgein : edgesin do
return T rue
return f lag
break
// Recursive call
f lag ← BACKWARDDFS(vout, d + 1, tin, seen)
if f lag then
Fig. 16: Efﬁcient algorithm to perform graph reduction on given provenance graph G and generate skeleton graph. We set maximum depth
(maxdepth) of backward DFS traversal in our experiments to 6.
TABLE II: Summary of observed space overheads for our attack
simulations. “#E” and “#V” mean the number of edges and vertices
respectively.
Scenario
APT29
APT3
CALDERA
Raw Prov. Graph
#V
1,541
15,979
247
#E
2,342
22,645
1,029
IIP Graph
#V
#E
31
30
15
14
49
50
#E
12
5
19
TPG
#V
13
6
20
Note that the highest threat score was given to a benign or
false alarm TPG. This is an interesting case which shows the
limitation of our approach that a high threat score is given to a
sequence of actions that match MITRE kill chain even if such
sequence is performed for a benign or legitimate purpose. In
this case, we found that a company employee compressed a
bunch of sensitives ﬁles on different hosts and then transferred
them to the company’s external data-hosting website. Even
though no attack was performed in this case, this whole course
of actions by employee matched, in order, to different tactics
from MITRE ATT&CK which led to a higher threat score.
APPENDIX D
ADDITIONAL CASE STUDY
The size of the raw provenance graphs, IIP graphs, and
TPGs in terms of total number of vertices and edges for
all
three APT attack cases we used in our evaluation is
summarized in Table II. TPG size is shown after applying
our readability pass.
In addition to the two simulations of actual advanced adver-
sary groups that were performed by red teams, we performed
our own third campaign using a conﬁgurable, automated
attack emulation framework called CALDERA [67] which is
maintained by MITRE. CALDERA provides a client “mal-
ware” agent and a command-and-control server that agents
can communicate with to receive commands to execute on the
infected machines.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:41:13 UTC from IEEE Xplore.  Restrictions apply. 
1188
TABLE I: Top 16 threat scoring TPGs out of total 681 TPGs.
TPG ID
Category
052c89
e431ac
69f88c
2e91b2
c17d94
9b1f4a
3f3fa5
08f25f