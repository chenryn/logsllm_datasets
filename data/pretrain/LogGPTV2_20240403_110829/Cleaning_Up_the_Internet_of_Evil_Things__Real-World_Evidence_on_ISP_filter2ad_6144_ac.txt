only notiﬁcations are not.
B. Impact of notiﬁcation content
To investigate if the improved notiﬁcation content made a
difference, we compared the remediation rates of the walled
garden group in the experiment to that in the observational
study. Remember, the customers in the observational study
Figure 4: Diagram of the randomized controlled experiment
possible for an infected device to not be seen for a few days
in the Shadowserver, IoTPOT and darknet data. This can be
caused by a range of reasons, including temporary network
disruptions, behavior of the malware or the infected device.
(We discuss these limitations in Section IX.)
Without additional safeguards, the missing observations
during the 14-day period that we track the infections could
easily lead us to overestimate the remediation rate. To mitigate
this issue, we include a safeguard. After the 14 days, we
monitor the infection data sources for an additional 21 days
for recurring observations of the customers that were in the
experiment. If we see a customer again in this period, we
will assume that he has not remediated during the 14 day
period. For 34 (15%) of all customers, we collected one or
more infection observations in the 21 day period. We therefore
set their status to not remediated – i.e., still infected – at the
end of the 14 days.
Our conservative approach has one downside: within the
period of 35 days (14+21), we treat every observation in
the Shadowserver, IoTPOT and darknet data as evidence that
the infection persists. In reality, some of these cases will be
reinfections of devices that had been clean for a short period,
rather than continuously infected. In other words, within this
period of 35 days we cannot distinguish between infection and
reinfection. To reliably measure reinfection rates, we therefore
turned to the customers from the observational study. We
continuously monitored our data sources for the IP addresses
associated with these customers for ﬁve months after the
observational study period ended in October 2017. If at any
point between November 2017 and early April 2018 we saw
these customers reappear in the Shadowserver, IoTPOT or
darknet data, we would count these cases as reinfections.
V. RESULTS
We can now evaluate the effectiveness of the Mirai notiﬁ-
cations. As can be seen in Figure 5, the total number of Mirai-
infected customers was reduced from around 150 to less than
80 infected customers per day at the end of the experiment.
To further understand the impact of the experiment, we will
ﬁrst compare the results for the different treatments (improved
6
Identify Mirai infected customersNotified before?YesDiscardNoRandomWalled gardenEmailControlTracking the infectionExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperimentExperiment050100150200250Jun-2017Aug-2017Oct-2017Dec-2017Feb-2018Apr-2018#Unique IP addresses were notiﬁed with the standard message. Table III shows a
slightly higher cleanup rate and a shorter the median infection
time for the improved walled garden treatment group com-
pared to the standard walled garden treatment group. This
difference, however, does not pass the log-rank signiﬁcance
test (χ2 = 1.7, p = 0.197). Either the effect is too small to be
visible with our sample size or there is no effect. We should
also note that this comparison is hampered by the fact that
the studies were conducted at different periods in time. In any
case, we cannot observe a clear impact of the more actionable
walled garden content.
C. Natural remediation
As we have seen in section V-A, the control group showed
remarkably high remediation rates, even though they were not
notiﬁed.
To conﬁrm the presence of this natural remediation in
other networks, we randomly selected 4 other ISPs within the
same country where our partner ISP operates and investigated
the remediation rates during the period of the observational
study. Though we do not control for the potential causes of
remediation, ﬁgure 7 shows that all 5 ISPs actually experience
some degree of remediation in their networks even though not
all of them issue notiﬁcations regarding Mirai-infections. This
suggests the pervasive presence of a natural remediation pro-
cess across different networks. We have investigated potential
explanations for this result.
We can rule out three sources of error. First: DHCP churn.
Churn often affects measurements that use IP addresses as
identiﬁers for hosts or users. This greatly complicates external
tracking, as devices might be assigned new IP addresses
during the measurement period. Our results are immune to
this problem, as we knew the ISP’s customer ID for each user
in the study. The ISP’s DHCP logs gave us ground truth on
the different IP addresses that were assigned to each customer
ID over time. Second source of error: additional notiﬁcations.
If customers in the control group were to receive some other
security notiﬁcation during the experiment, this might trigger
remediation actions that could also affect the Mirai infection.
Our design, however, ensured that customers in the control
group would not receive any other notiﬁcations during the 14-
day period.
A third source of error we investigated was whether our
ability to track infections deteriorated over time. We speculated
that perhaps cleaned devices would get reinfected with new
Mirai variants or other IoT malware families that we could
not observe in the darknet data using Mirai’s TCP sequence
number artifact. While theoretically we cannot rule this out, we
do observe that overall Mirai infection levels remained more
or less constant in the darknet data. So the Mirai variants that
produced the initial infections were still very active. There
was even an increase in command-and-control servers reported
during that period [16]. Also, we saw none of the affected
customers reappear in the other two datasets: Shadowserver
and IoTPOT.
One explanation that can explain, at least partially, natural
remediation is the fact
infections are reported
to be non-persistent [31]. We also conﬁrmed this ourselves
(see section V-G). This means that every power cycle or
that Mirai
unplugging action leads to cleanup. High natural cleanup might
thus be driven by users who turn off devices or otherwise
disconnect them, rather than use them continually. Indeed,
many of these infections are very short-lived. Around 37% of
the infections in the control group are seen only once or twice
and disappear from the darknet data within one hour. These
transient infections might also reﬂect volatile usage patterns
speciﬁc to certain IoT devices. Think of a NAS device that is
temporarily connected to another network, perhaps at a friends
house. It gets infected there, but then is removed again from
the network.
Now, these devices might get cleaned naturally because
of usage patterns, but wouldn’t they quickly get reinfected
again when they are turned back on? In the experiment, we
cannot distinguish between infection and reinfection (see Sec-
tion IV-D), so this might happen. However, all the devices that
we counted as clean were not seen again for 21 days after the
experimental treatment ended. This suggests that reinfection
stopped at some point. Something must have changed, beyond
a mere reboot. We take a closer look at the issue of reinfection
in section V-E.
D. Natural remediation in other networks
To investigate whether the high natural remediation rate in
the control group was an idiosyncratic result speciﬁc to this
network or customer base, we also analyzed the infection data
for two other networks of the same ISP: their business ser-
vices network and the network of a subsidiary brand offering
consumer broadband on the cheaper end of the market. We
compared the remediation rate of the control group from the
experiment to the rates for the two other networks. As with
our control group, the customers in the two other networks did
not receive any notiﬁcations for IoT infections from the ISP.
This makes them very relevant points of reference.
As shown in Table III, the other networks also display high
natural remediation rates. The rate in the business network
(55%) was lower compared to the control group (74%) and the
subsidiary (74%). Remediation in the two consumer groups
(control and subsidiary), however, are virtually the same.
Figure 6b also shows this pattern. The log-rank test reports a
signiﬁcant difference between customers with business service
subscription and the control group (log-rank test, χ2 = 5.4
with p−value = 0.0196) and business network and subsidiary
network (log-rank test, χ2 = 4.9 with p − value = 0.0268).
The median infection time for the business network was
also signiﬁcantly longer compared to the other networks. One
hypothesis for this ﬁnding is that for business continuity
reasons, business customers are less likely to reboot or power
off their devices as often as consumers. Related to this different
usage pattern, we would also expect the composition of IoT
device types to be different from the two consumer groups. As
we will discuss in section V-F, this is in fact the case. Taking
these factors into account, we ﬁnd very consistent natural
remediation rates across the different networks, increasing our
conﬁdence in the results of the experiment.
E. Long-term efﬁcacy
The non-persistent nature of Mirai means that rebooting,
shutting down or unplugging an infected device would cause
7
Table III: Summary statistics of Mirai remediation
Groups
Sample
Size
% clean
Median
infection time
Standard
deviation
Control (Experimental study)
Email (Experimental study)
Walled garden: improved (Experimental study)
Walled garden: standard (Observational study)
Subsidiary network (Observational study)
Business network (Observational study)
43
40
40
97
61
62
74%
77%
92%
88%
74%
58%
66 Hours
74 hours
26 Hours
27 Hours
51 Hours
198 Hours
142.51
144.18
91.64
121.63
148.02
141.64
(a) Infection rates for the different
during the study
treatment variables used
(b) Infection rates across different networks. The consumer
network data includes only the control group.
Figure 6: Survival curves of the Mirai infections
reinfection rate also is surprisingly low. This strongly suggests
that whatever action the customer took, it was more than a
mere reboot of the device. We have asked users about the
actions they took and discuss the results in Section VI
On the other hand, intentional action by the user cannot ex-
plain the whole story. This is what the high natural remediation
rate in the control group tells us. The high remediation rate
also contains a signal about low reinfection rates. Remember
that to conservatively count them as clean, we tracked the
customer IP addresses for an additional 21 days. We did not
see these devices again, which clearly means they stopped
getting reinfected at some point. In other words, while we
might explain the quick removal of Mirai from the combination
of non-persistence and device usage patterns, this does not
explain why most devices are never seen again. In short, while
the low reinfection rate is a positive ﬁnding, it is also one for
which we have no explanation.
F.
Impact of device type
So far we have encountered a number of surprisingly
positive results: high remediation rates across all groups, even
in the control group,
the two reference groups, and low
reinfection rates in the months thereafter. To understand if
these results are somehow the result of a peculiar composition
of device types in these networks, we take a closer look at the
affected devices. Is there anything special about them in terms
of the cleanup actions or usage patterns?
Following a similar methodology as Antonakakis et al.
in [1], we have used Censys [9] to determine the device
types. We analyzed the banner information obtained through
Censys scans and were able to label 88 devices (28%). These
devices were mainly network cameras/DVRs (11%), storage
units (7.44%) and routers (3.83%). However, the Censys scans
Figure 7: Cleanup rates for 4 randomly chosen ISPs within the
country where the partner ISP operates
it to be removed. This fact seems to be an important driver
of the high natural remediation rate we observed during the
experiment. However, merely rebooting the device does not
ﬁx the underlying problem as the device remains vulnerable
to infections once it comes back online. To put it differently,
the high remediation rates we observed in our experimental and
observational study might be Pyrrhic victories if the devices
are simply reinfected again soon thereafter. Removing the
underlying problem would require affected users to take other
actions, such as changing default passwords, updating the
ﬁrmware or changing router settings – measures that are much
more complicated than a mere reboot.
To get a sense of reinfection rates and the long-term
efﬁcacy of remediation efforts, we looked at the 97 customers
in the observational study. We investigated reinfection rates
for this group during a ﬁve-month period after the initial 35
days tracking period. We ﬁnd that only 5 of these customers
(5%) were seen again at some point during those ﬁve months
in the Shadowserver, IoTPOT, or darknet data. In other words:
not only is short-term remediation very high, the longer-term
8
Infection time (Days)02468101214Survival Probability0.00.20.40.60.81.0ControlEmailImproved Walled gardenStandard Walled gardenInfection time (Days)02468101214Survival Probability0.00.20.40.60.81.0BusinessConsumerSubsidiaryInfection time (days)02468101214Survival Probability0.00.20.40.60.81.0ISP 1Partner ISPISP 2ISP 3ISP 4did not allow us to label 72% of the infected devices due
to the lack of banner information. In order to increase the
number of identiﬁed devices, we further conducted port scans
on the unidentiﬁed devices suing the Network Mapper (Nmap).
With this active scanning we gathered banner information
of additional ports, i.e, port 5000 (UPnP), 8443 (alternative
HTTPS), 32400 (Plex media) and 37777 (QSee DVRs). This
allowed us to label 36 additional devices.
Table IV: Type of infected devices per service
Amount of Devices
20
13
3
1
6
4
13
5
4
3
2
1
3
9
18
1
1
11
1
3
124
219
(7.81 %)
(5.08 %)
(1.17 %)
(0.39 %)
(3.04 %)
(1.74 %)
(5.26 %)
(2.02 %)
(1.79 %)
(1.21 %)
(0.81 %)
(0.40 %)