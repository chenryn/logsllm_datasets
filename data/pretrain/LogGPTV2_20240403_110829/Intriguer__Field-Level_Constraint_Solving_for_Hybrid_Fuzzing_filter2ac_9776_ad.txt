tar
Size (Byte)
Description
1 A single NULL byte (0x00)
7,868 Generated by GCC compiler (§D)
46,080 Generated by Microsoft Visual C++ (§D)
5,614 Downloaded and minimized with ffmpeg
13,050(avg) Downloaded and minimized with afl-cmin (69)
2,048 Downloaded from FoRTE-Research
5.1 Evaluation Setup
To account for the random nature of fuzzing, we follow the recent
guideline for evaluating fuzz testing [17]: we perform multiple trials
and use statistical tests; evaluate different seeds; consider longer
timeouts; and evaluate bug-finding performance using ground truth
with benchmark test suites and real programs.
Programs. We used LAVA-M benchmark programs [11], and the
real programs in GNU binutils, ffmpeg, libav, libtiff, and
libarchive, for evaluation. The LAVA-M dataset is widely used
for evaluation and comparison of recent fuzzers, including VUzzer
and Qsym [8, 19, 27, 33]. Note that the binaries of LAVA-M involve
various conditions including multi-byte constraints to get to buggy
code; but to be free from concerns about overfitting problems, it
is also very important to involve real-world programs, such as
ffmpeg, in evaluation. GNU binutils [1] is a set of programs used
to create or read binary programs, object files, and libraries. ffmpeg
and libav [2] are free software tools and library that processes
audio and media files. libtiff [18] is a free software library that
processes tiff images. libarchive is a library that reads and writes
streaming archives. Recent studies and even commercial fuzzers
have used these real-world programs for bug discoveries [4, 12, 27,
33]. Table 6 summarizes the program data.
Fuzzers. We set baseline fuzzers for evaluation: Qsym and VUzzer
for benchmarks in LAVA-M (§5.2.1); and Qsym and AFL for bug
discoveries in real-world programs (§5.2.2) and for code coverage
(§5.3). In LAVA-M experiments, Intriguer and VUzzer use a single
core, and Qsym uses three cores for hybrid fuzzing. In real program
experiments, Intriguer and Qsym both perform hybrid fuzzing.
Seeds. The executable format (e.g., elf or pe) files are binaries com-
piled from 22 lines of C++ code containing a simple class, using
g++ and visual studio (§D). The mp4 file was downloaded from the
sample-videos7 site and left with only two video frames, reducing
7https://sample-videos.com/
Table 8: Number of bugs detected by the latest fuzzers and Intriguer.
We report the median of 20 runs per fuzzer and also the maximum.
Note that Intriguer detected all the bugs (2,136 bugs) in who. (5h)
Readers are referred to Table 16 in §E for more comparisons.
Program
uniq
base64
md5sum
who
Total
median
#Bugs
(listed) VUzz. Qsym Intr.
28
44
57
2,131
2,260
28
44
57
2,136
2,265
28
44
57
1,396
1,525
28
39
23
10
100
max
VUzz. Qsym Intr.
28
44
57
2,136
2,265
28
44
57
1,452
1,581
28
40
26
29
123
Figure 8: The cumulative number of bugs detected in LAVA-M’s
who over time. (a) Default 5-hour run; (b) Extended 24-hour run. The
solid lines are median. The shaded region around is the confidence
interval. The empty circle is the time that all the bug was detected.
We use the Mann Whitney U-test, which is non-parametric, between
Intriguer and Qsym for 20 runs (p < 10−7).
the repeated structures by ffmpeg. The tiff files were downloaded
from go-fuzz-corpus8 repository. We reduced 215 downloaded files
to 69 files by afl-cmin. The tar file was downloaded from FoRTE-
Research [24]. Table 7 summarizes the seed data.
Platform and configuration. We conducted our experiments on
a machine with 2.40GHz Xeon CPU and 384GB RAM, running
64bit Ubuntu 16.04 systems. In the experiments, we conformed to
the following comparison configuration: the LAVA-M dataset was
fuzzed for default five hours (and particularly who in 5h and 24h)
(§5.2.1), while real-world programs were fuzzed for 24 hours (§5.2.2,
§5.3, §5.4, §5.5, and §5.6). Additionally, we performed 5-day fuzzing
for ffmpeg (§5.2.2).
5.2 RQ1: Bug Discovery Capability
To answer RQ1, we compare the followings with other fuzzers: (i)
the number of bugs identified in LAVA-M, and (ii) the number of dis-
tinct bugs discovered in real-world programs. As for distinct bugs,
we performed triage based on a unique patch when the programs
were patched [17]. Otherwise, we manually ran deduplication again
after the triage based on a call stack.
5.2.1 LAVA-M Dataset. To compare the performance of Intriguer
with VUzzer (i.e. taint-based fuzzer) and Qsym (i.e. concolic-based
hybrid fuzzer), we performed 20 runs of fuzzing for each fuzzer
on the buggy programs of LAVA-M. Table 8 shows the results of
5-hour fuzzing on each program of the LAVA-M dataset. The first
two columns respectively show the target program names and the
8https://github.com/dvyukov/go-fuzz-corpus
Session 3A: Fuzzing: Methods and ApplicationsCCS ’19, November 11–15, 2019, London, United Kingdom523Table 9: The number of bugs found by Intriguer, Qsym, and AFL,
respectively, in real-world programs. (24h) We state the total num-
ber of 20 runs. Parentheses mean the number of bugs that the other
two fuzzers could not find.
nm
objdump
Program Seed
empty
elf
pe
empty
elf
elf
mp4
mp4
tiff
tar
-
readelf
ffmpeg
avconv
tiff2pdf
bsdtar
total
AFL
1 (0)
5 (0)
4 (0)
3 (0)
3 (0)
4 (0)
0 (0)
0 (0)
0 (0)
0 (0)
20 (0)
Qsym Intriguer
9 (6)
3 (0)
11 (5)
7 (1)
9 (5)
7 (3)
3 (0)
4 (1)
4 (1)
3 (0)
6 (2)
4 (0)
2 (1)
1 (0)
5 (3)
4 (2)
1 (1)
0 (0)
0 (0)
0 (0)
33 (7)
50 (24)
number of artificial bugs listed9 by the LAVA authors [11]. The
middle columns show the median values in the number of bugs
identified by each fuzzer, and the last three columns the maximum.
The LAVA-M benchmark results show that Intriguer outperforms
the state-of-the-art fuzzers. Qsym and VUzzer have difficulty find-
ing all the bugs hidden behind multibyte constraints within the
time budget. VUzzer detected only 4.4% of bugs and Qsym detected
58.2% of bugs, respectively, once in 20 runs of our experiments. On
the contrary, Intriguer found 100% of bugs within the same time
budget during our tests, two times in 20 runs; and when running
under the same conditions for 24 hours, Intriguer found all the
bugs nine times in 20 runs (Figure 8). Intriguer also found unlisted
bugs although we don’t show them in Table 8, e.g., in who, Intriguer
identified 2464 bugs when found all listed bugs (2136 + 328).
Figure 8 depicts the number of listed bugs found by Intriguer
and Qsym, respectively, in who over time. Intriguer found more
than 1,500 bugs in 5m; but Qsym slowed down in finding bugs
after 2h and found fewer than 1,500 bugs in 5h. Qsym was able to
find more bugs after 12h, but never succeeded in finding all the
bugs within 24h. This result indicates that the field-level constraint
solving approach of Intriguer is effective in discovering new test
cases and bugs in a shorter time.
5.2.2 Real-world Programs. In all programs, Intriguer found more
bugs than AFL. This indicates that Intriguer solves the complicated
constraints that the coverage-based fuzzer (AFL) could not solve,
and creates new test cases, consequently finding more bugs. In
addition, compared to Qsym, Intriguer found more bugs in objdump,
nm, readelf, ffmpeg, and tiff2pdf. This indicates that Intriguer
can discover bugs more efficiently by performing trace reduction
and field-level constraint solving to optimize symbolic emulation.
Only in avconv, Qsym found more bugs than Intriguer while they
respectively found three and two unique bugs. We observe that this
result was due to the Qsym’s slightly different seed prioritization
strategy, in which the most recently generated test case is selected
among test cases having the same priority.
9The LAVA-M programs contain additional “unlisted” bugs, also identified by Intriguer.
Integer Overflow
Integer Overflow
Floating Point Exception
Integer Overflow
Integer Overflow
Integer Overflow
Integer Overflow
Project
binutils Out-of-bounds Read
binutils
binutils
binutils Out-of-bounds Read
binutils
binutils
binutils Out-of-bounds Read
binutils Out-of-bounds Read
binutils
binutils Out-of-bounds Write
binutils Null Pointer Dereference
binutils Null Pointer Dereference
binutils
binutils Out-of-bounds Read
binutils Out-of-bounds Read
binutils Negative-size-param
binutils Out-of-bounds Read
binutils Out-of-bounds Read
binutils Out-of-bounds Read
binutils Out-of-bounds Read
binutils
binutils Out-of-bounds Read
Out-of-bounds Write
Integer Overflow
Null Pointer Dereference
Out-of-bounds Read
Out-of-bounds Read
Out-of-bounds Read
Null Pointer Dereference
Out-of-bounds Write
Null Pointer Dereference
Out-of-bounds Read
Out-of-bounds Read
Out-of-bounds Read
Out-of-bounds Read
Out-of-bounds Write
Out-of-bounds Read
Out-of-bounds Write
Out-of-bounds Read
Out-of-bounds Read
Out-of-bounds Read
Floating Point Exception
Out-of-bounds Read
libav
libav
libav
libav
libav
libav
libav
libav
libav
libav
libav
libav
libav
libav
libav
libav
libav
libav
libav
ffmpeg
Table 10: New bugs discovered in real-world programs.
Bug Type
Fixed
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
(cid:68)
Report ID
22307
22373
22376
22384
22385
22386
22443
22506
22507
22508
22509
22510
22809
23147
23148
23316
24266
24272
24273
24898
24921
24922
mailing list
1088