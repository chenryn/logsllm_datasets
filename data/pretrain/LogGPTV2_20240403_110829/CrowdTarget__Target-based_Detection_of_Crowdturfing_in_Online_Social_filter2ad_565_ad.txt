### 7.2 Twitter Application
Crowdturfing services can use a large number of Twitter applications to evade detection. By assigning different applications to different groups of workers, they can reduce the dominance of any single application. However, creating a large number of Twitter applications is not arbitrary, as Twitter restricts the number of applications that can be created per day and per account. Additionally, it is challenging to precisely control the ratio of the most dominant application because workers can retweet any tweet at any time.

### 7.3 Unreachable Retweeters
To minimize the number of unreachable retweeters, crowdturfing services might request workers to follow the posting user of a tweet they want to retweet. However, this approach is impractical for three key reasons:
1. **Unwanted Future Tweets**: Workers would receive future tweets from the posting user, even if they are not interested.
2. **Decreased Popularity**: Increasing the number of accounts they follow can decrease the workers' popularity on Twitter, which contradicts their goal.
3. **Follower Limitations**: Workers cannot follow the posting user if they have a small number of followers or if they have recently followed many accounts [27].

### 7.4 Click Information
To manipulate the number of clicks, crowdturfing services could request workers to click on a link in a tweet while retweeting it. This approach could potentially evade detection by CrowdTarget, but it has two significant problems:
1. **Worker Reluctance**: Workers may be unwilling to click on such links due to the risk of encountering malicious content (e.g., spam, phishing, or drive-by downloads).
2. **Click Pattern Differences**: The distributions of artificial clicks in terms of time, geographical location, user agents, and referrers are likely to differ from those of real clicks. Since all links shared on Twitter are automatically shortened to t.co links [28], Twitter can obtain detailed click information. Therefore, generating realistic click patterns using crowdturfing workers would be a difficult task. To date, no crowdturfing service is known to manipulate click numbers, so we cannot confirm our expectations. In future work, we will investigate the effort required to produce realistic click distributions.

### 8. RELATED WORK

#### 8.1 Detection of Crowdturfing Accounts
Malicious crowdsourcing has recently garnered significant attention. Motoyama et al. [20] analyzed various types of abuse tasks on Freelancer, one of the most popular crowdsourcing sites. Wang et al. [33] collected data from Chinese-based crowdturfing sites, Zhubajie and Sandaha, and analyzed their structures, scale, and financial aspects.

Several researchers have proposed methods to detect crowdturfing on online social networks (OSNs). Lee et al. [18] and Wang et al. [32] aimed to detect OSN accounts performing crowdturfing tasks on Twitter and Weibo, respectively. These studies used account-based features similar to those in conventional spam detection, such as the ratio of tweets with links, the number of tweets per day, and the number of retweets per tweet. Lee et al. [19] detected malicious tasks targeting Twitter on Fiverr, another popular crowdsourcing site.

#### 8.2 Detection of Malicious Accounts
A substantial body of research focuses on detecting malicious accounts in OSNs. We categorize these methods into three types: account-based, graph-based, and behavior-based.

- **Account-Based Methods** [12, 17, 23, 34, 35]: These methods extract various features from user profiles and postings to build machine-learning classifiers.
- **Graph-Based Methods** [9, 10, 13, 30, 36, 37]: These methods detect malicious accounts by leveraging the observation that such accounts typically have few connections with normal accounts.
- **Behavior-Based Methods**: Recent research detects malicious accounts by monitoring synchronized group activity. For example, COMPA [15] detects compromised accounts by identifying similar changes in account behavior within a short time. Clickstream [31] classifies accounts based on the similarity of clickstream sequences. CopyCatch [8] and SynchroTrap [11] detect malicious accounts with synchronized Facebook like patterns. CatchSync [16] uses synchronicity and normality of accounts to detect malicious activities.

#### 8.3 Detection of Black-Market Accounts
Some researchers have focused on black markets in OSNs. Stringhini et al. [24] analyzed Twitter follower markets, describing their characteristics and classifying market customers. Thomas et al. [25] investigated black-market accounts used for distributing Twitter spam. Cristofaro et al. [14] analyzed Facebook like farms by deploying honeypot pages. Viswanath et al. [29] detected black-market Facebook accounts based on their like behaviors.

### 9. CONCLUSION
In this paper, we introduced a novel crowdturfing detection method, CrowdTarget, which leverages the target objects of crowdturfing tasks. We observed that the manipulation patterns of these target objects remain consistent, regardless of the evasion techniques used by crowdturfing accounts. Through this observation, we distinguished tweets that received retweets from crowdturfing sites from those retweeted by normal Twitter users. Evaluation results showed that CrowdTarget can detect crowdturfing retweets on Twitter with a true positive rate (TPR) of 0.98 and a false positive rate (FPR) of 0.01.

### Acknowledgments
We would like to thank our shepherd Guoliang Xue and anonymous reviewers for their invaluable comments and suggestions. This work was supported by the ICT R&D program of MSIP/IITP [14-824-09-013, Resilient Cyber-Physical Systems Research].

### 10. REFERENCES
[References listed here as provided in the original text]

---

This version of the text is more coherent and professional, with improved clarity and structure.