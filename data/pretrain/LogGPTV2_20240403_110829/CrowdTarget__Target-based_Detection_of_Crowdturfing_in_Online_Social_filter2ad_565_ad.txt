OSNs can recognize such activities because the same IP ad-
dresses are frequently used.
Third, the services can use bot accounts to secretly per-
form tasks. CrowdTarget may not work correctly if the ser-
vices prepare an enough number of bot accounts to simulate
the retweet time distribution of normal tweets. However,
due to extra costs, we expect that the services would not
take this approach.
7.2 Twitter Application
The crowdturﬁng services can use a large number of Twit-
ter applications for evasion. By assigning diﬀerent appli-
cations to diﬀerent groups of workers, they can eliminate
dominant applications. However, they cannot arbitrary cre-
ate a large number of Twitter applications because Twitter
restricts the number of application creation per day and per
account. Furthermore, it is diﬃcult to exactly control the
ratio of the most dominant application, since workers can
retweet any tweet at any time.
7.3 Unreachable Retweeters
To reduce the number of unreachable retweeters, the crowd-
turﬁng services would request crowdturﬁng workers to fol-
low the posting user of a tweet they want to retweet. How-
ever, due to three important reasons, it is impractical. First,
workers should receive future tweets of the posting user even
if they do not want it. Second, increasing the number of fol-
lowings can decrease the popularity of workers on Twitter,
which is exactly opposite to their goal. Third, workers can-
not follow the posting user when the number of their follow-
ers is small or when they recently follow many accounts [27].
7.4 Click Information
To manipulate the number of clicks, the crowdturﬁng ser-
vices can request crowdturﬁng workers to click on a link
in a tweet while retweeting it. This approach could evade
CrowdTarget, but it has two problems. First, crowdturﬁng
workers unwilling to click on such a link because it may be
a malicious link (e.g., spam, phishing, and drive-by down-
loads). Second, we expect that the distributions of artiﬁcial
clicks in terms of time, geographical location, user agents,
and referrers diﬀer from those of real clicks. Note that all
links shared on Twitter are automatically shortened to t.co
links [28]. This allows Twitter to obtain detailed click in-
formation of all links on Twitter. Thus, generating realistic
click patterns by using crowdturﬁng workers would be a dif-
ﬁcult task. Unfortunately, to the best of our knowledge, no
crowdturﬁng service currently manipulates the number of
click such that we cannot conﬁrm our expectation. There-
fore, in future, we will show how much eﬀort is necessary to
produce realistic click distributions.
8. RELATED WORK
In this section, we explain related studies of our work.
8.1 Detection of Crowdturﬁng Accounts
Malicious crowdsourcing has recently received consider-
able attention. Motoyama et al. [20] analyze various types
of abuse tasks in Freelancer, one of the most popular crowd-
sourcing site. Wang et al. [33] collect data from crowdturf-
ing sites based in China, Zhubajie and Sandaha, and analyze
their structures, scale, and the amount of money involved in
it.
Several researchers propose methods to detect crowdturf-
ing aiming at OSNs. Lee et al. [18] and Wang et al. [32] aim
802Table 2: Example of veriﬁed accounts that received retweets from accounts using automated applications
Veriﬁed accounts Application name
Application homepage
PopWrapped
m bukairy
ODEONCinemas
alweeamnews
CaesarsPalace
Almatraﬁ
MohammadMamou KLILK API RETWEET http://www.klilk.com
http://tweetadder.com
http://www.rtwity.com
http://twitaculous.com
http://twittretweet.com
http://web.socialrewards.com
http://rettwwet.net
TweetAdder
rtwity
Twitaculous
twittretweet EEE
Social Rewards
rettwwet net
to detect OSN accounts performing crowdturﬁng tasks on
Twitter and Weibo, respectively. These studies use account-
based features introduced in conventional spam detection
studies, such as the ratio of tweets including links, the num-
ber of tweets per day, and the number of retweets per tweet.
Lee et al. [19] detect malicious tasks targeting Twitter in
Fiverr, one of the popular crowdsourcing site.
8.2 Detection of Malicious Accounts
There are a large number of studies of detecting mali-
cious accounts in OSNs. We classify them into three types:
account-based methods, graph-based methods, and behavior-
based methods. First, account-based methods [12, 17, 23, 34,
35] extract various features from user proﬁles and postings,
and use them to build machine-learning classiﬁers. Second,
graph-based methods [9, 10, 13, 30, 36, 37] detect malicious
accounts by using the observation that malicious accounts
usually have few connections with normal accounts. Third,
recent researchers detect malicious accounts by monitoring
their synchronized group activity. For example, COMPA [15]
detects compromised accounts by catching similar changes
of account behavior within a short time. Clickstream [31]
classiﬁes accounts based on the similarity of clickstream se-
quences. CopyCatch [8] and SynchroTrap [11] detect ma-
licious accounts that have synchronized Facebook like pat-
terns. CatchSync [16] uses synchronicity and normality of
accounts to detect malicious accounts.
8.3 Detection of Black-market Accounts
Some researchers focus on black markets for OSNs. Stringh-
ini et al. [24] analyze Twitter follower markets. They de-
scribe characteristics of Twitter follower markets and clas-
sify customers of the markets. Thomas et al. [25] inves-
tigate black-market accounts used for distributing Twitter
spams. Cristofaro et al. [14] analyze Facebook like farms
by deploying honeypot pages. Viswanath et al. [29] detect
black-market Facebook accounts based on their like behav-
iors.
9. CONCLUSION
In this paper, we proposed a novel crowdturﬁng detection
method using target objects of crowdturﬁng tasks, Crowd-
Target. We observed that the manipulation patterns of
the target objects maintained, regardless of what evasion
techniques crowdturﬁng accounts used. Through the ob-
servation, we distinguished tweets that received retweets by
crowdturﬁng sites from tweets that received retweets by nor-
mal Twitter users. Evaluation results showed that Crowd-
Target could detect crowdturﬁng retweets on Twitter with
TPR of 0.98 at FPR of 0.01.
Acknowledgments
We would like to appreciate our shepherd Guoliang Xue and
anonymous reviewers for their invaluable comments and sug-
gestions. This work was supported by ICT R&D program of
MSIP/IITP. [14-824-09-013, Resilient Cyber-Physical Sys-
tems Research]
10. REFERENCES
[1] Addmefast. http://addmefast.com/.
[2] Embedded tweets.
https://dev.twitter.com/web/embedded-tweets/.
[3] Klout. https://klout.com/.
[4] Retweets.pro. http://retweets.pro/.
[5] Socialshop. http://socialshop.co/.
[6] Traﬀup. http://traffup.net/.
[7] Twitter reaches spam lawsuit settlement with tweet
adder.
http://marketingland.com/twitter-reaches-spam-
lawsuit-settlement-with-tweet-adder-45890/.
[8] A. Beutel, W. Xu, V. Guruswami, C. Palow, and
C. Faloutsos. CopyCatch: Stopping group attacks by
spotting lockstep behavior in social networks. In
International World Wide Web Conference (WWW),
2013.
[9] Y. Boshmaf, D. Logothetis, G. Siganos, J. Ler´ıa,
J. Lorenzo, M. Ripeanu, and K. Beznosov. ´Integro:
Leveraging victim prediction for robust fake account
detection in OSNs. In Network and Distributed System
Security Symposium (NDSS), 2015.
[10] Q. Cao, M. Sirivianos, X. Yang, and T. Pregueiro.
Aiding the detection of fake accounts in large scale
social online services. In USENIX Symposium on
Networked Systems Design and Implementation
(NSDI), 2012.
[11] Q. Cao, X. Yang, J. Yu, and C. Palow. Uncovering
large groups of active malicious accounts in online
social networks. In ACM Conference on Computer and
Communications Security (CCS), 2014.
[12] Z. Chu, S. Gianvecchio, H. Wang, and S. Jajodia.
Who is tweeting on Twitter: Human, bot, or cyborg?
In Annual Computer Security Applications Conference
(ACSAC), 2010.
[13] G. Danezis and P. Mittal. SybilInfer: Detecting Sybil
nodes using social networks. In Network and
Distributed System Security Symposium (NDSS), 2009.
[14] E. De Cristofaro, A. Friedman, G. Jourjon, M. A.
Kaafar, and M. Z. Shaﬁq. Paying for likes?:
Understanding Facebook like fraud using honeypots.
In Internet Measurement Conference (IMC), 2014.
803[15] M. Egele, G. Stringhini, C. Kruegel, and G. Vigna.
[26] Twitter. State of Twitter spam.
COMPA: Detecting compromised accounts on social
networks. In Network and Distributed System Security
Symposium (NDSS), 2013.
[16] M. Jiang, P. Cui, A. Beutel, C. Faloutsos, and
S. Yang. CatchSync: Catching synchronized behavior
in large directed graphs. In ACM SIGKDD
International Conference on Knowledge Discovery and
Data Mining (KDD), 2014.
[17] K. Lee, J. Caverlee, and S. Webb. Uncovering social
spammers: Social honeypots + machine learning. In
International ACM SIGIR Conference on Research
and Development in Information Retrieval, 2010.
[18] K. Lee, P. Tamilarasan, and J. Caverlee.
Crowdturfers, campaigns, and social media: Tracking
and revealing crowdsourced manipulation of social
media. In International AAAI Conference on Web and
Social Media (ICWSM), 2013.
[19] K. Lee, S. Webb, and H. Ge. The dark side of
micro-task marketplaces: Characterizing Fiverr and
automatically detecting crowdturﬁng. In International
AAAI Conference on Web and Social Media
(ICWSM), 2014.
[20] M. Motoyama, D. McCoy, K. Levchenko, S. Savage,
and G. M. Voelker. Dirty jobs: The role of freelance
labor in web service abuse. In USENIX Security
Symposium, 2011.
[21] Scikit-learn. https://http://scikit-learn.org.
[22] J. Song, S. Lee, and J. Kim. I know the shortened
URLs you clicked on Twitter: Inference attack using
public click analytics and Twitter metadata. In
International World Wide Web Conference (WWW),
2013.
[23] G. Stringhini, C. Kruegel, and G. Vigna. Detecting
spammers on social networks. In Annual Computer
Security Applications Conference (ACSAC), 2010.
[24] G. Stringhini, G. Wang, M. Egele, C. Kruegel,
G. Vigna, H. Zheng, and B. Y. Zhao. Follow the green:
growth and dynamics in Twitter follower markets. In
Internet Measurement Conference (IMC), 2013.
[25] K. Thomas, D. McCoy, C. Grier, A. Kolcz, and
V. Paxson. Traﬃcking fraudulent accounts: The role
of the underground market in Twitter spam and
abuse. In USENIX Security Symposium, 2013.
https://blog.twitter.com/2010/state-twitter-
spam.
[27] Twitter Blogs. Following rules and best practices.
https://support.twitter.com/entries/68916-
following-rules-and-best-practices.
[28] Twitter Blogs. Next steps with the t.co link wrapper,
2011. https://blog.twitter.com/2011/next-steps-
with-the-tco-link-wrapper.
[29] B. Viswanath, M. A. Bashir, M. Crovella, S. Guha,
K. P. Gummadi, B. Krishnamurthy, and A. Mislove.
Towards detecting anomalous user behavior in online
social networks. In USENIX Security Symposium,
2014.
[30] B. Viswanath, A. Post, K. P. Gummadi, and
A. Mislove. An analysis of social network-based Sybil
defenses. In ACM SIGCOMM, 2010.
[31] G. Wang, T. Konolige, C. Wilson, X. Wang, H. Zheng,
and B. Y. Zhao. You are how you click: Clickstream
analysis for Sybil detection. In USENIX Security
Symposium, 2013.
[32] G. Wang, T. Wang, H. Zheng, and B. Y. Zhao. Man
vs. machine: Practical adversarial detection of
malicious crowdsourcing workers. In USENIX Security
Symposium, 2014.
[33] G. Wang, C. Wilson, X. Zhao, Y. Zhu, M. Mohanlal,
H. Zheng, and B. Y. Zhao. Serf and turf:
Crowdturﬁng for fun and proﬁt. In International
World Wide Web Conference (WWW), 2012.
[34] C. Yang, R. C. Harkreader, and G. Gu. Die free or live
hard? empirical evaluation and new design for ﬁghting
evolving Twitter spammers. In Recent Advances in
Intrusion Detection, pages 318–337. Springer, 2011.
[35] Z. Yang, C. Wilson, X. Wang, T. Gao, B. Y. Zhao, and
Y. Dai. Uncovering social network Sybils in the wild.
In Internet Measurement Conference (IMC), 2011.
[36] H. Yu, P. B. Gibbons, M. Kaminsky, and F. Xiao.
SybilLimit: A near-optimal social network defense
against Sybil attacks. In IEEE Symposium on Security
and Privacy (Oakland), 2008.
[37] H. Yu, M. Kaminsky, P. B. Gibbons, and A. Flaxman.
SybilGuard: Defending against Sybil attacks via social
networks. In ACM SIGCOMM, 2006.
804