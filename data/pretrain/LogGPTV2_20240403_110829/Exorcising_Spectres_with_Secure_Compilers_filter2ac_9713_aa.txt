title:Exorcising Spectres with Secure Compilers
author:Marco Patrignani and
Marco Guarnieri
Exorcising Spectres with Secure Compilers
Marco Patrignani∗
Marco Guarnieri
CISPA Helmholtz Center for Information Security
Germany
PI:EMAIL
IMDEA Software Institute
Spain
PI:EMAIL
ABSTRACT
Attackers can access sensitive information of programs by exploit-
ing the side-effects of speculatively-executed instructions using
Spectre attacks. To mitigate these attacks, popular compilers de-
ployed a wide range of countermeasures whose security, however,
has not been ascertained: while some are believed to be secure,
others are known to be insecure and result in vulnerable programs.
This paper develops formal foundations for reasoning about the
security of these defenses. For this, it proposes a framework of se-
cure compilation criteria that characterise when compilers produce
code resistant against Spectre v1 attacks. With this framework, this
paper performs a comprehensive security analysis of countermea-
sures against Spectre v1 attacks implemented in major compilers,
deriving the first security proofs of said countermeasures.
This paper uses a blue, sans-serif font for elements of the source language
and an orange, bold font for elements of the target language. Elements
common to all languages are typeset in a black, italic font (to avoid
repetitions). For a better experience, please print or view this in colour [48].
CCS CONCEPTS
• Security and privacy → Formal security models; Systems
security; • Software and its engineering → Compilers;
KEYWORDS
Spectre, Speculative Execution, Secure Compilation, Robust Safety
ACM Reference Format:
Marco Patrignani and Marco Guarnieri. 2021. Exorcising Spectres with
Secure Compilers . In Proceedings of the 2021 ACM SIGSAC Conference on
Computer and Communications Security (CCS ’21), November 15–19, 2021,
Virtual Event, Republic of Korea. ACM, New York, NY, USA, 17 pages. https:
//doi.org/10.1145/3460120.3484534
1 INTRODUCTION
By predicting the outcome of branching (and other) instructions,
CPUs can trigger speculative execution and speed up computation
by executing code based on such predictions. When predictions
are incorrect, CPUs roll back the effects of speculatively-executed
∗Also with Stanford University.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-8454-4/21/11.
https://doi.org/10.1145/3460120.3484534
instructions on the architectural state, i.e., memory, flags, and reg-
isters. However, they do not roll back effects on microarchitectural
components like caches.
Exploiting microarchitectural leaks caused by speculative execu-
tion leads to Spectre attacks [35, 37, 38, 41, 57]. Compilers support
a number of countermeasures, e.g., the insertion of lfence specu-
lation barriers [31] and speculative load hardening [16], that can
mitigate leaks introduced by speculation over branch instructions
like those exploited in the Spectre v1 attack [37].
Existing countermeasures, however, are often developed in an
unprincipled way, that is, they are not proven to be secure, and
some of them fail in blocking speculative leaks, i.e., leaks introduced
by speculatively-executed instructions. For instance, the Microsoft
Visual C++ compiler misplaces speculation barriers, thereby pro-
ducing programs that are still vulnerable to Spectre attacks [27, 36].
In this paper, we propose a novel secure compilation framework
for reasoning about speculative execution attacks and we use it
to provide the first precise characterization of security for a com-
prehensive class of compiler countermeasures against Spectre v1
attacks. Let us now discuss our contributions more in detail:
▶ We present a secure compilation framework tailored towards
reasoning about speculative execution attacks (Section 2). The dis-
tinguishing feature of our framework is that compilers translate
programs from a source language L, with a standard imperative
semantics, into a target language T equipped with a speculative
semantics capturing the effects of speculatively-executed instruc-
tions. This matches a programmer’s mental model: programmers
do not think about speculative execution when writing source code
(and they should not!) since speculation only exists in processors (
captured by T’s speculative semantics). It is the duty of a (secure)
compiler to ensure the features of T cannot be exploited.
Our framework encompasses two different security models for spec-
ulative execution: (1) (Strong) speculative non-interference [27] (SNI),
which considers all leaks derived from speculatively-executed in-
structions as harmful, and (2) Weak speculative non-interference [28],
which considers harmful only leaks of speculatively-accessed data.
▶ We introduce speculative safety (SS, Section 3), a novel safety
property that implies the absence of classes of speculative leaks.
The key features of SS are that (1) it is parametric in a taint-tracking
mechanism, which we leverage to reason about security by focusing
on single traces, and (2) it is formulated to simplify proving that a
compiler preserves it. We instantiate SS using two different taint-
tracking mechanisms obtaining strong SS and weak SS. We precisely
characterize the security guarantees of SS by showing that strong
(resp. weak) SS over-approximates strong (resp. weak) SNI.
▶ We define two novel secure compilation criteria: Robust Spec-
ulative Safety Preservation (RSSP) and Robust Speculative Non-Inter-
ference Preservation (RSNIP, Section 4). These criteria respectively
ensure that compilers preserve (strong or weak) SS and SNI robustly,
Session 2B: Formal Analysis and Verification CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea445i.e, even when linked against arbitrary (potentially malicious) code.
Satisfying these criteria implies that compilers correctly place coun-
termeasures to prevent speculative leaks. However, RSSP requires
preserving a safety property (SS) and it is simpler to prove than
RSNIP, which requires preserving a hyperproperty [20]. To the
best of our knowledge, these are the first criteria that concretely
instantiate a recent theory that phrases security of compilers as
the preservation of (hyper)properties [3, 4, 51] to reason about a
concrete security property, that is, the absence of speculative leaks.
▶ Using our framework, we perform a comprehensive secu-
rity analysis of countermeasures against Spectre v1 attacks imple-
mented in major C compilers (Section 5). Specifically, we focus on
(1) automated insertion of lfences (implemented in the Microsoft
Visual C++ and the Intel ICC compilers [33, 47]), and (2) speculative
load hardening (SLH, implemented in Clang [16]). We prove that:
– The Microsoft Visual C++ implementation of (1) violates weak
RSNIP and is thus insecure.
– The Intel ICC implementation of (1) provides strong RSNIP, so
compiled programs have no speculative leaks.
– SLH provides weak RSNIP, so compiled programs do not leak
speculatively-accessed data. This prevents Spectre-style attacks,
but compiled programs might still speculatively leak data ac-
cessed non-speculatively.
– The non-interprocedural variant of SLH violates weak RSNIP
and is thus insecure.
– Our novel variant of SLH, called strong SLH, provides strong
RSNIP and blocks all speculative leaks.
All our security proofs follow a common methodology (see Sec-
tion 4.3) whose key insight is that proving a countermeasure to be
RSSP is sufficient to ensure its security since SS over-approximates
SNI. This allows us to leverage SS to simplify our proofs.
We conclude by discussing limitations and extensions of our ap-
proach (Section 6) and related work (Section 7).
For simplicity, we only discuss key aspects of our formal models.
Full details and proofs are in the companion report [52].
continue the execution. Thus, line 3 might be executed even if y ≥
size. When size becomes available, the processor checks whether
the prediction was correct. If not, it rolls back all changes to the
architectural state and executes the correct branch. However, the
speculatively-executed memory accesses leave a footprint in the
cache, which enables an attacker to retrieve A[y] even for y ≥ size.
2.1 Threat Model
We study compiler countermeasures that translate source programs
into (hardened) target programs. In our setting, an attacker is an
arbitrary program at target level that is linked against a (compiled)
partial program of interest. The partial program (or, component)
stores sensitive information in a private heap that the attacker
cannot access. For this, we assume that attacker and component
run on separate processes and OS-level memory protection restricts
access to the private heap. For example, in Listing 1, the array A
would be stored in the private heap and the attacker is code that
runs before and after function get.
While attackers cannot directly access the private heap, they can
mount confused deputy attacks [29, 54] to trick components into
leaking sensitive information despite the memory protection.We
focus on preventing only speculative leaks, i.e., those caused by
speculatively-executed instructions. For this, our attacker can ob-
serve the program counter and the locations of memory accesses
during program execution. This attacker model is commonly used
to formalise code that has no timing side-channels [8, 44] without
requiring microarchitectural models. Following Guarnieri et al. [27],
we capture this model in our semantics through traces that record
the address of all memory accesses (e.g., the address of B[A[y]∗512]
in Listing 1) and the outcome of all control-flow instructions.
To model the effects of speculative execution, our target language
mispredicts the outcome of all branch instructions in the component.
This is the worst-case scenario in terms of leakage regardless of
how attackers poison the branch predictor [27].
2 MODELLING SPECULATIVE EXECUTION
To illustrate our speculative execution model, we first introduce
Spectre v1 (Listing 1). Using that, we define the threat model that we
consider (Section 2.1). Then, we present the syntax of our languages
(Section 2.2) and their trace model (Section 2.3). This is followed by
the operational semantics of our languages (Section 2.4). Next, we
present the source (non-speculative) trace semantics (Section 2.5)
and the target (speculative) trace semantics (Section 2.6). This for-
malisation focuses on the strong SNI model, so we conclude by
defining the changes necessary for weak SNI (Section 2.7).
1 void get (int y)
2
3
if (y < size) then
temp = B[A[y]∗512]
Listing 1: The classic Spectre v1 snippet.
Consider the standard Spectre v1 example [37] in Listing 1. Func-
tion get checks whether the index stored in variable y is less than
the size of array A, stored in the global variable size. If so, the
program retrieves A[y], multiplies it by the cache line size (here:
512), and uses the result to access array B. If size is not cached,
modern processors predict the guard’s outcome and speculatively
2.2 Languages L and T
Technically, we have a pair of source and target languages (L and T)
for studying security in the strong SNI model and a pair of source
and target languages (L- and T-) for studying weak SNI. Strong (L-T)
and weak (L--T-) languages have the same syntax and a very similar
semantics, which differ only in the security-relevant observations
produced during the computation. We focus this section and the
following ones on the strong languages L-T; we introduce the small
changes for the weak languages L--T- in Section 2.7.
The source (L) and target (T) languages are single-threaded While
languages with a heap, a stack to lookup local variables, and a notion
of components (our unit of compilation). We focus on such a setting,
instead of an assembly-style language like [17, 27], to reason about
speculative leaks without getting bogged down in complications
like unstructured control flow. This does not limit the power of
attackers: since attackers reside in another process, they would not
be able to exploit the additional features of assembly languages
(e.g., unstructured control flow) to compromise components.
The common syntax of L and T is presented below; we indicate
sequences of elements e1,· · · , en as e and e · e denotes a stack with
Session 2B: Formal Analysis and Verification CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea446top element e and rest of the stack e.
Programs W , P ::= H, F, I Codebase C ::= F, I
Imports I ::= f
Functions F ::= f (x) (cid:55)→ s; return; Attackers A ::= H, F [·]
where n ∈ Z
Heaps H ::= ∅ | H; n (cid:55)→ v
Expressions e ::= x | v | e ⊕ e
Values v ::= n ∈ N
Statements s ::= skip | s; s | let x = e in s | call f e | e := e
| e :=pr e | let x = rd e in s | let x = rdpr e in s
| ifz e then s else s | let x = e (if e) in s | lfence
We model components, i.e., partial programs (P), and attackers (A).
A (partial) program P defines its heap H, a list of functions F, and a
list of imports I, which are all the functions an attacker can define.
An attacker A just defines its heap and its functions. We indicate
the code base of a program (its functions and imports) as C.
Functions are untyped, and their bodies are sequences of state-
ments s that include standard instructions: skipping, sequencing,
let-bindings, function calls, writing the public and the private heap,
reading the public and private heap, conditional branching, condi-
tional assignments and speculation barriers. Statements can contain
expressions e, which include program variables x, natural numbers
n, arithmetic and comparison operators ⊕. Heaps H map memory
addresses n ∈ Z to values v. Heaps are partitioned in a public part
(when the domain n ≥ 0) and a private part (if n < 0). An attacker
A can only define and access the public heap. A program P defines
a private heap and it can access both private and public heaps.
2.3 Labels and Traces