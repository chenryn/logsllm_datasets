in turn suggests that, for
such methods to achieve perfect ﬂatness, they shall satisfy
∀pw ∈ Dpw, PrHW(pw) = PrPW(pw). In other words, the
probability distribution model (function) PrHW(·) of such
methods shall be equal to the password distribution model
PrPW(·) of the authentication system. It conforms to our
intuition, because password and honeyword would be indis-
tinguishable if they have the same distribution.
This in turn indicates that, for a method to be perfect,
PrHW(·) shall be the same with PrPW(·), while the latter
primarily depends on the underlying system (e.g., language,
service type and password policy) and can be approximated by
various probabilistic password models (e.g., List, PCFG-based
[58], Markov-based [40] and TarGuess [56]). This suggests
that these password models can be potentially employed to
build honeyword methods (i.e., PrHW(·)), and we show how
to make it a reality in the next section.
B. Three extensions
In the above, we have only investigated the best attacking
strategies for a distinguishing attacker A who is with capa-
bilities of A1 (see Table I). A1 does not exploit user PII
or user registration order. Yet, in reality a large fraction of
users (i.e., 36.95%∼51.43% [53]) build passwords with their
own PII; in Sec. IV, we show user registration order can also
be exploitable. We now provide the best attacking theory for
attackers A2, A3 and A4, respectively.
We demonstrate that, similar as attackers of type-A1, the
attackers of type- A2, A3 and A4 have the same equations of
∏
best attacking theories except with one more condition X.
∏
l̸=j Pr(hwi;ljpwi;j , X)
jX)
jX)
Pr(pwi;j
k
t=1 Pr(pwi;t
l̸=t Pr(hwi;ljpwi;t, X)
jSWi, X) =
Pr(pwi;j
∑
,
(5)
where the condition X is the personally identiﬁable informa-
tion (PII) for type-A2 attacker, the registration order Reg for
type-A3 attacker and (PII, Reg) for type-A4 attacker. In what
follows, we take X=PII for a concrete example.
Theorem 3: Let pwi;j (1 ≤ j ≤ k) denote the event that
Ui selects swi;j as her password, hwi;j denote that swi;j is
produced as Ui’s honeyword, and PII denote Ui’s PII. We have
∏
l̸=j Pr(hwi;l|pwi;j ;PII)
|SWi, PII) =
,
Pr(pwi;j
l̸=t Pr(hwi;l|pwi;t;PII)
under the assumption that hwi;1, . . . , hwi;j−1, hwi;j+1, . . . ,
hwi;k are mutually independent under the event (pwi;j, PII).
The detailed proof can be found in Appendix C.
We now instantiate/simplify Eq. 5, and derive the optimal
honeyword attacking strategies for type-A2∼A4 attackers un-
der these two cases of different honeyword methods.
For attackers of type-A2. As with a type-A1 attacker, there
are two cases (see the detailed deﬁnition in Sec. III-A) to be
considered for different types of honeyword methods.
Similar to Eq. 3, Eq. 6 explains that for non-password-model
based methods to be secure, probabilities of all sweetwords
in the same sweetword space should be approximately the
same under targeted password models. This is more difﬁcult
to achieve than the trawling scenario, because the probabilities
of targeted password models would change more drastically
∑
|PII)
Pr(pwi;j
k
t=1 Pr(pwi;t
∏
|PII)
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:19:56 UTC from IEEE Xplore.  Restrictions apply. 
972
k
. (6)
Case1 : Pr(pwi;j
|SWi, PII) =
[56]. Eq. 7, like Eq. 4, shows that for password-model based
methods to be secure, the targeted distribution of honeywords
∑
should be close enough to the distribution of passwords.
PrPW(swi;j|PII)
t=1 PrPW(swi;t|PII)
∑
PrPW(swi;j|PII)
PrHW(swi;j|PII)
(7)
Case2 : Pr(pwi;j
For attackers of type-A3. As user registration order is mainly
meaningful for password-model based methods, a type-A3
attacker is restricted to Case 2 in Sec. III-A. More speciﬁcally,
for Eq. 4, the attacker A can improve PrPW(swi;j) to be
PrPW(swi;j|Reg) and PrHW(swi;t) to PrHW(swi;t|Reg) by
using user registration order (e.g., by adaptively updating her
training set):
PrPW(swi;t|PII)
PrHW(swi;t|PII)
|SWi, PII) =
k
t=1
.
PrPW(swi;j )
PrHW(swi;j|Reg)
PrPW(swi;t)
|SWi, Reg) =
Pr(pwi;j
(8)
For attackers of type-A4. When a type-A3 attacker is further
equipped with user PII, she can improve her advantages by
combining Eqs. 7 and 8 to get:
PrHW(swi;t|Reg)
k
t=1
.
∑
Pr(pwi;j
|SWi, PII, Reg) =
∑
PrPW(swi;j|PII)
PrHW(swi;j|PII;Reg)
PrPW(swi;t|PII)
PrHW(swi;t|PII;Reg)
k
t=1
.
(9)
C. Applications of our attacking theories
We now show how to apply the above attacking theories
to design more effective attacks. Without loss of generality,
here we take the tweaking-tail method in [35] as the target
method. First of all, since Theorems 1 and 2 are general
(according to their deﬁnitions), so they can be readily applied
to any method. The next step is to choose the right attacking
theories by analyzing the properties of the method under study.
Since the tweaking-tail method satisﬁes the Property 1∼3, for
a type-A1 attacker, Eq. 3 is applicable; for a type-A2 attacker,
Eq. 6 is applicable. Since Ui’s honeywords generated by the
tweaking-tail method only relate to Ui’s real password PWi,
the registration order will be useless. Thus, in this case, type-
A3 and A4 attackers will not be more effective than type-A1
and A2 ones, respectively. In all, mainly Eqs. 3 and 6 are
helpful for attacking the tweaking-tail method.
Essentially, Wang et al.’s empirical evaluations [53] of Juels-
Rivest’s four methods [35] can be seen as some applications
of our attacking theories Eqs. 3 and 6, while their empirical
evaluations of two password-model based methods (i.e., PCFG
and Markov) can be seen as the applications of our attacking
theories Eq. 4. More specially, their “Norm top-PW” attacks
(see Fig. 7 of [53]) against Juels-Rivest’s four methods [35]
are instantiations of Eq. 3 for the type-A1 attacker, and Eqs.
6 for the type-A2 attacker; their “Norm PW-model” attacks
(see Fig. 10 of [53]) against password-model based methods
are instantiations of Eq. 4. This explains why Wang et al.’s
attacks are effective, and resolves their open question [53]:
“Is our attacking strategy optimal?”
Wang et al. [53] show that, if the attacker A2 exploits the
victim’s PII but the honeyword generation method does not
consider user PII, A2 can indeed improve her chance. Also
take the Tweaking-tail method as an example. As revealed
in Fig. 7(a) of [53], A2 can guess 47.1%∼61.3% more real
passwords when T2=104, and achieve 40.9%∼51.6% more
success rates in terms of the ϵ-ﬂatness metric (see the point
(x=1, y=0.5) in Fig. 7(d) of [53]). What’s most disturbing
is that, against every method, PII-enriched attackers now can
attain over 49.5% of success rates in distinguishing the real
password from 19 honeywords with only one guess (i.e., being
0.495+-ﬂat), while the desirable, optimal security is 0.05-ﬂat.
In the above we assume
that all hashed sweetwords
can be cracked and known to
A, yet in reality there might
be a portion of sweetwords
that are difﬁcult to be recov-
ered. Still, this new assump-
tion does not change our
optimal attacking strategies
in terms of ﬂatness: Now
the attacker only needs to
apply our strategy to these
cracked sweetwords. This is
essentially the “nut” strategy
in [35]: The attacker is more likely to crack user-chosen
passwords, but not hard honeywords (“nuts”).
Fig. 2. Success-number graph of the
honeyword method 1
3 Markov
+ 1
3 PCFG (see Sec. IV). Trained on
Dodonew-tr,
tested on Dodonew-ts.
Uncracked sweetwords are selected in
four ways: randomly or deemed strong
by Zxcvbn [59], per account (Local)
or among all sweetwords (Global).
3 List + 1
3List+ 1
3Markov+ 1
Comparatively, it is challenging to derive the optimal strat-
egy in terms of success number under the new assumption,
but we empirically show that simple approximations can
work very well. We experiment with the attacker’s strategy
treats all uncracked sweetwords as honeywords. The
that
server uses the 1
3PCFG model to generate
honeywords, and the trawling attacker accordingly uses the
strategy in Sec. IV to instantiate probabilistic models. Fig.
2 shows that when 20% uncracked sweetwords are selected
randomly, A’s success number is close to the ideal case (where
all sweetwords are cracked); when 20% strongest sweetwords
are marked as uncracked according to the Zxcvbn PSM [59],
A can even gain a higher advantage than the ideal case. This is
because Zxcvbn [59] helps eliminate these top 20% strongest
sweetwords which are more likely to be produced by password
models as honeywords. We obtain similar results no matter
the uncracked sweetwords are selected locally (per account)
or globally (in the whole sweetword ﬁle).
Summary. We, for the ﬁrst time, propose a series of theoretic
honeyword guessing models, each of which is based on varied
kinds of capabilities allowed to an attacker. Particularly, we are
the ﬁrst to consider realistic attackers that know the order of
user registration. These models enable us to design effective
experiments with real-world datasets to evaluate the strength of
a honeyword-generation method. All this pushes the evaluation
of honeywords toward statistical rigor, and also inspires the
design of robust honeyword-generation methods.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:19:56 UTC from IEEE Xplore.  Restrictions apply. 
973
Attacker type
(see Table I)
Type A1
Type A2
Type A3
Type A4
Password models used
Solutions to challenges
Our proposed method
List
TarList
+1 smooth
+1 smooth
1
3 Markov+ 1
3 List+ 1
3 TarList+ 1
3 PCFG
3 TarMarkov
1
+1 smooth; Internal training;
PrPW(·)
Pr g
HW(·) >20 tweak tail
+1 smooth; Internal training;
PrPW(·)
Pr g
HW(·) >20 tweak tail
AN OVERVIEW OF THE DESIGN AND EVALUATION SPACE OF OUR NEW HONEYWORD-GENERATION METHODS.†
TABLE V
How best to instantiate PrHW((cid:1))
How best to evaluate (i.e., compute the probabilities in Sec. III)
How best to instantiate PrPW((cid:1))
List; +1 smooth, PrPW(·)
TarList; +1 smooth, PrPW(·)
List; +1 smooth, PrPW(·)
TarList; +1 smooth, PrPW(·)
PrHW(·) =1 smooth
PrHW(·) =1 smooth
Pr g
HW(·) =1 smooth
Pr g
HW(·) =1 smooth
Same with our method
Same with our method
Same with our method
Same with our method
†The hybird method xList+yMarkov+zPCFG (x, y, z 2[0,1] and x+y+z=1) means: x fraction of honeywords are from List model, y from PCFG, etc.
+ 1
3 TarPCFG
IV. OUR NEW CONSTRUCTIONS
We now elaborate on our new construction techniques of
honeywords. Inspired by the above best “swords” (including
the attacking theories and experiments), we forge the cor-
responding “shields”—four secure and efﬁcient honeyword-
generation methods based on various representative password
models (e.g., trawling guessing models [40], [58] and targeted
guessing models [56]). However, the use of these password
models is not straightforward, but requires signiﬁcant, novel
and creative efforts, and we show this through a series of
exploratory investigations. Besides, we manage to resolve
several previously unexplored challenges that arise in the
practical deployment of a honeyword method.
A. Overview of our new constructions
The real-password related design approach in [35] have two
fundamental limitations. First, it easily reveals the features
(e.g., length and character composition) of the real password
PWi to the attacker A, once A has ofﬂine recovered a single
sweetword from the password hash ﬁle F . What’s worse, it is
inherently unable to produce k-1 honeywords with the equal
probability of Pr(PWi), because that user passwords follow
the Zipf’s law (see Case 1 in Sec. III-A). Thus, we prefer the
real-password unrelated design approach.
We consider four types of distinguishing attackers as listed
in Table I, and design one best honeyword method for each
of them. There is no single silver bullet. Our basic idea is
that, under a different kind of attacker, the best attack will be
different; to resist this different best attack, we need a different
best honeyword method. This results in our four methods
in Table V. The probabilistic password models (e.g., PCFG
[40] and Targeted-PCFG [56]) cannot be readily applied, but
require a number of tunings in both the design and evaluation
process. These tunings are particularly challenging when A is
with user registration order. The techniques in Table V and
their underlying rationales will be elaborated in what follows.
B. Exploratory experiments
With the attacking theories (see Eqs. 4, 7∼9 in Sec.
III-B), we now investigate which models with what tunings
(parameters) can best withstand a given type of attackers.
For attackers of type-A1. In this case, Eq. 4 applies. As there
are three kinds of major password models (i.e., List, Markov
and PCFG), a total of 7(=