cording to Eqs. (3) and (4).
In our implementation, we
carry out numerical integration to compute both E1 and E2
in those equations. Also we compute α(λ) for a range of
λ’s so we can compute the best possible (ε, δ) values using
Theorem 2.2. We ﬁnd that for the parameters of interest to
us, it suﬃces to compute α(λ) for λ ≤ 32.
At any point during training, one can query the privacy
loss in the more interpretable notion of (ε, δ) privacy using
Theorem 2.2. Rogers et al. [49] point out risks associated
with adaptive choice of privacy parameters. We avoid their
attacks and negative results by ﬁxing the number of iter-
ations and privacy parameters ahead of time. More gen-
eral implementations of a privacy accountant must correctly
distinguish between two modes of operation—as a privacy
odometer or a privacy ﬁlter (see [49] for more details).
Diﬀerentially private PCA. Principal component analy-
sis (PCA) is a useful method for capturing the main features
of the input data. We implement the diﬀerentially private
PCA algorithm as described in [25]. More speciﬁcally, we
take a random sample of the training examples, treat them
as vectors, and normalize each vector to unit (cid:96)2 norm to
form the matrix A, where each vector is a row in the ma-
trix. We then add Gaussian noise to the covariance matrix
AT A and compute the principal directions of the noisy co-
variance matrix. Then for each input example we apply the
312projection to these principal directions before feeding it into
the neural network.
We incur a privacy cost due to running a PCA. However,
we ﬁnd it useful for both improving the model quality and for
reducing the training time, as suggested by our experiments
on the MNIST data. See Section 4 for details.
Convolutional layers. Convolutional layers are useful for
deep neural networks. However, an eﬃcient per-example
gradient computation for convolutional layers remains a chal-
lenge within the TensorFlow framework, which motivates
creating a separate workﬂow. For example, some recent
work argues that even random convolutions often suﬃce [48,
14, 51, 56, 16].
Alternatively, we explore the idea of learning convolu-
tional layers on public data, following Jarrett et al. [32].
Such convolutional layers can be based on GoogLeNet or
AlexNet features [55, 37] for image models or on pretrained
word2vec or GloVe embeddings in language models [43, 46].
5. EXPERIMENTAL RESULTS
This section reports on our evaluation of the moments ac-
countant, and results on two popular image datasets: MNIST
and CIFAR-10.
5.1 Applying the Moments Accountant
As shown by Theorem 1, the moments accountant pro-
vides a tighter bound on the privacy loss compared to the
generic strong composition theorem. Here we compare them
using some concrete values. The overall privacy loss (ε, δ)
can be computed from the noise level σ, the sampling ra-
tio of each lot q = L/N (so each epoch consists of 1/q
batches), and the number of epochs E (so the number of
steps is T = E/q). We ﬁx the target δ = 10−5, the value
used for our MNIST and CIFAR experiments.
In our experiment, we set q = 0.01, σ = 4, and δ = 10−5,
and compute the value of ε as a function of the training
epoch E. Figure 2 shows two curves corresponding to, re-
spectively, using the strong composition theorem and the
moments accountant. We can see that we get a much tighter
estimation of the privacy loss by using the moments accoun-
tant. For examples, when E = 100, the values are 9.34
and 1.26 respectively, and for E = 400, the values are 24.22
and 2.55 respectively. That is, using the moments bound,
we achieve (2.55, 10−5)-diﬀerential privacy, whereas previ-
ous techniques only obtain the signiﬁcantly worse guarantee
of (24.22, 10−5).
5.2 MNIST
We conduct experiments on the standard MNIST dataset
for handwritten digit recognition consisting of 60,000 train-
ing examples and 10,000 testing examples [38]. Each exam-
ple is a 28 × 28 size gray-level image. We use a simple feed-
forward neural network with ReLU units and softmax of 10
classes (corresponding to the 10 digits) with cross-entropy
loss and an optional PCA input layer.
Baseline model.
Our baseline model uses a 60-dimensional PCA projection
layer and a single hidden layer with 1,000 hidden units. Us-
ing the lot size of 600, we can reach accuracy of 98.30% in
about 100 epochs. This result is consistent with what can
be achieved with a vanilla neural network [38].
Figure 2: The ε value as a function of epoch E for
q = 0.01, σ = 4, δ = 10−5, using the strong composition
theorem and the moments accountant respectively.
Differentially private model.
For the diﬀerentially private version, we experiment with
the same architecture with a 60-dimensional PCA projection
layer, a single 1,000-unit ReLU hidden layer, and a lot size of
600. To limit sensitivity, we clip the gradient norm of each
layer at 4. We report results for three choices of the noise
scale, which we call small (σ = 2, σp = 4), medium (σ =
4, σp = 7), and large (σ = 8, σp = 16). Here σ represents
the noise level for training the neural network, and σp the
noise level for PCA projection. The learning rate is set at 0.1
initially and linearly decreased to 0.052 over 10 epochs and
then ﬁxed to 0.052 thereafter. We have also experimented
with multi-hidden-layer networks. For MNIST, we found
that one hidden layer combined with PCA works better than
a two-layer network.
Figure 3 shows the results for diﬀerent noise levels.
In
each plot, we show the evolution of the training and testing
accuracy as a function of the number of epochs as well as
the corresponding δ value, keeping ε ﬁxed. We achieve 90%,
95%, and 97% test set accuracy for (0.5, 10−5), (2, 10−5),
and (8, 10−5)-diﬀerential privacy respectively.
One attractive consequence of applying diﬀerentially pri-
vate SGD is the small diﬀerence between the model’s ac-
curacy on the training and the test sets, which is consis-
tent with the theoretical argument that diﬀerentially private
training generalizes well [7]. In contrast, the gap between
training and testing accuracy in non-private training, i.e.,
evidence of overﬁtting, increases with the number of epochs.
By using the moments accountant, we can obtain a δ value
for any given ε. We record the accuracy for diﬀerent (ε, δ)
pairs in Figure 4. In the ﬁgure, each curve corresponds to the
best accuracy achieved for a ﬁxed δ, as it varies between 10−5
and 10−2. For example, we can achieve 90% accuracy for
ε = 0.25 and δ = 0.01. As can be observed from the ﬁgure,
for a ﬁxed δ, varying the value of ε can have large impact
on accuracy, but for any ﬁxed ε, there is less diﬀerence with
diﬀerent δ values.
Effect of the parameters.
Classiﬁcation accuracy is determined by multiple factors
313(1) Large noise
(2) Medium noise
(3) Small noise
Figure 3: Results on the accuracy for diﬀerent noise levels on the MNIST dataset. In all the experiments, the
network uses 60 dimension PCA projection, 1,000 hidden units, and is trained using lot size 600 and clipping
threshold 4. The noise levels (σ, σp) for training the neural network and for PCA projection are set at (8, 16),
(4, 7), and (2, 4), respectively, for the three experiments.
we achieve better accuracy by training the PCA layer sep-
arately. By reducing the input size from 784 to 60, PCA
leads to an almost 10× reduction in training time. The re-
sult is fairly stable over a large range of the noise levels for
the PCA projection and consistently better than the accu-
racy using random projection, which is at about 92.5% and
shown as a horizontal line in the plot.
Number of hidden units. Including more hidden units
makes it easier to ﬁt the training set. For non-private train-
ing, it is often preferable to use more units, as long as we
employ techniques to avoid overﬁtting. However, for diﬀer-
entially private training, it is not a priori clear if more hidden
units improve accuracy, as more hidden units increase the
sensitivity of the gradient, which leads to more noise added
at each update.
Somewhat counterintuitively,
increasing the number of
hidden units does not decrease accuracy of the trained model.
One possible explanation that calls for further analysis is
that larger networks are more tolerant to noise. This prop-
erty is quite encouraging as it is common in practice to use
very large networks.
Lot size. According to Theorem 1, we can run N/L epochs
while staying within a constant privacy budget. Choosing
the lot size must balance two conﬂicting objectives. On the
one hand, smaller lots allow running more epochs, i.e., passes
over data, improving accuracy. On the other hand, for a
larger lot, the added noise has a smaller relative eﬀect.
Our experiments show that the lot size has a relatively
large impact on accuracy. Empirically, the best lot size is
roughly
N where N is the number of training examples.
√
Learning rate. Accuracy is stable for a learning rate in
the range of [0.01, 0.07] and peaks at 0.05, as shown in Fig-
ure 5(4). However, accuracy decreases signiﬁcantly if the
learning rate is too large. Some additional experiments sug-
gest that, even for large learning rates, we can reach similar
levels of accuracy by reducing the noise level and, accord-
ingly, by training less in order to avoid exhausting the pri-
vacy budget.
Clipping bound. Limiting the gradient norm has two op-
posing eﬀects: clipping destroys the unbiasedness of the gra-
dient estimate, and if the clipping parameter is too small,
the average clipped gradient may point in a very diﬀerent
Figure 4: Accuracy of various (ε, δ) privacy values
on the MNIST dataset. Each curve corresponds to
a diﬀerent δ value.
that must be carefully tuned for optimal performance. These
factors include the topology of the network, the number of
PCA dimensions and the number of hidden units, as well as
parameters of the training procedure such as the lot size and
the learning rate. Some parameters are speciﬁc to privacy,
such as the gradient norm clipping bound and the noise level.
To demonstrate the eﬀects of these parameters, we manip-
ulate them individually, keeping the rest constant. We set
the reference values as follows: 60 PCA dimensions, 1,000
hidden units, 600 lot size, gradient norm bound of 4, ini-
tial learning rate of 0.1 decreasing to a ﬁnal learning rate
of 0.052 in 10 epochs, and noise σ equal to 4 and 7 respec-
tively for training the neural network parameters and for the
PCA projection. For each combination of values, we train
until the point at which (2, 10−5)-diﬀerential privacy would
be violated (so, for example, a larger σ allows more epochs
of training). The results are presented in Figure 5.
PCA projection.
In our experiments, the accuracy is
fairly stable as a function of the PCA dimension, with the
best results achieved for 60. (Not doing PCA reduces ac-
curacy by about 2%.) Although in principle the PCA pro-
jection layer can be replaced by an additional hidden layer,
314(1) variable projection dimensions
(2) variable hidden units
(3) variable lot size
(4) variable learning rate
(5) variable gradient clipping norm
(6) variable noise level
Figure 5: MNIST accuracy when one parameter varies, and the others are ﬁxed at reference values.
direction from the true gradient. On the other hand, in-
creasing the norm bound C forces us to add more noise to
the gradients (and hence the parameters), since we add noise
based on σC. In practice, a good way to choose a value for
C is by taking the median of the norms of the unclipped
gradients over the course of training.
Noise level. By adding more noise, the per-step privacy
loss is proportionally smaller, so we can run more epochs
within a given cumulative privacy budget. In Figure 5(5),
the x-axis is the noise level σ. The choice of this value has
a large impact on accuracy.
From the experiments, we observe the following.
1. The PCA projection improves both model accuracy
and training performance. Accuracy is quite stable
over a large range of choices for the projection dimen-
sions and the noise level used in the PCA stage.
2. The accuracy is fairly stable over the network size.
When we can only run smaller number of epochs, it is
more beneﬁcial to use a larger network.
3. The training parameters, especially the lot size and
the noise scale σ, have a large impact on the model
accuracy. They both determine the “noise-to-signal”
ratio of the sanitized gradients as well as the number
of epochs we are able to go through the data before
reaching the privacy limit.
Our framework allows for adaptive control of the training
parameters, such as the lot size, the gradient norm bound
C, and noise level σ. Our initial experiments with decreas-
ing noise as training progresses did not show a signiﬁcant
improvement, but it is interesting to consider more sophis-
ticated schemes for adaptively choosing these parameters.
5.3 CIFAR
We also conduct experiments on the CIFAR-10 dataset,
which consists of color images classiﬁed into 10 classes such
as ships, cats, and dogs, and partitioned into 50,000 training
examples and 10,000 test examples [1]. Each example is a
32 × 32 image with three channels (RGB). For this learning
task, nearly all successful networks use convolutional layers.
The CIFAR-100 dataset has similar parameters, except that
images are classiﬁed into 100 classes; the examples and the
image classes are diﬀerent from those of CIFAR-10.
We use the network architecture from the TensorFlow con-
volutional neural networks tutorial [2]. Each 32 × 32 image
is ﬁrst cropped to a 24 × 24 one by taking the center patch.
The network architecture consists of two convolutional lay-
ers followed by two fully connected layers. The convolutional
layers use 5 × 5 convolutions with stride 1, followed by a
ReLU and 2 × 2 max pools, with 64 channels each. Thus
the ﬁrst convolution outputs a 12 × 12 × 64 tensor for each
image, and the second outputs a 6×6×64 tensor. The latter
is ﬂattened to a vector that gets fed into a fully connected
layer with 384 units, and another one of the same size.
This architecture, non-privately, can get to about 86% ac-
curacy in 500 epochs. Its simplicity makes it an appealing
choice for our work. We should note however that by us-
ing deeper networks with diﬀerent non-linearities and other
advanced techniques, one can obtain signiﬁcantly better ac-
curacy, with the state-of-the-art being about 96.5% [28].
As is standard for such image datasets, we use data aug-
mentation during training. For each training image, we gen-
erate a new distorted image by randomly picking a 24 × 24
patch from the image, randomly ﬂipping the image along
the left-right direction, and randomly distorting the bright-
ness and the contrast of the image.
In each epoch, these
315(1) ε = 2
(2) ε = 4
(3) ε = 8
Figure 6: Results on accuracy for diﬀerent noise levels on CIFAR-10. With δ set to 10−5, we achieve accuracy
67%, 70%, and 73%, with ε being 2, 4, and 8, respectively. The ﬁrst graph uses a lot size of 2,000, (2) and (3)
use a lot size of 4,000. In all cases, σ is set to 6, and clipping is set to 3.
distortions are done independently. We refer the reader to
the TensorFlow tutorial [2] for additional details.
As the convolutional layers have shared parameters, com-
puting per-example gradients has a larger computational
overhead. Previous work has shown that convolutional lay-
ers are often transferable: parameters learned from one data-
set can be used on another one without retraining [32]. We
treat the CIFAR-100 dataset as a public dataset and use it
to train a network with the same architecture. We use the
convolutions learned from training this dataset. Retrain-
ing only the fully connected layers with this architecture for
about 250 epochs with a batch size of 120 gives us approxi-
mately 80% accuracy, which is our non-private baseline.
Differentially private version.
For the diﬀerentially private version, we use the same ar-
chitecture. As discussed above, we use pre-trained convolu-
tional layers. The fully connected layers are initialized from
the pre-trained network as well. We train the softmax layer,
and either the top or both fully connected layers. Based on
looking at gradient norms, the softmax layer gradients are
roughly twice as large as the other two layers, and we keep
this ratio when we try clipping at a few diﬀerent values be-
tween 3 and 10. The lot size is an additional knob that we