tiveness of MADE on detecting HTTPS malicious communication
with limited set of features, but this is an interesting topic for future
work.
Adversarial evasion. Adversarial attacks against supervised learn-
ing models have been highly effective in domains such as image
classification [14], face recognition [56], and cyber security [25].
We believe that some of these attack strategies could be adapted
to work against the machine learning models employed by MADE.
Attackers could manipulate some of the high-importance features
used by MADE to modify the results of classification. For instance,
the highest-rank feature in MADE is domain age, and therefore at-
tackers could register a domain in advance before using it for C&C
communication. However, this will incur some monetary costs to
attackers. It is also relatively straightforward for attackers to modify
communication profiles to malicious domains (such as bytes sent
and received, their ratio, user-agent strings, and URLs). Still, design-
ing an optimal evasion strategy in this setting is currently an open
problem, particularly in the black-box attack model when attackers
do not have access to the training set and details of the ML algorithm.
We also conjecture that enterprise-specific features (such as UA pop-
ularity) are harder to evade as attackers need additional information
about enterprise legitimate communications to design their evasive
attack samples. An additional challenge from attacker’s perspective
is that MADE uses random forests (ensemble of hundreds of trees),
currently believed to be more difficult to evade than linear models
(e.g., logistic regression or SVM).
5 RELATED WORK
Our work aims to detect suspicious HTTP communications in an
enterprise setting through machine learning analysis. There is a large
body of related literature in detecting malicious domains related to
spam, command-and-control activities or malware delivery, as well
as applying machine learning models to security datasets.
Detecting malicious domains. Ma et al. [40] evaluate a large num-
ber of features, including WHOIS, geographical, and URL lexical
features for detecting spam URLs. Zhao and Hoi [67] propose an
active learning framework for URL classification to handle imbal-
anced training datasets. Kruegel and Vigna [36] identify anomalies
in URL structure to detect web attacks. Soska and Cristin [58] design
a classifier for predicting the compromise of a website based on web
page structure and traffic statistics.
Several systems, e.g., Notos [8] and EXPOSURE [13], build
generic domain reputation systems by applying classification algo-
rithms on passive DNS data. Kopis [9] analyzes DNS data collected
at the upper level of the DNS hierarchy. Felegyhazi et al. [22] proac-
tively identify malicious domains by mining DNS zone files and
WHOIS registration information. Antonakakis et al. [10] build a
detector for DGA domains using a combination of lexical, entropy
and structural features extracted from DNS traffic collected from
an ISP. Segugio [51] propagates reputation scores from benign or
compromised machines to visited domains in the DNS query graph.
Comparing to HTTP logs, DNS logs include much less informa-
tion about external destinations visited by enterprise machines, are
smaller in size, and have lower risk of revealing user private infor-
mation. Therefore, DNS detection systems have an advantage when
storage and privacy (as mandated by recent European regulations)
are major concerns. On the downside, fewer features can be extracted
from DNS logs (as for example, the URL in HTTP connections is
not available). DNS logs are thus amenable for detecting certain
classes of malware (for instance, DGA or fast-flux), but are limited
in their ability to detect broader malicious communication.
Other data sources have been used for identifying malicious do-
mains. DISCLOSURE [12] and BotFinder [63] build models to
detect C&C traffic using features extracted from NetFlow records.
BotMiner [26] applies clustering to features extracted from network
flows for botnet detection. Nazca [33] detects malware delivery net-
works through graph analysis of web requests from ISP networks.
PREDATOR [28] designs a system for predicting domain reputation
at registration time. Shady Path [61] detects malicious web pages
by analyzing how a large set of browsers interact with web pages
and extracting characteristics from the redirection graphs generated
to these web pages. CAMP [52] leverages features collected from
users’ browsers during the file downloading process (e.g., the fi-
nal download URL and IP address) to identify malware hosted by
websites.
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Alina Oprea, Zhou Li, Robin Norris, and Kevin Bowers
Enterprise log analysis. In addition to the systems surveyed in
Table 1, we mention several enterprise log analysis systems. Bee-
hive [65] applies anomaly detection to identify suspicious enterprise
hosts. This is orthogonal to detecting malicious communication pat-
terns. Several papers [15, 41] use the idea of propagating trust in
the communication graph for detecting malicious domains. Web-
Witness [46] proposes a forensics method to determine malware
download paths after a malicious download event is detected.
Industry solutions. Applying machine learning to detect malicious
activities and reduce the workload of SOC has become popular in
cyber-security industry in recent years [49, 53]. Machine-learning
models have been applied in security applications such as automated
endpoint analysis (e.g., detecting malware based endpoint system
traces) [17, 23, 62], cloud instance monitoring (e.g., detect anoma-
lous account access) [7, 43], user behavioral analysis (e.g., identify-
ing users with high risk scores) [31, 54, 59], network communication
analysis (e.g., detecting malicious domains) [20, 55], security or-
chestration (e.g., assigning alert tickets to security analysts) [18],
and event triaging from data collected by SIEM [32, 39, 64]. MADE
focuses on prioritizing alerts related to enterprise malicious web
communications and can detect a range of malicious activities.
6 CONCLUSION
We describe the MADE system for detecting malicious HTTP com-
munication in enterprises by web proxy log analysis. MADE is built
in collaboration with SOC tier 3 analysts at a large enterprise and
leverages an extensive set of enterprise-specific and generic features
for capturing malicious behavior. The goal of MADE is to assign
risk scores to external destinations contacted by enterprise hosts
and prioritize the most suspicious ones. MADE is able to achieve
97% precision in the set of 100 highest-risk domains detected over a
month at only 6 · 10−5 FPR. MADE was successfully used in pro-
duction and discovered new malicious domains (not identified by
several state-of-the-art security technologies). Avenues for future
work include adversarial analysis of MADE (which features and ML
models are more resilient against advanced attackers), expanding the
set of malicious activities, and combining network with host data for
more comprehensive view into malicious campaigns.
ACKNOWLEDGEMENTS
We would like to thank the enterprise that gave us access to the
web proxy logs for analysis. We are grateful to the entire EMC
Critical Incident Response Center (CIRC) for their support over
several years when this work was performed. We would like to thank
Todd Leetham and Christopher Harrington for their suggestions in
designing MADE, insightful discussions on latest attacker trends,
and help with evaluating our findings. We also thank the RSA Data
Science team and RSA Engineering for their work on transitioning
MADE to production. Finally, we thank our shepherd Gianluca
Stringhini and the anonymous reviewers for their feedback on the
paper.
REFERENCES
[1] MaxMind. http://www.maxmind.com/.
[2] VirusTotal. http://www.virustotal.com/.
[3] Verizon 2018 data breach investigations report. https://www.verizonenterprise.
com/verizon-insights-lab/dbir/, 2018.
[4] Adblock Plus. EasyList. https://easylist-downloads.adblockplus.org/easylist.txt,
[5] Adblock Plus.
EasyPrivacy.
https://easylist-downloads.adblockplus.org/
2015.
easyprivacy.txt, 2015.
[6] Alexa. AWS | Alexa Top Sites - Up-to-date lists of the top sites on the web.
http://aws.amazon.com/alexa-top-sites/, 2014.
[7] Amazon. GuardDuty Intelligent Threat Detection AWS. https://aws.amazon.com/
guardduty/, 2018.
[8] Manos Antonakakis, Roberto Perdisci, David Dagon, Wenke Lee, and Nick Feam-
ster. Building a dynamic reputation system for DNS. In Proc. 19th USENIX
Security Symposium, 2010.
[9] Manos Antonakakis, Roberto Perdisci, Wenke Lee, Nikolaos Vasiloglou, II, and
David Dagon. Detecting malware domains at the upper DNS hierarchy. In Proc.
20th USENIX Security Symposium, 2011.
[10] Manos Antonakakis, Roberto Perdisci, Yacin Nadji, Nikolaos Vasiloglou, Saeed
Abu-Nimeh, Wenke Lee, and David Dagon. From throw-away traffic to bots:
Detecting the rise of DGA-based malware. In Proc. 21st USENIX Security Sympo-
sium, 2012.
[11] Karel Bartos, Michal Sofka, and Vojtech Franc. Optimized invariant representation
of network traffic for detecting unseen malware variants. In 25th USENIX Security
Symposium (USENIX Security 16), pages 807–822. USENIX Association, 2016.
[12] Leyla Bilge, Davide Balzarotti, William Robertson, Engin Kirda, and Christo-
pher Kruegel. DISCLOSURE: Detecting botnet Command-and-Control servers
through large-scale NetFlow analysis. In Proc. 28th Annual Computer Security
Applications Conference (ACSAC), ACSAC, 2012.
[13] Leyla Bilge, Engin Kirda, Kruegel Christopher, and Marco Balduzzi. EXPOSURE:
Finding malicious domains using passive DNS analysis. In Proc. 18th Symposium
on Network and Distributed System Security, NDSS, 2011.
[14] Nicholas Carlini and David A. Wagner. Towards evaluating the robustness of
neural networks. In IEEE Symposium on Security and Privacy, pages 39–57. IEEE
Computer Society, 2017.
[15] Kevin M.. Carter, Nwokedi Idika, and William. W. Streilein. Probabilistic threat
propagation for network security. IEEE Transactions on Information Forensics
and Security, 9, 2014.
[16] Sidharth Chhabra, Anupama Aggarwal, Fabricio Benevenuto, and Ponnurangam
Kumaraguru. Phi. sh/$ ocial: the phishing landscape through short urls.
In
Proceedings of the 8th Annual Collaboration, Electronic messaging, Anti-Abuse
and Spam Conference, pages 92–101. ACM, 2011.
[17] CrowdStrike. CrowdStrike Introduces Enhanced Endpoint Machine Learning
Capabilities and Advanced Endpoint Protection Modules. https://goo.gl/wVh3s9,
2017.
[18] Demisto. Top Machine Learning Use Cases â ˘A¸S Part 1. https://blog.demisto.com/
demistos-top-machine-learning-use-cases-part-1, 2018.
[19] DNS-BH. Malware Domain Blocklist. http://mirror1.malwaredomains.com/files/,
2015.
[20] Endgame. Using Deep Learning To Detect DGAs. https://www.endgame.com/
blog/technical-blog/using-deep-learning-detect-dgas, 2016.
[21] Brown Farinholt, Mohammad Rezaeirad, Paul Pearce, Hitesh Dharmdasani,
Haikuo Yin, Stevens Le Blond, Damon McCoy, and Kirill Levchenko. To catch a
Ratter: Monitoring the behavior of amateur DarkComet RAT operators in the wild.
In IEEE Symposium on Security and Privacy, pages 770–787. IEEE Computer
Society, 2017.
[22] Mark Felegyhazi, Christian Keibich, and Vern Paxson. On the potential of proac-
tive domain blacklisting. In Proc. Third USENIX LEET Workshop, 2010.
[23] FireEye. Reverse Engineering the Analyst: Building Machine Learning Models for
the SOC. https://www.fireeye.com/blog/threat-research/2018/06/build-machine-
learning-models-for-the-soc.html, 2018.
[24] WPO Foundation. CDN list. https://raw.githubusercontent.com/WPO-Foundation/
webpagetest/master/agent/wpthook/cdn.h, 2015.
[25] Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michae l Backes, and
Patrick D. McDaniel. Adversarial examples for malware detection. In ESORICS
(2), volume 10493 of LNCS, pages 62–79. Springer, 2017.
[26] Guofei Gu, Roberto Perdisci, Junjie Zhang, and Wenke Lee. BotMiner: Clustering
analysis of network traffic for protocol and structure-independent botnet detection.
In Proc. 17th USENIX Security Symposium, 2008.
[27] Tristan Halvorson, F. Matthew Der, Ian Foster, Stefan Savage, K. Lawrence Saul,
and M.Geoffrey Voelker. From .academy to .zone: An analysis of the new tld land
rush. In 15th Internet Measurement Conference (IMC), 2015.
[28] Shuang Hao, Alex Kantchelian, Brad Miller, Vern Paxson, and Nick Feamster.
PREDATOR: Proactive recognition and elimination of domain abuse at time-of-
registration. In Proceedings of the 2016 ACM SIGSAC Conference on Computer
and Communications Security, CCS ’16, pages 1568–1579. ACM, 2016.
MADE: Security Analytics for Enterprise Threat Detection
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
[29] Thorsten Holz, Christian Gorecki, Konrad Rieck, and Felix C Freiling. Measuring
and detecting fast-flux service networks. In NDSS, 2008.
[30] Xin Hu, Jiyong Jang, Marc Ph. Stoecklin, Ting Wang, Douglas Lee Schales,
Dhilung Kirat, and Josyula R. Rao. BAYWATCH: robust beaconing detection to
identify infected hosts in large-scale enterprise networks. In DSN, pages 479–490.
IEEE Computer Society, 2016.
[31] IBM. Machine Learning Analytics app. https://goo.gl/DCFCBN, 2016.
[32] IBM. Artificial Intelligence for Smarter Cybersecurity. https://www.ibm.com/
security/artificial-intelligence, 2018.
[33] Luca Invernizzi, Stanislav Miskovic, Ruben Torres, Sabyaschi Saha, Sung-Ju Lee,
Christopher Kruegel, and Giovanni Vigna. Nazca: Detecting malware distribution
in large-scale networks. In Proc. ISOC Network and Distributed System Security
Symposium (NDSS ’14), 2014.
[34] Emi Kalita. WannaCry Ransomware Attack: Protect Yourself from WannaCry
Ransomware Cyber Risk and Cyber War. Independently published, 2017.
[35] Platon Kotzias, Leyla Bilge, and Juan Caballero. Measuring PUP prevalence
and PUP distribution through pay-per-install services. In 25th USENIX Security
Symposium (USENIX Security 16), pages 739–756, Austin, TX, 2016. USENIX
Association.
[36] Christopher Kruegel and Giovanni Vigna. Anomaly detection of web-based attacks.
In Proceedings of the 10th ACM Conference on Computer and Communications
Security, CCS ’03, pages 251–261, New York, NY, USA, 2003. ACM.
[37] Zhou Li, Sumayah Alrwais, Yinglian Xie, Fang Yu, and XiaoFeng Wang. Find-
ing the linchpins of the dark web: A study on topologically dedicated hosts on
malicious web infrastructures. In Proceedings of the 2013 IEEE Symposium on
Security and Privacy, SP ’13, pages 112–126. IEEE Computer Society, 2013.
[38] Jinjin Liang, Jian Jiang, Haixin Duan, Kang Li, Tao Wan, and Jianping Wu. When
https meets cdn: A case of authentication in delegated service. In Security and
Privacy (SP), 2014 IEEE Symposium on, pages 67–82. IEEE, 2014.
[39] LogRhythm. Big Data Analytics. https://logrhythm.com/solutions/security/
security-analytics/, 2018.
[40] Justin Ma, Lawrence K. Saul, Stefan Savage, and Geoffrey M. Voelker. Beyond
blacklists: Learning to detect malicious web sites from suspicious URLs. In Proc.
15th ACM International Conference on Knowledge Discovery and Data Mining,
KDD, 2009.
[41] Pratyusa K. Manadhata, Sandeep Yadav, Prasad Rao, and William Horne. De-
tecting malicious domains via graph inference. In 19th European Symposium on
Research in Computer Security (ESORICS), 2014.
[42] MANDIANT. APT1: Exposing one of China’s cyber espionage units. Report
available from www.mandiant.com, 2013.
[43] Microsoft. Machine Learning in Azure Security Center. https://azure.microsoft.
com/en-us/blog/machine-learning-in-azure-security-center/, 2016.
[44] Shai Morag. Best practices for the SOC team â ˘A¸S where to automate, where to
think. https://www.infosecurity-magazine.com/opinions/best-practices-for-the-
soc-team, 2016.
[45] Terry Nelms, Roberto Perdisci, and Mustaque Ahamad. ExecScent: Mining for
new C&C domains in live networks with adaptive control protocol templates. In
Proc. 22nd USENIX Security Symposium, 2013.
[46] Terry Nelms, Roberto Perdisci, Manos Antonakakis, and Mustaque Ahamad.
WebWitness: Investigating, categorizing, and mitigating malware download paths.
In 24th USENIX Security Symposium (USENIX Security 15), pages 1025–1040,
Washington, D.C., 2015. USENIX Association.
[47] Alina Oprea, Zhou Li, Ting-Fang Yen, Sang Chin, and Sumayah Alrwais. Detec-
tion of early-stage enterprise infection by mining large-scale log data. In Proc.
IEEE/IFIP International Conference on Dependable Systems and Networks (DSN),
2015.
[48] Optimize Smart. Geek guide to removing referrer spam in Google Analyt-
ics. http://www.optimizesmart.com/geek-guide-removing-referrer-spam-google-
analytics, 2015.
[49] Paul Dwyer. The Security Operations Center Is Evolving Into a Risk Ana-
lytics Center. https://securityintelligence.com/the-security-operations-center-is-
evolving-into-a-risk-analytics-center/, 2018.
[50] Roberto Perdisci, Wenke Lee, and Nick Feamster. Behavioral clustering of HTTP-
based malware and signature generation using malicious network traces.
In
Proc. 7th USENIX Conference on Networked Systems Design and Implementation,
NSDI’10, 2010.
[51] Babak Rahbarini, Roberto Perdisci, and Manos Antonakakis. Segugio: Efficient
behavior-based tracking of malware-control domains in large isp networks. In
Proc. IEEE/IFIP International Conference on Dependable Systems and Networks
(DSN), 2015.
[52] Moheeb Abu Rajab, Lucas Ballard, Noe Lutz, Panayiotis Mavrommatis, and Niels
Provos. CAMP: content-agnostic malware protection. In Proc. ISOC Network
and Distributed System Security Symposium (NDSS ’13), 2013.
[53] Robert Lemos. AI is changing SecOps: What security analysts need to know. https:
//techbeacon.com/ai-changing-secops-what-security-analysts-need-know, 2018.
[54] RSA. NetWitness UEBA. https://www.rsa.com/en-us/products/threat-detection-
response/ueba, 2018.
[55] RSA. Threat Detection and Response NetWitness Platform. https://www.rsa.com/
en-us/products/threat-detection-response, 2018.
[56] Mahmood Sharif, Sruti Bhagavatula, Lujo Bauer, and Michael K Reiter. Acces-
sorize to a crime: Real and stealthy attacks on state-of-the-art face recognition. In
Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communica-
tions Security, pages 1528–1540. ACM, 2016.
[57] Robin Sommer and Vern Paxson. Outside the closed world: On using machine
learning for network intrusion detection. In Proc. IEEE Symposium on Security
and Privacy, SP ’10. IEEE Computer Society, 2010.
[58] Kyle Soska and Nicolas Christin. Automatically detecting vulnerable websites be-
fore they turn malicious. In Proceedings of the 23rd USENIX Security Symposium,
San Diego, CA, USA, August 20-22, 2014., pages 625–640, 2014.
[59] Splunk. SIEM - Security Information and Event Management. https://goo.gl/
Ljtc6t, 2018.
[60] Brett Stone-Gross, Christopher Kruegel, Kevin Almeroth, Andreas Moser, and
Engin Kirda. Fire: Finding rogue networks. In Computer Security Applications
Conference, 2009. ACSAC’09. Annual, pages 231–240. IEEE, 2009.
[61] Gianluca Stringhini, Christopher Kruegel, and Giovanni Vigna. Shady Paths:
Leveraging surfing crowds to detect malicious web pages. In Proc. 20th ACM
Conference on Computer and Communications Security, CCS, 2013.
[62] Symantec. How does Symantec Endpoint Protection use advanced machine learn-
ing? https://support.symantec.com/en_US/article.HOWTO125816.html, 2018.
[63] Florian Tegeler, Xiaoming Fu, Giovanni Vigna, and Christopher Kruegel.
BotFinder: Finding bots in network traffic without deep packet inspection. In
Proc. 8th International Conference on Emerging Networking Experiments and
Technologies, CoNEXT ’12, 2012.
[64] VECTRA. Cognito Detect is the most powerful way to find and stop cyberattackers
in real time. https://vectra.ai/assets/cognito-detect-overview.pdf, 2018.
[65] Ting-Fang Yen, Alina Oprea, Kaan Onarlioglu, Todd Leetham, William Robertson,
Ari Juels, and Engin Kirda. Beehive: Large-scale log analysis for detecting
suspicious activity in enterprise networks. In Proc. 29th Annual Computer Security
Applications Conference, ACSAC ’13, 2013.
[66] Apostolis Zarras, Alexandros Kapravelos, Gianluca Stringhini, Thorsten Holz,
Christopher Kruegel, and Giovanni Vigna. The dark alleys of madison avenue:
Understanding malicious advertisements. In Proceedings of the 2014 Conference
on Internet Measurement Conference, IMC ’14, pages 373–380, New York, NY,
USA, 2014. ACM.
[67] Peilin Zhao and Steven C.H. Hoi. Cost-sensitive online active learning with
application to malicious url detection. In Proceedings of the 19th ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining, KDD ’13,
pages 919–927, New York, NY, USA, 2013. ACM.