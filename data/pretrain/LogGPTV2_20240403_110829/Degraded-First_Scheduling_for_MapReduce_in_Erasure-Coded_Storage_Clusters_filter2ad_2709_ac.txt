 5
 4
 3
 2
 1
100
200
500
1000
Switch bandwidth (Mbps)
locality-first
degraded-first
(a) Erasure coding scheme
(b) Numbers of native blocks
(c) Rack download bandwidth
Figure 5. Numerical analysis results of locality-ﬁrst scheduling and degraded-ﬁrst scheduling.
· (R−1)kS
tasks (which takes time F T
N L ). Each rack is assumed to
have F
N R degraded tasks, so the total time required for all
degraded reads is F
RW . We further assume that the
N R
F
N blocks of the degraded tasks can be processed in parallel
by all available map slots in the cluster in a single map-slot
duration T . Thus, by summing up the times for local tasks
and degraded tasks, the MapReduce runtime under locality-
ﬁrst scheduling is:
F T
(R − 1)kS
F
+
·
N L
N R
RW
+ T.
Degraded-ﬁrst scheduling. We next consider degraded-ﬁrst
scheduling, which spreads the launch of degraded tasks over
the whole map phase. Here, we assume that the map tasks
are launched in a lock-step manner, such that the map phase
is divided into rounds, each of which launches the same
number of map tasks given all available slots. Since there
are a total of F map tasks and (N − 1)L available map slots
(N −1)L rounds of
in failure mode, there are approximately
launching the map tasks.
F
F
We need to address two cases in our analysis: (1) the
degraded tasks can ﬁnish degraded reads in one round and
(2) the degraded tasks need to ﬁnish degraded reads in more
than one round. In the ﬁrst case, it implies that all degraded
reads can be ﬁnished within
(N −1)L rounds, each of which
spans a slot duration T . Assuming that all degraded tasks
are further processed in parallel within a map-slot duration
+
T (as in above), the upper bound of the runtime is
T . In the second case, the bottleneck is the inter-rack data
transmission of degraded reads. Since each rack has F
N R
degraded tasks, it needs to spend the download time F
×
N R
(R−1)kS
RW . An additional time T is needed to process the
degraded tasks. While the racks are downloading data during
degraded reads, the local map tasks can be processed in
parallel. Thus, the runtime of the second case should be
F
+ T . Combining both cases, the MapReduce
· (R−1)kS
(N −1)L
F T
N R
runtime under degraded-ﬁrst scheduling is:
RW
(cid:3)
(cid:2)
max
F T
(N − 1)L
+ T,
F
N R
·
(R − 1)kS
RW
+ T
.
424424424
Numerical results. Based on our analysis, we now present
the MapReduce runtime results under different parameter
settings. The default cluster conﬁgurations are ﬁxed as: N =
40, R = 4, L = 4, S = 128MB, W = 1Gbps, T = 20s,
F = 1440, and (n, k) = (16, 12). We then vary one of
the parameters and compare the MapReduce runtimes under
locality-ﬁrst scheduling and degraded-ﬁrst scheduling. The
runtimes are normalized over that in normal mode (without
node failures).
Figure 5(a) shows the runtime results for different era-
sure coding schemes (8,6), (12,9), (16,12), and (20,15).
Degraded-ﬁrst scheduling always requires less runtime than
locality-ﬁrst scheduling, with the runtime reduction ranging
from 15% to 32%. The runtime of degraded-ﬁrst scheduling
stays the same since all degraded tasks can ﬁnish their
degraded reads in one round in our parameter settings.
On the other hand, the runtime of locality-ﬁrst scheduling
increases with k, since more data needs to be transmitted
for degraded reads after all local tasks are completed.
Figure 5(b) shows the runtime results versus the number
of blocks F , varied from 720 to 2880. The normalized run-
times of both scheduling algorithms decrease with F , since
the processing time of local tasks becomes more dominant.
Nevertheless, the runtime of degraded-ﬁrst scheduling is less
than that of locality-ﬁrst scheduling by 25% to 28%.
Finally, Figure 5(c) shows the runtime results versus the
download bandwidth W , varied from 100Mbps to 1Gbps.
As the download bandwidth increases, both scheduling algo-
rithms see reduced runtime as degraded reads takes less time
to ﬁnish. It is worth noting that degraded-ﬁrst scheduling
has the same runtime for W = 500Mbps and W = 1Gbps,
since the degraded tasks now can ﬁnish degraded reads in
one round. Overall, degraded-ﬁrst scheduling reduces the
runtime of locality-ﬁrst scheduling by 18% to 43%.
To summarize, in all cases, degraded-ﬁrst scheduling can
reduce the MapReduce runtime of the default locality-ﬁrst
scheduling in failure mode. Note that our analysis builds on
simpliﬁed settings. We resort to simulations for more general
scenarios (see Section V).
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:03:27 UTC from IEEE Xplore.  Restrictions apply. 
C. Enhanced Design
We describe two heuristics that further enhance the per-
formance of our basic degraded-ﬁrst scheduling implemen-
tation in Algorithm 2. Both heuristics take into account the
topology of the cluster when we schedule a set of map tasks
across the slaves.
Locality preservation. The default locality-ﬁrst scheduling
achieves high locality by ﬁrst launching local tasks whenever
they are available. On the other hand, Algorithm 2 may
break the locality. Speciﬁcally, if we ﬁrst assign degraded
tasks to a node, then the node may not have enough map
slots to process its local tasks. The master may instead
assign some of the local tasks of the node to other nodes
of different racks, and these tasks become remote tasks.
Having additional remote tasks is clearly undesirable as they
compete for network resources as degraded tasks do.
We implement
locality preservation by restricting the
launch of degraded tasks, such that we prevent the local map
tasks from being unexpectedly assigned to other nodes. We
provide a function ASSIGNTOSLAVE to determine whether
to launch a degraded task to a speciﬁc slave. Speciﬁcally,
given a set of unassigned map tasks to be scheduled, we
estimate the processing time for the local map tasks of each
slave s (denoted by ts), and the expected processing time
E[ts] for the local map tasks across all slaves. If ts > E[ts],
it means that slave s does not have spare resources to process
a degraded task, so we do not assign a degraded task to it.
We point out that our implementation also works for
heterogeneous settings, where some slaves may have better
processing power than others in the same cluster. If we
estimate the processing time for the local map tasks based
on not only the number of local map tasks, but also the
computing power of the slave node, then we allow the more
powerful slaves to process a degraded task while processing
more local map tasks.
Rack awareness. In failure mode, launching multiple de-
graded tasks in the same rack may result in competition for
network resources, since the degraded tasks download data
through the same top-of-rack switch. However, Algorithm 2
is oblivious to where a degraded task is launched.
To realize rack awareness, we provide a function AS-
SIGNTORACK to ensure that multiple degraded tasks are
not assigned to the same rack at nearly the same time.
Speciﬁcally, we keep track of the duration since the last
degraded task is assigned to each rack r (denoted by tr),
and the expected duration E[tr] across all racks. We avoid
assigning a degraded task to a slave in rack r if r satisﬁes
both of the following conditions: (1) if tr < E[tr], and (2)
if tr is less than some threshold. For the latter condition,
we choose the threshold as (R−1)kS
RW , which is the expected
time for a degraded read (see Section IV-B). Satisfying both
conditions imply that rack r has just recently launched a
degraded task that is still performing a degraded read. If
if ts < E[ts] then
Algorithm 3 Enhanced Degraded-First Scheduling
1: function ASSIGNTOSLAVE(slave s)
2:
3:
4:
5:
6: end function
end if
return true
return false
if tr < min(E[tr], threshold) then
7: function ASSIGNTORACK(rack r)
8:
9:
10:
11:
12: end function
end if
return true
return false
while a heartbeat comes from slave s do
13: procedure MAIN ALGORITHM
14:
15:
16:
17:
18:
isDegradedTaskAssigned = false
Compute ts, E[ts], tr, E[tr]
for each running job j in the job list do
if isDegradedTaskAssigned = false and
s has a free map slot then
19:
20:
end if
end if
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
end for
33:
end while
34:
35: end procedure
end if
end for
if j has an unassigned degraded task then
M
and
≥ md
Md
if m
ASSIGNTOSLAVE(s) == true and
ASSIGNTORACK(rackID(s)) == true then
assign a degraded task to s
isDegradedTaskAssigned = true
end if
for each free map slot on slave s do
if j has an unassigned local task then
assign the local task to s
else if j has an unassigned remote task then
assign the remote task to s
we launch another degraded task to rack r, it will lead to
unnecessary competition for network resources.
Putting it all together. Algorithm 3 shows the enhanced
version of degraded-ﬁrst scheduling, which includes local-
ity preservation and rack awareness through the functions
ASSIGNTOSLAVE and ASSIGNTORACK, respectively.
V. SIMULATION
We present simulation results and examine the perfor-
mance improvement of degraded-ﬁrst scheduling in general
scenarios. We implement a discrete event simulator for
MapReduce (see Section V-A). We ﬁrst compare enhanced
degraded-ﬁrst scheduling (EDF), which incorporates locality
preservation and rack awareness, with the default locality-
ﬁrst scheduling (LF) (see Section V-B). We then compare
the basic and enhanced versions of degraded-ﬁrst scheduling
(BDF and EDF, respectively), and show how locality preser-
425425425
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:03:27 UTC from IEEE Xplore.  Restrictions apply. 
Job
Master process
...
Job Queue
Map task queue,
Reduce task queue,
etc.
Request tasks
Assign tasks
Slave process
Execute tasks
Map slot process
Reduce slot process
Control Flow
Data Flow
NodeTree
Figure 6. The simulator architecture.
vation and rack awareness improve MapReduce performance
in both general and extreme cases (see Section V-C).
A. Simulator Overview
Our MapReduce simulator is a C++-based discrete event
simulator built on CSIM20 [8]. Figure 6 illustrates the
simulator architecture. We deploy processes to simulate
different components of a MapReduce system. There are
two types of processes: (1) node processes, which include
both master and slave processes, and (2) slot processes, each
of which manages either a map or reduce slot. We also
implement a NodeTree structure, which simulates a storage
cluster with two levels of switches (see Figure 2) and handles
all intra-rack and inter-rack transmission requests.
The ﬂow of the simulator is as follows. Each slave process
periodically sends heartbeats to the master process (every 3s)
and indicates in each heartbeat if it has any free slots. When
a MapReduce job is submitted, the master process initializes
the job by splitting the job into map and reduce tasks, and
enqueues the initialized job into a job queue. The map and
reduce tasks will later be assigned to slave processes via the
responses to their periodical heartbeats. If a process needs
to transmit blocks across racks (e.g., due to shufﬂe-and-sort
and degraded reads), then it notiﬁes the NodeTree structure
to hold the communication link for a duration needed for
the data transmission.
We can conﬁgure our simulator with different parameters,
such as the number of nodes, number of racks, number of
map/reduce slots per node, erasure coding scheme, schedul-
ing scheme, etc. We can also set a heterogeneous cluster
in which nodes have different processing capabilities. We
can also simulate multiple MapReduce jobs with different
numbers of map/reduce tasks and amounts of data being
shufﬂed between map and reduce tasks. The master main-
tains a job queue for all jobs in ﬁrst-in-ﬁrst-out (FIFO)
order, as the default MapReduce implementation in Hadoop
(version 0.22.0).
B. Locality-First vs. Degraded-First Scheduling
We start with considering a homogeneous cluster with the
following default conﬁgurations. It contains 40 nodes evenly
grouped into four racks (with 10 nodes each). The rack
download bandwidth is 1Gbps. The block size is 128MB.
We use (20,15) erasure codes. In contrast with the map-
only MapReduce job considered in Section IV-B, we here
consider a MapReduce job with both map and reduce tasks,
whose processing times follow normal distributions with
mean 20s and standard deviation 1s, and mean 30s and
standard deviation 2s, respectively. We allocate each node
with four map slots and one reduce slot. We create 1440
blocks in total, and randomly place them in the nodes based
on the requirements in Section III. The total number of map
tasks is equal to the total number of blocks (i.e., 1440), while
the number of reduce tasks is ﬁxed at 30. We assume that
each map task shufﬂes intermediate data of size 1% of the
block size to the reduce tasks. We simulate the single-node
failure mode by randomly disabling one of the nodes.
In each simulation experiment, we vary one of the conﬁg-
uration parameters and evaluate the impact on MapReduce
performance. For each set of parameters, we generate 30
cluster conﬁgurations with different random seeds. In each
conﬁguration, we measure the MapReduce runtime of each
of LF and EDF in failure mode, and also measure the
MapReduce runtime in normal mode without node failures
for reference. We compute the normalized runtime of each of
LF and EDF over that of normal mode. We plot a boxplot to
show the minimum, lower quartile, median, upper quartile,
and maximum of the 30 results and any outlier. Figure 7
shows the results, which we elaborate below.
Figures 7(a)-(c) show the normalized runtime results
versus the erasure coding parameters (n, k), the number of
native blocks to be processed, and the download bandwidth,
respectively. The results conform to our analysis ﬁndings in
Section IV-B. We brieﬂy summarize the results here. First,
from Figure 7(a), if we use an erasure coding scheme with
larger (n, k), EDF reduces the normalized runtime of LF by
a larger margin, ranging from 17.4% for (8,6) to 32.9% for
(20,15). Second, from Figure 7(b), as the number of native
blocks to be processed increases, the reduction of EDF over
LF drops, but EDF still reduces the normalized runtime by
34.8% to 39.6%. Finally, from Figure 7(c), the normalized
runtimes of both EDF and LF increase, while EDF reduces
the normalized runtime of LF by up to 35.1% on average
when the rack download bandwidth is 500Mbps.
We consider additional scenarios. Figure 7(d) shows the
normalized runtime results under different failure patterns,
including a single-node failure, a double-node failure, and a
rack failure. As more nodes fail, the normalized runtimes of
both scheduling schemes increase. EDF reduces the normal-
ized runtime of LF by 33.2%, 22.3%, and 5.9% on average
for a single-node failure, a double-node failure, and a rack
failure, respectively.
Figure 7(e) shows the normalized runtime results versus
the amount of intermediate data shufﬂed by map tasks. The
amount of intermediate data is conﬁgured as 1% to 30%
of that of the data processed by the map tasks. LF remains
unaffected in general since the degraded tasks run at the end
426426426
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:03:27 UTC from IEEE Xplore.  Restrictions apply. 
e
m
i
t
n
u
r
d