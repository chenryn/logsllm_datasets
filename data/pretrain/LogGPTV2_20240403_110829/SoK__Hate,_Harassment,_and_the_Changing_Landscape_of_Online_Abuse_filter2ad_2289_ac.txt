### Taxonomy of Online Hate and Harassment Attacks

**Table I: Taxonomy of online hate and harassment attacks, broken down by audience, communication channel, and capabilities involved.**

| **Category** | **Toxic Content** | **Content Leakage** | **Overloading** | **False Reporting** | **Impersonation** | **Surveillance** | **Lockout and Control** |
|--------------|------------------|---------------------|-----------------|--------------------|-------------------|------------------|-------------------------|
| **Bullying** | ✓                |                     |                 |                    |                   |                  |                         |
| **Trolling** | ✓                |                     | ✓               |                    |                   |                  |                         |
| **Hate Speech** | ✓              |                     |                 |                    |                   |                  |                         |
| **Profane or Offensive Content** | ✓ |                     |                 |                    |                   |                  |                         |
| **Threats of Violence** | ✓           |                     |                 |                    |                   |                  |                         |
| **Purposeful Embarrassment** | ✓    |                     |                 |                    |                   |                  |                         |
| **Incitement** | ✓                |                     |                 |                    |                   |                  |                         |
| **Sexual Harassment** | ✓            |                     |                 |                    |                   |                  |                         |
| **Unwanted Explicit Content (“Sexting”)** | ✓  |                     |                 |                    |                   |                  |                         |
| **Sextortion** | ✓                |                     |                 |                    |                   |                  |                         |
| **Doxing** |                     | ✓                   |                 |                    |                   |                  |                         |
| **Outing and Deadnaming** |         | ✓                   |                 |                    |                   |                  |                         |
| **Non-consensual Image Exposure (“Revenge Porn”)** | ✓  | ✓                   |                 |                    |                   |                  |                         |
| **Leaked Chats, Profiles** |         | ✓                   |                 |                    |                   |                  |                         |
| **Comment Spam** |                |                     | ✓               |                    |                   |                  |                         |
| **Dogpiling** | ✓                |                     | ✓               |                    |                   |                  |                         |
| **Raiding or Brigading** | ✓        |                     | ✓               |                    |                   |                  |                         |
| **Distributed Denial of Service (DDoS)** |                |                     | ✓               |                    |                   |                  |                         |
| **Notification Bombing** |          |                     | ✓               |                    |                   |                  |                         |
| **Zoombombing** | ✓              |                     | ✓               |                    |                   |                  |                         |
| **Negative Ratings & Reviews** | ✓  |                     | ✓               |                    |                   |                  |                         |
| **SWATing** |                     |                     |                 | ✓                  |                   |                  |                         |
| **Falsified Abuse Report** |        |                     |                 | ✓                  |                   |                  |                         |
| **Falsified Abuse Flag** |         |                     |                 | ✓                  |                   |                  |                         |
| **Impersonated Profiles** |         |                     |                 |                    | ✓                 |                  |                         |
| **Impersonated Chats or Images** | |                     |                 |                    | ✓                 |                  |                         |
| **Impersonated Webpages (SEO)** |  |                     |                 |                    | ✓                 |                  |                         |
| **Synthetic Pornography** | ✓      |                     |                 |                    | ✓                 |                  |                         |
| **Hijacked Communication** |       |                     |                 |                    | ✓                 |                  |                         |
| **Stalking or Tracking** |         |                     |                 |                    |                   | ✓                |                         |
| **Account Monitoring** |          |                     |                 |                    |                   | ✓                |                         |
| **Device Monitoring** |           |                     |                 |                    |                   | ✓                |                         |
| **IoT Monitoring (Passive)** |     |                     |                 |                    |                   | ✓                |                         |
| **Browser Monitoring (Passive)** | |                     |                 |                    |                   | ✓                |                         |
| **IoT Manipulation (Active)** |    |                     |                 |                    |                   | ✓                |                         |
| **Browser Manipulation (Active)** | |                     |                 |                    |                   | ✓                |                         |
| **Account Lockout** |             |                     |                 |                    |                   |                  | ✓                       |
| **Content Deletion** |            |                     |                 |                    |                   |                  | ✓                       |

**Key:**
- ✓: Indicates that the criterion always holds true.
- ✓ (frequent): Indicates that the criterion frequently holds true.
- No entry: Indicates that the criterion does not hold.

### Detailed Descriptions of Attack Categories

1. **Overloading [Availability; A1 + C3]**
   - **Definition**: Overloading includes any scenario where an attacker forces a target to triage hundreds of notifications or comments via amplification (C3), making it technically infeasible for the target to participate online due to jamming a channel (potentially via a DDoS attack) (C3).
   - **Examples**:
     - Organized trolling activity on Facebook, Reddit, and 4chan.
     - Use of “SMS bombers” to send thousands of text messages to a target.
     - Zoombombing, which disrupts video conferences.
     - Brigading, where a large group overwhelms the comment feed of a targeted individual.
     - Dogpiling, where a person is targeted to recant an opinion or statement.
     - DDoS attacks to censor content by overloading an individual’s network connection.
     - En masse negative comments and reviews, similar to Pizzagate and Gamergate.

2. **False Reporting [Integrity; C2]**
   - **Definition**: False reporting captures scenarios where an attacker deceives a reporting system or emergency service (C2) to falsely accuse a target of abusive behavior.
   - **Examples**:
     - SWATing, where an attacker falsely claims a bomb threat, murder, or other serious crime to send emergency responders to the target’s address.
     - Falsified abuse flagging, where an attacker flags content or an account as abusive, triggering automated algorithms to remove the content or suspend the account.
     - Falsified abuse reports with doctored evidence to convince authorities to take action.

3. **Impersonation [Integrity; A2 + M1 + C1]**
   - **Definition**: Impersonation occurs when an attacker assumes the online persona of a target to create content (M1) that will damage the target’s reputation or inflict emotional harm.
   - **Examples**:
     - Setting up fake social media accounts.
     - Exploiting privileged access to send emails or social media messages.
     - Spoofing the sender email address or phone number.
     - Setting up websites using SEO techniques to impersonate the target.
     - Phishing and counterfeit online storefronts.
     - Physical and sexual threats through impersonation, such as creating dating profiles to arrange for strangers to visit the target.
     - Synthetic generation of media, such as deep fakes or photoshopped images.

4. **Surveillance [Confidentiality; C4 exclusively]**
   - **Definition**: Surveillance involves an attacker leveraging privileged access to a target’s devices or accounts (C4) to monitor the target’s activities, location, or communication.
   - **Examples**:
     - Keyloggers and remote access trojans.
     - Subverting mobile phones, IoT devices, and GPS trackers.
     - Stalkerware and sharing techniques to monitor a target without their knowledge.
     - Accessing remote backups after separation.
     - Surveilling a target’s finances and spending.

5. **Lockout & Control [Integrity, Availability; A1+¬M1+C4]**
   - **Definition**: This category includes scenarios where an attacker leverages privileged access to a target’s account or device to interfere with how they engage with the world (A1). Such lockout and control excludes the creation of images or text (not M1); instead, attackers rely on actively subverting technology services.
   - **Examples**:
     - Hijacking smart home devices to broadcast profanity or manipulate settings.
     - Deleting communication to prevent documentation and reporting of abuse.
     - Controlling a target’s access to online resources for help.
     - Removing a target’s access to their online accounts, including financial resources.
     - Ransomware-like attacks in intimate partner violence.

### Prevalence and At-Risk Populations

**Survey Design and Deployment**

- **Instrument Design**: Our survey asked participants if they had personally experienced various forms of online abuse, expanding on previous surveys to include experiences related to lockout and control, surveillance, content leakage, impersonation, and toxic content.
- **Country Selection**: We selected countries for diversity across regions, development measures, cultural and legal responses, and the ability to use high-quality panels.
- **Survey Deployment**: Conducted in coordination with a market research firm, the survey was translated into multiple languages and back-translated for accuracy. The survey was conducted over three years in 22 countries, using a combination of high-quality, opt-in panels and nationally representative panels in the United States.

**Data Collection and Analysis**

- **Data Collection**: Respondents were recruited using stratified sampling with fixed quotas on country, age, and gender. In the United States, a nationally representative panel was used.
- **Analysis**: Data was analyzed to understand the prevalence and severity of online abuse, comparing results with similar surveys by Pew, Data and Society, the Anti-Defamation League, and Microsoft’s Digital Civility Index.

This taxonomy and survey provide a comprehensive framework for understanding and addressing the diverse and evolving landscape of online hate and harassment.