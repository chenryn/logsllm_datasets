### Phase III: Log Simulation and Policy Refinement

The algorithm described in the previous section assumes that file labels remain static, which simplifies the analysis but ignores the fact that file labels can change as operations in the log file are executed. If we did not make this simplifying assumption, the analysis would become overly complex due to the mutual dependencies between policy choices and file labels.

To address this issue, we simulate the accesses found in the log. During this simulation, we track the integrity levels of both objects and subjects and report any access that violates the policy generated in the previous step. The violation reports are aggregated by subject or object and sorted in descending order of the number of occurrences. This means that the subject or object with the highest number of violations is listed first. Subjects with a high number of conflicts may indicate programs that need to be trusted or untrusted programs that cannot be used.

Based on these conflict reports, the policy developer can refine the set of trusted, benign, or untrusted programs. If refinements are made, the analysis is repeated. In practice, multiple iterations of refinement may be necessary, although our experience shows that one iteration is often sufficient.

### Phase IV: Policy Generation for New Applications

New files and applications may be created or installed over time, and we cannot rely on existing logs to generate policies for them. Our approach is as follows:

- **For newly created objects**: Their labels are set to match the integrity level of the subject that created them. The default policy for these new objects allows their labels to be downgraded when they are written by lower-integrity subjects. Accesses to these objects are logged, and the resulting log is periodically analyzed using the same criteria to refine the initial policy. For example, if an object is frequently accessed by high-integrity subjects, the policy may be adjusted to deny writes from lower-integrity subjects.

- **For new software packages**: Labels for the objects in the package are computed based on the trust level of the package, which must be specified at installation. The policies for these files are refined over time as the package is used by the user.

### 3.3. Soundness of Policies

The policies derived above are based on accesses observed on an unprotected system. Since the system is unprotected, it is possible for the log to be compromised by malicious untrusted code. An important question is whether the soundness of the derived policies is compromised due to the use of such logs. A key feature of our policy generation technique is that it remains sound even if the logs are compromised. Therefore, if the generated policies are enforced on a newly installed system, they will preserve its integrity.

**Observation 2**: As long as the programs identified as trusted are indeed trustworthy, the policies generated will preserve system integrity even if the access logs were compromised due to attacks.

**Proof Sketch**: Preserving system integrity means that integrity-critical objects should never be written by low-integrity subjects. All integrity-critical objects are initialized to "preserve-high" in the first phase of the policy generation algorithm. The propagation steps in this phase can only add to the set of objects marked "preserve-high," not remove any. In the next phase, the "downgrade object" policy is applied only to those objects that are not marked "preserve-high." All other policy choices ensure that object labels will not be downgraded. Thus, the generated policy ensures that the labels of integrity-critical objects remain high.

If the logs are compromised, many conflicts may be reported during policy generation. Worse, because the compromised logs may not reflect the behavior of programs on an uncompromised system, the generated policies may deny many accesses (not recorded in the log), making the system unusable. Both symptoms suggest a compromised log file. The policy developer needs to obtain a new, uncompromised log and rerun the policy generation algorithm.

### 4. Limiting Trust

Unlimited and unrestricted trust is often the weakest link in security. To address this, PPI incorporates features to reduce the scope and nature of trust placed on different programs. We describe these features below, followed by a discussion of how they are used in important applications such as software installers, browsers, email handlers, window systems, and file utilities.

#### Invulnerable and Flow-Aware Applications

- **Invulnerable Applications**: These applications maintain high integrity even after reading low-integrity inputs. For example, an SSH server can be trusted to protect itself from potentially malicious network inputs.
  
- **Flow-Aware Applications**: These applications can handle inputs with different integrity levels simultaneously. They keep track of which inputs affect which outputs and label the outputs appropriately. Our enforcement framework provides the primitives for flow-aware applications to control the labels on their outputs. Flow-awareness is natural for some applications like web browsers, which already track associations between input and output actions.

A generic technique to mitigate the risk due to excessive trust is to deploy defenses against common exploitation methods, such as address-space randomization or taint-tracking. Taint-tracking is preferable due to the weaknesses of ASR against local attacks.

#### Context-Aware Trust

Programs are rarely designed to accept untrusted inputs on every input channel. For example, while an SSH server may be robust against malicious data received over the network, it cannot protect itself from malicious configuration files, shared libraries, or executables. Our approach limits trust to specific input contexts where an application is believed to be capable of protecting itself. For an SSH server, this may mean explicitly stating that it is invulnerable to inputs received on port 22.

For files, one approach to limit trust is to enumerate all the files read by an application in advance and identify those that can have low integrity. This is cumbersome and may not be feasible. An alternative approach is to categorize a file as "data input" or "control input" (configuration or library) and permit a trusted application to read low-integrity data inputs but not control inputs. However, manual identification of data and control inputs is also cumbersome. Instead, we rely on the properties of our policy synthesis techniques to achieve a similar effect. Configuration and library inputs are read during practically every run of an application, so they are marked "preserve-high" in the first phase of the policy generation algorithm, ensuring the application is not exposed to low-integrity configuration or library files.

### 4.1. Limiting Trust on Key Applications

#### Software Installers

Software installers pose a particular challenge in the context of integrity protection. Previous techniques simply designated software installers as "trusted," which is problematic in contemporary package management systems where packages may contain arbitrary installation scripts. Our approach uses two processes: a "worker" that runs as a low-integrity subject (but may have root privileges) and performs installation actions, and a "supervisor" that verifies the legitimacy of the actions performed during installation. If the verification succeeds, the supervisor renames the redirected copies of files to replace their original versions. Otherwise, the installation is aborted.

#### Web Browser and Email Handler

Web browsers and email clients act as conduits for data received from the network. In our system, both are considered flow-aware applications. Data received by a browser can be deemed high or low integrity based on the source and other factors like SSL. For the Mozilla browser, we built a small external program that uses the contents of a file "downloads.rdf" to correlate network inputs with the files written by the browser and label these files accordingly. We wrote a similar program for the Pine email reader.

#### X-Server and Other Desktop Daemons

GUI-based applications (X-clients) need to access the X-Server. To ensure continued operation of benign and untrusted X-client applications, the X-Server is made invulnerable on input channels where it accepts data from untrusted clients. We mitigate the risk in two ways: the X-Server is made invulnerable only on inputs received via sockets used to connect to untrusted clients, and we use the X security extension to restrict low-integrity applications from perpetrating attacks on other windows.

Unfortunately, due to the design of the GNOME desktop system, some servers (e.g., gconfd) need to be trusted to obtain a working system. We are currently investigating techniques to limit trust on these applications.

#### File Utilities

Applications that can run at multiple trust levels can introduce usability issues, especially when they operate on files with varying trust levels. We modified `cp` and `mv` to make them flow-aware, so that the output files correctly inherit the label from the input files.

### 5. Enforcement Framework

Our design is a hybrid system consisting of a user-level library and a kernel-resident checker. Integrity-critical enforcement actions are performed by the kernel component, while functionality enhancement features are relegated to the library. The kernel component does not deal with redirection policy and supports the notion of trusted subjects without concerning itself with mechanisms for limiting trust, which are provided by the user-level component. The kernel enforcement component is always trusted, while the user-level component is trusted only when it operates in the context of a high-integrity process.

In our implementation, the kernel-level component is realized using LSM (Linux Security Modules), which is part of the standard Linux kernel. We use the security hooks of LSM to enforce information flow policies. Although our policy framework allows for policies to be a function of objects and subjects, for simplicity, the policies enforced by the kernel component have limited dependence on subjects. More flexible subject-dependent policies can be realized using the user-level component.

Kernel-enforced policies are stored with objects using extended file attributes available on major Linux file systems (including ext2, xfs, and reiserfs). Policies and integrity labels are stored using these attributes. Specifically, a 3-bit attribute `integobj` is used to store the integrity level of a file (our implementation uses eight integrity levels). An 11-bit policy is associated with each file, consisting of two parts:

1. **Read and Write Operations**:
   - `down obj` (3 bits): Indicates the lowest integrity level to which this object can be downgraded.
   - `log obj` (1 bit): Indicates whether accesses to this object should be logged. This feature is used for auditing and generating the logs for policy generation.

2. **Subject Instantiation**:
   - `down sub` (3 bits): Indicates the lowest integrity level to which a process that executes this object can be downgraded.
   - `log sub` (2 bits): Indicates whether accesses made by this subject should be logged. A second bit indicates whether this policy should be inherited by descendants of a subject.
   - `invul sub` (1 bit): Indicates if this subject is invulnerable.
   - `super sub` (1 bit): Allows a subject to modify the labels associated with objects in the system. This capability is highly restricted, and in our implementation, there is one administrative program with this capability.

When the PPI system is initialized, the extended attributes associated with all files are populated using the labels and policies generated in Section 3. New files inherit the integrity of the subject creating them. The log bits are set by default, `super sub` and `invul sub` bits are cleared, and the `down sub` and `down obj` bits are set to zero. After a fork, the child inherits the parent’s attributes, including its integrity level. After an exec, the integrity of the subject is reduced (but can never be increased) to that of the file being executed. The `super sub` policy is inherited from an executable file only if the file has this capability.