t
i
s
o
P
e
s
a
F
l
Fig. 9. Results for DNS-based RL at the Edge Router
Our results also show that DNS rate limiting is capable of containing slow
spreading worms. As a comparison, Weaver’s Approximate TRW containment
mechanism can block worms that scan faster than 1 scan per second [21]. Using
the DNS scheme, with value of q = 3 and t = 5 for instance (3 direct-IP con-
nections in 5-second window), we can contain worms that scan at the rate of 0.6
scans per second (or more) with 99% accuracy.
To test the eﬀect of aggregate throttling, we implemented a single set of
cascading buckets for the entire network. For this set of experiments, the value
of q was set to 20, 50, and 100 IPs per ﬁve second window. Figure 9 shows the
error rates for the aggregate implementation. As shown, a q value of 20 or 50
IPs yielded few false negatives and a false positive rate of approximately three
to ﬁve percent. Note that when q is set to 20 or 50, the false negative rates of
edge-based rate limiting are lower than the host-level scheme. This is because
the aggregate traﬃc limit is more restrictive overall than the collective limit in
the host-based case. Although the false positive rates for the aggregate case are
slightly higher than the host-level case, overall the error rates are fairly low—5%
false positive and < 1% false positive.
9 Discussions
Analysis in the previous sections brought to light a number of issues with respect
to rate limiting technology. In this section we attempt to extrapolate from these
results and discuss some general insights.
DNS-based RL vs. others. A summary comparison of the DNS-based scheme
with the others is in Figure 10. The parameters here are consistent with the val-
ues used in the previous sections. As shown, DNS-based rate limiting has the
best performing false positive and false negative rates. Host-based DNS throt-
tling renders an average false positive and false negative rate below 1%. These
results present a strong case for DNS-based rate limiting.
Recall that the q value in DNS throttling allows for q untranslated IP connec-
tions per host to exit the network every t seconds. To put things in perspective,
for the ﬁrst day of infection, the network had a total of 468,300 outbound le-
38
C. Wong et al.
)
%
(
e
v
i
t
a
g
e
N
e
s
a
F
l
 30
 25
 20
 15
 10
 5
 0
ROC Curves for all RL schemes
False Positive and False Negative for CB Edge Router w/ PCH = 4096
CB Edge Router False Positive
CB Edge Router False Negative
FC Basic
FC Temporal
CB
CB Edge Router
MW End Host
DNS End Host
DNS Edge Router
 50
 40
 30
 20
 10
)
%
(
t
n
e
c
r
e
P
 0
 10
 20
 40
 50
 30
False Positive (%)
 60
 70
 80
 0
 0
 5
 10
Days
 15
 20
(a) Avg error rates
(b) Edge CB Results for PCH = 4096
Fig. 10. Avg. error rates for all RL schemes and Edge CB Results
gitimate ﬂows. When q = 7 a total of 463 legitimate ﬂows are dropped, which
yields a false positive rate of 0.099%. This is less than 1 dropped ﬂow per host
per day. As a comparison, CB dropped 3767 legitimate ﬂows for the same day,
a false positive rate of 7.8%.
The success of DNS RL can be attributed primarily to the fact that DNS
traﬃc patterns (or the lack thereof), compared to other statistics, more precisely
delineate worm traﬃc from normal behavior. DNS-based RL can thus impose
severe limitations on worm traﬃc without visibly impacting normal traﬃc.
One of the reasons that scanning worms are successful is because they are
able to probe the numeric IP space extremely rapidly in their search for poten-
tial victims. Navigating the DNS name space is a far more diﬃcult process to
automate, since the name space is less populated and has poorer locality prop-
erties. DNS-based throttling forces scanning worms to probe the DNS name
space, thereby reducing the scan hit rate and substantially raising the level of
diﬃculties for scanning worms to propagate.
We note that although our trace data reﬂects a simple worm that does not
attempt to mask itself, extending the DNS RL scheme to more sophisticated
worms is straightforward. We plan to address this in future work.
Issues with DNS-based rate limiting. An attacker can attempt to circum-
vent the DNS rate limiting mechanism in a number of ways:
First, a worm could use reverse DNS-lookups (PTR lookups) to “pretend”
that it has received a DNS translation for a destination IP. Jung et. al. [6]
characterizes that PTR lookups are primarily for incoming TCP connections or
lookups related to reverse blacklist services. These types of lookups can be easily
ﬁltered and not considered as valid entries in the DNS cache. In addition, a PTR
lookup prior to an infection attempt will signiﬁcantly reduce the infection speed.
Second, an attacker could setup a fake external DNS server and issue a DNS
query for each IP. We can alleviate this threat by establishing a “white-list”
of legitimate external DNS servers. Also, the attacker needs a server with a
substantial bandwidth to accommodate the scan speed, which is not trivial. A
case of interest here is SOHO (Small oﬃce Home oﬃce) users who may set up
their own routers and use legitimate external DNS servers. To accommodate
Empirical Analysis of Rate Limiting Mechanisms
39
such usage, we can use a packet scrubber such as Hogwash [5] to help correlate
DNS queries to responses.
Another attack against DNS throttling is to equip each worm with a dictionary
of host names and domains. This eﬀectively turns a scanning worm into a worm
with a hit-list. Hit-list worms are signiﬁcantly more diﬃcult to engineer. If the
only viable means to bypass DNS-based throttling is for the worm to carry a
hit-list, that in itself is a positive testimony for DNS-based throttling.
Dynamic vs static rates. Rate limiting schemes impact the rate of both legiti-
mate and malicious connections. Williamson’s imposes a strictly static rate, e.g.,
ﬁve distinct IPs per second, irrespective of the traﬃc demand. FC is predomi-
nately static while CB allows for a dynamic traﬃc rate by rewarding successful
connection and penalizing failed connections. Results in Figure 10 show that
CB outperforms FC. This is partially due to CB’s dynamic rates which render
a more graceful ﬁltering scheme that permits both bursty application behavior
and temporarily abnormal-but-benign traﬃc patterns. As we brieﬂy discussed in
Section 5, mechanisms that impose a static rate can beneﬁt from incorporating
dynamic rate limits. Dynamic rate limiting is an interesting topic worth further
study.
Host vs aggregate. An issue of signiﬁcance is host versus aggregate rate lim-
iting. The general wisdom is that host-level throttling is more precise but is at
the same time more costly because per host state must be maintained. Indeed,
Williamson’s IP throttling, when applied at the edge, rendered visibly higher
false positives than its host-based counterpart. This is because IP contact be-
havior at the host-level is more ﬁne-grained and thus more likely to be stable.
In contrast, aggregate traﬃc at the edge includes hosts whose behavior may
vary signiﬁcantly from each other, thereby contributing to a higher error rate.
A similar case was observed with CB when applied to the aggregate traﬃc, the
results of which are shown in Figure 10(b). As shown, the false positive rates
reach approximately 30%, compared to the 10% with the host-based deployment.
Edge-based DNS throttling, however, appears to be an exception. Figure 10(a)
shows that a carefully chosen rate limit, e.g., 50 IPs per ﬁve seconds, yields ex-
cellent accuracy for edge-based DNS throttling. It has lower false positive and
false negative rates than other host-based schemes. The fundamental reason be-
hind this is that DNS statistics, in particular the presence (or the lack) of IP
translations, remain largely invariant from host to the aggregate level.
This result is extremely encouraging, as aggregate rate limiting has a lower
storage overhead and is typically easier to deploy and maintain than host-based
schemes. Note that our study did not include an analysis on processing over-
head. Readers should be reminded that edge-based schemes in general imply
processing a larger amount of data per connection, therefore a trade-oﬀ between
storage and processing overhead exists. The aggregate DNS throttling result
allude to the possibility of pushing rate limiting deeper into the core where a
single instrumentation can cover many IP-to-IP paths and potentially achieve a
greater impact.
40
C. Wong et al.
We note that edge-based throttling in itself does not defend against internal
infection. One way to protect against internal infection (and not pay the cost
of host-level throttling) is to divide an enterprise network into various cells (as
suggested by Staniford [14]) and apply the aggregate throttling at the border of
each cell. We leave the analysis of more ﬁne-grained, intra-network protection
as future work.
10 Summary
A number of rate limiting schemes have been proposed recently to mitigate
scanning worms. In this paper, we present the ﬁrst empirical analysis of the
diﬀerent schemes, using real traﬃc and attack traces from an open network
environment. We believe that the scheme that performs well in an open network
and will perform equally well (if not better) in an environment with strict traﬃc
policies (e.g., enterprise network).
We evaluate and contrast the false positive and false negative rates for each
scheme. Our analysis reveals these insights. First, the subject of rate limiting
is by far the most signiﬁcant “parameter”—failed-connection behavior alone is
too restrictive as evidenced by FC; rate limiting ﬁrst-contacts renders better
results and DNS behavior-based rate limiting is by far the most accurate strategy.
Second, it is feasible to delineate worm behavior from normal traﬃc even at an
aggregate level, as indicated by the DNS analysis. This is an interesting result
because aggregate rate limiting alleviates the universal participation requirement
thought necessary for worm containment [10, 25]. This result also suggests that
it may be possible to apply rate limiting deeper into the core of the network,
a subject that is of great interest to many. Third, preliminary investigation
suggests that incorporating dynamic rates results in increased accuracy. As most
of rate limiting schemes to-date focus on static rates, an immediate follow-up
research is dynamic rate limiting and how that can be implemented in practice.
Acknowledgments
This material is based upon work supported by the National Science Foundation
under Grant No. 0326472. The authors thank Greg Ganger and Mike Reiter for
providing insightful feedback on preliminary versions of this work. We also thank
Matthew Williamson for technical discussions about this work.
References
1. Shigang Chen and Yong Tang. Slowing down internet worms. In Proceedings of
24th International Conference on Distributed Computing Systems, Tokyo, Japan,
March 2004.
2. M. Collins and M. Reiter. An empirical analysis of target-resident DoS ﬁlters. In
In Proceedings of 2004 IEEE Symposium of Security and Privacy, 2004.
Empirical Analysis of Rate Limiting Mechanisms
41
3. Daniel R Ellis, John G Aiken, Kira S Attwood, and S.D Tenaglia. A behavioral
approach to worm detection. In Proceedings of the 2004 ACM workshop on Rapid
Malcode. ACM Press, 2004.
4. G.R Ganger, Gregg Economou, and S. Bielski. Self-securing network interfaces:
What, why and how, Carnegie Mellon University Technical Report CMU-CS-02-
144, August 2002.
5. Hogwash. Inline packet scrubber. http://sourceforge.net/projects/hogwah.
6. H. Balakrishnan J. Jung, E. Sit and R. Morris. DNS performance and the eﬀec-
tiveness of caching. In Proceedings of the ACM SIGCOMM Internet Measurement
Workshop, San Francisco, California, November 2001.
7. J. Jung, V. Paxon, A. W. Berger, and H. Balakrishman. Fast portscan detection
using sequential hypothesis testing. In In Proceedings of 2004 IEEE Symposium
on Security and Privacy, 2004.
8. J.O Kephart and S. White. Directed-graph epidemiological models of computer
viruses. In Proceedings of the 1991 IEEE Computer Society Symposium on Research
in Security and Privacy, pages 343–359, May 1991.
9. H. Kim and B. Karp. Autograph: Toward automated, distributed worm signature
In Proceedings of the 13th USENIX Security Symposium, San Diego,
detection.
California, USA, August 2004.
10. D. Moore, C. Shannon, G. Voelker, and S. Savage. Internet quarantine: Require-
In Proceedings of IEEE INFOCOM
ments for containing self-propagating code.
2003, San Francisco, CA, April 2003.
11. Network-Associates. http://vil.nai.com/vil/content/v 100561.htm, 2003.
12. S.E. Schechter, J. Jung, and Arthur W. Berger. Fast detection of scanning worm
In In Recent Advances In Intrusion Detection (RAID) 2004, France,
infections.
September 2004.
13. S. Singh, Cristian Estan, George Varghese, and S. Savage. Automated worm ﬁnger-
printing. Proceedings of the 6th ACM/USENIX Symposium on Operating System
Design and Implementation, December 2004.
14. S. Staniford. Containment of scanning worms in enterprise networks. Journal of
Computer Science, 2004.
15. S. Staniford, V. Paxson, and N. Weaver. How to 0wn the internet in your spare
time. In Proceedings of the 11th USENIX Security Symposium, August 2002.
16. Symantec. W32.Blaster.Worm.
http://securityresponse.symantec.com/
avcenter/venc/data/w32.blaster.worm.html.
17. Symantec. W32.Welchia.Worm.
http://securityresponse.symantec.com/
avcenter/venc/data/w32.welchia.worm.html
18. Helen J. Wang, Chuanxiong Guo, Daniel R. Simon, and Alf Zugenmaier. Shield:
vulnerability-driven network ﬁlters for preventing known vulnerability exploits. In
Proceedings of the 2004 conference on Applications, technologies, architectures, and
protocols for computer communications, pages 193–204. ACM Press, 2004.
19. Y. Wang, D. Chakrabarti, C. Wang, and C. Faloutsos. Epidemic spreading in
real networks: An eigenvalue viewpoint. In Proceedings of the 22nd International
Symposium on Reliable Distributed Systems, 2003.
20. Y. Wang and C. Wang. Modeling the eﬀects of timing parameters on virus propa-
gation. In Proceedings of the 2003 ACM workshop on Rapid Malcode, pages 61–66.
ACM Press, 2003.
21. N. Weaver, S. Staniford, and V. Paxson. Very fast containment of scanning worms.
In Proceedings of the 13th USENIX Security Symposium, 2004.
42
C. Wong et al.
22. D. Whyte, E. Kranakis, and P.C. van Oorschot. DNS-based detection of scanning
In In Proccedings of Network and Distributed
worms in an enterprise network.
System Security, 2005.
23. M. Williamson. Throttling viruses: Restricting propagation to defeat malicious
mobile code. In Proceedings of the 18th Annual Computer Security Applications
Conference, Las Vegas, Nevada, December 2002.
24. C. Wong, S. Bielski, J. McCune, and C. Wang. A study of mass-mailing worms.
In Proceedings of the 2004 ACM workshop on Rapid Malcode. ACM Press, 2004.
25. C. Wong, C. Wang, D. Song, S. Bielski, and G.R Ganger. Dynamic quarantine of
internet worms. In Proceedings of DSN 2004, Florence, Italy, June 2004.
26. C. Zou, W. Gong, and D. Towsley. Code red worm propagation modeling and
analysis. In Proceedings of the 9th ACM Conference on Computer and Communi-
cation Security, November 2002.
COTS Diversity Based Intrusion Detection
and Application to Web Servers
Eric Totel, Frédéric Majorczyk, and Ludovic Mé
Supélec, BP 81127, 35511 Cesson-Sévigné Cedex, France
PI:EMAIL
Abstract. It is commonly accepted that intrusion detection systems (IDS) are re-
quired to compensate for the insufﬁcient security mechanisms that are available