0.0145
0.0159
0.0078
0.0059
16.0859
12.2279
15.7276
14.5999
13.0157
6.2288
9.8467
12.803
7.5356
5.4438
Table 3: HSD with AUC statistic
Dataset C4.5 RF New
Day1
Day 2
Day 3
Day 4
Day 5
Day 6
Day 7
Day 8
Day 9
Day 10
B
B
B
B
B
AB
B
B
B
AB
A
A
A
A
A
A
A
A
A
A
B
B
B
B
B
B
B
B
B
B
p-value
<0.0001
<0.0001
<0.0001
<0.0001
0.0001
0.006
0.0006
0.0001
0.0025
0.0103
Figure 5: Average performance
and the new detection method on the 10-day ground-truth
dataset.
In the experiments, the training data had 1,000
spam tweets and 10,000 non-spam tweets. One can see the
technique selection has a signiﬁcant impact to AUC at the
level of α = 5% because p-value < 0.05 holds for the 10 days
data. Then, we used the Tukey’s HSD testing to identify
which technique shows a signiﬁcant improvement over the
others.
Table 3 reports the Tukey’s HSD statistic test results on
the datasets across ten days. One can see the new detection
method performed signiﬁcantly better than the other tech-
niques in all cases. Precisely, the new method resulted in ‘A’
for all the ten small datasets, while both C4.5 and RF didn’t
obtain ‘A’ for any cases. Even though C4.5 achieved ‘AB’
for two cases, for most scenarios it did not exhibit any bet-
ter performance compared with RF. These results conﬁrm
the new detection method is robust and outperforms ex-
isting machine-learning based twitter spam detection meth-
ods. The reason is the new method can address the prob-
lem of a small number of imbalanced training data through
the combination of fuzzy-based redistribution and ensemble
with asymmetric sampling.
Figure 5 shows the overall performance of C4.5, RF and
the new method. Accuracy, detection rate and AUC are av-
eraged over all experiments. In each experiment, the rate of
spam testing samples to non-spam testing samples was set to
100. It simulated the realistic twitter spam rate, about 1%.
In the ﬁgure, we can observe that the three methods have
comparable accuracy. The new method results in outstand-
ing performance in terms of detection rate and AUC. The
detection rate of our new method is higher than the second
best method, C4.5, about 10 percent. RF has the worst de-
tection rate, which is much lower than the new method and
C4.5. C4.5 and RF have comparable AUC. The AUC of the
new method is higher than other methods over 5 percent.
Figure 6: Accuracy for testing set-1
We can make an initial conclusion that the new method can
detect more spam tweets accurately.
4.2.3 Day-based performance for testing set-1
In this work, we used two settings for testing data.
In
the ﬁrst testing data, we set the imbalanced rate between
spam and non-spam samples to 10. It simulated a very high
spam rate, about 10%, in some real-world scenarios. In the
second testing data, we set the imbalanced rate between
spam and non-spam samples to 100. It simulated a very low
spam rate, about 1%, in some real-world applications. This
section reports the results on the ﬁrst testing data. The
results on the second testing data are reported in Section
4.2.4
Figure 6 shows the accuracy of the three methods. All the
accuracy are higher than 0.9. C4.5 has the lowest accuracy,
about 0.92. The new method has the similar accuracy with
RF, which is higher than C4.5 up to 5 percent.
In this
case, accuracy is not critical. Even if we classify all testing
samples to the non-spam class, the accuracy is about 0.91.
However, the classiﬁer misclassiﬁed a large portion of the
spam samples as non-spam.
Figure 7 reports the AUC and detection rate of the three
methods. In general, the new method shows the best AUC
and the best detection rate across the 10 days. For AUC,
C4.5 and RF display comparable performance. The AUC
of the new method is higher than other two methods up
Accuracy Detection Rate AUCStd.AUC00.20.40.60.81Performance valueRFC4.5New012345678910Day0.50.60.70.80.91AccurayRFC4.5New117Figure 7: AUC and detection rate for testing set-1
to 8 percent. For example, on day 1, the AUC of the new
method is around 0.83, while the AUC of C4.5 and RF is
approximately 0.77. On day 6, all methods have very good
AUC. The AUC of the new method outperforms that of C4.5
and RF about 4 percent. The worst improvement occurred
on day 10. The new method has higher AUC than the second
best method, C4.5, less than 3 percent.
For detection rate, C4.5 has better performance than RF
across all 10 days. The detection rate of the new method is
higher than RF up to 20 percent. For example, on day 2,
the AUC of the new method is about 0.68, while the AUC
of C4.5 is less than 0.55. RF has the worst detection rate
that is 0.5. On day 9, the detection rate of the new method
is over 0.75, while C4.5’s detection rate is about 6.8 and
RF’s detection rate is 6.5. On day 10, C4.5 has comparable
detection rate with the new method. The detection rate of
RF is lower than other methods about 5 percent.
4.2.4 Day-based performance for testing set-2
Figures 8 and 9 report the spam detection results on the
second testing data.
In this testing data, the imbalanced
rate between spam and non-spam samples was 100. It sim-
ulated a very low spam rate, less than 1%. The results have
some diﬀerence to that reported in Section 4.2.3.
Figure 8 shows very high accuracy of the three methods.
Figure 8: Accuracy for testing set-2
RF has the best accuracy, which is close to 0.99. The diﬀer-
ence between RF and the new method is about 2 percent.
The new method is better than C4.5 in terms of accuracy.
As we mentioned before, accuracy is not critical for the ex-
periments of tweet spam detection. In this case, even if we
classify all testing samples to the non-spam class, the ac-
curacy is about 0.99. Accuracy is used here to conﬁrm the
classiﬁcation method is correctly implemented. We need to
pay more attention to the amount of correctly detected spam
tweets.
Figure 9 reports the AUC and detection rate of the three
methods, RF, C4.5 and the new method. In line with the
012345678910Day0.70.750.80.85AUCRFC4.5New11012345678910Day0.40.50.60.70.8Detection RateRFC4.5New11012345678910Day0.50.60.70.80.91AccuracyRFC4.5New118Figure 9: AUC and detection rate for testing set-2
results on the ﬁrst testing data, the new method had the best
AUC and the best detection rate across the 10 days. C4.5
does not always have better AUC than RF. For example,
on day 1, the average AUC of the new method is around
0.84. C4.5’s AUC is 0.76, which is higher than RF about 2
percent. On day 4, the second best method is RF, which has
higher AUC than C4.5 about 2 percent. The AUC of the
new method outperforms RF about over 10 percent on this
day. The C4.5’s AUC is comparable to the AUC of the new
method on day 10. They are higher than RF over 5 percent.
For detection rate, the new method is the best one. RF is
the worst method and C4.5 is in the middle. The detection
rate of the new method is dramatically higher than other
methods in most cases. For example, on day 1, the AUC
of the new method achieved 0.7, while the AUC of C4.5 is
less than 0.6. RF has the worst detection rate,which is 0.5.
On day 4, the detection rate of the new method is about
0.67, while the detection rates of C4.5 and RF are less than
0.5. On day 10, C4.5 has the same detection rate with the
new method. The detection rate of RF is lower than other
methods about 15 percent.
We can see the results on two diﬀerent testing dataset are
consistent. The new method displays excellent robustness
and outperforms c4.5 and RF signiﬁcantly in any case.
5. CONCLUSIONS
In this paper, we addressed the critical challenge of Twit-
ter spam drift. We treated it as a special machine learning
problem with a small number of imbalance data. We pro-
posed a new method combining two new techniques, fuzzy-
based redistribution and asymmetric sampling, to solve this
problem. The fuzzy-based redistribution technique applied
information decomposition technique generate more sythetic
spam samples. The asymmetric sampling technique per-
formed over-sampling on spam samples and under-sampling
on non-spam samples to balance the sizes in the training
data. The ensemble technique was used to combine the
spam classiﬁers over two diﬀerent training sets in order to
improve the robustness and accuracy of spam detection. To
evaluate the new method, we carried out a number of ex-
periments on a real-world 10-day ground-truth dataset. The
new method was compared to other two methods, C4.5 and
RF. Experiments results showed that the new method can
signiﬁcantly improve the detection performance for drifting
Twitter spam. AUC of spam detection can be improved
up to 10 percent. Detection rate can be improved over 20
percent.
6. REFERENCES
[1] Alex Hai Wang. Don’t follow me: Spam detection in twitter. In
012345678910Day0.650.70.750.80.850.9AUCRFC4.5New11012345678910Day0.30.40.50.60.70.8Detection RateRFC4.5New119Security and Cryptography (SECRYPT), Proceedings of the
2010 International Conference on, pages 1–10. IEEE, 2010.
[2] Chao Chen, Jun Zhang, Yang Xiang, and Wanlei Zhou.
Asymmetric self-learning for tackling twitter spam drift. In
Computer Communications Workshops (INFOCOM
WKSHPS), 2015 IEEE Conference on, pages 208–213. IEEE,
2015.
[3] Michael Mccord and M Chuah. Spam detection on twitter using
traditional classiﬁers. In Autonomic and trusted computing,
pages 175–186. Springer, 2011.
[4] Reza Bosagh Zadeh. Twitter engineering blog: All-pairs
similarity via dimsum. Twitter Engineering Blog, 2014.
[5] Chris Grier, Kurt Thomas, Vern Paxson, and Michael Zhang. @
spam: the underground on 140 characters or less. In
Proceedings of the 17th ACM conference on Computer and
communications security, pages 27–37. ACM, 2010.
[6] Kurt Thomas, Chris Grier, Justin Ma, Vern Paxson, and Dawn
Song. Design and evaluation of a real-time url spam ﬁltering
service. In Security and Privacy (SP), 2011 IEEE Symposium
on, pages 447–462. IEEE, 2011.
[7] Xianchao Zhang, Shaoping Zhu, and Wenxin Liang. Detecting
spam and promoting campaigns in the twitter social network.
In Data Mining (ICDM), 2012 IEEE 12th International
Conference on, pages 1194–1199. IEEE, 2012.
[8] Nilesh Dalvi, Pedro Domingos, Sumit Sanghai, Deepak Verma,
et al. Adversarial classiﬁcation. In Proceedings of the tenth
ACM SIGKDD international conference on Knowledge
discovery and data mining, pages 99–108. ACM, 2004.
[9] Fabricio Benevenuto, Gabriel Magno, Tiago Rodrigues, and
Virgilio Almeida. Detecting spammers on twitter. In
Collaboration, electronic messaging, anti-abuse and spam
conference (CEAS), volume 6, page 12, 2010.
[10] Hossam Faris, Khalid Jaradat, Malek Al-Zewairi, Omar Adwan,
et al. Improving knowledge based spam detection methods: The
eﬀect of malicious related features in imbalance data
distribution. International Journal of Communications,
Network and System Sciences, 8(5):118–129, 2015.
[11] Chao Chen, Jun Zhang, Xiao Chen, Yang Xiang, and Wanlei
Zhou. 6 million spam tweets: A large ground truth for timely
twitter spam detection. In Communications (ICC), 2015 IEEE
International Conference on, pages 7065–7070. IEEE, 2015.
[12] Fabricio Benevenuto, Gabriel Magno, Tiago Rodrigues, and
Virgilio Almeida. Detecting spammers on twitter. In
Collaboration, electronic messaging, anti-abuse and spam
conference (CEAS), volume 6, page 12, 2010.
[13] Pear Analytics. Twitter study–august 2009. San Antonio, TX:
Pear Analytics. Available at: www. pearanalytics.
com/blog/wp-content/uploads/2010/05/Twitter-Study-
August-2009. pdf,
2009.
[14] Kurt Thomas, Chris Grier, Dawn Song, and Vern Paxson.
Suspended accounts in retrospect: an analysis of twitter spam.
In Proceedings of the 2011 ACM SIGCOMM conference on
Internet measurement conference, pages 243–258. ACM, 2011.
[15] Jonathan Oliver, Paul Pajares, Christopher Ke, Chao Chen,
and Yang Xiang. An in-depth analysis of abuse on twitter.
Trend Micro, 225, 2014.
[16] Sarita Yardi, Daniel Romero, Grant Schoenebeck, et al.
Detecting spam in a twitter network. First Monday, 15(1),
2009.
[17] Haewoon Kwak, Changhyun Lee, Hosung Park, and Sue Moon.
What is twitter, a social network or a news media? In
Proceedings of the 19th international conference on World
wide web, pages 591–600. ACM, 2010.
[18] Gianluca Stringhini, Christopher Kruegel, and Giovanni Vigna.
Detecting spammers on social networks. In Proceedings of the
26th Annual Computer Security Applications Conference,
pages 1–9. ACM, 2010.
[19] Kyumin Lee, James Caverlee, and Steve Webb. Uncovering
social spammers: social honeypots+ machine learning. In
Proceedings of the 33rd international ACM SIGIR conference
on Research and development in information retrieval, pages
435–442. ACM, 2010.
[20] Hamzah Al Najada and Xingquan Zhu. isrd: Spam review
detection with imbalanced data distributions. In Information
Reuse and Integration (IRI), 2014 IEEE 15th International
Conference on, pages 553–560. IEEE, 2014.
[21] Chao Chen, Jun Zhang, Yi Xie, Yang Xiang, Wanlei Zhou,
et al. A performance evaluation of machine learning-based
streaming spam tweets detection. IEEE Transactions on
Computational Social Systems, 2(3):65–76, 2015.
[22] Jonghyuk Song, Sangho Lee, and Jong Kim. Spam ﬁltering in
twitter using sender-receiver relationship. In Recent Advances
in Intrusion Detection, pages 301–317. Springer, 2011.
[23] Chao Yang, Robert Harkreader, and Guofei Gu. Empirical
evaluation and new design for ﬁghting evolving twitter
spammers. Information Forensics and Security, IEEE
Transactions on, 8(8):1280–1293, 2013.
[24] Kurt Thomas, Chris Grier, Justin Ma, Vern Paxson, and Dawn
Song. Design and evaluation of a real-time url spam ﬁltering
service. In Security and Privacy (SP), 2011 IEEE Symposium
on, pages 447–462. IEEE, 2011.
[25] Sangho Lee and Jong Kim. Warningbird: A near real-time
detection system for suspicious urls in twitter stream.
Dependable and Secure Computing, IEEE Transactions on,
10(3):183–195, 2013.
[26] Shigang Liu, Jun Zhang, Yu Wang, and Yang Xiang.
Fuzzy-based feature and instance recovery. In Springer’s LNAI
Proceedings. Springer, 2016.
[27] Haibo He and Yunqian Ma. Imbalanced learning: foundations,
algorithms, and applications. John Wiley & Sons, 2013.
[28] Manuel Egele, Gianluca Stringhini, Christopher Kruegel, and
Giovanni Vigna. Compa: Detecting compromised accounts on
social networks. In NDSS, 2013.
[29] Michael Mccord and M Chuah. Spam detection on twitter using
traditional classiﬁers. In Autonomic and trusted computing,
pages 175–186. Springer, 2011.
[30] R Kishore Kumar, G Poonkuzhali, and P Sudhakar.
Comparative study on email spam classiﬁer using data mining
techniques. In Proceedings of the International
MultiConference of Engineers and Computer Scientists,
volume 1, pages 14–16, 2012.
[31] Mohamed Bekkar, H Kheliouane Djemaa, and T Akrouf
Alitouche. Evaluation measures for models assessment over
imbalanced data sets. Journal of Information Engineering and
Applications, 3(10):27–38, 2013.
[32] Chris Seiﬀert, Taghi M Khoshgoftaar, and Jason Van Hulse.
Improving software-quality predictions with data sampling and
boosting. Systems, Man and Cybernetics, Part A: Systems
and Humans, IEEE Transactions on, 39(6):1283–1294, 2009.
10