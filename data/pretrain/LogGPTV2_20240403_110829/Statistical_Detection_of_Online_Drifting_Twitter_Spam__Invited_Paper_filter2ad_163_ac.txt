### 优化后的文本

**数值数据:**
- 0.0145
- 0.0159
- 0.0078
- 0.0059
- 16.0859
- 12.2279
- 15.7276
- 14.5999
- 13.0157
- 6.2288
- 9.8467
- 12.803
- 7.5356
- 5.4438

**表3: HSD与AUC统计**
| 数据集 | C4.5 | RF | 新方法 |
| --- | --- | --- | --- |
| Day 1 | B | B | A |
| Day 2 | B | B | A |
| Day 3 | B | B | A |
| Day 4 | B | B | A |
| Day 5 | B | B | A |
| Day 6 | AB | B | A |
| Day 7 | B | B | A |
| Day 8 | B | B | A |
| Day 9 | B | B | A |
| Day 10 | AB | B | A |

**p值:**
- <0.0001
- <0.0001
- <0.0001
- <0.0001
- 0.0001
- 0.006
- 0.0006
- 0.0001
- 0.0025
- 0.0103

**图5: 平均性能**
展示了新检测方法在10天真实数据集上的平均性能。实验中，训练数据包含1,000条垃圾推文和10,000条非垃圾推文。可以看出，在α = 5%的显著性水平下，技术选择对AUC有显著影响，因为10天的数据中p值均小于0.05。随后，我们使用Tukey’s HSD测试来确定哪种技术表现出显著改进。

**表3** 报告了十天数据集上Tukey’s HSD统计测试的结果。可以看出，新检测方法在所有情况下都显著优于其他技术。具体来说，新方法在所有十个小型数据集中均获得“A”，而C4.5和RF在任何情况下均未获得“A”。尽管C4.5在两个案例中获得了“AB”，但在大多数情况下，其表现并不优于RF。这些结果证实了新检测方法的鲁棒性，并且优于现有的基于机器学习的Twitter垃圾信息检测方法。原因是新方法通过模糊重分布和不对称采样的结合解决了少量不平衡训练数据的问题。

**图5** 显示了C4.5、RF和新方法的整体性能。准确率、检测率和AUC是所有实验的平均值。每个实验中，垃圾测试样本与非垃圾测试样本的比例设置为100，模拟了现实中的Twitter垃圾信息率（约1%）。从图中可以看出，三种方法的准确率相当。新方法在检测率和AUC方面表现出色。新方法的检测率比第二好的方法C4.5高约10%。RF的检测率最低，远低于新方法和C4.5。C4.5和RF的AUC相当，而新方法的AUC比其他方法高出超过5%。

**图6: 测试集1的准确性**

初步结论是，新方法可以更准确地检测更多的垃圾推文。

**4.2.3 基于天数的性能测试集1**
在本研究中，我们使用了两种测试数据设置。在第一个测试数据中，我们将垃圾和非垃圾样本之间的不平衡率设置为10，模拟了某些现实场景中非常高的垃圾信息率（约10%）。在第二个测试数据中，我们将垃圾和非垃圾样本之间的不平衡率设置为100，模拟了某些实际应用中非常低的垃圾信息率（约1%）。本节报告第一个测试数据的结果。第二个测试数据的结果将在第4.2.4节中报告。

**图6** 显示了三种方法的准确性。所有方法的准确性均高于0.9。C4.5的准确性最低，约为0.92。新方法与RF的准确性相似，比C4.5高约5%。在这种情况下，准确性不是关键指标。即使将所有测试样本分类为非垃圾类，准确性也约为0.91。然而，分类器误将大量垃圾样本分类为非垃圾。

**图7** 报告了三种方法的AUC和检测率。总体而言，新方法在10天内显示出最佳的AUC和检测率。对于AUC，C4.5和RF的表现相当。新方法的AUC比其他两种方法高出最多8%。例如，在第1天，新方法的AUC约为0.83，而C4.5和RF的AUC约为0.77。在第6天，所有方法的AUC都非常好。新方法的AUC比C4.5和RF高出约4%。最差的改进发生在第10天。新方法的AUC比第二好的方法C4.5高出不到3%。

对于检测率，C4.5在10天内的表现优于RF。新方法的检测率比RF高最多20%。例如，在第2天，新方法的AUC约为0.68，而C4.5的AUC低于0.55。RF的检测率最低，为0.5。在第9天，新方法的检测率超过0.75，而C4.5的检测率约为6.8%，RF的检测率为6.5%。在第10天，C4.5的检测率与新方法相当。RF的检测率比其他方法低约5%。

**4.2.4 基于天数的性能测试集2**
**图8** 和 **图9** 报告了第二个测试数据上的垃圾检测结果。在这个测试数据中，垃圾和非垃圾样本之间的不平衡率为100，模拟了非常低的垃圾信息率（小于1%）。结果与第4.2.3节报告的结果有所不同。

**图8** 显示了三种方法非常高的准确性。RF的准确性最高，接近0.99。RF与新方法的差异约为2%。新方法在准确性方面优于C4.5。正如前面提到的，准确性在推特垃圾信息检测实验中并不是关键指标。在这种情况下，即使将所有测试样本分类为非垃圾类，准确性也约为0.99。这里使用准确性是为了确认分类方法的正确实现。我们需要更多关注正确检测到的垃圾推文数量。

**图9** 报告了三种方法的AUC和检测率。与第一个测试数据的结果一致，新方法在10天内具有最佳的AUC和检测率。C4.5并不总是比RF具有更好的AUC。例如，在第1天，新方法的平均AUC约为0.84。C4.5的AUC为0.76，比RF高约2%。在第4天，第二种最佳方法是RF，其AUC比C4.5高约2%。新方法的AUC在这一天比RF高出超过10%。在第10天，C4.5的AUC与新方法相当，两者都比RF高超过5%。

对于检测率，新方法是最好的。RF是最差的方法，C4.5居中。新方法的检测率在大多数情况下显著高于其他方法。例如，在第1天，新方法的AUC达到0.7，而C4.5的AUC低于0.6。RF的检测率最低，为0.5。在第4天，新方法的检测率约为0.67，而C4.5和RF的检测率均低于0.5。在第10天，C4.5的检测率与新方法相同。RF的检测率比其他方法低约15%。

我们可以看到，两个不同测试数据集的结果是一致的。新方法显示了出色的鲁棒性，并在任何情况下都显著优于C4.5和RF。

**5. 结论**
本文解决了一个关键挑战：Twitter垃圾信息漂移。我们将其视为一个具有少量不平衡数据的特殊机器学习问题。我们提出了一种新方法，结合了两种新技术——模糊重分布和不对称采样，以解决这个问题。模糊重分布技术通过信息分解生成更多的合成垃圾样本。不对称采样技术通过对垃圾样本进行过采样和对非垃圾样本进行欠采样来平衡训练数据的大小。集成技术用于结合两个不同训练集上的垃圾分类器，以提高垃圾检测的鲁棒性和准确性。为了评估新方法，我们在一个真实的10天基准数据集上进行了多次实验。新方法与另外两种方法C4.5和RF进行了比较。实验结果显示，新方法可以显著提高漂移Twitter垃圾信息的检测性能。垃圾信息检测的AUC可提高多达10%，检测率可提高超过20%。

**6. 参考文献**
[此处列出参考文献]

---

希望这个优化后的版本更加清晰、连贯和专业。如果有进一步的需求或修改，请随时告诉我。