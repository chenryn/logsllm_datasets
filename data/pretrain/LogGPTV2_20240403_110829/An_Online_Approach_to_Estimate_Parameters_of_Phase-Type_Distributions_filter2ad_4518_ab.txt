algorithm for mixtures of simple component distributions. We
ﬁrst present this basic online algorithm before we introduce
speciﬁc variants for different subclasses of PHDs. The ap-
proach from [7] can be easily applied to distributions where
each component only has a single parameter and consequently,
we ﬁrst describe the straightforward application to hyperexpo-
nential distributions. For other distributions like hyper-Erlang,
APHDs or general PHDs the application of the algorithm is
more complicated and will be introduced afterwards. More-
over, the approach from [7] assumes homogeneous data and
at some point further observations will have little to no effect
on the parameters. Consequently, we propose a new adaptive
variant of the algorithm in Sect. V which determines PHDs
that may change if the input stream changes.
In the following we consider an inﬁnite sequence of ob-
servations T and assume that data point th (h = 1, 2, . . .)
arrive sequentially. Deﬁne T:h as the sub-sequence of the ﬁrst h
observations, Th: as the sub-sequence starting with observation
h and Th:l for h ≤ l is the ﬁnite sub-sequence starting with
th and ending with tl. We usually use tk for the current
observation. The online EM-algorithm can be interpreted as
a stochastic approximation approach [33] in this setting.
A. Online-EM Algorithm
In an EM-algorithm we have the observed data from T , the
(cid:14)
unobserved data from X and the parameters of the distribution
(cid:5)
θ(x, t) be the detailed density and fθ(t) =
from Θ. Let f
(cid:5)
θ(x, t)dx. Then Ex|t,θ[.] is the conditional expectation if
t and θ are known. An ofﬂine EM-algorithm deﬁnes the so
called Q-function [5], [7] as
f
Exh|th,θ [log f
(cid:5)
θ(xh, th)] .
(6)
k(cid:15)
h=1
1
k
Qθ(T:k) =
(cid:16)
In the online EM-algorithm of [7] this is substituted by
ˆQk(θ) = ˆQk−1(θ)
(cid:17)
+γk
Exk|tk,θ(k−1)
(cid:5)
θ(k) (xk, tk)
f
(cid:19)
(7)
(cid:18) − ˆQk−1(θ)
for k > 0 and ˆQ0(θ) is some initial approximation. γk is
a decreasing sequence of non-negative values (see [7] and
Sect. V). The parameters of the distribution θ(k) are chosen
n(cid:15)
n(cid:15)
to maximize ˆQk(θ) over the set Θ. The approach can be
applied whenever ˆQk(θ) can be computed efﬁciently and can
be maximized with respect to the current parameter θ(k−1).
Often mixture distributions are used. Here we present concrete
realizations of the algorithms for different variants of PHDs.
B. Application to Hyperexponential Distributions
The simplest class of PHDs used for Online-EM ﬁtting
are hyperexponential distributions where the application is
straightforward. Hyperexponential distributions are mixtures
of exponential components. They have parameters θ =
(π1, . . . , πn, λ1, . . . , λn) where the πi are the frequencies of
the exponential components that have rates λi resulting in the
density
(hexp)
θ
f
(t) =
πigλi (t) =
πiλie
i=1
i=1
−λit
t ≥ 0.
(8)
g
g
λ
(tk)
(k−1)
i
(k−1)
λ
i
(k−1)
j
(k)
E[B
i
(k)
E[S
i
Then the following values can be computed in the E-step of
the algorithm for observation tk with θ(k−1).
Pθ(k−1) (Xk = i|tk) =
] = (1 − γk)E[B
] = (1 − γk)E[S
] +γ kPθ(k−1) (Xk = i|tk)
] +γ ktkPθ(k−1) (Xk = i|tk)
(9)
The E-step can be evaluated if started with appropriate initial
(0)
]. The new parameter vector
estimates for E[B
i
θ(k) is then computed in the M-step as π
] and
i = E[B
(k)
λ
E[S
π
(cid:3)n
j=1 π
(k−1)
(k−1)
i
i
] for i = 1, . . . , n.
(k)
(k)
i = E[B
i
] and E[S
(k−1)
j
(0)
i
]
(k)
i
(k)
i
(tk)
C. Application to Hyper-Erlang Distributions
Hyper-Erlang distributions are a generalization of hyper-
exponential distributions where the components are Erlang
distributions instead of exponential. We have parameters θ =
(π1, . . . , πm, λ1, . . . , λm, n1, . . . , nm) where the πi are the
frequencies of the Erlang components that have rates λi and
ni phases. Having two parameters for each component makes
the direct application of the EM-algorithm difﬁcult. In fact,
the efﬁcient estimation of the parameters of a hyper-Erlang
distribution is complicated in general, if all parameters have to
be considered, as there is an interplay between the parameters
λi and ni for an Erlang component. The algorithm in [13] that
present an ofﬂine EM-algorithm for hyper-Erlang distributions
overcomes this problem by estimating only λi and assumes
either given ni values or tries all combinations of ni values
m
i=1 ni and selects
for a given overall number of states n =
the best distribution from these combinations.
parameters
estimation
use
=
only, while
(π1, . . . , πm, λ1, . . . , λm)
n1, . . . , nm is ﬁxed and not part of the estimation procedure.
Then, the hyper-Erlang distribution has the following density
function
(cid:10)
Hence,
the
for
we
θ
m(cid:15)
(herd,(n1,...,nm))
θ
f
(t) =
πig
(erl,ni)
λi
(t)
(10)
i=1
103
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:54:41 UTC from IEEE Xplore.  Restrictions apply. 
⎧⎨⎩
(k−1)
m−1
(k−1)
]/E[S
m
parameter λ
E[B
following computation.
(k−1)
m
(11)
remains, that has to capture the difference
(k)
m ]. This results in the
] − E[B
(k)
m ]/E[S
if k = m
if k  λ
(k)
i = π
(k)
i +
(k)
i+1
(k)
i+1
(16)
(k)
i
(k)
i+1
(k)
λ
i
(k)
i
λ
λ
π
,
Additionally, the results from the last E-step, which are reused
in the next steps also have to be transformed.
where the Erlang density with rate λi and ni phases is given
by
(erl,ni)
λi
g
(t) =
−λit
i tni−1e
λni
(ni − 1)!
(k)
i
To compute π
gλi (t) by g
are then computed as
(erl,ni)
λi
(k)
i
(9) can be applied after substituting
and λ
(t). The new estimates for the parameters
(k)
(k)
i = E[B
i
π
] and λ
(k)
i =
]
(k)
niE[B
i
(k)
E[S
i
]
(12)
for i = 1, . . . , m. With these deﬁnitions we can either run
the algorithm for a single settings of n1, . . . , nm or for small
n compute all settings simultaneously and select
the best
approximation using the approach presented in the following
section.
D. Application to Acyclic Phase-Type Distributions
Hyperexponential and hyper-Erlang distributions are spe-
ciﬁc cases of APHDs. Each APHD can be transformed in the
canonical form (1) [14], [17]. The behavior of an APHD in
canonical form is as follows: With probability π1 the PHD
starts in state 1 and moves through all states 2, . . . , n from
where the absorption takes place. The time spent in this state
follows a hypoexponential (or generalized Erlang) distribution
with n states and rates λ1, . . . , λn. With probability π2 we
have a generalized Erlang distribution with n − 1 states and
rates λ2, . . . , λn and so on. Hence, we have a mixture of
m = n generalized Erlang distributions with parameter vector
θ = (π1, . . . , πn, λ1, . . . , λn) for APHDs in canonical form.
The rates λi are ordered according to their size. With these
deﬁnitions we obtain
(aphd)
θ
f
(t) =
(gerl)
λi,...,λm (t)
(13)
⎞⎠ .
m(cid:15)
and the probability densities of the generalized Erlang distri-
butions
(gerl)
λi,...,λm (t) =
g
−tλj
λje
j=i
λh
λh − λj
h=i,h(cid:4)=j
(14)
Obviously, the above function for the density of the compo-
(gerl)
nents g
λi,...,λm(t) only works if all λi are distinct. If this is
not the case, the density has to be computed numerically as
π(k−1)etkD(k−1) d(k−1) which will be shown below.
(k)
i = E[B
i
For the computation of the parameters, again (9) with the
(gerl)
λi,...,λm(t) can be applied. Then π(k)
densities g
] as
(k)
before. The computation of the new estimates λ
is slightly
i
more complex because we have a varying number of rates
depending on the component i and all rates except the ﬁrst are
relevant for several generalized Erlang distributions. However,
observe that for the last component m we have only one free
parameter, i.e. λm. This parameter can easily be estimated
(k)
m ]. Now, for the generalized Erlang
as λ
(k)
distribution from the last two states, we have two rates λ
m and
(k)
(k)
m has already been estimated. Thus, only one
m−1 where λ
λ
(k)
m = E[B
(k)
m ]/E[S
πig
m(cid:15)
⎛⎝ m(cid:22)
i=1
E[B
] = π
(k)
i
E[S
] = E[B
(k)
i
(k)
i
(cid:28)(cid:10)
(cid:28)
, E[B
(k)
i
]
(k)
i+1] = π
m
j=i
(cid:10)
1
(k)
j
λ
(cid:29)
(k)
i+1,
,
E[S
(k)
i+1] =E [B
(k)
i+1]
1
(k)
i
λ
+
m
j=i+2
1
(k)
j
λ
(cid:29)
(17)
Afterwards λ
(17) are iterated until the APHD is in canonical form.
(k)
i+1 are switched. The steps (16) and
and λ
(k)
i
E. General PHDs
We have to formulate online versions of (4) and (5) to
realize an online EM-algorithm for general PHDs. The E-step
then becomes
(k)
Eθ[B
i
(k)
Eθ[Y
i