60%
50%
40%
30%
20%
10%
0%
Figure 10: Percentage Reduction of legitimate targets for an
indirect call
(cid:3)
For indirect jumps, there could be many indirect jumps that re-
side in the PLT section, and these jumps have certain targets within
the current module. BinCC takes them into account and thus re-
duces the legitimate targets by 35% on average compared to BinC-
FI, as shown in Figure 11.
Figure 12 shows that BinCC reduces legitimate targets for a
return by 87% on average compared to BinCFI, this is because
BinCC signiﬁcantly reﬁnes the targets for direct returns by enforc-
ing a much more strict policy on them as compared to BinCFI. We
see gcc achieved the largest improvement. There are more direct
returns than indirect returns in this binary, and each direct return
338
100%
90%
80%
70%
60%
50%
40%
30%
20%
10%
0%
Figure 12: Percentage Reduction of legitimate targets for a re-
turn
(cid:3)
only has far less legitimate targets on average than each indirect
return. All these factors contribute to the improvement.
6.3 ROP Attacks Evaluation
Because of new security mechanisms such as ASLR and DEP,
ROP has gained much more popularity among attackers as a tech-
nique for launching exploits. CFI implementations such as CC-
FIR and BinCFI signiﬁcantly mitigate ROP attacks, since the vast
majority of ROP gadgets are instruction-misaligned and no longer
feasible for generating exploit. However, the work [5, 10] recently
showed that in some cases it is still possible for attackers to lever-
age call preceded ROP gadgets to build ROP chains and thus bypass
the protection from BinCFI and CCFIR.
To evaluate the ability of BinCC in preventing ROP attacks, we
introduce GS (Gadget Survivability) to represent the difﬁculty for
attackers to leverage call preceded gadgets while establishing ROP
chains for exploits under CFI protection. We deﬁne this metric as
follows.
GS =
|R|(cid:5)
i=0
|Ci|
|C|
1|R|
Suppose in a CFI enforced binary a return instruction was ful-
ly controlled by attackers, how likely this return could be used to
reach a call preceded gadget in this binary.
In the deﬁnition, Ci represents the legitimate target set for a re-
turn instruction ri under CFI enforcement, R represents the set
composed by all the returns, and C represents the set composed by
all the call preceded gadgets. For the return ri, it could reach the
|Ci| number of call preceded gadgets. So the probability that it was
controlled and could return to a call preceded gadget is 1|R| ∗ |Ci|
|C| .
(cid:2)|R|
i=0
|Ci|
|C| .
(cid:2)|R|
i=0
|C| , or, 1|R|
1|R| ∗ |Ci|
After taking all the returns into consideration, the average proba-
bility is
For BinCFI, from the formula, for each ri, |Ci| equals |C|, so
this metric value is 100%. This is consistent with the fact that the
hijacked return could reach any call preceded gadget within the
binary they protect.
However, for BinCC, this probability is much smaller, as both
direct returns and indirect returns are restricted to have far less le-
gitimate targets. Speciﬁcally, if the return was an indirect return, it
would be allowed to reach any indirect call sites. If the return was
a direct return, it would only be allowed to reach gadgets starting at
speciﬁc direct call sites. We calculate the probability under BinCC
as well as BinCFI for all tested samples, and present the statistics in
Table 2. From the table, we see that BinCC considerably degrad-
ed the probability to leverage call preceded ROP gadgets for ROP
attacks, only around 0.70%, with comparison to 100% for BinCFI.
program
BinCC
2.554%
lbm
0.321%
gcc
perlbench
0.530%
libquantum 0.210%
1.145%
omnetpp
0.299%
sjeng
1.138%
gobmk
0.474%
bzip2
0.573%
povray
milc
0.283%
0.569%
hmmer
0.444%
sphinx3
0.420%
h264ref
0.387%
astar
mcf
0.355%
1.237%
namd
1.017%
soplex
average
0.701%
BinCFI
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
Table 2: Gadget Survivability for BinCC and BinCFI
6.4 Performance
We evaluated both space and runtime overhead. For space over-
head, we compared the increase of address translation tables be-
tween BinCC and BinCFI, and also evaluated code size increase
and total ﬁle size increase compared to the original ﬁle. For runtime
overhead, we ran binaries enforced by BinCC as well as BinCFI
and ﬁnally made comparisons.
Space Overhead
6.4.1
As we use a similar infrastructure to BinCFI to manipulate bi-
naries, the reason for ﬁle size increase is as the same as that for
BinCFI, due to the new code section for instrumentation and new
read-only data sections for address translation hash tables. The new
code size increase 1.4 times the original code size, while the ﬁg-
ure for BinCFI is around 1.2. We introduce four kinds of tables
for storing targets of indirect calls, indirect jumps, indirect returns
and direct returns, while BinCFI uses two kinds for storing indirect
calls/jmps and returns. The total introduced tables size decrease
around 20% of the ﬁgure for BinCFI. Overall, the space overhead
is around 125% of the original binary size, 14% lower than the
ﬁgure for BinCFI. The reduction of tables size contributes to the
improvement of space overhead as compared to BinCFI. Accord-
ing to BinCFI’s implementation, the hash table size is a power of 2
and is relevant to the number of legitimate targets, so the table size
decreases greatly as we reﬁne the legitimate transfer targets size.
339
6.4.2 Runtime Overhead
We compared the runtime overhead of the programs enforced by
BinCC and BinCFI in Figure 13. In our test environment, the re-
sults showed that BinCFI increased around 18% percent, while our
solution increased around 22% percent, 4% higher than BinCFI.
The reason why our overhead is a bit higher than BinCFI is be-
cause we add extra instructions to help instrumentation for direct
returns, and perform separate address checking and translating. We
believe the overhead is reasonable and acceptable while comparing
to the ﬁner-grained protection provided to stripped binaries.
BinCC
BinCFI
80%
70%
60%
50%
40%
30%
20%
10%
0%
-10%
-20%
Figure 13: Runtime Overhead for Tested Samples
7. DISCUSSION
Although our solution has made considerable improvements for
restricting indirect control ﬂow transfers, the policy for indirec-
t calls still need improvement compared to returns. In our solution,
the protected binaries are still vulnerable to attacks altering indirect
call targets. Indirect call targets are permitted to reach any ICF, and
it would be considered as valid that if the target of an indirect call is
modiﬁed to another ICF in the binary. However, other binary only
CFI solutions face the same problem. Existing solutions [11, 18]
make improvement in protecting speciﬁc indirect call targets such
as C++ virtual functions. It is not hard for BinCC to combine them
to achieve more strict protection. We leave this as our future work.
Dynamic code such as JIT code could not be identiﬁed simply
through static analysis without source code, so our solution can not
handle this code. This is also a common open issue with other
current binary only CFI solutions. We leave it as our future work.
8. CONCLUSION
Existing binary-only CFI solutions apply relaxed CFI policies
due to the lack of source code or debug symbols. Although they
can mitigate common control ﬂow hijack threats, it is still possible
for adversaries to launch sophisticated attacks, for instance, ROP
attacks launched by leveraging call preceded gadgets.
In this paper, we propose a new binary only CFI protection scheme
BinCC, which provides ﬁner-grained protection for x86 stripped
ELF binaries. Through code duplication and static analysis, we di-
vide the code into mutually exclusive code continents. We further
classify indirect transfers in each code continent to be either Intra-
Continent transfers or Inter-Continent transfers, and apply strict C-
FI polices to constrain these transfers. To evaluate BinCC, we in-
troduce new metrics to estimate the average amount of legitimate
targets of each kind of indirect transfer as well as the difﬁculty to
leverage call preceded gadgets to generate exploits, and make com-
parisons with BinCFI. The experiments show that BinCC makes
great improvement on both aspects with a reasonable overhead.
[13] S. McCamant and G. Morrisett. Evaluating sﬁ for a cisc
architecture. In Usenix Security, page 15, 2006.
[14] V. Mohan, P. Larsen, S. Brunthaler, K. Hamlen, and
M. Franz. Opaque control-ﬂow integrity. In Symposium on
Network and Distributed System Security (NDSS), 2015.
[15] B. Niu and G. Tan. Modular control-ﬂow integrity. In
Proceedings of the 35th ACM SIGPLAN Conference on
Programming Language Design and Implementation,
page 58. ACM, 2014.
[16] B. Niu and G. Tan. Rockjit: Securing just-in-time
compilation using modular control-ﬂow integrity. In
Proceedings of the 2014 ACM SIGSAC Conference on
Computer and Communications Security, pages 1317–1328.
ACM, 2014.
[17] M. Payer, A. Barresi, and T. R. Gross. Fine-grained
control-ﬂow integrity through binary hardening. In Detection
of Intrusions and Malware, and Vulnerability Assessment,
2015.
[18] A. Prakash, X. Hu, and H. Yin. vfguard: Strict protection for
virtual function calls in cots c++ binaries. In Network and
Distributed System Security Symposium, NDSS, volume 15,
2015.
[19] A. Prakash, H. Yin, and Z. Liang. Enforcing system-wide
control ﬂow integrity for exploit detection and diagnosis. In
Proceedings of the 8th ACM SIGSAC symposium on
Information, computer and communications security, pages
311–322. ACM, 2013.
[20] R. Roemer, E. Buchanan, H. Shacham, and S. Savage.
Return-oriented programming: Systems, languages, and
applications. ACM Transactions on Information and System
Security (TISSEC), 15(1):2, 2012.
[21] H. Shacham. The geometry of innocent ﬂesh on the bone:
Return-into-libc without function calls (on the x86). In
Proceedings of the 14th ACM conference on Computer and
communications security, pages 552–561. ACM, 2007.
[22] P. Team. Pax address space layout randomization, 2003.
[23] C. Tice, T. Roeder, P. Collingbourne, S. Checkoway,
Ú. Erlingsson, L. Lozano, and G. Pike. Enforcing
forward-edge control-ﬂow integrity in gcc & llvm. In
USENIX Security Symposium, 2014.
[24] R. Wahbe, S. Lucco, T. E. Anderson, and S. L. Graham.
Efﬁcient software-based fault isolation. In ACM SIGOPS
Operating Systems Review, volume 27, pages 203–216.
ACM, 1994.
[25] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth,
T. Ormandy, S. Okasaka, N. Narula, and N. Fullagar. Native
client: A sandbox for portable, untrusted x86 native code. In
Security and Privacy, 2009 30th IEEE Symposium on, pages
79–93. IEEE, 2009.
[26] C. Zhang, T. Wei, Z. Chen, L. Duan, L. Szekeres,
S. McCamant, D. Song, and W. Zou. Practical control ﬂow
integrity and randomization for binary executables. In
Security and Privacy (SP), 2013 IEEE Symposium on, pages
559–573. IEEE, 2013.
[27] M. Zhang and R. Sekar. Control ﬂow integrity for cots
binaries. In Usenix Security, pages 337–352, 2013.
9. ACKNOWLEDGMENTS
We would like to thank anonymous reviewers for their feedback
in ﬁnalizing this paper. This work was achieved when Minghua
Wang was at Syracuse University as a visiting student. This re-
search was supported in part by National Science Foundation Grant
#1054605, Air Force Research Lab Grant #FA8750-15-2-0106, the
Major State Basic Research Development Program of China Grant
#2012CB315804, the National Natural Science Foundation of Chi-
na Grant #91418206, and China Scholarship Council (CSC). Any
opinions, ﬁndings, and conclusions made in this material are those
of the authors and do not necessarily reﬂect the views of the fund-
ing agencies.
10. REFERENCES
[1] M. Abadi, M. Budiu, Ú. Erlingsson, and J. Ligatti.
Control-ﬂow integrity principles, implementations, and
applications. ACM Transactions on Information and System
Security (TISSEC), 13(1):4, 2009.
[2] S. Andersen and V. Abella. Data execution prevention.
changes to functionality in microsoft windows xp service
pack 2, part 3: Memory protection technologies, 2004.
[3] T. Bletsch, X. Jiang, and V. Freeh. Mitigating code-reuse
attacks with control-ﬂow locking. In Proceedings of the 27th
Annual Computer Security Applications Conference, pages
353–362. ACM, 2011.
[4] T. Bletsch, X. Jiang, V. W. Freeh, and Z. Liang.
Jump-oriented programming: a new class of code-reuse
attack. In Proceedings of the 6th ACM Symposium on
Information, Computer and Communications Security, pages
30–40. ACM, 2011.
[5] N. Carlini and D. Wagner. Rop is still dangerous: Breaking
modern defenses. In USENIX Security Symposium, 2014.
[6] Y. Cheng, Z. Zhou, M. Yu, X. Ding, and R. H. Deng.
Ropecker: A generic and practical approach for defending
against rop attacks. In Symposium on Network and
Distributed System Security (NDSS), 2014.
[7] L. Davi, A.-R. Sadeghi, and M. Winandy. Ropdefender: A
detection tool to defend against return-oriented programming
attacks. In Proceedings of the 6th ACM Symposium on
Information, Computer and Communications Security, pages
40–51. ACM, 2011.
[8] U. Erlingsson, M. Abadi, M. Vrable, M. Budiu, and G. C.
Necula. Xﬁ: Software guards for system address spaces. In
Proceedings of the 7th symposium on Operating systems
design and implementation, pages 75–88. USENIX
Association, 2006.
[9] I. Evans, S. Fingeret, J. González, U. Otgonbaatar, T. Tang,
H. Shrobe, S. Sidiroglou-Douskos, M. Rinard, and
H. Okhravi. Missing the point (er): On the effectiveness of
code pointer integrity1. In Security and Privacy (SP), 2015.
[10] E. Goktas, E. Athanasopoulos, H. Bos, and G. Portokalidis.
Out of control: Overcoming control-ﬂow integrity. In
Security and Privacy (SP), 2014 IEEE Symposium on, pages
575–589. IEEE, 2014.
[11] D. Jang, Z. Tatlock, and S. Lerner. Safedispatch: Securing
c++ virtual calls from memory corruption attacks. In
Symposium on Network and Distributed System Security
(NDSS), 2014.
[12] V. Kuznetsov, L. Szekeres, M. Payer, G. Candea, R. Sekar,
and D. Song. Code-pointer integrity. In USENIX Symposium
on Operating Systems Design and Implementation (OSDI),
2014.
340