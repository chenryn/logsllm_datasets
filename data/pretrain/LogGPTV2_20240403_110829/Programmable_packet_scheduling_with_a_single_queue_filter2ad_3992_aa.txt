title:Programmable packet scheduling with a single queue
author:Zhuolong Yu and
Chuheng Hu and
Jingfeng Wu and
Xiao Sun and
Vladimir Braverman and
Mosharaf Chowdhury and
Zhenhua Liu and
Xin Jin
Programmable Packet Scheduling with a Single Queue
Zhuolong Yu
Chuheng Hu
Jingfeng Wu
Johns Hopkins University
Johns Hopkins University
Johns Hopkins University
Xiao Sun
Stony Brook University
Vladimir Braverman
Johns Hopkins University
Mosharaf Chowdhury
University of Michigan
Zhenhua Liu
Stony Brook University
Xin Jin
Peking University
ABSTRACT
Programmable packet scheduling enables scheduling algorithms to
be programmed into the data plane without changing the hardware.
Existing proposals either have no hardware implementations for
switch ASICs or require multiple strict-priority queues.
We present Admission-In First-Out (AIFO) queues, a new solu-
tion for programmable packet scheduling that uses only a single
first-in first-out queue. AIFO is motivated by the confluence of
two recent trends: shallow buffers in switches and fast-converging
congestion control in end hosts, that together leads to a simple
observation: the decisive factor in a flow’s completion time (FCT)
in modern datacenter networks is often which packets are enqueued
or dropped, not the ordering they leave the switch. The core idea of
AIFO is to maintain a sliding window to track the ranks of recent
packets and compute the relative rank of an arriving packet in the
window for admission control. Theoretically, we prove that AIFO
provides bounded performance to Push-In First-Out (PIFO). Empir-
ically, we fully implement AIFO and evaluate AIFO with a range
of real workloads, demonstrating AIFO closely approximates PIFO.
Importantly, unlike PIFO, AIFO can run at line rate on existing
hardware and use minimal switch resources—as few as a single
queue.
CCS CONCEPTS
• Networks → Programmable networks; Packet scheduling;
In-network processing; Data center networks.
ACM Reference Format:
Zhuolong Yu, Chuheng Hu, Jingfeng Wu, Xiao Sun, Vladimir Braverman,
Mosharaf Chowdhury, Zhenhua Liu, and Xin Jin. 2021. Programmable Packet
Scheduling with a Single Queue. In ACM SIGCOMM 2021 Conference (SIG-
COMM ’21), August 23–28, 2021, Virtual Event, Netherlands. ACM, New York,
NY, USA, 15 pages. https://doi.org/10.1145/3452296.3472887
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
SIGCOMM ’21, August 23–28, 2021, Virtual Event, Netherlands
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-8383-7/21/08. . . $15.00
https://doi.org/10.1145/3452296.3472887
1 INTRODUCTION
Packet scheduling is a central research topic in computer network-
ing. Over the past several decades, a great many packet scheduling
algorithms have been designed to provide different properties and
optimize diverse objectives [6, 11, 23, 40, 41]. Unfortunately, most
of these algorithms, despite many novel ideas among them, never
have found their way to impact the real world. This is largely due to
the high cost to design and deploy switch ASICs to implement them,
since packet scheduling algorithms must run in the data plane at
line rate in order to process every single packet.
Programmable packet scheduling is a holy grail for packet sched-
uling as it enables scheduling algorithms to be programmed into a
switch without changing the hardware design. With programmable
packet scheduling, one is able to develop or simply download a
packet scheduling algorithm that best matches the operational goals
of the network. This enables network operators to highly customize
packet scheduling algorithms based on their needs. Particularly,
it simplifies the testing and deployment of new scheduling algo-
rithms, and it enables algorithms that are targeted at small niche
markets and thus cannot justify the high cost of developing new
switch ASICs to be used and deployed.
A Push-In First-Out (PIFO) queue is a popular abstraction for
programmable packet scheduling [3, 47]. PIFO associates a rank
with each packet and maintains a sorted queue to buffer packets.
Newly arrived packets are inserted into the queue based on their
ranks, and packets are dequeued from the head. Different packet
scheduling algorithms can be implemented on top of PIFO by chang-
ing the rank computation function. Prior works have shown that
PIFO can support a wide range of popular scheduling algorithms,
such as Shortest Remaining Processing Time (SRPT) [41] for mini-
mizing flow completion times (FCTs) and Start-Time Fair Queueing
(STFQ) [13] for weighted fairness.
PIFO, while elegant in theory, is challenging to implement in
practice. A recent work [47] proposes a hardware design to support
PIFO at a clock frequency of 1 GHz on shared-memory switches.
The major design complexity lies in supporting a sorted queue at
1 GHz. Yet, there is a gap from the design to a real switch ASIC
implementation, and the design has scalability limitations—it can
only support a few thousand flows. SP-PIFO [3] is an approximation
of PIFO that can run on existing hardware. The basic idea is to map
the possibly large number of ranks into a small set of priorities,
and then simply schedule the small number of queues based on
179
SIGCOMM ’21, August 23–28, 2021, Virtual Event, Netherlands
Zhuolong Yu, et al.
their priorities. This solution, however, requires multiple precious
strict-priority queues.
In this paper, we present Admission-In First-Out (AIFO) queues,
a new solution for programmable packet scheduling that uses only
a single first-in first-out (FIFO) queue. FIFO (drop-tail) queues are
one of the simplest queues that can run at line rate and are available
in almost all switches. Thus, AIFO is amenable to be implemented
in high-speed switches with line rate, and we show not only a
concrete design, but also a real implementation of AIFO on ex-
isting hardware (Barefoot Tofino), with minimal requirements on
hardware primitives—a single FIFO queue, as opposed to multiple
strict-priority queues.
AIFO is motivated by the confluence of two recent trends in
datacenter networking: shallow buffers in the switches [5] and
fast-converging congestion control protocols implemented in end
hosts [22]. Together, they significantly reduce the queueing latency
inside the network, which is especially important for datacenter
environments where low latency is critical for real-time online
services with strict Service Level Objectives (SLOs) [5]. Given these
trends, we observe that the decisive factor in modern datacenters
is often which packets are enqueued or dropped by the switch, not
the ordering in which they leave the switch. For example, dropping
packets of an elephant flow when it competes with two mice flows
is more important to the flow completion times of the mice flows
than the ordering that their packets are dequeued, especially when
the queue length is kept small such that only a few packets occupy
it at any moment.
Based on this insight, the major technical challenge we tackle in
this paper is finding the right set of packets to admit into the queue.
Ideally, AIFO should admit the same set of packets as PIFO to closely
approximate it. AIFO addresses this challenge by maintaining a
sliding window to track the ranks of recent packets in the window
and computing the relative rank of an arriving packet in order
to decide whether to admit or proactively drop it even when the
queue may still have room! Unlike traditional active queue manage-
ment (AQM) solutions, AIFO drops packets based on their relative
ranks instead of using threshold comparisons against average queue
length [12, 34, 35] or delay estimations [32]. Theoretically, we prove
that AIFO provides performance close to that of PIFO. We comple-
ment it with a concrete data plane design and implementation to
show how to efficiently realize AIFO on Barefoot Tofino.
AIFO explores an interesting design question: what are the min-
imal hardware requirements for programmable packet scheduling?
AIFO is an extreme point in the design space—it only requires a
single FIFO queue. This is not only theoretically interesting, but
also has important practical implications. Our conversations with
industry collaborators, including a large-scale search engine and a
large-scale e-commerce service, indicate that physical queues are
critical resources, and are reserved to ensure strong physical isola-
tion and differentiation between applications of multiple tenants;
modern datacenters are already short of physical queues available in
switches. Unlike SP-PIFO which requires multiple physical queues
for packet scheduling, AIFO enables operators to continue using
physical queues for strong physical isolation and differentiation
between tenants, and additionally use AIFO to program the packet
scheduling algorithm for intra-tenant traffic (e.g., SRPT to minimize
the flow completion time).
(cid:42)(cid:46)(cid:44)(cid:35) (cid:36)(cid:40)
(cid:22)(cid:28)(cid:40)(cid:37)
(cid:16)(cid:41)(cid:39)(cid:42)(cid:46)(cid:45)(cid:28)(cid:45)(cid:36)(cid:41)(cid:40)
(cid:11)
(cid:13)
(cid:12)
(cid:10)
(cid:9)
(cid:33)(cid:36)(cid:43)(cid:44)(cid:45)(cid:1)(cid:41)(cid:46)(cid:45)
(cid:20)(cid:18)(cid:17)(cid:19)
(cid:22)(cid:28)(cid:40)(cid:37)(cid:1)(cid:16)(cid:41)(cid:39)(cid:42)(cid:46)(cid:45)(cid:28)(cid:45)(cid:36)(cid:41)(cid:40)(cid:1)(cid:33)(cid:41)(cid:43)(cid:1)(cid:23)(cid:35)(cid:41)(cid:43)(cid:45)(cid:32)(cid:44)(cid:45)(cid:1)(cid:22)(cid:32)(cid:39)(cid:28)(cid:36)(cid:40)(cid:36)(cid:40)(cid:34)(cid:1)(cid:20)(cid:43)(cid:41)(cid:30)(cid:32)(cid:44)(cid:44)(cid:36)(cid:40)(cid:34)(cid:1)(cid:24)(cid:36)(cid:39)(cid:32)(cid:1)(cid:2)(cid:23)(cid:22)(cid:20)(cid:24)(cid:3)
(cid:42)(cid:7)(cid:43)(cid:28)(cid:40)(cid:37)(cid:15)(cid:1)(cid:42)(cid:7)(cid:43)(cid:32)(cid:39)(cid:28)(cid:36)(cid:40)(cid:36)(cid:40)(cid:34)(cid:27)(cid:42)(cid:43)(cid:41)(cid:30)(cid:32)(cid:44)(cid:44)(cid:36)(cid:40)(cid:34)(cid:27)(cid:45)(cid:36)(cid:39)(cid:32)
(cid:22)(cid:28)(cid:40)(cid:37)(cid:1)(cid:16)(cid:41)(cid:39)(cid:42)(cid:46)(cid:45)(cid:28)(cid:45)(cid:36)(cid:41)(cid:40)(cid:1)(cid:33)(cid:41)(cid:43)(cid:1)(cid:23)(cid:45)(cid:28)(cid:43)(cid:45)(cid:6)(cid:24)(cid:36)(cid:39)(cid:32)(cid:1)(cid:17)(cid:28)(cid:36)(cid:43)(cid:1)(cid:21)(cid:46)(cid:32)(cid:46)(cid:32)(cid:36)(cid:40)(cid:34)(cid:1)(cid:2)(cid:23)(cid:24)(cid:17)(cid:21)(cid:3)
(cid:4)(cid:3) (cid:42)(cid:1)(cid:29)(cid:32)(cid:38)(cid:41)(cid:40)(cid:34)(cid:44)(cid:1)(cid:45)(cid:41)(cid:1)(cid:28)(cid:1)(cid:40)(cid:32)(cid:48)(cid:1)(cid:33)(cid:38)(cid:41)(cid:48)(cid:14)
(cid:42)(cid:7)(cid:44)(cid:45)(cid:28)(cid:43)(cid:45) (cid:15)(cid:1)(cid:47)(cid:36)(cid:43)(cid:45)(cid:46)(cid:28)(cid:38)(cid:27)(cid:45)(cid:36)(cid:39)(cid:32)
(cid:2)(cid:5)(cid:7)(cid:2)(cid:14)
(cid:42)(cid:7)(cid:44)(cid:45)(cid:28)(cid:43)(cid:45) (cid:15)(cid:1)(cid:6)(cid:1)(cid:8)(cid:2)(cid:47)(cid:36)(cid:43)(cid:45)(cid:46)(cid:28)(cid:38)(cid:27)(cid:45)(cid:36)(cid:39)(cid:32)(cid:5)(cid:1)(cid:33)(cid:36)(cid:40)(cid:36)(cid:44)(cid:35)(cid:27)(cid:45)(cid:36)(cid:39)(cid:32)(cid:25)(cid:42)(cid:7)(cid:33)(cid:38)(cid:41)(cid:48)(cid:27)(cid:36)(cid:31)(cid:26)(cid:3)
(cid:33)(cid:36)(cid:40)(cid:36)(cid:44)(cid:35)(cid:27)(cid:45)(cid:36)(cid:39)(cid:32)(cid:25)(cid:42)(cid:7)(cid:33)(cid:38)(cid:41)(cid:48)(cid:27)(cid:36)(cid:31)(cid:26)(cid:1)(cid:15)(cid:1)(cid:42)(cid:7)(cid:44)(cid:45)(cid:28)(cid:43)(cid:45) (cid:4)(cid:1)(cid:42)(cid:7)(cid:38)(cid:32)(cid:40)(cid:34)(cid:45)(cid:35)(cid:8)(cid:48)(cid:32)(cid:36)(cid:34)(cid:35)(cid:45)(cid:25)(cid:42)(cid:7)(cid:33)(cid:38)(cid:41)(cid:48)(cid:27)(cid:36)(cid:31)(cid:26)
(cid:42)(cid:7)(cid:43)(cid:28)(cid:40)(cid:37) (cid:15)(cid:1)(cid:42)(cid:7)(cid:44)(cid:45)(cid:28)(cid:43)(cid:45)
Figure 1: Background on programmable packet scheduling
with PIFO.
As an unexpected positive byproduct, AIFO naturally supports
starvation prevention by design, a necessary feature of pFabric [6]
that schedules the packets of the same flow in FIFO to prevent
packet reordering. While PIFO supports a wide variety of schedul-
ing algorithms, it cannot support starvation prevention needed by
pFabric because the latter packets of a flow would be scheduled first
when PIFO is programmed to use SRPT. With the strong demand
on minimizing FCTs for low-latency online services, pFabric is ar-
guably the killer application of programmable packet scheduling, as
pFabric is considered to be one of the best solutions for minimizing
FCTs. AIFO enables us to implement and deploy pFabric on existing
hardware.
In summary, we make the following contributions.
• We propose AIFO, a new approach to programmable packet
scheduling that uses only a single queue.
• We design an algorithm based on sliding windows and efficient
relative rank computation to realize AIFO in the switch data plane.
Theoretically, we prove that AIFO provides bounded performance
to PIFO.
• We implement a AIFO prototype on a Barefoot Tofino switch.
We use a combination of simulations and testbed experiments to
evaluate AIFO under a range of real workloads and scheduling
algorithms, demonstrating AIFO closely approximates PIFO.
Open-source. The code of AIFO is open-source and is publicly
available at https://github.com/netx-repo/AIFO.
2 BACKGROUND AND MOTIVATION
In this section, we first provide background information on pro-
grammable packet scheduling, and then use an example to motivate
the key ideas of AIFO.
2.1 Programmable Packet Scheduling
Programmable packet scheduling enables the packet scheduling
algorithm in a switch to be changed without the need to change
the switch ASIC. PIFO [47] is a proposal for programmable packet
scheduling. It contains two components: a PIFO queue and a rank
computation component. Each packet is associated with a rank. The
180
Programmable Packet Scheduling with a Single Queue
SIGCOMM ’21, August 23–28, 2021, Virtual Event, Netherlands
(cid:7)
(cid:7)
(cid:6)
(cid:9)
(cid:8)
(cid:6)
(cid:7)
(cid:7)
(cid:6)
(cid:6)
(cid:7)
(cid:6)
(cid:7)
(cid:9)
(cid:8)
(cid:6)
(cid:7)
(cid:7)
(cid:6)
(cid:6)
(cid:2)(cid:16)(cid:3)(cid:1)(cid:15)(cid:29)(cid:27)(cid:20)(cid:4)(cid:13)(cid:24)(cid:1)(cid:12)(cid:21)(cid:26)(cid:27)(cid:28)(cid:4)(cid:14)(cid:29)(cid:28)(cid:1)(cid:2)(cid:15)(cid:13)(cid:12)(cid:14)(cid:3)(cid:5)
(cid:15)(cid:13)(cid:12)(cid:14)
(cid:7)
(cid:7)