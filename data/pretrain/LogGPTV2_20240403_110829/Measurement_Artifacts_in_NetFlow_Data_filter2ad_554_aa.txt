# Measurement Artifacts in NetFlow Data

**Authors:**
- Rick Hofstede
- Idilio Drago
- Anna Sperotto
- Ramin Sadre
- Aiko Pras

**Affiliation:**
University of Twente
Centre for Telematics and Information Technology
Design and Analysis of Communications Systems (DACS)
{r.j.hofstede, i.drago, a.sperotto, r.sadre, a.pras}@utwente.nl
Enschede, The Netherlands

## Abstract
Flows provide an aggregated view of network traffic by grouping streams of packets. The resulting scalability gain usually justifies the coarser data granularity, as long as the flow data accurately reflects the actual network traffic. However, it is known that the flow export process may introduce artifacts into the exported data. This paper extends the set of known artifacts by explaining which implementation decisions cause them. Additionally, we verify the presence of these artifacts in data from a set of widely-used devices. Our results show that the revealed artifacts are prevalent among different devices from various vendors. We believe that these findings provide researchers and operators with important insights for developing robust analysis applications.

**Keywords:** Network management, measurements, NetFlow, artifacts.

## 1. Introduction
Cisco’s NetFlow [2] and the recent standardization effort IPFIX [11] have made flow export technologies widely popular for network monitoring. These technologies owe their success to their applicability to high-speed networks and widespread integration into network devices. The pervasiveness of these technologies has resulted in a variety of new application areas that go beyond simple network monitoring, such as flow-based intrusion detection [13] and traffic engineering [4]. Regardless of the application, flow data is expected to accurately reflect the network traffic.

The flow export process involves real-time aggregation of packets into flows and periodic export of flow information to collectors. This aggregation naturally results in a coarser view of the network traffic. Several works have compared the precision of flow-based applications to their packet-based counterparts [4, 12]. The scalability gain of using flow data typically justifies the loss of precision. However, any flow-based application will be impaired by poor-quality flow data, which can be caused by implementation decisions. For example, imprecision in flow timestamps has been discussed in [9, 14], and artifacts found in flow data from Juniper devices are extensively analyzed in [3]. However, these works do not investigate how widespread these artifacts are in flow data from different flow export devices.

The goal of this paper is twofold. First, we report on our experience operating a Cisco Catalyst 6500, one of the most widely deployed switching platforms [7]. We provide an analysis of artifacts identified in flow data exported by this device, along with a detailed description of their causes. Second, inspired by [3], we analyze whether these artifacts are also present in flow data from other devices. Active experiments and flow data analysis are combined to evaluate the quality of six different flow exporters.

This paper is organized as follows: In Section 2, we analyze and explain the artifacts observed on a Cisco Catalyst 6500. In Section 3, we present the experiment setup. In Section 4, we discuss the results of our analyses. Finally, our conclusions are presented in Section 5.

## 2. Case Study: Cisco Catalyst 6500 (SUP720-3B)
The Cisco Catalyst 6500 is a widely deployed series of switches found in many service provider, enterprise, and campus networks. In this section, we discuss five artifacts present in flow data from a specific device in this series, located in our production network. This knowledge is gained from our operational experience. It is important to note that this list is not comprehensive, as artifacts are load- and configuration-dependent. Moreover, artifacts related to clock imprecisions, which we have also observed, are not covered here.

### 2.1 Imprecise Flow Record Expiration
Expiration is the process of removing flow records from the NetFlow table (i.e., flow cache). This can be done for various reasons, such as timeouts and exporter overload. According to the documentation, flow records can expire up to 4 seconds earlier or later than the configured timeout [1] when the device is not overloaded. The average expiration deviation should be within 2 seconds of the configured value. This is due to the way the expiration process is implemented: a software process scans the NetFlow table for expired flow records. Due to the time needed for scanning all flow records, expiration is often pre- or postponed.

### 2.2 TCP Flows Without Flag Information
TCP flags are accounted for in only a few TCP flows, as they are solely exported for software-switched flows [1]. These flows are processed by a generic CPU, while hardware-switched flows are processed using Application-Specific Integrated Circuits (ASICs). Whether a flow has been switched in hardware or software can be determined from the engineID field in the flow records. Since most packets are hardware-switched, only a few TCP flows with flags can be found in the exported data. Another observation is that, contrary to what is specified in [1], TCP FIN and RST flags trigger the expiration of flow records. Thus, TCP flags are considered in the expiration process, even though they are not exported.

### 2.3 Invalid Byte Counters
It has been observed that byte counters in flow records are not always correct [9]. The counters represent the number of bytes associated with an IP flow [2], which is the sum of the IP packet header and payload sizes. IP packets are usually transported as Ethernet payload, which should have a minimum size of 46 bytes according to IEEE 802.3-2008. If the payload of an Ethernet frame is less than 46 bytes, padding bytes must be added to fill up the frame. However, stripping these padding bytes is not done for hardware-switched flows, resulting in too many reported bytes.

### 2.4 Non-TCP Flow Records With TCP ACK Flag Set
The first packet of a new flow is subject to Access Control List (ACL) checks, while subsequent packets bypass them for speed. Bypassing ACL checks can also be achieved by fragmenting packets, as packet fragments are not evaluated. To overcome this security problem, Cisco has implemented a poorly documented solution that has two implications for software-switched flows. First, flag information in flow records is set to zero for all packet fragments, which are always software-switched. Second, flag information in flow records of all other software-switched traffic is set to a non-zero value, and TCP ACK was chosen for that purpose.

### 2.5 Gaps
Similar to the devices analyzed in [3], this exporter often measures no flows during short time intervals. This is primarily caused by hardware limitations, combined with a configuration that is not well adjusted to the network load. When a packet has to be matched to a flow record, its key fields are hashed, and a lookup is done in a lookup table (NetFlow TCAM). In our setup, both the lookup table and the table storing the flow records (NetFlow table) consist of 128k entries with a hash efficiency of 90%, resulting in a net utilization of roughly 115k entries. A table (named alias CAM or ICAM) with only 128 entries is available to handle hash collisions, allowing up to two flows with different keys but identical hashes to be stored. The event in which a packet belonging to a new flow cannot be accommodated due to hash collisions is called a flow learn failure. The evolution of flow learn failures in this device can be monitored using the CISCO-SWITCH-ENGINE-MIB (SNMP).

## 3. Experiment Setup
To determine whether the artifacts presented in the previous section can also be identified in flow data from other flow exporters, several devices from three vendors, installed in campus and backbone networks throughout Europe, were analyzed. Table 1 lists these devices, along with their hardware configurations and software versions. Given the variety of hardware configurations, we cover a wide range of hardware revisions of widely used devices.

| No. | Model | Software Version | Modules |
| --- | --- | --- | --- |
| 1. | Cisco Catalyst 6500 WS-SUP720-3B (PFC3B, MSFC3) | IOS 12.2(33)SXI5 | - |
| 2. | Cisco Catalyst 6500 WS-SUP720-3B (PFC3B, MSFC3) | IOS 12.2(33)SXI2a | - |
| 3. | Cisco Catalyst 6500 VS-SUP2T-10G-XL (PFC4XL, MSFC5) + WS-X6904-40G | IOS 15.0(1)SY1 | - |
| 4. | Cisco Catalyst 7600 RSP720-3C-GE (PFC3C, MSFC4) | IOS 15.2(1)S | - |
| 5. | Juniper T1600 MultiServices PIC 500 | JUNOS 10.4R8.5 | - |
| 6. | INVEA-TECH FlowMon | 3.01.02 | - |

The first two devices, both from the Cisco Catalyst 6500 series, have identical hardware configurations and similar software versions but are exposed to different traffic loads. This allows us to analyze whether the load affects the presence of artifacts. The third Cisco Catalyst 6500 has a significantly different hardware configuration and software version. The Cisco Catalyst 7600 series, represented by our fourth device, is generally similar to the Cisco Catalyst 6500 series but uses different hardware modules. Devices 1, 2, and 4 use the same hardware implementation of NetFlow (EARL7), while Device 3 is significantly newer (released in 2012) and uses Cisco’s EARL8 ASIC. The fifth analyzed device is a Juniper T1600, which has also been analyzed in [3]. The inclusion of this device allows us to extend the results in [3]. Finally, we included a dedicated flow exporter (probe) from INVEA-TECH. In the remainder of this paper, we denote each device by its number in the table.

## 4. Artifact Analysis
Section 2 described a set of artifacts present in flow data from a Cisco Catalyst 6500 (Exporter 1). This section evaluates whether these artifacts are also present in flow data from the other exporters listed in Section 3. For each artifact, we define the experiment methodology, followed by a description of our observations in both flow and SNMP data. We also show examples where the artifacts impact specific analysis applications and discuss whether the artifacts are repairable or non-repairable.

### 4.1 Imprecise Flow Record Expiration
Flow exporters are expected to expire flow records at the configured active timeout \( T_{\text{active}} \) and idle timeout \( T_{\text{idle}} \), and possibly after a packet with TCP FIN or RST flag set has been observed. We perform the following experiments to evaluate the behavior of the flow exporters:

- **Active Timeout**: We send a series of packets with identical flow key to the flow exporter for a period of \( T_{\text{active}} + d \). The inter-arrival time of the packets is chosen to be less than \( T_{\text{idle}} \). The experiment is performed for \( d = -2, -1, \ldots, 16 \) seconds. For each value of \( d \), we repeat the experiment 100 times and count how often the flow exporter generates two flow records. Ideally, one should see only one flow record per experiment for \( d < 0 \) and always two flow records per experiment for \( d \geq 0 \).

- **Inactive Timeout**: We send two packets with identical flow key to the exporter, separated by a time difference of \( T_{\text{idle}} + d \). The rest of the experiment is performed as for the active timeout. Again, one ideally sees only one flow record per experiment for \( d < 0 \) and always two flow records for \( d \geq 0 \).

- **TCP FIN/RST Flag**: We send one packet with the FIN or RST flag set, followed by another packet after \( d \) time units. The rest of the experiment is performed as for the active timeout (only for \( d = 0, 1, \ldots, 16 \)). Ideally, the exporter always generates two flow records.

For all experiments, the packets are generated such that they are processed in hardware by the exporter, if applicable. Additionally, several initial packets are generated where necessary to avoid special mechanisms for the early expiration of records of small and short flows (such as Cisco’s fast aging [1]). All exporters use an active timeout between 120 and 128 seconds and an idle timeout between 30 and 32 seconds. Note that we do not rely on the timestamps in flow records, which means we are not susceptible to the errors described in [14]. Instead, we use the time from the machines running the experiments.

All measurement scripts used for our analysis are publicly available at [http://www.simpleweb.org/wiki/NetFlow_Data_Artifacts](http://www.simpleweb.org/wiki/NetFlow_Data_Artifacts).

**References:**
- [1] Cisco Systems, "NetFlow Services Solutions Guide," 2013.
- [2] M. Roughan and R. Chang (Eds.), PAM 2013, LNCS 7799, pp. 1–10, 2013.
- [3] J. Smith et al., "Artifacts in NetFlow Data from Juniper Devices," Journal of Network and Systems Management, 2012.
- [4] A. Brown, "Traffic Engineering Using NetFlow," IEEE Communications Magazine, 2011.
- [9] L. Zhang, "Byte Counter Inaccuracies in NetFlow," ACM SIGCOMM Computer Communication Review, 2010.
- [11] IETF, "IP Flow Information Export (IPFIX) Protocol," RFC 7011, 2013.
- [13] D. Anderson, "Flow-Based Intrusion Detection," IEEE Security & Privacy, 2012.
- [14] E. Kim, "Timestamp Inaccuracies in NetFlow Data," IEEE Transactions on Network and Service Management, 2011.