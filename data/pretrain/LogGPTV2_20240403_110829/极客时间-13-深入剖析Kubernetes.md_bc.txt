# 把两个字段的值拼装成 SQL，写入 change_master_to.sql.in 文件            echo "CHANGE MASTER TO MASTER_LOG_FILE='${BASH_REMATCH[1]}',\                  MASTER_LOG_POS=${BASH_REMATCH[2]}" > change_master_to.sql.in          fi                    
# 如果 change_master_to.sql.in，就意味着需要做集群初始化工作          if [[ -f change_master_to.sql.in ]]; then            
# 但一定要先等 MySQL 容器启动之后才能进行下一步连接 MySQL 的操作            echo "Waiting for mysqld to be ready (accepting connections)"            until mysql -h 127.0.0.1 -e "SELECT 1"; do sleep 1; done                        echo "Initializing replication from clone position"            
# 将文件 change_master_to.sql.in 改个名字，防止这个 Container 重启的时候，因为又找到了 change_master_to.sql.in，从而重复执行一遍这个初始化流程            mv change_master_to.sql.in change_master_to.sql.orig            
# 使用 change_master_to.sql.orig 的内容，也是就是前面拼装的 SQL，组成一个完整的初始化和启动 Slave 的 SQL 语句            mysql -h 127.0.0.1  需要注意的是：Pod 里的容器并没有先后顺序，所以在执行初始化 SQL> 之前，必须先执行一句 SQL（select 1）来检查一下 MySQL> 服务是否已经可用。当然，上述这些初始化操作完成后，我们还要删除掉前面用到的这些备份信息文件。否则，下次这个容器重启时，就会发现这些文件存在，所以又会重新执行一次数据恢复和集群初始化的操作，这是不对的。同理，change_master_to.sql.in在使用后也要被重命名，以免容器重启时因为发现这个文件存在又执行一遍初始化。**在完成 MySQL 节点的初始化后，这个 sidecar容器的第二个工作，则是启动一个数据传输服务。**具体做法是：sidecar 容器会使用 ncat 命令启动一个工作在 3307端口上的网络发送服务。一旦收到数据传输请求时，sidecar 容器就会调用xtrabackup \--backup 指令备份当前 MySQL的数据，然后把这些备份数据返回给请求者。这就是为什么我们在 InitContainer里定义数据拷贝的时候，访问的是"上一个 MySQL 节点"的 3307 端口。值得一提的是，由于 sidecar 容器和 MySQL 容器同处于一个 Pod里，所以它是直接通过 Localhost 来访问和备份 MySQL容器里的数据的，非常方便。同样地，我在这里举例用的只是一种备份方法而已，你完全可以选择其他自己喜欢的方案。比如，你可以使用innobackupex命令做数据备份和准备，它的使用方法几乎与本文的备份方法一样。至此，我们也就翻越了"第三座大山"，完成了 Slave节点第一次启动前的初始化工作。扳倒了这"三座大山"后，我们终于可以定义 Pod 里的主角，MySQL容器了。有了前面这些定义和初始化工作，MySQL容器本身的定义就非常简单了，如下所示：          ...      