title:Symmetric Encryption in Automatic Analyses for Confidentiality against
Active Adversaries
author:Peeter Laud
Symmetric encryption in automatic analyses for
conﬁdentiality against active adversaries ∗
Peeter Laud
Tartu University and Cybernetica AS
peeter PI:EMAIL
Abstract
In this report we present a technique for static analysis, correct with respect to
complexity-theoretic deﬁnitions of security, of cryptographic protocols for check-
ing whether these protocols satisfy conﬁdentiality properties. The approach is
similar to Abadi and Rogaway — we deﬁne patterns for cryptographic protocols
(they did it for formal expressions), such that the protocol is secure iff the patterns
are. We then statically analyse the patterns, they should be easier to analyse than
the protocols themselves. We consider symmetric encryption as the cryptographic
primitive in protocols. Handling this primitive has so far received comparatively
less attention in approaches striving to unite the formal and computational models
of cryptography.
1 Introduction
A cryptographic protocol is expected to satisfy certain security properties. In this pa-
per, we are interested in conﬁdentiality properties which state that all protocol runs
must look somehow similar — the view of the adversary may not depend on the secret
information that one legitimate protocol party wishes to transmit to some other one.
Protocols have to be veriﬁed about satisfying the required security properties. The
veriﬁcation procedure should produce some kind of proof that the property is satisﬁed.
It is possible to craft these proofs by hand. However, there exist a lot of protocols, so
automatic veriﬁcation methods are necessary. Such methods do indeed exist, there are
tools which take protocol descriptions as inputs and return whether these protocols are
secure or not (and in the case of insecurity, may even show an attack). The methods
do not necessarily always give a deﬁnite answer (the problem of deciding whether the
protocol is secure may be very hard, depending on the deﬁnition of security), they may
also have an option to answer “don’t know”. Even methods that sometimes answer
“don’t know” are useful if they can be expected to give deﬁnite answers for reasonable
protocols reasonable often. Quite often the methods have only two possible answers
— “secure” and “don’t know”. This is called “erring on the safe side” — labelling an
insecure protocol secure may have much more serious consequences than labelling a
secure protocol potentially insecure.
All the existing tools and methods for automatic checking of security properties
have one common shortcoming — they are based on the Dolev-Yao model, i.e. they
∗An abridged version of this paper appears in the proceedings of 2004 IEEE Symposium on Security and
Privacy.
1
assume “perfect” cryptography. In this model, the exchanged messages are modeled
as elements of a certain term algebra, the capabilities of the adversary and the security
deﬁnitions are also given in terms of that algebra.
In real life, and in the computational model, messages are not formal terms, but
are bit-strings. The adversary can be any efﬁcient algorithm. In theory, there is still a
gap between the Dolev-Yao model and the computational model. It is not known how
much of the results obtained for the Dolev-Yao model carry over to the computational
model. Abadi and Rogaway [2] have started bridging that gap by deﬁning patterns for
formal messages (built up from atomic messages, pairing and symmetric encryption),
such that the computational interpretations of the message and its pattern are indistin-
guishable. The pattern of a formal message has simpler structure than the message
itself. One could use that pattern to determine whether something about some secret
atomic message M can be found from a given message — if M does not occur in the
pattern of that message then the interpretation of that message surely does not leak M .
Abadi and J¨urjens [1] have later extended this line of work, basically giving a proto-
col analysis whose results are correct in the computational model if we only consider
passive adversaries.
Our approach is similar. Given a protocol, we construct a number of protocols
with simpler structure, this set of constructed protocols takes the role of the pattern.
We show that if none of the constructed protocols leak M , then the original protocol
does not leak M . A protocol surely does not leak M if it has not been used in the
construction of any messages exchanged during the run of this protocol; we use that
criterion to decide the security of constructed protocols. A preliminary version of the
analysis has been implemented [20].
This paper has the following structure. After reviewing some related work in Sec. 2
and basic deﬁnitions in Sec. 3 we deﬁne what a secure encryption system is in Sec. 4
and what a protocol is in Sec. 5. We give the security deﬁnition of the protocol in Sec. 6.
In Sec. 7 we describe our main contribution — a protocol transformation that makes
the protocols more easily analysable. The correctness of this transformation is based on
the security deﬁnition of symmetric encryption. This contribution gives a completely
automatable method of analysing protocols for the preservation of conﬁdentiality of
secret messages, the results of the analysis are correct in the computational model, even
when considering active adversaries. Last, we describe a very simple and conservative
information ﬂow analysis in Sec. 8 that is nevertheless quite successful in analysing
the transformed protocols. We give an example of the transformation (and subsequent
information ﬂow analysis) in Sec. 9.
2 Related work
The cryptographically sound analysis of the usage of cryptographic primitives is a
rather new research topic. Some work has been done in the area of considering only
passive adversaries by ourselves [23, 24] and before that, by Abadi et al. [2, 1]. These
papers have presented analyses for secure information ﬂow (or something equivalent
to that) for programs written in a certain language containing cryptographic primitives.
Particularly, [1] gave the means to automatically verify, when a protocol preserves con-
ﬁdentiality against passive adversaries. As we already explained before, our work may
be seen as an extension of [2, 1]. In some sense, we are probing here the limits of their
approach.
Backes, Pﬁtzmann et al. [28, 29, 30, 3, 4] have given a framework for faithful ab-
2
straction of cryptographic primitives, in a very general setting, allowing to model all
the details how a cryptographic primitive may or may not operate. This framework
allows them to reason about protocols, considering only the abstract primitives. The
“modelling of all details” is achieved by introducing an honest user into the system,
interacting with both the primitive and the adversary. The abstraction of the primitive
is a good one if there exists a transformation of adversaries, such that no honest user
can distinguish the interaction with the real primitive and any adversary from the in-
teraction with the abstract primitive and the transformed version of that adversary; this
notion is called simulatability. They have not presented any fully automatic analyses,
though. Recently, they have deﬁned a cryptographic library [7] with abstract cryp-
tographic operations and their implementations, and have proved that if a protocol is
secure with respect to abstract semantics then it is also secure with respect to concrete
semantics. The abstract semantics is rather similar to the Dolev-Yao model (although
not exactly the same). In some sense, the adversary attacking the library with respect
to the abstract semantics is even less powerful than the Dolev-Yao adversary, because it
may not be nondeterministic. In our opinion, it would be quite easy to add a Dolev-Yao
analyser, for example Blanchet’s [13], to the framework and show that its results are
cryptographically correct (at least for integrity properties).
Our results are still not subsumed by a combination of [7] and [13]. We consider
a different cryptographic primitive — symmetric encryption, while the library [7] con-
tains public-key encryption and signing. Our main improvement is in the handling of
secret keys. We put no restrictions on it. The library [7] only allows secret keys to
be used for decryption or signing, one may not put them to other expressions (neither
does a recent addendum [6] lift any of these restrictions put on secret decryption keys).
This constraint is nontrivial, removing it means that one has to deal with encryption
cycles [2]. An encryption cycle occurs when the adversary knows the encryption of
one (secret) key under the second, the encryption of the second secret key under the
third, etc., and the encryption of the last secret key under the ﬁrst. The computational
security deﬁnitions do not say anything about them — the setup of these deﬁnitions
does not allow the adversary to construct encryption cycles. We deal with encryption
cycles by replacing the concrete encryption primitive with the abstract primitive one
key at a time.
The determinism of the adversary attacking the library with respect to the abstract
semantics is obviously not a weakness of the results of Backes et al., but it may hamper
the further extension of these results. If it turns out that the Dolev-Yao adversary really
must be non-deterministic to achieve its full power, then non-determinism also has to be
built into the deﬁnitions of simulatability. When concieving simulatable abstractions to
symmetric encryption, one also has to account for the commitment problem that occurs
when the simulator ﬁrst receives a ciphertext and only later the corresponding plaintext
and the key. In [5], Backes and Pﬁtzmann actually give a simulatable abstraction of
symmetric encryption, but under the condition that neither the commitment problem
nor the encryption cycles occur.
Canetti [14] has given a framework similar to Backes, Pﬁtzmann et al. (some details
differ) with the same goals. He also postulates that an analysis similar to the one
presented here may be possible. Several cryptographic primitives have been presented
in this framework, for example commitments [15], secure channels [16] and multiparty
computation [17], although nothing similar to a cryptographic library. Apparently the
focus has been more on constructing protocols than analysing them.
Herzog [21] has given a computational implementation of the Dolev-Yao model
(with public-key encryption as the only cryptographic primitive) that actually respects
3
all the properties of the formal model, i.e. if a protocol is secure in the formal model
then its implementation is secure in the computational model. The downside of this re-
sult is the extremely strong security condition on the encryption — it must be plaintext
aware [9], this property is achievable only in the random oracle model [11] (Recently,
Herzog et al. [22] have given a deﬁnition of plaintext awareness that is sufﬁcient for
their purposes and does not require a random oracle, but needs a third party). In our
work, the security requirements put on the encryption primitive (security against adap-
tive CCA and ciphertext integrity) are achievable under the standard assumptions [10].
Herzog also does not handle encryption cycles, they are simply assumed not to occur.
3 Basic Cryptographic Notions
A function f : N → R is negligible if for all positive polynomials p there exists n0 ∈ N
such that for all n ≥ n0, |f (n)| < 1/p(n).
The cryptographic algorithms work with bit-strings, we denote the set of all bit-
strings with Σ. An algorithm A takes a number of arguments and returns a result.
It runs in probablistic polynomial-time (PPT) if there exists a polynomial p such that
the number of steps made by A is bounded by p(n) where n is the length of the ﬁrst
argument of A. In the following, the ﬁrst argument will always be the security parame-
ter, indicating the desired security of the cryptographic algorithms (more security also
means longer running times). As the deﬁnition of probabilistic polynomial-time spoke
about the length of the ﬁrst argument, the security parameter is given to the algorithms
in unary, denoted by 1n.
A probability distribution over some ﬁnite or countable set X is a function µ : X →
[0, 1], such that Px∈X µ(x) = 1. We denote the set of all probability distributions over
the set X by D(X). We denote picking the value of the random variable x according to
the distribution D ∈ D(X) by x ← D. The notation {|E : C|} denotes the distribution
of the random variable or expression E with the probability space deﬁned by C, here
C is a list of picking values to random variables and of deﬁning variables.
Two families of probability distributions D = {Dn}n∈N and D′ = {D′
n}n∈N,
n ∈ D(Σ), are indistinguishable, denoted D ≈ D′, if for all PPT algo-
where Dn, D′
rithms A, the difference of probabilities
P[b = 1 | x ← Dn, b ← A(1n, x)] − P[b = 1 | x ← D′
n, b ← A(1n, x)]
is a negligible function of n. Here the supposed role of A is to understand whether its
second argument was distributed according to Dn (then A should return 1) or according
to D′
n (then A should return something else). Indistinguishability is the cryptographic
equivalent of sameness. It is an equivalence relation over the set of families of proba-
bility distributions over Σ.
An algorithm A does not have to be fully speciﬁed. Instead, it may make queries
to an oracle. An oracle O is again a probabilistic algorithm. The algorithm A may
use special commands to query O with certain arguments. When queried, O runs and
returns the result back to A. We denote A, making queries to O, with AO. When we
want to stress that A may make queries to an oracle then we write it as A(·). When
we want to stress that O takes an argument, we write A together with O as AO(·). The
notation A(·),(·) means that A may make queries to two different oracles.
The notion of algorithms with oracles allows us to generalise the notion of indis-
tinguishability to algorithms. We say that two algorithms (or oracles; or black boxes)
4
O and O′ are indistinguishable if the difference of probabilities
P[b = 1 | b ← AO(1n,·)(1n)] − P[b = 1 | b ← AO′(1n,·)(1n)]
is negligible in n for all PPT algorithms A. Instead of algorithms we could have also
considered families of probability distributions over algorithms.
4 Security of encryption systems
An encryption system is a triple of algorithms (K, E, D). Here K is the key generation
algorithm, E is the encryption algorithm and D is the decryption algorithm. The algo-
rithms K and E are probabilistic, the algorithm D is deterministic. All algorithms take
the security parameter n (represented in unary — 1n) as an argument. Additionally,
E takes two more arguments — the key and the plaintext. Also, D takes two more
arguments — the key and the ciphertext. Let x ∈ Σ. For all k that may be returned
by K(1n) and for all y that may be returned by E(1n, k, x), the algorithm D(1n, k, y)
must return x.
The previous requirement stated only that D is the inverse of E. We also want
the encryption system to be secure, i.e. we want the ciphertext to not give away any
information about the plaintext. More concretely, we want the encryption system to
satisfy the following properties. If an encryption system satisﬁes these properties, then
we call it secure.
First, (K, E, D) must be secure against adaptive chosen-ciphertext attacks. This
means that no (probabilistic polynomial-time) adversary A(·),(·) that does not query its
second oracle with the values returned by the ﬁrst is unable to distinguish the pair of
black boxes E(1n, k, ·) and D(1n, k, ·) from the pair of black boxes E(1n, k, 0|·|) and
D(1n, k, ·). Here k is distributed according to K(1n) and 0|·| denotes the bit-string of
all zeroes with the same length as the argument to the black box. Note that with such
security deﬁnition, the length of the ciphertext must depend only on the length of the
plaintext.
The preceeding deﬁnition most closely follows that of Bellare et al. [8] (the variant
which they call “real-or-random indistinguishability”), although the notion of security
against CCA already appeared much earlier. The notion of non-adaptive CCA ﬁrst
appeared in [27] and adaptive CCA in [31].
Second, (K, E, D) must have ciphertext integrity. This means that for all proba-
bilistic polynomial-time adversaries A(·),(·) there is only a negligible probability that
during the run of AE(1n ,k,·),D(1n,k,·), the oracle D is queried with a bit-string x that is a
valid ciphertext and was not previously returned by the oracle E. Again, k is distributed
according to K(1n). This deﬁnition comes from [10].
Third, we want the algorithm E to return different bit-string each time it is queried.
In the absence of encryption cycles, this property easily follows from the security
against chosen-ciphertext attacks, but we want this property to hold universally.
The requirement for the encryption to always return different results can be for-
malized as follows. Consider the oracle E(1n, ·, ·). This oracle simply invokes the en-
cryption algorithm but it takes both the plaintext and the key as arguments (in contrast
to the oracle E(1n, k, ·)). We require that no adversary can cause (with non-negligible
probability) the oracle E(1n, ·, ·) to give the same answer to two queries.
An encryption system satisfying the last requirement can be constructed as follows.
Let (K′, E′, D′) be any encryption system secure against CCA and having ciphertext
5
integrity (such systems exist under standard assumptions, see [10]). We construct an
encryption system (K, E, D) as follows.
• K is equal to K′.
• E(1n, k, x) ﬁrst generates a random bit-string r of length n. It then constructs
y ← E′(1n, k, (x, r)) and outputs (y, r).
• D(1n, k, (y, r)) ﬁrst computes z = D′(1n, k, y). If z is not a pair of bit-strings
(x, r′), then it outputs ⊥. Otherwise it checks whether r = r′. If yes, then it
outputs x, otherwise it outputs ⊥.
Obviously the probability that E returns the same answer twice is bounded from above
by q2/2n, where q is the number of queries that the adversary makes to E(1n, ·, ·). It is
negligible, because q is at most polynomial in n.
Theorem 1. (K, E, D) is secure against CCA and has ciphertext integrity.
Proof. First we show that (K, E, D) is secure against CCA. Assume the opposite, then
there exists an adversary A that can distinguish
(E(1n, k, ·), D(1n, k, ·)) from (E(1n, k, 0|·|), D(1n, k, ·))
without passing the output of the ﬁrst black box to the second. We can now very easily
construct an adversary A′ that can distinguish
((E′(1n, k, (·, r)), r), D′(1n, k, ·)) from ((E′(1n, k, (0|·|, r)), r), D′(1n, k, ·))
(1)
without passing the ﬁrst part of the output of the ﬁrst black box to the second. The
adversary A′ works just like A, but additionally it implements the deﬁnition of D in
terms of D′. On the other hand, no adversary can distinguish
((E′(1n, k, (0|·|, r)), r), D′(1n, k, ·)) from ((E′(1n, k, 0|(·,r)|), r), D′(1n, k, ·))
(2)
without passing the ﬁrst part of the output of the ﬁrst black box to the second, this
follows directly from the security of (K′, E′, D′) against CCA. Indeed, (2) corresponds
just to a certain choice of bit-strings submitted to the ﬁrst black box. These bit-strings
are pairs of some bit-string consisting of zeroes only and a random bit-string. As A′
can distinguish (1) but nobody can distinguish (2), A′ can also distinguish
((E′(1n, k, (·, r)), r), D′(1n, k, ·)) from ((E′(1n, k, 0), r), D′(1n, k, ·))
(3)
without passing the ﬁrst part of the output of the ﬁrst black box to the second. But
this violates the security of (K′, E′, D′) against CCA. Indeed, (3) corresponds just to a
certain choice of bit-strings submitted to the ﬁrst black box. These bit-strings are pairs
where the second component is a random bit- string.
Let us show now that (K, E, D) has ciphertext integrity. Assume the opposite,
then there exists an adversary A that in interaction with black boxes E(1n, k, ·) and
D(1n, k, ·) can construct a valid ciphertext that it has not seen before. Then there exists
an adversary A′ (it works like A, but additionally implements the deﬁnitions of E and
D) that in interaction with black boxes E′(1n, k, ·) and D′(1n, k, ·) can construct a pair
(y, r), where y is a valid ciphertext that decrypts to (x, r) under D′(1n, k, ·). Also, A′
has not seen the pair (y, r) before. Now, if y had been an output of E′(1n, k, ·) before,
then the adversary A would have obtained a pair (y, r′) at this point as an output of
E(1n, k, ·). Also, here r 6= r′, as (y, r) was the new valid ciphertext constructed by A.
But it is impossible to obtain (y, r′) from E(1n, k, ·), as it is not a valid ciphertext of
(K, E, D) under the key k. Indeed, D′(1n, k, y) = (x, r) and r 6= r′.
6
5 Syntax and semantics of protocols
A protocol consists of a set of participants. Each participant is basically a program in
a certain programming language. The programs consist of computing certain values
from the ones already known to participants, exchanging messages and checking the
values of received messages. Additionally, there are some long-term secrets that the
participants know and/or share; these long-term secrets make the identiﬁcation of dif-
ferent participants possible and they have been changed before the start of the protocol.
For concreteness, we let a program be a sequence of statements where statements
are deﬁned in Fig. 1. The meaning (and semantics) of most statements should be clear.
P ::= k := gen key
x := encr k(y)
send x
x := constant(b)
|
|
|
|
y := (x1, . . . , xm)
|
y := decr k(x)
| x := receiveℓ
| x := y
i (y)
| x := πm
| x := random
| check(x = y)
k, x, x1, . . . , xm, y are variables from a set Var and b is a function mapping the secu-
rity parameter to some bit-string.
Figure 1: Statements
i (y) takes the i-th component of the m-tuple y. If y is not a m-tuple then the par-
πm
ticipant containing this statement is stuck. Also, decr k(y) gets stuck if y is not a valid
ciphertext encrypted with k, both decr k(y) and encr k(y) get stuck if k is not a valid
key, and check(x = y) gets stuck if the values of x and y differ. The recipient is not
speciﬁed in send x, because all communication is under the control of the adversary.
Executing the statement send x just means handing the value of the variable x over to
the adversary. Similarly, x := receiveℓ assigns to x the value procured by the adver-
sary. Here ℓ denotes the length that the received bit-strings must have. The quantity
ℓ is (a description of) a polynomially bounded function of type N → N, it maps the
security parameter to the expected length. The statement x := constant(b) assigns
to x the constant b, which may also depend on the security parameter. For example, b