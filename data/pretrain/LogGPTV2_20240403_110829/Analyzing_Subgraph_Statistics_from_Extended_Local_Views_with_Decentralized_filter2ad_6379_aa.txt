title:Analyzing Subgraph Statistics from Extended Local Views with Decentralized
Differential Privacy
author:Haipei Sun and
Xiaokui Xiao and
Issa Khalil and
Yin Yang and
Zhan Qin and
Wendy Hui Wang and
Ting Yu
Analyzing Subgraph Statistics from Extended Local Views with
Decentralized Differential Privacy
Haipei Sun
Qatar Computing Research
Institute
Stevens Institute of
Technology
PI:EMAIL
Xiaokui Xiao
National University of
Singapore
PI:EMAIL
Issa Khalil
Qatar Computing Research
Institute
PI:EMAIL
Yin Yang
Hamad Bin Khalifa
University
PI:EMAIL
Zhan Qin
SCST∗,AZFT†, Zhejiang
University
PI:EMAIL
Hui (Wendy) Wang
Stevens Institute of
Technology
PI:EMAIL
Ting Yu
Qatar Computing Research
Institute
PI:EMAIL
ABSTRACT
Many real-world social networks are decentralized in nature, and
the only way to analyze such a network is to collect local views of
the social graph from individual participants. Since local views may
contain sensitive information, it is often desirable to apply differen-
tial privacy in the data collection process, which provides strong
and rigorous privacy guarantees. In many practical situations, the
local view of a participant contains not only her own connections,
but also those of her neighbors, which are private and sensitive for
the neighbors, but not directly so for the participant herself. We call
such information beyond direct connections an extended local view
(ELV), and study two fundamental problems related to ELVs: first,
how do we correctly enforce differential privacy for all participants
in the presence of ELVs? Second, how can the data collector utilize
ELVs to obtain accurate estimates of global graph properties?
This paper points out that when collecting ELVs, it is insufficient
to apply a straightforward adaptation of local differential privacy
(LDP), a commonly used scheme in practice, to protect the privacy
of all network participants. The main problem is that an adversarial
data collector can accumulate private information on a specific
victim from multiple neighbors of the victim; even though the
data collected from each neighbor is perturbed under LDP, their
aggregate can still violate the victim’s privacy. To prevent this
attack, we formulate a novel decentralized differential privacy (DDP)
scheme, which requires that each participant consider not only her
own privacy, but also that of her neighbors involved in her ELV.
The stringent privacy requirement of DDP, however, makes it
challenging to design an effective mechanism for data collection.
∗School of Cyber Science and Technology
†Alibaba-Zhejiang University Joint Institute of Frontier Technologies
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’19, November 11–15, 2019, London, United Kingdom
© 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-6747-9/19/11...$15.00
https://doi.org/10.1145/3319535.3354253
Towards this goal, we design a novel multi-phase framework un-
der DDP that enables an analyst to accurately estimate subgraph
counts, an important property of social graphs. The main idea is
that instead of collecting subgraph counts directly, which would
require excessively noise, the analyst first asks individuals about
their respective minimum noise scale, which is private information
since it depends on the local graph structure, and, thus, must be
performed under DDP. For some types of subgraphs, this process is
applied recursively, i.e., the analyst asks about the necessary noise
to be injected into the private information on the minimum local
noise scale required to protect subgraph counts under DDP. As
case studies, we instantiate the proposed framework for three com-
mon subgraph patterns: triangles, three-hop paths, and k-cliques.
Extensive experiments using real data demonstrate that the pro-
posed scheme leads to accurate estimates of global subgraph counts,
whereas baseline solutions fail to obtain meaningful result utility.
CCS CONCEPTS
• Security and privacy → Data anonymization and sanitiza-
tion.
KEYWORDS
decentralized differential privacy; subgraph statistics; social net-
works
ACM Reference Format:
Haipei Sun, Xiaokui Xiao, Issa Khalil, Yin Yang, Zhan Qin, Hui (Wendy)
Wang, and Ting Yu. 2019. Analyzing Subgraph Statistics from Extended
Local Views with Decentralized Differential Privacy. In 2019 ACM SIGSAC
Conference on Computer and Communications Security (CCS ’19), November
11–15, 2019, London, United Kingdom. ACM, New York, NY, USA, 15 pages.
https://doi.org/10.1145/3319535.3354253
1 INTRODUCTION
In this paper, we consider the problem of analyzing a decentralized
social network, in which the analyst cannot directly obtain infor-
mation on the global structure of the network. Instead, the analyst
needs to communicate with individual participants of the network,
each of which has a limited local view of the whole social graph.
Then, the analyst combines information from different participants
to estimate the global network properties. The setting of decen-
tralized social networks could arise due to a variety of reasons.
First, many social networks are inherently decentralized as there is
no central organizer. For instance, the contact lists in everybody’s
mobile phones could be pieced together to form a giant contacts
social network, though no single entity is aware of the whole net-
work structure. Second, even when there is a centralized entity that
possesses the knowledge of the entire network, that entity may
choose not to share it with the analyst, out of business, legal or
other considerations. For example, an organization operating an
anonymous messaging app could see who messages whom (though
not necessarily message contents). However, it would be difficult
to share such a communication network with outsider analysts.
Collecting information of users’ local views has a clear privacy
implication, as they often reflect sensitive social interactions among
individuals. Any analysis of decentralized social networks thus has
to ensure rigorous protection of privacy. In this paper we consider
private data collection under the differential privacy scheme [11],
in which each individual injects random noise into her private
information, and only releases the perturbed version to the data
collector; the exact private information is never revealed. The scale
of random noise is calibrated according to a pre-defined privacy
budget [11]. A lower privacy budget leads to stronger perturbation
and lower accuracy of the analysis, and vice versa.
In many social networks, a participant is aware of not only
her own connections, but also a broader subgraph in her local
neighborhood. We call such a subgraph an extended local view (ELV).
For instance, with the default setting of Facebook (facebook.com),
a user allows each of her friends to see all her connections. In the
offline world, we also commonly accumulate knowledge on the
relationships between our friends, e.g., when we attend a social
event together. Hence, the ELV of a social network participant often
contains multi-hop neighbors and their connections. Accordingly, the
participant could reveal private information about her neighbors’
connections to the data collector. To our knowledge, this is the first
study that considers this problem: that an individual must protect
not only her own privacy, but also the privacy of her neighbors.
The presence of ELVs poses new challenges for privacy protec-
tion. As pointed out in Section 2, a straightforward application of
local differential privacy (LDP) [13], a popular scheme used in sev-
eral major software systems such as Google Chrome [13] and Apple
iOS / macOS [38], fails to provide sufficient privacy protection in
this case. The deficiency comes from the fact that in LDP, each
individual has her privacy budget locally, which covers her entire
ELV regardless of what specific information from the ELV is col-
lected. Therefore, an adversarial data collector with a target victim
in mind can gather multiple reports of the same private information
(e.g., whether the victim has a politically sensitive connection) from
multiple individuals in the victim’s neighborhood, and combine
them to infer the sensitive connection with high confidence.
We address the above problem with a new privacy preservation
scheme called decentralized differential privacy (DDP). As explained
in Section 2, all participants of the social network share the same
privacy budget, which covers the entire social graph; each individ-
ual, when reporting information about her ELV to the data collector,
must ensure that the released information is sufficiently perturbed
to protect all graph participants, i.e., the data collector cannot infer
the presence or absence of any edge in the graph from all collected
reports. Under DDP, however, it is rather challenging to design
an effective mechanism to obtain high result utility of an analysis,
since the privacy definition is over the global graph, whereas data
come from individual local views.
Towards the goal of accurate social graph analysis under DDP,
we propose a multi-phase framework for subgraph counting, a
fundamental type of graph analyses, under (ϵ, δ)-decentralized
differential privacy (defined in Section 2), where ϵ represents the
total privacy budget for all nodes in the social graph, and δ controls
the probability that every node’s privacy is preserved. The main
idea is that instead of collecting information (i.e., local subgraph
counts) directly, which would require excessive noise to cover worst-
case scenarios, the analyst first asks each node in the network
(corresponding to an individual) about the minimum amount of
noise necessary to protect the node’s local subgraph count under
DDP. In a subsequent phase, the analyst determines the minimum
noise scale for the whole network, and collects subgraph counts
accordingly. Since the noise scale now reflects the true social graph
structure rather than pathological, worst-case scenarios, the end
result is often significantly more accurate than directly collecting
subgraph counts from nodes.
Note that in the first phase, i.e., minimum noise scale computa-
tion, the noise scale reported by a node depends on the structure
of its ELV, which is private information. Therefore, the noise scale
itself must be perturbed to satisfy DDP. In the process of DDP-
compliant collection of noise scale, we can recursively apply the
above framework. In particular, the analyst first asks each node to
report the (second-level) minimum noise scale necessary to perturb
the (first-level) noise scale for subgraph counts. Then, the analyst
aggregates the second-level noise scale information to obtain a tight
bound on the noise for subgraph counts. The second-level noise
scale, in turn, depends on the nodes’ ELV structures, and needs to
be collected under DDP.
We instantiate this framework with several different types of sub-
graph patterns, including triangles, three-hop paths, and k-cliques,
each with its own specific optimizations. Extensive experiments,
using multiple real datasets, confirm that the proposed methods
obtain significantly higher result utility compared to baseline solu-
tions as well as existing ones.
In summary, we make the following contributions in the paper:
• We propose decentralized differential privacy, a new privacy
protection scheme for graph analysis that correctly enforces
differential privacy for all social network participants, in the
presence of extended local views.
• We design a novel multi-phase, recursive framework that
utilizes local graph structures to accurately estimate global
subgraph counts in a decentralized graph, under the (ϵ, δ)-
DDP requirement.
• We instantiate the proposed multi-phase framework on com-
mon subgraph patterns such as triangles, three-hop paths
and k-cliques, and develop pattern-specific optimization for
each case.
• We conduct comprehensive experiments over several real
social graphs. The results show that the proposed technique
consistently outperforms baseline and existing solutions in
terms of result accuracy, by large margins.
2 BACKGROUND AND DECENTRALIZED
DIFFERENTIAL PRIVACY
2.1 Differential Privacy
Since first proposed by Dwork et al. [11], differential privacy quickly
becomes a de facto standard privacy definition in sensitive data anal-
ysis and publishing. Differential privacy was originally designed
for the centralized setting, where a database of private user infor-
mation is managed by a trust party, who answers queries about the
database while preserving each user’s privacy. Formally, we have
the following definition:
Definition 2.1 (Differential privacy). A randomized mechanism
M satisfies (ϵ, δ)-differential privacy, if for any pair of neighboring
datasets D and D′ that differ by one record, and any set of possible
outputs S ⊆ ranдe(M), we have
Pr(M(D) ∈ S) ≤ Pr(M(D
′) ∈ S) · eϵ + δ .
When δ = 0, M satisfies ϵ-differential privacy.
Essentially, differential privacy ensures that from the output of
M, one cannot distinguish whether the input is D or D′ with high
confidence. ϵ is often called the privacy budget, as it controls the
strength of privacy protection offered by differential privacy.
One common technique to achieve differential privacy is the
Laplace mechanism [11], which adds noise following the Laplace
distribution to obfuscate the true outcome of a query. Specifically,
let f : D → Rd be a function, where D is a set of datasets and
d is a positive integer. The sensitivity of f , denoted ∆f , is given
by ∆f = max ∥ f (D) − f (D′) ∥1, over all pairs of neighboring
datasets D and D′. It has been shown that M(D) = f (D) + Y,
where Y ∼ Lap( ∆f
ϵ ), satisfies ϵ-differential privacy [11]. We also
call λ = ∆f
ϵ
Differential privacy is composable: given t randomized mecha-
nisms M1, . . . ,Mt that satisfy (ϵ1, δ1), . . . ,(ϵt , δt)-differential pri-
vacy respectively, the sequential composition of Mi(D) satisfies
the scale of the Laplace noise.
(t
i =1 ϵi ,t
i =1 δi)-differential privacy.
2.2 Decentralized Differential Privacy
Let G = (V , E) be a social graph, where V is the set of participants
and E is the set of edges. For simplicity, we assume G is undirected.
A data analyst, who have no access to the whole graph G, aims
to estimate global statistical properties of G, e.g., the number of
occurrences of a given subgraph such as triangles or cliques. To
do so, the analyst collects information from each participant, i.e.,
nodes in V . Each node v ∈ V has an extended local view (ELV) of G,
denoted Gv, which corresponds to a subgraph of G surrounding v.
Since each node v clearly knows all its direct connections, its
ELV Gv always contains (i) all edges involving v and (ii) all one-hop
neighbors of v, each of which (say, node u) satisfies that there exists
an edge (u, v) ∈ E. In this paper, we focus on a common type of ELV
that also includes two-hop neighbors1, as defined in the following.
Definition 2.2 (Two-Hop Extended Local View). Given a node v ∈
V , its two-hop extended local view (ELV) Gv consists of:
• v’s one-hop neighbors: {u | u ∈ V ∧ (u, v) ∈ E}.
1We leave ELVs beyond two-hop neighborhoods for future work as they are less
common in practice.
Figure 1: Example of two-hop ELVs
• Edges involving v: {e = (v, u) | e ∈ E}.
• v’s two-hop neighbors: {w | ∃u ∈ V ,(u, v) ∈ E ∧(u, w) ∈ E}.
• Edges involving v’s one-hop neighbors: {e = (u, w) | e ∈
E ∧ (u, v) ∈ E}
Figure 1 shows an example with 9 nodes v1, . . . , v9. The ELV of
v1 contains its one-hop neighbors v2 and v3, two-hop neighbors
v4 and v5, as well as the edges between these nodes. Similarly, the
ELV of v8 consists of nodes v5, v7, v9 (one-hop neighbors), v3, v4, v6
(two-hop neighbors), 3 edges between v8 and its one-hop neighbors,
2 edges between its one-hop neighbors, e.g., (v9, v7)), and 4 edges
connecting its one-hop and two-hop neighbors, e.g., (v5, v4).
In our setting, since the analyst needs to collect information
from all social network participants, we assume that the analyst
already knows their identities (i.e., membership in V ), and the
private information is on the connections between them (i.e., E). In
other words, we focus on the edge privacy model [20]. This leads
to the following definition of neighboring graphs:
Definition 2.3 (Neighboring graphs). Two graphs G and G′ are
neighboring graphs if G and G′ only differ in one edge, i.e., G′ can
be obtained by adding or removing one edge from G.
Why local differential privacy is insufficient. Before present-