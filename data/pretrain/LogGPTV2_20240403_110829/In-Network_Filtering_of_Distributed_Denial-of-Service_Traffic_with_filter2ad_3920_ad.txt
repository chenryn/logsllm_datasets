later in this section.
5.3.6 Dropping Pheromone. Multiple updates need to be made after
the ant selects the next offer y based on pxy . It adds offer y to sa
and lavl is updated (line 12). But most importantly, the ant will
update the graph by dropping a constant amount of pheromone,
τc , on the edge between x and y (line 13). This process is repeated
until lavl is empty, thereby completing the ants journey.
An interesting aspect of the ACO framework is the manner in
which pheromone is laid on the graph. As shown in Fig. 6, there are
two ways pheromone can be laid: between each couple of succes-
sively selected offers in a solution, or between all pairs of different
offers selected in a solution. Given a solution S = a, b, c, d, the first
option of laying pheromone emphasizes the order of choosing of-
fers by increasing the desirability of choosing a node b over nodes
c and d, if the ant is currently on node a. On the other hand, the
second option does not emphasize the order of choosing offers, but
rather increases the desirability of choosing any node (b, c, and d)
that is a part of the same solution S that node a belongs to. From
our evaluation of the ACO-based algorithm, we obtained slightly
better results when laying pheromone in the second way. This may
be because the desirability of choosing the next offer should not
be based solely on the previous offer chosen, but on all previous
offers chosen. This is unlike the TSP problem where the next city
on the route should be solely based on the previous city chosen.
After an ant completes its journey, its final solution sa is added
to sl oc , and the next ant begins its journey (lines 14 through 16).
Once all of the ants complete their journeys, the best solution sbst ,
or solution with the highest value, from sl oc is saved to sдl o , or a
list of best solutions at each cycle (lines 17 and 18). The next step
of the algorithm is the most important.
5.3.7 Evaporating Pheromone. Based on the latest best solution
found, each pheromone trail on the graph is updated (line 19 and
20). Pheromone will first be evaporated from each edge in the graph,
but after evaporation, the ant that produced sbst will be able to add
each edge in G begins with an equal amount of pheromone (line 3),
which will be explained in more detail later. Each ant a will build
up a solution, sa , or a set of offers, by traveling through the map
and adding each offer it visits to its solution (lines 4 and 5). If any
individual offer in the graph surpasses the budget, Wb , or collateral
damage threshold, Wc , it is removed from the graph before the algo-
rithm begins. An ant will begin by choosing a offer x in the graph,
uniformly and at random (line 6). It will then add the offer to sa
and the algorithm will update lavl , or the list of all available offers
(lines 7 and 8). In doing so, the algorithm is not only removing
x from lavl , but is also updating the offers that overlap with x so
that attack and legitimate traffic filtered by x does not impact the
overlapping offers’ values and weights, respectively. Additionally,
updating lavl removes all offers that if chosen next would surpass
either the budget or collateral damage threshold.
5.3.5 Probability of Choosing the Next Offer. After the first offer is
chosen, the ant will continue traveling through the graph, adding
to sa (lines 9 through 11). So while lavl is not empty, the ant will
select a next offer y ∈ lavl based on the probability pxy , given by
Equation 5:
pxy =
β
τ α
x y ×u
y
τ α
x z ×u
z ∈lav l
0,
,
β
z
if y ∈ lavl
otherwise
(5)
The probability pxy is the amount of pheromone between x and y, or
τxy , multiplied by the attractiveness of y all divided by the amount
of pheromone between x and every other available offer multiplied
by the attractiveness of every other available offer. The tuning
parameter α helps to control the importance of the pheromone trail
between two offers, while the tuning parameter β helps to control
In-Network Filtering of Distributed Denial-of-Service Traffic with Near-Optimal Rule Selection
ASIA CCS ’20, June 1ś5, 2020, Taipei, Taiwan
more pheromone to the edges that it traveled to create the solution
so as to negate the affects of evaporation. So given an edge (x, y),
the new amount of pheromone between offer x and offer y, or τ new
xy ,
in the graph is equal to (Equation 7):
τ new
xy = h(1 − ρ) × τ old
xy + ρ × ∆τ bst
xy iτmax
τmi n
(7)
where ρ, 0 ≤ ρ ≤ 1, represents the evaporation rate, τ old
xy represents
the amount of pheromone currently between x and y, and ∆τ bst
xy ,
which represents the addition of pheromone to the edges of the
best solution, is equal to (Equation 8):
∆τ bst
xy =(value(sbst ),
0,
if (x, y) ∈ sbst
otherwise
(8)
Therefore, the pheromone trails of the best solution will remain
the same, while trails from the other solutions will be evaporated.
This biases ants from the next cycles to choose solutions that are
similar to the best solutions found in previous cycles. However,
because we do not want the ants to be stuck at a local maxima, we
set a maximum and minimum amount of pheromone for each edge,
τmax and τmin , respectively. This entire process is repeated until
the number of cycles equals Cmax (line 21). After the last cycle is
completed, the algorithm concludes by selecting and returning the
best solution, ssol , among sдl o which is the final solution (line 22).
5.3.8 Approaching Optimality. The ACO-based rule selection algo-
rithm has a clear advantage over the greedy, naive, and dynamic
programming-based algorithms. Unlike the greedy, naive, and dy-
namic programming-based algorithms, the ACO-based algorithm
does not need to eliminate offers in order to handle the overlapping
nature of offers. As Cmax approaches infinity, ssol approaches the
optimal solution. In other words, with enough cycles, and given the
fact that each edge in G will always have a non-zero probability of
being traversed, the ACO-based algorithm is guaranteed to consider
all possible combinations of offers, and thereby, eventually find the
optimal solution (albeit, not in polynomial time).
5.4 Complexity Analysis
Performing a comprehensive complexity analysis of the rule se-
lection algorithm is a difficult task due to the stochastic nature
of the algorithm. However, the rule selection algorithm presented
in this paper is a specialized version of the MAX-MIN Ant Sys-
tem (MMAS) for the all-pairs shortest path problem (APSP) [46].
Sudholt et al. [46] evaluated the running time bounds of the gen-
eral MMASAP S P algorithm to be O(∆ℓℓ∗ +
ℓ
ρ ), given a graph of
n vertices, maximum degree ∆, maximum number of edges ℓ on
any shortest path, ℓ∗ which is equivalent to max{ℓ, ln n}, and the
pheromone evaporation rate ρ. Therefore, for the rule selection al-
gorithm, under a large-scale DDoS attack, the running time bounds
ρ ). Note, ℓ∗ can be replaced by ℓ because under
becomes O(∆ℓ2 +
a large-scale DDoS attack, the number of generated rules will most
likely be relatively large, in turn causing the number of offers to
be relatively large (≥ 100), thereby increasing the probability that
max{ℓ, ln n} = ℓ. In conclusion, the variable with the largest impact
on the rule selection algorithm’s running time is the total number
of offers the defense agent has to select from.
ℓ
5.5 Trust & Security Considerations
The rule selection algorithm relies on the trust between defense
agents and filtering networks (i.e., that the rules belonging to the
offers selected by the defense agent will be deployed by the filtering
networks). From the in-network defense systems we studied, some
either assume that the system is made up of trusted or semi-trusted
networks [10, 12, 16, 22, 28, 34], or rely on a trusted certificate au-
thority (CA) to establish trust among networks [32, 35, 39, 42]. Also,
recent work conducted by Gong et al. [21] attempt to tackle the
problem of lack of verifiable filtering (i.e., the defense agent has no
straightforward way of verifying if a filtering network has correctly
executed its filtering request) by utilizing hardware-based trusted
execution environments (TEEs) to create verifiable in-network fil-
ters. Such work can be leveraged to ensure trust between defense
agents and filtering networks. Because our main focus is not on the
deployment or implementation of a DDoS defense system, but on a
general rule selection algorithm that can benefit most in-network
approaches, we leave the more granular details on security and trust
to the aforementioned in-network defense systems and solutions.
Let’s consider how an adversary may attempt to thwart an in-
network DDoS defense solution that utilizes the rule selection
algorithm. In the case when a DDoS attack targets transit links
instead of a single victim network, as with the Crossfire [27] and
Coremelt [45] attacks, rule generation and selection must be done
in a collaborative manner as to minimize collateral damage. For sim-
plicity, let us assume that a DDoS attack is targeting one bottleneck
link. The network that is directly upstream to the bottleneck link
(the network unaffected by the bottleneck) will be responsible for
generating and selecting rules because, at its vantage point, it can
observe all of the DDoS traffic that needs to be filtered. However, by
not knowing what traffic is legitimate (traffic that is desired by net-
works downstream to the bottleneck link), it may cause collateral
damage to traffic that is destined to other downstream networks,
which is obviously unacceptable. Therefore, the defense agent (or
network generating the rules), must collaborate with the down-
stream networks, who are the true victims of the attack, to help
differentiate attack and legitimate traffic, to generate and select
appropriate rules. Unfortunately, persistent link-flooding attacks
may be made up of attack traffic that is indistinguishable from
legitimate traffic, making it impossible to avoid collateral damage.
Lee et al. [31] present a collaborate defense mechanism for miti-
gating persistent link-flooding attacks, which sends rerouting and
rate-control requests to upstream ASes. This in-network solution
can utilize the offer-based operational model to help incentivize
and guarantee successful collaboration between ASes.
An adversary may also change its behavior to render the rules
selected by the rule selection algorithm useless. For example, an
adversary could launch an attack that comprises of a series of
short-lived bursts, that may only last for a few seconds, and utilize
distinct bots for each burst, thereby making the source IP-based
rules deployed for previous bursts irrelevant and ineffective in
mitigating the current or subsequent bursts. The same applies for
attacks that leverage IP spoofing. In such a cases, the defense agent
can generate rules that filter on the basis of other TCP/IP fields
(e.g., protocol, payload, time-to-live (TTL), Type of Service (ToS),
etc.) or a combination of fields. It is important to reiterate that the
ASIA CCS ’20, June 1ś5, 2020, Taipei, Taiwan
Devkishen Sisodia, Jun Li, and Lei Jiao
 100
)
%
(
y
c
a
c
i
f
f
E
 80
 60
 40
 20
 0
 100
)
%
(
y
c
a
c
i
f
f
E
 80
 60
 40
 20
 0
 100
)
%
(
y
c
a
c
i
f
f
E
 80
 60
 40
 20
 0
optimal
ACO
dynamic
naive
greedy
 0
 10
 20
 30
 40
 50
 60
 70
 80
 90  100
Maximum # of Offers
(a) CAIDA 2007 (real-world)
optimal
ACO
dynamic
naive
greedy
 0
 10
 20
 30
 40
 50
 60
 70
 80
 90  100
Maximum # of Offers
(b) RADb 2016 (real-world)
optimal
ACO
dynamic
naive
greedy
 0
 10
 20
 30
 40
 50
 60
 70
 80
 90  100
Maximum # of Offers
(c) Mirai 2016 (synthetic)
Figure 7: Efficacy of selection algorithms under different
traffic traces.
rule selection algorithm is not dependent on the type of rule that
needs to be selected.
realistic as possible, we test the algorithms on two real-world attack
traces and one synthetic trace.
Note that the tuning parameters of any ACO-based algorithm af-
fects its performance. There is a plethora of research on approaches
to choosing the best values for the tuning parameters. However,
since this is not a focus for our work, we leverage existing re-
search on ACO applied to the multidimensional knapsack problem
to choose the values of our parameters [17]. It is very likely that
the values we chose for our parameters are not optimal and can be
improved. This is an aspect of our work that we will look into in
the future.
6.2 Experimental Setup
We built a simulation framework consisting of: 1) the ACO-based
algorithm along with the greedy, naive, dynamic programming-
based, and branch-and-bound-based rule selection algorithms for
comparison, 2) a real-world AS-level Internet topology, 3) three