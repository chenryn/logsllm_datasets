xeo - [0]ed
kprobe:vfs_read,
kprobe:vfs_readv,
kprobeivfs_vrite,
kprobe:vfs_wr1tev
$file = [struct file *)azg0,
$node = $file->f_inode->i_mode,
 [Btype[Snode s Oxfooo] , func, conm] = count |1
END
clear (8type) 
The BEGIN program sets up a hash table (@Ptype) for inode file modes to strings, which are then
looked up in the kprobes for the VFS functions.
Two months after writing this tool, I was developing socket I/O tools and noticed that I had not
written a VFS tool to expose the file modes from include/linux/fs.h (DT_FIFO, DT_CHR, etc.).
I developed this tool to do it (dropping the *DT_* prefix):
#1/usx/1ocal/bin/bpCtrace
#include 
BEGIX
printf(*Tracing VFs reads and xrltes... Hit Ctz1-C to end.\n*):
 / / fron include/1inux/fs,h:
type2str[0] - *(ec30*;
Btype2str[1] = *g1Fo*;
Btype2atr[2] - *CHR*;
type2str[4] - *o1R*;
x18 = [9]a1szed8
Btype2str[8] - *pso*;
Btype2atr[10] - *LNK;
---
## Page 351
314
Chapter S File Systems
Btype2str [12] - *sock*;
Btype2str[14] = *KHT;
kprobe:vfs_read,
kprobe:vfs_readv,
kprobeivfs_vrite,
kprobe:vfs_vr1tev
sfile =[atruct file *) azg0;
$type =($file=>f_inode=>i_mode >> 12) ≤ 15;
 [etype2str [Stype]。func,  conn]=count [) :
END
clear (8type2str) 
When I went to add it to this chapter, I discovered I had accidentally written a second version of
filetype(8), this time using a different header file for file type lookups. I’ve included the source
here as a lesson that sometimes there is more than one way to write these tools.
8.3.16 cachestat
cachestat(8)2 is a BCC tool that shows page cache hit and miss statistics. This can be used to
check the hit ratio and efficiency of the page cache, and run while investigating system and
application tuning for feedback on cache performance. For example, from a 36-CPU production
Hadoop instance:
cachestat
HITS
YISSES
DIRTIES HITRATIO
BUFFERS_MB
CACHED_MB
53401
2755
20953
95.095
14
90223
49599
4098
21460
92.37名
14
90230
16601
2689
61329
86.065
14
90381
151 97
2477
58028
85. 99%
1. 4
90522
18169
4402
51421
80.50%
14
90 656
57604
3064
22117
94.95§
14
90 693
76559
3777
3128
95 .305
14
90 692
49044
3621
26570
93.12
14
90743
[..-]
w8s on vacstion in Yulars, near Uluru, in the outback of Australia [87]. Since it's so tied to kemel intemals, it contsins 8
block comment in the header to describe it ss a sand castle: a new kemel version can esily break it and wash it m
Allan McAleavy ported it to BCC on 6-Nov-2015.
---
## Page 352
8.3 BPF Tools
315
This output shows a hit ratio often exceeding 90%. Tuning the system and application to bring
this 90%6 close to 100% can result in very large performance wins (much larger than the 10%
difference in hit ratio), as the application more often runs from memory without waiting on
disk I/O.
Large-scale cloud databases such as Cassandra, Elasticsearch, and PostgreSQL often make heavy
usage of the page cache to ensure that the hot dataset is always live in memory. This means that
one of the most important questions in provisioning datastores is if the working set fits into the
provisioned memory capacity. Nefix teams managing stateful services use this cachestat(8) tool
to help answer this question and inform decisions such as what data compression algorithms to
use and if adding more memory to a cluster would actually help performance.
A couple of simple examples can better explain the cachestat(8) output. Here is an idle system,
where a one-Gbyte file is created. The T option is now used to show a timestamp column:
+ cachestat -T
TIME
HITS
MISSES
DIRTIES HITBATIO
BUFFERS_MB
CACHED_NB
21 :06 : 47
0
0
0.009
6
191
21 :06 : 48
0
12088 9
0.00%
T.
663
21:06: 49
0
141167
0.009
6
1215
21:06: 50
795
0
1100.00%
9
1215
21 : 06 : 51
Q
0.009
9
1215
The DIRTIES column shows pages being written to the page cache (they are “dirty°), and the
CACHED_MB column increases by 1024 Mbytes: the size of the newly created file.
This file is then flushed to disk and dropped from the page cache (this drops all pages from the
page cache):
1syne
+ echo 3 > /proc/sys/vm/drop_caches
Now the file is read twice. This time a cachestat(8) interval of 10 seconds is usedl:
+ cachestat -T 10
7IME
HITS
HISSES
DIRTIES HITRATIO
BUFFERS_MB
CACHED_NB
21 : 08 : 58
771
1100.009
B
190
21 :09 : 08
9E055
53975
1. 6
sL6°LE
6
400
21 :09 : 18
15
68544
2
0 .029
9
668
21:09:28
798
65632
1.201
924
21 : 09 : 38
5
67424
0.019
1187
21 :09 : 48
3757
11329
24.905
1232
21:09: 58
2082
0
1100.009
9
1232
21 :10 : 08
268421
11
12
100.001
6
1232
21:10:18
0100.009
9
1232
21 :10 : 19
78.4
D
100.005
1232
---
## Page 353
316
6 Chapter 8 File Systems
The file is read between 21:09:08 and 21:09:48, seen by the high rate of MISSES, a 1ow HITRATIO,
and the increase in the page cache size in CACHED_MB by 1024 Mbytes. At 21:10:08 the file was
read the second time, now hitting entirely from the page cache (100%).
cachestat(8) works by using kprobes to instrument these kernel functions:
mark_page_accessed(): For measuring cache accesses
 mark_buffer_dirtyO): For measuring cache writes
• add_to_page_cache_Iru(): For measuring page additions
 account_page_dirtied(): For measuring page dirties
While this tool provides crucial insight for the page cache hit ratio, it is also tied to kernel
implementation details via these kprobes and will need maintenance to work on different kernel
versions. Its best use may be simply to show that that such a tool is possible.2?
These page cache functions can be very frequent: they can be called millions of times a second.
The overhead for this tool for extreme workloads can exceed 30%, though for normal workloads it
will be much less. You should test in a lab environment and quantify before production use.
Command line usage:
cachestat[options][1nterval[count]]
There is a T option to include the timestamp on the output
There is another BCC tool, cachetop(8),α that prints the cachestat(8) statistics by proces in a
top(1)-style display using the curses library.
8.3.17writeback
writeback(8) is a bpftrace tool that shows the operation of page cache write-back: when pages
are scanned, when dirty pages are flushed to disk, the type of write-back event, and the duration.
For example, on a 36-CPU system:
+ vriteback.bt
Attaching 4 pzobes...
Tracing vriteback... Hit Ctrl-C to end
1=≤520512>00
TIME
DEVICE
PAGES
REASON
0
periodic
0.013
03:42 : 55
253:1
4.0
pexiodic
0.167
03:43:00 253:1
0
periodic
0 .005
26 When I presented cachestat(8) in my LSPMM keynote, the mm engineers stressed that it will break, and later
explsined some of the challenges in doing this corectly for future kermels (thanks, Mel Gorman). Some of us, like at
Netfix, hve it working well enough for our kemels and workiads. But to become a robust tool for everyone, I think
either (A) someone needs to spend a few weeks studying the kemel source, trying different workloads, and working with
the mm engineers to truly solve it; or perhaps even bettet, (B) add /proc statistics so this can switch to being 8 counter
27 0rigin: cschetop(8) was reated by Emmanuel Bretelle on 1.3-Jul-2016,
based tool.
28 0rigin: I created it for bpftrace on 14-Sep-201.8.
---
## Page 354
8.3 BPF Tools
317
03:43: 01 253:1
11268
background
6.112
03:43: 01
253:1
11266
backgzound
03 :43 : 01
253:1
11314
background
22.209
03:43 : 02
253 :1
11266
background
20.698
03 :43 : 02
253:1
11266
background
7.421
03:43: 02
253 :1
11266
background
11.382
03:43 : 02
253:1
11266
background
6. 954
03:43: 02
253 :1
11266
background
8.749
03 :43 : 02
253:1
11266
backgrot
I1.C
14.518
0:E=E0
253 :1
92885
sync
64.655
03:43 : 04
253:1
syn.c
0.004
03 :43: 04
253:1
0
sync
0.002
03 :43 : 09
253:1
0
periodie
0 .012
03:43 : 14
253:1
0
pexiodic
0.016
[...]
This output begins by showing a periodic write-back every five seconds. These were not
writing many pages (0, 40, 0). Then there was a burst of background write-backs, writing tens
of thousands of pages, and taking between 6 and 22 milliseconds for each write-back. This
is asynchronous page flushing for when the system is running low on free memory If the 
timestamps were correlated with application performance problems seen by other monitoring
tools (e.g., cloud-wide performance monitoring), this would be a clue that the application
problem was caused by file system write-back. The behavior of the write-back flushing is tunable
(e.g-, sysctl(8) and vm.dlirty_writeback_centisecs). A sync write-back occurred at 3:43:04, writing
38,836 pages in 64 milliseconds.
The source to writeback(8) is:
#1/usx/local/bin/bpftrace
BEGIX
printf(*Tracing vriteback... Bit CtrlC to end.\n") 
printf(*9s -Bs Bs -16s sn*, *rIME*, *DEVICE*, *PAGEs*,
*REASON*,*sa*) ;
// see /sys/kernel/debug/tracing/events/xriteback/writeback_start/foznat
Breason[0] - *background*;
Breason[1] = *vascan*;
Breason[2] = *sync”;
Breason[3] = *periodic"
Breason[4] - *laptop_tiner*;
r_xou9s“sxouesx]。 =[s]u0see2g
Breason.[6] - *fs_free_space*;
Breason[7] = *forker_Chread";
---
## Page 355
318
Chapter S File Systems
tracepoint:vriteback:vri teback_start
8start[args->sb_dev] - nsecss
rsebedxusb_dev]/
nepqssb_dev] - args->nr_pages,
time I"B:H:s *)
printf (*4=8s 1=Bd 16s d.03d)n*, axgs=>nane, Spages,
reason |args=>reason] , $lat / 1000, $1at $ 10001;
delete (8start[$sb_dev]) 