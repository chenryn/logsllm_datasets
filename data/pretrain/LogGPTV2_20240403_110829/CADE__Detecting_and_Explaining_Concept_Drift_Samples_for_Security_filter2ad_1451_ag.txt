2010.
[61] Jost Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, and Mar-
tin Riedmiller. Striving for simplicity: The all convolutional net. In
Proc. of ICLR, 2015.
[62] Mukund Sundararajan, Ankur Taly, and Qiqi Yan. Axiomatic attribution
for deep networks. In Proc. of ICML, 2017.
[63] Romain Thomas. Lief - library to instrument executable formats.
https://lief.quarkslab.com/, April 2017.
2342    30th USENIX Security Symposium
USENIX Association
[64] Robert Tibshirani and Guenther Walther. Cluster validation by pre-
diction strength. Journal of Computational and Graphical Statistics,
2005.
[65] Daniele Ucci, Leonardo Aniello, and Roberto Baldoni. Survey of
machine learning techniques for malware analysis. Computers &
Security, 2019.
[66] Laurens van der Maaten and Geoffrey Hinton. Visualizing data using
t-SNE. Journal of Machine Learning Research, 2008.
[67] Alexander Warnecke, Daniel Arp, Christian Wressnegger, and Konrad
Rieck. Don’t paint it black: White-box explanations for deep learning
in computer security. In Proc. of Euro S&P, 2020.
[68] Fengguo Wei, Yuping Li, Sankardas Roy, Xinming Ou, and Wu Zhou.
Deep ground truth analysis of current android malware. In Proc. of
DIMVA, 2017.
[69] Xiaojun Xu, Chang Liu, Qian Feng, Heng Yin, Le Song, and Dawn
Song. Neural network-based graph embedding for cross-platform
binary code similarity detection. In Proc. of CCS, 2017.
[70] Rowland Yu. Ginmaster: a case study in android malware. In Virus
bulletin conference, 2013.
[71] Xinyang Zhang, Ningfei Wang, Shouling Ji, Hua Shen, and Ting Wang.
Interpretable deep learning under ﬁre. In Proc. of USENIX Security,
2020.
[72] Yaqin Zhou, Shangqing Liu, Jingkai Siow, Xiaoning Du, and Yang Liu.
Devign: Effective vulnerability identiﬁcation by learning comprehen-
sive program semantics via graph neural networks. In Proc. of NeurIPS,
2019.
[73] Jingbo Zhu, Huizhen Wang, Eduard Hovy, and Matthew Ma.
Conﬁdence-based stopping criteria for active learning for data annota-
tion. ACM Trans. Speech Lang. Process., 2010.
[74] Arthur Zimek, Erich Schubert, and Hans-Peter Kriegel. A survey on
unsupervised outlier detection in high-dimensional numerical data.
Statistical Analysis and Data Mining, 2012.
Appendix A: Boundary-based Explanation
To perform the boundary-based explanation, we ﬁrst need to
approximate the detection boundary of the drift detection mod-
ule with a parametric function. We need to run approximation
because the true boundary of the drift detector is threshold-
based, which is not parametric. Speciﬁcally, we used an MLP
classiﬁer to perform the approximation in the latent space.
Due to the limited number of drifting samples, to approximate
the decision boundary, we ﬁrst synthesized more drifting sam-
ples by adding Gaussian noise to the latent representations of
the detected drifting samples. Then, we trained an MLP g(zzz)
to classify the latent representations of the in-distribution sam-
ples from the drifting samples. After obtaining the approxima-
tion model, we combined it with the contrastive autoencoder
f to construct a supervised approximation of the detection
module (i.e. g( f (xxx))). We conducted the approximation in
the latent space rather than the input space for two reasons.
First, training an MLP in a low dimensional space is more
efﬁcient than in a high dimensional space. Second, directly
utilizing the original contrastive autoencoder enables a higher
ﬁdelity of the supervised approximation than approximating
the autoencoder with another network. Using the supervised
approximation, we then applied the perturbation-based expla-
nation method [22] to explain each drifting sample. Similar to
CADE, this method also outputs a mask indicating the feature
importance. We ranked the mmmi and pinpointed the features
with high mmmi as the important ones.
Appendix B: CADE Implementation Details
CADE. We implemented CADE based on the Keras [26]
package with Tensorﬂow [1] as the backend. The hyper-
parameters of CADE and the baselines are conﬁgured as the
following. As for CADE, we set the encoder as an MLP with
the architecture of 1340-512-128-32-7 for the Drebin dataset
(the ﬁrst dimension could vary when using different families
as the unseen family) and 83-64-32-16-3 for the IDS2018
dataset. The activation function for each hidden layer is the
ReLU function. We applied the Adam optimizer with the
learning rate of 0.0001 and epochs of 250 to train both net-
works. The batch size for Drebin and IDS2018 are 32 and
256, respectively. As for the hyper-parameters introduced by
the contrastive loss in Eqn. (1), we set λ = 0.1 and m = 10.
We applied the widely used empirical value for the MAD
threshold and coefﬁcient: TMAD = 3.5 and b = 1.4826. For
the hyper-parameters introduced by the explanation loss in
Eqn. (2), we set λ1 = 1e− 3 and used the Adam optimizer
with the learning rate of 0.01 to solve the optimization func-
tion. The training epoch is set as 250.
Drift Detection Baselines.
The vanilla autoencoder base-
line was implemented as a variant of our system without using
contrastive learning. We also implemented a multi-class ver-
sion of Transcend based on the source code provided by the
authors. The hyper-parameters of the vanilla AE baseline
are almost the same with CADE except for the MAD thresh-
old TMAD = 0. We tried TMAD = 3.5 for this method, which
resulted in zero precision and recall. The reason is that the dis-
tance in vanilla AE’s latent space is not optimized to compare
different samples and thus MAD lost its effectiveness.
For Transcend, we used an MLP with the architecture of
1340-100-30-7 for the Drebin dataset and 83-30-3 for the
IDS2018 dataset to train a multi-class classiﬁer. Then we
used the negative output probability −p as the non-conformity
measure of Transcend. We set the threshold of the credibility
p-value as 1.0. That is, a testing sample is marked as a drifting
sample if its p-value is lower than 1.0.
Explanation Baselines. We implemented the boundary-
based explanation method and the random selection as de-
scribed in the main text. For COIN, we used the source code
released by the authors as the implementation.5 The net-
work architectures of the approximation function g in the
boundary-based explanation are 7-15-2 and 3-15-2 for Drebin
and IDS2018, respectively. The optimizer, batch size, and
number of epochs are the same as those used in our sys-
5https://github.com/ninghaohello/
Contextual-Outlier-Interpreter
USENIX Association
30th USENIX Security Symposium    2343
Parameter
m = 5
m = 10
m = 15
m = 20
λ = 1
λ = 0.1
λ = 0.01
λ = 0.001
TMAD = 2.0
TMAD = 2.5
TMAD = 3.0
TMAD = 3.5
0.95 ± 0.05
0.96 ± 0.03
0.91 ± 0.06
0.93 ± 0.03
0.95 ± 0.03
0.96 ± 0.03
0.94 ± 0.03
0.89 ± 0.10
0.96 ± 0.03
0.96 ± 0.03
0.96 ± 0.03
0.96 ± 0.03
Norm. Effort
0.97 ± 0.05
1.00 ± 0.09
1.00 ± 0.14
1.06 ± 0.13
1.05 ± 0.11
1.00 ± 0.09
1.05 ± 0.09
1.19 ± 0.33
1.00 ± 0.09
1.00 ± 0.09
1.00 ± 0.09
1.00 ± 0.09
Drebin (Avg±Std)
F1
IDS2018 (Avg±Std)
F1
0.72 ± 0.39
0.96 ± 0.06
0.77 ± 0.33
0.98 ± 0.02
0.94 ± 0.09
0.96 ± 0.06
0.67 ± 0.47
0.95 ± 0.05
0.94 ± 0.09
0.95 ± 0.07
0.95 ± 0.07
0.96 ± 0.06
Norm. Effort
0.72 ± 0.39
0.95 ± 0.07
0.76 ± 0.34
1.02 ± 0.02
1.00 ± 0.00
0.95 ± 0.07
0.71 ± 0.42
0.93 ± 0.08
0.99 ± 0.02
0.97 ± 0.04
0.96 ± 0.05
0.95 ± 0.07
Table 9: Sensitivity test of three hyper-parameters on detecting
drifting samples. For each evaluation metric, we report the
mean value and the standard deviation across all the settings.
λ1
Drebin-FakeDoc
distance (Avg ± Std)
distance (Avg ± Std)
IDS2018-Inﬁltration
2.669 ± 3.343
2.403 ± 3.266
2.349 ± 3.238
2.322 ± 3.240
0.119 ± 0.058
0.085 ± 0.039
0.065 ± 0.035
0.064 ± 0.027
0.1
0.01
0.001
0.0001
Table 10: Sensitivity test on the hyper-parameter λ1 of ex-
plaining a drifting sample. “Ratio” means the percentage of
perturbed samples that cross the decision boundary.
Ratio
91.34%
96.85%
97.64%
99.21%
Ratio
1.99%
1.36%
1.41%
1.69%
tem. The hyper-parameters of solving the explanation masks
(i.e. optimizer and epoch) are also the same as our system.
Finally, we used the default choices of the hyper-parameters
from the authors’ code of COIN.
The original implementation of COIN provided by the au-
thors can be very slow when the dataset has a large number
of samples and outliers. For each detected outlier, COIN runs
KMeans clustering on its 10% of nearest neighbors to get its
contexts. To determine the best number of clusters (K), COIN
iterates K from 1 to a pre-deﬁned threshold and adopts the
measure of prediction strength [64] to assess the choice of
K. Prediction strength can be computationally expensive as
it requires pair-wise comparison on the labels predicted by
KMeans. To make it feasible, on the large IDS2018 dataset,
we only choose 1% of nearest neighbors and ﬁx the number of
clusters as a value between 1 and 4 for each outlier. Also, the
LinearSVM classiﬁer does not converge on about 6% of out-
liers even we set max iterations as 200,000. We report the best
average result on the converged cases obtained from COIN.
For the Drebin dataset, we keep all the hyper-parameters the
same as the original code.
Appendix C: Hyper-parameter Sensitivity
In Section 3.2, the loss function of contrastive autoencoder
has two hyper-parameters: λ and m. Here, we evaluate the
sensitivity of CADE’s performance to these hyper-parameters.
Our experiment methodology is to ﬁx one parameter and
swap the other one. We ﬁx λ as 0.1 and set m as 5, 10, 15,
Sampling Rate
F1 score
10% 15% 20% 25% 30%
0.97
0.96
0.98
0.98
0.98
Table 11: Sampling rate of IDS2018 dataset vs. F1 score of
CADE.
20. As shown in Table 9, CADE achieves a high F1 score on
the Drebin dataset when m = 5 and m = 10, but has some
minor degradation on m = 15 and m = 20. The detection
performance on the IDS2018 dataset is good when m is set to
a higher number e.g., m = 20. Recall that m is the threshold
to control the upper-bound distance that will be considered. A
dissimilar pair can contribute to the loss function only when
their distance is within the radius of m. As such, m can be set
to be higher if the dataset is more dispersed and noisy.
To test the effect of λ, we ﬁx m = 10 as before, and set λ as
1, 0.1, 0.01, and 0.001. λ controls the weight of the contrastive
loss. We can observe from Table 9 that if λ is too small, it
hurts CADE’s performance. The results conﬁrm the importance
of the contrastive loss.
In Algorithm 1, we set the threshold of MAD TMAD as 3.5,
which is an empirical value [40]. We also tested other com-
monly used MAD thresholds of 2, 2.5, 3. A smaller MAD
threshold will detect more samples as potential drifting sam-
ples, but it may not affect the ranking procedure. As shown in
Table 9, the average results of the detected drifting samples
keep the same as TMAD = 3.5 on Drebin and minor ﬂuctu-
ations on the IDS2018 dataset, indicating TMAD has subtle
effects on detecting drifting samples.
To assess the sensitivity of the hyper-parameter λ1 in the
loss function (Eqn.( 2)) of distance-based explanation, we
set λ1 as 0.1, 0.01, 0.001, and 0.0001. As shown in Table 10,
we notice that smaller λ1 can have a slightly smaller average
distance to the nearest centroid on both Drebin and IDS2018
datasets. Also, a smaller λ1 can increase the ratio of perturbed
samples that cross the decision boundary from 91.34% to
99.21% on Drebin-FakeDoc. While for IDS-Inﬁltration, the
ratio could vary on different values of λ1. But overall, both
evaluation metrics do not have signiﬁcant differences among
different values of λ1.
Appendix D: IDS2018 Additional Results
In our experiment, we only sampled 10% of the network traf-
ﬁc from the IDS2018 dataset. Trafﬁc sampling is a common
approach in intrusion detection, which allows us to compre-
hensively test different experimental setups. We also ﬁnd that
including more trafﬁc only increases the computational over-
head and has a negligible inﬂuence upon the performance. As
shown in Table 11, as the sampling rate increases, CADE’s F1
scores remain consistently high.
2344    30th USENIX Security Symposium
USENIX Association