title:Be Sensitive to Your Errors: Chaining Neyman-Pearson Criteria for
Automated Malware Classification
author:Guanhua Yan
Be Sensitive to Your Errors: Chaining Neyman-Pearson
Criteria for Automated Malware Classiﬁcation
Department of Computer Science
Binghamton University, State University of New York
Guanhua Yan
Binghamton, NY, U.S.A.
PI:EMAIL
ABSTRACT
Thwarting the severe threat posed by the voluminous mal-
ware variants demands eﬀective, yet eﬃcient, techniques for
malware classiﬁcation. Although machine learning oﬀers a
promising approach to automating malware classiﬁcation,
existing methods are oblivious of the costs associated with
the diﬀerent types of errors in malware classiﬁcation, i.e.,
false positive errors and false negative errors. Such treat-
ment adversely aﬀects later applications of per-family mal-
ware analysis such as trend analysis. Against this back-
drop, we propose a uniﬁed cost-sensitive framework for au-
tomated malware classiﬁcation. This framework enforces the
Neyman-Pearson criterion, which aims to maximize the de-
tection rate under the constraint that the false positive rate
should be no greater than a certain threshold. We develop
a novel scheme to chain multiple Neyman-Pearson criteria
on heterogeneous malware features, some of which may have
missing values. Using a large malware dataset with labeled
samples belonging to 12 families, we show that our method
oﬀers great ﬂexibility in controlling diﬀerent types of errors
involved in malware classiﬁcation and thus provides a valu-
able tool for malware defense.
Categories and Subject Descriptors
K.6.5 [Management of Computing and Information
Systems]: Security and protection
Keywords
Malware, classiﬁcation, Neyman-Pearson criterion
1.
INTRODUCTION
The Internet is now inundated with numerous malware
which are responsible for a wide range of malicious activi-
ties such as email spamming, botnets, and identity theft. As
evidenced by the Symantec reports showing as many as 286
million malware variants were created in 2010 and 400 mil-
lion in 2011 [35], we must equip ourselves with eﬀective, yet
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
ASIA CCS’15, April 14–17, 2015, Singapore..
Copyright c(cid:13) 2015 ACM 978-1-4503-3245-3/15/04 ...$15.00.
http://dx.doi.org/10.1145/2714576.2714578.
scalable, solutions to mitigating the ever-growing malware
threats. Traditional approaches based on malware signa-
tures produced from AV (Anti-Virus) software companies
have been shown fruitless in defending against current mal-
ware threats; some reports even go as far as claiming that
the existing AV solutions are “dead” [11, 2].
In some previous eﬀorts, machine learning has been of-
fered as an alternative approach to classifying the vast vol-
ume of malware attacks [30, 14, 25, 27, 21, 32, 26, 1, 38]).
Albeit promising, a few technical obstacles still remain as
we apply machine learning to automated malware classiﬁca-
tion in practice. First, the numbers of malware variants be-
longing to diﬀerent malware families are highly skewed [28].
Severe class imbalance across malware families poses signiﬁ-
cant challenges to controlling the accuracy of malware classi-
ﬁcation, as for a rare family with only a few instances, simply
ﬂagging every instance as negative would achieve high clas-
siﬁcation accuracy. Second, heterogeneous malware features
can be extracted from malware programs [40]. Ideally, we
would want to combine various types of features to achieve
highly accurate malware classiﬁcation. Existence of missing
feature values hinders the deployment of standard machine
learning techniques in a straightforward manner. Last but
not least, malware samples that are accurately labeled are
not easy to obtain, as it is diﬃcult, if not impossible, to
manually label a large number of malware variants, and it is
hard to overcome the inconsistency among classiﬁcation re-
sults by multiple AV software to ﬁnd unbiased labeled sam-
ples by consensus [16, 18]. Hence, in many cases, we possess
only a small number of malware samples that are conﬁdently
labeled along with a large number of unlabeled ones.
In this work we propose a uniﬁed malware classiﬁcation
framework that overcomes these challenges. This framework
is built on an ensemble of cost-sensitive malware classiﬁers,
each of which is trained individually on a type of features
extracted from malware programs. Hence, even if we cannot
collect one speciﬁc type of features from a malware program,
the framework can still rely on other types of features to in-
fer the family it should belong to. The cost-sensitive nature
of individual classiﬁers oﬀers us the ﬂexibility of imposing
diﬀerent penalties on false positive and false negative er-
rors. Taking advantage of how much penalties we assign to
each type of classiﬁcation errors, we enforce the Neyman-
Pearson criterion [31, 4], which aims to maximize the de-
tection rate of the ensemble classiﬁer while ensuring that
the false positive rate should be no greater than a certain
threshold. When only a small number of malware samples
are labeled, we leverage the structural information inherent
121in a large amount of unlabeled data to train high-quality
classiﬁers based on semi-supervised learning.
In a nutshell, our contributions made in this work can
be summarized as follows. (1) We design and implement
a uniﬁed cost-sensitive framework for automated malware
classiﬁcation, which overcomes various challenges we face
in classifying large numbers of malware variants into their
corresponding families in practice, such as missing feature
values, class imbalance, and diﬃculty in obtaining accu-
rately labeled samples. (2) To combine classiﬁcation results
from multiple cost-sensitive classiﬁers, we extend a well-
established concept in hypothesis testing, Neyman-Pearson
criterion [31, 4], and propose the chain Neyman-Pearson cri-
terion, which can be used to ensure that the false positive
rate of the ensemble classiﬁer should be no greater than a
certain threshold while maximizing its detection rate. (3)
We apply the dynamic programming technique to search op-
timal conﬁgurations that satisfy the chain Neyman-Pearson
criterion for individual classiﬁers, each trained on a speciﬁc
type of malware features. (4) Using a malware dataset con-
taining tens of thousands of malware instances belonging to
12 families, we demonstrate that our method oﬀers great
ﬂexibility in controlling diﬀerent types of errors involved in
automated malware classiﬁcation.
The rest of the paper is structured as follows. Section 2
presents the challenges in malware classiﬁcation. Section 3
introduces a uniﬁed malware classiﬁcation framework. Sec-
tion 4 discusses how to train individual classiﬁers and Sec-
tion 5 how to build an ensemble classiﬁer. Section 6 shows
the evaluation results. Section 7 discusses related work.
2. REALITY CHECK
Our study is based on a malware dataset from Oﬀensive
Computing [22] with 526,179 samples. While processing this
dataset, we encounter the following three major challenges.
2.1 Labeled and unlabeled data
In order to know the family each malware variant belongs
to, we upload its MD5 to the VirusTotal website [37] and
obtain the detection results from 43 AV software. Among
all these results, we consider only the detection results from
the ﬁve major AV software, McAfee, Kaspersky, Microsoft,
ESET (NOD32), and Symantec. Next, we extract the mal-
ware family information from the detection result from each
AV software. For instance, if Microsoft detects a malware
program as Trojan:Win32/Vundo.BY, we then identify its
family name as Vundo. Thereafter, we use the majority rule
to label a malware instance: if four out of ﬁve AV software
classify it as the same malware family, we assume it belong
to that family. Using this method, we are able to label only
26,848 instances, which belong to 12 distinct malware fam-
ilies, Bagle, Bifrose, Hupigon, Koobface, Ldpinch, Lmir,
Rbot, Sdbot, Swizzor, Vundo, Zbot, and Zlob. Conventional
wisdom is that we train a classiﬁer for each family based on
only labeled data. The large amount of unlabeled data how-
ever contain rich structural information that can be further
exploited to improve classiﬁcation accuracy.
2.2 Class imbalance issue
Figure 1 shows the number of instances labeled in each
family. The Full case includes both packed and unpacked
instances, and the Unpacked case has only unpacked in-
stances. The plot clearly shows high imbalance among dif-
ferent malware families. For instance, for the Unpacked case,
the Hupigon family has 31.2 times as many instances as the
Bagle family has. The class imbalance issue complicates
the search for an optimal classiﬁer [10]. For instance, con-
sider a widely used measure, classiﬁcation accuracy, which
is deﬁned to be the fraction of correctly classiﬁed instances.
When we train an optimal classiﬁer that maximizes classi-
ﬁcation accuracy from a dataset with only a few positive
samples, a dummy classiﬁer that simply classiﬁes every in-
stance as negative may stand out as the best one.
2.3 Missing feature values
We extract the following types of features from each mal-
ware program in our dataset. (1) Hexdump 2-gram: We
use utility hexdump to produce byte sequences from each
malware program, and a hexdump 2-gram feature is con-
structed by obtaining the frequencies of any two consecu-
tive bytes in the program. (2) Objdump 1-gram: We
use utility objdump to disassemble each malware program,
and treat the concatenation of the preﬁx and the opcode
in each instruction as a feature. The value of a feature is
the frequency which which it appears in the program. (3)
PE header: We extract information from the PE header of
each malware program with utility pefile. We extract two
types of features from PE headers. PE-num: numerical fea-
tures extracted from PE headers, PE-bool: boolean features
extracted from PE headers, such as bits in characteristic
ﬁelds, whether a DLL is imported, and whether a system
call in a DLL ﬁle is imported. (4) PIN trace: We exe-
cute each malware program in a controlled environment for
ﬁve minutes and use Pin [12], a dynamic binary instrumen-
tation tool, to dump the execution traces. We also extract
two types of features from PIN traces. PIN 2-gram: the fre-
quency of the ordered combination of opcodes in every two
consecutive instructions, and PIN SysCall: the number of
times that a system call has been invoked.
Figure 2 depicts the fraction of unpacked malware sam-
ples in each family that we are able to extract feature val-
ues successfully. Not surprisingly, we are able to extract
hexdump 2-gram and PE header (including both PE-num and
PE-bool) features successfully from every malware program.
However, for those objdump 1-gram features, we cannot ex-
tract features from a signiﬁcant portion of malware instances
because objdump crashes during the disassembly process.
This occurs similarly to Pin when we try to extract PIN
trace (including both PIN 2-gram and PIN SysCall) fea-
tures. Interestingly, there is no strong correlation between
missing objdump 1-gram and PIN trace feature values: for
some malware families (e.g., Koobface, Zbot and Zlob), we
are able to extract objdump 1-gram features from the ma-
jority of malware instances but can only extract PIN trace
features from a small portion of malware instances.
3. A UNIFIED MALWARE CLASSIFICATION
FRAMEWORK
A uniﬁed malware classiﬁcation framework is illustrated
in Figure 3. It works on a malware database that contains
not only labeled malware programs but also a large number
of unlabeled malware instances. Labeled malware samples
can come from those identiﬁed manually by malware foren-
sic analysts, or from consensus among multiple AV software.
Due to the voluminous malware variants, many malware in-
stances will remain as unlabeled in the malware database.
Rather than ignoring these unlabeled samples, our frame-
122Figure 1: Imbalanced number of
instances per family
Figure 2: Fraction of instances
with feature values per family
Figure 3: A uniﬁed malware clas-
siﬁcation framework
work exploits the structural information inherent among
these unlabeled samples when training malware classiﬁers.
We extract various types of features from malware pro-
grams. There have been a large literature dedicated to dis-
covering powerful features for malware detection or classiﬁ-
cation. In principle, our framework can integrate all these
diﬀerent types of features together, and provide a high-
quality malware classiﬁer based on their collective eﬀorts.
For each type of features extracted from malware programs,
we may need to perform feature selection before training a
classiﬁer on them, because for some types of malware fea-
tures, the number of features is so large that a classiﬁer
trained on all of them does not perform eﬃciently in prac-
tice, and for some classiﬁers, having more features does not
necessarily mean that its performance is better than that
when only a small number of features are used [40].
Once we have decided what features to use for each feature
type, we use these features collected from both labeled and
unlabeled malware instances to train a malware classiﬁer. In
parlance of machine learning, this process is semi-supervised
learning. Semi-supervised learning contrasts with super-
vised learning, which relies on only labeled data when train-
ing a classiﬁer. When labeled data are costly to obtain, the
performance of supervised learning usually suﬀers because
the distribution of labeled data used in the training dataset
may not be representative of the true distribution of the new
instances coming later. By contrast, semi-supervised learn-
ing exploits the structural information inherent in the large
amount of unlabeled data to approximate better the true
distribution of the instances which we will need to classify
later. A fundamental assumption behind semi-supervised
learning is that if two instances appear in the same clus-
ter, they are likely to belong to the same class [6]. Based
on this assumption, a semi-supervised classiﬁer either prop-
agates labeling information from labeled instances to those
unlabeled ones belonging to the same cluster, or searches for
classiﬁcation boundaries through only sparse areas.
Another key component of our framework is the cost sen-
sitiveness of the malware classiﬁer we train on each type of
features. When searching for an optimal classiﬁer for a spe-
ciﬁc type of malware features, we apply the Neyman-Pearson
criterion, which tries to maximize the detection rate under
the constraint that the false positive rate must be no greater
than a certain threshold [31, 4]. To enforce the Neyman-
Pearson criterion, we use a cost-sensitive classiﬁer with ad-
justable penalty weights on diﬀerent types of classiﬁcation
errors. We search for an optimal setting from the parameter
space of these weights, and use cross-validation techniques
to ensure that the Neyman-Pearson criterion should be met.
With multiple individual classiﬁers, each of them may
have its own opinion when we apply it on a new malware
variant. As we may have missing features for a feature type,
we assume that its corresponding classiﬁer classiﬁes it as
negative. This naturally leads to a classiﬁer ensemble based
on the ‘OR’ rule:
if any classiﬁer decides that a new vari-
ant should belong to a speciﬁc malware family, the ensemble
of classiﬁers believes it is a variant of that family; only all
classiﬁers decide it is a negative sample does the ensemble
classiﬁer classiﬁes it as negative. Such an ‘OR’ decision rule
can be easily translated into a sequence of malware classi-
ﬁers, each of which is trained on a speciﬁc type of malware
features.
If any of the classiﬁers decides a new sample is
positive, the ensemble classiﬁer terminates by ﬂagging it as
positive; only if the malware variant passes the tests of all
individual classiﬁers can it be ﬂagged as negative.
We further propose the chain Neyman-Pearson criterion,
which is applicable to multiple classiﬁers that work in tan-
dem. Under the chain Neyman-Pearson criterion, a dynamic
programming method is used to spread the overall false pos-
itive rate allowed for the ensemble classiﬁer over all the in-
dividual cost-sensitive classiﬁers as the constraints on their
false positive rates.
We now theoretically analyze the ensemble classiﬁer based
on the ‘OR’ rule. Regarding the ‘OR’ rule that combines
multiple classiﬁers, we have the following proposition about
its Vapnik-Chervonenkis (VC) dimension, which measures
the capacity of a classiﬁer [36]:
Proposition 1. Consider a hypothesis space H over do-
main X = {0, 1}n, which is a set of {0, 1}-valued functions.
For each h ∈ H and x = (x1, x2, ..., xn) ∈ X, we have
h(x) =(cid:81)n
i=1 xi. The VC-dimension of H is then 2.
Proof. Consider two points in X, x0 = 0 and x1 (cid:54)= 0.
Clearly, any h ∈ H can shatter the two points. However, for
any three distinct points in X, there must be at least two
of them each containing at least one non-zero element. No
hypothesis in H can shatter these two points.
We further have the following about the VC-dimension of
the classiﬁer ensemble combined with the ‘OR’ rule.
Proposition 2. Consider a set of k binary classiﬁers, whose
VC-dimensions are summed up to d. The VC-dimension of
the classiﬁer ensemble combined with the ‘OR’ rule is upper
bounded by (d + 2) log2[3e(k + 1)2].
Proof. The k binary classiﬁers combined with the ‘OR’
rule can be deemed as a feed-forward architecture with k + 1
computation nodes. The sum of all the computation nodes
in this architecture is d+2 (note that the node corresponding
to the ‘OR’ rule has a VC of 2, as seen from Proposition 1).
According to Theorem 1 in [3], we have the number of realiz-
able functions with m points, denoted by ∆(m), as follows:
∆(m) ≤ ((k + 1)em/(d + 2))d+2, for m ≥ d + 2.
(1)