be also applied to backdoor detection. For example,
to detect hidden malware time-bombs, Crandall et al.
[13] implemented a temporal search technique that runs
virtual machines at slightly different rates of time.
To explore malware code space, Wilhelm et al. [36]
used a forced-execution approach to force a driver to run
different paths. Moser et al. [23] and Brumley et al. [9]
independently implemented similar symbolic-execution-
based malware analysis systems to explore different
paths in malware. Comparetti et al. [12] proposed a
graph-match-based solution to determine the malicious
functionalities in malware samples.
These techniques can be used to detect certain type-
s of backdoors. However, there are also many anti-
analysis techniques, such as code obfuscation [11], [22],
[25] and code encryption [28], [38]. Instead of detecting
backdoors, we focus on nullifying the effects of a
backdoor in RCA login frameworks.
Backdoor prevention. Wysopal
an
overview on different backdoor mechanisms and ma-
licious indicators, and suggested using static analysis to
identify backdoor indicators such as static variables that
look like hashes or cryptographic keys, to prevent the
pre-owned special credentials.
[29] gave
Source code review cannot detect the backdoors that
are instrumented at
the binary level. Wheeler [35]
proposed a diverse double-compiling technique that
compares the untrusted binary with the one generated by
another trusted compiler. In addition, syntax-based [15]
or semantics-based [16] binary comparison techniques
can also be used to statically identify the equivalence of
binaries. The deviation detection method in [8] can dy-
namically identify the equivalence of execution traces.
These studies could alleviate the backdoor problems
caused by malicious compilers.
Hardware backdoor.
In recent years, hardware
backdoors became a hot topic [18], [31], [33], [34]. To
defend against malicious hardware, Hicks et al. [18]
proposed BlueChip, a hybrid hardware/software ap-
proach. BlueChip identiﬁes unused circuits during the
veriﬁcation tests, and uses trusted software to emulate
the unused circuits. Thus, even if the unused circuits
contain backdoor logic, they cannot be activated. This
method could be applied to isolate certain types of
backdoors in software. For example, if some pieces
of code in a login module are not
tested, we can
separate them from the login module. However, there
are many ﬂexible backdoor implementation methods.
Simple replacing unused code in login modules cannot
address the issue.
Waksman et al. [33] proposed a method to make the
backdoor intractable to attackers by scrambling the in-
puts. Due to the input data randomization, backdoors are
hardly controlled by attackers. Preventing the untrusted
login modules from receiving expected inputs is very
useful to defend backdoors. However, in login protocols,
many data, such as the challenge values, responses, can-
not be scrambled. Thus the method cannot be directly
used in login protocols.
IX. CONCLUSIONS
Response-computable authentication (RCA) is a two
party authentication model widely adopted by many lo-
gin systems. Unfortunately, these systems have suffered
from the threats of backdoors. A malicious developer
could leave backdoors in source code, through mali-
cious compilers, by planting delicate vulnerabilities, or
even through weak cryptography algorithms. Traditional
technologies have difﬁculty in completely eliminating
backdoors from login systems.
In this paper, we propose a framework for RCA
systems to ensure that no usable backdoor exists. And
we prove theorems about the upper bound of poten-
tial backdoor usability. Our framework splits the R-
CA model into one response-computation function and
some assistant logic. These assistant logic are fairly
simple and can be checked manually. The response-
computation function is usually complicated and may
have backdoors. We put this function into NaPu, a Na-
tive pure-function-enforcing sandbox. NaPu can prevent
an attacker from triggering backdoors via vulnerability
and ensure the response computing function pure. We
prove theorems to give the upper bound of backdoor
usability in a login module, which forms a theoretical
basis of our testing methods. Through the testing, either
we can detect the possible backdoor or we can ensure
the backdoor cannot be used by its creator. The idea of
enforcing functional purity could be used for multiple
applications beyond login modules, such as e-voting
machines [14], [27], [30]. How to extend the pure
function characteristic to enhance program security is
our future work.
We ported several popular login modules into this
framework and veriﬁed that
they are backdoor-free.
We also detected some real backdoors in login module
via probability testing. Our performance measurement
showed acceptable overhead. The result of automatic
standard tests shows that the framework can be applied
to real login systems to ensure no practically usable
backdoor.
ACKNOWLEDGMENTS
We are grateful to David Wagner, Shuo Chen, Prateek
Saxena, and the anonymous reviewers for their insight-
15
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:58 UTC from IEEE Xplore.  Restrictions apply. 
ful comments and suggestions. This research was sup-
ported in part by National Natural Science Foundation
of China (Grant No. 61003216), National University of
Singapore under NUS Young Investigator Award R-252-
000-378-101, and the Ofﬁce of Naval Research under
MURI Grant No. N000140911081.
REFERENCES
[1] NaCl project:Disabling sources of non-determinism for
guest code. http://code.google.com/p/nativeclient/wiki/
DeterministicExecution.
[2] ProFTPD Backdoor Unauthorized Access Vulnerability.
http://www.securityfocus.com/bid/45150.
[3] RSA SecurID Two-factor Authentication. http://www.
rsa.com/node.aspx?id=1156.
[4] TOTP: Time-based One-time Password Algorithm. http:
//tools.ietf.org/html/draft-mraihi-totp-timebased-08.
[5] Back Door
in Commercial Shopping Cart.
http://web.nvd.nist.gov/view/vuln/detail?vulnId=
CVE-2000-252.
2000.
[6] S. M. Bellovin and M. Merritt. Encrypted key exchange:
Password-based protocols secure against dictionary at-
tacks.
In IEEE SYMPOSIUM ON RESEARCH IN SE-
CURITY AND PRIVACY, pages 72–84, 1992.
[7] D. Brumley and D. Boneh. Remote timing attacks are
practical.
In Proceedings of the 12th conference on
USENIX Security Symposium - Volume 12, pages 1–1,
Berkeley, CA, USA, 2003. USENIX Association.
[8] D. Brumley, J. Caballero, Z. Liang, J. Newsome, and
D. Song. Towards automatic discovery of deviations
in binary implementations with applications to error
detection and ﬁngerprint generation. In Proceedings of
USENIX Security Symposium, Aug. 2007.
[9] D. Brumley, C. Hartwig, Z. Liang,
J. Newsome,
P. Poosankam, D. Song, and H. Yin. Automatical-
ly identifying trigger-based behavior in malware.
In
Book chapter in ”Botnet Analysis and Defense”, Editors
Wenke Lee et. al., pages 65–88. Springer US, 2008.
[10] C. Castelluccia, M. Durmuth, and D. Perito. Adaptive
password-strength meters from markov models.
In
Proceeding of the 19th Annual Network and Distributed
System Security Symposium (NDSS’12), 2012.
[11] C. Collberg, C. Thomborson, and D. Low. Manufac-
turing cheap, resilient, and stealthy opaque constructs.
In POPL ’98: Proceedings of the 25th ACM SIGPLAN-
SIGACT symposium on Principles of programming lan-
guages, 1998.
[12] P. M. Comparetti, G. Salvaneschi, E. Kirda, C. Kol-
bitsch, C. Kruegel, and S. Zanero. Identifying Dormant
Functionality in Malware Programs.
In 2010 IEEE
Symposium on Security and Privacy, pages 61–76, 2010.
[13] J. R. Crandall, G. Wassermann, D. A. S. de Oliveira,
Z. Su, S. F. Wu, and F. T. Chong. Temporal search:
detecting hidden malware timebombs with virtual ma-
chines.
In Proceedings of the 12th international con-
ference on Architectural support for programming lan-
guages and operating systems, ASPLOS-XII, pages 25–
36, New York, NY, USA, 2006. ACM.
[14] M. Finifter, A. Mettler, N. Sastry, and D. Wagner.
Veriﬁable functional purity in java. Proceedings of the
15th ACM conference on Computer and communications
security CCS 08, page 161, 2008.
[15] H. Flake. Structural comparison of executable objects.
In Proceedings of Detection of Intrusions and Malware
& Vulnerability Assessment (DIMVA), 2004.
[16] D. Gao, M. K. Reiter, and D. Song. BinHunt: Automati-
cally Finding Semantic Differences in Binary Programs.
In Proceedings of the International Conference on Infor-
mation and Communications Security, pages 238–255.
Springer-Verlag, 2008.
[17] J. Gonzalez and V. Paxson. Enhancing Network Intrusion
Detection with Integrated Sampling and Filtering.
In
Recent Advances in Intrusion Detection (RAID), volume
4219 of Lecture Notes in Computer Science, pages 272–
289. Springer Berlin / Heidelberg, 2006.
[18] M. Hicks, M. Finnicum, S. T. King, M. M. K. Martin,
and J. M. Smith. Overcoming an Untrusted Computing
Base: Detecting and Removing Malicious Hardware Au-
tomatically. In 2010 IEEE Symposium on Security and
Privacy (SP), pages 159–172, 2010.
[19] L. Ho and A. Atkins. Security of software outsourcing
in military and government agencies. In Proceedings of
IADIS International Conference on WWW/Internet 2005,
pages 347–355, 2005.
[20] S.-J. Horng, M.-Y. Su, and J.-G. Tsai. A dynamic back-
door detection system based on dynamic link libraries.
International Journal of Business and Systems Research,
2(3):244–257, 2008.
[21] J. Klensin, R. Catoe, and P. Krumviede.
IMAP/POP
AUTHorize Extension for Simple Challenge/Response.
RFC 2195, Internet Engineering Task Force, Sept. 1997.
[22] C. Linn and S. Debray. Obfuscation of executable code
to improve resistance to static disassembly. In CCS ’03:
Proceedings of the 10th ACM conference on Computer
and communications security, 2003.
[23] A. Moser, C. Kruegel, and E. Kirda. Exploring Multiple
Execution Paths for Malware Analysis. In SP ’07. IEEE
Symposium on Security and Privacy, pages 231–245,
2007.
[24] D. M’Raihi, M. Bellare, F. Hoornaert, D. Naccache,
and O. Ranen. HOTP: An HMAC-Based One-Time
Password Algorithm. RFC 4226, Internet Engineering
Task Force, Dec. 2005.
[25] I. V. Popov, S. K. Debray, and G. R. Andrews. Binary
obfuscation using signals.
In SS’07: Proceedings of
16th USENIX Security Symposium on USENIX Security
Symposium, Berkeley, CA, USA, 2007.
[26] A. Salomaa. Public-Key Cryptography. Springer, 1996.
ISBN 3-540-61356-0.
[27] N. Sastry, T. Kohno, and D. Wagner. Designing voting
machines for veriﬁcation.
In Proceedings of the 15th
conference on USENIX Security Symposium - Volume
15, Berkeley, CA, USA, 2006. USENIX Association.
[28] M. Sharif, A. Lanzi, J. Gifﬁn, and W. Lee.
Impeding
malware analysis using conditional code obfuscation. In
Proceedings of the 15th Annual Network and Distributed
System Security Symposium, San Diego, CA, February
2008.
[29] T. Shields and C. Wysopal. Detecting Certiﬁed Pre-
owned Software. In BlackHat-Europe, 2009.
[30] C. Sturton, S. Jha, S. A. Seshia, and D. Wagner. On
voting machine design for veriﬁcation and testability. In
Proceedings of the 16th ACM conference on Computer
and communications security, CCS ’09, pages 463–476,
New York, NY, USA, 2009. ACM.
16
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:58 UTC from IEEE Xplore.  Restrictions apply. 
chosen by this schema, the attacker can login success-
fully with a probability
P (S(cid:2), id(cid:2), cha(cid:2)) = P (S(cid:2)(id(cid:2), cha(cid:2))==f (pw, cha(cid:2))) .
{res1, res2, ..., resk}
be
the
Let
image
of
f (pw, cha(cid:2)), and M is the count of all possible
pws. Besides,
there are Mi passwords which may
cause f (pw, cha(cid:2)) equals to resi, where i = 1, 2, ..., k
and M1 + M2 + ... + Mk = M. Then, there are two
cases:
Case 1. The client-supplied response S(cid:2)(id(cid:2), cha(cid:2))
does not exist in the set {res1, res2, ..., resk}, i.e. there
is no i such that resi = S(cid:2)(id(cid:2), cha(cid:2)). As a result,
P (S(cid:2), id(cid:2), cha(cid:2)) = P (S(cid:2)(id(cid:2), cha(cid:2))==f (pw, cha(cid:2)))
Case 2. The client-supplied response S(cid:2)(id(cid:2), cha(cid:2))
exists in the set {res1, res2, ..., resk}, i.e. there is an
i such that resi = S(cid:2)(id(cid:2), cha(cid:2)). Besides, according to
the Premise 1, pw is random. As a result,
P (S(cid:2), id(cid:2), cha(cid:2)) = P (S(cid:2)(id(cid:2), cha(cid:2))==f (pw, cha(cid:2)))
= 0
≤ P max
col
= P (resi==f (pw, cha(cid:2)))
= Mi
M
= P cha
col
≤ max{M1,M2,...,Mk}
≤ P max
col
M
(cid:2)
In a word, the following statement holds:
P (S(cid:2), id(cid:2), cha(cid:2)) = P (S(cid:2)(id(cid:2), cha(cid:2))==f (pw, cha(cid:2)))
≤ P max
for any S(cid:2), id(cid:2) and cha(cid:2).
col
(2)
As a result, the Equation 1 and 2 contradict. So,
the assumption cannot be true, i.e. there is no backdoor
such that Pbackdoor > P max
. And thus, the theorem is
correct.
col
[31] C. Sturton, D. Wagner, and S. T. King. Defeating UCI:
Building Stealthy and Malicious Hardware. In 32th IEEE
Symposium on Security and Privacy, 2011.
[32] K. Thompson. Reﬂections on trusting trust. Communi-
cations of the ACM, 27(8):761–763, 1984.
[33] A. Waksman. Silencing Hardware Backdoors. In 32nd
IEEE Symposium on Security and Privacy, 2011.
[34] A. Waksman and S. Sethumadhavan. Tamper Evident
Microprocessors. In IEEE Symposium on Security and
Privacy, pages 173–188, 2010.
[35] D. A. Wheeler. Countering Trusting Trust
through
Diverse Double-Compiling.
In 21st Annual Comput-
er Security Applications Conference, Tucson, Arizona,
2005.
[36] J. Wilhelm and T. cker Chiueh. A forced sampled
In
execution approach to kernel rootkit identiﬁcation.
10th International Symposium on Recent Advances in
Intrusion Detection (RAID’07), pages 219–235, 2007.
[37] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth,
T. Ormandy, S. Okasaka, N. Narula, and N. Fullagar.
Native Client: A Sandbox for Portable, Untrusted x86
Native Code. In 30th IEEE Symposium on Security and
Privacy, pages 79–93, 2009.
[38] A. Young and M. Yung. Cryptovirology: Extortion-
based security threats and countermeasures. In SP ’96:
Proceedings of the 1996 IEEE Symposium on Security
and Privacy, page 129, Washington, DC, USA, 1996.
IEEE Computer Society.
[39] Y. Zhang and V. Paxson. Detecting backdoors.
In
Proceedings of the 9th conference on USENIX Security
Symposium - Volume 9, page 12, Denver, Colorado,
2000. USENIX Association.
APPENDIX
col
P max
Theorem 1 (Usability of backdoors in our frame-
work) Given any RCA implemented in our framework,
suppose its computation function is f () whose collision
probability is P max
, then any T2b-backdoor attacker-
s can only login successfully with a probability not
greater than the collision probability, i.e. Pbackdoor ≤
.
Proof: Assume there is a backdoor (S0, Pbackdoor)
in the RCA implemented in our framework such that
Pbackdoor > P max
, i.e. there is a client-side response
generation schema S0 such that the generated response
matches the expected response with a probability higher
than P max
col
col
.
More speciﬁcally, the backdoor attacker can choose
a special (or any) id0 and wait for a special (or any)
cha0, then sends back S0(id0, cha0) to the server for
further comparison. Finally, the server-side comparison
passes with a probability higher than P max
. In other
words, the following statement holds:
col
col
Pbackdoor = P (S0(id0, cha0)==f (pw, cha0))
> P max
col
(1)
for a certain S0, id0 and cha0.
On the other hand, for any response generation
schema S(cid:2) used by the attacker, for any id(cid:2) and cha(cid:2)
17
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:58 UTC from IEEE Xplore.  Restrictions apply.