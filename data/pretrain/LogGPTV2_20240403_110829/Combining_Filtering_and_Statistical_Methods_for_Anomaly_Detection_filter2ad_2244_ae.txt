341
00.050.10.150.200.20.40.60.81FPR1−FNRwletglrbasicvshift00.050.10.150.200.20.40.60.81FPR1−FNRwletglrbasicvshiftParameter Duration Volume
possible
values
Minutes ∆
Hours
Days
Forever
1 ≤ δ ≤ 2
δ = 1.1 or 0.9
δ ∼ 0
Num (Src,Dst)
(1, 1)
(N, 1)
(2, 2)
all ODs on 1 link
Shape
Ramp
Exponential
Square
Step
Table 1: Anomaly description parameters. ∆ is an additive factor, δ is a multiplicative factor.
domly between 5 min and 2 hours. The volume of the
original OD ﬂow added on top of the anomalous OD pair
ranged between 40% and 140%. The number of OD pairs
involved was between 1 and 7 OD pairs per anomaly, and
those selected were randomly chosen. The performance of
our four schemes for these 500 scenarios is presented in
Figure 3(b). For this data, the basic and GLR performed
best and equivalently. It is interesting to note that the rank-
ing of the four schemes, in terms of the ROC curve areas
is not entirely consistent between the Abilene data and the
synthetic ones. The main difference occurs with the GLR
method that does not perform very well for the Abilene data
but does for the synthetic data. The reason may lie in the
statistical properties of the anomalies themselves. In our
synthetic generator the way we add extra volume is equiva-
lent to changing the mean of the OD ﬂow for the duration of
the anomaly. Since the GLR method is focused on detect-
ing changes in the mean, it does well. It is possible that the
anomalies in the Abilene data experience variance changes
as well as mean changes. If this were true, it would explain
why the vshift method is second best for the Abilene data.
We leave the exploration of the statistical properties of the
anomalous moments for future work.
When using marked traces we should be careful. There
is always the risk that an anomaly is undetected or a nor-
mal behavior is marked as an anomaly. We conducted a
visual inspection to remove any false positive(s) detected
using the algorithms presented in [12]. We did not check
for the false negatives. Consider the examples in Figures
4(a) and 4(b). On the top plots we show how a single OD
pair evolves in time. The dashed line is our kalman ﬁl-
ter estimation of this OD ﬂow. We can see how it tracks
the changes in the OD ﬂow. On the bottom plots we show
the residual process for each of these two example ﬂows.
We also include the markings produced by the labeling al-
gorithm in [12]. Each box greater than 0 means that an
anomaly was marked at this time. In ﬁgure 4(a) our resid-
ual process indicates that there were two anomalies, while
the labeling procedure only marks one of them. According
to our methodology above, we would thus label the ﬁrst
spike as a false positive since we use the labeling method
to represent the “truth”. This anomaly could easily have
been a legitimate one. A similar situation arises for our
second example ﬂow. For these two examples, a simple
(a) OD pair #19
(b) OD pair #32
Figure 4: Example of the Innovation of an OD pair
visual inspection of the upper curve is enough to indicate
that these events should have been True Positives since the
two anomalies per ﬂow indicate the beginning and ending
of the anomaly. Because our algorithm may be able to de-
tect events that the labeling algorithm of [12] does not, yet
we use this algorithm to compute the FP ratio, it means that
our computed false positive rate should be considered as an
upper bound instead of the true value of the false positive
ratio.
5.2 Detection Time
One of the critical performance aspects of any anomaly de-
tection algorithm is the speed with which it can detect the
anomaly. The onset of attacks and/or anomalies on the In-
ternet today is extremely rapid thus creating real-time re-
quirements for anomaly detection algorithms that are chal-
lenging. Few, if any, of the previous work we have seen,
evaluate their algorithms in terms of detection time. We
deﬁne detection lag as the time at which we detect a true
anomaly minus the time the anomaly began. Since the un-
derlying time unit of our trafﬁc matrix data is 5 minutes,
each additional lag corresponds to an increment of 5 min-
utes. (Note that our methods are not intrinsically tied to a 5
minute time interval.)
Each anomaly in the two sets (Abilene and synthetic)
generates one sample detection lag value. We ensemble all
these values and summarize them using a cumulative distri-
bution. The results for the Abilene data are shown in Fig-
342
Internet Measurement Conference 2005 
USENIX Association
1
−150−100−5005010015000.050.10.150.2Bandwidth[MB/s]EstimationReal−150−100−5005010015000.20.40.60.8TimeInnovationAnomalyInnovation−150−100−5005010015000.050.10.150.20.25Bandwidth[MB/s]EstimationReal−150−100−5005010015000.51TimeInnovationAnomalyInnovation(a) Abilene
(b) Synthetic
(a) FNR
(b) FPR
Figure 5: CDF of the detection lag using Abilene and Syn-
thetic traces
Figure 6: FNR and FPR as a function of the anomaly size
ure 5(a) while the results for the synthetic data are shown
in Figure 5(b). In both cases, the basic method and GLR
methods exhibit excellent detection times. In the case of
Abilene data, the GLR method detected 90% of the anoma-
lies with no lag, while the basic method detected 95% of
the anomalies with no lag. For the synthetic data, the GLR
curve is not visible because it lies on the line where the
y-axis is 1 (underneath the basic curve). For the synthetic
cases, both the GLR and basic methods were able to detec-
tion 100% of the anomalies with no lag at all. The wavelet
analysis method performs less well; in particular there ap-
pear to be some difﬁcult anomalies that can take over half
an hour to detect. It is interesting that the vshift method
performs well for the synthetic data but not for the Abi-
lene data. In the synthetic case to detect an anomaly the
volume should be high enough to raise an alarm as soon
as it is observed otherwise it remains undetected and we
cannot computes a lag time. Whereas in the Abilene data
the vshift method is able to detect a subtle deviation in the
statistics of the process and therefore need more samples to
detect it. The motivation for using a wavelet method was
an intuition that “an anomaly should diffuse itself at several
time scales”. However, in the results the anomalies appear
differently at different time scales, and hence this approach
was not very powerful in detecting anomalies. Other uses
of wavelet methods in this context might prove more ben-
eﬁcial. For example, they might be useful for classifying
anomalies since wavelet methods can give a rich descrip-
tion of the anomaly dynamics. This interesting problem is
out of the scope of this paper.
5.3 Sensitivity Analysis
It is intuitive that enormous anomalies will be easy to detect
and that very tiny ones are going to be missed. It is interest-
ing to explore the space in between and see the impact of
the false positive and false negative ratios as the volume of
anomalies get smaller and smaller. In Figure 6(a) we plot
the false negative ratio versus the percentage increase in
the anomalous ﬂow. To get a broad range of anomalies, for
each tested volume level, we generate 50 anomalies with
various start times or number of OD ﬂows involved. We
did this for 10 different volumes with 1.2 ≤ δ ≤ 2.
Figure 6(a) matches our intuition.
If the OD ﬂow in-
creases by only 10 or 20% of its original value, we going to
miss the anomalies. However the drop off of three methods
is similar and fairly quick in the range of 40 - 100%. This
implies that if the load from an ingress node doubled, it
should be easy to catch all anomalies (low missed anomaly
rate). Note that this justiﬁes the fact that we don’t use δ > 2
in our synthetic anomaly generator.
The curve for the false positive rate (Figure 6(b)) is sur-
prising. Initially we would have expected for this also to
be a decreasing curve. But, as the anomaly becomes larger
(δ ≥ 1.5) all the ﬂows sharing a link have their estimates
corrected by a large amount. Thus the error is spread inside
the kalman ﬁlter to normal OD ﬂows. This in turn increases
the innovations leading to more false positives. This will
not impact the ability to detect an anomaly but rather cloud
the identity of the OD ﬂow carrying the anomaly.
6 Conclusions
Our solution to tackling volume anomalies in large net-
works consists of many parts. First we select an interesting
granularity level at which to perform anomaly detection,
namely that of a trafﬁc matrix. Second we use kalman ﬁl-
ters to ﬁlter the predictable part of the trafﬁc and to isolate
the prediction error. The form of our model allows us to
obtain the prediction error on the unobservable part of the
network system (the OD ﬂows) as well as for the observ-
able part (link loads). Third, we proposed two detection
schemes, but compared the performance of four of them.
Finally we discuss how to make decisions about the pres-
USENIX Association
Internet Measurement Conference 2005  
343
1
010203040500.50.60.70.80.91Lag Time [min]P(td<x)wletglrbasicvshift010203040500.50.60.70.80.91Lag Time [min]P(td<x)wletglrbasicvshift05010015020000.20.40.60.81Volume of the anomaly [%]FNRwletglrbasicvshift05010015020000.20.40.60.811.2x10−3Volume of the anomaly [%]FPRwletglrbasicvshiftence of anomalies through the use of statistical hypothesis
testing. We argue that the main measure of performance
of an anomaly detector should be the ROC curve that ex-
plicitly captures the relationship between false positive and
false negative rates. We give a mathematical foundation for
this approach through the Neyman-Pearson theorem that
identiﬁes how to select decision thresholds when balancing
the false positive and false negative tradeoff.
We considered four detection schemes that differ in the
statistical change they seek to detect. Interestingly, but per-
haps not surprisingly in retrospect, we found that the GLR
method (whose goal is to detect changes in the mean) per-
forms best when the anomaly is one that causes a change in
the mean (e.g., in the synthetic cases). Similarly we found
that the ’vshift’ method performs better for the Abilene data
than the synthetic data. We hypothesize that this occurs be-
cause the statistical properties of the anomalies themselves
in the Abilene data contain changes in the variance of the
residual trafﬁc process. (We intend to verify this in future
work by adding extra features into our synthetic anomaly
generator that will alter the variance of the anomaly.) If the
latter hypothesis is true, the implication is that the statisti-
cal change method that works best is the one checking the
parameter that undergoes a deviation in the anomaly. On
the one hand, this is motivation to do a study of the statisti-
cal properties of anomalies themselves. On the other hand,
it suggests that the best method for network administrators
could be a composite method that makes use of multiple
different kinds of tests.
In our study, the wavelet based method did not perform
well. Due to the popularity of wavelet based analyses, this
raises interesting questions as to when wavelet analysis is
and isn’t useful for the problem domain of anomaly detec-
tion. Most importantly, from a practical point of view, it is
good news that the simplest method performed best across
all validation tests. This could be due to the fact that the
Kalman model for the OD ﬂows correctly models the nor-
mal trafﬁc and thus the ﬁrst ﬁltering step is successful itself
in isolating anomalies.
Aknowledgements
We would like to thank Anukool Lakhina for generously
sharing his labeled Abilene traces with us. We are also
grateful to Simon Crosby for talking to us about ROC
curves.
References
[4] BASSEVILLE, M., AND NIKIFOROV,
changes: theory and application, 1993.
I. Detection of abrupt
[5] EGAN, J. Signal Detection Theory and ROC Analysis. Academic
Press, 1975.
[6] GUNNAR, A., JOHANSSON, M., AND TELKAMP, T. Trafﬁc matrix
estimation on a large ip backbone - a comparison on real data. In
ACM IMC (Oct. 2004).
[7] HAWKINS, D. M., QQUI, P., AND KANG, C. W. The changepoint
model for statistical process control. Journal of Quality Technology
35, 4 (october 2003).
[8] HUSSAIN, A. Measurement and Spectral Analysis of Denial of Ser-
vice Attacks. PhD thesis, USC, May 2005.
[9] JUNG, J., KRISHNAMURTHY, B., AND RABINOVICH, M. Flash
crowds and denial of service attacks: Characterization and impli-
cations for cdns and web sites.
In ACM WWW Conference (May
2002).
[10] KAILATH, T., SAYED, A. H., HASSIBI, B., SAYED, A. H., AND
HASSIBI, B. Linear Estimation. Prentice Hall, 2000.
[11] LAKHINA, A., CROVELLA, M., AND DIOT., C. Characterization
of network-wide anomalies in trafﬁc ﬂows. In ACM IMC (2004).
[12] LAKHINA, A., CROVELLA, M., AND DIOT., C. Diagnosing
network-wide trafﬁc anomalies. In ACM Sigcomm (2004).
[13] LAKHINA, A., PAPAGIANNAKI, K., CROVELLA, M., DIOT, C.,
KOLACZYK, E., AND TAFT, N. Structural analysis of network traf-
ﬁc ﬂows. In ACM Sigmetrics (2004).
[14] MALLAT, S. A Wavelet Tour of Signal Processing. Academic Press,
1999.
[15] MIRKOVIC, J., AND REIHER, P. A taxonomy of ddos attack and
ddos defense mechanisms. In ACM CCR (April 2004).
[16] MOORE, D., VOELKER, G. M., AND SAVAGE, S. Inferring inter-
net Denial-of-Service activity. In Proceedings of the 10th USENIX
Security Symposium (2001), pp. 9–22.
[17] SOMMERS, J., YEGNESWARAN, V., AND BARFORD, P. A frame-
work for malicious workload generation. In IMC (New York, NY,
USA, 2004), ACM Press, pp. 82–87.
[18] SOULE, A., LAKHINA, A., TAFT, N., PAPAGIANNAKI, K., SALA-
MATIAN, K., NUCCI, A., CROVELLA, M., AND DIOT, C. Traf-
ﬁc matrices: Balancing measurements, inference and modeling. In
ACM Sigmetrics (2005), ACM Press.
[19] SOULE, A., NUCCI, A., CRUZ, R., LEONARDI, E., AND TAFT, N.
How to identify and estimate the largest trafﬁc matrix elements in a
dynamic environment. In ACM Sigmetrics (New York, 2004).
[20] SOULE, A., SALAMATIAN, K., AND TAFT, N. Trafﬁc matrix track-
ing using kalman ﬁlters. ACM LSNI Workshop (2005).
[21] TEIXEIRA, R., DUFFIELD, N., REXFORD, J., AND ROUGHAN, M.
Trafﬁc matrix reloaded: Impact of routing changes. In PAM (2005).
[22] ZHANG, Y., ROUGHAN, M., DUFFIELD, N., AND GREENBERG,
A. Fast accurate computation of large-scale ip trafﬁc matrices from
link loads. In ACM Sigmretrics (2003), ACM Press, pp. 206–217.
[23] ZHANG, Y., ROUGHAN, M., LUND, C., AND DONOHO, D. An
information-theoretic approach to trafﬁc matrix estimation. In ACM
Sigcomm (2003), ACM Press, pp. 301–312.
[1] A.MARKOPOULOU, IANNACCONE, G., BHATTACHARYYA, S.,
CHUAH, C., AND DIOT, C. Characterization of Failures in an IP
Backbone. In In: IEEE Infocom (March 2004).
[24] ZWEIG, M. H., AND CAMPBELL, G. Receiver-operating character-
istic (roc) plots: a fundamental evaluation tool in clinical medicine.
In Clinical Chemisty (1993), vol. 93(4).
[2] BARFORD, P., KLINE, J., PLONKA, D., AND RON, A. A signal
analysis of network trafﬁc anomalies. ACM Sigcomm IMW (2002).
[3] BARFORD, P., AND PLONKA, D. Characterisitics of of network
trafﬁc ﬂow anomalies. In ACM IMW (Nov. 2001).
1
344
Internet Measurement Conference 2005 
USENIX Association