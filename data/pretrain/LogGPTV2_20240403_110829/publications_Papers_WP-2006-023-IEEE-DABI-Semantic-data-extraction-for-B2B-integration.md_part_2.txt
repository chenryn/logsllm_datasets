### S2S Middleware: Attribute Mapping and Data Extraction

#### 2.4.1 Obtain Extraction Schema
After processing the query, the system must retrieve data to answer it. The extraction is based on attributes, which require retrieval of the corresponding extraction schemas. For example, if the attribute `thing.product.brand` is associated with the WebL file `watch.webl` and a data source identifier `wpage_81`, the extraction schema will indicate how the extraction should be executed.

**Example:**
- **Attribute ID:** `thing.product.brand`
- **WebL File:** `watch.webl`
- **Data Source Identifier:** `wpage_81`

The attribute ID is linked to the WebL file containing the extraction rules, and the data source identifier informs the extractor manager which extractor to use and how to connect to it.

#### 2.4.2 Obtain Data Source Definition
Attributes are associated with data sources, and each data source has specific connection characteristics. Extractors need to know how to connect to these data sources. After retrieving an extraction schema, the extractor fetches the associated data source definition to enable access.

**Example:**
- **Attribute ID:** `thing.product.watch.case`
- **Extraction Method:** SQL Query
- **Data Source Identifier:** `DB_ID_45`

If the attribute `thing.product.watch.case` is extracted from a database, the mapping information would be set in SQL query language and associated with the data source identifier `DB_ID_45`.

**Mapping Entry:**
```sql
thing.product.watch.case = "SELECT aAttribute FROM aTable WHERE aAttribute = aValue, DB_ID_45"
```

#### 2.4.3 Data Extraction
This is the core of the extraction mechanism, supported by a mediator and a set of wrappers/extractors. The extraction process is carried out in four steps:

1. **Identify Data to Extract:**
   The extraction process starts by identifying the required attributes. This is determined by the query handler, which generates a list of attributes needed to satisfy the query.

2. **Obtain Extraction Schema:**
   Once the required attributes are known, the extractor retrieves the corresponding extraction rules from the Attribute Repository.

3. **Obtain Data Source Information:**
   The extractor then retrieves the connection information for the data sources from the Data Source Repository. This step ensures that all necessary prerequisites for data extraction are met.

4. **Extract Data:**
   The extraction manager delegates a specific extractor for each data source type. For web pages, a web wrapper is used; for databases, a database extractor is used. The extractor executes the extraction rules, gathers raw data, and sends it to the Instance Generator for compilation into an ontology instance.

### 2.5 Query Handler
A query sets the S2S extraction middleware in action. The input is based on a higher-level semantic query language, which is transformed to represent requests based on ontology classes. The Syntactic-to-Semantic Query Language (S2SQL) is a simplified version of SQL, where data location is transparent to the user. The syntax of S2SQL is as follows:

```sql
SELECT <attributes>
WHERE <condition>
AND <condition> ...
```

**Example Query:**
```sql
SELECT product WHERE brand = "Seiko" AND case = "stainless-steel"
```

The output is based on the ontology schema, specifically ontology classes. The result of the above query would be all products with the brand "Seiko" and a stainless-steel case, including their associated classes such as Product, Watch, and Provider.

### 2.6 Instance Generator
This module serializes the output data format and handles errors from queries and extraction phases. The S2S middleware supports OWL as the output format, but other formats like XML can also be easily adapted. The ontology population process (OWL instance generation) is automated, ensuring that the extracted information respects the ontology schema. This makes it easier to visualize data hierarchy and perform direct mapping.

### 4. Related Work
Several research projects aim to achieve similar objectives as the S2S middleware. However, our approach uses semantics and ontologies to achieve a higher degree of integration and interoperability. 

- **World Wide Web Wrapper Factory (W4F):** A framework for developing web wrappers/extractors, allowing users to create and deploy web wrappers.
- **Caméléon Web Wrapper Engine:** Capable of extracting from both text and binary formats, providing output in XML.
- **Artequakt:** An automatic ontology-based knowledge extraction system, customized for a specific domain.
- **Architecture for Semantic Data Access to Heterogeneous Information Sources:** Allows uniform access to heterogeneous data sources through a common query interface based on a Semantic Data Model.

### 5. Conclusion
Creating B2B processes for integrating various organizations is challenging due to the heterogeneity of data sources and systems. Middleware technology can enhance integration, but most current middleware only covers syntactical integration. Semantics are essential for supporting and enhancing integration. In this paper, we present a middleware architecture for semantic B2B integration, using semantic web technology and structured data (ontology schema) to offer a common understanding of a domain and assimilate heterogeneous systems.

### References
1. Sheth, A. (1998). Changing Focus on Interoperability in Information Systems: From System, Syntax, Structure to Semantics. In M.F. Goodchild et al. (Eds.), *Interoperating Geographic Information Systems*. Kluwer Academic Publishers.
2. W3C. (2004). OWL Web Ontology Language Reference. World Wide Web Consortium.
3. Cycorp. (2006). Cyc Knowledge Base. Retrieved from http://www.cyc.com/.
4. Genesereth, M. (2006). Knowledge Interchange Format (KIF). Retrieved from http://logic.stanford.edu/kif/dpans.html.
5. Lassila, O., & Swick, R. (1999). Resource Description Framework (RDF) model and syntax specification. W3C Working Draft WD-rdf-syntax-19981008. Retrieved from http://www.w3.org/TR/WD-rdf-syntax.
6. Kistler, T., & Marais, H. (1998). WebL - a programming language for the web. *Computer Networks and ISDN Systems*.
7. Sahuguet, A., & Azavant, F. (1999). Building Intelligent Web Applications Using Lightweight Wrappers. In *25th International Conference on Very Large Data Bases*. Edinburgh, Scotland, UK.
8. Firat, A., Madnick, S., & Siegel, M. (2000). The Caméléon Web Wrapper Engine. In *Workshop on Technologies for E-Services (TES 2000)*. Cairo, Egypt.
9. Alani, H., et al. (2003). Automatic Ontology-Based Knowledge Extraction from Web Documents. *IEEE Intelligent Systems*, 18(1), 14-21.
10. Rishe, N., et al. (2000). The Architecture for Semantic Data Access to Heterogeneous Information Sources. In *15th International Conference on Computer and Their Applications (ISCA 2000)*. New Orleans, Louisiana, USA.