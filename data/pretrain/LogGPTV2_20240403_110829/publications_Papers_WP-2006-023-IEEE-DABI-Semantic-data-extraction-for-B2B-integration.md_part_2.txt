var spliter = Str_Split(St[0][0],"<>");
var brand = Select(spliter[2],0,6); methods and languages.
This is the main section of the S2S middleware and
Step 3 – Attribute Mapping it is implemented by three tasks, Obtain Extraction
Finally the mapping is completed by adding the Schema, Obtain Data Source Definition and Data
mapping information in the attribute repository. This is Extraction.
done by associating the attribute ID with the extraction
rule code or module. For example, 2.4.1 Obtain Extraction Schema. After processing the
query, the system must retrieve data in order to answer
thing.product.brand = “watch.webl, wpage_81”
the query. The extraction is based on attributes, so this
area retrieves extraction schemas of the required
The attribute ID (thing.product.brand) is associated
attributes, thus indicating to the extractor how the
with the WebL file (watch.webl) containing the
extraction is executed.
extraction rules and a data source identifier
(wpage_81). This identifier is vital to inform the
2.4.2 Obtain Data Source Definition Attributes are
extractor manager which extractor to use and how to
associated with data sources and data sources have
connect to it.
connection characteristics. Therefore, extractors need
As another example, suppose that the attribute case
to know how to connect to each data source. After
(thing.product.watch.case) were extracted from a
retrieving an extraction schema, the extractor fetches
database, then the mapping information would have to
the associated data source definition to enable its
be set in SQL query language and would be associated
access. Now extraction can take place.
with the data source identifier to DB_ID_45. The
mapping entry would have the following characteristic:
2.4.3 Data Extraction. This is the hot point in the
extraction mechanism. It is supported by a mediator
thing.product.watch.case =
”SELECT aAtribute and a set of wrappers/extractors (details will be given
FROM aTable in the subsequent sections). The extraction process is
WHERE aAttribute=aValue, DB_ID_45”
carried out in four steps as illustrated in Figure 5.
At this stage the mapping module has information
Step 1 – Know what data to extract
about how to connect to data sources (in the data
The extracting process starts by identifying what 2.5 Query handler
data needs to be extracted. The extraction data must be
a set of attributes. This information is determined by A query is the event that sets the S2S extraction
the query handler that bases the required attribute list middleware in action. The input is based on a higher
on a query it generates, in order to suit the query. level semantic query language. This query is then
transformed to represent requests based on ontology
Step 2 – Obtain extraction schema (rules) classes. The Syntactic-to-Semantic Query Language
After knowing what attributes need to be extracted, (S2SQL) is the query language based on SQL
the extractor needs to know how to extract data for supported by the extraction module. It is a simpler
them. The Attribute Repository has the attribute list and version of SQL since data location is transparent from
related extraction rules. Thus, based on the attribute the query point of view. Thus the FROM and related
list, this element retrieves the information and forwards operators have no use in S2SQL and are thus not
it to the extractor. supported. This way, queries are created only with the
indication of which data is required. It is not necessary
to supply information about data location, data format,
extraction method, etc. The syntax of S2SQL is the
following,
SELECT 
WHERE 
AND …
An example of a query would be,
SELECT product WHERE brand=”Seiko”
AND case = “stainless-steel”
The output is based on the ontology schema, more
precisely ontology classes. The result of the previous
Figure 5 – Extraction process
example is all products with the brand Seiko and case
stainless-steel, i.e., product classes that have brand
Step 3 – Obtain data source information
Seiko and case stainless-steel. Thus the query output
After having the extraction rules, the extractor needs
will have all their associated classes, i.e. all products
to know how to connect to the data sources. As shown
have a Provider (Figure 2), and therefore the output
in the attribute registering process, registered attributes
classes will be Product, watch, and Provider.
have a reference in the Data Source Repository that
expresses data source connection information. In this
2.6 Instance generator
step, all references to the Data Source Repository
entries from each attribute are listed and the respective
This module serializes the output data format and
connection information is retrieved. After completing
handles the errors from the queries and from the
this phase, all requisites to extract data are fulfilled.
extraction phases. The S2S middleware supports the
output format OWL, but other outputs can easily be
Step 4 – Extract data (Data Extractor)
adapted to export plain text to XML, , and so on, being
Now data extraction mechanisms begin to gather
either structured, semi structured or unstructured
data. First, the extraction manager delegates a specific
formats.
extractor for each extraction method depending on the
The ontology population process (OWL instance
data source type. For Web pages, the extraction rules
generation) is executed in an automatic way. This is
are delegated to a Web wrapper, for databases to a
because the extracted information (used to map the
database extractor, and so on. The extractor executes
ontology to the data sources) respects the ontology
the extractions rules in the data sources and obtains
schema (classes and relationships). Therefore,
chunks of data. These data fragments of raw data are
transforming the unique identifiers of the ontology
then sent to the Instance Generator to be compiled in
attributes in a XML format is done naturally. This way
to an ontology instance.
it is easier to visualize data hierarchy and how the
direct mapping works. Direct mapping is done by
transforming the XML structure into the ontology
structure. Data semantics is set in the ontology schema We believe that the solution outlined above
and maintained in the output since the whole extraction provides a useful tool for taking better advantage of the
process is based on the same ontology schema. This future capabilities and benefits of semantic data models
approach has the advantage of providing an ontology- and the semantic Web.
independent system.
7. References
4. Related work
[1]. Sheth, A., Changing Focus on Interoperability in
There are several research projects which target the Information Systems: From System, Syntax, Structure to
same objectives as the S2S middleware. The main Semantics, in Interoperating Geographic Information
Systems, M.F. Goodchild, et al., Editors. 1998, Kluwer,
differences are that we use semantics and ontologies to
Academic Publishers. p. 5-30.
achieve a higher degree of integration and
[2]. OWL, OWL Web Ontology Language Reference, W3C
interoperability. The World Wide Web Wrapper
Recommendation. 2004, World Wide Web Consortium,
Factory (W4F) [7] toolkit is a good framework to
http://www.w3.org/TR/owl-ref/.
develop Web wrapper/extractor. It allows the user to [3]. Cycorp, Cyc KNowledge Base - http://www.cyc.com/.
create Web wrappers and deploy them as modules in a 2006.
bigger application.W4F extracts exclusively from Web [4]. Genesereth, M., Knowledge Interchange Format (KIF) -
pages and the output may be in an XML file or a Java http://logic.stanford.edu/kif/dpans.html. 2006.
interface. The Caméléon Web Wrapper Engine [8] is [5]. Lassila, O. and R. Swick, Resource Description
Framework (RDF) model and syntax specification. 1999,
capable of extracting from both text and binary
W3C Working Draft WD-rdf-syntax-19981008.
formats. The engine provides output in XML.
http://www.w3.org/TR/WD-rdf-syntax.
Artequakt [9] is an Automatic Ontology-Based
[6]. Kistler, T. and H. Marais, WebL - a programming
Knowledge Extraction from Web documents that language for the web. Computer Networks and ISDN
automatically extracts knowledge from an artistic Systems, 1998.
ontology and generates personalized biographies. The [7]. Sahuguet, A. and F. Azavant. Building Intelligent Web
major drawback of this system is that it is customized Applications Using Lightweight Wrappers. in 25th
to a specific domain. The Architecture for Semantic International Conference on Very Large Data Bases. 1999.
Edinburgh, Scotland, UK.
Data Access to Heterogeneous Information Sources
[8]. Firat, A., S. Madnick, and M. Siegel. The Caméléon Web
[10] allows heterogeneous data sources to have
Wrapper Engine. in Workshop on Technologies for E-
uniform access through a common query interface
Services (TES 2000). 2000. Cairo, Egypt.
based on Semantic Data Model.
[9]. Alani, H., et al., Automatic Ontology-Based Knowledge
Extraction from Web Documents. IEEE Intelligent Systems,
5. Conclusion 2003. 18(1): p. 14-21.
[10]. Rishe, N., et al. The Architecture for Semantic Data
Access to Heterogeneous Information Sources. in 15th
Creating B2B processes for integrating various
International Conference on Computer and Their
organizations are difficult to compose since
Applications (ISCA 2000). 2000. New Orleans, Louisiana,
organization data sources and systems are
USA.
heterogeneous. One way to increase the degree of
integration of B2B links between partners is to use
middleware technology. Nevertheless, most current
middleware only covers syntactical integration and it
has been recognized that semantics are an
indispensable approach to support and enhance
integration. Therefore, in this paper we have presented
middleware architecture for semantic B2B integration.
The main goal of the architecture is to offer a common
understanding of a domain and assimilate
heterogeneous systems (using semantic Web
technology). All this is supported by structured data
(Ontology schema) thus offering semantic data
representation benefits that allow data to be shared and
processed by automated tools as well as by people.