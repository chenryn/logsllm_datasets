**Title: On the Data-Flow Complexity of Web Processes**

**Author: Jorge Cardoso  
Department of Mathematics and Engineering  
University of Madeira, 9050-390 Funchal, Portugal  
Email: [PI:EMAIL]**

**Abstract:**
Organizations are increasingly challenged with managing e-commerce and e-business applications that involve Web services and Web processes. The design of these processes can become highly complex, often due to the extensive number of services in global markets. High complexity in a process can lead to several undesirable outcomes, such as poor understandability, increased errors, defects, and exceptions, which in turn require more time for development, testing, and maintenance. Therefore, it is essential to avoid excessive complexity. Flexibility and complexity are key guiding principles in the design of business processes, and they are generally inversely related. Processes with high complexity tend to be less flexible, as making changes becomes more complicated. In our previous work, we defined a metric to measure the control-flow complexity of Web processes. The primary goal of this paper is to study the issues and establish the requirements for developing a metric to analyze the data-flow complexity of Web processes.

**1. Introduction**
In the competitive e-commerce and e-business market, Web processes can span both between and within enterprises. While organizations aim for their Web processes to be simple, modular, easy to understand, maintain, and re-engineer, cross-organizational settings inherently introduce complexity. Effective process management requires a thorough analysis of Web process complexity. Studies indicate that 38% of process management solutions will be applied to redesign enterprise-wide processes (Delphi Group, 2002).

Complexity is closely linked to flexibility, a key enabler of innovation. Flexibility and complexity are guiding principles in the design of business processes and are generally inversely related. Processes with low complexity are usually more flexible, as they can quickly adapt to new products or services to meet changing customer and business partner needs.

In our previous work [3], we presented a control-flow complexity metric to improve the quality and maintainability of processes during development. We believe that no comprehensive metric exists to fully analyze the complexity of Web processes. Multiple metrics need to be developed to characterize specific aspects of Web processes. A control-flow metric alone cannot capture the full complexity; thus, a data-flow complexity metric is also essential. This paper addresses the challenges and proposes solutions for developing a data-flow complexity metric for Web processes.

**2. Web Process Complexity and Flexibility**
Flexibility should be a primary concern during the development of Web processes. Data-flow complexity measures should be considered during the construction or re-engineering of Web processes to monitor complexity trends and maintain predefined flexibility levels. A significant increase in complexity during testing may indicate a brittle, non-flexible, or high-risk process. As processes evolve over time, they can become fragile, necessitating techniques like complexity analysis to assess the system's condition. Complexity metrics can provide information on the cost and time required to make changes to a process to enhance its flexibility.

We define Web process complexity as the degree to which a process is difficult to analyze, understand, or explain. It can be characterized by the number and intricacy of Web service interfaces, transitions, conditional and parallel branches, loops, roles, activity categories, data structures, and other process characteristics [1].

**3. Web Services and Web Processes**
Data flow refers to the movement of data between the Web services in a Web process. We begin with a brief introduction to Web services and Web processes. A Web service is defined using a WSDL (Web Services Description Language) document, which contains XML definitions describing the service using four major elements: input and output messages, data types, port types, and bindings. In our study of data flow, we focus on messages and types.

While Web services can be used in isolation, they are often integrated into Web processes or workflows. BPEL4WS (Business Process Execution Language for Web Services) is a prominent solution for describing Web processes. BPEL4WS specifies the logic to control and coordinate Web services in a process flow, addressing challenges such as control flow (branch, loop, and parallel), data manipulation between Web services, faults, and compensation. Analyzing a BPEL4WS Web process specification provides a metric for Web service interface integration complexity (Section 4.3).

**4. Data-Flow Complexity**
The data-flow complexity of a Web process increases with the complexity of its data structures, the number of formal parameters of Web services, and the mappings between Web services' data.

Our data-flow complexity metric consists of three individual metrics:
a) Data complexity (Section 4.1),
b) Interface complexity (Section 4.2), and
c) Interface integration complexity (Section 4.3).

While the first two metrics relate to static data aspects (data declaration), the third metric is more dynamic, focusing on data dependencies between different activities in a process. We will discuss these three types of data complexity in the following sections.

**4.1 Data Complexity**
Creating a common data type system for diverse programming languages is one of the greatest challenges in building Web services. WSDL does not aim to create a standard for XML data typing but uses the W3C XML Schema data type specification [4] as its default choice, currently the most widely used specification for data typing.

We will study the different data types present in a WSDL document, specifically the complexity of the data types defined in the W3C XML Schema. The XML schema distinguishes between primitive, derived, and complex data types.

**Primitive Data Types:**
Primitive data types are not defined in terms of other data types. The XML schema defines 19 primitive data types, each associated with a data complexity constant \( c_i \) (Table 1).

| **XML Schema Primitive Data Types** | **\( c_i \)** |
|-------------------------------------|---------------|
| String                              | 1             |
| Boolean                             | 2             |
| Decimal                             | 3             |
| Float                               | 4             |
| Double                              | 5             |
| Duration                            | 6             |
| DateTime                            | 7             |
| Time                                | 8             |
| Date                                | 9             |
| gYearMonth                          | 10            |
| gYear                               | 11            |
| gMonthDay                           | 12            |
| gDay                                | 13            |
| gMonth                              | 14            |
| hexBinary                           | 15            |
| base64Binary                        | 16            |
| anyURI                              | 17            |
| QName                               | 18            |
| NOTATION                            | 19            |

For example, the declaration of a primitive type:

```xml
<xs:simpleType name="Fahrenheit">
  <xs:restriction base="xs:decimal"/>
</xs:simpleType>
```

A research question is whether all primitive data types have the same complexity. Two possible outcomes are:
a) All primitive data types have the same complexity, i.e., \( c_1 = c_2 = \ldots = c_{19} \).
b) Some primitive data types are more complex than others. For instance, the complexity of the 'dateTime' type (\( c_7 \)) might be greater than that of the 'Date' type (\( c_9 \)), as 'dateTime' can be seen as an aggregation of 'Date' and 'Time'.

**Question 1:** Do all primitive data types have the same data complexity? What is the complexity of each data type?

**Derived Data Types:**
Derived data types are defined in terms of other data types through restriction, list, or union. A derived data type must have greater complexity than its base type because the designer must remember both the base type and the additional information from the restriction, list, or union. How to treat restrictions, lists, or unions and which is more complex are questions that need to be explored.

**Question 2:** How do we calculate the complexity of derived data types?

**Complex Data Types:**
XML Schema has three compositor elements—sequence, choice, and all—that allow constructing complex data types from simpler ones. Sequence defines a compound structure in order, choice defines mutually exclusive data, and all defines an unordered group.

For example, two new data types, 'location' and 'temperature', are defined as follows:

```xml
<xs:complexType name="location">
  <xs:sequence>
    <xs:element name="country" type="xs:string"/>
    <xs:element name="state" type="xs:string"/>
    <xs:element name="city" type="xs:string"/>
  </xs:sequence>
</xs:complexType>

<xs:complexType name="temperature">
  <xs:sequence>
    <xs:element name="location" type="tns:location"/>
    <xs:element name="date" type="xs:date"/>
    <xs:element name="value" type="xs:decimal"/>
  </xs:sequence>
</xs:complexType>
```

Research is needed to determine the complexity of these complex data types.

**Question 3:** How do we calculate the complexity of complex data types?

**4.2 Interface Complexity**
Each Web service operation has an interface defining its input and output parameters. For example, consider the following WSDL specification:

```xml
<wsdl:operation name="GetTemperature">
  <wsdl:input message="tns:GetTemperatureRequest"/>
  <wsdl:output message="tns:GetTemperatureResponse"/>
</wsdl:operation>
```

The 'GetTemperature' operation has one input ('location') and one output ('temperature'). The inputs and outputs can be seen as references to lists of formal input and output parameters, respectively. We propose an Interface Complexity (IC) metric to describe the complexity of a Web service's interface:

\[ IC = IE \times PS \]

Where \( IE \) is the Interface Entropy and \( PS \) is the Parameters Structure. To calculate \( IE \) for the formal input and output parameters of an operation, we use Shannon's entropy concept [5]:

\[ IE(x) = -\sum_{i=1}^{n} p(i) \log_2 p(i) \]

Where \( n \) is the number of distinct data types in the interface, and \( p(i) \) is the probability of data type \( i \). If the entropy of an interface is 0, all parameters are of the same data type. If all parameters occur in equal numbers, the entropy is 1. For the example, the entropy of the input parameter is calculated as follows:

\[ IC('string', 'decimal') = -\left(\frac{2}{3} \log_2 \frac{2}{3}\right) - \left(\frac{1}{3} \log_2 \frac{1}{3}\right) = 0.92 \]

Interface entropy evaluates the difficulty for a designer to remember the data types of an operation. The Parameters Structure (PS) captures the number of input and output parameters:

\[ PS(o) = |o_{ip}| \times |o_{op}| \]

Where \( |o_{ip}| \) is the number of input parameters and \( |o_{op}| \) is the number of output parameters of operation \( o \).

**4.3 Interface Integration Complexity**
Interface integration complexity (ICC) measures the interdependence of Web services operations. In BPEL4WS, data is passed between Web services using data containers. The "assign" statement copies data from one container to another, with each "assign" activity containing one or more "copy" elements, each with a "from" and "to" element.

Higher coupling between Web services makes it more difficult for a designer to comprehend a given Web process. The integration of Web services' operations, due to the polarity of their interfaces, forces an output interface to connect to an input interface. While the output interface does not need to be fully integrated, the input interface must be fully mapped.

**Question 4:** How do we calculate the interface integration complexity of BPEL4WS containers?

**5. Conclusions**
The complexity of Web processes affects flexibility, understandability, usability, testability, reliability, and maintainability. Developing measures to analyze and reduce process complexity is crucial. Our goal is to analyze the design of Web processes using measurement strategies. We have discussed the issues related to developing a data-flow complexity metric and raised four important questions that need to be explored and answered.

**References:**
1. Cardoso, J., Evaluating Workflows and Web Process Complexity, in Workflow Handbook 2005, L. Fischer, Editor. 2005, Future Strategies Inc.: Lighthouse Point, FL, USA. p. 284.
2. Christensen, E., et al., W3C Web Services Description Language (WSDL). 2001.
3. BPEL4WS, Specification: Business Process Execution Language for Web Services Version 1.1. 2003, IBM.
4. XMLSchema, XML Schema Part 2: Datatypes Second Edition. 2004, W3C Recommendation 28 October 2004.
5. Shannon, C.E., A mathematical theory of communication. Bell System Technical Journal, 1948. 27(July): p. 379-423.
6. Miller, G.A., The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information. Psychological Review, 1956. 63: p. 81-97.
7. Card, D.N. and R.L. Glass, Measuring Software Design Quality. 1990, Englewood Cliffs, New Jersey: Prentice Hall.
8. Cardoso, J. and A. Sheth, Semantic e-Workflow Composition. Journal of Intelligent Information Systems (JIIS). 2003. 21(3): p. 191-225.