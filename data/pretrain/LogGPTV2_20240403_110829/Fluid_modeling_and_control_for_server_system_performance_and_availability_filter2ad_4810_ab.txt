### Authorized Use and Download Information
- **Authorized for use by:** Tsinghua University
- **Downloaded on:** March 20, 2021 at 05:35:50 UTC
- **Source:** IEEE Xplore
- **Restrictions apply.**

## Fluid Model for Server Performance and Availability

### Introduction
This section discusses the impact of Maximum Parallel Limits (MPL) on server performance and availability, as depicted in Figures 1 and 2. The fluid approximation method is used to model the system's state variables, treating them as real numbers rather than integers. This allows us to write the infinitesimal variations of these state variables with respect to time, which can be visualized as fluid flows, such as client request flows. The model is built using a set of differential equations, similar to those used in mechanics, physics, and electricity.

### State Variables
The three key state variables that describe and influence server performance and availability are:
- \( N_e \): The current number of concurrent client requests in the server.
- \( T_o \): The server throughput.
- \( \alpha \): The client request abandon rate.

These state variables are influenced by both themselves and input variables. The inputs to the proposed model are:
- \( N \): The server workload amount.
- \( M \): The workload mix (exogenous inputs).
- \( MPL \): The tunable parameter for server admission control.

In addition to input and state variables, the model has output variables, such as the average latency \( L \) to process a client request on the server.

### Model Formulation
Among the \( N \) concurrent clients trying to connect to a server, admission control authorizes \( N_e \) clients to enter the server, with \( 0 \leq N_e \leq N \) and \( 0 \leq N_e \leq MPL \).

Let \( cr(t, t+dt) \) be the number of client connections created on the server between \( t \) and \( t+dt \), and \( cl(t, t+dt) \) be the number of client connections closed on the server between \( t \) and \( t+dt \). The balance on \( N_e \) between \( t \) and \( t+dt \) is given by:
\[ N_e(t+dt) = N_e(t) + cr(t, t+dt) - cl(t, t+dt) \]

The incoming throughput \( T_i \) of the server, measured as the number of client connection demands per second, gives:
\[ cr(t, t+dt) = (1 - \alpha(t+dt)) \cdot T_i(t+dt) \cdot dt \]

Similarly, the outgoing throughput \( T_o \) of the server, measured as the number of client requests the server can handle per second, gives:
\[ cl(t, t+dt) = T_o(t+dt) \cdot dt \]

Combining these, we get:
\[ \dot{N_e}(t) = (1 - \alpha(t)) \cdot T_i(t) - T_o(t) \]

### Steady-State Assumptions
We assume that the system reaches a steady state in a reasonably short period of time \( \Delta \). During this period, the workload is relatively stable. The dynamics of \( T_o \) and \( \alpha \) can be approximated by first-order systems through their derivatives:
\[ \dot{T_o}(t) = -\frac{1}{\Delta} \left( T_o(t) - \bar{T_o} \right) \]
\[ \dot{\alpha}(t) = -\frac{1}{\Delta} \left( \alpha(t) - \bar{\alpha} \right) \]
where \( \bar{T_o} \) and \( \bar{\alpha} \) are the steady-state values of the outgoing throughput and the abandon rate, respectively.

### Finding Steady-State Values
A balance on the number of served client requests \( N_o \) gives:
\[ N_o(t+dt) = N_o(t) + sr(t, t+dt) \]
where \( sr(t, t+dt) \) is the number of served requests between \( t \) and \( t+dt \). Since there are \( N_e \) concurrent clients on the server and the average client request latency is \( L \), the number of served requests during \( dt \) will be:
\[ sr(t, t+dt) = \frac{dt}{L} N_e \]
Thus, we get:
\[ \dot{N_o} = \frac{N_e}{L} \]
which leads to:
\[ \bar{T_o} = \frac{N_e}{L} \]
This is an expression of Little's law.

By definition, \( \bar{\alpha} \) is equal to zero if \( N_e \) is smaller than \( MPL \), and \( \bar{\alpha} \) is equal to \( 1 - \frac{T_o}{T_i} \) if \( N_e = MPL \). However, the stochastic nature of client request arrivals may lead to situations where the measured average \( N_e \) is smaller than \( MPL \), but occasionally, the number of clients trying to access the server exceeds \( MPL \), resulting in some clients being rejected. This is illustrated in Figure 3, which compares the actual measured abandon rate with the naive estimation, showing a mismatch between the two.

To account for this behavior, we choose:
\[ \bar{\alpha} = \frac{N_e}{MPL} \left( 1 - \frac{T_o}{T_i} \right) \]
This means the probability of rejecting a client connection is higher when the average \( N_e \) is close to \( MPL \). Figure 3 shows that this improved method provides a more accurate estimation of the abandon rate.

### Final Equations
Combining the above, we have:
\[ \dot{T_o}(t) = -\frac{1}{\Delta} \left( T_o(t) - \frac{N_e(t)}{L(t)} \right) \]
\[ \dot{\alpha}(t) = -\frac{1}{\Delta} \left( \alpha(t) - \frac{N_e(t)}{MPL(t)} \left( 1 - \frac{T_o(t)}{T_i(t)} \right) \right) \]

### Latency Expression
Latency \( L \) depends on the global load of the server, i.e., the workload mix \( M \) and the number of concurrent clients \( N_e \). Figure 4 describes the evolution of latency \( L \) as a function of \( N_e \) for a given workload mix. A second-degree polynomial in \( N_e \) is a good approximation of the latency \( L \):
\[ L(N_e, M, t) = a(M, t) N_e^2 + b(M, t) N_e + c(M, t) \]
where \( c \) is positive, representing the zero-load latency, and \( a \) and \( b \) are also positive, modeling the processing time of requests.

### Summary of the Fluid Model
The proposed fluid model is given by equations (4) to (7), which reflect the dynamics of the state and output variables of server systems in terms of performance and availability.

### Control Techniques
In the following, we study the trade-off between the performance and availability of server systems and derive optimal admission control techniques based on the proposed fluid model. We provide two variants of control laws:
- **AM-C (Availability-Maximizing Control)**: Achieves the highest service availability given a fixed performance constraint.
- **PM-C (Performance-Maximizing Control)**: Meets a desired availability target with the highest performance.

#### AM-C: Availability-Maximizing Control
AM-C aims to guarantee a trade-off between server performance and availability with the following properties:
- (P1) The average client request latency does not exceed a maximum latency \( L_{max} \).
- (P2) The abandon rate \( \alpha \) is made as small as possible.

A feedback control law is proposed to automatically adjust the MPL server admission control parameter to satisfy this trade-off. The basic idea is to admit clients in such a way that the average client request latency \( L \) is close to \( L_{max} \). By construction, this maximizes the number of admitted clients \( N_e \), which induces a minimized abandon rate \( \alpha \).

A first approach could involve solving Eq. (7) such that \( L = L_{max} \). However, this approach is unwieldy since it requires knowledge of accurate values of parameters \( a \), \( b \), and \( c \) in equation 7, which may change over time. We propose another approach that avoids this online identification of model parameters. It is obtained via a simple input-output linearization technique, where the considered output is latency \( L \).

Roughly speaking, the approach aims to determine how to control the MPL value such that:
\[ \dot{L} = -\gamma_L (L - L_{max}) \]
As soon as \( \gamma_L > 0 \), this ensures the convergence of \( L \) to its maximum \( L_{max} \).

From Eq. (7), we have:
\[ \dot{L} = (2a N_e + b) \dot{N_e} \]
And since \( T_o \) and \( \alpha \) reach a steady state in a reasonably short period of time, \( T_o(t) = \bar{T_o} \) and \( \alpha(t) = \bar{\alpha} \). Therefore, with Eq. (4), we have:
\[ \dot{L} = (2a N_e + b) \left( 1 - \frac{N_e}{MPL} \right) (T_i - \bar{T_o}) \]

As a result, from Eqs. (8) and (9), MPL should be controlled as follows:
\[ MPL = \frac{N_e}{1 + \gamma_L (2a N_e + b) (T_i - \bar{T_o}) (L - L_{max})} \]

To free ourselves from \( a \) and \( b \), we choose to use \( \gamma_0 L = \gamma_L (2a N_e + b) (T_i - \bar{T_o}) \), which produces:
\[ MPL = \frac{N_e}{1 + \gamma_0 L (L - L_{max})} \]
where \( \gamma_0 L > 0 \) is a tuning parameter.

It follows that with Eq. (8) and control described in (10), the dynamic evolution of \( L \) is given by:
\[ \dot{L} = -(\gamma_0 L (2a N_e + b) (T_i - \bar{T_o})) (L - L_{max}) \]

In summary, the feedback control law given in (10) will reflect one of the following situations:
- If the current latency \( L \) is higher than \( L_{max} \), property (P1) is not guaranteed, and the control law will produce an MPL as a decreased value of the current number of admitted concurrent clients \( N_e \) (since \( 1 + \gamma_0 L (L - L_{max}) > 1 \)), which aims at meeting (P1).
- Symmetrically, if \( L \) is lower than \( L_{max} \), property (P1) holds, but property (P2) may not hold, and the control law will produce an MPL as an increased value of \( N_e \) (since \( 1 + \gamma_0 L (L - L_{max}) < 1 \)), which aims at meeting (P2).

#### PM-C: Performance-Maximizing Control
PM-C aims to meet a desired availability target with the highest performance. The goal is to ensure that the client request acceptation rate (i.e., \( 1 - \alpha \)) is maximized while maintaining the average client request latency \( L \) below a certain threshold.

The control law for PM-C is similar to AM-C but with a different objective. The feedback control law is:
\[ \dot{\alpha} = -\frac{1}{\Delta} \alpha (1 - \frac{N_e}{MPL}) \]

Thus, from Eqs. (11) and (12) and with the following control applied to MPL, \( \alpha \) will converge to \( \alpha_{max} \):
\[ MPL = \frac{\alpha N_e}{\alpha + \gamma_0 \alpha (\alpha - \alpha_{max})} \]
where \( \gamma_0 \alpha = \gamma \Delta \).

In summary, the proposed admission control techniques require a unique external parameter, \( \gamma \). This parameter has an impact on both the convergence time of the control (i.e., the number of iterations to converge to the optimal MPL) and the stability of the system. A low value of \( \gamma \) results in a long convergence time, while a high value can induce system oscillations. Choosing the right value of this parameter is crucial and depends on the time necessary for the system's QoS criteria (e.g., the abandon rate in the case of PM-C) to reach its steady state.

### Evaluation
This section describes the environment underlying our experiments and presents the results of the evaluation of the proposed fluid model and feedback controllers.

#### Experimental Setup
- **Testbed Application**: The evaluation was conducted using the TPC-C benchmark, an industry standard benchmark from the Transaction Processing Council that models a realistic database server application as a warehouse system.
- **Software and Hardware Environment**: Experiments were conducted on a set of two computers connected via a 100 Mb/s Ethernet LAN, one dedicated to the database server and the other to the client emulator. The database server is PostgreSQL 8.2.6. The proposed model and controllers were deployed using a non-linear monitoring system and Kalman filtering techniques. A proxy-based approach was followed to implement the AM-C and PM-C controllers, where a proxy stands in front of the database server to implement online feedback admission control. Both client and server machines run Linux Fedora 7.

#### Model Validation
Measurements were performed to validate the accuracy of the proposed fluid model and its ability to render the dynamics of the system. Specifically, we evaluated the model's ability to reflect the variation of the system state when input variables such as the server MPL and the workload amount \( N \) vary. The variation of the system state is described by the state variables \( N_e \), \( T_o \), and \( \alpha \). For the same set of input variables, the state reified by the model is compared with the actual state of the real system.

Figure 5 illustrates the case of a dynamic open-loop system where both the workload amount \( N \) and the server MPL vary over time. Figures 5(b), 5(c), and 5(d) present the evolution over time of the number \( N_e \) of concurrent clients admitted in the server, the outgoing throughput \( T_o \), and the abandon rate \( \alpha \), for both the real system and the modeled system.

### Conclusion
The proposed fluid model and feedback control techniques effectively capture the dynamics of server systems in terms of performance and availability. The model and control laws provide a robust framework for managing server admission control, ensuring optimal trade-offs between performance and availability.