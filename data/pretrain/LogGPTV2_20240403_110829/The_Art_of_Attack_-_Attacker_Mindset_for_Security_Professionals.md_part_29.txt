for a single attacker to wage war against a company and
even a country, and win! Technological advances make it
possible for attackers to continuously develop and improve tactics.
This results in everchanging threats which are made all the more
pernicious by the interconnectivity we’ve grown into.
Moreover, technologies have led to extremely sophisticated and
powerful criminal networks that are hard to identify and uncover
even when operating under our noses. To thwart such attacks and
threats, huge amounts of resources would have to be dedicated to
security by the government, but those resources aren’t there. The
gap is therefore bridged more and more by the private sector.
Criminal organizations come in many forms and can take
unlimited actions that aren’t always accurately forecastable. This
is where learning to think like them comes into play. Looking at
your organization through their mental filter can show you not only
how you are vulnerable, but where. Indicators of attack (IOA) focus
on detecting the intent of what an attacker is trying to accomplish,
regardless of the malware, tools or exploits they use. Indicator of
257
258 AFTER AMs
Compromise- based (IOC-b ased) detection approach does not iden-
tify the rising threats from malware-f ree intrusions or even zero-
day exploits. This is where an IOA-b ased approach, pioneered by
CrowdStrike, becomes useful (https://www.crowdstrike.com/
cybersecurity-101/indicators-of-compromise/ioa-vs-ioc/).
Indicators of Attack
Indicators of Attack are actions or a series of actions that an attacker
must execute in order to succeed. A spear phish is a good example
in order to illustrate the idea of an IOA.
A successful phishing email must persuade the target to follow
a link or open a document that will, in turn, infect their machine
and initial compromise takes place. They often aim to maintain
persistence and to make contact with a command and control site,
awaiting further instructions.
IOAs are concerned with the execution of these steps, the intent
of the adversary and the outcomes the attacker is pursuing. They are
not focused on the specific tools used to accomplish the objectives.
My position is not that IOA’s should be used in place of IOC’s.
I am of the opinion both are valuable. However, IOA’s are espe-
cially valuable when trying to determine why your business will be
attacked instead of only how. No advance knowledge of the tools or
malware (aka: Indicators of Compromise) is required, and so many
points of view can be offered and listened to.
Nontechnical Measures
My understanding of the evolution of cyber security is that for a
long time, attackers went for data on networks and servers, so we
protected them as best we could; then data and attackers went to
the endpoints, so we protected them the best we could; then the
data, and so the attackers, too, went to Software as a Service (SaaS)
and we authenticated them, but protection was limited. Threaded
throughout is the social engineering aspect of attacks, too, which
Staying Protected— The Business 259
has played a part steadily throughout the history of cyberattacks.
And only relatively recently have we really tried to build out our
defenses there. There are two categories of security: technical and
psychological. Because of this dichotomy, cybersecurity’s primary
concern with technical features often leaves us all at risk. It’s pre-
cisely why the community needs more discussion and thought
around AMs for defensive and offensive measures.
As was egregiously apparent with the recent Bitcoin- Twitter
scam, a win for an attacker doesn’t have to be brilliantly technical to
have adverse effects for hundreds of millions of people: ubiquitous
and mainstream technology is easily weaponized through AMs. The
attack itself saw prominent Twitter users, with the blue verification
checkmark next to their names, tweet “double your Bitcoin” offers,
promising their followers they’d double donations made to the
included links and send them back. For example, former President
Barack Obama’s account tweeted: “I am giving back to my commu-
nity due to Covid-1 9! All Bitcoin sent to my address below will be
sent back doubled. If you send $1,000, I will send back $2,000!” The
tweet has since been deleted. Elon Musk, Jeff Bezos, and Bill Gates
were among many prominent US figures targeted by the scam.
In this case, Twitter employees were the targets and, as we
know, if you aren’t an attacker or thinking like one, it can be hard
to stop the outcome.
The other thing that is needed if you are to protect yourself is
teaching your employees what to look out for— what an attack feels
like and how they can defend themselves even if they don’t know
they are in a position or situation where they need to. It’s so simple,
but it’s also worrying due to repercussions if you fail: if your employ-
ees are unprepared to deal with current and growing threats, you do
not have a shot at effective security. The threat landscape is always
changing, advancing, and growing, and employees have to be pre-
pared for this. It doesn’t mean everyone has to be highly strung and
forever on edge. But knowing what makes the company attractive,
understanding how attackers operate, and giving your employees
260 AFTER AMs
the power to treat security as something more than a concept is
essential. Employees are typically the ones on the front lines when
security incidents occur. However, many of them come into contact
with their organization’s cybersecurity policies through remind-
ers and restrictions. Those who don’t know about the policies, who
haven’t been able to commit them to memory, or who don’t recog-
nize attacks and remedies by reading what to do, are caught off-
guard, ill- equipped, and vulnerable.
Eliminating this issue requires a commitment to the resources,
personnel, and time to support an in-h ouse or outside team to
determine how vulnerable your organization is. This team will then
be required to show you, without fancy frills, what your landscape
looks like. This approach also requires corporate humility, which
boils down to implementing changes based on results. This is part
of a simple formula that will keep you safe as a company:
Employ tactical and combative methods internally through
the attacker mindset to identify security gaps and be willing to
change, employing corporate humility, to mitigate vulnerabilities
and security gaps.
That’s it. That explains how the most secure companies do the
impossible and remain ahead of attackers. Innovative companies
use this formula to change their position from defensive to offensive.
Resilient companies use it to become stronger. But all companies
require it. We are all at risk—t he owners, employees, and service
users—i f this is not being done. Companies and government alike
must always be able to identify dangerous shortcomings and react to
any glaring limitations quickly. If you can’t, you aren’t being proac-
tive. You aren’t invested in security— yours, the customers’, or the
employees’. The best way for us, as a society, to achieve higher levels
of security is to share information: share it with the authorities, with
the security community, and with each other—business to business
communication on what attack types and trends you are seeing is
essential if we are to advance our position in terms of security.
Staying Protected— The Business 261
Testing and Red Teams
If you’re hiring a red team, pentester, social engineering team, or
AMs expert, and if scope and the rules of engagement are signifi-
cantly restricted, you will not receive effective testing.
If you are part of an in-h ouse red team and you’re restricted,
you will struggle to effect real change, but you can aim to do so
in baby steps. You might consider documenting your thoughts on
where the company’s security faults and vulnerabilities lie and get-
ting them to an executive for potential future use and leverage (and
in case there is a breach, and all eyes turn to you. . .).
If you are in charge of a red team in-h ouse and cannot see
the full spectrum of benefit when employing them at their fullest
potential, you might consider looking further into this.
If you are in charge of a red team for hire but cannot see the
benefit of looking at the world both offensively and defensively, you
probably don’t have an effective red team.
In any instance of a red team, looking at attack trends will not
suffice. They are good to know about and to test, but your job is to
think like an attacker, looking at environments in isolation and work-
ing out how to best exploit them. Then you must look at those same
environments and determine how best to protect them. There is no
one- size-f its-a ll in security, and every business, organization, and
institution is vulnerable to attack, admittedly to varying degrees. Red
teaming seeks to uncover these vulnerabilities through a sharp AMs.
Survivorship Bias
Survivorship bias is when you aren’t working with all of the infor-
mation needed to make a complete analysis. We tend to focus on the
information we have and fail to consider the information we don’t
have. An example of this is illustrated in a story from World War II:
During WWII a mathematician named Abraham Wald helped the
US military determine where to add reinforcing armor on bomber
262 AFTER AMs
planes. Reinforcing the whole plane would render it too heavy, so
weight was added only where absolutely needed. Data and direc-
tion was collected and taken from returning planes based on where
they had taken damage (from bullets, shrapnel, etc.), essentially
mapping out where the damage tended to be. This is an example of
full- blown survivorship and Wald realized this. The data collected
could only account for the planes that made it back, and not for the
planes that were shot down and never returned. The areas a plane
could get shot, but still return, did not need additional armor to fly.
This is essential to understand as a business and an ethical attacker.
As an ethical attacker employing AMs, you cannot lean into
over- appreciating successes and underappreciate failures. Success
stories are easy to find while failures are usually ignored or lost
to time. You cannot look only at what made you successful as an
attacker and fail to notice what aptly countered you. If you do, you
will fail to grow, and you will fail to help your client see their whole
organization. As a whole industry, we cannot endlessly turn our
attention to the most successful ethical attackers. We must also be
aware of why attacks fail so we can then analyze the situation and
assess if it is truly secure or if the means of defeat lay elsewhere.
Businesses must also resist survivor bias. If you survive an
attack, it is not your triumphant defenses that need bolstering, it
is those that failed. Less obviously, as a business the culture can-
not shift to believing it survived an attack because it is completely
superior to those that didn’t. Those that didn’t may offer you more
insight than the other way round. In the simplest simple terms, as
a business that outperformed the rest, that concludes, based on
their attributes, without looking more broadly at the whole dataset,
including those with similar characteristics that failed to perform as
well, mistakes and vulnerabilities will occur.
Finally, whilst successful businesses can give advice on what
to do, businesses who failed in terms of security can give advice
on what not to do (which is just as valuable). This is also where I
return to the criticality of sharing information between businesses
and organizations: understanding where one business was success-
ful or unsuccessful can lead to helpful data and extrapolations that
can help the whole of business.
Staying Protected— The Business 263
The Complex Policy
Unfortunately, a cybersecurity policy does not equal cybersecu-
rity. In May 2018, research firm Clutch found that almost half of
employees don’t pay much attention to their employers’ cyberse-
curity policies (see https://clutch.co/it-services/resources/
how-employees-engage-company-cybersecurity-policies). One of
the biggest reasons internal cybersecurity practices are often inef-
fective is that they are overwhelming. If your policies are too com-
plex, they will ensure people take shortcuts, thereby functionally
circumventing them completely. This is where companies fail peo-
ple. It is also where regulations fail businesses and people. A policy
should be aimed toward giving anyone reading it a chance at under-
standing it.
Behavioral security tells us that defense begins in the brain. Let
the policies reflect this. They should be comprehensible and reason-
able, and they should not falter from their message: no matter what,
adhere to the process.
Finally, if you are in charge of a red team, social engineering
team, or pentest team, you cannot instill within your team mem-
bers what they should think. That is not your job, nor should you
want it to be. I don’t even think you should tell them what to do
directionally when in the planning phase—l et the environment be
open to all suggestions, and let the person who offered the idea talk
it all the way through. If it falls dead in the room, great. Move on to
the next, but do not make that individual feel bad. That suggestion
might spark another idea or help narrow down attack vectors. Have
your team learn how to form their own brand of attacker mindset.
Only when each person has a strong AMs in place can they learn
how to defend properly, because in doing so, they’ll be able to assess
a business and its defenses far more critically, describing blind spots
previously unknowable or invisible upon first inspection.
264 AFTER AMs
Protection
If you are going to defend your company against an attack, you must
first know who the enemy is by knowing what they want and what
will make it easy for that (or difficult) within your environment.
Protection is no easy feat with external attacks and insider
threats and two categories of employees aiding a security event
(the neutral and the lucrative). A relentless and dangerous bal-
ance exists between offense and defense, deepened in its insidi-
ousness when an attack is conducted in a stealthy manner. When
the offense has the advantage, there will always be engagement.
When it costs more to attack, or when the chances of an attack
defeating the defenses is low, there will be less engagement and
less success on the attacker’s side. This is your ultimate aim. Show
attackers that you are not “easy pickings”; use effective measures
they can’t plan for ahead of time. Be hard to defeat—use AMs to
assess yourself. Defend your business one level higher than you
think it needs.
Antifragile
Being antifragile is basically benefiting from volatility and
shock. Be ing robust is not the same as being antifragile. Something
that is robust will survive, but it will not benefit from harm. It will
simply act as though there was no trauma at all. Being antifragile is
being able to self-i mprove based on stressors and volatility.
In Antifragile: Things That Gain from Disorder (Random House
Publishing Group, 2014) author Nassim Nicholas Taleb coins the
word antifragile. He gives an example of its definition, stating that
“logically, the exact opposite of a ‘fragile’ parcel would be a package
on which one has written ‘please mishandle’ or ‘please handle care-
lessly.’ Its contents would not just be unbreakable but would benefit
from shocks and a wide array of trauma” (p. 32).
Staying Protected— The Business 265
The antifragility of something is determined by how fragile its
parts are. Paradoxically, the more fragile the parts of a system are,
the more antifragile that system can become; the parts that are frag-
ile direct the antifragility of the future system. This is best thought
of as trial and error. Taleb advocates for adding stress on purpose (in
your life; in your organization)— not too much, as we’ve discussed
before, because too much is detrimental. Exposure to a small dose
of stress will, over time, make us and our companies immune to
additional, larger quantities of stress.
An example of antifragility is the economy: its constituent parts,
from a one-p erson business to the biggest bank on Earth (as of this
writing Industrial & Commercial Bank of China), are all vulnerable
to fragility. But when one fails, the others learn from those mistakes
and are able to use those findings well into the future and become
stronger. The economy is antifragile, whereas its constituent parts
are all fragile.
In contrast, tranquility is not good for survival; shocks and the
unforeseen come with valuable information. Making a system tran-
quil will not aid its survival, as it will lag behind and lose its poten-
tial for growth.
Bottom line: antifragility fuels progress and advances society.
Failure of some things is okay so long as it is for the greater good
and we learn from it, thus becoming antifragile.
This concept applies to your business as well; you do not want to
mask, be blind to or ignore the gaps in your security. You should want
to be antifragile; add stress to your organization in a semi- controlled
way, thus allowing for growth and gaining from disorder. Keeping
this process under your control—a nd out of the control of a mali-
cious attacker—m eans being able to identify what’s vulnerable and
what’s sensitive and then safeguarding it with everything at your
company’s disposal—t echnology solutions as well as people and pro-
cess solutions. After all, this is exactly what an ethical attacker sees
and acts upon: who and what is vulnerable and what is sensitive. It’s,
of course, what a malicious attacker sees and acts upon, too.
266 AFTER AMs
The Full Spectrum of Crises
The Internet is undoubtedly the largest public data network. It ena-
bles and facilitates both personal and business communications the
world over. But although it can be used for good, it can be used for
bad as well. The Internet provides many advantages but comes with
many security threats. Having an Internet connection alters your
security risk profile. For instance, an offshore platform doesn’t have
to be connected to its on- land counterparts. It’s done to streamline
some of the operations needed to run a platform. The platform’s,
as well as the company’s, risk profile changes dramatically in
light of this.
Your business can undergo the full spectrum of crises, from a data