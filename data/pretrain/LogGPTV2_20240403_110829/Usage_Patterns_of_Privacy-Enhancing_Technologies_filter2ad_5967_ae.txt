their  identity.  If  the  customer  can  trust  the  shop,  anonymity  can  be  achieved  by  using 
anonymous shopping systems (see section 5.1), and in this case, the customer wants to check 
the privacy policy of the shop (se section 5.17-5.19 ), 
6.7  POSITIONAL INFORMATION 
In some situations, the geographical position of an individual – or the history of positions - is 
considered  private  information.  Because  an  increasing  number  of  common  user  situations 
involve information technology, there are various ways of tracing the individual’s position. 
Examples are reservations and tickets for airlines and other transport, which are linked to a 
credit card or other id token. Mobile phones leave clear traces of their position, and wireless 
LAN connected computers and PDA’s can be traced by the access points they are using. In 
some of these cases, the privacy can be enhanced by using e.g. SIM cards in the phone that is 
not  linked  to  the  user’s  identity  –  or  computer  addresses,  that  can  be  altered  by  the  user. 
However, the link can often be found by analyzing the traffic patterns (e.g. numbers called, 
emails sent, sites visited), even without analyzing the content, which could be encrypted: A 
number of encryption solutions are already in widespread use, in order to protect private data 
from being exposed to unauthorized parties, that have access to the medium (radio waves or 
public  networks).  Typical  examples  are  the  GSM  mobile  phones  encryption  of  the 
transmitted payload data (including voice), and WEP encryption of wireless networks. 
6.8  HEALTH CARE SERVICES 
Information related to a person’s health is generally classified as private, and should only be 
shared between a patient and the relevant health care staff. However, a safe treatment of a 
patient is relying on access to a full set of records, describing his medical history, condition, 
etc.,  and  the  ability  to  link  this  information  reliably  to  the  individual.  Therefore,  today’s 
procedures and systems handling clinical health information has primarily been designed to 
protect the patient’s health, rather than his privacy. And not surprising, most patients waive 
their right to privacy, when their health is at stake. Furthermore, the sharing of medical data 
with  public  and  private  medical 
institutions,  research  organizations  and 
pharmaceutical companies represents a wide range of challenges to privacy. The health care 
insurance 
Page 22 
Privacy Enhancing Technologies
META Group Report v 1.1
March 28, 2005
service  is  probably  the  most  important  area  for  employment  of  privacy  enhancing 
technologies,  both  as  an  integrated  part  of  the  enterprise  architecture,  and  as  stand-alone 
solutions  for  specific  needs.  Examples  of  such  applications  could  be  remodelling  public 
databases  (using  data  management  tools  described  in  section  5.2),  establishing  a  common 
privacy policy for the health sector (and implementing it with tools described in section 5.17 
– 5.19), or introducing alternative methods of identification of the patient (see section 5.20-
5.22). 
Page 23 
Privacy Enhancing Technologies
META Group Report v 1.1
March 28, 2005
7  MAJOR PET PLAYERS 
This  chapter  gives  a  reference  to  selected  providers  of  privacy  enhancing  products  and 
services, structured according to the principles set out in chapter 4. The list is not intended to 
be complete, but it includes examples of typical products and services. 
There  has  been  a  high  interest  in  privacy  technologies  in  the  early  years  of  this  century, 
which decreased somewhat in 2003 and early 2004. The list below includes some players that 
are obviously not in business anymore (marked with an asterisk *), but since they were very 
representative of their respective market segment, they are still listed. Since the interest in 
privacy  is  slightly  picking  up  in  late  2004  and  2005,  chances  are  that  new  players  will 
emerge, replacing those who vanished. 
7.1  PRIVACY PROTECTION 
http://www.epiphany.com/  
7.2  APPLICATION TOOLS 
E.piphany 
Unica 
Outerbay 
http://www.unica.com  
http://www.outerbay.com/  
http://www.synomos.com/  
http://www.custodix.com/  
http://www.privacyinc.com/  
7.3  ANONYMIZER PRODUCTS AND SERVICES 
Synomos Enterprise 
(ex Zero Knowledge)  
Custodix 
Privacy, Inc. 
Sapior Ltd. 
IPrivacy * 
http://www.sapior.com/  
http://www.iprivacy.com/  
7.4  ENCRYPTION TOOLS 
PGP Encryption 
http://www.pgp.com/  
7.5  FILTERS AND BLOCKERS 
Acronis Privacy Expert 
http://www.acronis.com/  
SynergeticSoft 
http://www.synergeticsoft.com/  
CRM Personalization
CRM Personalization
Application Data 
Management 
Monitors privacy 
compliance /governance 
Basic research ,TTP 
services. 
Virtual email addresses 
Pseudonym services, 
surrogate keys 
Browsing and email 
pseudonyms 
Encryption tools 
Spyware removal 
Activity traces clean-up 
Pop-up blocker 
Spam blocking tools 
Page 24 
Privacy Enhancing Technologies
META Group Report v 1.1
March 28, 2005
Privacy Manager  
Computer Associates / 
Pest Patrol 
http://www.anonymizer.com/
Spam blocking tools 
http://www.ca.com/products/pestpatrol/
Anti-Spyware solution 
http://www.ibas.no/datasletting  
http://www.privacyeraser.com/  
7.6  TRACK AND EVIDENCE ERASORS 
Ibas ExpertEraser 
PrivacyEraser 
7.7  PRIVACY MANAGEMENT 
INFORMATIONAL TOOLS 
7.8 
AT&T Privacy Bird 
OECD Privacy Policy 
Generator 
W3C Policy Validator 
Watchfire 
Privacy Council 
Coast 
Idcide * 
http://privacybird.com/  
http://www.oecd.org/  
http://www.w3.org/P3P/implementations
http://www.w3.org/P3P/validator.html  
http://www.watchfire.com/  
http://www.privacycouncil.com/  
http://www.coast.com/  
http://www.idcide.com/  
7.9  ADMINISTRATIVE TOOLS 
PrivacyRight 
IBM Tivoli Privacy 
Manager 
Access Data 
http://www.privacyright.com/  
http://www-
306.ibm.com/software/tivoli/products/privacy-
mgr-e-bus/  
http://www.accessdata.com/  
Harddisk data eraser 
Browser cleaning tools 
Reads P3P Policies 
Policy Generator Tool 
Online validator service 
Scans privacy 
compliance of web sites 
Scans privacy 
compliance of web sites 
Monitors privacy 
compliance of web sites 
Monitors privacy 
compliance of web sites 
Permission management 
and audit software 
Privacy management 
Forensics/Password 
recovery 
Page 25 
Privacy Enhancing Technologies
META Group Report v 1.1
March 28, 2005
8  RELEVANT GROUPS INFLUENCING PUBLIC PRIVACY PERCEPTION 
In Denmark, like most other European countries, the public awareness of privacy issues is 
still very low, mostly due to the fact that common knowledge of the issues is at a very low 
level. However, a number of organizations are  working to inform the public about privacy 
matters  and  influence  the  public  opinion  towards  demanding  e-services  that  respect  the 
privacy  of  the  citizen.  The  participants  of  our  research  have  identified  the  groups  and 
organizations listed in this section: 
•  European Commission, namely Directorate General “Internal Market” (EU DG IM) 
•  Article 29 Working Party at EU DG IM 
•  Organization for Economic Co-operation and Development (OECD) 
•  National (and e.g. in Germany and Switzerland also Regional) Data Protection 
Agencies 
•  EGovernment authorities (in Denmark: Digital Task Force, Ministry of Science) 
•  Human rights organizations (e.g. the Danish Human Rights Institute) 
•  Privacy user groups  
• 
Internet based forums on privacy 
•  Private institutions, researching and developing concepts 
•  Research community (universities, public institutions, e.g. Unabhängiges 
Landeszentrum für Datenschutz Schleswig-Holstein) 
•  Trade associations, representing industry sectors 
•  Commercial institutions, e.g. banking, insurance, Telco’s 
•  Private companies, selling PETs and consulting services 
•  Security working groups, e.g. IFIP Tech Committee 11 
•  User groups on sensitive data, e.g. health data 
Page 26 
Privacy Enhancing Technologies
META Group Report v 1.1
March 28, 2005
9  WHAT ARE THE PROBLEMS  
9.1  PRIVACY IN LEGACY APPLICATIONS WILL REQUIRE ADDITIONAL CHANGES 
Most of today’s Privacy Enhancing Technologies are conceptually designed to repair flaws in 
original  design  of  IT  systems  and  information  handling  procedures.  The  PETs  are 
conceptually add-on products to improve the privacy aspect of information systems that were 
built without this requirement. Hence, using PETs in a legacy environment will in most cases 
be a work-around solution, rather than an integrated component. As an example, adding PET 
to a legacy system (e.g. by replacing CPR-numbers with neutral identifiers) can have several 
negative side effects: 
a)  It can reduce the overall efficiency of the system, when e.g. database searches have to 
be performed with multiple criteria, rather than  using one unique key (the personal 
ID).  
b)  It can lead to less reliable data, when the unique keys are no longer visible, because 
flaws  in  the  data  consistency  are  less  likely  to  be  discovered  –  by  the  user  or  by 
maintenance tools. 
c)  It can increase the vulnerability of the system against fraud and abuse, because the 
possibilities of cross-checking one database against others has been limited. 
This  implies  that  adding  PETs  to  existing  legacy  applications  will  often  require  additional 
changes of the system, to maintain the efficiency, reliability and robustness of the service. 
Such changes are generally not covered by the services of PET suppliers, and they will often 
require detailed knowledge of the application.  
9.2  USER CONTROLLED PRIVACY CAN IMPACT USER RIGHTS 
The “classical” PET tools and services (anonymizers, pseudonymizers etc.) are designed to 
assist  the  user  in  protecting  his  true  identity  from  exposure.  When  using  such  tools  in  the 
interaction  with  services  that  assume  that  a  true  identity  is  presented,  the  user  may  be 
violating the business assumptions of the service provider. In other words, if the service has 
not been designed for anonymous users, the service provider could be unwilling or unable to 
fulfil his subsequent obligations towards the user, e.g. in case of warranty claims. 
9.3  EXPLOITING DESIGN FLAWS  
Some PET implementations are exploiting holes in the design of existing applications to add 
a level of privacy, for instance by inserting fictive data into fields designed to hold unique 
identification, where the appropriate check of the content has been omitted in the receiving 