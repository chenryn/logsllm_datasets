18
Lemma 3. Hybrid2(B)(k, x; r)
c≈ Hybrid3(B)(k, x; r)
Proof. This follows from the witness-indistinguishability property of the output proof, which guarantees that the index
of the circuit output being sent remains hidden. Indistinguishability follows directly from Lemma G.12 in shelat and
Shen’s proof [37].
Hybrid4(B)(k, x; r): This experiment is identical to the experiment Hybrid3(B)(k, x; r) except that the experi-
ment selects random inputs for Alice a(cid:48) and Cloud z(cid:48) following the parameters of the protocol.
Lemma 4. Hybrid3(B)(k, x; r)
c≈ Hybrid4(B)(k, x; r)
Proof. This follows from the security guarantees of the garbled circuit itself. Since the output of the circuit in the
real world matches the output of the trusted third party in the ideal world, B∗ learns nothing from the output received.
Since the output produced by replacing Alice’s input with random inputs is never returned to B∗, he cannot distinguish
between Alice’s real inputs and the random inputs. Finally, since Cloud’s input is two pseudorandom strings in the
real protocol, it is statistically indistinguishable from the experiment’s choice of z(cid:48). Thus, indistinguishability holds
even when z(cid:48) is revealed in the output release phase.
Lemma 5. Hybrid4(B)(k, x; r) runs in polynomial time.
Proof. This follows trivially from the fact that the main protocol runs in polynomial time. Since the experiment does
not perform any additional actions beyond the main protocol, it also runs in polynomial time.
Hybrid4(B)(k, x; r) is identical to the simulator SB running in the ideal world. The simulator runs B∗ and
controls Alice and Cloud. If any of the consistency checks fails, SB terminates the protocol. Otherwise, it delivers
B∗s input to the trusted third party in Hybrid3(B)(k, x; r), and outputs whatever B∗ outputs. By Lemma 1-5, this
simulator proves Theorem 1 when the mobile device is malicious (scenario 2).
A.3 Malicious cloud C∗
Consider when Cloud can perform arbitrary malicious actions while Alice and Bob follow the protocol in a semi-
honest manner. We construct a simulator SC in the ideal world to simulate Cloud’s view of a real execution of the
protocol. Note that since the simulator does not have the other parties’ inputs, nor does it know what input the ma-
licious C∗ will use. Thus, the inputs, commitments, and circuits generated by the cloud must be checked, and the
oblivious transfers must be simulated. Consider the following hybrid of experiments.
Hybrid1(C)(k, x; r): This experiment is identical to the experiment REAL(C)(k, x; r) except that instead of
running the circuit oblivious transfers, the experiment invokes the simulator SOT , which recovers both of C∗s inputs
to the oblivious transfer (i.e., the random coins {ρ(j)}j∈σ and the commitment keys {ξ(j)}j∈σ).
Lemma 6. REAL(C)(k, x; r)
c≈ Hybrid1(C)(k, x; r)
Proof. Based on the malicious security of the oblivious transfer primitive, we know that SOT exists. The proof of this
lemma follows directly from Lemma G.7 in shelat and Shen’s security proof [37].
Hybrid2(C)(k, x; r): This experiment is identical to the experiment Hybrid1(C)(k, x; r) except that if more than
σ/5 circuits are incorrectly constructed, then the experiment aborts.
c≈ Hybrid2(C)(k, x; r)
Lemma 7. Hybrid1(C)(k, x; r)
Proof. For a circuit to be incorrectly constructed means that the commitments {Θ(j), Ω(j), Φ(j), Ψ(j)} and the circuit
G(C)(j), for j ∈ σ, cannot be reconstructed given the objective circuit C and the randomness ρ(j). Again, this lemma
follows directly from Lemma G.8 in shelat and Shen’s proof [37].
Hybrid3(C)(k, x; r): This experiment is identical to the experiment Hybrid2(C)(k, x; r) except that the experi-
ment will abort if C∗s private inputs cannot be recovered for at least σ/5 of the evaluation circuits.
Lemma 8. Hybrid2(C)(k, x; r)
c≈ Hybrid3(C)(k, x; r)
19
Proof. From the previous lemma, we know that 4σ/5 of the circuits are correctly constructed. This implies that of
the 2σ/5 circuits chosen to be evaluated, at least σ/5 are “good” circuits. Let these “good” circuits be denoted as G,
where |G| ≥ σ/5. Assume for contradiction that there is some j ∈ G where z∗(j) cannot be recovered. The only
possible way that the experiment will not uncover the value for some z∗(j) is if {ψ(j)
}i∈[mc], when decommitted
i,z∗
from Ξ(j) using ξ(j) correctly decommits the i ⊕ 1 half of Ψ(j), which happens with negligible probability based on
the binding property of the commitment. Otherwise, at least one of the two commitments Ξ(j) or Ψ(j)
i must fail to
decommit, in which case both experiments abort.
i
Hybrid4(C)(k, x; r): This experiment is identical to the experiment Hybrid3(C)(k, x; r) except that the experi-
ment aborts if any of C∗s inputs to the good circuits in G is inconsistent.
Lemma 9. Hybrid3(C)(k, x; r)
c≈ Hybrid4(C)(k, x; r)
Proof. Informally, this proof follows from the 2-universal hash check used in the circuit. This lemma follows directly
from Lemma G.10 in shelat and Shen’s proof [37].
Hybrid5(C)(k, x; r): This experiment is identical to the experiment Hybrid4(C)(k, x; r) except that the experi-
ment chooses a random input for Alice y(cid:48) and computes y(cid:48) such that M · y(cid:48) = y(cid:48) and uses that as input to the input
oblivious transfers.
Lemma 10. Hybrid4(C)(k, x; r)
c≈ Hybrid5(C)(k, x; r)
Proof. Informally, this proof follows from the choose security of the OT primitive. This lemma follows directly from
Lemma G.14 in shelat and Shen’s proof [37].
Hybrid6(C)(k, x; r): This experiment is identical to the experiment Hybrid5(C)(k, x; r) except that the experi-
ment chooses a random input for Bob x(cid:48) and computes x(cid:48) by concatenating random strings e(cid:48) and r(cid:48) to x(cid:48) and uses
these inputs as input to the computation.
c≈ Hybrid6(C)(k, x; r)
Lemma 11. Hybrid5(C)(k, x; r)
Proof. Because C∗ never receives Bob’s inputs in any form, or output from the computation, he cannot distinguish
between using Bob’s real inputs and random inputs chosen by the experiment. Since C∗ only ever sees Bob’s in-
put commitment keys {γ(j)}j∈σ, which are pseudorandom strings in both experiments, these strings are statistically
indistinguishable as well.
Hybrid7(C)(k, x; r): This experiment is identical to the experiment Hybrid6(C)(k, x; r) except that the simulator
runs the function f (x(cid:48), y(cid:48)) for the inputs randomly chosen in the previous lemma. If f1(x(cid:48), y(cid:48))⊕e∗⊕pb and f2(x(cid:48), y(cid:48))⊕
pa do not match a majority of the evaluation outputs, the experiment aborts.
c≈ Hybrid7(C)(k, x; r)
Lemma 12. Hybrid6(C)(k, x; r)
Proof. This follows trivially from the fact that at least σ/5 circuits are correctly constructed and that C∗s inputs to
those circuits are consistent. Thus, the majority output will be exactly f1(x(cid:48), y(cid:48)) ⊕ e∗ ⊕ pb and f2(x(cid:48), y(cid:48)) ⊕ pa.
Hybrid8(C)(k, x; r): This experiment is identical to the experiment Hybrid7(C)(k, x; r) except that when C∗
returns the one-time pads w∗ in the output release, the experiment aborts if w∗ (cid:54)= z∗, where z∗ is the consistent input
to the good circuits in G. Otherwise, the experiment sends z∗ to the trusted third party as C∗s input.
c≈ Hybrid8(C)(k, x; r)
Lemma 13. Hybrid7(C)(k, x; r)
Proof. This follows from the collision-resistance of the 2-universal hash family. C∗ can only return a value w∗ such
that H · w∗ = H · z∗ with negligible probability, and so the experiments are indistinguishable.
Lemma 14. Hybrid8(C)(k, x; r) runs in polynomial time.
Proof. This follows trivially from the fact that the main protocol runs in polynomial time. Since the experiment only
evaluates f (·,·) (which is also polynomial time) in addition to the main protocol, it also runs in polynomial time.
20
Hybrid8(C)(k, x; r) is identical to the simulator SC running in the ideal world. The simulator runs C∗ and controls
Alice and Bob. If any of the consistency checks fails, SC terminates the protocol. Otherwise, it delivers C∗s input to
the trusted third party when it is completes Hybrid8(B)(k, x; r), and outputs whatever C∗ outputs. By Lemma 6-14,
this simulator proves Theorem 1 when Cloud is malicious (scenario 1).
A.4 Malicious and colluding mobile device and cloud BC∗
Consider when Bob and Cloud can perform arbitrary malicious actions and share arbitrary information while Alice
follows the protocol in a semi-honest manner. We observe that this scenario is equivalent to a malicious generator P ∗
1
in shelat and Shen’s proof of security [37], with some modiﬁcations to the lemmas to account for communicating with
two parties and to account for Cloud’s added input. We also note that in this scenario, the malicious and colluding
BC∗ may terminate the protocol early, preventing Alice from receiving her output. However, this is possible on the
evaluator’s side in shelat and Shen’s protocol, so we consider fair release a separate guarantee from security. We
describe the changes to each hybrid experiment in shelat and Shen’s proof below, as well as noting slight changes to
the proofs of each lemma.
Hybrid1(BC)(k, x; r): This experiment is identical to the experiment REAL(BC)(k, x; r) except that instead of
running the circuit oblivious transfers, the experiment invokes the simulator SOT , which recovers both of C∗s inputs
to the oblivious transfer (i.e., the random coins {ρ(j)}j∈σ and the commitment keys {γ(j)}j∈σ,{ξ(j)}j∈σ).
The proof of this hybrid follows directly from shelat and Shen, only it is extended to recover the commitments to
C∗s input as well as B∗s.
Hybrid2(BC)(k, x; r): This experiment is identical to the experiment Hybrid1(BC)(k, x; r) except that if more
than σ/5 circuits are incorrectly constructed, then the experiment aborts.
Again, this follows directly from shelat and Shen. However, the commitments to the Cloud’s input wires {Ψ(j)}j∈σ
must also be checked.
Hybrid3(BC)(k, x; r): This experiment is identical to the experiment Hybrid2(BC)(k, x; r) except that the exper-
iment will abort if both B∗ and C∗s private inputs cannot be recovered for at least σ/5 of the evaluation circuits.
Lemma 15. Hybrid2(BC)(k, x; r)
c≈
Hybrid3(BC)(k, x; r)
Proof. This lemma holds in the same manner as Lemma 8 when only the Cloud is malicious. Since the commitments
Θ(j) and Ψ(j) are constructed correctly, the only way that the input of either B∗ or C∗ cannot be recovered is if the
decommited values from Γ(j) and Ξ(j) decommitted the wrong halves of the commitments Θ(j) and Ψ(j) respectively.
This would imply that B∗ or C∗ was able to break the binding property of the commitment, which can only happen
with negligible probability.
Hybrid4(BC)(k, x; r): This experiment is identical to the experiment Hybrid3(BC)(k, x; r) except that the exper-
iment aborts if any of B∗ or C∗s inputs to the good circuits in G are inconsistent.
Again, this follows directly from shelat and Shen, expanded to handle the inputs of both malicious parties.
Hybrid5(BC)(k, x; r): This experiment is identical to the experiment Hybrid4(BC)(k, x; r) except that the input
recovered in the previous hybrid, x∗ = x∗||r∗||e∗ and z∗ = p∗
b are forwarded to the trusted third party, which re-
turns f (x∗, y, z∗). The experiment aborts if the majority output of the computation does not match fb(x∗, y)⊕ e∗⊕ pb.
a||p∗
Here we extend shelat and Shen to include the input from Cloud, which is added in as a blind to the output of
computation in the real protocol.
Hybrid6(BC)(k, x; r), Hybrid7(BC)(k, x; r),
Hybrid8(BC)(k, x; r): These hybrid experiments are identical to the hybrids in shelat and Shen’s proof. So, we
invoke them directly and the proofs follow as they are in the two-party case.
Finally, we demonstrate that in the ﬁnal step of the Whitewash protocol, the output release, that early termination
a. That is, Alice will always detect an
by B∗ or C∗ is functionally the same as C∗ returning an incorrect value for p∗
early termination, and will always detect an incorrect value of p∗
a except for a negligible probability.
21
Circuit
Hamming (1600)
Hamming (16384)
Matrix (3x3)
Matrix (5x5)
Matrix (8x8)
Matrix (16x16)
Dijkstra’s 10
Dijkstra’s 20
Dijkstra’s 50
RSA-256
WW
95.57 ± 0.48
941.15 ± 11.07
12.04 ± 0.26
35.62 ± 1.01
108.54 ± 3.55
620.34 ± 13.83
62.53 ± 2.69
181.55 ± 10.06
881.19 ± 37.97
30,872.58 ± 1,148.69
Timing (Seconds)
CMTB
453.36 ± 2.32
1,335.75 ± 3.69
493.28 ± 2.90
543.67 ± 4.23
702.13 ± 6.14
2,263.86 ± 108.27
532.55 ± 5.18
752.40 ± 3.58
1,800.47 ± 50.27
x
KSS
2614.04 ± 7.08
x
x
x
x
x
x
x
x
x
Reduction Over
CMTB
KSS
78.92% 96.34%
29.54%
97.56%
93.45%
84.54%
72.60%
88.26%
75.87%
51.06%
x
x
x
x
x
x
x
x
x
x
Table 4: Execution time (in seconds) for all tested circuits. Results with an ‘x’ indicate that a protocol was not able to
evaluate that circuit.
Lemma 16. The probability of catching a malformed p∗
termination.
Proof. Since the output fa(x∗, y) ⊕ p∗
then the output of the hash H · p∗
release. By the guarantees of a 2-universal hash, the probability that H · p∗
a was generated by a good circuit and C∗s input to that circuit was consistent,
a is correctly computed. Thus, let pa be the value that C∗ returns during the output
a is computationally indistinguishable from catching early
a = H · pa is negligible.
Given these changes to the simulator S1 in shelat and Shen’s proof, the modiﬁed simulator SBC proves Theorem 1
(without the fair release guarantee) when the mobile device and Cloud are malicious and colluding (scenario 3).
B Experiment Results
In Table 4 we provide full experimental timings for all three of the evaluated test circuits with 95% conﬁdence intervals.
For all Hamming Distance and Matrix Multiplication circuits, the execution times are averaged over 10 trials. For
RSA-256, we ran 3 executions.
22