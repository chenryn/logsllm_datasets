 1400
 1200
 1000
 800
 600
 400
 200
t
n
u
o
c
n
a
m
o
D
i
t
n
u
o
c
i
n
a
m
o
D
 0
 0
 2
 4
 6
 8
 10
 12
 14
Days
(b)
Figure 5: The ﬁrst time a domain is queried and the ﬁrst
time it is detected
net command and control servers. We do not only focus on
detecting Fast-Flux service networks.
A second branch of study that aims to detect malicious
domains [27, 36] leverages active DNS probing methods.
That is, the domains that are advertised to be malicious by
various sources (e.g. spam mails) are repeatedly queried to
detect the abnormal behavior. The main drawback of ac-
tive DNS analysis is the possibility of being detected by the
miscreants who manage the domains under analysis. Pas-
sive DNS analysis, in comparison, is more stealthy because
of its non-intrusiveness characteristics.
Based on URL features they extract from spam mails,
Ma et. al. [27] study a number of statistical methods for ma-
chine learning for classifying websites. In particular, they
analyze spam URLs according to their lexical construction,
and the information contained in the host name part of the
URL. To obtain the information from the host name, they
perform active probing to determine the number of IP ad-
dresses associated with the domain. Once they obtain the
IP address list, they analyze the location of the IP address
and to which ANS it belongs to. The main limitation of
this system is that it performs the analysis only based on the
domains that are included in spam mails. Hence, the sys-
tem cannot see other classes of malicious domains such as
command and control servers.
Another type of study on detecting malicious domains
leverages properties inherent to domain registrations and
their appearance in DNS zone ﬁles [20]. That is, they as-
sociate the registration information and DNS zone proper-
ties of domains with the properties of known blacklisted do-
mains for proactive domain blacklisting. This method com-
pletely relies on historical information. Therefore, it is not
able to detect domains that do not have any registration in-
formation and DNS zone commonalities with known black-
listed domains. On the other hand, our work, which does
not require any historical information, is able to detect such
domains.
6.2
Identifying Infected Machines by Monitoring
Their DNS Activities
In [16], the authors propose an anomaly-based botnet de-
tection mechanisms by monitoring group activities in the
DNS trafﬁc of a local network. The authors claim that
there exist distinguishing features to differentiate DNS traf-
ﬁc generated by botnets and benign clients. Similarly, [38]
also attempts to identify botnet DNS access behavior in a
local network. The authors use a bayesian algorithm. In
comparison to these existing works, we aim to identify ma-
licious domains from DNS trafﬁc in general, and do not
only focus on botnets.
6.3 Generic Identiﬁcation of Malicious Domains
Using Passive DNS Monitoring
To date, only one system has been proposed that aims to
detect malicious domains using passive DNS analysis. In
a concurrent and independent work very recently presented
by Antonakakis et al. [11], the authors present Notos. No-
tos dynamically assigns reputation scores to domain names
whose maliciousness has not been discovered yet.
We have compared EXPOSURE with Notos in Sec-
tion 5.5.2. EXPOSURE eliminates several shortcomings
of Notos. It does not require a wide overview of malicious
activities on the Internet, a much shorter training time, and
is able to classify domains that Notos would miss-classify.
7 Limitations
A determined attacker who knows how EXPOSURE
works and who is informed about the features we are look-
ing for in DNS trafﬁc might try to evade detection. To evade
EXPOSURE, the attackers could try to avoid the speciﬁc
features and behavior that we are looking for in DNS traf-
ﬁc. For example, an attacker could decide to assign uniform
TTL values across all compromised machines. However,
this would mean that the attackers would not be able to dis-
tinguish between more reliable, and less reliable hosts any-
more and would take a reliability hit on their malicious in-
frastructures. As another example, the attackers could try to
reduce the number of DNS lookups for a malicious domain
so that only a single lookup is performed every hour (i.e.,
so that the malicious domain is blacklisted). However, this
is not trivial to implement, reduces the attack’s impact, and
requires a high degree of coordination on the attacker’s side.
Even though it is possible for an attacker to stay below our
detection radar by avoiding the use of these features, we be-
lieve that this comes with a cost for the attacker. Hence, our
systems helps increase the difﬁculty bar for the attackers,
forces them to abandon the use of features that are useful
for them in practice, and makes it more complex for them
to manage their infrastructures.
Clearly, our detection rate also depends on the training
set. We do not train for the family of malicious domains
that constitute attacks that are conceptually unknown and
have not been encountered before in the wild by malware
analyzers, tools, or experts. However, the more malicious
domains are fed to the system, the more comprehensive our
approach becomes over time.
Note that if the networks that we are monitoring and
training our system on are not infected, obviously, we will
not see any malicious domains. We believe that we can im-
prove our ability to see more malicious attacks by having
access to larger networks and having more installations of
EXPOSURE.
8 Conclusions
The domain service (DNS) is a crucial component of the
Internet. DNS provides a two-way mapping between do-
main names and their IP addresses. Just as DNS is a crit-
ical service for the functioning of benign Internet services,
it has also started to play an important role for malicious
activities. For example, bots resolve DNS names to locate
their command and control servers, and spam mails contain
URLs that link to domains that resolve to scam servers.
In this paper, we introduced EXPOSURE, a system that
employs passive DNS analysis techniques to detect mali-
cious domains. Our thesis is that it is beneﬁcial to mon-
itor the use of the DNS system on a large-scale for signs
that indicate that a certain name is used as part of a ma-
licious operation. Our experimental results show that our
approach works well in practice, and that it is useful in auto-
matically identifying a wide category of malicious domains
such as botnet command and control servers, phishing sites,
and scam hosts. Compared to related work, our approach
is generic, and does only focus on a speciﬁc class of threat
(e.g., such as Fast-Flux botnets).
We believe that EXPOSURE is a useful system that can
help security experts and organizations in their ﬁght against
cyber-crime. As future work, we plan to release EXPO-
SURE to the public as a community service.
9 Acknowledgments
The research leading to these results has received
funding from the European Union Seventh Framework
Programme (FP7/2007-2013) under grant agreement no
257007. This work has also been supported in part by Se-
cure Business Austria, the European Commission through
project IST-216026-WOMBAT funded under the 7th frame-
work program, by the ONR under grant N000140911042
and by the National Science Foundation (NSF) under grants
CNS-0845559 and CNS-0905537. We thank the Inter-
net Security Consortium Security Information Exchange
project (ISC@SIE) for providing portion of the DNS data
used in our experiments. Additionally, we thank the Uni-
versity of Bergamo for providing access to their DNS trafﬁc
during the early phases of this work.
References
[1] RFC 1794 - DNS Support for Load Balancing. http:
//tools.ietf.org/html/rfc1794, 1995.
[2] RFC1834 - Whois and Network Information Lookup
http://www.faqs.org/
Service, Whois++.
rfcs/rfc1834.html, 1995.
[3] RFC 1912 - Common DNS Operational and Conﬁg-
uration Errors. http://www.faqs.org/rfcs/
rfc1912.html, 1996.
[4] Alexa Web Information Company. http://www.
alexa.com/topsites/, 2009.
[5] DNSBL - Spam Database Lookup. http://www.
dnsbl.info/, 2010.
[6] Google Safe Browsing. http://www.google.
com/tools/firefox/safebrowsing/, 2010.
[7] Internet Systems Consortium.
isc.org/, 2010.
https://sie.
[8] McAfee
SiteAdvisor.
siteadvisor.com/, 2010.
http://www.
[9] Norton Safe Web. http://safeweb.norton.
com/, 2010.
[10] B. Amini. Kraken Botnet Inﬁltration. http://
dvlabs.tippingpoint.com/blog/2008/
04/28/kraken-botnet-infiltration,
2008.
[11] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and
N. Feamster. Building a Dynamic Reputation System
for DNS. In 19th Usenix Security Symposium, 2010.
[12] Michle Basseville and Igor V. Nikiforov. Detection of
Abrupt Changes - Theory and Application. Prentice-
Hall, 1993.
[13] Ulrich Bayer, Christopher Kruegel, and Engin Kirda.
TTAnalyze: A Tool for Analyzing Malware. In 15th
EICAR Conference, Hamburg, Germany, 2006.
[14] Pavel Berkhin. Survey of clustering data mining tech-
niques. Technical report, 2002.
[15] A. P. Bradley. The use of the area under the ROC curve
in the evaluation of machine learning algorithms. In
Pattern Recognition, volume 30, pages 1145–1159,
1997.
[16] H. Choi, H. Lee, and H. Kim. Botnet detection by
In 7th
monitoring group activities in DNS Trafﬁc.
IEEE International Conference on Computer and In-
formation Technologies, 2007.
[17] Selina Chu, Eamonn Keogh, David Hart, Michael Paz-
zani, and Michael. Iterative deepening dynamic time
warping for time series. In In Proc 2 nd SIAM Inter-
national Conference on Data Mining, 2002.
[18] M. Cova.
Wepawet.
iseclab.org/.
http://wepawet.
[19] Malware Domains. Malware Domain Block List.
http://www.malwaredomains.com/, 2009.
[20] Mark Felegyhazi, Christian Kreibich, and Vern Pax-
son. On the potential of proactive domain blacklist-
ing. In Proceedings of the Third USENIX Workshop on
Large-scale Exploits and Emergent Threats (LEET),
San Jose, CA, USA, April 2010.
[21] F. Freiling, T. Holz, and G. Wicherski. Botnet Track-
ing: Exploring a Root-Cause Methodology to Prevent
Distributed Denial-of-Service Attacks. In 10th Euro-
pean Symposium On Research In Computer Security,
2005.
[22] A. Karasaridis, B. Rexroad, and D. Hoeﬂin. Wide-
scale Botnet Detection and Characterization.
In
Usenix Workshop on Hot Topics in Understanding
Botnets, 2007.
[23] E. Keogh, K. Chakrabarti, M. Pazzani, and S. Mehro-
tra. Locally adaptive dimensionality reduction for in-
dexing large time series databases. In ACM SIGMOD
Conference on Management of Data, pages 151–162,
2001.
[24] M. Konte, N. Feamster, and J. Jung. Dynamics of on-
line scam hosting infrastructure. In In Passive and Ac-
tive Measurement Conference, 2009.
[25] Malware Domains List. Malware Domains List.
http://www.malwaredomainlist.com/
mdl.php, 2009.
[26] Zeus Block List. Zeus domain blocklist. https:
//zeustracker.abuse.ch/blocklist.
php?download=domainblocklist, 2009.
[27] Justin Ma, Lawrence K. Saul, Stefan Savage, and Ge-
offrey M. Voelker. Beyond blacklists: Learning to
detect malicious web sites from suspicious urls.
In
Proceedingsof theSIGKDD Conference. Paris,France,
2009.
[28] J. Nazario and T. Holz. As the net churns: Fast-ﬂux
In International Conference on
botnet observations.
Malicious and Unwanted Software, 2008.
[29] E. Passerini, R. Paleari, L. Martignoni, and D. Br-
uschi. Fluxor: Detecting and monitoring fast-ﬂux ser-
vice networks.
In Detection of Intrusions and Mal-
ware, and Vunerability Assessment, 2008.
[30] R. Perdisci, I. Corona, D. Dagon, and W. Lee. De-
tecting Malicious Flux Service Networks through Pas-
sive Analysis of Recursive DNS Traces.
In 25th
Annual Computer Security Applications Conference
(ACSAC), 2009.
[31] Phishtank. Phishtank. http://www.phishtank.
com/, 2009.
[32] P. Porras, H. Saidi, and V. Yegneswaran. A Foray
In
into Conﬁcker’s Logic and Rendezvous Points.
In USENIX Workshop on Large-Scale Exploits and
Emergent Threats, 2009.
[33] J.R. Quinlan. Learning with continuous classes. Pro-
ceedings of the 5th Australian joint Conference on Ar-
tiﬁcial Intelligence, Singapore: World Scientiﬁc:343 –
348, 1995.
[34] B. Stone-Gross, M. Cova, L. Cavallaro, B. Gilbert,
M. Szydlowski, R. Kemmerer, C. Kruegel, and G. Vi-
gna. Your botnet is my botnet: Analysis of a botnet
takeover. In ACM Conference on Computer and Com-
munication Security (CCS), 2009.
[35] S. Theodoridis and K. Koutroumbas. Pattern Recog-
nition. Academic Press, 2009.
[36] T.Holz, C. Gorecki, K. Rieck, and F.C. Freiling. Mea-
suring and Detecting Fast-Flux Service Networks. In
Annual Network and Distributed System Security Sym-
posium (NDSS), 2008.
[39] F. Weimer. Passive DNS Replication. In FIRST Con-
ference on Computer Security Incident, 2005.
[40] IH. Witten and E. Frank. Data Mining: Practical Ma-
chine Learning Tools and Techniques. Morgan Kauf-
mann, 2005.
[41] J. Wolf. Technical details of Srizbis domain genera-
tion algorithm. http://tinyurl.com/6mdasc,
2008.
[42] B. Zdrnja, N. Brownlee, and D. Wessels. Passive Mon-
itoring of DNS anomalies. In DIMVA, 2007.
[37] D. Turaga, M. Vlachos, and O. Verscheure. On
K-Means Cluster Preservation using Quantization
Schemes. In IEEE International Conference on Data
Mining, ICDM09, 2009.
[43] H. Zitouni, S. Sevil, D. Ozkan, and P. Duygulu. Re-
ranking of Image Search Results using a Graph Al-
gorithm. In 9th International Conference on Pattern
Recognition, 2008.
[38] R. Villamarn-Salomn and J. C. Brustoloni. Bayesian
bot detection based on DNS trafﬁc similarity.
In
SAC’09: ACM symposium on Applied Computing,
2009.