Log Size of Sample Datasets
| BGL | 400 | 4k | 40k | 400k | 4m |
|---|---|---|---|---|---|
| HPC |600 |3k |15k |75k |375k |
| HDFS |1k |10k |100k |1m |10m |
| Zookeeper |4k |8k |16k |32k |64k |
| Proxifier |600 |1200 |2400 |4800 |9600 |
presented in Table 3 employing these parameters. Theresults show that IPLoM performs consistently in most     
cases except a 0.15 drop on Proxifier. SLCT varies a lot on HPC and Proxifier. The accuracy of LKE is volatile in Zoo-keeper because of its aggressive clustering strategy. LogSig obtains consistent accuracy on datasets with limited types of events, but its accuracy fluctuates severely on datasets with many log events (i.e., BGL and HPC).Findings. Parameter tuning is time-consuming for exist-ing log parsing methods except IPLoM, because they could not directly use parameters tuned on small sampled data for large datasets.The experimental results of POP are shown in Table 4 and Fig. 6. We observe that the accuracy of POP is very consistent for all datasets. The accuracy on Zookeeper is 0.99 for all 5 sampling levels, which indicates the parameters tuned on 2k sample dataset lead to nearly the same parsing results. For HPC, HDFS and Proxifier, the fluctuation of the accuracy is at most 0.02, while the accuracy is at least 0.95. For BGL, the accuracy has a 0.1 drop for the last two sampling levels. But POP can still obtain 0.89 accuracy in these two levels, while 0.1 is not a large drop compared with existing parsers in Fig. 6. Compared with existing methods, POP is the only parser that obtains high accuracy consistently on all datasets using the parameters tuned on small sampled data.4.3 	Efficiency of Log Parsing Methods
In this section, we evaluate the efficiency of all five log pars-ing methods. Specifically, we first measure the running time of these log parsers on 25 sampled datasets with varying number of log messages (i.e., log size) in Table 3. Second, we evaluate the running time of these log parsers on synthetic datasets containing over 200 million log messages, which is comparable to large-scale modern production systems [13].Note that running time in this paper means the time used to run log parsers (i.e., training time). In addition to training time, we measure the efficiency for parsing a new log mes-sage, which is 173 ms for BGL, 108 ms for HPC, 36 ms for HDFS, 29 ms for Zookeeper, and 20 ms for Proxifier. The matching process relies on regular expressions, thus its time depends on the number of log events and their lengths. The matching time is similar for different log parsers.4.3.1 Running Time on Real-World Datasets Fig. 6. Parsing accuracy on datasets in different size.
In Fig. 7, we evaluate the running time of the log parsing
methods on all datasets by varying the number of raw log messages (i.e., log size). Notice that as the number of raw log messages increases, the number of events becomes larger as well (e.g., 60 events in BGL400 while 206 events in BGL40k). Fig. 7 is in logarithmic scale, so we can observethe time complexity of these log parsers from the slope of the lines. As show in the figure, the running time of SLCT and IPLoM scale linearly with the number of log messages. They both could parse 10 million HDFS log messages within five minutes. However, as the slopes show, their running
HE ET AL.: TOWARDS AUTOMATED LOG PARSING FOR LARGE-SCALE LOG DATA ANALYSIS 	939
TABLE 4TABLE 4 
Parsing Accuracy of POP on Sample Datasets in Table 3 with Parameters Tuned on 2k Datasets
| BGL | 0.98 | 0.99 | 0.99 | 0.89 | 0.89 |
|---|---|---|---|---|---|
| HPC |0.95 |0.97 |0.96 |0.96 |0.97 |
| HDFS |1.00 |0.99 |0.99 |0.99 |0.99 |
| Zookeeper |0.99 |0.99 |0.99 |0.99 |0.99 |
| Proxifier |1.00 |1.00 |1.00 |0.99 |0.99 |
time increases fast as the log size becomes larger, becausethey are limited by the computing power of a single com-puter. The fast increasing speed can lead to inefficient pars-ing on production level log data (e.g., 200 million log messages). The running time of LogSig also scales linearly with the number of log messages. However, it requires much running time (e.g, 2+ hours for 10m HDFS log mes-sages), because its clustering iterations are computation-intensive and its word pair generation step is time-consum-ing. The time complexity of LKE is Oðn2Þ, where n is the number of raw log messages, which makes it unable to han-dle some real-world log data, such as BGL4m and 
HDFS10m. Running time of some LKE experiments is not plotted because LKE could not terminate in reasonable time (i.e., days or even weeks).
Findings. Clustering-based log parsers require much run-ning time on real-world datasets. Heuristic rule-based log parsers are more efficient, but their running time increases fast as the log size becomes larger. These imply the demand for parallelization.| The time complexity of POP is OðnÞ, where n is the num-ber of raw log messages. In step 1, step 2 and step 4, POP |  |  |  |  |  |
|---|---|---|---|---|---|
| The time complexity of POP is OðnÞ, where n is the num-ber of raw log messages. In step 1, step 2 and step 4, POP | | | | | |traverses all log messages once so the time complexity for these steps are all OðnÞ. In step 3, POP may scan some log messages more than once due to recursion. However, in the case of log parsing, the recursion depth can be regarded as a constant because it will not increase as the number of log messages, which remains small in all our datasets. Thus, the time complexity of step 3 is also OðnÞ. Finally, the time com-plexity of step 5 is Oðm2log mÞ, where m is the number of log events. We do not consider it in the time complexity of POP, because m is far less than n. So the time complexity of POP is Oðn þ n þ n þ n þ m2log mÞ ¼ OðnÞ.The “SinglePOP” lines represent the running time of the nonparallel implementation of POP on different datasets. We can observe that the running time of SinglePOP is even shorter than the parallel implementation of POP. Because the nonparallel implementation of POP does not require any data transportation between nodes, which is required by parallel programs. Besides, the parallel implementation needs to deploy the runtime environment (e.g., set up the nodes that will be used) at the beginning, though automati-cally, will cost some constant time.The experimental results of POP are presented in Table 5 and Fig. 7. Fig. 7 shows that POP has the slowest increasing speed of running time as the log size becomes larger. Its increasing speed is even much better (i.e., slower) than lin-ear parsers (i.e., SLCT, IPLoM, LogSig). For a few cases, the running time of POP even decreases when the log size becomes larger. This is mainly caused by two reasons. First,Fig. 7. Running time of log parsing methods on datasets in different size.
a larger dataset could benefit more from parallelization than a smaller one. Second, it is possible that a smaller data-set requires deeper recursion in step 3 of POP, which increases its running time. Compared with the existing methods, POP enjoys the slowest running time increase940 	IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, 	VOL. 15, 	NO. 6, 	NOVEMBER/DECEMBER 2018
TABLE 5	
Running Time of POP (Sec) on Sample Datasets in Table 3
| BGL | 71.87 | 134.48 | 271.98 | 268.12 | 527.63 |
|---|---|---|---|---|---|
| HPC |46.24 |61.29 |83.81 |119.81 |234.92 |
| HDFS |19.82 |19.17 |29.14 |41.03 |100.58 |
| Zookeeper |69.62 |72.22 |60.07 |75.56 |90.69 || Proxifier |18.00 |16.08 |16.60 |21.07 |24.22 |
because of its OðnÞ time complexity and its parallelization mechanism. It can parse a large amount of log messages very fast (e.g., 100 seconds for 10 million HDFS log mes-sages). Although its running time is slower than IPLoM and SLCT in some cases, POP turns out to be more efficient for two reasons. First, as we can observe from Fig. 7, the run-ning time increase of POP is the slowest, so POP will be faster than other log parsers when log size is larger. For example, POP is faster than IPLoM on 10m HDFS dataset. Second, the efficiency of IPLoM and SLCT is limited by computing power or/and memory of single computer,while POP is able to utilize multiple computers.    
4.3.2 Running Time on Large-Scale Synthetic Datasets Fig. 8. Running time on synthetic datasets.
In this section, we evaluate the running time of log parserson very large synthetic datasets, which are randomly gener-ated from BGL and HDFS. These two datasets are represen-tative because they include log datasets with a lot and a few log events respectively. BGL has more than 300 log events, while HDFS has 29. The synthetic datasets are generated from the real-world datasets. For example, to generate a 200m synthetic dataset from HDFS dataset, we randomly select a log message from the dataset each time, and repeat this random selection process 200 million times. Fig. 8 presents the experimental results in linear scale.In this figure, a result is neglected if its running time is larger than one hour, because we want to evaluate the effec-datasets because they require more recursive partitioning in step 3. We set 16G memory because this is a typical memory setting for a single computer. We observe that POP has the slowest growth speed among all three methods. Besides, POP requires the least running time for HDFS datasets. Though SLCT requires less time for BGL datasets, its run-ning time increases faster than POP, which is shown by their comparable results on 200m log message dataset gen-erated from BGL. Thus, POP is the most suitable log parser for large-scale log analysis, given that the size of logs will become even larger in the future.tiveness of these log parsers in production environment 4.4 Effectiveness of Log Parsing Methods on Log
(e.g., 120200 million log messages per hour [13]). Thus, experimental results of SLCT, IPLoM and POP are plotted, while LKE and LogSig require more than one hour on these datasets. The running time increase of IPLoM is the fastest among the plotted three. It requires more than an hour for two datasets generated from HDFS; therefore, they are not plotted. Besides, IPLoM requires more than 16G memory when the synthetic dataset contains 30m or more log mes-sages for both BGL and HDFS. Because IPLoM needs to loadMining: A Case Study
Log mining tasks usually accept structured data (e.g., matrix) as input and report mining results to developers, as described in Fig. 1. If a log parser is inaccurate, the gener-ated structured logs will contain errors, which can further ruin the input matrix of subsequent log mining tasks. A log mining task with erroneous input tends to report biased results. Thus, log parsing should be accurate enough to ensure the high performance of subsequent log miningthe whole dataset into memory, and it creates extra data of 	tasks.
comparable size in runtime. SLCT is more efficient than IPLoM, and it requires the least time on BGL datasets. SLCT only requires two passes across all log data, and it is imple-mented in C instead of Python. However, its running time increases fast as the log size becomes larger, because SLCT is limited by the computing power of single computer.Findings. Clustering-based log parsers cannot handle large-scale log data. Heuristic rule-based log parsers are efficient, but they are limited by the computing power or/ and memory of a single computer.
For POP, we use 64 executors on BGL datasets and 16 executors on HDFS datasets, each of which has 16G memory and 5 executor cores. We use more executors on BGLTo evaluate the effectiveness of log parsing methods on log mining, we apply different log parsers to tackle the pars-ing challenge of a real-world anomaly detection task. This task employs Principal Component Analysis (PCA) to detect anomalies. Due to the space limit, the technical details of this anomaly detection task is described in our supplementary report [24]. There are totally 16,838 anomalies in this task, which are found manually in [3]. We re-tune the parameters of the parsers for better parsing accuracy. LKE is not employed because it could not handle this large amount of data (10m+ lines) in reasonable time. Table 6 demonstrates the evaluation results. Reported anomaly is the number of anomalies reported by log mining model (i.e., PCA) while adopting different log parsers in the log parsing step.HE ET AL.: TOWARDS AUTOMATED LOG PARSING FOR LARGE-SCALE LOG DATA ANALYSIS 	941
TABLE 6 
Anomaly Detection with Different Log Parsing Methods (16,838 Anomalies)
| Parsing | Reported | Detected | False |
|---|---|---|---|
| Accuracy |Anomaly |Anomaly |Alarm |
| SLCT | 0.83 | 18,450 | 10,935 (64%) 7,515 (40%) | 10,935 (64%) 7,515 (40%) |  |  |
|---|---|---|---|---|---|---||---|---|---|---|---|---|---|
| LogSig |0.87 |11,091 |10,678 (63%) |413 (3.7%) |Fig. 9. Impact of GS |Fig. 9. Impact of GS |
| IPLoM |0.99 |10,998 |10,720 (63%) |278 (2.5%) |splitRel to 0.1, splitAbs to 10, maxDistance to 0. We observe |splitRel to 0.1, splitAbs to 10, maxDistance to 0. We observe |