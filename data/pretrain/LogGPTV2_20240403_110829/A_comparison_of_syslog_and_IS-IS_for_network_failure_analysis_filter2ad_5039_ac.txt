### 4.3 Syslogâ€™s False Positives

Most of the statistical properties of failures reported by syslog closely match those reported by IS-IS, but a few, such as individual failure duration, do not. In this section, we examine the causes of these discrepancies and explore data filtering mechanisms that can be applied to improve the accuracy of syslog-reported statistics.

**Table 6: Absolute count of ambiguous state changes by cause and state change direction.**

| Cause                | Down | Up   | Total |
|----------------------|------|------|-------|
| Lost Message         | 174  | 27   | 201   |
| Spurious Retransmission | 194  | 0    | 194   |
| Unknown              | 28   | 202  | 230   |
| **Total**            | 396  | 229  | 625   |

When comparing syslog failures to those reported by the IS-IS listener, we find that syslog reports 2,440 failures (21% of all syslog-reported failures) and 17.5 hours of downtime that were not observed by the IS-IS listener. These are false positives, i.e., failures that did not impact traffic.

- **Short Failures:** Short failures (ten seconds or less) account for 83% of all false positives, but they result in less than an hour of downtime.
- **Longer False Positives:** The remaining 373 false positives, which account for 94% of the false positive downtime, occur during periods of flapping, where a link fails multiple times in rapid succession. All but 19 of these longer false positives (a total of 15.1 hours of downtime) happen during flapping events.

**Causes of False Positives:**
- **Aborted IS-IS Handshake:** Very short false positives (one second or less) can be caused by an aborted IS-IS three-way handshake.
- **Reset Adjacency:** Another cause of very short failures (one second or less) is an adjacency reset, which often occurs immediately after a longer failure without generating an LSP, thus not being seen by the IS-IS listener.
- **Lost Messages:** Long false positives occur when both an "Up" and a subsequent "Down" message are lost, causing two short failures to appear as one long failure.

**Ambiguous State Changes:**
A failure in syslog is defined by a "Down" message followed by an "Up" message. However, we find 461 "Down" messages preceded by another "Down" message and 202 "Up" messages preceded by an "Up" message. This ambiguity makes it difficult to determine if a message was lost or if it was a spurious reminder of the link state. In aggregate, these ambiguous periods account for 7.8% of the measurement period across all links.

- **Testing for Missing Messages:** Using IS-IS data, we can test if a double "Up" or "Down" has occurred due to a missing syslog message. We find that 42% of all double "Down" periods are caused by a lost syslog "Up" message, and 86% of all double "Up" periods are caused by a lost "Down" message.
- **Spurious Retransmissions:** For the remaining unexplained state changes, we check if they occurred while the link was in the same state. We find that 52% of all double "Down" messages (91% of those not explained by a lost syslog "Up") occur during a failure according to IS-IS, and 14% of all double "Up" messages (all of those not explained by a lost syslog "Down") occur during uptime.

**Correcting Nonsensical State Transitions:**
Previous work ignored the time periods between these transitions, but with the help of IS-IS control data as ground truth, we can explore better strategies. We believe there are three potential options:
1. Assume the link is down.
2. Assume the link is up.
3. Assume the link is in the previous state.

After examining these strategies, we find that assuming the link remains in the previous state brings the link downtime as seen by syslog closest to matching the link downtime as seen by IS-IS.

### 4.4 Isolating Failures

While the statistical similarity of individual failure events according to syslog and IS-IS is important, many real-world metrics are aggregates of multiple events. Any error in reconstruction can be magnified when focusing on high-level metrics, such as customer availability.

**Customer Availability:**
CENIC's primary value as an ISP is in providing connectivity to its customers. Therefore, reliability is best gauged through customer availability rather than statics about individual network failures. Because most customers are multi-homed and CENIC has rings in its topology, detecting connectivity losses requires accurate state information about multiple links simultaneously.

**Isolation Events:**
During our study period, IS-IS observed 1,401 failure events that isolated a customer, affecting 74 distinct customers and resulting in 26 days of isolation. Syslog-reconstructed failures identified 1,060 distinct isolating events affecting 67 customer sites, resulting in 22.4 days of downtime. However, syslog-reconstructed failure events are not a perfect subset of IS-IS events; 58 events reported by syslog were not observed in the IS-IS data.

**Table 7: Number and duration of failures in which at least one CENIC customer was isolated from the backbone, as reconstructed from syslog and IS-IS.**

| Data Source | IS-IS | Syslog | Intersection |
|-------------|-------|--------|--------------|
| Isolating Events | 1,401 | 1,060 | 1,002        |
| Sites Impacted | 74    | 67     | 66           |
| Downtime (days) | 26.3  | 22.3   | 19.8         |

- **Unmatched Events:** Of the 58 unmatched events, 12 had no IS-IS-reported failures on the affected links, while the remaining 46 intersected but did not perfectly match some IS-IS failures. Two particularly egregious mismatches include a 7-hour isolation detected by syslog only nine seconds before it ended, and a 17-hour isolation reported by syslog that actually lasted less than one minute according to IS-IS.
- **IS-IS Only Events:** There were 399 events (corresponding to 6.5 days of downtime) reported by IS-IS that did not match syslog-reconstructed events. Of these, 82 were due to syslog missing a single state change message, accounting for 2.1 days (32%) of downtime. Additionally, 99 partially matched syslog-reconstructed events, accounting for 0.7 days (11%) of downtime. The remaining 218 unmatched isolating events had no related (or potentially related) syslog messages.

### 5. Conclusion

This study represents the first attempt to compare failure patterns reported by syslog-based analyses to those extracted through direct IGP monitoring. We find significant disagreement between the two sources, with roughly one quarter of all events reported by one data source not appearing in the other. Clearly, IS-IS monitoring is more accurate, as traffic shares fate with the routing protocol. However, our analysis indicates that syslog's omissions are heavily biased toward short failures, and many larger statistical properties of the network obtained through syslog, such as annualized downtime, number of failures, and time to repair, are reasonably accurate. Still, one must be cautious in drawing high-level conclusions, as syslog has a significantly different view of customer isolation compared to IS-IS.

In summary, syslog-based analyses may be useful for capturing aggregate failure characteristics where IGP data is not available. It is less well-suited to situations requiring precise failure-for-failure accounting.

### Acknowledgments

This work was supported in part by the UCSD Center for Networked Systems and the National Science Foundation through grant CNS-1116904. The authors would like to thank Brian Court, Darrell Newcomb, Jim Madden, Erick Sizelove, and our shepherd, Theophilus Benson, for their advice and suggestions.

### References

[1] COATES, M., CASTRO, R., AND NOWAK, R. Maximum likelihood network topology identification from edge-based unicast measurements. In Proceedings of ACM SIGMETRICS (June 2002).

[2] DHAMDHERE, A., TEIXEIRA, R., DOVROLIS, C., AND DIOT, C. NetDiagnoser: Troubleshooting network unreachabilities using end-to-end probes and routing data. In Proceedings of ACM CoNEXT (Dec. 2007).

[3] DUFFIELD, N. Network tomography of binary network performance characteristics. IEEE Transactions on Information Theory (Dec. 2006).

[4] GILL, P., JAIN, N., AND NAGAPPAN, N. Understanding network failures in data centers: Measurement, analysis, and implications. In Proceedings of ACM SIGCOMM (Aug. 2011).

[5] HUANG, Y., FEAMSTER, N., AND TEIXEIRA, R. Practical issues with using network tomography for fault diagnosis. Computer Communication Review (October 2008).

[6] KOMPELLA, R. R., YATES, J., GREENBERG, A., AND SNOEREN, A. C. Detection and localization of network black holes. In Proceedings of IEEE INFOCOM (May 2007).

[7] LABOVITZ, C., AHUJA, A., AND JAHANIAN, F. Experimental study of Internet stability and backbone failures. In Proceedings of FTCS (June 1999).

[8] LONVICK, C. The BSD syslog protocol. RFC 3164, August 2001.

[9] MAHIMKAR, A., YATES, J., ZHANG, Y., SHAIKH, A., WANG, J., GE, Z., AND EE, C. T. Troubleshooting chronic conditions in large IP networks. In Proceedings of ACM CoNEXT (Dec. 2008).

[10] MAHIMKAR, A. A., GE, Z., SHAIKH, A., WANG, J., YATES, J., ZHANG, Y., AND ZHAO, Q. Towards automated performance diagnosis in a large IPTV network. In Proceedings of the ACM SIGCOMM (Aug. 2009).

[11] MAO, Y., JAMJOOM, H., TAO, S., AND SMITH, J. M. NetworkMD: Topology inference and failure diagnosis in the last mile. In Proceedings of ACM IMC (Oct. 2007).

[12] MARKOPOULOU, A., IANNACCONE, G., BHATTACHARYYA, S., CHUAH, C.-N., GANJALI, Y., AND DIOT, C. Characterization of failures in an operational IP backbone network. Transactions on Networking (Aug. 2008).

[13] MORTIER, R. PyRT: Python routing toolkit. https://github.com/mor1/pyrt.

[14] POTHARAJU, R., AND JAIN, N. An empirical analysis of intra- and inter-datacenter network failures for geo-distributed services. In Proceedings of ACM SIGMETRICS (June 2013).

[15] QIU, T., GE, Z., PEI, D., WANG, J., AND XU, J. What happened in my network: Mining network events from router syslogs. In Proceedings of ACM IMC (Nov. 2010).

[16] SHAIKH, A., ISETT, C., GREENBERG, A., ROUGHAN, M., AND GOTTLIEB, J. A case study of OSPF behavior in a large enterprise network. In Proceedings of ACM IMC (Nov. 2002).

[17] TURNER, D., LEVCHENKO, K., SNOEREN, A. C., AND SAVAGE, S. California fault lines: Understanding the causes and impact of network failures. In Proceedings of ACM SIGCOMM (Aug. 2010).

[18] WANG, F., MAO, Z. M., WANG, J., GAO, L., AND BUSH, R. A measurement study on the impact of routing events on end-to-end Internet path performance. In Proceedings of ACM SIGCOMM (Sept. 2006).

[19] WATSON, D., JAHANIAN, F., AND LABOVITZ, C. Experiences with monitoring OSPF on a regional service provider network. In Proceedings IEEE ICDCS (2003).

[20] XU, W., HUANG, L., FOX, A., PATERSON, D., AND JORDAN, M. Detecting large-scale system problems by mining console logs. In Proceedings of ACM SOSP (Oct. 2009).

[21] YAMANISHI, K., AND MARUYAMA, Y. Dynamic syslog mining for network failure monitoring. In Proceedings of ACM SIGKDD (Aug. 2005).

[22] ZHANG, M., ZHANG, C., PAI, V., PETERSON, L., AND WANG, R. PlanetSeer: Internet path failure monitoring and characterization in wide-area services. In Proceedings of USENIX OSDI (Dec. 2004).