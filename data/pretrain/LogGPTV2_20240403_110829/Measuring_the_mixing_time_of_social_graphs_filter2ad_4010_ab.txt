1,155,148
20,353,734
15,807,563
26,151,771
27,562,349
2,987,624
μ
0.899418
0.987531
0.987531
0.998133
0.998133
0.998221
0.996879
0.996473
0.998133
0.997494
0.982477
0.992020
0.999387
0.999695
0.997972
4. RESULTS
Equipped with the mathematical tools explained in section 3, we
measure the mixing time of the different social graphs shown in
Table 1. In order to apply the tools in section 3 for measuring the
mixing time, we ﬁrst convert directed graphs to undirected, which
is similar to what is performed in other work [27, 3, 12, 11, 23,
30, 31, 32]. We further compute the largest connected compo-
nent in each graph and use it as a representative social structure
for measuring the mixing time, as the mixing time is undeﬁned for
disconnected graphs. For small to medium-sized graphs, we com-
pute SLEM directly from the transition matrix of the graph. On the
other hand, for feasibility reasons, we sample the representative
385subgraphs from each of the four large data sets (Facebook A, B and
Livejournal A, B) using the breadth ﬁrst search (BFS) algorithm
beginning from a random node in the graph as an initial point.3 We
perform this sampling process to obtain graphs of 10K, 100K and
1000K nodes out of 3 to 5 million nodes in each original social
graph. Bearing the different social graphs sizes in mind, as shown
in Table 1, we proceed to describe the results of our experiments.
Figure 1 and Figure 2 plot the lower bound of the mixing time for
the different graphs in Table 1. We choose to use the lower-bound,
but not the upper bound, because it is more relevant to the context
of our study. In particular, as we observe that the lower-bound of
the mixing time to satisfy a given  is large, it is obvious that the
mixing time for social graphs is slower than anticipated. As shown
in Figure 1, we also observe that the mixing time is very slow, in
particular for social graphs that require physical acquaintance of
the social actors, as can be seen in the general tendency of these
graphs. For example, physics co-authorship, Enron, and Epinion,
though the social network is small, a mixing time of 200 to 400 is
required to achieve  = 0.1. Similarly for larger social graphs, as
shown in Figure 2, the mixing time to achieve  = 0.1 is varying
and depends on the nature of the data set. For example, while it is
about 1500 to 2500 in case of Livejournal, it ranges from 100 to
about 400 in case of DBLP, Youtube, and Facebook.
Enron
Slashdot 1
Slashdot 2
Epinion
Physics 1
Physics 2
Physics 3
Wiki vote
 0
 20
 40
 60
 80
 100
Mixing time
e
c
n
a
t
s
i
d
n
o
i
t
a
i
r
a
v
l
a
t
o
T
0.50
0.45
0.40
0.35
0.30
0.25
0.20
0.15
0.10
0.05
0.00
Figure 1: Lower bound of the mixing time for the different data
sets used in our experiments — the case of small data sets.
e
c
n
a
t
s
i
d
n
o
i
t
a
i
r
a
v
l
a
t
o
T
0.50
0.45
0.40
0.35
0.30
0.25
0.20
0.15
0.10
0.05
0.00
Facebook A
Facebook A
DBLP
Youtube
LiveJournal B
LiveJournal B
 0
 500
 1000
 1500
 2000
Mixing time (walk length)
Figure 2: Lower bound of the mixing time for the different data
sets used in our experiments — the case of large data sets
To see how tight are these measurements we perform the follow-
ing experiment. We ﬁrst compute the lower bound of the mixing
time for the physics co-authorship data sets, which are also reason-
ably small and feasible to do exhaustive computations. Then we
measure the mixing time using the model in (2) from every pos-
sible source in the graph (the CDFs of the raw measurements are
3Note that BFS algorithm may bias the sampled graph to have
faster mixing. Since our goal is to show that the mixing time is
slower than expected, this only strengthens our position.
shown in Figure 3 for small t and and in Figure 4 for large t). We
aggregate these measurements into Figure 5, by sorting  at each t
and averaging values in various intervals as percentiles. We observe
that while the mixing time of most sources in social graphs is bet-
ter than that of the mixing time given by SLEM, the measurements
using SLEM are correct since the mixing time is by deﬁnition max-
imum of walk lengths for given  as shown in (2). However, even
considering this effect, still for most sources the mixing time is
slower than used by other papers (10 and 15 in SybilLimit).
F
D
C
1.00
0.90
0.80
0.70
0.60
0.50
0.40
0.30
0.20
0.10
0.00
w=80
w=100
w=200
w=300
w=400
w=500
 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1
F
D
C
1.00
0.90
0.80
0.70
0.60
0.50
0.40
0.30
0.20
0.10
0.00
w=80
w=100
w=200
w=300
w=400
w=500
 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1
Total variation distance
(a) Physics 2
Total variation distance
(b) Physics 3
Figure 4: The CDF of mixing time (long walks) for the three
physics datasets in Table 1. The variation distance is computed
for every possible node in the graph, brute-forcefully.
e
c
n
a
t
s
i
d
n
o
i
t
a
i
r
a
v
l
a
t
o
T
0.50
0.45
0.40
0.35
0.30
0.25
0.20
0.15
0.10
0.05
0.00
 0
DBLP 1
DBLP 3
DBLP 2
DBLP 4
DBLP 5
 400
 300
 200
 500
 100
Mixing time (walk length)
(a) Lower bound
100
e
c
n
a
t
s
i
d
10-1
n
o
i
t
a
i
r
a
v
10-2
l
a
t
o
T
10-3
 600
DBLP 1
DBLP 2
DBLP 3
DBLP 4
DBLP 5
 0  10  20  30  40  50  60  70  80  90  100
Mixing time (walk length)
(b) Average mixing time
Figure 6: Lower-bound vs. the top the average mixing time for
a sample of 1000 nodes in each data set, where DBLP x means
the minimum degree in that data set is x.
To understand the relationship between the network size and the
mixing time (of the same social graph) we use the different pre-
viously sampled subgraphs, using BFS, from Facebook and Live-
journal data sets (10K, 100K, and 1000K). We further measure the
mixing time using SLEM and the model in (2) for 1000 initial dis-
tributions. We further aggregate the top 10, median 20, and lowest
10 percentile of  corresponding to the given random walk, and
plot them along with the mixing time derived using SLEM where
the results are shown in Figure 7. We observe that for a million
nodes graph, while the mixing time in the top 10% in the sample
−5—an excellent value
we computed is 100 for an averaged  = 10
to the “theoretical” guarantees of the Sybil defenses, the SLEM-
−2 as shown in Figure 7(i).
based mixing time results in only  = 10
We attribute this difference to similar scenario as in the physics co-
authorship graphs. Similar observations can be seen in each of the
different large social graphs. It is worth mentioning that Livejour-
nal (Figure 7(k) and Figure 7(l)) present poor mixing in relation
with Facebook data sets, which are shown to be fast mixing.
Finally, to understand the methodology used for experimenting
in Sybilguard and SybilLimit, we perform the same trimming tech-
nique by iteratively removing lower degree nodes (for 1 up to 5)
from the DBLP data set and computed the mixing time of the re-
sulting graphs at each time (results shown in Figure 6). We observe
that the pruning of lower degree greatly improves the mixing time
of the social graph: for ﬁxed mixing time of 100, by successive
trimming the variation distance is reduced from about 0.2 to 0.03
(Figure 6(a)), and from about 0.015 to 0.002 (Figure 6(b)). But this
is with huge reduction of the graph size: DBLP 1 is of size 614,981
but after trimming up to 4 degree nodes, DBLP 5 is of size 145,497.
386F
D
C
1.00
0.90
0.80
0.70
0.60
0.50
0.40
0.30
0.20
0.10
0.00
w=1
w=5
w=10
w=20
w=40
 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1
Total variation distance
F
D
C
1.00
0.90
0.80
0.70
0.60
0.50
0.40
0.30
0.20
0.10
0.00
w=1
w=5
w=10
w=20
w=40
 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1
Total variation distance
F
D
C
1.00
0.90
0.80
0.70
0.60
0.50
0.40
0.30
0.20
0.10
0.00
w=1
w=5
w=10
w=20
w=40
 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1
Total variation distance
(a) Physics 1