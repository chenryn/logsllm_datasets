Std dev (σ)
Student
Other
High school
Bachelor
Post-graduate
Novice
Intermediate
Expert
OTO SSF
29
15
14
18
59
29.0
10.4
16
13
8
14
7
4
17
8
29
15
14
20
48
26.7
6.5
16
13
3
19
7
2
19
8
Total
58
30
28
18
59
27.8
8.7
32
26
11
33
14
6
36
16
interface from prior experience. SSF checks the software
that a user clicks to download against a known blacklist of
malicious software.
If the software is ﬂagged, then a red-
banner warning appears, intentionally delaying the down-
load procedure, and the user must click on the “Actions”
button to proceed with the download. Figure 6 depicts the
two SSF status bars that appear at the bottom of a browser:
a warning and a normal download deemed legitimate.
For our experiment, we modiﬁed the mockup slides for the
experts’ user study in Section 3.4 as follows:4 two conditions
diﬀer in the last step of each scenario when the interviewer,
who is role-playing as a close friend of the participant, clicks
on the download button. The SSF condition prompts IE’s
SSF dialog box (Figure 6), while OTO prompts the evidence
interface (Figures 3–5). Figures 7 and 8 show the snapshots
of the SSF and OTO interfaces, respectively. Similar to the
expert user study as described in Section 3.4, we asked each
participant to pretend that (s)he was helping a close friend
make a trust decision when downloading a piece of software
from the Internet.5
Pre-study.
Before we started the experiment, we pre-
sented 6 pre-study questions in random order to identify
each participant’s security knowledge level (see Table 6 for
questions). We then classiﬁed the participants as novice, in-
termediate, or expert if they correctly answered 0–2, 3–4, or
5–6 questions, respectively. Table 5 shows the classiﬁcation
of the participants based on their security knowledge.
During study. Before we began, we told the participants
that they would be given 10 scenarios, where some software
may be safe to download and some may be harmful to the
computer. Their task would be to recommend whether the
friend should proceed or cancel the download. We also ex-
plained that each participant would be paid $15, plus an ad-
ditional $1 for each question that they answered correctly,
with a maximum payment of $25. This payment method
was to incentivize the participants to provide the best ed-
ucated guess and mimic reality, rather than be extremely-
conservative or liberal.
4From the end-user’s point of view, only user experience matters,
and participants commented that our study was indistinguishable
from a real environment.
5We observed that participants cared more about providing hon-
est/correct advice to close friends than about protecting the lap-
top of an unrelated person (i.e., the interviewer). Hence, the role-
playing increased participation through passive help. Furthermore,
our experiment setting ensured that all participants were tested us-
ing the same browser and OS settings.
398Table 6: A pre-study questionnaire to identify the participants’ security knowledge.
• While browsing the web, you see a pop-up window showing that your computer is infected with viruses. This warning recommends
that you download antivirus software to delete the viruses from your computer. Do you think this software is safe to download?
• One of your close friends recommend a product called K7 SECURE-WEB for secure online ﬁnancial transactions. You google
the product and click the #1 top search result, which redirects you to http://www.k7computing.com/en/Product/
k7-secureweb.php. You see a link to purchase this product for $19.99. Do you think this software is safe to purchase?
• You log into Facebook and see that your friend posted a video clip entitled: OMG I just hate RIHANNA after watching this video.
When you click the video, you get a prompt asking you to install ActiveX codec player to watch this video clip. Do you think this
video codec is safe to download?
• While browsing the web, you see an advertisement about Google’s super-fast Chrome browser. When you click this advertisement,
you see an instruction page to install Chrome from https://www.google.com/chrome/. Do you think this software is safe to
download?
• You receive an instant message, such as AOL IM, MSN messenger, Google talk, etc., from your friend to download identity protection
software. When you click the link, it redirects you to http://download.cnet.com/ to download the software. Do you think
this software is safe to download?
• You are checking your email and you see that you have an urgent message from your bank. The email message says that the bank is
upgrading their software to improve your safety and security, and asks you to install the software that is attached to the email. Do you
think this software is safe to download?
productkey_setup.exe is not commonly downloaded and could harm your computer.
Delete
Actions
View Downloads
(a) A SSF warning for potentially malicious ﬁle download.
Do you want to run or save DownloadXPro.exe (650KB) from software-!les-a.cnet.com?
Run
Save
Cancel
(b) A SSF interface for normal downloads.
Figure 6: Microsoft IE’s SmartScreen Filter (SSF) interfaces.
Figure 7: A screenshot of a SmartScreen Filter (SSF) interface.
The SSF dialog box is shown at the bottom of the IE browser.
During the experiment, the interviewer walked through
the scenarios, and asked the same questions that we used for
the expert user study in Section 3.4. For this experiment, we
categorized the ten scenarios into the following four cases:
1. True positive (TP): the system properly detects mal-
ware as malicious. In this case, SSF displays a red warning
bar on the bottom of the screen, and OTO displays a red
interface with only negative evidence.
2. True negative (TN): the system properly detects the
legitimate software as legitimate. In this case, SSF dis-
plays a yellow warning bar on the bottom of the screen,
and OTO displays a blue interface with only positive ev-
idence.
3. False positive (FP): the system incorrectly detects the
legitimate software as malicious. In this case, SSF displays
a red warning bar on the bottom of the screen, forcing
Figure 8: A screenshot of an OTO interface. The OTO dia-
log box displays positive and negative pieces of evidence on the
grayed-out screen.
users to stop downloading, and OTO presents a yellow
OTO interface displaying more suspicious evidence than
trustworthy evidence.
4. False negative (FN): the system incorrectly detects mal-
ware as legitimate.
In this case, SSF displays a yellow
download warning bar on the bottom of the screen, and
OTO displays a yellow OTO interface with more positive
evidence than negative evidence.
Among 10 scenarios, we assigned two pieces of software
with easy to medium diﬃculty level to TP and TN cases, and
three pieces of software with medium to diﬃcult level to FP
and FN cases. Table 7 describes the scenario assignments.
When the interface prompted, we asked each participant if
(s)he thought the software was safe to download or harmful
399Table 7: Scenario assignments for TP, TN, FP, and FN cases.
h Legitimate
t
u
r
t
d
n
u
o
r
G
Malicious
System detection outcome
Legitimate
TN
Ahnlab
MindMaple
FN
ActiveX codec
HDD diagnostic
Adobe ﬂash
Malicious
FP
Rkill
Kaspersky
SPAMﬁghter
TP
Windows activation
Privacy violation
to the friend’s computer. Participants were given the fol-
lowing answer choices: (1) legitimate, (2) malicious, and (3)
unsure (each scenario had 1 correct answer and “unsure” was
counted as incorrect). We asked them to think aloud, and
the PowerPoint automatically logged the time duration until
the participants made trust decisions. After they decided,
we asked for justiﬁcations and while the users were thinking
aloud, the interviewer logged the answers for analysis.
Post-study.
After the experiment, we asked the partic-
ipants to answer questions to obtain feedback on the inter-
faces. More speciﬁcally, we asked how much the diﬀerent
types of evidence (as shown in Table 4) would help the par-
ticipants when downloading software.
6.3 General Observations
In this experiment, we observed that many participants
tend to trust their past experience and security knowledge
in certain scenarios that they are familiar with (e.g., TP and
FN scenarios); hence they used the SSF and OTO interfaces
for conﬁrmation of their judgments.
In the SSF condition, many participants were conservative
when prompted with a pop-up that they did not initiate. In
the OTO study, however, we noticed that the participants
began to rely on the evidence that the OTO interface pro-
vided, especially for those scenarios that were unfamiliar to
them. Many participants claimed that the websites looked
legitimate but they were not aware that the websites existed.
This allowed them to focus their attention on the evidence
to gain more knowledge, especially for TN and FP scenarios.
One concern with the OTO interface was that users may
need to spend time to read the evidence. However, we
observed that the participants did not take a signiﬁcantly
longer time with the OTO interface, as compared to the
SSF interface. Figure 9 shows the average response time
from 24 random participants (N = 11 for OTO, N = 13
for SSF) who did not think aloud while making trust deci-
sions, and Table 8 summarizes the average and maximum
time. One interesting observation is that overall, the par-
ticipants took less time to make trust decisions for OTO
compared to SSF. More speciﬁcally, the participants took
approximately the same amount of time for FN cases re-
gardless of the interface they were given, and the partici-
pants given the OTO interface took less time to decide for
FP, TP, and TN cases. This result is due to the follow-
ing observation from the experiment: In the SSF condition,
many participants took some time to make trust decisions
given scenarios that they never experienced before. In the
OTO condition, however, the participants relied on the dis-
played evidence lists to make trust decisions, resulting in
faster decisions compared to SSF.
Next, we analyze in detail the eﬀectiveness of OTO as
compared to SSF.
Figure 9: The average time that the participants spent to make a
trust decision on each scenario for SSF and OTO conditions (N =
13 for SSF, N = 11 for OTO).
Table 8: Mean and maximum time that the participants spent to
make trust decisions (N = 13 for SSF, N = 11 for OTO).
OTO
Mean
10.1 ± 6.9
6.6 ± 3.7
9.5 ± 5.0
11.0 ± 5.8
12.0 ± 9.4
Max
48
14
20
31
48
SSF
Mean
12.3 ± 7.6
12.1 ± 8.5
11.2 ± 6.5
13.3 ± 7.0
12.2 ± 8.4
Max
34
32
26
31
34
Overall
TP
TN
FP
FN
6.4 Effectiveness Analysis
We analyze if the OTO interface helps users make correct
trust decisions compared to Microsoft’s SSF interface (base
case). Based on the number of correct answers provided by
58 participants (29 participants for each condition), we ran a
Repeated Measures ANOVA test. The results conﬁrm that
the OTO interface helps people make more correct trust
decisions compared to the SSF interface regardless of the
participants’ background security knowledge, education level,
occupation, age, or gender. Table 9 summarizes the results.
We designed our study to test whether OTO helps users
make correct trust decisions even if the OS mistakenly cate-
gorizes legitimate software as malicious and vice versa. Be-
low is a list of hypotheses for 4 cases, along with detailed
analysis on how our study participants responded for 4 cases
using Mixed Models. In general, a signiﬁcant main eﬀect ex-
ists for diﬀerent interface conditions with 4 cases taken into
account (F (1, 65) = 18.1, p < .001), and the main eﬀect of 4
diﬀerent cases is signiﬁcant (F (3, 517) = 12.61, p < .0001).
Table 9 summarizes the results for speciﬁc cases.
True Positive (TP).
In the TP case, the OS correctly
identiﬁes malware. We tested two TP scenarios (“Windows
activation” and “Privacy violation”), given the following hy-
pothesis:
Hypothesis 1. When software is malicious and the OS
detects it as malicious, users given the OTO interface detect
the malware at least as well as those with the SSF interface.
The Mixed Model delivered no signiﬁcant diﬀerence be-
tween OTO and SSF for TP scenarios. Hence, Hypothesis 1
is valid and OTO performs at least as well as SSF for the
TP case.
True Negative (TN).
In the TN case, the OS correctly
identiﬁes legitimate software as legitimate. For 2 TN sce-
narios, namely “AhnLab” and “SPAMﬁghter Pro,” our hy-
pothesis is as follows:
Hypothesis 2. When software is indeed legitimate and
the OS detects it as legitimate, users given the OTO interface
detect the legitimacy at least as well as those given the SSF
interface.
400Table 9: Summary of Repeated Measures ANOVA (Overall), Mixed Models (TP, TN, FP, FN), and ANOVA (Usefulness, Annoyance)
results for the effectiveness of OTO compared to SSF (N = 58, 29 for each condition). The higher mean that is statistically signiﬁcant from
the other is highlighted in bold.
Overall
TP
TN
FP
FN
min: 0, max: 1
min: 0, max: 1
min: 0, max: 1
min: 0, max: 1
min: 0, max: 1
µ
.86
.67
σ ¯X
.03
.03
µ
.96
.93
σ ¯X
.05