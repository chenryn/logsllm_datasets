believe that Freenet’s content replication is likely suﬃcient to avoid signiﬁcant
loss of content due to realistic amounts of join-leave churn.
However, natural join-leave churn has another, rather unexpected impact on
the distribution of locations in the Freenet overlay. This additional impact re-
quires that the overlay has a stable core of peers that are highly available and
strongly interconnected, which is a common phenomeonon in most peer-to-peer
networks. In contrast to this set of stable core-peers, peers that contribute to
join-leave churn are likely to participate only brieﬂy and have relatively few
connections. Suppose the locations γi of the core-peers are initially biased to-
wards (or clustered around) a location α ∈ [0, 1). Furthermore, suppose that
(over time) thousands of peers with few connections (located at the fringe of the
network) contribute to join-leave churn.
Each of these fringe-peers will initially assign itself a random location β ∈
[0, 1). In some cases, this random choice β will be closer to α than some of the
Routing in the Dark: Pitch Black
11
γi-locations of the core nodes. In that case, the routing algorithm is likely to
swap locations between these fringe-peers and core-peers in order to reduce the
overall distances to neighbors (as calculated according to Equation (1)). Peers
in the core have neighbors close to α, so exchanging one of the γi’s for β will
reduce their overall distances. The fringe peers are likely to have few connections
to the core group and thus the overall product after a swap is likely to decrease.
Consequently, non-adversarial join-leave churn strengthens any existing bias
in the distribution of locations among the long-lived peers. The long-term results
of join-leave churn are equivalent to what the attack from Section 4.1 is able to
produce quickly – most peers end up with locations clustering around a few
values. Note that this phenomenon has been observed by Freenet users and was
reported to the Freenet developers – who so far have failed to explain the cause
of this degeneration.2 Since both the attack and natural churn have essentially
the same implications for the routing algorithm, the performance implications
established by our experimental results (Section 5) hold for both scenarios.
5
Experimental Results
This section presents experimental results obtained from a Freenet testbed with
up to 800 active nodes. The testbed, consisting of up to 18 GNU/Linux machines,
runs the actual Freenet 0.7 code. The nodes are connected to form a small-
world topology (using Kleinberg’s 2d-grid model [6]) with on average O(log2 n)
connections per node.
Each experiment consists of a number of iterations. In each iteration, nodes
are given a ﬁxed amount of time to swap locations. Then the performance of
the network is evaluated. The main performance metrics are the average path
length needed to ﬁnd the node that is responsible for a particular key, and the
percentage of the content originally available in the network that can still be
retrieved.
All nodes are conﬁgured with the same amount of storage space. Before each
experiment, the network is seeded with content with a random key distribution.
The amount of content is ﬁxed at a quarter of the storage capacity of the entire
network. The content is always (initially and after each iteration) placed at the
node with the closest location to the key. Nodes discard content if they do not
have suﬃcient space. Discarded content is lost for the duration of the experiment.
Depending on the goals of the experiment, certain nodes are switched into
attack mode starting at a particular iteration. The attacking nodes are randomly
chosen, and behave exactly as all of the other nodes, except for aggressively
propagating malicious node locations when swapping.
2 https://bugs.freenetproject.org/view.php?id=647, April 2007. We suspect that
the clustering around 0.0 is caused by software bugs, resulting in an initial bias for
this particular value, which is then strengthened by churn.
12
Anonymous
5.1
Distribution of Node Locations
Figure 7 illustrates the distribution of node locations on a circle before and
after an attack. The initial distribution on the left side consists of 800 randomly
chosen locations, which are largely evenly distributed over the entire interval.
The distribution on the right side shows the distribution after eight nodes
began an attack on the network in an attempt to create eight clusters. Note
that the number of attackers and the number of cluster locations can be chosen
independently.
Both plots use thicker dots in order to highlight spots where many peers are in
close proximity. Particularly after the attack peers often have locations that are
so close to each other (at the order of 2−30) that a simple plot of the individual
locations would just show a single dot. Thicker dots illustrate the number of
peers in close proximity, the spread of their locations is actually much smaller
than the thickness may suggest.
Fig. 7. Plot of node locations before and after attack.
5.2
Availability of Content
Figures 8, 9 and 10 show the data loss in a simulated Freenet network with 800
nodes and two, four and eight attackers respectively. The attackers attempt to
use swapping in order to cluster the locations of nodes in the network around
eight pre-determined values. The resulting clustering of many nodes around par-
ticular locations causes the remaining nodes to be responsible for disproportion-
ately large areas in the key space. If this content assignment requires a particular
node to store more content than the node has space available for, content is lost.
The attack is initiated after 75 iterations of ordinary network operation. After
just 200 rounds (corresponding to a roughly 5 hours of actual execution time)
the network has lost on average between 15% and 60% of its content, depending
on the number of attackers. Note that in our model, an individual attacker is
granted precisely the same resources as any ordinary user. The ﬁgures show the
average data loss (and standard deviations) over ﬁve runs. For each run, the
positions of the attackers were chosen randomly among the 800 nodes.
Routing in the Dark: Pitch Black
13
 0
 20
 40
 60
 80
 100
 0
 50
 100
 150
 200
% data loss
Time
Average Loss over with Std. Dev.
Fig. 8. Graph showing average data loss over 5 runs with 800 total nodes and 2
attack nodes using 8 bad locations with the attack starting after about 2h.
 0
 20
 40
 60
 80
 100
 0
 50
 100
 150
 200
% data loss
Time
Average Loss over time with Std. Dev.
Fig. 9. Graph showing average data loss over 5 runs with 800 total nodes and 4
attack nodes using 8 bad locations with the attack starting after about 2h.
 0
 20
 40
 60
 80
 100
 0
 50
 100
 150
 200
% data loss
Time
Average Loss over time with Std. Dev.
Fig. 10. Graph showing average data loss over 5 runs with 800 total nodes and
8 attack nodes using 8 bad locations with the attack starting after about 2h.
14
Anonymous
6
Discussion
Various strategies could be used to limit the impact of the proposed attack,
including changing the swapping policy, malicious node detection, and secure
multiparty communication. While some of these strategies can reduce the impact
of the attack, we do not believe that adopting any of the suggested measures
would address the attack in a satisfactory manner.
One possibility for reducing the eﬀect of the attack proposed in this paper
is to increase the amount of time between attempts to swap, or to have each
node in the network periodically reset its location to a random value. The idea
is that the malicious node locations would spread more slowly and be eventually
discarded. However, while this limits the impact of the attack, this defense also
slows and limits the progress of the network converging to the most fortuitous
topology.
However, the negative impact of churn may be handled by swapping locations
only with long lived peers. Recent measurement studies in peer-to-peer networks
have shown a power-law distribution of the uptime of peers; a large percentage of
peers have a short uptime. By adjusting the probability of location swapping to
be proportional to a peer’s uptime, the network may be able to prevent clustering
of the locations of long-lived peers due to join-leave churn.
Another possible method attempts to detect a malicious node based on know-
ing the size of the network. If a Freenet node were able to accurately produce
a close estimation of the size of the network, it could detect if an attacker was
swapping locations that are signiﬁcantly closer than what would be likely with
a random distribution of locations. The problem with this approach is that in
an open F2F network it is diﬃcult to reliably estimate the network’s size.
If there were a way for a node which purported to have a certain number
of friends to prove that all those friends existed, nodes could be more conﬁdent
about swapping. The Freenet developers suggested using a secure multiparty
computation as a way for a node to prove that it has n connections. The idea
would be for the swapping peers to exchange the the results of a computation
that could only be performed by their respective neighbors. But because nodes
can only directly communicate with their peers (F2F), any such computation
could easily be faked given appropriate computational resources. Of course, if
a node could directly communicate with another node’s neighbors, then the
topology could be discerned. However, in that case the protocol no longer works
for restricted-route networks.
7
Conclusion
The new Freenet routing algorithm is unable to provide performance guarantees
in networks where adversaries are able to participate. The algorithm also de-
generates over time (even without active adversaries) if the network experiences
churn. The recommended approach to address both problems is to periodically
reset the locations of peers. While this limits the deterioration of the routes
Routing in the Dark: Pitch Black
15
through adversaries and churn, such resets also sacriﬁce the potential conver-
gence towards highly eﬃcient routes. Secure and eﬃcient routing in restricted
route networks remains an open problem.
Acknowledgements
The authors thank Anonymous for feedback on an earlier draft of the paper.
References
1. Martin Casado and Michael J. Freedman. Illuminating the shadows: Opportunistic
network and web measurment.
http://illuminati.coralcdn.org/stats/, December
2006.
2. Ian Clarke. The freenet project. http://freenetproject.org/, 2007.
3. Ian Clarke, Oskar Sandberg, Brandon Wiley, and Theodore W. Hong. Freenet: A
distributed anonymous information storage and retrieval system. In Proc. of the
ICSI Workshop on Design Issues in Anonymity and Unobservability. International
Computer Science Institute, 2000.
4. Frank Dabek, M. Frans Kaashoek, David Karger, Robert Morris, and Ion Stoica.
Wide-area cooperative storage with CFS. In Proceedings of the 18th ACM Sym-
posium on Operating Systems Principles (SOSP ’01), Chateau Lake Louise, Banﬀ,
Canada, October 2001.
5. Michael T. Goodrich, Michael J. Nelson, and Jonathan Z. Sun.
The rainbow
skip graph: a fault-tolerant constant-degree distributed data structure. In SODA
’06: Proceedings of the seventeenth annual ACM-SIAM symposium on Discrete
algorithm, pages 384–393, New York, NY, USA, 2006. ACM Press.
6. Jon M. Kleinberg. Navigation in a small world. Nature, 406(6798):845–845, August
2000.
7. Jon M. Kleinberg. The small-world phenomenon: an algorithm perspective. In
STOC ’00: Proceedings of the thirty-second annual ACM symposium on Theory of
computing, pages 163–170, New York, NY, USA, 2000. ACM Press.
8. Petar Maymounkov and David Mazi`eres. Kademlia: A peer-to-peer information
system based on the xor metric. In Proceedings of IPTPS02, Cambridge, March
2002.
9. Stanley Milgram. The small-world problem. Psychology Today, pages 60–67, 1967.
10. William Pugh. Skip lists: A probabilistic alternative to balanced trees. In Workshop
on Algorithms and Data Structures, pages 437–449, 1989.
11. Sylvia Ratnasamy, Paul Francis, Mark Handley, Richard Karp, and Scott Shenker.
A scalable content addressable network. Technical Report TR-00-010, Berkeley,
Berkeley, CA, 2000.
12. Antony Rowstron and Peter Druschel. Pastry: Scalable, Decentralized Object Lo-
cation, and Routing for Large-Scale Peer-to-Peer Systems. Lecture Notes in Com-
puter Science, 2218, 2001.
13. Oskar Sandberg. Searching in a Small World. PhD thesis, University of Gothen-
burg and Chalmers Technical University, 2005.
14. Oskar Sandberg. Distributed routing in small-world networks. In ALENEX, 2006.
15. Ion Stoica, Robert Morris, David Karger, M. Frans Kaashoek, and Hari Balakr-
ishnan. Chord: A scalable peer-to-peer lookup service for internet applications. In
Proceedings of the 2001 conference on applications, technologies, architectures, and
protocols for computer communications, pages 149–160. ACM Press, 2001.
16. Duncan Watts and Steve Strogatz. Collective dynamics of ’small-world’ networks.
Nature, 393:440–442, 1998.