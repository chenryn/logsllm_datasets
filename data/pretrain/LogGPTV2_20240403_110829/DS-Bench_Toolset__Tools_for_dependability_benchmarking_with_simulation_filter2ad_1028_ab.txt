

		
	

				





	
 
	!

				
 
"#
$		
%

				
&
'(	
)

						
	
&
	
	
&

							

&
	)		(	
&
	
				
&
'(
				
'(	
)

						
	
&
	
	
&

							
)
	)
	(!
	
&
	()

								)

						
							

&
	)		(!
	
&

							

&	)		(!
	
&

							

	)		(!
	
&
*"(
%
							
	)		(	
&

				
'(
				((
						

						

								

+,+- .+/+- 
&+-0
+-1$



								

 .2 
&20
21$
2


								"+3%+-"-
%+-"-	,456/1!
%+-"-	-%
								
)+,+- .+/+- 
&+-0
+-1$

)
								
!
!
								&(
&(

						

				((
				)

						
 
	


						!
1$
!

						)
7
828)
7

				)

		


:((	;	<(

5
	.$)	<(

Figure 3. An Example of Benchmark Description (iperf)
Figure 4. An Example of Benchmark Settings
This dialog is automatically generated by DS-Bench by
interpreting the benchmark description shown in Figure 3.
Benchmark programs are stored in the benchmark
database and downloaded by each target machine, on de-
mand. In the current implementation, benchmark programs
are prepared as Debian R(cid:2) packages (.deb) and fetched by
the apt tool.
2) Benchmark Results: When a benchmark program com-
pletes, the results are sent to the controller. The results
are automatically extracted from the raw text output of the

	
	



'"		(
)


 !"#$

%&'
	()*&
(	
	+
()*

%,-',."+
%&'	* /&/01	
%,-',."+
%&'	* /&&01	
*	+ ,

	

						
	
	
							 !
					!"#	$%$	 #
						
	&
	
							 !
					!"#	$%%	 #
		


Figure 5. An Example of Data Extraction
program according to the rules speciﬁed in the benchmark
description. Figure 5 shows an example of data extraction
done by DS-Bench. Results are stored in the benchmark
database so that they can be referenced later.
DS-Bench supports several different ways to examine the
results. Results can be plotted as graphs, or printed as a table.
Another data processing method supported is an automatic
data reduction. DS-Bench supports multiple target machines
in a single benchmark run, so there may be more than one
result for some value. DS-Bench applies one of a number
of available “data reduction” operations on these values.
For example, the average score of results from all target
machines can be calculated and displayed.
3) Anomaly Loads: DS-Bench supports several anomaly
generators to generate anomaly loads. Anomaly generators
are basically classiﬁed into two categories. The ﬁrst type of
anomaly generator consists of programs that run on target
machines. For example, there are programs that consume
a lot of computing resources, such as CPU time, memory,
and I/O bandwidth, to simulate overloaded circumstances.
Some benchmark programs can be used for performance
measurement as well as for anomaly generation which puts
stress on the system. Benchmark programs and anomaly gen-
erators together are registered in the DS-Bench framework
and users may indicate whether a program is executed as
an anomaly load. This type of anomaly generator can be
easily added to the framework in the same way as regular
benchmark programs. The second type of anomaly generator
injects a fault from outside of the target machines, such as
the cutting of an external power source. In addition, several
fault injection methods that simulate hardware malfunctions,
such as a memory bit ﬂip, a disk I/O error, or a network
packet drop, are supported by FaultVM, a virtual machine
monitor with fault injection features. FaultVM is described
later in Section III-C. These fault injectors are also used as
anomaly generators. These anomaly loads are generated by
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:21:02 UTC from IEEE Xplore.  Restrictions apply. 
the D-Cloud controller.
4) Benchmark Scenarios: The most important feature of
DS-Bench is that it supports the making and execution of
benchmark scenarios, which describe when to run which
benchmark program or anomaly load. Benchmark programs
and anomaly loads can be overlapped in their execution.
C. The Execution Platform for DS-Bench: D-Cloud
D-Cloud is an execution platform for DS-Bench using
both a cluster of physical machines and a cloud computing
environment. The details of D-Cloud are as follows.
1) Overview of D-Cloud: D-Cloud was proposed as a
large-scale software testing environment, using cloud com-
puting technology for dependable distributed systems [18],
[19]. Originally, D-Cloud provided a cloud service based
on “Infrastructure as a Service (IaaS),” including a virtual
machine environment to develop a dependable system and
to assure that the system, in fact, is dependable. It was also
supposed to allow the test procedures to be automated as
a scenario using a large amount of computing resources
in the cloud by interpreting system conﬁgurations and test
scenario written in XML, as well as enable tests, including
hardware faults, by emulating hardware faults by FaultVM
ﬂexibly. In addition, FaultVM-SpecC was proposed in order
to enable ﬂexible customization of FaultVM, and provide
a model where the virtual machine is integrated with the
device, and is described in SpecC language [20].
We introduce D-Cloud as an execution platform for the
DS-Bench Toolset with several modiﬁcations and extensions.
In this case, the test scenario should be provided by the DS-
Bench controller instead of the proprietary scenario only for
D-Cloud. In order to measure the actual performance by
using DS-Bench, physical machines should also be included
in D-Cloud, and the resource management facility for the
physical machine environment should be added to D-Cloud.
2) Structure and Management of Computing Resources:
As shown in Figure 1, D-Cloud includes both a physical
machine environment and a virtual machine (VM) environ-
ment as a private cloud. In addition, there is a controller
node, which controls all of the physical machines and VMs,
namely the D-Cloud controller.
The D-Cloud controller ﬁrst gives a list of available
resources to the DS-Bench controller, and then it assigns
several physical machines and/or guest OSs provided by
cloud management software to the speciﬁc benchmark test
according to the request from the DS-Bench controller.
3) Physical Machine Environment: This environment is
used for testing those characteristics that can be only re-
vealed by the actual hardware environment, such as perfor-
mance evaluation, realtimeness, and timing errors. Anomaly
behavior caused by software problems, such as software
bugs or overloads, and hardware malfunctions that can
be caused by manipulating hardware devices other than
computer components, such as network disconnections and
''	#%
	'(')
	
	
	


	
&


	

 	
!

	
&
"#

$

	
	
%
	

"	
Figure 6. Workﬂow using D-Case Editor and DS-Bench
power shutdowns, are also simulated using physical ma-
chines.
In the physical machine environment, network down and
power off tests are performed using a network switch
and a power distribution unit (PDU) which is capable of
being switched on/off remotely using the Simple Network
Management Protocol (SNMP), or a machine halt using the
Intelligent Platform Management Interface (IPMI) protocol.
4) Cloud and VM Environment: When dealing with faults
in memory ﬂips, or with I/O devices, etc., such faults can be