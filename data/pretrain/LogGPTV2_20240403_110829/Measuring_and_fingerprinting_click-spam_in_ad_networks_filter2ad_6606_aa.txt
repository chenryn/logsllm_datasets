title:Measuring and fingerprinting click-spam in ad networks
author:Vacha Dave and
Saikat Guha and
Yin Zhang
Measuring and Fingerprinting Click-Spam in Ad Networks
Vacha Dave ∗
MSR India and UT Austin
PI:EMAIL
Saikat Guha
Yin Zhang
Microsoft Research India
PI:EMAIL
Univ. of Texas at Austin
PI:EMAIL
ABSTRACT
Advertising plays a vital role in supporting free websites and smart-
phone apps. Click-spam, i.e., fraudulent or invalid clicks on on-
line ads where the user has no actual interest in the advertiser’s
site, results in advertising revenue being misappropriated by click-
spammers. While ad networks take active measures to block click-
spam today, the effectiveness of these measures is largely unknown.
Moreover, advertisers and third parties have no way of indepen-
dently estimating or defending against click-spam.
In this paper, we take the ﬁrst systematic look at click-spam.
We propose the ﬁrst methodology for advertisers to independently
measure click-spam rates on their ads. We also develop an auto-
mated methodology for ad networks to proactively detect different
simultaneous click-spam attacks. We validate both methodologies
using data from major ad networks. We then conduct a large-scale
measurement study of click-spam across ten major ad networks and
four types of ads. In the process, we identify and perform in-depth
analysis on seven ongoing click-spam attacks not blocked by major
ad networks at the time of this writing. Our ﬁndings highlight the
severity of the click-spam problem, especially for mobile ads.
Categories and Subject Descriptors
K.6.5 [Management of Computing and Information Systems]:
Security and Protection—Online Advertising Fraud
Keywords
Click-Spam, Click-Fraud, Invalid Clicks, Trafﬁc Quality
1.
INTRODUCTION
Background and motivation: Click-spam costs online advertisers
on the order of hundreds of millions of dollars each year [4]. In-
stead of supporting free smartphone apps and websites, this money
ends up in the pocket of click-spammers. Click-spam 1 subsumes
a number of scenarios that all have two things in common: (1) the
advertiser is charged for a click, and (2) the user delivered to the
ad’s target URL has no actual interest in being there. Click-spam
can be generated using a variety of approaches, such as (i) botnets
(where malware on the user’s computer clicks on ads in the back-
ground), (ii) tricking or confusing users into clicking ads (e.g., on
parked domains), and (iii) directly paying users to click on ads.
∗Work done while at Microsoft Research India
1or equivalently, click-fraud. Since a fraudulent motive is often
difﬁcult to conclusively prove, we use the term click-spam instead.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’12, August 13–17, 2012, Helsinki, Finland.
Copyright 2012 ACM 978-1-4503-1419-0/12/08 ...$15.00.
Incentives for click-spam are linked directly to the ﬂow of money
in online advertising — advertisers pay ad networks for each click
on their ad, and ad networks pay publishers (websites or phone apps
that show ads) a fraction (typically around 70% [2]) of the revenue
for each ad clicked on their website or app. A publisher stands to
proﬁt by attracting click-spam to his site/app. An advertiser stands
to inﬂict losses on his competitor(s) by attracting click-spam to his
competitors’ ads. An advertising network stands to increase rev-
enues (but lose reputation) by not blocking click-spam.
Reputed online ad networks have in-house heuristics to detect
click-spam and discount these clicks [39]. No heuristic is per-
fect. Advertisers pay for false negatives (click-spam missed by
the heuristic). None of the ad networks we checked release any
speciﬁcs about click-spam (e.g., which keywords attract click-spam,
which clicks are click-spam, etc.) that would otherwise allow ad-
vertisers to optimize their campaigns, or compare ad networks.
Research goals and approach: We have two main research goals
in this paper. Our primary goal is to design a methodology that
enables advertisers to independently measure and compare click-
spam across ad networks. The basic idea behind our approach is
simple: since the user associated with click-spam is, by deﬁnition,
not interested in the ad, he would be less likely to make any extra
effort to reach the target website than a user legitimately interested
in the ad. The advertiser can measure this difference and use it
to estimate the click-spam fraction. Of course some legitimately
interested users may not make the extra effort (false positives), or
some uninterested users may still make the extra effort (false neg-
atives). We correct for both types of errors by using a Bayesian
framework, and by performing experiments relative to control ex-
periments. Section 3 details our methodology.
Validating the correctness of our methodology is challenging be-
cause there is no ground truth to compare against. Ad networks
do not know the false negative rate of their heuristics, and thus
tend to underestimate click-spam on their network [12]. The ac-
curacy of heuristics used by third-party analytics companies (e.g.,
Adometry) is unknown since their methodology and models are not
open to public scrutiny; indeed, ad networks contend they overesti-
mate click-spam [16]. We manually investigate tens of thousands of
clicks we received (in Section 5). We present incontrovertible ev-
idence of dubious behavior for around half of the search ad clicks
and a third of the mobile ad clicks we suspect to be click-spam,
and circumstantial evidence for the rest, thus establishing a tight
margin-of-error in our methodology. In the process, we discover
seven ongoing click-spam attacks not currently caught by major ad
networks, which we reported to the parties concerned.
Our secondary goal is to measure the magnitude of the click-
spam problem today. To this end, in Section 4, we apply our method-
ology to measure click-spam rates across ten major ad networks (in-
cluding Google, Bing, AdMob, and Facebook) and four ad types.
Our work represents the ﬁrst measurement study of click-spam.
We also identify key research problems that can have a measur-
able impact in tackling click-spam.
Contributions: We make three main contributions in this pa-
per.
(i) We devise the ﬁrst methodology that allows advertisers
175The publisher gets some fraction (typically 70%) of the revenue
that the ad network collects from the advertiser. The accounting
is performed as follows. The ad URL points to the ad network’s
domain with information about which ad was clicked (encoded in
the GET parameters). When the user clicks an ad, the browser
contacts the ad network, which logs the encoded information for
billing purposes and redirects the user to the advertiser’s site. This
redirection is typically performed through an HTTP 302 response,
which preserves the publisher’s URL in the HTTP Referer seen by
the advertiser’s Web server. Black-hat techniques such as Referer-
Cloaking [5] by the publisher, ad network policies [14], or bugs in
browsers and proxies may result in empty or bogus Referer values
being sent to the advertiser.
User engagement: The ad network can track limited user engage-
ment (i.e., ads viewed or clicked) for multiple ads shown across
multiple publishers (e.g., using cookies), but cannot, in general,
track user engagement after the click. The advertiser, on the other
hand, can track detailed user actions (only) on the advertiser’s own
website, but cannot track user engagement with other ads. Thus
while the ad network has a broad-but-shallow view, the advertiser
has a narrow-but-deep view into user engagement.
Click-spam discounts: Ad networks internally discount clicks
based on in-house heuristics. The user is still redirected to the ad-
vertiser, but the advertiser is not charged for the click. Ad networks
do not indicate which clicks were charged and which not in the
advertiser’s billing report.
3. ESTIMATING CLICK-SPAM
In this section we design a method that any party (e.g., advertis-
ers, ad agency, or researchers) can use to estimate click-spam rates
for a given ad without explicit cooperation from the ad network.
3.1 Challenges
It is not possible to ﬁrst identify (deﬁnitively)
No ground truth:
which clicks are click-spam, and then compute what fraction of the
total trafﬁc click-spam accounts for. A click is click-spam if the
user did not intend to click the ad. There is no way to conclusively
determine user intent without explicitly asking the user.
No global view: As mentioned, the ad network cannot track user
engagement on the advertiser site, and the advertiser has no knowl-
edge of the user’s engagement with other advertisers. For example,
the ad network does not know if the user never loads the adver-
tiser’s site after the click (we saw botnets exhibiting this behavior),
and the advertiser does not know if the same user is implicated in
click-spam attacks on another advertiser. The obvious solution is
for the ad network and advertiser to cooperate. But ﬁnancial dis-
incentives and legal concerns prevent them from doing so: the ad-
vertiser could lie in his favor (claiming fraud where there is none)
in order to gain deeper discounts from the ad network; the ad net-
work could be held liable if sharing user history with advertisers
has unforeseen privacy consequences.
Granularity: The granularity over which click-spam is estimated
is important. An ad network may have low click-spam overall, say,
but certain lucrative segments (e.g., mortgage) may be experiencing
orders of magnitude more click-spam. Advertisers require ﬁne-
grained measurements for their selected set of keywords.
Noise: As in any Internet-scale system, data is extremely noisy.
We encountered users where Referer headers are inexplicably omit-
ted, or browser User-Agents, IP addresses, cookies etc. change in-
explicably within the same session (perhaps a buggy browser or
proxy), and bad publishers that behave non-deterministically (per-
haps to avoid detection). At the same time, because clicking an ad
1: Time-line for serving ads.
to independently measure and compare click-spam rates across ad
networks. We validate the correctness of the methodology using
real-world data.
(ii) We report on the sophistication of ongoing
click-spam attacks and present strategies for ad networks to mit-
igate them. (iii) We conduct a large-scale in-depth measurement
study of click-spam today.
2. ONLINE ADVERTISING PRIMER
Search vs. contextual: Keyword-based advertising is broadly
classiﬁed into two categories: (i) search advertising, which are ads
based on search keywords that show up on the side of search re-
sults, and (ii) contextual advertising, which are ads that show up
on Web pages or in applications based on keywords extracted from
the context. Search ads may be syndicated — i.e., they are shown
not only on the search engine operated by the ad network (e.g.,
on www.google.com), but also on afﬁliate websites that offer cus-
tomized search engines (e.g., www.ask.com). The term publisher
refers to the party that showed the ad (e.g., website for contextual
ads, smartphone application for mobile ads, afﬁliate for syndicated
search ads). We do not consider other kinds of ads (e.g., ads in
videos, banner ads, etc.) in this paper.
Mobile vs. non-mobile: Both search and contextual advertis-
ing can be further classiﬁed as mobile or non-mobile based on
what device the search or webpage request originated from. Mo-
bile includes smart-phones and other mobile devices that have “full
browser capabilities”, as well as feature-phones with limited WAP
browsers. The reason we draw a distinction between mobile and
non-mobile is because we found ad networks internally seem to
have very different systems for serving the same ads to mobile vs.
to non-mobile users. We do not know the reason for this differ-
ence, but speculate it is because ad networks tend to expand through
mergers and acquisitions, resulting in multiple technology stacks
operating concurrently.
Ad delivery: Figure 1 illustrates the time-line for serving online
ads. When the user visits a publisher website, the website returns
an adbox (e.g., embedded iframe), which causes the user’s browser
to contact the ad network. The request to the ad network identiﬁes
the referring website through the HTTP Referer (sic) header. The
ad network then populates the adbox with contextual ads.
In an
alternate mechanism (not shown), premium publishers may directly
query the ad network for relevant ads and seamlessly integrate them
into the website content.
Charging model: While there are multiple charging models for
online advertising (e.g., impression-based, action-based), by far the
most common is pay-per-click (PPC or CPC), where the advertiser
is charged (and publisher paid) only if the user clicks on the ad.
176is a rare event, gathering good data is time-consuming. The combi-
nation results in very low signal-to-noise ratios.
3.2 Our Approach
We apply a Bayesian approach to work around the lack of ground
truth. Instead of attempting to conclusively identify which clicks
are click-spam, for a given ad, we create two scenarios detailed
below where the (unknown) fractions of click-spam trafﬁc is differ-
ent. We link the two using a Bayesian formula to effectively cancel
out quantities we cannot measure. The remaining quantities are
those an advertiser can measure locally without requiring a global
view. We control for noisy data (i.e., adjust for false-positives and
false-negatives) using a control experiment. Our approach does not
(and indeed cannot) report whether a speciﬁc click is click-spam or
not. The output is a single number representing our estimate of the
fraction of clicks for the given ad that click-spam accounts for.
3.2.1 Data Collection
The detailed data collection procedure is as follows.
1. The advertiser (or a researcher signed-up as an advertiser with
an ad network) creates his ads of interest in the usual way. That
is, enters the text of the ad, selects ad targeting criteria (i.e., search
keywords, user demographics, mobile vs. non-mobile, etc.), sets
his advertising budget (i.e., auction bid amount, daily-budget), and
sets the destination URL of the ad to his landing-page — a page on
the advertiser’s website the user should be sent to.
2. When a user clicks the ad, the advertiser website either loads the
intended landing-page for the ad, or with some (small) probability
ﬁrst loads an interstitial page before eventually loading the landing-
page. The point of the interstitial page is to turn away some fraction
of users (legit clicks or not). To this end, the interstitial page may
require some passive or active user engagement before continuing
on to the landing-page. An example of passive engagement is to
require the user to stay on the page for a few seconds before con-
tinuing on to the landing page (the interstitial page in this case may
simply show a “loading...” message; it is known that a few sec-
onds increase in page loading time can result in a measurable drop
in trafﬁc [6]). Some examples of active engagement is to require
the user to click a link (e.g., “This page has moved. Click here to
continue.”) or, in the extreme case, solve a CAPTCHA [15], both
of which also result in signiﬁcant drops in trafﬁc.
Assumption 1. An implicit assumption is that the interstitial page
will turn away a (unknown) larger portion of the click-spam traf-
ﬁc than the (unknown) portion of legitimate trafﬁc it turns away.
Speciﬁcally, we do not assume for example that all good users will
patiently wait a few seconds; rather we assume that a smaller por-
tion of click-spam trafﬁc will wait the duration than the portion of
good users doing so.
Indeed user dwell time and willingness to
click have long been considered an implicit measure of user inter-
est [29, 35]. Interstitial pages leverage this knowledge to enhance
the quality of the trafﬁc reaching the landing-page by some (un-
known) amount as compared to without the interstitial page.
3. Next the advertiser deﬁnes some advertiser-speciﬁc user en-
gagement that he considers ultimate proof that the user intended
to click the ad. For example, if the user makes a ﬁnancial transac-
tion on the advertiser’s site, or signs up for some mailing list, etc.
We call such users gold-standard users. Certainly not all users are
gold-standard. But as long as a handful of users coming directly
to the landing-page, and a handful coming to the landing-page via
the interstitial page are gold-standard, we can apply our Bayesian
approach below.
Assumption 2. We make an implicit assumption that for users that
are not turned away by the interstitial page, their likelihood of be-
coming gold-standard users is not signiﬁcantly changed. We do not
assume that the interstitial page will not turn away users who may
have become gold-standard users. Rather we assume for example
that some users will not wait on the interstitial page, but if they do,
they will not hold a grudge. We empirically ﬁnd this assumption to
hold in practice as we report later.
4. Lastly, extending the technique in [25], the advertiser creates a
second ad that is identical to the ad created in step 1 above with the
exception of the text of the ad. That is, the second ad has the same
targeting criteria, advertising budget, and destination URL, but the
text of the ad is junk (e.g., a random nonsensical combination of
words). We use this ad to adjust for false positives.
Assumption 3. We assume that very few users will intentionally
click the second ad. While some users may be curious about the
random set of words, we ﬁnd this assumption is borne out in prac-
tice. We also assume for now that the click-spam click-through-
ratio i.e., the ratio of click-spam clicks to impressions of the ad) is
independent of the text of the ad (we relax this assumption later).
3.2.2 Bayesian Estimation
Let Gd and Gi be the event that the user is a gold-standard user
that arrived either directly, or via the interstitial page respectively.
Let Id and Ii be the event that the user intended to click the ad (i.e.,
not click-spam) out of all users directly reaching the landing-page,
or all users reaching via the interstitial page respectively.
Bayesian equation for P (Id): The advertiser is interested in
learning P (Id). G and I are linked using Bayes theorem as fol-
lows: P (G|I) = P (I|G)×P (G)/P (I). Note that a gold-standard
user implies that the click is not click-spam, i.e., P (I|G) = 1. As
discussed above in Assumption 2, P (Gd|Id) ≃ P (Gi|Ii); substi-
tuting and simplifying yields: P (Id) = P (Gd)×P (Ii)
.
P (Gi)
P (G) is computed as the ratio of the number of gold-standard
clicks (g; known) to the number of clicks (n; known). P (Ii) is the
ratio of the number of non-click-spam clicks (ii; unknown) to the
number of clicks (ni; known) arriving via the interstitial page. The
above equation reduces to:
P (Id) =
gd
nd
× ii
ni
gi
ni
=
gd × ii
nd × gi
(1)
Only ii on the right-hand-side is unknown.
Estimating ii: As mentioned, the interstitial page enhances the