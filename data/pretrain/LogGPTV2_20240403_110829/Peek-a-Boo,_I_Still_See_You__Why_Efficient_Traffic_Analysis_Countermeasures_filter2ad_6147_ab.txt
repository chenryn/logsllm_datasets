density estimation techniques to determine the probability
Pr (Y |(cid:2)i), but instead uses the aggregated frequency of the
features (i.e., normalized distribution) across all training
vectors. Thus,
the H classiﬁer uses normalized counts
of (direction, length), whereas the LL classiﬁer exam-
ined raw counts. Furthermore, Herrmann et al. suggest a
number of approaches for normalizing these counts. For
our evaluation, we combine term frequency transformation
and cosine normalization, as these were identiﬁed by
Herrmann et al. to be the most effective in the SSH setting.
C. Panchenko et al. Classiﬁer
Panchenko et al. [14] (P) take a completely different
approach by applying a support vector machine (SVM)
classiﬁer to the problem of identifying web pages. A
support vector machine is a type of binary linear clas-
siﬁer that classiﬁes points in a high-dimensional space by
determining their relation to a separating hyperplane. In
particular, the SVM is trained by providing labeled points
and discovering a hyperplane that maximally separates the
two classes of points. Classiﬁcation occurs by determining
where the point in question lies in relation to the splitting
hyperplane. Due to the complexity of SVM classiﬁers, we
forego a detailed discussion of their various parameters
and options.
We conﬁgure our SVM as follows. We use the same
radial basis function (RBF) kernel as Panchenko et al. with
parameters of C = 217 and γ = 2−19. The P classiﬁer
uses a wide variety of coarse and detailed features of
the network data mostly derived from packet lengths and
ordering. Some of these features include the total number
of bytes transmitted, total number of packets transmitted,
proportion of packets in each direction, and raw counts
of packet lengths. There are also several features known
as “markers” that delineate when information ﬂow over
the encrypted connection has changed direction. These
markers aggregate bandwidth and number of packets into
discrete chunks. Each of the features considered by the P
classiﬁer are rounded and all 52 byte TCP acknowledge-
ment packets are removed to minimize noise and variance
in the training and testing vectors.
334
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:30 UTC from IEEE Xplore.  Restrictions apply. 
IV. COUNTERMEASURES
For ease of exposition and analysis, we organize the
considered countermeasures into three categories: those
that are inspired by the padding allowed within the SSH,
TLS and IPSec standards (Type-1); other padding-based
countermeasures (Type-2); and countermeasures that make
explicit use of source and target packet-length distributions
(Type-3). In what follows, we describe the operation of
the countermeasures we evaluate and discuss the overhead
they generate. Lengths are always measured in bytes.
A. Type-1: SSH/TLS/IPSec-Motivated Countermeasures
A common suggestion, already used in some implemen-
tations, like GnuTLS4, is to obfuscate plaintext lengths
by choosing random amounts of extra padding to append
to the plaintext prior to encryption. SSH, TLS and IPSec
allow up to 255 bytes of padding in order to align the to-
be-encrypted plaintext with the underlying block cipher
boundary, and also to provide some obfuscation of the
original plaintext length. We consider two ways in which
this might be implemented within SSH/TLS/IPSec: (1)
choose a single random amount of padding to be applied
across all plaintexts in the session, or (2) choose a random
amount of padding for each plaintext.
Session Random 255 padding: A uniform value r ∈
{0, 8, 16 . . . , 248} is sampled and stored for the session.5
Each packet in the trace has its length ﬁeld increased by r,
up to a maximum of the MTU.
Packet Random 255 padding: Same as Session Random
255 padding, except that a new random padding length r
is sampled for each input packet.
We note that our simulation of Session Random and
Packet Random padding in this setting are not exactly
what would be implemented in reality because we do not
have access to the size of the plaintext data from the
datasets available to us. Instead, our assumption is that the
plaintext data is sufﬁciently short to ﬁt into a single TCP
packet and therefore is closely approximated by simply
adding the padding to the length of the ciphertext. What we
simulate, therefore, is likely to overstate the efﬁcacy of the
countermeasure since the (at most) 255 bytes of padding
would be dominated by the true size of the plaintext (e.g.,
up to 214 bytes for TLS), thereby providing relatively
little noise. In contrast, our simulation allows for a much
larger ratio of plaintext to padding, which in turn adds
signiﬁcantly more noise.
B. Type-2: Other Padding-based Countermeasures
The second class of countermeasure we consider are
those padding mechanisms that are not easily supported in
4http://www.gnu.org/software/gnutls/
5We assume that the underlying encryption block size is 8 bytes. For
the Liberatore and Levine dataset, we know this assumption is true. We
do not expect classiﬁcation accuracies to be different if, in fact, the block
size was 16 bytes.
existing encrypted network protocol standards due to the
amount of padding added. In this scenario, we assume the
countermeasure will be capable of managing fragmentation
and padding of the data before calling the encryption
scheme. Most of the countermeasures considered by prior
work fall into this category, though we also consider a
randomized scheme that has not been previously explored.
Linear padding: All packet lengths are increased to the
nearest multiple of 128, or the MTU, whichever is smaller.
Exponential padding: All packet lengths are increased
to the nearest power of two, or the MTU, whichever is
smaller.
If the packet length is ≤ 128,
Mice-Elephants padding:
then the packet is increased to 128 bytes; otherwise it is
padded to the MTU.
Pad to MTU: All packet lengths are increased to the MTU.
Packet Random MTU padding: Let M be the MTU and (cid:2)
be the input packet length. For each packet, a value r ∈
{0, 8, 16, . . . , M − (cid:2)} is sampled uniformly at random and
the packet length is increased by r.
C. Type-3: Distribution-based Countermeasures
Wright et al. [22] presented two novel suggestions as
improvements upon traditional per-packet padding coun-
termeasures: direct target sampling (DTS) and trafﬁc mor-
phing (TM). On the surface, both techniques have the same
objective. That is, they augment a protocol’s packets by
chopping and padding such that the augmented packets
appear to come from a pre-deﬁned target distribution (i.e.,
a different web page). Ideally, DTS and TM have secu-
rity beneﬁts over traditional per-packet padding strategies
because they do not preserve the underlying protocol’s
number of packets transmitted nor packet lengths. Al-
though the full implementations details of DTS and TM
are beyond scope of this paper (see [22]), we give a high-
level overview here.
Direct target sampling: Given a pair of web pages A
and B, where A is the source and B is the target, we
can derive a probability distribution over their respective
packet lengths, DA and DB. When a packet of length i
is produced for web page A, we sample from the packet
length distribution DB to get a new length i(cid:2). If i(cid:2) > i,
we pad the packet from A to length i(cid:2) and send the
padded packet. Otherwise, we send i(cid:2) bytes of the original
packet and continue sampling from DB until all bytes
of the original packet have been sent. Wright et al. left
unspeciﬁed morphing with respect to packet timings. We
assume a negligible overhead to perform morphing and
specify a 10ms inter-packet delay for dummy packets.
In our experiments, we select the target distribution
uniformly at random from our set of k potential identi-
ties. The selected web page remains unchanged (i.e., no
335
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:30 UTC from IEEE Xplore.  Restrictions apply. 
Countermeasure
Session Random 255
Packet Random 255
Linear
Exponential
Mice-Elephants
Pad to MTU
Packet Random MTU
Direct Target Sampling
Trafﬁc Morphing
Overhead (%)
LL
9.0
9.0
4.2
8.7
41.6
81.2
40.1
86.4
60.8
H
7.1
7.1
3.4
10.3
39.3
58.1
28.8
66.5
49.8
Figure 2. Bandwidth overhead of evaluated countermeasures calculated
on Liberatore and Levine (LL) and Herrmann et al. (H) datasets.
countermeasures applied), while the remaining k − 1 web
pages are altered to look like it. After the source web page
has stopped sending packets, the direct target sampling
countermeasure continues to send packets sampled from
DB until the L1 distance between the distribution of sent
packet lengths and DB is less than 0.3.
Trafﬁc morphing: Trafﬁc morphing operates similarly to
direct target sampling except that instead of sampling from
the target distribution directly, we use convex optimization
methods to produce a morphing matrix that ensures we
make the source distribution look like the target while
simultaneously minimizing overhead. Each column in the
matrix is associated with one of the packet lengths in
the source distribution, and that column deﬁnes the target
distribution to sample from when that source packet length
is encountered. As an example, if we receive a source
packet of length i, we ﬁnd the associated column in the
matrix and sample from its distribution to ﬁnd an output
length i(cid:2). One matrix is made for all ordered pairs of source
and target web pages (A, B). The process of padding
and splitting packets occurs exactly as in the direct target
sampling case. Like the direct target sampling method,
once the source web page stops sending packets, dummy
packets are sampled directly from DB until the L1 distance
between the distribution of sent packet lengths and DB
is less than 0.3. In our simulations we select a target
distribution using the same strategy described for DTS.
D. Overhead
Although the focus of our evaluation lies in understand-
ing the security provided by these countermeasures, we
realize that their cost in terms of bandwidth overhead and
latency is an important factor that determines whether they
are applicable in practice or not. To this end, we present
the bandwidth overhead induced by the countermeasures
for both the Liberatore and Levine and Herrmann et al.
datasets in Figure 2. Overhead is calculated as (bytes sent
with countermeasure)/(bytes sent without countermeasure)
times 100. We note that these overhead measurements
differ from those of earlier work because we do not ap-
k = 2
k = 128
Type-1
Type-2
Type-3
Type-1
Type-2
Type-3
H
P
LL
85% 71% 99%
97% 80% 99%
98% 76% 99%
41% 13% 91%
46%
90%
82%
25%
5%
3%
Figure 3. The lowest average accuracy for each countermeasure class
against LL, H, and P classiﬁers using the Hermann dataset. Random
guessing yields 50% (k = 2) or 0.7% (k = 128) accuracy.
ply countermeasures to TCP acknowledgement (52-byte)
packets. For example, Liberatore and Levine [10] report
a Pad to MTU overhead of 145% and Wright et al. [22]
report 156%. We argue that acknowledgement packets
are present regardless of the content being downloaded
and there is no standard mechanism for application-layer
countermeasures to apply padding to TCP acknowledge-
ment (52-byte) packets. Nevertheless, as we will see in the
following section, there is almost no correlation between
overhead and the level of conﬁdentiality provided by the
countermeasure
V. EXISTING COUNTERMEASURES VERSUS
EXISTING CLASSIFIERS
We pit the LL, H, and P classiﬁers from Section III
against trafﬁc simulated as per the nine countermeasures
of the previous section. The testing methodology used was
described in Section II. We also look at classiﬁability of
the raw trafﬁc, meaning when no countermeasure (beyond
the normal SSH encryption) is applied.
We note that despite the appearance of the LL, H, and
P classiﬁers in the literature, all the results we report
are new. In particular, the H and P classiﬁers were never
tested against any of these countermeasures, while the LL
classiﬁer did look at efﬁcacy against Linear , Exponential,
Mice-Elephants, and Pad to MTU but only at k = 1000.
Figure 3 contains a high-level summary for k = 2 and
k = 128. We refer the interested reader to Appendix A for
comprehensive results.
In the rest of this section we analyze the results from
various points of view, including the role of the dataset,
the relative performance of the classiﬁers, and the relative
performance of the different countermeasures.
A. Comparing the Datasets
Before beginning digging into the results in earnest, we
ﬁrst evaluate the consistency and quality of the two avail-
able datasets. We do so to determine the extent to which
results gathered using them represent the identiﬁability
of the web pages rather than artifacts of the collection
process, such as connection timeouts and general collec-
tion failures. In Figure 4, we show the silhouette of the
accuracy achieved by the three classiﬁers across a number
of universe sizes and countermeasures using each of the
336
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:30 UTC from IEEE Xplore.  Restrictions apply. 
Figure 4. Comparison of accuracy silhouettes for the Liberatore and Levine and Herrmann datasets across all countermeasures for the LL, H, and P
classiﬁers, respectively.
datasets. That is, the lower boundary of each silhouette
is the best-performing countermeasure while the upper
boundary represents the worst-performing (which turned
out to always be no countermeasure, as one would expect).
Ideally, the classiﬁer accuracies should be roughly sim-
ilar, or at least show similar trends. Instead, what we
notice is a trend toward strong drops in performance as
the web page universe size increases in the Liberatore
dataset, whereas in the Herrmann dataset we see a much
smoother drop across multiple universe sizes and across
all classiﬁers. This is most notable under the P classiﬁer
(far right of Figure 4).
To take a closer look at the differences between the
datasets, we report some basic statistics in Figure 5. The
fraction of traces that have short duration, particularly ones
that are clearly degenerate (≤ 10 packets), is much higher
in the Liberatore dataset. Such degenerate traces act as
noise that leads to classiﬁcation errors. We suspect that
they arise in the dataset due to collection errors (e.g.,
incomplete website visits), and may imply that some pre-
vious works [10, 22] may underestimate the privacy threat
posed by web page trafﬁc analysis attacks. Despite the
extra noise, the classiﬁers performed well, just consistently
lower at high values of k as compared to the Herrmann
dataset. In addition, the Herrmann dataset was collected
in 2009, as opposed to the Liberatore dataset, which