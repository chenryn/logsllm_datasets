outputs
0    1     2     3
0    1     2     3
0    1     2     3
6 0 12 0
6 0 12 0
6 0 12 0
4 5 0 6
4 5 0 6
4 5 0 6
0 6 14 5
0 6 14 5
0 6 14 5
5 0 0 4
5 0 0 4
5 0 0 4
2 0
2 0
2 0
3 5
3 5
3 5
capacity,flow 
capacity,flow 
capacity,flow 
s
s
s
12,12
12,12
12,12
12,12
12,12
12,12
12,12
12,12
12,12
12,6
12,6
12,6
S= 1.5
S= 1.5
S= 1.5
T= 8 
T= 8 
T= 8 
a0
a0
a0
a1
a1
a1
a2
a2
a2
a3
a3
a3
12,6
12,6
12,6
5,5
5,5
5,5
6,6
6,6
6,6
5,2
5,2
5,2
6,6
6,6
6,6
4,4
4,4
4,4
14,6
14,6
14,6
6,3
6,3
6,3
5,0
5,0
5,0
4,4
4,4
4,4
b0
b0
b0
b1
b1
b1
b2
b2
b2
b3
b3
b3
12,12
12,12
12,12
12,11
12,11
12,11
12,12
12,12
12,12
12,7
12,7
12,7
t
t
t
outputs
outputs
outputs
0    1     2     3
0    1     2     3
0    1     2     3
6 0 6 0
6 0 6 0
6 0 6 0
4 5 0 3
4 5 0 3
4 5 0 3
0 6 6 0
0 6 6 0
0 6 6 0
2 0 0 4
2 0 0 4
2 0 0 4
uts
uts
uts
p
p
p
in
in
in
0
0
0
1
1
1
2
2
2
3
3
3
Fig. 1. Example showing a maximal ordered schedule constructed from a blocking flow. 
For any integer-valued flow, we can construct a schedule that 
transfers  cells  from  input  i  to output j based on the flow on the 
edge from input i to output j. Such a schedule does not violate any 
of the constraints on the number of cells that can be sent from any 
input or to any output. Also, any blocking flow corresponds to a 
maximal  schedule,  since  any  blocking  flow  corresponding  to  a 
schedule that fails to transfer a cell c from input i to output j can-
not saturate the edge from input i to output j; hence it must satu-
rate the edge from s to i or the edge from j to t. Such a flow corre-
sponds to a schedule in which either input i sends ST cells or out-
put j receives ST. 
Dinic’s  algorithm  [13]  for  the  maximum  flow  problem  con-
structs blocking flows in acyclic flow networks as one step in its 
execution. There are several variants of Dinic’s algorithm, that use 
different  methods  of  constructing  blocking  flows.  The  most 
straightforward method is to repeatedly search for st-paths with no 
saturated  edges  and  add  as  much  flow  as  possible  along  such 
paths. We can obtain a maximal, ordered scheduler by modifying 
Dinic’s  algorithm  so  that  it  preferentially  selects  edges  between 
input vertices and output vertices, according to the VOQ ordering 
at the input. The blocking flow shown in Fig. 1 was constructed in 
this way, based on the BLOOFA ordering. 
If paths are found using depth-first search and edges leading 
to dead-ends are removed, Dinic’s algorithm finds a blocking flow 
in O(mn) time where m is the number of edges and n is the num-
ber of vertices. Because the flow graphs used here have bounded 
depth and because the number of inputs, outputs and edges are all 
bounded by the number of non-empty VOQs, the algorithm finds a 
blocking flow in O(v) time where v is the number of non-empty 
VOQs.  This  yields  an  optimal  centralized  scheduler.  However, 
since  v  can  be  as  large  as  n2  (where  n  is  the  number  of  router 
ports), this is not altogether practical. 
We  can  obtain  a  distributed,  iterative  scheduling  algorithm 
based  on  similar  ideas.  Rather  than  state  this in the language of 
blocking flows, we describe it directly as a scheduling algorithm. 
In  the  distributed  scheduler,  we  first  have  an  exchange  of  mes-
sages in which each output announces the number of cells in its 
outgoing queue. The inputs use this information to maintain their 
VOQ order. Note that this requires that each output send n mes-
sages  and  each  input  receive  n  messages.  Next,  the  inputs  and 
outputs proceed through a series of rounds.  
In each round, inputs that have uncommitted cells to send and 
have not yet committed to sending ST cells, send bid messages to 
those outputs that are still prepared to accept more cells. The in-
puts construct their bids in accordance with the VOQ ordering. In 
particular, an input commits all the cells it has for the first output 
in  the  ordering  and  makes  similar  maximal  bids  for  subsequent 
outputs until it has placed as many bids as it can. Inputs may not 
overbid,  as  they  are  obliged  to  send  cells  to  any  output  that ac-
cepts  a  bid.  Note  that  at  most  one  of  the bid messages an input 
sends during a round does not commit all the cells that it has for 
the target output. 
During each round, outputs receive bids from inputs and ac-
cept as many as possible. If an output does not receive bids for at 
least ST cells, it does nothing during this round. That is, it sends 
no message back to the inputs. Such a “response” is treated by the 
inputs  as  an  implicit  accept  and  is  taken  into  account  in  subse-
quent bids. Once an output has received bids for a total ST cells, it 
sends an accept message to all the inputs (not just those that sent 
it bids). An accept message contains a pair of values (i,x) and it 
means that the output accepts all bids received from inputs with 
index  less  than  i,  rejects  all  bids  from  inputs  with  index  greater 
than  i  and  accepts  exactly  x  cells  from  input  i.  Once  an  output 
sends an accept message, its role in the scheduling is complete. 
This procedure has some attractive properties. First, each out-
put  sends  n  messages  in  the  bidding  process,  so  each  input  re-
ceives no more than n messages. Also, an input sends at most two 
bids  to  any  particular  output,  so  an  input  sends  at  most 2n bids 
and an output receives at most 2n bids. Thus, the number of cells 
that must be handled at any input or output during the scheduling 
is O(n). Unfortunately, this does not imply that the algorithm runs 
in  O(n)  time,  since  it  can  require  up  to  n  rounds  and  in  each 
round, there may be some outputs that handle close to n messages.  
It is possible to reduce the time for each round by having the 
switch elements that make up the interconnection network partici-
pate in the handling of bids and responses. However, in the next 
section we turn our attention instead, to algorithms that are sim-
pler 
implement  and  which,  while  not  provably  work-
conserving,  are  able  to  match  the  performance  of  the  work-
conserving algorithms, even under extreme traffic conditions.  
3. DISTRIBUTED BLOOFA 
The  work-conserving  algorithms  discussed  above  can  be  imple-
mented using iterative algorithms that require a potentially large 
number  of  message  exchanges.  In  this  section,  we  formulate  a 
distributed algorithm that approximates the behavior of BLOOFA 
while  requiring  just  one  exchange  of  messages.  Our Distributed 
BLOOFA (DBL) scheduler avoids the need for many message ex-
to 
phase 1
phase 1
phase 2
phase 2
phase 3
phase 3
phase 4
phase 4
Fig. 2. Typical stress test 
changes  by  having  the  inputs  structure  their  bids  to  avoid  the 
situation  swamping  some  outputs  with  more  bids  than  they  can 
accept, while leaving others with no bids. Specifically, the inputs 
use  a  technique  introduced  in  [11]  called  backlog-proportional 
allocation to limit the number of bids that are made to any output. 
DBL starts with each input i sending a message to each output 
j,  telling  it  how  many  cells B(i,j)  it  has  in  its  VOQ for output j. 
Each  output  j  then  sends  a  message  to  all  inputs  containing  the 
number of cells in its output queue (B(j)) and the total number of 
cells that inputs have to send it (B(+, j)2). Note that each input and 
output  sends  and  receives  n  messages.  Once  this  exchange  of 
messages  has  been made, each input independently decides how 
many cells to send to each output. To prevent too many cells from 
being  sent  to  any  output,  input  i  is  allowed  to  send  at  most  ST 
×B(i, j)/B(+, j) cells to output j. Each input then orders the outputs 
according  to  the length of their output queues and goes through 
this list, assigning as many cells as it is permitted for each output, 
before going to the next output in the list. The scheduling is com-
plete  when  the  input  has  assigned  a  total  of  ST  cells  or  has  as-
signed all the cells permitted by the bound. 
We  studied  the  performance  of  DBL  using  simulation  for 
speedups between 1 and 2. We start with an extreme traffic pat-
tern, we call a stress test, that is designed to probe the perform-
ance  limits  of  the  distributed  scheduling  algorithms.  While  the 
stress test is not a provably worst-case traffic pattern for any par-
ticular  scheduler,  it  does  create  conditions  that  make  it  difficult 
for schedulers to maintain ideal throughput.  
The stress test consists of a series of phases, as illustrated in 
Fig.  2.  In  the  first  phase,  the  arriving  traffic  at  each  of  several 
inputs is directed to a single output. This causes each of the inputs 
to build up a backlog for the target output. The arriving traffic at 
all  the inputs is then re-directed to a second output, causing the 
accumulation  of  a  backlog  for  the  second  output.  Successive 
phases proceed similarly, creating backlogs at each input for each 
of several outputs. During the last phase, the arriving traffic at all 
inputs is re-directed to a distinct new output for each input. Since 
each of the target outputs of the last phase has only a single input 
directing traffic to it, that input must send cells to it as quickly as 
they  come  in,  while  simultaneously  clearing  the  accumulated 
backlogs  for  the  other  outputs,  in  time  to  prevent  underflow  at 
those  other  outputs.  This  creates  an  extreme  condition  that  can 
lead to underflow. The timing of the transitions between phases is 
chosen so that the total number of cells in the system directed to 
each  output  is  approximately  the  same  at  the  time  the  transition 
takes place. The stress test can be varied by changing the number 
of participating inputs and the number of phases. 
2. We use the addition symbol (‘+’) as a function argument to 
denote the summation of the function over all values of that ar-
gument. 
Fig. 3 shows results from a sample stress test. The top chart 
shows the VOQ lengths at input 0 and the output queue lengths at 
outputs 0 to 4 (by symmetry, the VOQ lengths at other inputs will 
be approximately the same as those at input 0). The time unit is 
the update interval, T. The unit of storage is the number of cells 
that  can  be  sent  on  an  external  link  during  the  update  interval. 
Note that during the last phase, B(0,4) rises, indicating that input 
0 is unable to transfer cells to output 4 as quickly as they come in. 
This results in loss of link capacity at output 4. The second chart 
shows the miss fraction at output 4 during the last phase. The term 
“miss”  refers  to  a  missed  opportunity  to  send  a  cell.  The  miss 
fraction  measures  the  fraction  of  the  link  capacity  that  is  effec-
tively lost during the last phase due to such misses and is a meas-
ure  of how far the system deviates from being work-conserving. 
The  curve  labeled  simply,  “miss  fraction”  measures  the  average 
miss fraction during successive measurement intervals (the meas-
urement intervals are 25 time units long). The curve labeled “av-
erage miss fraction” is the fraction of the link capacity lost from 
the  start  of  the  last  phase  to  the  time  plotted.  We  observe  that 
almost 30% of the link’s capacity is effectively lost between the 
start of the last phase and the end of the period shown. 
The first chart in Fig. 4 shows how DBL performs on a series 
of stress tests with speedups varying between 1 and 1.5. (In these 
tests, the length of the stress test was set to 1.2 times the length of 
time that would be required to forward all the cells received dur-
ing the first phase in an ideal output-queued switch.) We see here 
that the average miss fraction (for the output targeted by input 0 in 
the  last  phase)  drops  steadily  with increasing speedup, dropping 
to zero before the speedup reaches 1.5. We performed 90 sets of 
stress tests, using different numbers of inputs and phases (up to 15 
inputs  and  15  phases).  The  results  plotted  in  the  figure  are  the 
worst-cases for 2, 3, 4 and 5 inputs. In all cases, the average miss 
fraction for the last phase target output dropped to zero for speed-
ups greater than 1.5.  
To compare DBL to BLOOFA, we performed the same series of 
90  stress  tests  on  BLOOFA.  For  speedups  below  2,  the  method 
used to select which inputs send traffic to a given output can have 
a significant effect on the performance of BLOOFA. For the results 
given here, we went through the outputs in order (from smallest 
output-side backlog to largest) and for each output j, we assigned 