rest of the network functions (NFs). These updates are generally
652
FlatBuffers-based (de)/serializationIn-Memory LogLoad BalancerFBs basedSerialization EnginePer Procedure CPF State SyncingPrimary Control Plane Function (CPF)CPF Replicas Control Traffic Aggregator(CTA)BSUESIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
Mukhtiar et al.
at the CTA ensures that the backup replica has up-to-date
state for the UE which can be used to serve the UE in the
event the primary CPF fails.
(4) CTA stores the ACK received from all the replicas with the
last message of the procedure in the store.
To keep the CTA message log size in check, the CTA periodically
scans the message store and prunes all the messages corresponding
to a procedure for which ACKs have been received from all the
backup CPFs.
4.2.4 Out-of-date Backup CPFs. We now describe the process
of marking a UE state as outdated in a replica.
(1) The CTA periodically scans the last message of every proce-
dure in the log store and if:
(a) An ACK is not received from one or multiple replicas for a
configurable timeout (e.g., 30 seconds in our case, because
procedure completion times are at most a few seconds),
it informs the corresponding replica(s) that the particular
UE’s state is outdated and also provides (i) the list of CPFs
(if exists) having up-to-date UE’s state, and (ii) the logical
clock associated with the last message of the procedure
(this is used to ignore the reception of outdated state).
(b) Replica(s) mark the state of the particular UE outdated.
(c) If a CPF is successful in fetching up-to-date UE’s state
from the list of CPFs provided by the CTA, it marks UE’s
state up-to-date.
(d) CTA deletes all the messages belonging to this procedure.
(2) If a replica receives state update for a UE, which was pre-
viously marked outdated, UE’s state in the CPF is marked
up-to-date.
(3) If a CPF receives a request from a UE for which it does not
have an up-to-date state, UE is asked to Re-Attach.
(4) If a second control procedure starts for a UE for which ACK
is not received from one or multiple replicas, CTA informs
the corresponding replica(s) that the UE’s state is outdated
and provides a list of CPFs having an up-to-date state.
4.2.5 Consistency and Failure Recovery. We describe the recov-
ery process under each of the failure scenarios enumerated below
(also depicted in Figure 5).
Failure Scenario 1 (Primary fails - backup up-to-date): In this
scenario, primary CPF fails, however, there exists a backup replica
which has successfully synchronized with the primary CPF on the
completion of the last procedure for the UE. In addition, there are no
ongoing procedures from the UE. In this case, the back-up replica
is up-to-date and satisfies Read your Write consistency.
Failure Scenario 2 (Primary fails - message replay on backup):
Primary CPF fails while there is an ongoing procedure from the
UE. However, the backup replica has successfully synchronized
with primary on completion of the previous procedure. In this case,
the CTA replays all the stored messages on the back-up replica
to make it up-to-date before serving the UE. After the messages
are replayed, the backup replica is up-to-date, and Read your Write
consistency is maintained.
Failure Scenario 3 (Primary fails - all replicas out-of-sync):
Primary CPF fails while no backup replica exists for the UE which
653
Figure 5: Failure scenarios.
was synchronized with the primary on previous procedure comple-
tion. In this case, we avoid the UE from operating in an outdated
state. Instead, we recreate a consistent UE state at the CPF, by
asking the UE to execute the Re-Attach procedure. The Re-Attach
procedure constructs consistent UE state, and any subsequent reads
operate on this state, hence satisfying Read your Writes consistency.
Failure Scenario 4 (CTA fails): In this case, the failure recovery
procedure is similar to one used in failure scenario 3. When a CTA
fails, the UE executes the Re-Attach procedure, through a new CTA,
creating (i) fresh state for the UE at new CPF(s) and (ii) a mapping
of the UE to a specific CPF on the new CTA.
In failure scenarios 1 and 2, Neutrino completely masks failure
from the UE. In failure scenario 3, we do not have an up-to-date
state for the UE in the core network. However, we prevent the UE
from operating on an outdated state, thus maintaining Read your
Writes consistency. However, as UE is asked to Re-Attach, this can
impact application performance because of the time required to
execute Re-Attach, as shown in Figure 9. As we do not backup CTA
state, recovery in failure scenario 4 is exactly similar to that of
scenario 3. In summary, Neutrino provides consistency in all the
above failure scenarios and significantly improves delay to recover
from failures in scenarios 1 and 2.
4.3 Proactive Geo-replication
As discussed in the previous section, a single CPF serves as a pri-
mary for each UE, and the state is replicated on N number of backup
replica(s). In this section, we discuss how this state can be used to
expedite handovers.
We first discuss our deployment model. Figure 6 shows our de-
ployment model. We divide the deployment area into regions. The
unit region, which we call the level-1 region, consists of multiple
BSs, one CTA, and a pool of CPFs.13 There are multiple options for
deploying CTA and CPFs. One option is co-locating the CTA with
the pool of CPFs (e.g., in a central office) which would serve all the
BSs in a level-1 region. Another option is deploying CTA and CPFs
on different edge nodes (e.g., combination of central towers and
13As a CTA also performs load balancing of the control traffic from the BSs, deploying
a CTA at each BS is not a viable option.
Out-of-dateUp-to-dateFailed(a) Failure scenarios 1 and 2PrimaryBackupUECTA(b) Failure scenario 3(c) Failure scenario 4BSA Low Latency and Consistent Cellular Control Plane
SIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
therefore no state migration is required. Such handovers are fast
because only BS change is required without any UE state migration
between CPFs.
Inter-CPF hand-over: Inter-CPF handover in the 4G/LTE system
is costly in terms of latency as the UE state needs to be migrated
to the target CPF. In edge deployment, where CPFs will be placed
closer to the UEs, the frequency of inter-CPF handovers will in-
crease. Neutrino provides a mechanism for faster handover between
the CPFs by proactively replicating UE’s state in the target region.
Consider the following example from the deployment scenario
in Figure 6(b). A UE moves across the level-1 regions where CTA of
the source cell is different from the target cell; e.g., a UE moves from
BS_10 (R5, CTA-5) to BS_30 (R4, CTA-4). When BS_10 determines
that handover (HO) to the target BS_30 is required and both BSs are
sharing the same level-2 rings, UE state migration before the HO
can be avoided. This is because Neutrino already keeps the state
of each UE on a CPF replica in the level-2 ring. We call such a HO,
Fast Handover.
4.4 Serialization Engine
We observe that FlatBuffers [28] provide the best trade-off in terms
of performance and expressiveness. They significantly speed-up
message processing times, and can represent different types of
control messages, e.g., we observed cellular control message widely
use unions and unsigned data types which are not supported by
LCM. FlatBuffers (FBs) is fast because it provides (i) direct access to
inner fields via pointers during decoding and (ii) needs no additional
memory allocation during encoding.
However, the performance benefits of FBs come at a cost: large
encoded message size. To provide fast access to inner fields, the
FBs compiler couples a vtable containing pointers with each table
containing data elements. The pointers in the vtable contain byte
offsets which are used to directly access a field in the encoded
message. While this speeds up the decoding time, these vtables
contribute significantly to the encoded message size. ASN.1 PER
on the hand follows a Length-Value encoding scheme and simply
couples the length of a table with its contents (also encoded as
Length-Value pairs). Hence resulting in a smaller encoded buffer
size as compared to FBs.
Optimizing FlatBuffers: Cellular control messages16 makes wide
use of unions containing single data elements. However, FBs only
supports tables in unions. When a single field needs to be added
to a union, it first has to be wrapped in a table. This is inefficient
because this wrapping generates a vtable for the single field. Since
the union contains a single field, traversal using the vtable pointers
is unnecessary. Ideally, we should be able to directly access the
single field. To address this issue, we introduced a new data type,
named svtable, that generates less metadata for single-value fields
in unions. Our optimization reduces 10 bytes for single scalar fields
in unions and 14 bytes for single variable length fields in tables
while also reducing the encoding and decoding times (see Figure 19
and 20). Other possible optimizations, include, the introducing a bit
string data type (since FBs currently only supports byte strings) and
variable-length data types, e.g., an integer in FBs is always encoded
in 4 bytes, even if it could be represented using fewer bytes.
16Specifically, message part of the S1AP protocol and NGAP protocol.
Figure 6: Deployment model. Left (a) shows regions defined
through geo-hashing, and Right (b) zooms into two sub-
regions containing CTAs and CPFs.
central office). For our evaluation, we assume CTA is co-located
with the CPFs serving a region. This option simplifies deployment,
and provides potentially lower propagation delays.
We assign each level 1 a geo-hash [4]. Each character in the
geo-hash represents two bits (one bit for GPS longitude and one
for latitude). If we take one character off from the geo-hash, we get
a geo-hash which points to a four times bigger region which we
call level-2 region. Geo-hash is not an essential requirement in our
design and the operator can manually define these regions however
our existing implementation is based on geo-hashes. Figure 6 (a)
shows four level-1 regions (R5, R4, R8, and R9). All these four
regions are collectively called the level-2 region. Figure 6 (b) shows
our deployment model.
Multiple consistent hash rings: BSs route control traffic to the
nearest CTA module. Each CTA implements two consistent hash
rings; (i) level-1 hash ring consists of all the CPFs in the level-1
region and (ii) level-2 hash ring includes all the CPFs in the level-2
region.14 How When CTA receives a control message from the
UE, it extracts a unique user ID,15 and hashes it to the level-1
ring to determine the primary CPF for the UE. When a control
procedure completes, the primary CPF replicates the user state on
N consecutive replicas on a level-2 ring (not included in the level-1
ring) based on the hash of the user’s ID. For example, if in Figure
6(a), a user is served by a CPF in the R5 region, its state will be
replicated on any N replicas from region R5, R8, or R9 based on the
hash of the user ID. Replicating state in other regions has certain
advantages, which include, (i) when handing over to a BS in the
nearby region, the user may find up-to-date state already present,
and (ii) different regions may have different failure modes. Based
on the description of the regions, we implement the following types
of handovers.
Intra-region hand-over: If a UE moves from one BS to another
BS within the same level-1 region in Neutrino, no CPF handover
is required. Consider the example of the deployment described in
Figure 6(b). If a UE move across the BSs within level-1 region where
CTA of the source and target cell remains the same, e.g. from BS_02
to BS_06 in region R5, the CPF serving the UE does not change
14One can potentially implement more than 2 consistent hash rings, however, there
are tradeoffs. We leave this exploration for future work.
15We specifically use MME-temporary mobile subscriber identity (M-TMSI) when the
UE is in idle state and the unique S1AP identifier for the UE in MME, when the UE
is active. Similar to [31], CTA assigns these two identifiers the same value for a UE
during the initial attach procedure.
654
(a)(b)CTA-5BS_05BS_01BS_02BS_03BS_06BS_10BS_09BS_08BS_07CTA-4BS_16BS_11BS_12BS_13BS_14BS_15BS_19BS_18BS_30R5R4CPF PoolCPF PoolLevel-2 RegionLevel-1 RegionR5R4R8R9SIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
Mukhtiar et al.
5 IMPLEMENTATION
We have implemented Neutrino and all supporting components
and functions in C/C++ programming language. A summary of our
implementation is given below:
Traffic Generator: Our traffic generator emulates both UE and BS;
it is based on DPDK (v 2.2 [2]) for fast I/O operations and is similar
to the traffic generator used in [50]. It replays real cellular control
traffic traces [45] and is also capable of serializing those control
messages using ASN.1 and our modified serialization scheme. In our
implementation, the base station communicates with the CTA using
S1AP—the protocol currently used in 4G/LTE networks between
the base stations and control plane functions.17
Message De/Serialization: We implemented the message serial-
ization (both ASN.1 and our FlatBuffers-based modified serialization
scheme) for all the control messages included in all the control pro-
cedures supported by our CPF implementation (see below). The
ASN.1 compiler we used is the same as used for OpenAirInter-
face [49], while the implementation of our serialization code is built
upon an open-source implementation of FlatBuffers [28].
Geo-Replication: For geo-replication, we implemented 2 bits per
character version of the Geo Hashing similar to the one used in [4],
thus causing a four-fold increase/decrease in the region size with
each character.
Control Traffic Aggregator: Our CTA module receives control
traffic from the BS through a custom DPDK application. A producer
thread reads packets from the NIC to ring buffers shared with
multiple consumer threads. Consumer threads read packets from
the shared ring buffers and transmit those to a CPF instance that is
selected based on the UE ID in the packet. We have implemented a
message logging module at the CTA using the standard C++ STL
map container. We have also implemented a consistent hashing
based load balancing scheme within the CTA, obviating the need
for separate load balancers.
Control Plane Function: Our CPF implementation supports the
following four control procedures: (i) initial attach, (ii) handover
with CPF change (iii) FastHandover and (iv) service request. To co-
ordinate various control procedures, we have implemented state
machines at both the CPF and the traffic generator. Our CPF im-
plementation also includes the module responsible for state repli-
cation. All experiments and evaluations are performed with five
CPF instances, each running on two CPU cores (one for processing
requests and the second one for state synchronization).
6 EVALUATION
In this section, we show the following:
(1) Impact on control procedure completion times: Neutrino
performs 2.3×, 3.4×, and 1.3× better in median PCT than exist-
ing EPC, SkyCore, and DPCM respectively.
(2) Impact under failures: In the case of CPF failure, it reduces
median PCT by 5.6× as compared to the existing EPC.
(3) Impact on control handovers: Neutrino improves handover
with CPF change by up to 3.1× in the median PCT. Neutrino
also implements a FastHandover which expedites handover op-
eration with proactive replication by up to 7×.
17A similar protocol is also used in 5G networks.
655