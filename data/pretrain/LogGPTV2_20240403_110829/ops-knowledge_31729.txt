User: I am trying to use Celery to output to multiple files. The task is very simple:

Get some data along with a file path
Append that data to the file path (and create the file if it doesn't exist)

I do not want to open/close the file handle each time, since I would write to the same file in many cases. So I made a simple FileHandlePool.
However, when running I noticed that for each thread/instance, celery will make a new FileHandlePool! So, I have files that are being overwritten.
What is the best way to handle this situation? Is it possible to have m FileHandlePool in the same scope as the main thread and have other celery threads access it?
Thanks!
Assistant: The pool does not seem to be shared by the celery threads. Ideal way to do it is to assign a single process the task of writing to files and all the celery threads should write to that process via queue.