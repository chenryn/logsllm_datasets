Note that there are many opensource NLP tools for POS tagging
and NER such as NLTK [30], CoreNLP [31], twitter_nlp [39], and
Twokenizer [35].
4.3 New and Re-emerging Words Detection
Not only is monitoring all the candidate words time-consuming,
but also it generates a lot of noise in event detection. Thus, it is
important to configure the words that need to be filtered away and
the words that can compose security events. For this purpose, we
have built the following dictionaries:
• DTech: This dictionary is for monitoring re-emerging words.
It includes technical words as well as security-specific words
like malware names, vulnerability names, company names,
and software/hardware names. We built an initial dictionary
by performing a statistical significance test for comparing
two proportions of a word between security and non-security
documents. We used 9,934 security news articles and 8,597
non-security news articles that had been collected from 9
mainstream news sites in 2017. We extracted the words in
security news whose occurrences were significantly larger
than those in non-security news at 5% significance level.
There were 14,592 words in our initial dictionary. We had
run our new word detection algorithm daily to 2.82 million
tweets collected from famous security [3, 4] for 4 years from
2014 to 2017 and had updated the detected new words to this
dictionary as described in below. By the end of 2017, there
were 16,014 words in this dictionary.
• DCommon: This dictionary is for deleting common English
words. It includes common English words as well as com-
mon Twitter terms. To build this dictionary, we extracted the
words that appeared significantly more often in non-security
news than security news with a statistical significance test.
Since the words in Twitter are quite different from those
in English dictionary, we also included Twitter words by
extracting top-100,000 words from 863 million tweets that
had been collected from Twitter using public API in early
2015 without any restrictions on keywords or users. How-
ever, some important words in security events like “apple”
and “google” were top words in both English dictionary and
Twitter. In order to exclude such words from DCommon, we
manually reviewed the words that were intersected with
DTech, Fortune 500 Companies [13], Best Buy [7], Consumer
Reports [11], and NVD CPE dictionary [16]. There were
72,623 words in this dictionary by the end of 2017.
• DWhitelist: This dictionary is for eliminating common tech-
nical words that are meaningless to monitor. Examples of
such words are “cyber”, “cybersecurity”, “infosec”, and “cy-
berattack”. We extracted common technical words using
IDF (inverse document frequency) for the words in DTech
over 9,934 security news articles. To extract common techni-
cal words from Twitter, we also computed IDF values of the
words in DTech over 101,604 tweets containing threat-related
keywords that had been collected from January to December
2017. In addition, we included the conference names like
“defcon”, “bhusa”, and “rsac” to this dictionary. There were
2,339 words in this dictionary by the end of 2017.
Session 13: Malware ASIA CCS ’20, October 5–9, 2020, Taipei, Taiwan670Note that news articles were processed in the same manner as in
Section 4.2 except Twitter-specific processing. When constructing
DCommon, we skipped step (2) in Section 4.2 because POS tagging
did not work perfectly, so words other than nouns were included in
the set of words to be monitored. Also, note that we considered top-
100,000 words from Twitter dataset because they covered roughly
98% of the word distribution of 863 million tweets.
We now explain how to detect new and re-emerging words. Let n
be the total number of tweets containing a given set of keywords in
between time t −1 and t. Also, let C be a set of words returned from
data preprocessing at time t. Denote by K a given set of keywords.
New Words Detection. We detect new words by removing the
words in DTech ∪ DCommon from the set C. Since the words in K
are not one to monitor, we weed out those words from C as well.
After getting candidate new words, we filter out the words whose
occurrences in n tweets are not statistically significant [1]. In other
words, we retain a word w that satisfies
(cid:114)
pt(w) ≥ zα
pt(w)(1 − pt(w))
,
n
where pt(w) = ft(w)/n with the number ft(w) of tweets containing
a word w at time t and zα is the (1 − α)-percentile of the standard
Normal distribution. Note that z0.05 = 1.645 for 95% confidence
(α = 0.05). If one wants to drop more words from candidate new
words, he/she can increase the confidence level.
Re-emerging Words Detection. Since the event detection based
on new words only works for the events involving new words, its
coverage for event detection is very limited. First, it cannot cover
threats formerly emerged or their variants. From our experiments,
we observe that a new-words-based event detection approach can-
not detect the variants of Spectre although they have been reported
repeatedly since its first seen on January 3rd 2018. Next, it can-
not discover the events earlier before new threats are named. We
found that there were several tweets about Key Reinstallation Attack
(KRACK) vulnerability a day before it was publicly announced on
October 16th 2017. However, any of those tweets never mentioned
new words like “KRACK”. For example, the first tweet on Octo-
ber 15th 2017 was “This is a core protocol-level flaw in WPA2 wi-fi
and it looks bad. Possible impact: wi-fi decrypt, connection hijacking,
content injection”. Finally, it does not work for any types of events.
Many data breach events do not involve new words. Tweets for
data breaches usually mention the victim companies, the size of
data breach, and what kinds of user data were exposed, so there
are not many new words explaining this event type. To expand
the coverage of new-words-based event detection approach, we
additionally monitor re-emerging words.
Our algorithm for re-emerging words detection basically moni-
tors the words in DTech, but not in DWhitelist (i.e., DTech\DWhitelist).
For re-emerging words detection, let CR be the list of the words in
C ∩ (DTech \ DWhitelist). We first filter out the words in CR whose
occurrences are not statistically significant as we do in new words
detection. Recall that the re-emerging words are defined as the
words that have been seen earlier, but show a sudden increase in
their frequencies at time t. Thus, we check if each word in CR makes
a statistically significant rise in its occurrence at time t compared
to before. There are many ways to measure a change in occurrence
of a word. For example, one may compute the difference in the
(cid:114)
which is calculated by ˆft(w) =k−1
(cid:113) 1
number of tweets including a word at time t and t − 1. In our al-
gorithm, we measure the difference between the number of tweets
containing a word at time t and its expected value based on the
past occurrences. To define this mathematically, let ft(w) be the
number of tweets containing a word w at time t. For each word w
in CR, we compute the expected number ˆft(w) of mentions about
w by the exponentially weighted moving average (EWMA) over
the past k occurrences with the smoothing factor λ (0 < λ < 1),
i =0 λ(1−λ)i ft−i(w). To determine
whether there is a rapid increase in the number of mentions about
w, we derive the range of values that ft(w) can take with high confi-
dence. For this, we compute ˆσ( ˆft(w)) = ˆσ
2−λ (1 − (1 − λ)2k) with
i =0 (ft−i(w) − ˆft−i(w))2. If there is no critical issue re-
ˆσ =
lated on the word w at time t, we expect that ft(w) takes the values
in between ˆft(w)− zα/2 · ˆσ( ˆft(w)) and ˆft(w) + zα/2 · ˆσ( ˆft(w)) with
100(1-α)% confidence since ft(w)− ˆft(w)
is approximately Gaussian
ˆσ( ˆft(w))
distributed with its mean 0 and variance 1. Otherwise, ft(w) is more
likely to take the value larger than the above upper bound. There-
fore, we detect a word w as a re-emerging word if ft(w) satisfies
k−1
(cid:113) λ
k
ft(w) ≥ ˆft(w) + zα/2 · ˆσ
(1 − (1 − λ)2k).
λ
2 − λ
Note that a higher λ decreases the effects of older observations
faster. Also, note that z0.025 = 1.96 for 95% confidence.
Figure 6 and 7 show examples of re-emerging words. The words
“spectre” and “intel” are both detected on January 3rd 2018 when In-
tel CPU vulnerabilities were publicly disclosed. Both words showed
a rapid rise in the number of mentions. In particular, the word
“spectre” had never appeared in a month before event. In the case
of the word “wifi”, it had been constantly mentioned with various
events from “wifi password hack”, “wifi cracker” to “wifi firmware
bug”. Unlike “spectre” and “intel”, the number of mentions was
mostly below 10 times even when they are triggered as events.
Note that, although new and re-emerging words are extracted
in each event type, the filtering rules of words are applied to the
number of tweets mentioning each word across all the event types.
Therefore, the order of categorization of tweets into event types
does not affect the words detected. It only affects where the event
is categorized.
We also note that, although we focus on event retrieval from
Twitter, the proposed algorithm is applicable to security news mon-
itoring as well as forum monitoring. In fact, we have successfully
applied the proposed algorithm to event detection from security
news although we do not report here.
Dictionary Update. Since new events keep appearing every day,
we need to update DTech for re-emerging words detection as we
detect new words. One may update DTech on a daily basis as new
words are detected. However, automatic update of the detected
new words accumulates noise in the dictionary DTech. This leads
to increase false positives in re-emerging words detection. Thus,
to reduce cumulative noise caused by automatic dictionary update,
either a daily human review or a conservative dictionary update
policy is required. To make our system fully automatic, we choose
the latter option. We decide to update each of the detected new
words on DTech when it keeps being detected as new words at least
Session 13: Malware ASIA CCS ’20, October 5–9, 2020, Taipei, Taiwan671CVE detection, we exclude tweets from vulnerability feeds and we
use the same filtering rules above, where n is the number of tweets
containing CVE IDs.
4.4 Event Generation
Our system detects events by identifying new words and re-emerging
words. However, this approach has a limitation that a word does
not have one-to-one correspondence with an event. That is, (i) two
or more detected words may represent one event – a new word
and a re-emerging word or two new words can come from one
tweet, and (ii) the detected word may not correspond to one event.
The latter case happens more often in event detection through re-
emerging words. For example, when the word “wifi” is detected as
a re-emerging word, it may be buzzed with wifi firmware bugs and
wifi inspector vulnerabilities on the same day.
To overcome the problem above, we develop an event generator
that merges or splits candidate events triggered by the detected
words as the final step of W2E. In each event type, our event gen-
erator performs clustering analysis on the tweets containing new
words and re-emerging words. Many security events are described
by context-specific words like the malware names, vulnerabilities,
victims, and attack targets. Thus, mentions about the same event
are likely to contain the same event-specific words. For this reason,
we extract a set of such words from each tweet and measure the
similarity between two tweets by computing the Jaccard similarity.
We extract event-specific words from each tweet in the following
steps: (1) We apply steps (3) and (4) in Section 4.2, (2) Security
terms and their alias are replaced by single representative terms in
the form of a single token. For example, “buffer overflow”, “buffer-
overflow”, “buffer_overflow”, and “buffer overrun” are replaced
by “buffer-overflow”, (3) After tokenization and lemmatization, we
prune the words in DCommon ∪ DWhitelist ∪ K. We then group
tweets by applying a hierarchical clustering method to the Jaccard
distance matrix. After clustering tweets within each event type, we
finally form events by grouping clusters of tweets across all the
event types in a similar manner. Note that two tweets having the
same external link form the same event.
Note that there are several clustering methods to group tweets
for event detection purposes [22]. One can adopt word embeddings
such as word2vec [33], GloVe [36], and ELMo [37] to represent
tweets into a vector space so that semantic distance between two
tweets is measured. However, we observe that, for tweets about
security events, clustering with context-specific words performs
much better than semantic clustering.
Since W2E runs in day to day, the same event can come up again
and again while it is being discussed on Twitter. Generating the
same alert repeatedly whenever an event is detected is inefficient
and annoying. Thus, we develop an event manager that merges
the events detected at time t into the events detected up to time
t − 1. Our event manager first takes over the events detected within
the past 7 days. It then retains event-specific words that appear at
least 50% of tweets in each event in order to extract context-specific
words for an event. It finally merges the detected events at time
t into the past events if the sets of context-specific words for two
events have the Jaccard similarity greater than 0.7.
Figure 6: The number of mentions about “intel” and “spectre” from
Dec 2017 to Jan 2018. The grey and blue dotted lines represent the
upper bounds for frequencies of “intel” and “spectre”, respectively.
The yellow and cyan spotted circles represent the days that the
words are flagged as re-emerging words. Both “intel” and “spectre”
identify the “spectre” vulnerability on its first day (Jan 3rd 2018).
twice in a week. Until the detected new words are updated into
DTech, those words show up in the list of new words.
Monitoring CVE IDs. When new vulnerabilities are found or the
known vulnerabilities are mentioned again, sensing those vulnera-
bilities is important for organizations to mitigate a potential risk.
W2E monitors some vulnerabilities from the tweets including a
given set of vulnerability-specific keywords. One may monitor
CVE IDs in the vulnerability event category by including “cve” into
the set of keywords. However, in that case, CVE IDs generate too
many events as well as dominate top events in the vulnerability
event category, so a human analyst may ignore the vulnerability
events without CVE IDs unless they are sufficiently mentioned.
Thus, W2E monitors CVE IDs separately. In CVE monitoring, we
are interested in pre-NVD CVEs, which are defined as CVEs whose
IDs are assigned, but are not published in NVD (National Vulnera-
bility Database) yet. After running our CVE monitor on Twitter, we
have found 345 pre-NVD CVEs during the periods from January
to December 2018. Among them, 309 CVEs are published and 36