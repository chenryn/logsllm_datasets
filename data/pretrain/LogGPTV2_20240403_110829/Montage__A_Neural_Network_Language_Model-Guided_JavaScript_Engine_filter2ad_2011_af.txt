tional relations among the AST subtrees.
TreeFuzz [41] is another model-based fuzzer. Its model
is built on the frequencies of co-occurring nodes and edges
from given AST examples. Their modeling of generating
tests is not directly applicable to the prevalent state-of-the-art
language models, tailored to train word sequences, not node
and edge relations in ASTs.
Aschermann et al. [2] and Blazytko et al. [6] recently pro-
posed NAUTILUS and GRIMOIRE, respectively. Both fuzzers
test programs that take highly structured inputs by leveraging
code coverage. Based on a given grammar, NAUTILUS gener-
ates a new JS test and checks whether it hits new code cov-
erage for further mutation chances. Contrary to NAUTILUS,
GRIMOIRE requires no user-provided components, such as
grammar speciﬁcation and language models, but synthesizes
inputs that trigger new code coverage. As they stated, GRI-
MOIRE has difﬁculties in generating inputs with complex
structures, requiring semantic information.
Previous studies of mutational fuzzing [7, 18, 24, 32, 44, 54,
57,58] focus on altering given seeds to leverage functionalities
that the seeds already test.
LangFuzz [24] is a mutational fuzzing tool that substitutes
a non-terminal node in a given AST with code fragments. It
iteratively replaces non-terminal nodes in the step of inserting
fragments. However, LangFuzz does not consider any context
regarding picking a promising candidate to cause a target
JS engine crash. On the other hand, Montage is capable of
learning implicit relations between fragments that may be
inherent in given examples.
Liu et al. [32] proposed a mutation-based approach to fuzz
the target program. Given a large corpus of C code, they
trained a sequence-to-sequence model to capture the inherent
pattern of input at character-level. Then, they leveraged the
trained model to mutate the seed. Their approach suffers from
the limitation that the model generates many malformed tests,
such as unbalanced parenthesis.
Language model for code. Hindle et al. [22] measured the
naturalness of software by computing the cross-entropy val-
ues over lexical code tokens in large JAVA and C applications.
They also ﬁrst demonstrated even count-based n-gram lan-
guage models are applicable to code completion. To make
more accurate suggestions for code completion, SLAMC [40]
incorporated semantic information, including type, scope, and
role for each lexical token. SLANG [43] lets a model learn
API call sequences from Android applications. It then uses
such a model to improve the precision of code completion.
GraLan learns the relations between API calls from the graph
of API call sequences, and ASTLan uses GraLan to ﬁll holes
in the AST to complete the code [39].
Maddison et al. [33] studied the generative models of nat-
ural source code based on PCFGs and source code-speciﬁc
structures. Bielik et al. [5] suggested a new generative prob-
USENIX Association
29th USENIX Security Symposium    2627
abilistic model of code called a probabilistic higher order
grammar, which generalizes PCFGs and parameterizes the
production rules on a context.
The objective of using a language model in all of the above
works is to make better suggestions for code completion. How-
ever, Montage focuses on generating JS tests that should be
accepted by a target JS engine.
9 Conclusion
We present Montage, the ﬁrst fuzzing tool that leverages an
NNLM in generating JS tests. We propose a novel algorithm
of modeling the hierarchical structures of a JS test case and
the relationships among such structures into a sequence of
fragments. The encoding of an AST into a fragment sequence
enables Montage to learn the relationships among the frag-
ments by using an LSTM model. Montage found 37 real-
world bugs in the latest JS engines, which demonstrates its
effectiveness in ﬁnding JS engine bugs.
Acknowledgements
We thank anonymous reviewers for their helpful feedback
and Yale Song who helped develop some of the ideas used
in this paper. We are also grateful to Jihoon Kim for kindly
sharing his ﬁndings, which indeed inspired our project. Fi-
nally, we thank Sunnyeo Park for collecting JS seeds used
for the evaluation. This work was partly supported by (1)
Institute for Information & communications Technology Pro-
motion (IITP) grant funded by the Korea government (MSIT),
No.2018-0-00254, and (2) LIG Nex1.
References
[1] Ebru Arisoy, Tara N. Sainath, Brian Kingsbury, and Bhu-
vana Ramabhadran. Deep neural network language mod-
els. In Proceedings of the NAACL-HLT 2012 Workshop,
pages 20–28, 2012.
[2] Cornelius Aschermann, Patrick Jauernig, Tommaso Fras-
setto, Ahmad-Reza Sadeghi, Thorsten Holz, and Daniel
Teuchert. NAUTILUS: Fishing for deep bugs with gram-
mars. In Proceedings of the Network and Distributed
System Security Symposium, 2019.
[5] Pavol Bielik, Veselin Raychev, and Martin Vechev.
PHOG: Probabilistic model for code. In Proceedings
of the International Conference on Machine Learning,
pages 2933–2942, 2016.
[6] Tim Blazytko, Cornelius Aschermann, Moritz Schlögel,
Ali Abbasi, Sergej Schumilo, Simon Wörner, and
Thorsten Holz. GRIMOIRE: Synthesizing structure
while fuzzing. In Proceedings of the USENIX Security
Symposium, pages 1985–2002, 2019.
[7] Sang Kil Cha, Maverick Woo, and David Brumley.
Program-adaptive mutational fuzzing. In Proceedings
of the IEEE Symposium on Security and Privacy, pages
725–741, 2015.
[8] Stanley F. Chen and Joshua Goodman. An empirical
study of smoothing techniques for language modeling.
In Proceedings of the 34th Annual Meeting on Asso-
ciation for Computational Linguistics, pages 310–318,
1996.
[9] Yang Chen, Alex Groce, Chaoqiang Zhang, Weng-Keen
Wong, Xiaoli Fern, Eric Eide, and John Regehr. Taming
compiler fuzzers. In Proceedings of the ACM Confer-
ence on Programming Language Design and Implemen-
tation, pages 197–208, 2013.
[10] Microsoft Corporation. Microsoft ChakraCore. https:
//github.com/Microsoft/ChakraCore.
[11] Chris Cummins and Alastair Murray. Compiler fuzzing
through deep learning. In Proceedings of the ACM Inter-
national Symposium on Software Testing and Analysis,
pages 95–105, 2018.
[12] Kyle Dewey, Jared Roesch, and Ben Hardekopf. Lan-
guage fuzzing using constraint logic programming. In
Proceedings of the International Conference on Auto-
mated Software Engineering, pages 725–730, 2014.
[13] Technical Committee 39 ECMA International. Test262.
https://github.com/tc39/test262.
[14] Felix A. Gers, Jürgen Schmidhuber, and Fred Cummins.
Learning to forget: Continual prediction with LSTM.
Neural Computation, 12:2451–2471, 1999.
[3] Yoshua Bengio, Réjean Ducharme, Pascal Vincent, and
Christian Janvin. A neural probabilistic language model.
The Journal of Machine Learning Research, 3(1):1137–
1155, 2003.
[15] Patrice Godefroid, Adam Kiezun, and Michael Y. Levin.
Grammar-based whitebox fuzzing. In Proceedings of the
ACM Conference on Programming Language Design
and Implementation, pages 206–215, 2008.
[4] Yoshua Bengio, Patrice Simard, and Paolo Frasconi.
Learning long-term dependencies with gradient descent
is difﬁcult. Transactions on Neural Networks, 5(2):157–
166, 1994.
[16] Patrice Godefroid, Hila Peleg, and Rishabh Singh.
Learn&Fuzz: Machine learning for input fuzzing. In
Proceedings of the International Conference on Auto-
mated Software Engineering, pages 50–59, 2017.
2628    29th USENIX Security Symposium
USENIX Association
[17] Joshua T. Goodman. A bit of progress in language
modeling. Computer Speech & Language, 15(4):403–
434, 2001.
[18] Tao Guo, Puhan Zhang, Xin Wang, and Qiang Wei.
GramFuzz: Fuzzing testing of web browsers based on
grammar analysis and structural mutation. In Proceed-
ings of the International Conference on Informatics Ap-
plications, pages 212–215, 2013.
[19] HyungSeok Han and Sang Kil Cha.
IMF: Inferred
model-based fuzzer. In Proceedings of the ACM Confer-
ence on Computer and Communications Security, pages
2345–2358, 2017.
[20] HyungSeok Han, DongHyeon Oh, and Sang Kil Cha.
CodeAlchemist: Semantics-aware code generation to
ﬁnd vulnerabilities in JavaScript engines. In Proceed-
ings of the Network and Distributed System Security
Symposium, 2019.
[21] Ariya Hidayat. ECMAScript parsing infrastructure for
multipurpose analysis. https://www.esprima.org.
[22] Abram Hindle, Earl T. Barr, Zhendon Su, Mark Gabel,
and Premkumar Devanbu. On the naturalness of soft-
ware. In Proceedings of the International Conference
on Software Engineering, pages 837–847, 2012.
[23] Sepp Hochreiter and Jürgen Schmidhuber. Long short-
term memory. Neural Computation, 9(8):1735–1780,
1997.
[24] Christian Holler, Kim Herzig, and Andreas Zeller.
Fuzzing with code fragments. In Proceedings of the
USENIX Security Symposium, pages 445–458, 2012.
[25] BuzzFeed Inc. Markovify. https://github.com/
jsvine/markovify.
[26] Theori
Inc.
pwn.js.
theori-io/pwnjs, 2017.
https://github.com/
[27] ECMA International. ECMAScript language spec-
iﬁcation. https://www.ecma-international.org/
ecma-262/.
[28] Dave Jones.
Trinity.
kernelslacker/trinity.
https://github.com/
[29] Rafal Józefowicz, Oriol Vinyals, Mike Schuster, Noam
Shazeer, and Yonghui Wu. Exploring the limits of lan-
guage modeling. CoRR, abs/1602.02410, 2016.
[31] George Klees, Andrew Ruef, Benji Cooper, Shiyi Wei,
and Michael Hicks. Evaluating fuzz testing. In Proceed-
ings of the ACM Conference on Computer and Commu-
nications Security, pages 2123–2138, 2018.
[32] Xiao Liu, Xiaoting Li, Rupesh Prajapati, and Dinghao
Wu. DeepFuzz: Automatic generation of syntax valid c
programs for fuzz testing. In Proceedings of the AAAI
Conference on Artiﬁcial Intelligence, pages 1044–1051,
2019.
[33] Chris J. Maddison and Daniel Tarlow. Structured gen-
erative models of natural source code. In Proceedings
of the International Conference on Machine Learning,
pages 649–657, 2016.
[34] Tomáš Mikolov, Martin Karaﬁát, Lukáš Burget, Jan ˇCer-
nock`y, and Sanjeev Khudanpur. Recurrent neural net-
work based language model. In Proceedings of the 11th
Annual Conference of the International Speech Commu-
nication Association, pages 1045–1048, 2010.
[35] Matt Molinyawe, Abdul-Aziz Hariri, and Jasiel Spelman.
$hell on Earth: From browser to system compromise. In
Proceedings of the Black Hat USA, 2016.
[36] David Molnar, Xue Cong Li, and David A. Wagner. Dy-
namic test generation to ﬁnd integer bugs in x86 binary
linux programs. In Proceedings of the USENIX Security
Symposium, pages 67–82, 2009.
[37] Mozilla. Hoisting.
https://developer.mozilla.
org/en-US/docs/Glossary/Hoisting.
[38] MozillaSecurity.
funfuzz.
MozillaSecurity/funfuzz.
https://github.com/
[39] Anh Tuan Nguyen and Tien N. Nguyen. Graph-based
statistical language model for code. In Proceedings of
the International Conference on Software Engineering,
pages 858–868, 2015.
[40] Tung Thanh Nguyen, Anh Tuan Nguyen, Hoan Anh
Nguyen, and Tien N. Nguyen. A statistical semantic
language model for source code. In Proceedings of the
International Symposium on Foundations of Software
Engineering, pages 532–542, 2013.
[41] Jibesh Patra and Michael Pradel. Learning to fuzz:
Application-independent fuzz testing with probabilis-
tic, generative models of input data. Technical Report
TUD-CS-2016-14664, TU Darmstadt, 2016.
[30] Yoon Kim, Yacine Jernite, David Sontag, and Alexan-
der M. Rush. Character-aware neural language models.
In Proceedings of the AAAI Conference on Artiﬁcial
Intelligence, pages 2741–2749, 2016.
[42] Van-Thuan Pham, Marcel Böhme, and Abhik Roychoud-
hury. Model-based whitebox fuzzing for program bina-
ries. In Proceedings of the International Conference on
Automated Software Engineering, pages 543–553, 2016.
USENIX Association
29th USENIX Security Symposium    2629
[43] Veselin Raychev, Martin Vechev, and Eran Yahav. Code
completion with statistical language models. In Proceed-
ings of the ACM Conference on Programming Language
Design and Implementation, pages 419–428, 2014.
[44] Alexandre Rebert, Sang Kil Cha, Thanassis Avgerinos,
Jonathan Foote, David Warren, Gustavo Grieco, and
David Brumley. Optimizing seed selection for fuzzing.
In Proceedings of the USENIX Security Symposium,
pages 861–875, 2014.
[45] Jesse Ruderman.
Releasing jsfunfuzz and dom-
http://www.squarefree.com/2015/07/28/
fuzz.
releasing-jsfunfuzz-and-domfuzz/, 2007.
[46] Joeri De Ruiter and Erik Poll. Protocol state fuzzing of
TLS implementations. In Proceedings of the USENIX
Security Symposium, pages 193–206, 2015.
[47] Juraj Somorovsky. Systematic fuzzing and testing of
TLS libraries. In Proceedings of the ACM Conference on
Computer and Communications Security, pages 1492–
1504, 2016.
[48] Aditya K. Sood and Sherali Zeadally. Drive-by down-
IT Professional,
load attacks: A comparative study.
18(5):18–25, 2016.
[49] Alexander Sotirov. Heap feng shui in JavaScript. In
Proceedings of the Black Hat USA, 2007.
[50] Michael Sutton, Adam Greene, and Pedram Amini.
Fuzzing: Brute Force Vulnerability Discovery. Addison-
Wesley Professional, 2007.
[52] PyTorch Core Team. Pytorch.
org/.
https://pytorch.
[53] Zhaopeng Tu, Zhendong Su, and Premkumar Devanbu.
In Proceedings of the
On the localness of software.
International Symposium on Foundations of Software
Engineering, pages 269–280, 2014.
[54] Spandan Veggalam, Sanjay Rawat, Istvan Haller, and
Herbert Bos. IFuzzer: An evolutionary interpreter fuzzer
using genetic programming. In Proceedings of the Eu-
ropean Symposium on Research in Computer Security,
pages 581–601, 2016.
[55] Dmitry Vyukov.
syzkaller. https://github.com/
google/syzkaller.
[56] Junjie Wang, Bihuan Chen, Lei Wei, and Yang Liu. Sky-
ﬁre: Data-driven seed generation for fuzzing. In Pro-
ceedings of the IEEE Symposium on Security and Pri-
vacy, pages 579–594, 2017.
[57] Maverick Woo, Sang Kil Cha, Samantha Gottlieb, and
Scheduling black-box mutational
David Brumley.
In Proceedings of the ACM Conference on
fuzzing.
Computer and Communications Security, pages 511–
522, 2013.
[58] Michal Zalewski. American Fuzzy Lop.
lcamtuf.coredump.cx/afl/.
http://
[51] Yusuke Suzuki. Escodegen. https://www.npmjs.com/
package/escodegen.
[59] ZERODIUM. Zerodium payouts. https://zerodium.
com/program.html.
2630    29th USENIX Security Symposium
USENIX Association