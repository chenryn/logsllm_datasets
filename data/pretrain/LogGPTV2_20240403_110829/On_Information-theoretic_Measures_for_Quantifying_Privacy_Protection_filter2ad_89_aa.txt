# Title: On Information-Theoretic Measures for Quantifying Privacy Protection of Time-Series Data

## Authors:
- Chris Y. T. Ma, Advanced Digital Sciences Center, Singapore
- David K. Y. Yau, Singapore University of Technology and Design, Advanced Digital Sciences Center, Singapore

## Abstract
Privacy protection of time-series data, such as household electricity usage reported by smart meters, is of significant practical importance. Solutions are available to improve data privacy by perturbing clear traces to produce noisy versions visible to adversaries, e.g., in battery-based load hiding (BLH) against non-intrusive load monitoring (NILM). A foundational task for research progress in this area is the definition of privacy measures that can truly evaluate the effectiveness of proposed protection methods. This is a challenging problem because resilience against known attack algorithms does not guarantee security against stronger, unknown algorithms. A more fundamental approach is to use information-theoretic measures, which quantify the inherent information available for exploitation by an adversary, independent of the adversary's specific attack methods or computational limitations.

In this paper, we analyze information-theoretic measures for privacy protection and apply them to several existing protection methods against NILM. We argue that although these measures abstract away the details of attacks, the type of information the adversary considers plays a key role in the evaluation. We propose a new measure, offline conditional entropy, which is better suited for evaluating the privacy of perturbed real-world time-series data compared to other existing measures.

## Categories and Subject Descriptors
E.3 [Data]: Data Encryption

## Keywords
Privacy Protection, Privacy Measure, Conditional Entropy, Correlated Time-series

## 1. Introduction
Privacy protection of time-series data is of significant practical importance. Such data includes mobility traces in location-based services and household electricity consumption measured by smart meters for demand response. If users' privacy is not assured in these applications, they may be reluctant to participate, and if they do, the leak of sensitive information could lead to damaging outcomes such as abuse of consumer rights or lawsuits.

To address these privacy concerns, solutions are available that perturb clear traces of time-series data to produce noisy versions, ensuring that any would-be adversaries have access only to the noisy data. For example, in battery-based load hiding (BLH) against non-intrusive load monitoring (NILM), the privacy concerns are well-documented. In other cases, the perturbation is constrained by the need to preserve data accuracy for various application needs, such as inferring congestion indices in location-based services.

While the design of specific privacy protection mechanisms is important, a foundational task for advancing the field is the definition of proper measures that can truly assess the privacy of the protection. Some measures, like k-anonymity, focus on protecting the identity of participants but ignore the information content of the data. Information-theoretic measures, on the other hand, directly quantify the amount of original information contained in the noisy data, providing a strong privacy guarantee independent of the adversary's operational details.

If elements in a data trace are uncorrelated temporally, mutual information can be used to measure privacy. However, real-world time-series data often exhibit temporal correlations, which adversaries can exploit in privacy attacks. Prior work has considered mutual information between distributions of pairs of consecutive data points, but this approach is limited to Markov-like dependencies. Real-world data typically exhibits more persistent temporal correlation, which has not been systematically studied in the context of privacy protection.

In this paper, we investigate four sets of privacy measures that subsume state-of-the-art measures used in prior work to evaluate BLH or more general time-series data:
1. A baseline definition of mutual information (MI) using individual elements in a time-series.
2. A normalized version of MI (NMI) adapted by Koo et al.
3. Conditional entropy (CE) for online prediction problems, adapted for privacy protection.
4. A new offline conditional entropy (OCE) measure to account for the full information available to the adversary.

We compare these measures over different values of the parameter \( k \) to expose the impact of temporal correlation. We use both synthetic and real data to ensure useful comparisons. Our major findings are:
- OCE appears to be superior as it satisfies our axiomatic properties of desirable privacy measures.
- CE, due to its original prediction intent, fails to account for all available information in a privacy attack, while MI, NMI, and OCE do not suffer from this limitation.
- Although MI can encompass all available information, its values across \( k \) are not comparable due to the inherent increase in symbol diversity with \( k \).
- OCE always measures the uncertainty of clear data points conditional on the noisy data, making its meaning unaffected by \( k \).

## 2. Problem Definition
We consider the problem of quantifying the protection of time-series data by different privacy-preserving strategies. This is an important problem due to the growing practice of collecting time-series data for applications such as smart-meter enabled demand-response and location-based services for mobile nodes. To address privacy concerns, various perturbation strategies have been proposed to cloak the time-series data before making it available to service providers. A proper privacy measure is crucial to avoid scenarios of inadvertent data re-identification.

Let a trace of clear time-series data be a stochastic process \( X = \{X_i\} \), where \( i \) is the time index and the \( X_i \)'s form a sequence of random variables. Let \( X^l \) be the stochastic process in which the symbols are the set of \( l \) consecutive data points in \( X \), \( l > 0 \). Let the corresponding noisy time-series data generated by a privacy-preserving strategy be a stochastic process \( Y = \{Y_i\} \), where \( i \) is the time index and the \( Y_i \)'s form a sequence of random variables. Let \( Y^l \) be the stochastic process in which the symbols are the set of \( l \) consecutive data points in \( Y \), \( l > 0 \). We aim to design an information-theoretic measure to compare the similarity and information content of \( X \) and \( Y \).