that penalties for non-compliance are common, but vary in
size based on the severity of infraction and size of customer
base. Monthly ﬁnes that can range from $5,000 to $100,000
and continue until compliance issues are resolved. If a data
breach occurs as a result of non-compliance, companies may
be responsible for consumer services (e.g., credit monitoring)
or may have payment-processing privileges revoked.
B. Findings
Within the 851 independent controls speciﬁed by PCI
DSS, we identiﬁed 46 security concerns: eight high-risk, 22
moderate-risk, and 16 low-risk (as shown in Figure 3). We
discarded six other potential issues, all of which were under-
deﬁned processes that did not result in any insecure practices
or conditions.
Security concern trends. We identiﬁed four issues related to
improperly identifying sensitive information. PCI DSS focuses
heavily on protecting primary account numbers (PANs) that are
tied to credit cards but fails to protect other information that
8
in “Requirement 5: Protect all systems against malware and
regularly update anti-virus software or programs” and Section
5.1. These sections rely solely on antivirus to prevent malware
infections. Numerous data breaches have shown that antivirus
alone cannot protect against all malware [11]. These limited-
scope requirements leave organizations exposed to multiple
attack vectors that will most likely occur frequently and have
moderate severity. These sections should mandate additional
controls such as application whitelisting, blocking access to
areas that permit persistence (e.g., Windows Registry Keys),
and enforcing least-privilege access.
Section 1.3.7 focuses on limiting the disclosure of private,
internal IP addresses from ﬁrewalls and routers, but fails to
discuss any other services that could leak the same information,
such as a domain name server or internal ﬁles (e.g., Word
documents) improperly exposed to search engines. Attackers
have leveraged common techniques such as “Google Hacking”
to discover internal network conﬁgurations and sensitive sys-
tems like a domain controller [35]; expanding the scope of
this moderate-risk issue to limit external enumeration would
improve its security.
Sections 11.1.c and 11.1.d actually incentivize less-secure
practices. Each subsection deﬁnes additional audit checks that
an assessor must conduct only if a particular security control
is in place (wireless scanning and automated monitoring,
respectively). Under this policy, ﬁnancial sanctions associated
with non-compliance could lead a security professional not
to implement a security control at all rather than risk having
it assessed as non-compliant — if it
the
organization is automatically compliant. These two particular
controls would have a negligible overall impact if they were
not in place; therefore, we assess this to be a low-risk issue. We
recommend that if the PCI SSC believes these security controls
are important, they should be mandatory rather than optional;
otherwise, these sections should be eliminated entirely.
is not present,
Ambiguous speciﬁcation. We identiﬁed 10 issues within
PCI DSS in which insufﬁcient details create ambiguity or
uncertainty. An example of a high-risk security concern with a
frequent probability and moderate severity stems from Section
A1.1 and limits the usage of Common Gateway Interface (CGI)
scripts to control privileged access to cardholder data. This
control is sound but is overly narrow; in modern systems, there
are a variety of applications that could access or manipulate
cardholder data in ways similar to CGI scripts. We recommend
simply replacing “CGI scripts” with “applications” to improve
the clarity of this control.
Section 11.3.3 discusses corrective action plans for vulner-
abilities discovered during penetration tests. The section does
not specify how soon after a penetration test vulnerabilities
must be addressed, nor the party responsible for ﬁxing the
vulnerabilities. Based on the researchers’ past experiences with
organizations delaying remediation, we assess this security
concern to have a high risk level with a frequent probability
of occurring and a moderate severity. Moreover,
the non-
validator assessor we spoke to conﬁrmed that in his experience,
organizations often delay remediation, and typically dedicate
one to two full-time employees for 30-40 days prior to an
inspection to ensure remediation is complete just in time [37].
We recommend this section specify a time limit (based on
vulnerability severity) for addressing issues discovered during
a penetration test and clarify the party responsible for ﬁxing
the vulnerable condition.
C. Expert validation
To assess our PCI DSS ﬁndings, we partnered with an
organization that is a PCI SSC member. Expert E3 represented
this organization, possessing 18 years of experience advising
the security practices of large ﬁnancial organizations, assess-
ing organizations’ adherence to PCI DSS security controls,
and conducting digital security assessments against networked
environments. E3 conﬁrmed past utilization of PCI DSS as a
line-by-line checklist as they audited organizations in the past.
We asked E3 to assess all eight high-risk issues and a
randomly-sampled subset of seven moderate issues and ﬁve
low-risk issues;
this accounts for 43% (20 of 46) of the
issues from our audit. E3 conﬁrmed 18 of the issues and
categorized the remaining two as plausible, although he had
not experienced them.
We observed no statistical difference between probability
estimates between E3 and our auditors (p = 0.77),but E3
assessed issues to be statistically more severe with medium
effect (p = 0.003, r = 0.469). During our post-survey
discussion with E3, he stated that the ﬁnancial impacts of
digital security breaches involving cardholder data caused him
to increase his assessed impact of each issue — had these
issues been present within another business sector, E3 would
not have assessed them as severely.
The ﬁrst issue assessed as plausible rather than conﬁrmed
involves Section 1.3.7 and information disclosure. E3 indicated
that internal data exposure is “inconsequential if boundary con-
ﬁguration is correct,” meaning an administrator is successfully
limiting which inbound connections from external entities are
allowed to communicate with private IP addresses. However,
E3 acknowledged that the security concern would exist if these
additional controls are not in place.
The second issue E3 ﬂagged as plausible rather than con-
ﬁrmed involves Section 5.1’s reliance on anti-virus software.
According to E3, organizations have lessened reliance on anti-
virus for protection; he argued that Section 5.1 would have
minimal impact on organizations with defensive strategies for
protecting network segments, user accounts, and key resources.
Additional defenses. E3 recommended account-protection so-
lutions such as multi-factor authentication to mitigate concerns
such as VLAN attacks or insufﬁcient protection of passwords.
As discussed for P1075 above, both the issues E3 assessed
as only plausible and his recommended additional defenses
hinge on additional security controls beyond the PCI DSS
standard; we cannot necessarily assume non-mandated controls
will be applied.
VI. RESULTS: NERC CIP 007-6
A. Overview
The North American Electric Reliability Corporation
(NERC) Reliability Standards deﬁne the requirements for
planning and operating North American bulk power systems
9
(BPSs), deﬁned as large interconnected electrical systems
consisting of generation and transmission facilities and their
industrial control systems [41]. All BPSs within the conti-
nental United States, Canada, and the northern portion of
Baja California, Mexico must comply with NERC Reliability
Standards, meaning that these security controls affect most
people living within these areas. The NERC Critical Infras-
tructure Protection (CIP) Committee, which oversees the set
of standards, comprises representatives from 30 companies and
municipalities across North America [42]. Although NERC is
an international not-for-proﬁt, its regulatory authority stems
from section 215(e) of the Federal Power Act and Title 18
Code of Federal Regulations §39.7. The set of standards that
make up CIP date back to 2009; in this study, we audited
CIP 007-6, which is the 2014 revision of the Systems Security
Management standard. CIP 007-6 includes key sections for
securing ports and services, patch management, malicious code
prevention, event monitoring, and access control.
NERC Regional Entities are the organizations responsible
for conducting audits and monitoring adherence to the com-
pliance standards within their assigned geographic region. On-
site audits typically last one week and occur every three years.
Accordng to our expert validator E4, a NERC Regional Entity
employs four to seven auditors per assessment, drawn from
a pool of full-time employees. Auditors typically conduct 7-
30 audits per year. E4 also noted that organizations allocate
a large portion of their operating budgets toward compliance
and often spend one year preparing for their audit.
Of the three standards we assessed, NERC has the strongest
sanctions (which can actually create security concerns, as dis-
cussed in Section VI-C). The maximum ﬁne for a compliance
violation is $1M (U.S.) per day; NERC or the applicable
Regional Entity determines the monetary ﬁne [40]. According
to our expert participant, ﬁnes for NERC non-compliance
are common. Recently, NERC levied a $10M ﬁne against
Duke Energy for 127 security infractions between 2015 and
2018 [22].
Qualitatively and quantitatively, CIP 007-6 had the
strongest security controls of the three documents we assessed
(shown in Figure 4), but numerous issues exist that we believe
create security gaps within compliant organizations.
B. Findings
NERC CIP has 79 individual controls. Our internal audit
identiﬁed 21 total issues; we categorized one as extremely-
high-risk, four as high-risk, six as moderate-risk, and 10 as
low-risk. We discarded one additional issue that we identiﬁed
as a duplicate entry.
Security concern trends. Seven of the 21 issues we identiﬁed
deal with overly vague terms such as “when feasible” or
“unnecessary” without deﬁning feasibility or necessity. For
example, Section 5.7 calls for limiting authentication attempts
or generating alerts when feasible. The subjectivity of these
statements can lead to misinterpretations of the standard and
potentially permit
insecure actions. Mandatory compliance
standards should be mandatory; either administrators must
limit authentication attempts or it
is merely a suggestion.
Additionally, none of the 21 issues we identiﬁed specify
which entity is responsible for speciﬁc actions, which can
Fig. 4: Distribution of security concerns identiﬁed forNERC
CIP 007-6. Color indicates the type of security concern;
each dot indicates by size how many security concerns were
identiﬁed with a given type, severity, and probability. Under-
deﬁned processes were most common (n=20).
s
lead to inaction. Notably, NERC identiﬁed “confusion regard-
ing expectations and ownership of tasks” as a key problem
contributing to Duke Energy’s non-compliance and eventual
ﬁne [22]. Below we present detailed examples of ﬁndings,
organized by their perceived root cause.
Data vulnerability. Based on our assessment, CIP 007-6 only
has one moderate-risk issue pertaining to a data vulnerabil-
ity. Section 5.1 states that administrators should “[h]ave a
method(s) to enforce authentication of interactive user ac-
cess, where technically feasible.” This caveat allows legacy
equipment with no provision for authenticating authorized
users to endure within a secure environment. It
is well-
documented that
legacy systems often have no password,
transmit unencrypted passwords, or never change passwords
from their default settings [13]. This permits attackers and
insider threats to easily gain control of legacy systems, which
could range from sensitive databases to the logical system “off
switch.” We argue that secure, authenticated access should be
a hardware and software requirement for all systems in this
critical environment, reducing the likelihood of such an attack.
Under-deﬁned process. The remaining 20 issues involve pro-
cesses that are not sufﬁciently detailed for a secure implemen-
tation. We assessed that Section 2.1 has an extremely high risk,
as written, due to the critical severity and frequent probability
of a security concern occurring within critical environments.
The issue involves the implementation of a patch management
program for improving the security of systems. Throughout
all of the NERC CIP documents, we were unable to ﬁnd
any mandate that organizations maintain a representative test
environment for patch evaluation. Applying patches directly
to live systems that provide power — including to critical
infrastructure such as hospitals — could result in outages and
corresponding loss of life; one such incident occurred in March
2008 and caused a nuclear power plant to shutdown [32].
Testing patches prior to live deployment allows administrators
to observe potential effects within their environment and
10
reduce the likelihood that unforeseen outages will occur as
the result of the patch [57].
We discovered a potential loophole in Sections 2.1 and 2.2,
which rely upon validated sources for patches against known
vulnerabilities. If the entity responsible for patching systems
does not provide sources, then there is no requirement for
patching. Additionally, CIP 007-6 does not account for patches
from external sources beyond the list of valid providers. Do
administrators have a requirement to apply a patch for a known
vulnerability if it is from an outside source? According to
Cardenas, there are instances where applying a patch may vio-
late the certiﬁcation of certain control systems [10]. We deem
this loophole to present a high risk due to the critical severity
associated with unpatched systems in these environments and
the occasional probability of their presence.
Section 5.3 requires administrators to “identify individuals
who have authorized access to shared accounts.” We assessed
shared accounts as a moderate-risk threat, as administrators
are unable to deploy granular controls on a by-need basis.
Shared accounts also inhibit auditing, as the compromise of a
privileged shared account could lead to the spread of malware
or outages that administrators cannot positively attribute to one
individual. Researchers from Sandia National Lab identiﬁed
this security concern in 2003 [51].
Section 5.4 outlines provisions that allow systems to re-
tain their default usernames and passwords if documentation
supports that the “vendor passwords were generated pseudo-
randomly and are thereby unique to the device.” Our auditors
believe that vendor-generated pseudorandom credentials can
present a threat to BPSs if the pseudorandom algorithm is
predictable (e.g., basing its seed on a unique identiﬁer such
as a serial number). This type of exploit requires in-depth
knowledge about the vendor’s algorithm and might seldom
occur despite posing a moderate risk to the environment. We
recommend eliminating this provision entirely and mandating
that administrators change all system credentials before allow-
ing a system to communicate with a BPS.
We identiﬁed a high-risk issue in Section 4.3 concerning
event
log retention. CIP 007-6 requires facilities to retain
90 days of consecutive logs and demonstrate proof of such
practice over a three year period. This relatively short-term
rolling requirement can interfere with incident investigations,
given that advanced persistent threats can operate within net-
works for years before being detected [1], [62]. We recommend
mandating that organizations ship logs to a data warehouse for
long-term storage and investigation support if needed.
C. Expert validation
We partnered with a government organization that focuses
on national security issues to validate our CIP 007-6 ﬁndings.
Expert E4, as the organization’s representative, has 20 years
of experience conducting digital security assessments against
BPSs. E4 conﬁrmed ﬁrst-hand utilization of NERC CIP stan-
dards as a checklist for past audits. E4 has served on nu-
merous executive councils and federal-level panels addressing
cybersecurity concerns within industrial control systems. Most
notably, E4 was a contributing author to many of the NERC
CIP standards.
Due to the complexity of NERC CIP, our 60- to 90-
minute survey could include only nine audit ﬁndings (43%).
We included the extremely-high risk issue and all four high-
risk issues, and we randomly sampled two moderate-risk and
two low-risk issues. Of these, E4 conﬁrmed one issue and
one broader trend, rejected one issue, and categorized the
remaining seven issues as plausible.
When comparing our auditors’ risk estimates to those
of E4, there was no statistical difference between severity
estimates (p = 0.18),but our auditors assessed the issues to be
statistically more likely with a large effect (p = 0.01, = 0.603).
E4, addressing these comparison differences, indicated that
CIP 007-6 relies heavily on the broader framework of CIP
standards and that security controls in other CIP documents