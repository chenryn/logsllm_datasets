# 19｜NeuralCF：如何用深度学习改造协同过滤？你好，我是王喆，今天，我们来学习协同过滤的深度学习进化版本，NeuralCF。在 [第 15节课  slate-object="inline"里，我们学习了最经典的推荐算法，协同过滤。在前深度学习的时代，协同过滤曾经大放异彩，但随着技术的发展，协同过滤相比深度学习模型的弊端就日益显现出来了，因为它是通过直接利用非常稀疏的共现矩阵进行预测的，所以模型的泛化能力非常弱，遇到历史行为非常少的用户，就没法产生准确的推荐结果了。虽然，我们可以通过矩阵分解算法增强它的泛化能力，但因为矩阵分解是利用非常简单的内积方式来处理用户向量和物品向量的交叉问题的，所以，它的拟合能力也比较弱。这该怎么办呢？不是说深度学习模型的拟合能力都很强吗？我们能不能利用深度学习来改进协同过滤算法呢？当然是可以的。2017年，新加坡国立的研究者就使用深度学习网络来改进了传统的协同过滤算法，取名NeuralCF（神经网络协同过滤）。NeuralCF大大提高了协同过滤算法的泛化能力和拟合能力，让这个经典的推荐算法又重新在深度学习时代焕发生机。这节课，我们就一起来学习并实现NeuralCF！ NeuralCF 模型的结构在学习 NeuralCF之前，我们先来简单回顾一下协同过滤和矩阵分解的原理。协同过滤是利用用户和物品之间的交互行为历史，构建出一个像图1左一样的共现矩阵。在共现矩阵的基础上，利用每一行的用户向量相似性，找到相似用户，再利用相似用户喜欢的物品进行推荐。![](Images/c32dc56e8a5e228d8b3253d595f1945c.png)savepage-src="https://static001.geekbang.org/resource/image/60/fb/604b312899bff7922528df4836c10cfb.jpeg"}图1 矩阵分解算法的原理矩阵分解则进一步加强了协同过滤的泛化能力，它把协同过滤中的共现矩阵分解成了用户矩阵和物品矩阵，从用户矩阵中提取出用户隐向量，从物品矩阵中提取出物品隐向量，再利用它们之间的内积相似性，进行推荐排序。如果用神经网络的思路来理解矩阵分解，它的结构图就是图2 这样的。 ![](Images/948243d5516a7aacb72a25928827f55d.png)savepage-src="https://static001.geekbang.org/resource/image/e6/bd/e61aa1d0d6c75230ff75c2fb698083bd.jpg"}图2 矩阵分解的神经网络化示意图图 2 中的输入层是由用户 ID 和物品 ID 生成的 One-hot 向量，Embedding层是把 One-hot 向量转化成稠密的 Embedding向量表达，这部分就是矩阵分解中的用户隐向量和物品隐向量。输出层使用了用户隐向量和物品隐向量的内积作为最终预测得分，之后通过跟目标得分对比，进行反向梯度传播，更新整个网络。把矩阵分解神经网络化之后，把它跟 Embedding+MLP 以及 Wide&Deep模型做对比，我们可以一眼看出网络中的薄弱环节：矩阵分解在 Embedding层之上的操作好像过于简单了，就是直接利用内积得出最终结果。这会导致特征之间还没有充分交叉就直接输出结果，模型会有欠拟合的风险。针对这一弱点，NeuralCF对矩阵分解进行了改进，它的结构图是图 3这样的。 ![](Images/772cbbbbd7ff7ce86b01b88ae0fee862.png)savepage-src="https://static001.geekbang.org/resource/image/5f/2c/5ff301f11e686eedbacd69dee184312c.jpg"}图3 NeuralCF的模型结构图 （出自论文Neural Collaborative Filtering）我想你一定可以一眼看出它们的区别，那就是 NeuralCF用一个多层的神经网络替代掉了原来简单的点积操作。这样就可以让用户和物品隐向量之间进行充分的交叉，提高模型整体的拟合能力。NeuralCF 模型的扩展，双塔模型有了之前实现矩阵分解和深度学习模型的经验，我想你理解起来 NeuralCF肯定不会有困难。事实上，NeuralCF的模型结构之中，蕴含了一个非常有价值的思想，就是我们可以把模型分成用户侧模型和物品侧模型两部分，然后用互操作层把这两部分联合起来，产生最后的预测得分。这里的用户侧模型结构和物品侧模型结构，可以是简单的 Embedding层，也可以是复杂的神经网络结构，最后的互操作层可以是简单的点积操作，也可以是比较复杂的MLP 结构。但只要是这种物品侧模型 + 用户侧模型 +互操作层的模型结构，我们把它统称为"双塔模型"结构。图 4就是一个典型"双塔模型"的抽象结构。它的名字形象地解释了它的结构组成，两侧的模型结构就像两个高塔一样，而最上面的互操作层则像两个塔尖搭建起的空中走廊，负责两侧信息的沟通。![](Images/bc75cf3e032692b1393cdb3a9d329649.png)savepage-src="https://static001.geekbang.org/resource/image/66/cf/66606828b2c80a5f4ea28d60762e82cf.jpg"}图4 双塔模型结构\（出自论文 Sampling-Bias-Corrected Neural Modeling for Large Corpus ItemRecommendations）对于 NerualCF 来说，它只利用了用户 ID 作为"用户塔"的输入特征，用物品ID作为"物品塔"的输入特征。事实上，我们完全可以把其他用户和物品相关的特征也分别放入用户塔和物品塔，让模型能够学到的信息更全面。比如说，YouTube在构建用于召回层的双塔模型时，就分别在用户侧和物品侧输入了多种不同的特征，如图5 所示。 ![](Images/d3078603f8c6259232c0c91fcbf4f94e.png)savepage-src="https://static001.geekbang.org/resource/image/e2/87/e2603a22ec91a9f00be4b73feyy1f987.jpg"}图5 YouTube双塔召回模型的架构\（出自论文 Sampling-Bias-Corrected Neural Modeling for Large Corpus ItemRecommendations）我们看到，YouTube 召回双塔模型的用户侧特征包括了用户正在观看的视频ID、频道 ID（图中的 seedfeatures）、该视频的观看数、被喜欢的次数，以及用户历史观看过的视频 ID等等。物品侧的特征包括了候选视频的 ID、频道ID、被观看次数、被喜欢次数等等。在经过了多层 ReLU神经网络的学习之后，双塔模型最终通过 softmax输出层连接两部分，输出最终预测分数。看到这里，你可能会有疑问，这个双塔模型相比我们之前学过的 EmbeddingMLP 和 Wide&Deep有什么优势呢？其实在实际工作中，双塔模型最重要的优势就在于它易上线、易服务。为什么这么说呢？你注意看一下物品塔和用户塔最顶端的那层神经元，那层神经元的输出其实就是一个全新的物品Embedding 和用户 Embedding。拿图 4 来说，物品塔的输入特征向量是x，经过物品塔的一系列变换，生成了向量 u(x)，那么这个 u(x) 就是这个物品的Embedding 向量。同理，v(y) 是用户 y 的 Embedding向量，这时，我们就可以把 u(x) 和 v(y)存入特征数据库，这样一来，线上服务的时候，我们只要把 u(x) 和 v(y)取出来，再对它们做简单的互操作层运算就可以得出最后的模型预估结果了！所以使用双塔模型，我们不用把整个模型都部署上线，只需要预存物品塔和用户塔的输出，以及在线上实现互操作层就可以了。如果这个互操作层是点积操作，那么这个实现可以说没有任何难度，这是实际应用中非常容易落地的，也是工程师们喜闻乐见的，这也正是双塔模型在业界巨大的优势所在。正是因为这样的优势，双塔模型被广泛地应用在YouTube、Facebook、百度等各大公司的推荐场景中，持续发挥着它的能量。NeuralCF 的 TensorFlow 实现熟悉了 NerualCF 和双塔模型的结构之后，我们就可以使用 TensorFlow来实现它们了。通过之前 Embedding+MLP 模型以及 Wide&Deep模型的实现，我想你对 TensorFlow中读取数据，定义特征，训练模型的过程肯定已经驾轻就熟了。我们只要更改之前代码中模型定义的部分，就可以实现NeuralCF。具体的代码你可以参考 SparrowRecsys 项目中的NeuralCF.py，我只贴出了 NeuralCF模型部分的实现。下面，我们重点讲解一下它们的实现思路。    