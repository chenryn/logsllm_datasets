Drum, 1000
Drum, 120
30
25
20
15
10
5
s
d
n
u
o
r
#
Push, 1000
Push, 120
Pull, 1000
Pull, 120
Drum, 1000
Drum, 120
80
70
60
50
40
30
20
10
s
d
n
u
o
r
#
0
0
5
10
15
x/F
20
25
30
35
0
10
20
30
40
50
60
70
80
α
(a) α = 10%.
(b) x = 32F .
Figure 1. Average propagation time to 99% of the correct processes, n = 120, 1000.
Push
Pull
Drum
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
s
e
s
s
e
c
o
r
p
t
c
e
r
r
o
c
f
o
e
g
a
t
n
e
c
r
e
p
Push
Pull
Drum
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
s
e
s
s
e
c
o
r
p
t
c
e
r
r
o
c
f
o
e
g
a
t
n
e
c
r
e
p
0
0
5
10
15
20
25
# rounds
30
35
40
45
50
0
0
5
10
15
20
25
# rounds
30
35
40
45
50
(a) α = 10%, x = 32F .
(b) α = 40%, x = 32F .
Figure 2. CDF: Average percentage of correct processes that receive M, n = 1000.
Figure 2 illustrates the cumulative distribution function
(CDF) of the percentage of correct processes that receive
M by a given round, under different DoS attacks. As ex-
pected, Push propagates M to the non-attacked processes
very quickly, but takes much longer to propagate it to the
attacked processes. Again, we see that Drum signiﬁcantly
outperforms both Push and Pull when a strict subset of the
system is attacked.
Interestingly, on average, Push propagates M to more
processes per round than Pull does (see Figure 2), although
the average number of rounds Pull takes to propagate M
to 99% of the correct processes is smaller than that of Push
(see Figure 1). This paradox occurs since, with Pull, there is
a non-negligible probability that M is delayed at the source
for a long time. In the full paper [1] we compute that with
F = 32, the probability for M not being propa-
F = 4 and x
gated beyond the source in 5, 10, and 15 rounds is 0.54, 0.3,
and 0.16 respectively. Once M reaches one non-attacked
process, it quickly propagates to the rest of the processes.
Therefore, even if by a certain round k, in most runs, a large
percentage of the processes have M , there is still a non-
negligible number of runs in which Pull does not reach any
process (other than the source) by round k. This large dif-
ference in the percentage of processes reached has a large
impact on the average depicted in Figure 2.
In contrast,
Push, which reaches all the non-attacked processes quickly
in all runs, does not have runs with such low percentages
factoring into this average. Nevertheless, Push’s average
propagation time to 99% of the correct processes is much
higher than Pull’s, because Push has to propagate M to all
the attacked processes, whereas Pull has to propagate M
only out of one attacked process.
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 10:04:10 UTC from IEEE Xplore.  Restrictions apply. 
s
d
n
u
o
r
#
30
25
20
15
10
5
0
0
Push, 120
Push, 500
Pull, 120
Pull, 500
Drum, 120
Drum, 500
Push, 120
Push, 500
Pull, 120
Pull, 500
Drum, 120
Drum, 500
100
90
80
70
60
50
40
30
20
10
s
d
n
u
o
r
#
10
20
30
40
α
50
60
70
80
90
0
0
10
20
30
40
50
60
70
80
90
α
(a) B = 7.2n (c = 2).
(b) B = 36n (c = 10).
Figure 3. Average propagation time to 99% of the correct processes.
7.2. Adversary Strategies
on other processes.
We now evaluate the protocols under a range of attacks
with ﬁxed adversary strengths. First, we consider severe at-
tack with B = 7.2n and B = 36n (corresponding to c = 2
and c = 10, resp.) fabricated messages per round. If the ad-
versary chooses to attack all correct processes, it can send
8 (resp., 40) fabricated messages to each of them in each
round, because 90% of the processes are correct. If the ad-
versary instead focuses on 10% of the processes, it can send
72 (resp., 360) fabricated messages per round to each. Fig-
ure 3 illustrates the protocols’ propagation times with dif-
ferent percentages of attacked processes, for system sizes
of 120 and 500. It validates the prediction of Lemma 2, and
shows that the most damaging adversary strategy against
Drum is to attack all the correct processes. That is, an adver-
sary cannot “beneﬁt” from focusing its capacity on a small
subset of the processes.
In contrast, the performance of
Push and Pull is seriously hampered when a small subset of
the processes is targeted. Not surprisingly, the three proto-
cols perform equally when all correct processes are targeted
(see the rightmost data point).
8. Implementation and Measurements
We have implemented Drum, Push, and Pull in Java. The
implementations are multithreaded. The operations that oc-
cur in a round are not synchronized, e.g., one process might
send messages before trying to receive messages in that
round, while another might ﬁrst receive a new message, and
then propagate it. We run our experiments on 50 machines
at the Emulab testbed [21], on a 100Mbit LAN, where a
single process is run on each machine (i.e., n = 50). We
designate 10% of the processes as malicious – they do not
propagate any messages, and instead perform DoS attacks
Our ﬁrst goal for these experiments is to validate the
simulation methodology. To this end, we experiment with
the same settings that were tested in Section 7. The results
are virtually identical to the simulation results, and can be
found in the full paper [1].
We proceed to evaluate the protocols in a realistic setting,
where multiple messages are sent. By running on a real
network, we can faithfully evaluate latency in milliseconds
(instead of rounds), as well as throughput.
In each experiment scenario, a total of 10, 000 messages
are sent by a single source, at a rate of 40 messages per
second. The average received throughput and latency are
measured at the remaining 44 correct processes (recall that
5 of the 50 processes are faulty.) The average throughput
is calculated ignoring the ﬁrst and last 5% of the time of
each experiment. The round duration is 1 second. Data
messages are 50 bytes long (The evaluation of [8] used a
similar transmission rate and similar message sizes.)
In a practical system, messages cannot reside in local
buffers forever, nor can a process send all the messages it
ever received in a single round. In our experiments, mes-
sages are purged from processes’ buffers after 10 rounds,
and each process sends at most 80 messages to each of its
gossip partners in a round. These are roughly twice the
buffer size and sending rate required for the throughput of
40 messages per round in an ideal attack-free setting, since
the propagation time in the absence of attacks is about 5
rounds. Due to purging, some messages may fail to reach
all the processes. Since we measure throughput at the re-
ceiving end, this is reﬂected by an average throughput lower
than the transmission rate (of 40 messages per second).
Figure 4 shows the throughput at the receiving processes
for Drum, Push, and Pull, under the DoS attack scenar-
ios staged in the validation above. Figure 4(a) indicates
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 10:04:10 UTC from IEEE Xplore.  Restrictions apply. 
)
c
e
s
/
s
g
s
m
(
t
u
p