    $ afl-fuzz -i testcase_dir -o findings_dir /path/to/program [params]
或者使用“@@”替换输入文件，Fuzzer会将其替换为实际执行的文件：
    $ afl-fuzz -i testcase_dir -o findings_dir /path/to/program @@ 
如果没有什么错误，Fuzzer就正式开始工作了。首先，对输入队列中的文件进行预处理；然后给出对使用的语料库可警告信息，比如这里提示有个较大的文件（14.1KB），且输入文件过多；最后，开始Fuzz主循环，显示状态窗口。
##### (3) 使用SCREEN
一次Fuzzing过程通常会持续很长时间，如果这期间运行afl-fuzz实例的终端终端被意外关闭了，那么Fuzzing也会被中断。而通过在`screen
session`中启动每个实例，可以方便的连接和断开。关于screen的用法这里就不再多讲，大家可以自行查询。
    $ screen afl-fuzz -i testcase_dir -o findings_dir /path/to/program @@ 
也可以为每个session命名，方便重新连接。
    $ screen -S fuzzer1
    $ afl-fuzz -i testcase_dir -o findings_dir /path/to/program [params] @@
    [detached from 6999.fuzzer1]
    $ screen -r fuzzer1
      ...
#### 2\. 黑盒测试
所谓黑盒测试，通俗地讲就是对没有源代码的程序进行测试，这时就要用到AFL的QEMU模式了。启用方式和LLVM模式类似，也要先编译。但注意，因为AFL使用的QEMU版本太旧，`util/memfd.c`中定义的函数`memfd_create()`会和glibc中的同名函数冲突，在[这里](https://www.mail-archive.com/PI:EMAIL/msg1643066.html)可以找到针对QEMU的patch，之后运行脚本`build_qemu_support.sh`就可以自动下载编译。
    $ apt-get install libini-config-dev libtool-bin automake bison libglib2.0-dev -y
    $ cd qemu_mode
    $ build_qemu_support.sh
    $ cd .. && make install
现在起，只需添加`-Q`选项即可使用QEMU模式进行Fuzzing。
    $ afl-fuzz -Q -i testcase_dir -o findings_dir /path/to/program [params] @@
#### 3\. 并行测试
##### (1) 单系统并行测试
如果你有一台多核心的机器，可以将一个`afl-fuzz`实例绑定到一个对应的核心上，也就是说，机器上有几个核心就可以运行多少`afl-fuzz`
实例，这样可以极大的提升执行速度，虽然大家都应该知道自己的机器的核心数，不过还是提一下怎么查看吧：
    $ cat /proc/cpuinfo\| grep "cpu cores"\| uniq
`afl-fuzz`并行Fuzzing，一般的做法是通过`-M`参数指定一个主Fuzzer(`Master
Fuzzer`)、通过`-S`参数指定多个从Fuzzer(`Slave Fuzzer`)。
    $ screen afl-fuzz -i testcases/ -o sync_dir/ -M fuzzer1 -- ./program
    $ screen afl-fuzz -i testcases/ -o sync_dir/ -S fuzzer2 -- ./program
    $ screen afl-fuzz -i testcases/ -o sync_dir/ -S fuzzer3 -- ./program
      ...
这两种类型的Fuzzer执行不同的Fuzzing策略，前者进行确定性测试（deterministic
），即对输入文件进行一些特殊而非随机的的变异；后者进行完全随机的变异。
可以看到这里的`-o`指定的是一个同步目录，并行测试中所有的Fuzzer将相互协作，在找到新的代码路径时，相互传递新的测试用例，如下图中以Fuzzer0的角度来看，它查看其它fuzzer的语料库，并通过比较id来同步感兴趣的测试用例。
`afl-whatsup`工具可以查看每个fuzzer的运行状态和总体运行概况，加上`-s`选项只显示概况，其中的数据都是所有fuzzer的总和。
还`afl-gotcpu`工具可以查看每个核心使用状态。
##### (2) 多系统并行测试
多系统并行的基本工作原理类似于单系统并行中描述的机制，你需要一个简单的脚本来完成两件事。在本地系统上，压缩每个fuzzer实例目录中`queue`下的文件，通过SSH分发到其他机器上解压。
来看一个例子，假设现在有两台机器，基本信息如下：
fuzzer1 | fuzzerr2  
---|---  
172.21.5.101 | 172.21.5.102  
运行2个实例 | 运行4个实例
为了能够自动同步数据，需要使用`authorized_keys`的方式进行身份验证。现要将fuzzer2中每个实例的输入队列同步到fuzzer1中，可以下面的方式：
    #!/bin/sh
    # 所有要同步的主机
    FUZZ_HOSTS='172.21.5.101 172.21.5.102'
    # SSH user
    FUZZ_USER=root
    # 同步目录
    SYNC_DIR='/root/syncdir'
    # 同步间隔时间
    SYNC_INTERVAL=$((30 * 60))
    if [ "$AFL_ALLOW_TMP" = "" ]; then
      if [ "$PWD" = "/tmp" -o "$PWD" = "/var/tmp" ]; then
        echo "[-] Error: do not use shared /tmp or /var/tmp directories with this script." 1>&2
        exit 1
      fi
    fi
    rm -rf .sync_tmp 2>/dev/null
    mkdir .sync_tmp || exit 1
    while :; do
      # 打包所有机器上的数据
      for host in $FUZZ_HOSTS; do
        echo "[*] Retrieving data from ${host}..."
        ssh -o 'passwordauthentication no' ${FUZZ_USER}@${host} \
          "cd '$SYNC_DIR' && tar -czf - SESSION*" >".sync_tmp/${host}.tgz"
      done
      # 分发数据
      for dst_host in $FUZZ_HOSTS; do
        echo "[*] Distributing data to ${dst_host}..."
        for src_host in $FUZZ_HOSTS; do
          test "$src_host" = "$dst_host" && continue
          echo "    Sending fuzzer data from ${src_host}..."
          ssh -o 'passwordauthentication no' ${FUZZ_USER}@$dst_host \
            "cd '$SYNC_DIR' && tar -xkzf - &>/dev/null" <".sync_tmp/${src_host}.tgz"
        done
      done
      echo "[+] Done. Sleeping for $SYNC_INTERVAL seconds (Ctrl-C to quit)."
      sleep $SYNC_INTERVAL
    done
成功执行上述shell脚本后，不仅`SESSION000` `SESSION002`中的内容更新了，还将`SESSION003`
`SESSION004`也同步了过来。
### 七、认识AFL状态窗口
通过状态窗口，我们可以监控Fuzzer运行时的各种信息，在[status_screen](http://lcamtuf.coredump.cx/afl/status_screen.txt)中有详细的说明，这里只是做一个简单的介绍，对已经了解这部分的读者可以直接跳过，如果需要更具体的内容，可以去看看原文。另外说一下，该输出信息也不是必须的，后面的文章中会提到如何将Fuzzer的输出重定向到`/dev/null`，然后通过其他方法取得Fuzzer运行状态。
① Process timing:Fuzzer运行时长、以及距离最近发现的路径、崩溃和挂起经过了多长时间。
② Overall results：Fuzzer当前状态的概述。
③ Cycle progress：我们输入队列的距离。
④ Map coverage：目标二进制文件中的插桩代码所观察到覆盖范围的细节。
⑤ Stage progress：Fuzzer现在正在执行的文件变异策略、执行次数和执行速度。
⑥ Findings in depth：有关我们找到的执行路径，异常和挂起数量的信息。
⑦ Fuzzing strategy yields：关于突变策略产生的最新行为和结果的详细信息。
⑧ Path geometry：有关Fuzzer找到的执行路径的信息。
⑨ CPU load：CPU利用率
### 八、总结
到此为止，本文已经介绍完了如何开始一次Fuzzing，但这仅仅是一个开始。AFL
的Fuzzing过程是一个死循环，我们需要人为地停止，那么什么时候停止？上面图中跑出的18个特别的崩溃，又如何验证？还有文中提到的各种概念——代码覆盖率、元组、覆盖引导等等又是怎么回事儿？所谓学非探其花，要自拔其根，学会工具的基本用法后，要想继续进阶的话，掌握这些基本概念相当重要，有助于后续更深层次内容的理解。所以后面的几篇文章，首先会继续本文中未完成的工作，然后详细讲解重要概念和AFL背后的原理，敬请各位期待。
### 参考资料
[1][American Fuzzy Lop](http://lcamtuf.coredump.cx/afl/)
[2][Yet another memory leak in ImageMagick](https://medium.com/@ilja.bv/yet-another-memory-leak-in-imagemagick-or-how-to-exploit-cve-2018-16323-a60f048a1e12)
[3][Vulnerability Discovery Against Apple
Safari](https://blog.ret2.io/2018/06/13/pwn2own-2018-vulnerability-discovery/)
[4][Pulling JPEGs out of thin
air](https://lcamtuf.blogspot.com/2014/11/pulling-jpegs-out-of-thin-air.html)
[5][parallel_fuzzing.txt](https://github.com/mirrorer/afl/blob/master/docs/parallel_fuzzing.txt)
[6][Fuzzing workflows; a fuzz job from start to
finish](https://foxglovesecurity.com/2016/03/15/fuzzing-workflows-a-fuzz-job-from-start-to-finish/)
[7] _Open Source Fuzzing Tools_ – ‘Chapter 10 Code Coverage and Fuzzing’
[8] _Fuzzing for Software Security Testing and Quality Assurance_ – ’7.2 Using
Code Coverage Information’
* * *