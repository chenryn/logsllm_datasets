context.write((KEYOUT) key, (VALUEOUT) value);
智能运维：从O搭建大规模分布式AlOps系统
Context context） throws IOException, InterruptedException {
）throws IOException,InterruptedException {
---
## Page 122
public class WordCount{
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.io.Text;
import
import
import
import
import java.util.StringTokenizer;
import java.io.IOException;
package
代码6-3
最后输出这个结果。
可以在reduce(函数中对单词在不同行中出现的次数进行累加，结果就是该单词出现的总次数，
值对会调用一次reduce(函数。在这个例子中，“键”是单词，“值”就是单词出现的次数。因此，
任务的执行过程中，第二阶段会对 Mapper 任务输出的键值对按照键进行排序，对于键相等的键
public static class WordCountMap extends
以下代码分两部分，其中代码 6-3主要包括 mapO和 reduceO函数，代码6-4是启动类。
org.apache.hadoop.io.LongWritable
org.apache.hadoop.io.IntWritable;
org.apache.hadoop.fs.Path;
org.apache.hadoop.conf.Configuration;
public void map(LongWritable key, Text value, Context context)
private Text word=new Text（）；//表示该行中某一单词
private final IntWritable one = new IntWritable(l);
com.demo.bigdata.mr;
while(token.hasMoreTokens()){
StringTokenizer token = new StringTokenizer(line);
String line = value.toString();
Mapper{
throws IoException,InterruptedException {
word.set(token.nextToken());
第6章大规模数据离线计算分析
/／表示单词在该行中出现的次数
95
---
## Page 123
路径
代码6-4
表示单词出现的总次数，是最后输出的value
96
public static class WordCountReduce extends
public static void main(String[] args) throws Exception {
 job.setReducerClass(WordCountReduce.class);// 设置自定义的 Reducer类
public void reduce(Text key, Iterable values,
智能运维：从O搭建大规模分布式AIOps系统
job.waitForCompletion(true);
FileOutputFormat.setOutputPath(job，new Path(args[1]))；// 告诉job 执行作业时的输出
FileInputFormat.addInputPath(
job.setOutputFormatCla
job.setInputFormatClass
job.setOutputValueClass(IntWritable.class);
job.setOutputKeyClass(Text.class);
job.setJobName("wordcount");
Job job= new Job(conf);// 创建一个job 对象，
Configuration conf = new Configuration();
ob.setJarByClass(WordCount.class);
context.write (key,
for（IntWritable val:values){
int sum =0;
Reducer
sum+=val.get（)；/／执行到这里，sum表示该单词出现的总次数
Context context)throws IoException,
context.write(word, one);
//表示单词出现的总次数
ass
new IntWritable（sum））；// key 表示单词，是最后输出的 key，sum
s（TextInputFormat.class）；//设置把输入文件处理成键值对的类
(TextOutputFormat.class);
/／让作业运行，直到运行结束，程序退出
（i
ob，
，new Path(args[O]））;/／告诉job 执行作业时的输入路径
，封装运行时所需要的所有信息
InterruptedException{
---
## Page 124
均匀。
被分发到一个或者少数几个Reducer 任务中，导致数据分布不均匀。
问题。
误或者Container加载失败，这时基本可以判断本次离线计算任务的输入数据可能存在数据倾斜
或者几台机器上，这些数据的计算速度远远低于平均计算速度，导致整个计算过程很慢。
6.2.2
行结束。
运行。最后一句job.waitForCompletion(true)，表示把 job 对象提交给 Hadoop 运行，直到作业运
次。
为输出的是每个单词，所以其出现次数是常量1。如果一行文本中包含两个 hello，则会输出两
格进行拆分，把每个单词作为新的键，数值1作为新的值，写入上下文context中。在这里，因
mapO函数的第二个形参是行文本内容，这是我们所关心的。核心代码表示把行文本内容按照空
场景 2：在 group by 时，如果分组的维度太少，维度的值分布不均匀，将导致数据分布不
场景1：当一个大表和一个小表 join 时，如果小表的 key 较集中，将会引起大表中的数据
Hadoop 中的数据倾斜主要表现在任务在Reducer阶段会长时间停留在大概99%处不能结束
数据倾斜就是指我们在计算数据的时候，数据的分散度不够，导致大量的数据集中到一台
在以上代码中，我们创建了一个job 对象，这个对象封装了任务，可以提交给 Hadoop 独立
下面列举了一些常见的导致数据倾斜的场景。
导致数据倾斜的原因可能有很多种，常见的原因如下。
在代码6.3和代码6.4中WordCountMap类的泛型依次是LongWritable,Text,Text,IntWritable
建表时考虑不周。比如同为 type 字段,其中一个表类型为 int，另一个表类型为 string。
某些 SQL 语句本身有问题。比如 SQL 中含有 distinct 的计算。
较大，都会引起数据倾斜。
业务数据本身有问题。比如业务数据 join 的 id 分布不均匀，或者 id 为 null 值的比重
key 分布不均匀。比如在两个表join 过程中，其中一个表的key 分布不均匀。
离线计算的数据倾斜问题
第6章大规模数据离线计算分析
97
---
## Page 125
如果将其中的 order_id 和订单表的 order_id 关联，就会出现数据倾斜。
再进行 union。为了方便理解，下面列举几个业务场景来进行说明。
hive.groupby.skewindata=true
hive.map.aggr=true
经过这两轮MR任务最后完成最终的聚合操作。相关的参数设置如下：
数据结果再按照key输出给 Reducer,这个过程可以保证相同的key被分布到同一个Reducer中。
中，从而达到负载均衡的目的。在第二个 MR 任务中，Mapper 根据第一个 MR 任务预处理后的
都进行部分聚合操作，并输出结果。这样处理的结果是相同的Key可以被分发到不同的 Reducer
进行聚合操作，当发生数据倾斜时进行负载均衡。所生成的查询计划会有两个MR 任务。在第
将导致数据分布不均匀。
一个 MR 任务中，Mapper 阶段的输出结果集合会被随机分布到 Reducer 阶段中，每个 Reducer
98
场景：比如在日志中，通常会发生信息丢失的问题。假如日志中的order_id存在丢失情况，
、场景 3：当大表与大表关联时，在关联的条件字段中，其中一个表的空值、null值过多，
解决方法 1：order_id为空值的则不参与关联，用 union all合并数据，如代码 6-5 所示。
案例1：空值产生的数据倾斜问题。
在业务逻辑优化效果不太好的情况下，有些时候可以将倾斜的数据单独拿出来处理，最后
3.特殊情况特殊处理
〇使用 mapjoin：让小的维度表（建议在 20000条记录以下）先写入内存，并按顺序扫描
2.优化SQL语句
可以通过修改 hive.map.aggr 和 hive.groupby.skewindata 参数同时配置为 true，在 Mapper 端
1．调节参数
针对数据倾斜，业界一般有以下几种解决方案。
O
智能运维：从O 搭建大规模分布式AIOps 系统
group by 优化：采用 sumO结合 group by 的方式替换 count(distinct)来完成计算。
的 Reducer 中。也可以对空值进行单独处理，然后再和其他非空值的计算结果进行合
空值优化：可以将空值的 key 变成一个字符串加上随机数，把倾斜的数据分布到不同
并。
大表完成join。这种方式比较适用于大表和小表的join。
---
## Page 126
select /*+mapjoin(t)*/* from log a
代码6-8
码6-8所示。
mapjoin不支持这么大的表。如果用普通的join，又会碰到数据倾斜的问题。那么解决方法如代
select /*+mapjoin(b)*/* from log a
代码6-7
高，但是如果小表很大，大到 mapjoin 会出现 bug 或异常，这时就需要特别处理了。例如：
就能把倾斜的数据分布到不同的 Reducer 中，从而解决数据倾斜问题。
如-99、”、null 等无效字符组合）产生的倾斜问题。把空值的key 变成一个字符串加上随机数,
方法1中 log 读取两次，job 数是 2；在解决方法2中 job 数是1。这种优化适合由于无效id（比
select*
代码6-6
select*fromlog a
unionall
and a.order_id is not null
on a.order_id =b.order_id
join orders b
select*from log a
代码6-5
left outer join（
on a.order_id = b.order_id;
left outer join orders b
b.order_id;
on case when a.order_id is null then cast(rand() *100o0 as bigint) else a.order_id end
left outer join orders b
from loga
where a.order_id is null;
select /*+mapjoin(c)*/b*
orders 表有超过600万条的记录，把orders 分发到所有的 Mapper 中也有不小的开销，而且
使用mapjoin 解决小表（记录数少）关联大表的数据倾斜问题。这种方法使用的频率非常
总结：解决方法2比方法1的执行效率更高，不但I/O少了，而且作业数也少了。在解决
解决方法2：为空值分配一个随机值，如代码6-6所示。
案例2：小表不小不大，怎么用mapjoin 解决数据倾斜问题。
仅供非商业用途或交流学习使用
第6章
大规模数据离线计算分析
6
---
## Page 127
6.2.3
起的，问题本身并不是很复杂。
中，可以通改变 job 的步骤、处理 key 值等方式来实现。数据倾斜多数是由于开发人员疏忽引
100
安全类（网络需要基础的安全保障）
集群类（将N台主机当成一个系统）
之间进行通信）
网络编程（通过程序实现在多台主机
网络通信类（网络是分布式的基础）
知识点分类
on a.order_id = t.order_id
表6-1中列出了分布式离线计算知识点分类及相关技术栈。
综上所述，
on c.order_id = d.order_id
join orders b
from ( select order_id from log group by order_id)(
智能运维：从O搭建大规模分布式AIOps系统
分布式离线计算的技术栈
，解决数据倾斜问题就是要将 Mapper 阶段的输出数据更均匀地分布到 Reducer
表6-1
Socket、多线程、非阻塞I/O、网络框架、Netty、Mina、MQ、同步RPC、异步RPC，
0高可用性：保证服务一直处于可用状态，如采用余的设备、多副本
以及一些主要的 RPC 协议，比如 RMI、Rest API 和 Thrift
OSI模型的 7层、TCP/IP、DNS、NAT、HTTP、SPDY/HTTP2、Telnet
相关技术栈
O
分布式离线计算知识点分类及相关技术栈
不可否认性：基于数字证书的数字签名和验签、基于密钥的散列
身份认证：基于用户名/口令、基于数字证书
分布式事务：保证在多台服务器上完成的操作符合事务的ACID属性
负载均衡：将大量的工作负载均匀分配到多台主机上
完整性：安全散列、消息认证码（MAC）
私密性：对称加密、非对称加密
一致性哈希：将数据分布到集群中的多台主机上
集群状态协调：如Zookeeper、分布式锁、选主
分布式一致性：
故障转移：当出现错误时自动解决
故障检测：心跳包、告警、性能预警
容错性：当硬件或软件发生故障时能够继续运转
分片：把数据分成多个数据集，由不同的服务器来分别处理
伸缩性（横向)：技术保障可通过添加计算机或设备来解决业务增长带来的压力
仅供非商业用途或交流学习使用
强一致性、最终一致性
---
## Page 128
用Kafka处理，也会用Flume来检测落地的文件，然后再转换成消息。
和SDK拿到事件后，转换成消息或落地成文件；第三块是消息中间件，接收第二块的消息，使
技术，在Web、H5 端采用通用的JS 模块，在移动客户端采用 SDK 捕获各种事件，当JS 模块
第一块是数据同步工具，从业务数据库同步数据，可支持增量和全量操作；第二块是日志采集
用层。
不在本节内容范围内。微博广告数据架构示意图如图6-9 所示。
算，都存在巨大的挑战。离线计算，主要需求是计算历史数据，关于当天的批处理或流式计算
景，数据仓库应该如何选择数据模型，如何在满足业务需求的同时能高效、准确地按时完成计
博有超级粉丝通、粉丝经济等丰富的广告产品，由于微博具有庞大的用户关系和复杂的业务场
本节将给大家介绍微博广告的离线计算。微博广告系统每天会产生10TB 以上的增量数据。微
6.3
数据采集层：数据采集是大数据架构最重要的一环。微博广告的数据采集主要分三大块，
微博广告数据架构主要分为四层，分别是数据采集层、数据计算层、数据服务层和数据应