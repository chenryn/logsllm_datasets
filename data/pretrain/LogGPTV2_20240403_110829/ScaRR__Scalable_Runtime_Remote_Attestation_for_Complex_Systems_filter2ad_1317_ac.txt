on the top of the stack and therefore is valid. Moving forward,
the Veriﬁer pops from the stack and pushes the edge (M3,A1),
which corresponds to the second invocation of the function
a(). At this point, the third measurement (C,C,H2) indicates
that the Prover exited from the function a() through the edge
(A2,M2), which is not in relation with (M3,A1). Thus, the
Veriﬁer detects the attack and triggers an alarm.
6
Implementation
Here, we provide the technical details of the ScaRR schema
and, in particular, of the Measurements Generator (Sec-
tion 6.1) and of the Prover (Section 6.2).
6.1 Measurements Generator
The Measurements Generator is implemented as a compiler,
based on LLVM [31] and on the CRAB framework [24].
(M1,A1)(M1,A1)(A2,M2)(M3,A1)(M3,A1)(A2,M2)valid!(A2,M2) ret_to (M1,A1)not valid!(A2,M2) ret_to (M3,A1)(S,C,H1)(C,C,H2)(C,C,H2)TimeUSENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 127Figure 7: Internal architecture of the Prover.
save the new edge in a buffer inside the kernel-space. While,
every time the application crosses a checkpoint, the ScaRR
Libraries invoke the ScaRR sys_measure syscall to save the
checkpoint in the current online measurement, calculate the
hash of the edges saved so far, and, ﬁnally, store the online
measurement in a buffer located in the kernel-space. When
the predeﬁned number of online measurements is reached,
the Prover sends a partial report to the Veriﬁer and starts
collecting new online measurements. The Prover sends the
partial report by using a dedicated kernel thread. The whole
procedure is repeated until the application ﬁnishes processing
the input of the Veriﬁer.
The whole architecture of the Prover relies on the kernel
as a trusted anchor, since we ﬁnd it more efﬁcient in compari-
son to other commercial trusted platforms, such as SGX and
TrustZone, but other approaches can be also considered (Sec-
tion 8). To develop the kernel side of the architecture, we add
around 200 lines of code to a Kernel version v4.17-rc3. We
also include the Blake2 source [4,11], which is faster and pro-
vides high cryptographic security guarantees for calculating
the hash of the LoAs.
7 Evaluation
We evaluate ScaRR from two perspectives. First, we measure
its performance focusing on: attestation speed (Section 7.1),
veriﬁcation speed (Section 7.2) and network impact (Sec-
tion 7.3). Then, we discuss ScaRR security guarantees (Sec-
tion 7.4).
We obtained the results described in this section by run-
ning the bench-marking suite SPEC CPU 2017 over a Linux
machine equipped with an Intel i7 processor and 16GB of
memory 1. We instrumented each tool to detect all the neces-
sary control-ﬂow events, we then extracted the ofﬂine mea-
surements and we ran each experiment to analyze a speciﬁc
performance metrics.
1We did not manage to map assembly BBL addresses to LLVM IR for
519.lbm_r and 520.omnetpp_r.
Figure 8: Average attestation speed measured as number of
online measurements per second.
7.1 Attestation Speed
We measure the attestation speed as the number of online mea-
surements per second generated by the Prover. Figure 8 shows
the average attestation speed and the standard deviation for
each experiment of the SPEC CPU 2017. More speciﬁcally,
we run each experiment 10 times, calculate the number of on-
line measurements generated per second in each run, and we
compute the ﬁnal average and standard deviation. Our results
show that ScaRR has a range of attestation speed which goes
from 250K (510.parest) to over 400K (505.mcf) of online
measurements per second. This variability in performance
depends on the complexity of the single experiment and on
other issues, such as the ﬁle loading. Previous works prove
to have an attestation speed around 20K/ 30K of control-ﬂow
events per second [8, 9]. Since each online measurement con-
tains at least a control-ﬂow event, we can claim that ScaRR
has an attestation speed at least 10 times faster than the one
offered by the existing solutions.
7.2 Veriﬁcation Speed
During the validation of the partial reports, the Veriﬁer per-
forms a lookup against the Measurements DB and an update
of the shadow stack. To evaluate the overall performance of
the Veriﬁer, we consider the veriﬁcation speed as the maxi-
mum number of online measurements veriﬁed per second. To
measure this metrics, we perform the following experiment
for each SPEC tool: ﬁrst, we use the Prover to generate and
save the online measurements of a SPEC tool; then, the Ver-
iﬁer veriﬁes all of them without involving any element that
might introduce delay (e.g., network). In addition, we also
introduce a digital ﬁngerprint based on AES [39] to simulate
an ideal scenario in which the Prover is fast. We perform
User-SpaceApplication ProcessKernel-SpaceScaRR LibrariesExecution startsOther instructionsScaRR sys_measureScaRR ModuleOnline measurement generationControl-flow eventCheckpointControl-flow interceptionExecution finishesReports managingScaRR sys_addactionControl-flow edge savingCheckpoint interception128          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX Associationiﬁcation phase. To reduce network congestion and improve
veriﬁcation speed, we perform an empirical measurement of
the amount of data (i.e., MB) sent on a local network with
respect to the veriﬁcation speed by applying different settings.
The experiment setup is similar to Section 7.2, but the Prover
and the Veriﬁer are connected through an Ethernet network
with a bandwidth of 10Mbit/s. At ﬁrst, we record 1M of online
measurements for each SPEC CPU 2017 tool. Then, we send
the partial reports to the Veriﬁer over a TCP connection, each
time adopting a different approach among the following ones:
Single, Batch, Zip [7], Lzma [32], Bz2 [1] and ZStandard [6].
The results of this experiment are shown in Figure 10. In
the ﬁrst two modes (i.e., Single and Batch), we send a single
online measurement and 50K online measurements in each
partial report, respectively. As shown in the graph, both ap-
proaches generate a high amount of network trafﬁc (around
80MB), introducing a network delay which slows down the
veriﬁcation speed. For the other four approaches, each par-
tial report still contains 50K online measurements, but it is
generated through different compression algorithms. All the
four algorithms provide a high compression rate (on average
over 95%) with a consequent reduction in the network over-
load. However, the algorithms have also different compression
and decompression delays, which affect the veriﬁcation speed.
The Zip and ZStandard show the best performances with 1.2M
of online measurements/s and 1.6M of online measurements/s,
respectively, while Bz2 (30K of online measurements/s) and
Lzma (0.4M of online measurements/s) are the worst ones.
The number of online measurements per partial report might
introduce a delay in detecting attacks and its value depends
on the monitored application. We opted for 50K because the
SPEC CPU tools generate a high number of online measure-
ments overall. However, this parameter strictly depends on the
monitored application. This experiment shows that we can use
compression algorithms to mitigate the network congestion
and keep a high veriﬁcation speed.
7.4 Attack Detection
Here, we describe the security guarantees introduced by
ScaRR.
Code Injection. In this scenario, an attacker loads mali-
cious code, e.g., Shellcode, into memory and executes it by ex-
ploiting a memory corruption error [38]. A typical approach is
to inject code into a buffer which is under the attacker control.
The adversary can, then, exploit vulnerabilities (e.g., buffer
overﬂows) to hijack the program control-ﬂow towards the
shellcode (e.g., by corrupting a function return address).
When a W⊕X protection is in place, this attempt will gen-
erate a memory protection error, since the injected code is
placed in a writable memory area and it is not executable.
In case there is no W⊕X enabled, the attack will generate a
wrong LoA detected by the Veriﬁer.
Figure 9: Average number of procedure calls and procedure
returns found during the Online Program Analysis of the
SPEC CPU 2017 tools.
the veriﬁcation by loading the ofﬂine measurements in an in-
memory hash map and performing the shadow stack. Finally,
we compute the average veriﬁcation speed of all tools.
According to our experiments, the average veriﬁcation
speed is 2M of online measurements per second, with a range
that goes from 1.4M to 2.7M of online measurements per
second. This result outperforms previous works in which the
authors reported a veriﬁcation speed that goes from 110 [21]
to 30K [9] of control-ﬂow events per second. As for the attes-
tation speed, we recall that each online measurement contains
at least one control-ﬂow event.
The performance of the shadow stack depends on the num-
ber of procedure calls and procedure returns found during the
generation of online measurements in the Online Program
Analysis phase. To estimate the impact on the shadow stack,
we run each experiment of the SPEC CPU 2017 tool and
count the number of procedure calls and procedure returns.
Figure 9 shows the average number of the above-mentioned
variables found for each experiment. For some experiments
(i.e., 505.mcf and 544.nab), the average number is almost one
since they include some recursive algorithms that correspond
to small LoAs. If the average length of the LoAs tends to one,
ScaRR behaves similarly to other remote RA solutions that
are based on cumulative hashes [8,9]. Overall, Figure 9 shows
that a median of push/pop operations is less than 4, which
implies a fast update. Combining an in-memory hash map and
a shadow stack allows ScaRR to perform a fast veriﬁcation
phase.
7.3 Network Impact and Mitigation
A high sending rate of partial reports from the Prover might
generate a network congestion and therefore affect the ver-
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 129can detect those attacks since they deviate from the original
control-ﬂow.
Function Reuse Attacks. Those attacks rely on a sequence
of subroutines, that are called in an unexpected order, e.g.,
through virtual functions calls in C++ objects. ScaRR can
detect these attacks, since the ScaRR control-ﬂow model con-
siders both the calling and the target addresses for each pro-
cedure call. Thus, an unexpected invocation will result in
a wrong LoA. For instance, in Counterfeit Object-Oriented
Programming (COOP) attacks [36], an attacker uses a loop
to invoke a set of functions by overwriting a vtable and in-
voking functions from different calling addresses generates
unexpected LoAs.
Figure 10: Comparison of different approaches for generat-
ing partial repors in terms of network trafﬁc and veriﬁcation
speed.
8 Discussion
Another strategy might be to overwrite a node (i.e., a
BBL) already present in memory. Even though this attempt
is mitigated by W⊕X, as executable memory regions are not
writable, it is still possible to perform the attack by chang-
ing the memory protection attributes through the operating
system interface (e.g., the mprotect system call in Linux),
which makes the memory area writable. The ﬁnal result would
be an override of the application code. Thus, the static RA of
ScaRR can spot the attack.
Return-oriented Programming. Compared to previous
attacks, the code-reuse ones are more challenging since they
do not inject new nodes, but they simply reorder legitimate
BBLs. Among those, the most popular attack [37] is ROP [17],
which exploits small sequences of code (gadgets) that end
with a ret instruction. Those gadgets already exist in the
programs or libraries code, therefore, no code is injected. The
ROP attacks are Turing-complete in nontrivial programs [17],
and common defence mechanisms are still not strong enough
to deﬁnitely stop this threat.
To perform a ROP attack, an adversary has to link together
a set of gadgets through the so-called ROP chain, which is
a list of gadget addresses. A ROP chain is typically injected
through a stack overﬂow vulnerability, by writing the chain
so that the ﬁrst gadget address overlaps a function return
address. Once the function returns, the ROP chain will be
triggered and will execute the gadget in sequence. Through
more advanced techniques such as stack pivoting [19], ROP
can also be applied to other classes of vulnerabilities, e.g.,
heap corruption. Intuitively, a ROP attack produces a lot of
new edges to concatenate all the gadgets, which means invalid
online measurements that will be detected by ScaRR at the
ﬁrst checkpoint.
Jump-oriented Programming. An alternative to ROP at-
tacks are the JOP ones [16, 48], which exploit special gad-
gets based on indirect jump and call instructions. ScaRR
In this section we discuss limitations and possible solutions
for ScaRR.
Control-ﬂow graph. Extracting a complete and correct
CFG through static analysis is challenging. While using
CRAB as abstract domain framework, we experienced some
problems to infer the correct forward destinations in case of
virtual functions. Thus, we will investigate new techniques to
mitigate this limitation.
Reducing context-switch overhead. ScaRR relies on a
continuous context-switch between user-space and kernel-
space. As a ﬁrst attempt, we evaluated SGX as a trusted plat-
form, but we found out that the overhead was even higher due
to SGX clearing the Translation-Lookaside Buffer (TLB) [40]
at each enclave exit. This caused frequent page walks af-
ter each enclave call. A similar problem was related to the
Page-Table Isolation (PTI) [46] mechanism in the Linux
kernel, which protects against the Meltdown vulnerability.
With PTI enabled, TLB is partially ﬂushed at every context
switch, signiﬁcantly increasing the overhead of syscalls. New
trusted platforms have been designed to overcome this prob-
lem, but, since they mainly address embedded software, they
are not suitable for our purpose. We also investigated tech-
nologies such as Intel PT [25] to trace control-ﬂow events at
hardware level, but this would have bound ScaRR to a spe-
ciﬁc proprietary technology and we also found that previous
works [25, 27] experienced information loss.
Physical attacks. Physical attacks are aimed at diverting
normal control-ﬂow such that the program is compromised,
but the computed measurements are still valid. Trusted com-
puting and RA usually provide protection against physical
attacks. In our work, we mainly focus on runtime exploita-
tion, considering that ScaRR is designed for a deployment
on virtual machines. Therefore, we assume to have an adver-
sary performing an attack from a remote location or from the
user-space and the hosts not being able to be physically com-
promised. As a future work, we will investigate new solutions
to prevent physical attacks.
130          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX AssociationData-ﬂow attestation. ScaRR is designed to perform run-
time RA over a program CFG. Pure data-oriented attacks
might force the program to execute valid, but undesired paths
without injecting new edges. To improve our solution, we
will investigate possible strategies to mitigate this type of
attacks, considering the availability of recent tools able to
automatically run this kind of exploit [28].
Toward a full semantic RA. We will investigate new ap-
proaches to validate series of online measurements by using
runtime abstract interpretation [25, 27, 33].
9 Related Work
Runtime RA shares properties with classic CFI techniques.
Thus, we discuss current state-of-the-art of both research ar-
eas.
Remote Attestation. Existing RA schemes are based on a
cryptographic signature of a piece of software (e.g., software
modules, BIOS, operating system). Commercial solutions that
implement such mechanisms are already available: TPM [42],
SGX [18], and AMD TrustZone [47]. Academic approaches,
which focus on cloud systems, are proposed by Liangmin et
al. [45] and Haihe et al. [12]. More speciﬁcally, their solutions
involve a static attestation schema for infrastructures as a
service and JVM cloud computing, respectively. Even though
these technologies can provide high-security guarantees, they
focus on static properties (i.e., signatures of components) and
cannot offer any defence against runtime attacks.
To overcome design limitations of static RA, researchers
propose runtime RA. Kil et al. [30] analyze base pointers
of software components, such as stack and heap, and com-
pare them with the measurements acquired ofﬂine. Bailey et
al. [13] propose a coarse-grained level that attests the order
in which applications modules are executed. Davi et al. [20]