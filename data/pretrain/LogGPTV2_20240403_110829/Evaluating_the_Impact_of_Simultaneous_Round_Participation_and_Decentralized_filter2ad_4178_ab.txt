In this case, the ﬂow of messages is from/to the round coor-
dinator, so that the number of messages exchanged during
round r is O(n). In some other protocols, we ﬁnd a decen-
tralized decision pattern in which the set X contains all the
n processes in the system [13, 9], i.e. X = Π. Thus, the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:38:39 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007messages are exchanged from/to everybody and they attain
a complexity of O(n2) in a round. The decentralization of
the decision aims at having faster decisions as well as better
tolerating crashes; however, at the expenses of generating a
higher network load, which in turn may negatively impact
the protocol’s performance. The protocol in study has the
noticeable feature of allowing the dynamic conﬁguration of
the set of processes belonging to the decision set X. The
only constraint to be observed, in order to preserve safety,
is that, giving a round r, the coordinators of r and r + 1
should belong to X [8]. Therefore, the protocol is able to
deﬁne its proper message exchange pattern for each round,
by varying the cardinality of X from 2 to n. So, in order
to accomplish the best performance, the protocol must ade-
quate the use of this feature to the network load.
3 Simulation Model
Figure 1 illustrates the design of the system by follow-
ing a modular approach in which modules communicate be-
tween them through a pre-deﬁned interface. The consensus
module calls upon the failure detection module via a GET-
FAULTY() interface in order to get the list of suspected pro-
cesses. On the other hand, the application module starts a
consensus by invoking the PROPOSE() interface and the de-
cision value is informed to the application via a DECIDE()
callback function. The modules communicate with each
other by means of message passing (SEND() and RECEIVE()
primitives) through a reliable network link represented by
the network interface module.
Application
propose(v)
decide(u)
Consensus
send
receive
Network Interface
getFaulty
list of suspected
FD Oracle
Figure 1. Design of The Consensus System
The conﬁguration of the HMMR-consensus has two in-
put parameters: i) the round window size (w) and ii) the
number of processes able to decide during the execution of
a round (x).
Failure Detection Model. To detect crash failures, a well
known solution consists in using timeouts to identify pro-
cesses suspected of having crashed. Usually, some monitor-
ing mechanism based on message exchanging is used; pro-
cesses that do not communicate with the others within a spe-
ciﬁc timeout are considered suspected. Particularly, in the
push-style of monitoring, every process pi sends heartbeat
messages at each η units of time to all the other processes
pj informing it is alive. If pj does not receive a heartbeat
from pi within δ units of time after the message is expected
to be sent, then pi will be suspected by pj. The values of η
and δ can be conﬁgured in order to guarantee some QoS on
the information provided by the failure detector.
QoS of failure detectors is partially deﬁned by the
restrictions imposed by their completeness and accuracy
properties. Consider a failure detection service composed
by independent modules. Some additional QoS metrics for
the local failure detection module F Di,j of process pi that
monitors process pj have been proposed in [5].
In par-
ticular, we are interested in the following accuracy QoS
metrics: mistake duration (TM ), mistake recurrence time
(TMR) and query accuracy probability (PA). Mistake dura-
tion and mistake recurrence time are random variables that
represent, respectively, the length of a period during which
a process pi remains wrongly suspecting pj and the time
elapsed between two consecutive periods of wrong suspi-
cions of F Di,j. On the other hand, PA represents the
probability that a failure detector is correct at a random
time. These metrics are related to each other as follows:
PA = 1 − E(TM )/E(TMR), where E(V ) is the expected
value of the random variable V [5]. Our failure detection
service is based on the push-style of monitoring and has a
conﬁgurable QoS. However, in the simulations, the deci-
sions on suspecting or not a process are not driven by the
expiration of timeouts, but by the conﬁguration of the QoS
metrics (TM , TMR and PA) discussed above. Yet, we use
values for η and δ to conﬁgure the failure detector; these
two parameters are required to determine the values of TM
and TMR. Moreover the knowledge of η is also necessary to
generate the message overhead corresponding to the normal
activity of a push-style failure detector.
Communication Model. The communication module rep-
resents a simple Ethernet network that accounts for resource
contention [15]. In this case, two resources may suffer con-
tention: CPU (one per process) and network link. The CPU
contention is related to the processing performed in each
host to send and receive messages (the cost of executing
the algorithm or the application itself is negligible). The
network contention regards the transmission delay associ-
ated with the messages exchanged by the application. A
message m transmitted from pi to pj will be delivered by
pj after TS + TN + TR, where TS and TR represent, re-
spectively, the CPU contention to send (source) and receive
(destination) m; and TN is the network contention. Note
that, the network is shared by all processes in the system,
but a mechanism is used to provide equity in the use of the
network; every process has a network queue that stores mes-
sages to be transmitted, and the access to the network link
is given by the use of a token that circulates among all pro-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:38:39 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007cesses. The time spent in the network resource is one unit
of time (ut) and the time spent in the CPU resource is λut
(the cost of processing a message is the same regardless if
it is accounted in the source or in the destination). The λ
parameter represents the relative speed of processing a mes-
sage on a host compared to transmitting it over the network,
where λ = TCP U /TN , TCP U = TS = TR and λ ≥ 0 [15].
By choosing different values for λ it is possible to represent
different network environments.
4 Performance Evaluation
4.1 Simulation Scenarios
The HMMR-consensus was evaluated by means of dis-
crete event simulation with the support of the Neko frame-
work [16]. The simulations consisted in running a num-
ber of consensus sequentially, ﬁxing the number of pro-
cesses to n = 5 and the maximum number of faults to
f = 2. The performance analysis of the HMMR-consensus
has been done through a number of experiments in different
conﬁguration scenarios. The conﬁguration scenarios were
deﬁned, by varying i) the round window size (w ∈ [1, 5]);
ii) the decentralized decision set cardinality (x ∈ [2, 5]),
and (iii) the QoS of the failure detector. This last parameter
was represented by the probability of wrong suspicions and
denoted as PF D (1 − PA). Real crashes (that are rare) were
not taken into account.
The failure detector was conﬁgured with three param-
eters: η, δ and PF D. We used η = 1, 000ut, δ = 1ut
and four conﬁgurations for PF D: 0%, 5%, 10% and 20%.
As explained in Section 3, the behavior of the failure de-
tection service is driven by the QoS metrics TM and TMR
whose values are obtained from speciﬁc probability distri-
bution functions. For TM , it was used an uniform distribu-
tion parameterized with upper and lower bounds deﬁned in
terms of the input parameters for the service (η, δ). On the
other hand, TMR was obtained by means of an exponen-
tial distribution parameterized with the value of E(TMR),
which in turn is obtained from E(TM) and PA as mentioned
in Section 3.
By tuning the value of λ it is possible to represent dif-
ferent levels of contention in the network. Particularly, the
most used values include λ = 10, λ = 0.1 and λ = 1,
which represent, respectively, a LAN, WAN and an inter-
mediate network conﬁguration [17].
Our main performance metric was the kth-smallest de-
cision time. By setting k to {1, n, f + 1}, we estimated
the ﬁrst, last and f + 1 smallest consensus decision times.
These values represent the best (k = 1), worst (k = n) and
the time required to be sure that at least one correct process
has decided (k = f + 1).
The scenarios used in the experiments were obtained by
combining w, x, the four PF D conﬁgurations and the three
network conﬁgurations, resulting in 240 scenarios. We exe-
cuted one experiment for each scenario. Every experiment
consisted in running 28, 800 sequential consensus with fre-
quency of one consensus after each 1, 000ut. Then, the per-
formance metrics used were related to the mean of the kth-
smallest decision times of all 28, 800 consensus executed
the mean of the 1st-smallest, the
in each experiment, i.e.
3rd-smallest and the 5th-smallest decision times. Note that,
there is one random variable in the execution of the HMMR-
consensus which is related to the probabilistic behavior of
the failure detection service. By running 28, 800 consensus
it was possible to reach 99% of conﬁdence level in the mean
decision times calculated2.
It was observed that the results for the three network con-
ﬁgurations (λ = 0.1, 1, 10) follow the same pattern and lead
to the same conclusions. Thus, without loss of information,
we will discuss the performance of the HMMR-consensus
considering the results for λ = 0.1.
4.2 Simulation Results
The analysis of the simulation results is subdivided into
two parts. First we consider only the conﬁgurations where
the window mechanism is not used (w = 1). Then we ana-
lyze the remaining conﬁgurations.
4.2.1 Impact of the Decision Pattern without Simulta-
neous Round Participation
The Baseline Conﬁguration. A distinguished conﬁgura-
tion, represented by w = 1 and x = 2, is of special interest
for us. We call it the baseline conﬁguration. It corresponds
to a slight optimization of the CT-consensus [2].
In the classical CT-consensus, during the ﬁrst phase of
a round r + 1, all the processes send their current estima-
tion of the decision value to the coordinator. In the code
of the baseline conﬁguration for HMMR-concensus this ex-
change is done at the end of the previous round r [8]: an
acknowledgment message is simultaneously sent to both
the coordinator of the current round and the coordinator of
the next round (by construction, in the baseline conﬁgura-
tion, this two particular processes are necessarily the two
elements of the decision set X). Compared to the classi-
cal CT-consensus, this difference is barely noticeable ex-
cept perhaps when one consider the coordinator of round
r: the sending of its estimation done normally at the begin-
ning of round r + 1 is now done during round r before it
2This conﬁdence level were calculated considering one experiment
with w = 1, x = 2 and PF D = 20%. Moreover, we have used the
maximum error of 2% of the mean value. This scenario represents the
worst one among those analyzed.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:38:39 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007gathers acknowledgment messages related to round r. Due
to this minor difference, the baseline conﬁguration is pre-
sented as a slight variation of the CT-consensus that never-
theless exhibits similar behaviors and performances to that
of the original protocol.
A study of the baseline conﬁguration conﬁrms that a
degradation of the QoS of the failure detector has a no-
ticeable impact on the performance of the protocol. For
example, we observe a performance degradation to get the
1st-smallest decision of as much as 33.4% for the baseline
conﬁguration, when worsening PF D from 0% to 20% (see
line 1 of Table 1)3. These results are in accordance with
other results presented in previous studies [6]. Moreover,
the choice of a particular metric among the 3 possible ones
(kth-smallest decision time with k ∈ {1, f + 1, n}) has also
a non-negligible inﬂuence on the decision time. Thus, with-
out varying the parameters x and w, we already observe that
the performance of the protocol is affected by the two ex-
ternal factors considered during all our evaluation (i.e., the
selected metric and the QoS of the failure detector).
x w
2
3
4
5
1
1
1
1
1st-smallest
33.4%
36.8%
38.8%
41.3%
performance degradation
3rd-smallest
26.2%
27.2%
28.8%
30.0%
5th-smallest
21.5%
23.4%
24.9%
25.3%
Table 1. Performance degradation when
worsening the QoS of the failure detector
from 0% to 20%
Other Conﬁgurations of the Decentralized Decision Pat-
tern without Simultaneous Round Participation. While
keeping the value of w equal to 1, we now increase the value
of x from 2 to n. Our results show that no matter the con-
sidered metric, the performance degradation of these con-
ﬁgurations when worsening PF D from 0% to 20% are al-
ways worse than those observed in the case of the baseline
conﬁguration (see Table 1). This result is mainly due to
the fact that the HMMR-consensus has been designed to be
used with a window mechanism. In particular, the condition
evaluated to start the next round is as weak as possible: be-
ing aware of the value proposed by the current coordinator
pc is a sufﬁcient condition for a process pi (cid:3)= pc to start the
next round. Stating a weak condition allows to start quickly
the simultaneous participation to the w ﬁrst rounds. When
3Given the performance values v1 and v2, v1 can be either better
(v1  v2) than v2. The corresponding percentual
gains/losses are obtained by the formula: (v2 − v1) ∗ 100/max(v2, v1),
where max(v2, v1) is the maximum value between v2 and v1. Such for-
mula was used to calculate the percentual performance results shown in
this paper.
w = 1, the start of round r + 1 and the end of round r al-
ways coincide. Thus, adding new processes in the decision
set has no interest. Indeed a new element in the set X will
never receive a majority of positive acknowledgments be-
cause it is allowed to switch to the next round (and forget
the current round) as soon as it receives a ﬁrst positive ac-
knowledgment. As increasing the value of x has an impact
on the contention, the performance is decreasing while the
value of x increases.
The adoption of a decentralized decision pattern always