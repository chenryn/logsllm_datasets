dealing with protected trusts; instead, it keeps a table of domain keys to answer the adversary’s
challenge queries (i.e., at this point the domain keys are still encrypted in domain tokens, but
domain tokens for protected trusts are never explicitly decrypted). To prove this hop we formalize
an invariant (c.f. Appendix C) that establishes an equivalence between honest trusts and protected
trusts occurring in the game, and further demonstrates that all trusts installed in genuine hosts
are protected. This invariant also implies consistent management of the same key for each handle,
which is necessary for indistinguishability-based security as mentioned above.25
At this point in the proof we can rely on the security of the multi-recipient encryption scheme
to replace the domain keys encrypted in protected domain tokens with ﬁxed constants. It is crucial
that there is a strict separation between protected trusts and dishonest trusts, since the reduction
to the security of the encryption scheme critically relies on the fact that one can use the left-or-right
challenge oracle for public-key encryption to emulate the encryption of domain keys in protected
domain tokens in both games. Intuitively, genuine HSMs map to the (honest) public keys in the
multi-recipient public-key encryption game. CCA security of the underlying encryption scheme
permits dealing with arbitrary InsideR queries, where one needs to decrypt ciphertexts contained
in domain tokens mauled by the adversary.
The ﬁnal step in the proof shows that, at this point, the adversary’s view is independent of the
domain key values and hence it has no advantage in winning the last game.
We conclude this section with the statement in EasyCrypt of the resulting security theorem.
The indistinguishability advantage is upper-bounded by the probability that an adversary can
break the domain management policy invariant (upper-bounded in lemma domain management in the
previous subsection), the probability that an adversary breaks the underlying signature scheme,
and the probability that an adversary breaks the underlying multi-recipient public-key encryption
scheme. Additional negligible terms account for the probability that the signing keys of honest
parties collide with keys that an adversary generates itself and uses as identities for adversarially
controlled operators and HSMs.
Pr[KMS RoR(A).main():res] ≤
1 / 2 + AdvAdvMRPKE(A)
MRPKE
+ Pr[CR(AdvCR(A)).main():res] +
q ops ∗ Pr[UF1op(AdvUF1op(A)).main():res] +
q hid ∗ Pr[UF1hsm(AdvUF1hsm(A)).main():res] + 
where
AdvD
Pr[MRPKE.Sec(D).main(false):¬res] − Pr[MRPKE.Sec(D).main(true):res]
 = q hid ∗ ((q hid + q tkmng + q tkmng) ∗ max size) / n keygen +
MRPKE =
q ops ∗ (((q tkmng + q installinitial) ∗ 2 ∗ max size) / n keygen)
6 EasyCrypt usage and extensions
The EasyCrypt development consists of 15K lines of code (loc), where 500 loc correspond to the
protocol speciﬁcation. Additionally, 2.5K loc establish reusable deﬁnitions and supporting lemmas
on standard cryptographic primitives and EasyCrypt data structures; 5.5K loc contain deﬁnitions
and general results on KMS-speciﬁc security models; and 6.5K loc is the approximate size of the
main security proof.
25 To complete this hop we made explicit a property that is implied by the unforgeability of digital signatures, and
which states that no adversary can guess the signing key of a genuine entity before it is generated. This allowed us
to show that any trust that was declared by the game to be dishonest remains dishonest even after a new identity
key is generated.
21
The core logics of EasyCrypt proved to be expressive enough and no exensions to these logics
were needed to complete the proofs. However, for convenience during the development, we intro-
duced a few new features that helped reduce the proof eﬀort resulting from the unprecedented
scale of this project. These new features do not enlarge the Trusted Computing Base (TCB) of
EasyCrypt, which is composed of a set of base tactics deﬁning the EasyCrypt core logics. Indeed,
all the added features generate internal proof trees that only rely on the core tactics. Hence, no bug
in the added features could lead to the acceptance of an invalid proof tree: this would be rejected
by the TCB.
Management of pre- and post-conditions Several core tactics require users to provide intermediate
assertions, e.g. loop invariants. When dealing with complex programs and speciﬁcations, writing
such intermediate assertions becomes cumbersome and error-prone. However, in a majority of cases,
these assertions can be expressed with little work from the current pre- and post-conditions (which
tend to grow in size). We added the possibility to match sub-formulas that appear in the current
proof goal and use these sub-formulas for new assertions. Doing this greatly decreases the proof
writing eﬀort and makes the proof script more robust, as the new assertion is given as a delta from
the active proof goals. It also provides more readable proof goals.
Proof automation Several core tactics of EasyCrypt generate proof obligations that code is lossless,
i.e. that it terminates with probability 1. We have implemented heuristics to deal with such goals
automatically.
We have also improved existing automation to chain applications of core tactics, and tuned
the implementation of some core tactics. In particular we have integrated an automatic version
of the frame rule, which removes parts of the post-condition that are immediately implied by the
pre-condition.
7 Lessons learned
In addition to producing the machine-checked speciﬁcations and security proofs for KMS DMP
that we described in this paper, this project was also an oportunity to better understant the
challenges posed by larger-scale developments to computer-aided cryptographic provable security,
and particularly when using EasyCrypt. We now give an overview of the main take-away lessons we
got from the project.
Imperative vs Functional speciﬁcation One of the strong points of EasyCrypt is that there is a
great deal of freedom in choosing how to formalize cryptographic primitives and security games. As
security models become more intricate, a crucial decision is how to model the keeping of state, as
there is usually a tension between game readability and the complexity of proof goals/invariants.
Favouring game readability means using EasyCrypt’s imperative language as much as possible
to describe the step-by-step actions that occur in each oracle call. This means using a dedicated
EasyCrypt module to syntactically distinguish the behaviour of each entity (or type of entity) in the
system, keeping each part of the game state as a separate local variable in the correct submodule,
and using if and while statements to deal with control-ﬂow. The consequence of this is that the top-
level program that describes the security experiment displays a very complex control-ﬂow, which
makes proving the equivalences required for game-hopping harder (in particular because game hops
typically require addressing particular cases that introduce additional branching points).
The alternative is to ﬂatten the speciﬁcacions of security experiments by collapsing the mod-
ule structure and moving as much of the detail as possible to EasyCrypt operators (functional
22
speciﬁcations of deterministic state transitions). This makes the speciﬁcations less readable, but
it naturally provides a slicing between probabilistic statements, which model the cryptographic
operations and associated control-ﬂow (e.g., branching on a signature veriﬁcation result) that are
usually the crucial program actions in indistinguishability and bad-event hops, from branching and
iteration statements that are only modeling state management operations (e.g., checking syntactic
validity of a message and deciding where it should be dispatched).
In this project we have used both approaches and, in hindsight, the conclusion is that starting
with a readable model that can be checked for soundness more easily and then ﬂattening it as a
ﬁrst game hop is often the best choice.
Modular proofs using global invariants A related issue in managing proof complexity is identifying
early on the abstraction boundaries that allow decomposing the proof into treatable self-contained
intermediate goals. For some cases this is straightforward to do, namely for sub-components in the
protocol that cryptographers naturally see as building-blocks (e.g., a signature service or a global
hash function) that give rise to simple and well-understood global invariants in the security games.
However, in this project we encountered protocol-speciﬁc semantically rich global invariants that
permit (once correctly identiﬁed and formalized) not only to break the proof down into manageable
subgoals, but also to simplify the top-level proof. Intuitively, we achieved this by: i. ﬁrst specifying
invariant I = I1∧ I2∧ I3 . . . globally in, say game Gi; then ii. reducing the preservation of I in game
Gi to a bad event occurring in a simpler ﬂattened game, where the probability of bad is bounded
at much lower cost; and iii. jumping to game Gi+1 where the preservation of I is hardwired as
checks of (and sometimes branching on) some sub-formula Ik directly in the code, where needed.
The challenge here is to pin down the minimal use of Ik in the new game, so that the invariant does
not need to be reproved, while keeping Gi+1 as simple as possible in order to complete the proof
more easily. As a side result of this design pattern, which we believe it is interesting to generalize
in future work, game Gi+1 now syntactically displays only the relevant parts of the established
invariant in its code, which makes it easier to understand the context for each proof goal.
Proof eﬀort Overall, from a rough analysis of the proof eﬀort involved in this project our intuition
is that the resources required to complete game hopping proofs by experienced EasyCrypt users,
once the games and security invariants are correctly speciﬁed (and following good practices, some
of which were highlighted above) scales “linearly with the complexity” of the programs/games,
similarly to functional equivalence proofs between programs with a reasonably close, if not identical,
control-ﬂow.
8 Related Work
There has been signiﬁcant work on the formal veriﬁcation of cryptographic API, and in particular
on PKCS tokens.
Delaune, Kremer, and Steel [16] model tokens as security protocols with a sole party, and
apply Dolev-Yao veriﬁcation methods to analyze their security. Bortolozzo, Centenaro, Focardi and
Steel [12] build an automated tool for model checking the security and functionality of tokens, and
evaluate commercially available PKCS tokens. They discover several security issues and validate
patches.
Cachin and Chandran [13] formalize computational security of cryptographic APIs, and show