both untrusted and trusted inputs. Untrusted inputs are
the well-known sources of injection possibilities such as
HTML form ﬁelds, HTML headers, query strings, cook-
ies, etc. Trusted inputs are often read from conﬁguration
ﬁles, trusted databases, etc. Note that the notion of what
is trusted and what is not is often not clear-cut. Section 3.1
describes how ScriptGard addresses this problem. Next,
we deﬁne what it means for a program to properly sanitize
its inputs.
Deﬁnition 7. A server-side program P : I → O deﬁnes
a relation from untrusted user inputs I to output string
O. The program interprocedural data ﬂow graph is a graph
(cid:104)N ,E(cid:105) with designated sets of nodes
(cid:104)Src, Snk , San(cid:105) ⊆ (cid:104)N × N × N(cid:105)
where Src are the sources that introduce an untrusted in-
puts in P, Snk are the sinks that write strings to the output
HTTP stream, and San are the sanitizers used by the pro-
gram.
Without loss of generality, we assume that sink nodes ei-
ther write untrusted strings to the output stream or trusted
strings, but never strings containing both.
Sink opera-
tions with mixed content can be translated to an equiv-
alent dataﬂow graph with only exclusively trusted or un-
trusted sink nodes using sink node splitting: the output
of a mixed string Snk(q1 + q2 + ··· + r1 + . . . qn) can
be split into a sequence of exclusive sink writes Snk(q1),
Snk(q2) . . . , Snk(r), . . . , Snk(qn).
Deﬁnition 8. An untrusted execution trace t of program
P is a sequence of executed nodes
(cid:126)t = n1, . . . , nk ∈ N
such that n1 ∈ Src, nk ∈ Snk .
Deﬁnition 9. Let t be an untrusted execution trace (cid:126)t =
n1 . . . nk and let (cid:126)f = f1, . . . , fm be a sequence of sanitizers
such that f1, . . . , fm is a subsequence of n2, . . . , nk−1.
For all inputs I, let O be the total output string just before
the execution of the sink node in (cid:126)t. We say that trace (cid:126)t is
properly sanitized if O induces context C and ψ(C) = (cid:126)f .
In other words, for all possible trace executions, we require
that the proper set of sanitizers be applied on trace for the
expected parsing context. Note that trusted traces are al-
lowed to change the browser context. A common example
of that is
output.WriteLine("");
where each string is a sink and the ﬁrst and third lines cor-
respond to browser state transitions.
Theorem 1. If untrusted trace (cid:126)t is properly sanitized, as-
sume the browser has read string O which induces context C.
Then reading the rest of the string output produced by (cid:126)t can-
not induce any contexts C(cid:48) (cid:54)= C.
Proof: Let input I = [IP ◦ IN P ]. By Deﬁnition 9, for all
input-output pairs IP → O, (cid:126)t contains sanitizers (cid:126)f correct
for any context C inducible by O. By Deﬁnition 6, we know
that applying (cid:126)f to the remainder of the input INP cannot
leave context C.
607For reasons of correctness, we wish to ensure that all un-
trusted execution traces are properly sanitized.
Deﬁnition 10. A server-side program P is properly sani-
tized if for every untrusted execution trace (cid:126)t of P, (cid:126)t is prop-
erly sanitized.
As an obvious corollary, if the program is properly san-
itized, then no untrusted input to the server program can
force the browser to change its context.
5.
IMPLEMENTATION DETAILS
We now describe our implementation in more detail, with
reference to the ASP.NET framework. This section ﬁrst
describes positive taint tracking implemented in Script-
Gard in Section 5.1, and then context inference and auto-
correcting runtime sanitization in Sections 5.2 and 5.3.
5.1 Positive Taint Tracking
Immutable objects,
We describe our full implementation for positive taint
tracking for strings in the .NET platform. The .NET run-
time supports two kinds of string objects: mutable and
immutable objects.
instances of the
System.String class, are called so because their value cannot
be modiﬁed once it has been created [23]. Methods that ap-
pear to modify a String actually return a new String con-
taining the modiﬁcation. The .NET language also deﬁnes
mutable strings with its System.Text.StringBuilder class,
which allows in-place modiﬁcation of string values; but all
access to the characters in its value are mediated through
methods of this class [24]. In essence, all strings in .NET
are objects, whose values are accessed through public meth-
ods of the class — the language does support a primitive
string type but the compiler converts string type to the
String object and uses class methods whenever the value of
a primitive string type is manipulated.
Using the encapsulation features oﬀered by the language,
we have implemented the taint status for each string object
rather than keeping a bit for each character. The taint sta-
tus of each string object maintains metadata that identiﬁes
if the string is untrusted and if so, the portion of the string
that is untrusted. Our implementation maintains a weak
hash table for each object, which keys on weak references to
objects, so that our instrumentation does not interfere with
the garbage collection of the original application objects and
scales in size. Entries to freed objects are therefore automat-
ically dropped. Taint propagation, capturing direct data de-
pendencies between string objects, is implemented by using
wrapper functions for all operations in string classes. Each
wrapper function updates the taint status of string objects
at runtime.
We use CCI Metadata [34], a robust static .NET binary
rewriting infrastructure to instrument each call to the string
object constructors with taint propagation methods. The
.NET language is a stack-based language and CCI Meta-
data provides the ability to interpose on any code block and
statically rewrite it. Using this basic facility, we have imple-
mented a library that allows caller instrumentation of spec-
iﬁed functions, which allows redirection of original method
calls to static wrapper methods of a user-deﬁned class. Redi-
rection of virtual function calls is handled the same way as
static calls with the exception that the wrapper function ac-
cepts the instance object (sometimes referred to as the this
parameter) is received as the ﬁrst argument to the wrapper
function.
Soundness Considerations: We explain how our positive
taint implementation is sound, i.e., does not miss identifying
untrusted data, with exception identiﬁed in point 5 below.
We show that this exception are rare in our test program.
1. The language encapsulation features provide the guar-
antee that all access to the string values are only per-
mitted through the invocation of methods deﬁned in
the string classes.
2. All constant strings belong to the immutable string
primitive type. Any modiﬁcation to the primitive
value by the program is compiled to a conversion to an
object of the string class, which invokes the string class
constructors. Thus, we can safely track all sources of
taint by instrumenting these constructors.
string
classes
3. The
System.String
and
System.Text.StringBuilder are both sealed classes;
that is, they cannot be inherited by other classes.
This eliminates the possibility that objects that we do
not track could invoke methods on the string classes.
4. Conversion between the two string classes is possible.
This involves the call to the Object.ToString generic
method. Statically, we instrument all these calls, and
use .NET’s built-in reﬂection at runtime to identify if
the dynamic instance of the object being converted to
a string and perform the taint metadata update.
5. String class constructors which convert values from
non-string types are treated as safe (or positively
tainted) by default. This is because we do not cur-
rently track taint status for these types. In principle,
this is a source of potential unsoundness in our imple-
mentation. For example, the following code will lead
our tracking to treat untrusted data as trusted:
String untrusted = Request.RawUrl;
var x = untrusted.ToCharArray();
....
String outputstr = new String(x);
httpw.Write(outputstr);
Fortunately, these constructors are rare in practice.
Figure 11(a) shows the distribution of functions in-
strumented by ScriptGard. The key ﬁnding is that
potentially unsound constructions occur only in 42 out
of 23,244 functions instrumented for our application.
Our implementation ignores this source of false neg-
atives presently; we can imagine verifying that these
do not interfere with our needs using additional static
analysis or implement more elaborate taint-tracking in
the future.
Output: The result of ScriptGard’s analysis is three
pieces of information. First, ScriptGard marks the por-
tion of the server’s output which is not positively tainted.
The untrusted texts are delimited using special markers con-
sisting of characters that are outside the alphabet used by
the application legitimately. Second, for each string writ-
ten to the HTTP output stream, it records the sequence
of propagators (such as string concatenation, format-string
based substitution) applied on the output text fragment.
In essence, this allows ScriptGard to (a) separate strings
608that are used for constructing HTML output templates from
other strings, and, (b) identify the propagator that places
the untrusted data into an output template. Third,
it
records a path string identifying the control ﬂow path lead-
ing to each HTML output sink operation.
In addition to the above information, ScriptGard gath-
ers the sequence of sanitizers applied to a given untrusted
data. To do this, each sanitizer is instrumented similarly
to surround the input data with additional special markup
identifying that sanitizer’s application to the input data.
The knowledge of the untrusted data along with the nest-
ing of sanitizers is thus encoded in the HTML output of the
server. This output is then subject to the context inference
step, which is described next.
5.2 Context Inference
For a given analyzed path the server outputs a HTML re-
sponse encoding the information identifying sub-strings that
are untrusted, as well as, the sequence of sanitizers applied.
ScriptGard employs a web browser to determine the con-
texts in which untrusted data is placed, in order to check
if the sanitization sequence is consistent with the required
sequence.
In our implementation, we use an HTML 5 compliant
parser used in the C3 browser, that has been developed from
scratch using code contracts to be as close to the current
speciﬁcation as possible. It has a fast JavaScript engine as
well. The parser takes an HTML page as input. In the page,
untrusted data is identiﬁed by special markup. The special
markup is introduced at the server’s output by our positive
taint-tracking.
We augment the HTML parser to track the sequence of
browser contexts in which data marked as untrusted ap-
pears. In our implementation for HTML, we treat each con-
text to be (a) the state of the lexer (as deﬁned in the HTML
5 draft speciﬁcation), (b) the stack of open elements (as de-
ﬁned in the HTML 5 draft speciﬁcation), and (c) speciﬁc
information about the local state of the parse tree (such as
the name of current tag or attribute being processed).
We apply techniques similar to string accenting for track-
ing untrusted data in other contexts [6]; DOM nodes that
correspond to untrusted data are also marked. Similar con-
text tracking is applied for the JavaScript parser. For the
policy of our applications and the policies identiﬁed in pre-
vious work [20], we have found this level of tracking to be
adequate.
Using context information, ScriptGard decides the cor-
rect sequence of sanitizers to apply for a given untrusted ex-
ecution trace. To determine the correct sanitizer sequence,
ScriptGard applies for each context in the trace, in the
nesting order, the appropriate sanitizer from the input san-
itization speciﬁcation. The inferred chain of sanitizers is
guaranteed to be correct for the trace, eliminating multi-
ple sanitization errors that could have resulted from manual
placement.
5.3 Runtime Sanitization Auto-Correction
During analysis or training, for each untrusted trace writ-
ing to sink operation S, ScriptGard records the static pro-
gram path by proﬁling. It also record the ﬁrst propagator P
in the dataﬂow computation, typically a string concatena-
tion or format-string based string substitution, that places
the untrusted data inside the trusted output string emit-
Figure 6: Distribution of DOM sizes, in nodes, across our training
HTML pages.
HTML Sink Context Correct sanitizer that suﬃces
HTMLEncode, SimpleTextFormatting
HTML Tag Context
Double Quoted Attribute HTMLAttribEncode
Single Quoted Attribute
HTMLAttribEncode
URL Path attribute
URLPathEncode
URL Key-Value Pair
URLKeyValueEncode
In Script String
EcmaScriptStringEncode
CDATA
HTMLEncode
Alpha − numerics
Style
Figure 7: Sanitizer-to-context mapping for our test application.
ted at S. ScriptGard instruments the deployed applica-
tion with a low-overhead runtime path detector. During
deployed operation, If the currently executing path is is in
the sanitization cache, ScriptGard sanitizes the untrusted
substring(s) in the output string using the following tech-
nique.
Rewriting untrusted output: ScriptGard maintains a
shadow copy of the untrusted data. If the path is not in the
sanitization cache, the actual value of the untrusted data is
used at output sink. If the path is in the sanitization cache,
the shadow copy is sanitized, then the results are output.
To do this, ScriptGard instrumentation-based program
transformation for maintaining shadow copies for each un-
trusted trace computation. Each untrusted trace computa-
tion is essentially a sequence of string propagator operations
like string concatenation and format-string based substitu-
tion writing at a sink S. At string propagators using un-
trusted inputs, the added instrumentation creates a shadow
copy of the untrusted data, and delimits it with special
markup. At S, if the path executed is in the sanitization
cache, the added instrumentation strips the actual value and
markup out, applies the sanitization on the shadow copy,
and writes it to the output stream. Finally, at S, if the path
is not in the sanitization cache, the instrumentation strips
the shadow value out and writes the actual value to the out-
put stream leaving the application behavior unchanged for
such paths.
6. EVALUATION
Our evaluation focuses on a large legacy application of
over 400,000 lines of server-side C# code. We accessed 53
01002003004005006007008009001,000Doc 5MPMeet 1Dmeet 2Social 2Dmeet 8Tsite 4Tsite 5Dmeet 7Doc 6Tsite 9Blog 7Tsite 10Tsite 7Dmeet 6MPMeet 6Dmeet 10Doc 9Tsite 1Dmeet 9Social 4Social 5Social 9Tsite 8Doc 3Social 6Social 3Tsite 3MPMeet 5Social 7Blog 9Tstite 6MPMeet 3MpMeet 4Blog 2Dmeet 4Tsite 2Social 8Social 1MpMeet 2Doc 8Doc 10Dmeet 5Blog 8Social 10Blog 6Doc 7Doc 2Dmeet 1Doc 1Blog 1Dmeet 3Blog 3Blog 4Doc 4Blog 5System Builtin ControlsDOM Nodes6096.1 Analysis Results
Context-mismatched sanitization: Figure 9 shows that
ScriptGard exercised 25,209 paths on which sanitization
was applied. Of these, 1,558 paths (or 6.1%) were improp-
erly sanitized. Of these improperly sanitized paths, 1,207
( 4.7% of the total analyzed paths) contained data that
could not be proven safe by our positive taint tracking infras-
tructure, so therefore are candidates for runtime automatic
choice of sanitization. The remaining 1.4% of paths were
sanitizing trusted strings improperly; ScriptGard does not
consider these to be safe, therefore they do not need runtime
correction.
We used Red Gate’s .NET Reﬂector tool, combined with
other decompilation tools, to further investigate the execu-
tions which ScriptGard reported as improperly sanitized.
Our subsequent investigation reveals that errors result be-
cause it is diﬃcult to manually analyze the calling context
in which a particular potion of code may be invoked. In par-
ticular, the source and the sink may be separated by several
intervening functions. Since ScriptGard instruments all
string operations, we can count how far sources and sinks
are removed from each other, as shown in 11(b).
In Fig-
ure 10, we graph the distribution of these lengths for a ran-
domly selected sample of untrusted paths. This shows that
a signiﬁcant fraction of the chains are long and over 200 of
them exceed 5 steps.
Our data on the length of def-use chains is consistent with
those reported in previous static analysis based work [18].
As explained in Section 2, the sharing of dataﬂow paths can
result in further ambiguity in distinguishing context at the
HTML output point in the server, as well as, in distinguish-
ing trusted data from untrusted data. In our investigation
we observed the following cases:
• A single sanitizer was applied in a context that did
not match. Typically, the sanitizer applied was in a
diﬀerent function from the one that constructed the
HTML template. This suggests that developers may
not fully understand how the context — a global prop-
erty — impacts the choice of sanitizer, which is a local
property. This is not surprising, given the complexity
of choices in Figure 7.
• A sanitizer was applied to trusted data (on 1.4% of the
paths in our experiment) We still report these cases
because they point to developer confusion. On further
investigation, we determined this was because sinks
corresponding to these executions were shared by sev-
eral dataﬂow paths. Each such sink node could output
potentially untrusted data on some executions, while
outputting purely trusted data on others.
• More than one sanitizer was applied, but the applied
sanitizers were not correct for the browser parsing con-
text of the data1.
Inconsistent Multiple Sanitization: We found 3,245
paths with more than one sanitizer. Of these, 285 (or 8%)
of the paths with multiple sanitization were inconsis-
tent with the context.
fell
into two categories: ﬁrst, we found 273 instances with
The inconsistent paths
1Errors where the combination was correct but the or-
dering was inconsistent with the nested context are reported
separately as inconsistent multiple sanitization errors.