in a password by monitoring the target application execution
time (e.g., xlock) when a keystroke event is received: a long
execution time indicates the modiﬁed key was typed by the
victim and a short execution time implies its absence. This
process is repeated for each key in the key map or until all
the keys in a password have been identiﬁed. However, this
intentionally causes the wrong character to be typed, possibly
alerting to the victim to the presence of the attack.
220
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:29:41 UTC from IEEE Xplore.  Restrictions apply. 
3) Memory Footprint: Cache attacks leverage the nearly-
ubiquitous design of shared cache and memory to detect the
use of speciﬁc memory addresses by a target application. An
attacker can discern which locations are or are not accessed by
a target application by measuring the time it takes to access
a speciﬁc address mapped to the same cache set. There are
several variations of this general approach in which the cache
set is primed by the attacker before invoking (or waiting for)
the target application and then later probed to measure latency
[77]. Since cache attacks can detect which memory locations
are accessed, as opposed to just CPU load, they can be used
as a spatial side channel and potentially determine which keys
were pressed. Such is the approach of the cache-hit ratio
template that characterizes which addresses are frequently
accessed by a target library or binary for each key [7]. Even
the row buffer in DRAM, which acts as a kind of cache, is
susceptible to this type of attack [66].
4) USB Crosstalk: Unlike radiative coupling, capacitive
coupling exploits the undesirable transfer of energy between
electrical components in close proximity. The keyboard state,
transmitted in 8-byte frames using NRZI encoding (see Sec-
tion II-D),
is clearly visible to neighboring USB devices
through both the data and power lines [67]. Using relatively
simple signal processing techniques, a malicious USB device
is capable of eavesdropping on upstream USB 1.x and 2.0
trafﬁc from neighboring devices connected to the same hub.
D. Attack the Network
The client-server programming model has come to domi-
nate web-based interactive applications. Although many web
applications utilize encrypted communications, most do not
take any measure to obfuscate the communication patterns
that manifest. This is especially problematic for applications
that wait for user input, as each network packet itself may
correspond to a keystroke revealing both the key press time
of the victim and the payload size of the server response.
1) Payload: In some cases, keystrokes can be identiﬁed
by the size of a response from the server in a web-based
application [68]. This affects applications that implement real-
time autocomplete suggestions, whereby each suggestion has
a unique size. As the server responds to each query consisting
of only a single keystroke, it provides a uniquely-sized list of
responses which yield considerable information gains.
2) Timing: Network timing attacks implicate a broad range
including those not
of real-time client-server applications,
susceptible to any form of payload analysis. As the victim
types in an otherwise idle application, the client emits bursts
of network trafﬁc which, to any listening adversary, can reveal
the key press timings of the victim. The key press latencies
can be used to either reconstruct the victim’s input from a
dictionary, or to guide a search in password cracking [8], [69].
There is, however, some debate as to whether this temporal
keylogging side channel is damaging in practice. The attacker
must be able to distinguish between network trafﬁc generated
by key presses and other unrelated trafﬁc. With background
trafﬁc, such a task may become impractical [78], [79].
E. Exﬁltration
Attackers face the additional problem of data exﬁltration
which, often neglected, can be more challenging than key-
logging itself. Methods of exﬁltration differ primarily based on
whether the attack was mounted on a device controlled by the
user (e.g., smartwatch or host computer) or the attacker (e.g.,
a microphone or antenna). The former scenario is especially
challenging since exﬁltration must be performed without alert-
ing the user to the attacker’s presence. So as to minimize the
risk of being detected, a covert channel may be established to
retrieve the logged keystrokes. Of particular note is JitterBugs,
a class of covert channels designed speciﬁcally for keystroke
exﬁltration [80]. JitterBugs establishes a covert channel by
modulating the keystroke timings themselves, which can later
be remotely detected over a network during an interactive
application. In a base-2 encoding scheme, each key press
transmits a single bit by aligning its time interval to a multiple
of some modulus m: time intervals close to 0 mod m are bit
0 and close to m
2 mod m are bit 1. This could be performed
either in software at the driver level, or in hardware as a
buffering device placed between the keyboard and the host.
V. DEFENSES
Completely eliminating some keylogging side channels has
proved to be an elusive goal [91], necessarily a consequence
of the difﬁculty to analytically describe any physical system
[92]. While protocols and design speciﬁcations may be built
deductively from a set of axioms, the physical components that
embody such a system are subject to noise, interference, and
unforeseen side effects. This leaves the possibility, however
small, that the system may not behave as intended. In this
sense, a keylogging side channel defense mitigates the possi-
bility of an attack under a speciﬁc set of assumptions, and not
in general. There are primarily three different approaches.
Impediment: A defense that restricts access to a sensor
or eliminates unwanted emanations can be said to impede
an adversary from observing the compromising signal. This
can be implemented digitally, such as through permissions-
based access control, or physically, such as by shielding or
suppressing the compromising emanations.
Obfuscation: Decreasing the signal-to-noise ratio can obfus-
cate the side channel, rendering a particular attack ineffective.
With this approach, an adversary may still observe the signal,
but the information content is too low for keystroke detection
and/or key identiﬁcation. Obfuscation can be achieved by in-
creasing background noise or decreasing the sensor resolution.
Concealment: The presence of superﬂuous information may
conceal the side channel from an adversary. With this ap-
proach,
intact but becomes in-
distinguishable from irrelevant overlapping signals aimed to
mask the true keyboard events, consequently making keystroke
detection much more difﬁcult. Since keystroke detection is a
prerequisite for key identiﬁcation, a defense that mitigates the
former is also generally effective against the latter. Like the
other approaches, concealment could be implemented digitally,
the original signal
is left
221
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:29:41 UTC from IEEE Xplore.  Restrictions apply. 
KEYLOGGING SIDE CHANNEL DEFENSES. DET=KEYSTROKE DETECTION, ID=KEY IDENTIFICATION.
TABLE III
Modality
Defense
r
e
s
U
d
r
a
o
b
y
e
K
EEG
EEG
Motion
Acoustic
Acoustic*
Acoustic*
EM Rad./Cap.
EM Rad.
EM Rad.
Induce covert responses to irrelevant stimuli
Filter keystroke-identifying features
Limit sensor permissions during typing
Reduce keyboard acoustic emanations
Keys produce homomorphic sounds
Emit synthetic keyboard sounds
Filter/shield EM emanations
Randomly delay matrix scan routine
Randomize matrix scan pattern
t CPU/Memory
s
o
CPU/Memory
H
.
t
e
N
HTTP
SSH/VoIP
Generate spurious key press/release events
Decrease timer resolution
Obfuscate packet size through padding
Randomly delay key press/release events
*Not including acoustic TDoA localization attacks.
by generating spurious keyboard events, or physically, such as
emitting synthetic keyboard sounds.
In addition to methodology, each defense in Table III is
characterized by the types of side channels they protect against
(spatial and/or temporal), whether they target keystroke detec-
tion and/or key identiﬁcation, and whether they produce any
noticeable side effects to the user, such as increased noise or
changes in application behavior.
A. Defend the User
Dynamic access control to emanating sensors on wearable
devices represents an effective defense that is transparent to
the user. Such a scheme could either limit sensor permissions
while the user is typing [51] or ﬁlter the features that permit
keystroke detection [71]. This form of impediment restricts
a malicious application from detecting the user’s keystrokes
without sacriﬁcing usability, although it requires the device to
reliably detect when the user is typing.
It might also be possible for a user to “trick” the device
by modifying their own behavior while typing as a form of
obfuscation. Wearing an EEG cap, this could be accomplished
by inducing covert responses to irrelevant stimuli, such as by
thinking of a different key than the key that is physically
pressed [71]. Some work in this area indicates that systems
using the P300 event related potential (ERP) for stimulus
detection can be defeated in this way [81], however EEG
key identiﬁcation likely leverages electromyogram (muscle)
artifacts induced by hand and eye movement [48].
B. Defend the Keyboard
Several defenses were adopted early on in response to
the TEMPEST threat, such as signal ﬁltering and protective
shielding, both aimed to impede EM emanations [3]. Ofﬁcial
EM radiation policies mandated a 200 ft perimeter to be se-
cured around vulnerable devices, a somewhat arbitrary choice
determined to be the largest manageable radius. Interestingly,
they also suggested that operating at
least 10 devices in
parallel could instead be used as a form of concealment
[2], in the same spirit as some host-based defenses recently
Method
Obfuscate
Impede
Impede
Impede
Obfuscate
Conceal
Impede
Obfuscate
Obfuscate
Conceal
Obfuscate
Obfuscate
Obfuscate
Target
ID
DET
DET
DET
ID
DET
DET
DET
ID
DET
DET
ID
ID
Channels Protected
S1
T










S2


















Noticeable
to User?
Ref.
[71], [81]
[71], [82]



[9], [83]
[3], [84]
[51]
[54]
[54]
[85]
[86]
[10]
[87], [88]



Maybe
[68]
[89], [90]
developed, e.g, KeyDrown [10]. For commodity keyboards,
ﬁltering the high frequency emissions of matrix scanning
may suppress the EM spike that enables column identiﬁcation
[84]. Likewise, randomizing the scan pattern [86] or inserting
random delays into the digitization routine [85] would mitigate
column identiﬁcation and keystroke detection, respectively.
The three different approaches to mitigation (impediment,
obfuscation, and concealment) are well captured by the various
acoustic defenses. As a form of impediment, a completely
“quiet” keyboard, one that emits no acoustic emanations,
would prevent all kinds of acoustic attacks despite having a
noticeable effect of lacking auditory feedback [54]. Instead,
a keyboard that obfuscates key acoustics by producing a
homogeneous sound for each key would make key identiﬁ-
cation difﬁcult, although such a device may be difﬁcult to
fabricate [54]. This approach is also not effective against
multi-mic TDoA localization attacks which do not make use
of individual key acoustics. Finally, concealment could be
achieved by emitting spurious keystroke sounds in proximity
to the user during typing [9], [83], however also potentially
failing against TDoA localization attacks if signal separation
can be performed based on source location.
C. Defend the Host
Given the number and complexity of shared resources
on modern computing devices (CPU, memory, etc.), host-
based attacks, especially those that leverage microarchitectural
side effects, are remarkably pervasive [93]. Decreasing timer
resolution can prevent some forms of keystroke detection, such
as those that detect spikes in CPU load [87], however there
remain numerous other side channels that can achieve the same
effect without explicit high-resolution timers [91].
A concealment-type defense may be more appropriate for
such attacks targeting the host. By generating many spuri-
ous keystrokes, which appear indistinguishable from the true
keystrokes, a user can evade keystroke detection by a malicious
application. This is the approach of KeyDrown, a three-
layer model that aims to protect against both CPU-load and
shared memory microarchitectural attacks targeting the kernel,
222
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:29:41 UTC from IEEE Xplore.  Restrictions apply. 
shared library, and application layers [10]. With relatively little
overhead, the artiﬁcial input events follow the same execution
path as the true keystrokes, degrading the practical detection
TPR to the point of random guessing.
D. Defend the Network
Padding represents a broad class of obfuscation-type de-
fenses against side channels that leverage network packet size.
However, where to pad (e.g., HTTP header vs body) and the
speciﬁc strategy that should be applied (e.g., padding to a
quantized length vs padding by random amounts) depends
on the particular application [68]. Given the wide range of
semantics in web application trafﬁc, compared to, e.g., SSH,
a general solution seems nontrivial.
Most network timing attacks, on the other hand, can be
prevented to a degree by introducing a small random delay
to the keyboard events by temporarily buffering the event
on the host or the keyboard itself [89], [90]. This random
delay obfuscates the actual time intervals between successive
keystrokes, effectively reducing the mutual information be-
tween the keystroke latencies and bigrams. The caveat is that
it also introduces an additional latency between the user and