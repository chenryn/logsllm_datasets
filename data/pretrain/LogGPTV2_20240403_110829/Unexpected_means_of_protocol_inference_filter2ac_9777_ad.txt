1.97
0.22
0.81
0.40
0.00
1.43
1.21
0.33
0.36
0.03
CSG
98.82
99.91
99.71
99.83
99.22
94.37
76.87
90.34
86.65
99.99
98.47
95.14
96.04
99.82
95.40
Table 2: Error, precision and recall rates of select protocols. The second column is the proportion
of the protocol in the entire trace. Trace key:  = Cambridge (226,046 ﬂows),  = Wireless
(403,752 ﬂows),  = Departmental (1,064,844 ﬂows).
three models (product distribution, Markov process, and CSG) are
at classifying ﬂows in a trace. We proceed in two phases. The ﬁrst
clustering phase accepts a training trace for training and produces
a deﬁnitive set of clusters for describing protocols in the trace. The
second classiﬁcation phase then labels the ﬂows in a testing trace
by associating them with one of the deﬁnitive clusters produced
in the ﬁrst phase. The purpose of this experiment is to simulate
the process by which a network administrator may use our system
— by ﬁrst building a set of clusters to describe distinct protocols
in the trafﬁc, and then using those clusters to construct classiﬁers
that recognize subsequent instances of the same protocols. Thus,
if the system functions as intended, it is sufﬁcient for the network
administrator to label an instance of each protocol and thereafter all
future trafﬁc will be labeled correctly. We describe the automated
phases of this experiment in more detail below.
7.2.1 Clustering Phase
Clustering is the process of producing a set of clusters (merged
cells) that succinctly describes the trafﬁc in a trace according to a
clustering metric. In the current implementation, this involves in-
serting the input trace into cells and merging cells according to host
contact patterns as described in Section 6. Then, the cell frame-
work promotes cells that meet the promotion threshold, and prunes
the rest from the cell table. In these experiments we promote cells
that contain at least 500 ﬂows. Afterward, we create a hierarchy of
cell merges using agglomerative clustering (described in Section 6),
and stop merging when the distance between all remaining clusters
is greater than the pre-speciﬁed merge threshold. The distance met-
ric is the weighted relative entropy for Product and Markov (Sec-
tion 4), and approximate graph similarity for CSGs (Section 5.2).
For our experiments, we set the merge threshold to 250 for Product,
150 for Markov, and 12% graph similarity for CSGs.
If more than one cell has a majority of ﬂows with a Protocol
X, then we include the cell with the largest number of Protocol X
ﬂows in the ﬁnal set of cells and delete the others where X is in
the majority. This accounting ensures that only one cell represents
a protocol, and makes this experiment more challenging. (Again,
recall that we apply labels to the ﬂows after merging.)
7.2.2 Classiﬁcation Phase
The goal of this phase is to associate each ﬂow from the test trace
with the cell that corresponds to the ﬂow’s protocol. To perform this
classiﬁcation, we take the clustered cells produced in Section 7.2.1,
classify each ﬂow with the protocol label of the closest matching
cell, and compute the classiﬁcation error rate.
7.2.3 Classiﬁcation Results
Table 1 summarizes the misclassiﬁcation rates for our framework
under the three protocol models. For each of the Cambridge, Wire-
less and Departmental traces, we trained on the ﬁrst half (in terms
of duration) and tested on the second half. “Total” error encom-
passes all misclassiﬁed ﬂows, including ﬂows belonging to proto-
cols that were absent from the training trace. “Learned” error rep-
resents the percent of all ﬂows that were misclassiﬁed and belonged
to a protocol present in the training trace. Finally, “unlearned” er-
ror is the percent of all ﬂows that belonged to protocols absent from
the training trace (not surprisingly, this last number stays consistent
across all protocols).
Overall, product distributions yielded the lowest total misclassi-
ﬁcation error across the traces (1.68–4.15%), while Markov Pro-
cesses had the highest (3.33–9.97%) and CSGs fell in the middle
(2.08–6.19%).
Table 2 presents misclassiﬁcation, precision, and recall rates for
select protocols within the three test traces. The product distribu-
tion model performed well over all protocols, particularly popu-
lar ones such as DNS, NTP, NBNS. This model beneﬁted strongly
from the presence of invariant protocol bytes at ﬁxed offsets within
the ﬂow. However, the largest number of misclassiﬁed ﬂows re-
sulted from false positive identiﬁcations for DNS. The precision
and recall numbers are high for DNS because it comprised the ma-
jority of ﬂows across the traces. Nevertheless, much of the misclas-
siﬁcation error came from binary protocols being misidentiﬁed as
DNS because of the uniformity of its byte-offset distributions (due
in part to its high prevalence).
The greatest weakness of Markov is misclassiﬁcation of binary
protocols such as NTP and NBNS. Unlike Product, Markov cannot
take advantage of information related to multiple byte offsets—
hence protocols that contain runs of NULL bytes, regardless of
their offset, are undesirably grouped together.
CSGs also struggled slightly with binary protocols that product
distribution successfully classiﬁed, such as NTP, but did best over-
all on SSH.
7.3 Unsupervised Protocol Discovery
The purpose of the protocol discovery experiment is to determine
whether we can use our technique to automatically identify new and
unknown protocols. Premise 3 suggests that new protocols will
emerge as clusters that are distinct from any known protocol. To
test this hypothesis, we perform the following experiment.
We split the trace into two equal parts, choose a protocol that
is present in both parts, remove it from the ﬁrst part, cluster both
halves independently, and then match clusters in the two halves
greedily. By greedily, we mean that the algorithm matches the
closest pair of clusters between the two halves, removes them from
consideration, and iterates on the remaining clusters. Finally, we
assign protocol labels to each of the clusters afterwards to evalu-
ate the effectiveness of the matching phase. Thus, if our system
works perfectly, it will correctly place the missing protocol into a
single homogeneous cluster that could then be labeled by the net-
work administrator. Unlike the classiﬁcation experiment we do not
eliminate multiple cells labeled with the same protocol.
We expect that clusters of the same protocol straddling the two
halves will match each other within the matching threshold. By
contrast, we expect the protocol that we withheld from the ﬁrst half
would stand out, i.e., the withheld protocol present in the second
trace would not have a close match from the ﬁrst half.
Table 3 shows the results of the protocol discovery experiment
over the two halves of the Departmental trace. We modeled pro-
tocols using product distributions, and withheld HTTP from the
ﬁrst half. The promotion threshold was 500 ﬂows per cell, and the
merge threshold was a weighted relative entropy of 250 (the same
parameters as the classiﬁcation experiment).
Our results indicate that there is a robust matching threshold for
which nearly all protocols from the ﬁrst trace match nearly all pro-
tocols from the second trace (covering 99% of all ﬂows), while
the new protocol is left unmatched. Speciﬁcally, the distance be-
tween the ﬁrst incorrectly matched cells (RTSP and the previously
excluded HTTP at 131.3) is three times larger than the distance be-
tween the last correctly matched cells (SNMP-SNMP at 44.5). An
unintentional result was that two protocols that were not present in
the ﬁrst half, RIPv1 and RADIUS, appeared in the second half with
a very distant match from the remaining cells of the ﬁrst half (more
than 300).
7.4 Classifying Excluded Trafﬁc
For the experiments in Sections 7.2 and 7.3, we used Ethereal as
an oracle to identify the protocols used by the ﬂows in the clusters
created by our models. Ethereal is not a perfect oracle, however,
and there were ﬂows that it could not identify, classifying them
generically as “TCP” or “UDP”. In the above experiments, we ex-
cluded those ﬂows from the analyses because we could not compare
clusters against a ground truth.
As a demonstration of the utility of our methodology for iden-
tifying ﬂows using unknown protocols, next we identify these ex-
cluded ﬂows. Speciﬁcally, we used product distributions to build
First Half w/o HTTP
Protocol
Cum. % Ind. %
Slammer
0.49
ISAKMP
0.58
NBNS
7.93
TFTP
0.65
DNS
60.87
SMB
0.85
SSDP
0.03
SNMP
0.82
SMTP
4.00
0.30
SMB
0.50 DCERPC
SNMP
0.10
BROWS.
0.96
Mssgr.
0.08
0.32
KRB5
DHCP
0.92
LDAP
0.13
SSL
6.87
0.08
SSL
0.91 YPSERV
0.11
SRVLOC
POP
1.50
0.19
SSL
SNMP
0.30
SSH
0.06
KRB5
0.05
0.04
IMAP
CLDAP
0.20
Syslog
0.06
NTP
8.10
NFS
0.15
SNMP
1.36
RTSP
0.06
0.30
SNMP
DAAP
0.12
0.49
1.07
9.01
9.66
70.52
71.37
71.40
72.22
76.22
76.52
77.02
77.12
78.08
78.15
78.47
79.39
79.52
86.39
86.47
87.39
87.49
89.00
89.19
89.49
89.55
89.60
89.64
89.85
89.91
98.01
98.16
99.52
99.58
99.88
100.00
Dist.
0.000
0.250
0.300
0.300
0.399
0.595
0.616
1.235
1.315
1.548
2.011
4.166
4.168
4.551
4.867
4.972
5.136
5.900
6.127
6.509
6.785
7.024
8.136
13.321
15.871
16.613
18.535
19.496
24.436
38.452
44.493
44.510
131.352
312.578
470.046
Second Half
Protocol
Slammer
ISAKMP
NBNS
TFTP
DNS
SMB
SSDP
SNMP
SMTP
SMB
DCERPC
SNMP
BROWS.
Mssgr.
KRB5
DHCP
LDAP
SSL
SSL
YPSERV
SRVLOC
POP
SSL
SNMP
SSH
KRB5
IMAP
CLDAP
Syslog
NTP
NFS
SNMP
HTTP
RIPv1
RADIUS
Ind. % Cum. %
0.43
0.87
7.99
8.41
64.87
65.59
65.62
66.42
70.41
70.68
71.15
71.24
72.06
72.49
72.78
73.56
73.67
79.39
79.43
80.25
80.35
81.58
81.65
81.93
82.00
82.03
82.08
82.23
82.29
89.13
89.18
90.40
99.87
99.89
100.00
0.43
0.44
7.12
0.42
56.46
0.72
0.03
0.80
4.00
0.27
0.47
0.09
0.82
0.43
0.29