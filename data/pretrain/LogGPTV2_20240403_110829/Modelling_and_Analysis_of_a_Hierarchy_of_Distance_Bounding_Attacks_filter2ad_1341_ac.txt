P
0
1
0
Note that the message received by PV uses the name p
rather than the challenge name a, hence, when using
preemption there is no way in which the answer to the
response to a timed challenge can be based on the mes-
sage outputted as part of that challenge.
1568    27th USENIX Security Symposium
USENIX Association
Rule (ASYNC) deﬁnes asynchronous communication,
which prevents processes from blocking when they are
ready to output. We could also avoid blocking by replac-
ing instances of out(M).P with out(M).0 | P, but intro-
ducing parallel composition reduces readability. More-
over, for purposes of compilation (Section 6), it is useful
to consider only linear processes.
4 Modelling DB protocols and attacks
We deﬁne distance bounding protocols as follows:
Deﬁnition 1 (Distance bound protocol speciﬁcation).
A distance bounding protocol speciﬁcation is a tuple
(P(id),V, ˜n), where
• P(id) = !new id.!Q for some process Q;
• V = !V(cid:48) for some process V(cid:48) that contains an event
• ˜n is a list of names known only to Q and V .
event(verify(id)).
We require that no further events are used in either pro-
cess and the only free names (i.e., names not declared as
new or bound by an input) used are those in ˜n and the
public channel c.
Process Q models a single run of a prover with the
identity id and P(id) represents arbitrarily many dis-
tinct provers, each of which can run arbitrarily many
times. Similarly, process V(cid:48) models a single run of
a veriﬁer and V models arbitrarily many runs. Event
“event(verify(id))” signiﬁes a successful execution of
the veriﬁer with a prover that uses identity id. Anony-
mous protocols can use a dummy id value. It is impor-
tant to note that the “verify” event does not mean that we
have veriﬁed that the protocol is secure, rather it means
that the veriﬁer believes it has completed a run of the pro-
tocol. This could be because there is a prover at the same
location as the veriﬁer, or it could be because an attacker
has performed a successful attack and tricked the veriﬁer.
The names ˜n are secrets known to the veriﬁer and all
provers; many well designed protocols will have no such
secrets, in which case ˜n will be the empty list, nonethe-
less many commercial devices continue to use global
shared secrets (see e.g. [22] for one of many examples).
Example 9. The protocol informally described in Ex-
ample 1 can be modelled as speciﬁcation (ProverE(id),
VeriﬁerE,(cid:104)k(cid:105)), where ProverE(id) and VeriﬁerE are as
described above, and k is the global shared key.
Since attackers can be present at a number of different
locations, we introduce system contexts as systems with
“holes,” in which a process may be placed. These holes
denote the locations in a system where the attacker can
act, and we write them as A. E.g., the system context
C1 = new k.[Veri f ierE | A ] | [ ProverE(id) | A ] repre-
sents a scenario in which the attacker can be co-located
with the veriﬁer V , and co-located with the prover Q,
whereas C2 = new k.[ Veri f ierE ] | [ ProverE(id) | A ]
represents a scenario in which the attacker is co-located
with the prover and is remote from the veriﬁer. When
the context is applied to a process the A symbol is re-
placed with that process, to give a system. E.g., C2[PA] =
new k.[ Veri f ierE ] | [ ProverE(id) | PA ].
Using our calculus, and system contexts, we can for-
mulate the ﬁve types of attacks against distance bounding
protocols described in Section 2, in which veriﬁers are
deceived into believing they are co-located with provers.
We formulate attacks as reachability requirements over
traces that represent executions of distance bounding
protocols. In particular, our formulations require an exe-
cution of a veriﬁer, with a remote prover, which ends in
a verify event for a particular id.
The following deﬁnition tells us if an attacker process
can be found that leads to a context performing a verify
event.
Deﬁnition 2. Given a name id and a system context C,
we write veriﬁed(id):C if there exists a process PA and a
trace:
{c},C[PA] −→∗ E, L ∪{[P ∪{new id.P}]r}
−→ E ∪{id(cid:48)}, L ∪{(cid:2)P ∪{P{id(cid:48)
/id}}(cid:3)
−→∗ E(cid:48), L (cid:48) ∪{[P(cid:48) ∪{event(verify(id(cid:48))).P(cid:48)}]r(cid:48)}
r}
where the only free name in PA is the public channel
name c and PA does not contain timers nor events.
It follows from our deﬁnition that veriﬁed(id):C denotes
a successful execution of a veriﬁer, therefore we would
expect it to hold for any context that places a veriﬁer and
prover, with the identity id, at the same location. By
comparison, we would not expect veriﬁed(id):C1, for the
aforementioned context C1, which places the veriﬁer and
prover at different locations, unless the protocol being
modelled is insecure.
Using this we can now formally deﬁne the different
types of distance bounding attacks.
Deﬁnition 3. Distance bound protocol speciﬁcation
(P(id),V, ˜n) is vulnerable to relay (or maﬁa) fraud, if
veriﬁed(id):new ˜n.[ V | A ] | [P(id) | A].
It follows from the deﬁnition that a relay attack is pos-
sible if the prover and veriﬁer are at different locations,
and an attacker process is co-located with each of the
prover and veriﬁer. Such an attack typically involves the
attacker process co-located with the veriﬁer answering
the timed challenges, using messages passed from the
other location. To keep our deﬁnitions simple we require
the same attacker process at both locations, though dif-
ferent parts of this process can act at each location. E.g.,
USENIX Association
27th USENIX Security Symposium    1569
an attacker process PPA | PVA might deﬁne process PPV
to interact with the veriﬁer and PAV to interact with the
prover.
Example 10. There is no process PA such that
veriﬁed(id):[ Veri f ierE | PA ] | [ProverE(id) | PA], i.e.,
no attacker can trick the veriﬁer into believing that it has
veriﬁed id when the provers are at a different location.
We informally reasoned why this protocol is safe from
relay attacks in Section 2 and we will verify this result
automatically in Section 7.
Relay/maﬁa fraud considers an attacker that does not
have the secret values of a normal prover. A more power-
ful “dishonest prover” attacker has access to such secrets.
Deﬁnition 4. Distance bound protocol speciﬁcation
(P(id),V, ˜n) is vulnerable to:
[ DP-A(id) ]
• distance fraud,
• distance hijacking,
P(id(cid:48)) ] | [ DP-A(id) ]
if veriﬁed(id) : new ˜n.[ V ] |
if veriﬁed(id) : new ˜n.[ V |
where P(id) = !new id.!Q and DP-A(id) denotes
!new id.out(id).Q(cid:48) | A, where Q(cid:48) outputs bound and free
names of Q (including names in ˜n, which are otherwise
hidden from the attacker) and the results of any private
function applications in Q, and A is the context hole.
The process DP-A(id) reveals all the secret values of a
normal prover to the attacker, which captures a dishonest
prover attacker.
Example 11. Speciﬁcation (ProverE(id),VeriﬁerE,(cid:104)k(cid:105))
is vulnerable to distance fraud. The prover process does
not declare new names, and there are no private func-
tions used therefore:
DP-A(id) = !new id.out(id).out(k) | A
We deﬁne PA as the process that receives the key k from
process DP-A, uses the key to decrypt the challenge and
response, and sends the response, without waiting for the
challenge:
PA = in(k).in(x).let (chal,resp) = dec(x,k) in out(resp)
Since the response is sent before the timer starts, it has
time to make it to the veriﬁer before the timer is active.
Hence, [ VeriﬁerE ] | [ !new id.out(id).out(k) | PA ] can
reduce such that the veriﬁer can perform the veri f ied
event, which means that veriﬁed(id) : [ VeriﬁerE ] |
[ DP-A(id) ] holds and the attack is possible.
The attack works because the attacker can preempt
the challenge. This can be prevented if the challenge
must be observed before a response can be provided,
which can be achieved by including a nonce in the chal-
lenge and requiring that nonce to be included in a re-
sponse. Hence, we considered the revised speciﬁcation
(ProverE2(id),VeriﬁerE2,(cid:104)k(cid:105)), where
VeriﬁerE2 = !in(id).new chal.new resp.
out(enc((chal,resp),k)).
new c2.startTimer.
out(chal,c2).in(=resp, =c2).
stopTimer.event(verify(id))
ProverE2(id) = !new id.!out(id)in(x).
let (chal,resp) = dec(x,k) in
in(=chal,x).out(resp,x)
It can be shown that this ﬁx sufﬁces to defend against
distance fraud attacks. Intuitively, the nonce c2 is only
sent when the timer is running, so the attacker can never
return this in time if not co-located with the veriﬁer.
Terrorist provers are less powerful
than dishonest
provers, because they will not send their secret values
to a third party. Nevertheless, by considering terrorist
provers working with another attacker that is co-located
with the veriﬁer, we can identify further attacks.
Deﬁnition 5. Distance bound protocol speciﬁcation
(P(id),V, ˜n) is vulnerable to:
• terrorist fraud,
if veriﬁed(id) : new ˜n.[ V | A ] |
• assisted distance fraud, if veriﬁed(id):new ˜n.[ V |
[ T P-A(id) ]
DP-A(id(cid:48)) ] | [ T P-A(id) ]
where P(id) = !new id.!Q, DP-A(id(cid:48)) is as speciﬁed in
Deﬁnition 4, and T P-A(id) denotes !new id.out(id).!Q(cid:48) |
A, where Q(cid:48) is the process that acts as an oracle with
all relevant functions for all bound and free names and
private function applications in Q, and A is the context
hole.
The process T P-A will perform operations on behalf of
the attacker, e.g., signing, encrypting and decrypting any
values the attacker wishes, but it will not reveal secret
values.
Example 12. Speciﬁcation (ProverE2(id), VeriﬁerE2,
(cid:104)k(cid:105)) is vulnerable to terrorist fraud attacks. We have
T P-A(id) = !(new id.out(id)
| in(x).let y = dec(x,k) in out(y)
| in(x).out(enc(x,k))) | A
This process can receive the encrypted challenge from
the veriﬁer, decrypt it, and send the resulting plaintext to
an attacker process co-located with the veriﬁer, all before
the timer is started. At the veriﬁer’s location we consider
the following attacker process PA = in(chal,resp).in(=
1570    27th USENIX Security Symposium
USENIX Association
chal,x).out(resp,x), this process can receive the chal-
lenge information from the terrorist prover process, and
then use it to complete the veriﬁer’s challenge. This suf-
ﬁces to show veriﬁed(id):new k.[ V | A ] | [ T P-A(id) ],
hence, the speciﬁcation is vulnerable to terrorist fraud.
Example 13. The second, more secure, protocol in Ex-
ample 2 can be modelled in our calculus as (V 2,P2,(cid:104)(cid:105))
where:
P2(id) = !new id .!out(id) . in(x) .
let (chal,resp) = dec(x,lookup(id)) in
out(ready) . in(=chal,nonce) .
out(xor(nonce,lookup(id)),resp)
V2 = !in(id) . new chal . new resp .
out(enc((chal,resp),lookup(id))) .
in(ready) . new nonce .
startTimer . out(chal,nonce) . in(xb, =resp) .
stopTimer . let xb = h(nonce,lookup(id))
in event(verify(id)) else 0
and lookup is a private function used to ﬁnd a unique key
shared between one particular prover and the veriﬁer,
and h is a public hash function.
We show in Section 7 that there does not exist any at-
tacker process that can make any of the system contexts
that model the attacker perform a verify event for the id
being tested. Therefore this protocol is secure against all
of these possible, different distance bounding attacks.
We only consider two locations when capturing differ-
ent types of attacks against distance bounding protocols.
More attack scenarios would be possible by considering
attackers at other locations, however, these scenarios are
strictly weaker than those presented, so they would not
lead to interesting deﬁnitions.
5 A hierarchy of attacks
We have modelled ﬁve types of attack against distance
bounding protocols by considering various scenarios in
which veriﬁers are deceived into believing they are co-
located with provers. These scenarios consider the fol-
lowing terms:
lay fraud and terrorist fraud);
• V | A, a veriﬁer co-located with a basic attacker (re-
• V , a veriﬁer in isolation (distance fraud);
• V | P(id(cid:48)), a veriﬁer co-located with honest provers
• V | DP-A(id(cid:48)), a veriﬁer co-located with dishonest
(distance hijacking);
provers (assisted distance fraud);
tacker (relay fraud);
• P(id) | A, remote provers co-located with an at-
• DP-A(id), remote dishonest provers in isolation
• T P-A(id), remote terrorist provers in isolation (ter-
(distance fraud and distance hijacking); and
rorist fraud and assisted distance fraud).
Yet, numerous combinations of these terms were not
considered by the deﬁnitions in the previous section, e.g.,
we have not considered a veriﬁer co-located with a ba-
sic attacker and some other prover, along with a remote
prover and a basic attacker: [V | A | P(id(cid:48))]
[P(id) |
P(id)]. We also have not considered co-location of re-
mote dishonest provers, e.g., DP-A(id(cid:48)) | T P-A(id).
|
We now consider a more general setting whereby a
veriﬁer is co-located with zero or more of a basic attacker
A, honest provers P(id(cid:48)), terrorist provers T P-A(id(cid:48)), and
dishonest provers DP-A(id(cid:48)). These provers all use iden-
tiﬁers that are distinct from the identiﬁer id, which is
being used in an attempt to deceive the veriﬁer. More-
over, at a distinct, remote location, we consider one or
more of honest provers P(id), terrorist provers T P-A(id),
and dishonest provers DP-A(id). Furthermore, the re-
mote location may additionally include one or more of a
basic attacker A, honest provers P(id(cid:48)), terrorist provers
T P-A(id(cid:48)), and dishonest provers DP-A(id(cid:48)). This gives
way to 24 · 23 · 24 = 2048 scenarios. Albeit, we can dis-
regard scenarios in which identiﬁer id is absent (since
without this any attack will be an attack on authentica-
tion, rather than a distance bounding attack, and authen-
tication attacks can be found using a range of other well
established methods, e.g. [1]). This gives us 24 · (23 −
1)· 24 = 1792 scenarios to consider, signiﬁcantly more
than the ﬁve scenarios that have been identiﬁed in the
literature.
We can reduce the number of scenarios we need to
consider by observing that there is a strict order on the
capabilities of the different attacker processes:
Lemma 1. For any distance bounding protocol speci-
ﬁcation (P(id),V, ˜n), from which we derive DP-A and
T P-A, and for all system contexts C, sets of names E and
names x ∈ {id,id(cid:48)}, we have
veriﬁed(id):C[A | P(x)]
⇒ veriﬁed(id):C[T P-A(x)]
⇒ veriﬁed(id):C[DP-A(x)]
Moreover, no reverse implication holds.
By ﬁlling a context’s hole with a process containing a
hole (as above), we derive a context (which is required
by the veriﬁed predicate).
It follows from Lemma 1 that we need not con-
sider more than one of the terms P(x), DP-A(x), or
USENIX Association
27th USENIX Security Symposium    1571
T P-A(x) at a particular location. For instance, the ver-
iﬁer can perform the verify event in the context [V ] |
[P(id) | A | DP-A(id)] if and only if it can perform the
event in the context [V ] | [DP-A(id)]. Hence, we need
not consider both these contexts; we need only consider
the latter, simpler context.
Honest and dishonest provers represent an arbitrary
number of provers. (The bound name used as the id of
these provers will be substituted for another value by the
(NEW) rule.) Hence, we have:
Lemma 2. For any distance bounding protocol speci-
ﬁcation (P(id),V, ˜n), from which we derive DP-A and
T P-A, and for any system contexts C[ ], sets of names
E, names id and id(cid:48), and X ∈ {P,DP-A,T P-A}, we have: