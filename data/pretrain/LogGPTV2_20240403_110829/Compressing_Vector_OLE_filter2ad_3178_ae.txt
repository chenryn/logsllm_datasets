·
n2.8
0
1
1 − t/n1
(cid:19)n0(cid:19)
.
Low-Weight Parity-Check. The low-weight parity-check attack requires (n1/(n1− n0−
1))t iterations on average, where at each iteration the adversary must compute a weight-
(n0 +1) parity-check, which requires (n0 +1) arithmetic operations. The entry “parity-check
cost” in Table 1 and Table 2 provides a lower bound on the bit-security of the LPN instance
with respect to the low-weight parity check attack, computed as
(cid:32)
(cid:18)
log2
(n0 + 1) ·
n1
n1 − n0 − 1
(cid:19)t(cid:33)
.
Inverse Syndrome Decoding. We now turn our attention to the ISD attack. Many
variants of the attack have been developped in the past years, and the asymptotic costs
of these attacks are often non-trivial to estimate. However, in our parametter setting,
the noise rate t/n1 is tiny, and the advantages of the variants of the original algorithm of
Prange [Pra62] vanish in this situation, as shown in the analysis of [TS16]. We will therefore
focus on bounding the cost of the original algorithm of Prange; since we will ﬁnd this attack
to have much worst performances than the Gaussian elimination and low-weight parity-
check attacks, this leaves a large security gap. We rely on the detailed concrete eﬃciency
20
Elette Boyle, Geoﬀroy Couteau, Niv Gilboa, and Yuval Ishai
Table 1. Optimal parameters of Gprimal for a given output size n. Both the security parameter λ and
the bitsize of ﬁeld elements log2 |F| are set to 128. The parameters are optimized under the constraint
that solving the corresponding LPN instance must require at least 280 arithmetic operations with either
low-weight parity check, Gaussian elimination, or ISD.
n
210
212
214
216
218
220
222
t
k
ISD cost Gaussian cost
parity-check cost
seed size
ratio
57
98
198
389
760
1419
2735
652
1589
3482
7391
15336
32771
67440
115
104
108
112
117
121
126
80
85
94
99
103
106
108
93
80
80
80
80
80
80
1288
2881
6495
14101
29990
63013
131285
0.8
1.4
2.5
4.6
8.7
16.6
31.9
Table 2. Optimal parameters of Gdual for a given output size n. Both the security parameter λ and
the bitsize of ﬁeld elements log2 |F| are set to 128. The parameters are optimized under the constraint
that solving the corresponding LPN instance must require at least 280 arithmetic operations with either
low-weight parity check, Gaussian elimination, or ISD.
n
210
212
214
216
218
220
222
t
44
39
34
32
31
30
29
c = n(cid:48)/n
ISD cost Gaussian cost
parity-check cost
seed size
ratio
4
4
4
4
4
4
4
117
112
107
109
112
116
120
80
80
80
84
88
93
97
100
92
84
82
82
82
82
535
553
551
584
629
669
706
1.9
7.4
29.7
112
417
1566
5941
analysis of ISD given in [HOSSV18], which shows that the bit-security of the LPN instance
with respect to Prange’s algorithm is upper-bounded by
(cid:1) · (n1 − n0)2.8
(cid:33)
,
(cid:32) (cid:0)n1
(cid:1)
(cid:0)n1−n0
t
t
log2
using again Strassen’s algorithm for the Gaussian elimination step. We use this upper
bound to calculate the entry “ISD cost” in Table 1 and Table 2. The ratios obtained in
Table 1 and Table 2 show that Gdual performs considerably better than Gprimal in terms of
optimal seed size; however, this comes at the cost of a worst computational eﬃciency.
5.2 Time-Complexity Optimizations
In this section, we describe optimizations that improve the computational eﬃciency of
Gprimal and Gdual. While using uniformly random matrices Ck,n and Hn(cid:48),n in Gprimal and
Gdual reduces their security to the standard LPN assumption, this choice is wasteful in
terms of computation since a random linear mapping takes quadratic time to compute. We
discuss diﬀerent methods to improve the computational complexity by using LPN-friendly
codes that are eﬃciently encodable.
Eﬃciently Encodable LPN-Friendly Codes. While the standard LPN assumption is
deﬁned with respect to uniformly random linear codes, it is common to assume the hardness
of LPN with respect to other kinds of codes. We list below a few possible alternatives.
– Local Codes. The hardness of LPN for local linear codes is a well-established assump-
tion [Ale03]. A local linear code with a (constant) locality parameter d is one where
Compressing Vector OLE
21
each codeword symbol is a linear combination of d message symbols. Equivalently, each
row of the generating matrix has at most d nonzero entries. Such local codes have a
trivial linear-time encoding algorithm. Consider implementing Gprimal with a d-local
code. By the analysis of [ADI+17], picking d = 10 leads to a reasonable security level
with respect to known attacks, provided that the dimension is suﬃciently large (as it
will be in our concrete estimations). With a d-local code, the primal linear mapping
can be computed using d · n multiplications over F.
However, local codes cannot be used with Gdual: in Gdual, we require the dual code to
be LPN-friendly. The dual code of a local code is an LDPC code, for which eﬃcient
decoding algorithms exist, hence LPN does not hold with respect to such codes.
– LDPC Codes. An alternative that works for Gdual is to use the transpose of an LDPC en-
coder (we need to transpose since we want to deﬁne a compressing mapping), hence ob-
taining a security reduction to the hardness of LPN with respect to local codes [Ale03].
While the encoding matrix of an LDPC code is not sparse, it admits a linear-time
encoding algorithms over arbitrary ﬁelds [KS12]. By the transposition principle (see
e.g. [Bor57, IKOS08]) the transposed mapping can be computed with essentially the
same circuit complexity as the encoding (it essentially consists in reversing the compu-
tation while interchanging XORs and fan-out operations). Using this code, computing
the compressive linear mapping requires at most d · (2n(cid:48) − n) multiplications (since it
is bounded by n(cid:48) · rw(Dn(cid:48)−n,n) + w(Dn(cid:48)−n,n), rw(Dn(cid:48)−n,n) = d, see Section 3.4, and
w(Dn(cid:48)−n,n) < (n(cid:48) − n) · rw(Dn(cid:48)−n,n) = d · (n(cid:48) − n)). Using n(cid:48) = c · n gives a cost of
(2c − 1) · d · n multiplications over F, where here too we choose d = 10.
– MDPC Codes. A more conservative variant of the above is to rely on MDPC codes
(medium-density parity-check codes), where the parity-check matrix has row weight
√
n) (instead of constant). MDPC codes have been thoroughly studied, since they
O(
are used in optimized variants of the famous McEliece cryptosystem [MTSB12].
– Quasi-Cyclic Codes. A third alternative option is to rely on quasi-cyclic codes, which ad-
mit fast (albeit superlinear) encoding algorithms. Quasi-cyclic codes have been recently
used to construct optimized variants of the LPN-based cryptosystem of Alekhnovich
and the code-based cryptosystem of McEliece [ABD+16, MBD+18].
– Druk-Ishai Codes. Another possibility is to rely on the linear-time encodable codes de-
velopped by Druk and Ishai in [DI14]. Their construction of linear-time encodable code
is essentially a concatenation of good a linear encoding and its transpose, intertwined
with random local mixing. This design strategy leads to codes satisfying the combinato-
rial properties of random linear codes (e.g. meeting the Gilbert-Varshamov bound) and
do not support eﬃcient decoding, while having a fast (linear-time) encoding algorithm;