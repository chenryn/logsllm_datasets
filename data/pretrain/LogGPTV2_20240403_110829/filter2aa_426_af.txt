A minimal example of this vulnerability to use with Electron Fiddle is available here:
https://gist.github.com/3d72d1fe96d3a6e97d24704d278074af
5. Automated Analysis
Building on an understanding of what vulnerabilities occur in Electron applications, an analysis of a
large number of actual Electron applications for indicators of these vulnerabilities and related problems is
presented in this chapter. The goal of this analysis is to gain a broader picture of the security of Electron
applications in the wild. To this end, statistics on security-related practices were collected for an empirical
analysis.
5.1. Overview
For the automated analysis, several tools were developed to collect, prepare, and analyse Electron applica-
tions. The analysis is split into three stages. For each stage, a script was written in JavaScript using Node.js.
In the first step, a list of potential Electron apps, both open and closed source, is collected. The second
stage then tries to download and extract these apps. The open source apps considered here can simply be
cloned using Git but for the closed source ones, a method for extracting the source from various binary
formats (including .deb, .exe, .dmg, .appimage, etc.) has to be developed. Further, this process has to
make sure that the extracted result is actually an Electron app to discard false positives. Finally, the apps
can actually be analysed for security-relevant indicators like the Electron version used, the preferences and
potential problems. These steps are described in more detail in the following sections.
In total, 1,204 applications were found and successfully analysed. The source code for the scripts is
available on GitHub: https://github.com/baltpeter/thesis-electron-analysis-src
5.2. Collecting Electron Apps
The first step is to collect an adequately large set of actual Electron applications. Two sources are used for
this purpose: The Electron app list1 and repositories on GitHub. This is to ensure a representative set of
apps that are actually used and to include both open and closed source apps.
The Electron app list is maintained by the Electron developers themselves. It has the advantage of already
being available as machine-readable YAML manifest files from GitHub2. As such, it can easily be processed
by a chain of map() and filter() operations in JavaScript.
On GitHub, repositories tagged with electron and with more than 50 stars are collected. While certainly
not perfect, the tags provide an easy way to collect only repositories with Electron apps in them. False
positives are later filtered out. The star threshold is set to only include apps that actually see some use and to
avoid collecting unmaintained forks and test projects or experiments. The desired data is accessed through
the GitHub REST API3 using the oﬀicial octokit/rest.js library4. In addition, the plugin-throttling.js5 and
plugin-rest.js6 plugins are used to avoid hitting rate limits.
There is some overlap between the sources, mainly in open source apps that are on GitHub and also
listed in the app list. These are deduplicated according to the repository URLs, discarding those results
1https://www.electronjs.org/apps
2https://github.com/electron/apps
3https://docs.github.com/en/rest
4https://github.com/octokit/rest.js/
5https://github.com/octokit/plugin-throttling.js/
6https://github.com/octokit/plugin-retry.js/
5.3. Downloading Apps and Source Code Extraction for Closed Source Apps
33
from GitHub that are already present in the app list. Therefore, the inconsistent repository URLs in the
app list have to be cleaned by removing the .git suﬀix and trailing slashes, where present, to make them
match the ones returned by the GitHub API.
Next, download links for the closed source apps7 have to be collected as the app list only contains
the website URL for those. The download links are collected manually for Windows, macOS, and Linux,
depending on what platforms the respective apps are offered on. Based on the assumption that extraction
would be easier, regular archives like .zip or .tar.gz are preferred over binaries like .exe installers and
distribution-specific formats like .deb and .dmg where available. On Linux, distribution-agnostic .appimage
files are preferred where available. No .rpm files were selected as all those instances also included a .deb
file. In some cases, a repository was found even though none was listed in the YAML manifest.
For some apps, no download link was found. This was usually due to them being discontinued, available to
paid users only or the provided download links simply not working.
All results are saved in a PostgreSQL database. For each app, the slug as a unique ID, name, website
URL, and, if applicable, repository URL are saved. For closed source apps, the repository override and the
download links for Windows, macOS and Linux (if available) are additionally saved in a separate table.
The apps were collected on July 1, 2020, with the script run taking 34 seconds. 906 results were found
on the app list and 907 on GitHub. After deduplication, 1,645 apps remained. Of those, 347 didn’t have
a repository URL listed but for 198 of them, at least one download link or repository URL was found
manually on the same day. This leaves a total of 1,496 apps.
5.3. Downloading Apps and Source Code Extraction for
Closed Source Apps
After a list of apps has been compiled, they have to be downloaded. For the closed source apps, the source
code further has to be extracted. The script for this purpose goes through a list of download strategies for
each app, until either one is successful or none are left. The strategies decide whether they were successful
by whether they can detect an extracted Electron app afterwards.
The following strategies are used (in their preferred order): git clone, Linux binary, macOS binary,
Windows binary. The git clone strategy is only tried if a repository is known. It tries to clone this repository
using Git and checks if it contains an extracted Electron app.
The binary strategies all use the same algorithm. They are only tried if the respective download link is
known. They try to download the app and extract the result as explained below. Then, they check whether
the extracted result is an Electron app already. Otherwise, they try to find an .asar file. As explained
in Section 3.1.2, .asar files are an archive format used to distribute Electron applications. The strategies
then try to extract this archive and detect an Electron application.
For this detection, the script tries to find a package.json file using a “find nearest file” algorithm. This
algorithm recursively searches for the filename in all subdirectories and returns the result with the fewest
slashes. If no package.json file is found, the detection returns false. Otherwise, it checks whether it
contains an Electron-related dependency, i.e. a package with a name starting with electron. This causes
some false positives but many Electron apps don’t explicitly depend on the electron package, so checking
for related dependencies is necessary. The related dependencies are mostly Electron-specific libraries and
packagers.
If no such dependency can be found, which isn’t uncommon either, the app entry point, which is specified
7Here, apps that don’t have a repository URL listed are assumed closed source as opposed to the actual definition of the
Open Source Initiative.
5.4. Scanning for Potential Security Problems
34
as main in the package.json file and necessary for Electron apps, is checked for a require('electron')
using the detective package8 which finds require() calls by walking the file’s AST. If one is found, true
is returned, otherwise false is returned.
This approach produces a false negative if a repository or application contains more than one package.json
file and the first one found isn’t the right one. This case was not handled as it only appears in very few
apps.
It was possible to implement the extraction algorithm relying only on p7zip9 for extraction, although an
easily extendable implementation was chosen. Using p7zip, most of the encountered archives can already
be extracted. However, there are quite a few cases of nested archives that need to be handled. For those, a
recursive approach that knows how to handle various types is used. This approach tries to extract known
file types until no new files are found anymore. The following file types are handled:
.tar.gz and .tar.xz files produce a tarball that needs to be extracted.
.deb packages contain control.tar.* and data.tar.* files. Of those, the data.tar.* file contains
the actual application and needs to be extracted.
.exe files are used by a variety of completely different installers and therefore need different post-
processing, most notably:
They may contain a .nupkg file which needs to be extracted again.
NSIS installers have a folder $PLUGINSDIR with a *.7z file that needs to be extracted.
When the extraction is successful, the directory of the extracted Electron app and the successful strategy
are saved in a database table. The script can be run in multiple stages as it only iterates over the apps that
haven’t been successfully processed before.
The download and extraction script was also run on July 1, 2020. It took 3.3 hours. In total, 1,204 apps
were successfully downloaded, extracted if necessary, and detected as Electron apps. For the other apps,
one of those steps failed, leading to their exclusion from further analysis. This means that either they could
not be extracted successfully (because of an invalid archive format or one that wasn’t handled by the script)
or no Electron application could be detected in the extracted source (most likely because going by the tag
electron on GitHub is of course an over-approximation which will match repositories that are not Electron
apps).
5.4. Scanning for Potential Security Problems
Finally, the collected apps need to be analysed and scanned for potential security problems. As the basis for
this, the third-party Electronegativity10 tool was selected. Electronegativity is an open source security scan-
ner specifically for Electron applications, offered by security research and development company Doyensec
[74]. It tries to identify misconfigurations and potential problems through a number of checks, which can
either be atomic or global. Atomic checks are used to identify basic issues like the value of a flag in a single
file, while the global checks work on the set of issues found by the atomic checks, further refining them if
necessary to weed out false positives and generate aggregate results.
Electronegativity can handle JavaScript, HTML, and JSON files. Each file is first parsed into a format the
checks can handle: JSON files are simply passed through JSON.parse() and HTML files are parsed using
cheerio11, an alternative implementation of jQuery designed for use in Node.js applications. For JavaScript
8https://github.com/browserify/detective
9https://sourceforge.net/projects/p7zip/
10https://github.com/doyensec/electronegativity
11https://github.com/cheeriojs/cheerio
5.4. Scanning for Potential Security Problems
35
files, an AST is generated using the Babel parser12, TypeScript ESTree13 or Esprima14 depending on the
file type and whether the previous parsers succeeded.15
The parsed files are then run through the individual atomic check functions.16 The checks are passed the
generated AST which they can match on to determine the settings used by the developers as well as any
other potential issues.
Finally, the results collected from the atomic checks are passed through the global check functions17 which,
based on having access to all previous results, can decide to remove items that were false positives or add
new items knowing that no CSP was found, for example, before being presented to the user.
The tool was designed to be used by app developers on their individual apps via the command line. In
order to fit the purpose of this thesis, it was extended. Wherever it aligned with the goals of the project,
changes were contributed back:
First of all, a way to run the scans programmatically was introduced.18 This had already been
requested by developers wanting to run Electronegativity in their continuous integration pipelines
and then further process the results.
Running the tool on a large number of apps revealed a few that caused it to crash. These were fixed.19
Electron has changed the default values for various settings over time. Electronegativity previously
did not consider that and always assumed the first version, leading to many false positives. It was
extended to take the Electron version into account and pass the respective default values for the
settings to the checks. The affected checks were also updated to behave according to those defaults.20
To this end, the Electron version detection was also extended to not only consider the package.json
file but also the actual installed packages, as well as a potential package-lock.json or yarn.lock
lockfile, depending on what is available.21 This was necessary as many applications, especially those
distributed as binaries and without source code available, often don’t include a complete package.json
file. To deal with the potential conflicting versions found from the different sources, the oldest is as-
sumed as the tool cannot know which one is actually used.
Additional changes were also made but not submitted upstream as those are specific to the use case in
this thesis:
Two checks were added that scan for common functions not specific to Electron that can lead
to XSS and code execution when called with user-provided input like element.innerHTML and
child_process.exec() respectively. While these are not specific to Electron, they often occur in
Electron apps and their use can be an indicator of how security-conscious the developers are.
A check was added to collect statistics on how often the Chromium DevTools are enabled. While not
a security risk per se, there is little reason to leave them enabled in production apps.
12https://babeljs.io/docs/en/babel-parser
13https://www.npmjs.com/package/@typescript-eslint/typescript-estree
14https://esprima.org/
15see: https://github.com/doyensec/electronegativity/blob/0885c151624d25acbb01f90a409f4b575ff3f1e8/src/parser/
parser.js
16see: https://github.com/doyensec/electronegativity/blob/0885c151624d25acbb01f90a409f4b575ff3f1e8/src/finder/
finder.js
17see: https://github.com/doyensec/electronegativity/blob/0885c151624d25acbb01f90a409f4b575ff3f1e8/src/finder/
globalchecks.js
18see this pull request: https://github.com/doyensec/electronegativity/pull/64
19see
these
pull
requests:
https://github.com/doyensec/electronegativity/pull/65,
https://github.com/doyensec/
electronegativity/pull/68
20see this pull request: https://github.com/doyensec/electronegativity/pull/66
21see this pull request: https://github.com/doyensec/electronegativity/pull/67
5.4. Scanning for Potential Security Problems
36
A check was added to collect statistics on what kinds of sites are loaded, i.e. whether local or remotes
sites are loaded through window.loadFile() and window.loadURL(). As discussed previously, remote
websites are much more dangerous in the context of Electron.
loadFile() can only load local sites but loadURL() can load remote and local sites depending on
the protocol. For this analysis, http: and https: URLs are considered remote and file: URLs are
considered local. Custom protocols are counted separately. All loads to URLs that don’t start with a
valid protocol [75] are considered as unknown.
Finally, all checks were modified to not only alert when problems are found but to also log “good
behaviour” like explicitly enabling security features or disabling dangerous ones. While not relevant
to a developer looking for problems in their code, this is necessary to gauge which security features
are actually used in the wild.
In addition to scanning for issues in the code, the apps are also scanned for known vulnerabilities in their
included dependencies. For this, the npm audit command is used. This tool compares the dependencies
specified in the package lockfile against a list of known vulnerabilities [27]. Before, this package lockfile
needs to be generated from the installed dependencies if it isn’t included in the app distribution anyway.
This is done through npm install --package-lock-only.
Not all checks included with Electronegativity are run. While certainly useful when testing individual
apps, many checks require manual review of the findings. However, the purpose of this analysis is only
to collect aggregate statistics on a large number of apps. Therefore, the following general statistics are
collected:
Which Electron version is used, looking at the package.json, yarn.lock, package-lock.json files
and the actual installed dependencies in the node_modules folder and considering the oldest found
dependency for electron?
How many remote and local sites are loaded using loadURL() and loadFile(), depending on the
URL that is passed?
How many protocol handlers are registered using one of the following functions:
registerHttpProtocol(),
registerServiceWorkerSchemes(),
registerStringProtocol(),
registerBufferProtocol(),
registerStandardSchemes(),
setAsDefaultProtocolClient(),
registerFileProtocol(), registerStreamProtocol()?
How many times are dangerous functions, potentially leading to XSS, called with non-literal input? In
particular, the following uses are considered: Setting element.innerHTML and element.outerHTML;
calling the functions document.write(), document.writeln(), element.insertAdjacentHTML(),
eval(), setTimeout(), setInterval() and setImmediate(); calling the Electron-specific functions
executeJavascript() and insertCSS(); or using the Function() constructor.
How
many
times
are
dangerous
functions,
potentially
leading
to
code
execution,
called
with
non-literal
input?
In
particular,
the
following
uses
are
considered:
Calling
child_process.exec()
and
child_process.execSync();
calling
child_process.execFile(),
child_process.execFileSync(), child_process.spawn() and child_process.spawnSync() with
options.shell set to true.
How many times is shell.openExternal() called with non-literal input?
How many CSPs are defined and how many of those are classified as weak, maybe weak, and strong by
Google’s CSP evaluator? CSPs set in HTML and JavaScript are both considered. A CSP is considered
weak if the CSP evaluator produces at least one finding of severity high or medium, it is considered
maybe weak if the evaluator produces at least one finding of severity high maybe or medium maybe