### Table 8: Significance of Domain Reputation Features

| Feature | p-value | Signif. |
|---------|---------|---------|
| 1.59e-06 | ***     |
| 3.46e-04 | ***     |
| 1.6e-04  | ***     |
| 8.1e-04  | ***     |
| 1.04e-06 | ***     |
| 2e-16    | ***     |
| 2.56e-07 | ***     |

### 4.2.5 Combining Relevant Features
In our final logistic regression model, we incorporate all features found to be significant in the above analyses, as listed in Table 9. We also conducted a χ² goodness-of-fit test to evaluate the hypothesis that the final model fits the training data set. The resulting p-value was very high (close to 1), indicating that the null hypothesis cannot be rejected. This finding provides confidence that the model is a good fit for the features modeling user demographics and behavior. Next, we present our evaluation results on the predictive power of the model.

### Table 9: Features Included in Final Logistic Regression Model

| Category       | Feature         | Description                                          |
|----------------|-----------------|------------------------------------------------------|
| Demographic    | Gender          | Gender of the user                                   |
|                | Country         | Country of the user’s office                         |
|                | Level           | Level in the management hierarchy                   |
| Technical      | VPN_conn        | Total number of VPN connections                      |
|                | VPN_dur         | Duration of VPN connections                          |
|                | VPN_sbytes      | Bytes sent in VPN connections                        |
|                | VPN_extip       | Number of external IPs connecting to the VPN         |
| Web            | Chat            | Number of chat sites visited                         |
|                | File transfer   | Number of file-transfer sites visited                |
|                | Freeware        | Number of freeware sites visited                     |
|                | Games           | Number of gaming/gambling sites visited              |
|                | Social networks | Number of social-networking sites visited            |
|                | Streaming       | Number of streaming sites visited                    |
|                | Non-Categorized | Number of non-categorized sites visited              |
|                | No_doms         | Number of distinct domains visited                   |
|                | Blocked         | Number of connections blocked by the proxy           |
|                | Challenged      | Number of connections challenged by the proxy        |
|                | Consented       | Number of connections consented by the proxy         |
|                | New_domains     | Number of new domains visited                        |

### 4.3 Evaluation
To evaluate the final model, we randomly split the set of all hosts into equal-sized training and testing sets. We estimate the parameters of the logistic regression model using the training set and compute the risk scores for hosts in the testing set. Figure 10 shows the cumulative distribution function (CDF) of scores for hosts in the testing set. It is evident that the CDF for hosts encountering malware is distinct from that for "clean" hosts, with the former having, on average, higher scores than the latter.

**Figure 10: Cumulative Distribution of Scores for Hosts Encountering Malware and Those That Did Not**

This suggests that user demographic and behavior features can be used to infer the likelihood of malware encounters. For example, hosts can be ranked based on their risk score under a model tuned to the specific organization. Proactive measures can then be applied to hosts with the highest scores to detect and remediate potential malware infections.

To assess the effectiveness of this prioritization approach, we ordered the hosts in the testing set based on the risk score output by the model and computed the malware encounter rate for the top n hosts. Figure 11 shows our results, averaged over ten independent runs, where each run splits the hosts into training and testing datasets, builds the model on the training set, and computes risk scores for hosts in the testing set. Results for models built with all features and those with each feature category are shown as separate lines in Figure 11.

**Figure 11: Ordering Hosts by Their Risk Score. The Malware Encounter Rate Decreases with the Hosts’ Score Ranking. Among the Top 1,000 Hosts, the Malware Encounter Rate is 51% (Well More Than 3× Higher Than the Overall Encounter Rate of 15%).**

With all 20 features combined, the malware encounter rate among the top 1,000 hosts is 51%, which is well more than 3× higher than the overall malware encounter rate in the enterprise (15.31%), as described in Section 3. Among the three feature categories, user demographics is the most powerful at indicating risk, followed by VPN behavior. Surprisingly, web activity contributes marginally to the overall model. One possible explanation is that, in our study, only 3.11% of the hosts encountered malware from the web (see Section 3.1), and among those, we have visibility into only a small fraction that occurred within the corporate network.

### 5. PREVIOUS STUDIES
Several prior works have examined the relationship between the likelihood of malware encounters and users' online behavior or demographic information. The datasets and methods used to identify malware encounters vary across these studies. In this section, we compare our results to those reported in previous studies where possible, and highlight instances where our findings corroborate or refute theirs. We also summarize some more distantly related works in Appendix C.

**Malware Encounter Rate:**
- **Microsoft Security Intelligence Report (2013)**: [12] involving over 600 million hosts with Microsoft security products, reported a worldwide malware encounter rate of around 18%.
- **Our Enterprise Dataset**: consisting of 62,884 hosts instrumented with the McAfee client over four months, has a similar encounter rate of 15.31%. On average, our weekly encounter rate is 1.26%.
- **Other Datasets**: Smaller datasets, such as network packet captures, exhibit similar encounter rates. Maier et al. [10] found that 1.23% of users subscribed to a European ISP exhibited scanning or spamming behavior or contacted known malware sites over 14 days. Carlinet et al. [4] observed 3.04% of Orange ISP customers in France generating traffic that triggered Snort alerts during three hours.

**User Studies:**
- **Ngo and Paternoster [14]**: Surveyed 295 university students, 46% of whom reported encountering malware at least once in the last year.
- **Lévesque et al. [9]**: Found that 38% of 50 participants were infected over four months.

The lower encounter rate in our dataset compared to prior works may be due to the network policies enforced in the enterprise, including whitelists and blacklists for outbound network connections, and restrictions on software installation on enterprise-managed hosts. Additionally, the populations studied in Lévesque et al. and Ngo and Paternoster (primarily students) may account for the higher encounter rates.

**User Demographics:**
- **Ngo and Paternoster**: Found that age and race are significantly related to the likelihood of encountering malware, but not gender, marital status, or employment status.
- **Lévesque et al.**: Agreed that age, gender, marital status, and employment status do not contribute to the risk of infection, but identified technical expertise as a significant factor.

Our employee dataset does not include personal information such as age or gender, and all users were employed. However, we did confirm that technical expertise correlates with the likelihood of encountering malware.

**User Behavior:**
- **Maier et al. and Ngo and Paternoster**: Examined the relationship between the use of security products and malware encounters. Maier et al. found that neither antivirus scanners nor regular OS and blacklist updates reduced malicious activities. Ngo and Paternoster found that having security software led to a higher probability of encountering malware, possibly due to users being more aware of infections.
- **Carlinet et al. and Lévesque et al.**: Found that more exposure to the Internet, in terms of traffic volume and the number of unique websites visited, resulted in a higher likelihood of malware encounters. Canali et al. [3] used logistic regression to show that browsing time, duration, and the number of distinct domains are better indicators of a user being at risk than the domain category, although their definition of "at risk" is broader and does not rely on documented malware encounters.

### 6. LIMITATIONS
By the nature of the data available to us, our conclusions are subject to several caveats:

- **Data Reliability**: Since we relied on McAfee reports to indicate malware encounters, our results do not reflect potential encounters detected and eliminated by firewalls/IPS, web browsers, or other security defenses. No antivirus solution detects all malware, so our encounters are biased toward mass-market malware that entered the enterprise via poorly defended vectors.
- **Indirect Indicators**: We do not have ground truth for many aspects of our investigation, requiring us to use indirect indicators. For example, we used McAfee reporting delays to infer whether each malware encounter occurred while the computer was on the corporate network and leveraged job titles as a surrogate for technical proficiency. These inferences come with a level of error, though the large amount of data in our study provides some statistical evidence for the correlations we observe.

Unknowns will be a factor in virtually any study of this type, introducing questions about the extent to which any single study, including this one, will be representative more broadly. We believe it is necessary to assemble a broad set of such studies to reveal common elements and differences. (We have attempted to draw out such similarities and differences with other studies in Section 5.) Only through repetition can lasting trends be identified.

### 7. RECOMMENDATIONS FOR THE ENTERPRISE
Our study suggests the following recommendations for reducing the rate of malware encounters in enterprise settings:

- **Proactive Scanning and Alert Prioritization**: Enterprises often deploy memory analysis tools on hosts. As these tools are labor-intensive, they must be deployed selectively. Our logistic regression model identifies hosts with a highly elevated risk of malware encounters (51% among the top 1,000 such hosts). This allows an enterprise to apply memory-scanning tools proactively, facilitating early detection of malware infection. Similarly, an enterprise can prioritize the investigation of alerts (e.g., generated by log-analysis tools) based on modeled host risk.
- **User Education**: User education has the potential to reduce behaviors responsible for a significant fraction of malware encounters. Several studies have affirmed the successes of carefully targeted educational campaigns. Our study highlights several opportunities for such targeting, e.g., educating users in low GDP countries to avoid the use of USB sticks with company laptops.
- **Caution with Site Categories**: In the studied enterprise, most web-based malware encounters permitted by the web proxy originate from sites categorized as business-appropriate under enterprise policy. This suggests that currently deployed website content categories are an inadequate basis for access restrictions. Tightening access policies by refining website categories and/or applying per-user (or per-group) rules may reduce web-based encounters.

Understanding the practical implications and effectiveness of any recommendation would require in-field studies and likely differ across enterprises based on their policies and compliance requirements. We hope our study will motivate future research in these areas.

### 8. CONCLUSION
We have presented the first large-scale epidemiological study of malware encounters in the setting of a large enterprise. Our study offers several key findings, including the preponderance of malware encounters outside the enterprise network, differences across geographies in the most important vectors of malware propagation, differences in encounter rates according to employee position in the management hierarchy, and a significant risk of web-based malware encounters that originated with sites categorized as safe and business-appropriate by the enterprise web proxy. While our study corroborates some findings in earlier research, it also sheds new light on the special characteristics of enterprise malware penetration and shows how these characteristics can be combined in a logistic regression model to achieve accurate identification of at-risk hosts. Finally, our study suggests promising, concrete policy- and education-based approaches to driving down malware encounter rates in enterprise environments.

### Acknowledgments
We are grateful to the anonymous enterprise who permitted us access to their data for the purposes of this study. We also thank James Lugabihl, Robin Norris, Todd Leetham, Christopher Harrington, Garrett Schubert, Justin Lamarre, Andrew Rutkiewicz, Michael Blanchard, Ronald L. Rivest, and members of RSA Laboratories for their many useful comments and suggestions on designing the experimental framework in the paper. We thank our shepherd Davide Balzarotti and anonymous reviewers for their feedback on drafts of this paper. This work was supported in part by NSF grant 0831245.

### 9. REFERENCES
[1] “epidemiology”. In Merriam-Webster.com, 15 May 2014.
[2] J. Caballero, C. Grier, C. Kreibich, and V. Paxson. Measuring pay-per-install: The commoditization of malware distribution. In 20th USENIX Security Symposium, Aug. 2011.
[3] D. Canali, L. Bilge, and D. Balzarotti. On the effectiveness of risk prediction based on users' browsing behavior. In 9th ACM Symposium on Information, Computer and Communications Security, June 2014.
[4] Y. Carlinet, L. Mé, H. Debar, and Y. Gourhant. Analysis of computer infection risk factors based on customer network usage. In 2nd International Conference on Emerging Security Information, Systems and Technologies, pages 317–325, Aug. 2008.
[5] M. P. Collins, T. J. Shimeall, S. Faber, J. Janies, R. Weaver, M. De Shon, and J. B. Kadane. Using uncleanliness to predict future botnet addresses. In 7th ACM Internet Measurement Conference, pages 93–104, Oct. 2007.
[6] A. Kleiner, P. Nicholas, and K. Sullivan. Linking Cybersecurity Policy and Performance. Microsoft Trustworthy Computing, 2013.
[7] M. W. Kreuter and R. J. Wray. Tailored and targeted health communication: Strategies for enhancing information relevance. American Journal of Health Behavior,