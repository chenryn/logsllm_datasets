server-side delay becomes larger relative to external delay.
2.2 QoE sensitivity and its heterogeneity
Our basic intuition is that the impact of the server-side delay of
a request on its QoE, i.e., its QoE sensitivity, varies greatly across
users. This follows directly from two observations, which we em-
pirically demonstrate here: the sigmoid-like relationship between
QoE and total delay, and the variability in requests’ external delays.
Sigmoid-like QoE-delay relationship: Figure 3 shows the QoE-
delay relationship of requests to one particular page type. Like
prior work, we estimate QoE by “time-on-site”, measured as the
difference between the start and end timestamps of their web ses-
sion. A web session includes all of the user’s engagement on the
website, such as subsequent clicks and other interactions, with no
period of inactivity greater than 30 minutes. Figure 3 groups the
total delays into equal-sized buckets, each with at least 5,000 users,
and plots the average QoE of users in each bucket. The key property
of this graph is its sigmoid-like shape. Initially the total delay is
small and the QoE is almost insensitive to any change in delay (the
delay is too short for users to perceive); then the QoE starts to drop
sharply with slope peaking at around 2,000 ms (this is the region
where reducing total delay makes a difference); finally, when the
total delay exceeds about 5,800 ms, the QoE becomes insensitive
again (the delay is long enough that a little additional delay, while
noticeable, does not substantially affect QoE). Accordingly, we can
roughly categorize all user requests into three sensitivity classes:
• Too-fast-to-matter (left blue-shaded area): QoE is not sensitive to
• Sensitive (middle orange-shaded area): QoE is sensitive to server-
server-side delay if total delay is below 2000 ms.
side delay when total delay is between 2000 ms and 5,800 ms.
Figure 3: We observe a non-linear relationship between QoE and
total delay (a), so reducing delay by the same amount can have a
dramatically different impact on QoE. We highlight different sensitiv-
ity regions with different colors. The same QoE-delay relationship is
observed in our MTurk-based user study (b).
• Too-slow-to-matter (right red-shaded area): QoE is not sensitive
to server-side delay if total delay exceeds 5,800 ms.
The sigmoid-like curve may look similar to deadline-driven util-
ity curves commonly used in prior work (e.g., [21, 41]), but there is
a difference. Traditionally, a service deadline is set where the QoE
starts to drop. But our analysis shows that when the total delay
exceeds any threshold, the QoE does not drop to zero immediately,
and instead decreases gradually as total delay increases. As we will
see in §7.4, this difference can cause deadline-driven schemes to
have suboptimal QoE.
We acknowledge that time-on-site may not always reflect how
satisfied users are with the web loading experience. Therefore, we
complement the above analysis with an IRB approved user study3
on Amazon MTurk [1]. We describe the detailed setup in Appen-
dix B and only give a summary here. Following similar work in
the crowdsourcing literature [48], we asked participants to watch
a web page load with different total delays and then to rate their
experience on a scale of 1-5. The total delays were randomly per-
muted per user to avoid any bias due to ordering. We ran this user
study on the same web page as in Figure 3(a) and plot the resulting
QoE curve in Figure 3(b). As the figure shows, the curve from the
user study shares the same sigmoid-like shape as the curve from
our trace analysis. We also repeated the user study on four other
popular websites; all websites yielded similar sigmoid-like QoE
curves, though the boundaries of the three sensitivity regions vary
slightly across the sites.
Although our observations about the QoE-delay relationship do
not seem different from prior work (e.g., [14, 22]), they have deeper
implications when combined with the next empirical observation
on the variability of external delays.
Variability in external delays: The sigmoid-like relationship
between QoE and delay means that the sensitivity of QoE to server-
side delay depends heavily on the external delay. Figure 4 shows
the distribution of external delays among requests for the same web
page received at the same frontend web cluster. We see a substantial
fraction of requests in each of the three sensitivity classes (25% too-
fast-to-matter, 50% sensitive, 25% too-slow-to-matter). The same
kind of distribution holds across web pages and is stable over time
in our traces.4 Note that the variance in Figure 4 is unlikely due
3Our study was approved by U. Chicago, IRB18-1096. It does not raise ethical issues.
4The total delay distributions in our traces are consistent with those observed in prior
work [16], though they may still vary with website type (e.g., online shopping vs.
search engine).
Shared-resource serviceFrontend web serverWAN(last-mile, ISP)DatacenterRequest(browser)external delayserver-side delaytotal delay0.2.4.6.81 0 6 12 18 24(a) Trace analysisQoE (Normalized)Page load time (sec.)MeanError 1 2 3 4 5 0 6 12 18 24(b) MTurk experimentGradePage load time (sec.)MeanErrorSIGCOMM ’19, August 19–23, 2019, Beijing, China
X. Zhang et al.
Figure 4: External delays exhibit great variance even among requests
received by the same web server cluster for the same page content.
to datacenter-level geographical differences, since our traces use a
global network of edge proxies to route users from the same region
to the same datacenter cluster, although this does not exclude geo-
graphical differences users in the same region. It is also unlikely due
to application-level differences, since the requests are all targeting
the same web page. In practice, a web service provider may see
even greater variability in external delays if its edge proxies are less
widely distributed than our traces (causing each datacenter cluster
to serve a larger geographic region), or if requests are processed
by a more centralized architecture (e.g., in many video streaming
CDNs [51]).
Since external delays are beyond the control of the web service
provider, they are an inherent property of the request from the
perspective of the service provider. This is in contrast to server-side
delays, which the service can influence.
2.3 Potential for improvement
We now use a trace-driven simulation to demonstrate the opportu-
nity of leveraging the heterogeneity of QoE sensitivity to server-side
delays. Suppose the dataset has n requests R = {r1, . . . , rn}, and
the server-side delay and external delay of request ri are si and ci,
respectively. Let Q(·) be the QoE function that takes total delay as
input and returns the expected QoE. The current QoE of ri can thus
= Q(si + ci). Table 2 summarizes our notation.
be denoted by V old
Reshuffling server-side delays: Now, let us consider a simple
analysis to counterfactually estimate the benefit of allocating re-
sources based on QoE sensitivity. We preserve both the external
delay of each request and the collection of server-side delays, but we
re-assign the server-side delays to requests as follows. We first rank
all requests in order of their derivative on the QoE curve,− dQ
,
dx
representing the impact on QoE of a small change in server-side de-
th-largest server-side delay to the request
lay. Then, we assign the k
th-least sensitive request
with the k
to server-side delay). Let π denote the resulting permutation of
server-side delays, i.e., request ri now has server-side delay sπ(i).
So the new QoE of request ri is V new
Intuitively, the above re-assignment gives small server-side de-
lays to requests that are sensitive to them, and larger delays to
requests that are less sensitive. If the server-side delays si are suf-
ficiently small, this assignment can be shown to be optimal, as
i =1 Q(sπ(i) + ci) =
follows. The average QoE can be written as 1
n
i =1 Q(ci). Suppose the ci are given and
1
n
w.l.o.g. c1 ≤ · · · ≤ cn, then this expression is maximized when
sπ(1) ≤ · · · ≤ sπ(n).
Practicality of simulation: To avoid assigning improbable server-
side delays to the requests, we first grouped the requests by page
type within one-minute time windows, and only re-assigned server-
side delays among requests in the same group and 10-second time
n
i =1 sπ(i)Q′(ci) + 1
th-smallest derivative (i.e., the k
= Q(sπ(i) + ci).
(cid:12)(cid:12)(cid:12)x =ci
n
n
i
i
n
i
i
Figure 5: Potential QoE gains through better allocation of server-side
resources based on QoE sensitivity. By reshuffling server-side delays
(solid yellow line), we achieve significant QoE gains that are close to
the (unrealizable) ideal of zero server-side delays (dashed blue line).
window. In other words, we do not assign the server-side delay of
an off-peak-hour request to a peak-hour request, or the server-side
delay of a simple static page request to a complex page request. We
also verified that the server-side delay distributions exhibit only
negligible changes within a time window. Nonetheless, there are
two important caveats. First, our analysis assumes the server-side
delays can be arbitrarily re-assigned among requests, which of
course is impractical. Second, the analysis uses a very simple algo-
rithm that assumes the set of server-side delays is fixed. In practice,
server-side delays are difficult to predict and depend on how re-
sources are allocated to requests. These issues make it challenging
to achieve the QoE gains predicted by our simulation; later sections
address the issues to extract as much gain as we can manage.
Potential gains in QoE and throughput: Figure 5 shows the
distribution of QoE improvements over all requests, i.e., (Qnew
−
, as predicted by our simulation. We see that a small
Qold
i
fraction of requests (less than 15.2%) suffer a marginally worse QoE
under the new assignment, but a substantial fraction of requests
(over 27.8%) see QoE improve by at least 20%. Overall, the new
average QoE is 15.4% higher than the old QoE. These improvements
are consistent across different page types in the traces. Note that
although the new assignment may worsen tail QoE, requests at
the tail have such small QoE derivatives that the additional degra-
dation is marginal. We conclude that there is substantial room to
improve QoE for a substantial fraction of users, without changing
the distribution of server-side delays.
)/Qold
Similarly, we can also support more concurrent requests, i.e.,
higher throughput, while maintaining a similar level of QoE. To
estimate the gain in throughput, we apply our reshuffling of server-
side delays to peak hours (higher throughput but worse QoE) and to
off-peak hours (lower throughput but better QoE). Figure 6 shows
the throughput and QoE during these two periods of time. We ran-
domly select web requests from two peak hours (4pm and 9pm) and
three off-peak hours (12am, 3am, 10pm), all in the Eastern Time
Zone. For every 10 minutes, we pick the last 10-second window,
reshuffle the server-side delays within the time window, and mea-
sure the new QoE as above. We can see that the new average QoE
during peak hours is similar to (even higher than) the old QoE dur-
ing off-peak hours. In other words, if we only apply our approach
during peak hours, we could support 40% more users without any
drop in average QoE.
Now, there are two contributing factors that suggest why these
potential gains can be realized over existing systems.
1. Existing systems are agnostic to user heterogeneity. Figure 7 shows
the distribution of server-side delays in a 10-second window for
requests whose external delays fall into different ranges. We see
0.2.4.6.81 2 4 6 8 12 16 2025%50%25%CDFPage load time (sec.)0.2.4.6.810100200300CDFPer-request QoE gain (%)Reshuffled delayZero server-side delayE2E: Embracing User Heterogeneity to Improve QoE on the Web
SIGCOMM ’19, August 19–23, 2019, Beijing, China
Figure 9: Overview of E2E.
Figure 6: Potential throughput improvement with similar QoE,
achieved by reshuffling server-side delays during peak hours and
off-peak hours.
Figure 7: Current server-side delays are uncorrelated with external
delays, showing that the existing resource allocation policy is agnostic
to QoE sensitivity. (Candlesticks show {5, 25, 50, 75, 95} percentiles.)
Figure 8: Server-side delays are highly variable, and not just at the
tail. This holds for different page types.
that there is little correlation between the external delay and
the corresponding server-side delay, which suggests that current
resource allocation and processing of these requests is agnostic
to QoE sensitivity. Our discussions with the Microsoft product
teams represented in our traces corroborate this finding.
2. Server-side delays are highly variable. Figure 8 shows that there is a
substantial variability in server-side delays even among requests
for the same page type. Part of this variance is due to tail per-
formance (as observed in prior work), but the lower percentiles
also show substantial variance. This variance in server-side de-
lays creates the “wiggle room” that makes the improvements in
Figure 5 possible.
2.4 Summary of key observations
The findings in this section can be summarized as follows:
• The variability of external delays across users and the sigmoid-
like relationship between QoE and page load time give rise to
heterogeneity in the QoE sensitivity of users to server-side delays.
• Our trace-driven simulation shows that by allocating server-side
delays based on the QoE sensitivity of each request, one could
potentially improve QoE by 20% with the same throughput, or
improve throughput by 40% with the same QoE.
• Existing server-side resource allocation is largely agnostic to
external delays, while server-side delays exhibit high variance,
which together create the opportunity to significantly improve
QoE over current schemes.
3 E2E: OVERVIEW
The next few sections describe E2E, a general resource allocation
system for web services that realizes the potential QoE and through-
put gains of leveraging user heterogeneity.
3.1 Architecture
Figure 9 illustrates the main components of E2E and how it interacts
with a web service system. Typically, a web request is first received
by a frontend web server (Figure 9 depicts only one web server,
but there may be multiple), which then forwards the request to
a backend infrastructure service (e.g., a distributed database or a
message broker) whose compute/network resources are shared