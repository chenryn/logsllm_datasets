v
i
t
i
s
o
P
e
u
r
T
0
0
0.2
0.4
0.6
False Positive Rate
0.8
1
Figure 2. ROC plots for three users: Faculty
Member, Ph.D. Student, and Master’s Student.
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:13:33 UTC from IEEE Xplore.  Restrictions apply. 
User
Fac. (dp)
Fac. (op)
Ph.D. (dp)
Ph.D. (op)
M.S. (dp)
M.S. (op)
psw
40
40
5
5
30
30
plw
800
800
100
75
600
300
pv
0
0
0
1
0
0
pC
10
20
10
20
10
10
pW
2.0
2.5
2.0
2.0
2.0
2.5
f p
0.11
0.04
0.16
0.04
0.13
0.1
f a
9
25
6
25
8
10
tp
1.0
0.96
0.91
0.90
0.55
1.0
Table 5. Model performance using default (dp) and optimal (op) parameter settings. f p: false positive
rate; f a: false alarm rate; tp: true positive rate.
AN are closer to user behavior than AU D; these two at-
tack models, however, are of minimal concern, as they can
be detected by users themselves (and as such, we wouldn’t
expect an attacker to behave in these ways). In contrast, it is
harder for users on their own to discover attackers behaving
according to model AU D. Thus, we chose to use model
AU D as the attack model for evaluating our model’s ability
to detect attacks.
5.3 Feasibility Analysis of the model
To date we have focused on using of(cid:3)ine experiments to
evaluate feasibility of the model for distinguishing legiti-
mate users from simulated attacker behavior (attack model
AU D).
In particular, we’ve focused on testing how dif-
ferent parameter settings affect the trade-off between false
positives and true positives. In order for our approach to be
feasible, it must be able to detect a signi(cid:2)cant number of
attacks while also generating no more false positives than a
regular user could be expected to handle.
Figure 2 is an ROC curve for each user based on 96 sets
of parameters, with one point per parameter set. These pa-
rameter sets are selected combination of the values listed in
Table 4. For the faculty and Ph.D. student users, most of
the points are located in the upper left corner, with false
positive rate less than 20% and true positive rates more
than 80%. For the master’s student, however, the points
are spread much more evenly across the range of false pos-
itives. These plots show that our model is a relatively accu-
rate representation of the behavior of faculty and Ph.D. stu-
dents; the disposition of the master’s student emails, how-
ever, do not appear to be signi(cid:2)cantly determined by the
sender of the email message. This discrepancy can be ex-
plained by the fact that this student receives a large num-
ber of automated messages for systems administrative pur-
poses, and these messages originate from a small number of
(non-human) email senders.
To further understand how these false positive rates
would translate into alarms that a user would have to as-
sess, we also analyzed the false alarm rate f a. f a repre-
sents the number of days that will pass on average between
false alarms. As the size of short-term data is set to be the
average number of new messages received each day, the f a
is equal to 1=f p.
Table 5 shows every user’s false positive rate, per-
average day false alarm rate, and true positive rate for de-
fault and optimal parameter settings. Optimal parameter
settings are those producing the best performance in terms
of low false positives and high true positives. From this
table we can see that for all users false alarm rates are rel-
atively low, in that a user would only be bothered once a
week at most, and for the better behaved users they would
only be bothered roughly once a month (on average). Yet,
even with these settings, over half (and generally, almost
all) attacks would be detected.
6 Discussion
Although we are greatly encouraged by our results, there
are also a number of limitations that must also be consid-
ered. First, perhaps most importantly, our results are based
on a very small user population. We do not believe, how-
ever, that our model (or indeed, any simple model of user
behavior) could ever apply to all users. Indeed, results on
one of our test subjects (the master’s student) show that
for some users, email disposition does not correlate well
with email sender. These results are suf(cid:2)cient, however, to
conclude that our modeling strategy has a good chance of
working for some high-volume email users. Further, it also
shows that user behavior modeling can be performed sim-
ply in the email archive domain through a judicious choice
of observables and a suitable model representation.
It should also be noted that a number of assumptions
were made when analyzing the results for true and false pos-
itives, ones that were not necessarily realistic. Users tend to
receive a highly variable number of messages a day and not
a constant stream of messages, and typical email archive
attackers would not read new email messages every day.
While such complications would need to be addressed by
an online implementation, we do not believe that the addi-
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:13:33 UTC from IEEE Xplore.  Restrictions apply. 
tion of such complications would change our basic results.
Also, in practice we would not want to exclude email
client behavior from normal access behavior (if we mon-
itored IMAP commands) given that it can be dif(cid:2)cult to
distinguish between intended user behavior and program-
generated incidental IMAP commands. Because program-
level behavior will be relatively repetitive, though, such an
addition shouldn’t have much of an impact on our false pos-
itive rates and in fact it should improve our true positive
rates (if attackers choose to use different email clients).
It is true that our detector can only detect an attack once
per day; further, we are uncertain what the effect of inter-
leaved attacker and normal behavior (e.g. at different times
of day) would have on our model’s accuracy. Though we
believe that our approach to simulating attack behaviors is
relatively systematic, there is still a signi(cid:2)cant gap between
realistic attacker behaviors and the attack model AU D. Can
we measure or estimate this gap, and can we improve upon
it in a meaningful way? This is an important question for
future work, both for this problem and for other approaches
to user-level anomaly intrusion detection.
Though user-level anomaly intrusion detection has nat-
ural weaknesses, from our current work we think it is pos-
sible to build a practical email archives intrusion detection
system by taking advantage of inherent features of the do-
main, selecting good features, and by using simple and ef(cid:2)-
cient modeling methods. Given the vulnerabilities and sen-
sitivity of email archives, we hope this work encourages the
development of email archive intrusion detection systems.
Acknowledgements: The authors would like to thank
the members of the CCSL for their participation, encour-
agement, and feedback. This work was supported by the
Canadian government through an NSERC Discovery Grant
and MITACS.
References
[1] D. Anderson, T. Frivold, and A. Valdes. Next-Generation
Intrusion Detection Expert System (NIDES): A Summary.
Technical Report SRI(cid:150)CSL(cid:150)95(cid:150)07, Computer Science Lab-
oratory, SRI International, May 1995.
[2] Apache Software Foundation.
http://spamassassin.apache.org.
SpamAssassin, 2005.
[3] F. Bergadano, D. Gunetti, and C. Picardi. User Authenti-
cation through Keystroke Dynamics. ACM Trans. Inf. Syst.
Secur., 5(4):367(cid:150)397, 2002.
[4] C. Chung, M. Gertz, and K. Levitt. DEMIDS: Misuse De-
tection System Database System. In IICIS, 1999.
[5] C. Cowan, C. Pu, D. Maier, J. Walpole, P. Bakke, S. Beat-
tie, A. Grier, P. Wagle, Q. Zhang, and H. Hinton. Stack-
Guard: Automatic Adaptive Detection and Prevention of
Buffer-Over(cid:3)ow Attacks.
In Proc. 7th USENIX Security
Conference, Jan 1998.
[6] M. Crispin. Request for Comment (RFC) 3501: Internet
Message Access Protocol(cid:151)Version 4rev1, March 2003.
[7] M. Delany.
Internet draft: Domain-based email authen-
tication using public-keys advertised in the DNS (Do-
mainKeys), March 2005.
http://www.ietf.org/internet-
drafts/draft-delany-domainkeys-base-02.txt.
[8] W. DuMouchel. Computer Intrusion Detection Based on
Bayes Factors for Comparing Command Transition Prob-
abilities. Technical report, National Institute of Statistical
Sciences (NISS), 1999.
[9] L. Heberlein, G. Dias, K. Levitt, B. Mukherjee, J. Wood, and
D. Wolber. A Network Security Monitor. In Proceedings of
the IEEE Symposium on Security and Privacy, 1990.
[10] S. Hofmeyr. An Immunological Model of Distributed Detec-
tion and its Application to Computer Security. PhD thesis,
University of New Mexico, 1999.
[11] G. Kim and E. Spafford. The Design and Implementation of
Tripwire: A File System Integrity Checker. In ACM Confer-
ence on Computer and Communication Security, 1994.
[12] J. Klensin. Request for Comment (RFC) 2821: Simple Mail
Transfer Protocol, April 2001.
[13] T. Lane. Machine Learning Techniques for the Computer
Security Domain of Anomaly Detection. PhD thesis, Purdue
University, 2000.
[14] Y. Li. Email archive intrusion detection systems. Master’s
thesis, Carleton University, 2005.
[15] R. Maxion and T. Townsend. Masquerade Detection Using
Truncated Command Lines. In DSN ’02: Proceedings of the
2002 International Conference on Dependable Systems and
Networks, 2002.
[16] J. Myers and M. Rose. Request for Comment (RFC) 1939:
Post Of(cid:2)ce Protocol(cid:151)Version 3, May 1996.
[17] M. Oka, Y. Oyama, H. Abe, and K. Kato. Anomaly
Detection Using Layered Networks Based on Eigen Co-
occurrence Matrix.
In RAID 2004 Proceedings, volume
3224 of LNCS, pages 223(cid:150)237. Springer-Verlag, 2004.
[18] B. Ramsdell. Request for Comment (RFC) 2633: S/MIME
Version 3 Message Speci(cid:2)cation, June 1999.
[19] M. Roesch. Snort(cid:151)Lightweight Intrusion Detection for
Networks. In Proceedings of LISA ’99: 13th Systems Admin-
istration Conference, Seattle, WA, November 7(cid:150)12 1999.
[20] M. Schonlau, W. DuMouchel, W. Ju, A. Karr, M. Theus,
and Y. Vardi. Computer intrusion: Detecting masquerades.
Statistical Science, 16(1):1(cid:150)17, 2001.
[21] A. Somayaji. Operating System Stability and Security
through Process Homeostasis. PhD thesis, University of
New Mexico, 2002.
[22] A. Somayaji and S. Forrest. Automated Response Using
System-Call Delays. In Proceedings of the 9th USENIX Se-
curity Symposium, Denver, CO, August 14(cid:150)17, 2000.
[23] The Spamhaus Project. http://www.spamhaus.org, 2005.
[24] University of Washington.
IMAP information center.
http://www.washington.edu/imap/, 2005.
[26] M. Wong and W. Schlitt.
[25] K. Wang and S. J. Stolfo. Anomalous Payload-based Net-
work Intrusion Detection. In RAID 2004 Proceedings, vol-
ume 3224 of LNCS, pages 203(cid:150)222. Springer-Verlag, 2004.
Internet draft: Sender pol-
icy framework (SPF) for authorizing use of domains in e-
mail, version 1, June 6 2005. http://www.ietf.org/internet-
drafts/draft-schlitt-spf-classic-02.txt.
[27] P. Zimmerman. The of(cid:2)cial PGP user’s guide. MIT Press,
Cambridge, MA, 1995.
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:13:33 UTC from IEEE Xplore.  Restrictions apply.