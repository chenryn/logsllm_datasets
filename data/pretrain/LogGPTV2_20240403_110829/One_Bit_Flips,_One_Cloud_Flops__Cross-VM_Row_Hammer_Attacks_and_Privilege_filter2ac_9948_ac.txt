ﬁve nodes in the connected components of G2 are b15,
b16, b17, b18 and b20. They are connected by four
triangles: (b15,b18,b20), (b16,b17,b20), (b16,b18,b20),
(b15,b17,b20).
Following the discussion in the pre-
vious paragraph, four XOR-schemes should be used
24  25th USENIX Security Symposium 
USENIX Association
6
to index banks: b20 ⊕ b15, b20 ⊕ b16, b20 ⊕ b17 and
b20 ⊕ b18. However, because b20 ⊕ b15 and b20 ⊕ b16
implies LATENCY({b15,b16,b20}) =1, but a triangle
(b15,b16,b20) doesn’t exist in our analysis, some of these
XOR-schemes need to be merged together. To complete
the analysis in the graph, we categorize nodes accord-
ing to the set of nodes they are connected with. For
instance, b20 is connected with {b15,b16,b17,b18} (i.e.,
C(b20) =b 15,b16,b17,b18). The node with the most
connected neighbors is the one involved in both XOR-
schemes (in this case, b20) and therefore is a row bit. The
nodes with the same set of neighboring nodes are used in
the same XOR-scheme: b15 and b16 are both connected
with {b17,b18,b20}, and therefore one XOR-scheme will
be b15 ⊕ b16 ⊕ b20; similarly, the other XOR-scheme will
be b17 ⊕ b18 ⊕ b20.
Detecting bank bits in more XOR-schemes.
If a bit
is involved in more than two XOR-schemes, we can ex-
tend the method for detecting two XOR-schemes to de-
tect it. Particularly, on the subset of nodes V − R − C,
we enumerate all combination of four bits and look for
LATENCY({bi,b j,bk,bl}) = 1, which, following the rea-
soning steps in the prior paragraph, suggests that one of
the bits is involved in three XOR-schemes. Again, we
need to study the connected components to determine
the conﬁguration of actual XOR-schemes, which can be
done by following a similar process as for two-XOR-
scheme-bit detection. For concision we don’t repeat the
discussion here. However, it is worth noting we have not
observed any bits that are used in more than two XOR-
schemes on the machines we have tested.
4 Effective Row Hammer Attacks
In this section, we discuss several facets of constructing
effective row hammer attacks in practice.
Row hammer code with or without mfence. prior
work has proposed two ways of conducting row ham-
mer attacks, pseudo code shown in Figure 4. Particularly,
in each loop of the attacks, after accessing two memory
blocks in two rows and ﬂushing them out of the cache us-
ing clflush instructions, the attack code can choose to
proceed with or without an mfence instruction before en-
tering the next loop. The beneﬁt of having an additional
mfence instruction is to force the clflush instructions
to take effect before the beginning of the next loop, while
the downside is that it will slow down the execution of
the program and thus reduce the frequency of memory
accesses. We will empirically evaluate the two methods
in Section 6.2.
Deterministic row hammer attacks. Prior studies [5]
on row hammer exploitation randomly selected DRAM
rows to attack and counted on luck to ﬂip memory bits
loop:
mov (X), %r10
mov (Y), %r10
clflush (X)
clflush (Y)
jmp loop
loop:
mov (X), %r10
mov (Y), %r10
clflush (X)
clflush (Y)
mfence
jmp loop
(a) clflush w/o mfence
(b) clflush w/ mfence
Figure 4: Pseudo code for row hammer attacks.
that happen to alter page tables. These approaches are
non-deterministic and thus hard to guarantee success. In
our paper, we propose to search exploitable bit ﬂips that
can be repeated in multiple runs. As will be discussed in
Section 5, only bit ﬂips at certain positions within a 64-
bit memory block can be exploited; also, only a fraction
of them are repeatable in row hammer attacks (we will
empirically evaluate the fraction of vulnerable bits that
are both exploitable and repeatable in Section 6.2.3). As
such, on those less vulnerable machines, especially cloud
servers, it is important to design methods to exhaustively
search for vulnerabilities so that at least one of the vul-
nerable bit satisﬁes all the requirements.
Exhaustive row hammering. To enumerate as many
DRAM rows as possible to look for vulnerable bits, we
developed the following data structure and algorithm to
conduct double-sided row hammer attacks on every row
in every bank: Especially, as will be shown later in
Table 1, some of the 12 least signiﬁcant address bits are
bank bits, which means the same 4KB memory page are
not always mapped to the same row. As such, we de-
signed a new data structure to represent memory blocks
in the same row. Our key observation is that cache-line-
aligned memory blocks are always kept in the same row
for performance reasons. We call a cache-line-aligned,
64B in size, memory block a memory unit, which is the
smallest unit of memory blocks for the purpose of book-
keeping. We design a three dimension array: The ﬁrst di-
mension represents the bank index, the second dimension
is the row index and the third dimension stores an array
of memory units mapped to the same row. For example,
on a Sandy Bridge processor with 2 memory channels, 1
DIMM per channel, 1 rank per DIMM, and 8 banks per
rank (totally 4GB memory), there are 24 = 16 elements
(i.e., 2 × 8 banks) in the ﬁrst dimension, 216 = 65536
elements (i.e., number of rows per bank) in the second
dimension, 27 = 128 elements (i.e., number of memory
units per row) in the third dimension.
Another observation we had for conducting efﬁcient
row hammer attacks is to avoid hammering on rows in se-
quential order. According to our experiments, a recently-
hammered row is harder to induce bit ﬂips when its
neighboring rows are hammered. This is probably be-
USENIX Association  
25th USENIX Security Symposium  25
7
cause the cells in this row has been recently charged
many times. Therefore, we targeted each row in a pseu-
dorandom order. Specially, we ﬁrst generate a pseudo-
random permutation of all rows in a bank, and then se-
quentially test one row from each bank from the ﬁrst to
the last one and start over, where rows in the same bank
are tested according to the pseudorandom order.
If no vulnerable bits were found in the ﬁrst round
of the attack, one can reboot the VM to obtain access
to other DRAM rows and conduct row hammer attacks
again. Even in public clouds, we found that rebooting
the guest VMs will relaunch the VM on the same host,
and possibly assigned to different (but largely overlap-
ping) physical memory. As such, although each VM only
has access to a small fraction of DRAM banks and rows,
using such an approach will greatly increase the tested
portion of the DRAM. We will empirically evaluate this
technique in Section 6.2.
Safe mode. To safely conduct row hammer attacks with-
out crashing the co-located VMs and the host machine,
we optionally conduct the row hammer attacks in a safe
mode: In Figure 5, only when we control all memory
units in row n, n +2 and n−2 do we conduct the double-
sided row hammer attacks on row n + 1 and n− 1. As
rarely would the row hammer attacks affect rows beyond
row n± 2, this method provides a safe mode to conduct-
ing row hammer attacks, which is particularly useful in
attacks conducted in public clouds.
Figure 5: A safe mode of row hammer attacks.
5 Cracking Memory Isolation
In this section, we present methods to conduct cross-
VM attacks enabled by DRAM row hammer vulnerabili-
ties, which will allow a malicious paravirutalized VM to
break VM isolation and compromise integrity and conﬁ-
dentiality of co-located VMs or even the VMM.
5.1 Xen Memory Management
Xen paravirtualization keeps three types of memory ad-
dress spaces: a virtual address space for each process, a
pseudo-physical address space for each VM, and a ma-
chine address space for the entire physical machine [17].
To be compatible with native OS kernels, a paravirtual-
ized OS kernel (e.g., already a part of mainstream Linux
kernel) maintains a contiguous pseudo-physical mem-
ory address space; the mapping between pseudo-physical
memory addresses and virtual addresses are maintained
at page-granularity, following the same semantic as its
non-virtualized counterparts. The major difference in
a Xen paravirtualized VM is the page frame number
(PFN) embedded in a page table entry (PTE): it is ﬁlled
with machine addresses rather than pseudo-physical ad-
dresses. This is because Xen paravirtualization does not
maintain a shadow page table in the hypervisor [17]. Ad-
dress translation conducted by the CPU only traverses
one layer of page tables. Such a memory management
mechanism is called direct paging [11]. The mapping
between each VM’s pseudo-physical memory pages to
machine memory pages is also kept in the hypervisor, but
guest VMs are allowed to query the mapping information
by issuing hypercalls (e.g., HYPERVISOR memory op()).
The mapping between virtual memory pages, pseudo-
physical memory pages and machine memory pages are
illustrated in Figure 6.
To enable security isolation, the Xen hypervisor keeps
track of the type of each memory page: page tables, seg-
ment descriptor page and writable pages. The hypervi-
sor enforces an invariant that only writable pages can be
modiﬁed by the guest VM. Whenever a page table hierar-
chy is loaded into the CR3 register upon context switch,
the hypervisor validates the memory types of the page ta-
bles to ensure the guest VM does not subvert the system
by modifying the content of the page tables. On Intel’s
x86-64 platforms, the page tables are organized in four-
levels: PGD, PUD, PMD, PT3. Particularly of interest to
us are the entries of PMD and PT, which are dubbed page
directory entries (PDE) and page table entries (PTE), re-
spectively. The structures of PDEs and PTEs are illus-
trated in Figure 7.
It is worthwhile noting that besides Xen paravirtual-
ization technology, recent Xen hypervisors also support
hardware-assisted virtualization, dubbed HVM in Xen’s
term [18]. The memory management in Xen HVM is dif-
ferent from that in PVM in many aspects. Most notably,
in HVM, guest VMs can no longer learn the physical ad-
dress of the pseudo-physical memory pages, due to the
intervention of a second-layer page table that is only ac-
3We use Linux terminology in this paper. Intel manuals call them page
map level 4 (PML4, or PGD), page directory pointer tables (PDPT, or
PUD), page directory tables (PDT, or PMD), page tables [6]. In Xen’s
terminology, they are called L4, L3, L2 and L1 page tables [11].
26  25th USENIX Security Symposium 
USENIX Association
8
bit.
following primitives:
• Addr(v) returns the machine address of a vulnerable
• Offset(v) returns the bitwise offset within a byte of
a vulnerable bit (the right-most bit has an offset of 0).
• Direction(v) could be one of 0 → 1, 1 → 0, or 0 ↔
• Position(v) =64 − ((Addr(v) % 8) × 8 + 8 −
Offset(v)), indicating the index of the bit in a 64-
bit aligned memory block (e.g., a page table entry).
The right-most bit has a position of 0.
1, indicating the most likely bit ﬂip directions.
of a page p.
• Virt(p) returns the virtual address of the beginning
• Differ(P1,P2) returns a set of indices of bits in
which the machine addresses of two memory pages
P1 and P2 differ.
Specially, when the vulnerable bit v satisﬁes
Position(v) ∈ [12,M], where M is the highest bit of
the physical addresses on the target machine, the attacker
could exploit the ﬂippable bit to replace an existing page
table with a carefully-crafted page table containing en-
tries pointing to physical pages external to the guest VM
via the following steps (Figure 8):
Figure 8: Page table replacement attacks.
• Step 1: In the attacker’s VM, allocate and map one
virtual memory page (denoted p), so that the vul-
nerable bit v has the same page offset as one of the
PFN bits in p’s corresponding PDE. More accurately,
Virt(p)/2(9+12) ≡ Addr(v)/8 mod 29. This can be
achieved by allocating 1GB (i.e., 512× 512× 4KB)
virtual pages in user space and map one of the pages
that satisﬁes the requirement.
• Step 2:
In guest kernel space, select two phys-
ical pages, P1 and P2, where Differ(P1,P2) =
is the
{Position(v)} and Position(v) of P1
(e.g., 0 if
original state of
the vulnerable bit
Figure 6: Memory management of Xen paravirtualized
VMs.
(a) PDE
(b) PTE
Figure 7: Structures of PDE, PTE.
cessible by the hypervisor. As such, much of the attack
techniques discussed in this section only works in Xen
paravirtualized machines.
5.2 Page Table Replacement Attacks
In this section, we present a method for a malicious guest
VM to exploit the bit ﬂips induced by row hammer at-
tacks to gain arbitrary accesses to memory on the host
machine. Instead of relying on an unreliable trial-and-
error approach used in prior studies [4, 20], in which a
large number of page tables are sprayed to increase the
chances of bit ﬂips taking place in PTEs, we propose a
novel approach that, given a set of DRAM bit ﬂips that
an attacker could repeatedly induce, deterministically ex-
ploits the repeatable bit ﬂips and gains access to physical
memory pages of other VMs or even the hypervisor.
To access the entire machine address space with both
read and write permissions, the attacker VM could do
so by modifying a page table entry within its own VM
so that the corresponding virtual address could be trans-
lated to a machine address belonging to other VMs or
the hypervisor. However, direct modiﬁcation of PTEs in
this manner is prohibited. Every PTE update must go
through the hypervisor via hypercalls, and thus will be
declined. We propose a novel attack that achieves this
goal by replacing the entire page tables in a guest VM
without issuing hypercalls, which we call the page table
replacement attacks.
For the convenience of discussion, we ﬁrst deﬁne the
USENIX Association  