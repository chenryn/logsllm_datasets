produce all or a portion of the data that will ultimately be 
visualized.  In other cases, the producer will consist of only an 
information system that generates the data. No human is directly 
involved in data production (e.g. a sensor network).  The producer 
may be co-located with the consumer, but it is more likely that the 
producer will need to communicate the data to the consumer via a 
communication channel.   
Figure 1. Generic producer-consumer information visualization system. 
Attacks influence any component, but the human end-user is the ultimate target. 
Each human and machine component processes data using 
subcomponents with finite resources.  Attacks can target any of 
these resources.  For the human, we chose to model these 
resources based on the Model Human Processor (MHP) 
architecture:  short term memory, long-term memory, cognition as 
well as perception and motor processing [19].  For each machine, 
we used the common information systems model of machine 
resources:  processing, short-term storage (RAM) and long-term 
storage (typically optical or magnetic storage media).  The human 
and its associated information system interact through the classic 
human-computer interaction boundary.  The human utilizes 
vision, hearing, speech and motor actions to interact with the 
information system.  Other senses (e.g. touch and smell) are not 
shown in the model, due to the limited availability of effective 
interface technologies.  The information system provides related 
input/output devices that support each of these human capabilities 
(e.g. CRT, speakers/sound sub-system, microphone, keyboard and 
mouse).  
4 
INFORMATION VISUALIZATION ATTACK TAXONOMY 
While attacks may range from overt to subtle, they share several 
common properties:  they attempt to influence how you visualize, 
what you visualize or when you visualize.  To this end, we present 
a taxonomy of attacks that follows the flow of information from 
human consumption back to initial data generation.  We have 
developed a comprehensive taxonomy of attacks, but for purposes 
of this paper, we provide a representative overview of the 
taxonomy and illustrative examples to highlight the vulnerabilities 
and surprisingly effective exploits of traditional information 
visualization systems.  We have chosen to follow the information 
flow from the human back towards data generation, believing that 
Target 
Attacks 
Possible Countermeasures 
Perceptual 
Buffers 
Force desired colors to be used  
Force smaller font 
Review annotation algorithms 
Limit range of colors, sizes 
allowed. 
Review preattentive literature 
for best interface objects  
Short Term 
Display updates too rapidly 
Compensate with buffers in 
visualization system. 
Memory 
Long Term 
Aggregation hides important detail 
Scaling lacks detailed enough resolution 
Attack paging of visualizations 
Lack of long term overviews  
Background images of 
historical data 
Use of paged and side-by-side 
images and overlays. 
Create smart book of visual 
signatures 
Processing 
Cognition 
Cognitive Processing 
Degrade trust in system 
Attack when human is not watching 
Cry wolf 
Visualization software causes poor 
conceptual model 
Display visualization’s source 
data 
Create visual log files 
Ambient Visualization 
Input 
Vision 
Causing occlusion of visual elements to 
conceal or manipulate visual 
presentation  
Inserting random noise into visualization 
Force less detailed scaling  
Occlusion of visualization elements  
Color choices impact color blind user 
Develop alternative 
visualizations and views of 
data 
Include customizable filters 
Provide multiple coordinated 
views of data 
Choose smart default settings 
Human 
Output 
Motor 
Cause alert which forces user motor 
response (e.g. clicking an OK button) 
Force the user to scroll  
UI requires unnecessary actions 
Review improved triggering 
mechanisms 
Explore alternative interface 
designs 
Table 1: Denial of information attack taxonomy illustrating representative attacks by model human processor target 
this is an intuitive and natural way to illustrate an interesting 
spectrum of attacks. We will use the components along the path 
(see Table 1) to illustrate how and when attacks may manifest. 
Attacks may influence any component, but the human end-user is 
the ultimate target.   
4.1 
ATTACKING THE HUMAN 
Humans are vulnerable targets with finite resources to perceive, 
interpret and act upon information.  Attackers consume these 
resources through information visualization systems by altering 
the accuracy, completeness, consistency and timeliness of 
information flows.  By focusing on human limitations these 
alterations 
create 
incomplete, 
ambiguous 
or 
incorrect 
visualizations that result in frustrated analysis, reasoning and 
decision-making. 
These 
malicious 
visualizations 
increase 
complexity, alter or destroy patterns, distort sequences and disrupt 
exploratory tasks which in turn may cause confusion, 
disorientation, disbelief, distraction or lack of trust. While not 
necessary, the effectiveness of attacks can be enhanced by 
specifically targeting individuals and their unique set of 
weaknesses and predispositions (consider our colorblind user 
from Section 1).  The following sections examine attacks against 
the human using a slightly streamlined version of the Model 
Human Processor (MHP) model of cognitive processing, memory, 
vision and motor resources [18]. 
4.1.1 
Attacking Human Memory 
Humans possess a limited ability to remember information over 
short and long periods of times.  Arguably, humans can remember 
7 +/- 2 “chunks” over a short period [20].  Regardless of the exact 
number, the human has a finite capability to retain and recall 
information.  By exploiting this limitation an attacker can greatly 
increase their likelihood of success. These attacks may manifest 
themselves gradually such that the user fails to see the pattern.  
Alternatively attacks may target the users ability to recall 
legitimate activity to the detail required to detect malicious 
activity.  Figure 2 illustrates this limitation.   This system, 
designed by the authors, attempts to provide a semantic zooming 
capability [21] for network traffic by allowing the user to view 
network information at variety of different scales from course 
grain overviews to high-resolution detail.  The user selects the 
level of resolution using the scale on the right of the interface.     
Despite this attempt at allowing users to compare network traffic, 
it suffers from limitations of human memory.  In our tests using 
the current configuration, users simply could not retain the 
context from one level to the next. Attackers could clearly exploit 
this weakness.  To the best of our knowledge, no security 
visualization systems directly support the ability to closely 
compare images for subtle differences required to detect this class 
of attack.  While Unix systems can use the diff command to 
compare text files, there is no equivalent visual diff.  Likewise, 
there are no security visualization systems that allow users to 
seamlessly compare images in a side-by-side manner frustrating 
effective comparison. 
4.1.2 
Attacking Cognitive Processing 
Cognitive 
processing 
deals 
with 
how 
humans 
interpret 
information.  By exploiting weaknesses in this processing, an 
attacker can mislead the human and obscure or camouflage 
attacks as well as lead users to incorrect conclusions, perhaps 
even frustrating the users to the point they abandon use of the 
system altogether.    Attacks can target attention, perception of 
time, decision-making, pattern recognition and perception of color 
and shape.  Attackers may increase cognitive complexity, add 
spurious packets to eliminate suspicious outliers or demand the 
attention of the user.  The following sections illustrate 
representative cognitive processing attacks against human 
attention and perception. 
4.1.2.1 
Attention 
By their nature, information visualization systems require human 
attention.  Depending on the design of the visualization and user 
interface the system may likely be tightly coupled with the user. It 
is impossible for a user to maintain 100% focus on their 
visualization system for long periods of time.  Even a distraction 
lasting a few seconds can cause a user to miss key information.  
Alternatively, the attacker may overwhelm the user by demanding 
too much attention. 
“Cry Wolf” Attack:  From the classic children’s story, an attacker 
can trigger activity, which in a normal scenario would require user 
attention.  As a result, if the system “cries wolf” enough times the 
operator will begin to lose trust and may disable the system 
altogether.  As an example, an attacker may subvert the snort 
intrusion detection system by creating packets that trigger alerts 
[22].  Snort alerts the user when it detects a signature in network 
activity that matches a known attack in its database. The snot tool 
is specifically designed to attack users through snort [23]. 
Utilizing snort’s database of signatures, snot can generate network 
traffic that matches alert rules.  Using snot, an attacker can trigger 
an alert at will.  
Displacement 
Attack: 
Displacement 
attacks 
occur 
in 
visualizations where incoming data visually displaces older 
information.  These visualizations are particularly susceptible to 
the limitations of human attention.  Figure 3 is a network 
monitoring and intrusion detection visualization from the rumint 
system that displays network traffic in a scrolling display [24].  
The bits of packets are plotted on the horizontal axis.  As each 
packet arrives it is plotted one pixel lower on the vertical axis.  
When the display reaches the bottom of the display window, it 
begins plotting at the top of the display, overwriting previous 
contents.  During the past year we have used this system in two 
operational settings.  The first was with the Georgia Tech 
Figure 2.  Semantic zoom visualization of network traffic.   
Honeynet and the second was with a dedicated commercial 
Internet Service Provider (ISP) residential connection.  In both 
instances, the network connection is not used for any legitimate 
traffic thus only malicious activity is seen.  Network packets 
typically arrive in small groups averaging one to five minutes per 
packet.  Scrolling in these instances is typically not a problem, as 
approximately 24 hours of traffic can be seen before older 
information is overwritten (although we have seen spikes in traffic 
where network activity has been significantly greater).  To test the 
time required for an attacker to scroll information off the page we 
conducted several experiments and found that it required only 2-3 
seconds to overwrite information on one of our research machines 
(AMD 2500+, Windows XP, 1GB RAM, 100MB Ethernet).  It is 
important to note that the theoretical limit based on network 
bandwidth alone is on the order of ten-thousandths of a second.  
We believe that a small lapse in attention on the order of seconds, 
even by a dedicated observer, is a reasonable possibility that an 
attacker may exploit to destroy traces of malicious activity. 
4.1.3 
Attacking Visual Perception 
Information visualization systems, and the great majority of 
interactive computing applications, rely heavily upon the human’s 
perceptual capabilities.  Visual perception is the processing of 
input stimuli based upon reflected wavelengths of light from 
which our brain constructs internal representations of the outside 
world [25].   By taking advantage of the strengths and weaknesses 
of visual perception, an attacker can alter this internal 
representation.  Consider the optical illusions from classic 
psychology.  Given the same input image, different subjects might 
interpret the picture differently.  In other examples, subjects are 
unable to correctly judge spatial relationships.  See the work by 
Bach for 52 online examples [26].  Examples of other known 
weakness include a blind spot in the visual field, motion induced 
blindness [27] and a limited ability to discriminate between 
colors.  Even adaptations, which can be considered strengths in 
some instances, become weaknesses when manipulated by an 
adversary, such as preattentive processing [28] and afterimages 
caused by light/dark adaptation [29].  Beyond simple 
manipulation, even more aggressive attacks are possible.  Small 
delays in virtual reality visualization systems can cause 
queasiness [30] and fifteen to twenty frames per second of certain 
images can trigger photosensitive epilepsy. (see Section 4.1.5) 
Color Mapping Attack:  The color mapping attack targets the use 
of color in visualizations.  Humans have a limited ability to 
discriminate between colors, on the order of 300,000 colors [29].  
Not all of these colors are interpreted as equivalent values, some 
are given heavier weight or draw more attention than others, and 
because color ranges are not uniform, normalization is used to 
help counteract the effect.  See the work of Rogowitz and Treinish 
for an excellent discussion [18].  Most computing systems can 
present far more colors than a human can discern, 224 possible 
colors is typical on today’s hardware.  Depending on the 
visualization system in use, features of the data are mapped, in a 
variety of ways, to colors used in the display.  Limited display 
colors allow an attacker to hide activity due to aggregation.  Large 
numbers of colors exceed or degrade the ability of humans to 
glean appropriate insights.  It is due to these system presentation 
and human interpretation gaps that users are vulnerable, 
particularly when the system provides only a limited ability to 
customize colors for given tasks. Figure 4 comes from a 
visualization system created by the authors.  It maps byte values 
from binary files to 256-level gray-scale pixels.  In this example, 
the figure shows the file structure of two jpeg files.  The left 
image is unaltered and the right image contains a steganographic 
message.  Despite our ability to distinguish hundreds of thousands 
of colors, in our experiments, users were unable to find the 
modified bits.  For future work we plan to pursue a visual diff 
tool, but the fact remains that for even a small number of colors, 
humans have difficulty in detecting differences.  This weakness 
allows malicious entities to operate below the detectable 
threshold.  Even the addition of a color legend is of little value. In 
a separate experiment we plotted network packets on a scatter plot 
using a commercial system.  Even with only 100 different colors 
mapped to packet features (colors were chosen by the system) and 
Figure 3:  Binary rainfall visualization of network 
packets. (One packet per row) 
Figure 5: Autoscale and motor resources attack example 
(overview) 
Figure 4: Binary visualization of two JPEG files.  The 
left image is unaltered and the right image contains a 
steganographic message.  Bytes from files are mapped to 
256-level grayscale pixels. 