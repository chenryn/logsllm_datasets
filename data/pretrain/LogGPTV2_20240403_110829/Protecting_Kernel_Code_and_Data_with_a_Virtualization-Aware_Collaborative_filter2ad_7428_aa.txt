title:Protecting Kernel Code and Data with a Virtualization-Aware Collaborative
Operating System
author:Daniela Alvim Seabra de Oliveira and
Shyhtsun Felix Wu
2009 Annual Computer Security Applications Conference
Protecting Kernel Code and Data with a
Virtualization-Aware Collaborative Operating
System
Daniela Alvim Seabra de Oliveira and S. Felix Wu
Department of Computer Science
University of California at Davis
{oliveira,wu}@cs.ucdavis.edu
Abstract—The traditional virtual machine usage model advo-
cates placing security mechanisms in a trusted VM layer and
letting the untrusted guest OS run unaware of the presence of
virtualization. In this work we challenge this traditional model
and propose a collaboration approach between a virtualization-
aware operating system and a VM layer to prevent tampering
against kernel code and data. Our integrity model is a relaxed
version of Biba’s and the main idea is to have all attempted
writes into kernel code and data segments checked for validity
at VM level. The OS-VM collaboration bridges the semantic gap
between tracing low integrity objects at OS-level (ﬁles, processes,
modules, allocated areas) and architecture-level (memory and
registers). We have implemented this approach in a proof-
of-concept prototype and have successfully tested it against
6 rootkits (including a non-control data attack) and 4 real-
world benign LKM/drivers. All rootkits were prevented from
corrupting kernel space and no false positive was triggered
for benign modules. Performance measurements show that the
average overhead to the VM for the OS-VM communication is
low (7%, CPU benchmarks). The greatest overhead is caused by
the memory monitoring module inside the VM: 1.38X alone and
1.46X when combined with the OS-VM communication. For OS
microbenchmarks the slowdown for the OS-VM communication
was 1.16X on average.
I. INTRODUCTION
Since the beginning of this decade virtual machines have
been extensively used for security-related applications such
as intrusion detection systems, malware analyzers, secure log-
ging and post-attack recovery using replay capabilities. This
popularity can be attributed to the various desirable properties
VM’s offer [40]: environment isolation, OS and architecture
extensibility, hardware multiplexing and easy manipulation of
its internal state.
The traditional usage model, proposed by Chen and Noble
in a seminal paper in 2001 [9], advocates placing security
mechanisms in the VM layer (which has complete control of
the system resources) and letting the guest OS run unaware
of the presence of virtualization. The threat model assumed is
that the VM is trustworthy and the OS running on top of it
can be easily compromised by malware. The vast majority
of security solutions presented in the literature employing
virtualization [4], [12], [14], [17], [18], [22], [23], [25], [27],
[37], [38], [46], [49] does not count on the guest OS to enhance
system security. A few solutions addressing active monitoring
[32], [39], [50] employ limited OS involvement, which is
accomplished by the introduction of hooks in certain points
of kernel code. It does not represent, however, an active and
on-the-ﬂy OS collaboration.
In this work we challenge the use of this traditional model
for security applications that rely heavily on inspecting or
manipulating OS abstractions. Security services operating only
at the architectural level (VM) are limited due to the semantic
gap between the VM layer and the requirements of the security
solution to be provided, which usually involve knowledge of
OS-level information. Also, building a fully transparent, secure
and isolated VM (for defense solutions and also for malicious
actions) may be fundamentally infeasible, as shown by recent
work [16]. Malware can present itself as a VM rootkit to
conceal its actions and effects [26], [36] and detect it is running
in a VM and change its behavior accordingly [15]. VM’s
can be detected because the majority of them have not been
designed with transparency as a requirement [15] and because
they interface with the Intel IA-32 ISA, which is not fully
virtualizable [34]. Even with the proposed architecture exten-
sions to make x86 processors fully virtualizable, virtual and
physical environments differ in their timing characteristics and
hardware conﬁgurations. For example, virtual environments
will present large variances in the execution time of certain
instructions when compared to native hardware. In the long
run, attackers will operate regardless of the presence of VM’s
[16].
We believe that for certain types of security requirements
a virtualization-aware and collaborative OS can provide, to-
gether with the VM layer, ﬁne-grained, ﬂexible and stronger
system protection. The advantage of this model is combining
the isolation and hardware extensibility properties of VM’s
with the best possible view of OS objects in an architec-
ture where OS and VM actively interface to achieve the
requirements of a security solution. The ﬁrst requirement of
this architecture and interface is that an attacker should not
compromise the integrity (code and data structures) of the
collaborating OS running on top of the VM layer. Also,
an attacker should not be able to modify the information
exchanged between OS and VM while interfacing with one
another.
In this paper we propose a collaboration between a
virtualization-aware operating system and a VM layer to
protect kernel code and data integrity. In our solution we
1063-9527/09 $26.00 © 2009 IEEE
DOI 10.1109/ACSAC.2009.49
451
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:11:22 UTC from IEEE Xplore.  Restrictions apply. 
employ a relaxed version of Biba’s integrity model [6] on an
architecture where a virtualization-aware OS and a VM layer
can actively collaborate to enforce the model. All attempted
writes into kernel code and data segments are checked for
validity at the architectural level. If the instruction attempting
the write operation is low integrity and the memory locations
in kernel code or data segments to be written are high integrity,
the write is aborted with the VM issuing a General Protection
fault. This terminates the process associated with the write
operation, but allows the system to continue its execution with
its integrity preserved.
In our integrity model we enforce that no subject can write
objects of higher integrity (The star Integrity Axiom). We
adopt two levels of integrity: trusted (high) and untrusted
(low). Immediately after boot, we consider everything in
kernel and user space as high integrity (establishment time).
After the establishment time, we consider every byte arriving
in the system through the network (main vector for attacks)
as low integrity, and we have the OS and VM to keep track
of how these bytes propagate into the system at the architec-
tural (memory and registers) and OS levels (ﬁles, processes,
modules and dynamically allocated areas). This dual-layer of
memory monitoring bridges the semantic gap between tracing
low integrity objects at OS-level and architecture-level.
We have implemented this approach as a proof-of-concept
prototype using Bochs [52] as the virtual machine layer and
the Linux operating system. It has been successfully tested
against 6 rootkits (including a non-control data attack) and 4
benign kernel modules and has not caused any false positives
or negatives.
This paper presents the following contributions:
(cid:129) We present a virtualization-aware architecture and in-
terface where the OS and a VM layer collaborate to
prevent integrity violations in kernel code and data by
enforcing Biba’s star (*) Integrity Axiom (no write up,
i.e, a low integrity subject does not write into a high
integrity object).
(cid:129) We implement this approach as a proof-of-concept pro-
totype using the Bochs Intel IA-32 emulator and Linux.
(cid:129) We evaluate this prototype against 6 rootkits and 4 benign
loadable kernel modules.
The rest of the paper is organized as follows. Section II
discusses attacks on kernel integrity. Section III presents our
integrity model and section IV describes the high-level view of
our approach. Section V details the design and implementation
of our architecture. Section VI presents our experimental
evaluation. In section VII we discuss the limitations of this
work and in section VIII related work. Our conclusions are
presented in section IX.
II. ATTACKS ON KERNEL INTEGRITY
Rootkits are a type of stealthy malware that enable attackers
who have gained administrator privileges or access to the
system (usually through vulnerability exploitation or social
engineering) to hide or covertly perform malicious actions and
maintain control of the system. They have been increasingly
used by attackers bundled with other type of malware such
as Trojans, droppers, bots and key loggers. Kernel rootkits
can corrupt, change, inﬂuence and add malicious behavior to
the OS kernel which compromises the integrity of the entire
system.
Preventing, detecting and recovering from kernel rootkit
attacks is difﬁcult given the complexity of kernel code and the
great number and variety of its data structures. This complexity
makes it harder to determine known kernel good states usually
employed in defense approaches. Attacks in the kernel can
succeed not only by adding or changing kernel code or altering
its control ﬂow, but also by tampering with certain key non-
control data structures. For instance, recent work [5] has
shown that an attacker can degrade system performance just by
tampering with the value of the zone table data structure and
can compromise kernel security functions by contaminating
the entropy pool. Further, an attacker has several avenues to
compromise kernel integrity: vulnerabilities in kernel code,
abuse of interfaces such as /dev/kmem [2], malicious loadable
kernel modules (LKM), hardware [13], virtual machines [26],
[36] and social engineering.
The solutions for kernel integrity defense presented in the
literature focus mainly on detection [3], [21], [22], [24], [25],
[31], [47] and most of them are not effective for detecting
attacks that involve value manipulation of kernel data struc-
tures [5]. The approaches addressing prevention rely on code
authentication [37], [38] or security policies made by an expert
that may fail to consider all possible data structures that can
be abused by an attacker [4], [18], [49].
III. THE INTEGRITY MODEL
Our defense approach against violations in kernel space has
the following goals: (i) prevent malicious tampering against
kernel code and data, (ii) for any given attempt to violate
kernel integrity, identify the process, ﬁle or kernel module
associated and also the source of the attack, (iii) after an
attempt, terminate the associated process or module, while
allowing the system to continue execution normally, (iv)
introduce minimal changes to the OS code and to the VM
architecture while keeping the performance overhead as low
as possible.
In our solution we have adopted a relaxed version of Biba’s
integrity model [6]. In this model, the Simple Integrity Axiom
states that a subject at a given level of integrity may not read an
object at a lower integrity level. The * (star) Integrity Axiom
states that a subject at a given level of integrity must not
write any object of higher integrity level. Adopting the Simple
Integrity Axiom in the context of OS’s is not practical given
their design: system calls, interrupt handlers and some kernel
threads, which we can consider as high integrity subjects, need
to access objects at various levels of integrity in the course of
their execution. The * (star) Integrity Axiom, on the other
hand, if properly enforced, can protect kernel code and data
from corruption and integrity violation (writes by subjects of
lower integrity).
In our approach, the subjects are instructions at the archi-
tectural level and processes and functions of loadable kernel
modules (LKM’s) at the OS level. The objects are the kernel
452
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:11:22 UTC from IEEE Xplore.  Restrictions apply. 
OS
(1) Software interrupt 
Request
parameters
CPU
GP registers
Kernel
Write
Read
(2) Invokes
VM
(3) Get parameters
(5) Return value
OS Request 
Manager
Shadow Memory
(4) Inspect and update
Fig. 1. OS-VM communication
code and data segments at architectural level and ﬁles and
dynamically allocated kernel memory at OS level. Immediately
after the boot sequence (establishment
time) we consider
everything in system memory and ﬁle system as trusted or
high integrity. After the establishment time, we consider as
untrusted or low integrity every byte arriving in the system
from the Ethernet device. We have adopted this deﬁnition of
trust because the network is the main attack vector for several
types of malware.
IV. HIGH-LEVEL VIEW
In our approach, to preserve kernel integrity, we need to
keep track of low integrity data at the OS and the architectural
level. To accomplish this we need close cooperation between
OS and VM: the VM cannot track down the propagation of
low integrity information at the level of ﬁles, processes and
modules as they are subjects managed by the OS. The OS, on
the other hand, cannot manage the propagation of untrusted
bytes inside memory and registers.
At
the architectural
level (VM) we keep track of how
network bytes propagate into the system memory (including
registers and memory from external devices). At the OS level
we keep track of ﬁles that are written with low integrity bytes,
processes and modules whose object code is low integrity and
areas in the kernel allocated by low integrity subjects.
The OS down-calls the VM through an unused software
interrupt (vector 15, reserved by Intel) called at certain points
during system execution to request information from the VM
about the integrity level of its objects and to pass information
to the VM regarding boundaries of data structures and implicit
propagation of low integrity data among OS objects that should
be mirrored at the architectural level. The request parameters
are passed in general purpose registers in an approach similar
to what is done for system calls. Upon executing such in-
struction, the CPU invokes the OS Request Manager module
to treat the request. Depending on the request identiﬁcation
number, this module reads the request parameters from general
purpose registers and may need to inspect internal VM state
to serve the OS request. It returns information to the OS
by writing into general purpose registers. Figure 1 illustrates
this communication. The VM notiﬁes the OS about integrity
violations using exceptions.
A. Tracking Low Integrity at the VM Level
We use a memory monitor module running in the VM to
keep track of how network bytes and their sources propagate
into the system memory,
including the register bank and
memory from external devices such as the network card. We
make use of a shadow memory space and a shadow register
bank to store information about the propagation of network
bytes in our system. Each component of this shadow storage
area has a 1:1 correspondence with the real component in the
system architecture. The network byte propagation information
is a set of integers representing the unique identiﬁcation of
their sources. Each network source is characterized by an IP
address and a port number. In our approach every time the
VM Ethernet card receives a frame, we insert a new entry for
the associated network source in our system if this is the ﬁrst
frame being received from the source. Then the frame bytes are
stored into the network device memory and the identiﬁcation
number of their sources is stored into the shadow memory of
the card at the same locations where the bytes were stored.
The memory monitor can thus keep track of how these bytes
propagate into the real system memory and registers as the
CPU reads, moves and processes them. Wherever these bytes
(and also their derived bytes) are stored, we can ﬁnd their
sources at our shadow memory space.
For example, let us suppose that byte 10 coming from
network source 1 is copied from the Ethernet card to user
space at memory location 1024. Then the system receives
byte 20 from network source 2 which gets stored into register
AL. If the CPU executes an instruction that adds register AL
to memory location 1024, and stores the result into memory
location 2048, the ﬁnal state of real and shadow memory will
be as illustrated in Figure 2. Byte 30 at memory location 2048
is considered to be originated from network sources 1 and 2,
and we store the union of the network source set associated
with bytes 10 and 20 to the shadow memory at location 2048.
When a memory location is overwritten with a byte that is not
derived from any network source, we simply remove the set
of network source ID numbers that might be stored into the
corresponding location in the shadow memory.
...
10
0
Ethernet Card Memory
{1}
...
0
Shadow Ethernet Card Memory
...
...
10
1024
{1}
Physical Memory
...
...
1024
Shadow Physical Memory
ADD
...
UNION
...
20
AL
{2}
Shadow AL
Fig. 2. Memory Monitor
10
1024
...
30
...
2048
Physical Memory
{1}
...
{1,2}
...
1024
Shadow Physical Memory
2048
For each network source active in the system we keep a
453
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:11:22 UTC from IEEE Xplore.  Restrictions apply. 
counter for the number of shadow memory locations storing
its ID number. When this counter reaches zero, we remove
the network source entry from our system. The lifespan of
most network sources is very short [12], for example, data
from a TCP connection will soon die in the system after the
connection was served and data from new connections arrive.
B. Tracking Low Integrity Data at the OS Level
1) Files: Every time a ﬁle is written, the OS down-calls
the VM to request information about the integrity level of
the bytes that are about to be written. Upon receiving the OS
request, the VM checks in its shadow memory at the location
where these bytes are stored whether or not that location is
associated with a network source. A memory location that is
associated with a network source is considered low-integrity.
If at least one of the bytes is low integrity the VM informs
the OS that the ﬁle will be written with low integrity data.
2) Process: In our architecture we set the integrity of a
process based on the integrity of its executable ﬁle. When the
operating system is preparing to execute a certain process, it
also checks the integrity level of the ﬁle carrying the process
object code. If the ﬁle is low integrity, the process integrity
level is also set to low.
3) Modules: The OS manages module integrity in a way
similar to the method for processes: when a module is created,
the OS checks the integrity level of the ﬁle storing the
module’s object code. If the ﬁle integrity is low, so will be
the module’s. In this case the OS requests the VM to set the
memory region holding the module’s object code low integrity
in its shadow memory. This down-call is necessary because the
bytes from the module binary ﬁle could have returned to the
ﬁle system and upon re-entering main memory the VM will
not have information about their integrity level.
4) Dynamically Allocated Kernel Memory: The OS also
needs to inform the VM whenever a low integrity subject
(kernel thread or module function) allocates kernel memory
so that the VM can set the corresponding memory range in
its shadow memory as low integrity. The OS pass to the
VM the address of this allocated region and its size. As
these areas should be considered low integrity, writes by low
integrity objects into them should not be considered a kernel
integrity violation. This allows a low integrity subject to be
able to write into their own allocated kernel memory regions.
Upon receiving the information about the new low integrity
kernel memory region, the VM updates its shadow memory
accordingly, i.e., the allocated memory region is marked as
low integrity and is associated to the same network source
belonging to the subject that allocated the area. When kernel
memory is freed the OS down-calls the VM so that
the
integrity level of such areas are set to high.
V. DESIGN AND IMPLEMENTATION
We have implemented a proof-of-concept prototype for this
architecture using the Bochs IA-32 emulator [52] as our hosted
VM and Linux 2.4.21 as the collaborating guest OS. We have
used version 2.4.21 to maintain compatibility with previous
work. The host OS is also Linux (2.6). Our prototype was
implemented as extensions to Bochs and minimal changes to
the collaborating OS.
A. Writes into Kernel Space
Kernel space can be written by the following subjects:
kernel threads and functions (including those from loadable
kernel modules and system calls), processes in user space
through the /dev/kmem or /dev/mem interface 1, and malware
exploiting vulnerabilities in kernel code that allow direct
injection of network bytes into kernel memory.
At the architectural level kernel space is composed of three
distinct segments: kernel CS (code), kernel DS (data) and
kernel SS (stack). In our defense approach we only enforce
the * (star) integrity axiom in kernel code and data segments.
The stack segment is expected to be written by low integrity
subjects executing at kernel level. For example, parameters of
system calls may be low integrity but as long as the system
calls themselves are not corrupted, this does not threaten kernel
integrity. System calls are intended to work on behalf of any
given user process at any integrity level. Also, parameters of
exported kernel functions may be low integrity if the module
or kernel thread invoking the function is low integrity. Again,
as long as the high integrity kernel function is not corrupted,
the fact that it deals with low integrity parameters does not
represent a breach of our integrity module because the data
structures managed and changed inside these functions (and
also inside system calls) are those expected to be changed
in the course of system execution. For instance, when a
low integrity kernel module registers itself as a character
device in the system it uses the exported kernel function
register chrdev (Linux 2.4.21). Inside this function the kernel
data structure chrdevs is updated with all the information
about the new character device: major number, name and its
ﬁle operations. In this case the function will be invoked from a
low integrity module, and consequently, the parameters passed
will be low integrity as well.
On the other hand, data structures such as the system call
table, processes list, zone table and entropy pool, for instance,
are not expected to be directly written. In fact the kernel does