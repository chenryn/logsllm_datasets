$git clone --recursive https://github.com/pytorch/pytorch  
$cd pytorch  
$python setup.py install  
running install  
running build_deps  
\-- The C compiler identification is GNU 6.4.0  
\-- The CXX compiler identification is GNU 6.4.0  
\-- Check for working C compiler: /usr/bin/cc  
\-- Check for working C compiler: /usr/bin/cc -- works  
\-- Detecting C compiler ABI info  
\-- Detecting C compiler ABI info - done  
\-- Detecting C compile features  
\-- Detecting C compile features - done  
\-- Check for working CXX compiler: /usr/bin/c++  
\-- Check for working CXX compiler: /usr/bin/c++ -- works  
\-- Detecting CXX compiler ABI info  
\-- Detecting CXX compiler ABI info - done  
\-- Detecting CXX compile features  
\-- Detecting CXX compile features - done  
\-- Found CUDA: /usr/local/cuda (found suitable version "9.0", minimum
required is "7.0")  
\-- Configuring done  
\-- Generating done  
\-- Build files have been written to:
/home/zjy/program/pytorch/torch/lib/build/nccl  
Scanning dependencies of target nccl  
[100%] Generating lib/libnccl.so  
Grabbing src/nccl.h >
/home/zjy/program/pytorch/torch/lib/build/nccl/include/nccl.h  
Compiling src/libwrap.cu >
/home/zjy/program/pytorch/torch/lib/build/nccl/obj/libwrap.o  
Compiling src/core.cu >
/home/zjy/program/pytorch/torch/lib/build/nccl/obj/core.o  
Compiling src/all_gather.cu >
/home/zjy/program/pytorch/torch/lib/build/nccl/obj/all_gather.o  
Compiling src/all_reduce.cu >
/home/zjy/program/pytorch/torch/lib/build/nccl/obj/all_reduce.o  
Compiling src/broadcast.cu >
/home/zjy/program/pytorch/torch/lib/build/nccl/obj/broadcast.o  
Compiling src/reduce.cu >
/home/zjy/program/pytorch/torch/lib/build/nccl/obj/reduce.o  
Compiling src/reduce_scatter.cu >
/home/zjy/program/pytorch/torch/lib/build/nccl/obj/reduce_scatter.o  
ptxas warning : Too big maxrregcount value specified 96, will be ignored  
ptxas warning : Too big maxrregcount value specified 96, will be ignored  
ptxas warning : Too big maxrregcount value specified 96, will be ignored  
ptxas warning : Too big maxrregcount value specified 96, will be ignored  
ptxas warning : Too big maxrregcount value specified 96, will be ignored  
ptxas warning : Too big maxrregcount value specified 96, will be ignored  
ptxas warning : Too big maxrregcount value specified 96, will be ignored  
Linking libnccl.so.1.3.5 >
/home/zjy/program/pytorch/torch/lib/build/nccl/lib/libnccl.so.1.3.5  
Archiving libnccl_static.a >
/home/zjy/program/pytorch/torch/lib/build/nccl/lib/libnccl_static.a  
[100%] Built target nccl  
Install the project...  
\-- Install configuration: "Release"  
\-- Installing: /home/zjy/program/pytorch/torch/lib/tmp_install/include/nccl.h  
\-- The C compiler identification is GNU 6.4.0  
\-- The CXX compiler identification is GNU 6.4.0  
\-- Check for working C compiler: /usr/bin/cc  
\-- Check for working C compiler: /usr/bin/cc -- works  
\-- Detecting C compiler ABI info  
\-- Detecting C compiler ABI info - done  
\-- Detecting C compile features  
\-- Detecting C compile features - done  
\-- Check for working CXX compiler: /usr/bin/c++  
\-- Check for working CXX compiler: /usr/bin/c++ -- works  
\-- Detecting CXX compiler ABI info  
\-- Detecting CXX compiler ABI info - done  
\-- Detecting CXX compile features  
\-- Detecting CXX compile features - done  
\-- Found CUDA: /usr/local/cuda (found suitable version "9.0", minimum
required is "5.5")  
\-- Autodetected CUDA architecture(s): 6.1  
\-- Found CUDA with FP16 support, compiling with torch.CudaHalfTensor  
\-- Removing -DNDEBUG from compile flags  
CMake Warning (dev) at
/home/zjy/anaconda3/share/cmake-3.9/Modules/FindOpenMP.cmake:200 (if):  
Policy CMP0054 is not set: Only interpret if() arguments as variables or  
keywords when unquoted. Run "cmake --help-policy CMP0054" for policy  
details. Use the cmake_policy command to set the policy and suppress this  
warning.
Quoted variables like "c" will no longer be dereferenced when the policy is  
set to NEW. Since the policy is not set the OLD behavior will be used.  
Call Stack (most recent call first):  
/home/zjy/anaconda3/share/cmake-3.9/Modules/FindOpenMP.cmake:324
(_OPENMP_GET_FLAGS)  
CMakeLists.txt:130 (FIND_PACKAGE)  
This warning is for project developers. Use -Wno-dev to suppress it.
\-- Found OpenMP_C: -fopenmp (found version "4.5")  
\-- Found OpenMP_CXX: -fopenmp (found version "4.5")  
\-- Compiling with OpenMP support  
\-- Checking prototype magma_get_sgeqrf_nb for MAGMA_V2 - True  
\-- Compiling with MAGMA support  
\-- MAGMA INCLUDE DIRECTORIES: /home/zjy/anaconda3/include  
\-- MAGMA LIBRARIES: /home/zjy/anaconda3/lib/libmagma.a  
\-- MAGMA V2 check: 1  
\-- Could not find hardware support for NEON on this machine.  
\-- No OMAP3 processor on this machine.  
\-- No OMAP4 processor on this machine.  
\-- Looking for cpuid.h  
\-- Looking for cpuid.h - found  
\-- Performing Test HAVE_GCC_GET_CPUID  
\-- Performing Test HAVE_GCC_GET_CPUID - Success  
\-- Performing Test NO_GCC_EBX_FPIC_BUG  
\-- Performing Test NO_GCC_EBX_FPIC_BUG - Success  
\-- Performing Test C_HAS_SSE1_1  
\-- Performing Test C_HAS_SSE1_1 - Success  
\-- Performing Test C_HAS_SSE2_1  
\-- Performing Test C_HAS_SSE2_1 - Success  
\-- Performing Test C_HAS_SSE3_1  
\-- Performing Test C_HAS_SSE3_1 - Failed  
\-- Performing Test C_HAS_SSE3_2  
\-- Performing Test C_HAS_SSE3_2 - Success  
\-- Performing Test C_HAS_SSE4_1_1  
\-- Performing Test C_HAS_SSE4_1_1 - Failed  
\-- Performing Test C_HAS_SSE4_1_2  
\-- Performing Test C_HAS_SSE4_1_2 - Success  
\-- Performing Test C_HAS_SSE4_2_1  
\-- Performing Test C_HAS_SSE4_2_1 - Failed  
\-- Performing Test C_HAS_SSE4_2_2  
\-- Performing Test C_HAS_SSE4_2_2 - Success  
\-- Performing Test C_HAS_AVX_1  
\-- Performing Test C_HAS_AVX_1 - Failed  
\-- Performing Test C_HAS_AVX_2  
\-- Performing Test C_HAS_AVX_2 - Success  
\-- Performing Test C_HAS_AVX2_1  
\-- Performing Test C_HAS_AVX2_1 - Failed  
\-- Performing Test C_HAS_AVX2_2  
\-- Performing Test C_HAS_AVX2_2 - Success  
\-- Performing Test CXX_HAS_SSE1_1  
\-- Performing Test CXX_HAS_SSE1_1 - Success  
\-- Performing Test CXX_HAS_SSE2_1  
\-- Performing Test CXX_HAS_SSE2_1 - Success  
\-- Performing Test CXX_HAS_SSE3_1  
\-- Performing Test CXX_HAS_SSE3_1 - Failed  
\-- Performing Test CXX_HAS_SSE3_2  
\-- Performing Test CXX_HAS_SSE3_2 - Success  
\-- Performing Test CXX_HAS_SSE4_1_1  
\-- Performing Test CXX_HAS_SSE4_1_1 - Failed  
\-- Performing Test CXX_HAS_SSE4_1_2  
\-- Performing Test CXX_HAS_SSE4_1_2 - Success  
\-- Performing Test CXX_HAS_SSE4_2_1  
\-- Performing Test CXX_HAS_SSE4_2_1 - Failed  
\-- Performing Test CXX_HAS_SSE4_2_2  
\-- Performing Test CXX_HAS_SSE4_2_2 - Success  
\-- Performing Test CXX_HAS_AVX_1  
\-- Performing Test CXX_HAS_AVX_1 - Failed  
\-- Performing Test CXX_HAS_AVX_2  
\-- Performing Test CXX_HAS_AVX_2 - Success  
\-- Performing Test CXX_HAS_AVX2_1  
\-- Performing Test CXX_HAS_AVX2_1 - Failed  
\-- Performing Test CXX_HAS_AVX2_2  
\-- Performing Test CXX_HAS_AVX2_2 - Success  
\-- SSE2 Found  
\-- SSE3 Found  
\-- AVX Found  
\-- AVX2 Found  
\-- Performing Test HAS_C11_ATOMICS  
\-- Performing Test HAS_C11_ATOMICS - Failed  
\-- Performing Test HAS_MSC_ATOMICS  
\-- Performing Test HAS_MSC_ATOMICS - Failed  
\-- Performing Test HAS_GCC_ATOMICS  
\-- Performing Test HAS_GCC_ATOMICS - Success  
\-- Atomics: using GCC intrinsics  
\-- Looking for sys/types.h  
\-- Looking for sys/types.h - found  
\-- Looking for stdint.h  
\-- Looking for stdint.h - found  
\-- Looking for stddef.h  
\-- Looking for stddef.h - found  
\-- Check size of void*  
\-- Check size of void* - done  
\-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m
- dl]  
\-- Library mkl_gf_lp64: /home/zjy/anaconda3/lib/libmkl_gf_lp64.so  
\-- Library mkl_gnu_thread: /home/zjy/anaconda3/lib/libmkl_gnu_thread.so  
\-- Library mkl_core: /home/zjy/anaconda3/lib/libmkl_core.so  
\-- Found OpenMP_C: -fopenmp (found version "4.5")  
\-- Found OpenMP_CXX: -fopenmp (found version "4.5")  
\-- Library gomp: -fopenmp  
\-- Library pthread: /usr/lib/x86_64-linux-gnu/libpthread.so  
\-- Library m: /usr/lib/x86_64-linux-gnu/libm.so  
\-- Library dl: /usr/lib/x86_64-linux-gnu/libdl.so  
\-- Looking for cblas_sgemm  
\-- Looking for cblas_sgemm - found  
\-- MKL library found  
\-- Performing Test BLAS_F2C_DOUBLE_WORKS  
\-- Performing Test BLAS_F2C_DOUBLE_WORKS - Failed  
\-- Performing Test BLAS_F2C_FLOAT_WORKS  
\-- Performing Test BLAS_F2C_FLOAT_WORKS - Success  
\-- Performing Test BLAS_USE_CBLAS_DOT  
\-- Performing Test BLAS_USE_CBLAS_DOT - Success  
\-- Found a library with BLAS API (mkl).  
\-- Found a library with LAPACK API. (mkl)  
\-- Found CUDNN: /usr/local/cuda/include  
\-- Found cuDNN: v7.0.4 (include: /usr/local/cuda/include, library:
/usr/local/cuda/lib64/libcudnn.so)  
CMake Deprecation Warning at src/ATen/CMakeLists.txt:7 (CMAKE_POLICY):  
The OLD behavior for policy CMP0026 will be removed from a future version  
of CMake.
The cmake-policies(7) manual explains that the OLD behaviors of all  
policies are deprecated and that a policy should be set to OLD only under  
specific short-term circumstances. Projects should be ported to the NEW  
behavior and not rely on setting a policy to OLD.
\-- Using python found in /home/zjy/anaconda3/bin/python  
['/home/zjy/program/pytorch/aten/src/THNN/generic/THNN.h',
'/home/zjy/program/pytorch/aten/src/THCUNN/generic/THCUNN.h',