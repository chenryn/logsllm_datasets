7: msk = (sk, D) ← SRE.KGen(1λ) (cid:46) Update msk for w after
8: MSK[w] ← msk, D[w] ← D, C[w] ← i + 1
Client & Server:
9: Run Σadd.Search(Kadd, w||i, σadd; EDBadd), and server gets a
list ((ct1, t1), (ct2, t2), . . . , (ct(cid:96), t(cid:96))) of ciphertext and tag pairs
search
Server:
1: Server uses (skR, D) to decrypt all ciphertexts {(cti, ti)} as
2: for i ∈ [1, (cid:96)] do
follows
Setup(1λ): The client generates (EDBadd, Kadd, σadd)←
$←− {0, 1}λ, and initializes lists
Σadd.Setup(1λ), picks Ks, Kt
MSK, C, D, and EDBcache for storing encryption keys asso-
ciated with each keyword, the search times of each keyword,
the compressed deletion list w.r.t. each keyword, and the search
results of previous queries, respectively. At the outset, MSK,
C and D are ﬁlled with symbol ⊥ and EDBcache is set
as empty. The algorithm then outputs K = (Kadd, Ks, Kt),
σ = (σadd, MSK, C, D) and EDB = (EDBadd, EDBcache).
Search(K, w, σ; EDB): When performing search on w,
the client obtains the search times i, the current secret key
sk and the compressed deletion list D associated with w,
by looking up C[w], MSK[w] and D[w], respectively. Then
it checks if i =⊥ (i.e., msk =⊥),
if so the client gets
nothing. Otherwise, the client computes the revoked secret
key skR ← SRE.cKRev(sk, D) and token tkn = F (Ks, w)
and sends(cid:0)(skR, D), tkn(cid:1) to the server. After this, the client
Update(K,(cid:0)op, (w, ind)(cid:1), σ; EDB): When adding a new
refreshes msk4, and runs Σadd.Search together with the server
to retrieve the encrypted indices matching w. Then the server
decrypts the non-deleted indices with skR, and returns them
along with the non-deleted ones in cache as the search result.
entry (w, ind) to the database, the client obtains the most
recent encryption key msk from MSK[w] and inserts the
encryption, ct ← SRE.Enc(msk, ind, t), of ind under tag
t = FKt(w, ind) to EDBadd. To delete the entry (w, ind), the
client inserts the corresponding tag t = FKt(w, ind) to the
compressed deletion list D (i.e., D ← SRE.Comp(D, t)).
We remark that, for simplicity, it is implicitly assumed
4The encryption key msk must be updated after each search and will be
used to encrypt future entries matching w, as noted by [9], [52].
11
end if
indi = SRE.Dec((skR, D), cti, ti)
if indi (cid:54)= ⊥ then
NewInd← NewInd ∪ {(indi, ti)}
else
DelInd← DelInd ∪ {ti}
3:
4:
5:
6:
7:
8:
9: end for
10: OldInd← EDBcache[tkn]
11: OldInd← OldInd\{(ind, t) : ∃ ti ∈ DelInd s.t. t = ti}
12: Res← NewInd ∪ OldInd, EDBcache[tkn] ← Res
13: return Res
Update(K, op, (w, ind), σ; EDB)
msk ← SRE.KGen(1λ), where msk = (sk, D)
MSK[w] ← msk, D[w] ← D
i ← 0, C[w] ← i
Client:
1: msk ← MSK[w], D ← D[w], i ← C[w]
2: if msk =⊥ then
3:
4:
5:
6: end if
7: Compute t ← FKt (w, ind)
8: if op = add then
9:
10:
11: else (i.e., op = del)
12:
13: end if
ct ← SRE.Enc(msk, ind, t)
Run Σadd.Update(Kadd, add, w||i, (ct, t), σadd; EDBadd)
D ← SRE.Comp(D, t), D[w] ← D
that at least one deletion happens for the queried keyword w.
In fact, this assumption can be removed by slightly adapting
the Search algorithm. Particularly, if no deletion occurs on
w, we only need to perform a deletion on a dummy identity
∗
ind∗ by running Update(K, del, (w, ind
), σ; EDB) prior to
computing skR. Moreover, we note that our DSSE is con-
structed modularly from Σadd and CSRE, so it would beneﬁt
immediately from any improvement on the building blocks.
B. Security Proof
Our scheme Σ can achieve Type-II backward privacy (cf.
Deﬁnition 4), which in contrast to Type-III backward privacy
does not leak which deletion operations remove which addition
operations. As previous works [9], [15], [52], it also achieves
forward privacy, which follows easily from that of Σadd. In
the following, we concentrate on Type-II backward privacy,
formalized as Theorem 2.
Theorem 2. The proposed scheme Σ is LBS-adaptively Type-
II-backward-private, if Σadd is an LF S-adaptively forward-
private SSE scheme, CSRE is IND-sREV-CPA secure and
F is a secure PRF, where LF S is the leakage of Σadd as
deﬁned in [7] and LBS = (LSrch
BS ,LU pdt
BS ) is deﬁned as
LU pdt
BS (op, w, ind) = op and LSrch
BS = (sp(w), TimeDB(w),
DelTime(w)).
Proof sketch. The proof is conducted in a similar way as Janus
[9] and Janus++ [52], except that the security of Σ relies on
that of the proposed SRE and the transcript is simulated with
less leakage. A simpliﬁed proof is given in Appendix A-B.
More details are shown in the full version.
V.
INSTANTIATION
In this section, we propose an instantiation of our generic
it follows the index of one entry with value ‘0’ to ﬁnd the
corresponding GGM leaf node for decryption.
As an example in Figure 1, two tags for ind1 and ind2 are
revoked, then skR consists of sk00, sk011 and sk101, which
will be sent to the server for search. When receiving skR, the
server can derive sk000 and sk001 from sk00 via G0(sk00) and
G1(sk00), respectively. Then it can use sk000, sk001, sk011 and
sk101 to decrypt the ind that is not revoked.
VI. EXPERIMENTAL EVALUATION
Our evaluation reports the time cost of insertion, search,
and deletion, as well as the communication cost, and compares
the above metrics with the state-of-the-art interactive and non-
interactive backward-private SSE schemes.
A. Implementation and Settings
We implement Aura in C++ and use OpenSSL to im-
i.e., AES and SHA256.
plement cryptographic primitives,
Pseudorandom generator in GGM PRF is implemented via
AES. In order to evaluate the performance of Aura under the
network environments, we leverage Thrift [49] to enable the
network communication between Aura client and server. Our
source code is publicly available in [1].
We conduct our evaluations under LAN and WAN envi-
ronments. We run Aura client and server on a Ubuntu Server
18.04 LTS workstation (Intel Core i7-8850H 2.6GHz CPU with
6 cores and 32GB RAM) for LAN evaluations. The delay
between the client and server is less than 0.1 ms, and the
bandwidth in between is 1, 000Mbps. For evaluations on the
WAN, we hire three e2-standard-8 instances (8 vCore, 32 GB
RAM) with Ubuntu Server 18.04 LTS from Google Cloud.
These instances are placed in Singapore, Sydney and South
Carolina, respectively. We use the server in Sydney as the
SSE server, and the one in Singapore (average round-trip delay
to Sydney: 103 ms, bandwidth to Sydney: 9, 700Mbps) and
South Carolina (average round-trip delay to Sydney: 197 ms,
bandwidth to Sydney: 9, 300Mbps) as the SSE client. All the
latency/bandwidth information is reported by Google [31].
We compare Aura with the interactive and non-interactive
SSE schemes. Regarding the interactive ones,
there exist
several schemes [9], [15], [22] achieving Type-II backward
privacy. In our evaluation, we compare with the most efﬁcient
scheme SDd [22], that features small client storage at the
expense of interactive update and search. Since SDd is not
implemented under the network environment, we adapt its
original implementation to make it compatible with Thrift.
Our implementation is available in [2]. For the non-interactive
schemes, we choose Janus++ [52]. Note that it can only
achieve Type-III backward privacy, while Aura achieves Type-
II backward privacy. In the following evaluation, we evaluate
the search cost required for the server to obtain the document
ind’s used for retrieving the real documents. We note that
the server in Aura and Janus++ can get the ind’s without
extra communication costs after getting search tokens from
the client, while the SDd server requires an extra round to
send the encrypted document ind’s back to the client and then
receive the decrypted ones from it.
For Janus++, we set the size of its tag space as 216.
long and the height of each
Namely, each tag is 16-bit
Fig. 1: Example of Compressed SRE
SSE scheme, termed as Aura. Notice that we can instantiate
it by integrating a concrete CSRE scheme with any forward-
private SSE scheme e.g., in [7], [9]. Next we focus on how
to instantiate the CSRE scheme by leveraging the GGM tree-
based PRF and the standard Bloom ﬁlter.
In particular, we employ the GGM tree-based PRF to
realize the multi-puncturable PRF and a standard Bloom ﬁlter
to generate a compact revocation list. In our SSE scheme,
each keyword w is associated with a GGM PRF key skw
and an (initially empty) Bloom ﬁlter Bw = 0b for deletion
on this keyword w between two consecutive search queries.
As introduced in Section III-C, a Bloom ﬁlter is used to
compress the deleted document tags and the GGM PRF key
will be revoked based on the compact revocation list, so the
number of leaf nodes in the GGM tree is set as the bit length
of Bloom ﬁlter. In our GGM PRF, G : {0, 1}λ ← {0, 1}2λ
is a length-doubling pseudorandom generator, and the output
of G(sk) is divided into two halves G0(sk) and G1(sk).
The value of GGM PRF F on (cid:96)-bit strings (i.e., ski) is
computed as Fsk(i) = Gi(cid:96)−1 (··· Gi1 (Gi0(sk))), where the
binary representation of the BF entry index i is i(cid:96)−1 ··· i1i0.
Here, (cid:96) = (cid:100)log(b)(cid:101) and b is the number of BF entries.
When inserting a (w, ind) pair, we follow the encryption
function of SRE. Speciﬁcally, the tag t of ind is ﬁrstly mapped
to h entry indices, {ij = Hj(t)}j∈[h], of the BF Bw. For each
index ij ∈ [0, b − 1], its corresponding leaf node Fskw (ij) is
calculated from the master secret key skw of the GGM tree.
Then the ind is encrypted with each leaf node as an encryption
key, and the h encrypted copies will be uploaded to the server.
After that, if the client starts to delete a (w, ind) pair, the tag
t of ind is inserted to the BF Bw for later batch revocation.
Namely, the h entries of Bw corresponding to t will be set to
‘1’. If more ind’s on this w are deleted, the associated tags t’s
are continuously inserted to Bw. For a search query over w,
the client generates the revoked secret key for the server, by
puncturing the associated GGM PRF key skw on the indices
of Bw entries with value ‘1’, i.e., Iw = {i(cid:48) ∈ [b] : Bw[i(cid:48)] =
1}. Speciﬁcally, for each revoked index in Iw, we ﬁnd a path
from the corresponding revoked leaf node to the root, and the
revoked secret key skR consists of the siblings of the nodes
on all the paths, but excluding those siblings that sit also on
some other paths. As a result, skR is generated on the ﬂy
before search and the complexity of the communication cost
is Θ(log(b)). Then skR and Bw are sent to the server with the
search token together. To conduct the search, the server ﬁrst
uses the search token to fetch the matched encrypted entries.
Meanwhile, it expands skR to get all leaf nodes of the GGM
tree except the revoked ones. After that, the server checks the
tag t of each fetched ciphertext with Bw to see if all h entries
of Bw with indices {Hj(t)} are marked as ‘1’. If so, it skips
this entry, as it is deleted and cannot be decrypted. Otherwise,
12
sksk0sk000sk001sk00sk01sk010sk011sk1sk100sk101sk10sk11sk110sk11101234567tG0(sk)G1(G0(sk))DeletedindRevoked skind1tind2TABLE II: Bloom Filter Storage Cost
d
10
100
1,000
10,000
Storage (KiB) 0.036 0.024 0.35
h = 5 h = 13 h = 5 h = 13 h = 5 h = 13 h = 5 h = 13
2.34 35.37 23.4
0.23
3.54
GGM tree is 16. Since SDd requires to specify the total
number of updates during the setup phase, we set the number
as ‘1,000,010’, ‘1,000,100’, ‘1,001,000’ and ‘1,010,000’ to
instantiate SDd in the evaluation.
To evaluate the scalability, we set d as ‘10’, ‘100’, ‘1,000’,
and ‘10,000’, where d is the number of maximum deletions
between two searches of a certain keyword, and set the number
of deletions dw = d. Then we derive two sets of BF parameters
based on the tradeoff between client storage saving and time
efﬁciency. For both parameter settings, we set the false positive
rate p = 10−4. We argue that
this rate is acceptable in
practice. If the number of matched documents in a query is
not large, e.g., < 10, 000, all results can be returned in high
conﬁdence. For very large datasets, a small amount of false
negatives are tolerable. For example, given a database with
web pages or domain-speciﬁc documents , it may contain near-
duplicate pages or documents. They may include almost the
same contents but with different identiﬁers [53], [56]. Missing
few results will not affect quality of service.
In the ﬁrst parameter setting, the size of BF is derived from
b = −d ln p/(ln 2)2, and the optimal number of hash functions
is equal to h = (cid:100)b/d ln 2(cid:101), which is 13. Accordingly, the BF
can bring 42.5% storage saving at the client compared to the
naive approach where the client uses a 32-bit string to denote
a deleted ind. This setting is suitable for clients with limited
storage, e.g., mobile devices. In the second setting, we envision
that a relatively powerful client can allocate more storage for
time efﬁciency, since the encryption time and search time scale
with h. To still gain storage saving for the client, we obtain
the minimum h, which is set as 5 and the saving is 12.5%.
Detailed space consumption of BF is given in Table II.
B. Evaluation and Comparison with SDd