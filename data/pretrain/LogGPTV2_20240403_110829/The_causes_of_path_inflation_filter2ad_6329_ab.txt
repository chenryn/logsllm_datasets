1
1
1
1
1
1
1
1
1
1
1
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
3
3
3
3
3
3
3
3
3
3
3
Dominant
Presence
Asia-Paciﬁc
Canada
Europe
Europe
Europe
Europe
Europe
Europe
US
US
US
US
US
US
US
US
US
US
US
US
US
Asia-Paciﬁc
Asia-Paciﬁc
Asia-Paciﬁc
Australia
Canada
Canada
Canada
Canada
Canada
Europe
Europe
Europe
Europe
Europe
Europe
Europe
Europe
Europe
International
US
US
US
US
US
US
US
US
US
US
US
US
US
US
US
US
US
Asia-Paciﬁc
Asia-Paciﬁc
Australia
Canada
US
US
US
US
US
US
US
Degree
199
162
161
111
67
90
172
256
1490
806
622
585
455
539
14
887
1735
2569
538
234
184
165
63
49
114
81
88
155
53
82
62
117
86
53
20
46
326
587
36
32
156
60
86
124
216
86
231
187
43
172
84
63
42
113
28
112
277
24
8
66
16
30
43
498
12
4
21
5
Table 1: ISPs studied, sorted by tier and their dominant re-
gional presence. Many ISPs have some POPs outside this dom-
inant operating region.
templates used by each ISP as input and proceeds in three steps:
ﬁrst, discover which ISP convention is used (AT&T), second, ex-
tract the location code (st6wa), and ﬁnally, map the location code
to a city name (Seattle, WA).
Using this DNS-based tool, we reduce each router-level trace-
route to a city-level path. This preserves routing policy because
most trafﬁc engineering decisions are made at the city (more pre-
cisely, POP) level [3, 31]. This step simpliﬁes later analysis in
three ways. First, it avoids the process of identifying the IP ad-
dresses that belong to the same router (alias resolution) and hence
eliminates a potential source of error. Second, measuring a nearly
complete backbone topology [2] is much easier than obtaining a
complete router-level topology, requiring fewer sources [2, 17, 27].
Inferring policy from an incomplete topology is much more difﬁ-
cult. Third, the city-level topology has fewer nodes (2,084 versus
52,000), simplifying routing policy inference and analysis.
We took great care to ensure that our location mapping was com-
plete and correct. While processing traces, our analysis ﬂags names
that match the router name pattern of ISP backbone routers but have
undeﬁned locations. We manually populate the tables of location
codes based on this output until complete. Not all routers have lo-
cation codes (Sprint customer routers, for instance); we infer the
location of such routers from that of their neighbors [27]. A prob-
lem with trusting DNS names for router location is that routers may
be improperly assigned to locations. The DNS name may be incor-
rect or stale, or the location inferred may be incorrect. For example,
one IP address had the location tag “ALT,” which is the three-letter
airport abbreviation for Alenquer, Brazil. In this case, the router
was in Atlanta, and was simply “ATL” mis-typed. We discover bad
location matches by ﬂagging physically impossible link latencies,
limited by speed of light in ﬁber (in this example, Georgia to Brazil
in 1 ms). We then disregard the trace until the router location infer-
ence has been corrected.
Large-scale, traceroute-based studies such as this one require an
approach to ﬁltering false links and paths that are observed during
routing changes. False links may arise from routing changes during
trace collection, since TTL-based path discovery is not atomic. We
remove a link if it does not obey the speed-of-light criterion or if it
is rarely used to carry trafﬁc in our traces. For example, we would
remove a direct link from Sydney to New York if, most of the time,
the path between Sydney and New York traverses Los Angeles. It
is important to remove these spurious links because they often rep-
resent a false, low latency, “non-stop” path through the network.
3.4 Inferring Policy
We study routing policy at three levels: intra-domain, peering,
and inter-domain path selection. Our techniques for extracting these
policies are different, and we defer the discussion of these tech-
niques to later sections. However, each layer of our analysis builds
on models validated at lower layers, so the overall accuracy of our
results depends on the accuracy of previous steps.
3.5 Studying Path Inﬂation
We analyze the impact of topology and routing policy on path
inﬂation between pairs of ISP cities. While aggregating statistics,
we assume that all city pairs are equal regardless of their size or the
amount of trafﬁc they carry. However, some normalization happens
automatically. In an ISP network, important “hub” cities are often
relied upon by many smaller “spoke” cities to get to the outside
world; hence, any path inﬂation between a pair of important cities
impacts many city pairs. As a result, path inﬂation between two
important cities impacts the aggregate measures more than inﬂation
between smaller cities.
200
150
100
500
s
P
O
P
d
e
r
e
v
o
c
s
i
D
800
600
400
200
s
e
g
d
e
y
t
i
c
-
r
e
t
n
i
d
e
r
e
v
o
c
s
i
D
0
0
10
20
30
40
Number of vantage points
0
0
10
20
30
40
Number of vantage points
Figure 2: The incremental beneﬁt of additional vantage points
for mapping the network. The ﬁrst vantage point ﬁnds the vast
majority of nodes in the network. However, it takes several van-
tage points to capture most of the edges, and additional vantage
points continue to contribute information.
While we focus on the inﬂation between city pairs, the absence
of data describing the amount of trafﬁc carried prevents us from
extending our analysis from the fraction of paths to the fraction
of packets that experience signiﬁcant inﬂation. In particular, if we
should ﬁnd that paths between some fraction of POP-pairs suffer
heavy inﬂation, that suggests but does not imply that a similar frac-
tion of trafﬁc will suffer inﬂation.
We compute link latencies using the geographic distance be-
tween the inferred location of adjacent routers. Except for networks
that use circuit-switching, geographic distance correlates well with
the minimum network delay [22]. This methodology is more robust
than extracting link latencies from traceroute data, as they can be
contaminated by queueing and unknown asymmetric reverse path
delay. However, this methodology underestimates the latencies of
links that do not take a direct path.
3.6 Completeness of the Dataset
Because our study is trace-driven, our results are limited by our
choice of vantage points and ISPs. We might miss POPs and edges
that belong to the ISPs we study. We conducted two simple analy-
ses to assess the completeness of our dataset with respect to these
ISPs. First, we compared the number of ISP pairs that peered in
our traceroutes to the number that peered in the BGP tables. We
found this fraction to be 71%. Second, we analyzed the amount
of new information that each vantage point added. Figure 2 shows
the number of POPs and city-level edges discovered as a function
of the number of vantage points. Although nearly all of the POPs
in our ISPs are captured with just a few vantage points, it is more
difﬁcult to capture all of the edges. We are well past the knee of the
curve, however, and each additional vantage point contributes little
new information. From these results we believe our topologies are
sufﬁciently complete for our task of assessing path inﬂation.
4.
INTRA-DOMAIN FACTORS
In this section, we ﬁrst study the impact of intra-domain topology
on path inﬂation, then describe our technique for inferring intra-
domain policy, and ﬁnally analyze its impact on path inﬂation.
4.1
Impact of Topology
We study the impact of ISP topology by measuring path inﬂation
along the shortest-latency path through the network. We compare
this shortest-latency path to a hypothetical direct link between the
two cities. The direct link “as the crow ﬂies” serves as an ISP-
independent reference point, and this comparison serves both to
estimate how well-connected ISP topologies are and to put mea-
surements of the inﬂation due to policy in context.
s
h
t
a
p
f
o
n
o
i
t
c
a
r
f
e
v
i
t
a
l
u
m
u
C
1.0
0.8
0.6
0.4
0.2
0.0
0
5
10
15
20
25
Additive inflation (ms)
95%
mean
median
)
s
m
(
n
o
i
t
a
l
f
n
i
e
v
i
t
i
d
d
A
30
20
10
0
20
0
Latency of direct link (ms)
80
40
60
Figure 3: Path inﬂation due to intra-domain topological con-
straints. The left graph shows the CDF of additive inﬂation,
and the right one shows the median and 95th percentile inﬂa-
tion as a function of latency of a hypothetical direct link.
We exclude ISPs that appear to use virtual circuit technologies
such as MPLS. This prevents us from underestimating path inﬂa-
tion, as these topologies have many IP-level edges without a cor-
responding physical link. We identiﬁed six such networks by their
unusually high edge to node ratio. We also exclude city pairs in the
ISP that were never observed in the same trace. This prevents us
from overestimating the inﬂation caused by topology if our traces
missed a link that would provide a shorter path between the cities.
The graph on the left of Figure 3 shows the cumulative distri-
bution function (CDF) of additive inﬂation. Most paths are not
inﬂated by much, pointing to the well-connectedness of most ISPs.
The median, mean, and 95th percentile inﬂation were 2, 3, and 10
ms, respectively. As explained below, the high inﬂation points cor-
respond to city pairs on different continents.
The graph on the right characterizes inﬂation as a function of