randomly as “noises” whose labels are manually ﬂipped.
The architecture of the WS model and the DS model is
chosen to be Multi-Layer Perceptron consisting of an input
layer, two hidden layers, and a softmax layer, where the ﬁrst
hidden layer consists of 500 nodes, and the second layer
consists of 1000 nodes. The training of the WS model and the
DS model implements the learning rate decay and the early
stopping API, and sets all hyper parameters to their default as
provided in TensorFlow [5].
First, we choose 3,000 samples randomly from WS to form
DS. Then we use WS to train the WS model, and use DS to
train the DS model. For each sample in DS, we use αw and
ωw to record its loss value in the ﬁrst epoch and the last epoch,
respectively, during the training of the WS model; and further
use αd and ωd to denote its loss value in the ﬁrst epoch and the
last epoch, respectively, during the training of the DS model.
Figure 1 illustrates the distributions and their ﬁtting curves
of correctly-labeled samples and wrongly-labeled samples
w.r.t. three variables, including (αw/ωw)/(αd/ωd) in Figure 1
(a), (αw/ωw) in Figure 1 (b), and (αd/ωd) in Figure 1 (c).
The bars in the ﬁgure indicate the number of samples at
certain value of the corresponding variable, while the curves
illustrate the kernel density estimation of the corresponding
variable, which is a non-parametric estimation of the variable’s
probability density function.
Figure 1 shows that the differences between the correctly-
labeled samples and the wrongly-labeled samples are more
apparent in terms of their distributions measured from the loss
values in training both the WS model and the DS model as
shown in Figure 1 (a), than in training the WS model alone
as shown in Figure 1 (b), and in training the DS model alone
as shown in Figure 1 (c).
The distribution differences shown in Figure 1 between the
correctly-labeled samples and the wrongly-labeled samples can
be measured in Wasserstein distance [6], which quantiﬁes the
minimum “cost” of turning one distribution to another. A larger
Wasserstein distance represents more signiﬁcant difference
between two distributions. Table I measures the Wasserstein
distances between the distributions that are given in Figure 1. It
3
Fig. 1: Distributions of Correctly-Labeled Samples and Wrongly-Labeled Samples
TABLE I: Wasserstein Distance between Distributions of
Correctly-Labeled and Wrongly-Labeled Samples
Model(s) Used
Wasserstein Distance
WS model
DS model
Both WS model and DS model
0.00295
0.01047
0.04387
Explanation on the differences of loss values. The dif-
ferential training heuristic is also enlightened by the following
theorem proved by S. Arora et al. in a recent research [9] on the
differences of loss values between correctly-labeled samples
and randomly-labeled samples during model training:
In a two-layer MLP model using ReLU activation and
trained by gradient descent, when there are inﬁnite nodes in
hidden layers and the model is fully trained, the following
equation holds:
(cid:118)(cid:117)(cid:117)(cid:116) n(cid:88)
TABLE II: Wasserstein Distance between Distributions of
Correctly-Labeled and Wrongly-Labeled Samples with Differ-
ent DS
(cid:107)y − u (k)(cid:107)2 =
(1 − ηλi)2k(v
(cid:124)
i y)2 ± ε
Size of DS Wasserstein Distance
3000
6000
9000
12000
15000
0.04387
0.03401
0.03334
0.01965
0.02703
suggests to distinguish between correctly-labeled samples and
wrongly-labeled samples according to the loss values collected
in training both the WS model and the DS model.
The size of DS is an important factor in differentiating the
distributions between correctly-labeled samples and wrongly-
labeled samples. Figure 2 and Table II show that using smaller
DS yields greater difference; it is thus desirable to choose DS
as small as possible in Differential Training.
On the other hand, DS should be large enough to converge
the training of the DS model
[15]. Therefore, we have two
criteria for choosing the size of DS: (1) DS should be as small
as possible to distinguish between correctly-labeled samples
and wrongly-labeled samples, and (2) DS should be large
enough for converging the training of the DS model. In our
experiments, we use a grid search to choose the size of DS
based on these two criteria.
4
i=1
where y = (y1, y2 . . . yn) denotes all the labels of the n
samples, u (k) denotes all the n predictions in the kth epoch,
and thus (cid:107)y − u (k)(cid:107)2 refers to the L2-norm distance between
the predicted labels and the true labels. Moreover, η refers
to the learning rate. vi refers to the orthonormal eigenvector
of sample i and λi refers to its corresponding eigenvalue
decomposed from the gram matrix H of the model, while the
gram matrix H is decided by the two-layer ReLU model in
the kth epoch as deﬁned in [46], [43], [16]. ε is a very small
value that can be ignored.
The equation shows that under the ideal condition, the
component of ((cid:107)y − u (k)(cid:107)2)2 for sample i in epochs 1 to k
(cid:124)
i y)2 and decreases
is a geometric sequence which starts at (v
at ratio (1 − ηλi)2.
Furthermore, in section 4 of paper [9], it is proven that
the samples with true labels have better alignment with larger
eigenvalues than the samples with random labels (or wrong
labels). In each epoch of model training, the square of L2-
((cid:107)y − u (k)(cid:107)2)2 thus demonstrates larger
norm distance
decreasing ratios (1 − ηλi)2 for correctly-labeled samples than
for wrongly-labeled samples.
Since the square of L2-norm distance ((cid:107)y − u (k)(cid:107)2)2 is
exactly the same as the L2 loss function between the actual
Fig. 2: Distributions of Correctly-Labeled Samples and Wrongly-Labeled Samples with Different Sizes of DS
consists of the transformed feature vectors and their associated
labels.
B. Phase II: Noisy Label Detection
The second phase “Noisy Label Detection” of Differential
Training consists of multiple iterations, in each of which the
noises in the training set are reduced until a stopping criterion
is met. Each iteration is illustrated in Figure 4, which consists
of four steps, including “Dataset Downsampling”, “Training of
WS and DS Models”, “Loss Vector Generation” and “Outlier
Detection”.
1) Dataset Downsampling: In the ﬁrst step “dataset down-
sampling”, Differential Training randomly downsamples the
whole training set WS to a smaller dataset, named “down-
sampled set,” or DS for short. The size of DS is selected
according to the two criteria described in the differential
training heuristic.
2) Training of WS and DS Models: After DS is generated,
two noise detection models, “WS model” and “DS model,”
are trained on WS and DS datasets, respectively. The two
noise detection models can be any deep learning classiﬁcation
models having the same network architecture for classifying
apps to be either malicious or benign according to their
feature vectors. Depending on the selection of app features,
various deep learning classiﬁcation models (e.g., Multi-Layer
Perceptron, Recurrent Neural Network, and Convolutional
Neural Network) may be selected to be noise detection models.
Differential Training uses the noise detection models to extract
the loss values for each input app during training; any deep
learning classiﬁcation model can be used as a noise detection
model as long as it outputs a loss value for each input app in
each epoch during its training process.
In our experiments conducted in this paper, we choose the
noise detection models to be Multi-Layer Perceptron (MLP)
that consists of two hidden layers, where the ﬁrst hidden
layer consists of 500 nodes and the second hidden layer 1000
nodes, and followed by a softmax layer as output. We use the
TensorFlow toolkit [5] to train the two models, where all the
parameters are set to their default values in the toolkit.
3) Loss Vector Generation: In the third step, the loss values
of each app in DS are collected from the two noise detection
Fig. 3: Structure of Differential Training
labels y and the predicted labels u (k), this theorem implies
that during the training of DS/WS model, the decreasing rates
of the loss values of correctly-labeled samples are larger than
(and thus different from) those of wrongly-labeled samples in
each epoch.
IV. DIFFERENTIAL TRAINING FRAMEWORK
Differential Training processes
in
three phases: “pre-processing,” “noisy label detection,” and
“malware detection with revised labels.” The structure of
Differential Training is shown in Figure 3.
a noisy dataset
A. Phase I: Pre-processing
In the ﬁrst phase, a machine learning based malware
detection approach is selected, and the raw app ﬁles from the
dataset of the approach are transformed into numeric feature
vectors through a “Feature Vector Generation” module which
should be speciﬁed by the malware detection approach. The
output of the phase I is the whole training set WS which
5
Fig. 4: Structure of a Single Iteration in Noisy Label Detection
models during their trainings. The loss values collected from
each model are arranged into a sequence in the order of training
epochs. Then the two sequences are concatenated to form a
“loss vector” for each app in DS.
4) Outlier Detection: In this step, a set of outlier detection
algorithms are applied to the loss vectors of all the apps in
DS. For each app whose loss vector is detected as an outlier,
its label is considered to be “wrong”, and thus ﬂipped with a
probability. Several points on the outlier detection are clariﬁed
below:
•
• Most outlier detection algorithms require a “contain-
ment rate” parameter as their input. This parameter
works as a threshold in identifying outliers. In Differ-
ential training, this parameter is set to the current ratio
of wrongly-labeled samples in WS. This noise ratio is
estimated using the method proposed by Goldberg-
er [19]. In particular, the noise ratio is estimated to
be (1 − aW S), where aW S is the accuracy of the WS
model in 5-fold cross-validation on WS.
To avoid any bias of a single outlier detection algorith-
m, we use 13 different outlier detection algorithms and
apply a majority voting to get the ﬁnal result of outlier-
s. Table III shows the outlier detection algorithms used
in Differential Training, where the ﬁrst 12 algorithms
are taken from a public toolkit named “PyOD” [3],
while the last algorithm “EllipticEnvelope” is taken
from the toolkit “sklearn” [4].
Another parameter named dropout ratio is introduced
in this step. After each outlier is detected according
to the majority voting, the label of the corresponding
sample is revised/ﬂipped with a probability equal to
the dropout ratio. The dropout ratio is used to reduce
the impact caused by any accidental error from either
outlier detection or noise rate estimation. The use of
this dropout ratio is inspired by the random dropout
mechanism in neural networks training [40], and the
ratio is set to 0.5 in our experiments.
•
TABLE III: List of Outlier Detection Algorithms used in
Differential Training
Angle-based Outlier Detector (ABOD)
Auto Encoder
Clustering Based Local Outlier Factor (CBLOF)
Histogram-based Outlier Detection (HBOS)
IsolationForest Outlier Detector (I-forest)
k-Nearest Neighbors Detector (kNN)
Local Outlier Factor (LOF)
Outlier Detection with Minimum Covariance Determinant (MCD)
Single-Objective Generative Adversarial Active Learning (So-gaal)
One-class SVM detector
Stochastic Outlier Selection (SOS)
Principal Component Analysis Outlier Detector (PCA)
EllipticEnvelope
5) Stopping Criterion: To stop the iterations in training
the WS model and the DS model, we use a stop criterion
that is similar to the early stopping adopted in neural network
training. The iterations stop once the ﬂuctuation of the es-
timated noise ratios in the last several iterations turns to be
smaller than a certain threshold. In experiments, we enforce
the stopping criterion through the API earlystop_callback()
from the TensorFlow toolkit, where all parameters are set to
their default values.
C. Phase III: Malware Detection with Revised Labels
Once the iterations stop,
the apps and their associated
labels in the whole set WS are ready for Android malware
detection. The original Android malware detection approach
can be trained using these apps’ feature vectors (which were
extracted in phase I) and their labels (which were revised in
phase II). In the experiments below, we use ground-truth data
to evaluate the performance of Differential Training with three
different Android malware detection approaches,
including
SDAC [47], Drebin [10], and DeepReﬁner [49].
We measure the performances of Differential Training
using the following metrics: (i) The number and the percentage
of wrong labels in the training set being reduced by Differ-
ential Training. (ii) The F-scores of the malware detection
6
approach when it is applied to the noisy training set, the noise-
reduced training set processed by Differential Training, and the
“ground-truth” training set. The differences between these F-
scores1 show that how much improvement in the performance
of the malware detection approach is made due to Differential
Training, and how close is the improved performance to the
upper bound.
In evaluating Differential Training with a malware
detection approach, we partition its “ground-truth” dataset into
two parts: 80% of them are used as the training set, and the
other 20% are used as testing/validation set. Given a noise ratio
0 ≤ rnoise ≤ 0.5, we randomly select each app in the training
set with probability rnoise ∗ 100%, and ﬂip the labels of the
selected apps to generate a noisily-labeled dataset. The default
value of the noise ratio is set to 10%, which is similar to the
ratio which we observed from VirusTotal during a period of
three years. After Differential Training revises the labels in
the training set, we refer it as the processed dataset. While we
train a malware detection approach using either ground-truth
dataset, noisy dataset, or processed dataset, we always evaluate
its performance using a “ground-truth” testing dataset.
Without confusion, we also call the framework Differential
Training by excluding phase III if the objective is to detect or
reduce noisy labels in a dataset without testing the malware
detection approach.
V. DIFFERENTIAL TRAINING WITH SDAC
A. Introduction of SDAC
SDAC is an Android malware detection approach that
uses “semantic distance based API clusters” to make malware
detection robust to the evolution of Android APIs. It measures
the contribution of an API to malware detection by its API
context, which refers to its neighbourhood APIs in the API
graphs derived from training apps. In the training process,
all APIs are transformed into numeric vectors according to
their API contexts, and the numeric vectors are clustered
into 1,000 API clusters. Then, each app is converted to a
1,000-dimensional binary vector depending on whether or not
the app includes any API in each API cluster. A supporting
vector machine (SVM) is trained using those binary vectors
that are derived from all training apps and their associated
labels. In the testing phase, if new APIs are employed by