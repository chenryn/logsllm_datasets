prises of two stages. The ﬁrst stage, shown in the left of the ﬁgure
and discussed thoroughly in Sec. 3, involves proﬁling an applica-
tion both statically and dynamically to extract code blocks, or basic
blocks (BBLs), and control-ﬂow information (CFG+). The latter
includes a partial control-ﬂow graph showing how the extracted
BBLs are connected, and frequency data indicating which branches
are taken more frequently than others.
This data is processed to generate optimized code to be injected
in the application, and code for running the analysis in parallel. The
ﬁrst contains code stubs that enqueue the information required to
237decouple DFT in a shared data structure. Note that ShadowReplica
does not naively generate code for enqueueing everything, but en-
sures that only information that has potentially changed since the
previous executed block are enqueued. This is one of our main
contributions, and problems of previous work [25, 33] that failed to
satisfy equation (1). The second includes code stubs that dequeue
information along with the analysis code.
The generated code is passed to the runtime component of Shad-
owReplica, shown in Fig. 2(b) and discussed in Sec. 4. We utilize
a DBI framework that allows us to inject the enqueueing stubs in
the application in an efﬁcient manner and with ﬂexibility (i.e., on
arbitrary instructions of a binary). Our motivation for using a DBI
is that it allows us to apply ShadowReplica on unmodiﬁed binary
applications, and it enables different analyses, security related or
others, by offering the ability to “interfere” with the application at
the lowest possible level.
Application threads are executing over the DBI and our tool,
which inject the enqueueing stubs. We will refer to an applica-
tion thread as the primary. For each primary, we spawn a shadow
thread that will run the analysis code, which we will refer to as the
secondary. While both threads are in the same address space, ap-
plications threads are running over the DBI’s VMM, but shadow
threads are executing natively, since the code generated in the ﬁrst
phase includes everything required to run the analysis. Our current
design spawns secondary threads in the same process used by the
DBI and the application. In the future, we are considering hosting
the secondary threads in a different process for increased isolation.
Communication between primary and secondary threads is done
through a ring-buffer structure optimized for multi-core architec-
tures (Sec. 4.2). The ring buffer is also used for the primary thread
to synchronize with the secondary, when it is required that the anal-
ysis is complete before proceeding with execution. For instance,
ensuring that integrity has not been compromised before allowing
a certain system call or performing a computed branch.
Multi-threaded applications accessing shared data within a crit-
ical area protected by locks (e.g., mutexes) are handled by using
an additional ring buffer structure for every critical area. When a
primary enters such an area by acquiring a lock, it ﬁrst synchro-
nizes with the secondary, and then they both switch to the new
ring buffer, which now receives all the information generated by
the enqueueing stubs. Before exiting the critical area, the primary
synchronizes again with the secondary, and then both switch to the
original buffer.
Finally, we export any new BBLs and CFG edges that are dis-
covered at runtime, which can be passed back for code analysis.
Extending the coverage of our analysis means that we can gener-
ate optimal code for a larger part of the application. Note that our
analysis also generates generic code for handling application code
not discovered during proﬁling. This “default” code performs all
necessary functionality, albeit slower than the optimized code gen-
erated for known BBLs and control-ﬂow edges.
2.4 Other Applicable Analyses
The main motivation behind ShadowReplica has been to acceler-
ate security techniques with well established beneﬁts, by providing
a methodology and framework that can utilize the parallelism of-
fered by multi-core CPUs. Besides DFT and DTA, we also imple-
mented a control-ﬂow integrity [1] tool to demonstrate the ﬂexibil-
ity of our approach. We argue that many other analyses can beneﬁt
from it.
Control-ﬂow Integrity. CFI [1], similarly to DTA, aims at pre-
venting attackers from compromising applications by hijacking their
control ﬂow. Programs normally follow predetermined execution
Figure 3: Example CFG. Nodes represent basic blocks and
edges are control transfers. During dynamic proﬁling, we count
how many times each edge is followed (edge labels).
paths. CFI enforces program ﬂow to follow one of these prede-
termined paths. Determining a complete CFG of a program is a
challenging task in itself, but assuming such a CFG is available,
CFI operates as follows. Run-time checks are injected in the appli-
cation to ensure that control ﬂow remains within the CFG. These
checks are placed before every indirect control ﬂow transfer in the
application and check that the destination is one of the intended
ones. Basically, all possible destinations of a particular control
ﬂow instruction are assigned the same id, which is validated be-
fore transferring control. While this can be overly permissive, be-
cause multiple instructions may have the same targets assigning
the same id to the super-set of destinations, this approach allows
for fast checks. We implemented CFI with ShadowReplica by us-
ing the CFG information extracted during the application proﬁling,
and by generating analysis code that checks whether a control-ﬂow
transfer is allowable, using the same control ﬂow enqueueing stubs
we used for DFT.
Other Analyses. Dynamic analyses that use DBI frameworks [22,
5, 23] can also readily make use of ShadowReplica (e.g., tech-
niques that focus on memory integrity detection). Valgrind’s Mem-
check [23] uses shadow memory to keep track of uninitialized val-
ues in memory and identify their (dangerous) use; Memcheck is
an ideal candidate for accelerating through ShadowReplica. Dr.
Memory [4] discovers similar types of programming errors includ-
ing memory leaks, heap overﬂows, etc. Software-based fault iso-
lation [30] mechanisms can also be easily supported through our
framework by using the existing code analysis for the primary and
small modiﬁcations to the secondary. Approaches that do not de-
pend on shadow memory can also be supported with moderate en-
gineering effort. Examples include call graph proﬁling, method
counting, and path proﬁling. Finally, ShadowReplica can be ex-
tended to work for analyses that refer to memory contents such as
integer overﬂow detection. Note that analyses of this type are less
common for binaries, as they require access to source code.
Limitations. There are problem areas where ShadowReplica is
not a good ﬁt, exactly because analysis code is decoupled from
execution. For instance, cache simulation [16] requires that the
ordering of memory accesses can be reconstructed accurately. This
task is challenging, even when using in-lined analysis code. It is
even more so, when the analysis code runs in parallel.
3. OFF-LINE APPLICATION ANALYSIS
We analyze the application off-line to generate optimized instru-
mentation code to be injected in primary threads, as well as a new
program in C that implements the analysis in the secondary (based
on the execution trace recorded by the primary). This section de-
scribes our methodology for doing so.
3.1 Application Proﬁling
The ﬁrst step of application analysis involves proﬁling (Fig. 2(a))
to gather code and control-ﬂow information. ShadowReplica uses
238both static and dynamic proﬁling. Currently, we perform static
proﬁling using the IDA Pro [15] disassembler, using its scripting
API. To complement our data, we built a tool over the Pin [22]
DBI framework that dynamically collects information about a bi-
nary by executing it with various inputs (e.g., test inputs and bench-
marks). New methodologies that improve code and CFG identiﬁca-
tion are orthogonal to our design and could be included alongside
our toolkit with little effort.
Every BBL identiﬁed during proﬁling is assigned a unique id
(BBID). BBIDs are calculated by combining the block’s offset from
the beginning of the executable image it belongs to with a hash of
the image’s text section to produce a 32-bit value. An example
control-ﬂow graph collected during proﬁling is shown in Fig. 3.
During dynamic proﬁling, we also keep a counter of how many
times each control-ﬂow transfer is observed.
In the example in
Fig. 3, when executing BBL2, BBL4 was followed 9999 times
while BBL3 only once.
3.2 Primary Code Generation
During code analysis we generate optimized code for the primary
thread to enqueue information necessary for performing DFT in
the secondary. The most frequently enqueued data are effective
addresses used in memory accesses and control-ﬂow transfers. This
section discusses our approach for minimizing the amount of data
we need to send to the secondary.
3.2.1 Effective Address Recording
A naive approach would transfer all addresses involved in mem-
ory operations to the secondary, leading to excessive overhead. We
developed a series of optimizations to reduce the number of ad-
dresses needed to be enqueued without compromising the sound-
ness of the analysis. Fig. 4 will assist us in presenting our methods.
We begin by transforming the BBL in Fig. 4 (a) into the DFT-
speciﬁc representation in Fig. 4 (b), which captures data depen-
dencies and data tracking semantics, as deﬁned in an intermediate
representation called Taint Flow Algebra (TFA) [18]. Each register
used in the BBL is treated like a variable. Whenever a register vari-
able is updated, a new version of the variable is created (e.g., eax1
in line 1 of Fig. 4(b)) that is valid within the BBL. For example, in
lines 1 to 4 and 6, of Fig. 4(b), a tag is copied, while in line 5 two
tags are combined, denoted by the OR (‘|’) operator.
Intra-block Optimization. We search for effective addresses
within a BBL that correlate with each other to identify the min-
imum set required that would correctly restore all of them in the
secondary. For instance, we only need to enqueue one of [esp0]
or [esp0 + 4] from Fig. 4 (b), as one can be derived from the
other by adding/subtracting a constant offset. This search is greatly
facilitated by the DFT transformation and register variables ver-
sioning, but it is applicable to all shadow memory analyses, as it
only tries to eliminate related addresses.
DFT Optimization. This optimization identiﬁes instructions,
and consequently memory operands, which are not going to be
used by the analysis in the secondary, by applying compiler op-
timizations, such as dead code elimination and data-ﬂow analysis,
against our DFT-speciﬁc representation of the BBL [18]. For in-
stance, in Fig. 4(b) we determine that the propagation in line 1 is
redundant, as its destination operand (eax1) is overwritten later in
line 3, before being referred by any other instruction. This allows
us to ignore its memory operand [esp0].
Inter-block Optimization. We extend the scope of the intra-
block optimization to cover multiple blocks connected by control
transfers. This implements backward data-ﬂow analysis [2] with
the partial CFG gathered during proﬁling. We begin by deﬁning the
input and output variables for each BBL. We then produce a list of
input and output memory operands which are live before entering
and when leaving a BBL. Using our representation, input memory
operands are the ones with all of its constituent register variables
in version 0, and output memory operands are the ones that have
all of its constituent register variables at their maximum version. In
our example in Fig. 4, the inputs list comprises of [esp0], and
the outputs list includes [esp0], [ebx1], [eax2 + ebx1],
and [eax2 + 2 × ebx1 + 200]. If all predecessors for the
BBL contain [esp0] in their outputs list, the block can harmlessly
exclude this from logging because the secondary still has a valid
reference to the value. The optimization has greater effect as more
inputs are found on the outputs lists of a block’s predecessors.
Since we only have a partial CFG of the application, it is possible
that at runtime we identify new execution paths that invalidate the
backwards data-ﬂow analysis. We tackle this issue by introducing
two heuristics that make inter-block optimization more conserva-
tive. First, if we ﬁnd any indirect jumps to a known BBL, we as-
sume that others may also exist and exclude these blocks from opti-
mization. Second, we assume that function entry point BBLs, may
be reachable by other, unknown indirect calls, and we also exclude
them. We consider these measures to be enough to cover most legit-
imate executions, but they are not formally complete, and as such
may not cover applications that are buggy or malicious. Note that
with the latter, we are not referring to vulnerable applications that
may be compromised, an event that can be prevented by DTA, but
malicious software that one may wish to analyze. In the case of
malware, this optimization can be disabled with negligible impact
on performance (see Sec. 6).
Linear Lower Bound. To enhance the intra- and inter-block
optimizations, we introduce the concept of Linear Lower bound,
which interprets memory operands as a series of linear equations:
breg + s × ireg + d
(2)
Memory addressing in x86 architectures can be expressed as a
linear equation (2). It contains two variables for base and index
registers (breg and ireg), a coefﬁcient s for scale, and a constant d
for displacement.2 Thus, we can say each BBL is associated with a
group of linear equations, where each equation represents a distinct
memory operand (Fig. 4(c)). For every BBL, we solve their group
of linear equations, which results in reducing the number of mem-
ory operands that need to be enqueued and decreasing the size of a
BBL’s inputs and outputs lists for the inter-block optimization. For
example, in line 5 of Fig. 4(c), [ebx1] is no longer required, as
it can be calculated from [eax2 + ebx1] and [eax2 + 2 ×
ebx1 + 200] in lines 4 and 6. It also helps inter-block analysis
by adding [eax2] to the BBL’s outputs list.
Having applied all, except the inter-block optimization, the num-
ber of effective addresses that need to be transferred for our exam-
ple is reduced from six to three (from Fig. 4(c) to (d)). The effects
of individual optimizations are discussed in Sec. 6.1.
3.2.2 Control Flow Recording
As in the previous section, a naive approach to ensure control
ﬂow replication would involve the primary enqueueing the BBID
of every BBL being executed. However, simply doing this for all
BBLs is too costly.
After examining how control-ﬂow transitions are performed in
x86 architectures, we identify three different types of instructions:
2Segmentation registers see limited use today, mostly for referring
to thread local storage (TLS). We ignore segmentation-based ad-
dressing for the Linear Lower Bound optimization.
239!"#$%$#&’(
)"#$%$#&*(
+"#,%-#&’(#.#/&’(#0#&*(#0#!112
3"#,%-#/&’(#0#&*(#2#.#&*(
4"#’55#&56#.#/&*(2
7"#,%-#&8(#.#/&8(#0#)#9#&*(#0#)112
!"#:;&’(!$12$1#0#32$1
)"#&’!#"=#&>$1#0#3
+"#&’)#"=&’(!#0#&*(!#0#!11
3"#&’+#"=#&’()#0#&*(!#
4"#&’3#"=#&*(!
7"#&’4#"=#&’()#0#)#9#&*(!#0#)11
!"#-%65#@AB@;&’1C#&’+C#&’4<#D
)"####AEF;EGH<#=#IEIJE;&’1#0#3<K
+"####L
3"####AEF;EMN<#?=#IEIJE;&’4#O#&’+#O)11<K
4"####AEF;EPH<#=#IEIJE;&’4<K
7"#Q
(a) x86 instruction
(b) DFT representation
(c) Distinct EAs
(d) Propagation body
Figure 4: Example of how a BBL is transformed during code analysis.
(a) direct jumps, (b) direct branches, and (c) indirect jumps. For
direct jumps, BBIDs for successor BBLs can be excluded from log-
ging, since there is only a single, ﬁxed exit once execution enters
into BBL0. For example, the transitions from BBL0 to BBL1, and
then to BBL2 in Fig. 3 can be excluded. Direct branches can have
two outcomes. They are either taken, or fall through where execu-
tion continues at the next instruction. We exploit this property to
only enqueue a BBID, when the least frequent outcome, according
to our dynamic proﬁling, occurs. For instance, when BBL3 follows
BBL2 in Fig. 3. We use the absence of BBL3’s id to signify that
BBL4 followed as expected. Note that if a BBL has two predeces-
sors and it is the most frequent path for only one of them, we log its
BBID. Last, for indirect jumps we always record the BBID follow-
ing them, since they are hard to predict. Fortunately, the number of
such jumps are less compared to direct transfers.
Applying our approach on the example CFG from Fig. 3, we
would only need to enqueue the id of BBL3 once. Obviously, this
approach offers greater beneﬁts when the proﬁling covers the seg-
ments of the application that are to run more frequently in practice.
It does not require that it covers all code, but unknown code paths
will not perform as well. We evaluate the effects of this optimiza-
tion for various applications in Sec. 6.
3.2.3 Ring Buffer Fast Checking
For every enqueueing operation from the primary, we should
check whether there is available space in the ring buffer to avoid
an overﬂow. However, performing this check within the DBI is
very costly, as it requires backing up the eflags register. We at-
tempt to reduce the frequency of this operation by performing it
selectively. For instance, every 100 BBLs. However, to correctly
placing the checks in the presence of CFG loops, so that they are
actually performed every 100 executed blocks, is challenging. We
mitigated this problem by introducing an algorithm, which ﬁnds ba-
sic blocks that program execution is ensured to visit at most every
k block executions. The problem formally stated is as follows.
We are given a CFG deﬁned as C = (V, E). C is a weighted
directed graph where V represents a set of basic blocks and E rep-
resents a set of edges that correspond to control transfers among
blocks. We also have a weight function w(v) that returns execution
counts for v ∈ V . Given that we want to ﬁnd a subset of vertices S
such that:
• For a given parameter k, we can assure that the program ex-
ecution will visit a node from S at most every k block exe-
cutions.
• Pv∈S w(v) is close to the minimum.
The above problem is identical to the feedback vertex set prob-
lem [13], which is NP-complete when any non-cyclic paths from
C is smaller than k. Thus, we can easily reduce our problem to
this one and use one of its approximation approaches. Addition-
ally, to take into consideration new execution paths not discovered
during proﬁling, the secondary monitors the ring buffer and signals
the primary, when it exceeds a safety threshold. Finally, we also
allocate a write-protected memory page at the end of the available
space in the ring buffer that will generate a page fault, which can
be intercepted and handled, in the case that all other checks fails.
3.3 Secondary Code Generation
During the off-line analysis we generate C code that implements
a program to dequeue information from the shared ring-buffer and
implement DFT. Listing 1 contains a secondary code block gener-
ated for the example in Fig. 4.
3.3.1 Control Flow Restoration
Each code segment begins with a goto label (line 2), which is
used with the goto statement to transfer control to the segment.
Control transfers are made by code appended to the segments. In
this example, lines 21 ∼ 31 implement a direct branch. First, we
check whether the ring buffer contains a valid effective address.
The presence of an address instead of BBID (i.e., the absence of
a BBID) indicates that the primary followed the more frequent
path (BBID 0xef13a598), as we determined during code analy-
sis (Sec. 3.2.2). Otherwise, the code most likely did not take the
branch and continued to the BBL we previously identiﬁed (in this
case 0xef13a5ba). We do not blindly assume this, but rather check
that this is indeed the case (line 25). We do this to accommodate
unexpected control-ﬂow transfers, such as the ones caused by sig-
nal delivery (Linux) or an exception (Windows). If an unexpected
BBID is found, we perform a look up in a hash table that contains
all BBLs identiﬁed during the analysis, and the result of the search
becomes the target of the transfer in line 29. Note that unknown
BBIDs point to a block handling the slow path. While a look up is
costly, this path is visited rarely. We also use macros likely()
and unlikely() (lines 5, 21, and 25) to hint the compiler to
favor the likely part of the condition.
3.3.2 Optimized DFT
Each code segment generated performs tag propagation for the
BBL it is associated with. Effective addresses are referenced di-
rectly within the ring buffer, and shadow memory is updated as
required by code semantics. For each BBL, optimized tag propaga-
tion logic is generated based on the methodology introduced in our
previous work [18]. Brieﬂy, this involves extracting tag propaga-
tion semantics and representing them in a DFT-speciﬁc form, which
is susceptible to multiple compiler-inspired optimizations that aim
at removing propagation instructions that have no practical effect
or cancel out each other, as well as reducing the number of instruc-
tions required for propagation by grouping them together.
The propagation code in lines 6 ∼ 12 is generated based on the
example in Fig. 4. rbuf() is a macro that returns a value in the
ring buffer relative to the current reading index. Ring buffer ac-
cesses correspond to ea0, ea3 and ea5 in Fig. 4(d). The MEM_E()
macro in lines 8 ∼ 11 translates memory addresses from the real
execution context to shadow memory locations, while REG() does
the same for registers.
240/∗ BBL label ∗/