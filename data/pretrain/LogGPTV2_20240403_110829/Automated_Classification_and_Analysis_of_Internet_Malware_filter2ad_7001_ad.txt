fact, while individual AV system rates may vary, over 96 percent of the malware
samples were detected by at least one of the AV systems. These samples are seen
signiﬁcantly more broadly than our single collection infrastructure and many AV
systems fail to detect them.
Conciseness. Conciseness represented the ability of the labeling system to group
similar items into groups that both reﬂected the important diﬀerences in samples,
but were devoid of superﬂuous labels. As in Section 2, we evaluate conciseness by
examining the characteristics of the grouping, or clusters, created by AV systems
with those created by our system. We examine the number of unique labels gener-
ated by the AV systems and a heuristically-generated notion of families or groups
of these labels extracted from the human readable strings. For example, the la-
bels W32-Sdbot.AC and Sdbot.42, are both in the “sdbot” family. As we noted
before, AV systems vary widely in how concisely they represent malware. Rela-
tive to other systems, our clusters strike a middle ground in conciseness, providing
fewer labels than the total unique labels of AV systems, but more than the number
of AV system families. This observation is consistent with the previous section—
the AV system families exhibit multiple diﬀerent behaviors, but these behaviors
have much in common across individual labels.
192
M. Bailey et al.
Consistency. Consistency referred to the ability of a labeling system to identify
similar or identical items in the same way. In the context of our behavioral
system goals, this implies that identical behaviors are placed in the same clusters.
In order to measure the consistency of the system, we examined the binaries
that exhibited exactly identical behavior. In the large sample, roughly 2,200
binaries shared exactly identical behavior with another sample. When grouped,
these 2,200 binaries created 267 groups in which each sample in the group had
exactly the same behavior. We compared the percentage of time the clusters
were identiﬁed as the same through our approach, as well as the various AV
system. As expected, our system placed all of the identical behaviors in the
same clusters. However, because consistency is a design goal of the system, the
consistency value for our technique is more a measure of correctness than quality.
What is interesting to note, however, is that AV systems obviously do not share
this same goal. AV systems only labled exactly identical behavior with the same
label roughly 31% to 68% percent of the time.
4.4 Application of Clustering and Behavior Signatures
In this subsection we look at several applications of this technique, in the context
of the clusters, created by our algorithm from the large dataset.
Classifying Emerging Threats. Behavioral classiﬁcation can be eﬀective in
characterizing emerging threats not yet known or not detected by AV signa-
tures. For example, cluster c156 consists of three malware samples that exhibit
malicious bot-related behavior, including IRC command and control activities.
Each of the 75 behaviors observed in the cluster is shared with other samples of
the group—96.92% on average, meaning the malware samples within the cluster
have almost identical behavior. However, none of the AV vendors detect the sam-
ples in this cluster except for F-Prot, which only detects one of the samples. It is
clear that our behavioral classiﬁcation would assist in identifying these samples
as emerging threats through their extensive malicious behavioral proﬁle.
Resisting Binary Polymorphism. Similarly, behavioral classiﬁcation can
also assist in grouping an undetected outlier sample (due to polymorphism or
some other deﬁciency in the AV signatures) together with a common family that
it shares signiﬁcant behaviors with. For example, cluster c80 consists of three
samples that share identical behaviors with distinctive strings ”bling.exe” and
”m0rgan.org.” The samples in this cluster are consistently labeled as a malicious
bot across the AV vendors except Symantec, which fails to identify one of the
samples. To maintain completeness, this outlier sample should be labeled similar
to the other samples based on its behavioral proﬁle.
Examining the Malware Behaviors. Clearly one of the values of any type
of automated security system is not to simply provide detailed information on
individual malware, but also to provide broad analysis on future directions of
malware. Using the behavioral signatures created by our system, we extracted
Automated Classiﬁcation and Analysis of Internet Malware
193
Table 10. The top ﬁve behaviors observed by type
Process
execs cmd.exe
execs IEXPLORE.EXE writes tasklist32.exe uses PRNG
Files
writes winhlp32.dat uses wininet.dll
Registry
Network
connects to 80
connects to 25
connects to 6667 execs regedit.exe
connects to 587
scans port 80
execs tasklist32.exe
execs svchost.exe
writes change.log
writes mirc.ini
writes svchost.exe
modiﬁes registered applications
modiﬁes proxy settings
modiﬁes mounted drives
the most prevalent behaviors for each of the various categories of behaviors we
monitor. The top ﬁve such behaviors in each category are shown in Table 10.
The network behavior seems to conform with agreed notions of how the tasks
are being performed by most malware today. Two of the top ﬁve network behav-
iors involve the use of mail ports, presumably for spam. Port 6667 is a common
IRC port and is often used for remote control of the malware. Two of the ports
are HTTP ports used by systems to check for jailed environments, download
code via the web, or tunnel command and control over what is often an unﬁl-
tered port. The process behaviors are interesting in that many process executa-
bles are named like common Windows utilities to avoid arousing suspicion (e.g.,
svchost.exe, tasklist32.exe). In addition, some malware uses IEXPLORE.EXE
directly to launch popup ads and redirect users to potential phishing sites. This
use of existing programs and libraries will make simple anomaly detection tech-
niques more diﬃcult. The ﬁle writes show common executable names and data
ﬁles written to the ﬁlesystem by malware. For example, the winhlp32.dat ﬁle
is a data ﬁle common to many Bancos trojans. Registry keys are also fairly in-
teresting indications of behavior and the prevalence of wininet.dll keys shows
heavy use of existing libraries for network support. The writing to PRNG keys
indicates a heavy use of randomization, as the seed is updated every time a
PRNG-related function is used. As expected, the malware does examine and
modify the registered application on a machine, the TCP/IP proxy settings (in
part to avoid AV), and it queries mounted drives.
5 Related Work
Our work is the ﬁrst to apply automated clustering to understand malware be-
havior using resulting state changes on the host to identify various malware
families. Related work in malware collection, analysis, and signature generation
has primarily explored static and byte-level signatures [23,17] focusing on in-
variant content. Content-based signatures are insuﬃcient to cope with emerging
threats due to intentional evasion. Behavioral analysis has been proposed as a
solution to deal with polymorphism and metamorphism, where malware changes
its visible instruction sequence (typically the decryptor routine) as it spreads.
Similar to our work, emulating malware to discover spyware behavior by using
anti-spyware tools has been used in measurements studies [22].
There are several abstraction layers at which behavioral proﬁles can be cre-
ated. Previous work has focused on lower layers, such as individual system
calls [15,10],instruction-based code templates [6], the initial code run on malware
194
M. Bailey et al.
infection (shellcode) [18], and network connection and session behavior [30]. Such
behavior needs to be eﬀectively elicited. In our work, we chose a higher abstrac-
tion layer for several reasons. In considering the actions of malware, it is not the
individual system calls that deﬁne the signiﬁcant actions that a piece of malware
inﬂicts upon the infected host; rather, it is the resulting changes in state of the
host. Also, although lower levels may allow signatures that diﬀerentiate mal-
ware, they do not provide semantic value in explaining behaviors exhibited by a
malware variant or family. In our work, we deﬁne malware by what it actually
does, and thereby build in more semantic meanings to the proﬁles and clusters
generated.
Various aspects of high-level behavior could be included in the deﬁnition of a
behavioral proﬁle. Network behavior may be indicative of malware and has been
used to detect malware infections. For example, Ellis et al. [9] extracted network-
level features, such as similar data being sent from one machine to the next. In
our work, we focus on individual host behavior, including network connection
information but not the data transmitted over the network. Thus, we focus more
on the malware behavior on individual host systems instead of the pattern across
a network.
Recently, Kolter and Maloof [13] studied applying machine learning to clas-
sify malicious executables using n-grams of byte codes. Our use of hierarchical
clustering based on normalized compression distance is a ﬁrst step at examining
how statistical techniques are useful in classifying malware, but the features used
are the resulting state changes on the host to be more resistant to evasion and
inaccuracies. Normalized information distance was proposed by Li et al. [16] as
an optimal similarity metric to approximate all other eﬀective similarity metrics.
In previous work [29], NCD was applied to worm executables directly and to the
network traﬃc generated by worms. Our work applies NCD at a diﬀerent layer
of abstraction. Rather than applying NCD to the literal malware executables,
we apply NCD to the malware behavior.
6 Limitations and Future Work
Our system is not without limitations and shares common weaknesses asso-
ciated with dynamic analysis. Since the malware samples were executed within
VMware, samples that employ anti-VM evasion techniques may not exhibit their
malicious behavior. To mitigate this limitation, the samples could be run on a
real, non-virtualized system, which would be restored to a clean state after each
simulation. Another limitation is the time period in which behaviors are collected
from the malware execution. In our experiments, each binary was able to run for
ﬁve minutes before the virtual machine was terminated. It is possible that cer-
tain behaviors were not observed within this period due to time-dependent or de-
layed activities. Previous research has been done to detect such time-dependent
triggers [8]. A similar limitation is malware that depends on user input, such
as responding to a popup message box, before exhibiting further malicious be-
havior, as mentioned in [22]. Finally, the capabilities and environment of our
Automated Classiﬁcation and Analysis of Internet Malware
195
virtualized system stayed static throughout our experiments. However, varying
the execution environment by using multiple operating system versions, includ-
ing other memory resident programs such as anti-virus protection engines, and
varying network connectivity and reachability may yield interesting behaviors
not observed in our existing results. Recently, a generic approach to these and
other problems associated with dynamic analysis has be suggested by Moser, et
al. [21]. Their approach is based on exploring multiple execution paths through
tracing and rewriting key input values in the system, which could yield additional
behaviors unseen in our single execution path.
Our choice of a high level of abstraction may limit ﬁne-grained visibility into
each of the observed behaviors in our system. A path for future work could in-
clude low-level details of each state change to supplement the high-level behavior
description. For example, the actual contents of disk writes and transmitted net-
work packets could be included in a sample’s behavioral proﬁle. In addition, we
plan to evaluate the integration of other high-level behavioral reports from ex-
isting systems, such as Norman [24] and CWSandbox [5], in the future. We will
also investigate further clustering and machine-learning techniques that may
better suit these other types of behavioral proﬁles. Finally, the causal graphs
from Backtracker, which are used to identify the behaviors in our system, also
include dependency information that is currently ignored. In future versions, this
dependency information could be used to further diﬀerentiate behaviors.
7 Conclusion
In this paper, we demonstrated that existing host-based techniques (e.g., anti-
virus) fail to provide useful labels to the malware they encounter. We showed
that AV systems are incomplete in that they fail to detect or provide labels
for between 20 to 49 percent of the malware samples. We noted that when
these systems do provide labels, these labels are not consistent, both within a
single naming convention as well as across multiple vendors and conventions.
Finally, we demonstrated that these systems vary widely in their conciseness—
from aggressive, nearly individual labels that ignore commonalities, to broad
general groups that hide important details.
To address these important limitations, we proposed a novel approach to
the problem of automated malware classiﬁcation and analysis. Our dynamic
approach executes the malware in a virtualized environment and creates a be-
havioral ﬁngerprint of the malware’s activity. This ﬁngerprint is the set of all
the state changes that are a causal result of the infection, including ﬁles mod-
iﬁed, processes created, and network connections. In order to compare these
ﬁngerprints and combine them into meaningful groups of behaviors, we apply
single-linkage hierarchical clustering of the ﬁngerprints using normalized com-
press distance as a distance metric. We demonstrated the usefulness of this
technique by applying it to the automated classiﬁcation and analysis of 3,700
malware samples collected over the last six months. We compared the clusters
generated to existing malware classiﬁcation (i.e., AV systems) and showed the
196
M. Bailey et al.
technique’s completeness, conciseness, and consistency. Through these evalua-
tions, we showed that this new technique provides a novel way of understanding
the relationships between malware and is an important step forward in under-
standing and bridging existing malware classiﬁcations.
Acknowledgments
This work was supported in part by the Department of Homeland Security (DHS)
under contract numbers NBCHC040146 and NBCHC060090, by the National
Science Foundation (NSF) under contract number CNS 0627445 and by corpo-
rate gifts from Intel Corporation and Cisco Corporation. We would like to thank
our shepherd, Jonathon Giﬃn, for providing valuable feedback on our submission
as well as the anonymous reviewers for critical and useful comments.
References
1. Arbor malware library (AML) (2006), http://www.arbornetworks.com/
2. Baecher, P., Koetter, M., Holz, T., Dornseif, M., Freiling, F.: The nepenthes plat-
form: An eﬃcient approach to collect malware. In: Zamboni, D., Kruegel, C. (eds.)
RAID 2006. LNCS, vol. 4219, Springer, Heidelberg (2006)
3. Barford, P., Yagneswaran, V.: An inside look at botnets. In: Series: Advances in
Information Security, Springer, Heidelberg (2006)
4. Beck, D., Connolly, J.: The Common Malware Enumeration Initiative. In: Virus
Bulletin Conference (October 2006)
5. Willems, C., Holz, T.: Cwsandbox (2007), http://www.cwsandbox.org/
6. Christodorescu, M., Jha, S., Seshia, S.A., Song, D., Bryant, R.E.: Semantics-aware
malware detection. In: Proceedings of the 2005 IEEE Symposium on Security and
Privacy (Oakland 2005), Oakland, CA, USA, May 2005, pp. 32–46. ACM Press,
New York (2005)
7. Cormen, T.H., Leiserson, C.E., Rivest, R.L., Stein, C.: Introduction to Algorithms.
MIT Press, Cambridge, MA (1990)
8. Crandall, J.R., Wassermann, G., de Oliveira, D.A.S., Su, Z., Wu, S.F., Chong, F.T.:
Temporal Search: Detecting Hidden Malware Timebombs with Virtual Machines.
In: Proceedings of ASPLOS, San Jose, CA, October 2006, ACM Press, New York
(2006)
9. Ellis, D., Aiken, J., Attwood, K., Tenaglia, S.: A Behavioral Approach to Worm
Detection. In: Proceedings of the ACM Workshop on Rapid Malcode (WORM04),
October 2004, ACM Press, New York (2004)
10. Gao, D., Beck, D., Reiter, J.C.M.K., Song, D.X.: Behavioral distance measurement
using hidden markov models. In: Zamboni, D., Kruegel, C. (eds.) RAID 2006.
LNCS, vol. 4219, pp. 19–40. Springer, Heidelberg (2006)
11. Hastie, T., Tibshirani, R., Friedman, J.: The Elements of Statistical Learning: Data
Mining, Inference, and Prediction. Springer, Heidelberg (2001)
12. King, S.T., Chen, P.M.: Backtracking intrusions. In: Proceedings of the 19th ACM
Symposium on Operating Systems Principles (SOSP’03), Bolton Landing, NY,
USA, October 2003, pp. 223–236. ACM Press, New York (2003)
13. Kolter, J.Z., Maloof, M.A.: Learning to Detect and Classify Malicious Executables
in the Wild. Journal of Machine Learning Research (2007)
Automated Classiﬁcation and Analysis of Internet Malware
197
14. Koutsoﬁos, E., North, S.C.: Drawing graphs with dot. Technical report, AT&T
Bell Laboratories, Murray Hill, NJ (October 8, 1993)
15. Lee, T., Mody, J.J.: Behavioral classiﬁcation. In: Proceedings of EICAR 2006 (April
2006)
16. Li, M., Chen, X., Li, X., Ma, B., Vit´anyi, P.: The similarity metric. In: SODA ’03:
Proceedings of the fourteenth annual ACM-SIAM symposium on Discrete algo-
rithms, Philadelphia, PA, USA. Society for Industrial and Applied Mathematics,
pp. 863–872 (2003)
17. Li, Z., Sanghi, M., Chen, Y., Kao, M., Chavez, B.: Hamsa: Fast Signature Gener-
ation for Zero-day Polymorphic Worms with Provable Attack Resilience. In: Proc.
of IEEE Symposium on Security and Privacy, IEEE Computer Society Press, Los
Alamitos (2006)
18. Ma, J., Dunagan, J., Wang, H., Savage, S., Voelker, G.: Finding Diversity in Remote
Code Injection Exploits. In: Proceedings of the USENIX/ACM Internet Measure-
ment Conference, October 2006, ACM Press, New York (2006)
19. McAfee: W32/Sdbot.worm (April 2003),
http://vil.nai.com/vil/content/v_100454.htm
20. Microsoft: Microsoft security intelligence report: (January-June 2006) (October
2006), http://www.microsoft.com/technet/security/default.mspx
21. Moser, A., Kruegel, C., Kirda, E.: Exploring multiple execution paths for mal-
ware analysis. In: Proceedings of the IEEE Symposium on Security and Privacy
(Oakland 2007), May 2007, IEEE Computer Society Press, Los Alamitos (2007)
22. Moshchuk, A., Bragin, T., Gribble, S.D., Levy, H.M.: A Crawler-based Study of
Spyware in the Web. In: Proceedings of the Network and Distributed System Se-
curity Symposium (NDSS), San Diego, CA (2006)
23. Newsome, J., Karp, B., Song, D.: Polygraph: Automatically generating signatures
for polymorphic worms. In: Proceedings 2005 IEEE Symposium on Security and
Privacy, Oakland, CA, USA, May 8–11, 2005, IEEE Computer Society Press, Los
Alamitos (2005)
24. Norman Solutions: Norman sandbox whitepaper (2003),
http:// download.norman.no/whitepapers/whitepaper Norman SandBox.pdf
25. Nykter, M., Yli-Harja, O., Shmulevich, I.: Normalized compression distance for
gene expression analysis. In: Workshop on Genomic Signal Processing and Statistics
(GENSIPS) (May 2005)
26. Prince, M.B., Dahl, B.M., Holloway, L., Keller, A.M., Langheinrich, E.: Under-
standing how spammers steal your e-mail address: An analysis of the ﬁrst six
months of data from project honey pot. In: Second Conference on Email and Anti-
Spam (CEAS 2005) (July 2005)
27. Walters, B.: VMware virtual platform. j-LINUX-J 63 (July 1999)
28. Wang, Y.-M., Beck, D., Jiang, X., Roussev, R., Verbowski, C., Chen, S., King,
S.T.: Automated web patrol with strider honeymonkeys: Finding web sites that
exploit browser vulnerabilities. In: Proceedings of the Network and Distributed
System Security Symposium, NDSS 2006, San Diego, California, USA (2006)
29. Wehner, S.: Analyzing worms and network traﬃc using compression. Technical
report, CWI, Amsterdam (2005)
30. Yegneswaran, V., Giﬃn, J.T., Barford, P., Jha, S.: An Architecture for Generat-
ing Semantics-Aware Signatures. In: Proceedings of the 14th USENIX Security
Symposium, Baltimore, MD, USA, August 2005, pp. 97–112 (2005)