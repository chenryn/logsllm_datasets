==== 消息队列 Kafka
在数据接入以后，将首先进入消息队列组件中进行暂存。部分开源/商业日志分析产品中并不引入消息队列组件，在数据量因为业务原因突发增量时，很有可能会导致后续索引流程达到瓶颈，最后导致整个集群性能波动直至数据丢失。
因此，从数据可靠性角度出发，消息队列是日志分析系统中不可或缺的组件。
此外，消息队列组件还有助于不同目的的数据分发和消费。在日志易平台中，包括数据清洗组件 LogRiver、备份组件 Archiver、智能运维组件 KPIMonitor、数据工厂组件 DataFlow 等，都可以从消息队列中的特定 Topic 主题进行数据消费。日志易同样允许非自身的其他第三方应用进行数据消费。
==== 数据清洗和路由 LogRiver
对数据进行 ETL 清洗是日志分析的前提步骤。为了尽量减少对客户应用的影响，数据采集层一般不进行具体的数据清洗操作。LogRiver 组件是日志易研发的数据清洗组件，它运行在消息队列组件的下游，可以进行无状态横向集群扩展。LogRiver 专注于流式单行日志解析。
除了数据清洗以外，LogRiver 还负责对数据的转发路由管理。目前，日志易支持对清洗以后的日志数据，根据指定规则，转发到消息队列组件的其他 Topic 主题，或者写入到索引存储组件的其他 Index 索引。经测试验证，LogRiver 组件比基于开源 Spark Streaming 实现的数据清洗入库速度，在相同资源消耗情况下提高了一个数量级。
==== 索引存储 Beaver
Beaver 存储引擎是日志易的核心技术所在。日志易在吸取了 Lucene 开源社区多年积累经验的基础上，针对日志数据的特点，采用 C++ 语言自主开发了 Beaver 索引存储组件。和主流开源方案相比，在日志分析场景上，提供了诸多功能和性能上的优势。
.方案优缺点对比
[options="header",cols="1,2a,2a"]
|====
|对比|	开源方案|  	Beaver
|真实时
|1. 准实时索引检索引擎
2. 模拟实时需要定期Flush将数据转化成磁盘结构（Refresh）,会消耗大量 IO
|1. 纯实时索引检索引擎
2. 内存原地检索不必耗费I/O
|并发写入效率提升
400%－500%
|1. Segment只能由一个线程写
2. 产生的Segment的数目极多，每个Segment的DOC数目少，严重依赖Merge
3. Merge会占用大量的IO和CPU
4. Merge不及时会导致低性能
|1. Segment支持内部并发写
2. 单Segment更大，减少Segment数量
3. Merge的规模小，正常情况下因Merge产生的IO和CPU消耗很低
|
查询性能提升50%－200%
|1. 实时系统中会导致频繁的Global Ordinal失效和重建
2. 由于Segment频繁变动导致Global Ordinal大量失效
3. 每次检索都需要检索全部的Segment
4. 按时间排序取Top N的算法不够高效
|1. Global Ordinal能长期使用
2. 可以根据时间戳和Query的范围排除大量不需要检索的Block
3. 某些情况下可以优化Query，不进行时间戳过滤
4. 按时间戳排序取Top N时排除掉大量的Block
|有效的内存控制
能同时打开更多索引	
|1. 能同时打开的索引数目有限
2. 所有打开的Segment都需要加载全部数据的Meta
3. Meta往往耗费大量的内存
|1. 选择性加载Meta
2. 可以管理的Segment没有内存限制
3. Meta耗费的内存可以控制
|更有效冷温热索引分级控制	
|1. 长期保留索引时，需要把所有索引源数据打开，带来很大资源消耗
2. 需要上层干预索引打开和关闭
3. 无法自动进行索引分级控制	
|1. 对索引打开数量不敏感
2. 引擎会自动根据ssd，sata，nas不同级别存储完成热，温，冷索引迁移和控制
|内存控制更好
|1. 采用Java开发
2. 高性能依赖JIT编译器
3. 容易引起GC	
|1. 采用C++开发
2. 性能优化可以做到极致
3. 内存使用完全可控
|====
Beaver 与主流开源方案的读写性能测试对比见下图：
image::images/beaver-resp.png[]
根据全方面对比，同样入库和查询条件下，beaver比主流开源方案要节省一半硬件成本。
==== 搜索统计 SPLServer
为了提供更加丰富和灵活的查询和统计功能，日志易设计了独特的 SPL(Search Processing Language) 语法。搜索统计模块 SPLServer 承担了对 SPL 的语法解析和任务调度工作。
其中，SPL 语法指令又分为流式指令和集中式指令。流式指令部分，SPLServer 在解析之后，可以自动分发到 Beaver 存储组件上分布式执行。集中式指令则在 SPLServer 本地执行。
此外，根据 SPL 语法作用的不同，还能分为生成指令等 10 类，我们总结 SPL 语法周期表如下：
image::images/spl-commands-table.png[]
SPLServer 上负责进行两类任务的调度工作。一类是查询层级，SPLServer 会自动对所有的 SPL 查询进行基于时间的分片，并对分片后的子任务进行公平轮询调度，以尽量保证不同用户的查询都能得到应有的响应。避免主流开源方案中一个大范围查询挂起全集群的现象。此外，SPLServer 可以根据用户需要，将特定场景(如海量分组数据精准统计)的查询，自动转换为 Flink 任务，分发给 Flink 集群执行。避免主流开源方案中对海量分组统计的结果误差和 OutOfMemory 故障现象。
另一类是结果处理层级，SPLServer 负责日志易所有需要后台离线执行的查询任务的执行计划调度。包括：离线任务、下载任务、定时任务、告警任务、报表任务等。
SPLServer 同样可以横向集群扩展，其中任务状态和任务结果数据，将依赖于名字服务组件 Zookeeper 和共享存储组件 HDFS。
==== 展现和接口 YottaWeb
在搜索统计基础上，所有的日志易展现层功能，包括但不限于：搜索、统计、可视化、仪表盘、报表、告警等。均有 YottaWeb 组件提供。此外，YottaWeb 组件还负责权限配置、资源管理和数据查询等各种功能服务的对外 API 接口。
YottaWeb 组件同样可以横向集群扩展，并通过最外层的负载均衡组件 Nginx 进行代理转发。
==== 算法服务 Analyzer
算法服务组件包括 KPIAnalyzer 和 LogAnalyzer。组件提供了日志易针对智能运维需求定制开发的各种 AI 算法。算法服务组件本身并不提供数据处理和产品功能层面的封装。指标数据的消费处理和算法调用，由 KPIMonitor 完成。日志数据的消费处理和算法调用，则会生成 FlinkStreaming 任务在 Flink 组件上完成。
==== 管理维护 Manager
日志易集群本身的运行维护，包括各组件的部署、配置变更、性能监控告警、版本升级，通过独立的 Manager 组件完成。日志易本身可以脱离 Manager 组件独立运行，但是为了长期运维考虑，建议用户采用 Manager 模块来管理和维护日志易集群。其中，各组件的性能监控指标数据，也同样存储在独立的 InfluxDB 组件中。
== 日志易部署需求
=== 服务器要求与资源评估
应用部署策略用以指导用户依据自身的业务规模，以及对性能、可靠性等方面的具体要求，来确定合适的系统配置和部署方案。用户的环境和要求千差万别，本节只是给出一个指导性的配置策略，依实际情况的不同，用户可能需要在本部署策略的基础之上做适当调整以满足特定需求。
==== 单服务器最低要求
在数据流量较小，eps 在 1000 以下的体验试用环境中，可以尝试最低配置的单台服务器部署。日志易要求的最低配置如下：
* OS：CentOS 6.5 x86_64
* CPU：8核 2.0GHz
* MEM：16GB
* DISK：300GB
数据量较大的正式环境中，需要在数台到上百台服务器上进行集群化部署。集群化部署的资源评估参见稍后章节。
==== CPU资源需求评估
集群部署的资源需求因规模不同而异，但规模只是影响部署需求和架构的诸多因素之一。以下推荐值可为您的规划提供一些参考，每个特定部署的实际数量将有所出入，根据日志量大小，我们分别为用户提供了小型、中型、大型3种推荐部署方案，部署的特性将随着规模的增长而变化，您可以在一定程度上了解所需要的内容。
* 小型
+
数据量20-100 GB/日，1000 ~ 5000 eps （event per second，每秒日志数量），需要10-20核CPU。
* 中型
+
数据量100GB-300GB /日，5000 ~ 15000 eps，需要20-54核CPU。
* 大型
+
数据量 >= 300GB /日，20000+ eps，至少需要54核CPU。