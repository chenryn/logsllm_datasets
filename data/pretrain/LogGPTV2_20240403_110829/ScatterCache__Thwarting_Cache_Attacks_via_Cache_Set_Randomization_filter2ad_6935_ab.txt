3.2
Two main ideas inﬂuenced the design of SCATTERCACHE to
reach the desired security properties. First, addresses should
be translated to cache sets using a keyed, security-domain
aware mapping. Second, which exact nways cache lines form a
cache set in a nways-way associative cache should not be ﬁxed,
but depend on the currently used key and security domain
too. SCATTERCACHE combines both mappings in a single
operation that associates each address, depending on the key
and security domain, with a set of up to nways cache lines.
In other words, in a generic SCATTERCACHE, any possible
combination of up to nways cache lines can form a cache set.
Figure 2 visualizes the idea and shows how it differs from
related work. Traditional caches as well as alternative designs
which pseudorandomly map addresses to cache sets statically
allocate cache lines to cache sets. Hence, as soon as a cache
set is selected based on (possibly encrypted) index bits, al-
ways the same nways cache lines are used. This means that all
addresses mapping to the same cache set are congruent and
enables PRIME+PROBE-style attacks.
In SCATTERCACHE, on the other hand, the cache set for
a particular access is a pseudorandom selection of arbitrary
nways cache lines from all available lines. As a result, there
is a much higher number of different cache sets and ﬁnding
addresses with identical cache sets becomes highly unlikely.
678    28th USENIX Security Symposium
USENIX Association
Set 0Set 1Set 2Set 3Addr. AAddr. BAddr. AAddr. BFigure 3: Idea: For an nways associative cache, nways indices
into the cache memory are derived using a cryptographic IDF.
This IDF effectively randomizes the mapping from addresses
to cache sets as well as the composition of the cache set itself.
Instead, as shown at the bottom of Figure 2, at best, partially
overlapping cache sets can be found (cf. Section 4.3), which
makes exploitation tremendously hard in practice.
A straightforward concept for SCATTERCACHE is shown in
Figure 3. Here, the Index Derivation Function (IDF) combines
the mapping operations in a single cryptographic primitive.
In a set-associative SCATTERCACHE with set size nways, for
each input address, the IDF outputs nways indices to form the
cache set for the respective access. How exactly the mapping
is performed in SCATTERCACHE is solely determined by the
used key, the Security Domain Identiﬁer (SDID), and the IDF.
Note that, as will be discussed in Section 3.3.1, hash-based as
well as permutation-based IDFs can be used in this context.
Theoretically, a key alone is sufﬁcient to implement the
overall idea. However, separating concerns via the SDID
leads to a more robust and harder-to-misuse concept. The
key is managed entirely in hardware, is typically longer, and
gets switched less often than the SDID. On the other hand,
the SDID is managed solely by the software and, depend-
ing on the implemented policy, has to be updated quite fre-
quently. Importantly, as we show in Section 4, SCATTER-
CACHE alone already provides signiﬁcantly improved se-
curity in PRIME+PROBE-style attack settings even without
software support (i.e., SDID is not used).
3.3 SCATTERCACHE Design
In the actual design we propose for SCATTERCACHE, the
indices (i.e., IDF output) do not address into one huge joint
cache array. Instead, as shown in Figure 4, each index ad-
dresses a separate memory, i.e., an independent cache way.
On the one hand, this change is counter-intuitive as
it decreases the number of possible cache sets from
(cid:1) to 2bindices·nways. However, this reduction
(cid:0)nways·2bindices +nways−1
nways
in possibilities is acceptable. For cache conﬁgurations with
up to 4 cache ways, the gap between both approaches is only
a few bits. For higher associativity, the exponential growth
ensures that sufﬁciently many cache sets exist.
On the other hand, the advantages gained from switching
to this design far outweigh the costs. Namely, for the original
idea, no restrictions on the generated indices exist. Therefore,
a massive nways-fold multi-port memory would be required to
Figure 4: 4-way set-associative SCATTERCACHE where each
index addresses exclusively one cache way.
be able to lookup a nways-way cache-set in parallel. The de-
sign shown in Figure 4 does not suffer from this problem and
permits to instantiate SCATTERCACHE using nways instances
of simpler/smaller memory. Furthermore, this design guar-
antees that even in case the single index outputs of the IDF
collide, the generated cache always consists of exactly nways
many cache lines. This effectively precludes the introduction
of systematic biases for potentially “weak” address-key-SDID
combinations that map to fewer than nways cache lines.
In terms of cache-replacement policy, SCATTERCACHE
uses simple random replacement to ensure that no systematic
bias is introduced when writing to the cache and to simplify
the security analysis. Furthermore, and as we will show in
Section 5, the performance of SCATTERCACHE with random
replacement is competitive to regular set associative caches
with the same replacement policy. Therefore, evaluation of
alternative replacement policies has been postponed. Inde-
pendent of the replacement policy, it has to be noted that, for
some IDFs, additional tag bits have to be stored in SCATTER-
CACHE. In particular, in case of a non invertible IDF, the
original index bits need to be stored to facilitate write back of
dirty cache lines and to ensure correct cache lookups. How-
ever, compared to the amount of data that is already stored for
each cache line, the overhead of adding these few bits should
not be problematic (< 5% overhead).
In summary, the overall hardware design of SCATTER-
CACHE closely resembles a traditional set-associative archi-
tecture. The only differences to contemporary ﬁxed-set de-
signs is the more complex IDF and the amount of required
logic which permits to address each way individually. How-
ever, both changes are well understood. As we detail in the
following section, lightweight (i.e., low area and latency) cryp-
tographic primitives are suitable building blocks for the IDF.
Similarly, duplication of addressing logic is already common
practice in current processors. Modern Intel architectures, for
example, already partition their Last-Level Cache (LLC) into
multiple smaller cache slices with individual addressing logic.
3.3.1 Suitable Index Derivation Functions
Choosing a suitable IDF is essential for both security and
performance. In terms of security, the IDF has to be an un-
predictable (but still deterministic) mapping from physical
addresses to indices. Following Kerckhoffs’s principle, even
USENIX Association
28th USENIX Security Symposium    679
IDFcache line addresskeyidx0-3idx0idx2idx1idx3SDIDoffsettagindexoffsetidx0way 3indextagIDFcache lineaddr.keyidx1idx2idx3way 1way 2way 0SDIDfor attackers which know every detail except the key, three
properties are expected from the IDF: (1) Given perfect con-
trol over the public inputs of the function (i.e., the physical
address and SDID) constructing colliding outputs (i.e., the
indices) should be hard. (2) Given colliding outputs, deter-
mining the inputs or constructing further collisions should be
hard. (3) Recovering the key should be infeasible given input
and output for the function.
Existing Building Blocks: Cryptographic primitives like
(tweakable) block ciphers, Message Authentication Codes
(MACs), and hash functions are designed to provide these
kind of security properties (e.g., indistinguishability of en-
cryptions, existential unforgeability, pre-image and collision
resistance). Furthermore, design and implementation of cryp-
tographic primitives with tight performance constraints is
already a well-established ﬁeld of research which we want
to take advantage of. For example, with PRINCE [13], a
low-latency block cipher, and QARMA [8], a family of low-
latency tweakable block ciphers, exist and can be used as
building blocks for the IDF. Such tweakable block ciphers
are a ﬂexible extension to ordinary block ciphers, which, in
addition to a secret key, also use a public, application-speciﬁc
tweak to en-/decrypt messages. Similarly, sponge-based MAC,
hash and cipher designs are a suitable basis for IDFs. These
sponge modes of operation are built entirely upon permuta-
tions, e.g., Keccak-p, which can often be implemented with
low latency [7, 11]. Using such cryptographic primitives, we
deﬁne the following two variants of building IDFs:
Hashing Variant (SCv1): The idea of SCv1 is to combine
all IDF inputs using a single cryptographic primitive with
pseudo random output. MACs (e.g., hash-based) are examples
for such functions and permit to determine the output indices
by simply selecting the appropriate number of disjunct bits
from the calculated tag. However, also other cryptographic
primitives can be used for instantiating this IDF variant.
It is, for example possible to slice the indices from the
ciphertext of a regular block cipher encryption which uses
the concatenation of cache line address and the SDID as the
plaintext. Similarly, tweakable block ciphers allow to use the
SDID as a tweak instead of connecting it to the plaintext.
Interestingly, ﬁnding cryptographic primitives for SCv1 IDFs
is comparably simple given that the block sizes do not have
to match perfectly and the output can be truncated as needed.
However, there are also disadvantages when selecting the
indices pseudo randomly, like in the case of SCv1. In par-
ticular, when many accesses with high spatial locality are
performed, index collisions get more likely. This is due to
the fact that collisions in SCv1 output have birthday-bound
complexity. Subsequently, performance can degrade when
executing many different accesses with high spatial locality.
Fortunately, this effect weakens with increasing way numbers,
i.e., an increase in associativity decreases the probability that
all index outputs of the IDF collide.
In summary, SCv1 translates the address without distin-
guishing between index and tag bits. Given a ﬁxed key and
SDID, the indices are simply pseudo random numbers that
are derived using a single cryptographic primitive.
Permutation Variant (SCv2): The idea behind the permu-
tation variant of the IDF is to distinguish the index from the
tag bits in the cache line address during calculation of the
indices. Speciﬁcally, instead of generating pseudo random in-
dices from the cache line address, tag dependent permutations
of the input index are calculated.
The reason for preferring a permutation over pseudo ran-
dom index generation is to counteract the effect of birthday-
bound index collisions, as present in SCv1. Using a tag de-
pendent permutation of the input index mitigates this problem
by design since permutations are bijections that, for a speciﬁc
tag, cannot yield colliding mappings.
Like in the hashing variant, a tweakable block cipher can
be used to compute the permutation. Here, the concatenation
of the tag bits, the SDID and the way index constitutes the
tweak while the address’ index bits are used as the plaintext.
The resulting ciphertext corresponds to the output index for
the respective way. Note that the block size of the cipher has
to be equal to the size of the index. Additionally, in order to
generate all indices in parallel, one instance of the tweakable
block cipher is needed per cache way. However, as the block
size is comparably small, each cipher instance is also smaller
than an implementation of the hashing IDF (SCv1).
Independently of the selected IDF variant, we leave the
decision on the actually used primitive to the discretion of
the hardware designers that implement SCATTERCACHE.
They are the only ones who can make a profound decision
given that they know the exact instantiation parameters (e.g.,
SDID/key/index/tag bit widths, number of cache ways) as
well as the allocatable area, performance, and power bud-
get in their respective product. However, we are certain that,
even with the already existing and well-studied cryptographic
primitives, SCATTERCACHE implementations are feasible
for common computing platforms, ranging from Internet of
Things (IoT) devices to desktop computers and servers.
Note further that we expect that, due to the limited ob-
servability of the IDF output, weakened (i.e., round reduced)
variants of general purpose primitives are sufﬁcient to achieve
the desired security level. This is because adversaries can only
learn very little information about the function output by ob-
serving cache collisions (i.e., no actual values). Subsequently,
many more traces have to be observed for mounting an attack.
Cryptographers can take advantage of this increase in data
complexity to either design fully custom primitives [55] or to
decrease the overhead of existing designs.
3.3.2 Key Management and Re-Keying
The key in our SCATTERCACHE design plays a central role in
the security of the entire approach. Even when the SDIDs are
known, it prevents attackers from systematically constructing
680    28th USENIX Security Symposium
USENIX Association
eviction sets for speciﬁc physical addresses and thwarts the
calculation of addresses from collision information. Keeping
the key conﬁdential is therefore of highest importance.
We ensure this conﬁdentiality in our design by mandating
that the key of is fully managed by hardware. There must not
be any way to conﬁgure or retrieve this key in software. This
approach prevents various kinds of software-based attacks
and is only possible due to the separation of key and SDID.
The hardware for key management is comparably simple as
well. Each time the system is powered up, a new random key is
generated and used by the IDF. The simplicity of changing the
key during operation strongly depends on the conﬁguration of
the cache. For example, in a write-through cache, changing the
key is possible at any time without causing data inconsistency.
In such a scenario, a timer or performance-counter-based re-
keying scheme is easily implementable. Note, however, that
the interval between key changes should not be too small as
each key change corresponds to a full cache ﬂush.
On the other hand, in a cache with write-back policy, the
key has to be kept constant as long as dirty cache lines reside
in the cache. Therefore, before the key can be changed in this
scenario without data loss, all modiﬁed cache lines have to be
written back to memory ﬁrst. The x86 Instruction-Set Archi-
tecture (ISA), for example, features the WBINVD instruction
that can be used for that purpose.
If desired, also more complex rekeying schemes, like way-
wise or cache-wide dynamic remapping [55], can be im-
plemented. However, it is unclear if adding the additional
hardware complexity is worthwhile. Even without changing
the key, mounting cache attacks against SCATTERCACHE is
much harder than on traditional caches (see Section 4). Sub-
sequently, performing an occasional cache ﬂush to update the
key can be the better choice.
3.3.3 Integration into Existing Cache Architectures
SCATTERCACHE is a generic approach for building processor
caches that are hard to exploit in cache-based side channel
attacks. When hardening a system against cache attacks, inde-
pendent of SCATTERCACHE, we recommend to restrict ﬂush
instructions to privileged software. These instruction are only
rarely used in benign userspace code and restricting them
prevents the applicability of the whole class of ﬂush-based at-
tacks from userspace. Fortunately, recent ARM architectures
already support this restriction.
Next, SCATTERCACHES can be deployed into the system
to protect against eviction based attacks. While not inherently
limited to, SCATTERCACHES are most likely to be deployed
as LLCs in modern processor architectures. Due to their large
size and the fact that they are typically shared across multiple
processor cores, LLCs are simply the most prominent cache
attack target and require the most protection. Compared to
that, lower cache levels that typically are only accessible by a
single processor core, hold far less data and are much harder
to attack on current architectures. Still, usage of (unkeyed)
skewed [63] lower level caches is an interesting option that
has to be considered in this context.
Another promising aspect of employing a SCATTERCACHE
as LLC is that this permits to hide large parts of the IDF
latency. For example, using a fully unrolled and pipelined IDF
implementation, calculation of the required SCATTERCACHE
indices can already be started, or even performed entirely, in
parallel to the lower level cache lookups. While unneeded
results can easily be discarded, this ensures that the required
indices for the LLC lookup are available as soon as possible.
Low latency primitives like QARMA, which is also used
in recent ARM processors for pointer authentication, are
promising building blocks in this regard. The minimal la-
tency Avanzi [8] reported for one of the QARMA-64 variants
is only 2.2 ns. Considering that this number is even lower
than the time it takes to check the L1 and L2 caches on re-
cent processors (e.g., 3 ns on a 4 GHz Intel Kabylake [2], 9 ns
on an ARM Cortex-A57 in an AMD Opteron A1170 [1]),
implementing IDFs without notable latency seems feasible.
3.4 Processor Interaction and Software
Even without dedicated software support, SCATTERCACHE
increases the complexity of cache-based attacks. However, to
make full use of SCATTERCACHE, software assistance and
some processor extensions are required.
Security Domains. The SCATTERCACHE hardware per-
mits to isolate different security domains from each other
via the SDID input to the IDF. Unfortunately, depending
on the use case, the deﬁnition on what is a security domain
can largely differ. For example, a security domain can be a
chunk of the address space (e.g., SGX enclaves), a whole
process (e.g., TrustZone application), a group of processes
in a common container (e.g., Docker, LXC), or even a full
virtual machine (e.g., cloud scenario). Considering that it is
next to impossible to deﬁne a generic policy in hardware that
can capture all these possibilities, we delegate the distinction
to software that knows about the desired isolation properties,
e.g., the Operating System (OS).
SCATTERCACHE Interface. Depending on the targeted
processor architecture, different design spaces can be explored
before deciding how the current SDID gets deﬁned and what
channels are used to communicate the identiﬁer to the SCAT-
TERCACHE. However, at least for modern Intel and ARM
processors, binding the currently used SDID to the virtual
memory management via user deﬁned bits in each Page Table
Entry (PTE) is a promising approach. In more detail, one or
more bits can be embedded into each PTE that select from a
list, via one level of indirection, which SDID should be used
when accessing the respective page.
Both ARM and Intel processors already support a similar
mechanism to describe memory attributes of a memory map-
ping. The x86 architecture deﬁnes so-called Page Attribute Ta-
USENIX Association
28th USENIX Security Symposium    681
bles (PATs) to deﬁne how a memory mapping can be cached.
Similarly, the ARM architecture deﬁnes Memory Attribute
Indirection Registers (MAIRs) for the same purpose. Both
PAT and MAIR deﬁne a list of 8 memory attributes which
are applied by the Memory Management Unit (MMU). The
MMU interprets a combination of 3 bits deﬁned in the PTE as
index into the appropriate list, and applies the corresponding
memory attribute. Adding the SDID to these attribute lists
permits to use up to 8 different security domains within a sin-
gle process. The absolute number of security domains, on the
other hand, is only limited by the used IDF and them number
of bits that represent the SDID.
Such indirection has a huge advantage over encoding data
directly in a PTE. The OS can change a single entry within the
list to affect all memory mappings using the corresponding
entry. Thus, such a mechanism is beneﬁcial for SCATTER-
CACHE, where the OS wants to change the SDID for all
mappings of a speciﬁc process.
Backwards Compatibility. Ensuring backwards compat-
ibility is a key factor for gradual deployment of SCATTER-
CACHE. By encoding the SDID via a separate list indexed by
PTE bits, all processes, as well as the OS, use the same SDID,
i.e., the SDID stored as ﬁrst element of the list (assuming all
corresponding PTE bits are ‘0’ by default). Thus, if the OS is
not aware of the SCATTERCACHE, all processes—including
the OS—use the same SDID. From a software perspective,
functionally, SCATTERCACHE behaves the same as currently
deployed caches. Only if the OS speciﬁes SDIDs in the list,
and sets the corresponding PTE bits to use a certain index,
SCATTERCACHE provides its strong security properties.
Implementation Example. In terms of capabilities, hav-
ing a single bit in each PTE, for example, is already sufﬁcient
to implement security domains with process granularity and to
maintain a dedicated domain for the OS. In this case, SDID0
can always be used for the OS ID while SDID1 has to be