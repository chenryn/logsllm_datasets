International Journal of Web Services Research, 5(2), 49-76, April-June 2008 49
business Process control-Flow
complexity:
Metric, Evaluation, and Validation
Jorge Cardoso, University of Madeira, Portugal
AbstrAct
Organizations are increasingly faced with the challenge of managing business processes, workflows, and
recently, Web processes. One important aspect of business processes that has been overlooked is their
complexity. High complexity in processes may result in poor understandability, errors, defects, and excep-
tions, leading processes to need more time to develop, test, and maintain. Therefore, excessive complexity
should be avoided. Business process measurement is the task of empirically and objectively assigning
numbers to the properties of business processes in such a way so as to describe them. Desirable attributes
to study and measure include complexity, cost, maintainability, and reliability. In our work, we will focus on
investigating process complexity. We present and describe a metric to analyze the control-flow complexity
of business processes. The metric is evaluated in terms of Weyuker’s properties in order to guarantee that
it qualifies as good and comprehensive. To test the validity of the metric, we describe the experiment we
have carried out for empirically validating the metric.
Keywords: business processes, complexity metrics, Web processes, workflows, software engineering.
IntroductIon ease several current infrastructure challenges,
Business process management systems (BPMS) such as data, application, and process integra-
(Smith & Fingar, 2003) provide a fundamental tion. With the emergence of Web services, a
infrastructure to define and manage business workflow management system becomes es-
processes. BPMS, such as Workflow Manage- sential to support, manage, and enact processes,
ment Systems (WfMS) (Cardoso, Bostrom & both among enterprises and within the enterprise
Sheth, 2004), have become a serious competitive (Sheth, van der Aalst & Arpinar, 1999).
factor for many organizations that are increas- A vast amount of work done so far in
ingly faced with the challenge of managing e- the business process field has targeted the
business applications, workflows, Web services, development of WfMS, including models
and Web processes. Business processes, such as (e.g., Petri nets), modeling languages (BPML,
Web processes (WS-BEPL, 2005) promise to 2004; BPMN, 2005; Leymann, 2001; Menzel,
Copyright © 2008, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global
is prohibited.
50 International Journal of Web Services Research, 5(2), 49-76, April-June 2008
Mayer, & Edwards, 1994; Singh, 1995; van research that needs to be explored is the com-
der Aalst, 1998; van der Aalst & Hofstede, plexity analysis of processes.
2003), and execution environments (Alonso, A business process is composed of a set
Mohan, Guenthoer, Agrawal, El Abbadi, & of activities, tasks, or services put together to
Kamath, 1994; Canós, Penadés, & Carsí, 1999; achieve a final goal. As the complexity of a
Jablonski, 1994; Kochut, Sheth, & Miller, process increases, it can lead to poor quality and
1999; Miller, Palaniswami, Sheth, Kochut, & be difficult to reengineer. High complexity in a
Singh, 1998; Wodtke, Weissenfels, Weikum, process may result in limited understandability
& Dittrich, 1996). Work has also been carried and more errors, defects, and exceptions, leading
out to develop methods to analyze processes processes to need more time to develop, test, and
in order to verify their correctness, testing the maintain. For example, in software engineer-
existence of livelocks and deadlocks (van der ing, it has been found that program modules
Aalst, 1998). with high-complexity indices have a higher
Recently, a new field of research for pro- frequency of failures (Lanning & Khoshgoftaar,
cesses has emerged. This new field—termed 1994). Therefore, excessive complexity should
process measurement—presents a set of be avoided. For instance, critical processes in
approaches to the quantification of specific which failure can result in the loss of human
properties of processes. Important properties to life require a unique approach to development,
analyze include the estimation of complexity, implementation, and management. For these
defects, process size, effort of testing, effort of types of processes, typically found in healthcare
maintenance, understandability, time, resources, applications (Anyanwu, Sheth, Cardoso, Miller,
and quality of service. Process measurement is & Kochut, 2003), the consequences of failure
still in its infancy, and much work has yet to are severe. The ability to produce processes of
be undertaken. higher quality and less complexity is a matter
The effective management of any process of endurance.
requires modeling, measurement, and quan- Surprisingly, in spite of the fact that there
tification. Process measurement is concerned is a vast amount of literature on software
with deriving a numeric value for attributes of measurement of complexity (Zuse, 1997), no
processes. Measures, such as Quality of Service significant research on process measurement of
measures (Cardoso, Miller, Sheth, Arnold, & complexity has yet been carried out. Analyzing
Kochut, 2004), can be used to improve process the complexity at all stages of process design and
productivity and quality. development helps avoid the drawbacks associ-
Designing and improving processes is a ated with high-complexity processes. Currently,
key aspect in order for businesses to stay com- organizations have not adopted complexity
petitive in today’s marketplace. Organizations metrics as part of their process management
have been forced to improve their business projects. As a result, simple processes may be
processes because customers are demanding designed in a complex way.
better products and services. When an organiza- This article integrates and expands our
tion adopts a process management philosophy, previous work (Cardoso, 2005c; 2005d; 2005f)
process improvement can take place. Indepen- and discusses the complexity of processes. In the
dently of the approach taken, which can be a first main section, we present the Control-Flow
Continuous Process Improvement (Harrington, Complexity (CFC) metric (Cardoso, 2005d)
1993), a Business Process Redesign (Wastell, in order to measure the degree of complex-
White, & Kawalek, 1994), or a Business Process ity of business processes from a control-flow
Reengineering (Ould, 1995) approach, methods perspective. As Lord William Thomson Kelvin
need to be available to analyze the processes (1824–1907) said, “If you cannot measure it,
undergoing improvements. To achieve an ef- you cannot improve it.” The use of the CFC
fective management, one fundamental area of metric allows designers to improve processes,
Copyright © 2008, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global
is prohibited.
International Journal of Web Services Research, 5(2), 49-76, April-June 2008 51
thus reducing the time spent reading and under- is stored and executed under the supervision of
standing processes in order to remove faults or the workflow system. One of the services sup-
adapt them to changed requirements. The CFC plied by the bank is the loan process depicted
metric can be used to analyze the complexity of in Figure 1.
business processes, as well as workflows and This very simple process is composed of
Web processes. In the second main section, we only four activities. The Fill Loan Request ac-
evaluate the Control-Flow Complexity metric in tivity allows clients to request a loan from the
terms of Weyuker’s properties (Weyuker, 1988). bank. In this step, the client is asked to fill out
Weyuker’s properties give an important basis to an electronic form with personal information
classify a complexity measure in order to deter- and data describing the loan being requested.
mine if it can be categorized as good, structured, The second activity, Check Educational Loan,
and comprehensive (Cardoso, 2005c). Finally, determines if the loan request should be accepted
the last main section describes the experiment or rejected. When the result of a loan application
that we have carried out for empirically validat- is known, it is e-mailed to the client using the
ing the proposed metric (Cardoso, 2006). Such Notify Educational Loan Client activity. Finally,
an experiment plays a fundamental role in our the Archive Application activity creates a report
work, since the experimentation is a crucial and stores the loan application data in a database
part of the evaluation of new metrics and is record. A complete description of this process
critical for the success of any measurement is described in Cardoso (2005e).
activity (Zelkowitz & Wallace, 1998). Through This first workflow application gains ac-
empirical validation, we demonstrate with real ceptance within the bank since it improves
evidence that the measure we proposed serves service to customers at several levels, allows
the purpose for which it was defined. significant cost savings, and improves com-
munication among employees; the managers
MotIVAtIon of the bank decide to add more services to be
In this section, we describe a scenario in order supported by the loan process. It was decided
to explain and illustrate the need for Control- to support not only educational loans but also
Flow Complexity (CFC) analysis during the home and car loans.
design and aging of a process. A major bank Before making any changes to the process,
has realized that in order to be competitive a control-flow complexity analysis is carried out.
and efficient, it must adopt a new, modern The outcome of the analysis indicates that the
information system infrastructure. Therefore, process has a very low complexity. Processes
a first step was taken in that direction with the with a low complexity have the capability to
adoption of a workflow management system to quickly change to accommodate new products
support its business processes. Since the bank or services in order to meet the changing needs
supplies several services to its customers, the of customers and business partners. Based on
adoption of a WfMS has enabled the logic of the complexity analysis results, the process was
bank processes to be captured in schema. As a changed, having now the structure illustrated
result, part of the services available to customers in Figure 2.
The new process (version 2) is composed
of nine activities. Because complexity was a
concern during the development of the new
process, it still maintains a complexity that is
Figure 1. The loan process (version 1) within an acceptable range.
For the twelve months that followed the
design and implementation of the second ver-
Fill Check Notify Archive sion of the process, several small changes were
Loan Education Loan Education Loan Application
Request Client introduced to the process. Unfortunately, since
Copyright © 2008, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global
is prohibited.
52 International Journal of Web Services Research, 5(2), 49-76, April-June 2008
Figure 2. The loan process (version 2)
the changes were done incrementally and each entails a lower complexity for the process can
one had a small impact on the structure of the be selected and implemented.
process, complexity analysis was not carried Analyzing the complexity at all stages of
out during the process redesign. As a result, the process design and development helps avoid
process structure is the following (Figure 3). the drawbacks associated with high-complexity
The process has evolved over time by modi- processes. Currently, organizations have not
fication and may have become fragile with age. implemented complexity limits as part of their
Therefore, it is necessary to use techniques such business process management projects. The use
as complexity analysis to assess the system’s of complexity analysis will aid in constructing
condition. A high complexity may be the sign and deploying processes and workflows that are
of a brittle, nonflexible, or high-risk process. If more simple, reliable, and robust.
high complexity is identified, the process may Processes are not static applications. They
need to be redesigned to reduce its complexity. are constantly undergoing revision, adaptation,
Redesign may involve breaking the process change, and modification to meet end users’
into subprocesses or simplifying the way the needs. The complexity of these processes and
business process is carried out. their continuous evolution make it very difficult
Let us consider again the process from to assure their stability and reliability. In-depth
Figure 3. Imagine that the designers are study- analysis is required for fixing defects in portions
ing alternatives to extend the process to handle of processes of high complexity (Figure 4.).
exceptions. The designers have identified three
ways to implement an exception-handling ProcEss coMPlExIty
mechanism, and they are undecided about Several definitions have been given to describe
which one to select. In such a scenario, the the meaning of software complexity. For ex-
CFC measure can be effectively used to help the ample, Curtis (1980) states that complexity is
designers in their decision. A “what-if analysis” a characteristic of the software interface that
can be carried out. For each alternative, the influences the resources another system will
CFC can be analyzed, and the alternative that expend or commit while interacting with the
software. Card and Agresti (1988) define rela-
Copyright © 2008, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global
is prohibited.
International Journal of Web Services Research, 5(2), 49-76, April-June 2008 53
Figure 3. The loan process (version 3)
Figure 4. Process complexity analysis and process reengineering
Process complexity Analysis and Process
reengineering
60
50
40 ytixelpmoc
30
20
Process Adaptation and Modification
10
Complexity Analysis and Process Reengineering
0
1 3 5 7 9 11 13 15 17 19 21 23 25 27 29
time
tive system complexity as the sum of structural stand, or explain. It may be characterized by
complexity and data complexity divided by the the number and intricacy of activity interfaces,
number of modules changed. Fenton (1991) transitions, conditional and parallel branches,
defines complexity as the amount of resources the existence of loops, roles, activity categories,
required for a problem’s solution. the types of data structures, and other process
After analyzing the characteristics and characteristics.
specific aspects of business processes and
workflows, we believe that the definition that is Process complexity Measurement
better suited to describe processes complexity requirements
can be derived from IEEE (1992). Therefore, The development of a model and theory to cal-
we define process complexity as the degree to culate the complexity associated with a process
which a process is difficult to analyze, under- or workflow needs to conform to a set of basic
Copyright © 2008, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global
is prohibited.
54 International Journal of Web Services Research, 5(2), 49-76, April-June 2008
but important properties. The metric should Activity complexity. This view on
be easy to learn, computable, consistent, and complexity simply calculates the number of
objective. Additionally, the following properties activities a process has. While this complexity
are highly desirable (Tsai, Lopex, Rodriguez, metric is very simple, it is very important to
& Volovik, 1986; Zuse, 1990): complement other forms of complexity. The
control-flow complexity of a process can be
• Simplicity. The metric should be easily very low, while its activity complexity can be
understood by its end users (i.e., process very high. For example, a sequential process
analysts and designers). that has a thousand activities has a control-flow
• Consistency. The metric should always complexity of 0, whereas its activity complexity
yield the same value when two independent is 100. This metric was inspired by lines-of-code
users apply the measurement to the same (LOC) metric used with a significant success
process (i.e., they should arrive at the same rate in software engineering (Jones, 1986).
result). Control-flow complexity. The control-
• Automation. It must be possible to auto- flow behavior of a process is affected by con-
mate the measurement of processes. structs such as splits, joins, loops, and ending and
• Measures must be additive. If two inde- starting points (Cardoso, 2005d). Splits allow
pendent structures are put into sequence, defining the possible control paths that exist in a
then the total complexity of the combined process. Joins have a different role; they express
structures is at least the sum of the com- the type of synchronization that should be made
plexities of the independent structures. at a specific point in the process. A control-flow
• Measures must be interoperable. Due to complexity model needs to take into account
the large number of existing specification the existence of XOR-split/join, OR-split/join,
languages both in academia and industry, AND-split/join, loops, and so forth.
the measurements should be independent of Data-flow complexity. The data-flow
the process specification language. A par- complexity of a process increases with the
ticular complexity value should mean the complexity of its data structures, the number
same thing whether it was calculated from of formal parameters of activities, and the
a process written in BPEL (BPEL4WS, mappings between activities’ data (Reijers &
2002), WSFL (Leymann, 2001), BPML Vanderfeesten, 2004). A data-flow complexity
(BPML, 2004), YAWL (van der Aalst & metric can be composed of several submetrics,