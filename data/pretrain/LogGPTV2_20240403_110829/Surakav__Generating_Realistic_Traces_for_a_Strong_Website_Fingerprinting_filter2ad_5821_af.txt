performed model quantization [45], which converts model
weights from ﬂoating-point values to integers. This reduced
the generator’s size from 23 MB to 3.4 MB. We compared sev-
eral generated traces from the quantized model and the original
model by ﬁxing the random seeds and found no difference in
them. According to the statistics from October 2020 to October
2021 [46], the directory servers spent 245 MB/s bandwidth on
average answering queries. We deﬁne the distribution cost as
the bandwidth for transferring the generator to clients, divided
by the average bandwidth consumed by the directory servers.
As shown in Figure 8, the distribution cost grows with
more clients downloading the generator. It decreases if the
generator gets updated less frequently. For example, Surakav
incurs only 4% distribution cost when there are 2.56 million
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:35:20 UTC from IEEE Xplore.  Restrictions apply. 
1567
TABLE V: Surakav performance with different ρ. We choose
ρ = 100 ms for our defense by default (marked in bold font).
TABLE VI: Surakav performance with different q. Our default
setting (Random) is close to the result of setting q at 0.5.
ρ (ms) Overhead (%)
Time
30
120
27
100
23
80
60
23
Data
65
67
79
92
Attack Accuracy (%)
DF
28.74
28.82
28.14
26.80
Tik-Tok
31.05
31.15
29.5
28.45
q
0.1
0.3
0.5
0.7
0.9
Random
Overhead (%)
Time
Data
28
98
28
84
30
73
55
29
30
42
67
27
Attack Accuracy (%)
DF
21.20
29.14
28.80
34.45
52.63
28.82
Tik-Tok
22.66
28.24
30.02
36.79
53.26
31.15
)
%
(
y
c
a
r
u
c
c
A
)
%
(
d
a
e
h
r
e
v
O
100
75
50
25
0
120
90
60
30
0
DF
Tik-Tok
0
0.2
0.4
0.6
0.8
1
δ
Data
Time
0
0.2
0.4
0.6
0.8
1
δ
Fig. 9: Surakav performance with different δ. With a larger δ,
both the time overhead and data overhead are reduced while
attack accuracy is increased.
users who update G every ten days. This cost is hyperbolically
reduced to 1.3% if they choose to update G every 30 days.
Note that Surakav scales better than Tor itself, as the directory
consensus ﬁle will increase in size with a larger network while
the generator will not.
D. Parameter Tuning
We discuss the effect of each parameter in this section. To
reduce data collection time, we use closed-world datasets for
the experiments. We present the attack accuracy of the two
strongest attacks, DF [5] and Tik-Tok [7].
1) Choosing a Suitable ρ: ρ deﬁnes the maximum possible
time gap in our defense to avoid sampling an unreasonably
large time gap. We increase ρ from 60 ms to 120 ms. δ is
ﬁxed at 0.4 and q is randomly sampled from (0,1) for each
load. As shown in Table V, the time overhead is reduced by
only 7% when we decrease ρ from 120 ms to 60 ms. However,
the data overhead increases by 27%. There is a sharp increase
in data overhead (+25%) when we adjust ρ from 100 ms to
60 ms. The increase in overhead does not bring much beneﬁt,
though; the accuracy of Tik-Tok only drops by 3% (31% →
28%), and the time overhead is only reduced by 4%. Therefore,
we set ρ = 100 ms by default since it achieves the best balance
between overhead and attack accuracy.
2) Varying δ: δ limits the maximum change the regulator
can make on the required burst size based on the real burst size.
The heavy and light settings for Surakav differ only by their
choice of δ (0.4 and 0.6 respectively). We further investigate
how other δ values would affect the performance by varying δ
from 0 to 1. Figure 9 shows the results. As before, ρ is ﬁxed
at 100 ms and q is random. When δ is reduced from 1 to 0, the
time overhead gradually increases from 20% to 36%. The data
overhead is more sensitive to the change of δ, increasing from
8% to 120%. On the other hand, lowering δ means stricter
control on burst size modiﬁcation, which increases the ﬁdelity
of the regulator to the generated trace; we see that Surakav
shows a high protection rate when δ  0.8
since it almost allows no modiﬁcation on burst sizes. As a
result, the attack accuracy for DF and Tik-Tok only drops by
2% when δ = 1.
3) Impact of q: q is the probability of skipping a fake
burst on the proxy side. To ﬁgure out how different values for
q could affect the defense, we ﬁx q at different values and
analyze the overhead and attack accuracy. Table VI shows the
results. ρ is ﬁxed at 100 ms and δ is ﬁxed at 0.4 for this
experiment. “Random” represents the default setting where
we sample a new q from (0,1) each time we load a new
webpage. The time overhead remains around 28%, while the
data overhead decreases when we increase q from 0.1 to 0.9.
This is because the probability of skipping a fake burst is
increased with a larger q. Accordingly, the accuracy values
of both attacks also increase. We ﬁnd there is a big jump in
attack accuracy when q > 0.7, so it is not recommended.
The expected value of q is 0.5 when we randomly sample
it from a uniform distribution between 0 and 1. Therefore, the
performance of Surakav when q is random should be close to
that when q is 0.5. This is validated by our results; both cases
yield similar data overhead and attack accuracy. To simplify
the conﬁguration, we choose to set q at random and let only
δ decide how much overhead budget we want to use.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:35:20 UTC from IEEE Xplore.  Restrictions apply. 
1568
VI. FORTIFYING OTHER DEFENSES
Using a generator, we can obtain realistic traces without
performing large-scale trafﬁc crawling. In this section, we
show that the trace generator not only brings about a new
strong defense in Surakav, but also strengthens the existing
ones. We study two defenses, Walkie-Talkie [10] and Trafﬁc-
Sliver [14], their limitations, and how we improve them with
a trace generator.
A. Walkie-Talkie
Walkie-Talkie [10] proposes to mold two traces into a
super-trace so that it yields the same trafﬁc pattern whichever
webpage is visited. Walkie-Talkie requires two parties to talk
in half-duplex mode. Therefore, a defended trace will be a
sequence of large bursts. Walkie-Talkie is able to guarantee a
maximum attack accuracy of 50% for any attack with moderate
overhead (31% data overhead and 34% time overhead on their
dataset). However, this result is built upon two prerequisites
that are hard to meet. Firstly, communicating in half-duplex
mode requires modiﬁcations on both the application layer
(to change browser behavior) and the network layer (to add
dummy packets). Cross-layer communication is necessary for
the modiﬁed browser to tell Tor when a burst ends. Such a
design increases the deployment complexity. Secondly, it as-
sumes the burst sequences of webpages are known in advance.
However, webpages change quickly, and it is very hard to
maintain and update such a database of burst sequences.
We can ﬁx the ﬁrst problem by enforcing a half-duplex
mode on the network layer: we buffer data from the application
layer for at most ttalkie time before releasing the burst onto
the wire and force both parties to take turns to send bursts so
that the defense is fully deployed on the network layer. We set
ttalkie = 500 ms in our experiments. For the second problem,
we train a new generator Gwt that can generate burst sequences
that look like real ones collected in half-duplex mode. When
we load a page, we randomly sample a burst sequence from
Gwt and mold the sequence with the real one. This creates a
new version of Walkie-Talkie that is more realistic to deploy,
which we call GAN-WT.
1) Training Gwt: To train a Gwt, we collect a new closed-
world dataset in half-duplex mode that contains 100 monitored
pages (each 500 instances). Since traces collected in half-
duplex mode are shorter than those collected in full-duplex
mode, we reduce trace length from 1400 to 1000 (95%
percentile for our training set). In addition, we adjust the
learning rate to 0.0003, α to 0.1, and the dimension of the
noise z to 100 since they yield the best generator. The other
hyperparameters remain unchanged as presented in Table II.
2) Evaluation: To evaluate GAN-WT, we collect another
undefended dataset
in half-duplex mode and simulate the
defense on it. The dataset is of the same size (70,000 instances)
as those in Section V. The results are shown in Table VII. With
86% data overhead and 22% time overhead, GAN-WT reduces
the TPR of both DF and Tik-Tok from 97% to 38%. The FPR
of Tik-Tok is increased from 0.7% to 2.7%.
TABLE VII: Evaluation of GAN-WT in the open-world sce-
nario. It greatly outperforms Random-WT, a variant of Walkie-
Talkie. All values are in percentages.
DF
Overhead
Data
Time
Defense
FPR
None
0.54
GAN-WT
4.12
Random-WT∗
2.81
∗The results for Random-WT are taken from [41].