title:Covert and Side Channels Due to Processor Architecture
author:Zhenghong Wang and
Ruby B. Lee
Covert and Side Channels due to Processor Architecture* 
Zhenghong Wang and Ruby B. Lee 
Department of Electrical Engineering, Princeton University 
{zhenghon,rblee}@princeton.edu 
Abstract 
Information  leakage  through  covert  channels  and 
is  becoming  a  serious  problem, 
side  channels 
these  are  enhanced  by  modern 
especially  when 
processor  architecture 
features.  We  show  how 
processor  architecture  features  such  as  simultaneous 
multithreading, control speculation and shared caches 
can  inadvertently  accelerate  such  covert  channels  or 
enable new covert channels and side channels. We first 
illustrate  the  reality  and  severity  of  this  problem  by 
describing  concrete  attacks.  We  identify  two  new 
covert  channels.  We  show  orders  of  magnitude 
increases  in  covert  channel  capacities.  We  then 
present  two  solutions,  Selective  Partitioning  and  the 
novel  Random  Permutation  Cache  (RPCache).  The 
RPCache  can  thwart  most  cache-based  software  side 
channel  attacks,  with  minimal  hardware  costs  and 
negligible performance impact. 
1. Introduction 
Covert channels and side channels are two types of 
information  leakage  channels.  A  covert  channel  uses 
mechanisms that are not intended for communications, 
e.g., writing and checking if a file is locked to convey 
a (cid:147)1(cid:148) or (cid:147)0(cid:148). In a covert channel [1], an insider process 
leaks information to an outsider process not normally 
allowed  to  access  that  information.    The  insider 
(sending)  process  could  be  a  Trojan  horse  program 
previously  inserted  stealthily  into  the  computer.  An 
outsider 
(receiving)  process  need  only  be  an 
unprivileged process. 
In  a  physical  side  channel  attack,  unconventional 
techniques  are  used  to  deduce  secret  information.  
Typically,  the  device  has  been  stolen  or  captured  by 
the  adversary  who  then  has  physical  access  to  it  for 
launching  a  physical  side-channel  attack.  Traditional 
side  channel  attacks 
involved  differential  power 
* This work was supported in part by DARPA and NSF Cybertrust 
0430487, and NSF ITR 0326372. 
analysis  [2-5]  and  timing  analysis  [6-10].  Different 
amounts  of  power  (or  time)  used  by  the  device  in 
performing  an  encryption  can  be  measured  and 
analyzed  to  deduce  some  or  all  of  the  key  bits.    The 
number  of  trials  needed  in  a  power  or  timing  side 
channel attack could be much less than that needed in 
mathematical cryptanalysis. 
In  this  paper,  we  consider  software  side  channel 
attacks. In these attacks, a victim process inadvertently 
assumes the role of the sending process, and a listening 
(attacker)  process  assumes  the  role  of  the  receiving 
process.  If  the  victim  process  is  performing  an 
encryption using a secret key, a software side channel 
attack  allows  the  listening  process  to  get  information 
that  leads  to  partial  or  full  recovery  of  the  key.  The 
main contributions of this paper are: 
• 
Identification  of  two  new  covert  channels  due  to 
processor  architecture  features,  like  simultaneous 
multi-threading (SMT) and speculation. 
•  Showing  that  covert  channel  capacities  have 
increased by orders of magnitude. 
•  Analysis of cache-based side channel attacks. 
• 
Insufficiency of software isolation approaches for 
mitigating information leakage through processor-
based covert and side channels. 
•  Selective  partitioning  solution  for  SMT-based 
covert channels.  
•  Novel  Random  Permutation  Cache  (RPCache) 
solution that can thwart cache-based software side 
channel attacks. 
Section  2  describes  the  threat  model.  Section  3 
illustrates the problem with real attacks and analysis of 
newly identified cache side channels. Section 4 shows 
the insufficiency of software solutions, motivating the 
need  for  hardware  solutions  to  a  hardware-induced 
problem. Section 5 provides our Selective Partitioning 
solution.  Section  6  presents  our  novel  Random 
Permutation  Cache  solution,  and  experimental  results 
on  its  performance  and  security.  Section  7  reviews 
related work and section 8 presents our conclusions. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:29:18 UTC from IEEE Xplore.  Restrictions apply. 
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 20062. Threat model 
The threat model is that of an adversary whose goal 
is to learn information that he has no legitimate access 
to.  Within the computer system, an adversary is one or 
more unprivileged user processes. 
Since  our  focus  in  this  paper  is  on  the  impact  of 
processor  architecture  features  on  the  problem,  we 
assume that the critical modules of the software system 
(like the OS kernel and the modules enforcing security 
policies)  are  free  of  software  vulnerabilities.  Other 
software  modules,  such  as  the  guest  OS  in  a  Virtual 
Machine  or 
the  application  software,  may  have 
security flaws that allow a cooperating process of the 
adversary,  e.g.  an  insider,  to  gain  access  to  the 
information.  In  this  case,  we  assume  that  appropriate 
security  policies  are  enforced  so  that  the  cooperating 
process is isolated from the adversary. In this paper we 
consider software attacks and do not consider physical 
attacks like bus probing and power analysis. 
3. Processor covert and side channels 
3.1. New SMT/FU covert channel 
Simultaneous  Multi-Threaded  (SMT)  processors 
[15] run many processes concurrently, sharing almost 
all processor resources in a very tightly coupled way.  
In  particular,  the  concurrent  threads  share  a  pool  of 
functional units (FUs) that are allocated dynamically to 
each process every cycle. By contending for the shared 
FUs, one process can interfere with another, leading to 
covert  channels.  Though  in  principle  this  is  a  typical 
covert  timing  channel  [13],  it  is  orders  of  magnitude 
faster than traditional covert channels.   
insider 
observer
int time, dt; 
int bit; 
(cid:133) 
(cid:133) 
time = 0; 
do { 
do { 
    bit = get_bit(); 
    dt = time; 
    if ( bit == 1 )  
    RUN(); 
         MULTIPLY();  
    time = get_time();
    else 
    STORE(time-dt); } 
         NULL(); } 
while ( !RX_end() ); 
while ( !TX_end() ); 
Figure 1. Pseudocode for SMT/FU channel  
Consider  a  system  which  contains  two  processes 
that  are  not  allowed  to  communicate  at  all  with  each 
other.  The  insider  (sender)  process  can  modulate  the 
use  of  functional  units,  e.g.  the  multipliers,  to  send 
information to the receiver process. Figure 1 shows the 
pseudocode for both processes. To send a (cid:145)1(cid:146) bit, the 
insider calls MULTIPLY() to execute a fixed number 
of  instructions  which  try  to  use  up  all  the  integer 
multipliers.  It  calls  NULL(),  which  executes  several 
hundred  NOP  instructions,  to  send  a  (cid:145)0(cid:146)  bit.  The 
observer senses the modulated signal by comparing its 
progression  with  a  timer  T.  By  calling  RUN(),  he 
executes  integer  multiply  instructions  at  a  constant 
rate. When a (cid:145)1(cid:146) is sent, most multipliers are used by 
the insider and the observer can detect this because his 
execution will be slowed down.  
We  implemented  this  channel  on  a  Pentium-4 
processor  with  hyper-threading  (Intel(cid:146)s  SMT),  which 
supports only two simultaneous threads [16]. Figure 2 
shows an example of the received waveform. The bit 
string shown is transmitting (cid:147)10101010(cid:133)(cid:148) 
l
)
e
c
y
c
(
e
d
u
l
a
n
g
S
i
t
i
l
p
m
A
1150
1100
1050
10
20
30
50
40
60
Receiver Time
70
80
90
100
Figure 2. Observed signal waveform 
3.2. SMT/cache side channel 
In  an  SMT  processor,  caches  are  also  shared.    An 
attacker  can  run  a  receiver  (or  observer)  process 
simultaneously  with  the  victim  process  on  an  SMT 
processor.  This  enables  observation  of  the  victim 
process(cid:146)s  cache  usage  at  run  time.  In  [12],  Percival 
demonstrated  an  attack  on  RSA  using  this  approach. 
The attack is simple: the attacker accesses an array of 
his own data repeatedly so that he occupies all cache 
lines.  During  the execution of the victim process, i.e. 
the  RSA  encryption  process  in  this  case,  if  the 
encrypting process accesses a cache line, the attacker(cid:146)s 
data  will  be  evicted.  The  next  time  the  attacker 
accesses  his  data  corresponding  to  this  cache line, he 
will  experience  a  cache  miss.  By  measuring  his 
memory access time, the attacker can detect such cache 
misses.  The  attacker  therefore  can  learn  the  victim 
process(cid:146)s cache access pattern, based on which he can 
determine when multiplication and squaring operations 
used  in  RSA  encryption  occur  in  the  victim  process. 
He can also learn which table entry is accessed during 
a  key-dependent  table  lookup  in  RSA.  The  attacker 
then  can  recover  the  RSA  key  of  the  victim  process, 
based on the observed cache usage information. 
In  [22]  Osvik  et  al.  applied  this  approach  to  AES 
and  demonstrated  how  easy  it  is  to  recover  the  key. 
They showed that after just 800 writes to a Linux dm-
crypt  encrypted  partition,  the  full  AES  key  can  be 
recovered. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:29:18 UTC from IEEE Xplore.  Restrictions apply. 
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 20063.3. Statistical cache side-channel 
In non-SMT processors, cache-based software side 
channel attacks are also possible. Bernstein(cid:146)s attack on 
AES  [11]  illustrates  such  an  attack.  The  victim  is  a 
software module that can perform AES encryption for 
a  user.  The  module  is  a  (cid:147)black  box(cid:148)  and  the  user  is 
only  able  to  choose  the  input  to  the  AES  software 
module and measure how long it takes to complete the 
encryption.  He  found  that  for  most  software  AES 
implementations  running  on  modern  processors,  the 
execution time of an encryption is input-dependent and 
can be exploited to recover the secret encryption key. 
Attack Description: The attack consists of three steps. 
1.  Learning phase: Let the victim use a known key K; 
the attacker generates a large number, N, of random 
plaintexts  P.  He  then  sends  the  plaintexts  to  the 
cipher  program  (a  remote  server  in  [11])  and 
records  the  encryption  time  for  each  plaintext.  He 
uses the algorithm shown in Figure 3 to obtain the 
timing characteristics for K. 
2.  Attacking phase: Repeat the same operation in the 
learning  phase  except  that  an  unknown  key  K(cid:146)  is 
used. Note that the input set is randomly generated 
and not necessarily the same as used in step 1. 
3.  Key  recovery:  Given  the  two  sets  of  timing 
characteristics, use the correlation algorithm shown 
in  Figure  4  to  recover  the  unknown  key  K(cid:146). 
Function  findMax()  searches  for  the  maximum 
value in the input array and returns its index. 
In Figure 3, P denotes a plaintext block that will be 
encrypted with the secret key K.  pi and ki denote the i-
th byte of P and K, i∈[0,15] (We assume 128-bit AES 
in this example; hence both the block to be encrypted, 
P, and the key, K, are 16 bytes long). A large number 
of  random  plaintext  blocks  P  are  encrypted  with  the 
same  key  K.  For  each  byte pi in the plaintext blocks, 
find  the  encryptions  where  pi  =  0,  and  calculate 
i(0,K) which is the average of the execution times of 
tavg
the AES encryptions where the ith plaintext byte is 0, 
using key K. Repeat for pi = 1, 2, (cid:133), 255. This can be 
plotted as a timing characteristic chart for byte i using 
key  K  as  shown  in  Figure  5(a),  where  i=0.  (This  is 
obtained  in  our  experiments  over  a  Pentium  M 
processor  with  Cygwin/OpenSSL0.9.7a).  The  x-axis 
represents the value of the plaintext byte pi, from 0 to 
255, and the y-axis the average encryption time (minus 
a fixed offset). Sixteen such charts are plotted, one for 
each  byte  position  of  the  plaintext  blocks.  These  16 
charts  together  represent  the  timing  characteristic, 
i(j,K),  for  0  ≤  i  ≤  15  and  0  ≤  j  ≤  255,  of 
denoted  tavg
AES encryption on a given platform for a given K. 
For key K: 
For s = 1 to N do begin 
Generate a random 128-bit Plaintext block, Ps; 
Ts = time taken for AES encryption of Ps using K;
end; 
For i = 0 to 15 do begin 
For j = 0 to 255 do begin 
count = 0;             
For s = 1 to N do begin 
If  pi = j then  
TSUMi(j) = TSUMi(j) + Ts; 
count = count+1; 
end; 
tavg
i(j,K) = TSUMi(j)/count;  
      end; 
end; 
Figure 3. Timing characteristic generation 
For i = 0 to 15 do begin 
   For j = 0 to 255 do begin 
Corr
j
][
=
[
t
i
avg
(
tKm
•
)
,
i
avg
(
Kjm
⊕
,
]
)’
255
∑
m
=
0
   end; 
   ki(cid:146)= findMax(Corr); 
end; 
Figure 4. Key-byte searching algorithm 