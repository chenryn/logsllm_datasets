An important question in machine learning model is to iden-
tify how much training data is sufﬁcient to achieve the desired
performance. Figure 15 shows the accuracy of our private
apex domain classiﬁer for different dataset sizes. Recall that
the size of our original balanced dataset for the two windows
is approximately 700 apexes from each class. As shown in
this ﬁgure, our classiﬁers yield an accuracy similar to the full
labeled set with approximately 70% of the labeled data.
6.5 Feature Stability over Time
Identifying how often one needs to re-train a classiﬁer to cope
with concept drift is quite important in practice. To measure
the impact of concept drifting on our classiﬁer, we create two
datasets which are one and two weeks apart from the AC-GT2
dataset. We evaluate the performance of our classiﬁer trained
on AC-GT2 with these two datasets of 100 labels that are one
and two weeks away from the training set. As shown in Ta-
ble 10, our classiﬁer maintains a good performance after two
weeks, though it is also clear its performance drops gradually
as the temporal gap between the training and testing data in-
creases. In order to maintain a high precision, we recommend
to retrain the classiﬁers weekly.
We further use the model trained with the labeled data in
AC-GT1 to classify data in AC-GT2. As expected, since the
two datasets are two months apart temporally, the classiﬁca-
tion accuracy drops dramatically, by 14%.
Table 10: Concept Drift Analysis of Private AC/C Classiﬁer
Validation Set
Same Week
After 1 Week
After 2 Weeks
Rec.
Prec.
Acc.
97.1% 99.1% 94.2%
95.0% 90.9% 100.0%
93.0% 87.7% 100.0%
Figure 13: ROC Curve for RF Private Compromised/Attacker-
Owned Classiﬁer for Phishtank URLs
6.2 Robustness
As VT provides services to the public, it could be a concern
that attackers may submit URL queries and indirectly inﬂu-
ence the VT features, e.g., #Total_Scans and #VT_Duration,
and consequently the classiﬁcation results in their favor. To
show the classiﬁer’s robustness against such manipulations,
we measure the performance of the classiﬁer when different
types of VT features are excluded. As shown in Table 9, the
inﬂuence of these features on the classiﬁcation performance
is not signiﬁcant. Even when we aggressively omit all VT
features, the classiﬁcation accuracy drops by only 6%. A
possible way to further improve robustness is to enrich the
classiﬁer with additional features from disparate sources such
as domain certiﬁcates.
Table 9: Robustness of Private AC/C Classiﬁer
Features
All
All - {VT Proﬁle}
All - {VT Proﬁle,VT Du-
ration, Positive Count}
All - {VT Proﬁle, VT Re-
port}
Rec.
Prec.
Acc.
96.4% 99.1% 92.6%
94.01% 94.1% 91.8%
92.9% 93.9% 90.9%
90.1% 92.0% 84.4%
Impact of Training Data Quality
6.3
The effectiveness of machine learning depends greatly on
the quality of the training data. In our study, we collect la-
beled training and testing data through manual inspection by
multiple domain experts and adopt mechanisms to handle
disagreements. Here we would like to see how our classiﬁer
would be affected if the training dataset is noisy, i.e., with
some data mislabeled. For this purpose, we deliberately inject
mislabeled training data, and re-train our classiﬁer for both
DS1 and DS2, while controlling the noise level, i.e., the per-
centage of mislabeled training data. As shown in Figure 14, in
general our classiﬁer can tolerate small amount of mislabeled
data. At 1% and 5% noise levels, the accuracy of our classiﬁer
USENIX Association
30th USENIX Security Symposium    3733
Figure 15: Accuracy of the Model with respect to the size of
the dataset
6.6 Misclassiﬁed Apex Domains
We utilize LIME [56], a well-known tool that provides expla-
nations for individual predicted data points, in order to study
the misclassiﬁed data points in AC-GT2. This classiﬁcation
results in 1 False Positive (FP) and 8 False Negatives (FNs).
We make two observations from this analysis. First, most of
the misclassiﬁed data points do not have PDNS features (
we use default values for missing PDNS features). Second,
the probability of prediction for the rest of the misclassiﬁed
ones is close to 0.5 making the prediction weak. Possible ap-
proaches to further reduce FPs/FNs are to either ﬁll missing
values using another similar data source such as active DNS
and/or incorporate additional features from desperate sources
such as WHOIS registration records in order to differentiate
the two classes further.
6.7 Comparison with Industry Practices
GSB [16] has been instrumental in protecting users across the
web from phishing and malware attacks. GSB is integrated
with several browsers including Chrome and also provides
API based access. GSB categorizes malicious websites as ei-
ther malware sites or phishing sites. Malware sites are further
classiﬁed as compromised or attacker-owned sites. However,
GSB does not provide public APIs or services that directly
classify individual URLs as compromised or attacker-owned.
Instead, it only reports aggregated statistics of these two types
of URLs that GSB has discovered. There is also no document
or paper detailing exactly how GSB classiﬁes compromised
and attacker-owned domains. Therefore, we could not directly
compare our classiﬁer with that used by GSB. Here we com-
pare the published statistics of these two types of URLs in the
Google Transparency Report [17] in August 2019. Figure 16
compares the statistics on the number of unique malicious
websites detected by GSB and VT.
While GSB detects around 30K new malicious websites
per week, VT detects 3 times more than that amount, which
shows that there is room to improve the coverage of malicious
domains of GSB. Our manual inspection of selected malicious
Figure 16: Comparison of GSB and Our Approach
websites from VT conﬁrmed this observation, i.e., there exists
many malicious domains marked by VT but not by GSB.
Further, from the Google Transparency Report, we see that
GSB only studies whether malware websites are compromised
or attacker-owned, yet, malware websites (2K websites on
average per week during the comparison time period) only
account for less than 7% of all the malicious websites detected
by GSB. In comparison, we categorize both phishing and
malware websites as attacker-owned or compromised. We
believe our approach can complement GSB to automatically
detect more attacker-owned/compromised domains.
In the APWG 2016 phishing trends report, Aaron et al. [21]
proposes to utilize three heuristics to distinguish compro-
mised domains from attacker-owned ones. They ﬂag a do-
main as malicious if it is reported for phishing within a very
short time of being registered, and/or contains a brand name
or misleading strings, and/or is registered in a batch or in a
pattern that indicates common ownership or intent. While
such a heuristic based approach may accurately identify some
attacker-owned/compromised domains, our analysis shows
that it misclassiﬁes many malicious domains. During our
study period we observe that 13% of attacker-owned domains
are detected after 3 months and they do not have any brand
names. In their approach, these domains are likely to be mis-
classiﬁed as compromised.
7 Limitations and Future Work
Features speciﬁc to URL intelligence sources. Our work
primarily utilizes the malicious URL intelligence from VT.
Indeed some of the features are speciﬁc to VT reports. We
have shown that even when such features are removed, our
classiﬁers could still perform well. Further, through experi-
ments over the Phishtank dataset, we also show that our clas-
siﬁers could be adapted to work with other URL intelligence
sources. However, admittedly, the accuracy on the Phishtank
dataset is not as high as that on the VT dataset with VT spe-
ciﬁc features. The observation is that, though our approach
is general enough, data source speciﬁc features would bring
additional improvement to our classiﬁer. Thus, in practice,
when applying our classiﬁer with other URL data sources, it
pays to derive further URL data source dependent features to
enhance our model. Similarly, we derived features utilizing
other data sources such as PDNS and Alexa domain ranking.
3734    30th USENIX Security Symposium
USENIX Association
We did not explore other publicly available data sources, e.g.,
WHOIS registration records, active DNS records, and cer-
tiﬁcate transparency logs. It is possible to design additional
features from such data sources to further improve our model.
Another promising direction is to utilize content based clas-
siﬁcation as the second layer of categorization of websites
whose predicted label is close to the decision boundary, i.e.
the probability of prediction is close to 50%. Such an ap-
proach scales to millions of URLs as content analysis, which
is resource-intensive, is performed only on a fraction of them.
Ground Truth. It is always a challenge to collect high-
quality ground truth training data for machine learning tasks.
It is particularly so for malicious domain research. In this
paper, we obtain through manual inspection labeled datasets
for training and testing, which is inevitably a tedious and time-
consuming process. As a result, our labeled data set is only
of a moderate scale (ranging from a few hundreds to over a
thousand). It is certainly desirable to evaluate our models on
a much larger data set, which could shed new insights of our
approach. In this work, we did not explore ways to obtain
labeled datasets through automated or semi-automated pro-
cesses. However, as shown in Section 6.3, noisy labeled data
tend to impact the accuracy of the trained model, especially
when mislabeled data account for a non-negligible portion
of the training data. How to balance the scale and quality of
training data, through advanced machine learning techniques
(e.g., weakly supervised technique such as Snorkle [55]) is
an interesting and important problem for malicious domain
research.
Re-Compromised Websites. We inspect random samples
of compromised domains predicted by our classiﬁer and ret-
rospectively analyze them utilizing historical VT reports. We
ﬁnd a concerning trend that some compromised websites after
being cleaned, which is indicated by subsequent VT clean re-
ports, gets compromised again. One possible reason for such
behavior is that an underlying vulnerability still remains. A
useful future direction is to come up with a reputation based
score for benign websites based on how often they get com-
promised and how quickly identiﬁed infections are cleaned.
8 Related Work
Malicious vs. compromised domains. Moore et al. [48]
show how Internet miscreants utilize Google search to iden-
tify vulnerable web servers that use unpatched software and
host phishing web pages. They also show how such servers get
repeatedly compromised when the root cause of vulnerability
is not addressed. They assess that 75.8% of the phishing web
sites they analyzed are hosted on compromised web servers.
Corona et al. [30] proposes an approach to detecting phish-
ing websites hosted on compromised domains by comparing
the HTML code and visual appearance of potential phishing
pages against the corresponding characteristics of the home-
page of compromised (hosting) website. Recently, Sophie
et al. [52] build a content-agnostic machine learning model
using three different phishing datasets APWG [3] and Phish-
Labs [10] and DeltaPhish [30]. However, there are several
shortcomings in their work: their classiﬁer heavily relies on
The Wayback Machine (WBM) [13] features that are not only
biased but also difﬁcult to collect. We observe that WBM
content is not available for many attacker-owned domains,
non-US websites as well as newly registered domains, lead-
ing many missing values in feature vectors. Further, some of
their predicted labels with high conﬁdence are in fact inaccu-
rate (e.g. 000a.biz and kl.com.ua are public hosting domains).
An interesting approach to identifying compromised domains
has been proposed by Liu et al. [42]. There key ideas to proﬁle
the good behavior of the passive DNS information of each
domain and measure the deviation as a differentiator. How-
ever, their approach fails to accurately ﬁlter public domains
and additionally the classiﬁcation requires considerable repu-
tation information on domains in order to make an accurate
decision. Recently, Marooﬁ et al. [45] proposed a content
based approach to classify malicious domains as attacker-
owned or compromised. They extract features from WHOIS
registration records, passive DNS, active DNS, page ranking
formation, and page content. Similar to previous approaches,
their approach focuses only on private apex domains. Further,
they ﬁlter public domains based only on the publicly available
sufﬁx lists. Yet we show in this work that such lists cover only
a small fraction of public domains. This results in inaccurate
classiﬁcation as most characteristics of public apex domains
are different from private apex domains. Further, unlike our
approach, all above approaches ignore compromised websites
on public domains.
Domain impersonation attacks. Malicious domains are
increasingly known to use cybersquatting such as combosquat-
ting [38] and target embedding [57] techniques to trick more
victims by mimicking legitimate domains and embedding
known popular “brand” names such as paypal or apple in
the domain name. While many of such domains are attacker
created, there are notable exceptions as long as they use brand
keywords in good faith (e.g. applefarm.com and amazonker-
atin.com). Hence, relying solely on likely brand imperson-
ation could result in many false positives. In our work, we uti-
lize brand impersonation as a likely signal of attacker-owned
domains, but it works together with other features to improve
the detection accuracy.
Phishing/malicious domain detection. These methods
can broadly be categorized into two groups: content-based and
content-agnostic. Content-based phishing for example [65,70]
utilizes features from the web page content itself to train
a machine learning model to detect phishing URLs. While
they are quite accurate, it is quite time consuming and re-
source intensive to train classiﬁers based on the content of
web pages. Content-agnostic phishing methods, on the other
hand, utilize features other than content based features such as
URL/domain lexical features, registration information, DNS
USENIX Association
30th USENIX Security Symposium    3735
information and hosting information [26, 61]. All these meth-
ods are in fact utilize features indicative of attacker-owned
domains (e.g. newly registered, hosted on an unreputed in-
frastructure, and fast IP ﬂuxing) and hence perform poorly
detecting compromised domains.
9 Conclusions
We design machine learning models to distinguish two kinds
of malicious URL hosting apex domains, public and private.
This classiﬁcation helps security professionals specify which
domain levels to block, the whole apex domain in the case of
private apexes or speciﬁc subdomains/path sufﬁxes in the case
of public ones. Our results show that we can classify apex
domains as public or private with 97.2% accuracy, 97.7% pre-
cision and 95.6% recall. From the private malicious domains,
we also design another machine learning model to differenti-
ate attacker-owned from compromised hosting apexes. This
distinction is crucial to help security operators take the ap-