### Identifying Sufficient Training Data for Machine Learning Models

A critical question in machine learning is determining the amount of training data required to achieve the desired performance. Figure 15 illustrates the accuracy of our private apex domain classifier for various dataset sizes. Our original balanced dataset for the two windows contains approximately 700 apexes from each class. As shown in the figure, our classifiers achieve an accuracy similar to that of the full labeled set with approximately 70% of the labeled data.

### Feature Stability Over Time

In practical applications, it is essential to determine how frequently a classifier needs to be retrained to address concept drift. To measure the impact of concept drift on our classifier, we created two datasets, one and two weeks apart from the AC-GT2 dataset. We then evaluated the performance of our classifier, trained on AC-GT2, using these two datasets, each containing 100 labels. Table 10 shows that our classifier maintains good performance after two weeks, although its performance gradually declines as the temporal gap between the training and testing data increases. For maintaining high precision, we recommend retraining the classifiers weekly.

We also tested the model trained with the labeled data from AC-GT1 on AC-GT2. As expected, since the two datasets are two months apart, the classification accuracy dropped significantly by 14%.

**Table 10: Concept Drift Analysis of Private AC/C Classifier**

| Validation Set | Recall | Precision | Accuracy |
|----------------|--------|-----------|----------|
| Same Week      | 97.1%  | 99.1%     | 94.2%    |
| After 1 Week   | 95.0%  | 90.9%     | 100.0%   |
| After 2 Weeks  | 93.0%  | 87.7%     | 100.0%   |

### Robustness Against Manipulation

Since VirusTotal (VT) provides services to the public, there is a concern that attackers might submit URL queries to indirectly influence VT features, such as `#Total_Scans` and `#VT_Duration`, thereby affecting the classification results. To demonstrate the classifier's robustness against such manipulations, we measured its performance when different types of VT features were excluded. Table 9 shows that the influence of these features on the classification performance is not significant. Even when all VT features are omitted, the classification accuracy drops by only 6%. A potential way to further enhance robustness is to enrich the classifier with additional features from diverse sources, such as domain certificates.

**Table 9: Robustness of Private AC/C Classifier**

| Features                                       | Recall  | Precision | Accuracy |
|------------------------------------------------|---------|-----------|----------|
| All                                            | 96.4%   | 99.1%     | 92.6%    |
| All - {VT Profile}                             | 94.01%  | 94.1%     | 91.8%    |
| All - {VT Profile, VT Duration, Positive Count}| 92.9%   | 93.9%     | 90.9%    |
| All - {VT Profile, VT Report}                  | 90.1%   | 92.0%     | 84.4%    |

### Impact of Training Data Quality

The effectiveness of machine learning models heavily depends on the quality of the training data. In our study, we collected labeled training and testing data through manual inspection by multiple domain experts, implementing mechanisms to handle disagreements. To assess the impact of noisy training data, we deliberately introduced mislabeled data and retrained our classifier for both DS1 and DS2, while controlling the noise level. As shown in Figure 14, our classifier can generally tolerate small amounts of mislabeled data. At 1% and 5% noise levels, the accuracy of our classifier remains relatively stable.

### Misclassified Apex Domains

We used LIME, a tool that provides explanations for individual predicted data points, to analyze misclassified data points in AC-GT2. This analysis resulted in 1 False Positive (FP) and 8 False Negatives (FNs). Two key observations were made: first, most misclassified data points lack PDNS features (default values were used for missing PDNS features); second, the prediction probability for the remaining misclassified ones is close to 0.5, indicating weak predictions. Possible approaches to reduce FPs/FNs include filling missing values using alternative data sources, such as active DNS, or incorporating additional features from diverse sources like WHOIS registration records to better differentiate the classes.

### Comparison with Industry Practices

Google Safe Browsing (GSB) has been instrumental in protecting users from phishing and malware attacks. GSB categorizes malicious websites as either malware or phishing sites, with malware sites further classified as compromised or attacker-owned. However, GSB does not provide public APIs or services to classify individual URLs as compromised or attacker-owned, and detailed information on their classification methods is not publicly available. Therefore, we could not directly compare our classifier with GSB's. Instead, we compared the published statistics of these two types of URLs in the Google Transparency Report in August 2019. Figure 16 compares the number of unique malicious websites detected by GSB and VT.

While GSB detects around 30,000 new malicious websites per week, VT detects three times that amount, suggesting room for improvement in GSB's coverage. Our manual inspection of selected malicious websites from VT confirmed that many domains marked as malicious by VT are not flagged by GSB. Additionally, GSB only studies whether malware websites are compromised or attacker-owned, which account for less than 7% of all detected malicious websites. In contrast, our approach categorizes both phishing and malware websites as attacker-owned or compromised, potentially complementing GSB to detect more attacker-owned/compromised domains.

### Limitations and Future Work

- **Feature Specificity:** Our work primarily uses malicious URL intelligence from VT. While removing VT-specific features still yields good performance, integrating other data sources, such as WHOIS, active DNS, and certificate transparency logs, could further improve the model.
- **Ground Truth Data:** Collecting high-quality ground truth data is challenging. Our current dataset, obtained through manual inspection, is moderate in size. Larger datasets and advanced techniques for semi-automated labeling, such as Snorkel, could provide new insights.
- **Re-Compromised Websites:** We observed that some compromised websites, after being cleaned, get compromised again. A future direction is to develop a reputation-based score for benign websites based on their compromise history and cleanup speed.

### Related Work

- **Malicious vs. Compromised Domains:** Previous studies have explored the use of Google search, HTML code, and visual appearance to identify compromised domains. However, these methods often rely on biased or difficult-to-collect features.
- **Domain Impersonation Attacks:** Techniques like combosquatting and target embedding are used to mimic legitimate domains. Our approach uses brand impersonation as one of several features to improve detection accuracy.
- **Phishing/Malicious Domain Detection:** Content-based and content-agnostic methods are used for detecting phishing URLs. Content-agnostic methods, which utilize features like URL/domain lexical features and registration information, often perform poorly in detecting compromised domains.

### Conclusions

We designed machine learning models to distinguish between public and private apex domains, achieving 97.2% accuracy, 97.7% precision, and 95.6% recall. From the private malicious domains, we further developed a model to differentiate attacker-owned from compromised hosting apexes. This distinction is crucial for security operators to take appropriate actions, such as blocking entire apex domains or specific subdomains.