challenge
counting
counter
 enable
clock
Figure 1: Self-Oscillating Loop Circuit.
Challenge Bit 1
Challenge Bit n−1
Challenge Bit n
1
0
1
0
1
0
1
0
1
0
Switch Block
Variable−delay
buffer
Switch Block
Variable−delay
buffer
Figure 2: Non-Monotonic Delay Circuit.
This section describes some of the techniques that can be
used to improve the reliability and strength of a PUF.
In each case, we have a PUF f that we are trying to
improve in some way. Control allows us to improve f by
constructing a new PUF g, that is based on f . The control
only allows f to be evaluated as part of an evaluation of
g, and only uses the result of the evaluation of f to help
evaluate g.
The block diagram in (cid:12)gure 3 shows most of the improve-
ments that are discussed in this section. For the improve-
ments to be robust to physical attack, the logic that sur-
rounds the PUF must be intertwined with it (see section 3.4)
so that an adversary can’t bypass the logic through physical
probing. In particular he must be prevented from reading
the PUF’s response directly before it goes through the out-
put random function, and from bypassing the input random
function by driving the PUF’s challenge directly.
In this section we will be using random functions, a real
implementation would naturally have to rely on pseudo-
random functions.
4.3.1 Preventing Chosen Challenge Attacks
Unless one ventures into quantum e(cid:11)ects (which would
make a PUF highly unreliable), the number of physical pa-
rameters that de(cid:12)ne a PUF is proportional to the size of the
system that de(cid:12)nes it. Therefore, in principle, if an attacker
is able to determine a number of primitive parameters that
is proportional to the size of the physical system, he can use
them to simulate the system and thus clone the PUF.
To try to determine primitive parameters, the attacker
gets a number of challenge-response pairs (CRPs), and uses
them to build a system of equations that he can try to solve.
By de(cid:12)nition, for a PUF, these equations are impossible to
solve in reasonable time. However, there can be physical
systems for which most CRPs lead to unsolvable equations,
while a small subset of CRPs give equations that are able
to break the PUF (which consequently is not really a PUF).
Such a system is not secure because an adversary can use the
CRPs that lead to simple equations to get a solvable system
of equations, calculate the primitive parameters, and clone
the PUF by building a simulator.
With control, it is nevertheless possible to build a secure
system out of one of these broken PUFs. One way of doing
this is for the control layer to simply refuse to give responses
to challenges that lead to simple equations. Unfortunately,
this method assumes that we know all the strategies that
the attacker might use to get a simple set of equations from
a chosen set of CRPs.
We can do even better if we pre-compose the broken PUF
with a random function. Instead of using f directly, we use
g(x) = f (h(x));
where h is a random function. With this method, it is im-
possible for the adversary to choose the challenge h(x) that
is being presented to the underlying PUF, so even if he (cid:12)nds
a challenge that would break it, he is unable to present that
challenge. Now, there is no need for the designer of the PUF
to know what challenges the adversary might try to exploit.
4.3.2 Post-Composition with a Random Function
It is desirable for the output of a PUF to exhibit as much
randomness as possible to prevent an adversary from guess-
153Improved PUF
ID
Challenge
Personality
Random
Hash
PUF
ECC
Random
Hash
Response
Redundancy Information
Figure 3: This diagram shows how control can be used to improve a PUF. Random hash functions are used
at the input and output of the PUF, an Error Correcting Code is used to make the PUF reliable, a unique
identi(cid:12)er guarantees that no two PUFs will be identical, and a personality selector allows the owner of the
PUF to maintain his privacy.
ing the response to one challenge by using the response to
another challenge. However, the output of a physical sys-
tem is likely to produce similar responses when faced with
similar stimuli. Moreover, as we discussed in section 4.3.1,
CRPs can be used to get systems of equations that relate
the PUF’s underlying physical parameters.
Both of these risks can be eliminated by doing a simple
transformation on the PUF. If f is the PUF that we are
trying to improve, and h is a random hash function, then
g(x) = h(x; f (x))
is a stronger PUF. The random hash function’s avalanche-
e(cid:11)ect ensures that nearby outputs of f will lead to com-
pletely di(cid:11)erent outputs of the composite function, and the
one-way7 nature of h means that to set up a system of equa-
tions, the adversary has to invert h (or include the de(cid:12)nition
of h in the system of equations, which is just as bad).
Post-composing the PUF with a random function is a very
important step because it makes the system provably resis-
tant to non physical attacks, as long as enough informa-
tion is extracted from the physical system before running it
through the output random function. In the case of a de-
lay circuit, the right thing would be to measure a number
of delays until a few hundreds of bits have been extracted
from the system, and then run the lot of them through the
random function.
4.3.3 Giving a PUF Multiple Personalities
A possible concern with the use of PUFs is in the area
of privacy.
Indeed, past experience shows that users feel
uncomfortable with processors that have unique identi(cid:12)ers,
because they feel that they can be tracked. Users could have
the same type of concern with the use of PUFs, given that
PUFs are a form of unique identi(cid:12)er.
This problem can be solved by providing a PUF with mul-
tiple personalities. The owner of the PUF has a parameter
that she can control that allows her to show di(cid:11)erent facets
of her PUF to di(cid:11)erent applications. To do this, we hash
the challenge with a user-selected personality number, and
use that hash as the input to the rest of the PUF.
In this way, the owner e(cid:11)ectively has many di(cid:11)erent PUFs
at her disposal, so third parties to which she has shown
7Random functions are one-way functions.
di(cid:11)erent personalities cannot determine if they interacted
with the same PUF.
We go into the details of protocols that use multiple per-
sonalities in [10].
4.3.4 Error Correction
In many cases, the PUF is being calculated using an ana-
log physical system.
It is inevitable that slight variations
from one run to the next will cause slight changes in the
digitized output of the PUF. This means that the chip only
produces an approximation of the response that is expected
of it. In some applications, the chip and the challenger can-
not directly compare the real response with the desired re-
sponse as this would require sending one of the responses in
the clear, thus compromising the shared secret. Therefore,
something must be done to make the PUF’s output identical
each time a challenge is reused.
A suitably selected error correcting code is one possibility.
When a challenge-response pair is created, some redundant
information is also produced that should allow slight vari-
ations in the measured parameters to be corrected for. On
subsequent uses of the challenge-response pair, the redun-
dant information is provided to the PUF along with the
challenge. It is used to correct the response from the physi-
cal system.
Naturally, the error correction must take place directly
on the measured physical parameters. In particular, if the
PUF is post-composed with a random function, the correc-
tion must take (cid:12)rst.
If multiple measurements are being
combined into one response, the error correction should op-
erate on all the measurements.
It is of course critical that the redundancy information
not give away all the bits of the response.
4.3.5 Multiple Rounds
To add even more complexity to the attacker’s problem,
it would be possible to use the PUF circuit multiple times
to produce one response. The corrected response from one
round can be fed back into the PUF circuit. After a few
rounds have been done, all their outputs could get merged
together along with the challenge, the personality and the
chip’s identi(cid:12)er and passed through a random hash function
to produce the global response.
1544.3.6 Unique Identiﬁer
With manufacturer resistant PUFs, the manufacturer re-
sistance is typically a result of the manufacturer’s limited
control over process variations. Each PUF is di(cid:11)erent be-
cause of these variations. However, it is possible that there
will be identical PUFs. This isn’t much of a problem, be-
cause in general (cid:12)nding a pair of PUFs that is identical re-
quires producing, and comparing an unreasonable number
of PUFs.
Nevertheless, it is possible to guarantee that any two PUFs
are di(cid:11)erent. To do so, we combine the actual challenge and
a unique identi(cid:12)er that is unique to the chip with a hash be-
fore running them through the rest of the PUF. The unique
identi(cid:12)er that is used here need not be secret, and can be
the IC’s serial number, for example.
In this way, no two PUFs are identical, and even if two
controlled PUFs share the same underlying PUF f , there is
no way for an adversary to (cid:12)nd this out (the manufacturer
might be able to discover it before setting the PUF’s unique
identi(cid:12)er, but the cost of testing is prohibitive in any case).
5. APPLICATIONS
What are the bene(cid:12)ts of having a unique hardware chip?
We believe there are many, and we describe a few applica-
tions here. Other applications can be imagined by study-
ing the literature on secure coprocessors. In particular, [16]
describes many applications that this work should be appli-
cable to. The authenticated identi(cid:12)cation application that
is listed applies to PUFs in general. It is in fact the only
application of PUFs until control is added. The other appli-
cations require controlled PUFs in order to be possible, the
relevant theory can be found in [10]. The important point
is that with control, it is possible for a PUF to be used to
provide a shared secret to an application.
5.1 Authenticated identiﬁcation
The most natural application to implement is authen-
ticated identi(cid:12)cation.
It is the application that was de-
scribed in [12]. One possible application is to securely iden-
tify smartcards. We can create a smartcard with a PUF, and
each time the PUF-smartcard is used, the card reader can
ask the card for responses to a speci(cid:12)c set of challenges to
identify the PUF. In this case each time the PUF-smartcard
is used, a new set of challenges has to be used, else the
PUF-smartcard is subject to replay attacks. This does not
pose a problem, since the card manufacturer can create a
large number of challenge-response pairs before the PUF-
smartcard is given to a user.
With current methods, it is possible for someone who is
in possession of a smartcard to produce a clone of it, by ex-
tracting its key information through one of many well doc-
umented attacks. If someone loses track of her card for a
while, her card can potentially have been cloned. Being in
physical possession of the smartcard is therefore not synony-
mous to being safe. With a PUF on the smartcard that can
be authenticated and identi(cid:12)ed, there is no longer any need
for a digital key that can be easily extracted. The smartcard
hardware is itself the secret key. This key cannot be dupli-
cated, so a person can lose control of the PUF-smartcard,
retrieve it, and continue using it. In this way it is possible
to lend the PUF-smartcard to a \friend" without causing a
permanent breach of security.
This method is well suited to credit cards since the impor-
tant point is to check that the person is in possession of her
original card. It does not, however provide guarantees that
the card reader is really talking to the original card, as it is
possible that a man in the middle attack is being carried out.
To get around this limitation for more sophisticated appli-
cations requires control and the protocols described in [10].
In section 6, we show that with 10 self-oscillating loops
such as those we have studied, it is possible to distinguish be-
tween up to 10 billion chips. In the same conditions, an ad-
versary who tries to guess the response correctly would have
only one chance in 1020 billion of succeeding. This number
need not be any greater because the adversary will exhaust
the prerecorded database of challenge-response pairs long
before he gets a signi(cid:12)cant probability of success.
In this case, the adversary will, however have successfully
carried out a denial of service attack. This attack can be
made as hard as breaking a non-PUF system by requiring
that the smartcard identify itself using a digital challenge-
response protocol before it challenges the card with one of
the limited number of PUF challenge-responses that it has.
Note that this method only allows authentication of the
smartcard to a remote server. It does not remove the need
for a PIN number, or biometrics, or some other means for
the card to identify the bearer of the card.
5.2 Proof of Execution on a Speciﬁc Processor
At present, computation power is a commodity that un-
dergoes massive waste. Most computer users only use a
fraction of their computer’s processing power, though they
use it in a bursty way, which justi(cid:12)es the constant demand
for higher performance. A number of organizations, such
as SETI@home and distributed.net, are trying to tap that
wasted computing power to carry out large computations in
a highly distributed way. This style of computation is un-
reliable, however, as the person requesting the computation
has no way of knowing that it was executed without any
tampering.
With chip authentication, it would be possible for a certi(cid:12)-
cate to be produced that proves that a speci(cid:12)c computation
was carried out on a speci(cid:12)c chip. The person requesting
the computation can then rely on the trustworthiness of the
chip manufacturer who can vouch that he produced the chip,
instead of relying on the owner of the chip.
There are two ways in which the system could be used.