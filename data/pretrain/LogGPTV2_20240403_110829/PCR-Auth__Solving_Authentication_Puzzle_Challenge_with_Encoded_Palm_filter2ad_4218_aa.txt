title:PCR-Auth: Solving Authentication Puzzle Challenge with Encoded Palm
Contact Response
author:Long Huang and
Chen Wang
4
6
5
3
3
8
9
.
2
2
0
2
.
4
1
2
6
4
P
S
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
2
2
0
2
©
0
0
.
1
3
$
/
2
2
/
9
-
6
1
3
1
-
4
5
6
6
-
1
-
8
7
9
|
)
P
S
(
y
c
a
v
i
r
P
d
n
a
y
t
i
r
u
c
e
S
n
o
m
u
i
s
o
p
m
y
S
E
E
E
I
2
2
0
2
2022 IEEE Symposium on Security and Privacy (SP)
PCR-Auth: Solving Authentication Puzzle
Challenge with Encoded Palm Contact Response
Department of Computer Science, Louisiana State University, Baton Rouge, LA 70803, USA
Email: PI:EMAIL, PI:EMAIL
Long Huang, Chen Wang
Abstract—Biometrics have been widely applied as personally
identiﬁable data for user authentication. However, existing bio-
metric authentications are vulnerable to biometric spooﬁng. One
reason is that they are easily observable and vulnerable to
physical forgeries. Examples are the apparent surface patterns of
human bodies, such as ﬁngerprints and faces. A more signiﬁcant
issue is that existing authentication methods are entirely built
upon biometric features, which almost never change and could
be obtained or learned by an adversary such as human voices. To
address this inherent security issue of biometric authentications,
we propose a novel acoustically extracted hand-grip biometric,
which is associated with every user’s hand geometry, body-fat
ratio, and gripping strength; It is implicit and available whenever
they grip a handheld device. Furthermore, we integrate a coding
technique in the biometric acquisition process, which encodes
static biometrics into dynamic biometric features to prevent data
reuse. Additionally, this low-cost method can be deployed on any
handheld device that has a speaker and a microphone.
In particular, we develop a challenge-response biometric au-
thentication system, which consists of a pair of biometric encoder
and decoder. We encode the ultrasonic signal according to a
challenge sequence and extract a distinct biometric code as
the response for each session. We then decode the biometric
code to verify the user by a convolutional neural network-based
algorithm, which not only examines the coding correctness but
also veriﬁes the biometric features presented by each biometric
digit. Furthermore, we investigate diverse acoustic attacks to our
system, by respectively assuming an adversary could present the
correct code, generate similar biometric features or successfully
forge both. Extensive experiments on mobile devices show that
our system achieves 97% accuracy to distinguish users and rejects
100% replay and synthesis attacks with 6-digit codes.
I. INTRODUCTION
Biometrics such as faces, ﬁngerprints and irises are increas-
ingly exploited to verify users because they are convenient to
use [1]. A recent report estimates that over 1.5 billion people
might use biometrics for authentication by 2023 [2]. However,
biometric security is attracting increasing public concerns.
Due to the increasingly advanced recording technologies,
3D printing, wireless eavesdropping and malware [3],
the
user’s biometrics are under two major replay threats, physical
forgeries and authentication data reuse. As reported by recent
studies, an adversary can perform various types of replay
attacks to spoof the user’s face [4], [5], [6], ﬁngerprint [6], [7],
iris [8], [9] and voice [10], [11]. Addressing the replay issues
has become a critical task for ensuring biometric security.
An active research direction for preventing relay attacks is
liveness detection. These approaches require motions to prove
live faces [12] and leverage heatmaps to detect live ﬁngers.
But these methods require the user’s participation to prove
“liveness” or are subject to additional sensor overheads. They
still have not fundamentally solved the two replay threats.
Behavioral characteristics (e.g., gaits) are a rapidly growing
category of biometrics, which can not be physically replicated
like body traits and are hard to imitate. To further address
the data replay issue, behavioral biometrics are increasingly
integrated with Challenge-Response (CR) protocols [13], [14].
Speciﬁcally, the user is asked to respond to a random sequence
challenge (e.g., letters and icons) for authentication by typing,
speaking or eye-tracking. The correctly repeated sequence
and the associated behavioral characteristics (e.g., keystroke
dynamics, voices and reﬂexive eye movements) are veriﬁed
as the response. However, the existing biometric CR solutions
all require active participation from the user, such as cognitive
activities and behavioral feedback; They are both intrusive and
time-consuming, which impedes their deployment.
it
This work aims to develop a biometric-based CR authen-
tication system for handheld devices, which not only solves
the above replay threats but also requires low user efforts. The
hand-grip biometric inherently comes with handheld devices,
and acquiring it requires no more efforts than obtaining a
ﬁngerprint. This biometric was traditionally extracted by an
array of pressure sensors that enclose the handheld device [15],
[16], [17]. We propose to describe this biometric acousti-
cally as Palm Contact Response (PCR) to facilitate dynamic
biometric features. Speciﬁcally, when using an ultrasound as
the stimulus signal,
interacts with the user’s contacting
palm and experiences damping, reﬂection and refraction before
reaching the microphone. These signal impacts are resulted
from both the user’s distinctive physiological
traits (e.g.,
hand geometry, palm size and body-fat ratio) and behavioral
characteristics (e.g., gripping strength). While the hand shape
can be physically replicated, the body-fat ratio and gripping
strengths are more implicit and hard to imitate. Moreover,
by manipulating the signal frequencies, we extract different
responses from the palm to make every authentication session
unique and non-repeated. In addition, the proposed biometric
CR authentication can be deployed on any handheld devices
(low-end or high-end) that have a speaker and a microphone.
No dedicated hardware is required.
We devise a novel biometric encoding technique to integrate
the hand-grip biometric with the CR protocol. Based on that
we develop the PCR-Auth system, whose handshake process
is shown in Figure 1. When a user requests an authentication,
© 2022, Long Huang. Under license to IEEE.
DOI 10.1109/SP46214.2022.00053
1034
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:37:04 UTC from IEEE Xplore.  Restrictions apply. 
biometric codes, which creates a huge response pool to
support everyday CR authentications. Moreover, we develop
a CNN-based method to decode the unique biometric code
for each session, which not only veriﬁes the biometric but
also checks the code correctness.
• New Attacks and Extensive Experiments: While the CR
authentication is designed to defeat replay attacks, we take
one step further to investigate new attacks, assuming an
adversary can repeat the code, replicate the biometric or
forge both. The system is then evaluated on multiple devices
under these attacks. Results show that our system veriﬁes
users with 97% accuracy and rejects up to 100% replay and
synthesis attacks with 6-digit PCR codes.
II. BACKGROUND AND SYSTEM MODELS
A. Palm Contact Response
The hand-grip biometric is an extension of the hand ge-
ometry biometric in the handheld device scenarios, which
describes how uniquely a user holds the device. It is tradition-
ally extracted by the pressure sensor-enclosed device surface
(e.g., piezoelectric materials) that captures not only the hand
geometry but also the pressure distributions of the contacting
palm [15], [16], [17]. Due to the high hardware requirement,
such a biometric has not attracted much attention.
Motivated by the recent vibration studies that use vibra-
tion signals to differentiate people’s palms pressing on a
surface [18], [19], we ﬁnd that the ordinary acoustic sounds
of a handheld device can distinguish people’s palm when it
grips the device. Speciﬁcally, after the speaker of the handheld
device generates a stimulus signal s(t), a portion of the signal
propagates in a direct path to reach the microphone (structure-
borne or near-surface air-borne), while other parts of the signal
go through more complicated reﬂected paths as shown in
Figure 1. The user’s gripping hand impacts these signals in
their propagation paths. Moreover, the speaker’s sounds induce
the device surface to vibrate at the same frequencies, which
serves as a second sound source and creates sounds in the
same frequencies and their harmonics, though losing a few
frequencies [20]. When in contact with a hand, the device
surface vibrations are impeded resulting in modiﬁed sounds.
All these sounds affected by the hand carry some biometric
information when they are picked up by the microphone.
We model the impact of a gripping hand on the speaker
sound (input) as a system response H(f ). The microphone
signal (output) can thus be expressed as ˆS(f ) = H(f )S(f )
in the frequency domain, where S(f ) is the original speaker
sound at frequency f. To show the microphone signal as the
sum of three signal components, the direct-path signal, the
reﬂected signal and the surface vibration sound, we divide the
system response into three subsystem responses Hd(f ), Hr(f )
and Hv(f ) accordingly and obtain Equation 1,
ˆS(f ) = Hd(f )S(f ) + Hr(f )S(f ) + Hv(f )S(f ).
(1)
We further express each subsystem response in terms of its
amplitude and phase and obtain Equation 2,
ˆS(f ) = |Hd(f )|S(f ) + |Hr(f )|S(f )ej2πf t + |Hv(f )|S(f )ej2πf τ ,
(2)
Fig. 1: The handshake process of PCR-Auth.
PCR-Auth generates a challenge (i.e., a random sequence).
The device encodes the challenge into a series of millisecond-
level ultrasonic pulses on different frequencies and plays the
sound to acquire the user’s encoded PCR, which includes the
direct-path signal, reﬂections and the induced surface vibration
sounds modiﬁed by the user’s palm. The encoded PCR is then
decoded, and the access permission is granted only when the
decoded sequence is correct and the biometric measurement
matches with the proﬁle. Our biometric encoding also enables
generating a huge response universe at a minimum training
overhead to support everyday authentication purposes.
The PCR-Auth consists of two components: 1) PCR En-
coder generates a One-Time-Challenge (OTC) Code and trans-
mits the stimulus signals through the narrow-band channels
indexed by each OTC digit, which encodes the user’s hand-
grip biometric into a PCR code. 2) PCR Decoder is a per-user
deep learning model trained at the registration phase, which
veriﬁes both the coding sequence and the PCR. In particular,
we exploit an OTC-guided bandpass ﬁlter to extract every
PCR digit from the right channels. The Signal-to-Noise Ratios
(SNRs) of the PCR digits are examined to verify the code
sequence, while incorrectly encoded PCR digits (i.e., on the
wrong channels) are ﬁltered out resulting in low SNRs. Next,
we derive the spectrogram to examine the user’s hand-grip
biometric features carried on each PCR digit. We develop
a Convolutional Neural Network (CNN)-based algorithm to
verify all PCR digits and leverage its multi-class classiﬁcation
capability to address human behavioral
inconsistency. The
CNN scores of each PCR digit are returned. We then apply a
cluster-based method to integrate the CNN scores and SNRs
of all PCR digits to make the authentication decision.
The main contributions are summarized as below:
• Unobtrusive Biometric CR Authentication: We propose
a solution to address the replay issues of biometric authen-
tications by integrating a coding technique with biometric
acquisition. The authentication process requires neither ac-
tive user participation nor additional hardware.
• An Implicit Biometric: We extract the user’s hand-grip
biometric via acoustic sensing, which is a combination of
the physiological and behavioral biometrics of the user’s
gripping hand. We show that
this biometric can show
dynamic features under different stimulus signals.
• Biometric Encoding: We encode a user’s biometric into
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:37:04 UTC from IEEE Xplore.  Restrictions apply. 
21035
ChallengeEncoded Palm Contact ResponseRequestPCR-AuthBiometric DecodingInduced Surface Vibration SoundsReflectionsDirect-pathsignalBiometric EncodingAcoustic-based PCR Acquisition Fig. 2: The impact of hand-grip to the smartphone’s sound.
where t and τ are the additional travel time of the reﬂected
signal and the surface vibration sound, compared to the
direct-path signal. Equation 2 explains how the three signal
components are modiﬁed by the gripping hand regarding both
amplitude and phase. In particular, the three types of signals
at frequency f are all damped by the gripping hand with
the scale factors |Hd(f )|, |Hr(f )| and |Hv(f )| respectively,
which are mainly determined by the user’s gripping hand.
The reﬂected signal and the surface vibration sound further
suffer from phase changes 2πf t and 2πf τ, because they
travel longer distances compared to the direct-path signal. The
phase changes are more related to the user’s hand geometry
and holding position. This work is based on the assumption
that people’s gripping hands are distinctive. As a result, the