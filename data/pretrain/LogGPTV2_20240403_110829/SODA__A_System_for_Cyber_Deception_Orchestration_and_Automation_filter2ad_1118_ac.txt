Figure 8: Communication among SODA’s different segments,
agents and the victim under attack.
web pages, decoy process lists, honey registry files etc. HF also
hosts REST APIs to provide service to the API hooks.
4 REAL-TIME ORCHESTRATION
In this section, we discuss how SODA orchestrates and tackles real-
world malware at run-time. This phase consists of four components:
Orchestration Engine Server (OES), Orchestration Engine Client
(OEC), Detection Agent and HoneyFactory (HF). The OES is the
core component in this phase and provides deception as a service
and manages HF. REST APIs are used to communicate among the
components. OES stores HF scripts, End-Point DLL and deception
profiles created in the previous phase. At first, the users install the
OEC, which is the interface between the victims and the OES. We
suggest the pre-built profiles to the users and the option to create
profiles according to their requirements. The whole procedure of
this phase is depicted in Figure 8 and explained in the following
sections.
Profile Creation: The user sends a profile creation request to
the OES through an user interface. First, OEC shows all the ma-
licious behaviors and their corresponding valid deception ploys
(actions) to the user. Next, the user selects the ploys she wants to
use for orchestration. To avoid errors caused by conflicts among
chosen ploys (e.g., two ploys disagree on the return value of API call
GetComputerName), we have made the deception ploys (e.g., API
hooks) for different malicious behaviors independent of each other.
We also carefully controlled the allowed combinations of deception
ploys in the user interface to avoid potential conflicts. Based on
the selection, OES prepares HF and generates a configuration file.
This configuration file is an input to the End-Point DLL and is re-
sponsible for enabling and disabling ploys. Next, OES forwards the
configuration file and the End-Point DLL to the user and deploys
the required HF automatically.
Pre-built Profile Selection: Instead of creating a new profile,
users can select one of our pre-built profiles. For each pre-built
profile, relevant deception ploys are shown to the user. Once the
user makes a selection based on her requirements, the rest of the
process is the same: HF preparation, config file generation and
Send pre-built profilesREST APIsGet pre-built profilesHoneyFactoriesHF1.......1. Deception Playbook(Profiles)2. Available HF DetailsHF preparationScriptsUser 1OrchestrationEngine ServerEnd-Point DLLHoneyFactoryScriptsConfig fileGeneratorOrchestrationEngine ClientSelect profile and ploysEnd-Point DLL, Config file2. Notify If MaliciousEnd-Point DLL, Config3. Inject DLL 4. REST API Communication (FakeExecute) User 2.......Pre-built Profile SelectionAvailable ploysProfile creation requestSelect ploysEnd-Point DLL, Config fileProfile CreationDetectionAgent1. Malware AttackAttacker5. MisInformation681ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Sajid, et al.
deployment. At this point, SODA is ready to deceive malware with
its arsenals.
Detection Agent: The entry point of SODA is a detection agent,
which detects malware and triggers the rest of the orchestration
process. However, the main focus of this research is not to detect
malware samples. Instead, we are solving the research problem of
designing a cyber deception system capable of providing dynamic
orchestration at run-time. Therefore, SODA can leverage existing
defense/mitigation systems and zero-day malware detection ap-
proaches as our detection agent. For example, [48] has an detection
accuracy of 97.09%. When the detection agent detects a malware
process, it notifies the OEC. Using the DLL injection approach,
OEC injects the End-Point DLL into malware memory, triggering
real-time orchestration.
Real-time deception using embedded API-hooking: Once
the detection agent confirms malware presence, OEC injects the
End-Point DLL into the malware process. It is important that such
injections happen in time to deceive the entire malware execu-
tion period, which is feasible because malware detection systems
usually suspend a process while checking and resume it if not mali-
cious. For example, Windows Defender registers a process-creation
callback routine (in its device driver WdFilter.sys [4]), which is
called whenever a process is created. This callback routine checks
if a new process is a malware process before it runs. SODA can
be integrated with Windows Defender’s callback mechanism such
that when a malware process is starting the OEC receives a noti-
fication and injects the end-point DLL into the malware process.
Now, Let’s describe how the orchestration works in this phase
with an InfoStealer named LokiBot, which tries to steal credentials
from the browsers. The user-selected strategy is FakeExecute and
the 4D goal is Depletion. The deception action for the aforemen-
tioned adversarial action is redirecting the calls to a HoneyFac-
tory and altering the actual credentials (Login Data) with honey
credentials. We observed the malware tried to read from the file:
(C:\Users\Administrator\AppData\Local\Google\Chrome\Us-
er Data\Default\Login Data), then to decrypt credentials it
calls CryptUnprotectData. The injected DLL monitored the invo-
cation of these APIs and determined the malware attempting to
steal credentials from browsers. Hence, when the malware invoked
CryptUnprotectData, the embedded hooking communicates with
HF, asks for a HoneyFile containing HoneyCredentials and replaces
the read result buffer with the content of the HoneyFile. As a result,
ultimately, the malware gets the HoneyCredentials instead of the
actual user credentials.
5 EVALUATIONS
We assess SODA with different types of malware (InfoStealers,
RATs, ransomware, spyware) aging less than two years (2019-21).
The outcomes of our experiments to validate the accuracy, effec-
tiveness, overhead and scalability of SODA, as well as the recall of
MSG extraction and MSG-to-MITRE mapping are described in the
following sections.
5.1 Recall of MSG extraction
5.1.1 Ground-Truth (GT1). We create a ground truth that can
be utilized to validate the accuracy of the MSG extraction. Malware
Tools
Kris et al. [39]
FORECAST [14]
DodgeTron [44]
SODA
Malware Behavior/Capability
Not
Identification (Using GT1)
Recall
0.62
0.34
0.09
0.97
Identified
36
62
86
3
Identified
58
32
8
91
Table 2: Comparison with other State-of-the-art tools in
terms of discovering malware behaviors/capabilities using
GT1 and their individual recall values
source codes can be found on GitHub; specifically, we are interested
in the malware source code written using WinAPIs and C++. We
downloaded 42 malware source codes from GitHub such as [6, 40],
along with the comments and descriptions explaining the malware’s
capabilities. In our context, we consider the malware capabilities as
malware behaviors. We manually went through these source codes,
identified the 94 distinct API sequences (in our context, MSGs),
and mapped them to 31 associate malware behaviors (according to
comments and description). In addition, we manually mapped these
31 malware behaviors to MITRE techniques. This ground truth is
referred to as GT1 and will be used in further evaluations.
5.1.2 Evaluation Metrics and Expectations. We obtain the bi-
naries by building the source code of the downloaded malware. We
ran them through our API Call Tracer and extracted the execution
traces. The expectation for GT1 is that the MSG extractor should
extract these 94 distinct API sequences (in our context, MSGs) from
the traces. However, the MSG extractor may extract more MSGs
than expected due to two reasons, 1) Some WinAPIs contain inter-
nal calls to other WinAPIs that are not apparent in the source code.
2) If the program does not specify memory management, Windows
manages it (APIs such as VirtualAlloc and VirtualFree appear in
the trace even though they are not in the source code). As a result,
accuracy/precision is not the appropriate metric for evaluating our
MSG extraction; instead, recall is the ideal metric for evaluation
because it represents relevant instances that were retrieved. We
also compared
5.1.3 Result obtained from the malware datasets regarding
GT1. We then fed the retrieved traces from the previous step into
the MSG extractor, which retrieved 113 unique MSGs. We manually
went through these MSGs and confirmed 91 of them are as expected
(belonging to the ground-truth). However, we validated that the
remaining three expected MSGs were retrieved as well, but the
extracted API sequences differed from the expected ones due to an
internal call to other WinAPIs. MSG extraction result is shown in
the Table 2. Recall value for our MSG extraction approach is:
RecallGT 1 =
T P
T P + F N
= 91
91 + 3 = 0.968
The recall value is promising and demonstrate the effectiveness
of our MSG extraction procedure.
5.1.4 Comparison with other state-of-the-art tools in terms
of discovering malware behaviors/ capabilities. We empiri-
cally compared SODA with Kris et al. [39], FORECAST [14] and
682SODA: A System for Cyber Deception Orchestration and Automation
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Family
InfoStealer
Ransomware
Malware
Family
Fareit
LokiBot
Pony
Racoon
Ryuk
GandCrab
Gh0st
RAT
VanilaRat
Quasar
Discovery Cuckoo Any.run SODA
T
P
T
P
T
P
T
P
T
P
T
P
T
P
T
P
T
P
8
39
7
21
8
231
7
45
6
27
8
192
2
4
1
1
5
14
7
126
2
173
4
191
8
23
3
32
10
109
2
57
0
0
2
4
8
149
11
243
17
582
16
51
6
102
10
245
6
69
12
12
13
16
Table 3: Number of techniques (T) and procedures (P) discov-
ered by SODA compared to Cuckoo sandbox and Any.run.
DodgeTron [44] that are capable of discovering malware behav-
ior/capabilities. For comparison, we used the collected traces (ob-
tained by the API tracer) of the 42 malware used to build the GT1.
We fed these traces to different tools and observed how many be-
haviors/capabilities were found by each tool. The comparison is
presented in Table 2. We found that SODA outperforms them at
identifying malware capabilities. In Appendix D, we provide more
comparative results to demonstrate SODA’s better coverage in de-
tecting malware capabilities and presenting them in the MITRE
ATT&CK framework as compared to the existing tools.
5.1.5 Comparison with existing Sandboxes. Identification of
malware behavior at the run-time is critical for SODA to select
accurate deception ploys. Thus, we also compared SODA with ex-
isting Sandboxes such as Cuckoo [3] and Any.run [1]. Both Cuckoo
and Any.run presents the observed malware behaviors in the form
of MITRE ATT&CK framework. In this experiment, we specifically
focus on Techniques and Procedures. A Technique represents how
an adversary accomplishes the tactic by performing an action and
a Procedure indicates the specific details of how an adversary
carries out a technique. In this experiment, we ran nine (9) dis-
tinct malware across Cuckoo, Any.run and SODA and listed the
observed malware behaviors in the form of Technique (T) and Pro-
cedure (P) in Table 3. Clearly, SODA discovers more techniques and
procedures than Cuckoo and Any.run.
5.2 MSG Classifier Evaluation
5.2.1 Ground-Truth (GT2). We created a ground truth that can
be utilized to evaluate the MSG-to-MITRE mapping using a remote
access Trojan (RAT). RAT is a type of malware that incorporates a
back door for gaining administrative control over the infected sys-
tem. RATs usually have two modules, one running on the attackers-
end (commonly referred to as "server" or "command and control
server" or "C&C server") and the other running on the victim-
end (client). The C&C server establishes remote communication on
the victim’s machine and sends commands to perform malicious
tasks. Typically, each command is associated with specific mali-
cious behavior. We took advantage of this to create our second
ground truth. We obtained the source code for 13 different RATs
Minimum word frequency
API TF-IDF enriching threshold
Word2Vec similarity threshold
Maximum number of words per MITRE technique
Table 4: MSG Classifier Parameters
4
20%
70%
40
n
Top-n accuracy
1
16
63.75% 81.25% 82.5% 86.3% 90.0% 96.2% 98.7%
13
2
3
4
5
Table 5: Top-n Accuracy of MSG Classifier
from GitHub capable of performing 33 distinct malicious behaviors
according to the descriptions provided in GitHub. We obtain the
binary files by building source codes. We run the client in the API
Call Tracer and run the C&C server on another VM connected to
our API Call Tracer. We run each command at a time using the C&C
server and store the traces into a log file. This design implies that
each of these log files corresponds to a particular malicious behav-
ior. For each log file, we extract MSGs and map them to malicious
behaviors and MITRE techniques manually. The MSG extractor