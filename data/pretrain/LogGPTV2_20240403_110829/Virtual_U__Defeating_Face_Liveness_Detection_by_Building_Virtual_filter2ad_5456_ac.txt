and pupil and form a three-dimensional distribution in
the RGB color space. We estimate this color distri-
bution with a 3D Gaussian function whose three prin-
ciple components can be computed as (b1,b2,b3) with
weight (σ1,σ2,σ3),σ1 ≥ σ2 ≥ σ3 > 0. We perform the
same analysis for the eye region of the average face
model obtained from 3DMM [39], whose eye is look-
ing straight towards the camera, and we similarly obtain
principle color components (bstd
2 ,bstd
3 ) with weight
(σ std
3 > 0. Then, we con-
vert the eye texture from the average model into the eye
texture of the user. For a texture pixel c in the eye region
of average texture, we convert it to
1 ,bstd
2 ≥ σ std
1 ≥ σ std
1 ,σ std
2 ,σ std
3 ),σ std
cconvert =
3
∑
i=1
σi
σ std
i
(c(cid:26)bstd
i
)bi.
(5)
In effect, we align the color distribution of the average
eye texture with the color distribution of the user’s eye
texture. By patching the eye region of the facial model
with this converted average texture, we realistically cap-
ture the user’s eye appearance with forward gaze.
USENIX Association  
25th USENIX Security Symposium  503
3.5 Adding Facial Animations
Some of the liveness detection methods that we test re-
quire that the user performs specific actions in order to
unlock the system. To mimic these actions, we can sim-
ply animate our facial model using a pre-defined set of
facial expressions (e.g., from FaceWarehouse [8]). Re-
call that in deriving in Eq. 2, we have already computed
the weight for the identity axis αid, which captures the
user-specific face structure in a neutral expression. We
can adjust the expression of the model by substituting a
specific, known expression weight vector αexp
std into Eq. 2.
By interpolating the model’s expression weight from 0 to
αexp
std , we are able to animate the 3D facial model to smile,
laugh, blink, and raise the eyebrows (see Figure 6).
Figure 6: Animated expressions. From left to right: smiling,
laughing, closing the eyes, and raising the eyebrows.
3.6 Leveraging Virtual Reality
While the previous steps were necessary to recover a re-
alistic, animated model of a targeted user’s face, our driv-
ing insight is that virtual reality systems can be lever-
aged to display this model as if it were a real, three-
dimensional face. This VR-based spoofing constitutes
a fundamentally new class of attacks that exploit weak-
nesses in camera-based authentication systems.
In the VR system, the synthetic 3D face of the user
is displayed on the screen of the VR device, and as the
device rotates and translates in the real world, the 3D
face moves accordingly. To an observing face authen-
tication system, the depth and motion cues of the dis-
play exactly match what would be expected for a hu-
man face. Our experimental VR setup consists of custom
3D-rendering software displayed on a Nexus 5X smart
phone. Given the ubiquity of smart phones in modern
society, our implementation is practical and comes at
no additional hardware cost to an attacker. In practice,
any device with similar rendering capabilities and iner-
tial sensors could be used.
On smart phones, accelerometers and gyroscopes
work in tandem to provide the device with a sense of
self-motion. An example use case is detecting when the
device is rotated from a portrait view to a landscape view,
and rotating the display, in response. However, these sen-
sors are not able to recover absolute translation — that
is, the device is unable to determine how its position has
changed in 3D space. This presents a challenge because
without knowledge of how the device has moved in 3D
space, we cannot move our 3D facial model in a realistic
fashion. As a result, the observed 3D facial motion will
not agree with the device’s inertial sensors, causing our
method to fail on methods like that of Li et al. [34] that
use such data for liveness detection.
Fortunately, it is possible to track the 3D position of
a moving smart phone using its outward-facing camera
with structure from motion (see §2.3). Using the cam-
era’s video stream as input, the method works by tracking
points in the surrounding environment (e.g., the corners
of tables) and then estimating their position in 3D space.
At the same time, the 3D position of the camera is re-
covered relative to the tracked points, thus inferring the
camera’s change in 3D position. Several computer vision
approaches have been recently introduced to solve this
problem accurately and in real time on mobile devices
[28, 46, 55, 56]. In our experiments, we make use of a
printed marker3 placed on a wall in front of the camera,
rather than tracking arbitrary objects in the surrounding
scene; however, the end result is the same. By incorpo-
rating this module into our proof of concept, the perspec-
tive of the viewed model due to camera translation can be
simulated with high consistency and low latency.4
An example setup for our attack is shown in Figure
7. The VR system consists of a Nexus 5X unit using
its outward-facing camera to track a printed marker in
the environment. On the Nexus 5X screen, the system
displays a 3D facial model whose perspective is always
consistent with the spatial position and orientation of the
authentication device. The authenticating camera views
the facial model on the VR display, and it is successfully
duped into believing it is viewing the real face of the user.
Figure 7: Example setup using virtual reality to mimic 3D
structure from motion. The authentication system observes a
virtual display of a user’s 3D facial model that rotates and trans-
lates and the device moves. To recover the 3D translation of the
VR device, an outward-facing camera is used to track a marker
in the surrounding environment.
3See Goggle Paper at http://gogglepaper.com/
4Specialized VR systems such as the Oculus Rift could be used to
further improve the precision and latency of camera tracking. Such ad-
vanced, yet easily obtainable, hardware has the potential to deliver even
more sophisticated VR attacks compared to what is presented here.
504  25th USENIX Security Symposium 
USENIX Association
4 Evaluation
We now demonstrate that our proposed spoofing method
constitutes a significant security threat to modern face
authentication systems. Using real social media photos
from consenting users, we successfully broke five com-
mercial authentication systems with a practical, end-to-
end implementation of our approach. To better under-
stand the threat, we further systematically run lab exper-
iments to test the capabilities and limitations of our pro-
posed method. Moreover, we successfully test our pro-
posed approach with the latest motion-based liveness de-
tection approach by Li et al. [34], which is not yet avail-
able in commercial systems.
Participants
We recruited 20 volunteers for our tests of commercial
face authentication systems. The volunteers were re-
cruited by word of mouth and span graduate students and
faculty in two separate research labs. Consultation with
our IRB departmental liaison revealed that no applica-
tion was needed. There was no compensation for par-
ticipating in the lab study. The ages of the participants
range between 24 and 44 years, and the sample consists
of 6 females and 14 males. The participants come from
a variety of ethnic backgrounds (as stated by the volun-
teers): 6 are of Asian descent, 4 are Indian, 1 is African-
American, 1 is Hispanic, and 8 are Caucasian. With their
consent, we collected public photos from the users’ Face-
book and Google+ social media pages; we also collected
any photos we could find of the users on personal or com-
munity web pages, as well as via image search on the
web. The smallest number of photos we collected for an
individual was 3, and the largest number was 27. The
average number of photos was 15, with a standard de-
viation of approximately 6 photos. No private informa-
tion about the subjects was recorded beside storage of the
photographs they consented too. Any images of subjects
displayed in this paper was done with the consent of that
particular volunteer.
For our experiments, we manually extracted the region
around user’s face in each image. An adversary could
also perform this action automatically using tag infor-
mation on social media sites, when available. One in-
teresting aspect of social media photos is they may cap-
ture significant physical changes of users over time. For
instance, one of our participants lost 20 pounds in the
last 6 months, and our reconstruction had to utilize im-
ages from before and after this change. Two other users
had frequent changes in facial hair styles – beards, mous-
taches, and clean-shaven – all of which we used for our
reconstruction. Another user had only uploaded 2 pho-
tos to social media in the past 3 years. These varieties all
present challenges for our framework, both for initially
reconstructing the user’s face and for creating a likeness
that matches their current appearance.
Industry-leading Solutions
We tested our approach on five advanced commercial
face authentication systems: KeyLemon5, Mobius6, True
Key [18], BioID [21], and 1U App7. Table 1 summarizes
the training data required by each system when learning a
user’s facial appearance, as well as the approximate num-
ber of users for each system, when available. All systems
incorporate some degree of liveness detection into their
authentication protocol. KeyLemon and the 1U App re-
quire users to perform an action such as blinking, smil-
ing, rotating the head, and raising the eyebrows. In ad-
dition, the 1U App requests these actions in a random
fashion, making it more resilient to video-based attacks.
BioID, Mobius and True Key are motion-based systems
and detect 3D facial structure as the user turns their head.
It is also possible that these five systems employ other
advanced liveness detection approaches, such as texture-
based detection schemes, but such information has not
been made available to the public.
Methodology
System
KeyLemon3
Mobius2
True Key1
BioID2
1U App1
Training Method
Single video
10 still images
Single video
4 videos
1 still image
# Installs
∼100,000
18 reviews
50,000-100,000
unknown
50-100
Table 1: Summary of the face authentication systems evaluated.
The second column lists how each system acquires training data
for learning a user’s face, and the third column shows the num-
ber approximate number of installations or reviews each sys-
tem has received according to (1) the Google Play Store, (2)
the iTunes store, or (3) softpedia.com. BioID is a relatively
new app and does not yet have customer reviews on iTunes.
All participants were registered with the 5 face authen-
tication systems under indoor illumination. The average
length of time spent by each of the volunteers to register
across all systems was 20 minutes. As a control, we first
verified that all systems were able to correctly identify
the users in the same environment. Next, before testing
our method using textures obtained via social media, we
evaluated whether our system could spoof the recogni-
tion systems using photos taken in this environment. We
5http://www.keylemon.com
6http://www.biomids.com
7http://www.1uapps.com
USENIX Association  
25th USENIX Security Symposium  505
thus captured one front-view photo for each user under
the same indoor illumination and then created their 3D
facial model with our proposed approach. We found that
these 3D facial models were able to spoof each of the
5 candidate systems with a 100% sucess rate, which is
shown in the second column of Table 2
Following this, we reconstructed each user’s 3D fa-
cial model using the images collected from public online
sources. As a reminder, any source image can be used as
the main image when texturing the model. Since not all
textures will successfully spoof the recognition systems,
we created textured reconstructions from all source im-
ages and iteratively presented them to the system (in or-
der of what we believed to be the best reconstruction, fol-
lowed by the second best, and so on) until either authen-
tication succeeded or all reconstructions had been tested.
Findings
We summarize the spoofing success rate for each system
in Table 2. Except for the 1U system, all facial recogni-
tion systems were successfully spoofed for the majority
of participants when using social media photos, and all
systems were spoofed using indoor, frontal view photos.
Out of our 20 participants, there were only 2 individu-
als for whom none of the systems was spoofed via the
social-media-based attack.
Looking into the social media photos we collected of
our participants, we observe a few trends among our re-
sults. First, we note that moderate- to high-resolution
photos lend substantial realism to the textured models.
In particular, photos taken by professional photographers
(e.g., wedding photos or family portaits) lead to high-
quality facial texturing. Such photos are prime targets
for facial reconstruction because they are often posted by
other users and made publicly available. Second, we note
that group photos provide consistent frontal views of in-
dividuals, albeit with lower resolution. In cases where
high-resolution photos are not available, such frontal
views can be used to accurately recover a user’s 3D fa-
cial structure. These photos are easily accessible via
friends of users, as well. Third, we note that the least
spoof-able users were not those who necessarily had a
low number of personal photos, but rather users who had
few forward-facing photos and/or no photos with suffi-
ciently high resolution. From this observation, it seems
that creating a realistic texture for user recognition is the
primary factor in determining whether a face authentica-
tion method will be fooled by our approach. Only a small
number of photos are necessary in order to defeat facial
recognition systems.
We found that our failure to spoof the 1U App, as well
as our lower performance on BioID, using social me-
dia photos was directly related to the poor usability of
Indoor
Spoof % Spoof % Avg. # Tries
100%
100%
100%
100%
100%
85%
80%
70%
55%
0%
Social Media
1.6
1.5
1.3
1.7
—
KeyLemon
Mobius
True Key
BioID
1U App
Table 2: Success rate for 5 face authentication systems using a
model built from (second column) an image of the user taken in
an indoor environment and (third and fourth columns) images
obtained on users’ social media accounts. The fourth column
shows the average number of attempts needed before success-
fully spoofing the target user.
those systems. Specifically, we found the systems have