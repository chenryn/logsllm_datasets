that match a block page template. This method may not capture all
block page templates, but this should not be a problem because of
our evaluation method. Because we are using precision and recall,
020406080100LengthofPagesinKBs0.00.20.40.60.81.0TotalFractionofPagesBlockedPageLengthsAccessiblePageLengths020406080100PercentDifferenceinPageLength0.00.20.40.60.81.0TotalFractionofPagesBlockedPagesAccessiblePages301Similarity Measure
Page Length
Cosine Similarity
DOM Similarity
Diff
True Positive/ Recall (%)
95.03 ±1.128· 10−3
97.94 ±2.341· 10−14
95.35 ±1.242· 10−2
99.13
False Positive (%)
1.371 ±1.829· 10−16
1.938 ±3.657· 10−16
3.732 ±1.866· 10−3
30.95
Precision (%)
79.80 ±1.915· 10−4
74.23 ±1.170· 10−14
59.28 ±8.929· 10−3
15.44
Threshold
30.19%
0.816
0.995
n/a
Table 1: Mean detection rates for similarity measures ± standard deviation are much better than a simple diff.
(a) Precision-recall curve for similarity measures.
(b) ROC curve for similarity measures.
Figure 4: Precision-recall and ROC curves demonstrate that the length comparison measure is the best similarity measure. Green dots mark the selected
threshold values on the graph.
we are evaluating our clustering based upon how well it identiﬁes
the templates we know about. Our method may also ﬁnd templates
we did not manually identify, but we do not evaluate the quality of
those clusters.
To evaluate the quality of each clustering, we computed an
F-1 measure for each cluster. The F-1 measure is a common
clustering evaluation measure that combines precision and recall
equally: 2·precision·recall
precision+recall . Finally, we calculated the overall F-1 mea-
sure by summing the maximum F-measure for each subsequence:
ni
∑i∈clusters
N · max j∈subsequences{ f (i, j)}, where N is the total num-
ber of block pages, ni is the number of block pages in the i’th cluster,
and f (i, j) is the F-measure for cluster i and subsequence j. By
taking the maximum F-measure for each subsequence, we associate
the block page template, or template subsequence, with the cluster
that best matches the template. We then average the F-measures
by weighting the F-measure for each subsequence according to the
number of pages using that template. Intuitively, this weighting
ensures that an outcome with 20 clusters each with one element
and an F-measure of 1 and one cluster with 1000 elements and an
F-measure of 0.01 does not score well. The F-1 measure scales
between 0 and 1; a higher score correlates with higher precision
and recall. When the F-1 measure is higher, the clustering strongly
corresponds with the identiﬁed common subsequences. Because
we generate common subsequences from a random sample of block
pages and each page matched at most one subsequence, clusters
with a high F-measure also strongly correspond to a single template.
Term frequency clustering performs well, with an F-1 measure
of 0.98; clustering based on page length is much worse, with an
F-1 measure of 0.64. This result makes sense because block pages
are generated from a template. Therefore, they often share the
same structure. Term frequency clustering identiﬁes block page
templates despite noise introduced by pages mislabeled as blocked
and a signiﬁcant amount of noise introduced by standard HTTP
error messages. For instance, the data set included a large number
of HTTP 302 and 404 responses. On the other hand, we were
surprised that page length produced poor-quality clusters. Block
Figure 5: Block pages have only a few distinct lengths.
page templates only replace small amounts of text (e.g.the URL of
the blocked Web site), so we expected similar page lengths within
a cluster. Interestingly, Figure 5 shows that block pages have few
distinct sizes; there are fewer clusters than templates.
Fingerprinting Filtering Tools. Where possible, we label each
cluster according to known signatures (e.g., from previous work [2]);
otherwise, we attempt to manually identify the block page vendor
based on features of each template. Using this method, we identiﬁed
ﬁve ﬁltering tools that generated 7 out of 36 clusters from the dataset.
In these cases, copyright notices within HTML comments, HTTP
header ﬁelds, or other signatures offered a deﬁnitive identiﬁcation.
The remainder of the clusters had no identifying information in the
ﬁngerprint, although unique HTTP headers indicated the use of a
distinct tool. Table 2 summarizes these results.
6 Case Studies
We now apply our detection and ﬁngerprinting techniques to the
ONI dataset to explore how the use of various block page methods
has evolved over time. Unfortunately, the ONI did not continuously
gather measurements, so we can only explore measurements from
small snapshots. Fortunately, each snapshot contains enough mea-
surements to make inferences about the presence of speciﬁc ﬁltering
tools. Because the censor could always choose to return nothing or
0.00.20.40.60.81.0Recall0.00.20.40.60.81.0PrecisionCosineSimilarityDOMSimilarityPageLength10−510−410−310−210−1100FalsePositiveRate0.00.20.40.60.81.0TruePositiveRateCosineSimilarityDOMSimilarityPageLength020000400006000080000100000120000LengthofPagesinBytes0.00.20.40.60.81.0TotalFractionofPages302Number of
Clusters
2
1
1
1
2
Product
Manufacturer
FortiGuard
Squid Proxy
Server
Netsweeper
Websense
WireFilter
Network
AS 24090 (Malaysia)
AS 2609 (Tunisia)
AS 12486 (United States), AS 15802 (United Arab
Emirates), and AS 12586 (Yemen)
AS 29584 (Azerbaijan)
AS 25019 (Saudi Arabia)
Time
Frame
2009
2010
2010-
2012
2010
2011
Block page contains the text “Powered by
Fingerprint
FortiGuard”
HTTP Headers contain the text “Server:
squid/2.6.STABLE16”
“webadmin/deny” in URL, which indicates that
Netsweeper is in use [2]
Websense copyright disclaimer is included in
HTML comments
HTTP Headers contain the text “Server:
Protected by WireFilter”
Table 2: Filtering tools identiﬁed from block page templates
Figure 6: Filtering mechanisms used in AS 18399 in Burma.
Figure 7: The appearance of two block page templates in AS 25019 marks
the use of WireFilter, a new ﬁltering tool in Saudi Arabia.
change the block page, the absence of a block page cluster does not
indicate that the given ﬁltering tool is no longer in use. To account
for this ambiguity, we include other types of blocking to give further
insight into changes in ﬁltering tools and capabilities. Speciﬁcally,
vectors refer to block page templates, HTTP indicates no response
to an HTTP request, DNS corresponds to either manipulation by
redirection or the lack of a response, TCP RST refers to TCP RST
ﬁltering, and runs shows when measurements were taken.
We also extend our analysis by determining if block pages are
the result of DNS redirection or not. We assume that the censor
can only use a few IP addresses to host block pages, so if DNS
redirection is in use, we expect the block pages to resolve to a
limited number of IP addresses. Though the number of resolved
IP addresses can ﬂuctuate due to CDNs, DNS redirection should
return signiﬁcantly fewer IP addresses than the number of distinct
URLs measured.
Political Shifts (Burma). Analyzing changes in ﬁltering mecha-
nisms and block pages in Burma (Myanmar) provides insight into
how censorship evolves as ﬁltering tools and regimes change. Fig-
ure 6 shows the censorship enforcement mechanisms and block
page clusters used in AS 18399 in Burma between 2007 and 2012.
Until mid 2009, AS 18399 used DNS redirection as a form of cen-
sorship. In mid-2009, a custom block page template for AS 18399,
vector 0, appears. Because the block pages in vector 0 resolved
568 URLs to 659 IPs, vector 0 does not appear to be using DNS
redirection. Unfortunately, we could not identify the product be-
hind vector 0, but these results indicate that AS 18399 in Burma
may have acquired a new ﬁltering tool in mid 2009. In late 2011,
Burma underwent a massive political shift and signiﬁcantly reduced
the extent of censorship [9], which may be reﬂected in the lack of
detected block pages after this time.
New Filtering Tools (Saudi Arabia). We observed that Saudi Ara-
bia, like many countries, has upgraded its censorship equipment
in recent years. Figure 7 illustrates this shift for AS 25019. Al-
though we do not know what type of ﬁltering equipment was used
in AS 25019 prior to 2011, we can conclude that a new ﬁltering tool,
WireFilter, begins censoring content in 2011. Oddly, WireFilter
appears to be using multiple block page templates concurrently,
which implies that multiple devices are in use.
Different Techniques in Different ISPs (Thailand). Different
ISPs implement Thailand’s censorship mandate differently. Figure 8
illustrates that AS 9737 and AS 17552 use different ﬁltering tools
and mechanisms to enforce censorship.
Figure 8a shows that AS 9737 has changed censorship mech-
anisms over time. The ﬁrst set of measurements in 2008 show
that AS 9737 uses DNS redirection and drops HTTP requests to
censor content. In 2010, AS 9737 starts using a new ﬁltering tool,
represented by vector 17. We could not identify vector 17, but it
appears to be a transparent proxy because the 30 URLS blocked by
vector 17 resolved to 48 unique IP addresses, indicating that DNS
injection was not used. It appears that AS 9737 is also trying to
mask the identity of its ﬁltering software because all HTTP headers
for vector 17 contain the string “Server: Apache/2.2.9 (Debian)”.
Figure 8b shows that AS 17552 and AS 9737 use different cen-
sorship enforcement mechanisms though they have both changed
their ﬁltering over time. Our data shows that AS 17552 switched
from DNS redirection to a new ﬁltering tool in late 2009, shown by
vector 8. Vector 8 does not appear to be the result of DNS redirec-
tion because its 19 URLS resolved to 28 IP addresses. AS 17552
also appears to obfuscate the identity of their ﬁltering tool because
all HTTP headers for the block page contain the string “Server:
Apache”.
2007200820092010201120122013TimeRunsTCPRSTDNSHTTPVector0BlockingTypes2007200820092010201120122013TimeRunsWireFilter1WireFilter2BlockingTypes303(a) Filtering mechanisms used in AS 9737 in Thailand
(b) Filtering mechanisms used in AS 17552 in Thailand
Figure 8: ASes 9737 and 17552 show that government mandated censorship can vary by ISP
Though ASes 9737 and 17552 use different block page templates,
they may be using different conﬁgurations of the same ﬁltering tool.
Vectors 8 and 17, the block pages for ASes 9737 and 17552, have
different structures, as vector 8 uses tables for layout and is around
6000 bytes in length, whereas vector 17 uses div tags for layout and
is around 1000 bytes in length. Despite these differences, the ﬁlter-
ing tools both appear to be transparent proxies, the ﬁltering tools
return similar HTTP headers, and both block pages contain similar
strings such as “The page you are trying to visit has been blocked
by the Ministry of Information and Communication Technology”
(vector 8) and “This website has been blocked by ICT” (vector 17).
7 Conclusion
We developed block page detection and ﬁltering tool identiﬁcation
techniques to enable scalable, continuous, and accurate censorship
measurements. Using these techniques, we built a block page de-
tection method with a 95.03% true positive rate and a 1.371% false
positive rate and a block page identiﬁcation method which correctly
identiﬁed block page templates for 5 known ﬁltering tools. These
methods signiﬁcantly improve the state of the art in censorship
measurement and set the stage for the next generation of censorship
measurements. Because the vendor and product behind many clus-
ters remains unidentiﬁed, future work could include ﬁngerprinting
existing block page products and using the ﬁngerprints to ﬁnd more
template matches.
Acknowledgments
We would like to thank the OpenNet Initiative and the Citizen Lab
for the use of their data. This work was supported by a Google
Faculty Research Award, a Google Focused Research Award, and
NSF awards CNS-1111723 and SaTC-1350720.
References
[1]: J. Crandall, D. Zinn, M. Byrd, E. Barr, and R. East. Conceptdoppler:
A weather tracker for internet censorship. In Proceedings of the 14th
ACM Conference on Computer and Communications Security, CCS
’07a, pages 352–365, New York, NY, USA, 2007. ACM. (Not cited.)
2013 conference on Internet measurement conference. ACM Request
Permissions, Oct. 2013. (Not cited.)
[3]: P. Gill, M. Crete-Nishihata, J. Dalek, S. Goldberg, A. Senft, and
G. Wiseman. Characterizing censorship of web content worldwide:
Another look at the opennet initiative data. http://www.cs.
stonybrook.edu/˜phillipa/papers/ONIAnaly.html,
2013. (Not cited.)
[4]: E. H and G. Karypis. Centroid-based document classiﬁcation:
Analysis & experimental results. Technical Report 00-017, University
of Minnesota, 2000. (Not cited.)
[5]: M. Marqui-Boire, J. Dalek, S. McKune, M. Carrieri,
M. Crete-Nishihata, R. Deibert, S. O. Khan, H. Noman,
J. Scott-Railton, and G. Wiseman. Planet blue coat: Mapping global
censorship and surveillance tools. Technical report, The Citizen Lab,
January 2013. (Not cited.)
[6]: H. Noman and J. C. York. West censoring east: The use of western
technologies by middle east censors, 2010-2011. Technical report,
The OpenNet Initiative, March 2011. (Not cited.)
[7]: X. Qi and B. D. Davison. Web page classiﬁcation: Features and
algorithms. ACM Comput. Surv., 41(2):12:1–12:31, Feb. 2009. (Not
cited.)
[8]: The Citizen Lab. Behind blue coat: Investigations of commercial
ﬁltering in syria and burma. Technical report, The Citizen Lab,
November 2011. (Not cited.)
[9]: The OpenNet Initiative. Burma (myanmar).
https://opennet.net/research/profiles/burma.
(Not cited.)
[10]: The OpenNet Initiative. The opennet initiative.
https://opennet.net. (Not cited.)
[11]: The Tor Project. Ooni: Open observatory of network interference.
https://ooni.torproject.org/. (Not cited.)
[12]: N. Weaver, C. Kreibich, M. Dam, and V. Paxson. Here be web proxies.
In M. Faloutsos and A. Kuzmanovic, editors, Passive and Active
Measurement, volume 8362 of Lecture Notes in Computer Science,
pages 183–192. Springer International Publishing, 2014. (Not cited.)
[2]: J. Dalek, B. Haselton, H. Noman, A. Senft, M. Crete-Nishihata, P. Gill,
and R. J. Deibert. A method for identifying and conﬁrming the use of
URL ﬁltering products for censorship. In IMC ’13: Proceedings of the
[13]: N. Weaver, R. Sommer, and V. Paxson. Detecting forged tcp reset
packets. In Presented as part of 16th Annual Network & Distributed
System Security Symposium, 2009. (Not cited.)
2007200820092010201120122013TimeRunsDNSHTTPVector17BlockingTypes2007200820092010201120122013TimeRunsTCPRSTDNSHTTPVector8BlockingTypes304