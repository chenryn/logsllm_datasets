Consider e.g.  a comparison “2< 3”: if one of the  terms  is 
affected  by an error (e.g.  “2 < 3000”) the logical outcome 
will  be  same,  so  this  error  will  simply  vanish. 
If  no 
timing constraints  are violated this error is harmless to the 
system. Alternatively,  the  fault  may have  hit the  idle task 
that executes whenever no other task needs the processor. 
This  helps  to  understand  previous  observations  [3]  that 
the  failure rate  grows with  increasing  system  load:  there 
is  simply  less  redundancy  available  to  tolerate  such 
events. 
the  use  of  duplicated  hardware. 
The remaining  1.7% of  the  faults produced  erroneous 
outputs  from  the  injected  Controller. In  the  FA  version, 
since no error detection is provided, truly  arbitrary  errors 
were  output.  In  the  FS  version,  as  expected,  all  these 
errors were  detected. The voter perceived  a disagreement 
on  the  outputs produced  by  both  controllers. These cases 
justify 
In  earlier 
experiments [IO],  we  used  software  replication  (re-execu- 
tion)  on  the  same  computer  and  observed  a  number  of 
cases  where  replication  leaked  erroneous  outputs.  This 
was  possible  because  the  copies  of  the  same  software 
running  in 
the  same  machine  were  not  completely 
fault-independent  and  could  affect  each  other.  In  this 
replicated 
independent 
computers  are  being  used,  no  common  mode  errors  can 
occur, so the hardware and  software replication  fulfill the 
goal  of  100% detection. This would  not  be  the  case  for 
software faults, but that is outside the scope of this study. 
A  closer look to  the  1.7% of  the  faults  that  produced 
erroneous  outputs  revealed  that  they  all  corrupted  the 
values  of  data  variables  used  in  the  computation  of  the 
setup,  however,  since 
two 
control  algorithm.  These  pure  data  errors  thus  deserved 
further attention from us. 
Controller behavior 
I  Detected error 
I 
Fail-Arbitrary 
(FA) 
I 
Fail-Silent 
(FS) 
I  82% 
482  I 
I 
Crash 
Correct output 
0% 
18% 
0 
106 
0% 
18% 
0 
106 
82% 
Undet wrong output 
0 
Table  2.  Behavior  of  the  Fail-Arbitrary and 
Fail-Silent  controllers  under  pure  data 
faults (% and no. of cases) 
482 
0% 
for 
It must be noticed that there are no crashes because  the 
faults’  targets  were  chosen  so  carefully.  Some  of  the 
faults did not  affect  the  system as would  be expected due 
to the intrinsic redundancy  described above. However, the 
most  puzzling  observation  came from the  behavior  of the 
pendulum 
the 
fail-arbitrary  version:  despite  the  output  of  errors  the 
pendulum  behaved  as if nothing occurred, and did not fall 
down a single time. 
the  wrong  outputs  produced  by 
These  observations  show  that  if  the  Fail-Silent  ap- 
proach  had  been  used,  the  overall  availability  would  be 
severely  reduced  for  this  fault  set  (82%)  unnecessarily, 
which  suggests  that  the  Fail-Arbitrary  model  is  more 
effective  than  the  Fail-Silent  model,  a  quite  surprising 
result that requires more detailed  scrutiny. 
We set out to  investigate  very  carefully what  happens 
after  an  error  is  generated. A  detailed  analysis  of  these 
errors  showed  that  the  reason  is  the  transient  nature  of 
such  errors. If  one fault  only  corrupts the  calculations of 
the output, and thus a wrong value is sent to the actuators, 
no  trace  of  this  error  remains  in  the  controller, and  then 
the following outputs are correct. 
We confirmed  this  hypothesis  by  injecting  a  series of 
150 faults specifically in the data variables that collect the 
controller  inputs  from  the  process  (rod  angle  and  cart 
position).  These  variables  are used  in  the  calculations of 
the  outputs  in  two  consecutive  control  cycles.  Every 
injected  fault  generated  an  error  that  was  output  to  the 
process, but  in  no case did the pendulum fell down. Only 
minor  disturbances  were  occasionally  observed  on  its 
movements.  These  pure  data  errors  were  all  detected  in 
the Fail-Silent  setup. 
319 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:07:01 UTC from IEEE Xplore.  Restrictions apply. 
Faults injected in data 
Faults injected in code 
Fail-Arbitrary 
Fail-Silent 
Fail-Arbitrary 
Fail-Silent 
Controller behavior 
I Detected error 
I 
(FA) 
(FS) 
I  99% 
396 
I 
(FA) 
(FS) 
I 23.1% 
Crash 
Correct output 
6,8% 
1,0% 
27 
4 
Undet. wrong output 
92,2% 
369 
0% 
1 Yo 
0% 
0 
4 
0 
49.1% 
29.4% 
21.5% 
293 
175 
128 
47.5% 
29.4% 
0% 
138 
283 
175 
0 
Table  3.  Behavior of  the  Fail-Arbitrary and  Fail-Silent controllers under  faults  with permanent 
effects (?/o  and no. of cases) 
4.1.3.  Permanently Induced Errors 
To  confirm  the  validity  of  the  observation  that  the 
reason  why  the  above  faults  had  no  impact  on  the 
pendulum  resulted  from  the  fact  that  the  ensuing  errors 
had  a lifetime  of only one or two control cycles, we have 
injected  two  series of  faults  that  had  a  permanent  effect 
throughout  the  following  control loops. One series of 596 
faults  affected  the  program code. The other series of 400 
faults  affected  permanent  data  structures,  such  as  the 
matrixes  used  in  the control  algorithm and  the calibration 
values  used  to convert the  input  values read, that  contain 
constant parameters of the control  algorithm (Table 3). 
The  disagreement  between  the  number  of  crashes  in 
the  two failure modes for the same set of injected  faults is 
explained  by  the  fact  that  after  the  activation  of  these 
faults,  the  system still managed  to produce wrong  outputs 
and later crashed. 
The  impact  of  faults  in  the  code  is  apparent.  These 
faults frequently crashed the system (49.1%). Whenever it 
didn’t  happen,  either  they  had  no  effect 
(29.4%)  or 
wrong  vales  were  produced  (21.5%) - in  1.6% of  the 
cases, the system crashed after producing wrong results. 
The figures  for data faults are also clear: almost every 
fault  injected  produces  a  wrong  output  (99%). The  sole 
exceptions  were  faults  that  affected  the  least  significant 
digits from  a double-precision floating-point  number that 
had  no  effect  in  the  results.  This  derives  naturally  from 
the  fact  that  affecting  the  constants used  to evaluate the 
control output  effectively  changes the algorithm. Some of 
the  faults  (6.8%) later  crashed the  system. Probably they 
were  data  pointers  that  generated  a  memory  protection 
fault, but we did not go into such detail. 
Most  interesting 
is  the  number  of  wrong  results 
produced that did not affect the pendulum’s behavior. 
The ratios  expressed  in  Table 4  are relative to  the  set 
of faults leading to a wrong output being produced, not to 
the  whole  set  of  injected  faults.  We  haven’t  considered 
either the faults that produced the  wrong outputs and  later 
crashed. 
These  figures  are  not  directly  measurable  against  the 
full set of errors since they  correspond to a biased  sample 
of  faults, those that  lead  to permanent errors. Even  so, a 
significant number of wrong outputs produced didn’t lead 
to a crash of the pendulum (88% of faults in data and 92% 
of faults in  code). During these experiments, we observed 
several  cases  where  the  amplitude of  the  movements  of 
the  pendulum  increased  regularly  until  collapse:  it  was 
clear  that  the  control  algorithm  was  affected  and  could 
not compensate adequately. 
I Process behavior 
I Collapse 
I 
I 88% 
I 
I  92% 
Faults injected 
Faults injected 
in data 
in code 
325 
118 
Tolerated 
10 
Table  4.  Effects of  wrong  outputs  on  the 
process (YO and no. of cases) 
12% 
8% 
44 
4.1.4.  Discussion 
The conclusion from the previous experiments is clear: 
failures affecting a single or a few iterations  of the control 
algorithm  were  meaningless  to  the  controlled  process. 
This  is  explained  by  the  fact  that  a  new  output  is 
produced every 30msec. Due to  the  mechanical  inertia of 
the  pendulum,  a  few  wrong  outputs  have  no  visible 
consequence.  Thus,  as  long as  the  following outputs  are 
correct  (the  faults  and  errors  are  transient)  the  wrong 
output 
in  practice  does  not  significantly  affect  the 
pendulum  behavior. Moreover, these  wrong outputs from 
the  controller can be arbitrarily  large:  since the  hardware 
output interface saturates (it has  12 bits resolution) errors 
from the controller are always bounded. 
This  observation  was  not  a  mere  accident:  it  was  a 
consistent  behavior  across  a  wide  range  of  faults  and 
environmental  circumstances.  Moreover,  this  observation 
agrees  with  common  sense in  the computer control field: 
“glitches”  are  absorbed  by  the  application’s  physical 
inertia (be it mechanical, chemical, thermal or other). 
With fail-silentness  achieved  by  structural  duplication, 
any  deviation,  even  if  minimal,  leads  to  an  immediate 
halt.  This  occurs  even  when  the  errors  would  have  been 
320 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:07:01 UTC from IEEE Xplore.  Restrictions apply. 
tolerated  by  the  controlled  system,  which,  as  we  have 
seen, is  the case for the  overwhelming majority  of errors. 
Still, it is  true  that a  few faults do lead  to the collapse of 
the  pendulum,  and  the  Fail-Silent  model  would  catch 
them  but  not  the  alternative  Fail-Arbitrary  model.  The 
cost  of  such cases may  be sufficiently high  as to  overrun 
the disadvantage of  lowered  availability  of the Fail-Silent 
model,  or  alternatively  to  justify  the  added  cost  of 
additional  redundancy,  for 
instance  another  pair  of 
controllers  that  would  take  over  control  when  the  first 
pair showed some disagreement. 
low-cost 
On  the  other  hand,  the  results  presented  thus  far  do 
indeed give good justification  to the approach followed in 
many 
industrial  controllers,  where  wrong 
outputs  can  happcn,  but  where  several  simple  measures 
(along  with  the  very  elfective  watchdog timers  for  crash 
detection) are used  to prevent  most  long lasting errors - 
program  code  and  fixed  parameters  would  be  typically 
stored  in  ROM  and  protected  by  sonic  kind  of  check 
code. Using  idle  time  the  system  would  continuously  try 
to  detect  any  corruption  that  might  happen.  Non-fixed 
parameters,  likc  c.g. calibration  data,  would  probably  be 
stored  in FLASH  RAM and be protected  by a check code. 
All 
fault 
avoidance during design (e.g. low board  temperature) and 
construction (e.g. highly reliable components). 
this  should  hc  complemented  by  careful 
[here  he 
Still,  can 
some  kind  of 
intermediate 
fault-model  that  could  be  more  forgiving  that Fail-Silent, 
thus leading to less service interruptions, but  still prevent 
in  our  case,  collapsing 
wrong  outputs 
the 
pendulum’? The Fail-Bounded model is a candidate. 