# Patroni: Simplifying High Availability for PostgreSQL

## Presenters
- **Alexander Kukushkin**
  - Database Engineer @ZalandoTech
  - Email: [PI:EMAIL]
- **Oleksii Kliukin**
  - Database Engineer @ZalandoTech
  - Email: [PI:EMAIL]
  - Twitter: [@hintbits]

## Zalando Overview
- Revenue: ~3 billion EUR
- Monthly visits: ~160 million
- Mobile traffic: 65%
- Databases: >170
- Tech employees: >1,300
- We are hiring!

## Radical Agility and Autonomous Teams
"Organizations which design systems... are constrained to produce designs which are copies of the communication structures of these organizations." — Conway’s Law

## Cloud Databases
- Rapid deployments
- Commodity hardware (cattle vs. pets)
- Standard configuration and automatic tuning

## Existing Automatic Failover Solutions
- **Promote a replica when the master is not responding:**
  - Potential split brain/multiple masters
- **Use one monitor node to make decisions:**
  - Single point of failure
  - Former master needs to be killed (STONITH)
- **Use multiple monitor nodes:**
  - Distributed consistency problem

### Distributed Consistency Problem
![Distributed Consistency](https://www.flickr.com/photos/kevandotorg)

## Patroni Approach: Use DCS
- **Distributed Configuration System (DCS):** Etcd, Zookeeper, or Consul
- **Built-in distributed consensus:** RAFT, Zab
- **Session/TTL to expire data:** e.g., master key
- **Key-value storage for cluster information:**
- **Atomic operations:** Compare-and-Swap (CAS)
- **Watches for important keys:**

### Leader Race Example
```plaintext
A: create("leader", "A", ttl=30) -> Success
B: create("leader", "B", ttl=30) -> Failure
```

### Key Structure
- `/service/cluster/`
  - `config`
  - `initialize`
  - `members/`
    - `dbnode1`
    - `dbnode2`
  - `leader`
  - `optime/`
    - `leader`
  - `failover`

### Keys That Never Expire
- **Initialize:**
  ```json
  {
    "key": "/service/testcluster/initialize",
    "value": "6303731710761975832"
  }
  ```
- **Leader/Optime:**
  ```json
  {
    "key": "/service/testcluster/optime/leader",
    "value": "67393608"
  }
  ```
- **Config:**
  ```json
  {
    "key": "/service/testcluster/config",
    "value": "{\"postgresql\":{\"parameters\":{\"synchronous_standby_names\":\"*\"}}}"
  }
  ```

### Keys with TTL
- **Leader:**
  ```json
  {
    "key": "/service/testcluster/leader",
    "value": "dbnode2",
    "ttl": 22
  }
  ```
- **Members:**
  ```json
  {
    "key": "/service/testcluster/members/dbnode2",
    "value": "{\"role\":\"master\",\"state\":\"running\",\"conn_url\":\"postgres://172.17.0.3:5432/postgres\",\"api_url\":\"http://172.17.0.3:8008/patroni\",\"xlog_location\":67393608}",
    "ttl": 22
  }
  ```

## Bootstrapping a New Cluster
- **Initialization race**
- **`initdb` by the winner of the initialization race**
- **Waiting for the leader key by the rest of the nodes**
- **Bootstrapping non-leader nodes (pg_basebackup)**

## Event Loop of a Running Cluster (Master)
- Update the leader key or demote if update fails
- Write the leader/optime (xlog position)
- Update the member key
- Add/delete replication slots for other members

## Event Loop of a Running Cluster (Replica)
- Update the member key
- Check that the cluster has a leader
  - Ensure `recovery.conf` points to the correct leader
  - Join the leader race if no leader is present
- Add/delete replication slots for cascading replicas

## Leader Race
- Check if the member is the healthiest
  - Evaluate its xlog position against all other members
- Try to acquire the leader lock
- Promote itself to become the master after acquiring the lock

## Live Demo

## Patroni Features
- Manual and Scheduled Failover
- Attach the old master with `pg_rewind`
- Customizable replica creation methods
- Dynamic configuration
- Pause (maintenance) mode
- `patronictl`

## Dynamic Configuration
- Ensure identical configuration of the following parameters on all members:
  - `ttl`, `loop_wait`, `retry_timeout`, `maximum_lag_on_failover`
  - `wal_level`, `hot_standby`
  - `max_connections`, `max_prepared_transactions`, `max_locks_per_transaction`, `max_worker_processes`, `track_commit_timestamp`, `wal_log_hints`
  - `wal_keep_segments`, `max_replication_slots`
- Change Patroni/PostgreSQL configuration dynamically
- Inform the user that PostgreSQL needs to be restarted (pending_restart flag)
- Store parameters in DCS and apply to all members

## Building HA PostgreSQL Based on Patroni
- **Client Traffic Routing:**
  - Patroni callbacks
  - `conf.d` + `haproxy`, `pgbouncer`
- **Backup and Recovery:**
  - WAL-E, Barman
- **Monitoring:**
  - Nagios, Zabbix, ZMON

## Spilo: Patroni + Docker + WAL-E + AWS/K8S

## When Should the Master Demote Itself?
- Balance between data loss risk and write availability
- Avoid too many master switches (adjust `retry_timeout`, `loop_wait`, `ttl`)
- Formula: `2 * retry_timeout + loop_wait < leader/optime - maximum_lag_on_failover`
  - `maximum_lag_on_failover` should be greater than the size of a WAL segment (16MB) for disaster recovery

## Attaching the Old Master Back as a Replica
- Diverged timelines after the former master crash
- Use `pg_rewind`
  - `use_pg_rewind`
  - `remove_data_directory_on_rewind_failure`

## Thank You!
- GitHub: [zalando/patroni](https://github.com/zalando/patroni)

## Useful Links
- **Spilo:** [zalando/spilo](https://github.com/zalando/spilo)
- **Confd:** [www.confd.io](http://www.confd.io)
- **Etcd:** [coreos/etcd](https://github.com/coreos/etcd)
- **RAFT:** [thesecretlivesofdata.com/raft/](http://thesecretlivesofdata.com/raft/)

## Rate Our Session!