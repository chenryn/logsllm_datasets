I have a Flask application running on a server, using multiple Gunicorn synchronous worker processes. The application currently logs to a file using `TimedRotatingFileHandler` within each worker. In retrospect, this approach seems unsafe, especially at high volume. 

Is there a standard way in Python to handle logging from multiple processes without resorting to writing my own socket-based logging server or a similar solution? How do other developers typically manage this?

We already use syslog to aggregate logs across servers to a central logging server, but I would ideally like to persist the logs on the application node first.

Thank you for your insights.

---

In response to our initial setup, we transitioned to sending logs to `stdout` and now rely on `supervisord` to aggregate and write these logs to a file. We also considered directly sending logs to `rsyslog`, but our current solution is working well for us.