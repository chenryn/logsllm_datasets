Trafﬁc volume. Figure 1 plots the distributions of down-
load, upload, and overall trafﬁc volume of user sessions. We
only consider TCP/UDP payload size when computing the
session size. Today’s mobile trafﬁc is dominated by down-
load, whose average size is about one order of magnitude
larger than that of upload. About 2.2% of user sessions carry
more than 1MB of downlink bytes, while only 0.4% upload
more than 1MB data in the user study trace. We notice a ma-
jor source of user-consumed trafﬁc is video, which accounts
for about half of download trafﬁc.
(a) Large upload
(b) Large download
Figure 2: Flow duration distributions.
(a) UL vs. DL
(b) Large upload
Figure 3: Flow rate distributions.
However, we observed that the fraction of upload bytes
is indeed non-trivial. Within the top 20% of user sessions
(in terms of their overall transferred bytes), the 25th, 50th,
and 75th percentiles of the fractions of upload trafﬁc are 9%,
20%, and 42%. Across all user sessions, the corresponding
fractions are higher, i.e., 19%, 50%, and 57%. The upload of
one user session even lasts for 11 minutes with 226 MB of
data transferred. We expect that in the future, the fraction of
upload trafﬁc will keep increasing because of the increas-
ingly popular user-generated trafﬁc. Compared to smart-
phones, wearable and IoT devices may incur even more up-
load trafﬁc, due to their ubiquitous sensing capabilities.
Flow duration. We use inter-packet arrival time to divide
a TCP ﬂow into multiple segments with a threshold of 1 sec-
ond. We also use the threshold of 1 second to eliminate idle
period of a TCP ﬂow. We then divide these segments into
upload bursts that only have TCP payload in uplink, and
download bursts with only TCP downlink payload, based
on the direction of transferred TCP payload. Given a TCP
ﬂow, we deﬁne its upload duration as the total duration of
all uplink bursts. Similarly, the download duration is the
total duration of all downlink bursts. Figure 2(a) plots the
upload durations for ﬂows with large upload trafﬁc volume
(100KB to 1MB, 1MB to 10MB, and at least 10MB). As ex-
pected, larger ﬂows tend to be longer in duration. For ﬂows
with large download trafﬁc volume, as shown in Figure 2(b),
their download duration exhibits distributions qualitatively
similar to those of upload duration, yet with the main differ-
ence being that the download duration is statistically shorter,
largely due to the higher downlink bandwidth compared to
the uplink bandwidth, as to be measured next.
Flow rate. We compute the upload (download) rate of
 0 0.25 0.5 0.75 1 0.001 0.01 0.1 1 10 100CDFSession size (MB)UploadDownloadUpload + Download 0 0.25 0.5 0.75 1 0.01 0.1 1 10 100 1000CDFUpload duration (s)0.1-1 MB1-10 MB> 10 MB 0 0.25 0.5 0.75 1 0.01 0.1 1 10 100 1000CDFDownload duration (s)0.1-1 MB1-10 MB> 10 MB 0 0.25 0.5 0.75 1 0.001 0.01 0.1 1 10 100CDFFlow rate (Mbps)UploadDownload 0 0.25 0.5 0.75 1 0.001 0.01 0.1 1 10CDFUpload rate (Mbps)0.1-1 MB1-10 MB> 10 MB305upload stream of the TCP ﬂow that p belongs to. Third, we
plot in Figure 4(a) the distributions of I(s) across all slots
grouped by their upload size. As shown, the upload RTT is
indeed highly “inﬂatable”, and larger upload tends to incur
much higher RTT. This resembles the “bufferbloat” effect
that is well studied for download [41, 22], and motivates us
to conduct a comprehensive investigation of bufferbloat for
cellular upload in §4.
Impact of Upload on Download Latency. We are also
interested in how upload impacts download latency, which
is quantiﬁed as follows. We ﬁrst generate one-second slots
using a similar way as employed in Figure 4(a), but this time
we only keep slots with both upload and download trafﬁc.
Then for every slot, we compute the average on-device de-
lay of download. Note that since our user study traces were
collected on client devices, we are only able to measure the
on-device component of the download RTT i.e., t1 shown in
Figure 6(b). Next, in Figure 4(b), we plot the distributions
of the on-device download delay grouped by the size of per-
slot upload size as is also done in Figure 4(a). We clearly
observe that concurrent upload affects the on-device down-
load delay because the ACK stream (for download) and the
data stream (for upload) share several on-device buffers. We
will conduct an in-depth investigation on this in §4 and §5.
Summary. Overall, we found that although the majority
of today’s smartphone trafﬁc remains to be download, the
upload trafﬁc can still be large. In particular, the median up-
load speed is 2.2Mbps for 10MB+ ﬂows and can achieve up
to 12.8Mbps in today’s LTE networks, enabling many appli-
cations to upload rich user-generated trafﬁc. We also found
that large upload tends to have higher RTT, and upload trafﬁc
may also increase the RTT experienced by concurrent down-
load. Furthermore, it is quite common that multiple TCP
ﬂows are transferring data concurrently on a mobile device,
leading to complex interactions possibly among uplink and
downlink ﬂows to be investigated soon.
4. ON-DEVICE QUEUING DELAY OF
UPLOAD TRAFFIC
We conduct a thorough analysis of the latency character-
istics for cellular upload trafﬁc. We found a signiﬁcant frac-
tion of the latency happens on the end-host device instead
of in the network (§4.1). In particular, in §4.2, we discover
the root cause of large Qdisc and ﬁrmware buffers playing
major roles in causing the excessive on-device delay, whose
prevalence across devices and carriers are shown in §4.3. We
also found in §4.4 that on-device queuing may signiﬁcantly
impact accurate uplink throughput estimation.
4.1 Overall Delay Characterization
When a mobile device is uploading data, its packets will
traverse various buffers in the protocol stack, as illustrated
in Figure 6: TCP buffers, link-layer buffers (Linux queuing
discipline), radio ﬁrmware buffers. Each buffer may incur
queuing delay. As a result, we may get different RTT values
if we conduct measurements at different layers. In this work,
we focus on three RTT measurements deﬁned bellow.
(a) RTT increase of upload (b) On-device delay of
download
Figure 4: Delay distributions.
a TCP ﬂow by dividing the total bytes of all upload (down-
load) bursts by its upload (download) duration that is deﬁned
above. We only consider ﬂows whose upload/download du-
ration are longer than a threshold, which is empirically cho-
sen to be 3 seconds, as the “rate” of a very short ﬂow is not
very meaningful. Figure 3(a) compares upload and down-
load rates for the user study trace. Statistically, download
is faster than upload, largely due to their differences in the
underlying channel rates of the LTE radio access network.
On the other hand, Figure 3(b) indicates larger upload ﬂows
(larger than 1MB) tend to have higher rates.
In the user
study dataset, for ﬂows that upload 1 to 10 MB data, their
25%, 50%, and 75% percentiles of upload rates are about
1.4Mbps, 2.4Mbps, and 3.8Mbps, which are comparable or
even higher than those of today’s many residential broad-
band networks. For 10MB+ ﬂows, the maximum achieved
throughput are 12.8Mbps for the user study traces. Such
high upload speed provides the infrastructural support for
user-generated trafﬁc.
Flow concurrency. We explore the concurrency of TCP
ﬂows per user. The result is shown in Figure 5. For every
one-second slot in each user session, we count the number
of TCP ﬂows that are transferring data. For the user study
trace, for 28.2% of the time (i.e., 28.2% of the one-second
slots across all user sessions), there exist at least two TCP
connections that perform either upload or download. The
results indicate that concurrent TCP transfers are quite com-
mon on today’s mobile devices. Motivated by this, we study
the interplay between uplink and downlink trafﬁc, a previ-
ously under-explored type of concurrency, in §5.
RTT Dynamics. We next study the RTT dynamics of cel-
lular upload from the user study trace. The RTT is mea-
sured by timing the timestamp difference between each up-
link TCP data packet and its corresponding ACK packet cap-
tured by tcpdump. We then study the ﬂuctuation of upload
RTT using the following methodology. First, we split each
user session into one-second slots and discard slots without
uplink trafﬁc. We also discard slots whose download trafﬁc
volume is non-trivial (using 5KB as a threshold). The pur-
pose is to eliminate the impact of concurrent download on
upload. Second, for each one-second slot s, we compute its
RTT increase I(s) = meanp{RTT(p) − MinRTT(p.f low)}
over all data packets {p} within the slot. RTT(p) is the mea-
sured RTT, and MinRTT(p.f low) is the minimum RTT of
 0 0.25 0.5 0.75 1 0.01 0.1 1CDFRTT increase (s)UL  100 KB 0.8 0.85 0.9 0.95 1 0.01 0.1 1CDFOn-device Delay (s)UL  100 KB306Figure 5: TCP concurrency distribution.
Figure 6: On-device bufferbloat (in thick blue).
calculated by subtracting RT TF measured from tcpdump
trace by the estimated queuing delay. The results of two
representative experiments with different uplink bandwidth
(2Mbps and 8Mbps, which are 50% and 98% percentiles of
upload rates measured from Figure 3(b), respectively) are
shown in Figure 7. Note the Y axes are in log scale.
As shown in both plots of Figure 7, at the beginning
of the TCP upload, RT TF increases steadily, and quickly
outweighs RT TB. When the uplink bandwidth is 2Mbps
(8Mbps), after 2MB (4MB) of data has been sent out, RT TF
is increased to around 1.3s (330ms), which is much larger
than RT TB maintaining stably at around 50ms. Meanwhile,
RT TQ starts to exceed RT TF , and becomes twice as large
as RT TF after another 2MB of data is uploaded. The abso-
lute difference between RT TQ and RT TF is as high as 3s
and 680ms in Figure 7(a) and 7(b), respectively.
Overall, we found that for cellular upload, surprisingly,
the RTT observed by mobile devices’ TCP stack (RT TQ)
can be signiﬁcantly larger than the RTT perceived by
tcpdump (RT TF ), which further far exceeds the pure net-
work RTT (RT TB). Depending on the uplink bandwidth,
RT TQ and RT TF can be 22x∼100x and 6x∼24x of RT TB,
respectively, during the steady phase of TCP bulk upload.
We call such a phenomenon on-device bufferbloat since it
is caused by excessive queuing delay on the mobile de-
vice, as opposed to the network, which is regarded as the
main source of excessive queuing for cellular downlink traf-
ﬁc [22]. As we will demonstrate later, on-device bufferbloat
has deep implications on, for example, uplink bandwidth es-
timation, multi-tasking performance, uplink scheduling al-
gorithms, and on-device buffer management.
4.2 Root Cause of On-device Queuing
We now explore the root cause of the excessive on-device
queuing delay. We begin with an overview of how outgo-
ing TCP packets on the sending path traverse the Linux ker-
nel (also used by Android) and radio chipset. As shown
in Figure 8, an application invokes the send() system call
at time tsA and the data is put into TCP buffer by kernel
through TCP sockets at time tsT . Note tsT may be later
than tsA if the socket is blocked. In Linux, a packet is stored
(a) Uplink BW 2Mbps
(b) Uplink BW 8Mbps
Figure 7: Overall latency characterization for a single
TCP upload ﬂow under two network conditions.
• RT TB consists of only the delay a packet experiencing
in the network. It does not include any delay caused by on-
device buffer (B stands for “base”).
• RT TF includes RT TB and the delay incurred by the
buffer in the radio ﬁrmware, which usually resides on the
cellular chipset of a mobile device (F stands for “ﬁrmware”).
• RT TQ includes RT TF , plus the delay incurred by the
queuing discipline (Qdisc), the link-layer buffer in the main
memory managed by the OS (Q stands for “Qdisc”).
Similarly, we can also deﬁne RTTs measured at higher
layers (TCP, application). Nevertheless, RT TB, RT TF , and
RT TQ are our particular interests, because their correspond-
ing network path or buffers are shared by multiple applica-
tions. As we will show in §5, if upload and delay sensitive
trafﬁc coexist, the former may severely interfere with the
latter due to the shared nature of lower-layer buffers. In con-
trast, the higher-layer buffers are usually not shared.
We now measure RT TB, RT TF , and RT TQ by perform-
ing bulk data upload over TCP on Samsung Galaxy S3, us-
ing Carrier 1’s LTE network. RT TQ and RT TF can be di-
rectly measured by tcp_probe [8] and tcpdump, respec-
tively. RT TB can only be indirectly estimated. For a given
upload trace, we keep track of the buffer occupancy and en-
queue/dequeue rates of the ﬁrmware buffer. We then use
them to estimate the ﬁrmware queuing delay3. RT TB is then
3The detailed methodology of ﬁrmware buffer occupancy
estimation is described in §6.2. Since the radio ﬁrmware we
use only reports ﬁrmware buffer occupancy of up to 150KB,
we validate our methodology when the occupancy is smaller
than 150KB and then use it to infer the buffer occupancy at
any time in the trace.
 0 0.25 0.5 0.75 1 0 2 4 6 8 10CDFTCP Concurrency (# of conns)TCPAppli-cationQdiscRadio FirmwareUE/NetworkBoundaryServerRTTBRTTFRTTQTFTQTTTADataACK(a) Bulk uploadTCPUE/NetworkBoundaryDataACK(b) Download when another bulk upload  flow exists in backgroundServertsAtsTtsQtsFtsNt1t2 1 0.04 0.4 4 0 2 4 6 8 10RTT (s) (log scale)Data sent (MB)RTTQRTTFRTTB 0.6 1 0.04 0.4 4 0 2 4 6 8 10RTT (s) (log scale)Data sent (MB)RTTQRTTFRTTB307Figure 9: On-device queuing delay on diverse devices
and cellular carriers.
a strong correlation (around 0.86) between the queuing delay
and the amount of trafﬁc in Qdisc.
Firmware Queuing. In LTE uplink, the data to be trans-
mitted from applications is processed and queued in the RLC
(Radio Link Control) buffer4, which is physically located in
the cellular chipset ﬁrmware. The amount of data available
for transmission on the UE (i.e., the ﬁrmware buffer occu-
pancy) is provided to the eNodeB through control messages
called Buffer Status Reports (BSR). BSR can report 64 lev-
els of buffer size with each level representing a buffer size
range [9]. The highest level of BSR is 150KB or above.
Based on BSR from all UEs, the eNodeB uplink scheduler
assigns network resources to each UE for uplink transmis-
sion in a centralized manner. The eNodeB sends control
messages called Scheduling Grants to inform a UE of the
scheduling decision. A UE is only allowed to transmit on
the physical uplink shared channel (PUSCH) with a valid
grant.