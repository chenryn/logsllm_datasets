### Persuasion Control Treatment and Defenses Against Cursor-Spoofing Attacks

**Persuasion Control Treatment (Group 1)**
In the persuasion control treatment, participants attempted to skip the animation. Assuming a similar percentage of participants tried to skip the advertisement during the attack, 84% of those who attempted to skip the ad fell for the attack (43% of 51%).

**Defenses Against Cursor-Spoofing Attacks**

**Disallowing Cursor Customization:**
A straightforward defense against cursor-spoofing attacks is to disallow cursor customization. This prevents the real cursor from being hidden, although the attack page can still draw a second, fake cursor. Some users might focus on the wrong cursor and fall for the attack. In Group 4, where cursor customization was disallowed, 12 out of 72 (16%) participants still fell for the attack. This result, combined with the attacker's ability to draw multiple fake cursors and emphasize one that is not the real cursor, suggests that this defense has limited effectiveness. However, it does reduce the attack success rate from 43% in Group 3 (without the defense) to 16% in Group 4 (with the defense). The difference between these two groups was statistically significant (p=0.0009).

**Freezing Defense:**
In Groups 5a-c, we deployed the freezing defense described in Section 5.1.2. When this defense triggers, all movement outside the protected region, including the video and fake cursor, is halted. This helps break the illusion of the fake cursor and draws the user’s attention to the part of the screen where there is still movement—containing the real cursor. The freeze is initiated when the cursor is within M pixels of the webcam dialog, for M values of 0, 10, and 20 pixels. At M=20px (Group 5c), the attack success rate dropped to 4% (tricking only 3 of 72 participants). This was significantly lower than the 16% success rate in Group 4 (p=0.0311).

**Augmenting Freezing Defense:**
Given the efficacy of the large-margin (20px) freezing defense in Group 5c, and the low rate of successful attacks, our sample size was too small to detect further benefits from muting the speaker or using a lightbox. Augmenting the freezing defense to mute the computer’s speaker (Group 6) resulted in an attack success rate of 2 of 70 (2%) participants. Adding a lightbox to grey over the frozen region (Groups 7 and 8) also resulted in attack success rates of 2-4%. The lightbox effect, while somewhat jarring, did not provide a measurably superior defense in our experiments.

### Double-Click Attacks

**Experiment Overview:**
In our second experiment, we tested the efficacy of the double-click timing attack (described in Section 4.2 and shown in Figure 2) and the defenses proposed in Section 5.2. The attack aims to trick the user into clicking the “Allow Access” button of a Google OAuth window by moving it under the user’s cursor after the first click of a double-click on a decoy button. If the “Allow” button is not clicked within two seconds, the attack times out without success.

**Attack Results:**
Of the 90 participants exposed to the simulated attack without any defense, the attack was successful against 43 (47%). Many users who were not successfully attacked escaped because the popup was not displayed quickly enough. The popup took more than 500ms to be displayed for 31 out of 46 users who timed out, with an average loading time of 833ms. Pre-loading the OAuth dialog in a pop-under window could improve the attack's efficacy.

**Defenses:**
Two groups of participants were protected by simulating the UI delay defense, treating clicks on the “Allow” button as invalid until it has been fully visible for a threshold of TA ms. We assigned two choices for TA: 250ms (Group 2a) and 500ms (Group 2b). The 250ms delay was effective, but 2 out of 91 (2%) participants in Group 2a still fell for the attack. The difference in attack success rates between the attack treatment (Group 1) and the UI delay defense treatment for TA=250ms (Group 2a) was statistically significant (p<0.0001).

### Whack-a-Mole Attacks

**Experiment Overview:**
We assigned two treatment groups to a simulated whack-a-mole attack that did not employ clickjacking. Group 1a was eventually shown a Like button, while Group 1b was shown the “allow” button in the Flash webcam access dialog. Participants first had to click on various buttons, many designed to habituate them into ignoring the context of the buttons. On the attack iteration, the Like button appeared as the next target object in the game.

**Attack Results:**
The Like button version of Group 1a succeeded on 83 of 84 (98%) participants, and the “allow” button of Group 1b succeeded on 69 of 71 (97%) participants. The differences between these two groups were not statistically significant.

**Timing Attack:**
In the whack-a-mole attack with timing (Group 2), the Like button was switched to cover one of the game buttons at a time chosen to anticipate the user’s click. This attack fooled 80 of 84 (95%) participants. Combining the timing technique with cursor spoofing (Group 3) resulted in 83 of 84 (98%) participants falling for the attack.

**Defenses:**
In Groups 4a-c, we combined the proposed defenses, including pointer re-entry, appearance delay of TA=500ms, and display freezing with padding area sizes of M=0px, 10px, and 20px. Using no padding area (M=0px), the attack succeeded on the first mouseover for 42 of 77 (54%) participants in Group 4a. Increasing the padding area to M=10px (Group 4b) reduced the first-mouseover success rate to 27 of 78 (34%).

This structured approach provides a clear and professional overview of the experiments, results, and defenses, making the text more coherent and easier to understand.