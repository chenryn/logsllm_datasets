title:An improved algorithm for tor circuit scheduling
author:Can Tang and
Ian Goldberg
An Improved Algorithm for Tor Circuit Scheduling
Can Tang
Ian Goldberg
Cheriton School of Computer Science
Cheriton School of Computer Science
University of Waterloo
Waterloo, ON, Canada
PI:EMAIL
University of Waterloo
Waterloo, ON, Canada
PI:EMAIL
ABSTRACT
Tor is a popular anonymity-preserving network, consisting
of routers run by volunteers all around the world. It pro-
tects Internet users’ privacy by relaying their network traﬃc
through a series of routers, thus concealing the linkage be-
tween the sender and the recipient. Despite the advantage of
Tor’s anonymizing capabilities, it also brings extra latency,
which discourages more users from joining the network.
One of the factors that causes the latency lies in Tor’s cir-
cuit scheduling algorithm, which allows busy circuits (those
with continuous traﬃc) to crowd out bursty circuits (those
with short bursts of traﬃc). In this work, we propose and
implement a more advanced scheduling algorithm which treats
circuits diﬀerently, based on their recent activity.
In this
way, bursty circuits such as those used for web browsing can
gain higher priority over busy ones such as used for bulk
transfer; the performance for most activities over Tor is im-
proved, while minimal overhead is incurred. Our algorithm
has been incorporated into the latest build of Tor.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: General—
Data communications; C.2.1 [Computer-Communication
Networks]: Network Architecture and Design; C.4 [Com-
puter Systems Organization]: Performance of Systems;
K.4.1 [Computers and Society]: Public Policy Issues—
Privacy
General Terms
Measurement, Performance, Security
Keywords
Tor, latency, onion routing
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’10, October 4–8, 2010, Chicago, Illinois, USA.
Copyright 2010 ACM 978-1-4503-0244-9/10/10 ...$10.00.
1.
INTRODUCTION
Tor [3] is a distributed anonymizing network that provides
privacy for its users. The network is formed by volunteers
all around the world running Onion Routers (ORs). The
ORs publish their related information, such as bandwidth
and exit policies, to a set of centralized servers called direc-
tory authorities. These directory authorities will negotiate
with each other and reach a consensus about the ORs. An
end user runs an Onion Proxy (OP) locally to tunnel appli-
cation requests through Tor; the OP downloads the consen-
sus from the directory authorities, randomly picks a set of
ORs, choosing them weighted by their reported bandwidths,
and builds circuits through them. Then application traﬃc
is relayed through the circuit, using layered encryption. In
this way, a single OR only sees its previous OR/OP and
next OR/OP, but not the actual sender-recipient relation-
ship, and the privacy of the user at the transport level is
preserved.
The anonymity provided by Tor relies on the size of the
anonymity set. Currently, there are around 1500 ORs [1],
and an estimated quarter million Tor users. Tor’s rapid
expansion period ended by the end of 2007 (in terms of the
number of ORs) [10]. After that, Tor entered a relatively
stable stage: the number of ORs joining the Tor network
roughly equaled the number leaving it. One of the obstacles
for Tor’s further expansion is its performance issues.
There are many causes for Tor’s performance issues. Din-
gledine and Murdoch [4] identiﬁed several main reasons that
Tor is slow. One of the causes is that bursty circuits do not
co-exist with busy circuits very well. When multiple cir-
cuits are sharing a single connection between two ORs, busy
circuits such as those used for bulk transfer will greatly de-
grade the performance of the bursty ones, such as those used
for web browsing. Although this eﬀect is inevitable due to
the limited bandwidth resources, we want to allocate the re-
sources more eﬃciently; that is, to give higher priority to the
circuits with low throughput or short bursts of traﬃc, and
make them faster. This is reasonable from the application
point of view as well: circuits for web browsing or instant
messaging are usually sensitive to delays, while those for
bulk transfer are usually not.
We see this as a general observation for anonymity net-
work design: diﬀerent data streams attain unequal beneﬁt
from properties of the network such as latency and through-
put. Although directly observing the data streams is gen-
erally not possible in such networks, any inferences that
can nonetheless be made about their utility functions can
yield improved eﬃciencies.
It is of course important to
329make these inferences only from already-exposed informa-
tion; re-engineering an anonymity network to leak more in-
formation about its contents can easily lead to increased
exposure, while merely optimizing behaviour based on in-
formation already in hand provides increased, although not
perfect, safety.
Our approach is to calculate the exponentially weighted
moving average (EWMA) for the number of cells sent on
each circuit. When selecting the circuit to process, we al-
ways pick one with the lowest EWMA value, and ﬂush cells
from that circuit. Newly created circuits and bursty cir-
cuits will usually have a low EWMA value, and so they will
be prioritized. Making the observation that circuits under
construction and bursty interactive circuits gain the most
from improved latency allowed us to eﬀect a noticeable im-
provement for those circuits that would see the most beneﬁt
from it, while making only a small change to Tor’s existing
behaviour.
In Section 2, we introduce the incentives and rationality
of our proposal, brieﬂy demonstrate the mechanism of Tor
circuits, and propose our improvement.
In Section 3, we
show the results of some experiments under diﬀerent sce-
narios, with analysis of the results and the overhead. Sec-
tion 4 examines the eﬀect of diﬀerent parameter values on
the performance of our system, and Section 5 explores the
performance improvements on Tor’s hidden services. Sec-
tion 6 relates the compatibility of our algorithm with the
existing Tor network. Section 7 provides some related work
on improving Tor’s performance. We discuss possible future
work in Section 8, and conclude in Section 9.
2. PRIORITIZING INTERACTIVE CIRCUITS
In this section, we propose our improvement on Tor’s cir-
cuit scheduling algorithm. First, we state the incentives for
our proposal; next, we describe the process by which Tor
ORs select which data is to be transmitted. Finally, we
describe our improvement over the existing system.
2.1 Incentives
Most users of Tor experience its performance issues:
it
incurs much higher latency than direct connections. Al-
though the multi-hop architecture inevitably brings extra
latency, the experienced latency is higher than this eﬀect
can explain.
One factor for Tor’s bad performance is its limited capac-
ity: the ORs are run by volunteers, usually on consumer
computers, with limited bandwidth. Within this limited
capacity, there are abuse issues observed in the Tor net-
work. According to McCoy et al. [12], a small number of
BitTorrent connections consume a very high proportion of
Tor bandwidth. These connections make Tor unusable for
many potential users.
Tor provides anonymity by mixing a speciﬁc user into a
crowd of users; therefore, the degree of anonymity Tor pro-
vides depends on the number of users. Higher latency will
discourage more users from joining the network. Hence, the
performance issues do not only aﬀect user experience, but
also degrade Tor’s security properties.
The uses of Tor can be divided into interactive streams
and non-interactive streams.
Interactive streams include
web browsing, instant messaging, SSH, and telnet, while
non-interactive streams include bulk ﬁle transfer such as
FTP and BitTorrent. Interactive streams are usually delay-
sensitive: users click on a link to a webpage and wait, ex-
pecting it to appear on the screen in seconds, while non-
interactive streams are not: BitTorrent users expect the ﬁle
download to be completed in hours or even days; they can
tolerate higher delays. We aim to improve Tor’s performance
by making ORs process interactive streams ﬁrst. This will
give interactive users (the majority of Tor users) a better ex-
perience, and will make little diﬀerence for non-interactive
users.
We note that in choosing to prioritize web browsing traﬃc
over BitTorrent, we are not making a policy or value judge-
ment; rather, we are observing that it is the web brows-
ing traﬃc that would gain the most from improved latency,
while the utility of decreasing BitTorrent latency would be
much smaller.
2.2 How Tor’s Circuits Work
As described in Section 1, a client runs an OP locally. The
OP randomly selects several ORs to form a path, then builds
a Tor circuit through this path. Each circuit is used by only
one client (OP). Between each pair of ORs on the path, a Tor
connection is established. If multiple circuits use the same
two ORs in sequence, they will share a single connection
between the two ORs. Based on the current number of users
and ORs, and the ORs’ capacities, we can infer that usually
connections will be shared by multiple circuits, especially
for the connections between high-bandwidth ORs. That is,
each OR will have simultaneous connections to a number of
other ORs (but only one connection to any given OR), and
each connection will transport data for a number of circuits.
All Tor traﬃc is relayed in ﬁxed-size (512-byte) cells. A
cell consists of a header ﬁeld and a payload. The header
contains metadata about the cell, such as the circuit iden-
tiﬁer. When a cell arrives at an OR, the OR decrypts the
cell, extracts the information necessary from the header, and
then pushes the cell into the output queue for its circuit (the
circuit queue). The time cost of this process is negligible [18]
as a fraction of the overall time for a cell to be processed by
an OR. Circuits with non-empty circuit queues are called
active circuits.
Each connection has an output buﬀer; data written to that
buﬀer will be transmitted to the next OR in FIFO order. As
multiple circuits generally share a single connection, the cells
in the circuit queues must be multiplexed into the output
buﬀer.
When there is room in the output buﬀer, the OR will
select an active circuit, and move some cells from its circuit
queue to the output buﬀer. If all of the cells are moved, the
circuit is marked inactive.
The contribution of this work is to change how Tor de-
cides from which active circuit to select cells. The previous
algorithm was simply to select active circuits in round-robin
fashion. We show that by making a more judicious selec-
tion, the performance of Tor for interactive circuits can be
notably improved, while minimally aﬀecting performance for
circuits performing bulk data transfer, which tend to be de-
lay insensitive in any event.
In order to prioritize interactive circuits, we need to de-
cide, for example, which circuits are using HTTP, and which
circuits are using BitTorrent. Unfortunately, we cannot de-
termine the application protocol by looking directly at the
content of the cells, since all of the cells are encrypted ex-
cept for at the exit OR. On the other hand, circuits using
330Figure 1: The Tor circuit structure for Experiment
1
HTTP may also perform bulk transfer, and we want to de-
prioritize them as well. Thus, the amount of traﬃc sent
recently should be an appropriate criterion on which to base
our scheduling decision. We should mention that we do not
want to block BitTorrent or similar applications by blocking
the port number at exit ORs, since Tor is intended to be
application neutral; additionally, port number blocking can
be easily circumvented by those ﬁle sharing applications.
2.3 Circuit Selection based on EWMA
We want to have a metric for “how many cells a circuit has
sent recently”, and base the circuit selection decision on this
metric. The metric needs to represent an average value over
a period of time of the activity for a circuit, and also needs
to decay over time, since we do not want the activity from
long ago to have a large impact on the current decision for
a circuit. EWMA seems to be a good choice for this metric.
First, we assign each circuit a cell count value, represent-
ing the average number of cells sent recently. Every time we
wish to ﬂush some cells to the connection’s output buﬀer, we
calculate the decayed cell count value for each circuit, based
on the EWMA equation that supports irregularly-spaced ob-
servations:
At+∆t = At · 0.5
∆t
H
where At+∆t is the new cell count value, At is the old cell
count value, ∆t is the elapsed time since the last observation
and H is the “half life” parameter; that is, H determines the
interval after which the previous average is reduced by half.
After the calculation, the OR picks the circuit with the
smallest cell count value, and ﬂushes that circuit’s cell queue
to the output buﬀer of the connection; the cell count value
is updated correspondingly:
A′
t+∆t = At+∆t + Ct,t+∆t
where Ct,t+∆t is the number of cells sent in the interval
(t, t + ∆t].
The value of H, as well as a switch for turning our whole
algorithm on or oﬀ, can be set in the Tor conﬁguration ﬁle.
As the equation shows, circuits with low or bursty traﬃc
will have low cell counts. These circuits are likely to be those
which are still in their creation phase, as well as circuits
for web browsing or instant messaging, which are exactly
the circuits we want to prioritize. For each OR, cells in
interactive circuits will wait for less time in the circuit queue
than without prioritization. The performance of interactive
circuits, on the whole, will be improved. As we show later,
the performance of circuits which are deprioritized suﬀers
only minimally.
e
l
i
t
n
a
u
Q
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
Prioritized
Unprioritized
 0.5
 1
 1.5
 2
 2.5
 3
 3.5
 4
 4.5
Seconds
Figure 2: CDF for time cost of downloading a small
ﬁle for unprioritized and prioritized Tor
3. EXPERIMENTS AND RESULTS
3.1 End-to-End Timing Analysis
The experiments in this section were performed on Plan-
etLab. PlanetLab [17] is a research network consisting of
nodes distributed globally, much like Tor. We selected a set
of ﬁve nodes from PlanetLab, and ran a private Tor network
on them. A typical Tor circuit consists of three ORs. The
OR directly connecting to an OP, the OR directly connect-
ing to the server, and the OR in the middle are called the
entry OR, exit OR, and middle OR, respectively. In our ex-
periment, we picked two nodes as directory authorities and
three nodes as ORs; we ran our modiﬁed Tor on the three
ORs.
Experiment 1 was designed to measure the time cost of
downloading a small ﬁle (simulating web browsing), while
there are competing bulk transfer circuits. According to
[23], the average web page size (including HTML, CSS and
images) grew from 93KB to over 312KB, from 2003 to 2008.
We picked 300KB as the ﬁle size we use for our experiment.
The ﬁle is hosted on the same machine as the exit OR, in
order to eliminate the variance introduced by the connection
between the web server and the exit OR.
We conﬁgured three local clients, who select the same
route, as shown in Figure 1. Two clients were performing
bulk transfer. We tried to download the 300KB ﬁle using
the other client, and recorded the elapsed time. We used
H = 66 for the algorithm, which means that after every
66 seconds, the old cell count will decay by a factor of 0.5.
This corresponds to our initial estimate that a decay of 10%
over 10 seconds would be appropriate. We performed 100
downloads for both unprioritized Tor (the stock Tor) and
our prioritized version of Tor. The cumulative distribution
function (CDF) of the results is shown in Figure 2.
In Experiment 1, we observed an average of 32% decrease
in the time to download a small ﬁle while there are simul-
taneous competing bulk transfers — the median time de-
creased from 2.60 seconds to 1.75 seconds.
During the experiment, when switching between unprior-
itized and prioritized Tor, we switched on the algorithm for
all three ORs at the same time. But does prioritizing one
of the ORs contribute the most to the eﬀect, or do all three
of them contribute equally to the improvement? In order
331e
l
i
t
n