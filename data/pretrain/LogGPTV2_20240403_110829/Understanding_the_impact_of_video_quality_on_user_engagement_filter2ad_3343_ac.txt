mirroring the same effect. Identifying and uncovering these hidden
relationships, however, is tedious. Second, content providers may
want to know the top k metrics that they should to optimize to im-
prove user engagement. Correlation-based analysis cannot answer
such questions.
1
i P [Y = yi] log
H(Y ) = (cid:80)
other random variable X is deﬁned as H(Y |X) = (cid:80)
To address the above challenges, we augment the correlation
analysis using the notion of information gain [32], which is based
on the concept of entropy. The entropy of random variable Y is
P [Y =yi] , where P [Y = yi] is the
probability that Y = yi. The conditional entropy of Y given an-
j P [X =
Xj]H(Y |X = xj) and the information gain is then H(Y ) −
H(Y |X), and the relative information gain is H(Y )−H(Y |X)
. Intu-
itively, this metric quantiﬁes how our knowledge of X reduces the
uncertainty in Y .
H(Y )
Speciﬁcally, we want to quantify what a quality metric informs
us about the engagement; e.g., what does knowing the AvgBitrate
or BufRatio tell us about the play time distribution? As with the
correlation, we bin the data into discrete bins with the same bin
speciﬁcations. For the play time, we choose different bin sizes de-
pending on the duration of the content. From this binned data, we
compute H(Y |X1, . . . , XN ), where Y is the discretized play time
2This happens with Pearson and Spearman correlation metrics also.
and X1, . . . , XN are quality metrics. From this estimate, we cal-
culate the relative information gain.
Note that these two classes of analysis techniques are comple-
mentary. Correlation provides a ﬁrst-order summary of monotone
relationships between engagement and quality. The information
gain can corroborate the correlation or augment it when the re-
lationship is not monotone. Further, it provides a more in-depth
understanding of the interaction between the quality metrics by ex-
tending to the multivariate case.
3.4 Regression
Rank correlation and information gain are largely qualitative anal-
yses. It is also useful to understand the quantitative impact of a
quality metric on user engagement. Speciﬁcally, we want to an-
swer questions of the form: What is the expected improvement in
the engagement if we optimize a speciﬁc quality metric by a given
amount?
For quantitative analysis, we rely on regression. However, as the
visualizations show, the relationships between the quality metrics
and the engagement are not always obvious and several of the met-
rics have intrinsic dependencies. Thus, directly applying regres-
sion techniques with complex non-linear parameters could lead to
models that lack a physically meaningful interpretation. While our
ultimate goal is to extract the relative quantitative impact of the
different metrics, doing so rigorously is outside the scope of this
paper.
As a simpler alternative, we use linear regression based curve
ﬁtting to quantify the impact of speciﬁc ranges of the most critical
quality metric. However, we do so only after visually conﬁrming
that the relationship is approximately linear over the range of inter-
est. This allows us to employ simple linear data ﬁtting models that
are also easy to interpret.
4. VIEW LEVEL ENGAGEMENT
The engagement metric of interest at the view level is PlayTime.
We begin with long VoD content, then proceed to live and short
VoD content. In each case, we start with the basic correlation based
analysis and augment it with information gain based analysis. Note
that we compute the binned correlation and information gain coefﬁ-
cients on a per-video-object basis. Then we look at the distribution
of the coefﬁcients across all video objects. Having identiﬁed the
most critical metric(s), we quantify the impact of improving this
quality using a linear regression model over a speciﬁc range of the
quality metric.
In summary, we ﬁnd that BufRatio consistently has the highest
impact on user engagement among all quality metrics. For exam-
ple, for a 90 minutes live event, an increase of BufRatio by 1%
can decrease PlayTime by over 3 minutes. Interestingly, the rela-
tive impact of the other metrics depend on the content type. For
live video, RateBuf is slightly more negatively correlated with
PlayTime as compared to long VoD; because the player buffer
 0 5 10 15 20 25 30 35 40 45 50 0 10 20 30 40 50 60 70 80 90 100Play Time (min)Buffering Ratio (%) 0 5 10 15 20 25 30 35 40 45 50 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2Play Time (min)Rate of Buffering Events (per min) 5 10 15 20 25 30 35 40 45 50 200 400 600 800 1000 1200 1400 1600 1800Play Time (min)Average Bitrate (kbps) 0 5 10 15 20 25 30 35 40 45 50 0 10 20 30 40 50 60 70 80 90 100Play Time (min)Rendering Quality (%)is small there is little time to recover when the bandwidth ﬂuctu-
ates. Our analysis also shows that higher bitrates are more likely to
improve user engagement for live content. In contrast to live and
long VoD videos, for short videos RendQual exhibits correlation
similar to BufRatio. We also ﬁnd that various metrics are not inde-
pendent. Finally, we explain some of the anomalous observations
from Section 3 in more depth.
4.1 Long VoD Content
Figure 6: Distribution of the univariate gain between the qual-
ity metrics and play time, for dataset LvodA.
Quality metric Correlation coefﬁcient
LvodA
-0.23
-0.67
0.41
JoinTime
BufRatio
RendQual
LvodB
-0.17
-0.61
0.38
(a) Absolute values
Table 2: Median values of the Kendall rank correlation coefﬁ-
cients for LvodA and LvodB. We do not show AvgBitrate and
RateBuf for LvodB because the player did not switch bitrates
or gather buffering event data. For the remaining metrics the
results are consistent with dataset LvodA.
is reversed compared to Figure 5. The reason (see Figure 7) is that
most of the probability mass is in the ﬁrst bin (0-1% BufRatio)
and the entropy here is the same as the overall distribution. Conse-
quently, the information gain for BufRatio is low; RateBuf does
not suffer this problem (not shown) and has higher information
gain. We also see that AvgBitrate has high information gain even
though its correlation was very low. We revisit this observation in
Section 4.1.1.
(b) Actual values (signed)
Figure 5: Distribution of the Kendall rank correlation coefﬁ-
cient between the quality metrics and play time for LvodA.
Figure 5 shows the distribution of the correlation coefﬁcients for
the quality metrics for dataset LvodA. We include both absolute
value and signed values to measure the magnitude and the nature (
i.e., increasing or decreasing) of the correlation. We summarize the
median values for both datasets in Table 2. The results are consis-
tent across both datasets for the common quality metrics BufRatio,
JoinTime, and RendQual. Recall that the two datasets corre-
spond to two different content providers; these results conﬁrm that
our observations are not unique to dataset LvodA.
The result shows that BufRatio has the strongest correlation
with PlayTime. Intuitively, we expect a higher BufRatio to de-
crease PlayTime (i.e., a negative correlation) and a higher RendQual
to increase PlayTime (i.e., a positive correlation). Figure 5(b) con-
ﬁrms this intuition regarding the nature of these relationships. We
notice that JoinTime has little impact on the play duration. Sur-
prisingly, AvgBitrate has very low correlation as well.
Next, we proceed to check if the univariate information gain
analysis corroborates or complements the correlation results in Fig-
ure 6. Interestingly, the relative order between RateBuf and BufRatio
Figure 7: Visualizing why buffering ratio does not result in a
high information gain even though it is correlated.
So far we have looked at each quality metric in isolation. A
natural question is: Does combining two metrics provide more
insights? For example, BufRatio and RendQual may be corre-
lated with each other. In this case knowing that both correlate with
PlayTime does not add new information. To evaluate this, we
show the distribution of the bivariate relative information gain in
Figure 8. For clarity, rather than showing all pairwise combina-
tions, for each metric we include the bivariate combination with
the highest relative information gain. For all metrics, the combina-
tion with the AvgBitrate provides the highest bivariate information
0.00.20.40.60.81.0Correlationcoefﬁcient(kendall)0.00.20.40.60.81.0FractionofvideosJointimeBufferingratioAveragebitrateRenderingqualityRateofbufferevents−1.0−0.50.00.51.0Correlationcoefﬁcient(kendall)0.00.20.40.60.81.0FractionofvideosJointimeBufferingratioAveragebitrateRenderingqualityRateofbufferevents0.000.050.100.150.200.25Relativeinformationgain0.00.20.40.60.81.0FractionofvideosJointimeBufferingratioAveragebitrateRenderingqualityRateofbufferevents 0 6 12 18 0 5 10 15 20 Avg. playtime 0 0.3 0.6 0.9 0 5 10 15 20 Prob. 0 0.3 0.6 0.9 1.2 0 5 10 15 20 Norm. entropyBufRatio partitiongain. Also, even though BufRatio, RateBuf , and RendQual had
strong correlations in Figure 5(a), their combinations do not add
much new information because they are inherently correlated.
Figure 8: Distribution of the best bivariate relative information
gains for LvodA
4.1.1 Strange behavior in AvgBitrate
Between Figures 5 and 6, we notice that AvgBitrate is the met-
ric with the weakest correlation but the second highest information
gain. This observation is related to Figure 3 from Section 3. The
relationship between PlayTime and AvgBitrate is not monotone;
it shows a peak between the 800-1000 Kbps, is low on either side
of this region, and increases slightly at the highest rate. Because
of this non-monotone relationship, the correlation is low. However,
knowing the value of AvgBitrate allows us predict the PlayTime;
there is a non-trivial information gain.
Now this explains why the information gain is high and the cor-
relation is low, but does not tell us why the PlayTime is low for
the 1000-1600 Kbps band. The reason is that the values of bitrates
in this range correspond to clients having to switch bitrates be-
cause of buffering induced by poor network conditions. Thus, the
PlayTime is low here mostly as a consequence of buffering, which
we already observed to be the most critical factor. This also points
out the need for robust bitrate selection and adaptation algorithms.
4.2 Live Content
Figure 9 shows the distribution of the correlation coefﬁcients for
dataset LiveA. The median values for the two datasets are sum-
marized in Table 3. We notice one key difference with respect to
the LvodA results: AvgBitrate is more strongly correlated for live
content. Similar to dataset LvodA, BufRatio is strongly corre-
lated, while JoinTime is weakly correlated.
Quality metric Correlation coefﬁcient
LiveA
-0.36
-0.67
-0.09
JoinTime
BufRatio
RendQual
LiveB
-0.49
-0.81
-0.16
Table 3: Median values of the Kendall rank correlation coefﬁ-
cients for LiveA and LiveB. We do not show AvgBitrate and
RateBuf because they do not apply to LiveB. For the remain-
ing metrics the results are consistent with dataset LiveA.
For both long VoD and live content, BufRatio is a critical met-
ric. Interestingly, for live, we see that RateBuf has a much stronger
negative correlation with PlayTime. This suggests that the Live
users are more sensitive to each buffering event compared to the
(a) Absolute values
(b) Actual values (signed)
Figure 9: Distribution of the Kendall rank correlation coefﬁ-
cient between the quality metrics and play time for LiveA.
Investigating this further, we ﬁnd that the
Long VoD audience.
average buffering duration is much smaller for long VoD (3 sec-
onds), compared to live (7s), i.e., each buffering event in the case
of live content is more disruptive. Because the buffer sizes in long
VoD are larger, the system fares better in face of ﬂuctuations in
link bandwidth. Furthermore, the system can be more proactive
in predicting buffering and hence preventing it by switching to an-
other server, or switching bitrates. Consequently, there are fewer
and shorter buffering events for long VoD. For live, on the other
hand, the buffer is shorter, to ensure that the stream is current. As
a result, the system is less able to proactively predict throughput
ﬂuctuations, which increases both the number and the duration of
buffering events. Figure 10 further conﬁrms that AvgBitrate is a
critical metric and that JoinTime is less critical for Live content.
The bivariate results (not shown for brevity) mimic the same effects
from Figure 8, where the combination with AvgBitrate provides
the best information gains.
4.2.1 Why is RendQual negatively correlated?
We noticed an anomalous behavior for PlayTime vs. RendQual
for live content in Figure 4(d). The previous results from both
LiveA and LiveB datasets further conﬁrm that this is not an anomaly
speciﬁc to the video shown earlier, but a more pervasive phenomenon
in live content.
To illustrate why this negative correlation arises, we focus on the
relationship between the RendQual and PlayTime for a particular
live video in Figure 11. We see a surprisingly large fraction of
viewers with low rendering quality and high play time. Further, the
0.00.10.20.30.40.5Relativeinformationgain0.00.20.40.60.81.0FractionofvideosJoinTime-AvgBitrateBufRatio-AvgBitrateRendQual-AvgBitrateRateBuf-AvgBitrate0.00.10.20.30.40.50.60.70.80.9Correlationcoefﬁcient(kendall)0.00.20.40.60.81.0FractionofvideosJointimeBufferingratioAveragebitrateRenderingqualityRateofbufferevents−1.0−0.8−0.6−0.4−0.20.00.20.40.60.8Correlationcoefﬁcient(kendall)0.00.20.40.60.81.0FractionofvideosJointimeBufferingratioAveragebitrateRenderingqualityRateofbuffereventsBecause the data collected during the corresponding period of
time does not provide the RendQual and RateBuf , we only fo-
cus on BufRatio and AvgBitrate, which we observed as the most
critical metrics for live content in the previous discussion. Fig-
ures 12(a) and 12(b) show that the trends and correlation coefﬁ-
cients for LiveH1 match closely with the results for datasets LiveA
and LiveB. We also conﬁrmed that the values for LiveH2 and