title:World-Driven Access Control for Continuous Sensing
author:Franziska Roesner and
David Molnar and
Alexander Moshchuk and
Tadayoshi Kohno and
Helen J. Wang
World-Driven Access Control for Continuous Sensing
Franziska Roesner1, David Molnar2, Alexander Moshchuk2,
Tadayoshi Kohno1,2, Helen J. Wang2
1University of Washington
2Microsoft Research
ABSTRACT
Modern applications increasingly rely on continuous moni-
toring of video, audio, or other sensor data to provide their
functionality, particularly in platforms such as the Microsoft
Kinect and Google Glass. Continuous sensing by untrusted
applications poses signiﬁcant privacy challenges for both de-
vice users and bystanders. Even honest users will struggle to
manage application permissions using existing approaches.
We propose a general, extensible framework for controlling
access to sensor data on multi-application continuous sens-
ing platforms. Our approach, world-driven access control,
allows real-world objects to explicitly specify access policies.
This approach relieves the user’s permission management
burden while mediating access at the granularity of objects
rather than full sensor streams. A trusted policy module on
the platform senses policies in the world and modiﬁes appli-
cations’ “views” accordingly. For example, world-driven ac-
cess control allows the system to automatically stop record-
ing in bathrooms or remove bystanders from video frames.
To convey and authenticate policies, we introduce passports,
a new kind of certiﬁcate that includes both a policy and op-
tionally the code for recognizing a real-world object.
We implement a prototype system and use it to study the
feasibility of world-driven access control in practice. Our
evaluation suggests that world-driven access control can ef-
fectively reduce the user’s permission management burden
in emerging continuous sensing systems. Our investigation
also surfaces key challenges for future access control mecha-
nisms for continuous sensing applications.
1.
INTRODUCTION
Continuous sensing is an emerging technology that en-
ables new classes of applications. New platforms, such as
Microsoft Kinect [37], Google Glass [14], and Meta Space-
Glasses [26], fundamentally rely on continuous video and
depth cameras to support natural user input via gestures
and continuous audio sensing for voice commands. Applica-
tions on these platforms leverage these capabilities to deliver
new functionality to users. For example, WordLens [34] is a
Google Glass and iPhone application that uses the camera to
continuously scan for words in the real world. It then shows
translations of these words overlaid on the user’s vision.
These new capabilities raise serious privacy concerns. Con-
sider a user who enters a locker room while wearing a Google
Glass. We identify four classes of privacy concerns in this
scenario. First, Word Lens or other untrusted applications
running on the Glass may see sensitive video data, both
about the user and about bystanders. Second, the user may
accidentally record bystanders by forgetting to turn oﬀ the
camera while entering the locker room. Third, the user may
Figure 1: Sensor Privacy Concerns. Camera restrictions
are common in sensitive locations like locker rooms, where both
device users’ and bystanders’ privacy are at risk from untrusted
applications. Continuous sensing platforms like Google Glass will
make it harder for honest users to mitigate such risks by manag-
ing applications’ permissions. World-driven access control allows
real-world objects to push policies to devices.
record herself in a locker room mirror and accidentally share
the recording on social media. Finally, malicious users could
use the Glass to record others without their knowledge.
The ﬁrst three classes of privacy concerns have honest
users who want to protect against untrusted applications
and user error. While protecting against malicious users is
also important, current approaches for addressing these pri-
vacy concerns do not work well even for honest users. In
this paper we thus assume that users are honest, but that
they may run untrusted applications.
Sensitive locations like locker rooms and bars commonly
handle these concerns today by posting explicit policies that
prohibit recording or the presence of recording devices (in-
cluding Google Glass [15]), as in Figure 1. This approach,
however, is hard to enforce and does little to protect a user
from untrusted applications or user error. Users must notice
the sign, then remember to turn oﬀ their device.
A new access control challenge. A natural way to ad-
dress these privacy concerns is with application permissions
in the operating system. However, continuous sensing and
natural user input pose new challenges to access control de-
sign. Today, platforms like Android, iOS, and Windows 8
deny untrusted applications default access to sensitive re-
sources like the camera and GPS. To determine which per-
missions to grant, these OSes put the user in the loop: with
manifests at application installation time (Android, Win-
dows 8) or prompts at the time of sensitive data access (iOS).
Previous work [12, 35], however, has shown that these
permission models are ﬂawed. Manifests are out of context
with applications’ use of sensitive data, making it hard for
users to understand what permissions applications need and
why. Prompts are disruptive and cause “prompt fatigue,”
conditioning users to simply click yes.
User-driven access control [35] addresses these ﬂaws by
coupling permission granting with user actions within an ap-
plication (e.g., clicking a special embedded camera button).
Microsoft Research Tech Report MSR-TR-2014-67
Unfortunately, this approach is not well-suited for contin-
uous sensing because it relies on explicit user interactions
with the device. By contrast, continuous sensing applica-
tions are, almost by deﬁnition, designed to automatically
“do things for you” without any such explicit actions.
Further, for applications with natural user input, like ges-
ture or voice, the input method itself relies on the camera or
microphone being always accessible. In these settings, per-
mission granting models that allow or deny access to entire
sensor streams are too coarse-grained.
The fundamental new challenge in permission system de-
sign for continuous sensing is thus enabling ﬁne-grained, au-
tomatic permission granting. For example, how should the
OS determine which objects in a video frame are accessi-
ble to an application? We pursued multiple unsuccessful at-
tempts to design access control for continuous sensing, which
we discuss in Section 3.1. From them, we learned that ac-
cess control decisions should depend on objects and people
around the user, and that these objects should specify their
own access policies in a distributed, context-sensitive way.
World-driven access control. Our solution is world-
driven access control. Using this approach, objects, places,
and people would present passports to the operating system.
A passport speciﬁes how to handle access control decisions
about an object, along with, optionally, code stating how
the object should be recognized. For example, in Figure 1,
the locker room might present a passport suggesting that
video or audio recording is prohibited. Passports provide a
distributed, context-sensitive approach to access control.
In our design (Section 3), a trusted policy module in the
OS detects passports, extracts policies, and applies those
policies dynamically to control applications’ access to sensor
data. Our design protects the user from untrusted applica-
tions while relieving the user of explicit permission manage-
ment. While users can override policies communicated by
passports, applications cannot.
Passports are intended to help users avoid accidentally
sharing or allowing applications to access sensitive data. For
example, a workplace can publish a passport stating that
whiteboards are sensitive, helping the user avoid recording
(and later accidentally sharing on social media) photos of
conﬁdential information on the whiteboard.
In the locker
room, a “no-record” policy helps the user avoid accidentally
allowing an untrusted application to access the video feed of
herself undressing in the mirror.
Passports can also help users respect others’ wishes with-
out requiring onerous manual conﬁguration. At the Ada-
Camp conference, for example, attendees wear red lanyards
to opt out of photography [3]. A world-driven access control
policy can tell the policy module to remove those attendees
from video streams and photos before applications see them.
The user does not need to manually check lanyards or re-
move the device entirely. Our approach allows dynamically
changing application permissions based on context, such as
being at a conference, without explicit user actions.
Making world-driven access control work requires over-
coming multiple challenges. First, there are many diﬀer-
ent policy communication mechanisms, ranging from QR
codes and Bluetooth to object recognition, each with dif-
ferent tradeoﬀs. Second, recognizing passports and comput-
ing policy decisions induces latency for applications. Third,
policy decisions may have false positives and false negatives.
Finally, our approach creates a new problem of policy au-
thenticity as adversaries may attempt to move, modify, or
remove markers that communicate policies. We describe
these and other challenges, as well as our approaches for
addressing them, in the context of our implementation in
Section 5 and our evaluation in Section 6.
Contributions. We introduce world-driven access control,
whereby application access to sensor data depends on poli-
cies speciﬁed by real-world objects. Our approach allows
the system to automatically manage application permissions
without explicit user interaction, and supports permissions
at the granularity of real-world objects rather than complete
sensor streams. We contribute:
(1) World-driven access control, a permission model for con-
tinuous sensing that allows real-world objects to communi-
cate policies using special passports. Our design enables a
distributed, context-sensitive approach for objects to con-
trol how sensitive data about them is accessed and for the
system to validate the authenticity of these policies.
(2) An extensible system design and implementation in which
a trusted policy module protects users from untrusted ap-
plications without requiring the user to explicitly manage
permissions. We evaluate our prototype in ﬁve diﬀerent set-
tings (Section 6) with representative policies from prior work
and real-world policies. Our design’s modularity allows us
to implement each policy in under 150 lines of C# code.
(3) Empowering objects with the ability to inﬂuence access
control decisions on users’ devices introduces numerous chal-
lenges. We crystallize these challenges and explore methods
for addressing them. For example, we introduce techniques
for mitigating latency and accuracy challenges in detecting
and enforcing policies (Sections 3-6), such as by combining
multiple means of communicating a policy.
In summary, world-driven access control is intended to
to relieve the user’s permission management burden while
preserving functionality and protecting privacy in emerg-
ing continuous sensing applications. This work presents a
new design point in the space of access control solutions for
continuous sensing applications. We believe that the foun-
dations laid herein will facilitate further work in the ﬁeld.
Previous work in this area focused on bystander privacy
(e.g., visual or electronic opt-outs [7, 16, 36]), or is speciﬁc to
one type of object alone. We discuss related work in detail in
Section 8. Finally, while our focus is on continuous sensing,
our policies can also apply to discrete sensing applications,
e.g., a cell phone camera taking a photo, as well as to output
permissions, e.g., permission for a camera to ﬂash or a phone
to ring. We reﬂect on challenges and discuss other extensions
in Section 7, then conclude in Section 9.
2. GOALS AND THREAT MODEL
We consider ﬁne-grained access control for sensor data on
platforms where multiple isolated applications desire contin-
uous access to system sensors, such as camera, microphone,
and GPS. In our model, the system is trustworthy and un-
compromised, but applications are untrusted.
Goals. Our goal is to help honest users manage applica-
tions’ permissions. A user may do so to (1) protect his/her
own privacy by minimizing exposure of sensor information
to untrusted applications, and/or (2) respect bystanders’ pri-
vacy wishes. We seek to help the user achieve these goals
with minimal burden; users should not need to continuously
manage permissions for each long-running application.
Microsoft Research Tech Report MSR-TR-2014-67
Constraints. We constrain our model in three ways:
(1) We consider only access control policies that are applied
at data collection time, not at data distribution time. These
policies aﬀect whether or not an application may receive a
data item — such as a camera frame or audio event — but
do not provide additional data ﬂow guarantees after an ap-
plication has already accessed the data.
(2) Policies apply to applications, not to the system itself.
For example, if a policy restricts camera access, the (trusted)
system still receives camera data but prevents it from reach-
ing applications. We observe that any system designed to
apply policies embedded in real-world sensor data must, by
deﬁnition, be able to receive and process sensor inputs.
(3) Users can always use another device that does not run
our system, and hence can, if they desire, violate real-world
policies with non-compliant devices. Our solution therefore
does not force user or device compliance and, indeed, ex-
plicitly allows users to override access control policies. We
consider techniques for verifying device compliance, which
have been studied elsewhere [24], out of scope.
Novel threat model. Our approach empowers real-world
objects with the ability to broadcast data collection policies.
Unlike conventional approaches to access control, like mani-
fests and prompts, we therefore transfer the primary policy
controls away from the user and onto objects in the real
world. Thus, in addition to untrusted applications, we must
consider the threat of adversarially-inﬂuenced real-world ob-
jects. For example, we must consider malicious policies de-
signed to prevent recording (e.g., criminals might appreciate
the ability to turn oﬀ all nearby cameras) or override poli-
cies that prohibit recording (e.g., someone seeking to embar-
rass users in the bathroom by causing them to accidentally
record). These threats guide several design decisions, which
we will return to later, like the ability for users to override
policy suggestions and our design of passports.
3. WORLD-DRIVEN ACCESS CONTROL
World-driven access control is based on three principles
derived from our initial attempts to build an access control
mechanism for continuous sensing, which we summarize. We
then describe our solution, key challenges we encountered,
and how our design addresses these challenges. Figure 2
shows world-driven access control in action, and Figure 3
shows a block diagram of our system.
3.1 Principles from Initial Approaches
Object-driven policies. In user-driven access control [35],
applications are granted access to sensitive resources as a
result of explicit in-application user interactions with special
UI elements (e.g., clicking on an embedded camera button).
This technique eﬀectively manages application permissions
without the drawbacks of prompts or install-time manifests,
and so we attempted to adapt it to continuous sensing.
In some cases, user-driven access control worked well —
photos and video chat on Google Glass, for example, are
triggered by explicit user actions like winking or using the
touchpad. However, many promising continuous sensing ap-
plications do not involve explicit user input. For example,
the WordLens translation application is object-driven, rather
than user-driven: it reacts to all words it “sees” and trans-
lates them without explicit user input. In future systems,
such applications that “do things for you” may run continu-
Figure 2: World-Driven Access Control
in Action.
World-driven access control helps a user manage application per-
mission to both protect her own privacy and to honor a by-
stander’s privacy wishes. Here, a person asks not to be recorded;
our prototype detects and applies the policy, allowing applications
to see only the modiﬁed image. In this case, the person wears a
QR code to communicate her policy, and a depth camera is used
to ﬁnd the person, but a variety of other methods can be used.
ously for long periods of time; they are uniquely enabled by
continuous sensing and raise the greatest privacy risks. At-
tempting to inject user actions into such applications — such
as allowing users to use a drag-and-drop gesture to grant ap-
plications one-time access to information about real-world
objects — felt disruptive and artiﬁcial.