# World-Driven Access Control for Continuous Sensing

**Authors:**
- Franziska Roesner<sup>1</sup>
- David Molnar<sup>2</sup>
- Alexander Moshchuk<sup>2</sup>
- Tadayoshi Kohno<sup>1,2</sup>
- Helen J. Wang<sup>2</sup>

**Affiliations:**
- 1 University of Washington
- 2 Microsoft Research

## Abstract
Modern applications increasingly rely on continuous monitoring of video, audio, and other sensor data to provide their functionality, particularly in platforms such as the Microsoft Kinect and Google Glass. Continuous sensing by untrusted applications poses significant privacy challenges for both device users and bystanders. Even honest users struggle to manage application permissions using existing approaches.

We propose a general, extensible framework for controlling access to sensor data on multi-application continuous sensing platforms. Our approach, world-driven access control, allows real-world objects to explicitly specify access policies. This approach relieves the user's permission management burden while mediating access at the granularity of objects rather than full sensor streams. A trusted policy module on the platform senses policies in the world and modifies applications' "views" accordingly. For example, world-driven access control can automatically stop recording in bathrooms or remove bystanders from video frames.

To convey and authenticate policies, we introduce passports, a new kind of certificate that includes both a policy and optionally the code for recognizing a real-world object. We implement a prototype system and use it to study the feasibility of world-driven access control in practice. Our evaluation suggests that world-driven access control can effectively reduce the user's permission management burden in emerging continuous sensing systems. Our investigation also surfaces key challenges for future access control mechanisms for continuous sensing applications.

## 1. Introduction
Continuous sensing is an emerging technology that enables new classes of applications. New platforms, such as the Microsoft Kinect, Google Glass, and Meta Space-Glasses, fundamentally rely on continuous video and depth cameras to support natural user input via gestures and continuous audio sensing for voice commands. Applications on these platforms leverage these capabilities to deliver new functionality to users. For example, WordLens is a Google Glass and iPhone application that uses the camera to continuously scan for words in the real world and then shows translations of these words overlaid on the user’s vision.

These new capabilities raise serious privacy concerns. Consider a user who enters a locker room while wearing a Google Glass. We identify four classes of privacy concerns in this scenario:
1. Untrusted applications running on the Glass may see sensitive video data about the user and bystanders.
2. The user may accidentally record bystanders by forgetting to turn off the camera while entering the locker room.
3. The user may record herself in a locker room mirror and accidentally share the recording on social media.
4. Malicious users could use the Glass to record others without their knowledge.

The first three classes of privacy concerns involve honest users who want to protect against untrusted applications and user error. While protecting against malicious users is also important, current approaches for addressing these privacy concerns do not work well even for honest users. In this paper, we assume that users are honest but may run untrusted applications.

Sensitive locations like locker rooms and bars commonly handle these concerns today by posting explicit policies that prohibit recording or the presence of recording devices (including Google Glass). However, this approach is hard to enforce and does little to protect a user from untrusted applications or user error. Users must notice the sign, then remember to turn off their device.

### A New Access Control Challenge
A natural way to address these privacy concerns is with application permissions in the operating system. However, continuous sensing and natural user input pose new challenges to access control design. Today, platforms like Android, iOS, and Windows 8 deny untrusted applications default access to sensitive resources like the camera and GPS. To determine which permissions to grant, these OSes put the user in the loop: with manifests at application installation time (Android, Windows 8) or prompts at the time of sensitive data access (iOS).

Previous work has shown that these permission models are flawed. Manifests are out of context with applications' use of sensitive data, making it hard for users to understand what permissions applications need and why. Prompts are disruptive and cause "prompt fatigue," conditioning users to simply click yes.

User-driven access control addresses these flaws by coupling permission granting with user actions within an application (e.g., clicking a special embedded camera button). Unfortunately, this approach is not well-suited for continuous sensing because it relies on explicit user interactions with the device. By contrast, continuous sensing applications are, almost by definition, designed to automatically "do things for you" without any such explicit actions. Further, for applications with natural user input, like gesture or voice, the input method itself relies on the camera or microphone being always accessible. In these settings, permission granting models that allow or deny access to entire sensor streams are too coarse-grained.

The fundamental new challenge in permission system design for continuous sensing is thus enabling fine-grained, automatic permission granting. For example, how should the OS determine which objects in a video frame are accessible to an application? We pursued multiple unsuccessful attempts to design access control for continuous sensing, which we discuss in Section 3.1. From them, we learned that access control decisions should depend on objects and people around the user, and that these objects should specify their own access policies in a distributed, context-sensitive way.

### World-Driven Access Control
Our solution is world-driven access control. Using this approach, objects, places, and people would present passports to the operating system. A passport specifies how to handle access control decisions about an object, along with, optionally, code stating how the object should be recognized. For example, in Figure 1, the locker room might present a passport suggesting that video or audio recording is prohibited. Passports provide a distributed, context-sensitive approach to access control.

In our design (Section 3), a trusted policy module in the OS detects passports, extracts policies, and applies those policies dynamically to control applications' access to sensor data. Our design protects the user from untrusted applications while relieving the user of explicit permission management. While users can override policies communicated by passports, applications cannot.

Passports are intended to help users avoid accidentally sharing or allowing applications to access sensitive data. For example, a workplace can publish a passport stating that whiteboards are sensitive, helping the user avoid recording (and later accidentally sharing on social media) photos of confidential information on the whiteboard. In the locker room, a "no-record" policy helps the user avoid accidentally allowing an untrusted application to access the video feed of herself undressing in the mirror.

Passports can also help users respect others' wishes without requiring onerous manual configuration. At the AdaCamp conference, for example, attendees wear red lanyards to opt out of photography. A world-driven access control policy can tell the policy module to remove those attendees from video streams and photos before applications see them. The user does not need to manually check lanyards or remove the device entirely. Our approach allows dynamically changing application permissions based on context, such as being at a conference, without explicit user actions.

Making world-driven access control work requires overcoming multiple challenges. First, there are many different policy communication mechanisms, ranging from QR codes and Bluetooth to object recognition, each with different trade-offs. Second, recognizing passports and computing policy decisions induces latency for applications. Third, policy decisions may have false positives and false negatives. Finally, our approach creates a new problem of policy authenticity as adversaries may attempt to move, modify, or remove markers that communicate policies. We describe these and other challenges, as well as our approaches for addressing them, in the context of our implementation in Section 5 and our evaluation in Section 6.

### Contributions
We introduce world-driven access control, whereby application access to sensor data depends on policies specified by real-world objects. Our approach allows the system to automatically manage application permissions without explicit user interaction and supports permissions at the granularity of real-world objects rather than complete sensor streams. We contribute:

1. **World-Driven Access Control**: A permission model for continuous sensing that allows real-world objects to communicate policies using special passports. Our design enables a distributed, context-sensitive approach for objects to control how sensitive data about them is accessed and for the system to validate the authenticity of these policies.
2. **Extensible System Design and Implementation**: A trusted policy module that protects users from untrusted applications without requiring the user to explicitly manage permissions. We evaluate our prototype in five different settings (Section 6) with representative policies from prior work and real-world policies. Our design's modularity allows us to implement each policy in under 150 lines of C# code.
3. **Addressing Challenges**: Empowering objects with the ability to influence access control decisions on users' devices introduces numerous challenges. We crystallize these challenges and explore methods for addressing them. For example, we introduce techniques for mitigating latency and accuracy challenges in detecting and enforcing policies (Sections 3-6), such as by combining multiple means of communicating a policy.

In summary, world-driven access control is intended to relieve the user's permission management burden while preserving functionality and protecting privacy in emerging continuous sensing applications. This work presents a new design point in the space of access control solutions for continuous sensing applications. We believe that the foundations laid herein will facilitate further work in the field. Previous work in this area focused on bystander privacy (e.g., visual or electronic opt-outs) or is specific to one type of object alone. We discuss related work in detail in Section 8. Finally, while our focus is on continuous sensing, our policies can also apply to discrete sensing applications, e.g., a cell phone camera taking a photo, as well as to output permissions, e.g., permission for a camera to flash or a phone to ring. We reflect on challenges and discuss other extensions in Section 7, then conclude in Section 9.

## 2. Goals and Threat Model
We consider fine-grained access control for sensor data on platforms where multiple isolated applications desire continuous access to system sensors, such as the camera, microphone, and GPS. In our model, the system is trustworthy and uncompromised, but applications are untrusted.

### Goals
Our goal is to help honest users manage applications' permissions. A user may do so to:
1. Protect his/her own privacy by minimizing exposure of sensor information to untrusted applications.
2. Respect bystanders' privacy wishes.

We seek to help the user achieve these goals with minimal burden; users should not need to continuously manage permissions for each long-running application.

### Constraints
We constrain our model in three ways:
1. We consider only access control policies that are applied at data collection time, not at data distribution time. These policies affect whether or not an application may receive a data item—such as a camera frame or audio event—but do not provide additional data flow guarantees after an application has already accessed the data.
2. Policies apply to applications, not to the system itself. For example, if a policy restricts camera access, the (trusted) system still receives camera data but prevents it from reaching applications. We observe that any system designed to apply policies embedded in real-world sensor data must, by definition, be able to receive and process sensor inputs.
3. Users can always use another device that does not run our system and hence can, if they desire, violate real-world policies with non-compliant devices. Our solution therefore does not force user or device compliance and, indeed, explicitly allows users to override access control policies. We consider techniques for verifying device compliance, which have been studied elsewhere, out of scope.

### Novel Threat Model
Our approach empowers real-world objects with the ability to broadcast data collection policies. Unlike conventional approaches to access control, like manifests and prompts, we transfer the primary policy controls away from the user and onto objects in the real world. Thus, in addition to untrusted applications, we must consider the threat of adversarially-influenced real-world objects. For example, we must consider malicious policies designed to prevent recording (e.g., criminals might appreciate the ability to turn off all nearby cameras) or override policies that prohibit recording (e.g., someone seeking to embarrass users in the bathroom by causing them to accidentally record). These threats guide several design decisions, such as the ability for users to override policy suggestions and our design of passports.

## 3. World-Driven Access Control
World-driven access control is based on three principles derived from our initial attempts to build an access control mechanism for continuous sensing, which we summarize. We then describe our solution, key challenges we encountered, and how our design addresses these challenges. Figure 2 shows world-driven access control in action, and Figure 3 shows a block diagram of our system.

### 3.1 Principles from Initial Approaches
**Object-Driven Policies**: In user-driven access control, applications are granted access to sensitive resources as a result of explicit in-application user interactions with special UI elements (e.g., clicking on an embedded camera button). This technique effectively manages application permissions without the drawbacks of prompts or install-time manifests, and so we attempted to adapt it to continuous sensing.

In some cases, user-driven access control worked well—photos and video chat on Google Glass, for example, are triggered by explicit user actions like winking or using the touchpad. However, many promising continuous sensing applications do not involve explicit user input. For example, the WordLens translation application is object-driven, rather than user-driven: it reacts to all words it "sees" and translates them without explicit user input. In future systems, such applications that "do things for you" may run continuously for long periods of time; they are uniquely enabled by continuous sensing and raise the greatest privacy risks. Attempting to inject user actions into such applications—such as allowing users to use a drag-and-drop gesture to grant applications one-time access to information about real-world objects—felt disruptive and artificial.