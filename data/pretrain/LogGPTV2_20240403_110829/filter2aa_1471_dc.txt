The DTrace initialization starts in early boot stages, when the Windows
loader is loading all the modules needed for the kernel to correctly start. One
important part to load and validate is the API set file (apisetschema.dll),
which is a key component of the Windows system. (API Sets are described in
Chapter 3 of part 1.) If the DTRACE_ENABLED BCD element is set in the
boot entry (value 0x26000145, which can be set through the dtrace readable
name; see Chapter 12 for more details about BCD objects), the Windows
loader checks whether the dtrace.sys driver is present in the
%SystemRoot%\System32\Drivers path. If so, it builds a new API Set
schema extension named ext-ms-win-ntos-trace-l1-1-0. The schema targets
the Dtrace.sys driver and is merged into the system API set schema
(OslApiSetSchema).
Later in the boot process, when the NT kernel is starting its phase 1 of
initialization, the TraceInitSystem function is called to initialize the Dynamic
Tracing subsystem. The API is imported in the NT kernel through the ext-
ms-win-ntos-trace-l1-1-0.dll API set schema. This implies that if DTrace is
not enabled by the Windows loader, the name resolution would fail, and the
function will be basically a no op.
The TraceInitSystem has the important duty of calculating the content of
the trace callouts array, which contains the functions that will be called by
the NT kernel when a trace probe fires. The array is stored in the
KiDynamicTraceCallouts global symbol, which will be later protected by
Patchguard to prevent malicious drivers from illegally redirecting the flow of
execution of system routines. Finally, through the TraceInitSystem function,
the NT kernel sends to the DTrace driver another important array, which
contains private system interfaces used by the DTrace driver to apply the
probes. (The array is exposed in a trace extension context data structure.)
This kind of initialization, where both the DTrace driver and the NT kernel
exchange private interfaces, is the main motivation why the DTrace driver is
called an extension driver.
The Pnp manager later starts the DTrace driver, which is installed in the
system as boot driver, and calls its main entry point (DriverEntry). The
routine registers the \Device\DTrace control device and its symbolic link
(\GLOBAL??\DTrace). It then initializes the internal DTrace state, creating
the first DTrace built-in provider. It finally registers all the available
providers by calling the initialization function of each of them. The
initialization method depends on each provider and usually ends up calling
the internal dtrace_register function, which registers the provider with the
DTrace framework. Another common action in the provider initialization is
to register a handler for the control device. User-mode applications can
communicate with DTrace and with a provider through the DTrace control
device, which exposes virtual files (handlers) to providers. For example, the
user-mode LibDTrace communicates directly with the PID provider by
opening a handle to the \\.\DTrace\Fasttrap virtual file (handler).
The syscall provider
When the syscall provider gets activated, DTrace ends up calling the
KeSetSystemServiceCallback routine, with the goal of activating a callback
for the system call specified in the probe. The routine is exposed to the
DTrace driver thanks to the NT system interfaces array. The latter is
compiled by the NT kernel at DTrace initialization time (see the previous
section for more details) and encapsulated in an extension context data
structure internally called KiDynamicTraceContext. The first time that the
KeSetSystemServiceCallback is called, the routine has the important task of
building the global service trace table (KiSystemServiceTraceCallbackTable),
which is an RB (red-black) tree containing descriptors of all the available
syscalls. Each descriptor includes a hash of the syscall’s name, its address,
and number of parameters and flags indicating whether the callback is
enabled on entry or on exit. The NT kernel includes a static list of syscalls
exposed through the KiServicesTab internal array.
After the global service trace table has been filled, the
KeSetSystemServiceCallback calculates the hash of the syscall’s name
specified by the probe and searches the hash in the RB tree. If there are no
matches, the probe has specified a wrong syscall name (so the function exits
signaling an error). Otherwise, the function modifies the enablement flags
located in the found syscall’s descriptor and increases the number of the
enabled trace callbacks (which is stored in an internal variable).
When the first DTrace syscall callback is enabled, the NT kernel sets the
syscall bit in the global KiDynamicTraceMask bitmask. This is very
important because it enables the system call handler (KiSystemCall64) to
invoke the global trace handlers. (System calls and system service
dispatching have been discussed extensively in Chapter 8.)
This design allows DTrace to coexist with the system call handling
mechanism without having any sort of performance penalty. If no DTrace
syscall probe is active, the trace handlers are not invoked. A trace handler
can be called on entry and on exit of a system call. Its functionality is simple.
It just scans the global service trace table looking for the descriptor of the
system call. When it finds the descriptor, it checks whether the enablement
flag is set and, if so, invokes the correct callout (contained in the global
dynamic trace callout array, KiDynamicTraceCallouts, as specified in the
previous section). The callout, which is implemented in the DTrace driver,
uses the generic internal dtrace_probe function to fire the syscall probe and
execute the actions associated with it.
The Function Boundary Tracing (FBT) and Process
(PID) providers
Both the FBT and PID providers are similar because they allow a probe to be
enabled on any function entry and exit points (not necessarily a syscall). The
target function can reside in the NT kernel or as part of a driver (for these
cases, the FBT provider is used), or it can reside in a user-mode module,
which should be executed by a process. (The PID provider can trace user-
mode applications.) An FBT or PID probe is activated in the system through
breakpoint opcodes (INT 3 in x86, BRK in ARM64) that are written directly
in the target function’s code. This has the following important implications:
■    When a PID or FBT probe raises, DTrace should be able to re-execute
the replaced instruction before calling back the target function. To do
this, DTrace uses an instruction emulator, which, at the time of this
writing, is compatible with the AMD64 and ARM64 architecture. The
emulator is implemented in the NT kernel and is normally invoked by
the system exception handler while dealing with a breakpoint
exception.
■    DTrace needs a way to identify functions by name. The name of a
function is never compiled in the final binary (except for exported
functions). DTrace uses multiple techniques to achieve this, which
will be discussed in the “DTrace type library” section later in this
chapter.
■    A single function can exit (return) in multiple ways from different
code branches. To identify the exit points, a function graph analyzer is
required to disassemble the function’s instructions and find each exit
point. Even though the original function graph analyzer was part of
the Solaris code, the Windows implementation of DTrace uses a new
optimized version of it, which still lives in the LibDTrace library
(DTrace.dll). While user-mode functions are analyzed by the function
graph analyzer, DTrace uses the PDATA v2 unwind information to
reliably find kernel-mode function exit points (more information on
function unwinds and exception dispatching is available in Chapter
8). If the kernel-mode module does not make use of PDATA v2
unwind information, the FBT provider will not create any probes on
function returns for it.
DTrace installs FBT or PID probes by calling the KeSetTracepoint
function of the NT kernel exposed through the NT System interfaces array.
The function validates the parameters (the callback pointer in particular) and,
for kernel targets, verifies that the target function is located in an executable
code section of a known kernel-mode module. Similar to the syscall provider,
a KI_TRACEPOINT_ENTRY data structure is built and used for keeping
track of the activated trace points. The data structure contains the owning
process, access mode, and target function address. It is inserted in a global
hash table, KiTpHashTable, which is allocated at the first time an FBT or
PID probe gets activated. Finally, the single instruction located in the target
code is parsed (imported in the emulator) and replaced with a breakpoint
opcode. The trap bit in the global KiDynamicTraceMask bitmask is set.
For kernel-mode targets, the breakpoint replacement can happen only
when VBS (Virtualization Based Security) is enabled. The
MmWriteSystemImageTracepoint routine locates the loader data table entry
associated with the target function and invokes the
SECURESERVICE_SET_TRACEPOINT secure call. The Secure Kernel is
the only entity able to collaborate with HyperGuard and thus to render the
breakpoint application a legit code modification. As explained in Chapter 7
of Part 1, Kernel Patch protection (also known as Patchguard) prevents any
code modification from being performed on the NT kernel and some
essential kernel drivers. If VBS is not enabled on the system, and a debugger
is not attached, an error code is returned, and the probe application fails. If a
kernel debugger is attached, the breakpoint opcode is applied by the NT
kernel through the MmDbgCopyMemory function. (Patchguard is not enabled
on debugged systems.)
When called for debugger exceptions, which may be caused by a DTrace’s
FTB or PID probe firing, the system exception handler
(KiDispatchException) checks whether the “trap” bit is set in the global
KiDynamicTraceMask bitmask. If it is, the exception handler calls the
KiTpHandleTrap function, which searches into the KiTpHashTable to
determine whether the exception occurred thanks to a registered FTB or PID
probe firing. For user-mode probes, the function checks whether the process
context is the expected one. If it is, or if the probe is a kernel-mode one, the
function directly invokes the DTrace callback, FbtpCallback, which executes
the actions associated with the probe. When the callback completes, the
handler invokes the emulator, which emulates the original first instruction of
the target function before transferring the execution context to it.
EXPERIMENT: Tracing dynamic memory
In this experiment, you dynamically trace the dynamic memory
applied to a VM. Using Hyper-V Manager, you need to create a
generation 2 Virtual Machine and apply a minimum of 768 MB and
an unlimited maximum amount of dynamic memory (more
information on dynamic memory and Hyper-V is available in
Chapter 9). The VM should have the May 2019 (19H1) or May
2020 (20H1) Update of Windows 10 or later installed as well as the
DTrace package (which should be enabled as explained in the
“Enabling DTrace and listing the installed providers” experiment
from earlier in this chapter).
The dynamic_memory.d script, which can be found in this
book’s downloadable resources, needs to be copied in the DTrace
directory and started by typing the following commands in an
administrative command prompt window:
Click here to view code image
cd /d "c:\Program Files\DTrace"
dtrace.exe -s dynamic_memory.d
With only the preceding commands, DTrace will refuse to
compile the script because of an error similar to the following:
Click here to view code image
dtrace: failed to compile script dynamic_memory.d: line 62: 
probe description fbt:nt:MiRem
ovePhysicalMemory:entry does not match any probes
This is because, in standard configurations, the path of the
symbols store is not set. The script attaches the FBT provider on
two OS functions: MmAddPhysicalMemory, which is exported
from the NT kernel binary, and MiRemovePhysicalMemory, which
is not exported or published in the public WDK. For the latter, the
FBT provider has no way to calculate its address in the system.
DTrace can obtain types and symbol information from different
sources, as explained in the “DTrace type library” section later in
this chapter. To allow the FBT provider to correctly work with
internal OS functions, you should set the Symbol Store’s path to
point to the Microsoft public symbol server, using the following
command:
Click here to view code image
set 
_NT_SYMBOL_PATH=srv*C:\symbols*http://msdl.microsoft.com/dow
nload/symbols
After the symbol store’s path is set, if you restart DTrace
targeting the dynamic_memory.d script, it should be able to
correctly compile it and show the following output:
Click here to view code image
The Dynamic Memory script has begun.
Now you should simulate a high-memory pressure scenario. You
can do this in multiple ways—for example, by starting your
favorite browser and opening a lot of tabs, by starting a 3D game,
or by simply using the TestLimit tool with the -d command switch,
which forces the system to contiguously allocate memory and write
to it until all the resources are exhausted. The VM worker process
in the root partition should detect the scenario and inject new
memory in the child VM. This would be detected by DTrace:
Click here to view code image
Physical memory addition request intercepted. Start physical 
address 0x00112C00, Number of
pages: 0x00000400.
   Addition of 1024 memory pages starting at PFN 0x00112C00 
succeeded!
In a similar way, if you close all the applications in the guest
VM and you recreate a high-memory pressure scenario in your host
system, the script would be able to intercept dynamic memory’s
removal requests:
Click here to view code image
Physical memory removal request intercepted. Start physical 
address 0x00132000, Number of
pages: 0x00000200.
   Removal of 512 memory pages starting at PFN 0x00132000 
succeeded!
After interrupting DTrace using Ctrl+C, the script prints out
some statistics information:
Click here to view code image
Dynamic Memory script ended.
Numbers of Hot Additions: 217
Numbers of Hot Removals: 1602
Since starts the system has gained 0x00017A00 pages (378 
MB).
If you open the dynamic_memory.d script using Notepad, you
will find that it installs a total of six probes (four FBT and two
built-in) and performs logging and counting actions. For example,
Click here to view code image
fbt:nt:MmAddPhysicalMemory:return
/ self->pStartingAddress != 0 /
installs a probe on the exit points of the MmAddPhysicalMemory
function only if the starting physical address obtained at function
entry point is not 0. More information on the D programming
language applied to DTrace is available in the The illumos
Dynamic Tracing Guide book, which is freely accessible at
http://dtrace.org/guide/preface.html.
The ETW provider
DTrace supports both an ETW provider, which allows probes to fire when
certain ETW events are generated by particular providers, and the etw_trace
action, which allows DTrace scripts to generate new customized
TraceLogging ETW events. The etw_trace action is implemented in
LibDTrace, which uses TraceLogging APIs to dynamically register a new
ETW provider and generate events associated with it. More information on
ETW has been presented in the “Event Tracing for Windows (ETW)” section
previously in this chapter.
The ETW provider is implemented in the DTrace driver. When the Trace
engine is initialized by the Pnp manager, it registers all providers with the
DTrace engine. At registration time, the ETW provider configures an ETW
session called DTraceLoggingSession, which is set to write events in a
circular buffer. When DTrace is started from the command line, it sends an
IOCTL to DTrace driver. The IOCTL handler calls the provide function of
each provider; the DtEtwpCreate internal function invokes the
NtTraceControl API with the EtwEnumTraceGuidList function code. This
allows DTrace to enumerate all the ETW providers registered in the system
and to create a probe for each of them. (dtrace -l is also able to display ETW
probes.)
When a D script targeting the ETW provider is compiled and executed, the
internal DtEtwEnable routine gets called with the goal of enabling one or
more ETW probes. The logging session configured at registration time is
started, if it’s not already running. Through the trace extension context
(which, as previously discussed, contains private system interfaces), DTrace
is able to register a kernel-mode callback called every time a new event is
logged in the DTrace logging session. The first time that the session is
started, there are no providers associated with it. Similar to the syscall and
FBT provider, for each probe DTrace creates a tracking data structure and
inserts it in a global RB tree (DtEtwpProbeTree) representing all the enabled
ETW probes. The tracking data structure is important because it represents
the link between the ETW provider and the probes associated with it. DTrace
calculates the correct enablement level and keyword bitmask for the provider
(see the “Provider Enablement” section previously in this chapter for more
details) and enables the provider in the session by invoking the
NtTraceControl API.
When an event is generated, the ETW subsystem calls the callback routine,
which searches into the global ETW probe tree the correct context data
structure representing the probe. When found, DTrace can fire the probe (still
using the internal dtrace_probe function) and execute all the actions
associated with it.
DTrace type library
DTrace works with types. System administrators are able to inspect internal
operating system data structures and use them in D clauses to describe
actions associated with probes. DTrace also supports supplemental data types
compared to the ones supported by the standard D programming language.
To be able to work with complex OS-dependent data types and allow the
FBT and PID providers to set probes on internal OS and application
functions, DTrace obtains information from different sources:
■    Function names, signatures, and data types are initially extracted from
information embedded in the executable binary (which adheres to the
Portable Executable file format), like from the export table and debug
information.
■    For the original DTrace project, the Solaris operating system included
support for Compact C Type Format (CTF) in its executable binary
files (which adhere to the Executable and Linkable Format - ELF).
This allowed the OS to store the debug information needed by DTrace
to run directly into its modules (the debug information can also be
stored using the deflate compression format). The Windows version
of DTrace still supports a partial CTF, which has been added as a
resource section of the LibDTrace library (Dtrace.dll). CTF in the
LibDTrace library stores the type information contained in the public
WDK (Windows Driver Kit) and SDK (Software Development Kit)
and allows DTrace to work with basic OS data types without
requiring any symbol file.
■    Most of the private types and internal OS function signatures are
obtained from PDB symbols. Public PDB symbols for the majority of
the operating system’s modules are downloadable from the Microsoft
Symbol Server. (These symbols are the same as those used by the
Windows Debugger.) The symbols are deeply used by the FBT
provider to correctly identify internal OS functions and by DTrace to
be able to retrieve the correct type of parameters for each syscall and
function.
The DTrace symbol server
DTrace includes an autonomous symbol server that can download PDB
symbols from the Microsoft public Symbol store and render them available to
the DTrace subsystem. The symbol server is implemented mainly in
LibDTrace and can be queried by the DTrace driver using the Inverted call
model. As part of the providers’ registration, the DTrace driver registers a
SymServer pseudo-provider. The latter is not a real provider but just a
shortcut for allowing the symsrv handler to the DTrace control device to be
registered.
When DTrace is started from the command line, the LibDTrace library
starts the symbols server by opening a handle to the \\.\dtrace\symsrv control
device (using the standard CreateFile API). The request is processed by the
DTrace driver through the Symbol server IRP handler, which registers the
user-mode process, adding it in an internal list of symbols server processes.
LibDTrace then starts a new thread, which sends a dummy IOCTL to the
DTrace symbol server device and waits indefinitely for a reply from the
driver. The driver marks the IRP as pending and completes it only when a
provider (or the DTrace subsystem), requires new symbols to be parsed.
Every time the driver completes the pending IRP, the DTrace symbols
server thread wakes up and uses services exposed by the Windows Image
Helper library (Dbghelp.dll) to correctly download and parse the required
symbol. The driver then waits for a new dummy IOCTL to be sent from the
symbols thread. This time the new IOCTL will contain the results of the
symbol parsing process. The user-mode thread wakes up again only when the
DTrace driver requires it.
Windows Error Reporting (WER)
Windows Error Reporting (WER) is a sophisticated mechanism that
automates the submission of both user-mode process crashes as well as
kernel-mode system crashes. Multiple system components have been
designed for supporting reports generated when a user-mode process,
protected process, trustlet, or the kernel crashes.
Windows 10, unlike from its predecessors, does not include a graphical
dialog box in which the user can configure the details that Windows Error
Reporting acquires and sends to Microsoft (or to an internal server
configured by the system administrator) when an application crashes. As
shown in Figure 10-38, in Windows 10, the Security and Maintenance applet
of the Control Panel can show the user a history of the reports generated by
Windows Error Reporting when an application (or the kernel) crashes. The
applet can show also some basic information contained in the report.
Figure 10-38 The Reliability monitor of the Security and Maintenance
applet of the Control Panel.
Windows Error Reporting is implemented in multiple components of the
OS, mainly because it needs to deal with different kind of crashes:
■    The Windows Error Reporting Service (WerSvc.dll) is the main
service that manages the creation and sending of reports when a user-