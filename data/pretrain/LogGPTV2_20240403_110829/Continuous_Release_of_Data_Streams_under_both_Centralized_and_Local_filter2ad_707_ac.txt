parameters, the best level of error that can be achieved is usually a
good indicator of c. When a public dataset is unavailable, one can
generate a synthetic dataset under some correlation assumption
and run experiments. In experiments conducted for this paper, we
choose c = 60, and use it for all datasets and settings.
Figure 1: Empirical comparison of approximated query re-
sults (Equation 6) and the true squared errors and their min-
imum points θq and θt on a real-world datasets (DNS). We
use ϵ = 0.1, m = 216
, r = 220. The x-axis is the possible value
of θ, and the y-axis is the query result or the measured error.
Verify the Approximation. Figure 1 illustrates the distribution
of Equation 6 and measured errors on a dataset that is used in
the experiments in Section 5. The dataset is a network streaming
dataset, called DNS. We use ϵ = 0.1, m = 216
, r = 220, which are the
same as those parameters used in experiments. From Figure 1, we
can see that the distributions between the truly measured errors
(Equation 4) and the corresponding Equation 6 on two datasets
are very close. The figure also illustrates the bias and variance
factors of Equation 6. The two factors grow in opposite directions
which makes a global minimum where the target θ lies. In addition,
we also show that the threshold θq that minimizes our queries
Equation 6 is close to the target threshold θt which minimizes the
real measured errors (Equation 4). Therefore, the above empirical
evaluation results show the capability of the threshold optimizer in
finding accurate θ values.
3.4 Perturber
The perturber inherits the hierarchical idea [8, 18] (also described
in Section 3.1). In this section, we start from the binary hierarchy
used in PAK and put together three improvements to it to obtain a
solution that is practical across a wide range of datasets.
1. Better Fan-out. According to Qardaji et al. [37], using a fan-
out b = 16 instead of 2 in the hierarchy can give better utility. The
result of optimal fan-out b = 16 is derived by analyzing the accuracy
(variance) of answering range queries. In particular, we assume the
range query is random and all layers in the hierarchy receive the
same amount of privacy budget. We then measure the expected
accuracy (measured by variance) of answering the range query.
The optimal value b = 16 is obtained by minimizing the variance.
It does not change on different datasets because the analysis is
data-independent. We thus use fan-out b = 16 by default.
2. Handling Infinite Streams. PAK requires a fixed length n a
priori in order to build the hierarchy. As a result, their algorithm
stops after n observations. In order to support infinite streams,
Chan et al. [8] proposed to have an infinitely high hierarchy, and
each layer receives a privacy budget inversely proportional to the
height of the layer. For example, the bottom layer receives 0.9ϵ,
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1241then its parent layer receives 0.92
ϵ, and so on. While this ensures
the overall privacy budget will never exceed ϵ, the higher layers
are essentially receiving a tiny amount of privacy budget.
In this paper, we note that most of the queries focus on limited
ranges, and propose to have an upper bound on the query range
denoted by r and then split ϵ equally to the h = ⌈logb r⌉ layers.
The value of r stands for a limit below which most queries’ ranges
fall, and is determined externally (e.g., if we receive one value per
minute, then it is unlikely that a query spans over a year). For each
chunk of r observations, we output a height-h hierarchy. We note
that each hierarchy handles a disjoint sub-stream of observations
and thus this extension does not consume additional privacy budget
because of the parallel composition property of differential privacy.
In the evaluation, we choose r = 220.
3. Online Consistency. Given a noisy hierarchy, Hay et al. [26]
proposed an efficient algorithm for enforcing consistency among
the values in it. By enforcing consistency, the accuracy of the hier-
archy can be improved. Note that this is a post-processing step and
does not consume any privacy budget. Unfortunately, the algorithm
is off-line and requires the whole hierarchy data to be available. Here
we propose an online version of the enforce-consistency algorithm,
so that we can output the noisy streams promptly.
Our method is built on the work of Hay et al. [26]. Due to space
limitation, we provide details of the algorithm in Appendix C. The
intuition is that, if we have two estimations of the same value, their
(weighted) average would be closer to the true value.
Knowing that the noisy estimates can be decomposed into true
values and pure noise, our method generates all required noise
in advance, followed by the consistency enforcement. In this way,
the consistent off-line noise can be directly added to the incoming
true values during online publishing. Because of the consistency
of both the true values and the noise, the noisy estimates will also
be consistent. Moreover, we prove that the result of our online
algorithm is equivalent to that of the off-line algorithm (the proof
is deferred Appendix C).
Theorem 3.1. The online consistency algorithm gives identical
results as the off-line consistency algorithm.
This together with the fact that the off-line consistency algorithm
can be seen as post-processing and thus satisfies DP, we can argue
that our online algorithm also satisfies DP.
3.5 Smoother
In this section, we introduce a smoother to further improve the
utility of the algorithm. Assuming the hierarchy from perturber
has h layers, the smoother is designed to replace the values from
the first s lower-level layers with predictions, which are based on
previous estimations. The first question is how to choose s.
Optimizing s. Selecting s is important. A larger s results in smaller
noise errors: because there are now h − s layers in the hierarchy,
each layer will receive more privacy budget according to sequential
composition (given in Section 2.4). On the other hand, a larger s
probably leads to a larger bias (because we are only doing the actual
estimate once every bs values; other estimates are from predictions
based on previous values, thus are independent of the true values
and less accurate). Choosing a good value of s thus is a balance
between noise errors and bias. Note that we already have noise error
term from Equation 4, but we need to calculate the bias introduced
by the smoother (the truncation bias in Equation 4 already exists
and does not change with s).
To estimate the smoothing bias, we assume that for each value,
the bias amount is approximately θ/3. We then assume there are
approximately bs/2 values in a query. Then the average squared
bias is approximated by b2s
9 . Therefore, we use the following
equation to approximate the squared error:
4 θ 2
(b − 1)(cid:0)logb(r) − s(cid:1)3 2θ
ϵ
2s
2
2 + b
4
2
θ
9 .
(7)
Given ϵ and r, s can be computed by minimizing the above error.
Smoothing Method. Given s, we now describe choices of imple-
menting the smoother. We consider a set of methods proposed in
the literature, and present their details in Appendix D. Among them,
the most straightforward one is “Recent” smoother, which predicts
the next values based on the most recent estimation. In evaluation,
we find it works the best, probably because the dataset we use is
spiky.
3.6 Summary and Discussions
In summary, our method takes the raw stream V = ⟨v1, v2, . . .⟩ as
input and outputs a private stream ˜V = ⟨ ˜v1, ˜v2, . . .⟩. Algorithm 1
gives the details of our method: We first cache the first m values and
obtain θ. Then for each of the following values, we first truncate it
and then use the hierarchical method together with the smoother
to output the noisy value.
In this paper, we focus on the setting used in PAK, where the
threshold optimizer does not publish the first m values, but uses
them to obtain θ. After the first m values, it sends θ to the perturber
and truncates any incoming value by θ. The perturber then outputs
values using the hierarchical method, and there is a smoother that
further processes the result. Our method is also flexible and can
work in other settings. We will discuss more about the flexibility of
ToPS in Section 7.
We claim that ToPS satisfies ϵ-DP. The perturber uses ϵ/h to
add Laplace noise to each layer of the hierarchical structure. By
sequential composition, the overall data structure satisfies ϵ-DP. To
find the threshold, ToPS uses a disjoint set of m observations and
runs an ϵ-DP algorithm. Due to the parallel composition property of
DP, the threshold optimizer and the perturber together satisfy ϵ-DP.
The online consistency algorithm and the smoother’s operations are
post-processing procedures and do not affect the privacy guarantee.
4 PUBLISHING STREAMS IN LDP SETTING
In this section, we introduce ToPL for publishing streaming data
under local DP (LDP). To the best of our knowledge, this is the first
algorithm that deals with this problem under LDP.
In LDP, users perturb their values locally before sending them
to the server, and thus do not need to trust the server. Applying to
the streaming values in our setting, each value should be perturbed
before being sent to the server. What the server does is only post-
processing of the perturbed reports.
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1242// Cache the first m values
// Equation 5
// Equation 6
// GSд = 1, q is monotonic
// Find θ via Noisy Max (Section 2.3)
*/
*/
Algorithm 1: ToPS
Input: V = ⟨v1, v2, . . .⟩, ϵ, m, upper bound on query range r
Output: ˜V = ⟨ ˜v1, ˜v2, . . .⟩
1 Vm ← ⟨v1, . . . vm⟩ ;
2 for θ = 1 to B do
3
5
4
ϵ
b(r) − mθ ;
mθ ← |{i | vi ≤ θ, i ∈ [m]}| ;
qθ (Vm) ← − mθ20r ϵ
˜qθ (V ) ;
(cid:113)2(b − 1) log3
˜qθ (V ) = qθ (Vm) + Lap(cid:0) 1
(cid:1) ;
(cid:104)15(cid:0)log16(r) − s(cid:1)3 2θ 2
6 θ ← arg maxθ
/* The previous part of the code finds θ .
/* Now we are ready to release the stream.
7 h ← log16 r ;
8 s ← arg mins
9 u ← 16s θ2
;
10 build ← True ;
11 foreach i > m do
12
13
14
15
vi ← min(vi, θ) ;
if build then
ϵ2 + 162s
θ 2
9
4
(cid:105) ;
ϵ
(cid:16) h−s
(cid:17) to each node ;
Init an (h − s)-layer hierarchy with fan-out 16 ;
Assign 0 to all nodes ;
Add Lap
Make the tree consistent ;
cur _node ← left-most noisy node on tree ;
build ← False ;
build ← True ;
Output cur _node − u × (16s − 1) ;
ut ← cur _node ;
cur _node ← next noisy node on tree ;
Output u/16s ;
cur _node ← cur _node + vi ;
if (i − m) mod r = 0 then
if (i − m) mod 16s = 0 then
else
16
17
18
19
20
21
22
23
24
25
26
27
28
// Equation 7
// Indicator to build a tree
// Truncate
// Build the virtual tree
// Appendix C
// Time to build another tree
// ‘‘Recent’’ smoother in Appendix D
ToPL follows the design framework of ToPS. There is a threshold
optimizer to find the threshold based on the optimal estimated
error, and the threshold is used to truncate the users’ values in the
later stage. Different from the centralized DP setting, in the local
setting, the obtained threshold will be shared with the users so
that they can truncate their values locally. The perturber section
is also run within each user’s local side, because of the privacy
requirement that no other parties other than the users themselves
can see the true data. There is no smoother section. In what follows,
we describe the construction for the threshold optimizer and the
perturber.
4.1 Design of the Threshold Optimizer
In LDP, each user only has a local view (i.e., they only know their
own data; no one has a global view of the true distribution of all
data), thus there is no Noisy Max mechanism (NM) (described in
Section 2.3) that we can use as in the DP setting. Instead, most
existing LDP algorithms rely on frequency estimation, i.e., estima-
tion of how many users possess each value, as what the Laplace
mechanism does in DP. We also rely on the frequency estimation
to find the optimal threshold. Although the distribution estima-
tion is more informative, it is actually less accurate than the Noisy
(cid:33)2
(cid:32) 
θ <t <B
Max mechanism because (to publish more information) more noise
needs to be added.
Frequency Estimation in LDP. Li et al. [33] propose the Square
Wave mechanism (SW for short) for ordinal and numerical domains.
It extends the idea of Randomized Response [49] in that values near
the true value will be reported with high probability, and those