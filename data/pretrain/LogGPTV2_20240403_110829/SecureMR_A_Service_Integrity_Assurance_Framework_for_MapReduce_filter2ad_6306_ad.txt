there is no way for it to know any duplication information
80
about the task that it handles because no duplicated tasks
have been assigned yet. Later when its collusive entities
receive the duplicated tasks, they need to return the same
results with the initial result. Otherwise, inconsistency will
be produced, which can be detected by the master. Thus,
the strategic attacker cannot misbehave because it is always
possible that the misbehavior could be detected as long as
there are duplicated tasks. However, intuitively, it delays the
execution of duplicated tasks, which may bring down the
performance of the system. In the following section, we will
evaluate the performance overhead of SecureMR under both
the naive task scheduling algorithm and the commitment-based
task scheduling algorithm.
C. Experimental Evaluation
System Implementation. We have implemented a proto-
type of SecureMR based on one existing implementation of
MapReduce, Hadoop [2]. In our prototype, we have imple-
mented both naive task scheduling algorithm and commitment-
based task scheduling algorithm mentioned in previous sec-
tions. Regarding consistency veriﬁcation, we have imple-
mented a non-blocking replication-based veriﬁcation scheme,
which means that reducers do not need to wait for all dupli-
cates of a map task to ﬁnish and users do not need to wait for
all duplicates to ﬁnish. Finally, users will be informed if an
inconsistency is detected after all duplicates ﬁnish.
Experiment Setup. We run our experiments on 14 hosts
provided by Virtual Computing Lab (VCL), a distributed
computing system with hundreds of hosts connected through
campus networks [25]. The Hadoop Distributed File System
(HDFS) is also deployed in VCL. We use 11 hosts as workers
that offer MapReduce services and one host as a master,
and HDFS uses 13 nodes, not including the master host. We
adopt the duplication strategy discussed in Section V-B. All
hosts used have similar hardware and software conﬁgurations
(2.66GHz Intel Intel(R) Core(TM) 2 Duo, Ubuntu Linux 8.04,
Sun JDK 6 and Hadoop 0.19). All experiments are conducted
by using Hadoop WordCount application [20].
Performance Analysis. First, we estimate the additional
overhead introduced by SecureMR in Table I and II. Table I
shows the performance overhead of SecureMR on the master,
a mapper and a reducer. Table II shows the additional bytes
to be transmitted on each communication between them. Note
that there are no additional messages introduced. Here, T and
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:04:27 UTC from IEEE Xplore.  Restrictions apply. 
i
)
S
(
e
m
m
T
e
s
n
o
p
s
e
R
300
250
250
200
150
100
50
50
0
0
i
)
S
(
e
m
m
T
e
s
n
o
p
s
e
R
300
250
250
200
150
100
50
50
0
0
i
)
S
(
e
m
m
T
e
s
n
o
p
s
e
R
300
250
250
200
150
100
50
50
0
0
i
)
S
(
e
m
m
T
e
s
n
o
p
s
e
R
350
300
250
200
150
100
50
0
0
20
25
30
35
40
200
400
600
800
1000
0
0.2
0.4
0.6
0.8
20
25
30
35
40
Number of Reduce Tasks
Number of Reduce Tasks
Data Size (M)
Data Size (M)
Duplication Rate
Duplication Rate
Number of Reduce Tasks
Number of Reduce Tasks
MapReduce
SecureMR without duplication
MapReduce
SecureMR without duplication
MapReduce Naive SecureMR C-based SecureMR
MapReduce
SecureMR with 40% duplication
Fig. 10. Response Time vs Number
of Reduce Tasks.
Fig. 11. Response Time vs Data Size.
Fig. 12. Response time vs Duplica-
tion Rate.
Fig. 13. Response time vs Number
of Reduce Tasks.
Type
Master
Mapper
Reducer
Cost Estimation
4 · Tsig + 3 · TEpub + Tver
2 · Tsig + TDpub + 3 · Tver +
r · Thash
2 · TDpub + 3 · Tver + Thash
Estimated Time
20ms
14 + (r + 1) · 40ms
51ms
PERFORMANCE OVERHEAD ON ENTITIES
TABLE I
duplication rate. Figure 13 shows the response time versus the
number of reduce tasks under the two scenarios, MapReduce
and SecureMR with 40% duplication rate, where the number
of map tasks is 60 and the data size is 1GB. Compared with
the no-duplication case in Figure 10, the performance overhead
caused by executing duplicated tasks ranges from 5% to 12%.
Type
Master-Mapper
Master-Reducer
Mapper-Reducer
Cost Estimation
2 · Dsig + r · Dhash
3 ·Dsig +Dhash +Dpub
3 ·Dsig +Dhash +Dpub
Additional Bytes
256 + r ∗ 20bytes
532bytes
532bytes
COMMUNICATION OVERHEAD BETWEEN ENTITIES
TABLE II
D denote the time and data transmission cost for different
secure operations such as encryption, decryption, signature,
veriﬁcation and hash. r is the number of reducers. The size
of each partition is around 14MB. We use SHA-1 to generate
hash values, and RSA to create signature or encrypt/decrypt
data. The estimation shows that the cost of communication is
negligible and the cost on each entity is small.
We also conduct experiments to evaluate the performance
overhead caused by SecureMR. Figure 10 shows the response
time versus the number of reduce tasks under two scenarios,
MapReduce and SecureMR without duplication, where the
number of map tasks is 60 and the data size is 1GB. The result
shows that the overhead of SecureMR is below 10 seconds,
which is small compared with the response time which is about
250 seconds. Figure 11 shows the response time versus the
data size, where the number of map tasks is 60 and the number
of reduce tasks is 25. Since the data size only affects the time
to generate hash values, it shows a similar overhead in Figure
10.
Regarding the performance overhead by executing dupli-
cated tasks, we compare the response time in three cases:
MapReduce, SecureMR with naive scheduling, and SecureMR
with commitment-based scheduling. Figure 12 shows the re-
sponse time versus the duplication rate. Since we adopts a
non-blocking veriﬁcation mechanism, the difference between
two scheduling algorithms is very small. The result shows
that the time overhead increases slowly with the increase of
81
VI. RELATED WORK
MapReduce recently has received a great amount of at-
tention for its simple model and parallel computation capa-
bility for data intensive computation in different application
and research areas. Chu et al. [6] applied MapReduce to
the multicore computation for machine learning. Ekanayake
et al. [4] applied MapReduce technique for two scientiﬁc
analyses, High Energy Physics data analyses and Kmeans
clustering. Mackey et al. [3] utilized MapReduce for High
End Computing applications. Most of them focus on how
to utilize MapReduce to solve issues or problems in speciﬁc
application domains. Few work pays attention to the service
integrity protection in MapReduce. SecureMR provides a set
of practical security mechanisms to ensure MapReduce data
processing service integrity.
Service integrity issues addressed in this paper also share
similarity with the problem addressed in [13]–[19]. Du et
al. [13] used sampling techniques to achieve efﬁcient and
viable uncheatable grid computing. Zhao et al. [14] pro-
posed a scheme called Quiz to combat collusion for result
veriﬁcation. Sarmenta et al.
[15] introduced majority vot-
ing, and spot-checking techniques, and presented credibility-
based fault tolerance. Although several existing techniques
have been proposed to address the service integrity issues
in different application areas [11], [13], [26], the integrity
assurance for MapReduce data processing service presents its
unique challenges like massive data processing and multi-party
distributed computation. SecureMR adopts a new decentralized
replication-based integrity veriﬁcation scheme to address these
new challenges, which fully utilizes the existing architecture
of MapReduce.
Regarding system security, Srivatsa and Liu proposed a
suite of security guards and a resilient network design to
secure content-based publish-subscribe systems [27]. PeerRe-
view [28] system ensures that Byzantine faults observed by a
correct node are eventually detected and irrefutably linked to a
faulty node in a distributed messaging system. Swamynathan
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:04:27 UTC from IEEE Xplore.  Restrictions apply. 
et. al. proposed a scheme to improve the accuracy of reputation
systems using a statistical metric to measure the reliability
of a peer’s reputation [29]. Different from previous works,
SecureMR is based on a trustworthy master and leverages
natural redundancy of map and reduce services and existing
MapReduce data processing mechanisms to perform compre-
hensive consistency veriﬁcation.
VII. CONCLUSION AND FUTURE WORK
In this paper, we have presented SecureMR, a practical
service integrity assurance framework for MapReduce. We
have implemented a scalable decentralized replication-based
veriﬁcation scheme to protect the integrity of MapReduce data
processing service. To the best of our knowledge, our work
makes the ﬁrst attempt to address this problem. Based on
Hadoop [2], we have implemented a prototype of SecureMR,
proved its security properties, evaluated the performance im-
pact resulted from the proposed scheme, and tested it on
a real distributed computing system with hundreds of hosts
connected through campus networks. Our initial experimen-
tal results show that the proposed scheme can ensure data
processing service integrity while imposing low performance
overhead.
However, although SecureMR provides an effective way to
detect misbehavior of malicious workers, it is impossible to de-
tect any inconsistency when all duplicated tasks are processed
by a collusive group. In order to counter this collusion attack,
we may resort to sampling techniques. We believe that the
unique properties of MapReduce may bring new opportunities
and challenges to adopt such new techniques.
ACKNOWLEDGMENT
This work is supported by the U.S. Army Research Ofﬁce
under grant W911NF-08-1-0105 managed by NCSU Secure
Open Systems Initiative (SOSI) and by the NSF under grant
IIS-0430166. The contents of this paper do not necessarily
reﬂect the position or the policies of the U.S. Government.
REFERENCES
[1] J. Dean and S. Ghemawat, “Mapreduce: simpliﬁed data processing
on large clusters,” in OSDI’04: Proceedings of the 6th conference on
Symposium on Opearting Systems Design & Implementation. Berkeley,
CA, USA: USENIX Association, 2004, pp. 10–10.
[2] “Hadoop
Tutorial,”
tutorial/start-tutorial.html.
http://public.yahoo.com/gogate/hadoop-
[3] G. Mackey, S. Sehrish, J. Lopez, J. Bent, S. Habib, and J. Wang,
“Introducing mapreduce to high end computing,” in Petascale Data
Storage Workshop Held in conjunction with SC08, 2008.
[4] J. Ekanayake, S. Pallickara, and G. Fox, “Mapreduce for data intensive
scientiﬁc analysis,” in eScience, 2008. eScience ’08. IEEE Fourth
International Conference on, 2008, pp. 277–284.
[5] M. Laclav´ık, M. ˇSeleng, and L. Hluch´y, “Towards large scale semantic
annotation built on mapreduce architecture,” in ICCS ’08: Proceedings
of the 8th international conference on Computational Science, Part III.
Berlin, Heidelberg: Springer-Verlag, 2008, pp. 331–338.
[6] C. T. Chu, S. K. Kim, Y. A. Lin, Y. Yu, G. R. Bradski,
A. Y. Ng, and K. Olukotun, “Map-reduce for machine learning on
multicore,” in NIPS, B. Sch¨olkopf, J. C. Platt, and T. Hoffman, Eds.
MIT Press, 2006, pp. 281–288. [Online]. Available: http://dblp.uni-
trier.de/rec/bibtex/conf/nips/ChuKLYBNO06
82
[7] G. A. amd F. Casati, H. Kuno, and V. Machiraju, “Web Services
Concepts, Architectures and Applications Series: Data-Centric Systems
and Applications,” Addison-Wesley Professional, 2002.
[8] T. Erl, “Service-Oriented Architecture (SOA): Concepts, Technology,
and Design,” Prentice Hall, 2005.
[9] “Amazon Elastic Compute Cloud,” http://aws.amazon.com/ec2/.
[10] D.
P. Anderson,
“Boinc:
a
system for
public-resource
[Online]. Available:
computing and storage,” 2004, pp. 4–10.
http://dx.doi.org/10.1109/GRID.2004.14
[11] “SETI@home.” http://setiathome.ssl.berkeley.edu/.
[12] “Amazon Elastic MapReduce,” http://docs.amazonwebservices.com/Elastic-
MapReduce/latest/DeveloperGuide/index.html.
[13] W. Du, J. Jia, M. Mangal, and M. Murugesan, “Uncheatable grid com-
puting,” in ICDCS ’04: Proceedings of the 24th International Conference
on Distributed Computing Systems (ICDCS’04). Washington, DC, USA:
IEEE Computer Society, 2004, pp. 4–11.
[14] S. Zhao, V. Lo, and C. GauthierDickey, “Result veriﬁcation and trust-
based scheduling in peer-to-peer grids,” in P2P ’05: Proceedings of
the Fifth IEEE International Conference on Peer-to-Peer Computing.
Washington, DC, USA: IEEE Computer Society, 2005, pp. 31–38.
[15] L. F. G. Sarmenta, “Sabotage-tolerance mechanisms for volunteer
Systems,
Computer
[Online]. Available:
computing
vol.
18,
citeseer.ist.psu.edu/sarmenta02sabotagetolerance.html
systems,”
no.
Future Generation
2002.
561–572,
4,
pp.
[16] C. Germain-Renaud and D. Monnier-Ragaigne, “Grid result checking,”
in CF ’05: Proceedings of the 2nd conference on Computing frontiers.
New York, NY, USA: ACM, 2005, pp. 87–96.
[17] P. Domingues, B. Sousa, and L. Moura Silva, “Sabotage-tolerance and
trust management in desktop grid computing,” Future Gener. Comput.
Syst., vol. 23, no. 7, pp. 904–912, 2007.
[18] P. Golle and S. Stubblebine, “Secure distributed computing in a
commercial environment,” in 5th International Conference Financial
Cryptography (FC. Springer-Verlag, 2001, pp. 289–304.
[19] P. Golle and I. Mironov, “Uncheatable distributed computations,” in CT-
RSA 2001: Proceedings of the 2001 Conference on Topics in Cryptology.
London, UK: Springer-Verlag, 2001, pp. 425–440.
[20] “WordCount, Hadoop,” http://wiki.apache.org/hadoop/WordCount.
[21] M. J. Atallah, Y. Cho, and A. Kundu, “Efﬁcient data authentication
in an environment of untrusted third-party distributors,” in ICDE ’08:
Proceedings of the 2008 IEEE 24th International Conference on Data
Engineering. Washington, DC, USA: IEEE Computer Society, 2008,
pp. 696–704.
[22] K. Fu, M. F. Kaashoek, and D. Mazi`eres, “Fast and secure distributed
read-only ﬁle system,” ACM Trans. Comput. Syst., vol. 20, no. 1, pp.
1–24, 2002.
[23] P. Devanbu, M. Gertz, C. Martel, and S. G. Stubblebine, “Authentic
third-party data publication,” in In Fourteenth IFIP 11.3 Conference on
Database Security, 1999, pp. 101–112.
[24] Q. Zhang, T. Yu, and P. Ning, “A framework for identifying compro-
mised nodes in wireless sensor networks,” ACM Trans. Inf. Syst. Secur.,
vol. 11, no. 3, pp. 1–37, 2008.
[25] “Virtual Computing Lab,” http://vcl.ncsu.edu/.
[26] D. Szajda, B. Lawson, and J. Owen, “Toward an optimal redundancy
strategy for distributed computations,” in Cluster Computing, 2005.
IEEE International, Sept. 2005, pp. 1–11.
[27] M. Srivatsa and L. Liu, “Securing publish-subscribe overlay services
with eventguard,” in CCS ’05: Proceedings of the 12th ACM conference
on Computer and communications security.
New York, NY, USA:
ACM, 2005, pp. 289–298.
[28] A. Haeberlen, P. Kouznetsov, and P. Druschel, “Peerreview: practical
accountability for distributed systems,” in SOSP ’07: Proceedings of
twenty-ﬁrst ACM SIGOPS symposium on Operating systems principles.
New York, NY, USA: ACM, 2007, pp. 175–188. [Online]. Available:
http://dx.doi.org/10.1145/1294261.1294279
[29] G. Swamynathan, B. Zhao, K. Almeroth, and S. Jammalamadaka, “To-
wards reliable reputations for dynamic networked systems,” in Reliable
Distributed Systems, 2008. SRDS ’08. IEEE Symposium on, Oct. 2008,
pp. 195–204.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:04:27 UTC from IEEE Xplore.  Restrictions apply.