[41] Lee Young Jun, Choi Sang-Hoon, Kim Chulwoo, Lim Seung-Ho, and Park Ki-
Woong. 2017. Learning Binary Code with Deep Learning to Detect Software
Weakness. In KSII The 9th International Conference on Internet (ICONI) 2017
Symposium.
[42] Zeping Yu, Rui Cao, Qiyi Tang, Sen Nie, Junzhou Huang, and Shi Wu. 2020. Order
Matters: Semantic-Aware Neural Networks for Binary Code Similarity Detection.
In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 1145–1152.
[43] Fei Zuo, Xiaopeng Li, Zhexin Zhang, Patrick Young, Lannan Luo, and Qiang Zeng.
2019. Neural Machine Translation Inspired Binary Code Similarity Comparison
beyond Function Pairs. In NDSS.
A OPCODE AND OPERAND TYPES FOR
OUTLIER DETECTION
Table 8 shows how we categorize different opcodes by referring
to [29]. Table 9 shows how we categorize different operand types.
The first column shows the type of operands combination. “none”
means the instruction has no operand, such as retn. “tri” means the
instruction has three operands. The other ones are instructions that
have two operands. For instance, “reg-reg” means both operands
are registers. The type of each operand has been listed in the second
and third columns.
B MORE FIGURES IN EVALUATIONS
Figure 15 and Figure 16 show the results of EKLAVYA in the Func-
tion Type Signature Inference task. Figure 15 is the loss value curves
Session 12A: Applications and Privacy of ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3249Table 8: Types of Opcodes
Table 9: Types of Operands
Types
Data Movement
Unary Operations
Binary Operations
Shift Operations
Special Arithmetic
Operations
Comparison and Test
Instructions
Conditional Set
Instructions
Jump Instructions
Conditional Move
Instructions
Procedure Call
Instructions
String Instructions
Floating Point
Arithmetic
Opcodes
mov, push, pop, cwtl, cltq, cqto,
cqtd
inc, dec, neg, not
lea, leaq, add, sub,imul, xor, or,
and
sal, sar, shr, shl
imulq, mulq, idivq, divq
cmp, test
sete, setz, setne, setnz, sets,
setns, setg, setnle,setge, setnl,
setl, setnge,setle, setng, seta,
setnbe, setae, setnb, setbe, setna
jmp, je, jz, jne, jnz, js, jns, jg,
jnle, jge, jnl, jl jnge, jle, jng, ja,
jnbe, jae, jnb, jb, jnae, jbe, jna
cmovne,
cmove,
cmovns,
cmovenz,
cmovge,
cmovg,
cmovle,
cmovnl,
cmovng,
cmovnbe,
cmovae,
cmovb,
cmovnae, cmovbe, cmovna
call, leave, ret, retn
cmovz,
cmovs,
cmovnle,
cmovnge,
cmova,
cmovnb,
cmps, cmpsb, cmpsl, cmpsw,
lods, lodsb, lodsl, lodsw,mov,
movsb, movsl, movsw
fabs, fadd, faddp, fchs, fdiv,
fdivp, fdivr, fdivrp, fiadd, fidivr,
fimul, fisub, fisubr, fmul, fmulp,
fprem, fpreml,frndint, fscale,
fsqrt, fsub,fsubp, fsubr, fsubrp,
fxtract
Figure 15: Loss value during training
of EKLAVYA during training. Figure 16 shows the accuracy curves
during the training.
Type
none
addr
ref
reg-reg
reg-addr
reg-cnst
reg-ref
ref-cnst
ref-reg
tri
Operand 1 Operand 2
# of Operands
-
address
memory
reference
register
register
register
register
memory
reference
memory
reference
-
-
-
-
register
register
constant
value
memory
reference
constant
value
register
-
0
1
1
2
2
2
2
2
2
3
Figure 16: Accuracy during training
C HYPERPARAMETERS
C.1 Embedding sizes
In this experiment, we evaluate the performance of PalmTree with
different embedding sizes. Here we use 64, 128, 256, and 512 as
instruction sizes, which is the same as the previous experiment. We
test these 4 models on our intrinsic evaluation tasks.
Table 10 shows all of the results of intrinsic evaluation when
having different embedding sizes. From the results, we can observe
that there is a clear trend that the performance becomes better
when increasing the embedding size. The largest embedding size
has the best performance in all three metrics. However, considering
efficiency, we recommend having a suitable embedding size config-
uration according to the hardware capacities. For example, we only
have a single GPU (GTX 2080Ti) in our server, thus we chose 128
as the embedding size.
C.2 Output layer configurations
In this experiment, we evaluate the performance of PalmTree with
different output layer configurations. It means that we select a dif-
ferent layer of the transformer model as the output of PalmTree.
By default, PalmTree uses the second-last layer as the output layer.
And we evaluate five different settings, which are the last layer, the
02004006008001000Iterations0.00.51.01.52.02.5Loss valueone-hotInstruction2Vecword2vecAsm2VecPᴀʟᴍTʀᴇᴇ-MPᴀʟᴍTʀᴇᴇ-MCPᴀʟᴍTʀᴇᴇ02004006008001000Iterations0.00.20.40.60.81.0Accuracyone-hotInstruction2Vecword2vecAsm2VecPᴀʟᴍTʀᴇᴇ-MPᴀʟᴍTʀᴇᴇ-MCPᴀʟᴍTʀᴇᴇSession 12A: Applications and Privacy of ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3250Table 10: Embedding sizes
Embedding
Sizes
64
128
256
512
opcode outlier
operand outlier
detection
detecion
Avg.
0.836
0.871
0.848
0.878
Stdev.
0.0588
0.0440
0.0560
0.0525
Avg.
0.940
0.944
0.954
0.957
Stdev.
0.0387
0.0343
0.0343
0.0335
basicblock
sim search
AUC
0.917
0.922
0.929
0.929
second-last layer, the third-last layer, and the fourth-last layer, on
our intrinsic evaluation tasks. The embedding size in this experi-
ment is set as 128.
Table 11: Output layer configurations
Layers
last
2nd-last
3rd-last
4th-last
Avg.
0.862
0.871
0.868
0.866
Stdev.
0.0460
0.0440
0.0391
0.0395
Avg.
0.982
0.944
0.956
0.961
opcode outlier
operand outlier
detection
detecion
basicblock
sim search
AUC
0.915
0.922
0.918
0.913
Stdev.
0.0140
0.0343
0.0287
0.0248
Table 11 shows all of the results of the intrinsic metrics when
having a different layer as the output layer. There is no obvious
advantage to choose any layer as the output layer. However, the
second-last layer has the best results in opcode outlier detection
and basicblock similarity search. Thus we chose the second-last
layer as the output layer in this paper.
C.3 Context window for CWP
Table 12: Context Window Sizes
opcode
outlier
Avg.
0.864
0.871
0.849
0.864
Stdev.
0.0467
0.0440
0.0444
0.0440
operand
outlier
Avg.
0.962
0.944
0.873
0.957
Stdev.
0.0168
0.0343
0.0514
0.0238
bb sim
search
AUC
0.923
0.922
0.916
0.914
EKLAVYA
Stdev.
Avg.
0.0548
0.930
0.0476
0.945
0.0633
0.908
0.916
0.0548
Sizes
1
2
3
4
In this experiment, we evaluate the performance of PalmTree
with different context window sizes in the CWP task. For instance,
if the context window size is 2, it means that we consider n−2, n−1,
n + 1 and n + 2 as contextual instruction when given instruction
n as a sample. We evaluate 1, 2, 3, and 4 as four different context
window sizes in this experiment. Table 12 shows all of the results of
the intrinsic metrics when training PalmTree with different context
window configurations. We can observe that context window size
1 and 2 have similar performance on the three intrinsic evaluation
metrics, but context window size 2 has the best performance on
the downstream task EKLAVYA. Further increasing the context
window size to 3 and 4 will lead to worse results. Based on these
results, we choose the context window size to be 2.
Session 12A: Applications and Privacy of ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3251