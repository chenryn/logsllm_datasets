p1(kj , kx) + p1(kj , ky) > τ. Suppose the la(cid:138)er case is true, the next
thing to check is whether kx and ky are log keys produced by con-
current threads in task T1. If they are, pd(kj , kx) always increases
with larger d values, i.e., p2(kj , kx) > p1(kj , kx), which is intuitive
because the appearance ordering of keys from concurrent threads
is not certain. Otherwise kx and ky do not belong to T1, thus we
add T2 = [kj , kx] and T3 = [kj , ky] into T ASK instead.
Finally, for each task T in T ASK, we eliminate T if its sequence
is included as a sub-sequence in another task.
4.3.2 Build workflow model. Once a log key sequence is sep-
arated out and identi(cid:128)ed for each task, the work(cid:131)ow model con-
struction for a task follows the same discussion from Section 4.2.2.
4.4 Using the work(cid:131)ow model
4.4.2 Using workflow to diagnose detected anomalies. Whenever
an anomaly is detected by DeepLog, the work(cid:131)ow model can be
used to help diagnose this anomaly and understand how and why
it has happened. Figure 5 shows an example. Using a history
sequence [26, 37, 38], the top prediction from DeepLog is log key
39 (suppose ❕ = 1), however the actual log key appeared is 67,
which is an anomaly. With the help of a work(cid:131)ow model for this
4.4.1
Set parameters for DeepLog model. In Section 3.1, we’ve
shown that DeepLog requires several input parameters, in particu-
lar, it needs the length of history sequence window h (for training
and detection), and the number of top ❕ log keys in the predicted
output probability distribution function to be considered normal.
Se(cid:138)ing a proper value for h and ❕ is problem dependent. Gen-
erally speaking, larger h values will increase the prediction accu-
racy because more history information is utilized in LSTM, until
it reaches a point where keys that are far back in history do not
contribute to the prediction of keys to appear. At this point contin-
uing to increase h does not hurt the prediction accuracy of LSTM,
because LSTM is able to learn that only the recent history in a long
sequence ma(cid:138)ers thus ignore the long tail. However, a large h value
does have a performance impact. More computations (and layers)
are required for both training and prediction, which slows down
the performance of DeepLog. (cid:140)e value of ❕, on the other hand,
regulates the trade-o(cid:130) between true positives (anomaly detection
rate) and false positives (false alarm rate).
(cid:140)e work(cid:131)ow model provides a guidance to set a proper value
for both h and ❕. Intuitively, h needs to be just large enough to
incorporate necessary dependencies for making a good prediction,
so we can set h as the length of the shortest work(cid:131)ow. (cid:140)e number
of possible execution paths represents a good value for ❕, hence, we
set ❕ as the maximum number of branches at all divergence points
from the work(cid:131)ows of all tasks.
Figure 5: Anomaly diagnosis using work(cid:131)ow.
task, users could easily identify the current execution point in
the corresponding work(cid:131)ow, and further discover that this error
happened right a(cid:137)er “Instance destroyed successfully” and before
“Deleting instance (cid:128)les *”, which means that this error occurred
during cleanup a(cid:137)er destroying a VM.
4.5 Discussion
Previous works [4, 21, 42] focused on constructing work(cid:131)ows from
multiple executions of just one task. (cid:140)e basic idea in their approach
follows 3 steps: 1) mine temporal dependencies of each pair of log
keys; 2) construct a basic work(cid:131)ow from the pairwise invariants
identi(cid:128)ed in step 1; 3) re(cid:128)ne work(cid:131)ow model using the input log key
sequence. A major limitation is that they are not able to work with
a log sequence that contains multiple tasks or concurrent threads
in one task, which is addressed by our study. Our task separation
methodology also provides useful insights towards the work(cid:131)ow
construction for each task.
5 EVALUATION
DeepLog is implemented using Keras [6] with TensorFlow [2] as the
backend. In this section, we show evaluations of each component
and the overall performance of DeepLog, to show its e(cid:130)ectiveness
in (cid:128)nding anomalies from large system log data.
5.1 Execution path anomaly detection
(cid:140)is section focuses on evaluating the log key anomaly detection
model in DeepLog. We (cid:128)rst compare its e(cid:130)ectiveness on large
system logs with previous methods, and then investigate the impact
of di(cid:130)erent parameters in DeepLog.
5.1.1 Previous methods. Previous work on general-purpose log
anomaly detection follows a similar procedure: they (cid:128)rst extract a
log key from each log message, and then perform anomaly detection
on the log key sequence.
(cid:140)e Principal Component Analysis (PCA) method [39] assumes
that there are di(cid:130)erent “sessions” in a log (cid:128)le that can be easily
identi(cid:128)ed by a session id a(cid:138)ached to each log entry. It (cid:128)rst groups
log keys by session and then counts the number of appearances
of each log key value inside each session. A session vector is of
size n, representing the number of appearances for each log key
in K in that session. A matrix is formed where each column is
a log key, and each row is one session vector. PCA detects an
abnormal vector (a session) by measuring the projection length
on the residual subspace of transformed coordinate system. (cid:140)is
approach is shown to be more e(cid:130)ective than its online counterpart
26373839404167Actual ExecutionPrediction (Correct Path)37: instance: * Terminating instance38: instance: * Instance destroyed successfully39: instance: * Deleting instance files *40: instance: * Deletion of * complete41: instance: * Took * seconds to destroy the instance on the hypervisor67: instance: * Error from libvirt during unfilter. Code=* Error=*online PCA [38] especially in reducing false positives, but this is
clearly an o(cid:132)ine method and cannot be used for online anomaly
detection. (cid:140)e implementation is open-sourced by [17].
Invariant Mining (IM) [22] constructs the same matrix as the PCA
approach does. IM (cid:128)rst mines small invariants that could be satis(cid:128)ed
by the majority of vectors, and then treats those vectors that do
not satisfy these invariants as abnormal execution sessions. (cid:140)is
approach is shown to be more e(cid:130)ective than an earlier work [11]
which utilizes work(cid:131)ow automata. (cid:140)e implementation is open-
sourced by [17].
TFIDF is developed in [44]. Although its objective is for IT system
failure prediction, which is di(cid:130)erent from anomaly detection as
shown in [39]. Nevertheless, we still included this method in our
evaluation as it also uses a LSTM-based approach. (cid:140)ere are several
key di(cid:130)erences. TFIDF groups log keys by time windows (each time
window is de(cid:128)ned by a user parameter), and then models each time
window (called “epoch”) using a TF-IDF (term-frequency, inverse
document frequency) vector. (cid:140)e Laplace smoothing procedure it
uses requires the knowledge of the total number of epochs (hence
the entire log (cid:128)le). TFIDF constructs a LSTM model as a binary
classi(cid:128)er, which needs both labeled normal and abnormal data for
training. Not only are anomaly log entries hard to obtain, but also,
new types of anomalies that are not included in training data may
not be detected. In contrast, DeepLog trains its LSTM model to be
a multi-class classi(cid:128)er, and only requires normal data to train.
CloudSeer is a method designed speci(cid:128)cally for multi-user Open-
Stack log [42]. It builds a work(cid:131)ow model for each OpenStack VM-
related task and uses the work(cid:131)ow for anomaly detection. (cid:140)ough it
achieves acceptable performance on OpenStack logs (a precision of
83.08% and a recall of 90.00% as reported in the paper), this method
does not work for other types of logs (e.g., HDFS log) where the
pa(cid:138)erns of log keys are much more irregular. For example, Cloud-
Seer only models log keys that “appear the same number of times”
in every session. In HDFS logs, only 3 out of 29 log keys satisfy
this criterion. Furthermore, this method cannot separate log entries
for di(cid:130)erent tasks in one log into separate sequences. It relies on
multiple identi(cid:128)ers to achieve this, which is not always possible for
general-purpose logs. (cid:140)us it is not compared against here.
5.1.2 Log data sets and set up.
HDFS log data set. It is generated through running Hadoop-based
map-reduce jobs on more than 200 Amazon’s EC2 nodes, and la-
beled by Hadoop domain experts. Among 11, 197, 954 log entries
being collected, about 2.9% are abnormal, including events such
as “write exception”. (cid:140)is was the main data set (cid:128)rstly used by an
o(cid:132)ine PCA-based [39] method, and subsequently used by several
other work including online PCA [38] and IM-based [22] methods.
Details of this dataset could be found in [38, 39].
OpenStack log data set. We deployed an OpenStack experiment
(version Mitaka) on CloudLab [30] with one control node, one net-
work node and eight compute nodes. Among 1, 335, 318 log entries
collected, about 7% are abnormal. A script was running to con-
stantly execute VM-related tasks, including VM creation/deletion,
stop/start, pause/unpause and suspend/resume. VM tasks were
scheduled with the pa(cid:138)ern of a regular expression (Create (Stop Start)
{0,3} (Pause Unpause) {0,3} (Suspend Resume) {0,3} Delete)+. A VM life
cycle starts with “VM create” and ends with “VM delete”, while task
pairs such as “Stop-Start”, “Pause-Unpause” and “Suspend-Resume”
may randomly appear from 0 to 3 times within a life cycle. INFO
level logs from nova-api, nova-scheduler and nova-compute were
collected and forwarded for analysis using Elastic Stack [33]. (cid:140)ree
types of anomalies were injected at di(cid:130)erent execution points: 1)
neutron timeout during VM creation; 2) libvirt error while destroy-
ing a VM; 3) libvirt error during cleanup a(cid:137)er destroying a VM.
Set up. To execute PCA-based and IM-based methods, we group
log entries into di(cid:130)erent sessions by an identi(cid:128)er (cid:128)eld, which for
HDFS log is block_id and for OpenStack log is instance_id. Each
session group is a life cycle of one block or a VM instance respec-
tively. We then parse each log entry into a log key. DeepLog can be
applied directly on log keys to train its weights and subsequently
be used to detect anomalies, while other methods require one more
step. (cid:140)ey need to count the number of appearances for each dis-
tinct log key within each session, and build a matrix where each
column is a distinct log key (so there will be n columns) and each
row represents a session vector, and the value of a cell Vij in the
matrix represents the count of log key kj in the i-th session.
DeepLog needs a small fraction of normal log entries to train its
model. In the case of HDFS log, only less than 1% of normal sessions
(4,855 sessions parsed from the (cid:128)rst 100,000 log entries compared
to a total of 11,197,954) are used for training. Note that DeepLog
can pinpoint which log entry (with its corresponding log key) is
abnormal, but in order to use the same measures to compare with
competing methods, we use “session” as the granularity of anomaly
detection, i.e., a session C is considered an abnormal session as long
as there exists at least one log key from C being detected abnormal.
Table 3 summarizes the two data sets. Note that PCA and IM
are unsupervised o(cid:132)ine methods that do not require training data,
whereas DeepLog only needs a training data produced by normal
system execution, and TFIDF requires both normal and abnormal
data to train.
Log
data set
HDFS
Number of sessions
Training data (if needed)
4,855 normal;
1,638 abnormal
Test data
553,366 normal;
15,200 abnormal
5,990 normal;
453 abnormal
n: Number
of log keys
29
40
OpenStack 831 normal;
50 abnormal
Table 3: Set up of log data sets (unit: session).
In addition to the number of false positives (FP) and false nega-
tives (FN), we also use standard metrics such as Precision, Recall
and F-measure. Precision= TP
TP+FP (TP stands for true positive) shows
the percentage of true anomalies among all anomalies detected;
Recall= TP
TP+FN measures the percentage of anomalies in the data
set (assume that we know the ground-truth) being detected; and
F-measure= 2·Precision·Recall
Precision+Recall
is the harmonic mean of the two.
By default, we use the following parameter values for DeepLog:
❕ = 9, h = 10, L = 2, and α = 64 and investigate their impacts
in our experiments. Recall ❕ decides the cuto(cid:130) in the prediction
output to be considered normal (i.e., the ❕ log key values with top-❕
probabilities to appear next are considered normal), and h is the
window size used for training and detection. L and α denote the
number of layers in DeepLog and the number of memory units in
one LSTM block respectively. For all other methods, we explored
false positive (FP)
false negative (FN)
833
619
Table 4: Number of FPs and FNs on HDFS log.
2122
1217
TFIDF N-gram DeepLog
95833
1256
1360
739
PCA IM
277
5400
their parameter space and report their best results. When the N-
gram method is used, we set N = 1 unless otherwise speci(cid:128)ed since
this shows the best performance for the N-gram method.
5.1.3 Comparison. Table 4 shows the number of false positives
and false negatives for each method on HDFS data. PCA achieves
the fewest false positives, but at the price of more false negatives.
Figure 6a shows a more in-depth comparison using recall, precision
and F-measure. Note that TFIDF is omi(cid:136)ed from this (cid:128)gure because
of limited space and its very poor relative performance.
Clearly, DeepLog has achieved the best overall performance, with
an F-measure of 96%. Our baseline solution N-gram also achieves
good performance when history length is 1. But, its performance