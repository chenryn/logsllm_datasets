0.927
0.854
Arch.
DistiBERT
BERT
MobileBERT
RoBERTa
DistilBERT
BERT
MobileBERT
RoBERTa
0.267 0.936
0.296 0.943
0.321
0.92
TN
24
22
23
24
48
44
48
46
FN
1
1
2
4
8
6
7
12
TP
23
23
22
20
40
42
41
36
FP
0
2
1
0
0
4
0
2
CE Loss
ROC-AUC
TrojAI R7
train
TrojAI R7
test
PICCOLO
TABLE IV: TrojAI leaderboard results
Other best
CE Loss
ROC-AUC
0.956 0.252
0.918 0.362
0.917
0.33
0.241 0.958
0.404 0.919
0.343 0.908
Test Holdout Test Holdout Test Holdout Test Holdout
0.964
Round5 0.325
Round6 0.255
0.907
Round7 0.297
0.895
that beats the IARPA round goal (i.e., CE loss lower than
0.3465) for rounds 6 and 7. It passes round 5 as well with
a performance boosting classiﬁer (which will be explained
later). It is also the only solution that passes round 6 with
signiﬁcantly better CE loss than others. As far as we know,
the best solutions from the other performers rely on classiﬁers
trained on the training set models. In round 5, the training,
test, and holdout sets have substantial overlap in the triggers
injected. As such, classiﬁers based methods have advantages.
PICCOLO does not rely on classiﬁers in general and the results
reported in Tables II and III do not make use of classiﬁer.
However, our round 5 submission to the leaderboard uses a
classiﬁer on the CLS dimension importance results to boost
performance, which explains the better leaderboard results
than those in Table II. In fact, we consider round 5 the hardest
due to the long and meaningful triggers, if the overlapping
triggers are not exploited.
Exposing Injected Triggers. We further study the triggers
exposed by various techniques. Speciﬁcally, we rank words
based on their inverted possibilities (of being a trigger word)
and inspect the ranks of the ground truth trigger words. T-
miner produces a list of candidate words with their frequencies
of appearing in generated perturbations. It ranks words based
on their frequencies. When a trigger has multiple words, we
report the one with the highest rank.
Table V shows the trigger word rankings for the TrojAI
round 6 training set. Here, the ranking means where a ground
truth trigger word ranks among all the inverted words. More
speciﬁcally, PICCOLO, GBDA, and T-miner invert a set of
candidate trigger words and list them in the descending order
according to their probability (of being a true trigger word).
For each model, we check whether the ground truth trigger
word is in the top 10/20/100 in the list. We then count the
T-miner on 100 randomly sampled models for TrojAI test sets.
We will release the random seed for selecting these models.
Observe that PICCOLO can achieve >0.85 detection accuracy
for all the evaluation sets, whereas the state-of-the-art methods
GBDA and T-miner only have at most 0.79 accuracy for most
cases. Particularly, for the DistilBERT models in TrojAI round
6 test set, GBDA has only 0.646 accuracy and T-miner has
only 0.53 accuracy. PICCOLO, on the other hand, can achieve
0.917 accuracy, signiﬁcantly outperforming the two baselines.
The number of false negatives by PICCOLO (1-35) is smaller
than GBDA (2-114) and T-miner (8-329), especially on the
TrojAI round 5 training set. For the NER tasks in TrojAI round
7, PICCOLO has consistent results with the overall detection
accuracy around 0.9 for most models. Comparing the results of
PICCOLO across different evaluation sets, PICCOLO performs
slightly worse on TrojAI round 5. This is largely due to
the existence of long and semantically complex phrase and
sentence triggers in round 5. Also observe that T-miner has
0.88 accuracy on the T-miner models, lower than that reported
in their paper [38]. The reason is that the reported results are
for only a subset of the models. We have cross-validated that
the results on the subset are consistent.
TrojAI Leaderboard. Table IV shows the leaderboard results.
The ﬁrst column shows the round number. Columns 2-3 show
the cross entropy (CE) loss on the test and holdout sets.
Columns 4-5 show the ROC-AUC. Columns 6-9 show the best
results from the other performers. In rounds 6 and 7, PICCOLO
achieves the top performance4. PICCOLO is the only solution
4TrojAI ranks the performance of submissions based on the CE loss.
Intuitively, the loss increases when the model classiﬁcation diverges from
the ground truth. A smaller loss suggests better performance [39]. Past
leaderboard results can be found at [56].
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:56:09 UTC from IEEE Xplore.  Restrictions apply. 
112035
TABLE V: Ranks of trigger words on R6 training set
DistilBERT (T:12)
GPT (T:12)
PICCOLO GBDA T-miner
PICCOLO GBDA T-miner
6
4
2
0
69
0
0
1
11
-
10
1
0
1
1
2
1
8
2550
8022
0
0
0
12
-
3
0
1
8
941
Top 10
10 - 20
20 - 100
Over 100
Lowest Rank
number of models that have the ground truth trigger in the top
10/20/100. A good inversion method should have ground truth
trigger words ranked as high as possible. The ﬁrst row shows
the architectures and the number of trojaned models (12).
The second row shows the different methods. Rows 3-6 show
different rank intervals and the number of trojaned models
whose highest ranked trigger word falls in the corresponding
interval. Row 7 shows the lowest rank of ground truth trigger
word among the 12 trojaned models. T-miner misses trigger
words and hence does not have a lowest rank. Observe that
for 10 out of 12 models, PICCOLO can ﬁnd at least one trigger
word in the top 10 candidate list on DistilBERT, and in the top
20 on GPT. PICCOLO fails to ﬁnd the trigger word in the top
100 for only one model. GBDA, on the other hand, can ﬁnd
one trigger word in the top 20 for only three models on both
DistilBERT and GPT. T-miner cannot ﬁnd any trigger words
in the top 20. Appendix IX-I also studies the effectiveness of
the tools for various kinds of backdoors.
C. Efﬁciency of PICCOLO
Table IX (in Appendix) shows the time cost of PICCOLO,
GBDA and T-miner. PICCOLO only takes a few hundred
seconds on sentiment classiﬁcation models , similar to GBDA.
It is about 10x faster than T-miner. On the T-miner models,
PICCOLO is 50x faster than T-miner. For the complex NER
tasks, PICCOLO can ﬁnish scanning within 10 minutes for all
the evaluated architectures.
D. Evaluation on Advanced Backdoors
Hidden Killer Attack. Hidden Killer uses sentence structures
as triggers (Section II-B). Table X (in Appendix) shows the
overall performance of PICCOLO for hidden killer attacks. The
ﬁrst column lists the different dataset and model combinations.
Columns 2-6 show the number of true positives (TP), false
positives (FP), false negatives (FN), true negatives (TN), and
the overall detection accuracy. Observe that for all the six
combinations, PICCOLO can achieve at
least 0.9 accuracy
with few FPs or FNs. We further investigate the reason why
PICCOLO can expose such backdoors. Speciﬁcally, we study
the frequency of the structure phrases before and after sentence
transformation. Table XI (in Appendix) shows the frequencies
of structure phrases (e.g., “when you” in ﬁrst row) in the
clean and poisoned SST-2 training sets used by hidden killer.
Observe that these phrases appear much more frequently in
the poisoned set. Such large frequency differences can easily
lead to strong correlations between the phrases and the target
label in the poisoned models. As a result, PICCOLO can invert
these phrases and recognize the trojaned models.
Combination Lock Attack. Combination Lock paraphrases
sentences by substituting a set of words/phrases with similar
meanings and uses the substitutions as the triggers (Sec-
tion II-B). Table XII (in Appendix) shows the detection
results of PICCOLO. It can achieve ≥0.9 accuracy with few
FNs or FPs. Similar to hidden killer, we have the same
observation that the data distribution is substantially altered
by combination lock, which forces the poisoned model to
learn speciﬁc words. Particularly, we use PICCOLO to reverse-
engineer a set of effective trigger words (i.e., having 1.0 ASR
for a set of inputs) from 8 poisoned models and count the
occurrences of these words in the clean and the poisoned
training sets. Figure 12 (in Appendix) shows the 17 trigger
words and their occurrences. Observe that these words are
indeed used in paraphrasing transformation during poisoning
and they occur much more often in the poisoned set than the
clean set. PICCOLO is hence able to expose such backdoors.
E. Adaptive Attacks
In this section, we study the scenario where the adversary
has knowledge of the mechanism of PICCOLO and aims
to bypass it. We investigate four adaptive attacks targeting
different parts of PICCOLO. The ﬁrst attack targets PICCOLO
’s dictionary. The second attack considers multiple triggers,
namely, the attacker inserts multiple triggers and adds a loss
to ensure that these triggers target different CLS dimensions.
The third attack targets the word discriminativity analysis. The
fourth targets the trigger inversion step. The details of the third
and fourth adaptive attacks are shown in Appendix IX-F
Targeting PICCOLO dictionary.
In this adaptive attack, the
attacker uses trigger words beyond PICCOLO’s dictionary. We
construct two larger dictionaries with 14k and 21k words,
respectively. Currently, we are not able to go beyond 21k
words due to the GPU memory limit of our local machine.
We trojan 80 models with triggers from the 14k dictionary but
beyond the original 7k word dictionary, with 40 models having
word triggers and the other 40 phrase triggers. Similarly, We
trojan 80 models with triggers from the 21k word dictionary
but beyond the 7k and 14k dictionaries. We trojan the models
using the code from TrojAI repository [39].
Besides using the original PICCOLO (with the 7k dic-
tionary), we also employ the 14k and 21k dictionaries in
PICCOLO. Table VI shows the detection results. The ﬁrst
column shows the different conﬁgurations (e.g., PICCOLO-14K
means that using the 14k dictionary in PICCOLO). Columns
2 to 4 show the results on triggers from the 14k dictionary.
Columns 5 to 7 show the results on triggers from the 21k
dictionary. Columns Word and Phrase denote the detection rate
of PICCOLO on trojaned models injected with word triggers
and phrase triggers, respectively. Column Both presents the
detection rate on trojaned models, half of which are injected
with word triggers and the other half with phrase triggers.
Observe that using trigger words beyond the dictionary does
degrade PICCOLO’s performance. However, PICCOLO per-
forms well when an inclusive dictionary is used. Note that
with sufﬁcient GPU memory, PICCOLO can support all English
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:56:09 UTC from IEEE Xplore.  Restrictions apply. 
122036
TABLE VI: Adaptive attack on dictionary
(cid:7)
Detection rate
In this attack,
Trigger word from 14k
Both Word
Phrase
0.55
0.58
0.6
0.8
0.85
0.83
0.85
0.9
0.8
Trigger word from 21k
Both Word
Phrase
PICCOLO-7k
0.45
0.53
0.6
PICCOLO-14k
0.45
0.58
0.52
PICCOLO-21k
0.83