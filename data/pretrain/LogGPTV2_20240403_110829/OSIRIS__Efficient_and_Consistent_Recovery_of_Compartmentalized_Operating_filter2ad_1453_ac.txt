window is open when a thread becomes active (i.e., starts
processing a message) and forcefully closed when the
same thread becomes inactive (i.e., explicitly yields to other
threads). Restoring the state from a crashed server also restores
the state of the inactive threads. The active thread, on the other
hand, needs special handling. When we take a checkpoint,
we call the thread library that forces the context to be saved.
When we restore a checkpoint, the thread library thinks the
crashed thread is still running while the server is in fact
starting in the main thread. For this reason, we call a function
to ﬁx the current thread variable and add the crashed thread
back to the run queue. After these steps, the thread library is
back to a consistent state and the server can run again.
V.
IMPLEMENTATION
We implemented our OSIRIS prototype on top of
the MINIX 3 microkernel-based operating system architec-
ture [8]. The core operating system consists of a number of
OS user-space processes (referred to as system servers) isolated
from each other using the MMU and a small microkernel
that performs privileged low-level operations (e.g., scheduling
and message passing). The underlying design adheres to the
principle of least authority (POLA), which minimizes the con-
sequences of faults through a combination of memory isolation
and by restricting each component (i.e., process) to only those
operations that are necessary for it to do its job. This compart-
mentalized design serves as a basis for fault isolation, which
is a key prerequisite for OSIRIS’ crash recovery strategy (with
no uncontrolled fault propagation across OS components).
To support our checkpointing algorithm we need to
update the undo log for each memory write, which introduces
The system servers at the core of our OSIRIS prototype
are: the Process Manager (PM), which manages processes and
6
signals, the Virtual Memory Manager (VM), which manages
virtual memory, the Virtual Filesystem Server (VFS), which
provides a virtual ﬁle system interface, the Data Store (DS),
which provides a persistent key-value store service, and the
Recovery Server (RS), which detects and restores crashed OS
components in the system. The VFS server in our prototype is
multithreaded to prevent slow disk operations from effectively
blocking the system. Our prototype allows all
these core
system components (including RS itself) to be recovered in
case of crashes using our design.
In addition, OSIRIS includes a set of LLVM link-time
instrumentation passes and static libraries together adding
up to 6,496 LOC1. The Recovery Server implements the
restart phase described in Section IV-C. The static libraries, in
turn, implement our checkpointing, rollback, and reconciliation
mechanisms. Compile-time settings allow SEEPs to be mapped
to their corresponding reconciliation mechanisms, which, as a
result, deﬁne the recovery policies supported by our system. To
enable OSIRIS’ recovery functionalities, we link every system
component against our static libraries and instrument (and
optimize) each component using our LLVM link-time passes.
A. Reliable Computing Base
The Reliable Computing Base (RCB) [34] consists of the
parts of the system that we need to trust to be free of faults.
The RCB in OSIRIS includes mechanisms that implement:
1)
2)
3)
4)
Checkpointing – Maintaining a simple per-request
undo log.
Restartability – Maintaining clones of OS compo-
nents, transferring state, and replacing crashed com-
ponents.
Recovery window management – Tracking whether
the per-component recovery window is open or not.
Initialization – Calling a component-speciﬁc function
to initialize the local state before entering the request
processing loop.
5) Message passing substrate - The underlying micro-
kernel in our prototype.
OSIRIS has a total of 237,270 LOC. The RCB adds up to
29,732 LOC which is only 12.5% of the entire code base.
VI. EVALUATION
We evaluate our system in terms of recovery coverage (Sec-
tion VI-A), survivability (Section VI-B), performance (Sec-
tion VI-C), and service disruption guarantees (Section VI-E).
For our experiments, we use two different workloads.
For our performance evaluation, we rely on Unixbench [35],
which is speciﬁcally designed and widely used to measure
OS performance. As a workload for recovery and survivability
tests, we use a homegrown set of 89 programs in total, written
to maximize code coverage in the system servers. In this
section, we refer to this set of programs as prototype test suite
(included in MINIX 3 [36]).
We use four recovery policies to evaluate OSIRIS. In
addition to the pessimistic and enhanced recovery policies
1Source lines of code generated using David A. Wheeler’s ‘SLOCCount’
7
Server
PM
VFS
VM
DS
RS
Recovery coverage (%)
Pessimistic
Enhanced
54.9
72.3
64.6
47.1
49.4
61.7
72.3
64.6
92.8
50.5
TABLE I.
Weighted average
PERCENTAGE OF TIME SPENT INSIDE THE RECOVERY
57.7
68.4
WINDOW FOR EACH SERVER (MEAN WEIGHTED BY TIME SPENT RUNNING
SERVER)
described in Section VI, we deﬁne two more policies as a
baseline for comparison purposes:
1)
2)
Stateless restart. This serves as a baseline to com-
pare against existing “microreboot systems” operating
stateless recovery.
Naive recovery. This serves as a baseline to compare
against best-effort recovery strategies with no special
handling.
A. Recovery coverage
To measure the opportunity for recovery under our chosen
recovery models, we measure the cumulative execution time
each server spends inside and outside the recovery window
while executing the prototype test suite. We count the number
of basic blocks covered during the execution in each of
the ﬁve servers and compute the recovery coverage as the
fraction of number of basic blocks executed inside recovery
windows out of the total number of basic blocks executed
in the servers. This provides an indication of how often the
system remains recoverable. Table I presents the results for
our pessimistic and enhanced recovery policies. As shown in
the table, the execution spends a mean of 57.7% and 68.4%
of the execution time across all the servers inside recovery
windows, respectively.
As shown in the table, DS has the lowest recovery coverage
in pessimistic mode and the highest in enhanced mode. This
indicates the presence of a SEEP fairly early in DS’ request
processing loop—which is non-state-modifying as marked in
enhanced mode. DS is a relatively simple server, which rarely
issues state-modifying calls to the rest of the system. Hence,
it is almost always recoverable. Since enhanced mode allows
SEEPs that perform read-only interactions with other compo-
nents to keep recovery windows open, the increase in recovery
coverage for PM can be explained by the many read-mostly
system calls it implements. This property applies to many
other OS components (indeed OSes are known to exhibit read-
mostly behavior in typical workloads) and overall our system
can be recovered 68.4% of the time. This means OSIRIS can
guarantee safe recovery in the majority of the cases.
B. Survivability
To demonstrate improved survivability of the system in the
presence of faults, we run large-scale fault injection experi-
ments. We conduct fault injection experiments by booting our
prototype inside a virtual machine and executing our prototype
test suite. We use a modiﬁed QEMU which allows us to log the
status of the system and outcomes of the tests in a way that is
Recovery mode
Pass
Fail
Shutdown
Stateless
Naive
Pessimistic
Enhanced
19.6%
20.6%
18.5%
25.6%
0.0%
2.4%
0.0%
6.5%
0.0%
0.0%
81.3%
66.1%
Crash
80.4%
77.0%
0.2%
1.9%
TABLE II.
SURVIVABILITY UNDER RANDOM FAULT INJECTION OF
FAIL-STOP FAILURE-MODE FAULTS.
Recovery mode
Stateless
Naive
Pessimistic
Enhanced
Pass
47.8%
48.5%
47.3%
50.4%
Fail
Shutdown
10.5%
11.9%
10.5%
12.0%
0.0%
0.0%
38.2%
32.9%
Crash
41.7%
39.6%
4.0%
4.8%
TABLE III.
SURVIVABILITY UNDER RANDOM FAULT INJECTION OF
FULL EDFI FAULTS.
not affected by the injected faults. We use EDFI [37] to inject
the faults. We perform a separate proﬁling run to determine
which fault candidates actually get triggered by our prototype
test suite to exclude those that are triggered during boot time or
are not triggered at all. Boot-time errors are not a good measure
for survivability and they are unrealistic because such faults
would be removed in the testing phase, while untriggered faults
would inﬂate the statistics with runs in which no recovery is
needed. The end result of each run is a log that we use to
classify the run based on whether the system crashed, whether
the tests succeeded, and what recovery decisions were taken.
We performed the experiments in eight different settings:
fault models and four
all combinations of
different recovery models. The ﬁrst fault model consists only
of fail-stop errors (dereferencing a NULL pointer). It allows
us to determine how effective our recovery mechanism is in
the fail-stop situation for which our system is designed. The
second fault model uses the full set of realistic software faults
available in EDFI, which shows to what extent the current
implementation of our approach also generalizes to other types
of common faults. To ensure comparability between recovery
strategies, we select faults to inject once for both fault models
and apply the same faults to each of the recovery models.
two different
Tables II and III show the performance of our recovery
system under fault injection for the fail-stop and full EDFI
fault models respectively. We injected a total of 757 fail-stop
faults and 992 full EDFI faults, each in a separate run. This
covers all the appropriate fault injection locations based on
our criterion that boot time and unreached faults are to be
excluded. We classify the outcomes of the runs in one of four
groups: “pass” means that the test suite has completed and all
tests passed, “fail” means that the test suite has completed but
one or more tests failed, “shutdown” means a non-recoverable
fault was detected and a controlled shutdown was performed,
“crash” means the system suffered from an uncontrolled crash
or hang. Since our aim is to measure survivability, the goal is
to keep the system running even if there is some degradation
of service (visible as failed tests). Hence, we prefer to have
as many completed (passed or failed) runs as possible. As for
the remainder, a controlled shutdown is much preferred over
a crash, which may indicate random behavior and corruption.
With fail-stop errors (the fault model for which our so-
lution was designed), the enhanced recovery mode manages
to provide signiﬁcantly better survivability than all the other
Benchmark
dhry2reg
whetstone-double
execl
fstime
fsbuffer
fsdisk
pipe
context1
spawn
syscall
shell1
shell8
geomean
TABLE IV.
Linux
1,707.8
464.1
1,006.4
2,975.8
320.7
1,398.9
1,143.3
1,590.2
1,204.5
122.5
430.1
1,605.3
873.5
(4.2)
(0.9)
(3.8)
(3.9)
(0.5)
(30.4)
(39.8)
(7.8)
(3.4)
(0.2)
(4.2)
(10.3)
OSIRIS
357.7
200.4
1,171.0
1,106.0
1,299.0
106.8
65.2
260.3
36.5
46.3
385.2
45.9
207.9
(1.1)
(0.1)
(3.9)
(1.9)
(229.1)
(0.4)