## PostgreSQL OUTER JOIN 优化的几个知识点 - 语义转换、内存带宽、JOIN算法、FILTER亲和力、TSP、HINT、命中率、存储顺序、扫描顺序、索引深度     
### 作者                                       
digoal                               
### 日期                                                                                                   
2017-12-21                             
### 标签                                
PostgreSQL , 内存带宽 , JOIN算法 , FILTER亲和力 , TSP , HINT , 索引扫描顺序与命中率 , 语义转换 , 扫描顺序 , 存储顺序 , 命中率 , 索引深度 , partial index          
----                                                                                                
## 背景       
一个OUTER JOIN的SQL优化，引出了一系列的知识点，非常值得深入探讨。  
内存带宽 , JOIN算法 , FILTER亲和力 , TSP , HINT , 索引扫描顺序与命中率 , 语义转换 , 扫描顺序 , 存储顺序 , 命中率 , 索引深度 , partial index   。    
## SQL样例  
```  
digoal_tbl_task：8 GB   
digoal_tbl_refund：14 GB   
SELECT * FROM   
digoal_tbl_task task   
 left outer JOIN    
digoal_tbl_refund refund   
on   
  task.biz_id = refund.id   
where   
  refund.refund_digoal_rid_id=35018 and refund.refund_type=3   -- 这个去掉的话，语义则不能互通了。  
  and task.digoal_dealid=2997380888 and task.task_type=300 and task.status=8   
limit 10 offset 20;   
```  
## 一、语义转换  
这条SQL虽然是OUTER JOIN，但是Join条件只有一个等值条件，而其他条件都在WHERE中，WHERE条件中同时还包含了可空表的非空查询条件，因此我们可以认为它的语义与INNER JOIN一致。  
```  
SELECT * FROM   
digoal_tbl_task task   
 INNER outer JOIN    
digoal_tbl_refund refund   
on   
  task.biz_id = refund.id   
where   
  refund.refund_digoal_rid_id=35018 and refund.refund_type=3   -- 这个去掉的话，语义则不能互通了。  
  and task.digoal_dealid=2997380888 and task.task_type=300 and task.status=8   
limit 10 offset 20;   
```  
## 二、性能指标  
单次查询响应速度约7毫秒。  
扫描了10217个数据块，这个也是后面重点优化的地方。  
```  
explain (analyze,verbose,timing,costs,buffers)   
SELECT * FROM   
digoal_tbl_task task   
 INNER outer JOIN    
digoal_tbl_refund refund   
on   
  task.biz_id = refund.id   
where   
  refund.refund_digoal_rid_id=35018 and refund.refund_type=3   -- 这个去掉的话，语义则不能互通了。  
  and task.digoal_dealid=2997380888 and task.task_type=300 and task.status=8   
limit 10 offset 20;   
 Limit  (cost=64173.00..64173.00 rows=1 width=799) (actual time=4.717..7.064 rows=10 loops=1)  
   Output: ................  
   Buffers: shared hit=10217  
   ->  Nested Loop  (cost=1.13..64173.00 rows=12 width=799) (actual time=0.248..7.060 rows=30 loops=1)  
         Output: ...........................  
         Buffers: shared hit=10217  
         ->  Index Scan using idx_digoal_rid_idtype on public.digoal_tbl_refund refund  (cost=0.56..19350.09 rows=5243 width=513) (actual time=0.021..0.802 rows=2513 loops=1)  
               Output: .......................  
               Index Cond: ((refund.refund_digoal_rid_id = 35018) AND (refund.refund_type = 3))  
               Buffers: shared hit=122  
         ->  Index Scan using idx_digoal_tbl_task_2 on public.digoal_tbl_task task  (cost=0.56..8.54 rows=1 width=286) (actual time=0.002..0.002 rows=0 loops=2513)  
               Output: ........................................  
               Index Cond: ((task.digoal_dealid = 2997380888::bigint) AND (task.task_type = 300) AND (task.status = 8) AND (task.biz_id = refund.id))  
               Buffers: shared hit=10095  
 Planning time: 0.420 ms  
 Execution time: 7.166 ms  
(16 rows)  
```  
## 三、内存带宽  
测试环境是60核的机器，按单次查询时间，理论上性能应该可以达到60*1000/7.166=8372的TPS。但是，实际上真实的压测，并发查询也只能达到300多的TPS。  
原因是什么？  
实际上我们通过命中率，我们大概可以推算出来，356的TPS时，占用的内存带宽约 29 GB/s。加上其他的损耗，基本上达到了内存带宽的瓶颈。  
```  
postgres=# show block_size;  
 block_size   
------------  
 8192  
(1 row)  
postgres=# select 10217*356*8;  
 ?column?   
----------  
 29098016  
(1 row)  
```  
因为内存读取占用了大量的时间，所以降低CACHE读取，是重点需要优化的。  
## 四、JOIN 算法  
PostgreSQL支持三种JOIN算法，嵌套循环、MERGE SORT、哈希JOIN。  
详见：  
[《PostgreSQL nestloop/hash/merge join讲解》](../201205/20120521_02.md)    
## 五、SQL HINT  
PostgreSQL HINT可以指定执行计划。  
详见:  
[《关键时刻HINT出彩 - PG优化器的参数优化、执行计划固化CASE》](../201607/20160723_02.md)    
比如  
```  
create extension pg_hint_plan;  
load 'pg_hint_plan';  
set client_min_messages ='notice';    
set client_min_messages ='log';    
set pg_hint_plan.debug_print =on;    
set pg_hint_plan.enable_hint=on;    
set pg_hint_plan.message_level =log;    
set pg_hint_plan.parse_messages =log;    
set pg_hint_plan.enable_hint_table =on;    
postgres=>  explain (analyze,verbose,timing,costs,buffers)   
/*+  
  NestLoop(task refund)  
  Leading(task refund)  
*/  
SELECT * FROM   
digoal_tbl_task task   
 left outer JOIN    
digoal_tbl_refund refund   
on   
task.biz_id = refund.id   
where   
refund.refund_digoal_rid_id=35018 and refund.refund_type=3   
and task.digoal_dealid=2997380888 and task.task_type=300 and task.status=8   
limit 10 offset 20;   
```  
## 六、JOIN 索引过滤  
在例子中，我们可以看到这样的执行计划，实际上在JOIN时，使用了索引，同时使用了索引过滤，而非查询过滤。  
索引过滤的好处是不需要额外的CPU运算。  
那么JOIN时，怎么样的条件能过滤呢？  
对于NESTLOOP JOIN：  
对于外表，除了JOIN都可以作为索引过滤条件。因为外表是需要遍历的，遍历时不知道它的JOIN KEY的VALUE到底是多少，所以作为复合索引没有必要把外表的JOIN字段加进来。  
作为内表，所有条件都可以作为索引过滤条件。包括JOIN字段，因为内表不是遍历的，而是通过外表传入的JOIN值来查询的，因此复合索引可以加速JOIN字段。  
那么应该如何创建索引呢？  
外表：WHERE条件中除了JOIN字段的其他字段，构建BTREE复合索引，等值条件作为驱动列，如果有多个等值条件，那么将稀疏（选择性不好的）列排在前面。  
```  
Index Cond: ((refund.refund_digoal_rid_id = 35018) AND (refund.refund_type = 3))  
```  
内表，WHERE条件中，所有字段构建BTREE复合索引，等值条件作为驱动列，如果有多个等值条件，那么将稀疏（选择性不好的）列排在前面。  
```  
Index Cond: ((task.digoal_dealid = 2997380888::bigint) AND (task.task_type = 300) AND (task.status = 8) AND (task.biz_id = refund.id))  
```  
## 七、nestloop join + limit 命中率优化  
在前面的执行计划中，虽然是limit 10 offset 20，最多实际上需要扫描30条外表即可，但是实际上，从LOOP值来看，外表扫描了2513次。  
这也是前面提到的问题所在，LOOP 2513次，直接带来了10095个数据块的访问。  
实际上每次访问了4个数据块  
```  
postgres=# select 10095/2513.0;  
      ?column?        
--------------------  
 4.0171110226820533  
(1 row)  
```  
这平均4个数据块是内表每一次LOOP时，访问每一条记录的 "索引访问+HEAP访问 (有一些ID不存在所以不需要访问heap)" 命中到的BLOCK，实际上对于单次扫描来说已经很小了。      
但是由于内表访问了2000多次，所以造成了IO放大。  
那么为什么30次的LIMIT，内表确LOOP了2513次？  
这说明外表提供的记录，扫了2513条，在内表中只有30条是满足JOIN和WHERE条件的记录，为了减少内表的扫描次数（最多降低到30次），我们可以通过调整外表的扫描顺序来实现。  
做法，只要预先把满足条件的数据，在外表重排一下即可。  
```  
create table tmp (like digoal_tbl_refund);  
insert into tmp select * from digoal_tbl_refund where id in   
  (select biz_id from digoal_tbl_refund where id in (select biz_id from digoal_tbl_task task where task.digoal_dealid=2997380888 and task.task_type=300 and task.status=8);  
delete from digoal_tbl_refund where id in (select biz_id from digoal_tbl_task task where task.digoal_dealid=2997380888 and task.task_type=300 and task.status=8);  
create table tmp1 (like digoal_tbl_refund);  
insert into tmp1 select * from tmp;  
insert into tmp1 select * from digoal_tbl_refund;  
-- 重建索引tmp1  
drop table digoal_tbl_refund;  
alter table tmp1 rename to digoal_tbl_refund;  
```  
当然这个做法不具备通用性，需要预先处理。我只是借机讲解背后的原理。  
这样做之后，只需要扫描30次内表了。  
```  
 Limit  (cost=61621.78..61621.78 rows=1 width=784) (actual time=0.479..0.634 rows=10 loops=1)  
   Output: ......................................  
   Buffers: shared hit=183  
   ->  Nested Loop  (cost=1.13..61621.78 rows=11 width=784) (actual time=0.088..0.629 rows=30 loops=1)  
         Output: .........................................................  
         Buffers: shared hit=183  
         ->  Index Scan using idx_digoal_rid_idtype_1 on public.digoal_tbl_refund refund  (cost=0.56..10839.91 rows=5945 width=513) (actual time=0.033..0.169 rows=30 loops=1)  