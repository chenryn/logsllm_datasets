### 6.1 Additional Evaluation for Verification

We conducted an additional evaluation to verify the correctness of our implementation of TeD (and P-TeD) by comparing our attack results with those reported in [51]. This comparison is necessary because the released TeD code [50] is incomplete and does not allow us to conduct our experiments. Our experimental results confirm the effectiveness of the trapdoored defense against existing state-of-the-art \(L_{\infty}\) and \(L_2\) adversarial attacks.

### 6.2 TeD - Single and All Categories

We first evaluate the attack performance of our FIA and baseline attacks (PGD and C&W) against TeD when it is used to defend a specific category \(C_t\) with a trapdoor (single category) and all categories with one trapdoor per category (all categories). The detection rates for both single and all categories are reported in Table 3, and their ROC curves are presented in Appendix A.4.

For all datasets except YouTube Face, each value in Table 3 is the average over all categories by attacking each category. For the YouTube Face dataset, each value is the average over 50 randomly selected categories by attacking each of the selected categories.

From the table, we observe that the detection rates of FIA are low (≤ 2.0%) except for the all categories on the YouTube Face dataset, where the detection rate is 6.1%. In contrast, the detection rates of PGD and C&W are generally high, with most above 90%, some between 70% and 90%, and only two instances with low detection rates: C&W against the single category on GTSRB (34.3%) and PGD against all categories on the same dataset (30.7%). These values are significantly higher than the highest detection rate of FIA (6.1%).

Many detection rates of PGD and C&W in Table 3 are significantly lower than those reported in [51]. Our investigation indicates that the results in [51] were likely obtained with FPR calculated using benign samples from categories other than the target category. We present the experimental results with this setting in Appendix A.3, which align well with those reported in [51].

### 6.3 P-TeD - Single and All Categories

#### 6.3.1 Detection Rate

The same experiment as in Section 6.2 was conducted on P-TeD. The detection rates for single and all categories are reported in Table 4, and their ROC curves are presented in Appendix A.4.

| Dataset | Single Category | All Categories |
|---------|-----------------|----------------|
| MNIST   | 1.0%            | 6.1%           |
| CIFAR10 | 92.8%           | 100%           |
| GTSRB   | 98.2%           | 99.8%          |
| YtbFace | 0.0%            | 100%           |

From the table, we can see that the detection rates of P-TeD are very high (above 94%) for both PGD and C&W attacks on all datasets. These results confirm that the trapdoored defense has a high chance of detecting adversarial examples generated with existing state-of-the-art white-box adversarial attacks. On the other hand, the detection rates for FIA are still low, below 5.9% except for the all categories on the YouTube Face dataset, where the detection rate is 14.3%. The experimental results indicate that FIA can effectively circumvent P-TeD too.

#### 6.3.2 Adversarial Generation Success Rate

An adversarial attack may fail to generate an adversarial example at the end of its iterative crafting process. The success rate to generate adversarial examples is also an important metric to measure the performance of an adversarial attack. Table 5 reports the adversarial generation success rates of FIA, PGD, and C&W on P-TeD protecting single and all categories at 5% FPR of benign target samples.

| Dataset | Single Category | All Categories |
|---------|-----------------|----------------|
| MNIST   | 96.2%           | 100%           |
| CIFAR10 | 94.9%           | 100%           |
| GTSRB   | 100%            | 100%           |
| YtbFace | 81.6%           | 79.3%          |

From Table 5, we can see that the generation success rates of both PGD and C&W are very high on all tested datasets, above 91% for PGD and above 99% for C&W. FIA’s generation success rates are similar to PGD and C&W except on the YouTube Face dataset. On the YouTube Face dataset, FIA has reasonable generation success rates (above 79%), but these rates are significantly lower than those of PGD and C&W. This is because the bound of 16 (i.e., \(\delta = 16\)) used by FIA on the YouTube Face dataset in our evaluation is a little tight for the dataset. If we relax the bound to 32, FIA has a higher generation success rate and a lower detection rate on the YouTube Face dataset, with both rates similar to their counterparts on the other three tested datasets. This is also true for TeD protecting single and all categories as reported in Table 3 and Section 6.2.

### 6.4 P-TeD Detection with Randomly Sampled Neurons and Multiple Trapdoors

When randomly sampled neurons are used, FIA maintains high attack success rates (≥ 79.5%), while OSA’s attack success rates reduce to 37.85% when the number of trapdoors per category increases to 13 and 5% randomly sampled neurons are used. This result indicates that FIA can effectively circumvent the strongest protection provided by the trapdoored defense.

With this strongest trapdoored protection, the generation success rate of FIA is around 40%, much lower than that reported in Table 5 when weaker trapdoored defense is used. A higher bound is needed if a higher generation success rate or a higher attack success rate is required.

### 6.5 Different Generation Layers

Different latent layers, except early layers in the forward pipeline, can be used as the generation layer. This is because an adversarial example needs a sequence of layers to transition from the source category to the target category in the feature space. We have conducted experiments to study FIA using different layers as the generation layer. In these experiments, the detection layer was set the same as the generation layer. The second column in Table 6 shows the adversarial attack success rate (ASR) and the adversarial generation success rate (GSR) for P-TeD to protect a single category at 5% FPR of benign target samples on MNIST. Table 12 in Appendix A.1 describes the detail of the network used for MNIST.

| Layer | ASR / GSR (%) |
|-------|---------------|
| dense | 94.8 / 96.2    |
| max_pool_2 | 93.3 / 64.1 |
| conv_2 | 93.9 / 36.3   |
| max_pool_1 | 97.3 / 15.1  |
| conv_1 | 95.3 / 7.3    |

From the second column of Table 6, we can see that the ASR is high (above 93%) and does not vary much, while GSR drops significantly from 96.2% to 7.3% when the generation layer moves backwards. The significant drop in ASR can be explained by the increasing difficulty of driving to the target as the generation layer moves backwards. A higher bound should be used to achieve a high ASR for an early generation layer, resulting in more noisy adversarial examples. For example, the third column (FIA×2) in Table 6 shows ASR and GSR when the bound is doubled to \(\delta = 128\) for MNIST. We can see that the GSR is significantly improved, and GSR drops much slower when the generation layer moves backward. At the same time, ASR has also been improved, to nearly 100% for all the tested layers.

There is an alternative way to improve GSR when the generation layer is not close to the penultimate layer: we can use the basic scheme to drive at the penultimate layer simultaneously with the original driving at the generation layer. The penultimate-layer driving guides an adversarial example into the target category and thus improves GSR. This revised scheme is denoted as FIA+G in Table 6, and the fourth column of Table 6 shows the experimental results on MNIST when the original bound (i.e., \(\delta = 64\)) was used. We can see that GSR is significantly improved, but ASR drops from 93.6% at the penultimate layer (i.e., dense in Table 6) to 75.3% at conv_2 layer. This behavior is caused by the fact that positive adversarial examples found in the preparation phase deviate from trapdoor signatures much more at a middle layer than at a late layer. The penultimate guidance helps increase GSR, but more generated adversarial examples also spread more in the feature space. Since the constraint is checked at a middle layer (and thus not very accurate) in crafting adversarial examples, this spreading may increase the chance to be detected, resulting in an increased detection rate.

### 6.6 Attack Success Rates with Different Configurations

We conduct the same experiments as reported in [51] to evaluate FIA’s performance against the strongest protection provided by P-TeD and compare it with the white-box attack, Oracle Signature Attack (OSA), the stronger version of the two attacks developed by Carlini [6] to attack the trapdoored defense. In our experiment, the number of trapdoors per category ranged from 1 to 13, and 100%, 10%, and 5% of randomly sampled neurons were used in detection. We set the same FPR for each subset and tried to maintain the total FPR (i.e., the detector’s FPR of benign target samples) at 5%. The number of subsets and the FPR for each subset were adjusted to try to make OSA’s performance curves similar to those reported in [51]. The same setting was used to evaluate FIA and OSA.

The attack success rates for P-TeD to protect all categories with different configurations are reported in Figure 1. The resulting total FPR is around 7.0% for each configuration. The results were obtained by using one batch with a size of 16 to generate adversarial examples in each round of queries in the preparation phase. The resulting number of queries used in the preparation phase was small. For example, we used a total of 25.9 and 26.5 queries on average for 100% and 5% randomly sampled neurons, respectively, when 13 trapdoors were injected per category.

From Figure 1, we can see that both FIA and OSA have high attack success rates when all neurons are used in the trapdoored detection: above 91% for OSA and nearly 100% for FIA. When 10% and 5% of neurons are used, the attack success rates decrease, but FIA still outperforms OSA.

### 6.7 Batch Size Impact on ASR and GSR

Table 8 shows the ASR and GSR of FIA on MNIST with P-TeD protecting single and all categories at 5% FPR when a single batch with different batch sizes is used in the preparation phase. The resulting average number of queries conducted in the preparation phase is reported in the bottom row.

| Batch Size | ASR | GSR | # Queries |
|------------|-----|-----|-----------|
| 32         |     |     |           |
| 16         |     |     |           |
| 64         |     |     |           |

This table provides insights into how the batch size affects the attack and generation success rates.