cal evaluation for an additional purpose: to verify correctness of
our implementation of TeD (and P-TeD) by comparing our attack
results with those reported in [51] since the released TeD code [50]
is incomplete for conducting our experiments. Our experimental
results conrm the eectiveness of the trapdoored defense against
existing state-of-the-art ùêø‚àû and ùêø2 adversarial attacks.
6.2 TeD - Single and All Categories
We rst evaluate the attack performances of our FIA and baseline
attacks PGD and C&W against TeD when it is used to defend a spe-
cic category ùê∂ùë° with a trapdoor (single category) and all categories
with one trapdoor per category (all categories). The detection rates
of both single category and all categories are reported in Table 3.
Their ROC curves are presented in Appendix A.4. For all datasets
except YouTube Face, each value in Table 3 is the average over
all categories by attacking each category. For YouTube Face, each
value in Table 3 is the average over 50 randomly selected categories
by attacking each of the selected category.
We can see from the table that the detection rates of FIA are low
(‚â§ 2.0%) except the all categories on the YouTube Face dataset, for
which the detection rate is 6.1%. On the other hand, the detection
rates of PGD and C&W are generally high: most are above 90%,
some are in the range between 70% and 90%, and only two have
low detection rates: the detection rate of C&W against the single
category is 34.3% on GTSRB, and that of PGD against the all cate-
gories is 30.7% on the same dataset. Both values are much higher
than the highest detection rate, 6.1%, of FIA reported in the table.
Many detection rates of PGD and C&W reported in Table 3 are
signicantly lower than those reported in [51]. Our investigation
indicates that the results in [51] are likely obtained with FPR cal-
culated with benign samples of categories other than the target
category. We present the experimental results with this setting in
Appendix A.3, which agree well with those reported in [51].
6.3 P-TeD - Single and All Categories
6.3.1 Detection Rate. The same experiment presented in Section 6.2
is also conducted on P-TeD. The detection rates of the single cat-
egory and the all categories are reported in Table 4. Their ROC
curves are presented in Appendix A.4. From the table, we can see
Single Category
All Categories
FIA PGD C&W FIA PGD C&W
1.0% 92.8% 98.2%
2.0% 100%
99.7%
0.0% 85.1% 95.2%
0.2% 98.7% 72.7%
0.3% 30.7% 71.8%
0.5% 85.8% 34.3%
1.6% 78.5% 95.1%
6.1% 100%
99.8%
MNIST
CIFAR10
GTSRB
YtbFace
Table 4: Detection rates at 5% FPR of benign target samples
when P-TeD defends single category and all categories.
Single Category
All Categories
FIA PGD C&W FIA
2.5%
5.2% 100%
100%
0.0%
0.0% 98.8% 92.2%
3.1% 97.5% 98.5%
0.4%
14.3% 100%
5.9% 94.9% 99.6%
PGD C&W
99.8%
100%
100%
95.6%
96.9% 99.4%
99.8%
MNIST
CIFAR10
GTSRB
YtbFace
Table 5: Adversarial generation success rates when P-TeD de-
fends single category and all categories at 5% FPR of benign
target samples.
PGD C&W FIA
Single Category
FIA
96.2% 94.9% 100%
100%
100%
100%
97.1% 100%
100%
81.6% 91.8% 100%
All Categories
PGD C&W
99.6%
99.5% 100%
100%
100%
100%
100%
100%
100%
79.3% 98.9% 100%
MNIST
CIFAR10
GTSRB
YtbFace
that the detection rates of P-TeD are very high (above 94%) for
both PGD and C&W attacks on all datasets. These results conrm
that the trapdoored defense has a high chance to detect adversarial
examples generated with existing state-of-the-art white-box adver-
sarial attacks. On the other hard, the detection rates for FIA are
still low, below 5.9% except the all categories on the YouTube Face
dataset, for which the detection rate is 14.3%. The experimental
results indicate that FIA can eectively circumvent P-TeD too.
6.3.2 Adversarial Generation Success Rate. An adversarial attack
may fail in generating an adversarial example at the end of its
iterative crafting process. The success rate to generate adversarial
examples is also an important metric to measure the performance
of an adversarial attack. Table 5 reports the adversarial generation
success rates of FIA, PGD, and C&W on P-TeD protecting single
category and all categories at 5% FPR of benign target samples.
From Table 5, we can see that the generation success rates of both
PGD and C&W are very high on all the tested datasets, above 91%
for PGD and above 99% for C&W. FIA‚Äôs generation success rates are
similar to PGD and C&W except on the YouTube Face dataset. On
the YouTube Face dataset, FIA has reasonable generation success
rates (above 79%), but these rates are signicantly lower than their
counterparts of both PGD and C&W. This is because the bound of
16 (i.e., ùõø = 16) used by FIA on the YouTube Face dataset in our
Session 11D: Data Poisoning and Backdoor Attacks in ML CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea3168evaluation is a little tight for the dataset. If we relax the bound to
32, FIA has a higher generation success rate and a lower detection
rate on the YouTube Face dataset, with both rates similar to their
counterparts on the other three tested datasets. This is also true
for TeD protecting single category and all categories reported in
Table 3 and Section 6.2.
6.4 P-TeD Detection with Randomly Sampled
Neurons and Multiple Trapdoors
randomly sampled neurons are used, FIA maintains high attack
success rates (‚â• 79.5%), while OSA‚Äôs attack success rates reduce to
37.85% when the number of trapdoors per category increases to 13
and 5% randomly sampled neurons are used. This result indicates
that FIA can eective circumvent the strongest protection provided
by the trapdoored defense.
With this strongest trapdoored protection, the generation suc-
cess rate of FIA is around 40%, much lower than that reported in
Table 5 when weaker trapdoored defense is used. A higher bound is
needed if a higher generation success rate or a higher attack success
rate is required.
6.5 Dierent Generation Layers
Dierent latent layers except early layers in the forward pipeline
can be used as the generation layer. This is because an adversarial
example needs a sequence of layers to transition from the source cat-
egory to the target category in the feature space. We have conducted
experiments to study FIA using dierent layers as the generation
layer. In these experiments, the detection layer was set the same
as the generation layer. The second column in Table 6 shows the
adversarial attack success rate (ASR) and the adversarial generation
success rate (GSR) for P-TeD to protect a single category at 5%
FPR of benign target samples on MNIST. Table 12 in Appendix A.1
describes the detail of the network used for MNIST.
From the second column of Table 6, we can see that the ASR is
high (above 93%) and does not vary much, while GSR drops sig-
nicantly from 96.2% to 7.3% when the generation layer moves
backwards. The signicant drop of ASR can be explained that it
becomes increasingly harder to drive to the target when the gen-
eration layer moves backwards. A higher bound should be used
to achieve a high ASR for an early generation layer, resulting in
more noisy adversarial examples. For example, the third column
(FIA√ó2) in Table 6 shows ASR and GSR when the bound is doubled
to ùõø = 128 for MNIST. We can see that the GSR is signicantly
improved, and GSR drops much slower when the generation layer
moves backward. At the same time, ASR has also been improved,
to nearly 100% for all the tested layers.
There is an alternative way to improve GSR when the generation
layer is not close to the penultimate layer: we can use the basic
scheme to drive at the penultimate layer simultaneously with the
original driving at the generation layer. The penultimate-layer driv-
ing guides an adversarial example into the target category and thus
improves GSR. This revised scheme is denoted as FIA+G in Table 6,
and the fourth column of Table 6 shows the experimental results
on MNIST when the original bound (i.e., ùõø = 64) was used. We can
see that GSR is signicantly improved, but ASR drops from 93.6%
at the penultimate layer (i.e., dense in Table 6) to 75.3% at conv_2
layer. This behavior is caused by the fact that positive adversarial
examples found in the preparation phase deviate from trapdoor
signatures much more at a middle layer than at a late layer. The
penultimate guidance helps increases GSR, but more generated ad-
versarial examples also spread more in the feature space. Since the
constraint is checked at a middle layer (and thus not very accurate)
in crafting adversarial examples, this spreading may increase the
chance to be detected, resulting in an increased detection rate. This
Figure 1: Attack success rates of FIA and OSA when P-TeD
protects all categories with 1 to 13 trapdoors per category
and with randomly sampled neurons at 100%, 10%, and 5%.
The strongest protection is provided with randomly sampled
neurons and multiple trapdoors per category [51]. We conduct the
same experiments as reported in [51] to evaluate FIA‚Äôs performance
against this strongest protection and compare it with the white-
box attack, Oracle Signature Attack (OSA), the stronger version of
the two attacks developed by Carlini [6] to attack the trapdoored
defense. In our experiment, the number of trapdoors per category
ranged from 1 to 13, and 100%, 10%, and 5% of randomly sampled
neurons were used in detection. We set the same FPR for each
subset and tried to maintain the total FPR (i.e., the detector‚Äôs FPR of
benign target samples) at 5%. The number of subsets and the FPR
for each subset were adjusted to try to make OSA‚Äôs performance
curves similar to those reported in [51]. The same setting was used
to evaluate FIA and OSA.
The attack success rates for P-TeD to protect all categories with
dierent congurations are reported in Fig. 1. The resulting total
FPR is around 7.0% for each conguration. The results were obtained
by using one batch with a size of 16 to generate adversarial examples
in each round of queries in the preparation phase. The resulting
number of queries used in the preparation phase was small. For
example, we used a total of 25.9 and 26.5 queries on average for
100% and 5% randomly sampled neurons, respectively, when 13
trapdoors were injected per category.
From Fig. 1, we can see that both FIA and OSA have high attack
success rates when all neurons are used in the trapdoored detection:
above 91% for OSA and nearly 100% for FIA. When 10% and 5%
135791113# of Trapdoors per Label00.20.40.60.81Attack Success RateOSA sampling ratio=100%OSA sampling ratio=10%OSA sampling ratio=5%FIA sampling ratio=100%FIA sampling ratio=10%FIA sampling ratio=5%Session 11D: Data Poisoning and Backdoor Attacks in ML CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea3169Table 6: ASR and GSR of FIA using dierent generation
layers and settings (see Section 6.5) on MNIST with single-
category P-TeD at 5% FPR of benign target samples.
LGeneration
dense
max_pool_2
conv_2
max_pool_1
conv_1
FIA
94.8 / 96.2
93.3 / 64.1
93.9 / 36.3
97.3 / 15.1
95.3 / 7.3
ASR / GSR (%)
FIA√ó2
100 / 100
100 / 99.4
100 / 90.5
99.8 / 83.9
99.5 / 62.8
FIA+G
93.6 / 96.3
82.8 / 96.7
75.3 / 96.7
85.6 / 94.0
83.9 / 91.5
FIA+GP
98.6 / 96.1
93.2 / 96.5
94.0 / 96.6
88.5 / 93.9
85.5 / 91.7
Table 8: ASR and GSR of FIA on MNIST with P-TeD protect-
ing single category and all categories at 5% FPR when a sin-
gle batch with dierent batch sizes is used in the preparation
phase. The resulting average number of queries conducted
in the preparation phase is reported in the bottom row.
Batch Size
ASR
GSR
# Queries
32
All Categories
Single Category
16
16
64