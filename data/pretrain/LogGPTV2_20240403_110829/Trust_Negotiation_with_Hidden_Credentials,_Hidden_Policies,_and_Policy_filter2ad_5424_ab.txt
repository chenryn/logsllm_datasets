1For simplicity, we model service s as a credential. In order to obtain
s, the client has to have credentials that satisfy φs.
about the speciﬁc UC, US pair, i.e., neither party can distin-
guish which pair was responsible for access or whether that
pair was minimal or not. It also implies that the trust negoti-
ation strategy we design need not make any particular effort
at zeroing in on a particular pair (e.g., a minimal one).
Example 1 Suppose the client and server have the follow-
ing policies:
Client
pc1 : c1 ← s2
pc2 : c2 ← s2 ∧ s3
pc3 : c3 ← s6
pc4 : c4 ← true
Server
ps : s ← c5 ∨ (c2 ∧ c4)
ps1 : s1 ← c6
ps2 : s2 ← c1
ps3 : s3 ← c4
where s denotes the server’s service, {s, s1, s2, s3} denote
the set of server’s credentials, {c1, c2, c3, c4} denotes the
set of the client’s credentials. Under Deﬁnition 1, the nego-
tiation between the client and server would fail as there is
a policy cycle between c1 and s2, and there exists no cre-
dential disclosure sequence ending with s. However, under
Deﬁnition 2, the negotiation succeeds, as UC = {c1, c2, c4}
and US = {s, s2, s3} is a solution pair.
Clearly, if the trust negotiation between the client and
server can succeed in Deﬁnition 1, it will also succeed in
Deﬁnition 2, but not vice-versa (e.g., see Example 1). In the
next section, we describe a reverse eager (RE) strategy that
efﬁciently determines whether the negotiation can succeed
(under Deﬁnition 2) given CS, PS, CC, and PC. Then, we
will give a privacy-preserving trust negotiation protocol that
securely implements the RE strategy without revealing CS
and PS to the client and without revealing CC and PC to
the server.
4 Our Approach
We begin this section with an intuitive, informal presen-
tation of our approach. The eager strategy for trust negotia-
tions can be thought of as one of “progressively increment-
ing the usable set”: The set of usable credentials is initially
set to the unconditionally usable credentials, and each iter-
ation adds to it credentials that have just (in that iteration)
become known to be usable. It is, in other words, a con-
servative approach, whose motto is that a credential is not
usable unless proved otherwise: The iterative process stops
when no more credentials are added to the usable set. This
conservatism of the eager approach is also why using that
strategy would lead us to deadlock on cycles. Our over-
all strategy is the opposite, and can be viewed as a “reverse
eager” strategy: Initially all credentials are temporarily con-
sidered to be usable, and each iteration decreases the set of
usable credentials (of course the decrease is achieved im-
plicitly, so as not to violate privacy – more on these imple-
mentation details is given in the next section). Note that,
because of the “optimism” of the RE strategy (in that a cre-
dential is tentatively usable, until proven otherwise), cycles
no longer cause a problem, because a “self-reinforcing” cy-
cle’s credentials will remain usable2 (whereas it deadlocked
in the eager strategy). This RE strategy (the details of which
are given later) is made possible by the fact that we carry out
the iterative process in a doubly blinded form, so that nei-
ther party learns anything (not only about the other party’s
credentials, but also about their use policies for these cre-
dentials). The RE strategy and blinded evaluations work
hand in hand: The former is useless without the latter, and
it should not be used outside of this particular framework.
The rest of this section gives a more precise presentation
by ﬁrst introducing the notation that will be used throughout
the rest of the paper, then deﬁning our problem and giving
a more detailed overview of our approach.
4.1 Notation and Deﬁnitions
Before describing the details of our approach, it is nec-
essary to give a more formal notation than the intuitive ter-
minology of the previous section.
• We use s to denote the server’s service or resource
that the client requests. Without loss of generality, we
model s as a credential.
• We use CC (resp., CS) to denote the set of the client’s
(resp., the server’s) hidden credentials. We use nC
and nS to denote the size of CC and CS, respectively.
Referring to Example 1, CC = {c1, c2, c3, c4} and
nC = 4.
• We use PC (resp., PS) to denote the set of the client’s
(resp., server’s) policies.
• We use R(pi) to denote the set of credentials relevant
to (i.e., that appear in) the policy function of the policy
pi. For example, if the policy function for pi takes the
form of φi(c1, . . . , ck), then R(pi) = {c1, . . . , ck}.
• We use R(PC) (resp. R(PS)) to denote the union
of all the R(pi)’s over all pi in PC (resp. PS), i.e.,
R(pi). We use mC and mS to de-
R(PC) = Spi∈PC
note the size of R(PC) and R(PS), respectively. Re-
ferring to Example 1, R(PS) = {c1, c2, c4, c5, c6} and
mS = 5.
• We use UC (resp., US) to denote the set of the client’s
(resp.,
the server’s) credentials whose policies are
presumed to have been satisﬁed (i.e., these are the
currently-believed usable credentials); as stated earlier,
these sets will decrease from one iteration to another.
Initially, UC = CC and US = CS, and throughout the
iterative process we have UC ⊆ CC and US ⊆ CS.
2See Section 4.4 for proof
4.2 Problem Deﬁnition
The goal of this paper is to develop a solution such that
the client and server are able to learn whether trust can be
established without either party revealing to the other party
anything about their own private credentials and policies
(other than, unavoidably, what can be deduced from the
computed answer). We formalize the privacy-preserving
trust negotiation problem as follows.
Problem 1 The server inputs CS and PS and the client in-
puts CC, PC, and a request for the server’s service s. In the
end, both the client and server learn whether the client’s ac-
cess to s can be granted based on their credentials and poli-
cies, without revealing their sensitive credentials and poli-
cies to the other party. In other words, they want to know
whether the trust negotiation between the client and server
succeeds under Deﬁnition 2 without leaking other informa-
tion, except for nC, nS, mC, and mS.
Having stated the problem, we will now discuss the in-
formation revealed by the protocol. The values nC and nS
reveal the number of credentials that the client and server
respectively have and the values mC and mS reveal the
size of all policies for all credentials for the client and the
server. We do not view this as a problem because the parties
can pad their list or their policies with dummy credentials.
We now list the security properties required of a solution (a
more detailed version is given in Section 8).
1. Correctness:
If trust can be successfully negotiated,
then both the client and server should output true with
overwhelming probability if they follow the protocol.
2. Robustness against malicious adversaries: If the trust
negotiation fails, then both the client and server should
output false even if one of the participants is malicious
(i.e., behaves arbitrarily) with overwhelming probabil-
ity.
3. Privacy-preservation: The client and server should
not learn anything about the other party’s private input
(credentials and policies) or intermediate results (us-
able credential sets), other than what can be deduced
from the yes/no outcome of the negotiation.
4.3 Overview of Our Approach
As described earlier, our overall strategy for privacy-
preserving trust negotiation is the RE strategy. During each
round of the RE strategy, a negotiator blindly (i.e., with-
out actually learning the outcome) checks which of their
presumed-usable local credentials are in fact not usable (ac-
cording to whether the policy for it has ceased to be satis-
ﬁed based on the the new presumed-usable credential set of
the other party). After this, the negotiator blindly decreases
their own local presumed-usable credential set accordingly.
Recall that we use UC (US) to denote the set of the client’s
(server’s) credentials that are presumed usable, i.e., at a par-
ticular stage of the iterative process, for each credential in
UC (US), the corresponding usability policy is currently sat-
isﬁed (although it may cease to be so in a future iteration).
We present the RE strategy in Figure 1.
reverse-eager-strategy(C, P, UO)
C: the local credentials of this party.
P: the local policies of this party.
UO: the credentials used by the other party.
Output:
U: the local credentials that can be used.
Procedure:
U = C;
For each credential c ∈ C
let c’s policy be pc : c ← φc;
if φc(UO) = 0, then U = U − {c};
return U.
Figure 1. Pseudocode for the RE strategy
Our approach to privacy-preserving trust negotiation is
to implement the RE strategy in a secure way. We give the
high-level description of our protocol in Figure 2. In it, the
server ﬁrst initializes US. Then the client and server run a
secure version of the RE strategy protocol to update UC and
US iteratively for n rounds, where n = min(nC, nS) (recall
that the trust negotiation using the eager strategy takes at
most n rounds). In the end, if s ∈ US (i.e., s can be used),
the negotiation succeeds, otherwise, it fails.
privacy-preserving-trust-nego(s, CC , PC, CS, PS)
Output:
true or false
Procedure:
Initialize US;
For i = 1, . . . , min(nC, nS)
UC = reverse-eager-strategy(CC, PC, US);
US = reverse-eager-strategy(CS, PS, UC);
If s ∈ US, output true, otherwise, output false.
Figure 2. High-level description of privacy-
preserving trust negotiation
Clearly, UC and US should not be known to either the
client or the server. Thus UC and US need to be maintained
in such a way that the values of UC and US: (1) are un-
known to the client and server and (2) cannot be modiﬁed
by a malicious client or server. We maintain UC in the fol-
lowing split way: For each c ∈ CC, the client generates two
random numbers rc[0] and rc[1], and the server learns one
of them, denoted as rc. If c ∈ UC, then rc = rc[1], oth-
erwise rc = rc[0]. The client does not learn which value
the server obtains, and so by splitting UC in this way, the
client does not learn UC. Furthermore, the server does not
learn anything about UC, as the values he obtains from the
client look random to him. We maintain US in an analogous
way. Our protocol will keep this form of splitting as an in-
variant through all its steps. This does not solve all privacy
problems of the negotiation, but it will be one of the guiding
principles of our protocol.
4.4 Proof of RE Strategy
We now provide a proof of the correctness of the RE
strategy for trust negotiations. That is, we prove that at
the end of the RE negotiation every unusable credential has
been marked as such (the other credentials correctly retain
their initial label of “usable”). So not only does RE not pro-
duce a minimal usable credential set pair CC, CS, in fact it
will produce a maximal pair in the sense that every creden-
tial (whether essential or not) is kept usable unless marked
otherwise. As stated earlier, this is justiﬁed by the indistin-
guishability to either party of any two solution pairs.
Throughout this section, we use CX,i, X ∈ {C, S}, to
denote the usable credential set of the client (if X = C) or
of the server (if X = S) after iteration i of the RE negotia-
tion has completed. We use CX,0 to denote the initial (prior
to iteration 1) usable credential set (which equals CX). We
use ¯X to denote {C, S} − X.
Letting C(X) denote the correct usable credentials for
X, our goal is therefore to prove that, after the last itera-
tion i of the RE negotiation, we have CX,i = C(X) and
C ¯X,i = C( ¯X). Note that CX,i = fX (CX,i−1, C ¯X,i−1) for
some monotonic function fX.
(Although in fact CXi de-
pends only on C ¯X,i−1 and not on CX,i−1, it does no harm
to give a more general proof, as we do below, for the case
when it can depend on both.)
The next lemma proves the intuitive fact that an iteration
i cannot cause an unusable credential to become usable.
Lemma 1 CX,i ⊆ CX,i−1, for i = 1, 2, . . ..
Proof: By induction on i. For the basis of the induction,
i = 1, the claim trivially holds because, prior to iteration
1, all the credentials of each party are in their initial usable
set CX,0. We now turn our attention to the inductive step,
i > 1. Observe that
1. during iteration i, CX,i is computed based on CX,i−1
and C ¯X,i−1, i.e., CX,i = fX (CX,i−1, C ¯X,i−1);
2. during iteration i − 1,
CX,i−1
based on CX,i−2 and C ¯X,i−2,
fX (CX,i−2, C ¯X,i−2);
is
computed
i.e., CX,i−1 =
3. by the induction hypothesis we have CX,i−1 ⊆ CX,i−2,
and C ¯X,i−1 ⊆ C ¯X,i−2
The above facts (1), (2), and (3),
together with the
monotonicity of the function fX, imply that CX,i ⊆ CX,i−1.
(cid:3)
A corollary of the above lemma is that, to prove the cor-
rectness of RE, it sufﬁces to show that for every credential
c of party X, c is unusable if and only if there is some itera-
tion i after which c /∈ CX,i. The next lemma proves the “if”
part. Recall that C(X) denote the correct usable credentials
for X.
Lemma 2 For every i, we have C(X) ⊆ CX,i.
Proof: By induction on i. The basis, i = 0, is trivial
because CX,0 = CX. For the inductive step, i > 0, we
assume that credential c was removed by iteration i (i.e.,
that c ∈ CX,i−1 and c /∈ CX,i), and we show that it must
then be the case that c /∈ C(X). Observe that
1. c /∈ fX (CX,i−1, C ¯X,i−1);
2. by the induction hypothesis, we have C(X) ⊆ CX,i−1
and C( ¯X) ⊆ C ¯X,i−1.
The above (1) and (2), together with the monotonicity of
fX, imply that c /∈ fX (C(X), C( ¯X)), i.e., that c /∈ C(X).
(cid:3)
The above lemma proved that every c removed by the
RE negotiation deserves to be removed (the “if” part). To
complete the proof, we need to prove the “only if” part:
That every unusable credential will eventually be marked as
such by the RE negotiation. That is, we need to prove that
every c /∈ C(X) will, for some i, be removed by iteration i.
This is proved in the next lemma.
Lemma 3 For every c /∈ C(X), there is an iteration i for
which c ∈ CX,i−1 and c /∈ CX,i.
Proof: For every credential c, let the level of c be deﬁned
as follows:
• If c is unconditionally usable then level(c) = 1.
• If the usability policy for c is pc then level(c) = 1 +
max{level(v) : v ∈ R(pc)}. (Recall that R(pc) is the