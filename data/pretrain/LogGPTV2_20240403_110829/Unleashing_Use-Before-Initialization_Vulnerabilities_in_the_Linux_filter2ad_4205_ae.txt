this field is
initialized.
• When a pointer-type field that is not fully initialized
is passed to other functions as a parameter or stored
to memory, we report it as unsafe, which thus requires
initialization.
• When a pointer-type field that is not fully initialized is
dereferenced (i.e., used as the pointer argument in memory
loading instruction (LoadInst), StoreInst, or function call
instruction (CallInst), we treat it as unsafe as well.
The basic alias analysis [23] provided by LLVM is adopted
to tackle the alias problem, so accessing pointer-type fields
via their aliases is also tracked. Since our analysis is intra-
procedural, such a basic alias analysis suffices for the purpose
of efficiently detecting pointer-type fields that lack proper
initialization. With this conservative taint analysis, we managed
to reduce the number of to-be-initialized bytes from 105,960
to 66,846.
2Since
the
the
/proc/sys/vm/mmap_min_addr tunable was introduced to prevent unprivileged
users from creating new memory mappings below the minimum address
version
2.6.23,
kernel
Linux
with
System call
null syscall
stat
open/close
select TCP
signal install
signal handle
fork+exit
fork+exec
prot fault
pipe
TCP
Average
Baseline W/ defense Overhead(%)
(0.0%)
(-4.8%)
(-5.0%)
(7.4%)
(0.0%)
(6.7%)
(-3.7%)
(2.9%)
(8.9%)
(1.7%)
(7.4%)
1.95%
0.04
0.42
1.20
2.44
0.11
0.60
163
447
0.327
8.906
25.6
0.04
0.40
1.14
2.62
0.11
0.64
157
460
0.356
9.058
27.5
TABLE III: LMBench results. Time is in microsecond.
B. Implementation
Both the analysis pass and the instrumentation pass are
implemented with LLVM. Both passes are inserted after all
optimization passes. To use the mitigation, users only need
to specify the option (i.e., -fsanitize=init-pointer) when
compiling the kernel source code. To compile Linux kernel
source code with LLVM, we applied the patches provided
by the LLVMLinux project [25]. The zero-initialization code
is inserted right after allocation sites. In LLVM IR, inline
assembly is invoked by a CallInst, which is treated as a sink
in our analysis, so the common inline assembly in Linux kernel
is not an issue.
C. Evaluating Pointer Initialization
To confirm that our mitigation is practical, we applied it
to the latest Linux vanilla kernel (x86_64, version 4.7) and
evaluated its performance. The testing is performed in the
virtual machine with the secured kernel. The host machine
is equipped with an Intel(R) Core(TM) i7-2760QM CPU @
2.40GHz processor and 10GB of RAM; the running OS is
64-bit Ubuntu 14.04 with Linux kernel version 3.13.0-55. The
virtual machine (VirtualBox) was configured to have a 4-core
processor and 4GB RAM; its OS is also 64-bit Ubuntu 14.04.
We used the default configuration to compile the kernel code.
Performance with system services. We used LMbench [27]
as the micro benchmark to test the runtime slowdown in system
services. The selected system services are mainly syscalls,
which conform to typical kernel performance evaluations (e.g.,
[19]). The evaluation results are shown in Table III. The average
performance overhead is only 2%, and in most cases, the
performance overhead is less than 5%. These numbers confirm
that our zero-initialization-based mitigation for kernel stack is
efficient.
Performance with user programs. We further used the SPEC
CPU 2006 benchmarks as a macro-benchmark to test the
performance impacts of our mitigation over the user-space
programs. We ran the test 10 times and adopted the average
number. Table IV shows the evaluation results. Our zero-
initialization-based mitigation imposes almost no performance
overhead (0.47%) to the SPEC benchmarks on average.
Both the LMbench and SPEC benchmark results confirm
that our mitigation is very efficient and reliable (no single error
was observed during the evaluation).
Programs
perlbench
bzip2
gcc
mcf
gobmk
hmmer
sjeng
libquantum
h264ref
omnetpp
astar
xalancbmk
milc
namd
dealII
soplex
povray
lbm
sphinx
Average
Baseline W/ defense Overhead(%)
(0.0%)
(0.2%)
(0.0%)
(-1.1%)
(0.0%)
(0.5%)
(0.6%)
(0.0%)
(0.5%)
(2.0%)
(-0.4%)
(0.0%)
(0.9%)
(0.1%)
(1.0%)
(0.0%)
(2.5%)
(1.2%)
(0.9%)
0.47%
3.62
4.74
0.945
2.71
13.9
2.02
3.28
0.0365
9.35
0.342
7.77
0.0611
4.47
8.84
10.5
0.0201
0.407
1.66
1.16
3.62
4.75
0.945
2.68
13.9
2.03
3.30
0.0365
9.40
0.349
7.74
0.0611
4.51
8.85
10.6
0.0201
0.417
1.68
1.17
TABLE IV: User space (x86_64) performance evaluation results with
the SPEC benchmarks. Time is in second, the smaller the better.
VIII. RELATED WORK
In this section, we provide a compact overview of the
offensive and defensive related works.
A. Memory Spraying
Memory spraying is a popular means to memory-corruption
attacks. By far the most popular memory spraying techniques is
heap spraying, an attack that was first described by SkyLined
in 2004 [38]. Heap spraying attacks fill large portions of
the victim’s heap memory with malicious code (e.g., NOP
sleds), thus increasing the chance of hitting malicious code for
hijacking the control flow [14, 15]. Although the heap spraying
technique itself has been countered by the introduction of Data
Execution Prevention (DEP), the evolution of heap spraying—
JIT spraying—has become a popular concept for enabling a
variety of web-based attacks [42]. JIT spraying exploits the
predictability of the JIT compiler to create predictable code
fragments that can be used to hijack control-flow [42, 50]. Since
these fragments reside in an executable code cache, mitigation
techniques like DEP or W ⊕ X can be bypassed [42, 50].
Existing defenses against heap/JIT spraying attacks either try
to detect the attack by searching for large amounts of NOP
sleds and shell code [14, 15, 38] or randomizes the memory
layout and register assignments [13, 14, 50]. Recently, memory
spraying has also been used to exploit the "Rowhammer"
vulnerability in DRAM devices where repeated access to a
certain row of memory causes bit flips in adjacent memory
rows [5, 40].
In contrast to all these existing spraying techniques, our
targeted stack-spraying target the stack instead of the heap.
More importantly, our stack spraying technique is deterministic
and stealthy (thus is hard to detect), and our exhaustive memory
spraying technique is highly reliable.
B. Kernel Exploits and Automated Exploits
Since the kernel is often a part of the trusted computing base
of a system, avoiding exploitable kernel vulnerabilities is critical
12
for the security of a system [9]. Nonetheless, despite the efforts
of kernel developers to find and eliminate these vulnerabilities,
new such vulnerabilities are still frequently detected. As of
the paper writing, a total of 1,526 vulnerabilities have been
reported in the Linux kernel alone, 203 of which were reported
in 2016 [37]. With Linux kernel vulnerabilities being on the
rise, corresponding exploitation techniques have caught the
interests of attackers. One recent approach exploits use-after-
free vulnerabilities in the Linux kernel by leveraging its memory
recycling mechanism [51], while another one circumvents
existing defenses by manipulating the kernel page table [21].
Although many vulnerabilities and their corresponding
exploits are still discovered manually, automatic detection
and exploit generation is becoming increasingly popular, as is
evidenced by the DARPA Cyber Grand Challenge (DARPA
CGC) [43]. In this challenge, teams are required to build
automated vulnerability scanning engines, which they then
use to compete in a Capture The Flag tournament. One of the
tools specifically developed for this challenge is Fuzzbomb [28],
which combines static analysis with symbolic execution and
fuzzing to detect vulnerabilities in programs. The combination
of symbolic execution and fuzzing is also used for the Driller
tool [45], which has also been tested on 126 of the DARPA CGC
binaries. Driller, like our approach, uses symbolic execution
to guide its fuzzing engine in case it fails to generate input
to satisfy complex checks in the code. This combination is
also used together with static and dynamic program analysis
to automatically generate exploits for a wide variety of
applications [47]. Similar to these approaches, we also use
a combination of symbolic execution and fuzzing to discover
execution paths that can achieve targeted spraying in the Linux
kernel.
C. Uninitialized Use Exploits
Despite the fact that uninitialized-use bugs are seldom
considered to be security-critical, a number of exploits for these
vulnerabilities have become known in recent years. Flake [16]
used a manual approach towards exploiting uninitialized local
variables on the user-space stack, while Cook [12] used an
unchecked copy_from_user() call with an uninitialized variable
to exploit the Linux kernel and gain root privileges. Jurczyk
in turn exploited CVE-2011-2018, a stack-based uninitialized-
variable reference vulnerability in the Windows kernel, which
allows an attacker to execute arbitrary code with system
privileges [17]. Last but not least, Chen exploited an heap-
based uninitialized-use vulnerability in Microsoft’s Internet
Explorer (CVE-2015-1745) using fuzzing [8]. Unlike these
ad-hoc attacks, our targeted stack-spraying is general and
automated.
D. Uninitialized Use Detection and Prevention
Researchers have proposed some detection mechanisms
for uninitialized uses; however, only few defenses against
uninitialized uses have been proposed. For detection, tools such
as kmemcheck [33], Dr.Memory [6], and Valgrind [41] leverage
dynamic instrumentation and analysis to track memory accesses
while compiler-based approaches like MemorySanitizer [44]
and Usher [52] insert tracking code to find uninitialized uses
at runtime. For defense mechanisms, Kurmus and Zippel [20]
proposed a technique for preventing exploits of memory-
corruption vulnerabilities. Their approach relies on single-split
kernels where system calls of untrusted processes can only
access a hardened kernel version while trusted processes can
access the unmodified kernel. A solution that is specifically
targeted towards uninitialized-use vulnerabilities is offered by
the PaX team, known for the invention of ASLR. Their GCC
compiler plugins, STACKLEAK and STRUCTLEAK, clear
the kernel stack on kernel-to-user transitions and initialize
all local variables that might be copied to user space, which
effectively prevents uninitialized uses of kernel memory [46].
A key difference of our efficient defense against uninitialized
uses is that instead of initializing all local variables, we
specifically initialize pointer-type fields that have not been
properly initialized before. While STACKLEAK and Split
kernel
introduce a significant performance overhead (e.g.,
STACKLEAK introduces an average of 40% runtime overhead
in system operations [26]), our lightweight defense imposes
almost no performance overhead.
E. Memory Safety Techniques
Memory-corruption errors such as dangling pointers are a
long-known problem in unsafe programming languages like C.