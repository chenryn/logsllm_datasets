### Problem and Approach

Existing machine learning (ML) models are designed to directly predict input patterns that achieve higher code coverage. In contrast, our approach utilizes neural networks (NNs) to create a smooth approximation of the program's branching behavior. We then employ gradient-guided input generation techniques to enhance code coverage. This method is more robust to errors in the ML models compared to end-to-end approaches. Our empirical results show that our strategy outperforms end-to-end modeling in both bug detection and edge coverage [72].

### Taint-Based Fuzzing

Several evolutionary fuzzers have attempted to use taint information to identify promising mutation locations [85, 42, 63, 73, 55, 22]. For instance, TaintScope [85] identifies input bytes that affect system or library calls and focuses on mutating these bytes. Similarly, Dowser [42] and BORG [63] use taint information to detect buffer boundary violations and buffer over-read vulnerabilities, respectively. Vuzzer [73] captures magic constants through static analysis and mutates existing values to these constants. Steelix [55] instruments binaries to collect additional taint information about comparison instructions. Angora [22] uses dynamic taint tracking to identify promising mutation locations and performs coordinate descent to guide mutations.

However, taint-tracking-based approaches are limited by the high overhead of dynamic taint analysis and the high rate of false positives in static taint analysis. Our experimental results demonstrate that NEUZZ significantly outperforms state-of-the-art taint-based fuzzers by using neural networks to identify promising mutation locations.

### Gradient-Guided Input Generation

Several studies [83, 22, 43] have explored the use of gradient-guided input generators and test optimization algorithms directly on target programs. However, without program smoothing, these techniques often struggle with discontinuities in the program's execution. Symbolic and concolic execution [50, 14, 77, 61, 36] use Satisfiability Modulo Theory (SMT) solvers to solve path constraints and find interesting test inputs. Some projects have combined fuzzing with symbolic execution [17, 32, 82], but these approaches face scalability issues due to path explosion, incomplete environment modeling, and the high overhead of symbolic memory modeling [16].

Concurrently, NEUEX [79] improved symbolic execution by learning dependencies between intermediate variables using NNs and combining gradient-guided neural constraint solving with traditional SMT solvers. In this paper, we focus on using NNs to enhance fuzzing, as it is the most popular technique for finding security-critical bugs in large, real-world programs.

### Neural Programs

A neural program is a neural network that learns a latent representation of the target program's logic. Recent works have synthesized such neural programs from input-output samples to accurately predict the program's outputs for new inputs [41, 74, 62]. In contrast, we use NNs to learn smooth approximations of a program's branching behaviors.

### Conclusion

We present NEUZZ, an efficient learning-enabled fuzzer that uses a surrogate neural network to smoothly approximate a target program's branch behavior. We demonstrate how gradient-guided techniques can generate new test inputs to uncover different bugs in the target program. Our extensive evaluations show that NEUZZ significantly outperforms ten state-of-the-art fuzzers in terms of detected bugs and achieved edge coverage. Our results highlight the potential of leveraging gradient-guided input generation techniques and neural smoothing to improve the effectiveness of the fuzzing process.

### Acknowledgments

We thank our shepherd Matthew Hicks and the anonymous reviewers for their constructive and valuable feedback. This work is sponsored in part by NSF grants CNS-18-42456, CNS-18-01426, CNS-16-17670, CNS-16-18771, CCF-16-19123, CNS-15-63843, and CNS-15-64055; ONR grants N00014-17-1-2010, N00014-16-1-2263, and N00014-17-1-2788; an ARL Young Investigator (YIP) award; a Google Faculty Fellowship; and an Amazon Web Services grant. Any opinions, findings, conclusions, or recommendations expressed herein are those of the authors and do not necessarily reflect those of the US Government, ONR, ARL, NSF, Google, or Amazon.

### References

[References are listed here, following the same format as provided in the original text.]

This revised version aims to improve clarity, coherence, and professionalism while maintaining the original content and structure.