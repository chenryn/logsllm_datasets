### 4. PrivaDroid Data Collection Platform

The PrivaDroid data collection platform consists of an Android application and a backend system for storing and analyzing the collected data. The platform is designed to gather both behavioral data related to specific events and in-situ survey responses immediately following those events. Additionally, PrivaDroid manages and tracks participant engagement throughout the study. This section outlines the types of data we collect, our survey design, and the localization process for the app into three additional languages. For technical details on PrivaDroid, please refer to Appendix B.

#### 4.1 Behavioral Data

The PrivaDroid application records participants' app installation and permission decision events, as well as the permission rationale dialogs presented by the apps. For app installation events, PrivaDroid logs the app’s package name or application ID, version information, and title. While PrivaDroid separately records app updates, this study focuses solely on initial app installations, disregarding updates. Permission decision events are logged when they occur through runtime permission request prompts or when users navigate to the Android Settings Menu to toggle an app's permissions. For each permission decision event, PrivaDroid captures the app information, the type of permission being requested or modified, and whether the participant granted or denied the permission.

Some applications use custom dialogs to provide explanations for permission requests, along with buttons for users to indicate their willingness to grant the permission. If the user agrees, the app will subsequently request the permission via the Android system. However, if the user disagrees, the app will not make the request. This practice can reduce the number of permission requests made via the system APIs, leading to undercounting of permission denials. To measure this effect and the frequency of such custom permission explanation dialogs, PrivaDroid captures the text on these dialogs using a keyword-based heuristic and the button that was clicked. The accuracy of this heuristic is evaluated in Section 5.3.1.

#### 4.2 Survey Design

Participants in the PrivaDroid study complete three types of surveys, detailed in Appendix A:

1. **Demographic Survey**: Immediately after sign-up, participants are required to provide demographic information, including age, gender, income, and education level. This data is used to analyze and compare behavior and privacy perspectives across different demographic groups.

2. **In-Situ Surveys**: These surveys are triggered at the moment a relevant event occurs, capturing participant expectations, comfort, or decision rationales. At the time of app installation, one survey (Appendix A.2) captures expectations about permissions before the app is used. Additional surveys (Appendix A.3 and A.4) are invoked right after a permission grant or deny event to capture participant rationales, runtime expectations, comfort, and the desire to grant temporarily. To avoid overloading participants, there is a minimum 5-minute interval between consecutive in-situ surveys [45].

3. **Exit Survey**: At the end of the 30-day study, participants must complete an exit survey to receive compensation. This survey uses questions from the established IUIPC privacy scale [23] to compute a privacy score for each participant along four dimensions: Control, Awareness, Collection, and Secondary Use. The original IUIPC scale, developed in 2004, focused on general "Internet use." We adapted the questions to focus on mobile privacy by replacing terms like "online companies" with "smartphone apps" and "consumer online privacy" with "mobile app privacy." Our 15 questions (Appendix A.5) are scored on a 5-point Likert scale, rather than the original 7-point scale, to accommodate multilingual surveys [47]. Answers are mapped to the range {−2,2}. To evaluate the quality of our mobile-specific IUIPC questions, we conducted a 100-person Amazon Mechanical Turk survey, which resulted in Cronbach’s Alpha scores in the range of 0.65 to 0.82, indicating acceptable reliability. Both the PrivaDroid and mTurk surveys include an attention check question to ensure participants are reading the questions, and data from participants who fail to answer correctly are discarded.

#### 4.3 App Localization

To include non-English speaking participants, PrivaDroid has been translated and localized into Chinese (Traditional), Spanish, and French. The translation process involves two parts:
1. **App Strings**: This includes the consent form, survey questions, and answers, which were translated using the Google Play Console service and then reviewed by native speakers.
2. **Android System UI Strings**: These include strings used in detecting permission changes made in the Android Settings menu, Android system runtime permission dialogs, and participants’ decisions. For these, we used translations provided in the open-sourced Android framework Git repositories.

### 5. Findings

#### 5.1 Data Summary

We advertised our study across three advertising networks in 10 countries and regions, running it from November 2019 to May 2020. Initially, we targeted females to encourage their participation. After recruiting at least 50 females per country, we relaxed the criteria to include all genders. Hong Kong was the only region where we did not reach 50 female participants; thus, we exclude Hong Kong data from demographic analysis but include it in aggregate analysis. In total, we spent $12,953.85 USD on advertising, generating 2,640,029 impressions, 20,947 clicks, and 5,377 installs of the PrivaDroid app. Of these, 1,719 participants completed the 30-day study. The gender distribution included 1,044 males, 655 females, and 10 participants who identified as neither or preferred not to state their gender. Another 2,207 participants joined but withdrew before completing the study. Table 1 summarizes the participant demographics. During the study period, participants carried out 72,214 app installation events, with 36% surveyed, and 36,152 permission decision events, with 30% surveyed. Due to our self-imposed limit on the frequency of daily surveys, not all events triggered a survey.

| Country/Region | Males | Females | Other/Prefer not to say |
|----------------|-------|---------|------------------------|
| Canada         | 107   | 75      | 5                      |
| US             | 99    | 132     | 3                      |
| Argentina      | 175   | 57      | 0                      |
| UK             | 86    | 57      | 1                      |
| France         | 97    | 53      | 0                      |
| Spain          | 126   | 82      | 1                      |
| South Africa   | 56    | 70      | 0                      |
| India          | 187   | 57      | 0                      |
| Singapore      | 59    | 52      | 1                      |
| Hong Kong      | 52    | 20      | 0                      |
| Total          | 1,044 | 655     | 10                     |

**Table 1: Country and Gender Demographics**

#### 5.2 Permission Denials

Of the approximately 36,000 permission decision events across 11 permission groups, participants denied 16.7% of these requests. Even without considering recently introduced permissions (e.g., Body Sensors, Physical Activity, and Call Logs), the average denial rate is close to the 16% reported in an earlier study [4]. In our current study, 8% of permission decisions occurred via the Settings menu, similar to the 5% reported in [4]. For these aggregate metrics, behavior has not changed much since 2017. Of the decisions made via the Settings menu, 40% were to deny a previously granted permission. While this number is high, it still indicates that the majority of decisions in the Settings menu were to grant a permission. As we will see, a top reason for denying a permission is the awareness that participants can later change their decision in the Settings menu.

The number of events and denial rates vary significantly based on the individual permission type. Permissions for Storage, Location, and Camera were frequently requested, each with more than 5,000 events. However, we observed very few permission decision events for Body Sensors, Call Logs, and Physical Activity, likely due to their novelty at the time of the study.

Figure 1 shows the denial rates for each permission group (excluding those with fewer than 50 decision events). Microphone, Calendar, and Contacts have the highest denial rates of 30%, 25%, and 19%, respectively. Permissions such as Location and Storage, which are the most frequently requested, have lower denial rates of 15% and 12%. The average denial rate across all permission requests was 16.7%. Compared to the denial rates recorded in [4] (which only included US participants), we see that denial rates for our US participants have increased for Calendar (to 21.7% from 10%) and SMS (to 15.6% from 10%), and decreased for Phone (12.6% from 19%), Location (8.5% from 15%), and Camera (11% from 15%).

Approximately 11% of our participants had Android 10 devices, which introduced the foreground-only permission option. Although denial rates for the Location permission on Android 10 and earlier versions were roughly the same at 17% and 15%, two-thirds of the Location permission grants in Android 10 were for foreground-only use. This suggests that users not only want to control whether location can be used but also when it is used. Since the option is only available for the Location permission and in Android 10, which did not make up a large portion of the data, we treat foreground-only options as permission grants in this paper.

When examining the rationales for denying permissions, the top three reasons were: “I can always grant it afterwards if I change my mind” (27% of denials), “I do not use the specific feature associated with the permission” (25% of denials), and “I think the app shouldn’t need this permission” (23% of denials). The first reason indicates that participants are aware of their ability to revise permission decisions, while the second and third reasons suggest that users may be trying to enforce the principle of least privilege based on their usage or understanding of the app. These rationales show that users consider app functionality and features when making permission decisions, which relates to the expectations analyzed in Section 5.3.

Our top reasons for denial are similar to those found in [4] (see Table 5 therein) with minor shifts in frequency. We tested the null hypothesis that the reasons for denying permissions in both our experiment and in [4] are from the same distribution using a Two-Sample Kolmogorov-Smirnov (K-S) test (using the data in Table 5 of [4]). The resulting Kolmogorov–Smirnov statistic (D value) is 0.375 with a p-value of 0.66. We thus accept the null hypothesis that the distribution of denial rationales has remained essentially the same as in [4], and the top reasons remain unchanged.

Similarly, the top reasons for granting permissions include: “I want to use a feature that needs this permission” (37% of grants), “I think the app won’t work otherwise” (25% of grants), and “I trust the developer” (23% of grants). These top reasons are the same as those indicated in [4]. Trust in the developer still plays a crucial role in whether participants decide to grant a permission to an app. To compare the histograms of grant reasons across the two studies, we formed a null hypothesis that the frequencies at which grant reasons were selected in both [4] and our experiment are from the same distribution. We conducted a two-sample K-S test and obtained a D value of 0.125 with a p-value of 1. Since the p-value is larger than the critical value of 0.05, we cannot reject the null hypothesis, and thus conclude that the frequency of how often each grant reason was chosen in our experiment is consistent with [4].

Overall, the top reasons for both grants and denials suggest that participants tend to rationalize their permission decisions as a trade-off between functionality and privacy. Reasons suggesting a more emotional response, such as “I have nothing to hide” or “I wanted the permission screen to go away,” were chosen less often.

**Temporary Permissions**: We also asked participants each time after they granted a permission if they would have preferred to grant it temporarily. We found that 24% of the times participants chose to grant a permission, they would have preferred to do so temporarily. Among the permissions surveyed at least 50 times, the desire to grant temporarily ranged from 21% to 26% depending on the permission. In line with this, the Android 11 OS release [41] includes a one-time grant option for Location, Microphone, and Camera permissions.

One could interpret the desire to grant temporarily as a hesitation or lack of comfort in granting a permission permanently. To check this, we compared how comfortable participants felt when granting permissions with their desire to grant them temporarily. When participants indicated they were not interested in granting a permission temporarily, 53% selected that they felt either very or somewhat comfortable granting those permissions. However, among those who said they would have liked to grant the permission temporarily, only 36% felt very or somewhat comfortable. To determine the influence of user comfort level on the desire to grant temporarily, we conducted a mixed-effects logistic regression on the grant surveys. In the mixed-effects logistic regression, we treated the participants’ indicated comfort level on the 5-point Likert scale as a numeric independent feature in the range [−2,2] and the desire to grant temporarily as the dependent feature. We included the permission type as a fixed effect to control for the influence of different numbers of events for each permission, and the participant and app as random effects to account for latent individual differences between participants and apps. The trained model showed a significant difference due to comfort.