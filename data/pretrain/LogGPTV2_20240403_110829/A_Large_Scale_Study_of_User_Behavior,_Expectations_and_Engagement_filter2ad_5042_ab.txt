4 PrivaDroid Data Collection Platform
The PrivaDroid data collection platform consists of an An-
droid application and a backend that stores and analyzes data.
PrivaDroid is designed to collect both behavioral data on cer-
tain events and in-situ survey responses right after those events
occur. PrivaDroid manages and tracks participant participa-
tion over the course of the study. We describe the data we col-
lect, how we design surveys and how we localize PrivaDroid
into 3 other languages. Technical details of PrivaDroid can be
found in Appendix B.
4.1 Behavioral Data
The PrivaDroid application records participants’ app install
and permission decision events, as well as the permission
rationale dialogs shown by the app. For app install events
PrivaDroid logs the app’s package name or the application ID,
its version info and the title. PrivaDroid records app updates
from app installs separately, but this study only considers
app installs and ignores updates. PrivaDroid logs permission
decision events that happen in the runtime permission re-
quest prompts, as well as decisions that occur when the user
navigates to the Android Settings Menu and toggles an app
permission there. For each permission decision event, Pri-
vaDroid captures the aforementioned app information, the
permission type being requested by the app or being modiﬁed
by the participant, as well as whether the participant granted
or denied the permission.
Some apps use a custom dialog that provides an expla-
nation for a permission request along with a set of buttons
for the users to indicate whether they are willing to grant
the permission. If the user agrees, the app will subsequently
request the permission via Android system. However, if the
user does not agree, the app will not request the permission.
This has the side effect of reducing the number of permission
requests made by an application via the system APIs, and
causing under-counting of the number of permission denies,
since PrivaDroid’s monitoring of permission decisions via the
system APIs doesn’t capture deny events occurring indirectly
in custom dialogs. To measure this effect, as well as measure
the frequency of applications using such permission expla-
nation dialogs, PrivaDroid captures the text on these dialogs
using a keyword-based heuristic and the accompanying button
that was clicked. We evaluate the accuracy of our heuristic in
Section 5.3.1.
4.2 Survey Design
Participants answer three types of surveys in the PrivaDroid
app (provided in Appendix A). First, PrivaDroid uses a sur-
vey to capture the demographic information of our recruited
participants. Participants are required to take this survey right
after sign-up. They are asked to provide their age, gender,
income and education level. We use this data to analyze and
compare behavior and privacy perspectives across different
demographic groups.
Second, PrivaDroid presents in-situ surveys that are de-
signed to capture either the participant expectation, comfort,
or decision rationale at the moment a relevant event occurs.
At app install time, we invoke one survey (Appendix A.2) to
capture expectations about permissions before the app is used.
Other surveys are invoked right after a permission grant or
deny event, so we can capture participant rationales, runtime
expectations, comfort, and desire to grant temporarily (Ap-
pendix A.3 and A.4). Following best practices, we impose a
limit of a minimum of 5 minutes between consecutive in-situ
surveys to avoid overloading participants [45].
Last, participants are required to answer an exit survey
at the end of the 30 day study to complete the experiment
and receive the compensation. The survey derives questions
from the well established IUIPC privacy scale [23]. The ques-
tions are used to compute a privacy score for each participant
along the four dimensions: Control, Awareness, Collection
and Secondary Use. As the IUIPC scale was originally de-
veloped in 2004 and focused on general “Internet use”, we
adapted the questions in a minor way to focus on mobile pri-
vacy. Speciﬁcally, we replaced the term “online companies”
with “smartphone apps”, and replaced the term “consumer
online privacy” with “mobile app privacy”. Our 15 questions
(See Appendix A.5) were scored on a 5-point Likert scale,
as opposed to the original 7-point scale as we learned that
multilingual surveys are more frequently done with 5-point
scales [47]. We mapped the answers to the range {−2,2}. To
evaluate the quality of our mobile-speciﬁc IUIPC questions,
we conducted a 100 person Amazon Mechanical Turk survey
and the resulting Cronbach’s Alpha scores in the range of
0.65 to 0.82 demonstrate acceptable reliability. Both the Pri-
vaDroid and mTurk surveys include a simple attention check
question to ensure that participants are actually reading the
questions, and we discard the data of participants who fail to
correctly answer the question.
806    30th USENIX Security Symposium
USENIX Association
4.3 App Localization
In order to include non-English speaking participants, we
translated and localised PrivaDroid into Chinese (Traditional),
Spanish and French. The translation consists of two parts:
1) strings in the PrivaDroid app, such as the consent form,
the survey questions and answers, etc.; and 2) strings in the
Android System UI, such as those used in detecting the per-
mission changes participants made on the Android Settings
page, Android system runtime permission dialogs and partic-
ipants’ decisions. For the ﬁrst part, we used the translation
service provided by the Google Play Console and then had
native speakers check the translations. For strings involved in
the Android System UI, we used the translations provided in
the open-sourced Android framework Git repositories.
5 Findings
5.1 Data Summary
We advertised our study on the three advertising networks
mentioned earlier, across 10 countries and regions, and ran
it from Nov 2019 to May 2020. As mentioned before, we
initially targeted our ads towards females to encourage their
participation. After onboarding 50 or more females per coun-
try, we relaxed the targeting criteria and showed ads to all.
Hong Kong was the only region where we did not reach 50
female participants; thus we use the Hong Kong data for ag-
gregate analysis hereafter, but not for demographic analysis.
In total we spent $12,953.85 USD on advertising to recruit
participants, which generated 2,640,029 impressions, 20,947
clicks and 5,377 installs of the PrivaDroid app. Of the installs,
1,719 participants stayed for the required 30 day period to
complete the study. 1,044 of our participants identiﬁed them-
selves as males, 655 as females, and the rest identiﬁed as
neither or preferred not to state their gender. Another 2,207
participants joined the study but withdrew before 30 days, thus
we exclude their data. (Many participants installed the app but
didn’t join the study.) Table 1 summarizes some participant
demographics. During the study period, these participants
carried out 72,214 app install events of which 36% were sur-
veyed, and 36,152 permission decision events of which 30%
were surveyed. Due to our self-enforced limitation on how
frequently surveys were shown to participants each day, not
all events result in a survey being triggered.
5.2 Permission Denials
Of the ∼36K permission decision events across the 11 per-
mission groups, we found that our participants denied 16.7%
of these permission requests. Even without considering the
events for recently introduced permissions (such as Body Sen-
sors, Physical Activity and Call Logs), the average deny rate
is very close to the 16% reported in an earlier study [4]. In
Country and Males
Region
Canada
US
Argentina
UK
France
Spain
South Africa
India
Singapore
Hong Kong
Total
107
99
175
86
97
126
56
187
59
52
1,044
Females Other
Prefer not
to say
75
132
57
57
53
82
70
57
52
20
655
5
3
0
0
1
1
0
0
0
0
10
1
3
1
0
0
3
0
0
1
1
10
Table 1: Country and Gender Demographics
Figure 1: Permission deny rates for each permission group
our current study, we observed that 8% of the permission de-
cisions occurred from the Settings menu, which is similar to
the 5% reported in [4]. For these two aggregate metrics, the
behavior has not changed much since 2017. Of all the deci-
sions our participants made via the Settings menu, 40% were
to deny a previously granted permission. While this number
is high, it still means that the majority of decisions made at
the Settings menu were to grant a permission. As we will
see shortly, a top reason for denying a permission is because
participants are aware that they can go to the Settings menu
and change their decision afterwards.
Both the number of events and deny rates vary a lot based
on the individual permission type. Storage, Location, and
Camera were heavily requested with each having >5K events.
However, we saw very few permission decision events for
Body Sensors, Call Logs and Physical Activity permissions -
perhaps because these three permissions were fairly new (at
USENIX Association
30th USENIX Security Symposium    807
MicrophoneCalendarContactsCameraPhoneLocationStorageSMSCall LogsPermission type051015202530Deny rate (%)the time of our study).
Figure 1 shows deny rates for each permission group (we
only include those with at least 50 decision events, thus elim-
inating Body Sensors and Physical Activity). Microphone,
Calendar and Contacts have the highest deny rates of 30%,
25% and 19%, respectively. Permissions such as Location and
Storage, which are the most frequently requested in our data,
have lower deny rates of 15% and 12%. The average deny rate
across all permission requests was 16.7%. Compared to deny
rates recorded in [4] (which only included US participants),
we see that deny rates for our US participants have increased
for Calendar (to 21.7% from 10%) and SMS (to 15.6% from
10%), and decreased for Phone (12.6% from 19%), Location
(8.5% from 15%), and Camera (11% from 15%).
About 11% of our participants had Android 10 devices,
giving them access to the foreground only permission option
introduced in it. Although deny rates for the Location per-
mission on Android 10 and earlier were roughly the same at
17% and 15%, two thirds of the Location permission grants
in Android 10 were foreground only. This suggests that users
not only want to be able to control if location can be used,
but when it is used as well. Since the option is only avail-
able for Location permission and in Android 10 alone, which
did not make up a big portion of the collected data, we treat
foreground only option as a permission grant in this paper.
In examining the rationales our participants gave for deny-
ing permissions, we see that the top three reasons for denies
are: “I can always grant it afterwards if I change my mind”
(27% of denies), “I do not use the speciﬁc feature associated
with the permission” (25% of denies), and “I think the app
shouldn’t need this permission” (23% of denies). The ﬁrst
reason indicates that participants are aware that they have the
ability to revise their permission grant and deny decisions,
while the second and third reason demonstrate that users may
be trying to enforce the principle of least privilege either
based on their usage of the application or their understanding
of the operation of the application. These rationales illustrate
that users think about app functionality and app features they
use, when permission requests are made; this kind of thinking
relates to expectations that we analyze in Section 5.3.
Our top reasons are the same as those found in [4] (see
Table 5 therein) with minor shifts in frequency. We test the
null hypothesis that the reasons for participants denying per-
missions in both our experiment and in [4] are from the same
distribution using a Two-Sample Kolmogorov-Smirnov (K-S)
test (using the data in Table 5 of [4]). The resulting Kol-
mogorov–Smirnov statistic (D value) is 0.375 with a p-value
of 0.66. We thus accept the null hypothesis that the distribu-
tion of deny rationales has essentially remained the same as
in [4], and the top reasons remain unchanged.
Similarly, the top reasons for permission grants include:
“I want to use a feature that needs this permission” (37%
of grants), “I think the app won’t work otherwise” (25% of
grants), and “I trust the developer” (23% of grants). These
top reasons are the same as those indicated in [4]. Trust in
the developer still seems to play an important role in whether
participants decide to grant a permission to an app. To com-
pare the histograms of grant reasons across the two studies,
we form a null hypothesis that the frequencies at which grant
reasons were selected in both [4] and our experiment are from
the same distribution. We again conducted a two sample K-
S test and obtained a D value of 0.125 with a p-value of 1.
Since the p-value is larger than the critical value of 0.05, we
cannot reject the null hypothesis, and thus conclude that the
frequency of how often each grant reason was chosen in our
experiment is consistent with [4].
Overall, the top reasons for both grants and denies sug-
gest that participants tended to rationalize their permission
granting and denying as a trade-off between functionality
and privacy. Reasons that suggest a more emotional response,
such as “I have nothing to hide” or “I wanted the permission
screen to go away” were chosen less often.
Temporary permissions. We also asked participants each
time after they granted a permission, if they would have liked
to grant it temporarily. We found that 24% of the times partic-
ipants chose to grant a permission, they would have preferred
to do so temporarily. Among the permissions that were sur-
veyed at least 50 times, the desire to grant temporarily ranged
from 21% to 26% depending upon the permission. In line with
this, the Android 11 OS release [41] includes a one-time grant
option for Location, Microphone and Camera permissions.
One could interpret the desire to grant temporarily as a
hesitation, or lack of comfort, in granting a permission per-
manently. To check this, we ﬁrst compared how comfortable
participants felt when granting permissions with their desire
to grant them temporarily. In the cases when participants
indicated they were not interested in granting a permission
temporarily, 53% of them selected that they felt either very or
somewhat comfortable granting those permissions. However,
among those who said they would have liked to grant the
permission temporarily, only 36% of them felt very or some-
what comfortable. To determine the inﬂuence of user comfort
level on the desire to grant temporarily, we carried out mixed
effects logistic regression on the grant surveys. In the mixed
effects logistic regression, we treat the participants’ indicated
comfort level on the 5-point Likert scale as numeric indepen-
dent feature in the range [−2,2] and the desire to temporarily
grant as the dependent feature. We include the permission
type as a ﬁxed effect to control the inﬂuence of different num-
ber of events for each permission, and the participant and
app as random effects so that the latent individual differences
between participants and apps are taken into account in the
form of different intercepts for each participant and app. The
trained model shows a signiﬁcant difference due to comfort