n to n. 
4.2. The Install Part of the Protocol 
together  with 
the  new  coordinator 
A  process  pi  that  receives  an  authentic,  doubly-
signed fail-signal from pc or p′c executes these steps: 
IN1:  c:=  c+1.  Ignore  any  incoming  order  message 
until 
installed.  Prepare 
BackLog message containing (a) received fail-signal, 
(b) committed order with the largest sequence number 
(max_committed) 
the  proof  of 
commitment,  and  (c)  all  acked  but  uncommitted 
orders. Multicast BackLog to all processes. 
IN2:  If  pi  =  pc  then  wait  until  BackLog  is  received 
least  (n-f)  distinct  processes.  Compute 
from  at 
NewBackLog  and  start_o  as  mentioned  below  and 
prepare a Start message containing those two. If pc is 
a  paired  process,  sign  and  send  Start  with  all  (n-f) 
BackLogs  to  p′c  else  sign  and  multicast  Start  to  all 
processes.  p′c  verifies  if  pc  computed  properly  the 
Start  as  per  the  (n-f)  BackLogs  received  with  it.  If 
Start is found valid, it is doubly-signed and multicast. 
IN3:  If  f  >  1,  any  pi  or  p′i,  i  ≠  c,  that  receives  an 
authentic doubly- signed Start, generates its signature 
for the received and sends its unique identifier and the 
signature to pc and  p′c. 
IN4:  pc  and  p′c,  after  receiving  identifier-signature 
tuples  from  (f-1)  distinct  processes  (other 
than 
themselves), multicasts these tuples to all.  
IN5: Any pi that receives an authentic doubly-signed 
Start and (f-1) identifier-signature tuples, regards that 
the new coordinator has been installed, treats Start as 
an order message with sequence number start_o and 
executes  the  normal  part  of  the  protocol to get Start 
committed.  Once  committed,  all  order  messages 
included in it are considered committed as well. Note 
if the max_committed of pi is smaller than the smallest 
o of order messages contained in Start, it is possible 
that pi has some order messages missing. In that case, 
pi  is  guaranteed  to  receive  each  of  those  order 
messages from at least (f+1) correct processes due to 
the  way  NewBackLog  is  computed.  So  it  waits  for 
(f+1) agreeing order messages to be received. 
The  process  pc  computes  NewBackLog  by  first 
including  the  order  that  has  the  largest  sequence 
number  (o)  amongst  all  the  max_committed  orders 
received 
(Let 
max{max_committed}  denote  o  of  this  order.)  It 
then includes every uncommitted order present in any 
(n-f)  BackLogs  with  sequence  no.  > 
of 
max{max_committed}.  
BackLogs. 
(n-f) 
in 
the 
the 
It  is  possible  that  p′c  finds  order 
and  order,  m  ≠  m’,  in  the  (n-f) 
BackLogs which it received from pc (together with 1-
signed  Start).  If  so,  it  should  verify  whether  pc  has 
chosen  to  put  the  ‘right’  order,  if  any,  into  the 
NewBackLog,  where  the  right  order  is  the  one  that 
might have been committed by some correct process. 
This  verification  is  done  using  the  BackLogs  which 
p′c  received  directly  from  other  processes.  Omitting 
the  details  for  space  reasons,  we  present  only  the 
principles  underpinning  this  verification.  If  both 
order  and  orderare 
doubly-signed  and  authentic,  then  both    pc-1  or  p′c-1 
have  failed  and,  by  assumption  3(a)(ii),  at  least  2D 
time  has  elapsed  subsequent  to  the  first  of  these 
failures has been observed. So, if, say, order,  is  committed  by  some  process,  then  p′c  will 
have at least (f+1) processes having included order      in  their  backlogs  and  only  at  most  f 
processes having included order.  
4.3. Protocol Optimizations 
This  sub-section  presents  two  optimisations.  The 
first  one  seeks  to  reduce  the  number  of  processes 
injecting  messages  on  to  the  network.  By  property 
SC3 and assumption 3(a)(i), a fail-signalled pair does 
have at least one failed process in it. So, every time a 
new coordinator is installed, the processes of the old 
coordinator  are  turned  into  ‘dumb’  processes  which 
can  execute 
transmit 
messages.    The  total  number  (n)  of  processes  in  the 
system is reduced by 2 to account for the new dumb 
processes  and  the  maximum  number  (f)  of  faulty 
processes by 1. 
the  protocol  but  cannot 
The  second  optimisation  aims  to  reduce  the 
number of order messages and ack messages injected 
into  the  system  through  batching  of  order messages. 
The coordinator process pc batches the doubly-signed 
order  messages  generated  over  a  period  of  time, 
batching-interval,  and  transmit  a  batch  of  order 
messages; similarly, processes transmit ack messages 
for  a  batch  of  order  messages.  Note  that  batch-size 
can become large if a long batching-interval is chosen 
or if too many client requests are sent. The effects of 
varying batching-interval and batch-size are studied in 
Section 5. 
4.4  Protocol  Extension  for  Signal-on-Crash 
and Recovery Set-up 
We suppose now that the assumptions of 3(b) hold 
instead  of  those  of  3(a).  Observe  that  only  3(b)(i)  is 
weaker compared to 3(a)(i). So, the extension needs to 
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:20:38 UTC from IEEE Xplore.  Restrictions apply. 
of 
the 
{up, 
pair: 
status 
address  only  the  implications  that  arise  due  to 
weakening of 3(a)(i), possibly by taking advantage of 
assumption 3(b)(ii): at least one process within a pair 
is always non-faulty.  
  A major implication of 3(b)(i) being weaker is that 
paired-processes  pc  and  p′c  may  find  each  other 
untimely even if both are non-faulty. So, after having 
fail-signalled,  if  they  subsequently  find  each  other 
timely  through  their  continued  mutual-checking  (see 
Section  3.1),  they  should  work  as  a  pair  if  the  need 
arises. Thus, SC2 holds no longer. Each process pc or 
p′c maintains a status variable statusc that indicates the 
down, 
operative 
permanently_down}.  statusc  is  irreversibly  set  to 
permanently_down  when  a  process  observes  a  value 
domain failure of its counter-part. 
Since  SC2  does  not  hold,  it  can  no  longer  be 
ascertained  that  f  failures  have  occurred  if  f  distinct 
process-pairs  have  fail-signalled,  and  therefore  when 
the  un-paired  pf+1  becomes  the  coordinator  it  cannot 
be  expected  to  be  non-faulty.  So,  (at  least)  (f+1) 
process-pairs  are  now  required  and  we  assume  that 
is  paired  with  p′f+1,  bringing  n  =  3f+2; 
pf+1 
furthermore, only paired processes are allowed to act 
as  coordinators.  Note  that  there  will  be  at  least  one 
process  pair  in  which  both  processes  are  non-faulty 
and see each other timely starting from some unknown 
time.  So,  eventually,  there  is  a  process-pair  whose 
operative status will be always up. However, until that 
always-up pair emerges and becomes the coordinator, 
the  system  can  be  in  an  unstable  state,  calling  for 
frequent coordinator changes.  We propose to use the 
view-change  part  of  BFT  protocol,  except  for  the 
following modifications: 
For  view  v,  the  pair  {pc,  p′c}  is  the  coordinator 
candidate where c = (v mod (f+1)) if (v mod (f+1)) ≠ 0, 
c = (f+1) otherwise. If pc or p′c does not have statusc = 
up when a ViewChange(v) message is received and 
therefore  does  not  want  to  act  as  the  coordinator  for 
the  proposed  new  view  v,  then  it  multicasts  an 
Unwilling(v)  message  which  includes  the  fail-signal 
message  as  well.  Any  process 
receives 
Unwilling(v) echoes it back to both pc or p′c  and, as in 
the  BFT  protocol,  multicasts  a  ViewChange(v+1) 
message.  (Note that non-coordinator processes do not 
wait  on  timeout:  they  either  expect  view  v  to  be 
installed  or  Unwilling(v)  to  be  received.)  If,  on  the 
other hand, pc and p′c have statusc = up, pc acts as the 
‘primary  process’  of  the  BFT  protocol,  with  all  its 
messages get endorsed and multicast by p′c as shown 
in Figure 2. 
that 
5.  Protocol 
Performance Study  
Implementation 
and 
The  protocols  were  implemented  in  Java  using 
JDK  1.5  and  on  a  cluster  of  15  Linux  machines 
(Fedora Core 4) connected by a LAN. Each machine 
has a 2.80 GHz Pentium IV processor and 2GB RAM. 
Paired  processes  communicate  using  RMI  and  the 
unpaired ones using TCP/IP sockets. The performance 
study has two parts: the first is of comparative nature 
in  the  best-case  scenario  and  the  second  involves 
assessing our protocols’ ability to deal with failures.  
The comparative performance study considers our 
protocols, BFT and a crash-tolerant protocol, denoted 
as  CT.  The  best-case  scenario  for  all  these  protocols 
is: no failures and also no suspicions of failures (see 
also  [2]).  In  this  scenario,  the  unknown  timing 
instance of assumption 3(b)(i) (in sub-section 2.1.1) is 
the system start-up time itself, i.e., 3(b)(i) becomes the 
same  as  3(a)(i).  So,  the  protocol  developed  for  the 
Signal-on-Crash set-up (denoted from now on as SC) 
behaves identically to its extension for the Signal-on-
Crash  and  Recovery  set-up.  Their  distinction  is 
meaningful only in the second part of the study. CT is 
simply derived from SC, with no process being paired 
and  no  cryptographic  techniques  used.    Specifically, 
the  shadow  processes  are  excluded  from  the  system 
(hence  n  =  2f+1),  the  coordinator  process  directly 
sends its order message to all other processes, and an 
order  message  is  committed  in  the  same  way  as  SC. 
CT  performance  can  therefore  be  used  to  see  the 
extent of slow-down in BFT and SC when the type of 
faults tolerated switches from crash to Byzantine. The 
parameters we measure are precisely defined below. 
Latency is the time interval between the instance the 
request is batched by the coordinator and the instance 
the  first  process  commits  a  sequence  number  (o)  for 
that request. This does not include the time duration a 
received request spends waiting to be batched. 
Throughput is the number of messages committed by 
an order process per second.  
Fail-over  latency  is  measured  as  the  time  interval 
between  the  moment  the  current  coordinator  issues 
fail-signal and the instance the new coordinator issues 
a Start message with (f+1) identifier-signature tuples.  
The parameters we vary are described below. 
techniques, 
Batching interval is varied from 40 milliseconds (ms) 
to  500  ms,  and  the  batch_size  is  fixed  at  1  KB. 
Cryptographic 
these 
experiments, constitute of three distinct combinations 
of  message  digest  and  signature  schemes:  MD5  for 
taking message digests together with RSA scheme for 
key sizes of 1024 and 1536, and SHA1 with DSA for 
the key size of 1024.  
used 
for 
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:20:38 UTC from IEEE Xplore.  Restrictions apply. 
Figure 4: Order latency for f = 2 using (a) MD5 with RSA key size 1024 (b) MD5 with RSA key size 
1536 (c) SHA1 with DSA key size 1024. 
 The 
Fault-  tolerance  parameter  (f)  takes  the  value  of  2 
and 3.  
BackLog  size  is  varied  between  1  KB  to  5  KB  to 
examine its effect on fail-over latency.  
results  of  our  performance  study  are 
presented  in  the  following  manner.  Figure  4  depicts 
order  latency  vs.  batching  interval  for  all  three 
protocols, each for all three cryptographic techniques 
and  f  fixed  at  2.  Figure  5  shows  throughput  vs. 
batching interval for all three protocols with all three 
cryptographic  techniques  and  f  fixed  at  2.    Finally, 
figure  6  shows  the  fail-over  latencies  of  the  SC 
protocol and its extension for the Signal-on-Crash and 
Recovery set-up, which we denote as SCR. They are 
measured  for  various  BackLog  sizes,  for  all  three 
crypto-techniques and for f = 2. Each point in a graph 
is an average over 100 experimental results. 
one 
into 
involving:  1 
to  order  a  request 
Order Latency: As depicted in Fig 3, BFT has three 
to  n 
phases 
(coordinator to all), n to n, and again n to n message 
transmissions;  the  SC  has  its  three  phases  as:  1  to  1 
(for  endorsement  within  the  pair),  2  to  n  (endorsed 
output to all), and n to n transmissions. Note that CT 
will only have the first and the second phases of SC 
combined 
coordinator 
disseminating  to  all  (1  to  n)  followed  by  n  to  n 
transmissions;  also  no  cryptographic  overhead  is 
incurred. 