title:Equivalence-based Security for Querying Encrypted Databases: Theory
and Application to Privacy Policy Audits
author:Omar Chowdhury and
Deepak Garg and
Limin Jia and
Anupam Datta
Equivalence-based Security for Querying Encrypted
Databases: Theory and Application to Privacy Policy
Audits
Omar Chowdhury
Purdue University
West Lafayette, Indiana
Deepak Garg
MPI-SWS
Germany
Limin Jia, Anupam Datta
Carnegie Mellon University
Pittsburgh, Pennsylvania
PI:EMAIL
PI:EMAIL
{liminjia,danupam}@cmu.edu
ABSTRACT
To reduce costs, organizations may outsource data storage
and data processing to third-party clouds. This raises conﬁ-
dentiality concerns, since the outsourced data may have sen-
sitive information. Although semantically secure encryption
of the data prior to outsourcing alleviates these concerns,
it also renders the outsourced data useless for any rela-
tional processing. Motivated by this problem, we present
two database encryption schemes that reveal just enough
information about structured data to support a wide-range
of relational queries. Our main contribution is a deﬁnition
and proof of security for the two schemes. This deﬁnition
captures conﬁdentiality oﬀered by the schemes using a novel
notion of equivalence of databases from the adversary’s per-
spective. As a speciﬁc application, we adapt an existing
algorithm for ﬁnding violations of a rich class of privacy
policies to run on logs encrypted under our schemes and
observe low to moderate overheads.
Categories and Subject Descriptors
H.2.0 [DATABASE MANAGEMENT]: General—Secu-
rity, integrity, and protection; K.4.1 [Computers and So-
ciety]: Public Policy Issues—Privacy, Regulation
Keywords
Privacy Policy Audit; HIPAA; GLBA; Querying Encrypted
Databases
1.
INTRODUCTION
To reduce infrastructure costs, small- and medium-sized
businesses may outsource their databases and database ap-
plications to third-party clouds. However, such data is of-
ten private, so storing it in a cloud raises conﬁdentiality
concerns. Semantically secure encryption of databases prior
to outsourcing alleviates conﬁdentiality concerns, but it also
makes it impossible to run any relational queries on the cloud
Permission to make digital or hard copies of part or all of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. Copyrights for third-
party components of this work must be honored. For all other uses, contact
the Owner/Author.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
Copyright is held by the owner/author(s).
ACM 978-1-4503-3832-5/15/10.
http://dx.doi.org/10.1145/2810103.2813638.
without client interaction. Several prior research projects
have investigated encryption schemes that trade-oﬀ perfect
data conﬁdentiality for the ability to run relational queries
[39, 6, 21]. However, these schemes either require client-side
processing [21], or require additional hardware support [6],
or support a very restrictive set of queries [39]. Our long-
term goal is to develop database encryption schemes that can
(1) be readily deployed on commercial oﬀ-the-shelf (COTS)
cloud infrastructure without any special hardware or any
kernel modiﬁcations, (2) support a broad range of (non-
update) relational queries on the encrypted database with-
out interaction with the client, (3) be implemented with low
or moderate overhead, and (4) provide provable end-to-end
security and a precise characterization of what information
encryption leaks in exchange for supporting a given set of
queries. Both in objective and in method, our goal is similar
to that of CryptDB [34], which attains properties (1)–(3),
but not (4).
As a step towards our goal, in this paper, we design two
database encryption schemes, EunomiaDET and EunomiaKH,
with properties (1)–(4). Our design is guided by, and partly
speciﬁc to, a single application, namely, audit of data-use
logs for violations of privacy policies. This application rep-
resents a real-world problem. Organizations are subject to
privacy legislation. For example, in the US, the healthcare
and ﬁnance industry must handle client data in accordance
with the federal acts HIPAA [1] and GLBA [2] respectively.
To remain compliant with privacy legislation, organizations
record logs of privacy-relevant day-to-day operations such as
data access/use and employee role changes, and audit these
logs for violations of privacy policies, either routinely or on
a case-by-case basis. Logs can be fairly large and are often
organized in commodity databases. Audit consists of a se-
quence of policy-guided queries. Audit is computationally
expensive but highly parallelizable, so there is signiﬁcant
merit in outsourcing the storage of logs and the execution
of audit algorithms to third-party clouds.
Security. We characterize formally what information about
an encrypted log (database) our schemes may leak to an ad-
versary with direct access to the encrypted store (modeling a
completely adversarial cloud). We prove that by looking at
a log encrypted with either of our schemes, an adversary can
learn (with non-negligible probability) only that the plain-
text log lies within a certain, precisely deﬁned equivalence
class of logs. This class of logs characterizes the uncertainty
of the adversary and, therefore, the conﬁdentiality of the
1130encrypted log [5]. Prior work like CryptDB lacks such a
theorem. CryptDB uses a trusted proxy server to dynam-
ically choose the most secure encryption scheme for every
database column (from a pre-determined set of schemes),
based on the queries being run on that column. While each
scheme is known to be secure in isolation and it is shown
that at any time, a column is encrypted with the weakest
scheme that supports all past queries on the column [32,
Theorem 2], there is no end-to-end characterization of in-
formation leaked after a sequence of queries.
(In return,
CryptDB supports all SQL queries, including aggregation
queries, which we do not support.)
Functionality. To demonstrate that our proposed encryp-
tion schemes support nontrivial applications, we adapt an
audit algorithm called reduce from our prior work [19] to
execute on logs encrypted with either EunomiaDET scheme or
EunomiaKH scheme. We implement and test the adapted al-
gorithm, ereduce, on both schemes and show formally that
the algorithm runs correctly on both schemes (except with
negligible probability). The algorithm ereduce can audit
all policies that reduce can, including most clauses of the
HIPAA and GLBA Privacy Rules [19].
Audit with ereduce is a challenging application for en-
cryption schemes because it requires almost all standard re-
lational query operations on logs. These operations include
selection, projection, join, comparison of ﬁelds, and what
we call displaced comparison (is the diﬀerence between two
timestamps less than a given constant?). Both our encryp-
tion schemes support all these query operations. The only
standard query operation not commonly required by privacy
audit (and not supported by our schemes) is aggregation
(sums and averages; counting queries are supported). Any
application that requires only the query operations listed
above can be adapted to run on EunomiaDET or EunomiaKH,
even though this paper focuses on the audit application only.
EunomiaDET and EunomiaKH trade eﬃciency and ﬂexibil-
ity diﬀerently. EunomiaDET uses deterministic encryption
and has very low overhead (3% to 9% over a no-encryption
baseline in our audit application), but requires anticipat-
ing which pairs of columns will be join-ed in audit queries
prior to encryption. EunomiaKH uses Popa et al.’s adjustable
key hash scheme [35, 34] for equality tests and has higher
overhead (63% to 406% in our audit application), but the
columns that will be join-ed during audit do not have to
be determined prior to encryption. To determine which
columns will be join-ed during audit for violations of a given
policy, we develop a new static analysis of policies, which we
call the EQ mode check.
To support displaced comparisons, which privacy audit
often requires, we design and prove the security of a new
cryptographic sub-scheme dubbed mOPED (short for, mu-
table order-preserving encoding with displacement). This
scheme extends the mOPE scheme of Popa et al. [33], which
does not support displacements, and may be of independent
interest.
Deployability. Both EunomiaDET and EunomiaKH can be
deployed on commodity database systems with some addi-
tional metadata.
In both schemes, a client encrypts the
individual data cells locally and store the ciphertexts in a
commodity database system in the cloud (possibly incre-
mentally). Audit (ereduce) runs on the cloud without in-
teraction with the client and returns encrypted results to
the client, who decrypts them to recover policy violations.
Both EunomiaDET and EunomiaKH use basic, widely-available
cryptographic operations only.
Contributions. We make the following technical contribu-
tions:
• We introduce two database encryption schemes, namely
EunomiaDET and EunomiaKH, that support selection,
projection, join, comparison of ﬁelds, and displaced
comparison queries. The schemes trade eﬃciency for
the need to predict expected pairs of join-ed columns
before encryption. As a building block, we develop the
sub-scheme mOPED, that allows displaced compari-
son of encrypted values.
• We characterize the conﬁdentiality attained by our
schemes as equivalence classes of plaintext logs and
prove that both our schemes are secure.
• We adapt an existing privacy policy audit algorithm
to execute on our schemes. We prove the functional
correctness of the execution of the algorithm on both
our schemes.
• We implement both our schemes and the adapted audit
algorithm, observing low overheads on EunomiaDET and
moderate overheads on EunomiaKH.
Proofs of theorems omitted from this paper can be found
in an accompanying technical report [15].
Notation. This paper is written in the context of the pri-
vacy audit application and our encryption schemes are pre-
sented within this context. We sometimes use the term “log”
or “audit log” when the more general term “database” could
have been used and, similarly, use the term “policy” or “pri-
vacy policy” when the more general term “query” would ﬁt
as well.
2. OVERVIEW OF EUNOMIA
We ﬁrst present the architecture of Eunomia. Then, we
motivate our choice of encryption schemes through examples
and discuss policy audit in Eunomia in more detail. Finally,
we discuss our goals, assumptions, and adversary model.
2.1 Architecture of Eunomia
We consider the scenario where an organization, called
the client or Cl, with sensitive data and audit requirements
wishes to outsource its log (organized as a relational database)
and audit process (implemented as a sequence of policy-
dependent queries) to a potentially compromisable third-
party cloud server, denoted CS. Cl generates the log from its
day-to-day operations. Cl then encrypts the log and trans-
fers the encrypted log to the CS. Cl initiates the audit pro-
cess by choosing a policy. The auditing algorithm runs on
the CS infrastructure and the audit result containing en-
crypted values is sent to Cl, which can decrypt the values in
the result.
The mechanism of log generation is irrelevant for us. From
our perspective, a log is a pre-generated database with a
public schema, where each table deﬁnes a certain privacy-
relevant predicate. For example, the table Roles may con-
tain columns Name and Role, and may deﬁne the mapping of
1131Cl’s employees to Cl’s organizational roles. Similarly, the ta-
ble Sensitive accesses may contain columns Name, File name,
and Time, recording who accessed which sensitive ﬁle at
what time. Several tables like Sensitive accesses may con-
tain columns with timestamps, which are integers.
2.2 Encryption Schemes
An organization may na¨ıvely encrypt the entire log with
a strong encryption scheme before transferring it to a cloud,
but this renders the stored log ineﬀective for audit, as audit
(like most other database computations) must relate diﬀer-
ent parts of the log. For example, suppose the log contains
two tables T1 and T2. T1 lists the names of individuals who
accessed patients’ prescriptions. T2 lists the roles of all in-
dividuals in the organization. Consider the privacy policy:
Policy 1: Every individual accessing patients’ prescriptions
must be in the role of Doctor.
The audit process of the above policy must read names
from T1 and test them for equality against the list of names
under the role Doctor in T2. This forces the use of an en-
cryption method that allows equality tests (or equi-joins).
Unsurprisingly, this compromises the conﬁdentiality of the
log, as an adversary (e.g., the cloud host, which observes the
audit process) can detect equality between encrypted ﬁelds
(e.g., equality of names in T1 and T2). However, not all is
lost: for instance, if per-cell deterministic encryption is used,
the adversary cannot learn the concrete names themselves.
A second form of data correlation necessary for audit is the
order between time points. Consider the following policy:
Policy 2: If an outpatient’s medical record is accessed by
an employee of the Billing Department, then the outpatient
must have visited the medical facility in the last one month.
Auditing this policy requires checking whether the dis-
tance between the timestamps in an access table and the
timestamps in a patient visit table is shorter than a month.
In this case, the encryption scheme must reveal not just
the relative order of two timestamps but also the order be-
tween a timestamp and another timestamp displaced by one
month. Similar to Policy 1, the encryption scheme must
reveal equality between patient names in the two tables.
To strike a balance between functional (audit) and con-
ﬁdentiality requirements, we investigate two cryptographic
schemes, namely EunomiaDET and EunomiaKH, to encrypt
logs. Each cell in the database tables is encrypted indi-
vidually. All cells in a column are encrypted using the same
key. EunomiaDET uses deterministic encryption to support
equality tests; two columns that might be tested for equal-
ity by subsequent queries are encrypted with the same key.
EunomiaDET requires that log columns that might be tested
for equality during audit are known prior to the encryption.
Audit under EunomiaDET is quite eﬃcient. However, adapt-
ing encrypted logs to audit diﬀerent policies that require
diﬀerent column equality tests requires log re-encryption,
which is costly. Our second scheme EunomiaKH handles fre-
quent policy updates eﬃciently. EunomiaKH relies on the ad-
justable key hash scheme [35, 34] for equality tests. A trans-
fer token is generated for each pair of columns needed to be
tested for equality prior to audit. EunomiaKH additionally