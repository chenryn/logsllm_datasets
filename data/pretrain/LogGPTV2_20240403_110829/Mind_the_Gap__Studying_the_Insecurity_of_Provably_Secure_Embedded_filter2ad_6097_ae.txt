(dma_addr). If the address on this bus falls within the key
region, a reset is triggered before the value can be read out.
a) Broken assumption: The internal dma_addr bus of
the 16-bit openMSP430 core measures only 15 bits. This is
because DMA accesses are always word-aligned, making the
last (zero) bit of the address redundant. However, our audit re-
vealed that, in the crucial connection of the veriﬁed HW-Mod to
the unveriﬁed openMSP430 core, the 15-bit dma_addr signal
was incorrectly zero-extended (instead of left-shifted) into a
16-bit signal as follows: {1’b0, dma_addr[15:1]}.
b) Attack: We experimentally validated that the incor-
rect, zero-extended address comparison in HW-Mod allows
untrusted DMA peripherals to trivially read out the entire
value of the secret key without triggering a reset. This means
a complete bypass of the main VRASED security goal (P1).
c) Mitigation: This issue reinforces the importance of in-
terface signals between veriﬁed and unveriﬁed components and
more generally highlights the limitations of automated model
generation of only a subset of the core. The implementation
should adhere to the model by adding the extension bit in the
correct place, i.e., {dma_addr[15:1], 1’b0}.
2) Inconsistent key sizes: VRASED speciﬁes [15, Deﬁni-
tion 2] a security parameter l, which equals the key size, as
well as the challenge and HMAC digest sizes. The VRASED
implementation, furthermore, uses HMAC-SHA256 with ex-
plicit challenge and digest sizes of 256 bits (l = 32 bytes).
a) Broken assumption: In contrast to the formal security
parameter deﬁnition above, the unveriﬁed secure key ROM
module of the modiﬁed core deﬁnes a 64-byte master key.
This entire 64-byte master key is used by SW-Att to derive a
32-byte challenge-dependent key, which is securely stored on
the exclusive stack and is subsequently used to calculate the
attestation HMAC.
Crucially, however, in the veriﬁed HW-Mod component, a
master key size of only KMEM_SIZE = 31 bytes is used for
access control to the secure key ROM, leaving the second half
of the master key completely unprotected. To make matters
worse, even the ﬁrst half of the master key is not completely
protected, as HW-Mod’s bounds checking excludes the byte at
key[KMEM_SIZE], i.e., the 32nd byte.
b) Attack: We experimentally validated that the incorrect
access control in HW-Mod allows untrusted code outside SW-Att
to directly read out all 33 affected bytes at key[31:63].
c) Mitigation: A consistent master key size should be
used throughout the implementation and the veriﬁcation code.
These ﬁndings further highlight the limitations of inter-
actions between veriﬁed and unveriﬁed components, and
maintaining consistent parameters between them. Importantly,
this crucial oversight was not detected because VRASED’s
veriﬁcation is parameterized with the same erroneous 31-byte
key size as HW-Mod.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:23:35 UTC from IEEE Xplore.  Restrictions apply. 
1647
C. Exploiting missing attacker capabilities
1) Secure metadata corruption with a peripheral: Both
the APEX [20] and RATA [21] VRASED extensions3 store
important metadata in secure MMIO peripheral registers.
a) Unmodeled capability: The secure proof-of-execution
register in APEX is implemented as a read-only peripheral
device. On openMSP430, all peripherals are connected to the
core via shared buses, both for addressing and for transferring
output values. If multiple peripherals output data in the same
cycle, the values are combined with a bitwise or operation.
We experimentally validated that a compromised DMA
device connected via the shared peripheral buses can interfere
with the values read from other peripherals. This includes
APEX’s secure proof-of-execution ﬂag, which resides at a
ﬁxed address in the MMIO space. APEX returns a secure
ﬂag value of ‘1’ when the attested program has successfully
completed, while ‘0’ is used to signal an error or tampering.
b) Attack: Whenever the secure APEX peripheral MMIO
register address is seen on the shared address bus, our proof-
of-concept compromised peripheral puts a ‘1’ on the shared
output bus. A ‘1’, when or-ed with the actual output value
of the APEX peripheral will always result in a value of ‘1’,
signaling successful execution to the core. This is the case even
if the attacker has previously tampered with the execution and
the value of the ﬂag in the secure register is ‘0’.
c) Mitigation: This issue highlights the risks of storing
security-sensitive data outside the security perimeter, among
untrusted and unveriﬁed components. Since this issue is a
result of the original openMSP430 design, it is not straightfor-
ward to ﬁx. A possible workaround is to avoid the untrusted
peripheral bus altogether and store crucial attestation metadata
on-chip, within the trust boundaries of the core itself.
2) Key leakage through stack pointer poisoning: The
HACL* [37] cryptographic library requires a stack to save
temporary state, including secrets. VRASED’s HW-Mod, there-
fore, enforces an exclusive stack XS for SW-Att.
a) Unmodeled capability: At the hardware level, only
HW-Mod is veriﬁed, VRASED reuses the existing HACL*
proofs [37] to claim full security for its trusted SW-Att software
component. However, SW-Att is also responsible for setting
up the execution environment expected by HACL* before
invoking the actual cryptographic primitives. Unfortunately,
this crucial trusted wrapper code remains entirely unveriﬁed.
Even worse, our security audit of the implementation re-
vealed that the secure stack pointer is set up by untrusted
code before invoking SW-Att. The trusted SW-Att entry code
does not validate that the stack points to XS as expected.
b) Attack: This vulnerability allows an attacker to freely
change the value of the stack pointer before entering SW-Att.
Since SW-Att can only write to XS and a shared memory
region M R to store the HMAC result, a logical choice is to
point the stack to M R, as it is also accessible by untrusted
3The source code of RATA was only released after we conducted our
research, so we did not analyze it beyond conﬁrming that it uses the same
shared peripheral bus and is thus potentially vulnerable to a similar attack,
which is left as future work.
software. SW-Att will now ﬁll M R with sensitive stack frames,
potentially including the secret key. Once the stack overﬂows
M R, an illegal write will happen and the CPU will reset.
However, the secure reset does not clear M R, which allows
the attacker to retrieve the leaked values after the reset.
We experimentally found that, with the predeﬁned size of
M R and without changing any conﬁguration parameters, the
CPU resets during zero-initialization of the local variable hold-
ing the key, i.e., before sensitive values are leaked. However,
by changing the optimization level of the compiler (e.g., as
conﬁrmed with msp430-clang v4.0.1 at -O1), this redun-
dant zero-initialization may be skipped. Note that this speciﬁc
zero-initialization is entirely redundant, and, hence, can be
safely removed without affecting functional correctness (A7).
We experimentally validated that, when the zero initialization
is skipped, the ﬁrst 22 key bytes are copied into M R before
reset, thereby breaking VRASED’s no-leakage property (P2).
c) Mitigation: This issue highlights the risks of com-
bining proofs (i.e., HW-Mod and HACL*) without a rigorous
holistic security argument. In this speciﬁc case, a more explicit
argument should be made about how VRASED intends to
fulﬁll the assumptions of the HACL* proof. The assump-
tion for stack-pointer initialization should be fulﬁlled when
entering SW-Att. This can be done either transparently at the
hardware level, within the veriﬁed HW-Mod logic; or inside the
SW-Att software component, using a trusted (and preferably
also veriﬁed) assembly entry stub that sanitizes the ABI
expected by the C compiler, similar to Intel SGX shielding
runtimes [52]. This stub should also properly cleanse caller-
save registers when exiting SW-Att (cf. Appendix C1).
3) Timing side channel
in authentication: To protect
against denial-of-service attacks, VRASEDA [15] extends SW-
Att with veriﬁer authentication. Speciﬁcally, VRASEDA only
executes the expensive attestation if a correct authentication
token, calculated from the challenge and the secret key, is
supplied with the request (cf. Appendix A1). Importantly, the
veriﬁer authentication primitive provided by VRASEDA is also
tightly coupled with the security of the more recent RATA [21]
VRASED extension.
a) Unmodeled capability: VRASEDA is entirely imple-
mented in trusted C code that is included at the entry point
of SW-Att and invokes the required HACL* cryptographic
primitives as shown in Listing 4. However, similar to the
previous issue, the C code itself remains entirely unmodeled
and unveriﬁed. Any security argument or assumptions about
this wrapper code are missing. Hence, a single vulnerability
in the trusted wrapper C code may invalidate SW-Att’s claimed
guarantees built on HACL*’s functional correctness, memory
safety, and secret-independent timing behavior.
1
2
3
4
5
6
7
if (memcmp(CHALL_ADDR, CTR_ADDR, 32) > 0) {
hacl_hmac(mac, key, CHALL_ADDR));
if (!memcmp(VRF_AUTH, mac, 32)) {
attest();
memcpy(CTR_ADDR, CHALL_ADDR, 32);
}
}
Listing 4. Authentication code in VRASEDA (simpliﬁed).
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:23:35 UTC from IEEE Xplore.  Restrictions apply. 
1648
b) Attack: Observe that line 3 is vulnerable to timing
attacks as it uses the standard memcmp function from libc
to determine whether the attacker-provided value VRF_AUTH
matches the expected mac authentication tag computed using
the secret key. This function terminates at the ﬁrst mismatching
byte pair, thus allowing an attacker to guess the secret authen-
tication mac value byte-by-byte, reducing the effort from an
exponential problem (25632) to a linear one (256 · 32).
We experimentally validated (cf. Table III in Appendix D).
that an attacker measuring SW-Att’s start-to-end execution time
can deterministically extract the expected mac value with little
effort and without key knowledge, thereby entirely bypassing
the main VRASEDA security goal.
c) Mitigation: This speciﬁc timing vulnerability can be
patched by using a constant-time memcmp implementation. In
general, however, this shows that any code included in SW-Att
needs to be thoroughly checked to not leak the key or any
information about it, which is difﬁcult to generalize.
More broadly, this issue once again highlights the impor-
tance of rigorous argumentation when reusing existing security
proofs (e.g., that of HACL*) combined with seemingly simple
wrapper code. This timing issue could have been prevented if
the wrapper were not developed in C, but instead written in
F* and properly integrated into the HACL* veriﬁcation.
4) Nemesis side-channel leakage: Given that VRASEDA
is vulnerable to timing side channels, and given that
the
Nemesis [32] interrupt latency attack on Sancus is the result
of the underlying openMSP430 architecture, a logical question
to ask is whether this side channel affects VRASED as well.
In VRASED, interrupts are not allowed during the execution
of SW-Att and should result in an immediate, secure CPU reset.
a) Unmodeled capability: HW-Mod contains the formally
veriﬁed Verilog logic that will reset the CPU in case of an in-
terrupt request during SW-Att execution. However, the way HW-
Mod is wired to the core allows a Nemesis-type side-channel
leakage. The signal monitored by HW-Mod is irq_detect,
which is only raised upon instruction retirement. In other
words, the reset will indeed always correctly happen, but it
will be delayed until the cycle when the interrupt handling
would normally start. This can also be seen in Figure 9, where
the interrupt arrives and the irq[8] signal changes in the 4th
cycle, but the irq_detect signal is only raised at the end
of the executing instruction, followed by the CPU reset.
1
2
3
4
5
6
7
8
9
10
11
clk
irq[8]
irq detect
vrased reset
instruction
PUSH r9
PUSH r8
RESET
Fig. 9.
Interrupt is only detected at the last cycle of the push instruction.
b) Attack: Since a CPU reset also zeroes benign timer
peripherals, the reset delay cannot be directly measured from
software. However, we experimentally developed a proof-
of-concept compromised DMA peripheral that is capable of
detecting CPU resets and saving information across them. This
allows a Nemesis-style “reset-latency” attacker to reconstruct
execution lengths for every individual instruction in SW-Att.
The effects on VRASED are arguably less severe than on
SancusV, since the HACL* code does not contain any secret-
dependent branches. As such, the only currently practical use
of this instruction-granular leakage would be to break a naively
patched memcmp solution that may be proposed against the
start-to-end timing attack presented in Section VI-C3.
c) Mitigation: This issue again highlights the attention
to be given to interface signals. Similar to Section V-C2,
the attack is enabled by wiring the wrong interrupt signal:
connecting HW-Mod with a signal that is immediately raised
for all interrupt sources would have ensured that the reset is
not delayed until instruction retirement.
More generally, this attack, along with the previous and next
ones, illustrates the ramiﬁcations and pitfalls of not modeling
time measurement as an important attacker capability.
5) DMA side-channel leakage: Just as with Nemesis, the
DMA side channel from Section IV is also a result of the
underlying openMSP430 architecture. Similar to interrupts,
DMA requests during the execution of SW-Att are disallowed.
a) Unmodeled capability: HW-Mod contains the formally
veriﬁed Verilog logic that will trigger a secure CPU reset
whenever detecting any DMA activity during SW-Att execution.
While this reset indeed prohibits direct data leakage, we found
that it, as with interrupts, does not prevent timing leakage.
There are two signals connected to DMA peripherals that
are driven by the core. First, a bus contains the data one cycle
after read requests. This is the same cycle as when the reset is
triggered, which also clears the data bus; this behavior ensures
that no sensitive data can be read out during SW-Att execution.
The other signal to the peripheral driven by the core is the
dma_ready signal, which shows whether the request was
successfully completed. This is the signal the DMA attacker
will monitor instead of the data bus. If this signal is high, there
was no contention on the memory bus. This signal is raised in
the same cycle when the DMA request is issued, so it is not
masked by the reset, which only happens in the next cycle.
b) Attack: We experimentally validated that an attacker
with untrusted peripheral access can fully exploit the DMA
side channel on VRASED to learn cycle-accurate memory
bus utilization for every instruction in SW-Att. This may have
severe effects if the code of SW-Att changes, while remaining
undetected by the HW-Mod security proof.
c) Mitigation: Since VRASED already disallows DMA
during SW-Att execution (in contrast to upstream Sancus [31]
which allows untrusted DMA accesses as a performance
optimization during enclave execution), a relatively easy ﬁx
would be to properly mask the dma_ready signal as well,
so no side-channel information leaks to the rogue peripheral.
D. Deductive errors
VRASED does not formalize the operational semantics
of the original openMSP430 core. Any core implementation
that satisﬁes ﬁve short assumptions A1-A5 (cf. Appendix B)
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:23:35 UTC from IEEE Xplore.  Restrictions apply. 
1649
should, hence, be covered by the proof. The end-to-end RA
security argument depends on two premises: the soundness of
the remote attestation scheme and the claim that the attacker
cannot learn the key. In the following, we argue that these
premises do not follow from the stated assumptions (for a
dissection of the full argument, we refer to Appendix E).
The claim that the attacker cannot learn the key is centered
around a lemma stating that a reset is caused if the key is read
directly, or if SW-Att writes outside the HMAC result region
M R. This lemma is rigorously formulated in LTL, and a
machine-checked proof is provided that shows that this lemma
follows from the LTL security invariants that were previously
shown to be enforced by HW-Mod. Speciﬁcally, the LTL rules
used in this part of the proof were shown to be enforced
by the state machine that was directly generated from HW-
Mod’s Verilog implementation, and we did not ﬁnd any issues
with this mechanized part of the proof. However, the premises
leading to this lemma and the further conclusions drawn from
it are formulated more informally in writing, and they can be
bypassed by modifying unveriﬁed parts of the core.
First,
it
leading up to the lemma,
is informally argued
that the key may only leak through (i) registers, supposedly
covered by A6; (ii) timing, supposedly covered by HACL*’s
secret-independent timing; and (iii) memory, covered by the
lemma. However, consider an alternative core implementation
that, when reading the key during the HMAC calculation,
delays this load operation by exactly as many clock cycles
as is the value of the key being read. Such a core satisﬁes A1-
A5, which do not specify constraints about timing, but does
not conform to HACL*’s machine model that should support