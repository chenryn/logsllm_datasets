their pattern were invited to the next pattern recall test.
Steps 5 and 6 were repeated after 15 minutes for the
second recall
test, and repeated again after 24 hours for
the third recall test. To remind the participants about those
two tests, our Android application was designed to send out
vibration notiﬁcations at appropriate times. Each participant
also received an email 24 hours after completing the second
TABLE II: Survey questions asked after each pattern recall
test. For Q2,
item format was “very
difﬁcult,” “difﬁcult,” “neutral,” “easy,” and “very easy.”
the ﬁve-level Likert
#
Q1
Q2
Q3
Q4
Question
Did you use an external storage (e.g., a
sheet of paper or a text ﬁle) to write down
your pattern?
How difﬁcult was it for you to remember
your pattern?
Did you use any special technique (e.g.,
creating character patterns, forming dic-
tionary words) to help you create and
remember your pattern?
If you answered “Yes” to Q4, what was
the special technique that you used?
Answers
yes/no
Likert
scale
yes/no
Open
ended
recall test, inviting him or her to the third recall test. In our
study, the two 15 minute and 24 hour break periods were
selected to reﬂect on the real-world smartphone lock and
unlock frequencies.
According to the results presented in [14],
the average
daily number of interactions with smartphones was 57 times.
Assuming that the daytime is about 14 hours, the mean break
duration between unlock sessions is about 15 minutes. We also
used a break of 24 hours for the third recall test based on the
assumption that a typical user would unlock his or her device
at least once a day. Even when people are on vacation, it is
likely that they would carry their phone with them, and unlock
their phone at least once a day. Those usage scenarios and
break durations are quite different to the way people would
use their passwords for logging into websites.
To prevent the participants from simply taking a snapshot
of their pattern and cheating, we disabled the screen capture
feature from our application. Before running the real user
study, we conducted several pilot studies with a total of 1,118
participants to ﬁx bugs, and address unclear instructions and
descriptions.
C. User data collected
Throughout the steps of the user study described in Sec-
tion III-B, we recorded the following information:
Selected pattern and pattern policy: For each participant,
we recorded the selected pattern and the assigned pattern
policy.
Number of initialization attempts: For each participant,
we recorded the number of times a participant tried to reset
the grid during pattern setup.
Number of unlock attempts: For all three pattern recall
tests, we recorded the number of attempts each participant
made in drawing the selected pattern.
Time taken for pattern setup: We measured the time it
took each participant to set up his or her pattern, starting from
when the participant ﬁrst saw the pattern screen view and
ending when the participant successfully selected a pattern.
To complete the setup process, each participant had to select
a pattern that conformed to the given pattern policy.
Time taken to authenticate: For all of the recall tests,
we measured the time it took each participant to complete an
341
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:26:42 UTC from IEEE Xplore.  Restrictions apply. 
authentication attempt, starting from when the participant ﬁrst
saw the login screen and ending when the participant either
drew the correct pattern or failed to draw the correct pattern
within ﬁve attempts.
Pattern recall results: For all of the pattern recall tests, we
recorded the results of the recall tests (i.e., whether a correct
pattern was entered) for each attempt made.
Survey answers: We recorded the participants’ answers to
the survey questions in Table II.
D. Mechanical Turk
To conduct a large-scale study, we used Amazon Mechanical
Turk, recruiting a sufﬁciently large number of participants to
perform meaningful statistical analyses. Participants had to be
located in the United States, and at least 18 years of age. The
participants who completed the ﬁrst and second recall tests
were rewarded with USD 1.50. The participants who came
back and completed the third recall test were rewarded with
additional USD 0.50.
E. Statistical tests
Without making any assumptions on data distributions, we
performed the Fisher’s Exact Test (FET) to compare the
proportion of cracked patterns, starting/end/overall point(s),
and pattern recall success rate based on survival rates for the
ﬁve policies in Table I. The statistical conﬁdence in the pattern
setup time, authentication time and attempts between the ﬁve
policies were tested using two-tailed unpaired t-test due to the
collected data was normally distributed (tested by Shapiro-
Wilk’s test). Recall difﬁculty was tested using unpaired Mann-
Whitney U test (MW U test) because a skewed distribution
was found in the participants’ Likert scale responses. Post-
hoc comparisons were corrected for multiple-testing using the
Bonferroni correction estimation when appropriate.
IV. RESULTS: USABILITY
This section presents the key usability results from the user
study, discussing pattern recall success rate and authentication
time.
A. Demographics
A total of 1,717 participants completed the ﬁrst pattern
recall test. 1,603 came back to complete the second pattern
recall test, and 1,236 came back complete the third pattern
recall test. Most of the participants were white (71%), and
the majority were in the 18–29 (61%) and 30–39 (29%)
age groups. About 51% were male. 54% had a university
degree, and 37% had a high school diploma. The details of the
demographics are presented in Table XIII (see Appendix A).
B. External storage usage
After completing each pattern recall
test, we asked the
participants about the use of an external storage (see Q1 in
Table II). There were only 44 participants who used an external
storage for at least one of the tests. 54.5% of such participants
were assigned with the Random policy. Most of them (84.1%)
used a piece of paper as an external storage. We discarded
those participants’ records to precisely measure pattern “recall
success rate.” Therefore we, in the rest of paper, used this
ﬁltered dataset excluding the participants who used an external
storage. We paid all the participants regardless of their answer
to this question though.
C. Recall success rate
We analyze the number of participants who successfully
recalled their pattern in the three recall tests to compare the
recall effects of the ﬁve policies presented in Table I.
1) Survival rates: First, we simply counted the number
of the remaining participants who successfully recalled their
pattern in all tests against the number of all initial participants.
We note that there were many participants who did not return
to complete the second or third test. 21.93–25.68% of those
assigned to the SysPal policies, 24.74% of those assigned to
the Original policy, and 16.77% of those assigned to the
Random policy did not return to complete the second or third
test. If we categorize those participants as failed participants,
the formula shown in Table III, (# remaining participants)/(#
initial participants), can be applied.
TABLE III: (# remaining participants)/(# initial participants)
with 95% binomial conﬁdence intervals across ﬁve policies.
Policy
Original
1-Point
2-Point
3-Point
Random
First Test
382/384
99.48%
0.98, 1.00
326/331
98.49%
0.97, 1.00
340/342
99.42%
0.98, 1.00
320/326
98.16%
0.96, 0.99
276/334
82.63%
0.78, 0.87
Second Test
365/384
95.05%
0.92, 0.97
317/331
95.77%
0.93, 0.98
330/342
96.49%
0.94, 0.98
312/326
95.71%
0.93, 0.98
265/334
79.34%
0.75, 0.84
Third Test
278/384
72.40%
0.68, 0.77
232/331
70.09%
0.65, 0.75
252/342
73.68%
0.69, 0.78
231/326
70.86%
0.66, 0.76
169/334
50.60%
0.45, 0.56
The ﬁrst test results show the participants’ recall success
rate soon after solving a puzzle (which takes about 2 minutes).
Interestingly, about 17.37% of the Random participants failed
to recall their pattern in the ﬁrst test. In all other policies, only
0.52–1.84% failed the ﬁrst test. The ﬁrst-test recall success
rate of all SysPal policies (98.16–99.42%) and Original
policy (99.48%) were better than Random policy (82.63%),
showing statistically signiﬁcant differences (all p < 0.001,
corrected FET). However, there was no statistically signiﬁcant
difference between the SysPal polices and Original policy
(all p = 1.0, corrected FET).
In the second test (taken at least 15 minutes after the ﬁrst
test) the recall success rate difference between the Random
policy and all other policies increased. For all SysPal and
Original participants, only 3.51–4.95% failed to recall their
pattern; 2.19–4.45% did not return to the second test even
though they had successfully recalled their patterns in the
ﬁrst test. All SysPal policies (95.71–95.77%) and Original
policy (95.05%) showed statistically signiﬁcant superiority
342
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:26:42 UTC from IEEE Xplore.  Restrictions apply. 
over Random policy (79.34%) in the second-test recall success
rate (all p < 0.001, corrected FET).
Similarly, after the third test (taken at least 24 hours after the
second test), we noticed further increase in the recall success
rate difference between the Random policy and all other
policies. For all SysPal and Original participants, 26.32–
29.91% failed to recall their patterns; 20.30–24.59% did not re-
turn to the third test even though they had successfully recalled
their pattern in the second test. All SysPal policies (70.09–
73.68%) and Original policy (72.40%) showed statistically
signiﬁcant superiority over Random policy (50.60%) in the
third-test recall success rate (all p < 0.001, corrected FET).
Again, we did not ﬁnd any statistically signiﬁcant difference
in recall success rate between the Original and all SysPal
policies (all p = 1.0, corrected FET).
2) Excluding those who dropped out without failing: Even
though we tried our best to bring back the participants to
subsequent tests – sending notiﬁcations and offering bonuses
– some participants still dropped out without failing. To
accommodate for such drop out rates, we used another recall
success rate metric that excludes those who dropped out
without failing (see Table IV). We used the formula of (#
remaining participants)/(# returned participants + # dropped
out after failing one of previous tests).
TABLE IV: (# remaining participants)/(# returned participants
+ # dropped out after failing one of previous tests) with 95%
binomial conﬁdence intervals across ﬁve policies.
Policy
Original
1-Point
2-Point
3-Point
Random
First Test
382/384
99.48%
0.98, 1.00
326/331
98.49%
0.97, 1.00
340/342
99.42%
0.98, 1.00
320/326
98.16%
0.96, 0.99
276/334
82.63%
0.78, 0.87
Second Test
365/(365+2)
99.46%
0.98, 1.00
317/(318+5)
98.14%
0.96, 0.99
330/(332+2)
98.80%
0.97, 1.00
312/(313+6)
97.81%
0.96, 0.99
Third Test
278/(287+2)
96.19%
0.93, 0.98
232/(240+6)
94.31%
0.90, 0.97
252/(263+4)
94.38%
0.91, 0.97
231/(236+7)
95.06%
0.92, 0.97
265/(275+58)
169/(210+68)
79.58%
0.75, 0.84
60.79%
0.55, 0.67
Compared to the ﬁrst metric, this second metric computed
similar survival rates for the ﬁrst two tests across all policies.
But it computed much higher third-test recall success rate,
showing more signiﬁcant differences in the third-test recall
success rate between the Random policy (60.79%) and all
other policies (94.31–96.19%).
For all three tests, we did not ﬁnd any statistically signiﬁcant
difference in recall success rate between the Original and
all SysPal policies. In fact, the overall recall success rate
of SysPal patterns was not too different from Original
patterns. But all of those policies demonstrated statistically
signiﬁcant superiority over Random (all p < 0.001, corrected
FET).
343
D. Authentication time and attempts made
We measured the authentication time (time taken to unlock
a device) by adding the preparation time (time taken until the
ﬁrst touch) and the input time (time measured after the ﬁrst
touch until a device is unlocked) [28]. Table V shows the mean
time taken to complete the authentication process for all three
recall tests. Appendix B visually compares the authentication
times between all the policies.
TABLE V: Mean time (sec) taken to complete authentication
across the ﬁve policies (μ: mean, σ: standard deviation).
Policy
Original
1-Point
2-Point
3-Point
Random
First Test
σ
μ
3.56
4.60
4.26
2.76
2.94
4.17
4.30
4.47
12.90
10.70
Second Test
σ
μ
3.64
4.73
4.07