`sum(skipmissing(x))` is reasonably fast, but since #27651 a naive
implementation of `sum` is even faster (up to 5Ã—). This is particularly clear
when the input array does contain missing values, probably because the naive
sum uses masked SIMD instructions while `skipmissing` relies on branching (and
the presence of missing values kills prediction).
I haven't investigated this deeply, but IIUC `sum(skipmissing(x))` dispatches
to `mapfoldl`, which uses the iteration protocol to go over the input. This
means we lose the benefit of `@inbounds` and of `@simd`. Maybe something like
#27384 would help with `@inbounds` at least?
    function mysum(X)
       s = zero(eltype(X))
       @inbounds @simd for x in X
           if x !== missing
               s += x
           end
       end
       s
    end
    # With Vector{Int}
    X1 = rand(Int, 10_000_000);
    X2 = Vector{Union{Missing,Int}}(X1);
    X3 = ifelse.(rand(length(X2)) . @btime mysum(X1);
     5.594 ms (1 allocation: 16 bytes)
    julia> @btime mysum(X2);
     5.791 ms (1 allocation: 16 bytes)
    julia> @btime mysum(X3);
     5.681 ms (1 allocation: 16 bytes)
    julia> @btime sum(skipmissing(X1));
     7.316 ms (2 allocations: 32 bytes)
    julia> @btime sum(skipmissing(X2));
     18.175 ms (2 allocations: 32 bytes)
    julia> @btime sum(skipmissing(X3));
     28.240 ms (2 allocations: 32 bytes)
    # With Vector{Float64}
    Y1 = rand(Float64, 10_000_000);
    Y2 = Vector{Union{Missing,Float64}}(Y1);
    Y3 = ifelse.(rand(length(Y2)) . @btime mysum(Y1);
     5.860 ms (1 allocation: 16 bytes)
    julia> @btime mysum(Y2);
     13.849 ms (1 allocation: 16 bytes)
    julia> @btime mysum(Y3);
     17.428 ms (1 allocation: 16 bytes)
    julia> @btime sum(skipmissing(Y1));
     13.816 ms (2 allocations: 32 bytes)
    julia> @btime sum(skipmissing(Y2));
     18.254 ms (2 allocations: 32 bytes)
    julia> @btime sum(skipmissing(Y3));
     28.430 ms (2 allocations: 32 bytes)