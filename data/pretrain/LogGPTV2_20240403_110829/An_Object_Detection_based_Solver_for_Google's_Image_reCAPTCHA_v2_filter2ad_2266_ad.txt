travel, old, art,
els further by utilizing adversarial training. Note that, even
though we call it adversarial training, some training samples
may not include adversarial noises. Since reCAPTCHA’s
source code and data are not open-source, it is challenging to
do further veriﬁcation.
Table 8 depicts the performance of our object detection
models. We can see that the object detection models with
augmented data can detect 149 (over 73%) out of 203 tar-
get objects in the perturbed images. That is over 17% per-
formance improvement with respect to our base models. It
is also evident that adversarial training provides signiﬁcant
performance boosts further while using only 500 training
samples. We suspect reCAPTCHA might be generating the
perturbation from a simple data distribution, which enabled
us to achieve such a great increase in performance despite
training against only a small number of adversarial samples.
We expect that adding more perturbed images from original
reCAPTCHA challenges will further enhance the detection
performance. Notice that models have misidentiﬁed some
objects after performing data augmentation and adversarial
training. We can reduce the number of misdetections by set-
ting the detection threshold to a higher value (our default is
0.2). However, doing so slightly degrades the overall perfor-
mance of the object detection models.
We note that advanced object detection systems, such as
YOLOv3, are less susceptible to anti-recognition techniques
employed by reCAPTCHA in general. For example, our base
object detection models (Table 8) perform much better in iden-
tifying objects in the perturbed images than vision APIs for
image recognition in Table 7. We assume that reCAPTCHA
mainly targeted image recognition and classiﬁcation systems
because all of the prior attacks against reCAPTCHA in lit-
erature are based on them. In summary, our ﬁndings imply
that an effectively trained object detection based solver can
neutralize reCAPTCHA’s anti-recognition attempts.
IP address rate-limit. To study whether reCAPTCHA en-
forces any IP address rate limit, we set up a 3-day experiment.
We select 3 reCAPTCHA-enabled websites and attempt to
initiate 1000 reCAPTCHA challenges to a chosen website
each day. We limit ourselves to 1000 requests to a site each
day to minimize the impact on the test website. Further, there
Table 7: Results of noisy grid classiﬁcation returned by im-
age recognition services. EM=No. of exact match label sets.
A=No. of acceptable label sets. E=No. of empty label sets.
MC=No. of misclassiﬁcations label sets.
Service
# of Grids
Google Cloud Vision
Microsoft Azure Computer
Vision
Amazon Rekognition
Clarifai
172
172
172
172
Labels
EM A
31
68
E MC
32
41
19
70
27
82
58
71
9
0
0
62
44
74
is a delay of 60 seconds between two subsequent requests. We
perform this experiment with 3 IP addresses: an institutional
IP, a residential IP, and a Tor anonymity network IP.
We experiment with the academic IP ﬁrst. On the ﬁrst
day, we can initiate 818 reCAPTCHA challenges, and the
remaining 182 attempts have been blocked. On the second
day, we are able to initiate the reCAPTCHA challenges 801
times, and the remaining 199 attempts have been blocked. On
the third day, none of our attempts has been blocked. The
duration of the blocking period usually ranges from 36 to
95 minutes. Note that getting the IP blocked in one web-
site by reCAPTCHA does not generally restrict that same IP
from initiating reCAPTCHA challenges on other websites,
which is normal behavior. We could initiate reCAPTCHA
challenges more than 800 times from a single IP address to
a particular website in any of the cases. Next, we repeat this
experiment from the same machine but with a residential IP
and observe a similar pattern. Finally, we experiment by tun-
neling the trafﬁc through the Tor network with the exit node
in Germany (selected randomly by the Tor client). During
this experiment, a signiﬁcant number of requests have been
blocked by reCAPTCHA. Speciﬁcally, at least 30% of our
requests are blocked each day. It is worth noting that the exit
node’s geolocation does not usually make that much of a
difference. We conﬁrm this by repeating the experiment sepa-
rately with a manually speciﬁed exit node in three different
278    23rd International Symposium on Research in Attacks, Intrusions and Defenses
USENIX Association
Table 8: Impact of anti-recognition on object detection mod-
els.
Table 9: Performance of human-based CAPTCHA solving
services.
Model
Objects
Objects
Detected
Objects
Detected with
Wrong Label
Base (B)
B+Basic
Augmentation (BA)
B+BA+Adversarial
Training
203
203
203
114
149
167
1
11
13
regions, namely North America (the US), Europe (Nether-
lands), and Asia (Hong Kong). It implies that reCAPTCHA
considers requests originating from an IP within the Tor net-
work to be highly suspicious.
Our ﬁndings also indicate that reCAPTCHA’s anti-bot tech-
nology follows a relaxed per IP address rate-limit approach
towards regular IP addresses. While it may be reasonable for
a modern web application to allow thousands of requests from
a single client machine with a unique IP address, a webpage
dedicated for the sole purpose of user registration or login
may not want to provide such freedom. Therefore, we rec-
ommend letting the website owners set up a custom daily IP
address rate-limit by adding such an option in reCAPTCHA
deployment settings and enforcing the restriction from the
reCAPTCHA backend.
6 Economic analysis
We use ﬁve popular human-based online CAPTCHA solving
services to compare their performance with our system. The
services are 2Captcha [1], Anti-Captcha [3], BestCaptcha-
Solver [4], DeathByCaptcha [6], and Imagetyperz [8]. We
submit 500 reCAPTCHA challenges to each service, total-
ing 2500 challenges for all the services combined. The av-
erage success rate and speed of breaking reCAPTCHA chal-
lenges are shown in Table 9. As we can see, our system
outperforms both BestCaptchaSolver and Imagetyperz. While
2Captcha, Anti-Captcha, and DeathByCaptcha perform a lit-
tle better than ours, they are signiﬁcantly slower. Our sys-
tem is more than 3.5x faster than the fastest human-based
CAPTCHA solving service. Further, the adversaries can run
our system with virtually no cost by deploying it on their
machines. Overall, our system’s performance is comparable
to that of human-based online CAPTCHA solving services,
and scammers could use it as an alternative to human workers
to automatically solve reCAPTCHA challenges.
7 Comparing to prior attacks
Sivakorn et al. leveraged online image annotation APIs
to break the earlier implementation of reCAPTCHA (re-
CAPTCHA 2015) with a success rate of 70.78% [44]. Since
then, reCAPTCHA has changed signiﬁcantly. In a similar
attack, Weng et al. evaluated the security of 10 real-world
Service
2Captcha
Anti-Captcha
BestCaptchaSolver
DeathByCaptcha
Imagetyperz
Our system
Success Rate (%)
Speed (s)
98.2
92.4
67.2
96.2
73
83.25
73.11
83.99
93.42
78.33
131.4
19.93
image CAPTCHAs, including reCAPTCHA 2018 [50]. They
used a CNN-based image classiﬁcation model to break re-
CAPTCHA 2018 challenges with a success rate of 79%. Note
that reCAPTCHA 2018 used to show relatively simple im-
ages when compared to the current reCAPTCHA challenges.
Further, Weng et al. encountered only 10 image categories
in the reCAPTCHA 2018 challenges, where we come across
18 object categories in the latest version of reCAPTCHA.
Moreover, the anti-recognition mechanism employed by the
current reCAPTCHA was not available in reCAPTCHA 2018
as well.
In summary, we propose a new approach to breaking the
most advanced version of reCAPTCHA using object detec-
tion models. Our method signiﬁcantly outperforms prior ap-
proaches as well as off-the-shelf object detection APIs. We
believe the stark difference in the performance between our
solver and off-the-shelf object detection APIs is because we
train our solver to handle reCAPTCHA object categories ex-
clusively. In contrast, object detection APIs are developed for
general-purpose object detection tasks. Further, as discussed
before, we assume that these services are still in their early
development stages.
8 Discussion
8.1 Ethics
We did not affect the security or the availability of the tested
websites during our data collection for preliminary analy-
sis or performing a live attack on reCAPTCHA as we limit
our access within the two iframe elements related to the
challenge. We also disclosed our ﬁndings to Google when we
developed our system’s initial implementation in August 2019.
Unfortunately, we have not noticed any discernible changes
to reCAPTCHA by Google that can prevent our attack. Our
system can still break the reCAPTCHA challenges with a
high success rate as of March 2020.
We have not published the source code of our tool due to
concerns over potential abuse by scammers and fraudsters
alike. However, we encourage researchers to contact us if
they want to use our tool for research purposes only.
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    279
8.2 Limitation
We design our attack to break reCAPTCHA challenges specif-
ically. While reCAPTCHA is the most widely deployed
CAPTCHA service on the Web, there are other popular image
CAPTCHA schemes. It will be interesting to see if we could
extend our object detection based solver module to attack a
whole family of similar image CAPTCHA designs. We plan
to conduct a study on the generalization of our attack as a
future extension.
8.3 Countermeasures
While it may not be possible to prevent our attack completely,
we provide several countermeasures to limit it.
Content heterogeneity. Our experiment shows that content
homogeneity has contributed to lowering the accuracy of
image recognition and classiﬁcation services. However, it has
minimal to no impact on our object detection based solver. As
such, reCAPTCHA’s current approach to resisting automated
attacks does not seem to be working. We recommend using
images from diverse and heterogeneous sources, which will
provide the CAPTCHA designers more ﬂexibility if they need
to expand the total number of object categories.
Incorporate natural language understanding to image
CAPTCHA test. The natural language understanding is con-
sidered as one of the three biggest open problems in natural
language processing [14]. This weakness could be exploited
to strengthen the security of image CAPTCHA. We suggest
utilizing the natural language understanding in forming the
challenge instruction so that the direction needed to solve a
challenge must be inferred through natural language reason-
ing. The current design of reCAPTCHA makes this informa-
tion readily available to the attacker.
Use spatial properties of the object. The main design ﬂaw
of reCAPTCHA is that an advanced object detection system
can solve its underlying AI problem for telling humans and
bots apart. The problem could be hardened for the machine
by exploiting the object’s spatial attributes, such as shape,
size, orientation, tilt direction, etc. However, it may require
extensive research to determine whether designing such a
CAPTCHA scheme is feasible in practice.
9 Related work
CAPTCHA is an active research area, and there exists an
extensive body of studies in this area. Due to space limita-
tions, we only discuss the works that are mostly related to
ours. Further, we mainly focus on CAPTCHA attack related
research.
Image CAPTCHAs. Golle et al. [29] used support vector
machine classiﬁers to break Asirra CAPTCHA [26]. Zhu et
al. analyzed the security of various earlier image CAPTCHAs
and proposed attacks to break them [54]. Sivakorn et al. used
deep learning techniques to break reCAPTCHA 2015 [44].
Later Weng et al. analyzed the security of several real-world
image CAPTCHAs, including reCAPTCHA 2018, and devel-
oped deep learning-based attacks that succeeded in breaking
all the CAPTCHAs tested in their work [50]. Osadchy et al.
proposed a new CAPTCHA scheme called DeepCAPTCHA
that exploits adversarial examples in CAPTCHA image gen-
eration to deceive DNN image classiﬁers [37]. Shi et al. pro-
posed a framework for generating text and image adversarial
CAPTCHAs [43].
Text CAPTCHAs. Most text CAPTCHA schemes have been
broken [20,28,34,35,51,52]. Chellapilla et al. proposed using
machine learning algorithms to break earlier text CAPTCHA
designs [20]. Yan et al. used simple pattern recognition al-
gorithms to break most of the text CAPTCHAs provided at
Captchaservice.org with a near-perfect success rate [51]. El
Ahmad et al. proposed a novel attack against reCAPTCHA
v1 2010 [25]. In 2011, Bursztein et al. evaluated the secu-
rity of 15 CAPTCHA schemes from popular web sites and
concluded that 13 of them were vulnerable to automated at-
tacks [19]. In 2014, Bursztein et al. used a machine learning-
based generic attack to break many popular real-world text
CAPTCHA schemes, including reCAPTCHA 2011 and re-
CAPTCHA 2013 [17]. In 2016, Gao et al. were able to break
many text CAPTCHAs using a low-cost attack that uses Log-
Gabor ﬁlters [28]. In 2018, Ye et al. proposed a Generative
Adversarial Networks (GANs) based approach to break 33
text CAPTCHA schemes [53].
Audio CAPTCHAs. Audio CAPTCHAs designed as al-
ternative CAPTCHA schemes for visually impaired users