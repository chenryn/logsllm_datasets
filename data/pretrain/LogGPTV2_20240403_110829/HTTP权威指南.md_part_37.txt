### 盲中继与Keep-Alive连接问题

在某些简单的盲中继实现中，一个常见且声名狼藉的问题是，由于它们无法正确处理`Connection`首部，可能会导致`keep-alive`连接挂起。图8-14展示了这种情况。

#### 图8-14 说明
1. **客户端请求**：Web客户端向中继发送包含`Connection: Keep-Alive`首部的报文，请求建立一条持久连接。客户端等待响应以确认其请求是否被接受。
2. **中继转发**：中继收到HTTP请求后，由于不理解`Connection`首部，将其原样传递给服务器（见图8-14b）。然而，`Connection`首部是一个逐跳首部，仅适用于单条传输链路，不应沿链路传递。
3. **服务器误解**：Web服务器收到带有`Connection: Keep-Alive`首部的请求时，误认为中继（对服务器来说，它看起来就像其他客户端）希望进行持久对话。服务器同意并回送一个`Connection: Keep-Alive`响应首部（见图8-14c），认为自己正在与中继进行持久对话。但中继对此一无所知。
4. **中继返回响应**：中继将服务器的响应及`Connection: Keep-Alive`首部一起发回给客户端（见图8-14d）。客户端看到这个首部，认为中继同意了持久对话。此时，客户端和服务器都认为正在进行持久对话，而中继却不知情。
5. **中继挂起**：中继对持久对话一无所知，因此会将所有数据转发给客户端，并等待服务器关闭连接。但由于服务器认为中继要求保持连接活跃，不会主动关闭连接，导致中继挂起。
6. **客户端继续请求**：客户端收到响应后，直接发送第二条请求（见图8-14e）。简单中继通常不会期望同一条连接上有多个请求到达，因此浏览器上的加载指示器会不停转动，但没有任何进展。

为避免这些问题，可以采用一些方法使中继更智能，但所有简化的代理都存在互操作性风险。构建特定目标的简单HTTP中继时，应特别注意其使用方法。对于大规模部署，建议使用完全遵循HTTP标准的代理服务器。

更多关于中继和连接管理的信息，请参阅第4.5.6节。

### 参考资料
- [RFC 2616](http://www.w3.org/Protocols/rfc2616/rfc2616.txt)：R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Mastinter, P. Leach, T. Berners-Lee 编写的“Hypertext Transfer Protocol”。
- [《Web代理服务器》](http://www.alternic.org/drafts/drafts-l-m/draft-luotonen-Web-proxy-tunneling-01.txt)：Ari Luotonen 编写，Prentice Hall 出版。
- [通用网关接口](http://cgi-spec.golux.com)：RFC项目页面。
- [W3C SOAP 1.2 工作草案](http://www.w3.org/TR/2001/WD-soap12-part0-20011217/)。
- [《SOAP Web服务开发》](Programming Web Services with Soap)：James Snell, Doug Tidwell, Pavel Kulchenko 编写，O’Reilly & Associates 出版。
- [W3C Web服务架构需求](http://www.w3.org/TR/2002/WD-wsa-reqs-20020429)。
- [《Web服务精髓》](Web Services Essentials)：Ethan Cerami 编写，O’Reilly & Associates 出版。

### 第九章：Web机器人

本章我们将探讨被称为Web机器人的自激活用户代理，继续我们的HTTP架构之旅。

#### Web机器人的定义
Web机器人是能够在无需人类干预的情况下自动执行一系列Web事务处理的软件程序。这些机器人会在不同网站间移动，获取内容，跟踪超链接，并处理找到的数据。根据它们的行为方式，人们给它们起了各种名字，如“爬虫”、“蜘蛛”、“蠕虫”等。

#### Web机器人的示例
- **股票图形机器人**：每隔几分钟向股票市场服务器发送HTTP GET请求，用获得的数据构建股市价格趋势图。
- **Web统计机器人**：收集有关万维网规模和发展的统计信息，统计页面数量、大小、语言和媒体类型。
- **搜索引擎机器人**：搜集所有文档以创建搜索数据库。
- **比较购物机器人**：从在线商店目录中收集Web页面，构建商品及其价格的数据库。

#### 爬虫及爬行方式
Web爬虫是一种递归遍历信息性网站的机器人，从第一个页面开始，逐步获取指向的所有页面。这些机器人沿着HTML超链接网络“爬行”，因此得名“爬虫”或“蜘蛛”。

#### 根集
爬虫开始访问的URL初始集合称为根集。选择根集时，应从足够多的不同站点中选择URL，以便最终能够访问到大部分感兴趣的Web页面。

#### 链接提取和标准化
爬虫在Web上移动时，会解析HTML页面，提取URL链接，并将相对URL转换为绝对形式。

#### 避免环路
机器人必须记录已访问过的URL，以避免陷入循环。环路会使爬虫陷入无限循环，消耗大量资源，并可能使Web服务器不堪重负。

#### 循环与复制
环路对爬虫有害的原因包括：
- 陷入循环，浪费时间和资源。
- 对Web服务器造成压力，可能导致拒绝服务。
- 收集大量重复内容，影响应用程序的有效性。

#### 记录访问过的URL
为了高效管理大量URL，可以使用复杂的数据结构，如搜索树、散列表、有损存在位图等。此外，还可以通过分类和集群来扩展爬虫的能力。

更多关于大规模数据管理的技术细节，请参考相关书籍和技术文档。