某些简单盲中继实现中存在的一个更常见（也更声名狼藉的）问题是，由于它们无
法正确处理Connection首部，所以有潜在的挂起keep-alive连接的可能。图8-14
对这种情况进行了说明。
222 ｜ 第8章
（b）服务器认为对方要求建
立keep-alive连接，所以任务
完成后不会关闭连接
(a) Connection:Keep-Alive (b) Connection:Keep-Alive
盲中继
(d) Connection:Keep-Alive (c) Connection:Keep-Alive
客户端 服务器
（c）中继会等待连接的关闭，
（e）下一条请求 忽略连接上所有的新请求
（f）中继不会去处理keep-alive连接上客户
端发出的第二条请求，所以它会挂起在那里
图8-14 如果简单盲中继是单任务的，且不支持Connection首部，就会挂起
这张图中发生的情况如下所述。
• 在图8-14a中，Web客户端向中继发送了一条包含Connection:Keep-Alive
首部的报文，如果可能的话要求建立一条keep-alive连接。客户端等待响应，以
确定它要求建立keep-alive信道的请求是否被认可了。
• 中继收到了这条HTTP请求，但它并不理解Connection首部，因此会将报文一
字不漏地沿着链路传递给服务器（参见图8-14b）。但Connection首部是个逐
跳首部；只适用于单条传输链路，是不应该沿着链路传送下去的。要有不好的事 212
情发生了！
• 在图8-14b中，经过中继转发的HTTP请求抵达Web服务器。当Web服务器收
到经过代理转发的Connection:Keep-Alive首部时，会错误地认为中继（对
服务器来说，它看起来就和其他客户端一样）要求进行keep-alive的对话！这对
Web服务器来说没什么问题——它同意进行keep-alive对话，并在图8-14c中回
送了一个Connection:Keep-Alive响应首部。那么，此时，Web服务器就认
为它是在与中继进行keep-alive对话，会遵循keep-alive对话的规则。但中继对
keep-alive会话根本就一无所知。
• 在图 8-14d 中，中继将 Web 服务器的响应报文，以及来自 Web 服务器的
Connection:Keep-Alive首部一起发回给客户端。客户端看到这个首部，认
为中继同意进行keep-alive对话。此时，客户端和服务器都认为它们是在进行
keep-alive对话，但与它们进行对话的中继却根本不知道什么keep-alive对话。
• 中继对持久对话一无所知，所以它会将收到的所有数据都转发给客户端，等待原
始服务器关闭连接。但原始服务器认为中继要求服务器将连接保持在活跃状态，
所以是不会关闭连接的！这样，中继就会挂起，等待连接的关闭。
• 在图8-14d中，当客户端收到回送的响应报文时，它会直接转向第二条请求，在
keep-alive连接上向中继发送另一条请求（参见图8-14e）。简单中继通常不会期
集成点：网关、隧道及中继 ｜ 223
待同一条连接上还会有另一条请求到达。浏览器上的圈会不停地转，但没有任何
进展。
有一些方法可以使中继稍微智能一些，以消除这些风险，但所有简化的代理都存在
着出现互操作性问题的风险。要为某个特定目标构建简单的HTTP中继，一定要特
别注意其使用方法。对任何大规模部署来说，都要非常认真地考虑使用真正的、完
全遵循HTTP的代理服务器。
更多与中继和连接管理有关的信息，参见4.5.6节。
8.7 更多信息
更多信息，请参见下列参考材料。
• http://www.w3.org/Protocols/rfc2616/rfc2616.txt
RFC 2616， 由 R. Fielding、J. Gettys、J. Mogul、H. Frystyk、L. Mastinter、 P.
Leach和T. Berners-Lee编写的“Hypertext Transfer Protocol”。
• Web Proxy Servers（《Web代理服务器》）
213 Ari Luotonen，Prentice Hall出版的计算机图书。
• http://www.alternic.org/drafts/drafts-l-m/draft-luotonen-Web-proxy-tunneling-01.txt
Ari Luotonen编写的“Tunneling TCP based protocols through Web proxy servers”
（“用隧道方式通过Web代理服务器传输基于TCP的协议”）。
• http://cgi-spec.golux.com
通用网关接口——RFC项目页面。
• http://www.w3.org/TR/2001/WD-soap12-part0-20011217/
W3C——SOAP版本1.2工作草案。
• Programming Web Services with Soap8（《Soap Web服务开发》）
James Snell、Doug Tidwell和Pavel Kulchenko编写，O’Reilly & Associates公司
出版。
• http://www.w3.org/TR/2002/WD-wsa-reqs-20020429
W3C——Web服务的架构要求。
• Web Services Essentials9（《Web服务精髓》）
214 Ethan Cerami，O’Reilly & Associates公司出版。
注8~9：这二本书的中文版已由中国电力出版社出版。（编者注）
224 ｜ 第8章
第9章
机器人
Web
225
本章我们来仔细了解一下被称为Web机器人（Web robot）的自活跃（self-animating）
用户代理，以继续我们的HTTP架构之旅。
Web机器人是能够在无需人类干预的情况下自动进行一系列Web事务处理的软件
程序。很多机器人会从一个Web站点逛到另一个Web站点，获取内容，跟踪超链，
并对它们找到的数据进行处理。根据这些机器人自动探查Web站点的方式，人们
为它们起了一些各具特色的名字，比如“爬虫”、“蜘蛛”、“蠕虫”以及“机器人”
等，就好像它们都有自己的头脑一样。
这里有几个Web机器人的示例。
• 股票图形机器人每隔几分钟就会向股票市场的服务器发送HTTP GET，用得到的
数据来构建股市价格趋势图。
• Web统计机器人会收集与万维网规模及发展有关的“统计”信息。它们会在
Web上游荡，统计页面的数量，记录每个页面的大小、所用语言以及媒体类型。1
• 搜索引擎机器人会搜集它们所找到的所有文档，以创建搜索数据库。
• 比较购物机器人会从在线商店的目录中收集Web页面，构建商品及其价格的数
据库。
9.1 爬虫及爬行方式
Web爬虫是一种机器人，它们会递归地对各种信息性Web站点进行遍历，获取第
一个Web页面，然后获取那个页面指向的所有Web页面，然后是那些页面指向的
所有Web页面，依此类推。递归地追踪这些Web链接的机器人会沿着HTML超链
215 创建的网络“爬行”，所以将其称为爬虫（crawler）或蜘蛛（spider）。
因特网搜索引擎使用爬虫在Web上游荡，并把它们碰到的文档全部拉回来。然后对
这些文档进行处理，形成一个可搜索的数据库，以便用户查找包含了特定单词的文
档。网上有数万亿的Web页面需要查找和取回，这些搜索引擎蜘蛛必然是些最复杂
的机器人。我们来进一步仔细地看看这些爬虫是怎样工作的。
9.1.1 从哪儿开始：根集
在把饥饿的爬虫放出去之前，需要给它一个起始点。爬虫开始访问的URL初始集合
被称作根集（root set）。挑选根集时，应该从足够多不同的站点中选择URL，这样，
爬遍所有的链接才能最终到达大部分你感兴趣的Web页面。
注1： http://www.netcraft.com收集了大量统计度量值，用于统计Web站点使用的是哪种类型的服务器。
226 ｜ 第9章
要在图9-1所示的Web上爬行，使用哪个根集比较好呢？与在真实的Web中一样，
没有哪个文档最终可以链接到所有其他文档上去。如果从图9-1的文档A开始，可
以到达B、C和D，然后是E和F，然后到J，然后到K。但没有从A到G，或从A
到N的链路。
A G L S
B C D H I M N T U
E F J O
K P Q R
图9-1 根集要能够到达所有的页面
这个Web结构中的某些Web页面，比如S、T和U，几乎是被隔离开来的——它们
是孤立的，没有任何链接指向它们。可能这些孤独的页面是一些新页面，还没人找
到它们。或者可能是一些非常老的或不显眼的页面。
总之，根集中并不需要有很多页面，就可以涵盖一大片Web结构。在图9-1中，要
抵达所有页面，根集中只需要有A、G和S就行了。
通常，一个好的根集会包括一些大的流行Web站点（比如http://www.yahoo.com）、
一个新创建页面的列表和一个不经常被链接的无名页面列表。很多大规模的爬虫产
品，比如因特网搜索引擎使用的那些爬虫，都为用户提供了向根集中提交新页面或
无名页面的方式。这个根集会随时间推移而增长，是所有新爬虫的种子列表。 216
9.1.2 链接的提取以及相对链接的标准化
爬虫在Web上移动时，会不停地对HTML页面进行解析。它要对所解析的每个页
面上的URL链接进行分析，并将这些链接添加到需要爬行的页面列表中去。随着
爬虫的前进，当其发现需要探查的新链接时，这个列表常常会迅速地扩张。2爬虫
要通过简单的HTML解析，将这些链接提取出来，并将相对URL转换为绝对形式。
2.3.1节讨论了如何进行这种转换。
注2： 我们会在9.1.3节开始讨论爬虫是否需要记住它们到过何处。在爬行过程中，这个已发现URL列表会
不断扩张，直到已经对Web空间进行了彻底的探查为止，这时爬虫就会到达一个不再发现新链接的
状态了。
Web机器人 ｜ 227
9.1.3 避免环路的出现
机器人在Web上爬行时，要特别小心不要陷入循环，或环路（cycle）之中。我们
来看看图9-2中所示的爬虫。
• 在图9-2a中，机器人获取页面A，看到A链接到B，就获取页面B。
• 在图9-2b中，机器人获取页面B，看到B链接到C，就获取页面C。
• 在图9-2c中，机器人获取页面C，会看到C链接到A。如果机器人再次获取页面A，
就会陷入一个环路中，获取A、B、C、A、B、C、A……
A B E B E B E
A A AB A
C C ABC C
D D D
（a）机器人获取页面A， （b）机器人跟踪链 （c）机器人跟踪链接，回到A
跟踪链接，获取B 接，获取页面C
图9-2 在Web的超链中爬行
机器人必须知道它们到过何处，以避免环路的出现。环路会造成机器人陷阱，这些
陷阱会暂停或减缓机器人的爬行进程。
9.1.4 循环与复制
至少出于下列三个原因，环路对爬虫来说是有害的。
• 它们会使爬虫陷入可能会将其困住的循环之中。循环会使未经良好设计的爬虫不
217 停地兜圈子，把所有时间都耗费在不停地获取相同的页面上。爬虫会消耗掉很多
网络带宽，可能完全无法获取任何其他页面了。
• 爬虫不断地获取相同的页面时，另一端的Web服务器也在遭受着打击。如果爬
虫与服务器连接良好，它就会击垮Web站点，阻止所有真实用户访问这个站点。
这种拒绝服务是可以作为法律诉讼理由的。
• 即使循环自身不是什么问题，爬虫也是在获取大量重复的页面 [通常被称为“dups”
（重复），以便与“loops”（循环）押韵]。爬虫应用程序会被重复的内容所充斥，
这样应用程序就会变得毫无用处。返回数百份完全相同页面的因特网搜索引擎就
是一个这样的例子。
228 ｜ 第9章
9.1.5 面包屑留下的痕迹
但是，记录曾经到过哪些地方并不总是一件容易的事。编写本书时，因特网上有数
十亿个不同的Web页面，其中还不包括那些由动态网关产生的内容。
如果要爬行世界范围内的一大块Web内容，就要做好访问数十亿URL的准备。记
录下哪些URL已经访问过了是件很具挑战的事情。由于URL的数量巨大，所以，
要使用复杂的数据结构以便快速判定哪些URL是曾经访问过的。数据结构在访问速
度和内存使用方面都应该是非常高效的。
数亿URL需要具备快速搜索结构，所以速度是很重要的。穷举搜索URL列表是根本不
可能的。机器人至少要用到搜索树或散列表，以快速判定某个URL是否被访问过。
数亿URL还会占用大量的空间。如果平均每个URL有40个字符长，而且一个Web
机器人要爬行5亿个URL（只是Web的一小部分），那么搜索数据结构只是存储这
些URL就需要20GB或更多的存储空间（40字节/URL×5亿个URL = 20GB）！
这里列出了大规模Web爬虫对其访问过的地址进行管理时使用的一些有用的技术。
• 树和散列表
复杂的机器人可能会用搜索树或散列表来记录已访问的URL。这些是加速URL
查找的软件数据结构。
• 有损的存在位图
为了减小空间，一些大型爬虫会使用有损数据结构，比如存在位数组（presence
bit array）。用一个散列函数将每个URL都转换成一个定长的数字，这个数字在 218
数组中有个相关的“存在位”。爬行过一个URL时，就将相应的“存在位”置
位。如果存在位已经置位了，爬虫就认为已经爬行过那个URL了。3
• 检查点
一定要将已访问URL列表保存到硬盘上，以防机器人程序崩溃。
• 分类
随着Web的扩展，在一台计算机上通过单个机器人来完成爬行就变得不太现实
了。那台计算机可能没有足够的内存、磁盘空间、计算能力，或网络带宽来完成
爬行任务。
注3： 由于URL的潜在数量是无限的，而存在位数组中的比特数是有限的，所以有出现冲突的可能——两
个URL可能会映射到同一个存在位上去。出现这种情况时，爬虫会错误地认为它已经爬行过某个实
际未爬行过的页面了。在实际应用中，使用大量的存在位就可以使这种情况极少发生。产生冲突的后
果就是爬虫会忽略某个页面。
Web机器人 ｜ 229
有些大型Web机器人会使用机器人“集群”，每个独立的计算机是一个机器人，
以汇接方式工作。为每个机器人分配一个特定的URL“片”，由其负责爬行。这
些机器人配合工作，爬行整个Web。机器人个体之间可能需要相互通信，来回传
送URL，以覆盖出故障的对等实体的爬行范围，或协调其工作。
Witten 等人编写的Managing Gigabytes: Compressing and Indexing Documents and
Images（《海量数据管理——文档和图像的压缩与索引》）4，Morgan Kaufmann出版
社出版，是实现大规模数据结构的很好的参考书。这本书讲的全是管理大量数据所
需的各种诀窍和技巧。
9.1.6 别名与机器人环路