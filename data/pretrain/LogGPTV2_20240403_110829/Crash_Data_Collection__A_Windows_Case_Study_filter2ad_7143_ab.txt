(149)
Internet 
Explorer, 59% 
(330)
Figure  2:  Web  Browsing  Application  Use  and  Crash 
Frequency.  Note- some users check e-mail using Netscape’s 
built-in  mail  application.  We  do  not  distinguish  between 
Netscape’s browser and e-mail crashes.  
4.3  Frequency  of  use  does  not  predict  frequency  of 
crash 
Periodical retrieval of snapshots of processes that 
run  on  users’  computers  offers  the  best  evaluation  of 
application  usage.  However,  due  to  stringent  privacy 
concerns,  it  is  hard,  if  not  impossible,  to  convince 
people  to  share  such  data  with  us.  We  solicited  a 
survey  directed  at  users  whose  machines  generated 
crashes and received a high response rate (over 50%). 
The  difficulty  of  objective  evaluation  of  computer 
usage  taints  this  data  less  accurate  than  automated 
monitoring.  However, 
information  highlights 
unusual  occurrences  in  application  crashes.  Figure  1 
outlines the distribution of application usage. 
they  are  not 
Comparing  columns  3  and  4  of  figure  1,  we 
observe  that  while  web  browsers  cause  a  majority  of 
crashes, 
the  most  frequently  used 
application. We further dissected web-browser crashes 
and use by explicit applications (see Figure 2). Internet 
Explorer is the  most commonly used, and the  highest 
crash  contributor  among  web  browsers.  Netscape  and 
Firefox have approximately the same proportion of use 
as well as crashes. Mozilla also appears to be a fairly 
popular browser; however, it does not generate nearly 
as  many  crashes  as  other  browsers.  A  possible 
this 
explanation for Mozilla’s robustness is its open source 
nature that benefits from user testing and evaluation. 
On average, users reported more frequent usage of 
email and document preparation applications than web 
browsers; 
these  applications  caused  a  significant 
proportion  of  crashes.  Recall  throughout  this  analysis 
that this data represents the Berkeley EECS department 
and  not  the  entire  Windows  user  population.  Usage 
statistics underscore this fact as code development and 
scientific  computation  are  uncommon  activities  for 
most Windows users.  
4.4 Applications hang frequently 
175 
66 
63 
54 
36 
32 
16 
16 
11 
11 
11 
10 
10 
10 
10 
8 
7 
7 
7 
7 
6 
5 
# hangs  % hangs 
26%
10%
9%
8%
5%
5%
2%
2%
2%
2%
2%
1%
1%
1%
1%
1%
1%
1%
1%
1%
1%
1%
Our  data  suggests  that  about  half  of  crashes  are 
generated  due  to  a  user’s  manual  termination  of  an 
application, i.e., application hang. Often, when an 
Application 
iexplore.exe 
winword.exe 
matlab.exe  
outlook.exe 
firefox.exe  
Netscp.exe  
powerarc.exe 
powerpnt.exe 
AcroRd32.exe  
excel.exe 
explorer.exe  
Acrobat.exe  
mozilla.exe  
msimn.exe 
thunderbird.exe  
AdDestroyer.exe  
Mathematica.exe 
msdev.exe  
netscape.exe  
wmplayer.exe  
notepad.exe 
TeaTimer.exe  
hp precisionscan 
pro.exe  
msaccess.exe 
photosle.exe  
rundll32.exe  
winamp.exe  
apps causing 
<1% of crashes 
each 
Total 
to  Various 
Figure  3:  Frequency  of  Hangs  due 
Applications.  Note- some of these applications are custom- 
authored by users. 
1%
1%
1%
1%
1%
4 
4 
4 
4 
4 
76 
674 
11%
Component 
Description 
Author 
NT system functions 
ntdll.dll  
Microsoft C runtime library  
msvcrt.dll  
Acrobat Reader  
acrord32.exe  
simpl_fox_gl.exe   User application  
User application  
ray_tracing.exe  
Scripting component functions   MS 
MS 
MS 
3rd party  Acrobat Reader 
3rd party 
3rd party 
pdm.dll  
firefox.exe 
user32.dll  
winword.exe 
exceed.exe  
Web browser 
Communication, message 
handler, timer functions  
Windows document editor 
Exceed X Windows  
3rd party 
MS 
MS 
3rd party 
Apps invoking 
component 
Internet Explorer, Matlab 
Acrobat, Netscape 
-- 
-- 
Visual Studio, Internet 
Explorer 
Firefox 
Firefox, Internet Explorer 
Word, Outlook 
Exceed 
%crash 
10.87% (90)
4.71% (39)
3.02% (25)
3.02% (25)
2.78% (23)
2.42% (20)
2.29% (19)
2.29% (19) 
2.29% (19)
1.81% (15)
Figure 4: Top ten problematic DLL and executable files causing crashes. Each component is annotated with a description of 
its  functionality,  authorship  (MS=Microsoft)  and  examples  of  applications  using  this  component.  The  percentage  of  crashes 
attributed  to  a  component  is  listed  in  the  last  column  along  with  the  raw  number  of  crashes  in  parenthesis.  This  percentage 
excludes  crashes  categorized  as  application  hangs.  Note-  for  user-written  executable  files,  we  are  unable  to  provide  sample 
applications that use the component. 
the 
tend 
represents 
Internet  Explorer, 
to  an  outdated 
insufficient  memory,  users 
application  does  not  respond  in  a  timely  manner, 
perhaps  due 
.dll,  an  overloaded 
processor  or 
to 
terminate  this  process  and  retry  subsequently.  It  is 
possible that such applications would crash eventually 
if  the  user  avoided  pre-termination  during  its  “hang”. 
Figure 3 outlines the applications that commonly hang. 
Again, 
largest 
proportion  of  applications  that  hang;  Netscape  and 
Firefox  fall  among  the  top  ten  commonly  hanging 
applications.  A  feasible  explanation  for  this  trend  is 
that  web  browsers  interact  with  numerous  other 
applications such as Macromedia Flash, Quicktime and 
Acrobat Reader. Often, perusing the contents of a web 
site  requires  a  user  to  download  un-trusted  and 
unreliable  code.  Consequently,  a  robust  browser 
application is forced to interact with other applications 
that  are  unsafe,  eventually  leading  to  crashes.  To 
resolve  this  problem,  interaction  must  be  restricted  to 
trusted,  safe  plug-ins,  avoiding  potentially  unsafe  and 
potentially  malicious  code.  In  contrast,  applications 
such  as  MS  Word,  Outlook  and  Matlab  can  hang  for 
different  reasons.  A  corrupt  file  or 
insufficient 
computation  memory  can  cause  the  application  to 
hang. In some scenarios, a file can be large enough to 
cause  problems  at  start  up.  A  practical  solution  must 
reduce 
the 
software/machine. 
4.5 .dll files are  not robust enough 
the  workload 
upgrade 
Figure 4 lists the top ten .dll and executable files 
blamed  for  crashes.  These  components  constitute  a 
significant  portion  of  non-application  hang-induced 
crashes. Apparently, a majority of problematic .dll files 
and/or 
invoked  by  multiple  applications.  A 
are 
few 
noteworthy  examples  are  ntdll.dll  and  msvcrt.dll. 
Among several scenarios, the same .dll can be blamed 
for a crash. For example, the caller of a .dll routine can 
pass  invalid  arguments  to  the  callee.  Alternately,  a 
.dll’s callee routine can return a bad value. Moreover, 
it is possible for a machine’s state to be corrupt at the 
time  of  .dll  execution.  Precise  inter-.dll  interface 
definition  and  sand-boxing  will  help  avoid  cascading 
effects of data corruption. 
5.  Future  Directions:  Open  source  data 
collection via BOINC Crash Collector 
To  collect  finer  grained  usage  information  and 
study a broader population of Windows users, we have 
embarked  on  an  effort 
target  public-resource 
computing  volunteers.  BOINC  is  a  platform  for 
pooling computer resources from volunteers to collect 
data  and  run  distributed  computations  [1].  A  popular 
example  of  an  application  using  this  platform  is 
SETI@home,  which  aggregates  computing  power  to 
‘search 
intelligence’.  BOINC 
provides  services  to  send  and  receive  data  from  its 
users to a BOINC server via the HTTP protocol using 
XML formatted files. Each subscribed user’s machine, 
when idle, is used to run BOINC applications.  
for  extraterrestrial 
Taking advantage of these efforts, we have created 
a  data  collection  application  to  run  on  this  platform. 
BOINC  provides  a  good  opportunity  to  collect  and 
aggregate data from users outside our department while 
addressing privacy concerns. We currently scrape crash 
dumps, and if user consents usage information such as 
hardware/software  profiles,  from  users’  machines  and 
send  corresponding  data  to  our  BOINC  server.  The 
to 
drawback of this mechanism is that we can only collect 
crash dumps that are stored in known locations on the 
user’s  computer,  consequently  excluding  application 
crash  dumps  that  are  stored  in  unknown  app-specific 
locations. Numerous people enthusiastically contribute 
data to projects on BOINC rather than corporations as 
they  favor  a  research  cause.  Additionally,  users 
appreciate 
that 
compares  their  machine  to  an  average  BOINC  user’s 
machine,  or 
recognition  as  pioneering 
contributors to the project.  
6.  Conclusion  
through  statistics 
incentive  either 
through 
Our  crash-data  related  study  has  contributed 
several Windows related revelations. The most notable 
reality  is  that  the  Windows  operating  system  is  not 
responsible  for  a  majority  of  PC  crashes  at  Berkeley. 
Application  software,  especially  browsers,  are  mostly 
responsible  for  these  crashes.  Users  can  alleviate 
computer  frustration  by  better  usage  discipline  and 
avoiding  unsafe  applications.  With  additional  data 
collection  and  mining,  we  hope  to  make  stronger 
claims about applications and also extract safe product 
design  and  usage  methodology  that  apply  universally 
to all operating systems. Eventually, this research can 
gauge product as well as usage evolution. 
Studying  failure  data  is  as  important  to  the 
computing  industry  as  it  is  to  consumers.  Product 
dependability evaluations, such as reports provided by 
J.D. Power and Associates, help evolve the industry by 
reducing quality differential between various products. 
Once  product  reliability  data  is  publicized,  users  will 
use  such 
their  purchasing 
decisions  and  usage  patterns.  Product  developers  will 
react  defensively  and  resulting  competition  will 
improve quality control.  
information 
to  guide 
References 
[1]  D. Anderson, “Public Computing: Reconnecting People 
to Science,” The Conference on Shared Knowledge and 
the Web, Residencia de Estudiantes, Madrid, Spain, 
Nov.  2003.  
[2]  A. Brown, L. Chung, and D. Patterson. “Including the 
Human Factor in Dependability Benchmarks,” In Proc. 
2002 DSN Workshop on Dependability Benchmarking, 
Washington, D.C.,  June 2002. 
[3]   A. Brown and M. Seltzer. “Operating System 
Benchmarking in the Wake of Lmbench: A Case Study 
of the Performance of NetBSD on the Intel x86 
Architecture,” In Proc. 1997 ACM SIGMETRICS 
Conference on the Measurement and Modeling of 
Computer Systems, Seattle, WA, June 1997.  
[4]   J. Forrester, B. Miller, “An Empirical Study of the 
Robustness of Windows NT Applications Using 
Random Testing,” In Proc. 4th USENIX Windows 
System Symposium, Seattle, WA, Aug. 2000. 
[5]   A. Ganapathi, Y. Wang, N. Lao and J. Wen. “Why PCs 
are Fragile and What We Can Do About It: A Study of 
Windows Registry Problems,” In Proc. International 
Conference on Dependable Systems and Networks 
(DSN-2004), Florence, Italy, June 2004. 
[6]   J. Gray. “Why Do Computers Stop and What Can Be 
Done About It?” Symp on Reliability in Distributed 
Software and Database Systems, pp 3–12, 1986. 
[7]   A. Kalakech, K. Kanoun, Y. Crouzet, J. Arlat, 
“Benchmarking the dependability of Windows NT4, 
2000 and XP,” In Proc. International Conference on 
Dependable Systems and Networks (DSN-2004), 
Florence, Italy, June 2004. 
[8]   M. Kalyanakrishnam, “Analysis of Failures in Windows 
NT Systems,” Masters Thesis, Technical report CRHC 
98-08, University of Illinois at Urbana-Champaign, 
1998. 
[9]   P. Koopman, J. DeVale, “The Exception Handling 
Effectiveness of POSIX Operating Systems,” IEEE 
Trans. on Software Engineering, Vol 26, No 9, pp 837-
848 Sept. 2000. 
[10]  I. Lee and R. Iyer, “Software Dependability in the 
Tandem GUARDIAN Operating System,” IEEE Trans. 
on Software Engineering, Vol 21, No 5, pp 455-467, 
May 1995. 
[11]  Y. Levendel, “Defects and Reliability Analysis of Large 
Software Systems: Field Experience,” Digest 19th 
Fault-Tolerant Computing Symposium, pp 238-243, 
June 1989.  
[12]  B. Murphy, “Automating Software Failure Reporting,” 
ACM Queue Vol 2, No 8, Nov. 2004. 
[13]  D. Oppenheimer, A. Brown, J. Traupman, P. Broadwell, 
and D. Patterson. “Practical issues in dependability 
benchmarking,” Workshop on Evaluating and 
Architecting System dependabilitY (EASY ’02), San 
Jose, CA, Oct. 2002. 
[14]  C. Shelton, P. Koopman, K. DeVale, “Robustness 
Testing of the Microsoft Win32 API,” In Proc. 
International Conference on Dependable Systems and 
Networks (DSN-2000), New York, June 2000. 
[15]  C. Simache, M. Kaaniche, A. Saidane, “Event log based 
dependability analysis of Windows NT and 2K 
systems,” In Proc. 2002 Pacific Rim International 
Symposium on Dependable Computing (PRDC'02), pp 
311-315, Tsukuba, Japan, Dec. 2002. 
[16]  D. Tang and R. Iyer, “Analysis of the VAX/VMS Error 
Logs in Multicomputer Environments – A Case Study 
of Software Dependability,” International Symposium 
on Software Reliability Engineering, Research Triangle 
Park, North Carolina, Oct 1992. 
[17]  A. Thakur, R. Iyer, L. Young, I. Lee, “Analysis of 
Failures in the Tandem NonStop-UX Operating 
System,” International Symposium on Software 
Reliability Engineering, Oct 1995. 
[18]  D. Wilson, B. Murphy, L. Spainhower, “Progress on 
Defining Standardized Classes for Comparing the 
Dependability of Computer Systems,” In Proc.  DSN 
2002 Workshop on Dependability Benchmarking, 
Washington, D.C.,  June 2002.