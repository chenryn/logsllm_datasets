There is a special case that the path used for address
translation is incomplete because a non-bottom-level paging-
structure entry is set to non-present, as shown in Figure 2(d).
This could happen when setting a breakpoint at a virtual
address that is not mapped in the guest, or after a non-
bottom-level paging-structure entry is modiﬁed. Spider sets
the paging structures along the path to read-only, including
the one that has the non-present entry. Later, when the
paging-structure entry changes from non-present to present,
the path will extend, and Spider will set the paging struc-
tures on the extended path to read-only. After the path
reaches the bottom-level paging-structure (e.g. as in Fig-
ure 2(a)), Spider could handle further modiﬁcations using
standard approaches as mentioned above.
4.4 Handling Code Modiﬁcation
When the guest tries to modify the content of a split page,
the write operation will be performed on its data view. This
means that if an instruction is modiﬁed, the change will not
be reﬂected in the code view. This could lead to incorrect
execution of self-modifying programs, and could be utilized
by malware to detect the existence of Spider. To guarantee
transparency, Spider must synchronize any change of the
data view to the code view.
As mentioned in Section 4.1, Spider sets the data view
of a split page to read-only in EPT to intercept any writing
attempt. When the guest tries to write to the page, an EPT
violation will be triggered and captured. Spider records
the oﬀset of the data OF F that is going to be written in
the page. Spider also records the length LEN that will
be synchronized by matching the instruction’s op-code in a
pre-built table which stores the maximum data length that
could be aﬀected by each type of instruction. Then Spider
will temporarily set the data view to writable, and let the
guest single-step through the instruction that performs the
write. After that, it will copy LEN bytes from oﬀset OF F
in the data view to the same oﬀset in the code view.
It is worth noting that the breakpoints that have been set
in the page may or may not be valid after code modiﬁcation.
For example, if the guest overwrites an instruction with the
same instruction, it indicates the guest is trying to overwrite
and disable the breakpoint set at that instruction; in that
case, the breakpoint is still valid and should be re-set when
overwritten. But if the guest overwrites the instruction with
a diﬀerent instruction, re-setting breakpoint at the original
place blindly may not make sense. Hence, we allow the user
to specify a function which will be invoked when the page
that contains the breakpoint is being modiﬁed, in which the
user could perform proper actions to handle the event, such
as re-setting the breakpoint at the same place, or moving it
to another location after analyzing the modiﬁed code.
4.5 Data Watchpoint
Spider allows setting a data watchpoint at a speciﬁc phys-
ical address by adjusting the EPT entry of the guest physi-
cal page that contains the memory address to read-only (to
trap write access) or execute-only (to trap both read/write
access). When the page is accessed, an EPT violation will
be triggered and captured by Spider. Spider will check
if a watchpoint has been set on the address that is ac-
cessed in the page; if so, it will call the corresponding user-
provided watchpoint handler. After that, it will temporarily
set the EPT entry to writable and resume the guest to single-
step through the instruction that does the memory access.
When the guest returns from single-stepping, Spider ad-
justs the EPT entry again to trap future accesses. Like invis-
ible breakpoint, data watchpoint also utilizes the virtual-to-
physical mapping monitoring method (Section 4.3) so that it
could be used to trap memory access at any virtual address.
4.6 Handling Timing Side-Effect
In hardware virtualization, since part of the CPU time
is taken by hypervisor and VMEntry/VMExit, a program
costs more time to run than in a native environment. At-
tackers could execute the RDTSC instruction to read the
Time Stamp Counter (TSC) which stores the elapsed CPU
cycles to detect the discrepancy. To maintain transparency,
Spider needs to hide the CPU cycles cost by hypervisor
(Th) and VMEntry/VMExit (Te) from the guest. Spider
measures Th by reading the TSC right after each VMExit
and right before each VMEntry and calculating the diﬀer-
ence. Te is approximated by proﬁling a loop of RDTSC
instruction in guest. Spider sets the TSC-oﬀset ﬁeld in vir-
tual machine control structure (VMCS) to −(Th +Te) so the
value is subtracted from the TSC seen by the guest [13].
5.
IMPLEMENTATION
We have implemented a prototype of Spider on the KVM
3.5 hypervisor. The prototype implements the design as
described in Section 4 in the kernel module part of KVM
(kvm-kmod) to provide the primitive of setting invisible
breakpoint at speciﬁed virtual address in a process address
space. Based on the primitive, it also implements a front-
end for Spider in the userspace part of KVM (qemu-kvm)
to provide features that make debugging and instrumenta-
tion more convenient. It is worth noting that Spider itself is
OS-independent; However, the front-end requires knowledge
of the guest OS to perform VMI [18] for some features. Cur-
rently, our front-end supports both Windows XP SP2 32-bit
and Ubuntu Linux 12.04 32-bit guest. We now discuss the
implementation of some features in our front-end.
Kernel Breakpoints. We have to specify an address space
when setting an invisible breakpoint. For kernel break-
points, we could specify the address space of any process as
the kernel space is mapped in the same way for any process.
We hence choose the address space of a long-lasting process
(init in Linux and System in Windows), so the breakpoint
will not be cleared due to process termination.
Monitor Process Creation. In practice, in addition to
debugging running programs, it is also desirable to have the
294
ability to get the control of a program at the moment when
it is just started. For example, when analyzing malware,
users often need to trap the execution at its entry point; if
the malware is already running, it would be too late to set
breakpoints. To meet such requirement, our front-end mon-
itors process creation events. We set invisible breakpoints at
related kernel functions to capture a newly created process
and match its name against the one speciﬁed by the user.
The user could get notiﬁed as soon as a process of the target
program is created, and perform corresponding actions such
as setting an invisible breakpoint at the entry point.
In Windows, a process is created through the NtCreatePro-
cessEx 1 system call, which calls the PspCreateProcess kernel
function to do the actual work. We set a breakpoint at the
instruction right after the call to PspCreateProcess. When
the breakpoint is triggered, we walk through the active pro-
cess list at PsActiveProcessHead to ﬁnd out the EPROCESS
of the newly created process. The name is stored in its Im-
ageFileName ﬁeld.
In Linux, there are two system calls fork and clone that
could be used to create a new process. They both call the
same function copy process to do the actual work, so we set a
breakpoint at the instruction right after the call. When the
breakpoint is triggered, the task struct of the newly created
task is in the EAX register as the return value. As clone
could also be called to create thread, we need to verify the
newly created task is a process by making sure its address
space identiﬁer (stored in task struct.mm->pgd ) is diﬀerent
from the one of the current task. The name is stored in the
task struct.comm ﬁeld.
Monitor Process Termination. When a process termi-
nates, all invisible breakpoints in its address space should be
cleared. We set invisible breakpoints at related kernel func-
tions to monitor process termination. When a terminating
process is captured, we use its address space identiﬁer to
check if it is one of our debuggee targets.
If so, we will
remove the target and clear all invisible breakpoints in it.
In Windows, we set the breakpoint at the entry of the
function PspProcessDelete, which handles cleanup when a
process terminates. When the breakpoint is triggered, we
read the ﬁrst argument of the function from the stack, which
is the EPROCESS structure of the process. The address
space identiﬁer is in its Pcb.DirectoryTableBase ﬁeld.
In Linux, we set the breakpoint at the entry of the function
do exit, which handles the termination of the current task.
However, the task could be a process or thread. We deter-
mine if the task is a process by checking if the task struct.pid
ﬁeld matches the task struct.tgid ﬁeld. The address space
identiﬁer is read from the task struct.mm->pgd ﬁeld.
The system call execve in Linux requires special handling.
Although it does not create or terminate a process, it changes
the program running in the current task. We consider that
both process “termination” and “creation” are involved in
this procedure: the current task which runs the previous
program is “terminated”, and one that loads the new pro-
gram is “created”. As execve calls do execve to do the actual
work, we set a breakpoint right before the function call to
capture the “terminated” current task, and another break-
point right after the call to capture the “created” one.
1Another system call NtCreateProcess for process creation
is a wrapper of NtCreateProcessEx.
6. EVALUATION
In this section, we present the evaluation of Spider. The
experiments are done on a Thinkpad T510 laptop with Intel
Core i7-3720QM 2.6GHz CPU and 8GB RAM. The host OS
is Ubuntu Linux 12.10 64-bit. We use Windows XP SP2
32-bit and Ubuntu Linux 12.04 32-bit as the guest OS. We
allocate 30GB hard disk and 1GB memory for the guest VM.
6.1 Transparency
Two groups of Windows programs with anti-debugging
and anti-instrumentation techniques are used to evaluate
the transparency of Spider. For comparison, we use Spi-
der, two debuggers (OllyDbg and IDA Pro) and two DBI
frameworks (DynamoRIO and PIN) to trap the execution of
these programs at certain locations. In Spider, the trapping
is done by setting invisible breakpoints. In the debuggers, we
use software or hardware breakpoints. The DBI frameworks
insert instrumentations at desired instructions for trapping.
The ﬁrst group of targets consists of 7 software protec-
tors, which are widely used by both COTS software vendors
and malware authors to protect their programs from be-
ing analyzed or modiﬁed. We apply these software protec-
tors to a system program hostname.exe in Window XP SP2.
This program reads and displays the host name of the local
system; our goal is to trap the execution of its protected
versions to get the host name string. We reverse-engineer
the original program and ﬁnd out the address of the host
name string is store in the eax register when the program
runs to the address 0x10011C6. This also holds in the pro-
tected versions, as this program does not contain relocation
information and could not be relocated by the protectors.
Hence, we set the traps at 0x10011C6 in the protected ver-
sions. However, for some of the protectors, we could not
set the trap when the program starts, as the instruction at
0x10011C6 is encrypted by the protectors and has not been
decrypted at that time. We hence set a data watchpoint at
0x10011C6 to monitor the decryption, and set the trap once
the instruction is decrypted.
We turn on all anti-debugging, anti-instrumentation and
anti-VM options of the protectors when using them. The
only exception is when we use Safengine Shielden, we turn
oﬀ its anti-VM option. With that option on, we found that
the program protected by Safengine Shielden would cease
to function even when we run it in vanilla KVM without
Spider; but it runs correctly in BitVisor, which is another
hardware virtualization based hypervisor. We hence con-
clude that the problem is due to the implementation of KVM
but not Spider.
The second group of targets includes 8 proof-of-concept
(POC) samples. Among these programs, eXait [30] aims at
detecting DBI frameworks. We randomly select 10 instruc-
tions in it for trapping. The rest 7 samples implement the
anti-debugging techniques commonly used in malware that
is not protected by protectors, according to the statistics
in [9]. Since these samples are very small (tens of instruc-
tions), we choose to trap every instruction in them.
The result is shown in Table 1. “Pass” indicates the pro-
gram runs properly and its execution is successfully trapped
at the desired location. “Fail” means the program fails to run
properly in the environment even without any trap. “Fail
HBP” and “Fail SBP” means the program fails to run prop-
erly after setting hardware breakpoint or software break-
point. We can see that OllyDbg and IDA Pro fail at every
295
Target
Spider OllyDbg 1.10
IDA Pro 6.1
DynamoRIO 4.0.1-1 PIN 2.12
Software Protectors (Applied to hostname.exe)
Pass
Safengine Shielden 2.1.9.0
Themida 2.1.2.0
Pass
PECompact 3.02.1 (w/ead loader) Pass
Pass
ASProtect 1.5
Pass
RLPack 1.21
Armadillo 9.60
Pass
Pass
tElock 0.98
Fail
Fail
Fail
Fail
Fail
Fail
Fail
Fail
Fail
Fail
Pass
Fail
Pass
Fail
Pass
Fail
Pass
Fail
Fail
Fail HBP/SBP Fail
Anti-debugging & Anti-instrumentation POC Samples
Fail
Pass
Pass
Pass
Pass
Pass
Fail
eXait
hardware bp.exe
heapﬂags.exe
instruction counting.exe
ntglobal.exe
peb.exe
rdtsc.exe
software bp.exe
Fail
Pass
Pass
Fail
Pass
Pass
Pass
Pass
Table 1: Transparency evaluation result of Spider and other debuggers/DBI frameworks.
Fail
Pass
Pass
Fail HBP
Pass
Fail
Fail
Fail HBP
Pass
Fail
Fail
Pass
Fail HBP/SBP Fail HBP/SBP Pass
Pass
Fail SBP
Pass
Fail
Fail
Fail HBP
Fail
Fail
Pass
Pass
Pass
Pass
Pass
Pass
Pass
Pass
Fail SBP
target except eXait; most targets could detect their exis-
tence even when no trap is set. DynamoRIO and PIN per-
form better, but are still detected by 5 and 4 targets, respec-
tively. Compared with them, Spider successfully maintains
transparency against all 15 targets; there are 3 targets that
could only be transparently trapped by Spider.
We also test Spider against techniques of detecting em-
ulators in [16, 17, 29], which we implement as individual
POC programs. We run them in Spider and trap every in-
struction in these programs as they are very short. As we
expected, none of them is able to detect Spider, as Spider
is built upon hardware virtualization.
6.2 Case Study I: Attack Provenance
In this case study, we demonstrate the use of Spider to
improve the tamper-resistance of an existing attack prove-
nance system BEEP [25]. Traditional attack provenance
approaches are based on analysis of system event log with
per-process granularity (i.e., each log entry pertains to one
process). Such approaches face the problem of dependency