When the bitrate of a video stream changes, the size of the video segment also
changes. For example, ads can be inserted into a video stream, and tracking this
change is an important indicator of the behavior of the video stream since the
ads can be encoded in diﬀerent bitrate.
Takeaway: Understanding the time taken to serve subsets of requests of the
same stream that share similar characteristics can reveal anomalous behavior in
diﬀerent dimensions, which is important for server-side QoE monitoring.
Request Arrival Times and Bitrate Changes
The behavior of the video player at the client plays an important role in how the
user experiences the video stream. Most common players employ Adaptive Bit
Rate (ABR) [1]. During playback, players try to estimate the achievable band-
width, i.e. which corresponding bitrate/quality can be achieved using the current
network conditions. When the available bandwidth drops, the ABR algorithm
drops the bitrate i.e., requests a subsequent video segment of a lower quality.
It is possible to understand how the client-side player perceives the connec-
tion by tracking when the request arrived and what bitrate the client requested.
We capture the request timing information in comparison to previous requests
on the same session by tracking the inter-arrival time of requests. In Fig. 4 we
show the Kernel Density Estimation (KDE) distribution of requests for a live
streaming provider over one day. We bucket each request into three bitrate types:
Low, Medium, and High. In most cases the request inter-arrival times are in the
order of few seconds, indicating normal player behavior where the player main-
tains suﬃcient video segments in the buﬀer to play next. However, we also notice
that in some cases, and more commonly when the used bitrate quality is low, the
SSQoE: Measuring Video QoE from the Server-Side
607
inter-arrival times can be high (greater than 30 s). To evaluate if the high inter-
arrival times correlate with change in bitrate, for each case where inter-arrival
times are higher than 12 s, we check if the current bitrate matches that of the
previous request of the same session. We chose the threshold of 12 s since the
particular provider examined here starts playback as soon as the player receives
a minimum of 12 s of video. We categorize the bitrate change into Same, Up, or
Down based on the direction of the quality change. We see that in more than
70% of the cases where inter-arrival times are high, the subsequent request is for
a lower quality segment (direction: Down). This shows that the player suﬀered
some delays and ABR reduced the quality of the video. ABR only switches qual-
ity to higher if it is sure the client will not see a negative impact. In about 20%
of the cases the direction of change in quality was Up, meaning even though the
inter-arrival times increased, the client may not have experienced a rebuﬀering
event.
Takeaway: The change in bitrate is a good metric to capture client player behav-
ior and to use as indication for client-perceived quality, but it is not enough by
itself to accurately estimate if the client experienced rebuﬀering.
4 Server-side Video QoE Measurement Methodology
Based on the takeaways from Sect. 3, in this section we present SSQoE: a server-
side QoE score calculation method that relies solely on CDN access logs, and
requires no other input from the client-side. The goal of this methodology is
to be content agnostic (it should work for any video customer at the CDN),
player agnostic (it should not make any assumptions about client video player
behavior), and to account for noise that is caused by millions of users connecting
to the platform as well as from video artifacts like quality change, ad breaks,
etc.
Information Needed from the CDN Access Logs
As our approach relies solely on the CDN access logs, we ﬁrst describe the
necessary ﬁelds that are extracted from the logs to perform this analysis. We
use three key pieces of information, a timestamp of when a client requested
a video asset, the segment ID (ﬁle/segment name) of the video asset, and a
session ID. We know the video length of the segments before hand, either via
a conﬁguration ﬁle or via estimations done using ffmpeg [3]. These ﬁelds are
easily available in most web server logs. In case of absence of explicit session
ID, a hash of the {client ip, user agent} tuple can be used. Hashing the tuple
obviates the need for IP-level tracking. Note the video asset segment ID usually
encodes the information of the bitrate. A full video such as a movie comprises
of many segments. Each segment is numbered incrementally, for example, A1.ts,
A2.ts, ... , etc. In this example let us say the ﬁrst letter is the quality type: A is
lowest, B is higher than A, C is higher than B, and so on. With this knowledge,
we look at requests from each client and check them in sequence. If their quality
changes, for example, A1.ts, B2.ts, A3.ts, we then add it to the rate of ﬂuctuation
metric.
608
A. Shah et al.
Player Buﬀer Estimation
To estimate if the client side video player ran out of video to play (i.e. suﬀered
rebuﬀering), we estimate the amount of video the player has in its buﬀer at
a given time. For every request received from a player, we add the respective
duration of video (in seconds) to the estimated buﬀer size. We note that the
segment length can change across segment types. For example, ad segments used
for server-side ad insertion can be shorter than main content video segments.
Therefore, for each session we have in memory the amount of video in the player’s
buﬀer. Every time we see a request for a segment of a session, we compare the
time diﬀerence between the previous request and current timestamp. Using this
information we can estimate how much video has been consumed. For example,
if at a given time the estimated buﬀer length for a client is 12 s, i.e. we estimate
that the player has 12 s of video available in its buﬀer, and the next request
is seen 15 s after the previous request, then we know that for at least for 3 s
the player must not have had any video to play. We refer to this as rebuﬀer
duration. With this approachs, without the need for any client-side beacons, we
can measure a key element that inﬂuences user’s QoE.
Calculating QoE Score
Estimating video rebuﬀer duration from the server-side provides the missing
piece needed to measure QoE without client-side participation. However, as
shown in the previous section, there are other metrics that prove to be useful.
First, video quality is a function of the bitrate. A higher average bitrate means
better video quality, and a better viewing experience. It has been shown before
that viewers tend to respond negatively to ﬂuctuations in bitrate and prefer
a constant bitrate [8]. Thus a constant lower bitrate impacts user engagement
less than many quality switches. A session can have low bitrate due its network
subscription package limits, device capabilities, etc. It is not accurate to count
every low bitrate session as lack or drop in QoE. Therefore, we keep track of jitter
in the bitrate i.e., the number of times the video stream changes its quality.
Second, we observed that in most cases the time taken to serve the requests
for a client remains fairly constant. We use this information to extract an average
time taken to serve a client in a time bin. We analyze this at per ASN or per User
Agent granularity to be able to compare similar clients. Any large ﬂuctuations
in average time taken metric is also a good indicator of anomalies.
Finally, we saw that for a stable video stream the player requests video
segments at a fairly constant rate from the server, when performance changes or
the player falls behind in a live stream it might request more segments to change
quality or catch up in a live stream. Any large ﬂuctuations in average requests
rate is also a good indicator of anomalies.
We deﬁne Rb, Tb, Bb, Ab to describe each metric, as described in Table 1.
These metrics represent aggregate information from all sessions in a time bucket
b. Equations 1–4 describe how each metric is calculated.
Rb =
(cid:2)total unique sessionsb
estimated rebuf f ering
bucket durationb ∗ total unique sessionsb
s=1
(1)
SSQoE: Measuring Video QoE from the Server-Side
609
Table 1. Deﬁnitions of metrics used for QoE score.
Metric Deﬁnition
Rb
Tb
Bb
Ab
Average estimated rebuﬀering ratio in bucket b
Average time taken to serve request in bucket b
Average bitrate drops in bucket b
Average requests per session in bucket b
(cid:2)total unique sessionsb
time taken
s=1
Tb =
(cid:2)total unique sessionsb
total unique sessionsb
number of bitrate drops
Bb =
s=1
total unique sessionsb
Ab =
total requestsb
total unique sessionsb
(2)
(3)
(4)
We track these metrics individually and calculate a derived anomaly indicator
score as well. We represent the QoE score at a given time bucket as a combination
of Rb, Tb, Bb, Ab (Eq. 5). We note that it is possible to add more dimensions to
our analysis to update the granularity of QoE score.
qoe scoreb = Rb ∗ Tb ∗ Bb ∗ Ab
(5)
Lower values are better for each dimension of QoE score. For example, a
good video stream should have lower estimated rebuﬀers, less time taken to
server requests, lower number of bitrate drops, etc. therefore higher values
of the QoE score represent anomalies. Having a single metric to track
QoE anomalies provides operational simplicity and a quick litmus test if further
analysis is needed. A single metric also simpliﬁes automated anomaly detection
and alerting, since standard techniques such as tracking changes (more than 3
standard deviations), cosine similarity, etc. can be easily used.
In this paper, we normalize the value of QoE score between 0 and 1 for
comparison with other monitoring metrics, by dividing each calculated value by
the maximum QoE score seen in a given time window. However, SSQoE tracks
the raw QoE score values and does not rely on this normalization; we simply do
this for easier representation and comparison of the results.
Detailed Algorithm to Extract Session Info
In Algorithm 1 we describe how SSQoE calculates the estimated rebuﬀering along
with the other metrics. For the sake of simplicity we present this method as one
procedure but our implementation comprises of optimizations that enable us
to perform such analysis at scale and at diﬀerent granularities, e.g. for diﬀerent
CDN customers, ASNs, user agents, etc. For each session, we extract all requests
(rs) seen in CDN logs. We initialize arrays ds, tts, Δts, bs to keep track of rebuﬀer
durations per request, time taken values per request, inter-arrival times between
610
A. Shah et al.
Algorithm 1. Extract Session Info
1: procedure extractSessionInfo(s)
2:
3:
in current bucket
rs ← Requests for session s sorted by time
ds ← array[] (cid:2) //Initialize array to store rebuﬀering duration for every timestamp seen
tts ← array[]
(cid:2) //Initialize array to store time taken to serve request
Δts ← array[]
(cid:2) //Initialize array to store inter-arrival times
bs ← array[]
(cid:2) //Initialize array to track bitrate changes
bsizes ← 0 (cid:2) //Initialize variable to track estimated video length in client player buﬀer
for each request rsi in rs do
(cid:2) //Track bitrate changes
segs ← Get segment ID from rsi URL
bsi ← comp(bsi , bs(i−1) )
if segswas requested before for session s then
Ignore duplicate requests for same segs
vlensi ← len(segs)
ttsi ← time taken to serve the request rsi
if i > 0 then
ti ← timestamp of request rsi
Δti ← ti − t(i−1)
bsizes ← bsizes − Δti
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
(cid:2) //Remove the time diﬀerence between requests from
if bsizes ¡ 0 then
← abs(bsizes) (cid:2) //Player rebuﬀered same amount as the gap detected
(cid:2) //Reset buﬀer length
estimated buﬀer length
in estimated buﬀer length
dsti
bsizes ← 0
bsizes ← bsizes + vlensi
ttsi ← moving average(tts(i−1) , ttsi )
return ds, tts, bs
subsequent requests, and bitrate changes per request for session s (Steps 1–6).
Duplicate requests are ignored, since from the server’s perspective same amount
of video will be available in the player buﬀer for two duplicate requests. For each
unique request received, for the session in current time bucket, we extract the
session ID, compare change in the bitrate from the previous request and ﬁnally
subtract the time diﬀerence between the current and previous request time from
our estimated client buﬀer, bsize (Steps 7–18). This describes the duration of
video that the client has already consumed. If a subsequent request of a session
does not arrive on time, bsize falls below zero, indicating a rebuﬀering event
(Steps 19–24). We extract all these metrics per session to be aggregated next.
Global Deployment
As mentioned in the previous paragraph, while the methodology can be described
as standalone process running on a server, our implementation of SSQoE lever-
ages the global scale of the CDN. Figure 5 describes an overview of our global
deployment. An edge service consumes CDN access logs for a given video provider
(a new instance is launched per video provider/customer). Each edge video QoE
SSQoE: Measuring Video QoE from the Server-Side
611
Fig. 5. Distributed log processing for live server-side QoE monitoring.
service only consumes logs for the past one minute from the same PoP as itself,
calculates the QoE score and exposes these metrics to a time-series monitoring
service at the CDN. Performing this computation at the edge locally per PoP
achieves two goals: 1) Get the QoE score as close to real-time as possible, which
is most beneﬁcial for live streams, and 2) Achieve redundancy. Operations at one
PoP does not aﬀect the QoE monitoring service at another PoP. This provides
resiliency in how we capture per PoP QoE anomalies.
5 Validation
In order to validate the methodology used by SSQoE we employ testbed consist-
ing of a server and client that we control, in order to compare the rebuﬀering
reported directly by the client to that measured by SSQoE using server-side logs.
We then also perform a detailed comparison between two weeks worth of client-
side beacon rebuﬀering data obtained from a large live sports video streaming
provider and the QoE estimates derived using SSQoE on the CDN during same