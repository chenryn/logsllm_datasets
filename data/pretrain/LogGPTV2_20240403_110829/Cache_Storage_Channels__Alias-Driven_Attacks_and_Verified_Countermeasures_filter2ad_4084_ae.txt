In order to enforce cacheability, the hypervisor would need to
enforce it on the ﬁrst stage of translation by intercepting the
page table setup of its guests, which creates an undesirable
performance overhead and undermines the idea of having two
independently operated stages of address translation.
4) W ⊕ X Policy
Unfortunately, enforcing cacheability of memory accesses
does not protect against the instruction-cache-based conﬁden-
tiality threat described earlier. In order to prevent an attacker
from storing incoherent copies for the same instruction address
in the memory system, the hypervisor would also need to
prohibit self-modifying code for the guests, i.e., ensure that all
guest pages are either writable or executable (W ⊕ X policy).
Since operating systems regularly use self-modiﬁcation, e.g.,
when installing kernel updates or swapping in pages,
the
association of pages to the executable or writable attribute
is dynamic as well and must be monitored by the hypervisor.
It also needs to ﬂush instruction caches when an executable
page becomes writable.
Overall, the solutions presented above seem to be more
suitable for paravirtualizing hypervisors, that are invoked by
the guests explicitly to conﬁgure their virtual memory. Adding
the required changes to the corresponding MMU virtualization
functionality seems straightforward. In fact, for the paravir-
tualizing hypervisor presented in this paper a tamper-proof
security monitor has been implemented and formally veriﬁed,
which enforces executable space protection on guest memory
and checks code signatures in order to protect the guests from
malicious code injection [12].
5) Always Cacheable Page Tables
the hypervisor against
To protect
the integrity threat a
lightweight specialization of the C ⊕ U policy introduced
above was implemented. It is based on the observation that
uncacheable aliases can only subvert
the integrity of the
hypervisor if they are constructed for the inputs of its MMU
virtualization functions. Thus the hypervisor needs only to
enforce the C⊕U policy, and consequently memory coherency,
on its inputs. While this can be achieved by ﬂushing the caches
appropriately (see Section V-C), a more efﬁcient approach
is to allocate the page tables of the guests in regions that
are always cacheable. These regions of physical memory
are ﬁxed for each guest and the hypervisor only validates
a page table for the guest
is allocated in this area.
In all virtual addresses mapping to the area are forced to
be cacheable. Obviously, also the guest system needs to be
if it
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:33 UTC from IEEE Xplore.  Restrictions apply. 
TABLE II
AES ENCRYPTION BENCHMARKS
AES encryption
Original SBoxes
Compact Last SBox
Scrambled Last SBox
Uncached Last SBox
Scrambled All SBoxes
Uncached All SBoxes
5 000 000 × 16B
Throughput
Time
3.317 MB/s
23s
3.179 MB/s
24s
30s
2.543 MB/s
2.119 MB/s
36s
0.578 MB/s
132s
152s
0.502 MB/s
10 000 × 8KB
Time
13s
16s
20s
26s
125s
145s
Throughput
6.010 MB/s
4.883 MB/s
3.901 MB/s
3.005 MB/s
0.625 MB/s
0.539 MB/s
AES encryption on Raspberry Pi 2 of one block (128 bits = 16 Bytes) and
512 blocks for different SBox layouts.
adapted to support the new requirement on the allocation of
page tables. However, given a guest system that was already
prepared to run on the original hypervisor,
the remaining
additional changes should be straight-forward. For instance,
the adaptation of the hypervisor example required changes to
roughly 35 LoC in the paravirtualized Linux kernel and an
addition of 45 LoC to the hypervisor for the necessary checks,
The performance of the hypervisor with always cacheable
page tables (ACPT) can be observed in Table I. Compared
to the original hypervisor there are basically no performance
penalties. In some cases the new version even outperforms
the original hypervisor, due to the ensured cacheability of
page tables. It turns out that in the evaluated Linux kernel,
page tables are not always allocated in cacheable memory
areas. The correctness of the approach is discussed in detail in
Section VI. The main veriﬁcation condition to be discharged
in a formal proof of integrity is that the hypervisor always
works on coherent memory, hence any correctness proof based
on a coherent model also holds in a more detailed model with
caches.
C. Repelling Alias-Driven Attacks
The countermeasures treated so far were aimed at restricting
the behaviour of the attacker to prevent him from harvesting
information from the cache channel or break memory co-
herency in an attack on integrity. A different angle to the
problem lies in focusing on the trusted victim process and
ways it can protect itself against an unrestricted attacker that
is allowed to break memory coherency of its memory and run
alias-driven cache attacks. The main idea to protect integrity
against such attacks is to (re)establish coherency for all mem-
ory touched by the trusted process. For conﬁdentiality, the idea
is to adapt the code of the victim in a way that its execution
leaks no additional information to the attacker through the
cache channel. Interestingly, many of the techniques described
below are suitable for both purposes, neutralizing undesirable
side effects of using the caches.
1) Complete Cache Flush
One of the traditional means to tackle cache side channels
is to ﬂush all instruction and data caches before executing
trusted code. In this way, all aliases in the cache are either
written back to memory (in case they are dirty) or simply
removed from the cache (in case they are clean). Any kind
of priming of the caches by the attacker becomes ineffective
since all his cache entries are evicted by the trusted process,
foiling any subsequent probing attempts using addresses with
mismatched cacheability. Similarly, all input data the victim
reads from the attacker’s memory are obtained from coherent
main memory due to the ﬂush, thus thwarting alias-driven
attacks on integrity.
A possible correctness proof that ﬂushing all caches elimi-
nates the information side channel would rely on the assertion
that, after the execution of the trusted service, an attacker will
always make the same observation using mismatched aliases,
i.e., that all incoherent lines were evicted from the cache.
Thus he cannot infer any additional knowledge from the cache
storage channel. Note, that here it sufﬁces to ﬂush the caches
before returning to the attacker, but to protect against the
integrity threat, data caches need to be ﬂushed before any
input data from the attacker is read.
For performance evaluation the ﬂushing approach was im-
plemented in the AES and hypervisor examples. At each
call of an AES encryption or hypervisor function, all data
and instruction caches are ﬂushed completely. Naturally this
introduces an overhead for the execution of legitimate guest
code due to an increased cache miss rate after calls to trusted
processes. At the same time the trusted process gets slowed
down for the same reason, if normally some of its data and
instructions were still allocated in the caches from a previous
call. Additionally the ﬂushing itself is often expensive, e.g.,
for ARM processors the corresponding code has to traverse
all cache lines in all ways and levels of cache to ﬂush them
individually. That all these overheads can add up to a sizeable
delay of even one order of magnitude is clearly demonstrated
by the benchmarks given in Tables II and I.
2) Cache Normalization
Instead of ﬂushing,
the victim can eliminate the cache
information side channel by reading a sequence of memory
cells so that the cache is brought into a known state. For
instruction caches the same can be achieved by executing
a sequence of jumps that are allocated at a set of memory
locations mapping to the cache lines to be evicted. In the
context of timing channels this process is called normalization.
If subsequent memory accesses only hit the normalized cache
lines, the attacker cannot observe the memory access pattern
of the victim, because the victim always evicts the same lines.
However the correctness of this approach strongly depends
on the hardware platform used and the replacement policy
of its caches. In case several memory accesses map to the
same cache line the normalization process may in theory evict
lines that were loaded previously. Therefore, in the veriﬁcation
a detailed cache model is needed to show that all memory
accesses of the trusted service hit the cache ways touched
during normalization.
3) Selective Eviction
The normalization method shows that cache side effects can
be neutralized without evicting the whole cache. In fact, it is
enough to focus on selected cache lines that are critical for
integrity or conﬁdentiality. For example, the integrity threat
on the hypervisor can be eliminated by evicting the cache
lines corresponding to the page table provided by the attacker.
4848
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:33 UTC from IEEE Xplore.  Restrictions apply. 
The ﬂushing or normalization establishes memory coherency
for the hypervisor’s inputs, thus making sure it validates the
right data. The method of selective ﬂushing was implemented
for the hypervisor scenario and benchmark results in Table
I show, as one would expect, that it is more efﬁcient than
ﬂushing the whole cache, but still slower than our specialized
ACPT solution.
To ensure conﬁdentiality in the AES example it sufﬁces
to evict the cache lines occupied by the SBoxes. Since the
incoherent entries placed in the same cache lines are removed
by the victim using ﬂushing or normalization, the attacker
subsequently cannot measure key-dependent data accesses to
these cache lines. For the modular exponentiation example
the same technique can be used, evicting only the lines in the
instruction cache where the code of the functions Mult and
ModReduce is mapped.
The correctness of selective eviction of lines for conﬁden-
tiality depends on the fact that accesses to other lines do not
leak secret information through the cache side channel, e.g.,
for the AES encryption algorithm lines that are not mapped
to an SBox are accessed in every computation, independent of
the value of the secret key. Clearly, this kind of trace property
needs to be added as a veriﬁcation condition on the code of
the trusted service. Then the classic conﬁdentiality property
can be established, that observations of the attacker are the
same in two computations where only the initial values of the
secret are different (non-inﬁltration [23]).
4) Secret-Independent Memory Accesses
The last method of eliminating the cache information side
channel is a special case of this approach. It aims to transform
the victim’s code such that it produces a memory access trace
that is completely independent of the secret, both for data
accesses and instruction fetches. Consequently, there is no
need to modify the cache state set up by the attacker, it will be
transformed in the same way even for different secret values,
given the trusted service receives the same input parameters
and all hidden states in the service or the cache model are part
of the secret information.
As an example we have implemented a modiﬁcation of
AES suggested in [51], where a 1KB SBox look-up table is
scrambled in such a way that a look-up needs to touch all
cache lines occupied by the SBox. In our implementation on
Raspberry Pi 2 each L1 cache line consists of 64 Bytes, hence
a 32bit entry is spread over 16 lines where each line contains
two bits of the entry. While the decision which 2 bits from
every line are used is depending on the secret AES key, the
attacker only observes that the encryption touches the 16 cache
lines occupied by the SBox, hence the key is not leaked.
Naturally the look-up becomes more expensive now because
a high number of bitﬁeld and shift operations is required to
reconstruct the original table entry. For a single look-up, a
single memory access is substituted by 16 memory accesses,
32 shifts, 16 additions and 32 bitﬁeld operations. The resulting
overhead is roughly 50% if only the last box is scrambled (see
Table II). This is sufﬁcient if all SBoxes are mapped to the
same cache lines and the attacker cannot interrupt the trusted
service, probing the intermediate cache state. Scrambling all
SBoxes seems prohibitively expensive though, slowing the
encryption down by an order of magnitude. However, since
the number of operations depends on the number of lines used
to store the SBox, if the system has bigger cache lines the
countermeasure becomes cheaper.
5) Reducing the Channel Bandwidth
Finally for the AES example there is a countermeasure
that does not completely eliminate the cache side channel,
but makes it harder for the attacker to derive the secret key.
The idea described in [51] is to use a more compact SBox
that can be allocated on less lines, undoing an optimization in
wolfSSL for the last round of AES. There the look-up only
needs to retrieve one byte instead four, still the implementation
word-aligns these bytes to avoid bit masking and shifting. By
byte-aligning the entries again, the table shrinks by a factor
of four, taking up four lines instead of 16 on Raspberry Pi
2. Since the attacker can distinguish less entries by the cache
line they are allocated on, the channel leaks less information.
This theory is conﬁrmed in practice where retrieving the AES
key required about eight times as many encryptions compared
to the original one. At the same time, the added complexity
resulted in a performance delay of roughly 23% (see Table II).
6) Detecting memory incoherency
A reference monitor (e.g. the hypervisor) can counter the
integrity threat by preventing the invocation of the critical
functions (e.g. the MMU virtualization functions) if memory
incoherency is detected. The monitor can itself use mis-
matched cache attributes to detect incoherency as follows. For
every address that is used as the input of a critical function, the
monitor checks if reading the location using the cacheable and
non-cacheable aliases yield the same result. If the two reads
differs, then memory incoherency is detected and the monitor
rejects the request, otherwise then request is processed.
D. Hardware based countermeasures
The cache-based storage channels rely on misbehaviour
of the system due to misconﬁgurations. For this reason, the
hardware could directly take care of them. The vector based
on mismatched cacheability attributes can be easily made
ineffective if the processor does not ignore unexpected cache
hits. For example, if a physical address is written using a non-
cacheable alias, the processor can invalidate every line having
the corresponding tag. Virtually indexed caches are usually
equipped with similar mechanisms to guarantee that there can
not be aliases inside the cache itself.
Hardware inhibition of the vector that uses the instruction
cache can be achieved using a snooping mechanism that
invalidates instruction cache lines whenever self-modiﬁcation
is detected, similar to what happens in x64 processors. In
architectures that perform weakly ordered memory accesses
and aggressive speculative execution, implementing such a
mechanism can become quite complex and make the out-
of-order execution logic more expensive. There is also a
potential slow-down due to misspeculation when instructions
are fetched before they are overwritten.
4949
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:33 UTC from IEEE Xplore.  Restrictions apply. 
Overall, the presented countermeasures show that a trusted
service can be efﬁciently secured against alias-driven cache
attacks if two properties are ensured: (1) for integrity, the
trusted service may only accesses coherent memory (2) for
conﬁdentiality, the cache must be transformed in a way such
that the attacker cannot observe memory accesses depending
on secrets. In next section, a veriﬁcation methodology pre-
sented that aims to prove these properties for the code of the
trusted service.
VI. VERIFICATION METHODOLOGY
The attacks presented in Section IV demonstrate that the
presence of caches can make a trustworthy, i.e. formally ver-
iﬁed, program vulnerable to both conﬁdentiality and security
threats. These vulnerabilities depend on the fact that for some
resources (i.e. some physical addresses of the memory) the
actual system behaves differently from what is predicted by
the formal model: we refer to this misbehaviour as “loss of