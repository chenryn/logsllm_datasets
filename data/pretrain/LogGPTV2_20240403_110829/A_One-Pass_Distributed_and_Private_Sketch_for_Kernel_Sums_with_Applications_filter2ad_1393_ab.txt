this paper, we set β = 0, which is simply called “ϵ-differential
privacy.” The Laplace mechanism [15] is a general method to satisfy
ϵ-differential privacy. By adding zero-mean Laplace noise to a real-
valued function, we obtain differential privacy if the noise is scaled
based on the sensitivity of the function (Definition 2.2).
Definition 2.2. Sensitivity [15] For a function A : D → Rd, the
L1-sensitivity of A is
∆ = sup ||A(D) − A(D′)||1
where the supremum is taken over all neighboring datasets D and
D′
Theorem 2.3. Laplace Mechanism [15] Let A : D → Rd be a
non-private function with sensitivity ∆ and let z ∼ Lap(∆/ϵ)d (d-
dimensional i.i.d Laplace vector). Then the function A(D) + z provides
ϵ-differential privacy.
2.2 Related Work
There are several existing techniques to release the kernel sum fD.
Table 1 compares these methods based on approximation error and
computational complexity. A common approach is to decompose
fD into a set of weighted basis functions using standard methods
from function approximation theory [46]. To create a private rep-
resentation of the function, we truncate the basis expansion to m
terms and represent fD as a set of weights in Rm. The weights can
then be released via the Laplace mechanism and used to construct a
private version of fD. The main theoretical difficulty lies in bound-
ing the sensitivity of the weights; once this is done, the algorithm
is straightforward.
Basis Expansion: Each basis term in the representation in-
creases the quality of the approximation but degrades the quality
of the weights, since the privacy budget ϵ is shared among the m
weights. This is a bias-variance tradeoff: we trade variance in the
form of Laplace noise with bias in the form of truncation error. The
Fourier basis [22], Bernstein basis [3], trigonometric polynomial
basis [45] and various kernel bases have all been used for private
function release. Because they all internally rely on function approx-
imation, all basis expansion mechanisms share similar properties.
For example, they are most effective when fD is a smooth func-
tion because fewer basis terms are needed to approximate smooth
curves. They also tend to be computationally infeasible in high
dimensions because function approximation suffers from the curse
of dimensionality.
Functional Data Analysis: An alternative set of techniques
rely on either functional data analysis [31] or synthetic databases [5,
23]. In [31], the authors use densities over function spaces to re-
lease a smoothed approximation to fD. By representing the sum
fD as an average over a set of kernels k(x, q) drawn from a distribu-
tion, we turn the task of representing fD into the well-established
problem of privately releasing distribution statistics. The key in-
sight from [31] is that we can efficiently release the mean with
(ϵ, β)-differential privacy.
Synthetic Databases: The main idea of [23] and [5] is to release
a set of weighted synthetic points that can be used in place of the
original dataset to estimate fD. While many synthetic database
algorithms exist, we focus on ones that are designed to minimize
the error of the privately released function fD. For example, [23]
provides theoretical error bounds that hold for a finite number of
evaluations of fD. The kernel mean embedding algorithm from [5]
attempts to release synthetic points with minimal distance to the
true dataset in a kernel embedding space. Optimizing the kernel
embedding distance is very similar to preserving the kernel density,
since the kernel mean embedding is a smoothed version of the KDE.
Synthetic databases may also be generated by privately training
a machine learning model, such as a generative adversarial net-
work (GAN), to reproduce the data. Methods such as DP-GAN [48]
and DP-cGAN [39] can be effective in practice, but require many
Session 12A: Applications and Privacy of ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3254iterations through the data to train and do not provide statistical
guarantees on the quality of the generated data.
Private Sketches: Finally, sketching is a well-established ap-
proach to both scalable machine learning and differential privacy.
A large class of sketching algorithms deal with numerical linear
algebra problems, where the sketch is created by projecting the
dataset with a random matrix [47]. These techniques form the basis
for differentially private linear regression [34], low rank approxima-
tion [41], and many other linear problems. Another class of private
sketches solve discrete problems, such as identifying frequent items
from a data stream [38].
The practice of adding noise to a sketch to obtain privacy is
a very well-established idea that has been applied to the Count-
Min Sketch, the HyperLogLog sketch, the AMS sketch, and many
other popular sketches. Clever extensions to these algorithms have
enabled numerous advances in areas such as federated learning.
For example, the algorithm in [27] uses a private Count-Min Sketch
to estimate the average gradient over a set of users. The FetchSGD
algorithm uses a Count Sketch for a similar purpose [33]. However,
sketching algorithms such as the Count Sketch deal with highly
specific tasks that are insufficient for the general problem of private
function release. It should be noted that there is no private sketch
that can address this problem. Existing sketches do not preserve
enough information to answer an unlimited set of function queries,
and existing solutions for private function release do not provide
the computational efficiency afforded by a sketching algorithm.
2.3 Locality-Sensitive Hashing
LSH Functions: An LSH family F is a family of functions l(x) :
Rd → Z with the following property: Under l(x), similar points
have a high probability of having the same hash value. We say that
a collision occurs whenever two points have the same hash code,
i.e. l(x) = l(y). In this paper, we use a slightly different definition
than the original [24] because we require the collision probability
at all points.
Definition 2.4. We say that a hash family F is locality-sensitive
with collision probability k(·,·) if for any two points x and y in
Rd, l(x) = l(y) with probability k(x, y) under a uniform random
selection of l(·) from F .
LSH Kernels: When the collision probability k(x, y) is a mono-
tone decreasing function of the distance metric dist(x, y), one can
show that k is a positive semidefinite kernel function [12]. We say
that a kernel function k(x, y) is an LSH kernel if it forms the collision
probability for an LSH family. For a kernel to be an LSH kernel, it
must obey the conditions described in [9]. A number of well-known
LSH families induce useful kernels [21]. For example, there are LSH
kernels that closely resemble the cosine, Laplace and multivariate
Student kernels [12].
2.4 RACE Sketch
LSH kernels are interesting because there are efficient algorithms
to estimate the quantity
fD(q) = 
x∈D
k(x, q)
when k(x, q) is an LSH kernel. In [12], the authors present a one-
pass streaming algorithm to estimate kernel density sums, a special
case of fD. The algorithm constructs a RACE (Repeated Array of
Count Estimators) sketch SD ∈ ZR×W , a 2D array of integers that
we index using LSH functions. This array is sufficient to report
fD(q) for any query q ∈ Rd. We begin by constructing R functions
{l1(x), ...lR(x)} from an LSH family F with the desired collision
probability. When an element x arrives from the stream, we hash
x to get R hash values, one for each row of SD. We increment
row i at location li(x) and repeat for all elements in the dataset. To
approximate fD(q), we return the mean of SD[r , lr(q)] over the
R rows. This streaming algorithm produces an efficient mergeable
summary that approximates the kernel density estimate for all
possible queries in a single pass.
To prove rigorous error bounds, observe that each row of SD is
an unbiased estimator of fD. The main theoretical result of [12] is
stated below as Theorem 2.5.
Theorem 2.5. Unbiased RACE Estimator[12] Suppose that X is
the query result for one of the rows of SD. That is, X = SD[r , lr(q)]
E[X] = fD(q)
var(X) ≤(cid:16) ˜fD(q)(cid:17)2
=
(cid:33)2
k(x, q)
(cid:112)
(cid:32)
x∈D
3 PRIVATE SKETCHES WITH RACE
We propose a private version of the RACE sketch.2 We obtain ϵ-
differential privacy by applying the Laplace mechanism to each
count in the RACE sketch array. Algorithm 1 introduces a differ-
entially private method to release the RACE sketch, illustrated in
Figure 1. It is straightforward to see that Algorithm 1 only requires
O(N R) hash computations. Assuming fixed R, we have O(dN) run-
time. Algorithm 2 shows how to query the sketch. The query algo-
rithm uses the fact that for row r of the array, the value of column
lr(q) is an unbiased estimator of fD(q). Algorithm 2 simply aver-
ages R of these estimators. Since many practical applications divide
fD by N , the number of elements in the private dataset, we also
estimate N directly from the private sketch. Note that this normal-
ization step is optional and does not affect privacy. To provide a
theoretical comparison with the methods in Table 1, we omit the nor-
malization from our analysis. We also analyze the median-of-means
estimate [4] rather than the mean, because the median-of-means
procedure allows us to prove exponential concentration around fD
without any assumptions.
Although the Laplace mechanism is a standard and well-known
method to achieve differential privacy for count data, the error
bounds and practical performance of Algorithms 1 and 2 are com-
parable to those of specialized privacy mechanisms such as the
Bernstein mechanism [3]. To better understand the tradeoffs of our
method, we provide a precise (non-asymptotic) theoretical quantifi-
cation of the estimation error in terms of the privacy budget and
the characteristics of fD.
3.1 Privacy
We begin by proving that the sketch returned by Algorithm 1 is
indeed ϵ-differentially private. We view Algorithm 1 as a function
2From this point onward, we use the term “RACE” to refer to our private version.
Session 12A: Applications and Privacy of ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3255Input: Dataset D, privacy budget ϵ, LSH family F , dimensions
R × W
Output: Private sketch SD ∈ ZR×W
Initialize: R independent LSH functions {l1, ..., lR} from the
LSH family F
SD ← 0R×W
for x ∈ D do
for r in 1 to R do
Increment SD[r , lr(x)]
end for
end for
SD = ⌊SD + Z⌋ where Z
iid∼ Lap(Rϵ−1)
Proof. Consider one of the W counters in the row. This counter
has sensitivity ∆ = 1 because adding or removing a single element
from the dataset can only create a change of ±1 in the counter.
Therefore, we can add Laplace noise Lap(1/ϵ) to release the count
with ϵ-differential privacy. Suppose we independently do this to
release all W counters. The parallel composition theorem [17] states
that if each counter is computed over a disjoint subset of the dataset,
then we can release all of the counters with ϵ-differential privacy.
This is indeed the case because each element in the dataset maps to
exactly one of the W counters under the LSH function. Thus, the
W noisy counters are computed on disjoint subsets and we can add
Laplace noise Lap(1/ϵ) to release the row.
□
Figure 1: Illustration of Algorithm 1 for SD ∈ Z3×6. We hash each element in the stream with LSH functions {l1, l2, l3} ∈ F
having collision probability k(x, y). In this example, l1(xi) = 3, l2(xi) = 2 and l3(xi) = 6. We increment the highlighted cells. The
addition of the Laplace noise is not shown in the figure, but is done by perturbing each count in SD.
Algorithm 1 Private RACE sketch
Lemma 3.1. Consider one row of the RACE sketch, and add in-
dependent Laplace noise Lap(1/ϵ) to each counter. The row can be
released with ϵ-differential privacy.
Algorithm 2 RACE query
fD(q)
Input: Sketch SD, query q, the same R LSH functions from
Algorithm 1
Output: Estimate of N−1
ˆfD ← 0
for r in 1 to R do
ˆfD = ˆfD + 1
i, j SD[i, j] (optional normalization step)
R SD[r , lr(q)]
(cid:98)N ← R−1
Return: ˆfD/(cid:98)N
end for
A : D → RR×W that takes in a dataset and outputs an R×W RACE
sketch. The codomain of A is the set of all RACE sketches with R
rows and W columns.
Proof Sketch: The sketch SD consists of R independent rows.
We can think of each row as a differentially private histogram over
the set of hash values for the dataset [49]. Lemma 3.1 shows that
we can privately release one of the rows by adding Laplace noise
with variance ϵ−1 (i.e. sensitivity ∆ = 1). Then, we repeatedly apply
Lemma 3.1 with a budget of ϵ/R to release all the rows, proving
the theorem.
Figure 2: Visualization of non-private (left) and private
(right) sketch-based KDE. Note the distinct boundaries be-
tween regions that map to different locations and counts
in the array. In Rd , RACE approximates functions with
a piecewise-constant spline over random partitions. The
Laplace mechanism perturbs the value of each partition.
Theorem 3.2. For any R > 0, W > 0, and LSH family F , the
output of Algorithm 1, or the RACE sketch SD, is ϵ-differentially
private.
Session 12A: Applications and Privacy of ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3256Proof. The sketch is composed of R independent rows. The
sequential composition theorem [17] states that given R mecha-
nisms M1, ...MR (one to release each row) which are indepen-
dently ϵ-differentially private, we can compute all the mechanisms
(i.e. release all rows) with Rϵ-differential privacy. To construct the
sketch, we apply Lemma 3.1 to each row with ϵ/R differential pri-
vacy by adding independent Laplace noise Lap(R/ϵ) to each counter.
Therefore, the sketch is ϵ-differentially private by the sequential
composition theorem.
□
3.2 Utility
Given a sufficiently good estimate of fD, one can easily construct
many different learning algorithms [3]. Therefore, we focus on
utility guarantees that bound the pointwise error of the private
RACE estimate for fD(q). Since the sketch is a simple collection of
R unbiased estimators, our proof strategy is to bound the deviation
between the estimate and the mean. This is done by bounding the
relative variance of the estimate and applying the median-of-means
concentration technique. We briefly reproduce the technique here.
Note that Lemma 3.3 is a special case3 of Theorem 2.1 from [4].
Lemma 3.3. Let X1, ...XR be R i.i.d. random variables with mean
E[X] = µ and variance ≤ σ
2. To get the median of means estimate ˆµ,
break the R random variables into k groups with m = R/k elements
in each group.
ˆµ = median(cid:169)(cid:173)(cid:171) 1
m
m
i =1
km
Xi(cid:170)(cid:174)(cid:172)
Xi , ...,
1
m
i =(k−1)m+1
Put k = 8 log(1/δ) and m = R/k. Then with probability at least
1 − δ, the deviation of the estimate ˆµ from the mean µ is
(cid:114)
| ˆµ − µ| ≤
32σ
2 log(1/δ)
R
Lemma 3.3 requires a bound on the variance of the private RACE
estimator, which we obtain by adding the independent Laplace
ϵ−2 to the bound from Theorem 2.5. Theorem 3.4
noise variance 2R
follows.
2
Theorem 3.4. Let ˆfD(q) be the median-of-means estimate using
an ϵ-differentially private RACE sketch with R rows and ˜fD(q) =