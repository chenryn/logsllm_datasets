为了提供一些基础，如果不是共同点的话，接下来是一个大纲，它可以被看作是符合*微服务*标签的架构的共同特征。应该理解的是，并不是所有的微服务架构都会在任何时候都表现出所有的特性。然而，由于我们确实期望大多数微服务体系结构会表现出这些特性中的大部分，所以让我们列出它们:
*   自主的
*   无国籍的
*   异步的
*   单一责任
*   松散耦合
*   可互换的
### 微服务的优势
我们刚刚列出的微服务的共同特征也有助于详细说明它们的优势。我们无意过多赘述这个问题，但至少让我们讨论一下主要的优点:
*   **微服务实现了一定程度的模块化**:这在实践中很难通过单一架构来实现。微服务的优势在于，单个服务的开发速度更快，更容易理解，也更容易维护。
*   **微服务使每个服务能够独立开发**:这是由专门关注该服务的团队完成的。微服务的优势是赋予开发人员选择最适合或更有意义的技术的自由，只要该服务遵守应用编程接口合同。默认情况下，这也意味着开发人员不再被项目开始时或开始新项目时可能过时的技术所困。不仅存在使用当前技术的选项，而且在相对较小的服务规模下，使用更相关和更可靠的技术重写旧服务现在也是可行的。
*   **微服务使每个服务都可以连续部署**:开发人员不需要协调本地化到他们服务的变更的部署。微服务的优势在于持续部署——一旦成功测试了变更，就会立即进行部署。
*   **微服务使每个服务能够独立扩展**:您只需要部署满足容量和可用性限制所需的每个服务的实例。此外，我们还可以简洁地匹配硬件以满足服务的资源需求(例如，针对 CPU 和内存密集型服务的计算或内存优化硬件)。微服务的优势不仅在于匹配容量和可用性，还在于利用针对服务优化的用户特定硬件。
所有这些优点都是非常有利的，但是接下来让我们详细说明一下可伸缩性。正如我们所看到的单片架构，虽然容易初始化扩展，但随着时间的推移，它在执行上肯定有缺陷；瓶颈比比皆是，最终，it 的扩展方法完全站不住脚。幸运的是，微服务作为一种架构风格，在扩展方面非常出色。一本经典的书《可伸缩性的艺术》([http://theartofscalability.com/](http://theartofscalability.com/))展示了一个非常有用的三维可伸缩性模型，它位于*比例立方体*([http://microservices.io/articles/scalecube.html](http://theartofscalability.com/))。
### 可扩展性方面的微服务
在所提供的模型中，沿着 X 轴扩展(即 Monolothic)，我们可以看到常见的水平复制方法，通过在负载平衡器后面运行应用的多个克隆副本来扩展该应用。这将提高应用的容量和可用性。
![Microservices at scalability](img/image_04_004.jpg)
可扩展性方面的微服务
沿着 Z 轴移动进行扩展(即 N 层/SOA)，每个服务器运行相同的代码副本(类似于 X 轴)。这里的区别在于，每个服务器只负责数据的一个严格子集(也就是说，通过拆分成相似的东西来进行数据分区或扩展)。因此，系统的给定组件负责将给定的请求路由到适当的服务器。
### 注
**分片**是一种常用的路由标准，其中请求的属性用于将请求路由到特定的服务器(例如，行的主键或客户的身份)。
正如 X 轴扩展一样，Z 轴扩展有助于提高应用的容量和可用性。然而，正如我们在本章中了解到的，单片或 N 层方法(X 轴和 Y 轴扩展)都不能解决我们不断增加的开发和应用复杂性的固有问题。为了有效地处理这些问题，我们需要应用 Y 轴伸缩(即微服务)。
缩放的第三个维度(Y 轴)涉及功能分解，或者通过拆分成不同的东西来缩放。在应用层，Y 轴扩展将把一个单一的应用分割成独立的服务集，其中每个服务实现一组相关的功能(例如，客户管理、订单管理等)。在本章的后面，我们将直接研究服务的分解。
我们通常可以看到的是同时利用缩放立方体的所有三个轴的应用。y 轴扩展将应用分解成微服务；在运行时，X 轴缩放在负载平衡器后面执行每个服务的多个实例，以增强输出和可用性，一些应用可能会另外使用 Z 轴缩放来划分服务。
### 微服务的缺点
通过了解微服务的一些缺点，让我们在此进行全面的尽职调查:
*   **部署基于微服务的应用要复杂得多**:与单体应用相比，微服务应用通常由大量服务组成。事实上，我们在部署它们时有更大的复杂性。
*   **微服务的管理和编排要复杂得多**:大量服务中的每个服务都将有多个运行时实例。需要配置、部署、扩展和监控的移动部件数量呈指数级增长。因此，任何成功的微服务部署都需要开发人员对部署方法进行更精细的控制，并结合高水平的自动化。
*   **测试微服务应用要复杂得多**:为微服务应用编写测试类不仅需要启动该服务，还需要启动其依赖服务。
一旦了解，我们就可以制定策略和设计来减轻这些缺点，并更好地规划故障排除领域。
### 设计微服务的考虑因素
我们回顾了从单一交付到多层再到容器化微服务的突破，并了解到每种服务都有自己的应用功能。每个架构都有自己的有效程度；这些架构的适当设计策略和应用对于您的部署成功是必要的。了解了单块式、N 层式和微服务的基本原则后，我们可以更好地根据每个用例从战略上实施最适合的体系结构。
![Considerations for devising microservices](img/Untitled-3.jpg)
从单声道到微型
微服务架构模式是复杂的、不断发展的应用的更好选择，尽管存在缺陷和实现挑战。为了将微服务用于现代云和 web 应用设计和部署，我们如何最好地利用微服务的优势，同时减轻潜在的缺点？
无论是开发新的应用还是更新旧的应用，微服务都必须考虑这些因素:
*   构建和维护高度可用的分布式系统是复杂的
*   更多的活动部件意味着需要跟踪更多的组件
*   松散耦合的服务意味着需要采取措施来保持数据的一致性
*   分布式异步进程会造成网络延迟和更多的应用编程接口流量
*   测试和监控单个服务具有挑战性
#### 减轻劣势
这可能是整本书提供的最简单的说明；然而，我们一次又一次地目睹了显而易见的事情，要么被完全忽视，要么被忽视，要么被低估。我们在此提出的意见是，尽管存在相对较少但已知的缺点，但存在解决几乎所有这些问题的现有和不断发展的机制；人们强烈期望容器市场将为当前问题发展出大量可行的解决方案。
同样，让我们从最基本的元素开始，作为成功的微服务应用的基础，这些应用需要较少的故障排除:
*   **获得全部所有权**:如果没有获得全部所有权，并且知道最终的成功直接取决于你和你的团队，那么你的项目及其产生的应用将会受到影响。承诺、奉献和坚持会带来丰厚的回报。
*   **形成完整的理解**:完全理解业务目标是什么，以及哪些技术可以最好地应用于实现这些目标，更不用说*如何*和*为什么*使用它们了。永远在学习！
*   **追求详尽、协调的规划**:战略规划，与其他应用涉众一起规划，针对失败进行规划，然后再规划一些；衡量你的结果并修改计划，连续重新评估计划。永远在衡量，永远在计划！
*   **利用当前技术**:在当今的技术气候下，利用好最稳定、功能最强的工具和应用势在必行；所以，找到他们。
*   **随着应用**进化:你必须像你正在使用的容器技术一样敏捷和适应性强；改变必须是你详尽的、协调的计划中被接受的一部分！
太好了。我们知道，我们不仅必须承认，而且必须积极参与我们的应用项目过程的最基本的元素。我们也知道并理解微服务架构方法的优点和缺点，这些优点有可能远远超过任何缺点。除了前面五个强大的项目之外，我们如何减轻这些缺点，以利用微服务为我们带来的好处？
## 管理微服务
此时，你可能会问自己“那么，Docker 在这场对话中处于什么位置？”我们的第一个半开玩笑的回答是，它确实非常适合！
Docker 非常适合微服务，因为它将容器隔离到一个流程或服务中。单个服务或流程的这种有意的容器化使得管理和更新这些服务变得非常简单。因此，Docker 之上的下一波浪潮导致了专门用于管理更复杂场景的框架的出现也就不足为奇了，包括如下:
*   如何管理集群中的单个服务？
*   如何跨主机管理服务中的多个实例？
*   如何在部署和管理层面协调多个服务？
正如在一个成熟的容器市场中所预期的那样，我们看到随着开源项目出现了额外的补充工具，例如 Kubernetes、MaestroNG 和 Mesos 等等，所有这些都是为了解决 Docker 容器化应用的管理、编排和自动化需求而出现的。例如，Kubernetes 是一个专门为微服务构建的项目，与 Docker 配合得非常好。Kubernetes 的关键特性直接迎合了微服务体系结构中非常必要的特性——通过 Docker 轻松部署新服务、服务的独立扩展、终端客户端对故障的透明性，以及简单的、基于名称的服务端点发现。此外，Docker 自己的原生项目——Machine、Swarm、Compose 和 Orca，虽然在撰写本文时仍处于测试阶段，但看起来非常有希望——很可能很快会被添加到 Docker 核心内核中。
由于我们稍后将把示例和讨论献给 Kubernetes、其他第三方应用，并把整整一章献给 Docker Machine、Swarm 和 Compose，让我们在这里看一个例子，利用我们之前使用的服务(NGINX、Node.js)以及 Redis 和 Docker Compose。
### 真实世界的例子
nginx > node . js > redis >复合 Docker
```
# Directly create and run the Redis image 
docker run -d -name redis -p 6379:6379 redis 
## Node Container 
# Set the base image to Ubuntu 
FROM ubuntu 
# File Author / Maintainer 
MAINTAINER John Wooten @CONSULTED  
# Install Node.js and other dependencies 
RUN apt-get update && \ 
        apt-get -y install curl && \ 
        curl -sL https://deb.nodesource.com/setup | sudo bash - && \ 
        apt-get -y install python build-essential nodejs 
# Install nodemon 
RUN npm install -g nodemon 
# Provides cached layer for node_modules 
ADD package.json /tmp/package.json 
RUN cd /tmp && npm install 
RUN mkdir -p /src && cp -a /tmp/node_modules /src/ 
# Define working directory 
WORKDIR /src 
ADD . /src 
# Expose portability 
EXPOSE 8080 
# Run app using nodemon 
CMD ["nodemon", "/src/index.js"] 
## Nginx Containers build 
# Set nginx base image 
FROM nginx 
# File Author / Maintainer 
MAINTAINER John Wooten @CONSULTED  
# Copy custom configuration file from the current directory 
COPY nginx.conf /etc/nginx/nginx.conf 
## Docker Compose 
nginx: 
build: ./nginx 
links: 
 - node1:node1 
 - node2:node2 
 - node3:node3 
ports: 
- "80:80" 
node1: 
build: ./node 
links: 
 - redis 
ports: 
 - "8080" 
node2: 
build: ./node 
links: 
 - redis 
ports: 
- "8080" 
node3: 