point to different functions for different threads at runtime.
Therefore, the number of threads that execute the same func-
tion is low, and hence BLOCKWATCH does not have enough
threads to compare at runtime. Second, BLOCKWATCH uses
the outer loops’ iteration numbers to generate the hash table
key for a branch (Section III-B). However, due to overhead
considerations, we choose to only check the branches whose
nesting levels are smaller than six. In other words, any branch
that occurs in loops deeper than six levels of nesting is not
checked by BLOCKWATCH. Raytrace has many loops deeper
than six levels of nesting which are not checked.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:23 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 8.
by BLOCKWATCH. Higher is better.
coverageoriginal (baseline) and coverageBLOCKWATCH (aggregated number) for branch-ﬂip faults: The dark part is due to the detection provided
2) Coverage results for branch-condition faults: Figure 9
shows the results of coverage of the seven programs both
with and without BLOCKWATCH, when faults are injected into
the branch’s condition data. The results are similar to those
in Figure 8. For example, when BLOCKWATCH is used, the
coverage increases from 90% to 97% for both the 4-thread
and 32-thread cases. However, the average coverageoriginal
value is 90%, which is much higher than the coverageoriginal
for branch-ﬂip faults (average 83%). This is because unlike
branch-ﬂip faults, branch-condition faults may or may not
cause the branch to ﬂip, and branch ﬂips are more likely to
lead to SDC in the programs.
VI. DISCUSSION
In this section, we compare the error-detection coverage
and performance overhead of BLOCKWATCH with that of
software-based duplication. Duplication is a general technique
that can protect programs from a large class of errors. How-
ever, we focus on control-data errors in this section as this is
the focus of BLOCKWATCH.
Coverage: Our results show that BLOCKWATCH improves
the SDC coverage of the SPLASH-2 programs under both
branch-ﬂip faults and branch-condition faults. Other than ray-
trace, all programs have a coverage value between 98% and
100% for errors in the control data. This indicates that when
the program is protected with BLOCKWATCH, the percentage
of SDCs is less than 2% for 6 of the 7 programs. To our
knowledge, duplication is the only other generic technique that
can provide near 100% coverage for SDCs. However, it has
other disadvantages (see below).
The coverage results can be improved in several ways: for
example, we use a fairly conservative method to classify the
branches’ category in this study, the result of which is that
there are some branches that may have runtime similarities but
are not checked by BLOCKWATCH. Therefore, it is possible
to improve the coverage of BLOCKWATCH by using a more
aggressive static analysis or by incorporating the program’s
dynamic information in the classiﬁcation of the branches.
Performance:
The average performance overhead of
BLOCKWATCH is 115% for 4 threads and 16% for 32 threads.
In contrast, software-based duplication incurs overheads of
200% to 300% for sequential programs [10]. Although this
overhead can be reduced through the use of speculative
optimizations, doing so is not straightforward for parallel
programs due to their non-determinism. Thus, the overhead
of BLOCKWATCH is comparable to that of software-based
duplication in the 4-thread case, but is almost an order of
magnitude lower in the 32-thread case.
Further, BLOCKWATCH is scalable while duplication is not.
This is because duplication requires program determinism,
which may not hold for parallel programs. This problem can
be solved by using determinism inducing techniques [21],
[22]. However, determinism inducing techniques require the
replica threads and the programs’ threads to follow the same
execution order. Forcing execution order among threads incurs
communication and waiting overheads that are proportional to
the number of threads in the program, and does not scale. In
contrast, BLOCKWATCH scales as it neither requires program
determinism nor locking.
BLOCKWATCH can be optimized to further reduce its over-
head. For example, our current implementation adds checks for
every branch that is eligible for checking. However, there may
be many branches that depend on the same set of variables, and
faults propagating to the data will affect all of them. Therefore,
it is sufﬁcient to check one of the branches.
As we scale BLOCKWATCH to higher numbers of threads,
it is possible that the monitor itself becomes a bottleneck. To
alleviate this, we can have multiple monitor threads structured
in a hierarchical fashion, each of which is assigned to a sub-
group of threads. This is an avenue for future work.
VII. RELATED WORK
We classify related work into six broad categories. Because
we discuss duplication in detail in Section VI, we do not
consider it here.
Control-ﬂow checking: Control-ﬂow Checking (CFC) tech-
niques such as ECCA [23], PECOS [24] and CFCSS [25]
check the conformance of the program’s control-ﬂow to its
static control ﬂow graph. However, CFC techniques cannot
detect errors that propagate to the control data and lead to
a valid but incorrect branch outcome, i.e., control-data errors
that result in the branch going the other way than its error-free
behavior. BLOCKWATCH detects this class of errors.
Statistical
techniques: AutomaDeD [11] uses Semi-
Markov Models (SMMs) to ﬁnd parallel
tasks that devi-
ate from other tasks’ behavior. AutomaDeD is similar to
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:23 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 9.
provided by BLOCKWATCH. Higher is better
coverageoriginal (baseline) and coverageBLOCKWATCH (aggregated number) for branch-condition faults: The dark part is due to the detection
BLOCKWATCH in that both techniques consider deviations as
detections. However, AutomaDeD differs from BLOCKWATCH
in three ways. First, AutomaDeD requires the programmer to
annotate their code with region identiﬁers which are used as
the building blocks of the SMMs. Second, AutomaDeD is
targeted towards software bugs during debugging, and not at
runtime hardware errors. Finally, AutomaDeD learns SMMs
at runtime, and can incur false-positives.
Mirgorodskiy et al. [12] use statistical techniques based on
function execution times in parallel programs’ tasks to detect
outliers. However, this approach does not detect errors that
do not cause a noticeable difference in the execution times
of functions. Their approach also incurs false-positives as the
execution times are learned at runtime.
Invariant based Checks: DMTracker [26] leverages invari-
ants on data movement to ﬁnd bugs in MPI-based parallel
programs. They leverage the observation that MPI programs
have regular communication patterns, which gives rise to
invariants on the transfer of data among the different tasks.
DMTracker differs from BLOCKWATCH in three ways. First,
the invariants are speciﬁc to MPI-based programs, and do
not apply for shared memory parallel programs. Second, the
invariants derived by DMTracker pertain to the messages sent
by the program, and not necessarily to the control-data. Finally,
DMTracker attempts to learn the pattern of data transfer at
runtime and may hence incur false-positives.
FlowChecker [27] also ﬁnds errors by tracking invari-
ants on communication operations in MPI parallel programs.
FlowChecker extracts message intentions, which are matching
pairs of sends and receive MPI calls, and checks whether
the message ﬂows in the underlying MPI library match the
extracted intentions. The goal of FlowChecker is to ﬁnd bugs
in MPI libraries that cause data loss or lead to mismatched
messages, rather than detect runtime hardware errors.
Static and Dynamic Analysis: Static analysis has been
extensively used for verifying in parallel programs [28], [29].
In these cases, the goal is to ﬁnd bugs in the program, rather
than detect runtime errors arising in hardware. Pattabiraman et
al. [30] use static analysis to derive runtime error detectors for
sequential programs. Their technique differs from ours in three
ways. First, they conﬁne themselves to critical variables that
have high fanout in the program. Second, they duplicate the
backward slice of the critical variable, and compare the value
computed by the slice with that in the program. This approach
will not work for non-deterministic parallel programs. Finally,
they use support from the hardware to track control-ﬂow
within the program, and hence require hardware modiﬁcations.
Dynamic analysis techniques detect errors by learning in-
variants over one or more executions [31], [32], [33]. These
techniques target only sequential programs, and hence do not
consider similarity across threads . Yim et. al. [34] propose
a technique to learn invariants for GPU programs, and use
the invariants for detecting errors. However, their focus is on
errors that can cause large deviations in the output as GPU
programs are inherently error-tolerant. A generic problem with
all dynamic techniques is that of false-positives, which can
trigger unwanted detection and recovery.
Algorithmic techniques: Algorithm-based Fault Tolerance
(ABFT) is an error detection technique for specialized parallel
computations such as matrix manipulation and signal process-
ing [35], [36]. Sloan et al. [37] develop error-resilient gradient
descent algorithms for stochastic processors, or processors that
allow variation-induced errors to occur by drastically shaving
off design margins in order to save power. Finally, Geist et al.
develop a class of naturally fault-tolerant algorithms for certain
classes of iterative parallel computations [38]. While these
techniques are efﬁcient, they only protect programs of the
speciﬁc type they target. In contrast, BLOCKWATCH targets
general-purpose parallel programs.
Similarity based performance improvement: Long et
al. [7] exploit the similarity in SPMD applications for per-
formance improvement. They merge instruction fetching if
certain instructions are the same among different threads and
merge instruction execution if the instructions and their input
operands are shared among different threads. However, they
do not leverage the similarity for error checking.
VIII. CONCLUSION
This paper presented BLOCKWATCH to detect control-data
errors in SPMD parallel programs. BLOCKWATCH statically
infers the similarity of the program’s control-data across
threads, and checks their conformance to the inferred sim-
ilarity at runtime. Upon detecting a violation, it raises an
exception and reports the error. Experimental results show that
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:23 UTC from IEEE Xplore.  Restrictions apply. 
BLOCKWATCH increases the average SDC coverage across
seven programs from 83% (90%) to 97% for branch-ﬂip
faults (branch-condition faults), while incurring only 16%
overhead in the 32 thread case (on a 32 core machine).
BLOCKWATCH is automated, incurs zero false-positives and
can run on unmodiﬁed hardware, thus making it suitable for
today’s multicore processors.
Future work will consist of extending BLOCKWATCH to
other classes of parallel programs (than pthreads-style pro-
grams), and to other program data (in addition to control-data).
We will also explore optimizations to reduce the performance
overhead of BLOCKWATCH even further.
Acknowledgements
This research was supported in part by a Discovery grant
from the National Science and Engineering Research Council
of Canada (NSERC) and startup funding from the University
of British Columbia (UBC). We thank Frolin Ocariza, Farid
Tabrizi, Anna Thomas and the anonymous reviewers of DSN
2012 for their insightful comments.
REFERENCES
[1] S. Borkar and A. Chien, “The future of microprocessors,” Communica-
tions of the ACM, vol. 54, no. 5, pp. 67–77, 2011.
[2] D. J. Sorin, Fault Tolerant Computer Architecture. Morgan & Claypool
Publishers, 2009.
[3] S. Borkar, “Thousand core chips: a technology perspective,” in the
Design Automation Conf., 2007, pp. 746–749.
[4] H. Sutter and J. Larus, “Software and the concurrency revolution,”
Queue, vol. 3, no. 7, pp. 54–62, 2005.
[5] E. N. M. Elnozahy, L. Alvisi, Y.-M. Wang, and D. B. Johnson, “A
survey of rollback-recovery protocols in message-passing systems,”
ACM Computer Survey, vol. 34, pp. 375–408, 2002.
[6] F. Darema, “The SPMD model: Past, present and future,” in the
European PVM/MPI Users’ Group Meeting, 2001, p. 1.
[7] G. Long, D. Franklin, S. Biswas, P. Ortiz, J. Oberg, D. Fan, and F. T.
Chong, “Minimal multi-threading: Finding and removing redundant in-
structions in multi-threaded processors,” in IEEE/ACM Int’l Symposium
on Microarchitecture, 2010, pp. 337–348.
[8] D. Thaker, D. Franklin, J. Oliver, S. Biswas, D. Lockhart, T. Metodi,
and F. Chong, “Characterization of error-tolerant applications when
protecting control data,” in IEEE Int’l Symposium on Workload Char-
acterization, 2006, pp. 142–149.
[9] G. Reis, J. Chang, N. Vachharajani, R. Rangan, and D. August, “SWIFT:
Software implemented fault tolerance,” in the Int’l Symposium on Code
Generation and Optimization, 2005, pp. 243–254.
[10] Y. Zhang, J. Lee, N. Johnson, and D. August, “DAFT: decoupled
acyclic fault tolerance,” in the Int’l Conf. on Parallel Architectures and
Compilation Techniques, 2010, pp. 87–98.
[11] G. Bronevetsky, I. Laguna, S. Bagchi, B. de Supinski, D. Ahn, and
M. Schulz, “AutomaDeD: Automata-based debugging for dissimilar
parallel tasks,” in IEEE/IFIP Int’l Conf. on Dependable Systems and
Networks, 2010, pp. 231–240.
[12] A. Mirgorodskiy, N. Maruyama, and B. Miller, “Problem diagnosis in
large-scale computing environments,” in ACM/IEEE Conf. on Supercom-
puting, 2006, pp. 88–100.
[13] S. Woo, M. Ohara, E. Torrie, J. Singh, and A. Gupta, “The SPLASH-2
programs: Characterization and methodological considerations,” in ACM
SIGARCH Computer Architecture News, vol. 23, no. 2, 1995, pp. 24–36.
[14] R. Cytron, J. Ferrante, B. Rosen, M. Wegman, and F. Zadeck, “Efﬁ-
ciently computing static single assignment form and the control depen-
dence graph,” ACM Trans. on Programming Languages and Systems,
vol. 13, no. 4, pp. 451–490, 1991.
[15] L. Lamport, “Specifying concurrent program modules,” ACM Trans. on
Programming Languages and Systems, vol. 5, no. 2, pp. 190–222, 1983.
[16] J. Wei and K. Pattabiraman, “BlockWatch: Leveraging similarity in par-
allel programs for error detection,” The University of British Columbia
(UBC), Tech. Rep. RADICAL-2012-03-01, 2012.
[17] C. Lattner and V. Adve, “LLVM: A compilation framework for life-
long program analysis & transformation,” in Int’l Symposium on Code
Generation and Optimization, 2004, pp. 75–86.
[18] B. Karlsson, Beyond the C++ standard library.
Addison-Wesley
Professional, 2005.
[19] V. Reddi, A. Settle, D. Connors, and R. Cohn, “PIN: a binary instru-
mentation tool for computer architecture research and education,” in the
Workshop on Computer Architecture Education, 2004.
[20] R. Alexandersson and J. Karlsson, “Fault injection-based assessment of
aspect-oriented implementation of fault tolerance,” in IEEE/IFIP Int’l
Conf. on Dependable Systems and Networks, 2011, pp. 303–314.
[21] C. Basile, K. Whisnant, Z. Kalbarczyk, and R. Iyer, “Loose synchro-
nization of multithreaded replicas,” in IEEE Symposium on Reliable
Distributed Systems, 2002, pp. 250–255.
[22] M. Olszewski, J. Ansel, and S. Amarasinghe, “Kendo: efﬁcient deter-
ministic multithreading in software,” in ACM SIGPLAN Notices, vol. 44,
no. 3, 2009, pp. 97–108.
[23] Z. Alkhalifa, V. Nair, N. Krishnamurthy, and J. Abraham, “Design
and evaluation of system-level checks for on-line control ﬂow error
detection,” IEEE Trans. on Parallel and Distributed Systems, vol. 10,
no. 6, pp. 627–641, 1999.
[24] S. Bagchi, Z. Kalbarczyk, R. Iyer, and Y. Levendel, “Design and
evaluation of preemptive control signature (PECOS) checking,” IEEE
Trans. on Computers, 2003.
[25] N. Oh, P. Shirvani, and E. McCluskey, “Control-ﬂow checking by
software signatures,” IEEE Tranactions on Reliability, vol. 51, no. 1,
pp. 111–122, 2002.
[26] Q. Gao, F. Qin, and D. Panda, “Dmtracker: ﬁnding bugs in large-
scale parallel programs by detecting anomaly in data movements,” in
ACM/IEEE Conf. on Supercomputing, 2007, pp. 1–12.
[27] Z. Chen, Q. Gao, W. Zhang, and F. Qin, “Flowchecker: Detecting bugs
in MPI libraries via message ﬂow checking,” in ACM/IEEE Int’l Conf.
for High Performance Computing, Networking, Storage and Analysis,
2010, pp. 1–11.
[28] M. Naik, A. Aiken, and J. Whaley, “Effective static race detection for
Java,” ACM SIGPLAN Conf. on Programming Language Design and
Implementation, vol. 41, no. 6, pp. 308–319, 2006.
[29] A. Vo, S. Aananthakrishnan, G. Gopalakrishnan, B. Supinski, M. Schulz,
and G. Bronevetsky, “A scalable and distributed dynamic formal veriﬁer
for MPI programs,” in ACM/IEEE Int’l Conf. for High Performance
Computing, Networking, Storage and Analysis, 2010, pp. 1–10.
[30] K. Pattabiraman, Z. Kalbarczyk, and R. Iyer, “Automated derivation of
application-aware error detectors using static analysis,” in IEEE Int’l
On-Line Testing Symposium, 2007, pp. 211–216.
[31] M. Hiller, A. Jhumka, and N. Suri, “On the placement of software
mechanisms for detection of data errors,” in IEEE/IFIP Int’l Conf. on
Dependable Systems and Networks, 2002, pp. 135–144.
[32] S. Hangal and M. Lam, “Tracking down software bugs using automatic
anomaly detection,” in the Int’l Conf. on Software Engineering, 2002,
pp. 291–301.
[33] S. Sahoo, M. Li, P. Ramachandran, S. Adve, V. Adve, and Y. Zhou, “Us-
ing likely program invariants to detect hardware errors,” in IEEE/IFIP
Int’l Conf. on Dependable Systems and Networks, 2008, pp. 70–79.
[34] K. Yim, C. Pham, M. Saleheen, Z. Kalbarczyk, and R. Iyer, “Hauberk:
Lightweight silent data corruption error detector for GPGPU,” in IEEE
Parallel & Distributed Processing Symposium, 2011, pp. 287–300.
[35] K. Huang and J. Abraham, “Algorithm-based fault tolerance for matrix
operations,” IEEE Trans. on Computers, pp. 518–528, 1984.
[36] J. Plank, Y. Kim, and J. Dongarra, “Algorithm-based diskless check-
pointing for fault tolerant matrix operations,” in the Int’l Symposium on
Fault-Tolerant Computing, 1995, pp. 351–360.
[37] J. Sloan, D. Kesler, R. Kumar, and A. Rahimi, “A numerical
optimization-based methodology for application robustiﬁcation: Trans-
forming applications for error tolerance,” in IEEE/IFIP Int’l Conf. on
Dependable Systems and Networks, 2010, pp. 161–170.
[38] A. Geist and C. Engelmann, “Development of naturally fault tolerant
algorithms for computing on 100,000 processors,” Journal of Parallel
and Distributed Computing, 2002.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:23 UTC from IEEE Xplore.  Restrictions apply.