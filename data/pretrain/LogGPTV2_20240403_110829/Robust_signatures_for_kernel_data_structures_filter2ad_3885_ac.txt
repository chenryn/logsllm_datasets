The constant template determines whether a ﬁeld always takes
on a particular value. This is useful, for example, for data structures
that have a “magic” number that identiﬁes them uniquely. Because
the features that are used for signature generation are known to be
robust (as these were the selection criteria described in Sections 4.1
and 4.2), we can have some conﬁdence that the operating system
performs sanity checking on such constant values.
The two remaining tests are particularly useful for ﬁnding con-
straints on pointer values. The bitwise AND test simply performs
a bitwise AND of all values observed. In many operating systems,
kernel memory resides in a speciﬁc portion of virtual address space,
such as (in Windows) the upper 2 gigabytes. One can determine if
a 32-bit pointer always points to kernel memory, then, by simply
checking that the highest bit is set.
Finally, the alignment test attempts to ﬁnd a natural alignment
for all values. As an optimization, many OS memory managers
allocate memory aligned on a natural processor boundary, such as
eight bytes. As a result, most pointers to kernel objects will like-
wise have some natural alignment that we can discover and use as
a constraint.
Our signature generator takes as input a comma-separated ﬁle,
where each row gives the ﬁeld name and a list of values observed
for that ﬁeld. For each ﬁeld, it applies the constraint templates to
the values listed and determines a boolean expression that is true
for every value. It then outputs a plugin for Volatility, written in
Python, that can be used to scan for the target data structure in a
memory image. An excerpt of the plugin generated to search for
instances of the EPROCESS data structure is given in Figure 5.
The signature generation mechanism produces extremely robust
results in practice: as we describe in Section 6.3, the signature we
generated for Windows process data structures found all instances
of the data structure in memory with no false positives or negatives.
Should this technique prove insufﬁcient for some data structure,
however (for example, if only a few features are robust enough to
use in a signature), more heavyweight techniques such as dynamic
heap type inference [32] could be used.
4.4 Discussion
Our experiments (described in Section 6) show that these tech-
niques can be used to derive highly accurate signatures for kernel
data structures that are simultaneously difﬁcult to evade. There are,
however, certain drawbacks to using probabilistic methods such as
dynamic analysis and fuzz testing. In particular, both techniques
may suffer from coverage problems.
In the proﬁling stage, it is
highly unlikely that every ﬁeld used by the operating system will
actually be accessed; there are many ﬁelds that may only be used in
special cases. Likewise, during fuzzing, it is possible that although
the operating system did not crash during the 30 seconds of testing,
it might fail later on, or in some special circumstances.
In both of these cases, however, we note that these omissions will
only cause us to ignore potentially robust features, rather than acci-
dentally including weak ones. Moreover, from an attacker’s point
of view, the malware need not work perfectly, or run in every spe-
cial case: sacriﬁcing correct operation in a tiny fraction of conﬁg-
urations may be worth the increased stealth afforded by modifying
these ﬁelds. Thus, a short time interval for testing is conservative:
it will never cause a weak feature to be used in a signature, as only
features whose modiﬁcation consistently causes OS crashes form
the basis of signatures. However, it may cause ﬁelds to be elimi-
nated that would, in fact, have been acceptable to use in a signature.
If too many ﬁelds are eliminated, the resulting signature may match
random data in memory, creating false positives. In any case, this
limitation is easily overcome by increasing the amount of time the
fuzzer waits before testing the OS functionality, or by exercising
the guest OS more strenuously during that time period.
However, there are some coverage issues that could result in
weak signatures. Because fuzzing is a dynamic process, it is pos-
sible to only inject a subset of values that causes the OS to crash,
while there exists some other set of values that can be used without
any negative effects. In this case, we may conclude that a given
feature is robust when in fact the attacker can modify it at will.
For most ﬁelds it is not practical to test every possible value (for
example, assuming each test takes only ﬁve seconds, it would still
require over 680 years to exhaustively test a 32-bit integer). In Sec-
tion 8, we will consider future enhancements to the fuzzing stage
that may improve coverage.
Finally, we note that although the features selected using our
method are likely to be difﬁcult to modify, there is no guarantee
that they will be usable in a signature. For example, although our
testing found that the ﬁeld containing the process ID is difﬁcult to
modify, it could still be any value, and examining a large number of
process IDs will not turn up any constraints on the value. In prac-
tice, though, we found that most of the “robust” features identiﬁed
were fairly simple to incorporate into a signature, and we expect
that this will be true for most data structures.
5. METHODOLOGY
Signature search is essentially a classiﬁcation problem: given an
unknown piece of data, we wish to classify it as an instance of our
data type or as something else. Our experiments, therefore, attempt
to measure the performance of the signatures using standard clas-
siﬁcation metrics: false positives and negatives. A false positive in
this case is a piece of data that matches the signature but would not
be considered a valid instance of the data structure by the operating
system. Conversely, a false negative is a valid instance that is not
classiﬁed as such by our signature. False negatives represent cases
where the attacker could successfully evade the signature, whereas
false positives could introduce noise and make it difﬁcult for to tell
what processes are actually running.
For our purposes, we only consider false positives that are syn-
tactically invalid. We note that an attacker could generate any num-
ber of false positives by simply making copies of existing kernel
data structures. These structures would be semantically invalid (the
operating system would have no knowledge of their existence), but
would be detected by a signature scanner. The possibility of such
“dummy” structures is a known weakness of signature-based meth-
ods for ﬁnding kernel data structures [47]; however, a solution to
this problem is outside the scope of this work.
For our experiments, we chose to generate a signature for the
Windows EPROCESS data structure, which holds information re-
lated to each running process. This structure was chosen because
it is the most commonly hidden by malicious software, and there
are a number of existing signature-based tools that attempt to locate
this data structure in memory [5, 36, 46]. We compare the success
571Name
Telnet
Command shell
NTFS Defragment
Explorer
Name
Internet Explorer
Mozilla Firefox
Name
WinQuake
Minesweeper
Name
Notepad
System Utilities
Version
5.1.2600.5512
5.1.2600.5512
5.1.2600.5512
6.0.2900.5512
Browsers
Version
7.0.5730.13
3.0.5
Version
1.06
5.1.2600.0
Games
Editor
Version
5.6.2600.5512
Debugger
Name
Notepad (debugged)
Windbg (debugging)
Version
5.6.2600.5512
6.9.0003.113 x86
Name
Outlook Express
Pidgin
Name
Pidgin Installer
Communications
Version
6.00.2900.5512
2.5.3
Installer
Version
2.4.0
Antivirus / Antispyware
Name
Avira AntiVir
Spybot Search & Destroy
Name
Apache HTTPd
network_listener
Version
8.2.0.337
1.6.0.0
Network Servers
Version
2.2.11
N/A
Multimedia
Name
Windows Media Player
iTunes
Version
9.00.00.4503
8.0.2.20
Table 1: List of applications proﬁled, along with the number of
ﬁelds in EPROCESS accessed.
of our signature with these tools. However, our work can also be
applied to generate signatures for other data structures.
5.1 Proﬁle Generation and Fuzzing
During the proﬁling stage, we examined access patterns for ﬁelds
in the EPROCESS data structure. To ensure that our data rep-
resented a wide range of possible application-level behavior, we
chose twenty different programs that performed a variety of tasks
(see Table 1 for a full list). To obtain a proﬁle, we ﬁrst launched
the application and noted the address of its associated EPROCESS
structure using the kernel debugger, WinDbg. We then instructed
the Xen hypervisor to monitor access to the page, and used the ap-
plication for a minimum of ﬁve minutes.
We note that in addition to differences caused by the unique func-
tion performed by each application, other activities occurring on
the system may cause different parts of the data structure to be ex-
ercised. In an attempt to isolate the effects caused by differences
in program behavior, as each proﬁle was generated we also used
Fields
112
135
123
143
Fields
153
147
Fields
129
108
Fields
151
Fields
145
146
Fields
148
143
Fields
188
Fields
130
136
Fields
108
139
Fields
142
142
the system to launch several new tasks (Notepad and the command
shell, cmd.exe), switch between interactive programs, and move
and minimize the window of the application being proﬁled.
After proﬁling the applications, we picked only the features that
were accessed in all twenty applications. This choice is conserva-
tive: if there are applications which do not cause a particular ﬁeld
to be exercised, then it may be possible for an attacker to design a
program that never causes the OS to access that ﬁeld. The attacker
would then be able to modify the ﬁeld’s value at will and evade any
signature that used constraints on its value.
As described in Section 4.2, features that were accessed by all
programs proﬁled were fuzzed to ensure that they were difﬁcult to
modify. Checking that the EPROCESS data structure is still func-
tioning after each fuzz test is much simpler if the associated pro-
gram has known, well deﬁned behavior. For this reason, we chose
to create a program called network_listener that opens a net-
work socket on TCP port 31337, waits for a connection, creates a
ﬁle on the hard drive, and ﬁnally exits successfully. The baseline
snapshot was taken just after launching network_listener in-
side the guest VM.
Because the program behavior is known in advance, the test to
see if the OS and program are still working correctly (φ) becomes
simple. From the host, we perform the following tests on the virtual
machine: