Journal of Web Semantics (accepted, to appear 2004), Elsevier.
Quality of Service for Workflows and
Web Service Processes
Jorge Cardoso1, Amit Sheth2, John Miller2, Jonathan Arnold3, and Krys Kochut2
1 Departamento de Matemática e Engenharias
Universidade da Madeira
9050-078 Funchal – Portugal
2 LSDIS Lab, Department of Computer Science
3 Fungal Genome Resource laboratory, Department of Genetics
University of Georgia
Athens, GA 30602 – USA
Abstract
Workflow management systems (WfMSs) have been used to support
various types of business processes for more than a decade now. In
workflows or Web processes for e-commerce and Web service
applications, suppliers and customers define a binding agreement or
contract between the two parties, specifying Quality of Service (QoS)
items such as products or services to be delivered, deadlines, quality of
products, and cost of services. The management of QoS metrics directly
impacts the success of organizations participating in e-commerce.
Therefore, when services or products are created or managed using
workflows or Web processes, the underlying workflow engine must accept
the specifications and be able to estimate, monitor, and control the QoS
rendered to customers. In this paper, we present a predictive QoS model
that makes it possible to compute the quality of service for workflows
automatically based on atomic task QoS attributes. We also present the
implementation of our QoS model for the METEOR workflow system.
We describe the components that have been changed or added, and discuss
how they interact to enable the management of QoS.
1 Introduction
With the advent and evolution of global scale economies, organizations need to be more
competitive, efficient, flexible, and integrated in the value chain at different levels,
including the information system level. In the past decade, Workflow Management
Systems (WfMSs) have been distinguished due to their significance and their impact on
organizations. WfMSs allow organizations to streamline and automate business processes
and reengineer their structure; in addition, they increase efficiency and reduce costs.
Several researchers have identified workflows as the computing model that enables a
standard method of building Web service applications and processes to connect and
exchange information over the Web (Chen, Dayal et al. 2000; Leymann 2001; Shegalov,
Gillmann et al. 2001; Fensel and Bussler 2002). The new advances and developments in
e-services and Web services set new requirements and challenges for workflow systems.
One important missing requirement is the management of Quality of Service (QoS).
Organizations operating in modern markets, such as e-commerce activities and
distributed Web services interactions, require QoS management. Appropriate control of
quality leads to the creation of quality products and services; these, in turn, fulfill
customer expectations and achieve customer satisfaction.
While QoS has been a major concern in the areas of networking (Cruz 1995;
Georgiadis, Guerin et al. 1996), real-time applications (Clark, Shenker et al. 1992) and
middleware (Zinky, Bakken et al. 1997; Frolund and Koistinen 1998; Hiltunen,
Schlichting et al. 2000), few research groups have concentrated their efforts on enhancing
workflow systems to support Quality of Service management. Most of the research
carried out to extend the functionality of workflow systems QoS has only been done in
the time dimension, which is only one of the dimensions under the QoS umbrella.
Furthermore, the solutions and technologies presented are still preliminary and limited
(Eder, Panagos et al. 1999). The industry has a major interest on the QoS of workflows
and workflow systems. Currently, ad-hoc techniques can be applied to estimate the QoS
of workflows.
For organizations, being able to characterize workflows based on QoS has four distinct
advantages.
(1) QoS-based design. It allows organizations to translate their vision into their
business processes more efficiently, since workflow can be designed according to
QoS metrics. For e-commerce processes it is important to know the QoS an
application will exhibit before making the service available to its customers.
(2) QoS-based selection and execution. It allows for the selection and execution of
workflows based on their QoS, to better fulfill customer expectations. As
workflow systems carry out more complex and mission-critical applications, QoS
analysis serves to ensure that each application meets user requirements.
(3) QoS monitoring. It makes possible the monitoring of workflows based on QoS.
Workflows must be rigorously and constantly monitored throughout their life
cycles to assure compliance both with initial QoS requirements and targeted
objectives. QoS monitoring allows adaptation strategies to be triggered when
undesired metrics are identified or when threshold values are reached.
(4) QoS-based adaptation. It allows for the evaluation of alternative strategies when
workflow adaptation becomes necessary. In order to complete a workflow
according to initial QoS requirements, it is necessary to expect to adapt, replan,
and reschedule a workflow in response to unexpected progress, delays, or
technical conditions. When adaptation is necessary, a set of potential alternatives
is generated, with the objective of changing a workflow as its QoS continues to
meet initial requirements. For each alternative, prior to actually carrying out the
2
adaptation in a running workflow, it is necessary to estimate its impact on the
workflow QoS.
This paper is composed of two parts. The first part presents a comprehensive model
for the specification of workflow QoS as well as methods to compute and predict QoS.
We start by investigating the relevant QoS dimensions that are necessary to correctly
characterize workflows. We not only target the time dimension, but also investigate other
dimensions required to develop a usable workflow QoS model. Once the QoS model is
defined, algorithms are necessary to compute the QoS of workflows. Quality metrics are
associated with tasks, and tasks compose workflows. The computation of workflow QoS
is done based on the QoS of the tasks that compose a workflow.
The second part of this paper describes the enhancements that need to be made to
workflow systems to support processes constrained by QoS requirements. The
enhancements include the implementation of a QoS model, the implementation of
algorithms to compute and predict workflow QoS, and the implementation of methods to
record and manage QoS metrics. These enhancements have been carried out for the
METEOR system (Kochut, Sheth et al. 1998) to allow the specification, recording, and
computation of QoS. The support of QoS requires the modification and extension of
several workflow system components, and the development of additional modules. While
the implementation was made for the METEOR system and the development is based on
a specific conceptual model, the main ideas presented in this study can be applied to the
vast majority of workflow systems available.
This paper is structured as follows. Section 2 describes a workflow process that
illustrates a real world scenario, which will be used to exemplify QoS through the rest of
the paper. Based on our scenario, a set of new requirements is derived and the current
limitations of WfMSs technology are stated. In section 3, we introduce our workflow
QoS model and describe each of its dimensions. Section 4 describes how the quality of
service of workflow tasks is calculated. Section 5 described how QoS estimates are set. In
Section 6, we present an algorithm to compute and estimate workflow QoS. Section 7 is
extensive and describes the modification of existing workflow system components and
the creation of new modules that have been developed to support the workflow QoS
management for the METEOR system. Each of the workflow components and new
modules are analyzed individually. Section 8 presents an example of how to compute the
QoS for the workflow introduced in our initial scenario. Section 9 discusses the related
work in the QoS area. Finally, section 10 presents our conclusions.
2 Workflows, Tasks, Web services, and Web processes
Web services and e-services have been announced as the next wave of Internet-based
business applications that will dramatically change the use of the Internet (Fabio Casati,
Ming-Chien Shan et al. 2001). With the development and maturity of infrastructures and
solutions that support e-services, we expect organizations to incorporate Web services as
part of their business processes. While in some cases Web services may be utilized in an
isolated form, it is natural to expect that Web services will be integrated as part of
workflows (Fensel and Bussler 2002). The increasingly global economy requires
advanced information systems such as those supporting multi-enterprise and Web-scale
3
processes. Important developments have already been made with the construction of
systems to support workflows (enterprise level), distributed workflows (inter-enterprise
and B2B level), and Web processes (global level) (Bussler 2003).
In the QoS model presented in this paper, tasks and Web services can be treated with
no difference. Workflow systems require tasks to have a structure which includes
information such as task name, formal parameters, relevant data, and invoked
applications. Web services include the same kind of information. For example, in
METEOR workflow system (Kochut, Sheth et al. 1999), business tasks have been
wrapped with CORBA objects to enable a transparent remote invocation. With recent
technological developments, a business task can now be wrapped with a Web service
interface. One of the advantages of using Web services is to enable easier and greater
interoperability and integration among systems and applications.
The analogy drawn between tasks and Web services is also valid for workflows and
Web processes. Workflows represent the automation of a business process, in whole or
part, during which documents, information or tasks are passed from one participant to
another for action, according to a set of procedural rules and are made of elements which
comprise transitions, logic conditions, data flows, parallel and conditional building
blocks, starting and ending points, splits, and joins. Web processes have precisely the
same characteristics. These allows us to conclude that Web processes can be viewed as
workflows that manage Web services instead of tasks (Cardoso and Sheth 2003).
Therefore, throughout this paper, the term ‘task’ or ‘workflow task’ corresponds to a
traditional workflow task or a Web service. It will later become evident that in order for
our model to be applied to workflows or Web processes, tasks or Web service only have
to adhere to the QoS model.
3 Scenario
The Fungal Genome Resource laboratory (FGR 2002) at the University of Georgia has
realized that to be competitive and efficient it must adopt a new and modern information
system infrastructure. Therefore, a first step was taken in that direction with the adoption
of a workflow management system (METEOR (Kochut, Sheth et al. 1999)) to support its
laboratory processes (Hall, Miller et al. 2003). Since the laboratory supplies several
genome services to its customers, the adoption of a WfMS has enabled the logic of
laboratory processes to be captured in a workflow schema. As a result, all the services
available to customers are stored and executed under the supervision of the workflow
system.
3.1 Workflow Structure
Before discussing this scenario in detail, we review the basis elements of the METEOR
workflow model.
A workflow is composed of tasks, networks and transitions. Tasks are represented
using circles, networks (sub-workflows) using rounded rectangles, and transitions are
represented using arrows. Transitions express dependencies between tasks and are
associated with an enabling probability (p , p ,.., p ). When a task has only one outgoing
1 2 n
4
transition, the enabling probability is 1. In such a case, the probability can be omitted
from the graph. A task with more than one outgoing transition can be classified as an
and-split or xor-split. And-split tasks enable all their outgoing transitions after completing
their execution. Xor-split tasks enable only one outgoing transition after completing their
execution. And-split tasks are represented with a ‘*’ and xor-split tasks are represented
with a ‘+’. A task with more than one incoming transition can be classified as an and-join
or xor-join. And-join tasks start their execution when all their incoming transitions are
enabled. Xor-join tasks are executed as soon as one of the incoming transitions is
enabled. As with and-split and xor-split tasks, and-join tasks and xor-join tasks are
represented with the symbol ‘*’ and ‘+’, respectively. When no symbol is present to
indicate the input or output logic of a task, then it is assumed to be an xor.
3.2 Workflow Description
Genomic projects involve highly specialized personnel and researchers, sophisticated
equipment, and specialized computations involving large amounts of data. The
characteristics of the human and technological resources involved, often geographically
distributed, require a sophisticated coordination infrastructure to manage not only
laboratory personnel and equipment, but also the flow of data generated.
One of the services supplied by the research laboratory is the DNA Sequencing
workflow. A simplified version of the DNA Sequencing workflow is depicted in Figure
1.
p
1
+
t 1 + t 5 p 2 t 6 t 7 t 8
Setup
Test Quality Get Sequences Sequence Proces
t t t
2 3 4 Processing Report
Prepare Prepare Clones Assembly
Sample and
Sequence
Figure 1– DNA Sequencing workflow
The workflow is composed of eight main tasks: Setup, Prepare Sample, Prepare
Clone and Sequence, Assembly, Get Sequences, Sequence Processing, and Process
Report. Each individual task carries out a particular function; if necessary, the workflow
can be spread across multiple research centers.
The Setup task is responsible for initializing internal variables of the workflow
process.
The second task, Prepare Sample, consists of isolating DNA from a biological sample.
The samples can be prepared using a variety of protocols. These protocols need to be
followed rigorously in order to obtain DNA that is not degraded in any form. A correctly
prepared sample will originate a better DNA sequencing, since the quality of the DNA
template is one of the most critical factors in DNA sequencing.
5
The task Prepare Clones and Sequence clones specific regions of the genome from
DNA isolated in the previous step. This step can be fully automated by computer control
(using, for example, a robotic system). This task also executes the sequencing, which
uses DNA sequencing machines to read each biochemical “letter” (A, G, C or T) of a
cloned DNA fragment. The output is composed of short decoded segments (a sequence
such as AGGCATTCCAG…). The use of automated sequencers has revolutionized the
field of bioinformatics by enabling scientists to catalogue sequence information hundreds
of times faster than was possible with pre-existing scanning techniques. This new
approach allows for automatic recognition, without major human intervention.
The Assembly task analyzes the DNA segments generated in the sequencing task. This
step includes the assembly of larger contiguous blocks of sequences of DNA from small
overlapping fragments. This is complicated by the fact that similar sequences occur many
times in many places of the genome.
The Test Quality task screens for the Escherichia coli (E. coli) contaminant in DNA
contigs. The clones grown in bacterial hosts are likely to be contaminated. A quick and
effective way to screen for the E. coli contaminant is to compare a given DNA sequence
to the E. coli genome. For E. coli, this task is made easier by the availability of its full
genome.
Get Sequences is a simple task that downloads the sequences created in the assembly
step, using the FTP protocol.
The Sequence Processing task analyzes the DNA segments generated in the assembly
step. The goal of this task is to find DNA sequences in order to identify macromolecules
with related structures and functions. The new DNA sequence is compared to a
repository of known sequences (e.g., Swiss-Prot or GenBank), using one of a number of
computational biology applications for comparison.
After obtaining the desired data from the Sequence Processing task, the results are
stored, e-mailed, and a report is created. The Process Report task stores the data
generated in the previous task in a database and creates a final report. It is responsible for
electronically mailing the sequencing results to the persons involved in this process, such
as researchers and lab technicians.
3.3 Workflow Application Requirements
In its normal operation, the Fungal Genome Resource laboratory executes the DNA
Sequencing workflow in a regular manner. Workflow instances are started in order to
render the sequencing services. In this scenario, and with current workflow technology,
the execution of the workflow instances is carried out without any quality of service
management on important parameters such as delivery deadlines, reliability, and cost of
service. The laboratory wishes to be able to state a detailed list of requirements for the
service to be rendered to its customers. Its requirements include the following:
(cid:131) The final report has to be delivered in 31 weeks or less, as specified by the
customer (e.g., NIH).
(cid:131) The profit margin has to be 10%. For example, if a customer pays $1,100 for a
sequencing, then the execution of the DNA Sequencing workflow must have a
cost for the laboratory that is less than $1,000.
6
(cid:131) In some situations, the client may require an urgent execution of DNA
sequencing. Therefore, the workflow has to exhibit high levels of reliability, since
workflow failures would delay the sequencing process.
The requirements for the genetic workflow application presented underline three non-
functional requirements: time, cost, and reliability. While the specification of such quality
requirements is important, current WfMSs do not supply a model to delineate their
specification or management.
Having already given a good description of the problem and motivating why a solution
is needed for the specification and management of QoS, in the next section we present a
QoS model which captures the specification of QoS metrics. This model is a basic stone
of our work, and will be used, not only to specify the QoS, but also compute the QoS of
workflows.
4 Workflow Quality of Service
Workflow QoS represents the quantitative and qualitative characteristics of a workflow
application necessary to achieve a set of initial requirements. Quantitative characteristics
can be evaluated in terms of concrete measures such as workflow execution time, cost,
etc. Qualitative characteristics specify the expected services offered by the system, such
as security and fault-tolerance mechanisms. QoS should be seen as an integral aspect of
workflows; therefore, it should be integrated with workflow specifications. The first step
is to define a workflow QoS model.
4.1 Characteristics of the QoS Model
One of the most popular workflow classifications distinguishes between ad hoc
workflows, administrative workflows, and production workflows. This classification was
first mentioned by (McCready 1992). The main differences between these types include
structure, repetitiveness, predictability, complexity, and degree of automation.
The QoS model presented here is better suited for production workflows (McCready