# Performance of Password Classifier Models

## Table 5: Model Evaluation on Holdout Test Dataset (10% Label Threshold)

| Recall | Susceptible | FPR | FNR |
|--------|-------------|-----|-----|
| 75%    | 0.19        | 0.18| 0.53|
| 90%    | 0.19        | 0.19| 0.46|
| 10%    | 0.25        | 0.35| 0.32|
| 25%    | 0.58        | 0.58| 0.16|
| 50%    | 0.70        | 0.70| 0.11|
| 75%    | 0.21        | 0.20| 0.56|
| 90%    | 0.22        | 0.21| 0.47|
| 10%    | 0.24        | 0.23| 0.35|
| 25%    | 0.62        | 0.61| 0.12|
| 50%    | 0.72        | 0.71| 0.05|
| 75%    | 0.27        | 0.25| 0.37|
| 90%    | 0.28        | 0.25| 0.32|
| 10%    | 0.41        | 0.39| 0.24|
| 25%    | 0.64        | 0.62| 0.14|
| 50%    | 0.74        | 0.73| 0.09|
| 75%    | 0.27        | 0.25| 0.38|
| 90%    | 0.28        | 0.25| 0.32|
| 10%    | 0.40        | 0.37| 0.23|
| 25%    | 0.63        | 0.61| 0.13|
| 50%    | 0.73        | 0.71| 0.09|
| 75%    | 0.23        | 0.20| 0.42|
| 90%    | 0.25        | 0.22| 0.37|
| 10%    | 0.39        | 0.36| 0.24|
| 25%    | 0.59        | 0.57| 0.14|
| 50%    | 0.69        | 0.68| 0.09|

### Description
The table above shows the performance of the password classifier models on the holdout test dataset, trained with a 10% label threshold. The models are evaluated at different recall operating points, and the metrics include the proportion of emails flagged as susceptible, false positive rates (FPR), and false negative rates (FPR).

### Practical Implications
Deploying such models would result in disabling typo-tolerance for a quarter or a third of users, while mitigating security degradation for up to three-quarters of the users who would otherwise be negatively affected by typo-tolerance. For many online services, this tradeoff may be suitable, as it limits security degradation while maintaining the majority of the functionality.

### Additional Model Evaluations

#### Table 9: 0% Label Threshold
- **Susceptibility Prediction Rate**: Above 63% for all policies and recall operating points.
- **FPR**: Similarly high.
- **Example**: CTop2 model at 90% recall exhibits a 3% FNR while predicting susceptibility for 78% of emails.
- **Conclusion**: This configuration can largely eliminate typo-tolerance's security degradation while preserving some functionality (e.g., for 22% of users).

#### Table 10: 25% Label Threshold
- **Susceptibility Prediction Rate**: Below 51%.
- **FNR**: As high as 85%.
- **Example**: CTop2 model at 50% recall predicts susceptibility for only 8% of emails with a 49% FNR.
- **Conclusion**: This configuration significantly reduces but does not eliminate the security impact of typo-tolerance, with limited functionality loss.

### Impact Analysis
- **Holdout Test Set Evaluation**: Revealed that these models offer different functionality versus security tradeoffs compared to fully enabling or disabling typo-tolerance.
- **Lower Bound Impact**: 86% of users have a password that could be typo-corrected by CTop1 and CTop2, and 100% of users have passwords that could be typo-corrected by CTop3-CTop5.
- **Conclusion**: A significant portion of users could still benefit from typo-tolerant authentication even with our models deployed.

### Computational Costs
- **Training**: Processing the data took approximately 12 hours using 20 parallel threads, and training a model took one hour on a single process.
- **Deployment**: The decision tree model can classify approximately 10K passwords per minute, and throughput can be scaled by running multiple instances in parallel.

### Conclusion
Our investigation into the security impact of typo-tolerant password authentication revealed that while typo-tolerance provides notable usability benefits, it also significantly degrades security under broader threat models, including credential stuffing and tweaking attacks. Our machine learning models offer a practical solution to mitigate these security costs while maintaining functionality, providing online services with the flexibility to deploy typo-tolerance in a more secure manner.

### Future Work
- **Machine Learning Approaches**: Further exploration of other machine learning algorithms to improve functionality-security tradeoffs.
- **Usability Impact**: Analyze the extent to which these models preserve typo-tolerance for users who actually make password typos.
- **Credential Tweaking Attacks**: Address the security implications of typo-tolerance against credential tweaking attacks.
- **Personalized Typo-Tolerance**: Revisit the security analysis of personalized typo-tolerance variants.
- **Password Change/Reset Policies**: Explore disallowing password changes where the old password could be corrected to the new one under the typo-tolerance policy.

### Acknowledgments
This work was supported in part by the National Science Foundation award CNS-2055549. We are grateful for their support. The opinions expressed in this paper do not necessarily reflect those of the research sponsors.

### References
[References listed here as provided in the original text]

---

This revised version organizes the information more clearly, making it easier to follow the results and conclusions. It also ensures that the tables and descriptions are presented in a coherent and professional manner.