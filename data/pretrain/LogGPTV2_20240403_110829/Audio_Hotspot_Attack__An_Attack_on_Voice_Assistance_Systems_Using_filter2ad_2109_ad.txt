### 7.2 Countermeasures

The Audio Hotspot Attack exploits the natural phenomenon of ultrasound self-demodulation in the air, making it impractical to block voice commands before they reach the target device. One possible solution is to detect and differentiate legitimate voice commands from malicious ones. There are two primary approaches to achieve this goal:

#### 7.2.1 Speaker Recognition
An effective and straightforward method is to employ speaker recognition. Many smart speakers, such as Google Home and Amazon Echo, already use this functionality. However, as discussed in Section 3, these methods remain vulnerable to advanced replay or voice-morphing attacks. Therefore, we need additional methods to detect voice commands emitted from parametric loudspeakers.

#### 7.2.2 Detecting Ultrasonic Sounds
Although the ultrasounds emitted from a parametric loudspeaker are demodulated in the air, un-demodulated ultrasonic components can still be observed in the sound wave. Figure 15 shows the spectrogram of a speech signal emitted from a parametric loudspeaker. The original speech data was "OK Google," generated using Amazon Polly (Ivy). In the spectrogram, the power of the ultrasonic component is around 40 kHz, corresponding to the carrier frequency of the AM-modulated sound. A harmonic overtone around 80 kHz is also observed. Thus, even after self-demodulation, ultrasonic components can be detected.

A practical approach to detecting these ultrasonic components is to use an ultrasonic sensor. While ultrasonic microphones are expensive, ultrasonic sensors are cheap and widely available. As suggested by Zhang et al. [33], MEMS microphones on mobile devices can sense acoustic sounds with frequencies higher than 20 kHz. If a device detects significant ultrasonic components, it can suspend operation and require user interaction to resume.

#### 7.2.3 Analyzing Frequency Patterns of Audible Sounds
Figure 16 presents the spectrograms of a voice signal ("OK Google" spoken by Amazon Polly) emitted from a dynamic loudspeaker and a parametric loudspeaker. Despite the same original voice data, the frequency patterns differ. The SPL of the sound wave generated from a parametric loudspeaker is proportional to the frequency of the original sound signal, leading to more or less observable high or low-frequency components at the target. The horizontal lines in the lower spectrogram represent folding noise, also known as aliasing. By observing this folding noise, we can detect attacks. In a brief experiment, we extracted components with frequencies above 10 kHz and computed their power. Normal sound waves had almost zero power, while directional sound beams had non-zero power. Using threshold-based detection, we could distinguish between sounds from a regular loudspeaker and a parametric loudspeaker with 100% accuracy.

#### 7.2.4 Voice Presentation Attack Detection (PAD) Method
Inaudible voice command attacks can be combined with presentation attacks, making the Presentation Attack Detection (PAD) method a viable countermeasure. This method, which assumes that the target voice assistant systems have not implemented it, can distinguish synthesized voices from authentic human voices. Liveness detection, which judges whether an input voice comes from a human or a dynamic speaker, is an example of a PAD method. In real environments, attacks often involve dynamic speakers. Therefore, a voice assistance system should be able to determine if a sound comes from a human or a dynamic speaker, even if it cannot identify a specific individual. Methods like Voice Gesture [33] proposed by Zhang et al. detect mouth movements using changes in ultrasonic waves, distinguishing between a human mouth and a dynamic speaker. This liveness detection method can be used to detect an Audio Hotspot Attack because ultrasonic transducers exhibit fewer movements than the human mouth.

### 7.3 Ethical Considerations

#### 7.3.1 Human Study Research
We conducted a human study to test the unrecognizability of the Audio Hotspot Attack using parametric loudspeakers. The experiments were designed to ensure no burden on participants' hearing or psychological states. The procedure was approved by the ethical review board at Waseda University. Participants provided informed consent, and the experimental procedures, potential risks, and benefits were explained. The sound levels were kept low to avoid discomfort, and participants were given breaks every ten minutes and could stop at any time without penalty.

#### 7.3.2 Offensive Security Research
This work aimed to explore the feasibility of inaudible voice command attacks. We demonstrated that such attacks are viable through methods like the Audio Hotspot Attack. Although this attack is a proof of concept, we have provided potential countermeasures. With the help of the national CERT, we have communicated with several manufacturers of voice assistance systems, receiving feedback on implementing countermeasures.

### 8 Related Works

#### 8.1 Voice Command Attacks
DolphinAttack [6], [34] inputs inaudible commands on a target microphone by AM modulating the sound with ultrasound as the carrier wave. This attack exploits the nonlinearity of MEMS and ECM microphones. In contrast, the Audio Hotspot Attack uses the natural phenomenon of air nonlinearity to demodulate AM-modulated ultrasonic signals, making it feasible even if microphone nonlinearity is removed. Additionally, Audio Hotspot Attacks can be employed from greater distances due to the higher decay rate of ultrasound.

#### 8.2 Audio Adversarial Examples
Audio Adversarial Examples [39] apply techniques similar to Image Adversarial Examples [40], [41] to voice waves. These examples are designed to cause machine learning models to make mistakes. Adding a small amount of noise to the original sound can result in erroneous recognition. Existing attacks, such as Hidden Voice Commands and DolphinAttack, exploit software, hardware, or machine learning vulnerabilities. The Audio Hotspot Attack, however, relies on a physical phenomenon, making it more challenging to mitigate.

### 9 Conclusion
In this work, we proposed a new inaudible voice command attack called the "Audio Hotspot Attack." Its feasibility was evaluated through extensive user studies and reproducible experiments. We demonstrated that when directional sounds are emitted from parametric loudspeakers and not perceived by nearby individuals, attacks can succeed over long distances (2-4 meters in a small room and up to 10+ meters in a hallway), and are robust against environmental noises. Although the Audio Hotspot Attack is currently a proof-of-concept, we have provided potential countermeasures. This attack uses the parametric phenomenon of ultrasound self-demodulation, offering new insights into security research for mobile and IoT devices from the perspective of acoustic inputs.

### Acknowledgments
This work was partially supported by JSPS Grant-in-Aid for Challenging Research (Exploratory), Grant Number 18K19789.

### References
[1] R. Iijima, S. Minami, Z. Yunao, T. Takehisa, T. Takahashi, Y. Oikawa, and T. Mori, “POSTER: Audio hotspot attack: An attack on voice assistance systems using directional sound beams,” in Proc. of the 2018 ACM SIGSAC Conference on Computer and Communications Security. ACM, 2018, pp. 2222–2224.
[Online]. Available: http://doi.acm.org/10.1145/3243734.3278497

[2] Apple. (2018) iOS Siri. [Online]. Available: https://www.apple.com/ios/siri/

[3] Google. (2018) Google Assistant. [Online]. Available: https://assistant.google.com

[4] Amazon. (2018) Amazon Alexa. [Online]. Available: https://alexa.amazon.com/spa/index.html

[5] N. Carlini, P. Mishra, T. Vaidya, Y. Zhang, M. Sherr, C. Shields, D. A. Wagner, and W. Zhou, “Hidden voice commands,” in Proceedings of 25th USENIX Security Symposium, 2016, pp. 513–530.

[6] G. Zhang et al., “Dolphinattack: Inaudible voice commands,” in Proceedings of the 2017 ACM SIGSAC, CCS, 2017, pp. 103–117.

[7] M. Yoneyama et al., “The audio spotlight: An application of nonlinear interaction of sound waves to a new type of loudspeaker design,” The Journal of the Acoustical Society of America, vol. 73, no. 5, pp. 1532–1536, 1983. [Online]. Available: