which would allow researchers to share and compare results
using similar tools. At present, we are developing such a
platform so that interested researchers can conduct further
work on security and privacy issues related to voice assis-
tance systems.
7.2 Countermeasures
Audio Hotspot Attack leverages the natural phenomenon
of ultrasound self-demodulation in the air; therefore, it is
not practical to try to block voice commands before they
reach the target device. One possible solution is to detect the
voice commands and differentiate them from others that are
legitimate. There are two ways to achieve this goal. An easy
and effective approach is to employ speaker recognition;
in fact, smart speakers such as Google Home or Amazon
Echo have already adopted this functionality. However, as
discussed in Section 3, such approaches are still vulnerable
to advanced replay or voice-morphing attacks. Therefore,
we require methods that can detect voice commands being
emitted from parametric loudspeakers. In the following
section, we discuss three potential approaches to achieve
this goal.
7.2.1 Detecting ultrasonic sounds
Although the ultrasounds emitted from a parametric loud-
speaker are demodulated in air, there are un-demodulated
ultrasonic components in the observed sound wave. Fig-
ure 15 shows the spectrogram of a speech signal emitted
Fig. 12. Average Jaccard index scores of the linear attack measured in
a 200 cm × 400 cm area. Left: dynamic speaker and Right: parametric
loudspeaker. The point (0, 0) is deﬁned as the location of the loud-
speaker. User cannot hear the on space except in front of the parametric
loudspeaker.
Fig. 13. Average Jaccard index scores for the cross attack measured
in a of 400 cm × 400 cm area. The point (200, 200) is deﬁned as the
demodulation point. We found that the users cannot hear sound waves
everywhere except in the center.
evaluations revealed that the directional sound generated
from the parametric loudspeakers achieved sufﬁcient unrec-
ognizability to perform the Audio Hotspot Attack. Speciﬁ-
cally, the sound generated with the cross attack was difﬁcult
for a human near the target device to perceive.
7 DISCUSSION
In this section, we discuss the limitations and extensions of
Audio Hotspot Attack, possible countermeasures against it,
and ethical issues considered during the experiments.
7.1 Limitations and possible extensions
Because the Audio Hotspot Attack uses sound wave(s) to
inject malicious voice commands, it will not succeed if there
is an obstacle between the target device and the parametric
loudspeaker(s) (e.g., a wall or a window). This limitation
also applies to other inaudible voice command attacks [32],
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TETC.2019.2953041, IEEE
Transactions on Emerging Topics in Computing
IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTING
11
Fig. 14. SPL measured for the three attack modes. The unit for the numerical values is dB(A). The setup is same as in the human study. We have
the speaker on the point (0,0) in the case of the dynamic speaker and linear attack. In the case of the X-Audio attack, (0, 0) is the demodulation
point for voice commands.
Fig. 15. Spectrogram of a speech signal emitted from a parametric
loudspeaker. The signal was recorded with an ultrasonic microphone.
The frequency range was set above 20 kHz (inaudible frequency). The
content is “OK Google”.
Fig. 16. Spectrogram of a speech signal emitted from a dynamic loud-
speaker (top) and a parametric loudspeaker (bottom). The signals were
recorded with a normal microphone. The frequency range was set below
20 kHz (audible frequency). We can see the folding noise at 10 kHz and
20 kHz in the bottom spectrogram. The content is “OK Google”.
Fig. 17. Speech signals generated from a dynamic loudspeaker (top),
a parametric loudspeaker (middle, linear attack), and Bottom: two para-
metric loudspeakers (bottom, cross attack). The content is “OK Google”.
from a parametric loudspeaker. The original speech data
was “Ok Google,” which was generated using Amazon
Polly (Ivy). In the spectrogram, the power of the ultrasonic
component is around 40 kHz, which corresponds to the
carrier frequency of the AM-modulated sound. A harmonic
overtone around 80 kHz was also observed. Thus, even
ultrasound is self-demodulated in the air, and it is possible
to observe ultrasonic components of sound waves.
A straightforward approach to detecting such ultrasonic
components is to apply an ultrasonic sensor. Although ul-
trasonic microphones are expensive, ultrasonic sensors are
cheap and readily available. As Zhang et al. suggested [33],
using MEMS microphones on mobile devices could be
an alternative solution, as these microphones can sense
acoustic sounds with frequencies higher than 20 kHz. Once
a device detects the non-negligible amounts of ultrasonic
components of a received sound wave, it may suspend the
operation and require interaction with the device owner to
resume the operation.
7.2.2 Analyzing the frequency patterns of audible sounds
Figure 16 presents the spectrograms of a voice signal (“OK
Google” as spoken by Amazon Polly) emitted from a dy-
namic loudspeaker and a parametric loudspeaker. Although
the original voice data was the same, there are different
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/.
-200-10001002002001000-100-20050.3552.9952.6652.0451.4150.5852.5255.2053.3451.5948.3250.0365.5251.9348.6148.0849.9751.6849.1846.5447.7647.1346.3848.2346.84Dynamic Speaker3240485664-200-10001002002001000-100-20037.4842.1469.9741.7043.7436.3843.0070.4039.5436.0536.7534.8574.6136.3044.5636.7035.3636.6338.1043.3036.9637.2637.1539.3737.91Linear Attack3240485664-200-10001002002001000-100-20043.2637.9136.2937.6037.0736.9239.9536.5036.9139.2436.3435.2942.7037.8137.6037.8837.8438.6342.8143.9741.6340.4639.7745.3750.56X-Audio Attack3240485664This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TETC.2019.2953041, IEEE
Transactions on Emerging Topics in Computing
IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTING
characteristics in the frequency patterns of the observed
sound waves. As can be seen in Eq. 4 (Section 2), the SPL of
the sound wave generated from a parametric loudspeaker is
proportional to the frequency of the original sound signal.
This indicates that if the sound is emitted from a parametric
loudspeaker, higher or lower frequency components are
more or less likely to be observed, respectively, at the target.
The horizontal lines shown in the lower spectrogram corre-
spond to the folding noise, which is also known as aliasing.
We can detect attacks if we observe the folding noise in
spectrograms. To validate the effectiveness of this approach,
we performed a brief experiment. From a given sound wave,
we extracted components that had the frequencies above 10
kHz, which is over the audible frequency of 8 kHz. We then
computed the power of the extracted sound wave. While
the normal sound wave had almost zero power, the sound
wave of the directional sound beam had non-zero power. By
simply applying a threshold-based detection, we were able
to distinguish the sound emitted by a loudspeaker from the
one emitted by a parametric speaker with 100% accuracy.
Figure 17 shows speech signals emitted from a dy-
namic loudspeaker and parametric loudspeakers. Again,
these speech signals were generated by the same original
voice signal (“OK Google”), via Amazon Polly (Ivy). For
the speech signals emitted from parametric loudspeakers
(middle and lower panels in the ﬁgure), there is an intrinsic
spike at the beginning of the speech signal. These spikes can
be used as a ﬁngerprint for detecting speech generated from
a parametric loudspeaker. These spikes and other intrinsic
characteristics can be used to differentiate speech gener-
ated from a parametric loudspeaker compared to speech
generated from a regular voice using heuristics or machine
learning-based approaches.
7.2.3 Voice Presentation Attack Detection (PAD) method
As inaudible voice command attacks will be combined with
the presentation attacks, we can apply the presentation at-
tack detection (PAD) method, which we assumed our target
voice assistant systems had not implemented, to detect an
Audio Hotspot Attack [9]. The ultimate countermeasure
against such an attack is to be able to distinguish a syn-
thesized voice from an authentic human voice. Liveness
detection [33], [35], [36], which judges whether an input
voice has come from a human or a dynamic speaker, is an
example of the PAD method that could achieve this goal.
In real environments, attacks on speech recognition devices
are by means of the latter. Therefore, it would be sufﬁcient
for a voice assistance system to be able to judge whether a
sound comes from a human or a dynamic speaker, even if it
is unable to identify a speciﬁc individual. Voice Gesture [33],
as proposed by Zhang et al., attempts to detect the move-
ment of a person’s mouth, by using changes in ultrasonic
waves that occur as a consequence of the mouth movements
and the position of the tongue when an approximately 20
kHz ultrasonic wave is emitted from a smart device (e.g.,
a smartphone or tablet) to the mouth of the user. This
method detects differences in movement between a mouth
and a dynamic speaker. The mouth movement changes
for each pronunciation variation, whereas the surface of a
dynamic speaker exhibits very little movement. The liveness
detection method could be used to detect an Audio Hotspot
12
Attack because ultrasonic transducers use fewer movements
than the human mouth.
In our experiments, we have shown that simple rule-
based or threshold-based detection work as countermea-
sures against the Audio Hotspot Attack. However, more
robust countermeasures will be required in realistic environ-
ments. In [9], some typical countermeasure methods using
the machine learning model are proposed. On the contrary,
in [37], the authors pointed out that the machine-learning
model does not work well for the datasets obtained in
different setups. Overcoming the problem of overﬁtting to
the speciﬁc datasets and/or environments is left for future
work.
7.3 Ethical Considerations
7.3.1 Human study research
We performed a human study to test the unrecognizability
of the Audio Hotspot Attack using parametric loudspeakers.
The experiments were carefully designed such that they
did not impose a burden on either the hearing or psy-
chological states of the participants. The procedure for the
human study was approved by the ethical review board at
Waseda University. Prior to the experiments, we performed
a pilot study to ensure the validity of our measures. Then,
Participants were provided with all information required to
make a meaningful decision as to whether or not they were
willing to participate in the experiment (informed consent).
We explained the reasons for conducting the study, what
the experimental procedures, potential risks and beneﬁts
were, and the ways in which participants could get more
information on the study. The SPL of the sound waves was
sufﬁciently low such that it did not cause the participants
any discomfort. Participants were also given two-minute
breaks every ten minutes and were able to stop participating
at any time without incurring any penalty.
7.3.2 Offensive security research
The objective of this work was to explore the feasibility of
the threats caused by inaudible voice command attacks. It
was demonstrated that inaudible voice command attacks
are viable through methods such as an Audio Hotspot
Attack. Although this attack was proof of concept, we
have also provided potential countermeasures by which
they can be counteracted. Furthermore, with the aid of the
national CERT, we have initiated communication regarding
this with several manufacturers of voice assistance systems.
Feedback, including plans for implementing the counter-
measures within the products concerned, has been received.
By the time of publication, vendor reaction will have been
received and will also be reportable.
8 RELATED WORKS
Voice command attacks
DolphinAttack [6], [34] is an attack that inputs inaudible
commands on a target microphone by AM modulating the
sound, with the ultrasound as the carrier wave. The basic
idea is based on the fact that the output of the MEMS
and ECM microphones that are mounted on smartphones
has nonlinearity [32], [38]. A nonlinear term is obtained
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TETC.2019.2953041, IEEE
Transactions on Emerging Topics in Computing
IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTING
by squaring the input signal in the output signal when
an AM ultrasonic signal by the prepared voice is inputted
to the microphone. That is, the output of the microphone
receiving the AM-modulated ultrasound includes the fre-
quency component of the original speech signal, and the
speech recognition algorithm of the system that received
the low-pass ﬁltered signal is applied as recognized speech,
even though the input signal only generates high-frequency
waves. The output generated by the nonlinear term has a
smaller voltage value than the normal output and therefore
it is easy to detect.
On the other hand, in an Audio Hotspot Attack, there is
a marked difference in that audible sounds, which have been
self-demodulated from the ultrasound waves, are received
by a target device. This phenomenon is established because
air is nonlinear and demodulates the AM-modulated ul-
trasonic signal, as shown in Section 2. Indeed, we cannot
eliminate nonlinearity from the air because it is a natural
phenomenon. In other words, even if microphone non-
linearity is completely removed, Audio Hotspot Attacks
are still feasible even though inaudible voice commands
are infeasible. In addition, Audio Hotspot Attacks can be
employed from greater distances than DolphinAttacks be-
cause ultrasound has higher-than-audible frequencies, and
therefore, it decays faster.
Audio adversarial examples
Audio Adversarial Examples [39] apply Image Adversarial
Example [40], [41] techniques to voice waves. Adversarial
examples are input to machine learning models that an
attacker has intentionally designed to cause the model to
make a mistake. The recognition results of the machine
learning model are easily affected by a small amount of
perturbation (small noise). Adding a small amount of noise
to the original sound intentionally results in erroneous
recognition. Therefore, Audio Adversarial Examples can
be misidentiﬁed as arbitrary commands. The user cannot
notice the subtle additional noise and targeted malicious
commands are therefore executed on the voice assistant.
Existing attacks assume that software or hardware vul-
nerabilities are related to attack successes. Hidden voice
commands and Audio adversarial examples use the vul-
nerabilities inherent to machine learning, and DolphinAt-
tack uses vulnerabilities of MEMS microphones. On the
other hand, the Audio Hotspot Attack uses a physical phe-
nomenon i.e.,non-linearity in the air. Audio Hotspot Attack
countermeasures are therefore more difﬁcult to create given
they do not rely on any existing vulnerabilities.
9 CONCLUSION
In this work, we proposed a new inaudible voice com-
mand attack named “Audio Hotspot Attack.” Its feasibility
was evaluated through extensive user studies and repro-
ducible experiments. We demonstrated that when direc-
tional sounds are emitted from parametric loudspeakers and
not perceived by a nearby person, attacks can succeed over
relatively long distances (2–4 m in a small room and up
to 10+ m in a hallway); further, these attacks are tolerant
against environmental noises. Although the Audio Hotspot
13
Attack is currently a proof-of-concept, possible countermea-
sures to render the threats unsuccessful have been provided.
The proposed attack uses ultrasound self-demodulation,
which is a parametric phenomenon. We believe that this
concept sheds new light onto ongoing security research
focused on mobile and IoT devices, from the viewpoint of
acoustic inputs.
ACKNOWLEDGMENTS
A part of this work was supported by JSPS Grant-in-
Aid for Challenging Research (Exploratory), Grant Number
18K19789.
REFERENCES
[1] R.
Iijima, S. Minami, Z. Yunao, T. Takehisa, T. Takahashi,
Y. Oikawa, and T. Mori, “POSTER: Audio hotspot attack:
An attack on voice assistance systems using directional
the 2018
sound beams,
and Communications
on Computer
ACM SIGSAC Conference
Security. ACM, 2018, pp. 2222–2224.
[Online]. Available:
http://doi.acm.org/10.1145/3243734.3278497
(poster presentation),” in Proc. of
[2] Apple.
(2018)
https://www.apple.com/ios/siri/
ios
-
siri.
[Online].
Available:
[3] Google.
(2018)
google-assistant.
[Online].
Available:
https://assistant.google.com
[4] Amazon.
(2018)
Amazon
alexa.
[Online].
Available:
https://alexa.amazon.com/spa/index.html
[5] N. Carlini, P. Mishra, T. Vaidya, Y. Zhang, M. Sherr, C. Shields,
D. A. Wagner, and W. Zhou, “Hidden voice commands,” in
Proceedings of 25th USENIX Security Symposium, 2016, pp. 513–530.
[6] G. Zhang et al., “Dolphinattack: Inaudible voice commands,” in
Proceedings of the 2017 ACM SIGSAC, CCS, 2017, pp. 103–117.
[7] M. Yoneyama et al., “The audio spotlight: An application
of nonlinear interaction of sound waves to a new type of
loudspeaker design,” The Journal of
the Acoustical Society of
America, vol. 73, no. 5, pp. 1532–1536, 1983. [Online]. Available: