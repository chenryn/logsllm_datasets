cally adjusted to accommodate signiﬁcant changes in ex-
ploit patterns.
3.2 Signature-Generation Component
The clustering module groups sessions and connections
with similar attack proﬁles according to a similarity met-
ric. We assume that sessions grouped together will corre-
spond to a single attack type or variants of a well-known
attack while disparate clusters represent distinct attacks
or attack variants that differ signiﬁcantly from some orig-
inal attack. Effective clustering requires two properties
of the attack data. First, data that correspond to an attack
and its variants should be measurably similar. A clus-
tering algorithm can then classify such data as likely be-
longing to the same attack. Second, data corresponding
to different attacks must be measurably dissimilar so that
a clustering algorithm can separate such data. We be-
lieve that the two required properties are unlikely to hold
for data sets that include signiﬁcant quantities of non-
malicious or normal trafﬁc. Properties of normal trafﬁc
vary so greatly as to make effective clustering difﬁcult
without additional discrimination metrics. Conversely,
malicious data contains identiﬁable structure even in the
presence of obfuscation and limited polymorphism. Ne-
mean’s use of honeynet data enables a reasonable num-
ber of meaningful clusters to be produced. While each
cluster ideally contains the set of sessions or connec-
tions for some attack, we also presume that this data will
contain minor obfuscations, particularly in the sequential
structure of the data, that correspond to an attacker’s at-
100
14th USENIX Security Symposium
USENIX Association
tempts to evade detection. These variations provide the
basis for our signature generation component.
The automata learning module constructs an attack
signature from a cluster of sessions. A generator is im-
plemented for a target intrusion detection system and
produces signatures suitable for use in that system. This
component has the ability to generate highly expressive
signatures for advanced systems, such as regular expres-
sion signatures with session-level context that are suit-
able for Bro [18, 28]. Clusters that contain many non-
uniform sessions are of particular interest. These differ-
ences may indicate either the use of obfuscation transfor-
mations to modify an attack or a change made to an exist-
ing attack to produce a new variant. Our signature gen-
eration component generalizes these transformations to
produce a signature that is resilient to evasion attempts.
Generalizations enable signatures to match malicious se-
quences that were not observed in the training set.
3.3 Current Limitations
New worms, viruses, and variants of existing malware
appear in the Internet everyday [16], and standard col-
lections of signatures are not able to keep pace. Thus,
the immediate goal for Nemean is to address this gap by
automating signature generation. Nemean does not ad-
dress automating the real-time deployment of signatures.
Given our emphasis on accurate, efﬁcient signatures and
not on timeliness, the current Nemean design includes
the following simple manual selection process:
• Selecting either or both of the generated session and
connection-level signatures for a given cluster. For multi-
step attacks such a Welchia, there is a benign connection
(a GET / request) that precedes the attack sequence. In
this case, the operator simply chooses either the connec-
tion signatures for the following steps of Welchia and/or
the session signature, but whitelists the signature corre-
sponding to the benign ﬁrst step. We provide results from
both connection and session-level signatures for each at-
tack in our evaluation but remove the benign connection
corresponding to Welchia. This was not an issue for other
attacks.
• A sanity check to ensure that a signature corresponds
to an attack cluster and not a misconﬁguration or inten-
tional data pollution. While this is not an issue in our
evaluation dataset, we consider this necessary for an op-
erational deployment. One of the interesting aspects of
our semantics-aware approach is that it results in signa-
tures with semantic context that are easily parsed. Mis-
conﬁguration could likely be separated by picking from
clusters with a large number of sources sent to a large
number of destinations5. However, fully-automating Ne-
mean and making it immune to data pollution remains an
area of future work.
One reason for this requirement is that unlike systems
such as EarlyBird and Autograph, the target of attacks
we seek to address is much broader than ﬂash worms.
It includes everyday targeted attacks, viruses spreading
through network shares and botnet sweeps that occur be-
low the noise thresholds and look similar to misconﬁg-
uration. We expect intentional data pollution through
large botnets to be an issue for aforementioned systems
as well.
4 DAC Implementation
We have implemented prototypes of each Nemean com-
ponent. While the Nemean design provides ﬂexibility
to handle any protocol, we focus our discussion on two
speciﬁc protocol implementations, HTTP (port 80) and
NetBIOS/SMB (ports 139 and 445), since these two ser-
vices exhibit great diversity in the number and types of
exploits.
• Transport-Level Normalization: Transport-level
normalization resolves ambiguities introduced at the net-
work (IP) and transport (TCP) layers of the protocol
stack. We check message integrity, reorder packets as
needed, and discard invalid or duplicate packets. The
importance of transport layer normalizers has been ad-
dressed in the literature [6, 21]. Building a normalizer
that perfectly resolves all ambiguities is a complicated
endeavor, especially since many ambiguities are operat-
ing system dependent. We can constrain the set of nor-
malization functions for two reasons. First, we only con-
sider trafﬁc sent to honeynets, so we have perfect knowl-
edge of the host environment. This environment remains
relatively constant. We do not need to worry about am-
biguities introduced due to DHCP or network address
translation (NAT). Second, Nemean’s current implemen-
tation analyzes network traces off-line which relaxes its
state holding requirements and makes it less vulnerable
to resource-consumption attacks.
Attacks that attempt to evade a NIDS by introducing
ambiguities to IP packets are well known. Examples of
such attacks include simple insertion attacks that would
be dropped by real systems but are evaluated by NIDS,
and evasion attacks that are the reverse [21]. Since Ne-
mean obtains trafﬁc promiscuously via a packet sniffer
(just like real a NIDS), these ambiguities must be re-
solved. We focus on three common techniques used by
attackers to elude detection.
First, an invalid ﬁeld in a protocol header may cause
a NIDS to handle the packet differently than the desti-
nation machine. Handling invalid protocol ﬁelds in IP
packets involves two steps: recognizing the presence of
the invalid ﬁelds and understanding how a particular op-
erating system would handle them. Our implementation
performs some of these validations. For example, we
USENIX Association
14th USENIX Security Symposium
101
1. Build the multiset C of all normalized connections.
2. Cluster C into exclusive partitions CL = {ξi}.
3. Produce a connection-level signature φξ for each cluster by generalizing cluster data.
4. Build the multiset S 0 of all sessions. Each session s0 ∈ S 0 is a sequence of identiﬁers denoting the connection
clusters that contain each connection in the session.
5. Cluster S 0 into partitions Ψ = {ψi}.
6. Produce a session-level signature Lψ for each cluster, generalizing the observed connection orderings.
7. Produce a NIDS signature. The signature is a hierarchical automaton where each transition in the session-level
signature requires that the connection-level signature for the identiﬁed connection cluster accepts.
Figure 3: Multi-level Signature Generalization (MSG) algorithm. Section 5 provides more complete details.
drop packets with an invalid IP checksum or length ﬁeld.
Second, an attacker can use IP fragmentation to
present different data to the NIDS than to the desti-
nation. Fragmentation introduces two problems: cor-
rectly reordering shufﬂed packets and resolving over-
lapping segments. Various operating systems address
these problems in different ways. We adopt the always-
favor-old-data method used by Microsoft Windows. A
live deployment must either periodically perform active-
mapping [26] or match rules with passive operating sys-
tem ﬁngerprinting. The same logic applies for frag-
mented or overlapping TCP segments.
Third, incorrect understanding of the TCP Control
Block (TCB) tear-down timer can cause a NIDS to im-
properly maintain state.
If it closes a connection too
early it will lose state. Likewise, retaining connections
too long can prevent detection of legitimate later connec-
tions. Our implementation maintains connection state for
an hour after session has been closed. However, sessions
that have been closed or reset are replaced earlier if a new
connection setup is observed between the same host/port
pairs.
• Service-Level Normalization: We provide a brief
discussion of the implementation of service normalizers
for two popular protocols: HTTP and NetBIOS/SMB.
Ambiguities in HTTP sessions are primarily intro-
duced due to invalid protocol parsing or invalid decod-
ing of protocol ﬁelds. In particular, improper URL de-
coding is a point of vulnerability in many intrusion de-
tection systems. Modern web servers allow substitution
of encoded characters for ASCII characters in the URL
and are often exploited as means for evasion of com-
mon NIDS signatures. Our DAC correctly decodes sev-
eral observed encodings such as hex encoding and its
variants, UTF-8 encoding, bare-byte encoding, and Mi-
crosoft Unicode encoding. Regardless of its encoding,
the DAC presents a canonical URL in ASCII format to
the clustering module. Currently, our implementation
does not handle all obvious HTTP obfuscations. For ex-
ample, we do not process pipelined HTTP/1.1 requests.
Such requests need to be broken into multiple connec-
tions for analysis. We plan to incorporate this function-
ality into our system in the future.
NetBIOS is a session-layer service that enables ma-
chines to exchange messages using names rather than
IP addresses and port numbers. SMB (Server Message
Block) is a transport-independent protocol that provides
ﬁle and directory services. Microsoft Windows ma-
chines use NetBIOS to exchange SMB ﬁle requests. Net-
BIOS/SMB signature evasion techniques have not been
well studied, possibly due to the lack of good NIDS rules
for their detection. A full treatment of possible Net-
BIOS/SMB ambiguities exceeds the scope of this paper.
5 Multi-level Signature Generalization
We designed the Multi-level Signature Generalization
(MSG) algorithm to automatically produce signatures for
normalized session data. The signatures must balance
speciﬁcity to the exploits observed in the data with gen-
erality, the ability to detect attack variants not previously
observed. We use machine-learning algorithms, includ-
ing clustering and ﬁnite state machine generalization, to
produce signatures that are well-balanced.
Due to the hierarchical nature of the session data, we
construct signatures for connections and sessions sepa-
rately. First, we cluster all connections irrespective of the
sessions that contain them and generalize each cluster to
produce a signature for each connection cluster. Second,
we cluster sessions based upon their constituent connec-
tions and then generalize the clusters. Finally, we com-
bine the session and connection signatures to produce
a hierarchical automaton signature, where each connec-
tion in a session signature must match the correspond-
ing connection signature. Figure 3 presents a high-level
overview of the algorithm.
Steps 1 and 2: Generating connection clusters. Let
S be the multiset of normalized sessions produced by the
data abstraction component. Denote each session s ∈ S
as an ordered list of connections: s = c1.c2. · · · .cns
. Let
Conn(s) = {ci}i=1...ns
be the multiset of connections
in s and C = Us∈S Conn(s) be the multiset of all con-
102
14th USENIX Security Symposium
USENIX Association
i=1
nections in the normalized data, where ] denotes multi-
set union. Let CL = {ξi}i=1...m be an exclusive clus-
tering of C into m clusters ξi. Clustering inserts every
element into a partition, soUm
ξi = C. Exclusive clus-
tering requires that no partitions overlap, so ξi ∩ ξj = ∅
for i 6= j. It immediately follows that there exists a well-
deﬁned function Γ : C → CL deﬁned as Γ(c) = ξ if
c ∈ ξ that returns the cluster containing c. Section 5.1
presents the implementation of the clustering algorithm.
Building connection-level signatures.
Learning algorithms generalize the data in each cluster
to produce signatures that match previously unseen con-
nections. Let Σ be the alphabet of network events com-
prising connection data. A learning algorithm is a func-
tion Learn : P(Σ∗) → P(Σ∗) that takes a set of strings
Step 3:
cφξ = Sc∈ξ c and returns a regular language φξ ⊇ cφξ.
Section 5.2 presents the generalization algorithms used
in our work. We recognize φξ with a regular automaton
that is the connection-level signature for cluster ξ.
Steps 4 and 5: Generating session clusters. Rewrite
the existing sessions to produce a new set S 0.
S 0 =
]
(cid:2)s0 = Γ(c1). · · · .Γ(cns
)(cid:3)
s=c1.··· .cns
∈S
From an implementation perspective, each Γ(ci) in a
rewritten session is simply an integer index indicating
which connection cluster contains the original connec-
Intuitively, we allow any connection ci compris-
tion.
ing part of session s to be replaced with any connection
i ∈ Γ(c1) identiﬁed by clustering as similar. Let Ψ be a
c0
clustering of S 0.
Steps 6 and 7: Building session-level signatures. As
with connection-level generalization, construct a regu-
lar language Lψ for each cluster ψ ∈ Ψ that accepts
the sessions in ψ and variants of those sessions. Again,
we recognize the language with a ﬁnite automaton. The
connection cluster identiﬁers Γ(c) label transitions in the
session-level automata. The resulting signature is thus
hierarchical: traversing a transition in the session signa-
ture requires connection data matching the signature for
the connection cluster.
5.1 Star Clustering Implementation
We cluster connections and sessions using the same al-
gorithm. We implemented the on-line star clustering al-
gorithm, which clusters documents based upon a similar-
ity metric [2]. This algorithm has advantages over more
commonly-known techniques, such as the k-means fam-
ily of algorithms [14]. For example, star clustering is ro-
bust to data ordering. Conversely, k-means produces dif-
ferent clusters depending upon the order in which data is
read. Moreover, we need not know a priori how many
start
GET /
200
SEARCH /
411
SEARCH /
411
GET /
200
SEARCH /AAAAAAAAAAAAA [more]
400
SEARCH /AAAAAAAAAAAAA [more]
400
SEARCH /AAAAAAAAAAAAA [more]
400
SEARCH /AAAAAAAAAAAAA [more]
400
end
Figure 4: Welchia session level signature. For brevity,
we label a single transition with both a request and a re-
ply.
clusters are expected. Although it seems suitable, we
make no claims that star is the optimal clustering algo-
rithm for our purposes, and we expect to consider other
algorithms in future work.
Star clustering builds a star cover over a partially-
connected graph. Nodes in the graph each represent one
or more items with semantically equivalent data. We ar-
bitrarily choose one item at each node to be the represen-
tative item. A link exists between two nodes if the sim-
ilarity between the corresponding representative items is
above a designated threshold. A star cluster is a collec-
tion of nodes in the graph such that each node connects
to the cluster center node with an edge. A star cover is
a collection of star clusters covering the graph so that
no two cluster centers have a connecting edge.
In the
original algorithm, a non-center node may have edges to
multiple center nodes and thus appear in multiple clus-
ters. We implemented a modiﬁed algorithm that inserts
a node only into the cluster with which it has strongest
similarity to produce an exclusive clustering.
Item similarity determines how edges are placed in the
graph. We implemented two different similarity metrics
to test sensitivity: cosine similarity [2] and hierarchi-
cal edit distance. The cosine similarity metric has lower
computational complexity than hierarchical edit distance
and was used for our experiments in Section 7.
Cosine similarity computes the angle between two
vectors representing the two items under comparison.
For each connection A, we build a vector DA giving the
distribution of bytes, request types, and response codes
that appeared in the network data. For sessions, the vec-
tor contains the distribution of connection cluster iden-
If θ is the angle between vectors DA and DB
tiﬁers.
representing items A and B, then:
cos θ =
DA · DB
kDAk kDBk
where ‘·’ represents inner product and kvk is the vector
USENIX Association
14th USENIX Security Symposium
103
start
GET
*
start
GET
POST
start
Session Request
Session Response
Negotiate Request
Negotiate Response
Session Setup Andx Request
Tree Connect Andx Request
\ADMIN$????? \IPC$?????
/winnt/system32/cmd.exe [more]
/scripts/nsiislog.dll
Tree Connect Andx Reply
Session Setup Andx Reply
Session Setup Andx Reply
Tree Connect Andx Request
/c+dir
*
*
200
end
200
400
end
Tree Connect Andx Reply
NT Create Andx Request
*
\System32\psexesvc.exe [more]
end
Figure 5: Nimda, Windows Media Player Exploit, and Deloder connection level signatures. The “*” transitions in the
Nimda signature match any σ ∈ Σ∗.
norm. All vector values are non-negative, so 0 ≤ θ ≤
π/2 and 1 ≥ cos θ ≥ 0. The similarity between items is
the value cos θ, with cos θ = 1 indicating equality.
Hierarchical-edit distance is a variation on the tradi-
tional edit-distance metric [2] which measures the cost of
transforming one string into another using insert, delete,
and replace operations. In contrast to the traditional edit-
distance metric, the hierarchical-edit distance metric pre-
serves connection ordering information within each ses-
sion and differentiates between the various data ﬁelds
within each connection. We believed these properties of
the hierarchical-edit distance metric would make it a bet-
ter similarity metric for clustering than the cosine metric.