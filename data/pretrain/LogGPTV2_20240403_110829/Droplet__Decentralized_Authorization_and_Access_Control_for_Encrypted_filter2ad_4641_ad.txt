in time-series data most queries require access to temporally
co-located data [58, 111]. E.g., data analytic apps work with
temporal data records (e.g., all records of a day).
Encryption. Each data chunk is initially compressed and
then encrypted at the source with an efﬁcient symmetric ci-
pher3. We rely on AES-GCM, as an authenticated encryption
scheme. Note that NIST bounds the use of AES-GCM to 232
encryptions for a given key/nonce pair. Due to our frequent
key rotations, we stay far below this threshold. The chunks
have a metadata segment containing, among others, the chunk
identiﬁer, the owner’s address, hashes to previous chunks (§5),
and the stream identiﬁer. The data ﬁeld contains the encrypted
and compressed data records. Services with access to the en-
cryption key can verify the integrity of the chunk and perform
an authenticated decryption. To ensure data ownership, each
chunk is also digitally signed. This allows parties without
access to the encryption key to verify the owner of the data
stream, albeit at a higher computation cost.
Storage Interface. The storage nodes expose a key-value in-
terface, with a common store/get interface with various ﬂavors
of get, such as getAll or getRange. For each incoming request,
the storage node ﬁrst veriﬁes the identity of the client (i.e.,
authentication) and looks up the corresponding access permis-
sions regarding the client’s identity (i.e., authorization). Each
request is accompanied with a universally unique identiﬁer
(UUID), deﬁned as the hash of the tuple: , where streamID is a unique identi-
ﬁer of an owner’s data stream. Traditional indexing for data
retrieval cannot be applied here as data chunks are encrypted.
Hence, we need to devise a mechanism to perform temporal
range queries over encrypted data efﬁciently. To avoid con-
sistency issues of a shared index, we exploit a simple local
lookup mechanism to enable temporal range queries. For a
constant lookup time of a record with timestamp ti, we com-
pute the counter of the chunk holding it based on the known
time interval ∆ of the chunks: (cid:98)(ti −t0)/∆(cid:99). For instance, we
can map the lookup of value 7 in Figure 7 to the identiﬁer
3 Note that it is important to apply padding to prevent inference attacks
based on the varying sizes of the chunks.
of chunk #1. The chunk metadata is included in the initial
stream registering transaction, as depicted in Figure 6. Note
that the chunk metadata additionally enables freshness checks
for chunks, since the chunk interval indicates the frequency
and time at which new data chunks are generated.
Strong Data Immutability. While Droplet provides in-
tegrity protection via authenticated encryption and digital
signatures, the data owner can still modify old data. Speciﬁc
applications might require a stronger notion of immutability
such that even the data owner can no longer modify the data
(e.g., contractual agreements in logistics). Droplet enables
such a notion of immutability through blockchain’s append-
only property [25]. The application developer can deﬁne a
grace period, after which data chunks become immutable.
For sensitive applications, this can be per chunk. Otherwise,
a more extended period can be selected. To accommodate
for the narrow bandwidth of blockchains, we leverage an an-
choring technique, where data immutability transactions are
reduced to the level of the grace period. To realize this, the
ﬁrst data chunk holds a pointer to the registration transac-
tion, and after the grace period, a transaction with a pointer
to the latest chunk is issued, as depicted in Figure 8. Since
all data chunks are cryptographically linked via hashes, all
data chunks in the grace period become immutable at once,
forming a chain of data chunks. To avoid a linear veriﬁcation
time, chunks hold hashes to several previous chunks, forming
a geometric series (i.e., logarithmic veriﬁcation time).
6 Privacy and Security Analysis
Authorization. In conventional authorization frameworks,
i.e., OAuth, any entity in possession of the bearer token can as-
sume the same access permissions granted to the token [100].
In case of token theft, the adversary in possession of the to-
ken can gain unauthorized access to the user’s resources (i.e.,
impersonation attack). Moreover, the compromise of an au-
thorization server enables the issuance of unauthorized access
tokens for all registered resources at the authorization server.
Droplet is not susceptible to these attacks. In Droplet, an au-
thorization claim with the scope of access is logged in the
blockchain in a privacy- preserving manner, such that only
the authorized party in possession of the correct private key
can claim ownership for data access, in a publicly-veriﬁable
manner. For an adversary to alter access permissions in the
blockchain, it requires forging a digital signature (i.e., break-
ing public key cryptography with a 128-bit security level) or
gaining control over the majority of the computing power in
the blockchain network (i.e., 51% attack [3]). Existing pro-
duction blockchains, e.g., Bitcoin or Ethereum, can be subject
to security attacks, such as routing [7] and selﬁsh mining [46],
which can lead to access permission state update transactions
to be dropped, delayed, or excluded. An active adversary can
employ these attacks to prevent/delay access permission mod-
iﬁcations of victims from taking effect. However, none of
these attacks can lead to unauthorized access permission.
USENIX Association
29th USENIX Security Symposium    2477
Val 1Val 2Val 3Val 4Val 5Val 6Val 7Val 8Val 9Val 10Chunk #0Chunk #1Chunk #2…Stored in the storage layertimet0t1t2Hash linkHash linkStored in the storage layerHash linkHash linkBlockchainincontrol layerEmbedded Hash linkHash link to initialtransaction…timet0t1Val1Val2Val3Val4Val5Val6Val7Val8Val9Val10Chunk #0Chunk #1Chunk #2…Stored in the storage layertimet0t1t2Figure 8: Example of immutable chunks, with a grace pe-
riod (t1 −t0). Chunks are cryptographically linked together,
forming a geometric series, enabling faster integrity checks.
An adversary is not capable of learning sensitive informa-
tion from the public blockchain, since only unlinkable pseudo-
identities and stream identiﬁers are stored. In proﬁling attacks,
the adversary creates proﬁles of all user identiﬁers and the net-
work of users [77]. An adversary can break the pseudonymity
of speciﬁc users. Hence, a large body of research aims at
concealing identity and relationships in public blockchains
while maintaining veriﬁability [27, 57, 92]. Droplet employs
dual-key stealth addresses, where the anonymity set is equal
to the set of users using non-spendable stealth addresses.
A malicious storage node (or authorization agent) could
hand out data without permission or data leakage might take
place due to system compromise. However, the impact of this
action is limited since data is end-to-end encrypted. Moreover,
leakage of a data encryption key results only in the disclosure
of the data stream segment associated with it. The compro-
mised key cannot be used to disclose old data nor can it be
used to gain access to future data due to pre-image resistance
property of hash functions. The distribution key (KD) for con-
tinuous stream subscription gives access to the latest token
from the primary chain. The compromise of KD has no im-
pact without access to the aligned token from the secondary
chain (Figure 4) since both tokens are required to compute
data encryption keys. An attacker needs to compromise an
authorized user’s private key to gain access to tokens from
the secondary chain. The blockchain provides auditable infor-
mation about when a stream was shared with whom; a crucial
piece of evidence to prove/disprove access rights violations
should the need arise.
Data Serialization. Data chunks are encrypted, integrity
protected, and authenticated. Any data chunk manipulations
are detectable via the digital signature and authenticated en-
cryption. Note that while a property of AES-GCM can be
exploited to ﬁnd collisions within ciphertexts that decrypt
to different valid plaintexts [39], the per chunk signature in
Droplet protects us from such an attack. The optional data
immutability is based on the security and immutability of
blockchain. The secure channel (i.e., TLS) for storing and
fetching data prevents replay attacks, in addition to ensuring
an authenticated and conﬁdential channel. An adversary with
access to disclosed encryption keys cannot alter old data, as
it requires access to the signing private key.
AES Encrypt
[µs]
[op/s]
SHA Hash
[µs]
[op/s]
ECDSA Sign
[ms]
[op/s]
IoT SW 298
IoT HW 42
50
Phone
Laptop
5.4
2.6
Cloud
3.4k
23.8k
20k
185k
384k
297
17
45
1.6
1.2
3.4k
58.8k
22.2k
623k
833k
270
174
4.4
1.3
1.1
3.7
5.7
227
770
909
Table 1: Performance of security operations – 128-bit security.
For IoT devices, we use OpenMote microcontrollers with
software (SW) computations or crypto accelerators (HW). As
a smartphone, we use a Nexus 5. As a laptop, we use Macbook
Pro. For the cloud, we use an Amazon t2.micro instance.
Implementation
7
Our reference implementation of Droplet is composed of
three entities implemented in Python: the client engine, the
storage-node engine, and the authorization agent. The client
engine is implemented in 1700 sloc. We utilize Pythons’s
cryptography library [89] for our crypto functions. For com-
pression, we use Lepton [41] for images and zlib [34] for
all other value types.
The storage engine can either run on the cloud or nodes of
a p2p storage network. For the cloud, we have integrated a
driver for Amazon’s S3 storage service.
We have as well a realization of Droplet with a serverless
computing platform with ASW Lambda serving as the in-
terface to the storage (i.e., S3). Once Lambda is invoked, it
performs a lookup in the access control state machine to pro-
cess the authorization request. For comparison, we implement
as well an OAuth2 authorization, based on AWS Cognito [11].
For the distributed storage, we build a DHT-based storage
network. We instantiate a Kademlia library [90] and extend it
with the security features of S/Kademlia [17]. On the p2p stor-
age nodes, we employ LevelDB [74]. Our extensions amount
to 2400 sloc.
The authorization agent is implemented with the virtu-
alchain library [3] to maintain the access control state ma-
chine. The virtualchain scans the blockchain, ﬁlters relevant
transactions, validates the encoded operations, and applies the
outcome to the global state. The state is persisted in an SQLite
database. The global state can either be queried through a
REST API or accessed directly through the SQLite database.
Our extensions to the virtualchain amount to 1400 sloc. As
the underlying blockchain, we employ a Bitcoin test-network
with a block generation time of 15 s.
8 Evaluation
Goals. One of our primary goals was to develop Droplet as
a practical system, which translates to ensuring: that Droplet
can (i) be supported by existing resource-constrained IoT
devices, (ii) sustain a high access permission lookup and
veriﬁcation throughput, and (iii) that the overhead to both
2478    29th USENIX Security Symposium
USENIX Association
Stored in the storage layerHash linkHash linkBlockchainincontrol layerEmbedded Hash linkHash link to initialtransaction…timet0t1data on storageblockchainembedded hash linkhash link to initialtransaction…timet0t1hash links(a) Average throughput for get.
(b) Latency for single store and get requests.
Figure 9: store/get performance for centralized and decentralized storage layers. The latency for the decentralized storage is
dominated by network routing. For fairness, all settings, including Vanilla S3 (w/o Droplet) operate on compressed data chunks.
data owners and consumers is low, allowing consumers to
process large volumes of data streams. Hence, our evaluation
metrics include the overheads (CPU, memory) that Droplet
imposes on each party, as well as the end-to-end throughput
and latency that apps experience with Droplet. Our evaluation
is conducted in the context of real-world devices, datasets,
and runtime environments.
Devices. We perform our evaluation on the following four de-
vice classes: (i) IoT: OpenMotes equipped with 32-bit ARM
Cortex-M3 SoC at 32 MHz, a public-key crypto accelerator
running up to 250 MHz. Fitbit trackers utilize a similar class
of micro-controllers; (ii) smartphone: LG Nexus5 equipped
with a 2.3 GHz quad-core 64-bit CPU, 2 GiB RAM; (iii) lap-
top: MacBook Pro equipped with 2.2 GHz Intel i7, 8 GiB
RAM; (iv) Cloud: EC2 t2.micro (1 vCPU, 1 GiB RAM).
Datasets. We validate the applicability of Droplet by de-
ploying three real-world IoT applications atop of Droplet
and quantifying the end-to-end overhead due to our system;
(i) for the Fitbit activity tracker, we use the anonymized ﬁtness
tracker data of the co-authors over one year (16 data types,
130 MB), which we use to synthesize data for an arbitrary
number of users. (ii) for the Ava health tracker [9], we use an
anonymized dataset from Ava [9] (10 s intervals, 13 sensors,
1.3 GB). (iii) for the ECOviz smart meter dashboard, we use
the publicly available anonymized ECO dataset (1.85 GB) for
6 households over 8 months [18].
Storage Infrastructure and Runtime Environment. We
run Droplet on both centralized and decentralized storage
layers. For the former, we use Amazon’s S3 service, and
for the latter, we implement and run several DHT nodes in
real-time on an emulated network (e.g., using netem [82]).
Evaluating Droplet in a decentralized storage setting is a com-
pelling case, as peer-to-peer storage networks could become
a viable solution for the IoT [110]. Additionally, this setup
resembles storage-oriented blockchains (e.g., Storj [103], File-
coin [102]), which still lack adequate mechanisms for secure
data sharing, where Droplet can be helpful. We also evaluate
Droplet’s performance in a serverless setting (Lambda [12])
and compare it to OAuth2 authorization. Emerging server-
less platforms require request-level authorization [1], where
Droplet can serve as an Authorization as a Service.
8.1 Microbenchmark
We instrument the client engine to perform the microbench-