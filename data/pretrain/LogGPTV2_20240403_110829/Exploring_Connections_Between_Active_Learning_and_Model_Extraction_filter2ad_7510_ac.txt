examples of this follow.
Example 3 (Decision tree extraction via QS active learning).
Let Fn,BF denote the set of boolean functions with domain
{0, 1}n and range {−1, 1}. The reader can think of −1 as 0
and +1 as 1. Using the range of {−1, +1} is very common
in the literature on learning boolean functions. An interesting
subset of Fn,BF is given by the functions that can be repre-
sented as a boolean decision tree. A boolean decision tree
T is a labeled binary tree, where each node v of the tree is
labeled by Lv ⊆ {1,··· , n} and has two outgoing edges. Every
leaf in this tree is labeled either +1 or −1. Given an n-bit
string x = (b1,··· , bn), bi ∈ {0, 1} as input, the decision tree
deﬁnes the following computation: the computation starts at
the root of the tree T . When the computation arrives at an
internal node v, we calculate the parity of ∑i∈Lv bi and go left
if the parity is 0 and go right otherwise. The value of the
leaf that the computation ends up in is the value of the func-
tion. We denote by F m
n,BT the class of boolean decision trees
with n-bit input and m nodes. Kushilevitz and Mansour [35]
present an active learning algorithm for the class Fn,BF that
works in the QS scenario. This algorithm utilizes the uniform
error to determine the stopping condition (refer § 2.2). The
authors claim that this algorithm has practical efﬁciency when
1314    29th USENIX Security Symposium
USENIX Association
n,BT .
restricted to the classes F m
n,BT ⊂ Fn,BF for any m. In partic-
ular, if the active learner L of [35] interacts with the oracle
OT∗ where T ∗ ∈ F m
n,BT , then L learns g ∈ Fn,BF such that
Prx∼{0,1}n[g(x) 6= T ∗(x)] ≤ ε with probability at least 1− δ
using a number of queries polynomial in n, m, 1
ε and log( 1
δ ).
Based on Observation 1, this directly translates to the exis-
tence of an adversary that implements ε-extraction with com-
plexity polynomial in n, m, 1
ε and conﬁdence 1− δ against
the class F m
Moreover, the algorithm [35] can be extended to (a)
boolean functions of the form f : {0, 1, . . . , k − 1}n →
{−1, +1} that can be computed by a polynomial-size k-ary
decision tree4, and (b) regression trees (i.e., the output is a real
value from [0, M]). In the second case, the running time of
the learning algorithm is polynomial in M (refer § 6 of [35]).
Note that the attack model considered here is a stronger model
than that considered by Tramèr et al. [55] because the at-
tacker/learner does not get any information about the internal
path of the decision tree (refer Remark 2).
Example 4 (Halfspace extraction via QS active learning).
Let Fd,HS be the hypotheses class of d-dimensional half-
spaces deﬁned in Example 1. Alabdulmohsin et al. [3]
present a spectral algorithm to learn a halfspace in the QS
scenario that, in practice, outperformed earlier active learning
strategies in the PAC scenario. They demonstrate, through
several experiments that their algorithm learns fw ∈ Fd,HS
such that kw − w∗k2 ≤ ε with approximately 2d log( 1
ε )
queries, where fw∗ ∈ Fd,HS is the labeling function used by O.
It follows from Observation 1 that an adversary utilizing this
algorithm implements ε-extraction against the class Fd,HS
with complexity O(d log( 1
ε )) and conﬁdence 1. We validate
the practical efﬁcacy of this attack in § 6.
Remark 2 (Extraction with auxiliary information). Observe
that we deﬁne model extraction for only those MLaaS servers
that return only the label value y for a well-formed query x
(i.e. in the oracle access setting). A weaker model considers
the case of MLaaS servers responding to a user’s query x
even when x is incomplete (i.e. with missing features), and
returning the label y along with some auxiliary information.
The work of Tramèr et al. [55] proves that model extraction
attacks in the presence of such “leaky servers” are feasible
and efﬁcient (i.e. low query complexity) for many hypoth-
esis classes (e.g., logistic regression, multilayer perceptron,
and decision trees). In particular, they propose an equation
solving attack [55, Section 4.1] that uses the conﬁdence val-
ues returned by the MLaaS server together with the labels
to steal the model parameters. For example, in the case of
logistic regression, the MLaaS server knows the parameters
a0, a1, . . . , ad and responds to a query x with the label y (y = 0
if (1 + e−a(x)) ≤ 0.5 and y = 1 otherwise) and the value a(x)
as conﬁdence value for y. Clearly, the knowledge of the con-
ﬁdence values allows an adversary to implement the same
attack we describe in Example 2 for linear regression models.
In [55, §4.2], the authors describes a path-ﬁnding attack that
use the leaf/node identiﬁer returned by the server, even for
incomplete queries, to steal a decision tree. These attacks
are very efﬁcient (i.e., d + 1 queries are needed to steal a
d-dimensional logistic regression model). However, their efﬁ-
ciency heavily relies on the presence of the various forms of
auxiliary information provided by the MLaaS server. While
the work in [55] performs preliminary exploration of attacks
in the black-box setting [17, 38], it does not consider more
recent and efﬁcient algorithms in the QS scenario. Our work
explores this direction through a formalization of the model
extraction framework that enables understanding the possi-
bility of extending/improving the active learning attacks pre-
sented in [55]. Furthermore, having a better understanding of
model extraction attack and its unavoidable connection with
active learning is paramount for designing MLaaS systems
that are resilient to model extraction.
4 Non-linear Classiﬁers
This section focuses on model extraction for two important
non-linear classiﬁers: kernel SVMs and discrete models (i.e.
decision trees and random forests). For kernel SVMs our
method is a combination of the adaptive-retraining algorithm
introduced by Tramèr et al. and the active selection strategy
from classic literature on active learning of kernel SVMs [12].
For discrete models our algorithm is based on the importance
weighted active learning (IWAL) as described in [11]. Note
that decision trees for general labels (i.e. non-binary case) and
random forests was not discussed in [11].
4.1 Kernel SVMs
In kernel SVMs (kSVMs), there is a kernel K : X× X → R
associated with the SVM. Some of the common kernels are
polynomials and radial-basis functions (RBFs). If the ker-
nel function K(., .) has some special properties (required by
classic theorem of Mercer [40]), then K(., .) can be replaced
with Φ(.)T Φ(.) for a projection/feature function Φ. In the
feature space (the domain of Φ) the optimization problem is
as follows5:
minw,bkwk2 +C ∑n
i=1 ηi
such that for 1 ≤ i ≤ n
yi ˆy(xi) ≥ 1− ηi
ηi ≥ 0
In the formulation given above, ˆy(x) is equal to wT Φ(x) + b.
Recall that prediction of the kSVM is the sign of ˆy(x), so ˆy(x)
is the “pre sign” value of the prediction. Note that for some
kernels (e.g. RBF) Φ is inﬁnite dimensional, so one generally
uses the “kernel trick”i.e. one solves the dual of the above
4A k-ary decision tree is a tree in which each inner node v has k outgoing
edges.
5we are using the formulation for soft-margin kSVMs
USENIX Association
29th USENIX Security Symposium    1315
problem and obtains a kernel expansion, so that
ˆy(x) =
n
∑
i=1
αiK(x, xi) + b
The vectors x1,··· , xn are called support vectors. We assume
that hyper-parameters of the kernel (C, η) are known; one can
extract the hyper-parameters for the RBF kernel using the
extract-and-test approach as Tramèr et al. Note that if Φ is
ﬁnite dimensional, we can use an algorithm (including active
learning strategies) for linear classiﬁer by simply working in
the feature space (i.e. extracting the domain of Φ(·)). How-
ever, there is a subtle issue here, which was not addressed
by Tramèr et al. We need to make sure that if a query y is
made in the feature space, it is “realizable” (i.e. there exists
a x such that Φ(x) = y). Otherwise the learning algorithm is
not sound.
Next we describe our model-extraction algorithm for
kSVMs with kernels whose feature space is inﬁnite dimension
(e.g. RBF or Laplace kernels). Our algorithm is a modiﬁca-
tion of the adaptive training approach from Tramèr et al. Our
discussion is specialized to kSVMs with RBFs, but our ideas
are general and are applicable in other contexts.
Extended Adaptive Training (EAT): EAT proceeds in mul-
tiple rounds. In each round we construct h labeled instances.
In the initial stage (t = 0) we draw r instances x1,··· , xr from
the uniform distribution, query their labels, and create an ini-
tial model M0. Assume that we are at round t, where t > 0,
and let Mt−1 be model at time t − 1. Round t works as follows:
create h labeled instances using a strategy StT (Mt−1, h) (note
that the strategy St is oracle access to the teacher, and takes
as parameters model from the previous round and number of
labeled instances to be generated). Now we train Mt−1 on the
instances generated by StT (Mt−1, h) and obtain the updated
model Mt . We keep iterating using the strategy StT (·,·) un-
til the query budget is satisﬁed. Ideally, StT (Mt−1, h) should
be instances that the model Mt−1 is least conﬁdent about or
closest to the decision boundary.
Tramèr et al. use line search as their strategy StT (Mt−1, h),
which can lead to several queries (each step in the binary
search leads to a query). We generate the initial model M0
as in Tramèr et al. and then our strategy differs. Our strat-
egy StT (Mt−1, 1) (note that we only add one labeled sample
at each iteration) works as follows: we generate k random
points x1,··· , xk and then compute ˆyi(xi) for each xi (recall
that ˆyi(xi) is the “pre sign” prediction of xi on the SVM Mt−1.
We then pick xi with minimum | ˆyi(xi) | and query for its label
and retrain the model Mt−1 and obtain Mt . This strategy is
called active selection and has been used for active learning of
SVMs [12]. The argument for why this strategy ﬁnds the point
closest to the boundary is given in [12, §4]. There are other
strategies described in [12], but we found active selection to
perform the best.
4.2 Decision Trees and Random Forests
Next we will describe the idea of importance weighted ac-
tive learning (IWAL) [11]. Our discussion will be specialized
to decision trees and random forests, but the ideas that are
described are general.
Let H be the hypothesis class (i.e. space of decision trees or
random forests), X is the space of data, and Y is the space of la-
bels. The active learner has a pool of unlabeled data x1, x2,··· .
For i > 1, we denote by X1:i−1 the sequence x1,··· , xi−1. After
having processed the sequence X1:i−1, a coin is ﬂipped with
probability pi ∈ [0, 1] and if it comes up heads, the label of
xi is queried. We also deﬁne a set Si (S0 = /0) recursively as
follows: If the label for xi is not queried, then Si = Si−1; oth-
erwise Si = Si−1 ∪ (xi, yi, pi). Essentially the set Si keeps the
information (i.e. data, label, and probability of querying) for
all the datapoints whose label was queried. Given a hypothesis
h ∈ H , we deﬁne err(h, Sn) as follows:
err(h, Sn) =
1
n ∑
(x,y,p)∈Sn
1
p
1h(x)6=y
(2)
Next we deﬁne the following quantities (we assume n ≥ 1):
hn = argmin{err(h, Sn−1) : h ∈ H }
h′n = argmin{err(h, Sn−1) : h ∈ H ∧ h(Xn) 6= hn(Xn)}
Gn = err(h′n, Sn−1)− err(hn, Sn−1)
Recall that pn is the probability of querying for the label for
Xn, which is deﬁned as follows:
if Gn ≤ µ(n)
s(n) otherwise
n−1 , and s(n) ∈ (0, 1) is the posi-
pn =(cid:26) 1
Where µ(n) =q c0 log n
n−1 + c0 log n
Gn = (cid:18)
c1√s− c1 + 1(cid:19)·r c0 log n
n− 1
tive solution to the following equation:
+(cid:18)
c2√s− c2 + 1(cid:19)·
c0 log n
n− 1
Note the dependence on constants/hyperparameters c0, c1
and c2, which are tuned for a speciﬁc problem (e.g. in their
experiments for decision trees [11, §6] the authors set c0 = 8
and c1 = c2 = 1).
Decision Trees: Let DT be any algorithm to create a decision
tree. We start with an initial tree h0 (this can constructed using
a small, uniformly sampled dataset whose labels are queried).
Let hn be the tree at step n− 1. The question is: how to con-
struct h′n? Let xn be the nth datapoint and Y = {l1,··· , lr} be
the set of labels. Let hn(xn) = l j. Let hn(l) be the modiﬁcation
of tree hn such that hn(l) produces label l 6= hn(xn) on data-
point xn. Let h′n be the tree in the set {hn(l) | l ∈ Y−{l j}}
that has minimum err(·, Sn−1). Now we can compute Gn and
the algorithm can proceed as described before.
Random Forests: In this case we will restrict ourselves to
binary classiﬁcation, but the algorithm can readily extended to
1316    29th USENIX Security Symposium
USENIX Association
the case of multiple labels. As before RF0 is the random forest
trained on a small initial dataset. Since we are in the binary
classiﬁcation domain, the label set Y = {1,−1}. Assume that
we have a random forest RF = {RF[1],··· , RF[o]} of trees
RF[i] and on a datapoint x the label of the random forest RF(x)
is the majority of the label of the trees RF[1](x),··· , RF[o](x).
Let RFn be the random forest at time step n− 1. The question
again is: how to construct RF′n? Without loss of generality, let
us say on xn RFn(xn) = +1 (the case when the label is −1 is
symmetric) and there are r trees in RFn (denoted by RF +1
(xn))