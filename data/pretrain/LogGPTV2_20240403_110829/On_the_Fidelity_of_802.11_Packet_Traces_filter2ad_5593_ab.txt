S
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 10
 20
 30
 40
 50
 100000
 10000
 1000
 100
 10
 1
e
r
o
c
S
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 10
 20
 30
 40
 50
 100000
 10000
 1000
 100
 10
 1
e
r
o
c
S
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 10
 20
 30
 40
 50
 100000
 10000
 1000
 100
 10
 1
Load (change in sequence number)
Load (change in sequence number)
Load (change in sequence number)
Fig. 4. Trace completeness visualization for Portland PDX traces [13]
IETF 2005 chan. 6 ple
IETF 2005 chan. 1 day
IETF 2005 chan. 6 day
e
r
o
c
S
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 10
 20
 30
 40
 50
 10000
 1000
 100
 10
 1
e
r
o
c
S
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 10
 20
 30
 40
 50
 10000
 1000
 100
 10
 1
e
r
o
c
S
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 10
 20
 30
 40
 50
 10000
 1000
 100
 10
 1
Load (change in sequence number)
Load (change in sequence number)
Load (change in sequence number)
Fig. 5. Trace completeness visualization for IETF 2005 conference traces [9]
5.2 Case Studies
We analyzed the completeness of several traces obtained from CRAWDAD using
the T-Fi visualization. We show two sets of traces: the Portland PDX VWave
dataset and traces collected during the 2005 IETF meeting. Monitors from these
traces may have captured unintended traﬃc from outside sources. The T-Fi plots
shown in Figs. 4 and 5 are ﬁltered to show only the BSS with the highest traﬃc.
Portland PDX. traces show how specialized 802.11 monitor equipment can
improve trace quality. Phillips et al. [13] used a VeriWave WT20 commercial
wireless monitor to capture their traces. VeriWave has a hardware radio inter-
connect to provide real time merging with 1 microsecond synchronization accu-
racy. UG has the best combination of high score and load. UG’s T-Fi plot has a
wide shaded region scoring 1 covering load values 1 to 40. This trace is close to
complete and contains both high and low load epochs; Fig. 3 (left) represents a
comparatively incomplete trace.
The pioneer trace (Fig. 4 center) was captured from an outdoor courtyard.
Even with powerful monitor hardware, the monitor missed many packets in the
pioneer trace. The trace contains a wide range of load values (1 to 50) but rarely
scored above 0.5 in higher load epochs. Evidently, the pioneer trace is missing
packets independently of the load. We believe the clients and AP captured by
the trace were out of range or the monitor was receiving interfered signals. The
psu-cs T-Fi plot (Fig. 4 right) has few dark-colored regions, indicating that there
was low load on the network.
On the Fidelity of 802.11 Packet Traces
139
Idle
Busy
 800
 600
 400
 200
 0
-200
-400
-600
)
c
e
s
o
r
c
m
i
(
e
c
n
e
r
e
f
f
i
d
k
c
o
C
l
 800
 600
 400
 200
 0
-200
-400
-600
)
c
e
s
o
r
c
m
i
(
e
c
n
e
r
e
f
f
i
d
k
c
o
C
l
-800
 250
 300
 350
-800
 1000
 1050
 1100
1 Beacon interval (50msec)
1 Beacon interval (50msec)
Fig. 6. Diﬀerence in monitor timestamps and beacon timestamps for the Sigcomm’04
“chi” trace (top left), with the load shown (bottom left). A controlled experiment with
50msec beacon intervals without load (middle) and with (right).
IETF 2005. traces exhibit high score variability under any given load. A load
that scores consistently is represented in a T-Fi plot by a column that has only
a few dark bars close together. This can be seen at sequence number change
40 on the T-Fi plot of “chan 6 ple” in Fig. 5. If the score varies greatly for a
sequence number change the column will consist of similar colored bars; “chan
1 day” shows this behavior between sequence number changes 10 and 40.
The traces captured during the plenary sessions are of higher quality than the
day sessions, showing the apparent eﬀects of mobility on trace completeness. T-Fi
plots of the day traces in Figure 5 do not score as highly as the plenary trace. For
example, the plenary session traces score higher in high bandwidth epochs. We
posit that the day traces scored lower in high bandwidth epochs because clients
are mobile during the day. During the plenary sessions, the meeting participants
were likely to be stationary more often than in the day traces.
6 Timestamp Accuracy
The accuracy of a trace’s timestamps is important for many applications; merg-
ing algorithms [5, 10], for instance, use monitor and beacon timestamps to form
a single, coherent view of the wireless network as viewed from potentially many
monitors. A common assumption in these algorithms is that the diﬀerence be-
tween a monitor’s timestamp—stamped in the kernel or the device itself—and
the AP’s timestamp—included in the beacon packet—is predictable and consis-
tent on at least the order of beacon intervals (100msec).
We test this hypothesis by observing the diﬀerence between monitor times-
tamp and beacon timestamp over time throughout a trace. For the Sigcomm’04
trace (Fig. 6 left), we plot the clock diﬀerence (top) and the load in number of
packets captured (bottom). The clock diﬀerence is not consistent from one bea-
con interval to the next, indicating that there is clock skew at the monitor and/or
the AP. To see whether the clock diﬀerence was at least consistent within a given
beacon interval, we collected our own trace using the MeshTest testbed [6] with
a beacon interval of 50msec. When no clients are sending data (Fig. 6 middle),
140
A. Schulman, D. Levin, and N. Spring
the clock diﬀerence does change between normal (100msec) beacon intervals, but
in what appears, in this case at least, to be a predictable manner. However, when
a client is sending (Fig. 6 right), the clock changes are not predictable, again
indicating a correlation of clock diﬀerence with load.
These results show that the common assumption underlying known merging
algorithms is false. The question remains whether this is suﬃcient to cause a
mis-ordering of packets. Though we have observed mis-orderings from Wit [10],
it is unclear whether this is due to an algorithmic error or simply a bug in Wit.
Nonetheless, we propose as a sanity check that merging algorithms ensure proper
sequence number order (not necessarily strictly increasing: §7).
7 Discussion
We considered the problem of quantifying wireless trace ﬁdelity and evaluated
a scoring method, proposed the T-Fi visualization, and presented an analysis of
clock accuracy in wireless traces. Wireless trace ﬁdelity applies when choosing,
improving, or inferring gaps in wireless traces.
Choosing a trace. Researchers will choose traces from a repository like CRAW-
DAD based primarily on the type of data in the trace, for example mobility or
traﬃc type. However, we expect ﬁdelity to decide which trace—or subset of the
trace—to use.
Improving traces. Measuring trace ﬁdelity need not be strictly a post-mortem
analysis; rather, researchers ought to measure the ﬁdelity of their measurements
during their measurement, so that they may, for example, move their monitors.
An interesting and important area of future work is to develop tools to aid in
the active capture of wireless traces, so that researchers can ensure high-ﬁdelity
traces in unique hotspots such as a conference.
We conclude with lessons we learned about merging and processing wireless
traces in the process of working with as many traces as we could collect.
Update tools in accordance with new specs. Tools to measure the ﬁdelity
of wireless traces must be updated frequently, as new 802.11 specs are deployed.
The 802.11e QoS amendment introduced a new sequence number space for QoS
in mid-2006. This did not turn up in our initial testing on the Sigcomm’04
trace, but did in the Portland traces (late 2006), and we had to adjust our tool
accordingly.
Account for vendor-speciﬁc behavior. Some vendors introduce behavior not
speciﬁed in 802.11, and this may make the trace appear to be of lower ﬁdelity. We
observed that the Cisco access point in the Sigcomm’04 trace assigned sequence
numbers to broadcast and multicast packets, then transmitted the packets after
others were sent, causing some sequence numbers to appear out of order. To
account for this, we allowed these packets to appear out of order in sequence
number.
On the Fidelity of 802.11 Packet Traces
141
Acknowledgements. We thank Justin McCann and the anonymous reviewers
for their helpful comments, Brenton Walker and Charles Clancy for allowing us
to use the MeshTest testbed, and Ratul Mahajan for supporting Wit.
References
1. Aguayo, D., Bicket, J., Biswas, S., Judd, G., Morris, R.: Link-level measurements
from an 802.11b mesh network. In: SIGCOMM (2004)
2. ANSI/IEEE. Std 802.11 (1999)
3. Biswas, S., Morris, R.: Opportunistic routing in multi-hop wireless networks. In:
SIGCOMM (2005)
4. Cheng, Y.-C., Afanasyev, M., Verkaik, P., Benk¨o, P., Chiang, J., Snoeren, A.C.,
Savage, S., Voelker, G.M.: Automating cross-layer diagnosis of enterprise wireless
networks. In: SIGCOMM (2007)
5. Cheng, Y.-C., Bellardo, J., Benk¨o, P., Chiang, J., Snoeren, A.C., Voelker, G.M.,
Savage, S.: Jigsaw: Solving the puzzle of enterprise 802.11 analysis. In: SIGCOMM
(2006)
6. Clancy, T., Walker, B.: MeshTest: Laboratory-based wireless testbed for large
topologies. In: TridentCom (2007)
7. CRAWDAD Website, http://crawdad.cs.dartmouth.edu/
8. Haeberlen, A., Mislove, A., Post, A., Druschel, P.: Fallacies in evaluating decen-
tralized systems. In: IPTPS (2006)
9. Jardosh, A., Ramachandran, K.N., Almeroth, K.C., Belding, E.: CRAWDAD data
set ucsb/ietf (v. 2005-10-19) (October 2005), Downloaded from
http://crawdad.cs.dartmouth.edu/ucsb/ietf2005
10. Mahajan, R., Rodrig, M., Wetherall, D., Zahorjan, J.: Analyzing the MAC-level
behavior of wireless networks in the wild. In: SIGCOMM (2006)
11. Navidi, W., Camp, T.: Stationary distributions for random waypoint models. IEEE
Transactions on Mobile Computing 3(1) (2004)
12. Paxson, V.: Strategies for sound Internet measurement. In: IMC (2004)
13. Phillips, C., Singh, S.: CRAWDAD data set pdx/vwave (v. 2007-08-13) (August
2007), Downloaded from http://crawdad.cs.dartmouth.edu/pdx/vwave
14. Rodrig, M., Reis, C., Mahajan, R., Wetherall, D., Zahorjan, J.: Measurement-based
characterization of 802.11 in a hotspot setting. In: E-WIND (2005)
15. Rodrig, M., Reis, C., Mahajan, R., Wetherall, D., Zahorjan, J., Lazowska, E.:
CRAWDAD data set In: uw/sigcomm2004 (v. 2006-10-17) (October 2006), Down-
loaded from http://crawdad.cs.dartmouth.edu/uw/sigcomm2004
16. Yeo, J., Banerjee, S., Agrawala, A.: Measuring traﬃc on the wireless medium:
Experience and pitfalls. Technical report, CS-TR 4421, University of Maryland,
College Park (December 2002) http://hdl.handle.net/1903/124
17. Yeo, J., Youssef, M., Agrawala, A.: A framework for wireless LAN monitoring and
its applications. In: WiSE (2004)
18. Yoon, J., Liu, M., Noble, B.: Random waypoint considered harmful. In: INFOCOM
(2003)