}  
```
调用FlushBuffer将BUFFER刷到内核，内核负责写如磁盘，在写checkpoint WAL前，必须写到磁盘。  
FlushBuffer@src/backend/storage/buffer/bufmgr.c  
```
/*  
 * FlushBuffer  
 *              Physically write out a shared buffer.  
 *  
 * NOTE: this actually just passes the buffer contents to the kernel; the  
 * real write to disk won't happen until the kernel feels like it.  This  
 * is okay from our point of view since we can redo the changes from WAL.  
 * However, we will need to force the changes to disk via fsync before  
 * we can checkpoint WAL.  在写checkpoint WAL前，buffer必须写到磁盘。  
 *  
 * The caller must hold a pin on the buffer and have share-locked the  
 * buffer contents.  (Note: a share-lock does not prevent updates of  
 * hint bits in the buffer, so the page could change while the write  
 * is in progress, but we assume that that will not invalidate the data  
 * written.)  
 *  
 * If the caller has an smgr reference for the buffer's relation, pass it  
 * as the second parameter.  If not, pass NULL.  
 */  
static void  
FlushBuffer(volatile BufferDesc *buf, SMgrRelation reln)  
{  
        XLogRecPtr      recptr;  
        ErrorContextCallback errcallback;  
        instr_time      io_start,  
                                io_time;  
        Block           bufBlock;  
        char       *bufToWrite;  
        /*  
         * Acquire the buffer's io_in_progress lock.  If StartBufferIO returns  
         * false, then someone else flushed the buffer before we could, so we need  
         * not do anything.  
         */  
        if (!StartBufferIO(buf, false))  
                return;  
        /* Setup error traceback support for ereport() */  
        errcallback.callback = shared_buffer_write_error_callback;  
        errcallback.arg = (void *) buf;  
        errcallback.previous = error_context_stack;  
        error_context_stack = &errcallback;  
        /* Find smgr relation for buffer */  
        if (reln == NULL)  
                reln = smgropen(buf->tag.rnode, InvalidBackendId);  
        TRACE_POSTGRESQL_BUFFER_FLUSH_START(buf->tag.forkNum,  
                                                                                buf->tag.blockNum,  
                                                                                reln->smgr_rnode.node.spcNode,  
                                                                                reln->smgr_rnode.node.dbNode,  
                                                                                reln->smgr_rnode.node.relNode);  
        LockBufHdr(buf);  
        /*  
         * Run PageGetLSN while holding header lock, since we don't have the  
         * buffer locked exclusively in all cases.  
         */  
        recptr = BufferGetLSN(buf);  // 这里又一个BUFFER头锁  
        /* To check if block content changes while flushing. - vadim 01/17/97 */  
        buf->flags &= ~BM_JUST_DIRTIED;  
        UnlockBufHdr(buf);  
        /*  
         * Force XLOG flush up to buffer's LSN.  This implements the basic WAL  //  XLOG 强写到buffer lsn位置，  
         * rule that log updates must hit disk before any of the data-file changes  // 确保在此之前数据块改变产生的XLOG都写入磁盘了.  
         * they describe do.  
         *  
         * However, this rule does not apply to unlogged relations, which will be  
         * lost after a crash anyway.  Most unlogged relation pages do not bear  
         * LSNs since we never emit WAL records for them, and therefore flushing  
         * up through the buffer LSN would be useless, but harmless.  However,  
         * GiST indexes use LSNs internally to track page-splits, and therefore  
         * unlogged GiST pages bear "fake" LSNs generated by  
         * GetFakeLSNForUnloggedRel.  It is unlikely but possible that the fake  
         * LSN counter could advance past the WAL insertion point; and if it did  
         * happen, attempting to flush WAL through that location would fail, with  
         * disastrous system-wide consequences.  To make sure that can't happen,  
         * skip the flush if the buffer isn't permanent.  
         */  
        if (buf->flags & BM_PERMANENT)  
                XLogFlush(recptr);  
        /*  
         * Now it's safe to write buffer to disk. Note that no one else should  
         * have been able to write it while we were busy with log flushing because  
         * we have the io_in_progress lock.  
         */  
        bufBlock = BufHdrGetBlock(buf);    
        /*  
         * Update page checksum if desired.  Since we have only shared lock on the  
         * buffer, other processes might be updating hint bits in it, so we must  
         * copy the page to private storage if we do checksumming.  
         */  
        bufToWrite = PageSetChecksumCopy((Page) bufBlock, buf->tag.blockNum);  
        if (track_io_timing)  
                INSTR_TIME_SET_CURRENT(io_start);  
        /*  
         * bufToWrite is either the shared buffer or a copy, as appropriate.  
         */  
        smgrwrite(reln,               //  将BUFFER写入磁盘  
                          buf->tag.forkNum,  
                          buf->tag.blockNum,  
                          bufToWrite,  
                          false);  
        if (track_io_timing)  
        {  
                INSTR_TIME_SET_CURRENT(io_time);  
                INSTR_TIME_SUBTRACT(io_time, io_start);  
                pgstat_count_buffer_write_time(INSTR_TIME_GET_MICROSEC(io_time));  
                INSTR_TIME_ADD(pgBufferUsage.blk_write_time, io_time);  
        }  
        pgBufferUsage.shared_blks_written++;  
        /*  
         * Mark the buffer as clean (unless BM_JUST_DIRTIED has become set) and  
         * end the io_in_progress state.  
         */  
        TerminateBufferIO(buf, true, 0);  
        TRACE_POSTGRESQL_BUFFER_FLUSH_DONE(buf->tag.forkNum,    // 单个buffer块 flush结束  
                                                                           buf->tag.blockNum,  
                                                                           reln->smgr_rnode.node.spcNode,  
                                                                           reln->smgr_rnode.node.dbNode,  
                                                                           reln->smgr_rnode.node.relNode);  
        /* Pop the error context stack */  
        error_context_stack = errcallback.previous;  
}  
```
Write the supplied buffer out.  
smgrwrite@src/backend/storage/smgr/smgr.c  
```
/*  
 *      smgrwrite() -- Write the supplied buffer out.  
 *  
 *              This is to be used only for updating already-existing blocks of a  
 *              relation (ie, those before the current EOF).  To extend a relation,  
 *              use smgrextend().  
 *  
 *              This is not a synchronous write -- the block is not necessarily  
 *              on disk at return, only dumped out to the kernel.  However,  
 *              provisions will be made to fsync the write before the next checkpoint.  
 *  
 *              skipFsync indicates that the caller will make other provisions to  
 *              fsync the relation, so we needn't bother.  Temporary relations also  
 *              do not require fsync.  
 */  
void  
smgrwrite(SMgrRelation reln, ForkNumber forknum, BlockNumber blocknum,  
                  char *buffer, bool skipFsync)  
{  
        (*(smgrsw[reln->smgr_which].smgr_write)) (reln, forknum, blocknum,  
                                                                                          buffer, skipFsync);  
}  
```
最后一步是将前面的write sync 到磁盘.  
smgrsync@src/backend/storage/smgr/smgr.c  
```
/*  
 *      smgrsync() -- Sync files to disk during checkpoint.  
 */  
void  
smgrsync(void)  
{  
        int                     i;  
        for (i = 0; i cycle_ctr = mdsync_cycle_ctr;  
                }  
        }  
        /* Advance counter so that new hashtable entries are distinguishable */  
        mdsync_cycle_ctr++;  
        /* Set flag to detect failure if we don't reach the end of the loop */  
        mdsync_in_progress = true;  
        /* Now scan the hashtable for fsync requests to process */  
        absorb_counter = FSYNCS_PER_ABSORB;  
        hash_seq_init(&hstat, pendingOpsTable);  
        while ((entry = (PendingOperationEntry *) hash_seq_search(&hstat)) != NULL)  
        {  
                ForkNumber      forknum;  
                /*  
                 * If the entry is new then don't process it this time; it might  
                 * contain multiple fsync-request bits, but they are all new.  Note  
                 * "continue" bypasses the hash-remove call at the bottom of the loop.  
                 */  
                if (entry->cycle_ctr == mdsync_cycle_ctr)  
                        continue;  
                /* Else assert we haven't missed it */  