0.18 (0.18)
0.02 (0.04)
0.07 (0.10)
0.07 (0.10)
0.02 (0.05)
0.04 (0.09)
0.03 (0.05)
Mean (Std)
0.88 (0.09)
0.81 (0.24)
0.86 (0.14)
0.91 (0.11)
0.85 (0.23)
0.86 (0.25)
0.89 (0.08)
0.83 (0.15)
0.85 (0.18)
0.91 (0.11)
0.88 (0.12)
0.88 (0.10)
0.95 (0.05)
0.91 (0.09)
0.93 (0.06)
0.98 (0.05)
0.96 (0.08)
0.96 (0.05)
0.88 (0.16)
0.75 (0.31)
0.78 (0.27)
0.89 (0.18)
0.80 (0.30)
0.78 (0.30)
0.89 (0.15)
0.83 (0.15)
0.81 (0.26)
0.91 (0.11)
0.81 (0.20)
0.82 (0.18)
0.98 (0.04)
0.93 (0.10)
0.93 (0.10)
0.98 (0.05)
0.96 (0.09)
0.97 (0.05)
0.87 (0.12)
0.76 (0.28)
0.80 (0.24)
0.88 (0.14)
0.80 (0.27)
0.80 (0.27)
0.89 (0.11)
0.82 (0.12)
0.82 (0.23)
0.90 (0.13)
0.83 (0.14)
0.84 (0.13)
0.96 (0.04)
0.92 (0.09)
0.93 (0.07)
0.98 (0.04)
0.96 (0.08)
0.96 (0.04)
recall =
F -measure = 2 ∗
T P
T P + F N
precision ∗ recall
precision + recall
(4)
(5)
5.3 Classiﬁcation Models & Feature Selection
We studied various models of classiﬁcations. In the ﬁrst
model, we utilized all the features explained in Table 1 for
training and later testing the classiﬁer. Second, in order to
improve the accuracy of the classiﬁcation, we ran a program
to ﬁnd the subset of features that produces the best classiﬁ-
cation results, as using many features can cause over ﬁtting
of the classiﬁer and therefore reduce the accuracy of the fu-
ture prediction, thus removing some features may improve
the accuracy. Therefore, we report, in the next subsection,
the results obtained by using the subset of features that
produces the best average results across all the participants
(users being authenticated) in the study. Third, we ﬁnd the
best subset of features that produces the best classiﬁcation
results per user.
For each of the three classiﬁcation models, we study the
identiﬁcation of the user based on a single game challenge
as well as on combining two challenges. As the average time
for solving a challenge is around 7.5 seconds, we believe that
utilizing two instances of the game challenges to identify the
user is not much of an overhead. However, it may improve
the accuracy by doubling the amount of captured interac-
tions between the user and the challenges.
In a real-life
authentication application, posing the user with two consec-
utive game challenges captures this scenario.
5.4 Classiﬁcation Results
Inter-Session Analysis: As mentioned in Section 4, we
collected data from 98 AMT workers during the ﬁrst day of
our data collection experiment. Each of them completed 60
challenges. We divided the collected data into 98 sets based
on the users’ identities (ids). In order to build a classiﬁer to
authenticate a user based on her gameplay biometrics, we
deﬁned two classes. The ﬁrst class contains the gameplay
data from a given user (to be identiﬁed), and the other class
contains randomly selected gameplay data from other users.
Then, we divided the data into two sets, one for training
and the other for testing. The ﬁrst 40 gameplay instances
of each participant and 40 gameplay instances of the ran-
domly selected set were used to train the classiﬁer, while
the other 20 are used for testing. We have tested our three
classiﬁcation models in two settings to evaluate our system.
In the ﬁrst setting, we used a single gameplay instance to
authenticate the user while in the second setting, we used
two instances of the gameplay to authenticate the user. The
merging is done by averaging all the features from the two
instances.
The results are shown in the ﬁrst row (“Day 1”)of each
block in Table 3. We see that utilizing two gameplay in-
stances is consistently better than using a single instance.
Also, we ﬁnd that the user-speciﬁc model outperforms both
the other models (using all the features and using the
features that provide the best average over all results).
Thereby, the best results are acquired by using the user-
speciﬁc model and merging two challenge instances in which
both the false positive rate and false negative rate = 2%.
Intra-Session Analysis: Our other main goal was to check
the accuracy of the classiﬁer over multiple sessions. As men-
tioned in Section 4, 62 AMT workers participated in the
study in the second day and 36 participated in the study in
the third day. For each of these users, we used the data of
the gameplay of the previous day(s) to train the classiﬁer
and then we tested the classiﬁer with the data collected in
the next day(s).
283
Table 4: Lab-Based Study Results: Performance for the classiﬁer for three diﬀerent classiﬁcation models. The ﬁrst part shows
the performance of the classiﬁer using all the features. The next part shows the results of using the features subset that
provides the best average results. The last part shows the result of using the best features subset for each user. For each of
the models, we show the results of using a single challenge and merging of two challenges. Highlighted cells emphasize the
most interesting results.
FPR
FNR
Precion
Recall
F-Measure
Mean (Std)
All features
Average overall best
User speciﬁc
Single
Merge
Single
Merge
Single
Merge
0.20 (0.12)
0.15 (0.18)
0.18 (0.13)
0.14 (0.15)
0.11 (0.09)
0.04 (0.08)
0.23 (0.14)
0.16 (0.16)
0.22 (0.14)
0.16 (0.14)
0.08 (0.09)
0.05 (0.08)
0.80 (0.10)
0.87 (0.15)
0.82 (0.11)
0.88 (0.12)
0.90 (0.08)
0.97 (0.06)
0.77 (0.14)
0.84 (0.16)
0.78 (0.14)
0.84 (0.14)
0.92 (0.09)
0.95 (0.08)
0.78 (0.10)
0.84 (0.13)
0.80 (0.10)
0.85 (0.10)
0.91 (0.06)
0.95 (0.05)
The results are shown in the second and third rows (“Day
2” and “Day 3”) in each block in Table 3. We ﬁnd that the
performance of the classiﬁer degrades slightly compared to
the ﬁrst day, inter-session analysis. Also, we still found that
merging two instances provides better results than using a
single instance. The best results are again acquired by using
the user-speciﬁc model and merging 2 instances. For the
second day, False Positive Rate = 0.05 and False Negative
Rate = 0.04 and for the third day False Positive Rate = 0.04
and False Negative Rate = 0.03.
Lab-based Study Analysis: Our lab experiment involved
20 participants who were asked to perform the study in con-
trolled settings. All of the participants were asked to solve 60
challenges using the same PC and same setting with min-
imal distraction. The results of the lab based study are
summarized in Table 4. The results indicate that merging
two challenges and using the user speciﬁc model can iden-
tify the user with high accuracy (0.05 False Negative Rate)
and reject the zero eﬀort attackers with high accuracy (0.04
False Positive Rate). The results are in line with the re-
sults acquired from the AMT study, which show that the
performance of the classiﬁer was related to the ability of the
classiﬁer to distinguish users’ unique way of solving the chal-
lenges rather than the platform and the settings they used
while solving the challenges.
5.5 Summary of Results
The results obtained from the classiﬁcation models show
that Gametrics is a viable form of behavioral biometrics.
The results show that the classiﬁer can identify the users
and reject a zero eﬀort attacker with a high overall accuracy,
especially when user-speciﬁc models are employed and two
game instances are merged together.
6.
IMPERSONATION ATTACKS
In Section 5.4, we demonstrated that Gametrics is robust
against zero-eﬀort attacks, reﬂected in the low False Positive
Rate. In this section, we analyze the security of Gametrics
against deliberate impersonation attacks
We ﬁrst considered shoulder-surﬁng impersonation at-
tacks. During the lab-based study’s data collection, a re-
searcher in our group served the role of an attacker, and
monitored, through video recording, the participants while
they were solving the challenges. For the impersonation at-
tack analysis, the attacker picked one of the participants who
had the most similar features, such as the time duration and
Table 5: Shoulder-Surﬁng Impersonation Attack Results
All features
Average overall best
User speciﬁc
FPR
0.15
0.07
0.20
0.10
0.31
0.03
Single
Merge
Single
Merge
Single
Merge
mouse movement speed, as that of the attacker, and tried to
mimic that participant by solving the challenges in a similar
way as the participant did for 60 times. Making a selec-
tion in this fashion is representative of a powerful scenario
where the attacker targets victims who are easier to attack.
If we can show that our Gametrics system can be resistant
to such a powerful attacker, it may be even more resistant
to other weaker, more realistic attackers who may not have
the capability to make such selections.
The performance of this attack is enumerated in Table 5.
For the user-speciﬁc model, the attack success rate came out
to be 0.31 when single instance of the challenges was used by
the classiﬁer, and decreased drastically to 0.03 when merg-
ing of two instances is used by the classiﬁer. There are two
main reasons for the increase in security when merging two
instances. First, the features that were used for the classiﬁ-
cation in the single instance model (i.e., the features subset
that yielded the highest classiﬁcation accuracy in the benign
and zero-eﬀort case) all related to the mouse movement char-
acteristics, namely, the features used were the drag speed,
the move and the drag acceleration and the drag silence.
However, in the merged instance model, more features were
used by the classiﬁer that relate to both of the cognitive
as well as the mouse movement characteristics of the user,
which made mimicking the victim much harder. Second,
the classiﬁer performs better as using two challenges involve
more interaction between the user and the challenges, and
make the mimicking task much harder for the attacker. In
all the other classiﬁcation models, we found that the se-
curity provided by merging two challenges was also much
higher than its corespondent in using a single challenge.
This suggests that our Gametrics system can defeat pow-
erful shoulder-surﬁng attacks with a high probability when
two game instances are merged and when user-speciﬁc model
is used.
284
In practice, it is possible that the attacker resorts to an au-
tomated strategy, for example, the use of robots, rather than
manual shoulder-surﬁng (which may be a tedious attack any-
way). A robotic attack to compromise behavioral authenti-
cation schemes, speciﬁcally touchscreen dynamics, has been
proposed in [29]. Such robots can be built to mimic the
user’s way of interacting with the authentication construct
based on the leaked authentication template. These attacks
have been shown to be able to signiﬁcantly decrease the per-
formance of touch-based authentication systems. In contrast
to tradition behavioral biometrics where the authentication
construct is static (i.e., PIN or pattern unlock), Gametrics
involves randomization in the object movements as well as
solving a game-based CAPTCHA (DCG) [18]. Thereby, to
build a robot that is able to mimic the user’s interaction
with the games, the robot is required to not only repeat
a previously recorded interaction between the user and the
authentication construct, but also to understand the under-
lying challenge as fast as a human user and then try to
mimic the user’s interaction with the challenge. Although
it is shown in [18] that DCG CAPTCHA can be attacked
using a dictionary-based attack, if the server incorporates a
large database of the challenges and display the challenges
randomly to the user, this task would become hard for the
bot as the dictionary search and the matching between each
of the moving objects and the stored answer objects in the
database would signiﬁcantly slow down this process. Fur-
thermore, matching each of the answer objects with the an-
swer objects stored in the dictionary requires some amount
of time, for instance in [18] the authors proposed to click
on the object to hold it while performing the object match-
ing. This would make it hard to mimic the user’s “pause
and drag” feature. Based on this analysis, we therefore con-
clude that even automated shoulder-surﬁng attacks against
Gametrics will not be eﬀective.
The authors of [19] showed that most of the currently pro-
posed behavrioral biometrics schemes (including keystroke
and touchscreen dynamics) are vulnerable to internal,
malware-based attacks. Malware installed on the device (au-
thentication terminal/phone) can record the user’s valid au-
thentication template and replay it later to authenticate it-
self as the user (e.g, replay a “pattern unlock” biometrics [7]),
or learn from multiple interactions between the user and
the device, and then reproduce the new data that has sim-
ilar features to the user’s valid interactions with the device
in order to fool the authentication system (e.g., learn the
user’s typing pattern and then enter another text mimick-
ing the user’s typing style). In contrast to other behavioral
biometrics schemes, the multi-round randomization embed-
ded in the Gametrics challenges as well as the requirement
of solving the underlying game-based CAPTCHA will make
Gametrics robust against such attacks. That is, even having
access to the authentication template or a prior authentica-
tion session data will not be suﬃcient for the attacker to
impersonate the user in the Gametrics system.
To sum up, Gametrics promises to address many of the
attacks that are known to be a signiﬁcant concern for tra-
ditional password-based authentication systems as well as
existing behavioral biometrics systems, including:
• User-side attacks, where the attacker observes the vic-
tim as she logs in, through manual or automated mech-
anisms, to learn the user’s input (password in password
system) or learn the way the user provides the input
(biometrics data from the current session in behavioral
biometrics systems). The attacker then attempts to re-
play the information in an authentication session at a
later point of time.
• Server-side attacks, where the attacker hacks into the
web server databases to learn the stored authentication
token (e.g., hash of passwords in password systems and
biometrics template in behavioral biometrics systems).
The attacker then uses this information to run an of-
ﬂine dictionary attack against passwords, or reproduce
the biometric data that matches with the template.
• Client-side attacks, where the attacker hacks into the
authentication terminal using which the user is logging
in and learn the user’s input. The attacker then at-
tempts to replay the information in an authentication
session at a later point of time.
7. DISCUSSION AND FUTURE WORK
Eﬃciency: The proposed Gametrics system can ﬁt well
for many applications noting the short time the user took
to solve the challenges (around 7.5 seconds for a single chal-
lenge and 15 seconds for two challenges). Moreover, the en-
rollment phase consisted of 40 challenges (around 5 minutes
on average) and provided a reasonably high identiﬁcation
accuracy. In short, building the classiﬁer model, updating
the model with the new data over time (e.g., as the user
logs in by playing new game instances) and testing a new
instance, all take a short amount of time.
User Experience: The Gametrics system also seems to
oﬀer high usability, as the average SUS score came to be
86.11 (standard deviation = 14.12) in the lab-study and
73.95 (standard deviation = 17.14) for the web study. SUS