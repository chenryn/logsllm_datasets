### High-Density System and Memory Utilization

Our system achieves exceptionally high density, using approximately 2 bytes of main memory per event in our largest dataset. This dataset, comprising 72 million edges, is comparable in size to the 128 million edges used in the graph database evaluation [23] mentioned earlier. Despite this, our memory utilization was just 111MB, significantly lower than the 256GB available in that study.

### Compact Event Log Generation

We also describe the generation of compact event logs based on our event reduction techniques (Section 5.1). We started with a space-efficient log format that was about 8 times smaller than a Linux audit log containing similar information. With FD reduction, the log size was further reduced by a factor of 35.3, and SD increased the reduction factor to approximately 41.4. These reductions are achieved before applying any data compression techniques like gzip, which can provide additional size reductions.

### Paper Organization

- **Section 2: Background on Forensic Analysis**  
  We provide an overview of forensic analysis, including the use of dependence graphs and the concepts of backward and forward analysis.
  
- **Section 3: Dependence-Preserving Reductions**  
  We introduce the formulation of dependence-preserving reductions, along with our FD and SD techniques.
  
- **Section 4: Efficient Algorithms for FD and SD**  
  We describe efficient algorithms for achieving FD and SD, along with a discussion on correctness and optimality.
  
- **Section 5: Compact Main-Memory Dependence Graph and Offline Event Logs**  
  We summarize the compact main-memory dependence graph and offline event log formats based on our event reductions.
  
- **Section 6: Implementation and Experimental Evaluation**  
  We present the implementation details and experimental results.
  
- **Section 7: Related Work**  
  We discuss related work in the field.
  
- **Section 8: Concluding Remarks**  
  We conclude with final remarks and future directions.

### Background

#### Dependence Graphs

System logs refer to two types of entities: subjects and objects. Subjects are processes, while objects are passive entities such as files, network connections, etc. Log entries represent events, which are actions (typically system calls) performed by subjects, e.g., read, write, and execute.

In most forensic analysis work [13, 15, 42], log contents are interpreted as a dependence graph. Nodes in the graph represent entities, and edges represent events. Edges are oriented in the direction of information flow and are timestamped. When multiple instances of an event are aggregated into a single instance, its timestamp becomes the interval between the first and last instances. Figure 1 shows a sample dependence graph, where circles denote subjects, and other shapes denote objects. Network connections are indicated by diamonds, files by ovals, and pipes by rectangles. Edges are timestamped, but their names are omitted. In-edges of subjects denote reads, and out-edges of subjects denote writes.

#### Backward and Forward Analysis

Forensic analysis addresses the questions of what, when, and how. The "what" question concerns the origin of a suspected attack and the impacted entities. The origin can be identified using backward analysis, starting from a suspicious entity and tracing backward in the graph. This analysis, first proposed in BackTracker [13], uses event timestamps to focus on paths in dependence graphs that represent causal chains of events. For example, a backward analysis from file C at time 5 will identify P and a.com. Of these, a.com is a source node (an object with no parent nodes) and is likely the entry point of the attack on C.

Although b.com is backward reachable from C in the standard graph-theoretic sense, it is excluded because the path from b.com to C does not always go forward in time. The set of entities impacted by the attack can be found using forward analysis [43, 1, 15] (also known as impact analysis), typically starting from an entry point identified by backward analysis. In the sample dependence graph, forward analysis from network connection a.com will reach all nodes, while a forward analysis from b.com will leave out C.

The "when" question asks when each step in the attack occurred, based on the timestamps of edges in the subgraph computed by forward and backward analyses. The "how" question focuses on understanding the steps in an attack in detail. To enable this, audit logs need to capture all key operations (e.g., important system calls) and key arguments such as file names, IP addresses, ports, and command-line options to processes.

### Dependence-Preserving Reductions

A reduction of a time-stamped dependence graph \( G \) to another graph \( G' \) involves keeping the same nodes but a subset of the events. Such a reduction may remove redundant events or combine similar events. As a result, some events in \( G \) may be dropped in \( G' \), while others may be aggregated into a single event. When events are combined, their timestamps are coalesced into a range that minimally covers all of them.

A log reduction must satisfy the following conditions:
- It should not change forensic analysis results.
- It should not affect our understanding of the results.

To meet the second requirement, we apply reductions only to read, write, and load events. All other events, such as fork, execve, remove, rename, and chmod, are preserved. Despite being limited to reads, writes, and loads, our reduction techniques are very effective in practice, as these events typically constitute over 95% of total events.

For the first requirement, our goal is to preserve the results of forward and backward forensic analysis. We ensure this by preserving forward and backward reachability across the original graph \( G \) and the reduced graph \( G' \). We begin by formally defining reachability in these graphs.

#### Reachability in Time-Stamped Dependence Graphs

A dependence graph \( G \) is a pair \((V, E)\), where \( V \) denotes the nodes in the graph and \( E \) denotes a set of directed edges. Each edge \( e \) is associated with a start time \( \text{start}(e) \) and an end time \( \text{end}(e) \). Reachability in this graph is defined as follows:

**Definition 1 (Causal Path and Reachability)**  
A node \( v \) is reachable from another node \( u \) if and only if there is a directed path \( e_1, e_2, \ldots, e_n \) from \( u \) to \( v \) such that:
\[ \forall 1 \leq i < n, \text{start}(e_i) \leq \text{end}(e_{i+1}) \]

We refer to a path satisfying this condition as a causal path. It captures the intuition that information arriving at a node through event \( e_i \) can possibly flow out through the event \( e_{i+1} \). In Figure 1, the path consisting of edges with timestamps 1, 6, 8, and 11 is causal, so L is reachable from a.com. In contrast, the path corresponding to the timestamp sequence 4, 3 is not causal because the first edge occurs later than the second. Hence, C is unreachable from b.com.

In forensics, we are interested in reachability of a node at a given time, so we extend the above definition as follows:

**Definition 2 (Forward/Backward Reachability at t)**  
- A node \( v \) is forward reachable from a node \( u \) at time \( t \), denoted \( u@t \rightarrow v \), if there is a causal path \( e_1, e_2, \ldots, e_n \) from \( u \) to \( v \) such that \( t \leq \text{end}(e_i) \) for all \( i \).
- A node \( u \) is said to be backward reachable from \( v \) at time \( t \), denoted \( u \rightarrow v@t \), if there is a causal path \( e_1, e_2, \ldots, e_n \) from \( u \) to \( v \) such that \( t \geq \text{start}(e_i) \) for all \( i \).

Intuitively, \( u@t \rightarrow v \) means \( u \)'s state at time \( t \) can impact \( v \). Similarly, \( u \rightarrow v@t \) means \( v \)'s state at \( t \) can be caused/explained by \( u \). In Figure 1, \( P@6 \rightarrow Q \), but \( P@11 \nrightarrow Q \). Similarly, \( a.com \rightarrow C@3 \), but \( b.com \nrightarrow C@3 \).

Based on reachability, we present three dependency-preserving reductions: CD, which is close to Xu et al.’s full trackability, and FD and SD, two new reductions introduced in this paper.

#### Continuous Dependence (CD) Preservation

This reduction aims to preserve forward and backward reachability at every instant of time.

**Definition 3 (Continuous Dependence Preservation)**  
Let \( G \) be a dependence graph and \( G' \) be a reduction of \( G \). \( G' \) is said to preserve continuous dependence if forward and backward reachability is identical in both graphs for every pair of nodes at all times.

In Figure 3, S reads from a file F at \( t = 2 \) and \( t = 4 \), and writes to another file \( F' \) at \( t = 3 \) and \( t = 6 \). Based on the above definition, continuous dependence is preserved when the reads by S are combined, as are the writes, as shown in the lower graph.

**Figure 3: Reduction that preserves continuous dependence.**

**Figure 4: Reduction that violates continuous dependence.**

In the original graph, \( F@3 \nrightarrow H \): the earliest time \( F@3 \) can affect S is at \( t = 4 \), and this effect can propagate to \( F'@6 \), but by this time, the event from \( F' \) to H has already terminated. In contrast, in the reduced graph, \( F@3 \) affects \( H@5 \).

Our definition of continuous dependence preservation is similar to Xu et al.’s definition of full trackability equivalence [42]. However, their definition is stricter and does not allow the reductions shown in Figure 3. They would permit those reductions only if node S had (a) no incoming edges between its outgoing edges and (b) no outgoing edges between its incoming edges.

Their stricter definition was likely motivated by efficiency considerations. Specifically, their definition ensures that reduction decisions can be made locally, e.g., by examining the edges incident on S. Thus, their criteria do not permit the combination of reads in either Figure 3 or Figure 4, since they share the same local structure at node S. In contrast, our continuous dependence definition is based on more powerful global reachability properties and can discriminate between the two examples to safely permit the aggregation in Figure 3 but not Figure 4. The downside of this power is efficiency, as continuous dependence may need to examine every path in the graph before deciding which edges can be removed.

Although the checking of global properties can be more time-consuming, the resulting reductions can be more powerful (i.e., achieve greater reduction). This is why we devote Section 4 to the development of efficient algorithms to check the more powerful global properties used in the two new reductions presented below.

Because of the similarity of Xu et al’s full trackability and our continuous dependence, we will henceforth refer to their approach as local continuous dependence (LCD) preservation. We end this discussion with examples of common scenarios where LCD reduction is permitted:
- **Sequence of reads without intervening writes:** When an application reads a file, its read operation results in multiple read system calls, each of which is typically logged as a separate event in the audit log. As long as there are no write operations performed by the application at the same time, LCD will permit the reads to be combined.
- **Sequence of writes without intervening reads:** The explanation in this case mirrors the previous case.

However, if reads and writes are interleaved, then LCD does not permit the reads (or writes) to be combined. In contrast, the FD notion presented below can support reductions in cases where an application is reading from one or more files while writing to one or more files.

#### Full Dependence (FD) Preservation

CD does not permit the reduction in Figure 4 because it changes whether the state of F at \( t = 3 \) propagates to H. But does this difference really matter in the context of forensic analysis? To answer this question, note that there is no way for F to become compromised at \( t = 3 \) if it was not already compromised before. Indeed, there is no basis for the state of F to change between \( t = 0 \) and \( t = 6 \) because nothing happens to F during this period.

More generally, subjects and objects do not spontaneously become compromised. Instead, compromises happen due to input consumption from a compromised entity, such as a network connection, compromised file, or user. This observation implies that keeping track of dependencies between entities at times strictly in between events is unnecessary, because nothing relevant changes at those times. Therefore, we focus on preserving dependencies at times when a node could become compromised, namely, when it acquires a new dependency.

Formally, let \( \text{Anc}(v, t) \) denote the set of ancestor nodes of \( v \) at time \( t \), i.e., they are backward reachable from \( v \) at \( t \):
\[ \text{Anc}(v, t) = \{ u | u \rightarrow v@t \} \]

Let \( \text{NewAnc}(v) \) be the set of times when this set changes, i.e.:
\[ \text{NewAnc}(v) = \{ t | \forall t' < t, \text{Anc}(v, t) \supset \text{Anc}(v, t') \} \]

We define \( \text{NewAnc}(v) \) to always include \( t = 0 \).

**Definition 4 (Full Dependence (FD) Preservation)**  
A reduction \( G' \) of \( G \) is said to preserve full dependence if for every pair of nodes \( u \) and \( v \):
- Forward reachability from \( u@t \) to \( v \) is preserved for all \( t \in \text{NewAnc}(u) \).
- Backward reachability of \( u \) from \( v@t \) is preserved at all \( t \).

In other words, when FD-preserving reductions are applied:
- The result of backward forensic analysis from any node \( v \) will identify the exact same set of nodes before and after the reduction.
- The result of forward analysis carried out from any node \( u \) will yield the exact same set of nodes, as long as the analysis is carried out at any of the times when there is a basis for \( u \) to get compromised.

To illustrate the definition, observe that FD preservation allows the reduction in Figure 4, since (a) backward reachability is unchanged for every node, and (b) \( \text{NewAnc}(F) = \{0\} \), and \( F@0 \) flows into S, \( F' \), and H in both the original and reduced graphs.

#### Source Dependence (SD) Preservation

We consider further relaxation of dependence preservation criteria to support more aggressive reduction, based on the typical way forensic analysis is applied. An analyst typically flags an entity as being suspicious, then performs a backward analysis to identify likely root causes. Root causes are source nodes in the graph, i.e., nodes without incoming edges. Source nodes represent network connections, preexisting files, processes started before the audit subsystem, pluggable media devices, and user (e.g., terminal) input. Then, the analyst performs a forward analysis to determine the extent of the attack. 

However, in order to fully investigate the extent of an attack, forensic analysis needs to focus on the earliest time a node could have been compromised, rather than the time when suspicious behavior is spotted. Otherwise, the analysis may miss effects that may have gone unnoticed between the time of compromise and the time suspicious behavior is detected.