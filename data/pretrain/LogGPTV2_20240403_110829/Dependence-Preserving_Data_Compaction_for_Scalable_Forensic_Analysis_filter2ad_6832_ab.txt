system achieves very high density: it uses about 2 bytes
of main memory per event on our largest data set. This
dataset, with 72M edges, is comparable in size to the
128M edges used in the graph database evaluation [23]
mentioned above. Yet, our memory utilization was just
111MB, in comparison with the 256GB available in that
study.
• We also describe the generation of compact event logs
based on our event reduction techniques (Section 5.1).
We began with a space-efficient log format that was about
8× smaller than a Linux audit log containing roughly the
same information. With FD reduction, it became 35.3×
smaller, while SD increased the reduction factor to about
41.4×. These numbers are before the application of any
data compression techniques such as gzip, which can
provide further reductions.
1.4 Paper Organization
We begin with some background on forensic analysis in
Section 2. The formulation of dependence-preserving
reductions, together with our FD and SD techniques, are
presented in Section 3. Efficient algorithms for achieving FD
and SD are described in Section 4, together with a treatment
of correctness and optimality. Section 5 summarizes a
compact main-memory dependence graph and offline event
log formats based on our event reductions. Implementation
and experimental evaluation are described in Section 6,
followed by related work discussion in Section 7 and
concluding remarks in Section 8.
USENIX Association
27th USENIX Security Symposium    1725
2 Background
Dependence graphs. System logs refer to two kinds of
entities: subjects and objects. Subjects are processes, while
objects correspond to passive entities such as files, network
connections and so on. Entries in the log correspond to
events, which represent actions (typically, system calls)
performed by subjects, e.g., read, write, and execute.
In most work on forensic analysis [13, 15, 42], the log
contents are interpreted as a dependence graph: nodes in
the graph correspond to entities, while edges correspond to
events. Edges are oriented in the direction of information
flow and have timestamps. When multiple instances of an
event are aggregated into a single instance, its timestamp be-
comes the interval between the first and last instances. Fig. 1
shows a sample dependence graph, with circles denoting sub-
jects, and the other shapes denoting objects. Among objects,
network connections are indicated by a diamond, files by
ovals, and pipes by rectangles. Edges are timestamped, but
their names omitted. Implicitly, in-edges of subjects denote
reads, and out-edges of subjects denote writes.
Backward and Forward Analysis. Forensic analysis is
concerned with the questions of what, when and how. The
what question concerns the origin of a suspected attack, and
the entities that have been impacted during an attack. The ori-
gin can be identified using backward analysis, starting from
an entity flagged as suspicious, and tracing backward in the
graph. This analysis, first proposed in BackTracker [13], uses
event timestamps to focus on paths in dependence graphs that
represent causal chains of events. A backward analysis from
file C at time 5 will identify P and a.com. Of these, a.com is
a source node, i.e., an object with no parent nodes, and hence
identified as the likely entry point of any attack on C.
Although b.com is backward reachable from C in the
standard graph-theoretic sense, it is excluded because the
path from b.com to C does not always go forward in time.
The set of entities impacted by the attack can be found
using forward analysis [43, 1, 15] (a.k.a. impact analysis),
typically starting from an entry point identified by backward
analysis. In the sample dependence graph, forward analysis
from network connection a.com will reach all nodes in the
graph, while a forward analysis from b.com will leave out C.
The when question asks when each step in the attack
occurred. Its answer is based on the timestamps of edges in
the subgraph computed by forward and backward analyses.
The how question is concerned with understanding the steps
in an attack in sufficient detail. To enable this, audit logs
need to capture all key operations (e.g., important system
calls), together with key arguments such as file names, IP
addresses and ports, command-line options to processes, etc.
3 Dependence Preserving Reductions
We define a reduction of a time-stamped dependence graph
G to be another graph G(cid:48) that contains the same nodes
but a subset of the events. Such a reduction may remove
“redundant” events, and/or combine similar events. As a
result, some events in G may be dropped in G(cid:48), while others
may be aggregated into a single event. When events are
combined, their timestamps are coalesced into a range that
(minimally) covers all of them.
A log reduction needs to satisfy the following conditions:
• it won’t change forensic analysis results, and
• it won’t affect our understanding of the results.
To satisfy the second requirement, we apply reductions only
to read, write1, and load events. All other events, e.g., fork,
execve, remove, rename and chmod, are preserved. Despite
being limited to reads, writes and loads, our reduction
techniques are very effective in practice, as these events
typically constitute over 95% of total events.
For the first requirement, our aim is to preserve the results
of forward and backward forensic analysis. We ensure this
by preserving forward and backward reachability across the
original graph G and the reduced graph G(cid:48). We begin by
formally defining reachability in these graphs.
3.1 Reachability in time-stamped dependence graphs
Dependence graph G is a pair (V,E) where V denotes the
nodes in the graph and E denotes a set of directed edges.
Each edge e is associated with a start time start(e) and an end
time end(e). Reachability in this graph is defined as follows:
Definition 1 (Causal Path and Reachability) A node v
is reachable from another node u if and only if there is
(directed) path e1,e2,...,en from u to v such that:
∀1 ≤ i < n start(ei) ≤ end(ei+1)
(1)
We refer to a path satisfying this condition as a causal path.
It captures the intuition that information arriving at a node
through event ei can possibly flow out through the event
ei+1, i.e., successive events on this path e1,e2,...,en can be
causally related. In Fig. 1, the path consisting of edges with
timestamps 1,6,8 and 11 is causal, so L is reachable from
a.com. In contrast, the path corresponding to the timestamp
sequence 4,3 is not causal because the first edge occurs later
than the second. Hence C is unreachable from b.com.
In forensics, we are interested in reachability of a node at
a given time, so we extend the above definition as follows:
Definition 2 (Forward/Backward Reachability at t)
• A node v is forward reachable from a node u at time t,
denoted u@t −→ v, iff there is a causal path e1,e2,...,en
from u to v such that t ≤ end(ei) for all i.
• A node u is said to be backward reachable from v at time t,
denoted u −→ v@t, iff there is a causal path e1,e2,...,en
from u to v such that t ≥ start(ei) for all i.
1There can be many types of read or write events, some used on files,
others used on network sockets, and so on. For example, Linux audit system
can log over a dozen distinct system calls used for input or output of data.
For the purposes of this description, we map them all into reads and writes.
1726    27th USENIX Security Symposium
USENIX Association
Intuitively, u@t −→ v means u’s state at time t can
impact v. Similarly, u −→ v@t means v’s state at t can be
caused/explained by u. In Fig. 1, P@6−→ Q, but P@11 (cid:54)−→
Q. Similarly, a.com −→ C@3 but b.com (cid:54)−→ C@3.
Based on reachability, we present three dependency-
preserving reductions: CD, which is close to Xu et al’s
full trackability, and FD and SD, two new reductions we
introduce in this paper.
3.2 Continuous dependence (CD) preservation
This reduction aims to preserve forward and backward
reachability at every instant of time.
Definition 3 (Continuous Dependence Preservation) Let
G be a dependence graph and G(cid:48) be a reduction of G. G(cid:48)
is said to preserve continuous dependence iff forward and
backward reachability is identical in both graphs for every
pair of nodes at all times.
In Fig. 3, S reads from a file F at t = 2 and t = 4, and writes to
another file F(cid:48) at t = 3 and t = 6. Based on the above defini-
tion, continuous dependence is preserved when the reads by S
are combined, as are the writes, as shown in the lower graph.
F
F
2
4
[2,4]
S
S
3
6
[3,6]
F(cid:48)
F(cid:48)
Fig. 3: Reduction that preserves continuous dependence.
Fig. 4 shows a reduction that does not preserve continuous
dependence. In the original graph, F@3 (cid:54)−→ H: the earliest
time F@3 can affect S is at t = 4, and this effect can
propagate to F(cid:48)@6, but by this time, the event from F(cid:48) to
H has already terminated. In contrast, in the reduced graph,
F@3 affects H@5.
F
F
2
4
[2,4]
3
6
[3,6]
F(cid:48)
F(cid:48)
S
S
5
5
H
H
Fig. 4: Reduction that violates continuous dependence.
Our definition of continuous dependence preservation is
similar to Xu et al.’s definition of full trackability equivalence
[42]. However, their definition is a bit stricter, and does not
allow the reductions shown in Fig. 3. They would permit
those reductions only if node S had (a) no incoming edges
between its outgoing edges and (b) no outgoing edges
between its incoming edges2.
2In particular, as per Algorithm 2 in [42], the period of the incoming
Their stricter definition was likely motivated by efficiency
considerations. Specifically, their definition ensures that
reduction decisions can be made locally, e.g., by examining
the edges incident on S. Thus, their criteria does not permit
the combination of reads in either Fig. 3 or Fig. 4, since they
share the same local structure at node S. In contrast, our con-
tinuous dependence definition is based on the more powerful
global reachability properties, and hence can discriminate
between the two examples to safely permit the aggregation in
Fig. 3 but not Fig. 4. The downside of this power is efficiency,
as continuous dependence may need to examine every path
in the graph before deciding which edges can be removed.
Although the checking of global properties can be more
time-consuming,
the resulting reductions can be more
powerful (i.e., achieve greater reduction). This is why we
devote Section 4 to development of efficient algorithms to
check the more powerful global properties used in the two
new reductions presented below.
Because of the similarity of Xu et al’s full trackability
and our continuous dependence, we will henceforth refer
to their approach as local continuous dependence (LCD)
preservation. We end this discussion with examples of
common scenarios where LCD reduction is permitted:
• Sequence of reads without intervening writes: When an
application reads a file, its read operation results in multi-
ple read system calls, each of which is typically logged
as a separate event in the audit log. As long as there are
no write operations performed by the application at the
same time, LCD will permit the reads to be combined.
• Sequence of writes without intervening reads: The expla-
nation in this case mirrors the previous case.
However, if reads and writes are interleaved, then LCD does
not permit the reads (or writes) to be combined. In contrast,
the FD notion presented below can support reductions in
cases where an application is reading from one or more files
while writing to one or more files.
3.3 Full Dependence (FD) Preservation
CD does not permit the reduction in Fig. 4, because it
changes whether the state of F at t = 3 propagates to H. But
does this difference really matter in the context of forensic
analysis? To answer this question, note that there is no way
for F to become compromised at t = 3 if it was not already
compromised before. Indeed, there is no basis for the state
of F to change between t = 0 and t = 6 because nothing
happens to F during this period.
More generally, subjects and objects don’t spontaneously
become compromised. Instead, compromises happen due
to input consumption from a compromised entity, such as
a network connection, compromised file, or user3. This
edge in Fig. 3 should not overlap the period between the end times of the
two edges out of S; per their Algorithm 3, the period of the S to F(cid:48) edge must
not overlap the period between the start times of the two edges out of F.
3We aren’t suggesting that a compromised process must immediately
USENIX Association
27th USENIX Security Symposium    1727
observation implies that keeping track of dependencies
between entities at times strictly in between events is
unnecessary, because nothing relevant changes at those times.
Therefore, we focus on preserving dependencies at times
when a node could become compromised, namely, when
it acquires a new dependency.
Formally, let Anc(v,t) denote the set of ancestor nodes of
v at time t, i.e., they are backward reachable from v at t.
Anc(v,t) = {u | u −→ v@t}.
Let NewAnc(v) be the set of times when this set changes, i.e.:
NewAnc(v) = {t | ∀t(cid:48) < t, Anc(v,t) ⊃ Anc(v,t(cid:48))}.
We define NewAnc(v) to always include t = 0.
Definition 4 (Full Dependence (FD) Preservation) A
reduction G(cid:48) of G is said to preserve full dependence iff for
every pair of nodes u and v:
• forward reachability from u@t to v is preserved for all
t ∈ NewAnc(u), and
• backward reachability of u from v@t is preserved at all t.
In other words, when FD-preserving reductions are applied:
• the result of backward forensic analysis from any node v
will identify the exact same set of nodes before and after
the reduction.
• the result of forward analysis carried out from any node
u will yield the exact same set of nodes, as long as the
analysis is carried out at any of the times when there is
a basis for u to get compromised.
To illustrate the definition, observe that FD preservation
allows the reduction in Fig. 4, since (a) backward reachability
is unchanged for every node, and (b) NewAnc(F) = {0},
and F@0 flows into S, F(cid:48) and H in the original as well as
the reduced graphs.
3.4 Source Dependence (SD) Preservation
We consider further relaxation of dependence preservation
criteria in order to support more aggressive reduction, based
on the following observation about the typical way forensic
analysis is applied. An analyst typically flags an entity as
being suspicious, then performs a backward analysis to
identify likely root causes. Root causes are source nodes in
the graph, i.e., nodes without incoming edges. Source nodes
represent network connections, preexisting files, processes
started before the audit subsystem, pluggable media devices,
and user (e.g., terminal) input. Then, the analyst performs an
exhibit suspicious behavior. However, in order to fully investigate the
extent of an attack, forensic analysis needs to focus on the earliest time a
node could have been compromised, rather than the time when suspicious
behavior is spotted. Otherwise, the analysis may miss effects that may have
gone unnoticed between the time of compromise and the time suspicious