and used to generate Twitter spam. We ﬁnd that, dur-
ing active months, the underground market was respon-
sible for registering 10–20% of all accounts that Twit-
ter later ﬂagged as spam. For their efforts, we estimate
that merchants generated a combined revenue between
$127,000– $459,000.
0.6
s
t
n
u
o
c
c
A
0.4
f
o
0.2
n
o
i
t
c
a
r
F
0.0
Apr 2012
Jul 2012
Oct 2012
Jan 2013
Apr 2013
Registration Date
Figure 6: Fraction of all suspended accounts over time that
originate from the underground market.
Impact on Twitter Spam
6.1
From our seed set of 121,027 accounts purchased from
27 merchants, we are able to identify several million
fraudulent accounts that were registered by the same
merchants. Of these, 73% were sold and actively tweet-
ing or forming relationships at one point in time, while
the remaining 37% remained dormant and were yet to be
purchased.
In cooperation with Twitter, we analyzed the total frac-
tion of all suspended accounts that appear to originate
from the merchants we track, shown in Figure 6. At its
peak, the underground marketplace was responsible for
registering 60% of all accounts that would go on to be
suspended for spamming. During more typical periods of
activity, the merchants we track contribute 10–20% of all
spam accounts. We note that the drop-off around April
does not indicate a lack of recent activity; rather, as ac-
counts are stockpiled for months at a time, they have yet
to be released into the hands of spammers, which would
lead to their suspension. The most damaging merchants
from our impact analysis operate out of blackhat forums
and web storefronts, while Fiverr and Freelancer sellers
generate orders of magnitude fewer accounts.8
6.2 Estimating Revenue
We estimate the revenue generated by the underground
market based on the total accounts sold and the prices
charged during their sale. We distinguish accounts that
have been sold from those that lay dormant and await sale
based on whether an account has sent tweets or formed
relationships. For sold accounts, we identify which mer-
8The exception to this is a Freelancer merchant kamalkishover, but
based on their merchant pattern overlapping with 9 other merchants,
we believe they are simply reselling accounts.
USENIX Association  
22nd USENIX Security Symposium  207
13
chant created the account and determine the minimum
and maximum price the merchant would have charged
for that account based on our historical pricing data.9
In the event multiple merchants could have generated
the account (due to overlapping registration patterns), we
simply take the minimum and maximum price of the set
of matching merchants.
We estimate that the total revenue generated by the
underground account market through the sale of Twitter
credentials is between the range of $127,000– $459,000
over the course of a year. We note that many of the
merchants we track simultaneously sell accounts for a
variety of web services, so this value likely represents
only a fraction of their overall revenue. Nevertheless,
our estimated income is far less than the revenue gener-
ated from actually sending spam [17] or selling fake anti-
virus [25], where revenue is estimated in the tens of mil-
lions. As such, account merchants are merely stepping
stones for larger criminal enterprises, which in turn dis-
seminate scams, phishing, and malware throughout Twit-
ter.
7 Disrupting the Underground Market
With Twitter’s cooperation, we disable 95% of all
fraudulent accounts registered by the 27 merchants we
track, including those previously sold but not yet sus-
pended for spamming. Throughout this process, we si-
multaneously monitor the underground market to track
fallout and recovery. While we do not observe an ap-
preciable increase in pricing or delay in merchant’s de-
livering new accounts, we ﬁnd 90% of all purchased ac-
counts immediately after our actioning are suspended on
arrival. While we successfully deplete merchant stock-
piles containing fraudulent accounts, we ﬁnd that within
two weeks merchants were able to create fresh accounts
and resume selling working credentials.
7.1 Suspending Identiﬁed Accounts
In order to disrupt the abusive activities of account mer-
chants, we worked with Twitter’s Anti-spam, SpamOps,
and Trust and Safety teams to manually validate the ac-
curacy of our classiﬁer and tune parameters to set an ac-
ceptable bounds on false positives (legitimate users in-
correctly identiﬁed as fraudulent accounts). Once tuned,
we applied the classiﬁer outlined in Section 5 to every ac-
count registered on Twitter going back to March, 2012,
9Determining the exact time of sale for an account is not possible
due to the potential of miscreants stockpiling their purchases; as such,
we calculate revenue for both the minimum and maximum possible
price.
ﬁltering out accounts that were already suspended for
abusive behavior.
From the set of accounts we identiﬁed10, Twitter it-
eratively suspended accounts in batches of ten thousand
and a hundred thousand before ﬁnally suspending all the
remaining identiﬁed accounts. At each step we moni-
tored the rate of users that requested their accounts be
unsuspended as a metric for false positives, where un-
suspension requests require a valid CAPTCHA solution.
Of the accounts we suspended, only 0.08% requested to
be unsuspended. However, 93% of these requests were
performed by fraudulent accounts abusing the unsuspend
process, as determined by manual analysis performed by
Twitter. Filtering these requests out, we estimate the ﬁ-
nal precision of our classiﬁer to be 99.9942%. The tuned
classiﬁer has a recall of 95%, the evaluation of which is
identical to the method presented in Section 5. Assuming
our purchases are a random sample of the accounts con-
trolled by the underground market, we estimate that 95%
of all fraudulent accounts registered by the 27 merchants
we track were disabled by our actioning.
7.2 Marketplace Fallout and Recovery
Immediately after Twitter suspended the last of the un-
derground market’s accounts, we placed 16 new orders
for accounts from the 10 merchants we suspected of con-
trolling the largest stockpiles. Of 14,067 accounts we
purchased, 90% were suspended on arrival due to Twit-
ter’s previous intervention. When we requested working
replacements, one merchant responded with:
All of the stock got suspended ... Not just mine .. It
happened with all of the sellers .. Don’t know what
twitter has done ...
Similarly, immediately after suspension, buyaccs.com
put up a notice on their website stating “Временно
не продаем аккаунты Twitter.com”, translating via
Google roughly to “Temporarily not selling Twitter.com
accounts”.
While Twitter’s initial intervention was a success, the
market has begun to recover. Of 6,879 accounts we pur-
chased two weeks after Twitter’s intervention, only 54%
were suspended on arrival. As such, long term disrup-
tion of the account marketplace requires both increasing
the cost of account registration (as outlined in Section 4)
and integrating at-signup time abuse classiﬁcation into
the account registration process (similar to the classiﬁer
10Due to operational concerns, we cannot specify the exact volume
of accounts we detect that were not previously suspended by Twitter’s
existing defenses.
208  22nd USENIX Security Symposium 
USENIX Association
14
outlined in Section 5). We are now working with Twitter
to integrate our ﬁndings and existing classiﬁer into their
abuse detection infrastructure.
8 Summary
We have presented a longitudinal investigation of the
underground market tied to fraudulent Twitter creden-
tials, monitoring pricing, availability, and fraud per-
petrated by 27 account merchants. These merchants
specialize in circumventing automated registration bar-
riers by leveraging thousands of compromised hosts,
CAPTCHA solvers, and access to fraudulent Hotmail, Ya-
hoo, and mail.ru credentials. We identiﬁed which reg-
istration barriers positively inﬂuenced the price of ac-
counts and distilled our observations into a set of recom-
mendations for how web services can improve existing
barriers to bulk signups. Furthermore, we developed a
classiﬁer based on at-registration abuse patterns to suc-
cessfully detect several million fraudulent accounts gen-
erated by the underground market. During active months,
the 27 merchants we monitor appeared responsible for
registering 10–20% of all accounts later ﬂagged by Twit-
ter as spam. For their efforts, these merchants generated
an estimated revenue between $127,000–$459,000. With
Twitter’s help, we successfully suspended 95% of all ac-
counts registered by the 27 merchants we track, deplet-
ing the account stockpiles of numerous criminals. We
are now working with Twitter to integrate our ﬁndings
and existing classiﬁer into their abuse detection infras-
tructure.
Acknowledgments
This work was supported by the National Sci-
ence Foundation under grants 1237076 and 1237265,
by the Ofﬁce of Naval Research under MURI grant
N000140911081, and by a gift from Microsoft Research.
Any opinions, ﬁndings, and conclusions or recommenda-
tions expressed in this material are those of the authors
and do not necessarily reﬂect the views of the sponsors.
References
[1] Alexa. Alexa top 500 global sites. http://www.alexa.com/topsites,
2012.
[2] D.S. Anderson, C. Fleizach, S. Savage, and G.M. Voelker. Spam-
In
scatter: Characterizing internet scam hosting infrastructure.
USENIX Security, 2007.
[3] F. Benevenuto, G. Magno, T. Rodrigues, and V. Almeida. Detect-
ing Spammers on Twitter. In Proceedings of the Conference on
Email and Anti-Spam (CEAS), 2010.
[4] J. Caballero, C. Grier, C. Kreibich, and V. Paxson. Measuring
pay-per-install: The commoditization of malware distribution. In
USENIX Security Symposium, 2011.
[5] CBL.
Composite Blocking List.
cbl.abuseat.org/, 2012.
http://
[6] G. Danezis and P. Mittal. Sybilinfer: Detecting sybil nodes using
social networks. In Proceedings of the Network and Distributed
System Security Symposium (NDSS), 2009.
[7] J. Franklin, V. Paxson, A. Perrig, and S. Savage. An inquiry into
the nature and causes of the wealth of Internet miscreants. In Pro-
ceedings of ACM Conference on Computer and Communications
Security, pages 375–388, October 2007.
[8] H. Gao, J. Hu, C. Wilson, Z. Li, Y. Chen, and B.Y. Zhao. Detect-
ing and characterizing social spam campaigns. In Proceedings of
the Internet Measurement Conference (IMC), 2010.
[9] C. Grier, L. Ballard, J. Caballero, N. Chachra, C.J. Dietrich,
K. Levchenko, P. Mavrommatis, D. McCoy, A. Nappa, A. Pit-
sillidis, et al. Manufacturing compromise: The emergence of
exploit-as-a-service. 2012.
[10] C. Grier, K. Thomas, V. Paxson, and M. Zhang. @spam: the un-
derground on 140 characters or less. In Proceedings of the ACM
Conference on Computer and Communications Security (CCS),
2010.
[11] T. Holz, C. Gorecki, F. Freiling, and K. Rieck. Detection and
mitigation of fast-ﬂux service networks.
In Proceedings of the
15th Annual Network and Distributed System Security Sympo-
sium (NDSS), 2008.
[12] C.Y. Hong, F. Yu,
and Y. Xie.
Populated ip ad-
dresses—classiﬁcation and applications. 2012.
[13] Heather Kelley.
83 million facebook accounts are fakes
http://www.cnn.com/2012/08/
and dupes.
02/tech/social-media/facebook-fake-
accounts/index.html, 2012.
[14] Brian Krebs. Spam volumes: Past & present, global & lo-
http://krebsonsecurity.com/2013/
cal.
01/spam-volumes-past-present-global-
local/, 2012.
[15] S. Lee and J. Kim. Warningbird: Detecting Suspicious URLs
In Symposium on Network and Distributed
in Twitter Stream.
System Security (NDSS), 2012.
[16] K. Levchenko, A. Pitsillidis, N. Chachra, B. Enright, M. Fele-
gyhazi, C. Grier, T. Halvorson, C. Kanich, C. Kreibich, H. Liu,
D. McCoy, N. Weaver, V. Paxson, G.M. Voelker, and S. Sav-
age. Click Trajectories: End-to-End Analysis of the Spam Value
Chain. In Proceedings of the 32nd IEEE Symposium on Security
and Privacy, 2011.
[17] D. McCoy, A. Pitsillidis, G. Jordan, N. Weaver, C. Kreibich,
B. Krebs, G.M. Voelker, S. Savage, and K. Levchenko. Phar-
maleaks: Understanding the business of online pharmaceutical
afﬁliate programs.
In Proceedings of the 21st USENIX confer-
ence on Security symposium. USENIX Association, 2012.
[18] A. Metwally and M. Paduano. Estimating the number of users be-
hind ip addresses for combating abusive trafﬁc. In Proceedings of
the 17th ACM SIGKDD international conference on Knowledge
discovery and data mining. ACM, 2011.
[19] M. Motoyama, K. Levchenko, C. Kanich, D. McCoy, G.M.
Voelker, and S. Savage. Re: Captchas–understanding captcha-
solving services in an economic context.
In USENIX Security
Symposium, volume 10, 2010.
USENIX Association  
22nd USENIX Security Symposium  209
15
[20] M. Motoyama, D. McCoy, K. Levchenko, S. Savage, and G.M.
Voelker. An analysis of underground forums. In Proceedings of
the Internet Measurement Conference (IMC). ACM, 2011.
[21] M. Motoyama, D. McCoy, K. Levchenko, S. Savage, and G.M.
Voelker. Dirty jobs: The role of freelance labor in web service
abuse. In Proceedings of the 20th USENIX Security Symposium,
2011.
[22] A. Pitsillidis, K. Levchenko, C. Kreibich, C. Kanich, G.M.
Voelker, V. Paxson, N. Weaver, and S. Savage. Botnet Judo:
Fighting spam with itself. 2010.
[23] P. Prasse, C. Sawade, N. Landwehr, and T. Scheffer. Learning to
identify regular expressions that describe email campaigns. 2012.
[24] W.E. Ricker. Computation and interpretation of biological statis-
tics of ﬁsh populations, volume 191. Department of the Environ-
ment, Fisheries and Marine Service Ottawa, 1975.
[25] B. Stone-Gross, R. Abman, R. Kemmerer, C. Kruegel, D. Steiger-
wald, and G. Vigna. The Underground Economy of Fake An-
tivirus Software. In Proceedings of the Workshop on Economics
of Information Security (WEIS), 2011.
[26] G. Stringhini, C. Kruegel, and G. Vigna. Detecting Spammers
In Proceedings of the Annual Computer
on Social Networks.
Security Applications Conference (ACSAC), 2010.
[27] K. Thomas, C. Grier, J. Ma, V. Paxson, and D. Song. Design and
Evaluation of a Real-time URL Spam Filtering Service. In Pro-
ceedings of the 32nd IEEE Symposium on Security and Privacy,
2011.
[28] K. Thomas, C. Grier, and V. Paxson. Adapting social spam
infrastructure for political censorship.
In Proceedings of the
5th USENIX conference on Large-Scale Exploits and Emergent
Threats. USENIX Association, 2012.
[29] K. Thomas, C. Grier, V. Paxson, and D. Song. Suspended Ac-
counts In Retrospect: An Analysis of Twitter Spam. In Proceed-
ings of the Internet Measurement Conference, November 2011.
[30] Twitter.
The
http://
support.twitter.com/entries/18311-the-
twitter-rules, 2010.
Twitter
Rules.
[31] G. Wang, C. Wilson, X. Zhao, Y. Zhu, M. Mohanlal, H. Zheng,
and B.Y. Zhao. Serf and Turf: Crowdturﬁng for Fun and Proﬁt.
In Proceedings of the International World Wide Web Conference,
2011.
[32] Y. Xie, F. Yu, K. Achan, R. Panigrahy, G. Hulten, and I. Osipkov.
Spamming botnets: Signatures and characteristics. Proceedings
of ACM SIGCOMM, 2008.
[33] C. Yang, R. Harkreader, J. Zhang, S. Shin, and G. Gu. Analyzing
Spammers’ Social Networks for Fun and Proﬁt: a Case Study of
Cyber Criminal Ecosystem on Twitter. In Proceedings of the 21st
International Conference on World Wide Web, 2012.
[34] H. Yu, M. Kaminsky, P.B. Gibbons, and A. Flaxman. Sybilguard:
defending against sybil attacks via social networks. ACM SIG-
COMM Computer Communication Review, 2006.
[35] Y. Zhao, Y. Xie, F. Yu, Q. Ke, Y. Yu, Y. Chen, and E. Gillum.
Botgraph: Large scale spamming botnet detection. 2009.
A Legal and Ethical Guidelines
To minimize the risk posed to Twitter or its users by
our investigation of the account market, we follow a set
of policies set down by our institutions and Twitter, re-
produced here to serve as a note of caution to other re-
searchers conducting similar research.
Twitter & Users Some of the account merchants we deal
with work in an on-demand fashion, where purchases we
place directly result in abusive registrations on Twitter
(e.g. harm) in violation of the site’s Terms of Services.
Even purchases from existing stockpiles might be mis-
construed as galvanizing further abuse of Twitter. As
such, we directly contacted Twitter to receive permission
to conduct our study. In the process, we determined that
any interactions with the underground market should not
result in harm to Twitter’s user base. In particular, ac-
counts we purchased should never be used to tweet or
form relationships while under our control. Furthermore,
we take no special action to guarantee our accounts are
not suspended (e.g disabled) by Twitter; our goal is to
observe the natural registration process, not to interact
with or impede Twitter’s service in any way.
Account Merchants We do not interact with merchants
anymore than necessary to perform transactions. To this
end, we only purchased from merchants that advertise
their goods publicly and never contact merchants outside
the web sites or forums they provide to conduct a sale
(or to request replacement accounts in the event of a bad
batch). Our goal is not to study the merchants themselves
or to collect personal information on them; only to ana-
lyze the algorithms they use to generate accounts.
Sensitive User Data Personal data logged by Twitter is
subject to a multitude of controls, while user names and
passwords sold by merchants also carry controls to pre-
vent fraud, abuse, and unauthorized access. First, we
never log into accounts; instead, we rely on Twitter to
verify the authenticity of credentials we purchase. Fur-
thermore, all personal data such as IP addresses or activi-
ties tied to an account are never accessed outside of Twit-
ter’s infrastructure, requiring researchers involved in this
study to work on site at Twitter and to follow all relevant
Twitter security practices. This also serves to remove
any risk in the event an account is compromised rather
than registered by an account merchant, as no personal
data ever leaves Twitter. To our knowledge, we never
obtained credentials for compromised accounts.
210  22nd USENIX Security Symposium 
USENIX Association
16