### 查看消息文件数据作为 Kafka 使用者，你是不是对 Kafka 底层文件里面保存的内容很感兴趣?如果是的话，你可以使用 kafka-dump-log 脚本来查看具体的内容。    $ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log Dumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.logStarting offset: 0baseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: truebaseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true......如果只是指定\--files，那么该命令显示的是消息批次（RecordBatch）或消息集合（MessageSet）的元数据信息，比如创建时间、使用的压缩算法、CRC校验值等。**如果我们想深入看一下每条具体的消息，那么就需要显式指定\--deep-iteration 参数**，如下所示：    $ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log --deep-iterationDumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.logStarting offset: 0baseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true| offset: 0 CreateTime: 1561597044911 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []| offset: 1 CreateTime: 1561597044932 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []| offset: 2 CreateTime: 1561597044932 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []| offset: 3 CreateTime: 1561597044932 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []| offset: 4 CreateTime: 1561597044932 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []| offset: 5 CreateTime: 1561597044932 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []| offset: 6 CreateTime: 1561597044932 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []| offset: 7 CreateTime: 1561597044932 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []| offset: 8 CreateTime: 1561597044932 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []| offset: 9 CreateTime: 1561597044932 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []| offset: 10 CreateTime: 1561597044932 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []| offset: 11 CreateTime: 1561597044932 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []| offset: 12 CreateTime: 1561597044932 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []| offset: 13 CreateTime: 1561597044933 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []| offset: 14 CreateTime: 1561597044933 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []baseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true......在上面的输出中，以竖线开头的就是消息批次下的消息信息。如果你还想看消息里面的实际数据，那么还需要指定**\--print-data-log 参数**，如下所示：    $ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log --deep-iteration --print-data-log
### 查询消费者组位移接下来，我们来看如何使用 kafka-consumer-groups脚本查看消费者组位移。在上一讲讨论重设消费者组位移的时候，我们使用的也是这个命令。当时我们用的是**\--reset-offsets 参数**，今天我们使用的是 **\--describe参数**。假设我们要查询 Group ID 是 test-group的消费者的位移，那么命令如图所示：![](Images/4bd349494590264da4c30df98058241f.png){savepage-src="https://static001.geekbang.org/resource/image/f4/ee/f4b7d92cdebff84998506afece1f61ee.png"}图中的 CURRENT-OFFSET 表示该消费者当前消费的最新位移，LOG-END-OFFSET表示对应分区最新生产消息的位移，LAG 列是两者的差值。CONSUMER-ID 是 Kafka消费者程序自动生成的一个 ID。截止到 2.2 版本，你都无法干预这个 ID的生成过程。如果运行该命令时，这个消费者程序已经终止了，那么此列的值为空。
## 小结好了，我们小结一下。今天我们一起梳理了 Kafka 2.2版本自带的所有脚本，我给出了常见的运维操作的工具行命令。希望这些命令对你操作和管理Kafka 集群有所帮助。另外，我想强调的是，由于 Kafka依然在不断演进，我们今天提到的命令的用法很可能会随着版本的变迁而发生变化。在具体使用这些命令时，你最好详细地阅读一下它们的Usage 说明。![](Images/4a87e82aa8df1d462c81306ed24daeaf.png){savepage-src="https://static001.geekbang.org/resource/image/5b/32/5b0daf262cde0c853a5cf9fbc9dfa332.jpg"}
## 开放讨论你在使用 Kafka命令的过程中，曾经踩过哪些"坑"，或者说有哪些惨痛的经历呢？欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。![](Images/a7d15815f9efb5693db5b2d278244658.png){savepage-src="https://static001.geekbang.org/resource/image/c8/bf/c89da43deab85fe7cb06acec867aa5bf.jpg"}
# 32 \| KafkaAdminClient：Kafka的运维利器你好，我是胡夕。今天我要和你分享的主题是：Kafka 的运维利器KafkaAdminClient。
## 引入原因在上一讲中，我向你介绍了 Kafka自带的各种命令行脚本，这些脚本使用起来虽然方便，却有一些弊端。首先，不论是 Windows 平台，还是 Linux平台，命令行的脚本都只能运行在控制台上。如果你想要在应用程序、运维框架或是监控平台中集成它们，会非常得困难。其次，这些命令行脚本很多都是通过连接 ZooKeeper来提供服务的。目前，社区已经越来越不推荐任何工具直连 ZooKeeper了，因为这会带来一些潜在的问题，比如这可能会绕过 Kafka的安全设置。在专栏前面，我说过 kafka-topics 脚本连接 ZooKeeper时，不会考虑 Kafka设置的用户认证机制。也就是说，任何使用该脚本的用户，不论是否具有创建主题的权限，都能成功"跳过"权限检查，强行创建主题。这显然和Kafka 运维人员配置权限的初衷背道而驰。最后，运行这些脚本需要使用 Kafka 内部的类实现，也就是Kafka**服务器端**的代码。实际上，社区还是希望用户只使用Kafka**客户端**代码，通过现有的请求机制来运维管理集群。这样的话，所有运维操作都能纳入到统一的处理机制下，方便后面的功能演进。``{=html}基于这些原因，社区于 0.11 版本正式推出了 Java 客户端版的AdminClient，并不断地在后续的版本中对它进行完善。我粗略地计算了一下，有关AdminClient的优化和更新的各种提案，社区中有十几个之多，而且贯穿各个大的版本，足见社区对AdminClient 的重视。值得注意的是，**服务器端也有一个 AdminClient**，包路径是kafka.admin。这是之前的老运维工具类，提供的功能也比较有限，社区已经不再推荐使用它了。所以，我们最好统一使用客户端的AdminClient。
## 如何使用？下面，我们来看一下如何在应用程序中使用 AdminClient。我们在前面说过，它是Java客户端提供的工具。想要使用它的话，你需要在你的工程中显式地增加依赖。我以最新的2.3 版本为例来进行一下展示。如果你使用的是 Maven，需要增加以下依赖项：        org.apache.kafka    kafka-clients    2.3.0如果你使用的是 Gradle，那么添加方法如下：    compile group: 'org.apache.kafka', name: 'kafka-clients', version: '2.3.0'