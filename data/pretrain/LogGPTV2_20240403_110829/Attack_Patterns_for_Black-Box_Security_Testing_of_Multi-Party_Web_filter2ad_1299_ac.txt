RA2
RA3
RA4
LCSRF
REPLAY x FROM (UV, SPM) IN (UM, SPT)
REPLAY x FROM (UM, SPM) IN (UM, SPT)
REPLAY x FROM (UM, SPT) IN (UM, SPT)
REPLAY y FROM S IN (UM, SPT)
where S = REPLAY x FROM (UM, SPT) IN (UV, SPM)
REPLACE req WITH REQUEST-OF y
FROM (UM, SPT) IN [UM SEND req]
RedURI REPLAY y FROM S IN (UM, SPT)
where S = REPLACE x WITH x(cid:48) IN (UV, SPT)
REPLAY x FROM (UV, SPT) IN (UM, SPT)
RA5
Legenda: The notation (x|y) ∈ S is used to abbreviate (x ∈ S OR y ∈ S).
Precondition
(TTP-SP ∈ x.ﬂow AND (SU|UU) ∈ x.labels)
(SP-TTP ∈ x.ﬂow AND (SU|AU) ∈ x.labels)
(TTP-SP ∈ x.ﬂow AND SU ∈ x.labels)
(SP-TTP ∈ x.ﬂow AND (SU|AU) ∈ x.labels AND
TTP-SP ∈ y.ﬂow AND (SU|UU) ∈ y.labels)
(TTP-SP ∈ y.ﬂow AND (SU|UU) ∈ y.labels)
(SP-TTP ∈ x.ﬂow AND RURI ∈ x.labels) AND
TTP-SP ∈ y.ﬂow AND (SU|UU) ∈ y.labels)
(TTP-SP ∈ x.ﬂow AND (SU|UU) ∈ x.labels AND
x.location = REQUESTURL)
Postcondition
(UV, SPT)
(UM, SPT)
(UM, SPT)
(UV, SPT)
(UM, SPT)
(UM, SPT)
(UV, SPT)
The generation of all other attack patterns go along the
same lines. For the creation of the attack pattern LCSRF we
were clearly inspired by attacks #7 and #8. It turns out that this
attack pattern is a bit more general than what it was created for.
In fact, it can uncover general CSRF based on POST requests.
An example of this will be discussed in the illustrative example
of Section IV.
A key step in the execution of an attack pattern is the selec-
tion of the elements to be replaced or replayed. For instance,
when executing RA1 against a given MPWA, the parameter x
can be instantiated with any element occurring in the HTTP
trace resulting from the execution of (UV, SPM). Trying them
all is clearly not acceptable. To tackle the problem, we inspect
the sessions and enrich the elements occurring in the HTTP
trace with syntactic, semantic, location and ﬂow labels whose
meaning is summarized in Figure 2. The preconditions in
Table III determine how these elements are selected for each
pattern.
For instance, since RA1 is a replay attack that tries to re-
play an element from (UV, SPM) to (UM, SPT), it is reasonable
to replay only those elements that ﬂow from TTP to SP, i.e.
data ﬂow label TTP-SP. Indeed, these are the ones that are
likely to comprise speciﬁc values that TTP issues for UV. In
addition, it would make little sense to replay elements whose
values do not change over different traces. This is why that
pattern selects only elements in the trace that are tagged either
as session unique (SU) or user unique (UU) (the users are
different among the sessions where the replay takes place).
The precondition of RA2 is analogous to that of RA1, but
since RA2 replays an element from (UM, SPM) to (UM, SPT),
then that element must ﬂow from SP to TTP. Similar reasoning
holds for other attack patterns. Notice that for RedURI pattern
(inspired by attacks #7 and #8), we consider only the URLs
that are chosen by the SPT, but can be changed by the users
(see deﬁnition of RURI label in Figure 2).
In Table III, we have also introduced a new attack pattern
named RA5 which is inspired by the “credential
leak in
browser history” threat model which is mentioned in the OAuth
2.0 threat model and security considerations document [20].
According to this threat model, UM and UV share the same
browser. In the attack strategy, UM replays (to SPT) the HTTP
elements that are issued by the TTP to SPT for UV. Notice that
in the preconditions it is mentioned that the security critical
parameters which are used in this attack strategy must be
located in the request URL. The request URLs of a browsing
session are likely to be stored in the browser history.
Last, but not least, attack patterns need a way to determine
whether the attack strategy they executed was successful to
detect any attack. The postconditions included in Table III
serve this purpose. The idea is that each one of the four
nominal sessions is associated with a Flag that deﬁnes what
determines the successful completion of it. For instance, a
string “Welcome Victim” could be the Flag for the nominal
session (UV, SPT) of a MPWA implementing a SSO solution
(assuming that “Victim” is the name provided by UV at SPT).
The concept of Flag will be further clariﬁed in the next section.
The postcondition is just a program that checks whether a
certain Flag is captured or not while executing the strategy.
A value of the form (U, SP ) in the column Postcondition
stands for this program checking for the Flag associated with
(U, SP ).
It must be noticed that
the deﬁnition of postcondition
depends on the speciﬁc MPWA under test.
IV. APPROACH
Figure 3 outlines the two processes underlying our ap-
proach. In the ﬁrst one, executable attack patterns are created,
reviewed, and improved by security experts (see Section IV-A).
The second process enables testers to identify security issues
in their MPWAs. In a nutshell, the testers (e.g., developers of
a MPWA) take advantage of the security knowledge embedded
within the executable attack patterns. We will see that what is
requested to testers is not much more of what they have to do
anyhow in order to test the business logic of their MPWAs.
See Section IV-B for details.
A. Creating, reviewing, and improving Attack Patterns
Working on our attack patterns require web application
security knowledge and implementation skills. Security ex-
perts,
in particular those who perform penetration testing
of web applications, have clearly both. Security experts can
thus read and understand attack patterns like those sketched
in Table III. Improving an attack pattern, by changing few
6
the element
is assigned different
Syntactic labels provide type information:a
- URL: a URL, e.g.,redirect uri=http://google.com,
- BLOB: an alphanumeric string with (optionally) special
characters, e.g., code=vrDK7rE4,
- WORD: a string comprised only of alphabetic characters,
e.g., response type=token,
- EMAIL: an email address, e.g., usrname=jdoe@example.
com,
- EMPTY: an empty value, e.g., state=,
- NUMBER: a number, e.g., id=5,
- BOOL: a boolean value, e.g., new=true, and
- UNKNOWN: none of the other syntactic labels match this
string, e.g., #target.
Semantic labels provide information on the role played by the
element within the MPWA:b
- SU (Session Unique):
values in different sessions.
- UU (User Unique): the element is assigned the same value
in the sessions of the same user.
- AU (App Unique): the element is assigned the same value
in the sessions of a single SP.
- MAND (Mandatory): the element must occur for the proto-
col to complete successfully.
- RURI (Redirect URI): the element must be MAND, it must
be a URL that is passed as a parameter in a request uri and it
is later found in the Location header of a redirection response.
Flow labels represent the data ﬂow properties of an element in
the HTTP trafﬁc. Currently we have two ﬂow labels: TTP-
SP and SP-TTP. Label TTP-SP (SP-TTP, resp.) means
that the corresponding element has been received from TTP
(SP, resp.) and then sent to SP (TTP, resp.). Location labels
denotes the location in the HTTP Message where the element
has been found. The labels that we use are REQUESTURI,
REQUESTHEADER, REQUESTBODY, RESPONSEHEADER and
RESPONSEBODY indicating the location of the element as
request URI, request header, request body, response header
and response body respectively.
aMost of the syntactic labels are borrowed from [36], [32]
bWhile the SU and UU labels are borrowed from [36], the AU and RURI
labels are new. The MAND label generalizes the SEC label introduced in [36],
where it was used to indicate a secret speciﬁc to the current session and
necessary for the success of the authentication, while here MAND is not
necessarily secret and SU.
Fig. 2: Syntactic, Semantic, Flow and Location Labels
Fig. 3: Approach
things here and there to e.g., make it a bit more general,
is also a straightforward follow-up step. Creation of attack
patterns asks for some more effort and, more importantly,
for inspiration. As discussed in Section III, with the only
exception of RA5, all attack patterns in Table III have been
inspired by attacks reported in literature. The discovery of a
previously unknown attack not yet covered by our catalog of
7
attack patterns is, of course, another source of inspiration. In
general, security experts can craft attack patterns capturing
novel attack strategies to explore new types of attacks. This
is the case for attack pattern RA5, which we developed to
explore the “credential leak in browser history” threat model
(e.g., see [20, §4.4.2.2]). This threat model, referred to as the
browser history attacker, is important because browsers can
be shared (e.g., public libraries, internet cafes). To the best of
our knowledge, we are the ﬁrst to include this threat model in
a black-box security testing approach.
A browser history attacker shares the same browser with
other Users. It is assumed that the user does not always clear
her browser history, but she properly signs out from her login
sessions. The attack pattern RA5 leverages this threat model by
replaying all the elements issued by the TTP that the attacker
can collect from the browser history of the victim. As we
will see in Section VI, by using this threat model, we have
been able to detect two attacks that could not be discovered
automatically using other state-of-the-art black-box security
testing techniques.
B. Security Testing Framework
The different phases of our security testing framework are
described below. Figure 4 shows how these phases concretely
apply on the following illustrative example: The developer
Diana has implemented the Stripe checkout solution in her
web application. She is required to ensure that (r1) the new
feature works as it should and (r2) it does not harm the
security of her web application. Diana feels conﬁdent for (r1)
as the Stripe API is documented and there are several demo
implementations available in the Internet that she can use as
references. However, she does not for (r2) as she does not have
a strong security background.
Let us see how our approach empowers people like Diana
(referred to as the tester) to do a systematic usage of the body
of knowledge collected by security experts.
(P1) Conﬁguration. The tester conﬁgures the testing envi-
ronment so to be able to collect traces for the four nominal ses-
sions: S1 = (UV, SPT), S2 = (UM, SPT), S3 = (UV, SPM),
and S4 = (UM, SPM). To this end, the tester creates two user
accounts, UV and UM, in her service provider SPT and in
a reference implementation SPM (the purpose of SPM is to
represent the SP controlled by the malicious party). Notice
that, this step does not require a strong security background
and normally does not add-up any additional cost for the tester
that wants to functionally test her MPWA. All major TTPs
provide reference implementations—e.g., [7], [6], [9], [4]—
to foster adoption of their solutions. In case a working ofﬁcial
reference implementation is not available, another SP (running
the same protocol) can be used.
(P2) Recording. In order to enable the testing engine to
automatically collect the necessary HTTP trafﬁc, the tester
records the user actions (UAs for short) corresponding to
sessions S1 to S4. This amount to collecting the actions UV
and UM perform on the browser B while running the protocol
with SPT and SPM. Additionally, for each sequence of UAs,
the tester must also identify a Flag, i.e. a regular expression
representing a pattern in the HTTP trafﬁc which can be used to
determine the successful execution of the user actions. Flags
must be different between each other so to be able to ensure
which session was completed without any ambiguity. Stan-
dard web browser automation technologies such as Selenium
The Stripe checkout protocol is illustrated in Figure 4a. It is slightly different than
the PayPal Payments Standard presented in Figure 1b. Hereafter how the Stripe
protocol works. In steps 1-5, the user U visits SP—an e-shopping application—at
URI SP and initiates the checkout of a product item I—the item is identiﬁed by
I ID. Upon receiving the checkout request, SP returns a payment form embedded
with a unique identiﬁer (DataKey) issued by Stripe to SP (step 6). The user
provides credit card details (Credentials) to Stripe and DataKey is sent in this
request (steps 7-8). After verifying the validity of Credentials, Stripe returns a
token (T oken) which is speciﬁc to the SP (steps 9-10). Upon presenting T oken and
Secret (a secret credential possessed by each SP integrating the Stripe checkout
solution) and Amt (cost of I), SP withdraws Amt from the user’s credit card
(steps 11-12). Finally, the status of the transaction is sent to the user (step 13).
(a) Stripe checkout protocol
(P1) Conﬁguration. Diana uses the SP she implemented as
SPT and the ofﬁcial reference implementations provided by
Stripe [14] as SPM. For each of them, she creates the two user
accounts UV and UM.
(P2) Recording. Table 4b summarizes the UAs and Flags
collected by Diana during the recording phase. Note that the
UAs are obtained from steps 1, 4, and 7 of Figure 4a, while the
Flag is derived from step 13 in Figure 4a (I1-I4 indicate four
different items).
(P3) Inference. An excerpt of the inference results of the
protocol underlying Diana’s
the Stripe
checkout protocol is shown in Table 4c.
implementation of
(P4) Application of Attack Patterns. The result of applying
each attack pattern of Table III on this example is reported in
Table 4d.
(b) User Actions and Flags of Stripe Checkout
No.
S1
Session
(UV, SPT)
S2
(UM, SPT)
S3
(UV, SPM)
S4
(UM, SPM)
UAs
1. Visit URI SPT
2. Click Checkout
3. Enter credentials UV
1. Visit URI SPT
2. Click Checkout
3. Enter credentials UM
1. Visit URI SPM
2. Click Checkout
3. Enter credentials UV
1. Visit URI SPM
2. Click Checkout
3. Enter credentials UM
Flag
“bought I1”