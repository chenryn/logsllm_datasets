title:Fallout: Leaking Data on Meltdown-resistant CPUs
author:Claudio Canella and
Daniel Genkin and
Lukas Giner and
Daniel Gruss and
Moritz Lipp and
Marina Minkin and
Daniel Moghimi and
Frank Piessens and
Michael Schwarz and
Berk Sunar and
Jo Van Bulck and
Yuval Yarom
Fallout: Leaking Data on Meltdown-resistant CPUs
Claudio Canella1, Daniel Genkin2, Lukas Giner1, Daniel Gruss1, Moritz Lipp1, Marina Minkin2,
Daniel Moghimi3, Frank Piessens4, Michael Schwarz1, Berk Sunar3, Jo Van Bulck4, Yuval Yarom5
1Graz University of Technology,
2University of Michigan,
3Worcester Polytechnic Institute,
4imec-DistriNet, KU Leuven,
5The University of Adelaide and Data61
ABSTRACT
Meltdown and Spectre enable arbitrary data leakage from memory
via various side channels. Short-term software mitigations for Melt-
down are only a temporary solution with a significant performance
overhead. Due to hardware fixes, these mitigations are disabled on
recent processors.
In this paper, we show that Meltdown-like attacks are still pos-
sible on recent CPUs which are not vulnerable to Meltdown. We
identify two behaviors of the store buffer, a microarchitectural re-
source to reduce the latency for data stores, that enable powerful
attacks. The first behavior, Write Transient Forwarding forwards
data from stores to subsequent loads even when the load address
differs from that of the store. The second, Store-to-Leak exploits the
interaction between the TLB and the store buffer to leak metadata
on store addresses. Based on these, we develop multiple attacks
and demonstrate data leakage, control flow recovery, and attacks
on ASLR. Our paper shows that Meltdown-like attacks are still pos-
sible, and software fixes with potentially significant performance
overheads are still necessary to ensure proper isolation between
the kernel and user space.
KEYWORDS
side-channel attack, Meltdown, Spectre, store buffer, store-to-load
ACM Reference Format:
Claudio Canella, Daniel Genkin, Lukas Giner, Daniel Gruss, Moritz Lipp,
Marina Minkin, Daniel Moghimi, Frank Piessens, Michael Schwarz, Berk
Sunar, Jo Van Bulck, Yuval Yarom. 2019. Fallout: Leaking Data on Meltdown-
resistant CPUs. In 2019 ACM SIGSAC Conference on Computer and Commu-
nications Security (CCS ’19), November 11–15, 2019, London, United Kingdom.
ACM, New York, NY, USA, 16 pages. https://doi.org/10.1145/3319535.3363219
1 INTRODUCTION
The computer architecture and security communities will remember
2018 as the year of Spectre and Meltdown [47, 51]. Speculative and
out-of-order execution, which have been considered for decades to
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
CCS ’19, November 11–15, 2019, London, United Kingdom
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-6747-9/19/11...$15.00
https://doi.org/10.1145/3319535.3363219
be harmless and valuable performance features, were discovered
to have dangerous industry-wide security implications, affecting
operating systems [47, 51], browsers [1, 47], virtual machines [78],
Intel SGX [74] and cryptographic hardware accelerators [72].
Recognizing the danger posed by this new class of attacks, the
computer industry mobilized. For existing systems, all major OSs
deployed the KAISER countermeasure [25], e.g., on Linux under the
name KPTI, potentially incurring significant performance losses [23].
For newer systems, Intel announced a new generation of silicon-
based countermeasures, mitigating many transient-execution at-
tacks directly in hardware, while improving overall performance [15].
However, while Intel claims that these fixes correctly address
the hardware issues behind Meltdown and Foreshadow, it remains
unclear whether new generations of Intel processors are properly
protected against Meltdown-type transient-execution attacks. Thus,
in this work we set out to investigate the following questions:
Are new generations of processors adequately protected against transient-
execution attacks? If so, can ad-hoc software mitigations be safely
disabled on post-Meltdown Intel hardware?
Unfortunately, this paper answers these
Our Contributions.
questions in the negative, showing that data leakage is still possible
even on newer Meltdown-protected Intel hardware, which avoids
the use of older software countermeasures. At the microarchitec-
tural level, in this work, we focus on the store buffer, a microarchi-
tectural element which serializes the stream of stores and hides the
latency of storing values to memory. In addition to showing how
to effectively leak the contents of this buffer to read kernel writes
from user space, we also contribute a novel side channel on the
translation lookaside buffer (TLB), named Store-to-Leak, that ex-
ploits the lacking permission checks within Intel’s implementation
of the store buffer to break KASLR, to break ASLR from JavaScript,
and to infer the kernel control flow.
Thus, in this work we make the following contributions:
(1) We discover a security flaw due to a shortcut in Intel CPUs,
which we call Write Transient Forwarding (WTF), that allows
us to read the data corresponding to recent writes.
(2) We demonstrate the security implications of the WTF shortcut
by recovering the values of recent writes performed by the OS
kernel, recovering data from within TSX transactions, as well
as leaking cryptographic keys.
(3) We identify a new TLB side channel, which we call Store-to-
Leak. Store-to-Leak exploits Intel’s store-to-load forwarding
unit in order to reveal when an inaccessible virtual store ad-
dress is mapped to a corresponding physical store address by
exploiting a missing permission check when forwarding from
these addresses.
(4) We demonstrate how to exploit Store-to-Leak for breaking
KASLR and ASLR from JavaScript, as well as how to use it
to simplify the gadget requirements for Spectre-style attacks.
(5) We identify a new cause for transient execution, namely assists,
which are small microcode routines that execute when the
processor encounters specific edge-case conditions.
(6) We implement the first documented Meltdown-type attacks that
exploit page fault exceptions due to Supervisor Mode Access
Prevention (SMAP).
Store-to-leak was responsibly dis-
Responsible Disclosure.
closed to Intel by the authors from Graz University of Technology
on January 18, 2019. Write Transient Forwarding was then responsi-
bly disclosed to Intel by the authors from the University of Michigan,
and University of Adelaide and Data61, on January 31, 2019. Intel
indicated that it was previously aware of the Write Transient For-
warding issue, assigning it CVE-2018-12126, Microarchitectural
Store Buffer Data Sampling (MSBDS). According to Intel, we were
the first academic groups to report the two respective issues.
Write Transient Forwarding was also disclosed to AMD, ARM,
and IBM, which stated that none of their CPUs are affected.
In concurrent works, RIDL [76] and
RIDL and ZombieLoad.
ZombieLoad [68] demonstrate leakage from the Line Fill Buffer
(LFB) and load ports on Intel processors. They show that faulty
loads can also leak data from these other microarchitectural re-
sources across various security domains. Fallout is different from
and complementary to the aforementioned contributions, as it at-
tacks the store buffer and store instructions, as opposed to loads.
RIDL, ZombieLoad, and this work were disclosed to the public under
the umbrella name of Microarchitectural Data Sampling (MDS).
2 BACKGROUND
In this section, we present background regarding cache attacks,
transient-execution attacks, Intel’s store buffer implementation,
virtual-to-physical address translation, and finally address-space-
layout randomization (ASLR).
2.1 Cache Attacks
Processor speed increased by several orders of magnitude over
the past decades. While the bandwidth of modern main mem-
ory (DRAM) has also increased, the latency has not kept up with
the change. Consequently, the processor needs to fetch data from
DRAM ahead of time and buffer it in faster internal storage. For this
purpose, processors contain small memory buffers, called caches,
that store frequently or recently accessed data. In modern proces-
sors, the cache is organized in a hierarchy of multiple levels, with
the lowest level being the smallest but also the fastest.
Caches are used to hide the latency of memory accesses, as
there is a speed gap between the processor and DRAM. As a result,
caches inherently introduce timing channels. A multitude of cache
attacks have been proposed over the past two decades [7, 28, 62, 80].
Today, the most important practical attack techniques are Prime+
Probe [62, 63] and Flush+Reload [80]. Some of these techniques
exploit the last-level cache, which is shared and inclusive on most
processors. Prime+Probe attacks constantly measure how long it
takes to fill an entire cache set. Whenever a victim process accesses
a cache line in this cache set, the measured time will be slightly
higher. In a Flush+Reload attack, the attacker constantly flushes
the targeted memory location, e.g., using the clflush instruction.
The attacker then measures how long it takes to reload the data.
Based on the reload time, the attacker determines whether a victim
has accessed the data in the meantime. Flush+Reload has been
used for attacks on various computations, e.g., web server function
calls [81], user input [29, 50, 67], kernel addressing information [27],
and cryptographic algorithms [6, 8, 19, 43, 64, 80].
Covert channels represent a slightly different scenario, in which
the attacker, who controls both the sender and receiver, aims to cir-
cumvent the security policy, leaking information between security
domains. Both Flush+Reload and Prime+Probe have been used as
high-performance covert channels [28, 52, 56].
2.2 Transient-Execution Attacks
Program code can be represented as a stream of instructions. Follow-
ing this instruction stream in strict order would result in numerous
processor stalls while instructions wait for all operands to become
available, even though subsequent instructions may be ready to
run. To optimize this case, modern processors first fetch and de-
code instructions in the front end. In many cases, instructions are
split up into smaller micro-operations (µOPs) [18]. These µOPs are
then placed in the so-called Reorder Buffer (ROB). µOPs that have
operands also need storage space for these operands. When a µOP
is placed in the ROB, this storage space is dynamically allocated
from the load buffer for memory loads, the store buffer for mem-
ory stores, and the register file for register operations. The ROB
entry only references the load and store buffer entries. While the
operands of a µOP still may not be available when it is placed in
the ROB, the processor can now schedule subsequent µOPs. When
a µOP is ready to be executed, the scheduler schedules it for execu-
tion. The results of the execution are placed in the corresponding
registers, load buffer entries, or store buffer entries. When the next
µOP in order is marked as finished, it is retired, and the buffered
results are committed and become architectural.
As software is rarely purely linear, the processor has to either
stall execution until a (conditional) branch is resolved or speculate
on the most likely outcome and start executing along the predicted
path. The results of those predicted instructions are placed in the
ROB until the prediction is verified. If the prediction was correct, the
predicted instructions are retired in order. Otherwise, the processor
flushes the pipeline and the ROB without committing any archi-
tectural changes and execution continues along the correct path.
However, microarchitectural state changes, such as loading data
into the cache or TLB, are not reverted. Similarly, when an interrupt
occurs, operations already executed out of order must be flushed
from the ROB. We refer to instructions that have been executed but
never committed as transient instructions [10, 47, 51]. Spectre-type
attacks [10, 11, 35, 46–48, 54] exploit the transient execution of
instructions before a misprediction is detected. Meltdown-type at-
tacks [5, 10, 39, 40, 46, 51, 72, 74, 78] exploit the transient execution
of instructions before a fault is handled.
2.3 Store Buffer
When the execution unit needs to write data to memory, instead
of waiting for the completion of the store, it merely enqueues the
request in the store buffer. This allows the CPU to continue execut-
ing instructions from the current execution stream, without having
to wait for the write to finish. This optimization makes sense, as
in many cases writes do not influence subsequent instructions, i.e.,
only loads to the same address should be affected. Meanwhile, the
store buffer asynchronously processes the stores, ensuring that
the results are written to memory. Thus, the store buffer prevents
CPU stalls while waiting for the memory subsystem to finish the
write. At the same time, it guarantees that writes reach the memory
subsystem in order, despite out-of-order execution.
For every store operation that is added to the ROB, the CPU
allocates an entry in the store buffer. This entry requires both the
virtual and physical address of the target. On Intel CPUs, the store
buffer has up to 56 entries [42], allowing for up to 56 stores to be
handled concurrently. Only if the store buffer is full, the front end
stalls until an empty slot becomes available again [42].
Although the store buffer hides the latency of stores, it also
increases the complexity of loads. Every load has to search the
store buffer for pending stores to the same address in parallel to
the regular L1 lookup. If the full address of a load matches the
full address of a preceding store, the value from the store buffer
entry can be used directly. This optimization for subsequent loads
is called store-to-load forwarding [34].
2.4 Address Translation and TLB
Memory isolation is the basis of modern operating system security.
For this purpose, processes operate on virtual instead of physical
addresses and are architecturally prevented from interfering with
each other. The processor translates virtual to physical addresses
through a multi-level page-translation table. The process-specific
base address of the top-level table is kept in a dedicated register,
e.g., CR3 on x86, which is updated upon a context switch. The page
table entries track various properties of the virtual memory region,
e.g., user-accessible, read-only, non-executable, and present.
The translation of a virtual to a physical address is time-consuming.
Therefore, processors have special caches, translation-lookaside
buffers (TLBs), which cache page table entries [38].
2.5 Address Space Layout Randomization
To exploit a memory corruption bug, an attacker often requires
knowledge of addresses of specific data. To impede such attacks, dif-
ferent techniques like address space layout randomization (ASLR),
non-executable stacks, and stack canaries have been developed.
KASLR extends ASLR to the kernel, randomizing the offsets where
code, data, drivers, and other mappings are located on every boot.
The attacker then has to guess the location of (kernel) data struc-
tures, making attacks harder.
The double page fault attack by Hund et al. [36] breaks KASLR.
An unprivileged attacker accesses a kernel memory location and
triggers a page fault. The operating system handles the page fault
interrupt and hands control back to an error handler in the user
program. The attacker now measures how much time passed since
triggering the page fault. Even though the kernel address is inac-
cessible to the user, the address translation entries are copied into
the TLB. The attacker now repeats the attack steps, measuring the
execution time of a second page fault to the same address. If the
memory location is valid, the handling of the second page fault will
take less time as the translation is cached in the TLB. Thus, the
attacker learns whether a memory location is valid even though
the address is inaccessible to user space.
The same effect has been exploited by Jang et al. [45] in com-
bination with Intel TSX. Intel TSX extends the x86 instruction set
with support for hardware transactional memory via so-called TSX
transactions. A TSX transaction is aborted without any operating
system interaction if a page fault occurs within it. This reduces the
noise in the timing differences that was present in the attack by
Hund et al. [36] as the page fault handling of the operating system
is skipped. Thus, the attacker learns whether a kernel memory
location is valid with almost no noise at all.
The prefetch side channel presented by Gruss et al. [27] exploits
the software prefetch instruction. The execution time of the instruc-
tion is dependent on the translation cache that holds the correct
entry. Thus, the attacker not only learns whether an inaccessible
address is valid but also the corresponding page size.
3 ATTACK PRIMITIVES
In this section, we introduce the underlying mechanisms for the
attacks we present in this paper. First, we introduce the Write Tran-
sient Forwarding (WTF) shortcut, that allows user applications
to read kernel and TSX writes. We then describe three primitives
based on Store-to-Leak, a side-channel that exploits the interaction
between the store buffer and the TLB to leak information on the
mapping of virtual addresses. We begin with Data Bounce, which
exploits the conditions for Store-to-Leak to attack both user and ker-
nel space ASLR (cf. Section 6). We then exploit interactions between
Data Bounce and the TLB in the Fetch+Bounce primitive. Fetch+
Bounce enables attacks on the kernel at a page-level granularity,
similar to previous attacks [21, 24, 65, 79] (cf. Section 7). We con-
clude this section by augmenting Fetch+Bounce with speculative
execution in Speculative Fetch+Bounce. Speculative Fetch+Bounce
leads to usability improvement in Spectre attacks (cf. Section 8).
3.1 Write Transient Forwarding
In this section, we discuss the WTF shortcut, which incorrectly
passes values from memory writes to subsequent faulting load
instructions. More specifically, as explained in Section 2.3, when
a program attempts to read from an address, the CPU must first
check the store buffer for writes to the same address, and perform
store-to-load forwarding if the addresses match. An algorithm for
handling partial address matches appears in an Intel patent [33].
Remarkably, the patent explicitly states that:
“if there is a hit at operation 302 [lower address match]
and the physical address of the load or store opera-
tions is not valid, the physical address check at oper-
ation 310 [full physical address match] may be con-
sidered as a hit and the method 300 [store-to-load
forwarding] may continue at operation 308 [block
load/forward data from store].”
MAP_POPULATE, ...);
memory_access(lut + 4096 * attacker_address[offset]);
tsx_end();
1 char* victim_page = mmap(..., PAGE_SIZE, PROT_READ | PROT_WRITE,
2
3 char* attacker_address = 0x9876543214321000ull;
4
5 int offset = 7;
6 victim_page[offset] = 42;
7
8 if (tsx_begin() == 0) {
9
10
11 }
12
13 for (i = 0; i < 256; i++) {
14
15
16
17 }