[4]) or RCF, a core calculus for F# (shown in [6]).
Protocol execution. Given a particular protocol Π (mod-
eled as a tree), the set of possible protocol traces is deﬁned
by traversing the tree: in case of an input node the adver-
sary nondeterministically picks a term t with S ⊢ t where
S are the terms sent so far through output nodes; at com-
putation nodes, a new term is computed by applying a con-
structor or destructor to terms computed/received at earlier
nodes; then the left or right successor is taken depending on
whether the destructor succeeded. The sequence of nodes
dec(dk (t1), enc(ek (t1), m, t2)) = m
isenc(enc(ek (t1), t2, t3)) = enc(ek (t1), t2, t3)
isenc(garbageEnc(t1, t2)) = garbageEnc(t1, t2)
isek (ek (t)) = ek (t)
isdk (dk (t)) = dk (t)
ekof (enc(ek (t1 ), m, t2 )) = ek (t1)
ekof (garbageEnc(t1 , t2 )) = t1
ekofdk (dk (t1)) = ek (t1)
verify(vk (t1), sig(sk (t1), t2, t3)) = t2
issig(sig(sk (t1), t2, t3)) = sig(sk (t1), t2, t3)
issig(garbageSig (t1, t2)) = garbageSig (t1, t2)
isvk (vk (t1)) = vk (t1)
issk (sk (t)) = sk (t)
vkof (sig(sk (t1), t2, t3)) = vk (t1)
vkof (garbageSig (t1, t2)) = t1
vkofsk (sk (t1)) = vk (t1)
fst (pair (x, y)) = x
snd (pair (x, y)) = y
unstring 0(string 0(s)) = s
unstring 1(string 1(s)) = s
equals(t1, t1) = t1
Figure 1: Rules deﬁning the destructors. A destruc-
tor application matching none of these rules evalu-
ates to ⊥.
we traverse in this fashion is called a symbolic node trace
of the protocol. By specifying sets of node traces, we can
specify trace properties for a given protocol. We refer to [4]
for details on the protocol model and its semantics.
3. DEFINITIONS OF COMPUTATIONAL
SOUNDNESS
We now sketch how computational soundness is deﬁned.
For details, we refer to [4].
In order to say whether we
have computational soundness or not, we ﬁrst need to
specify a computational implementation A. Following [4],
this is done by specifying a partial deterministic function
AF : ({0, 1}∗)n → {0, 1}∗ for each constructor or destruc-
tor F/n.3 Also AN is an distribution of bitstrings modeling
the distribution of nonces. Given a computational imple-
mentation, we can execute a protocol in the computational
model. This execution is fully analogous to the symbolic
execution, except that in computation nodes, instead of ap-
plying constructors/destructors F to terms, we apply AF
to bitstrings, and in input/output nodes, we receive/send
bitstring from/to a polynomial-time adversary.
Definition 1
(Comput. soundn. – simplified [4]).
We say a computational implementation A is a computa-
tionally sound implementation of a symbolic model for a
3Probabilistic algorithms such as encryption are modeled
by an explicit additional argument that takes a nonce as
randomness.
701m ∈ S
S ⊢ m
N ∈ NE
S ⊢ N
S ⊢ t
t ∈ T
F ∈ C ∪ D
S ⊢ evalF (t)
evalF (t) 6= ⊥
Figure 2: Deduction rules for the symbolic model
A
τ
Sim
β
Π
Figure 3: A typical CoSP simulator
class P of protocols if the following holds with overwhelming
probability for any polynomial-time adversary A and any
protocol Π ∈ P : The node trace in the computational
protocol execution is a valid node trace in the symbolic
protocol execution.
4. COMPUTATIONAL
SOUNDNESS
PROOFS IN COSP
Before we proceed and present the computational assump-
tions, we ﬁrst give an overview on how prior computational
soundness proofs were conducted. Since we based our result
on the proof in the CoSP framework, we review the proof
as it was performed there [4]. The problems we will face are
not speciﬁc to their proof though.
Remember that in the CoSP framework, a protocol is
modeled as a tree whose nodes correspond to the steps of
the protocol execution; security properties are expressed as
sets of node traces. Computational soundness means that
for any polynomial-time adversary A the trace in the com-
putational execution is, except with negligible probability,
also a possible node trace in the symbolic execution. The
approach for showing this is to construct a so-called simu-
lator Sim. The simulator is a machine that interacts with a
symbolic execution of the protocol Π on the one hand, and
with the adversary A on the other hand; we call this a hy-
brid execution. (See Figure 3.) The simulator has to satisfy
the following two properties:
• Indistinguishability: The node trace in the hybrid ex-
ecution is computationally indistinguishable from that
in the computational execution with adversary A.
• Dolev-Yaoness: The simulator Sim never (except for
negligible probability) sends terms t to the protocol
with S 0 t where S is the list of terms Sim received
from the protocol so far.
The existence of such a simulator (for any A) then guar-
antees computational soundness: Dolev-Yaoness guarantees
that only node traces occur in the hybrid execution that are
possible in the symbolic execution, and indistinguishability
guarantees that only node traces occur in the computational
execution that can occur in the hybrid one.
How to construct a simulator? In [4], the simulator
Sim is constructed as follows: Whenever it gets a term
from the protocol, it constructs a corresponding bitstring
and sends it to the adversary, and when receiving a bit-
string from the adversary it parses it and sends the re-
sulting term to the protocol. Constructing bitstrings is
done using a function β, parsing bitstrings to terms us-
ing a function τ .
(See Figure 3.) The simulator picks
all random values and keys himself: For each protocol
nonce N , he initially picks a bitstring rN . He then trans-
lates, e.g., β(N ) := rN and β(ek (N )) := Aek (rN ) and
β(enc(ek (N ), t, M )) := Aenc(Aek (rN ), β(t), rM ). Translat-
ing back also is natural: Given m = rN , we let τ (m) := N ,
and if c is a ciphertext that can be decrypted as m using
Adk (rN ), we set τ (c) := enc(ek (N ), τ (m), M ). However, in
the last case, a subtlety occurs: what nonce M should we
use as symbolic randomness in τ (c)? Here we distinguish
two cases:
If c was earlier produced by the simulator: Then c was
the result of computing β(t) for some t = enc(ek (N ), t′, M )
and some nonce M . We then simply set τ (c) := t and have
consistently mapped c back to the term it came from.
If c was not produced by the simulator:
In this case
it is an adversary generated encryption, and M should
be an adversary nonce to represent that fact. We could
just use a fresh nonce M ∈ NE, but that would intro-
duce the need of additional bookkeeping:
If we compute
t := τ (c), and later β(t) is invoked, we need to make sure
that β(t) = c in order for the Sim to work consistently (for-
mally, this is needed in the proof of the indistinguishability
of Sim). And we need to make sure that when computing
τ (c) again, we use the same M . This bookkeeping can be
avoided using the following trick: We identify the adversary
nonces with symbols N m annotated with bitstrings m. Then
τ (c) := enc(ek (N ), τ (m), N c), i.e., we set M := N c. This
ensures that diﬀerent c get diﬀerent randomness nonces N c,
the same c is always assigned the same N c, and β(t) is easy
to deﬁne: β(enc(ek (N ), m, N c)) := c because we know that
enc(ek (N ), m, N c) can only have been produced by τ (c). To
illustrate, here are excerpts of the deﬁnitions of β and τ (the
ﬁrst matching rule counts):
• τ (c) := enc(ek (M ), t, N ) if c has earlier been output
by β(enc(ek (M ), t, N )) for some M ∈ N, N ∈ NP
• τ (c) := enc(ek (M ), τ (m), N c) if c is of type ciphertext
and τ (Aekof (c)) = ek (M ) for some M ∈ NP and m :=
Adec(Adk (rM ), c) 6= ⊥
• β(enc(ek (N ), t, M ))
:= Aenc(Aek (rN ), β(t), rM )
if
M ∈ NP
• β(enc(ek (M ), t, N m)) := m if M ∈ NP
Bitstrings m that cannot be suitably parsed are mapped into
terms garbage (N m) and similar that can then be mapped
back by β using the annotation m.
Showing indistinguishability. Showing indistinguisha-
bility essentially boils down to showing that the functions
β and τ consistently translate terms back and forth. More
precisely, we show that β(τ (m)) = m and τ (β(t)) = t. Fur-
thermore, we need to show that in any protocol step where
a constructor or destructor F is applied to terms t1, . . . , tn,
we have that β(F (t1, . . . , tn)) = AF (β(t1), . . . , β(tn)). This
makes sure that the computational execution (where AF is
applied) stays in sync with the hybrid execution (where F is
applied and the result is translated using β). The proofs of
702these facts are lengthy (involving case distinctions over all
constructors and destructors) but do not provide much addi-
tional insight; they are very important though because they
are responsible for most of the implementation conditions
that are needed for the computational soundness result.
Showing Dolev-Yaoness. The proof of Dolev-Yaoness is
where most of the actual cryptographic assumptions come
in.
In this sketch, we will slightly deviate from the orig-
inal proof in [4] for easier comparison with the proof in
the present paper. The diﬀerences are, however, inessential.
Starting from the simulator Sim, we introduce a sequence
of simulators Sim 2, Sim 4, Sim 7. (We use a numbering with
gaps here to be compatible with our full proof [7].)
In Sim 2, we change the function β as follows: When in-
voked as β(enc(ek (N ), t, M )) with M ∈ NP , instead of com-
puting Aenc(Aek (rN ), β(t), rM ), β invokes an encryption or-
acle ON
enc to produce the ciphertext c. Similarly, β(ek (N ))
returns the public key provided by the oracle ON
enc. The hy-
brid executions of Sim and Sim 2 are then indistinguishable.
(Here we use that the protocol conditions guarantee that no
randomness is used in two places.) Also, the function τ is
changed to invoke ON
enc whenever it needs to decrypt a ci-
phertext while parsing. Notice that if c was returned by β(t)
with t := enc(. . . ), then τ (c) just recalls the term t without
having to decrypt. Hence ON
enc is never asked to decrypt a
ciphertext it produced.
In Sim 4, we replace the encryption oracle ON
enc by a fake
encryption oracle ON
fake that encrypts zero-plaintexts instead
of the true plaintexts. Since ON
enc is never asked to decrypt a
ciphertext it produced, IND-CCA2 security guarantees that
the hybrid executions of Sim 2 and Sim 4 are indistinguish-
able. Since the plaintexts given to ON
fake are never used, we
can further change β(enc(N, t, M )) to never even compute
the plaintext β(t).
Finally, in Sim 7, we additionally change β to use a sign-
ing oracle in order to produce signatures. As in the case of
Sim 2, the hybrid executions of Sim 4 and Sim 7 are indistin-
guishable.
Since the hybrid executions of Sim and Sim 7 are indis-
tinguishable, in order to show Dolev-Yaoness of Sim, it is
suﬃcient to show Dolev-Yaoness of Sim 7.
The ﬁrst step to showing this is to show that whenever
Sim 7 invokes β(t), then S ⊢ t holds (where S are the terms
received from the protocol). This follows from the fact that
β is invoked on terms t0 sent by the protocol (which are then
by deﬁnition in S), and recursively descends only into sub-
terms that can be deduced from t0. In particular, in Sim 4 we
made sure that β(t) is not invoked by β(enc(ek (N ), t, M ));
t would not be deducible from enc(ek (N ), t, M ).
Next we prove that whenever S 0 t, then t contains a vis-
ible subterm tbad with S 0 tbad such that tbad is a protocol
nonce, or a ciphertext enc(. . . , N ) where N is a protocol
nonces, or a signature, or a few other similar cases. (Visibil-
ity is a purely syntactic condition and essentially means that
tbad is not protected by an honestly generated encryption.)
Now we can conclude Dolev-Yaoness of Sim 7: If it does
not hold, Sim 7 sends a term t = τ (m) where m was sent by
the adversary A. Then t has a visible subterm tbad . Visi-
bility implies that the recursive computation of τ (m) had a
subinvocation τ (mbad ) = tbad . For each possible case of tbad
we derive a contradiction. For example, if tbad is a proto-
col nonce, then β(tbad ) was never invoked (since S 0 tbad )
and thus mbad = rN was guessed by the simulator without
ever accessing rN which can happen only with negligible
probability. Other cases are excluded, e.g., by the unforge-
ability of the signature scheme and by the unpredictability
of encryptions. Thus, Sim 7 is Dolev-Yao, hence Sim is in-
distinguishable and Dolev-Yao. Computational soundness
follows.
5. RESTRICTIONS IN THE PROOF AND
HOW TO SOLVE THEM
The proof of computational soundness from [4] only works
if protocols obey the following restrictions:
• The protocol never sends a decryption key (not even
within a ciphertext).
• The protocol never decrypts using a decryption key it
received from the net.
• The protocol avoids key cycles (i.e., encryptions of de-