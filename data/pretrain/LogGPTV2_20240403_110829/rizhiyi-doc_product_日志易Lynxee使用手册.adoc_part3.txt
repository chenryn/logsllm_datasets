==== 监控项设计最佳实践
在 IT 运维领域经典书籍《SRE：谷歌运维解密》中，介绍了一个监控指标的设计框架。将面向用户系统中最重要的衡量因素，总结为 4 个黄金指标：
延迟(lantency)::
衡量完成操作所需时间的指标。常见的比如：处理时间，响应时间或传输时间。
+
捕获各种服务的延迟使您可以构建 IT 系统不同性能特征的整体模型。这可以帮助您找到瓶颈，了解哪些资源需要最多的时间来访问，并注意何时突然花费的时间超过预期。
+
计算延迟时，需要区分成功和不成功请求，因为它们可能具有使服务平均值产生偏差的非常不同的配置文件。
流量(traffic)::
衡量组件和系统的“繁忙程度”。
+
流量速率对于帮助理解问题最为有用。例如，如果延迟增加超出可接受的水平，则能够将该时间帧与流量峰值相关联是有帮助的。
+
对于容量规划需求，还可以使用流量来了解可以处理的最大流量以及服务在各个负载阶段如何降级或失败。
错误(error)::
衡量组件的运行状况以及它们未能适当地响应请求的频率。
+
错误类型的指标，有些服务可能有现场的接口输出或供获取，有些需要运维人员通过外部手段监控获取。
饱和(saturation)::
测量给定资源的使用量。
+
饱和度数据提供有关服务依赖于有效运行的资源的信息。由于一个组件提供的服务可能被另一个组件使用，因此饱和度是表明底层系统容量问题的粘合度量之一。
+
因此，一层中的饱和度和延迟问题可能对应于底层中的流量或错误测量的显着增加。
使用这 4 个黄金指标，还需要在不同层次上关注系统的复杂性，书中总结为 5 个层次，依次如下：
单体服务器::
这也是最传统的服务器基础监控内容。根据布伦丹·格雷格(Brendan Gregg，Netflix 高级性能架构师，DTrace 工具作者)提出的USE性能分析方法，可以把这个层次划分为 CPU、内存、存储、网络等 4 个子层次。每个也有自己的具体黄金指标。
CPU:::
* 延迟：CPU调度程序的平均或最大延迟
* 流量：CPU利用率
* 错误：处理器特定的错误事件，出现故障的CPU
* 饱和度：运行队列长度
内存:::
* 流量：正在使用的内存量
* 错误：内存不足错误
* 饱和度：OOM事件，交换频率
存储设备:::
* 延迟：读取和写入的平均等待时间（await）
* 流量：读写I / O级别
* 错误：文件系统错误，磁盘错误 /sys/devices
* 饱和度：I / O队列深度
网络:::
* 延迟：网络驱动程序队列
* 流量：每秒传入和传出的字节或数据包
* 错误：网络设备错误，丢包
* 饱和度：溢出，丢弃数据包，重新传输的段
应用和服务::
应用服务层，衡量单个服务实例的指标。也是比较容易理解的部分：
* 延迟：完成请求的时间
* 流量：每秒服务请求数
* 错误：处理客户端请求或访问资源时发生的应用程序错误
* 饱和度：当前使用的资源的百分比或数量
集群服务器::
集群环境下，比单个实例要多加集群成员之间的协调和路由的衡量因素。所以错误和饱和度需要注意：
* 延迟：池响应请求的时间，与对等方协调或同步的时间
* 流量：池每秒处理的请求数
* 错误：处理客户端请求，访问资源或到达对等方时发生的应用程序错误
* 饱和度：当前使用的资源量，当前以容量运行的服务器数量，可用服务器数量。
依赖外部环境::
外部依赖通常在你的管理权责之外，一旦出问题，只能切换服务提供商。所以需要在业务规划之处，做好松耦合：
* 延迟：从服务接收响应或从提供者提供新资源所需的时间
* 流量：推送到外部服务的工作量，对外部API的请求数
* 错误：服务请求的错误率
* 饱和度：使用的帐户限制资源的数量（实例，API请求，可接受的成本等）
端到端的体验::
最终用户接触系统的第一步，也最合适作为整体用户体验的近似值监控指标。为了避免响应疲劳，可以通过这个直接影响 SLA 的最高层级的黄金指标的监控告警，在页面上逐级向下钻取其他层级的指标，调查最终问题。
* 延迟：完成用户请求的时间
* 流量：每秒的用户请求数
* 错误：处理客户端请求或访问资源时发生的错误
* 饱和度：当前使用的资源的百分比或数量
== 数据接入
Lynxee 支持从外部数据源直接接收指标数据，或从日志易平台数据源进行定时统计生成指标数据等不同方式完成指标数据的对接工作。
=== 外部 Kafka 对接
Lynxee 从日志易集群内置 Kafka 的特定主题中实时消费指标数据，默认主题为 lynxee_kpis，您可以通过日志易 Manager 中 kpi_monitor 模块的 `kafka.topic` 参数修改。
Lynxee 是一种实时数据监测系统，所以默认只对实时接入的最新数据进行异常检测判断。系统默认的"实时"范围为最近 10 分钟。您可以通过日志易 Manager 中 kpi_monitor 模块的 `realHealth.overtime` 参数修改。
Lynxee 支持监测的数据自主声明采样间隔，也支持对未声明的数据自动采用系统内置的的统一采样间隔，见 kpi_monitor 模块的 `realHealth.interval` 参数，默认为 1 分钟。即接入的指标数据，在未声明自己原始采样间隔的情况下，在检测(包括训练页面的手动检测和模型应用以后的实时检测)时，都按照每 1 分钟一个数据点来对待。同理，由多个指标监控项计算得到的服务健康度，也是每 1 分钟一个值(由于实时接入的偏差，同一分钟的健康度分值可能会随着指标的接入多次更新)。
系统将自动在指标名称后面附加展示采样间隔，不同采样间隔的指标数据，即使名称相同，也视作不同指标数据处理。
Lynxee 约定接入的指标数据应采用如下例所示格式。
[source,type="json"]
--------
{
 "operator":"user",
 "token":"xxxxxx",
 "service":"com.rizhiyi.beaver",
 "metric":"index.query_total",
 "endpoint":"192.168.1.111",
 "time_interval":"60000",
 "tags":{
     "index_name":"yotta"
 },
 "timestamp": 1234567890,
 "value":23232
}
--------
其中各字段解释如下:
* operator: 日志易用户名称。
* token: 日志易租户域标识。系统通过这两个信息来校验数据是否可以正常接入。
* endpoint: 指标的采集来源设备。此处应使用某个设备对象的名称。通常而言，这个设备也会归属于 service 代表的那个服务。如果未设置，默认为 default。
* service: 指标采集来源设备归属的服务名称，通过名称内部的`.` 串联多层次组织，形成树状关系。此处应使用某个服务对象的内部 ID。如果未设置，默认为 default。
* metric: 指标名称，通过名称内部的 `.` 串联多层次组织，形成树状关系。
* time_interval: 指标原始采样间隔，单位毫秒。如果未设置，默认为 realHealth.interval 设置值。
* tags: 如果指标在设备上有多重来源，可以采用 tags 键值对进行详细区分。比如：分磁盘的使用率、分索引的查询数等。你也可以将具体某块磁盘创建为设备类型，这样就无需 tags 标记。在使用 tags 标记时，指标监控必须明确指定到具体某个标记键值对。
* timestamp: 指标的某次采集时间，粒度为秒，长整型。
* value: 指标的某次采集取值，浮点数类型。
接收的指标数据，将存储在 kpi_monitor 索引中，您可以采用日志易 SPL 进行任意维度的查询和统计，甚至将 SPL 统计结果再次上卷为新的指标数据。上卷操作参见后续的"日志统计数据生成"章节。
image::images/lynxee-kpi-monitor-index.png[]
kpi_monitor 索引数据的字段结构描述如下：
* 原始指标数据包括以下字段：
** appname: 固定为 kpi_point
** timestamp: 指标的某次采集时间
** value: 指标的某次采集取值
** endpoint: 指标采集的来源终端实体
** name: 指标的名称
** service: 指标采集来源设备归属的服务名称
** time_interval_ms: 指标的采集间隔
** tags.: 附属于该指标的其他标签键值对
** kpi_id: 由上述service/name/endpoint/time_interval_ms/tags字段值所产生的可以唯一标识一个指标序列的ID
* 检测结果数据在原始数据字段基础上，还有以下新增或变化：
** appname: 实时检测的结果为detected_point，界面点击检测的结果为temp_detected_point
** bound: 算法计算得到正常范围区间，根据算法的不同，上下限可能不会全部具备
** health: 算法计算得到的指标检测健康度分值，取值范围在0-100之间
** label: 检测结果，0为正常，1为异常
** model_id: 运用的算法模型ID
** score: 算法返回的异常分值，不同算法的异常分值区间和意义不一致，不可用于横向对比，请采用转换以后的health分值
* 服务健康度数据是日志易单独计算并存储的数据，包含以下字段：
** appname: 固定为kpi_health
** timestamp: 服务健康度生成的时间
** health: 服务健康度分值
** service: 服务的名称
==== 树状名称最佳实践
Lynxee 并不强制规范指标数据对接时必须如何组织树状名称。本节仅介绍部分大型互联网企业的实践行为。
> 将企业 IT 治理关系定义为固定的 Schema，各层次从顶而下分别是：company, team, location, idc, product, subsystem, service, module, group, partition, cluster。
> 实践中并不要求所有层次都明确定义，可以跳跃定义。
比如一台机器在 CMDB 中的架构归属是：`company=yottabyte,team=rizhiyi,location=beijing,idc=dabailou,product=Lynxee,subsystem=web`，那么这台机器上面的查询数指标，自然就组织成为: `{"service":"yottabyte.rizhiyi.beijing.dabailou.Lynxee.web", "metric":"http.get_total.2xx"}` 了。
=== 外部对接数据的聚合指标
在外部数据对接完成以后，我们还可以基于对接结果，进行二次聚合统计。通常来说，集群场景下我们可能从外部 Kafka 对接获得不同设备上的查询数，负载等指标，而我们很自然会想到可能还需要一个集群总查询数，集群总平均负载这样的总体性指标，作为服务的核心指标来做观测。
在指标列表的第三列，表头上有 `f(x)` 小图标，点击即可选择，对该列下的不同 entity/tag 指标，进行求和或求平均值的二次聚合。聚合指标的 tag 名字，自动为 `AGG(kpis_list)` 形式。如下所示：
image::images/lynxee-kpi-agg-new.png[]
点击聚合图标以后，可以按需勾选加入聚合的指标。
image::images/lynxee-kpi-agg-select.png[]
注：目前暂时不支持动态的囊括相同 service/metric下的全部 entity/tag。
随后，页面将展示选定时段下的聚合数据预览折线图。如果您对预览数据效果满意，点击折线图右上角的"设为指标"按钮，正式保存为指标。该聚合指标和参与计算的其他 entity/tag 一样，属于同一个 service 和 metric 层次内。
image::images/lynxee-kpi-agg-backfill.png[]
一般而言，您可能希望在保存为指标的时候，让系统主动回溯一段历史数据，以便尽快的积累到足够的数据量方便算法的训练。在设为指标的配置弹层上，勾选"是否回溯数据"，并配置具体的回溯时间范围。点击"创建"。刷新页面后，在原位置可以看到新增了一行指标，鼠标聚焦后，高亮提示其类型为"聚合指标"，状态为"回溯中"或"回溯完成"。
image::images/lynxee-kpi-agg-tip.png[]
聚合指标在后续训练和检测操作上和普通对接指标保持一致。
=== 日志统计数据生成
Lynxee 支持从日志易平台上通过 SPL 查询统计方式生成全新的指标数据并检测其是否异常。在指标列表的右上方，点击打开新建指标的配置浮层：
image::images/lynxee-kpi-spl-new.png[]
配置内容包括：
* Service：新建指标所属Service，为和对接数据保持一致，名称部分约束为 `a.b.c` 格式。Service采用树状结构在指标探索页面的Service列展示。
* Metric：为和对接数据保持一致，名称部分约束为 `a.b.c` 格式。SPL 统计指标在指标探索页面的Metric列展示时依然采用树状结构。
* 过滤项：填写 SPL 语句中的查询过滤部分，即 `| timechart` 前面的部分。一般而言通常为 querystring，也可以带有非统计类 SPL 函数。比如 `appname:cisco | parse "(?\d{5})" | where eid>30000` 。
* 统计：选择一个 timechart 指令所支持的统计函数，并填写对应的统计参数，通常为字段名称。timechart 支持的统计函数包括：sum, avg, max, min, dc, count。
* 采样间隔：可选择 1/5/10/30 秒或 1/5/10/30 分钟或 1 小时等不同的采样间隔。
上图中配置项最后将生成预览数据结果的 SPL 查询语句为：`appname:mysql tag:slow req_time:>1000 | timechart span=1m count(appname)`。
填写完成后，点击"预览"，也会在页面下方展示 SPL 查询语句的返回结果，并以折线图方式预览。您如果对预览数据效果满意，点击折线图右上角的"设为指标"按钮，正式保存为指标。该指标附属于指定Service 层次内。
SPL指标的回溯及保存配置流程，模型训练及检测运用流程等，和聚合指标操作相同。
在日志统计指标生成以后，您可以在指标列表的 entity/tag 列，看到名为 default 的指标，鼠标聚焦之后，高亮提示其类型为"SPL指标"。
image::images/lynxee-kpi-spl-tip.png[]
[NOTE]
====
Lynxee需要采用独立的用户名密码来获取 SPL 数据的查询权限，请您创建好用户后，在日志易 Manager 的 kpi_monitor 模块中填写 `frontend.user` 和 `frontend.password` 参数。否则，不填写配置直接尝试创建 SPL 统计指标会失败报错。
====