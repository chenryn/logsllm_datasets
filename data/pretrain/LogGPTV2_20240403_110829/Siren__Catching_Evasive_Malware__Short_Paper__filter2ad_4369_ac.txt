input on the clone that damages the state because it 
would be thrown away later on. Again, malware can 
create a schedule and attempt to predict future usage 
by recording and examining old input. (If the input is 
old, then it is likely to have been entered before the 
clone operation and thus by the real user.) 
to 
identify  real  human 
For  all  of  these  input  generation  systems,  it  is 
currently an open question how difficult it would be 
for  an  attacker 
input. 
However, the attacking program has the extra burden 
of  needing  to  be  very  sure  that  it  is  correct.  If  the 
probability  that  the  input  is  actually  real  when  the 
malware program thinks it is, call it p, is much less 
than 1, then the probability of remaining undetected 
decreases  exponentially  over  time.  The  program 
could  still  have  pretty  good  odds  if  it  is  able  to 
package up very large amounts of data into a single 
burst. This attack can be easily prevented, however, 
by  employing  a  rate-limiting  anomaly  detection 
system  such  as  Web  Tap  [2] in  parallel  with  Siren. 
Now, if the probability of correctness for the malware 
program is .95, or it is correct 95% of the time about 
the user being present, then it still would have over a 
50% chance of being detected after sending 14 times. 
To  be  successful,  Siren  only  needs  to  fool  the 
attacker some of the time. 
5. Siren’s Security Analysis 
There  are  a  few  different  methods  that  an 
attacker  could  use  to  avoid  or  prolong  detection  by 
Siren. If the input generation algorithm is weak, then 
Siren can take advantage of its shortcomings to learn 
characteristics  of  real  input  or  even  identify  it 
immediately.  For  example,  if  input  is  only  injected 
into cloned virtual machines, then malware can look 
at  older  data  to  see  real  a  user’s  input  and  predict 
when he or she will be active next. If the generation 
algorithm  does  not  act  sufficiently  human,  malware 
may  be  able  to  use  this  to  its  advantage.  If  the 
algorithm never uploads files, for example, then a file 
upload  will  let  the  malware  know  that  it  is  safe  to 
send data over the network.  
is  an  attack 
succeed,  delivers 
As  mentioned  earlier,  one  of  the  preconditions 
for Siren to eventually detect a piece of malware is 
that  the  malware  must  continually  send  network 
messages over time. A potential vulnerability in the 
that  requires  user-
Siren  system 
interaction 
to 
the  payload 
immediately, and exits. One example of such a threat 
is an e-mail worm. If the worm only opens up when 
the  user  clicks  on  an  e-mail,  sends  e-mails  to 
everybody  in the  address  book,  and  then  terminates 
very  quickly,  Siren  would  have  a  very  hard  time 
detecting it. One way of mitigating this vulnerability 
is  to  deploy  additional  deception  methods,  such  as 
adding bogus addresses to the e-mail client’s address 
book. 
Another  precondition  for  Siren  to  be  able  to 
detect  a  piece  of  malicious  software  is  that  the 
attacker  cannot  determine  usage  through  an  out-of-
band channel. A hacker could call up a user on the 
phone  and  tell  that  person  to  enter  a  particular 
sequence  of  input  triggering  some  malware.  The 
hacker  could  also  talk  to  the  user  over  an  instant 
messaging  program  to  guarantee  that  the  user  is 
active  on  his  or  her  computer.  Although  these  and 
other  social  engineering  techniques  could  help  an 
attacker figure out when a user is present, and Siren 
has  no  way  to  stop  them,  they  are  not  trivial  to 
execute  and  usually  require  association  of  a  phone 
number and name with an IP or e-mail address. 
Finally, malicious software could hide data in a 
covert  channel.  One  example  would  be  modifying 
TCP  flags  in  outbound  traffic.  However,  these 
channels  are  often  very  low  bandwidth  and  would 
require  the attacker to  be  passively  listening  on  the 
path of a connection. 
6. Conclusion 
Traditional  behavioral  analysis  techniques  are 
able to detect many novel threats, but are vulnerable 
to mimicry attacks. In this paper, we presented Siren, 
a  detection  system  that  looks  at  human  input  to 
identify malicious network traffic. Siren also  injects 
bogus human input to confuse and disrupt attackers 
who try to mimic legitimate programs by waiting for 
user input to send network messages.  
realistic  human 
In this paper we discussed possible methods for 
creating 
input,  and  addressed 
potential  shortcomings  such  as  inadvertent  state 
modification.  For  our  evaluation,  we  manually 
entered a predetermined sequence of input on a clean 
machine  and  on  virtual  machines  with  ten  different 
types  of  spyware  installed.  Siren  was  able  to  detect 
all 
ten  spyware  programs,  while  a  competing 
anomaly  detection  system  that  does  in  inject  input 
was only able to detect three of the ten. Finally, we 
discussed  methods  of  attacking  Siren  itself  such  as 
out-of-band  information  gathering  and  identifying 
real activity by waiting for state-changing operations. 
7. Acknowledgements 
the 
from 
We  acknowledge  support 
Intel 
Corporation  and  the  National  Science  Foundation. 
We  also  thank  the  reviewers  for  their  helpful 
comments. 
8. References 
[1] P. Barham, B. Dragovic, K. Fraser, S. Hand, T. Harris, 
A. Ho,  R. Neugebauer,  I. Pratt,  and  A. Warfield.  Xen  and 
the  Art  of  Virtualization.  In  Proc.  19th  ACM  Symp.  on 
Operating Systems Principles, pp. 164-177, 2003. 
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
[2] K. Borders and A. Prakash. Web Tap: Detecting Covert 
Web Traffic. In Proc. 11th ACM Conf.  on Computer and 
Communications Security, pp. 110-120, 2004. 
[17]  S. King and P. Chen. Subvirt: Implementing malware 
with  virtual  machines.  In  IEEE  Symp.  on  Security  and 
Privacy, Oakland, California, May 2006. 
[3]  W.  Cheswick.  An  Evening  with  Berferd  In  Which  a 
Hacker  is  Lured  Endured  and  Studied.  In  Proc.  of  the 
Winter Usenix 92 Conference, 1992. 
[4]  M.  Chew  and  J.D.  Tygar: 
Image  Recognition 
CAPTCHAs. In Proc. 7th Information Security Conference,
2004. 
[5] C. Clark, K. Fraser, S. Hand, J. G. Hansen, E. Jul, C. 
Limpach,  I.  Pratt,  and  A.  Warfield.  Live  Migration  of 
Virtual  Machines.  Proc.  2nd  ACM/USENIX  Symp.  on 
Networked Systems Design and Implementation, 2005. 
[6] J. Clark and D. Pradhan. Fault Injection: A Method for 
Validating  Computer-System  Dependability.  Computer,
28(6):47-56, June 1995.  
[7] A. Coates, H. Baird, and R. Fateman. Pessimistic Print: 
A  Reverse  Turing  Test.  In  Proc.  Sixth  Intl.  Conf.  on 
Document Analysis and Recognition, pp. 1154, 2001. 
[18]  O.  Kolesnikov,  D.  Dagon,  and  W.  Lee.  Advanced 
Polymorphic  Worms:  Evading  IDS  by  Blending  in  with 
Normal Traffic. Georgia Tech Technical Report, GIT-CC-
04-15, 2004-2005. 
[19] C. Kruegel and E. Kirda. Automating Mimicry Attacks 
Using  Static  Binary  Analysis.  In  Proc.  14th  USENIX 
Security Symposium, pp. 161–176, 2005. 
[20] Y. Liao and V. R. Vemuri. Using Text Categorization 
Techniques for Intrusion Detection. In Proc.  11th USENIX 
Security Symposium, pp. 51-59, 2002. 
[21]  MessageLabs.  MessageLabs  Survey  Finds  Spyware 
No.  1  Web  Security  Issue  for  Australian  Businesses. 
http://www.computerworld.com.au/index.php/
id;478111644, 2005. 
[22]  K.  Mitnick  and  W.  Simon.  The  Art  of  Deception: 
Controlling the Human Element of Security. Wiley (2002). 
[8]  F.  Cohen,  D.  Lambert,  C.  Preston,    N.  Berry,  C. 
Stewart,  and  E.  Thomas.  A  Framework  for  Deception. 
http://www.all.net/journal/deception/Framework/
Framework.html, July 2001. 
[23]  M.  Naor.  Verification  of  a  Human  in  the  Loop,  or 
Identification via the Turing Test. Unpublished manuscript,
http://www.wisdom.weizmann.ac.il/~naor/PAPERS/human
_abs.html, 1996.  
[9] W Cui, R. Katz, and W. Tan. BINDER: An Extrusion-
Based Break-In Detector for Personal Computers. In Proc. 
USENIX Annual Technical Conference, 2005. 
[24]  B.  Schneier.  Attack  Trends:  2004  and  2005,  Queue,
June2005. http://www.schneier.com/blog/archives/2005/
06/attack_trends_2.html.
[25]  L.  Spitzner.  The  Other  Honeypot,  July  2003. 
http://www.securityfocus.com/infocus/1713.
[26]  K.  Tan,  K.S.  Killourhy,  and  R.A.  Maxion. 
Undermining  an  Anomaly-Based 
Intrusion  Detection 
System Using Common Exploits. In Proc. Fifth Intl. Symp. 
on Recent Advances in Intrusion Detection (RAID), pp. 54-
73. Lectures Notes in Computer Science #2516, Springer-
Verlag, Oct. 2002. 
[27]  Sun  Tzu.  The  Art  of  War  (translated  by  James 
Clavell). Dell Publishing, New York, 1983. 
[28]  D.  Wagner  and  P.  Soto.  Mimicry  Attacks  on  Host-
Based  Intrusion  Detection  Systems.  In  Proc.  9th  ACM 
Conf. on Computer and Communications Security, pp. 255-
264, 2002.
[29] Y. Zhang and V. Paxson. Detecting Stepping Stones. 
In  Proc.  9th  USENIX  Security  Symposium,  pp.  171-184, 
August 2000.
[10]  H.  Feng,  O.  Kolesnikov,  P.  Fogla,  W.  Lee,  and  W. 
Gong. Anomaly Detection Using Call Stack Information. In 
Proc. IEEE Symp. on Security and Privacy, 2003. 
[11]  T.  Garfinkel  and M.  Rosenblum.  A  Virtual Machine 
Introspection Based Architecture for Intrusion Detection. In 
Proc.  ISOC  Symp.  on  Network  and  Distributed  System 
Security, 2003. 
[12]  T.  Garfinkel  and  M.  Rosenblum.  When  Virtual  is 
Harder than Real: Security Challenges in Virtual Machine-
based  Computing  Environments.  In  Proc.  10th  Workshop 
on Hot Topics in Operating Systems (HotOS-X), May 2005. 
[13] S. A. Hofmeyr, S. Forrest, and A. Somayaji. Intrusion 
Detection  Using  Sequences  of  System  Calls.  Journal  of 
Computer Security, 6(3):151–180, 1998. 
[14] HoneyPots. http://www.honeypots.org, 2005. 
[15] A. Joshi, S. King, G. Dunlap, and P. Chen. Detecting 
Past and Present Intrusions through Vulnerability-Specific 
In  Proc.  Symp.  on  Operating  Systems 
Predicates. 
Principles, 2005. 
[16]  G.  H.  Kim  and  E.  H.  Spafford.  The  Design  and 
Implementation  of  Tripwire:  a  File  System  Integrity 
In  Proc.  ACM  Conf.  on  Computer  and 
Checker. 
Communications Security, 1994. 
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE