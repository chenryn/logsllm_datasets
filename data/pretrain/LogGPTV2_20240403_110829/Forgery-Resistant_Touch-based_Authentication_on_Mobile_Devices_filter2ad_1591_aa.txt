title:Forgery-Resistant Touch-based Authentication on Mobile Devices
author:Neil Zhenqiang Gong and
Mathias Payer and
Reza Moazzezi and
Mario Frank
Forgery-Resistant Touch-based Authentication on Mobile
Devices
Neil Zhenqiang Gong
ECE, Iowa State University
PI:EMAIL
Mathias Payer
CS, Purdue University
PI:EMAIL
Reza Moazzezi
EECS, UC Berkeley
PI:EMAIL
Mario Frank
EECS, UC Berkeley
PI:EMAIL
ABSTRACT
Mobile devices store a diverse set of private user data and
have gradually become a hub to control users’ other per-
sonal Internet-of-Things devices. Access control on mobile
devices is therefore highly important. The widely accepted
solution is to protect access by asking for a password. How-
ever, password authentication is tedious, e.g., a user needs
to input a password every time she wants to use the device.
Moreover, existing biometrics such as face, ﬁngerprint, and
touch behaviors are vulnerable to forgery attacks.
We propose a new touch-based biometric authentication
system that is passive and secure against forgery attacks. In
our touch-based authentication, a user’s touch behaviors are
a function of some random “secret”. The user can subcon-
sciously know the secret while touching the device’s screen.
However, an attacker cannot know the secret at the time
of attack, which makes it challenging to perform forgery at-
tacks even if the attacker has already obtained the user’s
touch behaviors. We evaluate our touch-based authentica-
tion system by collecting data from 25 subjects. Results are
promising: the random secrets do not inﬂuence user experi-
ence and, for targeted forgery attacks, our system achieves
0.18 smaller Equal Error Rates (EERs) than previous touch-
based authentication.
CCS Concepts
•Security and privacy → Authentication; Biometrics;
Keywords
touch biometrics; mobile authentication; forgery-resistant
biometrics
1.
INTRODUCTION
Since the introduction of the ﬁrst iPhone by Apple in June
2007, touch based mobile devices have become ubiquitous.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
ASIA CCS ’16, May 30-June 03, 2016, Xi’an, China
c(cid:13) 2016 ACM. ISBN 978-1-4503-4233-9/16/05. . . $15.00
DOI: http://dx.doi.org/10.1145/2897845.2897908
For instance, the volume of the smartphone market has al-
ready surpassed that of the PC market in 2011 [23]. Users of-
ten store a large amount of sensitive data on mobile devices.
Moreover, with the advent of Internet-of-Things (IoT) de-
vices such as smartwatches, ﬁtness trackers, the Nest Ther-
mostat [14], and medical devices like Bee [3], smartphones
have gradually become the hub of IoT. Speciﬁcally, a user
could use a smartphone to control her smartwatch, adjust
home temperature via remotely controlling the Nest Ther-
mostat, and view the user’s insulin injection data and glu-
cose levels from Bee. Access control on mobile devices is
important because having access to a user’s mobile device
allows an attacker to 1) access the user’s personal data, and
2) control the user’s other connected IoT devices and access
sensitive data on them. For instance, an attacker that ob-
tains access to a smartphone can access the user’s sensitive
SMS messages, emails, and apps, as well as manipulate the
user’s home temperature by remotely controlling the con-
nected Nest Thermostat.
The most popular method to address such threats is to
authenticate a user via password before allowing her to use
the device, i.e., the user logs in the device with a correct
password. However, users might turn oﬀ password authen-
tication because it is tedious and inconvenient [5, 10, 21].
For instance, Egelman et al. [10] showed that 42% of users
do not lock their smartphones, and 34% of them do so be-
cause locking is “too much of a hassle”. Moreover, it is well
known that conventional biometrics such as face, ﬁngerprint,
and voice are vulnerable to forgery attacks [1, 2, 11]. For
instance, ﬁngerprint readers can be tricked by taking an im-
age of the ﬁngerprint, forming a mold, and using wood glue
to make a fake ﬁnger [11]. Therefore, it is urgent to design
secure and usable authentication methods.
A number of recent studies have raised the possibility of
using low level interactions such as how a user touches the
screen as a biometric signature for authentication in mobile
devices [4, 9, 12, 13, 17]. The key idea for such authenti-
cation mechanisms is that users produce touch data all the
time when using the device so that authentication can be
passive, i.e., without requiring the user to carry out any ac-
tion dedicated to authentication.
However, this touch-based authentication mechanism, like
conventional biometrics,
is also vulnerable to forgery at-
tacks. For instance, an attacker (e.g., a ‘friend’ or the spouse
of the targeted user) can collect the targeted user’s touch
data via convincing her to use the attacker’s mobile devices
and recording her touch data. Later, the attacker can pro-
user in s from the behavior of the same user in other set-
tings and those of other users in all considered settings. In
the authentication phase, we randomly sample a predeﬁned
setting and use the corresponding model to continuously au-
thenticate the user in each time interval. Our authentica-
tion system can signiﬁcantly decrease the success rate of an
attacker who knows the targeted user’s touch data in all
settings. This is because the attacker cannot know the set-
ting used by our system at the time of attacks and replaying
touch data collected in a diﬀerent setting fails to pass the
authentication with high probability.
Third, we evaluate our system via collecting data from
25 subjects in ﬁve diﬀerent settings along the X axis and
ﬁve diﬀerent settings along the Y axis. We ﬁnd that users
can subconsciously adapt their touch behavior to diﬀerent
screen settings, i.e., the transitions between two settings do
not interrupt users nor aﬀect user experiences. Moreover,
our system achieves 0.02 to 0.09 smaller mean Equal Er-
ror Rates (EER) than previous work for random forgery at-
tacks and 0.17 to 0.18 smaller mean EERs than previous
work for targeted forgery attacks; the registration phase of
our authentication system takes a short period of time, i.e.,
touch data collected within two minutes are enough to train
a model for a setting; and our system achieves smaller EERs
with more screen settings.
behavior to screen settings.
In summary, our key contributions are as follows:
• We demonstrate the stability and sensitivity of touch
• We propose a new touch-based continuous authenti-
cation mechanism, which builds on the stability and
sensitivity properties of behavioral touch patterns to
achieve forgery-resistant touch signatures.
• We evaluate our authentication system via collecting
touch data from 25 subjects in ﬁve screen settings along
the X axis and ﬁve screen settings along the Y axis. We
demonstrate that our system signiﬁcantly outperforms
previous work at defending against forgery attacks.
2. BACKGROUND AND RELATED WORK
Screen settings: Users interact with a mobile device via
swiping, clicking, or zooming on the screen. For instance,
users often slide over the screen horizontally (e.g., navi-
gate to the next page of icons in the main screen or browse
through photos) and vertically (e.g., read webpages, social
media updates, or emails), which result in horizontal swipes
and vertical swipes, respectively. A swipe is also called a
stroke, and we will use them interchangeably in the paper.
The sensors on the screen record the location, timing,
pressure, and covering area of interactions. More speciﬁ-
cally, an interaction is a sequence of touch points (ti,xi,yi,pi,ai),
where ti is the timestamp, xi is the horizontal location, yi is
the vertical location, pi is the pressure, and ai is the cover-
ing area of the ith touch point. Then these touch points are
transformed by the operating system to higher-level primi-
tives such as clicks, swipes, and zooms. Applications on the
mobile device access the transformed primitives through the
operating system. In the following, touch behavior refers to
the raw touch data recorded by the screen sensors.
A screen setting controls how the sensed raw data is trans-
formed to the primitives that are used by applications. For
instance, screen settings can independently distort the X
(i.e., horizontal) axis or the Y (i.e., vertical) axis. Note that
Figure 1: Concepts of stability and sensitivity.
gram a Lego robot to replay the collected touch data on the
targeted mobile device, which can compromise the authen-
tication system with a high probability [19].
Our work: In this work, we demonstrate a defense against
forgery attacks to touch-based biometrics. In particular, we
defend against forgery attacks by leveraging the impact of
screen settings (serving as a random “secret”) on a user’s
touch behavior. The sensors on the screen of a mobile device
record where, when, how fast, and how heavily a user’s ﬁn-
ger touches the screen. Before the recorded raw data is sent
to applications on the mobile device, our approach trans-
forms the data as it passes through the operating system
according to a screen setting. For instance, a screen setting
of 0.8 horizontal distortion means that a 1.0cm long hor-
izontal line starting at a certain location on the screen is
received by the application as a 0.8cm long horizontal line
starting at the same location. Due to such modiﬁcations,
the running applications react diﬀerently to the actions of
the user. As a consequence, the user will adapt her touch
behavior (i.e., raw touch data recorded by screen sensors)
in order to achieve the desired application behavior.
Ide-
ally, the adaptation is performed subconsciously, i.e., the
user does not explicitly notice that the screen settings have
changed but still adapts the touch behavior to compensate
for this change. We investigate the impact of screen settings
on a user’s touch behavior and their applications to defend
against forgery attacks.
First, we ﬁnd that, when screen settings are discretized
properly, a user’s touch behavior in two diﬀerent screen set-
tings is stable, meaning that the behavior diﬀerence between
two diﬀerent users in the same setting is larger than that
between two diﬀerent settings for the same user. Stability
guarantees that we can distinguish a user’s touch behavior
from other users’. Unfortunately, stability implies that if we
learn a model to distinguish a user’s touch behavior from
other users’ using only a single setting, then forgery attacks
that replay the targeted user’s data collected in other set-
tings succeed with a high probability. Extending stability,
we ﬁnd that a user’s touch behavior in diﬀerent screen set-
tings is also sensitive, meaning that they have a high degree
of separability in the feature space. Sensitivity guarantees
that one can learn a model to distinguish touch behavior of
a user in two diﬀerent screen settings, serving as a basis for
a suﬃcient defense against forgery attacks. Figure 1 shows
the concepts of stability and sensitivity.
Second, based on our ﬁndings, we propose a novel contin-
uous authentication mechanism called adaptive touch-based
continuous authentication. Our system consists of a registra-
tion phase and an authentication phase. In the registration
phase, we sample a set of screen settings in which a user’s
touch behavior is both stable and sensitive. Then we train
a model for each setting s to distinguish the behavior of the
u,	
  Sa	
  u,	
  Sb	
  others,	
  Sa,	
  Sb	
  (a)	
  Unstable	
  and	
  sensi.ve	
  u,	
  Sb	
  others,	
  Sa,	
  Sb	
  (b)	
  Stable	
  and	
  insensi.ve	
  u,	
  Sb	
  others,	
  Sa,	
  Sb	
  (c)	
  Stable	
  and	
  sensi.ve	
  u,	
  Sa	
  u,	
  Sa	
  transformation is only applied to a sequence of touch points
and the ﬁrst touch point of any interaction is not trans-
formed. Therefore, one-touch operations like clicking a but-
ton on an application will not be aﬀected by diﬀerent screen
settings. Moreover, since screen settings are transparent to
applications, application developers do not need to change
their applications when the screen settings are modiﬁed.
Suppose a user draws a line from position (10,10) to po-
sition (110,110) on the screen. Under a screen setting of 0.8
Y-distortion the application would see a line from position
(10,10) to position (110,90). Under a screen setting of 1.2
X-distortion the application would see a line from position
(10, 10) to position (130, 110). To account for such transfor-
mations, the user will adapt her touch behavior to achieve
the desired application behavior.
Touch-based continuous authentication: Touch-based
authentication has been proposed ﬁrst in [9] and [16]. How-
ever, both methods require the user to carry out a speciﬁc se-
cret gesture at a deﬁned point of time (unlock challenge) and
then analyze how the gesture is carried out. More recently,
leveraging a user’s touch interactions obtained when the user
interacts with the device to continuously and implicitly mon-
itor the user has attracted increasing attentions. Complex
interactions such as zooming are too infrequently used to be
appropriate for continuous monitoring and clicks exhibit too
few features to be discriminative for users. Therefore, most
previous work focus on swiping interactions (i.e., strokes),
which were demonstrated to contain a behavioral biometric
signature that may be used to continuously authenticate the
user [4, 12, 13, 17, 20].
For instance, Frank et al. [12] extracted 31 features from
each stroke and trained a classiﬁer for a user to distinguish
her touch behavior from other users’. These features in-
clude the direction of the end-to-end line, average velocity,
start locations, and end locations of a stroke. For a com-
plete list of the features, please refer to Frank et al. [12].
More recently, Sae-Bae et al. [18] studied a canonical set of
22 multitouch gestures for authentication on mobile devices,
and they found a desirable alignment of usability and secu-
rity, i.e., gestures that are more secure are rated by users
as more usable. Sherman et al. [20] proposed to use free
gestures as a static authenticator to unlock mobile devices
and they further studied the memorability of user generated
gestures. Xu et al. [24] veriﬁed that touch-based authentica-