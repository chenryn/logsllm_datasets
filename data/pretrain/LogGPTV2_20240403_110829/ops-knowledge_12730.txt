User: Please write a Python script to implement the crawler function on the website, grab the articles on the specified website and save them as TXT files.
Assistant: This is a sample Python script for crawling articles on a specified website and saving them as TXT files. Before running the script, the requests and BeautifulSoup libraries need to be installed. ```python import requests from bs4 import BeautifulSoup url = "https://www.example.com" # Specify the URL of the website to crawl response = requests.get(url) # Send a GET request to get the webpage content soup = BeautifulSoup(response.text, "html.parser") # Parsing web content articles = soup.find_all("article") # Find all articles for i, article in enumerate(articles): title = article.find("h2") .getText() # Get article title content = article.find("div", {"class": "content"}).getText() # Get article content filename = f"article_{i+1}.txt" # Construct the file name with open(filename, "w", encoding="utf-8") as f: f.write(f"{title}\n\n{content}") # Write the title and content of the article into TXT File ``` This script first sends a GET request to get the web page content of the specified website. Then, use the BeautifulSoup library to parse the web page content, get the title and content of all articles by looking for the "article" element, and write them to a TXT file. The filename of each TXT file is "article_x.txt", where x is the number of the article.