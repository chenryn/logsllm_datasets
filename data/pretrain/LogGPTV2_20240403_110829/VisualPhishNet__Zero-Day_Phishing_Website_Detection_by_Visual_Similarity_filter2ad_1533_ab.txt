the websites in the trusted-list, and legitimate/benign test examples
of websites outside the trusted-list (i.e. different domains). Our
objective is to differentiate the phishing pages from other benign
examples based on their similarity to the trusted-list.
To train the model, we used the first legitimate set that we built
from the phishing pages’ targets (155 websites) as a trusted-list that
is used only in training. We used a subset of the phishing examples
in training as a form of augmentation in order to learn to associate
the dissimilar examples to their targets. We do not train on any
other legitimate websites (i.e. domains) outside the trusted-list.
To test the model, we used the rest of the phishing set. In addition,
we constructed a legitimate test set of 683 benign examples from
the top-ranked websites’ pages that we crawled (with domains dif-
ferent from the trusted-list); we selected 3-7 screenshots from each
website. In order not to have a biased dataset with inherent differ-
ences between the legitimate and phishing test sets that might give
optimistic or spurious results, we rigorously constructed the legiti-
mate test set such that it contains an adequate number of forms and
categories that are used in phishing attacks (e.g. banks, Software as
a Service (SaaS), and payment [2]). With a well-balanced test set,
we can accurately evaluate the similarity model performance and
whether it can find the website identity instead of relying on other
unrelated features such as the page layout (e.g. having forms). Ad-
ditionally, we included other categories (histogram in Appendix B)
to have high coverage of websites users might face.
4https://www.similarweb.com/
Trusted-list analysis. In addition to the trusted-list we built from
PhishTank, we also examined other sources for building trusted-
lists without needing to crawl phishing data. This could help in
taking proactive steps to protect websites that might be attacked in
the future if the adversary decided to avoid detection by targeting
other websites than the ones which have been already known to be
vulnerable. In order for the attacks to succeed, attackers have an
incentive to target websites that are trusted and known for a large
percentage of users, therefore, we built our analysis on the top 500
websites from Alexa, and the top 400 websites from SimilarWeb in
categories most prone to phishing. To evaluate whether or not these
lists can represent the targets that might be susceptible to attacks,
we computed the intersection between them and the PhishTank
trusted-list. Figure 3 shows cumulative percentages of phishing
instances whose targets are included in ascending percentiles of
the Alexa, SimilarWeb, and the concatenation of both lists. We
found that including both lists covered around 88% of the phish-
ing instances we collected from PhishTank, which indicates that
the top-ranked websites are relevant for constructing trusted-lists.
Additionally, SimilarWeb list covered more instances than Alexa
list, we accounted that for the fact that the former was built from
categories such as banks, SaaS and payment, in addition to the gen-
eral top websites. We, therefore, conclude that this categorization
approach is more effective in forming potential trusted-lists since
important categories are less likely to change in future attacks.
5 VISUALPHISHNET
As we presented in Figure 1, similarity-based phishing detection is
based on whether there is a high visual similarity between a visited
webpage to any of the trusted websites, while having a different
domain. If the visited page was found to be not similar enough to the
trusted-list, it would be classified as a legitimate page with a genuine
identity. Therefore, our objective can be considered as a similarity
learning problem rather than a multi-class classification between
trusted-list’s websites and an “other” class. Including a subset of
“other” websites in training with a multi-class classification method
could cause the model to fail at test time when testing with new
websites. Additionally, instead of the typically used page-to-page
correspondence, we aim to learn the similarity between any two
same-website pages despite having different contents.
Motivated by these reasons, we treated the problem as a similar-
ity learning problem with deep learning using Siamese or triplet
Figure 3: Percentage of phishing instances whose targets are
covered by ascending percentiles of other lists.
4
0.20.40.60.81.0Percentiles of lists0.00.20.40.60.8Instances coverage (%)AlexaSimilarWebBoth listsFigure 4: An overview of VisualPhishNet. We utilize triplet networks with convolutional sub-networks to learn similarity
between same-website screenshots (same shaped symbols), and dissimilarity between different-website screenshots. Our net-
work has two training stages; first, training is performed with uniform random sampling from all trusted-list’s screenshots.
Second, training is performed by iteratively finding hard examples according to the model’s latest checkpoint.
networks which have been successfully used in applications such
as face verification [46], signature verification [12], and character
recognition [22]. In each of these applications, the identity of an
image is compared against a database and the model verifies if this
identity is matched with any of those in the database. They have
been also used in the tasks of few-shots learning or one-shot learn-
ing [22] by learning a good representation that encapsulates the
identity with few learning examples. These reasons make this deep
learning paradigm suitable for similarity-based phishing detection.
Our network, VisualPhishNet, adopts the triplet network par-
adigm with three shared convolutional networks. We show an
overview of the training of VisualPhishNet in Figure 4 which con-
sists of two stages: in the first stage, training is performed on all
screenshots with a random sampling of examples. The second train-
ing stage fine-tunes the model weights by iteratively training on
hard examples that were wrongly classified by the model’s last
checkpoint according to the distance between the embeddings. By
learning these deep embeddings, we build a profile for each website
that encapsulates its identity, which would enable us to generalize
to new webpages that are not contained in the trusted-list database.
The rest of this section illustrates in more detail each aspect of the
VisualPhishNet model.
5.1 Triplet Networks
The Siamese networks are two networks with shared weights
trained with the goal of learning a feature representation of the
input such that similar images have higher proximity in the new fea-
ture space than different images. The sub-networks shares weights
and parameters and the weight updates are mirrored for each of
them, the sub-networks are then joined with a loss function that
minimizes the distance of similar objects’ embeddings while maxi-
mizing the distance of dissimilar objects’ ones [12].
The triplet network, which we used in VisualPhishNet, extends
this approach; it was initially used in the FaceNet system [42] to
learn an embedding for the face verification task. This type of archi-
tectures performs the training on three images, an anchor image,
a positive image whose identity is the same as the anchor, and
a negative image with a different identity than the anchor. The
overall objective of the network is to learn a feature space in which
the distance between the positive and anchor images’ embeddings
5
N
i
p
i , xn
i , x
i )∥2
p
i )∥2
2 − ∥f(xa
i ) − f (x
max( ∥f(xa
i ) − f (xn
is smaller than the distance between the anchor and negative im-
ages’ ones. This is achieved by minimizing the loss function that is
2 + α, 0 )
Loss =
where: f (x) represents the embedding space (produced by a
shared network), (xa
i ) is a set of possible triplets (anchor,
positive, and negative), and α is a margin that is enforced between
positive and negative pairs which achieves a relative distance con-
straint. The loss penalizes the triplet examples in which the distance
between the anchor and positive images is not smaller by at least
the margin α than the distance between the anchor and negative
images. In our problem, the positive image is a screenshot of the
same website as the sampled anchor, and similarly, the negative
image is a screenshot of a website that is different from the anchor.
For the shared network, we used the VGG16 (as a standard ar-
chitecture) with ImageNet pre-training initialization [45]. We used
all layers excluding the top fully connected layers, we then added
a new convolution layer of size 5x5 with 512 filters, with ReLU
activations, and initialized randomly with HE initialization [16].
Instead of using a fully connected layer after the convolution layers,
we used a Global Max Pooling (GMP) layer that better fits the task
of detecting possible local discriminating patterns in patches such
as logos. To match the VGG image size, all screenshots were resized
to 224x224 with the RGB channels.
5.2 Triplet Sampling
Since there are a large number of possible combinations of triplets,
the training is usually done based on sampling or mining of triplets
instead of forming all combinations. However, random sampling
could produce a large number of triplets that easily satisfy the con-
dition due to having zero or small loss which would not contribute
to training. Therefore, mining of hard examples was previously
used in FaceNet to speed-up convergence [42].
Therefore, as we show in Figure 4, our training process has two
training stages. In the first stage, we used a uniform random sam-
pling of triplets to cover most combinations. After training the
network with random sampling, we then fine-tuned the model by
iteratively finding the hard examples to form a new training subset.
First, we randomly sample a query set representing one screen-
shot from each website, then with the latest model checkpoint, we
All screenshotsRandom samplingTripletConvNetTripletsFirst training stageQueryFNFNFPQueryFPForm a database of hard examplesSecond training stageEmbeddings spaceTrain on hard examplesRepeatTrainTrain on all examplesTraining subsetRandom samplingTripletConvNetTripletscompute the L2 distance between the embeddings of the query set
and all the rest of training screenshots. In this feature space, the
distance between a query image and any screenshot from the same
website should ideally be closer than the distance from the same
query image to any image from different websites. Based on this,
we can find the examples that have the largest error in distance.
Hence, we retrieve the one example from the same website that
had the largest distance to the query (hard positive example), and
the one example from a different website that had the smallest
distance to the query (hard negative example). We then form a new
training subset by taking the hard examples along with the sampled
query set altogether, and we continue the training process with
triplet sampling on this new subset. For the same query set, we
repeat the process of finding a new subset of hard examples for
a defined number of iterations for further fine-tuning. Finally, to
avoid overfitting to a query set that might have outliers, we repeat
the overall process by sampling a new query set and selecting the
training subsets for this new query set accordingly.
This hard example mining framework can be considered as an
approximation to a training scheme where a query image is paired
with screenshots from all websites and a Softmin function is applied
on top of the pairwise distances with a supervised label, however,
this would not scale well with the number of websites in the trusted-
list, and therefore it is not tractable in our case as a single training
example would have 155 pairs (trusted websites).
5.3 Prediction
At test time, the closest screenshot in distance to a phishing test
page targeting a website should ideally be a screenshot of the same
website. Therefore, the decision is not done based on all triplets
comparison but it can be done by finding the screenshot with the
minimum distance to the query image. To this end, we use the
shared network to compute the embeddings then we compute the
L2 distance between the embeddings of the test screenshot and all
training screenshots. After computing the pairwise distances, the
test screenshot is assigned to the website of the screenshot that
has the minimum distance. This step could identify the website
targeted if the test page is a phishing page.
As depicted in Figure 1, if the minimum distance between a page
and the trusted-list is smaller than a defined threshold, the page
would be classified as a phishing page that tries to impersonate one
of the trusted websites by having a high visual similarity. On the
other hand, if the distance is not small enough, the page would be
classified as a legitimate page with a genuine identity. Therefore,
we apply a threshold on the minimum distance for classification.
6 EVALUATION
In this section, we first show the implementation details of Visual-
PhishNet and its performance, then we present further experiments
to evaluate the robustness of VisualPhishNet.
6.1 VisualPhishNet: Final Model
Evaluation metrics. Since our method is based on the visual simi-
larity of a phishing page to websites in the trusted-list, we computed
the percentage of correct matches between a phishing page and
its targeted website. We also calculated the overall accuracy of
6
the binary classification between legitimate test pages and phish-
ing pages at different distance thresholds to calculate the Receiver
Operating Characteristic (ROC) curve area.
Implementation details. To train the network, we used Adam
optimizer [21] with momentum values of β1 = 0.9, β2 = 0.999 and
a learning rate of 0.00002 with a decay of 1% every 300 mini-batches
where we used a batch size of 32 triplets. We set the margin (α)
in the triplet loss to 2.2. The first stage of triplet sampling had
21,000 mini-batches, followed by hard examples fine-tuning, which
had 18,000 mini-batches divided as follows: we sampled 75 random
query sets, for each, we find a training subset which will be used
for 30 minibatches, then we repeat this step 8 times. We used 40%
of the phishing examples in training (added to the targeted website
pages and used normally in triplet sampling) and used the other
60% for the test set. We used the same training/test split in the two
phases of training. We tested the model with the legitimate test
set consisting of 683 screenshots; these domains were only used
in testing since we train the model on trusted domains only (and
partially their spoofed pages).
Performance. Using VisualPhishNet, 81% of the phishing test
pages were matched to their correct website using the top-1 closest
screenshot, while the top-5 match is 88.6%. After computing the cor-
rect matches, we computed the false positive and true positive rates
at different thresholds (where the positive class is phishing) which
yielded a ROC curve area of 0.9879 (at a cut-off of 1% false positives,
the partial ROC area is 0.0087) outperforming the examined models
and re-implemented visual similarity approaches which we show
in the following sections.
6.2 Ablation Study
Given the results of VisualPhishNet, this sub-section investigates
the effects of different parameters in the model, we summarize our
experiments in Table 1 which shows the top-1 match and the ROC
area for each model in comparison with the final one (see Appen-
dix A for the ROC curves). We first evaluated the triplet network by
experimenting with Siamese network as an alternative. We used a
similar architecture to the one used in [22] with two convolutional
networks and a supervised label of 1 if the two sampled screenshots
are from the same website, and 0 otherwise. The network was then
trained with binary cross-entropy loss. We also examined both L1
and L2 as the distance function used in the triplet loss. Besides, we
inspected different architecture’s parameters regarding the shared
sub-network including the added convolution layer, and the final
layer that is used as the embedding vector where we experimented
with Global Average Pooling (GAP) [27], fully connected layer, and
taking all spatial locations by flattening the final feature map. In
addition to VGG16, we evaluated ResNet50 as well [17]. We also
studied the effect of the second training phase of hard examples
training by comparing it with a model that was only trained by
random sampling. As can be seen from Table 1, the triplet network
outperformed the Siamese network. Also, the second training phase
of hard examples improved the performance, which indicates the
importance of this step to reach convergence as previously reported
in [42]. We also show that the used parameters in VisualPhishNet
outperform the other studied parameters. Motivated by the ob-
servation that some phishing pages had poor quality designs and
were different from their targeted websites (see Appendix B for
examples), we studied the robustness of VisualPhishNet to the ra-
tio of phishing examples seen in training. We, thus, reduced the
training phishing set to only 20% and tested with the other 80%,
which slightly decreased the top-1 match (mostly on these different
examples).
6.3 Trusted-list Expansion
In addition to the PhishTank list gathered from phishing reports,
we studied other sources of trusted-lists as per the analysis pre-
sented earlier in our dataset collection procedure. We then studied
the robustness of VisualPhishNet’s performance when adding new
websites to the training trusted-list. To that end, we categorized the
training websites to three lists (as shown in Figure 5), the PhishTank
list, a subset containing 32 websites from SimilarWeb top 400 list
(418 screenshots), a subset containing 38 websites (576 screenshots)
from Alexa top 500 list. Since we have phishing pages for the web-
sites in the PhishTank list only, the other two lists can be used in
training as distractors to the performance on the phishing exam-
ples. When training on one of these additional lists, we remove its
websites from the legitimate test set yielding test sets of 562 and
573 screenshots in the case of adding SimilarWeb and Alexa lists
respectively.
k
r
o
w
t
e
n
-
b
u
S
VGG16
r
e
y
a
L
d
e
d
d
A
Conv 5x5(512) GMP
r
e
y
a
L
t
s
a
L
FC (1024)
GAP
FC (1024)
Flattening
Conv 3x3(512)
No new layer
ResNet50 No new layer
e
p
y
t
k
r
o
w
t
e
N
Triplet
Siamese
Siamese
e
c
n
a
t
s
i
D
L2
L1
L1