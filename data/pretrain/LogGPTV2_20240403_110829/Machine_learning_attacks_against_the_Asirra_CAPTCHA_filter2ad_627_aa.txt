# Machine Learning Attacks Against the Asirra CAPTCHA

## Author
Philippe Golle  
Palo Alto Research Center  
Palo Alto, CA 94304, USA  
Email: [Your Email]

## Abstract
The Asirra CAPTCHA, introduced at ACM CCS 2007, relies on the human ability to distinguish images of cats and dogs. Its security is based on the presumed difficulty of automating this task. In this paper, we present a classifier that achieves 82.7% accuracy in distinguishing between cat and dog images used in Asirra. This classifier, which combines support-vector machine (SVM) classifiers trained on color and texture features, allows us to solve a 12-image Asirra challenge with a 10.3% success rate. This probability of success is significantly higher than the 0.2% estimate provided in the original Asirra paper. Our results suggest caution in deploying Asirra without additional safeguards.

We also investigate the impact of our attacks on the partial credit and token bucket algorithms proposed for Asirra. The partial credit algorithm significantly weakens Asirra, and we recommend against its use. The token bucket algorithm, however, helps mitigate the impact of our attacks and allows Asirra to maintain a balance between usability and security. Our work provides insights into the choice of safeguard parameters for Asirra deployments.

### Categories and Subject Descriptors
K.6.5 [Computing Milieux]: Management of Computing and Information Systems—Security and Protection

### General Terms
Security

### Keywords
CAPTCHA, reverse Turing test, machine learning, support vector machine, classifier

### Introduction
The Asirra CAPTCHA, introduced at ACM CCS 2007, relies on the problem of distinguishing images of cats and dogs (Asirra stands for "Animal Species Image Recognition for Restricting Access"). An Asirra challenge consists of 12 images, each of which is either a cat or a dog. To solve the CAPTCHA, the user must select all the cat images and none of the dog images. Humans are very good at this task, with a 99.6% success rate within 30 seconds. This high usability is a significant advantage over traditional CAPTCHAs based on recognizing distorted strings of letters and numbers.

The security of Asirra is based on the presumed difficulty of classifying images of cats and dogs automatically. According to the authors of Asirra, evidence from the 2006 PASCAL Visual Object Classes Challenge suggests that cats and dogs are particularly difficult to tell apart algorithmically. A classifier based on color features, described in the original paper, achieved only 56.9% accuracy. The authors conjectured that achieving better than 60% accuracy would be challenging without a significant advance in the state of the art. With a 60% accurate classifier, the probability of solving a 12-image Asirra challenge is only about 0.2%.

In this paper, we describe a classifier that achieves 82.7% accuracy in distinguishing between cat and dog images used in Asirra. This classifier allows us to solve a 12-image Asirra challenge with a 10.3% success rate, which is significantly higher than the 0.2% estimate given in the original paper. While our success rate may appear low in absolute terms, it poses a serious threat to Asirra if additional safeguards are not deployed to prevent machine adversaries from requesting and attempting to solve too many CAPTCHAs at virtually no cost.

### Support Vector Machine Classifiers for Asirra Images
Asirra uses a large and growing database of approximately 3,000,000 images of cats and dogs licensed from the adoption service Petfinder.com. The images displayed by Asirra are 250-by-250 pixels. Most images contain a single cat or a single dog, but some images contain multiple cats or dogs. A few images contain no recognizable animal or both a cat and a dog, which cannot be classified according to Asirra's rules.

#### Image Collection
We collected 13,000 distinct images from the Asirra implementation publicly available on the Asirra website. The website serves Asirra CAPTCHAs consisting of 12 images selected at random from the entire Asirra image database. We wrote a script to automatically refresh the website and download the 12 images in the new Asirra CAPTCHA obtained after each refresh. Over the course of a night, our script refreshed the website approximately 1,100 times and downloaded just over 13,000 images. To avoid duplicates, every image was saved in a file named after a hash of its pixels (we detected and discarded 6 duplicate images). Other than duplicates, no images were deleted, filtered, or otherwise selected.

The collection of 13,000 images thus obtained is a representative, unbiased sample of Asirra images, as the Asirra service selects images randomly from its entire image database for each challenge. The Asirra authors conjecture that the wide variety of backgrounds, angles, poses, lighting, and other factors make accurate automatic classification difficult. We have every reason to believe that our subset of 13,000 images offers a similar diversity of factors.

#### Manual Classification
The next step was to manually classify the 13,000 images into three classes: Cat, Dog, and Other. The Cat and Dog classes are self-explanatory. The Other class was for images that either contained no recognizable animal or contained both a cat and a dog. Manual classification was followed by a manual verification step, in which 159 misclassified images (1.2% of the total) were detected and moved to the correct category. After verification, we obtained 6,403 images of cats (49.3%), 6,466 images of dogs (49.7%), and 131 other images (1.0% of the total). For the rest of our work, we kept only the images of cats and dogs and discarded the other images.

#### Building a Classifier
We experimented with different color and texture features computed from images. These features are described in the following sections. We trained a support vector machine (SVM) classifier with each set of features. SVM classifiers were chosen for their ability to extract linear combinations of features, their predictive power, and their computational scalability. We refer the reader to [10] for an excellent introduction to SVMs and a comparison of their characteristics with other learning methods. In short, an SVM is a supervised learning method that constructs an optimal linear boundary (or separating hyperplane) between two classes. This hyperplane is optimal in the sense that it maximizes the distance, or margins, between the hyperplane and the two classes on each side of it. The power of SVM classifiers comes from the fact that the linear boundary is not computed directly in feature space but in a transformed, higher-dimensional version of the feature space. The transformation is represented, loosely speaking, by a kernel function. Linear boundaries in the transformed space produce non-linear boundaries when mapped back to the original feature space.

#### Measuring Accuracy
We measured the accuracy of our SVM classifiers using 5-fold cross-validation on random subsets of our image collection. Cross-validation operates by dividing a subset of images into 5 randomly chosen partitions; 4 of these partitions are used for training while the remaining one is used for validation. We report results using subsets of various sizes (5,000 and 10,000 images) to show the influence of the size of the training sample on the accuracy of our classifier. The accuracy reported for our classifiers in the following sections is the average accuracy (and its standard deviation) over the 5 experiments of 5-fold cross-validation. All our subsets of images and all the partitions used for cross-validation were generated at random to avoid any bias that might affect our results.

#### SVM Implementation
We trained our SVM with a radial basis kernel. This kernel defines the inner product of two feature vectors \( v \) and \( v' \) as:
\[ K(v, v') = \exp(-\gamma |v - v'|^2) \]
The parameter \( \gamma \) was tuned with 5-fold cross-validation to achieve the best test error performance. We found that \( \gamma = 10^{-3} \) worked well for color features and \( \gamma = 10^{-1} \) worked well for texture features. We used the LIBSVM [3] Java implementation of SVM. We rewrote parts of the LIBSVM library to make more economical use of memory for vectors of boolean features. All computations were performed on a commodity PC.

### Results
Table 1 shows the accuracy of SVM classifiers trained on color features extracted from Asirra images. The color features are described in Section 2.1. The accuracy of the classifier is the fraction of cat and dog images classified correctly in the test set.

| Feature Set | N | Ch | Cs | Cv | # Images | # Features | Training Set | Mean Accuracy | Standard Deviation |
|-------------|---|----|----|----|-----------|------------|--------------|---------------|--------------------|
| F1          | 1 | 10 | 10 | 10 | 1,000     | 5,760      | 4,000        | 67.3%         | 1.6                |
| F2          | 3 | 10 | 10 | 6  | 9,000     | 9,000      | 4,000        | 74.6%         | 1.1                |
| F3          | 5 | 10 | 6  | 6  | 9,000     | 9,000      | 4,000        | 74.6%         | 0.6                |
| F3          | 5 | 10 | 8  | 6  | 10,000    | 9,000      | 8,000        | 75.7%         | 0.7                |

Table 2 shows the accuracy of SVM classifiers trained on a combination of color features.

| Feature Set | # Images | # Features | Training Set | Mean Accuracy | Standard Deviation |
|-------------|-----------|------------|--------------|---------------|--------------------|
| F1 ∪ F2 ∪ F3 | 5,000     | 15,760     | 4,000        | 76.3%         | 0.9                |
| F1 ∪ F2 ∪ F3 | 10,000    | 15,760     | 8,000        | 77.1%         | 0.6                |

### Conclusion
Our work demonstrates that the Asirra CAPTCHA can be vulnerable to machine learning attacks, achieving a 10.3% success rate in solving 12-image challenges. This success rate is significantly higher than the 0.2% estimate provided in the original Asirra paper. We recommend caution in deploying Asirra without additional safeguards. The partial credit algorithm weakens Asirra, and we recommend against its use. The token bucket algorithm, however, helps mitigate the impact of our attacks and allows Asirra to maintain a balance between usability and security. Our work provides insights into the choice of safeguard parameters for Asirra deployments.

### References
[1] Asirra website.
[3] LIBSVM: A Library for Support Vector Machines.
[5] Support Vector Machines.
[6] Asirra service documentation.
[7] Asirra: A CAPTCHA that Exploits Interest-Aligned Manual Image Categorization.
[8] Using SAT Solvers to Defeat Authentication Schemes.
[9] Traditional CAPTCHAs.
[10] An Introduction to Support Vector Machines and Other Kernel-Based Learning Methods.
[13] Finding Collisions in Hash Functions.
[14] Object Recognition Algorithms.

### Permissions
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.

CCS’08, October 27–31, 2008, Alexandria, Virginia, USA.
Copyright 2008 ACM 978-1-59593-810-7/08/10 ...$5.00.