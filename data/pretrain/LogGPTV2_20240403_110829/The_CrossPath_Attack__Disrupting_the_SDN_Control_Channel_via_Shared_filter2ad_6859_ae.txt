# 5.4 Reactive Routing

The reactive routing [9] application enables flexible and fine-grained routing decisions for different flows, a feature supported by almost all controllers. When a new flow is detected that does not match any existing rules, the first packet of the flow is forwarded to the reactive routing application. This application then analyzes the packet and calculates the optimal routing path for the new flow. In addition to processing data packets and installing flow rules, the application also queries the topology service to obtain information about host locations, switch states, and link statuses.

To demonstrate the effectiveness of our attack, we constructed a network topology with four hosts (h1, h2, h3, h4) and three switches (s1, s2, s3), as illustrated in Figure 15. The IP addresses for the hosts are as follows: h1 (10.0.0.1), h2 (10.0.0.2), h3 (10.0.0.3), and h4 (10.0.0.4). Hosts h1 and h2 send packets to h3. The default routing paths are:
- From h1 to h3: via s1, s2, and s3.
- From h2 to h3: via s2 and s3.
- A flow with TCP port 1111 from h2 to h3 follows a different path due to QoS requirements.

In this scenario, the compromised host h4 sends LDoS attack traffic to h3, targeting the control path of switch s2.

### 5.3 Learning Switch

The learning switch application [6] allows SDN switches to function like traditional IP network switches. It examines packets that do not match any existing rules and looks up the recorded mapping between the source MAC address and the corresponding port. If the destination MAC address is already associated with a port, the packet is forwarded to that port, and the necessary rules are installed to handle subsequent packets. Otherwise, the packet is flooded across all ports. As shown in Figure 12, the application relies on two services: the packet service, which forwards packets to the controller and back to the switch, and the flow rule service, which installs rules in the switch.

Our attack effectively disrupts the installation of forwarding decisions by interfering with the messages exchanged between the core services and the switches. Figure 14 illustrates the impact of the attack on the learning switch's functionality. The success ratio of rule installation is defined as the number of successfully installed rules over the number of rule requests within a second. Without the attack, the success ratio remains above 90% even with varying numbers of new flows. However, with the attack, the success ratio drops significantly. For example, at a rate of 250 new flows per second, the success ratio decreases to below 20%, rendering the learning switch ineffective. As shown in Figure 14b, the throughput of the switch is 0 Mbps for a long time under the attack when there are 250 new flows per second.

### 5.4 Attack Impacts on Reactive Routing

Figure 16 highlights the impacts of the attack on reactive routing. As shown in Figure 16a, the attack causes long-term routing rule inconsistency, leading to 100% link utilization. This is due to the transient rule inconsistency in SDN, which our attack exploits. In the network depicted in Figure 15, packets with an IP destination address of 10.0.0.3 and a destination port of 1111 loop between s1 and s2 when the application deletes the rule "10.0.0.3:1111, to s3" while the rule "10.0.0.3:1111, to s1" remains. Normally, this inconsistency lasts for a short period, but our attack delays the commands exchanged between the flow rule service and s2, causing the packets to loop for a longer duration and increasing link utilization.

Figure 16b shows a long-term routing blackhole when h3 is migrated from s3 to s2. Without the attack, the migration is completed within five seconds, as the topology service can track the new location via DHCP payload in packet-in messages. However, under the attack, these messages are delayed, preventing timely updates to the routing between other hosts and h3, resulting in a 10-second routing blackhole.

Moreover, by blocking LLDP packets between the topology service and switches, our attack can deactivate links in the topology database, leading to the removal of corresponding routing paths. In the Floodlight controller, a link is deactivated if no LLDP packets pass through it within 35 seconds. Figure 16c shows the original routing path from h2 to h3 being removed due to the deactivation of the link from s2 to s3. Additionally, our attack can reset the connections between switches and the controller by delaying control messages, as shown in Figure 16d, where the connection of switch s2 is reset, and all flow tables are cleared.

### 5.5 Load Balancer

Load balancing is widely used to improve resource usage, throughput, and reduce response delays by distributing workloads among multiple nodes. The SDN controller deploys the load balancer [7] application to achieve this. The application in the Floodlight controller supports round-robin and statistics-based scheduling. Round-robin scheduling randomly selects a server from a pool to serve each new request, while statistics-based scheduling chooses the server with the lowest utilization based on real-time switch port statistics.

We configured the load balancer application in Floodlight to use statistics-based scheduling, as it provides better load balancing under different client flow distributions. In our experiments, two hosts form a server pool, and two other hosts send flows to the servers. Figure 17a shows the switch port utilization over time without the attack. Initially, two elephant flows are sent to the servers, causing the port utilization to increase to 40% and 10%, respectively. At the 7th second, the rates of the two flows exchange, and the utilization of one server decreases from 40% to 10%, while the other increases from 10% to 40%. At the 14th second, a new elephant flow starts, and the application directs it to server #1, which has the lowest port utilization, reaching 70%.

Under the attack, the application mistakenly directs the new flow to server #2, as shown in Figure 17b, where the port utilization of server #2 reaches 100%. This is because our attack significantly delays the stats request and reply messages, preventing the application from accurately determining the current port utilization. The application incorrectly assumes that the port utilization of server #2 is still 10% when the new flow arrives.

### 6 Defense Schemes

This section discusses potential countermeasures that network administrators can implement to mitigate the attack.

#### Delivering Control Traffic with High Priority

One effective defense is to ensure that control traffic is forwarded with high priority, protecting it from congestion by malicious data traffic. This can be achieved by configuring Priority Queue (PQ) or Weighted Round Robin Queue (WRR) in switches. Many commercial SDN switches support at least one of these queueing mechanisms. Our implementation and evaluation show that this approach can effectively protect control traffic. Detailed implementations and evaluations are provided in Appendix B.

#### Proactively Reserving Bandwidth for Control Traffic

Another defense is to proactively reserve bandwidth for control traffic, suitable for SDN switches that do not support PQ and WRR. We implemented this using OpenFlow meter tables in our hardware switches, demonstrating that control traffic can be well-protected by reserving sufficient bandwidth. The main disadvantage is that the reserved bandwidth cannot be used by other traffic, even if there is ample free bandwidth. Future work will focus on dynamically reserving bandwidth for control traffic to optimize its use.

#### Disturbing Path Reconnaissances

Preventing the attack by disturbing path reconnaissances is another approach. Adding random delays when installing flow rules can result in incorrect delay measurements during path reconnaissances, reducing the accuracy of path reconnaissances to less than 30%. However, this method affects the rule installation of all flows, particularly impacting delay-sensitive mice flows. Developing a scheme to effectively disturb path reconnaissances while minimizing the impact on network flows is an area for future research.

### 7 Related Work

This section reviews related security research in SDN and legacy networks.

#### Reconnaissances in SDN

SDN reconnaissances have been extensively studied. Shin et al. [54] designed an SDN scanner to determine if a network is SDN by measuring ping response delays. Cui et al. [25] further demonstrated its feasibility in real SDN testbeds. Kl√∂ti et al. [39] presented a technique to determine if an SDN has rules for aggregated TCP flows by timing TCP setup times. Achleitner et al. [19] developed SDNMap to reconstruct flow rule compositions by analyzing probing packets with specific protocols. Liu et al. [45] created a Markov model to reveal rule distribution among switches. John et al. [56] introduced a sophisticated inference technique for SDN reconnaissance.