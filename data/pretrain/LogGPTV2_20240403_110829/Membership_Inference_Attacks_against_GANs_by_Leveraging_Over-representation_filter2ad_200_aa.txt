title:Membership Inference Attacks against GANs by Leveraging Over-representation
Regions
author:Hailong Hu and
Jun Pang
Membership Inference Attacks against GANs by Leveraging
Over-representation Regions
Hailong Hu
SnT, University of Luxembourg
Esch-sur-Alzette, Luxemburg
PI:EMAIL
Jun Pang
FSTM & SnT, University of Luxembourg
Esch-sur-Alzette, Luxemburg
PI:EMAIL
ABSTRACT
Generative adversarial networks (GANs) have made unprecedented
performance in image synthesis and play a key role in various
downstream applications of computer vision. However, GAN mod-
els trained on sensitive data also pose a distinct threat to privacy.
In this poster, we present a novel over-representation based mem-
bership inference attack. Unlike prior attacks against GANs which
focus on the overall metrics, such as the attack accuracy, our at-
tack aims to make inference from the high-precision perspective,
which allows the adversary to concentrate on inferring a sample
as a member confidently. Initial experimental results demonstrate
that the adversary can achieve a high precision attack even if the
overall attack accuracy is about 50% for a well-trained GAN model.
Our work will raise awareness of the importance of precision when
GAN owners evaluate the privacy risks of their models.
CCS CONCEPTS
• Security and privacy; • Computing methodologies → Ma-
chine learning;
KEYWORDS
Membership Inference Attacks; Generative Adversarial Networks;
Human Face Generation; Over-representation
ACM Reference Format:
Hailong Hu and Jun Pang. 2021. Membership Inference Attacks against
GANs by Leveraging Over-representation Regions. In Proceedings of the
2021 ACM SIGSAC Conference on Computer and Communications Security
(CCS ’21), November 15–19, 2021, Virtual Event, Republic of Korea. ACM, New
York, NY, USA, 3 pages. https://doi.org/10.1145/3460120.3485338
1 INTRODUCTION
Machine learning, including discriminative models and generative
models, has made tremendous progress in a wide range of applica-
tion domains. In particular, generative adversarial networks (GANs)
have made enormous progress in image generation since the sem-
inal work was proposed by Goodfellow et al. [4] in 2014. Since
then, GANs have achieved impressive performance in a variety of
areas — image synthesis, image-to-image translation, and texture
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea
© 2021 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-8454-4/21/11.
https://doi.org/10.1145/3460120.3485338
generation, etc. However, deploying these state-of-the-art tech-
niques on applications involving sensitive personal data, such as
the human face or healthcare data, has caused severe concerns
about privacy [2, 14, 16]. For instance, adversaries can mount a
membership inference attack against a machine learning model
in order to infer whether a given sample was in the training set,
which directly leads to information leakage of the training set [14].
Early studies about membership inference attacks concentrate
on discriminative models [13, 14], and overfitting is considered
as an important reason causing the leakage of training samples.
Furthermore, Yeom et al. [16] formally illustrate the connection
between overfitting and privacy risks and show that overfitting
is a sufficient condition but not a necessary condition for mem-
bership inference attacks. Indeed, there have been several works
advocating that for the training set of a machine learning model,
there are always some training points that are more vulnerable
to membership inference attacks, no matter whether the model is
overfitting [1, 2, 10, 11, 15]. For example, Carlini et al. [2] reveal
that certain training samples in language models which exhibit
no overfitting can be extracted, such as phone numbers and email
addresses from the victim model GPT-2. Long et al. [11] also show
that there exist vulnerable samples in well-generalized classification
models. Additionally, Leino et al. [10] further advocate that even if
only one training sample is inferred as a member confidently, then
it should be also considered as a privacy violation. Therefore, all
these works motivate us to study membership inference attacks
against GANs from the perspective of precision, i.e., whether the
adversary can infer a sample as a member confidently.
In this paper, we propose a novel membership inference attack
against GANs, which focuses on a high-precision inference. The
precision refers to the proportion of real members among the sam-
ples that are inferred as members. Our attack methodology is based
on the over-representation of GAN models: if the proportion of
training samples (member samples) in some regions is significantly
higher than that in other regions, then it can be abused by the ad-
versary to mount membership inference attacks. Our preliminary
results show that a high-precision attack can be achieved for a
well-trained GAN.
2 METHODOLOGY
2.1 Problem Formulation
Given a target GAN model 𝐺target and a target dataset 𝑋target, the
goal of membership inference attacks is to infer whether a sample 𝑥𝑡
from 𝑋target is used to train the target model 𝐺target.
Prior works [3, 5] perform membership inference attacks against
GANs by comparing how close a sample 𝑥𝑡 from 𝑋target is to the
Session 8: Poster & Demo Session CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2387Algorithm 1: Over-representation based attack
Input: target data: 𝑋target; target model: 𝐺, 𝐷; the number of
clusters: 𝑘
1 def constructMCScore(𝐺, 𝑘):
2
Sample 𝑚 samples ˜𝑋memb from 𝐺;
Sample 𝑛 samples ˜𝑋nonmemb from 𝐺;
˜𝐺, ˜𝐷 ← trainSubstituteModel( ˜𝑋memb);
Φmemb ← sigmoid( ˜𝐷( ˜𝑋memb));
Φnonmemb ← sigmoid( ˜𝐷( ˜𝑋nonmemb));
clusters ← cluster(Φmemb, Φnonmemb, 𝑘);
MCScore ← computeMCScore(Φmemb, 𝑚, Φnonmemb, 𝑛,clusters)
⊲ based on Eq. 1, MCScore: MC scores of regions ;
return MCScore,clusters
𝑋MCScore = []
forall 𝑥𝑡 of 𝑋target do
9
10 def assignMCScore(𝑋target, 𝐷, MCScore, clusters):
11
12
13
14
15
Φ𝑡 ← sigmoid(𝐷(𝑥𝑡));
𝑖 ← assignCluster(Φ𝑡 , clusters)
𝑋MCScore.append(MCScore[𝑖])
⊲ MC score of each sample from 𝑋target ;
⊲ 𝑖: index of cluster;
Figure 1: MC scores for target model StyleGAN.
3
4
5
6
7
8
sample generated by the target model 𝐺target. Our attack methodol-
ogy exploits one particular insight: when a generative model learns
the distribution of a data set, there exist over-representation re-
gions [12]. If a sample from 𝑋target falls in a region where the most
training samples of the target model lie, we believe this sample
is more likely to be a member sample. Thus, we define a member
confidence (MC) score to estimate the probability that each region
contains members (see Figure 1). Finally, a sample with MC score
higher than a threshold is predicted as a member. The key step of
our method is to estimate a MC score which represents a region
how frequent training samples occur.
Member Confidence Score. Let 𝑚, 𝑛 be the numbers of mem-
ber samples and nonmember samples, respectively. Here, member
samples also refer to training samples of a target model. Nonmem-
ber samples are from the same distribution of training samples,
but are not used for training. A region is a set of samples, which
can be constructed by clustering algorithms. It is also called a
cluster in our work and 𝑘 is the number of regions. Member and
nonmember samples are distributed among these regions, where
𝑚 = 𝑚1 + 𝑚2 + . . . + 𝑚𝑘 and 𝑛 = 𝑛1 + 𝑛2 + . . . + 𝑛𝑘. For the 𝑖th
region, there are 𝑚𝑖 member samples and 𝑛𝑖 nonmember samples.
Therefore, the ratio of member samples in the 𝑖th region is defined:
𝑟memb(𝑖) = 𝑚𝑖
𝑚 , and the ratio of nonmember samples in the 𝑖th re-
gion is: 𝑟nonmemb(𝑖) = 𝑛𝑖
𝑛 , we define the member confidence score
in the 𝑖th region as:
MCScore(𝑖) =
𝑟memb(𝑖)
𝑟memb(𝑖) + 𝑟nonmemb(𝑖)
(1)
As an example, we show the MC scores for target model StyleGAN
trained on FFHQ in Figure 1. We can observe that different regions
indeed show different proportions of member samples, i.e. different
MC scores.
2.2 Over-representation based Attack
In this work, we assume that an adversary can have access to the
whole GAN model, including the generator and the discriminator.
However, the adversary has no knowledge of the training dataset.
This attack scenario usually occurs when some research institutions
publish their models to the public to avoid directly sharing original
data, or model providers grant their models to their customers
which utilize their state-of-the-art models to develop their own
applications. For attack scenarios that require much less knowledge,
we leave it for future work.
16
17 def predictMemb(𝑥MCScore, 𝜏):
18