############################# Group Coordinator Settings 
#############################    group.initial.rebalance.delay其实配置文件并不多，对不对？从配置名称上也很容易知道它们和什么相关。这里比较重要的参数就是Socket Server 相关的，以及和 log相关的。 我觉得到了这里，这个逻辑就基本清楚了，对 Kafka的性能优化也就有了大体的判断。构建 Kafka 的性能优化思维导图我们可以根据以上的知识画出如下所示的，Kafka的基本优化点：![](Images/020979e8ad646d7b1bbc6b15d2ba2c61.png)savepage-src="https://static001.geekbang.org/resource/image/b2/db/b2b0ad6f744035d26d5efab25d4ec9db.png"}同样的，我把操作系统和 JDK 方面的优化当成独立的部分，在上图中只把Kafka 相关的内容列出来。有了上面的知识，也有了这个思维逻辑，那么就可以理出针对一个 Kafka应用要干的事情：1.       先分析一下具体的应用场景，关键是 topic、partition 数量、message    大小。    2.       确定要支撑的业务容量和时间长度。        3.       分析架构中需要的 broker 量级、partition、Segment    等配置。这些配置应该是架构师给出的准确预估，如果不能给出，那只能靠我们，也就是做性能测试的人给出具体的结论了。        对组件的性能分析思路我想告诉你的是对一个组件的性能分析思路。如果你有了下面这张图所示的思路，那至少可以覆盖大部分的性能问题了。这个思路就是：![](Images/728fbe4776db72a48c90b75e8b8dbee0.png)savepage-src="https://static001.geekbang.org/resource/image/62/ab/625d1ec2717f84cb2dc9119d8c7e43ab.jpg"}对于 Kafka 这样的队列服务器来说，状态计数器是啥子呢？让我们看一下Kafka 的一个 GrafanaDashboard。 ![](Images/54a60f0665150c3737442a692376d689.png)savepage-src="https://static001.geekbang.org/resource/image/f0/d7/f0025246911a11e34d0608e607669ad7.png"}![](Images/6f9d025caba8e33fbbf93cd9fc2682d2.png)savepage-src="https://static001.geekbang.org/resource/image/f9/1d/f9cefe3ff768fe06662a3ab26aca6c1d.png"}![](Images/e50aadc6a75864327880d0f647ee6f02.png)savepage-src="https://static001.geekbang.org/resource/image/35/37/35319958007c7fbcb2332cc920af7837.png"}从这几个图就能看得出来，最重要的是每秒产生了多少message，以及消费时间间隔。这两个对我们来说是最重要的队列计数器了。但是它们能不能告诉我们现在的队列服务器有没有瓶颈呢？显然是不能的。对于队列来说，消息都是异步被消费者取走的。所以队列中要有保存消息的能力，但是保存多久呢？永远保存吗？显然不现实。但是如果保存得太短了，正常的业务都可能做不下去，所以，我们要制定策略，哪些topic是实时处理的，处理不完怎么办？内存多大，能保存多少消息，积压了怎么办？所以对于队列服务器，只看上面的那几个计数器，我觉得过于片面。我们前面提到的 grafana+prometheus 监控操作系统、MySQL 的 DashBoard都有非常完整的数据，但是 Kafka 的 DashBoard显然信息不够，不能判断它自己有没有问题。操作系统的监控指标对 Kafka来说，也是异常的重要。就像之前我说过的那样，操作系统是不可绕过的分析节点。所以所有要做性能测试和性能分析的人，首先要学的就是操作系统方面的知识。示例下面我们来看一个简单测试示例。生产 10W 消息在这个示例中，共生产 10W 的消息，每个消息大小是 2000 字节，每秒产生5000 个消息。    [root@node-1 Kafka_2.13-2.4.0]
# /home/zee/Kafka/Kafka_2.13-2.4.0/bin/Kafka-producer-perf-test.sh --topic test --num-records 100000 --record-size 2000 --throughput 5000 --producer-props bootstrap.servers=172.18.0.2:9092,172.19.0.14:9092,172.20.0.7:9092    24997 records sent, 4999.4 records/sec (9.54 MB/sec), 15.8 ms avg latency, 398.0 ms max latency.    25010 records sent, 5001.0 records/sec (9.54 MB/sec), 26.0 ms avg latency, 514.0 ms max latency.    25000 records sent, 5000.0 records/sec (9.54 MB/sec), 1.1 ms avg latency, 24.0 ms max latency.    100000 records sent, 4998.000800 records/sec (9.53 MB/sec), 11.03 ms avg latency, 514.00 ms max latency, 1 ms 50th, 52 ms 95th, 305 ms 99th, 501 ms 99.9th.可以看到每秒有 9.53MB 的消息产生，平均响应时延是 11.03ms，最大时延是514ms。 生产 100W 消息在这个示例中，共生产 100W 的消息，每个消息大小是 2000 字节，每秒产生5000 个消息。    [root@node-4 bin]
# /home/zee/Kafka/Kafka_2.13-2.4.0/bin/Kafka-producer-perf-test.sh --topic test_perf --num-records 1000000 --record-size 2000 --throughput 5000 --producer-props bootstrap.servers=172.17.0.11:9092,172.19.0.14:9092,172.20.0.7:9092    24992 records sent, 4996.4 records/sec (9.53 MB/sec), 21.7 ms avg latency, 482.0 ms max latency.    25025 records sent, 5004.0 records/sec (9.54 MB/sec), 0.9 ms avg latency, 16.0 ms max latency.    ........    25000 records sent, 5000.0 records/sec (9.54 MB/sec), 0.6 ms avg latency, 9.0 ms max latency.    25005 records sent, 5001.0 records/sec (9.54 MB/sec), 0.7 ms avg latency, 30.0 ms max latency.    1000000 records sent, 4999.625028 records/sec (9.54 MB/sec), 2.05 ms avg latency, 482.00 ms max latency, 1 ms 50th, 1 ms 95th, 16 ms 99th, 267 ms 99.9th.可以看到每秒有 9.54MB 的消息产生，平均响应时延是 2.05ms，最大时延是482ms。 生产 1000W 消息在这个示例中，生产 1000W消息，其他参数不变：    [root@node-4 bin]