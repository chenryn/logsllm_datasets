title:Integro: Leveraging Victim Prediction for Robust Fake Account Detection
in OSNs
author:Yazan Boshmaf and
Dionysios Logothetis and
Georgos Siganos and
Jorge Ler&apos;ıa and
Jos&apos;e Lorenzo and
Matei Ripeanu and
Konstantin Beznosov
Íntegro: Leveraging Victim Prediction for Robust
Fake Account Detection in OSNs
Yazan Boshmaf∗, Dionysios Logothetis†, Georgos Siganos‡, Jorge Lería§,
Jose Lorenzo§, Matei Ripeanu∗, and Konstantin Beznosov∗
∗University of British Columbia
†Telefonica Research §Tuenti, Telefonica Digital
‡Qatar Computing Research Institute
Abstract—Detecting fake accounts in online social networks
(OSNs) protects OSN operators and their users from various ma-
licious activities. Most detection mechanisms attempt to predict
and classify user accounts as real (i.e., benign, honest) or fake (i.e.,
malicious, Sybil) by analyzing user-level activities or graph-level
structures. These mechanisms, however, are not robust against
adversarial attacks in which fake accounts cloak their operation
with patterns resembling real user behavior.
We herein demonstrate that victims, benign users who control
real accounts and have befriended fakes, form a distinct classiﬁ-
cation category that is useful for designing robust detection mech-
anisms. First, as attackers have no control over victim accounts
and cannot alter their activities, a victim account classiﬁer which
relies on user-level activities is relatively harder to circumvent.
Second, as fakes are directly connected to victims, a fake account
detection mechanism that integrates victim prediction into graph-
level structures is more robust against manipulations of the graph.
To validate this new approach, we designed Íntegro, a scalable
defense system that helps OSNs detect fake accounts using a
meaningful a user ranking scheme. Íntegro starts by predicting
victim accounts from user-level activities. After that, it integrates
these predictions into the graph as weights, so that edges incident
to predicted victims have much lower weights than others. Finally,
Íntegro ranks user accounts based on a modiﬁed random walk
that starts from a known real account. Íntegro guarantees that
most real accounts rank higher than fakes so that OSN operators
can take actions against low-ranking fake accounts.
We implemented Íntegro using widely-used, open-source dis-
tributed computing platforms in which it scaled nearly linearly.
We evaluated Íntegro against SybilRank, the state-of-the-art in
fake account detection, using real-world datasets and a large-
scale deployment at Tuenti, the largest OSN in Spain. We show
that Íntegro signiﬁcantly outperforms SybilRank in user ranking
quality, where the only requirement is to employ a victim classiﬁer
is better than random. Moreover, the deployment of Íntegro at
Tuenti resulted in up to an order of magnitude higher precision
in fake accounts detection, as compared to SybilRank.
Permission to freely reproduce all or part of this paper for noncommercial
purposes is granted provided that copies bear this notice and the full citation
on the ﬁrst page. Reproduction for commercial purposes is strictly prohibited
without the prior written consent of the Internet Society, the ﬁrst-named author
(for reproduction of an entire paper only), and the author’s employer if the
paper was prepared within the scope of employment.
NDSS ’15, 8-11 February 2015, San Diego, CA, USA
Copyright 2015 Internet Society, ISBN 1-891562-38-X
http://dx.doi.org/10.14722/ndss.2015.23260
I.
INTRODUCTION
The rapid growth of online social networks (OSNs), such
as Facebook, Twitter, RenRen, LinkedIn, Google+, and Tuenti,
has been followed by an increased interest in abusing them.
Due to their open nature, OSNs are particularly vulnerable to
the Sybil attack [1], where an attacker creates multiple fake
accounts called Sybils for various adversarial objectives.
The problem. In its 2014 earnings report, Facebook estimated
that up to 15 millions (1.2%) of its monthly active users are in
fact “undesirable,” representing fake accounts that are used in
violation of the site’s terms of service [2]. For such OSNs, the
existence of fakes leads advertisers, developers, and investors
to distrust their reported user metrics, which negatively impacts
their revenues [3]. Attackers create and automate fake accounts
for various malicious activities, including social spamming [4],
malware distribution [5], political astroturﬁng [6], and private
data collection [7]. It is therefore important for OSNs to detect
fake accounts as fast and accurately as possible.
The challenge. Most OSNs employ detection mechanisms that
attempt to identify fake accounts through analyzing either user-
level activities or graph-level structures. In the ﬁrst approach,
unique features are extracted from recent user activities (e.g.,
frequency of friend requests, fraction of accepted requests),
after which they are applied to a classiﬁer that has been trained
ofﬂine using machine learning techniques [8]. In the second
approach, an OSN is formally modeled as a graph, with nodes
representing user accounts and edges representing social rela-
tionships (e.g., friendships). Given the assumption that fakes
can befriend only few real accounts, the graph is partitioned
into two regions separating real accounts from fakes, with a
narrow passage between them [9]. While these techniques are
effective against naïve attacks, various studies showed they
are inaccurate in practice and can be easily evaded [7], [10],
[11]. For example, attackers can cheaply create fakes that
resemble real users, circumventing feature-based detection, or
use simple social engineering tactics to befriend a large number
of real users, invalidating the assumption behind graph-based
detection. In this work, we aim to tackle the question: “How
can we design a robust defense mechanism that allows an OSN
to detect accounts which are highly likely to be fake?”
Implications. If an OSN operator can detect fakes efﬁciently
and effectively, it can improve the experience of its users by
thwarting annoying spam messages and other abusive content.
The OSN operator can also increase the credibility of its user
metrics and enable third parties to consider its user accounts
as authentic digital identities [12]. Moreover, the operator can
better utilize the time of its analysts who manually inspect and
validate accounts based on user reports. For example, Tuenti,
the largest OSN in Spain with 15M active users, estimates that
only 5% of the accounts inspected based on user reports are in
fact fake, which signiﬁes the inefﬁciency of this manual pro-
cess [13]. The OSN operator can also selectively enforce abuse
mitigation techniques, such as CAPTCHA challenges [8] and
photo-based social authentication [14], to suspicious accounts
while running at a lower risk of annoying benign users.
Our solution. We present Íntegro, a robust defense system that
helps OSNs identify fake accounts, which can befriend many
real accounts, through a user ranking scheme.1 We designed
Íntegro for OSNs whose social relationships are bidirectional
(e.g., Facebook, Tuenti, LinkedIn), with the ranking process
being completely transparent to users. While Íntegro’s ranking
scheme is graph-based, the social graph is preprocessed ﬁrst
and annotated with information derived from feature-based
detection techniques. This approach of integrating user-level
activities into graph-level structures positions Íntegro as the
ﬁrst feature-and-graph-based detection mechanism.
Our design is based on the observation that victim accounts,
real accounts whose users have accepted friend requests sent
by fakes, are useful for designing robust fake account detection
mechanisms. In particular, Íntegro uses basic account features
(e.g., gender, number of friends, time since last update), which
are cheap to extract from user-level activities, in order to train a
classiﬁer to predict unknown victims in the OSN. As attackers
do not have control over victims nor their activities, a victim
classiﬁer is inherently more resilient to adversarial attacks
than a similarly-trained fake account classiﬁer. Moreover, as
victims are directly connected to fakes, they form a “border-
line” separating real accounts from fakes in the social graph.
Íntegro makes use of this observation by incorporating victim
predictions into the graph as weights, such that edges incident
to predicted victims have lower weights than others. Finally,
Íntegro ranks user accounts based on the landing probability of
a modiﬁed random walk that starts from a known real account.
The walk is “short” by terminating its traversal early before
it converges. The walk is “supervised” by biasing its traversal
towards nodes that are reachable through higher-weight paths.
As this short, supervised random walk is likely to stay within
the subgraph consisting of real accounts, most real accounts re-
ceive higher ranks than fakes. Unlike SybilRank [13], the state-
of-the-art in graph-based fake account detection, we do not
assume sparse connectivity between real and fake accounts,
which makes Íntegro the ﬁrst fake account detection system
that is robust against adverse manipulation of the graph.
For an OSN consisting of n users, Íntegro takes O(n log n)
time to complete its computation. For attackers who randomly
establish a set Ea of edges between victim and fake accounts,
Íntegro guarantees that no more than O(vol(Ea) log n) fakes
are assigned ranks similar to or higher than real accounts in the
worst case, where vol(Ea) is the sum of weights on edges in
Ea. Even with a random victim classiﬁer that labels accounts
as victims with 0.5 probability, Íntegro ensures that vol(Ea)
is at most equals to |Ea|, resulting in an improvement factor
of O (|Ea|/vol(Ea)) over SybilRank.
1In Spanish, the word “íntegro” means integrated, which suites our approach
of integrating user-level activities into graph-level structures.
Main results. We evaluated Íntegro against SybilRank using
real-world datasets and a large-scale deployment at Tuenti. We
chose SybilRank because it was shown to outperform known
contenders [13], including EigenTrust [15], SybilGuard [16],
SybilLimit [17], SybilInfer [18], Mislove’s method [19], and
GateKeeper [20]. In addition, as SybilRank relies on a ranking
scheme that is similar to ours, albeit on an unweighted graph,
evaluating against SybilRank allowed us to show the impact
of leveraging victim prediction on ranking quality. Our results
show that Íntegro consistently outperforms SybilRank in user
ranking quality, especially as Ea grows large. In particular,
Íntegro resulted in up to 30% improvement over SybilRank in
the ranking’s area under ROC curve (AUC), which represents
the probability that a random real account is ranked higher
than a random fake account.
In practice, the deployment of Íntegro at Tuenti resulted in
up to an order of magnitude higher precision in fake account
detection, where ideally fakes should be located at the bottom
of the ranked user list. In particular, for the bottom 20K low-
ranking users, Íntegro achieved 95% precision, as compared
to 43% by SybilRank and 5% by Tuenti’s user-based abuse
reporting system. More importantly, the precision dramatically
decreased when moving up in the ranked list, which means
Íntegro consistently placed most of the fakes at the bottom of
the list, unlike SybilRank. The only requirement with Íntegro is
to use a victim classiﬁer that is better than random. This can be
easily achieved during the cross-validation phase by deploying
a victim classiﬁer with an AUC greater than 0.5.
From system scalability standpoint, Íntegro scales to OSNs
with many million users and runs on commodity machines. We
implemented Íntegro on top of open-source implementations of
MapReduce [21] and Pregel [22]. Using a synthetic benchmark
of an OSN consisting of 160M users, Íntegro takes less than 30
minutes to ﬁnish its computation on 33 commodity machines.
Contributions. This work makes the following contributions:
• Integrating user-level activities into graph-level structures.
We presented the design and analysis of Íntegro, a fake account
detection system that relies on a novel technique for integrating
user-level activities into graph-level structures. Íntegro uses
feature-based detection with user-level activities to predict how
likely each user is to be a victim. By weighting the graph
such that edges incident to predicted victims have much lower
weights than others, Íntegro guarantees that most real accounts
are ranked higher than fakes. These ranks are derived from the
landing probability of a modiﬁed random walk that starts from
a known real account. To our knowledge, Íntegro is the ﬁrst
detection system that is robust against adverse manipulation of
the social graph, where fakes follow an adversarial strategy to
befriend a large number of accounts, real or fake, in an attempt
to evade detection (Sections III and IV).
• Implementation and evaluation. We implemented Íntegro on
top of widely-used, open-source distributed machine learning
and graph processing platforms. We evaluated Íntegro against
SybilRank using real-world datasets and a large-scale deploy-
ment at Tuenti. In practice, Íntegro has allowed Tuenti to detect
at least 10 times more fakes than their current user-based abuse
reporting system, where reported users are not ranked. With
an average of 16K reports per day [13], this improvement has
been useful to both Tuenti and its users (Sections V and VI).
2
II. BACKGROUND AND RELATED WORK
We ﬁrst outline the threat model we assume in this work.
We then present required background and related work on fake
account detection, abuse mitigation and the ground-truth, social
inﬁltration, and analyzing victims of fakes in OSNs.
A. Threat model
We focus on OSNs such as Facebook, RenRen, and Tuenti,
which are open to everyone and allow users to declare bilateral
relationships (i.e., friendships).
Capabilities. We consider attackers who are capable of cre-
ating and automating fake accounts on a large scale [23].
Each fake account, also called a socialbot [24], can perform
social activities similar to those of real users. This includes
sending friend requests and posting social content. We do not
consider attackers who are capable of hijacking real accounts,
as there are existing detection systems that tackle this threat
(e.g., COMPA [25]). We focus on detecting fake accounts that
can befriend a large number of benign users in order to mount
subsequent attacks, as we describe next.
Objectives. The objective of an attacker is to distribute spam
and malware, misinform, or collect private user data on a large
scale. To achieve this objective, the attacker has to inﬁltrate the
target OSN by using the fakes to befriend many real accounts.
Such an inﬁltration is required because isolated fake accounts
cannot directly interact with or promote content to most users
in the OSN [23]. This is also evident by a thriving underground
market for social inﬁltration. For example, attackers can now
connect their fake accounts with 1K users for $26 or less [26].
Victims. We refer to benign users who have accepted friend
requests from fake accounts as victims. We refer to friendships
between victims and fakes as attack edges. Victims control real
accounts and engage with others in non-adversarial activities.
B. Fake account detection
From a systems design perspective, most of today’s fake ac-
count detection mechanisms are either feature-based or graph-
based, depending on whether they utilize machine learning or
graph analysis techniques in order to identify fakes. Next, we
discuss each of these approaches in detail.
Feature-based detection. This approach relies on user-level
activities and its account details (i.e., user logs, proﬁles). By
identifying unique features of an account, one can classify each
account as fake or real using various machine learning tech-
niques. For example, Facebook employs an “immune system”
that performs real-time checks and classiﬁcation for each read
and write action on its database, which are based on features