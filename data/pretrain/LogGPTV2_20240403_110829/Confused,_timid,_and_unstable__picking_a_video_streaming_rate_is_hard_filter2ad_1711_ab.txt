# Analysis of Service A and B Throughput with and without Competing Flows

## 1. Introduction
- **Service A:**
  - **(a) No competing flow.**
  - **(b) One competing flow.**
  - **Figure 7:** Throughput at the HTTP layer for Service A, with and without a competing flow.

## 2. Initial Condition: No Competing Flow
- In the absence of a competing flow (first 400 seconds), the Service A client correctly selects the highest playback rate.
- The available network bandwidth (5 Mb/s) is significantly higher than the playback rate (1750 kb/s), allowing the client to fill its playback buffer efficiently.
- The bottleneck link remains fully occupied until the playback buffer fills up (after 185 seconds).
- Once the buffer is full, the client pauses to let it drain before issuing new requests, resulting in a periodic ON-OFF sequence.
- Before the buffer fills, the client requests a new 4-second segment every 1.5 seconds on average.
- After the buffer is full, the client requests a new 4-second segment every 4 seconds on average.
- During the 4-second OFF period, the TCP congestion window (cwnd) times out due to inactivity longer than 200 ms and resets to its initial value of 10 packets.
- Despite the cwnd reset, the client's video throughput remains accurate, reflecting the available bandwidth and explaining why the correct rate is chosen.

## 3. Competing Flow
- **Figure 8:** Evolution of cwnd for different segment sizes.
- **Figure 9:** Client's video rate selection based on available bandwidth.
- When a competing flow starts (after 400 seconds), the client's video throughput drops significantly.
- The cwnd for the video flow is repeatedly reduced by the competing flow, leading to high packet loss and low throughput.
- With a larger segment size, the cwnd has more time to climb to the correct steady state value, improving throughput.
- As the available bandwidth decreases, the client conservatively reduces the video rate. For example, when the bandwidth drops from 5 Mb/s to 2.5 Mb/s, the video rate drops to 1400 kb/s.

## 4. Combined Analysis
- A client streaming at 1750 kb/s perceives a median video throughput of 1787 kb/s with a competing flow.
- Based on this throughput, the client reduces the playback rate to 1050 kb/s, indicating that 50% of the time, the playback rate will drop to 1050 kb/s once the competing flow starts.
- The client's behavior is rational given the observed throughput, but the issue lies in the fact that Service A measures throughput above TCP, unaware of TCP's own issues.

## 5. Service B
- **Figure 16:** TCP throughput changes in the presence of a competing flow.
- **Figure 14:** CDF of the duration of OFF periods.
- **Figure 15:** Bytes requested during an ON period.
- Service B also exhibits ON-OFF behavior, but at the TCP level rather than the HTTP level.
- When the video playback buffer is full, the client stops taking data from the TCP socket buffer, triggering TCP flow control to pause the server.
- Almost all the OFF periods are longer than 200 ms, causing the cwnd to reset.
- During ON periods, Service B requests fewer bytes, which is insufficient for the cwnd to reach its steady state before the next OFF period.
- The TCP throughput is only around 1 Mbps to 1.5 Mbps, leading Service B to select a lower video rate (1000 kb/s or even 650 kb/s).

## 6. Conclusion
- Both Service A and Service B experience significant throughput reductions in the presence of competing flows.
- The periodic ON-OFF behavior and the cwnd reset contribute to the low throughput.
- Larger segment sizes and more efficient request patterns can help mitigate these issues, but the fundamental problem lies in the interaction between the client's adaptive rate selection and TCP's congestion control mechanisms.