### Optimizing the Bits per Unit Time in Our Attack

To enhance the bits per unit time obtained through our attack, we can set a threshold value \( T \) such that if the standard error of the first 100 connections exceeds \( T \), the attack is halted without producing any output. 

Setting the value of \( T \) involves optimizing the trade-off between the probability of finding a "good run" (where the standard error after 100 connections is less than \( T \)) and the information gain from such a run. A low \( T \) will cause the attacker to abort too many runs prematurely, while a high \( T \) will result in wasting time on numerous unproductive runs. Figure 9 illustrates this trade-off for our dataset. Although the exact trade-off curve may vary based on the distribution of candidate-to-entry node RTTs, we found that setting the "early abort" threshold to approximately 200ms provided the best balance for our data. This is intuitive, as trace-based measurement studies suggest that 70% of Internet connections have median RTTs below 200ms, and 80% have median RTTs below 400ms [2]. A circuit with a high standard error will typically yield less than \(-\log_2(0.8) = 0.3\) bits of information gain. In our measurements, 153 out of 216 runs (about 70%) had a standard error greater than 200ms after the first 100 connections, and 115 out of 216 runs (53%) had an "early" standard error of at least 400ms. Setting the threshold to the latter value resulted in an estimated information rate of 6.25 bits per hour.

### Discussion

#### Limitations

Several limitations exist in the current description of the attack. The most significant is the limited data on conditional information gain, which means we cannot conclusively evaluate how much additional information each run provides. This is partly due to our experimental method, which did not reuse clients; thus, a longitudinal study is needed for a more accurate assessment. Another reason is the coarse-grained handling of information: our measure of information gain assumes a uniform distribution over "plausible" clients, so repeated measurements where a client is plausible but unlikely (e.g., within two standard errors but not one) do not increase the measured information.

Another limitation is the assumption that a user repeatedly accesses a server from the same network location. This may be invalid in the short term due to route instability or in the long term due to host mobility. The attack could still be conducted if circuits originate from a small set of locations, such as a user's home and office networks, but it would be less effective if network locations change frequently.

#### Other Applications and Extensions

We evaluated our attacks in the context of the Tor anonymity scheme, but they should be generalizable to other low-delay anonymity protocols. Single-hop proxy services may leak more information about the client-proxy RTT, allowing precise linking attacks, though the strength of the client location attack may be reduced against services with a single proxy server location. Peer-to-peer designs like Crowds [31], MorphMix [32], and I2P [21] with lightly-loaded relays and multiple entry points might provide cleaner RTT measurements, enabling higher-precision client location. We are uncertain how these attacks will interact with low-delay mix cascades like AN.ON, as some network latency information should leak, but we lack empirical data on the noise distribution in such schemes.

Using different measurement procedures with appropriate application-layer protocols (e.g., persistent HTTP [16], IRC [29], and SIP [33]) could increase the speed and precision of our attacks. There is also room for evaluating alternative methods of implementing RTT oracles and possibly a more sophisticated testing procedure to avoid querying the RTT oracle for every pair of Tor entry node and candidate location. Finally, studying the impact of various Tor parameters, such as circuit lifetime, circuit length, and path selection, would be valuable.

Our attack may also apply to a recently proposed defense mechanism for hidden services, though it has not been tested. Øverlier and Syverson [30] described an attack on Tor hidden services that exploits the ability to make many requests, eventually connecting to a malicious Tor router as the first hop. They recommend using a small set of trusted "entry guards" as first hops to prevent the attack. However, using similar techniques, a malicious Tor node and hidden service client could recognize when it is the second hop router and obtain precise estimates of the hidden server’s RTT to each guard node. These estimates can be compared against candidate locations, and if there are sufficiently few and widely spread candidates, the hidden server’s location can be determined. Thus, one layer of entry guards may not be sufficient to protect a hidden server’s location.

Recent systems have been developed to geolocate an Internet client given its RTTs from a set of landmark nodes [18, 37]. In cases where candidate clients cannot be associated with IP addresses, these techniques could be applied to our attack, leaking information about the client’s physical location.

#### Mitigation

Several techniques and best practices can reduce the attacker’s success probability in the client location attack. For example, onion routers can minimize the success probability by allocating a fixed amount of bandwidth to each circuit, independent of the current number of circuits, and doing "busy work" during idle times. This may be an undesirable trade-off between anonymity and efficiency but will prevent the client location attack from succeeding. Additionally, Tor nodes can prevent being used as RTT oracles by refusing to extend circuits to nodes not listed in the directory, dropping ICMP ECHO REQUEST packets, and disabling recursive lookups from "outside" nodes if they control their DNS or reverse DNS hosts. Clients and their network administrators can drop ping packets and deny other attempts to learn their network coordinates to the necessary accuracy.

Both client location and circuit linking can be prevented by adding sufficient delays to make the RTT and timing characteristics of Tor servers independent of the underlying network topology. This can be achieved by delaying the forwarding of data at the client. Alternatively, in our evaluation, about half of the sampled circuits already had enough timing noise to defeat the client location attack. Introducing high-variance random delays in outgoing cells at each Tor node could be an effective countermeasure. Selecting delays from an identical distribution at each node would also make the timing distributions from different circuits look more alike, possibly thwarting the circuit-linking attack.

If the only way to thwart attacks based on latency and throughput is to add latency and restrict throughput, this would have serious implications for the design of low-latency anonymity systems and the quality of anonymity we can expect from such schemes. We believe our attacks are effective enough to motivate searching for other possible countermeasures. One possibility is to make the Tor path selection algorithm latency-aware by incorporating network coordinates into directory listings. Clients could then construct circuits with the explicit goal of having an RTT close to one of a small number of possibilities. This could help reduce the high average circuit RTTs we observed (5 sec), reduce the effectiveness of latency-based attacks, and allow clients to explicitly trade off some anonymity for better efficiency. However, more research is needed to understand the security implications of such an approach.

### Acknowledgments

The authors wish to thank Yongdae Kim, Jon McLachlan, Cat Okita, Ivan Osipkov, and Peng Wang for helpful comments and discussions about this work. This research was partially supported by the National Science Foundation under CAREER grant CNS-0546162.

### References

[1] TOR (the onion router) servers. http://proxy.org/tor.shtml, 2007.
[2] Aikat, J., Kaur, J., Smith, F. D., and Jeffay, K. Variability in TCP round-trip times. In IMC ’03: Proc. 3rd ACM SIGCOMM conference on Internet measurement (New York, NY, USA, 2003), pp. 279–284.
[3] Back, A., M¨oller, U., and Stiglic, A. Traffic analysis attacks and trade-offs in anonymity providing systems. In Proc. Information Hiding Workshop (IH 2001) (April 2001), LNCS 2137, pp. 245–257.
[4] Blum, A., Song, D., and Venkataraman, S. Detection of interactive stepping stones: Algorithms and confidence bounds. Proc. 7th Intl Symposium on Recent Advances in Intrusion Detection (RAID) (2004).
[5] Chaum, D. L. Untraceable electronic mail, return addresses, and digital pseudonyms. Communications of the ACM 24, 2 (1981), 84–88.
[6] Chun, B., Culler, D., Roscoe, T., Bavier, A., Peterson, L., Wawrzoniak, M., and Bowman, M. Planetlab: an overlay testbed for broad-coverage services. SIGCOMM Comput. Commun. Rev. 33, 3 (2003), 3–12.
[7] Costa, M., Castro, M., Rowstron, A., and Key, P. PIC: Practical internet coordinates for distance estimation. In ICDCS ’04: Proc. 24th Intl. Conf. on Distributed Computing Systems (Washington, DC, USA, 2004), IEEE Computer Society, pp. 178–187.
[8] Dabek, F., Cox, R., Kaashoek, F., and Morris, R. Vivaldi: a decentralized network coordinate system. In SIGCOMM ’04 (New York, NY, USA, 2004), ACM Press, pp. 15–26.
[9] Danezis, G. Statistical disclosure attacks: Traffic confirmation in open environments. In Proc. Security and Privacy in the Age of Uncertainty, (SEC2003) (Athens, May 2003), IFIP TC11, Kluwer, pp. 421–426.
[10] Danezis, G., Dingledine, R., and Mathewson, N. Mixminion: Design of a Type III Anonymous Remailer Protocol. In SP ’03: Proc. 2003 IEEE Symposium on Security and Privacy (Washington, DC, USA, 2003), IEEE Computer Society, p. 2.
[11] D´ıaz, C., and Serjantov, A. Generalising mixes. In Proc. 3rd Privacy Enhancing Technologies workshop (PET 2003) (March 2003), R. Dingledine, Ed., Springer-Verlag, LNCS 2760.
[12] Dingledine, R., et al. Anonymity bibliography. http://freehaven.net/anonbib, 1999 – 2007.
[13] Dingledine, R., Mathewson, N., and Syverson, P. F. Tor: The second-generation onion router. In Proc. 13th USENIX Security Symposium (August 2004).
[14] Fawcett, T. An introduction to ROC analysis. Pattern Recogn. Lett. 27, 8 (2006), 861–874.
[15] Federrath, H., et al. JAP: Java anonymous proxy. http://anon.inf.tu-dresden.de/.
[16] Fielding, R., Gettys, J., Mogul, J., Frystyk, H., Masinter, L., Leach, P., and Berners-Lee, T. IETF RFC 2616: Hypertext transfer protocol – HTTP/1.1. http://www.ietf.org/rfc/rfc2616.txt, 1999.
[17] Gil, T. M., Kaashoek, F., Li, J., Morris, R., and Stribling, J. The “King” data set. http://pdos.csail.mit.edu/p2psim/kingdata/, 2005.
[18] Gueye, B., Ziviani, A., Crovella, M., and Fdida, S. 2006. Constraint-based geolocation of internet hosts. IEEE/ACM Trans. Netw. 14, 6 (Dec. 2006), 1219-1232.
[19] Gummadi, K. P., Saroiu, S., and Gribble, S. D. King: estimating latency between arbitrary Internet end hosts. Proc. 2nd SIGCOMM Workshop on Internet measurement (2002), 5–18.
[20] Hintz, A. Fingerprinting websites using traffic analysis. In Proc. 2nd Privacy Enhancing Technologies workshop (PET 2002) (April 2002), R. Dingledine and P. Syverson, Eds., Springer-Verlag, LNCS 2482.
[21] jrandom, et al. I2P. http://www.i2p.net/, 2007.
[22] Kesdogan, D., Egner, J., and B¨uschkes, R. Stop-and-go MIXes: Providing probabilistic anonymity in an open system. In Proc. Information Hiding Workshop (IH 1998) (1998), Springer-Verlag, LNCS 1525.
[23] Ledlie, J., Gardner, P., and Seltzer, M. Network coordinates in the wild. In Proc. 4th USENIX Symposium on Network Systems Design and Implementation (April 2007).
[24] Mathewson, N., and Dingledine, R. Practical traffic analysis: Extending and resisting statistical disclosure. In Proc. 4th Privacy Enhancing Technologies workshop (PET 2004) (May 2004), vol. 3424 of LNCS, pp. 17–34.
[25] Moeller, U., Cottrell, L., Palfrader, P., and Sassaman, L. IETF draft: Mixmaster protocol version 2. http://www.ietf.org/internet-drafts/draft-sassaman-mixmaster-03.txt, 2005.
[26] Murdoch, S. J. Hot or not: Revealing hidden services by their clock skew. 13th ACM Conference on Computer and Communications Security (CCS) (2006).
[27] Murdoch, S. J., and Danezis, G. Low-Cost Traffic Analysis of Tor. In SP ’05: Proc. 2005 IEEE Symposium on Security and Privacy (Washington, DC, USA, 2005), IEEE Computer Society, pp. 183–195.
[28] Ng, T. E., and Zhang, H. A network positioning system for the Internet. Proc. USENIX Conference (2004).
[29] Oikarinen, J., and Reed, D. IETF RFC 1459: Internet relay chat protocol. http://www.ietf.org/rfc/rfc1459.txt, 1993.
[30] Øverlier, L., and Syverson, P. Locating Hidden Servers. In SP ’06: Proc. 2006 IEEE Symposium on Security and Privacy (S&P’06) (Washington, DC, USA, 2006), IEEE Computer Society, pp. 100–114.
[31] Reiter, M. K., and Rubin, A. D. Crowds: anonymity for web transactions. ACM Transactions on Information and System Security 1, 1 (1998), 66–92.
[32] Rennhard, M., and Plattner, B. Introducing MorphMix: peer-to-peer based anonymous Internet usage with collusion detection. In WPES ’02: Proc. 2002 ACM workshop on Privacy in the Electronic Society (New York, NY, USA, 2002), ACM Press, pp. 91–102.
[33] Rosenberg, J., et al. SIP: Session Initiation Protocol. IETF RFC 3261, http://tools.ietf.org/html/rfc3261, 2002.
[34] Serjantov, A., and Sewell, P. Passive attack analysis for connection-based anonymity systems. In Proc. ESORICS 2003 (October 2003).
[35] Spring, N., Wetherall, D., and Anderson, T. Scriptroute: A public Internet measurement facility. USENIX Symposium on Internet Technologies and Systems (USITS) (2003), 225–238.
[36] Syverson, P., Tsudik, G., Reed, M., and Landwehr, C. Towards an analysis of onion routing security. In Designing Privacy Enhancing Technologies: Proc. Workshop on Design Issues in Anonymity and Unobservability (July 2000), H. Federrath, Ed., Springer-Verlag, LNCS 2009, pp. 96–114.
[37] Wong, B., Stoyanov, I., and Sirer, E. G. 2006. Geolocalization on the internet through constraint satisfaction. In Proc. USENIX WORLDS 2006.
[38] Wright, M., Adler, M., Levine, B. N., and Shields, C. Defending anonymous communication against passive logging attacks. In Proc. 2003 IEEE Symposium on Security and Privacy (May 2003).