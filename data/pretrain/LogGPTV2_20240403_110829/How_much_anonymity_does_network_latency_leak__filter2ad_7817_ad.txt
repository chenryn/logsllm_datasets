0.014). Thus, we can increase the bits per unit time obtained
through our attack by setting a threshold value T such that,
if the ﬁrst 100 connections have standard error at least T ,
the attack is stopped with no output.
Setting the value of T requires optimizing a tradeoﬀ be-
tween the probability of ﬁnding a good run (one where the
standard error after 100 connections is less than T ) and the
information gain from a good run. Low values of T will
cause an attacker to abort early on too many runs, while
high values of T will cause the attacker to waste time on
too many useless runs. Figure 9 shows the tradeoﬀ between
the value of T and bits/hour for our data set. Although
the exact tradeoﬀ curve will likely diﬀer somewhat based on
the distribution of candidate-to-entry node RTTs, we found
that setting the “early abort” threshold to roughly 200ms
provided the best tradeoﬀ for our data set. Intuitively, this
makes sense: trace-based measurement studies suggest that
70% of Internet connections have median RTTs less than
200ms, and 80% have median RTTs less than 400ms [2], so
a circuit with such a high standard error will almost always
yield less than − log2 0.8 = 0.3 bits of information gain. In
our measurements, 153 of 216 runs – about 70% – had a stan-
dard error greater than 200ms after the ﬁrst 100 connections,
and 115/216 runs (53%) had “early” standard error at least
400ms. Setting the threshold to this latter value yielded an
estimated information rate of 6.25 bits per hour of work.
6. DISCUSSION
Limitations. There are several limitations in the attack
as currently described. The most serious of these is the lim-
ited data on conditional information gain, that is, we cannot
conclusively evaluate, from our data, how much additional
information each run of an attack provides. This is due in
part to limitations of our experimental method, which did
not re-use clients; thus a “longitudinal” study is needed to
more accurately assess conditional information gain. An-
other reason we could not accurately assess conditional in-
formation is due to the somewhat coarse-grained handling of
information: our measure of information gain essentially al-
ways assumes a uniform distribution over “plausible” clients,
so that repeated measurements in which a client is plausible
but unlikely (for example, lies within two standard errors of
our estimated RTT but not one) do not increase the infor-
mation as measured by our experiment.
Another limitation is that our client location attack as-
sumes that a user repeatedly accesses a server from the same
network location. This assumption may sometimes be in-
valid in the short term due to route instability, or in the
long term due to host mobility. It seems plausible that the
attack can still be conducted when circuits originate from
a small set of network locations, such as a user’s home and
oﬃce networks, but the attack would be of little use in case
of more frequent changes in network location.
Other Applications and Extensions. We evaluated our
attacks in the context of the Tor anonymity scheme, but we
expect that they should be generalizable to other low-delay
anonymity protocols.
Indeed, we expect that single-hop
proxy services will leak more information about the client-
proxy RTT, allowing fairly precise linking attacks, although
the strength of the client location attack will be somewhat
diminished against services that have a single proxy server
location. We also expect that peer-to-peer designs such
as Crowds [31], MorphMix [32] and I2P [21], with lightly-
loaded relays and multiple entry points, would yield cleaner
RTT measurements, allowing the attacker to locate clients
with higher precision. We are uncertain how the attacks pre-
sented here will interact with low-delay mix cascades such as
AN.ON; in principle some network latency information should
leak but we lack empirical data on the distribution of the
noise in this scheme.
As we previously mentioned, we believe the speed and
precision of our attacks can be increased by using a diﬀerent
measurement procedure when appropriate application-layer
protocols are utilized. Examples of protocols that can be
exploited to yield application layer acknowledgements in-
clude persistent HTTP [16], IRC [29], and SIP [33]. There
is likewise still room for evaluation of alternative methods of
implementing RTT oracles, and perhaps for a more sophisti-
cated testing procedure that avoids the expense of querying
the RTT oracle for every pair of Tor entry node and candi-
date location. Finally, it would be interesting to study the
impact of various Tor parameters on our attacks, such as
circuit lifetime, circuit length, and path selection.
Our attack may also be applicable to a recently proposed
defense mechanism for hidden services, although it has not
been tested. In particular, Øverlier and Syverson [30] have
described an attack on Tor hidden services that exploits the
ability to make many requests to a hidden service, so that
eventually the hidden service connects to a malicious Tor
router as the ﬁrst hop. They recommend using a small set
of trusted “entry guards” as ﬁrst hops to prevent the attack.
However, using essentially the same techniques, a malicious
Tor node and hidden service client should be able to rec-
ognize when it is the second hop router, and obtain very
precise estimates of the hidden server’s RTT to each of its
guard nodes. These estimates can be compared against can-
didate locations as in our client location attack, and if there
are suﬃciently few and widely spread candidates compared
to the number of entry guards, it should be possible to locate
the hidden server. Thus one layer of entry guards should not
be considered suﬃcient to protect a hidden server’s location.
Finally, several systems have recently been developed to
geolocate an Internet client given its RTTs from a set of
landmark nodes [18, 37].
In cases where candidate clients
cannot be associated with IP addresses, it may be possible
to apply these techniques to our attack, leaking information
about the client’s physical location.
Mitigation. There are a number of techniques and best
practices that can reduce the attacker’s probability of suc-
cess in the client location attack. For example, onion routers
can minimize the success probability of the Murdoch-Danezis
attack by allocating a ﬁxed amount of bandwidth to each
circuit, independent of the current number of circuits, and
doing “busy work” during idle time; this may be an unde-
sirable tradeoﬀ between anonymity and eﬃciency but will
prevent the client location attack from succeeding. Out-
side of such considerations, Tor nodes can prevent being
used as RTT oracles by refusing to extend circuits to nodes
that are not listed in the directory; they can drop ICMP
ECHO REQUEST packets in order to raise the cost of es-
timating their network coordinates; and if Tor node admin-
istrators have control over their DNS or reverse DNS hosts,
they can ensure that recursive lookups from “outside” nodes
are disabled. Tor clients and their network administrators
can likewise drop ping packets and deny other attempts to
learn their network coordinates to the necessary accuracy.
Both client location and circuit linking can be prevented
by adding suﬃcient delays to make the RTT and timing
characteristics of Tor servers independent of the underlying
network topology; this can be accomplished by delaying the
forwarding of data at the client. Alternatively, we can note
that in our evaluation, about half of the circuits we sampled
already had enough timing noise to essentially defeat the
client location attack. Given the limited time period over
which a Tor circuit is available for sampling, it may be an
eﬀective countermeasure for each node to introduce high-
variance random delays in outgoing cells. Selecting delays
from an identical distribution at each Tor node would also
make the timing distributions from diﬀerent circuits look
more alike, possibly thwarting the circuit-linking attack.
Of course, if the only way to thwart attacks based on la-
tency and throughput is to add latency and restrict through-
put, this would have serious implications for the design of
low-latency anonymity systems and the quality of anonymity
we can expect from such schemes. We believe that our at-
tacks are eﬀective enough to motivate searching for other
possible countermeasures. One interesting possibility is to
make the Tor path selection algorithm latency-aware, by
incorporating some notion of network coordinates into di-
rectory listings. Clients could then construct circuits with
the explicit goal of having an RTT close to one of a small
number of possibilities. Doing so could help reduce the high
average circuit RTTs we observed (5 sec), reduce the eﬀec-
tiveness of latency-based attacks, and allow clients to explic-
itly trade-oﬀ some anonymity for better eﬃciency. However,
more research is clearly needed to understand the security
implications of such an approach.
Acknowledgments. The authors wish to thank Yongdae
Kim, Jon McLachlan, Cat Okita, Ivan Osipkov, and Peng
Wang for helpful comments and discussions about this work.
This research was partially supported by the National Sci-
ence Foundation under CAREER grant CNS-0546162.
7. REFERENCES
[1] TOR (the onion router) servers. http://proxy.org/tor.shtml,
2007.
[2] Aikat, J., Kaur, J., Smith, F. D., and Jeffay, K. Variability in
TCP round-trip times. In IMC ’03: Proc. 3rd ACM
SIGCOMM conference on Internet measurement (New York,
NY, USA, 2003), pp. 279–284.
[3] Back, A., M¨oller, U., and Stiglic, A. Traﬃc analysis attacks
and trade-oﬀs in anonymity providing systems. In Proc.
Information Hiding Workshop (IH 2001) (April 2001), LNCS
2137, pp. 245–257.
[4] Blum, A., Song, D., and Venkataraman, S. Detection of
interactive stepping stones: Algorithms and conﬁdence bounds.
Proc. 7th Intl Symposium on Recent Advances in Intrusion
Detection (RAID) (2004).
[5] Chaum, D. L. Untraceable electronic mail, return addresses,
and digital pseudonyms. Communications of the ACM 24, 2
(1981), 84–88.
[6] Chun, B., Culler, D., Roscoe, T., Bavier, A., Peterson, L.,
Wawrzoniak, M., and Bowman, M. Planetlab: an overlay
testbed for broad-coverage services. SIGCOMM Comput.
Commun. Rev. 33, 3 (2003), 3–12.
[7] Costa, M., Castro, M., Rowstron, A., and Key, P. PIC:
Practical internet coordinates for distance estimation. In
ICDCS ’04: Proc. 24th Intl. Conf. on Distributed Computing
Systems (Washington, DC, USA, 2004), IEEE Computer
Society, pp. 178–187.
[8] Dabek, F., Cox, R., Kaashoek, F., and Morris, R. Vivaldi: a
decentralized network coordinate system. In SIGCOMM ’04
(New York, NY, USA, 2004), ACM Press, pp. 15–26.
[9] Danezis, G. Statistical disclosure attacks: Traﬃc conﬁrmation
in open environments. In Proc. Security and Privacy in the
Age of Uncertainty, (SEC2003) (Athens, May 2003), IFIP
TC11, Kluwer, pp. 421–426.
[10] Danezis, G., Dingledine, R., and Mathewson, N. Mixminion:
Design of a Type III Anonymous Remailer Protocol. In SP
’03: Proc. 2003 IEEE Symposium on Security and Privacy
(Washington, DC, USA, 2003), IEEE Computer Society, p. 2.
[11] D´ıaz, C., and Serjantov, A. Generalising mixes. In Proc. 3rd
Privacy Enhancing Technologies workshop (PET 2003)
(March 2003), R. Dingledine, Ed., Springer-Verlag, LNCS 2760.
[12] Dingledine, R., et al. Anonymity bibliography.
http://freehaven.net/anonbib, 1999 – 2007.
[13] Dingledine, R., Mathewson, N., and Syverson, P. F. Tor: The
second-generation onion router. In Proc. 13th USENIX
Security Symposium (August 2004).
[14] Fawcett, T. An introduction to ROC analysis. Pattern
Recogn. Lett. 27, 8 (2006), 861–874.
[15] Federrath, H., et al. JAP: Java anonymous proxy.
http://anon.inf.tu-dresden.de/.
[16] Fielding, R., Gettys, J., Mogul, J., Frystyk, H., Masinter,
L., Leach, P., and Berners-Lee, T. IETF RFC 2616:
Hypertext transfer protocol – HTTP/1.1.
http://www.ietf.org/rfc/rfc2616.txt, 1999.
[17] Gil, T. M., Kaashoek, F., Li, J., Morris, R., and Stribling, J.
The “King” data set.
http://pdos.csail.mit.edu/p2psim/kingdata/, 2005.
[18] Gueye, B., Ziviani, A., Crovella, M., and Fdida, S. 2006.
Constraint-based geolocation of internet hosts. IEEE/ACM
Trans. Netw. 14, 6 (Dec. 2006), 1219-1232.
[19] Gummadi, K. P., Saroiu, S., and Gribble, S. D. King:
estimating latency between arbitrary Internet end hosts. Proc.
2nd SIGCOMM Workshop on Internet measurement (2002),
5–18.
[20] Hintz, A. Fingerprinting websites using traﬃc analysis. In
Proc. 2nd Privacy Enhancing Technologies workshop (PET
2002) (April 2002), R. Dingledine and P. Syverson, Eds.,
Springer-Verlag, LNCS 2482.
[21] jrandom, et al. I2P. http://www.i2p.net/, 2007.
[22] Kesdogan, D., Egner, J., and B¨uschkes, R. Stop-and-go
MIXes: Providing probabilistic anonymity in an open system.
In Proc. Information Hiding Workshop (IH 1998) (1998),
Springer-Verlag, LNCS 1525.
[23] Ledlie, J., Gardner, P., and Seltzer, M. Network coordinates
in the wild. In Proc. 4th USENIX Symposium on Network
Systems Design and Implementation (April 2007).
[24] Mathewson, N., and Dingledine, R. Practical traﬃc analysis:
Extending and resisting statistical disclosure. In Proc. 4th
Privacy Enhancing Technologies workshop (PET 2004) (May
2004), vol. 3424 of LNCS, pp. 17–34.
[25] Moeller, U., Cottrell, L., Palfrader, P., and Sassaman, L.
IETF draft: Mixmaster protocol version 2. http://www.ietf.
org/internet-drafts/draft-sassaman-mixmaster-03.txt, 2005.
[26] Murdoch, S. J. Hot or not: Revealing hidden services by their
clock skew. 13th ACM Conference on Computer and
Communications Security (CCS) (2006).
[27] Murdoch, S. J., and Danezis, G. Low-Cost Traﬃc Analysis of
Tor. In SP ’05: Proc. 2005 IEEE Symposium on Security
and Privacy (Washington, DC, USA, 2005), IEEE Computer
Society, pp. 183–195.
[28] Ng, T. E., and Zhang, H. A network positioning system for the
Internet. Proc. USENIX Conference (2004).
[29] Oikarinen, J., and Reed, D. IETF RFC 1459: Internet relay
chat protocol. http://www.ietf.org/rfc/rfc1459.txt, 1993.
[30] Øverlier, L., and Syverson, P. Locating Hidden Servers. In
SP ’06: Proc. 2006 IEEE Symposium on Security and
Privacy (S&P’06) (Washington, DC, USA, 2006), IEEE
Computer Society, pp. 100–114.
[31] Reiter, M. K., and Rubin, A. D. Crowds: anonymity for web
transactions. ACM Transactions on Information and System
Security 1, 1 (1998), 66–92.
[32] Rennhard, M., and Plattner, B. Introducing MorphMix:
peer-to-peer based anonymous Internet usage with collusion
detection. In WPES ’02: Proc. 2002 ACM workshop on
Privacy in the Electronic Society (New York, NY, USA,
2002), ACM Press, pp. 91–102.
[33] Rosenberg, J., et al. SIP: Session Initiation Protocol. IETF
RFC 3261, http://tools.ietf.org/html/rfc3261, 2002.
[34] Serjantov, A., and Sewell, P. Passive attack analysis for
connection-based anonymity systems. In Proc. ESORICS 2003
(October 2003).
[35] Spring, N., Wetherall, D., and Anderson, T. Scriptroute: A
public Internet measurement facility. USENIX Symposium on
Internet Technologies and Systems (USITS) (2003), 225–238.
[36] Syverson, P., Tsudik, G., Reed, M., and Landwehr, C.
Towards an analysis of onion routing security. In Designing
Privacy Enhancing Technologies: Proc. Workshop on Design
Issues in Anonymity and Unobservability (July 2000),
H. Federrath, Ed., Springer-Verlag, LNCS 2009, pp. 96–114.
[37] Wong, B., Stoyanov, I., and Sirer, E. G. 2006. Geolocalization
on the internet through constraint satisfaction. In Proc.
USENIX WORLDS 2006.
[38] Wright, M., Adler, M., Levine, B. N., and Shields, C.
Defending anonymous communication against passive logging
attacks. In Proc. 2003 IEEE Symposium on Security and
Privacy (May 2003).