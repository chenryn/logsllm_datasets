### 3. Aalo Overview

Aalo employs a non-clairvoyant coflow scheduler that optimizes the communication performance of data-intensive applications without prior knowledge, while being resilient to the dynamics of job schedulers and data-parallel clusters. This section provides a brief overview of Aalo to help the reader understand the analysis and design of its scheduling algorithms (§4), mechanisms for handling dynamic events (§5), and detailed design (§6) presented in subsequent sections.

#### 3.1 Problem Statement

Our objective is to dynamically prioritize coflows without prior knowledge of their characteristics while respecting coflow dependencies. This problem—non-clairvoyant coflow scheduling with precedence constraints—is NP-hard, as coflow scheduling with complete knowledge is also NP-hard [20]. In addition to minimizing completion times (CCTs), we must ensure starvation freedom and work conservation.

#### 3.2 Architectural Overview

Aalo uses a loosely-coordinated architecture (Figure 2) because full decentralization can render coflow scheduling ineffective (Theorem A.1). It implements global and local controls at two time granularities:

- **Long-term global coordination**: Aalo daemons send locally observed coflow sizes to a central coordinator every 10 milliseconds. The coordinator determines the global coflow ordering using the D-CLAS framework (§4) and periodically sends updated schedules and globally observed coflow sizes to all daemons.
- **Short-term local prioritization**: Each daemon schedules coflows using the last-known global information. Between resynchronization, newly arrived coflows are enqueued in the highest-priority queue. Flows from new and likely small coflows receive high priority in the short term, but Aalo daemons realign with the global schedule as soon as updated information arrives. A flow that has just completed is replaced by a same-destination flow from the next coflow in the schedule for work conservation.

Frameworks use a client library to interact with the coordinator over the network to define coflows and their dependencies (§6). To send data, they must use the Aalo-provided `OutputStream`. The coordinator has an ID generator that creates unique `CoflowIds` while considering coflow dependencies (§5.1).

We have implemented Aalo in the application layer without any changes or support from the underlying network. We have deployed it in the cloud, and it performs well even for sub-second data analytics jobs (§7).

**Fault Tolerance:** Aalo handles three failure scenarios, including its own failures and those of the clients using it:
1. **Failure of an Aalo daemon:** Does not hamper job execution, as the client library automatically falls back to regular TCP fair sharing until the daemon is restarted. Upon restart, the daemon remains in an inconsistent state only until the next coordination step.
2. **Failure of the coordinator:** Client libraries keep track of locally observed sizes until the coordinator is restarted, while periodically trying to reconnect.
3. **Task failures and restarts:** Relevant flows are restarted by corresponding job schedulers. Such flows are treated like a new wave in a coflow, and their additional traffic is added to the current size of that coflow (§5.2).

**Scalability:** The faster Aalo daemons can coordinate, the better it performs. The number of coordination messages is linear with the number of daemons and independent of coflows. It is not a bottleneck for clusters with up to 100 machines, and our evaluation suggests that Aalo can scale up to 10,000 machines with minimal performance loss (§7.6). Most coflows are small and scheduled through local decisions, making Aalo handle tiny coflows effectively, unlike Varys.

### 4. Scheduling Without Prior Knowledge

In this section, we present an efficient coflow scheduler for minimizing CCTs without a priori information. First, we discuss the complexity and requirements of such a scheduler (§4.1). Next, we describe a priority discretization framework (§4.2) that we use to explore the trade-offs in designing an efficient, non-clairvoyant scheduler (§4.3). Based on our understanding, we develop Discretized Coflow-Aware Least-Attained Service (D-CLAS)—a mechanism to prioritize coflows and a set of policies to schedule them without starvation (§4.4). Finally, we compare our proposal with existing coflow schedulers (§4.5).

For brevity, we present the mechanisms in the context of single-stage, single-wave coflows. We extend them to handle multi-stage, multi-wave coflows, task failures, and speculation in Section 5.

#### 4.1 Complexity and Desirable Properties

The offline coflow scheduling problem—where all coflows arrive together and their characteristics are known a priori—is NP-hard [20]. Consequently, the non-clairvoyant coflow scheduling problem is also NP-hard.

In the non-clairvoyant setting, the smallest-bottleneck-first heuristic [20]—the best-performing clairvoyant heuristic—becomes inapplicable. This is because the bottleneck of a coflow is revealed only after it has completed. Instead, one must schedule coflows based on an attribute that:
1. Can approximate its clairvoyant counterpart using current observations.
2. Involves all the flows to avoid the drawbacks from the lack of coordination (Theorem A.1).

Note that a coflow’s bottleneck can change over time due to task failures and restarts, failing the first requirement. In addition to minimizing the average CCT, the non-clairvoyant scheduler must:
1. Guarantee starvation freedom for bounded CCTs.
2. Ensure work conservation to increase utilization.
3. Decrease coordination requirements for scalability.

**Coflow-Aware Least-Attained Service (CLAS):** Although the smallest-total-size-first heuristic had been shown to perform marginally worse (1.14×) than smallest-bottleneck-first in the clairvoyant setting [20], it becomes a viable option in the non-clairvoyant case. The current size of a coflow—how much it has already sent throughout the entire cluster—meets both criteria. Unlike a coflow’s bottleneck, it monotonically increases with each flow regardless of start time or endpoints. Setting a coflow’s priority that decreases with its current size ensures that smaller coflows finish faster, which minimizes the average CCT. Furthermore, it is a good indicator of actual size [41], as coflow size typically follows a heavy-tailed distribution [20, 11].

We refer to this scheme as Coordinated or Coflow-Aware Least-Attained Service (CLAS). Note that CLAS reduces to the well-known Least-Attained Service (LAS) [42, 45] scheduling discipline in the case of a single link.

#### 4.2 Priority Discretization

Using continuous priorities derived from coflow sizes can degenerate into fair sharing (§B), which increases the average CCT [19, 25, 20]. Coordination needed to find global coflow sizes poses an additional challenge. We must be able to preempt at opportune moments to decrease CCT without requiring excessive coordination.

In the following, we describe a priority discretization framework to design an efficient, non-clairvoyant coflow scheduler. Unlike classic non-clairvoyant schedulers—least-attained service (LAS) in single links [42, 45] and multi-level feedback queues (MLFQ) in operating systems [23, 21, 13]—that perform fair sharing in the presence of similar flows/tasks to provide interactivity, our solution improves the average CCT even in the presence of identical coflows.

**Multi-Level Coflow Scheduling:** A multi-level coflow scheduler consists of K queues (Q1, Q2, ..., QK), with queue priorities decreasing from Q1 to QK. The i-th queue contains coflows of size within [Qlo_i, Qhi_i], where Qlo_1 = 0, Qhi_K = ∞, and Qlo_(i+1) = Qhi_i. Actions taken during three lifecycle events determine a coflow’s priority:
- **Arrival:** New coflows enter the highest priority queue Q1.
- **Activity:** A coflow is demoted to Qi+1 from Qi when its size crosses the threshold Qhi_i.
- **Completion:** Coflows are removed from their current queues upon completion.

The first two ensure coflow prioritization based on its current size, while the last is for completeness.

#### 4.3 Trade-offs in Designing Coflow Schedulers

Given the multi-level framework, a coflow scheduler can be characterized by its information source, queue structure, and scheduling disciplines at different granularities. Trade-offs made while navigating this solution space result in diverse algorithms, ranging from centralized shortest-first to decentralized FIFO [19, 20, 25] and many in between. We elaborate on the key trade-offs below.

**Information Source:** There are two primary categories of coflow schedulers: clairvoyant schedulers use a priori information, and non-clairvoyant ones do not. Non-clairvoyant schedulers have one more decision to make: whether to use globally-coordinated coflow sizes or to rely on local information. The former is accurate but more time-consuming. The latter diverges (Theorem A.1) for coflows with large skews, which is common in production clusters [17, 20].

**Queue Structure:** A scheduler must also determine the number of queues it wants to use and their thresholds. On one hand, FIFO-derived schemes (e.g., Orchestra, Baraat) use exactly one queue. FIFO works well when coflows follow light-tailed distributions [25]. Clairvoyant efficient schedulers (e.g., Varys), on the other hand, can be considered to have as many queues as there are coflows. They perform the best when coflow sizes are known and are heavy-tailed [20]. At both extremes, queue thresholds are irrelevant.

For solutions in between, determining an ideal number of queues and corresponding thresholds is difficult; even for tasks on a single machine, no optimal solution exists [13]. Increasing the number of levels/queues is appealing, but fine-grained prioritization can collapse to fair sharing when coflow sizes are unknown and hurt CCTs. More queues also generate more "queue-change" events and increase coordination requirements.

**Scheduling Disciplines:** Finally, a coflow scheduler must decide on scheduling disciplines at three different granularities: (i) across queues, (ii) among coflows in each queue, and (iii) among flows within each coflow. The first is relevant when K > 1, while the second is necessary when queues have more than one coflow. In the absence of flow size information, size-based rate allocation algorithms like WSS [19] and MADD [20] cannot be used; max-min fairness similar to TCP is the best alternative for scheduling individual flows.

#### 4.4 Discretized Coflow-Aware Least-Attained Service

We propose Discretized CLAS (D-CLAS) that uses more than one priority queue (K > 1) to enable prioritization. The key challenge is finding a suitable K that provides sufficient opportunities for preemption while being small enough to not require excessive coordination.

To achieve our goals, each queue in D-CLAS contains exponentially larger coflows than its immediately higher-priority queue (Figure 3). Formally, Qhi_(i+1) = E × Qhi_i, where the factor E determines how much bigger coflows in one queue are compared to another. Consequently, the number of queues remains small and can be expressed as an E-based logarithmic function of the maximum coflow size.

The final component in defining our queue structure is determining Qhi_1. Because global coordination, irrespective of mechanism, has an associated time penalty depending on the scale of the cluster, we want coflows that are too small to be globally coordinated in Q1. Larger coflows reside in increasingly more stable, lower-priority queues (Q2, ..., QK).

While we typically use E = 10 and Qhi_1 = 10 MB in our cluster, simulations show that for K > 1, a wide range of K, E, and Qhi_1 combinations work well (§7.5).

**Non-Clairvoyant Efficient Schedulers:** D-CLAS clusters similar coflows together and allows us to implement different scheduling disciplines among queues and among coflows within each queue (Pseudocode 1). It uses weighted sharing to allocate resources efficiently.