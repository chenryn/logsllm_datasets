was scheduled before C1, and it would have been the same
if C1 was scheduled before C3.
This example considers only single-stage coﬂows with-
out egress contention. Coordinated coﬂow scheduling can be
even more effective in both scenarios (§7).
3 Aalo Overview
Aalo uses a non-clairvoyant coﬂow scheduler that optimizes
the communication performance of data-intensive applica-
tions without a priori knowledge, while being resilient to the
dynamics of job schedulers and data-parallel clusters. This
section brieﬂy overviews Aalo to help the reader follow the
analysis and design of its scheduling algorithms (§4), mech-
anisms to handle dynamic events (§5), and design details
(§6) presented in subsequent sections.
3.1 Problem Statement
Our goal is dynamically prioritizing coﬂows without prior
knowledge of their characteristics while respecting coﬂow
dependencies. This problem – non-clairvoyant coﬂow
scheduling with precedence constraints – is NP-hard, be-
cause coﬂow scheduling with complete knowledge is NP-
hard too [20]. In addition to minimizing CCTs, we must
guarantee starvation freedom and work conservation.
3.2 Architectural Overview
Aalo uses a loosely-coordinated architecture (Figure 2), be-
cause full decentralization can render coﬂow scheduling
pointless (Theorem A.1). It implements global and local
controls at two time granularities:
Local Daemon!Local Daemon!milliseconds!Local Daemon!D-CLAS!Sender1!Sender2!μs!Network Interface !Timescale!Local/Global Scheduling!Coordinator!395• Long-term global coordination: Aalo daemons send
locally-observed coﬂow sizes to a central coordinator every
O(10) milliseconds. The coordinator determines the global
coﬂow ordering using the D-CLAS framework (§4) and
periodically sends out the updated schedule and globally-
observed coﬂow sizes to all the daemons.
• Short-term local prioritization: Each daemon sched-
ules coﬂows using the last-known global information. In
between resynchronization, newly-arrived coﬂows are en-
queued in the highest-priority queue. While ﬂows from new
and likely to be small6 coﬂows receive high priority in the
short term, Aalo daemons realign themselves with the global
schedule as soon as updated information arrives. A ﬂow that
has just completed is replaced with a same-destination ﬂow
from the next coﬂow in the schedule for work conservation.
Frameworks use a client library to interact with the coor-
dinator over the network to deﬁne coﬂows and their depen-
dencies (§6). To send data, they must use the Aalo-provided
OutputStream. The coordinator has an ID generator that
creates unique CoﬂowIds while taking coﬂow dependencies
into account (§5.1).
We have implemented Aalo in the application layer with-
out any changes or support from the underlying network. We
have deployed it in the cloud, and it performs well even for
sub-second data analytics jobs (§7).
Fault Tolerance Aalo handles three failure scenarios that
include its own failures and that of the clients using it. First,
failure of a Aalo daemon does not hamper job execution,
since the client library automatically falls back to regular
TCP fair sharing until the daemon is restarted. Upon restart,
the daemon remains in inconsistent state only until the next
coordination step. Second, when the coordinator fails, client
libraries keep track of locally-observed size until it has been
restarted, while periodically trying to reconnect. Finally, in
case of task failures and consequent restarts, relevant ﬂows
are restarted by corresponding job schedulers. Such ﬂows
are treated like a new wave in a coﬂow, and their additional
trafﬁc is added up to the current size of that coﬂow (§5.2).
Scalability The faster Aalo daemons can coordinate, the
better it performs. The number of coordination messages
is linear with the number of daemons and independent of
coﬂows. It is not a bottleneck for clusters with O(100) ma-
chines, and our evaluation suggests that Aalo can scale up to
O(10, 000) machines with minimal performance loss (§7.6).
Most coﬂows are small and scheduled through local deci-
sions; hence, unlike Varys, Aalo handles tiny coﬂows well.
4 Scheduling Without Prior Knowledge
In this section, we present an efﬁcient coﬂow scheduler for
minimizing CCTs without a priori information. First, we dis-
cuss the complexity and requirements of such a scheduler
(§4.1). Next, we describe a priority discretization frame-
work (§4.2) that we use to discuss the tradeoffs in design-
ing an efﬁcient, non-clairvoyant scheduler (§4.3). Based on
6For data-parallel analytics, 60% (85%) coﬂows are less than 100 MB (1
GB) in total size [20, 25].
our understanding, we develop discretized Coﬂow-Aware
Least-Attained Service (D-CLAS) – a mechanism to priori-
tize coﬂows and a set of policies to schedule them without
starvation (§4.4). Finally, we compare our proposal with ex-
isting coﬂow schedulers (§4.5).
For brevity of exposition, we present the mechanisms in
the context of single-stage, single-wave coﬂows. We extend
them to handle multi-stage, multi-wave coﬂows as well as
task failures and speculation in Section 5.
4.1 Complexity and Desirable Properties
The ofﬂine coﬂow scheduling problem – i.e., when all
coﬂows arrive together and their characteristics are known a
priori – is NP-hard [20]. Consequently, the non-clairvoyant
coﬂow scheduling problem is NP-hard as well.
In the non-clairvoyant setting, smallest-bottleneck-ﬁrst
[20] – the best-performing clairvoyant heuristic – becomes
inapplicable. This is because the bottleneck of a coﬂow is re-
vealed only after it has completed. Instead, one must sched-
ule coﬂows based on an attribute that
1. can approximate its clairvoyant counterpart using cur-
rent observations, and
2. involves all the ﬂows to avoid the drawbacks from the
lack of coordination (Theorem A.1).
Note that a coﬂow’s bottleneck can change over time and
due to task failures and restarts, failing the ﬁrst requirement.
In addition to minimizing the average CCT, the non-
clairvoyant scheduler must
1. guarantee starvation freedom for bounded CCTs,
2. ensure work conservation to increase utilization, and
3. decrease coordination requirements for scalability.
Coﬂow-Aware Least-Attained Service (CLAS) Although
the smallest-total-size-ﬁrst heuristic had been shown to per-
form marginally worse (1.14×) than smallest-bottleneck-
ﬁrst in the clairvoyant setting [20], it becomes a viable op-
tion in the non-clairvoyant case. The current size of a coﬂow
– i.e., how much it has already sent throughout the en-
tire cluster – meets both criteria. This is because unlike a
coﬂow’s bottleneck, it monotonically increases with each
ﬂow regardless of start time or endpoints. As a result, set-
ting a coﬂow’s priority that decreases with it’s current size
can ensure that smaller coﬂows ﬁnish faster, which, in turn,
minimizes the average CCT. Furthermore, it is a good indica-
tor of actual size [41], because coﬂow size typically follows
heavy-tailed distribution [20, 11].
We refer to this scheme as Coordinated or Coﬂow-Aware
Least-Attained Service (CLAS). Note that CLAS reduces
to the well-known Least-Attained Service (LAS) [42, 45]
scheduling discipline in case of a single link.
4.2 Priority Discretization
Unfortunately, using continuous priorities derived from
coﬂow sizes can degenerate into fair sharing (§B), which in-
creases the average CCT [19, 25, 20]. Coordination needed
to ﬁnd global coﬂow sizes poses an additional challenge. We
must be able to preempt at opportune moments to decrease
CCT without requiring excessive coordination.
396In the following, we describe a priority discretization
framework to eventually design an efﬁcient, non-clairvoyant
coﬂow scheduler. Unlike classic non-clairvoyant schedulers
– least-attained service (LAS) in single links [42, 45] and
multi-level feedback queues (MLFQ) in operating systems
[23, 21, 13] – that perform fair sharing in presence of simi-
lar ﬂows/tasks to provide interactivity, our solution improves
the average CCT even in presence of identical coﬂows.
Multi-Level Coﬂow Scheduling A multi-level coﬂow
scheduler consists of K queues (Q1, Q2, . . . , QK), with
queue priorities decreasing from Q1 to QK. The i-th queue
contains coﬂows of size within [Qlo
1 =
0, Qhi
K = ∞, and Qlo
Actions taken during three lifecycle events determine a
coﬂow’s priority.
• Arrival: New coﬂows enter the highest priority queue Q1
• Activity: A coﬂow is demoted to Qi+1 from Qi, when its
• Completion: Coﬂows are removed from their current
size crosses queue threshold Qhi
i .
i ). Note that Qlo
i+1 = Qhi
i .
when they start.
i , Qhi
queues upon completion.
The ﬁrst two ensure coﬂow prioritization based on its current
size, while the last is for completeness.
4.3 Tradeoffs in Designing Coﬂow Schedulers
Given the multi-level framework, a coﬂow scheduler can be
characterized by its information source, queue structure, and
scheduling disciplines at different granularities. Tradeoffs
made while navigating this solution space result in diverse
algorithms, ranging from centralized shortest-ﬁrst to decen-
tralized FIFO [19, 20, 25] and many in between. We elabo-
rate on the key tradeoffs below.
Information Source There are two primary categories of
coﬂow schedulers: clairvoyant schedulers use a priori in-
formation and non-clairvoyant ones do not. Non-clairvoyant
schedulers have one more decision to make: whether to use
globally-coordinated coﬂow sizes or to rely on local infor-
mation. The former is accurate but more time consuming.
The latter diverges (Theorem A.1) for coﬂows with large
skews, which is common in production clusters [17, 20].
Queue Structure A scheduler must also determine the
number of queues it wants to use and their thresholds. On the
one hand, FIFO-derived schemes (e.g., Orchestra, Baraat)
use exactly one queue.7 FIFO works well when coﬂows
follow light-tailed distributions [25]. Clairvoyant efﬁcient
schedulers (e.g., Varys), on the other hand, can be considered
to have as many queues as there are coﬂows. They perform
the best when coﬂow sizes are known and are heavy-tailed
[20]. At both extremes, queue thresholds are irrelevant.
For solutions in between, determining an ideal number of
queues and corresponding thresholds is difﬁcult; even for
tasks on a single machine, no optimal solution exists [13].
Increasing the number of levels/queues is appealing, but
7Baraat takes advantage of multiple queues in switches to enable multiplex-
ing, but logically all coﬂows are in the same queue.
Figure 3: Discretized Coﬂow-Aware Least-Attained Service. Con-
secutive queues hold coﬂows with exponentially larger size.
ﬁne-grained prioritization can collapse to fair sharing when
coﬂow sizes are unknown and hurt CCTs. More queues also
generate more “queue-change” events and increase coordi-
nation requirements.
Scheduling Disciplines Finally, a coﬂow scheduler must
decide on scheduling disciplines at three different granulari-
ties: (i) across queues, (ii) among coﬂows in each queue, and
(iii) among ﬂows within each coﬂow. The ﬁrst is relevant
when K > 1, while the second is necessary when queues
have more than one coﬂow. In the absence of ﬂow size infor-
mation, size-based rate allocation algorithms like WSS [19]
and MADD [20] cannot be used; max-min fairness similar to
TCP is the best alternative for scheduling individual ﬂows.
4.4 Discretized Coﬂow-Aware Least-Attained Service
We propose Discretized CLAS or D-CLAS that use more
than one priority queues, i.e., K > 1, to enable prioritiza-
tion. The key challenge, however, is ﬁnding a suitable K that
provides sufﬁcient opportunities for preemption, yet small
enough to not require excessive coordination.
To achieve our goals, each queue in D-CLAS contains
exponentially larger coﬂows than its immediately higher-
priority queue (Figure 3). Formally, Qhi
i , where
the factor E determines how much bigger coﬂows in one
queue are from that in another. Consequently, the number of
queues remains small and can be expressed as an E-based
logarithmic function of the maximum coﬂow size.
i+1 = E×Qhi
The ﬁnal component in deﬁning our queue structure is de-
termining Qhi
1 . Because global coordination, irrespective of
mechanism, has an associated time penalty depending on the
scale of the cluster, we want coﬂows that are too small to be
globally coordinated in Q1. Larger coﬂows reside in increas-
ingly more stable, lower-priority queues (Q2, . . . , QK).
While we typically use E = 10 and Qhi
1 combinations work well (§7.5).
1 = 10 MB in our
cluster, simulations show that for K > 1, a wide range of
K, E, Qhi
Non-Clairvoyant Efﬁcient Schedulers D-CLAS clusters
similar coﬂows together and allows us to implement differ-
ent scheduling disciplines among queues and among coﬂows
within each queue (Pseudocode 1). It uses weighted sharing