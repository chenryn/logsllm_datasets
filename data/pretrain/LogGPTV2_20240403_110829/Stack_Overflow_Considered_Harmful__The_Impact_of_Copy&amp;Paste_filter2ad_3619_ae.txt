For completeness, we conduct a 5-fold cross validation on
the whole training data set with optimal penalty term C =
0.644. We report the confusion matrix of the best fold in Table
VIII. Note that the test size for each fold is 272.
True/Predicted
Secure (-1)
Insecure (+1)
Summary
Secure (-1)
Insecure (+1)
181
19
accuracy: 0.904
7
65
precision: 0.903
TABLE VIII: Confusion matrix
To conclude our model evaluation, we argue that our
SVM model could be improved by a more exhaustive feature
engineering phase and by increasing the size of the training
data set. In our experiment, we only remove comments in
code snippets as a preprocessing step. In practice, this will
be enhanced by applying a more complex token parser, e.g.,
to generate better quality of features.
static code parser,
Moreover, we did not
leverage control ﬂow information,
which is considered informative of predicting security level,
to enhance the model. A possible reﬁnement would be the
encoding of the relative position of each token in the snippet
into the features. However, this could double the size of input
feature dimension. Due to the complexity of model pruning
and the limit of the training sample size, we decided to leave
it for future work. Given the fact that the performance of
the SVM model already achieves a level of practicability,
we think that machine learning based approaches have the
potential to support security code analysis.
3) Large Scale Classiﬁcation: We applied our SVM code
classiﬁer on the complete set of 3,834 distinct security-related
snippets from Stack Overﬂow, including question and answer
snippets. Overall, we found 1,161 (30.28%) insecure snippets
and 2,673 (69.72%) secure snippets. Out of the 1,360 distinct
snippets found in answer posts, 420 (30.88%) snippets were
classiﬁed as insecure and and 940 (69.12%) as secure. For
the 2,474 distinct snippets we detected in questions posts,
741 (29.95%) snippets were classiﬁed as insecure and 1,733
(70.05%) as secure.
C. Evaluation of Code Detection
We applied our pipeline (cf. Section VI)
to a large
free Android applications from Google Play.
corpus of
Beginning in October 2015, we successfully downloaded
1,305,820 free Android applications from Google Play5. We
re-downloaded new versions until May 2016. The majority
of apps received their newest update within the last 12 months.
1) Apps with Copied and Pasted Code Snippets: Overall,
we detected copied and pasted snippets in 200,672 (15.4%)
apps. Of these apps, 198,347 (15.2%) contain a question
snippet and 40,786 (3.1%) apps contain an answer snippet.
5cf. https://play.google.com
An overwhelming amount of apps contain an insecure code
snippet: 196,403 (15%) apps contain at least one. The top
offending snippet has been found in 180,388 (13.81%) apps
and is presented in Listing 4. The remaining insecure snippets
were found in 43,941 (3,37%) distinct apps.
We found 506,922 (38.82%) apps that contain a secure
snippet. The most frequent secure snippet was detected in
408,011 (31.24%) apps while the remaining snippets were
contained in less then 73,839 (5.65%) apps. On average, an
insecure snippet is found in 4,539.96 apps, while a secure code
snippet is found in 10,719.83 apps.
To investigate insecure snippets that were detected by our
fully automated processing pipeline in detail, we performed
a manual post-analysis of the categories described in Section
IV. To be more precise, we examined all security-related
snippets that were detected in applications and sorted them
by category. In the following, we give counts for affected
applications for each security category. The given percentage
values are related to applications that contain a snippet from
Stack Overﬂow. Further, we discuss the most offending
snippets and estimate their practical exploitability.
2) SSL/TLS: The highest number of apps that implemented
an insecure code snippet used this snippet to handle TLS.
183,268 (14.03%) apps were affected by insecure TLS
handling through a copied and pasted insecure code snippet.
Conversely, only 441 (0.03%) of all apps contained a
secure code snippet related to TLS. For the large majority
of 182,659 (13.98%) apps with an insecure TLS snippet,
their code snippet matches a question code snippet on Stack
Overﬂow, while only 22,040 (1.68%) apps contain an insecure
TLS snippet that was present in an answer on Stack Overﬂow.
A high risk example in this category is given by the top
offending snippet as presented in Listing 4, which uses an
insecure custom TrustManager as described in Section VII-A.
Missing server veriﬁcation enables Man-In-The-Middle
attacks by presenting malicious certiﬁcates during the TLS
handshake. This snippet is a real threat with high risk of
exploitation in the wild, as shown in [2].
3) Symmetric Cryptography: The second highest number
of insecure code snippets in the wild were used for symmetric
cryptography in 21,239 (1.62%) apps. 19,452 (1.48%) of
the apps with a code snippet that was related to symmetric
cryptography had integrated a secure snippet. With a count of
19,189 apps, slightly more apps contain an insecure question
snippet
than an insecure answer snippet, which happened
in 15,125 apps. The insecure snippet with the highest copy
and paste count (found in 18,000 apps) within this category
proposes AES in ECB mode. According to [3]
this is
vulnerable to chosen-plaintext attacks. Further, applications
that include snippets with hard-coded cryptographic keys can
most often be reverse-engineered without much effort. This
leads leads to key leakage and therefore states a high risk (at
least in the case where the key is not obfuscated).
131
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:23:20 UTC from IEEE Xplore.  Restrictions apply. 
4) Asymmetric Cryptography: We found only 114 (0.01%)
apps that contained an insecure code snippet
related to
asymmetric cryptography, 698 (0.05%) apps contained a
secure asymmetric cryptography related snippet. 114 apps
with insecure snippets contain an insecure question snippet.
29 apps implemented a secure answer snippet, 688 a secure
question snippet.
5) Secure Random Number Generation: 8,228 (0.63%)
apps contain an insecure code snippet related to random
number generation, while 4,100 (0.31%) apps contained a
secure snippet. Most insecurities in this category come from
question snippets (this was true for 8,227 apps, while 7,991
apps contain an insecure answer snippet).
6) Hashes: For hash functions,
the majority of apps
containing code snippets from Stack Overﬂow contained
secure code snippets: This was true in 4,012 (0.3%), 14 apps
contained an insecure one.
7) Signatures: 15 apps contained a secure signature related
snippet, while no insecure snippet was found in apps in this
category. All of those snippets could be found in questions
on Stack Overﬂow.
8) Not Security-Related: Some of the snippets that were
detected in apps could not be assigned to one of the categories
above because they were not security-related as described in
III-C. 498,046 (38.1%) apps contained a snippet that was not
security-related and therefore classiﬁed as secure.
The most frequent secure snippet found in 408,011 apps
was also not security-related. Therefore, considering security-
related snippets only, we can state that signiﬁcantly more
Android applications contain an insecure snippet (196,403)
than a secure one (73,839) (cf. Section VII-C1).
9) Sensitive App Categories: The largest number of sensi-
tive apps that use insecure copied and pasted code snippets are
14,944 business apps, 4,707 shopping apps, and 4,243 ﬁnance
apps. We ﬁnd this result rather surprising, as we would have
expected that security receives special consideration for these
types of applications. Especially, ﬁnance apps have access
to bank account information and therefore we would have
expected them to be developed with extra care. Security and
privacy is especially important in apps that handle medical
data, as leaked sensitive data can have a severe impact on
users. We found 2,000 medical and 4,222 health&ﬁtness apps
that copied and pasted vulnerable Stack Overﬂow code. Apps
that are used for communication (3,745 apps) and social media
(4,459 apps) are also widely affected.
10) Download Counts: In order to prove that we did not
the long tail of unpopular apps provided by
only inspect
Google Play we provide download counts for apps that contain
insecure snippets in Figure 6.
Fig. 5: Distributions of insecure snippets found in Apps
Fig. 6: Download counts for Apps with insecure snippets
D. Evaluation of Community Feedback
For those insecure snippets that we detected in Android
applications, we analyzed the community feedback on Stack
Overﬂow as this represents the current public evaluation of
posted code snippets. The available feedback mechanisms
allow a very general evaluation of code snippets, e. g. with
the presentation of view counters and the individual post
score which results from up-/down-votes by the community.
In addition to this, code snippets can be commented which is
used to provide a more detailed feedback.
We analyzed if the existing feedback system provided by
132
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:23:20 UTC from IEEE Xplore.  Restrictions apply. 
SO is capable of informing the user about insecure snippets
in an adequate way. At that, we analyze if the currently given
feedback by the community is preventing or contributing to
copy and paste of insecure code into Android applications.
1) Scoring: According to Stack Overﬂow, a question snip-
pet is supposed to be up-voted if it shows reasonable research
effort
in order to motivate the community to reply to it.
Therefore, with a pure focus on security aspects we expect
insecure question snippets to be up-voted, as insecure code
snippets intuitively demand more community research than
secure ones. In contrast to question scores, answers are up-
voted (according to Stack Overﬂow) if they are estimated
useful. Regarding the score of insecure answer snippets we
expect a lower score as these do not provide a useful answer
considering security-related snippets.
The results in table IX show that the scoring of insecure
question snippets contradict to our assumption, because the
secure ones have a higher score. In other words, the com-
munity assigns a higher needed research effort to questions
with secure snippets. This is counter-intuitive from the security
perspective and therefore leads to the conclusion that question
scoring is not an adequate way of evaluating security. Of
course, the community estimates needed research effort on
the basis of a diversity of aspects, which outweigh security
considerations. However, regarding answers, the low scoring
of insecure snippets (as depicted in Table IX) correspond to
our expectations. Again, this positive correlation might be
caused by a variety of aspects, but from the security point
of view it reveals the desired community behavior. However,
aspects that are currently taken account for answer scoring are
likely to be weighted differently in the future.
Next, we additionally include security warnings in our eval-
uation. Here, the scoring for questions given by the community
are consistent with our intuition: Insecure questions including
a warning are assigned with a higher scoring (corresponding
to higher estimated research effort) than questions without
such a warning. However, the scoring estimation regarding
answer posts contradicts the desired community behavior: In-
secure answers with security warning are scored signiﬁcantly
higher compared to the ones without warnings (cf. Table
IX). Therefore, the inﬂuence of warnings (in answers) on the
community score is highly questionable. A high scored answer
with assigned security warning might confuse the reader.
The following considerations try an explanation of this
result. Though a security warning should have a strong impact
on the evaluation, the author of the warning can down-vote the
score only once. On the one hand, this gives the community
the ability to review the warning and to further reduce the
score or to comment disagreement. On the other hand, the
results show that the scoring of insecure snippets is partly
contradicting and we did not ﬁnd a single warning that has
been questioned in a subsequent comment. Acar et al. [42]
have shown that developers prefer functional snippets over
secure snippets when implementing security related tasks in
Android. This preference might also inﬂuence the scoring of
security-related snippets which can result into a score that
mostly considers functionality as the deﬁnition of a useful
answer.
When solely taking security considerations into account, we
conclude that the currently deployed feedback system is insuf-
ﬁcient for providing reliable and precise security estimation to
the user.
Secure
3.4/4.8
Insecure
1.7/4.4
Metadata
Avg. Score Q/A
Avg. Viewcount Q/A
TABLE IX: Community feedback for security-related snippets
regarding questions (Q) and answers (A)
Insecure+Warning
Insecure-Warning
2.4/15.5
4081/16534
1467/4341
2254/8117
2.3/6.2
2812/10001
2) Impact on Copy and Paste: Next, we investigated if
view count, warnings, and score of insecure snippets have
an impact on the extent they are copied into applications.
We ﬁrst ordered all snippets according to their detection
rate (the amount of applications that contained that snippet).
For the snippets that ranked highest and lowest on this list
(respectively 25% – we refer to these as top and bottom tier)
we extracted the corresponding metadata from Stack Overﬂow.
This allowed us to observe possible correlations between view
counts, warnings, and scoring to the actual copy and paste rate.
For both score and view count we found a positive correla-
tion: A higher score or view count corresponds to an increased
copy and paste count, as depicted in Table X. This yields for
both, questions and answers.
Interestingly, we see the opposite behavior with regard to
warnings: Snippets that have been commented with security
warnings are copied more often into applications than those
without. An exceptionally striking example for this observation
is the top offending snippet which was copied 180,388 times
despite of being commented with warnings (cf. Listing 4).
Metadata
Avg. Score (top/bottom tier)
Avg. Viewcount (top/bottom tier)
Questions
1.87/1.27
2,792/1,373
Answers
7.21/6.37
11,915/7805
TABLE X: Correlation of community feedback with copy and
paste count of insecure code snippets
E. Limitations
Besides the limitations of the intermediate steps discussed in
Sections III-C and IV-C, our processing pipeline does not fully
prove that copied snippets originate from Stack Overﬂow. To
illustrate this objection, there theoretically could exist a third
platform where snippets are copied and inserted to both, Stack
Overﬂow and Android applications. However, Stack Overﬂow
is the most popular platform for developer discussions6. Fur-
ther, [42] et al. showed that developers most often rely on
Stack Overﬂow when solving security-related programming
problems at hand. And ﬁnally, we found a positive correlation
of the snippets view counts with their detected presence in
applications (as discussed in Section VII-D2). Therefore, it is
very likely that snippets originate from Stack Overﬂow.
6cf. http://www.alexa.com/topsites
133
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:23:20 UTC from IEEE Xplore.  Restrictions apply. 
VIII. RELATED WORK
C. Investigation of Stack Overﬂow
We focus on related work in four key areas, i.e. security
investigation of Stack
of mobile apps, developer studies,
Overﬂow, and detection of code reusage in apps.
A. Security of Mobile Apps
Fahl et al. analyzed the security of TLS code in 13,500
popular, free Android applications [2]. They found that 8%
were vulnerable to Man-In-The-Middle attacks. In follow-up
work, they extended their investigation to iOS and found simi-
lar results: 20% of the analyzed apps were vulnerable to Man-
In-The-Middle attacks [17]. Oltrogge et al. [18] investigated
the applicability of public key pinning in Android applications
and came to the conclusion that pinning was not as widely
applicable as commonly believed. Egele et al. [3] investigated
the secure use of cryptography APIs in Android applications
and found more than 10,000 apps misusing cryptographic
primitives in insecure ways. Enck et al. [43] presented Taint-
Droid, a tool that applies dynamic taint tracking to reveal how
Android applications actually use permission-protected data.
They found a number of questionable privacy practices in
apps and suggested modiﬁcations of the Android permission
model and access control mechanism for inter-component
communication. Chin et al [44] characterized errors in inter-
application communications (intents) that can lead to inter-
ception of private data, service hijacking, and control-ﬂow
attacks. Enck et al. [45] analyzed 1,100 Android applications
and reported widespread security problems, including the use
of ﬁne-grained location information in potentially unexpected
ways, using device IDs for ﬁngerprinting and tracking and
transmitting device and location in plaintext. Poeplau et
al. [46] reported that many apps load application code via
insecure channels allowing attackers to inject malicious code
into benign apps.