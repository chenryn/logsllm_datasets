## PostgreSQL 异步消息实践 - Feed系统实时监测与响应(如 电商主动服务) - 分钟级到毫秒级的实现
### 作者      
digoal      
### 日期      
2017-11-11      
### 标签      
PostgreSQL , 异步消息 , 触发器 , 规则 , insert on conflict , 实时分析     
----      
## 背景     
在很多业务系统中，为了定位问题、运营需要、分析需要或者其他需求，会在业务中设置埋点，记录用户的行为在业务系统中产生的日志，也叫FEED日志。    
比如订单系统、在业务系统中环环相扣，从购物车、下单、付款、发货，收货（还有纠纷、退款等等），一笔订单通常会产生若干相关联的记录。    
每个环节产生的属性可能是不一样的，有可能有新的属性产生，也有可能变更已有的属性值。    
为了便于分析，通常有必要将订单在整个过程中产生的若干记录（若干属性），合并成一条记录（订单大宽表）。    
通常业务系统会将实时产生的订单FEED数据写入消息队列，消息队列使得数据变成了流动的数据：    
[《从人类河流文明 洞察 数据流动的重要性》](../201707/20170706_01.md)      
## 方案一、RDS PG + OSS + HDB PG 分钟清洗和主动检测    
数据通过消息队列消费后，实时写入RDS PG，在RDS PG进行订单FEED的合并，写入OSS外部表。(支持压缩格式，换算成裸数据的写入OSS的速度约100MB/s/会话)    
HDB PG从OSS外部表读取(支持压缩格式，换算成裸数据的读取OSS的速度约100MB/s/数据节点)，并将订单FEED数据合并到全量订单表。    
![pic](../201707/20170728_01_pic_001.jpg)        
[《打造云端流计算、在线业务、数据分析的业务数据闭环 - 阿里云RDS、HybridDB for PostgreSQL最佳实践》](../201707/20170728_01.md)      
数据进入HDB PG后，通过规则SQL，从全量订单表中，挖掘异常数据（或者分析）。    
通过这种方案，实现了海量订单FEED数据的分钟级准实时分析。    
**这个方案已支撑了双十一业务，超高吞吐、低延迟，丝般柔滑。**    
## 方案二、毫秒级FEED监测及实时反馈方案    
技术永远是为业务服务的，分钟级延迟虽然说已经很高了，但是在一些极端情况下，可能需要更低的延迟。    
实际上RDS PostgreSQL还有更强的杀手锏，可以实现毫秒级的异常FEED数据发现和反馈。    
流式处理+异步消息，方法如下：    
1、通过触发机制结合异步消息通道实现。    
![pic](20171111_01_pic_001.jpg)    
2、通过pipeline，流式SQL结合异步消息通道实现。    
![pic](20171111_01_pic_002.jpg)    
应用程序监听消息通道(listen channel)，数据库则将异常数据写入到消息通道(notify channel, message)。实现异常数据的主动异步推送。    
## 毫秒级FEED监测与反馈架构设计    
之前不做毫秒级的FEED监测，还有一个原因是HBASE的合并延迟较高，导致流计算在补齐字段时异常。使用RDS PG来实现异常监测，完全杜绝了补齐的问题，因为在RDS PG就包含了全字段，不存在补齐的需求。    
![pic](20171111_01_pic_003.jpg)    
### RDS PG设计    
1、分实例，提高系统级吞吐。（例如单实例处理能力是15万行/s，那么100个实例，可以支撑1500万行/s的实时处理。）    
例如：    
```    
DB0, DB1, DB2, DB3, ..., DB255    
```    
映射关系：    
```    
db0, host?, port?    
db1, host?, port?    
...    
```    
2、实例内使用分表，提高单实例并行处理吞吐。当规则众多时，分表可以提高单实例的规则处理吞吐。    
例如    
```    
tbl0, tbl1, tbl2, ..., tbl127    
tbl128, tbl129, tbl130, ..., tbl255    
```    
映射关系：    
```    
tbl0, db?    
tbl1, db?    
...    
```    
### HDB PG设计    
HDB PG依旧保留，用于PB级数据量的海量数据实时分析。    
数据通路依旧采用OSS，批量导入的方式。    
## DEMO    
1、创建订单feed全宽表（当然，我们也可以使用jsonb字段来存储所有属性。因为PostgreSQL支持JSONB类型哦。PostgreSQL支持的多值类型还有hstore, xml等。）    
```    
create table feed(id int8 primary key, c1 int, c2 int, c3 int, c4 int, c5 int, c6 int, c7 int, c8 int, c9 int, c10 int, c11 int, c12 int);    
```    
2、订单FEED数据的写入，例如A业务系统，写入订单的c1,c2字段。B业务系统，写入订单的c3,c4字段。......    
使用on conflict do something语法，进行订单属性的合并。    
```    
insert into feed (id, c1, c2) values (2,2,30001) on conflict (id) do update set c1=excluded.c1, c2=excluded.c2 ;    
insert into feed (id, c3, c4) values (2,99,290001) on conflict (id) do update set c3=excluded.c3, c4=excluded.c4 ;    
```    
3、建立订单FEED的实时监测规则，当满足条件时，向PostgreSQL的异步消息中发送消息。监听该通道的APP，循环从异步消息获取数据，即可满足消息的实时消费。    
规则可以保留在TABLE中，也可以写在触发器代码中，也可以写在UDF代码中。    
3\.1、如果数据是批量写入的，可以使用语句级触发器，降低触发器函数被调用的次数，提高写入吞吐。    
```    
create or replace function tg1() returns trigger as $$    
declare    
begin     
  -- 规则定义，实际使用时，可以联合规则定义表    
  -- c2大于1000时，发送异步消息    
  perform pg_notify('channel_1', 'Resone:c2 overflow::'||row_to_json(inserted)) from inserted where c2>1000;      
  -- 多个规则，写单个notify的方法。    
  --   perform pg_notify(    
  --                    'channel_1',      
  --                   case     
  --                    when c2>1000 then 'Resone:c2 overflow::'||row_to_json(inserted)     
  --                    when c1>200 then 'Resone:c1 overflow::'||row_to_json(inserted)     
  --                   end    
  --                  )     
  --   from inserted     
  --   where     
  --     c2 > 1000     
  --     or c1 > 200;      
  -- 多个规则，可以写多个notify，或者合并成一个NOTIFY。    
  return null;    
end;    
$$ language plpgsql strict;    
```    
3\.2、如果数据是单条写入的，可以使用行级触发器。（本例后面的压测使用这个）    
```    
create or replace function tg2() returns trigger as $$    
declare    
begin     
  -- 规则定义，实际使用时，可以联合规则定义表    
  -- c2大于9999时，发送异步消息    
  perform pg_notify('channel_1', 'Resone:c2 overflow::'||row_to_json(NEW)) where NEW.c2>9999;      
  -- 多个规则，调用单个notify，写一个CHANNEL的方法。    
  --   perform pg_notify(    
  --                    'channel_1',      
  --                   case     
  --                    when c2>1000 then 'Resone:c2 overflow::'||row_to_json(NEW)     
  --                    when c1>200 then 'Resone:c1 overflow::'||row_to_json(NEW)     
  --                   end    
  --                  )     
  --   where     
  --     NEW.c2 > 10000     
  --     or NEW.c1 > 200;      
  -- 多个规则，调用单个notify，写多个CHANNEL的方法。    
  --   perform pg_notify(    
  --                   case     
  --                    when c2>1000 then 'channel_1'     
  --                    when c1>200 then 'channel_2'     
  --                   end,    
  --                   case     
  --                    when c2>1000 then 'Resone:c2 overflow::'||row_to_json(NEW)     
  --                    when c1>200 then 'Resone:c1 overflow::'||row_to_json(NEW)     
  --                   end    
  --                  )     
  --   where     
  --     NEW.c2 > 1000     
  --     or NEW.c1 > 200;      
  -- 多个规则，可以写多个notify，或者合并成一个NOTIFY。    
  -- 例如    
  -- perform pg_notify('channel_1', 'Resone:c2 overflow::'||row_to_json(NEW)) where NEW.c2 > 1000;    
  -- perform pg_notify('channel_2', 'Resone:c1 overflow::'||row_to_json(NEW)) where NEW.c1 > 200;    
  -- 也可以把规则定义在TABLE里面，实现动态的规则    
  -- 规则不要过于冗长，否则会降低写入的吞吐，因为是串行处理规则。    
  -- udf的输入为feed类型以及rule_table类型，输出为boolean。判断逻辑定义在UDF中。    
  -- perfrom pg_notify(channel_column, resone_column||'::'||row_to_json(NEW)) from rule_table where udf(NEW::feed, rule_table);    
  return null;    
end;    
$$ language plpgsql strict;    
```    
3\.3、如上代码中所述，规则可以定义在很多地方。    
4、创建触发器。    
4\.1、语句级触发器(批量写入，建议采用)    
```    
create trigger tg1 after insert on feed REFERENCING NEW TABLE AS inserted for each statement execute procedure tg1();    
create trigger tg2 after update on feed REFERENCING NEW TABLE AS inserted for each statement execute procedure tg1();    
```    
4\.2、行级触发器(单步写入建议采用)，（本例后面的压测使用这个）    
```    
create trigger tg1 after insert on feed for each row execute procedure tg2();    
create trigger tg2 after update on feed for each row execute procedure tg2();    
```    
5、协商好通道名称。    
6、应用端监听消息通道。    
```    
listen channel_1;    
接收消息：    
loop    
  sleep ?;    
  get 消息;    
end loop    
```    
7、写入订单数据，每行数据都会实时过触发器，在触发器中写好了逻辑，当满足一些规则时，向协商好的消息通道发送消息。    
```    
postgres=# insert into feed (id, c1, c2) values (2,2,30001) on conflict (id) do update set c1=excluded.c1, c2=excluded.c2 ;    
INSERT 0 1    
```    
8、接收到的消息样本如下：    
```    
Asynchronous notification "channel_1" with payload "Resone:c2 overflow::{"id":2,"c1":2,"c2":30001,"c3":null,"c4":null,"c5":null,"c6":null,"c7":null,"c8":null,"c9":null,"c10":null,"c11":null,"c12":null}" received from server process with PID 38445.    
```    
9、批量插入    