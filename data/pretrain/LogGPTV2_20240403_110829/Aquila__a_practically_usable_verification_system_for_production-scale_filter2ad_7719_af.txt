The first experiment evaluated the performance under differ-
ent sizes of the program. Due to the complexity of the mapping
between the P4 program and encoded GCL, it is hard to evaluate
the scalability by comparing different programs. Instead, we con-
structed a huge P4 pipeline by connecting ùëò switch-T programs,
where ùëò ranges from 1 to 5. For each ùëò, we checked two versions,
one without bug and one with bugs, and reported the verification
time and memory usage. Figure 11a shows even for the largest case
(five switch-T connected), Aquila finished verification within 200
seconds, and consumed 3GB memory.
The second experiment focused on the number of entries in the
tables and influence of the ABV encoding. We installed different
number of entries in the tables and compared the performance
against two inferior approaches: the naive encoding that checks
entries one by one through if-else branching and the ABV with-
out lookup optimization. As shown in Figure 11b, as the number
of entries increases, Aquila‚Äôs verification time grows logarithmi-
cally, with the ùëÇ(log ùëõ) lookup optimization complexity. The naive
approach triggers time out after only 4k entries. The lookup opti-
mization further improved the verification time by up to 6√ó. Also,
across all three approaches, memory only grew mildly, suggesting
that the table lookup is a compute intensive job.
8.3 Bug Localization
Finally, we evaluated the bug localization. Based on switch-T pro-
gram, we built three versions: Large, which is the original switch-T
program; Medium, with DTEL and sFlow function disabled; Small,
with QoS, mirroring, L2 forwarding and IPv6 disabled additionally.
We injected three bugs, one with a wrong entry installed, one with
a statement missing, and one with a wrong statement. To evaluate
the performance of the localization algorithm, we introduced a
metric called precision. The precision denotes the percentage of
potential locations that Aquila can filter out. This value directly
reflects the amount of effort we can save. A 100% precision means
Aquila can accurately locate the bug with no false positive. Table 4
shows Aquila located wrong entry and code error bugs with 100%
precision in a few seconds. For the code missing bugs, because there
might be multiple potential bug locations, Aquila took longer time,
but is still able to maintain the precision around 95%.
9 LESSONS AND DISCUSSIONS
In this section, we share our lessons in designing and deploying
Aquila, and also discuss limitations of Aquila and open questions.
	0	50	100	150	20012345Time	(seconds)w/o	bugsw/	bugs101001kTimeout1k2k3k4k5kTime	(seconds)ABV+OptABVNaive	1	1.5	2	2.5	312345Memory	(GB)Number	of	copies	1.2	1.4	1.6	1.8	21k2k3k4k5kMemory	(GB)Number	of	additional	table	entriesSIGCOMM ‚Äô21, August 23‚Äì27, 2021, Virtual Event, USA
Tian et al.
Specifying service-specific properties. Most (about 90%) of our
specifications are service-specific properties. For example, (1) any
packet sending to 10.0.1/24 should not have VXLAN filed in its
header, (2) all packets from 20.1/16 should remain the DSCP val-
ues after leaving the current programmable switch, and (3) table
arp_ùë° should not be hit by packets destinating 12.0.2/24. Our expe-
rience shows specifying the above properties is much more chal-
lenging than undefined P4 behaviors such as invalid header and
out-of-register checking. This is because our engineers should well
first understand these service-specific properties and then express
them in a correct and complete way. While using LPI saves our
engineers‚Äô property-specifying time, an automatic specification
inferring approach based on example-based synthesis [3, 21] might
be a potential direction for building more efficient way to express
service-specific properties.
Verification or testing? Verification can offer rigorous correct-
ness checking by modeling program of interest and using some
prover to prove whether the target program is bug-free; on the
contrary, testing techniques provide input-output checking based
on the limited test case coverage. In Alibaba network, we need
both of above two techniques. Specifically, we are using verification
techniques (i.e., Aquila) to ensure the correctness of P4 program
in the perspective of packet processing logic; however, Aquila is
not able to detect bugs such as compiler and ASIC-specific bugs.
Thus, how to build a full-coverage testing technique capable of
automatically detecting compiler, hardware and performance bugs
in P4 programs is highly needed and is still an open question.
Distributed data plane verification. In Alibaba‚Äôs edge networks,
each programmable switch‚Äôs data plane program is individual; thus,
Aquila is only focused on verifying data plane program on a sin-
gle switch. As increasingly more new data plane applications are
launched in the future, we believe distributed data plane programs
may play important roles. A distributed data plane program means
multiple programmable switches, where switches‚Äô data plane pro-
grams are different, coordinately work together to process packets
for some purpose. For example, a super big table that may not
be put in a single switch‚Äôs ASIC can be split across multiple pro-
grammable switches [16]. Verifying such a distributed data plane
program‚Äîeven with heterogeneous underlying ASICs and program-
ming languages‚Äîwould need to address more challenges.
Automatically bug repairing. While Aquila can detect the po-
tential violations and automatically localize bugs, Aquila is not able
to fix the detected bugs. Automatically repairing bugs in data plane
programs is very challenging, because (1) the data plane program
may have very complex functional logic, (2) a buggy program may
have many different fixing solutions, and (3) it is also non-trivial to
avoid side effects when producing a potential fixing plan. Thus, we
leave how to automatically repair bugs in the future work.
Aquila‚Äôs usage phase. In Alibaba network, we are mainly using
Aquila in two phases: (1) checking data planes during service run-
time and (2) checking new data plane programs before updating
them in the network. In the service runtime, we aim to use Aquila
to check newly-required properties or check data planes if any new
table entries are installed. In the update phase, we use Aquila to en-
sure that the updated data planes still meet our required properties
ahead of time.
10 RELATED WORK
Programmable data planes checking. There have been several
verification techniques proposed to check correctness of programmable
data planes. For example, p4v [30] employs a classic verification
approach to formally check P4 program correctness in terms of any
table entry. Vera [48] leverages symbolic execution to ensure the
correctness of a network snapshot (including both P4 programs and
table entries). bf4 [11] targets undefined P4 behavior prevention
in runtime by automatically inferring assertions and preventing
table rules from potentially triggering bugs. bf4 is a good comple-
mentary to Aquila, since Aquila does not explicitly prevent bugs
in runtime. p4-assert [35] and p4-NOD [32] translate P4 code into
other language models (e.g., C and NoD) which are verifiable by the
existing frameworks. In addition, p4pktgen [36] and Netdiff [12]
use testing techniques to check programmable data planes.
Network configuration verification. Many efforts were proposed
to verify the correctness of network configuration‚Äîi.e., whether
a given network configuration meets the operation specification.
These efforts can be classified into two groups: control plane verifi-
cation [4, 13, 15, 19, 20, 38, 42, 47, 51, 52, 55, 56], and data-plane for-
warding verification [5, 23‚Äì25, 28, 29, 31, 37, 49, 50]. These systems
focused on checking the properties such as routing equivalence
and packet reachability, which are different from Aquila‚Äôs goal.
Data plane program synthesis. The state-of-the-art efforts in
synthesizing data plane program for programmable switching ASICs
are mainly focused on building compilers for chip-specific code
generation. For example, Lyra [16] and ùúáP4 [46] propose high-
level languages for engineers to easily express their programs and
the compilers generate chip-specific code such as P4 and NPL.
Domino [45] was built to support stateful processing, enabling a
wide class of data plane algorithms; as an enhancement effort, Chip-
munk [17, 18] leverages the synthesis technique to generate more
cases than Domino, and the generated code needs fewer resources
than Domino. Dejavu [54] targets compiling a hyper-converged
function-chain into a single ASIC.
11 CONCLUSION
This paper presents Aquila, the first-ever reported practically usable
verification system for programmable data planes in Alibaba. To
achieve the practical usage goal, Aquila makes four contributions:
(1) a language for engineers to express intent with ease; (2) a new
encoding approach making verification scalable to production-scale
data planes; (3) a bug localization approach capable of accurately
finding bugs resulting in violation; and (4) a self-validator for iden-
tifying issues in Aquila. Aquila has been used to verify Alibaba‚Äôs
programmable edge networks for half a year, and it successfully
prevented many potential failures resulting from data plane bugs.
This work does not raise any ethical issues.
ACKNOWLEDGMENTS
We thank our shepherd, Stefano Vissicchio, and SIGCOMM review-
ers for their insightful comments. Bingchuan Tian and Chen Tian
are supported in part by the National Natural Science Foundation
of China under Grant Numbers 61772265 and 62072228. Jiaqi Gao
and Minlan Yu are supported in part by NSF grant CNS-1834263.
oldvera.
REFERENCES
[1] Vera old version: P4 program verification. https://github.com/dragosdmtrsc/
[2] Vera2: P4 program verification. https://github.com/dragosdmtrsc/vera2.
[3] An, S., Singh, R., Misailovic, S., and Samanta, R. Augmented example-based
synthesis using relational perturbation properties. Proc. ACM Program. Lang. 4,
POPL (2020), 56:1‚Äì56:24.
[4] Beckett, R., Gupta, A., Mahajan, R., and Walker, D. A general approach to
[11] Dumitrescu, D., Stoenescu, R., Negreanu, L., and Raiciu, C. bf4: towards
network configuration verification. In ACM SIGCOMM (SIGCOMM) (2017).
[5] Beckett, R., Mahajan, R., Milstein, T. D., Padhye, J., and Walker, D. Don‚Äôt
mind the gap: Bridging network-wide objectives and device-level configurations.
In ACM SIGCOMM (SIGCOMM) (2016).
558‚Äì562.
[6] B.Kahn, A. Topological sorting of large networks. Commun. ACM 5, 11 (1962),
[7] Christakis, M., Heizmann, M., Mansur, M. N., Schilling, C., and W√ºstholz,
V. Semantic fault localization and suspiciousness ranking. In 25th International
Conference on Tools and Algorithms for the Construction and Analysis of Systems
(TACAS) (2019).
[8] Dang, H. T., Sciascia, D., Canini, M., Pedone, F., and Soul√©, R. Netpaxos:
Consensus at network speed. In ACM SIGCOMM Symposium on SDN Research
(SOSR) (2015).
[9] de Moura, L. M., and Bj√∏rner, N. Z3: An efficient SMT solver. In 14th Tools
and Algorithms for the Construction and Analysis of Systems (TACAS) (2008).
[10] Dijkstra, E. W. Guarded commands, nondeterminacy and formal derivation of
programs. Commun. ACM 18, 8 (1975), 453‚Äì457.
bug-free P4 programs. In ACM SIGCOMM (SIGCOMM) (2020).
[12] Dumitrescu, D., Stoenescu, R., Popovici, M., Negreanu, L., and Raiciu, C.
In 16th USENIX Symposium on
Dataplane equivalence and its applications.
Networked Systems Design and Implementation (NSDI) (2019).
[13] Fayaz, S. K., Sharma, T., Fogel, A., Mahajan, R., Millstein, T., Sekar, V., and
Varghese, G. Efficient network reachability analysis using a succinct control
plane representation. In 12th USENIX Symposium on Operating Systems Design
and Implementation (OSDI) (2016).
[14] Flanagan, C., and Saxe, J. B. Avoiding exponential explosion: Generating
compact verification conditions. In 28th ACM SIGPLAN-SIGACT Symposium on
Principles of Programming Languages (POPL) (2001).
[15] Fogel, A., Fung, S., Pedrosa, L., Walraed-Sullivan, M., Govindan, R., Maha-
jan, R., and Millstein, T. A general approach to network configuration analysis.
In 12th USENIX Symposium on Networked Systems Design and Implementation
(NSDI) (2015).
[16] Gao, J., Zhai, E., Liu, H. H., Miao, R., Zhou, Y., Tian, B., Sun, C., Cai, D., Zhang,
M., and Yu, M. Lyra: A cross-platform language and compiler for data plane
programming on heterogeneous ASICs. In ACM SIGCOMM (SIGCOMM) (2020).
[17] Gao, X., Kim, T., Varma, A. K., Sivaraman, A., and Narayana, S. Autogenerating
fast packet-processing code using program synthesis. In 18th ACM Workshop on
Hot Topics in Networks (HotNets) (2019).
[18] Gao, X., Kim, T., Wong, M. D., Raghunathan, D., Varma, A. K., Kannan, P. G.,
Sivaraman, A., Narayana, S., and Gupta, A. Switch code generation using
program synthesis. In ACM SIGCOMM (SIGCOMM) (2020).
[19] Gember-Jacobson, A., Viswanathan, R., Akella, A., and Mahajan, R. Fast
In ACM SIGCOMM
control plane analysis using an abstract representation.
(SIGCOMM) (2016).
[20] Giannarakis, N., Beckett, R., Mahajan, R., and Walker, D. Efficient veri-
fication of network fault tolerance via counterexample-guided refinement. In
International Conference on Computer Aided Verification (2019), Springer.
[21] Gulwani, S. Automating string processing in spreadsheets using input-output
In Proceedings of the 38th ACM SIGPLAN-SIGACT Symposium on
examples.
Principles of Programming Languages (POPL) (2011).
[22] Handley, M., Raiciu, C., Agache, A., Voinescu, A., Moore, A. W., Antichi, G.,
and W√≥jcik, M. Re-architecting datacenter networks and stacks for low latency
and high performance. In ACM SIGCOMM (SIGCOMM) (2017).
[23] Horn, A., Kheradmand, A., and Prasad, M. R. Delta-net: Real-time network
In 14th USENIX Symposium on Networked Systems
verification using atoms.
Design and Implementation (NSDI) (2017).
[24] Jayaraman, K., Bj√∏rner, N., Outhred, G., and Kaufman, C. Automated analysis
and debugging of network connectivity policies. In Technical Report MSR-TR-
2014-102 (2014).
[25] Jayaraman, K., Bj√∏rner, N., Padhye, J., Agrawal, A., Bhargava, A., Bisson-
nette, P. C., Foster, S., Helwer, A., Kasten, M., Lee, I., Namdhari, A., Niaz, H.,
Parkhi, A., Pinnamraju, H., Power, A., Raje, N. M., and Sharma, P. Validating
datacenters at scale. In ACM SIGCOMM (SIGCOMM) (2019).
[26] Jin, X., Li, X., Zhang, H., Soul√©, R., Lee, J., Foster, N., Kim, C., and Stoica,
I. Netcache: Balancing key-value stores with fast in-network caching. In 26th
Symposium on Operating Systems Principles (SOSP) (2017).
[27] Jose, M., and Majumdar, R. Cause clue clauses: error localization using maxi-
mum satisfiability. In 32nd ACM SIGPLAN Conference on Programming Language
SIGCOMM ‚Äô21, August 23‚Äì27, 2021, Virtual Event, USA
Design and Implementation (PLDI) (2011).
[28] Kazemian, P., Varghese, G., and McKeown, N. Header space analysis: Static
checking for networks. In 9th USENIX Symposium on Networked Systems Design
and Implementation (NSDI) (2012).
[29] Khurshid, A., Zhou, X., Zhou, W., Caesar, M., and Godfrey, P. B. VeriFlow:
Verifying network-wide invariants in real time. In 10th USENIX Symposium on
Networked Systems Design and Implementation (NSDI) (2013).
[30] Liu, J., Hallahan, W. T., Schlesinger, C., Sharif, M., Lee, J., Soul√©, R., Wang,
H., Cascaval, C., McKeown, N., and Foster, N. p4v: Practical verification for
programmable data planes. In ACM SIGCOMM (SIGCOMM) (2018).
[31] Lopes, N. P., Bj√∏rner, N., Godefroid, P., Jayaraman, K., and Varghese, G.
Checking beliefs in dynamic networks. In 12th USENIX Symposium on Networked
System Design and Implementation (NSDI) (2015).
[32] McKeown, N., Talayco, D., Varghese, G., Lopes, N., Bj√∏rner, N., and Ry-
balchenko, A. Automatically verifying reachability and well-formedness in P4
networks. Tech. rep., 2016.
[33] Milner, R. An algebraic definition of simulation between programs. In Proceed-
ings of the 2nd International Joint Conference on Artificial Intelligence (San Fran-
cisco, CA, USA, 1971), IJCAI‚Äô71, Morgan Kaufmann Publishers Inc., p. 481‚Äì489.
[34] Necula, G. C. Translation validation for an optimizing compiler. In Proceedings
of the ACM SIGPLAN 2000 Conference on Programming Language Design and
Implementation (New York, NY, USA, 2000), PLDI ‚Äô00, Association for Computing
Machinery, p. 83‚Äì94.
[35] Neves, M. C., Freire, L., Filho, A. E. S., and Barcellos, M. P. Verification of P4
programs in feasible time using assertions. In 14th International Conference on
emerging Networking EXperiments and Technologies (CoNEXT) (2018).
[36] N√∂tzli, A., Khan, J., Fingerhut, A., Barrett, C. W., and Athanas, P. p4pktgen:
Automated test case generation for P4 programs. In Symposium on SDN Research
(SOSR) (2018).
[37] Panda, A., Argyraki, K., Sagiv, M., Schapira, M., and Shenker, S. New
directions for network verification. In LIPIcs-Leibniz International Proceedings in
Informatics (2015), vol. 32.
[38] Panda, A., Lahav, O., Argyraki, K. J., Sagiv, M., and Shenker, S. Verifying
reachability in networks with mutable datapaths. In 14th USENIX Symposium on
Networked Systems Design and Implementation (NSDI) (2017).
[39] Park, D. Concurrency and automata on infinite sequences. In Theoretical Com-
puter Science (Berlin, Heidelberg, 1981), P. Deussen, Ed., Springer Berlin Heidel-
berg, pp. 167‚Äì183.
[40] Pavlinovic, Z., King, T., and Wies, T. Finding minimum type error sources. In
Proceedings of ACM International Conference on Object Oriented Programming
Systems Languages & Applications (OOPSLA) (2014).
[41] Pnueli, A., Siegel, M., and Singerman, E. Translation validation. In Tools and
Algorithms for the Construction and Analysis of Systems (Berlin, Heidelberg, 1998),
B. Steffen, Ed., Springer Berlin Heidelberg, pp. 151‚Äì166.
[42] Quoitin, B., and Uhlig, S. Modeling the routing of an autonomous system with
[46] Soni, H., Rifai, M., Kumar, P., Doenges, R., and Foster, N. Composing dataplane
C-BGP. IEEE Network 19, 6 (2005), 12‚Äì19.
[43] Ruffy, F., Wang, T., and Sivaraman, A. Gauntlet: Finding bugs in compilers
for programmable packet processing. In 14th USENIX Symposium on Operating
Systems Design and Implementation (OSDI) (2020).
[44] Sahoo, S. K., Criswell, J., Geigle, C., and Adve, V. S. Using likely invariants for
automated software fault localization. In Architectural Support for Programming
Languages and Operating Systems, (ASPLOS) (2013).