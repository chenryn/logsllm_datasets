a′
θ′ = s′
0−→ s′
1−→ s′
2−→ s′
3 . . .
0 ֒
1 ֒
2 ֒
are equivalent, written θ ∼Xh,T θ′, iﬀ i = 0 . . . ai = a′
si ∼Xh,T (pci) s′
si and s′
i and
i, where pci denotes the program counters of
i (which in particular must coincide).
We say that a program p veriﬁes LL non-interference
(p), iﬀ for every two traces θ and
w.r.t. X 0
θ′ obtained by executing p from initial states s and s′:
h, written LLNIX 0
h
s ∼Xh,T (pc0) s′ =⇒ θ ∼Xh,T θ′
Note that the deﬁnition is parameterized by (Xh, T ).
LL non-interference accurately captures the intended goal
of constant-time: indeed, it ensures that programs have the
same control ﬂow and perform the same sequence of memory
accesses for every pair of executions starting from equivalent
initial states.
Proposition 2
(Language-level security).
h ⊢ p, then p is LL non-
If a program p is typable, i.e. X 0
interfering, i.e. LLNIX 0
(p).
h
Proposition 2 states that constant-time programs verify LL
non-interference with respect to the set of secrets X 0
It
h.
proves security against a weak, passive attacker, which can
observe the sequence of memory accesses and program coun-
ters during program execution, but cannot observe the pro-
gram memory, or interleave the program’s execution with
2We allow inﬁnite traces. Later, we introduce partial traces,
which are necessarily ﬁnite. Moreover, we assume that s0
and s′
0 are initial states, i.e. their program counter is set to
a distinguished entry point pc0.
execution of code of its choice. Although we do not es-
tablish a connection formally, this model is closely related
to a system-level attacker model, called the non-concurrent
attacker model. In this model, the attacker is a malicious
operating system oa that co-resides with the operating sys-
tem ov on which the victim program executes. The attacker
initially performs some computations, for instance to set the
cache in a state of his choice. Then, the hypervisor performs
a context switch and makes the victim operating system ac-
tive, so that the victim program executes uninterruptedly.
Upon termination of the victim program execution, the hy-
pervisor performs a context switch; the attacker becomes
active again, and tries to guess from its accumulated obser-
vations the secret material, e.g.
the secret cryptographic
keys, manipulated by the victim program.
4.2 System-level security
Our second soundness theorem establishes a non-interference
property for a much stronger model, called the concurrent
attacker model. The setting of this attacker model is sim-
ilar to the non-concurrent attacker model, and considers a
virtualization platform with a malicious operating system
oa and the victim operating system ov on which a victim
program p executes. However, this model assumes that the
attacker is both active and adapative. More explicitly, oa
and ov execute concurrently under a scheduler controlled by
oa, which decides at each step to execute a sequence of steps
of its choice, to force resolution of a pending hypercall, or
to switch context in order to give control to the victim ov.
Furthermore, the attacker oa can observe ﬁnely the struc-
ture of the cache during execution, but cannot read into
the memory of ov, or read in the cache the values of en-
tries belonging to ov. At each step, the attacker oa can use
its previous observations to decide how to proceed. This
model signiﬁcantly generalizes the non-concurrent attacker
model captured by language-level security and in particular
captures the class of access-driven attacks, in which the at-
tacker makes ﬁne-grained observations about the sequence
of cache hits and misses.
Formally, we model the attacker model on top of an oper-
ational semantics of the virtualization plaform. The seman-
tics is built on top of a rich memory model that accounts
for virtual, physical, and machine addresses, memory map-
pings, page tables, TLBs (translation lookaside buﬀers), and
VIPT (virtually indexed physically tagged) cache. Formally,
the semantics is modelled as a labelled transition system:
t ֒ b−→ t′
where t, t′ range over states and b is an action. Informally, a
labelled transition as above indicates that the execution of
the action b by o in an initial state t leads to a new state t′.
Figure 9 provides a representative set of actions considered,
including reads and writes, extending or restricting memory
mappings, (un)registering memory pages, context and mode
switching, and hypercalls. Each action b has an eﬀect eﬀ(b);
see Figure 9 for examples of eﬀects. As in the language-
level setting, the visible eﬀects of reads and writes record
the addresses that are read and written, but not their value.
Then, we model the attacker as a function A that takes as
input a partial trace and returns either a tag v if the attacker
lets the victim operating system perform the next step of
execution, or an action of its choice that it will execute in the
next step. Since the choice of the attacker can only depend
on its view of the system, we deﬁne an equivalence relation
∼ on partial traces, and require that A is compatible with ∼,
i.e. A(θ) = A(θ′) for every partial traces θ and θ′ such that
θ ∼ θ′. Equivalence between partial traces is deﬁned from
equivalence ∼ on states (itself deﬁned formally in Section 6):
bn−1−−−→ tn
b2−→ . . . ֒
b1−→ t2 ֒
b0−→ t1 ֒
θ = t0 ֒
b′
b′
b′
b′
θ′ = t′
0−→ t′
1−→ t′
−1−−−−→ t′
2−→ . . . ֒
1 ֒
0 ֒
2 ֒
n′
n′
are equivalent, written θ ∼ θ′, iﬀ n = n′, and for i = 0 . . . n−
1, ti ∼ t′
i, and if the active OS of ti is ov then eﬀ(bi) = eﬀ(b′
i)
else if the active OS of ti is oa then bi = b′
i.
Given an attacker A and a victim program p, one can de-
ﬁne the concurrent execution (A k p)[t] of A and p with ini-
tial state t; informally, (A k p)[t] is the system trace that
interleaves execution of p by ov and adversarially-chosen
code by oa according to the adversarially-chosen schedul-
ing policy—both captured in the deﬁnition of A. Formally,
(A k p)[t] is deﬁned recursively: given a partial trace θ for
the concurrent execution, one computes A(θ) to determine
whether the next action to be executed is the attacker action
A(θ), in case A(θ) 6= v, or the next step in the execution of
p, in case A(θ) = v.
Given a program p and a set of initial secrets X 0
h, we
deﬁne an equivalence relation ∼X 0
on system states; the
relation is implicitly parameterized by a mapping of MachIR
(or equivalently x86) states to platform states. We say that
a program p veriﬁes SL non-interference w.r.t. an initial
set of high variables X 0
h, written SLNIXh (p), iﬀ for every
attacker A and initial states t and t′:
h
p(n) = loadς (addr , ~r , r , n ′)
PointsTo(n, addr , ~r ) = Symb(S)
τ (~r ) = High =⇒ S ∈ Xs
Xs, Xh ⊢ n : τ ⇒ τ [r 7→ τ (~r ) ⊔ Xh(S)]
p(n) = storeς (addr , ~r , r , n ′)
PointsTo(n, addr , ~r ) = Symb(S)
τ (~r ) = High =⇒ S ∈ Xs
τ (~r ) ⊔ τ (r ) ⊑ Xh(S)
Xs, Xh ⊢ n : τ ⇒ τ
Figure 5: Information ﬂow rules for S-constant-time
p[n] = loadς (addr , ~r , r , n ′)
Jaddr K(ρ, ~r ) = vaddr
vaddr /∈ Xs
µ[vaddr]ς = v
(n, ρ, µ) ֒
read vaddr
−−−−−−−−→ (n ′, ρ[r 7→ v], µ)
p[n] = storeς (addr , ~r , r , n ′)
Jaddr K(ρ, ~r ) = vaddr
vaddr /∈ Xs
store(µ, ς, vaddr, ρ(r )) = µ′
write vaddr
−−−−−−−−−→ (n ′, ρ, µ′)
(n, ρ, µ) ֒
p[n] = loadς (addr , ~r , r , n ′)
Jaddr K(ρ, ~r ) = vaddr
vaddr ∈ Xs
µ[vaddr]ς = v
(n, ρ, µ) ֒
∅
−→ (n ′, ρ[r 7→ v], µ)
p[n] = storeς (addr , ~r , r , n ′)
Jaddr K(ρ, ~r ) = vaddr
vaddr ∈ Xs
store(µ, ς, vaddr, ρ(r )) = µ′
(n, ρ, µ) ֒
∅
−→ (n ′, ρ, µ′)
[t ∼X 0
h
t′ ∧ t ∼ t′] =⇒ (A k p)[t] ∼ (A k p)[t′]
Figure 6: Modiﬁed IR semantics (excerpts)
Proposition 3
(System-level security).
If If a program p is typable, i.e. X 0
interfering, i.e. SLNIX 0
(p).
h
h ⊢ p, then p is SL non-
Proposition 3 states that constant-time programs verify SL
non-interference with respect to the set of secrets X 0
It
h.
proves security against a strong, active attacker, which can
interleave the program’s execution with execution of code of
its choice.
5. EXTENSIONS TO S-CONSTANT-TIME
We now outline an extension of the results of the previ-
ous section that accounts for stealth memory.
Informally
stealth memory provides a distinguished set of stealth ad-
dresses such that reading or writing from these addresses has
no visible eﬀect. We reﬂect this property of stealth memory
by relaxing the type system to allow secret-dependent mem-
ory accesses on stealth addresses. The modiﬁed typing rules
now involve a set Xs of addresses that must be mapped to
stealth memory. The main typing rules are now given in
Figure 5. Note that there is no requirement that stealth
addresses are high; in practice, stealth addresses often store
public tables.
Definition 4
(S-constant-time). A program p is S-
constant-time with respect to a set of variables X 0
h and a set
of stealth addresses Xs, written Xs, X 0
h ⊢ p, if there exists
(Xh, T ) such that for every S ∈ X 0
h, Xh(S) = High and for
all nodes n and all its successors n′, there exists τ such that
Xs, Xh ⊢ n : T (n) ⇒ τ ∧ τ ⊑ T (n′)
where ⊑ is the natural lifting of ⊑ from L to to types.
We automatically infer Xs, Xh and T using Kildall’s algo-
rithm.
LL non-interference is extended to the setting of stealth
memory simply by considering a modiﬁed labelled opera-
tional semantics (see Figure 6) where accessing variables in
Xs has no visible eﬀect; the notion of state equivalence re-
denote the re-
mains unmodiﬁed. Below we let LLNIXs,X 0
sulting policy.
h
Proposition 5
(Language-level security).
If Xs, X 0
h ⊢ p then LLNIXs,X 0
(p).
h
Given a program p, a set of initial secrets X 0
h, and a set of
stealth addresses Xs, we deﬁne an equivalence relation ∼X 0
on system states; the relation is implicitly parameterized by
a mapping of MachIR (or equivalently x86) states to plat-
form states that map elements of Xs to stealth addresses.
We say that a program p veriﬁes SL non-interference w.r.t.
an initial set of high variables X 0
h and a set of stealth ad-
dresses Xs, written SLNIXs,X 0
(p), iﬀ for every attacker A
and initial states t and t′:
h
h
[t ∼X 0
h
t′ ∧ t ∼ t′] =⇒ (A k p)[t] ∼ (A k p)[t′]
Proposition 6
(System-level security).
If Xs, X 0
h ⊢ p then SLNIXs,X 0
(p).
h
6. FORMALIZATION
In this section, we outline the formalization of the proof of
system-level security for S-constant-time. We ﬁrst describe
our model of virtualization; then we state an isolation theo-
rem; ﬁnally, we sketch how SL non-interference follows.
Simpliﬁcations. We make several simpliﬁcations. The most
relevant ones are listed next:
i. we take an abstract view of
page tables as mappings; ii. we abstract away implementa-