### Aggregation and Specific Applications

Various tools aggregate data [41], while others implement algorithms tailored for specific applications, such as location data [35], genomic data [27, 47], mobility data [37], and browser error reports [26].

### Formal Verification of Differential Privacy

Several tools have been proposed to provide formal verification of differential privacy guarantees, employing a wide range of verification approaches. These include dynamic checking [24, 36], relational program logic [2, 6], relational refinement type systems [9], linear (dependent) type systems [29, 42], product programs [7], methods based on computing bisimulation families for probabilistic automata [50, 51], and methods based on counting variants of satisfiability modulo theories [28]. However, none of these techniques can handle advanced composition, interactive online algorithms, or privacy that depends on accuracy.

Barthe et al. [5] present a system for reasoning about computational differential privacy [39], a relaxation of differential privacy where the adversary is computationally bounded.

### Coupling in Probability Theory and Cryptography

Coupling is a well-established tool in probability theory but is less familiar in computer science. It was only recently that couplings were used in cryptography. According to Hoang and Rogaway [31], Mironov [38] first used this technique in his analysis of RC4. Despite considerable research on probabilistic bisimulation (introduced by Larsen and Skou [33]) and probabilistic relational program logics (introduced by Barthe et al. [4]), there are few applications of coupling in formal verification.

The connection between liftings and couplings was recently noted by Barthe et al. [8] and explored for differential privacy by Barthe et al. [10]. The latter uses a coupling argument to prove that the sparse vector algorithm is differentially private, which we also consider in this work. The additional challenges we face include integrating advanced composition to provide a better privacy bound, proving that the sparse vector is differentially private in the interactive model, and developing a logic that allows reasoning about the adversary. Moreover, Barthe et al. [10] do not provide methods to prove privacy using accuracy.

### Recent Work on Automated Verification

In recent promising work, Zhang and Kifer [52] designed a system to automatically verify differential privacy for examples where the privacy proof uses tools beyond the standard composition theorem, including the Sparse Vector technique. Their proof strategy is similar to couplings, but their system uses a combination of product programs and lightweight refinement types backed by novel type-inference techniques, rather than a relational program logic. Their system can also optimize the privacy cost, which we do not consider. While their work is highly automated, it is limited to pure, (ε, 0) differential privacy and cannot verify the algorithms we consider, where privacy follows from accuracy or the advanced composition theorem. Their techniques also seem limited to couplings from bijections, making it unclear how to prove privacy for examples that use more advanced couplings like the optimal subset coupling.

### Concluding Remarks

We have presented an extension of the logic apRHL [6] that can express three classes of privacy proofs beyond current state-of-the-art techniques: privacy depending on accuracy, privacy from advanced composition, and privacy for interactive algorithms. We have formalized a generalization of the adaptive Sparse Vector algorithm, known as Between Thresholds [13]. This and other possible generalizations of the sparse vector could yield interesting results in domains like geo-indistinguishability [1].

For future work, it would be interesting to explore generalizations of differential privacy, such as concentrated differential privacy [12, 18], which features a simple composition principle that internalizes the advanced composition principle of standard differential privacy. However, it is currently unclear whether the definition of concentrated differential privacy, which involves Rényi divergences, can be modeled using apRHL. Additionally, there is room for improving the expressivity of apRHL for differential privacy. One example combining accuracy and privacy is the large margin mechanism [15]. The privacy proof for this algorithm requires careful reasoning about the size of the support when applying pointwise equality and sophisticated facts about the accuracy of the Sparse Vector. This example seems beyond the reach of our current techniques but could be handled by generalizing the existing rules.

Finally, it would be beneficial to explore a tighter integration of accuracy and privacy proofs. Currently, we use two systems, aHL and apRHL, to verify privacy, which can lead to awkward proofs since the two logics can only interact in specific places (i.e., the up-to-bad rules). A combined version of the logics could allow for more natural proofs.