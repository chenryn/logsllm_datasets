contain similar vulnerabilities.  They work  well as long 
as  the  enemy  is  cooperative  and  does  not  exploit  the 
intrinsic  vulnerabilities  in  the  system.    For  very  large 
software systems, however, it is virtually impossible (and 
completely  unnecessary) 
to  know  and  remove  all 
vulnerabilities.  Access control is useful to build specific 
well  understood  defenses  around  specific  system 
resources such as files or system services.  That is all. 
The missing piece of the computer security puzzle is 
that  of  behavioral  control.    It  is  simply  not  possible  to 
build  systems  that  are  free  from  vulnerabilities.    That 
should  never  be  an  objective  of  software  development.  
Normal users of a system doe not exploit vulnerabilities.   
Only  the  deliberate  misuse  of  systems  will  exploit 
vulnerabilities.  This misuse can be detected and acted on 
immediately.      To  demonstrate  this  concept  we  have 
  The  DOA  methodology 
tested a web server that contains perhaps one of the most 
vulnerable  builds  of  RedHat  6.2  Linux  running  on  the 
Internet  which  we  have  invited  people  to  attack.    With 
our  technology  in  place  we  have  bee  able  to  identify 
these assaults and stop them before they can exploit the 
known vulnerabilities in this operating system.   
5. Watcher 
The  Disallowed  Operational  Anomaly  computer 
security solution is a technology based on our behavioral 
control  methodology. 
is 
embodied in the Watcher for Linux product.   The Linux 
operating system was selected as the first expression for 
this technology  for a number of reasons.  The principle 
reason  was that it  was a sufficiently large and complex 
piece  of  software.    While  the  core  DOA  technology  is 
applicable  to  any  piece  of  software,  the  Linux  kernel 
provided a good demonstration ground.  Implicit in this 
is the fact that the source was available so that it could be 
easily  instrumented.    We  chose  to  instrument  an  OS 
kernel  because  doing  so  imposed  a  high  reliability 
requirement on the instrumentation and profiling process 
we  developed.    When  instrumenting  other  applications, 
such  as  apache,  there  is  not  such  a  high  reliability 
requirement.  
The  Linux  kernel  source  was  altered  in  four  ways.  
First,  about  3300    instrumentation  points  were  inserted 
throughout 
the  kernel.  These 
instrumentation points, or sensors, are the source of the 
execution behavioral data that is stored into the baseline 
and measure.  The sensors placed in code are principally 
used  to  determine  whether  a  given  code  segment  has 
been  reached  [cf.  14].  Secondly,  a  few  elements  were 
added to the task_struct and  sk_buff  structures  in 
the kernel.  These were employed to identify the cause of 
the  behavior  observed  at  the  instrumentation  points.  
Thirdly,  code  was  added  to  start  the  profiling  process 
when  a  process  is  executed  or  an  IP  packet  is  handed 
from  the  device  driver  to  ip_rcv().  And  finally,  a 
quick check was added in ip_rcv() against a table of 
banned IP addresses.  This permits packets to be dropped 
from banned hosts very early. 
Software  execution  can  be  observed  through  a 
variety  of  techniques.    Some  techniques  are  more 
invasive  than  others,  source  instrumentation  vs.  library 
interposing,  for  example.    The  granularity  of  execution 
information  available  also  varies  depending  on  the 
technique  chosen.    Some  techniques  can  only  provide 
information  at  the  system  call  level  [cf.  6,  7,  11,  18], 
others can provide it at instruction level in the monitored 
program.    These  techniques  are  collectively  called 
"sensors" 
the 
methodologies  for  observing  information  from  running 
  Sensors  are 
in 
this  document. 
the 
source 
for 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:06:32 UTC from IEEE Xplore.  Restrictions apply. 
For 
software.    Sensors  provide  the  necessary  telemetry  to 
observe the execution behavior of a program.   
5.1. Behavioral tagging 
  Watching execution behavior through the interaction 
of  the  modules  in  M  only  tells  us  part  of  the  story.  
Knowing  what  behavior  or  operations  in  the  set  O  are 
occurring  leads  directly  to  the  question  of  attribution.  
The  problems  is  to  know  who  or  what  is  causing  the 
behavior  being  observed  right  now.    Several  sensor 
techniques  described  above  lend  themselves  to  tagging 
the  cause  of  the  behavior  to  the  behavioral  data.    This 
information  is  referred  to  as  "tag  data."    Common  tag 
data  from  our  work  with  the  Linux  kernel  and  library 
interposing on Solaris 7 are:  IP addresses, process IDs, 
TCP session IDs, socket file descriptors, user IDs, etc. 
Source code instrumentation and library interposing 
are  two  methods  we  have  used  that  support  tagging 
rather  easily.    Implementing  behavioral  tagging  using 
other  sensor 
techniques  may  be  more  difficult.  
Behavioral  analysis  becomes  a  powerful  security 
technique by making use of the behavioral tag data. 
5.2. Behavioral baseline 
Behavioral  data  can  be  accumulated  into  a  set 
representing a baseline of program behavior.  The type of 
behavior  captured  in  the  baseline  determines  its  utility.  
If  the  normal  behavior  of  a  program  is  stored  in  the 
baseline, then it can be used to detect abnormal program 
usage.    If  the  baseline  is  generated  by  testing  the 
program, then it can be used to detect untested behavior. 
For  this  paper,  our  interest  is  security  rather  than 
reliability;  we  focus  on  detecting  abnormal  program 
usage rather than untested behavior. 
Creating  a  baseline  for  normal  program  usage  is 
simple.   The data from the  sensors simply  needs to be 
stored.  However, for a complex program such as a web 
server or an operating  system, the baseline can become 
very  large.    A  program's  sensors  can  quite  easily 
produce,  on  average,  half  a  million  data  points  per 
minute.  At times of high system activity, we have seen 
an  instrumented  Linux  kernel  emit  over  50,000  data 
points each second.  Real-time analysis techniques were 
developed that could deal with the enormous volume of 
behavioral data. 
Obviously  the  entire  collection  of  behavioral  data 
cannot  be  used  in  real-time  for  analysis  without  very 
powerful  hardware.    A  compact  model  that  completely 
represents  the  baseline  will  be  required  for  both  speed 
and brevity.  This model must be constructed so that real-
time comparisons between it and the profiles emitted by 
the  running  program  can  be  performed.    To  solve  this 
problem, the sensors for each program store data into a 
a  program 
profile. The profile has a dump interval that specifies the 
amount of epoch to gather before the profile is emitted.  
The sensor in each program module is given a numerical 
value called a "click ID."  These start at 1 and count up 
incrementally.   
5.3. The profiles 
that  has  100  points  of 
instrumentation,  the  profile  is  an  array  of  100  integers.  
The click IDs are used as indexes into the profile array. 
When  the  path  of  execution  passes  over  a  sensor,  the 
value  at  profile[clickID]  is  incremented.    The 
profile is handed off for processing once a fixed number 
of epochs have been recorded into it.  Each profile can be 
viewed  as  a  point  in  a  100  dimensional  space.    The 
baseline then is a collection of points in 100 dimensional 
space.    For  real  programs,  there  are  usually  several 
hundred points of instrumentation.  In the  Linux  kernel 
we  instrumented,  there  are  just  over  3000  points  of 
instrumentation.  For the kernel's baseline, this means a 
collection of points in a 3000 dimensional space. 
By treating each profile as the coordinates of a point, 
we  have  made  the  behavior  visual,  and  reduced  the 
bandwidth  of  behavioral  data  emitted  by  the  program.  
While  working  in  the  3000  dimensional  space  is  easier 
from  a  bandwidth  point  of  view, 
too 
computationally intensive for real-time application.  We 
must reduce the dimensionality to a manageable level for 
this approach to work. 
5.4. Problem simplification 
By  looking  at  the  data  in  each  profile  and  the 
corresponding  instrumented  source  code  it  is  clear  that 
certain  modules  always  are  invoked  together.    Modules 
identified by click IDs of 7, 8, 13, and 74 may always be 
called  together  for  example.    Through  the  use  of  a 
statistical filter we are able to establish a mapping vector 
that  maps  each  actual  program  modules  to  a  virtual 
module in a much smaller profile.  This mapping process 
is shown graphically in Figure 1.  For the Linux kernel, 
the  virtual  profile  tends  to  have  between  80  and  120 
virtual  modules.    This  means  that  Watcher  is  not 
processing the profiles from the 3300 points of the Linux 
kernel  but 
the  set  of  much  small 
dimensionality,  the  virtual  profiles.    The  size  of  the 
virtual  profile  depends  on  the  variety  of  different  tasks 
performed  by  the  program.    In  general,  single  purpose 
programs  have  smaller  virtual  profiles  than  general 
purpose  programs  whose  behavior  repertoire  is  much 
larger.  The  underlying structure of the  virtual  modules 
will  depend  very  much  on  the  diversity  of  the  activity 
performed.    In  general  the  larger  the  set  of  operations 
is  processing 
it 
is  still 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:06:32 UTC from IEEE Xplore.  Restrictions apply. 
actually  selected  by  the  user  from  O,  the  greater  the 
number of virtual modules 
Actual Modules
Actual Modules
Actual Modules
Virtual Modules
Virtual Modules
Virtual Modules
Mapping
Mapping
Mapping
Vector
Vector
Vector
Figure 1.  Mapping Actual Module Counts to 
Virtual Modules 
the  behavior  from 
5.5. Creating a model of normal behavior 
Each virtual profile can be viewed as a point in an 
approximately 100 dimensional space.  By plotting these 
points  we  observe  something  rather  remarkable.    The 
points  form  natural  clusters.    The  complete  plot  of  the 
baseline represents all of the behavior from the baseline 
generation  period.    The  entire  cluster  can  then  be 
represented by its center and some radius, epsilon, about 
the center point. These are called centroids.  By storing 
the mapping vector and the list of centroids, we are able 
to  represent 
the  baseline  very 
succinctly.  
The size of the model is determined primarily by the 
program's  range  of  behavior,  rather  than  the  amount  of 
data  collected  in  the  baseline.    The  model  representing 
the behavior of the Linux IP stack is roughly 30k, even 
when  the  baseline  ranges  from  2  to  60  MB.    These 
centroids  allow  Watcher  to  represent  nominal  behavior 
very  succinctly  and  thus  enable  real-time  comparisons 
with  new behavior.  The actual centroids representation 
for a typical calibration of the Linux kernel is shown in 
the  Figure  2.    This  succinct  representation  of  normal 
behavior permits the rapid computation of distances  for 
new emerging virtual profiles.   
5.6. Behavioral Measurement  
The  behavioral  baseline  will  serve  as  a  reference 
point 
is  behaving 
abnormally.    Abnormality,  however,  is  not  a  simple 
binary  condition.    Rather,  it  is  a  continuous  function.  
What 
the 
identify  when  a  program 
technique  for  measuring 
is  needed 
to 
is 
abnormality  of  a  profile  when  compared  against  the 
baseline data. 
As each profile is emitted by the sensors, the virtual 
profile  for  it  is  a  point  in  the  same  space  as  the  model 
built  from  the  baseline.    The  distance  between  the  new 
point  and  the  closest  centroid  can  be  calculated.    This 
distance is a scalar measurement of the normality of the 
behavior stored in the profile.  If the distance is less than 
the  epsilon  radius  used  in  creating  the  model,  then  the 
behavior  is  normal.    If  the  distance  is  greater  than  the 
epsilon radius, then the distance answers the question of 
the  how  abnormal  the  behavior  was.    When  an  attack 
changes the behavior of the program, the module sensors 
emit a profile whose distance is greater than the epsilon.  
When testing attacks that would normally succeed, these 
attacks  impact  the  behavior  of  the  targeted  program 
dramatically.  They are very visible. 
The  distance  values  describe  the  normality  of  the 
current program behavior.  By measuring the behavior of 
the program we open the door for enforcement of normal 
behavior.    Ideally,  an  administrator  should  be  able  to 
force all important programs to execute in their normal, 
approved  manner.    When  an  attack  cannot  change  the 
behavior  of  the  targeted  program,  the  attack  fails. 
Stopping the attack as it starts is the goal of behavioral 
control.    Doing  this  requires  two  additional  steps, 