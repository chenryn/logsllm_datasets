No
No
Some No
Yes
No
A “Yes” in the Deployable column indicates that
the defense could be deployed to existing computers.
A “Yes” in the User (resp. Root) column indicates
that the defense would prevent an unprivileged (resp.
root) process from reprogramming the iSight. A
“Some” indicates that some reprogramming attempts
would be prevented but others allowed.
If the hardware must remain the same, then if the
ﬁrmware on the camera could be changed to disallow
future reprogramming, then the camera would be secure
against our attacks. Unfortunately, the “Firmware Load”
USB device request used to reprogram the 8051 core is
handled entirely by the EZ-USB device itself and cannot
be blocked or handled by the 8051 itself [13, Section 3.8].
7
USENIX Association  
23rd USENIX Security Symposium  343
Thus no matter how one programs the device’s ﬁrmware,
it can be reprogrammed by an attacker who can send basic
USB messages to the camera.
Apple deploys sandboxing technology called the App
Sandbox6 [4] which can prevent applications inside
the sandbox from accessing the iSight. Speciﬁcally,
the com.apple.security.device.camera enti-
tlement enables an application to capture still images
and video from cameras, including the internal iSight.
The com.apple.security.device.usb entitle-
ment enables applications to access USB devices.
Any App Sandbox–protected application lacking the
usb entitlement would be prohibited from reprogram-
ming the iSight and thus prohibited from disabling the
indicator LED. Although an application with the usb en-
titlement but lacking the camera entitlement would be
prohibited from using the high-level APIs for accessing
the camera, such as the QTKit API [3], it could easily
reprogram the camera to not appear as a USB video class
(UVC) device and instead transfer the frames of video
using a custom protocol.
The major drawback to using the App Sandbox to pro-
tect the camera is that applications need to opt into the
protection, something malware is unlikely to do. Worse,
the App Sandbox has, at times, been broken allowing
applications to escape from the restrictions [12, 38].
Perhaps the best way to defend against reprogramming
the iSight without changing the hardware is to modify
the operating system to prevent particular USB device
requests from being sent to the camera. We have built
such a defense structured as an OS X kernel extension
called iSightDefender.
When iSight is powered for the ﬁrst time, it enumer-
ates with vendor ID 0x05ac and product ID 0x8300
and is programmed with the legitimate ﬁrmware via the
AppleUSBVideoSupport kernel extension as described in
Sections 3.3 and 4.2. When it reenumerates with prod-
uct ID 0x8501 the kernel matches and loads the normal
drivers as well as iSightDefender.
I/O Kit kernel drivers are written in a subset of C++
and each USB device is represented by an object of class
IOUSBDevice which is responsible for communicat-
ing with the hardware by sending messages to objects in
lower layers of the USB stack. When iSightDefender is
started, it overwrites the C++ virtual method table of its
“provider” IOUSBDevice to point to the virtual method
table of a subclass of IOUSBDevice.7 The subclass
overrides the four DeviceRequest member functions.
The overridden implementations check if the device re-
quest is for the “Firmware Load” vendor-speciﬁc request
6Formerly codenamed Seatbelt.
7There seems to be no supported mechanism for interposing on USB
device requests. The authors appreciate the irony of using virtual table
hijacking — a common hacker technique — for defending against attack.
and, if so, log the attempt in the system log and block the
request.
iSightDefender is able to block all user space re-
programming attempts,8 including those mounted from
within a virtual machine. The latter requires some care as
the normal drivers that match against the IOUSBDevice
are unloaded and the virtual machine monitor’s own driver
is loaded in their place.
Using iSightDefender raises the bar for attackers by
requiring the attacker to have root privileges in order to
reprogram the iSight. In some sense, this is the strongest
possible software-based defense. Since malware running
as root would have the ability to replace or modify kernel
code, any defense implemented in the kernel can, theoret-
ically, be bypassed. Despite this limitation, we believe it
is a step in the right direction and encourage its use.
iSightDefender, and its source code, is freely avail-
able.9
8 Secure camera designs
When designing a secure camera, there are two main
considerations. First, for sensors such as cameras and
microphones, an indicator that the sensor is recording is
essential to prevent surreptitious recording. (Although
laptop microphones do not, in general, have indicators, it
is common for stand alone USB microphones; see [29]
for an example.) For the highest level of assurance that
the indicator cannot be bypassed, the indicator should be
controlled completely by hardware.
Second, as with any peripheral connected to the com-
puter, a vulnerability in the ﬁrmware running on the pe-
ripheral or the ability to reprogram the ﬁrmware enables
an attacker to leverage all of the capabilities of the periph-
eral. Section 2 contains numerous examples of this. The
virtual machine escape in Appendix A is another example
where an attacker leverages the USB connection and the
ability of the EZ-USB to mimic any USB device to the
host computer. Apple’s most recent FaceTime cameras
in its 2013 MacBook Air model eschews USB 2.0. In-
stead, the camera is connected to the host computer over
PCIe [35]. Vulnerabilities in the camera would potentially
enable an attacker to have DMA access to the host sys-
tem. This is a signiﬁcantly stronger capability than USB
access.
8.1 Secure indicators
Laptop cameras are typically constructed by pair-
the Mi-
ing a CMOS image-sensor-on-a-chip (e.g.,
8In fact, iSightDefender worked so well that one author spent more
than an hour attempting to diagnose (nonexistent) problems with iSeeYou
before noticing the tell-tale lines in the system log indicating that iSight-
Defender had been loaded by a computer restart and it was blocking
reprogramming requests.
9https://github.com/stevecheckoway/
iSightDefender
8
344  23rd USENIX Security Symposium 
USENIX Association
cron MT9V112 found in the iSight or the Toshiba
TCM8230MB(A)) with a separate microcontroller that
handles communication with the host computer (e.g., the
EZ-USB FX2LP found in the older MacBooks or the
Vimicro VC0358 [61] found in more recent MacBook
Pros [28]. There are, of course, many possible combi-
nations of image sensors and microcontrollers one could
use.
Image-sensors-on-a-chip tend to have a number of com-
mon features that can be used to build a secure indicator.
1. Separate power connection for CMOS sensor itself.
For example, VAAPIX on the MT9V112 powers
its pixel array and PVDD on the TCM8230MB(A)
powers its photo diode. A GPIO pin on the micro-
controller can be connected to both the LED driver
circuit and the CMOS sensor power supply circuit.
Whenever images are to be captured, the microcon-
troller sets its GPIO pin appropriately, power is sup-
plied to the sensor and the LED turns on.
2. #RESET pins. The LED driver circuit can be con-
nected to the #RESET pin and a GPIO pin on the
microcontroller. The microcontroller would hold the
image sensor in reset whenever it was not captur-
ing images. Compared to the power connection for
CMOS sensor, holding the entire sensor-on-a-chip
in reset means that before images could be captured,
the sensor would need to be reconﬁgured. Recon-
ﬁguring typically means sending a few dozen bytes
over an I2C or SPI bus. This introduces a slight
delay.
3. Output clocks and synchronization signals. Image
sensors typically latch outputs on one edge of an
output clock signal and image consumers are ex-
pected to read the data on the other edge of the
clock. In addition, there are signals used to indicate
which part of the image the latched data represents.
For example, the MT9V112 has FRAME_VALID
and LINE_VALID signals indicating when it’s out-
putting a frame or a line within the frame, respec-
tively, whereas the TCM8230MB(A) has VD and HD
for vertical and horizontal synchronization. These
pins can also be used to control the LED by adding
some simple hardware that drives the LED if it has
seen one of these signals change in the past few
milliseconds.
Depending on the speciﬁcs of the image sensor
output signal, a retriggerable, monostable multivi-
brator can be used to drive the LED as long as its
input changes sufﬁciently often. The multivibrator’s
output pulse width needs to be set appropriately such
that it is triggered frequently enough to continuously
drive the LED while images are being recorded.
Some care must be taken when using these output
signals. The exact meanings of the signals can fre-
quently be changed by conﬁguring the sensor. This
is analogous to the situation with the iSight where
we changed the meaning of the STANDBY signal.
An all-in-one design where the image sensor is inte-
grated with the microcontroller which communicates to
the host computer is likely to have fewer options for a
secure design. A dedicated output pin which could drive
an indicator LED would sufﬁce. However, hardware de-
signers are typically loathe to dedicate pins to speciﬁc
functions, instead a variety of functions tend to be multi-
plexed over a single pin.
It is likely that, even in this case, there would be a
separate power connection for the CMOS sensor. As with
the two-chip design above, the LED driver circuit and a
power supply circuit could be driven by a GPIO.
8.2 Secure ﬁrmware
Although using one of the secure indicator designs de-
scribed above will ensure the LED will turn on when
the camera turns on, it does nothing to protect against
reprogramming attacks.
For this, we make four concrete recommendations
which, taken together, can secure the ﬁrmware on the
camera. These apply more generally to any peripheral or
embedded system connected to a host computer.
1. Store the ﬁrmware in nonvolatile storage on the cam-
era module. Most commercial off-the-self (COTS)
microcontrollers contain some amount of nonvolatile
storage, such as ﬂash memory, to hold ﬁrmware.10
By programming the ﬁrmware at the factory, one
avoids the possibility that the legitimate ﬁrmware
will be replaced by an attacker on the host system
before being downloaded to the microcontroller.
Depending on the speciﬁc requirements of the
system, the factory programming could be the com-
plete ﬁrmware or a secure loader designed to load
cryptographically signed ﬁrmware from the host (see
below).
2. Use a microcontroller which can block unwanted
ﬁrmware reprogramming attempts. It is essential that
trusted code running on the microcontroller is able
to block reprogramming attempts for illegitimate
ﬁrmware.
3. Firmware updates, if necessary, should be crypto-
graphically signed and the signature veriﬁed before
applying the update. This requires both nonvolatile
storage for the code to verify the signature and a
microcontroller which can block reprogramming at-
tempts. Since microcontrollers are typically resource
constrained devices, choosing an appropriate signa-
ture scheme which can be implemented within the
10Microcontrollers without nonvolatile storage can be paired with
external nonvolatile storage, such as ﬂash or an EEPROM, to the same
effect.
9
USENIX Association  
23rd USENIX Security Symposium  345
constraints is important. Scheme selection is outside
the scope of this paper but we note that recent micro-
controllers have started to contain specialized crypto
instructions which can reduce code size and increase
efﬁciency. For example, Rohde et al. [53] use spe-
cialized AES instructions in some Atmel ATxmega
microcontrollers to implement the Merkle signature
scheme.
4. Require root/administrator privileges to send repro-
gramming requests. Strictly as a matter of defense
in depth, software running on the host system should
restrict reprogramming attempts. Thus, even if the
hardware and ﬁrmware defenses prove inadequate,
this added layer of protection can still defend against
some attacks.
Adding this sort of restriction typically involves a
device-speciﬁc kernel module (our iSightDefender
is an example). This may be more difﬁcult for plug
and play devices expected to conform to standard
protocols and interact with generic drivers such as
USB video class (UVC) or USB human interface
device (HID) class devices.
The inability of the EZ-USB to block reprogramming
attempts indicates that this widely-used microcontroller
is inappropriate for use in any system where security is a
consideration.
Secure physical user interface Orthogonal to secure
indicators and secure software is a secure physical user
interface. Most webcams in laptops are controlled by
software: Software tells the camera when to power up,
when to capture video, and when to power down. A
simple solution to the problem is to provide a physical
switch similar to the switches found on laptop network
adapters which controls power to the camera. A second
simple solution is to provide a lens cover which the user
must physically move aside to use the camera. This would
be similar in spirit to the original external iSight and
similar in form to the amusingly named iPatch [58].
9 Discussion
Although some webcams, such as the Logitech QuickCam
Pro 9000, come with an explicit “LED control” that can
disable the LED [64], such controls are not the norm and,
in fact, are a very bad idea from both a security and a
privacy stand point. Giving the user the ability to disable
a privacy feature is tantamount to giving malware the
same capability.
This work concerns the technical challenge of hard-
ware exploitation; however, we would be remiss if we
did not discuss the (frequently unpleasant) real-world
consequences of vulnerabilities in privacy technology.
A particularly unsavory element of the hacker culture,
“ratters,” install malware bundled with remote adminis-
tration tools (RATs) on victims’ computers. There are
several popular RATs, including Blackshades and Dark-
Comet, which come with a variety of features such as
keyloggers, the ability to install additional malware, and
the ability to record video and sound using the webcam.
Rats are often installed with the goal of spying on women.
RATs and the ratters who use them have recently come
under public scrutiny after a recent Miss Teen USA’s
webcam was used by ratter Jared Abrahams to capture
her naked images without her knowledge [15]. Abrahams
arrest and guilty plea came on the heels of an ars technica
exposé on ratters [1].
A commonly asked question on forums devoted to rat-
ting, such as the Hack Forums “Remote Administrator
Tools” forum, is how can one disable the webcam’s LED.
In one representative thread, forum user “Phisher Cat”
asks
So as all of you know, newer laptops have
a light when a laptop webcam turns on, and so