images. This may be due to a time restriction: the radiologist
may perform the diagnosis immediately after the scan has been
taken, or the malware may be in the viewing application and
operating in real-time. This may also be due to a connectivity
restriction: many PACS do not have a direct connection to the
Internet. Therefore, the attacker would need to infect the PACS
with a malware that can perform the tampering autonomously.
However, for cancer injection, one may argue that there are
simpler automated methods than using a GAN. For example,
the malware could simply paste a pre-saved cropped image
of cancer into a scan at a candidate location (found using steps
1 and 2 in Fig. 8). Therefore, to validate the use of a GAN, we
evaluated this splice attack as a baseline comparison.
The experiment was setup as follows. To create our set
of ‘pre-saved cancers’ we carefully cut out ten 32x32x32
cubes of real cancerous nodules from [54]. We then removed
the irrelevant background tissue by producing transparency
(alpha) channels using equation (1).
The evaluation dataset contained 20 scans in total: 10 FM
and 10 TM. To create a FM scan, we took a random healthy
scan and used steps 1 and 2 of Fig. 8 to select a candidate
injection location. We then pasted one of the pre-saved cancers
into the scan at that location using the transparency channel.
To create the FM scans, we randomly selected 10 sick patients
with exactly one nodule each.
To evaluate the baseline attack, we asked radiologist R2 to
analyze the 20 scans and determine which of the scans were
authentic (TM) and which were tampered (FM) –similar to
the open trial. This task took the radiologist approximately
two hours to perform.
In summary, R2 correctly labeled all of the tampered
scans as fake. The only error was that R2 mislabeled three
of the authentic scans as fake. These results indicate that the
baseline cancer injection attack cannot trick a radiologist, in
comparison to CT-GAN which succeeds nearly every time.
The reason the baseline attack failed to trick R2 is because
the process of automatically pasting cancer creates obvious
artifacts. This is because the pasted samples ignore the
surrounding anatomy and may contain inconsistent noise
patterns (textures). Fig. 15 illustrates some examples of
these abnormalities such as cut bronchi, inconsistent noise
patterns, and unaligned borders. CT-GAN does not produce
these artifacts because it uses in-painting which considers the
original content and surrounding anatomy.
7 Countermeasures
The tampering of DICOM medical ﬁles is a well-known
concern. In the section we provide a brief overview of
solutions for preventing and detecting this attack.
Figure 14: Conﬁdence in detecting attacks - Open Trial.
of R2 who noted some noise in the area of one removal (FB).
This may be attributed to “inattentional blindness,” where
one may miss an obvious event (artifacts) while engaged in a
different task (searching for large nodules). In [58], the authors
showed that this phenomenon also affects radiologists.
With regards to the injected cancers (FM), the consensus
among the radiologists was that one-third of the injections re-
quire an immediate surgery/biopsy, and that all of the injections
require follow-up treatments/referrals. When asked to rate the
overall malignancy of the FM patients, the radiologists said
that nearly all cases were signiﬁcantly malign and pose a risk
to the patient if left untreated. Fig. 12 summarizes radiologists’
ratings of the FM patients. One interesting observation is that
the malignancy rating increased with the experience of the
radiologist. Finally, we note that an attacker could increase the
overall malignancy of the injections if CT-GAN were trained
only on samples with high malignancy and/or a larger diameter.
6.3 Results: Open Trial
In Table 4 we present the radiologists’ attack detection perfor-
mance with knowledge of the attack. Fig. 13 summarizes these
results and provides the radiologists’ accuracy (ACC) and area
under the curve (AUC). An AUC of 1.0 indicates a perfect
binary classiﬁer, whereas an AUC of 0.5 indicates random
guessing. The results show that the radiologists could not
consistently tell the difference between real and fake cancers
or identify the locations of removed cancers.
With regards to the attack success rates (bottom of Fig. 11),
knowledge of the attack did not signiﬁcantly affect cancer
removal (90% from 95.8%). However, the success of the cancer
injection was affected (70% from 99.2%). Moreover, R2 also
picked up on a particular pattern which gave away several
instances. This is a promising result, since it indicates that a
portion of CT-GAN’s attacks can be mitigated by educating
radiologists. However, aside from low accuracy (61% for de-
tecting an injection and 39% for detecting a removal), there was
a signiﬁcant number of false positives. With a high likelihood
of making a mistake, a radiologist may choose not to report
abnormalities. This is also apparent from the low conﬁdence
scores which the radiologists gave decisions (see Fig. 14).
In summary, both radiologists and AI are highly susceptible
to CT-GAN’s image tampering attacks. Although knowledge
of the attack can help mitigate some cases of cancer injection,
USENIX Association
28th USENIX Security Symposium    473
low:1234high:5Q1AQ1BQ2AQ2BQ2CQ2D(Q1) Likel(cid:76)hood you labeled...(cid:3)(A)...a real cancer as fake?(B)...a fake cancer as real?(Q2) Confidence you identified all...(cid:3)(A)...fake cancers?(B)...real cancers?(C)...removed cancers?(D)...real cancers with diam.>9mm?ScaleRadiologistR1R2R3detection by (1) extracting a scan’s noise pattern using a
Wiener ﬁlter, then (2) applying a multi-resolution regression
ﬁlter on the noise, and then (3) executing an SVM and ELM
together via a Bayesian Sum Rule model. Many domain
speciﬁc methods exist for detecting images tampered by
GANs (e.g., images/videos of faces [62–64]). However, the
supervised approach in [65] is more suitable for detecting our
attack since it is domain generic.
Several approaches have been proposed for unsupervised
setting as well. These approaches attempt to detect anomalies
(inconsistencies) within the tampered images. To detect these
inconsistencies, researchers have considered JPEG blocks,
signal processing, and compression/resampling artifacts [66].
For example, in a recent work the authors trained a Siamese net-
work to predict the probability that a pair of patches from two
images have the same EXIF metadata (e.g., focal length and
shutter speed) [67]. In [67], the model is trained using a dataset
of real images only. In [68], the authors proposed ‘noiseprint’
which uses a Siamese network to extract the camera’s unique
noise pattern from an image (PRNU) to ﬁnd inconsistent
areas. In their evaluation, the authors show that they can
detect GAN-based inpainting. In [69], the authors proposed
three strategies for using PRNU-based tampering localization
techniques with multi-scale analysis. Using this method, the
authors were able to detect forgeries of all shapes and sizes.
While these countermeasures may apply to CT-GAN in
some cases, they do admit some caveats; namely, that (1)
medical scans are usually not compressed so compression
methods are irrelevant, (2) these methods were tested on
2D images and not 3D volumetric imagery, and (3) CT/MR
imaging systems produce very different noise patterns than
standard cameras. For example, we found that the PRNU
method in [69] does not work out-of-the-box on our tampered
CT scans. This is because the noise patterns of CT images are
altered by a radon transform used to construct the image. As
future work, we plan to research how these techniques can be
applied to detecting attacks such as CT-GAN.
8 Conclusion
In this paper we introduced the possibility of an attacker mod-
ifying 3D medical imagery using deep learning. We explained
the motivations for this attack, discussed the attack vectors
(demonstrating one of them), and presented a manipulation
framework (CT-GAN) which can be executed by a malware au-
tonomously. As a case study, we demonstrated how an attacker
can use this approach to inject or remove lung cancer from full
resolution 3D CT scans using free medical imagery from the
Internet. We also evaluated the attack and found that CT-GAN
can fool both humans and machines: radiologists and state-
of-the-art AI. This paper also demonstrates how we should
be wary of closed world assumptions: both human experts and
advanced AI can be fooled if they fully trust their observations.
Figure 15: An illustration showing artifacts which can occur
when using an unsupervised splice attack instead of CT-GAN.
Only the middle slice is shown.
7.1 Prevention
To mitigate this threat, administrators should secure both
the data-in-motion (DiM) and the data-at-rest (DaR). To
secure data-in-motion, admins should enable encryption
between the hosts in their PACS network using proper SSL
certiﬁcates. This may seem trivial, but after discovering this
ﬂaw in the hospital we pen-tested, we turned to the PACS
software provider for comment. The company, with over 2000
installations worldwide, conﬁrmed to us that their hospitals do
not enable encryption in their PACS because “it is not common
practice”. We were also told that some of the PACS don’t
support encryption at all.16 To secure the DaR, servers and
anti-virus software on modality and radiologist workstations
should be kept up to date, and admins should also limit the
exposure which their PACS server has to the Internet.
7.2 Detection
The best way to detect this attack is to have the scanner sign
each scan with a digital signature. The DICOM image ﬁle
standard already allows users to store signatures within the
ﬁle’s data structure [59, 60]. However, although some PACS
software providers offer this feature, we have not seen it in
use within a PACS. If enabled, admins should check that valid
certiﬁcates are being used and that the radiologists’ viewing
applications are indeed verifying the signatures.
Another method for detecting this attack is digital wa-
termarking (DW). A DW is a hidden signal embedded into
an image such that tampering corrupts the signal and thus
indicates a loss of integrity. For medical images, this subject
has been researched in depth [20] and can provide a means for
localizing changes in a tampered image. However, we did not
ﬁnd any medical devices or products which implement DW
techniques. This may be due to the fact that they add noise to
images which may harm the medical analysis.
Tampered images can also be detected with machine
learning. In the supervised setting (where models are trained
on examples of tampered images) the authors in [61] propose
16See [52] for further comments.
474    28th USENIX Security Symposium
USENIX Association
References
[1] P. I, W. LR, et al. Health care spending in the united
JAMA,
states and other high-income countries.
319(10):1024–1039, 2018.
[2] J. R. Haaga. CT and MRI of the Whole Body. No. v. 1 in
CT and MRI of the Whole Body. Mosby/Elsevier, 2008.
ISBN 9780323053754.
[3] H. I. News. The biggest healthcare data breaches of 2018
(so far).
https://www.healthcareitnews.com/
projects/biggest-healthcare-data-breaches-
2018-so-far, 2019.
[4] T. George.
Feeling the pulse of cyber secu-
rity in healthcare, securityweek.com.
https:
//www.securityweek.com/feeling-pulse-cyber-
security-healthcare, 2018.
[5] I. Institute. Cybersecurity in the healthcare industry.
https://resources.infosecinstitute.com/
cybersecurity-in-the-healthcare-industry,
2016.
[6] L. Coventry and D. Branley. Cybersecurity in healthcare:
A narrative review of trends, threats and ways forward.
Maturitas, 113:48 – 52, 2018. ISSN 0378-5122.
[7] M. S. Jalali and J. P. Kaiser. Cybersecurity in hospitals:
A systematic, organizational perspective. Journal of
medical Internet research, 20(5), 2018.
[8] C. Beek. Mcafee researchers ﬁnd poor security
exposes medical data to cybercriminals, mcafee blogs.
https://securingtomorrow.mcafee.com/other-
blogs/mcafee-labs/mcafee-researchers-find-
poor-security-exposes-medical-data-to-
cybercriminals/, 2018.
[9] H. Huang. PACS-Based Multimedia Imaging Informat-
ics: Basic Principles and Applications. Wiley, 2019.
ISBN 9781118795736.
[10] Verizon. Protected health information data breach report.
white paper, 2018.
[11] F. Bray, J. Ferlay, et al.
Global cancer statistics
2018: Globocan estimates of incidence and mortality
worldwide for 36 cancers in 185 countries. CA: a cancer
journal for clinicians, 68(6):394–424, 2018.
[12] X. Wu, K. Xu, et al. A survey of image synthesis and
editing with generative adversarial networks. Tsinghua
Science and Technology, 22(6):660–674, 2017.
[13] I. Goodfellow, J. Pouget-Abadie, et al. Generative
In Advances in neural information
adversarial nets.
processing systems, pp. 2672–2680. 2014.
[14] W. Hu and Y. Tan. Generating adversarial malware
examples for black-box attacks based on gan. arXiv
preprint arXiv:1702.05983, 2017.
[15] M. Rigaki and S. Garcia. Bringing a gan to a knife-ﬁght:
Adapting malware communication to avoid detection.
In 2018 IEEE Security and Privacy Workshops (SPW),
pp. 70–75. IEEE, 2018.
[16] R. Chesney and D. K. Citron. Deep fakes: A looming
challenge for privacy, democracy, and national security.
U of Texas Law, Public Law Research Paper No. 692; U
of Maryland Legal Studies Research Paper No. 2018-21,
2018.
[17] P. Isola, J.-Y. Zhu, et al. Image-to-image translation with
conditional adversarial networks. arXiv preprint, 2017.
[18] T. Seals. Rsa conference 2019: Ultrasound hacked in
https://threatpost.com/