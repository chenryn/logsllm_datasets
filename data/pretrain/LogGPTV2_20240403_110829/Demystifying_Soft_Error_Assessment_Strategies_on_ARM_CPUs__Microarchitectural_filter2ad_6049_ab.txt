often be considered as unfeasible.
In this work we combine and compare the reliability eval-
uation performed using beam experiments and with statistical
fault injection on top of microarchitecture-level models. We
discuss at which level the pre-silicon reliability evaluation
performed on microarchitectural models provides similar data
when compared with beam experiments on real hardware.
Assuming fault injection and beam experiments are per-
formed on exactly the same hardware, software, and OS
conﬁgurations, there are still several reasons for beam and fault
injection FIT rates not to be identical and for neither of them
to be perfectly accurate if compared to the real device FIT
rate. Figure 1 visualizes the different sources of uncertainties
between the real FIT rate and the FIT rates measured with
beam experiments or predicted with fault injection and shows
the relative position of the reported FIT rates from each
approach.
As some device structures cannot be modeled (e.g. logic-
related latches), fault injection is likely to underestimate the
device FIT rate. Additionally, a simpliﬁed fault model (typi-
cally a single bit ﬂip model) is normally used for injections,
which add additional uncertainty to the predicted error rates
because in actual hardware implemented in recent technologies
multiple bits may be ﬂipped by a single particle strike.
When the real hardware is exposed to accelerated neutron
ﬂux, the whole chip is irradiated and a much more realistic
behavior is modeled as neutrons hit the CPU chip. However,
some resources/interfaces in the test board which are not part
of the evaluated CPU are exposed to the beam and can be
corrupted causing unresponsiveness in the system. Such cases
can lead to an overestimation of the device under test FIT
rate estimation through beam testing. In addition, the particles
counts in the irradiation facility is not as precise as fault
injection. This could lead to experimental errors that add
uncertainty to beam results.
Finally, the real FIT rate of a device in the ﬁeld depends
on both the device sensitivity and the particle ﬂux at which it
is going to be exposed. Besides uncertainties in the sensitivity
evaluations, also the particle ﬂux is subject
to signiﬁcant
28
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:16:22 UTC from IEEE Xplore.  Restrictions apply. 
TABLE II
SUMMARY OF SETUP ATTRIBUTES.
Property
Microarchitecture
Platform
CPU cores
L1 Cache
L2 Cache
Beam
Cortex-A9
Zynq 7000
1∗
Gem5
Cortex-A9∗
VExpress
1
32 KB 4-way
512 KB 8-way
32 KB 4-way
512 KB 8-way
Kernel version
3.14
3.13
Fig. 1. Our motivation in comparing the different reliability evaluation
methodologies and reasons for over- and under-estimations.
variations depending on the environmental conditions. JEDEC
suggests to uses 13n/cm2/h as ﬂux at NYC [18], but it also
states that the ﬂux is dynamic and could signiﬁcantly change
over time. It is worth noting that ﬁeld tests (i.e. exposing a high
number of devices to the natural radiation) could potentially be
more accurate than beam experiments and fault injection [31],
[32]. However, a huge amount of devices and long time of
exposure is required to gather a statistically signiﬁcant amount
of data, making ﬁeld tests mostly unpractical.
In Section VI, as one of the main insights of our paper, we
discuss the differences between the FIT rate we measure with
beam experiments and microarchitectural fault injection and
link the discussion to the abstract concept shown in Figure 1.
III. RELATED WORK
In this section we present related works in the ﬁeld of
reliability evaluation of modern devices through fault injection
and accelerated beam experiments.
Particle accelerators have been used for many years to mea-
sure and study the reliability of devices and applications [20],
[33]. Computing devices reliability has a strong tradition, mo-
tivated mainly by their use in safety-critical applications [9],
[34], [35].
ARM Cortex-A9 processors have been exposed to acceler-
ated particles beam and have been subjects and fault injection
in previous studies. In [36], [37], [38], and [39] authors
present beam experimental data on embedded ARM Cortex-
A9, propose hardening solutions, and discuss the impact of the
presence of an operating system in the application and device
reliability. [40] and [41] present results on architecture-level
fault injection of the processor core, while [42] includes a
microarchitecture-level fault injection on A9. [24] presents a
comparative reliability evaluation between microarchitecture
and RTL fault injection, for baremetal workloads running on
Cortex-A9, while [43], [44] also includes results of RTL fault
injection on ARM CPU cores. Apart from ARM processors,
fault injection on RTL was also used in [23], [28], [45].
Characterization of a full system using fault injection in ar-
chitecture level is presented in [46]–[51] with some works only
focusing on the vulnerability of the operating system. Some
high-level fault injection tools have also been developed in
the past that offer generic and cross-ISA software assessment
[52], [53]. Microarchitecture level fault injection has been
used in various studies [13], [54], [55] for assessing reliability
on a hardware component basis, but also for capturing the
performance deviation cause by the presence of faults in
speculative components [56], [57]. There are also studies [58]–
[63] that spread their focus beyond a single abstraction layer
and aim to exploit the beneﬁts of multiple abstraction layers to
either accelerate the evaluation process, or deliver cross-layer
reliability evaluation.
Some preliminary studies have proposed a comparison or
combination of different reliability evaluation techniques [23],
[28], [29], [39], [64], [65]. None of these works quantiﬁes the
accuracy of the fault injection reliability evaluation against
the physical end product, considering the full system stack.
This is the ﬁrst paper that both compare and combine beam
experiments and microarchitectural fault injection.
IV. METHODOLOGY
In this section we present the evaluation methodology for
the comprehensive comparative study of this paper. We ﬁrst
describe the ARM CPU and the selected benchmarks we
execute on it. Then, we present the microarchitectural fault
injection framework and the neutron beam experiment setup.
A. Benchmarks and Devices
Our study is performed on an ARM®CortexTM-A9 archi-
tecture embedded in a Xilinx ZynqTM-7000 AP System on
Chip (SoC) implemented in a 28 nm CMOS technology and
simulated in Gem5 (details in Section IV-C). The hardware
device has two ARM cores operating at a maximum frequency
of 667 MHz. Each core has a 32 KB 4-way set-associative
instruction and data caches and a 512 KB 8-way set-associative
Level 2 cache, which is shared between the cores [67]. We
tuned the Gem5 model to resemble the physically available
one and we have disabled the second core of the SoC in order
to make the two evaluation setups as close as possible. The
Linux kernel version we have tested on the Zynq board is
3.14 [68] while for Gem5 the used version is 3.13. These
were the closest kernel versions that have been ported on
the two platforms and were selected in order to minimize the
operative system differences between the two setups. Table II
presents the main characteristics of the two setups. Asterisks
indicate two differences. First, Gem5 Resembles Cortex-A9
conﬁguration, but the pipeline has some design differences
and, second, in the Zynq the second core is still physically
present, although disabled.
29
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:16:22 UTC from IEEE Xplore.  Restrictions apply. 
INPUT USED AND BENCHMARKS CHARACTERISTICS AS DESCRIBED IN [66].
TABLE III
BENCHMARK
CRC32
Dijkstra
FFT
Jpeg C
Jpeg D
MatMul
Qsort
Rijndael E
Rijndael D
StringSearch
Susan C
Susan E
Susan S
INPUT
26.6 MB ﬁle
100x100 Integer Adjacency matrix
a single ﬂoating point array with 32768 elements
512x512 PPM image with size of 786.5 KB
512x512 PPM image with size of 786.5 KB
128x128 Single precision ﬂoating point
a list of 50K doubles
3.2 MB ﬁle
3.2 MB ﬁle
76x95 pixels, 7.3 KB
76x95 pixels, 7.3 KB
76x95 pixels, 7.3 KB
1332 words to search in 1332 sentences (1 word per sentence) Memory intensive and Control intensive
CHARACTERISTICS
CPU intensive
Control intensive, memory intensive
Memory intensive and Control intensive
Memory intensive
CPU intensive
CPU intensive
Memory intensive
Memory intensive
Memory intensive
CPU intensive
CPU intensive
CPU intensive
To have a broad analysis and avoid the bias of results on
speciﬁc applications, we have chosen benchmarks with dif-
ferent computational characteristics. The applications chosen
are part of mibench [66] testbench and are listed below. Table
III shows the input used and some characteristics for each
benchmark:
• CRC32: It calculates the corresponding 32-bit Cyclic
Redundancy check (CRC) of a given ﬁle input. CRC is
widely used in networks and storage devices in order to
detect unwanted changes in the data.
• Dijkstra: This benchmark calculates the shortest path be-
tween 2 nodes using a adjacency matrix of size 100x100.
100 paths are calculated during each execution.
• FFT: It performs the Fast Fourier Transform (FFT) on a
wave on a array of 32,768 ﬂoating point data. The FFT
is widely used in digital signal processing.
• Jpeg C (Encode) and Jpeg D (Decode): These bench-
marks convert one PPM image to jpeg format (Jpeg C)
and vice versa (Jpeg D). The input ﬁle is the same
512x512 pixels image in two different formats: PPM for
Jpeg C and jpeg for Jpeg D.
• MatMul: It multiplies two 128x128 matrices. This al-
gorithm is used in image processing and Convolutional
Neural Networks (CNN).
• Qsort: It sorts an array using the quick-sort algorithm im-
plemented in the GNU C standard library. This algorithm
was chosen in order to represent data sorting operations.
• Rijndael E (Encryption) and Rijndael D (Decryption):
These two benchmarks use the Rijndael algorithm as
deﬁned in the Advanced Encryption Standard (AES).
One encrypts an input ﬁle (E) and the other decrypts an
encrypted input ﬁle (D).
• StringSearch: It searches a word in a sentence.
• Susan C: It uses the corner SUSAN algorithm in order
to ﬁnd the corners of the features. This algorithm is used
to detect corners in features in an image.
• Susan E: It uses the edge SUSAN algorithm in order to
ﬁnd the edges of the features.
• Susan S: It uses the SUSAN algorithm in order to remove
noise and preserve the image structure.
It is worth to mention that we use the exact same input
vector, i.e., the same values and same size for each correspond-
ing benchmark in both beam experiments and fault injection.
Further discussion is presented in Section IV-D.
B. Neutron Beam Experiments
Neutron beam experiments are one of the most precise ways
to evaluate devices and applications error rates. Faults are
induced with realistic probabilities and, as the whole chip is
irradiated, faults are not restricted to a subset of accessible
resources like for most software fault-injection frameworks.
Our radiation experiments were performed at the LANSCE
facility of the Los Alamos National Laboratory (LANL) in
Los Alamos, NM.
Figure 2 shows part of our setup at LANSCE. We irradiate
four Xilinx Zedboards with a 2 × 2 inches beam spot, which
is sufﬁcient to irradiate the chip uniformly without affecting
the onboard DDR. This means that data in the DDR is not
expected to be affected by radiation.
During the experiment, the ARM output is compared with
a golden reference which contains the expected output (pre-
computed in a fault free environment). Any mismatch between
the experimental and expected output is marked as an SDC and
logged for later analysis. Additionally, during the execution the
ARM sends an ”Alive” message to a host PC to indicate the
correct function of the application. If after a given period of
time no message is received, an attempt is made to contact
to the board and restart the application. If the attempt is
is logged as an Application Crash
successful,
(Linux is still running and responding). If no connection with
the board can be establish, the event is logged as a System
Crash, as the operating system has crashed.
the event
LANSCE provides a neutron beam suitable to mimic the at-
mospheric neutron effects in electronic devices. The available
neutron ﬂux was about 3.5×105n/(cm2/s), about 8 orders of
magnitude higher than the terrestrial ﬂux (13n/(cm2 × h) at
sea level [18]). Our experiment ran for about 260 effective
beam hours (i.e., not considering setup,
initialization, and
recover from crash times), which, when scaled to the natural
exposure, account for more than 2.9 million years. Since
the terrestrial neutron ﬂux is low, in a realistic application
30
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:16:22 UTC from IEEE Xplore.  Restrictions apply. 
MIN, MAX, AND AVERAGE ERROR MARGIN FOR EACH COMPONENT
ACROSS WORKLOADS FOR A GIVEN FAULT SAMPLE OF 1,000 FAULTS.
TABLE IV
Component
Register File
I$ Cache
D$ Cache
L2 Cache
DTLB
ITLB
Min Err Max Err
3.3 %
2.2 %
3.7 %
2.6 %
2.4 %
4.0 %