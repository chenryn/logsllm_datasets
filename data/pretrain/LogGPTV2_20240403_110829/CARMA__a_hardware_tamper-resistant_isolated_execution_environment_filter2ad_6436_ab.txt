device. We call this device the Trusted Device, or TD. Before
passing control to the SEC module, the SEEL ﬁrst attests to
the TD that the SEEL has been loaded correctly, and sets up
a secure channel between the SEEL and the TD.
We next describe each step of instantiating, using, and
cleaning up a CARMA session.
Secure Environment Setup. The SEEL and SEC module
are ﬁrst loaded into the CPU, and the SEEL begins exe-
cuting. The SEEL conﬁgures the CPU into Cache-as-RAM
mode, ensuring that subsequent execution will be entirely
within cache and not interact with untrusted RAM.
Attesting to Secure Setup. Since the Secure Environment
Setup was necessarily initiated by untrusted code, and the
SEEL and SEC were loaded across untrusted buses, we
1 Typically EEPROM or Flash memory.
2 Most BIOSes today are byte-addressable as RAM, so execution can pro-
ceed from power-up without the DRAM controller being initialized.
must securely attest the loaded code to the TD. Since the
CPU has no on-board hardware root of trust (e.g., the TPM
is external, across an untrusted bus), we use a SoftWare-
Only Root of Trust [3, 5, 7, 8, 16, 17, 19]. We extend the
Pioneer [15] system, which is an implementation of SWORT
on x86-class systems. In our setting, the TD is aware of the
expected memory content of the cache and sends a challenge
to the SEEL. The checksum function in the SEEL includes
execution state of the CAR environment in the checksum
computation. Any deviation from the expected loaded code
or CPU state will give an incorrect checksum result. As with
all SWORT checksum functions, the function is designed
such that a modiﬁed checksum function that attempts to “lie”
will take measurably longer to compute. Consequently, a
correct checksum received before a threshold time indicates
to the TD: the secure CAR environment is correctly set up,
SEEL and SEC code integrity, and SEEL execution integrity.
The typical attack against SWORT is to use a faster pro-
cessor than the target device to calculate the correct check-
sum value. This attack is partially prevented by the SWORT
function being designed such that no other local component
can compute it as quickly as the CPU, exploiting speciﬁc
execution capabilities of the CPU. Although a local graphics
card can also execute at high speed with high parallelism,
the sequential nature of the SWORT checksum function and
the optimized implementation for the target CPU precludes
such an attack.
Two stronger assumptions we must make are that the at-
tacker does not use a faster remote system to compute the
checksum, and that the attacker is unable to undetectably
overclock the CPU or replace it with a faster model such
that the “lying” checksum runs as fast as the correct check-
sum function. We could remove the former assumption us-
ing the Viper system proposed by Li et al., which uses sev-
eral short checksum functions instead of a single checksum
function, such that the latency to communicate with a re-
mote faster system would be greater than any computational
advantage [8].
Secure Channel Setup. We adapt the Software-based At-
testation for Key Establishment (SAKE) protocol [14] to
set up a shared secret key between our secure CAR exe-
cution environment and the TD. This shared secret key is
used to derive an encryption and authentication key to pro-
vide secrecy and integrity for all communication. The main
challenge in this context is to prevent a Man-In-The-Middle
(MITM) attack, as the CPU and TD cannot authenticate each
other. The idea that SAKE proposed is to use the checksum
of software-based attestation as a short-lived shared secret
to bootstrap an authentic public key. Since SAKE was de-
signed for sensor nodes, we can take advantage of the pow-
erful CPU to simplify the design. Speciﬁcally, the protocol
in CARMA (Figure 3) performs a Difﬁe-Hellman key ex-
change, where the CPU uses the checksum z computed via
software-based attestation to compute a MAC of its public
T D :
T D → CP U :
CP U :
CP U → T D :
T D :
CP U :
a R← {0, 1}(cid:96)
c = ga mod p
T1 = Current time
(cid:104)c(cid:105)
z = checksum over SEEL and SEC
b R← {0, 1}(cid:96)
d = gb mod p
(cid:104)d, MACz(d)(cid:105)
T2 = Current time
Verify (T2 − T1) ≤ Time thresh
verify MAC based on correct z
KT D,CP U = da mod p
KT D,CP U = cb mod p
Figure 3. CARMA Secure Channel Setup uses a slightly
modiﬁed SWORT attestation protocol for key establish-
ment [14]. A private Difﬁe-Hellman key of length (cid:96) is chosen
at random for each protocol execution.
key d. Since no other entity can compute z as quickly as the
CPU, z represents a short-lived shared secret.
However, numerous challenges still exist that need to be
addressed.
(1) Authentication of the CPU by the TD is still required;
how can the TD ensure that indeed the result originates from
the local CPU? In SAKE, the checksum computation in-
cludes a unique local value, such as a processor version num-
ber or silicon ID. Since we do not have either reliably avail-
able on current x86 CPUs, we need to resort to a different ap-
proach. We rely on the assumption already discussed in the
secure setup attestation step: that the attacker has no other
device available that can compute the checksum as fast as
the CPU and with sufﬁciently low communication latency.
(2) An adversary could steal the private key before attes-
tation starts, as it can inspect the state of the random number
generator within the CAR environment, thus predicting the
value of b. To thwart this attack, we make use of a hardware
random number generator within the CPU such as the Intel
Digital Random Number Generator (DRNG) [21]. Without
built-in random numbers, it may be possible to leverage un-
predictability of performance counters as entropy sources.
(3) An adversary would move the expensive computation
of gb before the checksum computation, thus saving time
and achieving faster checksum computation. This attack can
be defeated by performing the checksum computation long
enough such that the time overhead of the fastest adversarial
function would still be above the time threshold.
Secure SEC Execution. Once the secure channel is es-
tablished, the SEEL receives inputs to SEC from TD, exe-
cutes SEC (offering launch point integrity), and returns SEC
outputs to TD. Since the attestation function offers code in-
tegrity and SEEL execution integrity, we obtain the launch
point integrity as the SEC starts execution at the correct lo-
cation with the correct executable. Since the checksum func-
tion also veriﬁably turns off all interrupts and exceptions, the
execution cannot be disrupted by malware.
Secure Return. After execution, SEEL erases all Cache-
as-RAM execution state and resumes normal execution.
Implementation and Evaluation
3.
We have developed a proof-of-concept implementation that
demonstrates the feasibility of realizing our CARMA ap-
proach (§2.2) on a commodity PC platform. Our current pro-
totype implements the secure execution setup, secure SEC
execution and secure Return components of our execution
model (§2.2). We note that the remaining execution model
components, the secure setup attestation and secure channel
setup, have existing stand-alone implementations [14, 15].
Adapting them to our prototype should be relatively straight-
forward based on our design. The CARMA prototype cur-
rently runs on a AMD Family 10h CPU and is implemented
as a custom BIOS. We used a Tyan S2912e motherboard and
coreboot3 as our development platform. We now proceed to
describe the details of our SEEL and the SEC implementa-
tions.
The SEEL runs on the Boot-strap Processor (BSP) and
sets up the L2 cache as general purpose memory (for code
and data read/writes). It ﬁrst locks the CPU cache subsystem
by preventing write-backs and other out-of-order CPU oper-
ations (e.g., branch prediction and speculative loads). The
SEEL then sets up CPU memory addressing and caching
policies to address the L2 cache and maps the SEC code and
data into the cache, and transfers control to the SEC code
entry-point. When this happens, the SEC code is executing
entirely within the CPU cache along with associated data.
Our Secure Executable Code (SEC) is a simple applica-
tion that prints a ”Hello World!” string through the serial
port by employing the legacy in/out I/O instructions to
communicate with the UART. The SEC contains a SEEL
epilogue code, that it transfers control to, once the SEC is
done with its processing.
The SEEL epilogue code tears down the CAR environ-
ment in a secure fashion and allows normal program ex-
ecution. The SEEL epilogue code ﬁrst disables the CPU
cache, clears contents of MTRRs and programs the L2
cache-subsystem to the state at reset (i.e., no code caching).
CPU cache-invalidation, out-of-order execution primitives
(branch-prediction, speculative loads and stores) and self-
modifying code logic are then enabled before enabling the
CPU cache and resuming normal execution.
We conﬁrmed the instantiation of the cache-as-RAM
(CAR) environment by removing the DRAM modules from
our prototype system and by setting up a performance
counter to keep track of L2 cache evictions while runnning
our SEC code. For a successful instantiation of the CAR en-
vironment, there must be no L2 cache evictions since the L2
3 http://www.coreboot.org/
[12] T. M¨uller, A. Dewald, and F. Freiling. TRESOR runs encryp-
tion securely outside RAM. In Proceedings of USENIX Secu-
rity Symposium, 2011.
[13] Rochester Electronics. Counterfeit electronic components in
the U.S. supply chain. The Ofﬁce of Technology Evaluation,
U.S. Dept. of Commerce, 2010.
[14] A. Seshadri, M. Luk, and A. Perrig. SAKE: Software attesta-
tion for key establishment in sensor networks. In Proceedings
of International Conference on Distributed Computing in Sen-
sor Systems (DCOSS), June 2008.
[15] A. Seshadri, M. Luk, E. Shi, A. Perrig, L. VanDoorn, and
P. Khosla. Pioneer: Verifying integrity and guaranteeing ex-
ecution of code on legacy platforms. In Proc. Symposium on
Operating Systems Principals, 2005.
[16] A. Seshadri, A. Perrig, L. van Doorn, and P. Khosla. SWATT:
Software-based attestation for embedded devices. In Proceed-
ings of the IEEE Symposium on Security and Privacy, May
2004.
[17] M. Shaneck, K. Mahadevan, V. Kher, and Y. Kim. Remote
software-based attestation for wireless sensors. In Proceed-
ings of ESAS, 2005.
[18] E. R. Sparks. A security assessment of trusted platform
modules. Technical Report TR2007-597, Dartmouth College,
June 2007.
[19] D. Spinellis. Reﬂection as a mechanism for software integrity
veriﬁcation. ACM Transactions on Information and System
Security, 3(1):51–62, Feb. 2000.
[20] G. Suh, C. ODonnell, I. Sachdev, and S. Devadas. Design and
implementation of the AEGIS single-chip secure processor
using physical random functions. In Proceedings of Annual
International Symposium on Computer Architecture (ISCA),
June 2005.
[21] G. Taylor and G. Cox. Digital randomness. IEEE Spectrum,
48, Sept. 2011.
[22] A. Triulzi. The Jedi Packet takes over the Deathstar, tak-
In The 12th annual
ing NIC backdoor to the next level.
CanSecWest conference, 2010.
[23] VSI Alliance. The value and management of intellectual
assets. http://vsi.org/documents/datasheets/
TOC20IPPWP210.pdf, 2002.
[24] E. Witchel. Mondriaan Memory Protection. PhD thesis,
Massachusetts Institute of Technology, 2004.
[25] A. C. Yao. Protocols for secure computations. In Proceed-
ings of 23rd Annual Symposium on Foundations of Computer
Science, Nov 1982.
cache is being used as memory. Our tests revealed that the
value of the performance counter was always 0 during the
SEC execution. This indicates that there were no cache evic-
tions and conﬁrms that the SEC is executing entirely within
the CAR environment.
4. Conclusions
The lack of isolation mechanisms on modern commodity
systems results in an inherently interconnected system where
a single malicious component can control the other compo-
nents and render the entire system compromised. This raises
the question of whether it is possible to reduce the hardware
trusted computing base (TCB) on such commodity systems.
We demonstrate with the CARMA design that it is in-
deed possible on a commodity system to remove from the
hardware TCB the memory, memory controller, system
buses, and peripherals. This leaves in the hardware TCB
only the CPU itself and a simple external device. The re-
sulting secure execution environment has guaranteed code
integrity, launch point integrity, and data integrity and se-
crecy.
CARMA offers an exciting execution platform for secure
computation that we plan to explore in our future work.
References
[1] B. Chen and R. Morris. Certifying program execution with
secure procesors. In Proceedings of HotOS, 2003.
[2] R. Gennaro, C. Gentry, and B. Parno. Non-interactive veriﬁ-
able computing: Outsourcing computation to untrusted work-
ers. In Proceedings of the International Cryptology Confer-
ence (CRYPTO), Aug. 2010.
[3] V. Gratzer and D. Naccache. Alien vs. quine, the vanishing
circuit and other tales from the industry’s crypt. In Proceed-
ings of Eurocrypt, May 2006.
[4] D. Grawrock. Dynamics of a Trusted Platform: A Building
Block Approach. Intel Press, 2008.
[5] M. Jakobsson and K.-A. Johansson. Assured detection of
In HotSec,
malware with applications to mobile platforms.
Aug. 2010.
[6] B. Kauer. OSLO: Improving the security of Trusted Comput-
ing. In Proc. USENIX Security, 2007.
[7] R. Kennell and L. H. Jamieson. Establishing the genuinity of
remote computer systems. In Proceedings of the 12th USENIX
Security Symposium, Aug. 2003.
[8] Y. Li, J. M. McCune, and A. Perrig. Viper: Verifying the
In Proceedings of the
integrity of peripherals’ ﬁrmware.
ACM Conference on Computer and Communications Security
(CCS), 2011.
[9] Y. Lu, L.-T. Lo, G. R. Watson, and R. G. Minnich. Car: Using
cache as ram in linuxbios. coreboot.org, Sep 2006.
[10] J. M. McCune, Y. Li, N. Qu, Z. Zhou, A. Datta, V. Gligor, and
A. Perrig. TrustVisor: Efﬁcient TCB reduction and attesta-
tion. In Proceedings of the IEEE Symposium on Security and
Privacy, May 2010.
[11] J. M. McCune, B. Parno, A. Perrig, M. K. Reiter, and
H. Isozaki. Flicker: An execution infrastructure for TCB min-
imization. In Proc. ACM European Conference in Computer
Systems (EuroSys), 2008.