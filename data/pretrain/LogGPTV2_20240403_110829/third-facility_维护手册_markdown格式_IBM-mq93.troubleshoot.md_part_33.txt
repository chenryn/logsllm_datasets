### Using the RESET CLUSTER Command

**Effect:**
The `RESET CLUSTER` command stops all auto-defined cluster sender channels for the affected queue manager. After executing this command, you must manually restart any cluster sender channels that were stopped.

**IBM MQ Troubleshooting and Support 209**

### Queue Manager Does Not Rejoin the Cluster

**Symptom:**
A queue manager does not rejoin the cluster after issuing a `RESET CLUSTER` or `REFRESH CLUSTER` command.

**Cause:**
Executing the `RESET` or `REFRESH` commands may stop the channel from the queue manager to the cluster. This is done to ensure that the correct version of the channel runs once the command is completed.

**Solution:**
Check the status of the channels between the problematic queue manager and the full repositories. If necessary, use the `START CHANNEL` command to restart them.

**Related Information:**
- [Clustering: Using REFRESH CLUSTER Best Practices](#)

### Workload Balancing on Cluster-Sender Channels

**Symptom:**
Workload balancing specified on a cluster-sender channel is not working as expected.

**Cause:**
Workload balancing settings on a cluster-sender channel are often ignored. Instead, the cluster workload channel attributes should be set on the cluster-receiver channel at the target queue manager.

**Solution:**
Specify the cluster workload channel attributes on the cluster-receiver channel at the target queue manager.

**Related Reference:**
- `CLWLPRTY` channel attribute
- `CLWLRANK` channel attribute
- `CLWLWGHT` channel attribute
- `NETPRTY` channel attribute

### Outdated Information in a Restored Cluster

**Problem:**
After restoring a queue manager, its cluster information is outdated.

**Solution:**
On the restored queue manager (e.g., QM1), issue the `REFRESH CLUSTER(DEMO)` command to refresh the cluster information.

**Note:**
For large clusters, using the `REFRESH CLUSTER` command can be disruptive while it is in progress and at 27-day intervals thereafter when the cluster objects send status updates to all interested queue managers.

**Process:**
- The `REFRESH CLUSTER(DEMO)` command removes all information QM1 has about the cluster DEMO, except for its own queues and how to access the full repositories.
- QM1 then contacts the full repositories and informs them about itself and its queues.
- As a partial repository, QM1 gradually builds up its knowledge of other partial repositories through active communication within the cluster.

### Accidental Removal of a Queue Manager from a Full Repository

**Problem:**
A queue manager (e.g., QM1) was mistakenly removed from a full repository in cluster DEMO using the `RESET CLUSTER(DEMO) QMNAME(QM1) ACTION(FORCEREMOVE)` command.

**Solution:**
On QM1, issue the `REFRESH CLUSTER(DEMO)` command to restore the queue manager to the full repository.

**Note:**
For large clusters, using the `REFRESH CLUSTER` command can be disruptive while it is in progress and at 27-day intervals thereafter when the cluster objects send status updates to all interested queue managers.

### Possible Deletion of Repository Messages

**Problem:**
Messages destined for a queue manager (e.g., QM1) were removed from the `SYSTEM.CLUSTER.TRANSMIT.QUEUE` in other queue managers, potentially including repository messages.

**Solution:**
On QM1, issue the `REFRESH CLUSTER(DEMO)` command to restore the cluster information.

**Note:**
For large clusters, using the `REFRESH CLUSTER` command can be disruptive while it is in progress and at 27-day intervals thereafter when the cluster objects send status updates to all interested queue managers.

### Moving Two Full Repositories Simultaneously

**Problem:**
If both full repositories (e.g., QM1 and QM2) in cluster DEMO are moved to new network addresses simultaneously, the cluster is not updated with the new addresses automatically.

**Solution:**
1. Alter the `CONNAME` in the `CLUSRCVR` and `CLUSSDR` channels to specify the new network addresses.
2. Alter one of the queue managers (e.g., QM1) so it is no longer a full repository for any cluster.
3. On the altered queue manager, issue the `REFRESH CLUSTER(*) REPOS(YES)` command.
4. Alter the queue manager so it acts as a full repository again.

**Note:**
For large clusters, using the `REFRESH CLUSTER` command can be disruptive while it is in progress and at 27-day intervals thereafter when the cluster objects send status updates to all interested queue managers.

**Recommendation:**
To avoid the problem:
1. Move one queue manager (e.g., QM2) to its new network address.
2. Alter the network address in the `QM2 CLUSRCVR` channel.
3. Start the `QM2 CLUSRCVR` channel.
4. Wait for the other full repository queue manager (e.g., QM1) to learn the new address of QM2.
5. Move the other full repository queue manager (e.g., QM1) to its new network address.
6. Alter the network address in the `QM1 CLUSRCVR` channel.
7. Start the `QM1 CLUSRCVR` channel.
8. Alter the manually defined `CLUSSDR` channels for clarity, though they are not needed for the correct operation of the cluster.

### Unknown State of a Cluster

**Problem:**
Restoring the cluster information in all full repositories to a known state.

**Solution:**
1. Stop all `CLUSRCVR` channels to full repositories.
2. Change `CLUSSDR` channels to inactive.
3. Refresh the full repository systems.
4. Refresh the partial repository systems to rebuild the cluster.

**Note:**
For large clusters, using the `REFRESH CLUSTER` command can be disruptive while it is in progress and at 27-day intervals thereafter when the cluster objects send status updates to all interested queue managers.

**Steps:**
1. On all full repository queue managers:
   - Alter queue managers that are full repositories so they are no longer full repositories.
   - Resolve any in-doubt `CLUSSDR` channels.
   - Wait for the `CLUSSDR` channels to become inactive.
   - Stop the `CLUSRCVR` channels.
   - Issue the `REFRESH CLUSTER(DEMO) REPOS(YES)` command.
   - Alter the queue managers so they are full repositories again.
   - Start the `CLUSRCVR` channels to re-enable communication.
2. On all partial repository queue managers:
   - Resolve any in-doubt `CLUSSDR` channels.
   - Ensure all `CLUSSDR` channels are stopped or inactive.
   - Issue the `REFRESH CLUSTER(DEMO) REPOS(YES)` command.

### Handling a Failed Cluster Queue Manager

**Explanation:**
When a cluster queue manager fails, undelivered messages are backed out to the cluster transmission queue on the sending queue manager. In-flight messages wait until the queue manager is restarted.

**Solution:**
Use a high-availability mechanism to automatically restart the queue manager, such as configuring it as a multi-instance queue manager or using a platform-specific high availability mechanism.

### Handling a Failed Repository

**Problem:**
Cluster information is sent to repositories via the `SYSTEM.CLUSTER.COMMAND.QUEUE`. If this queue fills up, messages are routed to the dead-letter queue.

**Solution:**
1. Monitor the queue manager log or z/OS system console for messages indicating the `SYSTEM.CLUSTER.COMMAND.QUEUE` is filling up. Retrieve and reroute messages from the dead-letter queue.
2. Address storage allocation errors by stopping and restarting the queue manager to allocate more storage.

### Disabling a Cluster Queue for MQPUT

**Problem:**
All instances of a cluster queue used for workload balancing might be disabled for `MQPUT`, leading to `MQRC_CLUSTER_PUT_INHIBITED` or `MQRC_PUT_INHIBITED` return codes.

**Solution:**
Write a user exit program to modify the workload management routines so that messages can be routed to a destination that is disabled for `MQPUT`.

### Potential Issues When Switching Transmission Queues

**Insufficient Access to Transmission Queues on z/OS:**
- **Symptom:** A cluster-sender channel on z/OS reports it is not authorized to open its transmission queue.
- **Cause:** The channel initiator lacks authority to access the new queue.
- **Solution:** Grant the channel initiator the same access to the channel’s transmission queue as documented for `SYSTEM.CLUSTER.TRANSMIT.QUEUE`.

**Moving of Messages Fails:**
- **Symptom:** Messages remain queued on the old transmission queue.
- **Cause:** Unrecoverable error, such as the new transmission queue being full or storage exhausted.
- **Solution:** Review error messages in the queue manager’s error log, resolve the root cause, and restart the channel.

**Switch Does Not Complete:**
- **Symptom:** The queue manager repeatedly issues messages indicating it is moving messages, but the switch never completes.
- **Causes:**
  - Messages are put to the old transmission queue faster than they can be moved.
  - Uncommitted messages on the old transmission queue.
  - New transmission queue or storage medium is full.
- **Solution:** Check queue and channel status, start the channel, free space on remote queues, or increase the `MAXDEPTH` attribute on the transmission queue.

**Accidental Deletion of a Transmission Queue:**
- **Symptoms:**
  - Channels unexpectedly switch due to the removal of a matching `CLCHNAME` value.
  - `MQRC_UNKNOWN_XMIT_Q` error on a put to a cluster queue.
  - Channel abnormally ends because its transmission queue does not exist.
  - Queue manager cannot move messages to complete a switch operation.
- **Cause:** The transmission queue has been deleted.
- **Solution:** Redefine the transmission queue or complete the switch operation using `runswchl` with the `-n` parameter (or `CSQUTIL` with `MOVEMSGS(NO)` on z/OS).

### Troubleshooting RDQM Configuration Problems

**About This Task:**
Refer to the topics explaining the output of the `rdqmstatus` command for help with troubleshooting RDQM high availability (HA) and disaster recovery (DR) configurations.

**Related Tasks:**
- Viewing RDQM and HA group status
- Viewing DR RDQM status
- Viewing DR/HA RDQM and HA group status

This optimized text provides a clear, coherent, and professional guide to handling various IBM MQ cluster issues.