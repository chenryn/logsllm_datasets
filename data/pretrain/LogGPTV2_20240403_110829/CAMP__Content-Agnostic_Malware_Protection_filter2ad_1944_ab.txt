30% of binary downloads. Furthermore, the web browser sends
only features computed from the binary, not the binary itself,
to the server.
C. Server
The server pipeline has two different roles when processing
requests. First,
the server receives the client request and
renders a reputation verdict based on its reputation system
which encompasses aggregate information from all downloads
observed by the server during its measurement
intervals,
including e.g. 1 day, 7 day and 90 day intervals. Second, the
server uses the information provided by the client to update
its reputation data.
The reputation verdict is computed by a reputation metric
calculated by a binary circuit that has access to all features
from the client request and any reputation data that is ref-
erenced by those features, e.g. how many known benign or
malicious binaries are hosted on a given IP address, etc.
To incorporate information provided by the clients into
the reputation system, client requests are first despammed to
prevent misbehaving clients from unduly influencing the data.
Fig. 2. The browser warns the user that the download is malicious. The
intentionally discrete arrow presents an option to keep the file.
Fig. 3. The browser warns the user that the download is not commonly
downloaded.
Despammed requests are then processed within a few minutes
to generate up-to-date features.
To create a classification system that has both high per-
formance and high reliability, we employ BigTable [8] and
MapReduce [14] for distributed data storage and parallel
processing. In the following, we provide a detailed overview
of each component involved in making reputation decisions.
1) Reputation System: The heart of the decision process is
the reputation system. To better understand its properties, we
place it within the analysis framework proposed by Hoffman
et al. [19]. According to Hoffman a reputation system can be
characterized across the following three dimensions:
• Formulation, which represents the mathematical underpin-
nings of the reputation metric as well as its information
sources.
• Calculation, which is the concrete implementation of the
formulation.
• Dissemination, which characterizes how the results from
the reputation metric are propagated to participants.
In our case, both the calculation and dissemination are
centralized and deterministic. The storage of reputation data
is transient as each item expires after 90 of days.
In the following, we explain the formulation of the reputa-
tion system in more details.
Our reputation data is based solely on direct, automatic
sources. The output of the binary analysis pipeline is a trusted
automatic source. Data collected and sent by web browsers
is also a direct, automatic source but may be untrusted.
The reputation data consists of features across a variety of
dimensions that each describe some aspect of the binary or
its hosting infrastructure. As mentioned in Section III-B, for
each binary download, we receive not only a content-hash but
also related information such as corresponding URLs and IP
addresses of the servers hosting them, etc. The server may
derive further features from the client request.
The reputation data maps each feature to an aggregate that
contains measurements over data observed during a given
time frame. Aggregates are continuous features and consist
of two counts: the number of interesting observations and the
total number of observations. For example, assume CAMP
observed 10 downloads, 6 of which were malicious, on IP
address IPA. The aggregate corresponding to the feature
IP:IPA would then be {6, 10}. Each aggregate also contains
the first and last time the particular feature was seen.
The aggregates include both positive as well as negative
events, i.e. they can be both trust building and trust diminish-
ing. For example, the number of users downloading a binary
from a site may represent an increase in trust. On the other
hand, the number of malicious binaries hosted on a site may
diminish its trust.
As CAMP is deployed to a large number of users, many
of the design decisions in building the system are in favor
of reducing false positives. However, the performance of the
reputation system can be adjusted gradually to favor recall
over precision.
We provide a detailed discussion of CAMP’s reputation-
based detection in the next section but give an overview
here of the reputation system itself. The reputation system
is responsible for receiving a browser reputation request and
replying to it with a verdict.
For each client request, the reputation system can make a
decision based on a-priori information if either the URL or the
content hash is known to be malicious. Similarly, to respond to
major false positives, the reputation system consults a server-
side whitelist to override any reputation decision.
The reputation metric is calculated by a binary circuit that
references reputation data in form of previously computed
aggregates. The features from the client request and the
reputation formulation determine which aggregates are looked
up from the data store. The reputation system then computes
a verdict which can be either: benign, malicious or unknown;
see Section IV for a discussion of the different meanings. The
data store lookups happen in parallel and are non-blocking to
reduce overall latency. The time spent computing the decision
from the aggregates is insignificant compared to the time it
takes to look up data from the data store.
incurring any significant
2) Frontend and Data Storage: The frontend is responsible
for receiving requests from web browsers and answering them
without
latency. To achieve low
latency, we split the reputation metric computation and the
integration of new data into the reputation system into separate
components. Upon receiving a request, the frontend issues a
Remote Procedure Call (RPC) to the reputation system, which
determines whether the binary download is malicious. After
receiving an answer, the frontend writes the request and the
verdict to a data store that other components of the pipeline
can process, and then returns the verdict to the client.
As CAMP needs to handle a large number of web browser
requests, the temporary storage of request data requires a
carefully chosen storage layout. We use BigTable [8], a non-
relational distributed database that provides key-value stores
and allows the association of a timestamp with a given key.
While Bigtable scales well, it is limited to approximately 2GB
of data per key. For subsequent data processing it is helpful
to index requests by the URL of the binary. However, as
we store each request for two weeks and some URLs are
requested frequently, on the order of hundreds of thousands
times a day, we chose not to index solely by URL. Instead, we
append the Reverse-Ordered hexadecimal string representation
of the timestamp of the request to the URL. This causes the
data to be placed in different rows while maintaining identical
ordering compared to indexing by URL. This design decision
was crucial in scaling CAMP to handle popular URLs.
3) Spam Filtering: The spam filter processes the data writ-
ten by the frontends in real time and discards requests that do
not originate from regular users. We do not require the spam
filter to be highly accurate and false positives are acceptable.
The spam filter may make use of any information provided
in the client request and has visibility into all client requests
made within the last 24 hours. As a result, the spam filter can
apply velocity controls on the user IP address of the request,
the Autonomous System Number (ASN) corresponding to the
IP address, etc. The spam filter also ensures that requests are
properly formed and contain all required features, e.g. properly
formatted URLs, etc.
Requests not discarded by the spam filter are forwarded
to an aggregator that computes aggregate features used by
the reputation system. The output of the spam filter is also
employed to fetch binaries from the web that have not been
analyzed by the binary classifier. Since binary downloads may
carry sensitive information, we apply further filters so that
only binaries that exhibit sufficient diversity of context are
considered for analysis. The binary analysis does not gate
any reputation decision and may complete a long time after a
reputation decision was sent back to the web browser.
As stated previously, our goal is not only to make highly
accurate decisions but also to reduce the impact on the privacy
of web users as much as possible. The requests received from
web browsers reveal not only the binary URL visited by a user
but by their very nature also a corresponding source IP address.
The data processing architecture of the reputation system is
designed so that the source IP address is visible only to the
spam filter and completely deleted after two weeks. The binary
URL is visible to rest of the pipeline, but is stored in such
a way that it also is automatically deleted after two weeks.
The only information that is stored for up to 90 days are the
aggregates that make up the reputation data.
4) Aggregator: The basis of
the reputation system is
formed by the reputation data which consists of statistical
aggregates indexed by keys derived from request features.
Aggregates are computed and written by the aggregator, which
processes the output of the despammer and organizes aggre-
gates according to a three-dimensional index.
• The first
index dimension is defined by whether the
aggregate is computed from client requests or based on
aggregates from the binary analysis system. Aggregates
computed from client requests are considered untrusted
whereas aggregates from the binary analysis system are
inherently trusted.
• The second index dimension consists of features from
client requests and additional features derived from the
request on the server side.
• The third index dimension contains broad categories over
which aggregates are computed. For client side aggre-
gates, this contains the number of requests that received
a malicious reputation decision as well as the number
of requests for binaries known a priori to be malicious,
either based on their URL or corresponding content
hash. For the aggregates from the binary analysis system,
this contains the number of URLs hosting malicious
downloads as well as the number of malicious content
hashes.
For example, the aggregate for
client|site:foo.com|reputation
represents the total number of client requests for the site
foo.com as well as the number of client requests for the same
site that received a malicious reputation decision. Another
example is
analysis|site:foo.com|urls
which contains the total number of URLs found under foo.com
as well as the number of such URLs that were labeled
malicious by the binary analysis system.
To construct these aggregates, the despamming component
writes client requests to a temporary data store which is
indexed by the second aggregator index dimension. Then a
series of MapReduces [14] periodically processes all entries
in the data store. This process merges new data with older
aggregates to generate aggregates over different time intervals,
currently 1 day, 7 days, 14 days, 28 days and 98 days. All
aggregates computed this way are available to the reputation
system.
D. Client-side Whitelist
CAMP reduces the privacy impact on its users in several
different ways. Since the detection is content-agnostic, web
browsers do not need to send binary payloads to CAMP’s
servers. As users download binaries that potentially contain
sensitive information, any solution that requires transmission
of payload data is likely to face privacy challenges.
Another way in which CAMP reduces the privacy impact
is by client-side whitelists that determine which binaries are
trusted in advance. If a binary is trusted, CAMP does not need
to send the binary URL to a remote server. The whitelists
contain trusted domains such as microsoft.com as well as
trusted software publishers. A software publisher is identified
by the public key of the signing certificate and the CA certi-
fying it. The goal of the whitelists is to resolve the majority
of all downloads locally without requiring a reputation-based
decision. At the time of this writing, approximately 70% of all
downloads are considered benign due to policy or matching
client-side whitelists.
For a domain or signer to be added to the whitelist, it needs
to fulfill the following criterion. CAMP needs to have seen the
binaries from the domain or signer for at least 90 days without
encountering any signs of maliciousness. We add new domains
or signers to the whitelist in the order in which they contribute
to the number of requests received by CAMP over that time
period.
Since adding a domain or signer to the whitelist implies
that the CAMP server no longer receives any downloads for it,
we employ a web crawl to regularly analyze binaries hosted
.
s
t
s
e
u
q
e
r
l
d
a
o
n
w
o
d
d
e
t
s
i
l
e
t
i
h
w
f
o
%
 0.9
 0.85
 0.8
 0.75
 0.7
 0.65
 0.6
 0.55
 0.5
 0.45
determine with a high degree of confidence whether a binary
is benign or not.
Binaries hosted on the web fall within a wide spectrum
ranging from known- benign to known-malicious. Known-
benign binaries can be added to a whitelist and known-
malicious binaries to a blacklist. In an ideal situation, any
binary is either known to be good or known to be bad. The
reputation system described here is concerned with the gray
area between whitelists and blacklists.
For CAMP, we attempt to create a whitelist that covers the
majority of benign binaries and subject anything not covered
by it to a reputation decision. In the following, we explain
how to classify a binary using reputation data.
Signers
Domains
 0
 1000
 2000
 3000
 4000
 5000
 6000
 7000
 8000
 9000
 10000
Whitelist size.
A. Feature Extraction
Fig. 4.
The graph shows the percentage of downloads for which a web
browser would make a local reputation decision depending on the size of the
domain and signer whitelist.
on the trusted domains or signed by trusted signers. If the
binary analysis reveals evidence of malicious behavior, the
corresponding entries are removed from the whitelist and are
again subject to reputation-based detection.
Figure 4 shows the number of downloads that a web
browser would handle locally when adding more trusted sites
to the domain or the signer whitelist. We estimated these
values by considering all reputation requests that we received,
then iteratively adding the most popular trusted signers and
domains to our whitelist and tracking which requests would
have been handled locally by the browser. The graph does not
contain measurements for whitelists smaller than our initial
whitelists as CAMP does not have any knowledge about
requests corresponding to them. Our initial domain whitelist
contained 243 entries and matched approximately 47% of all
download requests remaining after policy checks. The graph
shows that by increasing the domain whitelist to 1000 entries
the local percentage of downloads not requiring a request to
CAMP would increase to 73%. The signer whitelist is more
effective as increasing it to 1000 entries would cover about
85% of downloads locally.
IV. REPUTATION SYSTEM
The goal of our reputation system is to determine a-priori if
a binary is likely going to be malicious or not without having
access to the content of the binary itself. Instead, metadata
about the binary such, as its hosting infrastructure and how
the user reached it, form the basis for detection.
One of the challenges with detecting malware is the ease
with which malware authors can change their binaries, e.g.
by repacking, and how quickly they can change the locations
from which binaries are being served. On the other hand,
there is no need to frequently change the hosting location of
benign binaries or the binaries themselves. Differences such as
these may be leveraged to create a reputation metric that can
For each feature in the client request, the reputation system
derives features that form the indices for aggregate lookups.
The aggregates contain statistics about the total number of
times a feature occurred and how many times it occurred in
a malicious context. Each feature type has a different set of
derived features.
For IP addresses, the features are the IP address itself, the
corresponding /24 netblock, as well as the corresponding /16
netblock. The rationale for using netblocks is that serving IP
address frequently change, e.g. due to load-balancing or due to
adversaries switching IP addresses to avoid IP-based blocking.
For netblocks that are used predominantly for serving mali-
cious content, the likelihood that a yet unknown IP address in
that netblock is also serving malicious content is often higher.
CAMP also uses URL-based features. The reputation re-
quest from the client contains the URL pointing directly to
the binary download as well as any URL encountered by the
web browser when following redirects to the binary. For each
URL, the reputation system extracts the host, the domain, and
the site. The domain and site are usually identical, but differ
for dynamic DNS providers where the site is the same as the
host name. The goal of using the site and domain as a feature
is to track potential ownership of resources hosted on them.
the signer
key and the corresponding CA certifying the key for each
certificate chain encountered in the binary signature. We also
keep track if the signature was trusted on the client, e.g.
the client had a trusted CA that was the root of one of the
certificate chains.
For the signature-based features, we extract
Some of the client features such as the content hash are
used directly in subsequent aggregate lookups.
B. Aggregate Computation
The aggregation step discussed in Section III-C4 computes
aggregates for all possible dimensions based on client features
and features derived on the server. However, not all of these
aggregates are consulted when making a reputation decision.
Which aggregates are consulted for rendering a reputation
verdict depends on the configuration of the reputation system
described below.
Request
URL
http://a.foo.com/
IP
10.0.0.1
Aggregate Index
analysis—host:a.foo.com—urls
analysis—domain:foo.com—urls
analysis—site:foo.com—digests
client—site:foo.com—requests
analysis—ip:10.0.0.1—urls
analysis—ip:10.0.0.1—digests
client—ip:10.0.0.1—requests
analysis—ip24:10.0.0.1/24—urls
analysis—ip16:10.0.0.1/16—digests
client—ip24:10.0.0.1/24—requests
1 day
0/1
0/2
3/22
10/20
0/1
0/1
7 day
1/10
1/20
4/25
20/50
0/1
0/1
28 day
3/100
7/200
11/153
123/2200
0/1
0/1
1183/1208
9801/11327
33555/37455
2/112
0/3