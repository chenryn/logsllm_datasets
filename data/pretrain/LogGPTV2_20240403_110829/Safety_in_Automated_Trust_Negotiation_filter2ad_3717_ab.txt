safety set forth in prior work is inadequate, thereby motivating our introduc-
tion of adequate deﬁnitions in Section 3. Consider the following illustration of
unsafe behavior exhibited by typical strategies.
Example 1. Bob obtains a credential from the Internal Revenue Service
(IRS) documenting his low-income status. This credential is useful, for example,
when Bob interacts with a nonproﬁt organization that offers a service preparing
free living wills over the Internet for people with low incomes. Suppose Bob uses
an AC policy recommended by the IRS for protecting this credential, which
says that Bob will show his IRS.lowIncome credential to organizations that
document they are registered with the IRS as nonproﬁts. Bob uses his ATN-
enabled browser to contact an ATN-enabled service provided by a nonproﬁt to
obtain a living will and Bob’s browser and the service’s access mediator will
negotiate successfully.
Another Web user, Alice, does not have a low-income credential. Alice and Bob
each visit the web site of an unfamiliar real estate service, SwampLand.com.
When Alice and Bob each request information about listed properties, the
SwampLand access mediator initiates a negotiation requesting Alice and Bob
prove they have low-income status, which is not an appropriate requirement. If
Alice and Bob use a typical ATN strategy, such as the TrustBuilder1-Relevant
Strategy [Yu et al. 2003], this request induces Bob to present his AC policy
for his low-income credential. The aim in doing so is to prompt SwampLand
to present a nonproﬁt credential, should it have one. This enables Bob, for
instance, to determine whether SwampLand is authorized to receive Bob’s low-
income credential without SwampLand having to transmit all its credentials to
Bob. By contrast, the same request for a low-income credentials causes the ne-
gotiation with Alice to fail, since Alice does not have the requested credential
ACM Transactions on Information and System Security, Vol. 9, No. 3, August 2006.
Safety in Automated Trust Negotiation
•
357
and, therefore, has no AC policy she can present, since AC policies are de-
ﬁned only for credentials one actually has. SwampLand.com can easily observe
the difference between Alice and Bob’s behaviors and deduce Bob’s low-income
status, even though Bob’s AC policy indicates he does not want to share that
information with for-proﬁt companies. Granted, SwampLand.com does not ob-
tain proof that Bob is low-income. However, this should provide Bob little
comfort in using the ATN strategy, as SwampLand.com’s unauthorized infer-
ences are accurate just in case he adheres to the protocols faithfully. Similarly,
SwampLand.com can deduce that Alice does not have the credential, although
Alice also may not wish this to be disclosed.
The unsafe behavior illustrated in this example is not an artifact of the de-
tails of the TrustBuilder strategy, but rather characterizes most ATN strategies.
It occurs because these strategies transmit AC policies, or information derived
from them, in an effort to focus exchanges on credentials that are relevant to
enabling the negotiation to succeed. This focus aims to reduce message size and
other resource utilization, as well as to avoid distributing sensitive information
needlessly. Assuming ATN strategy should not fail when success is possible, the
competing goal of protecting sensitive attributes and this goal of focused dis-
closure seem to be at odds with one another. This is because of the nature of
AC policies, namely, that they are associated only with attributes that the ne-
gotiator satisﬁes. A negotiator cannot consistently reply to credential requests
by transmitting AC policies without revealing which credentials he has and
which he does not have. Although it may be possible to obfuscate this infor-
mation to some degree by replying in a less consistent manner [Seamons et al.
2002], doing so tends to cause negotiation to fail unnecessarily. An alternative
is to introduce a form of policy that can be associated with an attribute whether
or not the negotiator satisﬁes it. In keeping with Winsborough and Li [2002a,
2002b], we call such policies ack policies. We now use a simple example to show
how ack policies can be used to stop information leakage.
Example 2. Continuing the scenario from Example 1, Bob adopts the IRS’s
recommended ack policy, which says that he will discuss the matter of low-
income status only with nonproﬁt organizations registered with the IRS. Alice
does not have the low-income status credential, but also considers information
about her income status sensitive, so she also adopts the same ack policy.
There is a simple negotiation strategy according to which when Alice and
Bob each visit the web site of SwampLand.com, and both are asked to prove
they have low-income status, both Alice and Bob then ask SwampLand.com
to prove that it is nonproﬁt. Therefore, SwampLand.com only learns that both
Alice and Bob considers their income status sensitive, but not whether they are
low-income or not.
2.1 Why Ack Policies Are Practical
It has been argued [Yu and Winslett 2003a] that the use of ack policies is
unworkable because people who feel they have nothing to hide with respect to
a given attribute will not bother to use an ack policy for that attribute, thereby
casting suspicion on those who do. However, in most cases, a negotiator wishing
ACM Transactions on Information and System Security, Vol. 9, No. 3, August 2006.
358
•
W. H. Winsborough and N. Li
to protect some of his sensitive attributes by using ack policies also needs to
enforce ack policies on some attributes about which he has nothing to hide.
Otherwise the fact that he protects the attribute probably indicates that he
has something to hide about whether he has that attribute. In particular, if a
negotiator has some attributes that it discloses to a given opponent and some
other attributes that it does not, the opponent can determine whether, among
those attributes for which the opponent is authorized, the negotiator uses ack
policies for attributes about which he has nothing to hide. If there are no such
ack policies, the opponent can infer that the negotiator likely has something to
hide with respect to other attributes with which the negotiator associates ack
policies.
Thus, in the typical case, the negotiator wishes to protect some attributes
about which he has nothing to hide and, therefore, little interest in designing
ack policies. In such cases, if there were a straightforward mechanism for ob-
taining suitable ack policies for potentially sensitive attributes, the simplest
course of action would be always to use them. After all, if exceptions were to be
made, they would have to be speciﬁed.
We argue that deﬁning appropriate ack policies and making them available
should be part of attribute vocabulary design. Using some mix of natural and
formal language, the vocabulary designer can be expected to explain the at-
tributes he names. Characterizing the appropriate recipients of the named in-
formation can be viewed as part of that explanation. This answers the question
of where ack policies come from.
To ensure that ack policies can be collected as needed, we can take advan-
tage of a mechanism that also provides a nice solution to the problem of avoid-
ing unintended collisions among attribute names. Name collisions can be pre-
vented by making each attribute name include a reference, such as a URL,
to a document describing the attribute vocabulary of which it should be in-
terpreted as being a part. Names containing different vocabulary references
cannot be misinterpreted as being the same. It is natural that the vocabulary
description should include a description of appropriate recipients of informa-
tion about attributes in the vocabulary. We argue that the latter description
should be expressed as a formal policy that can be automatically retrieved
by a negotiator. Using the suggested scheme for disambiguating the intended
vocabulary, any request that a negotiator prove he has a certain attribute
must include a reference to the vocabulary document. It, therefore, includes
a reference to an ack policy recommended by the vocabulary designer—the
premier expert in the meaning of the attribute. The negotiator can simply
retrieve the ack policy and use it as his own in the remainder of the negoti-
ation. By using the designer-recommended policy, the negotiator obtains not
only convenience, but uniformity in his behavior with respect to that of other
negotiators.
One minor drawback of the scheme is that if a negotiator retrieves an ack
policy during a negotiation, this network activity may be observable by the
adversary. A simple solution to this problem, however, is to retrieve the ack
policy for every attribute the adversary inquires about during negotiation.
ACM Transactions on Information and System Security, Vol. 9, No. 3, August 2006.
Safety in Automated Trust Negotiation
•
359
2.2 Safety and Delegation
Ensuring safe enforcement of ack policies is tricky. One difﬁculty comes from
the fact that credentials may contain rules for deriving principals’ attributes.
Such rules are necessary in credential systems that express delegation of au-
thority, as is almost essential in decentralized environments and is common
in most access control languages designed for distributed access control. When
credentials may contain delegations, having one attribute may imply having
another attribute. Suppose, for instance, that a credential asserts that anyone
who has attribute t1 also has attribute t2. The following two kinds of inference
can then be made.
r forward positive inference: If the opponent M knows that N has attribute t1,
then M infers that N also has attribute t2 (i.e., modus ponens).
r backward negative inference: If the opponent M knows that N does not have
attribute t2, then M infers that M does not have t1 either (i.e., modus tollens).
Furthermore, sometimes the only way of having the attribute t2 is by having
attribute t1. In that case M can perform the following two kinds of inference as
well.
r backward positive inference: If M knows that N has attribute t2, then M
infers that N also has attribute t1.
r forward negative inference: If M knows that N does not have attribute t1,
then M infers that N does not have attribute t2 either.
Because of the possibility of these (and maybe other) inferences, it is not obvious
what the precise safety requirement for ack policies should be. Although pre-
vious work develops techniques to try to defend against these inferences, it is
not clear whether these techniques satisfy the intended security requirements,
since such requirements have not been deﬁned in a precise way.
3. A FORMAL FRAMEWORK FOR TRUST NEGOTIATION
In this section, we present a formal framework for automated trust negotiation
and precise deﬁnitions for safety in this framework. In Section 3.1, we set up the
framework and in Section 3.2 we give the deﬁnition of the safety requirement
for a negotiation strategy. In Section 3.3 we show that the eager strategy sat-
isﬁes this safety requirement. In Section 3.4, we discuss two alternative safety
notions that appeal to different intuitions and show that they are weaker than
the deﬁnition in Section 3.2. We also present reasons why we ultimately dismiss
each of these alternatives as inadequate. In Section 4, we apply the framework
to a credential system that supports delegation, extending a strategy from the
literature to obtain a family of strategies that satisfy our safety notion.
3.1 The Framework
An ATN system is a 7-tuple (cid:4)K, T , E, S, T, Resource, Policy(cid:5) whose elements are
as follows:
ACM Transactions on Information and System Security, Vol. 9, No. 3, August 2006.
•
e∈E T (e).
W. H. Winsborough and N. Li
360
r K is a countable set of principals. Each principal is identiﬁed with a public
key. We use K , possibly with subscripts, to denote principals.
r T is a countable set of attributes. Each attribute t is identiﬁed by a pair
containing an attribute authority (which is a principal) and an attribute
name (which is a ﬁnite string over some standard alphabet).
r E is a countable set of credentials that could legally be issued. We use e for
members of Eand E for ﬁnite subsets of E.
r S : E → K is a function; S(e) ∈ K is called the subject of credential e. If
S(e) = K , e is a credential for K .
r T : E → 2T is a function such that each T (e) is ﬁnite and nonempty. A
credential e proves that S(e) has or possesses the attributes in T (e). For each
K and each set E of credentials for K , the set of attributes induced by E is
T (E) = (cid:2)
r Resource is a countable set of resources.
r Policy denotes the set of positive propositional logical formulas in which the
propositions are attributes in T . These formula are called policies and we
use φ to denote one policy. If E is a set of credentials having subject K and if
T (E) |= φ, we say that φ is satisﬁed by K .
Possession of attributes in T may be considered sensitive and the goal of ATN
is to protect such information. In our framework, one credential may prove
that its subject possesses more than one attribute. In addition to supporting
credentials that explicitly aggregate attributes, this feature will be useful when
we introduce delegation, in Section 4.
Notice that whether or not a credential proves possession of an attribute is
independent of the presence of other credentials. In particular, given a set of cre-
dentials E, if no credential e ∈ E proves an attribute t by itself, the combination
of credentials in E does not prove t either. We can and do allow conjunctions of
attribute to be required in policies. For instance, one can authorize a discount
for principals with a valid university student ID and an ACM membership
credential, but we do not enable one to deﬁne or protect the derived attribute
of being a student member of the ACM, based on these two credentials. The
student attribute or the ACM-member attribute must be protected if being a
student member of ACM is sensitive.
In this model, a participant in the ATN system is characterized by a ﬁnite
conﬁguration G, which is given by G = (cid:4)K G, EG, AckG, ACG(cid:5). The elements of
G are as discussed below. (We drop the subscripts when G is clear from context.)
We denote the set of all conﬁgurations by Conﬁguration .
r K is the principal controlled by the participant; this means that the par-
ticipant has access to the private key that corresponds to K , enabling the
participant to prove itself to be the (presumably unique) entity controlling
the key.
r E ⊂ E is the set of credentials that are assumed to have been issued for K in
the conﬁguration G.
r Ack : T (cid:3)→ Policy is a partial function mapping a ﬁnite subset of attributes in
T to policies. Attributes in the preimage of Ack are called sensitive attributes.
ACM Transactions on Information and System Security, Vol. 9, No. 3, August 2006.
Safety in Automated Trust Negotiation
•