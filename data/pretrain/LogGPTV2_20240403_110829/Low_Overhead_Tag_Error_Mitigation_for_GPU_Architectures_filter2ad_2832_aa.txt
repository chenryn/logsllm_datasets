title:Low Overhead Tag Error Mitigation for GPU Architectures
author:Atieh Lotfi and
Nirmal R. Saxena and
Richard Bramley and
Paul Racunas and
Philip P. Shirvani
2018 48th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
Low Overhead Tag Error Mitigation for GPU
Architectures
Atieh Lotﬁ∗†, Nirmal Saxena†, Richard Bramley†, Paul Racunas†, Philip Shirvani†
∗UC San Diego
†NVIDIA
Abstract—Cache structures on modern GPUs or CPUs occupy
a large area and are frequently accessed. This increases their
vulnerability to transient errors. With some area and energy
overhead,
these structures are often protected by ECC or
parity checking. However, in deference to the energy efﬁciency
and scalability challenges in high-performance computing, it is
crucial to minimize any unnecessary overhead while maintaining
the desired reliability. This paper evaluates the reliability of
unprotected tag SRAM structures in modern GPUs, and studies
the use of a low-overhead tag error mitigation mechanism. The
proposed mechanism exploits Galois-based hash functions for set-
index calculation to mitigate some pathological address strides
that cause false hit events. Extensive analysis on a modern GPU
indicates that the hash-based mechanism yields 10× reduction
in false hit probability (with 2% improvement in hit rate) for
write-through data caches when compared to a baseline cache
indexing scheme.
I. INTRODUCTION
In the past decade, graphics processing units (GPUs) have
emerged as a promising solution to achieve high performance
and energy efﬁciency for a variety of computing domains. To
improve performance and reduce energy overhead for access-
ing data from the main memory, all modern processors like
central processing units (CPUs) and GPUs have multiple levels
of cache memory structures that cache most recently used data.
These cache structures are vulnerable to transient hardware
errors, especially as their sizes increase and due to operating
at low voltage levels. These transient errors can cause failures
and corrupt application output. To protect against transient
errors, cache memories typically use error detection/correction
mechanisms, such as parity/error correcting codes (ECC) bits.
When a cache line is augmented with parity/ECC bits, then
every cache access also requires error detection/correction
encoding. While these error protection schemes impact area
and energy efﬁciency, they are necessary for the data portion
of the cache structures. However, in the tag structure of read-
only instruction caches or write-through data caches, there is
opportunity to eliminate the need for parity protection.
A single-bit error in the tag memory of a set-associative
cache is unsafe if the entries that map to the same set are
separated by a Hamming distance of 1. If an error happens
in a tag entry and this bit ﬂip results in an incorrect match
to the reference tag, the wrong data is read from the cache.
This false hit event might cause silent data corruption (SDC).
Therefore if we change the distribution of tag entries to reduce
the chance of mapping two tags with 1-bit Hamming distance
to the same set, the probability of an SDC event is reduced.
It has been shown that hash functions derived from Galois
Field [1] primitive polynomials satisfy this requirement. Using
this hash function, all address references that hash to the same
location would be at least 3-bit Hamming distance away from
each other. The Galois Field with base 2 (GF2) is very low
cost and easily implemented using eXclusive OR (XOR) gates
in hardware.
We propose an architecture that uses hash functions for
set-index calculation to change the distribution of tags in the
cache. Speciﬁcally, this paper makes the following contribu-
tions:
1) We use Galois-based hash functions, for set-index cal-
culation, in high performance and energy efﬁcient GPU
computing,
to mitigate false hit events and improve
performance. To the best of our knowledge, this work
is the ﬁrst to investigate the effectiveness of hash-based
cache indexing schemes for reliability purpose.
2) We provide a sensitivity analysis of cache reliability
to key architectural parameters: cache tag width, and
associativity. We quantify the resiliency and performance
of the hash-based cache indexing schemes for the read-
only instruction and write-through data caches of the
GPU architecture. We conclude that the error probability
is a function of workload address trace characteristics and
tag SRAM structure.
3) We deploy a fast method to measure the resiliency of a
cache without any explicit fault injection. This method is
based on calculating the Hamming distance between the
address reference tag and the existing valid tags in the
corresponding set.
4) We demonstrate, for the high-performance computing
(HPC) benchmarks, the probability of false-hit events in
the tag structures is very low and has a negligible impact
on the overall SDC FIT (failures in time) rate of the GPU.
Furthermore, we show that Galois-based hash functions
for tag structures in write-through data caches further
reduce the false hit probability by a factor of 10.
The rest of this paper is organized as follows. Section II
summarizes related work. Section III reviews some back-
ground information. Section IV discusses the design and
implementation of hash-based cache indexing scheme. Sec-
tions V and VI explain the simulation methodology and eval-
uate the resiliency and performance of the proposed method.
Section VII presents an analytical and Monte Carlo reliability
estimation for random traces. Finally, Section VIII concludes
the paper.
2158-3927/18/$31.00 ©2018 IEEE
DOI 10.1109/DSN.2018.00041
314
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:31:02 UTC from IEEE Xplore.  Restrictions apply. 
II. RELATED WORK
A. Low-cost Soft Error Protection for Cache Structures
A common solution to address soft errors in cache memories
is to apply error detection/correction code such as parity/ECC
bits uniformly across all cache lines [2]. Previous work on re-
ducing cache protection overhead either breaks the assumption
of uniform protection of all cache lines, or utilizes different
mechanisms to protect clean and dirty cache lines. Kim et.
al [3] suggest protecting only those cache lines that are most
frequently accessed in every cache set to trade between area
and level of data integrity. [4][5] proposed a method to reduce
area for protecting L2/L3 caches. Instead of using ECC for
all entries, it selectively applies ECC just to dirty cache lines;
other clean cache lines are protected by using parity check
codes instead. However, our goal is to use hash functions
to change the distribution of tag entries in the cache to
reduce the probability of undetected errors without using parity
protection.
B. Exploiting Hash Functions for Addressing Memory Struc-
tures
Hash functions are widely used in computer architecture
to minimize conﬂict misses in caches [6] or to improve
accessing to interleaved multibank memories [7]. A hash
function maps an address to a set-index. The easiest hash
function to implement for addressing cache memories is the
modulo function, which is traditionally used and selects some
of the least signiﬁcant bits of the reference address. However,
this way of set-index bit selection creates many conﬂicts for a
number of frequently occurring access patterns, such as large
power-of-2 strides. To avoid cache conﬂicts, alternative hash
functions were studied for set-index bit generation to reduce
conﬂict misses by achieving a more uniform cache access
distribution across the sets in the cache [8][9][10].
Several
types of hash functions have been investigated.
Depending on the situation, one type of hash function can
be more appropriate than another due to properties of ac-
cess patterns. The proposed techniques can be classiﬁed into
static [6] [10] [11] and adaptive [12] indexing schemes.
Among the static methods, XOR-based mapping policies
(e.g polynomial [13] and bitwise XOR [6]) are used to obtain
a pseudo-randomly placement of blocks. In this way, a better
distribution of blocks among cache sets can be obtained
which reduces the number of conﬂict misses. Rau proposed a
scheme [13] which describes a method for constructing XOR
mapping schemes based on polynomial arithmetic. Polynomial
indexing can be explained by considering address A = (an−1,
..., a1, a0) as a polynomial P(x) = an−1xn−1,..., a1x1, a0, where
the coefﬁcients are in the Galois Field GF(2) (can take on
values 0 or 1). This XOR-based polynomial modulus function
has very low complexity (requires only XOR operations) and
is suitable for computing a cache index. If the generator
polynomial is primitive and the code length is less than the
cycle length of the polynomial,
then the resulting code’s
Hamming distance is at least 3. Other works propose the
Fig. 1. Volta GPU block diagram
use of more complicated hash functions, like prime-number
based [10], which can be used for shared caches to minimize
conﬂict misses at the cost of increased latency and hardware
complexity. However, the complexity of these methods makes
these techniques unsuitable for ﬁrst level caches, where latency
is critical. For GPUs, researchers have studied the effects of
multiple static indexing techniques such as arbitrary modulus
indexing [14] and polynomial [15][16] on performance and
energy consumption. In the context of adaptive cache indexing
schemes, (ASCIB) [12] monitors the memory access pattern of
workloads in CPU at runtime, determines the best indexing bits
that are expected to minimize conﬂict misses for the observed
memory access pattern, and periodically reconﬁgures them
accordingly.
As opposed to this existing work, we study the effect
of using hash functions on reliability. To the best of our
knowledge, we are the ﬁrst to evaluate the use of Galois-
based hash functions, for set-index calculation for cache tags
in GPUs. Our goal is to mitigate some pathological address
strides that cause failures in the event of soft errors.
III. TARGET GPU ARCHITECTURE
This section provides a brief background on GPU architec-
ture and its resilience support. Figure 1 shows a simpliﬁed,
representative GPU architecture for NVIDIA Volta generation
[17]. The GPU architecture comprises multiple GPU Process-
ing Clusters (6 GPCs) and multiple streaming multiprocessors
(14 SMs per GPC) within each GPU. Large SRAM structures
like the Register File (RF) and the L1 Data Cache within
each SM and the L2 Cache Data are ECC protected. There
are a signiﬁcant number of tag SRAM structures within each
SM (L1 Instruction Cache, L1 Data Cache), within each GPC
(uTLBs) and within each GPU (TLBs). Some of these tag
SRAM structures (L1 Data Cache, for example) are already
protected. Since the point of coherence in the GPU is the L2
Cache, it turns out that the L1 Data cache is write-through.
The point of articulation of the GPU tag SRAM structures
is to highlight the area saving opportunity by evaluating the
effectiveness of low overhead tag error mitigation method. For
example, in the case of the L1 Data Cache tag SRAMs, there
is an opportunity to save a total of 168K SRAM bits required
for parity storage in all SM instances.
315
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:31:02 UTC from IEEE Xplore.  Restrictions apply. 
IV. LOW OVERHEAD TAG CHECKING
For a tag SRAM array without any parity protection, errors
in tag entries could cause false hits or false misses [18]. We
describe these events as follows:
Assume that an error happens in an unprotected tag entry,
Tag[i][ j] (for set-index i and way j) with value TA1, and
changes its value to TA2.
• Assume that
the tag SRAM receives a new address
reference with set-index i, and value TA1. In the absence
of error, this would be a hit. However, because of the
transient error, the result is not a hit. This event is called
false miss.
• Assume that the tag SRAM receives a new address refer-
ence with set-index i, and value TA2 (one-bit hamming
distance away from TA1). In this scenario, the Tag SRAM
would match the incoming reference with its erroneous
entry having value TA2. This situation is called false hit.
False hit can be divided into two conditions:
– Assume that the only entry having value TA2 was the
entry that had value TA1 prior to the transient failure.
This situation is called false hit under true miss.
– Assume that there is another error free entry in set-
index i with value TA2. In this situation, a new
reference with value TA2 would match two entries in
the tag cache. This situation is called false hit under
true hit.
The tag error event space is shown in Figure 3.
For tag SRAM structures that cache read-only or write-
through data, a false miss is not a reliability issue as a back-up
copy exists and can be serviced through a reﬁll. There might
be only a negligible impact on performance due to false misses
as these events are rare. However, a false hit under true miss
can cause silent data corruption (SDC). If robust circuit design
techniques are not used to detect multiple matches for the same
row, false hit under true hit condition could also cause SDC.
It should be noted that parity augmented tag SRAM arrays
Fig. 2. No explicit tag error checking
316
Fig. 3. Tag error event space
for single or odd bit errors effectively suppress the false hit
or miss events.
We explored different design alternatives and made an
observation that there exists a class of hash functions that
map unit-distance address strides across different sets. This
class of hash functions that are derived from Galois Field
primitive polynomials satisﬁes the properties listed below. We
use the example implementation in Figure 2 to describe these
properties. (Figure 2 illustrates an unprotected Tag SRAM
structure of a 4-way set-associative cache with 64 byte (B)
cache line size and 128KB capacity. Assuming a 48-bit address
width, Address[5:0] determines the byte within a 64B cache
line and Address[14:6] deﬁnes the set-index in the 4-way tag
SRAM array.)
• All address references that change in bit locations Ad-
dress[14:6] (in general, any n contiguous Address bits
in an n-bit hash function) will map to distinct set-index
values. This generalizes the uniform set-index distribution
property of hash free set-index calculation.
• All address references Address[47:6] that hash to the
same set-index value, will be at least Hamming distance =
3 away from each other. For example, if AddressA[47:6]
and AddressB[47:6] hash to the same set-index value i
then Hamming distance(AddressA,AddressB) > 2.
• It follows from the previous property that address refer-
ences with strides of power-of-2 (Hamming distance = 1)
or strides of sum of powers-of-2 (Hamming distance =
2) will have different set-index values. This eliminates
the false hit scenario that can happen in a hash-free
implementation that uses Address[14:6] for the set-index.
This hash-based approach eliminates false hits arising from
address strides with powers-of-2 or sum of two powers-of-2.
In the following sections, we estimate false hit probability for
address traces derived from HPC applications. An important
side beneﬁt of using a hash-based set-index is the marked im-
provement in uniformly distributing address references across
the sets and the improvement in the cache utilization. We also
study the effect on cache hit rate from using these false hit
reducing hash-based tag lookup methods.