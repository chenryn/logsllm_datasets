.28 (.06)
.25 (.17)
.30 (.14)
.27 (.08)
Table 1: Neural Results for Phishing Detection: Average cogni-
tive workload and average percentage of frequency of engage-
ment, distraction and sleep onset.
participants were actively engaged, and lowly distracted or sleep-
prone, during the experiment.
We noticed a statistically signiﬁcant difference in the means of
overall pfrENG, overall pfrDIS and overall pfrSO upon testing with
the Friedman test (χ2(2) = 34.6, p  .5); we did not see a statistically signiﬁcant difference
in pairwise comparison of these metrics across the DFake trials,
however. All these pairwise differences remained statistically sig-
niﬁcant even when applying Holm-Bonferroni correction.
This analysis shows that the participants’ frequency of being in
an engaged state was higher than their frequency of being in dis-
tracted state or sleep-onset state in the phishing task for all types
of trials (except DFake). This means that the participants were ac-
tively involved in making fake vs. real decisions (not getting dis-
tracted by it or ignoring it).
Finally, we contrasted different categories of trials (rows of the
Table 1.) with respect to our metrics. We found statistically signiﬁ-
cant differences in the means of pfrENG, pfrDIS and pfrSO among
the different types of trials, with Friedman test (χ2(11) = 141.5,
p  .5 for all comparisons). We also found a statistically signiﬁcant
difference between mean gaze durations of Logo and URL corre-
sponding to Fake trials (p=.001) with a medium effect size (r =
.49), EFake trials (p=0.015) with a medium effect size ( r = .35),
and DFake trials (p .6 for all compar-
isons); whereas Logo-URL difference was not statistically signif-
icant. All these differences remained statistically signiﬁcant after
Holm-Bonferroni corrections.
Based on the above analysis, we can conclude that participants
were ﬁxating more, and spending more time, at the Login and/or
Logo regions compared to the URL region, for all categories of
trials. This conﬁrms our hypothesis that users may not be spend-
ing enough time analyzing the key indicators of phishing attacks.
The users were actually looking more at the Login region than the
Logo region, which means they may have regarded the login form
as a better indicator of the legitimacy of the site than its logo. This
insight helps to explain why their real-fake decisions were not ac-
curate, as our task performance results show below.
When testing for differences between different categories of tri-
als (rows of Table 2) with respect to number of ﬁxations and gaze
duration using WSRT, no statistically signiﬁcant differences emerged.
Finally, we performed correlation analysis, using Spearman’s
correlation method, to elicit relationships in the mean gaze dura-
tions across different AOIs. We found a statistically signiﬁcant pos-
itive correlation between mean duration in Login (overall trial) and
mean duration in Logo (overall trial) (rcor =.606, p =.002), mean
duration Login( Fake) and mean duration Logo (Fake) (rcor =.591,
p=.003), mean duration Login and mean duration Logo (EFake)
(rcor =.569, p=.005), mean duration Login (Real) and mean du-
ration Logo (rcor = .551, p=.006) and between mean duration in
Login (DFake trial) and mean duration in Logo (DFake trial) (rcor=
.567, p=.005). These differences remained statistically signiﬁcant
upon correcting with Holm-Bonferroni correction, and suggest that
participants who spent more time at Login also spent more time at
Logo overall (and in DFake trials). The other pairs did not show
any signiﬁcant relationship.
7.1.3 Task Performance Results
We calculated the response times and the percentage of correctly
identiﬁed websites out of the total responses given by the partic-
ipants (referred to as accuracy), for different types of trials. The
response was counted as correct/incorrect only if the response was
provided (6.15% of trials were not responded to and are excluded
from our calculations). Table 3 summarizes our results.
The overall accuracy of correctly identifying a website is around
70%. It seems the highest for the real websites and the lowest for
the difﬁcult fake websites. Our average accuracy results are in line
485Metric →
Trial ↓
Real
Fake
Overall
Overall
EFake
DFake
Accuracy (%)
µ (σ)
83.24 (17.28)
62.31 (20.62)
68.35 (21.68)
55.94 (25.30)
69.69 (16.64)
Response Time (ms)
µ (σ)
1594 (339)
1663 (231)
1667 (268)
1655 (294)
1641 (257)
Table 3: Task Performance in Phishing Detection: Average ac-
curacy and response time
with, but slightly better than, the results of [17,26]. They are further
supported by our gaze pattern analysis which showed participants
were spending more time looking at the login ﬁeld and/or logo than
analyzing the URL.
The Friedman test showed a statistically signiﬁcant difference
in mean accuracies across Real trials, Fake trials, EFake trials and
DFake trials (χ2(3) = 32.7, p<.0005). On further contrasting the
accuracy rates across different types of trials with WSRT, we found
that participants identiﬁed real websites with a statistically signiﬁ-
cantly higher accuracy than fake websites ( p <.0005), with a large
effect size (r = .53 ). This seems to conform to our neural data anal-
ysis, which showed participants were seemingly more engaged, and
less distracted, in real trials than they were in fake trials. We also
found that the participants identiﬁed Real trials with statistically
higher accuracy than EFake trials (p=.003), with a medium effect
size (r = .44) and DFake trials (p < .0005), with a large effect size
(r = .54). Further, we found the accuracy for EFake trials to be sta-
tistically signiﬁcantly higher than the accuracy of DFake websites
(p =.017) with a medium effect size (r = .34).
Difﬁcult fake websites had a different URL, disguised to look
like the original one, with the layout of the original (real) website.
Each easy fake website, in contrast, had a URL and logo or layout
different from the corresponding real website. Therefore, it is natu-
ral that people were less accurate with difﬁcult fake websites. This
difference, however, did not remain statistically signiﬁcant when
using Holm-Bonferroni correction; all others were still statistically
signiﬁcant.
Post-Test Survey Analysis: 52% of our participants reported that
they had not heard about phishing attacks. The other 48% deﬁned
these attacks as, “Attacks from unsecured websites and they cause
viruses to occur”; “ someone trying to get your information with-
out you knowing; information can be stolen”; “Tracks cookies, pri-
vacy is reduced”; “steal your private information, lose money, ID
stolen”. This suggests that participants had some, but not very pre-
cise, understanding of phishing, which may help explain the overall
low accuracy.
7.1.4 Correlations
Upon using Spearman’s correlation, we found a large, statisti-
cally signiﬁcant decrease in the overall accuracy of phishing detec-
tion with the increase in the overall mean gaze duration in the login
area of websites (rcor=-.592, p = .003). This correlation remained
statistically signiﬁcant even when applying Holm-Bonferroni cor-
rection. It suggests that the participants who spent more time look-