any unauthorized login if the password is leaked to the attackers,
but our framework can still provide a certain level of defense such
that only about 10% to 25% percent of unauthorized login attacks
are successful under visual leakage of the passcode content.
6.3 Persistence Analysis
We collect an additional dataset to analyze the persistence of the
in-air-handwriting passcode. 40 users participating in the dataset
1 in section 3.3 were asked to write their passcodes five times as
a session, and 10 sessions in total. The data from each session
is collected at a different day. Then, we apply the step 2 of the
experiment protocol using the data of each session and the T-Fusion
algorithm. The score variation among the ten sessions is shown in
Figure 11. Each column of this plot corresponds to the results in one
session, which is similar to the score histogram shown in Figure 9.
Here, the scores of all 40 accounts are plotted as scattered points
from left to right across the width of the column for the session.
There is an increase of the scores of the login requests of legitimate
users over time if the templates and the classifiers are not updated,
although the extent of increase slows down after the fourth session.
However, the scores of the login requests of the random guessing
attacks do not have noticeable changes. These two factors make the
system harder to distinguish legitimate users from attackers, which
eventually leads to more frequent false rejection of legitimate users
if the decision threshold is not changed, shown in Figure 12.
There are two reasons. First, there are inherent variations of user
behaviors, which leads to differences in signals even for the same
user writing the same string. For example, most users write from
left to right using the index finger, but this left-to-right movements
of hand usually do not have a fixed angle relative to the pointing
direction of the index finger when writing the same content ev-
ery time in the air. The variation generally grows with multiple
sessions. However, the xyz-axes are determined by the pointing
direction in the signal preprocessing steps, which leads to varia-
tions in the signals. This is more significant for the camera device
because it directly tracks position and orientation. Second, the au-
thentication algorithm is not perfect. There are limited amount of
478ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Duo Lu, Yuli Deng, and Dijiang Huang
Figure 11: Variation of scores of legitimate user login requests and random guessing attacks among ten sessions. The decision
threshold is set to 0.413 for the camera device and 0.401 for the glove device, such that the corresponding single session
performance metrics are FRR ≈ 1%, FAR ≈ 0.001% without considering collision, and FAR ≈ 12% with considering collision.
Figure 12: Variation of True Acceptance Rate (TAR, i.e., 1 - FRR) among ten sessions using the decision threshold in Fig. 11.
signals obtained at registration, which make the system difficult to
capture or predict the long-term in-air-handwriting behavior varia-
tion. Meanwhile, the classification is designed to utilize signal-level
differences directly for more effective detection of spoofing attacks
from legitimate login requests, which also limits its generalization
capability under long-term variation.
To accommodate these variations, one solution is asking the
users to update the templates and retrain the SVM classifier. The
updated template is a combination of an old template and the up-
dating signal, i.e., T ← (1 − λ)T + λS, similar as [19]. After the
updating, the SVM classifier is retrained using the old templates
and the updating signals as positive data points and templates of
other accounts as negative data points. In Figure 12, we show the
performance change with four different scenarios: (a) only do the
updating in the first session while not changing the templates and
the SVM classifier after that; (b) similar to (a) but do the updating
in both the first session and the second session; (c) similar to (a)
but do the updating in the first five sessions; (d) do the updating in
all ten sessions, and this is the scenario that generates the results
labeled with update in Figure 11. From the results, we can observe
that long term performance can be improved by the updating, even
only updating at the first login immediately after registration can
boost the true accept rate to above 95% for all remaining sessions.
7 CONCLUSIONS AND FUTURE WORK
This paper presents a user authentication framework with two dif-
ferent types of devices using various features of in-air-handwriting
passcode, including temporal features, statistical features, and hand
geometry features. We also conduct a comparative evaluation of var-
ious matching algorithms and an analysis of these features to show
the insights of the algorithms. Although the results are promising,
it is still in an early stage with limitations. For example, the tracking
performance of the camera device degrades when the hand moves
fast or in some poses. Also, there might be usability concerns for
asking the user to put on a glove unless the glove is a default gesture
input device of the computing platform. Hence, we plan to design
a handheld device with localization capability or a lightweight
ring-like device with the same inertial sensor as the glove in the
future. Moreover, our matching algorithm and persistence study
is primitive. It is not clear whether freestyle in-air-handwriting
passcode is stable enough for user identity verification in the long
term under various environment. We plan to collect a large dataset
of in-air-handwriting of all possible combination of characters and
develop a data-driven method to convert a signal to a sequence
of stroke representations for fine-grained matching. Meanwhile,
we plan to collect data from the same user with more sessions
and expand the time span. Constraints in the writing content or
visual stimuli can also be added in future experiments to make
the users’ behavior more stable. Furthermore, we present a primi-
tive usability study in Appendix B with a survey of 100 users, but
the responses of the survey are subjective to each user and the
evaluation is qualitative. Hence, we intend to collect objective and
quantitative metrics of the usability in the future. Still, we believe
such an in-air-handwriting passcode-based authentication method
has a great potential in many wearable and VR/AR applications in
the future, and we hope our datasets can be helpful to researchers
in this field.
REFERENCES
[1] Ilhan Aslan, Andreas Uhl, Alexander Meschtscherjakov, and Manfred Tscheligi.
2014. Mid-air authentication gestures: an exploration of authentication based on
palm and finger motions. In Proceedings of the 16th International Conference on
Multimodal Interaction. ACM.
[2] Gonzalo Bailador, Carmen Sanchez-Avila, Javier Guerra-Casanova, and Alberto
de Santos Sierra. 2011. Analysis of pattern recognition techniques for in-air
signature biometrics. Pattern Recognition (2011).
[3] Muzaffar Bashir and Jurgen Kempf. 2009. Person authentication with RDTW
based on handwritten PIN and signature with a novel biometric smart pen device.
In IEEE Workshop on Computational Intelligence in Biometrics: Theory, Algorithms,
479Global Feature Analysis and Comparative Evaluation of Freestyle In-Air-Handwriting Passcode for User Authentication
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
and Applications, 2009. CIB 2009. IEEE, 63–68.
[4] Donald J Berndt and James Clifford. 1994. Using Dynamic Time Warping to Find
Patterns in Time Series.. In KDD workshop, Vol. 10. Seattle, WA.
[5] Aman Chahar, Shivangi Yadav, Ishan Nigam, Richa Singh, and Mayank Vatsa.
2015. A Leap Password based verification system. In IEEE 7th International
Conference on Biometrics Theory, Applications and Systems (BTAS). IEEE.
[6] Alexander Chan, Tzipora Halevi, and Nasir Memon. 2015. Leap Motion Controller
for Authentication via Hand Geometry and Gestures. In International Conference
on Human Aspects of Information Security, Privacy, and Trust.
[7] Gradeigh D Clark and Janne Lindqvist. 2015. Engineering Gesture-based Authen-
tication Systems. IEEE Pervasive Computing (2015).
[8] Elisabetta Farella, Sile O’Modhrain, Luca Benini, and Bruno Riccó. 2006. Gesture
signature for ambient intelligence applications: a feasibility study. In PerCom.
Springer.
[9] Julian Fierrez, Aythami Morales, Ruben Vera-Rodriguez, and David Camacho.
2018. Multiple classifiers in biometrics. Part 1: Fundamentals and review. Infor-
mation Fusion (2018).
[10] Marta Gomez-Barrero, Javier Galbally, Aythami Morales, Miguel A Ferrer, Julian
Fierrez, and Javier Ortega-Garcia. 2014. A novel hand reconstruction approach
and its application to vulnerability assessment. Information Sciences (2014).
[11] Feng Hong, Meiyu Wei, Shujuan You, Yuan Feng, and Zhongwen Guo. 2015.
Waving authentication: your smartphone authenticate you on motion gesture.
In Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human
Factors in Computing Systems. ACM.
[12] Donato Impedovo and Giuseppe Pirlo. 2008. Automatic signature verification:
The state of the art. IEEE Transactions on Systems, Man, and Cybernetics, Part C
(Applications and Reviews) 38, 5 (2008), 609–635.
[13] Donato Impedovo and Giuseppe Pirlo. 2018. Automatic signature verification in
the mobile cloud scenario: survey and way ahead. IEEE Transactions on Emerging
Topics in Computing (2018).
[14] Ajay Kumar, David CM Wong, Helen C Shen, and Anil K Jain. 2003. Personal
verification using palmprint and hand geometry biometric. In International Con-
ference on Audio-and Video-Based Biometric Person Authentication. Springer.
[15] Jonathan Lester, Blake Hannaford, and Gaetano Borriello. 2004. “Are You with
Me?”–Using Accelerometers to Determine If Two Devices Are Carried by the
Same Person. In PerCom. Springer.
[16] Jaime Lien, Nicholas Gillian, M Emre Karagozler, Patrick Amihood, Carsten
Schwesig, Erik Olson, Hakim Raja, and Ivan Poupyrev. 2016. Soli: Ubiquitous
gesture sensing with millimeter wave radar. ACM Transactions on Graphics (TOG)
35, 4 (2016), 142.
[17] Jiayang Liu, Lin Zhong, Jehan Wickramasuriya, and Venu Vasudevan. 2009.
uWave: Accelerometer-based personalized gesture recognition and its applica-
tions. Pervasive and Mobile Computing (2009).
[18] Duo Lu. 2021. 3D In-Air-Handwriting based User Login and Identity Input Method.
Ph.D. Dissertation. Arizona State University.
[21] Duo Lu, Kai Xu, and Dijiang Huang. 2017. A Data Driven In-Air-Handwriting
Biometric Authentication System. In IJCB. IEEE.
[22] Alessandra Lumini and Loris Nanni. 2017. Overview of the combination of
biometric matchers. Information Fusion (2017).
[23] Rene Mayrhofer and Hans Gellersen. 2007. Shake well before use: Authentication
based on accelerometer data. In PerCom. Springer.
[24] Ben Nassi, Alona Levy, Yuval Elovici, and Erez Shmueli. 2016. Handwritten
Signature Verification Using Hand-Worn Devices. arXiv:1612.06305 (2016).
[25] George E Raptis, Christina Katsini, Andrew Jian-Lan Cen, Nalin Asanka Gam-
agedara Arachchilage, and Lennart E Nacke. 2021. Better, Funner, Stronger: A
Gameful Approach to Nudge People into Making Less Predictable Graphical
Password Choices. In Proceedings of the 2021 CHI Conference on Human Factors
in Computing Systems. 1–17.
[26] Napa Sae-Bae, Nasir Memon, Katherine Isbister, and Kowsar Ahmed. 2014. Mul-
titouch gesture-based authentication. IEEE transactions on information forensics
and security 9, 4 (2014), 568–582.
[27] Napa Sae-Bae, Jonathan Wu, Nasir Memon, Janusz Konrad, and Prakash Ishwar.
2019. Emerging NUI-Based Methods for User Authentication: A New Taxonomy
and Survey. IEEE Transactions on Biometrics, Behavior, and Identity Science (2019).
[28] Hasan Sajid and S Cheung Sen-ching. 2015. VSig: Hand-gestured signature
recognition and authentication with wearable camera. In International Workshop
on Information Forensics and Security (WIFS). IEEE.
[29] Raul Sanchez-Reillo, Carmen Sanchez-Avila, and Ana Gonzalez-Marcos. 2000. Bio-
metric identification through hand geometry measurements. IEEE Transactions
on pattern analysis and machine intelligence (2000).
[30] Xiaoyuan Suo, Ying Zhu, and G Scott Owen. 2005. Graphical passwords: A
survey. In 21st Annual Computer Security Applications Conference (ACSAC’05).
IEEE, 10–pp.
[19] Duo Lu, Dijiang Huang, Yuli Deng, and Adel Alshamrani. 2018. Multifactor User
Authentication with In-Air-Handwriting and Hand Geometry. In 2018 Interna-
tional Conference on Biometrics (ICB). IEEE.
[20] Duo Lu, Dijiang Huang, and Anshul Rai. 2019. FMHash: Deep Hashing of In-Air-
Handwriting for User Identification. (2019).
Figure 13: Performance change of the T-Fusion method with
respect to the number of negative training samples.
[31] Jing Tian, Chengzhang Qu, Wenyuan Xu, and Song Wang. 2013. KinWrite:
Handwriting-Based Authentication Using Kinect.. In NDSS.
[32] Ruben Tolosana, Ruben Vera-Rodriguez, Julian Fierrez, and Javier Ortega-Garcia.
IEEE Transactions on
2021. DeepSign: Deep on-line signature verification.
Biometrics, Behavior, and Identity Science 3, 2 (2021), 229–239.
[33] Frank Weichert, Daniel Bachmann, Bartholomäus Rudak, and Denis Fisseler. 2013.
Analysis of the accuracy and robustness of the leap motion controller. Sensors
13, 5 (2013), 6380–6393.
[34] Susan Wiedenbeck, Jim Waters, Jean-Camille Birget, Alex Brodskiy, and Nasir
Memon. 2005. PassPoints: Design and longitudinal evaluation of a graphical
password system. International journal of human-computer studies 63, 1-2 (2005),
102–127.
[35] Jonathan Wu, James Christianson, Janusz Konrad, and Prakash Ishwar. 2015.
Leveraging shape and depth in user authentication from in-air hand gestures. In
International Conference on Image Processing (ICIP). IEEE.
[36] Jonathan Wu, Janusz Konrad, and Prakash Ishwar. 2013. Dynamic time warping
for gesture-based user identification and authentication with Kinect. In Interna-
tional Conference on Acoustics, Speech and Signal Processing. IEEE.
[37] Yulong Yang, Gradeigh D Clark, Janne Lindqvist, and Antti Oulasvirta. 2016.
Free-form gesture authentication in the wild. In Proceedings of the 2016 CHI
Conference on Human Factors in Computing Systems. 3722–3735.
[38] Alexandros Zaharis, Adamantini Martini, Panayotis Kikiras, and George Sta-
moulis. 2010. User authentication method and implementation using a three-axis
accelerometer. In International Conference on Mobile Lightweight Wireless Sys-
tems.
APPENDICES
A ANALYSIS ON FEATURE FUSION
One question is whether the weights learned from other accounts
only work for those accounts in T-Fusion and S-Fusion instead
of general random guessing attacks. To answer this, we conduct
another set of experiments where fewer randomly selected negative
training samples are used to learn the weights at registration. The
results are shown in Figure 13. The performance degrades slightly
with less negative training sample. However, even if signals from
most of the other accounts are not observed in training, the match-
ing algorithm can still work. One possible explanation is that the
element-wise distances are generally large for negative training
samples, and they form similar cluster patterns in high dimensional
feature space as Figure 7. Hence, a linear maximum margin decision
plane fitted from training data (i.e., SVM) is relatively robust with
the variation of the cluster shape. This also explains why we can
obtain reasonably good performance with only five positive train-
ing samples. We believe this is the advantage of template matching
based methods since the system only needs to calculate a rough
480ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Duo Lu, Yuli Deng, and Dijiang Huang
Figure 14: User evaluation results.
are the same, or it is difficult to decide which one is better or
worse, (c) our framework is worse. The results are shown in Figure
14 (right). We can see that the user has a mixed attitude on the
usability compared to traditional password, but our framework can
not replace biometrics like fingerprint and face for device unlock.
However, the majority of the users feel that our framework is more
secure than traditional password, and more than half of them feel
it is more secure than fingerprint and face.
Third, we ask the following questions:
1) Compared to password, our framework considers both hand-
writing content and handwriting style, i.e., combining a password
and a biometric trait. Is this feature important for a user authenti-
cation system?
2) Compared to biometrics, our framework allows change and
revoke the in-air-handwriting passcode, which is unlinked to per-
sonal identity. Is this feature important for a user authentication
system?
Among the surveyed users, 89% and 82% of them answer “impor-
tant” for the first and second features respectively. Combined with
the previous results, we can conclude that our framework does not
intend to replace existing password-based solution or biometrics.
Instead, due to its unique features that passwords and biometrics
lack, we believe that our framework is suitable in scenarios where
such features matter and where passwords and biometrics are not
applicable, for example, login over gesture interface on VR headset
or in operating theater.
At last, we ask the user which type of device is preferred between
a wearable device and a contactless device for hand motion tracking.
21% of the users choose the wearable device and the other 79%
choose the contactless device.
decision boundary relative to the template (which is generally easy),
rather than learning a model that must “remember” the templates
as in Hidden Markov Model or deep neural network-based methods
(which is generally hard). In fact, we tried a deep neural network,
but the performance is inferior. However, since the templates are
stored and retrieved in alignment, they are similar to plain text
passwords and cannot be hashed.
B USER EVALUATION
We investigated the usability of our framework by taking question-
naire from 100 users participated in the collection of dataset 1. Each
user is asked to submit a questionnaire.
First, the users evaluate various aspects of our in-air-handwriting
based login framework by putting down a score from 1 (strongly
disagree) to 5 (strongly agree) on the following statements. In these
statements, “the user” refers to the user taking this questionnaire.
The users are required to provide these scores based on their sub-
jective feeling.
(1) Since the passcode string is created by the user, the passcode
content is easy to memorize.
(2) From the perspective of a stranger, the passcode content
created by the user is difficult to guess.
(3) The passcode content is difficult to leak visually, i.e., it is
difficult to guess the passcode content based on the in-air-
handwriting movements.
(4) From the perspective of an imposter, it is difficult to mimic
the in-air-handwriting movements after seen them.
(5) It is easy to learn and register with our in-air-handwriting
(6) It is fast to login through our in-air-handwriting based login
based login framework.
framework.
(7) It is easy to update or revoke the passcode if the user forgets
it or if the user wants to change it.
(8) The user prefers to use it as the primary login method through
a gesture input interface.
The results are shown in Figure 14 (left). Overall, users feel
positive regarding our framework, although the usability is not
exceptionally good in a few aspects.
Second, we ask the user to compare our framework with the
password-based systems and biometrics including fingerprint and
face. The comparison is made on three aspects, the easiness of usage,
login speed, and security based on the feeling of users. The user
has three options: (a) our framework is better, (b) both methods
481