title:Recognizing Functions in Binaries with Neural Networks
author:Eui Chul Richard Shin and
Dawn Song and
Reza Moazzezi
Recognizing Functions in Binaries 
with Neural Networks
Eui Chul Richard Shin, Dawn Song, and Reza Moazzezi, University of California, Berkeley
https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/shin
This paper is included in the Proceedings of the 24th USENIX Security SymposiumAugust 12–14, 2015 • Washington, D.C.ISBN 978-1-939133-11-3Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXRecognizing Functions in Binaries with Neural Networks
Eui Chul Richard Shin, Dawn Song, and Reza Moazzezi
University of California, Berkeley
{ricshin, dawnsong, rezamoazzezi}@berkeley.edu
Abstract
Binary analysis facilitates many important applications
like malware detection and automatically ﬁxing vulner-
able software.
In this paper, we propose to apply ar-
tiﬁcial neural networks to solve important yet difﬁcult
problems in binary analysis. Speciﬁcally, we tackle the
problem of function identiﬁcation, a crucial ﬁrst step
in many binary analysis techniques. Although neural
networks have undergone a renaissance in the past few
years, achieving breakthrough results in multiple appli-
cation domains such as visual object recognition, lan-
guage modeling, and speech recognition, no researchers
have yet attempted to apply these techniques to problems
in binary analysis. Using a dataset from prior work, we
show that recurrent neural networks can identify func-
tions in binaries with greater accuracy and efﬁciency than
the state-of-the-art machine-learning-based method. We
can train the model an order of magnitude faster and eval-
uate it on binaries hundreds of times faster. Furthermore,
it halves the error rate on six out of eight benchmarks,
and performs comparably on the remaining two.
1
Introduction
Binary analysis enables many useful applications in
computer security, given the plethora of possible situ-
ations in which the original high-level source code is
unavailable, has been lost, or is otherwise inconvenient
to use. For example, detection of malware, hardening
software against common vulnerabilities, and protocol
reverse-engineering are most useful when the procedures
involved can directly operate on binaries.
The central challenge of binary analysis is perhaps the
lack of high-level semantic structure within binaries, as
compilers discard it from the source code during the pro-
cess of compilation. Malware authors often go a step fur-
ther and obfuscate their output in an attempt to frustrate
any possible analysis by researchers.
Functions are a seemingly basic yet fundamental piece
of structure in all programs, but most binaries come as an
undifferentiated sequence of machine-language instruc-
tions without any information about how parts group
into functions. Therefore, the many binary analysis
techniques which rely on function boundary information
must ﬁrst attempt to recover it through function identi-
ﬁcation. For instance, function identiﬁcation can assist
the addition of control-ﬂow integrity enforcement to bi-
naries, in restricting jumps appropriately. Similarly, de-
compilers and debuggers need to know the locations of
functions to provide useful output to the user [2].
Several previous works have attempted the function
identiﬁcation task, ranging from simple heuristics to ap-
proaches using machine learning. The problem might
seem simple at ﬁrst glance, but Bao et al. showed with
ByteWeight [2], a recently-proposed machine-learning-
based approach, that the simpler techniques used by pop-
ular tools like IDA Pro and the CMU Binary Analysis
Platform have relatively poor accuracy. By construct-
ing signatures of function starts as weighted preﬁx trees,
ByteWeight greatly improves on the accuracy of function
identiﬁcation results compared to past work. Neverthe-
less, it leaves much room for improvement, especially
in terms of computational efﬁciency: the authors report
that training on their dataset of 2,064 binaries required
587 compute-hours, whereas running the method on the
dataset took on the order of several compute-days. Also,
while ByteWeight achieves about 98% accuracy on some
benchmarks, it performs at just 92-93% on some others.
In this paper, we propose a new approach to function
identiﬁcation leveraging artiﬁcial neural networks. First
proposed in the 1940s, artiﬁcial neural networks arose
as a simple approximation of interconnected biological
neurons in the central nervous systems of animals, and
have remained an active area of of research since then.
However, in the past few years, neural networks have
experienced a signiﬁcant surge in popularity (often un-
der the name “deep learning”), largely been driven by
USENIX Association  
24th USENIX Security Symposium  611
new empirical results. The vastly larger amounts of pro-
cessing power and storage available today enabled re-
searchers to train much larger networks containing many
more stages of processing (hence the “deep” appellation)
and parameters than before, making full use of the mas-
sive labeled datasets available today; these factors have
led to repeated breakthroughs in benchmarks of the com-
puter vision and speech recognition communities, among
others.
We note some attractive features of neural networks.
First, they can learn directly from the original represen-
tation with minimal preprocessing (or “feature engineer-
ing”) needed. As an example, the preprocessing for im-
ages might discard information about the precise shad-
ing of objects; for binaries, Bao et al. disassembles the
code into instructions and removes immediate operands
from them. Second, neural networks can learn end-to-
end, where each of its constituent stages are trained si-
multaneously in order to best solve the end goal. In con-
trast, other state-of-the-art approaches to tasks like ma-
chine translation or question answering use pipelines of
discrete components trained separately at an unrelated
task, such as parsers or part-of-speech taggers. Empir-
ical evidence suggests that end-to-end learning enables
each stage to directly learn the intermediate representa-
tions necessary to solve the task, with less need for pre-
conceived notions (such as syntax trees) about what they
should look like.
Given the success that neural networks have shown in
other applications, we raise the question of whether they
would also prove adept at problems in binary analysis,
such as function identiﬁcation. Our search turned up no
other works which attempted using neural networks to
solve problems in binary analysis. Nevertheless, our ex-
perimental results show that they can successfully solve
the function identiﬁcation task accurately and efﬁciently.
If the experience in other ﬁelds can serve as a guide, they
may also prove useful for more complicated tasks in pro-
gram and binary analysis, especially for those which re-
quire complicated modeling or analysis difﬁcult to spec-
ify by hand. Furthermore, advances with neural networks
in other applications might prove directly adaptable and
lead to “free” gains in performance; this work certainly
relies on general advances within neural networks tar-
geted at entirely different applications.
With our proposed solution, we train a recurrent neu-
ral network to take bytes of the binary as input, and pre-
dict, for each location, whether a function boundary is
present at that location. We found that we did not need
to perform any preprocessing, such as disassembly or
normalization of immediates, in order to obtain good re-
sults. We evaluate our approach using the dataset pro-
vided by Bao et al. [2], enabling a direct comparison.
We found that recurrent neural networks can learn much
more efﬁciently than ByteWeight, which reported using
587 compute-hours; we can train on the same dataset
in 80 compute-hours, while achieving similar or better
accuracy. Testing the method on the dataset takes only
about 43 minutes of computation, whereas Bao et al. [2]
reported needing over 2 weeks.
In the rest of the paper, we ﬁrst precisely deﬁne the
problem at hand. We explain the necessary background
in neural networks, and describe the particular architec-
ture we chose to use for our method. We give the re-
sults of our empirical evaluation, describe some related
works in the areas of function identiﬁcation and neural
networks, and then conclude with some discussion.
We make the following contributions in this paper:
• We ﬁnd that neural networks are a viable approach
towards solving some problems in binary analysis.
• In particular, we show that recurrent neural net-
works can solve the function identiﬁcation problem
more efﬁciently than the previous state-of-the-art,
as shown by empirical evaluation on a dataset con-
sisting of multiple operating systems, architectures,
compilers, and compiler options.
• We describe the challenges we faced in correctly ap-
plying neural networks to this problem, and how to
address them.
2 Problem Deﬁnition
We ﬁrst deﬁne notation so that we can precisely deﬁne
the function identiﬁcation task that we address in this
paper. We then provide a formal deﬁnition of function
identiﬁcation.
2.1 Notation
We concern ourselves with the machine code contained
within a program binary or library. A typical exe-
cutable contains many different sections containing var-
ious information in addition to the code: for example,
dynamically-linked libraries to load, constant strings,
and statically-allocated variables, all of which we ignore.
We treat the code C itself as a sequence of bytes
C[0],C[1],··· ,C[l], where C[i] ∈ Z256 is the ith byte in
the sequence. We denote the n functions in the binary
as f1,··· , fn. We label the indices of the bytes of code
which belong to each function fi (i.e., the bytes corre-
sponding to instructions which might get executed while
running that function) as fi,1,··· , fi,li, where li is the to-
tal number of bytes in fi. Without loss of generality, we
assume fi,1 :
0000000000400830 :
int b0 = b, t, q;
int x0 = 0, x1 = 1;
if (b == 1) return 1;
while (a > 1) {
q = a / b;
t = b, b = a % b, a = t;
t = x0, x0 = x1 - q * x0, x1 = t;
}
if (x1 
-0xc(%rbp),%eax
%eax,-0x8(%rbp)
-0x8(%rbp),%eax
%rbp
(a) A C function which computes the
modular multiplicative inverse.
(b) Compiled with gcc -O0.
400830: cmp
400833: mov
400835: je
400837: cmp
40083a: jle
40083c: mov
40083e: mov
400844: xor
400846: jmp
400848: nopl
40084f:
...
400869: jg
40086b: add
40086d: mov
40086f: test
400871: cmovs
400874: retq
400875: nopl
400878: mov
40087d: retq
40087e: xchg
$0x1,%esi
%edi,%eax
400878 
$0x1,%edi
400878 
%esi,%ecx
$0x1,%r8d
%edi,%edi
400855 
0x0(%rax,%rax,1)
400850 
%edi,%esi
%edi,%eax
%edi,%edi
%esi,%eax
(%rax)
$0x1,%eax
%ax,%ax
(c) Compiled with gcc -O3. Function
ends at 40087d; 40087e is padding be-
tween this function and the next one.
Figure 1: An example function in C (taken from http://rosettacode.org/wiki/Modular_inverse#C), and its