in parallel. Their evaluation of the countermeasures only
considered their attack, and the results indicate that the
countermeasures provide improved TA resistance to it.
Hintz [9] discussed a simple attack for identifying which
of ﬁve popular web pages was visited over a single-hop
proxy service called SafeWeb. The proposed attack does
not require exact knowledge of web request sizes, but there
is little evaluation and it remains unclear how the attack
would fair with larger privacy sets.
Bissias et al. [1] demonstrated a weaker adversary than
that of Sun et al. [15], which could observe an SSH tunnel
and view only the length, direction, and timing of each
ciphertext transmitted, rather than web page objects. They
used cross-correlation to determine webpage similarity,
which is a metric commonly used for evaluating the simi-
larity of two time series. They achieved worse performance
than the classiﬁers we consider, and they did not explore
any countermeasures.
Liberatore and Levine [10] showed that it is possible
to infer the contents of an HTTP transaction encapsulated
in an SSH connection by observing only encrypted packet
lengths and the directions of unordered packets. We pro-
vided a detailed description of their classiﬁer in section III,
and we use their publicly-available dataset in our analy-
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:30 UTC from IEEE Xplore.  Restrictions apply. 
ses. They quantify the ability of several countermeasures,
including Linear, Exponential, Mice-Elephants, and Pad to
MTU padding schemes, to protect against their attack, but
only report on a privacy set size of k = 1000. These results
cast a positive light on some padding approaches, like Pad
to MTU, which reduces the accuracy of their proposed
classiﬁer from 68% to around 7%. We did not consider
k = 1000 in order to ensure consistency with other datasets
in our evaluation, but projecting out from the observed
trends we expect that, for example, the VNG++ classiﬁer
will do signiﬁcantly better than 7% at k = 1000 (c.f.,
Figure 9).
Herrmann et al. [8] collected encrypted traces from four
different types of single-hop encryption technologies, and
two multi-hop anonymity networks. We use a portion of
their dataset for our analyses. They were the ﬁrst to suggest
the use of a multinomial na¨ıve Bayes classiﬁer for trafﬁc
classiﬁcation that examines normalized packet counts. A
discussion of their classiﬁer was given in Section III.
Their evaluation of countermeasures was restricted to
application-layer countermeasures.
Panchenko et al. [14] presented a support vector ma-
chine classiﬁer as an improvement upon the work of
Herrmann et al. [8]. We discussed details of the Panchenko
classiﬁer in Section III. They apply it to Tor [6] trafﬁc
they generated in both a closed-word and open-world
setting, showing good accuracy, though worse than those
that the classiﬁers we consider achieve. Tor’s encryption
mechanisms already obfuscate some information about
plaintext lengths, making it harder, in general, to classify.
They did not report on their classiﬁer’s efﬁcacy against the
countermeasures we consider.
In an effort to minimize overhead incurred by previously
suggested padding schemes, Wright et al. proposed the
notion of trafﬁc morphing [22]. Their countermeasures
can minimize overhead while still making one web page
“look” like another with respect to speciﬁc features. As
Wright et al. suggested [22, Section 4.1], and Lu et al. later
conﬁrmed with their experimental evaluation [11], trafﬁc
morphing is only effective when the attacker restricts
attention to the same feature(s) targeted by the morphing
routine. Our results likewise indicate that attackers can still
succeed even when trafﬁc morphing is used to ensure the
normalized distribution of packet sizes is similar to some
target web page.
non-sequentially. They evaluate their countermeasure in
the presence of four existing classiﬁers [1, 3, 10, 15] and
show that HTTPOS is effective against all of them. We do
not consider these kinds of application-layer mechanisms,
and indeed our results suggest that such countermeasures
may be better positioned to defend against web page
identiﬁcation attacks.
IX. CONCLUDING DISCUSSION
Although a signiﬁcant amount of previous work has
investigated the topic of TA countermeasures, and speciﬁ-
cally the case of preventing website identiﬁcation attacks,
the results were largely incomparable due to differing
experimental methodology and datasets. Our work syn-
thesizes and expands upon previous ones, and it provides
sharper answers to some of the area’s central questions:
Do TA countermeasures prevent website ﬁngerprinting?
None of the nine countermeasures considered here pre-
vents the kind of website ﬁngerprinting attack addressed
by prior works [8, 10, 14, 22]. From a security perspective
this setting is conservative, and makes several simplifying
assumptions. (The attacker knows the privacy set; it trains
and tests on trafﬁc generated in the same way; the collected
trafﬁc does not account for (potentially) confounding ef-
fects, such as browser caching, interleaved web requests,
etc.) Nevertheless, our negative results suggest that one
should not rely solely upon these countermeasures to
prevent website ﬁngerprinting attacks.
Do TA attacks require individual packet lengths? No. We
implemented three coarse-feature classiﬁers: one using
only total time as a feature, one using only total per-
direction bandwidth, and one tracking only data bursts
(the VNG classiﬁer). These did not make direct use of
individual packet lengths or packet counts as features, yet
attained high accuracy against the countermeasures. This
highlights the point that masking ﬁne-grained information
is insufﬁcient, unless such masking also hides telling large-
scale features (e.g., individual object requests, size of web
objects, etc.).
Does classiﬁcation engine matter? Our experiments sug-
gest it is the features, and not the underlying classiﬁcation
engine, that matters. We implemented a na¨ıve Bayes-based
classiﬁer that used the same features as those exploited by
the SVM-based Panchenko et al. classiﬁer, and our exper-
iments show that these two perform almost identically.
Does the privacy-set size (k) matter? For the considered
setting, it seems not to matter much. When no countermea-
sure is used, attacks can achieve roughly the same accuracy
for k = 2 through k = 775. When countermeasures are
applied, the best classiﬁer’s accuracy does drop slowly
as k increases. This suggests that the countermeasures do
obfuscate some features that can improve accuracy. That
said, at the largest k, the best classiﬁers offer better than
60% accuracy against all of the countermeasures.
Both Panchenko et al. [14] and Luo et al. [12] suggest
concrete application-layer countermeasures. Panchenko et
al. propose the Camouﬂage countermeasure, which makes
spurious HTTP requests in parallel with legitimate ones,
and show that it renders their classiﬁer signiﬁcantly less
effective. The Luo et al. system is called HTTPOS and uses
a number of client-side mechanisms that take advantage of
existing HTTP functionality to add noise to encrypted web
trafﬁc. For example, HTTPOS randomizes HTTP GET re-
quests by adding superﬂuous data to headers and utilizing
HTTP byte range functionality to request subsets of data
344
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:30 UTC from IEEE Xplore.  Restrictions apply. 
Our work paints a pretty negative picture of the use-
fulness of efﬁcient, low-level TA countermeasures against
website-ﬁngerprinting attacks. But pessimism need not
prevail. Future work could investigate more detailed mod-
elings of real-world trafﬁc, and investigate applications of
TA countermeasures beyond website ﬁngerprinting. This
may uncover settings in which some countermeasures are
more successful than they were in our experiments. In
addition, the coarse features (e.g. bandwidth) that appear
near impossible to obfuscate efﬁciently at the level of
individual packets might be better handled at the applica-
tion layer. Previous works [8, 12] suggest application-layer
countermeasures with promising initial evaluations. Future
work could provide more extensive investigation of such
countermeasures.
REFERENCES
[1] George Bissias, Marc Liberatore, David Jensen, and
Brian Neil Levine. Privacy Vulnerabilities in Encrypted
HTTP Streams. In Proceedings of the Privacy Enhancing
Technologies Workshop, pages 1–11, May 2005.
[2] Peter Chapman and David Evans. Automated Black-Box
Detection of Side-Channel Vulnerabilities in Web Applica-
tions. In Proceedings of the ACM Conference on Computer
and Communications Security, pages 263–274, November
2011.
[3] Shuo Chen, Rui Wang, XiaoFeng Wang, and Kehuan
Zhang. Side-Channel Leaks in Web Applications: a Reality
Today, a Challenge Tomorrow. In Proceedings of the IEEE
Symposium on Security and Privacy, pages 191–206, May
2010.
[4] Heyning Cheng and Ron Avnur.
Trafﬁc Analysis
of SSL Encrypted Web Browsing, December 1998.
at: http://www.cs.berkeley.edu/∼daw/teaching/
Available
cs261-f98/projects/ﬁnal-reports/ronathan-heyning.ps.
[5] Tim Dierks and Eric Rescorla.
The Transport Layer
Security (TLS) Protocol Version 1.2. RFC 5246, August
2008. Updated by RFCs 5746, 5878, 6176. Available at:
http://www.ietf.org/rfc/rfc5246.txt.
[6] Roger Dingledine, Nick Mathewson, and Paul Syverson.
Tor: The second-generation onion router. In Proceedings of
the 13th conference on USENIX Security Symposium, pages
303–320, 2004.
[7] Xinwen Fu, Bryan Graham, Riccardo Bettati, Wei Zhao,
and Dong Xuan. Analytical and Empirical Analysis of
Countermeasures to Trafﬁc Analysis Attacks. In Proceed-
ings of the International Conference on Parallel Processing,
pages 483–492, October 2003.
[8] Dominik Herrmann, Rolf Wendolsky, and Hannes Feder-
rath. Website Fingerprinting: Attacking Popular Privacy
Enhancing Technologies with the Multinomial Naive-Bayes
Classiﬁer. In Proceedings of the ACM Workshop on Cloud
Computing Security, pages 31–42, November 2009.
[9] Andrew Hintz. Fingerprinting Websites Using Trafﬁc Anal-
ysis. In Proceedings of the Privacy Enhancing Technologies
Workshop, pages 171–178, April 2002.
Inferring the
[10] Marc Liberatore and Brian Neil Levine.
Source of Encrypted HTTP Connections.
In Proceedings
of the ACM Conference on Computer and Communications
Security, pages 255–263, November 2006.
[11] Liming Lu, Ee-Chien Chang, and Mun Chan. Website
Fingerprinting and Identiﬁcation Using Ordered Feature
Sequences. In Proceedings of the European Symposium on
Research in Computer Security, volume 6345 of Lecture
Notes in Computer Science, pages 199–214, September
2010.
[12] Xiapu Luo, Peng Zhou, Edmond W. W. Chan, Wenke Lee,
Rocky K. C. Chang, and Roberto Perdisci. HTTPOS:
Sealing Information Leaks with Browser-side Obfuscation
of Encrypted Flows.
In Proceedings of the Network and
Distributed Security Symposium, February 2011.
[13] Tom M. Mitchell. Machine Learning. McGraw-Hill, New
York, 1997.
[14] Andriy Panchenko, Lukas Niessen, Andreas Zinnen, and
Thomas Engel. Website Fingerprinting in Onion Routing-
based Anonymization Networks.
In Proceedings of the
Workshop on Privacy in the Electronic Society, pages 103–
114, October 2011.
[15] Qixiang Sun, Daniel R. Simon, Yi-Min Wang, Wilf Russell,
Venkata N. Padmanabhan, and Lili Qiu. Statistical Identiﬁ-
cation of Encrypted Web Browsing Trafﬁc. In Proceedings
of the IEEE Symposium on Security and Privacy, pages 19–
30, May 2002.
[16] David Wagner and Bruce Schneier. Analysis of the SSL
3.0 Protocol. In Proceedings of the USENIX Workshop on
Electronic Commerce, pages 29–40, November 1996.
[17] Wei Wang, Mehul Motani, and Vikram Srinivasan. Depen-
dent Link Padding Algorithms for Low Latency Anonymity
Systems.
the ACM Conference on
Computer and Communications Security, pages 323–332,
November 2008.
In Proceedings of
[18] Andrew M. White, Austin R. Matthews, Kevin Z. Snow, and
Fabian Monrose. Phonotactic Reconstruction of Encrypted
VoIP Conversations: Hookt on fon-iks. In Proceedings of
the IEEE Symposium on Security and Privacy, pages 3–18,
May 2011.
[19] Charles V Wright, Lucas Ballard, Scott E. Coull, Fabian
Monrose, and Gerald M Masson. Spot Me if You Can:
Uncovering Spoken Phrases in Encrypted VoIP Conversa-
tions. In Proceedings of the IEEE Symposium on Security
and Privacy, pages 35–49, May 2008.
[20] Charles V. Wright, Lucas Ballard, Scott E. Coull, Fabian
Monrose, and Gerald M. Masson. Uncovering Spoken
Phrases in Encrypted Voice over IP Conversations. ACM
Transactions on Information and Systems Security, 13:1–30,
December 2010.
[21] Charles V. Wright, Lucas Ballard, Fabian Monrose, and
Gerald M. Masson. Language identiﬁcation of encrypted
VoIP trafﬁc: Alejandra y Roberto or Alice and Bob? In
Proceedings of the USENIX Security Symposium, pages 1–
12, August 2007.
[22] Charles V. Wright, Scott E. Coull, and Fabian Monrose.
Trafﬁc Morphing: An Efﬁcient Defense Against Statistical
Trafﬁc Analysis.
the Network and
Distributed Security Symposium, pages 237–250, February
2009.
In Proceedings of
[23] Ye Zhu, Xinwen Fu, Bryan Graham, Riccardo Bettati, and
Wei Zhao. On Flow Correlation Attacks and Countermea-
sures in Mix Networks.
In Proceedings of the Privacy
Enhancing Technologies Workshop, volume 3424 of Lecture
Notes in Computer Science, pages 207–225, May 2004.
345
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:30 UTC from IEEE Xplore.  Restrictions apply. 
APPENDIX
Countermeasure
None
Session Random 255
Packet Random 255
Pad to MTU
Packet Random MTU
Exponential
Linear
Mice-Elephants
Direct Target Sampling
Trafﬁc Morphing
LL
98.1 ± 0.1
40.7 ± 0.3
80.6 ± 0.4
63.1 ± 0.5
45.8 ± 0.4
95.4 ± 0.2
96.6 ± 0.2
84.8 ± 0.4
25.1 ± 0.6
31.0 ± 0.7
H
98.9 ± 0.1
13.1 ± 0.2
40.1 ± 0.3
4.7 ± 0.1
11.2 ± 0.2
72.0 ± 0.4
89.4 ± 0.2
20.9 ± 0.3
2.7 ± 0.1
6.3 ± 0.3
P
97.2 ± 0.2
90.6 ± 0.3
94.9 ± 0.3
89.8 ± 0.4
92.1 ± 0.3
96.6 ± 0.3
96.8 ± 0.2
94.5 ± 0.3
81.8 ± 0.5
88.7 ± 0.4
Classiﬁer
BW
80.1 ± 0.6