identiﬁed sites are related to input-related errors or occasional
errors. Table 1 shows the study results.
We ﬁnd that 42% of the sites that can fail and trigger error
handling code are related to occasional errors. Besides, in the
study, we also observe that about 70% of the identiﬁed error
sites are related to checking error-indicating return values of
function calls (such as the example in Figure 3). This observa-
tion indicates that manipulating the return values of speciﬁc
function calls can cover most error handling code, which has
been adopted by some existing SFI-based approaches [10,18].
USENIX Association
29th USENIX Security Symposium    2597
Application
vim
bison
ffmpeg
nasm
catdoc
clamav
cﬂow
gif2png+libpng
openssl
Total
Studied ﬁle
Error site
Input-related
100
100
100
100
29
100
100
95
100
824
1163
184
881
673
91
1089
286
830
989
6,168
530 (46%)
96 (52%)
518 (59%)
564 (84%)
43 (47%)
522 (48%)
170 (59%)
556 (67%)
571 (58%)
3,570 (58%)
Occasional
633 (54%)
88 (48%)
363 (41%)
109 (16%)
48 (53%)
567 (52%)
116 (41%)
274 (33%)
418 (42%)
2,616 (42%)
Table 1: Study results of error handling code.
Tool
AFL
Honggfuzz
AFLFast
CollAFL
QSYM
REDQUEEN
Total
CVE
218
57
8
93
6
11
393
Error handling
Occasional error
85
17
2
15
0
2
121
3
3
0
4
0
1
11
Table 2: Study results of existing fuzzing tools.
2.4 Study of CVEs Found by Existing Fuzzing
To understand how existing fuzzing tools perform in detecting
bugs in error handling code, we further study the CVEs found
by some start-of-the-art fuzzing tools, including AFL [1],
Honggfuzz [30], AFLFast [13], CollAFL [26], QSYM [65]
and REDQUEEN [7]. We select these fuzzing tools because
CVEs found by them are publicly available. Speciﬁcally, for
AFL, a website [2] collects its found CVEs; for Honggfuzz,
the found CVEs are listed in its homepage; for AFLFast, Col-
lAFL, QSYM and REDQUEEN, the found CVEs are listed in
their papers as well. We manually read these CVEs and iden-
tify the ones related to error handling code, and also check
whether the identiﬁed CVEs are related to occasional errors.
Table 2 shows the study results.
We ﬁnd that 31% of CVEs found by these fuzzing tools
are caused by incorrect error handling code, such as the bug
shown in Figure 2. Only 9% of these CVEs are related to oc-
casional errors. This proportion is far less than the proportion
(42%) of occasional error sites among all error sites (found in
Section 2.3). The results indicate that existing fuzzing tools
may have missed many real bugs in error handling code trig-
gered by occasional errors. Thus, it is important to improve
fuzzing to support the testing of error handling code.
3 Basic Idea and Approach
3.1 Basic Idea
To effectively test error handling code, we introduce SFI in
fuzz testing by “fuzzing” injected faults according to the run-
time information of the tested program. To achieve this idea,
we build an error sequence that contains multiple error points.
An error point represents an execution point where an error
can occur and trigger error handling code. When performing
fault injection, each error point in an error sequence can nor-
mally run (indicated as 0) or fail by injecting a fault (indicated
as 1). Thus, an error sequence is actually as 0-1 sequence that
describes the failure situation of error points at runtime:
ErrSeq = [ErrPt1,ErrPt2, ...,ErrPtx], ErrPti = {0,1} (1)
Similar to program inputs, an error sequence also affects
program execution. This sequence can be regarded as the
“input” of possibly triggered errors. A key problem here is
which error points in an error sequence should be injected
with faults to cover as much error handling code as possible.
Inspired by existing fuzzing that fuzz program inputs using
the feedback of program execution, our basic idea is to fuzz
error sequence for fault injection to test error handling code.
3.2 Error Sequence Model
Existing SFI-based approaches often use context-insensitive
fault injection. Speciﬁcally, they only use the location of each
error site in source code to describe an error point, namely
ErrPt = , without considering the execution context
of this error site. In this way, if an fault is injected into an
error site, this error site will always fail when being executed
at runtime. However, an error site can be executed in different
calling contexts, and some real bugs (such as the double-free
bug shown in Figure 1) can be triggered only when this error
site only fails in speciﬁc calling context and succeeds in other
calling contexts. Thus, existing SFI-based approaches may
miss these real bugs.
To solve this problem, we propose a context-sensitive soft-
ware fault injection (SFI) method. Besides the location of
each error site, our method also considers the calling context
of the error site to describe error points, namely:
ErrPt =
(2)
To describe calling context of an error site, we consider
the runtime call stack when the error site is executed. This
runtime call stack includes the information of each function
call at the call stack (in order from caller to callee), including
the locations of this function call and called function. In this
way, a calling context is described as:
CallCtx = [CallIn f o1,CallIn f o2, ...,CallIn f ox]
CallIn f o =
(3)
(4)
Based on the above description, the information about each
error point can be hashed as a key, and whether this error point
should fail can be represented as a 0-1 value. Thus, an error
sequence can be stored as a key-value pair in a hash table:
2598    29th USENIX Security Symposium
USENIX Association
KEYVALUEHash(ErrPt1)0 or 1Hash(ErrPt2)0 or 1............Hash(ErrPtx)0 or 1Note that the runtime call stack of an executed error site is
related to program execution. Thus, error points cannot be stat-
ically determined, and they should be dynamically identiﬁed
during program execution. Accordingly, when performing
fault injection using error sequences, the faults should be
injected into error points during program execution.
According to our method, when an error site is executed
in N different calling contexts, there will be N different error
points for fault injection, instead of just one error point iden-
tiﬁed by context-insensitive fault injection. Thus, our method
can perform ﬁner-grained fault injection.
3.3 Context-Sensitive SFI-based Fuzzing
To effectively cover as much error handling code as possi-
ble, based on our context-sensitive SFI method, we propose
a novel context-sensitive SFI-based fuzzing approach to per-
form fault injection using the feedback of program execution.
As shown in Figure 4, our approach has six steps: 1) stati-
cally identifying the error sites in the source code of the tested
program; 2) running the tested program and collecting run-
time information about calling contexts of each executed error
site and code coverage; 3) creating error sequences about ex-
ecuted error sites according to runtime information; 4) after
running the program, mutating each created error sequence to
generate new sequences; 5) running the tested program and
injecting faults into error sites in speciﬁc calling contexts ac-
cording to the mutated error sequences; 6) collecting runtime
information, creating new error sequences and performing
mutation of these error sequences again, which constructs a
fuzzing loop. When no new error sequences are generated or
the time limit is reached, the fuzzing loop ends.
Figure 4: Procedure of our SFI-based fuzzing approach.
In our approach, mutating and generating error sequences
are important operations. Given a program input, our approach
considers code coverage in these operations and drops re-
peated error sequences. Initially such information is unavail-
able, and thus our approach performs a special initial mutation
for the ﬁrst execution of the tested program. For subsequent
executions, it performs the subsequent generation and mu-
tation of error sequences. All the generated error sequences
that increase code coverage are stored in a pool, and they
are ranked by contribution to code coverage. Our approach
preferentially selects error sequences for mutation.
Initial mutation. Our approach ﬁrst executes the tested pro-
gram normally, and creates an initial error sequence according
to runtime information. This error sequence contains executed
error points, and it is all-zero and used for the initial mutation.
The mutation generates each new error sequence by making
just one executed error point fail (0→1), as each error point
may trigger uncovered error handling code in related calling
context. Figure 5 shows an example of the initial mutation for
an error sequence, which generates four new error sequences.
Figure 5: Example of the initial mutation.
Subsequent generation and mutation. After executing the
tested program by injecting faults according to an original er-
ror sequence, some new error points may be executed, making
a new error sequence created. Our approach checks whether
the code coverage is increased (namely new basic blocks or
code branches are covered) during this execution. If not, the
original error sequence and the created error sequence (if it
exists) are dropped; if so, our approach separately mutates
the original error sequence and the created error sequence (if
it exists) to generate each new error sequence by changing
the value of just one error point (0→1 or 1→0). Then, our
approach compares these generated error sequences with ex-
isting error sequences, to drop repeated ones. Figure 6 shows
an example of this procedure for two error sequences, For
the ﬁrst error sequence ErrSeq1, a new error point ErrPtx is
executed, and thus our approach creates an error sequence
containing ErrPtx. As the code coverage is increased, our
approach mutates the two error sequences and generates nine
new error sequences. However, one of them is the same with
existing error sequence ErrSeq2, thus this new error sequence
is dropped. For the second error sequence ErrSeq2, a new
error point ErrPty is executed, and thus our approach creates
an error sequence containing ErrPty. As the code coverage is
not increased, our approach drops the two error sequences.
Note that each error point in an error sequence is related to
runtime calling context, thus when injecting faults into this
error point during program execution, our approach needs
to dynamically check whether the current runtime calling
context and error sites match the target error point. If this
error point is not executed during program execution, our
approach will ignore this error point.
USENIX Association
29th USENIX Security Symposium    2599
Fuzzing LoopNIdentify error sitesRun the tested programCreate error sequencesMutate error sequencesGenerate new error sequences andwithin time limit?EndCollect runtime informationRun the tested programPerform fault injectionYInitial error sequenceFirst executionInitial mutationGenerated error sequencesErrPta0ErrPtb0ErrPtc0ErrPtd0ErrPta1ErrPtb0ErrPtc0ErrPtd0ErrPta0ErrPtb1ErrPtc0ErrPtd0ErrPta0ErrPtb0ErrPtc1ErrPtd0ErrPta0ErrPtb0ErrPtc0ErrPtd1Tested ProgramFigure 7: Overall architecture of FIFUZZ.
4.1 Compile-Time Analysis
In this phase, FIFUZZ performs two main tasks:
Error-site extraction. For SFI-based approaches, the in-
jected errors should be realistic. Otherwise, the found bugs
might be false positives. To ensure that injected errors are real-
istic, many SFI-based approaches [18, 40, 55] require the user
to manually provide error sites, which requires much manual
work and cannot scale to large programs. To reduce manual
work, the error-site extractor uses a static analysis against the
source code of the tested program, to identify possible error
sites, from which the user can select realistic ones.
Our analysis focuses on extracting speciﬁc function calls as
error sites, because our study in Section 2.3 reveals that most
of error sites are related to checking error-indicating return
values of function calls. Our analysis has three steps:
S1: Identifying candidate error sites. In many cases, a func-
tion call returns a null pointer or negative integer to indicate a
failure. Thus, our analysis identiﬁes a function call as a candi-
date error site if: 1) it returns a pointer or integer; and 2) the
return value is checked by an if statement with NULL or zero.
The function call to av_frame_new_side_data in Figure 3 is
an example that satisﬁes the two requirements.
S2: Selecting library functions. A called function can be