title:Adversarial Traces for Website Fingerprinting Defense
author:Mohsen Imani and
Mohammad Saidur Rahman and
Matthew Wright
POSTER: Adversarial Traces for Website Fingerprinting Defense
Mohsen Imani
University of Texas at Arlington
PI:EMAIL
Mohammad Saidur Rahman
Rochester Institute of Technology
PI:EMAIL
Matthew Wright
Rochester Institute of Technology
PI:EMAIL
ABSTRACT
Website Fingerprinting (WF) is a traffic analysis attack that enables
an eavesdropper to infer the victim’s web activity even when en-
crypted and even when using the Tor anonymity system. Using
deep learning classifiers, the attack can reach up to 98% accuracy.
Existing WF defenses are either too expensive in terms of band-
width and latency overheads (e.g. 2-3 times as large or slow) or
ineffective against the latest attacks. In this work, we explore a
novel defense based on the idea of adversarial examples that have
been shown to undermine machine learning classifiers in other do-
mains. Our Adversarial Traces defense adds padding to a Tor traffic
trace in a manner that reliably fools the classifier into classifying
it as coming from a different site. The technique drops the accu-
racy of the state-of-the-art attack from 98% to 60%, while incurring
a reasonable 47% bandwidth overhead, showing its promise as a
possible defense for Tor.
KEYWORDS
Anonymity System; Privacy; Website Fingerprinting; Adversarial
Machine Learning; Defense
1 INTRODUCTION
Tor is known to be vulnerable to traffic analysis attacks. An ad-
versary who observes the both entry and exit sides of the traffic
on a Tor connection is able to correlate the traffic and link the
client to her destination. An adversary needs significant resources
to perform this attack reliably. A branch of traffic analysis that
requires fewer resources is Website Fingerprinting (WF). The goal of
the WF adversary is to identify which websites the client is visiting
by observing only the connection between the client and the guard,
as shown in Figure 1. This local passive adversary could be sniffing
the client’s wireless connection, have compromised her cable/DSL
modem, or gotten access to the client’s ISP or workplace network.
Figure 1: Website Fingerprinting Attack Model.
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
© 2018 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-5693-0/18/10.
https://doi.org/10.1145/3243734.3278493
The WF attack is a supervised classification problem, in which
the websites are the labels and each traffic trace is an instance to
be classified or trained on. The accuracy rate of the state-of-the-art
WF attack is 98% in a closed-world test [8].
In response to the threat of WF attacks, there have been several
defenses proposed [1, 2, 5–7, 11]. WF defenses try to change the
pattern of the traffic in a way that confounds the classifier. Tor traffic
is already divided into fixed-sized cells of 512 bytes, and the order
of objects requested from a site is randomized. The remaining ways
to modify traffic are to add padding packets and delay some packets.
The BuFLO family of defenses (including BuFLO [3], CS-BuFLO [1],
and Tamaraw [2]) apply these techniques and are effective, but make
loading a website take two or three times as long as in Tor. WTF-
PAD[4] offers lower overheads, but Sirinam et al. show an attack
that reaches 90% accuracy against it. The more recently proposed
Walkie-Talkie [10] is both effective and efficient, but there are major
challenges to practical deployment.
In this work, we introduce a new defense strategy using adver-
sarial examples generated by a deep neural network. We propose
a new method to modify the website traces that causes misclas-
sification in the classifier with moderate amounts of bandwidth,
even if the attacker is trained on the traces. Our defense drops the
accuracy rate of state-of-the-art attack from 98% to 60% with 47%
bandwidth overhead.
2 A NEW WF DEFENSE
We now introduce a new mechanism to perturb traffic traces such
that the classifier is not able to identify them reliably. We adapt the
idea of targeted adversarial examples [9]. To defend a given trace
(the source sample), our technique randomly picks a target sample
and gradually changes the source sample in a direction to get closer
to the target sample. Eventually, the sample has moved enough to
cause the classifier to misclassify it.
More concretely, assume that we have a set of sensitive sites
S that we want to protect and a model f (x) (called detector) that
is trained on a set of data from S (we will later discuss the cases
whether f (x) should be trained on only sensitive sites or both
sensitive and non-sensitive sites). We consider traffic trace Is as an
instance of source class s ∈ S that we want to alter such that it
is classified to target class t, t = f (Is) and t (cid:44) s. Is is a sequence
(cid:3). The only allowed operation on
of the bursts, Is =(cid:2)bI
0, bI
1, ..., bI
n
= bI
i
a burst, bI
i , is to add some positive values, δi >= 0, to that burst,
bI
+ δi. The reason for using δi >= 0 is that we want to
i
increase the volume of the bursts by sending dummy packets. If
δi  0
⩽ 0
s
where α is paramter that amplifies the output of the gradient. The
choice of α has an impact on the convergence and the bandwidth
overhead. If we pick large value for α, we will take bigger steps