title:Cruz: Application-Transparent Distributed Checkpoint-Restart on Standard
Operating Systems
author:G. John Janakiraman and
Jose Renato Santos and
Dinesh Subhraveti and
Yoshio Turner
Cruz: Application-Transparent Distributed Checkpoint-Restart 
on Standard Operating Systems 
G. (John) Janakiraman, Jose Renato Santos, Dinesh Subhraveti1, Yoshio Turner 
Internet Systems and Storage Laboratory  
HP Laboratories Palo Alto 
HPL-2005-66 
April 7, 2005* 
E-mail: {john.janakiraman,joserenato.santos,yoshio.turner}@hp.com 
checkpointing, 
snapshot, process 
migration, error 
recovery, 
availability 
requiring  application,
We  present  a  new  distributed  checkpoint-restart  mechanism,  Cruz,  that 
works  without 
library,  or  base  kernel 
modifications.  This  mechanism  provides  comprehensive  support  for
checkpointing  and  restoring  application  state,  both  at  user  level  and
within  the  OS.  Our  implementation  builds  on  Zap,  a  process  migration
mechanism, implemented as a Linux kernel module, which operates by
interposing  a  thin  layer  between  applications  and  the  OS.  In  particular,
we  enable  support  for  networked  applications  by  adding  migratable  IP 
and MAC addresses, and checkpoint-restart of socket buffer state, socket 
options,  and  TCP  state.  We  leverage  this  capability  to  devise  a  novel
method  for  coordinated  checkpoint-restart  that  is  simpler  than  prior 
approaches. For instance, it eliminates the need to flush communication 
channels  by  exploiting  the  packet re-transmission  behavior  of  TCP  and 
existing OS support for packet filtering. Our experiments show that the
overhead of coordinating checkpoint-restart is negligible, demonstrating 
the scalability of this approach. 
* Internal Accession Date Only 
 1Currently at Meiosys 
To be published in and presented at The International Conference on Dependable Systems and Networks (DSN-
2005), 28 June -1 July 2005, Yokohama, Japan 
© Copyright 2005 IEEE 
                          Approved for External Publication 
Cruz: Application-Transparent Distributed Checkpoint-Restart on Standard
Operating Systems
G. (John) Janakiraman
Jose Renato Santos
∗
Dinesh Subhraveti
Yoshio Turner
{john.janakiraman,joserenato.santos,yoshio.turner}@hp.com
Hewlett-Packard Laboratories
Abstract
We present a new distributed checkpoint-restart mech-
anism, Cruz, that works without requiring application, li-
brary, or base kernel modiﬁcations. This mechanism pro-
vides comprehensive support for checkpointing and restor-
ing application state, both at user level and within the
OS. Our implementation builds on Zap, a process migra-
tion mechanism, implemented as a Linux kernel module,
which operates by interposing a thin layer between applica-
tions and the OS. In particular, we enable support for net-
worked applications by adding migratable IP and MAC ad-
dresses, and checkpoint-restart of socket buffer state, socket
options, and TCP state. We leverage this capability to de-
vise a novel method for coordinated checkpoint-restart that
is simpler than prior approaches. For instance, it elimi-
nates the need to ﬂush communication channels by exploit-
ing the packet re-transmission behavior of TCP and existing
OS support for packet ﬁltering. Our experiments show that
the overhead of coordinating checkpoint-restart is negligi-
ble, demonstrating the scalability of this approach.
1. Introduction
Application checkpoint-restart mechanisms have the po-
tential to signiﬁcantly improve the operation of computing
environments. Application checkpoint-restart can improve
fault tolerance by allowing applications to recover from a
component failure by restarting from a recent point in the
execution. Application checkpoint-restart can also be used
to reduce application downtime during hardware and oper-
ating system (OS) maintenance by migrating the application
to a different machine before the maintenance operation. Fi-
nally, application checkpoint-restart can be used to suspend
or migrate jobs to support resource management in emerg-
ing Utility Computing and Grid environments [6].
An ideal checkpoint-restart mechanism should be
general-purpose and application-transparent, supporting a
∗
Currently at Meiosys
broad class of real applications without requiring applica-
tion modiﬁcations. It must checkpoint and restore all ap-
plication execution state including user-level state and the
state of OS resources used by the application. The mech-
anism must extend to parallel applications by supporting
consistent checkpoint-restart of processes running on mul-
tiple machines. Finally, the checkpoint-restart mechanism
must have a practical implementation that does not involve
designing special OSes or extensively re-engineering stan-
dard OSes. Such approaches are impractical because spe-
cial OSes have only limited appeal, and extensive OS mod-
iﬁcations require prohibitive code maintenance overhead.
Several application checkpoint-restart mechanisms are
described in the literature, but none of them meet these
requirements [13][9][3][12][1][17][15]. Library-based im-
plementations [13][9] require modiﬁcation of application
source code or re-linking of object code with special li-
braries, and they do not support applications that use system
services such as multithreading, interprocess communica-
tion, and network sockets. Vendors including SGI, Cray,
and IBM have integrated application checkpoint-restart into
proprietary systems but their implementation details are not
described in public documents. BLCR [3] is a kernel-
module based mechanism that requires application modiﬁ-
cations in cases where the application uses uncheckpointed
resources such as network sockets. Zap [12] is a kernel-
module based process migration mechanism that does not
require application or base kernel modiﬁcation. It integrates
a checkpoint-restart mechanism but this mechanism cannot
checkpoint and restore network socket state fully. However,
as we show in the rest of this paper, the Zap [12] architec-
ture can be extended to realize a checkpoint-restart mech-
anism that meets our requirements. Systems for check-
pointing parallel applications have been built using single
node checkpoint-restart mechanisms (e.g., MPVM [1] and
CoCheck [17] using Condor’s checkpointing [9] and LAM-
MPI [15] using BLCR [3]) but they are only applicable for
applications using speciﬁc message-passing libraries.
In this paper, we describe Cruz, a general-purpose,
application-transparent
checkpoint-restart mechanism.
Cruz’s single-node checkpoint-restart mechanism builds
on the Zap [12] architecture, thus avoiding the need for
Applications
Pods
Linux
Zap
Linux System calls
Figure 1. Zap architecture
application or base kernel modiﬁcation. We have enhanced
Zap in many ways enabling it to checkpoint and restart
complex applications such as databases and MPI applica-
tions. We focus our discussion in this paper on one critical
capability, the ability to migrate network addresses and
save and restore live network socket state in a manner that
is transparent to the application and external clients. To our
knowledge, this capability has not been reported in previous
literature. Leveraging our ability to capture a snapshot of
the network socket state of processes on a single machine,
we devise a novel protocol and method for implementing
coordinated checkpoint-restart of a distributed set of
processes. Our new method eliminates the expensive
step of ﬂushing communication channels required in prior
approaches for coordinated checkpoint-restart [1][17][15].
Our approach applies generally to TCP/IP [18] based
applications and does not require modiﬁcations to MPI [16]
or PVM [7] implementations.
The rest of the paper is organized as follows. Sec-
tion 2 reviews related work and presents an introduction
to the Zap [12] architecture. Section 3 gives an overview
of our solution approach for providing general-purpose ap-
plication checkpoint-restart. Section 4 describes our exten-
sions to Zap which enable improved support for checkpoint-
restart of networked applications. Section 5 describes our
solution for global coordinated checkpoint-restart of dis-
tributed applications. We present results from performance
evaluations in Section 6 and conclude in Section 7.
2. Related Work
Checkpoint-restart mechanisms have been implemented
at user-level and at kernel-level. User-level library-based
implementations [9][13] lack support for saving/restoring
kernel state other than open ﬁles and they require applica-
tion modiﬁcations or re-linking. Thus they work only for a
narrow set of applications. Kernel-level checkpoint-restart
mechanisms integrated into OSes such as SGI’s IRIX and
Cray’s Unicos are application-transparent and provide sup-
port for saving/restoring substantial portions of the appli-
cation’s kernel state including process IDs, shared mem-
ory, and pipes. However, they do not save/restore network
socket state and cannot restart applications when saved pro-
cess IDs/process group IDs are assigned to other running
applications. Moreover, extensively re-engineering the OS
to integrate support for checkpoint-restart is not practical
for most mainstream OSes.
BLCR [3] and Zap [12] implement checkpoint-restart
for Linux at the kernel level in an alternative way, us-
ing dynamically loaded kernel modules without modifying
the base kernel source code or requiring its re-compilation.
BLCR [3] saves/restores process state using a pre-existing
kernel module, VMADump1, which was designed to imple-
ment remote process forking in Beowulf clusters. BLCR
has extended VMADump to support multithreaded pro-
cesses and plans to add support for ﬁles, pipes, and other
features. However, BLCR does not support the checkpoint-
restart of communication socket state or the preservation
of application’s IP addresses across checkpoint-restart. In-
stead, BLCR [3] relies on applications or message passing
libraries to be modiﬁed to work around these issues. Also,
BLCR cannot restart an application successfully if any of
its process IDs are already in use during restore.
Zap [12] is an application-transparent process migration
system for Linux implemented as a kernel module. Zap,
illustrated in Figure 1, has two components: a thin virtual-
ization layer to create secure environments called PrOcess
Domains or pods and a mechanism for checkpointing and
restarting pods. The virtualization layer intercepts system
calls to expose only virtual identiﬁers (e.g., virtual process
IDs) to the processes within a pod instead of the physi-
cal identiﬁers returned by the OS. This results in a private
name space for each pod which isolates it from other pods
and decouples it from the OS. Checkpoint stops all the pro-
cesses within the pod and extracts their state, including OS
resource state relevant to the processes. Restart re-creates
these processes and restores their execution state, mostly by
invoking system calls. While the re-created OS resources
have different identiﬁers inside the operating system, Zap’s
virtualization layer masks this difference from applications.
Hence, Zap can restart processes successfully even when
their process ids are already in use within the operating sys-
tem, a unique capability that is not provided by BLCR [3]
or the kernel-based implementations mentioned previously.
Our work uses and builds on the powerful architecture of
Zap to realize a general-purpose checkpoint-restart imple-
mentation. The original Zap implementation [12] provided
support for a broad class of OS resources including: process
virtual memory, CPU state, ﬁle descriptors, pipes, signals,
and terminal state. Zap does not save or restore ﬁle system
state to avoid the high performance cost of transferring ﬁle
1http://bproc.sourceforge.net
system state. Like typical checkpoint-restart mechanisms,
it relies on a network-accessible ﬁle system that is acces-
sible from any machine on which the application may be
restarted. Integration of Zap with a ﬁle system with snap-
shot capability would enable checkpoint and restart of both
ﬁle system and computation state.
We have enhanced the original implementation of Zap by
adding the capability to checkpoint and restart OS resources
such as shared memory, semaphores, threads, sockets and
transient socket buffer state. We also extend Zap’s virtual-
ization layer to provide unique, externally routable IP ad-
dresses for each pod and preserve them across checkpoint
and restart. Thus networked applications can be check-
pointed on one machine and restarted on a machine with
a different IP address without changing the application’s IP
address and its connection state from the perspective of the
application or its remote clients.
Practical checkpoint-restart mechanisms for distributed
applications are limited to applications that communicate
using message passing models such as MPI [16] and
PVM [7]. MPVM [1], CoCheck [17], and LAM-MPI [15]
modify the message passing library (PVM or MPI) to im-
plement coordinated checkpoint and restart. These sys-
tems change the library as follows (with differences in de-
tails). They ﬂush all the messages that are in ﬂight be-
tween the application’s processes during checkpoint. They
re-establish network connections among the processes at
restart. Finally, since processes may be restarted on differ-
ent machines than they were running on before checkpoint,
the libraries are modiﬁed to reconstruct location informa-
tion at restart.
In contrast, our coordinated checkpoint-
restart approach eliminates all these steps resulting in a
much simpler, more efﬁcient, and more scalable implemen-
tation. We exploit our capability of saving and restoring
TCP socket state and socket buffer state to eliminate the
steps of ﬂushing communication channels (instead, we sim-
ply drop all in-ﬂight packets) and closing/reopening com-
munication channels. We preserve IP addresses for applica-
tions, thereby allowing processes to use normal IP mecha-
nisms to locate each other after restart. With these changes,
the number of coordination messages is reduced to the min-
imum necessary for ensuring the checkpoint is committed
on all nodes (i.e., equivalent to a two-phase commit [8]).
Furthermore, our resulting coordinated checkpoint-restart
mechanism can work for general TCP-based applications
(including MPI and PVM applications) without any changes
to applications or libraries.
A few coordinated checkpoint mechanisms designed
to work in conjunction with message logging mecha-
nisms [4][11] have exploited the message logs to eliminate
the need to ﬂush communication channels at checkpoint.
Logging messages has prohibitive performance overhead
for communication-intensive applications, so it is not a fea-
sible substitute for ﬂushing channels at checkpoint. Fur-
thermore, in contrast to our approach, these techniques still
require special communication libraries to log messages, to
reestablish network connections at restart, and to deal with
address relocation issues.
A few industry vendors offer products that integrate
checkpoint-restart functionality. Meiosys2 offers a Meta-
Cluster product capable of checkpointing and restarting dis-
tributed applications. MetaCluster has capabilities simi-
lar to our mechanism (e.g., saving and restoring TCP and
UDP connections and working without requiring applica-
tion modiﬁcations), but the details of its implementation
are not publicly available. VMWare3 provides virtual ma-
chine products including the capability to suspend, restart,
and migrate virtual machines between physical machines.
VMWare’s mechanisms differ from our approach in that
they checkpoint and restore the entire operating system in-
cluding all its applications instead of just a single appli-
cation, which imposes higher overhead at checkpoint and
restart time. VMWare’s hardware virtualization also im-
poses substantial performance overhead at runtime.
3. Solution Overview
In this paper we present Cruz, a powerful and general-
purpose checkpoint-restart mechanism. Cruz is application-
transparent, has a practical implementation based on a ker-
nel module without requiring modiﬁcations to the base ker-
nel, supports application migration between machines with-
out losing network connections, and efﬁciently supports
checkpoint-restart for distributed applications.
To realize these capabilities, we extend Zap to improve
its support for migrating networked applications. Our ex-
tensions to Zap enable it to save and restore the state of all
TCP connections used by a process as part of the process
state. This includes any received data that has not yet been
delivered to the process, any data submitted by the process
which has not yet been successfully acknowledged by the
recipient, and the state of the TCP connection. In addition,
we extend Zap to support network interface virtualization
to enable assigning a unique, externally routable IP address
to a pod which is preserved across checkpoint and restart.
These extensions enable pods to be migrated within an IP
subnet without disrupting communication, even if the re-
mote processes are not controlled by Zap.
The ability to capture TCP connection state enables an
elegant solution for the checkpoint-restart of distributed
processes that exploits the reliable messaging properties of
TCP. At checkpoint, only the states of the individual pro-
cesses (which includes the state of their TCP connections)
2http://www.meiosys.com
3http://www.vmware.com
are saved on the respective machines and any in-ﬂight mes-
sages in the network are discarded. At recovery, the TCP
connection states are restored and the TCP protocol ensures
that any messages which were previously discarded are re-
transmitted. A standard distributed commit protocol is used
to ensure atomicity of the checkpoint and restart.
4. Checkpoint-Restart for Networked Applica-
tions
This section describes our extensions to Zap’s support
for migrating networked applications. Section 4.1 explains
how Zap is extended to save/restore network socket state in-
cluding socket send and receive buffer contents. Although
the original Zap implementation had support for saving and
restoring a portion of socket state, it lacked support for sav-
ing/restoring data in send/receive buffers. Section 4.2 de-
scribes new support for assigning a network-visible IP ad-
dress to each pod which is preserved across migration. The
original Zap implementation assigned each pod a virtual IP
address that was not network-visible and relied on Zap at
both ends of the network connection to translate between
the virtual IP address and the network-visible IP address of
the host (by rewriting packet headers).
4.1. Network State Checkpoint-Restart
An application prepares to establish a TCP [18] con-
nection by invoking the OS to create an object called a
socket. The OS maintains the socket’s state which in-
cludes source/destination IP addresses/ports, TCP connec-
tion state including sequence numbers and connection sta-
tus, and various socket options that affect the data trans-
fer. The socket state also includes the contents of socket
send/receive buffers which reside in the kernel and store
data that are awaiting network transmission, acknowledge-
ment, or delivery to the application.
To accurately capture the state of all sockets used by
the application, the checkpoint-restart mechanism must en-
sure the application’s socket states cannot change during
the checkpoint procedure. They cannot be changed by the
application processes since Zap sends SIGSTOP signals to
stop the execution of all processes in a pod before check-
pointing it. However, OS kernel threads and the network de-
vice driver could change the socket states. Thus we extend
Zap such that at checkpoint time it acquires spin locks that
are required by the kernel for network processing to prevent
the network stack from delivering or transmitting packets
from/to the application’s sockets. Since these locks are held
only for the duration needed to save the socket states (rather
than the entire application state), the kernel’s network pro-
cessing is blocked only for a short duration.
We further extend Zap to checkpoint the frozen socket
state as follows.