## 每天5分钟,PG聊通透 - 系列1 - 热门问题 - 链接、驱动、SQL - 第9期 - 为什么OFFSET(翻页)会越来越慢?  
### 作者                              
digoal                              
### 日期                              
2021-12-20                            
### 标签                           
PostgreSQL , 热门问题           
----                            
## 背景         
- 问题说明(现象、环境)  
- 分析原因  
- 结论和解决办法  
## 链接、驱动、SQL       
#### 9、为什么OFFSET会越来越慢?     
https://www.bilibili.com/video/BV1W34y167Uz/   
1、offset 通常用在什么场景使用?   
翻页?    
2、数据库怎么知道 offset 了多少条符合条件的记录?   
首先扯远一点, 如果是个数组, 元组size固定, 大家思考一下offset怎么做到最快? 可以根据offset的个数算出起点, 将访问起点直接位移到指定存储地址. 例如4字节的元组, offset 100, 直接跳到400字节开始访问即可. 所以这样的访问不管offset多少性能都不会变慢.     
但是, 不管是索引扫描, 还是全表扫描, 亦或索引+其他非索引条件过滤, 输入条件都可能是变化的、而且元组的长度、索引的长度也可能是变化的, 更重要的是数据的组织形式并不是向数组一样顺序组织的. 所以没有办法像array一样, 直接位移存储来进行优化, 这也是为啥offset越后面越慢的原因?  下面用2个例子详细解释一下:    
`where x=? and y>? order by x limit 10 offset 100`     
- 使用x索引, y条件并不可知, 所以得遍历符合x条件的索引页.     
- 就算y条件也在索引中, 那么请看下面的另一个例子.       
`order by x limit 10 offset 100`     
- 使用x索引, 也得从索引遍历100条后, 才能获取后面的. 为什么要遍历这100条呢?     
- 索引没有版本号, 不遍历offset的条数, 怎么知道这条记录对当前事务是否可见.     
- 就算索引有版本号, 它也得读每条上面的版本号才能判断是否这条记录是否对当前事务可见, 所以还得遍历offset的条数.     
- 就算整个page有个全局可见标识, 它怎么知道1个index page里面有多少条记录? 以及一个page的value边界是什么? 所以还得遍历offset的条数.     
- 就算叶子结点知道每个index page有多少条, 但是分支节点和根节点总不知道吧?    
    - 因为任何一个结点, 如果要存储它的所有下游结点有多少条记录, 就必须实时更新.    
    - 对于根节点来说,  任何的插入更新删除都会涉及根节点的更新, 性能影响一定是极大的.    
    - 对于分支节点, 只有它下面的叶子结点中的记录有插入更新删除才会涉及到这个分支节点的更新.    
    - 对于叶子结点来说,  影响只在这个叶子里面的记录的增删改.    
    - 所以通常不会这么设计, 除非是静态数据.     
    - 那么通常只有叶子结点才知道它这个page有多少条记录以及value边界, 所以至少还是得按逻辑顺序扫描叶子结点的头信息(获取这个叶子结点有多少条记录).     
说这么多, 就是要证明 offset big value 没法在通用数据库的内核中进行优化(除非你的数据是静态数据, 内核才有优化的必要).    
如果关心索引结构可以看一下:   
- [《PostgreSQL rum 索引结构 - 比gin posting list|tree 的ctid(行号)多了addition info》](../201907/20190706_01.md)  
- [《[未完待续] PostgreSQL hash 索引结构介绍》](../201803/20180316_02.md)  
- [《深入浅出PostgreSQL B-Tree索引结构》](../201605/20160528_01.md)  
- [《PostgreSQL bloom 索引原理》](../202011/20201128_04.md)  
- [《PostgreSQL RUM 索引原理》](../202011/20201128_02.md)  
- [《PostgreSQL SP-GiST 索引原理》](../202011/20201128_01.md)  
- [《PostgreSQL GiST 索引原理 - 4》](../202010/20201004_04.md)  
- [《PostgreSQL GiST 索引原理 - 3》](../202010/20201004_03.md)  
- [《PostgreSQL GiST 索引原理 - 2》](../202010/20201004_02.md)  
- [《PostgreSQL GiST 索引原理 - 1》](../202010/20201004_01.md)  
- [《从难缠的模糊查询聊开 - PostgreSQL独门绝招之一 GIN , GiST , SP-GiST , RUM 索引原理与技术背景》](../201612/20161231_01.md)  
- [《重新发现PostgreSQL之美 - 13 brin 时序索引》](../202106/20210605_02.md)  
- [《PostgreSQL 14 preview - pageinspect 内窥heap,index存储结构 , 新增对gist索引的支持》](../202101/20210113_02.md)  
- [《PostgreSQL 黑科技 - 空间聚集存储, 内窥GIN, GiST, SP-GiST索引》](../201709/20170905_01.md)  
3、那么怎么优化呢?    
一页一页的翻, 是有优化方法的.   
3\.1、如果SQL不是在pk上order by, 那么可以order by联合PK索引. (对于没有pk的表, 可以增加1个序列(这个序列自动生成, 不变), 作为order by字段的联合UK). 用最后一条的value作为下次的条件输入, 去除offset.    
PS: 加PK或者UK的目的是防止gap.     
例子1:   
有PK的表.   
```   
create unlogged table a (id serial8 primary key, info text, crt_time timestamp);    
insert into a (info,crt_time) select 'test', clock_timestamp() from generate_series(1,1000000);   
```   
问题SQL:    
使用offset翻页   
```   
create index idx_a_1 on a (info,crt_time);   
select * from a where info='?' order by crt_time limit 10 offset 100;    
-- limit 10 offset 100 扫描了110行   
postgres=# explain (analyze,verbose,timing,costs,buffers) select * from a where info='test' order by crt_time limit 10 offset 100;   
                                                             QUERY PLAN                                                                 
-------------------------------------------------------------------------------------------------------------------------------------   
 Limit  (cost=3.26..3.55 rows=10 width=21) (actual time=0.072..0.078 rows=10 loops=1)   
   Output: id, info, crt_time   
   Buffers: shared hit=4   
   ->  Index Scan using idx_a_1 on public.a  (cost=0.42..28387.47 rows=1000000 width=21) (actual time=0.031..0.062 rows=110 loops=1)   
         Output: id, info, crt_time   
         Index Cond: (a.info = 'test'::text)   
         Buffers: shared hit=4   
 Planning:   
   Buffers: shared hit=28   
 Planning Time: 0.473 ms   
 Execution Time: 0.101 ms   
(11 rows)   
```   
优化:   
联合PK进行排序, 使用上一次翻页的最后一条, 作为临界条件传入下一次where条件中, 从而避免使用offset.      
```   
create index idx_a_2 on a (info,crt_time,id);    
select * from a where info=? and crt_time>=? and id>? order by crt_time,id limit 10 ;   
postgres=# select * from a where info='test' and crt_time>='2021-12-20 12:23:38.403651' and id>1 order by crt_time,id limit 10 ;   
   id    | info |          crt_time             
---------+------+----------------------------   
 1000102 | test | 2021-12-20 12:23:38.403651   
 1000103 | test | 2021-12-20 12:23:38.403671   
 1000104 | test | 2021-12-20 12:23:38.403673   
 1000105 | test | 2021-12-20 12:23:38.403675   
 1000106 | test | 2021-12-20 12:23:38.403677   
 1000107 | test | 2021-12-20 12:23:38.403678   
 1000108 | test | 2021-12-20 12:23:38.40368   
 1000109 | test | 2021-12-20 12:23:38.403683   
 1000110 | test | 2021-12-20 12:23:38.403685   
 1000111 | test | 2021-12-20 12:23:38.403687   
(10 rows)   
postgres=# select * from a where info='test' and crt_time>='2021-12-20 12:23:38.403687' and id>1000111 order by crt_time,id limit 10 ;   
   id    | info |          crt_time             
---------+------+----------------------------   
 1000112 | test | 2021-12-20 12:23:38.403689   
 1000113 | test | 2021-12-20 12:23:38.403691   
 1000114 | test | 2021-12-20 12:23:38.403693   
 1000115 | test | 2021-12-20 12:23:38.403695   
 1000116 | test | 2021-12-20 12:23:38.403696   
 1000117 | test | 2021-12-20 12:23:38.403698   
 1000118 | test | 2021-12-20 12:23:38.4037   
 1000119 | test | 2021-12-20 12:23:38.403715   
 1000120 | test | 2021-12-20 12:23:38.403717   
 1000121 | test | 2021-12-20 12:23:38.403719   
(10 rows)   
-- 使用上次的条件作为下次的临界条件, limit 10只需要扫描10行   
postgres=# explain (analyze,verbose,timing,costs,buffers) select * from a    
where info='test' and crt_time>='2021-12-20 12:23:38.403687' and id>1000111    
order by crt_time, id limit 10 ;   
                                                                    QUERY PLAN                                                                       
--------------------------------------------------------------------------------------------------------------------------------------------------   
 Limit  (cost=0.42..0.70 rows=10 width=21) (actual time=0.032..0.038 rows=10 loops=1)   
   Output: id, info, crt_time   
   Buffers: shared hit=4   
   ->  Index Only Scan using idx_a_2 on public.a  (cost=0.42..27946.47 rows=999789 width=21) (actual time=0.030..0.033 rows=10 loops=1)   
         Output: id, info, crt_time   
         Index Cond: ((a.info = 'test'::text) AND (a.crt_time >= '2021-12-20 12:23:38.403687'::timestamp without time zone) AND (a.id > 1000111))   
         Heap Fetches: 0   
         Buffers: shared hit=4   
 Planning:   
   Buffers: shared hit=4   
 Planning Time: 0.196 ms   
 Execution Time: 0.062 ms   
(12 rows)   
```   
例子2:   
没有PK、UK的表.    
```   
create unlogged table b (info text, crt_time timestamp, c1 int);      
insert into b (info,crt_time, c1) select 'test', clock_timestamp(), random()*100 from generate_series(1,1000000);   
```   
问题SQL:   
使用offset翻页.   
```   
create index idx_b_1 on b (info, c1);   
select * from b where info =? order by c1 limit 10 offset 100;    
postgres=# select * from b where info ='test' order by c1 limit 10 offset 1000;    
 info |          crt_time          | c1    
------+----------------------------+----   
 test | 2021-12-20 13:46:11.975846 |  0    
 test | 2021-12-20 13:46:11.975895 |  0    
 test | 2021-12-20 13:46:11.976153 |  0    
 test | 2021-12-20 13:46:11.976212 |  0    
 test | 2021-12-20 13:46:11.976319 |  0    
 test | 2021-12-20 13:46:11.976413 |  0    
 test | 2021-12-20 13:46:11.976444 |  0    
 test | 2021-12-20 13:46:11.97667  |  0    
 test | 2021-12-20 13:46:11.977002 |  0    
 test | 2021-12-20 13:46:11.977111 |  0    
(10 rows)   
-- limit 10 offset 1000 扫描了1010行   
postgres=# explain (analyze,verbose,timing,costs,buffers) select * from b where info ='test' order by c1 limit 10 offset 1000;    
                                                              QUERY PLAN                                                                 
--------------------------------------------------------------------------------------------------------------------------------------   
 Limit  (cost=26.56..26.82 rows=10 width=25) (actual time=0.992..1.006 rows=10 loops=1)   
   Output: info, crt_time, c1, uk   
   Buffers: shared hit=716   