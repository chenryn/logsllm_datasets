# Dynamic Searchable Encryption in Very-Large Databases: Data Structures and Implementation

**Authors:**
- David Cash
- Joseph Jaeger
- Stanislaw Jarecki
- Charanjit S. Jutla
- Hugo Krawczyk
- Marcel-Cătălin Roşu
- Michael Steiner

**Affiliations:**
- *Rutgers University (David Cash, Joseph Jaeger)*
- *University of California, Irvine (Stanislaw Jarecki)*
- *IBM Research (Charanjit S. Jutla, Hugo Krawczyk, Marcel-Cătălin Roşu, Michael Steiner)*

## Abstract
We design and implement dynamic symmetric searchable encryption schemes that efficiently and privately search server-held encrypted databases containing tens of billions of record-keyword pairs. Our basic theoretical construction supports single-keyword searches and offers asymptotically optimal server index size, fully parallel searching, and minimal leakage. Our implementation effort highlighted several factors ignored by earlier coarse-grained theoretical performance analyses, including low-level space utilization, I/O parallelism, and goodput. We introduce several optimizations to our theoretically optimal construction to address these factors. All of our schemes and optimizations are proven secure, and the information leaked to the untrusted server is precisely quantified. We evaluate the performance of our prototype using two very large datasets: a synthesized census database with 100 million records and hundreds of keywords per record, and a multi-million webpage collection that includes Wikipedia as a subset. Additionally, we report on an implementation that uses the dynamic SSE schemes developed here as the basis for supporting recent SSE advances, including complex search queries (e.g., Boolean queries) and richer operational settings (e.g., query delegation), in terabyte-scale databases.

## 1. Introduction

### 1.1 Background
Searchable symmetric encryption (SSE) allows one to store data at an untrusted server and later search the data for records (or documents) matching a given keyword while maintaining privacy. Recent works [3]–[5], [7], [9], [14], [15], [17], [19], [21] have studied SSE and provided solutions with varying trade-offs between security, efficiency, and the ability to securely update the data after it has been encrypted and uploaded. These constructions aim at practical efficiency, in contrast to generic cryptographic tools like homomorphic encryption or multiparty computation, which are highly secure but not likely to be efficient in practice.

Large data sizes motivate storage outsourcing, so an SSE scheme must scale well to be useful. Existing SSE schemes employ only symmetric cryptography operations and standard data structures, showing potential for practical efficiency. However, obstacles remain. While most constructions have theoretically optimal search times that scale only with the number of documents matching the query, the performance of their implementations on large datasets is less clear. Factors like I/O latency, storage utilization, and the variance of real-world dataset distributions degrade the practical performance of theoretically efficient SSE schemes. A critical source of inefficiency in practice (often ignored in theory) is a complete lack of locality and parallelism: To execute a search, most prior SSE schemes sequentially read each result from storage at a pseudorandom position, and the only known way to avoid this while maintaining privacy involves padding the server index to a prohibitively large size.

### 1.2 Contributions
We present the first SSE implementation that can encrypt and search on datasets with tens of billions of record/keyword pairs. Our design starts with a new, simple, theoretical SSE construction that uses a generic dictionary structure to achieve an asymptotic improvement over prior SSE schemes, offering optimal leakage, server size, search computation, and parallelism in search. This starting point generalizes and simplifies more ad-hoc techniques from [3]. We show how to make the scheme dynamic, meaning the data can be changed after encryption: Our scheme can easily support additions to the data, as well as deletions via revocation lists.

Because the scheme uses a generic dictionary that itself has no security properties, it allows for several extensions and modifications with only small changes to the security proofs. In particular, our implementation effort showed that disk I/O utilization remained a bottleneck, preventing scaling. Therefore, we extend our basic construction to improve locality and throughput. These extensions preserve privacy with slightly different leakages that we analyze with formal security proofs.

Below, we describe the techniques behind our results in more detail, starting with the new theoretical scheme that we extend later, and then compare our results to prior work.

### 1.3 Basic Construction
Our scheme is very simple (see Figure 2): It associates with each record/keyword pair a pseudorandom label and then stores the encrypted record identifier with that label in a generic dictionary data structure. The labels are derived so that the client, on input a keyword to query, can compute a keyword-specific short key allowing the server to search by first recomputing the labels, then retrieving the encrypted identifiers from the dictionary, and finally decrypting the matching encrypted record identifiers. The only information leaked to the server by the encrypted index (other than the indexes of records matching a query) is the number of items in the dictionary, i.e., the number of record/keyword pairs in the data. This scheme is easy to implement correctly (and with parallel searching) because we make no security demands on the dictionary, thus allowing instantiations as applications demand.

### 1.4 Extensions for External Storage
To compute the results of a keyword search with \( r \) matches, our basic scheme requires \( r \) retrievals from the dictionary for pseudorandom labels. Assuming \( O(1) \) cost of a dictionary retrieval, this is asymptotically optimal. However, in implementations, this will be far from optimal when the dictionary is stored in external memory (i.e., a block device like a HDD), because each random-looking retrieval will generate a disk read. This is in contrast to a plaintext system, which could store all of the matches in a single contiguous area of memory.

In view of this, we extend our scheme to use external storage more carefully while maintaining privacy. We first show how to securely "pack" related results together via a padding strategy to reduce the number of dictionary retrievals. However, even this modification was too slow for the datasets we targeted, and we noticed that real datasets exhibit extreme variability in the number of matches for a keyword: There were typically many keywords matching very few documents, then some keywords matching a significant fraction of the entire database. Our padding strategy thus becomes unsatisfactory because the (many) keywords matching only a few results create a lot of padding, and the searches that return a large number of results still trigger a large number of dictionary retrievals.

To address this, we introduce further modifications that replace dictionary reads with array reads when processing large numbers of results. These modifications result in a slightly different, but intuitively acceptable (and perhaps even better) leakage profile that we discuss below.

### 1.5 Extension for Updates
We observe that our scheme easily extends to allow for additions to the data after it has been uploaded. We only need to arrange that the client can compute the labels for the new data to be added, which it sends to the server to be added to the dictionary. This requires either client state or communication proportional to the total number of keywords ever added or deleted. To support deletions, we maintain a (pseudorandom) revocation list at the server that allows filtering out results that should be deleted. To actually reclaim space, we must re-encrypt periodically.

### 1.6 Other Applications
Recent constructions of SSE supporting more complex queries [3] and multi-client settings [13] use SSE as a black-box. Thus, our data structures and associated operations (including support for dynamic databases) are readily available to support terabyte-scale databases in these much richer/complex encrypted-search settings (see end of Section II).

### 1.7 Implementation
Our implementation remains efficient on datasets two orders of magnitude larger than the most scalable previous work [3], resulting in the first implementation of SSE on terabyte-scale databases containing tens of billions of indexed record/keyword pairs. We report on our prototype design and experimental results in Section V.

### 1.8 Comparison to Prior Work
In Figure 1, we compare our basic theoretical scheme to prior work. The basic scheme \( \Pi_{\text{bas}} \) generalizes and greatly simplifies an approach implicit in [3], which complicated the analysis by demanding security properties of the underlying data structures.

For a database with \( N \) record/keyword pairs, our basic scheme \( \Pi_{\text{bas}} \) produces an encrypted index of optimal size \( O(N) \), leaks only the size \( N \) and the matching record IDs, and processes a search with \( r \) results in optimal \( O(r) \) time, assuming \( O(1) \)-cost for dictionary retrievals. Searching is trivial to parallelize with any number of processors.

Most prior schemes leak additional information, such as the number of unique keywords, the size of the largest number of matches for a keyword, and so on. Some of these works also pad their encrypted indexes to be (worst-case) quadratic in their input size, which is impractical for large datasets. A notable issue with most prior work was a difficulty with parallelism: Other than [3], parallel searching was only achieved by two works that needed quadratic padding. Works like [7] required walking through an encrypted linked list and were not parallelizable at all. See the "Ind Leak," "Index Size," and "Search Time" columns in Figure 1.

The only prior dynamic schemes either had an impractically large index [14] or leaked the structure of the added documents [15], meaning the pattern of which keywords appear in which documents as they are added, which is a severe form of leakage compared to the usual SSE leakage of facts like the total database size. Our dynamic extension maintains the optimal index size and only leaks basic size information (and not document structure, as in [15]). Unlike prior dynamic schemes, ours does not reclaim space after each deletion—rather, we envision applications where deletions are relatively rare or, more generally, where a periodic complete re-encryption of the data is performed (re-encryption may be desirable to mitigate the leakage from updates with any dynamic SSE scheme).

### 1.9 More on Related Work
The notion of SSE we consider has its origins in work by Song, Wagner, and Perrig [19]. Several schemes since have improved upon the security and efficiency offered by the original schemes. The most similar to our construction is that of Chase and Kamara [5], and Cash et al. [3]. Chase and Kamara also uses a dictionary, but in a different way and with an impractical level of padding for large datasets. Cash et al. implements a scheme similar to our basic construction but do not address updates nor, as we show in Section V-E, does their approach achieve the same level of practical scalability.

There is also a related line of work on searchable public-key encryption starting with [2], all of which do not scale due to linear-time searching. The version of SSE we deal with inherently leaks the identifiers of documents that match a query, as well as when a query is repeated. It is possible to hide even this information using private information retrieval [6] or oblivious RAM [10]. Several recent improvements to oblivious RAM have been made, but they are beyond the scope of this paper.

---

**Figure 1: Comparison of SSE Schemes**

| Scheme | Security | Ind Leak | Dyn? | Dyn Leak | Index Size | Search Time/Comm | Dyn Comm |
|--------|----------|----------|------|----------|------------|------------------|----------|
| CGKO’06-1 [7] | NonAd | m, N | No | — | O(Mn) | O(r), O(r) | — |
| CGKO’06-2 [7] | Ad | m, n, M | No | — | O(Mn) | O(r), O(r) | — |
| CK’10 [5] | Ad | m, n | No | — | O(mn) | O(r), O(r) | — |
| LSDHJ’10 [21] | Ad | n, M | No | — | O(Mn) | O(r), O(r) | — |
| KO’12 [17] | Ad(UC) | m, N | No | — | EP(Wid) O(N + m) | O(r), O(1) | — |
| KPR’12 [15] | Adro | m, n | Yes | — | O(N) | O(r), O(1) | — |
| KP’13 [14] | Adro | N | Yes | — | O(N) | O(r), O(1) | — |
| Basic (Πbas here) | NonAd, Adro | N | No | — | O(N) | O(r), O(1) | — |
| Basic Adp (Πro_bas here) | NonAd, Adro | N | Yes | — | O(N) | O(r), O(1) | — |
| Basic Dyn (Πdyn here) | Ad | N | Yes | — | O(N) | O(r), O(1) | — |

---

This revised text aims to provide a clearer, more coherent, and professional presentation of the research, making it easier for readers to understand the contributions and technical details.