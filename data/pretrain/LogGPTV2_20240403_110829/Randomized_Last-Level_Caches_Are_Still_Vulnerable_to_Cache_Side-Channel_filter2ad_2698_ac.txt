n
o
i
t
c
v
E
g
n
d
n
F
i
i
f
o
y
t
i
l
i
Fig. 8. The probability of ﬁnding eviction sets with 25, 30 and 39 addresses
in a skewed LLC (1024 sets, 16 ways, 2 partitions) within limited number
of LLC accesses or evictions. Each result is averaged from 500 independent
experiments.
Fig. 9. The probability of ﬁnding the eviction sets with 30% evict rate in all
types of LLCs (CEASER and skewed cache with 2 to 16 partitions). Experi-
mental results (averaged from 500 independent experiments) are depicted in
dots while the probability in theory (Equation 3) is drawn in solid lines.
preferred remap period of 1600K LLC accesses (100 accesses
per cache block) [17]. In fact, 1600K LLC accesses are long
enough to ﬁnd partially congruent eviction sets with the high
eviction rate. CEASER-S is broken.
The reasons for the failure of CEASER-S are twofold: One
is its neglect of the possibility of using partially congruent
eviction sets, which require much lower number of LLC
accesses to ﬁnd than fully congruent eviction sets. The other
one is measuring the remap period by LLC accesses while
overlooking the ﬁlter effect of private caches. Fig. 8 reveals
the probability of using CT to ﬁnd eviction sets within limited
number of LLC evictions. Nearly all accesses observed by the
LLC lead to misses (caused by visiting random addresses),
indicating that all the re-accesses of the target address are
ﬁltered by private caches. The total number of cache accesses
observed by the LLC is halved.
Rather than periodically remapping the LLC, ScatterCache
proposes to use extra partitions to further increase the hardness
in ﬁnding eviction sets and assumes the extra hardness is
enough to thwart attacks [18]. ScatterCache estimates that
roughly 275 partially congruent addresses are needed to
achieve the 99% eviction rate in a randomized skewed cache
with eight partitions and ﬁnding such an eviction set requires
approximately 33.5M victim accesses (equivalent to 33.5M
LLC evictions), which is an intimidating large number. Fig. 9
demonstrates the number of LLC evictions required to ﬁnding
a partially congruent eviction set with 30% eviction rate in
all types of randomized caches. If an attacker tries to ﬁnd a
small eviction set (68 addresses for 30% eviction rate) instead
of the large one, the total number of LLC evictions is reduced
to 1.1M, which is only 3.3% of what the large eviction set
needs.6 Even if an attacker requires the 99% eviction rate,
she can choose to re-access and ﬂush the small eviction set
20 times. The total number of LLC evictions is around 2.7K,
which is just a negligible fraction (0.2%) of the LLC evictions
needed for ﬁnding the small set.7 ScatterCache is still unsafe
if eviction sets with low eviction rate are considered.
6We believe that ScatterCache has over-estimated the number of victim
accesses required. Instead of measuring the latency of re-accessing the random
address, an attacker can measure the latency of accessing the target address
(by the victim). This reduces the number of victim accesses to nways·2bindices·t,
which is
7This way of achieving the 99% eviction rate works only for the evict+time
of what ScatterCache estimates.
nways
1
attacks [2] though.
V. FIX THE RANDOMIZED SKEWED CACHES
Randomized skewed caches are still vulnerable to attacks
using partially congruent eviction sets found by the CT algo-
rithm. Several ideas are proposed in this section to strengthen
the defense while retaining performance.
A. Count Cache Evictions Rather than Accesses
As analyzed in Section IV-B, the failure of CEASER-S
is partially because the remap period is measured by LLC
accesses but half of the supposed accesses are ﬁltered by
private caches. We propose to measure the remap period by
LLC evictions.
In the CT algorithm, when the target address is cached in
the LLC, the probability that a newly fetched random address
is cached in the same set and partition with the target address
can be described as:
P =
1
SK
where K is the number of partitions. Assuming the LRU
replacement is used, the target address is evicted from the
LLC only when W
K evictions occurred in the same set and
partition. Therefore, the probability of collecting a partially
congruent eviction set of L addresses in E LLC evictions can
be estimated as:
P rob(X ≥ L) = 1 −
LW
K −1i=0 E
iP i(1 − P )E−i
As shown in Fig. 9, the theoretical probability calculated
using Equation 3 matches with the experiment result. We can
use this equation to estimate the time of ﬁnding an eviction set
(30% eviction rate) within different remap periods in various
randomized caches. Assuming the highest frequency of LLC
evictions is 800 MHz, Table II details the time estimation. If
we consider one year as a secure time margin for thwarting
potential attacks, the chosen remap periods along with its time
estimation are listed in the ﬁnal column. To safely thwart
attacks, the remap period of a two partitioned CEASER-S
LLC must be reduced to 14 LLC evictions per cache block
(by average). Even a skewed cache with 16 partitions has to
be remapped very 39 LLC evictions per cache block.
Such short remap periods might be considered intolerable.
However, remapping by counting LLC evictions is much more
efﬁcient than counting LLC accesses because the LLC miss
rate of normal applications is much lower than attacks. In
(2)
(3)
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:29:54 UTC from IEEE Xplore.  Restrictions apply. 
961
TABLE II
ESTIMATED TIME FOR SUCCESSFULLY FINDING AN EVICTION SET (30%
EVICT RATE) WITHIN DIFFERENT REMAP PERIODS (AVERAGE NUMBER OF
EVICTIONS PER CACHE BLOCK).
Remap Period
CEASER
Skew-2
Skew-4
Skew-8
Skew-16
100
0.3ms
0.5ms
0.9ms
1.4ms
1.8ms
50
20
0.4ms
0.32s
10
3.7y
0.3ms
0.5ms
>100y
0.9ms >100y >100y
>100y >100y
2.8s
1.2h
>100y >100y
(a)
(b)
Fig. 10. The remap process of CEASER (CEASER-S). Cache sets are
sequentially relocated as depicted in (a), where p points to the cache set
that s currently be relocated. During the remap process, the cache set index
for an incoming address is decided according to (b).
an ideal scenario, if the miss rate in the LLC is sufﬁciently
low, remapping every 14 LLC evictions per cache block would
trigger less remaps than remapping every 100 LLC accesses
per cache block (preferred by CEASER-S). Our performance
experiments in Section VII-A will analyze this effect in details.
B. Multi-Step Cache Relocation
Our experiment shows that 40% to 50% cache blocks in
the LLC are evicted during the remap process, which is why
frequent remaps can hurt performance signiﬁcantly. Borrowing
ideas from ZCache [25], we propose to use a multi-step
relocation in the remap process, which reduces the eviction
ratio to as low as 10%. This has two major beneﬁts: One is
the reduced performance loss as extra blocks remain in the
LLC. The other one is the reduced damage from denial-of-
service attacks [50]. An attacker can trigger frequent remaps
by forcing a large amount of LLC accesses or evictions. Since
the remap process cannot differentiate victim’s data from the
attacker’s, the attacker can use remaps as a stealthy way to
blindly evict victim’s data. If the eviction ratio is reduced from
50% to just 10%, the return of such attacks becomes marginal.
In the remap process proposed by CEASER [16], cache sets
are remapped sequentially as illustrated in Fig. 10a. Remapped
blocks (shadowed in gray) are recorded in their metadata and
a set-relocation pointer (p) always points to the cache set
currently being remapped. The cache block E is currently
being relocated to the next cache set chosen by the new key
(k). According to the replacement policy, G is evicted to make
a room for E. By repeating this procedure, all blocks in the set
are remapped and p moves to the next set. Since remapping
is a gradual procedure, normal cache accesses might occur in
Chosen Period
10 (3.7y)
14 (204y)
25 (40y)
35 (12y)
39 (12y)
(a)
(b)
Fig. 11. A multi-step relocation process. When the destination of a relocation
is taken by an unremapped cache block, this block is further relocated until an
empty space is found as in (a) or a remapped cache block is found and evicted
instead. The cache set index for an incoming address is decided according to
(b). When using the old cache set index i results in a miss, retry using the
new index i.
l
s
k
c
o
B
e
h
c
a
C
d
e
n
a
i
t
e
R
f
o
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
e
g
a
t
n
e
c
r
e
P
CEASER
Skew-2
Skew-4
Skew-8
Skew-16
6
3
5
Number of Relocations
4
Unlimited
1
2
Fig. 12. The percentage of cache blocks retained during remapping by
applying limited number of relocations. The maximum retaining percentage
is achieved when ‘inﬁnite’ trials of relocation are applied until a remapped
cache block is found as the replacement (and evicted). Each result is averaged
from 100 independent experiments.
parallel. Fig. 10b illustrates how the cache set index is decided.
The old cache set index i and the new one i are produced
simultaneously by two independent ciphers using the old key
k and the new key k respectively. When i ≥ p, denoting
the cache set is not remapped yet, the old index i is used.
Otherwise, the new index i should be used.
The problem of the original remap process is the eviction
of G. Whenever the target cache set for a relocated block is
full, a cache block is evicted, which leads to a high number of
evictions. Such evictions might be avoidable. The relocation
procedure can keep on relocating the blocks to be evicted, such
as G, in a chain until either a free space is found, as shown
in Fig. 11a, or a remapped block is to be evicted. Note that
using multi-step relocation does not increases the total number
of relocated blocks. Once a block is relocated, it is recorded
as remapped and will not be relocated again. The total number
of blocks to be relocated is equal to the number of blocks in
the LLC in both methods. As shown in Fig. 12, by allowing
unlimited number of relocations, the percentage of blocks
retained in the LLC grows. Randomized set-associative caches
(CEASER) beneﬁts the most as the percentage increases from
63% to 90%. The boost for randomized skewed caches drops
gradually with the number of partitions.
The calculation of the cache set index needs a small change
to support the multi-step relocation. As shown in Fig. 11b,
when i ≥ p, the old cache set index i should be used in the
same way as in the original CEASER. However, if it results in
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:29:54 UTC from IEEE Xplore.  Restrictions apply. 
962
ABCDEFGHIJKLMpevictedCipherkk'addresscachesetindexi > pii'01CipherABCDEFGHIJKLMpaddresscachesetindex& missii'01i > pretryCipherkk'Ciphercaches diminishes when the cache associativity increases. As
caches in modern processors are typically highly associative,
the marginal gain in performance might not justify the extra
hardware cost. For this reason, CEASER-S chooses to use
only two partitions. Some of our experiments show excessive
skewing (too many partitions) actually hurt performance as it
reduces the efﬁciency of the LRU replacement. One example is
already revealed in Fig. 12. The beneﬁt of multi-step relocation
drops with the increasing number of partitions.
From our own perspective in hardware designs, we also
believe that skewed cache signiﬁcantly complicates the de-
sign of modern LLCs which typically serve multiple cache
transactions in parallel. Taking the LLC design of the Rocket-
Chip (as shown in Fig. 13) as an example, before a tracker can
accept a transaction, the LLC must ensure that this transaction
would not conﬂict with the others currently being served.
This typically means that no transaction served simultaneously
should access the same cache set with others. Otherwise,
one of the conﬂicting transactions should be blocked before
it is accepted by a tracker (race condition). This is not a
serious issue for set-associative caches as the cache set index
of an incoming transaction can be calculated beforehand and
compared with the indices of all active trackers simultaneously
in a single cycle. For a skewed cache with K partitions and T
trackers, the incoming transaction might access anyone of the
K possible cache sets and it is not decided until the transaction
hits on a set or a target set is chosen for replacement. In the
worst scenario, K · T K parallel comparisons (rather than T
for the set-associative cache) are required to check potential
conﬂicts for an incoming transaction. Besides the obvious
hardware cost in doing so, this signiﬁcantly increases the
probability of blocking an incoming transaction due to a
conﬂict that might not occur eventually. It then prolongs the
cache accessing latency.
Therefore, we would like to investigate potential means to
strengthen the randomized set-associative caches.
B. Remap When Under Attack
Although randomized skewed caches are vulnerable only
to the CT algorithm, randomized set-associative caches are
vulnerable to all the three search algorithms introduced in
Section II-D. To thwart the CT algorithm, a 1024-set 16-way
CEASER LLC has to remap every 10 LLC evictions per cache
block according to Table II, which allows for a total of 160K
LLC evictions between remaps. However, our experiments
show that the numbers of LLC evictions (accesses) needed
for ﬁnding an eviction set are around 40.8K (168K) using the
PPT algorithm and 81.3K (532K) using the GE algorithm.
Both are valid threats.
Instead of shrinking the already short remap period, we
propose to trigger a remap when an attack using the two
algorithms is detected because both of them leave a unique
pattern in the cache set distribution of evictions. Let us ﬁrst
consider the PPT algorithm. By periodically sampling the
number of accesses and evictions occurred on individual cache
sets during two consecutive attacks, Fig. 14a and 14b reveal
Fig. 13. Support multi-step relocation in the LLC of the Rocket-Chip.
a miss, the new cache set index i should be used in a retrial
as the block might have already be relocated. Since reading
the metadata array and checking cache hit typically ﬁnish in
one or two cycles, and retrials occur only occasionally during
the relatively short remap process, the performance impact is
trivial considering the signiﬁcantly reduced eviction ratio.
Supporting multi-step relocation in the actual cache hard-
ware should be straightforward. Fig. 13 demonstrates the
internal structure of the LLC (L2) used in the Rocket-Chip
SoC [51] (available from lowRISC v0.4 [52]), which is a
widely adopted open processor design taped out for tens of
times. To support multiple concurrent cache transactions initi-
ated from the multiple L1 caches, each cache slice implements
multiple transaction trackers sharing the same accesses to the
metadata array, the data array and the writeback unit. When a
transaction arrives without any race condition, a free tracker
is allocated to serve it. To support remaps, a special remap
tracker is added. During a remap, it tracks the set-relocation
pointer and gradually relocates all cache blocks. In the case
of multi-step relocation, when an unremapped cache block is
swapped out, the remap tracker throws it back to itself as
a prioritized writeback transaction. As long as unremapped
blocks are swapped out, they are continuously relocated until
a free space is found or a remapped block is swapped out
instead (which is then evicted). This recursive procedure effec-
tively implements the unlimited steps of relocation. The only
hardware changes necessary to support multi-step relocation
include adding an incoming port to the remap tracker and
modifying its state machine accordingly.
VI. USE NORMAL INSTEAD OF SKEWED CACHES
Instead of advocating the use of randomized skewed cache
like CEASER-S and ScatterCache, we argue that randomized
set-associative caches can be sufﬁciently strengthened and
possess a better chance to be actually adopted in commercial
processors than their skewed counterparts. By a literature
research with our best effort, we cautiously believe that skewed
caches [53], [54] have not been adopted in the LLCs of any
commercially available modern processors. Promoting them
purely for security beneﬁts might be a hard sale.
A. Issues with Skewed Caches
We agree that skewed caches can improve cache efﬁciency
by reducing conﬂicts [53] and are natural candidates for
compressed caches [54]. However, it seems that they are not
yet embraced by the industry. One potential reason has already
been pointed out by CEASER-S [17]: The beneﬁt of skewed
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:29:54 UTC from IEEE Xplore.  Restrictions apply. 
963
dataarraymetadataarraytransactiontrackerwritebackunitL1/L2DRAMremaptrackerrelocated block)
s
e
s
s
e
c
c
a
C
L
L
(
e
m
T
i
)
s
e
s
s
e
c
c
a
C
L
L
(
e
m
T
i
)
s
e
s
s
e
c
c
a
C
L
L
(
e
m
T
i
229376
212992
196608
180224
163840
147456
131072
114688
98304
81920
65536
49152
32768
16384
229376
212992
196608
180224
163840
147456
131072
114688
98304
81920
65536
49152
32768
16384
229376
212992
196608
180224
163840
147456
131072
114688
98304