and the real datasets and scenarios we use in our evaluation
satisfy this property.
ADMM.
Alternating Direction Method of Multipliers
(ADMM) [15] is an established technique for distributed convex
optimization. To use ADMM, we ﬁrst reformulate Eq. 1 by
introducing additional variables and constraints:
(cid:5)Xiwi − yi(cid:5)2
i=1
minimize:
2 + λR(z),
{wi}m
i=1, z
such that: wi = z for all i ∈ {1, . . . , p}
(2)
This equivalent formulation splits w into wi for each party
i, but still requires that wi be equal to a global model z. To
solve this constrained formulation, we construct an augmented
Lagrangian:
L ({wi}m
i=1, z, u) =
m(cid:3)
(cid:5)Xiwi − yi(cid:5)2
m(cid:3)
i (wi − z) +
uT
2
where the dual variables ui ∈ R
d capture the mismatch between
(cid:2)m
the model estimated by party i and the global model z and
the augmenting term ρ
2 adds an additional
2
penalty (scaled by the constant ρ) for deviating from z.
i=1 ||wi − z||2
||wi − z||2
2 ,
2 + λR(z)+
i=1
ρ
m(cid:3)
(3)
1
2
i=1
i=1
ρ
The ADMM algorithm is a simple iterative dual ascent on
the augmented Lagrangian of Eq. (2). On the kth iteration,
each party locally solves this closed-form expression:
(cid:5)(cid:5)
zk − uk
(cid:5)−1 (cid:4)
i ← (cid:4)
i Xi + ρI
i yi + ρ
wk+1
XT
XT
(4)
(cid:4)
i
(cid:24)(cid:19)(cid:23)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:40:42 UTC from IEEE Xplore.  Restrictions apply. 
and then shares its local model wk+1
uk
i to solve for the new global weights:
m(cid:3)
zk+1 ← arg min
λR(z) +
ρ
i
z
||wk+1
i − z + uk
i ||2
2.
(5)
2
i=1
and Lagrange multipliers
Finally, each party uses the new global weights zk+1 to update
its local Lagrange multipliers
i ← uk
uk+1
i − zk+1.
i + wk+1
(6)
The update equations (4), (5), and (6) are executed iteratively
until all updates reach a ﬁxed point. In practice, a ﬁxed number
of iterations may be used as a stopping condition, and that is
what we do in Helen.
LASSO. We use LASSO as a running example for the rest of
the paper in order to illustrate how our secure training protocol
works. LASSO is a popular regularized linear regression model
that uses the L1 norm as the regularization function. The
LASSO formulation is given by the optimization objective
arg minw (cid:5)Xw−y(cid:5)2
2 +λ(cid:5)w(cid:5). The boxed section below shows
the ADMM training procedure for LASSO. Here, the quantities
in color are quantities that are intermediate values in the
computation and need to be protected from every party, whereas
the quantities in black are private values known to one party.
The coopetitive learning task for LASSO
i Xi + ρI
1) Ai ← (cid:4)
(cid:5)−1
Input of party Pi: Xi, yi
XT
2) bi ← XT
i yi
3) u0, z0, w0 ← 0
(cid:5)
4) For k = 0, ADMMIterations-1:
)
wk+1
a) wk+1
b) zk+1 ← Sλ/mρ
c) uk+1
i ← Ai(bi + ρ
i ← uk
(cid:4)
zk − uk
(cid:4)
(cid:2)m
i − zk+1
1
m
i + wk+1
i=1
(cid:4)
i
i + uk
i
(cid:5)(cid:5)
Sλ/mρ is the soft the soft thresholding operator, where
⎧⎪⎨
⎪⎩
a − κ a > κ
|a| ≤ κ
0
a + κ a < −κ
(7)
Sκ(a) =
The parameters λ and ρ are public and ﬁxed.
III. SYSTEM OVERVIEW
Figure 2 shows the system setup in Helen. A group of m
participants (also called parties) wants to jointly train a model
on their data without sharing the plaintext data. As mentioned
in Section I, the use cases we envision for our system consist of
a few large organizations (around 10 organizations), where each
organization has a lot of data (n is on the order of hundreds of
thousands or millions). The number of features/columns in the
dataset d is on the order of tens or hundreds. Hence d (cid:8) n.
We assume that the parties have agreed to publicly release
the ﬁnal model. As part of Helen, they will engage in an
interactive protocol during which they share encrypted data,
and only at the end will they obtain the model in decrypted
form. Helen supports regularized linear models including least
squares linear regression, ridge regression, LASSO, and elastic
net. In the rest of the paper, we focus on explaining Helen
via LASSO, but we also provide update equations for ridge
regression in Section VII.
A. Threat model
We assume that all parties have agreed upon a single
functionality to compute and have also consented to releasing
the ﬁnal result of the function to every party.
We consider a strong threat model in which all but one
party can be compromised by a malicious attacker. This means
that the compromised parties can deviate arbitrarily from the
protocol, such as supplying inconsistent inputs, substituting
their input with another party’s input, or executing different
computation than expected. In the ﬂu prediction example, six
divisions could collude together to learn information about one
of the medical divisions. However, as long as the victim medical
division follows our protocol correctly, the other divisions will
not be able to learn anything about the victim division other
than the ﬁnal result of the function. We now state the security
theorem.
Theorem 6. Helen securely evaluates an ideal functionality
fADMM in the (fcrs, fSPDZ)-hybrid model under standard cryp-
tographic assumptions, against a malicious adversary who can
statically corrupt up to m − 1 out of m parties.
We formalize the security of Helen in the standalone MPC
model. fcrs and fSPDZ are ideal functionalities that we use in
our proofs, where fcrs is the ideal functionality representing
the creation of a common reference string, and fSPDZ is the
ideal functionality that makes a call to SPDZ. Due to space
constraints, we present the formal deﬁnitions as well as the
security proofs in the full version of this paper.
Out of scope attacks/complementary directions. Helen does
not prevent a malicious party from choosing a bad dataset
for the coopetitive computation (e.g., in an attempt to alter
the computation result). In particular, Helen does not prevent
poisoning attacks [44, 18]. MPC protocols generally do not
protect against bad inputs because there is no way to ensure
that a party provides true data. Nevertheless, Helen will ensure
that once a party supplies its input into the computation, the
party is bound to using the same input consistently throughout
the entire computation; in particular, this prevents a party from
providing different inputs at different stages of the computation,
or mix-and-matching inputs from other parties. Further, some
additional constraints can also be placed in pre-processing,
training, and post-processing to mitigate such attacks, as we
elaborate in Section IX-B.
Helen also does not protect against attacks launched on the
public model, for example, attacks that attempt to recover the
training data from the model itself [65, 16]. The parties are
responsible for deciding if they are willing to share with each
other the model. Our goal is only to conduct this computation
securely: to ensure that the parties do not share their raw
(cid:24)(cid:19)(cid:24)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:40:42 UTC from IEEE Xplore.  Restrictions apply. 
participant 2
[      ]
participant 1
[      ]
  . . .
participant m
[      ]
communication 
exchanging 
encrypted data
global public key
private share of global secret key 
encrypted data summaries 
from other parties
private database of this party, 
input to coopetitive learning
Fig. 2: Architecture overview of Helen. Every red shape indicates secret information known only to the indicated party, and
black indicates public information visible to everyone (which could be private information in encrypted form). For participant
m, we annotate the meaning of each quantity.
plaintext datasets with each other, that they do not learn more
information than the resulting model, and that only the speciﬁed
computation is executed. Investigating techniques for ensuring
that the model does not leak too much about the data is a
complementary direction to Helen, and we expect that many of
these techniques could be plugged into a system like Helen. For
example, Helen can be easily combined with some differential
privacy tools that add noise before model release to ensure that
the model does not leak too much about an individual record
in the training data. We further discuss possible approaches
in Section IX-B.
Finally, Helen does not protect against denial of service –
all parties must participate in order to produce a model.
B. Protocol phases
We now explain the protocol phases at a high level. The ﬁrst
phase requires all parties to agree to perform the coopetitive
computation, which happens before initializing Helen. The
other phases are run using Helen.
Agreement phase.
In this phase, the m parties come together
and agree that they are willing to run a certain learning
algorithm (in Helen’s case, ADMM for linear models) over
their joint data. The parties should also agree to release the
computed model among themselves.
The following discrete phases are run by Helen. We summa-
rize their purposes here and provide the technical design for
each in the following sections.
Initialization phase. During initialization, the m parties
compute the encryption keys using a generic MPC protocol.
The public output of this protocol is a public key PK that is
known to everyone. Each party also receives a piece (called a
share) of the corresponding secret key SK: party Pi receives
the i-th share of the key denoted as [SK]i. A value encrypted
under PK can only be decrypted via all shares of the SK, so
every party needs to agree to decrypt this value. Fig. 2 shows
these keys. This phase only needs to run once for the entire
training process, and does not need to be re-run as long as the
parties’ conﬁguration does not change.
Input preparation phase.
In this phase, each party pre-
pares its data for the coopetitive computation. Each party Pi
precomputes summaries of its data and commits to them by
broadcasting encrypted summaries to all other parties. The
parties also need to prove that they know the values inside
these encryptions using zero-knowledge proofs of knowledge.
From this moment on, party Pi will not be able to use different
inputs for the rest of the computation.
By default, each party stores the encrypted summaries from
other parties. This is a viable solution since these summaries
are much smaller than the data itself. It is possible to also
store all m summaries in a public cloud by having each party
produce an integrity MAC of the summary from each other
party and checking the MAC upon retrieval which protects
against a compromised cloud.
Model compute phase. This phase follows the iterative
ADMM algorithm, in which parties successively compute
locally on encrypted data, followed by a coordination step
with other parties using a generic MPC protocol.
Throughout this protocol, each party receives only encrypted
intermediate data. No party learns the intermediate data because,
by deﬁnition, an MPC protocol should not reveal any data
beyond the ﬁnal result. Moreover, each party proves in zero
knowledge to the other parties that it performed the local
computation correctly using data that is consistent with the
private data that was committed in the input preparation phase.
If any one party misbehaves, the other parties will be able to
detect the cheating with overwhelming probability.
Model release phase. At the end of the model compute
phase, all parties obtain an encrypted model. All parties jointly
decrypt the weights and release the ﬁnal model. However, it is
possible for a set of parties to not receive the ﬁnal model at the
end of training if other parties misbehave (it has been proven
that it is impossible to achieve fairness for generic MPC in
the malicious majority setting [19]). Nevertheless, this kind of
malicious behavior is easily detectable in Helen and can be
enforced using legal methods.
(cid:24)(cid:19)(cid:25)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:40:42 UTC from IEEE Xplore.  Restrictions apply. 
IV. CRYPTOGRAPHIC GADGETS
Helen’s design combines several different cryptographic
primitives. In order to explain the design clearly, we split
Helen into modular gadgets. In this section and the following
sections, we discuss (1) how Helen implements these gadgets,
and (2) how Helen composes them in the overall protocol.
For simplicity, we present our zero knowledge proofs as
Σ-protocols, which require the veriﬁer to generate random
challenges. These protocols can be transformed into full