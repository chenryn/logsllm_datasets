public void run() {
             while (!stop) {
                 try {
                     // Perform work here
                 } catch (Throwable t) {
                     // Log the exception and continue
     WriteToUser(“An Error has occurred, put the kettle on”);
                     logger.log(Level.SEVERE, “Unexception exception”, t);
Sample 20.13
Error Handling
172
C++ Try–Catch
In general, it is best practice to catch a specific type of exception rather than use the basic catch(Exception) or 
catch(Throwable) statement in the case of Java. 
What to Review: The Order of Catching Exceptions
Keep in mind that many languages will attempt to match the thrown exception to the catch clause even if it means 
matching the thrown exception to a parent class.  Also remember that catch clauses are checked in the order they are 
coded on the page.  This could leave you in the situation where a certain type of exception might never be handled 
correctly, take the following example where ‘non_even_argument’ is a subclass of ‘std::invalid_argument’:
                 }
             }
         }
void perform_fn() {
   try {
      // Perform work here
   } catch ( const MyClassExtendedFromStdException& e) {
      // Log the exception and continue
      WriteToUser(“An Error has occurred, put the kettle on”);
      logger.log(Level.SEVERE, “Unexception exception”, e);
   }
 }
Sample 20.14
class non_even_argument : public std::invalid_argument {
 public:
  explicit non_even_argument (const string& what_arg);
 };
 void do_fn()
 {
    try
    {
       // Perform work that could throw 
    }
    catch ( const std::invalid_argument& e )
    {
Sample 20.15
Error Handling
173
The problem with this code is that when a ‘non_even_argument is thrown, the catch branch handling 
‘std::invalid_argument’ will always be executed as it is a parent of ‘non_even_argument’ and thus the runtime 
system will consider it a match (this could also lead to slicing).  Thus you need to be aware of the hierarchy of 
your exception objects and ensure that you list the catch for the more specific exceptions first in your code.
If the language in question has a finally method, use it. The finally method is guaranteed to always be called. 
The finally method can be used to release resources referenced by the method that threw the exception. This is 
very important. An example would be if a method gained a database connection from a pool of connections, 
and an exception occurred without finally, the connection object shall not be returned to the pool for some 
time (until the timeout). This can lead to pool exhaustion. finally() is called even if no exception is thrown. 
A Java example showing finally() being used to release system resources.
What to Review: Releasing resources and good housekeeping
RAII is Resource Acquisition Is Initialization, which is a way of saying that when you first create an instance of 
a type, it should be fully setup (or as much as possible) so that it’s in a good state.  Another advantage of RAII 
is how objects are disposed of, effectively when an object instance is no longer needed then it resources are 
automatically returned when the object goes out of scope (C++) or when it’s ‘using’ block is finished (C# ‘using’ 
directive which calls the Dispose method, or Java 7’s try-with-resources feature) 
RAII has the advantage that programmers (and users to libraries) don’t need to explicitly delete objects, the 
objects will be removed themselves, and in the process of removing themselves (destructor or Dispose) 
For Classic ASP pages it is recommended to enclose all cleaning in a function and call it into an error handling 
       // Perform generic invalid argument processing and return failure
    }
    catch ( const non_even_argument& e )
    {
       // Perform specific processing to make argument even and continue processing
    }
 }
void perform_fn() {
   try {
      // Perform work here
   } catch ( const MyClassExtendedFromStdException& e) {
      // Log the exception and continue
      WriteToUser(“An Error has occurred, put the kettle on”);
      logger.log(Level.SEVERE, “Unexception exception”, e);
   }
 }
Sample 20.16
Error Handling
174
statement after an “On Error Resume Next”.
Building an infrastructure for consistent error reporting proves more difficult than error handling. Struts 
provides the ActionMessages and ActionErrors classes for maintaining a stack of error messages to be reported, 
which can be used with JSP tags like  to display these error messages to the user. 
To report a different severity of a message in a different manner (like error, warning, or information) the 
following tasks are required: 
1. Register, instantiate the errors under the appropriate severity
2. Identify these messages and show them in a consistent manner.
Struts ActionErrors class makes error handling quite easy:
Now that we have added the errors, we display them by using tags in the HTML page.
References
• For classic ASP pages you need to do some IIS configuration, follow http://support.microsoft.com/
kb/299981 for more information.
• For default HTTP error page handling in struts (web.xml) see https://software-security.sans.org/
blog/2010/08/11/security-misconfigurations-java-webxml-files
ActionErrors errors = new ActionErrors()
 errors.add(“fatal”, new ActionError(“....”)); 
 errors.add(“error”, new ActionError(“....”)); 
 errors.add(“warning”, new ActionError(“....”));
 errors.add(“information”, new ActionError(“....”)); 
 saveErrors(request,errors); // Important to do this
Sample 20.17
Sample 20.18
Error Handling
175
How will your code and applications react when something has gone wrong?  Many companies that follow 
secure design and coding principals do so to prevent attackers from getting into their network, however 
many companies do not consider designing and coding for the scenario where an attacker may have found 
a vulnerability, or has already exploited it to run code within a companies firewalls (i.e. within the Intranet).
Many companies employ SIEM logging technologies to monitor network and OS logs for patterns that detect 
suspicions activity, this section aims to further encourage application layers and interfaces to do the same.
21.1 Description
This section concentrates on:
1. Design and code that allows the user to react when a system is being attacked.
2. Concepts allowing applications to flag when they have been breached.
When a company implements secure design and coding, it will have the aim of preventing attackers from 
misusing the software and accessing information they should not have access to.  Input validation checks for 
SQL injections, XSS, CSRF, etc. should prevent attackers from being able to exploit these types of vulnerabilities 
against the software.  However how should software react when an attacker is attempting to breach the 
defenses, or the protections have been breached?
For an application to alert to security issues, it needs context on what is ‘normal’ and what constitutes a 
security issue.  This will differ based on the application and the context within which it is running.  In general 
applications should not attempt to log every item that occurs as the excessive logging will slow down the 
system, fill up disk or DB space, and make it very hard to filter through all the information to find the security 
issue.
At the same time, if not enough information is monitored or logged, then security alerting will be very hard to 
do based on the available information.  To achieve this balance an application could use its own risk scoring 
system, monitoring at a system level what risk triggers have been spotted (i.e. invalid inputs, failed passwords, 
etc.) and use different modes of logging.  Take an example of normal usage, in this scenario only critical items 
are logged.  However if the security risk is perceived to have increased, then major or security level items 
can be logged and acted upon.  This higher security risk could also invoke further security functionality as 
described later in this section. 
Take an example where an online form (post authentication) allows a user to enter a month of the year.  Here 
the UI is designed to give the user a drop down list of the months (January through to December).  In this case 
the logged in user should only ever enter one of 12 values, since they typically should not be entering any text, 
instead they are simply selecting one of the pre-defined drop down values.
If the server receiving this form has followed secure coding practices, it will typically check that the form field 
matches one of the 12 allowed values, and then considers it valid.  If the form field does not match, it returns 
an error, and may log a message in the server.  This prevents the attacker from exploiting this particular field, 
however this is unlikely to deter an attacker and they would move onto other form fields.
REVIEWING SECURITY ALERTS
Reviewing Security Alerts
176
Reviewing Security Alerts
In this scenario we have more information available to us than we have recorded.  We have returned an error 
back to the user, and maybe logged an error on the server.  In fact we know a lot more; an authenticated user 
has entered an invalid value which they should never have been able to do (as it’s a drop down list) in normal 
usage. 
This could be due to a few reasons:
• There’s a bug in the software and the user is not malicious.
• An attacker has stolen the users login credentials and is attempting to attack the system.
• A user has logged in but has a virus/trojan which is attempting to attack the system.
• A user has logged in but is experiencing a man-in-the-middle attack.
• A user is not intending to be malicious but has somehow changed the value with some browser plugin, etc.
If it’s the first case above, then the company should know about it to fix their system.  If it’s case 2, 3 or 3 then the 
application should take some action to protect itself and the user, such as reducing the functionality available 
to the user (i.e. no PII viewable, can’t change passwords, can’t perform financial transactions) or forcing further 
authentication such as security questions or out-of-band authentication.  The system could also alert the user 
to the fact that the unexpected input was spotted and advise them to run antivirus, etc., thus stopping an 
attack when it is underway.
Obviously care must be taken in limiting user functionality or alerting users encase it’s an honest mistake, so 
using a risk score or noting session alerts should be used.  For example, if everything has been normal in the 
browsing session and 1 character is out of place, then showing a red pop-up box stating the user has been 
hacked is not reasonable, however if this is not the usual IP address for the user, they have logged in at an 
unusual time, and this is the 5th malformed entry with what looks like an SQL injection string, then it would be 
reasonable for the application to react.  This possible reaction would need to be stated in legal documentation.
In another scenario, if an attacker has got through the application defenses extracted part of the applications 
customer database, would the company know?  Splitting information in the database into separate tables 
makes sense from an efficiency point of view, but also from a security view, even putting confidential 
information into a separate partition can make it harder for the attacker.  However if the attacker has the 
information it can be hard to detect and applications should make steps to aid alerting software (e.g. SIEM 
systems).  Many financial institutions use risk scoring systems to look at elements of the user’s session to give 
a risk score, if Johnny always logs in at 6pm on a Thursday from the same IP, then we have a trusted pattern. 
If suddenly Johnny logs in at 2:15am from an IP address on the other side of the world, after getting the 
password wrong 7 times, then maybe he’s jetlagged after a long trip, or perhaps his account has been hacked. 
Either way, asking him for out-of-band authentication would be reasonable to allow Johnny to log in, or to 
block an attacker from using Johnny’s account.
If the application takes this to a larger view, it can determine that on a normal day 3% of the users log on 
in what would be considered a riskier way, i.e. different IP address, different time, etc.  If on Thursday it sees 
this number rise to 23% then has something strange happened to the user base, or has the database been 
hacked?  This type of information can be used to enforce a blanket out-of-band authentication (and internal 
investigation of the logs) for the 23% of ‘riskier’ users, thereby combining the risk score for the user with the 
overall risk score for the application.
177
Another good option is ‘honey accounts’ which are usernames and passwords that are never given out to 
users.  These accounts are added just like any other user, and stored in the DB, however they are also recorded 
in a special cache and checked on login.  Since they are never given to any user, no user should ever logon with 
them, however if one of those accounts are used, then the only way that username password combination 
could be known is if an attacker got the database, and this information allows the application to move to a 
more secure state and alert the company that the DB has been hacked.
What to Review
When reviewing code modules from a security alerting point of view, some common issues to look out for 
include:
• Will the application know if it’s being attacked?  Does it ignore invalid inputs, logins, etc. or does it log them 
and monitor this state to capture a cumulative perception of the current risk to the system?
• Can the application automatically change its logging level to react to security threats?  Is changing security 
levels dynamic or does it require a restart?
• Does the SDLC requirements or design documentation capture what would constitute a security alert?  Has 
this determination been peer reviewed?  Does the testing cycle run through these scenarios?
• Does the system employ ‘honey accounts’ such that the application will know if the DB has been compromised?
• Is there a risk based scoring system that records the normal usage of users and allows for determination or 
reaction if the risk increases?
• If a SIEM system is being used, have appropriate triggers been identified?  Has automated tests been created 
to ensure those trigger log messages are not accidentally modified by future enhancements or bug fixes?
• Does the system track how many failed login attempts a user has experienced?  Does the system react to this?
• Does certain functionality (i.e. transaction initiation, changing password, etc) have different modes of 
operation based on the current risk score the application is currently operating within?
•  Can the application revert back to ‘normal’ operation when the security risk score drops to normal levels?
• How are administrators alerted when security risk score rises? Or when a breach has been assumed?  At an 
operational level, is this tested regularly?  How are changes of personnel handled?
Reviewing Security Alerts
178
Attack detection undertaken at the application layer has access to the complete context of an interaction 
and enhanced information about the user. If logic is applied within the code to detect suspicious activity 
(similar to an application level IPS) then the application will know what is a high-value issue and what is noise. 
Input data are already decrypted and canonicalized within the application and therefore application-specific 
intrusion detection is less susceptible to advanced evasion techniques. This leads to a very low level of attack 
identification false positives, providing appropriate detection points are selected.
The fundamental requirements are the ability to perform four tasks:
1. Detection of a selection of suspicious and malicious events.
2. Use of this knowledge centrally to identify attacks.
3. Selection of a predefined response.
4. Execution of the response.
22.1 Description
Applications can undertake a range of responses that may include high risk functionality such as changes to 
a user’s account or other changes to the application’s defensive posture. It can be difficult to detect active 
defense in dynamic analysis since the responses may be invisible to the tester. Code review is the best method 
to determine the existence of this defense.
Other application functionality like authentication failure counts and lock-out, or limits on rate of file uploads 
are ‘localized’ protection mechanisms. This sort of standalone logic is ‘not’ active defense equivalents in 
the context of this review, unless they are rigged together into an application-wide sensory network and 
centralized analytical engine.
It is not a bolt-on tool or code library, but instead offers insight to an approach for organizations to specify 
or develop their own implementations – specific to their own business, applications, environments, and risk 
profile – building upon existing standard security controls.
What to Review
In the case where a code review is being used to detect the presence of a defense, its absence should be noted 
as a weakness. Note that active defense cannot defend an application that has known vulnerabilities, and 
therefore the other parts of this guide are extremely important. The code reviewer should note the absence 
of active defense as a vulnerability.
The purpose of code review is not necessarily to determine the efficacy of the active defense, but could simply 
be to determine if such capability exists.
Detection points can be integrated into presentation, business and data layers of the application.  Application-
specific intrusion detection does not need to identify all invalid usage, to be able to determine an attack. There 
is no need for “infinite data” or “big data” and therefore the location of “detection points” may be very sparse 
within source code.
REVIEW FOR ACTIVE DEFENSE
Reviewing for Active Defense
179
A useful approach for identifying such code is to find the name of a dedicated module for detecting suspicious 
activity (such as OWASP AppSensor). Additionally a company can implement a policy of tagging active defense 
detection points based on Mitre’s Common Attack Pattern Enumeration and Classifcation (CAPEC), strings 
such as CAPEC-212, CAPEC-213, etc.
The OWASP  AppSensor detection point type identifiers and CAPEC codes will often have been used in 
configuration values (e.g. [https://code.google.com/p/appsensor/source/browse/trunk/AppSensor/src/test/
resources/.esapi/ESAPI.properties?r=53 in ESAPI for Java]), parameter names and security event classification. 
Also, examine error logging and security event logging mechanisms as these may be being used to collect 
data that can then be used for attack detection. Identify the code or services called that perform this logging 
and examine the event properties recorded/sent. Then identify all places where these are called from.
An examination of error handling code relating to input and output validation is very likely to reveal the 
presence of detection points.  For example, in a whitelist type of detection point, additional code may have 
been added adjacent, or within error handling code flow:
In some situations attack detection points are looking for blacklisted input, and the test may not exist otherwise, 
so brand new code is needed.  Identification of detection points should also have found the locations where 
events are recorded (the “event store”). If detection points cannot be found, continue to review the code for 
execution of response, as this may provide insight into the existence of active defense.
The event store has to be analysed in real time or very frequently, in order to identify attacks based on 
predefined criteria. The criteria should be defined in configuration settings (e.g. in configuration files, or read 
from another source such as a database).  A process will examine the event store to determine if an attack is in 
progress, typically this will be attempting to identify an authenticated user, but it may also consider a single 
IP address, range of IP addresses, or groups of users such as one or more roles, users with a particular privilege 
or even all users. 
Once an attack has been identified, the response will be selected based on predefined criteria. Again an 
examination of configuration data should reveal the thresholds related to each detection point, groups of 
detection points or overall thresholds.
The most common response actions are user warning messages, log out, account lockout and administrator 
notification. However, as this approach is connected into the application, the possibilities of response actions 
are limited only by the coded capabilities of the application.
Search code for any global includes that poll attack identification/response identified above. Response actions 
(again a user, IP address, group of users, etc) will usually be initiated by the application, but in some cases other 
applications (e.g. alter a fraud setting) or infrastructure components (e.g. block an IP address range) may also 
be involved.
Examine configuration files and any external communication the application performs. 
  if ( var !Match this ) {
      Error handling
      Record event for attack detection
  }
Reviewing for Active Defense
180
The following types of responses may have been coded:
• Logging increased
• Administrator notification
• Other notification (e.g. other system)
• Proxy
• User status change
• User notification
• Timing change
• Process terminated (same as traditional defenses)
• Function disabled
• Account log out
• Account lock out
• Collect data from user.
Other capabilities of the application and related system components can be repurposed or extended, to 
provide the selected response actions. Therefore review the code associated with any localised security 
measures such as account lock out.
References
• The guidance for adding active response to applications given in theOWASP_AppSensor_Project
• Category: OWASP Enterprise Security API
• https://code.google.com/p/appsensor/ AppSensor demonstration code
Reviewing for Active Defense
181
Race Conditions occur when a piece of code does not work as it is supposed to (like many security issues). They 
are the result of an unexpected ordering of events, which can result in the finite state machine of the code to 
transition to a undefined state, and also give rise to contention of more than one thread of execution over the 
same resource. Multiple threads of execution acting or manipulating the same area in memory or persisted 