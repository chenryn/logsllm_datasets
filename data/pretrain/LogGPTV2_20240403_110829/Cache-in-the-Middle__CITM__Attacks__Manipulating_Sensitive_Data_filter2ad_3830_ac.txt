accomplished by the micro kernel running inside IEE. To bypass
the data cleaning operation, the attackers should lock the memory
overwriting on the L1 cache (i.e., preventing the data on L1 cache
from being evicted to memory). However, the eviction actions of
the L1 cache are determined by the memory operations on that
core and the core-isolated memory pages’ cache attributes. The
attackers cannot control the eviction by manipulating another core.
In addition, the cache attributes of the core-isolated memory are
controlled and protected by the micro kernel running in the IEE.
SANCTUARY defends against the concurrently running mali-
cious OS by protecting both memory and L2 cache. It allocates core-
isolated memory for each IEE. The memory isolation is achieved
through the Identity-based Filtering feature (see Section 2.1). Par-
ticularly, it assigns each core with a unique Non-Secure Access
IDentifier (NSAID), and allocates isolated memory regions for each
NSAID by configuring TZC-400. Since existing ARM platforms do
not support to assign the NSAID at the granularity of CPU core, i.e.,
all the CPU cores share the same NSAID, the memory isolation is
achieved through the ARM Fast Models virtualization tools rather
than on the actual development board. Protection of the L2 cache
is achieved by configuring the protected memory region as outer
non-cacheable. Thus, the sensitive data do not pass through the L2
cache, which is usually shared among all cores on the ARM mobile
devices. Since the L1 cache locates inside each core and cannot be
directly accessed from the other cores, SANCTUARY provides no
extra protection on L1 cache during concurrent execution. However,
we identify one Type I attack in SANCTUARY by manipulating the
L1 data cache on a different core.
5.1.2 Type I Attack in SANCTUARY. After investigating the cache
features on the ARM platform, we discover a cache attribute named
shareability that can be configured to read/write one core’s L1
data cache via operating another core’s L1 data cache [5] 1. The
shareability attribute defines the range of the cache to be ensured
of value coherency. There are two types of shareability domain, i.e.,
the inner shareability domain and the outer shareability domain. The
former ensures the value coherence among the cores inside one
cluster, and the later ensures the value coherence among the cores
1The shareability attribute works only for L1 data cache, but not L1 instruction cache.
Session 3E: Fuzzing/Trusted Execution Environments CCS '20, November 9–13, 2020, Virtual Event, USA1006in all clusters. When the ARM platforms have more than one group
of cores, each group represents a cluster. For instance, the Juno
r2 development board is equipped with two clusters, one cluster
with a quad-core Cortex-A53 processor and another cluster with a
dual-core Cortex-A72 processor [9].
Since value coherency is naturally ensured on the single-core
platforms, the shareability attribute is only configurable on the
multi-core platforms [8]. It only works when the processors run in
the Symmetric Multi-Processing (SMP) mode [8], which is set by de-
fault on most multi-core platforms. When the shareability attribute
is set, the value coherency can be ensured by the Snoop Control Unit
(SCU), which contains buffers that handle direct cache-to-cache
transfers between cores [7]. If the value on one core’s L1 data cache
is modified, SCU synchronizes the changes to the L1 data cache of
other same-cluster cores if the corresponding memory page is set
as inner shareable. The changes will be synchronized to all other
cores if the memory page is set as outer shareable [8]. For security
reason, the data on non-secure cache will not be synchronized to
secure cache, and vice versa.
We conduct a series of experiments to better understand the
impacts of the shareability attribute on the non-secure L1 data
cache [5] (see Appendix A). The results show that the data on
one core’s L1 data cache could be leaked out to and tampered by
another core, when both cores run in the normal world (it ensures
the corresponding cache lines to be non-secure) and access the same
physical memory address with that memory page’s cache attribute
set as inner shareable or outer shareable for both cores. The cache
attribute is configured separately for each core since it is configured
in the page tables, and each core has its own set of page tables. In
contrast, data on one core’s L1 data cache could not be leaked out to
and tampered by another core, when the corresponding memory is
set as non-shareable (i.e., inner&outer non-shareable) for that core.
5.1.3 Attacking Procedure. We simulate the cache operations of
Sanctuary on the i.MX6Quad SABRE development board. As illus-
trated in Figure 4, core_0 and core_1 are running in the normal
world, and core_2 is running in the secure world. The security-
sensitive application is running on core_0, and the untrusted rich
OS is running on core_1. The Static Trusted App (i.e., the IEE moni-
tor in SANCTUARY) runs on core_2, and it configures the TZC-400
to allocate an isolated memory region for core_0 and disable the
usage of L2 cache for core_0. Though the memory region assigned
to core_0 is non-secure memory, it is protected by the Static Trusted
App to block the access from core_1. The L1 cache lines accessed by
core_0 are non-secure cache, since they are accessed in the normal
world. According to our experimental results listed in Appendix A,
it is possible to affect one core’s L1 data cache by manipulating
another core’s L1 data cache, when both caches are non-secure.
Therefore, the sensitive data in core_0’s L1 data cache might be
stolen or modified through controlling core_1’s L1 data cache.
In Linux kernel, all the cacheable memory is by default set as
shareable (inner or outer shareable). According to the description
in the paper [14], the SANCTUARY system prevents the cache
based attacks by invalidating the L1 cache during the IEE context
switching processes and changing the cacheability attribute of the
core-isolated IEE memory to be inner cacheable, outer non-cacheable
during the runtime of an IEE. Since the shareability attribute is not
Figure 4: CITM Attack on SANCTUARY
configured, the protected memory will be by default set as shareable.
Therefore, we can read and write the sensitive data residing in the
L1 data cache during the concurrent execution (i.e., when an IEE is
running currently with the untrusted rich OS) by leveraging the
shareability attribute. As illustrated by the red lines in Figure 4, we
first craft a page table entry for core_1, configuring the memory
page’s cache attributes as shareable and making its physical address
point to a memory page of core_0 (i.e., a memory page protected
by SANCTUARY). Then, when we access the corresponding virtual
address on core_1, sensitive data in core_0’s L1 data cache could
be stolen or modified due to the value coherency ensured by the
shareability attribute.
In the above attacking procedure, we need to identify physical
addresses of IEE memory (i.e., memory allocated for core_0). Since
the page tables associated with the IEE memory is maintained in
the IEE, the attackers cannot directly obtain its physical address
range. However, the entire physical memory is divided into three
parts, i.e., IEE memory, TEE memory (memory allocated for the
secure world), and unprotected memory (memory allocated for the
untrusted rich OS). The address range of the unprotected memory
is naturally known to the malicious rich OS. The remaining two
memory regions can be distinguished since the cache corresponding
to IEE memory is non-secure while the cache of TEE memory
is secure. Though reading the TEE memory will always return
zero or generate an exception (depending on the configuration of
TZASC), reading of IEE memory can obtain real data when the
memory data is buffered in the cache. Therefore, we can identify
the IEE memory through probing the memory region apart from
the unprotected memory. Since the size of cache is normally smaller
than IEE memory, we may need to probe several times to identify
the entire IEE address range. The probing times depend on the size
of IEE and TEE memory, the time durance of IEE data in L1 data
cache, etc.
Note since the cache shareability attribute is not well-known
and never mentioned in SANCTUARY paper [14], when other de-
velopers follow the paper for reimplementation, there is a high
probability that their systems are prone to the same problem.
configureCore_0Security-sensitive ApplicationsL1 NS-cacheUntrustedRich OSL1 NS-cacheStatic Trusted AppL1 S-cacheL2 cacheNS-cacheS-cacheTZC-400Protected by Static Trusted AppProtected by TrustZoneCore_1Core_2MemoryNormal WorldSecure  WorldSANCTUARY ProcedureAttackProcedureData SynchronizationSession 3E: Fuzzing/Trusted Execution Environments CCS '20, November 9–13, 2020, Virtual Event, USA10075.2 Ginseng: Mapping to Non-Secure Cache
As described in Section 2.3, Ginseng is an IEE system that protects
the sensitive data by storing and processing them in registers. As
such, Ginseng is immune to the Type I attack. Also, since the con-
tents in registers do not pass through cache, it is immune to the
Type III attack too. However, we discover that Ginseng suffers from
the Type II attack. Ginseng relies on the TEE monitor running in
the secure world to perform the data cleaning operations during
the "switch out" process. Since the rich OS cannot be trusted, the
control flow is transferred directly from the IEE to the TEE monitor
by accessing the secure memory in the IEE in order to trigger a
secure interrupt. However, by manipulating the non-secure cache
(that maps to the secure memory) in the normal world, the attack-
ers can block the control flow switching from the IEE to the IEE
monitor and thus bypass the data cleaning operations.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
/*sensitive function*/
int genCode(sensitive long key_top,
sensitive long key_bottom) {
// operations for insensitive data
...
// invoke sensitive function
hmac_sha1(key_top, //sensitive data
//sensitive data
//insensitive data
//insensitive data
key_bottom,
challenge,
resultFull);
truncatedHash
// truncate 20-byte hmac_sha1() result to 4-byte
↩→
...
// invoke insensitive function
printf("OTP: %06d\n", truncatedHash);
return truncatedHash;
}
/*sensitive function*/
void run(){
// mark the protected data as sensitive
sensitive long key_top, key_bottom;
// read keys from TEE secure world
ss_read(UUID1, UUID2, key_top);
ss_read(UUID3, UUID4, key_bottom);
// invoke sensitive function
genCode(key_top, key_bottom);
}
hmac_sha1 (line 7) are sensitive functions. Function printf() (line
14) is an insensitive function, whose code integrity is not guaran-
teed. All sensitive data associated operations are executed in the
registers instead of in the memory.
To defend against malicious kernel, Ginseng introduces six se-
cure API functions to transfer the control flow directly from user
space of the normal world to GService (i.e., the IEE monitor in
Ginseng). Two of the secure API functions are provided for the
programs to securely interact with GService i.e., ss_write() and
ss_read(). Another four secure API functions will be inserted to
the program automatically by the compiler. The ss_saveCleanV()
and ss_readV() are two secure API functions inserted before and
after each function invocation inside the sensitive functions, where
the former is responsible for encrypting the sensitive data, storing
the encrypted data in memory, and cleaning the corresponding reg-
isters, and the later takes charge of decrypting the sensitive data and
restoring them into registers. For example, the ss_saveCleanV()
and ss_readV() will be inserted before and after the printf()
function (line 14) inside genCode(). Another two secure API func-
tions ss_start() and ss_exit() are inserted at the begin and end
of each sensitive function to conduct preparation work (e.g., per-
forming code integrity check for the sensitive function) and clean
all sensitive registers to prevent data leakage, respectively.
Before "switching out" of the IEEs, Ginseng achieves a cross-
world context switching directly from the IEEs that run in the
user space of the normal world to the GService that runs in the
secure world, and performs the security-sensitive operations (e.g.,
encrypting the sensitive data, cleaning the sensitive registers etc.)
in the GService. The normal way to trigger the cross-world context
switching is invoking the high privileged SMC instruction from
kernel space. However, the approach is not applicable in Ginseng,
since its IEEs run in the user space and are not able to invoke the
SMC instruction. Ginseng resolves the problem by triggering a se-
curity violation in the IEEs. Specifically, each secure API function
is assigned a unique secure memory by configuring TZASC. Then,
the invocation of a secure API function will trigger a security vio-
lation since it attempts to access secure memory from the normal
world. By default, the processor raises an external abort (EA) in the
normal world when handling the violation. To raise the EA in the
secure world, GService sets the external abort bit of the Secure
Configuration Register, so that GService can obtain the EA and
handle the requests sent by secure APIs without the attendance of
the malicious kernel.
Listing 1: A Sample Program Protected by Ginseng
5.2.1 Data Protection Mechanisms. We illustrate the working flow
of Ginseng system through a sample program shown in Listing 1.
The program is to perform a hmac_sha1 operation based on two
keys obtained from the secure world. Specifically, two local vari-
ables are marked to be protected as sensitive, i.e., key_top and
key_bottom (line 21). Ginseng provides a compiler to perform static
taint analysis for identifying all variables that may carry sensitive
data and allocating them in the registers. The functions involv-
ing sensitive data are identified as sensitive functions, and will
undergo code integrity check before being executed. In this exam-
ple, the functions run() (line 19), genCode() (lines 2 and 26), and
5.2.2 Type II Attack in Ginseng. However, this triggering solu-
tion could be manipulated since the cache lines corresponding
to the secure memory are non-secure. We use the secure API
ss_saveCleanV() as an example to illustrate the problem (lines 11
to 19 in Listing 2 are the implementation of ss_saveCleanV() in
Ginseng). It first loads the address of __channel_save_clean (the
secure memory assigned to ss_saveCleanV()) into register x4 (line
16). Then it loads the data from the secure memory located at x4 to
the register x0 (line 18). Figure 5 illustrates the detailed execution
flow. 1○ When the "secure memory loading" instruction (i.e., line
18) is executed, the processor tries to load data from cache. 2○ The
cache fetches data from secure memory due to cache miss. 3○ An
external abort is raised since accessing secure memory from normal
Session 3E: Fuzzing/Trusted Execution Environments CCS '20, November 9–13, 2020, Virtual Event, USA10083○,
the secure memory before step 1○ is executed. Then, when the pro-
cessor tries to load data from cache through the "secure memory
loading" instruction (i.e., step 1○), it encounters a cache hit rather
than cache miss. As such, the step 2○* will be executed while the
normal execution of steps 2○,
4○ and 5○ are blocked. Finally,
in step 6○, the insensitive function insensitive_func() could be
manipulated to read the uncleaned sensitive registers, since it is