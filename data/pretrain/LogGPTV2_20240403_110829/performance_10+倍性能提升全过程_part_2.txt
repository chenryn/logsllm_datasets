这500的tps算是一个老中医的经验。不过有些系统调整过Local Port取值范围，比如从1024到65534，那么这个tps上限就是1000附近。
同时观察这个时候CPU的主要花在sy上，最理想肯定是希望CPU主要用在us上，截图如下：
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/10+倍性能提升全过程/05703c168e63e968-05703c168e63e96821ea9f921d83712b.png)
**规则：性能优化要先把CPU从SI、SY上的消耗赶到US上去(通过架构、系统配置）；然后提升 US CPU的效率(代码级别的优化）**
sy占用了30-50%的CPU，这太不科学了，同时通过 netstat 分析连接状态，确实看到很多TIME_WAIT：
![localportissue-time-wait.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/10+倍性能提升全过程/2ae2cb8b0cb324b6-2ae2cb8b0cb324b68ca22c48c019e029.png)
**cpu要花在us上，这部分才是我们代码吃掉的**
***于是让PE修改了tcp相关参数：降低 tcp_max_tw_buckets和开启tcp_tw_reuse，这个时候TPS能从1000提升到3000***
鼓掌，赶紧休息，迎接双11啊
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/10+倍性能提升全过程/91353fb9c88116be-91353fb9c88116be3ff109e3528a4651.png)
## 测试环境优化到3000 TPS后上线继续压测
**居然性能又回到了500，太沮丧了**，其实最开始账号绑定慢，Passport这边就怀疑taobao api是不是在大压力下不稳定，一般都是认为自己没问题，有问题的一定是对方。我不觉得这有什么问题，要是知道自己有什么问题不早就优化掉了，但是这里缺乏证据支撑，也就是如果你觉得自己没有问题或者问题在对方，一定要拿出证据来(有证据那么大家可以就证据来讨论，而不是互相苍白地推诿）。
这个时候Passport更加理直气壮啊，好不容易在测试环境优化到3000，怎么一调taobao api就掉到500呢，这么点压力你们就扛不住啊。 但是taobao api那边给出调用数据都是1ms以内就返回了(alimonitor监控图表--拿证据说话）。
看到alimonitor给出的api响应时间图表后，我开始怀疑从优酷的机器到淘宝的机器中间链路上有瓶颈，但是需要设计方案来证明这个问题在链路上，要不各个环节都会认为自己没有问题的，问题就会卡死。但是当时Passport的开发也只能拿到Login和Userservice这两组机器的权限，中间的负载均衡、交换机都没有权限接触到。
在没有证据的情况下，肯定机房、PE配合你排查的欲望基本是没有的(被坑过很多回啊，你说我的问题，结果几天配合排查下来发现还是你程序的问题，凭什么我要每次都陪你玩？），所以我要给出证明问题出现在网络链路上，然后拿着这个证据跟网络的同学一起排查。
讲到这里我禁不住要插一句，在出现问题的时候，都认为自己没有问题这是正常反应，毕竟程序是看不见的，好多意料之外逻辑考虑不周全也是常见的，出现问题按照自己的逻辑自查的时候还是没有跳出之前的逻辑所以发现不了问题。但是好的程序员在问题的前面会尝试用各种手段去证明问题在哪里，而不是复读机一样我的逻辑是这样的，不可能出问题的。即使目的是证明问题在对方，只要能给出明确的证据都是负责任的，拿着证据才能理直气壮地说自己没有问题和干净地甩锅。
**在尝试过tcpdump抓包、ping等各种手段分析后，设计了场景证明问题在中间链路上。**
### 设计如下三个场景证明问题在中间链路上：
1.  压测的时候在userservice ping 依赖服务的机器；
1.  将一台userservice机器从负载均衡上拿下来(没有压力），ping 依赖服务的机器；
1.  从公网上非我们机房的机器 ping 依赖服务的机器；
这个时候奇怪的事情发现了，压力一上来**场景1、2**的两台机器ping淘宝的rt都从30ms上升到100-150ms，**场景1** 的rt上升可以理解，但是**场景2**的rt上升不应该，同时**场景3**中ping淘宝在压力测试的情况下rt一直很稳定(说明压力下淘宝的机器没有问题），到此确认问题在优酷到淘宝机房的链路上有瓶颈，而且问题在优酷机房出口扛不住这么大的压力。于是从上海Passport的团队找到北京Passport的PE团队，确认在优酷调用taobao api的出口上使用了snat，PE到snat机器上看到snat只能使用单核，而且对应的核早就100%的CPU了，因为之前一直没有这么大的压力所以这个问题一直存在只是没有被发现。
**于是PE去掉snat，再压的话 TPS稳定在3000左右**
---
## 到这里结束了吗？ 从3000到5400TPS
优化到3000TPS的整个过程没有修改业务代码，只是通过修改系统配置、结构非常有效地把TPS提升了6倍，对于优化来说这个过程是最轻松，性价比也是非常高的。实际到这个时候也临近双11封网了，最终通过计算(机器数量*单机TPS）完全可以抗住双11的压力，所以最终双11运行的版本就是这样的。 但是有工匠精神的工程师是不会轻易放过这么好的优化场景和环境的(基线、机器、代码、工具都具备配套好了）
**优化完环境问题后，3000TPS能把CPU US跑上去，于是再对业务代码进行优化也是可行的了**。
### 进一步挖掘代码中的优化空间
双11前的这段封网其实是比较无聊的，于是和Passport的开发同学们一起挖掘代码中的可以优化的部分。这个过程中使用到的主要工具是这三个：火焰图、perf、perf-map-java。相关链接：[http://www.brendangregg.com/perf.html](http://www.brendangregg.com/perf.html) ; [https://github.com/jrudolph/perf-map-agent](https://github.com/jrudolph/perf-map-agent)
### 通过Perf发现的一个SpringMVC 的性能问题
这个问题具体参考我之前发表的优化文章[http://www.atatech.org/articles/65232](http://www.atatech.org/articles/65232) 。 主要是通过火焰图发现spring mapping path消耗了过多CPU的性能问题，CPU热点都在methodMapping相关部分，于是修改代码去掉spring中的methodMapping解析后性能提升了40%，TPS能从3000提升到4200.
### 著名的fillInStackTrace导致的性能问题
代码中的第二个问题是我们程序中很多异常(fillInStackTrace），实际业务上没有这么多错误，应该是一些不重要的异常，不会影响结果，但是异常频率很高，对这种我们可以找到触发的地方，catch住，然后不要抛出去(也就是别触发fillInStackTrace)，打印一行error日志就行，这块也能省出10%的CPU，对应到TPS也有几百的提升。
![screenshot.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/10+倍性能提升全过程/36ef4b16c3c400ab-36ef4b16c3c400abf6eb7e6b0fbb2f58.png)
部分触发fillInStackTrace的场景和具体代码行(点击看高清大图）：
![screenshot.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/10+倍性能提升全过程/7eb2cbb4afc2c7d7-7eb2cbb4afc2c7d7007c35304c95342a.png)
对应的火焰图(点击看高清大图）：
![screenshot.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/10+倍性能提升全过程/894bd736dd03060e-894bd736dd03060e89e3fa49cc98ae5e.png)
![screenshot.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/10+倍性能提升全过程/2bb7395a2cc6833c-2bb7395a2cc6833c9c7587b38402a301.png)
### 解析useragent 代码部分的性能问题
整个useragent调用堆栈和cpu占用情况，做了个汇总(useragent不启用TPS能从4700提升到5400）
![screenshot.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/10+倍性能提升全过程/8a4a97cb74724b8b-8a4a97cb74724b8baa3b90072a1914e0.png)
实际火焰图中比较分散：
![screenshot.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/10+倍性能提升全过程/afacc681a9550cd0-afacc681a9550cd087838c2383be54c8.png)
**最终通过对代码的优化勉勉强强将TPS从3000提升到了5400(太不容易了，改代码过程太辛苦，不如改配置来得快）**
优化代码后压测tps可以跑到5400，截图：
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/10+倍性能提升全过程/38bb043c85c7b500-38bb043c85c7b50007609484c7bf5698.png)
## 最后再次总结整个压测过程的问题和优化历程
```
- docker bridge网络性能问题和网络中断si不均衡    (优化后：500->1000TPS)
- 短连接导致的local port不够                   (优化后：1000-3000TPS）
- 生产环境snat单核导致的网络延时增大             (优化后能达到测试环境的3000TPS）
- Spring MVC Path带来的过高的CPU消耗           (优化后：3000->4200TPS)
- 其他业务代码的优化(比如异常、agent等）         (优化后：4200->5400TPS)
```
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/10+倍性能提升全过程/2be2799d1eef982d-2be2799d1eef982d77e5c0a5c896a0e9.png)