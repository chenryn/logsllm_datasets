### The Second Dataset: Booter-Reported Attack Totals

The second dataset is derived from the booters themselves, who, presumably for marketing purposes, maintain a running total of the attacks they have executed. This data has been collected on a weekly basis since November 2017.

#### Data Collection and Analysis
We know that booters use SQL databases to store details of users and attacks, as numerous such databases have been leaked. Additionally, the source code of many booters has also been leaked, revealing PHP code that fetches counts directly from the SQL database. For example:
```php
$TotalUsers = $odb->query("SELECT COUNT(*) FROM 'users'")->fetchColumn(0);
$TotalAttacks = $odb->query("SELECT COUNT(*) FROM 'logs'")->fetchColumn(0);
```
This code retrieves the total number of users and attacks, which are then displayed on the booter's website.

#### Statistical Analysis
A few booters have inflated their counts (e.g., one started counting from 150,000 instead of zero), and some periodically wipe their databases, resetting the counts. One booter reported values that were regularly multiples of 1,000, and we excluded this data. However, no other obvious artificial patterns were observed in the dataset.

To ensure the integrity of the data, we performed several statistical tests on the weekly totals to determine if they might have been algorithmically generated. Count data tends to be heteroskedastic, meaning as numbers increase, the variance in the series also increases. Many of the smaller or shorter booter series showed too high a degree of variance or nonlinearity to perform meaningful tests. However, for the more substantial datasets, we conducted linear regression analysis and White’s heteroskedasticity test. We also performed skewness and kurtosis tests for normality, as real-world data often follow a normal distribution, while faked data would likely produce uniform distributions.

Our analysis indicated that the attack series of the top ten most active booters were normally distributed or heteroskedastic (with most being both) at a 95% confidence level. We further checked for simple multipliers applied to otherwise genuine data but found no sequences of any length with values all divisible by any prime less than 50.

#### Correlation with Reflected Attack Data
The booter self-reported dataset shows a moderate correlation (correlation coefficient of 0.47) with our own reflected attack dataset. Most importantly, it shows large drops in attack numbers at the same times and durations as significant drops in our attack time series, which we believe correspond to law enforcement interventions.

#### Use of the Dataset
This second dataset can also be used to determine when booters first appear, how many are taken down each week, and how many subsequently reappear. Unfortunately, the "birth" data is biased due to irregular intervals in data collection. However, the "death" and "resurrection" data can be analyzed to determine if interventions affect users (they choose to do fewer attacks) or booter operators (they choose to enter or leave the market).

### Modeling the Data

Measuring the direct effect of law enforcement interventions on crime is extremely challenging. Empirical associations, causal effects, and extraneous variables are hard to quantify, making it difficult to demonstrate mechanisms through true experiments. In a forthcoming paper, we attempt to trace these mechanisms empirically through mixed-methods qualitative work. Here, we focus on an in-depth quantitative approach using quasi-experimental designs, which are well-established in criminology and social sciences for making tentative claims about intervention effects.

#### Time Series Design
We adopted a time series design, specifically an interrupted time series approach, which is appropriate for data with interventions occurring at specific points in time, assumed to have an immediate effect. Our time series data, consisting of denial of service attacks, is non-normalized and skewed. Therefore, we used a maximum likelihood estimation approach with a negative binomial regression model, rather than an ARIMA approach, which relies on normally-distributed data.

#### Model Parameters and Results
We restricted our modeling to the period from June 2016 to April 2019, as there is a clear and fairly constant linear trend over this period. Weekly totals were used due to the high volatility of daily attack counts.

Negative binomial regression is well-suited for modeling count data and can account for seasonal patterns and non-stochastic slope components. It has been used to measure the effects of interventions on criminal offending.

For all periods in the time series that dropped significantly below the modelled series, we added dummy 'intervention' variables to model the effect sizes of these disruptions. We identified five statistically significant interventions, which correspond closely to events discussed earlier.

The model parameters are displayed in Table 1, and Figure 2 shows the correspondence between the model and measured attacks. We modeled seasonality over twelve one-month periods and included a component for the changing date of Easter, as booting patterns are strongly linked to school holidays.

#### Key Interventions
- **Xmas2018 Intervention (19/12/2018)**: Lasted for 10 weeks, resulting in a reduction of between 37% and 27% in overall recorded attacks. However, the effect lasted only three weeks in some countries and was not statistically significant in France.
- **Shutdown of HackForums’ SST Section (28/10/2016)**: Market suppression lasted for 13 weeks and longer in some countries.
- **Other Interventions**: Smaller but still significant drops in attack numbers, with takedowns showing delayed effects.

#### Country-Specific Analysis
We analyzed how various interventions affected different countries. Some countries saw similar patterns of growth in attacks, while others experienced unique variations. The detailed results are presented in Table 2 and Figure 2.

### Conclusion
If booters were generating fake data to feed their live attack counters, they would need considerable statistical acumen to reproduce the distributions we observe. While we cannot completely rule out forgery by highly knowledgeable booter operators, it seems unlikely. The booter self-reported dataset, along with our statistical analysis, provides strong evidence that the data is genuine and useful for evaluating the impact of law enforcement interventions.