title:Using Simple Per-Hop Capacity Metrics to Discover Link Layer Network
Topology
author:Shane Alcock and
Anthony McGregor and
Richard Nelson
Using Simple Per-Hop Capacity Metrics to
Discover Link Layer Network Topology
Shane Alcock1, Anthony McGregor1,2, and Richard Nelson1
1 WAND Group, University of Waikato(cid:1)
2 NLANR Measurement and Network Analysis Group,
San Diego Supercomputer Center(cid:1)(cid:1)
{spa1, tonym, richardn}@cs.waikato.ac.nz
Abstract. At present, link layer topology discovery methodologies rely
on protocols that are not universally available, such as SNMP. Such
methodologies can only be applied to a subset of all possible networks.
Our goal is to work towards a generic link layer topology discovery
method that does not rely on SNMP. In this paper, we will present a new
link layer topology discovery methodology based on variable packet size
capacity estimation. We will also discuss the problems that arose from
preliminary testing where diﬀerent brands of network cards aﬀected the
capacity estimates used to detect serializations. As a result, topologically
equivalent links fail to be classiﬁed as such by the capacity estimation
tool. To circumvent this issue, non-VPS methods of capacity estimation
that utilise back to back packet pairs have been investigated as a cali-
bration technique.
1
Introduction
Most topology discovery research focuses on the network (or IP) layer, dealing
with host machines and routers. At present, there are a number of tools that can
successfully perform topology discovery in this capacity. By contrast, there are
few eﬀective topology discovery tools that operate at the link layer. Most existing
tools utilise the Simple Network Management Protocol (SNMP) to perform link
layer topology discovery [1][2][3]. This is an eﬀective and straightforward method
but it requires that SNMP agents are running on every node in the target network
and that the appropriate access strings are known. This is not always possible.
Other tools that operate at the link layer are manufacturer speciﬁc and, as a
result, are even more restricted than SNMP-based tools. The goal is to create
(cid:1) The University of Waikato Network Research Group (WAND) Measurement and
Simulation project is supported by the New Zealand Foundation for Research Science
and Technology under the New Economy Research Fund, Contract UOWX0206.
(cid:1)(cid:1) NLANR Measurement and Network Analysis Group (NLANR/MNA) is supported
by the National Science Foundation (NSF) under cooperative agreement no. ANI-
0129677.
C. Dovrolis (Ed.): PAM 2005, LNCS 3431, pp. 163–176, 2005.
c(cid:1) Springer-Verlag Berlin Heidelberg 2005
164
S. Alcock, A. McGregor, and R. Nelson
a methodology for generic link layer topology discovery that does not rely on
SNMP.
Despite the lack of tools to automate the discovery process, knowledge of a
network’s topology at the link layer is important. Large scale Ethernet networks
linked by switches are becoming increasingly commonplace and it is diﬃcult for
network operators to accurately keep track of all the devices in their network. A
link layer topology discovery tool could form part of a larger network manage-
ment suite that would create and maintain an accurate picture of the network’s
topology. The maintenance portion of the suite would be particularly useful for
spotting unauthorized devices and machines being added to the network, and for
troubleshooting by identifying failing link layer devices. The discovery portion
could be used to check for bottlenecks and redundancy (or a lack thereof), or to
generate a map of the network, which is very diﬃcult to do manually for a large
network.
The lack of link layer topology discovery tools is due to the inherent trans-
parency of the link layer. Link layer devices cannot be communicated with,
queried, or interacted with by a remote computer (except via SNMP). This
means there is no direct way of discovering the existence of these devices. How-
ever, this does not rule out the use of a less direct method. An indirect method
would rely on the link layer devices aﬀecting the performance of the network in
a manner that is detectable and consistent.
Fortunately, one particular class of link layer device imparts a detectable
eﬀect upon any link in which such devices are present. Prasad, Dovrolis, and
Mah’s paper [4] on the eﬀect of store and forward switches on variable packet
size (VPS) capacity estimation tools showed that switches caused VPS capacity
estimation tools to consistently underestimate link capacity. This eﬀect can be
used to detect not only the presence of store and forward switches, but also
the quantity of switches and their capacities in the measured link. This eﬀect is
limited to store and forward devices so the focus of the remainder of this paper
will be on this particular class of devices. In modern Ethernet networks, store
and forward switches are the most common type of link layer device so limiting
the scope to switches only is not unreasonable. Other link layer devices, such
as hubs, require a diﬀerent method to discover and are the subject of future
research.
Initial testing showed that link layer topology can be inferred from VPS
capacity estimates, but it also introduced a more practical diﬃculty with the
methodology. Diﬀerent brands of network interface cards cause VPS capacity
estimation tools to provide diﬀerent estimates for otherwise equivalent links.
This is due to each brand of card having a slightly diﬀerent processing delay for
diﬀerently sized packets, which appears as a variation in the initial serialization
delay at both ends of the link. To alleviate this problem, we have attempted
to use non-VPS capacity estimation techniques as a means of calibrating the
topology discovery system so that the variation in delay at the network cards is
factored out.
Using Simple Per-Hop Capacity Metrics
165
The paper is organised as follows. Section 2 introduces variable packet size
capacity estimation and describes the underlying theories and techniques asso-
ciated with it. The eﬀect of switches on VPS tools and how that eﬀect can be
used to generate link layer topology information will also be discussed. Section 3
presents the results of putting the theory into practice. The practical problems
that arose from testing are described in Sect. 4 and the solutions we have inves-
tigated are detailed in Sect. 5. Section 6 concludes the paper with a discussion
of the current state of the methodology and future work in the area of link layer
topology discovery.
2 Variable Packet Size Capacity Estimation
Variable packet size (VPS) capacity estimation techniques utilize the relationship
between packet size, serialization delay, and capacity. The basic premise is that
serialization delay is proportional to the size of the packet being sent. The larger
the packet, the longer the serialization delay. The capacity of a link is the rate
at which bits can be inserted onto the physical medium and, hence, is directly
related to serialization delay. By measuring round trip times for diﬀerent sized
packets, it is possible to calculate the ratio of change in packet size to change in
serialization delay. This ratio will describe the capacity of the measured link.
A potential problem with the VPS method is the possibility of other delays,
such as queuing, increasing the round trip time by a signiﬁcant amount. The
potential eﬀects of queuing are presented in Fig. 1. Any queuing is going to result
in a round trip time measurement that is not solely aﬀected by serialization delay.
As such, an accurate capacity estimate cannot be made based on such skewed
round trip time measurements. To alleviate this, for each packet size numerous
packets are sent and the minimum round trip time is assumed to have been
unaﬀected by queuing or other delays. This technique has been standard in VPS
capacity estimation since pathchar [5]. VPS capacity estimation tools typically
allow the user to specify the number of packets to be sent for each packet size. In
situations where it is diﬃcult to observe a minimum RTT, the number of probes
may be increased to compensate.
Propogation and processing delays are assumed to be constant. For the pro-
pogation delay, a change would normally indicate a change in path requiring
restarting of the topology discovery process. In the test network used, the dis-
tances are only tens of meters at most so the propogation delay is negligable.
The processing delay is assumed to be deterministic and constant. This has held
true for the switches we have tested, but not the end stations as we will discuss
in section 4.
Tools that use the VPS methodology to generate capacity estimates include
Van Jacobson’s pathchar [5], Mah’s pchar [6], and Downey’s clink [7]. Each tool
uses the same basic algorithm. A packet size is selected at random from a series
of possible packet sizes. A packet of that size that will generate a response from
the destination machine is created and sent. The round trip time for the packet
is then recorded. Once a packet from each possible size has been sent a certain
166
S. Alcock, A. McGregor, and R. Nelson
VPS Capacity Estimation- Results for ALL Packets
)
s
(
i
e
m
T
p
i
r
T
d
n
u
o
R
 0.0009
 0.0008
 0.0007
 0.0006
 0.0005
 0.0004
 0.0003
 0.0002
 0.0001
 0
 200
 400
 800
 600
Packet Size (bytes)
 1000
 1200
 1400
 1600
Fig. 1. This graph shows the complete results of a typical pchar probe of a link. 32
packets were sent at each packet size and each packet size was 32 bytes apart. Note
the diﬀerences in round trip times between equally sized packets, often around half a
millisecond for many of the smaller packet sizes. These diﬀerences are often caused by
queuing. Taking the minimum round trip time at each packet size produces a smooth
straight line which describes the capacity of the link
number of times (this is usually speciﬁed by the user), the minimum round trip
time is calculated for each packet size. Using linear regression, the gradient of a
line that shows packet size versus round trip time can be calculated. Inverting
that gradient will give the estimated capacity of the link.
One major ﬂaw with variable packet size capacity estimation is the fact that
such a method will signiﬁcantly underestimate the capacity of any link that
contains store and forward link layer devices. As described in a paper by Prasad,
Dovrolis, and Mah [4], this eﬀect is due to each store and forward device adding
an extra serialization into the link that is not accounted for by the capacity
estimation tool (see Fig. 2). VPS tools use the TTL ﬁeld of a packet to determine
the number of hops in a link but link layer devices do not decrement the TTL
counter due to their transparency. From the perspective of the VPS tool, each
hop only contains one serialization, regardless of how many switches might be
present. However, the round trip time is multiplied by the number of extra
unnoticed serializations, making the link appear a lot slower than it really is.
For example, a link between two machines contains two store and forward
switches. Both the switches and the Ethernet adaptors on the machines are
operating at the same capacity. This link contains three serialization delays:
one at the originating host, and one for each switch. Each serialization delay
increases the round trip time of a packet sent across the link. Hence, the round
trip time for the link is approximately three times what it would be if there
were no switches in the link. This makes the gradient of the packet size versus
Using Simple Per-Hop Capacity Metrics
167
Fig. 2. A demonstration of the eﬀect of a switch on a link between two hosts. At
the network layer, it appears that the hosts are directly connected. At the link layer,
a switch basically splits the hop into two, creating an extra serialization delay. Since
VPS tools operate at the network layer, they do not take that serialization into account
when making capacity estimates, resulting in underestimation
round trip time line three times what it would normally be. This gradient, when
inverted, would produce a capacity estimate one-third the value of the nominal
capacity.
Although, this underestimation eﬀect is a problem for capacity estimation, it
provides information regarding the presence of store and forward devices. If the
nominal capacity is known (or accurately estimated by another method) prior
to calculating a VPS capacity estimate, the degree of underestimation can be
used to infer the number of extra serializations and, as a result, the number of
link layer devices, within the link. The equation to convert a capacity estimate
into a quantity of serializations is:
Serializations =
nominal capacity
estimated capacity
(1)
Using the above equation gives the number of serializations including the original
serialization at the sending host. This equation works best when all the devices
are operating at the same capacity. If some of the serialization delays are of
diﬀerent lengths, it is no longer a simple case of comparing the VPS estimate to
the nominal capacity. Fortunately, most Ethernet switches have capacities that
make it easier to detect the diﬀering serialization delays.
The serialization delay of a 10 Mbps device is ten times that of a 100 Mbps
device. This relationship also holds between 100 Mbps devices and 1 Gbps de-
vices. As it is unlikely that a single hop will contain ten switches of the same
capacity, it is reasonable to assume that every ten serializations suggested by a
VPS estimate are actually a single serialization for a lower capacity device. By
168