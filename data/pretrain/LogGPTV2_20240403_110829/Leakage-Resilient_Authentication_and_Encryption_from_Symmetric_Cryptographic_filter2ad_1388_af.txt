pages 278–296. Springer, 2004.
106[26] A. Moradi, A. Poschmann, S. Ling, C. Paar, and
H. Wang. Pushing the limits: A very compact and a
threshold implementation of AES. In K. G. Paterson,
editor, EUROCRYPT, volume 6632 of Lecture Notes
in Computer Science, pages 69–88. Springer, 2011.
[27] M. Naor and G. Segev. Public-key cryptosystems
resilient to key leakage. In CRYPTO 2009, volume
5677 of Lecture Notes in Computer Science, pages
18–35. Springer, 2009.
[28] S. Nikova, V. Rijmen, and M. Schl¨aﬀer. Secure
hardware implementation of nonlinear functions in the
presence of glitches. J. Cryptology, 24(2):292–321,
2011.
[29] P. Pessl, F. Standaert, S. Mangard, and F. Durvaux.
Towards leakage simulators that withstand the
correlation distinguisher. ASIACRYPT 2014 rump
session talk, 2014.
[30] C. Petit, F. Standaert, O. Pereira, T. Malkin, and
M. Yung. A block cipher based pseudo random
number generator secure against side-channel key
recovery. In ASIACCS 2008, pages 56–65. ACM, 2008.
[31] K. Pietrzak. A leakage-resilient mode of operation. In
EUROCRYPT 2009, volume 5479 of Lecture Notes in
Computer Science, pages 462–482. Springer, 2009.
[32] E. Prouﬀ and T. Roche. Higher-order glitches free
implementation of the AES using secure multi-party
computation protocols. In B. Preneel and T. Takagi,
editors, CHES 2011, volume 6917 of Lecture Notes in
Computer Science, pages 63–78. Springer, 2011.
[33] F. Regazzoni, W. Yi, and F.-X. Standaert. FPGA
implementations of the AES masked against power
analysis attacks. In COSADE 2011, pp 56-66,
Darmstadt, Germany, February 2011.
[34] M. Rivain and E. Prouﬀ. Provably secure higher-order
masking of AES. In S. Mangard and F. Standaert,
editors, CHES 2010, volume 6225 of Lecture Notes in
Computer Science, pages 413–427. Springer, 2010.
[35] J. Schipper. Leakage-resilient authentication. Msc
thesis, Centrum Wiskunde and Informatica, The
Netherlands, 2010.
[36] F. Standaert, O. Pereira, and Y. Yu. Leakage-resilient
symmetric cryptography under empirically veriﬁable
assumptions. In CRYPTO 2013, volume 8042 of
Lecture Notes in Computer Science, pages 335–352.
Springer, 2013.
[37] F. Standaert, O. Pereira, Y. Yu, J. Quisquater,
M. Yung, and E. Oswald. Leakage resilient
cryptography in practice. In Towards
Hardware-Intrinsic Security - Foundations and
Practice, Information Security and Cryptography,
pages 99–134. Springer, 2010.
[38] Y. Yu and F. Standaert. Practical leakage-resilient
pseudorandom objects with minimum public
randomness. In CT-RSA 2013, volume 7779 of Lecture
Notes in Computer Science, pages 223–238. Springer,
2013.
[39] Y. Yu, F. Standaert, O. Pereira, and M. Yung.
Practical leakage-resilient pseudorandom generators.
In CCS 2010, pages 141–151. ACM, 2010.
APPENDIX
A. PROOF OF THEOREM 1
Consider the following hybrid games:
Hybrid H +. This is the original security game executed as
deﬁned in the experiment Forgeeuf−cma
AL,MAC(n) (Deﬁnition 1, Re-
mark 1). In particular, the q session keys k(i)
(i = 1, 2, . . . , q)
1
are the output of F on random IV s. Let the queried mes-
sages (each containing (cid:96) blocks) be denoted as mi = (cid:104)m(i)
1 ,
(cid:96) (cid:105) (i = 1, 2, . . . , q). The advantage of a q-query ad-
. . . , m(i)
versary AL in Forgeeuf−cma
AL,MAC(n) is (cid:48).
Hybrid H ++. This is the same as hybrid H + except that
the q IV s randomly chosen are distinct. Let ++ denote the
advantage of AL in this hybrid. Using the birthday bound,
we have that:
(cid:12)(cid:12)
(cid:48) − ++(cid:12)(cid:12) ≤ q2
2n+1 .
(1)
Hybrid H∗. This is the same as hybrid H ++ except that
$← {0, 1}n are chosen uniform ran-
the q session keys k(i)
domly and independently. Let ∗ denote the advantage of
1
AL in this hybrid. It is easy to see that:
(cid:12)(cid:12)++ − 
∗(cid:12)(cid:12) ≤ prf .
(2)
This is because using the adversary AL of MAC1, we can
construct a (s, t(cid:48), prf ) against F.
Hybrids H∗
i,j. Next, we successively transform the hybrid
i,j (1 ≤ i ≤ q +1, 0 ≤ j ≤ (cid:96)) by transform-
H∗ into hybrids H∗
ing the normal execution of the block cipher F into an ideal
execution one message block at a time. More precisely, the
hybrids H∗ and H∗
1,1, the out-
1 , m(1)
put of F(k(1)
1 ) while processing the ﬁrst message block
during the ﬁrst tag-generation query is a uniform random
element in {0, 1}n and leakages are simulated (cf. Lemma
1). The processing of the remaining message blocks in the
ﬁrst as well as the later queries is carried out “normally.”
By “normal” we mean that the actual values of F are used
for all except the ﬁrst block of the ﬁrst message and all the
session keys, unless for consistency we are forced to use the
random sampled value in case the inputs (k(1)
1 ) to F
appear again elsewhere later.
1,0 are identical. In hybrid H∗
1 , m(1)
More generally, in the hybrid H∗
i,(cid:96) and H∗
i,j, all the evaluations of
F are treated as ideal until (and including) the jth message
block of the ith tag query. All the remaining evaluations of
F are normal upto the consistency requirement mentioned
i+1,0 are identical for 1 ≤ i ≤
above. The hybrids H∗
q, and the veriﬁcation of the plausible forgery output by AL
is considered as q + 1-st tag query except that the leakages
and the tag are not output. This means that the hybrids
H∗
q+1,j correspond to idealizing the execution of F during the
veriﬁcation stage. Note that the goal of the adversary AL
is to break the strong-unforgeability of MAC1. This means
that either it outputs a forgery on a distinct IV for a possibly
previously queried message, or it outputs a forgery on a
previously queried IV but on a distinct message. We assume
without loss of generality that the forgery output by AL
satisﬁes either of the above two conditions and it makes
exactly q tag request queries. Hence the hybrids H∗
q+1,j will
be present. Note that this last sequence of hybrids may be
107avoided if we try to follow the standard approach of ﬁrst
showing that the construction is a PRF and hence it is a
MAC. But it turns out this way we need more hybrid games
than the current approach.
Next, we show that in the successive hybrids H∗
i,j and
i,j+1 (1 ≤ i ≤ q + 1, 0 ≤ j ≤ (cid:96) − 1), the views of AL
H∗
are computationally identical upto the 2-simulatable leakage
assumption. Let i,j and i,j+1 denote the advantages of AL
in the hybrids H∗
i,j+1, respectively.
i,j and H∗
.
2n
i,j or hybrid H∗
Lemma 5. |i,j − i,j+1| ≤ prf + 2-sim + (q+1)2((cid:96)+1)2
Proof. Using AL as a subroutine, we construct a (s(cid:48), t(cid:48))-
bounded distinguisher DL for the distributions of Lemma 1
that has advantage as indicated on the R.H.S. of Lemma
5. DL simulates hybrid H∗
i,j+1 depending on
whether its input distribution is actual or ideal, respectively.
DL chooses a uniform random shared secret key k, random
session keys ki,1 (1 ≤ i ≤ q), and possibly a random session
key kq+1,1 for veriﬁcation if the target forgery is on a diﬀer-
ent IV. Whenever DL samples a random output value, say
γ, on “key-message” input (α, β) it records the input/output
pair ((α, β), γ) in a table T , in addition to the simulated
leakage S L(˜k∗, β, γ) (˜k∗ $← {0, 1}n). This table is used to
consistently return the same (random) output on the same
input pair. Also, all the block cipher evaluations while the
processing the tag requests return random outputs and sim-
ulated leakages until (including) the jth message block of the
ith tag request. Recall the notation that the j(cid:48)th block of the
i(cid:48)th message is denoted by mi(cid:48),j(cid:48) , and the corresponding key
and the output for the evaluation of F is denoted by ki(cid:48),j(cid:48)
and ki(cid:48),j(cid:48)+1, respectively. A ‘*’ in the superscript of a pa-
rameter, for example, as in k∗
i(cid:48),j(cid:48) , explicitly denotes that the
parameter was chosen uniform randomly and independently
(and was not computed normally).
At this point, DL ﬁrst receives its input d5 upon querying
$← {0, 1}n (cf.
its challenger with Gen(˜k∗
Remark 3). It then uses d5 instead of the simulated leakage
S L(˜k∗
i,j). Note that the output of this round is im-
plicitly set to k(cid:48) (if j = 0, then the session key k∗
i,1 is implic-
itly set to k(cid:48)). It then builds the view for the (i, j + 1)th ex-
ecution of F by querying its challenger for (d1, d3) by query-
ing Enc(mi,j+1) (p0 := mi,j+1). DL then provides AL with
(d1, d3). The remaining steps are executed normally by eval-
uating F with the (known) inputs. In case any inconsistency
arises when F is evaluated with the inputs present in the ta-
ble T , then the corresponding output value recorded in the
table is used. Such a situation does arise when the adver-
sary outputs a possible forgery on a message m(cid:48) w.r.t. the
IV IVi, such that m(cid:48) (cid:54)= mi share a common preﬁx. Also,
note that to evaluate F w.r.t. the (implicit) key k(cid:48), DL has
to use its input distribution to determine the output. This
means that if there are more than two queries to F w.r.t. the
(implicit) key k(cid:48), then DL will abort the simulation. Denote
this abort event by Abort.
i,j, mi,j) with ˜k∗
i,j, mi,j, k∗
i,j
In order for this simulation by DL to AL to be consistent
with the working of MAC1, two events must not occur.
• All the random values sampled (and listed in table T )
must be distinct.
• The abort event Abort mentioned above must not occur.
Let us denote both the events by Collision. The reason for the
ﬁrst of the above conditions is that if the intermediate values
repeat, then a possible pattern could arise in the successive
intermediate values and there by implicitly setting the out-
put of the (i, j)th step to k(cid:48) may lead to inconsistency. Next,
to ensure that the Abort event does not arise, and hence 2-
simulatable assumption suﬃces, we need to make sure that
k(cid:48) is never used as key more than once later. This means
that F is not queried with the input (k∗
i,j, mi,j) more than
once later. Note that if the ﬁrst condition above does not
occur, then the outputs of the later steps are function of pa-
rameters independent of the value k∗
i,j, except possibly once
during the veriﬁcation stage. It is easy to see that:
Pr[Collision] ≤ (q + 1)2((cid:96) + 1)2
2n
.
(3)
Hence the lemma follows from Lemma 1 and (3).
Note that there are at most (q + 1)(cid:96) distinct hybrids H∗
(1 ≤ i ≤ q + 1, 0 ≤ j ≤ (cid:96)) since the hybrids H∗
are identical for 1 ≤ i ≤ q. Also note that the hybrids H∗
and H∗
|
∗ − q+1,(cid:96)| ≤ (q + 1)(cid:96)(prf + 2−sim) +
1,0 are identical as well. Hence we obtain:
(q + 1)3(cid:96)((cid:96) + 1)2
i,(cid:96) and H∗
i+1,0
i,j
.
2n
(4)
1
2n+1
2n−((q+1)((cid:96)+1))2 + (q+1)2((cid:96)+1)2
Lemma 6. q+1,(cid:96) ≤
Proof. In this hybrid, all the evaluations of F are ideal,
that means that distinct “key-message” input pairs produce
random output values, and all the leakages are simulated.
To break the strong-unforgeability property of MAC1, AL
must either output a forgery on a distinct IV for a possibly
previously queried message, or it outputs a forgery on a pre-
viously queried IV but on a distinct message. This implies
that during the veriﬁcation step, conditioned on the event
of no collision of randomly chosen output values, there will
be distinct “key-message” pairs with which F will be queried
and, as a consequence, a random output will be produced.
Further, no collision would imply that the same would hap-
pen with the later message blocks during the veriﬁcation
step, including the ﬁnal block. Note that the probability
of collision is at most (q+1)2((cid:96)+1)2
. Again, conditioned on
the event of no collision, the probability that the tag τ out-
put by AL is a valid forgery for the message m is at most
2n−((q+1)((cid:96)+1))2 . Hence the lemma follows.
2n+1
1
Theorem 1 follows from (1), (2), (4) and Lemma 6.
108