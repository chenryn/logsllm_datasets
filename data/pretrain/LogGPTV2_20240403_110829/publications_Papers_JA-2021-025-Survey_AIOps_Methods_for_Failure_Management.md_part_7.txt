### 4.3.1 Behavioral Models and Anomaly Detection

In many cases, real labeled samples are not available, but it may be possible to obtain a set of behavioral rules or an execution model for the system. This model information is particularly valuable when diagnosing failures (see Section 4.4.2). Using a behavioral model, various pattern-matching approaches can be developed. For example, access to a probabilistic context-free grammar (PCFG) allows an anomaly detection algorithm to identify unlikely structures and detect anomalies. Magpie [11] proposes using PCFGs to model event sequences and detect anomalous requests. A similar approach is used in Reference [26] to detect failures by searching for anomalies in execution paths (i.e., traces), which is especially useful for localizing and diagnosing failures.

More often, a behavioral model of the system is inferred from past execution history, typically expressed in logs. One such model is the Finite State Machine (FSM) [12, 45]. In a study by Fu et al. [45], log entries are first mapped to their corresponding template version, called a log key. Similar log entries are grouped via clustering, and FSMs are learned to model program workflows from log evidence. The resulting model can be used to verify correct program execution and detect software problems. The entire approach was tested on log files from two distributed computing frameworks, achieving 95% accuracy in log key extraction during the detection of different types of manually inserted failures.

Beschastnikh et al. adopt a similar approach with their system CSight [12]. As the primary goal of failure detection is to enable root-cause analysis, the authors also conducted a user study on the usefulness of FSM diagrams compared to other graphical debugging tools for identifying execution errors. The study found that FSM diagrams enabled subjects to identify problems more frequently (+11%) compared to those shown time-spaced diagrams, which were considered less understandable.

In Reference [29], a causal model of request executions is constructed from component-level trace logs. This model, called The Mystery Machine, identifies predefined causal relationships between components through iterative refinement. According to the authors, The Mystery Machine can be used to conduct an anomaly analysis of service requests based on segment features, allowing the aggregation of similar requests by structure and latency. This inspection helped identify unnecessary debugging components occasionally returned in user requests.

### 4.3.2 Internet Traffic Classification (ITC)

Internet Traffic Classification (ITC) is a task connected to network failure detection. ITC categorizes packets exchanged by a network system to identify network problems, optimize resource provisioning, and improve Quality-of-Service [43, 97]. It can be applied to analyze local network flow, incoming server requests, or outgoing responses. ITC is also widely used for cybersecurity purposes, such as intrusion detection [97, 142]. These supported areas are connected to the appearance of failures, justifying the discussion of ITC as part of failure management.

Moore et al. [97] propose using Supervised Machine Learning to classify observed Internet traffic. Their work selects relevant features from a set of 248 discriminative variables (such as payload size, TCP port, etc.) to train a Naïve Bayes classifier and separate traffic into different categories (e.g., application-wise, maliciousness vs. legitimacy, etc.). The approach is later augmented with kernel estimation to overcome the limitations of the Gaussian assumption.

In a follow-up work [8], the Bayesian framework is extended to Bayesian Neural Networks, reaching 95–99% accuracy depending on the specific test case. Este et al. [43] develop a framework based on SVM models for TCP traffic classification. Single-direction traffic flows between nodes are classified with multi-class kernel SVMs, depending on the application-level protocol they utilize. Single-class (one-versus-all) models are also trained to set apart outlier packets. The model achieves correct prediction rates of over 90% on three datasets under test.

Wang et al. [142] propose an end-to-end classification method for encrypted traffic based on 1D CNN. The input to the CNN is raw packet data grouped according to different conventions, such as flow and session. The approach is evaluated on a public dataset (ISCX) containing both VPN and non-VPN data, where it is used to assign observed traffic into one of 14 categories defined based on the application (e.g., E-mail, streaming, chat, etc.). The 1D CNN model improves the state of the art on the described dataset by approximately 10% in terms of precision and 8% in terms of recall.

### 4.3.3 Log Enhancement

Log enhancement aims to improve the quality and expressiveness of system logs, which are frequently used for detection and diagnosis tasks by IT operators and AIOps algorithms.

Zhu et al. [168] propose a logging suggestion tool called LogAdvisor to learn practical logging suggestions from existing log instances. In code snippets, several structural, syntactical, and textual features are extracted and filtered based on information gain. A decision tree is then trained to suggest logging of snippets as a binary classification problem. The approach is compared to several baselines, including a random 50% predictor, a previous algorithmic approach called ErrLog [155], and other Machine Learning models. LogAdvisor is shown to reduce logging overhead compared to ErrLog when logging is not required, although it is less precise and may occasionally miss informative print statements.

In Reference [163], an approach for automated placement of log printing statements (Log20) based on information theory is proposed. First, entropy is shown to be an informative measure for the placement of printing statements. Then, a greedy dynamic programming algorithm for placing printing statements is implemented. The overall approach is tested on four popular distributed systems, where Log20 can be as informative as different log-level policies while significantly reducing the print overhead (from 1.58 entries per request down to 0.08 for the INFO log level).

### 4.4 Root-Cause Analysis (RCA)

Failure detection involves the collection of symptoms, i.e., observations indicative of failures. Root-cause analysis, on the other hand, is the process of inferring the set of faults that generated a given set of symptoms [130]. In a complex and distributed system, it is first necessary to isolate and restrict the analysis to the responsible component or functional subsystem, a task known as fault localization.