monitoring units could be enhanced in the following
ways for the purpose of attack detection:
Event Filtering for BTS: Currently, none of com-
mercially available processor supports Event Filtering
for BTS. Although Intel Core i7 supports Event Filtering
for LBR, its register stack is not big enough for security
diagnosis. If the hardware support for more ﬂexible
ﬁltering of events is available, the performance overhead
and complexity of CFIMon could be further reduced
in different usage scenarios. For example, if the BTS
is with the support of selective sampling of only call
or return instructions, the overhead in CFIMon would
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:49:22 UTC from IEEE Xplore.  Restrictions apply. 
be signiﬁcantly lowered when detecting return-oriented
programming.
Co-existing Multiple Counters for Security: The
support for simultaneous monitoring of multiple events
is poor in commodity processors. For example, when
monitoring 4 events at the same time in Intel processors,
the precision is lowered and the performance overhead
increases signiﬁcantly. Hence, we plan to investigate the
hardware support to increase the concurrency level of
performance monitoring, yet without sacriﬁcing perfor-
mance and precision signiﬁcantly. This also enables the
co-existence of CFIMon with performance tuning.
Precise Linear Address Information of Memory
Stores: Although Intel Core i7 supports precise linear
address information of memory operation with event
mem inst retired:latency above threshold, it cannot be
used to detect non-control-data attacks [23] due to the
following reasons: it randomly tags instructions by hard-
ware and only tagged instructions have linear address
information; as the minimal latency threshold is set to
4, it is unable to report memory loads of latency less
than 4 cycles; To enable the detection of non-control-
data attacks by checking the data ﬂow integrity or write
integrity testing [27], it is desirable for the PMUs to
provide with a precise event which can record speciﬁc
memory stores with linear address information.
7. Related Work
There is already a considerable amount of work aiming
at detecting or preventing security attacks and improv-
ing performance counters. However, none of them has
exploited performance counters for the use of attack de-
tection and analysis. In this section, we shortly describe
related literatures in performance counters and discuss
some typical systems in the security area:
7.1. Performance Counters
Performance counters have been used extensively
for performance proﬁling [28] and online optimiza-
tion [29]. Being aware of the importance of perfor-
mance counters, previous researchers have proposed a
variety of architectural techniques in order to provide
low-overhead, non-intrusive and accurate performance
monitoring [19], [21]. Software developers have also
provided a number of interfaces to support simple and
portable uses of diverse performance counters. In this
paper, by exploiting existing hardware and software
support for performance monitoring, we demonstrate
the novel use of performance counters to non-intrusive
detection of security attacks with unmodiﬁed, deployed
applications.
In a recent positional paper, Yuan et al. [30] con-
duct a survey on how diverse PMU features such as
itlb misses, branch miss predict and branch trace store
could be used to detect various attacks. However, their
approach are ad-hoc and there is no uniformed to detect
and analyze different attacks related to violation of
control ﬂow integrity. Avritzer et al. [31] performed a
set of tests to measure CPU, memory and I/O usages
between normal and attacking runs and concluded that
the accumulated resource usages tend to be different.
However,
they failed to show how to leverage the
difference for precise and in-place detection of attacks.
7.2. Control Flow Attacks and its Countermea-
sures
Code-reuse Attacks: Code-reuse
attacks have
emerged recently. Return-to-libc attacks [5] has been
used as an effective means to exploit many security
vulnerabilities. Return-oriented programming [6] and
its variety “pop+jmp” attacks [11] and jump-oriented
programming [7] go a step further by reusing existing
binary sequences instead of function calls, and thus
place much less assumptions on victim programs.
Defending Against Code-reuse Attacks: There are
also a number of efforts aiming at detecting or defend-
ing against code-reuse attacks. For example, ROPde-
fender [32] uses a shadow stack together with binary
rewriting to validate each return target. DynIMA [10]
instead leverages the characteristics of return-oriented
programming of using short code sequences before “ret”
to detect possible attacks. Return-less kernel instead
using compiler-rewriting However, these approaches are
ad-hoc in defending only a special class of code-reuse
attack and most of them require rewrite either source
code or binaries.
Security Through Diversity: Security through run-
ning several diverse copies and comparing the re-
sults [33], [34] has been a useful technique to defend
against a variant of attacks, by increasing the attacking
difﬁculty in requiring understanding and attacking sev-
eral copies simultaneously. When implementing purely
in software, this usually means that the resource con-
sumption will be increased by approximately the num-
ber of diverse copies. Hence, recent researchers exploit
the architectural support and multicore hardware [35]
to reduce the resource consumption and increase per-
formance.
Security Through Randomization: Randomizing
the execution environments such as instruction sets [36],
[37], and address spaces [38] is an effective approach to
defend code-injection attacks or memory errors. As the
environments (ISA, address spaces) assumed by attack-
ers are different from the real execution environments,
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:49:22 UTC from IEEE Xplore.  Restrictions apply. 
attacking code will fail to execute. While effective, it
could incur signiﬁcant performance degradation without
the hardware support [36], or is only effective to a
speciﬁc attack [38].
Control and Data Flow Integrity: Dynamically
enforcing the integrity of control ﬂow [13] or data
ﬂow [39] could defend against attacks aiming at altering
the normal control and data ﬂow. It has also been
implemented in the system address space [40]. However,
it requires binary rewriting of software and would incur
non-trivial performance overhead [16].
Taint Tracking: Taint tracking is a general security
defense technique. It works by marking data from
untrusted channels as tainted, tracking the propagation
of the tags during execution, and checking the tags
before critical uses of data to detect attacks. There
has been a considerable number of systems that extend
existing hardware to support taint tracking
[41], as
well as software-based implementation using compiler
instrumentation [42], running the code in an emula-
tor [43], binary translator [44] and JVM [45]. Compared
to its hardware counterparts, software-based taint track-
ing is more expressive but would result in signiﬁcant
performance overhead (e.g., 3.6X for LIFT [44] and
37X for TaintCheck [43]), or require instrumenting
software [42].
Security on Existing Hardware: As CFIMon, pre-
vious researchers have also leveraged existing hardware
support for security. For example, SHIFT [46] exploits
existing hardware support for control speculation to
implement an efﬁcient and ﬂexible taint tracking sys-
tem. BOSH [47] uses the ﬂow-sensitive tags in taint
tracking to implement an efﬁcient binary obfuscation
system. Compared to CFIMon, these systems require
instrumenting the software using compilers, thus cannot
work on unmodiﬁed and deployed binaries.
8. Conclusion and Future Work
In this paper, we observed that many security exploits
against control ﬂow can result in precisely identiﬁable
control ﬂow deviation in performance samples. Based
on the observation, we designed and implemented CFI-
Mon, which leveraged the branch trace store mechanism
in performance counters for the purpose of detecting
a wide variety of security attacks to control ﬂow,
including classic code-injection attacks and emerging
code-reuse attacks. Our evaluation using several realis-
tic vulnerabilities showed that CFIMon can effectively
detect attacks on these vulnerabilities. Performance re-
sults indicates that CFIMon has modest performance
overhead for real-world applications, and we proposed
our several hardware proposals for further enhancement
to the detection ability and performance in existing
processors.
CFIMon has made its ﬁrst step in using performance
monitoring units for the purpose of attack detection. In
future work, we plan to extend and improve CFIMon in
several directions. First, while this paper only explores
the use of PMU for security attacks, the idea of CFI-
Mon could also be similarly applied to other types of
bugs such as race conditions, ordering violations and
deadlocks, whose behaviors might also result in some
performance anomaly. However, as the performance
anomaly of some types of bugs could be insigniﬁcant
compared to that of security attacks, it would also be
interesting to couple with minor architectural support to
ﬁltering out possible false positives, as those in Event
Filtering. Second, CFIMon does not detect high-level
semantic attacks now, whose explosion usually requires
understanding the high-level semantics of a program.
In our future work, we plan to extend our system with
program semantics to detect such attacks. Finally, CFI-
Mon is designed with the aim of supporting unmodiﬁed
applications. However, if being coupled with compiler
transformation or instrumentation support, it could fur-
ther reduce the complexity and increasing the precision
of CFIMon. In the future, we plan to investigate how
compilers could be used to make applications friendlier
to CFIMon.
Acknowledgments
We thank the anonymous reviewers for their insight-
ful comments. This work was funded by China Na-
tional Natural Science Foundation under grant num-
bered 61003002, a grant from the Science and Technol-
ogy Commission of Shanghai Municipality numbered
10511500100, Fundamental Research Funds for the
Central Universities in China and Shanghai Leading
Academic Discipline Project (Project Number: B114).
References
[1] C. Zou, W. Gong, and D. Towsley, “Code red worm propagation
modeling and analysis,” in Proc. CCS, 2002, pp. 138–147.
[2] D. Moore, V. Paxson, S. Savage, C. Shannon, S. Staniford,
and N. Weaver, “Inside the Slammer worm,” IEEE Security &
Privacy, vol. 1, no. 4, pp. 33–39, 2003.
[3] M. Bailey, E. Cooke, D. Watson, F. Jahanian, and J. Nazario,
“The Blaster Worm: Then and Now,” IEEE Security & Privacy,
vol. 3, no. 4, pp. 26–31, 2005.
[4] PITAC Team, “Cybersecurity: A crisis of prioritization.” Pres-
ident’s Information Technology Advisory Committee (PITAC),
Tech. Rep., Feb. 2005.
[5] R. Wojtczuk, “The advanced return-into-lib (c) exploits: Pax
case study,” Phrack Magazine, Volume 0x0b, Issue 0x3a, Phile#
0x04 of 0x0e, 2001.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:49:22 UTC from IEEE Xplore.  Restrictions apply. 
[6] H. Shacham, “The geometry of innocent ﬂesh on the bone:
Return-into-libc without function calls (on the x86),” in Pro-
ceedings of the 14th ACM conference on Computer and com-
munications security. ACM, 2007, pp. 552–561.
[7] T. Bletsch, X. Jiang, V. Freeh, and Z. Liang, “Jump-oriented
programming: A new class of code-reuse attack,” in Proceedings
of
the 6th ACM Symposium on Information, Computer and
Communications Security. ACM, 2011, pp. 30–40.
[8] C. Cowan, C. Pu, D. Maier, H. Hinton, J. Walpole, P. Bakke,
S. Beattie, A. Grier, P. Wagle, and Q. Zhang, “Stackguard:
Automatic adaptive detection and prevention of buffer-overﬂow
attacks,” in Proc. Usenix Security, 1998.
[9] C. Cowan, M. Barringer, S. Beattie, G. Kroah-Hartman,
M. Frantzen, and J. Lokier, “FormatGuard: Automatic protec-
tion from printf format string vulnerabilities,” in Proc. Usenix
Security, 2001.
[10] L. Davi, A.-R. Sadeghi, and M. Winandy, “Dynamic integrity
measurement and attestation: towards defense against return-
oriented programming attacks,” in Proceedings of the 2009 ACM
workshop on Scalable trusted computing, 2009, pp. 49–54.
[11] S. Checkoway, L. Davi, A. Dmitrienko, A. Sadeghi, H. Shacham,
and M. Winandy, “Return-oriented programming without re-
turns,” in Proc. CCS, 2010, pp. 559–572.
[12] J. Li, Z. Wang, X. Jiang, M. Grace, and S. Bahram, “Defeating
return-oriented rootkits with Return-Less kernels,” in Proc.
Eurosys, 2010, pp. 195–208.
[13] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti, “Control-ﬂow
integrity principles, implementations, and applications,” ACM
Transactions on Information and System Security (TISSEC),
vol. 13, no. 1, pp. 1–40, 2009.
[14] T. Bletsch, X. Jiang, and V. Freeh, “Mitigating code-reuse
attacks with control-ﬂow locking,” in Proc. ACSAC, 2011.
[15] T. Zhang, X. Zhuang, S. Pande, and W. Lee, “Anomalous
path detection with hardware support,” in Proceedings of the
2005 international conference on Compilers, architectures and
synthesis for embedded systems. ACM, 2005, pp. 43–54.
[16] M. Budiu, ´U. Erlingsson, and M. Abadi, “Architectural support
for software-based protection,” in Proc. Workshop on Architec-
tural and system support for improving software dependability,
2006, p. 51.
[17] Y. Shi and G. Lee, “Augmenting branch predictor to secure pro-
gram execution,” in Dependable Systems and Networks, 2007.
DSN’07. 37th Annual IEEE/IFIP International Conference on.
IEEE, 2007, pp. 10–19.
[18] J. Anderson, L. Berc, J. Dean, S. Ghemawat, M. Henzinger,
S. Leung, R. Sites, M. Vandevoorde, C. Waldspurger, and
W. Weihl, “Continuous proﬁling: where have all
the cycles
gone?” ACM SIGOPS Operating Systems Review, vol. 31, no. 5,
p. 14, 1997.
[19] J. Dean, J. Hicks, C. Waldspurger, W. Weihl, and G. Chrysos,
“ProﬁleMe: Hardware support for instruction-level proﬁling on
out-of-order processors,” in Proc. MICRO, 1997, pp. 292–302.
[20] B. Sprunt, “Pentium 4 performance-monitoring features,” IEEE
Micro, vol. 22, no. 4, pp. 72–82, 2002.
[21] AMD, “Instruction-based sampling: A new performance analysis
technique,” developer.amd.com/assets/amd ibs paper en.pdf.
[22] I. Molnar,
“Performance
counters
for
linux,
v8.”
http://lwn.net/Articles/336542, 2009.
[23] S. Chen, J. Xu, E. Sezer, P. Gauriar, and R. Iyer, “Non-Control-
Data Attacks Are Realistic Threats,” in Proc. USENIX Security,
2005.
[24] Metasploit Team, “Metasploit,” http://www.metasploit.com/.
[25] “Exim,” http://www.exim.org/.
[26] B. Fitzpatrick, “Distributed caching with memcached,” Linux
journal, 2004.
[27] P. Akritidis, C. Cadar, C. Raiciu, M. Costa, and M. Castro, “Pre-
venting memory error exploits with WIT,” in IEEE Symposium
on Security and Privacy, 2008, pp. 263–277.
[28] G. Ammons, T. Ball, and J. Larus, “Exploiting hardware per-
formance counters with ﬂow and context sensitive proﬁling,” in
Proc. PLDI, 1997, pp. 85–96.
[29] R. Azimi, M. Stumm, and R. Wisniewski, “Online performance
analysis by statistical sampling of microprocessor performance
counters,” in Proc. Supercomputing, 2005, pp. 101–110.
[30] L. Yuan, W. Xing, H. Chen, and B. Zang, “Security breaches
as pmu deviation: Detecting and identifying security attacks
using performance counters,” in 2011 ACM SIGOPS Asia-paciﬁc
Workshop on Systems, 2011.
[31] A. Avritzer, R. Tanikella, K. James, R. G. Cole, and E. Weyuker,
“Monitoring for security intrusion using performance signa-
tures,” in Proceedings of the ﬁrst joint WOSP/SIPEW interna-
tional conference on Performance engineering, 2010, pp. 93–
104.
[32] L. Davi, A. Sadeghi, and M. Winandy, “Ropdefender: A detec-
tion tool to defend against return-oriented programming attacks,”
in Proceedings of the 6th ACM Symposium on Information,
Computer and Communications Security. ACM, 2011, pp. 40–
51.
[33] B. Cox, D. Evans, A. Filipi, J. Rowanhill, W. Hu, J. Davidson,
J. Knight, A. Nguyen-Tuong, and J. Hiser, “N-variant systems:
A secretless framework for security through diversity,” in Proc.
USENIX Security, 2006, pp. 105–120.
[34] A. Nguyen-Tuong, D. Evans, J. Knight, B. Cox, and J. Davidson,
“Security through redundant data diversity,” in Proc. DSN, 2008,
pp. 187–196.
[35] R. Huang, D. Deng, and G. Suh, “Orthrus: efﬁcient software
integrity protection on multi-cores,” in Proc. ASPLOS, 2010,
pp. 371–384.
[36] G. Kc, A. Keromytis, and V. Prevelakis, “Countering code-
injection attacks with instruction-set randomization,” in Proc.
CCS, 2003.
[37] E. Barrantes, D. Ackley, S. Forrest, and D. Stefanovi´c, “Ran-
domized instruction set emulation,” ACM Transactions on Infor-
mation and System Security (TISSEC), vol. 8, no. 1, pp. 3–40,
2005.
[38] H. Shacham, M. Page, B. Pfaff, E. Goh, N. Modadugu, and
D. Boneh, “On the effectiveness of address-space randomiza-
tion,” in Proc. CCS, 2004, pp. 298–307.
[39] M. Castro, M. Costa, and T. Harris, “Securing software by
enforcing data-ﬂow integrity,” in Proc. OSDI, 2006.
[40] U. Erlingsson, M. Abadi, M. Vrable, M. Budiu, and G. Necula,
“XFI: Software guards for system address spaces,” in Proc.
OSDI, 2006, p. 88.
[41] J. Crandall and F. Chong, “Minos: Control Data Attack Preven-
tion Orthogonal to Memory Model,” in Proc. MICRO, 2004.
[42] W. Xu, S. Bhatkar, and R. Sekar, “Taint-enhanced policy en-
forcement: A practical approach to defeat a wide range of
attacks,” in Proc. USENIX Security, 2006, pp. 121–136.
[43] J. Newsome and D. Song, “Dynamic taint analysis for automatic
detection, analysis, and signature generation of exploits on
commodity software,” in Proc. NDSS, 2005.
[44] F. Qin, C. Wang, Z. Li, H. Kim, Y. Zhou, and Y. Wu, “LIFT: A
Low-Overhead Practical Information Flow Tracking System for
Detecting Security Attacks,” in Proc. MICRO, 2006, pp. 135–
148.
[45] W. Enck, P. Gilbert, B. Chun, L. Cox, J. Jung, P. McDaniel, and
A. Sheth, “TaintDroid: An Information-Flow Tracking System
for Realtime Privacy Monitoring on Smartphones,” in Proc.
OSDI, 2010.
[46] H. Chen, X. Wu, L. Yuan, B. Zang, P. Yew, and F. Chong, “From
Speculation to Security: Practical and Efﬁcient Information Flow
Tracking Using Speculative Hardware,” in Proc. ISCA, 2008, pp.
401–412.
[47] H. Chen, L. Yuan, X. Wu, B. Zang, B. Huang, and P. Yew,
“Control ﬂow obfuscation with information ﬂow tracking,” in
Proc. MICRO, 2009, pp. 391–400.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:49:22 UTC from IEEE Xplore.  Restrictions apply.