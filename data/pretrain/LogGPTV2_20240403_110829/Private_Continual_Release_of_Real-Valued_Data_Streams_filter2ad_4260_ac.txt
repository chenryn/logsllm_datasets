(cid:18)m
(cid:19)
pi(1 − p)m−i.
=
i
i=0
(5)
We denote by βqt the bound on the error probability function
g.
C. Privately Obtaining the λp-Quantile
For this section we assume that xp ≤ ˆxλp holds. As
discussed before, setting the threshold τ to ˆxλp is not private.
To obtain a differentially private estimate, we utilize smooth
sensitivity. As shown in [10], smooth sensitivity can be used
to display the median in a differentially private manner. We
modify the median algorithm described therein to privately re-
lease the λp-quantile. First we compute the smooth sensitivity
of the empirical λp-quantile, i.e., ˆxλp, as
{e−bkLSσ(cid:48)(ˆxλp) : d(σ, σ(cid:48)) ≤ k},
SSσ,b(ˆxλp) =
where
max
k=0,1,...,m+1
LSσ(cid:48)(ˆxλp) = max
t=0,1,...,k+1
|¨σ(P + t) − ¨σ(P + t − k − 1)|.
Here, ¨σ is the sorted string of the ﬁrst m values of σ in
ascending order with 0 added as a prepend and B as an
appendix; and P is the rank of ˆxλp. This can be done in O(m2)
time [10, §3.1].
Warm: After computing the smooth sensitivity, we can set
the threshold τ as
τ = ˆxλp +
SSσ,b(ˆxλp)
a
· noise,
where noise is either the Laplace or standard Gaussian noise.
For both, we can set b ≤
−2 log(δ) as the smoothing parameter
(Deﬁnition 10. If we use the Laplace distribution with scale 1,
2 results in (, δ)-differential privacy. When the noise is
a = 
standard Gaussian, then a = √− ln δ
gives us (, δ)-differential
privacy [10]. However, as discussed in Section IV-A, we
require Pr[τ  m, if
x ≤ τ then we release c(σ, i) through the BT algorithm with
noise Lap( τ log2(n−m)
). This causes an additive error αLap in
the computation of c with an associated error probability βLap.
On the other hand, if x > τ, we instead assume that the new
observation is exactly τ and then again add noise as before.
This induces an additional error term, which we have called
outlier error, denoted αout. We denote the probability of the
outlier error by βout. In the following, we bound these two
errors by ﬁrst assuming the (unrealistic) worst case scenario,
i.e., every new observation after the time lag m steps is
exactly B with probability p. We then use the more realistic
assumption that the distribution of the stream is light-tailed,
and show that based on real-world datasets we are expected to
gain signiﬁcant utility in practice.
A. Worst Case Error
Let ξ denote the PDF of the outlier error and Ξ its CDF. Let
E be a random variable denoting the outlier error and let Ei =
σ(i) − min{σ(i), τ} denote the outlier error of observation i,
which is bounded by B − τ. Assuming each element of σ is
distributed as X ∼ FB (cf. Deﬁnition 4), we have Ξ(x) ≥
F (x− xp) for strictly positive x ∈ X. The worst case is when
the PDF is given as
ξ(x) = ∆(x)(1 − p) + ∆(x − (B − τ ))p,
Clearly, this holds true for any p ≤ pmax as well. Figure 5
shows that this assumption holds for the train trips dataset for
p = 0.005-quantile. The ﬁgure shows the ECDF of travel times
against the CDF of the exponential distribution with parameter
(cf. Fact 1). The assumption also holds
γ =
for the supermarket dataset with the same p-quantile. We omit
the graph due to repetition.
= − ln 0.005
− ln p
xp
x0.005
where ∆ is the Dirac delta function. This means that beyond
the p-quantile, all the values are equal to B. With this as-
sumption we can estimate the (αout, βout)-utility (Deﬁnition 5)
as follows:
(cid:34) n(cid:88)
i=1
Pr
Ei ≥ αout
(cid:35)
≥ exp(hαout)
(cid:35)
(cid:35)
h
i=1
= Pr
(cid:34)
n(cid:88)
Ei ≥ hαout
(cid:32)
(cid:34)
(cid:33)
n(cid:88)
≤ E[exp(h(cid:80)n
(cid:81)n
exp(hαout)
E[exp(hEi)]
i=1
i=1 Ei)]
= Pr
exp
Ei
h
i=1
=
=
=
exp(hαout)
E[exp(hE)]n
exp(hαout)
(1 − p + peh(B−τ ))n
ehαout
= βout.
Solving for αout, we get
n ln(1 − p + peh(B−τ )) + ln 1
.
Fig. 5. The distribution of the train trips dataset compared to an exponential
distribution with the same p = 0.005-quantile. The real distribution is above
the exponential distribution, indicating that it is light-tailed.
βout
αout =
h
The value of h ≈
according to Eq. 4, we want m (cid:29) 1
h (cid:28) 1. The above then becomes
(B−τ )pn minimizes αout. Recall
that
p, which implies that
1
αout = pn(B − τ )
ln
1
βout
+ 1
+ o(1).
Adding this to the utility term αLap from the BT algorithm
(Eq. 3) [5] we see that the overall error α is
(cid:18)
(cid:18)
(cid:19)
(cid:115)
1
βLap
8 ln
(cid:19)
α ≤ 1
