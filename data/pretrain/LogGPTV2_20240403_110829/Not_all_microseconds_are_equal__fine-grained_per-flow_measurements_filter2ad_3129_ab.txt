s
m
/
y
a
e
d
l
n
a
e
m
l
a
c
o
l
s
m
/
y
a
e
d
l
n
a
e
m
l
a
c
o
l
global: RMSRE=12.2
1s: RMSRE=1.72
10ms: RMSRE=0.16
0.1ms: RMSRE=0.054
 0.01
 0.1
 1
 mean delay per src-dst / ms
(a) SANJ
 10
global: RMSRE=0.68 
1s: RMSRE=0.65
10ms: RMSRE=0.33
0.1ms RMSRE =0.055
 0.0001
 0.0001
 0.001
 0.01
 0.1
 1
 10
 mean delay per src-dst / ms
(b) CHIC
Figure 1: Scatter plot of local vs actual mean delay per source-
destination pair; SANJ and CHIC traces, localization intervals
0.1ms, 10ms, and 1s. Global average delay also shown as hori-
zontal line.
In our study, we divide time into ﬁxed interval windows of the
same width, and for each key k and interval i, we record the num-
ber ni,k of packets present in interval i and their average queueing
delay di,k. The average queueing delay encountered by packets
during interval i is
(cid:2)
(cid:2)
k ni,kdi,k
(cid:2)
(cid:2)
i ni,kdi,k
k ni,k
i ni,k
.
.
˜di =
Dk =
Now the average delay encountered by packets of key k is
Hence if our intuition is correct, replacing di,k by ˜di in the def-
inition of Dk, i.e., taking a weighted average of the di weighted
by the numbers of packets ni,k for key k in each intervals, should
yield a fairly accurate approximation of di, at least for sufﬁciently
narrow intervals. We call the result of the substitution localized
mean delay, in full it becomes:
(cid:2)
(cid:2)
(cid:2)
˜di
i ni,k
i ni,k
=
(cid:2)
i,j ni,kni,jdi,j/
i ni,k
(cid:2)
(cid:2) ni,(cid:2)
˜Dk =
Figure 1 displays scatter plots of the localized and true mean
delays per 2-tuple key for SANJ and CHIC, for localization win-
dows of 0.1ms, 10ms and 1s. For clarity, we show only 1 in 4,000
points. Observe closer agreement for smaller windows, while for
large windows the scatter appears to revert to a more horizontal re-
gression, reﬂecting normalization over longer windows. Note that
the localized mean delay is far better predictor of a key’s mean de-
lay than the global average packet delay, shown as a horizontal line.
We quantify the accuracy via the root mean square relative error
29d = 0.01ms
d = 0.03ms
d = 0.1ms
d = 0.3ms
d = 1ms
d = 3ms
 d = 10ms
 1
 0.8
 0.6
 0.4
 0.2
 0
 1e-05
 0.0001
 0.001
 0.01
 0.1
 1
delay burst duration x (seconds)
(a) SANJ
d = 0.01ms
d = 0.03ms
d = 0.1ms
d = 0.3ms
d = 1ms
d = 3ms
 d = 10ms
 1
 0.8
 0.6
 0.4
 0.2
)
d
,
x
(
Q
)
d
,
x
(
Q
 0
 1e-05
 0.0001
 0.001
 0.01
 0.1
 1
delay burst duration x (seconds)
(b) CHIC
Figure 2: Delay burst distributions for traces SANJ and CHIC.
Proportion Q(x, d) of time spent in bursts of duration at least x,
in which delay was at least d, for d = (0.03, 0.1, 0.3, 1, 3, 10)ms.
(RMSRE) over all keys, shown in the plot key. Note that even for
the smallest localization time (0.1ms), the median number of pack-
ets per window was 21 (CHIC) and 35 (SANJ). Thus the accuracy
of the localized mean delay is not simply an artifact of comparing
a key’s packet with itself! Accuracy appears closer for SANJ than
CHIC, presumably a consequence of its higher offered load, as ev-
idenced by the longer mean delays in Table 1. We now relate these
differences speciﬁcally to the burst properties of delay episodes.
2.3 Burst properties of queueing delay
We can further account for the accuracy of the localized mean
delay by examining the temporal properties of delay bursts. For this
purpose, a burst of delay above d corresponds to a maximal set of
some number n of successive packets with arrival times t1, . . . , tn
whose delay exceeds d. In this case, the burst duration is taken as
tn+1 − t1 (or tn − t1 if packet n is the last packet in the trace).
We calculated the proportions Q(x, d) of the time spent a burst of
duration at least x in which the delay was at least d.
The displays of Q in Figure 2 account for the differences ob-
served between SANJ and CHIC. As reference delay we take the
global mean packet delay δ and ask what duration of bursts the
queue spends at least half its time above that level, i.e., what is
the duration τ for which Q(τ, δ) = 1/2? Provided there are suf-
ﬁciently many background packets in a window of duration τ , we
expect the local mean to be fairly accurate. For SANJ, δ = 0.39ms
leading to τ of roughly 10ms, while for CHIC, δ = 0.29ms lead-
ing to τ of roughly 0.1ms. In both cases this is within the small-
est window considered; the larger τ value for SANJ would seem
to account for its greater accuracy, apparent in the Figure 1. We
also found conﬁrmation of our delay model in relating the burst
timescale to the accuracy of localized mean estimates for a given
window for the WEB700 and WEB468 traces (omitted for brevity).
2.4
Implications for measurement design
We now tie together the phenomena of performance diversity and
delay localization with the problem of per-ﬂow delay estimation.
We argue in §3 that a brute force approach in which routers or other
devices timestamp every packet is neither necessary nor feasible to
produce ubiquitous per-ﬂow delay measurements. The major con-
sequence of performance diversity is that performance statistics of
a given ﬂow may differ signiﬁcantly from those of another (such as
a background ﬂow or a probe stream). However, the performance
statistics of two sets of packets will agree more closely, if their
packets transit at roughly the same times, at least within the typical
duration of delay bursts. The crucial observation is that, rather than
measuring the delay of each packet in ﬂow directly, it can be sufﬁ-
cient to infer its performance from that of a set of reference packets
provided the packet transmission times are sufﬁciently close.
Now, routers are particularly well placed to create measurements
from which to determine the transit delay times of packets. Routers
therefore can create a reference stream of packets on a link, giving
rise to a reference set of link delay measurements. Then the delay
of any given ﬂow can be estimated by selecting measurements from
the reference stream that are localized to the packets of the ﬂow un-
der study. This represents a big saving in measurement complexity
due to reuse: For different ﬂows, different reference delay mea-
surements are selected as required from the reference stream. Ef-
fectively, we can improve the accuracy of the delay measurement of
a given ﬂow, by increasing the number of samples contributing to
that measurement, speciﬁcally selecting those that are most likely
to be correlated with it. As an illustrative example, consider a ﬂow
with 100 packets. If a sampling rate of 1-in-100 is used, the ﬂow’s
latency measurements are computed using approximately 1 sample.
With our approach, we can compute the latency measurements with
all 100 packets, except each packet’s latency is estimated using the
reference stream (inducing a small amount of approximation error)
yielding more accurate results.
In view of the relations between estimation accuracy, delay burst
duration, and temporal localization width described above, the ap-
proach is contingent on having a probe stream that is sufﬁciently
dense to encounter a typical ﬂows packets within bursts of delays
of interest. This is easier to accomplish for high loads, delays be-
ing higher and delay bursts being longer. But even when probes are
not sufﬁciently dense for this purpose—resulting in insufﬁciently
narrow localization—we found examples to display no worse ac-
curacy than a naive global average of the type that would be pro-
duced by non-local averaging over a probe stream. We remark that
a recent approach of leveraging background ﬂow records for delay
estimation [25] suffers in this way, because it is inherently unable
to control the temporal disposition of reference measurements.
We believe the relevance of these ﬁndings for our study is not
in the absolute delay values detailed in Table 1, nor the particular
localization timescales found in our study. For example, higher
speed links may be expected to have shorter queueing delays and
hence, shorter timescales for the localization of packet delays. But
this effect is compensated for by the fact that a higher packet rate
link can be expected to accommodate a higher rate reference packet
stream, that can therefore sample delays at a ﬁner granularity. Note
also that our ﬁndings are more relevant within ﬁnancial and data
center networks, that tend to more stringent in the latency bounds
that in a general WAN. For example, a past study [10] found delay
jitter across two POPs to be mostly less than 1ms; however, this
value can mask the signiﬁcant diversity amongst smaller delays at
the level of microseconds that would still impact performance on a
ﬁnancial network.
303. REFERENCE LATENCY INTERPOLATION
In our setting, we consider a stream of packets traveling from
a sender to a receiver (e.g., ingress and egress router interfaces),
and we are interested in estimating per-ﬂow latencies. We assume
ﬁne-grained time synchronization between the sender and receiver.
Within a router, this is straightforward as they both typically oper-
ate within the same clock domain. Even across routers, microsec-
ond precision time-synchronization can be achieved with the help
of primitives such as IEEE 1588 [15] that are increasingly being
deployed within routers.
(Note that the error due to clock syn-
crhonization is an additive component to the estimates computed
by our architecture.) We ﬁrst quickly discuss possible solutions
and see why they may not work well.
3.1 Problems with previous solutions
Naive approach. One way to obtain latency estimates is to main-
tain timestamps for each packet at the sender and receiver. For
estimating per-ﬂow latencies, we just collect the timestamps for all
packets that belong to a given ﬂow and aggregate them. The biggest
problem with this approach is scale: At 10 Gbps, the number of
packets is of the order of a few million per second making it expen-
sive in terms of number of timestamps maintained (memory), of
updating timestamps into speciﬁc data structures or packets them-
selves (processing), and transporting the timestamps from sender to
the receiver or wherever the latencies are computed (bandwidth).
Packets carrying timestamps: We can potentially embed times-
tamps within packets, but IP packets currently do not have a times-
tamp ﬁeld while TCP options are typically meant for end-to-end
latencies. Embedding timestamps require changes to packet head-
ers, and may cause intrusive changes to the router forwarding paths
(that often involve third-party components such as TCAMs, switch
fabric ASICs) that vendors often refrain from adopting. In addi-
tion, adding packet headers to each and every packet can consume
signiﬁcant extra bandwidth that is not desirable. For example, a 32
bit timestamp per packet (assuming minimum size packets of 40
bytes) could use up to 10% capacity.
LDA. If we are only interested in aggregate delay, we could just
maintain two counters at the sender and the receiver that maintain
the number of packets and their timestamp sum. At the end of
the interval, the sender could transmit these two counters to the re-
ceiver which can subsequently compute the average delay. This
is the basic idea exploited in a recently proposed data structure
called LDA [23]. In order to account for potential packet loss, LDA
uses a stage of sampling and multiple buckets (say 1,000) to ensure
that statistics are computed over a large number of samples. While
this idea works great for aggregate delays, it is unclear how to ex-
tend this idea for obtaining per-ﬂow estimates. The trivial idea of
maintaining LDAs with many counters for each and every ﬂow is
not likely to scale as the number of ﬂows could be large. Even if
we could somehow provision storage for each and every LDA, the
sender counters for each ﬂow need to be periodically transmitted
to the receivers. Thus, control bandwidth is going to be too high.
One could argue that per-ﬂow measurements may be required only
for a small subset of “important” ﬂows, in which case, maintaining
per-ﬂow LDA (for that subset of ﬂows) would be feasible. Unfor-
tunately, however, it is not often clear which set of ﬂows need to
be chosen for per-ﬂow measurements in advance. Besides, deter-
mining the right size of the LDA banks may be difﬁcult in advance
since ﬂow sizes are not known a priori.
We therefore need to consider alternate mechanisms to achieve
our goal. In particular, we can exploit the observations in our pre-
vious section (§2) that packets that belong to different ﬂows experi-
ence similar delay when they are closely spaced within each other.