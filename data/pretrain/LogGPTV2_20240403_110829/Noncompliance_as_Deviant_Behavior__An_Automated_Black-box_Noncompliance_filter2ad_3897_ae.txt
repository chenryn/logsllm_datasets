### 9. Comparison with Baseline (RQ2)

We compare the effectiveness of DIKEUE with the conformance testing framework defined in the 3GPP specification [5] and property-guided testing by previous approaches [12, 19, 30, 32, 37].

#### 9.1. Comparison with Conformance Test Cases

We first evaluate the performance of DIKEUE against the 3GPP conformance test cases [5] based on two criteria: (i) test coverage; (ii) identified deviant behavior issues.

Since it is not feasible to calculate coverage for a black-box UE implementation, such as an iPhone, we apply DIKEUE to srsUE [6] v20.10.1, an open-source implementation by srsLTE [6]. We use the percentage of lines and functions executed, as measured by Gcov [3], as an indicator for code coverage. Given that our analysis focuses on the NAS and RRC layers, we do not compute the total number of lines and functions in srsUE. Instead, we calculate the percentage of lines covered within each function, considering only those relevant to our analysis.

Let \( Le(f) \) be the number of lines executed in function \( f \) in the srsUE implementation, and \( L(f) \) be the total number of lines in \( f \). We define line coverage as:
\[ \text{Line Coverage} = \frac{\sum_{i=1}^{m} Le(f_i)}{\sum_{i=1}^{m} L(f_i)} \]
where \( f_1, f_2, \ldots, f_m \) are the functions relevant to the NAS and RRC layers. Similarly, let \( n \) be the number of functions executed in srsUE, and \( m \) be the total number of relevant functions. We define function coverage as:
\[ \text{Function Coverage} = \frac{n}{m} \]

For the baseline coverage, we identify 88 test cases related to the RRC and NAS analysis from the 3GPP conformance test cases [5] and run them on the srsUE implementation. The conformance testing achieves 82.58% line coverage and 83.4375% function coverage. In contrast, DIKEUE performs significantly better, achieving 89.47% line coverage and 89.185% function coverage.

We also apply the 88 test cases to 14 devices. If the same conformance test case induces different outputs in different implementations, we note it as a deviant behavior. Through the conformance test cases, only 2 deviating behaviors were captured, compared to the 17 issues automatically identified by DIKEUE.

#### 9.2. Comparison with Existing LTE Works

Table 4 compares our approach with existing LTE testing approaches based on several criteria, including automation, specification, implementation analysis, and stateful testing.

##### 9.2.1. Comparison with LTEFuzz

LTEFuzz [39] is a recent approach for dynamic testing of the LTE protocol based on stateless dynamic testing with pre-generated test cases. DIKEUE differs from LTEFuzz in several ways. First, DIKEUE not only performs dynamic testing but also automatically reconstructs the FSM of the underlying UE implementation, allowing for in-depth analysis. Second, DIKEUE can uncover stateful vulnerabilities, whereas LTEFuzz's analysis is stateless. For example, LTEFuzz cannot uncover the Replayed GUTI_reallocation attack (discussed in Section 8.1.1), which was discovered by DIKEUE and acknowledged by both Qualcomm and Samsung as a high-severity issue. This is because the attack is triggered only at a specific state of the protocol implementation, not for a GUTI_reallocation packet replayed at an arbitrary protocol state.

##### 9.2.2. Comparison with Property-Guided Testing

Previous work [12, 19, 30, 37] has applied property-guided testing on FSMs derived from standards or extracted from white-box analysis. To compare DIKEUE with these approaches, we test the properties from previous approaches and run model checking on the FSMs derived from the implementations. As the previous properties are all for the NAS layer only, for a fair comparison, we only test for NAS layer property violations. Through property-guided testing, we identify 3 deviations (E2, E5, O9) among the 10 issues found by DIKEUE in the NAS layer.

### 10. Components Performance (RQ3)

We now evaluate the performance of DIKEUEâ€™s main components.

#### 10.1. FSM Inference Module Performance

Table 2 shows the number of states and transitions in the inferred models for 14 devices. Each model includes, on average, 22 states and around 600 transitions. There are notable exceptions in the model learning phase for different devices. For instance, both MediaTek phones (HTC One E9+ and Huawei Y5) require substantially more queries and time to learn the models. This is because MediaTek phones require up to 6 input symbols, including RRC_sm_command and RRC_reconf in a specific sequence, to complete the attach procedure. Consequently, it takes the learner more time to generate this specific sequence of messages, and without it, none of the future procedures, such as GUTI reallocation, tracking area update, service procedure, etc., can proceed.

| Device | Total States | Total Transitions | # Queries |
|--------|--------------|-------------------|-----------|
| M      | 5756         | 5756              | 1620      |
| M      | 5756         | 5756              | 1968      |
| M      | 5756         | 5756              | 0         |
| M      | 5756         | 5756              | 896       |
| E      | 4340         | 4340              | 1416      |
| E      | 4340         | 4340              | 1416      |
| E      | 4340         | 4340              | 1416      |
| E      | 4340         | 4340              | 1416      |

This table provides a detailed breakdown of the FSM inference module's performance across different devices.