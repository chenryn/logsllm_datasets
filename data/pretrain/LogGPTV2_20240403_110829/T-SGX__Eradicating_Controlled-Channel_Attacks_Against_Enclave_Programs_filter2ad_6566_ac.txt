22
leaq EB.2(%rip), %r15
23
jmp
springboard.next
24
25 EB.2:
...
26
Fig. 6: Transaction transition code on the springboard and at the end
of each execution block (denoted EB).
to subsequent execution blocks. While these execution
blocks may be distributed over many memory pages,
only the springboard contains code that is not wrapped
in a transaction.
If an exception occurs inside an execution block, the
processor transfers control directly to the abort handler
whose address is specified at XBEGIN.
The abort handler determines whether it has to restart
the transaction or terminate the enclave program. The
operating system will only see exceptions on the
springboard page.
3)
4)
C. Execution Blocks
This section explains how the T-SGX compiler partitions
a program into execution blocks that can be executed as
transactions. We begin with a simple partitioning scheme that
yields correct and functional programs. After that, we introduce
various optimization techniques that drastically reduce the
overhead of the simple scheme.
T-SGX computes the control flow graph of the program and
tests for each basic block if it satisfies the transaction limits
imposed by TSX and an execution time bound we establish. In
particular, T-SGX makes a conservative estimate of the write
and read sets of the basic blocks with respect to a cache model,
as explained in §V-C1. We approximate execution time by
counting the number of instructions in the basic block. Most
basic blocks satisfy the two constraints. The remaining basic
blocks are split by T-SGX into smaller blocks until all split
blocks satisfy the transaction constraints. The resulting set of
blocks is the partitioning into execution blocks under the basic
scheme.
1) Transaction Constraints: TSX imposes strict bounds on
the read and write sets of each transaction. The write set must
fit into the L1 data cache. That is, the L1 data cache must be
able to hold all memory writes of a transaction.
For example, on Skylake processors, the L1 data cache
has a size of 32 kB. It is 8-way set associative with 64-byte
Fig. 7: Overall procedure of T-SGX: 1 A host program calls an
enclave program. 2 Enclave execution is managed by the springboard
that jumps into execution blocks scattered across multiple pages.
The execution blocks jump back to the springboard when they are
successfully executed. 3 When an exception occurs in a execution
block, control goes directly to the abort handler on the springboard.
4 The enclave program either terminates or is interrupted. The OS
can only identify the page containing the springboard.
Fig. 8: Mapping of memory addresses to L1 cache slots.
cache lines. We can visualize this cache as eight copies (ways)
of a 4 kB page partitioned into 64 slots of size 64 bytes
(see Figure 8). The 64-byte cache line size is the granularity
at which cache space is assigned. Multiple write operations
within a single 64-byte aligned 64-byte address range occupy
a single cache line. This 64-byte line is mapped to the slot in
the L1 cache at the same page offset. A memory access within
the 64-byte line causes it to be loaded into one of the eight
ways at the corresponding slot in the L1 cache. This will cause
the previous content of the of the way to be evicted from the
L1 cache.
As the write set of a transaction must be kept in the L1
cache until the end of the transaction, a transaction will fail if
its write set includes more than eight cache lines that map to
a single slot. The T-SGX compiler uses this cache condition
to determine if the write set of an execution block is too large.
If it is, it will split the execution block into smaller units (as
explained above).
Since the exact addresses of memory write operations may
not be known at compile time, we have to use a conservative
approximation. That is, given uncertainty about the addresses of
memory accesses at run time, we assume the worst possibility.
This may cause T-SGX to split the program into unnecessarily
small execution blocks. However, it guarantees that the write
set will fit into the L1 cache.
7
Kernel spaceEnclaveentry point❷ execution❸ abort❹ terminate (or interrupted)User  spaceabort handlerspringboard (R-X)xend()xbegin()jmp r15xend()jmp r15push rbpmov rax, rbx...// jmp EB1mov EB1, r15jmp nextHost program❶ EENTERmov rbx, rcx...// jmp EB2mov EB2, r15jmp nextException handlerbegin:next:entryEB1transactional regionscontrol flowsEEXIT/AEX...mov entry, r15jmp beginend:8 ways64 slots..................0xc00000xc00400xc00800xc00c00xc01000xc01400xc01800xc01c00xc0200Main memoryL1 cache...
leaq loop.header(%rip), %r15
jmp
springboard.next
...
leaq loop.header(%rip), %r15
jmp
springboard.next
...
incq 32(%rsp)
1 # T-SGX
2 EB:
3
4
5
6 loop.body:
7
8
9 loop.header:
10
11
12
13
14
15 loop.end:
16
...
...
cmpq $100, 32(%rsp)
jbe
leaq loop.end(%rip), %r15
jmp
springboard.next
loop.body
1 # TSX Basic
2 EB:
3
4
5
6 loop.body:
7
8
9
10
11 loop.header:
12
13
14
15
16
17
18 loop.end:
19
...
...
incq 32(%rsp)
leaq loop.header(%rip), %r15
jmpq springboard.next
...
cmpq $100, 32(%rsp)
leaq loop.body(%rip), %r15
jbe
leaq loop.end(%rip), %r15
jmp
springboard.next
springboard.next
Fig. 9: An example of the loop optimization.
More precisely, we distinguish between three types of
memory accesses. First, addresses that are known completely
at compile time can be mapped directly to a cache slot. Second,
memory accesses given by an unknown base address and a
known fixed offset (e.g., rsp+8, rsp+16) are grouped by the
base pointer. We compute the maximum number of occupied
ways separately for each group (base pointer) and add the
maxima over all groups. Third, we model an access whose
address is completely unknown as occupying one way of every
slot. Finally, we add the largest way-count from each of the
three cases to obtain an upper bound on the L1 requirements
of the execution block.
We use a similar strategy to analyze the read set of execution
blocks, and we count instructions as a proxy for execution time.
D. Optimization Techniques
An empty transaction with XBEGIN and XEND costs about 200
cycles. This can have a significant performance impact on the
end-to-end application run time (see §VIII). The simple, basic-
block-based partitioning uses basic block boundaries as the
default place to begin and end transactions. However, it is often
possible to place transactions around larger units of program
execution, such as loops or functions. This subsection describes
optimization techniques that follow this strategy and that can
remove most of the overhead of the simple partitioning. Note
that these optimizations do not interfere with OS scheduling,
since interrupts cause transactions to be aborted (§II-C2).
1) Loops: Simple partitioning places transactions inside the
loop body. That is, every iteration of even the simplest loops
(e.g., memcpy()) is at least one separate transaction. Our first
optimization technique is to pull the transaction out of the loop
where possible. Rather than creating a transaction for every
loop iteration, we create a single transaction for the entire loop
execution.
The main difficulty is to determine the write set of a loop.
In general, this is not a tractable problem. However, in practice,
many loops have simple relationships between the iteration
number and the addresses of memory accesses in that iteration.
For example, we frequently observe a simple linear relationship.
That is, during the k-th iteration, the loop will access address
8
a + b ∗ k, where a and b are constants known at compile time.
We use data-flow analysis to determine such relationships.
Given the write set of the loop, we perform the tests
of §V-C1 to determine if the optimization can be applied. If
the test fails because the number of loop iterations is too large
or unknown, we can still apply the optimization by partially
unrolling the loop. For example, if for up to 100 iterations
the write set of the loop fits into the L1 cache, we place a
transaction around every 100 iterations of the loop. This allows
us to amortize the transaction cost over possibly many loop
iterations (see Figure 9).
2) Functions and if-statements: This optimization attempts
to merge all execution blocks within a function into a single
execution block covering the entire function. We attempt to
compute the write and read sets and instruction count for the
entire function. If the function is complicated (e.g., contains
loops), this may not succeed, and we do not optimize the
function. If we can obtain the read and write sets and the
instruction count and if they pass the tests of §V-C1 then we
merge the entire function into a single execution block.
Similarly, if we can determine the read and write sets of if-
then-else statements and if they meet the conditions of §V-C1,
we merge the if-then-else statement into a single execution
block.
E. Abort Sequence
If a transaction fails, TSX will transfer control to the abort
address specified in the XBEGIN instruction. T-SGX places this
address on the springboard.
A simple version of the abort code restarts the transaction
unconditionally until it succeeds. The appeal of this design lies
in its simplicity. The abort code is stateless and only a few
instructions long. However, if a transaction has to access a page
that has been unmapped, this design will restart the transaction
indefinitely, which is not an optimal defense strategy (§VII).
The alternative is for the abort code to monitor transaction
aborts for signs of attacks and to stop program execution if an
attack is detected. Lacking hardware support for distinguishing
between page faults and regular interrupts as the cause of a
transaction abort, we use the following criterion. If a transaction
aborts more than n times, the abort code will terminate program
execution, where n is a parameter that must be chosen such that
the likelihood of seeing n consecutive transaction aborts due to
benign causes under normal operation is very low. Based on the
analysis of §VIII-B4, we set n = 10. The controlled-channel
attack [65] requires millions of page faults to obtain sensitive
information, so that 10 would be a reasonable threshold to
defeat it.
Aborting execution when an unmapped page is detected
may leak to the attacker that the enclave was trying to access
this page. However, as explained in §VII, this strategy ensures
that the attacker does not learn anything else through the page
fault channel.
An implementation difficulty arises from the fact that the
attack detection code is not stateless, as it has to count the
number of times a transaction is aborted. In order to maintain
the important springboard property that the only memory
accesses of springboard code outside transactions are execute
accesses to the springboard page, we store the counter in a
CPU register that we reserve in the compiler.
F. Preventing Reruns
The decision to run the enclave should be made by its
owner and not by the attacker. This can be easily enforced by
having the enclave code wait for a cryptographically secured
authorization before it accesses sensitive data. We make this
authorization an optional part of T-SGX.
The attack model of [65] assumes that the victim runs
only once. Furthermore, the use model described in [65] (a
remote user controlling a SGX-protected Haven instance or
VM in the cloud via a remote desktop protocol) effectively
includes an authorization to run (the remote user’s commands)
that is cryptographically secured (through the remote desktop
protocol).
G. External calls
T-SGX places an XEND before calls from the enclave into
the untrusted part of the address space (an EEXIT instruction).
Similarly, T-SGX places a XBEGIN instruction close to the
enclave entry points specified in the SGX Thread Control
Structures (TCSs).
H. Illegal instructions
The T-SGX compiler ensures that no instructions that are
illegal under SGX or TSX are generated for an enclave binary.
This is unproblematic, as those instructions are not necessary
to generate regular application code.
VI.
IMPLEMENTATION
We have built a prototype of T-SGX based on the LLVM
compiler. Our prototype produces T-SGX-enabled binaries that
can be run in an enclave just like the original binary. Our
prototype can handle arbitrary C and C++ code.
The main part of our prototype is integrated into the back-
end of LLVM. It starts by performing the analysis described
in §V based on the basic blocks produced by LLVM. After
that, it modifies the instruction sequence as it is being emitted
by LLVM. In particular, it places two instructions (to load the
address of the next execution block into the r15 register and
to jump to the springboard) at the end of each execution block.
In the case of 64-bit code, we reserve the r15 register for this
purpose (i.e., to communicate the address of the next block to
the springboard). Jump and call instructions (including indirect
jumps and calls) are also made to jump to the springboard with
the destination address loaded into r15.
As TSX uses the rax register, we reserve a second register
to save the value of rax at the end of each execution block
that writes to rax and to restore it at the beginning of each
execution block that reads rax before writing to it.
Our prototype also includes a plugin to the LLVM front-end
that injects a function wrapper for each exported function into
the LLVM intermediate representation. The entire prototype
consists of 4,110 lines of C++ code.
VII. SECURITY ANALYSIS
For T-SGX-based enclave programs, the attacker can only
observe page fault locations (faulting addresses) on (a) the
springboard page and (b) the unsecured pages containing
function wrappers for the external enclave entry points. The
latter can be ignored, as they do not access sensitive data.
Furthermore, as shown below, the attacker cannot use
page faults to obtain deterministic notification when enclave
execution accesses the springboard. These two properties of
T-SGX disable the two main uses of the page-fault channel
in the attacks of [65] and [54]: (a) leaking page numbers of
memory accesses and (b) giving the attacker synchronization
points that allow him/her to track the the victim’s execution.
An example of the latter is the strategic unmapping of code
pages in [65] such that, every time the victim calls a function
that accesses sensitive data (looking up a word in the Hunspell
hash table, rendering a character, decoding an 8 × 8 pixel
block of an image), a page fault interrupts (stops) the victim
and invokes the attacker, who can then advance him/her state
machine and update the set of unmapped pages. By blocking
these two mechanisms, T-SGX effectively protects enclave
programs against the known page-fault-channel-based attacks.
For the full-strength T-SGX variant that requires the enclave-
owner’s consent to run the enclave program (§V-F) and that
aborts enclave execution as soon as a page fault is detected
(§V-E), a stronger statement can be made: The attacker will
learn at most one page access by the victim. Recall that the
attacks of [65] required millions of page faults.
Given a reliable attack detection mechanism, the argument
is straightforward. The first time one of the victim’s transactions
aborts, T-SGX will detect an attack and stop the execution. As
the attacker will not be able to run the victim again, he/she
cannot observe more than the one page access that caused the
springboard to abort the execution. Whether the attack detection
described in §V-E is sufficiently robust is arguable.
Attack detection. For enclave execution, it is reasonable
to require that the enclave encounters no unexpected page
faults. Thus, attack detection reduces to detecting page faults
for T-SGX-secured pages. The problem would be trivial if
the TSX hardware would distinguish between page faults
and interrupts in the eax value provided to the abort handler.
Lacking such hardware support, our abort handler declares an
attack after a small number of consecutive transaction failures.
This approximation is motivated by our evaluation (§VIII):
Transactions tend to be short (1,000 to 2,000 cycles), and we
have never observed more than three consecutive transaction
aborts or false positives.
Restarting the transaction several times before aborting
enclave execution could, in principle, give the attacker an
opportunity to observe that the page has been accessed and
to make the page accessible before the springboard terminates
enclave execution. However, it appears that the attacker would
have to rely mainly on other mechanisms (beyond the page-
fault channel) to detect that the page had been accessed. In
other words, while we cannot exclude the possibility that the
attacker could gain more information, it appears that he/she
would have to rely primarily on powerful mechanisms beyond
the page-fault channel (e.g., cache side channels), which is not
the focus of T-SGX.
9
Attacks on the Springboard. We noted above that the attacker
cannot obtain deterministic notification of springboard accesses
through the page-fault channel. More precisely, the attacker
cannot force page faults on springboard accesses.
Before execution of sensitive enclave code starts,
the
springboard must be mapped and accessed since any sensitive
code is called from the springboard. The attacker can, of course,
unmap the springboard in the page tables at any time. However,
accesses to springboard will continue to succeed (without
causing page faults) as long as the springboard’s mapping
is in the TLB. Furthermore, this mapping is unlikely to be
evicted quickly from the TLB, as the springboard is accessed
very frequently (§VIII).
All reliable methods for removing the springboard’s map-
ping from the TLB (e.g., flushing the TLB) require the attacker
to run code on the enclave’s core or send an inter-processor
interrupt (IPI) to the core, interrupting the enclave execution
eventually. The key observation is that, by construction of