h
g
u
o
r
h
T
80
70
60
50
40
30
20
10
0
64
256
1024
Packet size (Bytes)
1514
Fig. 8. Breakdown of performance improvement by each technique
Kargus
Suricata
Haetae w/o host offloading
Haetae w/ host offloading
)
s
p
b
G
(
t
u
p
h
g
u
o
r
h
T
80
70
60
50
40
30
20
10
0
)
s
p
b
G
(
t
u
p
h
g
u
o
r
h
T
40
35
30
25
20
15
10
5
0
ANCS13
Haetae w/o host offloading
Haetae w/ host offloading
64
256
1024
1514
Packet size (Bytes)
100
200
Packet size (Bytes)
256
512
Fig. 9. Performance comparison with (a) synthetic HTTP workloads, (b) the NIDS
proposed in ANCS ‘13 [24] (36 tiles)
are diﬀerent, we scale down the performance numbers in the paper. For fair com-
parison, we use only 36 tiles for Haetae but increase the number of rules (7,867
rules), similar to [24]. Figure 9(b) shows the ﬁnal results. While previous work
achieves 6 to 11.3 Gbps for 100 to 512B packets, Haetae without host oﬄoading
achieves 7.4 to 20.6 Gbps for the same size, which is 1.2 to 1.8x more eﬃcient.
Moreover, Haetae with host oﬄoading achieves 1.7 to 3.2x improvements over
the previous work. The improvements come from two main reasons. First, unlike
pipelining, Haetae’s parallel architecture reduces load imbalance and ineﬃcient
usage of the tiles. We observe that the performance of [24] ﬂattens at 512B
packets, presumably due to the overheads of pipelining. Second, Haetae saves
the computation cycles by applying the mPIPE oﬄoading and the lightweight
metadata structures.
In terms of power consumption, Haetae is much more eﬃcient: Haetae with
host oﬄoading (TILE-Gx72 and two Intel E5-2690 CPUs) shows 0.23 Gbps per
watt while Kargus (two Intel X5680 CPUs and two NVIDIA GTX580 GPUs)
achieves only 0.04 Gbps per watt, spending 5.8x more power than Haetae.
106
J. Nam et al.
6.4 Real Traﬃc Performance
We evaluate the performance with real traﬃc traces obtained from a 10 Gbps
LTE backbone link at one of the largest mobile ISPs in South Korea. We remove
unterminated ﬂows from the real traﬃc traces and shape them to increase the
overall transmission rate (up to 53 Gbps). The real traﬃc trace ﬁles are ﬁrst
loaded into RAM before packets are replayed. The ﬁles take up 65 GB of physical
memory (2M TCP ﬂows, 89M packets). To increase the replay time, we replay
the ﬁles 10 times repeatedly. Like the previous measurements, we use the same
ruleset (2,435 HTTP rules) as well.
Table 1 shows the throughputs of Haetae and other NIDSes. With the real
traces, Haetae is able to analyze 4.2x and 1.9x more packets than Baseline
Suricata and Karugs respectively. While Haetae achieves up to 79.3 Gbps with
the synthetic workload, the throughput with the real workload decreases due to
two major reasons. First, the modules related to ﬂows are fully activated. Unlike
the synthetic workload, the real workload has actual ﬂows. The ﬂow management
module needs to keep updating ﬂow states and the stream module also needs to
reassemble ﬂow streams. Thus, these modules consume much more cycles with
the real workload than with the synthetic workload. Second, while the synthetic
workload consists of packets of the same size, the real traﬃc has various data
and control packets of diﬀerent sizes. The average packet size of the real traﬃc
traces is 780 bytes, and the throughput is 16 % lower than that of 512B packets
in the synthetic workload.
Table 1. Performance comparison with the real traﬃc
IDS
Baseline Suricata Kargus
Haetae
Throughput 11.6 Gbps
25.2 Gbps 48.5 Gbps
7 Related Work
We brieﬂy discuss related works. We categorize the previous NIDS works into
three groups by their hardware platforms: dedicated-hardware, general-purpose
multi-core CPU, and many-core processors.
NIDS on Dedicated-hardware: Many works have attempted to scale the
performance of pattern matching with dedicated computing hardware, such as
FPGA, ASIC, TCAM, and network processors. Barker et al. implement the
Knuth-Morris-Pratt string matching algorithm on an FPGA [18]. Mitra et al.
develops a compiler that converts Perl-compatible regular expression (PCRE)
rules into VHDL code to accelerate the Snort NIDS [27]. Their VHDL code
running on an FPGA achieves 12.9 Gbps of PCRE matching performance.
Tan et al. implement the Aho-Corasick algorithm on an ASIC [32]. Yu et al.
Haetae: Scaling the Performance of Network Intrusion Detection
107
employ TCAMs for string matching [36] while Meiners et al. optimize regular
expression matching with TCAMs [26]. While these approaches ensure high per-
formance, a long development cycle and a lack of ﬂexibility limit its applicability.
NIDS on Multi-core CPU: Snort [29] is one of the most popular software
NIDSes that run on commodity servers. It is initially single-threaded, but more
recent versions like SnortSP [12] and Para-Snort [19] support multi-threading to
exploit the parallelism of multi-core CPU. Suricata [14] has the similar architec-
ture as Snort and it allows multiple worker threads to perform parallel pattern
matching on multi-core CPU.
Most of multi-threaded NIDSes adopt pipelining as their parallel execution
model: they separate the packet receiving and pattern matching modules to
a diﬀerent set of threads aﬃnitized to run on diﬀerent CPU cores so that the
incoming packets have to traverse these threads for analysis. As discussed earlier,
however, pipelining often suﬀers from load imbalance among the cores as well as
ineﬃcient CPU cache usage.
One reason for the prevalence of pipelining in early versions of multi-threaded
software NIDSes is that popular packet capture libraries like pcap [10] and net-
work cards at that time did not support multiple RX queues. For high perfor-
mance packet acquisition, a CPU core had to be dedicated to packet capture
while other CPU cores were employed for parallel pattern matching. However,
recent development of multi-queue NICs and multi-core packet I/O libraries such
as PF RING [11], PSIO [20], netmap [28] allows even distribution of incoming
packets to multiple CPU cores, which makes it much easier to run an indepen-
dent NIDS engine on each core. Haetae takes the latter approach, beneﬁting
from the mPIPE packet distribution module while it avoids the ineﬃciencies
from pipelining.
NIDS on Many-core Processors: Many-core GPUs have recently been
employed for parallel pattern matching. Gnort [33] is the seminal work that accel-
erates multi-string and regular expression pattern matching using GPUs. Smith
et al. conﬁrm the beneﬁt of the SIMD architecture for pattern matching, and
compare the performance of deterministic ﬁnite automata (DFA) and extended
ﬁnite automata (XFA) [30] on G80 [31]. Huang et al. develop the Wu-Manber
algorithm for GPU, which outperforms the CPU version by two times [22]. More
recently, Snort-based NIDSes like MIDeA [34] and Kargus [23] demonstrate that
the performance of software engines can be signiﬁcantly improved by hybrid
usage of multi-core CPU and many-core GPU. For example, Kargus accepts
incoming packets at 40 Gbps with PSIO [20], a high-performance packet capture
library that exploits multiple CPU cores. It also oﬄoads the Aho-Corasick and
PCRE pattern matching to two NVIDIA GPUs while it performs function call
batching and NUMA-aware packet processing. With these optimizations, Kargus
achieves an NIDS throughput over 30 Gbps on a single commodity server.
Jiang et al. have proposed a Suricata-based NIDS on a TILE-Gx36 plat-
form with 36 tiles [24]. While their hardware platform is very similar to ours,
their NIDS architecture is completely diﬀerent from Haetae. Their system adopts
pipelining from Suricata and mostly focuses on optimal partitioning of tiles for
108
J. Nam et al.
tasks. In contrast, Haetae adopts per-tile NIDS engine and focuses on reduc-
ing per-packet operations and oﬄoading ﬂows to host machine. We ﬁnd that
our design choices provide performance beneﬁts over their system: 20 to 80 %
performance improvement in a similar setting.
8 Conclusion
In this paper, we have presented Haetae, a highly scalable network intrusion
detection system on the Tilera TILE-Gx72 many-core processor. To exploit high
core scalability, Haetae adopts the shared-nothing, parallel execution architec-
ture which simpliﬁes overall NIDS task processing. Also, Haetae oﬄoads heavy
per-packet computations to programmable network cards and reduces the packet
metadata access overhead by carefully re-designing the structure. Finally, Haetae
beneﬁts from dynamic CPU-side ﬂow oﬄoading to exploit all processing power
in a given system. We ﬁnd that our design choices provide a signiﬁcant per-
formance improvement over existing state-of-the-art NIDSes with great power
eﬃciency. We believe that many-core processors serve as a promising platform
for high-performance NIDS and our design principles can be easily adopted to
other programmable NICs and many-core processors as well.
Acknowledgments. We thank anonymous reviewers of RAID 2015 for their insight-
ful comments on our paper. This research was supported in part by SK Telecom
[G01130271, Research on IDS/IPS with many core NICs], and by the ICT R&D pro-
grams of MSIP/IITP, Republic of Korea [14-911-05-001, Development of an NFV-
inspired networked switch and an operating system for multi-middlebox services],
[R0190-15-2012, High Performance Big Data Analytics Platform Performance Acceler-
ation Technologies Development].
References
1. A hash function for hash table lookup. http://www.burtleburtle.net/bob/hash/
doobs.html
2. AMD: OpenCL Zone. http://developer.amd.com/tools-and-sdks/
3. AMD Opteron Processor Solutions. http://products.amd.com/en-gb/opteroncpu
result.aspx
4. Check Point IP Appliances. http://www.checkﬁrewalls.com/IP-Overview.asp
5. EZchip TILEncore-Gx72 Intelligent Application Adapter. http://tilera.com/
products/?ezchip=588&spage=606
6. Intel Data Direct I/O Technology. http://www.intel.com/content/www/us/en/io/
direct-data-i-o.html
7. Intel DPDK. http://dpdk.org/
8. Kalray MPPA 256 Many-core processors. http://www.kalrayinc.com/kalray/
products/#processors
9. NVIDIA: What is GPU Computing? http://www.nvidia.com/object/what-is-gpu-
computing.html
10. PCAP. http://www.tcpdump.org/pcap.html
Haetae: Scaling the Performance of Network Intrusion Detection
109
11. PF RING. http://www.ntop.org/products/pf ring
12. SnortSP (Security Platform). http://blog.snort.org/2014/12/introducing-snort-30.
html
13. Sourceﬁre 3D Sensors Series. http://www.ipsworks.com/3D-Sensors-Series.asp
14. Suricata Open Source IDS/IPS/NSM engine. http://suricata-ids.org/
15. The Intel Xeon Processor E7 v2 Family. http://www.intel.com/content/www/us/
en/processors/xeon/xeon-processor-e7-family.html
16. TILE-Gx Processor Family. http://tilera.com/products/?ezchip=585&spage=614
17. Aho, A.V., Corasick, M.J.: Eﬃcient string matching: an aid to bibliographic search.
Commun. ACM 18(6), 333–340 (1975)
18. Baker, Z.K., Prasanna, V.K.: Time and area eﬃcient pattern matching on
FPGAs. In: Proceedings of the ACM/SIGDA International Symposium on Field-
Programmable Gate Arrays (FPGA), pp. 223–232. ACM (2004)
19. Chen, X., Wu, Y., Xu, L., Xue, Y., Li, J.: Para-snort: A multi-thread snort on
multi-core ia platform. In: Proceedings of the Parallel and Distributed Computing
and Systems (PDCS) (2009)
20. Han, S., Jang, K., Park, K., Moon, S.: Packetshader: a gpu-accelerated software
router, vol. 41, pp. 195–206 (2011)
21. Handley, M., Paxson, V., Kreibich, C.: Network intrusion detection: Evasion, traﬃc
normalization, and end-to-end protocol semantics. In: USENIX Security Sympo-
sium, pp. 115–131 (2001)
22. Huang, N.F., Hung, H.W., Lai, S.H., Chu, Y.M., Tsai, W.Y.: A GPU-based
multiple-pattern matching algorithm for network intrusion detection systems. In:
Proceedings of the International Conference on Advanced Information Networking
and Applications - Workshops (AINAW), pp. 62–67. IEEE (2008)
23. Jamshed, M.A., Lee, J., Moon, S., Yun, I., Kim, D., Lee, S., Yi, Y., Park, K.: Kar-
gus: a highly-scalable software-based intrusion detection system. In: Proceedings
of the ACM Conference on Computer and Communications Security (CCS), pp.
317–328 (2012)
24. Jiang, H., Zhang, G., Xie, G., Salamatian, K., Mathy, L.: Scalable high-
performance parallel design for network intrusion detection systems on many-core
processors. In: Proceedings of the ACM/IEEE Symposium on Architectures for
Networking and Communications Systems (ANCS). IEEE Press (2013)
25. Kuon, I., Tessier, R., Rose, J.: FPGA architecture: Survey and challenges. In:
Foundations and Trends in Electronic Design Automation, vol. 2, pp. 135–253.
Now Publishers Inc. (2008)
26. Meiners, C.R., Patel, J., Norige, E., Torng, E., Liu, A.X.: Fast regular expres-
sion matching using small TCAMs for network intrusion detection and prevention
systems. In: Proceedings of the 19th USENIX conference on Security, pp. 8–8.
USENIX Association (2010)
27. Mitra, A., Najjar, W., Bhuyan, L.: Compiling PCRE to FPGA for accelerating
Snort IDS. In: Proceedings of the ACM/IEEE Symposium on Architecture for
Networking and Communications Systems (ANCS), pp. 127–136. ACM (2007)
28. Rizzo, L.: netmap: a novel framework for fast packet i/o. In: USENIX Annual
Technical Conference. pp. 101–112 (2012)
29. Roesch, M., et al.: Snort - lightweight intrusion detection for networks. In: Pro-
ceedings of the USENIX Systems Administration Conference (LISA) (1999)
30. Smith, R., Estan, C., Jha, S., Kong, S.: Deﬂating the big bang: fast and scalable
deep packet inspection with extended ﬁnite automata. ACM SIGCOMM Comput.
Commun. Rev. 38, 207–218 (2008)
110
J. Nam et al.
31. Smith, R., Goyal, N., Ormont, J., Sankaralingam, K., Estan, C.: Evaluating gpus
for network packet signature matching. In: Proceedings of the IEEE International
Symposium on Performance Analysis of Systems and Software (ISPASS) (2009)
32. Tan, L., Sherwood, T.: A high throughput string matching architecture for intru-
sion detection and prevention. In: ACM SIGARCH Computer Architecture News,
vol. 33, pp. 112–122. IEEE Computer Society (2005)
33. Vasiliadis, G., Antonatos, S., Polychronakis, M., Markatos, E.P., Ioannidis, S.:
Gnort: high performance network intrusion detection using graphics processors. In:
Lippmann, R., Kirda, E., Trachtenberg, A. (eds.) RAID 2008. LNCS, vol. 5230,
pp. 116–134. Springer, Heidelberg (2008)
34. Vasiliadis, G., Polychronakis, M., Ioannidis, S.: Midea: a multi-parallel intrusion
detection architecture. In: Proceedings of the ACM Conference on Computer and
Communications Security (CCS), pp. 297–308 (2011)
35. Woo, S., Jeong, E., Park, S., Lee, J., Ihm, S., Park, K.: Comparison of caching
strategies in modern cellular backhaul networks. In:Proceeding of the Annual Inter-
national Conference on Mobile Systems, Applications, and Services (MobiSys), pp.
319–332. ACM (2013)
36. Yu, F., Katz, R.H., Lakshman, T.V.: Gigabit rate packet pattern-matching using
tcam. In: Proceedings of the IEEE International Conference on Network Proto-
cols(ICNP), pp. 174–183. IEEE (2004)