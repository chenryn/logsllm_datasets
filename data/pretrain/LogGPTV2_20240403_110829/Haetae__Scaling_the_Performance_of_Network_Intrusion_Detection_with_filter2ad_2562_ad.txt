# Performance Analysis and Comparison

## 8. Breakdown of Performance Improvement by Each Technique
The following figures illustrate the performance improvement achieved by each technique. The x-axis represents the packet size in bytes, while the y-axis shows the throughput in Gbps.

### Figure 8: Breakdown of Performance Improvement by Each Technique
- **Kargus**
- **Suricata**
- **Haetae without host offloading**
- **Haetae with host offloading**

Packet sizes: 64, 256, 1024, 1514 bytes

### Figure 9: Performance Comparison
#### (a) Synthetic HTTP Workloads
- **Kargus**
- **Haetae without host offloading**
- **Haetae with host offloading**

Packet sizes: 64, 256, 1024, 1514 bytes

#### (b) NIDS Proposed in ANCS â€˜13 [24] (36 tiles)
- **ANCS13**
- **Haetae without host offloading**
- **Haetae with host offloading**

Packet sizes: 100, 200, 256, 512 bytes

For a fair comparison, we scaled down the performance numbers and used only 36 tiles for Haetae, increasing the number of rules to 7,867, similar to [24]. The results show that:
- Previous work achieves 6 to 11.3 Gbps for 100 to 512B packets.
- Haetae without host offloading achieves 7.4 to 20.6 Gbps, which is 1.2 to 1.8x more efficient.
- Haetae with host offloading achieves 1.7 to 3.2x improvements over the previous work.

These improvements are attributed to:
1. **Parallel Architecture**: Unlike pipelining, Haetae's parallel architecture reduces load imbalance and inefficient usage of tiles. The performance of [24] flattens at 512B packets due to pipelining overheads.
2. **mPIPE Offloading and Lightweight Metadata**: Haetae saves computation cycles by using mPIPE offloading and lightweight metadata structures.

In terms of power consumption, Haetae (TILE-Gx72 and two Intel E5-2690 CPUs) achieves 0.23 Gbps per watt, while Kargus (two Intel X5680 CPUs and two NVIDIA GTX580 GPUs) achieves only 0.04 Gbps per watt, consuming 5.8x more power.

## 6.4 Real Traffic Performance
We evaluated the performance using real traffic traces from a 10 Gbps LTE backbone link at one of the largest mobile ISPs in South Korea. We removed unterminated flows and shaped the traffic to increase the overall transmission rate (up to 53 Gbps). The real traffic trace files, occupying 65 GB of physical memory (2M TCP flows, 89M packets), were loaded into RAM before replaying. The files were replayed 10 times to increase the replay time. The same ruleset (2,435 HTTP rules) was used as in previous measurements.

### Table 1: Performance Comparison with Real Traffic
| IDS               | Throughput (Gbps) |
|-------------------|-------------------|
| Baseline Suricata | 11.6              |
| Kargus            | 25.2              |
| Haetae            | 48.5              |

With real traces, Haetae analyzes 4.2x and 1.9x more packets than Baseline Suricata and Kargus, respectively. The throughput with real workload decreases due to:
1. **Flow Management Modules**: These modules are fully activated, requiring updates to flow states and reassembly of flow streams, consuming more cycles.
2. **Packet Size Variability**: Real traffic has various data and control packets of different sizes, with an average packet size of 780 bytes, resulting in a 16% lower throughput compared to 512B packets in synthetic workloads.

## 7. Related Work
We briefly discuss related works, categorizing them by their hardware platforms: dedicated-hardware, general-purpose multi-core CPU, and many-core processors.

### NIDS on Dedicated-Hardware
- **FPGA, ASIC, TCAM, Network Processors**: Many works have attempted to scale pattern matching performance using dedicated computing hardware. Examples include:
  - Barker et al. [18]: Implementing the Knuth-Morris-Pratt string matching algorithm on an FPGA.
  - Mitra et al. [27]: Developing a compiler to convert PCRE rules into VHDL code for Snort NIDS.
  - Tan et al. [32]: Implementing the Aho-Corasick algorithm on an ASIC.
  - Yu et al. [36]: Using TCAMs for string matching.
  - Meiners et al. [26]: Optimizing regular expression matching with TCAMs.
  - While these approaches ensure high performance, they suffer from long development cycles and lack flexibility.

### NIDS on Multi-core CPU
- **Snort [29]**: One of the most popular software NIDSes, initially single-threaded but now supporting multi-threading in recent versions like SnortSP [12] and Para-Snort [19].
- **Suricata [14]**: Similar architecture to Snort, allowing multiple worker threads for parallel pattern matching.
- **Pipelining**: Common in multi-threaded NIDSes, but often suffers from load imbalance and inefficient CPU cache usage.
- **Recent Developments**: Multi-queue NICs and multi-core packet I/O libraries (PF RING [11], PSIO [20], netmap [28]) allow even distribution of incoming packets to multiple CPU cores, making it easier to run independent NIDS engines on each core. Haetae benefits from the mPIPE packet distribution module, avoiding pipelining inefficiencies.

### NIDS on Many-core Processors
- **GPUs**: Gnort [33] accelerates multi-string and regular expression pattern matching using GPUs. Smith et al. [30] compare DFA and XFA performance on G80 [31]. Huang et al. [22] develop the Wu-Manber algorithm for GPU, outperforming the CPU version.
- **Hybrid Usage**: Snort-based NIDSes like MIDeA [34] and Kargus [23] demonstrate significant performance improvements by hybrid usage of multi-core CPU and many-core GPU. Kargus accepts incoming packets at 40 Gbps with PSIO [20] and offloads Aho-Corasick and PCRE pattern matching to NVIDIA GPUs, achieving over 30 Gbps throughput.
- **TILE-Gx36 Platform [24]**: Jiang et al. proposed a Suricata-based NIDS on a TILE-Gx36 platform, adopting pipelining and focusing on optimal tile partitioning. In contrast, Haetae adopts a per-tile NIDS engine, reducing per-packet operations and offloading flows to the host machine, providing 20 to 80% performance improvement.

## 8. Conclusion
In this paper, we presented Haetae, a highly scalable network intrusion detection system on the Tilera TILE-Gx72 many-core processor. Haetae exploits high core scalability through a shared-nothing, parallel execution architecture, offloads heavy per-packet computations to programmable network cards, and reduces packet metadata access overhead. Additionally, Haetae benefits from dynamic CPU-side flow offloading. Our design choices provide significant performance improvements over existing state-of-the-art NIDSes with great power efficiency. We believe many-core processors serve as a promising platform for high-performance NIDS, and our design principles can be easily adopted to other programmable NICs and many-core processors.

## Acknowledgments
We thank the anonymous reviewers of RAID 2015 for their insightful comments. This research was supported in part by SK Telecom and the ICT R&D programs of MSIP/IITP, Republic of Korea.

## References
[References listed here, formatted as provided in the original text]

---

This revised text aims to be more clear, coherent, and professional, with improved structure and readability.