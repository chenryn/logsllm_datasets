to be modified due to the occurrence of the card’s nonces within it.
Furthermore, we conjecture that if the card’s nonces (e.g. nC) can be
inferred from passive observation of the execution, then versions
of the protocols in question that resist terrorist fraud would be
vulnerable to relay attacks, thus violating a primary security goal
of these protocols.
7 CONCLUSIONS
This paper addressed symbolic analysis of security protocols in
the presence of colluding agents. Colluding agents are agents who
are not under full control of the adversary, yet they are willing
to deviate from the intended protocol execution with the goal to
invalidate a given property. By looking at different use-cases, we
observe that post-collusion security may or may not be a desirable
goal. This is because the risk of irreparable damage to the security
of a protocol may motivate agents to avoid collusion.
We proposed a concrete symbolic formulation of post-collusion
security that can be implemented in state-of-the-art protocol verifi-
cation tools such as Tamarin. We used our definition to illustrate
that leakage of session data can lead to impersonation of agents.
This is particularly interesting in the context of authentication prop-
erties in which agents, by leaking only session-fresh data, enable
the adversary to successfully break the authentication property in
every session thereafter.
By means of post-collusion security, we provided the first formal
symbolic definition of (resistance to) the sophisticated terrorist
fraud attack against distance-bounding protocols. By using our
theoretical model and the Tamarin tool, we provided computer-
verifiable proofs of the (in)security of over 25 distance-bounding
protocols that account for all classes of attacks, as given by the
literature on distance bounding. To the best of our knowledge, this
is the most extensive and sound set of security/vulnerability proofs
within this research subject.
Our analysis reports that for the vast majority of the analysed
protocols at least one attack exists. The vulnerable protocols include
protocols based on the ISO/IEC 14443 standard such as Mastercard’s
PayPass [31], Visa’s payWave with distance-bounding [21], and
NXP’s MIFARE Plus with proximity check [58]. Finally, we pro-
posed fixes for these protocols and provide computer-verifiable
security proofs of the repaired protocols. The proposed fixes form
demonstrative examples that could be used to improve proximity-
based secure systems that follow the standard, or may even form
guidance for a future version of the standard itself.
A ATTACKS ON DISTANCE BOUNDING
There exist four main classes of attacks on distance-bounding proto-
cols. Some authors consider more classes but, consistent with [26],
our classification represents an exhaustive partition of the full
space of attacks: mafia fraud [29], distance fraud [28], distance hi-
jacking [26], and terrorist fraud [29]. We briefly describe next these
attacks, and their graphical representations are shown in Figure 9.
Mafia Fraud (Figure 9a) Given a verifier V , a close compro-
mised agent A uses a distant and honest prover P to make V
believe that P is close. The attack works in two sessions: one
between A and P (the so-called pre-ask session) and another
one between V and A. In most cases, A relays the verbatim
untimed communication between P and V , and impersonates
P to V during the fast phase.
Distance Fraud (Figure 9b) Given a verifier V , a distant and
compromised prover P anticipates V ’s challenges so that V
believes that P is close. This means that P must be able to
reproduce the responses prior to receiving the challenges.
For this type of attack, P does not need to use any other
provers.
Distance Hijacking (Figure 9c) Given a verifier V , a distant
and compromised prover P makes use of a close and honest
prover A to make V believe that P is close. To achieve this, P
lets A run the fast phase with V . Then (or, in some protocols,
before) P hijacks the session, injecting their own identity-
defining messages, possibly during the verification phase of
the protocol. This makes V believe that they are running the
protocol, and in particular the fast phase, with P.
Terrorist Fraud (Figure 9d) Given a verifier V , a close and
compromised prover A, and a distant (non-compromised)
prover P collude to make V believe that P is close. A condition
for this attack to be valid is that, without further collusion
involving A, it must not be possible to further convince V
that A is close.
B CHOTHIA ET AL.’S FRAMEWORK VS. OURS
In this appendix we provide a detailed description on the incon-
sistencies between Chothia et al.’s work [20] in relation to our
framework and results.
B.1 On Terrorist Fraud
Chothia et al.’s terrorist fraud approach and ours yield different
results when analysing the DBToy protocol in Example 2. The rea-
son is a fundamental difference between the approaches in defining
what consists a terrorist fraud attack.
Both definitions state that a distant prover, by colluding with
a close and compromised prover, make a verifier believe that the
distant prover is close. The definitions differ in the condition on the
collusion that make one consider the attack as valid. Chothia et al.’s
definition states that a terrorist fraud occurs whenever the distant
prover does not reveal their secret keys in the process of collusion.
Our definition, on the other hand, requires a stronger condition, in
that the distant prover must not allow the compromised prover to
proof proximity in further sessions without further collusion.
The reason for this is related to the reveal of messages that are
as relevant as secret keys, rather than the reveal of secret keys
themselves. For example, for some protocols, a prover’s leakage
of session-fresh data can lead to their impersonation in every ses-
sion thereafter. A running example is given as follows. Consider a
distance-bounding protocol Proto in which every crypto-operation
uses a shared, symmetric key. Let us assume that the only aid the
distant prover can provide the close prover with is to give away the
shared key. If we follow Chothia et al.’s approach, Proto would be
resistant to terrorist fraud. Consider now another protocol Proto′
that results from Proto by replacing any instance of a shared key
k by its hash h(k). Therefore, if we use Chothia et al.’s approach,
Proto′ would not be resistant to terrorist fraud, as the distant prover
can leak h(k), which does not reveal k itself. In this case, the mes-
sage h(k) is equally as valuable as the key k itself. This means that
the key-hashing transformation weakens the protocol, which does
not seem to be a coherent statement. The mentioned issue does not
occur if we apply our approach as both Proto and Proto′ would be
resistant to terrorist fraud.
A
V
(a) Mafia fraud
A
V
P
P
V
(b) Distance fraud
A
V
P
P
(c) Distance hijacking
(d) Terrorist fraud
Figure 9: Types of attack on distance-bounding protocols. In all cases, V is the verifier, P is the prover who V claims prox-
imity to, and A is an agent in the proximity of V . Filled icons represent agents who either collude or are compromised by
the adversary. Unfilled icons represent honest agents, i.e. agents who don’t deviate from the protocol specification. The en-
circled area represents V ’s proximity, which is bounded by the predefined threshold on the round-trip time. Dashed arrows
represent untimed communication, which is communication that does not occur entirely within the fast phase. Thanks to
https://thenounproject.com for the icons.
Another inconsistency between our results on terrorist fraud
analysis and those of Chothia et al. is with respect to Hancke and
Kuhn’s protocol [34], depicted in Figure 10. This protocol was
reported as resistant to terrorist fraud by Chothia et al.’s ProVerif
model [20]. We refute Chothia et al.’s statement by demonstrating
a trivial terrorist attack, represented in Figure 11.
Recall that in Chothia et al. [20], the prover’s response message
is modelled as f (ch, NV , NP , k) which is an inaccurate modelling
compared to the original protocol specification. We remark that
the order of the arguments is not the issue, but the level at which
they occur in the function f . In particular, the prover uses the
values NV , NP and k to seed a PRNG д before the fast phase begins.
During the phase phase, the prover then uses this PRNG to respond
to challenges. As a result, a more faithful representation of the
challenge response message is f (ch, д(k, NV , NP)), in which the
shared key k is not in the same level as the challenge ch. As a result,
the prover can leak д(k, NV , NP) (i.e. the seeded PRNG) without
leaking k. In the representation of Chothia et al., k and ch are at
the same level, hence in order for the prover to leak dbsec_hnst-
breaking data, the shared key k must be leaked, and this indeed
makes the attack no longer valid. This is the reason for which
Chothia et al. do not deliver the attack depicted Figure 11.
B.2 On Distance Hijacking
Chothia et al.’s analysis reports no attack, other than terrorist fraud,
against Meadows et al.’s protocol [46] version in which the prover’s
Figure 10: Hancke and Kuhn’s protocol [34]. In Chothia et
al. [20] the prover’s response f (ch, д(k, NV , NP)) is modelled
as f (ch, NV , NP , k). This over-approximated modelling is the
cause for which Chothia et al.’s analysis results did not iden-
tify a terrorist fraud attack against this protocol.
fast phase response is ⟨NV , P ⊕ NP⟩, and the MAD protocol [19]
with one-way authentication. These protocols are depicted in Fig-
ures 12 and 13, respectively.
sharedkVsharedkPfreshNV,chfreshNPNVNPchRTTf(ch,g(k,NV,NP))PiscloseFigure 13: Capkun et al.’s MAD protocol [19]. This is the vari-
ant with prover-to-verifier authentication. H is a hash func-
tion and MACk is a keyed-MAC function.
Figure 11: A terrorist fraud attack on Hancke and Kuhn’s
protocol [34]. The distant prover P colludes with the close
and compromised prover A by giving away д(k, NV , NP), rep-
resented by the dashed arrow. This allows A to impersonate
P to the verifier V during the fast phase, hence V believes
that P is close. The same false-proximity proof cannot be is-
sued in further sessions without further collusion because
д(k, NV , NP) is fresh in every session and k is not revealed.
Figure 12: Meadows et al.’s protocol [46], where locP denotes
the location of the prover P. Such location has no impact
on any symbolic analysis as it comes in plain text, thus it is
modelled as a nonce. Three instances of the protocol are pro-
posed by the authors, given by the following three choices
of f : ⟨NV , P ⊕ NP⟩, ⟨NV , P, NP⟩, and NV ⊕ h(P, NP) where ⊕ is
the exclusive-OR and h is a collision-free hash function.
Our analysis, however, identifies a valid distance hijacking at-
tack against each of these protocols (see Figures 14 and 15). In
both cases, the compromised prover P, who is distant from the
Figure 14: A distance hijacking attack on Meadows et al.’s
:= ⟨NV , P ⊕ NP⟩. P learns NV
protocol with the choice f
and A ⊕ NA from passive observation of the legitimate fast
phase. Hence, P produces their own authentication message
⟨s, h(k, s)⟩, given that the equality P ⊕ NP = A ⊕ NA.
verifier V , hijacks the session between V and a close-by and hon-
est prover A by replacing the final authentication message of the
legitimate and close P with their own authentication message, thus
making V believe that P is close. In the case of Meadows et al.’s
protocol, the existence of this attack is indeed consistent with the
authors’ own statement that their model does not cover attacks
of the compromised-prover type. As previously mentioned in Sec-
tion 6.2 before, a number of previous papers, such as [6, 26, 27, 44],
also report distance hijacking attacks against these two protocols.
sharedkwithPVAsharedkwithVPfreshNV,chfreshNPNVg(k,NV,NP)NPchRTTf(ch,g(k,NV,NP))PisclosesharedkVsharedkPfreshNVfreshNPV,‘hello’NVRTTf(NV,P,NP)s:=hP,locP,NP,NVis,h(k,s)PisclosesharedkVsharedkPfreshbfreshs,s′H(s,s′)bRTTs⊕bs′,MACk(V,P,b,s)PisclosesharedkwithPVAsharedkwithVPfreshNVfreshNAV,‘hello’NVRTTNV,A⊕NANP:=P⊕(A⊕NA)s:=hP,locA,NP,NVis,h(k,s)Pisclose] |
[ !(new id;
let idP=id in !DishonestProver)
]
However, this naive implementation leads to several problems when
applying it to various protocols:
• In this configuration, ‘honest’ sessions can be completed
between the verifier and local prover. The non-specificity of
the query can lead to these honest traces being flagged as
potential attacks.
• Many protocols which admit distance hijacking attacks in-
volve the prover revealing their identity only late in the pro-
tocol, by use of a shared key or signing key. One workaround
- using a dummy message to indicate to a verifier who their
partner is - affects the faithfulness of the model and can lead
to the false attacks mentioned above.
• Several distance hijacking attacks (including Meadows and
MAD) rely on the adversary abusing the algebraic properties
of the exclusive-or operator. It is not clear if the equational
theory used in the given models (which relies on applying
deconstructor functions) is sufficient to model a prover being
unable to distinguish e.g. x ⊕ y and x ⊕ z ⊕ z ⊕ y.
We emphasize that while the model of Chothia et al. distinguishes
which prover in a configuration is the one being ‘tested’ for prox-
imity, their tooling does not make this distinction without manually
modifying compiled output files. This difference between model
and implementation has no impact in configurations in which hon-
est executions cannot complete, but this is not the case for distance
hijacking attacks.
ACKNOWLEDGMENTS
This work was partially supported by the Luxembourg National
Research Fund (FNR) under the grants AFR-PhD-10188265 and
C15-IS-10428112. We thank S. Delaune and A. Debant for their
comments on our Tamarin models.
REFERENCES
[1] Yonatan Aumann and Yehuda Lindell. 2010. Security Against Covert Adversaries:
Efficient Protocols for Realistic Adversaries. J. Cryptology 23, 2 (2010), 281–343.
https://doi.org/10.1007/s00145-009-9040-7
[2] Gildas Avoine, Muhammed Ali Bingöl, Ioana Boureanu, Srdjan Capkun, Gerhard P.
Hancke, Süleyman Kardas, Chong Hee Kim, Cédric Lauradoux, Benjamin Martin,
Jorge Munilla, Alberto Peinado, Kasper Bonne Rasmussen, Dave Singelée, Aslan
Tchamkerten, Rolando Trujillo-Rasua, and Serge Vaudenay. 2019. Security of
Distance-Bounding: A Survey. ACM Comput. Surv. 51, 5 (2019), 94:1–94:33.
https://dl.acm.org/citation.cfm?id=3264628
[3] Gildas Avoine, Muhammed Ali Bingöl, Süleyman Kardas, Cédric Lauradoux, and
Benjamin Martin. 2011. A framework for analyzing RFID distance bounding
protocols. Journal of Computer Security 19, 2 (2011), 289–317. https://doi.org/10.
3233/JCS-2010-0408
[4] Gildas Avoine, Xavier Bultel, Sébastien Gambs, David Gérault, Pascal Lafourcade,
Cristina Onete, and Jean-Marc Robert. 2017. A Terrorist-fraud Resistant and
Extractor-free Anonymous Distance-bounding Protocol. In Proceedings of the
2017 ACM on Asia Conference on Computer and Communications Security, AsiaCCS
2017, Abu Dhabi, United Arab Emirates, April 2-6, 2017. 800–814. https://doi.org/
10.1145/3052973.3053000
[5] Gildas Avoine, Cédric Lauradoux, and Benjamin Martin. 2011. How secret-sharing
can defeat terrorist fraud. In Proceedings of the Fourth ACM Conference on Wireless
Network Security, WISEC 2011, Hamburg, Germany, June 14-17, 2011. 145–156.
https://doi.org/10.1145/1998412.1998437
[6] Gildas Avoine, Sjouke Mauw, and Rolando Trujillo-Rasua. 2015. Comparing