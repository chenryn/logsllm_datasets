Our basic usage model consists of two phases. First,
we run a simulation in which sensitive data (e.g. com-
ing from the keyboard, network, etc.) is identiﬁed as
tainted. The workload consists of normal user interac-
tion, e.g. logging into a website via a browser. In the sec-
ond phase, the simulation data is analyzed with the anal-
ysis framework. This allows us to answer open-ended
queries about the simulation, such as where tainted data
came from, where it was stored, how it was propagated,
etc.
We will begin by looking at the implementation of
TaintBochs, focusing on modiﬁcations to the simulator
to facilitate tainting, logging, etc. We will then move
on to examine the analysis framework and how it can be
used with other tools to gain a complete picture of data
lifetime in a system.
3.1 Hardware Level Tainting
There are two central issues to implementing hard-
ware level tainting: ﬁrst, tracking the location of sensi-
tive state in the system, and, second, deciding how to
evolve that state over time to keep a consistent picture of
which state is sensitive. We will examine each of these
issues in turn.
Shadow Memory To track the location of sensitive
data in TaintBochs, we added another memory, set of
registers, etc. called a shadow memory. The shadow
memory tracks taint status of every byte in the system.
Every operation performed on machine state by the pro-
cessor or devices causes a parallel operation to be per-
formed in shadow memory, e.g. copying a word from
register A to location B causes the state in the shadow
register A to be copied to shadow location B. Thus to
determine if a byte is tainted we need only look in the
corresponding location in shadow memory.
If any bit in a byte is tainted, the entire byte is consid-
ered tainted. Maintaining taint status at a byte granular-
ity is a conservative approximation, i.e. we do not ever
lose track of sensitive data, although some data may be
unnecessarily tainted. Bit granularity would take mini-
mal additional effort, but we have not yet encountered a
situation where this would noticeably aid our analysis.
For simplicity, TaintBochs only maintains shadow
memory for the guest’s main memory and the IA-32’s
eight general-purpose registers. Debug registers, con-
trol registers, SIMD (e.g. MMX, SSE) registers, and
ﬂags are disregarded, as is chip set and I/O device state.
Adding the necessary tracking for other processor or
I/O device state (e.g. disk, frame buffer) would be quite
straightforward, but the current implementation is sufﬁ-
cient for many kinds of useful analysis. We are not ter-
ribly concerned about the guest’s ability to launder taint
bits through the processor’s debug registers, for exam-
ple, as our assumption is that software under analysis is
not intentionally malicious.
Propagation Policy We must decide how operations
in the system should affect shadow state. If two registers
A and B are added, and one of them is tainted, is the
register where the result are stored also tainted? We refer
to the collective set of policies that decide this as the
propagation policy.
In the trivial case where data is simply copied, we
perform the same operation in the address space of
shadow memory. So, if the assignment A ← B exe-
cutes on normal memory, then A ← B is also executed
on shadow memory. Consequently, if B was tainted then
A is now also tainted, and if B was not tainted, A is now
also no longer tainted.
The answer is less straightforward when an instruc-
tion produces a new value based on a set of inputs. In
such cases, our simulator must decide on whether and
how to taint the instruction’s output(s). Our choices
must balance the desire to preserve any possibly interest-
ing taints against the need to minimize spurious reports,
i.e. avoid tainting too much data or uninteresting data.
This roughly corresponds to the false negatives vs. false
positives trade-offs made in other taint analysis tools. As
we will see, it is in general impossible to achieve the lat-
ter goal perfectly, so some compromises must be made.
Processor instructions typically produce outputs that
are some function of their inputs. Our basic propaga-
tion policy is simply that if any byte of any input value is
tainted, then all bytes of the output are tainted. This pol-
icy is clearly conservative and errs on the side of taint-
ing too much. Interestingly though, with the exception
of cases noted below, we have not yet encountered any
obviously spurious output resulting from our policy.
Propagation Problems There are a number of quite
common situations where the basic propagation policy
presented before either fails to taint interesting informa-
tion, or taints more than strictly necessary. We have dis-
covered the following so far:
• Lookup Tables. Sometimes tainted values are used
by instructions as indexes into non-tainted memory
(i.e. as an index into a lookup table). Since the tainted
value itself is not used in the ﬁnal computation, only
the lookup value it points to, the propagation pol-
icy presented earlier would not classify the output as
tainted.
This situation arises routinely. For example, Linux
routinely remaps keyboard device data through a
lookup table before sending keystrokes to user pro-
grams. Thus, user programs never directly see the
data read in from the keyboard device, only the non-
tainted values they index in the kernel’s key remap-
ping table.
Clearly this is not what we want, so we aug-
mented our propagation policy to handle tainted in-
dexes (i.e. tainted pointers) with the following rule:
if any byte of any input value that is involved in the
address computation of a source memory operand is
tainted, then the output is tainted, regardless of the
taint status of the memory operand that is referenced.
• Constant Functions. Tainted values are sometimes
used in computations that always produce the same
result. We call such computations constant functions.
An example of such a computation might be the fa-
miliar IA-32 idiom for clearing out a register: xor
eax, eax. After execution of this instruction, eax
always holds value 0, regardless of its original value.
For our purposes, the output of constant functions
never pose a security risk, even with tainted inputs,
since the input values are not derivable from the out-
put. In the xor example above, it is no less the sit-
uation as if the programmer had instead written mov
eax, 0. In the xor case, our naive propagation pol-
icy taints the output, and in the mov case, our prop-
agation policy does not taint the output (since imme-
diate inputs are never considered tainted).
Clearly, our desire is to never taint the output of
constant functions. And while this can clearly be
done for special cases like xor eax, eax or sim-
ilar sequences like sub eax, eax, this cannot be
done in general since the general case (of which the
xor and sub examples are merely degenerate mem-
bers) is an arbitrary sequence of instructions that ul-
timately compute a constant function. For example,
assuming eax is initially tainted, the sequence:
mov ebx, eax
add ebx, ebx
; ebx = eax
; ebx = 2 * eax
shl eax, 1
xor ebx, eax
; eax = 2 * eax
; ebx = 0
Always computes (albeit circuitously) zero for ebx,
regardless of the original value of eax. By the time
the instruction simulation reaches the xor, it has no
knowledge of whether its operands have the same
value because of some deterministic computation or
through simple chance; it must decide, therefore, to
taint its output.
One might imagine a variety of schemes to address
this problem. Our approach takes advantage of the
semantics of tainted values. For our research, we are
interested in tainted data representing secrets like a
user-typed password. Therefore, we simply deﬁne by
ﬁat that we are only interested in taints on non-zero
values. As a result, any operation that produces a zero
output value never taints its output, since zero outputs
are, by deﬁnition, uninteresting.
This simple heuristic has the consequence that
constant functions producing nonzero values can still
be tainted. This has not been a problem in practice
since constant functions themselves are fairly rare,
except for the degenerate ones that clear out a reg-
ister. Moreover, tainted inputs ﬁnd their way into a
constant function even more rarely, because tainted
memory generally represents a fairly small fraction
of the guest’s overall memory.
• One-way Functions. Constant functions are an inter-
esting special case of a more general class of compu-
tations we call one-way functions. A one-way func-
tion is characterized by the fact that its input is not
easily derived from its output. The problem with one-
way functions is that tainted input values generally
produce tainted outputs, just as they did for constant
functions. But since the output value gives no prac-
tical information about the computation’s inputs, it
is generally uninteresting to ﬂag such data as tainted
from the viewpoint of analyzing information leaks,
since no practical security risk exists.
A concrete example of this situation occurs in
Linux, where keyboard input is used as a source of
entropy for the kernel’s random pool. Data collected
into the random pool is passed through various mix-
ing functions, which include cryptographic hashes
like SHA-1. Although derivatives of the original key-
board input are used by the kernel when it extracts
entropy from the pool, no practical information can
be gleaned about the original keyboard input from
looking at the random number outputs (at least, not
easily).
Our system does not currently try to remove
tainted outputs resulting from one-way functions,
since instances of such taints are few and easily iden-
tiﬁable. Moreover, such taints are often useful for
identifying the spread of tainted data, for example,
the hash of a password is often used as a crypto-
graphic key.
Evading Tainting While the propagation policy de-
ﬁned above works well for us in practice, data can be
propagated in a manner that evades tainting. For exam-
ple, the following C code,
if (x == 0) y = 0;
else if (x == 1) y = 1;
...
else if (x == 255) y = 255;
effectively copies x to y, but since TaintBochs does not
taint comparison ﬂags or the output of instructions that
follow a control ﬂow decision based on them, the asso-
ciated taint for x does not propagate to y. Interestingly,
the Windows 2000 kernel illustrates this problem when
translating keyboard scancodes into unicode.
Another possible attack comes from the fact that
TaintBochs never considers instruction immediates to be
tainted. A guest could take advantage of this by dynami-
cally generating code with proper immediate values that
constructs a copy of a string.
Because such attacks do exist, TaintBochs can never
prove the absence of errors; we don’t expect to use it
against actively malicious guests. Instead, TaintBochs is
primarily focused on being a testing and analysis tool for
ﬁnding errors.
Taint Sources TaintBochs supports a variety of meth-
ods for introducing taints:
• Devices.
I/O devices present an excellent opportu-
nity to inject taints into the guest, since they represent
the earliest point of the system at which data can be
introduced. This is a crucial point, since we are in-
terested in the way a whole system handles sensitive
data, even the kernel and its device drivers. Taint-
Bochs currently supports tainting of data at the key-
board and network devices. Support for other devices
is currently under development.1
Keyboard tainting simply taints bytes as they are
read from the simulated keyboard controller. We use
this feature, for example, to taint a user-typed pass-
word inside a web browser (see section 4.1.1 for de-
tails). This features is essentially binary: keyboard
tainting is either on or off.
1Support for disk tainting and frame buffer tainting is currently un-
derway. With this addition we hope to more completely understand
when data is leaked to disk and its lifetime there. We anticipate this
will be complete before publication.
Tainting data at the Ethernet card is a slightly more
complicated process. We do not want to simply taint
entire Ethernet packets, because Ethernet headers,
TCP/IP headers, and most application data are of lit-
tle interest to us. To address this we provide the net-
work card with one or more patterns before we begin
a simulation. TaintBochs scans Ethernet frames for
these patterns, and if it ﬁnds a match, taints the bytes
that match the pattern. These taints are propagated to
memory as the frame is read from the card. Although
this technique can miss data that should be tainted
(e.g. when a string is split between two TCP packets)
it has proved sufﬁcient for our needs so far.
• Application-speciﬁc. Tainting at the I/O device level
has as its chief beneﬁt the fact that it undercuts all
software in the system, even the kernel. However
this approach has limitations. Consider, for exam-
ple, the situation where one wants to track the life-
time and reach of a user’s password as it is sent over
the network to an SSH daemon. As part of the SSH
exchange, the user’s password is encrypted before be-
ing sent over the network, thus our normal approach
of pattern matching is at best far more labor intensive,
and less precise than we would like.
Our current solution to this situation, and others
like it, is to allow the application to decide what is
interesting or not. Speciﬁcally, we added an instruc-
tion to our simulated IA-32 environment to allow the
guest to taint data: taint eax. Using this we can
modify the SSH daemon to taint the user’s password
as soon as it is ﬁrst processed. By pushing the taint
decision-making up to the application level, we can
skirt the thorny issue that stopped us before by taint-
ing the password after it has been decrypted by the
SSH server. This approach has the unfortunate prop-
erty of being invasive, in that it requires modiﬁcation
of guest code. It also fails to taint encrypted data in
kernel and user buffers, but such data is less interest-
ing because the session key is also needed to recover
sensitive data.
3.2 Whole-System Logging
TaintBochs must provide some mechanism for an-
swering the key questions necessary to understand taint
propagation: Who has tainted data? How did they get
it? and When did that happen?. It achieves this through
whole-system logging.
Whole system logging records sufﬁcient data at simu-
lation time to reconstitute a fairly complete image of the
state of a guest at any given point in the simulation. This
is achieved by recording all changes to interesting sys-
tem state, e.g. memory and registers, from the system’s
initial startup state. By combining this information with
the initial system image we can “play” the log forward
to give us the state of the system at any point in time.
Ideally, we would like to log all changes to state,
since we can then recreate a perfect image of the guest
at a given instant. However, logging requires storage for
the log and has runtime overhead from logging. Thus,
operations which are logged are limited to those neces-
sary to meet two requirements. First we need to be able
to recreate guest memory and its associated taint status
at any instruction boundary to provide a complete pic-
ture of what was tainted. Second, we would like to have
enough register state available to generate a useful back-
trace to allow deeper inspection of code which caused
tainting.
To provide this information the log includes writes to
memory, changes to memory taint state, and changes to
the stack pointer register (ESP) and frame pointer reg-
ister (EBP). Each log entry includes the address (EIP)
of the instruction that triggered the log entry, plus the
instruction count, which is the number of instructions
executed by the virtual CPU since it was initialized.
To assemble a complete picture of system state Taint-
Bochs dumps a full snapshot of system memory to disk
each time logging is started or restarted. This ensures
that memory contents are fully known at the log’s start,
allowing subsequent memory states to be reconstructed
by combining the log and the initial snapshot.
Logging of this kind is expensive: at its peak, it pro-
duces about 500 MB/minute raw log data on our 2.4
GHz P4 machines, which reduces about 70% when we
add gzip compression to the logging code. To further
reduce log size, we made it possible for the TaintBochs
user to disable logging when it is unneeded (e.g. during
boot or between tests). Even with these optimizations,
logging is still slow and space-consuming. We discuss
these overheads further in section 6.
3.3 Analysis Framework
Taint data provided by TaintBochs is available only
at the hardware level. To interpret this data in terms of
higher level semantics, e.g. at a C code level, hardware
level state must be considered in conjunction with ad-
ditional information about software running on the ma-