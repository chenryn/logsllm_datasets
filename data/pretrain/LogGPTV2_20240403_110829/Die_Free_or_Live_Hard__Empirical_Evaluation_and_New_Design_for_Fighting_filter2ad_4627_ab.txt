r
i
p
m
E
1
0.8
0.6
0.4
0.2
0
0
A
B
C
All Spammers
All Accounts
All Spammers
All Accounts
Missed Spammers
1
0.8
0.6
0.4
0.2
F
D
C
l
a
i
c
i
r
i
p
m
E
All Accounts
Missed Spammers
A
B
C
All Spammers
All Accounts
All Spammers
1
0.8
0.6
0.4
0.2
F
D
C
l
a
c
i
r
i
p
m
E
All Spammers
Missed Spammers
All Accounts
A
B
C
All Spammers
All Accounts
100
200
300
# of Followers
400
500
0
0
2
4
6
Fofo Ratio
8
10
0
0
100
200
300
# of Tweets
400
500
(a) Number of followers
(b) Fofo Ratio
(b) Number of tweets
Fig. 2. Proﬁle-based feature examination on three existing detection work
Mixing Normal Tweets: Based on observations of the missed spammers by
the existing work, we can ﬁnd that some of them post non-spam tweets to dilute
their spam tweet percentage. Fig. 3(a) shows a real example of a spammer that
posts famous quotes, “Winning isn’t everything, but wanting to win is. – Vince
Lombardi”, between tweets containing links to phishing and scam websites.
8
Posting Heterogeneous Tweets: In order to avoid content-based detec-
tion features such as tweet similarity and duplicate tweet count, spammers use
tools to “spin” their tweets so that they can have heterogeneous tweets with the
same semantic meaning using diﬀerent words. Fig. 3(b) shows a spammer that
posts various messages encouraging users to sign up for a service. The service is
eventually a trap to steal users’ email addresses. Notice that the spammer uses
three diﬀerent phrases that have the same semantic meaning: “I will get more.
You can too!”, “you will get more.”, and “want get more, you need to check”.
An example of tools that can be used to create such heterogeneous tweets, called
spin-bot [15], is shown in Fig. 3(c). By typing a phrase into the large text ﬁeld
and pressing “Process Text”, a new phrase with the same semantic meaning and
yet diﬀerent words is generated below.
(a) Mixing Normal Tweets (b) Posting Heterogeneous Tweets
(c) Spin-bot
Fig. 3. Case studies for content-based feature evasion tactics
From the above analysis, we can ﬁnd that Twitter spam accounts are indeed
evolving to evade existing detection methods to increase their lifespan.
5 Designing New Features
In this section, to counter spammers’ evasion tactics, we propose several new
and more robust detection features. A robust feature should either be diﬃcult
or expensive to evade: a feature is diﬃcult to evade if it requires a fundamental
change in the way that a spammer performs its malicious deeds; a feature is
expensive to evade if the evasion requires much money, time or resources. On
the basis of spam accounts’ special characteristics, we design 10 new detection
features including three Graph-based features, three Neighbor-based features,
three Automation-based features and one Timing-based feature, which will be
described in details in the following sections.
5.1 Graph-based Features
If we view each Twitter account i as a node and each follow relationship as a
directed edge e, then we can view the whole Twittersphere as a directed graph
G = (V, E). Even though the spammers can change their tweeting or following
behavior, it will be diﬃcult for them to change their positions in this graph.
According to this intuition, we design three graph-based features: local clustering
coeﬃcient, betweenness centrality, and bi-directional links ratio.
9
Local Clustering Coeﬃcient: The local clustering coeﬃcient [10] for a vertex
is the proportion of links between the vertices within its neighborhood divided
by the number of links that could possibly exist between them. This metric can
be utilized to quantify how close a vertex’s neighbors are to being a clique. For
each vertex v in the Twitter graph, its local clustering score can be computed
by Eq. (1), where Kv is the sum of the indegree and outdegree of the vertex v,
and |ev| is the total number of edges built by all v’s neighbors.
LC(v) =
2|ev|
Kv · (Kv − 1)
(1)
Since legitimate users usually follow accounts whose owners are their friends,
colleagues or family members, these accounts are likely to have a relationship
with each other. However, since spammers usually blindly follow other accounts,
these accounts usually do not know each other and have a looser relationship
among them. Thus, compared with the legitimate accounts, Twitter spammers
will have smaller local clustering coeﬃcient.
Betweenness Centrality: Betweenness centrality [4] is a centrality measure of
a vertex within a graph. Vertices that occur on many shortest paths between
other vertices have a higher betweenness than those that do not. In a directed
graph, betweeness centrality of each vertex v can be computed by Eq. (2), where
δst is the number of shortest paths from s to t, and δst(v) is the number of
shortest paths from s to t that pass through a vertex v, and n is the total
number of vertexes in the graph.
BC(v) =
1
(n − 1)(n − 2)
· X
s6=v6=t∈V
δst(v)
δst
(2)
This metric reﬂects the position of the vertex in the graph. Nodes that occur
in many shortest paths have higher values of betweenness centrality. A Twitter
spammer will typically use a shotgun approach to ﬁnding victims, which means
it will follow many accounts without regard for whom they are or with whom
these victims are connected. As a result, many of their victims are unrelated
accounts, and thus their shortest path between each other is the average shortest
path between all nodes in the graph. When the Twitter spammer follows these
unrelated accounts, this creates a new shortest path between any victim following
of the spam account and any other victim following, through the spam account.
Thus, the betweenness centrality of the spammer will be high.
Bi-directional Links Ratio: If two accounts follow with each other, we con-
sider them to have a bidirectional link between each other. The number of bi-
directional links of an account reﬂects the reciprocity between an account and its
followings. Since Twitter spammers usually follow a large number of legitimate
accounts and cannot force those legitimate accounts to follow back, the number
of bi-directional links that a spammer has is low. On the other hand, a legiti-
mate user is likely to follow his friends, family members, or co-workers who will
follow this user back. Thus, this indication can be used to distinguish spammers.
However, Twitter spammers could evade this by following back their followers.
10
Thus, we create another feature named bi-directional links ratio (Rbilink), which
can be computed in Eq. (3).
Rbilink =
Nbilink
Nf ing
(3)
where Nbilink and Nf ing denote the number of bi-directional links and the num-
ber of followings. The intuition behind this feature is that even though the spam-
mers can increase the value of Nbilink through following back their followers or
obtaining “following-backs” from other accounts, compared with their high val-
ues of Nf ing, their values of Rbilink will be relatively diﬃcult to increase to be
comparable with that of legitimate accounts. Although this feature still can be
evaded, the spammers need to pay more to evade this feature.
5.2 Neighbor-based Features
In this section, we design three neighbor-based features to distinguish Twitter
spammers and legitimate accounts: average neighbors’ followers, average neigh-
bors’ tweets, and followings to median neighbors’ followers.
Average Neighbors’ Followers: Average neighbors’ followers, denoted as Anf er,
of an account v represents the average number of followers of this account’s fol-
lowings, which can be computed with Eq.(4).
Anf er(v) =
1
|Nf ing(v)|
· X
u∈Nf ing(v)
Nf er(u)
(4)
where Nf er and Nf ing denote the number of followers and followings, respec-
tively. Since an accounts’ follower number usually reﬂects this account’s popu-
larity or reputation, this feature reﬂects the quality of the choice of friends of an
account. It is obvious that legitimate accounts intend to follow the accounts who
have higher quality unlike the spammers. Thus, the average neighbors’ followers
of legitimate accounts are commonly higher than that of spammers.
Average Neighbors’ Tweets: Similar to the average neighbors’ followers, since
an account’s tweet number could also reﬂect this account’s quality, we design
another feature, named average neighbors’ tweets, which is the average number of
tweets of this account’s following accounts. Note that these two features can be
evaded by following popular Twitter accounts (seen in Section 6). We also design
another relatively robust neighbor-based detection feature, named followings to
median neighbors’ followers.
Followings to Median Neighbors’ Followers: To extract this feature, we ﬁrst
deﬁne the median number of an account’s all following accounts’ follower num-
bers as Mnf er. Then, the followings to median neighbors’ followers of an account,
denoted as Rf ing mnf er, can be computed by the ratio of this account’s following
number to Mnf er, as shown in Eq.(5).
Rf ing mnf er =
Nf ing
Mnf er
(5)
11
Since spammers can not guarantee the quality of the accounts they follow, their
values of Mnf er are typically small. Thus, due to spammers’ large numbers of
followings, spammers’ values of Rf ing mnf er will be also high. For the legitimate
accounts, to show the analysis of this feature, we divide them into two diﬀerent
types: common accounts (legitimate accounts without large numbers of followers)
and popular accounts (legitimate accounts with large numbers of followers). For
the ﬁrst type of accounts, they may also just follow their friends which leads to a
small value of Mnf er. However, since their following numbers are also not high,
common accounts’ values of Rf ing mnf er are not high. For the popular accounts
who are usually celebrities, famous politicians, or professional institutions, they
will usually choose accounts who are also popular to follow. In this way, these
accounts’ values of Mnf er will be high, leading to low values of Rf ing mnf er.
From the above analysis, we can ﬁnd that spammers will have higher values
of this feature than that of legitimate accounts. In addition, since we use the
median value rather than the mean, it will be very diﬃcult for spammers to
increase their values of Mnf er by following a few very popular accounts. Thus,
this feature is diﬃcult to be evaded.
5.3 Automation-based Features
Due to the large cost of manually managing a large number of spam accounts,
many spammers choose to create a custom program using Twitter API to post
spam tweets. Thus, we also design three automation-based features to detect
spammers: API3 ratio, API URL ratio and API Tweet Similarity.
API Ratio: API ratio is the ratio of the number of tweets with the tweet
source of “API” to the total number of tweet count. As existing work [26] shows,
many bots choose to use API to post tweets, so a high API ratio implies this
account is more suspicious.
API URL Ratio: API URL ratio is the ratio of the number of tweets contain-
ing a URL posted by API to the total number of tweets posted by API. Since
it is more convenient for spammers to post spam tweets using API, especially
when spammers need to manage a large amount of accounts. Thus, a higher API
URL ratio of an account implies that this account’s tweets sent from API are
more likely to contain URLs, making this account more suspicious.
API Tweet Similarity: Spammers can use tricks to evade the detection feature
of tweet similarity as described in Section 4 and still choose to use API to
automatically post malicious tweets. Thus, we also design API tweet similarity,
which only compute the similarity of those tweets posted by API. Thus, a higher
API tweet similarity of an account implies that this account is more suspicious.
3 The source of tweets sent by unregistered third-party applications in Twitter will be
labeled as “API” rather than speciﬁc application names, e.g., “TweetDeck” [16]. In
this paper, we use “API” to refer those unregistered third-party tools.
12
5.4 Timing-based Features
Similar to other timing-based features such as tweeting rate presented in [22],
we also design another timing-based feature named following rate.
Following Rate: Following rate reﬂects the speed at which an account follows
other accounts. Since spammers will usually follow many other accounts in a
short period of time, a high following rate of an account indicates that the
account is likely a spam account. Since it is diﬃcult to collect the time when
an account follows another account, we use the ratio of an account’s following
number to the age of the account at the time to obtain an approximate value.
After designing these new features, we ﬁrst formalize the robustness of most
of the existing detection features and our designed features in Section 6. Then, we
combine some existing eﬀective features and our features to build a new machine
learning detection scheme and evaluate it based on our dataset in Section 7.
6 Formalizing Feature Robustness
In this section, to deeply understand how to design eﬀective features to detect
Twitter spammers, we formalize the robustness of the detection features.
6.1 Formalizing the Robustness
Before analyzing the robustness, we ﬁrst build a model to deﬁne the robustness
of the detection features. In terms of spammers’ dual objectives C avoiding de-
tection and achieving malicious goals, the robustness of each feature F , denoted
as R(F ), can be viewed as the tradeoﬀ between the spammers’ cost C(F ) to
avoid the detection and the proﬁts P (F ) by achieving malicious goals. Thus, the
robustness of each feature can be computed by Eq. (6).