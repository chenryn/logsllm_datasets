### Diversity of the Sample
We observed a significant number of unique URLs specific to each data source, likely due to differences in their data collection and detection methodologies.

### Report URLs and Prune if Blacklisted
If a URL is not initially blacklisted, we report it directly to blacklists and other key anti-phishing entities. This is done with the aim of getting the URL blacklisted, using the approach and infrastructure described in Section 7.2. We then prune URLs that are blacklisted within a reasonable period and retain those that remain unblacklisted. Recent studies have shown that once detected by a blacklist’s backend, most phishing URLs display blacklist warnings within two hours [46]. Therefore, we set a two-hour cutoff to eliminate URLs that blacklists can successfully detect but may have initially failed to discover.

### Analyze (Evasive) Phishing Websites
We manually inspect the remaining URLs to understand why they evade blacklist detection. Our analysis includes examining the evasion techniques employed and the behavior (i.e., general appearance and user interface) of the websites. We visit each URL and test different variations of request parameters until we successfully retrieve the content. This allows us to infer the server-side evasion techniques used by each phishing website. We also visually analyze the websites and inspect client-side source code to uncover additional evasion logic and compare them to known phishing kits to determine the most common techniques. Simultaneously, we identify and exclude false positives or offline websites.

### Design (Evasion-inspired) Experiments
After analyzing a representative sample of URLs, we abstract the key trends observed and design experiments to replicate them in a controlled setting (Section 6). 

### PhishTime Framework Overview
An effective way to empirically evaluate the performance of anti-phishing blacklists is to deploy a large batch of specially-configured test phishing websites, report these websites directly to blacklists, and monitor them to see if and when they are blacklisted [44, 48]. For our longitudinal evaluation of blacklist performance, we make a series of such deployments at regular intervals over an extended period. Each deployment includes multiple distinct batches of websites to support different experiments. The goal is to provide insights into potential gaps within the ecosystem, which could lead to actionable security recommendations. To achieve this, we closely replicate the phishing website configurations (i.e., evasion techniques) used by attackers. To identify such configurations and guide our experimental design, we developed the PhishTime framework.

### Permissions and Focus
We obtained permission from PayPal, Inc. to use PayPal-branded phishing websites throughout our experiments. Therefore, in our PhishTime ecosystem analysis, we also focus on PayPal phishing websites in the wild. Although we were unable to collaborate with other companies for this research, our methodology is generic and can be applied to any brand(s).

### PhishTime Framework
The PhishTime framework is a systematic, semi-automated approach for identifying evasive (i.e., unmitigated) phishing websites in the wild. We use the framework to characterize both typical and emerging evasion techniques used by real phishing websites. Understanding the ecosystem’s response to typical phishing enables the identification of gaps currently being exploited by attackers, while the analysis of less prominent emerging evasion techniques provides additional insights.

### Deploy PhishTime Experiments
Finally, we deploy these experiments (Section 7) to evaluate blacklist performance over time in the face of diverse evasion techniques.

### Ecosystem Recommendations
We use our experimental results to make security recommendations for specific blacklists or the ecosystem (Sections 8-9). Any resulting ecosystem changes can influence the design of experiments in future framework deployments.

### PhishTime Analysis
In January 2019, we used the PhishTime framework to identify phishing websites in the wild capable of evading blacklisting for extended periods. We characterized typical evasion techniques used by these websites and designed experiments to empirically measure the response of blacklists to these techniques in a controlled manner. In August 2019, we identified less common (but more sophisticated) emerging evasion techniques and designed additional experiments to test these techniques. A timeline of our ecosystem analysis using PhishTime and subsequent experiment deployments is shown in Figure 2.

### Typical Evasion Techniques
We analyzed 4,393 distinct phishing URLs in the wild and found that 183 failed to be promptly blacklisted. Of these 183 websites, 96 were never blacklisted before going offline (average lifespan: 17 hours, 12 minutes), 87 were ultimately blacklisted in at least one desktop browser (average speed: 7 hours, 4 minutes), and 23 were blacklisted in at least one mobile browser (average speed: 12 hours, 2 minutes). Ten websites remained live without blacklisting for over one week. By analyzing URLs in email lures reported to PayPal, we found that 177 of these websites had lure URLs that redirected to a different final landing URL with the phishing content. We observed redirection through third-party services and attacker-controlled domains, often using JavaScript-based redirection alongside traditional HTTP redirection. At least 146 websites used some form of server-side cloaking, and 42 websites shared a domain or subdomain with another phishing website, reflecting phishers’ tendency to reuse infrastructure.

### Emerging Evasion Techniques
Eight of the 96 phishing websites that were never blacklisted implemented clever mechanisms to evade detection: five presented visitors with a CAPTCHA challenge before displaying the phishing content, two required the user to click on a button in a popup window before redirecting to the phishing page, and one would not render content before detecting mouse movement. We refer to these as behavior-based evasion techniques because they require specific user behavior to display phishing content.

### Experimental Design
We transition from observing the ecosystem to actively measuring it by replicating observed phishing website configurations across a large sample of our own artificial phishing websites. We deploy these websites, report the respective URLs to several anti-phishing entities, and monitor the speed and coverage of blacklists as they respond to our reports. We conducted our experiments ethically to avoid harming any real users or anti-phishing systems, as discussed in Section 9.2.

### Deployment Summary
In total, we made one preliminary deployment in March 2019 and six main deployments of experiments at regular intervals between May 2019 and January 2020. The purpose of the preliminary deployment was to verify the soundness of our experimental design and the technical correctness of our framework. We summarize our deployments in Table 1.

### Measuring Blacklist Speed & Coverage
These experiments focus primarily on measuring the detection performance (i.e., speed and coverage) of blacklists. As it is generally infeasible for attackers to avoid discovery in traditional phishing attacks (e.g., at scale through email spam), our reporting methodology ensures that all URLs deployed in these experiments are promptly discovered by the blacklists we test. We do so by simultaneously reporting the URLs to multiple blacklists and other anti-phishing entities, as detailed in Section 7.2.

### Experiment A: Baseline
For our simplest experiment, we launch a single batch of basic phishing websites with no evasion technique in each deployment. These, and all other websites we deploy, use HTTPS to match current ecosystem trends [2]. This experiment establishes a baseline for the best-case speed and coverage provided by blacklists and measures if these metrics remain consistent over time.

### Experiment B: Basic Evasion
In this experiment, we test two straightforward cloaking techniques inspired by our observations: websites that only allow traffic from browsers with a mobile user agent [20, 30] and websites that render content using JavaScript. We alternate these two cloaking techniques between deployments. This experiment evaluates blacklists’ response to slightly more sophisticated phishing by comparing against the baseline response in Experiment A and establishes a point of comparison for even more sophisticated phishing in later experiments. It also assesses blacklist coverage on mobile devices, as mobile devices have historically been prone to phishing [63], and recent work has revealed gaps in blacklisting on mobile devices [44].

### Experiment C: Typical Evasion (Redirection)
Each deployment in this experiment includes three batches of websites focused on evaluating the evasiveness of redirection. We pair each phishing website with a different URL that redirects to it with an HTTP 302 status code [20]. We only report the redirection URLs (i.e., the URLs that could serve as lures in a phishing email) and configure each phishing website with the same evasion technique as Experiment B in the respective deployment. In the first batch, we use a popular link shortening service, bit.ly, to generate the redirection links. In the second batch, we use our own .com domains (each different from the website’s domain) for the redirection links. In the third batch, we use .com domains for the redirection links and configure them with server-side IP and hostname cloaking [45]. This batch most closely mirrors the typical configuration of the phishing websites we observed. By changing one variable between the three batches, we can compare the blacklisting of phishing websites that combine redirection with cloaking on both the lure and the phishing website with the blacklisting of websites with lesser degrees of evasion. We can also evaluate the feasibility for attackers to use, and the ecosystem’s mitigation of, third-party redirection services.

### Experiment D: Domain Reuse
After completing each Experiment C deployment, we generate identical...