`先知安全技术社区独家发文，如需转载，请先联系社区授权；未经授权请勿转载`
> 做好基础安全运维工作
# 1\. 为什么做日志关联分析
安全团队针对安全事件的2个主要（能力）阶段：一个是发现攻击事件，另外一个是防御正在进行的攻击。首先第一个阶段，发现攻击事件，大部分安全团队从明显的被黑特征才知道自己组织的业务被攻击，来源可能几种：
  * 业务/外部通知系统不能访问或有篡改情况；
  * 上级管理单位下发的安全通告；
  * 兄弟部门（运维部门）通告。
无论那种情况对安全部门都是很糟糕的情况，安全人员有限，工作也杂也多，从单个安全设备上确认是否是有效的攻击事件几乎不可能，但是如果将攻击事件产生的日志以线性过程的方式收集呈现出来可以辅助确认真实的攻击事件。
# 2\. 怎样做日志关联分析
首先需要确定都有哪些安全事件，还是以典型业务网络为例说明。
应用服务器与数据库服务器分离，并对外提供业务服务。基本的安全防护设备都有，参考[《怎样做好基础安全设备运维》](http://www.freebuf.com/articles/es/159265.html)。  
以威胁建模和风险的评估的角度考虑业务可能遭受的入侵和风险场景（可以通过头脑风暴的形式），下面以几个典型的场景为例：
  1. 黑客发现并利用应用上传漏洞上传 Web shell 并获取应用服务器的权限，之后尝试攻击内网其他服务器。  
分析这个攻击过程，先分2种情况：安全人员知道 Web 应用的某个页面存在上传漏洞（漏洞报告获得），从 WAF 或 IDS 上检测到上传 Web shell
行为， Web 应用服务器上的主机入侵检测或 Web shell 检测也发现有恶意文件，到这里就能判断是一次正在进行的入侵事件了；如果安全人员不知道 Web
应用存在上传漏洞，从 WAF 或 IDS 上检测上传攻击事件，从 Web 服务器主机入侵检测系统上或 Web Shell
检测工具上检测到变更/篡改，或者直接检测到上传木马文件，也能确定是入侵事件。  
此次攻击过程可以在以下设备上生成相关日志：
    * Web 应用日志
    * WAF 攻击日志
    * IDS 攻击日志
    * Web 服务器主机入侵检测系统日志
    * Web 服务器用户命令历史日志
    * Web 服务器 Web shell 检测日志（如果有的话）
    * Web 程序漏洞报告
分析各个安全设备上日志的记录，如时间、源地址、源端口、目的地址、目的端口、事件类型、URL 地址，Web shell 事件，从 WAF/IDS
获取事件源IP，使用该IP在应用日志上查询是否在上传页面 POST 过数据， 检查同时间是否有主机 Web shell
告警事件，如果发生，则确认是入侵事件，立即告警安全人员进行处理。获取过程逻辑如下午所示：
  1. 黑客发现并利用应用上传漏洞上传 Web shell 并获取应用服务器的权限，之后篡改了应用服务器主页面（主要指图片或其他 HTML 静态资源）。  
这个与第一个例子基本一致，在最后一步是使用主机 IDS 检测到关键资源文件变更
  2. 黑客发现并利用应用服务器 SQLi 漏洞进行拖库。  
分析攻击过程，首先业务网站上存在 SQLi 漏洞，安全人员可能知道或不知道，入侵者攻击时会触发 IDS/WAF 日志事件，数据库审计系统检测到应用发出
WAF SQLi 告警执行的查询语句。涉及到的日志如下：
    * WAF/IDS 告警日志
    * 数据库审计系统日志
其实这种方法只能副辅助确认成功的 SQLi 注入攻击，并不能确定是否成功拖库。实际关联的是2个日志的 SQL 查询的关键词。
  3. 自动化攻击工具通过 SSH 弱口令登录内网应用服务器，下载并在受害服务器上执行挖矿程序，同时对内网其他服务器服务暴力破解攻击。  
分析攻击过程：暴力破解密码工具在主机上会产生大量登录尝试，在服务器上留下登录尝试日志，如果部署了 IDS，IDS 也会提示有暴力破解攻击。从 bash
命令历史日志里可能存在执行下载命令，运维系统检测到服务器 CPU 利用率提升。
  4. 黑客获取用户的身份凭证，并在深夜登录业务系统进行敏感业务操作（转账、支付）  
这个日志收集过程要收集业务相关的日志，如登录日志、转账日志、支付日志等，通过用户的业务使用习惯形成用户画像的一系列标签。之后定义异常行为，如异地登录，连续登录失败次数、使用代理登录、异常时间登录、大额转账、异常时间转账、转账到异常账户等行为。  
关联的日志主要是2方面：异常登录成功，之后执行异常的业务操作。再举个例子，深夜用户使用国外IP登录业务域名系统，修改的域名系统的指向记录。  
业务日志关联的难点在于历史遗留系统并没有收集业务行为的日志，2次开发也很困难，可以考虑通过基于 Nginx WAF 的形式搜集业务日志，也是比较难。
  5. 内网某个应用服务器感染病毒或木马，并向内网其他服务器发送攻击包。  
2个方面：一个是杀毒软件告警和主机异常行为关联，主机异常行为可以是新的进程、新的账户、新安装的程序、注册表的修改等；另一个是杀毒软件告警和入侵检测事件关联，入侵检测事件可能是感染病毒的主机有发攻击探测包，有扫描行为等。
  6. 应用系统遭受 CC 攻击。  
CC 攻击可以通过 WAF 或者 DDoS 防御系统检测出来，结合运维监控的检测结果，如访问变慢，连接数变多，消耗系统资源变多辅助判断。
上面只是列出几个典型的攻击场景，实际分析时可以结合自己的业务，列出将所有可能的入侵形式，之后考虑入侵过程以及入侵过程在相应设备上产生的日志，再分析日志之间的关联规则就比较简单了。
# 3\. 关于安全事件的日志收集
为确保能够做好日志的关联分析，需要使用集中化的日志系统并尽可能的收集安全设备和服务器上的所有日志，使用集中化的日志也能防止黑客入侵后，删除服务器上的相关日志导致的发现入侵症状后却没日志分析的情况。日志收集有条件可以购买
splunk ，开源的也可以使用 ELK Stack，云服务可以使用日志易，根据自己的业务规模和资源情况选用合适的产品。选择的建议：
  * 查询速度快
  * 易部署和维护
  * 易进行二次开发
收集的日志信息可以形成适合自己组织业务的威胁情报数据，如近3天的入侵源 IP 资源池，近一月的流行流行漏洞和攻击方式，代理 IP
库等等。也适用于组织其他业务的安全防御工作。另外关联分析的结果需要结合告警平台，将产生的告警事件通知到相关人员，告警可以使用短信、邮件、微信等方式，可以自建，也可以结合运维系统（如
zabbix）进行发送。也可以结合 zabbix 的事件处理程序直接对在运维平台上完成整个事件的处置。
将安全事件相关日志收集今昔收集，再用一些关联规则确定真实的攻击事件，实际就是
SIEM，将规则的提取、使用和禁用的过程做个一个生命周期的管理，结合安全事件的处置形成一套标准化的东西。
部分规则可以使用机器学习的套路，就是 NB 大数据、机器学习类解决方案了^^。
关联规则大家可以在评论中讨论。