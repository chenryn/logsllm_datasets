title:Scalable proximity estimation and link prediction in online social
networks
author:Han Hee Song and
Tae Won Cho and
Vacha Dave and
Yin Zhang and
Lili Qiu
Scalable Proximity Estimation and Link Prediction in
Online Social Networks
Han Hee Song Tae Won Cho Vacha Dave Yin Zhang
Lili Qiu
The University of Texas at Austin
{hhsong, khatz, vacha, yzhang, lili}@cs.utexas.edu
ABSTRACT
Proximity measures quantify the closeness or similarity between
nodes in a social network and form the basis of a range of appli-
cations in social sciences, business, information technology, com-
puter networks, and cyber security.
It is challenging to estimate
proximity measures in online social networks due to their massive
scale (with millions of users) and dynamic nature (with hundreds
of thousands of new nodes and millions of edges added daily). To
address this challenge, we develop two novel methods to efﬁciently
and accurately approximate a large family of proximity measures.
We also propose a novel incremental update algorithm to enable
near real-time proximity estimation in highly dynamic social net-
works. Evaluation based on a large amount of real data collected
in ﬁve popular online social networks shows that our methods are
accurate and can easily scale to networks with millions of nodes.
To demonstrate the practical values of our techniques, we con-
link pre-
sider a signiﬁcant application of proximity estimation:
diction, i.e., predicting which new edges will be added in the near
future based on past snapshots of a social network. Our results re-
veal that (i) the effectiveness of different proximity measures for
link prediction varies signiﬁcantly across different online social
networks and depends heavily on the fraction of edges contributed
by the highest degree nodes, and (ii) combining multiple proximity
measures consistently yields the best link prediction accuracy.
Categories and Subject Descriptors
H.3.5 [Information Storage and Retrieval]: Online Information
Services—Web-based services; J.4 [Computer Applications]: So-
cial and Behavioral Sciences—Sociology
General Terms
Algorithms, Human Factors, Measurement
Keywords
Social Network, Proximity Measure, Link Prediction, Embedding,
Matrix Factorization, Sketch
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’09, November 4–6, 2009, Chicago, Illinois, USA.
Copyright 2009 ACM 978-1-60558-770-7/09/11 ...$10.00.
1.
INTRODUCTION
A social network [53] is a social structure modeled as a graph,
where nodes represent people or other entities embedded in a so-
cial context, and edges represent speciﬁc types of interdependency
among entities, e.g., values, visions, ideas, ﬁnancial exchange, friend-
ship, kinship, dislike, conﬂict or trade. Understanding the nature
and evolution of social networks has important applications in a
number of ﬁelds such as sociology, anthropology, biology, eco-
nomics, information science, and computer science.
Traditionally, studies on social networks often focus on rela-
tively small social networks (e.g., [30, 31] examine co-authorship
networks with about 5000 nodes). Recently, however, social net-
works have gained tremendous popularity in the cyber space. On-
line social networks such as MySpace [40], Facebook [18] and
YouTube [55] have each attracted tens of millions of visitors ev-
ery month [44] and are now among the most popular sites on the
Web [4]. The wide variety of online social networks and the vast
amount of rich information available in these networks represent
an unprecedented research opportunity for understanding the na-
ture and evolution of social networks at massive scale.
A central concept in the computational analysis of social net-
works is proximity measure, which quantiﬁes the closeness or sim-
ilarity between nodes in a social network. Proximity measures form
the basis for a wide range of important applications in social and
natural sciences (e.g., modeling complex networks [6, 13, 25, 42]),
business (e.g., viral marketing [23], fraud detection [11]), informa-
tion technology (e.g., improving Internet search [35], collaborative
ﬁltering [7]), computer networks (e.g., constructing overlay net-
works [45]), and cyber security (e.g., mitigating email spams [22],
defending against Sybil attacks [56]).
Unfortunately, the explosive growth of online social networks
imposes signiﬁcant challenges on proximity estimation. First, on-
line social networks are typically massive in scale. For example,
MySpace has over 400 million user accounts [41], and Facebook
has reportedly over 120 million active users world wide [19]. As
a result, many proximity measures that are highly effective in rel-
atively small social networks (e.g., the classic Katz measure [26])
become computationally prohibitive in large online social networks
with millions of nodes [48]. Second, online social networks are of-
ten highly dynamic, with hundreds of thousands of new nodes and
millions of edges added daily.
In such fast-evolving social net-
works, it is challenging to compute up-to-date proximity measures
in a timely fashion.
Approach and contributions. To address the above challenges,
we develop two novel techniques, proximity sketch and proximity
embedding, for efﬁcient and accurate proximity estimation in large
social networks with millions of nodes. We then augment these
techniques with a novel incremental proximity update algorithm
to enable near real-time proximity estimation in highly dynamic
322social networks. Our techniques are applicable to a large family
of commonly used proximity measures, which includes the afore-
mentioned Katz measure [26], as well as rooted PageRank [30, 31]
and escape probability [50]. These proximity measures are known
to be highly effective for many applications [30, 31, 50], but were
previously considered computationally prohibitive for large social
networks [48, 50].
To demonstrate the practical value of our techniques, we con-
sider a signiﬁcant application of proximity estimation:
link pre-
diction, which refers to the task of predicting the edges that will
be added to a social network in the future based on past snap-
shots of the network. As shown in [30, 31], proximity measures
lie right at the heart of link prediction. Understanding which prox-
imity measures lead to the most accurate link predictions provides
valuable insights into the nature of social networks and can serve
as the basis for comparing various network evolution models (e.g.,
[6, 13, 25, 42]). Accurate link prediction also allows online social
networks to automatically make high-quality recommendations on
potential new friends, making it much easier for individual users to
expand their social neighborhood.
We evaluate the effectiveness of our proximity estimation meth-
ods using a large amount of real data collected in ﬁve popular online
social networks: Digg [14], Flickr [20], LiveJournal [33], MyS-
pace [40], and YouTube [55]. Our results show that our methods
are accurate and can easily scale to handle large social networks
with millions of nodes and hundreds of millions of edges. We also
conduct extensive experiments to compare the effectiveness of a
variety of proximity measures for link prediction in these online
social networks. Our results uncover two interesting new ﬁndings:
(i) the effectiveness of different proximity measures varies signif-
icantly across different networks and depends heavily on the frac-
tion of edges contributed by the highest degree nodes, and (ii) com-
bining multiple proximity measures using an off-the-shelf machine
learning software package consistently yields the best link predic-
tion accuracy.
Paper organization. The rest of the paper is organized as follows.
In Section 2, we develop techniques to efﬁciently and accurately
approximate a large family of proximity measures in massive, dy-
namic online social networks. In Section 3, we describe link pre-
diction techniques. In Section 4, we evaluate both proximity esti-
mation and link prediction in ﬁve popular online social networks.
In Section 5, we review related work. We conclude in Section 6.
2. SCALABLE PROXIMITY ESTIMATION
Proximity measures are the basis for many applications of so-
cial networks. As a result, a variety of proximity measures have
been proposed. The simplest proximity measures are based on ei-
ther the shortest graph distance or the maximum information ﬂow
between two nodes. One can also deﬁne proximity measures based
on node neighborhoods (e.g., the number of common neighbors).
Finally, several more sophisticated proximity measures involve in-
ﬁnite sums over the ensemble of all paths between two nodes (e.g.,
Katz measure [26], rooted PageRank [30, 31], and escape proba-
bility [50]). Compared with more direct proximity measures such
as shortest graph distances and numbers of shared neighbors, path-
ensemble based proximity measures capture more information about
the underlying social structure and have been shown to be more ef-
fective in social networks with thousands of nodes [30, 31, 50].
Despite the effectiveness of path-ensemble based proximity mea-
sures, it is computationally expensive to summarize the ensemble
of all paths between two nodes. The state of the art in estimat-
ing path-ensemble based proximity measures (e.g., [50]) typically
can only handle social networks with tens of thousands of nodes.
As a result, recent works on proximity estimation in large social
networks (e.g., [48]) either dismiss path-ensemble based proximity
measures due to their prohibitive computational cost or leave it as
future work to compare with these proximity measures.
In this section, we address the above challenge by developing
efﬁcient and accurate techniques to approximate a large family of
path-ensemble based proximity measures. Our techniques can han-
dle social networks with millions of nodes, which are several orders
of magnitude larger than what the state of the art can support. In
addition, our techniques can support near real-time proximity esti-
mation in highly dynamic social networks.
2.1 Problem Formulation
Below we ﬁrst formally deﬁne three commonly used path-ensemble
based proximity measures: (i) Katz measure, (ii) rooted PageRank,
and (iii) escape probability. We then show that all three proxim-
ity measures can be efﬁciently estimated by solving a common
subproblem, which we term the proximity inversion problem. In
all our discussions below, we model a social network as a graph
G = (V, E), where V is the set of nodes, and E is the set of edges.
G can be either undirected or directed, depending on whether the
social relationship is symmetric.
Katz measure. The Katz measure [26] is a classic path-ensemble
based proximity measure. It is designed to capture the following
simple intuition: the more paths there are between two nodes and
the shorter these paths are the stronger the relationship is (because
there are more opportunities for the two nodes to discover and in-
teract with each other in the social network). Given two nodes
x, y ∈ V , the Katz measure Katz[x, y] is a weighted sum of the
number of paths from x to y, exponentially damped by length to
count short paths more heavily. Formally, we have
Katz[x, y] =
∞
Xℓ=1
Katz · |pathshℓi
βℓ
x,y|
(1)
where pathshℓi
is a damping factor.
x,y is the set of length-ℓ paths from x to y, and βKatz
Let A be the adjacency matrix of graph G, where
A[x, y] =  1,
0,
if hx, yi ∈ E,
otherwise.
(2)
As shown in [31], the Katz measures between all pairs of nodes
(represented as a matrix Katz) can be derived as a function of the
adjacency matrix A and the damping factor βKatz as follows:
Katz =
∞
Xℓ=1
Katz Aℓ = (I − βKatz A)−1 − I
βℓ
(3)
where I is the identity matrix. Thus, in order to compute Katz, we
just need to compute the matrix inverse (I − βKatz A)−1.
Rooted PageRank. The rooted PageRank [30, 31] is a special
instance of personalized PageRank [8,12]. It deﬁnes a random walk
on the underlying graph G = (V, E) to capture the probability for
two nodes to run into each other and uses this probability as an
indicator of the node-to-node proximity. Speciﬁcally, given two
nodes x, y ∈ V , the rooted PageRank RPR[x, y] is deﬁned as the
stationary probability of y under the following random walk: (i)
with probability 1−βRPR , jump to node x, and (ii) with probability
βRPR , move to a random neighbor of current node.
The rooted PageRank between all node pairs (represented as a
matrix RPR) can be derived as follows. Let D be a diagonal ma-
trix with D[i, i] = Pj A[i, j]. Let T = D−1A be the adjacency
matrix with row sums normalized to 1. We then have:
RPR = (1 − βRPR )(I − βRPR T )−1
(4)
323Therefore, to compute RPR, we just need to compute the matrix
inverse (I − βRPR T )−1. Also note that the standard PageRank can
be computed simply as the average of all the columns of RPR.
Escape probability. The escape probability [50] is another path-
ensemble based proximity measure. Given two nodes x, y ∈ V ,
the escape probability EP[x, y] from x to y is deﬁned as the prob-
ability that a random walk which starts from node x will visit node
y before it returns to node x [16]. The escape probability EP[x, y]
can be directly derived from the rooted PageRank as follows.
EP[x, y] =
Q[x, y]
Q[x, x]Q[y, y] − Q[x, y]Q[y, x]
(5)
where matrix Q = RPR/(1 − βRPR ) = (I − βRPR T )−1.
As shown in [16], when the underlying graph G = (V, E) is
undirected, the escape probability EP is also closely related to sev-
eral other random walk induced proximity or distance measures:
effective conductance EC, effective resistance ER, and commute
time CT. Speciﬁcally, we have:
EC[x, y] = |N (x)| · EP[x, y]
ER[x, y] = 1/EC[x, y]
CT[x, y] = 2 · |E| · ER[x, y]
(6)
(7)
(8)
The common subproblem: proximity inversion. From the above
discussions, it is evident that the key to estimating all three path-
ensemble based proximity measures is to efﬁciently compute ele-
ments of the following matrix inverse:
P
△
= (I − βM )−1 =
∞
Xℓ=0
βℓM ℓ
(9)
where M is a sparse nonnegative matrix with millions of rows and
columns, I is an identity matrix of the same size, and β ≥ 0 is a
damping factor. We term this common subproblem the proximity
inversion problem.
2.2 Scalable Proximity Inversion
The key challenge in solving the proximity inversion problem
(i.e., computing elements of matrix P = (I − βM )−1) is that
while M is a sparse matrix, P is a dense matrix with millions of
rows and columns. It is thus computationally prohibitive to com-
pute and/or store the entire P matrix. To address the challenge,
we ﬁrst develop two novel dimensionality reduction techniques to
approximate elements of P = (I − βM )−1 based on a static snap-
shot of M : proximity sketch and proximity embedding. We then
develop an incremental proximity update algorithm to approximate
elements of P in an online setting when M continuously evolves.
P[x,y] is hashed into entry S  [x,g (y)] in each hash table S  (k=1, ..., H)
k
k
k
So S  [x,g (y)] gives an upper bound on P[x,y]
k
k
Estimate P[x,y] by taking the min upper bound in all H hash tables
P[x,y]
m x mP
S [x,g (y)]
k
+=P[x,y]
k
Sk
Figure 1: Proximity sketch
we ﬁrst construct an indicator row vector u such that u[i] = 1 for
∀i ∈ S and u[j] = 0 for ∀j 6∈ S. We then approximate the sum of
Similarly, to compute the sum of a subset of rows Pi∈S P [i, ∗],
rows Pi∈S P [i, ∗] = u P as:
u P = u (I − βM )−1 =
βℓu M ℓ ≈
βℓu M ℓ
(11)
ℓmax
∞
Xℓ=0
Xℓ=0
In one extreme where S contains all the column indices, we can
compute the sum of all columns in P . This is useful for computing
the PageRank (which is the average of all columns in the RPR ma-
trix). In the other extreme where S contains only one element, we
can efﬁciently approximate a single row or column of P .
Complexity. Suppose M is an m-by-m matrix with n non-zeros.
Computing the product of sparse matrix M and a dense vector v
takes O(n) time by exploiting the sparseness of M . So it takes
O(n · ℓmax) time to compute {M ℓv | ℓ = 1, . . . , ℓmax} and ap-
proximate P v. Note that the time complexity is independent of the
size of the subset S. The complexity for computing uP is identical.
Note however that the above approximation algorithm is not efﬁ-
cient for estimating individual elements of P . In particular, even if
we only want a single element P [x, y], we have to compute either a
complete row P [x, ∗] or a complete column P [∗, y] in order to ob-
tain an estimate of P [x, y]. So we only apply the above technique
for preprocessing. We will develop several techniques in the rest of
this section to estimate individual elements of P efﬁciently.
cating the inﬁnite expansion P∞
sionPℓmax
Beneﬁts of truncation. We achieve two key beneﬁts by trun-
ℓ=0 βℓM ℓ to form a ﬁnite expan-
ℓ=0 βℓM ℓ. First, we completely eliminate the inﬂuence of
paths with length above ℓmax on the resulting sums. This is desir-
able because as pointed out in [30, 31], proximity measures that are
unable to limit the inﬂuence of overly lengthy paths tend to perform
ℓ=0 βℓM ℓ is
ℓ=0 βℓM ℓ may reach inﬁnity
poorly for link prediction. Second, we ensure that Pℓmax
always ﬁnite, whereas elements of P∞
when the damping factor β is not small enough.
2.2.1 Preparation
2.2.2 Proximity Sketch
We ﬁrst present an algorithm to approximate the sum of a subset
of rows or columns of P = (I − βM )−1 efﬁciently and accurately.
We use this algorithm as a basic building block in both proximity
sketch and proximity embedding.
Algorithm. Suppose we want to compute the sum of a subset of
ﬁrst construct an indicator column vector v such that v[i] = 1
for ∀i ∈ S and v[j] = 0 for ∀j 6∈ S. The sum of columns
columns: Pi∈S P [∗, i], where S is a set of column indices. We
Pi∈S P [∗, i] is simply P v and can be approximated as:
βℓM ℓ v
P v = (I − βM )−1 v =
βℓM ℓ v ≈
(10)
ℓmax
∞
Xℓ=0
Xℓ=0
Our ﬁrst dimensionality reduction technique, proximity sketch,
exploits the mice-elephant phenomenon that frequently arises in
matrix P in practice, i.e., most elements in P are tiny (i.e., mice)
but few elements are huge (i.e., elephants).
Algorithm. Figure 1 shows the data structure for our proximity
sketch, which consists of H hash tables: S1, · · · , SH . Each Sk
is a 2-dimensional array with m rows and c ≪ m columns. A
column hash function gk : {1, · · · , m} → {1, · · · , c} is used to
hash each element in Pm×m (P [x, y]) into an element in Sk m×c
(Sk[x, gk(y)]). We ensure that different hash functions gk(·) (k =
1, · · · , H) are two-wise independent.
In each Sk, each element
P [x, y] is added to entry Sk[x, gk(y)]. Thus,
where ℓmax bounds the maximum length of the paths over which
the summation is performed.
Sk[a, b] = Xy: gk(y)=b
P [a, y]
(12)
324Note that each column of Sk: Sk[∗, b] = Py:gk(y)=b P [∗, y] can
be computed efﬁciently as described in Section 2.2.1.
Since P is a nonnegative matrix, for any x, y ∈ V and any k ∈
[1, H], Sk[x, gk(y)] is an upper bound for P [x, y] according to
Eq. 12. We can therefore estimate P [x, y] by taking the minimum
upper bound in all H hash tables in O(H) time. That is:
ˆP [x, y] = min
k
Sk[x, gk(y)]
(13)
Probabilistic accuracy guarantee. Our proximity sketch effec-
tively summarizes each row of P : P [x, ∗] using a count-min sketch
[10]: {Sk[x, ∗] | k = 1, · · · , H}. As a result, we provide the same
probabilistic accuracy guarantee as the count-min sketch, which is
summarized in the following theorem (see [10] for detailed proof).
THEOREM 1. With H = ⌈ln 1
δ ⌉ hash tables, each with c = ⌈ e
ǫ ⌉
columns, the estimate ˆP [x, y] guarantees: (i) P [x, y] ≤ ˆP [x, y];
and (ii) with probability at least 1 − δ, ˆP [x, y] ≤ P [x, y] + ǫ ·
Pz P [x, z].
Therefore, as long as P [x, y] is much larger than ǫ · Pz P [x, z],
the relative error of ˆP [x, y] is small with high probability.
Extension. If desired, we can further reduce the space requirement
of proximity sketch by aggregating the rows of Sk (at the cost of
lower accuracy). Speciﬁcally, we associate each Sk with a row hash
function fk(·). We then compute
Rk[a, b] = Xx: fk (x)=a
Sk[x, b]
(14)
and store {Rk} (instead of {Sk}) as the ﬁnal proximity sketch.
Clearly, we have Rk[a, b] = Px: fk (x)=aPy: gk (y)=b P [x, y]. For
any x, y ∈ V , we can then estimate P [x, y] as
ˆP [x, y] = min
k
Rk[fk(x), gk(y)]
(15)
2.2.3 Proximity Embedding
Our second dimensionality reduction technique, proximity em-
bedding, applies matrix factorization to approximate P as the prod-
uct of two rank-r factor matrices U and V :
Pm×m ≈ Um×r · Vr×m
(16)
In this way, with O(2 m r) total state for factor matrices U and V ,
we can approximate any P [x, y] in O(r) time as:
ˆP [x, y] =
r
Xk=1
U [x, k] · V [k, y]
(17)
Our technique is motivated by recent research on embedding net-
work distance (e.g., end-to-end round-trip time) into low-dimensional
space (e.g., [32, 34, 43, 49]). Note however that proximity is the
opposite of distance — the lower the distance the higher the prox-
imity. As a result, techniques effective for distance embedding do
not necessarily work well for proximity embedding.
Algorithm. As shown in Figure 2(a), our goal is to derive the
two rank-r factor matrices U and V based on only a subset of rows
P [L, ∗] and columns P [∗, L], where L is a set of indices (which
we term the landmark set). We achieve this goal by taking the
following ﬁve steps:
1. Randomly select a subset of ℓ nodes as the landmark set L. The
probability for a node i to be included in L is proportional to
the PageRank of node i in the underlying graph1. Note that
1We also consider uniform landmark selection, but it yields worse
accuracy than PageRank based landmark selection (see Section 4).
(a) goal: approximate P as the product of two rank−r matrices U, V
     by only computing a subset of rows P[L,*] and columns P[*,L]
P[L,L]
P[L,*]
~
~
]
*
,
L
[