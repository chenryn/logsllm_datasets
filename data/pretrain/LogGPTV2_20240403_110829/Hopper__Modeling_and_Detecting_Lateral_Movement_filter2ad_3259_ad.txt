since it makes no difference whether Hopper classiﬁes each
day’s logins individually or in one aggregate batch.
7 Evaluation
We evaluated Hopper on our 15-month data set, measuring
its detection rate (fraction of attacks detected) and the vol-
ume of false positives it generates. Our data does not contain
any known lateral movement attacks, but it does contain one
in-situ lateral movement attack conducted by Dropbox’s pro-
fessional red team. Additionally, we generated and injected
a realistic and diverse set of 326 simulated attacks into our
data for a more thorough evaluation (§ 7.2). Hopper success-
Path
Length
2
3
4
5
6
# of Paths with Potential
Credential Switch
3,357,353
829,044
128
6
4
Table 3: The volume of multi-hop paths, with a potential switch in
credentials, inferred by Hopper’s causality engine. The left column
reports the path length and the right column reports the total number
of paths with that length that Hopper generated, across our dataset.
fully detected 94.5% of the attacks in our data, including the
red team attack, while generating an average of 9 false posi-
tives per day (§ 7.3): an 8× reduction in the number of false
positives produced by prior state-of-the-art (§ 7.4).
Implementation
7.1
For our experiments, we implemented Hopper in Python 2.7
on a Linux server with 64GB of RAM and a 16-core proces-
sor. Table 3 shows the total number of multi-hop paths that
Hopper generated, based on the optimized implementation
described in our extended technical report [22]. In aggregate,
the full set of paths (containing the attributes described in
Table 2 and their feature values) consume a total of 2.5GB of
memory. Running Hopper’s path generation algorithm across
our entire data set took a total CPU time of 35 minutes and 13
seconds, and running Hopper’s feature extraction and detec-
tion algorithms on every day in our data set took a cumulative
CPU time of 83 minutes and 9 seconds.
The dramatic drop in long-length paths reﬂects the fairly
ﬂat topology of Dropbox’s network, the ﬁltering steps that
Hopper takes to remove noisy and spurious login activity
(§ 3.2), and the optimization Hopper uses of only tracking
paths with potential (or clear) credential switching. System
administrator activity predominates these multi-hop paths,
since most other users perform logins directly into their target
service (e.g., short one-hop paths).
7.2 Attack Data
Red Team Attack: Our data contains one lateral movement
attack generated by Dropbox’s professional red team. The red
team began their attack from a “compromised” employee’s
laptop (selected from a preexisting pool of volunteers).4 Their
attack simulated a common APT scenario [17, 51], where an
4The red team followed their standard safety protocols when conducting
this simulation, which included obtaining prior consent from all “compro-
mised users”, coordinating extensively with the security incident response
team, and conducting any necessary remediation that resulted from the simu-
lated attack (e.g., resetting any credentials that they accessed).
3102    30th USENIX Security Symposium
USENIX Association
attacker conducts lateral movement to access an organiza-
tion’s Domain Controllers (credential management servers).
From their initial foothold, the red team conducted a series
of reconnaissance and internal login (lateral movement) op-
erations. They identiﬁed and acquired a new, elevated set of
credentials, which they then used to access one of the organi-
zation’s Domain Controllers. Apart from requiring that their
movement occurred via logins (as opposed to exploiting a re-
mote access vulnerability), the red team performed this attack
under no constraints or input from us. We did not examine the
red team data until we had frozen the design and parameters
of our detector. The red team’s attack created an UNCLEAR
path, because the attack “stole” and used a sysadmin’s cre-
dentials from a server that had a recent inbound login by the
sysadmin. Hopper’s unclear causality detector successfully
identiﬁed this attack. Based on its anomaly score, Hopper
ranked this attack path as the most suspicious path on that day
and the 45th most suspicious path across all paths during the
month of the attack.
Realistic Attack Simulations: Dropbox employs multiple
sets of security controls and detection approaches, including
commercial security products, external security audits, and
custom tools developed by in-house security teams. Across
all of these sources, no incidents of real-world lateral move-
ment have been detected. Given the lack of real-world attack
instances, we developed an attack synthesis framework and
generated an additional 326 realistic lateral movement attacks.
Our attack framework covers a wide range of real-world at-
tacks described in public breach reports and academic sur-
veys [43], ranging from ransomware to targeted APT attacks.5
We randomly selected 50 employees in our data as starting
victims, whose machines served as “compromised” footholds
for attackers to launch their lateral movement. For each start-
ing victim, our framework synthesized twelve different attack
scenarios, corresponding to a pairing of one of three ATTACK
GOALS with one of four types of STEALTHINESS.
Given a starting victim and attack scenario, our framework
synthesizes a set of lateral movement login entries that begin
at a random date and time (when the starting victim was
still active in our data). Leveraging the global graph of all
logins in our data set, our framework simulates an attacker
who iteratively (1) accrues a set of “compromised” credentials
(the starting victim’s credentials, and after each new login, the
users who recently accessed the login’s destination machine),
and then (2) synthesizes login entries to new destinations that
the attack’s compromised credential set can access.
The three attack goals specify when an attack succeeds
(stops generating new logins) and the shape of the attack’s
movement. Modeling ransomware, an Aggressive Spread at-
tack generates new logins by iterating over its compromised
credential set and performs logins into every machine acces-
Exploratory Aggressive Targeted
38 / 40
10 / 13
*39 / 41
12 / 13
37 / 41
13 / 14
41 / 41
12 / 14
38 / 41
14 / 14
41 / 41
14 / 14
TP Rate
113 / 122
37 / 41
121 / 123
38 / 41
No stealth†
Prior Edge
Active Cred.
Combined
Detection Rate
103 / 110
107 / 110
99 / 107
309 / 327
Table 4: Summary of Hopper’s detection (true positive) rate across
the different scenarios simulated by our attack framework and the red
team attack (§ 7.2). Rows correspond to the four different stealthiness
levels and columns correspond to the three attack goals that our
framework simulated for each user. The last column and last row
report Hopper’s overall detection (TP) rate. The scenario marked
with an asterisk (TARGETED and ACTIVE CRED) includes one red
team attack, which Hopper detected. †The false negatives in the “No
stealth” row stem from inaccurate attributes in the attack logins.
sible by each credential; this attack terminates after accessing
50 machines, or once it makes a login into every machine
available to its ﬁnal credential set. An Exploratory Attack
stops generating new logins once it accesses a machine that
its initial victim did not have access to; this attack iteratively
generates new logins by randomly selecting a credential from
its compromised set and a new destination accessible to the
selected credentials. Targeted Attacks perform logins until
they access a high-value server (e.g., Domain Controllers).
These attacks generate logins by computing a shortest path to
elevated credentials that can access a high-value server, and
then compute a shortest path that uses these new credentials
to access the high-value server.
Additionally, our attack framework only produces logins
that follow the scenario’s speciﬁed stealthiness. An attack
with Prior Edge stealthiness only generates logins that tra-
verse edges that legitimate users have previously made. An
attack with Active Credential stealthiness only uses a set of
credentials in a login if the credential’s legitimate user was
recently logged into the source machine (i.e., creating lo-
gin paths with unclear causality). An attack with Combined
Stealthiness only generates logins with both of the properties
above (e.g., mimicry-style attacks). The fourth type corre-
sponds to an attacker without any stealthiness requirements.
We generated 326 successful attacks, with 205 attacks
across the three stealthier levels (Table 4); users did not al-
ways have viable attack paths, leading to less than 50 attacks
per scenario (e.g., users with limited access or who lacked
stealthy paths for a targeted attack). The red team attack cor-
responded to a Targeted Attack with Active Credential stealth-
iness; our framework can produce the same attack path if we
run it from the same starting victim with these parameters.
7.3 Results
5Our simulation code is available at https://github.com/grantho/
lateral-movement-simulator
Evaluation Procedure: We divided our data into a 2-month
training window (Jan 1 – Mar 1, 2019), which we used to
USENIX Association
30th USENIX Security Symposium    3103
bootstrap the feature extraction and scoring components of
Hopper that require historical data, and a 13-month evalua-
tion window (Mar 1, 2019 to Apr 1, 2020). Our evaluation
data contained 713,617,425 successful logins, and 2,941,173
logins after applying Hopper’s data ﬁltering steps (§ 3.1). We
ran Hopper over this evaluation data to compute its false posi-
tive rate and detection (true positive) rate. For any detection
component that required historical training data, we used a
rolling window of the preceding 30 days. For our anomaly
scoring algorithm (§ 6.2), we used a budget of 5 alerts / day,
and explore the sensitivity of this parameter below.
Attack Detection Rate (True Positives): For each of the 326
attacks synthesized by our framework, we injected the attack’s
logins into our evaluation data and ran Hopper on the day(s)
when the attack occurred. For the red team exercise, we exam-
ined the alerts that Hopper generated on the day of the attack.
We deemed Hopper successful if it generated an alert for any
attack path made by the simulated attacker or red team.
Table 4 shows that Hopper successfully detected a total
of 309 attacks (94.5%), which includes the attack performed
by Dropbox’s expert red team. Hopper detected 138 attacks
through its rule set for paths with clear credential switching
(§ 6.1). In all of these attacks, the simulated attacker either
used a new set of credentials in a login from their initial
foothold machine or from a server that the legitimate user
(of the new credentials) had not recently accessed, enabling
Hopper to identify a movement path where the attacker clearly
switched to using new credentials.
However, most (180) attacks created paths with UNCLEAR
causality, either because the attack quickly capitalized on new
credentials that were recently used on a server, or because the
attack simulated a stealthy adversary who only used new cre-
dentials from machines where the legitimate user was recently
or currently active. Detecting these paths falls to Hopper’s
anomaly scoring detector (§ 6.2). With a budget of 5 alerts
per day, Hopper successfully identiﬁed 171 of these attacks
(95%), including the red team attack.
False Negatives: Of the 18 false negatives, Hopper missed
9 attacks because of attribute errors in the login data. For
each of these 9 false negatives, the attack logins had an in-
correct client vs. server label for a machine, and/or contained
incorrect information about a machine’s owner. If we replaced
this inaccurate login information with the correct attributes
(acquired from additional, up-to-date data sources at Drop-
box), Hopper could successfully detect all 9 of these false
negatives with its clear credential switch detector. Nonethe-
less, we count these attacks as false negatives since real data
inevitably contains imprecise information. Additionally, Hop-
per failed to detect 9 stealthy attacks using a daily budget of
5 alerts. For all of these false negatives, every attack login
traversed an edge with at least three prior days where the
legitimate user had performed a login along the edge.
Figure 5: ROC Curve for Hopper’s unclear causality detector (§ 6.2)
at different budgets (1–11 daily alerts). The True Positive Rate re-
ports the fraction of (180) attacks with unclear causality that Hopper
detects. The FP Rate reports the number of false alarms divided by
the number of logins in our evaluation data (2.94M).
Figure 6: The ranking of attack paths with UNCLEAR causality,
relative to all of the login paths that occurred on the day of an attack.
Budget Sensitivity and Attack Rankings: Including the red
team attack, 180 attacks produced paths with unclear causality.
Figure 5 shows the detection performance of Hopper for these
attacks, using different daily budgets for its anomaly scoring
detector. Hopper uses this budget to build a set of the historical
alerts over the past month, and then alerts on a new path (with
unclear causality) if its score is greater than or equal to any
scores of the historical alerts (§ 6.2). If Hopper used a daily
budget of 11 alerts, it could eliminate 9 false negatives and
detect all 180 attacks with a false positive rate of 0.00076.
We also assessed the ranking of these UNCLEAR PATH
attacks relative to the benign paths in our data, based on
their anomaly scores. Figure 6 shows that Hopper ranks these
attacks as highly suspicious, with over 66% of attacks ranked
as the most suspicious path on the day each attack occurred.
False Positives: To compute Hopper’s false positive rate, we
ran Hopper on all non-synthesized logins for each day in our
evaluation data. We conservatively labeled all of the alerts
Hopper produced as false positives if they did not relate to
the red team attack.
With a daily budget of 5 alerts for its anomaly scoring
detector, Hopper’s two detection algorithms generated a total
of 3,560 false positives (FP) across the 396-day evaluation
window: an average of 9 alerts / day and a false positive rate
of 0.0012 across the 2.94M ﬁltered logins in our evaluation
data. Hopper’s rule-based detector for CLEAR paths produced
3104    30th USENIX Security Symposium
USENIX Association
0.00000.00010.00020.00030.00040.00050.00060.00070.0008False Positive Rate0.00.20.40.60.81.0True Positive Rate02468101214Attack ranking across all paths on day of attack0.00.20.40.60.81.0Cumul. fraction: attackswith unclear causalityDetector
SAL (equal FP)
SAL (equal TP)
Hopper
Detection Rate
156 / 327 (47.7%)
309 / 327 (94.5%)
309 / 327 (94.5%)
False Positives
3,556 (0.12%)
27,927 (0.94%)
3,560 (0.12%)
Table 5: Prior state-of-the-art, SAL [44], produces 8× as many FP
as Hopper to detect the same number of attacks. At a similar number
of FP’s as Hopper, SAL detects roughly half as many attacks (§ 7.4).
2,216 FP’s, and the remaining 1,344 FP’s come from Hopper’s
anomaly scoring detector. On some days, Hopper’s anomaly
scoring detector generated less than 5 alerts because (1) not
every day had 5 suspicious paths with unclear causality (e.g.,
weekends and holidays), and (2) our alert clustering resulted
in some days with fewer alerts (§ 6.2).
We identiﬁed several common reasons for many of these
false positives. Across the 2,216 false positives generated by
our CLEAR path detector, approximately 10% of these false
positives correspond to logins where a user’s laptop accesses
a particular service using a special service account. Another
41.5% correspond to machine imaging and provisioning ac-
tivity, where a sysadmin runs a script that uses their elevated
set of credentials to conﬁgure a laptop for a new owner (these
logins occurred at a remote ofﬁce that Hopper’s data clean-