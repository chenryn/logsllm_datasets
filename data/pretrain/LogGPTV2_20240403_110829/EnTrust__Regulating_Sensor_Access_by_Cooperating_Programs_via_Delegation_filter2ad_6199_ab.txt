Security Guarantee. To mitigate such attack vec-
tors, an authorization mechanism must provide the fol-
lowing guarantee, for any sensor operation to be autho-
rized, that operation must be: (1) initiated by an input
event; (2) authorized for the input event to trigger the
sensor operation; and (3) authorized for the sequence of
programs receiving the input event directly or indirectly
through IPCs leading to the program performing the sen-
sor operation. Such a guarantee ensures that any sensor
operation must be initiated by an input event, the input
event must imply authorization of the resultant sensor
operation by the requesting program, and all programs
associated with communicating the request for the sen-
sor operation must be authorized to enable the sensi-
tive data to be collected by the requesting program.
To achieve the security guarantee above, we require a
mechanism that accurately tracks the delegations lead-
ing from input events to resulting sensor operations, as
well as a mechanism to authorize sensor operations to
collect sensitive data given input events and delegations.
Regarding tracking delegations, a problem is that de-
termining whether an IPC derives from an input event
or receipt of a prior IPC depends on the data flows
produced by the program implementations in general.
Solving this problem requires data flow tracking, such
as performed by taint tracking. However, taint track-
ing has downsides that we aim to avoid. Static taint
tracking can be hard to use and be imprecise [30] and
dynamic taint tracking has non-trivial overhead [29]. In-
stead, we aim to explore solutions that ensure all sensor
operations resulting from an input event are detected
(i.e., we overapproximate flows) without heavyweight
analysis or program modifications.
Authorizing sensor operations to collect sensitive
data, given an input event and one or more delegations,
depends on determining the parties involved in the del-
egation as well as the user’s intent when generating the
event. Methods that restrict the permissions of an op-
eration to the intersection of permissions granted to the
parties involved [7], have been found to be too restric-
tive in practice. Decentralized information flow con-
trol [23, 24] (DIFC) prevents information leakage while
allowing some privileged programs to make flexible se-
curity decisions to determine when to permit communi-
cations that are normally unauthorized, which has been
applied to mobile systems [20, 13]. However, these infor-
mation flow control techniques focus on preventing the
leakage of sensitive information available to programs,
whereas the main goal here is to prevent programs from
obtaining access to sensitive information in the first
place by abusing sensor access. To address this problem
more directly, researchers have explored techniques that
enable users to express the intent of their input events
to authorize sensor operations, binding this intent to the
context in which the input event was elicited, such as
the graphical user interface (GUI) context [9, 10, 11]. In
IoT environments, researchers have similarly explored
gathering program execution context (e.g., data flows)
to enable users to authorize IoT operations more accu-
rately [16]. However, none of these techniques account
for delegations of tasks to other processes. We aim to
explore methods for eliciting user authorizations for sen-
sor operations using contextual information related to
the tracking of input events and subsequent delegations.
Further, researchers have explored learning methods
to predict permissions for sensor operation based on
prior user decisions [14, 15]. However, accurate user
decision making is vital for improving the accuracy of
these learning techniques.
3 Security Model
Trust Model – We assume that the system (e.g., Linux
kernel, operating system, system services, and device
drivers) is booted securely, runs approved code from
device vendors, and is free of malice; user-level programs
(e.g., applications) are isolated from each other via the
sandboxing mechanism using separated processes [35,
36]; and, by default, user-level programs have no direct
access to sensors due to the use of a Mandatory Access
Control (MAC) policy [37, 38] enforced from boot time.
We assume the use of trusted paths, protected by MAC,
allowing users to receive unforgeable communications
from the system, and providing unforgeable input events
to the system. Our assumptions are in line with existing
research on trusted paths and trusted user interfaces for
browsers [39], X window systems [40, 41], and mobile
operating systems [42].
Threat Model – We assume that users may install
programs from unknown sources that may be malicious,
then grant such programs access to sensors at first use.
Despite the default isolation via sandboxing, programs
may communicate via IPC mechanisms (i.e., intents or
570    28th USENIX Security Symposium
USENIX Association
Figure 2: EnTrust Authorization Method – Input events,
handoff events, and sensor operations are linked via delega-
tion graphs to compute unambiguous delegation paths for
user authorization of sensor operations.
broadcast messages). Thus, user-level programs (e.g.,
apps) may leverage such communication to exploit the
attack vectors described in Section 2. Our objective is to
provide a mechanism that helps users control how coop-
erating programs access sensors. How programs manage
and share the data collected from sensors is outside the
scope of our research. Researchers have already exam-
ined solutions to prevent data leakage based on taint
analysis [29, 30, 31, 18] and Decentralized Information
Flow Control (DIFC) [20, 23, 24, 32].
4 EnTrust Authorization Design
In this section, we describe our proposed framework,
EnTrust, designed to restrict when programs may per-
form sensor operations by requiring each sensor oper-
ation to be unambiguously associated with an input
event, even if the sensor operation is performed by
a program different from the one receiving the input
event. Figure 2 provides an overview of the EnTrust
authorization system, which consists of five steps.
In
the first three steps, EnTrust mediates and records in-
put events, inter-process communication events (hand-
off events), and sensor operation requests, respectively,
to construct a delegation graph connecting input events
to their handoff events and sensor operation requests.
In the fourth step, EnTrust uses the constructed del-
egation graph to compute an unambiguous delegation
path to a sensor operation request from its originating
input event. Unless the authorization cache contains a
user authorization for the constructed delegation path
already, the fifth step elicits an authorization from the
user for the delegation path, and caches the authoriza-
tion for later use for the same delegation path. Option-
ally, users can review their prior decisions and correct
them via an audit mechanism that logs past authorized
and denied delegation graphs.
4.1 Building Delegation Graphs
The first challenge is to link input events to all the sen-
sor operations that result from cooperating programs
processing those events and then construct delegation
graphs rooted at such input events.
Figure 3: Delegation graphs connect input events with op-
eration requests for sensors via handoff events.
First, for each input event received via a sensor s
for a program pi, EnTrust creates an input event tuple
e = (c,s, pi,t0), where c is the user interface context cap-
tured at the moment the input event occurred; s is the
sensor through which the event was generated; pi is the
program displaying its graphical user interface on the
screen and receiving the input event e; and t0 is the time
of the input event (step 1 in Figure 2). Note: EnTrust
is designed to mediate both input events coming from
input sensors (e.g., touch events on widgets rendered on
the screen) as well as voice commands captured via the
microphone. Voice commands are translated into text
by the Google Cloud Speech-to-Text service.
Second, after receiving the input event, program pi
may hand off the event to another program p j. EnTrust
mediates handoff events by intercepting spawned in-
tents and messages exchanged between programs [43]
and models them as tuples h = (pi, p j,ti), where pi is
the program delegating the input event, p j is the pro-
gram receiving the event, and ti is the time the event
delegation occurred (step 2 in Figure 2).
Third, when the program p j generates a request r for
an operation o targeting a sensor d, EnTrust models
the request as a tuple r = (p j,o,d,t j), where p j is the
program requesting the sensor operation, o is the type of
sensor operation requested, d is the destination sensor,
and t j is the time the sensor operation request occurred
(step 3 in Figure 2).
Lastly, EnTrust connects sensor operation requests to
input events via handoff events by constructing a del-
egation graph to regulate such operations, as shown in
Figure 3. A delegation graph is a graph, G = (V,E),
where the edges (u,v) ∈ E represent the flow of input
events to programs and sensors, and the vertices, v ∈ V,
represent the affected programs and sensors. Figure 3
shows a simple flow, whereby a source sensor s receives
an input event e that is delivered to a program pi, which
performs a handoff event h to a program p j that per-
forms an operation request r for a destination sensor
d. Thus, there are three types of edges:
input event
to program (user input delivery), program to program
(handoff), and program to sensor operation request (re-
quest delivery).
Upon mediation of a sensor request r, EnTrust com-
putes the associated delegation path by tracing back-
wards from the sensor request r to the original input
event e. Hence, the operation request r = (p j,o,d,t j)
above causes a delegation path: (c,s, pi,t0) → (pi, p j,ti)
→ (p j,o,d,t j) to be reported in step 4 in Figure 2.
Delegation paths are then presented to the user for au-
thorization (see Section 4.3). The identified delegation
path is shown to the user using natural language, in a
USENIX Association
28th USENIX Security Symposium    571
Figure 4: Two scenarios that create ambiguity. Multiple in-
put events or handoff events delivered to the same program.
manner similar to first-use authorizations. We assess
how effectively users utilize delegation paths to produce
authorizations in a laboratory study in Section 6.2.
4.2 Computing Delegation Paths
Critical to computing delegation paths is the ability for
EnTrust to find an unambiguous reverse path from the
sensor operation request r back to an input event e. In
particular, a delegation path is said to be unambiguous
if and only if, given an operation request r by a program
p j for a sensor d, either there was a single input event
e for program p j that preceded the request r, or there
was a single path pi → p j in the delegation graph, where
program pi received a single input event e.
To ensure unambiguous delegation paths without pro-
gram modification, we need to define the conditions un-
der which operations that create ambiguities cannot oc-
cur. First, ambiguity occurs if the same program pi re-
ceives multiple input events and then performs a hand-
off, as depicted by the left side of Figure 4. In this case,
it is unclear which one of the input events resulted in the
handoff. To prevent this ambiguous case, we leverage
the insight that input events are relatively infrequent,
processed much more quickly than users can generate
them, and have a higher priority than other processing.
We observe that the time between distinct input events
is much larger than the time needed to produce the op-
eration request corresponding to the first input event. If
every input event results in an operation request before
the user can even produce another distinct input event,
then there will be only one input event (edge) e from a
source sensor (node) s to program (node) pi, which re-
ceived such input event. Therefore, there will be no am-
biguous input event for program pi. Thus, we propose
to set a time limit for each input event, such that the
difference between the time t0 at which an input event e
is generated and the time t j for any sensor operation re-
quest r – based on that input event – must be below that
limit for the event to be processed. Note that, once an
input event is authorized (Section 4.3), repeated input
events (e.g., pressing down a button multiple times) are
not delayed. Indeed, repeated input events are expected
to generate the same delegation path. Should the pro-
grams produce a different delegation path - in the mid-
dle of a sequence of operations spawned in this manner
- then EnTrust would require a new authorization for
the new delegation path, as described in Section 4.3.
Second, ambiguity is also possible if the same program
p j receives multiple handoff events before performing a
sensor operation request, as depicted by the right side
Figure 5: A program pk attempts leveraging the input event
received from program pi to get program p j to generate an
operation request.
of Figure 4. Note that, handoff events may not be re-
lated to input events (e.g., intents not derived from in-
put events). In this case, it is unclear which handoff is
associated with a subsequent sensor operation request.
Ambiguity prevention for handoff events is more subtle,
but builds on the approach used to prevent ambigu-
ity for input events. Figure 5 shows the key challenge.
Suppose a malicious program pk tries to “steal” a user
authorization for a program p j to perform a sensor op-
eration by submitting a handoff event that will be pro-
cessed concurrently to the handoff event from another
program pi, which received an input event. Should a
sensor operation request occur, EnTrust cannot deter-
mine whether the sensor operation request from p j was
generated in response to the event handoff h1 or to the
event handoff h2. So EnTrust cannot determine the del-
egation path unambiguously to authorize the operation
request.
If EnTrust knows the mapping between ac-
tions associated to handoff events and whether they are
linked to sensor operations, EnTrust can block a hand-
off from pk that states an action that requires an input
event. EnTrust knows this mapping for system services,
by having visibility of all inter-procedural calls for pro-
grams part of the operating system; however, EnTrust
may not know such mapping for third-party apps whose
inter-procedural control flow is not mediated to favor
backward compatibility with existing apps.
Thus, we extend the defense for input events to pre-
vent ambiguity as follows: once the target program has
begun processing a handoff associated with an input
event, EnTrust delays the delivery of subsequent hand-
off events until this processing completes or until the
assigned time limit ends. Conceptually, this approach
is analogous to placing a readers-writers lock [44] over
programs that may receive handoffs that result from in-
put events. Note that, the use of time limits ensures no
deadlock since it ensures preemption. To avoid starving
input events (e.g., delaying them until the time limit),
we prioritize delivery of handoffs that derive from in-
put events ahead of other handoffs using a simple, two-
level scheduling approach. We assess the impact of the
proposed ambiguity prevention mechanisms on existing
programs’ functionality and performance in Section 7.
4.3 Authorizing Delegation Paths
For controlling when a sensor operation may be per-
formed as the result of an input event, users are in the
best position to judge the intent of their actions. This is
572    28th USENIX Security Symposium
USENIX Association
inline with prior work advocating that it is highly desir-
able to put the user in context when making permission
granting decisions at runtime [16, 33, 17]. Therefore,
users must be the parties to make the final authoriza-
tion decisions. To achieve this objective, EnTrust elicits
an explicit user authorization every time that a new del-
egation path is constructed (step 5 in Figure 2). Hence,
to express a delegation path comprehensively, EnTrust
builds an authorization request that specifies that dele-
gation path to the user. Prior work presented users with
information about the Graphical User Interface (GUI)
used to elicit the input event, including GUI compo-
nents [9, 10, 11], user interface workflows [13], and Ap-
plication Programming Interface (API) calls made by
applications [11, 16]. EnTrust, instead, presents the
delegation path that led to the sensor operation, which
includes the GUI context (c in the input event) and the
handoffs and sensor operations. As a result, EnTrust
ensures that all the programs receiving sensor data are
clearly identified and reported in the authorization re-
quest presented to the user, along with the input event,
handoff events, and the resulting sensor operation.
To reduce users’ authorization effort, EnTrust caches
authorized delegation paths for reuse. After storing an
authorized delegation path, EnTrust proceeds in allow-
ing the authorized sensor operation. For subsequent
instances of the same input event that results in exactly
the same delegation path, EnTrust omits step 5 and
automatically authorizes the sensor operation by lever-
aging the cached authorization. Note that, EnTrust
requires an explicit user’s authorization only the first
time a delegation path is constructed for a specific in-
put event, similarly to the first-use permission approach.
As long as the program receiving an input event does
not change the way it processes that event (i.e., same
handoffs and operation request), no further user autho-
rization will be necessary. In Section 6.2, we show that
such an approach does not prohibitively increase the
number of access control decisions that users have to
make, thus avoiding decision fatigue [45].
Further, EnTrust evicts cached authorizations in two
scenarios. First, if a new delegation path is identified
for an input event that already has a cached delegation
path, then EnTrust evicts the cached authorization and
requires a new user authorization for the newly con-
structed delegation path, before associating it to such
an input event and caching it. Second, users can lever-
age an audit mechanism, similar to proposals in related
work [11, 15], to review previous authorizations and
correct them if needed. Denied authorizations are also
logged for two reasons. First, they allow users to have
a complete view of their past decisions; but more im-
portantly, they allow EnTrust to prevent malicious pro-
grams from annoying users by generating authorization
requests over a give threshold, for operations already
denied by the user in the past. Also, users may set
the lifetime of cached authorizations, after which they