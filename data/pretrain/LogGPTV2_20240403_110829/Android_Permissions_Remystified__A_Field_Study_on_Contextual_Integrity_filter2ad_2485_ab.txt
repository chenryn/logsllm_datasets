ADD VOICEMAIL
READ SMS
SEND SMS
Activity
Change application sync settings
when the user is roaming
View nearby SSIDs
Access Internet when roaming
Communicate via NFC
Read users’ browser history
Read GPS location
Read network-inferred location
(i.e., cell tower and/or WiFi)
Directly access GPS data
Read call history
Read call history
Read sent/received/draft SMS
Send SMS
Table 1: The 12 permissions that Felt et al. recommend
be granted via runtime dialogs [14]. We randomly took
screenshots when these permissions were requested by
applications, and we asked about them in our exit survey.
3.2 Recruitment
We placed an online recruitment advertisement on
Craigslist in October of 2014, under the “et cetera jobs”
section.1 The title of the advertisement was “Research
Study on Android Smartphones,” and it stated that the
study was about how people interact with their smart-
phones. We made no mention of security or privacy.
Those interested in participating were directed to an on-
line consent form. Upon agreeing to the consent form,
potential participants were directed to a screening appli-
cation in the Google Play store. The screening applica-
tion asked for information about each potential partici-
pant’s age, gender, smartphone make and model. It also
collected data on their phones’ internal memory size and
the installed applications. We screened out applicants
who were under 18 years of age or used providers other
than T-Mobile, since our experimental phones could not
attain 3G speeds on other providers. We collected data on
participants’ installed applications so that we could pre-
install free applications prior to them visiting our labo-
ratory. (We copied paid applications from their phones,
since we could not download those ahead of time.)
We contacted participants who met our screening re-
quirements to schedule a time to do the initial setup.
Overall, 48 people showed up to our laboratory, and of
those, 40 qualiﬁed (8 were rejected because our screen-
ing application did not distinguish some Metro PCS users
1Approved by the UC Berkeley IRB under protocol #2013-02-4992
502  24th USENIX Security Symposium 
USENIX Association
4
cations, and we instructed them to use these phones as
they would their normal phones. Our logging framework
kept track of every protected resource accessed by a user-
level application along with the previously-mentioned
contextual data. Due to storage constraints on the de-
vices, our software uploaded log ﬁles to our server every
two hours. However, to preserve participants’ privacy,
screenshots remained on the phones during the course
of the week. At the end of the week, each participant
returned to our laboratory, completed an exit survey, re-
turned the phone, and then received an additional $100
gift card (i.e., slightly more than the value of the phone).
3.3 Exit Survey
When participants returned to our laboratory, they com-
pleted an exit survey. The exit survey software ran on
a laptop in a private room so that it could ask questions
about what they were doing on their phones during the
course of the week without raising privacy concerns. We
did not view their screenshots until participants gave us
permission. The survey had three components:
• Screenshots—Our software displayed a screenshot
taken after one of the 12 resources in Table 1 was
accessed. Next to the screenshot (Figure 2a), we
asked participants what they were doing on the
phone when the screenshot was taken (open-ended).
We also asked them to indicate which of several ac-
tions they believed the application was performing,
chosen from a multiple-choice list of permissions
presented in plain language (e.g., “reading browser
history,” “sending a SMS,” etc.). After answering
these questions, they proceeded to a second page of
questions (Figure 2b). We informed participants at
the top of this page of the resource that the appli-
cation had accessed when the screenshot was taken,
and asked them to indicate how much they expected
this (5-point Likert scale). Next, we asked, “if you
were given the choice, would you have prevented
the app from accessing this data,” and to explain
why or why not. Finally, we asked for permis-
sion to view the screenshot. This phase of the exit
survey was repeated for 10-15 different screenshots
per participant, based on the number of screenshots
saved by our reservoir sampling algorithm.
• Locked Screens—The second part of our survey
involved questions about the same protected re-
sources, though accessed while device screens were
off (i.e., participants were not using their phones).
Because there were no contextual cues (i.e., screen-
shots), we outright told participants which appli-
cations were accessing which resources and asked
them multiple choice questions about whether they
wanted to prevent this and the degree to which these
Name
Type
Permission
App Name
Timestamp
API Function
Visibility
Screen Status
Connectivity
Location
View
History
(a) Screenshot
Log Data
API FUNC
ACCESS WIFI STATE
com.spotify.music
1412888326273
getScanResults()
FALSE
SCREEN ON
NOT CONNECTED
Lat
-122.XXX -
1412538686641 (Time it was updated)
com.mobilityware.solitaire/.Solitaire
com.android.phone/.InCallScreen
com.android.launcher/com.android.-
launcher2.Launcher
com.android.mms/ConversationList
37.XXX Long
(b) Corresponding log entry
Figure 1: Screenshot (a) and corresponding log entry (b)
captured during the experiment.
from T-Mobile users). In the email, we noted that due
to the space constraints of our experimental phones, we
might not be able to install all the applications on their
existing phones, and therefore they needed to make a
note of the ones that they planned to use that week. The
initial setup took roughly 30 minutes and involved trans-
ferring their SIM cards, helping them set up their Google
and other accounts, and making sure they had all the ap-
plications they needed. We compensated each participant
with a $35 gift card for showing up at the setup session.
Out of 40 people who were given phones, 2 did not re-
turn them, and 2 did not regularly use them during the
study period. Of our 36 remaining participants who used
the phones regularly, 19 were male and 17 were female;
ages ranged from 20 to 63 years old (µ = 32, σ= 11).
After the initial setup session, participants used the ex-
perimental phones for one week in lieu of their normal
phones. They were allowed to install and uninstall appli-
USENIX Association  
24th USENIX Security Symposium  503
5
Three researchers independently coded 423 responses to
the open-ended question in the screenshot portion of the
survey. The number of responses per participant varied,
as they were randomly selected based on the number of
screenshots taken: participants who used their phones
more heavily had more screenshots, and thus answered
more questions. Prior to meeting to achieve consensus,
the three coders disagreed on 42 responses, which re-
sulted in an inter-rater agreement of 90%. Taking into
account the 9 possible codings for each response, Fleiss’
kappa yielded 0.61, indicating substantial agreement.
4 Application Behaviors
Over the week-long period, we logged 27M application
requests to protected resources governed by Android per-
missions. This translates to over 100,000 requests per
user/day. In this section, we quantify the circumstances
under which these resources were accessed. We focus on
the rate at which resources were accessed when partici-
pants were not actively using those applications (i.e., sit-
uations likely to defy users’ expectations), access to cer-
tain resources with particularly high frequency, and the
impact of replacing certain requests with runtime conﬁr-
mation dialogs (as per Felt et al.’s suggestion [14]).
Invisible Permission Requests
4.1
In many cases, it is entirely expected that an applica-
tion might make frequent requests to resources protected
by permissions. For instance, the INTERNET permis-
sion is used every time an application needs to open a
socket, ACCESS FINE LOCATION is used every time
the user’s location is checked by a mapping application,
and so on. However, in these cases, one expects users to
have certain contextual cues to help them understand that
these applications are running and making these requests.
Based on our log data, most requests occurred while par-
ticipants were not actually interacting with those appli-
cations, nor did they have any cues to indicate that the
applications were even running. When resources are ac-
cessed, applications can be in ﬁve different states, with
regard to their visibility to users:
1. Visible foreground application (12.04%): the user
is using the application requesting the resource.
2. Invisible background application (0.70%): due to
multitasking, the application is in the background.
3. Visible background service (12.86%): the appli-
cation is a background service, but the user may be
aware of its presence due to other cues (e.g., it is
playing music or is present in the notiﬁcation bar).
4. Invisible background service (14.40%): the appli-
cation is a background service without visibility.
5. Screen off (60.00%):
the application is running,
but the phone screen is off because it is not in use.
(a) On the ﬁrst screen, participants answered questions to estab-
lish awareness of the permission request based on the screenshot.
(b) On the second screen, they saw the resource accessed, stated
whether it was expected, and whether it should have been blocked.
Figure 2: Exit Survey Interface
behaviors were expected. They answered these
questions for up to 10 requests, similarly chosen by
our reservoir sampling algorithm to yield a breadth
of application/permission combinations.
• Personal Privacy Preferences—Finally, in order
to correlate survey responses with privacy prefer-
ences, participants completed two privacy scales.
Because of the numerous reliability problems with
the Westin index [45], we computed the average
of both Buchanan et al.’s Privacy Concerns Scale
(PCS) [10] and Malhotra et al.’s Internet Users’ In-
formation Privacy Concerns (IUIPC) scale [31].
After participants completed the exit survey, we re-
entered the room, answered any remaining questions,
and then assisted them in transferring their SIM cards
back into their personal phones. Finally, we compen-
sated each participant with a $100 gift card.
504  24th USENIX Security Symposium 
USENIX Association
6
Permission
ACCESS NETWORK STATE
WAKE LOCK
ACCESS FINE LOCATION
GET ACCOUNTS
ACCESS WIFI STATE
UPDATE DEVICE STATS
ACCESS COARSE LOCATION
AUTHENTICATE ACCOUNTS
READ SYNC SETTINGS
INTERNET
Requests
31,206
23,816
5,652
3,411
1,826
1,426
1,277
644
426
416
Application
Facebook
Google Location Reporting
Facebook Messenger
Taptu DJ
Google Maps
Google Gapps
Foursquare
Yahoo Weather
Devexpert Weather
Tile Game(Umoni)
Requests
36,346
31,747
22,008
10,662
5,483
4,472
3,527
2,659
2,567
2,239
Table 2: The most frequently requested permissions by
applications with zero visibility to the user.
Table 3: The applications making the most permission
requests while running invisibly to the user.
Combining the 3.3M (12.04% of 27M) requests that were
granted when the user was actively using the application
(Category 1) with the 3.5M (12.86% of 27M) requests
that were granted when the user had other contextual
cues to indicate that the application was running (Cat-
egory 3), we can see that fewer than one quarter of all
permission requests (24.90% of 27M) occurred when the
user had clear indications that those applications were
running. This suggests that during the vast majority of
the time, access to protected resources occurs opaquely
to users. We focus on these 20.3M “invisible” requests
(75.10% of 27M) in the remainder of this subsection.
Harbach et al. found that users’ phone screens are off
94% of the time on average [22]. We observed that
60% of permission requests occurred while participants’
phone screens were off, which suggests that permission
requests occurred less frequently than when participants
were using their phones. At the same time, certain appli-
cations made more requests when participants were not
using their phones: “Brave Frontier Service,” “Microsoft
Sky Drive,” and “Tile game by UMoni.” Our study col-
lected data on over 300 applications, and therefore it is
possible that with a larger sample size, we would ob-
serve other applications engaging in this behavior. All of
the aforementioned applications primarily requested AC-
CESS WIFI STATE and INTERNET. While a deﬁnitive
explanation for this behavior requires examining source
code or the call stacks of these applications, we hypothe-
size that they were continuously updating local data from
remote servers. For instance, Sky Drive may have been
updating documents, whereas the other two applications
may have been checking the status of multiplayer games.
Table 2 shows the most frequently requested permis-
sions from applications running invisibly to the user (i.e.,
Categories 2, 4, and 5); Table 3 shows the applica-
tions responsible for these requests (Appendix A lists
the permissions requested by these applications). We
normalized the numbers to show requests per user/day.
ACCESS NETWORK STATE was most frequently re-
quested, averaging 31,206 times per user/day—roughly
once every 3 seconds. This is due to applications con-
stantly checking for Internet connectivity. However, the
5,562 requests/day to ACCESS FINE LOCATION and
1,277 requests/day to ACCESS COARSE LOCATION
are more concerning, as this could enable detailed track-
ing of the user’s movement throughout the day. Sim-
ilarly, a user’s location can be inferred by using AC-
CESS WIFI STATE to get data on nearby WiFi SSIDs.
Contextual integrity means ensuring that information
ﬂows are appropriate, as determined by the user. Thus,
users need the ability to see information ﬂows. Current
mobile platforms have done some work to let the user
know about location tracking. For instance, recent ver-
sions of Android allow users to see which applications
have used location data recently. While attribution is a
positive step towards contextual integrity, attribution is
most beneﬁcial for actions that are reversible, whereas
the disclosure of location information is not something
that can be undone [14]. We observed that fewer than
1% of location requests were made when the applica-
tions were visible to the user or resulted in the display-
ing of a GPS notiﬁcation icon. Given that Thompson et
al. showed that most users do not understand that appli-
cations running in the background may have the same
abilities as applications running in the foreground [42],
it is likely that in the vast majority of cases, users do not
know when their locations are being disclosed.
This low visibility rate is because Android only shows a
notiﬁcation icon when the GPS sensor is accessed, while
offering alternative ways of inferring location. In 66.1%
of applications’ location requests, they directly queried
the TelephonyManager, which can be used to deter-
mine location via cellular tower information. In 33.3%
of the cases, applications requested the SSIDs of nearby
WiFi networks. In the remaining 0.6% of cases, applica-
USENIX Association  
24th USENIX Security Symposium  505
7
tions accessed location information using one of three
built-in location providers: GPS, network, or passive.
Applications accessed the GPS location provider only
6% of the time (which displayed a GPS notiﬁcation).
In the other 94% of the time, 13% queried the network
provider (i.e., approximate location based on nearby cel-
lular towers and WiFi SSIDs) and 81% queried the pas-
sive location provider. The passive location provider
caches prior requests made to either the GPS or network
providers. Thus, across all requests for location data, the
GPS notiﬁcation icon appeared 0.04% of the time.
While the alternatives to querying the GPS are less ac-
curate, users are still surprised by their accuracy [17].
This suggests a serious violation of contextual integrity,
since users likely have no idea their locations are being
requested in the vast majority of cases. Thus, runtime no-
tiﬁcations for location tracking need to be improved [18].
Apart from these invisible location requests, we also ob-