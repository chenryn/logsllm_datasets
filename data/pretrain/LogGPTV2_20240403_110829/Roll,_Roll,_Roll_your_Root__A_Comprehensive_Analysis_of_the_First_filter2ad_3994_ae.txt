### Rollover, Identified in the 2016 Rollover Design Team Report

The 2016 Rollover Design Team report [2] identified an increase in the size of the DNSKEY Resource Record Set (RRset) as a significant concern. This increase was particularly notable during the revocation and removal process, as detailed in Section 2.2.1.

### DNSKEY RRset Size and Resolver Behavior

When the KSK-2010 key was revoked, the size of the DNSKEY RRset reached its maximum value of 1,425 bytes. We analyzed whether this increase hindered resolvers from fetching the record set and causing validation errors. Although there were other moments during the rollover when the response size was significantly higher than usual, we focused on the revocation event because it represented the maximum size.

#### Fallback to TCP

The first sign we expected to see if resolvers experienced problems was an increase in fallback to TCP. We studied the RSSAC002 data concerning traffic types but found no evidence of such an increase during the revocation. However, this data does not contain information on individual query types such as DNSKEY. If resolvers are unable to fall back to TCP, they may become unable to fetch the DNSKEY RRset altogether.

#### RIPE Atlas Measurements

We used measurements from RIPE Atlas to detect whether any vantage points were unable to retrieve the DNSKEY RRset from the root after the increase in size. Resolvers were marked as unable to retrieve the DNSKEY RRset if they could not fetch the RRset within 5 seconds.

Out of 17,925 vantage points, 1,975 (11%) were able to fetch the DNSKEY RRset before revocation but failed to fetch it at least once 48 hours after the revocation. Only 67 of these (0.4%) never managed to fetch the key set after the revocation. Even though the IPv6 minimum MTU is 1,280 bytes, vantage points that contacted resolvers via IPv6 did not fail more often than those using IPv4. We also found no resolvers that turned bogus after the revocation. This leads us to conclude that the increased response size during revocation only caused problems for a few resolvers and did not impact validators, which was also expected by the KSK rollover design team [2].

### The Return of KSK-2010

We end this section with a surprising comeback. As mentioned in Section 4.3.1, the number of resolvers signaling support for KSK-2010 has been on the rise since its removal from the root zone DNSKEY RRset. This increase is also visible in the RFC 8145 signals sent to root servers. By the end of July 2019, almost 39% of signalers again reported having KSK-2010 in their trust anchor set. This raises the question of why a retired trust anchor is making a comeback.

While it is impossible to attribute the observed rise to a single source, we have convincing evidence of the most likely cause: DNS resolver software shipping with built-in or pre-configured trust anchors.

#### Ubuntu and Unbound

First, we note that the current long-term supported version of Ubuntu (18.04 LTS) ships with Unbound version 1.6.7, which supports RFC 8145. In addition, Ubuntu includes a pre-configured trust anchor package that includes both KSK-2010 and KSK-2017. Upon startup, Unbound loads both trust anchors, marks KSK-2010 as "missing," but as the trust anchor is still configured, Unbound signals its presence in its RFC 8145 telemetry. Any installation of Ubuntu 18.04 LTS with Unbound that was running for at least 30 days when KSK-2010 was published as revoked would have cleaned up the old trust anchor. However, any installation (or re-installation) after February 20, 2019, could not complete the RFC 5011 revocation and retained KSK-2010 as a trust anchor.

#### BIND on Ubuntu

We also verified the behavior of another popular open-source DNS resolver implementation on the same OS. Ubuntu 18.04 LTS ships with BIND version 9.11.3, which includes both KSK-2010 and KSK-2017 as built-in trust anchors. By default, the Ubuntu package for BIND is configured to perform DNSSEC validation using the built-in trust anchors. Upon startup, if BIND does not find a configured trust anchor in the DNSKEY RRset returned by the root servers, it will not signal this trust anchor in its RFC 8145 telemetry. However, this does not mean the trust anchor is removed. We verified that BIND retains KSK-2010 in its trust anchor file on disk, so if the key were ever to return in the root DNSKEY RRset, we expect BIND to accept it as a valid trust anchor again.

### Second Example: Verisign's Public DNS Service

As mentioned previously, Fig. 12 shows an increase in KSK-2010 beginning in the middle of June 2019 from a single network, AS7342, which is the origin AS for Verisign’s public DNS service. The rise in KSK-2010 signalers corresponds to an upgrade of the software used on the public DNS resolver. The newly deployed version supports the Root Sentinel (RFC 8509) and is packaged with a configuration that includes both KSK-2010 and KSK-2017 as trust anchors.

### Key Takeaways After the Roll

The biggest problem during the whole process, arguably, occurred after the roll with the significant increase in DNSKEY queries. This problem was not foreseen in the design report [2], underlining the importance of independent studies of such major events on the Internet and confirming the need for meaningful telemetry. Additionally, it is clear that trust anchor management is complex and that shipping trust anchors with software has long-lasting effects.

### Related Work

As discussed in the introduction, the root DNSSEC KSK rollover is a first-of-its-kind event. Our discussion of related work focuses on earlier studies that have looked at the operation of the DNS root server system and the impact of DNSSEC on the performance of DNS resolvers.

#### Early Studies

The earliest work to study DNS traffic to root servers by Danzig et al. [42] dates back to 1992, five years after DNS was adopted as the Internet’s naming system [43]. This study illustrates that software bugs causing excessive traffic are a problem of all ages. In 2001, Brownlee et al. [44] studied almost two weeks of traffic to F Root and found a surprising amount of problematic traffic, with 14% of queries consisting of malformed address (A) queries. In 2003, Wessels et al. [45] studied 24 hours of F Root traffic and concluded that 98% of queries were malformed or unnecessary. Since 2006, DNS-OARC has collected Day-in-the-Life (DITL) datasets [18], which typically include traffic to most root servers. In 2008, Castro et al. [19] analyzed three years of DITL data and found that 98% of queries were unnecessary.

#### Operational Changes

Apart from studying traffic at the root, past work has also looked at operational changes to the root system. A particularly impactful event is the change of the IP address of a root server. Lentz et al. [46] studied one such change for D Root in 2013 and concluded that such address changes take a long time to propagate to the global resolver population, with the old address still seeing significant amounts of traffic months after the change. Wessels et al. [47] showed how the aftereffects of an address change linger, finding that the old IP address for J Root still receives on average 400 queries per second from some 130,000 sources thirteen years after the address change.

### Discussion and Recommendations

#### Improving Telemetry

A key challenge faced during the KSK rollover was sparse and distorted telemetry from resolvers. Ideally, those responsible for the rollover would want to know both the exact state of resolvers (in terms of DNSSEC validation) and how important these resolvers are (in terms of the number of clients relying on them). This provides actionable intelligence that allows prioritization of "important" resolvers (serving millions of users).

Table 7 summarizes the supported features of existing telemetry protocols:

| **Feature** | **RFC 8145** | **RFC 8509** |
|-------------|--------------|--------------|
| **Automatic** | Yes | Requires query |
| **All configured** | Yes | Only those queried |
| **Passive** | Yes | Active |
| **Vulnerable to manipulation** | Yes | Only to on-path attackers |

Clearly, during the root KSK rollover, such comprehensive telemetry was not available. While RFC 8145 saw significant deployment before the rollover, it was difficult to interpret its signals. This was mostly due to four reasons: first, RFC 8145 only allows for passive observations by root DNS operators, making it impossible to query resolvers for further state information. Second, there is no telemetry on the query volume a resolver processes, making it hard to judge how relevant or risky a resolver with problems is. Third, RFC 8145 may propagate through upstream systems (NATs, DNS forwarders, caches, and other middle-boxes), leading to distorted signals and hiding systems with actual problems. Fourth, although we have not seen any evidence of tampering, an attacker could artificially inflate the number of resolvers that have not acquired the new key by spoofing RFC 8145 telemetry signals.

#### The Root Sentinel (RFC 8509)

The Root Sentinel (RFC 8509) addresses the first limitation of RFC 8145 by using active measurements from the client perspective to establish the DNSSEC trust anchors configured on a resolver. While standardized too late to be of use during the current rollover, our analysis shows that RFC 8509 is seeing rapid deployment and provides useful signals as of September 13th, 2019. Nevertheless, RFC 8509 also suffers from the second and third limitations discussed for RFC 8145, albeit with different signal distortion (e.g., assuming a Root Sentinel query is sent to resolvers at a large ISP while it is actually handled by a local forwarder).

Based on our analysis of the current rollover, we recommend exploring incremental improvements to both RFC 8145 and RFC 8509. The quality of such signaling would be greatly improved if it were possible to identify true signal sources, identify cases where signals are forwarded, and estimate the number of users being serviced. We recognize that there are serious concerns around such detailed signaling. Weighing the tradeoffs requires further thought and debate in the community.

#### Extended Error Codes

Another issue compounding the difficulties of interpreting resolver validation problems is the ambiguity of the SERVFAIL error code validators send upon failure. Effectively, only by combining results from different measurements (cf. Table 2) can we be reasonably confident that a resolver has issues with DNSSEC validation. We therefore strongly support a draft under review in the IETF that proposes to send extended error codes for DNSSEC failures [54].

### Introducing a Standby Key

There is an ongoing debate in the DNS community about introducing a KSK standby key in the root zone by default [55]. Because the rollover was postponed by a year, this has already been tested for a single standby key without leading to issues with, e.g., response sizes. We therefore think it safe to introduce such a standby key as multiple community members have suggested. An immediate benefit of this is that resolvers are much more likely to pick up the new key if it is pre-published for a longer period. Given the rollover policy of the root [1], such a standby key could even be published years in advance.

### Trust Anchor Distribution

The 2018 KSK rollover was the first time a large population of DNSSEC validators needed to update their trust anchor. At the start of the process, the design team expected RFC 5011 to be the main means through which validators keep their trust anchors up to date [2]. Our observations suggest that where RFC 5011 was used, it generally worked as intended. In the few instances where problems did occur, this was either due to misconfigurations or incomplete implementations.