title:MOPT: Optimized Mutation Scheduling for Fuzzers
author:Chenyang Lyu and
Shouling Ji and
Chao Zhang and
Yuwei Li and
Wei-Han Lee and
Yu Song and
Raheem Beyah
MOpt: Optimized Mutation Scheduling for Fuzzers
Chenyang Lyu, Zhejiang University; Shouling Ji, Zhejiang University & Alibaba-Zhejiang 
University Joint Research Institute of Frontier Technologies; Chao Zhang, BNRist & INSC, 
Tsinghua University; Yuwei Li, Zhejiang University; Wei-Han Lee, IBM Research; Yu Song, 
Zhejiang University; Raheem Beyah, Georgia Institute of Technology
https://www.usenix.org/conference/usenixsecurity19/presentation/lyu
This paper is included in the Proceedings of the 28th USENIX Security Symposium.August 14–16, 2019 • Santa Clara, CA, USA978-1-939133-06-9Open access to the Proceedings of the 28th USENIX Security Symposium is sponsored by USENIX.MOPT: Optimized Mutation Scheduling for Fuzzers
Chenyang Lyu†, Shouling Ji†, +, ((cid:2)), Chao Zhang¶, ((cid:2)), Yuwei Li†, Wei-Han Lee§, Yu Song†, and Raheem
Beyah‡
†Zhejiang University, +Alibaba-Zhejiang University Joint Research Institute of Frontier Technologies,
¶BNRist & INSC, Tsinghua University, §IBM Research, ‡Georgia Institute of Technology
E-mails: PI:EMAIL, PI:EMAIL,
PI:EMAIL,
PI:EMAIL,
PI:EMAIL, PI:EMAIL,
rbeyah@ece.gatech.edu.
Abstract
Mutation-based fuzzing is one of the most popular vul-
nerability discovery solutions. Its performance of generat-
ing interesting test cases highly depends on the mutation
scheduling strategies. However, existing fuzzers usually
follow a speciﬁc distribution to select mutation operators,
which is inefﬁcient in ﬁnding vulnerabilities on general pro-
grams. Thus, in this paper, we present a novel mutation
scheduling scheme MOPT, which enables mutation-based
fuzzers to discover vulnerabilities more efﬁciently. MOPT
utilizes a customized Particle Swarm Optimization (PSO)
algorithm to ﬁnd the optimal selection probability distribu-
tion of operators with respect to fuzzing effectiveness, and
provides a pacemaker fuzzing mode to accelerate the con-
vergence speed of PSO. We applied MOPT to the state-
of-the-art fuzzers AFL, AFLFast and VUzzer, and imple-
mented MOPT-AFL, -AFLFast and -VUzzer respectively,
and then evaluated them on 13 real world open-source pro-
grams. The results showed that, MOPT-AFL could ﬁnd
170% more security vulnerabilities and 350% more crashes
than AFL. MOPT-AFLFast and MOPT-VUzzer also outper-
form their counterparts. Furthermore, the extensive evalu-
ation also showed that MOPT provides a good rationality,
compatibility and steadiness, while introducing negligible
costs.
1 Introduction
Mutation-based fuzzing is one of the most prevalent vul-
nerability discovery solutions. In general, it takes seed test
cases and selects them in certain order, then mutates them in
various ways, and tests target programs with the newly gen-
erated test cases. Many new solutions have been proposed
in the past years, including the ones that improve the seed
generation solution [1, 2, 3], the ones that improve the seed
Chenyang Lyu and Shouling Ji are the co-ﬁrst authors. Shouling Ji and
Chao Zhang are the co-corresponding authors.
selection strategy [4, 5, 6, 7, 8], the ones that improve the
testing speed and code coverage [9, 10, 11, 12], and the ones
that integrate other techniques with fuzzing [13, 14, 15].
However, less attention has been paid to how to mutate test
cases to generate new effective ones. A large number of well-
recognized fuzzers, e.g., AFL [16] and its descendants, lib-
Fuzzer [17], honggfuzz [18] and VUzzer [6], usually prede-
ﬁne a set of mutation operators to characterize where to mu-
tate (e.g., which bytes) and how to mutate (e.g., add, delete
or replace bytes). During fuzzing, they use certain mutation
schedulers to select operators from this predeﬁned set, in or-
der to mutate test cases and generate new ones for fuzzing.
Rather than directly yielding a mutation operator, the muta-
tion scheduler yields a probability distribution of predeﬁned
operators, and the fuzzer will select operators following this
distribution. For example, AFL uniformly selects mutation
operators.
There are limited solutions focusing on improving the mu-
tation scheduler. Previous works [7, 8] utilize reinforcement
learning to dynamically select mutation operators in each
round. However, they do not show signiﬁcant performance
improvements in vulnerability discovery [7, 8]. Thus, a bet-
ter mutation scheduler is demanded. We ﬁgure out that, most
previous works cannot achieve the optimal performance be-
cause they fail to take the following issues into consideration.
Different operators’ efﬁciency varies. Different mutation
operators have different efﬁciency in ﬁnding crashes and
paths (as shown in Fig. 3). Thus, fuzzers that select mu-
tation operators with the uniform distribution are likely to
spend unnecessary computing power on inefﬁcient operators
and decrease the overall fuzzing efﬁciency.
One operator’s efﬁciency varies with target programs.
Each operator’s efﬁciency is program-dependent, and it is
unlikely or at least difﬁcult to statically infer this depen-
dency. Thus the optimal mutation scheduler has to make
decisions per program, relying on each operator’s runtime
efﬁciency on the target program.
One operator’s efﬁciency varies over time. A mutation op-
erator that performs well on the current test cases may per-
USENIX Association
28th USENIX Security Symposium    1949
form poorly on the following test cases in extreme cases. As
aforementioned, the optimal mutation scheduler rely on op-
erators’ history efﬁciency to calculate the optimal probability
distribution to select operators. Due to the dynamic char-
acteristic of operator efﬁciency, this probability calculation
process should converge fast.
The scheduler incurs performance overhead. Mutation
schedulers have impacts on the execution speed of fuzzers.
Since the execution speed is one of the key factors affecting
fuzzers’ efﬁciency, a better mutation scheduler should have
fewer computations, to avoid slowing down fuzzers.
Unbalanced data for machine learning. During fuzzing,
the numbers of positive and negative samples are not bal-
anced, e.g., a mutation operator could only generate interest-
ing test cases with a small probability, which may affect the
effectiveness of gradient descent algorithms and other ma-
chine learning algorithms [7, 8].
In this paper, we consider mutation scheduling as an op-
timization problem and propose a novel mutation schedul-
ing scheme MOPT, aiming at solving the aforementioned is-
sues and improving the fuzzing performance.
Inspired by
the well-known optimization algorithm Particle Swarm Op-
timization (PSO) [19], MOPT dynamically evaluates the ef-
ﬁciency of candidate mutation operators, and adjusts their
selection probability towards the optimum distribution.
MOPT models each mutation operator as a particle mov-
ing along the probability space [xmin,xmax], where xmin and
xmax are the pre-deﬁned minimal and maximal probability,
respectively. Guided by the local best probability and global
best probability, each particle (i.e., operator) moves towards
its optimal selection probability, which could yield more
good-quality test cases. Accordingly, the target of MOPT
is to ﬁnd an optimal selection probability distribution of op-
erators by aggregating the probabilities found by the parti-
cles, such that the aggregation yields more good-quality test
cases. Similar to PSO, MOPT iteratively updates each par-
ticle’s probability according to its local best probability and
the global best probability. Then, it integrates the updated
probabilities of all particles to obtain a new probability dis-
tribution. MOPT can quickly converge to the best solution of
the probability distribution for selecting mutation operators
and thus improves the fuzzing performance signiﬁcantly.
MOPT is a generic scheme that can be applied to a wide
range of mutation-based fuzzers. We have applied it to sev-
eral state-of-the-art fuzzers, including AFL [16], AFLFast
[5] and VUzzer [6], and implement MOPT-AFL, -AFLFast
and -VUzzer, respectively. In AFL and its descendants, we
further design a special pacemaker fuzzing mode, which
could further accelerate the convergence speed of MOPT.
We evaluated these prototypes on 13 real world pro-
grams.
In total, MOPT-AFL discovered 112 security vul-
nerabilities, including 97 previously unknown vulnerabili-
ties (among which 66 are conﬁrmed by CVE) and 15 known
CVE vulnerabilities. Compared to AFL, MOPT-AFL found
170% more vulnerabilities, 350% more crashes and 100%
more program paths. MOPT-AFLFast and MOPT-VUzzer
also outperformed their counterparts on our dataset. We fur-
ther demonstrated the rationality, steadiness and low costs of
MOPT.
In summary, we have made the following contributions:
• We investigated the drawbacks of existing mutation
schedulers, from which we conclude that mutation operators
should be scheduled based on their history performance.
• We proposed a novel mutation scheduling scheme
MOPT, which is able to choose better mutation operators and
achieve better fuzzing efﬁciency. It can be generally applied
to a broad range of existing mutation-based fuzzers.
• We applied MOPT to several state-of-the-art fuzzers,
including AFL, AFLFast and VUzzer, and evaluated them
on 13 real world programs. The results showed that MOPT
could ﬁnd much more vulnerabilities, crashes and program
paths, with good steadiness, compatibility and low cost.
• MOPT-AFL discovers 97 previously unknown security
vulnerabilities, and helps the vendors improve their prod-
ucts’ security. It also ﬁnds 15 previously known vulnerabili-
ties in these programs (of latest versions), indicating that se-
curity patching takes a long time in practice. We open source
MOPT-AFL along with the employed data, seed sets, and
results at https://github.com/puppet-meteor/MOpt-AFL to fa-
cilitate the research in this area. A technical report with more
details can also be found there [20].
2 Background
2.1 Mutation-based Fuzzing
Mutation-based fuzzing [5, 6, 13, 14, 15, 16, 17, 18] is
good at discovering vulnerabilities, without utilizing prior
knowledge (e.g., test case speciﬁcation) of target programs.
Instead, it generates new test cases by mutating some well-
formed seed test cases in certain ways.
The general workﬂow of mutation-based fuzzing is as fol-
lows. The fuzzer (1) maintains a queue of seed test cases,
which can be updated at runtime; (2) selects some seeds from
the queue in certain order; (3) mutates the seeds in various
ways; (4) tests target programs with the newly generated test
cases, and reports vulnerabilities or updates the seed queue
if necessary; then (5) goes back to step (2).
In order to efﬁciently guide the mutation and fuzzing,
some fuzzers will also instrument target programs to collect
runtime information during testing, and use it to guide seeds
updating and decide which seeds to select and how to mutate
them. In this paper, we mainly focus on the mutation phase
(i.e., step (3)).
2.2 Mutation Operators
Mutation-based fuzzers could mutate seeds in inﬁnite
number of ways. Considering the performance and usability,
1950    28th USENIX Security Symposium
USENIX Association
Figure 1: Three mutation scheduling schemes used in the three stages of AFL [16].
Table 1: Mutation operators deﬁned by AFL [16].
Operators
Meaning
Type
bitﬂip
byteﬂip
arithmetic
inc/dec
interesting
values
user
extras
auto
extras
random
bytes
delete
bytes
insert
bytes
overwrite
bytes
cross over
Invert one or several consecutive bits in a test
case, where the stepover is 1 bit.
Invert one or several consecutive bytes in a test
case, where the stepover is 8 bits.
Perform addition and subtraction operations on
one byte or several consecutive bytes.
Replace bytes in the test cases with hard-coded
interesting values.
Overwrite or insert bytes in the test cases with
user-provided tokens.
Overwrite bytes in the test cases with tokens rec-
ognized by AFL during bitflip 1/1.
Randomly select one byte of the test case and
set the byte to a random value.
Randomly select several consecutive bytes and
delete them.
Randomly copy some bytes from a test case and
insert them to another location in this test case.
Randomly overwrite several consecutive bytes
in a test case.
Splice two parts from two different test cases to
form a new test case.
bitflip 1/1,
bitflip 2/1,
bitflip 4/1
bitflip 8/8,
bitflip 16/8,
bitflip 32/8
arith 8/8,
arith 16/8,
arith 32/8
interest 8/8,
interest 16/8,
interest 32/8
user (over),
user (insert)
auto extras
(over)
random byte
delete bytes
insert bytes
overwrite
bytes
cross over
in practice these fuzzers, including AFL [16] and its descen-
dants, libFuzzer [17], honggfuzz [18] and VUzzer [6], usu-
ally predeﬁne a set of mutation operators, and choose some
of them to mutate seeds at runtime. These mutation operators
characterize where to mutate (e.g., which bytes) and how to
mutate (e.g., add, delete or replace bytes).
For example, the well-recognized fuzzer AFL predeﬁnes
11 types of mutation operators, as shown in Table 1. In each
type, there could be several concrete mutation operators. For
instance, the bitflip 2/1 operator ﬂips 2 consecutive bits,
where the stepover is 1 bit. Note that, different fuzzers could
deﬁne different mutation operators.
2.3 Mutation Scheduling Schemes
At runtime, mutation-based fuzzers continuously select
some predeﬁned mutation operators to mutate seed test
cases. Different fuzzers have different schemes to select oper-
ators. For example, AFL employs three different scheduling
schemes used in three stages, as shown in Fig. 1.
1. Deterministic stage scheduler. AFL applies a deter-
ministic scheduling scheme for seed test cases that are picked
to mutate for the ﬁrst time. This scheduler employs 6 de-
terministic types of mutation operators in order, and applies
them on the seed test cases one by one. For instance, it will
apply bitflip 8/8 to ﬂip each byte of the seed test cases.
2. Havoc stage scheduler. The major mutation schedul-
ing scheme of AFL is used in the havoc stage. As shown in
Figure 2: The general workﬂow of mutation-based fuzzing
and mutation scheduling.
Fig. 2, AFL ﬁrst decides the number, denoted as Rt, of new
test cases to generate in this stage. Each time, AFL selects
a series of Ro mutation operators following the uniform dis-
tribution, and applies them on the seed to generate one test
case. The havoc stage ends after Rt new test cases have been
generated.
3. Splicing stage scheduler.
In some rare cases, AFL
works through the aforementioned two stages for all seeds,
but fails to discover any unique crash or path in one round.
Then AFL will enter a special splicing stage. In this stage,
AFL only employs one operator cross over to generate
new test cases. These new test cases will be fed to the havoc
stage scheduler, rather than the program being tested, to gen-
erate new test cases.
The mutation scheduler in the ﬁrst stage is determinis-
tic and slow, while the one in the last stage is rarely used.
The scheduler in the havoc stage, as shown in Fig. 2, is
more generic and has been widely adopted by many fuzzers.
Therefore, in this paper we mainly focus on improving the
scheduler used in the havoc stage, which thus can be imple-
mented in most mutation-based fuzzers. More speciﬁcally,
we aim at ﬁnding an optimal probability distribution, fol-
lowing which the scheduler could select better mutation op-
erators and improve the fuzzing efﬁciency.
2.4 Mutation Efﬁciency
Different mutation operators work quite differently. An
intuitive assumption is that, they have different efﬁciency on
different target programs. Some are better than others at gen-
erating the test cases, denoted as interesting test cases, that
can trigger new paths or crashes.
To verify our hypothesis, we conducted an experiment on
AFL to evaluate each operator’s efﬁciency. To make the eval-
uation result deterministic, we only measured the interesting
test cases produced by 12 mutation operators in the deter-
ministic stage. The result is demonstrated in Fig. 3.
In the deterministic stage, the order of mutation operators
and the times they are selected are ﬁxed. Fig. 4 shows the
USENIX Association
28th USENIX Security Symposium    1951
if(the first time to mutate this test case)Deterministic stageOperator: bitflip, byteflip, arithmetic inc/dec, interesting values, auto extras, user extras. Havoc stageOperator: bitflip, byteflip, arithmetic inc/dec, interesting values, random byte, delete bytes, insert bytes, overwrite bytes.  Splicing stageOperator: cross over.   if(AFL mutates all the test cases in the queue but discovers no crashes or paths && this test case has not  entered splicing stage for this time)YesNoYesRead next test case from the fuzzing queue, start from the first case again when fuzzer finishes all the cases in queue. Noseedseed poolmutateselect operatorsapply operatorsmutation operators (with distribution)Rt timesRo operatorsinteresting test casesRt  test        casesFigure 3: Percentages of interesting test cases produced by
different operators in the deterministic stage of AFL.
order and the times that operators are selected by AFL during
fuzzing avconv, indicating the time the fuzzer spent on.
• Different mutation operators’ efﬁciencies on one target
program are different. For most programs, the operators
bitflip 1/1, bitflip 2/1 and arith 8/8 could yield
more interesting test cases than other operators. On the other
hand, several other mutation operators, such as bitflip
16/8, bitflip 32/8 and arith 32/8, could only produce
less than 2% of interesting test cases.
• Each operator’s efﬁciency varies with target programs.
An operator could yield good outputs on one program, but
fail on another one. For example, arith 8/8 performs well
on exiv2 and tiff2bw, but only ﬁnds 12% of the interesting
test cases on avconv.
• AFL spends most time on the deterministic stage. We
record the time each stage spends and the number of inter-
esting test cases found by each stage in 24 hours, as shown
in Fig. 5. We ﬁrst analyze a special case. For tiff2bw,
since AFL cannot ﬁnd more interesting test cases, it ﬁnishes
the deterministic stage of all the inputs in the fuzzing queue
and skips the deterministic stage for a long time. Then, AFL
spends most time on the havoc stage while ﬁnding nothing.
For the other three cases, AFL spends more than 70% of the
time on the deterministic stage. When fuzzing avconv, AFL
even does not ﬁnish the deterministic stage of the ﬁrst in-
put in 24 hours. Another important observation is that the
havoc stage is more efﬁcient in ﬁnding interesting test cases
compared to the deterministic stage. Moreover, since AFL