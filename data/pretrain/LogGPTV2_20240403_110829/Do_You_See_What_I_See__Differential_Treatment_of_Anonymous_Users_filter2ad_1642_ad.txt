REDSTATION,GB (2.66)
SINGLEHOP-INC,US (2.09)
MCCI-AS,IR (8.92)
RMH-14-Rackspace,US (8.14)
RACKSPACE-Rackspace,US (7.43)
DREAMHOST-AS,US (6.32)
BBIL-AP BHARTI Airtel,IN (5.59)
OCN NTT,JP (20.90)
MCCI-AS,IR (12.46)
DREAMHOST-AS,US (8.83)
GO-DADDY-COM-LLC,US (3.51)
FBDC FreeBit,JP (2.56)
(b) STRICT Web Footprint (52,148,437 IP addresses forming 1.42% of probed IPv4)
TABLE IV: ASN distribution (top 5) of IP addresses that block Tor across exit nodes for LAX and STRICT. For each exit node, we show the percentage of
footprint that blocks it, and ASN distribution (%) of blocking IP addresses in the footprint.
Axigy1
Axigy2
NForce2
Voxility1
MCCI-AS,IR
RMH-14 - Rackspace,US
RACKSPACE - Rackspace,US
DREAMHOST-AS, LLC,US
CNNIC-SGATHER-AP,CN
DREAMHOST-AS,US
KUNET-AS,KR
REDSTATION,GB
LLC-SK-CONTINENT,RU
tropicalweb-as,MZ
RMH-14-Rackspace,US
RACKSPACE - Rackspace,US
AIRCEL-IN Aircel Ltd.,IN
DREAMHOST-AS, LLC,US
Rackspace Ltd.,GB
OCN NTT Communications,JP
DREAMHOST-AS, LLC,US
KUNET-AS,KR
BEKKOAME INTERNET INC.,JP
tropicalweb-as,MZ
(a) LAX Web Footprint
Axigy1
Axigy2
NForce2
Voxility1
MCCI-AS,IR
RMH-14 - Rackspace,US
RACKSPACE - Rackspace,US
DREAMHOST-AS,US
Rackspace Ltd.,GB
MCCI-AS,IR
DREAMHOST-AS,US
KUNET-AS,KR
REDSTATION,GB
AS-INTERMEDIA,US
MCCI-AS,IR
RMH-14 - Rackspace,US
RACKSPACE - Rackspace,US
DREAMHOST-AS,US
Rackspace Ltd.,GB
OCN NTT Communications,JP
MCCI-AS,IR
DREAMHOST-AS,US
KUNET-AS,KR
BEKKOAME INTERNET INC.,JP
(b) STRICT Web Footprint
TABLE V: ASN distribution (top 5) by fraction of IP addresses in their subnet that block Tor across exit nodes for LAX and STRICT. As multiple ASNs block
Tor 100%, we further order them by ASN size (the number of IP addresses in an ASN).
P(T , NT} | A)
P(T , NT} | W )
P(T , NT} | B)
P(T , NT} | D)
T = 0
T ∈ {1, 2}
NT = 0
NT ∈ {1, 2}
n2
(1 − n)2 + 2n(1 − n)
(1 − n)2 + 2n(1 − n)
n2
n2
(1 − n)2 + 2n(1 − n)
1
0
1
0
n2
(1 − n)2 + 2n(1 − n)
1
0
1
0
P(T , NT})
(a + w)n2 + b + d
−(cid:0)n2 − 1(cid:1) (a + w)
−(a + b)(cid:0)n2 − 1(cid:1)
an2 + bn2 + d + w
TABLE VI: Likelihood of scan outcomes: conditioned on category of target IP address and unconditional.
denying (W).2 In this context, we treat responding with an
error the same as denying responses.
We cannot directly observe which category a node falls
into, but we send two probe packets from either a Tor node
2While the whitelisting case seems unlikely, we need to consider it for a
complete analysis.
or non-Tor node and then count the number of responses (0,
1 or 2) from each: T for the number of successful responses
from the Tor node, and NT for non-Tor node. To estimate
the category given a count we must know the likelihood
P(T | c) and P(NT | c) for each category c ∈ C where
C = {A, W, B, D}.
7
P(A | T , NT}) P(W | T , NT}) P(B | T , NT}) P(D | T , NT})
T = 0
T ∈ {1, 2}
NT = 0
NT ∈ {1, 2}
(a+w)n2+b+d
(a+b)n2+d+w
an2
a
a+w
an2
a
a+b
(a+w)n2+b+d
n2 w
w
a+w
w
(a+b)n2+d+w
0
b
(a+w)n2+b+d
d
(a+w)n2+b+d
(a+b)n2+d+w
0
bn2
b
a+b
0
d
(a+b)n2+d+w
0
TABLE VII: Posterior probability of IP addresses falling into each category given a scan outcome.
If n gives the probability of the loss of a probe packet or
its corresponding response, then, assuming independence, the
probability of losing 0, 1 or 2 packets is (1 − n)2, 2(1 − n)n,
and n2 respectively. Although the two probes are sent with a
6.7 s delay to reduce correlated loss, we will show how to drop
the assumption of independence later. We assume that for W,
NT = 0; for B, T = 0; and for D, T = 0 ∧ NT = 0, which
corresponds to the deﬁnition of the RAW web footprint—a
single non-Tor response means that the IP address is not in D,
and a single Tor response means that the address is not in B.
Given these deﬁnitions, Table VI shows the likelihood of each
response given a category, and we can then calculate P(T ) =
c∈C P(NT | c)P(c). If
we know the network loss rate, receiving 2 packets in response
to a pair of probe packets does not add any more information
than receiving 1 so we combine these two cases. We deﬁne
the prior probability of an IP address being in each category
as a for P(A), b for P(B), d for P(D) and w for P(W).
c∈C P(T | c)P(c) and P(NT ) =(cid:80)
(cid:80)
Using Bayes law, we can now calculate the probability
that an IP address is of each category, given the count of
probe responses: P(c | T ) = (P(T | c)P(c))/P(T ) and
P(c | NT ) = (P(NT | c)P(c))/P(NT ), as shown in Ta-
ble VII. We can drop the assumption about independent packet
loss probabilities by noting that
the value for n is never
used directly, only n2, so we can specify n2 directly as the
probability of the loss of two consecutive packets, taking into
account any dependence between loss probabilities.
We perform the probability calculation for each IP address
by selecting a row from Table VII based on the type of scan
(Tor or non-Tor) and number of probe responses, then applying
each formula to update the estimate of P(A), P(W), P(B) and
P(D). The formulae depend on the network loss rate n2, as
well as the previous estimates of P(A), P(W), P(B) and P(D)
(a, w, b and d). The ﬁrst time we calculate the probabilities we
must provide prior probabilities (for which we use the uniform
distribution), but the effect of this choice diminishes as we
consider each new set of probe results.
Note that if we receive at least 1 response to a non-Tor
probe, w = d = 0 and thus P(B | N T ∈ {1, 2}) becomes
equal to P(B | N T = 0). Therefore the probability that a target
IP address is blacklisting Tor depends only on n2, the prior
probability estimates, whether we ever receive a response to a
Tor probe (as then P(B) = 0); whether we receive a response
to at least one non-Tor probe (then P(W) = P(D) = 0); and
the total number of scans we performed.
To estimate n2 we average how often an IP address appears
to be inaccessible from one site, despite being accessible from
at least one of the others. This is always less than 1% so
we take this as a conservative estimate for n2. We can then
8
compute P(B) for each category of IP address: those outside
of the RAW footprint (N T = 0 for all 7 non-Tor scans), and
those inside the footprint with T = 0 for all 4 Tor scans
have non-zero P(B). IP addresses with T > 0 for any scan
have P(B) = 0. From these probabilities we can estimate
the expected number of blacklisting nodes by multiplying the
number of IP addresses of each category (count) by P(B)
for that category, and taking the normal approximation of
the binomial distribution we can ﬁnd the 95% conﬁdence
interval as 3 standard deviations of the normal distribution
with µ = count × P(B) and σ2 = count × P(B)(1 − P(B)).
Of the 3,662,744,599 IP addresses scanned, 103,329,073
are inside the RAW footprint leaving 3,559,415,526 outside.
For those IP addresses outside the footprint P(B) = 5× 10−15
and so the expected number of blacklisting nodes missed is
0.000018 ± 0.012. Of the IP addresses inside the footprint
which never responded to any of the Tor-scans, P(B) = 1 −
1 × 10−8. Therefore the expected number of blacklisting IP
addresses is between 0.15 and 0.16 less than the count for each
exit node studied, with 95% conﬁdence interval between ±1.16
and ±1.22. So overall we can conclude that the number of
scans performed are sufﬁcient to almost completely eliminate
the effect of network loss.
V. APPLICATION-LAYER DISCRIMINATION
We have seen that Tor exit nodes encounter a restricted
Internet at layers 3/4. In this section we describe our experi-
ments to measure layer 7, i.e., application-layer blocking of
Tor users. We base our observations on two data sources:
1) ﬁve days of our own intensive scans of 1,000 URLs from a
control server and through every Tor exit node; and 2) a year’s
worth of paired Tor/non-Tor scans of over 2,300 URLs from
the Open Observatory of Network Interference (OONI). OONI
is a global network measurement platform aimed at detecting
censorship and surveillance, one of whose tests is particularly
suited to our study.
There are two main ways Tor users may ﬁnd themselves
blocked by a server. The server may block Tor users specif-
ically, using a blacklist of Tor exit node addresses. The only
maintenance required is keeping the blacklist up to date.
Alternatively, Tor users may simply be caught up in an
automated blocking system that does not target Tor per se,
but merely reacts to the consolidated trafﬁc of the many
users that come from an exit node. Perhaps the most con-
spicuous current example of this phenomenon is CloudFlare’s
‘Attention Required!’ CAPTCHA page. CloudFlare is a large
content delivery network (CDN) that by default assesses the
‘reputation’ of each client IP address in terms of how much
malicious trafﬁc it has been observed to send, and blocks
attempted access by clients with sufﬁciently poor reputations.
A. Contemporary Scans
To measure the differential treatment of Tor users, we visit
Alexa top 1,000 URLs once from all available Tor exit nodes
and once without Tor. For the former, we used Exitmap [29],
a fast and extensible Python-based scanner for Tor exit nodes.
Exitmap uses Stem [12] to connect to the Tor network, and
enables running a module over all available exit nodes. It is
designed to monitor the reliability and trustworthiness of exit
nodes [30] but its basic architecture is generic and it can be
used to run any query.
Exitmap downloads a Tor consensus and extracts the cur-
rently available exit nodes. It then initiates circuits using the