approaches force RNNs to increase the probability of predicting
𝑥𝑡 through the sequence with first 𝑡 − 1 samples. In other words,
the loss function of RNNs is to maximize 𝑓 (x) = Pr(𝑥𝑡|𝑥1𝑥2...𝑥𝑡−1)
during training. Similar to reconstruction-based models, such RNNs
can predict the next (i.e., 𝑡-th) sample in normal time-series with
higher probability, while wrongly predict 𝑡-th sample for anomaly
(i.e., with lower probability).
2.3 Anomaly Detection Systems for Security
We start by introducing the general pipeline of unsupervised DL-
based anomaly detection systems in security domains. Then, we
briefly introduce three types of systems with several state-of-the-art
works in diverse security domains.
Pipeline of DL-based Anomaly Detection Systems. As shown
on the left of Figure 1, security applications often start with unstruc-
tured raw data, such as network traffic and system logs. These data
cannot be directly fed into DNNs, thus pre-processing and feature
engineering based on domain-specific knowledge are required. For
example, network traffic can be processed by aggregating related
packets into flows through Netflow [52], and free-text system log en-
tries can be parsed into the sequence of log keys indicating message
type for entries [12, 57]. After preprocessing, well-structured data
can be fed into different kinds of DNNs, performing the aforemen-
tioned reconstruction/prediction based learning to detect anomalies.
In this study, we separate security-related anomaly detection sys-
tems into three types according to different structures of source
data: tabular data, time-series and graph data.
Tabular Data based Systems. Tabular data is the most common
type that is structured into rows (also called feature vectors), each of
which contains informative features about one sample. In general,
most types of DNNs are designed to process tabular data. Tabular
data based anomaly detection systems have been developed for
network intrusion detection [35, 59] and key performance indica-
tors (KPI) anomaly detection [56]. For example, Kitsune[35] is a
“Normal”/“Anomaly”DeepAIDTime-SeriesTabular DataRaw DataGraph Data DL-based Anomaly Detection SystemsInterpreter (§4)Establishing Trustsfor Systems (§6.3)RNN/LSTMAutoencoderGNN/GE PreprocessingFeature EngineeringDistiller (§5)0.30.70.61.00.4Easy to DebugSystems (§6.4)Incorporating expertknowledge (§6.5)Reducing FalsePositives (§6.6)Reliable ResultsRaw DataYesInterpretationReasonable?YesNoEstablish Trust onModel DecisionsAnomaly?DL-based AnomalyDetection SystemYesNo   Capture well-known rules     Discover new KnowledgeKnown Rules?FP?Yes     Update System     Update DistillerInterpreter    Diagnose&DebugSession 12A: Applications and Privacy of ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3199Table 1: Comparison of representative DL interpreters.
LIME[42] LEMNA[20] COIN[31] CADE[58] DeepLIFT[44] DeepAID
Approx. Approx. Approx. Perturb.
B.P.
B.P.
Interpreters
Method (§2.1)
Support Unsupervised∗
Support Tabular Data
Support Time Seires
Support Graph Data
Stable†
Efficient†
Robust†
= partially true,
( = true,
∗ Here we mean whether an interpreter can directly support unsupervised
models without abnormal training data;
† These three indicators are measured through our experiments in §6.
= false);
state-of-the-art network intrusion detection systems based on un-
supervised DL. It collects raw packets from the monitoring network
and then retrieves feature vector from the meta information of each
packet which contains over 100 statistics. Finally, tabular features
are fed into ensemble Autoencoders to perform reconstruction-
based anomaly detection.
Time-Series based Systems. Time-series is a sequence of data
samples indexed in time order. Any data with temporal information
can essentially be represented as time-series, such as network traffic
[61] and system logs [12]. Specifically, DeepLog [12] first abstracts
each kind of system log as a discrete key and parse Hadoop file
system (HDFS) logs to sequences of discrete log key indexes. Then,
RNN/LSTM is leveraged for prediction-based anomaly detection.
Graph Data based Systems. Graph data structure is useful for
modeling a set of objects (nodes) and their relationships (links) at
the same time [64]. Graph data based anomaly detection is receiv-
ing more attention in security domains. Especially for advanced
persistent threat (APT) detection, researchers have leveraged Graph
Neural Networks (GNN) or Graph Embedding (GE) for unsuper-
vised detection [6, 22]. For example, GLGV [6] is developed to detect
lateral movement in APT campaigns. GLGV constructs authentica-
tion graphs from authentication logs within enterprise networks.
The training data is collected from the purely benign authentication
graphs through DeepWalk [41], which is a NN-based GE method.
Thus, GLGV can use the reconstruction-based approach to detect
abnormal authentications indicating lateral movement in APT.
2.4 Overview of DeepAID Design
The overview of DeepAID is shown on the right of Figure 1 in-
cluding two core parts: Interpreter and Distiller. Interpreter pro-
vides high-quality interpretations dedicated to DL-based anomaly
detection systems for security, which provides a general model-
independent framework by formulating the interpretation to a
unified optimization problem with security-related constraints. We
instantiate Interpreter on aforementioned three types of security
systems. Based on the interpretations from DeepAID Interpreter,
we additionally propose a model-based extension called Distiller
to facilitate human interaction with DL models. Distiller can store
informative interpretations and expert feedback and into its FSM-
based model. With Interpreter, security operators can better under-
stand system behaviors and trust system decisions. With Distiller,
DL-based security system becomes debuggable, transparent, and
human-in-the-loop. In Figure 2, we provide the workflow of some
use cases to improve the practicality of such security systems with
the help of DeepAID, which will be discussed in detail in §6.
3 MOTIVATION
In this section, we provide the key motivations of this work from
three aspects. Firstly, why unsupervised DL-based security systems
need interpretations and improvements? (§3.1) Secondly, why ex-
isting interpretation approaches are insufficient for unsupervised
DNNs? (§3.2) Thirdly, why we need Distiller? (§3.3)
3.1 Why Security Systems Need DeepAID?
In general, there are four major drawbacks in unsupervised DL-
based security systems.
Hard to Establish Trusts for System Decisions. Security oper-
ators need sufficient reasons about the anomaly to take further
actions since misoperation will induce a very high cost. Compared
with traditional rule-based systems which contain detailed reasons
in their alert logs, DL-based anomaly detection algorithms can only
return “abnormal” or “normal”. As a result, such systems become
unreliable with over-simplified outputs.
Difficult to Diagnose System Mistakes. Without understand-
ing the black-box models, it is almost impossible to diagnose and
repair mistakes in DL-based systems. For example, it is difficult
to tell whether a mistake is caused by implementation bugs, or
over-fitting/under-fitting, or redundant features, or other reasons.
Failed to be Human-in-the-Loop. Unlike tasks in other domains
such as image analysis, security-related systems should be human-
in-the-loop instead of fully automated, owing to high cost of errors
and reliance on expert knowledge. That is to say, security systems
require to incorporate experts’ knowledge and be adjusted accord-
ing to expert feedback. However, the black-box nature makes it
difficult for experts to interact with DL models or use expert knowl-
edge/experience to improve systems.
Fatigue on tons of False Positives. One of the most critical chal-
lenges of developing practical DL-based anomaly detection systems
in security domains is to save operators from overwhelming FPs.
There are many reasons for FPs such as insufficient learning of
distribution of normal training data, and the appearance of concept
drift (i.e., distribution of test data is changing and deviates from
training data).
We attribute the above drawbacks to the lack of interpretability
in DNNs. Therefore, we develop DeepAID to interpret DL-based
security systems and further solve the above drawbacks.
3.2 Why Not Existing Interpretations?
Although DL interpretability has been extensively studied [19, 37],
we argue that existing interpretations are unadaptable for unsuper-
vised DL-based security systems for the following two reasons.
Ill-suited for Unsupervised Learning. Most existing interpreta-
tion methods serve supervised models. However, there are clear
differences between supervised and unsupervised models with re-
spect to the mechanism of training and detection. For supervised
DNNs, the interpretation goal is to answer why a certain input
is classified as an anomaly. However, this is not the case for un-
supervised DL models since they are not supposed to learn any
Session 12A: Applications and Privacy of ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3200Table 2: Notations
Notation
x◦; (𝒙◦, X◦, X◦)
x∗; (𝒙∗, X∗, X∗)
𝑓𝑅(·), E𝑅(·, ·), 𝑡𝑅
∥ · ∥𝑝, (·)𝑖, (·)(𝑡)
𝑁 , 𝐾
𝑓𝑃 (·), 𝑡𝑃
E𝐺 (·)
Description
Interpreted anomaly; (tabular, time-series, graph form)
Reference for interpretation; (tabular, time-series, graph form)
# dimension in features and interpretation vectors (non-zero)
Reconstruction-based DNN, error function and threshold
Prediction-based DNN and threshold
𝐿𝑝-norm, 𝑖-th element, 𝑡-th iteration
Graph embedding function
D𝑡𝑎𝑏(·), D𝑡𝑠(·), D𝑔𝑟𝑎(·) Objective function (for tabular, time-series, graph form)
Neighborhood scale for initialization of tabular Interpreter
𝜎𝑛
knowledge from abnormal data. Here we introduce a more reason-
able goal, which is to answer why a certain anomaly is not considered
as normal. That is to say, for unsupervised DL models, what we
need to interpret is deviation, not classification. We need to seek the
reason why anomalies deviate from normal data.
Failed to Deploy in Security Domains. Firstly, the intention of
interpreting security applications differs: Security practitioners are
more concerned about how to design more reliable systems based
on interpretations and solve the aforementioned domain-specific
problems, rather than excessive pursuit of understanding the details
of DNN. Consequently, Some interpretations used to understand
the operating mechanism of DNN are not applicable to security
applications [13, 39, 62]. Secondly, different from other domains,
security applications have a low tolerance for errors, which re-
quires the interpretations to be high-quality and robust. However,
recent studies have shown that existing interpretations failed to be
adopted in security domains due to their poor performance [14, 54].
For one thing, approximation-based interpretation approaches are
inaccurate, unstable and time-consuming due to the stochastic sam-
pling for training surrogate simple models. For another, existing
interpretations have shown to be vulnerable to adversarial attacks
[18, 47, 60] or even random noise [14, 54].
3.3 Why DeepAID Needs Distiller?
Why Distiller? With interpretations from DeepAID Interpreter,
model decisions become interpretable, but it is still difficult for
security participants to get involved in the decision-making process.
In this case, Distiller provides a bridge to make the entire system
become human-in-the-loop.
Why Not Existing Distillation Approaches? Knowledge distil-
lation has been proposed to provide global interpretations by replac-
ing the entire DL models with interpretable models [33, 55] (Note
that they differ from approximation-based methods in §2.1 since
the latter uses surrogate models for local approximation). However,
global substitute model will inevitably induce performance reduc-
tion. By contrast, Distiller in DeepAID is just a back-end extension
to DL-based systems, instead of replacing them.
4 INTERPRETING ANOMALIES
In this section, we first give high-level ideas of DeepAID Inter-
preter and provide a unified problem formulation for interpreting
unsupervised DL models, followed by detailing its instantiations
on three types of unsupervised DL-based security systems. Table 2
lists some important notations used in this paper.
ing the workflow of high-speed online systems.
4.1 Unified Formulation of Interpretations
High-level Ideas for Interpreting Anomalies. In this study, we
primarily focus on interpreting anomalies since they are more con-
cerned than normal data. As mentioned in §3.2, motivated by the
different learning mechanism of unsupervised DNNs from super-
vised ones, we redefine interpretations of unsupervised models as
seeking the reason why anomalies deviate from normal data in the
DL model. From a high level, the proposed Interpreter uses “defer-
ence from reference” to interpret the deviation of anomalies. Specif-
ically, we formulate the interpretation of an anomaly as solving
an optimization problem which searches a most suitable reference
which is considered as normal by the DL model. Then, the inter-
pretation of this anomaly is derived by pinpointing the deference
between this anomaly and its reference.
Special Concerns for Security Domains. As mentioned before,
there are special security requirements for interpreters in security
domains [14, 54].
(1) Fidelity: should be high-fidelity for imitating original DNNs;
(2) Conciseness: results should be concise and human-readable;
(3) Stability: results on the same sample should be consistent;
(4) Robustness: robust against adversarial attacks or noises;
(5) Efficiency: interpretations should be available without delay-
Unified Problem Formulation. Given an anomaly x◦, our goal
is to find a reference x∗, then the interpretation of x◦ is provided by
the difference between x◦ and x∗. In light of the above requirements,
we formulate interpretations of x◦ in unsupervised DNNs (denoted
with 𝑓 ) for security domains as the following optimization problem:
argminx∗ L𝑓 𝑖𝑑(x∗; 𝑓 ) + 𝜆1L𝑠𝑡𝑎(x◦; 𝑓 , x∗) + 𝜆2L𝑐𝑜𝑛(x◦, x∗)
(1)
(2)
where L𝑓 𝑖𝑑, L𝑠𝑡𝑎 and L𝑐𝑜𝑛 respectively measures the loss of fi-
delity, stability, and conciseness, balanced by weight coefficients 𝜆1
and 𝜆2. The constraint (2) means that x∗ must be searched in the
same feature space as the anomaly x◦ (measured by R). Below, we
will detail instantiations of the formulation and technical solution
for three types of systems (according to different data types of x◦).
4.2 Tabular Data Interpreter
As mentioned in §2, tabular data needs reconstruction-based learn-
ing models. Following the unified framework in §4.1, the fidelity
loss of tabular anomaly data 𝒙◦ can be transformed by adding a
constraint to ensure searched reference 𝒙∗ is decided to be normal.
To define stability loss, we ensure 𝒙∗ to be as close to 𝒙◦ as possible
while satisfying other constraints. We use Euclidean distance for
measuring this term. To define conciseness loss, we leverage 𝐿0-
norm to measure the difference between 𝒙∗ and 𝒙◦, which measures
total number of non-zero elements in 𝒙∗ − 𝒙◦. Consequently, the
interpretation of tabular anomaly can be formulated as:
s.t. x∗ ∈ R(x◦),
argmin
𝒙∗ ∥𝒙∗ − 𝒙◦∥2 + 𝜆∥𝒙∗ − 𝒙◦∥0
s.t. E𝑅(𝒙∗, 𝑓𝑅(𝒙∗)) < 𝑡𝑅
(3)
(4)
(5)