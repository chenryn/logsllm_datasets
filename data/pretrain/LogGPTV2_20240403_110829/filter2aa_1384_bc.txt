Click Undeploy to undeploy webshell.
Figure 11.2
Confirmation that webshell is undeployed
Figure 11.3
Confirming that the WAR file has been undeployed
204
CHAPTER 11
Post-engagement cleanup
11.5.2 Closing the Sticky Keys backdoor
In section 5.5.1, you learned how to create a backdoor to the Apache Tomcat server by
replacing the Sticky Keys binary, sethc.exe, with a copy of the Windows command
prompt, binary cmd.exe: the infamous Sticky Keys backdoor. This allows anyone who
connects to the target server with a Remote Desktop Protocol (RDP) client to launch
a system-level command prompt by pressing the Shift key five times. Instead of the
Sticky Keys dialog, a command prompt with system privileges is launched. Leaving the
server in this state creates additional risks for your client, so the backdoor needs to be
closed when you are finished with your engagement. 
 Connect to the server using whatever means of remote access you are most com-
fortable with. I’ll use RDP for illustrative purposes. To move into the directory con-
taining the Sticky Keys binary, type the following command at the prompt:
cd c:\windows\system32
Now replace the backdoored binary file sethc.exe (which is actually a copy of
cmd.exe) with the original binary that you set aside in chapter 5, with the command
copy sethc.exe.backup sethc.exe. 
 Last, verify that you have removed the backdoor by pressing the Shift key five
times. You should see the familiar Sticky Keys dialog, not a Windows command
prompt (figure 11.4).
11.5.3 Uninstalling persistent Meterpreter callbacks
Back in chapter 8, I showed you how to set up a persistent Meterpreter autorun back-
door executable to maintain reliable re-entry into a compromised Windows target. If
you don’t take care of this binary, it will call out again and again to your attacking
machine’s IP address and port number. Theoretically, if an attacker could stand up
their own Metasploit listener on the same IP address and port, they could receive a
Meterpreter session on this target, so you’d better be sure to clean up after yourself
before closing out this engagement.
Figure 11.4
Confirming that Sticky Keys works properly
205
Closing backdoors
 Luckily, Metasploit placed a handy resource file in the ~/.msf4/logs/persistence
folder that contains the commands necessary to uninstall the backdoor. Inspecting
the file with the cat command reveals that you need to run only two commands: 
 One to delete the .vbs script you created 
 A reg command to delete the registry key you created to autorun the .vbs file
If I look in my persistence folder by running the command ls –lah, I can see that my
file is called GOHAN_20200514.0311.rc, just as it says in this listing.
total 12K
drwxrwxr-x 2 pentest pentest 4.0K May 14 12:03 .
drwxrwxr-x 3 pentest pentest 4.0K May 14 12:03 ..
-rw-rw-r-- 1 pentest pentest  111 May 14 12:03 GOHAN_20200514.0311.rc    
Now, if I look at the contents of that file using the command cat GOHAN_
2020514.0311.rc, I see the remove and registry commands that were just discussed
(see listing 11.10). Remotely access Gohan using CrackMapExec (CME) and issue
these commands one at a time, first deleting the YFZxsgGL.vbs file and then using reg
deleteval to remove the registry key.
NOTE
You’ll notice that the first command, rm, doesn’t work on Windows
because it isn’t a Windows OS command. The resource file can be run
directly from within the Metasploit console. You could do so by typing run
/path/to/resource/file. I don’t typically have an active Metasploit console
running while I’m doing post-engagement cleanup, so I connect to the target
machine and issue the commands manually, replacing rm with del. Feel free
to use whatever method works best for you.
rm c:////YFZxsgGl.vbs    
reg deleteval -k 'HKLM\Software\Microsoft\Windows\CurrentVersion\Run' -v
OspsvOxeyxsBnFM   
I know the topic of cleaning up after yourself isn’t as exciting as hacking into remote
systems and compromising vulnerable targets. That said, it is a necessary part of net-
work pentesting, and you should take it seriously. Remember, the purpose of these
cleanup activities is not to be confused with trying to erase your tracks or cover that
you were there. It is instead to ensure that you don’t leave your client in a less secure
state than they were in when you began the engagement. The next chapter covers the
final step in completing your INTP: writing a solid pentest deliverable.
Listing 11.9
Metasploit resource file to remove the Meterpreter autorun backdoor
Listing 11.10
Contents of the resource file showing rm and reg commands
Name of the resource file
containing cleanup commands
Path to the vbs file that needs to be deleted
The reg command to delete the registry key
206
CHAPTER 11
Post-engagement cleanup
Summary
 Active shell connections need to be closed to prevent unauthorized people
from using them to compromise targets on your client’s network.
 You don’t delete local user accounts that you created. Instead, you deactivate
them and notify your client so they can properly delete them. 
 Remove any miscellaneous files such as registry hive or ntds.dit copies that an
attacker could use to compromise your client.
 Configuration changes that leave systems in a less secure state than when you
started your engagement need to be correctly reversed to their original state.
 Any backdoors you left open to ensure reliable re-entry into a compromised tar-
get need to be properly closed and removed to ensure that a real attacker can’t
use them to compromise your client’s network.
Exercise 11.1: Performing post-engagement cleanup
Using your engagement notes as a reference, go back and perform post-engagement
cleanup throughout your target environment:
 Kill all active shell connections.
 Deactivate all user accounts that you created.
 Remove all leftover files that you placed on compromised hosts.
 Reverse all configuration changes that you made.
You can find a list of things that should be cleaned up from the Capsulecorp Pentest
environment in appendix E.
207
Writing a
 solid pentest deliverable
The final piece of the puzzle that you need to create is your engagement report—
or, as it’s more commonly referred to in the industry, your deliverable. In this chap-
ter, I go over all the components that make up a solid pentest deliverable. There
are eight of them, and I explain the purpose of each section and what it should
contain. Appendix D is an example of a complete standalone INTP deliverable,
which I would present to Capsulecorp if it had been a real company that hired me
to perform a pentest engagement. You can and should feel free to use this example
report as a template or framework when creating your own deliverables.
 After you’ve produced a few, you’ll start to come up with your own style and
adjust things to your liking. I don’t bother covering the style or look and feel of a
deliverable because that’s completely up to the company you work for and their
corporate branding guidelines. It’s important to point out that a pentest deliver-
able is the work product of an individual company that sells pentesting services. For
This chapter covers
 The eight components of a pentest deliverable
 Closing thoughts
208
CHAPTER 12
Writing a solid pentest deliverable
that reason, deliverables differ in size, structure, color, fonts, charts and graphs, and
so on from company to company. 
 Rather than try to set the bar or establish a standard of excellence, I offer instead a
set of guidelines that I believe most pentest companies are already following, so you
should, too. You may find additional sections in other pentest reports, but the eight sec-
tions you learn about in this chapter exist in every good pentest report you’ll ever read.
12.1
Eight components of a solid pentest deliverable
Before diving into the details of each section, let’s first take a high-level look at all of
them, as follows: 
 Executive summary—Serves as a standalone report that you present to executive
leadership. They aren’t concerned with technical details, just the high-level bul-
lets. This section answers the who, what, where, when, and why questions. The
how answer is provided throughout the rest of the deliverable.
 Engagement methodology—Explains the methodology you used to conduct the
engagement. Usually, you also provide information about the type of attacker
you’re modeling and then spell out the objectives and potential activities that
take place throughout the four phases of your methodology.
 Attack narrative—Should read almost as if you’re telling a story. Explain how you
moved from A to Z, so to speak. Spell out all of the systems you had to compro-
mise to take over the network, but leave the details of the compromises for the
next section.
 Technical observations—Nine times out of 10, this is the section your client will
flip straight to upon opening your report for the first time. These observations,
or findings as they’re more commonly referred to, explain in detail what was
wrong from a security standpoint and how you were able to compromise sys-
tems in the client’s environment. These findings should correlate directly with
the authentication, patching, and configuration vulnerabilities you identified in
chapter 4.
 Appendix: severity definitions—Contains objective, fact-based definitions of
exactly what your finding severity ratings mean. If written well, this section can
help resolve disputes you may have with your client about a specific finding
being marked as high or critical.
 Appendix: hosts and services—Typically contains raw information in table form
showing all the IP addresses you identified and all the ports and services that
were listening on them. On a large engagement with thousands of hosts, I typi-
cally put this information in a supplemental document such as an Excel spread-
sheet.
 Appendix: tool list—Typically a single page with a bulleted list of all the tools you
used during your engagement and a hyperlink to each tool’s website or GitHub
page.
209
Executive summary
TIP
A typical pentest statement of work (SOW) will include verbiage about
tool development. If it isn’t in the SOW template your company uses, it’s not
uncommon for your client to request to add it. Depending on the client, they
may ask that any tools you create specifically for this engagement become
their intellectual property. More often than not, this is to prevent you from
writing a blog post saying that you just made a cool new tool that helped you
hack into Company XYZ.
 Appendix: additional references—I admit, this is filler that 9 out of 10 clients will
not read. But it is typical for a pentest deliverable to contain a list of links to
external resources that vary from hardening guides to best practice security
standards published by industry authorities.
Figure 12.1 depicts the eight sections of a successful pentest deliverable, from top to
bottom. Although this isn’t written in stone, you’ll typically see the eight sections in
this sequence.
Now that you know which components to include in your pentest deliverable, let’s talk
about each one in greater detail, beginning with the executive summary. 
12.2
Executive summary
The best way I can describe the executive summary portion of a penetration test deliv-
erable is as a 30,000-foot view of the entire engagement. It’s a page or two at most that
you could remove from the report and present as a standalone document to a busi-
ness executive. The executive isn’t concerned with the specific details of the engage-
ment, just the bullet points. A good executive summary answers the who, what, where,
Executive summary
    High-level overview of the entire 
    engagement
    Explains the four-phased penetration
    testing methodology
    Step-by-step walk-through of your attack
    path from beginning to end
    Also called findings: the issues that
    allowed you to penetrate the environment
    Objective definitions that remove personal
    bias from rating findings
    Open ports and services discovered during
    phase 1
    List of tools you used during the engagement,
    usually with hyperlinks for more information
    Supplemental resources: usually best practice
    security guides from industry authorities
Engagement methodology
Attack narrative
Technical observations
Appendix: Severity definitions
Appendix: Hosts and services
Appendix: Tool list
Appendix: Additional references
Figure 12.1
The eight components of a solid pentest deliverable
210
CHAPTER 12
Writing a solid pentest deliverable
and when; the rest of the pentest report focuses on the how (as mentioned already,
but probably not for the last time). 
 The final report of a pentest is the only tangible work product that clients are left
with after an engagement. I’ve often joked that it’s a $20,000 Word document con-
verted to PDF. Naturally, pentest companies or individuals try to differentiate them-
selves from their competitors by adding all sorts of colorful charts, graphs, and data
points. If you looked at 10 different executive summaries from as many different
pentest organizations, you’d see differences in each of them. But you’d probably see
the following in all of them:
 Goals and objectives—What was the purpose of the engagement? What were the
penetration testers attempting to accomplish, and why?
 Dates and Times—When did the engagement take place, what date did testing
begin, and when did it end?
 Scope—What system or groups of systems were tested during this engagement?
Were any systems excluded or not allowed to be tested?
 High-level results—What happened? Was the test successful/unsuccessful? How
so? What is the recommended course of action moving forward?
These are considered to be minimum requirements. You can reference the executive
summary in appendix D for a complete example from the Capsulecorp penetration
test. Right after the executive summary is the section explaining the engagement
methodology. 
NOTE
In this section, I mention converting a Word document to a PDF. It
should be mentioned that the integrity of a penetration test deliverable is
highly important, and you should never give your client an editable docu-
ment. This isn’t to suggest that clients are dishonest and would alter the
report, but more of a control to ensure that they can’t alter the document in
any way. 
12.3
Engagement methodology
The engagement methodology is important for a couple of reasons. First, it answers
questions many readers of your report will have, such as, “How did you go about the
testing?” and “What types of attacks were you most interested in?” The term penetration
testing has become pretty obscure these days and can mean a hundred different things
to a hundred different people. Describing your testing methodology up front and in
as much detail as you can helps to set expectations and make sure you and the reader
of your report are communicating with similar language.
 The second reason this section is important is for the inevitable “clean report” you’ll
have to write one day. At some point in your career, you’ll conduct an engagement for
a company that does a fantastic job of securing its network. Or maybe it limits your test-
ing scope to the areas of the network it knows don’t have any issues. Either way, you’ll
211
Technical observations
be forced to deliver a clean report without any findings in it. I can’t articulate exactly
why this is painful to penetration testers, but it is. I imagine it has something to do with
ego and feeling incompetent or unable to penetrate the environment. There is also a
valid concern that your client will feel ripped off. They paid you $10,000 to do a
pentest, and you gave them a report with nothing in it! What were you doing the whole
time? What did they pay you for?
 This is where the methodology section can help illustrate all of the various testing
activities and attack vectors you attempted against the scoped environment. A good
engagement methodology section contains language describing the type of attacker
that was emulated during the test. It should also explain the amount of information
that was given up front in the form of white box, grey box, or black box descriptions.
We covered this in section 2.1.1.
TIP
Of course, you’ll be using a template to complete your report, so the
methodology can’t contain every single thing you did and every command
you ran unless you want to rewrite it from scratch after every engagement.
Instead, list the four-phased methodology you learned in this book and
include bullet points for all the desired actions: identify live hosts, enumerate
listening services, cross-reference reported software versions with known
exploits, test authentication prompts for default credentials, and so on, all the
way through the phases and components of your engagement methodology.
12.4
Attack narrative
This section of the report should read like a short story summarizing exactly what you
did as an attacker but with specific details. Describe in linear fashion how you went
from plugging your laptop into a conference room data jack to taking control of the
entire network with no up-front knowledge other than a list of IP address ranges. You
can be somewhat vague in your attack narrative by saying things like “Protocol-specific
target lists were targeted for vulnerability discovery,” because your engagement meth-
odology section explains in more detail what protocol-specific target lists and vulnerability
discovery mean.
 You can choose to illustrate your attack narrative with screenshots or keep it as text
only. That is a personal preference, as long as you explain precisely how you carried
out your attacks and articulate how and why you were able to achieve the level of
access that you obtained during your engagement.
12.5
Technical observations
The primary focus of your pentest report will be the technical observations, more
commonly referred to as findings. These findings provide details about the authentica-
tion, configuration, and patching vulnerabilities that allowed you to penetrate further
into your client’s network environment. Findings should include the following:
212
CHAPTER 12
Writing a solid pentest deliverable
 A. Severity rating—The severity rating assigned to that particular finding. Make
sure it is consistent with your severity definitions. Severity ratings vary quite a bit
between organizations, committees, frameworks, and even individual pentest-
ers. This book makes no attempt to state an authoritative definition of what
severity “low” or “medium” means. My only concern is that you have concrete,
objective definitions for what you mean when you say something is of a particu-
lar severity; I cover that later in this chapter.
 B. Descriptive title—A one-sentence title that describes the finding. The title
alone should explain the problem.
 C. Observation—A more detailed explanation of what you observed.
 D. Impact statement—A description of the potential impact on the business. A
previous mentor of mine used to call it the “so what” factor. Imagine that you’re
communicating your findings to a non-technical business executive. When you
tell them you gained access to the database server, they respond with “So what?”
Your impact statement is whatever you would say next to communicate why an
attacker gaining access to the database is bad.
 E. Evidence—This is self-explanatory. A screenshot, code listing, or command
output will do the trick: something that shows proof that you were able to use
the finding to compromise a target in some way.
 F. Assets affected—The IP address or hostname of the assets affected. On a large
engagement, sometimes a single finding affects dozens or even hundreds of
assets. In that case, it’s common practice to move them into an appendix at the
end of the report and merely reference the appendix in the finding. 
 G. Recommendation—Actionable steps that your client can take to resolve the
issue. You can’t just say that something is broken and they should fix it; you