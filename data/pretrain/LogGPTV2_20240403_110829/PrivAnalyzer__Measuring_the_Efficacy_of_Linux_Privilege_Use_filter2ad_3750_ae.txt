rity improvement. The results in Table V show that this new
su cannot launch our four modeled attacks for at least 12% of
its execution. Furthermore, since ROSA is unable to deliver a
verdict on attacks 1 and 2 for privilege sets 6 and 7 within our
5 hour limit, we assume that our refactored su is invulnerable
to all the attacks for an additional 87% of its execution time.
This is because, as Section VIII discusses, ROSA’s analysis
often takes longer when attacks are impossible as ROSA must
search the entire state space. We believe our refactored su is
invulnerable for nearly 99% of its execution.
Looking at Table III, we see that su is vulnerable with all
the privilege sets except the empty one. The last privilege to
remain live is CAP_SETUID (Table III). Similar to passwd,
the PrivAnalyzer results help identify which privilege in-
creases the exposure to privilege escalation, helping guide the
developer on where to focus refactoring efforts.
E. Security Refactoring Lessons
Our refactoring work provides two key insights into writing
privileged applications on Linux:
a) Change Credentials Early: We observed that many
privileged operations in privileged programs simply require
that a process running as one user create or manipulate
resources e.g., processes and ﬁles, owned by one other user.
However, Linux privileges such as CAP_DAC_OVERRIDE
allow a process to manipulate ﬁles owned by any user.
A better approach is to use CAP_SETUID and CAP_SET-
GID to provide the process with two sets of credentials: one in
the real UID and GID and another in the saved UID and GID.
Fig. 5: Search time for passwd.
Fig. 6: Search time for ping.
601
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:13:55 UTC from IEEE Xplore.  Restrictions apply. 
sensitive system ﬁles. For example, a password-changing
program shouldn’t be able to read and write device ﬁles, but
it can on Ubuntu. Having different special users own different
ﬁles allows privileged programs to conﬁgure themselves to
only access the ﬁles that they need (as we did by changing
/etc/shadow to be owned by a special etc user).
VIII. PERFORMANCE EVALUATION
We now evaluate the performance of ROSA, PrivAnalyzer’s
bounded model checker, using the programs in Table II. We
perform our experiments on a Dell Precision 3620 workstation
with a 3.6 GHz Intel R(cid:2) i7-7770 processor, 16 GB of RAM,
and a 1 TB TOSHIBA DT01ACA1 hard disk running Ubuntu
16.04. We use the time system call to report the sum of user
and system time in seconds that ROSA takes to reach a verdict.
We run each test 10 times to compute the average search
time and the standard deviation. Figures 5, 6, 7, 8, and 9
show that, in most of the experiments, ROSA needs less than
2 seconds to reach a verdict. However, in one case (the one in
which su has dropped all of its privileges), ROSA takes almost
40 seconds to decide that su cannot read or write /dev/mem.
We believe this is due to the search space: for attacks like
those on /dev/mem, numerous system calls such as open(),
setresuid(), chown(), and chmod() are relevant. For
attacks that fail, ROSA must determine that all combinations
of executing these system calls does not lead to compromise.
In contrast, fewer system calls are relevant to attacks 3 and
4 which kill off other processes or bind to privileged ports,
providing ROSA a smaller state space to search.
Figures 10 and 11 show ROSA’s performance when ana-
lyzing the refactored passwd and su programs. In general,
ROSA takes longer to reach a verdict for the refactored pro-
grams. For example, ROSA takes almost 12 hours to determine
that the refactored passwd cannot write to /dev/mem when
it executes with privilege set 3 (as Table V shows). There
are cases in which the operating system kills ROSA due to
high memory consumption (3 days of execution), and we do
not get a response. We believe this behavior is due to the
large state space to explore. Attacks 1 and 2 involve a larger
Fig. 7: Search time for sshd.
Fig. 8: Search time for su.
The process can then switch the effective UID/GID between
the real UID/GID and the saved UID/GID without privilege.
This allows privileges such as CAP_SETUID and CAP_-
SETGID to be removed early in execution and often allows
privileges such as CAP_CHOWN, CAP_DAC_READ_SEARCH,
and CAP_DAC_OVERRIDE to be eliminated entirely.
b) Create Special Users for Special Files: On Ubuntu,
root owns many of the system conﬁguration ﬁles. Conse-
quently, running as one user provides access to nearly all
Fig. 9: Search time for thttpd.
Fig. 10: Search time for refactored passwd.
602
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:13:55 UTC from IEEE Xplore.  Restrictions apply. 
extract the minimal sets of programs that can lead to the
modeled attack. Although VulSAN can identify chains of
compromises between programs in a system, it cannot identify
the damage that a single program could cause on its own if
exploited. PrivAnalyzer analyzes the behavior of individual
programs to determine whether their use of privileges mitigates
the risks of privilege escalation attacks.
Vijayakumar et al. [27] evaluate the attack surface of a
program, i.e. the program entry points that are accessible to an
adversary. They use the operating system’s Mandatory Access
Control (MAC) policy to automatically separate program data
into two sets: 1) trusted, and 2) adversary controlled data.
Using runtime analysis, they collect the set of entry points
that access objects outside of the constructed trusted set. The
proposed method measures the attackability of a program,
i.e. how likely it
is that a program gets attacked in any
way. PrivAnalyzer measures the vulnerability window of a
program to an attack, i.e. how long the program is vulnerable
to a speciﬁed attack. While both systems evaluate important
security metrics, the former relies on a MAC scheme and
cannot model dynamic changes of access rights. PrivAnalyzer
evaluates the vulnerability of a program in a discretionary
access control system, accounting for dynamic changes in the
access control policy.
X. FUTURE WORK
Several interesting directions exist for future work. First,
we plan to enhance PrivAnalyzer to model additional operating
system privilege models, allowing us to compare their efﬁcacy.
For example, PrivAnalyzer could model Solaris privileges [28]
and Capsicum [5] and investigate whether they can provide
greater protection than Linux privileges.
Second, we will model additional attacks and defenses.
For example, our current evaluation assumes that attacks
can corrupt application control-ﬂow and data-ﬂow. With en-
hancements to PrivAnalyzer, we can model attacks that are
weakened due to defenses such as control-ﬂow integrity [29]
and code-pointer integrity [30] and determine what types of
attacks such a weakened attacker can perform.
XI. CONCLUSIONS
This paper presented PrivAnalyzer, an automated tool that
measures the risk that privileged programs can pose. PrivAna-
lyzer adds two new components to the AutoPriv compiler [11]:
the ChronoPriv vulnerability analyzer and the ROSA bounded
model checker. Using PrivAnalyzer, we measured the efﬁcacy
of using Linux privileges and showed that enabling, disabling,
and removing privileges from otherwise unmodiﬁed applica-
tions does not signiﬁcantly improve their security posture.
We then refactored two privileged Linux programs to better
leverage Linux privileges and used PrivAnalyzer to measure
the security improvement. From this exercise, we learned two
key approaches for using Linux privileges more effectively.
ACKNOWLEDGEMENTS
We thank the anonymous reviewers for their insightful feed-
back. This work was funded by NSF award CNS-1463870.
Fig. 11: Search time for refactored su.
number of system calls and UID/GID values. ROSA must try
every combination of UID/GID pairs in each system call to
determine that no combination of process UID/GID settings
and ﬁle ownership settings will permit the attack to succeed.
Given how quickly ROSA can ﬁnd solutions when attacks are
possible, we believe that the attacks are likely to fail when
ROSA cannot return an answer in reasonable time.
IX. RELATED WORK
Zanin et al. [9] propose an automatic tool for evaluating
security policy conﬁgurations for SELinux. SELinux [26] is
a system that allows an administrator to specify a set of
rules which the Linux kernel enforces when making access
control decisions. These rules enable the generation of security
policies which are ﬂexible yet difﬁcult for administrators to
reason about. To evaluate the efﬁcacy of an SELinux security
policy conﬁguration, Zanin et al. [9] formalize the semantics of
the conﬁguration constructs and expose the relationships that
occur among the conﬁguration rules. Based on the proposed
formal model entitled SELAC [9], they develop a tool that
decides whether access of a speciﬁc object by a given subject
under the conﬁgured policy is possible. Zanin et al. propose
a tool [9] that, similar to PrivAnalyzer, can reach verdicts
about the possibility of attacks allowed under a speciﬁc set
of conﬁguration rules. However, unlike our work, they do
not quantify the vulnerability window of the system under a
speciﬁc conﬁguration. In this work, we show that PrivAnalyzer
can evaluate hypothetical attacks at different points during
the dynamic execution of a program under different sets of
privileges. This evaluation led us to refactor a subset of these
programs and show that we can improve their security.
Chen et al. develop VulSAN [10], a tool that quantiﬁes
the quality of protection offered by mandatory access control
systems. Given an attack objective and the attacker’s initial
resources, VulSAN identiﬁes minimal sets of programs that,
if compromised, can lead to the attack succeeding. VulSAN
maps the security policies and the state of the system to
Prolog facts. VulSAN then generates a graph for each attack
scenario that is modeled. Each path in the graph is a sequence
of different program executions. VulSAN uses the graph to
603
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:13:55 UTC from IEEE Xplore.  Restrictions apply. 
REFERENCES
[1] M. E. Russinovich and D. A. Solomon, Microsoft Windows Internals,
Fourth Edition: Microsoft Windows Server(TM) 2003, Windows XP, and
Windows 2000 (Pro-Developer). Redmond, WA, USA: Microsoft Press,
2004.
[2] D. P. Bovet and M. Cesati, Understanding the LINUX Kernel, 2nd ed.
Sebastopol, CA: O’Reilly, 2002.
[3] M. K. McKusick, G. V. Neville-Neil, and R. N. M. Watson, The
Design and Implementation of the FreeBSD Operating System, 2nd ed.
Addison-Wesley Professional, 2014.
[4] J. L. Berger, J. Picciotto, J. P. L. Woodward, and P. T. Cummings,
“Compartmented mode workstation: Prototype highlights,” IEEE Trans.
Softw. Eng., vol. 16, no. 6, pp. 608–618, Jun. 1990.
[5] R. N. M. Watson, J. Anderson, B. Laurie, and K. Kennaway, “Capsicum:
Practical capabilities for UNIX,” in Proceedings of the 19th USENIX
Conference on Security, ser. USENIX Security’10. Berkeley, CA, USA:
USENIX Association, 2010, pp. 3–3.
[6] S. E. Hallyn and A. G. Morgan, “Linux capabilities: Making them work,”
in Proceedings of The Linux Symposium, Ottawa, Canada, July 2008.
[7] linuxcontainers.org, “Linux Containers,” https://linuxcontainers.org/,
[Online; accessed 28-March-2019].
[8] D. Documentation, “Docker,” https://docs.docker.com/engine/security/
security/, [Online; accessed 28-March-2019].
[9] G. Zanin and L. V. Mancini, “Towards a formal model for security
policies
speciﬁcation and validation in the selinux system,” in
Proceedings of the Ninth ACM Symposium on Access Control Models
and Technologies, ser. SACMAT ’04. New York, NY, USA: ACM,
2004, pp. 136–145. [Online]. Available: http://doi.acm.org/10.1145/
990036.990059
[10] H. Chen, N. Li, and Z. Mao, “Analyzing protection quality of
security-enhanced operating systems,” in Proceedings of
the 10th
Annual Information Security Symposium, ser. CERIAS ’09. West
Lafayette,
IN: CERIAS - Purdue University, 2009, pp. 8:1–8:1.
[Online]. Available: http://dl.acm.org/citation.cfm?id=2788357.2788369
[11] X. Hu, J. Zhou, S. Gravani, and J. Criswell, “Transforming code
to drop dead privileges,” in 2018 IEEE Cybersecurity Development
(SecDev), vol. 00, Sept 2018, pp. 45–52.
[Online]. Available:
doi.ieeecomputersociety.org/10.1109/SecDev.2018.00014
[12] M. Clavel, F. Dur´an, S. Eker, P. Lincoln, N. Mart´ı-Oliet, J. Meseguer, and
C. Talcott, All About Maude - a High-performance Logical Framework:
How to Specify, Program and Verify Systems in Rewriting Logic. Berlin,
Heidelberg: Springer-Verlag, 2007.
[13] Argus Systems Group, Inc., “Security features programmer’s guide,”
Savoy, IL, September 2001.
[14] Solar Designer, “return-to-libc attack,” August 1997, https://insecure.
org/sploits/linux.libc.return.lpr.sploit.html [Online; accessed 11-March-
2019].
[15] S. Chen, J. Xu, E. C. Sezer, P. Gauriar, and R. K. Iyer, “Non-
control-data Attacks Are Realistic Threats,” in Proceedings of the 14th
USENIX Security Symposium (SEC), Baltimore, MD, 2005, pp. 12–12.
[Online]. Available: http://dl.acm.org/citation.cfm?id=1251398.1251410
[16] N. Provos, “Improving host security with system call policies,” in 12th
USENIX Security Symposium, August 2003.
[17] A. One, “Smashing the Stack for Fun and Proﬁt,” Phrack, vol. 7, Novem-
ber 1996, http://www.phrack.org/issues/49/14.html [Online; accessed 11-
March-2019].
[18] H. Shacham, “The Geometry of Innocent Flesh on the Bone: Return-
into-libc without Function Calls (on the x86),” in Proceedings of the 14th
ACM SIGSAC Conference on Computer and Communications Security
(CCS), Alexandria, VA, October 2007, pp. 552–561.
[19] C. Lattner and V. Adve, “LLVM: A compilation framework for
lifelong program analysis & transformation,” in Proceedings of
the
International Symposium on Code Generation and Optimization:
Feedback-directed and Runtime Optimization, ser. CGO’04. Palo Alto,
CA: IEEE Computer Society, 2004, pp. 75–86. [Online]. Available:
http://dl.acm.org/citation.cfm?id=977395.977673
[20] C. Lattner et al., “LLVM Language Reference Manual,” January 2016.
[Online]. Available: http://releases.llvm.org/3.7.1/docs/LangRef.html
[21] “Linux programmer’s manual: mem(4),” November 1992.
[22] S. Checkoway, L. Davi, A. Dmitrienko, A.-R. Sadeghi, H. Shacham,
and M. Winandy, “Return-oriented Programming Without Returns,” in
Proceedings of the 17th ACM SIGSAC Conference on Computer and
Communications Security (CCS), Chicago, IL, October 2010.
[23] K. Z. Snow, F. Monrose, L. Davi, A. Dmitrienko, C. Liebchen, and
A.-R. Sadeghi, “Just-In-Time Code Reuse: On the Effectiveness of
Fine-Grained Address Space Layout Randomization,” in Proceedings
the 34th IEEE Symposium on Security and Privacy (S&P),
of
San Francisco, CA, May 2013, pp. 574–588. [Online]. Available:
http://dx.doi.org/10.1109/SP.2013.45
[24] D. A. Wheeler, “SLOCCount Version 2.26,” 2004.
[25] “Apachebench: A complete benchmarking and regression testing suite.
http://freshmeat.net/projects/apachebench/,” July 2003.
[26] S. Smalley, “Conﬁguring the selinux policy,” NSA, Tech. Report,
February 2005.
[27] H. Vijayakumar, J. Schiffman, and T. Jaeger, “Integrity walls: Finding
attack surfaces from mandatory access control policies,” in 7th ACM
Symposium on Information, Computer, and Communications Security
(ASIACCS), May 2012.
[28] J. Mauro and R. McDougall, Solaris Internals: Core Kernel Architecture.
Prentice Hall PTR, 2000.
[29] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti, “Control-
implementations, and applications,” ACM
ﬂow integrity principles,
Transactions on Information Systems Security, vol. 13, pp. 4:1–
4:40, November 2009. [Online]. Available: http://doi.acm.org/10.1145/
1609956.1609960
[30] V. Kuznetsov, L. Szekeres, M. Payer, G. Candea, R. Sekar, and D. Song,
“Code-pointer integrity,” in Proceedings of the 11th USENIX Conference
on Operating Systems Design and Implementation, ser. OSDI’14.
Berkeley, CA, USA: USENIX Association, 2014, pp. 147–163.
[Online]. Available: http://dl.acm.org/citation.cfm?id=2685048.2685061
604
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:13:55 UTC from IEEE Xplore.  Restrictions apply.