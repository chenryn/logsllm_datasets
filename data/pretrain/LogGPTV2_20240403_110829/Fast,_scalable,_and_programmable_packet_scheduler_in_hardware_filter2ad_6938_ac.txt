network hardware devices as an avenue for future work.
4 THE EXPRESSIVENESS OF PIEO
In this section, we use the PIEO primitive and the programming
framework described in §3 to express a wide range of packet sched-
uling algorithms. Without loss of generality, the pseudo code for
the programming functions presented in this section assumes the
output-triggered model described in §3.2.1.
4.1 Work-conserving algorithms
Deficit Round Robin (DRR) [34]. DRR schedules flows in a round-
robin fashion. When a flow is scheduled, DRR transmits packets
from the flow until the flow runs out of credit (deficit_counter).
post-dequeue-func(flow f): {
f.deficit_counter += f.quanta
while (f.queue not empty
& f.deficit_counter ≥ size(f.queue.head)):
f.deficit_counter -= size(f.queue.head)
send(f.queue.head)
if (f.queue empty): f.deficit_counter = 0
else: pre-enqueue-func(f)
}
other functions: default as described in §3.2.1
Weighted Fair Queuing (WFQ) [13]. WFQ calculates a virtual
finish time for each packet in a flow, and at any given time, schedules
the flow whose head packet has the smallest finish time value.
pre-enqueue-func(flow f): {
r = Link_Rate / f.weight
# rate for flow f
f.finish_time = max(f.finish_time, virtual_time)
+ (size(f.queue.head) / r)
f.rank = f.finish_time
f.predicate = True
ordered_list.enqueue(f)
}
post-dequeue-func(flow f): {
virtual_time += (size(f.queue.head) / Link_Rate)
rest is default as described in §3.2.1
}
other functions: default as described in §3.2.1
Worst-case Fair Weighted Fair Queuing (WF2Q+) [5]. WF2Q+
calculates a virtual start and finish time for each packet in a flow,
and at any given time, schedules the flow whose head packet has
the smallest finish time value amongst all the flows whose head
packet has the start time less than or equal to current virtual time.
pre-enqueue-func(flow f): {
calculate f.start_time as in Fig. 2(a)
calculate f.finish_time as in Fig. 2(a)
f.rank = f.finish_time
f.predicate = (virtual_time(at deq) ≥ f.start_time)
ordered_list.enqueue(f)
}
post-dequeue-func(flow f): {
calculate virtual_time as in Fig. 2(a)
rest is default as described in §3.2.1
}
other functions: default as described in §3.2.1
4.2 Non-work conserving algorithms
Token Bucket (TB) [50]. TB schedules packets from eligible flows,
i.e., flows with enough tokens, or else defers the scheduling of the
flow to some future time by when the flow has gathered enough
tokens.
pre-enqueue-func(flow f): {
f.tokens += f.rate * (now - f.last_time)
if (f.tokens > f.burst_threshold):
f.tokens = f.burst_threshold
if (size(f.queue.head) ≤ f.tokens):
send_time = now
else:
send_time = now +
(size(f.queue.head) - f.tokens) / f.rate
f.tokens -= size(f.queue.head)
f.last_time = now
f.rank = send_time
f.predicate = (wall_clock_time(at deq) ≥ send_time)
ordered_list.enqueue(f)
}
other functions: default as described in §3.2.1
Rate-controlled Static-Priority Queuing (RCSP) [53]. This class
of algorithms shape the traffic in each flow by assigning an eligi-
bility time to each packet within the flow, and at any given time,
schedules the highest priority flow amongst all the flows with an
eligible packet at the head of the queue.
pre-enqueue-func(flow f): {
send_time = f.queue.head.time
f.rank = f.priority
f.predicate = (wall_clock_time(at deq) ≥ send_time)
ordered_list.enqueue(f)
}
other functions: default as described in §3.2.1
4.3 Hierarchical scheduling
So far we have only discussed flat scheduling. However, in practice,
it is often desirable to group flows into a hierarchy of classes, e.g.,
a two-level hierarchy comprising a group of VMs, with a group
of flows within each VM. In this example, the link bandwidth can
be shared amongst the VMs using some scheduling policy, e.g., a
rate-limit for each VM, while one can use a different scheduling
372
Fast, Scalable, and Programmable Packet Scheduler in Hardware
SIGCOMM ’19, August 19–23, 2019, Beijing, China
Figure 4: Hierarchical packet scheduling in PIEO.
policy to schedule the flows within each VM, e.g., fair queuing. In
general, we can represent such hierarchies using a tree structure,
as shown in Fig. 4, where the leaf nodes represent the flows, while
the non-leaf nodes represent higher-level classes, such as VMs.
Unfortunately, since each non-leaf node can implement it’s own
custom scheduling policy to schedule it’s children, a single PIEO is
not sufficient to express hierarchical scheduling policies. However,
we can support hierarchical scheduling using multiple PIEOs.
We associate each node in the tree (except the root node) with a
queue—for leaf nodes, these are per flow FIFO queues storing the
packets, while for non-leaf nodes, these are logical queues, which are
references to the set of child queues for that node. Next, we associate
each non-leaf node with a logical PIEO, which schedules the node’s
children. Since PIEO allows us to filter a subset of elements from
an ordered list using a predicate, all the nodes at the same level
of hierarchy can share the same physical PIEO, which can then
be logically partitioned into a set of logical PIEOs, one for each
node at the same level in the hierarchy, with the size of each logical
PIEO equal to number of corresponding node’s children (Fig. 4).
Next, each non-leaf node p maintains the start and end indices of
it’s logical PIEO and the eligibility predicate of each of it’s child
element f is extended with (p.start ≤ f.index ≤ p.end), thus allowing
one to extract the ordered list of elements in p’s logical PIEO (p’s
children) from the physical PIEO.
Enqueue in each level happens independently and is triggered by
the same conditions as for flat scheduling, e.g., packet enqueue into
an empty queue (§3.2.1). Dequeue always starts at the root PIEO,
and propagates down to the lower levels in the tree hierarchy. Each
lower level PIEO is associated with a FIFO to store the dequeued ids
from the parent level. Dequeue at a level i is triggered whenever the
corresponding FIFO in not empty. The logical PIEO corresponding
to node fifo.head is then extracted, and the smallest ranked eligible
element in the logical PIEO is dequeued and put into the FIFO at
level i − 1, until we reach the lowest non-leaf level, at which point
the dequeued element (a leaf node representing a flow) is scheduled
for transmission. All this is demonstrated in Fig. 4.
Finally, to support n−level hierarchical scheduling with arbitrary
tree topologies, we need n physical PIEOs. We map this hierarchy
to the hardware as an array of n independent physical PIEOs with
a FIFO as the interface between any two consecutive PIEOs in the
arraylist (Fig. 4).
4.4 Asynchronous scheduling
Starvation avoidance in strict priority scheduling. A common
way to avoid starvation of lower priority flows in a strict priority
based scheduling algorithm is to periodically increase the priority
of the flow being starved. This is generally triggered whenever
a flow has spent time larger than some threshold without being
scheduled. Assuming flows are ranked by their priority in PIEO, one
can define an alarm function and handler that can asynchronously
update the starving flow’s priority to avoid starvation.
async_event e = (curr_time - f.age ≥ threshold)
alarm-func(async_event e): ordered_list.dequeue(f)
alarm-handler(flow f): {
f.age = curr_time
f.priority = f.priority - 1
pre-enqueue-func(f)
}
Scheduling based on asynchronous network feedback. Cer-
tain datacenter protocols such as [51, 12] can result in change of
a flow’s rank or eligibility based on some asynchronous feedback
from the network. E.g., in D3 [51], already scheduled flows can be
quenched asynchronously based on network feedback.
async_event e = receipt of pause or resume feedback
alarm-func(async_event e): {
if (recvd pause feedback for flow f):
f.block = True
ordered_list.dequeue(f)
if (recvd resume feedback for flow f):
f.block = False
pre-enqueue-func(f)
}
alarm-handler(flow f): default as described in §3.2.1
4.5 Priority scheduling
Several scheduling algorithms assign a priority to each element,
and schedule elements in the order of their priority. Examples
include Shortest Job First (SJF) [47], Shortest Remaining Time First
(SRTF) [48], Least Slack Time First (LSTF) [45], and Earliest Deadline
First (EDF) [44]. Such algorithms can be expressed using a priority
queue datastructure. One can easily emulate a priority queue using
PIEO, by setting the rank of each element as equal to it’s priority
value, and setting the eligibility predicate of each element as true.
373
123f1f2f3f4f5f6132f6f4f3f1f213f6f4f3f1f22123f6f4f1f2node 2’s logical PIEOextractedusing predicateenqueue in L1 PIEOtriggered by enqueuein empty f6 queuedequeue triggered atL2 PIEOwhen link is idlepkt scheduledpkt enqueued in f61b2a2b1aFIFOFIFOFIFORootdequeue at L1 PIEOf3 scheduled for transmissionenqueue in L2 PIEOas the logical queuefor 2 not emptyafter dequeueL1L22elogicalqueuef1f2f3f4f5f6Single PIEOFlat schedulerHierarchical schedulerf4f6f1f3f2Rootper ﬂow FIFO queues123RootRootRoot112233logical PIEOfor node 1enqueue in L2 PIEOtriggered by enqueuein empty logical queuefor 31c(2.start <= f.index <= 2.end)2c2dEnqueueDequeueSIGCOMM ’19, August 19–23, 2019, Beijing, China
Figure 5: PIEO scheduler hardware architecture. A priority
encoder takes as input a bit vector and returns the smallest
index containing 1.
5 HARDWARE DESIGN
"All problems in computer science can be solved by another level of
indirection."
— David Wheeler
In this section, we describe the hardware design of PIEO scheduler.
We assume that the target hardware device is equipped with
SRAM. Further, we assume that SRAM is divided into multiple
blocks, and each SRAM block comprises independent access ports.
Such a memory layout is very common in hardware devices, e.g.,
Stratix V FPGA [17] used in our prototype (§6) comprise ∼2500
dual-port SRAM blocks of size 20 KBits each, where each SRAM
block has access latency of one clock cycle.
5.1 Architecture
PIEO scheduler comprises an ordered list, that supports three prim-
itive operations (§3.1)—enqueue(f), dequeue(), and dequeue(f). How-
ever, implementing an ordered list in hardware presents a funda-
mental trade-off between time complexity and hardware resource
consumption. To keep up with increasing link speeds, we want to
execute each primitive operation atop the ordered list in O(1) time.
However, to achieve this, state-of-the-art designs such as PIFO [37]
require parallel access to each element in the list using the clas-
sic parallel compare-and-shift architecture [29], and hence have
to store the entire list in flip-flops (as opposed to a more scalable
memory technology such as SRAM), and associate a comparator
with each element. Thus, such a design requires O(N) flip-flops and
comparators for a list of size N , and with the slowdown in transistor
scaling [11, 14], this limits the scalability of such a design.
In this paper, we present a design of the ordered list that still
executes primitive operations in O(1) time, but only needs to access
and compare O(√
N) elements in parallel, while the ordered list sits
entirely in SRAM. The key insight we use is to store and access the
ordered list using one level of indirection (Fig. 5). More specifically,
the ordered list is stored as an array (of size 2√
N ) of sublists in
SRAM, where each sublist is of size √
N elements. Elements within
each sublist are ordered by both increasing rank (Rank-Sublist), and
increasing order of eligibility time (Eligibility-Sublist). We stripe
374
Vishal Shrivastav
the elements of each sublist across O(√
N) dual-port SRAM blocks,
which allows us to access two entire sublists in one clock cycle.
Next, we maintain an array (of size 2√
N ) in flip-flops, which stores
the pointers to the sublists, with sublists in the array ordered by
increasing value of the smallest rank within each sublist. Thus,
by sweeping across the sublists in the order they appear in the
pointer array, one can get the entire list of elements in the order of
increasing rank.
Enqueue and dequeue operations proceed in two steps—First,
we figure out the right sublist to enqueue into or dequeue from,
using parallel comparisons and priority encoding on the pointer
array, and then extract the corresponding sublist from SRAM. Sec-
ond, we use parallel comparisons and priority encoding on the
extracted sublist to figure out the position within the sublist to