Brand
Similar
Fake_TLD
Pop_Keywords
Entropy
Brand_In_Path
Similar_In_Path
URL length
#Query_Params
Table 6: Attacker-Owned/Compromised Apex Classiﬁer Features
Description
VT Report Features
Novel
The duration between the ﬁrst and the last time the URL is scanned in VT
The response code returned for the website as reported in VT report
The length of the content as reported in VT report
Is the ﬁnal URL different from the original URL as reported in VT report?
The number of scanners detected the URL as malicious
Is the domain of the URL marked as malicious in VT?
VT Proﬁle Features
The number of times the domain is scanned earlier (extracted from VT NOD)
The number of times the domain is marked as benign earlier
The number of subdomains marked malicious by previous VT reports
PDNS (Hosting) Features
The length of the domain footprint seen in PDNS
The number of authoritative NS in which the domain was hosted
The number of lookups recorded for the domain in PDNS
The number of SOA domains under which the domain was hosted
Is the apex of the domain the same as the apex of the SOA domain?
Lexical Host Features
The number of levels in the subdomain part of the FQDN
The number of dashes appear in the FQDN
Does it impersonate a popular Alexa top 1000 brand?
Does the domain contain words within Levenshtein distance 2 of a popular Alexa top brand?
Does the domain name include a fake gTLD (com, edu, net, org, gov)?
Does the domain name include popular keywords?
The entropy of the FQDN
Lexical Path Features

[62]
[62]
[42]





[29]
Derived from [41]
[29]


[44]
[44]
Derived from [38]
Derived from [38]
Derived from [57]
Derived from [38]
[24, 25]
Does the path have an Alexa top 1000 brand name(s)?
Does the path contain words within Levenshtein distance 2 of a popular Alexa top brand?
The length of the URL
The number of query parameters in the URL
Alexa Features
Derived from [38], [45]
Derived from [38], [45]
[44, 46, 47]
[40]
Alexa_Rank_Avg
Is_In_Alexa_1Year
The average Alexa rank during the study period
Does the apex appear consistently in Alexa Top 1M throughout the previous year?
[52]
Derived from [58]
reasons. First, attackers try to ride on the reputation of com-
promised domains, which are also often long lived. Malicious
domains deployed over compromised private apexes thus are
more evasive and hard to detect by current reputation systems.
Second, many private apex domains are not well maintained
or patched in time. Compromised private apex domains are
abundant and become more economically favorable for at-
tackers than setting up their own apex domains, which could
incur cost during domain registration.
This observation is consistent with prior work done on
phishing websites [30] and public threat intelligence re-
ports [4, 19]. Yet, our study is not limited to a speciﬁc type
of malicious URLs. Instead, it covers a variety of malicious
domains with a much larger scale, utilizing a more compre-
hensive dataset collected from VT.
Figure 10 shows the average Alexa rank distribution for
compromised and attacker-owned apex domains. As expected,
most of the attacker-owned domains have either low Alexa
ranking or no rank. However, it is interesting to see that there
are some attacker-owned domains with Alexa ranking below
100K. Another interesting observation is that about 10% of
compromised private apexes are not ranked, indicating that
attackers launch attacks from less popular benign websites as
Figure 9: ROC Curves for RF Compromised/Attacker-Owned
Classiﬁers
5.2.4 Observations
Following the pipeline shown in Figure 2, we applied the
above classiﬁcation model and labeled all the 725,325 pri-
vate apex domains in DS1 and DS2 that host malicious URLs
with #scanners ≥ 5. We observe that 65.6% of such private
apex domains are classiﬁed as compromised, indicating that
attackers utilize more compromised apex domains than cre-
ating their own apex domains, which could be due to several
3730    30th USENIX Security Symposium
USENIX Association
well, which could be utilized to launch attacks such as DDoS
that do not require reputable sites.
Figure 10: Average Alexa Ranking for Compromised and
Attacker-Owned Domains
Figure 11 shows the number of days from the registration
to ﬁrst malicious behavior during our study period. The ﬁrst
malicious behavior is approximated as the ﬁrst VT report
indicating a website is malicious and thus it provides an up-
per bound on how soon attackers utilize these websites after
registration. 20% of attacker-owned domains are utilized to
launch attacks soon after they are registered. However, many
other domains are utilized several months after registration,
necessitating one to have detection mechanisms in place be-
yond the initial registration period. This behavior is consistent
with the trend that attackers park their domains before using
them to launch attacks so that they can evade detection by
many existing reputation based systems. A concerning fact
is that benign domains on the other hand gets compromised
several years after they are registered. Frequent reasons for
such delayed compromise are that some technologies utilized
in unmaintained benign websites become outdated and/or
servers on which they are deployed are not upgraded over
time, making them easy targets for attackers.
Figure 11: #Days from Registration to First Malicious Behav-
ior During the Study Period
5.3 Attacker-Owned/Compromised
Website Classiﬁer
Public
In this section, we further categorize those URLs hosted
in public apexes as attacker-owned or compromised. Note
that different from the classiﬁer for private apex do-
mains, this classiﬁer is not
to classify a public apex
domain, but its subdomains that could be either preﬁx-
based (e.g., alice.000webapphost.com) or sufﬁx-based (e.g.,
sites.google.com/site/alice). For brevity, we call them public
websites.
5.3.1 Ground Truth Collection
We manually create from DS1 a ground truth set of com-
promised and attacker-owned public websites AC-P-GT. We
check the content of a public website to determine if the
website is created by attackers or compromised. Further,
some public apex services such as 000webapphost.com and
blogspot.com identify and block some attacker-owned web-
sites. We use this information to collect additional attacker-
owned public websites. In total we collect 613 compromised
public websites and 1157 attacker-owned public websites.
5.3.2 Feature Engineering
We utilize all features in Table 6 except the hosting features
Name_Servers, SOA_Domains_Nos and SOA_Domain as
public websites from a given apex domain often have similar
hosting infrastructures managed by the apex domain owner.
It should be noted that unlike in the private apex classiﬁer,
features are extracted at subdomain or path sufﬁx level as
our goal is to classify public websites, not apexes. Further,
we utilize the additional path features listed in Table 7. We
noticed that most long lived public websites (like blogs) have
many associated pages (URLs), but attacker-created ones are
usually short lived and tend not to create many pages to launch
their attacks. The feature #URLs captures this difference.
Variations in the paths belonging to a given public website are
captured by features Std_Path_Depth and Std_Query_Params,
as compromised public websites are likely to create paths
quite different from those created by attackers.
5.3.3 Model Training and Observations
We train a RF classiﬁer with a balanced dataset. We achieve
an accuracy of 97.2% with 97.2% precision and 98.1% recall
with 10-fold cross validation. Figure 12 shows the ROC curve
for this classiﬁer.
We then utilize this classiﬁer to label the remaining public
websites in DS1. We observe that, unlike private apexes, at-
tackers primarily create their own subdomains or path preﬁxes
on public domains (80.5%). We attribute this difference to the
low cost associated with creating public websites.
USENIX Association
30th USENIX Security Symposium    3731
Table 7: Additional features for the public website classiﬁer
Feature Name
#URLs
Std_Path_Depth
Std_Query_Params
The number of URLs corresponding to the website.
Standard deviation of the path depth of URLs belonging to the website.
Standard deviation of the number of query parameters for each URL belonging to the website.
Description
Novel
Derived from [52]


6 Classiﬁer Analysis
We have shown so far the features of the three classiﬁers and
their classiﬁcation accuracy over the malicious URL datasets
collected from VT. In this section, we perform further analysis
of their properties, including how well they could be general-
ized to URL intelligence beyond VT, their robustness against
feature manipulation, the impact when the training data are
noisy or of a smaller scale, and how they compare with cur-
rent industrial practices. Due to space limit, we focus our
analysis on the classiﬁer that classiﬁes private apex domains
as compromised or attacker-owned (see Section 5.2).
6.1 Applicability to Other URL Intelligence
Sources
Our discussion so far is based on the data collected from VT.
Indeed some of the features for the private apex classiﬁer are
also speciﬁc to VT. It raises the question whether our approach
could be applied with other URL intelligence sources. In this
section, we show how our methodology can be adapted to
work with other intelligence feeds. In particular, we adapt our
approach to build a private apex classiﬁer over the data from
Phishtank. Phishtank makes a veriﬁed list of phishing URLs
every hour. We take the list of URLs appeared in our second
study period from Nov 1 2019 to Nov 14 2019.
Ground Truth Collection: We collect 7756 URLs from
Phishtank during the study period. First we ﬁlter the public
apex domains by passing the URLs through our public/private
classiﬁer. This results in 6377 private phishing URLs and
2804 private apex domains. Following a process similar to the
GT collection for the private AC/C classiﬁer, out of the 2804
private apex domains, we collect 183 compromised domains
and 392 attacker-owned domains.
Feature Extraction: We collect all features except VT
proﬁle features mentioned in Table 6, as they are speciﬁc to
VT and are not appliable for Phishtank.
Model Training: Similar to other classiﬁers, we train a RF
classiﬁer with a balanced dataset. We achieve an accuracy
of 91.2% with 93.5% precision and 93.5% recall, which is
comparable to the accuracy achieved over the VT dataset.
Figure 13 shows the ROC curve for this classiﬁer.
The performance is slightly lower than that for the private
AC/C classiﬁer for VT URLs. We attribute this difference to
smaller dataset sizes as well as the reduced number of features
utilized. We believe the performance could be improved by
utilizing additional features such as registration information
and certiﬁcate information.
Figure 12: ROC Curve for RF Public Compromised/Attacker-
Owned Classiﬁer
We analyze the Alexa ranking associated with the identiﬁed
attacker-owned/compromised public websites. As expected,
only a small fraction (2.28%) of public malicious websites
in DS1 made it to Alexa top 1M during the attack time pe-
riod. However, it is interesting to observe that during this time
more compromised public websites (6.87%) are observed in
Alexa top list compared to 1.17% of attacker-owned websites.
Further, compromised ones stayed in the Alexa top list longer
than attacker-owned ones (6.8 vs. 2.9 days). These observa-
tions indicate that even though compromised public websites
are the minority, the damage they may cause is higher than
that of attacker-owned public websites.
5.4 Summary of Attack Types
Table 8 summarizes the distribution of attack types classiﬁed
by our two-step classiﬁcation of URLs. In the ﬁrst step, we
classify apex domains as public and private. In the second
step, we classify private apexes as compromised and attacker-
owned apexes, and websites of public apexes as compromised
and attacker-owned, which include both preﬁx based subdo-
mains and sufﬁx based paths.
Table 8: Distribution of Attack Types in our Dataset
Type
Malicious
Compromised
Attacker-Owned
Public
1% Apexes
46.5% URLs
20.5% Sites
79.5% Sites
Private
99% Apexes
53.5% URLs
65.6% Apexes
34.4% Apexes
3732    30th USENIX Security Symposium
USENIX Association
is reduced by only 0.9% and 4.2% respectively. Further, there
seems to be a linear correlation with the noise level and the
classiﬁer accuracy. When a signiﬁcant portion of the training
data is mislabeled (e.g., 15%), the classiﬁer accuracy drops
greatly.
(a) AC-GT1
(b) AC-GT2
Figure 14: Performance with Noisy Labels
Impact of the Size of Training Data
6.4