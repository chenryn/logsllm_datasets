known data throughout microarchitectural buffers by repeat-
edly loading and storing that data to different virtual addresses
and memory types. The victim can either be a separate applica-
tion running on the sibling CPU thread or running time-sliced
on the same thread, e.g., using multithreading.
During synthesis, Transynther randomly chooses, mutates,
and combines building blocks for 1 and 2 . To prepare the
microarchitecture ( 1 ), Transynther randomly chooses an op-
eration (load, store, or ﬂush) and an address from the load-
target pool. Then, the address is mutated by adding a random
offset between 0 B and 4 kB. This ensures that the address
still maps to the same page in most cases, however, to the
page offset of a different cache line. Note that there is the case
that a multi-byte load might lead to a split-page load if parts if
the offset is too large. We intentionally allow this behavior, as
split-page loads are also corner cases that may trigger leakage.
For 2 , Transynther randomly chooses a load operation and a
load target. Similarly, a randomly chosen offset between 0 B
and 4 kB is added to the load target address.
Transynther also randomly inserts independent operations
between the preparation of the microarchitecture ( 1 ) and
the faulting load ( 2 ). Such operations are, e.g., nops (no op-
erations), ALU operations on unrelated registers, as well as
additional architectural faults. These instructions add a certain
amount of timing differences and thus increase the chance of
triggering a race condition in the pipeline. These operations
have been shown to increase the leakage rate for existing
1430    29th USENIX Security Symposium
USENIX Association
attacks, as observed in the published proof-of-concept imple-
mentations for other transient-execution attacks [39, 52].
Finally, Transynther adds another load operation consum-
ing the value of the faulting load in 2 and encoding it into the
cache. This operation simply accesses the nth page in a 256-
page array, where n is the byte value provided by the faulting
load in 2 [11, 39]. Again, Transynther randomly inserts in-
dependent operations between this step and the faulting load
to vary the timing between 2 and 3 .
3.2 Evaluation Phase
In the evaluation phase, Transynther evaluates whether the
synthesized code snippets from the synthetisation phase lead
to data leakage. Transynther uses an evaluation framework
consisting of a preparation part that ﬁlls microarchitectural
buffers, the synthesized code snippet augmented with excep-
tion suppression, and a Flush+Reload loop to recover the
values encoded in 3 . The code in the evaluation framework
is executed in an endless loop for a user-speciﬁed amount
of time, e.g., 2 seconds. The values recovered using Flush+
Reload are compared to the known values from the prepa-
ration part. For every evaluated snippet, Transynther logs
the number of correct and wrong leaked values. Snippets for
which correct leakage is detected are candidate snippets used
in the classiﬁcation phase. Snippets that do not leak correct
values are discarded and not further analyzed. In contrast to
traditional application fuzzing, there is no feedback in our
approach enabling Transynther to improve a snippet. The only
feedback that the CPU provides is whether the snippet leaks
data or not. Moreover, as we try to discover vulnerabilities in
the microarchitecture, we cannot use a CPU emulator [42].
3.3 Classiﬁcation Phase
In the ﬁnal phase, Transynther analyzes the source of the
leakage using microarchitectural buffer grooming,and perfor-
mance counters.
Microarchitectural Buffer Grooming. The main idea of mi-
croarchitectural buffer grooming is to put microarchitectural
buffers into a known state. To achieve this, we ﬁll every mi-
croarchitectural buffer with known data that is unique for
each buffer. Hence, if any leakage is observed, the leakage
source can be inferred from the values. In the simplest case,
each buffer contains a repeated, single printable character.
For example, by storing several ‘S’-characters, we “ﬁll” the
store buffer with this character. If we then leak multiple ‘S’-
characters, we can consider the store buffer as a potential leak-
age source. By having a unique character per buffer, buffer
grooming provides an elementary form of data taint track-
ing [4]. In the case of data leakage, Transynther at least knows
the origin of the data.
For buffer grooming, we only consider on-core data buffers,
i.e., the L1 data cache, store buffer, line-ﬁll buffers, load buffer,
load ports, and WC buffers. While buffer grooming is straight-
forward for certain buffers, e.g., the L1 cache, it is more difﬁ-
cult for other buffers, e.g., the line-ﬁll buffer. Fortunately, Intel
provides software sequences for mitigating some of the MDS
attacks if microcode update cannot be used. These software
sequences are designed to zero-out the data in all microarchi-
tectural data buffers [24], i.e., it sets the values in all buffers
to a known value of zero.
lfence
1 mov %[scratch], %rdi
2
3 orpd (%[zero_ptr]) , %xmm0
4 orpd (%[zero_ptr]) , %xmm0
5 xorl %eax, %eax
6 1: clﬂushopt
7 addl $8, %eax
8 cmpl $8∗12, %eax
5376(%[scratch],%rax,8)
jb 1b
9
10 sfence
11 movl $6144, %ecx
12 xorl %eax, %eax
13 rep stosb
14 mfence
Listing 1: Software sequence to overwrite all microarchitec-
tural buffers for Skylake and newer microarchitectures [24].
Listing 1 shows the software sequence used to zero-out the
buffers on Skylake and newer microarchitectures. In Lines 3
to 4, the load ports are zeroed out. Then, 12 cache lines are
ﬂushed (Line 6) to ensure that 12 of the subsequent writes in
Line 13 have to go through the 12 line-ﬁll-buffer entries [52].
Using rep stosb additionally ensures that the WC-buffer
entries of the line-ﬁll buffer are also used, and thus zeroed-
out. For buffer grooming, we can rely on an adapted software
sequence. Instead of writing zero to all buffers, we write a
repeated, unique character to every buffer. This is as simple as,
e.g., letting zero_ptr point to a memory content not contain-
ing 0 but ‘L’-characters to ensure that load port is overwritten
with repeating ‘L’s. Moreover, we can replace the rep stosb
with a normal mov in a loop to distinguish WC buffers from
general line-ﬁll buffers.
The obvious limitation is that Transynther cannot track
the actual ﬂow of the data in hardware. For example, data
in the store buffer could have already been written to the L1
cache and subsequently been leaked from the L1 cache. Still,
for Transynther it looks as if the data was leaked from the
store buffer. To reduce the number of false classiﬁcations, we
additionally rely on hardware performance counters.
Performance Counters. To gain additional insight on the
leakage source, we augment Transynther with the ability to
record hardware performance counters while leaking val-
ues. Thus, in addition to the source of the leaked values, we
also observe the active microarchitectural elements. Table 1
shows the performance counters we used.Some of these per-
formance counters have already been shown to successfully
identify leakage sources [30, 52]. Transynther correlates the
USENIX Association
29th USENIX Security Symposium    1431
Table 1: The performance counters used in Transynther to
identify the active microarchitectural elements.
Counter
MEM_LOAD_RETIRED.FB_HIT
MEM_LOAD_RETIRED.L1_HIT
MEM_LOAD_RETIRED.L2_HIT
L1D_PEND_MISS.FB_FULL
LD_BLOCKS.STORE_FORWARD
LD_BLOCKS_PARTIAL.ADDRESS_ALIAS Load blocked by partial address match.
MEM_INST_RETIRED.SPLIT_LOADS
Description
Data loaded from a line-ﬁll-buffer entry.
Data loaded from the L1 data cache.
Data loaded from the L2 data cache.
Data is neither in L1 nor in ﬁll buffer.
Store buffer blocks load.
Data spans across two cache lines.
performance-counter values with the number of leaked bytes
using the Pearson correlation coefﬁcient (Figure 8 in Ap-
pendix B). A high positive correlation between the number of
leaked bytes and the events for a microarchitectural element
indicates that this element is involved in the leakage. With
microarchitectural buffer grooming and the correlation coefﬁ-
cient from the performance counters, Transynther can provide
an educated guess of the leakage source.
3.4 Transynther Results
In our ﬁrst set of experiments on Intel CPUs, we ran Tran-
synther for about 46 500 test cases distributed on the three
Intel Core i7-7700 (Kaby Lake), i7-8650U (Kaby Lake R),
and i9-9900K (Coffee Lake) CPUs. We ran each test case for
2 s, totaling about 26 CPU hours. Transynther generated 5100
code snippets, which showed transient leakage. Based on the
classiﬁcation and subsequent manual analysis, we ﬁltered the
generated code snippet to 100 interesting cases with a unique
code and leakage pattern. We identiﬁed multiple classes of
leaking code sequences, as described in Section 3.4.1.
We also ran some tests on an AMD Ryzen 5 2500U and
show that while there is no data leakage on AMD, AMD is
not by-design immune to the root cause of Meltdown-type
attacks. In our second experiment, we ran Transynther for
about 10 000 test cases on an AMD machine. Similarly, we
ran each test case for 2 s, totaling about 5 CPU hours. We
report our ﬁndings in Section 3.4.2.
3.4.1 Intel
Split Cache Access. Transynther reproduced various variants
of split cache access that lead to MLPDS. Split accesses re-
fer to memory accesses that span over two cache lines and
are handled differently from normal loads accessing a sin-
gle cache line. In the generated proof of concepts, we can
observe that when split access is suffering a faulty load, it
directly leaks the data that is loaded by the sibling CPU thread
( 1 ). Split access works for page faults (user-accessible and
present), as well as for microcode assists caused by setting the
accessed bit. We only saw MLPDS leakage on Kaby Lake and
Kaby Lake R but not on the Coffee Lake microarchitecture.
Another observation is that MLPDS with split access works
much faster when there is a page fault caused by accessing a
non-present page before the target faulty load2. In contrast,
a page fault caused by accessing a non-user-accessible page
does not increase the leakage rate. Split accesses can also be
triggered via vector move instructions ( 2 ), which lead to the
same behavior and leakage.
Vector Move. A faulting vector load instruction with cor-
rect alignment and without crossing a cache line can leak
data ( 3 ). 3 Depending on which part of the vector is read, it
can leak different parts of the implicitly write-combined data.
Prior faults also affect which part of the data is leaked. We
hypothesize that this is due to the different time it takes to
handle the exception for the fast string copy operation. Fault-
ing vector loads also show fast leakage for a non-canonical
address, whereas a simple non-canonical fault requires addi-
tional memory grooming to work. In contrast, to split cache
accesses, we did not observe leakage for a page fault in our
setup of microarchitectural buffer grooming. Note that while
Intel refers to all these cases as MLPDS [24], we distinguish
the speciﬁc case of leaking from implicit WC.
AVX Alignment Fault. Transynther created many variants of
alignment-enforcing vector loads, e.g., vmovaps, in combina-
tion with unaligned addresses, leading to a general-protection
exception. The results indicate that the alignment exception is
prioritized in the pipeline as it does not depend on the address
type ( 4 ). In contrast to 3 , 4 also works with page faults
and even valid addresses that are not causing any faults for
regular memory operations, e.g., vmovups or mov.
Store-to-leak. Transynther showed that during a TSX trans-
action, Store-to-leak [11] works on all addresses except for
non-present addresses ( 5 ).
Transynther also generated a case that when an unrelated
rep mov instruction is executed before the store, Store-to-
leak does not forward the data anymore. We further noticed
that adding a fence instruction between the store and load
prevents Store-to-leak. For Fallout [10], it has no effect ( 6 ).
4K-Aliasing Forwarding (Fallout). As discovered in Fall-
out [10], store-to-load forwarding can falsely forward data
when the least-signiﬁcant 12 bits of the store and load ad-
dress match [46]. Transynther reproduced combinations of
addresses that can forward when the store and load are a mul-
tiple of 4 kB apart ( 7 ). We veriﬁed that false forwarding on
4 kB aliasings only works with supervisor fault and access-bit
assist. Transynther showed that the forwarding is agnostic to
the address of the store, i.e., any store regardless of whether
the target is a valid or invalid address is forwarded as far as it
meets the 4 kB aliasing condition.
Store-to-load Forwarding and AVX. In our experiments,
both Fallout and Store-to-leak [10] also work with aligned
2In contrast to non-canonical addresses, Intel microarchitectures do not
treat the null addresses differently than any other non-present pages.
3Vector load instructions can enforce alignment e.g., movaps or be
alignment-agnostic e.g., movups. A correct alignment here means that either
the address of the load is aligned, or the alignment-agnostic version is used.
1432    29th USENIX Security Symposium
USENIX Association
Case
1
2
3
4
5
6
7
8
9
10
11
12
13
14
Table 2: Leakage variants discovered by Transynther.
, random instructions)
, random instructions)
, random instructions)
, random instructions)
Preparation
(access
(access
(access
(access
-
(rep mov + store, store + fence + load)
-
-
Store
-
-
-
-
store (to load)
store (to load)
store (4K Aliasing) +
store (4K Aliasing, to load) +
/
/
/
/
/
/
/
(Sibling on/off)
(Sibling on/off + clﬂush (store address))
(Sibling on/off + repmov (to Load))
store (random address) +
store (Cache Offset of Load) +
store (to Load)
-
(random instructions)
Store (Unaligned to Load)
AVX Store (to Load)
Load
+
AVX
AVX +
AVX
/
/
/
/ AVX
/
/
/
/
AVX
/
/
/
+
+
/
/
/
/
+
+
/
/
/
/
/
/
/
/
/
/
/
/
/
/
/
-
random ﬁll stores
Non-canonical Address Fault
Non-present Page Fault
Supervisor Protection Fault
AVX Alignment Fault
Access-bit Assist
Split-Cache Access Assist
Access without fault or Assist
Name
MLPDS
MLPDS
Medusa
Medusa
S2L
-
MSBDS
MSBDS, S2L
MSBDS
MSBDS
Medusa,
MLPDS
Medusa
Medusa,
MLPDS,
MSBDS
MSBDS
AVX loads. However, when the load suffers a vector align-
ment general-protection exception, Store-to-leak and Fallout
both ignore the address types for both stores and loads ( 8 ).
Store-Forwarding and Faulting Stores. Transynther dis-
covered that faulting stores can be forwarded independently
of address aliasing and matching. In 9 , we perform a store
to non-present addresses causing a page fault, e.g., a null ad-
dress. When the sibling thread is turned on and off, the store
is forwarded to the faulting load without any aliasing. Inter-
estingly, we can still index over which byte of the store to be
leaked. This variant of MSBDS only works with supervisor
fault and non-canonical address exceptions.
Store Forwarding and Cache Aliasing. Transynther also
created code sequences that leak the store data based on alias-
ing of only the cache offset. This is in contrast to the current
understanding that only full address matching or 4 kB aliasing
forwards the data ( 10 ).
Store Forwarding and Stale Load Forwarding. As we
mentioned in various cases, grooming the pipeline may af-
fect which data will be forwarded/leaked ﬁrst. For instance,
Transynther generated a multitude of proof of concepts that
different types of buffers and values can be leaked with vec-
tor alignment exception. We only mention one example here
that, Store-to-Leak can be turned into to a case where both
the store, and a value from the sibling thread (MLPDS or
Medusa) are leaked. In this case, we prepared the architecture
with a rep mov instruction with the destination address being
the faulty load address. When the sibling thread is switching
on/off, we see that both the forwarded store and the values
loaded by the sibling thread are leaked ( 11 ).
In this proof-of-concept, rep mov which is handled by
a speciﬁc microcode assist [26], is causing the value from
a sibling thread to be loaded instead of the expected store-
forwarding, i.e., the value stored previously. We investigated
the effect of rep mov and found out that we can use it to create
a new variant of leakage from the WC buffer (Section 4.2.3).
Unaligned Store Forwarding. We also found using Transyn-
ther that unaligned store forwardings can leak values from a
sibling thread. This is a special case of store-forward in which
the store and load overlap partially, but the actual data bytes
on the store can not be forwarded to the load. We investigate
this case further and use it as a new attack variant for Medusa
in Section 4.2.2 ( 12 ).
Non-canonical Addresses. Non-canonical addresses are han-
dled differently from regular memory addresses on Intel
CPUs [55]. During an early stage of address decoding, the pro-
cessor converts a 64-bit address to a compacted form, as the
actual supported address space is not 64-bit. During this con-
version, if the address does not follow the canonical form [27],
a general-purpose exception will be thrown. We also veriﬁed
that there is no page table walk for non-canonical addresses
and an early mechanism throw an exception matching the
description in the patent.
Medusa observed various cases where the combination of
non-canonical address faults will leak data with a different
behavior. For instance, store-to-leak on a no-canonical address
may not always leak the value of the store. Instead, depending
on speciﬁc grooming of the architecture, we see that both
the store and loads from the sibling thread are leaked ( 13 ).
Another interesting observation is that in certain cases for the
store buffer, a non-canonical fault would always leak the last
store disregarding any type of aliasing. In this case, we have
ﬁlled the store buffer with various valid stores, and depending
on what state the store buffer will be (a different set of random
stores), there are cases where the last store will always be
forwarded to the load ( 14 ).
USENIX Association
29th USENIX Security Symposium    1433
Transactional Asynchronous Abort (TAA). The Transac-
tional Asynchronous Abort (TAA) [25] represents another
vulnerability allowing to leak data from the same microarchi-
tectural buffers as MDS. TSX transactions can be aborted by
data conﬂicts, resource exhaustion, certain instructions, syn-
chronous exception events, e.g., page faults, or asynchronous
events within the pipeline [27].
We recorded the performance counters statistics of differ-