title:Robust TCP Stream Reassembly in the Presence of Adversaries
author:Sarang Dharmapurikar and
Vern Paxson
Robust TCP Stream Reassembly In the Presence of Adversaries
Sarang Dharmapurikar
Vern Paxson
Washington University in Saint Louis
International Computer Science Institute, Berkeley
PI:EMAIL
PI:EMAIL
Abstract
There is a growing interest in designing high-speed network de-
vices to perform packet processing at semantic levels above the
network layer. Some examples are layer-7 switches, content in-
spection and transformation systems, and network intrusion de-
tection/prevention systems. Such systems must maintain per-
ﬂow state in order to correctly perform their higher-level pro-
cessing. A basic operation inherent to per-ﬂow state manage-
ment for a transport protocol such as TCP is the task of reassem-
bling any out-of-sequence packets delivered by an underlying
unreliable network protocol such as IP. This seemingly prosaic
task of reassembling the byte stream becomes an order of mag-
nitude more difﬁcultto soundly execute when conducted in the
presence of an adversary whose goal is to either subvert the
higher-level analysis or impede the operation of legitimate trafﬁc
sharing the same network path.
We present a design of a hardware-based high-speed TCP
reassembly mechanism that is robust against attacks. It is in-
tended to serve as a module used to construct a variety of net-
work analysis systems, especially intrusion prevention systems.
Using trace-driven analysis of out-of-sequence packets, we ﬁrst
characterize the dynamics of benign TCP trafﬁcand show how
we can leverage the results to design a reassembly mechanism
that is efﬁcientwhen dealing with non-attack trafﬁc. We then
reﬁne the mechanism to keep the system effective in the pres-
ence of adversaries. We show that although the damage caused
by an adversary cannot be completely eliminated, it is possible
to mitigate the damage to a great extent by careful design and
resource allocation. Finally, we quantify the trade-off between
resource availability and damage from an adversary in terms of
Zombie equations that specify, for a given conﬁguration of our
system, the number of compromised machines an attacker must
have under their control in order to exceed a speciﬁed notion of
“acceptablecollateral damage.”
1 Introduction
The continual growth of network trafﬁc rates and the in-
creasing sophistication of types of network trafﬁcprocess-
ing have driven a need for supporting trafﬁc analysis using
specialized hardware. In some cases the analysis is in a
purely passive form (intrusion detection, accounting, per-
formance monitoring) and for others in an active, in-line
form (intrusion prevention, ﬁrewalling, content transfor-
mation, network address translation). Either way, a key
consideration is that increasingly the processing must op-
erate at a semantic level higher than the network layer; in
particular, we often can no longer use stateless process-
ing but must instead maintain per-ﬂow state in order to
correctly perform higher-level analyses.
Such stateful analysis brings with it the core problem
of state management: what hardware resources to allocate
for holding state, how to efﬁciently access it, and how to
reclaim state when the resources become exhausted. De-
signing a hardware device for effective state management
can require considerable care. This is particularly the case
for in-line devices, where decisions regarding state man-
agement can adversely affect network operation, such as
prematurely terminating established TCP connections be-
cause the device no longer has the necessary state to cor-
rectly transform the ﬂow.
Critically, the entire problem of state management be-
comes an order of magnitude more difﬁcultwhen con-
ducted in the presence of an adversary whose goal is to
either subvert the hardware-assisted analysis or impede
the operation of legitimate trafﬁcalong the same network
path.
Two main avenues for subverting the analysis (“eva-
sion”) are to exploit the ambiguities inherent in observ-
ing network trafﬁc mid-stream [18, 12] or to cause the
hardware to discard the state it requires for sound anal-
ysis.
If the hardware terminates ﬂows for which it has
lost the necessary state, then the adversary can pursue the
second goal of impeding legitimate trafﬁc—i.e.,denial-
of-service, where rather than targeting the raw capacity of
the network path or end server, instead the attacker targets
the newly-introduced bottleneck of the hardware device’s
limited state capacity.
Issues of state-holding, disambiguation, and robust op-
eration in the presence of ﬂoodingarise in different ways
depending on the semantic level at which the hardware
conducts its analysis.
In this paper we consider one of
the basic building blocks of higher-level analysis, namely
the conceptually simple task of reassembling the layer-4
byte streams of TCP connections. As we will show, this
seemingly prosaic bookkeeping task—justtrack the con-
nection’s sequence numbers, buffer out-of-sequence data,
USENIX Association
14th USENIX Security Symposium
65
lay down new packets in the holes they ﬁll, and deliver
to the next stage of processing any bytes that are now in-
order—becomes subtle and challenging when faced with
(i) limited hardware resources and, more importantly, (ii)
an adversary who wishes to either undermine the sound-
ness of the reassembly or impair the operation of other
connections managed by the hardware.
While fast hardware for robust stream reassembly has
a number of applications, we focus our discussion on en-
abling high-speed intrusion prevention. The basic model
we assume is a high-speed, in-line network element de-
ployed at a site’s gateway (so it sees both directions of the
ﬂows it monitors). This module serves as the ﬁrst stage of
network trafﬁc analysis, with its output (reassembled byte
streams) feeding the next stage that examines those byte
streams for malicious activity. This next stage might also
execute in specialized hardware (perhaps integrated with
the stream reassembly hardware), or could be a function-
ally distinct unit.
A key consideration is that because the reassembly
module is in-line, it can (i) normalize the trafﬁc [12] prior
to subsequent analysis, and (ii) enable intrusion preven-
tion by only forwarding trafﬁc if the next stage signals
that it is okay to do so. (Thus, by instead signaling the
hardware to discard rather than forward a given packet,
the next stage can prevent attacks by blocking their deliv-
ery to the end receiver.) As we will discuss, another key
property with operating in-line is that the hardware has the
potential means of defending itself if it ﬁnds its resources
exhausted (e.g., due to the presence of state-holding at-
tacks). It can either reclaim state that likely belongs to at-
tacker ﬂows, or else at least exhibit graceful degradation,
sacriﬁcing performance ﬁrst rather than connectivity.
A basic notion we will use throughout our discussion is
that of a sequence gap, or hole, which occurs in the TCP
stream with the arrival of a packet with a sequence number
greater than the expected sequence number. Such a hole
can result from packet loss or reordering. The hardware
must buffer out-of-order packets until a subsequent packet
ﬁlls the gap between the expected and received sequence
numbers. After this gap is ﬁlled, the hardware can then
supply the byte-stream analyzer with the packets in the
correct order, which is crucial for higher-level semantic
analysis of the trafﬁc stream.
At this point, the hardware can release the buffer al-
located to the out-of-order packet. However, this pro-
cess raises some natural questions:
if the hardware has
to buffer all of the out-of-order packets for all the connec-
tions, how much buffer does it need for a “typical” TCP
trafﬁc? How long do holes persist, and how many con-
nections exhibit them? Should the hardware immediately
forward out-of-order packets along to the receiver, or only
after they have been inspected in the correct order?
To explore these questions, we present a detailed trace-
driven analysis to characterize the packet re-sequencing
phenomena seen in regular TCP/IP trafﬁc. This analy-
sis informs us with regard to provisioning an appropriate
amount of resources for packet re-sequencing. We ﬁnd
that for monitoring the Internet access link of sites with
several thousand hosts, less than a megabyte of buffer suf-
ﬁces.
Moreover, the analysis helps us differentiate between
benign TCP trafﬁc and malicious trafﬁc, which we then
leverage to realize a reassembly design that is robust in
the presence of adversaries. After taking care of traf-
ﬁc normalization as discussed above, the main remain-
ing threat is that an adversary can attempt to overﬂow the
hardware’s re-sequencing buffer by creating numerous se-
quence holes. If an adversary creates such holes in a dis-
tributed fashion, spreading them across numerous connec-
tions, then it becomes difﬁcult to isolate the benign trafﬁc
from the adversarial.
Tackling the threat of adversaries gives rise to another
set of interesting issues: what should be done when the
buffer overﬂows? Terminate the connections with holes,
or just drop the buffered packets? How can we minimize
the collateral damage? In light of these issues, we devise
a buffer management policy and evaluate its impact on
system performance and security.
We frame our analysis in terms of Zombie equations:
that is, given a set of operational parameters (available
buffer, trafﬁc volume, acceptable collateral damage), how
many total hosts (“zombies”) must an adversary control in
order to inﬂict an unacceptably high degree of collateral
damage?
The rest of the paper is organized as follows. Section 2
discusses the related work. In Section 3 we present the re-
sults of our trace-driven analysis of out-of-sequence pack-
ets. Section 4 describes the design of a basic reassembly
mechanism which handles the most commonly occurring
re-ordering case. In Section 5, we explore the vulnera-
bilities of this mechanism from an adversarial point of
view, reﬁne it to handle attacks gracefully, and develop
the Zombie equations quantifying the robustness of the
system. Section 6 concludes the paper.
2 Related Work
Previous work relating to TCP stream reassembly primar-
ily addresses (i) measuring, characterizing and modeling
packet loss and reordering, and (ii) modifying the TCP
protocol to perform more robustly in the presence of se-
quence holes.
Paxson characterized the prevalence of packet loss and
reordering observed in 100 KB TCP transfers between a
number of Internet hosts [16], recording the trafﬁc at both
sender and receiver in order to disambiguate behavior. He
66
14th USENIX Security Symposium
USENIX Association
found that many connections are loss-free, and for those
that are not, packet loss often comes in bursts of consec-
utive losses. We note that such bursts do not necessarily
create large sequence holes—if all packets in a ﬂight are
lost, or all packets other than those at the beginning, then
no hole is created. Similarly, consecutive retransmissions
of the same packet (which would count as a loss burst
for his deﬁnition) do not create larger holes, and again
might not create any hole if the packet is the only one un-
acknowledged. For packet reordering, he found that the
observed rate of reordering varies greatly from site to site,
with about 2% of all packets in his 1994 dataset being
reordered, and 0.6% in his 1995 dataset. However, it is
difﬁcult to gauge how we might apply these results to to-
day’s trafﬁc, since much has changed in terms of degree
of congestion and multipathing in the interim.
Bennett and colleagues described a methodology for
measuring packet reordering using ICMP messages and
reported their results as seen at a MAE-East router [5].
They found that almost 90% of the TCP packets were re-
ordered in the network. They provide an insightful dis-
cussion over the causes of packet reordering and isolate
the packet-level parallelism offered by packet switches
in the data path as the main culprit. Our observations
differ signiﬁcantly from theirs; we ﬁnd that packet re-
ordering in TCP trafﬁc affects 2–3% of the overall traf-
ﬁc. We attribute this difference to the fact that the results
in [5] reﬂect an older generation of router architecture.
In addition, it should be mentioned that some router ven-
dors have modiﬁed or are modifying router architectures
to provide connection-level parallelism instead of packet
level-parallelism in order to eliminate reordering [1].
Jaiswal and colleagues presented measurements of out-
of-sequence packets on a backbone router [13]. Through
their passive measurements on recent OC-12 and OC-48
traces, they found that packet reordering is seen for 3–5%
of overall TCP trafﬁc. This more closely aligns with our
ﬁndings. Gharai and colleagues presented a similar mea-
surement study of out-of-order packets using end-to-end
UDP measurements [11]. They too conclude that reorder-
ing due to network parallelism is more prevalent than the
packet loss.
Bellardo and Savage devised a clever scheme for mea-
suring TCP packet reordering from a single endpoint and
discriminating between reordering on the forward path
with that on the reverse path [4].
(For many TCP con-
nections, reordering along one of the paths is irrelevant
with respect to the formation of sequencing holes, because
data transfers tend to be unidirectional, and reordered ac-
knowledgments do not affect the creation of holes.) They
quantify the degree that reordering rates increase as the
spacing between packets decreases. The overall reorder-
ing rates they report appear consistent with our own ob-
servations.
Laor et. al.
investigated the effect of packet reorder-
ing on application throughput [14]. In a laboratory with a
Cisco backbone router connecting multiple end-hosts run-
ning different OSes, they measured HTTP throughput as
a function of injected packet reordering. Their experi-
ments were however conﬁned to cases where the reorder-
ing elicited enough duplicate-ACKs to trigger TCP’s “fast
retransmission” in the sender. This leads to a signiﬁcant
degradation in throughput. However, we ﬁnd that this
degree of reordering does not represent the TCP trafﬁc
behavior seen in actual trafﬁc, where very few reordered
packets cause the sender to retransmit spuriously.
Various algorithms have been proposed to make TCP
robust to packet reordering [6, 7, 21].
In [6], Blanton
and Allman propose to modify the duplicate-ACK thresh-
old dynamically to minimize the effect of duplicate re-
transmissions on TCP throughput degradation. Our work
differs from theirs in that we use trace-driven analysis to
guide us in choosing various parameters to realize a robust
reassembly system, as well as our interest in the compli-
cations due to sequence holes being possibly created by
an adversary.
In a project more closely related to our work, Schuehler
et al. discuss the design of a TCP processor that maintains
per-ﬂow TCP state to facilitate application-level analy-
sis [20]. However, the design does not perform packet
reordering—instead, out-of-order packets are dropped.
There are also some commercial network processors
available today that perform TCP processing and packet
reassembly. Most of these processors, however, are used
as TCP ofﬂoad engines in end hosts to accelerate TCP pro-
cessing. To our knowledge, there are few TCP processors
which process and manipulate TCP ﬂows in-line, with In-
tel’s TCP processor being one example [10]. TCP pack-
ets are reordered using a CAM that stores the sequence
numbers of out-of-order packets. When a new data packet
arrives, the device compares its sequence number against
the CAM entries to see if it plugs any of the sequence
holes. Unfortunately, details regarding the handling of
edge cases do not appear to be available; nor is it clear
how such processors handle adversarial attacks that aim
to overﬂow the CAM entries.
Finally, Paxson discusses the problem of state manage-
ment for TCP stream reassembly in the presence of an
adversary, in the context of the Bro intrusion detection
system [17]. The problem is framed in terms of when to
release memory used to hold reassembled byte streams,
with the conclusion being to do so upon observing an ac-
knowledgment for the data, rather than when the data ﬁrst
becomes in-sequence, in order to detect inconsistent TCP
retransmissions. The paper does not discuss the problem
of managing state for out-of-sequence data; Bro simply
buffers such data until exhausting available memory, at
which point the system fails.
USENIX Association
14th USENIX Security Symposium
67
Trace duration (seconds)
Total packets
Total connections
Connections with holes
Total holes
Max buffer required (bytes)
Avg buffer required (bytes)
Max simultaneous holes
Max simultaneous holes
in single connection
Fraction of holes with
< 3 packets in buffer
Fraction of connections with
single concurrent hole
Fraction of holes that overlap
hole on another connection
of same external host (§ 5.1)
Univsub
303
1.25M
53K
1,146
2,048
128 KB
5,943
15
9
90%
96%
0.5%
Univ19
∗
5,697 / 300
6.2M
237K
17,476
29,003
91 KB
2,227
13
16
Lab2
Lablo
3,602
3,604
1.5M 14.1M
215K
50K
41,611
4,469
8,848
79,321
253K
68 KB
13,392
3,111
39
9
6
16
87%
98%
90%
87%
96%
97%
Super
3,606
3.5M
21K
598
4,088
269 KB
122
6
6
97%
97%
T3
10,800
36M
1.04M
174,687
575K
202 KB
28,707
94
85
85%
95%
Munich
6,167
220M
5.62M