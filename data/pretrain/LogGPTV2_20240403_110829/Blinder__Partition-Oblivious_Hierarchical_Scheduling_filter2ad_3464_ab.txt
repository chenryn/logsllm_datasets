regular tick counter. While ΠR is preempted by ΠS, τR,2’s ex-
ecutions are delayed. Because its priority is higher than τR,1,
upon returning from ΠS’s preemption, the accumulated jobs
of τR,2 execute, increasing the counter value by the number
of times it could not execute during the preemption. Depend-
ing on the length of the preemption, the difference curr_c -
prev_c at 2 changes, which enables a multi-bit channel.
3.1 Adversary Model
We assume that task execution is time-invariant. That is, if a
task executes for a period of time ∆t, the progress that it makes
from time t0 to t0 +∆t remains indistinguishably constant even
if t0 changes. This assumption might be violated by, for exam-
ple, microarchitectural timing-channels [20, 23, 24, 26]. We
assume that the microarchitectural timing-channels are prop-
erly mitigated [15, 18] to the degree that the time-invariant
property holds. We acknowledge that the microarchitectural
timing-channels play an important role in interferences. In this
paper, we show that an algorithmic timing-channel through
hierarchical scheduling can exist even if the microarchitec-
2420    30th USENIX Security Symposium
USENIX Association
𝝉𝑹,𝟏𝝉𝑺,𝟏𝝉𝑹,𝟐Time𝐶←𝐶+1𝝉𝑹,𝟏𝝉𝑺,𝟏𝝉𝑹,𝟐Time(a) 𝚷𝑺sends bit 0 𝐶←𝐶+1(b) 𝚷𝑺sends bit 1 Partition SPartition R𝑡"𝑡#𝑡$𝑡"𝑡#𝑡$𝐶Read1212WW𝐶Read𝐶Read𝐶+1Readvoid sender_job(int bit) {if (bit==1)n_loops= 10000000;elsen_loops=  2000000;for (i=0; i<n_loops; i++)asm("nop");}int receiver1_job(void) {prev_c= shared_c;n_loops= 6000000;for (i=0; i<n_loops; i++) asm("nop");curr_c= shared_c;return curr_c-prev_c;}void receiver2_job(void) {shared_c++; }1W22W12W1bit=1:bit=0:Time12W𝝉𝑺,𝟏TimePartition SPartition R𝝉𝑹,𝟐WWWWWWWWWWXWWW12(a) curr_c-prev_c	=6𝝉𝑹,𝟏(b) curr_c-prev_c	=9Figure 8: Motivating scenario of illegitimate information ﬂow.
tural timing-channels are completely closed. Hence, we can
view the microarchitectural channels as an orthogonal issue.
Partitions can communicate with each other but only
through explicit channels to send/receive data such as sensor
data, actuation commands, system-monitoring information,
and so on. These channels are monitored, and no unknown
explicit channels exist. In Linux-based environment, software
compartmentalization mechanisms such as Linux contain-
ers (LXC) [10] can help reduce hidden channels as well as
providing proper resource (e.g., memory, I/O) isolation.
We do not limit an adversary’s ability to control its tim-
ing; he/she can even request the scheduler to launch tasks
at precise times, using facilities that are intended for man-
aging precedence constraints among tasks in both same and
different partitions (e.g., data sender and receiver) and also
for aligning task arrivals with certain events such as periodic
retrieval of sensor data. With such capabilities, the adversary
can maximize the chance for successful communication over
the covert channel through hierarchical scheduling. Our goal
is to prevent the adversary from forming the covert channel
even under such optimized conditions.
Motivating Scenario: We implemented the scenario pre-
sented above on an 1/10th-scale autonomous driving system
that is composed of four partitions as shown in Figure 8.
The implementation details are presented in Section 6.1. The
partitions are scheduled by the sporadic-polling scheduler,
and each partition is isolated inside an LXC. In this system,
various run-time information such as driving commands are
collected via explicit channels by the health monitoring par-
tition Π4 for a post-analysis purpose. We can consider an
ill-intended system administrator who exploits a covert chan-
nel to collect sensitive information such as location data that
are supposed not to be collected. In the system, the navigation
partition, which computes a navigation path for the behavior
controller, may leak the current location data to the health
monitoring module in which it is secretly stored along with
other run-time information, bypassing communication moni-
tors. Speciﬁcally, we took advantage of the watchdog process
in Π4; upon receiving a heartbeat message from Π3, the re-
ceiver task is launched with a delay to time itself to the sender.
This approach is advantageous in that the sender and receiver
tasks do not need to coordinate their timing in advance – the
timing and frequency are controlled by the sender. Of course,
if the adversary had a full control of the system, it could be
easily conﬁgured to launch the tasks in phase.
Figure 9: Accuracy of communication over the covert channel
through LITMUSRT’s hierarchical scheduling.
3.2 Feasibility Test
Although this paper does not aim to propose an advanced at-
tack technique, we demonstrate the feasibility of the scenarios
presented above in a general setting. For this, we used the sys-
tem conﬁguration shown in Table 1 in Section 6.2. The parti-
tions divide the CPU share equally (with α = 1.25). The tasks’
inter-arrival times are not ﬁxed, and thus they can arrive at ar-
bitrary times. This creates unpredictable interference with the
sender and receiver. We implemented the sender and receiver
tasks in Π3 and Π4, respectively, as middle-priority tasks and
tried three different base system loads (β ∈ {0.25,0.625,1.0})
to vary the amount of noise on the covert channel. The sender
and the receiver use a simple repetition code of length 5.
We tried two approaches: (i) phased-based and (ii) message-
based launches. In the phase-based approach, the sender and
receiver tasks arrive periodically (every 100 ms) from the
same initial phase using LITMUSRT’s synchronous-release
function. The message-based scheme takes advantage of a le-
gitimate communication channel as explained above. Figure 9
presents the communication accuracy under the two schemes.
Each data point is measured for 30 minutes. Although the
success rate is considerably high when the system is light-
loaded, it drops as the interference by other partitions and
tasks increases (i.e., high-loaded). Overall, the message-based
coordination achieves higher accuracy than the phase-based
scheme because in the former, both the sender and receiver
tasks are delayed together until the sender takes the CPU.
Whereas in the latter, the receiver’s arrival is independent
from the sender.
Based on these observations, we tried a simple technique
that can signiﬁcantly improve the accuracies – giving more
weight to bit ‘1’ when decoding a repetition code. This is
based on the fact that the receiver is more likely to see bit ‘0’
because its execution is likely to be delayed by other tasks
(i.e., τR,1 and τR,2 in Figure 5(a) are delayed together). As
shown in Figure 9, this biased majority voting improves the
accuracy by up to 14%. It can be further enhanced if the sender
and receiver tasks were allowed to choose their partition-
local priorities. This is based on the fact that communication
between them is likely to be successful if they execute back-
to-back. Hence, we tried giving the Π3-local lowest-priority
to the sender and the Π4-local highest-priority to the receiver,
USENIX Association
30th USENIX Security Symposium    2421
SECCOMPSECCOMPSECCOMPBehavior ControlLXCLXCLXCLXCSteering cmdActuationLocationCameraCovertChannelVision-based SteeringNavigationHealthMonitoringΠ!Π"Π#Π$Blocks time-related system callsE.g., gettimeofdayUbuntu with LITMUSRTSECCOMPNavigation cmdΠ!&Π"→Π#: LogAll Π$→Π#: HeartbeatBiased Majority VotePriority AssignmentFigure 10: Schedule traces generated by LITMUSRT under our
solution that correspond to Figures 5(b) and 7(b).
which resulted in an improvement of up to 9%. Although
we did not try, the accuracies can be further improved if, for
example, (i) other tasks execute in a strictly-periodic fashion,
(ii) the sender and receiver can take into account other tasks’
timing properties such as periods, (iii) they can coordinate
with their partition-local tasks for a better timing, and so on.
The results above highlight that systems that employ hi-
erarchical scheduling with non-static time partitioning are
vulnerable to such covert timing-channel, and an adversary
can use various techniques to increase the chance of success-
ful communication. Our solution, which will be presented in
later sections, deters such attempts even when the system is
conﬁgured in favor of the adversary. In fact, the adversary’s
best chance at distinguishing timing variations from other
partitions becomes no better than a random guess because
the cases in Figures 5(b) and 7(b) cannot occur under our
solution, as shown in Figure 10.
4 Non-interference of Partition-Local Schedule
Following the deﬁnition in [32], we deﬁne information-
ﬂow through hierarchical scheduling as follows:
Deﬁnition 2 (Information-ﬂow through hierarchical schedul-
ing). Information is said to ﬂow from a partition Π j to an-
other partition Πi when changes in the temporal behavior of
Π j result in changes in Πi’s observation on its local state.
Section 3 presented how illegitimate information-ﬂow can
be established between non-static partitions even without us-
ing time measurements. Speciﬁcally, the tasks of partition ΠR
were able to perceive ΠS’s varying execution behavior from
observing changes in their own partition’s local schedule [29].
Deﬁnition 3 (Partition-local schedule). The Πi-local sched-
ule is deﬁned as a mapping from the partition-local time, t(i),
to task set Πi. The partition-local time advances only when it
is selected by the global scheduler to serve its tasks.
Figure 11 shows how the varying execution of ΠS changes
the local schedule of ΠR. For instance, as soon as ΠR returns
from the preemption at local time t(R)
, task τR,1 continues
1
its execution in Case (a). Whereas in Case (b), τR,2 executes
because it is the highest-priority task in the ready queue of
ΠR when it resumes. Similarly, at the local time t(R)
, task τR,2
2
executes in Case (a) while τR,1 executes in Case (b).
The fundamental reason why the partition-local schedule
changes is because the tasks are released at non-deterministic
Figure 11: Two different local schedules of ΠR due to the
varying execution of ΠS. Notice that the local time of ΠR
does not advance while it is not running due to a preemption.
local times even if they arrive at deterministic physical times.
For example, τR,2 arrives at physical time t2 as shown in Fig-
ure 5. However, in the ΠR-local time, it is released at t(R)
1 +∆t
in Case (a) and t(R)
in (b) as shown in Figure 11. Thus, the
1
amount of progress that τR,1 makes until τR,2’s release varies,
which enables them to know the order of their executions.
If tasks are released at deterministic local-time points, they
always produce the same partition-local schedule because the
state of the partition’s ready queue changes at the determin-
istic time points. Following the deﬁnition in [29], we deﬁne
the non-interference property of partition-local schedule as
follows:
Deﬁnition 4 (Non-interference of partition-local schedule).
Partition Πi is said to be non-interferent if its local schedule
is invariant to how other partitions ΠΠΠ\{Πi} execute. Specif-
ically, Πi’s local schedule is deterministic if tasks of Πi are
released at deterministic Πi-local times.
5 Partition-Oblivious Hierarchical Scheduling
In this section, we present Blinder, a run-time schedule
transformation algorithm that makes non-static time parti-
tions oblivious to others’ varying behavior. Our design goals
for Blinder are to (i) make it agnostic to global and local
scheduling mechanisms, (ii) incur low scheduling overhead,
and (iii) make its worst-case impact on the responsiveness
deterministic, which is important for real-time applications.
5.1 High-level Idea
Partition-local schedules can be made deterministic simply
by a static partitioning; that is, partitions are suspended at
deterministic time points for ﬁxed amount of time. This, how-
ever, may lead to low CPU utilization as brieﬂy discussed
in Section 2.2. Hence, instead of controlling when and how
long partitions should execute, we aim to allow partitions
to be scheduled still in non-static ways (thus taking advan-
tage of the improved responsiveness of non-static partitioning
schemes) while preventing the non-deterministic behaviors
from being distinguishable by local tasks. Blinder achieves
this by controlling when to introduce task to partition, i.e.,
task release time.
2422    30th USENIX Security Symposium
USENIX Association
0ms10ms20ms30ms40ms50ms60ms70ms80ms90ms100ms110ms120ms130ms140ms150ms160ms170ms180ms190ms200ms210ms220ms230ms240ms250ms260ms270ms280ms290ms300ms310ms320ms330ms340ms350ms360ms370ms380ms390ms400ms410ms420ms430ms440ms450ms460ms470ms480ms490ms500ms510ms520ms530ms540ms550ms560ms570ms580ms590ms600ms610ms620ms630ms640ms650ms660ms670ms680ms690ms700ms710ms720ms730ms740ms750ms760ms770ms780ms790ms800ms810ms820ms830ms840ms850ms860ms870ms880ms890ms900ms910ms920ms930ms940ms950ms960ms970ms980ms990ms1000ms/9664(0.00ms, 0.00ms)/9653(0.00ms, 0.00ms)/9654(0.00ms, 0.00ms)/9655(0.00ms, 0.00ms)/9656(0.00ms, 0.00ms)/9657(0.00ms, 0.00ms)/9658(0.00ms, 0.00ms)/9659(0.00ms, 0.00ms)/9660(0.00ms, 0.00ms)/9661(0.00ms, 0.00ms)/9662(0.00ms, 0.00ms)/9663(0.00ms, 0.00ms)0ms10ms20ms30ms40ms50ms60ms70ms80ms90ms100ms110ms120ms130ms140ms150ms160ms170ms180ms190ms200ms210ms220ms230ms240ms250ms260ms270ms280ms290ms300ms310ms320ms330ms340ms350ms360ms370ms380ms390ms400ms410ms420ms430ms440ms450ms460ms470ms480ms490ms500ms510ms520ms530ms540ms550ms560ms570ms580ms590ms600ms610ms620ms630ms640ms650ms660ms670ms680ms690ms700ms710ms720ms730ms740ms750ms760ms770ms780ms790ms800ms810ms820ms830ms840ms850ms860ms870ms880ms890ms900ms910ms920ms930ms940ms950ms960ms970ms980ms990ms1000ms/10883(0.00ms, 0.00ms)/10886(0.00ms, 0.00ms)/10887(0.00ms, 0.00ms)𝝉𝑹,𝟐𝝉𝑹,𝟏𝝉𝑺,𝟏𝝉𝑹,𝟐𝝉𝑹,𝟏𝝉𝑺,𝟏curr_c-prev_c	=0curr_c-prev_c	=6𝝉𝑹,𝟏𝝉𝑺,𝟏𝝉𝑹,𝟐𝝉𝑹,𝟏𝝉𝑺,𝟏𝝉𝑹,𝟐𝑡!(#)𝑡%(#)𝑡!(#)𝑡%(#)Case (a)Case (b)Δ𝑡𝑡&(#)𝑡&(#)Π"Π#Local timeLocal timeFigure 12: Blinder controls the release times of newly-arrived
tasks to make the partition-local schedule deterministic.
Figure 13: Πi’s canonical local schedule.
Figure 12 illustrates the high-level idea using a two-
partition example that is similar to the case considered in
Figure 5. Here, the release of τi,2 that arrives at physical time
t2 is deferred as if Π j’s preemption did not occur. Speciﬁ-
cally, τi,2’s release is deferred until t4 to ensure that τi,1 would
execute for the amount of time that it would have done (i.e.,
∆y = t2 −t1) if the preemption by Π j did not happen. Hence,
τi,2 is released at t4 = t3 + ∆y where t3 is when Πi returns
from the preemption. Thus, τi,1 is guaranteed to execute for
(t1 −t0) + (t4 −t3) = (t1 −t0) + (t2 −t1) = t2 −t0 = ∆x +∆y.
Note that it is independent from the duration of the preemp-
tion by Π j, i.e., t3 −t1. Thus, τi,1 makes the same amount of
progress, i.e., ∆x +∆y, until τi,2 is released, regardless of how
long the preemption is. Such a deferment is applied also to
certain tasks that arrive while the partition is active. τi,3 is
an example. If it was released immediately upon the arrival
at time t6, τi,1 would be preempted by τi,3, which would not
occur if Π j’s preemption was shorter or did not happen. On
the other hand, τi,2’s second arrival at time t8 does not need to
be deferred because all the prior executions that are affected
by the partition-level preemption complete before t8, and thus
τi,2’s execution does not change the local schedule of Πi.
Blinder guarantees that tasks are always released at deter-
ministic partition-local times by enforcing that the partition-
local schedules to follow the partition’s canonical local sched-
ule – the local schedule when no other partitions run [29]. Fig-
ure 13 shows an example canonical local schedule of Πi that
resulted in the schedule in Figure 12. For instance, the ﬁrst ar-
rival of τi,2 is released at Πi-local time t(i)
a + (∆x + ∆y).
Only the corresponding physical time varies in the presence of
other partitions. An actual schedule observed in the physical-
time domain under Blinder can be viewed as the canonical
schedule being stretched out over time by higher-priority parti-
tions. Hence, actual schedules vary with the partition schedule
while the partition-local schedule remains same.
b = t(i)
Figure 14: Blinder uses arrival queue to control task release.
The canonical local schedule, however, cannot be statically
constructed because tasks may arrive at arbitrary times and
have variable execution times. Most importantly, these in
turn affect when partition budget is depleted and replenished.
Hence, the challenge lies in determining for how long τi,2’s
release must be deferred (i.e., ∆y in Figure 12), which depends
on the amount of CPU time that τi,1 would have used if not
preempted by Π j. The crux of Blinder algorithm is the on-line
construction of canonical local schedule.
5.2 Blinder Algorithm
Figure 14 illustrates a high-level overview of Blinder algo-
rithm. It constructs a canonical local schedule of partition in
the run-time by having an arrival queue hold newly-arrived
tasks until releasing them to the ready queue at the right tim-
ing: it depends on how the partition is scheduled. Without
Blinder, every newly-arriving task is immediately inserted to
the ready queue. As discussed earlier, this is the very source
of information-ﬂow between partitions.
5.2.1 Scheduling Primitives
Blinder algorithm does not require a change in the generic
hierarchical scheduler presented in Algorithm 1 (Section 2.1).
That is, at each scheduling decision, a partition is selected
according to the global scheduling policy. It is important
to notice that Blinder only controls the task release times.
Once tasks are released, they are scheduled according to the
partition-speciﬁc local scheduling policy that is independent
from Blinder algorithm, as shown in Algorithm 2 (last line).
Task arrival, release, and departure: TaskArrive is in-
voked at any time when a new task τi, j arrives to partition Πi.
The task is inserted into the arrival queue QA
i (t), annotated
with the arrival time ta(τi, j) = t, as shown in Algorithm 3.
As long as the partition Πi is selected by the global scheduler
to run, i.e., Π(t) = Πi, it checks for task release. As shown in
Algorithm 2, Blinder releases tasks that meet a certain condi-
tion (which will be introduced shortly) by moving them from
the arrival queue to the ready queue. TaskDepart, shown in
Algorithm 2: LocalScheduler(Πi)
∆ti: time used by Πi since the last check
Usedi ← Usedi + ∆ti
for τi, j ∈ QA
i (t) do
lagi, j ← lagi, j − ∆ti
if lagi, j == 0 then
i (t) ← QA
QA
i (t) ← QR
QR
i (t)−{τi, j}
i (t)∪{τi, j}
end
/* Reduce lag */
/* Release task */
end
τi(t) ← select a task from QR
i (t) according to local scheduling policy
USENIX Association
30th USENIX Security Symposium    2423
𝝉𝒊,𝟏𝝉𝒋,𝟏Physical𝝉𝒊,𝟐𝝉𝒊,𝟑𝑡!𝑡"𝑡#𝑡$𝑡%𝑡&𝑡’𝑡(Π)Π*𝝉𝒊,𝟐𝑡+(-)𝑡/(*)Π’-localDeferredDeferred𝑡0Δ𝑥Δ𝑦Δ𝑥+Δ𝑦Δ𝑦𝑡1(*)𝑡2(*)𝝉𝒊,𝟏𝝉𝒊,𝟐𝝉𝒊,𝟑𝝉𝒊,𝟐𝑡"($)𝑡&(’)Π!-local𝑡((’)𝑡)(’)Arrival QueueReady QueueTask ArrivalTask DepartureTime-orderedPriority-orderedBlinderLocal SchedulerReleaseAlgorithm 3: TaskArrive(τi, j)
ta(τi, j) ← t
i (t) ← QA
QA
lagi, j ← lagi(t)
if Mi(t) == Mnormal and Preempted(Πi,t) == True then
i (t)∪{τi, j}
/* Arrival time of τi, j */
/* Initialize lagi, j */
EnterDeferredMode(Πi)
end
Algorithm 4: TaskDepart(τi, j)
i (t) ← QR
QR
if QR
i (t) == /0 and Mi(t) == Mdeffered then
if QA
i (t)−{τi, j}
i (t) == /0 then
Mi(t) ← Mnormal
else
end
end
/* Switch to normal mode */
ShiftRelease(Πi)
/* Update lag in QA
i (t) */
Algorithm 4, is called when a task execution completes and