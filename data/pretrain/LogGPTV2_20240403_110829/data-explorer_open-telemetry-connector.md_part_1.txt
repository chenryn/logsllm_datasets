---
title: Ingest data from OpenTelemetry to Azure Data Explorer
description: Learn how to use Azure Data Explorer as an OpenTelemetry sink.
ms.date: 10/03/2022
ms.topic: how-to
ms.reviewer: ramacg
---
# Ingest data from OpenTelemetry to Azure Data Explorer
[!INCLUDE [real-time-analytics-connectors-note](includes/real-time-analytics-connectors-note.md)]
[OpenTelemetry](https://opentelemetry.io/docs/concepts/what-is-opentelemetry/) (OTel) is an open framework for application observability. The instrumentation is hosted by the Cloud Native Computing Foundation (CNCF), which provides standard interfaces for observability data, including [metrics](https://opentelemetry.io/docs/concepts/observability-primer/#reliability--metrics), [logs](https://opentelemetry.io/docs/concepts/observability-primer/#logs), and [traces](https://opentelemetry.io/docs/concepts/observability-primer/#distributed-traces). The OTel Collector is made up of the following three components: **receivers** deal with how to get data into the Collector, **processors** determine what to do with received data, and **exporters** are responsible for where to send the received data.
The [Azure Data Explorer exporter](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/azuredataexplorerexporter) supports ingestion of data from many receivers into Azure Data Explorer. 
> [!NOTE]
> * The configuration settings are summarized in the [readme documentation](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/exporter/azuredataexplorerexporter/README.md).
> * For the exporter source code, see [Azure Data Explorer exporter](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/azuredataexplorerexporter). 
In this article, you learn how to:
> [!div class="checklist"]
> * Set up your environment
> * Configure the Azure Data Explorer exporter
> * Run the sample application
> * Query incoming data
## Prerequisites
* An Azure subscription. Create a [free Azure account](https://azure.microsoft.com/free/)
* A cluster and a database: [Quickstart: Create an Azure Data Explorer cluster and database](create-cluster-and-database.md)
## Set up your environment
In this section, you prepare your environment to use the OTel exporter.
### Create a Microsoft Entra app registration
Microsoft Entra application authentication is used for applications that need to access Azure Data Explorer without a user present. To ingest data using the OTel exporter, you need to create and register a Microsoft Entra service principal, and then authorize this principal to ingest data an Azure Data Explorer database.
1. Using your Azure Data Explorer cluster, follow steps 1-7 in [Create a Microsoft Entra application registration in Azure Data Explorer](provision-azure-ad-app.md).
1. Save the following values to be used in later steps:
    * Application (client) ID
    * Directory (tenant) ID
    * Client secret key value
### Grant the Microsoft Entra app permissions
1. In the query tab of the [web UI](https://dataexplorer.azure.com/), connect to your cluster. For more information on how to connect, see [Add clusters](web-query-data.md#add-clusters).
1. Browse to the database in which you want to ingest data.
1. Run the following management command, replacing the placeholders. Replace *DatabaseName* with the name of the target database and *ApplicationID* with the previously saved value. This command grants the app the [database ingestor](kusto/access-control/role-based-access-control.md) role. For more information, see [Manage database security roles](kusto/management/manage-database-security-roles.md).
    ```kusto
    .add database  ingestors ('aadapp=') 'Azure Data Explorer App Registration'
    ```
    > [!NOTE]
    > The last parameter is a string that shows up as notes when you query the roles associated with a database. For more information, see [View existing security roles](kusto/management/manage-database-security-roles.md#show-existing-security-roles).
### Create target tables
1. Browse to [Azure Data Explorer web UI](https://dataexplorer.azure.com/). 
1. Select **Query** from the left menu. 
1. Expand the target cluster in the left pane.
1. Select the target database to give your queries the correct context.
1. Run the following commands to create tables and schema mapping for the incoming data:
    ```kusto
    .create-merge table  (Timestamp:datetime, ObservedTimestamp:datetime, TraceId:string, SpanId:string, SeverityText:string, SeverityNumber:int, Body:string, ResourceAttributes:dynamic, LogsAttributes:dynamic) 
    .create-merge table  (Timestamp:datetime, MetricName:string, MetricType:string, MetricUnit:string, MetricDescription:string, MetricValue:real, Host:string, ResourceAttributes:dynamic,MetricAttributes:dynamic) 
    .create-merge table  (TraceId:string, SpanId:string, ParentId:string, SpanName:string, SpanStatus:string, SpanKind:string, StartTime:datetime, EndTime:datetime, ResourceAttributes:dynamic, TraceAttributes:dynamic, Events:dynamic, Links:dynamic) 
    ```
### Set up streaming ingestion
Azure Data Explorer has two main types of ingestion: batching and streaming. For more information, see [batching vs streaming ingestion](ingest-data-overview.md#continuous-data-ingestion). The *streaming* method is called *managed* in the Azure Data Explorer exporter configuration. Streaming ingestion may be a good choice for you if you need the logs and traces are to be available in near real time. However, streaming ingestion uses more resources than batched ingestion. The OTel framework itself batches data, which should be considered when choosing which method to use for ingestion.
> [!NOTE]
> [Streaming ingestion](ingest-data-streaming.md) must be enabled on Azure Data Explorer cluster to enable the `managed` option.
> You can check if streaming is enabled using the [.show database streaming ingestion policy](kusto/management/show-database-streaming-ingestion-policy-command.md) command.
Run the following command for each of the three tables to enable streaming ingestion:
```kusto
.alter table  policy streamingingestion enable
```
## Configure the Azure Data Explorer exporter
In order to ingest your OpenTelemetry data into Azure Data Explorer, you need [deploy and run](https://opentelemetry.io/docs/collector/deployment/) the OpenTelemetry distribution with the following Azure Data Explorer exporter configuration.
1. Configure the Azure Data Explorer exporter using the following fields:
    |Field | Description | Suggested setting|
    |---|---|---|
    | Exporters| Type of exporter | Azure Data Explorer | 
    |  cluster_uri |   URI of the Azure Data Explorer cluster that holds the database and tables |  https:// &lt;cluster>.kusto.windows.net |
    | application_id |  Client ID|  &lt;application id> |
    | application_key| Client secret |  &lt;application key> |
    | tenant_id | Tenant |  &lt;application tenant>|
    | db_name | Database that receives the logs | oteldb, or other database you have already created
    | metrics_table_name | The target table in the database db_name that stores exported metric data. | OTELMetrics
    | logs_table_name | The target table in the database db_name that stores exported logs data. | OTELLogs
    | traces_table_name | The target table in the database db_name that stores exported traces data. | OTELTraces
    | ingestion_type | Type of ingestion: managed (streaming) or batched | managed
    | otelmetrics_mapping | Optional parameter. Default table mapping is defined during table creation based on OTeL [metrics attributes](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/azuredataexplorerexporter#metrics). The default mapping can be changed using this parameter. | &lt;json metrics_table_name mapping>
    | otellogs_mapping | Optional parameter. Default table mapping is defined during table creation based on OTeL [logs attributes](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/azuredataexplorerexporter#logs). The default mapping can be changed using this parameter. | &lt;json logs_table_name mapping>
    | oteltraces_mapping | Optional parameter. Default table mapping is defined during table creation based on OTeL [trace attributes](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/azuredataexplorerexporter#traces). The default mapping can be changed using this parameter. |&lt;json traces_table_name mapping>
    | logLevel |  | info
    | extensions | Services: extension components to enable | [pprof, zpages, health_check]
    | traces | Services: traces components to enable   |  receivers: [otlp]  processors: [batch]  exporters: [azuredataexplorer]
    | metrics | Services: metrics components to enable | receivers: [otlp]  processors: [batch]  exporters: [logging, azuredataexplorer]
    | logs | Services: logs components to enable | receivers: [otlp]  processors: [batch]  exporters: [ azuredataexplorer]
1. Use the "--config" flag to run the Azure Data Explorer exporter.
The following is an example configuration for the Azure Data Explorer exporter:
```yaml
exporters:
  azuredataexplorer:
    cluster_uri: "https://.kusto.windows.net"
    application_id: ""
    application_key: ""
    tenant_id: ""
    db_name: "oteldb"
    metrics_table_name: "OTELMetrics"
    logs_table_name: "OTELLogs"
    traces_table_name: "OTELTraces"
    ingestion_type : "managed"
    otelmetrics_mapping : ""
    otellogs_mapping  : ""
    oteltraces_mapping  : ""
  logging:
    logLevel: info
service:
  extensions: [pprof, zpages, health_check]
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [azuredataexplorer]
    metrics:
      receivers: [otlp]