title:Workshop on Dependability Benchmarking
author:Philip Koopman and
Henrique Madeira
Workshop on Dependability Benchmarking
Philip Koopman
ECE Department & ICES
Carnegie Mellon University
Pittsburgh, PA, USA
PI:EMAIL
Henrique Madeira
Information Engineering Deptartment
University of Coimbra
Coimbra, Portugal
PI:EMAIL
Classical features such as raw performance and func-
tionality have long driven the computer industry to improve
their products. But now, dependability and maintainability
are seen as equally important. While there are relatively
straightforward ways to evaluate and compare performance
and functionality of different systems or components, the
evaluation of dependability and maintainability features is
much more difficult. Among the challenges that must be
addressed are: incorporating the effects of software fail-
ures,
opaque
off-the-shelf hardware and software components, including
the effects of typical maintenance, operational, and config-
uration management procedures, and accommodating the
fact that different application areas have different require-
ments for the various factors influencing dependability.
characterizing
dependability
the
of
The goal of the Dependability Benchmarking Workshop
is to provide a forum for the computer industry and acade-
mia to discuss problems associated with the evaluation and
characterization of dependability and maintainability of
components and computer systems. The identification of
dependability benchmarking measures and the essential
technologies for dependability benchmarking, including
both experimental measuring and modeling technologies,
are central aspects of this large discussion meant to garner
ideas on practical and cost-effective ways to evaluate de-
pendability and maintainability features.
This workshop is the outcome of the first two years of
work of
the IFIP 10.4 WG SIG on Dependability
Benchmarking (SIGDeB) [SIGDeB02]. That SIG was
formed in November 1999 under the IFIP 10.4 WG to pro-
mote the research, practice, and adoption of benchmarks
for computer-related system dependability. Koopman &
Madeira were the founding co-chairs.
The SIGDeB charter focusses on four areas in particular:
• Exchanging ideas about dependability benchmarking,
from
including
practitioners
universities, industry, and government agencies.
researchers
and
(cid:127) Documenting the state of the art for dependability
measurement and benchmarking.
(cid:127) Creating lists of issues that must be resolved to advance
dependability benchmarking to a mature science.
i
(cid:127) Eventually, proposing a mechanism and agenda for a
group to propose dependability benchmarks.
Of course those are long term objectives that will require
far more than two years of work to accomplish. But several
of the papers presented are the results of SIGDeB collabo-
rations that have made progress. Beyond that, this work-
shop represents the first focussed exchange of ideas about
dependability benchmarking in a public forum.
While the SIGDeB has been working, two other re-
search programs have been created to address related areas:
DBench and HDCP. Both DBench and HDCP have mem-
bership overlaps with SIGDeB, but are different in purpose.
DBench is a 3-year European research program to “de-
fine a conceptual framework and an experimental environ-
ment for benchmarking the dependability of COTS and
COTS-based systems” [DBench02]. It emphasizes the ar-
eas of dependability measurement, identification of mal-
functions/weaknesses,
tuning components to improve
dependability, and dependability comparisons. Most mea-
surements use fault injection, and the majority of partici-
pants come from the fault tolerant computing community.
The HDCP (High Dependability Computing Program) is
a long-term collaboration of US universities and NASA,
with expected industry participation,
to “ensure that the
software we create meets the ever more challenging re-
quirements of continuous operation, safety critical reliabil-
ity, high integrity and high security” [HDCP02]. HDCP is
formed largely of researchers from the software engineer-
ing community.
We are pleased that the papers being presented represent
the SIGDeB, DBench, HDCP, and other researchers not
formally affiliated with any of those groups.
References:
[DBench02]
Benchmarking
http://www.laas.fr/DBench/ accessed April 4, 2002.
Dependability
Project,
[HDCP02]
Program,
http://west.cmu.edu/research/hdcp.html accessed June 11, 2002.
Dependability
Computing
High
SIG
[SIGDeb02]
Benchmarking
http://www.dependability.org/wg10.4/SIGDeB/ accessed April 4,
2002.
Dependability
on