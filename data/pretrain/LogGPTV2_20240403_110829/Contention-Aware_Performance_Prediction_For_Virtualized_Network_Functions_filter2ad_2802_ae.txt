### Figure 16: SLOMO’s Prediction Error When Contentiousness Vector is Observed Versus Composed

### 7.3 SLOMO Use Cases

To demonstrate the practical benefits of SLOMO, we present two key use cases: efficient online scheduling in an NFV (Network Function Virtualization) cluster and improved resource partitioning using CAT (Cache Allocation Technology).

#### Scheduling with SLOMO

We consider an online scheduling scenario where the operator periodically receives NF (Network Function) scheduling requests, each containing the NF's description and an SLA (Service Level Agreement) that specifies the maximum allowable throughput drop relative to solo operation. The operator's goal is to maximize resource utilization while minimizing SLA violations.

Given that the optimal algorithm for this task is NP-complete [37], we employ a greedy incremental algorithm that evaluates, for every node, whether the addition of the NF will lead to SLA violations [51]. If no feasible schedule is found, an additional server is provisioned.

In our simulations, we run 10 trials, each consisting of 1000 scheduling requests. Each NF is randomly selected from a pool of profiled NFs and given a throughput SLA in the 5-30% range. We exhaustively test all possible combinations of requests to determine the feasible schedules and those that result in SLO (Service Level Objective) violations.

We compare SLOMO's schedules with those derived using Dobrescu's CAR-based model and ResQ, a contention-aware scheduler by Tootoonchian et al. [51]. Table 8 presents the simulation results in terms of the percentage of additional machines required with respect to the optimal schedule and the associated SLO violations.

| System       | Resource Overhead (%) | SLO Violations (%) |
|--------------|-----------------------|--------------------|
| SLOMO        | 1.5%                  | 0%                 |
| ResQ [51]    | 6%                    | 3%                 |
| Dobrescu [24]| 14%                   | 0%                 |

**Table 8: Resource Requirements and SLO Violations in Online NF Scheduling**

#### SLOMO and CAT

We test our NFs on the Broadwell architecture (Skylake does not support CAT) and allocate 25% of the LLC (Last Level Cache, 5MB) to the target NF. Competitors contend for the remaining LLC space. Table 9 shows the average absolute mean prediction error for the target NF using SLOMO against the percentage difference in the target's throughput from its solo performance in the same partition of the LLC. We categorize our target NFs as sensitive or insensitive to contention. We observe that SLOMO’s prediction error is approximately 3 times lower than the "error" an operator would make assuming that CAR achieves perfect isolation and linear performance scaling.

| NF           | SLOMO Error (%) | Observed Drop (%) |
|--------------|-----------------|-------------------|
| Not Sensitive| <1%             | <1%               |
| Sensitive    | 4.5%            | 13.8%             |

**Table 9: SLOMO Prediction Error in the Presence of CAT**

### 7.4 Extrapolation

Finally, we demonstrate the potential of extrapolation. We use 5 NF types (IP Router, FlowStats, VPN, Snort, and Maglev LB) and, in each experiment, change either the number of unique traffic flows or the ruleset size by a factor of up to ±20%. For example, for FlowStats, the initial NF processed 400K unique flows. Our new configurations were in the [320K-480K] range. This is because, intuitively, one can only extrapolate when the NF’s behavior is not expected to change drastically. As discussed in §7.1, extrapolating changes for FlowStats between 40K and 400K flows would be unwise.

Figure 17 shows the absolute mean prediction error broken down across NFs that are sensitive to contention (IPRouter, FlowStats, Snort) and non-sensitive NFs. For contention-sensitive NFs, using the extrapolated sensitivity adds, on average, 3% to the prediction error compared to the average error when the sensitivity function is known. Without extrapolation, i.e., when using the old sensitivity function, the prediction error doubles on average. For non-sensitive NFs, the difference in error is marginal.

**Figure 17: Prediction Error of Extrapolated Sensitivity Functions**

### 8. Discussion

#### What if NFi Does Not Use Packet Acceleration?

For NFs that do not use packet acceleration, the kernel-based network stack becomes the major performance bottleneck, determining NFs' sensitivity [35]. However, with competing NFs running on dedicated cores and appropriate core-interrupt affinity, NFi’s contentiousness can still be characterized using SLOMO.

#### Can SLOMO Account for Other Sources of Contention?

Additional sources of contention fall within SLOMO’s scope as long as PCM (Performance Counter Monitor) exposes utilization metrics about these resources. For instance, relaxing the one NF per core assumption might lead to L2 cache contention, breaking NUMA affinity might result in QPI interconnect contention, and multiple traffic flows might contend for NIC resources [46]. Because PCM provides data on L2 hit rates and QPI bandwidth, SLOMO should perform well in these scenarios. However, SLOMO cannot currently address contention at the NIC because PCM does not measure NIC resources. Exploring what metrics to collect in scenarios beyond PCM’s scope is left for future work.

### 9. Related Work

#### Performance Prediction

Prior work in the architecture community identifies performance degradation due to shared-resource contention [26, 47, 48]. These works focus on informing processor designs that can dynamically reallocate shared resources during runtime without offline profiling. They complement SLOMO by providing architectural insights.

#### NF Management

Work in NFV management acknowledges the degradation problem and suggests workarounds via NF placement, such as E2 [41] and CoMB [44], which consolidate NFs to avoid cross-switch traffic. However, these works do not model contention-related performance degradation. Other works have looked at scaling NFs based on observable triggers like congestion, long tail latency, or packet drops [28, 31]. Using SLOMO for performance prediction can improve the utilization and SLAs for these efforts.

#### NF Isolation

Recent efforts explore ways to provide performance isolation between NFs on the same host, such as Netbricks [42] and ResQ [51]. These efforts are complementary to SLOMO, which can inform the design of isolation policies.

#### Prediction and Verification via Symbolic Execution

Recent work by Pedrosa et al. [43] uses symbolic execution to understand the execution paths an NF can take and uses a cache simulator to identify adversarial workloads. This requires access to NF source code, whereas SLOMO can work with black-box NF realizations. Similar works rely on symbolic execution to provide performance contracts or verify the correctness of Network Functions [30, 53].

### 10. Conclusions

Providing performance guarantees when NFs share hardware remains a challenge in NFV. Accurately predicting the potential performance for a future colocation configuration can inform provisioning and placement decisions in today’s NFV orchestration frameworks. While prior work identified the memory contention problem in NFV, it treated memory as a monolithic whole, leading to insufficient accuracy. In this work, we systematically investigate the memory subsystem and the sources behind contention-related slowdown. Our insights enable the development of SLOMO, a performance prediction framework for NFV. We show that SLOMO reduces prediction error by 2-5× and enables 6-14% more efficient cluster utilization compared to prior work.

**Ethics:** This work does not raise any ethical issues.

**Acknowledgments:** We thank our shepherd and the reviewers for their feedback. This work was supported in part by the CONIX Research Center, one of six centers in JUMP, a Semiconductor Research Corporation (SRC) program sponsored by DARPA, and NSF awards 1440056, 1440065, and 1700521.

### References

[References remain unchanged]

This version of the text is more structured, clear, and professional, with improved readability and coherence.