Figure 16: SLOMO’s prediction error when contentiousness vector is observed
versus composed.
7.3 SLOMO use cases
To demonstrate SLOMO’s practical benefits, we first show that
SLOMO can enable efficient online scheduling in an NFV cluster.
Then, we demonstrate how SLOMO can enable better resource
partitioning using CAT[6].
Scheduling with SLOMO: We consider an online scheduling sce-
nario where the operator periodically receives NF scheduling re-
quests, containing the NF’s description and an SLA (i.e., maximum
throughput drop relative to solo). The operator’s goal is to maxi-
mize resource utilization while minimizing SLA violations. Given
that the optimal algorithm for this task is NP-complete [37], we opt
for a greedy incremental algorithm that evaluates for every node
whether the addition of the NF will lead to SLA violations [51]. If
there’s no feasible schedule then we provision an additional server.
We run 10 simulations of 1000 scheduling requests, where an
NF is picked randomly from the pool of profiled NFs and is given a
throughput SLA in the 5 − 30% range. We exhaustively run all
possible combinations of requests in our deployment to deter-
mine the feasible schedules and those result in SLO violations.
We compare SLOMO’s schedules with those derived using Do-
brescu’s CAR-based model and ResQ, a contention aware scheduler
by Tootoonchian et al. [51]. Table 8 presents the simulation results
in terms of how many additional machines (%) with respect to the
optimal schedule each approach requires and the associated SLO
violations (% of requests).
System
SLOMO
ResQ [51]
Dobrescu [24]
Resource overhead (%)
SLO violations
1.5%
6%
14%
0
3%
0
Table 8: Resource requirements and SLO violations in online NF scheduling.
GradientBoostingRidgeRegressionLinearRegressionLassoRegressionNeuralNetworkPolynomialRegressionGaussianProcessDecisionTree101102103104Prediction Error (%)SnortIP RouterVPNFlowStatsStatelessFirewallMagLev LBSuricatapfSense01020304050Prediction Error (%)ComposedObservedComposed SoloSLOMO and CAT: We test our NFs on the Broadwell architecture
(Skylake does not support CAT) and allocate 25% of the LLC (5MB)
to the target NF. The competitors contend for the remaining LLC
space. Table 9 shows the average absolute mean prediction error for
the target NF using SLOMO against the percentage difference in the
target’s throughput from its solo performance in the same partition
of the LLC. We categorize our target NFs as sensitive vs. insensitive
to contention. We observe that SLOMO’s prediction error is ∼ 3×
lower that the "error" an operator would make assuming that CAR
achieves perfect isolation and linear performance scaling.
NF
SLOMO error Observed drop
Not sensitive
Sensitive
<1%
4.5%
<1%
13.8%
Table 9: SLOMO Prediction error in the presence of CAT
7.4 Extrapolation
Finally, we show the promise of extrapolation. We use 5 NF
types (IP Router, FlowStats, VPN, Snort and Maglev LB) and at
each experiment we change either the number of unique traffic
flows or the ruleset size by a factor of up to ±20%. For example,
for Flowstats, the initial NF processed 400K of unique flows. Our
new configurations were in the [320K-480K] range. That is because,
intuitively, one can only extrapolate when the NF’s behavior is not
expected to change drastically. Considering the discussion in §7.1
about the behavior of FlowStats being radically different for 40K
and 400K flows, extrapolating this change would be unwise.
Figure 17 shows the absolute mean prediction error broken down
across NFs that are sensitive to contention (IPRouter, FlowStats,
Snort) with that of non-sensitive NFs. For contention sensitive
NFs, using the extrapolated sensitivity adds on average 3% to the
prediction error compared to the average error when the sensitivity
function is already known. Without extrapolation i.e., when we use
the old sensitivity function, the prediction error on average doubles.
For non-sensitive NFs, the difference in error is marginal.
Figure 17: Prediction error of extrapolated sensitivity functions
8 DISCUSSION
What if NFi does not use packet acceleration? In cases of NFs
that do not use packet acceleration, we find that the kernel-based
network stack will become the major performance bottleneck and
determine NFs’ sensitivity [35]. However, as competing NFs run on
dedicated cores and with appropriate core-interrupt affinity, NFi’s
contentiousness can still be characterized using SLOMO.
Can SLOMO account for other sources of contention? Addi-
tional sources of contention fall within SLOMO’s scope as long as
PCM exposes utilization metrics about these resources. For instance,
relaxing the one NF per core assumption might lead to contention
in the L2 cache, breaking NUMA affinity might result in contention
at the QPI interconnect, and multiple traffic flows might contend for
NIC resources [46]. Because PCM exposes data about L2 hit rates
and QPI bandwidth, we would expect SLOMO to perform well in
this scenario. On the other hand, SLOMO cannot currently address
contention at the NIC because PCM does not measure resources
at the NIC. We leave an exploration of what metrics to collect in
scenarios beyond the scope of PCM to future work.
9 RELATED WORK
Performance prediction: Prior work in the architecture com-
munity identifies performance degradation due to shared-resource
contention [26, 47, 48]. The focus here is to inform processor de-
signs that can dynamically reallocate their shared resources during
runtime without offline profiling of each process. These works are
complimentary to ours as the focus is on the architectural design
that enables insights similar to SLOMO’s.
NF management: Work in NFV management acknowledges the
degradation problem and suggested workarounds via NF placement;
e.g., E2 [41] and CoMB [44] consolidate NFs to avoid cross-switch
traffic. However, these works do not model contention-related per-
formance degradation. Other works have also looked at scaling NFs
based on observable triggers such as congestion, long tail latency
or packet drops [28, 31]. Using SLOMO for performance prediction
can improve the utilization and SLAs for these efforts.
NF isolation: Recent efforts explore ways to provide performance
isolation between NFs on the same host; e.g., Netbricks [42] and
ResQ [51]. These efforts are complementary to SLOMO which can
be used to inform the design of isolation policies.
Prediction and verification via symbolic execution: Recent
work by Pedrosa et al. [43] uses symbolic execution to understand
the execution paths a NF can take and uses a cache simulator to iden-
tify adversarial workloads. This requires access to NF source code,
whereas SLOMO can work with blackbox NF realizations. Similar
works rely on symbolic execution either to provide performance
contracts or to verify the correctness of Network Functions [30, 53].
10 CONCLUSIONS
Providing performance guarantees when NFs share hardware
remains an elusive goal in NFV. The ability to accurately predict
the potential performance for a future colocation configuration
can inform the provisioning and placement decisions in today’s
NFV orchestration frameworks. While prior work identified the
memory contention problem in NFV, it treated memory as mono-
lithic whole and cannot provide sufficient accuracy in today’s NFV
landscape. In this work we systematically investigate the memory
subsystem and the sources behind contention-related slowdown.
Our insights enable the development of SLOMO, a performance
prediction framework for NFV. We show that relative to prior work
SLOMO reduces prediction error by 2-5× and enables 6-14% more
efficient cluster utilization.
Ethics: This work does not raise any ethical issues.
Acknowledgments: We thank our shepherd and the reviewers
for their feedback. This work was supported in part by the CONIX
Research Center, one of six centers in JUMP, a Semiconductor Re-
search Corporation (SRC) program sponsored by DARPA, and NSF
awards 1440056, 1440065, and 1700521.
Not SensitiveSensitive0510152025Prediction Error (%)Known SensitivityExtrapolated SensitivityNo ExtrapolationNo Extrapolation DobrescuREFERENCES
[1] Aggregate PCM Metrics. https://software.intel.com/en-us/forums/software-
tuning-performance-optimization-platform-monitoring/topic/277497.
[2] AT&T. Domain2.
https://www.att.com/Common/about_us/pdf/AT&T%
20Domain%202.0%20Vision%20White%20Paper.pdf.
[3] AT&T. ECOMP.
https://policyforum.att.com/wp-content/uploads/2017/03/
ecomp-architecture-whitepaper-att.pdf.
[4] Dpdk-performance tuning guide. https://doc.dpdk.org/guides-16.11/linux_gsg/
[5] ETSI. Network Functions Virtualization.
https://portal.etsi.org/NFV/
nic_perf_intel_platform.html.
NFV_White_Paper.pdf.
2009.
[6] Intel cache allocation technology. https://www.intel.com/content/www/us/en/
communications/cache-monitoring-cache-allocation-technologies.html.
[7] Intel direct data i/o technology. https://www.intel.com/content/www/us/en/io/
data-direct-i-o-technology.html.
[8] Intel PCM. https://github.com/opcm/pcm.
[9] Intel skylake-x review: Core i9 7900x,
i7 7820x and i7 7800x tested.
https://www.anandtech.com/show/11550/the-intel-skylakex-review-core-i9-
7900x-i7-7820x-and-i7-7800x-tested/4.
[10] Linux Foundation. OPNFV. https://www.opnfv.org/.
[11] Mellanox-performance tuning guide. https://community.mellanox.com/s/article/
performance-tuning-for-mellanox-adapters.
[12] Reducing os jitter due to per-cpu kthreads. https://www.kernel.org/doc/html/
latest/admin-guide/kernel-per-CPU-kthreads.html.
[13] Snort: Network Intrusion Detection & Detection System. https://www.snort.org.
[14] SR-IOV. https://github.com/intel/sriov-network-device-plugin.
[15] Suricata: Open source ids, ips, nsm ensgine. https://suricata-ids.org.
[16] A. Abel, F. Benz, J. Doerfert, B. Dörr, S. Hahn, F. Haupenthal, M. Jacobs, A. H.
Moin, J. Reineke, B. Schommer, et al. Impact of resource sharing on performance
and performance prediction: A survey. In International Conference on Concurrency
Theory, pages 25–43. Springer, 2013.
[17] L. A. Barroso, J. Clidaras, and U. Hölzle. The datacenter as a computer: An
introduction to the design of warehouse-scale machines. Synthesis lectures on
computer architecture, 8(3):1–154, 2013.
[18] J. Benesty, J. Chen, Y. Huang, and I. Cohen. Pearson correlation coefficient. In
Noise reduction in speech processing, pages 1–4. Springer, 2009.
[19] C. M. Buechler and J. Pingle. pfsense: The definitive guide. Reed Media Services,
[20] C. Delimitrou and C. Kozyrakis. Paragon: Qos-aware scheduling for heteroge-
neous datacenters. In ACM SIGPLAN Notices, volume 48, pages 77–88. ACM,
2013.
[21] C. Delimitrou and C. Kozyrakis. Quasar: resource-efficient and qos-aware cluster
management. ACM SIGPLAN Notices, 49(4):127–144, 2014.
[22] T. G. Dietterich. Ensemble methods in machine learning. In International workshop
on multiple classifier systems, pages 1–15. Springer, 2000.
[23] I. D. Direct. I/o technology (intel ddio) a primer, 2012.
[24] M. Dobrescu, K. Argyraki, and S. Ratnasamy. Toward predictable performance
in software packet-processing platforms. In Proc. NSDI 12, pages 141–154, San
Jose, CA, 2012. USENIX.
[25] M. Dobrescu, N. Egi, K. Argyraki, B. Chun, K. Fall, G. Iannaccone, A. Knies,
M. Manesh, and S. Ratnasamy. Routebricks: Exploiting parallelism to scale
software routers. In Proc. SOSP 2009, SOSP ’09, pages 15–28, New York, NY, USA,
2009. ACM.
[26] E. Ebrahimi, C. J. Lee, O. Mutlu, and Y. N. Patt. Fairness via source throttling: a
configurable and high-performance fairness substrate for multi-core memory
systems. In ACM Sigplan Notices, volume 45, pages 335–346. ACM, 2010.
[27] J. H. Friedman. Greedy function approximation: a gradient boosting machine.
Annals of statistics, pages 1189–1232, 2001.
[28] A. Gember-Jacobson, R. Viswanathan, C. Prakash, R. Grandl, J. Khalid, S. Das,
and A. Akella. Opennf: Enabling innovation in network function control. In
ACM SIGCOMM Computer Communication Review, volume 44, pages 163–174.
ACM, 2014.
[29] D. M. Hawkins. The problem of overfitting. Journal of chemical information and
computer sciences, 44(1):1–12, 2004.
[30] R. Iyer, L. Pedrosa, A. Zaostrovnykh, S. Pirelli, K. Argyraki, and G. Candea. Perfor-
mance contracts for software network functions. In 16th {USENIX} Symposium
on Networked Systems Design and Implementation ({NSDI} 19), pages 517–530,
2019.
[31] M. Kablan, A. Alsudais, E. Keller, and F. Le. Stateless network functions: Breaking
the tight coupling of state and processing. In NSDI, pages 97–112, 2017.
[32] E. Kohler, R. Morris, B. Chen, J. Jannotti, and F. Kaashoek. The click modular
router. In Proc. TOCS 2000, volume 18, pages 263–297. ACM, 2000.
[33] C. Kozyrakis, A. Kansal, S. Sankar, and K. Vaid. Server engineering insights for
large-scale online services. IEEE micro, 30(4):8–19, 2010.
[34] M. Kurth, B. Gras, D. Andriesse, C. Giuffrida, H. Bos, and K. Razavi. Netcat:
Practical cache attacks from the network, 2020.
[35] J. Li, N. K. Sharma, D. R. K. Ports, and S. D. Gribble. Tales of the tail: Hardware, os,
and application-level sources of tail latency. In Proceedings of the ACM Symposium
on Cloud Computing, SOCC ’14, page 1–14, New York, NY, USA, 2014. Association
for Computing Machinery.
[36] Y. Li and M. Chen. Software-defined network function virtualization: A survey.
IEEE Access, 3:2542–2553, 2015.
[37] E. C. man Jr, M. Garey, and D. Johnson. Approximation algorithms for bin packing:
A survey. Approximation algorithms for NP-hard problems, pages 46–93, 1996.
[38] J. Mars, L. Tang, and R. Hundt. Heterogeneity in “homogeneous” warehouse-
scale computers: A performance opportunity. IEEE Computer Architecture Letters,
10(2):29–32, 2011.
[39] J. Mars, L. Tang, R. Hundt, K. Skadron, and M. L. Soffa. Bubble-up: Increasing
utilization in modern warehouse scale computers via sensible co-locations. In
Proceedings of the 44th annual IEEE/ACM International Symposium on Microarchi-
tecture, pages 248–259. ACM, 2011.
[40] L. A. Mauricio, M. G. Rubinstein, and O. C. Duarte. Proposing and evaluating
the performance of a firewall implemented as a virtualized network function. In
2016 7th International Conference on the Network of the Future (NOF), pages 1–3.
IEEE, 2016.
[41] S. Palkar, C. Lan, S.Han, K. Jang, A. Panda, S. Ratnasamy, L. Rizzo, and S. Shenker.
E2: A framework for nfv applications. In Proc. SOSP 2015, SOSP ’15, pages 121–136,
New York, NY, USA, 2015. ACM.
[42] A. Panda, S. Han, K. Jang, M. Walls, S. Ratnasamy, and S. Shenker. Netbricks:
Taking the v out of nfv. In OSDI, pages 203–216, 2016.
[43] L. Pedrosa, R. Iyer, A. Zaostrovnykh, J. Fietz, and K. Argyraki. Automated
In Proceedings of
synthesis of adversarial workloads for network functions.
the 2018 Conference of the ACM Special Interest Group on Data Communication,
SIGCOMM ’18, pages 372–385, New York, NY, USA, 2018. ACM.
[44] V. Sekar, N. Egi, S. Ratnasamy, M. Reiter, and G. Shi. Design and implementation
of a consolidated middlebox architecture. In Proc. of NSDI 2012, NSDI’12, pages
24–24, Berkeley, CA, USA, 2012. USENIX Association.
[45] J. Sherry, S. Hasan, C. Scott, A. Krishnamurthy, S. Ratnasamy, and V. Sekar.
Making middleboxes someone else’s problem: network processing as a cloud
service. ACM SIGCOMM Computer Communication Review, 42(4):13–24, 2012.
[46] B. Stephens, A. Akella, and M. Swift. Loom: Flexible and efficient {NIC} packet
scheduling. In 16th {USENIX} Symposium on Networked Systems Design and
Implementation ({NSDI} 19), pages 33–46, 2019.
[47] L. Subramanian, V. Seshadri, A. Ghosh, S. Khan, and O. Mutlu. The application
slowdown model: Quantifying and controlling the impact of inter-application
interference at shared caches and main memory. In Proc. ACM MICRO 2015, pages
62–75. ACM, 2015.
[48] L. Subramanian, V. Seshadri, Y. Kim, B. Jaiyen, and O. Mutlu. Mise: Providing
performance predictability and improving fairness in shared main memory sys-
tems. In High Performance Computer Architecture (HPCA2013), 2013 IEEE 19th
International Symposium on, pages 639–650. IEEE, 2013.
[49] L. Tang, J. Mars, and M. L. Soffa. Contentiousness vs. sensitivity: Improving
contention aware runtime systems on multicore architectures. In Proceedings of
the 1st International Workshop on Adaptive Self-Tuning Computing Systems for the
Exaflop Era, EXADAPT ’11, pages 12–21, New York, NY, USA, 2011. ACM.
[50] L. Tang, J. Mars, N. Vachharajani, R. Hundt, and M. L. Soffa. The impact of mem-
ory subsystem resource sharing on datacenter applications. In ACM SIGARCH
Computer Architecture News, volume 39, pages 283–294. ACM, 2011.
[51] A. Tootoonchian, A. Panda, C. Lan, M. Walls, K. Argyraki, S. Ratnasamy, and
S. Shenker. Resq: Enabling slos in network function virtualization. In 15th USENIX
Symposium on Networked Systems Design and Implementation NSDI 18. USENIX,
2018.
[52] Y. Yang and J. O. Pedersen. A comparative study on feature selection in text
categorization. In Icml, volume 97, page 35, 1997.
[53] A. Zaostrovnykh, S. Pirelli, R. Iyer, M. Rizzo, L. Pedrosa, K. Argyraki, and G. Can-
dea. Verifying software network functions with no verification expertise. In
Proceedings of the 27th ACM Symposium on Operating Systems Principles, pages
275–290, 2019.
[54] Z.-H. Zhou. Ensemble methods: foundations and algorithms. Chapman and
Hall/CRC, 2012.