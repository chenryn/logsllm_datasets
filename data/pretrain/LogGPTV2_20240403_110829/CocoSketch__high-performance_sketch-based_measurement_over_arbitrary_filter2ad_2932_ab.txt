arbitrary partial key queries enables a broad spectrum of potential
use cases. In Trumpet [65], applications, such as guiding rule place-
ment [66], coflow scheduling [67], and multi-key rate limiting [68],
require estimation results over many different keys. For instance,
there are often thousands of rules in rule management [66], which
require measurement on different combinations of fields/prefixes
in the 5-tuple (i.e., tens to hundreds of different keys). Moreover,
in security and diagnosis scenarios [21, 42â€“48], it is often hard to
predict which keys are relevant to future security incidents unless
we exhaustively track all possible keys. For example, DDoS detec-
tion needs various metrics (e.g., heavy hitters, distinct flows) over
potentially many flow keys, including SrcIP/DstIP, the 5-tuple, and
any arbitrary prefixes of them [21].
2.3 Existing Solutions and Limitations
In this section, we show why existing single-key sketches are ill-
suited to arbitrary partial key queries, whereas the theory literature
offers a promising yet impractical approach.
One single-key sketch per key: One strawman to realize ar-
bitrary partial key queries is by creating one single-key sketch
(e.g., [33, 40]) for each possible partial key. This method does not
scale to many keys because deploying and updating many sketches
simultaneously can cause significant storage and update overheads.
Recent work R-HHH [39] can reduce the per-sketch operation over-
head on multiple sketches (by randomly selecting ğ‘‚(1) sketches
to be updated per packet). While this sampling-based approach
improves the sketch throughput in software, it will significantly
increase resource usage to reach the same error bound or lower
the accuracy given the same amount of memory space [39]. In
hardware switches such as Barefoot Tofino [49], its resource usage
(summarized in Table 2) will grow linearly with more sketches, so
this approach cannot support more than a handful of keys.
Full-key sketch with post recovery: Alternatively, we can de-
ploy a single-key sketch for the full key and use the two following
ways to recover the size of a partial-key flow from the full-key flow
information, though neither is ideal. (i) One way is to recover the
size of each partial-key flow by querying and aggregating the sizes
of all possible full-key flows that belong to the partial-key flow,
but the number of such full-key flows can be prohibitively large:
e.g., with the 32-bit SrcIP as the partial key and the 104-bit 5-tuple
as the full key, one needs to query (2104/232)=272 full-key flows
Resource Name
Hash Distribution Unit
Stateful ALU
Gateway
Map RAM
SRAM
Count-Min R-HHH
22.22%
16.67%
8.33%
7.11%
4.27%
20.83%
16.67%
7.81%
7.11%
4.27%
Table 2: Resource usage breakdown of one single-key sketch
(same configuration as Â§7.1) on a Tofino switch. The resource
bottleneck is the hash distribution unit (in bold). A Tofino
switch cannot support more than four single-key sketches.
Theory
Target
(cid:16)ğ‘“ (ğ‘’) âˆ’(cid:98)ğ‘“ (ğ‘’)(cid:17)2
(cid:16)ğ‘“ (ğ‘’) âˆ’(cid:98)ğ‘“ (ğ‘’)(cid:17)2
minimize maxğ‘’
Single-key sketches
Subset sum estimation minimizeğ‘’
of flow ğ‘’.(cid:98)ğ‘“ (ğ‘’) is the estimated size of flow ğ‘’.
Table 3: In contrast to single-key sketches, subset sum esti-
mation optimizes a different accuracy objective that is more
suitable for arbitrary partial key queries. ğ‘“ (ğ‘’) is the real size
to estimate merely one partial-key flow. (ii) An alternative way is
that, instead of aggregating the estimates of all full-key flows, we
aggregate only the full-key flows that are explicitly logged in the
sketch. Prior analysis [53], however, suggests that aggregating such
a subset of flows can yield high estimation bias and variance, and
our evaluation in Â§7.5 indeed shows that it has higher estimation
errors on partial keys than on the full key.
Subset sum estimation: We advocate for a more promising ap-
proach â€“ casting the arbitrary partial key query problem to the
subset sum estimation problem. As summarized in Table 3, unlike
single-key sketches that minimize the maximum estimation error
on individual keys, subset sum estimation offers an unbiased es-
timate on the sum of all (and any subset of) items with minimum
variance. It fits nicely with our goal since each partial-key flow size
equals the total size of a subset of full-key flows.
Unfortunately, existing work on subset sum estimation, notably
Unbiased SpaceSaving (USS) [53], is impractical for network mea-
surement. As will be elaborated in Â§3.2, USS performs ğ‘‚(ğ‘›) memory
accesses on every arriving packet, where ğ‘› is the number of flows
currently maintained in the system and can be on the scale of 104.
Such prohibitive per-packet update overhead makes USS hard to
keep up with the line rate requirements on software platforms and
infeasible to run on some hardware platforms such as Barefoot
Tofino [49]. Without changing the algorithm, it might be hard to
speed it up with better implementation to achieve desirable per-
formance. Â§7.2 shows that when accelerated by a hash table and a
double linked list, USS still only achieves less than 1/3 the through-
put of a single-key sketch.
In summary, re-using single-key sketches is a fundamental mis-
match with the accuracy requirements of arbitrary partial key
queries, whereas USS fits the accuracy goal of arbitrary partial
key queries but falls short on system performance. The following
sections will provide more details of USS and how we make it
practical for hardware/software-based network measurements.
SIGCOMM â€™21, August 23â€“28, 2021, Virtual Event, USA
Y. Zhang et al.
Figure 1: CocoSketch architecture.
3 OVERVIEW
We now give an overview of our solution, CocoSketch, and its two
key ideas: stochastic variance minimization (Â§3.2) and removal of
circular dependencies (Â§3.3).
3.1 Problem Scope
Requirements: CocoSketch has three design requirements:
â€¢ [R1] Accuracy guarantees over partial keys: CocoSketch should
provide accuracy guarantees for all partial key queries. This paper
focuses on the accuracy of flow size-related queries (e.g., heavy
hitter detection, heavy change detection).
â€¢ [R2] Compute and memory resource efficiency: CocoSketch
should achieve high throughput using small memory footprints,
on both software and hardware platforms.
â€¢ [R3] Compatibility with diverse platforms: CocoSketch should
work on both software (e.g., CPU and OVS [50]) and hardware
(e.g., FPGA [51] and reconfigurable ASIC [49]) platforms [69â€“73].
CocoSketch workflow: Before the measurement starts, the oper-
ator defines a full key ğ‘˜ğ¹ , of which any key that might be queried
will be a partial key. ğ‘˜ğ¹ can be a large range of packet header fields
such as 5-tuple or application-layer headers. Figure 1 shows the
workflow of CocoSketch. CocoSketch maintains a single sketch
with ğ‘‘ Â· ğ‘™ buckets (where ğ‘‘ and ğ‘™ are configurable parameters). On
each arriving packet, CocoSketchâ€™s data plane updates the sketch
in two logical steps:
Step 1: Extract the full key value ğ‘’ of the flow and use ğ‘‘ hash
functions to map ğ‘’ to ğ‘‘ buckets, each from an array of ğ‘™ buckets.
Step 2: Update the counters of the mapped buckets with the
packet size using stochastic variance minimization (explained shortly).
At the end of each measurement window, CocoSketchâ€™s control
plane will answer flow size queries defined on any partial key
ğ‘˜ğ‘ƒ â‰º ğ‘˜ğ¹ , with two logical steps:
recover the size of each recorded full-key flow.
Step 3: Based on the sketch maintained by the data plane, first
Step 4: Aggregate the sizes of only the recorded full-key flows
to infer the size of the flows defined by the queried partial key ğ‘˜ğ‘ƒ.1
Next, we discuss the two technical ideas of CocoSketch. Figure 2
illustrates CocoSketchâ€™s performance advantages over the baselines.
1Note that this step would have had no accuracy guarantee, if the sketch were a full-key
sketch updated by the traditional single-key sketch algorithm (as discussed in Â§2.3).
Figure 2: Accuracy-throughput analysis.
3.2 Stochastic Variance Minimization
Variance minimization in Unbiased SpaceSaving: Before de-
scribing our approach, we first explain how Unbiased SpaceSaving
(USS) [53] minimizes its variance of flow size estimates and why
it has a high update delay. For each incoming packet with full-key
flow ğ‘’ and packet size ğ‘¤, (1) if ğ‘’ is already tracked in a bucket,
then USS increments the counter of ğ‘’ in this bucket by ğ‘¤, so that
variance is not increased; (2) otherwise, USS scans all buckets to
find the min-sized bucket counter ğ¶ğ‘šğ‘–ğ‘›, increments it by ğ‘¤, and
then replaces the flow key associated with the bucket with ğ‘’ with
probability ğ‘¤
. As the number of memory accesses per update is
ğ¶ğ‘šğ‘–ğ‘›
the same as the number of buckets (on a scale of 104), USS violates
[R2] and [R3]. How to reduce the update cost of USS while still
maintaining the high accuracy guarantees?
Reducing update delay: We propose Stochastic Variance Mini-
mization: for each packet whose flow is not currently tracked by
the sketch, CocoSketch finds the smallest bucket among the ğ‘‘ hash-
indexed buckets (instead of all buckets), increments the counter,
and replaces the flow in the same way as USS (see details in Â§4.1).
In other words, if ğ‘‘ is the total number of buckets, CocoSketch
would be equivalent to USS. However, CocoSketch sets ğ‘‘ to be
much smaller (e.g., 2 to 4) than the number of buckets (e.g., 104),
thus drastically reducing the update delay.
Now, the key question is why updating the bucket among only
ğ‘‘ buckets (instead of all buckets) per packet still yields unbiased
size estimation with small variance?
Preserving estimation accuracy: The intuition is two-fold. Here,
we assume that the flow sizes follow a heavy-tailed distribution
(i.e., most flows have small sizes).
â€¢ First, for a large flow, the counter of the bucket where the flow
maps is a quite accurate estimate of its real flow size. This is
because, like in USS, its counter is mostly incremented by the
same large flow with a small chance of collision.
Packet!",4Step 1: Hash each packet toone bucket in each array!%,19!(,15â„+(.)â„/(.)Stochastic Variance MinimizationStep 2: Update mapped buckets based on stochastic variance minimizationupdateupdateData PlaneControl PlaneStep 3: Build the table of full key 01based on results in the sketchFullKeySize!+21!311!"39â€¦â€¦â€¦!515Step 4: Query arbitrary partial key 06by aggregating full key 01Partial KeySize7+={!+,!"}60â€¦â€¦â€¦7=={!3,!5}26Network StreamPacket: (Full key, Size)â€¦â€¦CocoSketchUSSThroughputAccuracySingle-key SketchCocoSketch: High-Performance Arbitrary Partial Key Measurement
SIGCOMM â€™21, August 23â€“28, 2021, Virtual Event, USA
Figure 3: Reconfigurable Match-Action pipeline.
â€¢ Second, for small flows, our technique, like USS, spreads out
the small flows among the mapped buckets (like a â€œload bal-
ancingâ€ process) to control the per-flow variance. Intuitively, by
always incrementing the minimum bucket among ğ‘‘ stochastically
selected buckets, it enjoys the benefit of â€œpower-of-ğ‘‘ choicesâ€.
Though these bucketsâ€™ values do not converge as fast as USS, the
maximum collisions in all buckets are still bounded with a high
probability, after a sufficiently large number of small flows arrive.
Even if the workload is not heavy-tailed, our theoretical analysis
(Â§5.2 and Â§A.2) shows that CocoSketch can still achieve the same
accuracy guarantee as that of USS by adding more buckets to in-
crease the hash space and reduce collisions. In the worst case, we
need ğ‘œ(cid:16)(1/ğ›¿)1/ğ‘‘(cid:17) times more space than USS, where ğ›¿ is the prob-
ability that a given error threshold is violated. In practice, when
ğ‘‘ = 2, ğ›¿ = 0.01, only 1.6Ã— more buckets are needed to achieve accu-
racy on par with USS. As a result, our evaluation Â§7.5 shows that
compared to USS, CocoSketch improves throughput by 100Ã— with
only a marginal drop in accuracy (less than 3% drop in F1 Score).
3.3 Circular Dependency Removal
While stochastic variance minimization allows CocoSketch to achieve
high performance in software platforms, it cannot be efficiently
implemented in hardware platforms due to inherent circular de-
pendencies in its update operations. We show this issue using the
Tofino architecture and propose an effective solution to address it.
Constraints in RMT switches: Figure 3 shows the pipeline archi-
tecture of a Tofino switch as an example of RMT (reconfigurable
match-action table) switches [74]. Each pipeline consists of multi-
ple stages, and importantly, each stage cannot access the memory
of any prior stages. Therefore, any sketch update algorithm must
follow a unidirectional workflow, i.e., data flow strictly from the
first stage to the last stage. Moreover, each pipeline has a limited
number (e.g., 12) of stages, and each stage has limited memory (e.g.,
SRAM and TCAM) and computing (e.g., ALU) resources. Thus, any
sketch algorithm must fit in a small memory space and perform a
small number of memory accesses per packet.
Circular dependencies and their removal: Unfortunately, sto-
chastic variance minimization introduces two forms of circular de-
pendency as illustrated in Figure 4, making it incompatible with the
unidirectional workflow in RMT switches. We design a hardware-
friendly algorithm (see details in Â§4.2) to remove these dependencies
for better performance and resource efficiency in hardware.
â€¢ First, we need to remove the circular dependency across buckets.
Recall that there are ğ‘‘ > 1 corresponding buckets per packet
update. The updates to these ğ‘‘ buckets depend on each other, i.e.,
whether a bucket needs an update depends on the key/value in
Figure 4: Removing circular dependency
each of the remaining buckets, causing a circular dependency.
To address this, we update each bucket independently and in
parallel. Instead of running one instance of stochastic variance
minimization on ğ‘‘ buckets, we run ğ‘‘ instances of stochastic vari-
ance minimization, each performed on only one bucket. Clearly,
stochastic variance minimization on one bucket may lead to larger
errors. To control the errors, we use the median value among the
ğ‘‘ buckets as the final result.
â€¢ Second, we further remove the circular dependency between
the flow key and its estimated size within each bucket. This