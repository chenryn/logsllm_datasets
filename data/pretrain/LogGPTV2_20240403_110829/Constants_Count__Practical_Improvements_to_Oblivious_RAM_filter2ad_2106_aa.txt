title:Constants Count: Practical Improvements to Oblivious RAM
author:Ling Ren and
Christopher W. Fletcher and
Albert Kwon and
Emil Stefanov and
Elaine Shi and
Marten van Dijk and
Srinivas Devadas
Constants Count: Practical Improvements  
to Oblivious RAM
Ling Ren, Christopher Fletcher, and Albert Kwon, Massachusetts Institute of Technology; 
Emil Stefanov, University of California, Berkeley; Elaine Shi, Cornell University; Marten van 
Dijk, University of Connecticut; Srinivas Devadas, Massachusetts Institute of Technology
https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/ren-ling
This paper is included in the Proceedings of the 
24th USENIX Security Symposium
August 12–14, 2015 • Washington, D.C.
ISBN  978-1-939133-11-3
Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXConstants Count: Practical Improvements to Oblivious RAM
Ling Ren
MIT
Christopher Fletcher
MIT
Albert Kwon
MIT
Emil Stefanov
UC Berkeley
Elaine Shi
Cornell University
Marten van Dijk
UConn
Srinivas Devadas
MIT
Abstract
Oblivious RAM (ORAM) is a cryptographic primitive
that hides memory access patterns as seen by untrusted
storage. This paper proposes Ring ORAM, the most
bandwidth-efﬁcient ORAM scheme for the small client
storage setting in both theory and practice. Ring ORAM
is the ﬁrst tree-based ORAM whose bandwidth is in-
dependent of the ORAM bucket size, a property that
unlocks multiple performance improvements.
First,
Ring ORAM’s overall bandwidth is 2.3× to 4× better
than Path ORAM, the prior-art scheme for small client
storage. Second, if memory can perform simple un-
trusted computation, Ring ORAM achieves constant on-
line bandwidth (∼ 60× improvement over Path ORAM
for practical parameters). As a case study, we show Ring
ORAM speeds up program completion time in a secure
processor by 1.5× relative to Path ORAM. On the the-
ory side, Ring ORAM features a tighter and signiﬁcantly
simpler analysis than Path ORAM.
1
Introduction
With cloud computing and storage gaining popularity,
privacy of users’ sensitive data has become a large con-
cern. It is well known, however, that encryption alone
is not enough to ensure data privacy. Even after encryp-
tion, a malicious server still learns a user’s access pattern,
e.g., how frequently each piece of data is accessed, if the
user scans, binary searches or randomly accesses her data
at different stages. Prior works have shown that access
patterns can reveal a lot of information about encrypted
ﬁles [14] or private user data in computation outsourc-
ing [32, 18].
Oblivious RAM (ORAM) is a cryptographic primi-
tive that completely eliminates the information leakage
in memory access traces. In an ORAM scheme, a client
(e.g., a local machine) accesses data blocks residing on
a server, such that for any two logical access sequences
of the same length, the observable communications be-
tween the client and the server are computationally in-
distinguishable.
ORAMs are traditionally evaluated by bandwidth—
the number of blocks that have to be transferred between
the client and the server to access one block, client stor-
age—the amount of trusted local memory required at the
client side, and server storage—the amount of untrusted
memory required at the server side. All three metrics
are measured as functions of N, the total number of data
blocks in the ORAM.
A factor that determines which ORAM scheme to use
is whether the client has a large (GigaBytes or larger) or
small (KiloBytes to MegaBytes) storage budget. An ex-
ample of large client storage setting is remote oblivious
ﬁle servers [30, 17, 24, 3]. In this setting, a user runs on
a local desktop machine and can use its main memory
or disk for client storage. Given this large client storage
budget, the preferred ORAM scheme to date is the SSS
construction [25], which has about 1 · logN bandwidth
and typically requires GigaBytes of client storage.
In the same ﬁle server application, however, if the user
is instead on a mobile phone, the client storage will have
to be small. A more dramatic example for small client
storage is when the client is a remote secure processor
— in which case client storage is restricted to the pro-
cessor’s scarce on-chip memory. Partly for this reason,
all secure processor proposals [18, 16, 8, 31, 22, 7, 5, 6]
have adopted Path ORAM [27] which allows for small
(typically KiloBytes of) client storage.
The majority of this paper focuses on the small client
storage setting and Path ORAM. In fact, our construc-
tion is an improvement to Path ORAM. However, in
Section 7, we show that our techniques can be eas-
ily extended to obtain a competitive large client storage
ORAM.
USENIX Association  
24th USENIX Security Symposium  415
Path ORAM
Ring ORAM
Ring ORAM + XOR
Online Bandwidth
Z logN = 4logN
∼ 1· logN
∼ 1
Overall Bandwidth
2Z logN = 8logN
3-3.5logN
2-2.5logN
log N levels
~
Table 1: Our contributions. Overheads are relative to an in-
secure system. Ranges in constants for Ring ORAM are due to
different parameter settings. The bandwidth cost of tree ORAM
recursion [23, 26] is small ( 150× for practical parameterizations. In con-
trast, the SSS construction does not have this bucket size
parameter and can achieve close to 1· logN bandwidth.
(This bucket-size-dependent bandwidth is exactly why
Path ORAM is dismissed in the large client storage set-
ting.)
Second, despite the importance of overall bandwidth,
online bandwidth—which determines response time—
is equally, if not more, important in practice. For Path
ORAM, half of the overall bandwidth must be incurred
online. Again in contrast, an earlier work [3] reduced
the SSS ORAM’s online bandwidth to O(1) by grant-
ing the server the ability to perform simple XOR compu-
tations. Unfortunately, their techniques do not apply to
Path ORAM.
1.2 Our Contributions
In this paper, we propose Ring ORAM to address both
challenges simultaneously. Our key technical achieve-
ment is to carefully re-design the tree-based ORAM such
that the online bandwidth is O(1), and the amortized
overall bandwidth is independent of the bucket size. We
compare bandwidth overhead with Path ORAM in Ta-
ble 1. The major contributions of Ring ORAM include:
• Small online bandwidth. We provide the ﬁrst
tree-based ORAM scheme that achieves ∼ 1 online
bandwidth, relying only on very simple, untrusted
computation logic on the server side. This repre-
sents at least 60× improvement over Path ORAM
for reasonable parameters.
• Bucket-size independent overall bandwidth.
While all known tree-based ORAMs incur an over-
all bandwidth cost that depends on the bucket size,
Ring ORAM eliminates this dependence, and im-
proves overall bandwidth by 2.3× to 4× relative to
Path ORAM.
• Simple and tight theoretical analysis. Using novel
proof techniques based on Ring ORAM’s eviction
416  24th USENIX Security Symposium 
USENIX Association
2
algorithm, we obtain a much simpler and tighter
theoretical analysis than that of Path ORAM. Of in-
dependent interest, we note that the proof of Lemma
1 in [27], a crucial lemma for both Path ORAM and
this paper, is incomplete (the lemma itself is cor-
rect). We give a rigorous proof for that lemma in
this paper.
As mentioned, one main application of small client
storage ORAM is for the secure processor setting. We
simulate Ring ORAM in the secure processor setting and
conﬁrm that the improvement in bandwidth over Path
ORAM translates to a 1.5× speedup in program comple-
tion time. Combined with all other known techniques,
the average program slowdown from using an ORAM is
2.4× over a set of SPEC and database benchmarks.
Extension to larger client storage. Although our ini-
tial motivation was to design an optimized ORAM
scheme under small client storage, as an interesting by-
product, Ring ORAM can be easily extended to achieve
competitive performance in the large client storage set-
ting. This makes Ring ORAM a good candidate in obliv-
ious cloud storage, because as a tree-based ORAM, Ring
ORAM is easier to analyze, implement and de-amortize
than hierarchical ORAMs like SSS [25]. Therefore, Ring
ORAM is essentially a united paradigm for ORAM con-
structions in both large and small client storage settings.
Organization.
In the rest of this introduction, we give
an overview of our techniques to improve ORAM’s on-
line and overall bandwidth. Section 2 gives a formal se-
curity deﬁnition for ORAM. Section 3 explains the Ring
ORAM protocol in detail. Section 4 gives a complete for-
mal analysis for bounding Ring ORAM’s client storage.
Section 5 analyzes Ring ORAM’s bandwidth and gives
a methodology for setting parameters optimally. Section
6 compares Ring ORAM to prior work in terms of band-
width vs. client storage and performance in a secure pro-
cessor setting. Section 7 describes how to extend Ring
ORAM to the large client storage setting. Section 8 gives
related work and Section 9 concludes.
1.3 Overview of Techniques
We now explain our key technical insights. At a high
level, our scheme also follows the tree-based ORAM
paradigm [23]. Server storage is a binary tree where each
node (a bucket) contains up to Z blocks and blocks per-
colate down the tree during ORAM evictions. We intro-
duce the following non-trivial techniques that allow us
to achieve signiﬁcant savings in both online and overall
bandwidth costs.
Eliminating online bandwidth’s dependence on
bucket size.
In Path ORAM, reading a block would
amount to reading and writing all Z slots in all buckets on
a path. Our ﬁrst goal is to read only one block from each
bucket on the path. To do this, we randomly permute
each bucket and store the permutation in each bucket as
additional metadata. Then, by reading only metadata,
the client can determine whether the requested block is
in the present bucket or not. If so, the client relies on
the stored permutation to read the block of interest from
its random offset. Otherwise, the client reads a “fresh”
(unread) dummy block, also from a random offset. We
stress that the metadata size is typically much smaller
than the block size, so the cost of reading metadata can
be ignored.
For the above approach to be secure, it is impera-
tive that each block in a bucket should be read at most
once—a key idea also adopted by Goldreich and Ostro-
vsky in their early ORAM constructions [11]. Notice that
any real block is naturally read only once, since once a
real block is read, it will be invalidated from the present
bucket, and relocated somewhere else in the ORAM tree.
But dummy blocks in a bucket can be exhausted if the
bucket is read many times. When this happens (which
is public information), Ring ORAM introduces an early
reshufﬂe procedure to reshufﬂe the buckets that have
been read too many times. Speciﬁcally, suppose that
each bucket is guaranteed to have S dummy blocks, then
a bucket must be reshufﬂed every S times it is read.
We note that the above technique also gives an addi-
tional nice property: out of the O(logN) blocks the client
reads, only 1 of them is a real block (i.e., the block of
interest); all the others are dummy blocks. If we allow
some simple computation on the memory side, we can
immediately apply the XOR trick from Burst ORAM [3]
to get O(1) online bandwidth.
In the XOR trick, the
server simply XORs these encrypted blocks and sends a
single, XOR’ed block to the client. The client can recon-
struct the ciphertext of all the dummy blocks, and XOR
them away to get back the encrypted real block.
Eliminating overall bandwidth’s dependence on
bucket size. Unfortunately, na¨ıvely applying the above
strategy will dramatically increase ofﬂine and overall
bandwidth. The more dummy slots we reserve in each
bucket (i.e., a large S), the more expensive ORAM evic-
tions become, since they have to read and write all the
blocks in a bucket. But if we reserve too few dummy
slots, we will frequently run out of dummy blocks and
have to call early reshufﬂe, also increasing overall band-
width.
We solve the above problem with several additional
techniques. First, we design a new eviction procedure
that improves eviction quality. At a high level, Ring
USENIX Association  
24th USENIX Security Symposium  417
3
ORAM performs evictions on a path in a similar fashion
as Path ORAM, but eviction paths are selected based on
a reverse lexicographical order [9], which evenly spreads
eviction paths over the entire tree. The improved eviction
quality allows us to perform evictions less frequently,
only once every A ORAM accesses, where A is a new
parameter. We then develop a proof that crucially shows
A can approach 2Z while still ensuring negligible ORAM