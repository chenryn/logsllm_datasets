title:Privacy and accountability for location-based aggregate statistics
author:Raluca A. Popa and
Andrew J. Blumberg and
Hari Balakrishnan and
Frank H. Li
Privacy and Accountability for Location-based Aggregate
Statistics
Raluca Ada Popa
PI:EMAIL
MIT
Andrew J. Blumberg
University of Texas, Austin
PI:EMAIL
Frank H. Li
MIT
PI:EMAIL
Hari Balakrishnan
MIT
PI:EMAIL
ABSTRACT
A signiﬁcant and growing class of location-based mobile applica-
tions aggregate position data from individual devices at a server and
compute aggregate statistics over these position streams. Because
these devices can be linked to the movement of individuals, there
is signiﬁcant danger that the aggregate computation will violate the
location privacy of individuals. This paper develops and evaluates
PrivStats, a system for computing aggregate statistics over location
data that simultaneously achieves two properties: ﬁrst, provable
guarantees on location privacy even in the face of any side informa-
tion about users known to the server, and second, privacy-preserving
accountability (i.e., protection against abusive clients uploading
large amounts of spurious data). PrivStats achieves these properties
using a new protocol for uploading and aggregating data anony-
mously as well as an efﬁcient zero-knowledge proof of knowledge
protocol we developed from scratch for accountability. We imple-
mented our system on Nexus One smartphones and commodity
servers. Our experimental results demonstrate that PrivStats is a
practical system: computing a common aggregate (e.g., count) over
the data of 10, 000 clients takes less than 0.46 s at the server and
the protocol has modest latency (0.6 s) to upload data from a Nexus
phone. We also validated our protocols on real driver traces from
the CarTel project.
Categories and subject descriptors: C.2.0 [Computer Communi-
cation Networks]: General–Security and protection
General terms: Security
1.
INTRODUCTION
The emergence of location-based mobile services and the interest
in using them in road transportation, participatory sensing [28, 21],
and various social mobile crowdsourcing applications has led to
a fertile area of research and commercial activity. At the core of
many of these applications are mobile nodes (smartphones, in-car
devices, etc.) equipped with GPS or other position sensors, which
(periodically) upload time and location coordinates to a server. This
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’11, October 17–21, 2011, Chicago, Illinois, USA.
Copyright 2011 ACM 978-1-4503-0948-6/11/10 ...$10.00.
information is then processed by the server to compute a variety of
aggregate statistics.
As primary motivation, consider applications that process streams
of GPS position and/or speed samples along vehicle trajectories,
sourced from smartphones, to determine current trafﬁc statistics such
as average speed, average delay on a road segment, or congestion at
an intersection. Several research projects (e.g., CarTel [21], Mobile
Millennium [27]) and commercial products (e.g., TomTom [34]) pro-
vide such services. Another motivation is social mobile crowdsourc-
ing, for example, estimating the number of people at a restaurant to
determine availability by aggregating data from position samples
provided by smartphones carried by participating users.
A signiﬁcant concern about existing implementations of these
services is the violation of user location privacy. Even though
the service only needs to compute an aggregate (such as a mean,
standard deviation, density of users, etc.), most implementations
simply continuously record time-location pairs of all the clients
and deliver them to the server, labeled by which client they belong
to [21, 27, 22]. In such a system, the server can piece together all
the locations and times belonging to a particular client and obtain
the client’s path, violating her location privacy.
Location privacy concerns are important to address because many
users perceive them to be signiﬁcant (and may refuse to use or even
oppose a service) and because they may threaten personal security.
Recently (as of the time of writing this paper), two users have sued
Google [26] over location data that Android phones collect citing
as one of the concerns “serious risk of privacy invasions, includ-
ing stalking." The lawsuit attempts to prevent Google from selling
phones with software that can track user location. Just a week before,
two users sued Apple [25] for violating privacy laws by keeping a
log of user locations without offering users a way to disable this
tracking or delete the log. Users of TomTom, a satellite navigation
system, have expressed concern over the fact that TomTom logs
user paths and sells aggregate statistics (such as speeding hotspots)
to the police, who in turn install speed cameras [34]. A study by
Riley [35] shows even wider location privacy fears: a signiﬁcant
number of drivers in the San Francisco Bay Area will not install toll
transponders in their cars because of privacy concerns. Moreover,
online databases are routinely broken into or abused by insiders
with access; if that happens, detailed records of user mobility may
become known to criminals, who can then attempt security attacks,
such as burglarizing homes when they know that their residents are
away [40].
In this paper, we design, implement, and evaluate PrivStats, a
practical system for computing aggregate statistics in the context of
mobile, location-based applications that achieves both strong guar-
653antees of location privacy and protection against cheating clients.
PrivStats solves two major problems: it provides formal location
privacy guarantees against any side information (SI) attacks, and it
provides client accountability without a trusted party. Because of
these contributions, in comparison to previous systems [16], Clique-
Cloak [14], [19], [24], [20], and Triplines [18], PrivStats provides
the strongest formal privacy and correctness guarantees while mak-
ing the weakest trust assumptions.
Side information refers to any out-of-bound information the server
may have, which, when used together with the data the server gets
in a system, can help the server compromise user location privacy.
Some previous work ensures that clients upload data free of identi-
ﬁers (they upload approximate time, location, and data sample), but
even when all data is anonymized, a considerable amount of private
location information can still leak due to side information. As a sim-
ple example, if the server knows that Alice is the only person living
on a street, it can infer that Alice just left or arrived at her house
when receiving some speed updates from that street. SI can come in
many forms and has been shown to leak as much as full client paths
in some cases: Krumm [24], as well as Gruteser and Hoh [17], show
that one can infer driver paths from anonymized data and then link
them to driver identities using side information such as knowledge
of map, typical driving behavior patterns, timing between uploads,
and a public web service with addresses and names. Despite SI’s
ability to leak considerable location privacy, previous systems for
mobile systems aggregates either do not address the problem at all,
or they only treat speciﬁc cases of it, such as areas of low density
(see §10).
- Although a malicious SM opens the doors to potential SI leakage
from the number of uploads and the values uploaded, a signiﬁcant
degree of privacy remains because client uploads are always
anonymized, free of timing and origin information. Our SM is
distributed on the clients, resulting in few compromised client
SMs in practice.
- Our design of the SM (§5) facilitates distribution and ensuring its
correctness: the SM has light load, ≈ 50 times less load than the
Our ﬁrst contribution is to provide an aggregate statistics proto-
col with strong location privacy guarantees, including protection
against any general side information attack. We formalize our
guarantees by providing a deﬁnition of location privacy, termed
strict location privacy or SLP (Def. 2), which speciﬁes that the
server learns nothing further about the location of clients in the face
of arbitrary side information other than the desired aggregate result;
then, in §5, we provide a protocol, also termed SLP, that provably
achieves our deﬁnition.
While we manage to hide most sources of privacy leakage in our
SLP protocol without any trust assumptions, hiding the number of
tuples generated by clients information-theoretically can be reduced,
under reasonable model assumptions, to a problem in distributed
algorithms that can be shown to be impossible to solve. The reason
is that it requires synchronization among a set of clients that do
not know of each other. Our solution is to use a lightweight and
restricted module, the smoothing module (SM), that helps clients
synchronize with respect to the number of tuples upload and per-
forms one decryption per aggregate. We distribute the SM on the
clients (each “client SM” is responsible for handling a few aggre-
gates) so as to ensure that at most a small fraction of SMs misbehave.
We provide our strong SLP guarantees for all aggregates with honest
SMs, while still ensuring a high level of protection for compromised
SMs:
- A compromised SM cannot change aggregate results undetectably
and cannot collude with clients to allow them to corrupt aggre-
gates.
server, performs two simple tasks summing up to only 62 lines
of code (excluding libraries) which can be easily scrutinized for
correctness, and only uses constant storage per aggregate.
- In contrast to our limited SM, trusted parties in previous work [18,
14, 20, 16] had the ability to fully compromise client paths and
modify aggregate results when corrupted; at the same time, their
use still did not provide general SI attack protection.
Since clients are anonymous, the problem of accountability be-
comes serious: malicious clients can signiﬁcantly affect the correct-
ness of the aggregate results. Hoh et al. [19] present a variety of
attacks clients may use to change the aggregate result. For exam-
ple, clients might try to divert trafﬁc away from a road to reduce
a particular driver’s travel time or to keep low trafﬁc in front of
one’s residence, or divert trafﬁc toward a particular road-way to
increase revenue at a particular store. A particular challenge is that
accountability and privacy goals are in tension: if each client upload
is anonymous, it seems that the client could upload as many times
as she wishes. Indeed, most previous systems [16, 14, 24, 20] do
not provide any protection for such client biasing attacks and the
few that provide such veriﬁcation ([18, 19]) place this task on heav-
ily loaded trusted parties that when compromised can release full
location paths with user identities and can corrupt aggregate results.
Our second contribution is a privacy-preserving accountability
protocol without any trusted parties (§6). We provide a crypto-
graphic protocol for ensuring that each client can upload at most a
ﬁxed quota of values for each aggregate. At the core of the protocol,
is an efﬁcient zero-knowledge proof of knowledge (ZKPoK) that
we designed from scratch for this protocol. The zero-knowledge
property is key in maintaining the anonymity of clients. Therefore,
no trusted party is needed; in particular, the SM is not involved in
this protocol.
Finally, our third contribution is an implementation of the overall
system on Nexus One smartphones and commodity servers (§9).
One of our main goals was to design a practical system, so we strived
to keep our cryptographic protocols practical, including designing
our ZKPoK from scratch. Computing a common aggregate (e.g.
count) over the data of 104 clients takes less than 0.46 s at the server,
the protocol has modest latency of about 0.6 s to upload data from a
Nexus phone, and the throughput is linearly scalable in the number
of processing cores. We believe these measurements indicate that
PrivStats is practical. We also validated that our protocols introduce
little or no error in statistics computation using real driver traces
from the CarTel project [21].
2. MODEL
In this section, we discuss the model for PrivStats. Our setup
captures a wide range of aggregate statistics problems for mobile
systems.
2.1 Setting
In our model, we have many clients, a server, and a smoothing
module (SM). Clients are mobile nodes equipped with smartphones:
drivers in a vehicular network or peers in a social crowdsourcing
application. The server is an entity interested in computing certain
aggregate statistics over data from clients. The SM is a third party
involved in the protocol that is distributed on clients.
We assume that clients communicate with the server and the SM
using an anonymization network (e.g., Tor), a proxy forwarder, or
other anonymizing protocol to ensure that privacy is not compro-
mised by the underlying networking protocol. In this paper, we
assume these systems succeed in hiding the origin of a packet from
an adversary; it is out of our scope to ensure this. We assume that
654these systems also hide network travel time; otherwise clients must
introduce an appropriate delay so that all communications have
roughly the same round trip times.
Clients can choose which aggregates they want to participate in;
they can opt-out if the result is deemed too revealing.
A sample is a client’s contribution to an aggregate, such as average
speed, delay on a road, or a bit indicating presence in a certain
restaurant. Clients can generate samples periodically, as is the case
in vehicular systems, or at certain location/times, as is the case for
social mobile crowdsourcing systems. A sample point is a pair
consisting of a location and a time interval where/when clients
should generate a sample. We say that a client passes through a
sample point if the client passes by the location and in the time
interval of a sample point.
An aggregate to be computed consists of a sample point and the
type of data clients should sample. The server may only be interested
in computing certain aggregates. We assume that clients know the
aggregates of interest (e.g., from a public database or a deterministic
algorithm), that is, at which sample points they should upload and
what kind of samples they should generate. We assume that each
aggregate has an identiﬁer id, with the mapping between identiﬁers
and aggregates publicly known (e.g., a hash). Therefore, clients
generate tuples of the form id, sample, meaning that their sample
for aggregate id is sample. We denote by aggregate result the result
of the aggregation of all client samples for an aggregate. Each
aggregate has an associated sample interval denoting an interval
of acceptable values for the sample. For example, suppose that
id = 2 corresponds to an aggregate with sample point road segment
S and time interval between T1 = 4.00 pm to T2 = 4.15 pm, and
type of sample “average speed” (the sample interval could be 0 mph
– 100 mph). A client passing through S, in the interval of time
[T1, T2] should take a sample of their average speed. The client
generates the tuple: 2, 24 mph. Finally, the aggregate result over
all clients could be 30 mph. (Note that the server may choose to
compute the function in “real time” or at some later point in time.)
To preserve privacy, clients in PrivStats will transform these tuples
(e.g., encrypt and add cryptographic tokens) and use a certain upload
strategy to upload the transformed tuples to the server. Note that
clients are not uploading their identity with the tuples, unlike in
some existing systems [21, 12].
2.2 Threat Model