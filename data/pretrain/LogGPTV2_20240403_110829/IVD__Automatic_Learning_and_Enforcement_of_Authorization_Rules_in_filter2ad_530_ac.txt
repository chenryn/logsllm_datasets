l
t
s
e
u
q
e
R
r
e
p
m
a
S
Legitimate
requests
t
n
a
i
r
a
v
n
r
e
k
c
e
h
C
x
Malicious
request I
DB
l
t
s
e
u
q
e
R
r
e
p
m
a
S
Invariant Inference
Engine
Legitimate
requests
DB
t
n
a
i
r
a
v
n
r
e
k
c
e
h
C
x
Malicious
request I
DB
l
t
s
e
u
q
e
R
r
e
p
m
a
S
(a) INVARIANT DETECTOR’s request sampler and invariant checker
intercept requests between a client and a database system.
(b) INVARIANT DETECTOR uses a central invariant inference en-
gine and distributed request samplers and invariant checkers.
Fig. 3: INVARIANT DETECTOR has three loosely coupled components: the request sampler logs a representative part of database
requests, which are used for ofﬂine learning by the invariant inference engine. The learning process produces a set of likely
invariants, which are passed to the invariant checker to be tested by evaluating them against all requests for a period of time.
All invariants that are never broken are then ratiﬁed and used to block requests that do not match them.
the group. Breaking authorization invariants can have serious
consequences, such as allowing an attacker to perform actions
on behalf of a different user. In addition, such attacks can be
difﬁcult to spot and recover from, since the database remains
consistent.
Conversely, data validation invariants are constraints that
apply to the entire database, regardless of user identity. In
other words, the database is consistent if and only if all data
validation invariants hold. For example, an advertiser cannot
remove their primary payment method if they have active
advertisement campaigns, or the length of a post must be under
1000 characters. While IVD can catch data consistency bugs,
as we will show in one case study (§V-C), consistency checks
often require other predicates and are not the focus of our
work.
In the rest of this section we discuss the three components
that make up IVD, shown in Figure 3: the request sampler
(§III-A), the invariant inference engine (§III-B) and the in-
variant checker (§III-C).
A. The Request Sampler
To achieve scalability, IVD does not attempt to infer invari-
ants in real time. Instead, we gather representative data and use
an ofﬂine learning process to mine for invariants. The request
sampler is responsible for the data gathering step. Its purpose
is to log a conﬁgurable number of requests from each invariant
category, along with the values of local and global properties
at the time of the database request.
To have access to all relevant data, the request sampler lives
at the boundary between a client and a database server, as
shown in Figure 3a. It intercepts database requests and has
access to both local properties through the database request
arguments and to global properties through a lightweight web
application API.
When multiple clients and database instances are involved,
the request sampler becomes a distributed system, sampler in-
stances being colocated with either the clients or the databases
to achieve good performance. For simplicity and robustness,
the individual samplers are stateless and completely indepen-
dent of each other. However, they still need to synchronize
to globally log the desired number of requests from each
invariant category. We solve this problem by globally assigning
a sampling rate to each invariant category, which the samplers
use as a probability to log. Due to the dynamic nature of
the workloads seen by IVD, we can not use a static sampling
rate. Instead an external component (not pictured in Figure 3)
periodically analyses all logs and increases the rate for invari-
ant categories that were under-sampled and decreases it for
categories that were over-sampled. The new sampling rates
are then distributed to every request sampler.
It is important to ﬁnd the right balance in the number of
requests to sample. A number too low leads to increased
false positives while a number too high will be expensive in
terms of storage and processing time of the logged data. We
empirically found that 2000 samples per invariant category,
resulting in an invariant inference engine workload of roughly
500 million total samples per learning cycle, matches well our
computational capacity (§V-D).
B. The Invariant Inference Engine
The invariant inference engine looks for patterns in the
data logged by the request sampler. It ﬁrst splits log entries
according to their invariant category. Each category is then
analyzed separately, allowing for a large degree of parallelism.
1099
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:23:44 UTC from IEEE Xplore.  Restrictions apply. 
To mitigate the false positives caused by sampling, we use
a two-stage invariant deployment process. All newly-created
invariants go through an evaluation period, in which they are
checked against all requests. However, any requests that violate
newly created invariants are not blocked, but rather cause the
invariants to be invalidated. If an invariant is not violated
during the evaluation period, it is ratiﬁed and any subsequent
requests violating it are classiﬁed as malicious and blocked
from reaching the database. The evaluation period mechanism
is implemented in the centralized invariant inference engine
rather than in the distributed invariant checkers,
to allow
for a simple and robust implementation of the latter. The
invariant checkers only need to log all violations along with
the invariant that caused them. The inference engine then picks
up the violation logs and decides which invariants should be
invalidated.
The inference engine executes periodically. At each run
it analyzes the logs created since the previous run to ﬁnd
invariants to be put into evaluation mode, and the logs for
the current evaluation period, i.e. the past ﬁve days in our
implementation, to ratify invariants that passed evaluation. Our
approach is stateless in that it does not look at the existing
invariants, but only at the request and violation logs. This
makes the algorithm easy to reason about and has the added
beneﬁt of making the inference process oblivious to transient
failures in previous runs.
The invariant inference engine uses observations as ground
truth, therefore it fundamentally needs to observe the OSN
during normal operation. In particular, invariants for new OSN
features can only be learned if authorization bugs in the new
features are not actively exploited during the learning period.
We consider this to be only a small limitation because new
features usually go through testing and internal dogfooding
where triggered bugs are expected to be reported. Regression
bugs, on the other hand, are caught by virtue of preexisting
invariants, and their detection does not depend on a period of
quiescence.
C. The Invariant Checker
The invariant checker lives at the boundary between a client
and the database system, similarly to the request sampler.
However, unlike the request sampler, the checker runs syn-
chronously on all database requests. For each database request,
it ﬁrst retrieves the endpoint that made the request and the
involved entity types to determine the invariant category for the
request. It then uses the category to get all relevant invariant
predicates. The predicates are evaluated and any violations
are logged. Furthermore, if a ratiﬁed invariant is violated, the
database request gets aborted and an application exception is
thrown.
Aborted requests cause notiﬁcations that trigger a manual
investigation. An engineer can either conﬁrm that the root
cause of the violation is a bug and proceed to ﬁx it, or deem the
violated invariant spurious or no longer relevant. For the latter
case, she will blacklist the invariant for the speciﬁc invariant
category where the violation was triggered.
Most blacklisted invariants fall under one of three classes:
coincidental correlations, modiﬁed product behavior, and
rarely used features. The ﬁrst
involve conditions that had
occurred almost always without being necessary for correct
product behavior. For example, a user would have almost
always seen a post before liking it (the has seen property is
usually encoded as an association from the user to the post,
which can be inferred into a association existence invariant),
but
this is not a requirement. The second class includes
invariants that were valid for a previous OSN version but are
not anymore, e.g. after switching from a policy where only
a business proﬁle’s administrator is allowed to ask users to
follow the business proﬁle to a policy where users who already
follow the business proﬁle can invite their friends to do the
same. Finally, some invariants are not correct but are learned
because the code paths that cause their violation were never
exercised during the learning period.
While spurious invariants are inevitable since our learning
process bases ground truth on a limited number of obser-
vations, we have several defenses against them. First, the
ratiﬁcation algorithm requires the invariant to hold for a set
minimum number of requests over at least ﬁve days before
it can be enforced. This does not, however, protect against
invariants that are no longer correct as a consequence of
changes in system behavior. These situations are mitigated
in two ways. First, invariants are also enforced on developer
machines. This allows developers to notice problems early
and remove the invariants. Second, code changes are canaried
before being sent to the entire ﬂeet of servers. The canaries
can detect an abnormal number of failures and block the
deployment until the situation is manually remediated. Finally,
invariants can be manually blacklisted, with changes taking
effect in a matter of seconds across the entire ﬂeet of servers,
as we will discuss in IV-C.
IV. IMPLEMENTATION
In this section we describe INVARIANT DETECTOR’s imple-
mentation, focusing on the challenges that we had to overcome
to handle the scale of Facebook’s workload. We separate
the discussion into two: we ﬁrst look at the request sampler
and invariant checker, which are implemented in the database
clients, and then discuss the invariant inference engine, which
is built on top of Facebook’s data analytics infrastructure.
A. Database Client Components
i.e.
IVD’s request sampler and invariant checker are imple-
mented in Facebook’s graph database clients,
its web
servers. The main reason for this placement is to avoid having
to pass client state, e.g. the logged-in user, to the databases.
This also allows us to distribute the load across many machines
at the expense of having to make the invariants accessible
on each of them. While Facebook offers several interfaces
through which users can interact with it—desktop and mobile
websites, APIs for external clients, mobile applications, and
internal tools— they all share the same database API, which
1100
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:23:44 UTC from IEEE Xplore.  Restrictions apply. 
input : Request sampler logs for the last day
output: invariant category → invariants map
1 foreach invariant category c in input do
2
3
4
5
6
7
8
9
10
11
// check that we have enough requests
rqs = size(c.requests);
if rqs < EvalThreshold then continue;
all eq pairs = [];
foreach request rq in c.requests do
foreach p in rq.equal properties do
all eq pairs.addAll(combinations(p, 2))
end
end
foreach property pair in all eq pairs do
if all eq pairs.count(property pair) == rqs then
output[c].add(property pair);
end
12
13 end
Algorithm 3: Pseudocode algorithm describing IVD’s
HiveQL invariant inference data pipeline for equality predi-
cates.
violation logs for the last month
input : Request sampler logs for the last 7 days,
output: invariant category → invariants map
1 foreach invariant category c in input do
2
3
4
5
checked = map();
foreach request rq in c.requests do
foreach iv in rq.checked invariants do
if iv not in violations[c] then
checked[iv].add(rq.date);
end
end
foreach iv in checked do
6
7
8
9
if MeetsRatiﬁcationThreshold(checked[iv]) then
output[c].add(iv);
end
10
11 end