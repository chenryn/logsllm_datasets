title:Minimal TCB Code Execution
author:Jonathan M. McCune and
Bryan Parno and
Adrian Perrig and
Michael K. Reiter and
Arvind Seshadri
Minimal TCB Code Execution (Extended Abstract)(cid:3)
Jonathan M. McCune, Bryan Parno, Adrian Perrig, Michael K. Reiter, and Arvind Seshadri
Carnegie Mellon University
Abstract
We propose an architecture that allows code to ex-
ecute in complete isolation from other software while
trusting only a tiny software base that is orders of mag-
nitude smaller than even minimalist virtual machine
monitors. Our technique also enables more meaningful
attestation than previous proposals, since only measure-
ments of the security-sensitive portions of an applica-
tion need to be included. We achieve these guarantees
by leveraging hardware support provided by commodity
processors from AMD and Intel that are shipping today.
1
Introduction
The large size and huge complexity of modern op-
erating systems makes them dif(cid:2)cult to analyze and
vulnerable to attack. The Linux kernel currently (as
of version 2.6) consists of nearly 5 million lines of
code [23], while Microsoft’s Windows Vista includes
over 50 million lines of code. Even Virtual Machine
Monitors (VMMs), often touted as smaller and more
secure than commodity operating systems, include sub-
stantial amounts of code that tend to grow over time. For
example, the initial implementation of the Xen VMM
required 42K lines of code [4] and within a few years al-
most doubled to approximately 83K lines [13]. Applica-
tion code depends on all of this code for its security, thus
swelling the size of its Trusted Computing Base (TCB)
far beyond the application code itself. As a result, even
security-conscious application developers can make few
guarantees about the security their applications provide.
As we discuss in more detail in Section 6, such a large
TCB also prevents current proposals for system-wide
code attestation [2, 14, 18] from providing meaningful
security information.
(cid:3)This research was supported in part by CyLab at Carnegie Mel-
lon under grant DAAD19-02-1-0389 from the Army Research Of(cid:2)ce,
and grants CT-0433540 and CCF-0424422 from the National Science
Foundation, by the iCAST project, National Science Council, Taiwan
under the Grants No. (NSC95-main) and No. (NSC95-org), and by a
gift from AMD. Bryan Parno is supported in part by an NDSEG Fel-
lowship, which is sponsored by the Department of Defense. The views
and conclusions contained here are those of the authors and should not
be interpreted as necessarily representing the of(cid:2)cial policies or en-
dorsements, either express or implied, of AMD, ARO, CMU, NSF, or
the U.S. Government or any of its agencies.
In this work, we describe a Secure Execution Archi-
tecture (SEA) that allows security-sensitive code to ex-
ecute in complete isolation from all other software (in-
cluding the operating system and VMM, if present) and
hardware devices. This dramatic reduction in the size of
the TCB for an application (see Figure 1) enables mean-
ingful software attestation and facilitates formal security
analysis of the software remaining in the TCB. Our SEA
provides these guarantees without requiring a reboot.
Our architecture leverages hardware support for se-
cure virtualization provided by AMD’s Secure Virtual
Machine (SVM) architecture [1] or Intel’s Trusted Exe-
cution Technology (TXT) [10]. These technologies pro-
vide a hardware-based dynamic root of trust, as well as
new forms of memory protection. They are designed
to atomically measure and launch a VMM or security
kernel (SK) without requiring a reboot [1, 9]. In con-
trast, we propose using this technology to securely exe-
cute sensitive application code in complete isolation and
then return to the user’s legacy operating system. By
doing so, we eliminate the OS from the application’s
TCB. Furthermore, our architecture can be deployed to-
day, and need not await the development of a perfectly
secure VMM. SVM- and TXT-equipped processors are
currently shipping in commodity servers and PCs.
Many security-sensitive applications can bene(cid:2)t from
our architecture. For example, when users log in to a
server using SSH, their passwords are transmitted to the
server over an encrypted and authenticated channel. At
the server, however, the passwords are decrypted and ex-
ist (cid:147)in the clear(cid:148) in the SSH server’s memory, where a
malicious root user, OS, kernel module, or device can
readily obtain them. By encrypting the user’s password
so that only code executed with our SEA can decrypt
it, the user can safely transmit a password to the server
without worrying about the security of the server’s op-
erating system or any other software the server might be
executing. The server can use attestation to convince the
client system (and hence, the user) that these additional
protections are in place without revealing any additional
information about the con(cid:2)guration of the server itself.
Likewise, a server could use SEA to improve the se-
curity of its SSL keys. Our architecture can also help
secure e-commerce applications, e-voting, online auc-
tions, or medical databases, for example. It is particu-
larly well-suited to handling sensitive data such as cryp-
tographic keys.
1
App
1
...
App
n
C
App
1
App
n
...
Legacy
OS
Legacy
OS
SLB
system (cid:2)rst boots. This allows a remote veri(cid:2)er to dis-
tinguish between code run using SKINIT and code run
immediately after a reboot, which is necessary since any
code that can access the TPM can extend PCRs. Thus,
a system using a v1.2 TPM can attest to the fact that the
SKINIT instruction was executed with a particular SLB.
C
2.3 Attestation
CPU / Hardware TPM
CPU / Hardware
TPM
Figure 1. The (cid:2)gure on the left illustrates a tradi-
tional architecture, with an application that executes
a segment of sensitive code (C). The (cid:2)gure on the
right demonstrates the use of our architecture to exe-
cute the sensitive code. The shaded portions represent
the components that must be trusted in each scenario.
The secure loader block (SLB) consists of the security-
sensitive code plus a tiny amount of shim code.
Systems equipped with a TPM can generate attesta-
tions, which are digitally signed aggregates of a TPM’s
PCR values. The TPM uses a private Attestation Identity
Key (AIK) to produce signatures, which remote parties
can verify using the corresponding public AIK.
3 Problem De(cid:2)nition
In this section, we summarize the goals for our archi-
tecture and describe the adversaries we seek to thwart.
2 Background
3.1 Goals
Our architecture requires hardware security features
which have recently come to market. We provide a brief
introduction to the relevant hardware features.
2.1 Late Launch
Processors with AMD’s SVM or Intel’s TXT include
the ability to use a late launch command to create a
dynamic root of trust. In this work, we will focus on
AMD’s SVM technology, but Intel’s TXT-enabled pro-
cessors behave similarly. SVM includes a processor
instruction, SKINIT, that takes a secure loader block
(SLB) de(cid:2)ned by a physical start address and a length
up to 64KB as an argument. The SKINIT instruction
enables various hardware-level protections for the SLB,
transmits a copy of the SLB to the system’s TPM so that
it can be measured (hashed) into PCR 17, and then be-
gins to execute the SLB [1]. The hardware protections
disable interrupts, prevent DMA access to the SLB, and
even prohibit access by hardware debuggers attached to
the motherboard.
2.2 Resettable PCRs and TPM v1.2
The speci(cid:2)cation for version 1.2 TPMs [21] includes
several new features. The most important feature for
our work is the inclusion of dynamically resettable plat-
form con(cid:2)guration registers (PCRs). On v1.1b TPMs,
the value in a PCR can be reset only by rebooting the
computer. With v1.2 TPMs, certain registers (currently
PCRs 17(cid:150)22) can be reset under carefully controlled cir-
cumstances. For example, the SKINIT instruction will
reset the value of PCR 17 to zero before extending it
with the measurement of the SLB. Note that PCR 17 as-
sumes a default value of twenty bytes of 0xff when a
Below, we enumerate the goals for our architecture:
(cid:149) Isolation. Isolate security-sensitive code execution
from all other code and devices on the system, in-
cluding the operating system.
(cid:149) Provable Protection. Convince a remote party that
the security-sensitive code executed with the proper
protections.
(cid:149) Meaningful Attestation. Provide meaningful at-
testations that include measurements of exactly the
security-sensitive code and its inputs and outputs,
and nothing else. This provides the dual advan-
tages of giving the veri(cid:2)er a tractable veri(cid:2)ca-
tion task (in the sense of actually deriving mean-
ing from the measurements, as opposed to learning
only that millions of lines of code were executed),
and leaking as little information as possible about
the remaining software state on the attesting system
(since it is not security-relevant).
(cid:149) Minimal Mandatory TCB. Minimize the amount
of software that must be trusted. While a partic-
ular application may need additional functionality
added to its TCB, e.g., to display an image on the
screen, the amount of code that every application
must include in its TCB should be minimized.
The original design for AMD and Intel’s new tech-
nology called for the initiation of a (cid:147)secure(cid:148) VMM fol-
lowing the SKINIT instruction [9]. While this approach
achieves our (cid:2)rst two goals, it only partially achieves the
goal of Meaningful Attestation, and it fails to provide a
Minimal Mandatory TCB. All applications must com-
pletely trust the VMM which increases the size of the
TCB and reduces the usefulness of software attestation.
2
3.2 Adversary Model
In designing our architecture, we allow the adversary
the ability to run arbitrary code on the targeted com-
puter. The adversary can control the operating system,
devices that use DMA (direct memory access), and in-
voke SKINIT on SLBs of its choosing. Like the Trusted
Computing Group’s speci(cid:2)cation for the TPM [21], we
allow the adversary to launch simple hardware attacks,
such as power cycling the machine at arbitrary times,
but we assume she cannot use highly sophisticated at-
tacks, e.g., monitoring and modifying communications
on the high-speed bus between the CPU and main mem-
ory. Note that the comparatively low-speed bus between
the CPU and the TPM employs a special protocol de-
signed to thwart snooping [21].
4 Secure Execution Architecture
Below, we describe the design for our architecture.
Due to space constraints, we limit the discussion to a
high-level overview. We also describe various exten-
sions that can enhance the basic functionality.
4.1 High-level Design
Using AMD SVM and a v1.2 TPM, we show how to
execute a small piece of code, which we call a Piece
of Application Logic (PAL). The PAL is executed
with much stronger isolation guarantees than modern
operating systems can provide, while minimizing the
amount of additional code that must be trusted. The
PAL is protected from all software running on the sys-
tem, from all of the peripherals installed on the PC, and
even from hardware debuggers attached directly to the
motherboard. At present, the application programmer
must provide all of the code that will compose the PAL,
though, as we discuss in Section 6, a variety of tech-
niques exist to automate this process. The operating sys-
tem must carefully consider which PALs it wishes to ex-
ecute (for example, by performing its own measurement
before invoking SKINIT), since by default a PAL has
considerable power. We discuss techniques for limiting
this power in Section 6.
In our system, instead of using the SKINIT instruc-
tion to launch a new VMM or SK and wipe out all previ-
ous execution state (cf., Sec. 15.26.6 of [1]), we preserve
the current execution environment, invoke the SKINIT
instruction with the PAL as a parameter, and then re-
sume the legacy OS once the PAL terminates. Below,
we describe this process in more detail.
Invoking the PAL.
In order to execute a PAL with
our enhanced protection guarantees, code operating at
ring 0 (e.g., a kernel module) must (cid:2)rst save the state
of the current execution environment to a well-known
location. This includes the base address of the page ta-
bles, global and local descriptor tables (if present), in-
terrupt descriptor tables, the task register contents, ex-
tended features register (EFER) contents, and certain
bits in the EFLAGS register. On a multi-CPU system,
SKINIT must be executed by the bootstrap processor
(BSP). First, however, the OS must deschedule all ap-
plication processors (APs) and send each one an INIT
inter-processor-interrupt (IPI) so that they enter a halted
state [1]. The binary for the PAL is then passed as a
parameter to the invocation of the SKINIT instruction.
Note that although the OS invokes the PAL, the OS need
not be trusted for the PAL to execute securely. Once the
PAL starts to execute, the OS cannot tamper with the ex-
ecution environment or monitor it in any way. The CPU
and TPM guarantee that a legitimate PAL’s secrets can-
not be read by a modi(cid:2)ed PAL.
The Secure Execution Environment.
The invoca-
tion of the SKINIT instruction automatically resets the
TPM’s PCRs 17(cid:150)22 and extends PCR 17 with the hash
of the PAL. A tiny shim layer of system code (con-
sisting of a few hundred lines of code) extends PCR 18
with the input parameters to the PAL and jumps to the
beginning of the PAL. Note that the PAL and the shim
combine to form the SLB, and thus both are included
in the measurement performed by the SKINIT instruc-
tion. While the PAL executes, it enjoys all of the pro-
tections described in Section 2.1: protection from DMA,
protection from software executing on other processors,
and even protection from hardware debuggers. When
the PAL terminates, it jumps back to the tiny code shim
to begin resuming the OS.
Resuming the OS. After the execution of the PAL
completes, the tiny shim of code erases all traces of the
PAL’s execution. It overwrites any memory used, clears
values stored in the registers and (cid:3)ushes the processor’s
caches. The shim also extends PCR 18 with the out-
put values from the PAL, and then extends both PCR
17 and 18 with a known public value to signal the ter-
mination of the PAL in subsequent attestations. This
prevents untrusted code from claiming that any values it
extends into PCRs 17 or 18 were actually generated by
the PAL. The shim then restores the state of the origi-
nal OS from the standard location at which it was stored
before the invocation of SKINIT. Finally, it resumes ex-
ecution of the original OS. On a multi-CPU system, the
OS sends each application processor (AP) a Startup IPI
and reschedules it.
4.2 Extensions
While we have described the basic processes for
achieving strong isolation, we also suggest a number of
extensions to this basic functionality.
3
Attestation.
In many scenarios, the computer (or
attestor) performing the security-sensitive operations
would like to convince a remote veri(cid:2)er that the opera-
tion was performed using our SEA. For example, in our
SSH-password example, the server would like to con-
vince the client that her password will be handled by a
speci(cid:2)c piece of trusted code executing with the protec-
tions offered by our architecture.