old questions about certiﬁcate authorities. Ars Technica,
Aug. 2011.
[11] P. Bright. Independent Iranian hacker claims responsibility
for Comodo hack. Ars Technica, Mar. 2011.
[12] J. Callas, L. Donnerhacke, H. Finney, and R. Thayer. RFC
2440 OpenPGP Message Format, Nov. 1998.
[13] D. Chaum. Untraceable electronic mail, return addresses,
and digital pseudonyms. Communications of the ACM,
24(2), Feb. 1981.
[14] D. Chaum and T. P. Pedersen. Wallet databases with ob-
servers. CRYPTO, 1993.
[15] D. Eastlake. RFC 2535: Domain Name System Security
Extensions. 1999.
[16] C. Evans, C. Palmer, and R. Sleevi. Internet-Draft: Public
Key Pinning Extension for HTTP. 2012.
[17] P. Everton. Google’s Gmail Hacked This Weekend? Tips
To Beef Up Your Security. Hufﬁngton Post, Jul. 2013.
[18] E. Felten. A Court Order is an Insider Attack, Oct. 2013.
[19] T. Fox-Brewster. WhatsApp adds end-to-end encryption
using TextSecure. The Guardian, Nov. 2014.
[20] M. Franklin and H. Zhang. Unique ring signatures: A
practical construction. Financial Cryptography, 2013.
[21] P. Gallagher and C. Kerry. FIPS Pub 186-4: Digital signa-
ture standard, DSS. NIST, 2013.
[22] S. Gaw, E. W. Felten, and P. Fernandez-Kelly. Secrecy,
ﬂagging, and paranoia: Adoption criteria in encrypted
email. CHI, 2006.
[23] B. Gellman. The FBI’s Secret Scrutiny. The Wasington
Post, Nov. 2005.
[24] B. Gellman and L. Poitras. U.S., British intelligence min-
ing data from nine U.S. Internet companies in broad secret
program. The Washington Post, Jun. 2013.
[25] S. Gibbs. Gmail does scan all emails, new Google terms
clarify. The Guardian, Apr. 2014.
[26] I. Goldberg, K. Hanna, and N. Borisov.
pidgin-
otr. http://sourceforge.net/p/otr/pidgin-otr/
ci/master/tree/, Retr. Apr. 2014.
[27] S. Goldberg, M. Naor, D. Papadopoulos, L. Reyzin, S. Vas-
ant, and A. Ziv. NSEC5: Provably Preventing DNSSEC
Zone Enumeration. NDSS, 2015.
[28] V. Goyal. Reducing trust in the pkg in identity based
cryptosystems. CRYPTO, 2007.
[29] V. Goyal, S. Lu, A. Sahai, and B. Waters. Black-box
accountable authority identity-based encryption. ACM
CCS, 2008.
[30] T. Icart. How to hash into elliptic curves. CRYPTO, 2009.
[31] J. Jonsson and B. Kaliski. RFC 3447 Public-Key Cryptog-
raphy Standards (PKCS) #1: RSA Cryptography Speciﬁ-
cations Version 2.1, Feb. 2003.
[32] R. Kainda, I. Flechais, and A. W. Roscoe. Usability and Se-
curity of Out-of-band Channels in Secure Device Pairing
Protocols. SOUPS, 2009.
[33] J. Katz. Analysis of a proposed hash-based signa-
https://www.cs.umd.edu/~jkatz/
ture standard.
papers/HashBasedSigs.pdf, 2014.
[34] T. H.-J. Kim, L.-S. Huang, A. Perrig, C. Jackson, and
V. Gligor. Accountable key infrastructure (AKI): a pro-
posal for a public-key validation infrastructure. WWW,
2013.
[35] M. Kranch and J. Bonneau. Upgrading HTTPS in midair:
HSTS and key pinning in practice. NDSS, 2015.
[36] D. W. Kravitz. Digital signature algorithm, 1993. US
Patent 5,231,668.
[37] M. Krohn and C. Coyne. Keybase. https://keybase.
io, Retr. Feb. 2014.
[38] B. Laurie and E. Kasper.
parency.
RevocationTransparency.pdf, Retr. Feb. 2014.
Revocation Trans-
http://sump2.links.org/files/
[39] B. Laurie, A. Langley, E. Kasper, and G. Inc. RFC 6962
Certiﬁcate Transparency, Jun. 2013.
396  24th USENIX Security Symposium 
14
USENIX Association
[40] B. Laurie, G. Sisson, R. Arends, and D. Black. RFC 5155:
DNS Security (DNSSEC) Hashed Authenticated Denial
of Existence. 2008.
[41] J. Li, M. Krohn, D. Mazières, and D. Shasha. Secure
untrusted data repository (SUNDR). OSDI, 2004.
[42] G. Lindberg. RFC 2505 Anti-Spam Recommendations for
SMTP MTAs, Feb. 1999.
[43] M. Madden. Public Perceptions of Privacy and Security
in the Post-Snowden Era. Pew Research Internet Project,
Nov. 2014.
[44] M. Marlinspike and T. Perrin. Internet-Draft: Trust Asser-
tions for Certiﬁcate Keys. 2012.
[45] J. Mayer. Surveillance law. Available at https://class.
coursera.org/surveillance-001.
[46] M. S. Melara. CONIKS: Preserving Secure Communica-
tion with Untrusted Identity Providers. Master’s thesis,
Princeton University, Jun 2014.
[47] S. Micali, M. Rabin, and S. Vadhan. Veriﬁable random
functions. FOCS, 1999.
[48] N. Perloth. Yahoo Breach Extends Beyond Yahoo to
Gmail, Hotmail, AOL Users. New York Times Bits Blog,
Jul. 2012.
[49] T. Pornin. RFC 6979: Deterministic usage of the digi-
tal signature algorithm (DSA) and elliptic curve digital
signature algorithm (ECDSA). 2013.
[50] Electronic Frontier Foundation. Secure Messaging Score-
https://www.eff.org/secure-messaging-
card.
scorecard, Retr. 2014.
[51] Electronic Frontier Foundation. National Security Letters
- EFF Surveillance Self-Defense Project. https://ssd.
eff.org/foreign/nsl, Retr. Aug. 2013.
[52] Electronic Frontier Foundation.
National Security
https://www.eff.org/issues/national-
Letters.
security-letters, Retr. Nov. 2013.
[53] Electronic Frontier Foundation. Sovereign Keys. https:
//www.eff.org/sovereign-keys, Retr. Nov. 2013.
[54] Electronic Frontier Foundation. SSL Observatory. https:
//www.eff.org/observatory, Retr. Nov. 2013.
[55] Internet Mail Consortium.
S/MIME and OpenPGP.
http://www.imc.org/smime-pgpmime.html, Retr.
Aug. 2013.
[56] LEAP Encryption Access Project. Nicknym. https://
leap.se/en/docs/design/nicknym, Retr. Feb. 2015.
[57] Reuters. At Sina Weibo’s Censorship Hub, ’Little Brothers’
Cleanse Online Chatter, Nov. 2013.
[58] Thoughtcrime Labs Production. Convergence. http:
//convergence.io, Retr. Aug. 2013.
[59] R. L. Rivest, A. Shamir, and L. Adleman. A method for
obtaining digital signatures and public-key cryptosystems.
Communications of the ACM, 21(2):120–126, 1978.
[60] M. D. Ryan. Enhanced certiﬁcate transparency and end-
to-end encrypted email. NDSS, Feb. 2014.
[61] A. Sahai and H. Seyalioglu. Fully secure accountable-
authority identity-based encryption.
In Public Key
Cryptography–PKC 2011, pages 296–316. Springer, 2011.
[62] B. Schneier. Apple’s iMessage Encryption Seems to
Be Pretty Good. https://www.schneier.com/blog/
archives/2013/04/apples_imessage.html,
Retr.
Feb. 2015.
[63] C.-P. Schnorr. Efﬁcient signature generation by smart
cards. Journal of Cryptology, 4(3), 1991.
[64] C. Soghoian and S. Stamm. Certiﬁed Lies: Detecting and
Defeating Government Interception Attacks against SSL.
Financial Crypto’, 2012.
[65] R. Stedman, K. Yoshida, and I. Goldberg. A User Study
of Off-the-Record Messaging. SOUPS, Jul. 2008.
[66] N. Unger, S. Dechand, J. Bonneau, S. Fahl, H. Perl, I. Gold-
berg, and M. Smith. SoK: Secure Messaging. IEEE Sym-
posium on Security and Privacy, 2015.
[67] B. Warner. Pairing Problems, 2014.
[68] D. Wendlandt, D. G. Andersen, and A. Perrig. Perspec-
tives: improving SSH-style host authentication with multi-
path probing. In Usenix ATC, Jun. 2008.
[69] A. Whitten and J. D. Tygar. Why Johnny can’t encrypt: a
usability evaluation of PGP 5.0. USENIX Security, 1999.
[70] P. R. Zimmermann. The ofﬁcial PGP user’s guide. MIT
Press, Cambridge, MA, USA, 1995.
A Discrete-log Based VRF Construction
We propose a simple discrete-log based VRF in the random
oracle model. By deﬁnition, this scheme is also a VUF as
required. This construction was described by Franklin and
Zhang [20] although they considered it already well-known.
Following Micali et al.’s outline [47], the basic idea is to publish
a commitment c to the seed k of a pseudo-random function,
compute y = fk(x) as the VUF, and issue non-interactive zero-
knowledge proofs that y = fk(x) for some k to which c is a
commitment of. The public key and private key are c and k.
Parameters. For a group12 G with generator g of prime
order q, the prover chooses a random k R
← (1,q) as their private
key and publishes G = gk as their public key. We require two
hash functions: one which maps to curve points [6, 30] H1 :
∗ →G and one which maps to integers H2 : ∗ →(1, q) which
are modeled as random oracles.
VRF computation. The VRF is deﬁned as:
VRFk(m) =H 1(m)k
Non-interactive proof The prover must show in zero-
knowledge that there is some x for which G = gk and H = hk
for h = H1(m). The proof is a standard Sigma proof of equal-
ity for two discrete logarithms made non-interactive using the
Fiat-Shamir heuristic [14]. The prover chooses r R
← (1,q) and
transmits s = H1(m,gr,hr) and t = r− sk mod q.
To verify that VRFk(m) = H1(m)k is a correct VRF compu-
tation given a proof (s,t), the veriﬁer checks that
s = H1(cid:31)m,gt · Gs,H(m)t · VRFk(m)s(cid:30)
We refer the reader to [14, 20] for proof that this scheme sat-
isﬁes the properties of a VRF. Note that the pseudorandomness
12Note that we use multiplicative group notation here, though this
scheme applies equally to elliptic-curve groups.
USENIX Association  
15
24th USENIX Security Symposium  397
reduces to the Decisional Difﬁe-Hellman assumption. The tuple
(H1(m),G = gk,VRFk(m) =H 1(m)k) is a DDH triple, there-
fore an attacker that could distinguish VRFk(m) from random
could break the DDH assumption for G .
Efﬁciency. Proofs consist of a group elements (the VRF
result H1(m)k) and two integer which is the size of the order of
the group ((s,t)). For 256-bit elliptic curve, this leads to proofs
of size 768 bits (96 bytes).
B Analysis of Equivocation Detection
CONIKS participants check for non-equivocation by consulting
auditors to ensure that they both see an identical STR for a given
provider P. Clients perform this cross-veriﬁcation by choosing
uniformly at random a small set of auditors from the set of
known auditors, querying them for the observed STRs from
P, and comparing these observed STRs to the signed tree root
presented directly to the client by P. If any of the observed
STRs differ from the STR presented to the client, the client is
sure to have detected an equivocation attack.
B.1 Single Equivocating Provider
Suppose that foo.com wants to allow impersonation of a user
Alice to hijack all encrypted messages that a user Bob sends
her. To mount this attack, foo.com equivocates by showing
Alice STR A, which is consistent with Alice’s valid name-to-
key binding, and showing Bob STR B, which is consistent with
a fraudulent binding for Alice.
If Bob is the only participant in the system to whom foo.com
presents STR B, while all other users and auditors receive STR
A, Alice will not detect the equivocation (unless she compares
her STR directly with Bob’s). Bob, on the other hand, will
detect the equivocation immediately because performing the
non-equivocation check with a single randomly chosen auditor
is sufﬁcient for him to discover a diverging STR for foo.com.
A more effective approach for foo.com is to choose a subset
of auditors who will be presented STR A, and to present the
remaining auditors with STR B. Suppose the ﬁrst subset contains
a fraction f of all auditors, and the second subset contains
the fraction 1− f . If Alice and Bob each contact k randomly
chosen providers to check consistency of foo.com’s STR, the
probability that Alice fails to discover an inconsistency is f k,
and the probability that Bob fails to discover an inconsistency is
(1− f )k. The probability that both will fail is ( f − f 2)k, which is
maximized with f = 1
2 . Alice and Bob therefore fail to discover
equivocation with probability
4(cid:30)k
ε ≤(cid:31) 1
In order to discover the equivocation with probability 1 − ε,
Alice and Bob must perform − 1
2 checks. After perform-
ing 5 checks each, Alice and Bob would have discovered an
equivocation with 99.9% probability.
2 log ε
Figure 8: This graph shows the probability that Alice
and Bob will detect an equivocation after each per-
forming k checks with randomly chosen auditors.
B.2 Colluding Auditors
Now suppose that foo.com colludes with auditors in an attempt
to better hide its equivocation about Alice’s binding. The col-
luding auditors agree to tell Alice that foo.com is distributing
STR A while telling Bob that foo.com is distributing STR B. As
the size of the collusion increases, Alice and Bob become less
likely to detect the equivocation. However, as the number of
auditors in the system (and therefore, the number of auditors
not participating in the collusion) increases, the difﬁculty of
detecting the attack decreases.
More precisely, we assume that foo.com is colluding with a
proportion p of all auditors. The colluding auditors behave as
described above, and foo.com presents STR A to a fraction f
of the non-colluding providers. Alice and Bob each contacts k
randomly chosen providers. The probability of Alice failing to
detect equivocation within k checks is therefore (p + (1− p) f )k
and the probability of Bob failing to detect equivocation within
k checks is (p + (1− p)(1− f ))k. The probability that neither
Alice nor Bob detects equivocation is then
ε = ((p + (1− p) f )(p + (1− p)(1− f )))k
As before, this is maximized when f = 1
Alice and Bob fail to detect the equivocation is
2 , so the probability that
2 (cid:30)2k
ε ≤(cid:31) 1 + p
If p = 0.1, then by doing 5 checks each, Alice and Bob will
discover equivocation with 99.7% probability.
Figure 8 plots the probability of discovery as p and k vary. If
fewer than 50% of auditors are colluding, Alice and Bob will
detect an equivocation within 5 checks with over 94% probabil-
ity. In practice, large-scale collusion is unexpected, as today’s
secure messaging services have many providers operating with
different business models and under many different legal and
regulatory regimes. In any case, if Alice and Bob can agree on a
single auditor whom they both trust to be honest, then they can
detect equivocation with certainty if they both check with that
trusted auditor.
398  24th USENIX Security Symposium 
16
USENIX Association