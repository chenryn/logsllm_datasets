title:Quantifying Interference between Measurements on the RIPE Atlas
Platform
author:Thomas Holterbach and
Cristel Pelsser and
Randy Bush and
Laurent Vanbever
Quantifying Interference between Measurements
on the RIPE Atlas Platform
Thomas Holterbach
Cristel Pelsser
Randy Bush
ETH Zürich
Internet Initiative Japan
Internet Initiative Japan
Laurent Vanbever
ETH Zürich
PI:EMAIL
PI:EMAIL
PI:EMAIL
PI:EMAIL
ABSTRACT
Public measurement platforms composed of low-end hard-
ware devices such as RIPE Atlas have gained signiﬁcant
traction in the research community. Such platforms are in-
deed particularly interesting as they provide Internet-wide
measurement capabilities together with an ever growing set
of measurement tools. To be scalable though, they allow for
concurrent measurements between users. This paper answers
a fundamental question for any platform user: Do measure-
ments launched by others impact my results? If so, what can
I do about it?
We measured the impact of multiple users running exper-
iments in parallel on the RIPE Atlas platform. We found
that overlapping measurements do interfere with each other
in at least two ways. First, we show that measurements per-
formed from and towards the platform can signiﬁcantly in-
crease timings reported by the probe. We found that increas-
ing hardware CPU greatly helped in limiting interference on
the measured timings. Second, we show that measurement
campaigns can end up completely out-of-synch (by up to one
hour), due to concurrent loads. In contrast to precision, we
found that better hardware does not help.
1.
INTRODUCTION
Public measurement platforms composed of many low-end
devices or probes, such as RIPE Atlas [1], are increasingly
used by researchers and network operators. In addition to
measure network performance [2, 3, 4], these platforms are
now used to map the Internet [5], detect routing attacks [6],
routing anomalies [7] and censorship [8, 6].
To scale and be practical, measurement platforms sched-
ule measurements in parallel, without providing feedback
to the user. When put together with the limited hardware
and software capabilities, this raises the question of mea-
surement interferences. What is the impact of an increased
load on the precision of measurements performed? Do the
measurements performed by one participant impact the re-
sults obtained by others? If so, by how much? Can this have
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a
fee. Request permissions from Permissions@acm.org.
IMC’15, October 28–30, 2015, Tokyo, Japan.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3848-6/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2815675.2815710.
an impact on previous research results? This paper answers
these questions empirically for the RIPE Atlas platform.
By measuring the interference between our own measure-
ments (§3), we show that measurements do indeed interfere
with each other, sometimes signiﬁcantly. More particularly,
we found that user-induced interferences can impact two as-
pects of measurements: precision and synchrony.
First, the precision of delay measurements (e.g., using
ping) performed either from or towards probes can be sig-
niﬁcantly impacted when other measurements are launched
from or toward them (§4).
Second, user-induced interferences can heavily desynchro-
nize experiments performed on multiple probes, even when
launched at the same time (§5).
Our key ﬁndings are as follows:
• The precision of measurements performed from and to-
wards the probe are impacted when other measurements
use the probe at the same time. On older hardware, de-
lays increase by more than 1 ms in the median case and
by more than 7 ms for the 95th percentile (Table 2).
• Measurements are very quickly desynchronized when other
measurements are run in parallel. Under heavy load, com-
pletion time may be delayed by close to 1 hour (Figure 8).
• Upgrading the probe hardware signiﬁcantly improves pre-
cision levels, but does not help ensuring good synchro-
nization levels (§5).
• Previous research results, as well as the RIPE Atlas his-
toric dataset, may have been aﬀected by interfering mea-
surements. We also highlight two techniques to mitigate
interferences in the future (§6).
Overall, our results show that measurement interferences
should be systematically taken into account when analyzing
results from public platforms. To ensure reproducibility, all
our measurement and analysis tools are available online [9].
2. THE RIPE ATLAS PLATFORM
We now describe how Atlas works and highlight its in-
creasing popularity among the academic community.
As of April 2015, RIPE Atlas is composed of over
6,700 public probes scattered in 197 countries. Three
versions of the probes exist, diﬀering only by their hardware.
Version 1 and version 2 are identical except for the amount
of RAM they have. Both are Lantronix XPort Pro with a
167MHz CPU, 8MB or 16MB of RAM, respectively and a
16MB ﬂash. The version 3 probe is a revamped TP-Link TL-
437v1
v2
v3
Total
In progress
3.1M 7M
58K
19.7M
120K 414K
Total
29.8M
592K
Table 1: Overall, RIPE Atlas has hosted 29.8 million in-
dividual measurements. When we collected those results,
592,000 concurrent individual measurements were running
on the platform.
ments2 (Table 1). V3 probes hosted 2/3 of the measure-
ments, while v1 and v2 probes hosted the rest. In March
2015, the user who used the most credits spent 83.3 million
credits [14]. This is enough to perform more than 2,700,000
traceroutes. During the same month, the most used Atlas
probe (a v1) provided 608,824 results [14], one every 4 sec-
onds. Finally, the number of concurrent measurements is
important. As an illustration, the platform was executing
592,000 concurrent individual measurements when we col-
lected the statistics of Table 1.
An increasing number of research papers use RIPE Atlas.
As an illustration, Machado et al. [15] used it to perform
more than 3,000 traceroutes between a set of Atlas probes
and a destination in Switzerland to see whether traﬃc stayed
in the Schengen space. Fanou et al. [16] performed 1,108,709
traceroutes from 214 probes located in Africa to measure the
impact of IXPs on interdomain routing in this region. Fi-
adino et al. [17] perfomed DNS requests for *.whatsapp.net
from 600 Atlas probes to identify IP addresses hosting this
service. Cicalese et al. [18] performed ping measurements
from over 6000 probes located in 350 ASes in order to enu-
merate and geolocate IP-level anycast replicas.
Atlas probes are becoming popular destinations. De-
spite being designed for sourcing measurements, Atlas probes
are increasingly used as targets by researchers [19, 20, 21,
16]. For example, Aben et al. [19] launched 7140 one-oﬀ
traceroutes between a set of Atlas probes located in Sweden
to infer topological properties. As the IP addresses of the
Atlas probes are publicly available, users can target them
from any possible sources (not necessarily from an Atlas
probe). This enables users to perform hybrid measurement
campaigns, with powerful machines as sources, and Atlas
probes as destinations. Doing so, one can bypass the RIPE
Atlas limitations (e.g., frequency, credits cost) while keep-
ing some of its interesting characteristics such as the large
number of probes.
Some Atlas probes are more used than others. Due
to their geographical position, IPv6 capability or a NAT
gateway, some probes are more attractive than others. For
instance, the distribution of probes per-country is highly
skewed [22, 23]. While there are more than 1,200 Atlas probes
in Germany, there are 29 countries with only one Atlas
probe. The recent project sbucket [24] (supported by RIPE)
aims at selecting probes based on spatial distribution rather
than uniformly. Doing so would then to increase the load on
isolated probes.
Figure 1: RIPE Atlas is composed of more than 6000 low-
end probes which diﬀer by their hardware: v1 and v2 probes
are not powerful with respect to v3.
MR3020 router with a 400MHz CPU, 32MB of RAM and a
4MB NAND. The v3 probes are therefore more powerful.
Figure 1 depicts the evolution of the number of public
probes per version since the platform inception. The num-
ber of v3 probes increased rapidly after they started to be
distributed in 2013. While the number and proportion of
v1 and v2 probes is decreasing, they remain non-negligible,
accounting for 28.2% of the probes in April 2015.
RIPE Atlas uses credits to regulate the platform
usage and schedules users’ measurements concur-
rently. As of 2015, RIPE Atlas oﬀers four1 types of mea-
sures to its users: ping, traceroute, DNS and SSL [10]. In
RIPE Atlas, a measurement is deﬁned by a type, a fre-
quency and set of probes. It can therefore refer to an ar-
bitrary number of individual measurements performed from
multiple probes. Users can also provide a start date and an
end date. If none is provided, the measurement will start as
soon as possible and has to be stopped manually. Measure-
ments can be repeated or run only once (one-oﬀ ). One-oﬀ
measurements are near real-time if no start time is deﬁned:
users should expect results within 10 seconds [10].
RIPE Atlas regulates users load via a credit system. Users
earn credits by hosting a probe and use them to perform
measurements. RIPE’s cost model is based on the resources
each measurement needs. traceroute is the most expen-
sive measurement, while ping is the cheapest. One-oﬀ mea-
surements are also more expensive (twice more) than their
scheduled counterparts as their arrival is not predictable.
RIPE Atlas uses basic scheduling strategies on each
probe to handle concurrent load. The source code of
the RIPE Atlas probes is based on BusyBox [11]. It has
been adapted to improve the event management using the
libevent library [12]. In addition, probes control the mea-
surements frequency with eperd, a cron-like utility that can
run measurements at regular intervals. One-oﬀ measurements
are managed by the utility eooqd. Probes receive measure-
ment requests from their controller with a telnet daemon. As
several users can use a probe at the same time, it is essen-
tial to somehow schedule and limit users requests. In 2013,
RIPE made the Atlas source code publicly available [13] but
not yet the controller’s.
Atlas probes are popular sources of measurements
and are increasingly used in research. Since its incep-
tion, Atlas performed almost 30 million individual measure-
1
HTTP measurements are possible but are restricted to re-
searchers and other interested users on a case-by-case basis.
2As a measurement may involve a large number of probes,
the number of individual measurements is more representa-
tive of the load of the platform.
438Atlas probe
under test
  External
Ring nodes
Reported
 delays
LAN
Colocated 
Ring node
Gateway
Internet
External measurements
Figure 2: As opposed to traditional measurements which
pass through the Internet (red arrows), the packets between
the tested Atlas probe and its colocated Ring node (green
arrow) always stay in the local network, thus preventing our
measurements from being polluted by Internet variations.
3. QUANTIFYING INTERFERENCE
We describe how we quantify interference between mea-
surements performed on a RIPE Atlas probe. We take the
perspective of one user λ and one probe ρ and measure the
eﬀects on the results reported by ρ to λ when: i) ρ originates;
or ii) is the target of concurrent measurements. In partic-
ular, we look at changes in the delay reported by ρ when
concurrent one-oﬀ traceroutes are originated or when ρ is
being used as ping destination. We use NL Ring nodes [25]
as destinations (resp. as sources) of the pings sourced on
(resp. destined to) ρ. We also look at changes in the com-
pletion time of one-oﬀ traceroute experiments performed on
ρ.
We measure the delay reported by a probe using
ping Delay-based measurements are indeed the most sensi-
tive to concurrent load. In contrast, traceroute, SSL, and