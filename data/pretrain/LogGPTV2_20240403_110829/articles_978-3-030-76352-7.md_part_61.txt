### Figure 14: Messages in vs. Messages Consumed for BPI Ch. 2017 Event Log

In the context of Scalable Online Conformance Checking, we observe that the flow of incoming messages (i.e., events from the stream) and the flow of processed messages (i.e., consumed events) overlap significantly more in the DSC version compared to the PL version. This indicates that the consumer lag in the DSC version is considerably lower than in the PL version. Consequently, the two proposed extensions effectively reduce the computational effort required.

## 6. Conclusion

This paper presents an implementation for scalable online conformance checking based on incremental prefix-alignment calculation. The proposed implementation leverages Apache Kafka, a widely used streaming platform in industry, providing a solid foundation for the industrial application of online conformance checking techniques. Additionally, we introduced two extensions that significantly reduce the computational effort. Our experiments demonstrate that the proposed implementation, combined with these extensions, can efficiently process real-life event streams.

Future work should address the problem of determining when a process instance or case is considered complete. This decision is crucial because, due to limited memory resources, we will eventually need to delete aggregates, i.e., the current search state stored for each process instance (as shown in Fig. 7). However, this is a general challenge within the field of online process mining and is outside the scope of this paper.

## References

1. van der Aalst, W.M.P. (1998). The Application of Petri Nets to Workflow Management. *J. Circuits Syst. Comput.*, 8(1), 21–66.
2. van der Aalst, W.M.P., Adriansyah, A., van Dongen, B.F. (2012). Replaying History on Process Models for Conformance Checking and Performance Analysis. *Wiley Interdisc. Rew. Data Mining Knowl. Discov.*, 2(2), 182–192.
3. van der Aalst, W.M.P. (2016). *Process Mining - Data Science in Action*. Springer, Heidelberg. https://doi.org/10.1007/978-3-662-49851-4
4. Adriansyah, A. (2014). Aligning Observed and Modeled Behavior. Ph.D. thesis, Eindhoven University of Technology.
5. Adriansyah, A., van Dongen, B.F., van der Aalst, W.M. (2013). Memory-Efficient Alignment of Observed and Modeled Behavior. BPM Center Report, p. 03.
6. Burattin, A., Carmona, J. (2018). A Framework for Online Conformance Checking. In: Teniente, E., Weidlich, M. (eds.) *BPM 2017. LNBIP*, vol. 308, pp. 165–177. Springer, Cham. https://doi.org/10.1007/978-3-319-74030-0_12
7. Burattin, A., Sperduti, A., van der Aalst, W.M.P. (2014). Control-Flow Discovery from Event Streams. In: Proceedings of the IEEE Congress on Evolutionary Computation, CEC 2014, Beijing, China, 6–11 July 2014, pp. 2420–2427. IEEE.
8. Burattin, A., van Zelst, S.J., Armas-Cervantes, A., van Dongen, B.F., Carmona, J. (2018). Online Conformance Checking Using Behavioural Patterns. In: *BPM*.
9. Carmona, J., van Dongen, B.F., Solti, A., Weidlich, M. (2018). *Conformance Checking - Relating Processes and Models*. Springer, Cham. https://doi.org/10.1007/978-3-319-99414-7
10. van Dongen, B. (2019). Dataset BPI Challenge 2019. https://doi.org/10.4121/uuid:d06aff4b-79f0-45e6-8ec8-e19730c248f1
11. van Dongen, B. (2017). BPI Challenge 2017. https://doi.org/10.4121/uuid:5f3067df-f10b-45da-b98b-86ae4c7a310b
12. van Dongen, B. (2020). BPI Challenge 2020: Domestic Declarations. https://doi.org/10.4121/uuid:3f422315-ed9d-4882-891f-e180b5b4feb5
13. Einziger, G., Friedman, R., Manes, B. (2017). TinyLFU: A Highly Efficient Cache Admission Policy. *ACM Trans. Storage*, 13(4), 1–31.
14. Eugster, P.T., Felber, P.A., Guerraoui, R., Kermarrec, A.M. (2003). The Many Faces of Publish/Subscribe. *ACM Comput. Surv. (CSUR)*, 35(2), 114–131.
15. Kreps, J., Narkhede, N., Rao, J., et al. (2011). Kafka: A Distributed Messaging System for Log Processing. *Proc. NetDB*, 11, 1–7.
16. Leemans, S.J.J., Fahland, D., van der Aalst, W.M.P. (2014). Discovering Block-Structured Process Models from Event Logs Containing Infrequent Behaviour. In: Lohmann, N., Song, M., Wohed, P. (eds.) *BPM 2013. LNBIP*, vol. 171, pp. 66–78. Springer, Cham. https://doi.org/10.1007/978-3-319-06257-0_6
17. de Leoni, M.M., Mannhardt, F. (2015). Road Traffic Fine Management Process. https://doi.org/10.4121/uuid:270fd440-1057-4fb9-89a9-b699b47990f5
18. Murata, T. (1989). Petri Nets: Properties, Analysis and Applications. *Proc. IEEE*, 77(4), 541–580.
19. Podlipnig, S., Bösörményi, L. (2003). A Survey of Web Cache Replacement Strategies. *ACM Comput. Surv. (CSUR)*, 35(4), 374–398.
20. Rozinat, A., van der Aalst, W.M.P. (2008). Conformance Checking of Processes Based on Monitoring Real Behavior. *Inf. Syst.*, 33(1), 64–95.
21. Schuster, D., van Zelst, S.J. (2020). Online Process Monitoring Using Incremental State-Space Expansion: An Exact Algorithm. In: Fahland, D., Ghidini, C., Becker, J., Dumas, M. (eds.) *BPM 2020. LNCS*, vol. 12168, pp. 147–164. Springer, Cham. https://doi.org/10.1007/978-3-030-58666-9_9
22. van Zelst, S.J., Bolt, A., Hassani, M., van Dongen, B.F., van der Aalst, W.M.P. (2017). Online Conformance Checking: Relating Event Streams to Process Models Using Prefix-Alignments. *Int. J. Data Sci. Anal.*, 8(3), 269–284. https://doi.org/10.1007/s41060-017-0078-6

---

### Bringing Cognitive Augmentation to Web Browsing Accessibility

**Alessandro Pina¹, Marcos Baez², and Florian Daniel¹**

¹ Politecnico di Milano, Milan, Italy  
² LIRIS – University of Claude Bernard Lyon 1, Villeurbanne, France

**Abstract**

In this paper, we explore the opportunities brought by cognitive augmentation to provide a more natural and accessible web browsing experience. We explore these opportunities through conversational web browsing, an emerging interaction paradigm for the Web that enables blind and visually impaired users (BVIP), as well as regular users, to access the contents and features of websites through conversational agents. Informed by the literature, our previous work, and prototyping exercises, we derive a conceptual framework for supporting BVIP conversational web browsing needs. We then focus on the challenges of automatically providing this support, describing our early work and prototype that leverage heuristics considering structural and content features only.

**Keywords:** Chatbots, Conversational web browsing, Heuristics, Web accessibility

## 1. Introduction

Accessing the Web has long relied on users correctly processing and interpreting visual cues to have a proper user experience. Web browsers and the information and services they provide are optimized to make full use of users' visual perceptive capabilities for organizing, delivering, and fulfilling their goals. This introduces problems for blind and visually impaired people (BVIP) who, due to genetic, health, or age-related conditions, cannot effectively rely on their visual perception [6].

Assistive technologies such as screen readers have traditionally supported BVIP users in interacting with visual interfaces. These tools exploit the accessibility tags used by web developers and content creators to facilitate access to information and services online, typically by reading out the elements of the website sequentially from top to bottom (see Fig. 1). They are usually controlled with a keyboard, offering shortcuts to navigate and access content. The challenges faced by BVIP in browsing the Web with this type of support are well documented in the literature, ranging from websites not designed for accessibility [10, 18] to limitations of screen reading technology [3, 21, 29].

**Fig. 1.** Example serialization of a website by a screen reader. HTML elements are read typically from top to bottom, as informed by the website's HTML structure.

Cognitive augmentation has been regarded as a promising direction to empower populations challenged by the traditional interaction paradigm for accessing information and services [7]. Conversational browsing is an emerging interaction paradigm for the Web that builds on this promise to enable BVIP, as well as regular users, to access the contents and services provided by websites through dialog-based interactions with a conversational agent [4]. Instead of relying on the sequential navigation and keyboard shortcuts provided by screen readers, this approach would enable BVIP to express their goals by directly "talking to websites." The first step towards this vision was to identify the conceptual vocabulary for augmenting websites with conversational capabilities and explore techniques for generating chatbots out of websites equipped with bot-specific annotations [13].

In this paper, we delve deeper into the opportunities of cognitive augmentation for BVIP by building a conceptual framework that takes the lessons learned from the literature, our prior work, and prototyping exercises to highlight areas for conversational support. We then focus on the specific tasks that are currently served poorly by screen readers and describe our early work towards a heuristic-based approach that leverages visual and structural properties of websites to translate the experience of graphical user interfaces into a conversational medium.

## 2. Conceptual Framework

### 2.1 Motivating Scenario

Before introducing the main concepts, we illustrate our vision by describing an example interaction of a BVIP looking for information on COVID-19 on a local newspaper. Peter, 72, is a visually impaired man affected by Parkinson's disease who keeps hearing about the new virus COVID-19 on TV and wants to be updated constantly about recent news from his favorite local newspaper, The Tambury Gazette. However, his experience with screen readers has been poor and frustrating, often requiring assistance from others to get informed.

The vision is to enable users like Peter to browse the Web by directly "talking" to websites. As seen in Fig. 2, the user interacts with the website in dialog-based voice-based interactions with a conversational agent (e.g., Google Assistant). The user can start the session by searching for the website or opening it directly if already bookmarked. Once open, the user can inquire about the relevant actions available in the current context (e.g., "What can I do in this website?"), which are automatically derived by the conversational agent based on heuristics. Instead of sequentially going through the website, the user can look up specific information within the website matching their interests (e.g., "Lookup COVID"). The user can then follow up on the list of resulting articles and choose one to be read out. As part of these interactions, the user can use voice commands to navigate and get oriented in the website.

**Fig. 2.** Example of conversational browsing on an information-intensive website.

The above illustrates the experience of browsing a website by leveraging natural language commands that improve over the keyboard-based sequential navigation of websites. As we will see, more advanced support can be provided by leveraging the content and application-specific domain knowledge, but in this work, we focus on improving the features provided by screen readers, making no assumptions about compliance with accessibility and bot-specific annotations.

### 2.2 Characterizing Conversational Browsing Support

Enabling conversational browsing requires first and foremost understanding the type of support needed to meet BVIP needs. Informed by previous research, our own work, and prototyping experiences, we highlight a few relevant areas in Table 1 and describe them below.

**Table 1.** Categories of support for engaging BVIP in conversations with websites

| **Category** | **Skills** | **Examples** |
|--------------|------------|--------------|
| **Metadata & Content** | Overview | "What is this website about?" |
| | Content Q&A | "When are sports coming back?" |
| | Summary | "Summarize the article?" |
| | About | "Who are the authors of this article?" |
| | Yes/No | "Is the article written in English?" |
| **Browsing** | Outline | "What can I do in this website?" |
| | Orientation | "Where am I?" |
| | Navigation | "Go to the main page"; "Next article" |
| | Lookup | "Lookup COVID" |
| **Reading** | Reading | "Read article"; "Stop reading" |
| **Workflows** | Element-specific | "Fill out the form" |
| | App-specific | "Post a new comment on the news article" |
| **Operations** | Open | "Open The Tambury Gazette" |
| | Search | "Search for The Tambury Gazette" |
| | Bookmark | "Bookmark page The Tambury Gazette" |
| | Speech | "Increase speech rate" |
| | Verbosity | "Turn on short interactions" |

#### Conversational Access to Content and Metadata

BVIP should be able to satisfy their information needs without having to sequentially go through all the website content and structure—a process that can be time-consuming and frustrating for screen reader users [18]. This support is rooted in ongoing efforts in conversational Q&A [12] and document-centered digital assistants [17]. The idea is to support BVIP users in performing natural language queries (NLQ) on the contents of websites and inquiring about the properties defined in the website's metadata. For example, a BVIP user might request an overview of the website (e.g., "What is this website about?"), engage in question and answering, with questions that can be answered by referring directly to the contents of the website (e.g., "When are the sports coming back?"), and ask for summaries of the contents of the website, its parts, or responses from the agent (e.g., "Summarize the article"). Users might also ask about the properties and metadata of the artifacts, such as last modification, language, authors (e.g., "Who are the authors of this article?"), or simply engage in yes/no questions on metadata and content (e.g., "Is the document written in English?").

#### Conversational Browsing

BVIP should be allowed to explore and navigate the artifacts using natural language, so as to support more traditional information-seeking tasks. The idea is to improve on the navigation provided by traditional screen readers, which often require learning complex shortcuts and lower-level knowledge about the structure of the artifact (e.g., to move between different sections), by allowing users to utter simpler high-level commands in natural language. This category of support is inspired by the work in Web accessibility, in using spoken commands to interact with non-visual web browsers [3, 28] and conversational search [26, 27]. For example, BVIP should be able to inquire about the website organization and get an outline (e.g., "What can I do in this website?"), navigate through the structure of the website and even across linked web pages (e.g., "Go to the main page"), and be able to get oriented during this exploratory process (e.g., "Where am I?"). The user should also be able to look up relevant content to avoid sequentially navigating the page structure (e.g., "Lookup COVID").

#### Conversational User Workflows

BVIP should also be able to enact user workflows by leveraging the features provided by the website. This is typically done by the users, enacting their plan by following links, filling out forms, and pressing buttons. These low-level interactions have been explored by speech-enabled screen readers such as Capti-Speak [3], enabling users to utter commands (e.g., "press the cart button," "move to the search box"). We call these element-specific intents. In our previous work, we highlighted the need for supporting application-specific intents, i.e., intents that are specific to the offerings of a website (e.g., "Post a new comment on the news article") and that would trigger a series of low-level actions as a result. In our approach, such experience required bot-specific annotations [13]. The automation of such workflows has also been explored in the context of Web accessibility. For example, Bigham et al. [9] introduced the Trailblazer system, which focused on facilitating the process of creating web automation macros by providing step-by-step suggestions based on CoScript [19]. It is also the focus of research in robotic process automation [20].

#### Conversational Control Operations

BVIP should be able to easily access and personalize the operational environment. This goes from simple operations to support the main browsing experience, such as searching and opening websites and managing bookmarks, to personalizing properties of the voice-based interactions. Recent works in this context have highlighted the importance of providing BVIP with higher control over the experience. Abdolrahmani et al.