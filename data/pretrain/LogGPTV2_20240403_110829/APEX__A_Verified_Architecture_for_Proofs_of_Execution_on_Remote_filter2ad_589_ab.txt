et al. [5] veriﬁed an assembly implementation of SHA-256,
Poly1305, AES and ECDSA. Zinzindohoué, et al. [45] devel-
oped HACL*, a veriﬁed cryptographic library containing the
entire cryptographic API of NaCl [3]. Larger security-critical
systems have also been successfully veriﬁed. Bhargavan [4]
implemented the TLS protocol with veriﬁed cryptographic
security. CompCert [32] is a C compiler that is formally veri-
ﬁed to preserve C code semantics in generated assembly code.
Klein et al. [28] designed and proved functional correctness of
the seL4 microkernel. More recently, VRASED [15] realized a
formally veriﬁed hybrid RA architecture. APEX architecture,
proposed in this paper, uses VRASED RA functionality (see
Section 3.2 for details) composed with additional formally
veriﬁed architectural components to obtain provably secure
PoX.
Proofs of Execution (PoX)– Flicker [34] offers a means for
obtaining PoX in high-end devices. It uses TPM-based attes-
tation and sealed storage, along with late launch support of-
fered by AMD’s Secure Virtual Machine extensions [43] to
implement an infrastructure for isolated code execution and
attestation of the executed code, associated inputs, and outputs.
Sanctum [13] employs a similar approach by instrumenting
Intel SGX’s enclaved code to convey information about its
own execution to a remote party. Both of these approaches are
only suitable for high-end devices and not for low-end devices
targeted in this paper. As discussed earlier, no prior hybrid RA
architecture for low-end devices provides PoX.
USENIX Association
29th USENIX Security Symposium    773
3 Background
3.1 Formal Veriﬁcation, Model Checking &
Linear Temporal Logic
Computer-aided formal veriﬁcation typically involves three ba-
sic steps. First, the system of interest (e.g., hardware, software,
communication protocol) is described using a formal model,
e.g., a Finite State Machine (FSM). Second, properties that the
model should satisfy are formally speciﬁed. Third, the system
model is checked against formally speciﬁed properties to guar-
antee that the system retains them. This can be achieved by
either Theorem Proving or Model Checking. In this work, we
use the latter to verify the implementation of system modules,
and the former to derive new properties from sub-properties
that were proved for the modules’ implementation.
In one instantiation of model checking, properties are speci-
ﬁed as formulae using Temporal Logic (TL) and system models
are represented as FSMs. Hence, a system is represented by a
triple (S,S0,T ), where S is a ﬁnite set of states, S0 ⊆ S is the set
of possible initial states, and T ⊆ S×S is the transition relation
set – it describes the set of states that can be reached in a single
step from each state. The use of TL to specify properties allows
representation of expected system behavior over time.
We apply the widely used model checker NuSMV [11],
which can be used to verify generic HW or SW models. For
digital hardware described at Register Transfer Level (RTL)
– which is the case in this work – conversion from Hardware
Description Language (HDL) to NuSMV model speciﬁcation
is simple. Furthermore, it can be automated [26], because the
standard RTL design already relies on describing hardware as
an FSM.
In NuSMV, properties are speciﬁed in Linear Temporal
Logic (LTL), which is particularly useful for verifying sequen-
tial systems, since LTL extends common logic statements with
temporal clauses. In addition to propositional connectives, such
as conjunction (∧), disjunction (∨), negation (¬), and implica-
tion (→), LTL includes temporal connectives, thus enabling
sequential reasoning. In this paper, we are interested in the
following temporal connectives:
• Xφ – neXt φ: holds if φ is true at the next system state.
• Fφ – Future φ: holds if there exists a future state where φ
is true.
• Gφ – Globally φ: holds if for all future states φ is true.
• φ U ψ – φ Until ψ: holds if there is a future state where ψ
holds and φ holds for all states prior to that.
• φ B ψ – φ Before ψ: holds if the existence of state where
ψ holds implies the existence of an earlier state where φ
holds. This connective can be expressed using U through
the equivalence: φ B ψ ≡ ¬(¬φ U ψ).
This set of temporal connectives combined with propositional
connectives (with their usual meanings) allows us to specify
powerful rules. NuSMV works by checking LTL speciﬁcations
against the system FSM for all reachable states in such FSM.
3.2 Formally Veriﬁed RA
VRASED [15] is a formally veriﬁed hybrid (hardware/software
co-design) RA architecture, built as a set of sub-modules, each
guaranteeing a speciﬁc set of sub-properties. All VRASED sub-
modules, both hardware and software, are individually veriﬁed.
Finally, the composition of all sub-modules is proved to satisfy
formal deﬁnitions of RA soundness and security. RA sound-
ness guarantees that an integrity-ensuring function (HMAC in
VRASED’s case) is correctly computed on the exact memory
being attested. Moreover, it guarantees that attested memory
remains unmodiﬁed after the start of RA computation, protect-
ing against “hide-and-seek” attacks caused by self-relocating
malware [9]. RA security ensures that RA execution generates
an unforgeable authenticated memory measurement and that
the secret key K used in computing this measurement is not
leaked before, during, or after, attestation.
To achieve aforementioned goals, VRASED software
(SW-Att) is stored in Read-Only Memory (ROM) and relies
on a formally veriﬁed HMAC implementation from HACL*
cryptographic library [45]. A typical execution of SW-Att is
carried out as follows:
1. Read challenge C hal from memory region MR.
2. Derive a one-time key from C hal and the attestation mas-
ter key K using an HMAC-based Key Derivation Func-
tion (KDF).
3. Generate an attestation token H by computing an HMAC
over an attested memory region AR using the derived key:
4. Write H into MR and return the execution to unprivileged
H = HMAC(KDF(K ,MR),AR)
software, i.e, normal applications.
VRASED hardware (HW-Mod) monitors 7 MCU signals:
• PC: Current Program Counter value;
• Ren: Signal that indicates if the MCU is reading from
bit);
These signals are used to determine a one-bit reset signal out-
put. Whenever reset is set to 1 a system-wide MCU reset is trig-
gered immediately, i.e., before the execution of the next instruc-
tion. This condition is triggered whenever VRASED’s hardware
detects any violation of its security properties. VRASED hard-
ware is described in Register Transfer Level (RTL) using Finite
State Machines (FSMs). Then, NuSMV Model Checker [12]
is used to automatically prove that such FSMs achieve claimed
security sub-properties. Finally, the proof that the conjunction
of hardware and software sub-properties implies end-to-end
soundness and security is done using an LTL theorem prover.
memory (1-bit);
ory (1-bit);
• Wen: Signal that indicates if the MCU is writing to mem-
• Daddr: Address for an MCU memory access;
• DMAen: Signal that indicates if Direct Memory Access
(DMA) is currently enabled (1-bit);
• DMAaddr: Memory address being accessed by DMA.
• irq: Signal that indicates if an interrupt is happening (1-
774    29th USENIX Security Symposium
USENIX Association
More formally, VRASED end-to-end security proof guarantees
that no probabilistic polynomial time (PPT) adversary can win
the RA security game (See Deﬁnition 7 in Appendix B) with
non-negligible probability in terms of the security parameter.
4 Proof of Execution (PoX) Schemes
A Proof of Execution (PoX) is a scheme involving two parties:
(1) a trusted veriﬁer V rf, and (2) an untrusted (potentially
infected) remote prover P rv. Informally, the goal of PoX is to
allow V rf to request execution of speciﬁc software S by P rv.
As part of PoX, P rv must reply to V rf with an authenticated
unforgeable cryptographic proof (H ) that convinces V rf that
P rv indeed executed S. To accomplish this, verifying H must
prove that: (1) S executed atomically, in its entirety, and that
such execution occurred on P rv (and not on some other device);
and (2) any claimed result/output value of such execution, that
is accepted as legitimate by V rf, could not have been spoofed
or modiﬁed. Also, the size and behavior (i.e., instructions) of S,
as well as the size of its output (if any), should be conﬁgurable
and optionally speciﬁed by V rf. In other words, PoX should
provide proofs of execution for arbitrary software, along with
corresponding authenticated outputs. Deﬁnition 1 speciﬁes
PoX schemes in detail.
We now justify the need to include atomic execution of S in
the deﬁnition of PoX. On low-end MCUs, software typically
runs on “bare metal" and, in most cases, there is no mechanism
to enforce memory isolation between applications. Therefore,
allowing S execution to be interrupted would permit other
(potentially malicious) software running on P rv to alter the
behavior of S. This might be done, for example, by an appli-
cation that interrupts execution of S and changes intermediate
computation results in S data memory, thus tampering with
its output or control ﬂow. Another example is an interrupt that
resumes S at different instruction modifying S execution ﬂow.
Such actions could modify S behavior completely via return
oriented programming (ROP).
4.1 PoX Adversarial Model & Security Deﬁni-
tion
occurs, Adv can not tamper with, or inﬂuence, this execution’s
outputs. These notions are formalized by the security game in
Deﬁnition 2.
We note that Deﬁnition 2 binds execution of S to the time
between V rf issuing the request and receiving the response.
Therefore, if a PoX scheme is secure according to this deﬁni-
tion, V rf can be certain about freshness of the execution. In
the same vein, the output produced by such execution is also
guaranteed to be fresh. This timeliness property is important to
avoid replays of previous valid executions; in fact, it is essential
for safety-critical applications. See Section 7.3 for examples.
Correctness of the Executable: we stress that the purpose
of PoX is to guarantee that S, as speciﬁed by V rf, was exe-
cuted. Similar to Trusted Execution Environments targeting
high-end CPUs, such as Intel SGX, PoX schemes do not aim
to check correctness and absence of implementation bugs in
S. As such, it is not concerned with run-time attacks that ex-
ploit bugs and vulnerabilities in S implementation itself, to
change its expected behavior (e.g., by executing S with inputs
crafted to exploit S bugs and hijack its control ﬂow). In partic-
ular, correctness of S need not be assured by the low-end P rv.
Since V rf is a more powerful device and knows S, it has the
ability (and more computational resources) to employ various
vulnerability detection methods (e.g., fuzzing [10] or static
analysis [14]) or even software formal veriﬁcation (depending
on the level of rigor desired) to avoid or detect implementation
bugs in S. This type of techniques can be performed ofﬂine
before sending S to P rv and the whole issue is orthogonal
to the PoX functionality. We also note that, if S needs to be
instrumented for PoX (see Section 5.1 for a discussion on this
requirement), it is important to ensure that this instrumentation
does not introduce any bugs/vulnerabilities into S.
Physical Attacks: physical and hardware-focused attacks
are out of scope of this paper. Speciﬁcally, we assume that Adv
can not modify code in ROM, induce hardware faults, or retrieve
P rv secrets via physical presence side-channels. Protection
against such attacks is considered orthogonal and could be
supported via standard physical security techniques [38]. This
assumption is inline with other hybrid architectures [7, 15, 20,
29].
We consider an adversary Adv that controls P rv’s entire soft-
ware state, code, and data. Adv can modify any writable mem-
ory and read any memory that is not explicitly protected by
hardware-enforced access control rules. Adv may also have
full control over all Direct Memory Access (DMA) controllers
of P rv. Recall that DMA allows a hardware controller to di-
rectly access main memory (e.g., RAM, ﬂash or ROM) without
going through the CPU.
We consider a scheme PoX = (XRequest, XAtomicExec,
XProve, XVerify) to be secure if the aforementioned Adv has
only negligible probability of convincing V rf that S executed
successfully when, in reality, such execution did not take place,
or was interrupted. In addition we require that, if execution of S
4.2 MCU Assumptions
We assume the same machine model introduced in VRASED
and make no additional assumptions. We review these assump-
tions throughout the rest of this section and then formalize
them as an LTL machine model in Section 6.
Veriﬁcation of the entire CPU is beyond the scope of this pa-
per. Therefore, we assume the CPU architecture strictly adheres
to, and correctly implements, its speciﬁcations. In particular,
our design and veriﬁcation rely on the following simple ax-
ioms:
A1 – Program Counter (PC): PC always contains the address
of the instruction being executed in a given CPU cycle.
USENIX Association
29th USENIX Security Symposium    775
Deﬁnition 1 (Proof of Execution (PoX) Scheme).
A Proof of Execution (PoX) scheme is a tuple of algorithms [XRequest, XAtomicExec, XProve, XVerify] performed between P rv and V rf where:
1. XRequestV rf→P rv(S ,·): is an algorithm executed by V rf which takes as input some software S (consisting of a list of instructions {s1,s2, ...,sm}).
V rf expects an honest P rv to execute S. XRequest generates a challenge C hal, and embeds it alongside S, into an output request message asking
P rv to execute S, and to prove that such execution took place.
2. XAtomicExecP rv(ER,·): an algorithm (with possible hardware-support) that takes as input some executable region ER in P rv’s memory,
containing a list of instructions {i1,i2, ...,im}. XAtomicExec runs on P rv and is considered successful iff: (1) instructions in ER are executed from
its ﬁrst instruction, i1, and end at its last instruction, im; (2) ER’s execution is atomic, i.e., if E is the sequence of instructions executed between i1
and im, then {e|e ∈ E} ⊆ ER; and (3) ER’s execution ﬂow is not altered by external events, i.e., MCU interrupts or DMA events. The XAtomicExec
algorithm outputs result string O. Note that O may be a default string (⊥) if ER’s execution does not result in any output.
3. XProveP rv(ER,C hal,O,·): an algorithm (with possible hardware-support) that takes as input some ER, C hal and O and is run by P rv to
output H , i.e., a proof that XRequestV rf→P rv(S ,·) and XAtomicExecP rv(ER,·) happened (in this sequence) and that O was produced by
XAtomicExecP rv(ER,·).
4. XVerifyP rv→V rf (H ,O,S ,C hal,·): an algorithm executed by V rf with the following inputs: some S, C hal, H and O. The XVerify algorithm
checks whether H is a valid proof of the execution of S (i.e., executed memory region ER corresponds to S) on P rv given the challenge C hal, and if
O is an authentic output/result of such an execution. If both checks succeed, XVerify outputs 1, otherwise it outputs 0.
Remark: In the parameters list, (·) denotes that additional parameters might be included, depending on the speciﬁc PoX construction.
Deﬁnition 2 (PoX Security Game).
– Let treq denote time when V rf issues C hal ← XRequestV rf→P rv(S ).
– Let tveri f denote time when V rf receives H and O back from P rv in response to XRequestV rf→P rv.
– Let XAtomicExecP rv(S ,treq → tveri f ) denote that XAtomicExecP rv(ER,·), such that ER ≡ S, was invoked and completed within the time interval
[treq,tveri f ].
– Let O ≡ XAtomicExecP rv(S ,treq → tveri f ) denote
that XAtomicExecP rv(S ,treq → tveri f ) produces output O. Conversely, O (cid:54)≡
XAtomicExecP rv(S ,treq → tveri f ) indicates O is not produced by XAtomicExecP rv(S ,treq → tveri f ).
2.1 PoX Security Game (PoX-game): Challenger plays the following game with Adv:
1. Adv is given full control over P rv software state and oracle access to calls to the algorithms XAtomicExecP rv and XProveP rv.
2. At time treq, Adv is presented with software S and challenge C hal.
3. Adv wins in two cases:
(a) None or incomplete execution: Adv produces (HAdv,OAdv), such that XVerify(HAdv,OAdv,S ,C hal,·) = 1,
(b) Execution with tampered output: Adv calls XAtomicExecP rv(S ,treq → tveri f ) and can produce (HAdv,OAdv),
without calling XAtomicExecP rv(S ,treq → tveri f ).
such that XVerify(HAdv,OAdv,S ,C hal,·) = 1 and OAdv (cid:54)≡ XAtomicExecP rv(S ,treq → tveri f )
2.2 PoX Security Deﬁnition:
A PoX scheme is considered secure for security parameter l if, for all PPT adversaries Adv, there exists a negligible function negl such that:
Pr[Adv,PoX-game] ≤ negl (l)
A2 – Memory Address: Whenever memory is read or writ-
ten, a data-address signal (Daddr) contains the address of the
corresponding memory location. For a read access, a data read-
enable bit (Ren) must be set, while, for a write access, a data
write-enable bit (Wen) must be set.
A3 – DMA: Whenever the DMA controller attempts to access
the main system memory, a DMA-address signal (DMAaddr)
reﬂects the address of the memory location being accessed and
a DMA-enable bit (DMAen) must be set. DMA can not access
memory when DMAen is off (logical zero).