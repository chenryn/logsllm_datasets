forensic logging techniques [49, 45]. API and binder logs de-
livered via openat() system call are handled here. They are
further processed to retrieve API and binder information in
the server when we inject logs into a relational database.
If the kernel module generates data faster than the user-
level daemon can consume, we might lose data. To prevent
the loss of information in the ring buﬀer, we make sure that
the ring buﬀer has enough space to store the current sys-
tem call. When we intercept the entry of a system call, we
check the remaining space of the ring buﬀer.
If the ring
buﬀer is full, the kernel module suspends the execution of
the system call and allows the user-space daemon to con-
sume the ring buﬀer. We allocate each ring buﬀer with 16
MBytes, for example, Nexus 6 needs four ring buﬀers and
Nexus 9 has two, one for each CPU-core. In our experiments
with I/O intensive workloads and Android benchmark ap-
plications, ring buﬀers hardly become full. The user-space
daemon is multi-threaded process that eﬃciently consumes
ring buﬀers. It compresses the data using zlib before writ-
ing to the storage, then periodically sends the compressed
log to a predeﬁned server via ssh protocol. In our current
setup, we send the log every 10 minutes if wiﬁ is available.
Table 1 shows a runtime and space overhead of Linux au-
dit and DroidForensics’s system call logger. In this exper-
iments, we use popular Android benchmark applications,
namely PCMark [10], TabletMark [13], and 3DMark [1].
These benchmarks have been used by IT magazines and de-
velopers to compare performances between diﬀerent devices
and Android versions.
PCMark-work benchmark simulates basic oﬃce work tasks
such as web-browsing, video editing, writing, photo editing
and parsing data. PCMark-storage accesses various types
of ﬁles located in internal storage, external storage and lo-
cal database. TabletMark simulates web-browsing, email ac-
cessing, and watching and editing photos and videos. 3DMark
uses OpenGL ES benchmarks to measure CPU and GPU
performance. Each benchmark execution takes 20 to 60 min.
The third column shows runtime overhead of Linux audit
system. It goes up to 38%. The forth and ﬁfth columns show
overhead from our technique while we turn-oﬀ the compres-
sion, and turn-on the compression, respectively. DroidForensics
with the compression is a little slower than without the com-
pression, but it still shows much lower overhead (3.17% on
average and 4.14% in the worst case) than Linux audit. The
last three columns show space consumption of system call
logs generated by Audit, DroidForensics without the com-
pression, and DroidForensics with the compression, respec-
tively. DroidForensics with the compression shows much
smaller log size than other two cases (9.5 times smaller than
Audit and 6.9 times smaller than without the compression).
We can observe similar results from Nexus 9 tablet (details
are elided). We argue that 3% to 4% of runtime overhead
from DroidForensics with the compression is acceptable in
practice. All other experiments in this paper are conducted
with the compression turned on.
3.4 User Interface
DroidForensics uses MySQL database as a back-end stor-
age and we provide a declarative interface based on SQL-like
language to the user. Various levels of logs are encoded into
SQL database and the user can compose one or more queries
on relations to reconstruct Android attacks. We deﬁned a
set of relations that describe aspects of Android API, binder
and system calls. Figure 5 presents the detailed schemas.
Pid and Uid shows the process id and the user id of the pro-
cess, and Time means the timestamp of the event. Binder
event shows a causal relation between the client and the
server processes. It has Spid and Suid ﬁelds for the server’s
process id and user id. Stime and Etime are timestamps
for BR_TRANSACTION and BC_REPLY event respectively. We
assume that the server’s events happens between Stime and
Etime are causally related to the client process (details are
discussed in the section 3.2).
If additional information is
available (e.g., SMS body or a recipient’s address), we store
them in MSG ﬁeld.
API event presents the interaction between Android app
and underlying Android Framework. We use Name and
ARG ﬁelds to represent the API name and their important
arguments (e.g., SQLite query).
System call event shows the interaction between the pro-
cess and Android kernel. We use Num for system call num-
ber and Target for the target system object. We additionally
deﬁne TargetType ﬁeld to show the type of the object such
as ﬁle, socket, or process. It is useful to understand low-level
process behaviors such as process X reads ﬁle A, process Y
send a packet to IP 1.2.3.4 or process X kills process Y.
Figure 6 shows how DroidForensics’ user interface works.
DroidForensics accepts SQL-like query from the user and
our pre-processor converts it into SQL queries. Our post-
processor generates a causal graph from the query results
6
671Figure 5: Database schema for log properties
time. TabletMark simulates web-browsing, email accessing,
and watching and editing photos and videos. Each bench-
mark execution takes 10 to 60 minutes and we run each
benchmark 5 times and report the average.
Figure 7 shows the runtime overhead. The graph shows
separate results from each test and overall bar represents
a ﬁnal score reported from each benchmark suite. Web-
browsing benchmark in PCMark shows the highest over-
head, which is 6.16% slower than original Android without
DroidForensics. Overall results show that DroidForensics
only causes negligible runtime overhead (2.58% on average).
Figure 8 presents the forensic log
Space Overhead:
size changes over 24 hours. In this experiment, we install
DroidForensics on Nexus 6 and Nexus 9 devices and ask
graduate students to use them for 24 hours. Both Nexus 6
and Nexus 9 cannot use SMS, phone or LTE because Nexus
9 is a wiﬁ-only model and we removed a sim card from Nexus
6 for this experiment. The users stayed wiﬁ-available places
such as home and oﬃce over 90% of time during this ex-
periments. We installed Chrome web-borwser, Gmail app,
and a few other utility and game applications before the ex-
periment. We also implemented a simple script app that
records the current size of our forensic log when the user
clicks a button. We ask each user to click the button every
hour until he goes to bed at midnight. Next morning at
8am, the user clicked the button again to get the ﬁnal log
size. Because we do not have log size data between 12am
to 8am, we present an average rate of log increase during
that period. The results show that Nexus 6 log grows at
4.75MB/hour in a daytime and 3.45MB/hour at night and
the log in Nexus 9 grows at an rate of 8.9MB/hour in a day-
time and 3.2MB/hour at night. Note that DroidForensics
can transfer the log to the server (if wiﬁ is available), but
we did not transfer any log in this experiment. If the user
can use wiﬁ every one hour, average space consumption of
DroidForensics will be 5.6MB on average and 16.21MB in
the worst case. If the user can send the log every 10 minutes,
the device requires only less than 3MB additional storage for
the forensic log. The majority of the logs (97.9%) are sys-
tem call logs, 1.6% of the logs are generated from Binder,
and 0.5% of are from API.
4.2 Effectiveness
We collect 30 real-world Android malware samples and
evaluate DroidForensics on them. We install each malware
package to Android-6.0.1 r42 on Nexus 6 device. Then we
execute a malware while DroidForensics collects forensic logs.
After the execution, we use SQL-like queries to reconstruct
Figure 6: The user inferface of DroidForensics.
and the user can iteratively compose queries based on gen-
erated causal graphs. Our post-processor can merge the new
results into the previous graph so that the user can inspect
the attack with a uniﬁed graph. We demonstrated how the
user can utilize DroidForensics to reconstruct the Android
attack in section 2.
4. EVALUATION
To establish the practicality of DroidForensics, we mea-
sure the runtime and space overhead it incurs for forensic
logging. We also evaluate DroidForensics on 30 real-world
and one crafted Android malwares, and we can easily recon-
struct their behaviors. Finally, we use Android Compatibil-
ity Test Suite (CTS) on our modiﬁed Android framework
and the results show that our modiﬁcation does not aﬀect
the compatibility. The experiments were performed on two
devices; Nexus 6 with Snapdragon 805 CPU (Quad-core 2.7
GHz, 32-bit) and 3GByte RAM, and Nexus 9 with Tegra K1
CPU (Dual-core 2300 MHz, 64-bit) and 2GByte RAM. We
use Android-6.0.1 r42 for Nexus 6 and 6.0.1 r46 for Nexus
9.
4.1 Logging Overhead
Runtime Overhead:
In this experiment, we examine
the runtime overhead incurred by DroidForensics. Overhead
was measured by widely used Android benchmark programs
including PCMark for Android [10], 3DMark [1], Antutu [3],
DiscoMark [7], and TabletMark [13].
PCMark simulates basic oﬃce work tasks such as web-
browsing, video editing, writing, photo editing and pars-
ing data. 3DMark uses OpenGL ES benchmarks to mea-
sure CPU and GPU performance. Antutu measures perfor-
mance of the device in multiple aspects. For instance, 3D-
test evaluates the performance of 3D rendering, UX exam-
ines the performance of multi-tasking and application execu-
tions, CPU and RAM tests use CPU-intensive and memory
workloads to measure the device performance. DiscoMark
developed at ETH and it opens and closes installed appli-
cations multiple times to measure the application’s launch
7
[Pre-processor]Compile QueryMySQL DB(API, Binder, Syscall Tables)SQL-likeQueryCausalgraphsSQLqueriesSQLoutputDroidForensicsForensic LogsServer[Post-processor]Generate Graph672Figure 7: The runtime overhead of DroidForensics
Figure 8: Accumulated log size from the one-day execution.
behaviors of the malware. We start from a query, SELECT *
from API,BIN,SYS where pid=malware_pid;, then we com-
pose additional queries based on the output of the previ-
ous query until we ﬁnd all relations from the malware pro-
cess. To evaluate the eﬀectiveness of DroidForensics, an-
other graduate student studied each malware with manual
approaches such as understanding various analysis reports
on the web and inspecting the malwares using APK ana-
lyzer, ADB and log-cat. We compare the analysis outputs’
from DroidForensics and the manual inspection.
Table 2 shows the result. The ﬁrst and second columns
present malware family and package names. The last column
presents the comparison between DroidForensics and the
manual inspection. “Full” represents DroidForensics can dis-
cover all attack behaviors. “Partial” means DroidForensics
misses part of attack behaviors. It happens from two ran-
somware samples, namely LockScreen and FBI.Locker. Both
show similar behaviors. They ﬁrst lock the device, then send
a SMS message in the background to indicate a succesful in-
fection, and ﬁnally display a ransom message (html page)
via Android webview. DroidForensics successfully captures
SMS sending and a ransom message events, but we failed to
capture the behaviors for the device locking. To lock the de-
vice, they manipulate event handlers to hinder the user from
doing any activity on the device. For instance, a malware
overrides event handlers for all actions to home button, back
button, and power button to completely ignore user actions.
Some of touch actions are ignored as well. Our current im-
plementation does not capture function overriding events.
However, we believe this is not a fundamental limitation of
our approach and we plan to support them in near future.
Speciﬁcally, if the application overrides any handler, we will
capture the overriding event and records the name of old
and new event handlers.
The columns from third to ﬁfth represent the type of
logs we needed to understand the attack. We mark ((cid:88))
if a log is needed in attack reconstruction. For example,
com.android.mms20 malware deletes its launcher icon, then
steals IMEI, IMSI and GPS location. It also collects a list
of installed applications. After that, the malware attempts
to send SMS message to a hard-coded number. We can re-
construct all those behaviors from API and binder logs and
we did not need system call logs to understand the attack.
Apparently, the generated graph from our queries (e.g., SE-
LECT * from API,SYS,BIN where pid=malware;) contains
system call edges, but we can fully reconstruct the attack
without them.
It can happen mainly because of the fol-
lowing reasons. First, system calls may not be involved in
the attack behaviors (e.g., SQLite query to memory-loaded
tables). Second, in some cases, we can detect system call
events that contribute the attack, but it can be more clearly
explained by the higher-level logs. For example, mms20 deletes
its launcher icon to hide from the user. We captured two
diﬀerent events that show deleting application icon event:
1) an API log shows a SQLite query, DELETE FROM icons
WHERE componentName LIKE com.android.mms20;, 2) a sys-
tem call log, pwrite app_icons.db shows a low-level action
that modiﬁed app icon.db ﬁle. Obviously, the API log is
much clearer and easier to understand. So we do not mark
the system call column for mms20.
The last row (com.nativeCode) is a crafted malware that
uses native components to access ﬁles, establish a connec-
tion to C&C server, and send information to the server. As
expected, API and Binder logs are not useful, but we can re-
construct all behaviors from system calls. The results from
this experiment show that all three loggers are essential to
reconstruct attacks. All the samples (except the crafted one)
we have used in this study are publicly available on Contagio
Mobile [6].
8
0.0%1.0%2.0%3.0%4.0%5.0%6.0%7.0%Runme OverheadNexus 6Nexus 9PCMark for Android3DMarkAntutuDiscoMarkTabletMark673Is this log needed?
Attack
Syscall Reconstruction?
Malware family
Package Name
app.rewards.amazon.com.amazonrewards
com.dsifakf.aoakmnq
com.example.windseeker
com.droidmojo.celebstalker
com.lge.clock
com.android.mms20
ru.blogspot.playsib.savageknife
com.atools.cuttherope
com.android.systemsecurity
qqkj.qqmagic
com.elite
com.bytedroid.liveprints
com.armorforandroid.security
com.andnottech.morningandnight
token.generator
com.fanta.services
com.security.cert
com.example.android.service
com.Titanium.Gloves
org.projectvoodoo.simplecarrieriqdetector
frhfsd.siksdk.ujdsfjkfsd
com.software.application
il.co.egv
com.exp.tele
com.android.locker
com.googleprojects.mmsp
Worm.Gazon
Android. Smsstealer
Android.Windseeker
Android.Tetus
AVPass
unknown
BadNews B
CutTheRope
unknown
LockScreen
AngryBird
HongTouTou
AndroidArmour
unknown
Android.FakeToken
FantaSDK
Pincer.A
unknown
Android.Titan
Qicsomos A