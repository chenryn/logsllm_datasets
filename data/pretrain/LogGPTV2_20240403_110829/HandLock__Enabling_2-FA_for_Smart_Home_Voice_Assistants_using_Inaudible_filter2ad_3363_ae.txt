### Computational Overhead
The computational overhead increases as the system processes more data.

### True Positive Rates (TPRs) and False Alarm Rates (FARs)
The TPRs in this scenario decrease more compared to those found in Scenario 1. However, the FAR remains below 0.78% for U = 5 users, as the negative class contains more information (i.e., it is exposed to more negative instances).

### Impact of the Number of Microphones
To evaluate how the performance is impacted by the number of microphones used, we select n (1 ≤ n ≤ 5) out of the six available microphones. This results in 6Cn combinations for each gesture. We run five experiments, including any n microphones, using the 960 top features. Figure 19 shows that the average F-Score generally improves for all gestures when the number of microphones is increased. The average F-Score using two microphones for five gestures is above 96%, indicating that HandLock can still achieve reasonable accuracy even with just two microphones.

### Temporal Stability
The motivation behind evaluating the accuracy of HandLock using training and testing samples from different days is that, in the real world, the user will provide training samples only on the first day when setting up HandLock, and then HandLock should be able to identify them on subsequent days. To calculate the overall accuracy of HandLock for each of the five gestures using training and testing samples from different days, we randomly chose 10 participants out of our 39 and collected additional data after one week and one month of their first visit (i.e., Dataset 2 in Table 4). Figure 20a shows the FRR for five gestures over three different time periods, where all models are trained on the data from the first visit. We observe that the FRR slightly increases over time. However, we can potentially reuse high-confidence samples as training data and periodically rebuild the model.

#### Rebuilding the Model Periodically
To rebuild the model periodically, we compute the ROC curve on the data collected from the first visit (i.e., Dataset 1 in Table 4) and determine the threshold (i.e., prediction probability) for the optimal operating point. We then adopt an incremental learning approach, dividing the 30 test samples from the following week and month into six batches, each containing five samples. We reuse the test samples that are correctly predicted with a probability greater than the optimal threshold (0.75) to retrain our model. Figure 20b shows the FRR when using the incremental training approach. We see that the FRR reduces compared to Figure 20a.

### Impact of Distance
To evaluate the impact of the distance from the hand to the microphone, three participants were asked to perform 20 samples of the 'Z' gesture at varying distances of 10 cm, 20 cm, 30 cm, 40 cm, and 50 cm. We tested the model trained on Dataset 1 (see Table 4 for details) using the samples collected at different distances. After running the experiment 10 times, we found the average TPR to be 93.50%, 95.10%, 94.58%, and 86.28% for distances of 10 cm, 20 cm, 30 cm, and 40 cm, respectively, compared to the reference TPR of 95.17% for the three users. The results show that our system has stability within the distance range of 10 to 30 cm, but the performance drops by 9% at 40 cm. Our segmentation method successfully segments only 20.15% of samples at 50 cm, as the Q traces are too weak to surpass our threshold T. Thus, our system currently performs well for any distance ≤ 30 cm.

### Impact of Ambient Noise
To evaluate the impact of environmental noise, we set up our device one meter away from a TV broadcasting news with a sound pressure of 80 dB. Three participants were asked to perform 20 samples of the 'Z' gesture. We observed that the background noise is below 15 kHz, confirmed by analyzing the spectrogram of the collected data. We tested the model trained on Dataset 1 (see Table 4 for details) for the 'Z' gesture and tested it on the samples collected under ambient noise to determine robustness. After rerunning the experiment 10 times, the average TPR was 95.10%. Compared to the reference TPR of 96.29% (see Table 5), we can see that the ambient background noise typically found in homes does not significantly impact our system.

### Cross-Environment Analysis
To evaluate the impact of different surroundings (e.g., rooms), we collected an additional dataset in a home setting (e.g., inside a bedroom). We collected 60 samples of the 'Z' gesture and tested the model trained on Dataset 1 (see Table 4 for details) for the 'Z' gesture. The average TPR was around 89.33%. To improve robustness, we adopted an incremental learning approach, dividing the 60 test samples into 12 batches, each containing five samples. We then used high-confidence testing samples (i.e., test sample predicted probability ≥ 0.75) to retrain our model. With the incremental learning approach, HandLock achieved a TPR of 98.5%.

### System Performance
Next, we present the processing latency and memory consumption of our implementation of HandLock on a personal computer equipped with an Intel i7-2600 3.40GHz processor and 16 GB RAM. Identifying a legitimate user for a given gesture sample (in the binary classification setting) using six audio-stream data took, on average, 56 ms. When generating classification models, our implementation used an average of 214 MB of memory. The Respeaker Core V2 is equipped with a quad-core ARM Cortex A7 (1.5GHz) and 1 GB RAM. Thus, our memory requirements can easily be met by commodity voice assistants.

### Post-Study Survey and Responses
Table 6 summarizes the post-study survey and responses.

| Question | Response (count) |
|----------|------------------|
| How easy was it to use our system (HandLock)? | Extremely easy (24), Somewhat easy (17), Neither easy nor difficult (3), Somewhat difficult (0), Extremely difficult (0) |
| What would be an acceptable duration for authentication? | Less than 1 sec (9), 1–4 sec (28), 4–8 sec (6), More than 8 sec (1) |
| At most how many authentication attempts would you be comfortable making? | 1 (6), 2 (13), 3 (20), 4 (2), 5 (3) |
| Would you deploy HandLock on your voice assistant? | Definitely yes (14), Probably yes (25), Might or might not (1), Probably not (4), Definitely not (0) |
| Compare HandLock with an app-based 2-FA approach (i.e., tapping) | Much Better (16), Somewhat better (18), About the same (10), Somewhat worse (0), Much worse (0) |

### User Study and Feedback
In this section, we analyze the usability of HandLock by conducting a post-study survey, where all participants providing hand gesture data complete a survey at the end of the data collection process. We also ask participants to compare HandLock against an existing app-based 2-FA approach, where users authenticate by tapping a button on the app.

#### Data Collection Procedure
Each participant in our study completed a post-study survey, where they were asked about their experience and expectations using our proposed gesture-based authentication technique. We also asked participants questions about comparing our approach with a tap-based 2-FA approach on a mobile app. Table 6 lists the basic questions asked. Participants also answered the SUS (System Usability Scale) questionnaire, which is a well-known standard for measuring the usability of software systems and consists of 10 standard usability questions, each with five possible answers (5-point Likert scale, where 1 represents strong disagreement and 5 represents strong agreement). We computed the SUS score for both HandLock and the app-based 2-FA approach.

#### Takeaways
In analyzing the user responses, we filtered out one user as they completed the survey in 75 seconds, which is below the median response time (546 seconds) by a factor of 7 (i.e., the user most likely did not pay much attention to the questions).

First, we analyzed the user's experience and expectations for using HandLock. 93.18% (41/44) of participants considered HandLock to be either extremely easy or somewhat easy to use, as shown in Table 6. 88.64% (39/44) of participants said they would probably or definitely deploy HandLock on their own voice assistants. Around 77.27% of participants felt that HandLock is better (i.e., either somewhat or much better) than using a mobile app-based 2-FA approach. Our survey also asked participants for comments about the pros and cons of our approach. Some examples of the comments received include:

- **P1**: "I think range is a very important factor in terms of user experience. If I can unlock the assistant while sitting on a bed/sofa, that would be quite impactful."
- **P18**: "Advantage is you only need yourself (no phone on you). Disadvantage is your hands have to be free."
- **P21**: "More convenient than other authentications. The sound could be more pleasant, if it’s a tune."
- **P28**: "Very hygienic, no need for other equipment or network. Looking forward to it, I hope it can be put into the market and applied in practice as soon as possible."
- **P38**: "Handlock – gesture-based authentication is a very simple, efficient, and fast way of getting access. The only thing I would like to suggest is it should be compact."

From the comments, we can see that, in general, participants felt that the system was easy to use. There were some concerns about being close to the device and having full hand functionality. However, we believe these concerns are unlikely to manifest too often in reality.

The authentication duration plays a vital role in assessing usability. The vast majority (63.64%; 28/44) of participants reported that the acceptable duration for authentication should lie within 1 to 4 seconds. We computed the average duration for performing a single gesture to be around 1.89 (±0.64) seconds. Since the average processing latency is 56 milliseconds (as reported in Section 4.4), the total end-to-end verification time required by HandLock is around 2 seconds. Thus, our approach would satisfy the expectation for the majority of users. In terms of the number of authentication attempts, 88.64% of participants (39/44) would tolerate at best three attempts. In Section 4.1.6, we show that the expected number of attempts required for a successful authentication is around 1.05 ± 0.24, which is below the tolerance level indicated by the participants.

Next, we compare HandLock with other alternatives using SUS scores. A SUS score of above 68 is typically considered above average, and anything below 68 is below average. Based on the participants’ responses, the mean SUS score for HandLock is 71.88 ± 18.69, while the mean SUS score for an app-based 2-FA is 62.96 ± 12.25. One reason for HandLock obtaining a higher SUS score is that the participants consider the system as device-free and easy-to-use, as evident from their free text comments. For the participants who own voice assistants, the mean SUS score for HandLock and app-based 2-FA is 74.64 ± 17.58 and 64.05 ± 15.26, respectively. For the participants who did not own voice assistants, the mean SUS score for HandLock and app-based 2-FA is 69.35 ± 19.69 and 61.96 ± 13.53, respectively. Thus, in general, participants found our approach to be more usable than an app-based 2-FA approach.

### Acknowledgments
We thank our anonymous reviewers for their valuable feedback. We give special thanks to all the participants who took the time to participate in our data collection study. This material is based upon work supported in part by the National Science Foundation under grant number CNS-1849997. Any opinions, findings, and conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.

### Limitations and Discussion

#### Sound Generation
The majority of our participants could not hear the generated sound. However, a few participants could hear the sound. The National Institute of Occupational Safety and Health (NIOSH) defines hazardous noise as sound that exceeds 85 dB over a typical 8-hour day, which could cause hearing loss. In reality, HandLock would play near-ultrasound sounds for just a few seconds at a sound pressure level of 50 dB (SPL) during the authentication process. Thus, our approach is unlikely to cause any hearing issues. To further improve usability, we can either use higher frequencies (i.e., above 18 kHz) or low-frequency music/tone (e.g., ≤ 8 kHz), something we plan to explore in the future.

#### Simultaneous Movements
Currently, we assume that at any given time, only a single user performs a predefined gesture. HandLock further assumes that while a user performs a predefined gesture, there are no background movements close to the device. If multiple users perform predefined gestures simultaneously or if there are background movements close to the device, HandLock may not identify the users from the gestures. However, HandLock's accuracy is not significantly impacted by the movements of people 3 meters away from the device, as we observed that the signal interference is very weak from such a distance.

#### Distance Limitation
In our setting, the user performs the gesture on top of the device from a distance of 5 to 30 cm. Millisonic [50] made a preliminary effort towards tracking gestures at room scale. In the future, we plan to explore augmenting HandLock to enable user identification from gestures at longer distances.

### Conclusion
In this paper, we present a new modality of acoustic signal-based 2-FA system for smart home voice assistants, called HandLock. HandLock extracts unique movement characteristics of a user’s hand gesture. We extensively evaluated HandLock using a large dataset of over 15,000 gesture samples, covering five common gestures, and showed that it can achieve an average TPR of 96.51% across 34 users while the FAR is 0.82%. However, HandLock can achieve a TPR of 99.91% with three gesture attempts. We also extensively evaluated HandLock’s accuracy, stability, and resiliency to attacks under various settings. We believe this simple yet effective 2-FA approach is a first step towards helping consumers better protect sensitive operations carried out by voice assistants.

### References
[1] 2016. Teardown Tuesday: Amazon Echo Dot v2. Retrieved March 25, 2020 from www.allaboutcircuits.com/news/teardown-tuesday-amazon-echo-dot-v2/
[2] 2019. Historical Households Tables. Retrieved March 25, 2020 from https://www.census.gov/data/tables/time-series/demo/families/households.html
[3] 2019. The Smart Audio Report from NPR and Edison Research, Spring 2019. Retrieved May 25, 2020 from https://www.edisonresearch.com/the-smart-audio-report-from-npr-and-edison-research-spring-2019/