but computational overhead increases.
shows that the TPRs decrease more compared to the TPRs found in
scenario 1. However, the FAR remains below 0.78% for U = 5 users
as the negative class contains more information (i.e., exposed to
more negative instances).
Impact of the number of microphones used. To evaluate how
4.3.2
the performance is impacted by the number of microphones used,
we select n (1 ≤ n ≤ 5) out of the six microphone data. Conse-
quently, we have 6Cn combinations for each gesture. We run 5
experiments including any n microphones using the 960 top fea-
tures. Figure 19 shows that the average F-Score, in general, improves
for all gestures when increasing the number of microphones. The
average F-Score using two microphones for five gestures is above
96%, which means HandLock still can achieve reasonable accuracy
even with 2 microphones.
4.3.3 Temporal stability. The motivation behind evaluating the
accuracy of HandLock using training and testing samples from dif-
ferent days is that in the real world, the user will provide training
samples only on the first day when setting up HandLock, and then
HandLock should be able to identify them on subsequent days. To
calculate the overall accuracy of HandLock for each of the five ges-
tures using training and testing samples from different days we
randomly chose 10 participants out of our 39 and collected addi-
tional data after one week and one month of their first visit (i.e.,
Dataset 2 in Table 4). Figure 20a shows the FRR for 5 gestures for
three different time-periods, where all models are trained on the
data from the first visit. We can see that in general FRR slightly in-
creases. However, we can potentially reuse high confidence samples
as training data and rebuild the model periodically.
11
(a) No incremental learning
(b) Incremental learning
Figure 20: FRR over time (day, week and month).
To rebuild the model periodically, we compute the ROC curve
on the data collected from the first visit (i.e., Dataset 1 in Table 4)
and determine the threshold (i.e., prediction probability) for the
optimal operating point. We next adopted an incremental learning
approach, where we divide the 30 test samples from the following
week and month into 6 batches where each batch contains 5 samples.
We then reuse the test samples that are correctly predicted with a
probability greater than the optimal threshold (0.75) to retrain our
model. Figure 20b shows the FRR when using incremental training
approach. We see that FRR reduces compared to Figure 20a.
Impact of distance . To evaluate the impact of distance from
4.3.4
the hand to the microphone, three participants were asked to per-
form 20 samples of the ‘Z’ gesture at varying distances of 10 cm,
20 cm, 30 cm, 40 cm, 50 cm. We test the model trained on Dataset 1
(see Table 4 for details) using the samples collected under different
distances. After running the experiment 10 times we found the av-
erage TPR to be 93.50%, 95.10%, 94.58% and 86.28% for the distance
of 10 cm, 20 cm, 30 cm and 40 cm, respectively, compared to the
reference TPR of 95.17% for the 3 users. The result shows that our
system has stability within the distance of 10 ∼ 30 cm, but the per-
formance drops by 9% at 40 cm distance. Our segmentation method
only successfully segments 20.15% of samples at the distance of 50
cm, as the Q traces are too weak to surpass our threshold T . Thus,
our system currently performs well for any distance ≤ 30 cm.
Impact of ambient noise. To evaluate the impact of environ-
4.3.5
mental noise, we set up our device one meter away from a TV
broadcasting news with a sound pressure of 80 dB. Three partici-
pants were asked to perform 20 samples of ‘Z’ gesture. We observe
that the background noise is below 15 kHz, confirmed by analyzing
the spectrogram of the data collected. We test the model trained
on Dataset 1 (see Table 4 for details) for the ‘Z’ gesture and test on
the sample collected under ambient noise to determine robustness.
After rerunning the experiment 10 times, the average TPR is 95.10%.
Compared to the reference TPR of 96.29% (see Table 5) we can see
that the ambient background noise typically found at homes does
not significantly impact our system.
4.3.6 Cross-environment analysis. To evaluate the impact of differ-
ent surroundings (e.g., rooms), we collected one additional dataset
under home setting (e.g., inside a bedroom). We collected 60 sam-
ples of ‘Z’ gesture. We then test the model trained on Dataset 1
(see Table 4 for details) for the ‘Z’ gesture. The average TPR was
around 89.33%. To improve the robustness, we adopted an incre-
mental learning approach, where we divided the 60 test samples
2345Number of enrolled users80859095100TPR (%)TPR--SGTPR--MGNumber of microphoneF-Score (%)FRR (%)DayWeekMonthFRR (%)DayWeekMonth261RAID ’21, October 6–8,2021, San Sebastian, Spain
Shaohu Zhang and Anupam Das
into 12 batches with each batch containing 5 samples. We then use
high confidence testing samples ( i.e., test sample predicted proba-
bility ≥ 0.75) to retrain our model. We found that with incremental
learning approach, HandLock can achieve a TPR of 98.5%.
4.4 System Performance
Next, we present the processing latency and memory consump-
tion of our implementation of HandLock on a personal computer
which is equipped with Intel i7-2600 3.40GHz processor and 16
GB RAM. Identifying a legitimate user for a given gesture sample
(in the binary classification setting) using six audio-stream data,
took on average 56 ms. When generating classification models, our
implementation used an average memory of 214 MB. Respeaker
Core V2 is equipped with quad-core ARM Cortex A7 (1.5GHz) and
1 GB RAM. Thus, our memory requirement can easily be fulfilled
by commodity VAs.
Table 6: Summary of post-study survey and responses.
Question
How easy was it to use our
system (HandLock)?
What would be an accept-
able duration for authenti-
cation?
At most how many
authentication attempts
would you be comfortable
making?
Would you deploy Hand-
Lock on your voice assis-
tant?
Compare HandLock with
an app-based 2-FA ap-
proach (i.e., tapping)
Response (count)
Extremely easy (24), Somewhat easy
(17), Neither easy nor difficult (3),
Somewhat difficult (0), Extremely dif-
ficult (0)
Less than 1 sec (9), 1–4 sec (28), 4–8
sec (6), More than 8 sec (1)
1 (6), 2 (13), 3 (20), 4 (2), 5 (3)
Definitely yes (14), Probably yes (25),
Might or might not (1), Probably not
(4), Definitely not (0)
Much Better (16), Somewhat bet-
ter(18), About the same (10), Some-
what worse (0), Much worse (0)
5 USER STUDY AND FEEDBACK
In this section, we analyze the usability of HandLock by conducting
a post-study survey, where all participants providing hand gesture
data complete a survey at the end of the data collection process.
We also ask participants to compare HandLock against an existing
app-based 2-FA approach, where users authenticate by tapping a
button on the app.
Data Collection Procedure. Each participant in our study com-
pleted a post-study survey, where they were asked about their
experience and expectations using our proposed gesture-based au-
thentication technique. We also asked participants questions about
comparing our approach with a tap-based 2-FA approach on a mo-
bile app. Table 6 list the basic questions asked. Participants also
answered the SUS (System Usability Scale) questionnaire, which is
a well-known standard for measuring the usability of software sys-
tems and consists of 10 standard usability questions, each with five
possible answers (5-point Likert scale, where 1 represents strong
disagreement and 5 represents strong agreement) [12] (the 10 ques-
tions are provided in Table 7 in Appendix A). We compute SUS
score for both HandLock and the app-based 2-FA approach.
Takeaways. In analyzing the user responses, we filtered out one
user as he/she completed the survey in 75 seconds which is below
the median response time (546 seconds) by a factor of 7 (i.e., the
user most likely did not pay much attention to the questions).
First, we analyze user’s experience and expectations for using
HandLock. 93.18% (41/44) participants consider HandLock to be
either extremely easy or somewhat easy to use as shown in Table 6.
88.64% (39/44) participants said they would probably or definitely
deploy HandLock on their own VAs. Around 77.27% of participants
felt HandLock is better (i.e., either somewhat or much better) than
using a mobile app-based 2-FA approach. Our survey also asked
participants for comments about the pros and cons of our approach.
Following are some examples of the comments received.
12
P1: I think range is a very important factor in terms of user
experience. If I can unlock the assistant while sitting on a
bed/sofa, that would be quite impactful.
P18: Advantage is you only need yourself (no phone on you).
Disadvantage is your hands have to be free.
P21: More convenient than other authentications. The sound
could be more pleasant, if it’s a tune.
P28: Very hygienic, no need for other equipment or network.
Looking forward to it, I hope it can be put into the market
and applied in practice as soon as possible.
P38: Handlock – gesture-based authentication is a very sim-
ple, efficient and fast way of getting access. The only thing I
would like to suggest is it should be compact.
As we can see from the comments, in general, the participants
felt that the system was easy to use. There were some concerns
about being close to the device and having full hand functionality.
However, we feel these are concerns that are not likely to manifest
too often in reality.
The authentication duration plays a vital role in assessing us-
ability. Vast majority of the (63.64 %; 28/44) participants report
that the acceptable duration for authentication should lie within
1 ∼ 4 seconds. We computed the average duration for perform-
ing a single gesture to be around 1.89 (±0.64) seconds. Since, the
average processing latency is 56 milliseconds (as we reported in
the Section 4.4), the total end-to-end verification time required by
HandLock is around 2 seconds. Thus, our approach would satisfy
the expectation for the majority of the users. In terms of number
of authentication attempts, 88.64 % participants (39/44) would tol-
erate at best three attempts. In Section 4.1.6, we show that the
expected number of attempts required for a successful authenti-
cation is around 1.05 ± 0.24, which is below the tolerance level
indicated by the participants.
Next, we will compare HandLock with other alternatives using
SUS scores. A SUS score of above 68 is typically considered above
average and anything below 68 is below average [12]. Based on
the participants’ responses the mean SUS score for HandLock is
71.88 ± 18.69, while the mean SUS score for an app-base 2-FA is
262HandLock: Enabling 2-FA for Smart Home Voice Assistants using Inaudible Acoustic Signal
RAID ’21, October 6–8,2021, San Sebastian, Spain
62.96 ± 12.25. One reason for HandLock obtaining a higher SUS
score is that the participants consider the system as device-free
and easy-to-use as evident from their free text comments. For the
participants who own VAs, the mean SUS score for HandLock and
app-based 2-FA is 74.64 ± 17.58 and 64.05 ± 15.26, respectively.
For the participants who did not own VAs, the mean SUS score for
HandLock and app-based 2-FA is 69.35 ± 19.69 and 61.96 ± 13.53,
respectively. Thus, in general, participants found our approach to
be more usable than an app based 2-FA approach.
ACKNOWLEDGMENTS
We thank our anonymous reviewers for their valuable feedback.
We give special thanks to all the participants who took the time
to participate in our data collection study. This material is based
upon work supported in parts by the National Science Foundation
under grant number CNS-1849997. Any opinions, findings, and
conclusions, or recommendations expressed in this material are
those of the authors and do not necessarily reflect the views of the
National Science Foundation.
6 LIMITATIONS AND DISCUSSION
Sound Generation. The majority of our participants could not
hear the generated sound. However, a few participants could hear
the sound. The National Institute of Occupational Safety and Health
(NIOSH) defines hazardous noise as sound that exceeds 85 dB over
a typical 8-hour day [22], which could cause hearing loss. In reality
HandLock would play near-ultrasound sounds just for a few seconds
at the sound pressure level of 50 dB (SPL) during the authentica-
tion process. Thus, our approach most likely will not cause any
hearing issues. To further improve the usability, we can either use
higher frequencies sound (i.e., above 18kHz) or use low frequency
music/tone (e.g., ≤ 8kHz), something we plan to explore in the
future.
Simultaneous Movements Currently, we assume that at any
given time, only a single user performs a predefined gesture. Hand-
Lock further assumes that while a user performs a predefined ges-
ture, there are no background movements close to the device. If
multiple users perform predefined gestures simultaneously or if
there are background movements close to the device, HandLock
may not identify the users from the gestures. HandLock’s accuracy,
however, is not impacted significantly by the movements of peo-
ple 3 meters away from the device as we observed that the signal
interference is very weak from such distance.
Distance Limitation. In our setting, the user performs the gesture
on top of the device from a distance of 5 to 30 cm. Millisonic [50]
made a preliminary effort towards tracking gestures at room scale.
In future, we plan to explore augmenting HandLock to enable user
identification from gestures at longer distances.
7 CONCLUSION
In this paper, we present a new modality of acoustic signal based 2-
FA system for smart home voice assistants, called HandLock. Hand-
Lock extracts unique movement characteristics of a user’s hand
gesture. We extensively evaluated HandLock using a large data set
of over 15,000 gesture samples, covering five common gestures and
showed that it can achieve an average TPR of 96.51% across 34
users while the FAR is 0.82%. However, HandLock can achieve a
TPR of 99.91% with three gesture attempts. We also extensively
evaluate HandLock’s accuracy, stability and resiliency to attacks
under various settings. We believe this simple, yet effective 2-FA
approach is a first step towards helping consumers better protect
sensitive operations carried out by voice assistants.
13
REFERENCES
[1] 2016. Teardown Tuesday: Amazon Echo Dot v2. Retrieved March 25, 2020 from
www.allaboutcircuits.com/news/teardown-tuesday-amazon-echo-dot-v2/
[2] 2019. Historical Households Tables. Retrieved March 25, 2020 from https://
www.census.gov/data/tables/time-series/demo/families/households.html
[3] 2019. The Smart Audio Report from NPR and Edison Research, Spring 2019. Re-
trieved May,25 2020 from https://www.edisonresearch.com/the-smart-audio-
report-from-npr-and-edison-research-spring-2019/