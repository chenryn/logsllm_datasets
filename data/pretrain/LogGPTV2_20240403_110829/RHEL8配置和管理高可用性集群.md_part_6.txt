    对于特定环境，您可以跳过这一步来禁用集群服务。这可让您确保在节点重新加入集群前解决集群或您的资源中的任何问题。如果禁用了群集服务，则需要在该节点上执行
    `pcs cluster start`{.literal} 命令，在重新引导节点时手动启动该服务。
    :::
    ``` literallayout
    [root@z1 ~]# pcs cluster enable --all
    ```
:::
您可以使用 `pcs cluster status`{.literal}
命令显示集群的当前状态。由于在使用 `pcs cluster setup`{.literal} 命令的
`--start`{.literal}
选项启动群集服务时，在启动群集服务时可能会有一些延迟，因此您应该确保在对群集及其配置执行任何后续操作前启动并运行群集。
``` literallayout
[root@z1 ~]# pcs cluster status
Cluster Status:
 Stack: corosync
 Current DC: z2.example.com (version 2.0.0-10.el8-b67d8d0de9) - partition with quorum
 Last updated: Thu Oct 11 16:11:18 2018
 Last change: Thu Oct 11 16:11:00 2018 by hacluster via crmd on z2.example.com
 2 Nodes configured
 0 Resources configured
...
```
:::
::: section
::: titlepage
# []{#assembly_creating-high-availability-cluster-configuring-and-managing-high-availability-clusters.html#proc_configure-multiple-ip-cluster-creating-high-availability-cluster}创建使用多个链接的高可用性集群 {.title}
:::
您可以通过指定每个节点的所有链接，使用 `pcs cluster setup`{.literal}
命令创建具有多个链接的红帽高可用性集群。
创建具有两个链接的双节点群集的基本命令格式如下：
``` literallayout
pcs cluster setup cluster_name node1_name addr=node1_link0_address addr=node1_link1_address node2_name addr=node2_link0_address addr=node2_link1_address
```
有关此命令的完整语法，请查看 `pcs`{.literal}(8)man page。
当创建具有多个链接的集群时，您应该考虑以下内容。
::: itemizedlist
-   `addr=地址`{.literal}
    参数的顺序非常重要。节点名称后指定的第一个地址为
    `link0`{.literal}，第二个 `地址用于 link1`{.literal}，以此类推。
-   默认情况下，如果没有为链接指定
    `link_priority`{.literal}，则链接的优先级等于链接号。然后，链接优先级为
    0、1、2、3 等，以此类推，0 是最高链路优先级。
-   默认链路模式是
    `被动的`{.literal}，即使用带有最低编号链路优先级的主动链接。
-   使用 `link_mode`{.literal} 和 `link_priority`{.literal}
    的默认值，指定的第一个链接将用作最高优先级链接，如果该链接失败，则将使用指定的下一个链接。
-   可以使用 `knet`{.literal} 传输协议（即默认传输协议）指定最多 8
    个链接。
-   所有节点必须具有相同数量的 `addr= 参数`{.literal}。
-   从 RHEL 8.1 开始，可以使用
    `pcs cluster link add、pcs cluster link remove、pcs cluster link delete、pc`{.literal}
    s `cluster link delete 和 pcs`{.literal}
    `cluster link update`{.literal}
    命令在现有群集中添加、删除``{=html} 和更改链接。
-   与单链路集群一样，请勿将 IPv4 和 IPv6
    地址混合到一个链接中，虽然您可以有一个链接运行 IPv4，另一个运行
    IPv6。
-   与单链路集群一样，只要在一个单一的链接中没有混合使用 IPv4 和
    IPv6，且名称可以被解析为 IPv4 或 IPv6 地址，就可以使用 IP
    地址或名称来指定地址。
:::
以下示例创建一个名为 `my_twolink_cluster`{.literal}
的双节点群集，它有两个节点 `rh80-node1`{.literal} 和
`rh80-node2`{.literal}。`rh80-node1`{.literal} 有两个接口，IP 地址
192.168.122.201 为 `link0`{.literal}，192.168.123.201 为
`link1`{.literal}。`rh80-node2`{.literal} 有两个接口，IP 地址
192.168.122.202 为 `link0`{.literal}，192.168.123.202 为
`link1`{.literal}。
``` literallayout
# pcs cluster setup my_twolink_cluster rh80-node1 addr=192.168.122.201 addr=192.168.123.201 rh80-node2 addr=192.168.122.202 addr=192.168.123.202
```
要将链接优先级设置为与默认值不同的值（即链接号），您可以使用
`pcs cluster setup`{.literal} 命令的 `link_priority`{.literal}
选项设置链接优先级。以下两个示例命令各自创建一个具有两个接口的双节点群集，其中第一个链接
0 具有链接优先级 1，而链接 1 的链接优先级为 0。首先使用链接 1，链接 0
将充当故障转移链接。由于未指定链接模式，因此默认为被动。
这两个命令是等效的。如果您没有在 `link`{.literal}
关键字之后指定链接号，pcs `接口`{.literal}
会自动添加链接号，从最低未使用的链接编号开始。
``` literallayout
# pcs cluster setup my_twolink_cluster rh80-node1 addr=192.168.122.201 addr=192.168.123.201 rh80-node2 addr=192.168.122.202 addr=192.168.123.202 transport knet link link_priority=1 link link_priority=0
# pcs cluster setup my_twolink_cluster rh80-node1 addr=192.168.122.201 addr=192.168.123.201 rh80-node2 addr=192.168.122.202 addr=192.168.123.202 transport knet link linknumber=1 link_priority=0 link link_priority=1
```
您可以将链接模式的值设置为 `与`{.literal} `pcs cluster setup`{.literal}
命令的 `link_mode`{.literal} 选项的默认值不同的值，如下例所示：
``` literallayout
# pcs cluster setup my_twolink_cluster rh80-node1 addr=192.168.122.201 addr=192.168.123.201 rh80-node2 addr=192.168.122.202 addr=192.168.123.202 transport knet link_mode=active
```
以下示例同时设置链接模式和链接优先级。
``` literallayout
# pcs cluster setup my_twolink_cluster rh80-node1 addr=192.168.122.201 addr=192.168.123.201 rh80-node2 addr=192.168.122.202 addr=192.168.123.202 transport knet link_mode=active link link_priority=1 link link_priority=0
```
有关将节点添加到具有多个链接的现有集群的详情，请参阅
[将节点添加到具有多个链接的集群](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_and_managing_high_availability_clusters/assembly_clusternode-management-configuring-and-managing-high-availability-clusters#proc_add-nodes-to-multiple-ip-cluster-clusternode-management){.link}。
有关使用多个链接更改现有集群中的链接的详情，请参阅
[在现有集群中添加和修改链接](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_and_managing_high_availability_clusters/assembly_clusternode-management-configuring-and-managing-high-availability-clusters#proc_changing-links-in-multiple-ip-cluster-clusternode-management){.link}。
:::
::: section
::: titlepage
# []{#assembly_creating-high-availability-cluster-configuring-and-managing-high-availability-clusters.html#proc_configuring-fencing-creating-high-availability-cluster}配置隔离 {.title}
:::
您必须为集群中的每个节点配置保护设备。有关保护配置命令和选项的详情，请参考
[在红帽高可用性集群中配置隔离](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_and_managing_high_availability_clusters/assembly_configuring-fencing-configuring-and-managing-high-availability-clusters){.link}。
有关隔离的一般信息及其在红帽高可用性集群中的重要程度，请查看[红帽高可用性集群中的保护](https://access.redhat.com/solutions/15575){.link}。
::: {.note style="margin-left: 0.5in; margin-right: 0.5in;"}
### 注意 {.title}
在配置隔离设备时，应该注意该设备是否与集群中的任何节点或者设备共享电源。如果某个节点及其隔离设备共享了电源，那么如果它的电源出现问题，集群可能就无法收到隔离功能的保护。这样的集群应该有冗余电源来保护设备和节点，或者具有没有和节点共享电源的额外的隔离设置。其他替代的隔离方法，比如
SBD 或存储隔离，也可以用来对电源问题提供冗余保护。
:::
::: title
**流程**
:::
这个示例使用主机名为 `zapc.example.com`{.literal} 的 APC
电源开关来隔离节点，并使用 `fence_apc_snmp`{.literal}
隔离代理。由于这两个节点都将被同一隔离代理隔离，因此您可以使用
`pcmk_host_map`{.literal} 选项将这两个隔离设备配置为单一资源。
您可以使用 `pcs stonith`{.literal} create 命令将设备配置为
astonith``{=html} 资源来创建隔离设备。以下命令配置名为
`myapc`{.literal} 的 aston `ith`{.literal} 资源，该资源对节点
`z1.example.com 和 z2.example.com`{.literal} 使用
`fence_apc_snmp`{.literal}
隔离代理。``{=html}`pcmk_host_map`{.literal} 选项将
`z1.example.com`{.literal} 映射到端口 1，并将 `z2.example.com`{.literal}
映射到端口 2。APC 设备的登录值和密码都是
`apc`{.literal}。默认情况下，该设备对每个节点都使用 60
秒的监视间隔时间。
请注意，您可以在为节点指定主机名时使用 IP 地址。
``` literallayout
[root@z1 ~]# pcs stonith create myapc fence_apc_snmp \
ipaddr="zapc.example.com" \
pcmk_host_map="z1.example.com:1;z2.example.com:2" \
login="apc" passwd="apc"
```
以下命令显示现有 STONITH 设备的参数。
``` literallayout
[root@rh7-1 ~]# pcs stonith config myapc
 Resource: myapc (class=stonith type=fence_apc_snmp)
  Attributes: ipaddr=zapc.example.com pcmk_host_map=z1.example.com:1;z2.example.com:2 login=apc passwd=apc
  Operations: monitor interval=60s (myapc-monitor-interval-60s)
```
配置了隔离设备后，您应该测试该设备。有关测试隔离设备的详情请参考
[测试隔离设备](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_and_managing_high_availability_clusters/assembly_configuring-fencing-configuring-and-managing-high-availability-clusters#proc_testing-fence-devices-configuring-fencing){.link}。
::: {.note style="margin-left: 0.5in; margin-right: 0.5in;"}
### 注意 {.title}
不要通过禁用网络接口来测试您的隔离设备，因为这不会正确测试隔离功能。
:::
::: {.note style="margin-left: 0.5in; margin-right: 0.5in;"}
### 注意 {.title}
当配置了隔离功能，且启动集群后，网络重启会触发节点的隔离，即使没有超过超时时间也会重启网络。因此，不要在集群服务运行时重启网络服务，因为它将在节点上触发意外隔离。
:::
:::
::: section
::: titlepage
# []{#assembly_creating-high-availability-cluster-configuring-and-managing-high-availability-clusters.html#proc_cluster-backup-creating-high-availability-cluster}备份和恢复集群配置 {.title}
:::
以下命令在 tar
归档中备份集群配置，并从备份中恢复所有节点上的集群配置文件。
::: title
**流程**
:::
使用以下命令，在 tar
存档中备份集群配置。如果没有指定文件名，会使用标准输出。
``` literallayout
pcs config backup filename
```
::: {.note style="margin-left: 0.5in; margin-right: 0.5in;"}
### 注意 {.title}
`pcs config backup`{.literal} 命令仅备份 CIB
中配置的群集配置本身；资源守护进程配置不在此命令范围之内。例如：如果您在集群中配置了
Apache 资源，则会备份资源设置（位于 CIB 中），而 Apache
守护进程设置（如\'/etc/httpd\'
中的设置）及其服务的文件不会被备份。同样，如果集群中配置了数据库资源，则不会备份数据库本身，而是备份数据库资源配置（CIB）。
:::
使用以下命令从备份中恢复所有节点上的集群配置文件。如果没有指定文件名，将使用标准输入。指定
`--local`{.literal} 选项仅恢复当前节点上的文件。
``` literallayout
pcs config restore [--local] [filename]
```
:::
::: section
::: titlepage
# []{#assembly_creating-high-availability-cluster-configuring-and-managing-high-availability-clusters.html#proc_enabling-ports-for-high-availability-creating-high-availability-cluster}为高可用性附加组件启用端口 {.title}
:::
集群组件的理想防火墙配置取决于本地环境，您可能需要考虑节点是否有多个网络接口或主机外防火墙是否存在。
如果您正在运行 `firewalld`{.literal}
守护进程，请执行以下命令启用红帽高可用性附加组件所需的端口。
``` literallayout
# firewall-cmd --permanent --add-service=high-availability
# firewall-cmd --add-service=high-availability
```
您可能需要修改开放端口以适合本地条件。
::: {.note style="margin-left: 0.5in; margin-right: 0.5in;"}
### 注意 {.title}
您可以使用 `rpm -q firewalld`{.literal} 命令确定您的系统中是否安装了
firewalld``{=html} 守护进程。如果安装了 `firewalld`{.literal}
守护进程，您可以使用 `firewall-cmd --state`{.literal}
命令确定其是否在运行。
:::
下表显示了为红帽高可用性附加组件启用的端口，并解释了该端口的用途。
::: table
[]{#assembly_creating-high-availability-cluster-configuring-and-managing-high-availability-clusters.html#tb-portenable-HAAR}
**表 4.1. 为高可用性附加组件启用的端口**
::: table-contents
+--------------------+------------------------------------------------+
| 端口               | 什么时候需要                                   |
+:===================+:===============================================+
| TCP 2224           | 所有节点上都需要默认的 `pcsd`{.literal}        |
|                    | 端口（pcsd Web UI                              |
|                    | 需要且节点到节点的通信需要）。您可以使用       |
|                    | `/etc                                          |
|                    | /sysconfig/pcs d 文件中的 PCSD_PORT`{.literal} |
|                    | 参数来配置 pcs``{=html}                 |
|                    | d``{=html} 端口。                       |
|                    |                                                |
|                    | 打开端口 2224 非常重要，从而使来自任何节点的   |
|                    | `pcs`{.literal}                                |
|                    | 可以                                           |
|                    | 与群集中的所有节点（包括自身）进行通信。当使用 |
|                    | Booth 集群票据管理程序或一个 quorum            |
|                    | 设备时，您必须在所有相关主机上打开端口         |
|                    | 2224，比如 Booth abiter 或者 quorum 设备主机。 |
+--------------------+------------------------------------------------+
| TCP 3121           | 如果集群有 Pacemaker                           |
|                    | 远程节点，则所有节点都需要这个端口             |
|                    |                                                |
|                    | 完整集群节点上 `基于 pacemaker`{.literal}      |
|                    | 的守护进程将在端口 3121 联系 Pacemaker         |
|                    | 远程节点上的 `pacemaker_remoted`{.literal}     |
|                    | 守护进程。如果使用一个单独的接口用于集群通     |
|                    | 信，则该端口只需要在那个接口上打开。至少应该在 |
|                    | Pacemaker                                      |
|                    | 远程节点上完整集群节点打开这个端口。因为       |
|                    | 用户可以在完整节点和远程节点间转换主机，或使用 |
|                    | 主机网络在容器内运行远程节点，您可以为所有节点 |
|                    | 打开端口。不需要向节点以外的任何主机打开端口。 |
+--------------------+------------------------------------------------+
| TCP 5403           | 当使用对仲裁设备使用                           |
|                    | `corosync-qnetd`{.literal}                     |
|                    | 时，仲裁设备主机上需要。可以使用               |
|                    | `corosync-qnetd`{.literal} 命令的              |
|                    | `-p`{.literal} 选项更改默认值。                |
+--------------------+------------------------------------------------+
| UDP 5404-5412      | corosync                                       |
|                    | 节点需要这些端口以便在节点间进行通信。打开端口 |