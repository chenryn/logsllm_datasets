`If COUNT("set") >= 2 and COUNT("%") >= 4 and COUNT("&") >=4 and
COUNT("call")>= 2 then obfuscated`
#### 第三种方法
第三种方法是组合正则表达式和if-then规则。  
这使开发和维护的负担极大地增加，并且仍然存在前两种方法的缺点。
例3 一个带有正则表达式的if-then规则(if-then规则与正则表达式的组合)，用于检测混淆
`If length()>= 20 and COUNT(“&")> 8 and MATCHES_REGEXP("(set [a-zA-Z0-9]+=.*
&&)+ (call set [a-zA-Z0-9]+=%[a-zA-Z0-9%]+%).* call %. *%") then obfuscated`
显然，很容易意识到生成、测试、维护并确保这些规则的效果是多么麻烦。
真正的手工构建的混淆检测器，将由数十或数百个规则组成，并且在检测中仍然存在gaps(漏洞、缺口)。
### 机器学习方法 - 超越模式匹配和规则
使用ML简化了这些问题的解决方案。  
本文举例说明两种ML方法：
  * 1.基于特征的方法(a feature-based approach)
  * 2.无特征的端到端方法(a feature-less end-to-end approach)
有一些ML技术可以处理任何类型的原始数据（只要数据是数字类型的数据就行），神经网络就是一个很好的例子。大多数其他ML算法要求建模者在将原始数据输入算法之前从原始数据中提取有关信息（称为特征）。后一种类型的一些示例是基于树的算法，如本博客发过的这篇文章：[Building
Machine Learning Models for the SOC | FireEye
Inc](https://www.fireeye.com/blog/threat-research/2018/06/build-machine-learning-models-for-the-soc.html)，其中我们使用了Gradient-Boosted树型模型，描述了基于树的算法的结构和用途。
### ML基础 - 神经网络
神经网络是一种ML算法，最近变得非常流行。它由一系列称为神经元(neurons)的元素组成。神经元本质上是一个元素，它接受一组输入，计算这些输入的加权和(weighted
sum)，然后将总和输入非线性函数。已经表明，相对浅的(微弱的)神经元网络可以近似输入和输出之间的任何连续映射。  
我们用于当前这项研究的特定类型的神经网络是所谓的卷积神经网络（CNN），它主要是为计算机视觉应用开发的，但也在包括自然语言处理在内的其他领域取得了成功。神经网络的主要优点之一是它可以在不必手动设计特征的情况下进行训练。
### 无特征的ML
神经网络可以与特征数据一起使用，这种方法的一个吸引人的地方是它可以处理原始数据（转换为数字形式）而无需进行任何特征设计或提取。  
模型的第一步是将文本数据转换为数字形式。我们使用了基于字符的编码，其中每个字符类型都由实际数值编码。该值在训练过程中自动获得，并在字符应用于cmd.exe时，传送有关字符之间的关系的语义信息。
### 基于特征的ML
我们还尝试了手工设计的特征和梯度增强的决策树算法。  
为这个模型开发的特征基本上是统计性质的——源于字符集和关键字的出现和频率。  
例如，存在数十个`％`字符或长而连续的字符串可能有助于检测潜在的混淆。虽然任何单特征都不能完美地分离这两个类，但是基于树的模型中存在的"多个特征的组合"能够学习数据中的灵活模式(flexible
patterns)。预期这些模式是足够健壮的，并且可以通用到、普及到未来的混淆变体。
### 数据和实验
为了开发我们的模型，我们从数万个终端的事件中收集了非混淆的数据，并使用工具Invoke-DOSfuscation中的各种方法生成了混淆过的数据。我们使用大约80％的数据作为训练数据开发出了我们的模型，并用剩余的20％数据来测试了这些模型。我们保证我们的训练和测试是分割明确的。  
对于无特征的ML（即神经网络），我们只需将Unicode码位输入到CNN模型的第一层，第一层将码位转换为语义上有意义的数字表示(这个叫做embeddings)，然后将其提供给神经网络的其余部分。
对于渐变增强树方法，我们从原始命令行生成了许多特性。以下是其中一些:
对于梯度增强树(Gradient Boosted Tree)方法，我们从原始命令行中生成了许多特性。如这些：
  * 命令行的长度
  * 命令行中的插入`^`符号的数量
  * 管道符号`|`的数量
  * 命令行中的空白符号的分数
  * 特殊字符的分数
  * 字符串的熵
  * 命令行中字符串`cmd`和`power`的频率
虽然每一个单独的特征都是一个弱信号，并且每个自身都不可能是一个很好的鉴别器，但是一个灵活的分类器，如梯度增强树(Gradient Boosted
Tree)使用这些特征对足够的数据进行训练，能够对混淆过的和非混淆的命令行进行分类，尽管有上述的一些困难。
### 结果
根据我们的测试集进行评估，我们能够从 梯度增强树(Gradient Boosted Tree) 和 神经网络模型 得到几乎相同的结果。
GBT模型，F1值( F1-score)、准确率(Precision)和召回率(Recall)等指标均接近1.0。GBT模型接近完美。  
CNN模型，准确性略低。
虽然我们当然不指望能在现实世界中获得完美的结果，但这些实验室结果仍然是令人鼓舞的。回想一下，我们所有混淆的示例都是由一个源生成的，即Invoke-DOSfuscation工具。虽然Invoke-DOSfuscation生成各种混淆样本，但在现实世界中，我们期望至少看到一些与Invoke-DOSfuscation生成的样本非常不同的样本。我们目前正在收集真实世界混淆过的命令行，以便更准确地了解此模型对来自实际恶意参与者的混淆样本的通用性。我们预计cmd命令混淆，类似于之前的PowerShell混淆，将继续出现在新的恶意软件家族中。
作为一个额外的测试，我们请Daniel Bohannon(Invoke-DOSfuscation这一Windows命令行混淆工具的作者)提供一些混淆的样本，根据他的经验，这些样本很难被传统的混淆检测器识别。  
实测每种情况，我们的ML探测器仍然都能够检测到混淆。一些样本如下：
    cmd.exe /v/r "set 9S=e3zo Hi Vi3tor and Vikray!&set Zq=!9S:3=c!&setZYk9=!Zq:y=m!&set rQ2=!ZYk9:z=h!&&cmd /r %rQ2%
    cmd /r "set a=tat -ano&set b=nets&cmd /r %b% %a%
    cmd /v /r "set a=ona- tatsten&for/L %b in(11 -1 0) do setc=!c!!a:~%b,1!&if %b equ 0 call %c:~3%
* * *
我们还创建了看起来非常难理解的"文本"（这些文本是有效的Windows命令行），并且没有混淆，但是对于人类直观看到它们会感觉有点混淆。这样做是为了通过边界样本来测试一下检测器的有效性。在这种情况下，检测器也能够正确地将文本分类为非混淆文本。
这样的样本如下：  
第一眼看上去好像是被混淆的样本，但实际上并没有混淆。而且很可能欺骗非ML的解决方案(但是ML混淆检测器目前能够将其标识为非混淆)
例4
    cmd.exe /c 'C:\windows\system3213636363bsdshshshshsGF@#&()____.737.473783873.bat
* * *
最后，是一个复杂但没有混淆过的命令行，它被我们的ML混淆检测器正确分类，但可能会根据统计特征欺骗非ML的检测器（例如用手工的权衡方案和一个阈值的基于规则的检测器，"使用特殊字符的比例"、"命令行的长度"或"命令行的熵"等特征。
例5 使用简单统计特征的ML检测器可能错误分类的样本（但是，我们的ML混淆检测器目前将其识别为非混淆）
    cmd /c echo nbt local > C:\windows\temp\nessus_L571HG8Q.txt & nbtstat-n>> C:\windows\tempnessus_L571HG8Q.txt & echo nbt_cache >> C:windows\temp\nessus_L571HG8Q.txt & nbtstat C >> C:\windows\temp\nessus_L57 1HG8Q.txt & echonbt_session_ip > C:\windows\temp\nessus_L571HG8Q.txt & nbtstat -S >> C:\windows\temp\nessus_L571HG8Q.txt & echo nbt_session_name >> C:windows\temp\nessus_L571HG8Q.txt & nbtstat -S >> C:\windows\temp\nessus_L571HG8Q.txt
结果如下：  
GBT分类器自信地预测了"非混淆"，得分为19.7%
    [INFO] FeatureExtractor extraction complete.
    {'prediction': 'non-obf, 'score': 19.73551018580834, 'reasons': []}
### CNN与GBT的结果对比
我们比较了使用精心选择的特征构建的高度调优的GBT分类器 和 使用原始数据(无特征ML)训练的CNN分类器的结果。  
虽然CNN的结构没有进行大量调整，但有趣的是，例4所示的样本，GBT分类器自信地预测了"非混淆"，得分为19.7%(这是对分类器的结果"非混淆"的信心度量的补充)。同时，CNN分类器预测"非混淆"的置信概率为50%——正好在混淆和非混淆的边界处。CNN模型的误分类次数也多于梯度增强树(GBT)模型。这两种情况都很可能是CNN调优不足的结果，而不是无特征方法的根本缺陷。
### 总结
在这篇博文中，我们描述了一种ML方法来检测混淆过的Windows命令行，它可以作为一个信号来帮助识别恶意的命令行。通过使用ML技术，我们演示了一种非常精确的机制来检测此类命令行，而不需要借助于维护复杂if-then规则和正则表达式的技术（这种技术通常是不充分的，而且成本很高）。更全面的ML方法足够灵活，可以捕捉混淆中的新变化，当检测到gaps(漏洞、缺口)时，通常可以这样处理：通过向训练集添加一些精心选择的evader样本并重新训练模型。
这次ML技术的成功ML的成功应用再次证明了ML在替代"复杂的手工或编程方法"解决计算机安全问题方面的有效性。
在未来几年，我们预计ML将在网络安全公司中扮演越来越重要的角色。