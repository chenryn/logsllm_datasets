title:Detecting and Analyzing Automated Activity on Twitter
author:Chao Michael Zhang and
Vern Paxson
Detecting and Analyzing Automated Activity on Twitter
Chao Michael Zhang1 and Vern Paxson1,2,(cid:2)
1 University of California, Berkeley, CA
2 International Computer Science Institute, Berkeley, CA
Abstract. We present a method for determining whether a Twitter account ex-
hibits automated behavior in publishing status updates known as tweets. The ap-
proach uses only the publicly available timestamp information associated with
each tweet. After evaluating its effectiveness, we use it to analyze the Twitter
landscape, ﬁnding that 16% of active accounts exhibit a high degree of automa-
tion. We also ﬁnd that 11% of accounts that appear to publish exclusively through
the browser are in fact automated accounts that spoof the source of the updates.
1 Introduction
Twitter is a microblogging service that allows its members to publish short status up-
dates known as tweets. Over 180 M visitors interact with Twitter each month, generating
55 M tweets/day [13]. User accounts and their status updates are public by default, ac-
cessible by the general public via Twitter’s two application program interfaces (APIs).
The large number of users, low privacy expectations, and easy-to-use API have made
Twitter a target of abuse, whether relatively benign in the form of spam and disruptive
marketing tactics [5], or malicious in the form of links to malware [17] and phishing
schemes [8]. Often abuse on Twitter employs automation for actions such as publishing
tweets, following another user, and sending links through private messages.
Prior research on Twitter has studied the properties of the social network [10], char-
acteristics of users and their behavior [11], and social interactions between users [9], but
not speciﬁcally regarding the issue of automation on Twitter (other than our own use
of the technique we develop here to assist with ﬁnding Twitter “career” spammers [7]).
In this work we present a technique for determining whether a Twitter account ap-
pears to employ automation to publish tweets, as manifest in ﬁne-grained periodicities
in tweet timestamps. Our approaach has the beneﬁt of being able to ﬁnd legitimate
accounts compromised by spammers who employ automation. We evaluate the test’s
effectiveness and describe its weaknesses, including the ability for determined adver-
saries to evade it by directly mimicing human posting patterns. Finally, we examine
various facets of Twitter as a service and discuss the prevalence of automation in each.
2 Background and Measurement Data
Tweets are short messages (limited to 140 characters) posted to a Twitter account using
a browser, a stand-alone application, an API, or SMS messages. Information associated
(cid:2) This work was supported by NSF grants CNS-0831535, CNS-0905631, and NSF-0433702,
and ONR MURI Grant N000140911081.
N. Spring and G. Riley (Eds.): PAM 2011, LNCS 6579, pp. 102–111, 2011.
c(cid:2) Springer-Verlag Berlin Heidelberg 2011
Detecting and Analyzing Automated Activity on Twitter
103
with each tweet includes the time at which the update was created and the source by
which the status appears to have been posted. Users on Twitter can subscribe to the
tweets of another account by choosing to follow that account. The user will then receive
that account’s tweets through the main “timeline” prominently displayed on the Twitter
website and via separate applications, or via SMS messages. Accounts have two main
privacy settings: Public accounts have their content visible to the general public regard-
less of whether the visitor is logged in or not, while protected accounts can only be
viewed by users who have had follow requests accepted by the account owner.
Twitter’s “Veriﬁed Account” program allows people and companies to show that
their account in fact belongs to them. Twitter only makes this program available to a
modest number of accounts that deal with mistaken identity or impersonation problems;
at the time of this writing there are 1,738 veriﬁed accounts.
Twitter is a real time communication service, and at any given time there may be cer-
tain topics that are widely discussed among members in the community. These trending
topics are featured prominently to provide users with an up-to-date glimpse at what
the community is talking about. Twitter uses algorithms to constantly determine these
popular topics, publishes them to the website, and makes them available through APIs.
Twitter provides two APIs through which developers can interact with the service.
The “REST API” provides methods for reading and writing data to the main service,
while the “Search API” handles queries for searching tweets and obtaining trending
topics. The API can be accessed through basic authentication using an account’s user-
name and password, or can be accessed through OAuth [2], allowing users to provide
third-party applications with access to their data stored on Twitter.
For our purposes we term any account that publishes a signiﬁcant portion of its
tweets automatically using a computer program as a bot. We refer to tweets published in
real-time by a human as manual, or organic, tweets.
Data Used in the Study. We draw upon public data associated with accounts and status
updates. We evaluated 106,573 distinct accounts using data from 3 weeks in April 2010.
Since we rely on public information, we only examine accounts with “public” privacy.
For each account, the REST API can return the latest 3,200 tweets, with 200 updates
returned per call (we examined a maximum of 300 tweets per account, to avoid skew
due to API timeouts). Tweets returned by the API include a timestamp indicating when
Twitter received the tweet (1 sec precision), the account’s followers and privacy settings,
the client program from which the tweet apparently originated, and whether the account
has been “veriﬁed.”
3 Detecting Tweet Automation
We base our detector on the premise that highly automated accounts will exhibit timing
patterns that do not manifest in the tweet times of non-automated users. In particular,
a human user posting updates to Twitter organically is most likely indifferent towards
what second-of-the-minute or what minute-of-the-hour they post updates.1 Therefore,
an organic sequence of update times should appear to be randomly drawn from a uni-
form distribution across seconds-of-the-minute and minutes-of-the-hour. The upper left
1 This will certainly be the case if their posting is well-modeled as a Poisson process.
104
C.M. Zhang and V. Paxson
Fig. 1. Timing plots for different Twitter accounts. Each point represents a single tweet. The
x-axis gives the tweet’s minutes-in-the-hour and the y-axis the seconds-in-the-minute. The upper
left plot passes our χ2 test for expected uniformity, presumably reﬂecting organic behavior. The
others all fail, exhibiting different patterns of non-uniformity, except for the lower right, which
exhibits hyper-uniformity, too good to be produced by a random-uniform process.
plot in Figure 1 shows a typical timing graph for human-generated tweet times. While
not completely uniform, they lack noticeable groupings or patterns.
Automated accounts, on the other hand, may exhibit timing distributions that lead to
detectable non-uniformity (or excessive uniformity) due to a number of reasons. First,
automation is often invoked by job schedulers that execute tasks at speciﬁed times or
intervals, and these are usually speciﬁed in round quantities such as minute-granularity.
Furthermore, Twitter imposes a limit of 1,000 tweets/day (as well as ﬁner-grained limits
for smaller units of time), so there is no apparent beneﬁt in scheduling automated tweets
more often than say one a per-minute basis. Given scheduling at minute-granularity,
the seconds-within-the-minute when such tweets appear are unlikely to be uniformly
distributed across the minute. The upper middle plot in Figure 1 shows a timing graph
of a user who exhibits this type of automated behavior. While the times are distributed
somewhat uniformly for minutes-of-the-hour, the user clearly tends to publish updates
towards the beginning of the minute.
If scripts publish tweets at scheduled times in each hour, then we will ﬁnd tweet
times clustering at those scheduled minutes. On the other hand, if a script publishes
updates on a per-minute basis, it may exhibit a timing pattern that is too uniform, which
also distinguishes it from organic activity. The upper right plot in Figure 1 shows the
timing graph of a user that publishes tweets every 5 minutes in the hour; the lower left
plot shows an account that automatically posts updates at the beginning of the hour; and
the lower middle plot shows an account that publishes nearly all of its updates during
two particular times of the hour.
Detecting and Analyzing Automated Activity on Twitter
105
Non-uniform timing can also arise from delay-based automated behavior: scripts
programmed to pause for a certain amount of time after each tweet. Delays that always
run the script at the same minutes-of-the-hour will manifest as either extremely non-
uniform across minutes-of-the-hour, or, in rare cases, too uniform across minutes-of-
the-hour. This latter arises when run times creep into delay-based automation, meaning
that small delays that should lead to non-uniformity instead appear to exhibit excessive
uniformity. The lower right plot in Figure 1 shows the timing graph of an account that
is perfectly uniform across seconds-of-the-minute and minutes-of-the-hour due to what
appears to be slowly drifting times. Thus, we can conclude the presence of automation
if we ﬁnd tweet times either not uniform enough, or too uniform.
Testing for Automated Behavior. We use Pearson’s χ2 test to assess whether a set of
update times is consistent with the uniform second-of-the-minute and minute-of-the-
hour distributions expected from human users. The p-value returned by the χ2 test is
the probability of the observed distribution of times arising if the account is indeed
publishing updates uniformly across seconds-of-the-minute or minutes-of-the-hour. If
the probability is too low, it indicates that the account exhibits non-uniform behavior in
choosing which second-of-the-minute or minute-of-the-hour to publish a post; likewise,
if the probability is too high, it suggests that the account is using a mechanism that
causes it to publish tweets with a level of uniformity that is unlikely to be observed
from natural human use.
For our test we use a two-sided signiﬁcance level of 0.001, or 0.1%, as the threshold
for failing the test. We chose this level after preliminary examination of a small subset
of the accounts. We selected a quite low level to avoid incurring many statistical false
positives due to the large volume of accounts that we examine. Thus, we expect only
2 in 1,000 human accounts with uniform distributions to fail each test.
A common rule of thumb for Pearson’s χ2 test is that 80% of bins should have an
expected count of at least 5 [6]. Therefore if we have 300 timestamps for an account we
use 60 bins for assessing seconds-of-the-minute and minutes-of-the-hour. If we have
fewer, then we use only 6 bins, unless the account has fewer than 30 tweets, in which
case we exclude it due to insufﬁcient data. Eliminating such accounts does not signif-
icantly impair our study as we presume that the interesting uses of automation occur
when accounts regularly tweet.
Automated accounts can exhibit non-uniform timing patterns for both seconds-of-
the-minute and minutes-of-the-hour, both indicative of automation. Therefore, we per-
form a separate χ2 test for each, with a failure of either indicating automation.
4 Evaluating the Test
An important issue is that we lack ground truth regarding whether accounts are truly
automated or organic, and also whether automation reﬂects unwanted activity. However,
we form a partial assessment as follows. From an initial evaluation of 18,147 accounts
we found that 975 accounts had seconds-of-the-minute p-values less than 0.001, and 15
accounts had p-values greater than 0.999. The same ﬁgures for minutes-of-the-hour are
2,599 p-values less than 0.001 and 76 greater than .999.
106
C.M. Zhang and V. Paxson
We manually examined hundreds of timing graphs to conﬁrm they exhibited clear
non-uniform or hyper-uniform behavior, and randomly selected dozens of accounts for
manual veriﬁcation. (Accounts that did not visibly manifest non-uniform behavior, but
were ﬂagged by the test, generally turned out to indeed use third party applications that
automate tweets.) This latter included an examination of the user’s proﬁle and their ﬁrst
page of recent status updates. In nearly all cases we could determine that the account
exhibited strong evidence of likely automation not reﬂecting social human use, based
on status updates (i.e., number of updates, sources, frequency, and contents) and other
features of the account’s Twitter page (i.e., user icon, background image, screenname,
number of followers and friends, and website URL). See below for further discussion
of our evaluation of false positives and false negatives.
This assessment gives us conﬁdence that a signiﬁcance level of 0.001 can effectively
capture accounts that exhibit anomalous timing behavior. However, we also note that
such a stringent signiﬁcance level can cost us the opportunity of observing hybrid ac-
counts that publish with a mix of manual and automatic updates. Some hybrid users
may utilize different applications for these two kinds of updates, allowing us to sepa-
rate these sources in order to evaluate our test. For example, one hybrid we identiﬁed
used the third-party applications TweetDeck [3] and HootSuite [12], both applications
that provide an interface for reading and creating tweets. However, TweetDeck does not
offer functionality for automating tweet creation, while HootSuite provides a schedul-
ing feature. This account’s timing graph exhibits distinct periodicity. Testing only the
tweets posted from TweetDeck, however, does not exhibit such patterns (and passes
the χ2 test), while tweets originating from “HootSuite” exhibit updates at ﬁve minute
intervals, failing the χ2 test.
False Positives. A false positive occurs an account fails our test but is in fact organic.
Along with statistical ﬂuctuations (which will contribute about 2 false positives per
1,000 accounts we assess), these can arise due to legitimate organic use that deviates
from uniform timing. For example, a student who only publishes Twitter updates in
between class periods may fail our test because their tweets will tend towards certain
minutes-of-the-hour.
An example of an account that fails our test but otherwise appears to be organic
is the account of television personality Phil McGraw, also known as Dr. Phil [1]. Af-
ter inspecting the account, we found that it consistently publishes one update per day
shortly before the show begins to remind followers to watch. Although these updates
are manually generated, they are skewed towards the ﬁrst half of the hour.
While we discovered a few false positives along these lines, we note that all of them
concerned accounts that failed on minutes-of-the-hour for the type of reason described
above. We have not discovered any apparently legitimate human account that exhibits
anomalous timings for seconds-of-the-minute.
False Negatives. On the other hand, our false negative rate is likely considerably higher
for a number of reasons. First, as discussed above, hybrid behavior can mask automated
posting due to blending it with organic posting. We could potentially detect more such
instances by using a less stringent signiﬁcance level, but at the cost of more statistical
false positives. Second, automated accounts that exhibit uniformity in some fashion
Detecting and Analyzing Automated Activity on Twitter
107
will of course be missed by our test. In particular, one form of this can arise from
copycat automation, i.e., an automated account that posts in reﬂection of non-automated
timings. For example, an automated accounts triggered by an RSS feed will reﬂect the
timings of the source rather than a speciﬁc schedule.
Evasion. One can easily design an automated account to evade the χ2 test by uni-
formly spreading its tweets across seconds-of-the-minute and minutes-of-the-hour. For
example, the account could post whenever a known-organic account posts; or simply
generate exponentially distributed interarrivals. There does not seem to currently ex-
ist any incentive for automated accounts to be intentional about exhibiting uniformity.
However, if Twitter adopts a test like ours as a countermeasure to detect possible abuse,
then accounts may begin evading the test in this way.
5 Analyzing Twitter’s Landscape
Using the χ2 test, we analyzed public tweets and accounts to determine the prevalence
of automated accounts on the service and how the use of automation varies with respect
to different factors. We sampled the public timeline of global tweets via the REST API,
which makes available the 20 most recent tweets, refreshed every minute. We were
therefore able to obtain a sample of 1,200 tweets per hour. In addition, we used the
Search API to query for samples based on keywords and to obtain trending topics. For
a range of keywords, we performed a search every minute and recorded the accounts
behind the 10 most recent results, for which we then analyzed the posting account. We
sampled search results for between two and four days for each keyword. In addition to
the constantly changing public timeline and sampled search results, we also obtained
accounts from various static lists, including veriﬁed users, most-followed users, and
followers of the most-popular account, collecting up to 300 tweets for each account.
For each account we have six possible dispositions. Passed accounts pass the χ2 test
while Failed accounts do not. Insufﬁcient accounts do not have the 30 status updates
necessary to perform the test. Protected accounts have their privacy settings set to pro-
tected, so we could not test them. Suspended accounts have been suspended by Twitter
for reasons such as spamming and abusing the API. These accounts are rendered com-
pletely inaccessible through the API. However, their user IDs may persist for a time
in various places on Twitter, and therefore may be included in our analysis. Not Found
accounts no longer exist on Twitter. When an individual or business deactivates their
Twitter account, the API returns an error when requesting data from that account. How-
ever, the user ID may persist on various pages of Twitter for up to 30 days, and may be
detected by our analysis.
Table 1 summarizes our results. We note that accounts might exhibit varying degrees
of automation depending on temporal factors such as time of the day or day of the
week. For example, an account may syndicate news from a news source that publishes
more heavily during the waking hours of the day, or may publish from a source that is
inactive on weekends. Therefore, a more accurate assessment of automated activity on
Twitter may monitor activity over the course of weeks or months in order to determine
average levels of automation. Our present analysis does not take these considerations
into account, which we leave for future work. Finally, we emphasize that our estimates
108
C.M. Zhang and V. Paxson
Table 1. Automation testing results for different facets of the Twitter landscape (lower bounds)
Public timeline accounts 19,436 15,330 2,817
Public timeline tweets 18,331 14,790 2,475
113
121
25