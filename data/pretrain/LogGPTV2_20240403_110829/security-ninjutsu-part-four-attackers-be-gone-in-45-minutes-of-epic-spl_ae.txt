| ] || eval search=  	"(user=" . mvjoin(search, " OR user=") . ")" |list of users |Technique: Subsearches 
Taking more than 60 seconds
▶ Unfortunately there’s no magic here, beyond the inherent magic of acceleration.▶ There *is* a change you can make to limits.conf, but I’ve virtually never heard of 	anyone making that change because it is global across the entire server/cluster.▶ So instead, swing down to tstats in the NINJA section, and follow the link to get 	perspectives on how to approach acceleration!Technique: Subsearches 
Working Example
▶ For a concrete working example, check out the examples under "tstats," and 	under "stats + eval"
▶ Notably the example under stats+eval took much much longer than using an 	"OR" (or multisearch! "Technique: Advanced Commands", towards the end).▶ I once did an end-to-end test of performance while looking for threat intel indicators. I compared the performance of doing an [|inputlookup] subsearch to add search criteria, against just looking for all the IPs and then doing a lookup. At 15 indicators, the subsearch was so much faster it was almost silly. At tens of thousands of indicators, the lookup option is faster.
© 2017 SPLUNK INC.© 2017 SPLUNK INC.
Advanced Techniques
Let’s Get Techy In Here
Technique: Summary Indexing
Background and Challenges
▶ "I want to look at statistics over one hundred or more days of authentication 	activity, but the search takes too long to complete"
▶ "I am analyzing a dataset that requires stats on stats [see this technique 
	elsewhere] but the first stats generates millions of rows and the search isincredibly slow."
▶ "I have a very slow search using transaction [or threat intel, or etc] and don’t want 	the analysts to have to wait for it, can I just store the results of it?"
▶ "I need to expose this data to analysts, but they can’t see the actual usernames!"
▶ We will look at each of these scenarios in more depth to explain why Summary 
Indexing helps here.
Technique: Summary Indexing Essential Data Aggregation▶ Take a search, any search, and then index the result, all without license cost!
tag=authentication
| stats count as num_auths 
	dc(dest) as num_dests 
	values(dest) as dest_values 
	values(Account_Domain) as Domains 	values(EventCode) as EventCode 	by user, 
	Logon_Type, 
	action
| collect index=authentication_summaries
Start with whatever base search you want
Here we are using stats to pull a number ofaggregate metrics. The best part about Summary Indexing is that almost anything you put in front of the "by" clause is free from a performance 
perspective. More on this in a moment... 
	Here’s the high risk part - whatever we split by increases the number of records (and amount of disk 	space) exponentially. More on this in a moment…Now we just pull this data in via collect. What this 	actually does is write it to a special file in 	$SPLUNK_HOME/var/spool/splunk
Technique: Summary Indexing
Summary Indexing for Data Summarization
▶ The example just given with authentication data is a classic illustration of this technique. Suppose you want to analyze a few metrics around Windows Auth data to do behavioral searching on users logging into more searches than normal, but you have 4 TB of Windows Security logs per day, and that would be 120 TB with a 30 day baseline.▶ You can use summary indexing to record just the aggregate metrics every day. Suppose somewhat arbitrarily that even including the hostnames, each event was 1 KB. Even in a large org with 300k employees that would consume just 300 MB of disk space per day, and a 30 day baseline search would only have to search 9 GB of data, a reduction of 13,333x.▶ We see Summary Indexing being used extensively for scenarios you don’t require the full event fidelity. For example, if you’re indexing huge volumes of Stream, Flow or DNS logs, but sometimes all you need to know if "did these two hosts communicate with each other, and what day/hour" you can summarize the data dramatically.
Technique: Summary Indexing Summary Indexing for Stats on Stats▶
▶
▶
▶
▶ As described elsewhere in this presentation, stats on stats is an incredibly powerful technique! The use case we just covered is one example - we would first run stats to prepare our dataset, and then run stats again to actually detect outliers: 
| bucket _time span=1d | stats {metrics} by user, _time | stats {outlier} by userThere’s an innate performance challenge in that, though. Suppose a company with 30k users where you want to detect a change in the number of servers logged into per day, with a 3 month baseline. That would be 90k users * 5 days per week * 14 weeks. That would be 6.3 million rows to keep in memory!Splunk has an inherent limit in the amount of rows that can be kept in memory. Above that limit it takes partial result sets and writes them to disk. {This may not be 100% accurate for the internals, but it’s generally right:} So maybe you’d get 1M results in memory, and then it would gzip those, and write them to disk. Then it would pull the next 1M results, gzip those and write them to disk, etc. Once it has all the groups of results, it would then read sections of the data back in, decompress them, group them, compress them, and re-write them out to disk, until eventually it is complete.That means that a search for 1M row may complete in 4 minutes but a search for 2M rows could complete in 16 minutes. Because the limit here is in MB used, it’s not as clear as saying "keep it below 1M rows" but in my experience the slowdown occurs somewhere between 800k and 2M rows depending on what columns you have. Also notably, a 4 minute search taking 16 minutes once per day in the middle of the night isn’t actually a problem most of the time, so violating the theshold a little bit is fine. But a 3M row search could then take 30 minutes, 4M row 50 minutes, and eventually your pain becomes great.Why so much background discussion? Summary Indexing solves this problem in a lovely fashion. Run the daily aggregation search, where in any day you will only have 90k records (easy). Then when you run the behavioral search, you are looking at raw logs in your summary index and you again only have to track 90k rows. 
Without Summary Indexing
With Summary IndexingWith Summary Indexing
| ~1.6 Billion | 6.3 Million | 90 Thousand | ~23 Thousand | 90 Thousand | 6.3 Million | 90 Thousand |
|---|---|---|---|---|---|---|
| Raw Logs |Stats Rows |Stats Rows |Raw Logs Daily |Stats Rows Daily |Raw Logs |Stats Rows |
Technique: Summary Indexing
Making Slow Searches Fast
▶ One of my favorite use cases for both transaction (covered elsewhere in this presentation) and summary indexing is the idea of taking a *very* slowtransaction search and then outputting the relevant details into a summary index.
▶ For example, Ironport logs are a classic use case for transaction, and if you have a 50k employee organization then that search is going to be terribly slow over any long period of time, but the SOC will always want to understand email records.
▶ | transaction {whatever} | table _time {whatever other fields are relevant to 	understand} | collect index=our_email_logs▶ Then analysts can just run a quick search of index=our_email_logs to get individual pieces. You can still retain the raw data in your Ironport indexes for anything you didn’t capture in the summary index.
Technique: Summary Indexing
Summary Indexing for Anonymization
▶ This is generally only reluctantly recommended because of the performance and disk space 	limitations, but I did want to include it because we are talking about Summary Indexing.▶ If you have a data source that you want to expose to a group in your org, but who aren’t permitted 	to see all data (such as employee names), you can summary index your data into a new index.
▶ index=sensitive | rex mode=sed "s/employee=\"[^\"]*/employee=\"masked" | collect index=masked
▶ That said, be cautious of trying to do this at really high scale (e.g., limit can vary a lot based on 	your system, but maybe 150 GB/day?)Technique: Summary Indexing A Note on Cardinality
▶
▶
▶ A lot of mechanics in Splunk are dependent on cardinality, which is a measure of how much variability there is in fields. E.g., if you have 30k users and 50k endpoints, | stats … by user would have a maximum of 30k rows, but | stats … by user, dest could theoretically reach 1.5 billion. If you did | stats … by user, dest, EventCode you might end up in the tens of billions.This has two implications when it comes to summary indexing. One is why summary indexing helps when doing stats on stats (see a couple of slides ago). The other bigger is when you are choosing what you want to put in your summary index.My general recommendation is to put any numbers you might ever need before the by in your stats. For example, when analyzing authentication data, why not track the number of event codes, number of servers, number of logon types, number of Kerberos errors, etc. If I have 30k users and am tracking 7 different metrics, and add an 8th, I see an incremental increase in disk space used, but basically that’s it.If I have short field names (remember that we write those to disk, so you pay your storage vendor by the byte), it’s almost nothing. 
▶
▶ The flip side, is that I recommend not putting anything after the by clause unless you really need to. Adding "by EventCode" to the end of a Windows Authentication search will increase the number of rows (and amount of disk space by between 6 and 15x depending on how your windows logging is set up.I just ran a quick test looking at PAN logs for one hour. In the first example, I don’t include app at all. In the second, I include the list of apps. In the third, I split by app. 
| KB | # Rows | Search |
|---|---|---|
| 3,160 |17,584 |index=pan_logs | stats count dc(dest) as NumDests sum(bytes_*) as sum_bytes_* avg(bytes_*) as avg_bytes_* dc(dest_port) as numDestPorts by src_ip || 3,776  + 616 |17,584 |index=pan_logs | stats count dc(dest) as NumDests sum(bytes_*) as sum_bytes_* avg(bytes_*) as avg_bytes_* dc(dest_port) as numDestPorts values(app) as apps by src_ip |
| 11,700  + 8,540 |63.239 |index=pan_logs | stats count dc(dest) as NumDests sum(bytes_*) as sum_bytes_* avg(bytes_*) as avg_bytes_* dc(dest_port) as numDestPorts by src_ip app |
Technique: Summary IndexingTechnique: Summary Indexing
What about si commands?
▶ If you have heard of the si commands, my recommendation is that you don’t ever 	use the si commands. They’re comparably rigid and difficult to understand.
▶ If you want to pursue this more, I would recommend the Splunk data Science 	EDU class.
Technique: Summary Indexing
Multiple different summaries in a single index▶ One final concept here. The first time you create a summary index, you might put it in a dedicated index, or just use index=summary that ships by default with Splunk.
▶ When you have 25 different summaries, you will need some way to distinguish them. When you save a summary index via the WebUI, it will ask you if you want to define a marker, which is a kvpair that gets added into the raw event.▶ I personally prefer to control my destiny and use the | collect command rather than the WebUI (though probably I should switch to the WebUI). I implement a marker by adding a new field before the | collect.
▶ index=* | stats … | eval marker="BaselineAuthData" | collect index=xyz
▶ When defining a marker, you want a medium-long string so that we can use 	bloom filters and our indexing, but avoid punctuation.Technique: Summary Indexing
No Skipped Searches
▶ While we’re here - skipped searches are a common problem on heavily loaded Splunk environments. You want to avoid skipped searches as much as possible, but you can work around that by telling Splunk to use continuous scheduling.
▶ This setting is in savedsearches.conf, and is called realtime_schedule. (Note, because we want to make this as confusing as possible, a real-time schedule is not the real thing as a real-time search. I know, I know.)▶ Realtime_schedule defines what happens with a search job is skipped. Either:
• You skip that time range and move on (bad for summary indexing, and the default)
• You go wait until you can run for that time range, introducing lag.
▶ You want the latter (and also to minimize skipped searches by not overloading 	your Splunk environment).
Technique: Lookup Caching Background and Challenges▶ Splunk is a time oriented product, but sometimes we can build better detections 	with a non-time oriented state store
▶ "I only want to alert on this if a host has been online for at least a month"▶ "I only want to alert if this is the 5thtime this has happened in the past month"
▶ Splunk Security Essentials Use Case:
• Alert the first time something occurs for any host with a baseline of at least 7 days, and 	remember the last 90 days.• Do this without searching over 90 days every time.
	Technique: Lookup Caching
▶ You can input a lookup, then output a lookup, and then continue on your search. 
Run this search every day/hour, and take advantage of a 90 day baseline!
tag=authentication
| stats earliest(_time) as earliest latest(_time) as latest 
by user, dest
| inputlookup append=t login_tracker.csv| stats min(earliest) as earliest max(latest) as latest by user, dest
| where latest > relative_time(now(), "-90d") | outputlookup sample_cache_group.csv
| where earliest >= relative_time(now(), "-1d@d")
Start with whatever base search you want
Eventually summarize to a subset of fields that you 	will be analyzing. Because we want to control the 	size of the lookup, this should usually be a small 	number of fields. (More on this next)*Add* our existing cache with the append=t trigger
Now we can recompute our earliest and latest. The 	first time was just for our search duration (last 	day/hour/etc). Now it has the baseline data too.
Now this search is more up to date than our lookup. Update the lookup, and optionally filter out useless 	data to manage the overall lookup size.
Finally you can continue with your actual detectionTechnique: Lookup Caching
How big can your lookup be?
▶ Pretty big is the general answer. In my head, I try to keep these lookups less than 800 MB, but it can vary depending on how often you run the search itself (e.g., a search every 10 min should be smaller, because otherwise the search won’t complete in time.▶ The biggest limitation is around disk space and search completion time. If you have 10GB available, don’t create big lookups. If you have to read in 8M rows each time the search runs, you won’t be able to run it that often.
▶ Concrete example: first logon by server in a shop with 300k users.
• Each row: 2 x 10 byte timestamp, username avg 15 bytes, hostname avg 40 bytes = 75 bytes• Suppose each user connects to 40 core servers, with 10 random servers per week
• For each user, that would be 170 servers for a 3 month baseline.
• 170 servers * 300,000 users * 75 bytes = 3.5 GB - very big! Maybe just track interactive logins.
Technique: Lookup Caching
CSV Lookup or kvstore?
▶ I asked around a bunch when building this technique into Splunk Security 	Essentials, and basically the answer was "eh, neither is really better."▶ Reasons:
• Because we are writing out the entire list every time (| outputlookup uses append=f) we don’t 	get to take advantage of kvstore incremental update
• Because we aren’t sending to the indexers we don’t have to think about the kvstore replication 	method
• Because we are doing an | inputlookup append=t instead of | lookup we don’t take advantage of 	kvstore’s index capability▶ My recommendation: Use CSV lookups
• There is no benefit to kvstore, and we all know how to manage and deal with csvs. Just way 	easier.
Technique: Lookup Caching
Don’t Big Lookups Hurt Splunk?
▶ Biggest Risk to this technique: Lookups use up disk space, and by default will be sent to your indexers in search bundles. If you talk to any large Splunk admin, they will shout you out the door with the terrors of creating 800 MB lookups that break bundle replication.▶ Here’s the secret though - this technique doesn’t get any benefit from sending the lookup to the indexers. We aren’t filtering out raw results with it, we’re just using it for enrichment on the Search Head. Keep it out of the bundles via distsearch.conf. This should be common knowledge among advanced admins.
•	https://answers.splunk.com/answers/520843/regex-for-distributed-search-blacklist-not-working.html•	https://docs.splunk.com/Documentation/Splunk/6.6.2/DistSearch/Limittheknowledgebundlesize
▶ Now there’s one unknown still here: With SHC, we do still have to replicate those lookups. We don’t have concrete knowledge of where issues lie here, but feedback from our top architects suggest that those limits are way way higher than with normal bundle replication. If you have an 800 MB lookup, it’s probably prudent to not re-generate it every 10 minutes (maybe once per day makes sense? Again, maybe every 10 minutes would be fine though.. We really have no data). I’ve yet to hear about anything short of a >50 GB kvstore breaking SHC replication, which would suggest that we have high limitsTechnique: Lookup Caching Working Example
▶ This has been figured out in Splunk Security Essentials. 
| 
 |  | 1. | Download the app off Splunkbase | Download the app off Splunkbase | Download the app off Splunkbase |
|---|---|---|---|---|---|
|   | |2. |Open up a First Seen Detection (e.g., First Time Logon to New Server) |Open up a First Seen Detection (e.g., First Time Logon to New Server) |Open up a First Seen Detection (e.g., First Time Logon to New Server) ||   | |3. |Add a lookup in the "Lookup to Cache Results" |Add a lookup in the "Lookup to Cache Results" |Add a lookup in the "Lookup to Cache Results" |
|   | |4. |Read the description |Read the description |Read the description |
|   | |5. |Read the description |Read the description |Read the description |
|   | |5. |Hit the checkbox and OK |Hit the checkbox and OK |Hit the checkbox and OK ||   | |6. |Click "Show SPL" to see the SPL |Click "Show SPL" to see the SPL |Click "Show SPL" to see the SPL |
|   | | | | | |
Technique: Confidence Checking
Background and Challenges
▶ Many times when we look at building use cases, particularly statistical ones, we 
need to be able to measure the degree to which we have a baseline.
▶ "I built a first time seen behavioral use case, but it’s alerting on brand new 	people!"▶ "I built a time series analysis behavioral use case, but it’s alerting on someone 	with only 3 days of baseline!"
Technique: Confidence Checking First Time Seen Detections
▶ When we do a first time seen detection (see First Time Seen elsewhere in this 	presentation), we often want to build in confidence checking.
tag=authentication 
| eval day=strftime(_time, "%d/%m/%Y")| eval day=strftime(_time, "%d/%m/%Y") 
| eventstats dc(day) as days_of_baseline by user
| where days_of_baseline > 7
| stats earliest(_time) as earliest latest(_time) as latest by user