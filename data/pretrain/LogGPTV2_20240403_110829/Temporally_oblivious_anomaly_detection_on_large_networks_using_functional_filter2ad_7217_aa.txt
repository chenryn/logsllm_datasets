title:Temporally oblivious anomaly detection on large networks using functional
peers
author:Kevin M. Carter and
Richard Lippmann and
Stephen W. Boyer
Temporally Oblivious Anomaly Detection on Large
Networks Using Functional Peers∗
Kevin M. Carter, Richard P. Lippmann, and Stephen W. Boyer
PI:EMAIL, PI:EMAIL, PI:EMAIL
MIT Lincoln Laboratory
Lexington, MA USA
ABSTRACT
Previous methods of network anomaly detection have fo-
cused on deﬁning a temporal model of what is “normal,”
and ﬂagging the “abnormal” activity that does not ﬁt into
this pre-trained construct. When monitoring traﬃc to and
from IP addresses on a large network, this problem can be-
come computationally complex, and potentially intractable,
as a state model must be maintained for each address. In
this paper, we present a method of detecting anomalous net-
work activity without providing any historical context. By
exploiting the size of the network along with the minimal
overhead of NetFlow data, we are able to model groups of
hosts performing similar functions to discover anomalous be-
havior. As a collection, these anomalies can be further de-
scribed with a few high-level characterizations and we pro-
vide a means for creating and labeling these categories. We
demonstrate our method on a very large-scale network con-
sisting of 30 million unique addresses, focusing speciﬁcally
on traﬃc related to web servers.
Categories and Subject Descriptors
C.2.3 [Network Operations]: Network Monitoring
General Terms
Measurement, Security
Keywords
Anomaly detection, network security, machine learning
1.
INTRODUCTION
To complement signature-based intrusion detection sys-
tems (IDS) such as Snort [17] and Bro-IDS [16], there has
∗
This work is sponsored under Air Force Contract FA8721-
05-C-0002. Opinions, interpretations, conclusions and rec-
ommendations are those of the authors and are not neces-
sarily endorsed by the United States Government.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’10, November 1–3, 2010, Melbourne, Australia.
Copyright 2010 ACM 978-1-4503-0057-5/10/11 ...$10.00.
been much research in the area of anomaly-based systems
[22, 11], which do not match pre-deﬁned signatures, but
rather identify behavior which is rare compared to a data-
driven model. This approach provides the beneﬁt of being
able to detect zero-day attacks – or deviations of known at-
tacks without a signature – as long as they deviate from the
normal traﬃc patterns. Sommer and Paxson [20] provide a
detailed breakdown of several of the reasons why machine
learning based anomaly detection methods have failed to
reach wide adoption. We address two important weaknesses
and develop an anomaly detection method that scales to
large networks and provides context for decisions.
In this paper we present a method for anomaly detection
on very large-scale networks which is temporally oblivious,
e.g. we do not utilize any historic information about a host
to determine if it is anomalous. In complete isolation, it is
impossible to determine if a host is behaving in an anoma-
lous fashion during a given moment without the historical
context that is typically used for anomaly detection. How-
ever, in the presence of numerous functional peers – hosts
providing similar services – we can identify those hosts ex-
hibiting signiﬁcantly diﬀerent behaviors over a static snap-
shot in time. This intuition follows from the fact that many
functions and services have inherent properties which gov-
ern their behavior. In our approach, the model used to de-
tect anomalies consists of measurements over the group of
peers and automatically compensates for variations in traf-
ﬁc patterns over time. While abnormal by deﬁnition, the
anomalies detected can be further characterized by a small
set of descriptions, and we provide an automated method of
providing these qualitative assessments.
The contributions of this paper to network anomaly de-
tection are as follows:
• Temporal modeling is not required, instead we use on-
the-ﬂy data driven statistics from other active network
hosts performing similar functions.
• Computation is low because only NetFlow [1] features
are used and instead of building one reference model
per host, only one reference model is required for each
general function. This supports scaling to very-large
networks.
• After training, anomalies are automatically categorized
by a small set of descriptive characterizations, requir-
ing minimal additional computation in a live environ-
ment.
465Table 1: Anomaly Detection Features
Incoming
Outgoing Ratio (Outgoing/Incoming)
Bytes / Packet (B/P)
Packets / Flow (P/F)
B / P
P / F
Flows / Unique External Source IP (F/SIP)
F / DIP
Bytes
Packets
Flows
# Unique External Source IP (SIP)
DIP
IP addresses
1.1 Previous Work
Some recently presented methods of network anomaly de-
tection focus on detecting volume anomalies which show a
sharp change (typically an increase) in the traﬃc volumes
received by a network or host [2, 21, 22]. This approach
may miss important traﬃc variations because the volume
increases to an individual host are often masked by varia-
tions in normal network traﬃc [11]. There has been work
to detect speciﬁc types of malicious volume activity such as
port scanning [18], worm and botnet propagation [6, 8], and
denial of service attacks [4, 23, 14]. These techniques use
properties of machine learning, along with high-level net-
work information (such as NetFlow records) to detect these
very speciﬁc activities. Additional work has been done to
classify internet traﬃc into speciﬁed applications [13]. While
payload-oblivious techniques have their natural limitations
[7], they scale to large networks. Statistical entropy has been
used to detect a more general class of anomalies [10, 11, 12,
15], measuring the change in the distribution of network
traﬃc. These methods have been shown to be very success-
ful at identifying when an anomaly occurs on the network,
but they require additional post-processing to identify the
responsible parties, which has seen additional work [3].
2. DETECTING ANOMALOUS HOSTS
We deﬁne an anomalous host as one which exhibits be-
havior that is signiﬁcantly dissimilar to other hosts on the
monitored network performing similar function(s) during an
observation window; stressing speciﬁcally that anomalous is
not necessarily malicious. While network traﬃc is known to
be highly variable over short periods for individual hosts, on
large networks there are frequently many hosts performing
similar functions. This makes it possible to detect anoma-
lies among these functional peers by using the collection of
hosts as a reference to detect the few which deviate from
this behavior.
2.1 Data and Features
Given our goal for detection on large-scale networks, we
utilize unsampled NetFlow data as full packet capture is
often unfeasible. From the data, we extract a 12-dimensional
feature vector x from each host on the monitored network
during a T second observation window. These aggregated
ﬂow features are listed in Table 1, where SIP and DIP refer
to the number of external unique source and destination
IP addresses respectively, and the ratio of IP addresses is
computed as DIP/SIP.
With the exception of the number of unique IP addresses
communicating with the host, each feature is invariant to the
scale of the network or service utilization. This was chosen
speciﬁcally so that hosts with similar utilization patterns are
observed as such, regardless of the number of external hosts
accessing the service. However, it is still necessary to include
the number of unique IP addresses connecting to the host
in order to give some context to the access patterns.
2.2 Identifying Outliers
Measuring Dissimilarity
Given the collection of feature vectors for the N IP addresses
on the network X = [x1, x2, . . . , xN ], we identify anoma-
lies by ﬁrst deﬁning a dissimilarity measure for each pair
of hosts. As each measured feature from Table 1 covers a
diﬀerent range, we normalize each feature to the same rel-
ative scale. We choose to normalize each feature such that
there is unit distance between the 10th and 90th percentiles
of that feature. Speciﬁcally, let fp(y) be deﬁned such that it
returns the pth percentile of the data in vector y. For exam-
ple, f50(y) would be equal to the median of y. We normalize
each feature i in X such that
X(i) = X(i)/(f90(X(i)) − f10(X(i))),
where X(i) = [x1(i), . . . , xN (i)]. This normalization ensures
that 80% of the mass of data will lie in the same range for
the various features, but the outliers will still stand out as we
are linearly scaling the data. Once normalized, we calculate
pairwise distances between hosts with a standard Euclidean
(L2) distance D(xi, xj) =(cid:2) xi − xj (cid:2)2.
Hierarchical Clustering
After calculating the pairwise dissimilarities between hosts,
we employ hierarchical clustering [9] to identify outliers.
Clustering is performed by ﬁrst assigning each host to its
own cluster or node. The two nodes with the smallest link-
age cost between them are merged to form a new node, and
the process is repeated until all hosts belong to the same
node. For this task we use single-linkage clustering, which
deﬁnes the cost of merging nodes A and B as min{D(a, b) :
a ∈ A, b ∈ B}; the minimum distance between any two hosts
in the nodes. This is a logical linkage criterion for anomaly
detection as we aim to ﬁnd those samples which are most
dissimilar from others. This method results in a hierarchical
cluster tree in which the top of the tree is a single cluster
containing all hosts, and the bottom of the tree contains a
unique cluster for each host.
Intuition suggests that in the presence of outliers, the ﬁnal
nodes to merge would contain the potential outliers, as the
linkage cost will be among the largest of any nodes in the
set. We develop a stopping criterion intentionally designed
to identify these outliers. Note that the linkage cost L(i)
is strictly non-decreasing over iterations i; we stop merg-
ing clusters at the point where L(i) > αL(i − 1), α > 1.
For a large enough value of α, this stopping criterion will
identify the ﬁrst signiﬁcant jump in the linkage cost. When
the cost of merging two nodes is a signiﬁcant gain over the
previous merge, any remaining clusters are distinctly diﬀer-
ent and any sample belonging to a cluster with less than n
466members is ﬂagged as an outlier. The threshold n may be
deﬁned either as a constant value, or some function of the
set size N . By our deﬁnition of anomaly, if there is a clus-
ter of activity with ≥ n members, those hosts will not be
ﬂagged because there is a large enough contingent of hosts
exhibiting similar behaviors. Hence, certain activities which
are not historically normal to the monitored network may
go undetected. This does not mean the activity is not ma-
licious or temporally anomalous, it is simply not anomalous
for the monitored network during this window T .
2.3 A Network Illustration
We tested our anomaly detection method on seven contin-
uous days of traﬃc on a monitored network consisting of 30
million hosts. Our data comes from gateway border routers
that observe all traﬃc entering and leaving the network and
transmit all ﬂow records to a central repository. We use the
SiLK system to query this database and compute aggregate
statistics [5]. This centralized system alleviates concerns of
asymmetric routing, as we are guaranteed to see both sides
of the ﬂow.
As a proof-of-concept, we limit our analysis to incoming
traﬃc with destination port 80 and outgoing traﬃc with
source port 80. This corresponds primarily, although not
exclusively, to those IP addresses hosting web services. Note
that we do not make a distinction between TCP and UDP
for this analysis. On this monitored network, there are
roughly 750 hosts receiving applicable traﬃc at any given