title:Moving Beyond Set-It-And-Forget-It Privacy Settings on Social Media
author:Mainack Mondal and
G&quot;unce Su Yilmaz and
Noah Hirsch and
Mohammad Taha Khan and
Michael Tang and
Christopher Tran and
Chris Kanich and
Blase Ur and
Elena Zheleva
Moving Beyond Set-It-And-Forget-It
Privacy Settings on Social Media
Mainack Mondal
IIT Kharagpur / University of Chicago
PI:EMAIL
Mohammad Taha Khan
University of Illinois at Chicago
PI:EMAIL
Chris Kanich
University of Illinois at Chicago
PI:EMAIL
Günce Su Yılmaz
University of Chicago
PI:EMAIL
Michael Tang
University of Chicago
PI:EMAIL
Blase Ur
University of Chicago
PI:EMAIL
Noah Hirsch
University of Chicago
PI:EMAIL
Christopher Tran
University of Illinois at Chicago
PI:EMAIL
Elena Zheleva
University of Illinois at Chicago
PI:EMAIL
ABSTRACT
When users post on social media, they protect their privacy by
choosing an access control setting that is rarely revisited. Changes
in users’ lives and relationships, as well as social media platforms
themselves, can cause mismatches between a post’s active privacy
setting and the desired setting. The importance of managing this
setting combined with the high volume of potential friend-post
pairs needing evaluation necessitate a semi-automated approach.
We attack this problem through a combination of a user study
and the development of automated inference of potentially mis-
matched privacy settings. A total of 78 Facebook users reevaluated
the privacy settings for five of their Facebook posts, also indicating
whether a selection of friends should be able to access each post.
They also explained their decision. With this user data, we designed
a classifier to identify posts with currently incorrect sharing set-
tings. This classifier shows a 317% improvement over a baseline
classifier based on friend interaction. We also find that many of
the most useful features can be collected without user intervention,
and we identify directions for improving the classifier’s accuracy.
CCS CONCEPTS
• Security and privacy → Usability in security and privacy.
KEYWORDS
privacy settings, access control, retrospective privacy, predictor
ACM Reference Format:
Mainack Mondal, Günce Su Yılmaz, Noah Hirsch, Mohammad Taha Khan,
Michael Tang, Christopher Tran, Chris Kanich, Blase Ur, and Elena Zheleva.
2019. Moving Beyond Set-It-And-Forget-It Privacy Settings on Social Media.
In 2019 ACM SIGSAC Conference on Computer and Communications Security
(CCS ’19), November 11–15, 2019, London, United Kingdom. ACM, New York,
NY, USA, 18 pages. https://doi.org/10.1145/3319535.3354202
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
CCS ’19, November 11–15, 2019, London, United Kingdom
© 2019 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-6747-9/19/11.
https://doi.org/10.1145/3319535.3354202
1 INTRODUCTION
For users to select a proper access control setting when sharing data,
they must consider the intended audience, their personal preference,
and the broader context. In many cases, this decision is “set it, and
forget it.” That is, the access control decision made when initially
sharing the data persists until it is changed, even if a user would
no longer choose that same setting. For instance, a Facebook post
made in 2006 when a user was a college student with 100 Facebook
friends may have very different implications in 2019 when the user
is a parent in the workforce with 2,000 Facebook friends. Whether a
privacy setting chosen in 2006 still applies in 2019 could depend on
an innumerable collection of potential features, which points to a
significant cognitive burden for users. This burden is compounded
by the sheer volume of posts accumulated over time, all in need
of privacy setting reevaluation. As a result, manual retrospective
privacy management is nigh impossible for users.
While a manual approach is completely untenable, many of the
potentially predictive features that could help automate this process
are personal enough that the only way to understand them is to
ask the user. As a result, the explosion of potential features calls for
an iterative, breadth-first approach. The features used within such
an automation tool should be derived from deep user interaction.
The questions asked during these interactions should be driven by
hypotheses about potentially effective inference. They should be
consistent with the combined goal of minimizing incorrect privacy
settings, not interrupting users, and minimizing data collection.
To understand risks posed by shifting privacy preferences and
to identify features that could be used to identify potentially incor-
rect settings, we conducted a study of 78 Facebook users. With the
participant’s informed consent, we automatically analyzed their
full timeline and activity log. We then asked participants to reeval-
uate five posts’ privacy settings and indicate whether six chosen
Facebook friends should be able to access each post. While prior
studies have used the Facebook API in concert with user surveys to
evaluate Facebook privacy settings [4, 6, 23, 33], to our knowledge
we are the first to evaluate these privacy settings contextualized in
an account’s full history, including changes in friends over time.
Our participants were active Facebook users, and 71% of them
had accounts that were at least a decade old, providing a rare look
CCS ’19, November 11–15, 2019, London, United Kingdom
Mondal et al.
into the longitudinal evolution of Facebook privacy settings. In
contrast with prior longitudinal work on Facebook privacy [47,
73], we found that participants’ most common privacy setting was
“Friends only.” We also note that the median participant had four
times as many friends in 2018 as they did in 2009. The meaning
of the “Friends only” setting, and thus the visibility of such posts,
has changed substantially over time. Participants expected their
Facebook friends to sometimes look at their old posts, emphasizing
the importance of updating privacy settings even for old content.
While 45% of participants reported having used Facebook’s “pri-
vacy checkup,” current retrospective mechanisms proved insuf-
ficient. A number of the privacy settings active on participants’
Facebook accounts did not reflect their current intentions. Overall,
65.3% of participants reported wanting to change the privacy setting
of at least one of the five posts we presented to them. This repre-
sented 25.5% of posts participants saw, with rough parity between
increasing and decreasing visibility.
Using insights from the user study regarding how users con-
ceptualize and decide to modify their privacy settings, we built
models to predict which posts from the history of a user’s Face-
book account are most likely to have active privacy settings that
no longer match the user’s intent, as well as which posts perhaps
should not be shared with specific Facebook friends. Due to the
sensitive and subjective nature of managing privacy settings, we
optimized our prediction algorithm design for deployment as part
of a human-in-the-loop model that augments, rather than replaces,
human decision-making processes. In this setting, posts with pri-
vacy settings that may diverge from the intended one are flagged
for the user, similar to Facebook’s “people you may know” interface.
Our predictive model achieved a 317% improvement in accuracy
(precision-recall AUC) when compared to simple prediction rules
such as limiting sharing for friends with low levels of interaction.
The predictive power of a variety of features (including user fea-
tures, post statistics, the post’s content, and characteristics of the
audience) show that the friend context really matters in predict-
ing the correct privacy setting. Crucially, we found that the most
predictive features can be collected without human interaction.
Surprisingly, observable friendship dynamics like the frequency
of interaction on Facebook or length of friendship alone are insuffi-
cient as predictors. The former was weakly correlated with privacy
preferences, and the latter was not significantly correlated with
privacy preferences at all. Participants often wanted to share with
Facebook friends with whom they never visibly interacted, some of
whom were close friends or family members in the offline world.
While a few prior studies found that users need to retrospectively
revisit Facebook privacy settings [4, 6], we take a holistic, user-
centric approach to unpack this problem within the context of a
user’s entire Facebook history, including the dynamics of changing
sets of Facebook friends. We also take the first concrete steps toward
building human-in-the-loop interfaces that use predictive models
to identify posts whose privacy settings the user ought to revisit.
2 FACEBOOK PRIVACY SETTINGS
Facebook users control access to their posts by choosing privacy set-
tings with the Audience Selector [22]. While the particular settings
Facebook provides have changed substantially over the years, they
have encompassed granting or denying access to both individual
users and to roles (e.g., the user’s Facebook friends, user-specified
groups of friends, users tagged in a post). Just as in traditional role-
based access control (RBAC), roles like ‘friends’ or ‘users tagged
in this post’ describe sets that shift over time. Previously, permis-
sions could be granted to a user’s networks (e.g., University X). This
option has since been removed. We focus on the following five
settings that specify to whom Facebook content is accessible:
• public (previously “everyone”): anyone on the web [20]
• friends+: the user’s Facebook friends plus the friends of
some/all of those friends (e.g., friends of friends, friends plus
anyone tagged) [19, 40]
• friends: the user’s Facebook friends [40]
• custom: a user-specified subset of Facebook friends [19]
• only me: only the user [19]
In addition to changing the available options over time, Facebook
has also varied the default, complicating longitudinal privacy man-
agement. In 2008, the default was friends plus networks [40]. The
default was changed to public in 2010 [54] and friends in 2014 [50].
3 PROPOSED IMPLEMENTATION
This paper reports on a user study designed to build a longitudinal
understanding of Facebook privacy attitudes and practices, as well
as an investigation of how preferences correlate with various prop-
erties of posts, users, and settings. The ultimate goal of building this
increased understanding of privacy settings over time is to build a
human-in-the-loop retrospective privacy management system. In
such a model, suggested privacy setting modifications would be
presented to users through an interface that closely mirrors the
“people you may know” feature on many social media sites.
With such an interface in mind, the objective we wish to maxi-
mize in this work is not pure accuracy, but rather a balance between
accuracy and the importance of the suggested change. Regardless of
the accuracy of such a prediction service, users must retain agency
over important decisions like adding friends or revoking access to
shared posts. An important implication is that while false negatives
are certainly unwanted, the cost of such an incorrect suggestion is
less catastrophic than in other security and privacy contexts, such as
intrusion or spam detection. Furthermore, as this is a maintenance
task, this suggestion interface can complement direct management
tools like Facebook’s “privacy checkup.”
4 RELATED WORK
Broadly, privacy settings on social media can be considered a form
of RBAC, which allows policies that specify permissions based on
a user’s role (e.g., “manager” or “contractor”) [64, 67]. Access con-
trol policies can be complex, as documented in studies of system
administrators [7, 8]. A rich literature has proposed many tech-
niques for helping users accurately specify and audit access control
policies. These techniques include matrix-style visualizations [62],
rich queries of the authorization server [84], decision-support sys-
tems [11, 14], and human-in-the-loop iterative refinement of poli-
cies [36]. Researchers have also proposed alternate ways of ex-
pressing access control policies based on context [41], just-in-time
requests [51], and semantic tags [38, 52].
Moving Beyond Set-It-And-Forget-It Privacy Settings on Social Media
CCS ’19, November 11–15, 2019, London, United Kingdom
Mismanagement of Facebook privacy settings can be caused by
user misunderstandings [1, 15, 49], mismatches between the actual
and expected dissemination of content [9, 12, 45], and overly com-
plex user interfaces [33]. In 2011, Liu et al. surveyed 200 Facebook
users, finding that 63% of posts were exposed to a larger audience
than desired [47]. While users sometimes choose not to share con-
tent proactively [68] or delete content [2, 58], the mismanagement
of privacy settings can cause embarrassment and regret [69, 76].
4.1 Longitudinal Privacy on Facebook
Use of a social media platform changes considerably over time.
Backstrom et al. noted a significant turnover in a user’s set of close
Facebook friends [5], causing a “time collapse” in which temporal
context is lost [13]. Privacy behaviors also change. Stutzman et al.
found increased non-public content in Facebook profile attributes
(e.g, date of birth) over time [73]. Users themselves also change [4].
We observe that, because of friend addition or deletion, the num-
ber of people included in these settings also implicitly changes over
time. In RBAC parlance, the friend role is granted to, or revoked
from, different users at different times. This change is automatic. A
post made in 2009 and shared with friends might be visible to 150
users when created, but friend additions may cause it to be shared
with 1,500 users in 2019 without changing the privacy setting.
These longitudinal changes in platforms, combined with users’
life and relationship changes, necessitate retrospective management
of privacy settings [59]. Prior work found that although access con-
trol settings in corporate environments rarely need to change [70],
access control settings chosen long ago are frequently inaccurate
moving forward in both social media [3, 4, 6] and cloud storage [37].
Two closely related studies have documented the need to revisit
privacy settings for past posts. Through user studies leveraging the
Facebook API, both Ayalon and Toch [4] and Bauer et al. [6] showed
participants past posts. In the former study, participants answered
questions about their likelihood to edit or hide the post. In the latter
study, participants answered questions about their desired future
audience for the post. These studies found that life events and the
passage of time are weakly correlated with desired changes in a
post’s audience. The first part of our study partially revisits this
work. However, we collect a far larger and richer set of features.
We also explicitly show participants a given post’s current privacy
setting during the study and ask whether they would actually want
to change it. We also use the full history of interactions between
a user and each of their Facebook friends to further understand
the longitudinal evolution of privacy settings. In contrast to the
previous work, our work also aims to build predictive models for
identifying posts with currently inaccurate privacy settings.
Facebook and similar platforms provide few options for retro-
spectively reevaluating privacy settings. In 2011 Facebook intro-
duced a “limit past posts” feature that changes all posts shared more
widely than with only the user’s Facebook friends to the friends-
only setting [31]. The “privacy checkup” feature, introduced in
2014 [50], lets users examine and change their default privacy set-
ting. While these tools can be effective, they unilaterally update
sharing settings for large sets of posts or friends. We instead focus
on finding specific posts whose privacy settings are likely to be
inaccurate. Revisiting old posts is also facilitated by Facebook’s “on
this day” feature, which highlights posts from a given date in earlier
years [34]. However, it neither provides a global view of aging posts
nor offers assistance on retrospectively managing privacy.
4.2 Helping Users Choose Privacy Settings
Researchers have proposed a number of strategies to help users
choose privacy settings. These techniques include audience-centric
views of a post [44] and the ability to assign Facebook friends to
custom groups (e.g., “band people”) [35]. Variants of both have since
been adopted by Facebook. Researchers have also suggested new
visualizations of privacy settings [16, 53] and automated “nudges”