capability, as there are many different attack vectors given
this capability. As a hardware-based solution, we also do not
limit where the vulnerabilities are: they can be in user-mode
applications, OS kernel, hypervisor, etc. However, we assume
all hardware components are trusted and bug free, so attacks
that exploit hardware vulnerabilities, such as the row hammer
attack [42], are out-of-scope.
Similar to NX-bit, HDFI requires software modiﬁcations
to obtain its beneﬁts. This can be done in many ways:
manual modiﬁcation, compiler-based modiﬁcation, static binary
rewriting, dynamic binary rewriting, etc. For the example
applications we demonstrated in this paper, we either manually
modiﬁed the source or leveraged compiler-based approaches.
However, we must emphasize that this is not a limitation of
HDFI and source code is not always necessary.
III. BACKGROUND AND RELATED WORK
This section provides the background of HDFI and compares
HDFI with related work.
A. Data-ﬂow Integrity
The goal of HDFI is to prevent attackers from exploiting
memory corruption vulnerabilities to tamper/leak sensitive data.
To achieve this goal, we leverage data-ﬂow integrity (DFI) [10].
DFI ensures that the runtime data-ﬂow cannot deviate from the
data-ﬂow graph generated from static analysis. In particular,
DFI assigns an identiﬁer to each write instruction and records
the ID of the last instruction that writes to a memory position;
then at each read instruction, DFI checks whether the ID of
the last writer belongs to the set allowed by static analysis.
Take Example 1. This code snippet contains a buffer overﬂow
vulnerability at line 6, which allows attackers to use strcpy()
to overwrite the return address saved at line 3 and launch
control-ﬂow hijacking attacks. Such attacks can be prevented
by checking if the return address read at line 8 is deﬁned by
the store instruction at line 3.
; argv[1]
; char buff[16]
; strcpy(buff, argv[1])
; return
sp,sp,-32
ra,24(sp)
a1,8(a1)
a0,sp
strcpy
a0,0
ra,24(sp)
sp,sp,32
ra
1 main:
add
2
(cid:2)sdset1
3
ld
4
mv
5
call
6
li
7
(cid:2)ldchk1
8
add
9
jr
10
Example 1: A typical stack buffer overﬂow example, in RISC-V
assembly, in which HDFI prevented by replacing load and store
instructions with two new load and store instructions (line 3 and
8). strcpy() at line 6 can overﬂow the return address saved at line 3,
and HDFI can accordingly detect the overﬂow when it is loaded back
at line 8.
In HDFI, we extend the ISA to perform DFI-style checks
with hardware. Speciﬁcally, we leverage memory tagging to
record the last writer of a memory word and provide new
instructions to set and check the tag. However, instead of
trying to fully replicate DFI, which would require supporting
arbitrary tag size, we focus on providing isolation, i.e., using a
one-bit tag to indicate the trustworthiness of the writer. Using
the same example, HDFI can be utilized to prevent the attack
by (1) using a new instruction sdset1 (store and set tag) to
set the tag of memory used to store return address to 1 (line
3); and (2) when loading the return address from memory for
function return, using another instruction ldchk1 (load and
check tag) to check if the memory tag is still 1. Since normal
store instructions (e.g., sd) would set the tag to 0, if attackers
try to overwrite the return address, the ldchk1 instruction would
fail and generate a memory exception.
B. Tag-based Memory Protection
Tag-based memory protection is not new and has been
explored in many previous works. For example, lowRISC [8]
uses a 2-bit tag to specify if a memory address is readable and
writable. Loki [84] also allows developers to specify permission
with a memory address, but is more ﬂexible, as the permission is
related to the current protection domain. The problem with these
approaches (including the Mondriaan protection model [79]) is
that, although the objects (memory addresses) are ﬁne-grained,
the subjects are still coarse-grained—the access permissions are
applied to the whole program or the whole protection domain.
However, the subjects are individual instructions in HDFI.
An alternative approach is to associate the access permission
with pointers instead of memory locations. For example,
Watchdog [51] and the application data integrity (ADI) [57]
mechanism on SPARC M7 processors allow a program to
associate memory addresses and pointers with versions (tags)
and require that when accessing the memory the version of
the pointer must match the version of the memory. The tricky
33
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:12:03 UTC from IEEE Xplore.  Restrictions apply. 
part of this approach is how to maintain the tag of a pointer,
because every pointer should have two tags: one indicating the
tag of the target memory, and the other indicating the tag of
the memory where the pointer is stored. Without this, attackers
can still tamper with the pointers. Watchdog handles this by
using shadow memory to maintain the ﬁrst type of tags, but it
is unclear whether or how ADI handles this issue.
Write integrity test [2] is another tag-based memory safety
enforcement mechanism. It enforces that each write operation
(instead of pointer) can only write to objects that are allowed
by the static data-ﬂow graph. However, since the integrity test
is only enforced on write operations, WIT can only enforce
data integrity, but not data conﬁdentiality.
they must
A common issue with all the aforementioned approaches
is that
track the liveness of memory objects,
which makes the protection more complicated. For instance,
in Example 1, to protect the return address, all aforementioned
systems must tag the memory used for return address at
prologue. Here we must pay special attention to the order
of tagging and store: if store happens before tagging, the
system would be vulnerable to time-of-check-to-time-of-use
(TOCTTOU) attack, because the address might be modiﬁed
unless the two operations are guaranteed to be atomic. Then,
after the function ﬁnishes execution and returns, the current
stack frame is freed, so the old memory position used to store
the return address must be unprotected for future re-use. Here is
another tricky part—if the capability system is location-based,
or does not assign a new version for every memory allocation
(which is very challenging for ﬁxed tag size), then it would
be subject to use-after-free (UAF) based attacks. Moreover,
for software that heavily utilizes custom memory allocators,
such as browsers and OS kernels, tracking object allocation is
non-trivial. Fortunately, HDFI does not need to track liveness
of memory objects.
Among existing hardware features, Minos
[18] and
CHERI [77] are the closest to HDFI. Speciﬁcally, Minos uses
one-bit tags to indicate the integrity of code pointers and
updates the tag based on the Biba model [6]. CHERI [77] also
uses one-bit tags to indicate whether a memory address stores a
valid capability (fat pointer). This bit can only be set when the
memory content is written by a capability-related instructions
and is cleared when written by normal store instructions.
Comparing to them, the advantage of HDFI is ﬂexibility—
as will be shown in §V, besides pointers, HDFI can also be
used to protect generic data like uid; and along with the Biba
model, HDFI can also be used to enforce the Bell–LaPadula
model [5].
C. Tag-based Hardware
Because memory tagging is widely used for dynamic
information ﬂow tracking (DIFT), which can be very expensive
when purely done in software [56]. For this reason, numerous
hardware solutions have been proposed, including pure DIFT-
oriented [18, 20, 40, 69], and more general, programmable
metadata processing [13, 25, 28, 75]. The most signiﬁcant
difference of HDFI from these solutions is our emphasis on
minimizing hardware changes so as to make HDFI more likely
to be adopted in practice. In particular, HDFI does not require
modifying register ﬁles, ALU, main memory, or the bandwidth
between cache and main memory. More importantly, instead of
requiring half of all physical memory dedicated to store tags
(i.e., an overhead of 100%), HDFI only impose 1.56% memory
overhead.
D. Memory Safety
Since memory safety issues are the root cause of many
attacks [70], researchers have proposed many solutions to
address this problem, including automated code transforma-
tion [55], instrumentation-based [2, 10, 53, 54], and hardware-
based [27, 36, 51, 52, 77]. The biggest hurdle for adopting these
solutions is their performance overhead—even with hardware
assistance, the average overhead is still 29% on benchmark
workloads [52]. To help further reduce the overhead, HDFI
is designed to enable another optimization direction—using
isolation to limit the protection scope and only enforcing mem-
ory safety over the isolated data. Such data could be security
sensitive, e.g., code pointers [43], generic pointers [17, 77], or
important kernel data [66]. It could also be data that can be
statically proved to be memory safe, e.g., safe stack [43]. We
believe such a combination would allow us to build powerful
yet efﬁcient solutions to eliminate all memory corruption based
attacks.
IV. HDFI ARCHITECTURE
In this section, we present the design of HDFI, which includes
two major components: the ISA extension and the memory
tagger. Our current design tags memory at machine-word
granularity because most sensitive data we want to protect
are of this size (e.g., pointers). For data not of this size,
we can manually extend the size, or leverage compilers. To
prevent attackers from creating inconsistent views of data and
its corresponding tag and launching TOCTTOU attacks in a
multi-core/-processor system, we require all HDFI instructions
to be atomic (i.e., data and tag must always be loaded and stored
together) and comply with the same cache consistency model
as other memory accessing instructions. To avoid changing
the main memory system and the data link between main
memory and the processor, our current design stores all the
tag information at a dedicated area called tag table. In our
current design, tag table is allocated and initialized by the
OS kernel during boot, similar to how Intel SGX reserves
the secure pages (i.e., EPC pages) for enclaves [36]. Once
allocated, the memory region for the tag table will be protected
from malicious modiﬁcation (§IV-D).
A. ISA Extension
To enforce DFI, the authors added two high-level instructions:
SETDEF and CHECKDEF [10]. Since HDFI only supports one-bit
tags, in order to allow programs to use DFI-style checks to
enforce the integrity/conﬁdentiality level of memory contents,
we introduce three new instructions:
• sdset1 rs,imm(rb): store word and set tag to 1.
44
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:12:03 UTC from IEEE Xplore.  Restrictions apply. 
• ldchk0 rd,imm(rb): load word and check if tag equals 0.
• ldchk1 rd,imm(rb): load word and check if tag equals 1.
Note that we do not have an instruction that explicitly
sets the tag to 0. Instead, HDFI implicitly sets the tag of
the destination memory to 0 when written by regular store
instructions. However, HDFI preserves the semantics of regular
load instructions, i.e., tag is not checked on regular load
operations. To check the tag bit of the target memory region,
HDFI provides ldchk0 and ldchk1. To enable the OS kernel
to capture tag mismatch, we also introduced a new memory
exception, which is similar to other memory faults except for
the error code.
HDFI also provides a special instruction alias mvwtag 1 for
copying the memory from a source to a destination along with
the corresponding tag bits. This special operation is necessary
to achieve optimal performance in modern system software.
Speciﬁcally, modern OS kernels like Linux use copy-on-write
(CoW) to share memory between the parent process and its
child processes. However, if we use normal sd operations to
perform the copy, it could break HDFI-protected applications
because the tag information is lost; on the other hand, we
also cannot use sdset1 because it allows attackers to abuse
this feature to tag arbitrary data. To solve this problem, we
introduced the mvwtag instruction to allow OS kernels to copy
data while preserving the tag. Please also note that because
memcpy can cause memory corruption, we do not recommend
using mvwtag to implement memcpy unless the developer can
guarantee memory safety for all the invocations of memcpy.
B. Memory Tagger
Our hardware extension is similar to lowRISC [8]. Speciﬁ-
cally, to simplify the implementation of the new instructions
and support atomicity in a multi-core/-processor system, we
modiﬁed the interface between the processor core and the cache
system (including the coherence interconnect) to associate each
data with its tag. In particular, when the processor core executes
a memory related instruction such as sd, sdset1 or ld, it sends
a request to the data cache(s). This request includes a data
ﬁeld and a command ﬁeld. HDFI adds one tag bit to the data
ﬁeld, so for every memory write request, data is always stored
with the tag; and for memory load requests, tags can be (not
always, see §IV-C for detail) loaded with data.
To facilitate this, we augmented the caches to hold the tags
for the cached memory units, as shown in Figure 1. To hold the
tag bits for the cached memory units, the caches have a one-bit
register for each machine word to store the corresponding tag.
When the processor core sends a store request, the L1 cache
can simply update the data and tag value with the incoming
value from the core; and when the core sends a read request,
the L1 data cache provides the core with the tag bit, with
which the core can check whether the tag matches expected
value or not.
1Since we do not extend general register ﬁles with tag, this operation is an
alias for two instructions: load data and tag from source into a special register
then store them to the destination.
Req/resp
Tilelink
Tilelink
Core
Core
L1 Cache
L1 Cache
L2 Cache
DFITagger
Interconnect
Physical memory
L1 Cache
tag
tag
tag
tag
cacheline
cacheline
cacheline
cacheline
...
Physical 
memory
Tag Table
Additional 
HW resources
New HW
component
Fig. 1: Design of HDFI. The processor core and caches are augmented
and the DFITAGGER is added.
While the L2 cache can also be augmented similarly to hold
the tags for each memory unit, we believe it is not feasible to
add the tag bits physically to the external main memory. For
this reason, we added an additional module DFITAGGER in
between the L2 cache and the main memory, which decomposes
memory accesses from the L2 cache to separate data accesses
and tag accesses. Data accesses are handled as usual and tag
accesses are handled as follows. HDFI preserves a memory
chunk to be used as tag table (Figure 1), which acts as a huge
bit vector to store tag bits. When the L2 cache issues a memory
access, DFITAGGER maps the physical address to a table entry
of the tag table and generates a tag access.
C. Optimizations
Unfortunately, the additional memory accesses to the tag
table introduce non-negligible performance overhead. More
speciﬁcally, without any optimization, HDFI will double the
memory accesses because for every cache miss, DFITAGGER
needs to issue one data access and another tag access. To
minimize this impact, we developed several optimization
techniques.
1) Tag Cache: The most straightforward way of reducing
the overhead is caching, so we introduced a tag cache within
the DFITAGGER to exploit the locality of memory accesses.
Moreover, tag cache also allows DFITAGGER to fetch a set
of tags from the main memory in the cache line granularity