[56] Tinghuai Ma, Jinjuan Zhou, Meili Tang, Yuan Tian, Abdullah Al-Dhelaan, Mz-
nah Al-Rodhaan, and Sungyoung Lee. 2015. Social network and tag sources
based augmenting collaborative recommender system. IEICE Transactions on
Information and Systems 98, 4 (2015), 902–910.
[57] Bamshad Mobasher, Robin Burke, Runa Bhaumik, and Jeff J Sandvig. 2007. Attacks
and remedies in collaborative recommendation. IEEE Intelligent Systems 22, 3
(2007), 56–63.
[58] Bamshad Mobasher, Robin Burke, Runa Bhaumik, and Chad Williams. 2005.
Effective attack models for shilling item-based collaborative filtering systems. In
Proceedings of the WebKDD Workshop. 13–23.
[59] Movielens. 2019. Movielens. https://movielens.org/.
[60] Movielens. 2019. Movielens datasets. https://grouplens.org/datasets/movielens/.
[61] MovieLens. 2021. robots.txt. https://movielens.org/robots.txt.
[62] Netflix.com. 2019. Netflix. https://www.kaggle.com/netflix-inc/netflix-prize-
data/.
[63] Michael O’Mahony, Neil Hurley, Nicholas Kushmerick, and Guénolé Silvestre.
2004. Collaborative recommendation: A robustness analysis. ACM Transactions
on Internet Technology (TOIT) 4, 4 (2004), 344–377.
[64] Arkadiusz Paterek. 2007. Improving regularized singular value decomposition
for collaborative filtering. In Proceedings of KDD Cup and Workshop, Vol. 2007.
5–8.
[65] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme.
2012. BPR: Bayesian personalized ranking from implicit feedback. arXiv preprint
arXiv:1205.2618 (2012).
[66] R Tyrrell Rockafellar. 1993. Lagrange multipliers and optimality. SIAM Rev. 35, 2
(1993), 183–238.
[67] Jorge Rodas-Silva, José A Galindo, Jorge García-Gutiérrez, and David Benavides.
2019. RESDEC: online management tool for implementation components selec-
tion in software product lines using recommender systems. In Proceedings of the
23rd International Systems and Software Product Line Conference-Volume B. 63.
[68] Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. 2001. Item-based
collaborative filtering recommendation algorithms. In Proceedings of the 10th
International Conference on World Wide Web (WWW). 285–295.
[69] Roei Schuster, Tal Schuster, Yoav Meri, and Vitaly Shmatikov. 2020. Humpty
Dumpty: Controlling word meanings via corpus poisoning. In Proceedings of the
IEEE Symposium on Security and Privacy (S&P). 1295–1313.
[70] Carlos E Seminario and David C Wilson. 2014. Attacking item-based recom-
mender systems with power items. In Proceedings of the 8th ACM Conference on
Recommender Systems. 57–64.
[71] Brent Smith and Greg Linden. 2017. Two decades of recommender systems at
Amazon.com. IEEE Internet Computing 21, 3 (2017), 12–18.
[72] Junshuai Song, Zhao Li, Zehong Hu, Yucheng Wu, Zhenpeng Li, Jian Li, and Jun
Gao. 2020. PoisonRec: An Adaptive Data Poisoning Framework for Attacking
Black-box Recommender Systems. In Proceedings of the IEEE 36th International
Conference on Data Engineering (ICDE). 157–168.
[73] Zhoubao Sun, Lixin Han, Wenliang Huang, Xueting Wang, Xiaoqin Zeng, Min
Wang, and Hong Yan. 2015. Recommender systems based on social networks.
Journal of Systems and Software 99 (2015), 109–119.
[74] Synced. 2020. China’s AI-powered NetEase is music to your ears.
https:
//syncedreview.com/2018/02/14/chinas-netease-music-uses-ai-to-win-hearts/
[75] Jinhui Tang, Xiaoyu Du, Xiangnan He, Fajie Yuan, Qi Tian, and Tat-Seng Chua.
2019. Adversarial training towards robust multimedia recommender system.
IEEE Transactions on Knowledge and Data Engineering (2019).
[76] Twitter. 2020. Twitter.com. https://twitter.com/.
[77] Chao Wang, Qi Liu, Runze Wu, Enhong Chen, Chuanren Liu, Xunpeng Huang,
and Zhenya Huang. 2018. Confidence-aware matrix factorization for recom-
mender systems. In Proceedings of the 32nd AAAI Conference on Artificial Intelli-
gence.
[78] Hao Wang, Naiyan Wang, and Dit-Yan Yeung. 2015. Collaborative deep learning
for recommender systems. In Proceedings of the 21th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining. 1235–1244.
[79] Hongwei Wang, Miao Zhao, Xing Xie, Wenjie Li, and Minyi Guo. 2019. Knowledge
graph convolutional networks for recommender systems. In Proceedings of the
28th International Conference on World Wide Web (WWW). 3307–3313.
[80] Jun Wang, Lantao Yu, Weinan Zhang, Yu Gong, Yinghui Xu, Benyou Wang, Peng
Zhang, and Dell Zhang. 2017. Irgan: A minimax game for unifying generative
and discriminative information retrieval models. In Proceedings of the 40th In-
ternational ACM SIGIR conference on Research and Development in Information
Retrieval. 515–524.
[81] Jason Weston, Samy Bengio, and Nicolas Usunier. 2010. Large scale image anno-
tation: learning to rank with joint word-image embeddings. Machine Learning
81, 1 (2010), 21–35.
[82] David C Wilson and Carlos E Seminario. 2013. When power users attack: assessing
impacts in collaborative recommender systems. In Proceedings of the 7th ACM
Conference on Recommender Systems. 427–430.
(a) Impact on P RES @10.
(b) Impact on H R@10.
Figure 9: Impact of the number of nodes in one sampling
trail.
[83] Xingyu Xing, Wei Meng, Dan Doozan, Alex C Snoeren, Nick Feamster, and Wenke
Lee. 2013. Take this personally: Pollution attacks on personalized services. In
Proceedings of the 22nd USENIX Security Symposium (USENIX). 671–686.
[84] Guolei Yang, Neil Zhenqiang Gong, and Ying Cai. 2017. Fake co-visitation
injection attacks to recommender systems. Proceedings of the Annual Network &
Distributed System Security Symposium (NDSS) (2017).
[85] Hongzhi Yin, Weiqing Wang, Liang Chen, Xingzhong Du, Quoc Viet Hung
Nguyen, and Zi Huang. 2018. Mobi-SAGE-RS: A sparse additive generative
model-based mobile application recommender system. Knowledge-Based Systems
157 (2018), 68–80.
[86] Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton,
and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale
recommender systems. In Proceedings of the 24th ACM SIGKDD International
Conference on Knowledge Discovery & Data Mining. 974–983.
[87] Yonghong Yu, Yang Gao, Hao Wang, and Ruili Wang. 2018. Joint user knowledge
and matrix factorization for recommender systems. World Wide Web 21, 4 (2018),
1141–1163.
[88] M. Brovman Yuri. 2020.
Complementary item recommendations at
https://tech.ebayinc.com/engineering/complementary-item\-
eBay scale.
recommendations-at-ebay-scale/.
[89] Yihe Zhang, Jiadong Lou, Li Chen, Xu Yuan, Jin Li, Tom Johnsten, and Nian-
Feng Tzeng. 2020. Towards Poisoning the Neural Collaborative Filtering-Based
Recommender Systems. In European Symposium on Research in Computer Security.
461–479.
[90] Chang Zhou, Jinze Bai, Junshuai Song, Xiaofei Liu, Zhengchao Zhao, Xiusi Chen,
and Jun Gao. 2018. Atrank: An attention-based user behavior modeling frame-
work for recommendation. In Proceedings of the 31th AAAI Conference on Artificial
Intelligence.
A APPENDIX
A.1 The Indicators of Different Social Websites
Table 9 summarizes the popular websites of different categories
where an attacker can apply the two methods for sampling data.
It exhibits an attacker could use at least one method to collect
sampling data from these popular websites.
A.2 Table 10: Statistics of each dataset
A.3 Impacts of Various Parameters
We further conduct experiments to evaluate the impacts of various
parameters involved in the sampling trails collection phase.
Impact of node counts on each sampling trail. We target to
the CML recommender algorithm and vary the number of nodes
on each sampling trail from 5 to 50 in the sampling collection
phases. Figure 9(a) shows the performance (i.e., PRES @10) of our
surrogate model for reproducing CML with varying node counts
in the sampling trail. The results exhibit PRES @10 values increase
first and then drop. This indicates that both too many and too few
nodes will degrade the performance of surrogate model. The reason
1020304050#ofnodesinonesamplingtrial020406080100PRES@10(%)AirbnbUSAirbnbNYAirbnbMANHAmazonNetEaseMusicMoiveLens1020304050#ofnodesinonesamplingtrial020406080100HR@10(%)ml-100kml-1mml-20mnfam-bam-dtrg+acSession 1A: Cybercrime CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea65Table 9: The sampling data collection methods that can be adopted by the popular social websites.
Website
Amazon
E-commerce
eBay
Taobao
Airbnb
Tourism
Social network Twitter
Facebook
MovieLens
NetEase Music
Netflix
YouTube
Yelp
Entertainment
Review
Random Walk
Collection
Type-I Recommendation
Indicator
Random Injection
Collection
Type-II Recommendation
Indicator
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Products related to this item
Customers who bought this item also bought
Customers who viewed this item also viewed
Similar sponsored items
People who viewed this item also viewed
Find similar items
More places to stay
You might like
Similar movies
Similar songs
More like this
Up next
You might also consider
Y
Y
Y
Y
Y
Y
Y
Gift ideas inspired by your shopping history
Inspired by your browsing history
Sponsored items based on your recent views
Who to follow
People You May Know
Top picks
Main view
YouTube’s homepage
Table 10: Statistics of the dataset
Dataset ml-100k ml-1m ml-20m n f
# users
# items
138, 494
26, 745
6, 040
3, 706
943
1, 682
480, 189
17, 770
am-b
8, 026, 324
2, 330, 066
am-d
478, 235
266, 414
tr
8, 262, 545
8, 262, 545
д+
106, 476
106, 476
ac
4, 107, 340
4, 107, 340
other datasets. For the two largest datasets, Amazon and NetEase
Music, they reach to the stable status slower than others. This
implies that for a larger dataset, we should collect more sampling
trails to train our surrogate model. That is, the PRE@10 and HT @10
values fluctuate respectively from 49.6% to 52.2% and from 40.5%
to 44.2% only. This experiment demonstrates that our attack is
effective to dynamic recommender systems as well.
A.4 Table 11: Availability Attack on Matrix
Factorization-based CF Algorithms
A.5 Table 12: Availability Attack on Neural
Network-based CF Algorithms
A.6 Table 13: Target Attack on Neural
Network-based CF Algorithms
A.7 Table 14: Availability attack and target
attack on NCF with ‘Crime/Documentary’
and ‘Blues’ subcategories
A.8 Figure 11: Subcategory Size Distributions
on eBay and Amazon
A.9 Attack Complicated Recommender
Systems
Some CF-based recommender algorithms may incorporate certain
features to enhance the recommender systems’ recommendation
capability, so we conduct experiments to validate our attack per-
formance on such a category of systems. We consider ml-1m and
am-b datasets and extract the movie and book genres, respectively,
as item features. DCF is employed as the underlying recommender
algorithm and the item features are incorporated to train the two
datasets for recommendations. The results of our availability attack
and target attack are presented in Table 15. We observe that when
Figure 10: Impact of the number of sampling trails.
is that too few nodes will limit the total number of collected items,
which thus cannot help surrogate model to capture the sufficient
intrinsic patterns for training. On the other hand, too many nodes
will capture more noises and redundant information, which will
harm the surrogate model training. Our empirical study shows if
the dataset size is unknown, 20 nodes in each trail can derive a
satisfactory surrogate model.
We continue to examine the impact of the node counts in each
trail on the attack performance. Figure 9(b) shows the results (i.e.,
HR@10) of our target attack on the CML with various node counts
in the sampling trail. The trending is similar as in Figure 9(a), where
the HR@10 values first increase and then drop. This set of experi-
ments also confirms that 20 is a suitable choice for the node count
in the sampling trail.
Impact of the Number of Sampling Trails. We target to the
IBCF recommender algorithm and vary the number of sampling
trails from 1, 000 to 15, 000. Figure 10 shows the performance (i.e.,
PRES @10) of the surrogate model when varying the number of
sampling trails. We can see the performance of surrogate model
improves with the increasing of sampling trails amount until it
reaches to the stable status. For AirbnbMAN H , which is the smallest
dataset, it reaches to stable status with fewer sampling trails than
50001000015000#ofsamplingtrials020406080100PRES@10(%)AirbnbUSAirbnbNYAirbnbMANHAmazonNetEaseMusicMoiveLensSession 1A: Cybercrime CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea66Table 11: Comparison of our availability attack ReverseA and other availability attack method RandomA on matrix-factorization
based CF Algorithms
PRE@10(%)
ml-100k
am-d
RandomA
ReverseA
RandomA
ReverseA
0.1
1.44
3.57
1.32
5.53
0.3
1.89
3.69
0.62
2.08
ALS
Attack Ratio (%)
0.5
3.0
5.45
2.33
11.42
4.82
5.67
1.95
5.82
21.54
1.0
2.95
6.41
2.95
7.01
5.0
7.24
24.34
8.15
45.82
0.1
1.67
4.27
1.53
5.87
0.3
1.96
4.88
0.65
3.25
SV D
Attack Ratio (%)
0.5
3.0
6.08
2.38
15.08
7.38
6.45
2.24
6.12
23.87
1.0
3.14
3.40
3.55
7.52
5.0
8.22
29.33
9.82
53.14
0.1
1.48
3.57
1.44
3.66
0.3
1.85
4.01
0.63
2.35
BPR
Attack Ratio (%)
0.5
3.0
6.38
2.37
16.34
5.98
6.02
1.55
5.65
29.94
1.0
3.72
9.07
2.84
5.89
5.0
9.29
33.26
9.28
57.74
Table 12: Comparison of our availability attack ReverseA and other availability attack method RandomA on neural network
based CF Algorithms
PRE@10(%)
Attack ratio (%)
0.1
0.3
0.5
1.0
3.0
5.0
RandomA
ReverseA
NCF
CML