title:Monitoring IDS Background Noise Using EWMA Control Charts and
Alert Information
author:Jouni Viinikka and
Herv&apos;e Debar
Monitoring IDS Background Noise Using
EWMA Control Charts and Alert Information
Jouni Viinikka and Herv´e Debar
France T´el´ecom R&D, Caen, France
{jouni.viinikka,herve.debar}@francetelecom.com
Abstract. Intrusion detection systems typically create large amounts
of alerts, processing of which is a time consuming task for the user. This
paper describes an application of exponentially weighted moving average
(EWMA) control charts used to help the operator in alert processing.
Depending on his objectives, some alerts are individually insigniﬁcant,
but when aggregated they can provide important information on the
monitored system’s state. Thus it is not always the best solution to
discard those alerts, for instance, by means of ﬁltering, correlation, or
by simply removing the signature. We deploy a widely used EWMA
control chart for extracting trends and highlighting anomalies from alert
information provided by sensors performing pattern matching. The aim
is to make output of verbose signatures more tolerable for the operator
and yet allow him to obtain the useful information available. The applied
method is described and experimentation along its results with real world
data are presented. A test metric is proposed to evaluate the results.
Keywords: IDS background noise, alert volume reduction, EWMA
1 Introduction
Perfectly secure systems have been shown to be extremely diﬃcult to design and
implement, thus practically all systems are vulnerable to various exploits or at
least to legitimate users’ privilege abuse. Systems used to discover these attacks
are called Intrusion Detection Systems (IDSes).
The work in intrusion detection begun from the need to automate audit trail
processing [1] and nowadays IDSes themselves can generate enormous amounts
of alerts. Just one sensor can create thousands of alerts each day, and a large
majority of these can be irrelevant [2], partly because the diagnostic capabilities
of current, ﬁelded intrusion detection systems are rather weak [3] [4]. This alert
ﬂood can easily overwhelm the human operating the system and the interesting
alerts become buried under the noise.
1.1 Alert Overﬂow and Correlation
The need to automate alert processing and to reduce the amount of alerts dis-
played to the operator by the system is a widely recognized issue and the research
community has proposed as one solution to correlate related alerts to facilitate
the diagnostics by the operator [5].
E. Jonsson et al. (Eds.): RAID 2004, LNCS 3224, pp. 166–187, 2004.
c(cid:1) Springer-Verlag Berlin Heidelberg 2004
Monitoring IDS Background Noise Using EWMA Control Charts
167
Alert correlation has three principal objectives with regard to information
displayed to the operator:
Volume reduction: Group or suppress alerts, according to common proper-
ties. E.g. several individual alerts from a scan should be grouped as one
meta alert.
Content improvement: Add to the information carried by individual alert.
E.g. the use of topology and vulnerability information of monitored system
to verify or evaluate the severity of the attack.
Activity tracking: Follow multi-alert intrusions evolving as time passes. E.g.
if attacker ﬁrst scans a host, then gains remote-to-local access, and ﬁnally
obtains root access, individual alerts from these steps should be grouped
together.
We perform volume reduction eliminating redundant information by aggre-
gating alerts that are not strictly symptoms of compromise and appear in high
volumes. Only changes in the behavior of the aggregate ﬂow are reported to the
user. Correlation techniques capable of detecting unknown, novel relationships
in data are said to be implicit and techniques involving some sort of deﬁnition of
searched relationships are called explicit. As the aggregation criteria is manually
selected, this is an explicit correlation method. Overall, we aim to save operator
resources by freeing the majority of time units that manually processing the
background noise would require and thus to enable him to focus on more rele-
vant alerts. Even though this manual processing is likely to be periodic skimming
through the accumulated noise, if there are several sources with omnipresent ac-
tivity, the total time used can be signiﬁcant. Next we discuss why despite the
large amounts of alerts background noise monitoring can be useful.
1.2 The Need for Other Type of Processing
Also according to our experience (see Sect. 2.3) a relatively large portion of alerts
generated by a sensor can be considered as background noise of the operational
system. However, the division to true and false positives is not always so black
and white. The origins of problem can be coarsely divided to three. 1) Regardless
of audit source, the audit data usually does not contain all required technical
information, such as the topology and the vulnerability status for the monitored
system for correct diagnosis. 2) The non-technical contextual factors, such as op-
erator’s task and the mission of the monitored system, have an eﬀect on which
types of alerts are of high priority and relevant. 3) Depending on the context of
the event, it can be malicious or not, and part of this information can not be ac-
quired by automated tools or inferred from the isolated events. For the ﬁrst case,
think of a Snort sensor that does not know if the attack destination is running
a vulnerable version of certain OS or server and consequently can not diagnose
whether it should issue an alert with very precise prerequisites for success. An
example of the second is a comparison of on-line business and military base. At
the former the operator is likely to assign high priority on the availability of the
168
Jouni Viinikka and Herv´e Debar
company web server, and he might easily discard port scans as minor nuisance.
At the latter the operator may have only minor interest towards the availability
of the base web server hosting some PR material, but reconnaissance done by
scanning can be considered as activity warranting user notiﬁcation. Instead of
high priority attacks, the third case involves action considered only as potentially
harmful activity, such as ICMP and SNMP messages that indicate information
gathering or network problems, malicious as well as innocuous as part of normal
operation of the network. Here the context of the event makes the diﬀerence,
one event alone is not interesting, but having a thousand or ten events instead of
the normal average of a hundred in a time interval can be an interesting change
and this diﬀerence can not be encoded into signature used by pattern matching
sensor.
This kind of activity can be see to be on the gray area, and the resulting
alerts somewhere between false and true positive. Typically the operator can
not aﬀord to monitor it as such because of the sheer amount of events. The
current work on correlation is largely focusing on how to pick out the attacks
having an impact on monitored system and show all related events in one attack
report to the operator. Depending on the approach, the rest of the alerts are
assigned such a low priority that they do not reach the alert console [3], or
they can be ﬁltered out before entering the correlation process [6, 4]. However,
if the signature reacting to gray area events is turned on, the operator has some
interest towards them. Therefore it is not always the best solution to only dismiss
these less important alerts albeit their large number. Monitoring aggregated
ﬂows can provide information about the monitored system’s state not available
in individual alerts, and with a smaller load on operator. Our work focuses on
providing this type of contextual information to the user.
1.3 Objectives
We want to examine the possibility to track the behavior of alert ﬂows and the
goals for this work are following:
1. Highlight abnormalities. The primary interest was to detect interesting
artifacts from high volume alert ﬂows. Even though traﬃc considered only
harmful is so commonplace that operators can not usually aﬀord to monitor
it as such, by focusing on abnormal changes, the burden would be smaller.
2. Reduce the number of alerts handled by the operator while retain-
ing the information source. We would also like to point out only the inter-
esting artifacts. Given the ﬁrst objective, a signiﬁcant alert reduction would
be required. If achieved, it would be feasible to keep these signatures acti-
vated in the system, providing the operator the desired information through
the aggregates. A suﬃciently low artifact output would also allow the use
of this method in parallel with other correlation components for additional
information, regardless how the correlation engine considers the alerts.
Monitoring IDS Background Noise Using EWMA Control Charts
169
3. Measure the reduction. We do not know what we do not measure. To see
the eﬀect of the techniques some metrics are needed. This goal is essentially
linked to the next one, the determination of the applicability. It is also im-
portant for the operator to know how much is being suppressed for better
situation understanding.
4. Determine the applicability of the approach with diﬀerent alert
ﬂows. The applicability of the method for processing high volume alert ﬂows,
and more speciﬁcally with diﬀerent types of alert ﬂows, needs to be deﬁned.
5. Trend visualization. The power of human visual processing capability has
been found useful also in intrusion detection, especially to detect anomalies
or patterns diﬃcult to handle for an AI [7]. To improve operator’s view of
current system state and the nature of anomalies, alert ﬂow and trend ought
to be visualized.
A variation of the EWMA control charts is proposed to achieve these goals.
This control chart was designed and has been used to process alerts created and
logged by sensors deployed in a production system at France T´el´ecom.
The rest of the paper describes our ﬁndings, Sect. 2 presents the EWMA
control charts and our variation. Section 3 describes practical experimentation
and proposes a new metric for evaluating our approach. Related work is viewed
in Sect. 4 and we oﬀer our conclusions in Sect. 5.
2 EWMA Control Charts
In this section we present shortly mathematical backgrounds of EWMA, its use
for control chart procedure, and then our variation for noise monitoring.
2.1 Backgrounds in Statistical Process Control
EWMA control charts were originally developed for statistical process control
(SPC) by Roberts [8], who used the term geometric moving averages instead
of EWMA, and since then the chart and especially the exponentially weighted
moving average have been used in various contexts, such as economic applications
and intrusion detection [9–11]. More details are available in Sect. 4.
In SPC a manufacturing process is seen as a measurable entity with a dis-
tribution. The over-all quality of the product resulting from the process is con-
sidered dependent on the process mean, which is to be kept at the ﬁxed level
and the variations as small as possible. An EWMA control chart can be used
to monitor the process mean by maintaining an exponentially moving average of
the process value. The average is compared to preset control limits, deﬁning the
acceptable range of values. Next we describe this procedure in more detail.
The exponentially weighted moving average is deﬁned as
zi = (1 − λ)zi−1 + λxi ,
(1)
where 0 < λ < 1 . Here zi is the current value of exponentially smoothed average,
zi−1 the previous smoothed value, and xi is the current value of monitored
statistic. The name exponential smoothing is also used for this type of averaging.
170
Jouni Viinikka and Herv´e Debar
This recursive formulation distinguishes EWMA from the basic moving av-
erages, such as simple moving average or weighted moving average. Exponential
smoothing takes all past data into account with signiﬁcance decaying expo-
nentially as a function of time. However, at the same time only the previous
smoothed value and current measure are required to compute the new smoothed
value. The decay is controlled by the factor λ and (1− λ) is called the smoothing
factor. The name becomes more apparent by rewriting (1) as
zi = λxi + λ(1 − λ)1xi−1 + λ(1 − λ)2xi−2 + . . .
(2)
. . . + λ(1 − λ)i−2x2 + λ(1 − λ)i−1x1 + (1 − λ)ix0 ,
where i ≥ 0 . Now it can be seen that the current data from time instant i
receives weight λ and old data from instant i − j receives weight λ(1 − λ)j . If
the interest is in the long-term trend, large smoothing factors should be used
and vice versa.
As the monitored statistic in (1) is process mean, xi is the average of subgroup
of n samples taken at time instant i. The standard deviation for z can be obtained
with equation
(cid:1)
λ
2 − λ
Since xi is an average of n samples σ¯x is σx/
deviation of x, supposed to be known a priori.
σz =
σ¯x .
√
n, where σx is the the standard
(3)
The upper and lower control limits (UCL, LCL) set as
x0 ± 3σz
(4)
deﬁne the interval for z where process is deemed to be under control. Here x0 is
the nominal average of the process, also supposed to be known a priori. For each
new measurement, the current value of statistic z is calculated by using (1), and
if the control limits are surpassed, instability is signaled.
Exponential smoothing can be approximated by a standard moving average
with a window size n. According to Roberts [8], for a given λ a roughly equivalent
window size n is determined from
n =
− 1 .
2
λ
(5)
With this equation the decay speed becomes more intuitive knowing the mea-
surement interval length. We call the product of n and the sampling interval
length for x the memory of the statistic, as events older than that have only
little signiﬁcance on current z. For example, smoothing factor 0.92 would trans-
late to a window size 24, and for 0.80 corresponding n is 9. This shows also how
larger smoothing factor corresponds to averaging over larger number of samples.
2.2 The Control Chart for Alert Flows
Our needs diﬀer from those of Roberts’ quite much, and also to a smaller degree
from those of the related work in intrusion detection (Sect. 4). Below our varia-
Monitoring IDS Background Noise Using EWMA Control Charts
171
tion of the technique is described, building largely on [11], and the rationale for
changes and choices is provided.
The monitored measure is the alert intensity of a ﬂow x, the number of
alerts per time interval. One alert ﬂow consists typically of alerts generated by
one signature, but also other ﬂows, such as alerts generated by a whole class of
signatures, were used. Intensity x is used to form the EWMA statistic of (1).
This statistic is called the trend at time i.
It is quite impossible to deﬁne a nominal average as the test baseline x0
for (4), since these ﬂows evolve signiﬁcantly with time. Like Mahadik et al. [11], to
accommodate the dynamic, non-stationary nature of the ﬂows, the test baseline
is allowed to adapt to changes in alert ﬂow, and the control limits for time instant
i are
(6)
Here n is a factor expressing how large a deviation from trend is acceptable and
σz−1 is z’s standard deviation at interval i − 1. The control limits for interval i
are thus calculated using trend statistics from interval i − 1.
zi−1 ± n · σzi−1 .
To obtain the standard deviation σz, another EWMA statistic
i = (1 − λ)z2
z2
i−1 + λx2
i
(7)
is maintained, where xi is the current intensity as in trend calculation. The
standard deviation is computed as
(cid:2)
σzi =
i − (zi)2i .
z2
(8)
Now for each new interval and for each alert ﬂow, 1) the alert intensity
is measured, 2) the control limits are calculated, and 3) the decision whether
the interval is abnormal or not is taken. Both [9] and [11] test smoothed event
intensity against the control limits. They use a larger smoothing factor with (1)
to obtain the baseline zi from (6) and apply (1) with smaller smoothing factor
to have smoothed event intensity that is tested against control limits. This is
done to reduce the eﬀect of wild values in the observations. However, in the case
of alerts, these outliers are usually of interest for the operator and testing the
raw intensity, or in other words using (1 − λ) = 0 to obtain the value that is
tested against control limits, gave us better capability to capture small variations
occurring in some extremely stable alert ﬂows.
2.3 Learning Data
The tool was developed for an IDS consisting of Snort sensors logging alerts
into a relational database. The sensors are deployed in a production network,
one closer to Internet and two others in more protected zones. This adds to the
diﬃculty of measuring and testing, since we do not know the true nature of
traﬃc that was monitored. On the other hand, we expect the real world data to
contain such background noise and operational issues that would not be easily
incorporated to simulated traﬃc.
172
Jouni Viinikka and Herv´e Debar
Table 1. Five most proliﬁc signatures in the ﬁrst data set
signature name
number of alerts
proportion
SNMP Request udp
ICMP PING WhatsupGold Windows
ICMP Destination Unreachable (Comm
Adm Proh)
LOCAL-POLICY External connexion from
HTTP server
ICMP PING Speedera
sum
176 009
72 427
57 420
51 674
32 961
390 491
30 %
13 %
10 %
9 %
6 %
68 %
The data set available to us in this phase contained over 500 K alerts accumu-
lated during 42 days. Of the 315 activated signatures, only ﬁve were responsible
for 68 % of alerts as indicated in Table 1 and we chose them for further scrutiny.
To give an idea of the alert ﬂow behavior, examples of alert generation intensi-
ties for four of these signatures are depicted in Fig. 1 and the ﬁfth, ICMP PING
WhatsupGold Windows, is visible in Figs. 2 and 3 (described with more details
in Sect. 2.4). The relatively benign nature of these alerts and their high volume
was one of the original inspirations for this work. These alerts are good examples
of the problem three discussed in Sect. 1.2 and demonstrate the reason why we
opt not just ﬁlter even the more deterministic components out. For example,
the alert ﬂow in Fig. 1(c) triggered by SNMP traﬃc over UDP had only few
(source, destination) address pairs, and the constant component could be easily
ﬁltered out. However, this would deprive the operator being notiﬁed of behavior
such as the large peak and shift in constant component around February 15th
as well or the notches in the end of February and during March 15th. Not neces-
sarily intrusions, but at least artifacts worth further investigation. On the other
hand, we do not want to distract the operator with the alerts created during
the hours that represent the stable situation with constant intensity. For the
others, Fig. 1(a) shows alerts from a user deﬁned signature reacting to external
connections from an HTTP server. The alerts occur in bursts as large as several
thousands during one hour and the intensity proﬁle resembles impulse train. As
custom made, the operator has likely some interest in this activity. In Figs. 1(b)
and 1(d) we have alerts triggered by two diﬀerent ICMP Echo messages, former
being remarkably more regular than latter. In the system in question, deactiva-
tion of ICMP related signatures was not seen as an solution by the operator as
they are useful for troubleshooting problems. Consequently, we had several high
volume alert ﬂows for which the suppression was not the ﬁrst option.
2.4 Deploying the Control Chart
The behavior of the model deﬁned in Sect. 2.2 was explored with ﬁve ﬂows made
up from these ﬁve signatures (Figs 1, 2, and 3) by varying several parameters.
A combination that would 1) catch desired artifacts from the alert ﬂow and
2) create as small amount of new alerts as possible, was searched. Not having
Monitoring IDS Background Noise Using EWMA Control Charts
173
 10000
 1000
r
u
o
h
r
e
p
s
t
r
e
A
l
 100
 10
 1000
r
u
o
h
r
e
p
s
t
r
e
A
l
 100
 1
Feb-08 Feb-15 Feb-22 Mar-01 Mar-08 Mar-15