dling; and hooks for allowing host applications to provide non-
intrusive callbacks that run synchronously at well-deﬁned times.
HILTI also supports two styles of concurrency. First, within a
single hardware thread, one can multiplex analyses by switching ar-
bitrarily between stacks using co-routines. Consider protocol anal-
ysis where the host application incrementally feeds chunks of pay-
load into the parsing code, switching between different sessions as
their packets arrive. When the host’s C code calls for the ﬁrst time
the HILTI parsing function for a session, HILTI internally instanti-
ates a ﬁber object for the call’s execution that can capture its state,
and then proceeds with processing the data. Once parsing reaches
the end of the currently available chunk, it suspends execution by
freezing the stack and copying the CPU’s registers into the ﬁber.
Later, when new payload arrives for that session, the application
resumes parsing by reactivating the ﬁber, leading HILTI to rein-
state the frozen stack and continue where it left off. Compared to
traditional implementations—which typically maintain per-session
state machines manually that record the current state—this model
remains transparent to the analysis code and hence simpliﬁes its
structure.
Second, HILTI provides threads for distributing an analysis con-
currently across CPU cores. We employ an Erlang-style thread-
ing model that provides an application with a large supply of
lightweight virtual threads, which a runtime scheduler then maps
to a small number of hardware threads via cooperative multi-
tasking. HILTI identiﬁes threads with 64-bit integer IDs: The in-
struction thread.schedule foo("abc") 123456 sched-
ules an asynchronous invocation of the function foo with one
string argument abc to thread number 123456. The ID-based
model maps directly to hash-based load-balancing schemes that
networking applications commonly deploy for parallel trafﬁc anal-
ysis (e.g., Suricata [5] and Bro [44]). For example, to distribute
ﬂow processing across threads, one would hash the ﬂow’s 5-tuple
into an integer and then interpret that value as the ID of the vir-
tual thread to assign the corresponding analysis to. As processing
within each virtual thread proceeds sequentially, this approach im-
plicitly serializes all computation relating to a single ﬂow and thus
obviates the need for further intra-ﬂow synchronization. We ﬁnd
typical analysis tasks amenable to this model [43].
HILTI’s execution model prevents data races and low-level dead-
locks by design: virtual threads cannot share state directly.
In
particular, HILTI does not provide global variables visible across
threads. Instead, each virtual thread receives its own set of thread-
local variables for recording state related to its processing. Ex-
changing global state requires explicit message passing, either by
connecting threads with HILTI’s thread-safe channel data type, or
by scheduling tasks to a target thread and passing the relevant in-
Functionality Mnemonic
Bitsets
Booleans
CIDR masks
Callbacks
Closures
Channels
Debug support
Doubles
Enumerations
Exceptions
File i/o
Flow control
Hashmaps
Hashsets
IP addresses
Integers
Lists
bitset
bool
network
hook
callable
channel
debug
double
enum
exception
file
(No joint preﬁx)
map
set
addr
int
list
Functionality
Packet i/o
Packet classiﬁcation
Packet dissection
Ports
Proﬁling
Raw data
References
Regular expressions
Strings
Structs
Time intervals
Timer management
Timers
Times
Tuples
Vectors/arrays
Virtual threads
Mnemonic
iosrc
classifier
overlay
port
profiler
bytes
ref
regexp
string
struct
interval
timer_mgr
timer
time
tuple
vector
thread
Table 1: HILTI’s main instruction groups.
formation as arguments.2 In either case, the runtime deep-copies
all mutable data so that the sender will not see any modiﬁcations
that the receiver may make. This strict model of data isolation en-
ables reliable concurrent execution because it encourages value se-
mantics as opposed to complicated data dependencies that would
require locks to synchronize access.
3.3 Proﬁling & Debugging
A key challenge for high-volume trafﬁc analysis is assessing and
optimizing runtime performance [16]. HILTI supports measuring
CPU and memory properties via proﬁlers that track attributes such
as CPU cycles, memory usage, and cache performance for arbitrary
blocks of code. During execution the HILTI runtime records mea-
sured attributes to disk at regular intervals, e.g., enabling tracking
of CPU time spent per time interval [16, 17]. The HILTI compiler
can also insert instrumentation to proﬁle at function granularity.
3.4 Host Application API
HILTI comes with an extensive C API that offers host applica-
tions direct access to its data types. In addition, control ﬂow can
transfer bi-directionally between applications and HILTI. C pro-
grams call HILTI functions via the C stubs, and HILTI code can
invoke arbitrary C functions. The API integrates exception han-
dling, timer management, ﬁber resumption, and thread scheduling
between HILTI and application.
A second part of HILTI’s API
is a C++ AST interface
for constructing HILTI programs in memory.
hiltic and
hilti-build are in fact just wrappers around this API, which
host applications can likewise employ to compile their analysis
speciﬁcations into HILTI code. Combining AST and JIT interfaces
enables applications to go all the way from user-level speciﬁcation
to native code on the ﬂy.
4. APPLICATION EXEMPLARS
We now develop four applications as examples to illustrate
HILTI’s ability to accommodate a wide range of common network
processing tasks: (i) a BPF-style packet ﬁlter engine; (ii) a stateful
ﬁrewall; (iii) a parser generator for network protocols; and (iv) a
compiler for Bro scripts. We have implemented all four as pro-
totypes. While we consider the former two primarily proof-of-
concepts, the latter two represent realistic and fully functional ap-
plications that we intend to further improve as HILTI matures.
2Note that the interpretation of HILTI’s global keyword in code
examples below is “a variable global to the current virtual thread”.
464type IP::Header = overlay {
# :  at  unpack  [(bits)]
version: int at 0 unpack UInt8InBigEndian (4, 7),
hdr_len: int at 0 unpack UInt8InBigEndian (0, 3),
[...]
src:
dst:
at 12 unpack IPv4InNetworkOrder,
at 16 unpack IPv4InNetworkOrder
addr
addr
}
bool filter(ref packet) { # Input: raw data.
}
### Compiled rule set (net1 -> net2) -> {Allow, Deny}.
### Generated by the application’s analysis compiler.
void init_rules(ref> r) {
# True -> Allow; False -> Deny.
classifier.add r (10.3.2.1/32,
classifier.add r (10.12.0.0/16, 10.1.0.0/16) False
classifier.add r (10.1.6.0/24, *) True
classifier.add r (10.1.7.0/24, *) True
10.1.0.0/16) True
local addr a1, a2
local bool b1, b2, b3
# Extract fields and evaluate expression.
a1 = overlay.get IP::Header src packet
b1 = equal a1 192.168.1.1
a1 = overlay.get IP::Header dst packet
b2 = equal a2 192.168.1.1
b1 = or b1 b2
b2 = equal 10.0.5.0/24 a1
b3 = or b1 b2
return b3
}
Figure 4: Generated HILTI code for the BPF ﬁlter
host 192.168.1.1 or src net 10.0.5.0/24.
Berkeley Packet Filter.
As an initial simple application to explore, we implemented a
compiler for BPF [32]. BPF traditionally translates ﬁlters into code
for its custom internal stack machine, which it then interprets at
runtime. Compiling ﬁlters into native code via HILTI avoids the
overhead of interpreting, enables further compile-time code opti-
mization, and facilitates easy extension of the ﬁltering capabilities
in the future.
Figure 4 shows HILTI code that our compiler produces for a sim-
ple BPF ﬁlter. The generated code leverages a HILTI overlay type
for parsing IP packet headers. Overlays are user-deﬁnable compos-
ite types that specify the layout of a binary structure in wire for-
mat and provide transparent type-safe access to its ﬁelds while ac-
counting for speciﬁcs such as alignment and endianness. While our
proof-of-concept BPF compiler supports only IPv4 header condi-
tions, adding further BPF features would be straight-forward. The
compiler could also go beyond standard BPF capabilities and, for
example, add stateful ﬁltering [25].
Stateful Firewall.
Our second proof-of-concept host application is a basic state-
ful ﬁrewall, implemented as a Python host application that com-
piles a list of rules into corresponding HILTI code. To simplify
the example, our tool supports only rules of the form (src-net,
dst-net) → {allow,deny}, applied in order of speciﬁca-
tion. The ﬁrst match determines the result, with a default action of
deny. In addition, we provide for a simple form of stateful match-
ing: when a host pair matches an allow rule, the code creates a
temporary dynamic rule that will permit all packets in the opposite
direction until a speciﬁed period of inactivity has passed.
Figure 5 shows the code generated for a simple rule set, along
with additional static code that performs the matching. The code
leverages two HILTI capabilities: (i) the classiﬁer data type for
matching the provided rules; and (ii) a set indexed by host pair
to record dynamic rules, with a timeout set to expire old entries.
While we have simpliﬁed this proof-of-concept ﬁrewall for demon-
stration purposes, adding further functionality would be straight-
forward. In practice, the rule compiler could directly support the
syntax of an existing ﬁrewall system, like iptables.
### The host application also provides the following
### static code.
# Data type for a single filter rule.
type Rule = struct { net src, net dst }
# The classifier storing the rules.
global ref> rules
# Dynamic rules: address pairs allowed to communicate.
global ref > > dyn
# Function to initialize classifier at startup.
void init_classifier() {
rules = new classifier # Instantiate.
call init_rules(rules)
classifier.compile rules
# Add rules.
# Freeze/finalize.
# Create set for dynamic state with timeout of 5 mins
# of inactivity.
dyn = new set>
set.timeout dyn ExpireStrategy::Access interval(300)
}
# Function called for each packet, passing in
# timestamp and addresses. Returns true if ok.
bool match_packet(time t, addr src, addr dst) {
local bool b
# Advance HILTI’s global time. This will expire
# inactive entries from the state set.
timer_mgr.advance_global t
# See if we have a state entry for this pair.
b = set.exists dyn (src, dst)
if.else b return_action lookup
lookup: # Unknown pair, look up rule.
try { b = classifier.get rules (src, dst) }
catch ( ref e ) {
return False # No match, default deny.
}
if.else b add_state return_action
add_state: # Add dynamic rules to allow both sides.
set.insert dyn (src, dst)
set.insert dyn (dst, src)
return_action: # Return decision.
return b
}
Figure 5: HILTI code for ﬁrewall example.
A Yacc for Network Protocols.
To provide a more complete example, we reimplemented the
BinPAC parser generator [36] as a HILTI-based compiler. Bin-
PAC is a “yacc for network protocols”: given a protocol’s grammar,
it generates the source code of a corresponding protocol parser.
While the original BinPAC system outputs C++, our new version
targets HILTI. As we also took the opportunity to clean up and
extend syntax and functionality, we nicknamed the new system
BinPAC++.
465const Token
const NewLine
const WhiteSpace = /[ \t]+/;
= /[^ \t\r\n]+/;
= /\r?\n/;
type RequestLine = unit {
Token;
WhiteSpace;
URI;
WhiteSpace;
method:
:
uri:
:
version: Version;
NewLine;
:
};
type Version = unit {
:
number: /[0-9]+\.[0-9]+/;
/HTTP\//; # Fixed string as regexp.
};
(a) BinPAC++ grammar excerpt for HTTP.
struct http_requestline_object {
hlt_bytes* method;
hlt_bytes* uri;
struct http_version_object* version;
[... some internal fields skipped ...]