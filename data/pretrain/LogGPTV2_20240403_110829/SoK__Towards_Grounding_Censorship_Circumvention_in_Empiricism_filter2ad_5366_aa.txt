title:SoK: Towards Grounding Censorship Circumvention in Empiricism
author:Michael Carl Tschantz and
Sadia Afroz and
anonymous and
Vern Paxson
2016 IEEE Symposium on Security and Privacy
2016 IEEE Symposium on Security and Privacy
SoK: Towards Grounding Censorship
Circumvention in Empiricism
Michael Carl Tschantz∗, Sadia Afroz∗, Anonymous‡, and Vern Paxson∗†
∗International Computer Science Institute
†University of California, Berkeley
Abstract—Eﬀective evaluations of approaches to circumventing
government Internet censorship require incorporating perspec-
tives of how censors operate in practice. We undertake an
extensive examination of real censors by surveying prior mea-
surement studies and analyzing ﬁeld reports and bug tickets from
practitioners. We assess both deployed circumvention approaches
and research proposals to consider the criteria employed in their
evaluations and compare these to the observed behaviors of real
censors, identifying areas where evaluations could more faithfully
and eﬀectively incorporate the practices of modern censors. These
observations lead to an agenda realigning research with the
predominant problems of today.
I. Introduction
Censorship circumvention research seeks to develop ap-
proaches for facilitating access to banned Internet resources, a
domain with a fundamentally adversarial nature arising from
the ongoing interactions between circumventors and censors.
Both parties ﬁnd themselves locked in an arms race where each
side must manage tradeoﬀs between eﬃcacy and expenditure.
These tradeoﬀs continually evolve in subtle ways as new
technologies change the costs of various approaches.
Given this complexity, undertaking sound evaluation of
potential circumvention approaches proves both crucial and
diﬃcult. Sound evaluation is crucial since, due to limited
resources, the developers of circumvention approaches cannot
implement and deploy every prospective approach; they need
criteria for selecting the most promising. It is diﬃcult, on the
other hand, because unidentiﬁed weaknesses in an approach
oﬀer potential openings to censors, but worst-case analyses
that presume censors will necessarily exploit such vulnerabil-
ities ignore the realities of censors who aim to avoid blocking
proﬁtable traﬃc while staying within their budget constraints.
Soundly incorporating these realities into evaluations requires
grounding in empirical observations of real censors.
While the evaluation sections of research papers provide
some insight into the promise of a given circumvention ap-
proach, each paper employs its own evaluation methodology,
typically selected with the capabilities of the approach in mind
but often not balanced against realistic models of censors. Fur-
thermore, such approach-oriented evaluations make it diﬃcult
to compare across diﬀerent approaches, or to determine how
well an evaluation predicts real-world performance. Prototyped
‡ This coauthor chooses to forgo identiﬁcation in protest of the IEEE
Security and Privacy Symposium’s acceptance of support from the US
National Security Agency. While it pains us for his signiﬁcant contributions
to the work to go unrecognized here, we respect the heartfelt principles that
led him to his position.
approaches meeting their own evaluation criteria can succumb
to vulnerabilities not considered by their evaluation (e.g., [1]).
Approach. To address this disconnect between evaluation and
the actual operating conditions of censorship circumvention
approaches, in this work we seek to ground the evaluation
of circumvention approaches in empirical observations of real
censors. To do so, we systematically compare the behaviors of
real censors to the evaluation criteria used by circumvention-
approach designers.
Our work systematizes the evaluation of approaches for
censorship circumvention in four ways:
1) We collect data on real-world attacks to show the current
state of censorship practice (Sections II and IV),
2) We survey circumvention approaches and their eval-
uations to illuminate the current state of evaluation
(Sections V and VI, respectively),
3) We compare the evaluations designed to assess the
diﬃculty of blocking an approach to the actual actions
of real censors (Section VII),
4) We point to open research problems whose resolution
will improve evaluation (Section VIII).
We also limit
Scope. We focus our discussion on censorship by governments
attempting to prevent subjects from accessing particular web
resources outside the government’s jurisdiction. The censor
seeks to detect and disrupt banned traﬃc by placing monitors
at the edges of their network—just as customs inspectors
intercept and examine physical goods at international borders.
the types of circumvention we consider
to channel-based approaches that (1) bypass country-level
censors that monitor network traﬃc between two end points,
(2) communicate with resources outside the censors’ borders,
and (3) enable low-latency connections (roughly, fast enough
for web browsing). Our scope excludes concerns such as
internal censorship of newspapers or disruption of entirely
domestic communication. Even so, the remaining space of
censor activity and circumvention approaches is large, with 55
approaches or evaluations of approaches [2–56] falling within
our scope. Figure 1 shows a generic model of censorship and
circumvention under the scope we use.
Overview. We ﬁrst take a detailed look at the arms race
between Tor and China as an illustration of the cat-and-mouse
nature of censorship and circumvention (Section II). After
covering related work (Section III), we broaden our view by
examining censorship incidents involving other channel-based
circumvention approaches (Section IV).
2375-1207/16 $31.00 © 2016 IEEE
© 2016, Michael Carl Tschantz. Under license to IEEE.
DOI 10.1109/SP.2016.59
DOI 10.1109/SP.2016.59
914
914
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:11:18 UTC from IEEE Xplore.  Restrictions apply. 
Inside
Outside
Instructions
1
Identifiers
2
Circumventor's website
Circumvention service
Monitor
Monitor
Forwarder
Destination
3
User
Fig. 1. An illustration of the type of censorship we study. First, censored
users within a censor’s jurisdiction gather information about how to use an
approach, which may include a program download. Second, the users gain
various identiﬁers, such as IP addresses and passwords. Third, they run their
traﬃc through a client-side program that applies various transformations to
hide the true destination and content. In the case of a banned destination, the
approach sends the obscured traﬃc to some allowed destination that acts as
a forwarder to the real destination.
Next, we provide a survey of channel-based censorship
circumvention (Section V) and its evaluation (Section VI).
Unlike other surveys on circumvention [57–59], we do not
focus on comparing the approaches themselves, but rather on
comparing their evaluations. We enumerate the criteria that
the developers of each approach used in their evaluations. We
ﬁnd little commonality in the evaluation methods employed.
While some diversity is to be expected given that approaches
diﬀer in goals and intended deployment environments, we
ﬁnd no globally organizing principles guiding the selection
of evaluation criteria.
We focus on the criteria related to detecting circumventing
traﬃc and compare them to the actions of real censors (Sec-
tion VII). We observe that system designers tend to emphasize
censor capabilities that may become important in the future,
but not seen in practice today, with little assessment on actual
detection techniques used by current censors. In particular, we
identify three disconnects between practice and research:
1) Real censors attack how users discover and set up
channels, whereas research often centers on channel
usage,
2) Real censors prefer cheap passive monitoring or more
involved active probing, whereas research often looks at
complex passive monitoring and traﬃc manipulations at
line speed, and
3) Censors favor attacks that do not risk falsely blocking
allowed connections due to packet loss, whereas research
considers many less robust attacks.
We end with a research agenda to realign the evaluation
of circumvention approaches with the actions of real cen-
sors (Section VIII). We propose augmenting prior approach-
speciﬁc methods of evaluation with a new methodology for
creating evaluation criteria and interpreting results, and with
tools for aiding evaluators.
Throughout, we provide recommendations on how to im-
prove evaluations. However, we do not ultimately end with
any list of “correct” evaluation criteria, nor actually evaluate
any approaches. We believe that
the range of approaches
915915
used is too wide for any one list to cover all use cases, or
for a single study to attempt to comprehensively rank them.
Rather, we hope to provide a systematic method of thinking
about evaluation that will guide evaluators of circumvention
approaches in their selection of appropriate criteria on a case-
by-case basis.
Also, we do not intend for this work to discount the utility
of forward-looking studies that anticipate the more advanced
censors of the future. Rather, we aim to make the tradeoﬀs
clear: some approaches considered by research are likely
years ahead of the point where their overhead is justiﬁed
by actual censors eﬀectively blocking less advanced methods;
meanwhile, censors block deployed approaches using simple
attacks. We hope this observation inspires the research com-
munity towards also providing tools for preventing simpler
attacks, which would yield immediate beneﬁts for many real
users.
We make details and our database available at
http://internet-freedom-science.org/circumvention-survey/
II. Illustrating the Problem Space:
Tor and the Great Firewall
The problem space we consider has both disparate aspects
and a complicated arms-race-driven evolution. In this section
we frame the space through the lens of the Tor anonymity
system and the “Great Firewall” (GFW), the primary national
censorship apparatus of China. The conﬂict between these two
actors is representative of the larger world of censorship and
circumvention, and oﬀers us a way of introducing diﬀerent
notions and the associated terminology we will use in our
discussion, as well as providing some of the grounding in
real-life censorship that underlies many of our perspectives.
Tor provides a convenient focus due to the relatively ex-
tensive documentation of its censorship and circumvention
counter-responses. We mined blog posts, bug reports, and the
Tor Project’s public documentation to identify the censorship
events that underlie our narrative. A progression emerges: Tor,
which was not originally designed for circumvention, is used
to evade the GFW. The censor blocks the Tor website and the
servers that make up the anonymity network; Tor responds
with mirrors and secret entry servers. The censor begins
to identify Tor by protocol features; Tor deploys protocol
encapsulation to hide those features. The censor starts actively
scanning for Tor servers; Tor introduces protocols immune to
scanning.
In this recounting, in our terminology the GFW plays the
role of a censor: a government entity that disrupts access to
certain Internet resources outside its jurisdiction (in this case,
China). The censor employs monitors, traﬃc ﬁltering devices
at the edge of the network. Tor and its users are circumventors
who seek to evade the censor’s controls. We divide circumven-
tors into users, those within the censor’s jurisdiction who try
to access blocked content; and advocates, those who develop,
deploy, and maintain systems that enable circumvention. We
term any means of evading the censor’s blocking a censorship
circumvention approach, or “approach” for short. Tor oﬀers
not a single approach, but multiple “pluggable” approaches,
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:11:18 UTC from IEEE Xplore.  Restrictions apply. 
each with advantages and disadvantages. A user’s connection
to the Tor network (however accomplished) is an example of
what we call a channel. The Tor network itself is an example
of a forwarder. A channel disguises user traﬃc so that it may
reach a forwarder that then passes the traﬃc on to its ultimate
destination. Refer to Figure 1 for the relative positioning of
user, monitor, and forwarder.
The Tor network began operating in 2003 [60]. Designed for
anonymity, early Tor had major deﬁciencies as a circumven-
tion approach. Unsurprisingly, the ﬁrst action the GFW took
against Tor was simple: in 2008 it blocked the www.torproject.
org website [61]. In response, advocates deployed website
mirrors and email-based software distribution mechanisms.
The raw Tor protocol—today often called “vanilla” Tor
to distinguish it from the more resistant approaches that
followed—has many distinguishing features that make it easy
to detect. We call any such distinguishing feature a vulner-
ability, by analogy to software security. Similarly, we refer
to the eﬀective leveraging of a vulnerability by the censor
for detection and taking action against circumvention as an
exploit. We call a chain of exploits aimed at disrupting a
channel an attack. One of vanilla Tor’s biggest vulnerabilities
is its hardcoded list of public directory authorities, from which
users download the similarly public list of relay IP addresses.
In late 2009 the GFW exploited this vulnerability by blocking
the IP addresses of directory authorities and relays [62, 63].
The steps of the attack in this case are (1) downloading
the list of relays and adding their addresses to a blacklist;
(2) dynamically blocking any access to those addresses when
observed in a traﬃc stream.
In response to the blocking of its directory requests and
relays, Tor introduced “bridges”, secret relays without publicly
listed addresses. (Bridges had in fact been prepared earlier,
in 2007, in anticipation of this type of blocking [64, 65]—
the arms race is not merely reactive.) Users must ﬁrst learn
the IP address of a bridge in some out-of-band fashion, for
example by email, an instance of what we term an identiﬁer
distribution mechanism (IDM), the means by which a user
learns the information required to establish a connection to
a forwarder. After blocking the public relays, the GFW went
after bridges by attacking the IDM, enumerating bridges from
the centralized bridge database one by one [62, 63, 66].
Private bridges—those distributed by word of mouth rather
than through a centralized database—remained unblocked for
a time. Even with secret bridge addresses, though, Tor remains
vulnerable to deep packet inspection (DPI), protocol-aware
ﬁltering that considers application-layer semantics. Tor uses
TLS in fairly distinctive ways that make it relatively easy to
detect. For example, the ﬁrewall began to identify the use of
Tor by looking for Tor’s distinctive list of TLS client cipher
suites in 2011 [67]. For a time, Tor developers responded
with incremental reﬁnements to make Tor’s use of TLS less
distinctive [68]. A more lasting solution came in the form
of “pluggable transports”, modular circumvention approaches
that form an additional layer around Tor TLS to protect it from
protocol ﬁngerprinting. Pluggable transports use a variety of
techniques to hide the fact that Tor is in use.
of the ﬁrewall used DPI detection of Tor as a cue to employ
active probing, posing as a user and connecting to suspected
circumvention forwarders to block them by address if con-
ﬁrmed. In late 2011 the ﬁrst evidence of active probing against
Tor appeared [69]. Later, the censors employed probing for
certain pluggable transports, as well as non-Tor channels such
as virtual private networks (VPNs) [70]. The latest pluggable
transports are designed to resist active probing by incorporat-
ing per-forwarder secrets or by co-locating forwarders with
non-circumvention-related services.
This brings us to the state-of-the-art for Tor-related circum-
vention: censors that employ website and IP address blocking,
IDM disruption, deep packet inspection, and active probing;
and circumvention approaches that use secret IP addresses,
encrypt their payloads, and resist active probing.
III. Related work
To our knowledge, the literature lacks published surveys
analyzing censorship attacks on circumvention approaches.
The closest is Dingledine and Appelbaum’s slide deck listing
attacks on Tor [63].
Elahi et al. oﬀer a report decomposing circumvention ap-
proaches into various phases and components to compare how
they mitigate attacks on each [58]. For example, the for-
warders, IDM, channel setup, and channel usage in our model
of circumvention each has an analog in Elahi et al.’s model.
More narrowly focused, a report by Khattak et al. covers
pluggable transports, a subset of channel-based approaches
designed to plug into a larger system, such as Tor [59]. Their
work decomposes the channel of such transports into layers
similar to a network stack to consider attacks and mitigations
at each layer. Each of these two technical reports provides
a survey of which tools oﬀer which properties, similar to
our Table IV. However, our survey diﬀers in goal and scope:
Rather than attempting to compare approaches, our study’s
primary goal is to compare evaluations in terms of how they
relate to real-world concerns, grounding our discussion in
empirical data regarding the behavior of actual censors.
K¨opsell and Hillig proposed a taxonomy of circumvention
approaches. They model censors as either blocking on circum-
stances or content [71], similar to our breakdown of channel
setup and usage. However, they do not empirically study how
their model compares to real attacks.
Prior works has also empirically evaluated approaches.
Roberts et al. assessed deployed circumvention approaches by
testing whether they work in various countries [55]. Callanan
et al. used a combination of in-laboratory tests and user
surveys to determine the usability, performance, and security
characteristics of a variety of deployed approaches [53].
Robinson et al. [72] performed a study of 1,175 Chinese
Internet users and found GoAgent [25] to be the most widely
used tool. They concluded that collateral damage caused by
an evasion tool should be the ultimate criterion for evasion,
arguing that a censor will not block a technology viewed as
economically or politically indispensable to the regime.
Leberknight et al. [73, 74] classify evasion tools and ex-
amine the relationship between a tool’s classiﬁcation and its
The GFW’s DPI came with a twist, however: The operators
916916
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:11:18 UTC from IEEE Xplore.  Restrictions apply. 
lifespan. Their study grouped 15 tools into general types:
HTTP proxy, CGI proxy, rerouting, IP tunneling, and dis-
tributed hosting. Examining the lifespan of these tools and
when new censorship technologies arose, they conclude that
users gravitate toward the fastest unblocked approach Their
work does not however develop corresponding measurements
or delve into the technical issues of blocking and evasion.
By applying common methods to assessing circumven-
tion technologies in their environment, these empirical works
(i.e., [53, 55, 72–74]) assessed the success of deployed ap-
proaches. However, researchers and developers need criteria
applicable to undeployed approaches. They must carefully
select which proposals to develop and deploy due to the
costs associated with such eﬀorts. For this reason, we aim
to understand how censors operate in order to predict which
approaches will perform well if deployed.
Others have provided deﬁnitions of success or lists of
criteria for circumvention approaches to fulﬁll. For exam-
ple, Dingledine enumerates general properties that make for
good evasion approaches [56]. While he presents anecdo-
tal evidence, his work does not systematically explore the
capabilities of censors to justify his criteria. Pﬁtzmann and
Hansen provide deﬁnitions of security properties, such as
undetectability, unobservability, and unblockability, but they
do not ground these using empirical observations [75].
Houmansadr et al. [1] and Geddes et al. [76] empiri-
cally evaluate the vulnerability to blocking of a selection
of mimicry-based approaches. We compare these evaluation
methods to real-world attacks in Section VII.
IV. Censorship As Practiced
In this section we examine censorship as practiced today
more broadly than our previous sketch of Tor and China.
We seek to illuminate the capabilities and limitations of
current censors, with important implications for designing and
evaluating eﬀective approaches to circumvention.
We develop our knowledge of today’s censors from two
sources: measurement studies of censors, and reports from the
ﬁeld about actual blocking events.
We ﬁnd little empirical analysis in the literature regarding
how real censors block circumvention. Thus, we focus on
collecting and organizing ﬁeld reports, ﬁrst for Tor, followed
by those about other deployed approaches.
A. Measurement Studies
We examined 31 measurement studies [70, 77–106]. Ta-
ble I provides an overview of what they show about such
censorship. The majority of the papers assessed censorship
of non-circumventing traﬃc. At the end of this subsection, we
consider those that did look at the censorship of circumventing
traﬃc.
Studies documented censors disrupting traﬃc by injecting
fake DNS replies [81, 92], sending forged TCP Resets [79,
80, 83, 91], actively probing a suspicious protocol [70, 82]
and using URL ﬁltering systems, such as Blue Coat [95],
Netsweeper [101], and SmartFilter [102]. While some have
conjectured that the GFW uses machine learning based upon
917917
Censor’s capabilities
Seen
DNS injection
HTTP injection
TCP RST injection
Packet dropping
Stateless
Stateful
Packet reassembly
Using Netsweeper
Using Blue Coat
Using SmartFilter
China 2007 [105], 2011 [89], China 2014 [92];
Pakistan 2010 [107], 2013 [81]; Iran 2013 [80]
Pakistan 2013 [81]
China 2006 [83], China 2010 [90]
Iran 2013 [80], China 2015 [77],
China 2002 [78], 2006 [83]
China 2007 [85], China 2012 [88], China 2013 [79]
China 2013 [79]
Pakistan 2013 [101], Qatar 2013 [102],
UAE 2013 [102], Yemen 2013 [102]
Syria 2011 [96, 108]; Burma 2011 [102];
UAE 2013 [102], Qatar 2013 [102]
Iran 2004 [109], Qatar 2013 [102],
Saudi Arabia 2012 [102], UAE 2013 [102]
Censor Capabilities as Found in Prior Measurement Studies of
Non-circumventing Traffic
TABLE I
their interactions with it (e.g., [110]), we know of no rigorous
studies suggesting such. A few papers also examined reverse-
engineering the internal structure of censors [79, 83, 92].
In-path vs. On-path. Censorship system can operate in-path or
on-path. An in-path monitor is a forwarding element between
two networks through which all traﬃc must ﬂow, such as
Syria’s and Qatar’s employment of Blue Coat [102]. An on-
path monitor passively examines passing traﬃc and can inject,
but not remove, packets, such as China’s GFW [91].
Each type of censorship system has advantages and lim-
itations. On-path censors cannot conduct exploits requiring
dropping packets (e.g., “packet dropping” [76]). On the other
hand, in-path censors face exacerbated processing challenges
due to the need to process all traﬃc at line rate lest the monitor
introduces a performance bottleneck. Accordingly, attacks that
rely on analyzing distributions of features (for example) could
prove diﬃcult to perform for an in-path monitor.
Stateless vs. Stateful. Stateless censors process packets indi-
vidually, or at most perform limited packet reassembly. As
such, circumventors can evade them by splitting sensitive
strings into multiple packets. Stateful censors track transport-
layer signalling and perform packet reassembly, with a corre-
sponding processing and memory burden. The GFW operated
in a stateless fashion before 2007 [78, 83], but stateful as of
2007, conﬁrmed in 2013 [79, 85], indicating a system upgrade.
Whitelist vs. Blacklist. The majority of the censors use a
blacklist
to ﬁlter disallowed contents. We noted only two
incidents of whitelisting based censors: Iran in 2013 [63, 80]
and Tunisia in 2009 [63]. Aryan et al. studied censorship
in Iran in 2013 [80] when non-whitelisted protocols were
throttled. They found SSH ﬁle transfers got throttled to around
15% of its standard bandwidth and an obfuscated protocol,
similar to the Tor’s Obfsproxy protocol,1 got throttled to near
zero at about 60 seconds into the connection.
Blocking Timeline. Censors have particular motivations for
censorship, which the onset of censorship can illuminate.
For example, China and Iran increase censorship activity to
1The paper did not test any real circumvention protocol but used simple
obfuscation approach, for example, XORing packet payloads with a predeﬁned
key, to obfuscate the SSH ﬁle transfer including the unencrypted portion of
the handshake.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:11:18 UTC from IEEE Xplore.  Restrictions apply. 
reduce political chaos, leading to blocking of circumvention
systems before or during political events [111]. Aryan et al.
studied Iranian censorship before the June 2013 presidential
election and discovered that Iranian censors only allowed a
small number of whitelisted protocols [80]. Such patterns of
employment suggest that circumvention approaches that can
distribute sets of new identiﬁers or new protocols only during
critical times might succeed by denying the censors suﬃcient
time to detect and block all of them.
Censorship of Circumvention. Winters and Lindskog studied
the active probing by China that sends requests to suspected
nodes to identify and block Tor when using its “Obfs2”
circumvention extensions (“pluggable transports”) [82], and
Ensaﬁ et al. studied the extension of active probing to Tor’s
Obfs3 transport [70]. Distinguishing the censor’s probes from
real users can prove challenging, as at least for China the
censor draws upon a large number of IP addresses to originate
the probes.
Ensaﬁ et al. [103] studied reachability of Tor relays and
directory authorities from China. Using “SYN backlog” scan-
ning, they conﬁrmed the GFW blocks access to Tor relays
and directory authorities by dropping their SYN/ACK replies
to clients.
From the leaked logs of Blue Coat deployed in Syria in
2011, Chaabane et al. found censorship of less that 2% of
requests to the Tor network, but heavy censorship of other
circumvention services such at Hotspot Shield [96].
We ﬁnd it striking that just four papers have examined the
censorship of circumvention approaches:
Research Gap 1. Little research has examined how real
censors exploit vulnerabilities in circumvention approaches,
leading to a dearth of realistic censor models.
B. Tor
To partly address Gap 1, we conducted and analyzed a
survey of prior ﬁeld reports on the blocking of deployed
approaches. The story of Tor and the GFW in Section II
forms a part of this larger analysis. Table II summarizes the
censorship incidents we found and what we know about them.
The table is based upon ﬁeld reports primarily coming from
Tor advocates, developers, and users in the form of bug reports,
blog posts, presentations, and comments. We undertook a
comprehensive study of Tor’s blog and bug tracker to ﬁnd
as many censorship-related reports as possible. We collected
747 blog posts and 13,337 bug-tracker reports from 12/2007
to 3/2015. We seeded a list of known censorship events with
9 blog posts and 11 bug reports [63]. Finding that grep-
style searches yielded too many false positives, we used these
manually labeled instances as a training set for a supervised
machine-learning classiﬁer, which found an additional 5 bug
reports and 11 blog posts about speciﬁc censorship events.
We associate each event with its target (Tor, in most cases),
as well as with the steps that make up the censor’s attack.
Some steps are vague because of a lack of documentation;
for instance some are simply “Block” because we do not
know exactly how the block was eﬀected. Each step of an
attack corresponds to some sort of detection, or an action
918918
taken based on a previous detection. Attacks can span multiple
phases in the use of a circumvention approach. We observe a
common pattern of the dynamic detection of traﬃc destined
for a forwarder, followed by blacklisting of the forwarder’s
address to prevent any future communication.
In general, we see a progression from simple to more
complex on the part of both censor and circumventor. Thailand
blocked the www.torproject.org website in 2006 [63]. In 2007,
Saudi Arabia [63] and Iran [115] began blocking HTTP
requests with the string “/tor/” in the URL, intending to block
communication with the Tor directory authorities.
DPI against the Tor protocol itself came only later, but
took a variety of forms. Examples include checking for Tor’s
characteristic TLS renegotiation (Syria in 2011 [63]); checking
for a speciﬁc Diﬃe-Hellman parameter during key negotiation
(Iran in January 2011 [116]); measuring the TLS certiﬁcate
lifetime (Iran in September 2011 [118]); and checking for
speciﬁc TLS cipher suites (Ethiopia [130], Kazakhstan [125],
the UAE [129], and the Philippines [126] in 2012).
Tor is occasionally caught up in more general censorship.
In 2009 Tunisia blocked all but a few TCP ports [63]. Only re-
lays running on those ports remained accessible. Throttling—
deliberate slowing—of encrypted traﬃc took place in separate
incidents in Iran in 2009, 2011–2012, and 2013 [63, 131].
Even more extreme, Egypt [132] and Libya [133] in 2011 and
Syria [134] in 2012 completely disabled Internet access for
a period of days or weeks.
(We elide such total-censorship
events from Table II.)
That instances of complete network blocking are rare and
short-lived highlights an important general principle. Censors
could prevent all circumvention by permanently disabling the
network—but
they do not, because Internet access brings
general beneﬁts that outweigh the harm of circumvention.
The censor would prefer, ideally, to block forbidden sites
and circumvention traﬃc, and nothing else. The purpose of
circumvention is to make it diﬃcult for the censor to distin-
guish these cases, thereby forcing the censor to allow some
circumvention traﬃc (underblocking), or else block some non-
circumvention traﬃc (overblocking), resulting in collateral
damage. The higher the costs of overblocking, the more likely
the censor will tend towards underblocking.
C. Approaches Other Than Tor
We also collected reports of censorship events against other
deployed approaches. We ﬁnd these harder to come by since
most approaches do not oﬀer as much public documentation as
Tor does. Thus, here we oﬀer not a comprehensive overview
but illustrations of real censorship incidents that highlight
additional facets regarding the operation of real censors.
Popularity-Driven Blocking. VPN Gate launched in March
2013 and quickly accrued over 5,000 unique clients from
China [32]. Only three days after launch, and presumably as a
result of this sudden popularity, the Great Firewall blocked the
VPN Gate website and its central database of relay servers.
Soon after, Chinese censors began crawling the database of
servers more than once a day to maintain an up-to-date
blacklist.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:11:18 UTC from IEEE Xplore.  Restrictions apply. 
Event
Target
Steps
China 2008a [61]
China 2008b [61]
China 2009a [62, 63]
China 2009b [62, 63]
China 2010 [63, 66]
China 2011/10 [63, 67, 70,
82, 112, 113]
Tor
Tor
Tor
Tor
Tor
Tor
China 2013/01 [70, 113]
Tor+obfs2
China 2013/07 [70]
Tor+obfs3
Ethiopia 2012/06 [114]
Iran 2007 [63, 115]
Iran 2009 [63, 115]
Iran 2011/01 [63, 116]
Iran 2011/10 [63, 117]
Iran 2011/09 [63, 118]
Iran 2012/10 [119]
Iran 2012/11 [119]
Iran 2012/02a [120, 121]
Iran 2012/02b [120]
Iran 2012/02c [120]