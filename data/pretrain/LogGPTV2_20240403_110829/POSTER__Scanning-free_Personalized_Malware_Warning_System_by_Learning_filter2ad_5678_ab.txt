u , wj ∈ W \ W +
u
Here W +
u represents the set of infected malware for the user
u. For each user, BPR optimizes the pairwise error between
infected and uninfected malware for personalized ranking.
To adopt the scenario of malware ranking, we model the
probability that a malware wi really has higher risk than wj
for a user u according to the BPR optimization criterion [5]
as follows:
P (r(u, wi) > r(u, wj)) =
1
−(ˆr(u,wi)−ˆr(u,wj ))
.
1 + e
Here ˆr(u, wi) is the predicted risk of wi for the user u. Hence,
we can learn the model by maximizing the log-likelihood
over the training data DS and estimating parameters. The
maximizing procedure is converted to solve the objective as
follows:
(cid:16)
1 + e−(ˆr(u,wi)−ˆr(u,wj ))(cid:17)
ln
(cid:88)
+
1
2
||U||2+
||W||2.
1
2
min
(u,wi,wj )∈DS
The latter two terms in the equation are L2 regularization
for reducing overﬁtting. Because the number of possible un-
infected malware wj is large, the sampling techniques are
utilized in the training procedure. Therefore, we can op-
timize the malware ranking for each user.
It can also be
considered as involving the prior probabilities for model pa-
rameters in a Bayesian view. The results of BPR with MF
are denoted as BPR-MF in this paper.
3.3 Hybrid Prediction
Both MF and MPP have their advantages in diﬀerent
cases. Hybrid prediction aims to predict values by aggregat-
ing predictions of two proposed methods. As two kinds of
predictions are in diﬀerent scales, they need to be standard-
ized before aggregation. We estimate the mean value and
standard deviation to standardize predictions. For example,
the standardized value of MF predictions can be calculated
as follows:
stdMF(u, w) =
ˆr(u, w) − ˆµu
,
ˆσu
where ˆµu and ˆσu are mean and standard deviation estimated
by predicted values for the user u. The standardized MPP
predictions can be calculated similarly. Then we can aggre-
gate predictions of two methods as:
Hybrid(u, w) = α · stdMF(u, w) + (1 − α) · stdMPP(u, w),
where 0 ≤ α ≤ 1 is a parameter determining the weights of
two methods. Note that when α = 1 the hybrid prediction
is identical to the MF method, and when α = 0 the hybrid
prediction is identical to the MPP method. The results of
hybrid prediction are denoted as Hybrid.P in this paper.
4. EXPERIMENTS
Our experimental data comprises malware detection logs
provided by Trend Micro between 6 June, 2013 and 10 June,
2013. For some rare malware and users, we remove some
entries such that every user and malware has at least ﬁve
entries. After ﬁltering, there are 292,113 users and 13,781
malware in 1,880,212 detection entries. We separate detec-
tion entries into two datasets with the same size, training
data Strain and testing data Stest. After separating, there
are 939,658 entries in Strain and 940,554 in Stest. For each
user u, every method will give a ranking to all malware which
did not infect the user u in Strain. Our aim is to measure
how a method can rank infected or potential malware with
a higher position. With the ground truth in Stest, we eval-
uate the quality of rankings with two evaluation measures,
including mean reciprocal rank (MRR) and Normalized Dis-
counted Cumulative Gain at position k (NDCG@k). MRR
evaluates the position of the ﬁrst infected malware in the
ranked list. NDCG@k evaluates the overall performance of
top-k predictions. While calculating NDCG values, the in-
fected malware will be given score 5, and the uninfected ones
gain 0. Instead of using MAP as the evaluation measure, we
utilize NDCG because the false alarms (i.e., uninfected pre-
dictions) should be penalized.
Table 1 shows the performance of methods. BPR-MF out-
performs the MPP baseline in MRR and NDCG at latter po-
sitions. MPP is better than BPR-MF in NDCG@1, which
represents the accuracy of the ﬁrst prediction. The reason is
that popular malware infects most users. However, less pop-
ular malware cannot be predicted well by MPP, thus MPP
is worse than BPR-MF in other measures. Aggregating the
beneﬁts of two methods, hybrid prediction has the best per-
formance in all measures. The high MRR value shows that
the ﬁrst infected malware is ranked in top-2 positions av-
eragely for each user. The NDCG results also show our
approach has good performance in general predictions.
Table 1: Performance Comparison of Methods, K
means the dimension of latent factors and α means
the parameter in the hybrid prediction.
Method
MRR
NDCG@1 NDCG@5 NDCG@10
MPP (Baseline)
0.5763
0.4667
BPR-MF (K = 5)
0.5825
BPR-MF (K = 10)
0.5855
0.4288
0.4381
0.2524
0.3013
0.3096
0.2603
0.3225
0.3277
BPR-MF (K = 15)
0.5898
0.4390
0.3110
0.3310
Hybrid.P (α = 0.8)
0.6245
0.5010
0.3154
0.3380
Then we analyze the aggregation of two methods in the
hybrid prediction. Figure 1 shows the performance of MRR
and NDCG@1 with diﬀerent α in the hybrid prediction. Re-
call that when α = 0 the hybrid prediction is identical to
MPP, and when α = 1 the hybrid prediction is identical
to BPR-MF. The lager α for BPR-MF generally results in
better performance. It implies that BPR-MF is more im-
portant in aggregation, but MPP still beneﬁts the overall
performance in both MRR and NDCG in the hybrid predic-
tion model.
5. CONCLUSIONS AND FUTURE WORK
In this paper, we ﬁrst present a framework for personal-
ized malware warning system by matrix factorization tech-
niques of collaborative ﬁltering. Furthermore, we propose
Figure 1: The performance of MRR and NDCG@1
with diﬀerent α in the hybrid prediction.
the hybrid prediction method aggregating popularity-based
approach and matrix factorization approach. The meth-
ods are evaluated by real-world malware detection logs and
have convincing performance for discovering infecting mal-
ware for users individually. Our future work is to combine
more meta-data of users and malware into current methods.
6. REFERENCES
[1] F. Cohen. Computer viruses: theory and experiments.
Computers & security, 6(1):22–35, 1987.
[2] M. Egele, T. Scholte, E. Kirda, and C. Kruegel. A
survey on automated dynamic malware-analysis
techniques and tools. ACM Computing Surveys
(CSUR), 44(2):6, 2012.
[3] Y. Koren, R. Bell, and C. Volinsky. Matrix
factorization techniques for recommender systems.
Computer, 2009.
[4] R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. Lukose,
M. Scholz, and Q. Yang. One-class collaborative
ﬁltering. In Proceedings of the Eighth IEEE
International Conference on Data Mining, 2008.
[5] S. Rendle, C. Freudenthaler, Z. Gantner, and
L. Schmidt-Thieme. BPR: Bayesian personalized
ranking from implicit feedback. In UAI ’09, pages
452–461, 2009.
[6] K. Rieck, P. Trinius, C. Willems, and T. Holz.
Automatic analysis of malware behavior using
machine learning. Journal of Computer Security, 2011.
[7] X. Su and T. M. Khoshgoftaar. A survey of
collaborative ﬁltering techniques. Advances in
artiﬁcial intelligence, 2009.
[8] P. Szor. The art of computer virus research and
defense. 2005.
[9] G. Tahan, L. Rokach, and Y. Shahar. Mal-id:
Automatic malware detection using common segment
analysis and meta-features. JMLR, 2012.
[10] Y. Ye, D. Wang, T. Li, and D. Ye. Imds: Intelligent
malware detection system. In Proceedings of the 13th
ACM SIGKDD international conference on Knowledge
discovery and data mining, pages 1043–1047. ACM,
2007.
00.20.40.60.810.580.590.60.610.62αMRR  00.20.40.60.810.440.460.480.5NDCG@1MRRNDCG@1