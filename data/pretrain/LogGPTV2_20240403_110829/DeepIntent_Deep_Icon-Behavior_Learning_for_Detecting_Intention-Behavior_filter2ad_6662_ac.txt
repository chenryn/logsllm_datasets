vector. We concatenate forward and backward feature vectors into
the overall feature vector for an input word, i.e., hi = [‚Éóhi; ‚Éóhi]. By
setting the maximum length of text to N , we can obtain N feature
vectors of the text as fv = [h1, .., hN ] where hi ‚àà Rd. For text
feature initialization, we can also directly adopt word embedding
models [49, 57]. However, such models tend to ignore the order of
the words in the sentence. In this work, we set d = 100 and N = 20
as the length of most surrounding texts are within this limitation.
5.4 Feature Combination
With the extracted icon features and text features, we next combine
them to obtain the joint feature vectors. The key idea is to apply the
parallel co-attention mechanism [47, 90] to bidirectionally update
the icon features and text features with the guidance of each other,
as shown in Figure 8 (c). Take the direction from icon features to
text features as an example. Here, the attention improves the text
feature vector by highlighting the words that are relevant to the
image.
fv, we first define the correlation matrix C ‚àà RN√óM as follows,
Specifically, with the extracted icon features fu and text features
v Wc fu )
C = tanh( f T
(3)
where Wc ‚àà Rd√ód contains the parameters to be learned. Note
that, there are M regional feature vectors for an icon and N fea-
ture vectors for its text. Consequently, this C matrix contains the
similarities/correlations between M √ó N pairs of feature vectors.
Based on the above correlation matrix, we can connect the icon
features and text features by transferring the features for each other.
In particular, we use the following equations to update the icon
features with the guidance of text features,
Hu = tanh(Wu fu + (Wv fv )C)
au = so f tmax (WhHu )
Àúfu =
u f (i )
(a(i )
u )
MX
i =0
(4)
where Àúfu ‚àà Rd contains the updated icon feature vector, Wv ,Wu ‚àà
Rk√ód ,Wh ‚àà R
1√ók are parameters, and k is the dimension size of
these parameters. In the above equations, Hu ‚àà Rk√óM stands for
the feature matrix obtained by transforming the text features (i.e.,
fv) into icon features through the correlation matrix C, and au
stands for the importance/weights of each regional feature vector
to the final icon feature vector. Analogously, we can update the text
features from fv to Àúfv and the equations are omitted for brevity. In
practice, we update the icon features and text features in parallel.
With the updated icon features and text features, the combined
feature vector f ‚àà Rd for an icon and its text is computed as follows.
(5)
f = Àúfu + Àúfv
5.5 Training
Given the above design, the next step is to train the icon-behavior
model to connect the features to the used permissions. We formulate
it as a multi-label prediction problem to allow one icon to match
multiple permissions. Since the prediction of each permission can be
(a) Icon feature extraction.
(b) Text feature extraction.
(c) Feature combination.
Figure 8: Structure of the icon-behavior model.
Therefore, we design our own DenseNet with 4 channels (RGBA)
to extract icon features, as shown in Figure 8 (a). Our DenseNet
starts with a convolutional layer, followed by four dense blocks
and three transition layers between these dense blocks. For all the
icons, we resize them to 128 √ó 128 (most icons are within this size).
For an icon u, the output of our DenseNet is a 16 √ó 16 √ó 68 tensor,
which means that there are M = 16 √ó 16 regions of the icon each of
which is represented via a du = 68 dimensional vector, i.e.,
fu = DenseN et (u),
(1)
128√ó128√ó4 is the color tensor of the input icon (with
where u ‚àà R
width 128, height 128, and channel number 4), and fu ‚àà Rdu√óM
contains M regional feature vectors each of which is of du dimen-
sion. In practice, we further add a fully connected layer after the
DenseNet to convert each regional feature vector into a new vector
that has the same dimension with the text feature vectors.
5.3 Text Feature Extraction
To initialize the text features, we employ the state-of-the-art bidirec-
tional RNNs to extract the text features, whose structure is shown
in Figure 8 (b). For an input text v, i.e., a sequence of words, we
first embed each word into a vector vi, and then feed these vectors
into the RNNs with GRU neurons [10],
‚Éóhi = GRU (vi , ‚Éóhi‚àí1)
‚Éóhi = GRU (vi , ‚Éóhi +1)
(2)
Input IconDenseNetùë¢Dense BlockTransition LayerDense BlockConvolution‚Ä¶‚Ä¶√ó3ùëìùë¢sendsmsnormaltextInput TextBidirectional RNNEmbeddingùë£ùëìùë£‚Ä¶‚Ä¶‚Ä¶ùê∂ùëìùë¢ùëìùë£‡∑©ùëìùë£‡∑©ùëìùë¢ùëìIcon Feature and Text FeatureCo-Attentionpermission group. Note that we exclude certain permissions (e.g.,
READ_PHONE_STATE and permissions in the SENSORS and CALL_LOG groups)
since these permissions are not evident to the users through UIs
(e.g., READ_PHONE_STATE) or rarely appear in the collected apps (e.g.,
ANSWER_PHONE_CALL). We also add the NETWORK group for network com-
munications as some apps may disclose users‚Äô data. Then, we use
group-wise outlier detectors to compute the group-based outlier
scores through each used permission. For example, the example
icon in Figure 9 uses only the SMS permission. Then, the outlier
detector corresponds to this permission group will be activated.
Next, as one icon may be related to multiple permission groups,
we aggregate the group-based outlier scores to form the the final
outlier score. Here, a key step is to compute the weights of each
group-based outlier score. The final outlier score reflects the overall
likelikood of intention-behavior discrepancy for the input test icon.
6.2 Computing Group-Wise Outlier Score
There exist several choices for the group-wise outlier detector, in-
cluding KNN [59], OCSVM [65], IForest [44], and AutoEncoders [3].
We empirically found that the performances of these detectors are
relatively close to each other (Section 7.3.3). Therefore, we adopt
the AutoEncoder structure for simplicity, which is known to be an
effective replacement of traditional methods for the outlier detec-
tion problem [3]. The key idea of AutoEncoder is to first reduce the
dimension of the original feature and then reconstruct it, i.e.,
–¥ = reduce ( f )
‚Ä≤ = reconstruct (–¥)
f
(6)
where f ‚àà Rd is the original feature vector from the icon-behavior
model, –¥ is the reduced feature vector, and f ‚Ä≤ ‚àà Rd is the re-
constructed feature vector for f . Specially, we implement reduce
and reconstruct with two fully-connected layers, respectively. The
learning process is then guided by minimizing the reconstruction
error, i.e.,
min
f (j ) ‚àí f
.
(7)
(cid:16)
dX
j=1
‚Ä≤(j )(cid:17)2
We train one AutoEncoder for each permission group, with the
icons from benign apps (the same input with the icon-behavior
learning). Then, for a test icon, the reconstruction error of the cor-
responding AutoEncoder is used to indicate the outlier score for
each permission group. The intuition is that normal icons in the
same permission group can be easily reconstructed while the recon-
struction of anomalies would be relatively difficult. To be specific,
suppose the test icon uses a permission in the i-th permission group,
and f ‚Ä≤
is the reconstructed feature vector in the i-th corresponding
i
AutoEncoder. Then, si = ( f ‚àí f ‚Ä≤
2 is used as the outlier score for
i )
this permission group.
6.3 Computing Final Outlier Score
Given that there are n permission groups with scores [s1, s2, ..., sn],
the remaining problem is to aggregate these scores into a final
outlier score s. In this work, we consider the following three aggre-
gation methods. Note that the computations of all the following
aggregation methods are based on the output of the learned icon-
behavior model.
Figure 9: Workflow of detecting intention-behavior discrep-
ancy.
formulated as a binary classification problem, we use the sigmoid
function in logistic regression [29] to predict whether the icon
matches each of the permissions. Next, since multiple permissions
used by an icon can be treated as a probability distribution, we
employ the binary cross entropy [21] as our loss function to measure
the differences between the predicted permissions and the real ones
obtained by our static analysis. The detailed equations are omitted
for brevity. With the trained icon-behavior model, we can easily
obtain the joint feature vector f of a test icon by feeding its icon
image and contextual text into the model.
6 DETECTING INTENTION-BEHAVIOR
DISCREPANCY
Based on the learned icon-behavior model, we next detect the icon-
behavior discrepancies via identifying the permission-based out-
liers. For example, if the feature vector of an icon is far away from
that of normal icons with the same permissions, there might be a
mismatch between the icon intention and its behavior. Although
we can directly use the icon-behavior model to predict the permis-
sion uses for each icon and then detect the outliers based on the
prediction results, we deliberately add an outlier detection module
for the following two reasons. First, directly using the prediction
results would be less accurate as neural networks are inherently
probabilistic, especially considering the fact that there might exist
some intention-behavior discrepancies in the training data. Instead,
we try to make use of the learned low-dimensional features as these
features tend to be more robust [52, 94], which is also verified by
our experimental results. Second, our outlier detection module can
effectively make use of the prediction results from the learned icon-
behavior model. For example, if the icon-behavior model predicts
that the test icon should use a certain permission, the test icon is
less likely to be an outlier in this permission group.
6.1 Outlier Detection Overview
The overview of the outlier detection module is shown in Figure 9.
Given a test icon and its contextual text from a new APK file, we first
extract its low-dimensional feature vector f based on the learned
icon-behavior model, and obtain its actual permission uses by static
analysis (Section 4). We organize the sensitive permissions into
permission groups based on the Android dangerous permission
groups [22] (see Table 2), and learn an outlier detector for each
Detecting Group-wise OutliersComputing the Final Outlier Scoredistance-based prediction-basedùë†1ùë†ùëõùë†2Features and Permissionssend smsSMSPermissionoutlier scorePermission Groups
Sensitive Permissions
NETWORK
INTERNET
CHANGE_WIFI_STATE
LOCATION
ACCESS_COARSE_LOCATION
MICROPHONE
SMS
CAMERA
CALL
STORAGE
CONTACTS
ACCESS_FINE_LOCATION
ACCESS_MOCK_LOCATION
RECORD_AUDIO
SEND_SMS
READ_SMS
WRITE_SMS
RECEIVE_SMS
CAMERA
CALL_PHONE
WRITE_EXTERNAL_STORAGE
READ_EXTERNAL_STORAGE
READ_CONTACTS
WRITE_CONTACTS
GET_ACCOUNTS
MANAGE_ACCOUNTS
Table 2: Sensitive permissions and permission groups.
AUTHENTICATE_ACCOUNTS
apps are flagged by at least 20 anti-virus engines on VirusTotal and
are further removed by app markets. For all the apps, we apply our
icon-behavior association techniques (Section 4) to obtain the triples
of ‚ü®icon, text, permissions‚ü©. We then divide these permissions into
8 permission groups as shown in Table 2. The distribution of the 8
permission groups is shown in Figure 10.
Next, to train the icon-behavior model, we randomly select 80% of
the triples from benign apps as training data, and use the remaining
20% of the triples from benign apps as a test set, i.e., benign test
set. The benign test set is used to evaluate the effectiveness of
DeepIntent in predicting permission uses based on the icons and
texts. To evaluate the effectiveness of DeepIntent in detecting
intention-behavior discrepancies, we further use all the triples from
malicious apps as the second test set, i.e., malicious test set. We also
apply DeepIntent on the benign test set to see whether there are
intention-behavior discrepancies in these benign apps.
Obtaining Ground-Truths. Since not all the permission uses in
malicious apps are abnormal, we need to collect the ground-truth
of intention-behavior discrepancies for icon widgets. We recruited
10 volunteers who are graduate students from computer science
and have been using Android phones for at least three years. We
then ask these volunteers to manually mark if there are intention-
behavior discrepancies based on the‚ü®icon, text, permissions‚ü© triples.
We define a discrepancy as an icon widget uses the permissions that
cannot be justified by the icons and texts in the UIs. Specifically, we
randomly selected 1500 triples from both test sets. Each triple is
assigned to two volunteers for them to mark independently. In
cases the two volunteers disagree with each other, we will ask an-
other volunteer to discuss with these two volunteers. If a consensus
cannot be reached, we will exclude this triple.
Overall, we obtain 7691, 1274, and 1362 unique triples that con-
tain sensitive permission uses in the training set, the benign test
Figure 10: Distribution of sensitive permission groups.
Distance-based aggregation. The first aggregation method is based
on the clustering degree of the neighbor icons near the test icon.
Here, the distance is computed based on the features learned from
the icon-behavior model in the vector space. The intuition is that
if the local neighborhood of a test icon is closely clustered, the
AutoEncoder should have been sufficiently trained in the neighbor-
hood; therefore, the ourlier score is more reliable. Here, we compute
the average distance among the T nearest neighbors of the test icon,
and use it to weight the group-based outlier scores as
s = s1/Av–¥Dis1 + s2/Av–¥Dis2 + ... + sn/Av–¥Disn,
where Av–¥Disi means the average distance among the neighbors
in i-th permission group. We normalize 1/Av–¥Disi to compute s.
Prediction-based aggregation. In the second aggregation method,
we integrate the predicted probabilities over the permissions for
a test icon from the icon-behavior model. The intuition is that if
the icon-behavior model predicts that the icon widget should use a
certain permission, the test icon tends not to be an outlier in this
permission group. Therefore, we have
s = s1 ‚àó (1 ‚àí p1) + s2 ‚àó (1 ‚àí p2) + ... + sn ‚àó (1 ‚àí pn ),
where pi is the probability of using the i-th permission (group)
predicted by the icon-behavior model.
Combined aggregation. Based on the above two aggregation meth-
ods, we also define a combined method by adding the two weights,
i.e.,
s = s1 ‚àó (1 ‚àí p1 + 1/Av–¥Dis1) + ... + sn ‚àó (1 ‚àí pn + 1/Av–¥Disn ).
7 EVALUATION
We evaluate DeepIntent on a large number of real world apps.
Specifically, we aim to answer the following research questions:
‚Ä¢ RQ1: How effective is the co-attention mechanism for icons and
‚Ä¢ RQ2: How effective is icon-behavior association based on static
‚Ä¢ RQ3: How effective is DeepIntent in detecting intention-behavior
analysis in improving icon-behavior learning?
texts in improving icon-behavior learning?
discrepancies?
7.1 Evaluation Setup
To evaluate DeepIntent, we collected 9,891 benign apps and 16,262
malicious apps. The benign apps are downloaded from Google Play,
and we further send them to VirusTotal to ensure that no anti-virus
engines flag them as positive. We resort to Wang et al. [77] and
RmvDroid [2, 78] to collect the up-to-date malicious apps. These
NETWORK61%LOCATION21%MICROPHONE4%SMS4%CAMERA3%CALL1%STORAGE2%CONTACTS4%OTHER7%Metric
Precision
Recall
F1
Method
IconIntent
icon_only
text_only
concatenate
add
co-attention
IconIntent
icon_only