Protocol 8: Once L receives a validated SRR from E, it posts a
signature on the hash of SRR to BC as acknowledgment. L then
asks C to hand over KCI to be able to decrypt I’s encrypted emails
in SRR and conduct surveillance.
Protocol 9: This is not a part of the regular workflow of SAMPL
and is optionally executed by members of U on an as needed basis.
It can be implemented using smart contracts. In Protocol 9, any
member(s) of a set of watchdog organizations, u ∈ U (e.g., ACLU),
who monitor the BC, can contact J whenever an SO expires and
retrieve KJ LC , KE J LC. Entity u decrypts the SO (P1 and P2), verifies
signatures (P3), and can contact I who was surveilled. I, u can then
investigate and verify the validity of reason for surveillance, if due
2256
Algorithm 7: E verifying SRR received from C.
: SRR received from C.
Input
Output:Accept or reject SRR.
1 E retrieves SR from SRR, and verifies signature σ E
SR
2 for each Cx ∈ SRR; x ∈ [1..bSize] do
on BC.
posted
3
4
5
E confirms that Cx is dated within time period ι from
the SR.
E computes H(Cx), runs RbNum ←
rootCompute(Cx ||siblingHashes(Cx)||bNum), and
checks “true” ?
= Verify(V KPIj , RbNum, σRbNum).
Finally, E verifies ZKP for V KPIj
with given (σAI||πAI||σPIj ||πPIj ||д||zkpVerf ).
used to sign σRbNum
6 end
7 If E accepts SRR, a confirmation is posted on BC. Since all
BC transactions are signed, we denote the corresponding
transaction signature as σ E
; and SRR is forwarded to L,
SRR
who handles it as described in Protocol 8.
8 If E rejects SRR, it notifies J, C and SRR is not sent to L. It
also stores evidence of the reason for rejection, which will
be provided to J, C upon request.
Protocol 8: L on receiving validated SRR from E.
Input
Output:Surveillance carried out by L.
Parties : L and C.
:Verified SRR received by L from E.
1 L receives SRR, and posts a signed hash of SRR to BC as
2 L gets KCI from C to decrypt I’s emails (Cx ’s contained in
acknowledgment of SRR received.
SRR), and carry out surveillance.
Protocol 9: Protocol run by members of U.
Input
Output:u checks adherence to protocol by parties involved
:SO posted on BC.
in surveillance in relation to SO and follows up
with J.
E:
Parties :u ∈ U and J.
/* Whenever there is a message posted on BC by
*/
1 u ∈ U checks the signatures of the hashes posted.
/* Whenever an SO expires according to ι ∈ [ts , te]
*/
2 u contacts J and retrieves KJ LC , KE J LC. u decrypts P1, P2
posted on BC:
and verifies P3 of the SO.
diligence was applied, and lawful procedures were followed during
surveillance.
6 APPLICABILITY: CASE STUDY OF U.S.
LEGAL SYSTEM
In this section, we discuss how our system can be instantiated and
adapted in a real-world legal system to provide accountability. We
consider the U.S. legal system as an example, and discuss our system
within its constitutional and jurisdictional parameters. SAMPL can
be modified to be applicable to legal systems in other countries.
6.1 Different Authorization Paths
The U.S. constitution provides several authorization paths for law
enforcement agencies to obtain permission to conduct surveillance,
some with judicial oversight, some without. We discuss them below.
Electronic Communications Privacy Act (ECPA): ECPA was
created by the U.S. Congress in 1986 [17] to elucidate the boundaries
of government surveillance on citizens, and clearly define the ways
and means by which government surveillance can be conducted.4
ECPA can be used by federal law enforcement agencies to obtain
information about users’ emails in transit, emails at rest, phone calls,
location data, and more. ECPA provides law enforcement agencies
two methods of accessing users’ information: via warrant, or via
subpoena. A subpoena is a court order demanding that someone
or something be provided to assist in a case. For issuing a warrant,
the law enforcement agency must show the issuing judge probable
cause that a crime has been, or will be committed. Most warrants are
unsealed when charges are filed against someone, and the defendant
has the right to see the evidence collected against them before the
trial.
Per ECPA statute 18 U.S.C. §2616 [3] and statute 18 U.S.C. §2703 [4],
emails in transit, emails in storage on home computer, and un-
opened emails in remote storage stored for ≤ 180 days all need
a warrant for law enforcement access. Opened emails in remote
storage, and unopened emails stored for > 180 days only need a
subpoena for law enforcement access.
Our system can be deployed in a straightforward manner in
both cases, as described in Section 5, where the SO written to the
blockchain by J can be either a subpoena or a warrant. The SR
and the furnished data are all routed through the Enforcer, E, who
writes the data transfer success/failure to the blockchain BC for
auditing (refer Section 5).
National Security Letter (NSL): The USA PATRIOT Act §505 [36,
37] empowered the Federal Bureau of Investigation (FBI) to is-
sue a National Security Letter compelling companies to disclose
information about their customers for a national security-related
investigation. An NSL is typically issued to a company by a local
FBI field office and does not require judicial oversight. It can be
used to obtain meta-information about phone/email records, times,
length of service, network addresses, how a customer paid for ser-
vice; although the FBI cannot obtain actual content of phone/email
records. An NSL can also be used by the FBI to obtain financial
details, such as credit reports, and bank account details from banks,
credit unions and insurance companies. Any recipient of an NSL is
prohibited by law or “gagged” from disclosing their receipt of the
NSL, which makes oversight difficult. Additionally, the U.S. govern-
ment can seek judicial enforcement of an NSL in non-compliance
situations, under ECPA statute 18 U.S.C. §2709.
4There have been calls to reform ECPA, with several amendments to the law being made
over the years, such as the USA PATRIOT Act, among others. It has also faced criticism
for being outdated and not inclusive of many modern methods of communication,
since it was first codified in 1986. Nevertheless, as of this writing, ECPA with its
amendments is the law in the U.S. relating to surveillance processes. A full discussion
of proposals and avenues for future ECPA reform, and their possible consequences on
our system is out of the scope of this paper.
Session 9E: Web Censorship and AuditingCCS ’19, November 11–15, 2019, London, United Kingdom2257Since NSL does not require a judge, there is no J to post the SO to
BC. But L and C can still use SAMPL and hence E for auditability. L
would create an SO for the NSL, post it on BC, and then create an SR,
before sending it to E. E would then pass it on to C, after checking
that the SO and the SR does not request content of emails (which
is a legal restriction on NSLs). Note that E cannot check if an SO is
for a genuine national security issue, since U.S. law expressly gives
discretionary powers to the FBI while deciding to issue NSLs. But
what E can help check is if the SO and SR adhere to legal guidelines,
that is, the agency is only seeking meta-information. On receipt of
the SR from E, C will construct and return an SRR to E, who will
then verify it and send it to L.
Our pseudonymous identity scheme prevents E from learning
the actual identities of the users whose details were requested. As
discussed before, E writes the pass/fail result of the SR and SRR to
the BC. The legal/political feasibility of writing encrypted NSLs to
the BC is out of the scope of this paper.
Foreign Intelligence Surveillance Act (FISA): FISA was enacted
in 1978 and amended in 2008 by the U.S. Congress for the purposes
of surveillance related to foreign powers and persons [22]. Under
FISA, a person who is believed to be a foreign power, or spying
on behalf of a foreign power can be put under surveillance, even
if they haven’t engaged in any criminal activity. Over the years,
the ambit of FISA has gradually expanded to include electronic
surveillance, “roving wiretap” surveillance, pen-registers, and trap-
and-trace devices, per 50 U.S.C. Ch. 36 [5]. Additionally, FISA per-
mits warrantless surveillance5 up until certain time periods, beyond
which the agency conducting the surveillance needs to obtain a
warrant from a special court called the FISA court [23]. Although
the court maintains records of its proceedings, the FISA court’s
records are not available to the public.
Our system can be applied to the FISA ecosystem, which en-
compasses the court, and surveilling agencies which work with it,
such as the NSA. The FISA ecosystem operates with little to no
auditability (other than annual aggregate statistics published by the
court). Using our system, the FISA court judges will issue and post
an encrypted SO on the BC. The E can verify that the surveillance
is not conducted in wholesale or an overarching manner by agen-
cies, and only data that is pertinent to an ongoing investigation is
revealed by companies. In particular, our system allows indepen-
dent non-profit organizations (e.g., ACLU) to verify if due process
has been followed during FISA-authorized surveillance, even if the
actual court orders are never made public, without compromising
national security.
6.2 Law Enforcement Agencies Overreach:
Violations, “sneak peeks” and more
In the U.S. legal system, a government agency, e.g., FBI or NSA
is, in most cases, required to present a warrant to a company for
conducting surveillance on its customers, and conduct the surveil-
lance within the confines of the warrant. Unfortunately, in practice,
there are agency overreaches; we outline a few here. In 2018, the
NSA’s Office of Inspector General (OIG) in its first semi-annual
unclassified report to the U.S. Congress described the investiga-
tions and activities of the NSA [32]. Among other findings, the OIG
5One such program has recently come to light [41].
report found “several deficiencies that have the potential to impact
the protection of U.S. persons privacy rights,” in relation to FISA
investigations conducted by the NSA.
A report by the Department of Justice (DoJ) OIG found that
the FBI issued NSLs “contrary to statutory limitations," issued “im-
proper requests under the statute referenced in the NSL”, “obtained
information beyond the time period referenced in the NSL,” and
various other illegal uses of NSLs [1]. A partially redacted 300-page
report by the DoJ OIG [2] also found that the FBI acquired phone
call information regarding “hot numbers” without legal process,
made inaccurate statements to the FISA court, and improperly used
FBI administrative subpoenas. The OIG report also finds that the
FBI uses “exigent letters” and other informal requests for phone
records that do not comply with legal requirements or FBI policies
governing the acquisition of those records. The same report also
found the FBI has a practice of conducting “sneak peeks” for tele-
phone toll records in providers’ databases without due process, a
practice that violates the ECPA statute 18 U.S.C. §2702(a)(3).
All said, our system will help systematize a seemingly unpre-
dictable process that would help law enforcement agencies and
companies ensure that they follow the letter of the law with respect
to issuing and responding to surveillance requests respectively.
7 SECURITY ANALYSIS
We prove the security of our constructions in the well-known Uni-
versal Composability (UC) framework [12]. The UC paradigm el-
egantly captures the conditions under which a given distributed
protocol is secure, by comparing it to an ideal realization of the
protocol. To this end, the UC framework defines two “worlds”:
the real-world, where the protocol, π to be proved secure runs in
the presence of a real-world adversary, A. The other is the ideal-
world, where the entire protocol, ϕ is executed by an ideal, trusted
functionality, in the presence of a simulator, S, which models the
ideal-world adversary. All users only talk to an ideal functional-
ity via secure and authenticated channels, the ideal functionality
takes input from users, performs some computations in a possibly
interactive manner, and returns the output of the protocol. The
goal then is to prove that no distinguishing algorithm, commonly
called as “environment”, Z, can successfully distinguish between
the execution (EXEC) of the two worlds.
7.1 Design of Ideal Functionalities
We define an ideal functionality, FSurveil which encompasses all our
other functionalities and algorithms, and consists of four indepen-
dent ideal functionalities, FSurveil = (FSAMPL
, Finit, Fcreate, FBC).
Furthermore, we assume that FSurveil maintains internal state that
is accessible at any time to FSAMPL
, Finit, Fcreate, FBC. We describe
the functionalities of FSurveil, discuss some of their motivating
design choices, and give the proof of the following theorem in
Appendix B.
zk
zk
Theorem 7.1. Let FSurveil be an ideal functionality for SAMPL.
Let A be a probabilistic polynomial-time (PPT) adversary for SAMPL,
and let S be an ideal-world PPT simulator for FSurveil. SAMPL UC-
realizes FSurveil for any PPT distinguishing environment Z.
Session 9E: Web Censorship and AuditingCCS ’19, November 11–15, 2019, London, United Kingdom2258(a)
(b)
(c)
Figure 4: (a) Verification time of SRR by E for different surveillance durations (legends) at batch size of 32 messages, (b) Verification time of
SRR, batch size of 64 messages, and (c) Merkle tree computation time at C for different message sizes (legends) and batch sizes.
8 EXPERIMENTATION AND RESULTS
We evaluate the performance of SAMPL for scalability, and to bench-
mark the operations performed by different entities within SAMPL
with varying system parameters and surveillance requirements.
8.1 Experimental Setup
Four Desktop class machines with Intel(R) Core(TM) i7-6700K CPUs
and 8 GB RAM each were used to run our implementation of SAMPL.
Each of the machines ran a single entity in SAMPL: J, E, L, and
C, communicating over C Sockets. The entities were coded using
the C programming language and compiled with gcc version 7.3.0
(Ubuntu 7.3.0-27 ubuntu1 18.04). Our code, along with test data gen-
erators, and a small test database is available online [33]. Random
user data, for 500 users, was pre-generated and stored in an SQL
database (we use email as the representative application) at C. User
data was created for 120 days.
In our experiment, RI for a given user is tied to their real name
and each user has an AI tied to their name in the database, where
the AI is a key pair that is tied to the user’s PIi; i ∈ [1..m] using
ZKPs. We simulated with only a single PIi for each user’s data,
during the surveillance period. The cryptographic operations of
signing and verifying user data, and ZKP related operations were
prototyped using the Charm Cryptographic framework [7]. AES-
256 in GCM mode was used for the symmetric key encryption
involving KCI , KJ LC, and KEJ LC. For emulating the blockchain in
SAMPL, we used Ethereum [18]. Each entity ran its own Ethereum
node and communicated with the local blockchain network.
8.2 Metrics and Parameters
Separate simulations were run for 5, 10, 15, and 30 users in the SO
posted by J. The surveillance periods simulated were 5, 10, 20, and
50 days. These aforementioned values (number of users, days) were
chosen to demonstrate scalability in the event of concurrency. We
evaluate SAMPL using the following metrics:
(1) ZKP generation and verification time per user: The Prime192v1
Elliptic Curve was used as the prime order group G for ZKP as
described in Protocol 11.
(2) Merkle root generation and signing per user: Simulations were
run for batch-sizes with 16, 32, 64, 128, and 256, leaves in the tree
with message sizes set to 1 KB, 75 KB, 1 MB, and 2 MB.
(3) Enforcer Verification Time: Measured for 5, 10, 15, and 30 users,
batch sizes of 32 and 64 messages, and surveillance period of 5, 10,
20, and 50 days. The message size was set to 75 KB.
Verification of SR by E as depicted in Figure 1: Step 11, is not
quantified in the results because it does not involve complex cryp-
tographic operations. This step would incur a low computational
cost regardless of the number of AIs and duration of surveillance
in SR, as it only involves comparisons and range checks between
SR and the corresponding SO on BC.
8.3 Results
Table 2 reflects the ZKP verification and generation times per user
averaged over 100 runs. The generation time is calculated for the