Leveraging Log Instructions in Log-based Anomaly
Detection
Jasmin Bogatinovski∗, Gjorgji Madjarov‡, Sasho Nedelkoski∗, Jorge Cardoso† and Odej Kao∗
∗ Technical University Berlin, Berlin, Germany, Email: PI:EMAIL
† Huawei Munich Research, Munich, Germany
‡ University Ss Cyril and Methodius, Skopje, North Macedonia
Abstract—Artificial Intelligence for IT Operations (AIOps) rootcausesandremediatethem.ThediverseAIOpstechniques
describes the process of maintaining and operating large IT enable fast, efficient and effective prevention of upcoming
systems using diverse AI-enabled methods and tools for, e.g.,
failures,aimingtominimizetheirhazardouseffectsduringthe
anomaly detection and root cause analysis, to support the reme-
daily operational activities [1]. 2202
diation, optimization, and automatic initiation of self-stabilizing
IT activities. The core step of any AIOps workflow is anomaly In this paper, we focus on anomaly detection in the context
detection, typically performed on high-volume heterogeneous of AIOps, as a core step towards enhancing fault tolerance:
data such as log messages (logs), metrics (e.g., CPU utilization), the earlier an anomaly is detected, the more time is available
and distributed traces. In this paper, we propose a method for luJ
to prevent the failure and mitigate the impact on the QoS.
reliable and practical anomaly detection from system logs. It
We focus on system log messages (logs) as semantically rich
overcomes the common disadvantage of related works, i.e., the
need for a large amount of manually labeled training data, by data written by humans for humans. The logs allow a more 7
building an anomaly detection model with log instructions from insightfulanalysisandinterpretationthan,e.g.,metricdata[2].
thesourcecodeof1000+GitHubprojects.Theinstructionsfrom For example, a sharp increase in the network packet loss (a ]IA.sc[
diversesystemscontainrichandheterogenousinformationabout
commonlyusedmetricfornetworkmonitoring)onlyindicates
many different normal and abnormal IT events and serve as a
aproblemwiththenetwork,butitdoesnotprovideacluewhy
foundation for anomaly detection. The proposed method, named
ADLILog, combines the log instructions and the data from the it happens. In comparison, logs give semantically meaningful
systemofinterest(targetsystem)tolearnadeepneuralnetwork clues for the anomaly. For example, when a switch generates
modelthroughatwo-phaselearningprocedure.Theexperimental the log “System is rebooting now.”, the operator detects that
1v60230.7022:viXra
results show that ADLILog outperforms the related approaches
the switch is failing (potentially anomalous) and obtain a clue
byupto60%ontheF scorewhilesatisfyingcorenon-functional
1 that the potential anomaly is caused by switch rebooting.
requirements for industrial deployments such as unsupervised
design, efficient model updates, and small model sizes. Logsaregeneratedfromloginstructionsthatdevelopersin-
IndexTerms—anomalydetection,logdata,systemdependabil- sertinthesourcecode(e.g.,log.info(”VMtook%fsecondsto
ity, AIOps, deep learning spawn.”, createSeconds)) to visualise important system events
and to create hints for the operators that run the system as a
I. INTRODUCTION
black-box [3]. The log instructions are commonly composed
IT infrastructures in numerous application fields consist of of static text (log template), variable parameters of the event
thousands of networked software (microservices) and hard- (e.g., createSeconds), and log level giving information about
ware (e.g., IoT, Edge) components. The uninterrupted and the severity level of the event (e.g., ”info”, ”fatal”, ”error”).
correct interaction is crucial for the functionality of the over- Theloglevelscomeatdifferentgranularity,conditionedonthe
all system and the deployed applications. However, this IT usedprogramminglanguagesandlogginglibraries.Thelower
complexity combined with the required QoS guarantees (e.g. loglevelssuchas”info”areusuallyusedwhendescribingnor-
maximal latency) increasingly overwhelms the IT operators malstateorstatetransitions,e.g.,”Successfulconnection.”.In
in charge. The current trends of agile software development contrast,higherloglevelssuchas”error”,”critical”,or”fatal”
with hundreds of updates and daily deployments further ex- commonlyaccompanyeventsthatdescribeabnormalstatesor
acerbate the operational challenges. The holistic overview, state transitions, e.g., ”Machine failure”. Therefore, the log
operation, and maintenance of the IT infrastructure grow levels encode rich expert information for manual detection
even more challenging when additionally it is affected by of anomalous events, frequently used in today’s operational
unforeseen factors such as failures, software errors, security practices [3]. For example, to diagnose an anomaly, operators
breaches,orexternalenvironmentalevents.Companiesreactto commonly use manual search for logs with higher levels such
thesethreatsbyemployingadditionalsitereliabilityengineers as ”error”, ”critical”, or ”fatal” [4].
(SREs) as well as by deploying AI-enabled methods for IT Owning to the ever-increasing IT system complexities,
operations (AIOps) [1]. logs are constantly generated in large volumes (e.g., up to
TheAIOpsmethodscollectandanalyseplentyofITsystem several TB per day [5]). The emergence of complexity makes
information – metric data (e.g., CPU utilization), logs, and the manual log-based anomaly detection time-consuming [3],
traces(pathsoffunctioncalls)todetectanomalies,locatetheir promptingtheneedforautomation[6],[7].Thereby,automatic
methods for log-based anomaly detection are increasingly tion II presents our study that examines the potential of the
researched and adopted [8]–[14]. Current methods are com- log instructions to aid anomaly detection. Section III intro-
monlygroupedintotwofamilies,i.e.,supervisedandunsuper- duces ADLILog. Section IV gives the experimental results.
vised [6]. Existing supervised methods depend on manually Section V discusses the related work. Section VI concludes
labeled training data. Due to the constant evolution of the the paper and gives directions for future work.
softwaresystems[11],thesupervisedmethodsrequirearepet-
II. EXAMININGTHEPOTENTIALOFLOGINSTRUCTIONS
itive, time-expensive labeling process, which is oftentimes
FORLOG-BASEDANOMALYDETECTION
practically challenging and infeasible [5]. The unsupervised
methods mitigate the labeling problem by modeling with
logs from normal system states and detecting any significant In this section, we examine the potential of the log instruc-
deviations from the modeled normality state as anomalies. tions to aid anomaly detection. We start with our observation
However, the lack of explicit information about anomalous that there exist two log instructions severity groups, based on
logs during modeling leads to limited input representation, theirloglevels,i.e.,”normal”(”info”)and”abnormal”(”fatal”,
reducing their detection performance, and questioning their ”critical”, and ”error”). Following the usages of the log levels
practical usability [6]. for anomaly detection [4], we assume that the static texts of
To address the two challenges, we propose ADLILog. The theinstructionshavecomplementarypropertiesconcerningthe
central idea of the method is to use data from public code twoseveritylevelgroups,preservinganomaly-relatedinforma-
projects (e.g., GitHub) alongside the data from the system tion. To study the validity of the assumption, we analyze two
of interest (target system) when learning the anomaly detec- language properties of the word combinations (n-grams) in
tion model. Since the public code projects contain numerous theloginstructionsstatictextswithrespecttothetwogroups.
log instructions for diverse normal and abnormal events, we Specifically, by studying the n-gram uniqueness among the
assume that they may encode rich anomaly-related informa- groups, we examine the differences in the vocabulary used
tion. Following the usage of the log levels for manual log to describe normal/abnormal events. By relating the n-grams
anomaly detection, we considered grouping the instructions withtheexpressedintent(e.g.,positiveintentrelatestonormal
basedontheloglevelstoextractanomaly-relatedinformation. system state), we examine the semantic diversity between
Specifically,wecreatedtwoseveritylevelgroupsfromthelog the groups, i.e., if the n-grams express positive (normal state
instructions based on their log levels – ”normal” (composed transition)ornegative(abnormalstatetransition)intents.Inthe
of ”info”) and ”abnormal” (composed of ”error”, ”fatal”, and following, we first describe the 1) log instruction collection
”critical”). To verify our assumption, we conducted a study to procedure and then present the 2) uniqueness and the 3)
examine the anomaly-related language properties between the sentiment analyses of the log instructions static texts.
two groups (i.e., diversity in the vocabulary and the sentiment
A. Log Instruction Collection and Processing
of the words). The study results show that the two groups
extractanomaly-relatedinformationthatcanbeusedasabasis For the starting point of the analysis, we created a repre-
foranomalydetection.Basedonthisobservation,weintroduce sentativedatasetbycollectingloginstructionsfromthesource
ADLILog,whichusestheanomaly-relatedinformationalong- codeofmorethan1000publiccodeprojectsfromGitHub.We
side the target system data to learn a deep learning anomaly included a wide spectrum of domains and programming lan-
detection model through a two-phase learning procedure. guages (Python, Java, C++), covering different log instruction
An important advantage of ADLILog is that, by having ac- types.Theheterogeneityenablesustoexaminethevocabulary
cessto”normal”andespecially”abnormal”eventdescriptions diversity and semantic properties used in describing normal
from many different software systems, it learns a model by and abnormal events across systems. That way, we consider
supervised learning objectives, without the need for target- diverse logging styles and a wide range of events, with
system log labels (i.e., its unsupervised method). Thereby, complementary severity levels. To account for the reliability
ADLILog eliminates the need for time-expensive labeling in the log level assignment, we selected projects with more
while preserving the advantage of supervised modeling. The than a 100-stars and at least 20 contributors. The collection
latter addresses the challenge of limited input representa- procedure resulted in more than 100.000 log instructions.
tion during modeling. To prove the quality of detection, we Afterwards, we process the log instructions by extracting
extensively evaluate ADLILog against seven related methods the log levels and the static texts to represent their severity
on two widely used benchmark datasets and demonstrate that levels and the event descriptions. The diverse programming
our method outperforms the supervised methods by 5-24%, languagesusedifferentnamesfortheloglevels.Therefore,as
and the unsupervised by 40-63% on F score. The datasets1 afirststep,weunifyalltheloglevels.Wepreprocessthestatic
1
and method implementation2 are available as open-source for texts by applying several preprocessing techniques, similar to
fostering the research on this practically relevant problem. related works [15], including lower-case word transformation,
The remaining of the paper is structured as follows. Sec- splittingthestatictextsonwhitespace,removingplaceholders,
removing ASCII special characters and stopwords from the
1https://zenodo.org/record/6376763 SpacyEnglishdictionary[16].WerefertothisdataasSeverity
2https://github.com/ADLILog/ADLILog Level (SL) data. It is a set of tuples from two elements – (1)
the static text of log instruction, and (2) the severity group model from Spacy [16]. We justify the applicability of the
based on the aforenamed log level to severity group mapping sentiment model by pointing to the observed similarities
(e.g., (”machine error”, ”abnormal”)). We used the SL data betweengenerallanguageandlogs(asshorttexts)[17].Since
to conduct the log instruction examination study. Similar to the sentiment model is trained on diverse language texts, it
related log instruction analysis studies [17], we extracted the has learned notions of positive, neutral or negative intent. We
n-grams from the static text by varying the value for the n run the n-grams through the model to obtain the sentiment
parameter in the range n = {3,4,5}. An n-grams analysis score. We used the sentiment score to categorize the n-
showsthatmanyn-gramsappearonce.Toeliminatetheimpact gramsintothreecategories,i.e.,positive,negativeandneutral.
oftheraren-gramsontheanalysis,weconsideredthen-grams We relate the events from the ”normal” severity group with
that appear more than three times [17]. positiveintentbecausetheydescribeasuccessfulstateorstate
transition. Similarly, we relate the ”abnormal” group with a
B. Log Instructions Static Texts Uniqueness Analysis
negative intent because it describes unsuccessful system state
Intuitively, when describing abnormal events, the static text or state transition. The third category contains n-grams with
typicallycontainsn-gramslike”failure”or”errorconnection”, neutral intent, i.e., events without strongly expressed intent.
as opposed to normal events, where n-grams like ”successful” TABLE II summarize the results of the n-gram sentiment
and ”accepted” are more likely to appear. Therefore, we analysis. For each of the three sentiment categories, we show
assumethattheloginstructionsstatictextsofthetwoseverity the percentages of the n-grams concerning the two severity
levelgroupssharedifferent,partiallyoverlappingvocabularies. groups. In the positive intent category 66.94% of the n-
To verify this, we considered an approach from information grams are associated with the normal severity group, and
theory that defines the amount of information uncertainty in 28.13%arerelatedtotheabnormalseveritygroup.Incontrast,
a message [18]. In our case, we analyze the relation of the from the n-grams associated with negative intent, 69.75% are
n-grams with the two severity groups. At first, given an n- associated with the abnormal group, 23.13% are associated
gram (e.g., ”machine failure”), there is high uncertainty for withthenormalseveritygroup,and7.12%aresharedbetween
the assigned severity group. As we receive more information the two. These two observations show that there exists a
for the n-gram (e.g., new logs with the n-gram ”machine relationship between the normal group and positive intent,
failure”), its uncertainty concerning the associated severity and the abnormal group and the negative intent. Therefore,
groupisreduced.Forexample,ifthen-gram”machinefailure” the proposed severity log level grouping aligns with human
is associated five times with the ”abnormal” and one time intuition when expressing positive and negative sentiments.
with the ”normal” severity group, we have low uncertainty. Structuring the static text of the log instructions by their log
In contrast, if another n-gram, e.g., ”verifying connection” is levels in the proposed way extracts anomaly-related informa-
associated three times with the ”abnormal” and three times tion. Combining this observation with the uniqueness in the
with the ”normal” group, the n-gram uncertainty is high. vocabularies between the two severity groups demonstrates
To measure the uncertainty, we used Normalized Shanon’s that SL data has rich anomaly-related properties, which can
entropy [18]. We calculated the entropy for each n-gram and serve as a foundation for anomaly detection.
reported the key statistics of the n-grams entropy distribution.
TABLEI III. ADLILOG:LOG-BASEDANOMALYDETECTIONBY
LOGINSTRUCTIONSSTATICTEXTSUNIQUENESSANALYSISRESULTS LOGINSTRUCTIONS
Min 1st Qu. Median 3rd Qu. Max
Average Entropy 0.00 0.00 0.00 0.27 0.51 Following the affirmative observations about anomaly-
related information encoded in the SL data from the ex-
TABLE I summarizes the key properties of the n-gram amination study, in this section, we introduce ADLILog as
entropy distribution. It is seen that the median of the distri- an unsupervised log-based anomaly detection method. Fig. 1
bution is 0. This means that the majority of the n-grams are illustrates the overview of the approach. Logically, it is com-
associated with only one of the two severity groups. Thereby, posed of (1) log preprocessing, (2) deep learning framework
thetwoseveritygroupsarecharacterizedwitharatherunique and (3) anomaly detector. The role of the log preprocessing
vocabulary. While this analysis gives information about the is to process the raw logs by carefully selecting preprocessing
uniqueness of the vocabularies, it does not account for the transformations that expose rich information for the deep