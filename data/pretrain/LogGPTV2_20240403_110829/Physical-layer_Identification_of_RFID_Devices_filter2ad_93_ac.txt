calculated as follows.
scr(hR, hT ) = min(
( ˆGT − ˆGR)tΣ−1
( ˆGT − ˆGR)tΣ−1
GR( ˆGT − ˆGR),
GT ( ˆGT − ˆGR)) (5)
Values of the matching score closer to 0 indicate a bet-
ter match between the feature templates. The proposed
matching uses the mean and covariance of both test and
reference templates. It also ensures the symmetric prop-
erty, that is scr(hR, hT ) = scr(hT , hR).
It should be noted that the proposed feature extraction
and matching method can be efﬁciently implemented
in hardware as they use only linear transformations for
feature extraction and inter-vector distance matchings.
These operations have a low memory footprint and are
computationally efﬁcient.
(cid:113)
(cid:113)
4.2.2 PCA Training
In order to compute the eigenvalues and corresponding
eigenvectors of the high-dimensional data (the number
5We discovered that the feature templates are distributed in ellip-
soidal manner and therefore use Mahalanobis distance that weights
each projected sample according to the obtained eigenvalues.
7
0100200300400500−505Time (microseconds)Signal amplitude (V)Time length to start of responseTime length ofresponse020040060080010001200−1−0.500.511.522.53Time (ns)Signal amplitude (V)  JCOP NXP 4.1 Card modulation shapeStart of ATQA responseOn−Off keying modulationConsidered endof samples (cid:28) the number of dimensions), we used the
following lemma:
Lemma: For any K × D matrix W , mapping x →
W x is a one-to-one mapping that maps eigenvectors of
W T W onto those of W W T .
Here W denotes a matrix containing K samples of di-
mensionality D. Using this lemma, we can ﬁrst eval-
uate the covariance matrix in a lower space, ﬁnd its
eigenvectors and eigenvalues and then compute the high-
dimensional eigenvectors in the original data space by
normalized projection [7]. Based on this description, we
compute the PCA matrix WP CA=[ (cid:126)u1 (cid:126)u2 . . . (cid:126)ui] by solv-
ing the eigenvector equation:
(
1
K
X T X)(X T (cid:126)vi) = λi(X T (cid:126)vi)
(6)
where X is the training data matrix K × D and (cid:126)vi are
the eigenvectors of XX T . We then compute the eigen-
vectors of our matrix (cid:126)ui by normalizing:
(cid:126)ui =
1√
Kλi
(X T (cid:126)vi)
(7)
It should be noted that other algorithms like proba-
bilistic PCA (e.g., EM for PCA) can potentially be also
used given the fact that we discovered that only 5-10
eigenvectors are predominant. We intend to investigate
these as a part of our future work.
5 Performance Results
In this section, we present the performance results of our
ﬁngerprinting system. First, we review the metrics that
we use to evaluate the classiﬁcation and identiﬁcation ac-
curacy.
5.1 Evaluation Metrics
As a metric for classiﬁcation, we adopt the average clas-
siﬁcation error rate, deﬁned as the percentage of incor-
rectly classiﬁed signatures to a predeﬁned set of classes
of signatures (e.g., countries). We used the 1-Nearest
Neighbor rule [7] for estimating the similarity between
testing and reference signatures from a given class; that
is, a testing signature is matched to all reference sig-
natures from all classes and assigned to the class with
nearest distance similarity. It should be noted that more
sophisticated classiﬁers can be devised such as Support
Vector Machines (SVM), Probabilistic Neural Networks
(PNN) [7]. However these classiﬁers require more train-
ing which we do not consider in this work.
As metrics for identiﬁcation, we adopt the Equal Error
Rate (EER) and the Receiver Operating Characteristic
(ROC) since these are the most agreed metrics for eval-
uating identiﬁcation systems [8]. The False Accept Rate
8
(FAR) and the False Reject Rate (FRR) are the frequen-
cies at which the false accept and the false reject events
occur. The FAR and FRR are closely related to each
other in the Receiver Operating Characteristic (ROC).
ROC is a curve which allows to automatically compute
FRR when the FAR is ﬁxed at a desired level and vice
versa [8]. The operating point in ROC, where FAR and
FRR are equal, is called the Equal Error Rate (EER). The
EER represents the most common measure of the accu-
racy of identiﬁcation systems [1]. The operating thresh-
old value at which the EER occurs is our threshold T for
an Accept/Reject decision.
To increase the clarity of presentation, we use the Gen-
uine Accept Rate (GAR = 1 - FRR) in the ROC because it
shows the rate of Accepts of legitimate identities. In ad-
dition, we also compute FRR for common target values
of FAR (e.g., FAR = 1%).
5.2 Classiﬁcation Results
In this section, we present the results of the classiﬁca-
tion using modulation-shape and spectral features.
In
this evaluation, we consider all our passport samples and
5 of the JCOP NXP 4.1 cards. Here, the identity docu-
ments ID1, ID2, ID3, ID4, ID7, ID8 (see Table 1) and
the JCOP cards implement Type A communication pro-
tocol, whereas ID5 and ID6 use Type B protocol. It is
interesting to notice that within the same country class
(C1) we have documents with two different communi-
cation protocols (ID1-ID4 and ID8 implement Type A,
whereas ID5 implements Type B protocol).
5.2.1 Classiﬁcation using Modulation-shape Fea-
tures
The modulation-shape features described in Section 4
show the discriminant artifacts in the transponder’s re-
sponse. In particular, we discovered that these artifacts
(shapes) vary from one transponder to another on out-of-
speciﬁcation carrier frequencies.
Figure 6 shows the modulation envelope shapes of the
initial sequence of the RFID transponder’s response af-
ter Hilbert transformation for 4 different classes of Type
A protocol devices. These were recorded at an out of
speciﬁcation carrier frequency Fc=13.16MHz. Visual in-
spection shows that the modulation shapes not only dif-
fer from class to class but also are stable within different
runs.
In order to quantify these observations more precisely,
we considered classiﬁcation with 3 classes (2 countries +
JCOP cards) with all ﬁngerprints from two different runs.
The classiﬁcation process was repeated 8 times with 8
different reference ﬁngerprints per class for validation.
Table 2: Classiﬁcation using modulation-shape features (Experiment 2)
Number of Classes
Class structure
Average Classiﬁcation Error Rate
3
4
2
(C1),(C2),(JCOP)
(ID1,ID3,ID4,ID8), (ID2), (ID7), (JCOP)
(ID5-C1),(ID6-C3)
0%
0%
0%
(a)
(b)
Figure 6: Modulation shape of the responses of 4 different classes (C1),(C1-ID2),(C2),(JCOP): a) ﬁrst run b) second
run. In each run, the sample transponders were freshly placed in the ﬁngerprinting setup. These plots show the stability
of the collected modulation-shape features across different runs.
The results show perfect separability of the classes
with average classiﬁcation error rate of 0%.
In addi-
tion, after detailed inspection of the modulation-shape
features we discovered that ID2 from C1 differs signif-
icantly from the representatives of that class. We there-
fore formed a new classiﬁcation scenario with 5 classes
and obtained again a classiﬁcation error rate of 0%. It
is an interesting result given that ID1 and ID2 are is-
sued by the same country, in the same year and place
of issue. However, their transponders are apparently dif-
ferent. The modulation-shapes of ID1,ID3 and ID4 from
C1 could not be further distinguished using the combina-
tion of modulation-shape features and Euclidean match-
ing. Table 2 shows the results.
Similar to Type A, the 2 Type B transponders from
two different countries (C1,C3) available in our popula-
tion showed complete separability with classiﬁcation er-
ror rate of 0%. We acknowledge that our data set is insuf-
ﬁcient due to the difﬁculty of obtaining e-passports. We
believe however that our results are promising to stimu-
late future work with a larger set of e-passports.
In summary,
the modulation shapes at an out-of-
speciﬁcation carrier frequency are successful in catego-
rizing different classes of transponders (e.g., countries).
They are quickly extractable and stable across different
runs. For the classiﬁcation task, there is no need of statis-
tical analysis in contrast with the proposed spectral fea-
tures analyzed in the next sections. An additional ad-
vantage is that specialized hardware is not required as
current RFID readers can be easily adapted.
5.2.2 Classiﬁcation using Burst and Sweep Spectral
Features
We also performed classiﬁcation using burst and sweep
spectral features (Experiment 3 & 4) on the same set
of classes as with modulation-shape features (Table 2).
Similar to the modulation-shape features, this classiﬁca-
tion achieved a 0% classiﬁcation error rate on the pro-
posed classes. Moreover, using the spectral features we
were also able to distinguish individually each of our 9
identity documents with an EER=0%, i.e. we were able
to verify the identify of each individual document with
an accuracy of 100% with FRR=FAR=0%. This result
motivated us to estimate the identiﬁcation accuracy of
spectral features on a larger set of identical (of the same
make and model) transponders.
Identiﬁcation results
5.3
In this section we present the results of the identiﬁcation
capabilities of the (burst and sweep) spectral features for
9
020040060080010001200Time (ns)  JCOP NXP 4.1 CardC1C1−ID2C2020040060080010001200Time (ns)  JCOP NXP 4.1 CardC1C1−ID2C2(a)
(b)
Figure 7: Spectral features identiﬁcation accuracy for different number of samples N used to built the ﬁngerprint
and for different subspace dimensions: a) burst spectral features, b) sweep spectral features. 50 identical (same
manufacturer and model) transponders are used in the computation.
our data population (50 identical JCOP NXP 4.1 cards).
We adopt the following approach. We ﬁrst evaluate the
accuracy over the data collected in a single run of the
experiment (Section 5.3.1 and 5.3.2). We then quantify
the feature stability of the spectral features by consider-
ing samples from two independent runs together (Section
5.3.3).
We validate our results using cross-validation [7]. We
measured 50 samples per transponder per run of which
we use 5-10 samples for training and the remaining 40-
45 samples for testing depending on the number of sam-
ples N used to build the ﬁngerprint. The training and
testing data are thus separated and allow validation of
the identiﬁcation accuracy.
5.3.1 Identiﬁcation using Burst Spectral Features
In this evaluation, we consider the samples from the burst
dataset, from a single experiment run (Experiment 3) in
order to obtain a benchmark accuracy. We varied two
parameters: the number of samples N used to build the
feature templates (ﬁngerprints) and the dimension of the
PCA subspace used to project the original features into.
The dimension of the PCA subspace is also related to the
feature template size which we discuss below.
The results of this analysis are presented in Figure 7a
for different N and subspace dimensionality. The di-
mension of the features before the projection is 19998.
The results show the EER of the system reaching 0.0537
(5.37%) for N=15. This means that our system correctly
identiﬁes individual identical transponders with an accu-
racy of approximately 95% (GAR at the EER operating
point) using the features extracted from the burst sam-
ples. We later show that this accuracy is preserved in
cross-matchings between different runs. Table 3 summa-
rizes the underlying data, namely the number of samples
N, total genuine and imposter matchings performed for
EER computation6, Accept/Reject threshold, EER and
conﬁdence interval (CI).
The results in Figure 7a also conﬁrm that using the
ﬁrst 5 eigenvectors to project and store the feature tem-
plate provides the highest accuracy. Our proposed fea-
tures therefore form compact and computationally efﬁ-
cient ﬁngerprints (see Section 5.4).
5.3.2
Identiﬁcation using Sweep Spectral Features
Similarly to the above analysis, we considered the ﬁrst
run of samples from the sweep experiment (Experiment
4) dataset. For computational reasons, we did not con-
sider the entire sample. Instead, we extracted the spec-
tral features from the part of the sample between 220 to
270 microseconds. As it can be seen in Figure 4, this
part contains the biggest shape changes in the frequency
sweep. This decision reduced the considered space to
100000 points which allowed reasonably fast feature ex-
traction (26 s per sample). This clearly excludes some
discriminant information from our analysis, and future
work should include other sections of the sample signals.
The results are presented in Figure 7b for N=15 and
6The number of genuine and imposter matchings depends on the
number of available ﬁngerprints per transponder. For N=10, we are
able to built 4 different ﬁngerprints with the testing data within a run.
This results in 6 different matchings of ﬁngerprints from the same de-
vice (i.e., genuine matchings) and 392 different matchings of ﬁnger-
prints from different transponders (i.e., imposter matchings). For 50
transponders, this makes 300 genuine and 19600 imposter matchings.
10
1510152030405051015202530Subspace DimensionalityEqual Error Rate (%)  N=15N=10N=515101520304050456789101112Subspace DimensionalityEqual Error Rate (%)  N=15(a)
(b)
(c)
Figure 8: Feature stability in identiﬁcation: a) burst spectral features b) sweep spectral features. 50 identical (same
manufacturer and model) transponders are used in the experiments. c) burst and sweep spectral features on independent
transponder sets for training and testing; 20 transponders are used for training and 30 transponders - for testing; N=15.
different subspace dimensions. The dimension of the
original features before projection is 49998. We com-
puted the EER for N=15 (see Burst analysis in Sec-
tion 5.3.1). The obtained EER is 0.0469 (4.69%), when
using the ﬁrst 5 eigenvectors to project and store the fea-
ture template. The obtained accuracy is therefore similar
to the one obtained with the burst features, i.e. our sys-
tem correctly identiﬁes the individual identical transpon-
ders with an accuracy of approximately 95% (GAR at the
EER point). Table 3 shows the conﬁdence intervals.
5.3.3 Feature Stability
In the previous sections we have analyzed the identiﬁ-
cation accuracy using burst and sweep spectral features
within a single experiment run. This allows us to have a
benchmark for estimating the stability of the features. In
particular, we performed the following stability analysis:
1. Using the linear transformations WP CA obtained in