### Matching Algorithm for Causal Inference

#### 1. Matching Step
- **Treated Set (T):** All abandoned views for short content.
- **Untreated Set (C):** All abandoned views for long content.

For each \( u \in T \), we randomly select a \( v \in C \) such that:
- Both \( u \) and \( v \) belong to viewers in the same geography.
- Both \( u \) and \( v \) have the same connection type.

The matched set of pairs \( M \subseteq T \times C \) ensures that the confounding variables are the same, with the only difference being the treatment (short vs. long content).

#### 2. Scoring Step
For each pair \((u, v) \in M\):
- Compute the outcome as follows:
  - \( \text{outcome}(u, v) = +1 \) if \( u \) was abandoned with a smaller startup delay than \( v \).
  - \( \text{outcome}(u, v) = -1 \) if \( u \) was abandoned with a larger startup delay than \( v \).
  - \( \text{outcome}(u, v) = 0 \) if the startup delays when \( u \) and \( v \) were abandoned are equal.

The net outcome is calculated as:
\[ \text{Net Outcome} = \frac{\sum_{(u,v) \in M} \text{outcome}(u, v)}{|M|} \times 100 \]

A positive net outcome supports Assertion 5.3, while a negative value provides evidence against it. The matching algorithm produced a net outcome of 11.5%, indicating that the matched pairs supporting the assertion exceed those negating it by 11.5%.

#### Statistical Significance
To derive statistical significance, we formulate the null hypothesis \( H_0 \) that the treatment (long vs. short video) has no impact on abandonment. If \( H_0 \) holds, the outcomes are equally likely to be positive or negative.

Using the sign test from Section 4.2, we match \( n = 78,840 \) pairs. If \( H_0 \) holds, the expected number of pairs with a positive outcome is \( n/2 = 39,420 \). Our data show \( x = 43,954 \) pairs with positive scores, which is \( x - n/2 = 4,534 \) pairs in excess of the mean.

We bound the p-value by computing the two-sided tail of the binomial distribution:
\[ \text{p-value} \leq \text{Prob}\left(\left|X - \frac{n}{2}\right| \geq \left|x - \frac{n}{2}\right|\right) \leq 3.3 \times 10^{-229} \]

This p-value is much smaller than the required significance level of 0.001, leading us to reject \( H_0 \). Thus, our QED analysis is statistically significant.

### QED for Assertion 5.3
To investigate a causal conclusion for Assertion 5.3, we set up a QED where the treatment is the connection type of the user, and the outcome measures the relative tolerance to startup delay.

For each pair of network types \( A \) and \( B \):
- **Treated Set (T):** All abandoned views with connection type \( A \).
- **Untreated Set (C):** All abandoned views with connection type \( B \).

The matching algorithm is identical to the one described earlier, but the match criterion in step 1 is changed to match for identical content and identical geography.

The results of the matching algorithm are shown in Figure 13. For instance, the likelihood that a mobile viewer exhibited more patience than a fiber viewer is greater by a margin of 38.25%. We use the sign test to compute the p-value for each QED outcome in the table. All outcomes in Figure 13 are statistically significant with exceedingly small p-values, except the DSL-versus-cable comparison, which is inconclusive.

### Viewer Engagement
We study the extent to which a viewer is engaged with the video content. A simple metric for engagement is play time. Figure 14 shows the cumulative distribution function (CDF) of play time over our entire dataset. A significant number of views have very small play times, with a median of 35.4 seconds. This is likely due to "video surfing" where viewers quickly view a sequence of videos to find interesting content.

Play time is influenced by both the viewer's interest in the video and the stream quality. To understand the impact of stream quality, we need to neutralize the bias from confounding variables such as viewer interest, geography, and connection type. We use normalized rebuffer delay, which equals \( 100 \times (\text{rebuffer delay} / \text{video duration}) \).

#### Assertion 6.1
An increase in (normalized) rebuffer delay can cause a decrease in play time.

To evaluate this, we classify views by bucketing their normalized rebuffer delay into 1% buckets and plot the average play time for all views within each bucket (Figure 15). The decreasing trend visualizes the negative correlation between normalized rebuffer delay and play time, with a Kendall correlation of -0.421.

### QED Analysis for Assertion 6.1
To examine the causality, we devise a QED where the treatment set \( T \) consists of all views that suffered a normalized rebuffer delay more than a certain threshold \( \gamma \% \).

#### 1. Match Step
- **Treated Set (T):** Views with a normalized rebuffer delay of at least \( \gamma \% \).
- **Untreated Set (C):** Views without rebuffering.

For each view \( u \in T \), we pick a view \( v \) uniformly and randomly from the untreated set such that:
- The viewer of \( v \) has the same geography, connection type, and is watching the same video as the viewer of \( u \).
- View \( v \) has played at least the same amount of the video without rebuffering.

#### 2. Score Step
For each pair \((u, v) \in M\):
\[ \text{outcome}(u, v) = \frac{\text{play time of } v - \text{play time of } u}{\text{video duration}} \]
\[ \text{Net Outcome} = \frac{\sum_{(u,v) \in M} \text{outcome}(u, v)}{|M|} \times 100 \]

Figure 16 shows that on average, a view that experienced a normalized rebuffer delay of 1% or more played 5.02% less of the video. There is a general upward trend in the net outcome with increasing values of \( \gamma \).

### Repeat Viewership
We study repeat viewers who return to watch more videos after an initial visit. Repeat viewers are highly valued by content providers as they are more engaged and loyal.

#### Assertion 7.1
A viewer who experienced a failed visit is less likely to return to the content providerâ€™s site within a specified time period than a similar viewer who did not experience a failed visit.

To examine this, we classify each view as either failed or normal. For each failed visit (and normal visit), we compute the return time, defined as the next time the viewer returns to the site (Figure 17). The probability of returning within 1 day after a failed visit is 8.0% versus 11% after a normal visit. Similarly, the probability of returning within 1 week after a failed visit is 25% versus 27% after a normal visit.

### QED Analysis for Assertion 7.1
We perform a QED analysis to strengthen Assertion 7.1 by considering viewers with a failed visit as the treated set \( T \). For each \( u \in T \), we find a matching viewer \( v \) that is similar in all confounding variables, including geography, connection type, and content provider. We also ensure that the propensity to watch videos prior to the treatment is equivalent for \( u \) and \( v \).

Figure 18 shows the CDF of the aggregate play time of a viewer across all visits. The treated set \( T \) tends to contain more frequent visitors who watch more videos, introducing a bias.