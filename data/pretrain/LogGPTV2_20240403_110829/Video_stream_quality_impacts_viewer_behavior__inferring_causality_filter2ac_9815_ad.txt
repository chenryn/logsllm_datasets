The matching algorithm is described as follows.
1. Match step. Let the treated set T be all abandoned
views for short content and let untreated set C be all
the abandoned views for long content. For each u ∈ T
we pick uniformly and randomly a v ∈ C such that
u and v belong to viewers in the same geography and
have the same connection type. The matched set of
pairs M ⊆ T × C have the same attributes for the
confounding variables and diﬀer only on the treatment.
2. Score step. For each pair (u, v) ∈ M , we compute
an outcome(u, v) to be +1 if u was abandoned with a
smaller startup delay than v. If u was abandoned with
a larger startup delay than v, then outcome(u, v) =
−1. And, outcome(u, v) = 0, if the startup delays
when u and v were abandoned are equal. Now,
N et Outcome =!"(u,v)∈M outcome(u, v)
|M|
# × 100.
Note that a positive value for net outcome provides posi-
tive (supporting) evidence for Assertion 5.3, while a nega-
tive value provides negative evidence for the assertion. The
results of the matching algorithm produced a net outcome of
11.5%. The net outcome shows that the matched pairs that
support Assertion 5.2 exceed those that negate the asser-
tion by 11.5%. The positive net outcome provides evidence
of causality that was not provided by the prior correlational
analysis alone by eliminating the threats posed by the iden-
tiﬁed confounding variables.
To derive statistical signiﬁcance of the above QED re-
sult, we formulate a null hypothesis Ho that states that
the treatment (long versus short video) has no impact on
If Ho holds, the outcome(u, v) is equally
abandonment.
likely to be positive (+1) as negative (-1). We now use
the sign test that we described in Section 4.2 to derive a
bound on the p-value. Since we matched n = 78, 840 pairs,
if Ho holds, the expected number pairs with a positive out-
come is n/2 = 78, 840/2 = 39, 420. Our observational data
however had x = 43, 954 pairs with positive scores, i.e.,
x − n/2 = 4534 pairs in excess of the mean. We bound
the p-value by showing that it is extremely unlikely to have
had 4534 positive pairs in excess of the mean by computing
the the two-sided tail of the binomial distribution with n
trials and probability 1/2:
n
2 |≥| x −
n
2% ≤ 3.3 × 10−229
(1)
p-value ≤ Prob$|X −
The above bound for the p-value is much smaller than the
required signiﬁcance level of 0.001 and leads us to reject
the null hypothesis Ho. Thus, we conclude that our QED
analysis is statistically signiﬁcant.
5.2 QED for Assertion 5.3
To investigate a causal conclusion for Assertion 5.3, we
set up a QED where the treatment is the connection type of
the user and the outcome measures the relative tolerance of
219the viewer to startup delay. For each pair of network types
A and B, we run a matching algorithm where the treated
set T is the set of all abandoned views with connection type
A and untreated set is all abandoned views with connection
type B. The matching algorithm used is identical to the
one described earlier except that the match criterion in step
1 is changed to match for identical content and identical
geography. That is, for every matched pair (u, v), view u
has network type A and view v has network type B but
both are views for the same video and belong to viewers in
the same geography.
The results of the matching algorithm are shown in Fig-
ure 13. For instance, our results show that the likelihood
that a mobile viewer exhibited more patience than a ﬁber
viewer is greater than the likelihood that opposite holds by
a margin of 38.25%. Much as in Section 5.1, we use the
sign test to compute the p-value for each QED outcome in
the table. All QED outcomes in Figure 13 turned out to be
statistically signiﬁcant with exceedingly small p-values, ex-
cept the dsl-versus-cable comparison that was inconclusive.
Speciﬁcally, our results show that a that a mobile viewer ex-
hibits more patience than other (non-mobile) viewers, and
the result holds with exceedingly small p-values (< 10−17).
Our results also provide strong evidence for DSL and cable
users being more patient than ﬁber users, though the p-value
for the dsl-versus-ﬁber was somewhat larger (4.6×10−5) but
still statistically signiﬁcant. The dsl-versus-cable compari-
son was however inconclusive and not statistically signiﬁcant
as the p-value of the score was 0.06 that is larger than our
required signiﬁcance level of 0.001.
```````````
Untreated
Treated
mobile
dsl
cable
dsl
cable
ﬁber
33.81
-
-
35.40
-0.75
-
38.25
2.67
3.65
Figure 13: Net QED outcomes support the causal
impact of connection type on viewer patience for
startup delay, though the impact is more pro-
nounced between mobile and the rest. The p-value
for all entrees are very small (< 10−17), except dsl-
versus-cable (0.06) and dsl-versus-ﬁber (4.6 × 10−5).
6. VIEWER ENGAGEMENT
We study the extent to which a viewer is engaged with
the video content of the content provider. A simple metric
that measures engagement is play time. Here we study play
time on a per view basis, though one could study play time
aggregated over all views of a visit (called visit play time) or
play time aggregated over all visits of a viewer (called viewer
play time). Figure 14 shows the CDF of play time over
our entire data set. A noticeable fact is that a signiﬁcant
number of views have very small play time with the median
play time only 35.4 seconds. This is likely caused by “video
surﬁng” where a viewer quickly views a sequence of videos
to see what might of interest to him/her, before settling in
on the videos that he/she wants to watch. The fact that
a viewer watched on average of 22.48 minutes per visit (cf.
Figure 4) is consistent with this observation. Play time is
clearly impacted by both the interest level of the viewer
in the video and the stream quality. Viewer interest could
Figure 14: A signiﬁcant fraction of the views have
small duration.
itself be a function of complex factors, for instance, Italian
viewers might be more interested in soccer world cup videos
than American viewers, even more so if the video is of a
game where Italy is playing. In understanding the impact
of stream quality on viewer engagement, the challenge is to
neutralize the bias from confounding variables not related
to stream quality such as viewer interest, geography, and
connection type. Since more rebuﬀer delay is expected of
videos with a longer duration, we use normalized rebuﬀer
delay5 that equals 100 × (rebuﬀer delay/video duration).
Assertion 6.1. An increase in (normalized) rebuﬀer de-
lay can cause a decrease in play time.
To evaluate the above assertion, we ﬁrst classify views by
bucketing their normalized rebuﬀer delay into 1% buckets.
Then, we compute and plot the average play time for all
views within each bucket (see Figure 15). The decreasing
trend visualizes the negative correlation that exists between
normalized rebuﬀer delay and play time. The Kendall cor-
relation between the two metrics is −0.421, quantifying the
negative correlation.
6.1 QED Analysis
To examine the causality of Assertion 6.1, we devise a
QED where the treatment set T consists of all views that suf-
fered normalized rebuﬀer delay more than a certain thresh-
old γ%. Given a value of γ as input, the treated views are
matched with untreated views that did not experience re-
buﬀering as follows.
1. Match step. We form a set of matched pairs M as
follows. Let T be the set of all views who have a nor-
malized rebuﬀer delay of at least γ%. For each view u
in T , suppose that u reaches the normalized rebuﬀer
delay threshold γ% when viewing the tth second of the
5Note that normalized rebuﬀer delay can go beyond 100% if
we rebuﬀer for longer than the total duration of the video.
220Normalized Rebuﬀer Delay γ Net Outcome
P-Value
(percent)
(percent)
1
2
3
4
5
6
7
5.02
5.54
5.7
6.66
6.27
7.38
7.48
< 10−143
< 10−123
< 10−87
< 10−86
< 10−57
< 10−47
< 10−36
Figure 16: A viewer who experienced more rebuﬀer
delay on average watched less video than an identical
viewer who had no rebuﬀer.
increasing values of γ. Much as in Section 5.1, we use the
sign test to compute the p-values for each QED outcome.
All p-values were extremely small as shown in Figure 16,
making the results statistically signiﬁcant.
7. REPEAT VIEWERSHIP
We study the viewers who after watching videos on a con-
tent provider’s site return after some period of time to watch
more. Repeat viewers are valued highly-valued by media
content providers as these viewers are more engaged and
more loyal to the content provider’s site. Even a small de-
crease (or, increase) in the return rate of viewers can have a
large impact on the business metrics of the content provider.
Clearly, a number of factors, including how captivating the
video content is to the viewer, inﬂuence whether or not a
viewer returns. However, we show that stream quality can
also inﬂuence whether or not a viewer returns.
The most drastic form of quality degradation is failure
when a viewer is unable to play a video successfully. Fail-
ures can be caused by a number of issues, including problems
with the content (broken links, missing video ﬁles, etc), the
client software (media player bugs, etc), or the infrastruc-
ture (network failure, server overload, etc). More frustrating
than a failed view is a failed visit where a viewer tries to play
videos from the content providers site but fails and leaves
the site immediately after the failure, presumably with some
level of frustration. (Note that the deﬁnition of a failed visit
does not preclude successful views earlier in that visit before
the last view(s) that failed.) We focus on the impact of a
failed visit experienced by a viewer on his/her likelihood of
returning to the content provider’s site.
Assertion 7.1. A viewer who experienced a failed visit
is less likely to return to the content provider’s site to view
more videos within a speciﬁed time period than a similar
viewer who did not experience a failed visit.
To examine if the above assertion holds, we classify each
of our views as either failed or normal (i.e., not failed). For
each failed visit (resp., normal visit), we compute the return
time which is deﬁned to be the next time the viewer returns
to the content provider’s site. (Return time could be inﬁnite
if they do not return to the site within our trace window.)
Figure 17 shows the CDF of the return time for both failed
visits and normal visits. It can be seen that there is signiﬁ-
cant reduction in the probability of return following a failed
visit as opposed to a normal one. For instance, the proba-
bility of returning within 1 day after a failed visit is 8.0%
Figure 15: Correlation of normalized rebuﬀer delay
with play time.
video, i.e., view u receives treatment after watching
the ﬁrst t seconds of the video, though more of the
video could have been played after that point. We
pick a view v uniformly and randomly from the set of
all possible views such that
(a) the viewer of v has the same geography, connec-
tion type, and is watching the same video as the
viewer of u.
(b) View v has played at least t seconds of the video
without rebuﬀering till that point.
2. Score step. For each pair (u, v) ∈ M , we compute
play time of v − play time of u
outcome(u, v) =
video duration
.
N et Outcome =!"(u,v)∈M outcome(u, v)
|M|
# × 100.
Note that closer we can make the matched views u and v
in variables other than the treatment, the more accurate
our QED results. Though as a practical matter, adding too
many matching parameters can highly reduce the availabil-
ity of matches, eventually impacting the statistical signiﬁ-
cance of the results. It is worth noting step 1(b) above where
we ensure that v watches the video to at least the same point
as when u ﬁrst received treatment. Thus, at the time both
u and v play the tth second of the video, they have viewed
the same content and the only diﬀerence between them is
one had rebuﬀering and the other did not. The net outcome
of the matching algorithm can be viewed as the diﬀerence in
the play time of u and v expressed as a percent of the video
duration. Figure 16 shows that on average a view that ex-
perienced normalized rebuﬀer delay of 1% or more played
5.02% of less of the video. There is a general upward trend
in the net outcome when the treatment gets harsher with
221versus 11% after a normal one. Likewise, the probability
of returning within 1 week after a failed visit is 25% versus
27% after a normal one.
Figure 17: Probability of the return after a failed
visit and after a normal visit. The probability of
returning within a speciﬁed return time is distinctly
smaller after a failed visit than after a normal one.
7.1 QED Analysis
We perform a QED analysis to strengthen Assertion 7.1
by considering viewers6 with a failed visit to be the treated
set T . For each u ∈ T we ﬁnd a matching viewer v that
is similar to u in all the confounding variables. As before,
we ensure that viewers u and v are from the same geogra-
phy, have the same connection type, and are viewing content
from the same content provider. However, there is a subtle
characteristic that need to be matched. Speciﬁcally, we need
also ensure that the propensity of u to watch videos prior to
when u received treatment is equivalent to the corresponding
propensity of v. This ensures that any diﬀerential behavior
after the treatment can be attributed to the treatment itself.
To reinforce the last point, a viewer who watches more
video at a site is more likely to have had a failed view. There-
fore, the treated set T of viewers has a bias towards contain-
ing more frequent visitors to site who also watch more video.
Figure 18 shows the CDF of the aggregate play time of a
viewer across all visits. It can be seen that the treated set T