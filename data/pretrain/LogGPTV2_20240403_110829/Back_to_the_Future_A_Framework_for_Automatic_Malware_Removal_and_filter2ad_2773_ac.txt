195
129
2135
Detected Modi(cid:2)cations Detected Modi(cid:2)cations
File
242
385
112
2
2
44
336
File
42
151
24
2
2
44
330
61
4
59
1
0
1
1
1
0
1
8
Our Tool
Commercial Tool
False Negative
Registry Key
File
83%
61%
79%
0%
0%
0%
2%
69%
97%
97%
0%
0%
0%
88%
Table 2. Comparison of our tool and commercial tools’ ability to detect (cid:2)les and registry keys modi-
(cid:2)ed by malware.
Program
eZula installer
Kazaa installer
Happy99.Worm
unzip (5MB (cid:2)le)
Not monitored Monitored as trusted Monitored as untrusted
CPU Time
3.953s
48.965s
4.858s
0.535s
4.516s
59.824s
4.963s
0.666s
6.338s
101.466s
4.937s
1.013s
Log Size
4959 KB
12552 KB
6 KB
336 KB
Table 3. CPU time and disk space overhead of our tool while running benign and malware programs.
our logging system by writing a large amount of new data,
or repeatedly overwriting the same location. The only ef-
fective attack is to overwrite a large amount of trusted data,
which we can deal with by limiting the maximum amount
of data that an untrusted process may overwrite.
Security of the Dichotomy of Trustworthiness We as-
sume that once the user considers a process trusted, it re-
mains trusted until the user explicitly reclassi(cid:2)es it as un-
trusted. This ignores the possibility that a trusted but vul-
nerable process may become untrusted because malicious
code has been injected into it.
5.2. Security of the Implementation
We discuss the security of our prototype implemented on
Windows:
† Read and write operations: Our current prototype only
considers read and write operations on the Windows
registry and on the (cid:2)le system. It considers some IPCs
mechanisms, such as communication through named
pipes as combined read and write operations. There-
fore, when an untrusted program sends a message to
a trusted program, this message passing violates the
integrity model. However, in our current implemen-
tation we do not monitor all IPC mechanisms includ-
ing shared memory and Windows message passing.
Since we cannot easily monitor device drivers installed
by untrusted programs, we consider their installation
as violating the integrity property. We also assume,
optimistically, that after an untrusted program writes
data to the network, the data will not be read by some
trusted programs from the network later; therefore, we
do not monitor read or write operation on the network.
† Security of the monitoring mechanism: The princi-
ple of complete mediation requires that untrusted pro-
grams should be unable to attack or circumvent the
monitoring mechanism [18]. We install our monitor
as a kernel driver before we run untrusted programs.
Therefore, our monitor can intercept and control all the
API calls made by untrusted programs from the user
space. Our prototype treats all the processes spawned
by untrusted processes as untrusted and transitively
monitors the spawned processes. Therefore, we be-
lieve that our monitor is secure from tampering or cir-
cumvention by user-level processes. While our pro-
totype can prohibit untrusted programs from installing
kernel drivers by standard means, we do not prevent at-
tacks on trusted processes that may install rootkits on
the system.
† Security of the logging mechanism: We have discussed
the security of the logging mechanism of the frame-
work in Section 5.1. In the implementation, we need
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006to ensure that no untrusted process can tamper with the
logs. Since our framework hooks into all the API calls
that access the (cid:2)le system, it protects the logs by deny-
ing access to it from all except the logging process.
† Security of the recovery mechanism: Since our frame-
work maintains system integrity, recovery can always
succeed. In particular, before the monitor begins re-
covery, it aborts the untrusted process (and any process
spawned by it). Therefore, the process cannot interfere
directly with the recovery mechanism.
6. Related Work
SEE [20, 12], proposed the idea of using one-way iso-
lation to create a safe execution environment. Untrusted
programs modify a separate temporary copy of the (cid:2)le sys-
tem rather than the original. SEE allows the user the option
to commit these changes to the original (cid:2)le system once
the untrusted program (cid:2)nishes. We view SEE as a dual to
our approach: SEE allows the untrusted programs to run
to completion, but may not be able to commit some data
back to the original (cid:2)le system. Our framework allows un-
trusted programs to write to the (cid:2)le system immediately, but
our framework may prohibit some untrusted programs from
running to completion.
Goel et al. designed a system to recover a (cid:2)le system af-
ter an intrusion is detected. The Taser [7] intrusion recovery
system logs all process, (cid:2)le and network operations. It can
then use this audit log to determine the resultant (cid:2)le sys-
tem modi(cid:2)cations after an intrusion. Once a compromised
process is (cid:3)agged by IDS network activity logs or (cid:2)lesys-
tem changes, all changes to the (cid:2)le system depending on
that process can be reversed. The dependency is derived
from information (cid:3)ow between processes and (cid:2)les by sys-
tem calls. While Taser has similar logging and recovery
components compared with our approach, the main diﬁer-
ence is the timeliness of response. Our approach can act
immediately when an untrusted process taints a trusted one
since we monitor the actual kernel objects in the operat-
ing system. Taser identi(cid:2)es malicious behavior by an IDS,
and only acts after the IDS signals an intrusion. Since an
IDS may have false negatives, Taser may never respond to
the tainting of trusted processes. Moreover, if an IDS does
not respond immediately after an intrusion happens, Taser
would need to reverse all the operations of legitimate pro-
cesses from the time of intrusion to the time of intrusion
detection, resulting in the loss of any work done by the le-
gitimate processes.
Our work is also related to the general isolation strat-
egy with virtual machines, which provide an eﬁective, reli-
able mechanism for isolating untrusted applications. King
et al. added support for virtual machines monitors into the
Linux kernel for achieving high performance [11]. How-
ever, using virtual machines to execute untrusted programs
has its shortcomings. First, untrusted programs running in-
side a virtual machine cannot access resources created by
programs running outside the virtual machine, which may
break many programs. Second, virtual machines are expen-
sive. Con(cid:2)guring each untrusted program to run in its own
virtual machine with a complete operating system requires
considerable amounts of system resources and human time.
Our framework is inspired by recovery-oriented com-
puting (ROC), which is a framework for recovering from
system component failure and operator errors [16, 4].
It
contains three stages: rewind, repair, and replay. Its threat
model is that any component in the system may fail, and
that the operator may make a mistake at any time. Since
our goal is to run untrusted programs safely, we need a dif-
ferent threat model: we assume that most applications on
the system are trustworthy, so we can focus on monitoring
and logging a few untrusted applications. Therefore, our
framework has a much smaller overhead for logging and
recovery. Our framework also avoids possibly expensive
snapshots required in ROC.
Logging has been used for replaying system events. Re-
Virt uses logging for intrusion detection. It runs applica-
tions inside a virtual machine and logs their events. Then, it
analyzes intrusions by replaying the logged events [6]. King
et al. uses logging for debugging operating systems [10].
They run an operating system inside a virtual machine, log
all its events, and use the logs to debug the operating system.
We use logging for a diﬁerent purpose: we want to recover
the system to a safe state, rather than replay the events. This
diﬁerence requires that we design our logging system diﬁer-
ently. We do not need to take a snapshot of the system; we
just log all the events. During recovery, we start from the
current state of the system and undo each oﬁending event in
the reverse chronological order. In this approach, we have
avoided taking a system snapshot, which may be very ex-
pensive. Logging has also been used for system recovery.
A log-structured (cid:2)le system [17] takes this idea even fur-
ther: the entire (cid:2)le system is in a log-like structure, which
speeds up both (cid:2)le writing and crash recovery. It in(cid:3)uenced
the design of (cid:2)le system recovery in our framework.
Reparable (cid:2)le service (RFS) [22] uses a similar idea of
logging and recovery to repair compromised network (cid:2)le
servers, such as NFS servers.
It interposes a RFS server
between the NFS server and clients for logging (cid:2)le update
operations, and these logs can be used later for rolling back
these operations. It is used for a diﬁerent purpose from that
of our approach, and as such, it is more complicated:
it
requires modifying all the NFS clients as well as interposing
the RFS server between the NFS server and its clients.
Our logging mechanism employs a simple tainting anal-
ysis to track trustworthiness of data. Similar ideas have
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006been used for many other purposes. Chow et al. proposed to
use whole-system simulation with tainting analysis to ana-
lyze how sensitive data are handled in large programs [5].
Newsome et al. used dynamic taint analysis for automatic
detection of overwrite attacks in processes. BackTracker [9]
identi(cid:2)ed automatically potential sequences of steps that
occurred in an intrusion. Starting with a single detection
point, it identi(cid:2)ed (cid:2)les and processes that could have af-
fected that detection point. In comparison, our framework
tracks the propagation of untrusted data for preserving sys-
tem integrity and removing malware.
7. Conclusion
We have described Back to the Future, a novel frame-
work for automatically removing malware and repairing its
damage to the system. The framework preserves system in-
tegrity while the user is running untrusted programs, and
allows untrusted programs to run as long as possible until
they may harm trusted programs. The framework achieves
these goals by monitoring untrusted programs, logging their
operations, and using the logs to remove malware and to
restore infected data. We implemented this framework on
Windows and tested our prototype on real spyware, adware,
Trojan horses, and email worms. With acceptable runtime
and storage overhead, we detected all the malware’s modi-
(cid:2)cations found by commercial tools, while the commercial
tools overlooked up to 97% of the modi(cid:2)cations found by
our tool.
Acknowledgments
We thank Hong Li at Intel IT Research for helpful dis-
cussions.
References
[1] Norton AntiVirus.
http://www.symantec.com/
avcenter.
[2] Spybot. http://www.safer-networking.org/en.
[3] M. Bishop. Computer Security: Art and Science. Addison-
Wesley, 2003.
[4] A. B. Brown and D. A. Patterson. Undo for operators: Build-
In Proceedings of the 2003
ing an undoable e-mail store.
Annual USENIX Technical Conference, 2003.
[5] J. Chow, B. Pfaﬁ, T. Gar(cid:2)nkel, K. Christopher, and
M. Rosenblum. Understanding data lifetime via whole sys-
tem simulation.
In Proceedings of the USENIX Security
Symposium, Aug. 2004.
[6] G. W. Dunlap, S. T. King, S. Cinar, M. Basrai, and P. M.
Chen. Revirt: Enabling intrusion analysis through virtual-
machine logging and replay.
In Proceedings of the 2002
Symposium on Operating Systems Design and Implementa-
tion (OSDI), 2002.
[7] A. Goel, K. Po, K. Farhadi, Z. Li, and E. de Lara. The taser
intrusion recovery system. In SOSP ’05: Proceedings of the
twentieth ACM symposium on Operating systems principles,
pages 163(cid:150)176, New York, NY, USA, 2005. ACM Press.
[8] E. L. Howes.
Anti-spyware testing.
http://www.
spywarewarrior.com/, 2004.
[9] S. King and P. Chen. Backtracking intrusions. In Proceed-
ings of the 2003 Symposium on Operating Systems Princi-
ples (SOSP), 2003.
[10] S. King, G. Dunlap, and P. Chen. Debugging operating sys-
tems with time-traveling virtual machines. In Proceedings
of the 2005 Annual USENIX Technical Conference, 2005.
[11] S. T. King, G. W. Dunlap, and P. M. Chen. Operating system
In Proceedings of the 2003
support for virtual machines.
Annual USENIX Technical Conference, June 2003.
[12] Z. Liang, V. Venkatakrishnan, and R. Sekar. Isolated pro-
gram execution: An application transparent approach for ex-
ecuting untrusted programs. In Annual Computer Security
Applications Conference, 2003.
[13] Mark Russinovich and Bryce Cogswell. Description of
regmon tool. http://www.sysinternals.com/ntw2k/
source/regmon.shtml.
[14] G. Nebbett. Windows NT/2000 Native API Reference. Que,
2000.
[15] One
in Three Computers Has Malicious Code.
http://www.marketingvox.com/archives/2004/10/
06/one_in_three_computers_has_malicious_code,
2004.
[16] D. A. Patterson, A. Brown, P. Broadwell, G. Candea,
M. Chen, J. Cutler, P. Enriquez, A. Fox, E. Kiciman,
M. Merzbacher, D. Oppenheimer, N. Sastry, W. Tetzlaﬁ,
J. Traupman, and N. Treuhaft. Recovery-oriented comput-
ing (roc): Motivation, de(cid:2)nition, techniques, and case stud-
ies. Technical Report UCB//CSD-02-1175,, UC Berkeley
Computer Science, 2002.
[17] M. Rosenblum and J. K. Ousterhout. The design and imple-
mentation of a log-structured (cid:2)le system. ACM Transactions
on Computer Systems, 10(1):26(cid:150)52, 1992.
[18] J. Saltzer and M. Schroeder. The protection of information
in computer systems. Communications of the ACM, 17(7),
1974.
[19] S. Saroiu, S. D. Gribble, and H. M. Levy. Measurement and
analysis of spyware in a university environment. In Proceed-
ings of the First Symposium on Networked Systems Design
and Implementation - NDSI’04, Mar. 2004.
[20] W. Sun, Z. Liang, V. Venkatakrishnan, and R. Sekar. One-
way isolation: An eﬁective approach for realizing safe ex-
ecution environments. In Proceedings of Network and Dis-
tributed Systems Symposium (NDSS), 2005.
[21] Sven B. Shcreiber. Undocumented Windows 2000 Secrets: A
Programmer’s Cookbook, volume 1. Addison-Wesley, Up-
per Saddle River, NJ, 1st edition, 2001.
[22] N. Zhu and T.-C. Chiueh. Design, implementation, and eval-
uation of repairable (cid:2)le service. In Proceedings of the 2003
International Conference on Dependable Systems and Net-
works (DSN ’03), 2003.
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006