some side channel, then B2 will leak 2 × K bits to R1 as they
are co-resident for two epochs (Row 4 of Step 1).
2. Information sharing across adversary’s VMs: Our threat model
allows adversarial client’s VMs to collaborate to increase the
rate of information extraction. For instance, in the context of
Prime+Probe attack [42], adversarial VMs may decide to work
on different parts of the cryptographic key and combine these to
reconstruct the key. Let us revisit the example in Figure 1. As
shown in Step 2, if the Red VMs collaborate then they can ex-
tract more information (marked as C in Step 2 which extracted
3× K bits in contrast to 2× K bits for NC model). Assuming
the same leakage rate of K bits per epoch between a pair of
VMs, we now see that the Red client can extract a total 3 × K
bits over the three epochs from each Blue VM (Row 1 and 3 of
Step 2).
3. Information replication of the target: Depending on a client’s
workload, different VMs belonging to a client may carry the
same bits of private information. For instance, consider a repli-
cated web server deployment with all the replicas having the
same private database records.
Intuitively, having replicated
client workloads poses higher threat as they can lead to higher
information leakage. Revisiting our example in Figure 1, we
see that the Red VM R1 can potentially extract 3× K bits over
the three epochs in case the Blue VMs are replicas because the
Blue VMs B1 and B2 carry the same information. In contrast,
if B1 and B2 were not replicas, then R1 will have K bits from
B1 and 2× K bits from B2 but these could not be combined as
information are distinct. Note that this can be combined with
the collaboration described above. That is, if R1–3 were also
collaborating, then in aggregate the adversary Red will have
gathered 6× K bits of private information from the tenant Blue
over the three epochs (Row 1 of Step 3).
3.3 Formalizing Information Leakage Model
The above discussion provided an intuitive overview of the differ-
ent dimensions in modeling information leakage. Next, we for-
mally deﬁne the information leakage so that it can be used to guide
the placement and migration decisions of the Nomad system.
Preliminaries: Let VM c,i denote VM i belonging to the client c
and VM c(cid:48),i(cid:48) denote the VM i(cid:48) of a different client c(cid:48) (i.e., a poten-
tial adversary). Let CoRes c,i,c(cid:48),i(cid:48) (t) be a binary indicator variable
that captures if VM c,i and VM c(cid:48),i(cid:48) are co-resident at an epoch, t;
i.e., there exists some machine m on which they both reside at t.
Then, having deﬁned per-epoch co-residency between VM pairs,
we need to summarize this value across time. In order to aggregate
information leakage as a function of co-residency across time, we
consider a sliding window model over the most recent ∆ epochs.
For example, if cryptographic keys are refreshed periodically (say
every few hours), then any bits of information an adversary VM has
gathered the previous day will have no value since the key has been
modiﬁed.
Let InfoLeak c,i→c(cid:48),i(cid:48) (t, ∆) denote the information leakage from
VM c,i to VM c(cid:48),i(cid:48) measured over the sliding window of time [t −
MachineR1R2R3B1B2Epoch 1R1R2R3B1B2R1R2R3B1B2Epoch 2 Epoch 3Per VM-pair Leakage   B1 R1= K (1)B1 R2= 0 (2)B1 R3= 2K (3)B2 R1= 2K (4)B2 R2 = K (5)B2 R3 = 0 (6)K bits of leakage between co-residentVMs per epochSummarizingacross Red VMsB1 RCSum(K,0,2K)= 3K  (1)NCMax(K,0,2K) = 2K  (2)B2RCSum(2K,K,0)= 3K  (3)NC Max(2K,K,0)= 2K  (4)PerClient-pair (B R) LeakageSum((1),(3))= 6K bits (1)Max((5)-(7)) = 3K bits (2)Max((1),(3))= 3K bits (3)Max((2),(4))= 2K bits (4)Step 1Step 2Step 3Summarizingacross Blue VMsB R1RSum(K,2K) = 3K (5)B R2RSum(0,K)   =  K(6)B R3R Sum(2K,0)= 2K (7)These equations naturally capture our intuitive explanations from
earlier; the leakage is highest when we have replication and collab-
oration (i.e., (cid:104)R, C(cid:105)) and least when neither occurs (i.e.,(cid:104)NR, NC(cid:105)).
When we have either replication or collaboration but not both, the
value will be in between these two extremes.
4 System Overview
∆, t]. Formally,
InfoLeak c,i→c(cid:48),i(cid:48) (t, ∆) =
(cid:88)
t∈[t-∆,t]
CoRes c,i,c(cid:48),i(cid:48) (t)
(1)
Then, we can use information leakage at a VM granularity to
construct information leakage at a client granularity over time,
InfoLeak c→c(cid:48) (t, ∆). This quantity deﬁnes information leakage
from a given client c to a different c(cid:48) measured at epoch t over the
sliding window of time [t − ∆, t], and is also a function of client
replication and adversary collaboration.2
Modeling different leakage scenarios: Given these preliminaries,
we can model four possible cases.
1. NonReplicated client; NonCollaborating adversary ((cid:104)NR, NC(cid:105)):
If there is no replication and no collaboration, then the infor-
mation leakage for a client will be the maximum per-VM-pair
information leakage across all pairs of clients. Formally,
InfoLeak
(cid:104)NR,NC(cid:105)
c→c(cid:48)
(t, ∆) = M ax
M ax
InfoLeak c,i→c(cid:48),i(cid:48) (t, ∆)
i
i(cid:48)
(2)
Under the (cid:104)NR, NC(cid:105) scenario (Figure 1), the Blue client
leaked a total of 2 × K bits to the Red adversary because the
maximum information leakage between any VM pair was 2×K
bits (Row 4 of Step 3).
2. NonReplicated client; Collaborating adversary ((cid:104)NR, C(cid:105)):
In this case, for each client VM, there will be a cumulative ef-
fect across the adversary VMs since they can collaborate. How-
ever, the inter-client leakage will be determined by the client
VM that has leaked the most. Formally,
InfoLeak
(cid:104)NR,C(cid:105)
c→c(cid:48)
(t, ∆) = M ax
i
InfoLeak c,i→c(cid:48),i(cid:48) (t, ∆)
(3)
In our example, under the (cid:104)NR, C(cid:105) scenario, each Blue client’s
VMs leaked 3 × K bits across all Red VMs. Thus, the leakage
from Blue to Red will be 3 × K bits (Row 3 of Step 3).
3. Replicated client; NonCollaborating adversary ((cid:104)R, NC(cid:105)):
In this case, there will be a cumulative effect across the client
VMs since they have the same information but the inter-client
leakage will be determined by the adversary VM that has ex-
tracted the most information. Formally,
InfoLeak
(cid:104)R,NC(cid:105)
c→c(cid:48)
(t, ∆) = M ax
i(cid:48)
InfoLeak c,i→c(cid:48),i(cid:48) (t, ∆)
(4)
Revisiting our example, we see that each Red VM (i.e., VM R1,
VM R2, and VM R3) has extracted 3 × K , K , and 2 × K bits,
respectively, from all Blue client’s VMs. Therefore, the Blue
client, under the non-collaborating scenario of the Red VMs,
has leaked a total of 3 × K bits (Row 2 of Step 3).
4. Replicated client; Collaborating adversary ((cid:104)R, C(cid:105)): Finally,
when the client is replicated and the adversary can collabo-
rate, we see cumulative effects across both client and adversary
VMs. Formally,
(cid:104)R,C(cid:105)
c→c(cid:48) (t, ∆) =
InfoLeak c,i→c(cid:48),i(cid:48) (t, ∆)
(cid:88)
(cid:88)
InfoLeak
(cid:88)
i(cid:48)
(cid:88)
i
i
i(cid:48)
(5)
Revisiting our example, we see that the Blue client leaks a total
of 6 × K bits to the Red client (Row 1 of Step 3).
2Note
InfoLeak c→c(cid:48) need not be equal to InfoLeak c(cid:48)→c.
information leakage
that
the
is
asymmetric
and
Figure 2: System overview
In this section, we provide a high-level overview of the Nomad
system which provides a side-channel agnostic mechanism to de-
fend against the information leakage attacks discussed in the pre-
vious sections. Figure 2 shows the overall system architecture of
Nomad.
High-level idea: Recall that we consider a strong adversary model
capable of (a) launching arbitrary (and unforeseen) side channels
and (b) precisely targeting potential victims. Moreover, the client
does not know which other clients might be potential threats. Thus,
every other client is a potential side-channel threat. Our goal is
to provide a mitigation mechanism against this strong threat model
and without any modiﬁcation to client guest OS, hypervisors, or the
cloud provider’s hardware platforms.
One extreme solution might be for clients to request “single ten-
ancy” solutions (i.e., dedicated hardware). While this may be an
option, it sacriﬁces the statistical multiplexing gains that are key
for the low costs of cloud computing. That said, this extreme so-
lution does provide some intuition on how we can defend against
arbitrary side channels from arbitrary tenants in the cloud, namely
minimizing co-residency.
Building on this insight, we envision a provider-assisted approach
where cloud clients leverage the provider as a trusted ally via an
opt-in “migration-as-a-service” solution. Our speciﬁc contribution
here is in identifying a new security-speciﬁc use case for migration
beyond the typical applications for planned maintenance [11].
Having described the high-level idea of Nomad, we now describe
the APIs (i.e., Service API and Client API) of Nomad before de-
scribing the end-to-end workﬂow.
Service API: As we saw in the previous section (§3), the informa-
tion leakage between a pair of clients depends on the information
sharing capabilities of the adversarial client’s VMs and the infor-
mation replication across the client’s VMs.
Thus, the cloud provider needs to make a decision at deployment
time regarding the type of adversarial and client model it wants to
offer; i.e., decide if it wants (cid:104)NR, NC(cid:105), (cid:104)NR, C(cid:105), (cid:104)R, NC(cid:105), or
(cid:104)R, C(cid:105) model. We assume this decision is made public. Different
cloud providers may choose one or the other depending on their
cost-performance considerations or customer needs or the same
DepartureController MachineVMMachineVMVMMachineVMMigrationEnginePlacementAlgorithmAPIClientConstraintsDeploymentModelCloud ProviderVMClientsVMVMClient APIService APIMove SetsService & Client APIVM WorkloadsConfig.Move VMs {…}time it takes to extract the secret). Intuitively, this condition means
that an adversary should not be able to recover the secret even if an
adversarial client is co-resident for the entire duration of the sliding
window. Note that K , in reality, refers to abstract rate of leakage,
which is the basic leakage rate for (cid:104)NR, NC(cid:105) (i.e., single VM case)
and some function of replication and collaboration otherwise. For
clarity, we base our discussion on the (cid:104)NR, NC(cid:105) case.
These parameters can be conﬁgured on knowing the state-of-the-
art leakage characteristics (i.e., K ). To make our discussion more
concrete, we explain using the work of Zhang et al., [42] as an
example, which took 6 hours to extract a 457-bit key giving a leak-
age rate of 1.27 bits per min. Thus, we suggest D = 30 min and
∆ = 10 epochs to ensure that K × ∆ × D ≤ P = 6 hours.
We do acknowledge that Nomad is not resilient against fast side-
channel attacks that extract the secret within an epoch (i.e., [21,
27]). Fast side-channel attacks, in principle, could be addressed by
reducing D accordingly (i.e., for side-channel attacks capable of
extracting the key in 2–3 min, we suggest D = 30 sec). However,
decreasing D comes at a cost of performance degradation. Further-
more, the cluster size has to decrease accordingly to handle small
D to ensure that the time to compute the placement is smaller than
D (Figure 5). In this case, we suggest using other side-channel de-
fenses in conjunction with Nomad (i.e., a general side-channel so-
lution) to strengthen defenses against evolving side channels. For
instance, such approaches can be used to 1) reduce K (e.g., inject-
ing cache noise [45] or divide the private keys among several client
VMs [31]); and 2) reduce P by refreshing the key (i.e., secret)
frequently.
Challenges: Having described this high-level view of the Nomad
system, we highlight key practical challenges we need to address
to turn this vision into practice:
• Efﬁcient algorithm: Given the four different models of infor-
mation leakage, we need efﬁcient algorithms that can work
in all four models. For instance, a seemingly natural solu-
tion might be to simply randomize the VM assignments across
epochs. However, as we will see, such naive solutions can actu-
ally be counterproductive (Figure 4 in §8). Finally, we need to
ensure that the provider and the clients do not incur signiﬁcant
performance penalty due to VM migrations.
• Scalability: Large cloud deployments have roughly tens of thou-
sands servers. Therefore, the Nomad Placement Algorithm must
be capable of scaling to such large deployments. While the
problem can be theoretically formulated as a large constrained
optimization problem, even state-of-art solvers cannot solve a
problem instance with more than 40 machines even after a day
(Table 1 in §8).
• Deployability: Nomad must be incrementally deployable with
minimal changes to the existing production stack and control
platforms and without modiﬁcations to client applications.
In the following section, we show how we design efﬁcient and
scalable greedy heuristics that can apply generally to all four de-
ployment options. Then, in §7 we describe how Nomad can be
seamlessly added to a production cloud management system and
discuss our speciﬁc experiences with OpenStack. Finally, we
show empirically in §8 with simulated workloads that we can achieve
good bounds on information leakage using a small number of mi-
grations and that the impact on typical cloud workloads (e.g., repli-
cated web services and Hadoop MapReduce) is small.
5 Nomad Placement Algorithm
In this section, we describe the design of the Placement Algorithm
in Nomad. We begin by describing the high-level problem that we
Figure 3: High-level view of the Placement Algorithm
provider may offer varied offerings. Clients who wish to be pro-
tected against a speciﬁc model of information leakage based on
their workloads and preferences can choose a cloud provider with
the desired service offering (i.e., R client who wants a guarantee
against NC adversary chooses a provider with (cid:104)R, NC(cid:105) offering).
Client API: Nomad allows clients to specify their workload con-
straints to help minimize the impact of migrations on client applica-
tions. This API allows clients to specify non-migration constraints
on some VM instances. For example, in the web server case the
front-end load balancer has to have zero down time and similarly
in the Hadoop case the master node has to always be up.
End-to-end workﬂow: Now, we describe the end-to-end work-
ﬂow of Nomad. Client VMs arrive and depart based on their work-
load requirements. The provider runs a Placement Algorithm with
the goal of minimizing the information leakage across arbitrary
pairs of clients (e.g., ensuring that no speciﬁc pair of clients are
co-resident for a signiﬁcant chunk of time) while also minimiz-
ing disruption to the client applications. To achieve this goal, the
Placement Algorithm takes a few key inputs to decide a placement
policy (Figure 3).
1. API: The Placement Algorithm needs to know 1) Service API
(i.e., the deployment model) to correctly compute the InfoLeak-
age between client-pairs, and 2) Client API to know which VM
instances are “non-movable” when computing VM placements.
2. VM placements and workloads: The current and past VM as-
signments for past ∆ epochs are used to decide next placement
assignments. The Placement Algorithm also takes an input of
VM arrivals/departures since the last epoch. These are used to
update VM-pair co-residency states internally tracked by the
algorithm.
3. Conﬁgurations: Conﬁgurations such as ∆ (sliding window)
and migration budget are also used in the algorithm.
Using these inputs, the Placement Algorithm computes the VM
assignments for the next epoch. The provider runs a Migration
Engine which takes the logical output of the Placement Algorithm