### (Un)Smashing the Stack

#### Introduction: Taking the Blue Pill (At First)

My first exposure to buffer overflows, like much of my introduction to the security field, came while working for a small ISP and consulting shop in the 1990s. Dave, who was building a security practice, took me under his wing. I was a budding Linux geek with an affinity for Bash. After a brief lecture about the finer points of tcsh, Dave borrowed my laptop running Slackware and showed me the Bash overflow in PS1, discovered by Razvan Dragomirescu. This demonstration was useful because it showed how a simple environment variable could overwrite a pointer. However, I immediately asked the pertinent question: what good does it do to crash a command shell and then run a command in the context of the same user? I supposed that if I ever encountered a restricted Bash shell, I was now armed to the teeth.

Still, I wanted to understand: how did those bits of shellcode get where they shouldn't be, and how did they execute a payload like "/bin/ls"? 

Not long after Dave's demonstration, I spent a lot of time studying Aleph One's work, got a good grasp of the concepts, and then went on a career path that rarely touched on the internals of buffer overflows. Over the next ten years, I was busy building defenses and mitigating the deluge of remote exploits hitting my customers and employers. I spent my days and nights scouring BugTraq (later Vulnwatch and Full-Disclosure), writing internal advisories, firefighting compromises and outbreaks, and repeating the mantra: "Patch early, and patch often."

In recent years, we seem to have found ourselves, as Bruce Schneier often points out, getting progressively worse at our jobs. While aggressive code auditing of critical infrastructure like BIND, Apache, Sendmail, and others may have reduced the volume of memory corruption vulnerabilities, they haven't reduced the severity of the exposure when such vulnerabilities are found. The client side is also a minefield, with email-based attacks, phishing, pharming, XSS, CSRF, and other threats showing that users are a weak link. Web application threats and the messy client- and server-side issues with Web 2.0 further complicate matters. Memory corruption vulnerabilities can lead to the exploitation of even the best-educated, best-hardened, and best-audited environments, rendering all other protection mechanisms irrelevant.

The most recent example that comes to mind, likely because I spent a very long week involved in cleanup for both private sector and government sites, is Big Yellow. A remote service listening on an unfiltered port on thousands of machines, running with high privileges, and vulnerable to a stack-based overflow. Sound familiar?

In my caffeine-addled fog during an all-night incident response for this latest worm, I asked myself: Does this make sense? Should we blame vendors, disclosure, automation, or the cardinal sin of failing to patch, for what ultimately comes down to a fundamental problem in error handling and memory allocation, described by Dave as "ten pounds of crap in a five-pound bag"?

Recently, Jon Richard Moser of Ubuntu Hardened analyzed the first 60 Ubuntu Security Notices and found that around 81% were due to buffer overflows, integer overflows, race conditions, malformed data handling, or a combination of these. Moser believes that the aggregate of available proactive security measures in compilers, kernel patches, and address space protections could obviate many, if not all, of these vulnerabilities. After a lot of digging, I think Moser may be right, though the devil is in the details.

#### When Dinosaurs Roamed the Earth

The first widely exploited buffer overflow was also the first self-replicating network worm, known as the Morris Worm, which is detailed in RFC1135, "The Helminthiasis of the Internet." The Morris Worm, a 99-line piece of C code, brought large sections of the then-primarily research network offline by starving systems of resources and saturating network connections while searching for other hosts to infect. One of its replication vectors was a stack-based overflow in the `gets()` call in SunOS’s `fingerd`.

Gene Spafford, in his 1988 analysis, described the vulnerability, noting that the standard C library has routines that read input without checking for bounds, such as `gets()`, `scanf/fscanf/sscanf`, `sprintf`, and `strcat/strcpy`. What strikes me is that Spafford's observations remain relevant today. Unchecked input for misallocated strings or arrays, and the resulting ability to overwrite pointers and control execution flow, whether on the stack, the heap, or elsewhere, remains a solvable problem, yet the exposure persists.

After Morris, things were quieter on the buffer overflow front. The rapid adoption of PCs and the lack of a security model for commodity operating systems meant that the primary attack surfaces were boot sectors and executables. Viruses were more scrutinized as an attack vector. However, buffer overflows were known and understood, with Nate Smith describing "Dangling Pointer Bugs" and the "Fandango on Core" as known issues in the ALGOL and FORTRAN communities since the 1960s.

As soon as alternatives to writing code directly to hardware in assembler became readily available, the abstraction created exposure. While a move to type-safe or interpreted languages has been suggested as the best solution, the massive installed base of critical applications and operating systems developed in C and C++ makes this infeasible for many years. Even interpreted languages need an interpreter, and overflows in the interpreter itself can still lead to exploitation, despite type safety, bounds-checking, and sandboxing.

#### Things Get Interesting

In February 1995, Thomas Lopatic posted a bug report and some proof-of-concept code to the Bugtraq mailing list, detailing a buffer overflow in NCSA HTTPD 1.3. The unchecked buffer in NCSA’s code to parse GET requests could be abused due to the use of `strcpy()` rather than `strncpy()`, similar to the Morris worm. He included example code that wrote a file named "GOTCHA" in the server’s `/tmp` directory, after inserting some assembler into the stack.

US-CERT recorded a handful of buffer-overflow-based vulnerabilities in the years since Morris, but Lopatic's finding was particularly relevant due to the rapid adoption of NCSA’s httpd and the growth of the Internet. The ability to arbitrarily execute code on any host running a web server, from anywhere on the Internet, created new interest in memory corruption vulnerabilities as a simple and effective way to execute arbitrary code remotely.

In the next two years, Mudge released a short paper on using GCC to build shellcode without knowing assembly and how to use gdb to step through the process of inserting code onto the stack. Shortly after, Aleph One’s seminal work on stack-based overflows expanded on Mudge's work, providing the basis for the body of knowledge still relevant today in exploiting buffer overflows. It's hard to find a book or research paper on overflows that doesn’t reference "Smashing the Stack for Fun and Profit," and for good reason. Aleph One’s paper raised the bar, synthesizing all the information available at the time, and made stack-based overflow exploit development a refinable and repeatable process. While it didn't create the overflow problem, it provided a starting point for clearly understanding it.

---

**Shawn Moyer**  
Chief Researcher, SpearTip Technologies  
[http://www.speartip.net](http://www.speartip.net)  
{ b l a c k h a t } [ at ] { c i p h e r p u n x } [ dot ] { o r g }