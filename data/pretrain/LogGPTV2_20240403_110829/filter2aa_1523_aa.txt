(((uuunnn)))   SSSm
m
maaassshhhiiinnnggg   ttthhheee   SSStttaaaccckkk:::   
22288 77755 666ee 22299 55533 666dd 66611 7733 66688 66699  66ee 66677 22200 55544 6688   6655   2200   55533 77744 66611 66633 666bb 333aa
8    5    e    9    3    d    1    73    8    9 6e    7    0    4    68 65 20
3    4    1    3    b    a    
fff o
ttt
fff   6 65 72 66    c    fff 77    3    c    0    3    
   5    e
4    5    2    d    5    1    3    
1    e    
   4    8    5    0    2    5    1    c    0    7    fff   72 6c    4    
O
OOvvveeerrr llloow
w
wsss,,,   CCCooouuunnn eeerrrm
m
meeeaaasssuuurrreeesss,,,   
444 77766  6655   7722   6666 666cc 666    7777 77733 222cc 22200 44433 666fff 77755 666ee   77744 66655 77722 666dd 66655 66611 77733 777555 777222 666555 777333 222ccc
aaannnddd   ttthhheee   RRReeeaaalll   W
W
Wooorrrlllddd   
66611 666ee 666444 222000 77744 66688 66655 22200 55522 66655 66611 666cc 22200 55577 666 7722   66cc 66644
Shawn Moyer 
Chief Researcher, SpearTip Technologies 
http://www.speartip.net
{ b l a c k h a t } [ at ] { c i p h e r p u n x } [ dot ] { o r g } 
0x00: Intro :: Taking the blue pill (at first). 
My first exposure to buffer overflows, like much of my introduction to the security field, 
was while working for a small ISP and consulting shop in the 90’s. Dave, who was building a 
security practice, took me under his wing. I was a budding Linux geek, and I confessed an 
affinity for Bash. After a brief lecture about the finer points of tcsh, Dave borrowed my laptop 
running Slackware, and showed me the Bash overflow in PS1, found by Razvan Dragomirescu.  
This was a useful demonstration in that a simple environment variable would work to overwrite a 
pointer, though I immediately asked the importunate question of what good it did anyone to get 
a command shell to crash and then, well, run a command, in the context of the same user. I 
supposed if I ever encountered a restricted Bash shell somewhere, I was now armed to the 
teeth. 
Just the same, I wanted to understand: how did those bits of shellcode get where they shouldn’t 
be, and get that nasty “/bin/ls” payload to run?  
Not too long after Dave’s demonstration, I spent a lot of time puzzling over Aleph One, got my 
brain around things relatively well, and then rapidly went orthogonal on a career that rarely, if 
ever, touched on the internals of buffer overflows. I was far too busy over the next ten years or 
so (like most folks in InfoSec) building defenses and sandbagging against the deluge of remote 
exploits hitting my customers and employers. I spent my days and nights scouring BugTraq (later 
Vulnwatch and Full-Disclosure), writing internal advisories, firefighting compromises and 
outbreaks, and repeating the same mantra to anyone who would listen: 
Patch early, and patch often.  
Rinse, lather, repeat.  
Service packs begat security rollups.  
Security rollups begat Patch Tuesday   
.
Patch Tuesday begat off-cycle emergency updates.  
Last week, the network admins rebooted my workstation three times. Seriously. 
In the past few years, we seem to have found ourselves, as Schneier often points out, getting 
progressively worse and worse at our jobs. While aggressive code auditing of critical pieces of 
infastructure like Bind, Apache, Sendmail, and others may have reduced the volume of memory 
corruption vulnerabilities found in critical services in recent years, they haven’t reduced the 
severity of the exposure when they are.  
Of course, the client end is a minefield as well – email-based attacks, phishing, pharming, XSS, 
CSRF and the like have all shown that users are unfailingly a weak link, to say nothing of web 
application threats and the miles of messy client- and server-side issues with Web 2.0… Just the 
same, memory corruption vulnerabilities can lead to exploitation of even the best-educated, best-
hardened, best-audited environments, and render all other protection mechanisms irrelevant.  
The most recent proof that comes to mind, likely because I spent a very long week involved in 
cleanup for both private sector and some government sites, is Big Yellow. Say it with me: A 
Shawn Moyer :: (un)Smashing the Stack :: DefCon 0x0F :: Page 2 of 13 
remote service. Listening on an unfiltered port on thousands of machines. Running with very high 
privileges. Vulnerable to a stack-based overflow.  
Sound familiar? 
In my caffeine-addled fog on an all-night incident response for this latest worm-of-the-moment, I 
asked myself: Does this make sense? Should we really be blaming vendors, or disclosure, or 
automation, or even the cardinal sin of failing to patch, for what ultimately comes down to a 
fundamental problem in error handling and memory allocation, described to me so succinctly by 
Dave all those years ago as “ten pounds of crap in a five pound bag”? 
Recently, Jon Richard Moser of Ubuntu Hardened did an analysis of the first 60 Ubuntu Security 
Notices, and found that of these, around 81% were due to either buffer overflows, integer 
overflows, race conditions, malformed data handling, or a combination of all four. Moser believes 
that the aggregate of available proactive security measures in compilers, kernel patches, and 
address space protections available today could serve to obviate many, if not all of these 
vulnerabilities.  
After a lot of digging, I think Moser may be right, though the devil, of course, is in the details.  
0x01: When Dinosaurs roamed the Earth. 
The first widely exploited buffer overflow was also what’s generally credited as the first 
self-replicating network worm, the response to which is covered in detail in RFC1135, circa 1988: 
“The Helminthiasis of the Internet”. A helminthiasis, for those without time or inclination to crack 
open a thesaurus, is a parasitic infestation of a host body, such as that of a tapeworm or 
pinworm. The analogy stuck, and all these years later it’s still part of the lingua franca of IT. 
The Morris Worm was a 99-line piece of C code designed with the simple payload of replicating 
itself, that (intentionally or otherwise) brought large sections of the then-primarily research 
network offline for a number of days, by starving systems of resources and saturating network 
connections while it searched for other hosts to infect.  
What’s relevant today about Morris is one of the vectors it used for replication: a stack-based 
overflow in the gets() call in SunOS’s fingerd. In his analysis in 1988, Gene Spafford describes 
the vulnerability, though he’s a bit closed-mouthed about the mechanics of how things actually 
worked: 
The bug exploited to break fingerd involved overrunning the buffer the daemon used for 
input. The standard C library has a few routines that read input without checking for 
bounds on the buffer involved. In particular, the gets() call takes input to a buffer 
without doing any bounds checking; this was the call exploited by the Worm. 
The gets() routine is not the only routine with this flaw. The family of routines 
scanf/fscanf/sscanf may also overrun buffers when decoding input unless the user 
explicitly specifies limits on the number of characters to be converted. Incautious use of 
the sprintf routine can overrun buffers. Use of the strcat/strcpy calls instead of the 
strncat/strncpy routines may also overflow their buffers. 
Shawn Moyer :: (un)Smashing the Stack :: DefCon 0x0F :: Page 3 of 13 
What strikes me most about the above is that Spafford is still spot-on, nineteen years later. 
Unchecked input for misallocated strings or arrays, and the resulting ability to overwrite pointers 
and control execution flow, whether on the stack, the heap or elsewhere, remains a (mostly) 
solvable problem, and yet the exposure remains with us today. 
After Morris, things were a bit quieter for awhile on the buffer overflow front. Rapid adoption of 
PC’s, and the prevalence of nothing even resembling a security model for commodity operating 
systems, meant that the primary attack surfaces were boot sectors and executables, and for the 
rest of the 1980’s virii were of substantially more scrutiny as an attack vector, for both defenders 
and attackers. 
This isn’t to say this class of vulnerabilities wasn’t known or understood, or that Morris was the 
first to exploit them – in fact Nate Smith, in a paper in 1997, describes “Dangling Pointer Bugs”, 
and the resulting “Fandango on Core” as being known of in the ALGOL and FORTRAN 
communities since the 1960’s!  
As has widely been stated, as soon as alternatives to writing code directly to hardware in 
assembler became readily available, the abstraction has created exposure. Of course, I’d be 
remiss if I didn’t point out that for nearly as long, a move to type-safe or even interpereted 
languages has been suggested as the best solution.  
Just the same, let’s accept for now that the massive installed base of critical applications and 
operating systems in use today that are developed in C and C++ will make this infeasible for 
many, many years to come. Also, as Dominique Brezinski pointed out in a recent BlackHat talk, 
even an interpereted language, presumably, needs an interpereter, and overflows in the 
interpereter itself can still lead to exploitation of code, safe types, bounds-checking, and 
sandboxing notwithstanding.  
0x02: Things get interesting. 
In February of 1995, Thomas Lopatic posted a bug report and some POC code to the 
Bugtraq mailing list. 
Hello there, 
.
We've installed the NCSA HTTPD 1 3 on our WWW server (HP9000/720, HP-UX 9.01) and 
I've found that it can be tricked into executing shell commands. Actually, this bug is 
similar to the bug in fingerd exploited by the internet worm. The HTTPD reads a
maximum of 8192 characters when accepting a request from port 80. When parsing the 
URL part of the request a buffer with a size of 256 characters is used to prepend the 
document root (function strsubfirst(), called from translate_name()). Thus we are able to 
overwrite the data after the buffer. 
The unchecked buffer in NCSA’s code to parse GET requests could be abused due to the use of 
strcpy() rather than strncpy(), just as described by Spafford in his analysis of the Morris worm 
seven years earlier. He included some example code that wrote a file named “GOTCHA” in the 
server’s /tmp directory, after inserting some assembler into the stack.  
Shawn Moyer :: (un)Smashing the Stack :: DefCon 0x0F :: Page 4 of 13 
US-CERT recorded a handful of buffer-overflow-based vulnerabilities in the years since Morris, 
but what made a finding like Lopatic’s so relevant was the rapid adoption of NCSA’s httpd, and 
the growth of the Internet and its commercialization. This really was a whole new (old) ballgame. 
The ability to arbitrarily execute code, on any host running a web server, from anywhere on the 
Internet, created a new interest in what Morris’ stack scribbling attack a number of years ago had 
already proven: memory corruption vulnerabilities were a simple and effective way to execute 
arbitrary code remotely, at will, on a vulnerable host. 
In the next two years, Mudge released a short paper (which he described as really a note to 
himself) on using GCC to build shellcode without knowing assembly, and how to use gdb to step 
through the process of inserting code onto the stack.  
Shortly after, Aleph One’s seminal work on stack-based overflows expanded on Mudge, and 
provided the basis for the body of knowledge still relevant today in exploiting buffer overflows. 
It’s hard (if not impossible) to find a book or research paper on overflows that doesn’t reference 
“Smashing the Stack for Fun and Profit”, and with good reason.  
Aleph One’s paper raised the bar, synthesizing all the information available at the time, and made 
stack-based overflow exploit development a refinable and repeatable process. This is not to say 
that the paper created the overflow problem, and almost certainly the underground had 
information at the time to rival that available to the legitimate security community. While in some 
ways kicking off the disclosure debate, what “Smashing the Stack” ultimately provided was a 
starting point for clearly understanding the problem. 