### Over the Following Month

While we were able to isolate the problem to a single vendor in this instance, our process for reaching out to them does not scale to all middleboxes and vendors. We do not know if other bits exposed by QUIC have been ossified by this or other middleboxes, and we lack a method to answer this question at an Internet-wide scale. We learned that middlebox vendors are reactive; they build responses to observed changes in traffic patterns. This pattern of behavior exposes a "deployment impossibility cycle": deploying a protocol change widely requires it to work through a vast range of middleboxes, but middleboxes only change their behavior in response to the wide deployment of the change. This experience reinforces the premise on which QUIC was designed: when deploying end-to-end changes, encryption is the only means available to ensure that bits that should not be used by a middlebox are, in fact, not used.

### 8. Related Work

SPDY [3] aims to reduce web latency and has been subsumed by the HTTP/2 standard [8]. QUIC is a natural extension of this work, further reducing latency down the stack.

QUIC’s design is most similar to Structured Stream Transport (SST) [23]. Both SST and QUIC use channel identifiers, monotonically increasing packet numbers, encrypted transport headers, and lightweight streams. However, QUIC builds on these ideas with several key differences. For example, while SST avoids handshake latency for subsequent streams, the first stream incurs it. QUIC avoids handshake latency on repeat connections to the same server and includes version negotiation in the handshake. Stream multiplexing to avoid head-of-line blocking is not a new concept; it is present in SCTP [62], SST [23], and as message chaining in Minion [32]. QUIC borrows this design idea. Additionally, QUIC uses shared congestion management among multiple application streams, similar to SCTP, SST, and the Congestion Manager [7].

MinimaLT [51] was developed contemporaneously and shares a similar 0-RTT handshake, multiplexes application "connections" within an encrypted MinimaLT "tunnel," and performs congestion control and loss detection on the aggregate. MinimaLT also prevents the linkability of a connection as it migrates from one IP address to another, a privacy-preserving feature currently under consideration as QUIC evolves at the IETF.

Modifications to TCP and TLS have been proposed to address their handshake latencies. TCP Fast Open (TFO) [11, 53] reduces the handshake latency of TCP by allowing data in the TCP SYN segment to be delivered to a receiver on a repeat connection to the same server. TFO and QUIC differ in two key ways. First, TFO limits client data in the first RTT to the amount that fits within the TCP SYN segment, whereas QUIC allows a client to send as much data as allowed by the congestion and flow controllers in the initial RTT. Second, TFO is useful on repeat connections to a destination with the same IP address as the first connection. Since servers often use multiple IP addresses for the same hostname, repeat TCP connections to the same domain may end up at different server IP addresses. QUIC, combining the cryptographic layer with transport, uses 0-RTT handshakes with repeat connections to the same origin. Finally, while TFO is now implemented in major operating systems (Windows, Linux, MacOS/iOS), its deployment is limited due to middlebox interference [50] and slow client OS upgrades.

QUIC’s cryptographic handshake protocol was initially homegrown but has been formally analyzed by various groups [20, 38, 44]. Facebook’s Zero Protocol was directly derived from QUIC’s cryptographic protocol [35]. TLS 1.3 [55], inspired in part by QUIC’s handshake protocol [42], addresses the handshake latency of TLS 1.2, the currently deployed TLS version. Since TLS 1.3 now provides the latency benefits of QUIC’s cryptographic handshake, IETF standardization work will replace QUIC’s cryptographic handshake with TLS 1.3 [63].

### 9. Conclusion

QUIC was designed and launched as an experiment and has now become a core part of our serving infrastructure. We knew that the wide deployment of a new UDP-based encrypted transport for HTTP was an ambitious goal, with many unknowns, including whether UDP blocking or throttling would be show-stoppers. Our experimentation infrastructure was critical in QUIC’s deploy-measure-revise cycles, allowing us to build and tune a protocol suited for today’s Internet.

We expect to continue working on reducing QUIC’s CPU cost at both the server and the client and improving QUIC performance on mobile devices. One of QUIC’s most important features is its ability to serve as a platform for wide-scale experimentation with transport mechanisms, both at the server and at the client. Ongoing experimentation and work is continuing on several fronts. First, we are experimenting with connection migration to reduce latency and failures with various mobile applications. Later work may include the implementation of general-purpose multipath [31, 54]. Second, we are experimenting with modern congestion controllers such as BBR [10] and PCC [16]. Third, we are working on using QUIC for WebRTC [4] and intend to explore avenues for better supporting real-time payloads.

The lessons we learned and described in this paper are transferable to future work on Internet protocols. Of the lessons, a few important ones are worth reiterating. First, developing and deploying networking protocols in user space brings substantial benefits, making development, testing, and iteration cycles faster and easier. Second, layering enables modularity but often at the cost of performance, and re-designing and rewriting critical paths in the protocol stack is a useful exercise. Squashing the layers of HTTPS in QUIC allowed us to weed out inefficiencies in the HTTPS stack.

Finally, while a tussle between the endpoints and the network is expected and inevitable, it can only be resolved when all interested parties come to the table [13]. Previous attempts to deploy protocols that require any modification to network devices—ECN [41], SCTP [62], TCP Fast Open [11], and MPTCP [47, 54], to name a few—have unequivocally exposed the difficulties of incentivizing and achieving consensus on proposed network changes. As noted in [13], "the ultimate defense of the end-to-end mode is end-to-end encryption." Encryption forces the conversation among various parties and remains the sole guardian of the end-to-end principle.

### Acknowledgments

A project of this magnitude is not possible without a lot of hands. We thank Amin Vahdat, Assar Westerlund, Biren Roy, Chris Bentzel, Danner Stodolsky, Jeff Callow, Leonidas Kontothanassis, Mihai Dumitrescu, Mike Warres, Misha Efimov, Roberto Peon, Siddharth Vijayakrishnan, Tarun Bansal, Ted Hardie, and Yu-Ting Tseng for their work and support over the years.

We thank all groups at Google that helped deploy QUIC, especially the Traffic Team.

We also thank folks at Akamai, Caddy (quic-go), and Christian Huitema for implementing and/or adopting QUIC early and providing incredibly valuable feedback. Without their help, QUIC would not be where it is today.

We thank Jeff Mogul, Matt Welsh, Stuart Cheshire, our shepherd Ankit Singla, and the anonymous SIGCOMM reviewers for reviewing previous versions of this paper. Without their help, this paper would have been an unreadable mess.

### References

[References remain unchanged and are listed as provided in the original text.]

---

This revised version aims to improve clarity, coherence, and professionalism while maintaining the original content and structure.