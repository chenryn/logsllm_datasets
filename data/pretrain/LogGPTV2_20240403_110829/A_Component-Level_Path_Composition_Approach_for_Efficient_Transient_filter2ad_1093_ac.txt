### 3.2. Expected Instantaneous Reward Calculation

Given the number of possible reorderings of local transitions between two immediate synchronized transitions, we have:

\[
Y_i = 0, \quad (15)
\]
where
\[
i! \left( \prod_{j=1}^{J} k(j) \right) \quad \text{and} \quad \sum_{i=0}^{k(j)} \frac{1}{i!}
\]

Using equations (10), (13), (14), and (15), we can compute the expected instantaneous reward for a model. Let \(\mathcal{L}\) be the set of all sequences of synchronized transitions. The expected instantaneous reward \(E[R_s]\) is computed by:

\[
E[R_s] = \sum_{\sigma \in \mathcal{L}} \sum_{m=|\sigma|}^{\infty} \sum_{i=0}^{k(j)} \frac{1}{i!} \left( \prod_{j=1}^{J} k(j) \right) \cdot \text{Prob}(\sigma) \cdot \left( \sum_{j=1}^{|\sigma|} \gamma(j) \cdot \lambda^{k(j)} \right)
\]

for \(j = 1, 2, \ldots, |\sigma|\), where \(\gamma(j)\) is the subpath reward and \(\lambda\) is the state transition rate.

For an additive reward, we must use the summation in (10) instead of the last product in (16). The equations for the expected accumulated reward can be derived similarly.

### 3.3. Algorithm for Computing Expected Reward

The algorithm works by generating the set of sequences of synchronized transitions. For each sequence, a class of composable subpaths is explored, and their values are precomputed using (10) and (13). Afterward, the subpaths are composed, and their values are used to compute the expected reward of the model. The subpaths in a class of composable subpaths may be explored using a depth-first strategy to minimize memory usage. The algorithm is storage-efficient because during each stage of the computation, only two real values for each subpath are stored. Additionally, it is computationally efficient because each subpath, as a redundant computation across many paths, is computed only once and reused multiple times.

### 3.4. Selecting Important Subpaths

Although there are many paths to consider, a large number often contribute little or no reward toward the computation of the bounds on the solution of a model. We can speed up the computation by identifying important paths and discarding those that contribute little or nothing toward tightening the bounds. Our approach is based on additional information available from the computed subpaths.

Several subpath factors directly affect the reward contribution of a path. One of the main factors is the subpath reward \(\gamma(i)(\alpha(i))\). If a subpath has zero reward, all paths composed from it also have zero reward. By efficiently computing the projection of a component reward vector \(r(i)\) onto component \(i\), we can cache and reuse the projected reward vector. When subpaths are being explored, their reward values can be computed efficiently by a scalar product of the subpath state distribution vector and the projected reward vector, with a complexity of \(O(n_i)\) rather than \(O(n_i^2)\), where \(n_i\) is the size of the state space of component \(i\).

We implement this approach by computing all projected reward vectors and caching them before any subpath is computed. As the subpaths are explored, the projected reward vectors are used to compute the subpath reward values. Those subpaths that contribute non-zero reward values are retained for composition with other subpaths; the rest are discarded immediately. When a zero-reward subpath is discarded, we also discard the successive subpaths that can be generated from it, although they may have non-zero reward values. In our experiments, the contributions of these discarded subpaths toward tightening the bounds appear to be negligible.

### 4. Numerical Results

We evaluate our algorithm by studying its performance in analyzing two models with very different characteristics: a distributed information service system and a media multicast system. In the former model, we evaluate the reliability and availability of the system; in the latter model, we evaluate the performability properties of the corresponding system. The latter model has more components, a larger state space, and tighter coupling among the components.

#### 4.1. Model Description of the Distributed Information Service System

We augment the original model of the distributed information service system with synchronized transitions among the components to describe how faults are propagated through the system. We increase the number of front-end modules to model the occurrence of a fault only when a majority of the modules are corrupted. We also model double redundancy in the processing units by adding an additional module for every module in the original processing units. These additions result in a model with approximately \(2.7 \times 10^{18}\) states, which is too large to be analyzed using traditional techniques but can be analyzed using our approach.

The model consists of six front-end modules that interact with four processing units. Each processing unit includes redundant components, such as processors, switches, memory units, and databases, each with its own repair facility. Fault propagation is modeled as follows:
- When a majority of the six front-end modules are corrupted, the front-end is considered faulty and may propagate the error to any of the four processing units.
- When both processors in a processing unit are corrupted, they may propagate the error to their working switches.
- When both switches of a processing unit are corrupted, they may propagate their errors to the working memory units.
- When both memory units of a processing unit are corrupted, they may propagate their errors to the working databases.

We vary activity rates in the submodels and among the synchronized activities to ensure the model does not have symmetries that would allow it to be lumped. The model has 5 submodels (modeling 38 components) and 4 synchronized activities. The state space of the whole model has \(2 \times 3^{38} \approx 2.7 \times 10^{18}\) states. We computed the reliability of the system over the interval \([0, 1.0]\), the point availability at time 0.1, and the interval availability over the interval \([0.0, 0.1]\) when all components in the model were in the working state.

#### 4.2. Model Description of the Media Multicast System

The SAN model of the media multicast system is parameterized by many variables, allowing us to measure the sensitivity of the system and the likelihood of buffer overflow. The model consists of a source (CMU) that multicasts frames to clients Berkeley, UIUC1, and UWisc. Berkeley and UIUC1, in turn, multicast the frames further to UCSB, UIUC2, and UKY. The complete model has seven submodels and approximately \(1.9 \times 10^{20}\) states.

Frames are initially generated by the source, CMU. The tasks of the clients are to decode, process, and encode the frames for further multicast. All components may be in one of the operational, corrupted, or failed modes at any instant of time, and they all have their own repair facilities. They may transmit frames only when they are operational. When they are corrupted, their frame buffers are flushed, and transmitted frames are dropped when the clients' buffers are full. The sensitivity of the system depends on the buffer sizes, transmission rates, and processing rates of the components.

By varying these parameters, we can compute the probability of having a buffer overflow or buffer flushing at some time after the system has been in operation. The results are not meant to be representative of any real system, but they show that the parameters are interdependent and that our algorithm works correctly in computing the results for the varied parameters.

#### 4.3. Experimental Evaluation

We conducted all experiments on a workstation with an AMD Athlon XP 2700+ processor running at 2.17 GHz with 1.0 GB of RAM. The operating system was Red Hat Linux 9.0, and we compiled our implementation using g++ 3.3 with the optimization flag -O3.

For the distributed information service system model, the MÖbius simulation results are:
- Point availability: 0.99883 ± 2.11883414 × 10⁻⁴
- Interval availability: 0.099934 ± 1.340263 × 10⁻⁵
- Reliability: 0.98616 ± 7.241023 × 10⁻⁴

For the media multicast system model, the MÖbius simulation results are:
- Probability of buffer overflow: 0.925 ± 1.63 × 10⁻²
- Probability of buffer flushing: 0.365 ± 2.99 × 10⁻²

Tables 1 and 2 show the results for the availability and reliability measures, respectively, of the distributed information service system model calculated using our path-based approach. The lower and upper bounds for each measure converge as the path length increases. Although the path-selection approach discards zero-reward subpaths and their successive subpaths, the bound values for this particular model are not affected up to the seventh significant digits in any of the experiments we performed.

Column "Basic Algorithm Time (sec)" lists the time taken to evaluate the model using the path-based approach described in [6]. Column "Path Decomposition Enhanced Algorithm Time (sec)" lists the time taken using our new algorithm, which makes use of the path-decomposition and path-selection schemes. As shown in the time columns for both the availability and reliability results, our new algorithm achieves approximately 80% performance improvement relative to the previous algorithm. As the path length gets longer, the algorithm performs better. For example, at the path length of 6 for the availability results, it achieves almost 85% improvement; at the same path length for the reliability results, it achieves 87% improvement. We do not have the timing result for the basic approach at the path length of 7, because it takes too long to compute.

Tables 3 and 4 show the results for the probabilities of buffer overflow and buffer flushing, respectively, for the media multicast system model. For this model, the values of the bounds computed by the basic approach and by the new algorithm differ somewhat. We list the values of both bounds in the tables for comparison. To better understand the rates of convergence of the bounds, we provide a detailed analysis in the following sections.