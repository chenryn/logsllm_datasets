we do not strive for confidentiality with our approach, the use
of a cryptographically secure cipher is not needed. The resulting
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Robert Schilling, Mario Werner, Pascal Nasahl, and Stefan Mangard
encoded data is then simply stored into memory like in a regular
system.
When data is read back from memory into a processor regis-
ter, the decoding with respect to the target address is performed.
Considering that the performed decoding operation is the inverse
of the encoding, a genuine data value is restored only when the
read has been performed from the correct address. Otherwise, an
incorrect data value is generated which can be detected via the used
data-protection scheme. Note that the detection of address tamper-
ing during memory writes is possible like this as well. However,
the detection is delayed to the point where the incorrectly written
value is read back into the processor.
(cid:16)
(cid:17)
(cid:16)
(cid:17)
4.2 The Linking Approach
As already mentioned, the general idea behind our memory access
protection approach is to link the data that is stored in memory with
its respective address. Instead of directly writing a register value
DReд into memory at the a certain address p (i.e., mem[p] = DReд),
a little more work has to be performed in our scheme. Namely, as
shown in Equation 2, the linking function l has to be evaluated in
order to determine the value that is actually written to the memory
at address p.
mem[p] = l
= lp
DReд
p, DReд
(2)
The purpose of this linking function is to combine the address p
with the data value DReд. However, not every function can be used
for this purpose. At the very least, the following two requirements
have to be fulfilled in this context. First, for each address p, the link-
ing function lp has to be a permutation. Having this property means
that lp performs a bijective mapping and that an inverse function
p exists, i.e., ∀p, DReд → l−1
l−1
= DReд. Subsequently,
memory read operations can be implemented using this inverse
function as shown in Equation 3. As the result, from the software
perspective, encoding data when storing to memory and decoding
data when loading from memory is completely transparent, yields
the expected result, and can be performed for every memory access.
(cid:17)(cid:17)
DReд
(cid:16)
(cid:16)
p
lp
−1 (p, mem[p]) = l
−1
p (mem[p])
(cid:16)
DReд = l
(3)
Second, to ensure that addressing faults are detectable, data
encoded under one address should yield a modified value when
being decoded under a different address, i.e., ∀p, p′, DReд : p (cid:44)
p′ → l−1
p′
ified value should not be a valid code word in terms of the used
data-protection code.
(cid:17)(cid:17) (cid:44) DReд. Note, furthermore, that the mod-
DReд
(cid:16)
lp
Function Selection. Various functions, like for example crypto-
graphic ciphers, fulfill these requirements and are therefore suitable
to link the data and the address information as required by the mem-
ory access protection scheme. However, given that we aim for a
low-overhead design, less resource demanding functions have been
investigated.
Interestingly, already a simply xor operation, as shown in Equa-
tion 4 and Equation 5, is sufficient as the linking function for our
use case. In more detail, in our scheme, addresses are encoded us-
ing arithmetic multi-residue codes and the data encoding can be
selected arbitrarily. On the one hand, when the same multi-residue
code is also used for the data, e.g., an encoded pointer is written
to memory, using the xor operation is good choice given that that
multi-residue codes are not closed under the xor operation. Subse-
quently, it is also unlikely that combining multiple valid code words
yields a valid result and therefore facilitates error detection. On the
other hand, even when a data protection code which is closed under
the xor operation is used, still similar error detection capabilities
are expected. After all, combining code words from different codes
is highly unlikely to yield sensible results.
mem[p] = p ⊕ DReд
DReд = p ⊕ mem[p]
(4)
(5)
Linking Granularity. Theoretically, the previously described link-
ing approach can be applied with arbitrarily granularity. Therefore,
applying the technique on the processor’s native word size, e.g.,
64-bit in our prototype, may appear natural. However, performing
xor-based linking on such a coarse granularity does not yield the
desired amount of diffusion. Namely, bytes that are close to each
other, i.e., with a stride of 8 bytes when operating on 64-bit, are
highly likely to have the same address pad. Furthermore, in many
real-world applications, also misaligned data accesses with arbi-
trary size have to be supported efficiently. Situations like this, for
example, commonly arise when arbitrarily aligned data is copied
via the memcpy function.
Therefore, to fix the problem of the low diffusion and the arbi-
trarily aligned data accesses, we perform the linking of data and
address with byte-wise granularity. Each byte, even when it is part
of a larger memory transfer, is independently linked with its re-
spective address. Hereby, each individual byte-address pointer is
still multi-residue encoded to provide the desired diffusion during
linking. Furthermore, the actual linking is again performed via an
xor similar to Equation 4. However, considering that the data and
its address have different bit sizes, an additional compression is
applied on the address before linking. Namely, each 64-bit address
p = [p0, p1, . . . , p7] gets reduced to an one byte value p′ by xor-ing
the individual address bytes as shown in Equation 6.
7
i =0
′ =
p
pi
(6)
Applying this approach to a full 64-bit word is visualized in Fig-
ure 3. Considering the number of needed multi-residue operations
for such a word-sized access, using this linking scheme effectively
requires hardware support. In this work, we therefore integrated
the needed transformations directly into special load and store
instructions. From the software perspective, encoding data when
storing to memory and decoding data when loading from memory
is completely transparent and can be performed for next to every
memory access.
4.3 Memory-Mapped I/O
Memory-mapped I/O (MMIO) is a common communication inter-
face in embedded processors to access peripherals. In MMIO, the
peripheral registers are mapped into the standard memory layout
Pointing in the Right Direction - Securing Memory Accesses in a Faulty World
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
value of the pointer, which also includes the MMIO-bit in the pro-
tection domain. As a second instruction, we add support to decode a
multi-residue encoded register (rdec). Both instructions are idempo-
tent, meaning they can repeatedly be executed (encoding an already
encoded value does not change the encoding).
radd, raddi, rsub. To support pointer arithmetic on encoded point-
ers, hardware support for the most commonly used operations is
added. Concretely, we support adding two multi-residue encoded
register values (radd), adding a multi-residue encoded value to an
immediate value (raddi), and subtracting multi-residue encoded
values (rsub). The immediate value in the raddi instruction is not
yet multi-residue encoded. However, these values are part of the
instruction encoding and are already protected via the CFI code
protection scheme. Note that, before the immediate can be used
in a residue operation, it gets encoded as part of the instruction
execution.
rlxck, rsxck. Since we now use encoded pointers and require
data linking/unlinking, dedicated memory instructions are added
to the ISA. Therefore, a family of new load (rlxck) and store (rsxck)
instructions is added. Herby, the x denotes the access granularity
of the memory operation. Concretely, we support byte (b), half-
word (h), word (w), and double word (d) accesses with and without
sign extension, which corresponds to the original memory access
instructions in the RISC-V 64-bit ISA. The new instructions have
the same operand interface as the original load and store instruc-
tions of RISC-V. However, they now take an encoded pointer for
addressing the memory. The memory instructions also contain a
plain immediate value to add an offset to the pointer, which is pro-
tected by the CFI code protection. Furthermore, these instructions
perform the data linking and unlinking on a byte-wise granularity.
However, if the 40th-bit, the MMIO bit, is set to one, no data linking
and unlinking is performed, which allows us to use a protected
pointer when accessing a memory location, which does not support
data linking, e.g., a memory-mapped peripheral.
Since every memory access is replaced with its protected coun-
terpart, the protection mechanism could already be implemented in
the original load and store instructions of the processor. However,
for the sake of still supporting the original RISC-V instructions, they
are left unmodified, and new instructions are added separately.
5.2 Hardware
The instruction set is only one part of our protected architecture.
We also implemented the modified instruction set in hardware. As
foundation, the open-source 32-bit RISC-V core RI5CY [33] is used.
This core is extended to a 64-bit processor meaning that the register
file, datapath, and load-and-store unit are modified and all necessary
instructions are added to be compliant with the RISC-V RV64IM
instruction set. Furthermore, we added the new instructions to
deal with multi-residue encoded pointers, as defined in Section 5.1.
Figure 4 shows the modified processor pipeline, which includes
a dedicated arithmetic logical unit (ALU) for residue operations.
Furthermore, immediate values, which are part of the instruction,
get encoded during the instruction decode stage of the processor
pipeline. The load-and-store unit is extended to support data linking
and unlinking to protect all memory accesses.
Figure 3: Byte-wise data linking of a 64-bit word. Each byte
gets xored with its respective xor-reduced encoded address.
of the processor. This allows the CPU to use ordinary load and store
instructions to access the peripheral.
However, in order to protect the memory access, our architec-
ture uses redundant pointers and links them with the data before
executing the memory access. Since a standard memory-mapped
peripheral is not aware of this data linking, wrong data would be
written to the device. Therefore, we cannot apply data linking when
accessing a memory-mapped peripheral. However, we still can use
an encoded pointer to access the memory-mapped peripheral as
this does not influence the data. In order to use an encoded pointer
but not perform the data linking, we would need special instruc-
tions for load and store for this purpose. We avoid this overhead by
encoding this information directly into the encoded pointer. The
load and store instructions detect this and do not perform the data
linking accordingly.
As shown in Section 3, we redundantly encode the pointer us-
ing a multi-residue code. In Figure 2, we show the pointer layout
where the 41st MMIO-bit indicates whether the pointer is for an
MMIO access without data linking. The residues, which form the
redundancy of the pointer, are computed over the 40-bit functional
pointer value and the MMIO-bit to protect both against tampering.
5 ARCHITECTURE
The concept of protected pointers and linked memory accesses is
integrated in a prototype implementation based on a 64-bit RISC-V
architecture. In this section we first discuss the new instructions,
show how we integrated them into the architecture, and finally
show a compiler prototype to automatically protect all memory
accesses in a program.
5.1 New Instructions
As previously described, it requires hardware support to efficiently
perform the residue arithmetic such that the performance penalty
is acceptable. In this work, we extend the instruction set of the
processor with instructions that operate in the encoded residue
domain. In particular, the following custom instructions are added
to the instruction set.
renc, rdec. To efficiently encode a value into the multi-residue
domain, a dedicated encoding instruction (renc) is added. The en-
coding operation computes the residues over the 41-bit functional
d0d7d6d5d4d3d2d1. . .p7,0p0,0Xor-reduced pointer p7Xor-reduced pointer p0ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Robert Schilling, Mario Werner, Pascal Nasahl, and Stefan Mangard
5.3 Software
To make the countermeasure practical and protect every memory
access in the program, the new instructions and the protection
mechanism also need to be integrated into the compiler. In the
following, we integrate our countermeasure to the LLVM-based C
compiler [17].
An LLVM-based compiler is partitioned into three parts, the front
end, the middle end, and the back end. While the middle end opti-
mizes target-independently on an intermediate code representation,
the back end transforms the universal intermediate representation
to a target-dependent code. To protect every memory access in the
program, the countermeasure needs to be inserted in the back end
stage of the compiler. Any earlier transformation can potentially
miss a memory access leaving some accesses possibly unprotected
(e.g., the stack is created in the target-dependent part of the back
end). Even in the back end, the protection happens right before the
final instruction scheduling.
LLVM’s back end uses a directed acyclic graph (DAG) represen-
tation, the Selection DAG, for the code generation. The intermediate
representation is transformed in a series of steps to finally emit the
machine code. However, the back end has no information about
pointers and addresses. Therefore, this information is created and
propagated manually on the Selection DAG. Dedicated pointer
nodes are added to the Selection DAG where pointers are created,
e.g., when creating a FrameIndex node used for a local stack mem-
ory access. This information is then propagated on the Selection
DAG and all dependent operations are replaced with their corre-
sponding residue counterpart. If we obtain an instruction, which
is not supported by the residue code, the pointer is decoded, the
operation is performed in the unencoded domain, and then, the
pointer is re-encoded. However, this sequence of instructions is not
used in the majority of the transformations. Finally, protected load
and store instructions are emitted, which use an encoded pointer
for addressing the memory.
If the program uses a constant address, e.g., the address of a
global variable, this information needs to be encoded to the multi-
residue domain. However, the compiler does not have this infor-
mation yet. Therefore, it creates a relocation such that the linker
can fill in the correct address information. Since this information
requires multi-residue encoding, the linker is also modified. In our
work, we use a custom RISC-V back end of LLVM’s lld linker. In
addition to resolving regular relocations, our linker also applies
multi-residual encoding to pointers in the binary. This includes
pointers synthesized in code as well as pointers stored in the mem-
ory, which additionally get linked with address information. Similar
to that, data stored in the read-only section of the binary is also
linked with its address. As soon as these values are loaded into a
register, the unlinking operation is performed and the correct value
is restored.
6 EVALUATION
In order to make a countermeasure usable in practice, the overhead
must be reasonable. In this section, we first show the introduced
hardware overhead and then evaluate different benchmark applica-