title:Threat Intelligence Computing
author:Xiaokui Shu and
Frederico Araujo and
Douglas Lee Schales and
Marc Ph. Stoecklin and
Jiyong Jang and
Heqing Huang and
Josyula R. Rao
Threat Intelligence Computing
Xiaokui Shu
IBM Research
PI:EMAIL
Frederico Araujo
IBM Research
PI:EMAIL
Douglas L. Schales
IBM Research
PI:EMAIL
Marc Ph. Stoecklin
IBM Research
PI:EMAIL
Jiyong Jang
IBM Research
PI:EMAIL
Heqing Huang
IBM Research
PI:EMAIL
Josyula R. Rao
IBM Research
PI:EMAIL
ABSTRACT
Cyber threat hunting is the process of proactively and iteratively
formulating and validating threat hypotheses based on security-
relevant observations and domain knowledge. To facilitate threat
hunting tasks, this paper introduces threat intelligence computing as
a new methodology that models threat discovery as a graph compu-
tation problem. It enables efficient programming for solving threat
discovery problems, equipping threat hunters with a suite of potent
new tools for agile codifications of threat hypotheses, automated
evidence mining, and interactive data inspection capabilities.
A concrete realization of a threat intelligence computing plat-
form is presented through the design and implementation of a
domain-specific graph language with interactive visualization sup-
port and a distributed graph database. The platform was evaluated
in a two-week DARPA competition for threat detection on a test bed
comprising a wide variety of systems monitored in real time. Dur-
ing this period, sub-billion records were produced, streamed, and
analyzed, dozens of threat hunting tasks were dynamically planned
and programmed, and attack campaigns with diverse malicious
intent were discovered. The platform exhibited strong detection
and analytics capabilities coupled with high efficiency, resulting in
a leadership position in the competition. Additional evaluations on
comprehensive policy reasoning are outlined to demonstrate the
versatility of the platform and the expressiveness of the language.
CCS CONCEPTS
• Security and privacy → Intrusion detection systems; Formal
security models; • Computing methodologies; • Information
systems → Query languages;
KEYWORDS
Threat hunting; intrusion detection; computing methodology
ACM Reference Format:
Xiaokui Shu, Frederico Araujo, Douglas L. Schales, Marc Ph. Stoecklin,
Jiyong Jang, Heqing Huang, and Josyula R. Rao. 2018. Threat Intelligence
Computing. In 2018 ACM SIGSAC Conference on Computer and Communi-
cations Security (CCS ’18), October 15–19, 2018, Toronto, ON, Canada. ACM,
New York, NY, USA, 16 pages. https://doi.org/10.1145/3243734.3243829
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5693-0/18/10...$15.00
https://doi.org/10.1145/3243734.3243829
1 INTRODUCTION
After decades of research and development on intrusion and anom-
aly detection, malware analysis, domain expert systems, and secu-
rity information and event management systems, modern cyberse-
curity practice still relies heavily on human experts for information
digestion and decision making in tasks such as context completion,
false positive elimination, and end-to-end attack story construction.
The problem can be traced in part to the involved threat campaign
discovery process, which often demands the ability to establish
causal inferences based on missing contextual information and
domain knowledge not easily enumerable by current techniques.
Not surprisingly, one major gap between completely autonomous
threat detection and today’s automated systems is the inability to
effectively model all required knowledge in pre-programmed sys-
tems. Conventional approaches either i) program specific human
knowledge into their detection logic (such as rule-based detection,
intrusion detection expert systems, and behavior-based detection),
or ii) acquire detection knowledge from limited and scarce training
domains (such as binary analysis, anomaly detection, and automatic
feature engineering). The former category exhibits incomplete cog-
nitive traits associated with the encoding of contextual domain
knowledge applied to pre-programmed threat detection models,
while the latter subsumes the difficult and tedious task of eliminat-
ing false positives to separate anomalous (e.g., evolution of user
behaviors) from malicious (e.g., an actual exploit) behaviors.
Moreover, machine learning-based detection schemes learn from
preset domains (e.g., feature domains for unsupervised clustering),
and these learning domains are neither adaptive nor guaranteed to
cover the ever-evolving attack techniques. For example, *.*.*.255
is commonly set as a broadcast IP, which is not security-relevant
until an analyst links it to a data exfiltration campaign that hides the
destination of a cross-host information movement. Such context-
sensitive knowledge is usually opaque and hard to generalize given
the commonplace dependency on exogenous factors that elude fully-
automated threat discovery approaches. To aggravate the problem,
typical solutions introduce interpretation gaps that often lead to
erroneous conclusions and increased burden on cyber combatants.
Therefore, human involvement remains indispensable for effec-
tively uncovering cyber threats buried in the myriad of loosely-
related events captured by sensors deployed across systems and
networks. Analysts in security operation centers (SOCs) digest indi-
cators of compromise (IOCs) fired by various automated detection
modules, perform event triage, sift through false alarms, and search
for correlations to discover potential threats or attack campaigns.
The extracted threat intelligence (including context, actionable ad-
vice, etc.) can be shared and consumed by other analysts to support
Session 9D: VulnDet 1CCS’18, October 15-19, 2018, Toronto, ON, Canada1883agile detection strategies. Among SOC analysts, a special task force
composed of threat hunters actively creates and validates new attack
hypotheses to derive additional threat intelligence.
As a formal security practice, threat hunting can be strenuous
to conduct due to its dynamic nature and uncertainty, requiring a
fluid interplay between human deliberation and specialized tooling
for inspection and reasoning. Existing toolkits include i) security
information and event management (SIEM) systems such as HP
ArcSight [31], ii) threat intelligence sharing platforms such as IBM
X-Force [35], and iii) individual task scripting such as process-level
back-tracking in Cb Response [9]. Unfortunately, these tools do not
cope with dynamic reasoning [75] requirements, and are difficult
to customize and interoperate. For example, a threat hunter who
desires to quickly investigate the dynamic loading behavior used by
a 0-day attack, needs to first backtrack data- and control-flows with
unique constraints associated with the particular exploit, which is
difficult to express and program using existing tools.
To overcome these disadvantages and facilitate human-machine
agile detection strategy co-development, we introduce threat intel-
ligence computing as a new methodology for rapidly programming
threat hunting workflows, searching for threat evidence, and iter-
atively validating threat hypotheses to uncover attack campaigns
with loosely coupled attack steps. By recasting threat hunting as a
programming task, the new paradigm provides (1) a standard repre-
sentation for traces, logs, alerts, and threat intelligence holding het-
erogeneous formats and interfaces, (2) programmability for much
faster development iterations than traditional security software de-
velopment, and (3) an interoperable, metasploit-like programming
environment, in which threat hunters can easily and declaratively
create and execute threat hunting workflows.
To ensure uniform data representation, we express computations
on one or many computing devices as a temporal graph, defined
as a computation graph (CG). Similar to process calculi [1], basic
elements in a CG are entities (e.g., processes, files, sockets) and
events (e.g., file read, process fork). A CG references the entire
history of computation including any entities or events associated
with attacks or threats. Security-relevant data such as alerts, IOCs,
and intermediate threat analysis results are subgraphs, which can
be denoted by labels on elements of a CG. As a result, threat de-
tection becomes a graph computation problem whose solution is to
iteratively deduce threat-inducing subgraphs in a CG.
To manage CGs and program graph computations atop them,
we conceptualize, formalize, and evaluate τ -calculus, a graph com-
putation platform for threat intelligence computing. It comprises
i) a Turing-complete domain-specific language (DSL) with syntax
tailored for programming on CGs, ii) a graph database designed and
implemented to cope with efficient data storage and retrieval for
live and forensic threat investigations, and iii) peripheral compo-
nents for supporting interactive programming. In addition to basic
features, such as variable reference and declarative programming,
we conceptualize the language for superior code composability
and reusability than existing general-purpose graph languages,
e.g., Gremlin [73], Cypher [64]. We also back our graph database
with a distributed key-value store for low-level CG operation op-
timization targeting unique CG properties, such as data locality
and immutability. This architecture gives τ-calculus an edge over
conventional graph databases, e.g., Neo4J [65], which cannot meet
the performance requirements of typical threat hunting scenarios.
Our contributions can be summarized as follows:
• We formalize threat intelligence computing as a new security
paradigm, define a CG as an abstract data model compatible
with diverse monitoring granularities, and describe threat
hunting as an application of threat intelligence computing.
• We design τ-calculus as a graph computation platform for
threat intelligence computing. It consists of a domain-specific
language with syntax tailored for CG computations, and a
distributed graph database optimized for CG operations.
• We realize τ-calculus and its peripherals in Haskell and Type-
Script including the language interpreter, the graph database,
the interactive console, and the CG Browser (for interactive
CG visualization and inspection).
• We evaluate the practicality, effectiveness, and performance
of τ-calculus in a two-week DARPA threat detection compe-
tition on live-monitored systems (Windows, FreeBSD, Linux,
and Android) and demonstrate its strong capabilities for
threat hunting, automated detection, and policy reasoning.
2 THREAT INTELLIGENCE COMPUTING
Threat intelligence computing discovers threats, deduces threat in-
telligence, and supports efficient threat hunting through a standard
data representation (Section 2.1), programmability (Section 2.3),
and an interactive programming environment (Section 4).
2.1 Computation Graph
A computation graph (CG) is an abstract representation of compu-
tations inspired by process calculi [1]. At its core, a CG is a labeled
semi-directed temporal graph which objectively records both intru-
sive and non-intrusive computations on computing devices plus
security knowledge associated with the computations. Table 1 for-
mally defines a CG as a 4-tuple ⟨T, V, L, Λ⟩ where Ψ and Θ denote
time and the monitoring space, and T and V denote monitored enti-
ties and traced events within Ψ× Θ. Labels L in a CG contain critical
information for security reasoning. A label lb ∈ L associates a set
of elements through Λ, where lb denotes one of three categories:
• Element attribute (objective information derived from com-
putation recording): a label identifies a set of elements with
a particular attribute, e.g., an event type READ.
• Element relation (objective information derived from com-
putation recording): a label expresses some relation among
a set of elements, e.g., a provenance linkage between READ
and WRITE event of a process, which connects hundreds of
READ/WRITE events. This label embeds finer-grained prove-
nance information into an inter-process level CG.
• Security knowledge (subjective information regarding the
security and privacy goals and reasoning procedures): a label
marks a group of elements with some security knowledge.
This label can be generated as either i) intermediate/final
results of threat deduction, or ii) organization policies, IOCs,
or anomaly scores imported from external detection systems,
e.g., a set of confidential files, or IPs marked as C&C servers.
Session 9D: VulnDet 1CCS’18, October 15-19, 2018, Toronto, ON, Canada1884Table 1: Terms and Symbols in Computation Graph (Scope: Ψ, Θ; Composition: T, V, L, Λ; Helper: M)
Symbol
Name
time Ψ = {ψ , . . . }
space Θ = {θ, . . . }
entities T = {en, . . . }
events V = {ev, . . . }
labels L = {lb, . . . }
mappings Λ
elements M = {el, . . . }
Definition
Ψ = (Z, +)
Θ = (Z, +)
en = ⟨θ,ψ ,ψ ′⟩
ev = ⟨en, en′,ψ⟩
T × V ↔ L
el ∈ T ∪ V
Description
time counted in machine cycles or aggregated units
space of entities those can be monitored or traced
computation entities with their lifespans
information flows as pairs of entities at specific times
an enumeratable set of labels
bi-directional mapping between elements and labels
an element is an alias referencing an entity or an event
Visualization
x-axis
y-hyperplane
line segments along x-axis
line segments in y-hyperplane
labels on line segments
‡ Event directions are expressed in the order of entities. Bi-directed and non-directed events are also included in real-world uses regarding monitoring capabilities.
\
-\ proc
-\ proc \ p1
-\ proc \ p2
-\ proc \ p3
-\ tmp
-\ tmp \ f1
-\ tmp \ f2
(a) host filesystem
(b) a computation graph
Figure 1: CG example at host level (processes and files).
CG is an abstraction of computations. It is able to represent Turing-
complete computations at different monitoring granularities, which
supports threat reasoning and detection at different levels. Figure 1
describes one example of a CG at the host level and Appendix A
describes two other CG examples at the network and process levels.
In Figure 1, system activities are logged via syscall monitoring and
program instrumentation. Entities in this CG consist of subjects (e.g.,
processes and threads) and objects (e.g., files, pipes, and network
sockets). Security data is embedded in labels: lb1:sensitive indi-
cates that enf 2 contains sensitive information, and lb2:untrusted
indicates that enp3 is not certified by the company. Data leakage
occurs when enp3 can be traversed from enf 2, as shown in Figure 1.
2.2 Security Model For Threat Hunting
Given a CG that records objective computation histories regarding
both intrusive and non-intrusive data, threat discovery reduces to
the graph query problem of iteratively computing the closure over