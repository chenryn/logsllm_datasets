the templates extracted by the static analysis, we measure
how much context about the passed string the static
analysis extracts. First, we measure for each call site
how many known characters are present per template,
on average. The majority of call sites contain at least 10
known characters and for 10,967 call sites (21.24%), there
is no known character, i.e., our approach relies entirely
on dynamic information. Second, we measure how many
unknown parts the extracted templates contain. As shown
in Figure 13a, the templates for the vast majority of call
sites has at most one hole, and very few templates contain
more than ﬁve holes.
The main reason for templates with a relatively large
number of holes is that the string passed to injection API
is constructed in a loop that appends unknown values to
the ﬁnal string. The static analysis unrolls such loops a
ﬁnite number of times, creating a relatively large number
of unknown parts.
Third, we measure how many templates the analysis
extracts per call site. Because diﬀerent executed paths may
cause diﬀerent string values to be passed at a particular
call site of an injection API, the analysis may yield multiple
templates for a single call site. Figure 13b shows that for
most call sites, a single template is extracted.
Reasons for imprecision: To better understand the
reasons for imprecision of the static analysis, we measure
how frequent particular kinds of nodes in template trees
are. We ﬁnd that 17.48% of all call sites have a template
tree with at least one node that represent a function
parameter. This result suggests that an inter-procedural
static analysis might collect even more context than our
current analysis. To check whether the static analysis may
miss some sanitization-related operations, we measure how
many of the nodes correspond to string operations that are
not modelled by the analysis and to calls of functions whose
name contains “escape”, “quote”, or “sanitize”. We ﬁnd that
these nodes appear at only 3.03% of all call sites. The
low prevalence of such nodes, reiterates the observation
we made during our study: An npm module that uses
sanitization when calling an injection API is the exception,
rather than the rule.
the one-minute timeout after which we stop the analysis
of a module. The average analysis time for these modules
is 4.38 seconds, showing the ability of our approach to
analyze real-world code at a very low cost.
We conclude from these results that the static analysis
is eﬀective for the large majority of call sites of injection
APIs. Either the analysis successfully shows a call site to
receive only statically known values, or it ﬁnds enough
context to yield a meaningful security policy to be checked
at runtime. This ﬁnding conﬁrms our design decision to use
a scalable, intra-procedural analysis. The main reason why
this approach works well is because most strings passed
to injection APIs are constructed locally and without any
input-dependent path decisions.
B. Runtime Mechanism
For evaluating the runtime mechanism we consider a
set of 24 vulnerable modules listed in Figure 14. The
set includes modules reported as vulnerable on the Node
Security Platform, modules with vulnerabilities found dur-
ing our study, and clients of known vulnerable modules.
We exercise each module both with benign and with
malicious inputs that propagate to the call sites of injection
APIs.12 As benign inputs, we derive example usages from
the documentation of a module. As malicious inputs, we
manually craft payloads that accomplish a speciﬁc goal.
The goal for eval is to add a particular property to the
globally available console object. For exec, the goal is to
create a ﬁle in the ﬁle system. Figure 14 lists the modules
and the type of injection vector we use for the malicious
inputs. “(I)nterface” means that we call the module via
one of its exported APIs, “(N)etwork” means that we pass
data to the module via a network request, “(F)ile system”
means that the module reads input data from a ﬁle, and
“(C)ommand line” means that we pass data as a command
line argument to the module. In total, we use 56 benign
inputs and 65 malicious inputs.
False positives: Across the 56 benign inputs, we observe
ﬁve false positives, i.e., a false positive rate of only 8.92%.
Three false positives are caused by limitations of our
static analysis. For example, Figure 15 contains code that
constructs a command passed to exec by transforming an
array keys of strings using Array.map. Because our static
analysis does not model Array.map, it assumes that the
second part of cmd is unknown, leading to a PAST with a
single unknown subtree. Our runtime policy allows ﬁlling
this subtree with only a single argument, and therefore
rejects benign values of dmenuArgs that contain two argu-
ments. Further improvements of our static analysis, e.g.,
by modeling built-in functions, will reduce this kind of false
positive.
The remaining two false positives are caused by the set
of safe node types in our runtime mechanism. For example,
the mol-proto module uses eval to let a user deﬁne arbitrary
function bodies, which may include AST nodes beyond
our set of safe node types. Arguably, such code should be
Analysis running time: Our analysis successfully com-
pletes for 96.27% of the 15,604 modules without hitting
12The modules and inputs are available as benchmarks for future
research: URL removed for double-blind review.
11
(a) CDF for the average number of
holes per call site. Note the logarithmic
horizontal axis.
(b) CDF for the number of inferred
templates per call site. Note the loga-
rithmic horizontal axis.
(c) Overhead of runtime checks de-
pending on input size.
Fig. 13: Details on static analysis and overhead of runtime checks.
k
r
a
m
h
c
n
e
B
e
l
u
d
o
M
r
o
t
c
e
v
n
o
i
t
c
e
j
n
I
s
u
o
i
c
i
l
a
m
s
t
u
p
n
I
s
e
v
i
t
a
g
e
n
e
s
l
a
F
s
e
v
i
t
i
s
o
p
e
s
l
a
F
n
g
i
n
e
b
s
t
u
p
n
I
)
s
m
(
d
a
e
h
r
e
v
o
e
g
a
r
e
v
A
gm
libnotify
codem-transcode
printer
mixin-pro
modulify
mol-proto
mongoosify
mobile-icon-resizer
m-log
mongo-parse
mongoosemask
mongui
mongo-edit
mock2easy
I
I
N
I
I
I
I
I
FS
I
I
I
N
N
N
I
growl
FS
autolint
N
mqtt-growl
chook-growl-reporter I
bungle
1
4
1
1
2
1
1
1
1
11
1
1
1
1
1
1
4
1
1
FS 14
1
I
1
I
I
3
CL 1
2
2
4
4
4
2
2
2
5
1
2
1
2
1
2
2
4
2
1
4
4
4
4
4
56 65
ﬁsh
git2json
kerb request
keepass-dmenu
Total
Average
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0 0.41
1 0.19
0 0.80
0 0.28
0 0.16
1 0.04
1 0.07
0 0.04
0 0.39
0 0.05
0 0.11
0 0.04
0 0.05
0 0.04
0 0.03
0 2.72
0 1.59
0 3.19
0 1.60
0 1.99
0 0.21
1 0.37
0 0.25
1 0.52
5
0.74
e
p
y
T
Advisories
(Sect. II)
Reported by us
(Sect. III-D)
Case study
(Sect. III-E)
Other exec
(Sect. III-B)
Fig. 14: Results for runtime enforcement. Used injection
vectors: module’s interface (I), network (N), ﬁle system
(FS), command line (CL).
refactored for enhanced security. Alternatively, if a user
of a module trust that module, she can whitelist either
speciﬁc call site of the injection API or the entire module.
Overall, we conclude that the approach is eﬀective at
preventing injections while having a false positive rate
12
return ’- ’ + flag + ’ " ’ + dmenuOpts [ flag ] + ’" ’;
1 var keys = Object . keys ( dmenuOpts );
2 var dmenuArgs = keys . map ( function ( flag ) {
3
4 }). join ( ’ ’);
5 var cmd = ’echo | dmenu -p " Password :" ’ + dmenuArgs ;
6 exec ( cmd );
Fig. 15: Example of a false positive.
that is reasonably low, in particular for a fully-automated
technique.
False negatives: Synode prevents all attempted in-
jections during our evaluation,
i.e., there are not false
negatives. In general, however, there are multiple reasons
that might cause false negatives. First, our static analysis
fails to identify highly dynamic sink calls:
global["ev"+"al"](userInput);
Because the code to construct call targets can be arbitrar-