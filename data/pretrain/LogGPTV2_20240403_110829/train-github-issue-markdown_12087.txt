## üêõ Bug
There is a weird behaviour of a backward function when performing a reduction
operation (sum) on a dense tensor generated from the sparse one. For example,
just multiplying the dense tensor by one causes the generation of the
RuntimeError during the backward pass: `view size is not compatible with input
tensor's size and stride (at least one dimension spans across two contiguous
subspaces). Use .reshape(...) instead.`. Weirdly enough if there are several
sums for resulting dense tensor the problem disappears.
    import torch
    idxs = torch.tensor([[0, 2, 3], [1, 1, 2], [2, 1, 4], [3, 5, 1]], device=0)
    values = torch.randn((4, 6, 5), device=0, requires_grad=True)
    sparse_tensor = torch.sparse_coo_tensor(indices=idxs.t(),
                                            values=values[idxs.split(split_size=1, dim=1)].squeeze(),
                                            size=values.shape)
    dense_tensor = torch.sparse.sum(sparse_tensor, dim=2).to_dense()
    dense_tensor = dense_tensor.sum(dim=1) # + dense_tensor.sum(dim=1)
    (dense_tensor * 1).sum().backward()  #  `view size is not compatible with input tensor's size and stride`
    # dense_tensor.sum().backward()  #  no exceptions observed
## Environment
PyTorch Version is 1.2.0  
OS: Ubuntu  
Cuda: 10.1
cc @ezyang @ssnl @albanD @zou3519 @gqchen @vincentqb