(cid:17)
(cid:17)
(cid:17)
(cid:28)
plaintext
ciphertext plaintext
ciphertext plaintext
(cid:23)(cid:19)
(cid:24)(cid:19)
(cid:25)(cid:19)
(cid:23)
(cid:24)
(cid:25)
Search space
N=3
(cid:20)
(cid:20)(cid:17)(cid:20)
(cid:20)(cid:17)(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:20)(cid:17)(cid:28)
(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:22)
(cid:17)
(cid:17)
(cid:17)
(cid:23)
(cid:17)
(cid:17)
(cid:17)
(cid:24)
(cid:24)(cid:17)(cid:20)
(cid:24)(cid:17)(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:25)
(cid:17)
(cid:17)
(cid:17)
(cid:26)
(cid:17)
(cid:17)
(cid:17)
(cid:28)
(cid:50)(cid:51)(cid:40)
(cid:20)(cid:19)
(cid:20)(cid:20)
(cid:20)(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:20)(cid:28)
(cid:21)(cid:19)
(cid:17)
(cid:17)
(cid:17)
(cid:22)(cid:19)
(cid:17)
(cid:17)
(cid:17)
(cid:23)(cid:19)
(cid:17)
(cid:17)
(cid:17)
(cid:24)(cid:19)
(cid:24)(cid:20)
(cid:24)(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:25)(cid:19)
(cid:17)
(cid:17)
(cid:17)
(cid:26)(cid:19)
(cid:17)
(cid:17)
(cid:17)
(cid:28)(cid:19)
(cid:20)
(cid:20)(cid:17)(cid:20)
(cid:20)(cid:17)(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:20)(cid:17)(cid:28)
(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:22)
(cid:17)
(cid:17)
(cid:17)
(cid:23)
(cid:17)
(cid:17)
(cid:17)
(cid:24)
(cid:24)(cid:17)(cid:20)
(cid:24)(cid:17)(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:25)
(cid:17)
(cid:17)
(cid:17)
(cid:26)
(cid:17)
(cid:17)
(cid:17)
(cid:28)
(cid:3)(cid:11)(cid:22)(cid:19)(cid:15)(cid:3)(cid:22)(cid:12)
(cid:3)(cid:11)(cid:26)(cid:19)(cid:15)(cid:3)(cid:26)(cid:12)
Property
Analysis
(cid:20)(cid:19)
(cid:20)(cid:20)
(cid:20)(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:20)(cid:28)
(cid:21)(cid:19)
(cid:17)
(cid:17)
(cid:17)
(cid:22)(cid:19)
(cid:17)
(cid:17)
(cid:17)
(cid:23)(cid:19)
(cid:17)
(cid:17)
(cid:17)
(cid:24)(cid:19)
(cid:24)(cid:20)
(cid:24)(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:25)(cid:19)
(cid:17)
(cid:17)
(cid:17)
(cid:26)(cid:19)
(cid:17)
(cid:17)
(cid:17)
(cid:28)(cid:19)
(cid:20)(cid:20)
(cid:20)(cid:17)(cid:20)
(cid:20)(cid:17)(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:20)(cid:17)(cid:28)
(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:22)
(cid:22)(cid:22)(cid:22)(cid:22)(cid:22)(cid:22)(cid:22)(cid:22)(cid:22)(cid:22)(cid:22)(cid:22)
(cid:17)
(cid:17)
(cid:17)
(cid:23)
(cid:17)
(cid:17)
(cid:17)
(cid:24)
(cid:24)(cid:17)(cid:20)
(cid:24)(cid:17)(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:25)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:26)
(cid:26)(cid:26)(cid:26)(cid:26)
(cid:26)(cid:26)(cid:26)(cid:26)
(cid:17)
(cid:17)
(cid:17)
(cid:28)
(cid:22)(cid:20)
(cid:22)(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:23)(cid:19)
(cid:23)(cid:20)
(cid:23)(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:24)(cid:19)
(cid:24)(cid:20)
(cid:24)(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:25)(cid:19)
(cid:25)(cid:20)
(cid:17)
(cid:17)
(cid:17)
(cid:25)(cid:28)
(cid:22)(cid:17)(cid:20)
(cid:22)(cid:17)(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:23)
(cid:23)(cid:17)(cid:20)
(cid:23)(cid:17)(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:24)
(cid:24)(cid:17)(cid:20)
(cid:24)(cid:17)(cid:21)
(cid:17)
(cid:17)
(cid:17)
(cid:25)
(cid:25)(cid:17)(cid:20)
(cid:17)
(cid:17)
(cid:17)
(cid:25)(cid:17)(cid:28)
Search space
N=39
Fig. 1. A simple illustration of information leakage of OPE schemes, where
(30,3) and (70,7) are the known ciphertext-plaintext pairs. The untrusted server
tries to obtain the ciphertext of 5 (plaintext) analyzing the order property.
C. Low Entropy of Social Networks
In this sub-section, we show the low entropy associated with
social network datasets. For this, we analyze three real-world
datasets and present how the limited number of attribute values
and the existence of landmark attribute [1], [25] facilitate the
leakage of information.
The three real-world datasets that are analyzed are as
follows: (1) Infocom06 dataset [26] was from the attendees
of the IEEE Infocom 2006 Conference, who contributed their
mobility information ((x,y)-coordinate data) through their mo-
bile devices and social attributes from questionnaires. (2) Sig-
comm09 dataset [27] was collected by smartphones distributed
to a set of volunteers in the ACM Sigcomm 2009 Conference.
Each device was initialized with some basic (e.g., country,
afﬁliation) and extended social proﬁle (e.g., interests from
Facebook proﬁle). Also, the devices recorded the locations
of the volunteers during the conferences. (3) Weibo dataset
[28] was captured through the user proﬁle API and keyword
extra API in Sina Weibo (Chinese twitter), which include some
basic and extended social attributes (i.e., 10 interests). The user
interest attribute is deﬁned as the frequency of semantically
related keywords. Also, the ‘check-in’ information includes
location information based on Google map locations, which is
an interface provided by Weibo.
First, as discussed in Section IV-B, PPE will leak more
information due to the limited number of plaintexts. Now,
we utilize the entropy to evaluate the limited number of the
attribute values in social proﬁle data so that we are able to
determine whether PPE can be directly used to encrypt the
social proﬁle attributes. In order to show the entropy of a
given social attribute Al in a social network, we calculate
H(Al) = −(cid:2)
Ti
U
log
Ti
U
(1)
i
(cid:2)
Ti is the total number of users, and Ti
where Ti is the number of users with the attribute value i,
U indicates the
U =
probability of attribute Al having value i. H(Al), therefore,
represents the entropy of social attribute Al.
i
The properties of
Infocom06, Sigcomm09, and Weibo
datasets are summarized in Table II. We note that attributes
with signiﬁcantly small entropy exist in the real-world social
proﬁle datasets. This situation aggravates the information
leakage of a PPE scheme.
Second, we show how the landmark attributes [1], [25] will
lead to information leakage. A landmark attribute is based
on the fact that human activities (e.g., geographic and social
constrains [29]) exhibit structured patterns. For example, some
geographic locations may have much more ‘check-ins’ than
others. In other words, landmark attributes are prevalent in
social attribute data. Since PPE is a symmetric encryption
and some users should share a key to encrypt the proﬁle, the
ciphertexts of the landmark attributes are still noticeable. We
formally deﬁne the landmark attribute as follows:
Deﬁnition 2: Landmark attribute is an attribute with
value i whose probability Ti
U larger than threshold τ, where
Ti is the number of users with the attribute value i and U is
the total number of users, U =
(cid:2)
Ti.
i
As also discussed in [1] and [25], the existence of landmark
attributes in social proﬁle data can undermine the anonymiza-
tion, which increases the social proﬁle dataset’s propensity
for leakage. For example, when an untrusted server observes
a ciphertext appearing more often than others, the untrusted
server can regard this as ciphertext generated by the encryption
of a landmark attribute value. The existence of landmark
attributes associated with the three real-world datasets is
shown in Table II. As seen, for each dataset, at least one
or more landmark attribute exist, which can exacerbate the
usage of PPE schemes in social network settings. As Table II
TABLE II
THE PROPERTIES OF DATASETS
Dataset
Infocom06
Sigcomm09
Weibo
Node
78
76
1 million
the Number of Attributes
6
6
17
290290290
Entropy
AVG MAX MIN
0.82
3.10
3.40
0.86
0.54
5.14
5.34
5.62
9.21
Landmark Attribute
τ = 0.6
τ = 0.8
2
3
5
1
1
3
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:04:56 UTC from IEEE Xplore.  Restrictions apply. 
indicates, real-world social proﬁle datasets have low entropy
and landmark values, which leads to high information leakage
and the situation is aggravated when these datasets are used
with PPE.
In conclusion, as Table II indicates, real-world social proﬁle
datasets have low entropy and landmark values, which leads to
high information leakage with PPE. Therefore, the user proﬁle
attribute data used in a privacy-preserving proﬁle matching
scheme should have high entropy. Accordingly, in Section
VI, we propose a technique to increase the entropy to enable
private proﬁle matching based on PPE.
V. PROBLEM FORMULATION
In this section, the system model and assumptions are given.
Then, we outline the adversary model and design goals.
A. System Model and Assumptions
A privacy-preserving proﬁle matching scheme involves
users with mobile devices running the same mobile social
services and an untrusted server to process proﬁle matching
operations. Each user has a social proﬁle, including some
social proﬁle attributes such as gender, education, location, and
interests. Social attribute data can be generated through three
methods: user input in online social networks (e.g., birthday,
gender), device capture using sensors (e.g., location), and data
analysis based on the user behavior in online social networks
(e.g.,
interests). For instance, several methods have been
proposed to extract user interest information from Facebook’s
‘Like’ using semantic knowledge based techniques [1], [30],
[31].
We assume each user v updates her encrypted social proﬁle
i } on the untrusted server periodically. At another time
{c
(v)
t, user v submits a query request for proﬁle matching, Qq =
, to an untrusted server, where q is the query
ID, t is the time-stamp and IDv is the identity of user v in
a mobile social service. Then, the untrusted server correctly
matches proﬁles using the encrypted user proﬁles, and returns
k nearest proﬁles matching results to the user. Finally, the user
veriﬁes whether the proﬁle matching results are correct.
Without loss of generality, we assume that each user has a
unique ID and share the same social proﬁle format, where each
attribute value ai ∈ Zn . Also, each mobile device has similar
storage capacity and computing power (e.g., smartphones).
Each untrusted server is powerful and resourceful enough to
store social proﬁle attribute data and process proﬁle matching
operations (e.g., requests). As previous works [8], [9], [12],
[14], [15], we assume that social proﬁle attribute data in
the mobile device are captured from trusted social network
interfaces such that users would not change their social proﬁle
attribute data.
B. Adversary Model and Design Goals
In our threat model, we consider the following three types
of adversaries regarding the server and users:
• Honest-but-curious server where the server follows the
designated protocol speciﬁcation honestly while it
is
curious to analyze data in its storage so as to learn ad-
ditional information of the plaintext beyond the property
deﬁned in the PPE. For example, it can execute a chosen-
ciphertext attack where it chooses a ciphertext and obtain
its corresponding plaintext. Then, it can enumerate all the