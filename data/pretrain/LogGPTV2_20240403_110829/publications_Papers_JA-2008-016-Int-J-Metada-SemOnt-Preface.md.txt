Int. J. Metadata, Semantics and Ontologies, Vol. 3, No. 1, 2008 1
Preface
Jorge Cardoso
SAP Research CEC, SAP AG,
Chemnitzer Strasse 48, 01187 Dresden, Germany
E-mail: PI:EMAIL
Christoph Bussler
BEA Systems, Inc.,
475 Sansome Street, San Francisco, CA 94111, USA
E-mail: PI:EMAIL
Francesco Guerra
Dipartimento di Economia Aziendale,
Universita’ di Modena e Reggio Emilia,
via le Berengario 51, 41100 Modena, Italy
E-mail: PI:EMAIL
Biographical notes: Jorge Cardoso (http://www.dme.uma.pt/jcardoso) joined SAP Research
(Germany) in 2007. He previously gave lectures at the University of Madeira, the University of
Georgia and at the Instituto Politécnico de Leiria. He received his PhD in Computer Science from
the University of Georgia in 2002. He worked at the Boeing Company on enterprise application
integration and at CCG, Zentrum fur Graphische Datenverarbeitung on computer supported
cooperative work. He has organised several international conferences on semantic web and
information systems, and has published several refereed papers and edited several books in the
areas of workflow management systems, semantic web, and related fields.
Christoph Bussler (http://hometown.aol.com/chbussler) is Senior Staff Software Engineer at
Merced Systems, Inc. His interests include workflow and process management, B2B and
EAI integration, and semantic computing. He is author of several books and journal articles on
integration and semantics. He is active in the professional community as keynote speaker,
conference and workshop organiser as well as program committee member. He has a PhD in
Computer Science from the University of Erlangen, Germany, and worked in several
organisation, including BEA, Cisco Systems, Digital Enterprise Research Institute, Oracle,
The Boeing Company and Digital Equipment Corporation.
Francesco Guerra (http://www.dbgroup.unimo.it/~guerra/) is an Assistant Professor in Computer
Engineering at the Faculty of Economics of the University of Modena and Reggio Emilia, where
he teaches enterprise information systems. His main research interests include integration of
heterogeneous information sources, ontologies, and the semantic web. He has participated in
several Italian and European projects. At present, he is involved in the Italian FIRB project
NEP4B: Networked Peers for Business (years 2006–2008), and in the European FP6 STREP
project STASIS: Software for Ambient Semantic Interoperable Services (2006–2008). He has a
PhD in information engineering from the University of Modena and Reggio Emilia.
Traditional search techniques establish a direct connection and synonymy. In the first case, one word specified in a
between the information provided by users with the search query might have several meanings and, in the second
engine. Users are only allowed to specify a set of keywords case, distinct words may designate the same concept.
that will be syntactically matched against a database of If appropriate strategies are used and included in a new
keywords and references. This simple approach has several generation of search engines, the number of false results can
drawbacks since it gives rise to a low precision (the ratio of be drastically reduced. As a result, the impact of these two
positive results with respect to the total number of false and degrading factors can be reduced and even eliminated.
positive results retrieved) and low recall (the ratio of As the interconnection of research areas such as
positive results retrieved with respect to the total number of artificial intelligence, semantic web, and linguistics
positive results in the reference base). Many factors becomes stronger and more mature, it is reasonable to
influence this low precision and recall, namely polysemy explore how better search engines can be developed to more
Copyright © 2008 Inderscience Enterprises Ltd.
2 J. Cardoso et al.
adequately respond to users’ needs. A new kind of search In several approaches, thesaurus-based indexes improve
engine that has been explored for a few years now has been the result of document retrieval, in particular by solving the
termed “semantic-based search engines” by many problems of synonyms and allowing the disambiguation of
researchers. The underlying paradigm of these engines homonyms. Owing to the large amount of documents, these
is to find resources based on similar concepts and approaches often rely on automatic techniques for
logical relationships and not just similar words. These annotating documents with terms from thesauri. Eckert et al.
engines typically rely on the use of metadata, controlled claim that the quality of the thesaurus used as a basis for
vocabularies, thesauri, taxonomy, and ontologies to describe indexing ensure the quality of the whole indexing process.
the searchable resources to ensure that the most relevant In the forth paper, the authors present and evaluate a method
items of information are returned. combining the application of statistics and appropriate
The intend of this special issue is to bring together a visualisation techniques supporting the detection of
compilation of recent research and developments toward the potential problem in a thesaurus.
creation of a new paradigm for search engines that relies on The fifth paper addresses another interesting problem,
metadata, semantics and ontologies, by providing readers i.e., the expressive power of query languages used with
with a “broad spectrum vision” of the most important issues current search engine. Schellhase and Lukasiewicz face this
on semantic search engines. issue by proposing a search query paradigm developed for
One of the main problems concerns the recognition of literature searches. Their approach exploits the same
items of interest in web documents. The first three papers metadata about research publications, authors, organisations
face this issue following three different perspectives. and scientific events used by other scientific search engines,
In the first paper, Xu and Embey apply techniques from data but it provides a query language based on description
extraction, information retrieval and machine learning for logics and variable-strength conditional preferences.
achieving this goal. Their approach is based on an extraction The theoretical foundation of their language is
ontology describing the information of interest for users that domain-independent and thus it may be adapted to other
is exploited for extracting data from web documents. areas.
The application of several heuristics on the extracted data Finally, in the last paper, Battré introduces an
provides some statistical measures that are exploited by optimisation approach for RDF stores based on distributed
means of machine-learned rules for determining the hash tables that cache and reuse intermediate results created
documents containing relevant information. in previous queries in order to allow a quick processing of
The second paper presents the CORE module, which new queries. The paper includes an evaluation section
enables incremental searching based on co-occurrence of where different caching strategies are compared.
entities – as well as ranking – tracking trends and popularity
timelines. CORE extends the KIM platform for semantic
annotation, indexing and retrieval, which provides an Acknowledgement to reviewers
infrastructure for the automatic extraction of named entity
Dean Allemang; Francesco Bellomi; Abraham Bernstein;
reference and descriptions from text documents. CORE
Omar Boucelma; Paolo Bouquet; Patrick Brezillon;
introduces the concept of context (block of content) and
Andrea Calì; Steve Cayzer; Oscar Corcho; Matteo Cristani;
evaluates associative relations between entities on the basis
Emanuele Della Valle; Martin Dzbor; Alfio Ferrara;
of their frequency in a specific context. Moreover, CORE
Doug Foxvog; Rosa Galli; Stefan Grimm; Mohand-Said
can track trends in time for a set of entities based on their
Hacid; Hyoil Han; Andreas Harth; Jeff Heflin;
occurrence and co-occurrence frequency enabling the
Vipul Kashyap; Atanas Kiryakov; Claus-Peter Klas; Ruben
popularity rank of these in specific period of times. The user
Lara; Domenico Lembo; Frank Leymann; Pasquale Lops;
interface giving access to the CORE functionality is
Federica Mandreoli; Mihhail Matskin; Andrea Maurino;
described with details as well as some interesting types of
Brian McBride; Gregoris Mentzas; Gianluca Moro;
user search.
Lyndon Nixon; Matteo Palmonari; Massimo Paolucci;
In the third paper, Sindice is presented, a lookup index
Dimitris Plexousakis; Axel Polleres; Christoph Quix;
over resources crawled on the semantic web to locate
Evangelos D. Sakkopoulos; Giovanni Semeraro;
semantic web data sources. Sindice collects RDF documents
Amit Sheth; Pavel Shvaiko; Kiril Ivanov Simov;
and indexes these on resource URIs, inverse functional
Sergej Sizov; Peter Spyns; Giorgos Stamou;
properties and keywords. By means of a web front-end and
Armando Stellato; Heiner Stuckenschmidt; Gerd Stumme;
a public API, it is possible to look up resources and to
Ludger van Elst; Roland Wagner; Benjamin Yen;
search full-text descriptions obtaining as a result the URL of
Ilya Zaihrayeu.
sources where the resources occur.