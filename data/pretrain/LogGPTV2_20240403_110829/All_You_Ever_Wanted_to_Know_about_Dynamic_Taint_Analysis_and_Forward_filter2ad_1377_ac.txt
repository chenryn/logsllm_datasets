still allows an attacker to jump to untainted, yet attacker-
determined locations. This is an example of undertaint by
the policy. This means that the tainted jump policy may miss
an attack.
One possible ﬁx is to use the tainted addresses policy
shown in Table V. Using this policy, a memory cell is tainted
if either the memory cell value or the memory address is
tainted. TaintCheck [50], a dynamic taint analysis engine
for binary code, offers such an option.
The tainted address policy, however, also has issues. For
example, the tcpdump program has legitimate code similar
to the program above. In tcpdump, a network packet is ﬁrst
read in. The ﬁrst byte of the packet is used as an index into
a function pointer table to print the packet type, e.g., if byte
0 of the packet is 4, the IPv4 printer is selected and then
called. In the above code z represents the base address of
the function call table, and x is the ﬁrst byte of the packet.
Thus, the tainted address modiﬁcation would cause every
non-trivial run of tcpdump to raise a taint error. Other code
constructs, such as switch statements, can cause similar table
lookup problems.
The tainted address policy may ﬁnd additional taint ﬂows,
but may also overtaint. On the other hand, the tainted jump
policy can lead to undertaint. In security applications, such
as attack detection, this dichotomy means that the attack
detector either misses some exploits (i.e., false negatives) or
reports safe executions as bad (i.e., false positives).
Control-ﬂow taint. Dynamic taint analysis tracks data ﬂow
taint. However, information ﬂow can also occur through
control dependencies.
Informally, a statement s2 is control-dependent on state-
ment s1 if s1 controls whether or not s2 will execute. A
more precise deﬁnition of control-dependency that uses post-
dominators can be found in [30]. In SIMPIL, only indirect
and conditional jumps can cause control dependencies.
Example 5. Consider the following program:
1
2
3
4
x := g e t
i f x = 1 then goto 3 e l s e goto 4
y := 1
:= 42
i n p u t (· )
z
The assignment to y is control-dependent on line 2, since
the branching outcome determines whether or not line 3 is
executed. The assignment to z is not control-dependent on
line 2, since z will be assigned the value 42 regardless of
which branch is taken.
If you do not compute control dependencies, you cannot
determine control-ﬂow based taint, and the overall analysis
may undertaint. Unfortunately, pure dynamic taint analysis
cannot compute control dependencies, thus cannot accu-
rately determine control-ﬂow-based taint. The reason is sim-
ple: reasoning about control dependencies requires reasoning
about multiple paths, and dynamic analysis executes on a
single path at a time. In the above example, any single
execution will not be able to tell that the value of y is
control-dependent and z is not.
There are several possible approaches to detecting control-
dependent taint:
1) Supplement dynamic analysis with static analysis.
Static analysis can compute control dependencies,
and thus can be used to compute control-dependent
taint [3, 21, 53]. Static analysis can be applied over
the entire program, or over a collection of dynamic
analysis runs.
2) Use heuristics, making an application-speciﬁc choice
whether to overtaint or undertaint depending upon the
scenario [21, 50, 64].
Sanitization. Dynamic taint analysis as described only adds
taint; it never removes it. This leads to the problem of taint
spread: as the program executes, more and more values
become tainted, often with less and less taint precision.
A signiﬁcant challenge in taint analysis is to identify when
taint can be removed from a value. We call this the taint
sanitization problem. One common example where we wish
to sanitize is when the program computes constant functions.
A typical example in x86 code is b = a ⊕ a. Since b will
always equal zero, the value of b does not depend upon a.
x86 programs often use this construct to zero out registers.
A default taint analysis policy, however, will identify b as
tainted whenever a is tainted. Some taint analysis engines
check for well-known constant functions, e.g., TEMU [2]
and TaintCheck [50] can recognize the above xor case.
The output of a constant function is completely indepen-
dent of user input. However, some functions allow users
to affect their output without allowing them to choose an
arbitrary output value. For example, it is computationally
hard to ﬁnd inputs that will cause a cryptographically secure
hash function to output an arbitrary value. Thus, in some
application domains, we can treat the output of functions
like cryptographic hash functions as untainted. Newsome
et al. have explored how to automatically recognize such
cases by quantifying how much control users can exert on
a function’s output [49].
Finally, there may be application-dependent sanitization.
For example, an attack detector may want to untaint values if
the program logic performs sanitization itself. For example,
if the application logic checks that an index to an array is
within the array size, the result of the table lookup could be
considered untainted.
Time of Detection vs Time of Attack. Dynamic taint
analysis be used to ﬂag an alert when tainted values are
used in an unsafe way. However, there is no guarantee that
the program integrity has not been violated before this point.
One example of this problem is the time of detection/time
of attack gap that occurs when taint analysis is used for
attack detection. Consider a typical return address overwrite
exploit. In such attacks, the user can provide an exploit
that overwrites a function return address with the address
of attacker-supplied shellcode. The tainted jump policy
will catch such attacks because the return address will
become tainted during overwrite. The tainted jump policy
is frequently used to detect such attacks against potentially
unknown vulnerabilities. [21–23, 50, 64]
Note, however, that the tainted jump policy does not raise
an error when the return address is ﬁrst overwritten; only
when it is later used as a jump target. Thus, the exploit will
not be reported until the function returns. Arbitrary effects
could happen between the time when the return address is
ﬁrst overwritten and when the attack is detected, e.g., any
calls made by the vulnerable function will still be made
before an alarm is raised. If these calls have side effects,
e.g., include ﬁle manipulation or networking functions, the
effects can persist even after the program is aborted.
The problem is that dynamic taint analysis alone keeps
track of too little information. In a return overwrite attack,
the abstract machine would need to keep track of where
return addresses are and verify that they are not overwritten.
In binary code settings, this is difﬁcult.
value v
Π
32-bit unsigned integer | exp
::=
::= Contains the current constraints on
symbolic variables due to path choices
Table VI: Changes to SIMPIL to allow forward symbolic
execution.
Another example of the time of detection/time of attack
gap is detecting integer overﬂow attacks. Taint analysis alone
does not check for overﬂow: it just marks which values are
derived from taint sources. An attack detector would need
to add additional logic beyond taint analysis to ﬁnd such
problems. For example, the tainted integer overﬂow policy
shown in Table V is the composition of a taint analysis check
and an integer overﬂow policy.
Current taint-based attack detectors [2, 21, 50, 64] typ-
ically exhibit
time of detection to time of attack gaps.
BitBlaze [2] provides a set of tools for performing a post
hoc instruction trace analysis on execution traces produced
with their taint infrastructure for post hoc analysis. Post hoc
trace analysis, however, negates some advantages of having
a purely dynamic analysis environment.
IV. FORWARD SYMBOLIC EXECUTION
Forward symbolic execution allows us to reason about
the behavior of a program on many different
inputs at
one time by building a logical formula that represents a
program execution. Thus, reasoning about the behavior of
the program can be reduced to the domain of logic.
A. Applications and Advantages
Multiple inputs. One of the advantages of forward symbolic
execution is that it can be used to reason about more than one
input at once. For instance, consider the program in Example
6 — only one out of 232 possible inputs will cause the
program to take the true branch. Forward symbolic execution
can reason about the program by considering two different
input classes — inputs that take the true branch, and those
that take the false branch.
Example 6. Consider the following program:
1
2
3
4
x := 2∗ g e t
i f x−5 == 14 then goto 3 e l s e goto 4
/ /
/ / normal b e h a v i o r
c a t a s t r o p h i c
i n p u t (· )
f a i l u r e
Only one input will trigger the failure.
B. Semantics of Forward Symbolic Execution
The primary difference between forward symbolic execu-
tion and regular execution is that when get input(·) is eval-
uated symbolically, it returns a symbol instead of a concrete
value. When a new symbol is ﬁrst returned, there are no
constraints on its value; it represents any possible value.
As a result, expressions involving symbols cannot be fully
evaluated to a concrete value (e.g., s + 5 can not be reduced
further). Thus, our language must be modiﬁed, allowing a
value to be a partially evaluated symbolic expression. The
changes to SIMPIL to allow forward symbolic execution are
shown in Table VI.
Branches constrain the values of symbolic variables to
the set of values that would execute the path. The up-
dated rules for branch statements are given as S-TCOND
and S-FCOND in Figure 6. For example,
if the execu-
tion of the program follows the true branch of “if x >
2 then goto e1 else goto e2”, then x must contain a value
greater than 2. If execution instead takes the false branch,
then x must contain a value that is not greater than 2.
Similarly, after an assertion statement, the values of symbols
must be constrained such that
they satisfy the asserted
expression.
We represent these constraints on symbol assignments
in our operational semantics with the path predicate Π.
We show how Π is updated by the language constructs in
Figure 6. At every symbolic execution step, Π contains the
constraints on the symbolic variables.
C. Forward Symbolic Execution Example
The symbolic execution of Example 6 is shown in Ta-
ble VII. On Line 1, get input(·) evaluates to a fresh sym-
bol s, which initially represents any possible user input. s
is doubled and then assigned to x. This is reﬂected in the
updated ∆.
When forward symbolic execution reaches a branch, as
in Line 2, it must choose which path to take. The strategy
used for choosing paths can signiﬁcantly impact the quality
of the analysis; we discuss this later in this section. Table VII
shows the program contexts after symbolic execution takes
both paths (denoted by the use of the S-TCOND and
S-FCOND rules). Notice that the path predicate Π depends
on the path taken through the program.
D. Forward Symbolic Execution Challenges and Opportu-
nities
Creating a forward symbolic execution engine is concep-
tually a very simple process: take the operational semantics
of the language and change the deﬁnition of a value to
include symbolic expressions. However, by examining our
formal deﬁnition of this intuition, we can ﬁnd several
instances where our analysis breaks down. For instance:
• Symbolic Memory. What should we do when the
analysis uses the µ context — whose index must be
a non-negative integer — with a symbolic index?
• System Calls. How should our analysis deal with
external interfaces such as system calls?
• Path Selection. Each conditional represents a branch
in the program execution space. How should we decide
which branches to take?
We address these issues and more below.
Symbolic Memory Addresses. The LOAD and STORE rules
evaluate the expression representing the memory address
to a value, and then get or set the corresponding value
at that address in the memory context µ. When executing
concretely, that value will be an integer that references a
particular memory cell.
When executing symbolically, however, we must decide
what
to do when a memory reference is an expression
instead of a concrete number. The symbolic memory address
problem arises whenever an address referenced in a load
or store operation is an expression derived from user input
instead of a concrete value.
When we load from a symbolic expression, a sound
strategy is to consider it a load from any possible sat-
isfying assignment for the expression. Similarly, a store
to a symbolic address could overwrite any value for a
satisfying assignment to the expression. Symbolic addresses
are common in real programs, e.g., in the form of table
lookups dependent on user input.
Symbolic memory addresses can lead to aliasing issues
even along a single execution path. A potential address
alias occurs when two memory operations refer to the same
address.
Example 7. Consider the following program:
1
2
s t o r e ( addr1 , v )
z = load ( addr2 )
If addr1 = addr2, then addr1 and addr2 are aliased and
the value loaded will be the value v. If addr1 (cid:54)= addr2, then
v will not be loaded. In the worst case, addr1 and addr2
are expressions that are sometimes aliased and sometimes
not.
There are several approaches to dealing with symbolic
references:
• One approach is to make unsound assumptions for
removing symbolic addresses from programs. For ex-
ample, Vine [2] can optionally rewrite all memory
addresses as scalars based on name, e.g., Example 7
would be rewritten as:
1 mem addr1 = v
z = mem addr2
2
The appropriateness of such unsound assumptions
varies depending on the overall application domain.
• Let subsequent analysis steps deal with them. For
example, many application domains pass the generated
formulas to a SMT solver [6, 33]. In such domains
we can let the SMT solver reason about all possible
v is a fresh symbol
µ, ∆ (cid:96) get input(·) ⇓ v
S-INPUT
µ, ∆ (cid:96) e ⇓ e(cid:48) Π(cid:48) = Π ∧ e(cid:48)
ι = Σ[pc + 1]
Π, Σ, µ, ∆, pc, assert(e) (cid:32) Π(cid:48), Σ, µ, ∆, pc + 1, ι
S-ASSERT
µ, ∆ (cid:96) e ⇓ e(cid:48) ∆ (cid:96) e1 ⇓ v1 Π(cid:48) = Π ∧ (e(cid:48) = 1)
ι = Σ[v1]
Π, Σ, µ, ∆, pc, if e then goto e1 else goto e2 (cid:32) Π(cid:48), Σ, µ, ∆, v1, ι
µ, ∆,(cid:96) e ⇓ e(cid:48) ∆ (cid:96) e2 ⇓ v2 Π(cid:48) = Π ∧ (e(cid:48) = 0)
ι = Σ[v2]
Π, Σ, µ, ∆, pc, if e then goto e1 else goto e2 (cid:32) Π(cid:48), Σ, µ, ∆, v2, ι
S-TCOND
S-FCOND
Figure 6: Operational semantics of the language for forward symbolic execution.
Statement
start
x := 2*get input(·)
if x-5 == 14 goto 3 else goto 4
if x-5 == 14 goto 3 else goto 4
∆
{}
{x → 2 ∗ s}
{x → 2 ∗ s}
{x → 2 ∗ s}
Π
true
Rule
true
[(2 ∗ s) − 5 == 14]
¬[(2 ∗ s) − 5 == 14]
S-ASSIGN
S-TCOND
S-FCOND
pc
1
2