# Context-Aware Attacks on Advanced Driver Assistance Systems (ADAS)

## Abstract
This paper introduces a strategic, context-aware attack targeting control commands within an ADAS. The attack identifies critical moments during driving scenarios to initiate attacks and the durations that can cause hazards before human drivers or ADAS safety mechanisms can intervene. Our experiments show that steering is particularly vulnerable, and existing forward collision warning systems are insufficient. Human alertness is crucial for timely intervention, and automated safety mechanisms are essential for checking ADAS-issued control actions.

## 1. Introduction
Recent advancements in autonomous driving have led to increased deployment of Level 2 ADAS features. However, these systems are not immune to security threats. This study presents a strategic, context-aware attack that targets control commands within an ADAS. The attack aims to find the most critical times during a driving scenario to activate attacks, as well as the attack durations, which can cause hazards before a human driver or the ADAS safety mechanism can correct the behavior.

## 2. Experimental Setup
### 2.1 Simulation Environment
We use the CARLA urban driving simulator [50] to conduct our experiments. The simulation environment includes a variety of driving scenarios, such as highway driving, city driving, and parking maneuvers. We also incorporate OpenPilot [13], an open-source self-driving system, to simulate the ADAS.

### 2.2 Attack Strategy
The attack strategy involves identifying the most critical moments during a driving scenario to initiate attacks. The attack types include:
- **Acceleration**: Increasing the vehicle's speed.
- **Deceleration**: Reducing the vehicle's speed.
- **Steering**: Altering the steering angle.
- **Deceleration-Steering**: Combining deceleration and steering.

### 2.3 Data Collection
We collect data from the simulation, including the number of hazards and accidents, the time-to-hazard (TTH), and the driver's reaction times. The results are summarized in Table V.

## 3. Results and Observations

### 3.1 Effectiveness of Driver Intervention
Table V shows the results across different attack types, including the number of hazards prevented by the driver. For timely hazard mitigation, the driver's reaction/mitigation times should be shorter than the TTH. Our experiments indicate that without the driver's reaction, the attacks could achieve very high hazard and accident success rates (almost 100% for all attack types). However, when simulating the human driver's reaction, 83.3% of hazards are prevented for the Acceleration attack, reducing 50% of collision events. Similar hazard reductions are observed for the Deceleration (58.8%) and Deceleration-Steering (70.8%) attacks.

**Observation 4: Human alertness for timely intervention is important in preventing hazards and accidents.**

However, the driver's reaction does not prevent Steering attacks (zero hazards prevented for steering attacks in Table V), and these attacks still achieve very high hazard and accident success rates (e.g., 100% for Steering-Right and Acceleration-Steering). This is because hazards happen in less than 1.63 seconds, which is much less than the average human driver reaction time (2.5 seconds), indicating that attacks targeting the steering angle are the most difficult to mitigate by the driver.

**Observation 5: Steering is the most effective attack type that cannot be easily halted by the human driver.**

### 3.2 Impact of Strategic Value Corruption
Although driver intervention reduces hazard and accident rates, it may also introduce new hazards. For example, to avoid a collision with the lead vehicle, the Ego vehicle may stop in the middle of a lane, causing a rear collision, or collide with curb objects. Table V shows that up to 66.7% of new hazards occurred after preventing attacks on the gas output.

After adding the strategic value corruption, even though there is an overall 6.8% increase in hazard success rates (76.6% to 83.4%), the total number of alerts generated by the ADAS decreases to 4, and only less than 0.1% of the induced hazards are prevented by the driver, even for cases where the average TTH is longer than the average driver reaction time (2.5 seconds) (e.g., Acceleration, Deceleration, and Deceleration-Steering attacks). This further illustrates the effectiveness of the Context-Aware strategy for evading detection by the ADAS and/or the human driver.

**Observation 6: The strategic value corruption is effective in evading human driver detection and safety checks of ADAS.**

## 4. Threats to Validity
Although our attack strategy is efficient in finding potential weaknesses in the ADAS control software, its robustness and efficacy might be affected by the quality of sensor data used for context inference or by existing defense mechanisms (e.g., control invariant detection [53] or context-aware monitoring [31]). Our simulations consider OpenPilot safety checks and human driver interventions. However, other safety and security mechanisms that can be implemented in firmware or hardware interface of the car (e.g., Panda's safety checks, AEB, encryption, or intrusion detection) are not included in this study. Further evaluation of the robustness and detectability of the attacks are directions for future work.

## 5. Conclusion
This paper presents a strategic, context-aware attack that targets control commands within an ADAS. The attack finds the most critical times during a driving scenario to activate attacks, as well as the attack durations, which can cause hazards before a human driver or the ADAS safety mechanism can correct the behavior. Our experimental results and observations show that steering is particularly vulnerable and that the existing warning system for forward collisions is insufficient. Our results also highlight the importance of human alertness for timely intervention in preventing hazards and accidents and the importance of automated safety mechanisms that can check the control actions issued by ADAS.

## Acknowledgment
This work was partially supported by the Commonwealth of Virginia under Grant CoVA CCI: C-Q122-WM-02 and by the National Science Foundation (NSF) under Grant No. 1748737.

## References
[1] “Autonomous driving starts to hit mainstream as 3.5 million new cars had level 2 features in Q4 2020?” 2021. Available: https://canalys-prod-public.s3.eu-west-1.amazonaws.com/static/press_release/2021/CanalysAutomediaalertQ420L2WW.pdf
[2] “SAE Levels of Driving Automation™ Refined for Clarity and International Audience,” https://www.sae.org/blog/sae-j3016-update, 2021.
[3] A. H. M. Rubaiyat, Y. Qin, and H. Alemzadeh, “Experimental resilience assessment of an open-source driving agent,” in 2018 IEEE 23rd Pacific Rim International Symposium on Dependable Computing (PRDC). IEEE, 2018, pp. 54–63.
...
[53] H. Choi, W.-C. Lee, Y. Aafer, F. Fei, Z. Tu, X. Zhang, D. Xu, and X. Xinyan, “Detecting attacks against robotic vehicles: A control invariant approach,” in Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security. ACM, 2018, pp. 801–816.