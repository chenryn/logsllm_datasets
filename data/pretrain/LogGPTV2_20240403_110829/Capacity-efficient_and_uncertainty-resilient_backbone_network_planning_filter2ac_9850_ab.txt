 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
Pipe
Hose
 0
 0.2
 0.4
 0.6
 0.8
 1
Normalized total tra(cid:1)c volume
F
D
C
 1.1
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
Pipe
Hose
 0  0.5  1  1.5  2  2.5  3  3.5  4  4.5
Coe(cid:1)cient of Variation
Figure 2: Hose traffic reduction.
Figure 3: Total traffic distribution
of Hose vs. Pipe.
Figure 4: Coefficient of Variation with Pipe
vs. Hose traffic.
(cid:1)(cid:8)
(cid:1)(cid:7)(cid:3)(cid:4)
(cid:1)(cid:7)
(cid:1)(cid:6)(cid:3)(cid:4)
(cid:1)(cid:6)
(cid:1)(cid:5)(cid:3)(cid:4)
(cid:1)(cid:5)
(cid:1)(cid:2)(cid:3)(cid:4)
(cid:22)
(cid:21)
(cid:20)
(cid:19)
(cid:14)
(cid:18)
(cid:1)
(cid:17)
(cid:1)
(cid:16)
(cid:15)
(cid:14)
(cid:1)
(cid:1)
(cid:1)
(cid:7)(cid:10)(cid:13)(cid:8)(cid:1)(cid:3)(cid:1)(cid:16)(cid:12)(cid:1)(cid:2)
(cid:7)(cid:10)(cid:13)(cid:8) (cid:4) (cid:16)(cid:12) (cid:2)
(cid:5)(cid:12)(cid:15)(cid:8)(cid:1)(cid:2) (cid:6)(cid:11)(cid:9)(cid:14)(cid:8)(cid:15)(cid:15)
3 HOSE-BASED CAPACITY PLANNING
In this section, we give an overview of the capacity planning prob-
lem and our system design. Table 1 lists the notations throughout
the paper.
(cid:2)(cid:7)(cid:9)(cid:2)(cid:8) (cid:2)(cid:7)(cid:9)(cid:2)(cid:4) (cid:2)(cid:7)(cid:9)(cid:2)(cid:10) (cid:2)(cid:7)(cid:9)(cid:2)(cid:11) (cid:2)(cid:7)(cid:9)(cid:2)(cid:12) (cid:2)(cid:7)(cid:9)(cid:2)(cid:13) (cid:2)(cid:7)(cid:9)(cid:5)(cid:2)
(cid:23)(cid:16)(cid:24)
Figure 5: Service traffic from DC regions B and C to A.
the standard deviation of the traffic demand divided by the mean.
Figure 4 shows the coefficient of variation for the total daily peak
traffic in the backbone. The relative traffic dispersion in Hose is
much smaller than Pipe, with a shorter tail as well. As a result,
the Hose model provides a more stable signal for planning and
simplifies traffic forecast. With these, it is not hard to envision the
network scaling up as easily as storage and compute resources,
where a node can have an accurate approximation of its future
growth, without worrying about the interaction with other nodes
in the network.
Adaption to service evolvement Services evolve over time in
production. Possible causes include service behavior changes, re-
labeling of Quality of Service (QoS) classes, traffic shift for load
balancing, new service launches, and many others. Figure 5 shows
an example from the user database (UDB) service at Facebook. Due
to resource and operational constraints, the UDB servers storing
user data only sit in a few regions, and UDB-less regions rely on
a caching service called Tao [2] to fetch data from UDB regions
nearby. Figure 5 plots the amount of Tao traffic flowing from UDB
regions B and C to UDB-less region A. The significant traffic change
is a result of Tao service changing the primary UDB region from B
to C, with a canary on a few shards on 03/05 and a complete policy
change on 03/09. Both incidents created several Tbps of traffic shifts,
where a Pipe model would fail. In contrast, because the total traffic
amount stayed the same, the Hose ingress traffic at region A had
little disruption. The traffic aggregation nature of Hose is naturally
more resilient to service changes, making it a future-proof solution
to network planning.
Network model Our backbone network connects a number of
DCs and PoPs together. It consists of IP routers over a Dense Wave-
length Division Multiplexing (DWDM) optical network. The back-
bone routers are connected using IP links that route over multiple
fiber segments. We represent this network as a two-layer graph: the
IP network 𝐺 = (𝑉 , 𝐸), where the vertices 𝑉 are backbone routers
and the edges E are IP links, and the optical network 𝐺 (cid:2) = (𝑉 (cid:2), 𝐸 (cid:2)),
where the vertices 𝑉 (cid:2)
are Optical Add-Drop Multiplexers (OADMs)
and the edges 𝐸 (cid:2)
are fiber segments.
For each IP link 𝑒 ∈ 𝐸, 𝐹𝑆 (𝑒) is the set of fiber segments that 𝑒
rides over, which form a path on the optical topology. The IP link
𝑒 consumes a portion of spectrum on each fiber segment 𝑙 ∈ 𝐸 (cid:2)
over which 𝑒 is realized. For example, a 100Gbps IP link realized
using Quadrature Phase Shift Keying (QPSK) modulation can con-
sume 50GHz of spectrum over all fiber segments in its path. The
relationship between IP capacity and optical spectrum is shown in
Section 5.1.
Failure model We consider a set of fiber failures in the backbone.
Every IP link 𝑒 ∈ 𝐸 over the failed fibers would be down. In order to
provide desired reliability to the service traffic, we pre-define a set of
failures 𝑅 referred to as planned failures. The production network
should be planned with sufficient capacity such that all service
traffic can be routed for each failure 𝑟 ∈ 𝑅. Detailed resilience
policy in capacity planning will be presented in Section 5.2.
Traffic forecast Capacity planning depends on the projected traf-
fic demand in the future. Instead of modeling the organic growth
of link-wise traffic like done in ISP networks, for content providers,
it is common practice to forecast the future traffic demand per ser-
vice based on service profiling. This is because services, as content
generators, provide a more reliable source of truth for traffic de-
mand. For inter-DC traffic, service teams calibrate server utilization,
especially CPU utilization, to devise service growth plans under
the server budget allocated by the company. They provide service
scaling factors, which are applied to the current service traffic to
form the future demands. For PoP-DC traffic, we model user growth
and cache misses at PoPs to predict the amount of content retrieval
between PoPs and different DCs. The demands can be aggregated
in different ways, e.g., per-site-pair basis for traditional Pipe-based
planning and per-site basis for Hose-based planning.
549
Table 1: Notations
Definition
The IP topology with backbone routers and IP links
The optical topology with OADMs and fiber segments
The set of fiber segments which IP link 𝑒 goes through
The number of sites (DCs and PoPs combined) in the backbone
A 𝑁 × 𝑁 Traffic Matrix (TM)
The traffic volume from site 𝑖 to site 𝑗 in 𝑀
A 1 × 𝑁 all-ones vector to retrieve source nodes in 𝑀
A 𝑁 × 1 all-ones vector to retrieve destination nodes in 𝑀
A 1 × 𝑁 vector bounding egress traffic of source nodes in 𝑀
A 𝑁 × 1 vector bounding ingress traffic of destination nodes in 𝑀
} Hose constraints for the egress and ingress traffic demands
Symbol
𝐺 = (𝑉 , 𝐸)
𝐺 (cid:2) = (𝑉 (cid:2), 𝐸(cid:2))
𝐹𝑆 (𝑒)
𝑁
𝑀
𝑚𝑖,𝑗
(cid:4)𝑢𝑠
(cid:4)𝑢(cid:2)
𝑑
(cid:4)ℎ𝑠
(cid:4)ℎ(cid:2)
𝑑
𝐻 = { (cid:4)ℎ𝑠, (cid:4)ℎ(cid:2)
𝑑
𝛼
𝜖
𝑐 ∈ 𝐶
𝐷 (𝑐)
𝑇
𝐴𝑀
𝑃
𝑆
𝑏 ∈ 𝐵
𝑥 (𝑙)
𝑦 (𝑙)
𝑧 (𝑒)
𝜑 (𝑒)
𝜆𝑒
𝛾
𝑟𝑞 ∈ 𝑅𝑞
𝑓𝑖,𝑗 (𝑢, 𝑣)
𝜙𝑙
𝜓𝑙
Edge threshold in the sweeping algorithm (§ 4.2)
Flow slack in Dominating Traffic Matrix (DTM) selection (§ 4.3)
A network cut in the cut set
The set of DTMs for a network cut 𝑐 under flow slack 𝜖
A set of candidate DTMs
A binary 0-1 assignment variable indicating if DTM 𝑀 is selected
A convex polytope to represent the high-dimensional Hose space
A set of sample points in the Hose space 𝑃
A plane in a collection of planes in the Hose space 𝑃
The cost of procuring and deploying a fiber segment 𝑙 ∈ 𝐸(cid:2)
The cost of turning up a dark fiber 𝑙 ∈ 𝐸(cid:2)
The cost of provisioning a new wavelength to add an IP link 𝑒 ∈ 𝐸
The spectral efficiency of an IP link 𝑒 ∈ 𝐸
The IP capacity of IP link 𝑒 ∈ 𝐸
Routing overhead
A failure scenario in the planned failure set for QoS class 𝑞
A traffic flow from source 𝑖 to destination 𝑗 via IP link {𝑢, 𝑣 } ∈ 𝐸
The number of fibers to be lighted up on fiber segment 𝑙 ∈ 𝐸(cid:2)
The number of fibers to be deployed on fiber segment 𝑙 ∈ 𝐸(cid:2)
Problem statement Network capacity is the maximum through-
put (in Gbps, Tbps, or Pbps) the IP network, and individual IP links,
can carry. The problem of Capacity Planning is to compute the de-
sired network capacity to be built in the future. Building a network
involves complex steps:
(1) Procure fibers from third-party providers
(2) Build terrestrial and submarine fiber routes
(3) Pull fibers on existing ducts
(4) Install line system to light up the fibers
(5) Secure space and power at optical amplifiers and sites
(6) Procure, deliver, install hardware (optical and IP) at sites
All these activities have high lead time, taking months or even
years to deliver. Thus, capacity planning is critical to the future
evolution and profitability of the network.
In the network planning problem, the objective is to dimension
the network for the forecast traffic under the planned failure set 𝑅
by minimizing the total cost of solution. The cost of the network
is calculated based on a weighted function of equipment (fibers
and other optical and IP hardware) procurement, deployment, and
maintenance to realize the network plan. The specific cost model is
introduced in Section 5.1.
Planning schemes At Facebook, we categorize capacity planning
into two sub-problems: short-term planning and long-term plan-
ning. Short-term planning outputs the exact IP topology, i.e., the
IP links and the capacity on each link, while long-term planning
only determines the fibers and hardware to procure. This design
decision is based on the fact that network building is an iterative
process and long-term planning only serves as a reference most
550
(cid:7)(cid:17)(cid:8)(cid:11)(cid:11)(cid:12)(cid:9)
(cid:3)(cid:15)(cid:17)(cid:10)(cid:9)(cid:8)(cid:18)(cid:19)(cid:10)(cid:17)
(cid:8)(cid:13)(cid:23)(cid:27)(cid:17)(cid:11)(cid:13)
(cid:7)(cid:23)(cid:21)(cid:14)(cid:17)(cid:18)(cid:17)(cid:20)(cid:15)
(cid:4)(cid:21)(cid:24)(cid:13)(cid:1)(cid:2)(cid:13)(cid:19)(cid:10)(cid:20)(cid:12)
(cid:1)
(cid:1)(cid:14)
(cid:2)(cid:4)(cid:10)(cid:4)(cid:5)(cid:7)(cid:12)(cid:13)(cid:1)(cid:3)(cid:8)(cid:4)(cid:9)(cid:9)(cid:6)(cid:11)
(cid:7)(cid:17)(cid:8)(cid:11)(cid:11)(cid:12)(cid:9)(cid:1)(cid:5)(cid:8)(cid:19)(cid:17)(cid:12)(cid:20)(cid:1)
(cid:4)(cid:10)(cid:14)(cid:10)(cid:17)(cid:8)(cid:19)(cid:15)(cid:17)
(cid:7)(cid:17)(cid:22)(cid:13)
(cid:9)(cid:6)(cid:24)
(cid:2)(cid:8)(cid:16)(cid:8)(cid:9)(cid:12)(cid:19)(cid:21)
(cid:6)(cid:16)(cid:19)(cid:12)(cid:13)(cid:12)(cid:22)(cid:10)(cid:17)
(cid:5)(cid:21)(cid:20)(cid:15)(cid:28)(cid:25)(cid:13)(cid:23)(cid:19)(cid:1)(cid:7)(cid:18)(cid:10)(cid:20)
(cid:8)(cid:16)(cid:21)(cid:23)(cid:25)(cid:28)(cid:25)(cid:13)(cid:23)(cid:19)(cid:1)(cid:7)(cid:18)(cid:10)(cid:20)
(cid:3)(cid:10)(cid:17)(cid:18)(cid:26)(cid:23)(cid:13)
(cid:8)(cid:11)(cid:13)(cid:20)(cid:10)(cid:23)(cid:17)(cid:21)(cid:24)
Figure 6: System Architecture
times. For example, the fiber procurement plan may change at de-
ployment time according to availability of fiber resources on the
market. Short-term planning is conducted only after fiber and hard-
ware are secured and in place, because turning up capacity can
happen at a short notice.
Planning pipeline Figure 6 illustrates the planning process. Back-
bone network planning starts from traffic forecast. As aforemen-