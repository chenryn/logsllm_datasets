which is not surprising since these types of attackers had
partial information about the signatures.
In Figure 16 (a), we summarized the maximum achiev-
able recall for each victim under all attack models, when
the precision is required to be 100%. This ﬁgure provides
insight on the trade-off between security and usability. For
instance, operator #1 may aim to tune KinWrite so that it
can prevent random attackers from passing veriﬁcation with
a high conﬁdence, while operator #2 may tune KinWrite to
block insider attackers. As a result, on average fewer tri-
als are required for an honest user to pass veriﬁcation in the
ﬁrst system than in the second system. Figure 16 (b) shows
the precision when the recall was 75%. This ﬁgure illus-
trates how easily an attacker can pass veriﬁcation, when an
operator decides to tune KinWrite so that users can pass ver-
75% trials on average. In our experiments, we
iﬁcation by 1
observed that CA attackers, Ob attackers, and CA&Ob-4 at-
tackers had a slightly higher chance to pass veriﬁcation than
random attackers, but KinWrite would reject all of them (5
types) with a probability of 97% on average and reject in-
sider attackers with a 75% probability on average.
In addition, the results suggest that the choice of signa-
ture affects the performance of KinWrite, since some sig-
natures are more robust to shoulder surﬁng than others. For
instance, the signature ‘Tj’ is the hardest to imitate among
all four signatures, and watching the signing motion mul-
tiple times did not improve the imitation. In comparison,
the signature ‘Bry’ was the easiest to mimic, and observ-
ing multiple times helped. The feedback from ‘attackers’
reveals the reason: ‘Bry’ was signed much more slowly
than ‘Tj’. Hence, the slow motion of ‘Bry’ made imita-
tion easier while the fast motion and the ambiguous shape of
the signature ‘Tj’ made the task difﬁcult. Interestingly, af-
ter we gave the spelling of the signatures ‘Bry’ and ‘Tj’
to the Ob-4 attackers, they could no longer mimic as well as
they used to, because they started to write the text in their
own style instead of purely emulating the signature motion.
In summary, our experiments show that KinWrite can
reject most attackers with a high probability. Even with a
strong attacker (i.e., an insider attacker), KinWrite perform
gracefully. In real application scenarios, many of these at-
tacks, especially Insider attacks, can be prevented by phys-
ical protection or by a good system design. For instance,
knowing the exact shape of a 3D-signature will increase the
chances of a successful attack, and thus KinWrite does not
display the signed 3D-signature in real time and only stores
the normalized feature vectors of templates.
7 Conclusion
We have designed a behavior-based authentication system
called KinWrite that can be used for building access control.
By letting users sign their passwords in 3D space, we turned
short and easy-to-crack passwords into behavioral biomet-
rics, i.e, 3D-signatures. KinWrite utilizes Kinect, a low-cost
motion input sensor, to capture ﬁngertip movement when
a user signs her password in space, and constructs a 3D-
signature. To verify a user, based on her 3D-signatures
that may change over time, we extracted features that are
likely to contain personal gesture information, and we used
Dynamic Time Warping to calculate the similarity between
samples. One advantage of using DTW is that KinWrite
only needs to store one template for each user.
To evaluate the performance of KinWrite, we collected
1180 samples for 35 different signatures over ﬁve months.
In addition, we modelled 5 types of attackers who tried
to impersonate a legitimate user, and collected 1200 3D-
signature samples from 18 ‘attackers’. The evaluation re-
sults obtained using these samples show a 100% precision,
and a 99% recall on average in the presence of random at-
tackers, e.g., an attacker trying to impersonate a legitimate
user in a brute force manner; a 100% precision and a 77%
recall on average for all attackers. These results suggest
that KinWrite can deny the access requests from all unau-
thorized users with a high probability, and honest users can
acquire access with 1.3 trials on average.
Acknowledgement
The authors would like to thank all volunteers for their
help collecting data and Carter Bays for improving the pa-
per. This work has been funded in part by NSF CNS-
0845671, NSF GEO-1124657, AFOSR FA9550-11-1-0327,
NSF-1017199, and ARL W911NF-10-2-0060.
References
[1] Y. Zhang, F. Monrose, and M. K. Reiter, “The se-
curity of modern password expiration: an algorithmic
framework and empirical analysis,” in Proceedings of
the 17th ACM conference on Computer and communi-
cations security, 2010, CCS ’10, pp. 176–186.
[2] X. Suo, Y. Zhu, and G. S. Owen, “Graphical pass-
words: A survey,” in Proceedings of the 21st Annual
Computer Security Applications Conference, 2005,
ACSAC ’05, pp. 463–472.
[3] J. Cornwell, I. Fette, G. Hsieh, M. Prabaker, J. Rao,
K. Tang, K. Vaniea, L. Bauer, L. Cranor, J. Hong,
B. McLaren, M. Reiter, and N. Sadeh,
“User-
controllable security and privacy for pervasive com-
puting,” in IEEE Workshop on Mobile Computing Sys-
tems and Applications (HotMobile), Feb 2007, pp. 14–
19.
[4] NSTC Subcommittee on Biometrics and Identity
Management, “Privacy & biometrics: Building a con-
ceptual foundation,” pp. 1–57, 2006.
[5] F. Tari, A. A. Ozok, and S. H. Holden, “A comparison
of perceived and real shoulder-surﬁng risks between
alphanumeric and graphical passwords,” in Proceed-
ings of the second symposium on Usable privacy and
security, 2006, SOUPS ’06, pp. 56–66.
[6] “Kinect,” http://www.xbox.com/en-US/KINECT.
[7] Z. Zhang, Chen Z, J. Shi, F. Jia, and M. Dai, “Sur-
face roughness vision measurement in different ambi-
ent light conditions,” Int. J. Comput. Appl. Technol.,
vol. 39, no. 1/2/3, pp. 53–57, Aug. 2010.
[8] K. Khoshelham, “Accuracy analysis of kinect depth
data,” GeoInformation Science, vol. 38, no. 5/W12,
pp. 1, 2010.
[9] R. Dhamija and A. Perrig, “Deja vu: a user study
using images for authentication,” in Proceedings of
the 9th conference on USENIX Security Symposium,
Aug. 2000, SSYM’00.
[10] S. Wiedenbeck, J. Waters, L. Sobrado, and J-C. Bir-
get, “Design and evaluation of a shoulder-surﬁng re-
sistant graphical password scheme,” in Proceedings of
the working conference on Advanced visual interfaces,
2006, AVI ’06, pp. 177–184.
[11] A. Forget, S. Chiasson, and R. Biddle, “Shoulder-
surﬁng resistance with eye-gaze entry in cued-recall
graphical passwords,” in Proceedings of the 28th in-
ternational conference on Human factors in comput-
ing systems, 2010, CHI ’10, pp. 1107–1110.
[12] L. D. Paulson, “Taking a graphical approach to the
password,” Computer, vol. 35, 2002.
[13] N. K. Ratha, J. H. Connell, and R. M. Bolle, “En-
hancing security and privacy in biometrics-based au-
thentication systems,” IBM Syst. J., vol. 40, no. 3, pp.
614–634, 2001.
[14] K. Revett, “A bioinformatics based approach to user
authentication via keystroke dynamics,” International
Journal of Control, Automation and Systems, vol. 7,
no. 1, pp. 7–15, 2009.
[15] F. Monrose, M. K. Reiter, and S. Wetzel, “Password
hardening based on keystroke dynamics,” in Proceed-
ings of the 6th ACM conference on Computer and
communications security, 1999, CCS ’99, pp. 73–82.
[16] N. Zheng, A. Paloski, and H. Wang,
“An efﬁcient
user veriﬁcation system via mouse movements,” in
Proceedings of the 18th ACM conference on Com-
puter and communications security, 2011, CCS ’11,
pp. 139–150.
[17] A. A. E. Ahmed and I. Traore, “A new biometric tech-
nology based on mouse dynamics,” IEEE Transaction
on Dependable and Security Computing, vol. 4, no. 3,
pp. 165–179, 2007.
[18] I. Jermyn, A. Mayer, F. Monrose, M. K. Reiter, and
“The design and analysis of graphi-
A. D. Rubin,
cal passwords,” in Proceedings of the 8th conference
on USENIX Security Symposium, Aug. 1999, vol. 8 of
SSYM’99, pp. 1–14.
[19] J. Richiardi, H. Ketabdar, and A. Drygajlo, “Local
and global feature selection for on-line signature veri-
ﬁcation,” in Proceedings of the 8th International Con-
ference on Document Analysis and Recognition, 2005,
ICDAR ’05, pp. 625–629.
[20] J. Fierrez-Aguilar, L. Nanni, J. Lopez-Pe nalba,
J. Ortega-Garcia, and D. Maltoni, “An on-line signa-
ture veriﬁcation system based on fusion of local and
global information,” in Proceedings of the 5th inter-
national conference on Audio- and Video-Based Bio-
metric Person Authentication, 2005, AVBPA’05, pp.
523–532.
[21] H. Byun and S-W. Lee, “Applications of support vec-
tor machines for pattern recognition: A survey,” in
Proceedings of the First International Workshop on
Pattern Recognition with Support Vector Machines,
London, UK, 2002, SVM ’02, pp. 213–236, Springer-
Verlag.
[22] N. Cristianini and J. Shawe-Taylor, An introduction
to support Vector Machines: and other kernel-based
learning methods, Cambridge University Press, New
York, NY, USA, 2000.
[23] S. Haykin, Neural Networks: A Comprehensive Foun-
dation, Prentice Hall PTR, Upper Saddle River, NJ,
USA, 2nd edition, 1998.
[24] J. Fierrez,
J. Ortega-Garcia, D. Ramos,
and
J. Gonzalez-Rodriguez,
“Hmm-based on-line sig-
nature veriﬁcation: Feature extraction and signature
modeling,” Pattern Recognition Letters, vol. 28, pp.
2325–2334, 2007.
[25] D. Muramatsu and T. Matsumoto, “An hmm on-line
signature veriﬁer incorporating signature trajectories,”
in Proceedings of the 7th International Conference on
Document Analysis and Recognition, 2003, vol. 1 of
ICDAR ’03, pp. 438–442.
[26] A. Jain,
“On-line signature veriﬁcation,” Pattern
Recognition, vol. 35, no. 12, pp. 2963–2972, Dec.
2002.
[27] A. Kholmatov and B. Yanikoglu, “Identity authen-
tication using improved online signature veriﬁcation
method,” Pattern Recognition Letters, vol. 26, no. 15,
pp. 2400–2408, Nov. 2005.
[28] T. Ohishi, Y. Komiya, and T. Matsumoto, “On-line
signature veriﬁcation using pen-position, pen-pressure
and pen-inclination trajectories,” in Proceedings of
the International Conference on Pattern Recognition,
2000, vol. 4, pp. 547–550.
[29] D. S. Guru and H. N. Prakash, “Online signature ver-
iﬁcation and recognition: An approach based on sym-
bolic representation,” IEEE Transactions on Pattern
Analysis and Machine Intelligence, vol. 31, pp. 1059–
1073, 2009.
[30] D. Muramatsu, K.K. Yasuda, and T. Matsumoto, “Bio-
metric person authentication method using camera-
based online signature acquisition,” in Proceedings of
the 2009 10th International Conference on Document
Analysis and Recognition, 2009, ICDAR ’09, pp. 46–
50.
[31] V. S. Nalwa, “Automatic on-line signature veriﬁca-
tion,” in Proceedings of the IEEE third Asian Confer-
ence Computer Vision, 1997, pp. 215–239.
[32] A. Kubota., Y. Hatori., K. Matsuo, M. Hashimoto,
and A. Koike, “A study on biometric authentication
based on arm sweep action with acceleration sensor,”
in Proceedings of International Symposium on Intelli-
gent Signal Processing and Communication, 2006, pp.
219–222.
[33] J. Liuand L. Zhong, J. Wickramasuriya, and V. Va-
sudevan,
“User evaluation of lightweight user au-
thentication with a single tri-axis accelerometer,” in
Proceedings of the 11th International Conference on
Human-Computer Interaction with Mobile Devices
and Services, 2009, MobileHCI ’09, pp. 15:1–15:10.
[34] M. Bashir, G. Scharfenberg, and J. Kempf, “Person
authentication by handwriting in air using a biometric
smart pen device.,” BIOSIG, pp. 219–226, 2011.
[35] L. Xia, C-C. Chen, and J. K. Aggarwal,
“Human
detection using depth information by kinect,”
in
Workshop on Human Activity Understanding from 3D
Data in conjunction with CVPR (HAU3D), Colorado
Springs, USA, 2011.
[36] C-C. Cko, M-C. Chen, T-F. Wu, S-Y. Chen, and C-
C. Yeh, “Cat motor: an innovative system to detect
the behavior of human computer interaction for peo-
ple with upper limb impairment,” in Proceedings of
the 4th international conference on Universal access
in human-computer interaction: applications and ser-
vices, Berlin, Heidelberg, 2007, UAHCI’07, pp. 242–
250, Springer-Verlag.
[37] D. Uebersax, J. Gall, M. V. den Bergh, and L. V. Gool,
“Real-time sign language letter and word recognition
from depth data,” in ICCV Workshops, 2011, pp. 383–
390.
[38] J. Garstka and G. Peters, “View-dependent 3d pro-
jection using depth-image-based head tracking,” in
Proceedings of the 8th IEEE International Workshop
on ProjectorCamera Systems (PROCAMS), 2004, pp.
52–57.
[39] J. L. Raheja, A. Chaudhary, and K. Singal, “Tracking
of ﬁngertips and centers of palm using kinect,” Com-
putational Intelligence, Modelling and Simulation, In-
ternational Conference on, vol. 0, pp. 248–252, 2011.
[40] K. Khoshelham and S. O. Elberink, “Accuracy and
resolution of kinect depth data for indoor mapping ap-
plications,” Sensors, vol. 12, no. 2, pp. 1437–1454,
2012.
[41] P. O. Kristensson, T. Nicholson, and A. Quigley,
“Continuous recognition of one-handed and two-
handed gestures using 3d full-body motion tracking
sensors,” in Proceedings of the 2012 ACM interna-
tional conference on Intelligent User Interfaces, New
York, NY, USA, 2012, IUI ’12, pp. 89–92, ACM.
[42] E. Stone and M. Skubic, “Evaluation of an inexpen-
sive depth camera for in-home gait assessment,” Jour-
nal of Ambient Intelligence and Smart Environments.
[43] R. Plamondon and G. Lorette, “Automatic signature
veriﬁcation and writer identiﬁcation - the state of the
art,” Pattern Recognition, vol. 22, no. 2, pp. 107–131,
1989.