of the conditions and make the additional boomerangs
compatible with the diﬀerential path.
3.3 Precise Conditions of Neutral Bits
We also improved the rate of partial solutions generated
by looking more precisely at the eﬀect of each neutral
bit. In particular, we found that some neutral bits ﬂip
with very high probability a certain condition after the
step for which they are considered neutral. Therefore,
these bits can be used as message modiﬁcations rather
than neutral bits: instead of considering both the initial
message and the message with the neutral bit applied
and to test both of them at the later step, we can directly
test the condition and decide which message to consider.
Using this bit as message modiﬁcation instead of neutral
bit is more eﬃcient, as one invalid branch in the search
tree will be rightfully not explored.
In some cases, we also found that a bit that is neutral
up to step i can only break some of the conditions of step
i, while the rest will never be impacted. Therefore, we
can test the conditions that are not aﬀected before using
that neutral bit, so as to avoid unnecessary computations.
This strategy can be seen as a more precise neutral bit
approach, where the attacker doesn’t work step-wise, but
instead condition-wise: more ﬁne-grained ﬁltering will
lead to computation savings.
All in all, these tricks result in a better exploration
of the collision search tree by cutting branches earlier.
We give detailed benchmarks results and complexity esti-
mates in Table 4, after implementing our improvements
in the code of [23] (where an Ai-solution refers to an
input pair that is following the diﬀerential path until
word Ai inclusive).
3.4 Building Diﬀerential Trails
Following [12], we try to reuse as much as possible the
previous works on SHA-1, and to keep our diﬀerential
trail as close as possible to the attack of Stevens et
1844    29th USENIX Security Symposium
USENIX Association
al. [23], out of simplicity. More precisely, for each block
of the collision phase, as starting point we reused exactly
the same core diﬀerential path as in [23]: the diﬀerence
positions in the message are the same, and the diﬀerence
positions in the internal state are the same after the ﬁrst
13 steps (roughly). We also tried to keep diﬀerence signs
to be the same as much as possible. However, we made
some modiﬁcations to the boomerangs and neutral bits
as explained in the previous subsection.
The starting path skeleton is depicted in Figure 3. For
each new block of the near-collision phase, we:
1. collect the incoming chaining variable and its diﬀer-
ences and insert them inside the skeleton;
2. set the signs of the diﬀerences in the very last steps
(chosen so as to minimize the ﬁnal collision com-
plexity according to the graph, see Section 4) and
generate the linear system of all equations regarding
the message words;
3. compute a valid non-linear diﬀerential path for the
ﬁrst steps;
4. generate base solutions, i.e. partial solutions up to
A14, possibly using help of neutral bits;
5. from the base solutions, search for a pair of messages
that fulﬁls the entire diﬀerential path, using neutral
bits, message modiﬁcations and boomerangs.
Steps 1 to 4 are done on CPU because they are not too
computationally intensive, but step 5 runs on GPU.
In comparison with a classical collision attack [23], our
paths have fewer degrees of freedom because of additional
constraints on the late-step message bits, and denser
input diﬀerence on the chaining variable. However, we
had enough degrees of freedom to ﬁnd a conforming
messages pair for all blocks during the attack. The use of
the additional short boomerangs reduces also the number
of neutral bits that can be used, but we still had enough
to keep the GPU busy (in stage 5) while the CPU was
producing the base solutions (in stage 4), even though
our computation cluster is composed of low range CPUs.
4.1 Graph Construction
In order to eﬃciently erase the diﬀerences from the set
S, [12] uses a graph where vertices are the state diﬀerence
in S, and there is an edge between δ and δ0 if δ0 − δ can
be obtained as the output diﬀerence of the compression
function (using a near-collision block). The birthday
phase designates a starting node in the graph and we
just have to follow a path leading to the zero diﬀerence,
as illustrated in Figure 4. For each edge, we search for
a block with the correct output diﬀerence, using near-
collision search, with a cost that depends on the target
diﬀerence. In the following, we denote the cost for the
optimal output diﬀerences as Cblock; it is equivalent to
the cost of an identical-preﬁx collision.
Large graph. We started with the same approach as
in [12], building a series of graphs with increasing limits
on the number of blocks allowed. More precisely, we
consider the set of all nodes that are reachable with a
path of cost at most 24 Cblock and up to 10 blocks. This
results in a graph with 236.2 nodes1, which requires 2TB
of storage (storing only the nodes and their cost).
In order to minimize the complexity of the
Clustering.
near-collision phase of the attack, [12] uses a clustering
technique to exploit multiple paths in the graph (see
Figure 5). Indeed, the near-collision search does not
have to commit to a ﬁxed output diﬀerence. When two
output diﬀerences correspond to useful paths in the graph
and are compatible with the same diﬀerential path, the
attacker can run the near-collision search and stop as
soon as one of them is obtained.
Concretely, let us assume we have two output diﬀer-
ences δ1 and δ2 compatible with the same diﬀerential
trail, that can each be reached with a cost of Cblock.
There are two diﬀerent ways to erase a diﬀerence −δ1−δ2
in the state:
• a block with diﬀerence δ1, followed by a block with
diﬀerence δ2;
4 Improving SHA-1 CP Collision Attack
In order to take advantage of the low-level improvements
to collision attack techniques, we must also improve the
high-level chosen-preﬁx collision attack.
The complexity of the birthday phase depends on the
size of the set S of diﬀerences that can be erased from the
state, therefore we need a larger set. For the near-collision
phase, the complexity depends on how we combine the
near-collision blocks to erase the diﬀerence in the state.
We improve the graph techniques of [12] and suggest
a more heuristic approach, resulting in a lower average
complexity, but without a guaranteed upper bound.
• a block with diﬀerence δ2, followed by a block with
diﬀerence δ1.
If we don’t decide in advance the target diﬀerence for
the ﬁrst block, the search is expected to reach either δ1
or δ2 with a cost of only 0.5 Cblock, leading to an attack
complexity of 1.5 Cblock rather than 2 Cblock.
In our case, we initially consider nodes at distance up
to 24 Cblock and we run the clustering technique to get a
better estimate of the complexity when we don’t specify
in advance the sequence of diﬀerences. After several
weeks of computation on a machine with 48 cores and
1The largest graph suggested in [12] has size 233.7.
USENIX Association
29th USENIX Security Symposium    1845
Collision (old)
Collision (new)
arch
GPU
K20x (1 GPU) Kepler
Maxwell
GTX 970
GTX 1060
Pascal
GTX 1080 Ti Pascal
Hashrate A33 rate SHA-1 A33 rate (r) SHA-1 Gain
9.1
1.7GH/s
3.9GH/s
9.6
8.8
4.0GH/s
12.8GH/s
8.8
255k/s
570k/s
470k/s
1500k/s
261.2
261.2
261.6
261.6
28k/s
59k/s
53k/s
170k/s
264.4
264.5
264.7
264.7
Table 4: Cost of collision attacks. One collision requires on average 248.5 A33-solutions (those results include the
boomerang on M6[8]).
Note: we use the hashrate from hashcat, which is slightly over-optimistic (i.e. attack cost in SHA-1 computations is
overestimated).
i
-4:
-3:
-2:
-1:
00:
01:
02:
03:
04:
05:
06:
07:
08:
09:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
Ai
______________________________
|
|
|
|
| Incoming Chaining Variable |
|
|
|______________________________|
??????????????????????????????--
????????????????????????????????
????????????????????????????????
????????????????????????????????
?????????????????????|?|????????
?????????????????????|?|????????
????-------------------0-0??????
???x------------------|--0?0--??
???-------------------|--1?1--??
???--------------------|0|?---??
??x--------------------|0|0-----
-------------------------111----
n--------------------------000--
--n------------------------111--
u-1-1---------------------------
un0-0---------------------------
u--1----------------------------
u-u0----------------------------
u-------------------------------
u-u-----------------------------
Wi
----xx------------------------x-
xx-------------------------x----
x-xx-x---------------------xxx--
--xxxx-----------------------x--
x-xxxx---------------------xx-x-
-x------------------------x----
--x--x-----------------0-0-xxx--
xxx-xx------------1-1------x-x--
----xx------------------------x-
xx----------------------0--x----
x-xx-x-------------1-------xxx--
--x-xx-------------------111-x--
x-xxux---------------------xx---
x-xx----------------------1u----
--------------------------1-xx--
x-xxx----------------------n----
----u----------------------nu---
-xxnn----------------------n----
--0-n----------------------n-n--
-xuu-----------------------n----
x-nux----------------------nnu--
Figure 3: Skeleton of starting diﬀerential path for all blocks during the near-collision phase of our CP collision attack
on SHA-1 (only the ﬁrst 20 steps are depicted). The MSB’s are on the right and “-” stands for no constraint, while
the notation “|” on two bits vertically adjacent mean that these two bits must be equal. The other notations are
similar to the ones used in [7]. This is only to give a general idea of the diﬀerential path used, as several conditions on
the message and/or on the internal state are not represented here.
δ
δ
δ
δ
0
0
0
0
Figure 4: Graph search.
Figure 5: With clustering.
Figure 6: Bi-directional.
Figure 7: Implicit.
1846    29th USENIX Security Symposium
USENIX Association
3TB of RAM, we ﬁnd that almost 90% of the nodes are
actually at distance 6 Cblock or less, as seen in Table 5.
All the diﬀerences in this set are active only on a 64-
bit mask. Therefore, we use those bit positions for the
birthday phase: we truncate SHA-1 to the remaining 96
bits2 and we generate a large number of partial collisions
until one of them corresponds to a diﬀerence in the
graph.
4.2 Bi-directional Graph
Since the CP collision attack is essentially a path search
in a graph, we can use a bi-directional search to make
the search more eﬃcient. More precisely, when we eval-
uate the cost of a node, instead of just looking it up
in the graph, we recompute all edges starting from the
node to see if they reach the graph and compute the
cost using the clustering formula. This corresponds to a
bi-directional search where we pre-compute in the back-
wards direction the set of values that go to zero after at
most 10 blocks, and during the online phase, we compute
one block forward. This is illustrated by Figure 6, where
black dots correspond to precomputed nodes stored in
the graph, and white dots are only computed during the
online phase.
This can be seen as a time-memory trade-oﬀ: we use
nodes at a distance up to 11 blocks, but we only build
explicitly the graph with 10 blocks. Moreover, we can
use nodes that are not reachable with a single trail of
cost below 24 Cblock, and that are therefore excluded
from our initial graph. Indeed, if there exists a trail such
that the cost is below 24 Cblock when removing an edge,
the forward search using that edge will hit the explicit
graph, and we can evaluate the distance of the node.
We can’t compute exactly the size of this implicit
graph, but we can evaluate it experimentally by simulat-
ing the birthday phase of the attack. We found that we
need on average 226.4 attempts before hitting the graph,
which corresponds to a graph size of roughly 238 (assum-
ing that we detect being in the graph with a probability
of 0.75, as was the case with the parameters of [12]).
4.3 Implicit Nodes
Following [12], we build the graph using a set D of 8768
potential output diﬀerences with high probability (cor-