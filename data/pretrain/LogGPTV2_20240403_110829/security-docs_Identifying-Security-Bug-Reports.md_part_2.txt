- Test models using test data set (noiseless).
In class-dependent noise experiments, for psbr ∈ P and pnsbr ∈ P we do the following for all combinations of psbr and pnsbr:
- Generate noise for training and validation data sets;
- Train logistic regression, naive Bayes and AdaBoost models using training data set (with noise); 
- Tune models using validation data set (with noise);
- Test models using test data set (noiseless).
## V. EXPERIMENTAL RESULTS
In this section analyze the results of experiments conducted according to the methodology described in section IV.
_a) Model performance without noise in the training data set_: One of the contributions of this paper is the proposal of a machine learning model to identify security bugs by using only the title of the bug as data for decision making. This enables the training of machine learning models even when development teams do not wish to share bug reports in full due to presence of sensitive data. We compare the performance of three machine learning models when trained using only bug titles.
The logistic regression model is the best performing classifier. It is the classifier with the highest AUC value, of 0.9826, recall of 0.9353 for a FPR value of 0.0735. The naive Bayes Classifier presents slightly lower performance than the logistic regression Classifier, with an AUC of 0.9779 and a recall of 0.9189 for a FPR of 0.0769. The AdaBoost classifier has an inferior performance in comparison to the two previously mentioned classifiers. It achieves an AUC of 0.9143, and a recall of 0.7018 for a 0.0774 FPR. The area under the ROC curve (AUC) is a good metric for comparing performance of several models, as it summarizes in a single value the TPR vs. FPR relation. In the subsequent analysis we will restrict our comparative analysis to AUC values.
![Table I](./media/TableI.png)
_A. Class Noise: single-class_
One can imagine a scenario where all bugs are assigned to class NSBR by default, and a bug will only be assigned to class SBR if there is a security expert reviewing the bug repository. This scenario is represented in the single-class experimental setting, where we assume that pnsbr = 0 and 0 sbr sbr = 0 compared to a AUC-ROC of model where psbr = 0.25 differs by 0.003 for logistic regression, 0.006 for naive Bayes, and 0.006 for AdaBoost. In the case of psbr = 0.50, the AUC measured for each of the models differ from the model trained with psbr = 0 by 0.007 for logistic regression, 0.011 for naive Bayes, and 0.010 for AdaBoost. logistic regression classifier trained in the presence of single-class noise presents the smallest variation in its AUC metric, i.e. a more robust behavior, when compared to our naive Bayes and AdaBoost classifiers.
_B. Class Noise: class-independent_
We compare the performance of our three classifiers for the case where the training set is corrupted by a class-independent noise. We measure the AUC for each model trained with different levels of pbr in the training data.
![Table III](./media/TableIII.png)
In Table III we observe a decrease in the AUC-ROC for every noise increment in the experiment. The AUC-ROC measured from a model trained on noiseless data compared to a AUC-ROC of model trained with class-independent noise with pbr = 0.25 differs by 0.011 for logistic regression, 0.008 for naive Bayes, and 0.0038 for AdaBoost. We observe that label noise does not impact the AUC of naive Bayes and AdaBoost classifiers significantly when noise levels are lower than 40%. On the other hand, logistic regression Classifier experiences an impact in AUC measure for label noise levels above 30%.
![AUC Variation Impact](./media/AUC.png)
Fig. 1. Variation of AUC-ROC in class-independent noise. For a noise level pbr =0.5 the classifier acts like a random classifier, i.e. AUC≈0.5. But we can observe that for lower noise levels (pbr ≤0.30), the logistic regression learner presents a better performance compared to the other two models. However, for 0.35≤ pbr ≤0.45 naive Bayes learner presents better AUCROC metrics.
_C. Class Noise: class-dependent_
In the final set of experiments, we consider a scenario where different classes contain different noise levels, i.e. psbr &#8800; pnsbr. We systematically increment psbr and pnsbr independently by 0.05 in the training data and observe the change in behavior of the three classifiers.
![Logistic Regression](./media/TableIV.png)
![Naive Bayes](./media/TableV.png)
![AdaBoost](./media/TableVI.png)
Tables IV, V, VI show the variation of AUC as noise is increased in different levels in each class for logistic regression in Table IV, for naive Bayes in Table V and for AdaBoost in Table VI. For all classifiers, we notice an impact in AUC metric when both classes contains noise level above 30%. naive Bayes behaves mot robustly. The impact on AUC is very small even when the 50% of the label in the positive class are flipped, provided that the negative class contains 30% of noisy labels or less. In this case, the drop in AUC is of 0.03. AdaBoost presented the most robust behavior of all three classifiers. A significant change in AUC will only happen for noise levels greater than 45% in both classes. In that case, we start observing an AUC decay greater than 0.02.
_D. On The Presence of Residual Noise in the Original Data Set_
Our data set was labeled by signature-based automated systems and by human experts. Moreover, all bugs reports have been further reviewed and closed by human experts. While we expect that the amount of noise in our data set is minimal and not statistically significant, the presence of residual noise does not invalidate our conclusions. Indeed, for the sake of illustration, assume that the original data set is corrupted by a class-independent noise equal to 0 br i.i.d, the resulting noise per entry will be p∗ = p(1 − pbr )+(1 − p)pbr . For 0 br  br . Thus, the performance of our classifiers would be even better if they were trained with a completely noiseless data set (p = 0) in the first place. In summary, the existence of residual noise in the actual data set means that the resilience against noise of our classifiers is better than the results here presented. Moreover, if the residual noise in our data set were statistically relevant, the AUC of our classifiers would become 0.5 (a random guess) for a level of noise strictly less than 0.5. We do not observe such behavior in our results.
## VI. CONCLUSIONS AND FUTURE WORKS
Our contribution in this paper is twofold. 
First, we have shown the feasibility of security bug report classification based solely on the title of the bug report. This is particularly relevant in scenarios where the entire bug report is not available due to privacy constraints. For example, in our case, the bug reports contained private information such as passwords and cryptographic keys and were not available for training the classifiers. Our result shows that SBR identification can be performed at high accuracy even when only report titles are available. Our classification model that utilizes a combination of TF-IDF and logistic regression performs at an AUC of 0.9831. 
Second, we analyzed the effect of mislabeled training and validation data. We compared three well-known machine learning classification techniques (naive Bayes, logistic regression and AdaBoost) in terms of their robustness against different noise types and noise levels. All three classifiers are robust to single-class noise. Noise in the training data has no significant effect in the resulting classifier. The decrease in AUC is very small ( 0.01) for a level of noise of 50%. For noise present in both classes and is class-independent, naive Bayes and AdaBoost models present significant variations in AUC only when trained with a data set with noise levels greater than 40%. 
Finally, class-dependent noise significantly impacts the AUC only when there is more then 35% noise in both classes. AdaBoost showed the most robustness. The impact in AUC is very small even when the positive class has 50% of its labels noisy, provided that the negative class contains 45% of noisy labels or less. In this case, the drop in AUC is less than 0.03. To the best of our knowledge, this is the first systematic study on the effect of noisy data sets for security bug report identification.
### FUTURE WORKS
In this paper we have started the systematic study of the effects of noise in the performance of machine learning classifiers for the identification of security bugs. There are several interesting sequels to this work, including: examining the effect of noisy data sets in determining the severity level of a security bug; understanding the effect of class imbalance on the resilience of the trained models against noise; understanding the effect of noise that is adversarially introduced in the data set.
### REFERENCES
[1]    John Anvik, Lyndon Hiew, and Gail C Murphy. Who should fix this bug? _In Proceedings of the 28th international conference on Software engineering_, pages 361–370. ACM, 2006.
[2]    Diksha Behl, Sahil Handa, and Anuja Arora. A bug mining tool to identify and analyze security bugs using naive bayes and tf-idf. In _Optimization, Reliabilty, and Information Technology (ICROIT)_, 2014 International Conference on, pages 294–299. IEEE, 2014.
[3]    Nicolas Bettenburg, Rahul Premraj, Thomas Zimmermann, and Sunghun Kim. Duplicate bug reports considered harmful really? In _Software maintenance, 2008. ICSM 2008. IEEE international conference on_, pages 337–345. IEEE, 2008.
[4]    Andres Folleco, Taghi M Khoshgoftaar, Jason Van Hulse, and Lofton Bullard. Identifying learners robust to low quality data. In _Information Reuse and Integration, 2008. IRI 2008. IEEE International Conference on_, pages 190–195. IEEE, 2008.
[5]    Benoˆıt Frenay.´ _Uncertainty and label noise in machine learning_. PhD thesis, Catholic University of Louvain, Louvain-la-Neuve, Belgium, 2013.
[6]    Benoˆıt Frenay and Michel Verleysen. Classification in the presence of´ label noise: a survey. _IEEE transactions on neural networks and learning systems_, 25(5):845–869, 2014.
[7]    Michael Gegick, Pete Rotella, and Tao Xie. Identifying security bug reports via text mining: An industrial case study. In _Mining software repositories (MSR), 2010 7th IEEE working conference on_, pages 11–20. IEEE, 2010.
[8]    Katerina Goseva-Popstojanova and Jacob Tyo. Identification of security related bug reports via text mining using supervised and unsupervised classification. In _2018 IEEE International Conference on Software Quality, Reliability and Security (QRS)_, pages 344–355, 2018.
[9]    Ahmed Lamkanfi, Serge Demeyer, Emanuel Giger, and Bart Goethals. Predicting the severity of a reported bug. In _Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on_, pages 1–10. IEEE, 2010.
[10]    Naresh Manwani and PS Sastry. Noise tolerance under risk minimization. _IEEE transactions on cybernetics_, 43(3):1146–1151, 2013.
[11]    G Murphy and D Cubranic. Automatic bug triage using text categorization. In _Proceedings of the Sixteenth International Conference on Software Engineering & Knowledge Engineering_. Citeseer, 2004.
[12]    Mykola Pechenizkiy, Alexey Tsymbal, Seppo Puuronen, and Oleksandr Pechenizkiy. Class noise and supervised learning in medical domains: The effect of feature extraction. In _null_, pages 708–713. IEEE, 2006.
[13]    Charlotte Pelletier, Silvia Valero, Jordi Inglada, Nicolas Champion, Claire Marais Sicre, and Gerard Dedieu.´ Effect of training class label noise on classification performances for land cover mapping with satellite image time series. _Remote Sensing_, 9(2):173, 2017.
[14]    PS Sastry, GD Nagendra, and Naresh Manwani. A team of continuousaction learning automata for noise-tolerant learning of half-spaces. _IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)_, 40(1):19–28, 2010.
[15]    Choh-Man Teng. A comparison of noise handling techniques. In _FLAIRS Conference_, pages 269–273, 2001.
[16]    Dumidu Wijayasekara, Milos Manic, and Miles McQueen. Vulnerability identification and classification via text mining bug databases. In _Industrial Electronics Society, IECON 2014-40th Annual Conference of the IEEE, pages 3612–3618. IEEE_, 2014.
[17]    Xinli Yang, David Lo, Qiao Huang, Xin Xia, and Jianling Sun. Automated identification of high impact bug reports leveraging imbalanced learning strategies. In _Computer Software and Applications Conference (COMPSAC), 2016 IEEE 40th Annual_, volume 1, pages 227–232. IEEE, 2016.
[18]    Deqing Zou, Zhijun Deng, Zhen Li, and Hai Jin. Automatically identifying security bug reports via multitype features analysis. In _Australasian Conference on Information Security and Privacy_, pages 619–633. Springer, 2018.