ity. As our case studies show (see Sections 5 and 6), ϕ typically
does not provide individual accountability, and hence, veriﬁability
is merely a weak form of accountability, and as argued before, of-
ten too weak in practice, since in case something goes wrong, it is
not possible to held individual parties accountable.
4. RELATED WORK
As already mentioned in the introduction, accountability and ver-
iﬁability play a crucial role for many cryptographic tasks and pro-
tocols. However, in most works, accountability and veriﬁability or
related notions are merely described informally or are tailored to
speciﬁc protocols and security aspects (see, e.g., [4, 5, 17, 47, 45,
14, 13, 41, 3, 11, 40, 37, 10, 12]).
The only work which tried to deal with the general notion of
accountability (and which illustrates that coming up with a con-
vincing deﬁnition for accountability is non-trivial) is the one by
Jagadessan et al. [23]. Based on an abstract labeled transition sys-
tem, Jagadessan et al. proposed several candidate deﬁnitions for
accountability. However, the authors themselves pointed out se-
vere problems with all these candidates. None of these candidates
captures the central intuition behind our deﬁnition that if a de-
sired goal of the protocol is not met then some misbehaving par-
ties are (rightly) blamed. Moreover, the framework proposed by
Jagadessan et al. inherently cannot deal with (even symbolic) cryp-
tography, as, for example, one of their propositions (Proposition
5) capturing properties of the framework would fail in presence of
digital signatures.
In [1, 9], tool-supported analysis of speciﬁc properties related to
accountability have been carried out for a certiﬁed email protocol
and a non-repudiation protocol, respectively.
In [6], a notion related to accountability is considered in the set-
ting of simulation-based security and tailored speciﬁcally to the
problem of secure multi-party computation.
In [21], a weaker notion related to accountability, namely, au-
ditability is formalized in RCF. The approach is model speciﬁc and
tailored towards automatic analysis by type checking. It assumes
that honest parties trigger audit actions. Also, the properties to be
audited are not expressed in relation to the actual traces, but with re-
spect to assume statements that honest and dishonest agents make,
where dishonest agents may make false statements.
Auditability based on log ﬁles is considered in many papers, with
various applications, including network ﬁle systems and peer-to-
peer email [22], network storage services [46], and business pro-
cesses [8].
In [44], three types of veriﬁability, namely eligibility veriﬁabil-
ity, universal veriﬁability, and individual veriﬁability are formal-
ized within the applied π-calculus (see also Section 3). These deﬁ-
nitions are tailored to an automatic analysis and are, as the authors
say, merely sufﬁcient conditions for veriﬁability. Moreover, these
deﬁnitions are applicable only to e-voting protocols and assume
some particular structure of these protocols.
Juels, Catalano and Jakobson [26] present a cryptographic deﬁ-
nition of veriﬁability, which is speciﬁcally tailored to their voting
protocol [25, 26].
γ is guaranteed by ϕ in P and veriﬁable by J.
(5)
If we additionally assume that, in P, J blames only ϕ (i.e. if J out-
puts ψ, then ψ = ϕ), then we also have that (5) implies (4).
This holds for both the symbolic and the computational deﬁni-
tions, where in the latter case the same δ ∈ [0,1] can be used for
accountability and veriﬁability.
5. ANALYZING BINGO VOTING
In this section, we analyze accountability and veriﬁability prop-
erties of the Bingo voting system [10] in the cryptographic set-
ting. Our analysis reveals some interesting new features of the sys-
tem. While it turns out that the system does not provide individual
accountability, the level of accountability/veriﬁability it provides
5
does not depend on the random number generator used in the voting
booth being honest; the numbers it produces may be predictable.
Our analysis also illustrates the necessity of the parameter δ in our
computational deﬁnitions of accountability and veriﬁability.
5.1
Informal Description of the Protocol
We denote the Bingo Voting System by PBingo(n,qnum,qrec,
s,(cid:126)p), where n is the number of voters, qnum and qrec are the prob-
abilities that an honest voter performs the required checks (see
below), s is the number of rounds in the zero-knowledge proofs,
and (cid:126)p = (p0, . . . , pl) is the probability distribution on the possible
choices that a voter has, with p0 being the probability that an honest
voter abstains from voting and pi, i ∈ {1, . . . ,l}, being the proba-
bility that she votes for candidate i.
In addition to the voters, the participants in this system are: (i)
A voting machine (M), which is the main component in the voting
process. The machine uses a bulletin board, that everybody has
read-access to, for broadcasting messages. (ii) A random number
generator (RNG) which is an independent source of randomness,
with its own display, and which is connected to the voting machine.
(iii) Some number of auditors who will contribute randomness in a
distributed way used for randomized partial checking (RPC) in the
zero-knowledge proofs provided by the voting machine.
The election consists of three phases described below: initializa-
1, . . . ,x j
tion, voting, and tallying.
Initialization phase.
In this phase, the voting machine, for ev-
ery candidate j, generates n random numbers x j
n, along with
an unconditionally hiding commitment comm( j,x j
i ) for each pair
( j,x j
i ); more precisely, Pedersen commitments are used. All com-
mitments are then shufﬂed and published on the bulletin board.
Moreover, zero-knowledge proofs are published to guarantee that
the same number n of commitments is created for every candidate
(see Appendix A.1).
Voting phase.
In this phase, a voter can enter the voting booth to
indicate the candidate of her choice, say j, to the voting machine,
by pressing a button corresponding to j. Note that a voter can of
course also abstain from voting. Then, the RNG creates a fresh
random number which is displayed to the voter and transfered to
the voting machine. The machine then prints a receipt consisting
of the candidate names along with the following numbers next to
them: The number next to the chosen candidate is the fresh random
number, where the voter is expected to check that this number is
the same as the one displayed by the RNG. Next to every other
candidate j(cid:48), the machine prints a so far unused number x j(cid:48)
i , for
some i. We assume that an honest voter checks with probability
qnum whether the receipt shows the number displayed by the RNG
at the correct position and complains publicly if this is not the case.
Tallying phase.
In this phase, the voting machine ﬁrst publishes
the result of the election as well as all the receipts given to voters
(in a lexicographical order). A voter is supposed to check whether
her receipt appears on the bulletin board. We assume that a voter
checks her receipt on the bulletin board with probability qrec.
The machine also opens the commitments to all pairs ( j,x j
i )
i has not been printed on
is unused, i.e., x j
where the number x j
i
any receipt.
Moreover, the machine provides zero-knowledge proofs to show
that the commitments that it has not opened yet can be correctly as-
signed to the receipts, i.e., for every receipt, l−1 commitments (be-
longing to l− 1 different candidates and different for every receipt)
can be assigned to l−1 different candidates so that the number next
to a candidate coincides with the number in the corresponding com-
mitment. These zero-knowledge proofs are described in Appendix
A.1.
Now every observer can determine the result of the election: the
number of votes for candidate j is the number of opened commit-
ments of the form comm( j,x j
i ), for some i, minus the number of
abstaining voters.
The probability distributions (cid:126)p and qnum /qrec on the choices and
the checks, respectively, could be generalized to model that the
probabilities qnum and qrec are not necessarily independent and, fur-
thermore, the voters do not necessarily act independently of each
other; however, we stick to the simpler case above.
5.2 Properties of the Protocol
Goal.
Ideally, one might expect the system to provide individual
accountability whenever the goal γopt is violated, where γopt con-
tains all runs in which the result the machine outputs corresponds
exactly to the input of all the voters. However, this goal is too strong
for almost all real voting system: It is typically impossible to give
any guarantees concerning dishonest voters. In fact, a dishonest
voter may, for example, ignore the fact that her receipt is invalid or
is not posted on the bulletin board, and she might indicate this to
dishonest voting authorities/machines. Hence, the voting machine
can potentially alter the dishonest voter’s vote without the risk of
being detected.
Therefore, the best goal γ we can hope for, in general, is that the
result is correct up to the votes of dishonest voters. More formally,
γ is satisﬁed in a run if the published result equals the actual votes
of the honest voters in this run and votes of dishonest voters are
distributed in some way on the candidates, possibly differently to
the actual votes of the dishonest voters. This goal seems realistic
and we believe that it is the goal every voting system should aim for.
In particular, in the case of veriﬁability, if this goal is achieved, one
can be sure that the votes of the honest voters are counted correctly
and that every dishonest voter votes at most once.
For the analysis of voting systems it is instructive to also con-
sider a family of goals γk, where γk coincides with γ except that up
to k of the votes of honest voters (rather than only dishonest voters)
may be altered as well; obviously γ = γ0. Note that since honest
voters check their receipts only with a certain probability (qnum and
qrec in our setting), undetected altering of votes by voting authori-
ties/machines may occur, but hopefully only with a small probabil-
ity.
We will deﬁne this family of goals formally below, after we have
described some modeling details. Before that, however, we dis-
cuss problems with accountability that the Bingo voting system
displays, which can be easily understood without the detailed deﬁ-
nition of the goal.
Problems. Problem 1. If a voter v accuses the machine of not
having printed the number shown by the RNG on the receipt next
to the candidate chosen by v, it is unclear who cheated, unless one
makes the (unrealistic) assumption that the devices keep a com-
pletely trusted log of their actions: the voter (who possibly falsely
claimed something went wrong), the RNG (which possibly trans-
mitted the wrong number to the machine), or the machine (which
possibly ﬁlled out the receipt incorrectly). Hence, a judge can in
this case only state dis(M)∨dis(RNG)∨dis(v). There are two ways
to react to this statement: I) Stop the election process. However, it
is difﬁcult to draw any practical consequences from this verdict,
such as punishing one of these parties. Also, the problem is that
any dishonest voter could easily spoil the whole election process.
II) Ignore the statement (formally, the judge should not make such
a statement, even if a voter complains) and continue the election
6
process. In this case, one has, however, to weaken the goal γ one
aims for: The published result of the election can only be accurate
up to honest voters who did not complain and, as before, dishonest
voters. We discuss variant I) in more detail below; variant II) is
discussed in Appendix A.4.
Problem 2.
It is problematic if a number occurs twice on two
different receipts, which, if parties are honest, should happen with
only negligible probability: Consider the case that both the ma-
chine and the RNG are dishonest (and cooperate). The machine
then can know upfront the values that the RNG will produce. As-
sume that the RNG will produce the number r for voter v. In this
case, the voting machine could create commitments on (c,r) for
all candidates c. Now, if v votes for some candidate c0, the ma-
chine can print r next to c0 on the receipt and print a fresh random
number next to a different candidate. The machine can then per-
form correctly the ZK-proof, although it changed the vote of v. As
the machine has to open all commitments (possibly after shufﬂing
and re-randomization) it is visible that two times the same num-
ber occurs. However, the following cases could hold true: (i) the
machine and the RNG are dishonest (as in the case above), (ii) the
machine is honest but the RNG produced several times the same
number, and (iii) the RNG is honest and the machine produced sev-
eral times the same number. Hence it is not clear which individual
party misbehaved. Since M and the RNG are considered to be part
of the authorities, not knowing which speciﬁc device to blame is
not as problematic as in the previous case.
Judging Procedure.
In order to be able to formally state and
prove the level of accountability the protocol provides, we ﬁrst de-
ﬁne a judging procedure, which decides whether to accept a run or
whether to blame (groups of) parties. Such a procedure should, in
fact, be part of the protocol speciﬁcation.
The judging procedure is based solely on publicly available in-
formation, and hence, can be carried out both by an external judge
and a regular protocol participant. The procedure consists of the
following steps, where we assume that the procedure is run hon-
estly by some party a. In the following, we describe the behavior
of the agent a:
J1. If a participant b deviates from the protocol in an obvious way,
e.g., the RNG does not display a number or the voting machine
does not publish the commitments in the initialization phase, a
blames the respective participant by stating the trivial formula
dis(b). The voting machine is also blamed if a zero-knowledge
proof is not correct or a voter rightly complains about her re-
ceipt, i.e., she has a receipt that is not shown on the bulletin
board.
J2. If a voter v complains in the booth, a states the formula
dis(M) ∨ dis(RNG) ∨ dis(v) as explained above (Problem 1).
We denote the set of runs in which some voter complains in the
booth by αcompl.
J3. We denote the event that a number occurs twice on two dif-
In this case, the agent a states
ferent receipts with αtwice.
dis(M)∨ dis(RNG), as explained above (Problem 2).
J4. The agent a states dis(M) if a number occurs twice on one re-
ceipt or the machine opens a commitment to a number that al-
ready appears on a receipt.
J5. If none of the above happens, a accepts the run.
Modeling. The Bingo Voting system can easily be modeled as
a protocol in the sense of Deﬁnition 1, where in addition to the
participants mentioned in Section 5.1, we also consider a sched-
uler and a voting booth (see Appendix A.2 for details). We denote
this protocol by Pa
Bingo1(n,qnum,qrec,s,(cid:126)p), where the agent a car-
7
ries out the above judging procedure. We list some crucial security
assumptions reﬂected in our modeling:
A1. There is only an unidirectional connection from the RNG to
the machine, i.e., the machine cannot send messages to the
RNG (see below for the justiﬁcation).
A2. One of the auditors that contribute to the randomness used for
the randomized partial checking of the zero-knowledge proofs
is honest. (Clearly, if all auditors were dishonest, the machine
could change the result of the election by faking the zero-