我们将在`app.py`文件中设置所有的日志配置。让我们分解配置的每个部分:
1.  首先，我们将生成一个附加`request_id`的格式化程序，以便它在生成日志时可用:
```
class RequestFormatter(logging.Formatter):
    ''' Inject the HTTP_X_REQUEST_ID to format logs '''
    def format(self, record):
        record.request_id = 'NA'
        if has_request_context():
            record.request_id = request.environ.get("HTTP_X_REQUEST_ID")
        return super().format(record)
```
可以看到，`request.environ`变量中有`HTTP_X_REQUEST_ID`表头。
2.  稍后，在`create_app`中，我们将设置附加到`application`记录器的处理程序:
```
# Enable RequestId
application.config['REQUEST_ID_UNIQUE_VALUE_PREFIX'] = ''
RequestID(application)
if not script:
    # For scripts, it should not connect to Syslog
    handler = logging.handlers.SysLogHandler(('syslog', 5140))
    req_format = ('[%(asctime)s] %(levelname)s [%(request_id)s] '
                    %(module)s: %(message)s')
    handler.setFormatter(RequestFormatter(req_format))
    handler.setLevel(logging.INFO)
    application.logger.addHandler(handler)
    # Do not propagate to avoid log duplication
    application.logger.propagate = False
```
我们只在脚本运行时设置处理程序。`SysLogHandler`包含在 Python 中。之后，我们设置格式，包括`request_id`。格式化程序使用我们之前定义的`RequestFormatter`。
Here, we are hardcoding the values of the logger level to `INFO` and the `syslog` host to `syslog`, which corresponds to the service. Kubernetes will resolve this DNS correctly. Both values can be passed through environment variables, but we didn't do this here for the sake of simplicity.
记录器尚未传播，因此避免将其发送给`root`记录器，该记录器将复制日志。
# 记录每个请求
我们需要捕获的每个请求中都有共同的元素。Flask 允许我们在请求之前和之后执行代码，所以我们可以用它来记录每个请求的公共元素。让我们学习如何做到这一点。
从`app.py`文件中，我们将定义`logging_before`功能:
```
from flask import current_app, g
def logging_before():
    msg = 'REQUEST {REQUEST_METHOD} {REQUEST_URI}'.format(**request.environ)
    current_app.logger.info(msg)
    # Store the start time for the request
    g.start_time = time()
```
这会创建一个带有单词`REQUEST`的日志，以及每个请求的两个基本部分——方法和 URI——它们来自`request.environ`。然后，他们会被添加到应用记录器的`INFO`日志中。
我们还使用`g`对象来存储请求开始的时间。
The `g` object allows us to store values through a request. We will use it to calculate the time the request is going to take.
也有相应的`logging_after`功能。它收集请求结束时的时间，并以毫秒为单位计算差值:
```
def logging_after(response):
    # Get total time in milliseconds
    total_time = time() - g.start_time
    time_in_ms = int(total_time * 1000)
    msg = f'RESPONSE TIME {time_in_ms} ms'
    current_app.logger.info(msg)
    msg = f'RESPONSE STATUS {response.status_code.value}'
    current_app.logger.info(msg)
    # Store metrics
    ...
    return response
```
这将允许我们检测花费更长时间的请求，并将其存储在指标中，我们将在下一节中看到。
然后，在`create_app`功能中启用这些功能:
```
def create_app(script=False):
    ...
    application = Flask(__name__)
    application.before_request(logging_before)
    application.after_request(logging_after)
```
这将在我们每次生成请求时创建一组日志。
生成日志后，我们可以在`frontrail`界面进行搜索。
# 搜索所有的日志
来自不同应用的所有不同日志将被集中，并可在`http://syslog.example.local`进行搜索。
如果你打电话到`http://frontend.example.local/search?search=speak`搜索想法，你会在日志中看到对应的想法后端，如下图截图所示:
![](img/1254a0cc-90d6-4340-b901-95536a0a34e0.png)
我们可以通过请求标识进行过滤，即`63517c17-5a40-4856-9f3b-904b180688f6`，来获取思想后端请求日志。紧随其后的是`thoughts_backend_uwsgi`和`frontend_uwsgi`请求日志，它们显示了请求的流程。
在这里，您可以看到我们之前谈到的所有元素:
*   请求前的`REQUEST`日志
*   `api_namespace`请求，包含应用数据
*   `RESPONSE`之后的日志，包含结果和时间
在思想后端的代码中，我们故意留下了一个错误。如果用户试图分享一个新想法，它就会被触发。我们将使用它来学习如何通过日志调试问题。
# 通过日志检测问题
对于运行系统中的任何问题，都可能出现两种错误:预期错误和意外错误。
# 检测预期错误
预期错误是通过在代码中显式创建`ERROR`日志而引发的错误。如果正在生成错误日志，这意味着它反映了预先计划的情况；例如，您无法连接到数据库，或者有一些数据以旧的不推荐使用的格式存储。我们不希望这种情况发生，但我们看到了这种情况发生的可能性，并准备了代码来处理它。他们通常会很好地描述情况，以至于问题很明显，即使解决方案并不明显。
它们相对容易处理，因为它们描述了可预见的问题。
# 捕获意外错误
意外错误是可能发生的其他类型的错误。事情以不可预见的方式发展。意外错误通常是由于 Python 异常在代码中的某个点被引发而没有被捕获而产生的。
如果日志记录已正确配置，任何未被捕获的异常或错误将触发`ERROR`日志，其中将包括栈跟踪。这些错误可能不会立即显而易见，需要进一步调查。
To help explain these errors, we introduced an exception in the code for the Thoughts Backend in the `Chapter10` code. You can check the code on GitHub ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend)). This simulates an unexpected exception.
当试图为一个登录用户发布一个新想法时，我们得到一个奇怪的行为，并在日志中看到以下错误。如下图右上角所示，我们通过`ERROR`进行过滤，过滤问题:
![](img/3bad0ee5-9505-4648-8158-cf878d1969ad.png)
如您所见，栈跟踪显示在一行中。这可能取决于您如何捕获和显示日志。Flask 将自动生成一个状态代码为 500 的 HTTP 响应。如果呼叫者没有准备好接收 500 响应，这可能会触发更多的错误。
然后，栈跟踪会让你知道什么坏了。在这种情况下，我们可以看到在第 80 行的`api_namespace.py`文件中有一个`raise Exception`命令。这允许我们定位异常。
Since this is a synthetic error that's been generated specifically as an example, it is actually easy to find out the root cause. In the example code, we are explicitly raising an exception, which produces an error. This may not be the case in a real use case, where the exception could be generated in a different place than the actual error. Exceptions can be also originated in a different microservice within the same cluster.
检测到错误后，目标应该是用微服务中的单元测试来复制它，以便生成异常。这将允许我们在受控环境中复制条件。
如果我们为`Chapter10`中可用的思想后端代码运行测试，我们将会因此看到错误。请注意，日志显示在失败的测试中:
```
$ docker-compose run test
...
___ ERROR at setup of test_get_non_existing_thought ___
-------- Captured log setup ---------
INFO flask.app:app.py:46 REQUEST POST /api/me/thoughts/
INFO flask.app:token_validation.py:66 Header successfully validated
ERROR flask.app:app.py:1761 Exception on /api/me/thoughts/ [POST]
Traceback (most recent call last):
 File "/opt/venv/lib/python3.6/site-packages/flask/app.py", line 1813, in full_dispatch_request
 rv = self.dispatch_request()
 File "/opt/venv/lib/python3.6/site-packages/flask/app.py", line 1799, in dispatch_request
 return self.view_functions[rule.endpoint](**req.view_args)
 File "/opt/venv/lib/python3.6/site-packages/flask_restplus/api.py", line 325, in wrapper
 resp = resource(*args, **kwargs)
 File "/opt/venv/lib/python3.6/site-packages/flask/views.py", line 88, in view
 return self.dispatch_request(*args, **kwargs)
 File "/opt/venv/lib/python3.6/site-packages/flask_restplus/resource.py", line 44, in dispatch_request
 resp = meth(*args, **kwargs)
 File "/opt/venv/lib/python3.6/site-packages/flask_restplus/marshalling.py", line 136, in wrapper
 resp = f(*args, **kwargs)
 File "/opt/code/thoughts_backend/api_namespace.py", line 80, in post
 raise Exception('Unexpected error!')
Exception: Unexpected error!
INFO flask.app:app.py:57 RESPONSE TIME 3 ms
INFO flask.app:app.py:60 RESPONSE STATUS 500 
```
一旦错误在单元测试中重现，修复它通常是微不足道的。添加一个单元测试来捕获触发错误的条件集，然后修复它。新的单元测试将检测错误是否已经在每个自动化构建中被重新引入。
To fix the example code, remove the `raise` line of code. Then, things will work again.
有时，问题无法解决，因为它可能是外部的。也许我们数据库中的某些行有问题，或者另一个服务正在返回格式不正确的数据。在那些情况下，我们无法完全避免错误的根本原因。但是，有可能捕获问题，进行一些补救，并从意外错误转移到预期错误。
请注意，并不是每一个检测到的意外错误都值得花费时间。有时，未捕获的错误提供了问题所在的足够信息，这超出了 web 服务应该处理的范围；例如，可能存在网络问题，web 服务无法连接到数据库。当你想把时间花在发展上时，运用你的判断力。
# 日志策略
我们在处理日志时有一个问题。特定信息的适当级别是什么？这是`WARNING`还是`ERROR`？这应该是一个`INFO`声明吗？
大多数日志级别的描述都使用了定义，如*程序显示了潜在的有害情况*或*程序突出显示了请求的进度*。这些都是模糊的，在现实生活环境中不是很有用。相反，尝试通过将每个日志级别与预期的后续操作相关联来定义它们。这有助于明确当发现特定级别的日志时该做什么。
下表显示了不同级别的一些示例以及应该采取的措施:
| **日志级别** | **采取的行动** | **评论** |
| `DEBUG` | 没什么？ | 未跟踪。 |
| `INFO` | 没什么？ | `INFO`日志显示关于请求流的一般信息，以帮助跟踪问题。 |
| `WARNING` | 曲目编号。警惕提高水平。 | `WARNING`日志跟踪已自动修复的错误，如重试连接(但最终连接)或数据库数据中可修复的格式错误。突然增加可能需要调查。 |
| `ERROR` | 曲目编号。警惕提高水平。全部复习。 | `ERROR`日志跟踪无法修复的错误。突然增加可能需要立即采取行动，以便能够补救。 |
| `CRITICAL` | 立即响应。 | `CRITICAL`日志表明系统出现灾难性故障。甚至有一个会表示系统不工作，无法恢复。 |
这只是一个建议，但它对如何应对提出了明确的期望。根据您的团队和您期望的服务级别的工作方式，您可以根据您的用例对它们进行调整。
在这里，层次非常清晰，并且接受将生成一定数量的`ERROR`日志。不是所有的事情都需要立即修复，但是应该记录并检查它们。
In real life, `ERROR` logs will be typically categorized as "we're doomed" or "meh." Development teams should actively either fix or remove "mehs" to reduce them as much as possible. That may include lowering the level of logs if they aren't covering actual errors. You want as few `ERROR` logs as possible, but all of them need to be meaningful.