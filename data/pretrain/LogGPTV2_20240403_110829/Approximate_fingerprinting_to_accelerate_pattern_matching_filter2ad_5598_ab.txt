F(abc)
F(bcd)
fingerprint table
a) general case
b) single fingerprint table
c) multiple fingerprint table
d) unifying table
Figure 1: Approximate Fingerprinting
doing so, we reduce the number of table indexing operations
by a factor of s. The number of such operations, L, is given
by:
‰
ı
L =
b − w + 1
s
(1)
The problem with sliding the window forward by s bytes is
that we would not be able to detect those patterns that cross
window boundaries. A solution is then to add extra entries
to the ﬁngerprint table that will report all matches which
contain any sequence of characters (s− 1) byte long followed
by the ﬁrst (w − s + 1) characters of a pattern as a match.
This solution will increase the number of false positives for
all those patterns that do not cross the window boundary.
Indeed, we are trading an increase in the ﬁngerprint table
size and an increase in the false positive rate for a decrease
in the number of ﬁngerprint table lookups.
Figure 1b shows a detailed example with a window size of
4 bytes and the pattern abcd. The window is slid forward
by 2 bytes at each step. At the ﬁrst step, the ﬁngerprint
is computed on the substring from byte 1 through byte 4.
On the next iteration, the window would move forward by
2 bytes and a new ﬁngerprint would be computed on the
substring between byte 3 and byte 6. We will detect the
presence of abcd in the payload if it starts at byte position 1
or if it starts at byte position 3. We will miss the presence of
abcd in the packet if it is oﬀset by 1 byte at the beginning.
For this reason, we add extra entries to the ﬁngerprint table
denoted by *abc where the * represents a single character
from the alphabet (i.e., we add 256 entries to the ﬁngerprint
table). The amount of memory required for the pattern
table is given by
np · f · (1 + 256
s−1
(2)
where np is the total number of original patterns, f is the
size of ﬁngerprint in bytes and s is the window step size in
bytes.
),
Reducing the memory footprint. Using a single pattern
table as shown in Figure 1b is not very memory eﬃcient.
According to (2), the amount of memory required to store
all the patterns in the table increases exponentially with the
window step size, s. Therefore, this approach is impractical
for window step sizes greater than 2 bytes.
One solution to this problem is to use multiple tables
(see Figure 1c) to store ﬁngerprints of substrings of vary-
ing lengths starting from w bytes down to w − s bytes. The
memory reduction comes from the fact that all the extra
patterns we introduced previously diﬀered in the ﬁrst s − 1
characters, but were the same for the remaining w − s + 1
characters. Thus, the extra 256s−1 patterns stored in the
single table case described above can be represented by a
single entry in a separate ﬁngerprint tables that contains
shorter patterns. The memory growth is now linear with the
number of patterns and the window step size and therefore
scales well with the increase of the window step size. The
number of extra tables needed is the same as the window
step size s. Note that since Rabin’s ﬁngerprints are com-
puted incrementally, it is trivial to obtain the ﬁngerprint of
the last w − s + 1 bytes when computing a ﬁngerprint for w
bytes.
Consider the same example described previously: window
sizes w of 4 bytes, the window step size s is 2 bytes and we
look for the pattern abcd In the single table case, we would
need an extra 256 entries of the form *abc to be stored in
the pattern table. Now, these are represented in another
pattern table by just the common portion of the string abc.
The steps proceed as follows. A ﬁrst ﬁngerprint, F , is
computed over the ﬁrst window and a second ﬁngerprint, F (cid:2)
,
is computed over the shorter window. The ﬁrst ﬁngerprint
table is looked up with F . If a match is found, then abcd is
present in the ﬁrst window (there is a small chance of a false
positive due to collisions in the ﬁngerprint space). If F is
not found in the ﬁrst ﬁngerprint table, the second ﬁngerprint
table is looked up with F (cid:2)
. If a match is found, it is reported
as a possible hit. This example is illustrated in Figure 1c.
The amount of memory required for these pattern tables is
np · f · s, where np is the total number of original patterns,
f is the size of ﬁngerprint in bytes and s is the window step
size in bytes.
While the multi-table approach is well suited for a hard-
ware implementation, where multiple small tables can eas-
ily be accessed in parallel,
in a software implementation
the multiple sequential memory accesses would signiﬁcantly
lower performance. Thus, alternatively, the multiple tables
can be compressed into a single, unifying table (see Fig-
ure 1d), by storing only suﬃxes of length w − s + 1 bytes
(the shortest sub-window) of all the entries in the multiple
ﬁngerprint tables. In our practical example, to detect abcd
would thus mean storing the ﬁngerprints F (cid:2)
of strings abc
(from the original ”w − s + 1” table) and bcd (suﬃx of entry
abcd in the w − s + 2 table, as in Figures 1c and 1d). This
solution further reduces the table size and requires only one
ﬁngerprint computation and one lookup, but increases the
possible number of false positive matches and ﬁngerprint
collisions, due to only a portion of the string being matched
and possible overlaps of these shorter substrings.
Total rules
Non-pattern rules
Pattern containing rules
content containing rules
2836
146
2690
1930
Table 1: Snort rule database statistics.
4. EVALUATION
We conduct two experiments to evaluate the performance
of the approximation pattern matching method. The ﬁrst
experiment models the performance of the preprocessor which
uses the method described in Figure 1c. This conﬁguration
of the preprocessor is ideal for hardware implementation on
an FPGA or network interface card. The evaluation is fo-
cused on three aspects: (i) the memory footprint of the ﬁn-
gerprint tables required to store the patterns; (ii) the num-
ber of table lookups per packet — that varies with the step
size s as given by (1); and (iii) the number of false positives
in the packet trace, i.e. the number of packets unnecessarily
forwarded to the precise pattern matching algorithm.
The second experiment models the performance of the
preprocessor which utilizes the method described in Fig-
ure 1d. This conﬁguration is more suited to a software
implementation on a general purpose processor. The evalu-
ation is focused on two aspects: (i) the time required to pro-
cess a stream of packets with and without the preprocessor;
and (ii) the fraction of the original data that is forwarded
to the precise pattern matching algorithm.
In order to provide a realistic packet stream, we consider
two long packet traces (Trace 1 and Trace 2) with full pay-
loads collected in a residential access network [9]. The site
where the trace was collected represents a user population
estimated in the order of 20,000 with a large number of
services and applications. Trace 1 is 20 minutes long and
contains 19,018,509 packets. Trace 2 is 70 minutes long and
contains 67,875,101 packets.
String Patterns. The set of patterns we search in the pay-
loads are derived from the Snort rules database as of August
25, 2005. The rule statistics for this database are shown in
Figure 1. This table shows that there are 2,690 rules in Snort
which require pattern matching. Payload pattern matching
within Snort is speciﬁed by the content, uricontent or the
pcre payload detection rule options. The content option al-
lows to specify an exact matching pattern. The uricontent
option results in a search in the normalized request URI
ﬁeld. It only works in conjunction with a HTTP preproces-
sor. The pcre option allows to specify a regular expression
over the payload to be sought for. Our system can be placed
in line with any other existing pre-processing that Snort per-
forms today (e.g., HTTP inspection, protocol parsing etc.)
and label all the packets that could potentially trigger a
match. The capability to match on both uricontent and
pcre options exist2. In our study, we consider only those
rules that present the content option (1,930 rules).
The approximate ﬁngerprint method can only be applied
to content patterns that are longer than the window size
2In the current Snort implementation, almost every regular
expression rule carries a content rule and only upon a match
of this string the appropriate regular expression evaluation
is triggered. The actual content string is often a substring
of the pcre regular expression.
1
0.8
0.6
0.4
0.2
)
x
≥
h
t
g
n
e
l
(
P
0
0
4
8
12
all patterns
max length per rule
40
44
48
52
20
16
36
content pattern length (bytes)
24
28
32
Figure 2: Complementary cumulative distribution
of content string lengths
(w) chosen for computing the ﬁngerprint. A large window
size would result in more accurate pattern matching and
a smaller number of false positives. Also, increasing the
window size would enable us to increase the step size (s) and
thus reduce the total number of ﬁngerprint table lookups per
packet.
To ﬁnd an appropriate value of w we look at the distribu-
tion of the length of the patterns in the Snort ruleset. Fig-
ure 2 shows the complementary cumulative distribution of
content pattern lengths. The dashed line shows the distri-
bution for all patterns, while the solid line shows the length
distribution for the longest pattern in each rule. We can see
that a window size of 4 bytes would cover 90.78% of all rules,
while a size of 8 bytes would cover 58.45% of the rules.
To accommodate rules with patterns shorter than the win-
dow size, a diﬀerent pre-processing step would be needed. A
combination of a Bloom ﬁlter and the approximate ﬁnger-
print would be a possible fast single lookup solution, and is a
subject of our ongoing work. Discussion of this technique is
beyond the scope of this article, however, relevant references
indicate that a feasible solution exists [16].
Performance Results. First, we test the conﬁguration
of the pre-processor which is suited for a hardware imple-
mentation (described in Figure 1c). We evaluate the perfor-
mance by running Snort on two traces: the original packet
trace and a “reduced” packet trace that contains all packets
deemed suspicious by our pre-processor. We measure the
run times for Snort on the two traces to get an idea of the
performance gain the pre-processor can provide. Trace 1
was used for this experiment.
Table 2 summarizes our experimental results. We used 16
bit wide ﬁngerprints for window sizes of 4 bytes and 32 bit
wide ﬁngerprints for window sizes of 8 bytes. For w = 4, the
subset of the Snort ruleset we considered contains 1637 rules
and 543 unique patterns. For w = 8, the Snort rule subset
contains 1057 rules and 426 unique patterns. Columns 3,
4 and 5 show the size, processing time and alerts returned
by Snort for the original trace, while columns 6 to 9 show
the same data for the reduced pre-processed trace. The last
column shows the memory footprint of that particular pre-
processor conﬁguration in Kbytes. This number does not
include bookkeeping overhead and represents the amount
of space required to store the ﬁngerprint table alone. In a
real hardware implementation, the number shown in Table
Window
(bytes)
Step
(bytes)
4
4
4
8
8
8
8
8
8
1
2
3
1
2
3
4
5
6
Packets
19,018,509
19,018,509
19,018,509
19,018,509
19,018,509
19,018,509
19,018,509
19,018,509
19,018,509
Full Trace
Time (sec.)
401.13
401.13
401.13
402.98
402.98
402.98
402.98
402.98
402.98
Pre-Processed Trace
Memory