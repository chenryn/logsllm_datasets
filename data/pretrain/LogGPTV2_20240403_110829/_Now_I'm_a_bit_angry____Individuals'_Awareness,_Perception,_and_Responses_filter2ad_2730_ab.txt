a list of all breaches associated with their provided email
address and links to resources on data breach recovery to help
them process and act on this potentially new information.
3.2 Recruitment
We recruited participants via Proliﬁc,2 an online research
platform similar to Amazon Mechanical Turk with more de-
mographically diverse subjects [57], between August and
October 2020. We balanced participants’ age and gender dis-
tributions in data collection. After the ﬁrst 171 participants,
we realized and corrected a storage error that caused missing
data in income and ratings for taken/intended actions. We note
in Section 5 how we accounted for this in our analyses. Par-
ticipants were compensated $2.50 for an average completion
time of 13.37 minutes ($11.22/hour).
3.3 Analyses
We collected data from 416 participants; three participants
were excluded as they did not respond to any open-ended
questions meaningfully, resulting in 413 participants in total.
We based our sample size on our planned analyses: Bujang et
al. [11] suggest n=500 or n=100+50×#IVs as the minimum
sample size for logistic regressions. For the linear regression
(RQ4), G*Power suggests n=127 for detecting medium ef-
fects ( f 2=.15), with α=.05, β=.80. With 413 participants
2https://prolific.co
(435 email-speciﬁc responses; 792 breach-speciﬁc responses)
we met or exceeded these thresholds.
97% of participants passed our generic attention check. Of
the 302 participants who were shown at least one breach,
only 55% passed the breach-speciﬁc attention check, whereas
the rest chose “none of these” (42%) or a decoy option
(3%). We reviewed open-ended responses from participants
who failed this attention check, and all of them were de-
tailed and insightful. We also did not ﬁnd signiﬁcant cor-
relations between this attention check’s performance and
participants’ breach-speciﬁc responses about awareness (chi-
squared test, χ(1)=.06, p=0.8), concern level (Mann Whit-
ney test, W =58395, p=0.2), and whether they had taken ac-
tion (chi-squared test, χ(1)=.29, p=0.6). Thus, we did not
exclude any of these participants as our ﬁndings suggest the
question was not a reliable exclusion criterion.
Qualitative analysis. We analyzed participants’ open-
ended responses using inductive coding [75]. For Questions
7, 10, 14, 16, and 18, a primary coder created an initial code-
book based on all responses. Multiple coders then iteratively
improved the codebook. A second coder analyzed 20% of
responses to each question to ensure high inter-rater reliabil-
ity [45]. Cohen’s κ were 0.89 (Q7), 0.73 (Q10), 0.74 (Q14),
0.81 (Q16), and 0.78 (Q18). We resolved all coding discrepan-
cies through discussions. Appendix B includes the codebook,
with common themes highlighted.
Statistical analysis. We conducted regressions to identify
inﬂuential factors with respect to breach status (RQ1), aware-
ness (RQ3), emotional response (RQ4) and behavioral re-
sponse (RQ5). We included a random-intercept for individual
participants to account for repeated observations between mul-
tiple breaches. However, for models corresponding to RQ1
the random effects were close to zero and caused a bound-
ary singularity ﬁt, so we conducted single-level regressions
instead. For all models, we treated participant demographics
(age, gender, education, occupational background) as control
variables: we report a model’s output with participant demo-
graphics when it has a signiﬁcantly better ﬁt than the model
without; otherwise, we opt for the simpler model in report-
ing the results. We treated participants’ responses of concern
level on a 5-point Likert scale as a continuous variable in our
regressions, which has limitations, as we discuss below.
3.4 Limitations
As with most surveys, parts of our ﬁndings rely on self-
reported data, which is prone to biases. For instance, prior
work has shown a gap between self-reported behavioral in-
tentions and actual behaviors in security contexts [34] and
beyond [78]. We do not imply that all participants would take
actions they reported. Nevertheless, participants’ self-reported
396    30th USENIX Security Symposium
USENIX Association
intentions to act can inform future research and mechanism
design to better protect consumers against data breaches.
HIBP’s API does not return breaches marked sensitive such
as those involving adult sites. Accessing these breaches re-
quires sending a conﬁrmation message to participant-provided
email addresses for ownership veriﬁcation. We decided not
to do this as it may suggest to participants that we store their
email addresses even though we do not.
Our study only included data breaches involving email ad-
dresses, which may not represent all breaches (e.g., only 4%
of breaches recorded by Privacy Rights Clearinghouse [63]
included email addresses). Relatedly, the email-focused na-
ture of these breaches means it is difﬁcult to track whether
and how breached organizations in our sample notiﬁed af-
fected individuals and how that impacts consumer reactions,
because existing breach notiﬁcation databases mostly docu-
ment letter-based notiﬁcations [98]. Future research can look
into breaches that expose a broader range of data types and
consider organizations’ handling of breaches when feasible.
Regarding our analyses, we considered several options of
treating the Likert responses of concern level: ordinal, nomi-
nal, or continuous. Treating concern as ordinal would intro-
duce square and cubit effects into the model — these effects
are difﬁcult to interpret and inconsistent with the scale. Treat-
ing concern as nominal would lose information about the
scale’s ordering and prevent comparisons across all levels
(e.g., with “not at all concerned” as the baseline, the regres-
sion would not describe the difference when moving up or
down the scale between “slightly concerned” and “extremely
concerned”). Treating concern as continuous would require
a more cautious interpretation of the p-values in the analy-
sis, and it assumes equal differences between the scale items.
After discussions with our university’s statistical consulting
service, we followed their advice and decided to treat concern
as a continuous variable. While this comes with the limita-
tions mentioned above, it also allows a more straightforward
and meaningful interpretation of results, which we prioritize
to make the results more accessible.
4 Data Description
Participant proﬁle. Table 1 summarizes our 413 partic-
ipants’ demographics and breach status. Our participants
were almost evenly distributed between men and women but
skewed educated and younger. 122 (30%) described having a
background in information technology; 25 (6%) in law.
In total, participants provided 435 email addresses. 421
(97%) accounts were solely owned by the participant, and ten
were shared with someone else. Four were either someone
else’s account or a made-up address for the study, and so
were removed from the data. Participants whose initial email
address was not exposed in any breach could scan another:
393 participants (95%) scanned only one email address, 18
scanned two addresses, and only two scanned three addresses.
Men
Women
Non-Binary
18-24
25-29
30-34
35-39
40-44
45-49
50-54
54-59
60-64
65+
Some High School
High School or Equiv.
Some College
Associate (voc./occ.)
Associate (aca.)
Bachalor
Masters
Professional
Doctorate
IT Background
No IT Background
Prefer not to say
Law Background
No Law Background
Prefer not to say
No Data
$150K
Total
Num. (%)
W/ Breaches
139 (70%)
162 (76%)
1 (50%)
56 (73%)
35 (69%)
33 (79%)
29 (59%)
26 (58%)
29 (91%)
30 (77%)
30 (88%)
19 (70%)
15 (88%)
0 (0%)
35 (76%)
70 (80%)
14 (100%)
19 (95%)
108 (77%)
46 (55%)
4 (80%)
6 (38%)
67 (55%)
224 (81%)
11 (85%)
14 (56%)
278 (74%)
10 (71%)
115 (68%)
15 (94%)
20 (91%)
26 (93%)
19 (73%)
40 (89%)
28 (74%)
22 (59%)
13 (54%)
302 (73%)
Total
199
212
2
77
51
42
49
45
32
39
34
27
17
1
46
88
14
20
140
83
5
16
122
278
13
25
374
14
170
16
22
28
26
45
38
37
24
413
Num. (%)
W/o Breaches
Avg. (Med./Std.)
Breaches
60 (30%)
50 (24%)
1 (50%)
21 (27%)
16 (31%)
9 (21%)
20 (41%)
19 (42%)
3 (9%)
9 (23%)
4 (12%)
8 (30%)
2 (12%)
1 (100%)
11 (24%)
18 (20%)
0 (0%)
1 (5%)
32 (23%)
37 (45%)
1 (20%)
10 (62%)
55 (45%)
54 (19%)
2 (15%)
11 (44%)
96 (26%)
4 (29%)
55 (32%)
1 (6%)
2 (9%)
2 (7%)
7 (27%)
5 (11%)
10 (26%)
15 (41%)
11 (46%)
111 (27%)
4.49 (2/5.97)
6.11 (4/6.28)
11.00 (11/11.00)
3.90 (2/5.15)
4.25 (2/4.90)
6.55 (3/8.72)
4.63 (1/7.05)
4.36 (2/5.04)
6.59 (4/6.05)
6.72 (6/6.16)
6.12 (5/4.82)
6.52 (3/6.85)
8.24 (8/6.06)
0.00 (0/0.00)
4.59 (3/4.61)
5.67 (3/6.63)
8.07 (6/6.51)
6.10 (4/5.99)
6.04 (4/6.56)
4.10 (2/5.68)
11.60 (13/7.71)
1.44 (0/2.26)
3.82 (1/6.30)
5.91 (4/6.06)
8.00 (9/6.41)
5.80 (2/9.63)
5.29 (3/5.93)
6.36 (5/6.25)
4.45 (2/6.21)
7.81 (4/8.59)
6.77 (4/5.79)
5.89 (3/5.37)
4.58 (2/5.35)
8.04 (7/6.50)
6.95 (4/6.61)
4.05 (2/4.63)
3.92 (2/5.34)
5.36 (3/6.23)
Table 1: Participant demographics and breach status (n=413).
For the 431 owned or shared email accounts, we further