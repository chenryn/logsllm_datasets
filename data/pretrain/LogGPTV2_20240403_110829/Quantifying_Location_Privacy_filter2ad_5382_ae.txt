w
e
b
t
y
c
a
v
i
r
P
n
o
i
t
a
c
o
L
y
c
a
v
i
r
P
n
o
i
t
a
c
o
L
s
g
n
i
t
e
e
m
f
o
r
e
b
m
u
n
d
e
t
c
e
p
x
e
f
o
s
s
e
n
t
c
e
r
r
o
c
N
I
15
10
5
0
i
n
o
g
e
r
a
n
i
s
r
e
s
u
f
o
r
e
b
m
u
n
d
e
t
c
e
p
x
e
f
o
s
s
e
n
t
c
e
r
r
o
c
N
I
8
7
6
5
4
3
2
1
0
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
Hiding Level
(i) LPPM(0, 0, *)
Hiding Level
(ii) LPPM(1, 3, *)
(a) LPLO-ATT(u, t) for all users u and times t
25
20
15
10
5
0
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
Hiding Level
(i) LPPM(0, 0, *)
Hiding Level
(ii) LPPM(1, 3, *)
(b) LPMD-ATT(u, v) for all pairs of users u, v
8
7
6
5
4
3
2
1
0
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
the effectiveness of
Figure 4 illustrates the results that we have obtained
about
the precision-reduction and
location-hiding LPPMs against these three attacks. Each
row in the ﬁgure corresponds to one attack. The left-
hand column shows the results for the LPPM with pa-
rameters (0, 0, 0.0), (0, 0, 0.1), ..., (0, 0, 0.9), and the right-
hand column shows
the LPPM with
the results
for
Hiding Level
(i) LPPM(0, 0, *)
Hiding Level
(ii) LPPM(1, 3, *)
(c) LPAP-ATT (r, t) for all regions r and times t
The system-level location-privacy against attacks LO-ATT(a),
Figure 4.
MD-ATT(b) and AP-ATT(c). Left-hand and right-hand side plots show the
attack results against LPPM(0, 0, ∗) and LPPM(1, 3, ∗), respectively.
The last parameter of LPPMs (hiding level λh) is shown on the x-axis.
The boxplot shows, in particular, the median, 25th and 75th percentiles.
258
parameters (1, 3, 0.0), (1, 3, 0.1), ..., (1, 3, 0.9). Recall
that
LPPM(µx, µy, λh) denotes the location-privacy preserving
mechanism with parameters µx and µy as the number
of dropped low-order bits from the x and y coordinates,
respectively, and with parameter λh as the probability of
hiding a region. Each box-and-whisker diagram (boxplot)
shows the system level
location-privacy of users for a
speciﬁc set of LPPM parameters against a speciﬁc attack.
The bottom and top of a box show the 25th and 75th
percentiles, and the central mark shows the median value.
The ends of the whiskers represent the most extreme data
points not considered as outliers, and the outliers are plotted
individually.
By system-level location-privacy, we collectively refer to
the privacy values (expected error - incorrectness) achieved
for all possible combinations of attack parameters ((u, t)
for LO-ATT, (u, v) for MD-ATT, (r, t) for AP-ATT). The
system-level location-privacy is represented by the median
privacy value, shown in the boxplot as the central mark
in the box. We also plot the 25th and 75th percentiles
of the privacy value in order to show the diversity of
adversary’s expected error. As an example, the ﬁrst boxplot
in Figure 4(a).ii, which is associated with 0.0 in the x-axis,
shows LPLO-ATT (u, t) for all u and t, using LPPM(1, 3, 0.0).
We expect to see improvement in location privacy, as we
increase the level of obfuscation. We also expect to observe
convergence of location privacy to its near maximum value,
when we set the location-hiding level equal to 0.9 (i.e.,
90% of the users’ locations are hidden from the adversary).
Unsurprisingly, we observe these two things in the plots:
Reading a plot from left to right we see the effect of increas-
ing the hiding level λh (0.0 to 0.9) for constant precision-
reducing levels µx and µy. Namely, the privacy always
increases, although the effect is much more pronounced in
LO-ATT(ﬁrst row). By comparing corresponding boxes of
two adjacent plots, i.e., same hiding levels, we see the added
value of the precision-reducing mechanism (on the left, µx
and µy are both 0; on the right, µx is 1 and µy is 3). Again,
the clearest improvement happens in LO-ATT.
An interesting conclusion is that the effect of the LPPM
is most positive against LO-ATT, which is, in a sense, the
most intrusive attack of the three: it targets the exact location
of a single user at a single time. The other two attacks,
especially AP-ATT, are more related to statistics of the user
mobility, so there could even be legitimate reasons that
one would want to collect that information. For instance, a
researcher who studies the geographical distribution of users
would be interested in the number of users in a region. We
can conclude that the tested LPPMs protect users’ location-
privacy against malicious adversaries, but they still provide
information for less harmful activities.
Now, we assess the appropriateness of
two metrics,
namely k-anonymity and entropy, for quantifying location
privacy. Note that any other heuristic metric can be evaluated
)
H
N
(
y
p
o
r
t
n
E
d
e
z
i
l
a
m
r
o
N
−
y
c
a
v
i
r
P
n
o
i
t
a
c
o
L
)
K
N
(
y
t
i
m
y
n
o
n
a
−
K
d
e
z
i
l
a
m
r
o
N
−
y
c
a
v
i
r
P
n
o
i
t
a
c
o
L
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0
0.2
0.4
0.6
0.8
1
Location Privacy − INcorrectness of the adversary (LP)
(a) Entropy vs. Incorrectness
0.2
0.4
0.6
0.8
1
Location Privacy − INcorrectness of the adversary (LP)