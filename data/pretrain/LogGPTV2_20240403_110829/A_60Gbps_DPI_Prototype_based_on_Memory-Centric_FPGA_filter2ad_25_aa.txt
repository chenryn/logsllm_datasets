title:A 60Gbps DPI Prototype based on Memory-Centric FPGA
author:Jinshu Su and
Shuhui Chen and
Biao Han and
Chengcheng Xu and
Xin Wang
A 60Gbps DPI Prototype based on
Memory-Centric FPGA
Jinshu Su† ‡, Shuhui Chen†, Biao Han†, Chengcheng Xu†, Xin Wang†
†College of Computer, National University of Defense Technology, Changsha, 410073, China
‡National Key Laboratory of Parallel and Distributed Processing, Changsha, 410073, China
{sjs, shchen, nudtbill, xuchengcheng, wangxin}@nudt.edu.cn
ABSTRACT
Deep packet inspection (DPI) is widely used in content-
aware network applications to detect string features. It
is of vital importance to improve the DPI performance
due to the ever-increasing link speed.
In this demo,
we propose a novel DPI architecture with a hierarchy
memory structure and parallel matching engines based
on memory-centric FPGA. The implemented DPI pro-
totype is able to provide up to 60Gbps full-text string
matching throughput and fast rules update speed.
CCS Concepts
•Networks → Deep packet inspection; •Theory
of computation → Pattern matching;
Keywords
DPI; string matching; hierarchical memory
1.
INTRODUCTION
DPI is a hardware and software solution that moni-
tors a network’s data stream by looking deep into data
packets. It provides important security and translation
functions in many network applications, such as net-
work intrusion detection system (NIDS), anti-virus pro-
tection, Internet content ﬁltering, etc. Until recently,
most DPI systems are not able to keep up with mod-
ern, 40Gbps+ network speed.
String pattern matching (SPM) is one of the most
widely used DPI mechanisms, in which the payload byte
sequence is matched against a dictionary of strings. As
the SPM methodology has to inspect the payload char-
acters byte by byte, it is usually regarded as the bottle-
neck of DPI. Most SPM solutions employ the classical
Permission to make digital or hard copies of all or part of this work for personal
or classroom use is granted without fee provided that copies are not made or
distributed for proﬁt or commercial advantage and that copies bear this notice
and the full citation on the ﬁrst page. Copyrights for components of this work
owned by others than ACM must be honored. Abstracting with credit is per-
mitted. To copy otherwise, or republish, to post on servers or to redistribute to
lists, requires prior speciﬁc permission and/or a fee. Request permissions from
permissions@acm.org.
SIGCOMM ’16, August 22-26, 2016, Florianopolis , Brazil
c(cid:13) 2016 ACM. ISBN 978-1-4503-4193-6/16/08. . . $15.00
DOI: http://dx.doi.org/10.1145/2934872.2959079
Figure 1: The DPI system architecture
Aho-Corasick algorithm [5] to generate a time-eﬃcient
deterministic ﬁnite automaton (DFA) for fast process-
ing. However, the throughputs of existing DPI systems
are greatly limited by high memory access latency dur-
ing the SPM procedure [6].
In order to break through the above limitations, we
propose a novel DPI architecture with a hierarchy mem-
ory structure and parallel matching engines based on
memory-centric FPGA. Then, we implement a DPI pro-
totype which is able to provide up to 60Gbps full-text
string matching speed. We will demonstrate the high
performance of the prototype with various rule sets and
traﬃcs in a well-deployed network environment.
2. SYSTEM ARCHITECTURE
Fig.1 depicts the overview of our implemented DPI
system architecture. The core components of the memory-
centric FPGA in the DPI prototype are 48 parallel match-
ing engines combined with a two-level hierarchy mem-
ory architecture. An auxiliary multi-core processor is
employed to compile the string dictionary to a DFA,
which is deployed to memory through PCIe.
Firstly, based on the observation that very few states
are frequently accessed during the matching process, we
combine the on-chip RAM banks with oﬀ-chip DRAM
to build a two-level hierarchy memory architecture, where
the large DRAM is used to store the whole state tran-
sition table (STT) of DFA and the fast on-chip RAM is
employed to store the frequently accessed parts of the
STT. Thus, an optimized storage mechanism for DFA
is able to store only a tiny part of the STT on FPGA
while guaranteeing a relatively low cache miss rate. In
627