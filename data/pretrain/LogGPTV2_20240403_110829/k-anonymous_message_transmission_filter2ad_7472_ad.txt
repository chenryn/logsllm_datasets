### 5.3 Optimizations and Concerns

#### 5.3.1 Minimizing Turnover
If a significant number of honest parties leave the network (even temporarily), the k-anonymity property may be violated. To minimize this risk, one approach is to impose a high computational cost for rejoining a group. Protocols such as Dwork and Naor's moderately hard functions [8] or Back's Hashcash [1] can be used to achieve this.

#### 5.3.2 Rate Adjustment
A major challenge in implementing fully anonymous protocols like DC-Nets is the need to fully synchronize a large number of hosts. In the proposed protocol, however, there is no such requirement, as groups can operate asynchronously. This allows each group to optimize its time between rounds to approximate the average sending rate of the group. This can be achieved automatically by using the outcome of the protocol, which provides a good estimate of the number of parties transmitting each round. If no parties transmit, the intra-round gap can be increased additively. Conversely, if many parties transmit, the intra-round gap can be decreased multiplicatively, similar to other fair communication protocols.

### 6. Conclusions
We have introduced the concept of k-anonymous message transmission, drawing an analogy to the k-anonymity concept from privacy literature. Using this notion, we have developed simple and efficient protocols for anonymous message transmission that are provably secure against a strong adversary. We believe that further research could explore whether other multiparty computation tasks can be simplified using a similar approach, i.e., by weakening security goals in a manner that is still sufficient for many applications. Additionally, an important future step is to implement our protocol to determine the actual overhead and achievable throughput.

### Acknowledgements
This work was partially supported by the National Science Foundation under Grants CCR-0122581 and CCR-0058982 (The Aladdin Center). It was also partially supported by the Army Research Office (ARO) and the Center for Computer and Communications Security (C3S) at Carnegie Mellon University. Nicholas Hopper was partially supported by a NSF graduate research fellowship. The authors would like to thank Manuel Blum, Bartosz Przydatek, Mike Reiter, Latanya Sweeney, and the anonymous CCS reviewers for their helpful discussions and comments.

### 7. References
[1] Adam Back. Hashcash. Unpublished manuscript, May 1997. Available electronically at http://www.cypherspace.org/hashcash/.

[2] Mihir Bellare and Phil Rogaway. Random Oracles are Practical. Computer and Communications Security: Proceedings of ACM CCS'93, pages 62-73, 1993.

[3] Ted Bridis. Verizon Loses Suit Over Music Downloading. Associated Press, April 24, 2003.

[4] David Chaum. The Dining Cryptographers Problem: Unconditional Sender and Recipient Untraceability. Journal of Cryptology 1(1), pages 65-75, 1988.

[5] David Chaum. Untraceable Electronic Mail, Return Addresses, and Digital Pseudonyms. Communications of the ACM 24(2), pages 84-88, 1981.

[6] David Chaum, Jan-Hendrik Evertse, Jeroen van de Graaf, and René Peralta. Demonstrating Possession of a Discrete Logarithm Without Revealing It. Advances in Cryptology: CRYPTO'86, pages 200-212, 1987.

[7] Danny Dolev, Cynthia Dwork, Orli Waarts, and Moti Yung. Perfectly Secure Message Transmission. Journal of the ACM 40(1), pages 17-47, 1993.

[8] Cynthia Dwork and Moni Naor. Pricing via Processing, or: Combating Junk Mail. Advances in Cryptology: CRYPTO'92, pages 139-147, 1993.

[9] The GNUnet website. http://www.ovmj.org/GNUnet/.

[10] Oded Goldreich, Amit Sahai, and Salil Vadhan. Honest Verifier Statistical Zero-Knowledge Equals General Statistical Zero-Knowledge. Proceedings of 30th Annual ACM Symposium on Theory of Computing (STOC'98), pages 399-408, May 1998.

[11] Shafi Goldwasser, Silvio Micali, and Charles Rackoff. The Knowledge Complexity of Interactive Proof-Systems (Extended Abstract). Proceedings of 17th Annual ACM Symposium on Theory of Computing (STOC'85), pages 291-304, 1985.

[12] David Mazieres and M. Frans Kaashoek. The Design, Implementation, and Operation of an Email Pseudonym Server. Computer and Communications Security: Proceedings of ACM CCS'98, pages 27-36, 1998.

[13] Torben P. Pedersen. Non-Interactive and Information Theoretic Secure Verifiable Secret Sharing. Advances in Cryptology: CRYPTO'91, pages 129-140, 1991.

[14] Andreas Pfitzmann and Michael Waidner. Networks Without User Observability – design options. Advances in Cryptology: EUROCRYPT'85, pages 245-253, 1985.

[15] Michael K. Reiter. A secure group membership protocol. IEEE Transactions on Software Engineering 22(1), pages 31-42, 1996.

[16] Michael K. Reiter and Aviel D. Rubin. Crowds: Anonymity for Web Transactions. ACM Transactions on Information and System Security 1/1, pages 66-92, 1998.

[17] Emin Gün Sirer, Milo Polte, and Mark Robson. CliqueNet: A Self-Organizing, Scalable, Peer-to-Peer Anonymous Communication Substrate. Unpublished manuscript, December 2001. Available electronically at http://www.cs.cornell.edu/People/egs/papers/cliquenet-iptp.pdf.

[18] Latanya Sweeney. k-Anonymity: a Model for Protecting Privacy. International Journal on Uncertainty, Fuzziness and Knowledge-based Systems 10(5), pages 557-570, 2002.

[19] Michael Waidner. Unconditional sender and recipient untraceability in spite of active attacks. Advances in Cryptology: EUROCRYPT'89, pages 302-319, 1989.

[20] M. Wright, M. Adler, B. Levine, and C. Shields. An analysis of the degradation of anonymous protocols. Proceedings of ISOC Symposium on Network and Distributed System Security, 2002.

### Appendix
#### A. Protocol 2 Does Not Need Reliable Broadcast
One technical point not addressed in our presentation is whether an adversary can disrupt the protocol by sending different messages to different parties in place of broadcasts. Intuitively, the commitments used in the multiparty sum protocol (Protocol 2) prevent this situation as long as all parties participate. However, since we are not aware of a published proof, we outline one here. The proof shows that no single adversarial party can cause two honest parties to compute different outputs, and any set of k adversarially controlled parties can be simulated by a single party.

**Lemma 1.** For any n, if discrete logarithms in \(\mathbb{Z}_p\) are hard, no single party can cause two honest parties to compute different outputs in Protocol 2.

*Proof.* There are only two opportunities for the adversary (without loss of generality, \(P_1\)) to cheat via the lack of reliable broadcast: he may send (at least) two different commitment vectors \(\{C_{1,j} : j \in [n]\}\) in step 1, or he may send two different sum values \((R_1, S_1)\) in step 3. If any attempt at step 1 is caught, the adversary is constrained by the commitment protocol in step 3. Thus, it remains to prove that any attempt to send two distinct commitment vectors \(\{C^*_{1,j}, C^\dagger_{1,j}\}\) is subsequently caught. Notice that there must be some \(j\) such that \(C^*_{1,j} \neq C^\dagger_{1,j}\). Without loss of generality, suppose \(j = 2\). At least one party must receive \(C^*_{1,2}\) and at least one must receive \(C^\dagger_{1,2}\). Suppose these parties are \(P_2\) and \(P_3\), respectively. If \(P_1\) incorrectly opens \(C^*_{1,2}\) to \(P_2\), this is caught by \(P_2\) in step 2. Otherwise, if \(P_1\) correctly opens \(C^*_{1,2}\) to \(P_2\), when \(P_3\) receives the value \((R_2, S_2) = (r^*_{1,2} + \sum_{j \geq 2} s_{j,2}, S_2)\) from \(P_2\) and checks if \(g^{S_2} h^{R_2} = C^*_{1,2} \prod_{j \geq 2} C_{j,2}\), this check will fail since \(C^*_{1,2} \neq C^\dagger_{1,2}\).

**Lemma 2.** Any group of k (out of n) adversaries who cause two honest parties to compute different outputs in Protocol 2 with significant probability can be simulated by a single adversarial party (out of \(n - k + 1\)) with the same success probability.

*Proof.* Without loss of generality, denote the k adversarially controlled parties by \(P_{n-k+1}, \ldots, P_n\), and let \(\ell = n - k\). We will show how a single adversarial party \(Q\) can simulate the interaction between the honest parties \(P_1, \ldots, P_\ell\) and the adversarial parties. Assume the parties \(P_{\ell+1}, \ldots, P_n\) are delaying adversaries, waiting until every honest party has spoken in each round. \(Q\) can simulate the honest parties to \(P_{\ell+1}, \ldots, P_n\) as follows:

1. **Commitment Phase:** When \(P_i\) sends \(Q\) the commitment \(C_{i,\ell+1}\), \(Q\) computes a random sharing of this commitment:
   - \(Q\) chooses k random shares \(s^{(2)}_{i,\ell+j}\).
   - \(Q\) chooses k random values \(r^{(2)}_{i,\ell+j}\).
   - \(Q\) computes \(C^{(2)}_{i,\ell+1} = C_{i,\ell+1} h^{s^{(2)}_{i,\ell+1}} g^{r^{(2)}_{i,\ell+1}}\) and \(C^{(2)}_{i,\ell+j} = g^{s^{(2)}_{i,\ell+j}} h^{r^{(2)}_{i,\ell+j}}\) for \(2 \leq j \leq k\).
   - \(Q\) sends \(\{C_{i,j} : j \leq \ell\}, \{C^{(2)}_{i,\ell+1}, \ldots, C^{(2)}_{i,n}\}\) to each adversarially controlled party.

2. **Sharing Phase:** When \(P_i\) sends \(Q\) the values \(r_{i,\ell+1}, s_{i,\ell+1}\), \(Q\) sends \((r_{i,\ell+1} + r^{(2)}_{i,\ell+1}, s_{i,\ell+1} + s^{(2)}_{i,\ell+1})\) to \(P_{\ell+1}\) and \((r^{(2)}_{i,\ell+j}, s^{(2)}_{i,\ell+j})\) to \(P_{\ell+j}\) for \(2 \leq j \leq k\).

3. **Broadcast Phase:** When \(P_i\) sends \((R_i, S_i)\) to \(Q\), \(Q\) sends \((R_i, S_i)\) to each \(P_{\ell+j}\).

Notice that by following this procedure, \(Q\) perfectly simulates the honest parties to the adversarial parties. In the opposite direction, \(Q\) emulates \(P_{\ell+1}, \ldots, P_n\) to the honest parties as follows:

1. **Commitment Phase:** If each \(P_{\ell+i}\) sends the commitment vector \(\{C_j\}\) to \(P_j\), then \(Q\) sends the commitment vector \(\{\prod_i C_{\ell+i,l}\}\) to \(P_j\).

2. **Sharing Phase:** If each \(P_{\ell+i}\) sends the value \((r_{\ell+i,j}, s_{\ell+i,j})\) to \(P_j\), then \(Q\) sends the value \((\sum_i r_{\ell+i,j}, \sum_i s_{\ell+i,j})\) to \(P_j\).

3. **Broadcast Phase:** If each \(P_{\ell+i}\) sends the value \((R_j, S_j)\) to \(P_j\), then \(Q\) sends \((\sum_i R_j, \sum_i S_j)\) to \(P_j\).

If the messages sent by \(P_{\ell+1}, \ldots, P_n\) all pass all of the checks in Protocol 2, then so do the messages sent by \(Q\). Thus, \(Q\) forces an inconsistent outcome with the same probability as \(P_{\ell+1}, \ldots, P_n\), as claimed.

**Theorem 6.** If discrete logarithms in \(\mathbb{Z}_p\) are hard, no adversary can cause two honest parties to compute different outputs in Protocol 2.

*Proof.* The theorem follows by the conjunction of Lemma 1 and Lemma 2: since any k adversarial parties can force an inconsistent outcome with the same probability as some individual party, and no individual party can force an inconsistent outcome if discrete logarithms in \(\mathbb{Z}_p\) are hard, no adversary (controlling any number of parties) can force an inconsistent outcome.