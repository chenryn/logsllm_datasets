of H(S||Pi); thus any party, given the list of participants,
can determine the group of any other party, and the other
participants in his own group.
5.3 Optimizations and Concerns
5.3.1 Minimizing Turnover
If a signiﬁcant number of honest parties leave the net-
work (even temporarily) then the k-anonymity property may
sometimes be violated. A possible approach to minimize
this risk is by charging a high computational cost to rejoin
a group, using a protocol such as Dwork and Naor’s moder-
ately hard functions [8] or Back’s Hashcash [1].
5.3.2 Rate Adjustment
Notice that a signiﬁcant barrier to the implementation of
a fully anonymous protocol such as DC-Nets is the need
to fully synchronize n hosts when n is large.
In the pro-
tocol proposed here, there is no such requirement — the
groups may operate asynchronously of one another. Be-
cause of that, each individual group may optimize its time
between rounds to approximate the average sending rate of
the group. This can be accomplished automatically using
the fact that the outcome of the protocol gives a good esti-
mate of the number of parties transmitting each round; so if
no parties transmit, an additive increase in the intra-round
gap may be used, and if many parties transmit, a multiplica-
tive decrease may be used, as in other fair communications
protocols.
6. CONCLUSIONS
We have introduced the notion of k-anonymous message
transmission by analogy to the concept of k-anonymity from
the privacy literature. Using this notion we are able to give
simple and eﬃcient protocols for anonymous message trans-
mission which have provable security against a very strong
adversary. We believe an interesting avenue for further re-
search is to investigate whether other multiparty computa-
tion tasks can also be simpliﬁed using a similar approach,
i.e. by weakening the security goals in a manner which is
still suﬃcient for many applications. We also believe an im-
portant future step is the implementation of our protocol in
order to determine the actual overhead introduced and the
achievable throughput.
Acknowledgements
This material is based upon work partially supported by the
National Science Foundation under Grants CCR-0122581
and CCR-0058982 (The Aladdin Center). This work was
also partially supported by the Army Research Oﬃce (ARO)
and the Center for Computer and Communications Security
(C3S) at Carnegie Mellon University. Nicholas Hopper was
also partially supported by a NSF graduate research fellow-
ship. The authors wish to thank Manuel Blum, Bartosz
Przydatek, Mike Reiter, Latanya Sweeney, and the anony-
mous CCS reviewers for helpful discussions and comments.
7. REFERENCES
[1] Adam Back. Hashcash. Unpublished manuscript, May
1997. Available electronically at
http://www.cypherspace.org/hashcash/.
[2] Mihir Bellare and Phil Rogaway. Random Oracles are
Practical. Computer and Communications Security:
Proceedings of ACM CCS’93, pages 62-73, 1993.
[3] Ted Bridis. Verizon Loses Suit Over Music
Downloading. Associated Press, April 24, 2003.
[4] David Chaum. The Dining Cryptographers Problem:
Unconditional Sender and Recipient Untraceability.
Journal of Cryptology 1(1), pages 65-75, 1988.
[5] David Chaum. Untraceable Electronic Mail, Return
Addresses, and Digital Pseudonyms. Communications
of the ACM 24(2), pages 84-88, 1981.
[6] David Chaum, Jan-Hendrik Evertse, Jeroen van de
Graaf and Ren´e Peralta. Demonstrating Possession of a
Discrete Logarithm Without Revealing It. Advances in
Cryptology: CRYPTO’86, pages 200-212, 1987.
[7] Danny Dolev, Cynthia Dwork, Orli Waarts and Moti
Yung. Perfectly Secure Message Transmission. Journal
of the ACM 40(1), pages 17-47, 1993.
[8] Cynthia Dwork and Moni Naor. Pricing via Processing,
or: Combating Junk Mail. Advances in Cryptology:
CRYPTO’92, pages 139-147, 1993.
[9] The GNUnet website. http://www.ovmj.org/GNUnet/.
[10] Oded Goldreich, Amit Sahai, and Salil Vadhan.
Honest Veriﬁer Statistical Zero-Knowledge Equals
General Statistical Zero-Knowledge. Proceedings of 30th
Annual ACM Symposium on Theory of Computing
(STOC’98), pages 399-408, May 1998.
[11] Shaﬁ Goldwasser, Silvio Micali, Charles Rackoﬀ. The
Knowledge Complexity of Interactive Proof-Systems
(Extended Abstract). Proceedings of 17th Annual ACM
Symposium on Theory of Computing (STOC’85), pages
291-304, 1985.
[12] David Mazieres and M. Frans Kaashoek. The Design,
Implementation, and Operation of an Email
Pseudonym Server. Computer and Communications
Security: Proceedings of ACM CCS’98, pages 27-36,
1998.
[13] Torben P. Pedersen. Non-Interactive and Information
Theoretic Secure Veriﬁable Secret Sharing. Advances in
Cryptology: CRYPTO’91, pages 129-140, 1991.
[14] Andreas Pﬁtzmann and Michael Waidner. Networks
Without User Observability – design options. Advances
in Cryptology: EUROCRYPT’85, pages 245-253, 1985.
[15] Michael K. Reiter. A secure group membership
protocol. IEEE Transactions on Software Engineering
22(1), pages 31-42, 1996.
[16] Michael K. Reiter and Aviel D. Rubin. Crowds:
Anonymity for Web Transactions. ACM Transactions
on Information and System Security 1/1, pages 66-92,
1998.
[17] Emin G¨un Sirer, Milo Polte, and Mark Robson.
CliqueNet: A Self-Organizing, Scalable, Peer-to-Peer
Anonymous Communication Substrate. Unpublished
manuscript, December 2001. Available electronically at
http://www.cs.cornell.edu/People/egs/papers/
cliquenet-iptp.pdf.
[18] Latanya Sweeney. k-Anonymity: a Model for
Protecting Privacy. International Journal on
Uncertainty, Fuzziness and Knowledge-based Systems
10(5), pages 557-570, 2002.
[19] Michael Waidner. Unconditional sender and recipient
untraceability in spite of active attacks. Advances in
Cryptology: EUROCRYPT’89, pages 302-319, 1989.
[20] M. Wright, M. Adler, B. Levine, and C. Shields. An
analysis of the degradation of anonymous protocols.
Proceedings of ISOC Symposium on Network and
Distributed System Security, 2002.
APPENDIX
A. PROTOCOL 2 DOES NOT NEED RELI-
ABLE BROADCAST
One technical point is not addressed in our presentation:
since we avoid the use of reliable broadcast, is it possible
for an adversary to disrupt the protocol by sending diﬀerent
messages to diﬀerent parties in place of broadcasts? It is in-
tuitively clear that the commitments used in the multiparty
sum protocol (Protocol 2 ) prevent this situation as long as
all parties participate; but since we are not aware of a pub-
lished proof to this eﬀect, we outline one here. The idea
of the proof is conceptually simple: ﬁrst we show that no
single adversarial party may force an inconsistent outcome,
and then we show that any set of k adversarially controlled
parties can be successfully simulated by a single party. The
result follows.
∗
Lemma 1. For any n, if discrete logarithms in (cid:1)
p are
hard, no single party may cause two honest parties to com-
pute diﬀerent outputs in Protocol 2 .
†
1,j
1,j},{C
∗
1,j (cid:4)= C
∗
Proof. There are only two opportunities for the adver-
sary (without loss of generality, P1) to cheat via the lack
of reliable broadcast: he may send (at least) two diﬀerent
commitment vectors {C1,j : j ∈ [n]} in step 1, or he may
send two diﬀerent sum values (R1, S1) in step 3. Note ﬁrst,
that if any attempt at step 1 will be caught, then the ad-
versary is constrained by the commitment protocol in step
3. Thus it remains to prove that any attempt to send two
} is subsequently
distinct commitment vectors {C
caught. To see that this is true, notice that there must be
†
some j, such that C
1,j. Without loss of generality,
suppose j = 2. Furthermore, at least one party must receive
C
, without loss of gen-
erality, suppose these parties are P2 and P3, respectively.
∗
1,2 to P2; obvi-
Now, suppose that P1 incorrectly opens C
ously this is caught by P2 in step 2. Otherwise, suppose P1
∗
1,2 to P2; then when P3 receives the value
correctly opens C
∗
1,2 + j≥2 sj,2) from P2, and
(R2, S2) = (r
†
checks if gS2hR2 = C
1,2 	j≥2 Cj,2, this check will fail since
1,2 (cid:4)= C
∗
C
Lemma 2. Any group of k (out of n) adversaries who
cause two honest parties to compute diﬀerent outputs in Pro-
†
1,2, by assumption.
∗
1,2 + j≥2 rj,2, s
, and at least one must receive C
∗
†
tocol 2 with signiﬁcant probability may be simulated by a sin-
gle adversarial party (out of n− k + 1) with the same success
probability.
Proof. Without loss of generality, denote the k adver-
sarially controlled parties of the hypothesis by Pn−k+1, . . . ,
Pn, and let (cid:1) = n− k. We will show how a single adversarial
party Q may simulate the interaction between the honest
parties P1, . . . , P(cid:7) and the adversarial parties. First, with-
out loss of generality, assume the parties P(cid:7)+1, . . . , Pn to
be delaying adversaries: that is, all adversarially controlled
parties wait until every honest party has spoken in each
round. (If they do not wait, they can be rewritten to do
so without decreasing their success probability) Then Q can
simulate the honest parties to P(cid:7), . . . , Pn as follows:
1. Commitment Phase: When Pi sends Q the com-
mitment Ci,(cid:7)+1, Q computes a random sharing of this
commitment:
• Q chooses k random shares s
• Q chooses k random values r
(cid:2)
i,(cid:7)+j
• Q computes C
(cid:1)
(cid:2)
i,1 gr
i,(cid:7)+1 = Ci,(cid:7)+1hs
i,(cid:1)+j for 2 ≤ j ≤ k.
• Q sends {Ci,j : j ≤ (cid:1)},{C
(cid:2)
i,(cid:7)+1, . . . , s
∈ (cid:1)q.
(cid:1)
i,(cid:1)+1 , and C
i,j : (cid:1) < j ≤ n} to each
(cid:2)
(cid:1)
= gs
i,(cid:1)+j hr
(cid:2)
i,n subject
(cid:2)
i,(cid:7)+j = 0.
to j s
(cid:2)
i,(cid:7)+j
(cid:1)
adversarially controlled party.
2. Sharing Phase: when Pi sends Q the values ri,(cid:7)+1,
(cid:2)
(cid:2)
i,(cid:7)+1, si,(cid:7)+1 + s
i,(cid:7)+1) to P(cid:7)+1,
i,(cid:7)+j) to P(cid:7)+j, for 2 ≤ j ≤ k.
(cid:2)
si,(cid:7)+1, Q sends (ri,(cid:7)+1 + r
and (r
(cid:2)
i,(cid:7)+j, s
3. Broadcast Phase: When Pi sends (Ri, Si) to Q, Q
sends (Ri, Si) to each P(cid:7)+j.
Notice that by following this procedure, Q perfectly sim-
ulates the honest parties to the adversarial parties. In the
opposite direction, Q emulates P(cid:7)+1, . . . , Pn to the honest
parties as follows:
1. Commitment Phase: If each P(cid:7)+i sends the commit-
} to Pj , then Q sends the commit-
ment vector {C j
ment vector {	i C j
(cid:7)+i,l
} to Pj.
(cid:7)+i,l
2. Sharing Phase: If each P(cid:7)+i sends the value (r(cid:7)+i,j,
s(cid:7)+i,j) to Pj, then Q sends the value (i r(cid:7)+i,j, i s(cid:7)i,j)
to Pj .
3. Broadcast Phase: If each P(cid:7)+i sends the value (Rj
i , Sj
i )
to Pj , then Q sends (i Rj
i , i Sj
i ) to Pj .
If the messages sent by P(cid:7)+1, . . . , Pn all pass all of the checks
in Protocol 2, then so do the messages sent by Q. Thus Q
forces an inconsistent outcome with the same probability as
P(cid:7)+1, . . . , Pn, as claimed.
∗
Theorem 6. If discrete logarithms in (cid:1)
p are hard, no
adversary may cause two honest parties to compute diﬀerent
outputs in Protocol 2 .
Proof. The theorem follows by the conjunction of lemma
1 and lemma 2: since any k adversarial parties can force an
inconsistent outcome with the same probability as some in-
dividual party, and no individual party may force an incon-
∗
p are hard, then
sistent outcome if discrete logarithms in (cid:1)
∗
p are hard, no adversary (con-
if discrete logarithms in (cid:1)
trolling any number of parties) may force an inconsistent
outcome.