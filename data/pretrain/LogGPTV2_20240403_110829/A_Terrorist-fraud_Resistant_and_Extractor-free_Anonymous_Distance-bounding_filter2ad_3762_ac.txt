the veriﬁer aborts. Otherwise, he returns a random
n-bit string m.
803Veriﬁer V
N V $← {0, 1}n
Pick ci ∈ {0, 1}
Start clock
Stop clock
Prover P
N P
shared secret key: x
←−−−−−−−−−−−−−−−− N P $← {0, 1}n
−−−−−−−−−−−−−−−−→
α = P RFx(N P, N V )
N V
for i = 0 to n
ci
−−−−−−−−−−−−−−−−→
←−−−−−−−−−−−−−−−−
ri
ri =
(cid:26)
αi
αi ⊕ xi
if ci = 0
if ci = 1
Figure 1: The classical countermeasure against terrorist fraud: if the prover gives both possible responses,
such as for instance αi and αi⊕xi to his accomplice for a given ci, he leaks one bit of his long-term authentication
secret x. Note that PRF is a pseudorandom function keyed with x.
Veriﬁer V
dk: decryption key
vk: veriﬁcation key
Initialisation
Prover P
ek: encryption key
sk: signature key
idpub(P ): public identity of P
idprv(P ): private identity of P
α||β $← {0, 1}2·n, σp = S.sigsk(α||β||idprv(P ))
(α||β||idprv(P )||σp) = E.decdk(e)
if S.vervk(σp, α||β||idprv(P )) = 0 then abort
m $← {0, 1}n
Pick ci ∈ {0, 1}
Start clock
Stop clock
←−−−−−−−−−−−−−−−− e = E.encek(α||β||idprv(P )||σp)
e||idpub(P )
m
−−−−−−−−−−−−−−−−→
Distance Bounding
for i = 0 to n
ci
−−−−−−−−−−−−−−−−→
←−−−−−−−−−−−−−−−−
ri
(cid:26)
ri =
αi
βi ⊕ mi
if ci = 0
if ci = 1
store ∆ti
If #{i : ri and ∆ti correct} = n then
OutV := 1; else OutV := 0
Veriﬁcation
−−−−−−−−−−−−−−−−→
OutV
Figure 2: Our generic and provably secure DB construction TREAD built from an IND-CCA2-secure encryption
scheme E and an EUF-CMA-secure signature scheme S. The symbol || denotes the concatenation operation.
Afterwards, during the n time-critical rounds, he gen-
erates random bits ci with a uniform distribution, starts
his clock, sends ci, gets back ri, stops his clock and
stores the corresponding elapsed time ∆ti. Finally, he
veriﬁes that (1) ∆ti ≤ tmax and (2) ri = (αi ∧ ¬ci) ∨
((βi⊕ mi)∧ ci), for all i ≤ n. If this holds, he sends an
accepting bit OutV = 1, otherwise he sends OutV = 0.
DB.join(ID, UL) is the algorithm to register a new prover
with identiﬁer ID in the list UL. It returns the keys
(ek, dk) for E and (sk, vk) for S. Depending on the
primitives E and S, dk and vk may be public or private,
and can sometimes be equal respectively to ek and sk.
DB.revoke(ID, UL, RL) is the algorithm to revoke a prover
with identiﬁer ID and move him to the revoke list RL.
These last two algorithms depend on the instance of the
protocol and are described in the following section. TREAD
adopts the sign-then-encrypt paradigm instead of the more
usual encrypt-then-sign. If the latter were used, an eaves-
dropper would be able to infer the identity of any prover, by
verifying the signature on the message e with all the public
keys listed in UL. The security is nonetheless preserved, at
the cost of using an IND-CCA2 secure encryption scheme.
2.2 Instantiations
Three instances of our construction are presented here.
Eﬃcient symmetric-key scheme. Computational eﬃ-
ciency is critical for the design of DB protocols as they are
usually run in resource-limited devices.
Our most eﬃcient construction is based on an IND-CCA2
symmetric-key encryption scheme SKE and an EUF-CMA
message authentication code scheme MAC. The public iden-
tity idpub(P ) is the identity of the prover and the private
identity idprv(P ) is set to null. Since SKE and MAC are
symmetric, we have ek = dk and sk = vk. Thus, the prover
and the veriﬁer have the same symmetric key k = (ek, sk).
804In this construction, the veriﬁers have access to a private
list UL containing all the secret keys of legitimate provers.
An authority should add any prover in the private list UL
or in the revokation public list RL. It is also responsible to
distribute securely these lists to the legitimate veriﬁers.
Prover privacy and public-key encryption.
In appli-
cations such as contactless payment schemes, shared secret
keys should not be used. Thus, with the emergence of NFC-
enabled smartphones, public-key DB protocols are crucial.
TREAD can be instantiated with an IND-CCA2 public-key
encryption PKE and an EUF-CMA digital signature scheme
S-SIG, in which the public identity idpub(P ) is set to null,
and the private one idprv(P ) is the identity of P (or his
veriﬁcation key). The keys ek and dk are the public and the
private keys of the veriﬁer, and sk and vk are the (private)
signature and the (public) veriﬁcation keys of the prover.
With such a protocol, two sessions by the same user are
unlinkable for an external eavesdropper as the only informa-
tion sent about the prover’s identity is encrypted with the
veriﬁer’s public key. However, veriﬁers have the power to
link sessions. In this construction, the veriﬁers have access
to a public list UL containing the public keys of legitimate
provers. An authority is in charge of adding provers in the
public list UL or in the revokation public list RL.
Prover anonymity and group signature. Finally, TREAD
can provide full prover-anonymity with respect to a mali-
cious veriﬁer. As proﬁling users is now a common threat, it
is crucial to develop privacy-preserving DB protocols.
Both the prover anonymity and the revocability properties
can be achieved by instantiating TREAD with an IND-CCA2
public-key encryption scheme PKE and a revocable group
signature scheme G-SIG.
In this case, the public identity
idpub(P ) is set to null and the private identity idprv(P ) is
set to the identity of the group IDG. Many groups may
coexist but prover-anonymity with respect to the veriﬁer is
only guaranteed up to a prover’s group. The keys ek and
dk are the public and private keys of the veriﬁer, sk is the
prover’s signing key and vk is the group veriﬁcation key.
Group signature schemes allow a user to anonymously sign
on behalf of his group. Hence, the veriﬁer can check if the
prover belongs to the claimed group, but cannot identify him
precisely nor link his sessions. In this scenario, the join and
revoke algorithms take their full meaning. Let (gpk, msk) be
the group/master key pair of the scheme G-SIG. Then,
DB.joinmsk(ID, gpk, UL) returns a prover signing key skID for
PID. It also outputs a value regID and adds PID to UL.
DB.revokemsk(ID, gpk, RL, UL) computes the logs revID for PID,
using regID and msk, and moves PID from UL to RL.
3. MODELS AND SECURITY PROOFS
In this section, we describe the models for deﬁning DB
protocols and to characterize the classical threats against
these protocols. Then, we prove the main security properties
of the instantiations of our TREAD construction.
3.1 Formal Security Models
To the best of our knowledge three security models exist
for distance bounding: the original one by Avoine and co-
authors [2], a second one by D¨urholz, Fischlin, Kasper and
Onete [16] (DFKO) and a third one by Boureanu, Mitrokotsa
and Vaudenay [7]. In this paper, we use the DFKO model
and its strong TF-resistance notion (SimTF). The DFKO
model is also extended to address DH attacks [14]. Finally,
we use the privacy and anonymity models derived from the
work of Gambs, Onete and Robert [19], which are compati-
ble with the proposed extension of the DFKO model.
Distance-bounding protocols. DB protocols are interac-
tive protocols running between two participants. The objec-
tive of the prover P is to convince the veriﬁer V that he is
legitimate and located at a distance at most dmax from him.
The participants interact during rounds, deﬁned as se-
quences of messages. For some of these rounds, the veriﬁer
uses a clock to measure the time elapsed between the emis-
sion of a challenge ci and the reception of the response ri.
These back-and-forth rounds are referred to as time-critical
rounds. In most protocols, the DB phase of a protocol is
composed of either n independent time-critical rounds or
only one combined time-critical round. Non-critical phases
are simply called slow phases. After measuring the elapsed
time at the end of each time-critical round, the veriﬁer com-
pares this value to a threshold tmax associated with the max-
imal allowed distance dmax.
If one of these tests fails, the
prover will not be considered in the vicinity of the veriﬁer.
The veriﬁer is assumed to behave honestly during the au-
thentication of a prover. However, if it is possible, he may
try to lift the anonymity of a prover or to link sessions to a
given prover. Additionally, provers can potentially behave
maliciously and attempt to fool the veriﬁer, either by them-
selves or by using (voluntary or unwilling) accomplices.
Adversary model. In the DFKO model, an adversary can
interact with provers and veriﬁers in three kinds of sessions.
Each session is associated with a unique identiﬁer sid.
• Prover-veriﬁer sessions to observe an honest execution
of the protocol between a prover and a veriﬁer.
• Prover-adversary sessions to interact with a honest
prover as a veriﬁer.
• Adversary-veriﬁer sessions to interact with a legiti-
mate veriﬁer as a prover.
The adversaries are deﬁned in terms of their computa-
tional resources (i.e., time) t, the number of prover-veriﬁer
sessions qobs they may observe, the number qv of adversary-
veriﬁer sessions and the number qp of prover-adversary ses-
sions they initiate, and their winning advantage for the cor-
responding security games.
To capture the notion of relays, the DFKO framework uses
an abstract clock keeping track of the sequence of the adver-
sary’s actions. It is given as a function marker : N × N → N,
such that marker(·,·) is strictly increasing. It can be used
to deﬁne tainted time-critical rounds. This notion is used
to rule out some illegitimate actions of attackers, due for in-
stance to the veriﬁer’s ability to detect pure relays through
his accurate clock. More precisely, an adversary cannot win
a game in a tainted session.
In the following deﬁnitions,
Πsid[i, . . . , j] denotes a sequence of messages (mi, . . . , mj)
exchanged during the session sid of the protocol.
Following the terminology introduced by Vaudenay [24]
and later re-used to deﬁne prover-anonymity [20], if an ad-
versary is assumed to know the ﬁnal result of an authenti-
cation session (i.e., accept or reject), he is said to be wide
while otherwise he is narrow. Orthogonally, if the adversary
805may never corrupt provers, he is considered to be weak while
if a corruption query is only followed by other such queries,
the adversary is forward. Finally, if there is no restriction
on the corruption queries, the adversary is said to be strong.
In this paper, we consider the strongest adversary model
possible, namely wide-strong adversaries.
Security analysis. We give the proofs of the main prop-
erties of our constructions: (1) TF resistance, (2) MF re-
sistance, (3) DH resistance (implying DF resistance), (4)
prover privacy and ﬁnally (5) prover anonymity. In our con-
text, the last property is the strongest one as it protects the
privacy of the provers against the veriﬁers themselves. The
proofs of the TF resistance and prover anonymity properties
are among the main contributions of this paper.
The slow-phase impersonation threat is discarded in our
analysis [16]. This property refers exclusively to how much
impersonation resistance the slow phases of the protocol
adds to the impersonation protections provided in the time-
critical phases of the MF countermeasures. The notion of
slow-phase impersonation security was introduced especially
for resource-limited provers, which cannot handle a high
number of time-critical rounds. However, such a restriction
is no longer a problem for contactless devices, which have
become faster and more eﬃcient in their interactions. As a
consequence, we choose to rely only time-critical phases to
achieve impersonation resistance, rather than adding that
property in slow phases of our DB protocols.
Game structure. The threat models are represented as
security games involving an adversary A and a challenger
simulating the environment for him. All these game-based
proofs start with the challenger building the simulation envi-
ronment using DB.gen(1λ). For clarity, this step is omitted
in their descriptions. The adversary interacts with the sim-
ulated environment through oracles that he is allowed to
run concurrently. These include a prover oracle (for prover-
adversary sessions), a veriﬁer oracle (for adversary-veriﬁer
sessions) as well as a session oracle to simulate an honest
exchange between the prover and the veriﬁer.
Thus, the challenger may have to simulate these oracles:
Veriﬁer(·) runs the protocol DB.veriﬁer(ID, dk, vk, UL, RL).
Prover(·) runs the protocol DB.prover(ek, sk).
Session(·) returns the transcript of a new honest run of the
protocol DB.auth(R, n).
Joinc(·) simulates the arrival of a corrupted prover Ui by
running DB.join(i, UL) and returning the secret keys
of this prover.
Corrupt(·) simulates the corruption of a prover Ui by return-
ing his secret keys.
3.2 Terrorist-Fraud Resistance
D¨urholz, Fischlin, Kasper and Onete deﬁned the notion of
simulation-based TF-resistance SimTF [16]. In this model,
a far-away malicious prover P wants to use an accomplice
A close to the veriﬁer to authenticate.
If the prover P is
rational, A should not receive during the attack enough in-
formation allowing him to impersonate P later on in any
MF or IF attacks. This is formalized as a two-phase game.
During the ﬁrst phase, A tries to authenticate with the help
of P , in which pA denotes his success probability. During
the second phase, a simulator SimTF(e, IK) takes the inter-
nal view IK of A and a valid initial commitment e of P , and