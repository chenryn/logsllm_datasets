### More Ubiquitous, Users Are Becoming More Aware of the Value of Their Data

As data becomes more ubiquitous, users are becoming increasingly aware of its value. Generally, feelings that the risk was low and thus implementing new behaviors was unnecessary were more common in physical security than in digital security.

### It’s Not My Job

Eighteen participants rely on the companies whose software, hardware, or services they use to ensure their safety. These participants do not appear to be making explicit cost-benefit calculations about specific personal behaviors being redundant to the services provided by these companies. Instead, they assume that they are not responsible for the security of a given system because a trusted corporation is handling it. This motivation for rejecting security advice is unique to the digital-security domain. For example, Participant 8 (P8) commented, “I had been banking with a bank that I wasn’t happy with. Then I went to Bank of America, which was this big bank. I thought, ‘Oh, they’re awesome, so I don’t have to worry about anything. I will be safe.’”

### Relying on Prompts and Defaults

In addition to trusting corporations, participants also rely on browser and device prompts (N=20), software defaults (N=20), and security requirements imposed by their services (e.g., password length) (N=14) to keep them secure. For instance, many participants use a password or passcode to lock their phone because the phone prompted them to do so during setup. P2 noted, “When you boot up these phones now, they just give you the option.” Similarly, P4 stated she only has passwords or passcodes on her Mac products because, “the Mac products prompt you to set up the security things...I never thought about it [for the Kindle]. I guess it wasn’t prompted...I would have to look up how to do it on the Kindle.” Participants also rely on software defaults, such as those in antivirus software, to provide security measures. P17 mentioned, “I have a script and popup blocker because it was through McAfee and it was automatic. I’m not really tech-savvy where I can block stuff and go into my settings and know what I’m messing with.”

### Other Reasons for Rejecting Advice

Nine participants felt oversaturated and lacked the time to implement the advice they received, even if they thought it was good. P7 said, “Part of it is just saturation. You get so much information from so many sources. I don’t even know sometimes what’s worth looking at.” Additionally, P6 noted that he often does not take security advice because he has “kind of reached a level of don’t care. It’s so obvious to me that I don’t know what I don’t know, that it’s frustrating to try to tease apart what would be helpful and what wouldn’t.”

The advice may also be too advanced (N=7), too inconvenient (N=6), or participants may feel that no matter what, they will be hacked (N=11). Even highly educated participants may reject digital-security advice for being too advanced (N=4). P9, who holds a computer engineering degree, acknowledged, “I know that HTTPS and SSL exist, but I don’t even know what the acronyms mean. I know that some websites are more secure and others aren’t, and I don’t pay attention to it.” P8, who holds a master’s degree, also struggles with complex advice: “Depending on the number of steps and the complexity of it, I sometimes reject it because I’m not an IT person...it can be complex what they’re asking me to do.”

### Less Common but Interesting Reasoning

A few participants described less common but interesting reasons for rejecting advice. One participant (P3) noted that he rejects advice because he sees it in the wrong venue: “I see the information while on [public transit] to work and then by the end of the day, looking at a computer is the last thing I want to do.” We hypothesize that this factor may be important for many users, even though no other participants explicitly mentioned it. A few other participants reported rejecting what they perceived as good advice for others because they were already confident in their own behaviors (N=3). P25 stated, “I do what I do based on my own personal feelings and intellect, so I don’t find it useful, but for someone who didn’t know, it would be useful. I just have my own way of protecting what I do, so it’s like if someone’s telling you how to make a PB&J sandwich, and I’m like, I know how to do it. But if they’re saying something drastic—don’t do this, this, and this—then I’ll look at it, but usually, no.”

### Security-Sensitive vs. General Participants

We observed differences between participants’ behavior in the physical- and digital-security domains, as well as between security-sensitive and general participants. We recruited security-sensitive participants to investigate how extra training in handling confidential or sensitive data at work affects how participants process security advice in their personal lives. Below, we discuss some trends that differentiate security-sensitive from general participants; given our qualitative data and limited sample size, these findings mainly suggest directions for further exploration. The prevalence of these differences in our sample is summarized in Figure 5.

#### Two-Factor Authentication

Seven out of 15 security-sensitive participants in our study had adopted two-factor authentication (2FA), compared to eight out of 10 general participants. Four of these security-sensitive participants cited privacy concerns as a reason for not using 2FA. Thus, we hypothesize that security-sensitive users may be less trusting that the service requesting 2FA can protect their personal information. Participants’ motivations for accepting and rejecting two-factor authentication are discussed in more detail in Section IV-F. This potential difference between the privacy concerns of security-sensitive and general users should be confirmed with additional quantitative investigation, as discussed in Section V.

#### Advice Evaluation

Nine out of 15 security-sensitive participants cited the trustworthiness of the advice source as their key metric for choosing to take digital-security advice, compared to only two out of 10 general participants. We suspect that security-sensitive users may be more discerning about advice because they have been trained to critically evaluate the digital information they encounter. A primary component of workplace digital-security training is reminders not to trust unknown individuals [59], [60].

#### Workplace Digital-Security Advice

Thirteen out of 15 security-sensitive participants took advice from their workplace, contrasted with four out of 10 regular participants. This is perhaps unsurprising given the workplace emphasis on digital security and regular trainings for security-sensitive users.

#### Beliefs About the Utility of Digital Security Advice

Eight out of 15 security-sensitive participants in our sample believed that digital-security advice was more useful than physical security advice, compared to two out of 10 general participants. We speculate this may be related to these participants being more frequently reminded to pay attention to digital security and data sensitivity.

#### Feelings of Inevitability

General participants in our sample expressed more feelings of inevitability (‘no matter what, I will be hacked’) than did security-sensitive participants. Six out of 10 general participants expressed these feelings, contrasted with three out of 15 security-sensitive participants. We hypothesize that less formal training may contribute to general users feeling more powerless.

### Case Study: Two-Factor Authentication

As mentioned in Section II-B, Ion et al. report that the use of two-factor authentication (2FA) is one of the top three security behaviors recommended by or used by security experts. However, only 40% of the non-expert participants in that study reported using 2FA. Our results shed light on the reasoning behind users’ acceptance or rejection of this behavior.

#### How and Why I Use Two-Factor Authentication

More than half of the participants we interviewed reported using 2FA (N=14). In our interview questions about 2FA, we started by defining it as “a service where you might put in your phone number and then be sent a verification code.” Given this definition, all participants recognized 2FA and were able to substantively answer our interview questions on this topic. Of our 14 participants who had used 2FA, five used it for some, but not all, services for which it is offered. These participants use 2FA for services they feel are particularly important. P6 said, “I’ve got 2FA on one thing, and that is my insurance company. I did that because [of a negative experience at my workplace]. I figured that [my insurance] was one of the most important things, because...it covers every aspect in my life. I didn’t want anyone to mess with that.”

Alternatively, participants may only use 2FA on services that strongly encourage or force them to do so. P12 commented, “I do that with Xbox Live, they force me to do that. I think Google, they want me to do that, but I always say later.” Similarly, P14 stated, “Yes, at one time Verizon, because I have a Verizon email account, it asked me to do [2FA], it takes a while but I’ve done it...it forced me to do it.” Of the remaining nine participants who used 2FA, two did not understand what they were doing. P16 commented, “You mean when it asks to use by text or phone call? I do that, even though I hate doing it, because I’m trying to figure out what is the purpose, but it says the purpose is your safety and security.”

#### Why I Don’t Use Two-Factor Authentication

Eleven participants knew about but chose not to use 2FA. Five of these participants declined 2FA due to privacy concerns, specifically, worries about giving out their personal phone number, GPS tracking based on that phone number, and the service providing 2FA’s ability to keep their information secure. For example, P13 said, “No, [I want] nothing connected to the phone. So, the phone is directly connected to the email. I don’t feel comfortable to let people in if it’s connected to the email account.” Similarly, P3 said, “I think I do have that [2FA] capacity. I think I’ve always declined Gmail enabling that access...Based on what I know about Gmail, it just seemed like giving up too much information to Google.” Regarding the protection of the information used for verification, P23 said, “Google has prompted, but I’ve always ignored it because I think that someone will get ahold of it, I’m not saying they would, but I’m just always like, you know, yeah.”

In addition to privacy concerns, two participants declined to use 2FA due to convenience concerns. P9 said, “Two years ago, at the beginning of the summer, Google introduced 2FA, and this was an issue because I tried to log in and I didn’t get cell service and I couldn’t get the text message to log in, and that was the last time I tried to change anything.” And two participants declined the service due to not understanding the purpose of the tool.

### Design Guidelines

In the following section, we make several design suggestions and recommendations for future work. While our data supports these design suggestions, our results are qualitative and thus have limited generalizability. Future research is recommended to confirm the efficacy and necessity of these designs.

#### Develop Vignettes to Simulate Negative Experiences

As shown both in our results and in Rader et al.’s work, negative events experienced by users or their friends can be key motivators for security behavior change [3]. However, we prefer that users do not undergo these negative experiences. Moreover, even if the cost of a negative security event was worth the skills the user learned, there are few ways to artificially create these negative security experiences without stressing or harming users.

Our findings highlight a potential solution to this problem—mini-clips, training videos, or other media designed to artificially create a salient negative-security experience. We found evidence in our sample that mimicking negative events via a well-crafted fictional narrative with relatable characters can be very effective. We believe that this idea has merit, as stories can be “a very powerful way to represent and convey complex, multi-dimensional ideas,” and the efficacy of using fictional vignettes to improve behavior has been proven in the organizational development and health-behavior change fields [61], [62].

Our findings suggest three elements that may be important to the efficacy of such vignettes: creating relatable characters, demonstrating clear causes for negative security events, and ensuring that characters who fix security problems appear trustworthy. Findings from prior work in the entertainment-education field, primarily around health behavior change, can help inform the creation of relatable characters [63], [64]. However, further research, which will likely draw upon work in the communications, psychology, and education fields, is required to determine how to create relatable characters and trustworthy advisors. Many of our participants considered IT professionals and “tech-savvy” individuals among their friends and family to be trustworthy advice sources. Prior work on technology help-seeking suggests a number of attributes common to those who are asked or observed for technology advice [65], [66]. However, a deeper investigation is needed to determine what will lead users to trust a character portrayed in a vignette as an authoritative source of digital-security advice.

Further evaluation of what makes a piece of media trustworthy will be required to a) pursue this design and b) generally indicate trustworthiness for other security advice distributed via the media. This evaluation may include drawing upon measures of credibility developed in the mass communications and marketing fields [67], [68].

#### Avoid the Perception of Marketing

We found that users reject security advice that contains marketing material. Therefore, advice that suggests or encourages purchasing a particular product or service (especially if associated with the advice source) reduces credibility and should be avoided. Further, designing digital-security advice that clearly states the author’s qualifications—for example, “John Smith, Senior Security Engineer at Google”—may increase advice credibility and authenticity.

#### Reassure Users About Privacy

Both 2FA and password managers appear in the top six expert-recommended digital security behaviors [8]. Our results suggest that privacy concerns and misunderstandings are at least partially driving low adoption of each technique. For example, regarding password managers, P7 noted, “I don’t like the notion of a machine memorizing my password. I don’t know where it’s going, I don’t know who has it, and I don’t know what is happening with it.” For 2FA, we hypothesize that users may be prioritizing the immediate risk of sharing private information (e.g., phone number) over the long-term risk of compromising a service (e.g., email). This is an example of present bias, our tendency to prioritize immediate rewards or concerns over long-term gains [69].

Thus, our third recommendation is to clearly explain to users (and not just in a privacy policy that no users will read) how their personal data, such as a phone number for 2FA or passwords for a password manager, will be protected. Mitigating these privacy concerns could provide high-impact benefits for users.

#### Explore the Effect of Security Sensitivity

Our results suggest possible differences between security-sensitive and general users, such as higher importance placed on digital security, fewer feelings of inevitability, and higher reliance on the workplace as a source of digital-security advice. Given our small sample size, we were not able to report the general prevalence of these differences and whether these differences result in meaningfully better security behavior. The behavioral impact of workplace security training and sensitive data exposure is an important avenue for future exploration.

#### Distribute Advice Via Pre-existing Channels

Many of our participants trust hardware and software companies to keep them secure without additional intervention; other participants valued direct advice from those companies. Thus, corporations such as Google, Apple, Facebook, and Comcast are well positioned to make a large impact on users’ digital security, as already-trusted sources of perceived credible advice. However, our results suggest that it may be crucial for these corporations to make it clear that they are the source of the advice and to avoid the perception of marketing so that users can easily recognize the credibility of their information.