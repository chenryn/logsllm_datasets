more ubiquitous, users are becoming more aware of the value
of their data. Overall, feelings that risk was low and therefore
implementing a new behavior was unnecessary were more
common for physical than digital security.
It’s Not My Job.
Eighteen participants rely on the com-
panies whose software, hardware, or services they use to
keep them safe. These participants do not seem to be making
explicit cost-beneﬁt calculations about particular personal be-
haviors being redundant to the services provided by these com-
panies; rather, they simply assume that they are not responsible
for the security of a given system because a corporation they
trust is taking care of it. This motivation for rejecting security
advice was unique to the digital-security domain. For example,
P8 comments, “I had been banking with a bank that I wasn’t
happy with. Then I went to Bank of America, which was this
big bank. I’m like, ‘Oh, they’re awesome so I don’t have to
worry about anything. I will be safe.’”
In addition to trusting corporations to take care of security
for them, participants also rely on browser and device prompts
(N=20), software defaults (N=20) and security requirements
imposed by their services (e.g., your password must be 16
characters long) (N=14) to keep them safe. For example, many
participants use a password or passcode to lock their phone
because the phone prompted them to do so at set-up. P2 says,
“When you boot up these phones now, they just give you
the option.” Relatedly, P4 says she only has passwords or
passcodes on her Mac products because, “the Mac products
prompt you to set up the security things...I never thought about
it [for the Kindle]. I guess it wasn’t prompted...I would have
to look up, how to do it on the Kindle.” In addition to prompts,
participants rely on software defaults, such as those in anti-
virus software, to provide security tactics: P17 comments, that
she has a script and popup blocker because it “was through
McAfee and it was automatic.
. . . I’m not really technical
savvy where I can block stuff and...go into my settings and
know what I’m messing with.”
Other reasons for rejecting advice.
Nine participants
stated that
they felt oversaturated and lacked the time to
implement the advice they saw, even if they thought it was
good advice. P7 says: “Part of it is just saturation. You get so
much information from so many sources. I don’t even know
sometimes what’s worth looking at.” Additionally, P6 notes
that in general he often does not take security advice because
he has “kind of reached a level of don’t care. It’s so obvious to
me that I don’t know what I don’t know, that it’s frustrating to
try to tease apart what would be helpful and what wouldn’t.”
The advice may also be too advanced (N=7), too incon-
venient (N=6), or participants may feel that no matter what,
they will be hacked (N=11). Even participants who are highly
educated may reject digital-security advice for being too
advanced (N=4). P9 holds a computer engineering degree and
says he knows that HTTPS and SSL exist, but “I don’t even
know what the acronyms mean, I know that some websites
are more secure and others aren’t, and I don’t pay attention
to it.” P8, who holds a master’s degree, also struggles to
understand too-complex advice: she sometimes rejects advice,
“Depending on the number of steps and the complexity of it
because I’m not a IT person . . . it can be complex what they’re
asking me to do.”
Finally, a few participants described reasoning that was
less common but still interesting, with possible implications
for design. One participant (P3) noted that he rejects advice
because he see it in the wrong venue: “I see the information
while on [public transit] to work and then by the end of the
day, looking at a computer is the last thing I want to do.” We
hypothesize that this factor may be important for many users,
even though no other participants explicitly mentioned it. A
few other participants reported rejecting what they perceived
280280
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:08 UTC from IEEE Xplore.  Restrictions apply. 
as good advice for others because they were already conﬁdent
in their own behaviors (N=3). P25 notes that having others
tell him how to be digitally secure is pointless, because: “I do
what I do based on my own personal feelings and intellect,
so I don’t ﬁnd it useful, but for someone who didn’t know
it would be useful. Never found any of the advice useful. I
just have my own way of protecting what I do, so it’s like
if someone’s telling you how to make a PB&J sandwich, and
I’m like I know how to do it. But if they’re saying something
drastic—don’t do this, this, and this—then I’ll look at it, but
usually, no.”
E. Security-Sensitive vs. General Participants
In addition to differences between participants’ behavior
in the physical- and digital-security domains, we also noted
possible differences between participants in our sample who
are and are not security-sensitive. We recruited security-
sensitive participants to investigate how extra training in
handling conﬁdential or sensitive data at work would affect
how participants process security advice in their personal
lives. Below, we discuss some observed trends that appear to
differentiate security-sensitive from general participants; given
our qualitative data and limited sample size, these ﬁndings
mainly serve to suggest directions for further exploration. The
prevalence of these differences in our sample is summarized
in Figure 5.
Two-Factor Authentication.
Seven of 15 security-sensitive
participants in our study had adopted two-factor authentication
(2FA), compared to eight of 10 general participants. Four
of these security-sensitive participants cite privacy concerns
as a reason for not using 2FA. Thus, we hypothesize that
security-sensitive users may be less trusting that the service
requesting 2FA can protect their personal information. Par-
ticipants’ motivations for accepting and rejecting two-factor
authentication are discussed in more detail in Section IV-F.
This potential difference between the privacy concerns of
security-sensitive and general users should be conﬁrmed with
additional quantitative investigation, as discussed in Section V.
Advice Evaluation.
Nine of 15 security-sensitive partici-
pants cited the trustworthiness of the advice source as their
key metric for choosing to take digital-security advice, com-
pared to only two of 10 general participants. We suspect
that security-sensitive users may be more discerning about
advice because they have been trained to look critically at the
digital information they come across. A primary component
of workplace digital-security training is reminders not to trust
unknown individuals [59], [60].
Workplace Digital-Security Advice.
Thirteen out of 15
security-sensitive participants took advice from their work-
place, contrasted with four of 10 regular participants. This is
perhaps unsurprising given the workplace emphasis on digital-
security and regular trainings that occur for security-sensitive
users.
Beliefs About the Utility Digital Security Advice.
Eight
of 15 security-sensitive participants in our sample believed
Which is more useful?
General Participants
Sec. Sens. Participants
2
8
7
Physical
Digital
Why do you take advice?
General Participants
Sec. Sens. Participants
2
8
6
9
9
Simple, Salient, Other
Trust Source
Do you use 2FA?
General Participants
Sec. Sens. Participants
2
8
7
8
No
Yes
Workplace is a source of security information?
General Participants
Sec. Sens. Participants
4
6
2
13
No
Yes
Feelings of Inevitability?
General Participants
4
6
Sec. Sens. Participants
12
3
No
Yes
Fig. 5. Security-sensitive participants in our sample tend to differ from
general participants in their valuation of digital-security advice, their reasons
for taking advice, their use of two-factor authentication, and some of their
advice sources.
that digital-security advice was more useful
than physical
security advice, compared to two of 10 general participants.
We speculate this may be related to these participants being
more frequently reminded to pay attention to digital security
and data sensitivity.
Feelings of Inevitability. General participants in our sample
expressed more feelings of inevitability (’no matter what,
I will be hacked’) than did security-sensitive participants.
Six out of 10 general participants expressed these feelings,
contrasted with three out of 15 security sensitive participants.
We hypothesize that less formal training may contribute to
general users having more feelings of powerlessness.
F. Case Study: Two-factor Authentication
As mentioned in Section II-B, Ion et al. report that use
of two-factor authentication (2FA) is one of the top three
security behaviors recommended by or used by security ex-
perts. However, only 40% of the non-expert participants in
281281
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:08 UTC from IEEE Xplore.  Restrictions apply. 
that study reported using 2FA. Our results shed some light
on the reasoning behind users’ acceptance or rejection of this
behavior.
How and Why I Use Two-Factor Authentication. Of the
participants we interviewed, more than half reported using
2FA (N=14). In our interview questions about 2FA, we started
by deﬁning 2FA as “a service where you might put in your
phone number and then be sent a veriﬁcation code.” Given this
deﬁnition, all participants recognized 2FA and were able to
substantively answer our interview questions on this topic. Of
our 14 participants who had used 2FA, ﬁve used 2FA for some,
but not all, services for which it is offered. These participants
use 2FA for those services they feel are particularly important:
P6 says, “I’ve got 2FA on one thing, and that is my insurance
company. I did that because [of a negative experience at my
workplace]. I ﬁgured that [my insurance] was one of the most
important things, because...it covers every aspect in my life. I
didn’t want anyone to mess with that.”
Alternately, participants may only use 2FA on services that
strongly encourage or force them to do so: “I do that with
Xbox Live, they force me to do that. I think Google, they
want me to do that but I always say later,” comments P12. 1
Similarly, P14 says: “Yes, at one time Verizon, because I have
a Verizon email account, it asked me to do [2FA], it takes a
while but I’ve done it...it forced me to do it.” Of the remaining
nine participants who used 2FA, two did not understand what
they were doing: P16 comments, “You mean when it asks to
use by text or phone call? I do that, even though I hate doing
it, because I’m trying to ﬁgure out what is the purpose, but it
says the purpose is your safety and security.”
Why I Don’t Use Two-Factor Authentication.
Eleven
participants knew about but chose not to use 2FA. Five of these
participants declined 2FA due to privacy concerns: speciﬁcally,
they worried about giving out their personal phone number,
about GPS tracking based on that phone number, and about
the service providing 2FA’s ability to keep their information se-
cure. For example, P13 says: “No, [I want] nothing connected
to the phone. So, the phone is directly connected to the email.
I don’t feel comfortable to let people in if it’s connected to
the email account.” Similarly, P3 says: “I think I do have that
[2FA] capacity. I think I’ve always declined Gmail enabling
that access...Based on what I know about Gmail, it just seemed
like giving up too much information to Google.” With regard
to protecting the information used for veriﬁcation, P23 says:
“Google has prompted but I’ve always ignored it because I
think that someone will get ahold of it, I’m not saying they
would, but I’m just always like, you know, yeah.”
In addition to privacy concerns, two participants declined to
use 2FA due to convenience concerns: “Two years ago, at the
beginning of the summer, Google introduced 2FA, and this
was an issue because I tried to log in and I didn’t get cell
service and I couldn’t get the text message to log in, and that
was the last time I tried to change anything,” says P9. And
1Note that XBox Live does not require two-factor authentication, but this
participant may have misinterpreted the prompt screen as a requirement.
282282
two participants declined the service due to not understanding
the purpose of the tool.
V. DESIGN GUIDELINES
In the following section, we make a number of design
suggestions and recommendations for future work. While our
data suggests support for these design suggestions, our results
are qualitative and so have limited generalizability, thus future
research is recommended to conﬁrm the efﬁcacy and necessity
of these designs.
Security
Develop Vignettes
Experiences.
results and in
As
Rader et al.’s work, negative events experienced by users
or their friends can be key motivators for security behavior
change [3]. However, we would prefer that users do not
undergo these negative experiences. Moreover, even if the
cost of a negative security event was worth the skills the
user learned, there are few ways to artiﬁcially create these
negative security experiences without stressing or harming
users.
to
shown both in our
Simulate Negative
Our ﬁndings highlight a potential solution to this prob-
lem—mini-clips, training videos, or other media designed to
artiﬁcially create a salient negative-security experience. We
found evidence in our sample that mimicking negative events
via a well-crafted ﬁctional narrative with relatable characters
can be very effective. We believe that this idea has merit, as
stories can be “a very powerful way to represent and convey
complex, multi-dimensional ideas” and the efﬁcacy of using
ﬁctional vignettes to improve behavior has been proven in
the organizational development and health-behavior change
ﬁelds [61], [62].
Our ﬁndings suggest three elements that may be important
to the efﬁcacy of such vignettes: creating relatable characters,
demonstrating clear causes for negative security events; and
ensuring that characters who ﬁx security problems appear
trustworthy. Findings from prior work in the entertainment-
education ﬁeld, primarily around health behavior change, can
help inform the creation of relatable characters [63], [64].
However, further research, which will likely draw upon work
in the communications, psychology and education ﬁelds, is
required to determine how to create relatable characters and
trustworthy advisors. Many of our participants considered
IT professionals and “tech-savvy” individuals amongst their
friends and family to be trustworthy advice sources. Prior work
on technology help seeking suggests a number of attributes
common to those who are asked or observed for technology
advice [65], [66]. However, a deeper investigation is needed to
determine what will lead users to trust a character portrayed in
a vignette as an authoritative source of digital-security advice.
Further evaluation of what makes a piece of media trust-
worthy will be required in order to a) pursue this design
and b) generally indicate trustworthiness for other security
advice distributed via the media. This evaluation may include
drawing upon measures of credibility developed in the mass
communications and marketing ﬁelds [67], [68].
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:08 UTC from IEEE Xplore.  Restrictions apply. 
Avoid the Perception of Marketing. We found that users
reject security advice that contains marketing material; there-
fore, advice that suggests or encourages purchasing a particular
product or service (especially if associated with the advice
source) reduces credibility and should therefore be avoided.
Further, designing digital-security advice that clearly states
the author’s qualiﬁcations—for example “John Smith, Senior
Security Engineer at Google,” may increase advice credibility
and authenticity.
Reassure Users About Privacy.
Both 2FA and password
managers appear in the top six expert-recommended digi-
tal security behaviors [8]; our results suggest that privacy
concerns and misunderstandings are at least partially driving
low adoption of each technique. For example, with regard to
password managers, P7 notes that she does not like “the notion
of a machine memorizing my password, I don’t know where
it’s going, I don’t know who has it and I don’t know what is
happening with it.” For 2FA, we hypothesize that users may be
prioritizing the immediate risk of sharing private information
(e.g. phone number) over the long-term risk of compromising
a service (e.g. email). This is an example of present bias,
our tendency to prioritize immediate rewards or concerns over
long-term gains [69].
Thus, our third recommendation is to clearly explain to
users (and not just in a privacy policy that no users will
read) how their personal data, such as a phone number for
2FA or passwords for a password manager, will be protected.
Mitigating these privacy concerns could provide high-impact
beneﬁts for users.
Explore the Effect of Security Sensitivity.
Our results
suggest possible differences between security-sensitive and
general users, such as higher importance placed on digital
security, fewer feelings of inevitability, and higher reliance
on the workplace as a source of digital-security advice. Given
our small sample size, we were not able to report the general
prevalence of these differences and whether these differences
result in meaningfully better security behavior. The behavioral
impact of workplace security training and sensitive data expo-
sure is an important avenue for future exploration.
Distribute Advice Via Pre-existing Channels. Many of
our participants trust hardware and software companies to keep
them secure without additional intervention; other participants
valued direct advice from those companies. Thus, corporations
such as Google, Apple, Facebook and Comcast are well
positioned to make a large impact on users’ digital security, as
already-trusted sources of perceived credible advice. However,
our results suggest that it may be crucial for these corporations
to make it clear that they are the source of the advice and
to avoid the perception of marketing so that users can easily
recognize the credibility of their information.