3
32
#Retries #Offsets Time
72 µs
512
64000
262144
512
64000
262144
13.648 ms
1.713 s
42 µs
8.61 ms
1.33 s
F1-Score
1
1
0.98
1
1
0.96
Table 3: Evaluation of Data Bounce in finding the kernel
base address, its direct-physical map, and the kernel mod-
ules. Number of retries refers to the maximum number of
times an offset is tested, and number of offsets denotes the
maximum number of offsets that need to be tried.
always present and modules are separated by unmapped addresses,
we can detect where a module starts and ends. In a second step,
we use this information to estimate the size of all loaded kernel
modules. The world-readable /proc/modules file contains informa-
tion on modules, including name, size, number of loaded instances,
dependencies on other modules, and load state. For privileged users,
it additionally provides the address of the module. We correlate
the size from /proc/modules with the data from our Data Bounce
attack and can identify all modules with a unique size. On the i7-
6600U, running Ubuntu 18.04 (kernel version 4.15.0-47), we have a
total of 26 modules with a unique size. On the i9-9900K, running
Ubuntu 18.10 (kernel version 4.18.0-17), we have a total of 12 mod-
ules with a unique size. Table 3 shows the accuracy and performance
of Data Bounce for finding and classifying those modules.
Breaking KASLR with the KAISER Patch. As a countermea-
sure to Meltdown [51], OSs running on Intel processors prior to
Coffee Lake R have deployed the KAISER countermeasure, which
removes the kernel from the address space of user processes (see
Figure 8 (bottom)). To allow the process to switch to the kernel
address space, the system leaves at least one kernel page in the
address space of the user process. Because the pages required for
the switch do not contain any secret information, there is no need
to hide them from Meltdown [12].
However, we observed that the pages that remain in the user
space are randomized using the same offset as KPTI. Hence, we
can use Data Bounce to de-randomize the kernel base address even
with KPTI enabled. To the best of our knowledge, we are the first to
demonstrate KASLR break with KPTI enabled. Finally, we note that
on CPUs with hardware Meltdown mitigation, our KASLR break
is more devastating, because we can de-randomize not only the
kernel base address but also the kernel modules
6.2 Recovering Address Space Information
from JavaScript
In addition to unprivileged native applications, Data Bounce can
also be used in JavaScript to leak partial information on allocated
and unallocated addresses in the browser. This information can
potentially lead to breaking ASLR. In this section, we evaluate the
performance of Data Bounce from JavaScript running in a mod-
ern browser. We conducted this evaluation on Google Chrome
70.0.3538.67 (64-bit) and Mozilla Firefox 66.0.2 (64-bit).
Figure 8: (Top) Address space with KASLR but without
KAISER. (Bottom) User space with KASLR and KAISER.
Most of the kernel is not mapped in the process’s address
space anymore.
There are two main challenges for mounting Data Bounce from
JavaScript. First, there is no high-resolution timer available. There-
fore, we need to build our own timing primitive. Second, as there
is no flush instruction in JavaScript, Flush+Reload is not possible.
Thus, we have to resort to a different covert channel for bringing
the microarchitectural state to the architectural state.
To measure timing with a high resolution,
Timing Primitive.
we rely on the well-known use of a counting thread in combination
with shared memory [22, 69]. As Google Chrome has re-enabled
SharedArrayBuffers in version 67 [2], we can use the existing
implementations of such a counting thread. In Firefox, we emulated
this behavior by manually enabling SharedArrayBuffers.
In Google Chrome, we can also use the BigUint64Array to en-
sure that the counting thread does not overflow. This improves
the measurements compared to the Uint32Array used in previous
work [22, 69] as the timestamp is increasing strictly monotonically.
In our experiments, we achieve a resolution of 50 ns in Google
Chrome, which is sufficient to distinguish a cache hit from a miss.
As JavaScript does not provide a method
Covert Channel.
to flush an address from the cache, we have to resort to eviction,
as shown in previous work [22, 47, 61, 69, 77]. Thus, our covert
channel from the microarchitectural to the architectural domain,
i.e., the decoding of the leaked value which is encoded into the
cache, uses Evict+Reload instead of Flush+Reload.
For the sake of simplicity, we can also access an array 2–3 times
larger than the last-level cache to ensure that data is evicted from
the cache. For our proof-of-concept, we use this simple approach
as it is robust and works for the attack. While the performance
increases significantly when using targeted eviction, we would
require 256 eviction sets. We avoid generating these eviction sets
because the process is time-consuming and prone to errors.
In JavaScript, we cannot access an inaccessible
Illegal Access.
address architecturally. However, as all modern browsers use just-
in-time compilation to convert JavaScript to native code, we can
leverage speculative execution to prevent the fault. Hence, we rely
on the same code as Kocher et al. [47] to speculatively access an out-
of-bounds index of an array. This allows to iterate over the memory
(relative from our array) and detect which pages are mapped and
which pages are not mapped.
0x7FFFFFFFFFFF0xFFFF800000000000Kernel SpaceCodeNon CanonicalUser Space0CodeStack⋯⋯⋯CodeStack⋯⋯⋯0constKernel Pages Left After KPTIKernel Startn
o
i
t
c
e
t
e
D
0.8
0.6
0.4
0.2
0
target
reference
mouse movement
keyboard mouse movement
0
20
40
80
60
Sampling Period
100
120
140
Figure 9: Data Bounce with Evict+Reload in JavaScript
clearly shows whether an address (relative to a base address)
is backed by a physical page and thus valid.
Figure 10: Mouse movement detection. The mouse move-
ments are clearly detected. The USB keyboard activity does
not cause more TLB hits than observed as a baseline.
Full Exploit. When putting everything together, we can dis-
tinguish for every location relative to the start array, whether a
physical page backs it or not. Due to the limitations of the JavaScript
sandbox, especially due to the slow cache eviction, the speed is or-
ders of magnitude slower than the native implementation, as it can
be seen in Figure 9. Still, we can detect whether a virtual address
is backed by a physical page within 450 ms, making Data Bounce
also realistic from JavaScript.
7 FETCH+BOUNCE
Fetch+Bounce uses Data Bounce to spy on the TLB state and en-
ables more powerful attacks as we show in this section. So far, most
microarchitectural side-channel attacks on the kernel require at
least some knowledge of physical addresses [65, 67]. Since physi-
cal addresses are not provided to unprivileged applications, these
attacks either require additional side channels [26, 67] or have to
blindly attack targets until the correct target is found [71].
With Fetch+Bounce we directly retrieve side-channel informa-
tion for any target virtual address, regardless of the access permis-
sions in the current privilege level. We can detect whether a virtual
address has a valid translation in either the iTLB or dTLB, thereby
allowing an attacker to infer whether an address was recently used.
Fetch+Bounce allows an attacker to detect recently accessed
data pages in the current hyperthread. Moreover, an attacker can
also detect code pages recently used for instruction execution in
the current hyperthread. Next, as the measurement with Fetch+
Bounce results in a valid mapping of the target address, we also
require a method to evict the TLB. While this can be as simple as
accessing (dTLB) or executing (iTLB) data on more pages than there
are TLB entries, this is not an optimal strategy. Instead, we rely on
the reverse-engineered eviction strategies from Gras et al. [21].
We first build an eviction set for the target address(es) and then
loop Fetch+Bounce on the target address(es) to detect potential
activity, before evicting the target address(es) again from iTLB and
dTLB. Below, we demonstrate this attack on the Linux kernel.
7.1 Inferring Control Flow of the Kernel
The kernel is a valuable target for attackers, as it processes all inputs
coming from I/O devices. Microarchitectural attacks targeting user
input directly in the kernel usually rely on Prime+Probe [58, 61, 66,
67] and thus require recovery of physical address information.
With Fetch+Bounce, we do not require knowledge of physical
addresses to spy on the kernel. In the following, we show that
Fetch+Bounce can spy on any type of kernel activity. We illustrate
this with the examples of mouse input and Bluetooth events.
As a proof of concept, we monitor the first 8 pages of a target
kernel module. To obtain a baseline for the general kernel activ-
ity, and thus the TLB activity for kernel pages, we also monitor
one reference page from a rarely-used kernel module (in our case
i2c_i801). By comparing the activity on the 8 pages of the ker-
nel module to the baseline, we determine whether the module is
currently used or not. For best results, we use Fetch+Bounce with
both the iTLB and dTLB. This makes the attack independent of the
activity type in the module, i.e., there is no difference between data
access and code execution. Our spy changes its hyperthread after
each Fetch+Bounce measurement. While this reduces the attack’s
resolution, it allows to detect activity on all hyperthreads. Next, we
sum the resulting TLB hits over a sampling period which consists
of 5000 measurements, and then apply a basic detection filter to
this sum by calculating the ratio between hits on the target and
reference pages. If the number of hits on the target pages is above
a sanity lower bound and above the number of cache hits on the
reference page, i.e., above the baseline, then the page was recently
used.
Detecting User Input. We now investigate how well Fetch+
Bounce works for spying on input-handling code in the kernel.
While [67] attacked the kernel code for PS/2 keyboards, we target
the kernel module for USB human-interface devices, allowing us to
monitor activity on a large variety of modern USB input devices.
We first locate the kernel module using Data Bounce as described
in Section 6.1. With 12 pages (kernel 4.15.0), the module does not
have a unique size among all modules but is 1 of only 3. Thus, we
can either try to identify the correct module or monitor all of them.
Figure 10 shows the results of using Fetch+Bounce on a page
of the usbhid kernel module. It can be clearly seen that mouse
movement results in a higher number of TLB hits. USB keyboard
input, however, seems to fall below the detection threshold with
our simple method. Given this attack’s low temporal resolution,
repeated accesses to a page are necessary for clear detection. Previ-
ous work has shown that such an event trace can be used to infer
user input, e.g., URLs [49, 61].
Bluetooth events can give valu-
Detecting Bluetooth Events.
able information about the user’s presence at the computer, e.g.,
connecting (or disconnecting) a device usually requires some form
of user interaction. Tools, such as Windows’ Dynamic Lock [57],
use the connect and disconnect events to unlock and lock a com-
puter automatically. Thus, these events are a useful indicator for
detecting whether the user is currently using the computer, as well
as serve as a trigger signal for UI redressing attacks.
quiet
target
reference
]
%
[
s
t
i
h
1
0.5
0
0
noise
connect
audio
audio
50
100
150
200
Sampling Period
Figure 11: Detecting Bluetooth events by monitoring TLB
hits via Fetch+Bounce on pages at the start of the bluetooth
kernel module.
To spy on these events, we first locate the Bluetooth kernel
module using Data Bounce. As the Bluetooth module is rather large
(134 pages on kernel 4.15.0) and has a unique size, it is easy to
distinguish it from other kernel modules.
Figure 11 shows a Fetch+Bounce trace while generating Blue-
tooth events. While there is a constant noise floor due to TLB
collisions, we can see a clear increase in TLB hits on the target
address for every Bluetooth event. After applying our detection
filter, we can detect events such as connecting and playing audio
over the Bluetooth connection with a high accuracy.
Our results indicate that the precision of the detection and dis-
tinction of events with Fetch+Bounce can be significantly improved.
Future work should investigate profiling code pages of kernel mod-
ules, similar to previous template attacks [29].
8 LEAKING KERNEL MEMORY
In this section, we present Speculative Fetch+Bounce, a novel
covert channel to leak memory using Spectre. Most Spectre at-
tacks, including the original Spectre attack, use the cache as a
covert channel to encode values leaked from the kernel [11, 35, 46–
48, 54, 60, 70]. Other covert channels for Spectre attacks, such as
port contention [9] or AVX [70] have since been presented. How-
ever, it is unclear how commonly such gadgets can be found and
can be exploited in real-world software.
With Speculative Fetch+Bounce, we show how TLB effects on
the store buffer (cf. Section 7) can be combined with speculative
execution to leak kernel data. We show that any cache-based Spec-
tre gadget can be used for Speculative Fetch+Bounce. As secret-
dependent page accesses also populates the TLB, such a gadget also
encodes the information in the TLB. With Data Bounce, we can
then reconstruct which of the pages was accessed and thus infer the
secret. While at first, the improvements over the original Spectre
attack might not be obvious, there are two advantages.
Advantage 1: It requires less control over the Spectre gadget.
First, for Speculative Fetch+Bounce, an attacker requires less control
over the Spectre gadget. In the original Spectre Variant 1 attack, a
gadget like if ( index < bounds ) { y = oracle[ data[index]
* 4096 ]; } is required. There, an attacker requires full control
over index, and also certain control over oracle. Specifically, the
base address of oracle has to point to user-accessible memory
which is shared between attacker and victim. Furthermore, the base
address has to either be known or be controlled by the attacker. This
limitation potentially reduces the number of exploitable gadgets.
Second, with
Advantage 2: It requires no shared memory.
Speculative Fetch+Bounce, we get rid of the shared-memory re-
quirement. Especially on modern operating systems, shared mem-
ory is a limitation, as these operating systems provide stronger
kernel isolation [25]. On such systems, only a few pages are mapped
both in user and kernel space, and they are typically inaccessible
from the user space. Moreover, the kernel can typically not ac-
cess user space memory due to supervisor mode access prevention
(SMAP). Hence, realistic Spectre attacks have to resort to Prime+
Probe [73]. However, Prime+Probe requires knowledge of physical
addresses, which is not exposed on modern operating systems.
With Speculative Fetch+Bounce, it is not necessary to have a
memory region which is user accessible and shared between user
and kernel. For Speculative Fetch+Bounce, it is sufficient that the
base address of oracle points to a kernel address which is also
mapped in user space. Even in the case of KPTI [53], there are still
kernel pages mapped in the user space. On kernel 4.15.0, we identi-
fied 65536 such kernel pages when KPTI is enabled, and multiple
gigabytes when KPTI is disabled. Hence, oracle only has to point
to any such range of mapped pages. Thus, we expect that there are
simpler Spectre gadgets which are sufficient to mount this attack.
To evaluate Speculative Fetch+Bounce, we use a
Leaking Data.
custom ioctl in the Linux kernel containing a Spectre gadget as
described before. We were able to show that our proof-of-concept
Spectre attack works between user and kernel in modern Linux
systems, without the use of shared memory.
9 DISCUSSION AND COUNTERMEASURES
Intel recently announced [37] that new post-Coffee Lake R proces-
sors are shipped with silicon-level mitigations against WTF (MSBDS
in Intel terminology). However, to the best of our knowledge, Intel
did not release an official statement regarding Store-to-Leak miti-
gations. In this section, we discuss the widely deployed software
and microcode mitigations released by Intel to address microarchi-
tectural data sampling attacks [41]. We furthermore discuss the
limitations of our analysis.
In this paper and our original
Leaking Stale Store Buffer Data.
vulnerability disclosure report, we focused exclusively on leaking
outstanding store buffer entries in the limited time window after
the kernel transfers execution to user space. That is, we showed
that the WTF shortcut can be abused by unprivileged adversaries
to leak in-flight data from prior kernel store instructions that have