However, because executable programs may be invoked on a ma-
chine that is not connected to the Internet, code signing certificates
may include trusted timestamps and have special requirements for
revocation.
Trusted timestamping. A trusted timestamp certifies the signing
time of the code and extends the trust in the program beyond the
validity period of the certificate. In TLS, when a certificate expires,
any service (e.g., web, email, etc.) associated with the certificate
becomes invalid. However, if program code is properly signed and
timestamped within its validity period, the code can remain valid af-
ter the certificate expires. To timestamp signed code, the hash value
of an original program code is sent to a Time-Stamping Authority
(TSA). The TSA appends the current timestamp to the received
hash value, calculates a new hash, and digitally signs it with its
private key. The TSA then returns the signature and the current
timestamp in plain text. The publisher appends the received signa-
ture, timestamp, and TSA certificate chains to the signed program
code.
Revocation. For TLS, CAs do not provide the revocation status
of expired certificates. In contrast, because of timestamping, code-
signing CAs must keep updating the certificate revocation infor-
mation even after the certificate expires.
As trusted timestamps cause an indefinite extension of the cer-
tificate validity, revocation mechanisms play a more important role
in the code signing ecosystem. Suppose a code signing certificate is
valid between ti (issue date) and te (expiration date). The certificate
is revoked at some point (no matter before or after the expiration
6https://www.globalsign.com/en/blog/casc-code-signing-certificate-requirements-
for-developers/
7For example, in 2001 VeriSign issued two code signing certificates with the common
name of “Microsoft Corporation" to an adversary who claimed to be a Microsoft
employee [25].
date) and its revocation date is set to tr . Any program that is signed
and timestamped between ti and tr is still valid even though the
certificate is revoked. This is based on the assumption that we know
when the certificate has been compromised, and all the code signed
and timestamped before tr is valid. However, the CA may not know
the exact date when the certificate was compromised. Consequently,
CAs may set the revocation date equal to the issue date. In this case,
all the (even benign) programs signed with that certificate become
invalid. The policy on setting revocation dates varies from one CA
to another.
2.3 Threat model
We consider an adversary with two goals: (1) to distribute and in-
stall malware on end-user machines; and (2) to conceal its identity.
In consequence, the adversary aims to sign malware samples in
order to evade AV detections and platform security policies such
as User Account Control and SmartScreen. At the same time, the
adversary does not want to obtain a legitimate code-signing certifi-
cate, which would reveal its identity. This second goal distinguishes
our adversary from the PUP publishers considered in the prior work
on code-signing abuse [18, 19, 21, 34]. To achieve these goals, the
adversary exploits weaknesses in the code-signing PKI to obtain
signed malware samples, which bypass various defenses. These
weaknesses fall into three categories: inadequate client-side protec-
tions, publisher-side key mismanagement, and CA-side verification
failures.
Inadequate client-side protections. While Windows operating
systems have the ability to verify code-signing signatures, they
often allow unsigned or improperly signed software to be installed
and executed. If a program requires elevated privileges, UAC notifies
the user and includes a message about the publisher’s identity (or
lack thereof, if the signature is invalid). However, if the user choses
to grant the privilege, Windows does not take further enforce-
ment actions. To fill this gap, anti-virus tools may block malicious
programs with invalid signatures. However, each tool includes an
independent implementation of the signature verification, which
may result in different interpretations of certificate validity.
Publisher-side key mismanagement. Publishers are expected
to restrict access to their code signing keys and to keep them secure.
If the adversary gains access to the development machines involved
in the signing process, it can steal the private key that corresponds
to the publisher’s certificate—thus compromising the certificate—or
it can use those machines to sign malware.
A certificate is compromised when the private key is no longer
in the sole possession of its owners. Signing keys may be stolen in
two ways:
• An adversary may breach the publisher’s network and gain
access to a machine storing the private key. The adversary
may then use the key for signing malware. This method was
likely employed for Stuxnet and Duqu 2.0 [10, 31], advanced
pieces of malware that carried valid signatures and certifi-
cates belonging to legitimate companies located in Taiwan.
• When a private key is compromised, the certificate associ-
ated with the key should be revoked and then re-issued with
a new key pair. However, developers may reuse the compro-
mised key in the new certificate. Key reuse was previously
documented in 14% of TLS certificates revoked following
Heartbleed [6].
Infected developer machines may also be utilized to silently
sign malicious code with the publisher’s valid certificate. The
W32/Induc.A [27] malware was first found in 2009, and infected
Delphi files. When executed, the malware searched for files required
by the Delphi compilers, and injected malicious code into those files.
In consequence, additional malware could be signed with a valid
certificate, during the compilation process, and then distributed in
a legitimate software package.
CA-side verification failures. CAs are responsible for verifying
clients’ identity before issuing a code signing certificate. However,
this verification process may fail, resulting in certificates issued to
publishers who hide their real identities.
Identity theft occurs when the adversary successfully masquer-
ades as a reputable company and convinces a CA to issue a code-
signing certificate bearing that company’s name. For example, in
January 2001 Verisign mistakenly issued two code signing certifi-
cates to an adversary who claimed to be an employee of Microsoft,
owing to a human error in the verification process [25]. However,
identity theft does not necessarily need to target large software
corporations. Companies in other industries, which do not release
software and do not need code signing certificates, may be easier
targets as they do not expect to be affected by this form of identity
theft.
Shell companies may also help the adversary acquire code signing
certificates legally from a CA. Because the shell company appears
legitimate, CAs have no reasons to decline the application for the
certificate. A disadvantage for this form of abuse is that the valid,
but unfamiliar, publisher name has not accumulated reputation in
defenses like SmartScreen and may not be trusted by users. How-
ever, valid signatures may nevertheless prevent anti-virus scanning,
and users may feel encouraged to install the software if the Win-
dows dialog indicates that the publisher is verified.
2.4 Challenges for measuring code signing
The challenges in this study for measuring code signing are collect-
ing of binaries and distinguishing between the abuse cases. For TLS
it is possible to get a comprehensive list of certificates by scanning
the IP spaces. However, for code signing there exists no easy way to
collect all the certificates used in the field. Even for the certificates
we are able to collect, it is hard to capture all the binaries signed by
these certificates. A further challenge is to identify the abuse case,
e.g., compromised certificate, identity theft, shell company. While
some well-studied malware samples, such as Stuxnet and Duqu,
are known to use compromised certificates, in most cases it is hard
to find a ground truth about the type of abuse. The only precise
information available is whether a certificate is revoked, as CAs
distribute lists of revoked certificates. For most of the certificates
on these lists, the revocation reason is left unspecified [19].
3 MEASUREMENT METHODS
To characterize breaches of trust in the Windows code signing PKI,
we collect information on Authenticode certificates used to sign
malware samples in the wild. We then classify these cases according
to the threat model from Section 2.3 and we investigate the PKI
weaknesses that facilitated the abuse. To overcome the challenges
that have prevented this analysis until now, we propose methods
for prioritizing the collection of certificates that are likely to be
abusive and an algorithm for distinguishing among the three types
of threats we consider.
3.1 Data sources
We identify hashes of signed malware samples, and the correspond-
ing publishers and CAs, from Symantec’s WINE dataset, we collect
detailed certificate information from VirusTotal, and we assess the
publishers using OpenCorporates and HerdProtect.
Worldwide Intelligence Network Environment
(WINE).
WINE [4] provides telemetry collected by Symantec’s products
on millions of end-hosts around the world (10.9 million). Users of
these products can opt-in to report telemetry about security events
(e.g., executable file downloads, virus detections) on their hosts.
These hosts are real computers in active use, rather than honeypots.
From the WINE data set, we query the (a) anti-virus (AV) telemetry
and (b) binary reputation.
The AV telemetry data contains information on the anti-virus
signatures triggered on user machines. From this data, we collect
the SHA256 hash of the binary that triggered the report and the
name of the AV detection signature assigned to the binary. We
extract about 70,293,533 unique hashes.
The binary reputation data reports download events on the user
machines. From this data, we extract the SHA256 hash of the bi-
nary, the server-side timestamp of the event, and the names of the
publisher and the CA from the code signing certificate. There are
587,992,001 unique binaries here. This data set does not provide
more detailed information about the certificate such as its serial
number. In consequence, WINE does not allow us to distinguish
between files signed with different certificates belonging to the
same publisher.
VirusTotal. To collect information about code signing certificates,
we query VirusTotal [35]. This service provides an API for scan-
ning files using up to 63 different anti-virus (AV) products, and
for querying the previous scanning reports. We query VirusTotal
using a private API, provided by VirusTotal, and retrieve the fol-
lowing information: the first-submission timestamp to VirusTotal,
the number of AV engines that detected the file as malicious, the
assigned detection name, and the file code signing information.
OpenCorporates. OpenCorporates8 maintains the largest open
database of businesses around the world, providing information
on over 100 million companies. We use this database to determine
whether publishers that own certificates used to sign malware
correspond to legitimate companies.
HerdProtect. We further investigate the reputation of the com-
pany, as software publisher, using HerdProtect9. For each publisher
in our dataset, we collect the following information: whether the
publisher is known to release PUPs, a summary of the company
(location, business type, etc.), and a sample of the certificates issued
to the publisher.
8https://opencorporates.com
9http://www.herdprotect.com/
3.2 System overview
Pipeline overview. As illustrated in Figure 1, our data collection
and analysis consists of four steps: seed collection, data filtration,
input data preparation and identifying potentially abusive certifi-
cates.
• Seed collection. We start by collecting a set of unique SHA256
file hashes from the AV telemetry data set in WINE. We
exclude the hashes detected by signatures that do not nec-
essarily indicate a malicious activity, such as hacktools (e.g.
password crackers, vulnerability scanners) or adware. To
this set, we add a list of hashes of known malicious binaries,
provided separately by Symantec. We then join this list of
hashes to the binary reputation schema, to determine which
files have a digital signature. This results in a tentative list
of binaries that are both digitally signed and malicious.
• Filtering data. The tentative list generated in the previous
step may contain PUPs and benign programs. We filter out
PUPs in three ways. First, we exclude the PUP publishers
identified in prior work [18, 19, 21, 34]. Second, we query
HerdProtect for all company names (the common names in
certificates). If they are labeled as PUP publishers, we remove
their hashes from the list. Third, we pick 10 samples for each
common name, and filter out them if at least one of them is
determined to be a PUP as discussed in Section 3.3. For the
files whose subject is specified as Microsoft or Anti-virus
companies, we sample the files using the Symantec ground
truth. In order words, we only take the ones that have bad
reputation in the Symantec ground truth for those files.
• Input data preparation. We use the filtered hashes to query
VirusTotal. The VirusTotal reports provide detailed informa-
tion on the code signing certificate and AV detection results
for each binary. We consider a binary to be signed malware if
1) it is properly signed, and 2) the detection names suggest it
is malware, as detailed in Section 3.3. Note that at this stage
we expect to see a number of malware samples with mal-
formed signatures. We analyze these samples in Section 4,
but we do not pass them further down the pipeline.
After we obtain the list of signed malware, we use the  pairs from our list to query binary reputation
schema in WINE. The result of the query is a list of poten-
tially benign binaries that are signed with the same certifi-
cates used to signed the malware. We then query VirusTotal
again with this list, and we use the reports to identify benign
files, as described in Section 3.3.
• Identify potentially abusive certificates. For each code signing
certificate used to sign malware, we infer the type of abuse
using the algorithm described in Section 3.4.
3.3 Binary labeling
Malware. We distinguish malware from benign and potentially un-
wanted programs using the approach proposed in [21]. Specifically,
for each binary we define cmal as the number of anti-virus products
invoked by VirusTotal that flagged the binary as malicious. We set
cmal ≥ 20 as the threshold for suspicious binaries. We then inspect
the labels given by these AV products and compute rpup as the
fraction of labels indicative of PUPs (we utilize the same keywords
Figure 1: Data analysis pipeline.
we then infer the corresponding type of abuse using the method
illustrated in Figure 2.
Compromised certificates. As described in Section 2.3, a compro-
mised certificate is initially issued to a legitimate publisher and is
used to sign benign programs. After the private key is compromised,
the certificate is shared between the legitimate owner and the mal-
ware authors. In consequence, we expect to see both benign and
malicious programs in a compromised certificate’s group. For each
group of binaries in this category, we further analyze the trusted
timestamps to reconstruct the timeline of the abuse.
Identity theft & shell companies. When the malware authors
are able to convince a CA to issue them a code signing certificate,
they have no motivation to use the certificate to sign benign code
as well. We therefore expect to see only malicious programs in
such a certificate’s group. We distinguish between cases of identity
theft and certificates belonging to shell companies by querying
OpenCorporates and HerdProtect. Specifically, if we find a publisher
in either of these directories, and the company address in the X.509
certificate matches the information in the directory, we suspect
that the company is a victim of identity theft.
Verification. The VirusTotal reports allow us the reliably identify
all the binaries with malformed digital signatures. Because this case
does not involve any failures on the part of the publisher or the
CA, we run experiments to determine if these signatures bypass
client-side protections. Among the other types of abuse, we have a
higher degree of confidence in our determination that a certificate is
compromised, as we can observe that it is likely utilized by multiple
actors. Some of the other certificates may also be compromised,
but we cannot determine this because we cannot collect all the
benign binaries in the wild. Similarly, we have a higher degree of
confidence in the identity fraud determination than in recognizing
shell companies, because some companies may be missing from the
directories we utilize. To verify our results, we manually analyze
their timelines, and we contact their owners and CAs to confirm
our findings.
Figure 2: Flowchart of the abuse detection algorithm.
as in the prior work). We consider that a binary is malware if it has
cmal ≥ 20 and rpup ≤ 10%.
Benign programs. We also utilize the VirusTotal reports to de-
termine if a program is benign. If a file has cmal = 0 and a valid
signature, we treat it as benign.
3.4 Abuse detection algorithm
As explained in Section 3.2, in the third step of our pipeline we
identify binaries that carry malformed digital signatures. These sig-
natures do not match the hash of the binary and were likely copied
literally from other signed binaries. In this case, the adversary does
not control the code signing certificate, but nevertheless tries to
produce a binary that may appear to be signed.
The rest of binaries identified by our pipeline are properly signed