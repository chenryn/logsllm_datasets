# 16 \| 环境管理：一切皆代码是一种什么样的体验？你好，我是石雪峰。网上经常流传着一些有关偏见地图的段子，通俗点说，"偏见地图"就是说网友对世界其他地方的印象，比如很多人认为天津人都会说相声。如果软件开发中也有偏见地图的话，那么，对不熟悉运维的人来说，提到运维团队，可能就觉得是维护环境的那帮人。于是，环境就成了软件行业的"头号背锅侠"。比如，线上出故障了，可以是环境配置错误；测试有些功能没测到，可以是没有测试环境；开发出Bug了，也不管三七二十一，先甩给环境再说......所以你看，好像什么问题都可能跟环境相关。这种没来由的偏见，也加剧了开发和运维之间的不信任。环境管理的挑战那么，为啥环境总是让人这么不放心呢？其实，这是因为，现代企业所面对的业务复杂性，很大程度上都可以直观地体现在环境管理的方方面面上。总结起来，我认为一共有5 点： 1.**环境种类繁多**首先，软件关联的环境种类越来越多，比如开发环境、测试环境、UAT用户验收测试环境、预发布环境、灰度环境、生产环境等。光是分清这些环境的名字和作用，就不是件容易的事情。2.**环境复杂性上升**现代应用的架构逐渐从单体应用向微服务应用转变。随着服务的拆分，各种缓存、路由、消息、通知等服务缺一不可，任何一个地方配置出错，应用都有可能无法正常运行。这还不包括各种服务之间的依赖和调用关系，这就导致很多企业部署一套完整环境的代价极高，甚至变成了不可能完成的任务。3.**环境一致性难以保证**比如，那句经典的甩锅名言"在我的机器上没问题"说的就是环境不一致的问题。如果无法保证各种环境配置的一致性，那么类似的问题就会无休止地发生。实际上，在很多企业中，生产环境由专门的团队管理维护，管理配置还算受控。但是对于开发环境来说，基本都属于一个黑盒子，毕竟是研发本地的电脑，即便想管也管不到。4.**环境交付速度慢**由于职责分离，环境的申请流程一般都比较冗长，从提起申请到交付可用的环境，往往需要2 周甚至更长的时间。一方面，这跟公司内部的流程审批有关。我见过一家企业申请一套环境需要 5级审批，想象一下，于一家扁平化组织的公司，从员工到 CEO之间的层级可能也没有 5级。另一方面，环境配置过程依赖手动完成，过程繁琐，效率也不高，大多数情况下，环境配置文档都属于过时状态，并不会根据应用升级而动态调整，这么一来二去，几天就过去了。5.**环境变更难以追溯**产品上线以后出现问题，查了半天才发现，原来是某个环境参数的配置导致的。至于这个配置是谁改的，什么时间改的，为什么修改，经过了哪些评审，一概不知，这就给线上环境的稳定性带来了极大的挑战和潜在的风险。要知道，**环境配置变更的重要性，一点也不亚于代码变更，通常都需要严格管控**。基础设施即代码你可能会问，有没有一种方法，可以用来解决这些问题呢？还真有！这就是基础设施即代码。可以这么说，如果没有采用基础设施即代码的实践，DevOps一定走不远。那么，到底什么是基础设施即代码呢？**基础设施即代码就是用一种描述性的语言，通过文本管理环境配置，并且自动化完成环境配置的方式。典型的就是以CAPS为代表的自动化环境配置管理工具**，也就是 Chef、Ansible、Puppet 和 Saltstacks四个开源工具的首字母缩写。这个概念听起来比较抽象，那么，所谓基础设施即代码，这个描述基础设施的代码长什么样子呢？我给你分享一段Ansible的配置示例，你可以参考一下。    ---      - name: Playbook        hosts: webservers        become: yes        become_user: root        tasks:          - name: ensure apache is at the latest version            yum:              name: httpd              state: latest          - name: ensure apache is running            service:              name: httpd              state: started无论你是否了解Ansible，单就这段代码而言，即便你不是专业运维或者工具专家，在注释的帮助下，你也大概能理解这个环境配置过程。实际上，这段代码就做了两件事：安装http 的软件包，并启动相关服务。为什么基础设施即代码能够解决以上问题呢？首先，对于同一个应用来说，各种环境的配置过程大同小异，只是在一些配置参数和依赖服务方面有所差别。**通过将所有环境的配置过程代码化，每个环境都对应一份配置文件，可以实现公共配置的复用**。当环境发生变更时，就不再需要登录机器，而是直接修改环境的配置文件。这样一来，环境配置就成了一份活的文档，再也不会因为更新不及时而失效了。其次，**环境的配置过程，完全可以使用工具自动化批量完成**。你只需要引用对应环境的配置文件即可，剩下的事情都交给工具。而且，即便各台机器的初始配置不一样，工具也可以保证环境的最终一致性。由于现代工具普遍支持幂等性原则，即便执行完整的配置过程，工具也会自动检测哪些步骤已经配置过了，然后跳过这个步骤继续后面的操作。这样一来，大批量环境的配置效率就大大提升了。最后，既然环境配置变成了代码，自然可以直接纳入版本控制系统中进行管理，享受版本控制的福利。任何环境的配置变更都可以通过类似Git命令的方式来实现，不仅收敛了环境配置的入口，还让所有的环境变更都完全可追溯。基础设施即代码的实践，通过人人可以读懂的代码将原本复杂的技术简单化，这样一来，即便是团队中不懂运维的角色，也能看懂和修改这个过程。这不仅让团队成员有了一种共同的语言，还大大减少了不同角色之间的依赖，降低了沟通协作成本。这也是基础设施即代码的隐形价值所在，特别符合DevOps 所倡导的协作原则。看到这儿，你可能会说，这不就是一种自动化手段吗？好像也没什么特别的呀。回头想想，DevOps的初衷就是打破开发和运维的隔阂，但究竟要如何打通呢？在大多数公司，部署上线的工作都是由专职的运维团队来负责，开发团队只要将测试通过的软件包提供给运维团队就行了。所以，**开发和运维的自然边界就在于软件包交付的环节，只有打通开发环节的软件集成验收的CI 流水线和运维环节的应用部署 CD流水线上线，才能真正实现开发运维的一体化**。而当版本控制系统遇上基础设施即代码，就形成了一种绝妙的组合，那就是**GitOps**。开发运维打通的 GitOps 实践顾名思义，GitOps 就是基于版本控制系统 Git来实现的一套解决方案，核心在于基于 Git这样一个统一的数据源，通过类似代码提交过程中的拉取请求的方式，也就是PullRequest，来完成应用从开发到运维的交付过程，让开发和运维之间的协作可以基于Git 来实现。虽然 GitOps 最初是基于容器技术和 Kubernetes平台来实现的，但它的理念并不局限于使用容器技术，实际上，**它的核心在于通过代码化的方式来描述应用部署的环境和部署过程**。在 GitOps中，每一个环境对应一个环境配置仓库，这个仓库中包含了应用部署所需要的一切过程。比如，使用Kubernetes的时候，就是应用的一组资源描述文件，比如部署哪个版本，开放哪些端口，部署过程是怎样的。当然，你也可以使用 Helm 工具来统一管理这些资源文件。如果你还不太熟悉Kubernetes，可以简单地把它理解为云时代的 Linux，而 Helm 就是 RPM 或者APT这些包管理工具，通过应用打包的方式，来简化应用的部署过程。除了基于 Kubernetes 的应用，你也可以使用类似 Ansible Playbook的方式。只不过与现成的 Helm 工具相比，使用 Ansible时，需要自己实现一些部署脚本，不过这也不是一件复杂的事情。你可以看看下面的这段配置文件示例。这些配置文件采用了 yml格式，它描述了应用部署的主要信息，其中，镜像名称使用参数形式，会有一个独立的文件来统一管理这些变量，你可以根据应用的实际版本进行替换，以达到部署不同应用的目标。    apiVersion: extensions/v1beta1    kind: Deployment    spec:      replicas: 1      template:        metadata:          labels:            app: demo         spec:          containers:          - name: demo            image: "{{ .Values.image.tag }}"            imagePullPolicy: IfNotPresent            ports:            - containerPort: 80现在，我们来看看这个方案是如何实现的。首先，开发人员提交新的代码改动到 Git仓库，这会自动触发持续集成流水线，对于常见的版本控制系统来说，配置钩子就可以实现。当代码经过一系列的构建、测试和检查环节，并最终通过持续集成流水线之后，就会生成一个新版本的应用，并上传到制品库中，典型的就是Docker 镜像文件或者 war包的形式。 以上面的配置为例，假如生成了应用的 1.0版本镜像，接下来，会自动针对测试环境的配置仓库创建一个代码合并请求，变更的内容就是修改镜像名称的版本号为1.0。这个时候，开发或者测试人员可以通过接受合并的方式，将这段环境变更配置合入主干，并再一次自动化地触发部署流水线，将新版本的应用部署到测试环境中。每次应用的部署采用相同的过程，一般就是将最新版本的应用制品拷贝到服务器并且重启，或者更新容器镜像并触发滚动升级。这个时候，测试环境就部署完成了，当然，如果使用Kubernetes，可以利用**命名空间的特性**，快速创建出一套独立的环境，这是使用传统部署的应用所不具备的优势。在测试环境验收通过后，可以将代码合并到主分支，再一次触发完整的集成流水线环节，进行更加全面的测试工作。当流水线执行成功后，可以自动针对预发布环境的配置仓库创建一个合并请求，当评审通过后，系统自动完成预发布环境的部署。如果职责分离要求预发布环境的部署必须由运维人员来操作，把合并代码的权限只开放给运维人员就行了。当运维人员收到通知后，可以登录版本控制系统，查看本次变更的范围，评估影响，并按照部署节奏完成部署。而这个操作，只需要在界面点击按钮就可以实现了。这样一来，开发和运维团队的协作就不再是一个黑盒子了。大家基于代码提交评审的方式完成应用的交付部署，整个过程中的配置过程和参数信息都是透明共享的。我跟你分享一幅流程图，希望可以帮你充分地理解这个分层部署的过程。![](Images/a86de3dbcded73015da4ff69d4406288.png)savepage-src="https://static001.geekbang.org/resource/image/2d/fc/2de091bea58d1c4f376a26fa61c8f0fc.png"}那么，GitOps的好处究竟有哪些呢？首先，就是**环境配置的共享和统一管理**。原本复杂的环境配置过程通过代码化的方式管理起来，每个人都能看懂。这对于开发自运维来说，大大地简化了部署的复杂度。另外，所有最新的环境配置都以 Git仓库中为准，每一次的变更和部署过程也同样由版本控制系统进行记录。即便仅仅是环境工具的升级，也需要经过以上的完整流程，从而实现了环境和工具升级的层层验证。所以，这和基础设施即代码的理念可以说有异曲同工之妙。开发环境的治理实践关于开发环境的治理，我再给你举一个实际的案例。对于智能硬件产品开发来说，最大的痛点就是各种环境和工具的配置非常复杂，每个新员工入职，配置环境就要花上几天时间。另外，由于工具升级频繁和多平台并行开发的需要，开发经常需要在多种工具之间进行来回切换，管理成本很高。关于这个问题，同样**可以采用基础设施即代码的方法，生成一个包含全部工具依赖的Docker 镜像，并分发给开发团队**。在开发时仅需要拉起一个容器，将代码目录挂载进去，就可以生成一个完全标准化的研发环境。当工具版本升级时，可以重新制作一个新的镜像，开发本地拉取后，所有的工具就升级完成了，这大大简化了研发环境的维护成本。其实，我们也可以发挥创新能力，**把多种工具结合起来使用，以解决实际问题**。比如，我们团队之前要同时支持虚拟化设备和容器化两种环境，虚拟化可以采用传统的Ansible 方式完成环境部署，但容器化依赖于镜像的Dockerfile。这就存在一个问题：要同时维护两套配置，每次升级的时候也要同时修改虚拟化和容器化的配置文件。于是，为了简化这个过程，就可以把两者的优势结合起来，使用单一数据源维护标准环境。具体来说，在 Dockerfile中，除了基础环境和启动脚本，环境配置部分同样采用 Ansible的方式完成，这样每次在生成一个新的镜像时，就可以使用相同的方式完成环境的初始化过程，配置示例如下：    FROM  harbor.devops.com:5000/test:ansible     MAINTAINER XX     ADD ./docker  /docker    WORKDIR /docker    RUN export TMPDIR=/var/tmp && ansible-playbook -v -i playbooks/inventories/docker playbooks/docker_container.yml开发本地测试的实践其实，我始终认为，环境管理是 DevOps 推行过程中的一个潜在“大坑”。为了提升开发者的效率，业界也在探索很多新的实践方向。我在前面也给你介绍过快速失败的理念，只有在第一时间反馈失败，才能最小化问题修复成本。而对于研发来说，由于测试环境的缺失，往往要等到代码提交并部署完成之后才能获取反馈，这个周期显然是可以优化的。关于如何解决开发本地测试的问题，在 Jenkins 社区也有一些相关的实践。比如，你基于 Kubernetes创建了一套最小测试环境，按照正常过程来说，如果改动一行代码，你需要经过代码提交、打包镜像、上传制品、更新服务器镜像等，才能开始调试。但如果你使用KSync工具，这些过程统统可以省略。KSync可以帮你建立本地工作空间和远端容器目录的关联，并自动同步代码。也就是说，只要在本地IDE 里面修改了一行代码，保存之后，KSync就可以帮你把本地代码传到线上的容器中，对于类似 Python这样的解释型语言来说特别省事。谷歌也开源了一套基于容器开发自动部署工具Skaffold，跟 KSync 类似，使用 Skaffold命令就可以创建一套 Kubernetes 环境。当本地修改一行代码之后，Skaffold会自动帮你重新生成镜像文件，推送远端，并部署生效，让代码开发变得所见即所得。研发只需要专注于写代码这件事情，其余的全部自动化，这也是未来DevOps 工程实践的一个发展方向。总结今天，我给你介绍了企业环境管理的五个难题：种类多，复杂性，一致性，交付速度和变更追溯，并解释了为什么基础设施即代码是解决环境管理问题的最佳实践，还跟你分享了三个基础设施即代码的案例，希望能够帮助你理解这个过程。如果你不太了解 Kubernetes和容器，可能会有些内容难以消化。我想跟你说的是，**无论采用什么技术，代码化管理的方式都是未来的发展趋势**，建议你结合文章中的代码和流程图仔细梳理一下，并且尝试使用CAPS工具重新定义环境部署过程，将环境配置过程实现代码化。如果有问题，可以及时在留言区提问。思考题你认为推行开发自运维的最大难点是什么？关于解决这些难点，你有什么建议吗？欢迎在留言区写下你的思考和答案，我们一起讨论，共同学习进步。如果你觉得这篇文章对你有所帮助，欢迎你把文章分享给你的朋友。![](Images/94ddfb3c31810c68bfd0097449ef5eeb.png)savepage-src="https://static001.geekbang.org/resource/image/7c/33/7c26a9b917677371cf3aac78d949ae33.jpg"}
# 17 \| 部署管理：低风险的部署发布策略你好，我是石雪峰，今天我来跟你聊聊部署管理。 在 DevOps年度状态报告中，有四个核心的结果指标，其中仅"部署"这一项就占了两个关键指标，分别是**部署频率**和**部署失败率**。顺便提一下，另外两个指标是**前置时长**和**平均故障修复时长**。 对 DevOps来说，部署活动就相当于软件交付最后一公里的最后一百米冲刺。只有通过部署发布，软件真正交付到最终用户手中的时候，前面走过的路才真正创造了价值。 部署和发布这两个概念，经常会被混用，但严格来说，部署和发布代表两种不同的实践。**部署是一组技术实践，表示通过技术手段，将本次开发测试完成的功能实体**（比如代码、二进制包、配置文件、数据库等）**应用到指定环境的过程**，包括开发环境、预发布环境、生产环境等。部署的结果是对服务器进行变更，但是这个变更结果不一定对外可见。 发布，也就是Release，更偏向一种业务实践，也就是**将部署完成的功能正式生效，对用户可见和提供服务的过程**。发布的时机往往同业务需求密切相关。很多时候，部署和发布并不是同步进行的，比如，对于电商业务来说，要在0 点上线新的活动，那么如果部署和发布不分离，就意味着要在 0 点的前 1秒，完成所有服务器的变更，这显然是不现实的。 那么，我想请你思考这样一个问题：所谓的低风险发布，是不是要在发布之前确保本次变更的功能万无一失了，才会真正地执行发布动作呢？ 事实上，即使没这么说，很多公司也都是这样做的。传统软件工程在流程设计的时候，也是希望通过层层的质量手段，来尽可能全面地验证交付产品的质量。典型的应用就是测试的V模型，从单元测试、集成测试、系统测试，到用户验收，还有各类专项测试，其实都是为了在发布之前发现更多的问题，以此来保障产品的质量。 那么，在 DevOps模式下，是否也倡导同样的质量思想呢？我觉得这是一个有待商榷的问题。 实际上，随着发布频率的加速，留给测试活动的时间越来越有限了。与此同时，现在业务的复杂度，也比十年前高了不知道多少个等级。每次发布涉及PC 端、移动端，还有小程序、H5等多种形态，更别提成百上千的终端设备了。要在有限的时间里，完成所有的测试活动，本来就是件很有挑战的事情。而且，各个公司都在衡量测试开发比，更是限制了测试人力投入的增长，甚至还要不断下降。 你当然可以通过自动化手段来提升测试活动的效率，但穷尽测试本来就是个伪命题。那么，明明说了DevOps可以又快又好，难道是骗人的吗？ 当然不是。这里的核心就在于 DevOps模式下，质量思想发生了转变。简单概括就是：**要在保障一定的质量水平的前提下，尽量加快发布节奏，并通过低风险发布手段，以及线上测试和监控能力，尽早地发现问题，并以一种最简单的手段来快速恢复。** 这里面有几个关键词：**一定的质量水平**，**低风险发布手段**，**线上测试和监控**，以及**快速恢复**。我分别来给你解释一下。 一定的质量水平这个"一定"要怎么理解呢？对于不同形态的软件来说，质量标准的高低自然是不相同的。比如，我有一个制造卫星的同学，他们对于软件质量的要求就是要做到几年磨一剑，甚至是不计成本的。但对于互联网这种快速迭代的业务来说，大家都习惯了默认会出问题，所以在圈定测试范围和测试覆盖的基础上，只要完成严重问题的修复即可发布，低级别的问题可以在后续的众测和灰度的环节继续处理。 所以，与定义一个发布质量标准相比，更重要的随着 DevOps的推广，扭转团队的质量观念。**质量不再是测试团队自身的事情，而是整个交付团队的事情**。如果出现了线上问题，团队要一起来定位和修复，并且反思如何避免类似的问题再次发生，从失败中学习。 而测试能力的向前、向后延伸，一方面，提供了工具和平台以帮助开发更容易地进行自测；另一方面，加强针对线上监控埋点等类型的测试，可以保证线上问题可以快速暴露，正常获取辅助分析用户行为的数据，这会全面提升整体的发布质量。 低风险的发布手段既然发布是一件不可回避的高风险事情，那么，为了降低发布活动的风险，就需要有一些手段了。典型的包括以下几种：蓝绿部署，灰度发布和暗部署。 **1. 蓝绿部署** 蓝绿部署就是为应用准备两套一模一样的环境，一套是蓝环境，一套是绿环境，每次只有一套环境提供线上服务。这里的蓝和绿，只是用于区分两套环境的标志而已。在新版本上线时，先将新版本的应用部署到没有提供线上服务的环境中，进行上线前验证，验证通过后就达到了准备就绪的状态。在发布时间点，只要将原本指向线上环境的路由切换成另外一套环境，整个发布过程就完成了。 一般来说，**这种方式的实现成本比较高**。因为有两套一模一样的环境，只有一套用于真正地提供线上服务。为了减少资源浪费，在实际操作中，另外一套环境可以当作预发布环境使用，用来在上线之前验证新功能。另外，在这种模式下，数据库普遍还是采用同一套实例，通过向下兼容的方式支持多个版本的应用。 ![](Images/0ea8def7c200d2b7bfe4b266c8acc02f.png)savepage-src="https://static001.geekbang.org/resource/image/47/27/47931f5ea26ae8fe57dee79022046527.png"}>  > [图片来源：> > > [https://www.gocd.org/2017/07/25/blue-green-deployments.html> > > >**2. 灰度发布** 灰度发布，也叫金丝雀发布。与蓝绿部署相比，灰度发布更加灵活，成本也更低，所以，在企业中是一种更为普遍的低风险发布方式。 **灰度发布有很多种实现机制，最典型的就是采用一种渐进式的滚动升级来完成整个应用的发布过程**。当发布新版本应用时，根据事先设计好的灰度计划，将新应用部署到一定比例的节点上。当用户流量打到这部分节点的时候，就可以使用新的功能了。 值得注意的是，要保证同一个用户的行为一致性，不能时而看到新功能，时而看到老功能。当然，解决办法也有很多，比如通过用户ID 或者 cookie的方式来识别用户，并划分不同的组来保证。 新版本应用在部分节点验证通过后，再逐步放量，部署更多的节点，依次循环，最终完成所有节点的部署，将所有应用都升级到新版本。分批部署只是实现灰度发布的方法之一，利用配置中心和特性开关，同样可以实现指向性更强的灰度策略。比如，针对不同的用户、地域、设备类型进行灰度。 对于移动端应用来说，灰度发布的过程也是必不可少的。我以 iOS平台应用为例，带你梳理下发布的步骤。首先，公司的内部用户可以自行下载安装企业包，进行新版本验证和试用。试用OK 后，再通过官方的 Testflight平台对外开启灰度，这样只有一部分用户可以收到新版本通知，并且在Testflight中安装新版本。灰度指标符合预期后，再开启全量用户升级。 现在很多应用都采用了动态下发页面的方法，同样可以使用特性开关，来控制不同用户看到不同的功能。 ![](Images/098c0e42de3024d8a8b8c1e5104bdaa2.png)savepage-src="https://static001.geekbang.org/resource/image/65/5c/65b39fae9bece629c567d35055ac7f5c.png"}>  > [图片来源：> > > [https://www.gocd.org/2017/07/25/blue-green-deployments.html> > > >**3. 暗部署** 随着 A/B测试的兴起，暗部署的方式也逐渐流行起来。**所谓暗部署，就是在用户不知道的情况下进行线上验证的一种方法**。比如后端先行的部署方式，把一个包含新功能的接口发布上线，这个时候，由于没有前端导向这个接口，用户并不会真实地调用到这个接口。当用户进行了某些操作后，系统会将用户的流量在后台复制一份并打到新部署的接口上，以验证接口的返回结果和性能是否符合预期。 比如，对于电商业务场景来说，当用户搜索了一个关键字后，后台有两种算法，会给出两种返回结果，然后可以根据用户的实际操作，来验证哪种算法的命中率更高，从而实现了在线的功能验证。 ![](Images/913b14478877fdb832b82f31f746624c.png)savepage-src="https://static001.geekbang.org/resource/image/0b/88/0b723413da42fd5327523ba115d0f088.png"}>  > [图片来源：> > > [https://www.gocd.org/2017/07/25/blue-green-deployments.html> > > >以上这三种低风险发布手段，如果应用规模整体不大，蓝绿部署是提升系统可用性的最好手段，比如各类Hot-standby的解决方案，其实就是蓝绿部署的典型应用。而对于大规模系统来说，考虑到成本和收益，灰度发布显然就成了性价比最高的做法。如果想要跑一些线上的测试收集真实用户反馈，那么，暗部署是一种不错的选择。 线上测试和监控那么，如何验证多种发布模式是正常的呢？核心就在于线上测试和监控了。实际上，在DevOps中有一种全新的理念，那就是：**监控就是一种全量的测试**。 你可能会问，为什么要在线上进行测试？这岂不是非常不安全的行为吗？如果按照以往的做法，你应该做的就是花费大量精力来建立一个全仿真的预发布环境，尽可能地模拟线上环境的内容，以达到验证功能可用性的目标。但只要做过测试的团队就知道，测试环境永远不能替代生产环境，即便在测试环境做再多的回归，到了生产环境，依旧还是会有各种各样的问题。 关于测试环境和生产环境，有一个特别有趣的比喻：测试环境就像动物园，你能在里面看到各种野生动物，它们都活得都挺好的；生产环境就像大自然，你永远无法想象动物园里的动物回到大自然之后会有什么样的行为，它们面临的就是一个完全未知的世界。产生这种差异的原因有很多，比如环境设备的差异、用户行为和流量的差异、依赖服务的差异等，每一个变量都会影响组合的结果。 那么，既然无法事先模拟发布后会遇到的所有场景，该如何做线上验证呢？比较常见的，有三种手段。 **1.采用灰度发布、用户众测等方式，逐步观察用户行为并收集用户数据，以验证新版本的可用性是否符合预期。** 这里的主要实践之一就是**埋点功能**。在互联网产品中，埋点是一种最常用的产品分析和数据采集方法，也是数据驱动决策的主要依据之一。它的价值就在于，根据预先设计的收集和监控数据的方法，采集用户的行为、产品质量、运营数据等多维度的数据。 大型公司一般都实现了自己的埋点SDK，根据产品设计需求，可以自动化地采集数据，并配置采集粒度；对于小公司来说，像**友盟**这种第三方统计工具，就可以满足绝大多数情况的需求了。 **2. 用户反馈。** 除了自动化的采集数据之外，用户主动的反馈也是获取产品信息的第一手资料。而用户反馈的渠道有很多，公司里面一般都有**用户运营和舆情监控系统**，用于按照"关键字"等自动爬取各个主流渠道的产品信息。一旦发现负面的反馈，就第一时间进行止损。 **3. 使用线上流量测试。** 这一点在讲暗部署时我也提到过，最典型的实践就是**流量镜像**。除了做线上的 A/B测试，最常用的就是将线上真实的用户流量复制下来，以实时或者离线的方式回放到预发布环境中用于功能测试。 除此之外，流量镜像还有很多高级的玩法。像是根据需求选择性地过滤一些信息，比如使用只读的查询内容来验证搜索接口。另外，还可以按照倍数放大和缩小流量，以达到服务压测的目的。还有，可以自动比对线上服务和预发布服务的返回结果，以验证相同的流量过来时，两个版本之间系统的行为是否一致。另外，流量镜像的数据可以离线保存，这对于一些偶发的、难以复现的用户问题，提供了非常难得的数据积累，可以帮助研发团队进一步分析，以避免此类问题的再次发生。 在工具层面，我推荐你使用开源的 **GoReplay工具** 。它基于 Go语言实现，作用于 HTTP层，不需要对系统进行大量改造，并且能很好地支持我刚才提到的功能。 快速恢复一旦发现新版本发布后不符合预期，或者有严重的缺陷，最重要的就是尽快控制局面，解决故障。**平均故障修复时长**（MTTR）是 DevOps 的四个核心指标之一，DevOps的质量信心不仅来源于层层的质量门禁和自动化验证，出现问题可以快速定位和修复，也是不可忽视的核心能力之一。 平均故障修复时长可以进一步拆解为平均故障检测时长（MTTD）、平均故障识别诊断时长（MTTI），以及平均故障修复时长（MTTR）。在故障发生后，根据服务可用性指标SLA，对问题进行初步分析定位，明确解决方案。在这个领域，一款好用的线上诊断工具，可以大大地帮助你缓解燃眉之急。比如**阿里的开源工具Arthas**，就可以实时监控堆栈信息、JVM信息，调用参数，查看返回结果，跟踪节点耗时等，甚至还能查看内存占用、反编译源码等，堪称问题诊断利器。 ![](Images/b20ff61ac5d78062ec7e8b900f2f6cde.png)savepage-src="https://static001.geekbang.org/resource/image/6a/0f/6aca9b3215235e21bdd4a87e8e607e0f.jpg"}初步对问题进行分析定位后，你可以有两种选择：**向前修复和向后回滚**。 **向前修复就是快速修改代码并发布一个新版本上线，向后回滚就是将系统部署的应用版本回滚到前一个稳定版本**。无论选择哪一种，考验的都是自动化的部署流水线和自动化的回滚能力，这也是团队发布能力的最佳体现。而在DevOps的结果指标中，部署前置时长描述的恰恰就是这段时长。当然，最佳实践就是自动化的流水线。往往在这个时候，你就会希望流水线更快一些，更自动化一些。 ![](Images/3bcaea96bc3d27562fa956d5b4da5166.png)savepage-src="https://static001.geekbang.org/resource/image/46/7c/467adeb8aa1afc297b7009217c8a627c.png"}最后，再提一点，你可能在很多大会上听过"故障自愈"，也就是出现问题系统可以自动修复。这听起来有点神奇，但实际上，故障自愈的第一步，就要做好**服务降级和兜底策略**。这两个听起来很专业的词是啥意思呢？别着急，我给你举个例子，你就明白了。 我给你截了两张某购物 App的图片，你可以对比看下有什么不同。 ![](Images/fdbf4cd659117bbe5c240a81aa3ca1ef.png)savepage-src="https://static001.geekbang.org/resource/image/ea/65/eaedb72bd38b7811e2af44c2047c2165.png"}如果你仔细看的话，你会发现，单这一个页面就有大大小小 8个差异。所以，**服务降级就是指，在流量高峰的时候，将非主路径上的功能进行临时下线，保证业务的可用性**。典型的做法就是通过**功能开关的方式**来手动或自动地屏蔽一些功能。 ![](Images/45576c1486174f0ba2e5dc6a99873807.png)savepage-src="https://static001.geekbang.org/resource/image/e6/ce/e611e299e35d831ce705bb0c7ef17dce.png"}而兜底策略是指，当极端情况发生时，比如服务不响应、网络连接中断，或者调用服务出现异常的时候，也不会出现崩溃。常见的做法就是缓存和兜底页面，以及前端比较流行的骨架屏等。 总结在这一讲中，我给你介绍了 DevOps模式下质量思想的转变，那就是要在保障一定的质量水平的前提下，尽量加快发布节奏，并通过低风险发布手段，以及线上测试和监控能力，尽早地发现问题，并以一种最简单的手段来快速恢复。 质量活动是有成本的，为了保证快速迭代发布，一定程度的问题发生并不是末日，更重要的是通过质量活动向前向后延伸，并在生产环境加强监控和测试。同时，三种典型的低风险发布方式可以满足不同业务场景的需求。当问题发生时，不仅要做到快速识别，快速修复，还要提前通过服务降级、兜底策略等机制保证系统服务的连续性。 思考题你所在的企业采用了哪些手段来保障部署活动是安全可靠的呢？ 欢迎在留言区写下你的思考和答案，我们一起讨论，共同学习进步。如果你觉得这篇文章对你有所帮助，欢迎你把文章分享给你的朋友。 ![](Images/94ddfb3c31810c68bfd0097449ef5eeb.png)savepage-src="https://static001.geekbang.org/resource/image/7c/33/7c26a9b917677371cf3aac78d949ae33.jpg"}