F. Araujo, G. Ayoade, K. Al-Naami, Y. Gao, K.W. Hamlen, and L. Khan
tpr
Table 3: Detection rates (%) for scripted attack scenarios (PA ≈ 1%)
compared with results from non-deceptive training (parenthesized)
Classifier
Bi-Di OML
91.00 (+13.2) 0.01 (-41.2) 91.14 (+22.2) 90.00 (+30.3) 98.92 (+97.1)
N-Gram OML 65.00 (-19.9) 0.01 (-5.1) 88.58 (+0.0) 80.00 (-8.4) 98.50 (+84.0)
Bi-Di SVM 79.00 (+1.2) 0.78 (-40.5) 89.88 (+20.9) 78.69 (+19.0) 50.57 (+36.1)
N-Gram SVM 92.42 (+7.5) 0.01 (-5.1) 96.89 (+8.3) 93.84 (+5.5) 99.05 (+84.6)
93.63 (+8.8) 0.01 (-5.1) 97.00 (+8.4) 94.89 (+6.5) 99.06 (+84.6)
Ens-SVM
bdr
acc
fpr
F2
tpr
Table 4: Detection rates (%) for red team evaluation (PA ≈ 1%) com-
pared with results from non-deceptive training (parenthesized)
Classifier
bdr
Bi-Di-OML
94.00 (-4.0) 0.39 (-52.6) 93.10 (+23.1) 94.00 (+7.0) 70.88 (+69.1)
Ngram-OML 99.00 (+1.0) 0.01 (-50.0) 99.90 (+26.9) 94.00 (+5.0) 99.01 (+97.1)
Bi-Di-SVM 99.56 (+1.6) 1.15 (-51.9) 99.19 (+29.2) 99.39 (+12.4) 46.65 (+44.8)
N-Gram-SVM 92.25 (-6.75) 0.01 (-50.0) 96.35 (+23.4) 93.70 (+4.7) 98.94 (+97.0)
99.56 (+0.56) 0.01 (-50.0) 99.19 (+26.2) 99.39 (+10.4) 99.02 (+97.1)
Ens-SVM
acc
fpr
F2
Figure 6: Ens-SVM classification tpr for 0–16 attack classes for train-
ing on decoy data and testing on unpatched server data.
Figure 7: False positive rates for various training set sizes
trained with 300 instances from 3 different attack classes. In each
run, the classifier is trained with 1800 normal instances and 100 ∗ n
attack instances with n ∈ [1, 16] attack classes sourced from decoys.
Each run executes ten experiments where the attacks are shuffled
in a cross-validation-like fashion, and the average is reported. This
ensures training is not biased toward any specific attacks.
6.2 Experimental Results
Table 3 measures the accuracy of classifiers that were trained using
deceptive servers, and then tested on attacks against unpatched
servers. Attacks are uniformly distributed across all synthetic attack
classes and variants described in §6.1. Each result is compared (in
parentheses) against the same experiment performed without any
deception. The results show that leveraging deception yields an
8–22% increase in classification accuracy, with an 8–20% increase
in true positives and a 5–41% reduction in false positives. Env-SVM
achieves 97% accuracy with almost no false positives (0.01%).
These significant gains demonstrate that the detection models of
each classifier learned from deception-enhanced data generalize be-
yond data collected in decoys. This showcases the classifier’s ability
to detect previously unseen attack variants. DeepDig thus enables
administrators to add an additional level of protection to their en-
tire network, including hosts that cannot be promptly patched, via
the adoption of a honey-patching methodology.
Figure 6 shows that as the number of training attack classes
(which are proportional to the number of vulnerabilities honey-
patched) increases, a steep improvement in the true positive rate
is observed, reaching an average above 93% for Ens-SVM, while
average false positive rate in all experiments remains low (< 1%).
This demonstrates that deception has a feature-enhancing effect—
the IDS learns from the prolonged adversarial interactions to detect
more attacks.
Testing on an “unknown” vulnerability. We also measured our
approach’s ability to detect a previously unseen, unpatched remote
code execution exploit (CVE-2017-5941) carrying attack payloads
(classes 17–22) resembling the payloads that have been used to ex-
ploit honey-patched vulnerabilities (CVE-2014-6271). In this exper-
iment, CVE-2017-5941 is used as an n-day vulnerability for which
no patch has been applied. The resulting 98.6–99.8% tpr and 0.01–
0.67% fpr show that crook-sourcing helps the classifier learn attack
patterns unavailable at initial deployment, but revealed by deceived
adversaries during decoy interactions, to learn exploits for which
the classifier was not pre-trained.
Red teaming validation. Table 4 summarizes detection accura-
cies against the red team. In this experiment, we incrementally
trained our previously trained model with new attack instances col-
lected from live decoys, and used it to detect human attacks against
unpatched servers. The accuracy rates are much higher against
human opponents than against the synthetic attacks, indicating
that our synthetic data constitutes a challenging test. This may
be in part because replicating the high diversity of the synthetic
attacks would require an extremely large-scale human study.
False alarms. Figure 7 plots the false positive rates for classifiers
that have undergone 30 incremental training iterations, each with
1–30 normal/attack instances per class. With just a few attack in-
stances (≈ 5 per attack class), the false positive rates drop to almost
zero, demonstrating that DeepDig’s continuous feeding back of
attack samples into classifiers greatly reduces false alarms.
6.3 Base Detection Analysis
In this section we measure the success of DeepDig in detecting
intrusions in the realistic scenario where attacks are a small frac-
tion of the interactions. Although risk-level attribution for cyber
attacks is difficult to quantify in general, we use the results of a prior
study [25] to approximate the probability of attack occurrence for
 0 20 40 60 80 100 0 2 4 6 8 10 12 14 16%number of attack classesens-SVM 0 20 40 60 0 5 10 15 20 25 30%number of instances per attack classBi-DiN-Gramens-SVMBi-Di-OMLNgram-OMLImproving Intrusion Detectors by Crook-sourcing
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
server instance are genuine patching lapses and which are de-
ceptions, and it does not distinguish honey-patched servers from
servers that are slowed by any number of other factors (e.g., fewer
computational resources).
7 DISCUSSION
Role of deception. Our approach facilitates supervised learning,
whose widespread use in the domain of intrusion detection has
been impeded by many challenges involving the manual labeling
of attacks and the extraction of security-relevant features [17, 69].
Results demonstrate that even short-term deceptive responses to
cyberattacks can significantly ameliorate both of these challenges.
Just a few strategically chosen honey-patched vulnerabilities accom-
panied by an equally small number of honey-patched applications
provide a machine learning-based IDS sufficient data to perform
substantially more accurate intrusion detection, thereby enhancing
the security of the entire network. This suggests that deception can
and should play a more significant role in machine learning-based
IDS deployments.
Generalization. The results presented in §6 show that our ap-
proach substantially improves the accuracy of intrusion detection,
reducing false alarms to much more practical levels. This is es-
tablished experimentally with moderate- to large-scale synthetic
attacks and a small-scale red teaming study. Future work should
explore larger numbers of attack classes and larger (e.g., industrial
scale) datasets to simulate threats to high-profile targets. Due to
the high-dimensional nature of the collected data, we chose OAML
and SVM in Bi-Di and N-Gram. However, our approach is agnostic
to the feature set and classification model; therefore, future work
should study the effectiveness of deception for enhancing a variety
of learning frameworks.
An avenue of future work is to leverage system call arguments in
addition to the features we collected. A common technique is to use
pairwise similarity between arguments (as sequences) of different
streams [17], and then implement a k-NN (k-Nearest Neighbors)
algorithm with longest common subsequence (LCS) as its distance
metric. Generally, packet- and system-level data are very diverse
and contain other discriminating features that should be explored.
Online training. The flood of data that is continuously streamed
into a typical IDS demands methods that support fast, online clas-
sification. Prior approaches update the classification model incre-
mentally using training batches consisting of one or more training
instances. However, this strategy necessitates frequently re-training
the classifier, and requires a significant number of instances per
training. Future research should investigate more appropriate con-
ditions for re-training the model. Change point detection (CPD) [34]
is one promising approach to determine the optimal re-training
predicate, based on a dynamic sliding window that tracks significant
changes in the incoming data, and therefore resists concept-drift
failures.
Class imbalance. Standard concept-learning IDSes are frequently
challenged with imbalanced datasets [35]. Such class imbalance
problems arise when benign and attack classes are not equally
represented in the training data, since machine learning algorithms
tend to misclassify minority classes. To mitigate the effects of class
imbalance, sampling techniques have been proposed [20], but they
often discard useful data (in the case of under-sampling), or lead to
Figure 8: DeepDig performance overhead measured in average
round-trip times (workload ≈ 500 req/s)
the specific scenario of targeted attacks against business and com-
mercial organizations. The study’s model assumes a determined
attacker leveraging one or more exploits of known vulnerabilities
to penetrate a typical organization’s internal network, and approxi-
mates the prior of a directed attack to PA = 1% (based on real-world
threat statistics).
To estimate the success of intrusion detection, we use a base
detection rate (bdr) [40], expressed using the Bayes theorem:
P(A|D) =
P(A) P(D|A)
P(A) P(D|A) + P(¬A) P(D|¬A)] ,
(5)
where A and D are random variables denoting the occurrence of
a targeted attack and the detection of an attack by the classifier,
respectively. We use tpr and fpr as approximations of P(D|A) and
P(D|¬A), respectively.
The final columns of Tables 3–4 present the bdr for each classifier,
assuming P(A) = PA. The parenthesized comparisons show how
our approach overcomes a significant practical problem in intrusion
detection research: Despite exhibiting high accuracy, typical IDSes
are rendered ineffective when confronted with their extremely
low base detection rates. This is in part due to their inability to
eliminate false positives in operational contexts. In contrast, the
fpr-reducing properties of deception-enhanced defense facilitate
much more effective detection of intrusions in realistic settings,
with bdr increases of up to 97%.
6.4 Monitoring Performance
To assess the performance overhead of DeepDig’s monitoring ca-
pabilities, we used ab (Apache HTTP server benchmarking tool)
to create a massive user workload (more than 5,000 requests in
10 threads) against two web server containers, one deployed with
network and system call monitoring and another unmonitored.
Figure 8 shows the results, where web server response times are
ordered ascendingly. Our measurements show average overheads of
0.2×, 0.4×, and 0.7× for the first 100, 250, and 500 requests, respec-
tively, which is expected given the heavy workload profile imposed
on the server. Since server computation accounts for only about 10%
of overall web site response delay in practice [70], this corresponds
to observable overheads of about 2%, 4%, and 7% (respectively).
While such overhead characterizes feasibility, it is irrelevant to
deception because unpatched, patched, and honey-patched servers
are all slowed equally by the monitoring activity. The overhead
therefore does not reveal which apparent vulnerabilities in a given
 0 10 20 30 40 50 0 50 100 150 200 250 300 350 400 450 500msrequestsmonitoringno monitoringACSAC ’19, December 9–13, 2019, San Juan, PR, USA
F. Araujo, G. Ayoade, K. Al-Naami, Y. Gao, K.W. Hamlen, and L. Khan
poor generalizations (in the case of oversampling). This scarcity of
realistic, balanced datasets has hindered the applicability of machine
learning approaches for web intrusion detection. By feeding back
labeled attack traces into the classifier, DeepDig alleviates this data
drought and enables the generation of adequate, balanced datasets
for classification-based intrusion detection.
Intrusion detection datasets. One of the major challenges in
evaluating intrusion detection systems is the dearth of publicly
available datasets, which is often aggravated by privacy and intel-
lectual property considerations. To mitigate this problem, security
researchers often resort to synthetic dataset generation, which af-
fords the opportunity to design test sets that validate a wide range of
requirements. Nonetheless, a well-recognized challenge in custom
dataset generation is how to capture the multitude of variations and
features manifested in real-world scenarios [11]. Our evaluation
approach builds on recent breakthroughs in dataset generation for
IDS evaluation [13] to create statistically representative workloads
that resemble realistic web traffic, thereby affording the ability to
perform a meaningful evaluation of IDS frameworks.
Establishing a straight comparison of our results to prior work
is frustrated by the fact that the majority of machine learning-
based intrusion detection techniques are still tested on extremely
old datasets [1, 69], and approaches that account for encrypted
traffic are scarce [44]. For instance, recently-proposed SVM-based
approaches for network intrusion detection have reported true
positive rates in the order of 92% for the DARPA/KDD datasets,
with false positive rates averaging 8.2% [54, 82]. Using the model
discussed in §6.3, this corresponds to an approximate base detection
rate of only 11%, in contrast to 99.06% estimated for our approach.
However, the assumptions made by DARPA/KDD do not reflect the
contemporary attack protocols and recent vulnerabilities targeted
in our evaluation, so this might not be a fair comparison. Future
work should consider reevaluating these prior approaches using
updated datasets reflective of modern attacks, for reproducible
comparisons.
8 RELATED WORK
8.1 ML-based Intrusion Detection
Machine learning-based IDSes (cf., [17, 31, 57, 58, 63]) find patterns
that do not conform to expected system behavior, and are typically
classified into host-based and network-based approaches.
Host-based detectors recognize intrusions in the form of anoma-
lous system call trace sequences, in which co-occurrence of events
is key to characterizing malicious behavior. For example, malware
activity and privilege escalation often manifest specific system call
patterns [17]. Seminal work in this area has analogized intrusion
detection via statistical profiling of system events to the human
immune system [29, 36]. This has been followed by a number of
related approaches using histograms to construct profiles of nor-
mal behavior [55]. Another frequently-used approach employs a
sliding window classifier to map sequences of events into individual
output values [21, 78], converting sequential learning into a classic
machine learning problem. More recently, long call sequences have
been studied to detect attacks buried in long execution paths [68].
Network-based approaches detect intrusions using network data.
Since such systems are typically deployed at the network perimeter,
they are designed to find patterns resulting from attacks launched
by external threats, such as attempted disruption or unauthorized
access [11]. Network intrusion detection has been extensively stud-
ied in the literature (cf., [1, 11]). Major approaches can be grouped
into classification-based (e.g., SVM [28], [7], Bayesian network [45]),
information-theoretic [51], and statistical [46–48] techniques.
Network-based intrusion detection systems can monitor a large
number of hosts at relatively low cost, but they are usually opaque
to local or encrypted attacks. On the other hand, intrusion detection
systems operating at the host level have complete visibility of mali-
cious events, despite encrypted network payloads and obfuscation
mechanisms [43]. Our approach therefore complements existing
techniques and incorporates host- and network-based features to
offer protective capabilities that can resist attacker evasion strate-
gies and detect malicious activity bound to different layers of the
software stack.
Another related area of research is web-based malware detection
that identifies drive-by-download attacks using static analysis, dy-
namic analysis, and machine learning [16, 42]. In addition, other
studies focus on flow-based malware detection by extracting fea-
tures from proxy-logs and using machine learning [10].
8.2 Cyber-Deception in Intrusion Detection
Honeypots are information systems resources conceived to attract,
detect, and gather attack information [71]. They are designed such
that any interaction with a honeypot is likely to be malicious.
Shadow honeypots [3] are a hybrid approach in which a front-
end anomaly detection system forwards suspicious requests to a
back-end instrumented copy of the target application, which vali-