Finally, we describe an attack using similar techniques
against the Apache HTTP Server. While previous attacks have
focused on Nginx, MTB and proﬁling are general and can be
applied to other targets. Arbitrary process execution can be
achieved on the Apache web server using a similar approach:
1) Use proﬁling to ﬁnd the indirect code pointer of the
exec-like function ap_get_exec_line.
2) Use MTB to corrupt a function pointer to point at
ap_get_exec_line and cause an exec call under
attacker control.
For the sake of brevity, we describe the details of this attack
in Appendix B.
All exploits succeeded in control hijacking while Apache
and Nginx were protected by full-featured Readactor. Note
that Turing completeness is trivially provided if the inputs to
exec() or system() can be compromised. An example of
this is in Nginx Attack 2, where we leverage an exec() call
made by Nginx to execute a reverse shell written in python.
V. GENERALITY OF AOCR ATTACKS
The sophisticated exploitation techniques discussed in this
paper may provide the impression that opportunities for such ex-
ploits are rare. We argue that, in fact, the exploitable constructs
are very common in real-world code bases. Code pointers
are extremely common in any production-level application or
server, so the opportunities for leaking indirect code pointers
are almost certainly present too. It is also a common idiom in
C to pass around structs ﬁlled with function pointers as a way
to perform dynamic dispatch, which also provides additional
code pointers.
We also argue that the MTB technique used to facilitate
the exploits is both optional and surprisingly easy to ﬁnd.
A. Necessity of MTB
In our exploits, we leveraged MTB to simplify the identiﬁ-
cation of the open() callstack. MTB allowed us to assume
that at the time of our probe Nginx or Apache was blocked
immediately before a system call, reducing the set of possible
callstacks to less than 10 and providing unlimited time to read
the stack. This allowed us to proﬁle a pointer to the open()
system call in seconds.
While MTB makes proﬁling substantially easier, it is not
required to successfully perform such an attack. The attack
can succeed even if the targeted thread was still running.
However, instead of having to identify the open() callstack
out of approximately 10 possibilities, the attacker would have
to identify it out of potentially hundreds of possibilities. To
quantify the difﬁculty of such an attack we captured a sample
of stack traces, and analyzed whether an attacker is still able
to identify a targeted function call.
Therefore, we ran Nginx under Linux perf tools in
sampling mode, and captured 2,500 samples of the callstack
(approximately 200 unique) over a period of 10 seconds. Of
those 2,500 sampled callstacks, about 12 samples (∼0.5%) were
the targeted open() callstack from our attack. Without MTB,
the application might modify the stack during a probe. An
attacker can tolerate this by repeating the probes to conﬁrm the
results. Given this small adjustment, we found that our proﬁling
attack (see Section III-A) is still effective in identifying the
open() callstacks without generating false-positives.
B. Applicability of MTB
While MTB utilizes mutexes to exert control over a target, it
is important to note that this does not mean a program needs to
rely on mutexes to be vulnerable to MTB. In fact, in our exploits,
we do not target a mutex used by Nginx. Instead we target a
mutex used by glibc. Due to the use of mutexes by glibc to
implement POSIX compliance, any application that both (1) is
multithreaded and (2) performs I/O is potentially vulnerable. As
threads are used to perform I/O without blocking an applications
execution, this makes MTB applicable to a very large variety
of server applications. In fact, on Linux, performing I/O on
threads is essentially the only way to achieve non-blocking ﬁle
I/O (Nginx claims performance improvements of up to 9x by
simply enabling threaded I/O).
Furthermore, it is not necessary for an application to
be explicitly multi-threaded. There are many situations in
which application frameworks make use of threads internally,
unbeknownst to the application. Examples of this include (1)
libuv: the framework for asynchronous I/O. Used in projects
such as node.js and the Julia language, libuv implements
all ﬁle operations via a thread pool; (2) OpenJDK:
the
open source implementation of the Java Platform, Standard
Edition. OpenJDK implements asynchronous I/O via a thread
pool; (3) glibc: the POSIX asynchronous I/O functions (e.g.
aio_read()) are implemented with glibc-internal threads and
mutexes. Thus, even seemingly single-threaded applications
may be vulnerable simply due to underlying frameworks
creating threads.
VI. X-ONLY IMPLEMENTATION CHALLENGES
Up until this point, we assumed an ideal and comprehensive
implementation of execute-only memory that our AOCR
attack can bypass. However, actually achieving such an ideal
and comprehensive implementation is surprisingly difﬁcult in
practice. Leaky code pointer protection is not the only challenge
facing code randomization defenses. Modern operating systems
such as UNIX-based systems provide a myriad of facilities
that can potentially leak protected memory to an attacker. In
this section, we brieﬂy discuss two such vectors that are hard
to mitigate and are in fact unprotected in the execute-only
defenses that we studied. The ﬁrst, Direct Memory Access
(DMA), offers attackers the potential to bypass execute-only
protection by abusing memory access and leaking code directly.
Unlike related work that focuses on abusing DMA via malicious
hardware devices, we discuss an attack that is a form of the
confused deputy attack through which an application can fool
the system to make malicious DMA requests on its behalf
using software-only attacks. The second vector is the proc
ﬁlesystem in Linux that can potentially leak information about
execute-only memory. Preventing this vector is hard because
disabling it would break many benign applications.
If these vectors are available, an attacker can use them
to leak code pages directly, and does not have to resort to
AOCR techniques. We discuss them here to further illustrate
the challenges of effectively preventing CRA attacks in complex,
modern systems.
A. Forged Direct Memory Access Attack
Execute-only defenses protect code pages from direct read
accesses by applying additional permissions to memory pages in
software [3] or hardware [15, 22]. This enforcement, however,
applies only to regular memory accesses (i.e., TLB-mediated).
Accesses performed by devices capable of Direct Memory
Access (DMA), e.g., GPUs, disk drives, and network cards, do
not undergo translation by the MMU and are unaffected by
page permission. We call these accesses “non-TLB-mediated.”
The idea of exploiting systems via DMA is well studied, es-
pecially in the context of DMA-capable interfaces with external
connectors, e.g., IEEE 1394 “Firewire” and Thunderbolt.
As described in the threat model (Section II), we are mainly
concerned about a remote attacker. For that, the attacker must
be able to perform software-based DMA from a userspace appli-
cation. Typically, user space applications cannot directly make
requests to DMA-capable devices. However, some user space
functionality is implemented via the kernel requesting a device
to perform DMA against a userspace-controlled address. Ex-
amples of this include OpenCL’s CL_MEM_USE_HOST_PTR
ﬂag and Linux’s O_DIRECT ﬂag.
An attacker can use Linux’s O_DIRECT ﬂag to maliciously
request software-based DMA to bypass execute-only memory
permissions, thus alleviating the need for compromised pe-
ripheral devices or hardware attacks. We call such an attack
a Forged DMA (FDMA) attack which is a form of confused
deputy attack, and brieﬂy demonstrate its feasibility. The novelty
of FDMA is its broad applicability remotely and from user
space applications. Unlike well-studied DMA attacks such the
one used in bypassing Xen [62], FDMA does not require a
malicious device or kernel permissions.
9
Applications that use the O_DIRECT ﬂag natively are
vulnerable to our FDMA attack. More surprisingly though,
even applications that never use the O_DIRECT ﬂag, but pass
the ﬂags to ﬁle read or write operations through a ﬂags variable
residing in data memory are also vulnerable to this attack. An
attacker can perform a simple data-only attack to maliciously
change the ﬂag variable to O_DIRECT in order to force a
regular ﬁle operation to become a DMA access.
We investigated the prevalence of direct I/O and ﬂags vari-
ables is in popular real-world software packages. Our analysis
focused on Internet-facing web servers (AOLserver, Apache,
Boa, lighttpd, Nginx, OpenSSH, Squid, and Firebird) due to
their exposure and database managers (Hypertable, MariaDB,
Memcached, MongoDB, MySQL, PostgreSQL, Redis, and
SQLite) due to their focus on fast I/O. The results indicate that
the majority of web servers and database managers (13 out of
16) do not natively use the O_DIRECT ﬂag; however, 10 out
of 16 of them (AOLserver, Nginx, OpenSSH, Squid, Firebird,
Hypertable, MongoDB, MySQL, PostgreSQL, and SQLite) use
variables to store ﬂags that can be corrupted by an attacker
to set the O_DIRECT ﬂag. As such, an attacker can use an
FDMA attack in these applications to read execute-only code
pages to build a conventional ROP attack even in the presence
of execute-only defenses. The FDMA attack would obviate
the exploit, and does not require an AOCR attack to bypass
execute-only memory permissions.
B. Procfs Attack
The proc ﬁlesystem is another implementation challenge
that can obviate execute-only bypasses.
The proc ﬁlesystem is a ﬁle-like structure that contains
information about each process. It is implemented for a variety
of UNIX-like operating systems [20, 32]. In this paper, we
focus on the Linux implementation of procfs [10].
The Linux kernel creates a directory for each process that
can be accessed via /proc//. Processes can
access their own directory via /proc/self/. The ﬁles within
the procfs directory are, for the most part, treated in the
same way as any other ﬁle in a ﬁlesystem. They have ownership
settings and assigned permissions, and are accessed via the
same mechanisms as any other ﬁle. Through them, a wealth
of information about the process is made available: details
about program invocation, processing status, memory access,
ﬁle descriptors, networking, and other internal details.
Several of
the procfs ﬁles
(e.g., auxv, maps,
numa_maps, pagemaps, smaps, stat, syscall,
exe, stack, and task) include memory addresses that
reveal information about the randomized code layout. The
mem ﬁle even allows direct disclosure of the process memory
regardless of memory permissions.
To carry out a procfs attack, the attacker needs to (1)
discover the location of a suitable piece of executable memory,
and (2) leak executable memory directly by corrupting the
filename argument to a ﬁle read operation. The maps and
smaps ﬁles provide, among other things, the starting and
ending addresses of each mapped memory region, along with
that region’s memory permissions and the ﬁle (if any) with
which the region is associated. After that, reading the mem ﬁle
10
directly leaks the executable regions. Note that even when the
vulnerability does not allow arbitrary ﬁle reads, the procfs
attack can be mounted by performing a data-only corruption
on any ﬁle read operation.
The procfs attack also allows a leakage of the actual
code pointers followed by a traditional ROP attack, without
requiring the sophistication of an AOCR attack.
Because procfs is baked into the Linux ecosystem as the
needed native interface for many system utilities and programs,
removing or otherwise blocking access to it would disrupt a
major kernel API and break a Linux distribution. Fundamental
Linux command-line tools depend on access to procfs, most
notably free, kill, pkill, pgrap, pmap, ps, pwdx,
skill, slabtop, snice, sysctl, tload, top, uptime,
vmstat, w, and watch. Similarly, additional programs in
GNU coreutils and binutils, and the util-linux package make
use of procfs. Debuggers like gdb and system monitoring
tools like nmon are among the many other programs reliant
upon the continued functionality of procfs.
The exposed nature of procfs has long been recognized
and attacks proposed to exploit it especially with regard to
differential privacy [30, 64]. Although it cannot be removed
entirely due to the above-mentioned concerns, some defenses
have attempted to restrict access to procfs. For example,
GRSecurity’s kernel patchset [55] has several conﬁguration
options to restrict access to procfs entries by user or group,
with the intent that different critical processes can run as
different users and be unable to compromise other processes.
One recent defense [63] proposes falsifying information in
procfs to mitigate other types of attacks.
However, these defenses focus on blocking other processes’
access to the procfs of a given process; they do not prevent
access by a process to its own procfs entry set, and any
ﬁner-grained procfs restriction by username would result
in breaking benign applications. As such, effectively securing
procfs without breaking benign applications remains an open
research problem.
IMPACT ON LEAKAGE-RESILIENT DEFENSES
VII.
Defenses that do not provide leakage resilience are trivially
vulnerable to AOCR and weaker forms of information leakage.
Therefore, we focus on those that offer (some) resilience.
Direct leakage refers to attacks that read code pages, while
indirect leakage refers to attacks that leak code addresses
from the stack or heap during execution. Since AOCR attacks
leak hidden or indirection (e.g., trampoline) pointers indirectly
from the stack or heap, they are a form of indirect leakage
attacks. Also, since non-TLB-mediated leakages directly read
code pages (using mechanisms not protected by memory
permissions), they are a form of direct information leakage.
Accordingly, there are four sub-classes of information leakage:
direct leakage via TLB-mediated code reads, direct leakage
via non-TLB-mediated code reads, indirect leakage of code
pointers, and indirect leakage of indirect code pointers.
Our attacks are applicable to randomization defenses
regardless of the granularity or type of randomization. For
example, various randomization defenses propose library-level,
function-level, or instruction-level randomization approaches.
TABLE I.
DEFENSES PROTECTING AGAINST DIFFERENT CLASSES OF INFORMATION LEAKAGE ATTACKS
Defenses
TLB-Mediated
(e.g., buffer over-read [56])
Non-TLB-Mediated
(e.g., DMA§ VI)
Code Pointer Leaks
(e.g., Ret addr. leak [17])
Indirect Code Pointer Leaks
(e.g., AOCR § III)
Direct Leaks
Indirect Leaks
PointGuard [14]
Oxymoron [4]
Isomeron [17]
XnR [3]
HideM [22]
Readactor [15, 16]
Heisenbyte [58]
NEAR [61]
ASLR-Guard [38]
TASR [7]
In AOCR, we abuse and chain indirect code pointers to achieve
control-ﬂow hijacking. Regardless of how the underlying code
has been randomized, as long as the semantics remain intact,
our proﬁling attack remain applicable. In attacks that use
implementation challenges (FDMA), the exact contents of code
pages are read (via non-TLB-mediated accesses), so regardless
of the how intrusive the randomization is, we can disclose the
randomized code and perform a conventional ROP attack.
Table I summarizes leakage-resilient randomization defenses
and their vulnerabilities to various types of attacks. We brieﬂy