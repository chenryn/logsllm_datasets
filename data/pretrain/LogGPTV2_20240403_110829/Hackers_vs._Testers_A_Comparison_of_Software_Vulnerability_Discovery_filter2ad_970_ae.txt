no matter their likelihood vs. value calculation.
Estimating likelihood. Because most modern code bases are
very large, both populations expressed the need to triage which
program components to search based on the likelihood of
ﬁnding a vulnerability. Both populations described several
similar heuristics for this. First, practitioners focus on code
segments that they expect were not heavily tested previously
(T=5, H=11). H7W, for example, considers where developers
are “not paying attention to it [security] as much.”
Next, testers and hackers look at parts of the code where
multiple bugs were previously reported (T=3, H=9). As T2W
said, “There were issues with those areas anyway. . . so I ﬁgured
that that was probably where there was most likely to be
security issues. . . bugs cluster.”
Both populations mentioned situations when code is new
(e.g., rushed to release to ﬁx a major feature issue) (T=5,
H=5), or when they do not think the developers understand the
underlying systems they are using (e.g., they noticed an odd
implementation of a standard feature) (T=1, H=3). Additionally,
some hackers also looked at old code (e.g., developed prior to
the company performing stringent security checks) (T=0, H=7)
and features that are rarely used (T=0, H=3).
Testers determine value by impact to company. As we
would expect, testers determine value by estimating the negative
effect to the company if exploited (T=8, H=3) or if the program
fails a mandated audit (e.g., HIPAA, FERPA) (T=4, H=0).
Because of this motivation, they tend to focus on features that
are most commonly used by their user base (T=2) and areas of
the code that handle sensitive data (e.g., passwords, ﬁnancial
data) (T=8). T5W said he considers “usage of the site, [that
is] how many people are going to be on a certain page or
certain area of the site, [and] what’s on the page itself, [such
as] forms” to determine where a successful attack would have
the most impact.
Hackers maximize expected payout using several strategies.
Previous research has shown that hackers are more likely to
participate in a program whenever the bounties are higher [17],
and bounty prices increase with vulnerability severity [16]. We
also observed that hackers cite the size of the bounty payout
as their key motivator; however, we found that hackers follow
one of two strategies when deciding how to best maximize
their collective payouts.
384
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:29:31 UTC from IEEE Xplore.  Restrictions apply. 
developers agree with their assessment of severity. Participants
deﬁned importance as a function of the business impact on
the company (T=8, H=3), how much control the vulnerability
gives the attacker (e.g., limited data leakage vs. arbitrary code
execution) (T=3, H=6), and how easily an attacker can exploit
the vulnerability (T=2, H=6). T10W said ,“You need to be
able to express not only what the problem is and where the
problem lies, but also how this could be used to do X amount of
damage.” Additionally, some hackers discussed spending time
after ﬁnding a vulnerability to understand the full implications
of the issue (T=0, H=4). H9G said “When I ﬁnd an issue, I
don’t necessarily rush to the developer. . . I could probably chain
the vulnerability to other vulnerabilities to be more impactful
and more impressive. . . [and] I get paid more, which is certainly
a factor.”
Our practitioners also emphasized the need to make their
reports easy for developers to understand by considering the
technical and security background of their audience (T=7,
H=11). As T2W stated, when “there’s not enough experience
with security across the [development] team, I tend to give
them more information to make it easier.” Some practitioners
also use phrasing and wording that are easy to read (T=4, H=5).
T1W said he checks to see if “I missed anything grammar-
wise. . . does it have proper ﬂow?” If he thinks it might be hard
to read, he “pull[s] another tester and say[s], ‘Hey, does this
make sense?’ ” In some cases, practitioners use a ﬁxed format
(T=6, H=3) so that developers know where to look for speciﬁc
information based on previous reports or by looking at the
headings. Finally, many participants discussed maintaining an
open-minded, respectful tone when discussing the vulnerability
to avoid triggering a defensive response (T=8, H=5). T2W
stressed the importance of respectful tone, saying, “Probably the
biggest thing is keeping it factual and neutral. Some developers
take any [report] as an attack on their ability to code.”
VII. DISCUSSION AND RECOMMENDATIONS
Our key ﬁndings can be summarized as follows:
• The two factors most critical to vulnerability discover suc-
cess are vulnerability discovery experience and underlying
system knowledge.
• Both hackers and testers typically develop sufﬁcient sys-
tem knowledge through their employment and interactions
with their community.
• Although hackers and testers develop vulnerability dis-
covery experience through similar means, hackers are
exposed to a wider variety of programs and vulnerabilities
through the different types of employments, exercises, and
communities they are involved in and the more diverse
bug reports they read. This provides hackers an important
advantage over testers.
• Access to the development process is a mixed blessing.
Access facilitates reporting for testers by building rapport
and shared language, but “outsider by design” status allows
hackers to recognize mistaken assumptions.
• Hackers attempting to maximize value typically pursue
one of two strategies: identify “low-hanging fruit” quickly
or develop a deep knowledge advantage.
With these ﬁndings in mind, we suggest recommendations for
organizations and individuals involved in software vulnerability
discovery and directions for future work.
A. Training in the workplace
Our results suggest that extending testers’ vulnerability
discovery experience will improve their efﬁcacy at ﬁnding
vulnerabilities before release. We suggest two approaches for
use within testers’ existing work context; we also recommend
future work to explore how to expand that context.
Security champions. Many of our testers described learning
from more experienced testers (T=8). As a ﬁrst change, we
recommend hiring a small number (one or two) hackers to
work alongside testers, highlighting potential vulnerabilities and
sharing security-testing techniques. Deliberately introducing
hackers to the team should cultivate learning opportunities.
T8H discussed the success of this approach in her organization,
saying, “I had two gentlemen. . . who were really into security
testing. . . . They eventually went on to create a whole new
security team.
. . . Most of my security testing is all from
what I’ve learned from them.” T8H emphasized that this
effort, which began with two testers experienced in security
pointing out problems to their less experienced co-workers, led
within three years to development of a company-wide security
consciousness. Further, she said that external security reviews
of their product now ﬁnd many fewer vulnerabilities than they
did prior to introducing security champions.
Bug-report-based exercises. Many of our testers spend time
discussing interesting bugs found by their peers in regular
training sessions (T=7). However, simply discussing a vulner-
ability does not allow the hands-on practice our participants
considered necessary. Instead, we suggest hands-on training
based on vulnerabilities previously found in the company’s
code, either via formal exercises or simply by asking testers
to search the pre-ﬁx code and try to ﬁnd the vulnerability (as
suggested by H1H in Section VI-A2. Such exercises will allow
testers not only to learn about different vulnerabilities, but also
to gain practical experience looking for them.
Future work to increase variety of experiences. The afore-
mentioned approaches, however, will still only expose testers
to a limited range of vulnerabilities within the program(s) on
which they work. Further research is required to determine
the best way to provide broader exposure to testers. Many
of our testers participate in internal hacking exercises (T=6),
but it was not clear why they do not participate in external
exercises. Prior research has found that these exercises typically
require a signiﬁcant time commitment and prior knowledge,
which we hypothesize are not a good ﬁt for testers [103], [104].
One possible solution is to create tailored CTFs with hints
that slowly introduce new concepts, as some CTFs currently
do [105]. This approach is referred to as “scaffolding” in
385
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:29:31 UTC from IEEE Xplore.  Restrictions apply. 
education literature and provides students the necessary support
to allow learning and avoid despair [106].
Similarly, many testers cited internal bug reports as a learning
source (T=6), but they do not spend time reading external
reports like hackers do (T=1, H=13). One possible reason
could be that it is difﬁcult to ﬁnd vulnerability reports without
knowing the correct online resources to consult. Currently bug
reports are dispersed among corporate vulnerability disclosure
sites [81], [86], [107], personal GitHub repos [108], community
mailing lists [109], and public vulnerability databases [110],
[111]. Creating a single aggregated repository or searchable
source for bug reports and discovery tutorials, and pointing
testers to it, could expose testers to a wider range of informa-
tion.
Further work should evaluate these techniques and develop
others to encourage testers to expand the variety of their
vulnerability discovery experience.
B. Hacker-developer relationships
While improving testers’ vulnerability-ﬁnding skills could
meaningfully improve security, companies will likely still
need security experts to ﬁnd the most complex problems.
Unfortunately, many of our hackers described difﬁculties
communicating with developers, resulting in their ﬁndings
either not being accepted or not being ﬁxed properly (T=9).
To solve this challenge, we look to learn from the strengths of
our testers.
Establish consistent relationships early. We found that testers
have an advantage in the reporting phase because they have built
a relationship with developers through their inherent access to
the development process. Additionally, the two hackers who
mentioned cultivating a close relationship with a particular
company described similar beneﬁts. We therefore recommend
companies make efforts to build relationships with hackers as
early as possible.
First, we recommend that organizations maintain a consistent
point of contact with hackers, so that any time a hacker reports
a vulnerability, they communicate with the same person and
build a shared language, understanding, and trust. Obviously,
a single point of contact is not always useful because a hacker
may only report one vulnerability. In these cases, it is important
for companies to be as open as possible when providing
requirements and expectations to the hacker. Some potential
improvements might be to provide more detailed templates and
examples of effective reporting, to give feedback or ratings
on (speciﬁc sections of) reports and how they did or didn’t
help developers, and answer hacker questions throughout the
process to avoid confusion.
Further, our results support industry-wide standardization of
vulnerability reporting procedures. This includes agreeing on
report templates, “good” reporting examples, and vulnerability
deﬁnitions. Standardizing expectations and vocabulary should
provide consistency across programs and reduce the burden to
build individual relationships with each company.
Hackers as security advocates. Additionally, further work
is needed to understand how hackers can best convey the
importance of a vulnerability, given limited communication
channels and time to inﬂuence developer decisions. Future
research should therefore focus on improving hacker reporting
through improved resources and training. For example, a
centralized repository of real-world cases where an attacker
has exploited a vulnerability that hackers can use as examples
could help with demonstrating a vulnerability’s importance.
Relatedly, Haney and Lutter suggest providing hackers with
formal training in how to best advocate for cybersecurity within
complex organizational and structural environments [100].
C. Tailor compensation to motivation
Assuming we can improve testers’ vulnerability discovery
skills so they can ﬁnd a greater number of relatively simple
vulnerabilities, bug bounty policies should be adjusted to focus
hacker searches on more challenging vulnerabilities. Based on
our results, we suggest two possible bug bounty policy changes
below. Further research is necessary to evaluate the efﬁcacy of
these changes in real-world settings.
Adjust payout structure as security posture matures. Ini-
tially, a company could offer high payouts for all vulnerabilities,
attracting hackers via a high likelihood-to-value ratio. This
higher participation will likely generate a large number of bug
reports that testers can learn from. As the company grows
more security-mature internally, it may be possible to reduce
payouts for low-level vulnerabilities and shift these funds to
pay for more complex vulnerabilities. Further, they may wish
to reward hacker specialization by offering bonuses for ﬁnding
multiple vulnerabilities.
Use non-monetary motivators. In addition to increasing
monetary funding, companies can also take advantage of non-
monetary motivators to increase the overall payout without com-
mitting additional dollars. Most bounties already take advantage
of recognition and fun through the use of leaderboards or “walls
of fame” as well as the innate enjoyment our participants report
deriving from ﬁnding a vulnerability. However, companies
should also consider the negative effects of their actions during
the reporting process, such as delaying or not publishing a
report due to company politics (T=0, H=2) or dismissing the
report without providing sufﬁcient feedback (T=7, H=9). These
actions depress the recognition and enjoyment value for the
hacker. Companies can take advantage of hackers’ altruistic
tendencies by indicating the impact an exploited vulnerability
could have on the affected user base in the project’s description.
Finally, companies could attract hackers seeking personal
growth by highlighting skills that could be developed while
looking for vulnerabilities and offering online resources to
support learning.
ACKNOWLEDGMENTS
We thank Michael Hicks and the anonymous reviewers for
their helpful feedback; the two major bug bounty platform
companies and the many CTF teams and testing groups that
supported our recruitment efforts; and Cynthia Wu and the DC
386
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:29:31 UTC from IEEE Xplore.  Restrictions apply. 
Agile Software Testing Group for providing valuable insights
into the world of software testing.
REFERENCES
[1] Y. Shoshitaishvili, M. Weissbacher, L. Dresel, C. Salls, R. Wang,
C. Kruegel, and G. Vigna, “Rise of the hacrs: Augmenting autonomous
cyber reasoning systems with human assistance,” in Proc. of the 24th
ACM SIGSAC Conference on Computer and Communications Security,
ser. CCS ’17. ACM, 2017.
[2] N. Rutar, C. B. Almazan, and J. S. Foster, “A comparison of bug
ﬁnding tools for java,” in Proc. of the 15th International Symposium
on Software Reliability Engineering, ser. ISSRE ’04.
IEEE Computer
Society, 2004, pp. 245–256.
[3] D. Baca, B. Carlsson, K. Petersen, and L. Lundberg, “Improving
software security with static automated code analysis in an industry
setting.” Software: Practice and Experience, vol. 43, no. 3, pp. 259–279,
2013.
[4] A. Doupé, M. Cova, and G. Vigna, “Why johnny can’t pentest: An
analysis of black-box web vulnerability scanners,” in Proc. of the 7th
International Conference on Detection of Intrusions and Malware, and
Vulnerability Assessment, ser. DIMVA’10. Springer-Verlag, 2010, pp.
111–131.
[5] A. Austin and L. Williams, “One technique is not enough: A comparison
of vulnerability discovery techniques,” in Proc. of the Fifth International
Symposium on Empirical Software Engineering and Measurement, ser.
ESEM ’11.
IEEE Computer Society, 2011, pp. 97–106.
[6] N. Antunes and M. Vieira, “Comparing the effectiveness of penetration
testing and static code analysis on the detection of sql injection
vulnerabilities in web services,” in Proc. of the 2009 15th IEEE Paciﬁc
Rim International Symposium on Dependable Computing, ser. PRDC
’09.
IEEE Computer Society, 2009, pp. 301–306.
[7] L. Suto, “Analyzing the effectiveness and coverage of web application
security scanners,” BeyondTrust, Inc, Tech. Rep., 2007. [Online]. Avail-
able: https://www.beyondtrust.com/resources/white-paper/analyzing-the-
effectiveness-and-coverage-of-web-application-security-scanners/
[8] L. Suto, “Analyzing the accuracy and time costs of web application
security scanners,” BeyondTrust, Inc, Tech. Rep., 2010. [Online]. Avail-
able: https://www.beyondtrust.com/wp-content/uploads/Analyzing-the-
Accuracy-and-Time-Costs-of-Web-Application-Security-Scanners.pdf
[9] G. McGraw and J. Steven, “Software [in]security: Comparing apples,
oranges, and aardvarks (or, all static analysis tools are not created
equal,” Cigital, 2011, (Accessed 02-26-2017). [Online]. Available:
http://www.informit.com/articles/article.aspx?p=1680863
[10] A. Edmundson, B. Holtkamp, E. Rivera, M. Finifter, A. Mettler, and
D. Wagner, “An empirical study on the effectiveness of security code
review,” in Proc. of the 5th International Conference on Engineering
Secure Software and Systems, ser. ESSoS’13. Springer-Verlag, 2013,
pp. 197–212.