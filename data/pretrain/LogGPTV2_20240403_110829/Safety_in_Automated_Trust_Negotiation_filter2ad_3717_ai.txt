Let init(G) be given by G = (cid:4)K G, EG, AckG, ACG, LG(cid:5) and let init(G(cid:3)) be given
G, AckG(cid:3), ACG, LG(cid:3)(cid:5). We begin by showing AckG(cid:3)
by G(cid:3) = (cid:4)K G, E
(cid:3)
is the same as
AckG and LG = LG(cid:3). By assumption, AckG (K .r)
is nontrivial if, and only
if, AckG(cid:3) (K .r)
is nontrivial, for each attribute K .r. So step (1) of init collects
the same delegation credentials in both cases. Because AckG is identical to
AckG(cid:3) , the delegation credential graph does not depend on G and the dummy
attributes introduced in step 2 are uniquely determined, it follows that AckG(cid:3)
is the same as AckG . Thus AckG(K .r) is nontrivial if, and only if, AckG(cid:3)(K .r) is
nontrivial, and consequently, step 3 collects the same delegation credentials in
both cases. So LG = LG(cid:3), as desired.
Next we use induction on i ∈ [1, (cid:5)] to show that the response sequence
[m1, m2, . . . , m(cid:5)] generated by using G is identical to the response sequence
(cid:3)
(cid:3)
(cid:3)
(cid:5)] generated by using G(cid:3). We simultaneously show that except
[m
1, m
2, . . . , m
for the conﬁgurations they contain, the sequences of states [q1, q2, . . . , q(cid:5)] and
(cid:3)
(cid:3)
(cid:3)
(cid:5)] used in the construction of the respective message sequences are
1, q
2, . . . , q
[q
also identical.
(cid:3)
(cid:3)
i, m
i
(cid:5) = replyttg(q
Base case. Because AckG is identical to AckG(cid:3) , the state q1 produced by
(cid:3)
startttg(G, ρ, K A) is the same as the state q
1 produced by startttg(G, ρ, K A). It fol-
(cid:3)
lows that the messages m1 and m
1 produced by each of the respective functions
are also the same.
Induction step. We must show that for i ∈ [2, (cid:5)], assuming mi−1 = m
(cid:3)
i−1 and
i−1 differ only in their conﬁgurations, then (cid:4)qi, mi(cid:5) = replyttg(qi−1, ai−1)
(cid:3)
that qi−1 q
is the same as (cid:4)q
(cid:3)
i−1, ai−1), again, except for the conﬁgurations
in the states. To do this, we use an inner induction on the iterations of the loop in
the deﬁnition of replyttgto show that in corresponding iterations, the values of ttg
and outmsg obtained by using G, are the same as the values obtained by using
(cid:3)
, which we denote by ttg(cid:3) and outmsg(cid:3). The base case is straightforward: the
G
(cid:3)
outer induction assumption tells us that ttgold and ttg
old are the same, so in the
(cid:3)
third line of replyttg, apply(ai−1.ops, ttgold) is the same as apply(ai−1.ops, ttg
old) ;
the output messages outmsg and outmsg(cid:3) are both empty lists.
For the inner induction step, we assume that the TTGs and output messages
are the same at the top of the loop, and show that they are again the same
at the bottom. Because choice is deterministic, it is sufﬁcient to show that
, K A, ttg(cid:3)). This, together
candidates(G, K A, ttg) is the same as candidates(G
with the fact that the TTGs are again the same at the bottom, will show that
each of the two negotiations terminate the loop at the same point. This will
complete the proof.
, K A, ttg(cid:3)) by
We show that candidates(G, K A, ttg) is the same as candidates(G
considering each node in the TTGs and each processing rule that might be used
(cid:3)
(cid:3)
ACM Transactions on Information and System Security, Vol. 9, No. 3, August 2006.
388
•
W. H. Winsborough and N. Li
to process it, and by showing that (each instance of) the rule applies when using
conﬁguration G if, and only if, it applies when using conﬁguration G(cid:3). In the
following paragraphs we consider the opponent-side processing rules; cases are
labeled according to node-processing rule. The veriﬁer-side processing rules are
similar.
Case 1(a) In this case AckG(K .r) is trivially satisﬁed, which means that no
member of UnAcks(G, M )
is reachable from K .r in the delegation credential
graph. (This follows from step 2 of init.) So K .r ←− K O ∈ EG if, and only if,
K .r ←− K O ∈ releaseable(E, UnAcks(G, M )). This, in turn, holds if, and only
if, K .r ←− K O ∈ releaseable(EG(cid:3), UnAcks(G, M )), by the theorem’s hypothe-
ses. Finally, K .r ←− K O ∈ releaseable(EG(cid:3), UnAcks(G, M )) holds if, and only
if, K .r ←− K O ∈ EG(cid:3), again because no member of UnAcks(G, M ) is reachable
from K .r.
Case 1(b) We have already argued that LG = LG(cid:3), so rule 1(b) applies to ttg if,
and only if, it applies to ttg(cid:3).
Case 1(c) The satisfaction state of nodes is uniquely determined by the struc-
ture of the TTG and the processing state of nodes in it. By induction hypothesis,
at the top of the loop ttg and ttg(cid:3) are identical in structure, including in the pro-
cessing state of each node. It follows that the satisfaction state of T is the same
in the two TTGs. Moreover, since ttg and ttg(cid:3) are identical, for each node, the
same instances of 1(a) and 1(b) can be and have been applied to that node in
ttg as in ttg(cid:3). (We say a rule “has been applied” if performing the rule does not
change the TTG.)
Case 2(a) Because AckG = AckG(cid:3), the same instances of this rule apply when
using G as when using G(cid:3).
Case 2(b) Since ttg and ttg(cid:3) are identical, for each node, the same instances of
2(a) can be and have been applied to that node in ttg as in ttg(cid:3). An argument sim-
ilar to that used in case 1(c) shows that the satisfaction state of (cid:4)K O :eAck
?(cid:2) K V(cid:5)
is the same in ttg as in ttg(cid:3). In the case that the satisfaction state is unknown,
rule 2(b) applies neither using G nor using G(cid:3). If it is satisﬁed, it follows by
Proposition 4.1 that M has attributes that satisfy AckG(K .r), which tells us
that no element of UnAcks(G, M )
is reachable from K .r in the delegation
credential graph. Thus, as we showed in case 1(a), K .r ←− K O ∈ EG if, and
only if, K .r ←− K O ∈ EG(cid:3). So the same instances of rule 2(b) apply using G as
using G(cid:3).
Case 2(c) Since ttg and ttg(cid:3) are identical, for each node, the same instances of
2(a) can be and have been applied to that node in ttg as in ttg(cid:3). As in case 2(b),
?(cid:2) K V(cid:5) is the same in the two TTGs. We have
the satisfaction state of (cid:4)K O :eAck
argued above that LG = LG(cid:3). So the same instances of rule 2(c) apply in ttg
using G as apply in ttg(cid:3) using G(cid:3).
Case 2(d) Since the two graphs are identical, the same instances of 2(a), 2(b),
and 2(c) apply to ttg as apply to ttg(cid:3), each rule instance has been applied to ttg
if, and only if, it has been applied to ttg(cid:3). So the rule 2(d) can be applied to ttg
if, and only if, it can be applied to ttg(cid:3).
ACM Transactions on Information and System Security, Vol. 9, No. 3, August 2006.
Safety in Automated Trust Negotiation
•
389
ACKNOWLEDGMENTS
Both authors are supported by NSF ITR grant CCR-0325951 (BYU). We thank
the anonymous reviewers for their many helpful suggestions.
REFERENCES
BLAZE, M., FEIGENBAUM, J., AND LACY, J. 1996. Decentralized trust management. In Proceedings of
the 1996 IEEE Symposium on Security and Privacy. IEEE Computer Society Press, Piscataway,
New Jersey. 164–173.
BONATTI, P. AND SAMARATI, P. 2000. Regulating service access and information release on the web.
In Proceedings of the 7th ACM Conference on Computer and Communications Security (CCS-7).
ACM Press, New York. 134–143.
BONATTI, P., KRAUS, S., AND SUBRAHMANIAN, V. S. 1995. Foundations of secure deductive databases.
Knowledge and Data Engineering 7, 3, 406–422.
DOMINGO-FERRER, J., Ed. 2002.
Inference Control in Statistical Databases, From Theory to Prac-
tice. Lecture Notes in Computer Science, vol. 2316. Springer-Verlag, New York.
GOGUEN, J. AND MESEGUER, J. 1982. Security policies and security models. In Proceedings of the
1982 IEEE Symposium on Security and Privacy. IEEE Computer Society Press, Piscataway, New
Jersey. 11–20.
GOLDREICH, O. 2001. The foundations of cryptography—Vol. 1: Basic tools. Cambridge University
Press, Cambridge.
HERZBERG, A., MASS, Y., MIHAELI, J., NAOR, D., AND RAVID, Y. 2000. Access control meets public key
infrastructure, or: Assigning roles to strangers. In Proceedings of the 2000 IEEE Symposium on
Security and Privacy. IEEE Computer Society Press, Piscataway, New Jersey. 2–14.
HESS, A., JACOBSON, J., MILLS, H., WAMSLEY, R., SEAMONS, K. E., AND SMITH, B. 2002. Advanced
client/server authentication in TLS. In Network and Distributed System Security Symposium.
203–214.
HOLT, J. E., BRADSHAW, R. W., SEAMONS, K. E., AND ORMAN, H. 2003. Hidden credentials. In Proceed-
ings of the 2nd ACM Workshop on Privacy in the Electronic Society.
LI, J., LI, N., AND WINSBOROUGH, W. H. 2005. Automated trust negotiation using cryptographic cre-
dentials. In CCS ’05: Proceedings of the 12th ACM conference on Computer and communications
security. ACM Press, New York. 46–57.
LI, N., MITCHELL, J. C., AND WINSBOROUGH, W. H. 2002. Design of a role-based trust management
framework. In Proceedings of the 2002 IEEE Symposium on Security and Privacy. IEEE Com-
puter Society Press, Piscataway, New Jersey. 114–130.
LI, N., DU, W., AND BONEH, D. 2003a. Oblivious signature-based envelope. In Proceedings of the
22nd ACM Symposium on Principles of Distributed Computing (PODC 2003). ACM Press, New
York.
LI, N., GROSOF, B. N., AND FEIGENBAUM, J. 2003b. Delegation Logic: A logic-based approach to
distributed authorization. ACM Transactions on Information and System Security (TISSEC) 6, 1
(Feb.), 128–171.
LI, N., WINSBOROUGH, W. H., AND MITCHELL, J. C. 2003c. Distributed credential chain discovery in
trust management. Journal of Computer Security 11, 1 (Feb.), 35–86.
RIVEST, R. L., SHAMIR, A., AND ADLEMAN, L. M. 1978. A method for obtaining digital signatures and
public-key cryptosystems. Communications of the ACM 21, 120–126.
SEAMONS, K. E., WINSLETT, M., AND YU, T. 2001. Limiting the disclosure of access control poli-
cies during automated trust negotiation. In Proceedings of the Symposium on Network and Dis-
tributed System Security (NDSS’01).
SEAMONS, K. E., WINSLETT, M., YU, T., YU, L., AND JARVIS, R. 2002. Protecting privacy during on-line
trust negotiation. In 2nd Workshop on Privacy Enhancing Technologies. Springer-Verlag, New
York.
STADDON, J. 2003. Dynamic inference control. In Proceedings of the 8th ACM SIGMOD Workshop
on Research issues in data mining and knowledge discovery. ACM Press, New York. 94–100.
SUTHERLAND, D. 1986. A model of information. In Proceedings of the 9th National Computer Se-
curity Conference. 175–183.
ACM Transactions on Information and System Security, Vol. 9, No. 3, August 2006.
390
•
W. H. Winsborough and N. Li
WANG, L., WIJESEKERA, D., AND JAJODIA, S. 2003. Cardinality-based inference control in data cubes.
Journal of Computer Security 12, 5 (Sept. 2004), 655–692.
WINSBOROUGH, W. H. AND LI, N. 2002a. Protecting sensitive attributes in automated trust nego-
tiation. In Proceedings of the ACM Workshop on Privacy in the Electronic Society. ACM Press,
New York, 41–51.
WINSBOROUGH, W. H. AND LI, N. 2002b. Towards practical automated trust negotiation. In Pro-
ceedings of the Third International Workshop on Policies for Distributed Systems and Networks
(Policy 2002). IEEE Computer Society Press, Piscataway, New Jersey. 92–103.
WINSBOROUGH, W. H., SEAMONS, K. E., AND JONES, V. E. 2000. Automated trust negotiation. In
DARPA Information Survivability Conference and Exposition. Vol. I. IEEE Press, Piscataway,
New Jersey. 88–102.
WINSLETT, M., YU, T., SEAMONS, K. E., HESS, A., JACOBSON, J., JARVIS, R., SMITH, B., AND YU, L. 2002.
Negotiating trust on the web. IEEE Internet Computing 6, 6 (Nov./Dec.), 30–37.
YU, T. AND WINSLETT, M. 2003a. Policy migration for sensitive credentials in trust negotiation. In
Proceedings of the ACM Workshop on Privacy in the Electronic Society. ACM Press, New York.
9–20.
YU, T. AND WINSLETT, M. 2003b. Uniﬁed scheme for resource protection in automated trust ne-
gotiation. In Proceedings of IEEE Symposium on Security and Privacy. IEEE Computer Society
Press, Piscataway, New Jersey. 110–122.
YU, T., MA, X., AND WINSLETT, M. 2000. Prunes: An efﬁcient and complete strategy for trust nego-
tiation over the internet. In Proceedings of the 7th ACM Conference on Computer and Commu-
nications Security (CCS-7). ACM Press, 210–219.
YU, T., WINSLETT, M., AND SEAMONS, K. E. 2003. Supporting structured credentials and sensitive
policies through interoperable strategies for automated trust negotiation. ACM Transactions on
Information and System Security (TISSEC) 6, 1 (Feb.), 1–42.
Received May 2004; revised July 2005; accepted April 2006
ACM Transactions on Information and System Security, Vol. 9, No. 3, August 2006.