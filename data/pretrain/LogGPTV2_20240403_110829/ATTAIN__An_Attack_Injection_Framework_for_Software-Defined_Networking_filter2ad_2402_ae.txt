### Experimental Setup and Results

#### Timing and Actions
- **t = 30 s:**
  - **h2 pings h1 for 10 s:** This represents an external user accessing an external network host.
  - **h6 pings h1 for 10 s concurrently:** This represents an internal user accessing an external network host.

- **t = 50 s:**
  - **h2 pings h3 for 60 s:** This represents an external user accessing an internal network host.

- **t = 95 s:**
  - **h6 pings h1 for 10 s again:** This represents an internal user accessing an external network host.

#### Results
Table II summarizes the results of the connection interruption experiment. For each controller implementation, we evaluated the attack in both fail-safe and fail-secure scenarios. We examined the security metrics for unauthorized increased access incidents in the data plane for external users attempting to access internal network hosts and denial of service incidents for internal users attempting to access external network hosts after the connection interruption.

- **Fail-Safe Cases:**
  - The DMZ firewall switch defaulted to a learning switch mode, operating independently of the controller. While this allowed internal users to access external network hosts, it also permitted external users to access internal network hosts, representing unauthorized increased access.

- **Fail-Secure Cases:**
  - In most cases (except for Ryu), the DMZ firewall switch prevented new flows from being created. This prevented external users from accessing internal network hosts but also blocked internal users from accessing external network hosts, leading to a data plane denial of service against legitimate traffic.
  - **Ryu Exception:**
    - Ryu did not trigger rule φ2 due to its differently specified flow match attributes, so the attack never entered state σ3.

### Table II: Connection Interruption Experiment Results
| Scenario | External User Accesses External Host (t = 30 s) | Internal User Accesses External Host (t = 30 s) | External User Accesses Internal Host (t = 50 s) | Internal User Accesses External Host (t = 95 s) |
|----------|------------------------------------------------|-----------------------------------------------|------------------------------------------------|------------------------------------------------|
| Floodlight/OVS | Secure | Safe | No | No |
| POX/OVS | Secure | Safe | No | No |
| Ryu/OVS | Secure | Safe | Yes | Yes |

The results indicate a trade-off between allowing increased access and creating a denial of service when control plane connections are interrupted.

### Memory Footprint Optimization
By using a counter value in the conditional expression `EXAMINEFRONT(δcounter) = n`, the memory footprint of the attack description is significantly reduced from O(n) to O(1) attack states.

### Discussion

#### Language Expressiveness
Our attack language allows practitioners to express more sophisticated attacks than those discussed in Section VII. Examples include:

- **Message Reordering Attack:**
  - Store messages in a deque δ acting like a stack, insert messages using `PREPEND(δ, m)` |M| times ∀m ∈ M, and retrieve and send messages in reverse order using `SHIFT(δ)` and `PASSMESSAGE` actions |M| times.

- **Message Replay and Flooding Attacks:**
  - Store messages in a deque δ acting like a queue, use `DUPLICATEMESSAGE` and `PREPEND(δ, m)` actions to duplicate and store message copies |M| times ∀m ∈ M, and later use `POP(δ)` and `PASSMESSAGE` actions to replay messages in FIFO order |M| times. Flooding can be implemented similarly.

Our language currently implements deterministic attacks, but future work will consider stochastic and adaptive decision-making.

#### Modeling Efficiency
Using storage objects, practitioners can efficiently model repetitive actions with significantly less memory. For example, an attack requiring n instances of a particular message can use a deque `δcounter` of length 1 to represent a counter variable, condensing this portion into one attack state. Incrementing the counter can be done through the action `PREPEND(δcounter, SHIFT(δcounter) + 1)`.

#### Distributed Injection
The runtime injector imposes a total ordering of control plane events due to its centralized nature. In a distributed runtime injector architecture, total ordering could be imposed through distributed systems techniques, but this may increase latency and affect attack results if messages depend on physical time guarantees. Future work will address total ordering, timing, and consistency model challenges.

### Related Work

#### SDN Security, Troubleshooting, and Debugging
- **DELTA [5]:** A vulnerability detection tool for SDN that fuzz-tests control protocol messages. ATTAIN extends this approach with a standardized language for writing attack descriptions.
- **Scott-Hayward et al. [21]:** Classify SDN security issues and attacks by affected layers and effects.
- **Kl¨oti et al. [22]:** Use the STRIDE methodology to analyze OpenFlow protocol security, assuming the controller is adequately secured, which is tunable in ATTAIN’s attack model.
- **Hong et al. [9]:** Propose novel SDN attacks that can be written in the ATTAIN attack language.
- **OFRewind [23]:** Records control and data plane events for replay during troubleshooting.
- **OFf [24]:** Interfaces with open-source controllers for debugging but requires library additions to the controller source code.
- **OFTest [25]:** Validates switches for OpenFlow compliance, while ATTAIN includes multiple switches and controllers with reusable attack descriptions.

#### Fault and Attack Injection
- **AJECT [26, 27]:** Generates test cases based on a user-specified protocol specification and simulates attacks on an application protocol.
- **Loki [28]:** Uses a partial view of the global system state for injections but requires software modifications for probing.

### Conclusion
We proposed ATTAIN, an attack injection framework for testing the security and performance of OpenFlow-based SDN architectures. Our framework allows practitioners to model systems and attacker capabilities, specify reusable attack descriptions, and actuate runtime attacks. We evaluated ATTAIN with two attacks, finding different manifestations in control and data planes across implementations. Future work will focus on attack language abstractions and exploring the security assumptions in SDN implementations.

### Acknowledgment
We thank Jenny Applequist for editorial assistance and members of the PERFORM Group for feedback. This work was supported by the Army Research Office under Award No. W911NF-13-1-0086 and the Air Force Research Laboratory and Air Force Office of Scientific Research under agreement number FA8750-11-2-0084.

### References
[References listed as in the original text]

---

This optimized version aims to improve clarity, coherence, and professionalism, making the content easier to understand and follow.