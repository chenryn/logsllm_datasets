 **Is this a request for help?** (If yes, you should use our troubleshooting
guide and community support channels, see
http://kubernetes.io/docs/troubleshooting/.):
I'm hoping that this issue will resolve the problem I'm seeing.
**What keywords did you search in Kubernetes issues before filing this one?**
(If you have found any duplicates, you should instead reply there.):
`deployment`, `replica set`, `OldReplicaSets`
* * *
**Is this a BUG REPORT or FEATURE REQUEST?** (choose one):
Bug report
**Kubernetes version** (use `kubectl version`):
    Client Version: version.Info{Major:"1", Minor:"4", GitVersion:"v1.4.4", GitCommit:"3b417cc4ccd1b8f38ff9ec96bb50a81ca0ea9d56", GitTreeState:"clean", BuildDate:"2016-10-21T02:48:38Z", GoVersion:"go1.7.1", Compiler:"gc", Platform:"darwin/amd64"}
    Server Version: version.Info{Major:"1", Minor:"4", GitVersion:"v1.4.5", GitCommit:"5a0a696437ad35c133c0c8493f7e9d22b0f9b81b", GitTreeState:"clean", BuildDate:"2016-10-29T01:32:42Z", GoVersion:"go1.6.3", Compiler:"gc", Platform:"linux/amd64"}
**Environment** :
Google Container Engine
**What happened** :
I ran `kubectl apply -f` as usual to apply any changes to Deployment, Service,
Ingress resources. The deployment did not create a new replica set with the
updated container image. Going to the Kubernetes Dashboard I can confirm that
the deployment was correctly updated with the new metadata.
The only difference when this issue started happening was a small code change.
I've tried multiple updates since and nothing changed. The nodes were on
version 1.4.0 but I've tried updating them to 1.4.5 but still the same issue
is happening.
The old pods are still operational and serving requests normally.
**What you expected to happen** :
The deployment should have created a new replica set with three pods, then
rolled them out.
**How to reproduce it** (as minimally and precisely as possible):
I don't know.
**Anything else do we need to know** :
I've attached a file with the deployment's current configuration, as well as
the deploy script I use to deploy: files.zip
Here's the output of `kubectl describe`:
    $ kubectl describe deployment/fika-io
    Name:			fika-io
    Namespace:		default
    CreationTimestamp:	Sun, 16 Oct 2016 10:58:42 -0400
    Labels:			app=fika-io
    Selector:		app=fika-io
    Replicas:		3 updated | 3 total | 3 available | 0 unavailable
    StrategyType:		RollingUpdate
    MinReadySeconds:	0
    RollingUpdateStrategy:	1 max unavailable, 1 max surge
    OldReplicaSets:		fika-io-749979362 (3/3 replicas created)
    NewReplicaSet:		
    No events.
Note that there is no `NewReplicaSet`.