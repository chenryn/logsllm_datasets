a
D
t
e
s
a
t
a
D
0.1
0.1
0.2
k = 0.005
k = 0.01
k = 0.015
k = 0.02
62.01
13218
72161
4112.7
232689
249344
86.16
9895.7
40301
6166.4
82449
94.12
6726
24952
8227.1
86034
186891
115664
100.69
8901.6
20381
13105
175203
103929
Section 5.3, and compare its accuracy with a baseline his-
togram method. For comparison purpose, we empirically
choose the optimal bin width for the histogram method3.
That is, for each query range, we computer the mean square
error for k = 0.0025 to 0.04 with a step of 0.0025, and
choose the smallest error among them. Part of the errors
are shown in Table 5. Figure 4 shows the details of the ex-
periment result. For example, when the queries is of size
0.1, the mean square error of the baseline method is 6726,
3
The step of revealing the optimal bin width could reveal more infor-
mation and thus the whole process may not be diﬀerentially private.
Nevertheless, it can serve as a baseline to compare the performance
of the purposed mechanisms.
where as with the construction under 0.001-neighbourhood
is 543, and with 0.0001-neighbourhood is 109. By exploiting
δ-neighbourhood, we can achieve signiﬁcantly higher utility.
For example, in dataset 1, the utility improves by a factor
of 100 with 4km-neighbourhood, while many existing mech-
anisms can only improve the result by a factor of 2 [25, 3].
Note that our notion is orthogonal to existing techniques,
and thus potentially could be combined to attain higher u-
tility.
5.5 Other Publishing Mechanisms
For some mechanisms, it is easier to apply the notion of
In this Section we analyze their perfor-
δ-neighbourhood.
mance under δ-neighbourhood.
5.5.1 Publishing Sorted 1D Points
Fang et al. [9] propose a method of publishing 1D his-
togram by directly publishing the sorted point. The sensi-
tivity of this mechanism depends on the size of the domain,
say m.
Under δ-neighbourhood, the sensitivity of the publishing
method is reduced to δm and therefore the Laplace noise
required to achieve ϵ-diﬀerential privacy is reduced from
Lap(m/ϵ) to Lap(mδ/ϵ). Thus, there is signiﬁcant improve-
ment when applying the publishing method as it is. Figure
5 shows the improvement for expected mean square error for
range query of 10,000 runs for each range size.
Although the error is signiﬁcantly decreased (the factor of
improvement on mean square error is approximately (1/δ2)
00.20.40.60.810.20.40.60.8100.20.40.60.8100.20.40.60.8100.20.40.60.8100.20.40.60.8100.050.10.150.20.250.30.350.4102104106108Range widthMean square errorBaseline histogramHistogram with 0.001−neighbourhoodHistogram with 0.0001−neighbourhood00.050.10.150.20.250.30.350.4103104105106107108Range widthMean square errorBaseline histogramHistogram with 0.001−neighbourhoodHistogram with 0.0001−neighbourhood00.050.10.150.20.250.30.350.4103104105106107108Range widthMean square errorBaseline histogramHistogram with 0.01−neighbourhoodHistogram with 0.001−neighbourhood165for δ-neighbourhood), it is not clear how to generalize the
construction to higher dimensions. The method of using
locality preserving transformation as described by Fang et
al. [9] would not help since here we are required to preserve
locality in the “diﬃcult” direction.
Figure 5: Average error for range query.
Figure 6: Average error for median.
5.5.2 Publishing Median
Publishing median diﬀerentially privately is technically
challenging. To publish the median of a set of 1D points
in [0, m], a noise of Lap(m/ϵ) is required, although for most
database instances, the “local sensitivity” is low, i.e. chang-
ing any element in that particular database instance will
not signiﬁcantly change the value of the median. Nissim
et al. [18] proposed a method that adds noise proportion-
al to the “smooth sensitivity” (a smooth bound of the local
sensitivity) of a database instance. He showed that this
mechanism has high accuracy when the smooth sensitivity
is low.
The δ-neighbourhood can further reduce the noise require-
ment when “local sensitivity” can be still large. With δ-
neighbourhood, we can reduce the global sensitivity, and
thus bound the smooth sensitivity for some worst case s-
cenarios. Figure 6 shows the noise required to publish the
median of a synthesized dataset with random 1D points gen-
erated under the exponential distribution and then scaled to
[0, 1]. For each size of the dataset, we repeat the process 300
times and the average smooth sensitivity is recorded under
diﬀerent neighbourhood deﬁnitions.
6. DYNAMIC DATASETS
We now investigate dynamic datasets. Consider situations
where information on entities are collected periodically over
time, say at discrete time 1, 2 . . .. Occasionally, statistics
are to be published. Intuitively, with limited budget, it is
impossible to continuously publish meaningful information
indeﬁnitely, in fact, Dwork et al. [7] showed a negative result
under a setting that captures this intuition. However, in
some scenarios, the entities are not required to contribute
at all collection times, and are likely to leave within a short
period. With such restriction, it should be now possible to
continuously publish with low noise indeﬁnitely, as eﬀect of
information contributed earlier would diminish in time.
6.1 Example 1
One situation where publishing dynamic dataset can ben-
eﬁt from δ-neighbourhood is when sensitive information on-
ly last for a short period. Consider a regional ﬂu response
organization who wants to continuously collect daily infor-
mation on the health conditions of visitors, and release the
information occasionally. Alice wants to infer whether Bob
has been to the region based on the released information.
If the publishing mechanism A is ϵ-diﬀerential privacy, then
Alice’s inference is bounded by:
P r(A(D0 + {x}) ∈ R) ≤ exp(2ϵ)P r(A(D0) ∈ R),
where x is Bob’s information. If all visitors must leave with-
in 14 days, then x must be near the source, i.e. d(x,⊥) < 14
days, otherwise the dataset is invalid. Hence, under this con-
straint on the datasets, the guarantee under the standard
neighbourhood and δ-neighbourhood are equivalent.
6.2 Example 2
Let us revisit Example 1. Suppose the authority allows
some visitors to stay for a longer period, say 28 days, even
if the dataset is published under 14-neighbourhood, there is
still protection. If Bob indeed stayed for 28 days, the bound
is relaxed to exp(2ϵ). Hence, similar to the spatial datasets,
the protection is being redistributed with more protection
to entities with shorter stay.
6.3 Formulation
Let a sequence x1, x2, . . . be the data contributed by an
entity, where each xi ∈ U + {⊥} is the data contributed at
time i, with U being the domain of the contributed data,
and ⊥ being a special symbol indicating that the entity is
not contributing at that time. Let us call a sequence con-
taining only the symbol ⊥ a null sequence. A dataset D
is a set of the aforementioned sequences. We assume that
every entity in D has contributed a data in U at some time,
and thus D does not contain null sequence. The preﬁx of
a sequence x contains data contributed by the entity up to
time n, denoted x[1..n], where n is the length of the preﬁx.
Let us denote D[1..n] the set of such preﬁxes in D that are
not null sequence. In addition, denote Dn the set of all n-th
elements of the sequences in D that is not ⊥, that is, Dn
contains all data contributed at time n.
At certain time, say time t, some information on Dt is
to be published. We assume that information is published
at any time i, and let Ai be the publishing mechanism em-
ployed at time i. Hence, the data published are A1(D1),
A2(D2), . . .. Combining all the data published before time
0.050.10.150.20.250.30.350.40.450.5104105106107Range widthMean Square ErrorStandard neigbhourhood0.1−neighbourhood10203040506070809010000.0020.0040.0060.0080.010.012Dataset sizeSmooth sensitivityStandard neighbourhood0.02−neighbourhood0.005−neighbourhood166ϵ-diﬀerential privacy. In general, we say that a mechanism
achieves sustainable diﬀerential privacy when the factor in
the assurance is bounded by a constant independent of n.
7. PUBLISHING DYNAMIC DATASET: AL-
LOCATING BUDGET
The privacy requirement ϵ is often called the privacy bud-
get as it can be divided between and allocated to a group
of mechanisms. As shown in section 6.5, sustainable ϵ-
diﬀerential privacy can be achieved by ensuring budget spent
in any sliding window is bounded by ϵ (Theorem 2). There
are many ways to allocate the budget over the time window
and yet achieving sustainable privacy. An interesting ques-
tion is on how to allocate the budget ϵi to the mechanism
Ai at each time i, so as to minimize the “total error”.
1 (wiErri(ϵi)), where
Err(·) is a non-negative function quantifying the error in-
curred by the mechanism Ai in term of the budget, and the
non-negative weight wi gives the weightage of the query at
time i. A zero weight at time i, i.e. wi = 0, corresponds
to the event that no publishing is required at time i. Now,
given a weightage w = ⟨w1, . . . , wn⟩ and the privacy require-
ment, we want to ﬁnd an allocation of the budget ϵi so as
to minimize the total error.
We consider total error of the form
∑
n
We consider two settings. Under the oﬄine setting, the
publisher knows all the weights at time 0, and hence the pub-
lisher can determine the allocation before publishing. This
setting could be unrealistic in scenarios where the publisher
does not know the queries in advance. Under the online set-
ting, the value of wi is only known at time i and the budget
ϵi has to be committed before time t + 1.
7.1 Ofﬂine Allocation
The oﬄine budget allocation problem can be formulated
as the following optimization problem:
Problem 1 Oﬄine Budget Allocation
Given:
Find:
Minimize:
Subject to:
i=1
δ ∈ Zn, ϵ, w = ⟨w1 . . . wn⟩ ∈ Rn≥0
n∑
⟨ϵ1, ϵ2, . . . , ϵn⟩
wiErri(ϵi)
δ∑
i=1
ϵk+i ≤ ϵ, for k = 1, 2, . . . , (n − δ).
′
n+1, we can treat the “eﬀects” of mechanisms A1,A2, . . . ,An
as a single mechanism A∗
6.4
n that operates on D[1..n].
(cid:14)-Neighbour on Dynamic Dataset
′
′
Given two datasets, D and D
, or D +{x} = D
are δ-neighbourhood if, and only if D + {x} = D
, under the standard neigh-
bourhood, they are neighbours if, and only if they diﬀer
by one entity. That is, there is a sequence x and y s.t.
D +{x} = D
+{y}. This is essentially the
same notion of neighbourhood for user-level privacy studied
by Dwork et al. [7][8].
For two sequences x = ⟨x1, x2, . . .⟩ and y = ⟨y1, y2, . . .⟩,
let us deﬁne d(x, y) to be the value is − it where is is the
̸= yis and it is the largest index
smallest index s.t. xis
̸= yit . That is, it is the length of the smallest
s.t. xit
consecutive subsequence that contains all the diﬀerences.
We take the null sequence as the source. Hence, D and
′
D
, or
D + {y} = D
+ {z}, for some y, z s.t. d(y, z) ≤ δ, or
some x s.t. d(x, ˆ⊥) ≤ δ where ˆ⊥ denotes the null sequence.
When δ = 1, then providing diﬀerential privacy under δ-
neighbourhood is same as the event-level privacy studied by
Dwork et al. [7].
6.5 Sustainable Differential Privacy
If each mechanism Ai is ϵ-diﬀerentially private under ei-
ther notions of neighbourhood, then the mechanism A∗
n is
(nϵ)-diﬀerentially private under the respective neighbour-
hood. However, for δ-neighbourhood, we should be able to
“reuse” the budget spent on much earlier published data.
This observation is formulated in the following theorem:
′
′
Theorem 2 Let D be a dynamic dataset with the mecha-
n, A1, A2, . . .An as deﬁned above in Section 6.3. If
nism A∗
mechanism Ai is ϵi-diﬀerentially private under the standard
δ∑
neighbourhood for each i ∈ {1, . . . , n}, and
ϵk+i ≤ ϵ,
for k ∈ {0, 1, . . . , (n − δ)},
i=1
Proof. Consider two datasets D and D
then A∗
n is ϵ-diﬀerentially private under δ-neighbourhood.
′
+
{y} = D + {x} and d(x, y) ≤ δ. Let is be the smallest
index at which x and y diﬀer. Consider an output a =
⟨a1, a2 . . . an⟩ of A∗
n(D), we have the probability that A∗
gives the same output on dataset D
, where D
as:
n
′
′