on a large “exclusion” zone around the target node and randomly
set their own coordinates outside this zone to try and attract honest
nodes out of the exclusion zone. Note that an attacker always uses
the same coordinate when lying to a given honest node.
5.2.1 Detection Method Performance
Figure 10: True positive test fraction.
true positives is constantly high, regardless of the signiﬁcance level
chosen, for moderate to quite signiﬁcant proportions of malicious
nodes in the population (up to 20% of malicious nodes). However,
thereafter the proportion of correct positive tests starts to decrease,
although the rate of decrease is inversely proportional to the sig-
niﬁcance level used. This is because a higher signiﬁcance level
produces more positive tests, catching most malicious embedding
steps, and so many more false positives are needed to make up a
signiﬁcant proportion of these. In light of this, a signiﬁcance level
of 5% offers a good compromise.
Figure 11: False Positive Rate.
Figure 12: False negative rate.
Figures 11 and 12 show the false positive and negative rates re-
spectively. As expected, a higher signiﬁcance level results in a
more aggressive test that incorrectly classiﬁes a larger portion of
Figure 9: ROC curves. Each tick on the plots corresponds to a
different value of the test’s signiﬁcance level (α).
To evaluate the efﬁciency of the test, we ﬁrst plot in ﬁgure 9,
ROC (Receiver Operation Characteristics) curves observed for dif-
ferent signiﬁcance levels (α) and several intensities of attacks.
These plots show, for each signiﬁcance level4, the point corre-
sponding to the false positive rate along the x-axis and to the true
positive rate along the y-axis, with one curve per malicious group
size. Obviously, the closer to the upper left corner of the graph a
curve is, the better, since such points correspond to high true posi-
tive rates (i.e. a high proportion of positives being reported as such
by the test) for low false positive rates (i.e. a small proportion of
negatives incorrectly reported as positives). We observe that from
this perspective, the detection method can be considered to be ex-
cellent for 20% of malicious nodes or less, and still performs well
even under heavy attack of up to about 30% of malicious nodes,
while the power of the detection method naturally decreases as the
malicious population becomes more signiﬁcant. Another interest-
ing properties of ROC curves is that they show the optimal range
for the signiﬁcance level. Indeed, as the slope of the ROC curve
ﬂattens, the increase in true positive rate is proportionally smaller
than the corresponding increase in false positives. In other words, a
higher signiﬁcance level, although it always increases the true pos-
itive rate of the test, is not always productive as it eventually does
more bad than good through increased false positive rates (i.e. the
proportion of normal embedding steps that are aborted increases).
This means that the signiﬁcance level of the test should be set to a
value that yields a point in the “elbow” of the ROC curve. Based
on ﬁgure 9, we can deduce that a signiﬁcance level of 5% seems to
be a good compromise.
Figure 10 shows the true positive test fraction of the detection
method for various test signiﬁcance levels under various intensity
of attacks. We see that the proportion of positive tests that are
4Signiﬁcance level values α always increase as a ROC curve is
“followed” from the origin. In our experiments, we used values of
1%, 3%, 5% and 10% for α.
5.3 Securing NPS
To test our proposed detection method in the context of the NPS
coordinate system, we chose to study the effects of colluding iso-
lation attack as described in [11]. The malicious nodes cooper-
ate with each other and behave in a correct and honest way until
enough of them become reference points at each layer. As soon as
a minimum number of malicious reference points has been reached
(in our experiments this number is set to 5) in a layer, these at-
tackers identify a common set of victims (50% of the normal nodes
they know from the layer directly below). When involved in the
positioning of their victims, the malicious nodes agree to pretend
they are all clustered into a remote (far away) part of the coordinate
space and try and push the victims into a remote location at the
”opposite” of where the attackers pretend to be, in order to isolate
the victims from the other nodes in the coordinate space. In order
to evade detection, including the basic detection method proposed
in NPS and which is always turned on in our experiments, the ma-
licious nodes use the sophisticated anti-detection method proposed
in [11] during their attacks.
5.3.1 Detection Method Performance
normal embedding steps (ﬁgure 11) as malicious, while a more le-
nient test (lower signiﬁcance level) wrongly reports a higher pro-
portion of malicious embedding steps as normal (ﬁgure 12).
Incorrect test results do have a negative impact on the embedding
system: false positives artiﬁcially reduce the size of available nor-
mal nodes that can be used for normal embedding; false negatives
give malicious nodes opportunities to corrupt and distort the coor-
dinate space, which can propagate through the system and result in
a greater proportion of normal nodes being identiﬁed as malicious
(false positives) because of mis-positioning. This is exempliﬁed
in ﬁgure 11, where the false positive rate increases faster, as the
population of malicious nodes increases, for lower values of the
signiﬁcance level of the test. Also, despite the fact that the false
negative rate curves (ﬁgure 12) clearly exhibit negative slopes, one
should note that these rates decrease much slower than the increase
in malicious population. That is to say that as the number of mali-
cious nodes in the system increases, the number of false negatives
does increase, and more damage is incurred in the coordinate space.
Although the accuracy of coordinate systems increases with the
number of participating nodes, false negatives can therefore have a
greater impact on the system than false positives and should there-
fore be thwarted in priority. As the false negative rates exhibited by
tests with signiﬁcance levels of 5% and 10% are roughly similar,
while the more aggressive test yields proportionally a higher false
positive rate, the signiﬁcance level of 5% is a good compromise.
5.2.2 Embedding System Performance
From section 5.2.1, it should be clear that a signiﬁcance level
of 5% gives the overall best test performance. We therefore set the
signiﬁcance level to this value and assess the resistance of a Vivaldi
system under various intensity of attacks.
Figure 13: Distribution of measured relative errors.
The cumulative distribution function of the measured relative er-
rors, across all normal nodes, after convergence (in the sense of
error convergence as deﬁned in [12]) is shown in ﬁgure 13 (for the
time being, ignore the curve entitled ”Using Dedicated Surveyors
for Embedding”). We see that the detection mechanism renders
the system practically immune to the attack, when the proportion
of malicious nodes is 30%, or less, of the overall node population.
Although the system does indeed show degraded performance for
higher intensities of malicious attacks, the steeper slope of the CDF
with detection, compared to the corresponding curve without (e.g.
curves for 50% of malicious nodes), shows that the detection mech-
anism is not completely overwhelmed and still offers good protec-
tion by signiﬁcantly reducing the impact of the attack.
Figure 14: ROC curves.
Figure 14 shows the ROC curves for the detection test in NPS.
These curves show characteristics similar to those observed in the
Vivaldi system (see section 5.2.1), albeit slightly better. In particu-
lar, these curves show that the detection method withstands heavier
attacks better in NPS than in Vivaldi.
There are several reasons for this. First, the basic detection
method in NPS works in concert with our own, providing greater
opportunities to identify malicious behavior. Also, by its very na-
ture, the embedding method in NPS is less prone to mis-positioning
error propagation amongst normal nodes, as nodes in the lower
layer do not take part in the embedding of other nodes. And ﬁ-
nally, by design, the attack considered in this section makes fewer
victims than that studied in section 5.2 (i.e. 50% of normal nodes
as victims vs 100% in Vivaldi).
The same observation is also true for the false positive and false
negative rates (not shown) with again, overall, a signiﬁcance level
of 5% seemingly offering the best compromise between “catch-
ing” malicious embedding steps while not being overly cautious
and over-reacting to normal variations in network conditions.
The similarities between the test performance under NPS and Vi-
valdi, despite the different nature of the attacks under consideration
and even differences in coordinate “structure” (two-dimensional
with height for Vivaldi versus eight-dimensional for NPS), illus-
trates the generality of the proposed detection method. This is be-
cause our detection test is based on the modeling of a dimension-
less quantity (the relative error) which is at the very core of any
embedding method.
5.3.2 Embedding System Performance
We study the performance of the NPS embedding system when
subject to increasing intensity of attacks, while being protected by
our detection scheme. Note that in this section, “detection off”
really means that our proposed detection mechanism is not used,
but the basic NPS detection mechanism is still “on”.
Figure 15: Distribution of measured relative errors.
Figure 15 shows the cumulative distribution function of relative
errors in the system. We note again similarities with the dynamic
behavior of similar Vivaldi systems, except that the tail of the CDF
for 50% malicious nodes with detection is heavier than the corre-
sponding curve in the Vivaldi case. Keeping in mind that in NPS
not all nodes are victims and that not all normal nodes will prop-
agate mis-positioning errors, this indicates that the attack is still
quite effective against its victims, albeit “dampened” by the de-
tection mechanism. This effect is compounded by the fact that,
with our simple detection protocol, malicious nodes that have found
their way into the layer hierarchy of NPS and act as Reference
Points, do stay in place throughout the experiment, despite numer-
ous detections of their corrupt embedding steps.
Nevertheless, the detection method proposed affords near immu-
nity to the system up to rather severe attack conditions (e.g. about
30% of malicious nodes in the system).
6. DISCUSSIONS AND CONCLUSIONS
We have presented a method for malicious behavior detection to
secure the embedding phase of Internet coordinate systems. Our
method does not rely on the geometric properties of the coordinate
space, and is therefore unaffected by potential triangular inequal-
ity violations which often occur in the Internet [21, 22]. Instead,
our detection test is based on the modeling of the dynamic relative
errors observed in a clean system. The relative error is a dimension-
less quantity which is at the very core of any embedding method,
leading us to believe that our proposed detection test can effec-
tively identify malicious behavior in very many embedding proto-
cols and coordinate space structures that are under a potential very
large range of attacks. The experiments presented in this paper do
show that the performance of the detection test is effectively the
same in two different scenarios involving different embedding pro-
tocols and different attacks. As far as we know, this is the ﬁrst such
general detection test, capable of surviving sophisticated attacks.
Also, we consider exclusively attacks aimed at distorting the co-
ordinate space, carried out by nodes inside the embedding system.
Our method thus succeeds where more obvious methods based on
authentication would fail.
In practice, we introduced the concept of Surveyor nodes which,
by design, are immune to embedding attacks and do observe the
properties of the coordinate system in clean conditions. The Sur-
veyors make up the basis of a “security infrastructure”. It is impor-
tant to note that the deployment of Surveyors does not equate to im-
posing an embedding infrastructure: peer-to-peer based embedding
systems, like Vivaldi, do retain their infrastructure-less embedding
characteristics. Indeed, apart from a test to accept or ﬁlter out em-
bedding steps, our method does not entail any change to the op-
erations of the embedding protocols. Even though this paper does
not address the problem of external attacks on the infrastructure
(e.g. denial of service attacks, “link clogging”, etc.), we note that
solutions to such attacks have been proposed elsewhere (e.g. [24]).
The operations of the proposed detection protocol were delib-
erately kept simple and tested on systems where Surveyors were
chosen randomly, although their representativeness increases with
closeness to their “clients”. Despite the possibly non-optimal Sur-
veyor distribution resulting from such a choice, the results obtained
show the effectiveness of our proposal in securing Internet coordi-
nate systems. Nevertheless, given the enhanced coordinate service
afforded by our detection test and simple detection protocol, one
might envisage that ISPs may readily want to deploy Surveyors
within their network to offer enhanced coordinate service to their
customers. Such business-driven strategic deployment can only im-
prove representativeness of Surveyors, and thus improve the secu-
rity of large-scale coordinate service, with possibly a much smaller
proportion of Surveyors than the upper bound reported in this paper
(as illustrated by the simple k-means deployment in section 3.3).
More sophisticated Surveyor selection mechanisms than those pre-
sented in this paper could also result in better security through bet-
ter representativeness in large-scale coordinate systems. We believe
that the increased robustness provided by our proposal could act as
a catalyzer to the acceptance and deployment of large-scale coordi-
nate services in the Internet.
Nevertheless, with a trusted Surveyor infrastructure in place, it
could be argued that using these Surveyors for positioning other
nodes would ensure immunity to any insider attacks. For Vivaldi,
using the Surveyors for positioning would mean that normal nodes
only choose Surveyors as neighbors. The embedding performance
of such Vivaldi scenario is depicted by the “using dedicated Survey-
ors for embedding”-curve of ﬁgure 13, with the 1% Surveyors of
the simple k-means deployment method. It can clearly be seen that
such use of the Surveyor infrastructure trades embedding accuracy
for increased security. A similar NPS scenario, where only Sur-
veyors would be chosen as Landmarks and reference points, unsur-
prisingly led to embedding performance equivalent to a clean NPS
system, as the hierarchical embedding structure in both systems are
very similar. An NPS system where only Surveyors would be cho-
sen as Landmarks and reference points actually looks like a hybrid
system between GNP [1] and NPS: it is a ﬁxed infrastructure sys-
tem (like GNP), but with distributed Landmark coordinate compu-
tation and a hierarchical structure (like NPS). In both cases above, a
clear scalability issue arises as the load on each Surveyor increases
as their number decreases. In light of the discussion on strategic
Surveyor deployment, as well as lower bound on the number of
required Surveyors (see above and section 3.3), it is not clear that
the solution of embedding against Surveyors only is practically vi-
able. Even if it were, a hybrid solution, where Surveyors would be
used for malicious activity detection under mild to medium attack
intensities and exclusively used for embedding under more severe
conditions, would be more accurate and afford better scalability.
Furthermore, each node using malicious behavior detection does
so in isolation, as there is no cooperation between nodes in a bid to
improve detection and identiﬁcation of malicious nodes. Instead,
any embedding step identiﬁed as malicious by a node is simply,
and quietly, ignored and discarded locally. One of the reasons the
detection protocol was designed in this way was to avoid poten-
tial denial-of-service attacks that could result from the sharing of
information about malicious activity, with the view of excluding
offending nodes. Indeed, such an approach could open the door to
an attack that consists in trying to get honest nodes excluded from
the system through the collusion of wrong malicious reports. Trust
propagation could be used to mitigate or remove this threat and thus
allow detection cooperation amongst nodes, which could only im-
prove the security of the overall system and push the boundary of
applicability of the detection by reducing further the impact of very
large-scale attacks on the embedding system.
A property of coordinate systems that has been observed in large-
scale deployment is coordinate drift [7]. While the drift rate is low
enough that it does not interfere with our detection method, and can
thus be ignored, drift, and in general coordinate variations, can nev-
ertheless be an issue for applications using the coordinate system
for distance estimation (the “usage phase” of the coordinate ser-
vice). Indeed, even though the embedding phase of the system may
have been secured, this would not prevent a malicious node from
blatantly lying about its coordinates when a node requests them for
simple distance estimation during normal use of the service. This
normal use of the service must therefore also be secured, perhaps
through the use of validity period for “certiﬁed” coordinates. This
is left as future work. However, because lying about its own coor-
dinate during a simple distance estimation only fools a single other
node at a time, this type of application-level attack is less danger-
ous than an attack on the embedding phase itself which can distort
the coordinate space and thus spoil the coordinate computations of
unsuspecting honest nodes (and thus bias distance estimates involv-
ing these nodes). This is the reason why we chose to address the
problem of securing the embedding phase ﬁrst.
Acknowledgments
We would like to thank Dina Papagiannaki, Guy Leduc and the
anonymous reviewers for their useful comments that helped im-
prove the paper.
7. REFERENCES
[1] T. E. Ng, and H. Zhang, Predicting internet network distance with
coordinates-based approaches, in Proceedings of the IEEE INFOCOM, New
York, June 2002.
[2] M. Pias, J. Crowcroft, S. Wilbur, S. Bhatti, and T. Harris, Lighthouses for
Scalable Distributed Location, in Proceedings of International Workshop on
Peer-to-Peer Systems (IPTPS03), Berkeley, February 2003.
[3] M. Costa, M. Castro, A. Rowstron, and P. Key, Practical Internet coordinates
for distance estimation, in Proceedings of the IEEE International Conference
on Distributed Computing Systems (ICDCS), Tokyo, March 2004.
[4] T. E. Ng and H. Zhang, A Network Positioning System for the Internet, in
Proceedings of the USENIX annual technical conference, Boston, June 2004.
[5] F. Dabek, R. Cox, F. Kaashoek and R. Morris, Vivaldi: A decentralized
network coordinate system, in Proceedings of the ACM SIGCOMM, Portland,
Oregon, August 2004.
[6] Y. Shavitt and T. Tankel, Big-Bang Simulation for embedding network
distances in Euclidean Space, in Proceedings of the IEEE INFOCOM, New
york, June 2002.
[7] J. Ledlie, P. Gardner, and M. Seltzer, Network Coordinates in the Wild, in
Proceedings of NSDI, Cambridge, MA, April 2007.
[8] I. Stoica, R. Morris, D. Karger, M. F. Kaashoek, and H. Balakrishnan, Chord:
A Scalable Peer-to-peer Lookup Service for Internet Applications, in
Proceedings of SIGCOMM, San Diego, CA, August 2001.
[9] Azureus BitTorrent Client. http://azureus.sourceforce.net
[10] www.skype.com
[11] M. A. Kaafar, L. Mathy, T. Turletti, and W. Dabbous, Virtual Networks under
Attack: Disrupting Internet Coordinate Systems, in Proceedings of CoNext
2006, Lisboa, December, 2006.
[12] M. A. Kaafar, L. Mathy, T. Turletti and W. Dabbous, Real attacks on virtual
networks: Vivaldi out of tune, in Proceedings of the SIGCOMM workshop on
Large Scale Attack Defense (LSAD),Pisa, September 2006.
[13] R.E. Kalman, A New Approach to Linear Filtering and Prediction Problems,
in Transactions of the ASME - Journal of Basic Engineering Vol. 82: pp.
35-45, 1960.
[14] R.E. Kalman, and R.S. Bucy, New Results in Linear Filtering and Prediction
Theory, in Transactions of the ASME - Journal of Basic Engineering Vol. 83:
pp. 95-107, 1961.
[15] Y. Zhang, N. Dufﬁeld, V. Paxson, and S. Shenker, On the Constancy of
Internet Path Properties, in Proceedings of ACM SIGCOMM Internet
Measurement Workshop, San Francisco, CA, November 2001.
[16] Z. Ghahramani, G. Hinton, Parameter Estimation for Linear Dynamical
Systems, University of Toronto, Technical Report CRG-TR-96-2.
[17] M. A. Kaafar, L. Mathy, C. Barakat, K. Salamatian, T. Turletti and
W. Dabbous, Securing Internet Coordinate System: Embedding Phase,
Technical Report INRIA inria-00151257.
[18] K. P. Gummadi, S. Saroiu, and S. D. Gribble, King: Estimating Latency
between Arbitrary Internet End Hosts, in Proceedings of SIGCOMM Internet
Mesasurement Workshop (IMW), Pittsburgh, PA,November 2002.
[19] H. Lilliefors, On the Kolmogorov-Smirnov test for normality with mean and
variance unknown, Journal of the American Statistical Association, Vol. 62.
pp. 399-402, June, 1967.
[20] A. Soule, K. Salamatian, and N. Taft, Combining Filtering and Statistical
Methods for Anomaly Detection, in Proceedings of Internet Measurement
Conference (IMC), Berkeley, October, 2005.
[21] E. K. Lua, T. grifﬁn, M. Pias, H. Zheng, and J. Crowcroft, On the accuracy of
Embeddings for Internet Coordinate Systems, in Proceedings of Internet
Measurement Conference (IMC), Berkeley, October 2005.
[22] H. Zheng, E. K. Lua, M. Pias, and T. Grifﬁn, Internet Routing Policies and
Roun-Trip Times, in Proceedings of the Passive Active Measurement (PAM),
Boston, March 2005.
[23] J. Bilmes, A gentle tutorial on the EM algorithm including gaussian mixtures
and baum-welch, Technical Report TR-97-021, International Computer
Science Institute, Berkeley, CA, 1997.
[24] A. Keromytis, V. Misra and D. Rubenstein, SOS: Secure Overlay Services, in
Proceedings of ACM SIGCOMM, Pittsburgh, PA, August 2002.