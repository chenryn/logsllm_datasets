{"node":"172.253.52.103","region_name":"k8s-overlay","region_id":"donotcare","log_data":"Feb 14 03:32:16 k8s-storage-node03 kubelet: E0214 03:32:16.539197    1935 cadvisor_stats_provider.go:401] Partial failure issuing cadvisor.ContainerInfoV2: partial failures: [\"/kubepods/burstable/podf379c920-cad4-4ac2-bdfd-b9e539c01292/1db16a77e31fa6f4637818ce1693d228429d4bd8e21228a8aba301eea39e63ce\": RecentStats: unable to find data in memory cache]","log_level":"0","file_name":"messages.log","paths":"/var/log/messages.log","time":1676316736841211,"@timestamp":"2023-02-13T19:32:16.842778Z","root_account":"alauda","source":"host","log_type":"file"}
{"node":"172.253.52.103","region_name":"k8s-overlay","region_id":"donotcare","log_data":"Feb 14 03:32:16 k8s-storage-node03 kubelet: I0214 03:32:16.739643    1935 topology_manager.go:221] [topologymanager] RemoveContainer - Container ID: e696008fa5bcc48c59c80e3f5049f772707b59f2119938b9f88ce70a2e6dfb07","log_level":"0","file_name":"messages.log","paths":"/var/log/messages.log","time":1676316736841213,"@timestamp":"2023-02-13T19:32:16.842998Z","root_account":"alauda","source":"host","log_type":"file"}
{"node":"172.253.52.103","region_name":"k8s-overlay","region_id":"donotcare","log_data":"Feb 14 03:32:16 k8s-storage-node03 kubelet: E0214 03:32:16.756794    1935 pod_workers.go:191] Error syncing pod f379c920-cad4-4ac2-bdfd-b9e539c01292 (\"rook-ceph-osd-30-7b5dcddf4d-w9sbf_rook-ceph(f379c920-cad4-4ac2-bdfd-b9e539c01292)\"), skipping: failed to \"StartContainer\" for \"expand-bluefs\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=expand-bluefs pod=rook-ceph-osd-30-7b5dcddf4d-w9sbf_rook-ceph(f379c920-cad4-4ac2-bdfd-b9e539c01292)\"","log_level":"0","file_name":"messages.log","paths":"/var/log/messages.log","time":1676316736841215,"@timestamp":"2023-02-13T19:32:16.843192Z","root_account":"alauda","source":"host","log_type":"file"}
{"project_name":"cpaas-system","application_name":null,"provider":"","product":"","component":"","node":"172.253.52.103","nodes":"172.253.52.103","region_name":"k8s-overlay","region_id":"donotcare","log_data":"audit 2023-02-13 19:32:17.128433 mon.f (mon.2) 7099546 : audit [DBG] from='admin socket' entity='admin socket' cmd='mon_status' args=[]: dispatch\n","log_level":"0","paths":"stdout","file_name":"stdout","time":1676316737264066,"root_account":"alauda","source":"container","log_type":"log","kubernetes_labels":{"app":"rook-ceph-mon","ceph_daemon_id":"c","ceph_daemon_type":"mon","mon":"c","mon_cluster":"rook-ceph","pod-template-hash":"b9696cffd","rook_cluster":"rook-ceph"},"kubernetes_namespace":"rook-ceph","pod_name":"rook-ceph-mon-c-b9696cffd-x4x4f","pod_id":"9aab540b-7e57-4c68-b328-bcb850f1720f","container_id":"2f99e454a1c199c21efcb01adfda3ee8782c902d9bd0f51a81af50ad7a19b9f2","container_id8":"2f99e454","docker_container_name":"mon","kubernetes_container_name":"mon"}
{"project_name":"cpaas-system","application_name":null,"provider":"","product":"","component":"","node":"172.253.52.103","nodes":"172.253.52.103","region_name":"k8s-overlay","region_id":"donotcare","log_data":"audit 2023-02-13 19:32:17.128675 mon.f (mon.2) 7099547 : audit [DBG] from='admin socket' entity='admin socket' cmd=mon_status args=[]: finished\n","log_level":"0","paths":"stdout","file_name":"stdout","time":1676316737264103,"root_account":"alauda","source":"container","log_type":"log","kubernetes_labels":{"app":"rook-ceph-mon","ceph_daemon_id":"c","ceph_daemon_type":"mon","mon":"c","mon_cluster":"rook-ceph","pod-template-hash":"b9696cffd","rook_cluster":"rook-ceph"},"kubernetes_namespace":"rook-ceph","pod_name":"rook-ceph-mon-c-b9696cffd-x4x4f","pod_id":"9aab540b-7e57-4c68-b328-bcb850f1720f","container_id":"2f99e454a1c199c21efcb01adfda3ee8782c902d9bd0f51a81af50ad7a19b9f2","container_id8":"2f99e454","docker_container_name":"mon","kubernetes_container_name":"mon"}
{"project_name":"cpaas-system","application_name":null,"provider":"","product":"","component":"","node":"172.253.52.103","nodes":"172.253.52.103","region_name":"k8s-overlay","region_id":"donotcare","log_data":"debug 2023-02-13 19:32:17.409 7f3886360700  1 mon.c@1(peon).osd e27233 _set_new_cache_sizes cache_size:134217728 inc_alloc: 67108864 full_alloc: 67108864 kv_alloc: 67108864\n","log_level":"0","paths":"stdout","file_name":"stdout","time":1676316737411486,"root_account":"alauda","source":"container","log_type":"log","kubernetes_labels":{"app":"rook-ceph-mon","ceph_daemon_id":"c","ceph_daemon_type":"mon","mon":"c","mon_cluster":"rook-ceph","pod-template-hash":"b9696cffd","rook_cluster":"rook-ceph"},"kubernetes_namespace":"rook-ceph","pod_name":"rook-ceph-mon-c-b9696cffd-x4x4f","pod_id":"9aab540b-7e57-4c68-b328-bcb850f1720f","container_id":"2f99e454a1c199c21efcb01adfda3ee8782c902d9bd0f51a81af50ad7a19b9f2","container_id8":"2f99e454","docker_container_name":"mon","kubernetes_container_name":"mon"}
{"project_name":"","application_name":null,"provider":"","product":"","component":"kube-ovn-controller","node":"172.253.52.103","nodes":"172.253.52.103","region_name":"k8s-overlay","region_id":"donotcare","log_data":"I0214 03:32:17.024708       6 election.go:51] waiting for becoming a leader\n","log_level":"0","paths":"stdout","file_name":"stdout","time":1676316737024835,"root_account":"alauda","source":"container","log_type":"log","kubernetes_labels":{"app":"kube-ovn-controller","component":"network","pod-template-hash":"7655484c5d","type":"infra"},"kubernetes_namespace":"kube-system","pod_name":"kube-ovn-controller-7655484c5d-dz4q5","pod_id":"606802f6-8ddf-4836-bd20-eb79ca7ea55e","container_id":"de1d9b6d670892d9e335daeea4c023f1ffe0a5e167b92ab371d8cc8b0f18efe5","container_id8":"de1d9b6d","docker_container_name":"kube-ovn-controller","kubernetes_container_name":"kube-ovn-controller"}
{"node":"172.253.52.103","region_name":"k8s-overlay","region_id":"donotcare","log_data":"Feb 14 03:32:17 k8s-storage-node03 kubelet: E0214 03:32:17.396347    1935 pod_workers.go:191] Error syncing pod 797f966d-0916-4586-969b-8d28ce25fc36 (\"rook-ceph-osd-35-6c456cd5cc-svnh5_rook-ceph(797f966d-0916-4586-969b-8d28ce25fc36)\"), skipping: failed to \"StartContainer\" for \"expand-bluefs\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=expand-bluefs pod=rook-ceph-osd-35-6c456cd5cc-svnh5_rook-ceph(797f966d-0916-4586-969b-8d28ce25fc36)\"","log_level":"0","file_name":"messages.log","paths":"/var/log/messages.log","time":1676316737841217,"@timestamp":"2023-02-13T19:32:17.841635Z","root_account":"alauda","source":"host","log_type":"file"}
{"node":"172.253.52.103","region_name":"k8s-overlay","region_id":"donotcare","log_data":"Feb 14 03:32:17 k8s-storage-node03 kubelet: E0214 03:32:17.686467    1935 actual_state_of_world.go:590] MarkFSResizeRequired failed to find expandable plugin for pod \"797f966d-0916-4586-969b-8d28ce25fc36\" volume: \"kubernetes.io/local-volume/osd-data-z9mq7\" (volSpecName: \"osd-data-z9mq7\")","log_level":"0","file_name":"messages.log","paths":"/var/log/messages.log","time":1676316737841223,"@timestamp":"2023-02-13T19:32:17.841885Z","root_account":"alauda","source":"host","log_type":"file"}
{"node":"172.253.52.103","region_name":"k8s-overlay","region_id":"donotcare","log_data":"Feb 14 03:32:17 k8s-storage-node03 kubelet: E0214 03:32:17.783173    1935 pod_workers.go:191] Error syncing pod f379c920-cad4-4ac2-bdfd-b9e539c01292 (\"rook-ceph-osd-30-7b5dcddf4d-w9sbf_rook-ceph(f379c920-cad4-4ac2-bdfd-b9e539c01292)\"), skipping: failed to \"StartContainer\" for \"expand-bluefs\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=expand-bluefs pod=rook-ceph-osd-30-7b5dcddf4d-w9sbf_rook-ceph(f379c920-cad4-4ac2-bdfd-b9e539c01292)\"","log_level":"0","file_name":"messages.log","paths":"/var/log/messages.log","time":1676316737841225,"@timestamp":"2023-02-13T19:32:17.842109Z","root_account":"alauda","source":"host","log_type":"file"}
{"project_name":"cpaas-system","application_name":null,"provider":"","product":"","component":"","node":"172.253.52.103","nodes":"172.253.52.103","region_name":"k8s-overlay","region_id":"donotcare","log_data":"cluster 2023-02-13 19:32:08.301504 mgr.a (mgr.20525692) 257593 : cluster [DBG] pgmap v257594: 2348 pgs: 2348 active+clean; 4.6 TiB data, 11 TiB used, 33 TiB / 44 TiB avail; 4.8 MiB/s wr, 315 op/s\n","log_level":"0","paths":"stdout","file_name":"stdout","time":1676316738285722,"root_account":"alauda","source":"container","log_type":"log","kubernetes_labels":{"app":"rook-ceph-mon","ceph_daemon_id":"c","ceph_daemon_type":"mon","mon":"c","mon_cluster":"rook-ceph","pod-template-hash":"b9696cffd","rook_cluster":"rook-ceph"},"kubernetes_namespace":"rook-ceph","pod_name":"rook-ceph-mon-c-b9696cffd-x4x4f","pod_id":"9aab540b-7e57-4c68-b328-bcb850f1720f","container_id":"2f99e454a1c199c21efcb01adfda3ee8782c902d9bd0f51a81af50ad7a19b9f2","container_id8":"2f99e454","docker_container_name":"mon","kubernetes_container_name":"mon"}
{"project_name":"cpaas-system","application_name":null,"provider":"","product":"","component":"","node":"172.253.52.103","nodes":"172.253.52.103","region_name":"k8s-overlay","region_id":"donotcare","log_data":"cluster 2023-02-13 19:32:10.306022 mgr.a (mgr.20525692) 257594 : cluster [DBG] pgmap v257595: 2348 pgs: 2348 active+clean; 4.6 TiB data, 11 TiB used, 33 TiB / 44 TiB avail; 6.1 MiB/s wr, 374 op/s\n","log_level":"0","paths":"stdout","file_name":"stdout","time":1676316738285762,"root_account":"alauda","source":"container","log_type":"log","kubernetes_labels":{"app":"rook-ceph-mon","ceph_daemon_id":"c","ceph_daemon_type":"mon","mon":"c","mon_cluster":"rook-ceph","pod-template-hash":"b9696cffd","rook_cluster":"rook-ceph"},"kubernetes_namespace":"rook-ceph","pod_name":"rook-ceph-mon-c-b9696cffd-x4x4f","pod_id":"9aab540b-7e57-4c68-b328-bcb850f1720f","container_id":"2f99e454a1c199c21efcb01adfda3ee8782c902d9bd0f51a81af50ad7a19b9f2","container_id8":"2f99e454","docker_container_name":"mon","kubernetes_container_name":"mon"}
{"project_name":"cpaas-system","application_name":null,"provider":"","product":"","component":"","node":"172.253.52.103","nodes":"172.253.52.103","region_name":"k8s-overlay","region_id":"donotcare","log_data":"cluster 2023-02-13 19:32:12.309832 mgr.a (mgr.20525692) 257595 : cluster [DBG] pgmap v257596: 2348 pgs: 2348 active+clean; 4.6 TiB data, 11 TiB used, 33 TiB / 44 TiB avail; 5.3 KiB/s rd, 5.5 MiB/s wr, 345 op/s\n","log_level":"0","paths":"stdout","file_name":"stdout","time":1676316738285812,"root_account":"alauda","source":"container","log_type":"log","kubernetes_labels":{"app":"rook-ceph-mon","ceph_daemon_id":"c","ceph_daemon_type":"mon","mon":"c","mon_cluster":"rook-ceph","pod-template-hash":"b9696cffd","rook_cluster":"rook-ceph"},"kubernetes_namespace":"rook-ceph","pod_name":"rook-ceph-mon-c-b9696cffd-x4x4f","pod_id":"9aab540b-7e57-4c68-b328-bcb850f1720f","container_id":"2f99e454a1c199c21efcb01adfda3ee8782c902d9bd0f51a81af50ad7a19b9f2","container_id8":"2f99e454","docker_container_name":"mon","kubernetes_container_name":"mon"}