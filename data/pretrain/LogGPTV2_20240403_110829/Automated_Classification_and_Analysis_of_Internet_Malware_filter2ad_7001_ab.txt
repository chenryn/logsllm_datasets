16
100
Consistency. To investigate consistency, we grouped malware into categories
based on the labels provided by AV vendors. For each pair of distinct malware
labeled as the same by a particular system, we compared the percentage of time
the same pair was classiﬁed by other AV systems as the same. For example, two
binaries in our legacy dataset with diﬀerent MD5 checksums were labeled as
Automated Classiﬁcation and Analysis of Internet Malware
183
Table 4. The percentage of malware samples detected across datasets and AV vendors.
AV does not provide a complete categorization of the datasets.
Dataset AV Updated Percentage of Malware Samples Detected
Name
legacy
small
small
large
McAfee F-Prot ClamAV Trend
93.73
54.0
86.8
80.0
20 Nov 2006
20 Nov 2006
31 Mar 2007
31 Mar 2007
97.4
76.9
52.4
51.5
100
48.7
67.4
54.6
99.8
61.0
68.0
76.4
94.8
38.4
55.5
60.1
Symantec
W32-Blaster-worm-a by McAfee. These two binaries were labeled consistently
by F-Prot (both as msblast), and Trend (both as msblast), but inconsistently
by Symantec (one blaster and one not detected) and ClamAV (one blaster, one
dcom.exploit). We then selected each system in turn and used its classiﬁcation
as the base. For example, Table 3 shows that malware classiﬁed by McAfee as
the same was only classiﬁed as the same by F-Prot 13% of the time. However,
malware classiﬁed by F-Prot as the same was only classiﬁed as the same by
McAfee 50% of the time. Not only do AV systems place malware into diﬀerent
categories, these categories don’t hold the same meaning across systems.
Completeness. As discussed earlier, the design goal for completeness is to
provide a label for each and every item to be classiﬁed. For each of the datasets
and AV systems, we examined the percentage of time the AV systems detected
a given piece of malware (and hence provided a label). A small percentage of
malware samples are still undetected a year after the collection of the legacy
datasets (Table 4). The results for more recent samples are even more profound,
with almost half the samples undetected in the small dataset and one quarter
in the large dataset. The one quarter undetected for the large set is likely an
overestimate of the ability of the AV, as many of the binaries labeled at that
point were many months old (e.g., compare the improvement over time in the
two labeling instances of small). Thus, AV systems do not provide a complete
labeling system.
Table 5. The ways in which various AV products label and group malware. AV labeling
schemes vary widely in how concisely they represent the malware they classify.
legacy(3,637 binaries)
small(893 binaries)
Unique Labels Clusters or Families Unique Labels Clusters or Families
McAfee
F-Prot
ClamAV
Trend
Symantec
116
1216
590
416
57
34
37
41
46
31
122
379
253
246
90
95
62
65
72
81
Conciseness. Conciseness refers to the ability of the labeling system to pro-
vide a label that reﬂects the important characteristics of the sample without
superﬂuous semantics. In particular, we ﬁnd that a label that carries either too
much or too little meaning has minimal value. To investigate this property, we
examined the number and types of labels and groups provided by the AV sys-
tems. Table 5 shows the number of unique labels provided by the AV systems
184
M. Bailey et al.
as well as the number of unique families these labels belong to. In this analysis,
the family is a generalized label heuristically extracted from the literal string,
which contains the portion intended to be human-readable. For example, the
literal labels returned by a AV system W32-Sdbot.AC and Sdbot.42, are both
in the “sdbot” family. An interesting observation from this table is that these
systems vary widely in how concisely they represent malware. Vendors such as
Symantec appear to employ a general approach, reducing samples to a small
handful of labels and families. On the other extreme, FProt appears to aggres-
sively label new instances, providing thousands of unique labels for malware,
but still maintaining a small number of groups or families to which these labels
belong.
3 Behavior-Based Malware Clustering
As we described in the previous section, any meaningful labeling system must
achieve consistency, completeness, and conciseness, and existing approaches,
such as those used by anti-virus systems, fail to perform well on these met-
rics. To address these limitations, we propose an approach based on the actual
execution of malware samples and observation of their persistent state changes.
These state changes, when taken together, make a behavioral ﬁngerprint, which
can then be clustered with other ﬁngerprints to deﬁne classes and subclasses of
malware that exhibit similar state change behaviors. In this section, we discuss
our deﬁnition and generation of these behavioral ﬁngerprints and the techniques
for clustering them.
3.1 Deﬁning and Generating Malware Behaviors
Previous work in behavioral signatures has been based at the abstraction level
of low-level system events, such as individual system calls. In our system, the
intent is to capture what the malware actually does on the system. Such in-
formation is more invariant and directly useful to assess the potential damage
incurred. Individual system calls may be at a level that is too low for abstract-
ing semantically meaningful information: a higher abstraction level is needed to
eﬀectively describe the behavior of malware. We deﬁne the behavior of malware
in terms of non-transient state changes that the malware causes on the system.
State changes are a higher level abstraction than individual system calls, and
they avoid many common obfuscation techniques that foil static analysis as well
as low-level signatures, such as encrypted binaries and non-deterministic event
ordering. In particular, we extract simple descriptions of state changes from the
raw event logs obtained from malware execution. Spawned process names, mod-
iﬁed registry keys, modiﬁed ﬁle names, and network connection attempts are
extracted from the logs and the list of such state changes becomes a behavioral
proﬁle of a sample of malware.
Observing the malware behavior requires actually executing the binaries. We
execute each binary individually inside a virtual machine [27] with Windows
XP installed. The virtual machine is partially ﬁrewalled so that the external
Automated Classiﬁcation and Analysis of Internet Malware
185
impact of any immediate attack behaviors (e.g., scanning, DDoS, and spam) is
minimized during the limited execution period. The system events are captured
and exported to an external server using the Backtracker system [12]. In addition
to exporting system events, the Backtracker system provides a means of building
causal dependency graphs of these events. The beneﬁt of this approach is that
we can validate that the changes we observe are a direct result of the malware,
and not of some normal system operation.
3.2 Clustering of Malware
While the choice of abstraction and generation of behaviors provides useful infor-
mation to users, operators, and security personnel, the sheer volume of malware
makes manual analysis of each new malware intractable. Our malware source
observed 3,700 samples in a six-month period—over 20 new pieces per day. Each
generated ﬁngerprint, in turn, can exhibit many thousands of individual state
changes (e.g., infecting every .exe on a Windows host). For example, consider
the tiny subset of malware in table 6. The 10 distinct pieces of malware generate
from 10 to 66 diﬀerent behaviors with a variety of diﬀerent labels, including
disjoint families, variants, and undetected malware. While some items obviously
belong together in spite of their diﬀerences (e.g., C and D), even the composition
of labels across AV systems can not provide a complete grouping of the malware.
Obviously, for these new behavioral ﬁngerprints to be eﬀective, similar behaviors
need to be grouped and appropriate meanings assigned.
Table 6. Ten unique malware samples. For each sample, the number of process, ﬁle,
registry, and network behaviors observed and the classiﬁcations given by various AV
vendors are listed.
Label MD5
P/F/R/N McAfee
A 71b99714cddd66181e54194c44ba59df 8/13/27/0 Not detected
B be5f889d12fe608e48be11e883379b7a 8/13/27/0 Not detected
C df1cda05aab2d366e626eb25b9cba229 1/1/6/1 W32/Mytob.gen@MM W32/IRCBot-based!Maximus
D 5bf169aba400f20cbe1b237741eﬀ090
E eef804714ab4f89ac847357f3174aa1d
F 80f64d342fddcc980ae81d7f8456641e 2/11/28/1 IRC/Flood.gen.b
G 12586ef09abc1520c1ba3e998baec457
H ﬀ0f3c170ea69ed266b8690e13daf1a6
I
J
36f6008760bd8dc057ddb1cf99c0b4d7 3/22/29/3 IRC/Generic Flooder IRC/Zapchast.AK@bd
c13f3448119220d006e93608c5ba3e58 5/32/28/1 Generic BackDoor.f W32/VB-Backdoor!Maximus
1/1/6/2 W32/Mytob.gen@MM Not detected
1/2/8/3 PWS-Banker.gen.i
1/4/3/1 W32/Pate.b
1/2/8/1 Not detected
Trend
W32/Backdoor.QWO
W32/Backdoor.QWO
W32/Bancos.IQK
W32/Backdoor.AHJJ
W32/Parite.B
W32/Bancos.IJG
Our approach to generating meaningful labels is achieved through clustering
of the behavioral ﬁngerprints. In the following subsections, we introduce this ap-
proach and the various issues associated with eﬀective clustering, including how
to compare ﬁngerprints, combine them based on their similarity, and determine
which are the most meaningful groups of behaviors.
Comparing Individual Malware Behaviors. While examining individual
behavioral proﬁles provides useful information on particular malware samples,
our goal is to classify malware and give them meaningful labels. Thus malware
samples must be grouped. One way to group the proﬁles is to create a distance
metric that measures the diﬀerence between any two proﬁles, and then use the
186
M. Bailey et al.
Table 7. A matrix of the NCD between each of the 10 malware samples in our example
A B C D E
F G H
I
J
A 0.06 0.07 0.84 0.84 0.82 0.73 0.80 0.82 0.68 0.77
B 0.07 0.06 0.84 0.85 0.82 0.73 0.80 0.82 0.68 0.77
C 0.84 0.84 0.04 0.22 0.45 0.77 0.64 0.45 0.84 0.86
D 0.85 0.85 0.23 0.05 0.45 0.76 0.62 0.43 0.83 0.86
E 0.83 0.83 0.48 0.47 0.03 0.72 0.38 0.09 0.80 0.85
F 0.71 0.71 0.77 0.76 0.72 0.05 0.77 0.72 0.37 0.54
G 0.80 0.80 0.65 0.62 0.38 0.78 0.04 0.35 0.78 0.86
H 0.83 0.83 0.48 0.46 0.09 0.73 0.36 0.04 0.80 0.85
I 0.67 0.67 0.83 0.82 0.79 0.38 0.77 0.79 0.05 0.53
J 0.75 0.75 0.86 0.85 0.83 0.52 0.85 0.83 0.52 0.08
metric for clustering. Our initial naive approach to deﬁning similarity was based
on the concept of edit distance [7]. In this approach, each behavior is treated
as an atomic unit and we measure the number of inserts of deletes of these
atomic behaviors required to transform one behavioral ﬁngerprint into another.
The method is fairly intuitive and straightforward to implement (think the Unix
command diﬀ here); however, it suﬀers from two major drawbacks:
– Overemphasizing size. When the size of the number of behaviors is large,
the edit distance is eﬀectively equivalent to clustering based on the length
of the feature set. This overemphasizes diﬀerences over similarities.
– Behavioral polymorphism. Many of the clusters we observed had few
exact matches for behaviors. This is because the state changes made by mal-
ware may contain simple behavioral polymorphism (e.g., random ﬁle names).
To solve these shortcomings we turned to normalized compression distance
(NCD). NCD is a way to provide approximation of information content, and it
has been successfully applied in a number of areas [25,29]. NCD is deﬁned as:
N CD(x, y) = C(x + y) − min(C(x), C(y))
max(C(x), C(y))
where ”x + y” is the concatenation of x and y, and C(x) is the zlib-compressed
length of x. Intuitively, NCD represents the overlap in information between two
samples. As a result, behaviors that are similar, but not identical, are viewed as
close (e.g., two registry entries with diﬀerent values, random ﬁle names in the
same locations). Normalization addresses the issue of diﬀering information con-
tent. Table 7 shows the normalized compression distance matrix for the malware
described in Table 6.
Constructing Relationships Between Malware. Once we know the in-
formation content shared between two sets of behavioral ﬁngerprints, we can
combine various pieces of malware based on their similarity. In our approach,
we construct a tree structure based on the well-known hierarchical clustering
algorithm [11]. In particular, we use pairwise single-linkage clustering, which de-
ﬁnes the distance between two clusters as the minimum distance between any
two members of the clusters. We output the hierarchical cluster results as a tree
graph in graphviz’s dot format [14]. Figure 2 shows the generated tree for the
malware in Table 6.
Automated Classiﬁcation and Analysis of Internet Malware
187
c9
c6
c4
c8
c1
c2
G
A
B
c3
D
C
c7
c5
J
0.7
0.6
0.5
0.4
0.3
0.2
0.1
E
H
F
I
A
B
F
I
J
C
D
E
H
G
Fig. 2. On the left, a tree consisting of the malware from Table 6 has been clustered via
a hierarchical clustering algorithm whose distance function is normalized compression
distance. On the right, a dendrogram illustrating the distance between various subtrees.
Extracting Meaningful Groups. While the tree-based output of the hierar-
chical clustering algorithm does show the relationships between the information
content of behavioral ﬁngerprints, it does not focus attention on areas of the
tree in which the similarities (or lack thereof) indicate an important group of
malware. Therefore, we need a mechanism to extract meaningful groups from
the tree. A naive approach to this problem would be to set a single threshold
of the diﬀerences between two nodes in the tree. However, this can be prob-
lematic as a single uniform distance does not accurately represent the distance
between various subtrees. For example, consider the dendrogram in Figure 2.
The height of many U-shaped lines connecting objects in a hierarchical tree il-
lustrates the distance between the two objects being connected. As the ﬁgure
shows, the diﬀerence between the information content of subtrees can be sub-