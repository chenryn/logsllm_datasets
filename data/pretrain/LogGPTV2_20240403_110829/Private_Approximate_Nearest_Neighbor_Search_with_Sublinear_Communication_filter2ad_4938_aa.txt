title:Private Approximate Nearest Neighbor Search with Sublinear Communication
author:Sacha Servan-Schreiber and
Simon Langowski and
Srinivas Devadas
2
0
7
3
3
8
9
.
2
2
0
2
.
4
1
2
6
4
P
S
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
2
2
0
2
¬©
0
0
.
1
3
$
/
2
2
/
9
-
6
1
3
1
-
4
5
6
6
-
1
-
8
7
9
|
)
P
S
(
y
c
a
v
i
r
P
d
n
a
y
t
i
r
u
c
e
S
n
o
m
u
i
s
o
p
m
y
S
E
E
E
I
2
2
0
2
2022 IEEE Symposium on Security and Privacy (SP)
Private Approximate Nearest Neighbor Search
with Sublinear Communication
Sacha Servan-Schreiber
MIT CSAIL
Simon Langowski
MIT CSAIL
Srinivas Devadas
MIT CSAIL
Abstract‚ÄîNearest neighbor search is a fundamental building-
block for a wide range of applications. A privacy-preserving
protocol for nearest neighbor search involves a set of clients
who send queries to a remote database. Each client retrieves the
nearest neighbor(s) to its query in the database without revealing
any information about the query. To ensure database privacy,
clients must learn as little as possible beyond the query answer,
even if behaving maliciously by deviating from protocol.
Existing protocols for private nearest neighbor search re-
quire heavy cryptographic tools, resulting in high computational
and bandwidth overheads. In this paper, we present the Ô¨Årst
lightweight protocol for private nearest neighbor search. Our
protocol is instantiated using two non-colluding servers, each
holding a replica of the database. Our design supports an
arbitrary number of clients simultaneously querying the database
through the two servers. Each query consists of a single round
of communication between the client and the two servers. No
communication is required between the servers to answer queries.
If at least one of the servers is non-colluding, we ensure that
(1) no information is revealed on the client‚Äôs query, (2) the total
communication between the client and the servers is sublinear in
the database size, and (3) each query answer only leaks a small
and bounded amount of information about the database to the
client, even if the client is malicious.
We implement our protocol and report its performance on
real-world data. Our construction requires between 10 and 20
seconds of query latency over large databases of 10M feature
vectors. Client overhead remained under 10 ms of processing
time per query and less than 10 MB of communication.
I. INTRODUCTION
Nearest neighbor search is used in a wide range of online
applications,
including recommendation engines [23, 81],
reverse image search [56], image-recognition [57], earthquake
detection [86], computational linguistics [62], natural-language
processing [73], targeted advertising [72, 82], and numerous
other areas [53, 58, 68, 72].
In these settings, a server has a database of high-dimensional
feature vectors associated with items. Clients send query vectors
to the server to obtain the set of items (a.k.a. neighbors) that
have similar vectors relative to the issued query. Typically, the
client only obtains the identiÔ¨Åers (IDs) of the neighbors rather
than the feature vectors themselves, as the server may wish to
keep the feature vectors private. The IDs of the feature vectors
can be documents, songs, or webpages, and therefore all the
client requires as output for correct functionality.
For a concrete example, consider a music recommendation
engine such as Spotify. The Spotify server holds a database
of song feature vectors. Each feature vector can be seen
as a concise representation of song attributes‚Äîe.g., genre,
Fig. 1: Overview of approximate nearest neighbor search and the
privacy-preserving protocol considered in this paper. In the private
setting, a client with a query (blue square) interacts with a remote
database via two non-colluding servers (Servers A and B). The client
combines the responses from both servers to obtain the approximate
nearest neighbor ID (in this case the ANN ID = 5) without revealing
the query to the servers.
popularity, user ratings‚Äîencoded in a high-dimensional vector
space. A Spotify user has a vector of features (the query)
representing their musical interests. The goal is to recommend
songs the user may Ô¨Ånd interesting, which should have similar
features. This is done using nearest neighbor search to Ô¨Ånd the
ID (e.g., the song) of a vector similar to the query. The client
learns the recommended song without learning the potentially
proprietary feature vector associated with it (beyond what can
be implicitly inferred through similarity with the query).
In the above example, the Spotify database learns the client‚Äôs
features. It is not difÔ¨Åcult to see that in applications that
involve more sensitive user data, revealing these features can
easily violate user privacy. Such applications include targeted
advertising [13, 47, 72, 80, 82], biometric data [14, 38], medical
records [9, 78], and DNA data analysis [24, 60, 67, 83].
These applications construct queries from highly personal user
information. For example, in the medical setting, a person‚Äôs
medical history, demographics, and even DNA can be compiled
into a query. The resulting neighbors can consist of other
people who have similar symptoms, gene sequences, or health
conditions [65]. Both regulatory and ethical reasons dictate that
such personal information (represented in the query) should
be kept private from the database.
¬© 2022, Sacha Servan-Schreiber. Under license to IEEE.
DOI 10.1109/SP46214.2022.00074
1911
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:00:59 UTC from IEEE Xplore.  Restrictions apply. 
—Ñ,0 -4*)“ä+-$1/  -#Client-$1/  -# -1 - -1 - -1 -,0 -4—Ä—Å—Ç—É—Ñ—Ö—Ü—áClient,0 -4“ø—Ñ—Ñ,0 -4—Ñ,0 -4—Ä—Å—Ç—É—Ñ—Ö—Ü—á“ó - ./ $"#*-
“ò€î€ô“ø—Ñ. - /.#- .The potential privacy issues surrounding similarity search
have motivated a handful of privacy-preserving protocols [26,
50, 70, 78, 87]. However, existing protocols are highly inefÔ¨Å-
cient. Prior work either makes use of heavy cryptographic
tools (e.g., two-party computation and fully-homomorphic
encryption) or fails to provide strong privacy guarantees for
users (e.g., leak information on the query to the server). See
the overview of related work in Section IX.
Additionally, existing protocols do not consider malicious1
clients that may attempt to abuse the system to learn more
information about the database. The proposed solutions leave
open the problem of designing a concretely efÔ¨Åcient protocol
for private nearest neighbor search, especially in settings where
parties may act maliciously by deviating from protocol.
The contribution of this paper is the design and imple-
mentation of a lightweight protocol for private Approximate
Nearest Neighbor (ANN) search. SpeciÔ¨Åcally, by lightweight we
require: (1) minimal communication and computation overhead
on the client, and (2) reasonable computational overheads on
the database. This is in contrast to prior work which either
requires gigabytes of communication to instantiate a multi-party
computation protocol or uses fully-homomorphic encryption to
perform the computation resulting in excessive computational
overhead on the database (see related work in Section IX).
Our protocol provides strong security guarantees for both
the client and the database. We ensure that our protocol is
concretely efÔ¨Åcient and requires little communication between
the client and the database servers (and no communication
between servers). We achieve this without compromising on
privacy for the client‚Äînothing is leaked on the client‚Äôs query.
For database privacy, our construction requires some extra
database leakage compared to the (minimal) baseline leakage
which only reveals the ANN to the client. The small additional
leakage allows us to eschew oblivious comparisons, which
are inefÔ¨Åcient to instantiate [84]. However, we are careful
to quantify the extra leakage relative to the baseline. In our
analysis, we show that the leakage is at most a constant factor
worse than the baseline. We empirically show that this constant
is at most 16√ó the baseline leakage on real-world datasets,
under worst-case parameters (see Section VII-B).
Private ANN search. We operate in the following model
(see Figure 1 for a simpliÔ¨Åed illustration). Fix a database
DB containing a set of N feature vectors v1, . . . , vN and
corresponding item identiÔ¨Åers ID1, . . . , IDN . A client has a
query vector q. The client must learn only the ID(s) of the
nearest neighbor(s) relative to q under some similarity (or
distance) metric. For client privacy, the protocol must not
leak any information about q to the database servers. For
database privacy, the protocol must leak as little as possible on
v1, . . . , vN to the client. Observe that perfect database privacy
(i.e., no database leakage) is unattainable because the client
1Existing work requires secure function evaluation between the client and server,
which can be ‚Äúupgraded‚Äù to malicious-security at the cost of computationally
expensive transformations based on zero-knowledge proofs [44]. The use of
fully-homomorphic encryption is another alternative to provide malicious
security but comes at a high efÔ¨Åciency cost.
must learn at least one ID corresponding to a neighboring vector
in the database, which indicates that the vector associated with
the ID is similar to the query. We therefore focus on minimizing
extra leakage of the database to the client beyond this baseline.
Our approach. We start by redesigning the standard locality-
sensitive-hashing based data structure for ANN search with
the goal of avoiding oblivious comparisons (the efÔ¨Åciency
bottleneck of prior work). We achieve this by replacing brute-
force comparisons with a radix-sort [54] inspired approach for
extracting the nearest neighbor, without sacriÔ¨Åcing accuracy.
We then show how to query this new data structure through a
novel privacy-preserving protocol. Our protocol uses distributed
point functions [42] as an existing building block for private
information retrieval. We then apply a new tool we call partial
batch retrieval (a spin on batch-PIR [8]; see Section V-A) to
reduce the server processing overhead when answering queries.
Finally, to provide database privacy, we use a new technique we
call oblivious masking (Section V-A), which hides all-but-one
neighbor ID from the query answer.
We show that our protocol
is (1) accurate through a