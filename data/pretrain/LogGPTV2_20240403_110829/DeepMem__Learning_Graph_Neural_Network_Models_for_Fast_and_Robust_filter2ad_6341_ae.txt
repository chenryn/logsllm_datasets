related to DeepMem.
Small Objects. DeepMem may not perform well for small ob-
jects with few or no pointers, like many other pointer-based ap-
proaches [19]. Our approach model objects based on both content
of objects and topological relations between objects. Small objects
(cid:22)(cid:22)(cid:20)(cid:24)(cid:22)(cid:20)(cid:26)(cid:22)(cid:20)(cid:28)(cid:22)(cid:20)(cid:30)(cid:23)(cid:22)(cid:27)(cid:23)(cid:22)(cid:23)(cid:27)(cid:24)(cid:22)(cid:24)(cid:27)(cid:25)(cid:22)(cid:25)(cid:27)(cid:26)(cid:22)(cid:26)(cid:27)(cid:27)(cid:22)(cid:27)(cid:27)(cid:28)(cid:22)Percentage %Mutated Bytes AmountPrecision RateRecall Rate(cid:22)(cid:22)(cid:20)(cid:24)(cid:22)(cid:20)(cid:26)(cid:22)(cid:20)(cid:28)(cid:22)(cid:20)(cid:30)(cid:23)(cid:22)(cid:27)(cid:23)(cid:22)(cid:23)(cid:27)(cid:24)(cid:22)(cid:24)(cid:27)(cid:25)(cid:22)(cid:25)(cid:27)(cid:26)(cid:22)Percentage %Mutated Bytes AmountPrecision RateRecall Rate(a) _EPROCESS
(b) _ETHREAD
(c) _DRIVER_OBJECT
(d) _FILE_OBJECT
Figure 6: Node Embedding Visualization using t-SNE
(a) ROC versus Iterations T
(b) ROC versus Embedding Vector Size
(c) ROC versus Layer Depth of σ
Figure 7: ROC Curves by Tuning Parameters
lacking pointers are not informative enough and also have weak or
no relations with other nodes in the memory. Thus very little infor-
mation could be gathered from others nodes to make inference on
the objects. Fortunately, important kernel objects like _EPROCESS,
_ETHREAD and _DRIVER_OBJECT are long enough for our approach
to achieve over 99.6% recall and over 99.5% precision rate, which is
sufficient for general memory forensic purposes.
Data Diversity and Validity. To generate diverse dumps, we
try to simulate random user actions and allocate kernel objects in
random positions in the memory, as described in the evaluation
section. Even with these efforts, our dataset may not be diverse
enough. To make it more diverse, researchers can use different
physical machines, load different drivers, etc. Nevertheless, our
evaluation on the dataset at least demonstrates the feasibility of
DeepMem in a homogeneous environment (e.g., an enterprise net-
work in which all computers have the same configuration and in a
cloud environment where VMs are instantiated from the same base
image). We use Volatility to label memory dumps as ground truth.
According to the paper [25], Volatility achieves zero FPs and FNs
for most of their plugins for non-malicious dumps. So our training
set labeling should not be affected. Plus, we can use other solutions
to label memory dumps as suggested in this paper, such as using
DECAF [15].
Cross Operating System Versions. In the evaluation phase,
we have already demonstrated the robustness of our approach in
scenarios like pool tag attack, DKOM process hiding and random
bytes mutation. It shows that our approach tolerates well for small
changes and manipulations of the memory. This feature is useful
in real-world applications. For example, our approach will adapt
to systems changes across versions and patches. We leave this for
future work.
6 RELATED WORK
Memory forensic analysis aims at exploring the semantic content of
interests from volatile memory of different platforms and operating
systems, such as Windows [5, 12], Linux [19, 20], Android [19, 26–
28], etc. Among them, kernel object recognition is a fundamental
task. Basically, the approaches can be classified into two categories
according to memory search methods: one is list-traversal [5, 21]
approach, the other is signature-based scanning [3, 4, 11, 20, 23, 32].
List traversal approaches usually start searching objects from
the global root in the memory, then gradually expand the search
scope and find more objects by traversing along the point-to di-
rections of pointers. KOP [5] applies inter-procedural points-to
analysis to compute all possible types for generic pointers, uses a
pattern matching algorithm to resolve type ambiguities, and uti-
lizes knowledge of kernel memory pool boundaries to recognize
dynamic arrays.
Signature scanning approaches usually scan the memory image
from the start to the end sequentially. During the scanning, it tests
whether the observed memory subsequences match the designed
object signatures, then decides the object type of the sequence. Sig-
Graph [20] utilize point-to relations between different objects to
generate non-isomorphic signatures for data structures in an OS
−40−200204060−40−200204060P_24_20P_52_16P_76_64P_192_20P_236_4P_300_36P_400_64P_496_8P_516_64P_584_20−40−200204060−40−2002040T_84_28T_252_12T_340_20T_472_8T_496_24T_528_20T_556_16T_580_8T_596_20T_624_64−40−20020−40−2002040D_8_4D_16_4D_28_4D_40_64D_40_16D_44_64D_48_8D_56_64D_96_64D_132_36−40−2002040−40−200204060F_8_4F_20_32F_24_28F_28_24F_56_28F_56_44F_92_8F_108_8F_124_12F_124_160.00.20.40.60.81.0False Positive Rate0.00.20.40.60.81.0True Positive Rate_FILE_OBJECTT=1T=2T=30.00.20.40.60.81.0False Positive Rate0.00.20.40.60.81.0True Positive Rate_FILE_OBJECTEmbedding Size=16Embedding Size=32Embedding Size=640.00.20.40.60.81.0False Positive Rate0.00.20.40.60.81.0True Positive Rate_FILE_OBJECTLayer Depth=1Layer Depth=2Layer Depth=3expert analysis, 3) it utilizes deep neural network architectures for
efficient parallel computation, and 4) it extracts robust features that
are resistant to attacks like pool tag manipulation, DKOM process
hiding.
The experimental result shows that it performs well in terms of
accuracy, robustness, and efficiency. For accuracy, it reaches above
99.5% recall and precision rate for important kernel objects like
_EPROCESS and _ETHREAD. For robustness, the recognition result
stays stable in different attack scenarios, like manipulating pool tags,
pointers, and even random byte mutations. For efficiency, we turn a
memory dump into an intermediate memory graph representation,
and then detect objects of different types using the graph. The
detection time of each object type is about 13 seconds.
ACKNOWLEDGEMENT
We appreciate the anonymous reviewers for the valuable comments.
We thank Zhenxiao Qi for collecting dataset, Abhishek Srivastava
for providing technical suggestions on TensorFlow and Sri Shaila
for proofreading. The research work is supported by National Sci-
ence Foundation under Grant No. 1664315, 1719175, TWC-1409915.
This work was supported in part by FORCES (Foundations Of Re-
silient CybEr-Physical Systems), which receives support from the
National Science Foundation (NSF award numbers CNS-1238959,
CNS-1238962, CNS-1239054, CNS-1239166). This work is also sup-
ported by Center for Long-Term Cybersecurity from UC Berkeley.
Any opinions, findings, and conclusions or recommendations ex-
pressed in this paper are those of the authors and do not necessarily
reflect the views of the National Science Foundation.
kernel. Dimsum [19] constructs boolean constraints from data struc-
ture definition and memory page contents to build graphical models
so that it can recognize data structure instances in un-mappable
memory. Then it performs probabilistic inference to generate re-
sults ranked with probabilities. An object is detected once it satisfies
all the constraints. Dimsum has slightly higher false negative rate
than Value-Invariant and SigGraph, but it has significantly less
false positive rate than those two systems. Dimsum conducts prob-
abilistic inference and constraint solving to infer the address of
kernel object. To do so, it needs to create many boolean variables
for each memory location, making the factor graph very large and
very expensive to resolve. So Dimsum introduces a pre-processing
phase to reduce the number of locations to test. It may not be robust
if the attackers find a way to evade the pre-processing phase.
In comparison, DeepMem is fundamentally different. The key to
the list-traversal approach is to find the special global root from
which extra objects are traversed and expanded through pointers.
DeepMem does not need to start scanning from the root. It is able
to examine every segment in the memory then comprehensively
evaluate these segments and connections between them to make
a holistic inference decision. We use pointers only in topological
information propagation computation, in this case, an unlinked
pointer would not have a huge impact on the propagation while
list-traverse will completely stop working if a link is broken. The
key to the signature-based approach is to find accurate and robust
signatures for each type of kernel object. It needs to face problems
like generic pointer problem, constraints explosion etc. DeepMem
learns the pointer and non-pointer constraints automatically in-
stead of using hard signatures or expert-made constraints, and
captures non-linear relations between nodes in the graph. It is
more expressive than signature-based approaches, and thus more
accurate and robust. Moreover, both list-traversal and signature
scanning depend partially or fully on operating source code or
data structure definitions. DeepMem does not need this domain
knowledge and specifications.
We also leverage several deep learning techniques [18] in graph
modelings, such as node embedding and node classification. We use
a modified Graph Neural Network [30] to model nodes that preserve
local content information and contextual topological information
through information propagation. Other researchers also make use
of contextual information in the graph to solve the graph embedding
problem [8, 38, 39]. We use Fully-Connected Neural Networks to
make inference in node properties [34]. What is common in these
models is that they are able to achieve an end-to-end learning,
where patterns of data are automatically explored without domain
knowledge or human intervention.
7 CONCLUSION
In this paper, we proposed a graph-based kernel object detection
approach DeepMem. By constructing a whole memory graph and
collecting information through topological information propaga-
tion, we can scan the memory dumps and infer objects of various
types in a fast and robust manner. DeepMem is advanced in that 1)
it does not rely on the knowledge of operating system source code
or kernel data structures, 2) it can automatically generate features
of kernel objects from raw bytes in memory dump without manual
REFERENCES
[1] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey
Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al.
2016. TensorFlow: A System for Large-Scale Machine Learning.. In OSDI.
[2] Cosimo Anglano. 2014. Forensic analysis of WhatsApp Messenger on Android
smartphones. (2014).
[3] Arati Baliga, Vinod Ganapathy, and Liviu Iftode. 2008. Automatic inference and
enforcement of kernel data structure invariants. In Computer Security Applications
Conference (ACSAC).
[4] Chris Betz. 2018. MemParser. https://sourceforge.net/p/memparser/wiki/Home/.
[5] Martim Carbone, Weidong Cui, Long Lu, Wenke Lee, Marcus Peinado, and Xuxian
Jiang. 2009. Mapping kernel objects to enable systematic integrity checking. In
Proceedings of the 16th ACM conference on Computer and communications security.
ACM, 555–565.
[6] Andrew Case and Golden G Richard III. 2016. Memory forensics: The path
forward. (2016).
[7] Weidong Cui, Marcus Peinado, Zhilei Xu, and Ellick Chan. 2012. Tracking Rootkit
Footprints with a Practical Memory Analysis System. In Proceedings of USENIX
Security Symposium.
[8] Hanjun Dai, Bo Dai, and Le Song. 2016. Discriminative embeddings of latent vari-
able models for structured data. In International Conference on Machine Learning.
2702–2711.
[9] DKOM 2018. FU rootkit. https://www.blackhat.com/presentations/win-usa-04/
bh-win-04-butler.pdf.
[10] Brendan Dolan-Gavitt, Tim Leek, Michael Zhivich, Jonathon Giffin, and Wenke
Lee. 2011. Virtuoso: Narrowing the Semantic Gap in Virtual Machine Introspec-
tion. In Proceedings of the IEEE Symposium on Security and Privacy (Oakland).
[11] Brendan Dolan-Gavitt, Abhinav Srivastava, Patrick Traynor, and Jonathon Giffin.
2009. Robust signatures for kernel data structures. In Proceedings of the 16th ACM
Conference on Computer and Communications Security. 566–577.
[12] Qian Feng, Aravind Prakash, Heng Yin, and Zhiqiang Lin. 2014. MACE: high-
coverage and robust memory analysis for commodity operating systems. In
Proceedings of the 30th Annual Computer Security Applications Conference (AC-
SAC’14). ACM, 196–205.
[13] Yangchun Fu and Zhiqiang Lin. 2012. Space Traveling across VM: Automatically
Bridging the Semantic-Gap in Virtual Machine Introspection via Online Kernel
Data Redirection. In Proceedings of the 2012 IEEE Symposium on Security and
Privacy(Oakland’12). IEEE, 586–600.
[14] James A Hanley and Barbara J McNeil. 1982. The meaning and use of the area
under a receiver operating characteristic (ROC) curve. (1982).
[15] Andrew Henderson, Aravind Prakash, Lok Kwong Yan, Xunchao Hu, Xujiewen
Wang, Rundong Zhou, and Heng Yin. 2014. Make it work, make it right, make
it fast: building a platform-neutral whole-system dynamic binary analysis plat-
form. In Proceedings of the 2014 International Symposium on Software Testing and
Analysis.
[16] Greg Hoglund and James Butler. 2006. Rootkits: subverting the Windows kernel.
[17] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-
(2006).
mization. (2014).
[18] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. (2015).
[19] Zhiqiang Lin, Junghwan Rhee, Chao Wu, Xiangyu Zhang, and Dongyan Xu. 2012.
Dimsum: Discovering semantic data of interest from un-mappable memory with
confidence. In Proc. NDSS.
[20] Zhiqiang Lin, Junghwan Rhee, Xiangyu Zhang, Dongyan Xu, and Xuxian Jiang.
2011. SigGraph: Brute Force Scanning of Kernel Data Structure Instances Using
Graph-based Signatures. In Proceedings of the Network and Distributed System
Security Symposium.
(2008).
[21] Zhiqiang Lin, Xiangyu Zhang, and Dongyan Xu. 2010. Automatic reverse en-
gineering of data structures from binary execution. In Proceedings of the 11th
Annual Information Security Symposium.
[22] Laurens van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE.
[23] Nick L Petroni, Aaron Walters, Timothy Fraser, and William A Arbaugh. 2006.
FATKit: A framework for the extraction and analysis of digital forensic data from
volatile system memory. (2006).
[24] David Martin Powers. 2011. Evaluation: from precision, recall and F-measure to
ROC, informedness, markedness and correlation. (2011).
[25] Aravind Prakash, Eknath Venkataramani, Heng Yin, and Zhiqiang Lin. 2015. On
the Trustworthiness of Memory Analysis-An Empirical Study from the Perspec-
tive of Binary Execution. (2015).
[26] Brendan Saltaformaggio, Rohit Bhatia, Zhongshu Gu, Xiangyu Zhang, and
Dongyan Xu. 2015. GUITAR: Piecing together android app GUIs from memory
images. In Proceedings of the 22nd ACM SIGSAC Conference on Computer and
Communications Security. ACM, 120–132.
[27] Brendan Saltaformaggio, Rohit Bhatia, Zhongshu Gu, Xiangyu Zhang, and
Dongyan Xu. 2015. Vcr: App-agnostic recovery of photographic evidence from an-
droid device memory images. In Proceedings of the 22nd ACM SIGSAC Conference
on Computer and Communications Security.
[28] Brendan Saltaformaggio, Rohit Bhatia, Xiangyu Zhang, Dongyan Xu, and
Golden G Richard III. 2016. Screen after Previous Screens: Spatial-Temporal
Recreation of Android App Displays from Memory Images.. In USENIX Security
Symposium.
[29] Brendan Saltaformaggio, Zhongshu Gu, Xiangyu Zhang, and Dongyan Xu. 2014.
DSCRETE: Automatic Rendering of Forensic Information from Memory Images
via Application Logic Reuse.. In USENIX Security Symposium.
[30] Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele
Monfardini. 2009. The graph neural network model. (2009), 61–80.
[31] Jürgen Schmidhuber. 2015. Deep learning in neural networks: An overview.
[32] Andreas Schuster. 2006. Searching for processes and threads in Microsoft Win-
dows memory dumps. (2006).
[33] Andreas Schuster. 2008. The impact of Microsoft Windows pool allocation
strategies on memory forensics. In Digital Investigation, Volume 5.
[34] Alexander G Schwing and Raquel Urtasun. 2015. Fully connected deep structured
networks. (2015).
[35] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
Salakhutdinov. 2014. Dropout: a simple way to prevent neural networks from
overfitting. (2014).
[36] VirtualBox 2018. VirtualBox. https://www.virtualbox.org/.
[37] Volatility 2018.
Volatility: Memory Forencis System.
https://www.
volatilityfoundation.org/.
[38] Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural deep network em-
bedding. In Proceedings of the 22nd ACM SIGKDD international conference on
Knowledge discovery and data mining.
[39] Xiaojun Xu, Chang Liu, Qian Feng, Heng Yin, Le Song, and Dawn Song. 2017.
Neural Network-based Graph Embedding for Cross-Platform Binary Code Simi-
larity Detection. In Proceedings of the 2017 ACM SIGSAC Conference on Computer
and Communications Security.
[40] Yue Zhang and Stephen Clark. 2008. Joint word segmentation and POS tagging
using a single perceptron. (2008).
[41] Hai Zhao, Chang-Ning Huang, and Mu Li. 2006. An improved Chinese word
segmentation system with conditional random field. In Proceedings of the Fifth
SIGHAN Workshop on Chinese Language Processing.
[42] Fan Zhou, Yitao Yang, Zhaokun Ding, and Guozi Sun. 2015. Dump and analysis
of android volatile memory on wechat. In Communications (ICC), 2015 IEEE
International Conference on.
(2015).