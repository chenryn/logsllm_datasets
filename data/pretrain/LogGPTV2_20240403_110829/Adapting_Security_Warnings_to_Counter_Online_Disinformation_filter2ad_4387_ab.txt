must also address the challenge that participants may be more
likely to disregard warnings that hinder task completion [11,
96]. Later research overcame these limitations using ﬁeld
studies, which measure users’ reactions to warnings at scale
in realistic environments [10, 13–15, 17, 19].
This body of work has deﬁnitively established that actively
interrupting a user’s workﬂow with a warning is more effec-
tive at preventing risky behaviors than passively showing the
warning. Wu et al. compared popup warnings to toolbar icons
and found that the popups caused users to behave with signif-
icantly more caution [8]; Egelman et al. observed that 79%
of participants chose not to click through interstitial warnings
compared to 13% for contextual warnings [9]. As a result,
interstitials and other forms of active security warnings have
become standard in all major browsers [17].
Several studies compared multiple warning designs and
found that clear messages and use of visual cues can improve
comprehension and adherence [11–14]. Personalizing mes-
sages based on user-speciﬁc psychological factors has not,
however, shown a signiﬁcant effect on adherence [16].
Limits of Analogizing to Disinformation Warnings The
goals of security and disinformation warnings are not identi-
cal, so to study disinformation warnings, we must adapt—not
simply reuse—the ﬁndings and methods from security warn-
ing research. Security warnings protect users from harms
that are typically individualized, irreversible, and otherwise
difﬁcult for users to avoid themselves. The risks of disinfor-
mation, by contrast, are usually more collective and diffuse
(see Section 2.2) and reversible (e.g., by receiving accurate
information). Moreover, a user who encounters disinforma-
Figure 1: Search results pages displayed contextual warnings.
tion may be readily capable of protecting themselves from
the risk (e.g., if they are media literate). As noted earlier, dis-
information warnings also have speech implications that are
distinct from security warnings. The differences between the
security and disinformation problem domains motivate us to
emphasize designs that inform users throughout our work.
3 Laboratory Study
We began with a laboratory study designed to examine how
participants would process and react to contextual and intersti-
tial disinformation warnings when searching for information.
The search engine context is conducive to studying behavioral
effects because participants have a concrete goal (ﬁnding a
piece of information) and multiple pathways to achieve that
goal (different search results and information sources).
We posed three research questions:
RQ1: In encounters with contextual and interstitial
disinformation warnings, do users notice the warnings?
Prior studies of contextual warnings note that one reason ef-
fect sizes are low or insigniﬁcant is that participants fail to
notice the warnings. Effective warnings must attract user at-
tention through conspicuous design or prominent placement.
RQ2: When users notice contextual and interstitial
warnings, do they understand that the warnings have to
do with disinformation? If a user misunderstands a warn-
ing, they may drop it from further cognitive consideration or
respond in unintended ways that could increase risk.
RQ3: When users encounter and comprehend con-
textual and interstitial disinformation warnings, do they
change their behaviors in the intended way by opting for
alternative sources of information? This is an important
outcome of warning exposure, which we aim to measure as
described in Section 3.4.
3.1 Warning Designs
We adapted contextual and interstitial disinformation
warnings from modern security warnings used by Google.
Google’s warnings are well studied [10, 14, 15, 17, 19, 21,
99] and widely deployed, making them a useful template to
design warnings that participants will believe are real.
We developed our contextual warning (Figure 1) based on
a warning for compromised websites that Google displays in
search results. We changed the color of the text from hyperlink
blue to bold black to indicate that the text could not be clicked.
We also added a red and white exclamation icon next to the
search result to make the warning more noticeable.
We adapted our interstitial warning (Figure 2) from Google
Figure 2: Participants encountered interstitial warnings after
clicking search results.
Chrome’s warning page for malware. We modiﬁed the text
to reference disinformation and changed the “Details” button
to “Learn more.” Clicking “Learn more” revealed a message
explaining that an automated system had ﬂagged the site as
disinformation and a “Continue” button that allowed the user
to bypass the warning and continue to their selected page.
3.2 Study Design
In a laboratory setting, each participant completed a think-
aloud role-playing task followed by an interview. By observ-
ing the participant during the task, we could tell if they noticed
the warnings (RQ1) and altered their behavior in response
(RQ3). Using the interviews, we could conﬁrm whether the
participant noticed the warnings, ask whether they compre-
hended the warnings (RQ2), and seek additional insights into
how the participant processed the warnings.
Role-Playing Task The participant assumed the persona of
an academic researcher trying to ﬁnd answers to four ques-
tions using Google search. As our subjects were students, we
believed this persona would be comfortable and aid with task
immersion. For each question, we provided multiple sources
of information and attached a warning to just one source so
that the participant did not have to click through the warning to
complete the task.3 Unknown to the participant, two questions
were control rounds with no warnings and two were treatment
rounds where warnings were inserted via a browser extension.
We assigned participants in equal numbers to receive either
contextual or interstitial warnings in both treatment rounds.
Search Tasks We designed the search tasks (shown in Ta-
ble 1) to cover simple facts that could be easily found with
a single Google search. For the treatment tasks, we selected
facts speciﬁc to non-U.S. countries and covered by little-
known, non-U.S. news sources in order to satisfy three ad-
ditional design goals. First, the facts were related to cur-
rent events due to the study’s focus on news disinforma-
3Studies of security warnings have shown that this “task focus effect” can
bias participants’ behavior [11, 96].
tion. Second, so that participants could choose between mul-
tiple sources, each fact was publicly reported by at least two
English-language news websites. Third, we aimed to select
facts and websites that participants were not likely to be fa-
miliar with so as to avoid participants having preconceived
biases about the information or the credibility of the sources.
3.3 Study Procedures
We explained the task and role to each participant at the
beginning of their session. We asked the participant to be-
have as if they were using their own computer and to narrate
their thoughts and actions as they performed the task. We
framed the study as examining research and search engine
usage behaviors to avoid priming participants to think about
disinformation or warnings.
Participants began the task on the Google homepage. We
informed participants that they could use either of two speciﬁc
websites to ﬁnd a particular piece of information, and that
they should start with the ﬁrst website and could switch to
the second for any reason.4 Control rounds occurred ﬁrst and
third and treatment rounds occurred second and fourth, with
the question order randomized within those sets.
We did not prescribe speciﬁc search queries to use, but most
participants used a similar format: a set of terms relevant to
the fact they needed to ﬁnd combined with the name of the
website on which they wanted to ﬁnd the information. The
participant would enter the query, navigate through results
to ﬁnd the requested information, and verbally provide an
answer to the researcher. We would then instruct them to
return to the Google homepage to begin the next round.
3.4 Data Collection
We took notes during each session to record how the par-
ticipant selected search results, browsed the websites to seek
information, reacted to warnings, and described their thoughts
and actions. We also computed two metrics for each warning:
a clickthrough rate (CTR) and an alternative visit rate (AVR).
Clickthrough Rate CTR is a commonly used metric in
studies of security warnings. It measures the proportion of
warning encounters where a participant dismisses the warning
and proceeds, instead of going back. For contextual warnings,
we recorded a clickthrough if the participant clicked a result
that had an attached warning and a non-clickthrough if they
chose a different result or changed the search query to use
the second suggested website. For interstitial warnings, we
recorded a clickthrough if the participant clicked “Learn more”
and then bypassed the warning. If the participant clicked
“Back to safety” or used the browser back button to go back
to the search results, we recorded a non-clickthrough.
Alternative Visit Rate We also recorded whether partici-
pants visited an alternative source (i.e., the secondary website)
4This design directly parallels an evaluation of security warnings con-
ducted by Sunshine et al. [11].
during a task, either because the user did not continue beyond
the warning to the primary source or because the user sought
to conﬁrm the accuracy of the information from the primary
source.5 We used this data to compute each warning’s AVR:
the proportion of tasks where a participant visited an alterna-
tive source before completing the task. AVR is a new metric
we devised for empirically measuring the behavioral effects of
a disinformation warning.6 A high AVR indicates that a warn-
ing can inﬂuence users to decide to visit secondary sources of
information.7 In some cases this will cause a user not to see
the disinformation at all, and in all cases it exposes the user
to alternative information.
Interview After the ﬁnal round, we informed participants
of the true purpose of the study, then conducted the interview.
We ﬁrst asked about the participant’s general understanding of
disinformation: how they deﬁned disinformation, what made
them believe a website might contain disinformation, and if
they had ever encountered content that they recognized as
disinformation. Next, we asked the participant to describe
their reactions to the warnings that they encountered during
the study. We prompted participants to elaborate on these
responses until we could determine whether the participant
had noticed and comprehended the warnings (RQ1 and RQ2).
Before the next round of questions, we showed the partici-
pant printouts of the contextual and interstitial warnings used
in the study. We then asked whether the participant believed
the warnings would be effective in use, if they felt that one
format would be more effective than the other, and if they had
recommendations for how disinformation warnings in general
could be made more effective.
Finally, we asked about the participant’s demographics,
academic background, and level of news consumption.8
Coding We combined interview transcripts with our notes
to form a single report for each session, then open coded the
reports using Dedoose. One author performed the initial cod-
ing, producing 253 unique codes, then condensed the codes
into themes. A second author validated this work, ensuring
that the codes accurately reﬂected the study data and that the
proposed themes were justiﬁed by the codes.
3.5 Participant Recruiting
We recruited participants through the Princeton Univer-
sity Survey Research Center, which advertises to randomly
5CTR and AVR are closely related: a non-clickthrough is a type of alter-
native visit. As a result, AVR ≥ 1− CTR.
6Another advantage of the AVR metric is that it is available in control
conditions, not just treatment conditions. We did not record alternative visits
for control rounds in the laboratory study, but we make extensive use of
control round AVR in the crowdworker study.
7AVR does not capture user perceptions of warnings or the accuracy of
user beliefs, which is why we pair this approach with qualitative methods. It
is an important open question whether encounters with high AVR warnings
are associated with more accurate beliefs, easier correction of misperceptions,
or better ability to distinguish disinformation from real news.
8We list all survey questions in supporting materials [100].
Table 1: We measured clickthrough rates (CTR) and alternative visit rates (AVR) in treatment rounds of the laboratory study.
Round
Control 1
Control 2
Treatment 1
Treatment 2
Participant Instructions
Contextual Warning
CTR
AVR
Interstitial Warning
CTR
AVR
Find the total area of Italy in square kilometers
on Wikipedia or WorldAtlas.
Report the price of a pair of men’s New Balance 574
on JoesNewBalanceOutlet or 6pm.com.
Find the political party of Taiwan’s Premier on
TheNewsLens or FocusTaiwan.
Find the name of the girl reported missing in Barbados
on Feb 11, 2019 on BarbadosToday or LoopNewsBarbados.
–
–
15/20
18/20
–
–
7/20
4/20
–
–
–
–
7/20
13/20
11/20
10/20
selected students. We also sent recruiting emails to distribu-
tion lists of various student organizations. We received 76
responses and selected 40 participants. Our participant group
consisted of 16 women and 24 men aged 18-28 years old,
studying across 17 disciplines.
Clearly this sample is biased in several respects, including
age, education level, and social group. Later in this work, we
evaluate a signiﬁcantly more diverse sample recruited online
(see RQ1 in Section 4). In the context of security warning
studies, student populations have been shown to provide simi-
lar results to more representative samples [96].
The recruiting and consent materials provided to partic-
ipants indicated that the study would take 30-45 minutes
and focus on the user experience of search engines, with no
mention of disinformation or browser warnings. Participants
signed consent forms before beginning the study and were
paid $15. The study was approved by the Princeton IRB.
3.6 Results
We present quantitative results for the warnings’ behavioral
effects (Table 1). We also discuss how notice and compre-
hension related to participant behavior and present qualitative
results on user opinions and perceptions of the warnings.
3.6.1 Behavioral Effects
Contextual The CTR for the contextual warning was very
high: 33/40. There were a total of 11/40 alternative visits: 7
non-clickthroughs and 4 occasions where a participant who
clicked through a warning went back to search again using
the secondary source.
Interstitial The CTR for the interstitial warning was much
lower: 18/40. We observed 1 alternative visit after a click-
through and 22 alternative visits after non-clickthroughs, for
a total AVR of 23/40.
3.6.2 Notice and Comprehension