width in our simulation in Figure 4.
We recap how to choose A and S for a given Z in Ta-
ble 4. For the rest of the paper, we will choose A and S
this way unless otherwise stated. Using this method to
set A and S, we show online and overall bandwidth as a
function of Z in Figure 5. In the ﬁgure, Ring ORAM does
not use the XOR technique on reads. For Z = 50, we
achieve ∼ 3.5logN bandwidth; for very large Z, band-
width approaches 3logN. Applying the XOR technique,
online bandwidth overhead drops to close to 1 which re-
duces overall bandwidth to ∼ 2.5logN for Z = 50 and
2The possibility that a bucket needs to be early reshufﬂed twice
before an eviction is negligible.
6.1 Bandwidth vs. Client Storage
To give a holistic comparison between schemes, Figure 6
shows the best achievable bandwidth, for different client
storage budgets, for Path ORAM and Ring ORAM. For
each scheme in the ﬁgure, we apply all known optimiza-
tions and tune parameters to minimize overall bandwidth
given a storage budget. For Path ORAM we choose Z = 4
(increasing Z strictly hurts bandwidth) and tree-top cache
to ﬁll remaining space. For Ring ORAM we adjust Z, A
and S, tree-top cache and apply the XOR technique.
To simplify the presentation, “client storage” includes
all ORAM data structures except for the position map
– which has the same space/bandwidth cost for both
Path ORAM and Ring ORAM. We remark that applying
the recursion technique (Section 3.7) to get a small on-
chip position map is cheap for reasonably large blocks.
For example, recursing the on-chip position map down
to 256 KiloBytes of space when the data block size
is 4 KiloBytes increases overall bandwidth for Ring
ORAM and Path ORAM by < 3%.
The high order bit is that across different block sizes
and client storage budgets, Ring ORAM consistently re-
duces overall bandwidth relative to Path ORAM by 2-
2.7×. We give a summary of these results for several rep-
resentative client storage budgets in Table 5. We remark
that for smaller block sizes, Ring ORAM’s improvement
over Path ORAM (∼ 2× for 64 Byte blocks) is smaller
relative to when we use larger blocks (2.7× for 4 Kilo-
Byte blocks). The reason is that with small blocks, the
cost to read bucket metadata cannot be ignored, forcing
Ring ORAM to use smaller Z.
USENIX Association  
24th USENIX Security Symposium  425
11
Z, A (Ring ORAM only) Ring ORAM Ring ORAM (XOR)
Online, Overall Bandwidth overhead
Block Size (Bytes)
64
4096
10,11
33,48
48×, 144×
20×, 82×
24×, 118×
∼ 1×, 60×
Path ORAM
120×, 240×
80×, 160×
Table 5: Breakdown between online and ofﬂine bandwidth given a client storage budget of 1000× the block size for several
representative points (Section 6.1). Overheads are relative to an insecure system. Parameter meaning is given in Table 2.
7 Ring ORAM with Large Client Storage
If given a large client storage budget, we can ﬁrst choose
very large A and Z for Ring ORAM, which means band-
width approaches 2logN (Section 5).3 Then remaining
client storage can be used to tree-top cache (Section 3.6).
For example, tree-top caching t = L/2 levels requires
O(√N) storage and bandwidth drops by a factor of 2
to 1 · logN—which roughly matches the SSS construc-
tion [25].
Burst ORAM [3] extends the SSS construction to han-
dle millions of accesses in a short period, followed by
a relatively long idle time where there are few requests.
The idea to adapt Ring ORAM to handle bursts is to de-
lay multiple (potentially millions of) EvictPath opera-
tions until after the burst of requests. Unfortunately, this
strategy means we will experience a much higher early
reshufﬂe rate in levels towards the root. The solution
is to coordinate tree-top caching with delayed evictions:
For a given tree-top size t, we allow at most 2t delayed
EvictPath operations. This ensures that for levels ≥ t,
the early reshufﬂe rate matches our analysis in Section 5.
We experimentally compared this methodology to the
dataset used by Burst ORAM and veriﬁed that it gives
comparable performance to that work.
8 Related Work
ORAM was ﬁrst proposed by Goldreich and Ostro-
vsky [10, 11]. Since then, there have been numerous
follow-up works that signiﬁcantly improved ORAM’s ef-
ﬁciency in the past three decades [21, 20, 2, 1, 29, 12,
13, 15, 25, 23, 9, 27, 28]. We have already reviewed two
state-of-the-art schemes with different client storage re-
quirements: Path ORAM [27] and the SSS ORAM [25].
Circuit ORAM [28] is another recent tree-based ORAM,
which requires only O(1) client storage, but its band-
width is a constant factor worse than Path ORAM.
Reducing online bandwidth.
Two recent works
[3, 19] have made efforts to reduce online bandwidth
(response time). Unfortunately, the techniques in Burst
ORAM [3] do not work with Path ORAM (or more
generally any existing tree-based ORAMs). On the
3We assume the XOR technique because large client storage implies
a ﬁle server setting.
Figure 7: SPEC benchmark slowdown.
6.2 Case Study: Secure Processors
In this study, we show how Ring ORAM improves the
performance of secure processors over Path ORAM. We
assume the same processor/cache architecture as [5],
given in Table 4 of that work. We evaluate a 4 GigaByte
ORAM with 64-Byte block size (matching a typical pro-
cessor’s cache line size). Due to the small block size,
we parameterize Ring ORAM at Z = 5, A = 5, X = 2
to reduce metadata overhead. We use the optimized
ORAM recursion techniques [22]: we apply recursion
three times with 32-Byte position map block size and get
a 256 KB ﬁnal position map. We evaluate performance
for SPEC-int benchmarks and two database benchmarks,
and simulate 3 billion instructions for each benchmark.
We assume a ﬂat 50-cycle DRAM latency, and com-
pute ORAM latency assuming 128 bits/cycle processor-
memory bandwidth. We do not use tree-top caching
since it proportionally beneﬁts both Ring ORAM and
Path ORAM. Today’s DRAM DIMMs cannot perform
any computation, but it is not hard to imagine having
simple XOR logic either inside memory, or connected to
O(logN) parallel DIMMs so as not to occupy processor-
memory bandwidth. Thus, we show results with and
without the XOR technique.
Figure 7 shows program slowdown over an insecure
DRAM. The high order bit is that using Ring ORAM
with XOR results in a geometric average slowdown of
2.8× relative to an insecure system. This is a 1.5× im-
provement over Path ORAM. If XOR is not available, the
slowdown over an insecure system is 3.2×.
We have also repeated the experiment with the uniﬁed
ORAM recursion technique and its parameters [5]. The
geometric average slowdown over an insecure system is
2.4× (2.5× without XOR).
426  24th USENIX Security Symposium 
USENIX Association
12
other hand, Path-PIR [19], while featuring a tree-based
ORAM, employs heavy primitives like Private Informa-
tion Retrieval (PIR) or even FHE, and thus requires a
signiﬁcant amount of server computation. In compari-
son, our techniques efﬁciently achieve O(1) online cost
for tree-based ORAMs without resorting to PIR/FHE,
and also improve bursty workload performance similar
to Burst ORAM.
Subsequent work. Techniques proposed in this paper
have been adopted by subsequent works. For example,
Tiny ORAM [6] and Onion ORAM [4] used part of our
eviction strategy in their design for different purposes.
9 Conclusion
This paper proposes Ring ORAM, the most bandwidth-
efﬁcient ORAM scheme for the small (constant or poly-
log) client storage setting. Ring ORAM is simple, ﬂexi-
ble and backed by a tight theoretic analysis.
Ring ORAM is the ﬁrst tree-based ORAM whose
online and overall bandwidth are independent of tree
ORAM bucket size. With this and additional proper-
ties of the algorithm, we show that Ring ORAM im-
proves online bandwidth by 60× (if simple computa-
tion such as XOR is available at memory), and overall
bandwidth by 2.3× to 4× relative to Path ORAM. In a
secure processor case study, we show that Ring ORAM’s
bandwidth improvement translates to an overall program
performance improvement of 1.5×. By increasing Ring
ORAM’s client storage, Ring ORAM is competitive in
the cloud storage setting as well.
Acknowledgement
This research was partially by NSF grant CNS-
1413996 and CNS-1314857, the QCRI-CSAIL partner-
ship, a Sloan Fellowship, and Google Research Awards.
Christopher Fletcher was supported by a DoD National
Defense Science and Engineering Graduate Fellowship.
References
[1] BONEH, D., MAZIERES, D., AND POPA, R. A. Remote
oblivious storage: Making oblivious RAM practical.
Manuscript,
http://dspace.mit.edu/bitstream/
handle/1721.1/62006/MIT-CSAIL-TR-2011-018.
pdf, 2011.
[2] DAMG ˚ARD, I., MELDGAARD, S., AND NIELSEN, J. B.
Perfectly secure oblivious RAM without random oracles.
In TCC (2011).
[4] DEVADAS, S., VAN DIJK, M., FLETCHER, C. W., REN,
L., SHI, E., AND WICHS, D. Onion oram: A con-
stant bandwidth blowup oblivious ram. Cryptology ePrint
Archive, 2015. http://eprint.iacr.org/2015/005.
[5] FLETCHER, C., REN, L., KWON, A., VAN DIJK, M.,
AND DEVADAS, S. Freecursive oram: [nearly] free recur-
sion and integrity veriﬁcation for position-based oblivious
ram. In ASPLOS (2015).
[6] FLETCHER, C., REN, L., KWON, A., VAN DIJK, M.,
STEFANOV, E., SERPANOS, D., AND DEVADAS, S. A
low-latency, low-area hardware oblivious ram controller.
In FCCM (2015).
[7] FLETCHER, C., REN, L., YU, X., VAN DIJK, M.,
KHAN, O., AND DEVADAS, S. Suppressing the obliv-
ious ram timing channel while making information leak-
age and program efﬁciency trade-offs. In HPCA (2014).
[8] FLETCHER, C., VAN DIJK, M., AND DEVADAS, S. Se-
cure Processor Architecture for Encrypted Computation
on Untrusted Programs. In STC (2012).
[9] GENTRY, C., GOLDMAN, K. A., HALEVI, S., JUTLA,
C. S., RAYKOVA, M., AND WICHS, D. Optimizing oram
and using it efﬁciently for secure computation.
In PET
(2013).
[10] GOLDREICH, O. Towards a theory of software protection
and simulation on oblivious rams. In STOC (1987).
[11] GOLDREICH, O., AND OSTROVSKY, R. Software pro-
In J. ACM
tection and simulation on oblivious rams.
(1996).
[12] GOODRICH, M. T., AND MITZENMACHER, M. Privacy-
preserving access of outsourced data via oblivious ram
simulation. In ICALP (2011).
[13] GOODRICH, M. T., MITZENMACHER, M., OHRI-
MENKO, O., AND TAMASSIA, R. Privacy-preserving
group data access via stateless oblivious RAM simula-
tion. In SODA (2012).
[14] ISLAM, M., KUZU, M., AND KANTARCIOGLU, M. Ac-
cess pattern disclosure on searchable encryption: Ramiﬁ-
cation, attack and mitigation. In NDSS (2012).
[15] KUSHILEVITZ, E., LU, S., AND OSTROVSKY, R. On
the (in) security of hash-based oblivious ram and a new
balancing scheme. In SODA (2012).
[16] LIU, C., HARRIS, A., MAAS, M., HICKS, M., TIWARI,
M., AND SHI, E. Ghostrider: A hardware-software sys-
tem for memory trace oblivious computation. In ASPLOS
(2015).
[17] LORCH, J. R., PARNO, B., MICKENS, J. W., RAYKOVA,
M., AND SCHIFFMAN, J. Shroud: Ensuring private ac-
cess to large-scale data in the data center. In FAST (2013).
[18] MAAS, M., LOVE, E., STEFANOV, E., TIWARI, M.,
SHI, E., ASANOVIC, K., KUBIATOWICZ, J., AND
SONG, D. Phantom: Practical oblivious computation in a
secure processor. In CCS (2013).
[3] DAUTRICH, J., STEFANOV, E., AND SHI, E. Burst oram:
Minimizing oram response times for bursty access pat-
terns. In USENIX (2014).
[19] MAYBERRY, T., BLASS, E.-O., AND CHAN, A. H. Ef-
ﬁcient private ﬁle retrieval by combining oram and pir. In
NDSS (2014).
USENIX Association  
24th USENIX Security Symposium  427
13
[20] OSTROVSKY, R. Efﬁcient computation on oblivious
rams. In STOC (1990).
[21] OSTROVSKY, R., AND SHOUP, V. Private information
storage (extended abstract). In STOC (1997).
[22] REN, L., YU, X., FLETCHER, C., VAN DIJK, M., AND
DEVADAS, S. Design space exploration and optimiza-
tion of path oblivious ram in secure processors. In ISCA
(2013).
[23] SHI, E., CHAN, T.-H. H., STEFANOV, E., AND LI, M.
Oblivious ram with o((logn)3) worst-case cost. In Asi-
acrypt (2011).
[24] STEFANOV, E., AND SHI, E. Oblivistore: High perfor-
mance oblivious cloud storage. In S&P (2013).
[25] STEFANOV, E., SHI, E., AND SONG, D. Towards practi-
cal oblivious RAM. In NDSS (2012).
[26] STEFANOV, E., VAN DIJK, M., SHI, E., CHAN, T.-
H. H., FLETCHER, C., REN, L., YU, X., AND DE-
VADAS, S. Path oram: An extremely simple oblivious
ram protocol. Cryptology ePrint Archive, 2013. http:
//eprint.iacr.org/2013/280.
[27] STEFANOV, E., VAN DIJK, M., SHI, E., FLETCHER, C.,
REN, L., YU, X., AND DEVADAS, S. Path oram: An
extremely simple oblivious ram protocol. In CCS (2013).
[28] WANG, X. S., CHAN, T.-H. H., AND SHI, E. Cir-
cuit oram: On tightness of the goldreich-ostrovsky lower
bound. Cryptology ePrint Archive, 2014.
http://
eprint.iacr.org/2014/672.
[29] WILLIAMS, P., AND SION, R. Single round access pri-
vacy on outsourced storage. In CCS (2012).
[30] WILLIAMS, P., SION, R., AND TOMESCU, A. Privatefs:
A parallel oblivious ﬁle system. In CCS (2012).
[31] YU, X., FLETCHER, C. W., REN, L., VAN DIJK, M.,
AND DEVADAS, S. Generalized external interaction
with tamper-resistant hardware with bounded information
leakage. In CCSW (2013).
[32] ZHUANG, X., ZHANG, T., AND PANDE, S. HIDE: an in-
frastructure for efﬁciently protecting information leakage
on the address bus. In ASPLOS (2004).
A Bucket Structure
Table 6 lists all the ﬁelds in a Ring ORAM bucket and
their size. We would like to make two remarks. First,
only the data ﬁelds are permuted and that permutation
is stored in ptrs. Other bucket ﬁelds do not need to
be permuted because when they are needed, they will
be read in their entirety. Second, count and valids are
stored in plaintext. There is no need to encrypt them
since the server can see which bucket is accessed (deduc-
ing count for each bucket), and which slot is accessed in
each bucket (deducing valids for each bucket). In fact,
if the server can do computation and is trusted to follow
Algorithm 5 Helper functions.
count, valids, addrs, leaves, ptrs, data are ﬁelds of the
input bucket in each of the following three functions
1: function GetBlockOﬀset(bucket,a)
2:
3:
4:
5:
6:
read in valids, addrs, ptrs
decrypt addrs, ptrs
for j ← 0 to Z − 1 do
return ptrs[ j]
if a = addrs[ j] and valids[ptrs[ j]] then
return a pointer to a random valid dummy
(cid:30) block of interest
(cid:30) track # of remaining real blocks
if valids[ptrs[ j]] then
read in valids, addrs, leaves, ptrs
decrypt addrs, leaves, ptrs
z ← 0
for j ← 0 to Z − 1 do
1: function ReadBucket(bucket)
2:
3:
4:
5:
6:
7: