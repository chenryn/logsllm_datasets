### Sample Selection Strategies

Once all initial samples have been analyzed and additional analysis resources are available, we proceed to select a second sample for each peHash, and so on. Below are the detailed selection strategies:

- **Static**: This strategy is similar to the peHash-based approach but uses a sample’s static cluster, identified using techniques from Jacob et al. [23], instead of its peHash. This method, combined with the peHash selection strategy, represents the state-of-the-art in sample selection.

- **ForeCast**: We use FORECAST to select samples for analysis. We test FORECAST with values of \( L \) (the level of parallelism) ranging from 50 to 1600.

- **Optimum**: In this scenario, we perform sample selection based on FORECAST’s cluster scoring technique, assuming that cluster prediction is 100% accurate. That is, we know the behavioral cluster of each sample before execution. While this strategy is not practical, it serves as an upper bound on the benefits a sample selection strategy can achieve.

### Simulation Results

Figure 3 presents the simulation results for network endpoint scores with \( L = 100 \). The X-axis shows the capacity of the simulated sandbox relative to the real sandbox, representing the percentage of daily samples the simulated sandbox can handle. The Y-axis indicates the percentage of relevant features observed over the 61-day period, which corresponds to the percentage of C&C endpoints discovered by the simulated sandbox.

#### Table 4: Simulation Results at 15% Sandbox Capacity

| Number of Features | Percentage of Features | Improvement over Random |
|--------------------|------------------------|-------------------------|
| 1645               | 17%                    | 0%                      |
| 2242               | 23%                    | 36%                     |
| 2504               | 26%                    | 52%                     |
| 3900               | 41%                    | 137%                    |
| 3857               | 40%                    | 134%                    |
| 3899               | 41%                    | 137%                    |
| 3821               | 40%                    | 132%                    |
| 3825               | 40%                    | 133%                    |
| 3732               | 39%                    | 127%                    |
| 5271               | 55%                    | 220%                    |

FORECAST clearly outperforms the random selection strategy. To provide concrete numbers, we compared the approaches at 15% of the simulated sandbox capacity, as limited resources make sample selection more critical. The results show that FORECAST significantly improves the discovery of relevant features.

### Runtime Performance

Table 5 shows FORECAST’s runtime for the simulation on the 2010 dataset, running on a single server. The total time per sample is under one second, which is negligible compared to the four minutes our sandbox spends executing each sample. Note that the cost of running AV engines on the samples is not included, as we obtain AV results from VirusTotal [7]. Performing AV-scanning with all engines supported by VirusTotal would require an additional five seconds per sample using a single machine [16].

### Evasion Techniques

Our experiments demonstrate that FORECAST is effective in selecting samples for dynamic analysis that provide useful information. However, malware authors might attempt to evade analysis by tricking our system into not selecting their binaries. They could attack our cluster prediction component, which relies on the static features discussed in Section 3.2. Possible evasion techniques include:

- **Polymorphic Mutation**: Malware authors could develop techniques to mutate samples to evade peHash [41] and static clustering [23].
- **Mimicry Attack**: They could try to mimic benign behavior or low-interest clusters (e.g., Allaple cluster) to avoid detection. However, such samples would likely be detected by most AV engines, making evasion challenging.

### Related Work

There is extensive research on malware detection and analysis. Current popular methods include sandboxes [13, 3, 4, 5, 6], which run unknown programs in an instrumented environment to record interactions with the operating system and network. Other approaches include dynamic activity clustering [11, 14], supervised malware classification [36], and static techniques [26, 35, 25, 40]. Some tools can process packed malware without dynamic unpacking [33, 41, 23], but they often require dynamic analysis. Our system, FORECAST, outperforms these methods by efficiently selecting relevant samples without executing them.

### Conclusion

Given the high volume of malware samples discovered daily, efficient use of time is crucial for dynamic malware analysis systems. FORECAST selects the most relevant samples for analysis based on a domain-specific scoring function. Our experiments show that FORECAST is highly effective, achieving high accuracy and outperforming other selection strategies on a test set of over 600,000 malware samples.

### Acknowledgements

This research was funded by the European Union Seventh Framework Programme (SysSec), the Prevention, Preparedness, and Consequence Management of Terrorism and other Security-related Risks Programme (i-Code), and the Austrian Research Promotion Agency (TRUDIE).

### References

[References listed as provided in the original text]

This revised version aims to enhance clarity, coherence, and professionalism while maintaining the essential details and structure of the original text.