B. Error Reports and Patches
Current best practices dictate that program crashes on end-
user systems can be reported back to the software developers.
The developers use these reports to prioritize and address bugs
and to produce software updates that improve the stability and
security of their products.
Error reports contain machine state information such as the
instruction pointer plus stack and register contents at the time
of the crash. The reports are sent to a server that performs two
tasks: it uses debug information to determine the source code
location of the crash and it matches the new error report with
previous reports to rank bugs by frequency.
Unfortunately, software diversity interferes with the pro-
cessing of error reports. The randomization of the program
implementation makes error reports diverge even if two users
trigger the exact same error. Programs are typically distributed
without debugging information and therefore report crashes
using the instruction pointer plus the register and stack contents.
Developers store a single copy of the debugging information
for each software release to translate locations in the binary
into source code locations in a process known as symbolication.
With code layout randomization, however,
the instruction
pointer corresponding to a particular source code line will vary
between variants. If not addressed, diversiﬁcation interferes
with symbolication of error reports.
A straw-man solution is to generate or store debug infor-
mation for each program variant on the error reporting server.
Unfortunately, this is space consuming and impractical for
client-side diversiﬁcation approaches. The alternative is to hide
the effects of diversiﬁcation from error reporting frameworks.
Error reports can be transformed to a “canonical” version
matching what an undiversiﬁed copy of the program would
report for the same error. This requires a way to integrate with
existing error reporting mechanisms and meta-data to drive the
transformations.
Diversiﬁcation approaches that randomize the on-disk
representation of programs also interfere with software patches.
If each user has a unique program copy, patches must be
customized to each individual copy. Neither of these challenges
have received much attention to date.
C. Implementation Disclosure
Besides low entropy, information leakage threatens the
effectiveness of diversiﬁed defenses. Information leaks are
accidental disclosures of the layout or contents of process or
kernel memory [56]. ASLR shifts all addresses by the same
amount such that relative distances within a library remain
unchanged; this means that an attacker can infer the entire
code layout if a single code address is disclosed.
Finer-grained code randomization also affects the relative
distances between code fragments. Bypassing such random-
ization requires disclosure of multiple code addresses. Snow
et al. [60] demonstrate a just-in-time code-reuse attack that
uses JavaScript to discover the code layout (via a bounds
checking error in C++ code) and to build a customized ROP
chain, thus defeating ﬁne-grained code-diversiﬁcation. Bittau et
al. [9] perform a “blind return-oriented-programming” attack by
exploiting a buffer overﬂow in the nginx web-server and using
the response (crash, no crash) as a side channel to incrementally
guess the position of a required gadget set in fully diversiﬁed
binaries. These attacks call for work on new types of diversity
that prevent or tolerate (partial) information disclosure.
Crane et al. [20] propose that diversiﬁed binaries be “booby-
trapped” with code that detects guessing attacks. A booby-trap
is an instruction sequence beginning with an unconditional
branch past its last instruction so the trap is skipped during
normal execution; attempts to execute code at random addresses,
however, will eventually trigger the trap. Traps help alert
defenders to attacks and may even allow programs to operate
through attacks by recovering corrupted state.
D. Measuring Efﬁcacy
The study of how diversity affects the adversary’s effort is in
its infancy. Many of the works we survey report several detailed
performance metrics on standardized benchmarks. This is in
stark contrast to the security evaluations which are frequently
qualitative, i.e., based on a logical argument on why attacks
fail, an analytical calculation of the resulting entropy, or the
demonstration of concrete attacks that fail.
Few studies quantify the impact of diversiﬁcation—e.g.,
by counting surviving gadgets when defending against ROP
attacks [31] or the percentage of code that can be matched
after diversiﬁcation [17]. On a similar note, entropy results
determine the space of a diversiﬁed population, but there are
no studies that show how well program variants are distributed
within that space. This matters because some transformations
are not always legal; performing equivalent instruction selection
on a program with thousands of functions can generate many
variants in principle, but if only a handful of functions use
instructions that can be substituted, then the resulting population
is not sufﬁciently diverse.
We believe the reasons for this are twofold. First, there
is a lack of consensus on acceptable methodologies. Second,
having a set of publicly available tools to evaluate and compare
approaches with would reduce the effort to evaluate security.
Numerous papers have been published on how to perform
sound performance evaluations; we think a similar effort should
be undertaken with respect to efﬁcacy metrics for diversiﬁed
software.
288
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:59:27 UTC from IEEE Xplore.  Restrictions apply. 
E. Diversity as a Counter to Side Channel Attacks
Covert channels exist whenever computation has observable
side-effects. For example, the time to divide two numbers
depends on the operands and the time to access a memory
location depends on the state of the memory hierarchy.
Attackers can build statistical models that correlate sensitive
program data, e.g., cryptographic keys, with side-effects by
observing the target program operating on known inputs. The
growing popularity of cloud computing, which co-locates
computation of its customers on shared hardware, only increases
the need for a solution to this long standing problem.
One of the key requirements to build a side-channel attack
is the ability to accurately replicate the victim environment.
However, software diversity breaks exactly this assumption.
Attackers no longer have easy access to an exact copy of
the target program. Consequently, we expect that existing and
side-channel speciﬁc randomizing transformations provides an
effective counter to this long standing threat.
VII. CONCLUSIONS
The overall idea of software diversity is simple. However,
we show how the interactions with current development,
distribution, and security practices are not. We bring clarity
to this complex ﬁeld by treating the major axes of software
diversity independently while using a consistent terminology.
There is a tension between pre-distribution and post-
distribution diversiﬁcation approaches. The former are easy to
implement portably, support the widest range of transformations,
and can defend against client-side attacks. The latter support
legacy and proprietary software, amortize diversiﬁcation costs,
and require no changes to current distribution mechanisms. In
terms of performance, approaches of both kinds can deliver
acceptable overheads (as low as 1-5%). The two fastest binary
rewriters may not preserve program semantics [47], [21] though.
With two exceptions [21], [40] research in software diversity
does not consider compatibility with security features such as
crash reporting and code signing.
Naturally, the research in software diversity can be extended;
we point out several promising directions. There is currently a
lack of research on hybrid approaches combining aspects of
compilation and binary rewriting to address practical challenges
of current techniques. We also point to the need to address
memory disclosure attacks on diversity and ﬁnally argue that
diversiﬁed software may provide an effective defense against
side channel attacks.
ACKNOWLEDGMENTS
We thank the anonymous reviewers, Prof. Greg Morrisett,
Stephen Crane, and Mark Murphy for their insightful reviews,
helpful suggestions, and proofreading.
This material is based upon work partially supported by the
Defense Advanced Research Projects Agency (DARPA) under
contracts D11PC20024 and N660001-1-2-4014, by the National
Science Foundation (NSF) under grant No. CCF-1117162, and
by a gift from Google.
Any opinions, ﬁndings, and conclusions or recommenda-
tions expressed in this material are those of the authors and
do not necessarily reﬂect the views of the Defense Advanced
Research Projects Agency (DARPA), its Contracting Agents,
the National Science Foundation, or any other agency of the
U.S. Government.
[1] M. Abadi, M. Budiu,
REFERENCES
´U. Erlingsson, and J. Ligatti. Control-ﬂow
integrity. In Proceedings of the 12th ACM Conference on Computer
and Communications Security, CCS ’05, pages 340–353, 2005.
[2] Aleph One. Smashing the Stack for Fun and Proﬁt. Phrack Magazine,
7(49), 1996. http://www.phrack.org/issues.html?id=14&issue=49.
[3] K. Anand, M. Smithson, K. Elwazeer, A. Kotha, J. Gruen, N. Giles, and
R. Barua. A compiler-level intermediate representation based binary
analysis and rewriting system. In Proceedings of the 8th ACM European
Conference on Computer Systems, EuroSys ’13, pages 295–308, 2013.
[4] A. Avizienis and L. Chen. On the implementation of N-version pro-
gramming for software fault tolerance during execution. In Proceedings
of the International Computer Software and Applications Conference,
COMPSAC ’77, pages 149–155, 1977.
[5] E. Barrantes, D. Ackley, S. Forrest, and D. Stefanovi´c. Randomized
instruction set emulation. ACM Transactions on Information and System
Security, 8(1):3–40, 2005.
[6] S. Bhatkar, D. DuVarney, and R. Sekar. Address obfuscation: An
efﬁcient approach to combat a broad range of memory error exploits. In
Proceedings of the 12th USENIX Security Symposium, SEC ’03, pages
105–120, 2003.
[7] S. Bhatkar and R. Sekar. Data space randomization. In Proceedings of the
Conference on Detection of Intrusions and Malware, and Vulnerability
Assessment, DIMVA ’08, pages 1–22, 2008.
[8] S. Bhatkar, R. Sekar, and D. DuVarney. Efﬁcient techniques for
comprehensive protection from memory error exploits. In Proceedings
of the 14th USENIX Security Symposium, SEC ’05, pages 271–286,
2005.
[9] A. Bittau, A. Belay, A. Mashtizadeh, D. Mazi`eres, and D. Boneh.
Hacking blind. In Proceedings of the 35th IEEE Symposium on Security
and Privacy, S&P ’14, 2014.
[10] D. Blazakis. Interpreter exploitation. In Proceedings of the 4th USENIX
Workshop on Offensive technologies, WOOT’10, 2010.
[11] L. Chen and A. Avizienis. N-version programming: A fault-tolerance
approach to reliability of software operation. In Twenty-Fifth Interna-
tional Symposium on Fault-Tolerant Computing, 1995, ’ Highlights from
Twenty-Five Years’, FTCS ’95, page 113, 1995.
[12] M. Chew and D. Song. Mitigating buffer overﬂows by operating
system randomization. Technical Report CMU-CS-02-197, Department
of Computer Science, Carnegie Mellon University, 2002.
[13] F. Cohen. Operating system protection through program evolution.
Computers and Security, 12(6):565–584, Oct. 1993.
[14] C. Collberg, C. Thomborson, and D. Low. A taxonomy of obfuscating
transformations. Technical Report 148, Department of Computer Science,
University of Auckland, New Zealand, 1997.
[15] C. S. Collberg, S. Martin, J. Myers, and J. Nagra. Distributed application
tamper detection via continuous software updates. In Proceedings of the
28th Annual Computer Security Applications Conference, ACSAC ’12,
pages 319–328, 2012.
[16] C. S. Collberg, C. D. Thomborson, and D. Low. Manufacturing cheap,
resilient, and stealthy opaque constructs. In Proceedings of the 25th
ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages, POPL ’98, pages 184–196, 1998.
[17] B. Coppens, B. De Sutter, and J. Maebe. Feedback-driven binary code
diversiﬁcation. Transactions on Architecture and Code Optimization,
9(4), Jan. 2013.
[18] B. Coppens, B. D. Sutter, and K. D. Bosschere. Protecting your software
updates. IEEE Security & Privacy, 11(2):47–54, 2013.
[19] C. Cowan, C. Pu, D. Maier, J. Walpole, P. Bakke, D. Beattie, A. Grier,
P. Wagle, Q. Zhang, and H. Hinton. StackGuard: Automatic Adaptive
Detection and Prevention of Buffer-Overﬂow Attacks. In Proceedings
of the 7th USENIX Security Symposium, SEC ’98, pages 63–78, 1998.
289
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:59:27 UTC from IEEE Xplore.  Restrictions apply. 
[20] S. Crane, P. Larsen, S. Brunthaler, and M. Franz. Booby trapping
In Proceedings of the 2013 Workshop on New Security
software.
Paradigms, NSPW ’13, pages 95–106, 2013.
[21] L. V. Davi, A. Dmitrienko, S. N¨urnberger, and A.-R. Sadeghi. Gadge me
if you can: secure and efﬁcient ad-hoc instruction-level randomization
for x86 and ARM.
In Proceedings of the 8th ACM Symposium on
Information, Computer and Communications Security, ASIACCS ’13,
pages 299–310, 2013.
[22] B. De Sutter, B. Anckaert, J. Geiregat, D. Chanet, and K. Bosschere.
Instruction set limitation in support of software diversity. In P. Lee
and J. Cheon, editors, Information Security and Cryptology ICISC ’08,
volume 5461 of Lecture Notes in Computer Science, pages 152–165.
Springer Berlin Heidelberg, 2009.
[23] R. El-Khalil and A. D. Keromytis. Hydan: Hiding information in
program binaries. In Proceedings of the 6th International Conference on
Information and Communications Security, ICICS ’04, pages 187–199,
2004.
[24] S. Forrest, A. Somayaji, and D. Ackley. Building diverse computer
systems. In Proceedings of the Workshop on Hot Topics in Operating
Systems, HotOS ’97, pages 67–72, 1997.
[25] M. Franz. E unibus pluram: Massive-scale software diversity as a defense
mechanism. In Proceedings of the 2010 Workshop on New Security
Paradigms, NSPW ’10, pages 7–16, 2010.
[26] D. Geer, C. P. Pﬂeeger, B. Schneier, J. S. Quarterman, P. Metzger,
R. Bace, and P. Gutmann. CyberInsecurity: The cost of monopoly –
how the dominance of Microsoft’s products poses a risk to security.
Computer and Communications Industry Association, 2003.
[27] C. Giuffrida, A. Kuijsten, and A. S. Tanenbaum. Enhanced operating
system security through efﬁcient and ﬁne-grained address space ran-
domization. In Proceedings of the 21st USENIX Security Symposium,
SEC ’12, pages 475–490, 2012.
[28] A. Gupta, S. Kerr, M. Kirkpatrick, and E. Bertino. Marlin: A ﬁne grained
randomization approach to defend against ROP attacks. In J. Lopez,
X. Huang, and R. Sandhu, editors, Network and System Security, volume
7873 of Lecture Notes in Computer Science, pages 293–306. Springer
Berlin Heidelberg, 2013.
J. Hiser, A. Nguyen-Tuong, M. Co, M. Hall, and J. W. Davidson. ILR:
Where’d my gadgets go? In Proceedings of the 33rd IEEE Symposium
on Security and Privacy, S&P ’12, pages 571–585, 2012.
[29]
[30] A. Homescu, S. Brunthaler, P. Larsen, and M. Franz. librando: Trans-
parent code randomization for just-in-time compilers. In Proceedings of
the 20th ACM Conference on Computer and Communications Security,
CCS’13, pages 993–1004, 2013.
[31] A. Homescu, S. Neisius, P. Larsen, S. Brunthaler, and M. Franz.
Proﬁle-guided automatic software diversity.
In Proceedings of the
11th IEEE/ACM International Symposium on Code Generation and
Optimization, CGO ’13, pages 1–11, 2013.
[32] A. Homescu, M. Stewart, P. Larsen, S. Brunthaler, and M. Franz.
Microgadgets: Size does matter in Turing-complete return-oriented
programming. In Proceedings of the 6th USENIX Workshop on Offensive
Technologies, WOOT ’12, pages 64–76, 2012.
[33] R. N. Horspool and N. Marovac. An approach to the problem of
detranslation of computer programs. Comput. J., 23(3):223–229, 1980.
[34] T. Jackson, A. Homescu, S. Crane, P. Larsen, S. Brunthaler, and M. Franz.
Diversifying the software stack using randomized NOP insertion. In
S. Jajodia, A. K. Ghosh, V. Subrahmanian, V. Swarup, C. Wang, and
X. S. Wang, editors, Moving Target Defense II, volume 100 of Advances
in Information Security, pages 151–173. Springer New York, 2013.
[35] T. Jackson, B. Salamat, A. Homescu, K. Manivannan, G. Wagner, A. Gal,
S. Brunthaler, C. Wimmer, and M. Franz. Compiler-generated software
diversity. In S. Jajodia, A. K. Ghosh, V. Swarup, C. Wang, and X. S.
Wang, editors, Moving Target Defense, volume 54 of Advances in
Information Security, pages 77–98. Springer New York, 2011.
[36] M. Jacob, M. Jakubowski, P. Naldurg, C. Saw, and R. Venkatesan. The
superdiversiﬁer: Peephole individualization for software protection. In
K. Matsuura and E. Fujisaki, editors, Advances in Information and
Computer Security, volume 5312 of Lecture Notes in Computer Science,
pages 100–120. Springer Berlin / Heidelberg, 2008.
[37] G. S. Kc, A. D. Keromytis, and V. Prevelakis. Countering code-injection
attacks with instruction-set randomization. In Proceedings of the 10th
ACM Conference on Computer and Communications Security, CCS ’03,
pages 272–280, 2003.
[38] C. Kil, J. Jun, C. Bookholt, J. Xu, and P. Ning. Address space
layout permutation (ASLP): Towards ﬁne-grained randomization of
commodity software. In Proceedings of the 22nd Annual Computer
Security Applications Conference, ACSAC ’06, pages 339–348, 2006.
[39] S. Krahmer. x86-64 buffer overﬂow exploits and the borrowed code
chunks exploitation techniques, 2005. http://www.suse.de/∼krahmer/
no-nx.pdf.
[40] P. Larsen, S. Brunthaler, and M. Franz. Security through diversity: Are
we there yet? IEEE Security & Privacy, 12(2):28–35, 2014.
[41] C. Linn and S. K. Debray. Obfuscation of executable code to improve
resistance to static disassembly.
In Proceedings of the 10th ACM
Conference on Computer and Communications Security, CCS ’03, pages
290–299, 2003.
[42] C.-K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. Lowney,
S. Wallace, V. J. Reddi, and K. Hazelwood. Pin: Building customized
program analysis tools with dynamic instrumentation. In Proceedings
of the 2005 ACM SIGPLAN Conference on Programming Language
Design and Implementation, PLDI ’05, pages 190–200, 2005.
[43] S. McCamant and G. Morrisett. Evaluating SFI for a CISC architecture.
In Proceedings of the 15th USENIX Security Symposium, SEC ’06, pages
209–224, 2006.
[44] Nergal. The advanced return-into-lib(c) exploits: PaX case study.
Phrack Magazine, 11(58), 2001. http://www.phrack.org/issues.html?
issue=58&id=4.
[45] N. Nethercote and J. Seward. Valgrind: A framework for heavyweight
dynamic binary instrumentation.
In Proceedings of the 2007 ACM
SIGPLAN Conference on Programming Language Design and Imple-
mentation, PLDI ’07, pages 89–100, 2007.
[46] G. Novark and E. D. Berger. Dieharder: securing the heap. In Proceed-
ings of the 17th ACM conference on Computer and communications
security, CCS ’10, pages 573–584, 2010.
[47] V. Pappas, M. Polychronakis, and A. D. Keromytis. Smashing the
gadgets: Hindering return-oriented programming using in-place code
randomization. In Proceedings of the 33rd IEEE Symposium on Security
and Privacy, S&P ’12, pages 601–615, 2012.
[48] PaX. Homepage of The PaX Team, 2001. http://pax.grsecurity.net.
[49] M. Payer. Too much PIE is bad for performance. Technical report, ETH
Z¨urich, 2012.
[50] K. Pettis and R. C. Hansen. Proﬁle guided code positioning.
In
Proceedings of the ACM SIGPLAN 1990 Conference on Programming
Language Design and Implementation, PLDI ’90, pages 16–27, New
York, NY, USA, 1990. ACM.
[51] R. Pucella and F. B. Schneider.
Independence from obfuscation:
A semantic framework for diversity. Journal of Computer Security,
18(5):701–749, 2010.
[52] B. Randell. System structure for software fault tolerance. SIGPLAN
[53]
Not., 10(6):437–449, 1975.
J. Salwan. ROPgadget
ROPgadget/.
tool, 2012.
http://shell-storm.org/project/
[54] E. J. Schwartz, T. Avgerinos, and D. Brumley. Q: Exploit hardening
made easy. In Proceedings of the 20th USENIX Security Symposium,
SEC ‘11, 2011.
[55] K. Scott, N. Kumar, S. Velusamy, B. Childers, J. Davidson, and
M. Soffa. Retargetable and reconﬁgurable software dynamic translation.
In Proceedings of the 1st IEEE/ACM International Symposium on Code
Generation and Optimization, CGO ’03, pages 36–47, 2003.
[56] F. J. Serna. The info leak era on software exploitation. In Black Hat
USA, 2012.
[57] H. Shacham. The geometry of innocent ﬂesh on the bone: Return-into-
libc without function calls (on the x86). In Proceedings of the 14th
ACM Conference on Computer and Communications Security, CCS ’07,
pages 552–561, 2007.
[58] H. Shacham, M. Page, B. Pfaff, E. Goh, N. Modadugu, and D. Boneh.
On the effectiveness of address-space randomization. In Proceedings of
the 11th ACM Conference on Computer and Communications Security,
CCS ’04, pages 298–307, 2004.
290
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:59:27 UTC from IEEE Xplore.  Restrictions apply. 
[59] E. Shioji, Y. Kawakoya, M. Iwamura, and T. Hariu. Code shredding:
byte-granular randomization of program layout for detecting code-
reuse attacks. In Proceedings of the 28th Annual Computer Security
Applications Conference, ACSAC ’12, pages 309–318, 2012.
[60] K. Z. Snow, F. Monrose, L. V. Davi, A. Dmitrienko, C. Liebchen, and
A.-R. Sadeghi. Just-in-time code reuse: On the effectiveness of ﬁne-
grained address space layout randomization. In Proceedings of the 34th
IEEE Symposium on Security and Privacy, S&P ’13, pages 574–588,
2013.
[61] L. Szekeres, M. Payer, T. Wei, and D. Song. SoK: eternal war in memory.
In Proceedings of the 34th IEEE Symposium on Security and Privacy,
S&P ’13, pages 48–62, 2013.
[62] L. Torczon and K. Cooper. Engineering A Compiler. Morgan Kaufmann
Publishers Inc., San Francisco, CA, USA, 2nd edition, 2011.
[63] M. Tran, M. Etheridge, T. Bletsch, X. Jiang, V. W. Freeh, and P. Ning.
On the expressiveness of return-into-libc attacks. In Proceedings of the
14th Interntional Symposium on Recent Advances in Intrusion Detection,
RAID ’11, pages 121–141, 2011.
[64] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin. Binary stirring:
self-randomizing instruction addresses of legacy x86 binary code. In
Proceedings of the 19th ACM Conference on Computer and Communi-
cations Security, CCS ’12, pages 157–168, 2012.
[65] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin. Securing untrusted
code via compiler-agnostic binary rewriting. In Proceedings of the 28nd
Annual Computer Security Applications Conference, ACSAC ’12, pages
299–308, 2012.
[66] T. Wei, T. Wang, L. Duan, and J. Luo. INSeRT: Protect dynamic code
generation against spraying. In Proceedings of the 2011 International
Conference on Information Science and Technology, ICIST ’11, pages
323–328, 2011.
[67] D. W. Williams, W. Hu, J. W. Davidson, J. Hiser, J. C. Knight, and
A. Nguyen-Tuong. Security through diversity: Leveraging virtual
machine technology. IEEE Security & Privacy, 7(1):26–33, 2009.
[68] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth, T. Ormandy,
S. Okasaka, N. Narula, and N. Fullagar. Native client: A sandbox
for portable, untrusted x86 native code. In Proceedings of the 30th IEEE
Symposium on Security and Privacy, S&P ’09, pages 79–93, 2009.
[69] M. Zhang and R. Sekar. Control ﬂow integrity for COTS binaries. In
Proceedings of the 22nd USENIX Security Symposium, SEC ’13, pages
337–352, 2013.
291
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:59:27 UTC from IEEE Xplore.  Restrictions apply.