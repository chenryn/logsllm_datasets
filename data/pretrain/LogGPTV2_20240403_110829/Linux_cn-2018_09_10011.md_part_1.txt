---
author: Amit Saha
category: 软件开发
comments_data: []
count:
  commentnum: 0
  favtimes: 3
  likes: 0
  sharetimes: 0
  viewnum: 6383
date: '2018-09-14 09:51:06'
editorchoice: false
excerpt: 通过学习这些关键的术语和概念来理解 Python 应用监测。
fromurl: https://opensource.com/article/18/4/metrics-monitoring-and-python
id: 10011
islctt: true
largepic: /data/attachment/album/201809/14/095110zhc8emsexexmuon8.png
permalink: /article-10011-1.html
pic: /data/attachment/album/201809/14/095110zhc8emsexexmuon8.png.thumb.jpg
related: []
reviewer: wxy
selector: lujun9972
summary: 通过学习这些关键的术语和概念来理解 Python 应用监测。
tags:
- 监测
- Python
- 指标
thumb: false
title: 理解监测指标，并使用 Python 去监测它们
titlepic: true
translator: qhwdw
updated: '2018-09-14 09:51:06'
---
> 
> 通过学习这些关键的术语和概念来理解 Python 应用监测。
> 
> 
> 
![Understanding metrics and monitoring with Python](/data/attachment/album/201809/14/095110zhc8emsexexmuon8.png "Understanding metrics and monitoring with Python")
当我第一次看到术语“ 计数器   counter ”和“ 计量器   gauge ”和使用颜色及标记着“平均数”和“大于 90%”的数字图表时，我的反应之一是逃避。就像我看到它们一样，我并不感兴趣，因为我不理解它们是干什么的或如何去使用。因为我的工作不需要我去注意它们，它们被我完全无视。
这都是在两年以前的事了。随着我的职业发展，我希望去了解更多关于我们的网络应用程序的知识，而那个时候就是我开始去学习 监测指标   metrics 的时候。
我的理解监测的学习之旅共有三个阶段（到目前为止），它们是：
* 阶段 1：什么？（王顾左右）
* 阶段 2：没有指标，我们真的是瞎撞。
* 阶段 3：出现不合理的指标我们该如何做？
我现在处于阶段 2，我将分享到目前为止我学到了些什么。我正在向阶段 3 进发，在本文结束的位置我提供了一些我正在使用的学习资源。
我们开始吧！
### 需要的软件
在文章中讨论时用到的 demo 都可以在 [我的 GitHub 仓库](https://github.com/amitsaha/python-monitoring-talk) 中找到。你需要安装 docker 和 docker-compose 才能使用它们。
### 为什么要监测？
关于监测的主要原因是：
* 理解 正常的 和 不正常的 系统和服务的特征
* 做容量规划、弹性伸缩
* 有助于排错
* 了解软件/硬件改变的效果
* 测量响应中的系统行为变化
* 当系统出现意外行为时发出警报
### 指标和指标类型
从我们的用途来看，一个**指标**就是在一个给定*时间*点上的某些数量的 测量 值。博客文章的总点击次数、参与讨论的总人数、在缓存系统中数据没有被找到的次数、你的网站上的已登录用户数 —— 这些都是指标的例子。
它们总体上可以分为三类：
#### 计数器
以你的个人博客为例。你发布一篇文章后，过一段时间后，你希望去了解有多少点击量，这是一个只会增加的数字。这就是一个 计数器   counter 指标。在你的博客文章的生命周期中，它的值从 0 开始增加。用图表来表示，一个计数器看起来应该像下面的这样：
![Counter metric](/data/attachment/album/201809/14/095111xnvttvuzoilv6n0z.png "Counter metric")
*一个计数器指标总是在增加的。*
#### 计量器
如果你想去跟踪你的博客每天或每周的点击量，而不是基于时间的总点击量。这种指标被称为一个 计量器   gauge ，它的值可上可下。用图表来表示，一个计量器看起来应该像下面的样子：
![gauge metric](/data/attachment/album/201809/14/095111n1nknrr8zncnkkcq.png "gauge metric")
*一个计量器指标可以增加或减少。*
一个计量器的值在某些时间窗口内通常有一个 最大值   ceiling 和 柱状图   histogram （在 Prometheus 中这么叫它）或 计时器   timer （在 StatsD 中这么叫它）是一个跟踪 已采样的观测结果 的指标。不像一个计数器类或计量器类指标，柱状图指标的值并不是显示为上或下的样式。我知道这可能并没有太多的意义，并且可能和一个计量器图看上去没有什么不同。它们的不同之处在于，你期望使用柱状图数据来做什么，而不是与一个计量器图做比较。因此，监测系统需要知道那个指标是一个柱状图类型，它允许你去做哪些事情。
![Histogram metric](/data/attachment/album/201809/14/095112c46b9l913up3ahz6.png "Histogram metric")
*一个柱状图指标可以增加或减少。*
### Demo 1：计算和报告指标
[Demo 1](https://github.com/amitsaha/python-monitoring-talk/tree/master/demo1) 是使用 [Flask](http://flask.pocoo.org/) 框架写的一个基本的 web 应用程序。它演示了我们如何去 计算 和 报告 指标。
在 `src` 目录中有 `app.py` 和 `src/helpers/middleware.py` 应用程序，包含以下内容：
```
from flask import request
import csv
import time
def start_timer():
    request.start_time = time.time()
def stop_timer(response):
    # convert this into milliseconds for statsd
    resp_time = (time.time() - request.start_time)*1000
    with open('metrics.csv', 'a', newline='') as f:
        csvwriter = csv.writer(f)
        csvwriter.writerow([str(int(time.time())), str(resp_time)])
    return response
def setup_metrics(app):
    app.before_request(start_timer)
    app.after_request(stop_timer)
```
当在应用程序中调用 `setup_metrics()` 时，它配置在一个请求被处理之前调用 `start_timer()` 函数，然后在该请求处理之后、响应发送之前调用 `stop_timer()` 函数。在上面的函数中，我们写了时间戳并用它来计算处理请求所花费的时间。
当我们在 `demo1` 目录中运行 `docker-compose up`，它会启动这个 web 应用程序，然后在一个客户端容器中可以生成一些对 web 应用程序的请求。你将会看到创建了一个 `src/metrics.csv` 文件，它有两个字段：`timestamp` 和 `request_latency`。
通过查看这个文件，我们可以推断出两件事情：
* 生成了很多数据
* 没有观测到任何与指标相关的特征
没有观测到与指标相关的特征，我们就不能说这个指标与哪个 HTTP 端点有关联，或这个指标是由哪个应用程序的节点所生成的。因此，我们需要使用合适的元数据去限定每个观测指标。
### 《Statistics 101》
（LCTT 译注：这是一本统计学入门教材的名字）
假如我们回到高中数学，我们应该回忆起一些统计术语，虽然不太确定，但应该包括平均数、中位数、百分位和柱状图。我们来简要地回顾一下它们，不用去管它们的用法，就像是在上高中一样。
#### 平均数
 平均数   mean ，即一系列数字的平均值，是将数字汇总然后除以列表的个数。3、2 和 10 的平均数是 (3+2+10)/3 = 5。
#### 中位数
 中位数   median 是另一种类型的平均，但它的计算方式不同；它是列表从小到大排序（反之亦然）后取列表的中间数字。以我们上面的列表中（2、3、10），中位数是 3。计算并不是非常直观，它取决于列表中数字的个数。
#### 百分位
 百分位   percentile 是指那个百（千）分比数字低于我们给定的百分数的程度。在一些场景中，它是指这个测量值低于我们数据的百（千）分比数字的程度。比如，上面列表中 95% 是 9.29999。百分位的测量范围是 0 到 100（不包括）。0% 是一组数字的最小分数。你可能会想到它的中位数是 50%，它的结果是 3。
一些监测系统将百分位称为 `upper_X`，其中 X 就是百分位；`upper 90` 指的是在 90% 的位置的值。
#### 分位数
“q-分位数”是将有 N 个数的集合等分为 `qN` 级。`q` 的取值范围为 0 到 1（全部都包括）。当 `q` 取值为 0.5 时，值就是中位数。（ 分位数   quantile ）和百分位数的关系是，分位数值 `q` 等于 `100` 百分位值。
#### 柱状图
 累积柱状图   cumulative histogram 也是一个柱状图，它的每个桶的数包含前一个桶的数，因此命名为累积。将上面的数据集做成累积柱状图后，看起来应该是这样的：
![Cumulative histogram](/data/attachment/album/201809/14/095113yqx6xph8xt6xxonp.png "Cumulative histogram")
#### 我们为什么需要做统计？
在上面的 Demo 1 中，我们注意到在我们报告指标时，这里生成了许多数据。当我们将它们用于指标时我们需要做统计，因为它们实在是太多了。我们需要的是整体行为，我们没法去处理单个值。我们预期展现出来的值的行为应该是代表我们观察的系统的行为。
### Demo 2：在指标上增加特征
在我们上面的的 Demo 1 应用程序中，当我们计算和报告一个请求的延迟时，它指向了一个由一些特征 唯一标识的特定请求。下面是其中一些：
* HTTP 端点
* HTTP 方法
* 运行它的主机/节点的标识符
如果我们将这些特征附加到要观察的指标上，每个指标将有更多的内容。我们来解释一下 [Demo 2](https://github.com/amitsaha/python-monitoring-talk/tree/master/demo2) 中添加到我们的指标上的特征。
在写入指标时，`src/helpers/middleware.py` 文件将在 CSV 文件中写入多个列：
```
node_ids = ['10.0.1.1', '10.1.3.4']
def start_timer():
    request.start_time = time.time()
def stop_timer(response):
    # convert this into milliseconds for statsd
    resp_time = (time.time() - request.start_time)*1000
    node_id = node_ids[random.choice(range(len(node_ids)))]
    with open('metrics.csv', 'a', newline='') as f:
        csvwriter = csv.writer(f)
        csvwriter.writerow([
            str(int(time.time())), 'webapp1', node_id,
            request.endpoint, request.method, str(response.status_code),
            str(resp_time)
        ])
    return response
```
因为这只是一个演示，在报告指标时，我们将随意的报告一些随机 IP 作为节点的 ID。当我们在 `demo2` 目录下运行 `docker-compose up` 时，我们的结果将是一个有多个列的 CSV 文件。
#### 用 pandas 分析指标
我们将使用 [pandas](https://pandas.pydata.org/) 去分析这个 CSV 文件。运行 `docker-compose up` 将打印出一个 URL，我们将使用它来打开一个 [Jupyter](http://jupyter.org/) 会话。一旦我们上传 `Analysis.ipynb notebook` 到会话中，我们就可以将 CSV 文件读入到一个 pandas  数据帧   DataFrame 中：
```
import pandas as pd
metrics = pd.read_csv('/data/metrics.csv', index_col=0)
```
`index_col` 表明我们要指定时间戳作为索引。
因为每个特征我们都要在数据帧中添加一个列，因此我们可以基于这些列进行分组和聚合：