title:Sketchlearn: relieving user burdens in approximate measurement with
automated statistical inference
author:Qun Huang and
Patrick P. C. Lee and
Yungang Bao
SketchLearn: Relieving User Burdens in Approximate
Measurement with Automated Statistical Inference
Qun Huang†, Patrick P. C. Lee‡, and Yungang Bao†
†State Key Lab of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences
‡Department of Computer Science and Engineering, The Chinese University of Hong Kong
ABSTRACT
Network measurement is challenged to fulfill stringent re-
source requirements in the face of massive network traffic.
While approximate measurement can trade accuracy for re-
source savings, it demands intensive manual efforts to config-
ure the right resource-accuracy trade-offs in real deployment.
Such user burdens are caused by how existing approximate
measurement approaches inherently deal with resource con-
flicts when tracking massive network traffic with limited
resources. In particular, they tightly couple resource config-
urations with accuracy parameters, so as to provision suffi-
cient resources to bound the measurement errors. We design
SketchLearn, a novel sketch-based measurement framework
that resolves resource conflicts by learning their statistical
properties to eliminate conflicting traffic components. We
prototype SketchLearn on OpenVSwitch and P4, and our
testbed experiments and stress-test simulation show that
SketchLearn accurately and automatically monitors various
traffic statistics and effectively supports network-wide mea-
surement with limited resources.
CCS CONCEPTS
• Networks → Network measurement;
KEYWORDS
Sketch; Network measurement
ACM Reference Format:
Qun Huang, Patrick P. C. Lee, and Yungang Bao. 2018. SketchLearn:
Relieving User Burdens in Approximate Measurement with Au-
tomated Statistical Inference. In SIGCOMM ’18: ACM SIGCOMM
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear
this notice and the full citation on the first page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior specific permission and/or a fee. Request
permissions from permissions@acm.org.
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5567-4/18/08...$15.00
https://doi.org/10.1145/3230543.3230559
2018 Conference, August 20–25, 2018, Budapest, Hungary. ACM, New
York, NY, USA, 15 pages. https://doi.org/10.1145/3230543.3230559
1 INTRODUCTION
Network measurement is indispensable to modern network
management in clouds and data centers. Administrators mea-
sure a variety of traffic statistics, such as per-flow frequency,
to infer the key behaviors or any unexpected patterns in op-
erational networks. They use the measured traffic statistics
to form the basis of management operations such as traffic
engineering, performance diagnosis, and intrusion preven-
tion. Unfortunately, measuring traffic statistics is non-trivial
in the face of massive network traffic and large-scale net-
work deployment. Error-free measurement requires per-flow
tracking [15], yet today’s data center networks can have
thousands of concurrent flows in a very small period from
50ms [2] down to even 5ms [56]. This would require tremen-
dous resources for performing per-flow tracking.
In view of the resource constraints, many approaches in
the literature leverage approximation techniques to trade be-
tween resource usage and measurement accuracy. Examples
include sampling [9, 37, 64], top-k counting [5, 43, 44, 46],
and sketch-based approaches [18, 33, 40, 42, 58], which we
collectively refer to as approximate measurement approaches.
Their idea is to construct compact sub-linear data structures
to record traffic statistics, backed by theoretical guarantees
on how to achieve accurate measurement with limited re-
sources. Approximate measurement has formed building
blocks in many state-of-the-art network-wide measurement
systems (e.g., [32, 48, 55, 60, 62, 67]), and is also adopted in
production data centers [31, 68].
Although theoretically sound, existing approximate mea-
surement approaches are inconvenient for use. In such ap-
proaches, massive network traffic competes for the limited
resources, thereby introducing measurement errors due to
resource conflicts (e.g., multiple flows are mapped to the same
counter in sketch-based measurement). To mitigate errors,
sufficient resources must be provisioned in approximate mea-
surement based on its theoretical guarantees. Thus, there
exists a tight binding between resource configurations and
accuracy parameters. Such tight binding leads to several prac-
tical limitations (see §2.2 for details): (i) administrators need
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
Huang et al.
to specify tolerable error levels as input for resource configu-
rations; (ii) each configuration is tied to specific parameters
(e.g., thresholds); (iii) the theoretical analysis only provides
worst-case analysis and fails to guide the resource configu-
rations based on actual workloads; (iv) each configuration
is fixed for specific flow definitions; and (v) administrators
cannot readily quantify the extent of errors for measurement
results. How to bridge the gap between theoretical guaran-
tees and practical deployment in approximate measurement
remains a challenging yet critical issue [13].
We address this issue by focusing on sketch-based mea-
surement, which fully records the chosen statistics of all ob-
served packets in fixed-size data structures (i.e., sketches). We
propose SketchLearn, a sketch-based measurement frame-
work that addresses the above limitations in approximate
measurement through a fundamentally novel methodology.
Its idea is to characterize the inherent statistical properties
of resource conflicts in sketches rather than pursue a per-
fect resource configuration to mitigate resource conflicts.
Specifically, SketchLearn builds on a multi-level sketch [17]
to track the frequencies of flow records at bit-level granu-
larities. The multi-level structure leads to multiple bit-level
Gaussian distributions for the sketch counters, which we jus-
tify with rigorous theoretical analysis (see §4). SketchLearn
leverages the Gaussian distributions to address the limita-
tions of state-of-the-arts. It iteratively infers and extracts
large flows from the multi-level sketch, until the residual
multi-level sketch (with only small flows remaining) fits some
Gaussian distribution. By separating large and small flows,
SketchLearn eliminates their resource conflicts and improves
measurement accuracy. Such iterative inference can be done
without relying on complicated model parameters, thereby
relieving administrators to a large extent from configuration
burdens. SketchLearn further allows arbitrary flow defini-
tions, provides error estimates for measurement results, and
supports large-scale network-wide measurement (see §5). To
our knowledge, SketchLearn is the first approximate mea-
surement approach that builds on the characterization of the
inherent statistical properties of sketches.
We prototype SketchLearn atop OpenVSwitch [52] and
P4 [53] (see §6) to show its feasibility of being deployable
in both software and hardware switches, respectively. Our
testbed experiments and stress-test simulation show that
with only 64KB of memory and 92 CPU cycles of per-packet
processing, SketchLearn achieves near-optimal accuracy for
a variety of traffic statistics and addresses the limitations of
state-of-the-arts (see §7).
2 MOTIVATION
We start with measuring per-flow frequencies of network traf-
fic across time intervals called epochs. Each flow is identified
by a flowkey, which can be defined based on any combina-
tion of packet fields, such as 5-tuples or source-destination
address pairs. We obtain the per-flow frequencies, in terms of
packet or byte counts, for all or a subset of flows of interest
in each epoch. Based on per-flow frequencies, we can derive
sophisticated traffic statistics (see §5.1), such as heavy hitters
[43], heavy changers [17], superspreaders and DDoS [19],
cardinality [66], flow size distribution [38], and entropy [30].
2.1 Design Requirements
We first pose the design requirements for practical network
measurement deployment.
Requirement 1 (R1): Small memory usage. Network
measurement should limit memory usage in both hard-
ware and software deployments. For hardware devices (e.g.,
switching ASICs and NetFPGA), high memory usage aggra-
vates chip footprints and heat consumptions, thereby increas-
ing manufacturing costs. Even though modern switching
ASICs have larger SRAM (e.g., 50-100MB) [45], the available
SRAM size remains limited for per-flow tracking. Software
switches in servers [54] can leverage abundant server-side
DRAM. However, high memory usage not only depletes the
memory of co-located applications (e.g., VMs or contain-
ers), but also degrades their performance due to more severe
cache contentions [27].
Requirement 2 (R2): Fast per-packet processing. Net-
work measurement must process numerous packets at high
speed. For example, a fully utilized 10Gbps link corresponds
to a packet rate of 14.88Mpps for 64-byte packets; equiva-
lently, the time budget for each packet is only around 200
CPU cycles in a 3GHz processor. As the packet buffer size is
limited, any packet that significantly exceeds the time budget
can cause subsequent packets to be dropped.
Requirement 3 (R3): Real-time response. Some measure-
ment tasks, such as anomaly detection, necessitate real-
time statistics to respond quickly to potentially catastrophic
events. Lightweight measurement solutions are more pre-
ferred to avoid unexpected delays [20, 57].
Requirement 4 (R4): Generality. Designing and deploy-
ing specific solutions for each type of traffic statistics is in-
effective and also requires sophisticated resource allocation
across different solutions to provide accuracy guarantees
[47, 48]. Instead, a practical measurement solution should be
applicable to general types of traffic statistics [40, 41].
Also, resource requirements vary between hardware and
software. For example, ASIC switches have high throughput
but limited memory (see R1); in contrast, commodity hosts
generally have sufficient memory but limited CPU process-
ing power (see R2). Enabling unified measurement for both
software and hardware platforms is critical.
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
(a) Precision
(b) Recall
Figure 1: (L2) Accuracy with smaller thresholds.
2.2 Limitations of Existing Approaches
Approximate measurement makes design trade-offs between
resource usage and measurement accuracy (see §1). However,
existing approximate measurement approaches (including
sampling, top-k counting, and sketch-based approaches) still
fail to address the following limitations.
Limitation 1 (L1): Hard to specify expected errors. Ex-
isting approximate measurement approaches mostly provide
theoretical guarantees that the estimated result has a relative
error ϵ with a confidence probability 1 − δ, where ϵ and δ
are configurable parameters between 0 and 1. How to pa-
rameterize the “best” ϵ and δ requires domain knowledge
for different scenarios.
Limitation 2 (L2): Hard to query different thresholds.
Some measurement tasks are threshold-based. For example,
heavy hitter detection [43] finds all flows whose frequen-
cies exceed some threshold. However, existing heavy hitter
detection approaches take the threshold as input for con-
figurations, thereby making both the theoretical analysis
and actual measurement accuracy heavily tied to the thresh-
old choice. Figure 1 shows the precision and recall for six
representative heavy hitter detection approaches (see their
details in §7). We first configure the threshold as 1% of total
frequency. Then all approaches can achieve 100% in both pre-
cision and recall (not shown in the figure). If we decrease the
threshold to 0.5% and 0.1% of total traffic without changing
the configuration, then the figure shows that the precision
and recall sharply drop to less than 80% and 20%, respectively.
Limitation 3 (L3): Hard to apply theories to tune con-
figurations. Even though we can precisely specify the errors
and query thresholds, it remains challenging to apply the
theoretical results for two reasons. First, some measurement
approaches (e.g., [7, 40, 58]) only provide asymptotic com-
plexity results but not closed-form parameters for configura-
tions. Second, most approximate measurement approaches
perform worst-case analysis and do not take into account
actual workloads. Some studies (e.g., [23, 44]) address heavy-
tailed traffic distribution, but they need the exact distribution
models as input and cannot readily adapt to actual network
conditions. SCREAM [48] dynamically tunes configurations
based on prior runtime behaviors, but it requires complicated
coordination of a centralized controller to collect sketch sta-
tistics and fine-tune sketch configurations.
(a) Memory
(b) Peak per-packet CPU cycles
Figure 2: (L3) Resource usage of theory-based and
empirically-tuned configurations.
To justify this limitation, we consider heavy hitter detec-
tion with threshold 1%, relative error 1%, and error probabil-
ity 5%. We employ two configurations: one exactly follows
theoretical results, while the other is empirically tuned to
achieve the configured errors. Figure 2 compares their mem-
ory consumption and peak per-packet processing overhead
(in CPU cycles), measured by testbed experiments (see §7). It