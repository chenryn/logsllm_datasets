P (Etop) =
P (Etop|Eblock) × P (Eblock)
(cid:88)
(cid:88)
blocks
cells
P (Eblock) =
P (Eblock|Ecell) × P (Ecell)
Acell
Ablock
Ablock
Atop
(1)
(2)
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:43:27 UTC from IEEE Xplore.  Restrictions apply. 
328P (Etop) in Equation 1 corresponds to the total system-
level vulnerability. The term P (Etop|Eblock) stands for
the system-level vulnerability arising from errors at
the
output of a particular block in the system. Estimation of
this term using fault injection experiments at the system
level is demonstrated in Section VI. To aggregate top-level
vulnerabilities (arising from errors in different blocks) into
a single system-vulnerability metric, each term needs to be
derated using two factors. First, the vulnerability of the block
itself (P (Eblock)), as not all errors originating within the
block manifest at its output, and second, an area derating
), which gives the probability of the speciﬁc
factor ( Ablock
Atop
block being the target of a particle strike, given that the
top-level is struck.
Block vulnerability is similarly deﬁned in Equation 2
in terms of its constituent components – standard cells or
gates. P (Eblock|Ecell) corresponds to the block vulnerability
arising from errors at the output of a speciﬁc gate in the
block. Results of fault injection experiments using FIsim
shown in Figure 2 corresponds precisely to this term. Each
point in the ﬁgures corresponds to the block-vulnerability
when errors were injected at a speciﬁc cell-output (net).
An aggregation rule similar to that of Equation 1 can be
used in Equation 2. Block vulnerability estimates (arising
from errors in different cells) need to be derated when
they are aggregated to estimate total block vulnerability.
This derating is captured by the terms P (Ecell), the cell-
vulnerability and Acell
Ablock
The main advantage of such an approach is that when
additional information about lower-level implementation is
not available, it can conservatively be assumed vulnerable
100% of the time (P (Elower−level) = 1). For example, if
there isn’t sufﬁcient information to estimate the vulnerability
of a standard cell, P (Ecell) can be assigned 1 until it can
be further reﬁned using implementation details.
.
At the system level the area derating factor can play a
more signiﬁcant role (Equation 1). That is, when estimating
the impact that a particular microarchitecture structure has
on the vulnerability of a whole device such as a processor,
its area relative to the total area can give rise to signiﬁcant
derating. For example, the area of an adder relative to the
total area of a microprocessor can be quite insigniﬁcant,
1
Similarly,
the area derating factor in Equation 2 can
conservatively be assumed to be
#cells until speciﬁc layout
details are available. For example, each graph in Figure 2
shows vulnerability of the total combinational block as a
numerical average of vulnerabilities of all nets in the block.
This estimate makes the following assumptions. First, all
#cells.
nets are equally vulnerable to a fault, i.e. Acell
Ablock
Further, any fault occurring in a cell propagates an error to its
output, i.e. P (Ecell) = 1. These assumptions are obviously
incomplete representations of the actual scenario, but when
more detailed information becomes available, the model can
further be reﬁned.
= 1
given that a very large on-chip area is taken up by cache
and other SRAM-based array structures. This makes the
adder circuit a relatively small
target within the whole
processor for a soft error from, for example a transient fault.
However, applications such as custom ASICs and embedded
processors employed in safety-related applications may not
include large cache structures in order to provide more
deterministic operation. In such cases, the contribution of
the otherwise small microarchitecture structures that imple-
ment combinational blocks towards the computation of total
vulnerability becomes signiﬁcant.
A. Results from FIsim
The results obtained from the fault injection simulator
generated by the FIsim compiler contain a wealth of in-
formation about the way errors manifest at circuit outputs
in the presence of internal errors. For example, Figure 3(a)
shows a distribution of the different error multiplicities
observed from a fault campaign conducted on a 32-bit
Kogge-Stone adder. 1000 fault simulations were run on
each of the 482 internal nets. It shows that of the 482000
total fault simulations conducted, about 32% experiments
resulted in no response (0 bits in error) and ∼60% produced
error on exactly one bit. The remaining ∼8% comprise the
remaining fault multiplicities, i.e. 2-16. No fault injection in
the campaign produced errors in more than 16 bits. Figure
3(a) shows the same distribution on two scales – as a count
of the number of experiments on the logarithmic scale and
as a percentage on the linear scale.
by the expression(cid:80)(cid:0)32
(cid:1) and is approximately 4.3 billion.
If the fault-to-error propagation in an adder circuit were
truly random, errors originating within the adder could, in
the worst case, propagate to all output bits of the adder
(e.g. error in carry-in bit). Enumerating all such output error
combinations can quickly get intractable with the width of
the adder. For example, the possible number of random error
combinations at the output of a 32 bit adder can be evaluated
However, after 482000 fault simulations (482 nets × 1000
faults per net) on the 32-bit Kogge-Stone adder, just 501
unique patterns were observed. This comprises 0.000012%
of the possible combinations. This observation is important
when designing fault injection experiments at a higher level
in the design hierarchy. It simpliﬁes the deﬁnition of the
fault-to-error model and therefore how errors can credibly
be reproduced at a higher level simulation. The fault space
from which to choose a fault in a campaign is signiﬁcantly
smaller that a random selection of wrong bits.
i
When considering one bit upsets, which comprise 88% of
all experiments counted vulnerable, the position at which the
error appears can either be considered random and uniformly
distributed or according to a distribution such as the one
shown in Figure 3(b). It shows the frequency of error at each
output bit position for experiments that produced an error at
exactly one output bit. If the error at each bit position was
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:43:27 UTC from IEEE Xplore.  Restrictions apply. 
329(a) Distribution of number of wrong bits in a 32-bit Kogge-Stone adder
(b) Distribution of observed position of single bit errors
(c) Distribution of observed positions of two bit errors
(d) Distribution of observed positions of three bit errors
Figure 3. Various error distributions in a 32-bit Kogge-Stone adder. For Figures 3(b)–3(d), the x-axis shows bit position and y-axis shows frequency of
observation (%).
considered to be equally likely, the expected frequency of
error at each position would be 3.125% (1/32, dashed line
in Figure 3(b)).
All two bit errors appeared to be conﬁned to one of four
error combination patterns. Each error combination pattern is
distinguished by the difference between the positions of bits
in error, speciﬁcally being equal to 1, 2, 4 or 8 bits. A similar
pattern can be observed for three bit error combinations –
the difference in bit position between the ﬁrst and second
wrong bits was always the same as that between the second
and third wrong bits. Further, this difference was conﬁned to
one of three values – 1, 2 and 4 bit positions. Such regularity
of error patterns can be attributed to the fact that the topology
and fan-out of Kogge-Stone adders are very regular and well-
deﬁned. Error patterns for other circuits may be signiﬁcantly
different.
Distributions of each of these error patterns are shown
in Figures 3(c) and 3(d). The relative frequency of each
error pattern within each multiplicity is also indicated next
to each series. For example, in Figure 3(d), the patterns with
a difference of 1 between the bit position in error (wrong
bits are x, x+1, x+2) form 70% of all three bit error patterns.
Observations from such analyses are valuable in that they
provide error patterns that can be emulated to reproduce
errors at higher levels. For example, when reproducing two
bit error patterns at the high level, an experiment where the
error patterns (x, x+1) and (x, x+2) each appear with 50%
probability would be fairly representative of the observation
in Figure 3(c), as the occurrence of the patterns (x, x+4) and
(x, x+8) are relatively rare. Further, the largely ﬂat proﬁles of
each series in Figures 3(c) and 3(d) indicate that the position
of occurrence of two and three bit errors appear more or
less uniformly distributed when compared to the position
of one bit errors shown in Figure 3(b). This implies that a
random selection of x to introduce a two or three bit error
at the system level is valid. Again, these results can vary
signiﬁcantly from circuit to circuit.
VI. METHODOLOGY FOR SYSTEM-LEVEL
VULNERABILITY ESTIMATION
System-level vulnerability may be estimated in a number
of ways. Irrespective of the approach, the basic methodology
is to estimate the fraction of faults that will affect correctness
of the output. One approach for processors is to estimate the
fraction of instructions that is required for architecturally
correct execution (ACE) [9][10]. Another approach is to
use fault
injection, where an error arising from a fault
is reproduced within a workload and its effects on the
output are statistically quantiﬁed [11][12]. ACE method-
ologies are not suitable to study the effects of different
fault models on system vulnerability because correctness
of output is estimated by detailed analyses of the behavior
of instructions; i.e., how they manipulate data stored in the
resources that they use. Fault injection, on the other hand, is
more conducive to studying system effects of different fault
models because an estimate obtained from fault injection
will be more precise than ACE methodologies if the fault-to-
error model is well deﬁned [12]. Fault injection into a high-
ﬁdelity system simulation running workloads in the presence
of errors was therefore chosen as the approach to estimating
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:43:27 UTC from IEEE Xplore.  Restrictions apply. 
0!10!20!30!40!50!60!70!1!10!100!1000!10000!100000!1000000!0!2!4!6!8!10!12!14!16!% experiments!# experiments!Number of bits in error!# experiments!% experiments!3105101520254.500.511.522.533.543.125310510152025200.511.5(x, x+1) 48%(x, x+2) 40.5%(x, x+4) 11%(x, x+8) 0.5%310510152025300.511.522.5(x, x+1, x+2) 70%(x, x+2, x+4) 29%(x, x+4, x+8) 1%330to this would be to run the simulation of a workload to
completion after a fault has been injected and to determine
outcome by comparing output with a gold output (fault-free).
While this approach may be precise, it can be practical only
if the workloads are small enough to allow the execution
of long campaigns to satisfy the constraint
imposed by
statistical conﬁdence. For these reasons, the widely used
SPEC benchmark applications are not suitable workloads for
fault injection on microarchitectures. While prior work in the
literature does make use of SPEC benchmarks as workloads,
they are usually not run to completion as they typically
consist of billions of simulated cycles. Consequently, a small
snapshot of each benchmark is what is often simulated in
the presence of faults. This approach is not precise when
making decisions about the outcome of a workload in the
presence of a fault and can give rise to signiﬁcant error in
the estimated parameters.
For these reasons MiBench [14] was the workload of
choice. It is a free and commercially representative set of ap-
plications directed towards embedded applications. MiBench
applications are considerably smaller when used with the
small data set in comparison to SPEC benchmarks (tens of
millions vs. billions of simulated cycles). SPEC benchmarks
are typically used for performance measurements, where
having large applications is beneﬁcial. However, for the
experiments presented here, performance metrics are of little
signiﬁcance because it is the functional correctness of a
microarchitecture in the presence of faults that is sought.
It is more important to be able to quickly and precisely
determine the outcome of the output of a representative
workload in the presence of faults. The applications in the
MiBench suite served to fulﬁll both of these requirements,
but the appropriate workload must always be determined for
the system and application under consideration.
3) Experiment Control: Automating fault campaigns is
another key aspect of practical fault injection. PERL scripts
were used to automate the various steps in each fault injec-
tion experiment and over long fault campaigns. A fault-free
execution of each workload was carried out to determine the
execution time and the gold output to compare to after each
fault injection. Each fault injection experiment consisted
of setup and start of the simulator with the appropriate
parameters and workload. When the chosen instruction/cycle
was reached, the saboteur module injected an error and
resumed execution.
system-level vulnerability. In this paper, general purpose
processors (with a focus on embedded architectures, al-
though high performance architectures are not excluded) are
used as the system model, but ASICs, ﬁeld programmable
gate arrays (FPGAs), graphics processing units (GPUs),
application speciﬁc instruction processors (ASIPs), etc. can
all employ a generalized version of the methodology detailed
here.
A. Fault Injection Infrastructure
For the experiments designed to estimate system-level
vulnerability, fault injections were performed on a micro-
architecture simulator running benchmark applications as
the workload. Fault injection in simulation has a number of
advantages, including the observability and controllability
to track execution cycles and to inject faults into precise
locations at precise points in time. Another valuable feature
that simulation provides is the ability to switch execution
to native hardware in order to speed up long fault injection
campaigns and possibly run workloads to completion (the
importance of which is discussed below).
lack cache structures,
1) Choice of Simulator: PTLsim [13] is a cycle accurate
x86-64 architecture simulator that has all of the advantages
mentioned above to enable easy augmentation for fault
injection. The main advantage among which is its ability to
easily switch to native hardware execution when executed
on any x86-64 hardware. This capability is very valuable
to realize fast forwarding to speed up simulation times.
PTLsim, by default, is an x86-64 microarchitecture simulator