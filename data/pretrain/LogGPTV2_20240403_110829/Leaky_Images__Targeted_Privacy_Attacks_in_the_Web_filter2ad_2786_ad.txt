the repository my-awesome-project can access the image.
To control the number of users that have access to the image,
the attacker can remove or add contributors to the project.
e.g.,
Dropbox Every image uploaded on Dropbox can be ac-
cessed through a leaky image endpoint by appending the
HTTP parameter dl=1 to a shared image URL. Dropbox
allows the attacker to share such images with arbitrary email
addresses and to ﬁne-tune the permissions to access the im-
age by including and excluding users at any time. Once the
image is shared, our attack can be successfully deployed,
930    28th USENIX Security Symposium
USENIX Association
Table 4: Leaky images in popular websites, the attack’s preconditions, the image sharing channel and the implemented authen-
tication mechanism as introduced in Table 2
Domain
facebook.com
twitter.com
google.com
Prerequisites
Victim and attacker are ”friends”
Victim and attacker can exchange messages
None
Authentication mechanism
(5), (2)
(2)
(3), (2)
wordpress.com
github.com
dropbox.com
live.com
skype.com
Victim is a viewer of the attacker’s private blog
Victim and attacker share a private repository
None
None
Victim and attacker can exchange messages
Image sharing channel
Image sharing
Private message
Google Drive document
Private message
Posts on private blogs
Private repository
Image sharing
Shared folder on OneDrive
Private message
(2)
(3), (2)
(3), (6), (2)
(3), (2)
(2)
without requiring the victim to accept the shared image.
However, the victim can revoke its rights to access an image
by removing it from the “Sharing” section of her account.
Live.com Setting up a leaky image on One Drive, a cloud
storage platform available on a live.com subdomain, is very
similar to the other two ﬁle sharing services that we study,
Google Drive and Dropbox. The attacker can share images
with arbitrary email addresses and the victim does not need
to acknowledge the sharing. Moreover, the attacker can eas-
ily deploy a group attack due to the ease in changing the
group of users that have access to a particular image.
Skype
In the Skype web interface, every image sent in a
chat is a leaky image. Note that most of the users probably
access the service through a desktop or mobile standalone
client, hence the impact of this attack is limited to the web
users. Moreover, Skype automatically logs out the user from
time to time, limiting the time window for the attack.
Our study of leaky images in real-world sites enables several
observations.
Leaky images are prevalent The ﬁrst and perhaps most
important observation is that many of the most popular web-
sites allow an attacker to create leaky images. From an at-
tacker’s point of view, a single leaky image is sufﬁcient to
track a user. If a victim is registered as a user with at least
one of the affected image sharing services, then the attacker
can create a user account at that service and share a leaky
image with the victim.
Victims may not notice sharing a leaky image Several
of the affected image sharing services enable an attacker to
share an image with a speciﬁc user without any notice given
to the user. For example, if the attacker posts an image on
her Facebook proﬁle and tweaks the privacy settings so that
only the victim can access it, then the victim is not informed
in any way. Another example is Google Drive, which allows
sharing ﬁles with arbitrary email addresses while instructing
the website to not send an email that informs the other user.
Victims cannot “unshare” a leaky image For some ser-
vices, the victim gets informed in some way that a connec-
tion to the attacker has been established. For example, to set
up a leaky image on Twitter, the attacker needs to send a pri-
vate message to the victim, which may make the victim sus-
picious. However, even if the victim knows about the shared
image, for most websites, there is no way for a user to re-
voke its right to access the image. Speciﬁcally, let’s assume
the victim receives a cute cat picture from a Google Hang-
outs contact. Let us now assume that the victim is aware of
the leaky image attack and that she suspects the sender of the
image tracking her. We are not aware of any way in which
the victim can revoke the right to access the received image.
Image sharing services use a diverse mix of implemen-
tation strategies Secret URLs and per-user authenticated
URLs are widely implemented techniques that protects
against our attack. However, many websites use multiple
such strategies and hence, it is enough if one of the API end-
points uses leaky images. Identifying this endpoint is often
a hard task: for example, in the case of Facebook, most of
the website rigorously implements secret URLs, but one API
endpoint belonging to a mobile subdomain exposes leaky im-
ages. After identifying this endpoint we realized that it can
be accessed without any problem from a desktop browser as
well, enabling all the attacks we describe in Section 3.
The attack surface varies from site to site Some but not
all image sharing services require a trust relation between the
attacker and the victim before a leaky image can be shared.
For example, an attacker must ﬁrst befriend a victim on Face-
book before sharing an image with the victim, whereas no
such requirement exists on Dropbox or Google Drive. How-
ever, considering that most users have hundreds of friends on
social networks, there is a good chance that a trust channel is
established before the attack starts. In the case of Wordpress
the prerequisite that the ”victim is a viewer of the attacker’s
private blog” appears harder to meet and may require ad-
vanced social engineering. Nonetheless, we believe that such
leaky images may still be relevant in certain targeted attacks.
USENIX Association
28th USENIX Security Symposium    931
Moreover, three of the eight vulnerable sites allow attackers
to share images with arbitrary users, without any prerequi-
sites (Table 4).
Since our study of the prevalence of leaky images is mostly
manual, we cannot guarantee that the 22 sites for which we
could not create a leaky image are not affected by the prob-
lem. For some sites, though, we are conﬁdent that they
are not affected, as these sites do not allow users to upload
images. A more detailed analysis would require in-depth
knowledge of the implementation of the studied sites, and
ideally also access to the server-side source code. We hope
that our results will spur future work on more automated
analyses that identify leaky images.
4.3 Responsible Disclosure and Feedback
from Image Sharing Services
After identifying image sharing services that suffer from
leaky images, we contacted their security teams to disclose
the problem in a responsible way. Between March 26 and
March 29, 2018, we sent a detailed description of the gen-
eral problem, how the speciﬁc website can be abused to cre-
ate leaky images, and how it may affect the privacy of users
of the site. Most security teams we contacted were very re-
sponsive and eager to collaborate upon ﬁxing the issue.
Conﬁrmed reports The last three columns of Table 3 sum-
marize how the security teams of the contacted companies
reacted to our reports. For most of the websites, the security
teams conﬁrmed that the reported vulnerability is worth ﬁx-
ing, and at least six of the sites have already ﬁxed the prob-
lem or have decided to ﬁx it.
In particular, the top three
websites all conﬁrmed the reported issue and all have been
working on ﬁxing it. Given the huge user bases of these
sites and the privacy implications of leaky images for their
users, this reaction is perhaps unsurprising. As another sign
of appreciation of our reports, the authors have received bug
bounties from (so far) three of the eight affected sites.
Dismissed reports Two of our reports were ﬂagged as
false positives. The security teams of the corresponding web-
sites replied by saying that leaky images are a “desired be-
havior” or that the impact on privacy of their user is limited.
Comparing Table 3 with Table 4 shows that the sites that dis-
miss our report are those where the prerequisites for creating
a leaky image are harder to fulﬁll than for the other sites:
Creating a leaky image on GitHub requires the attacker and
the victim to share a private repository, and Wordpress re-
quires that the victim is a viewer of the attacker’s private
blog. While we agree that the attack surface is relatively
small for these two sites, leaky images may nevertheless
cause surprising privacy leaks. For example, an employee
might track her colleagues or even her boss if their company
uses private GitHub repositories.
Case study: Fix by Facebook To illustrate how image
sharing services may ﬁx a leaky images problem, we de-
scribe how Facebook addressed the problem in reaction to
our report. As mentioned earlier, Facebook employs mostly
secret URLs and uses content delivery networks to serve im-
ages. However, we were able to identify a mobile API end-
point that uses leaky images and redirects the user to the cor-
responding content delivery network link. This endpoint is
used in the mobile user interface for enabling users to down-
load the full resolution version of an image. The redirec-
tion was performed at HTTP level, hence it resulted in a suc-
cessful image request when inserted in a third-party website
using the  HTML tag. The ﬁx deployed by Facebook
was to perform a redirection at JavaScript level, i.e. load an
intermediate HTML that contains a JavaScript snippet that
rewrites document.location.href. This ﬁx enables a
benign user to still successfully download the full resolution
image through a browser request, but disables third-party im-
age inclusions. However, we believe that such a ﬁx does not
generalize and cannot be deployed to the other identiﬁed vul-
nerabilities. Hence, we describe alternative ways to protect
against a leaky image attacks in Section 5.
Case study: Fix by Twitter A second case study of how
websites can move away from leaky images comes from
Twitter that changed its API7 in response to our report8.
First, they disabled cookie-based authentication for images.
Second, they changed the API in a way that image URLs are
only delivered on secure channels, i.e., only authenticated
HTTPS requests. Last, Twitter also changed the user inter-
face to only render images from strangers when explicit con-
sent is given. Essentially, Twitter moved from implementa-
tion strategy (2) to (5) in Table 2 in response to our report.
Overall, we conclude from our experience of disclosing
leaky images that popular websites consider it to be a serious
privacy problem, and that they are interested in detecting and
avoiding leaky images.
5 Mitigation Techniques
In this section, we describe several techniques to defend
against leaky image attacks. The mitigations range from
server-side ﬁxes that websites can deploy, over improved pri-
vacy settings that empower users to control what is shared
with them, to browser-based mitigations.
7https://twitter.com/TwitterAPI/status/
1039631353141112832
8https://hackerone.com/reports/329957
932    28th USENIX Security Symposium
USENIX Association
5.1 Server-Side Mitigations
The perhaps easiest way to defend against the attack pre-
sented in this paper is to modify the server-side implemen-
tation of an image sharing service, so that it is not possible
anymore to create leaky images. There are multiple courses
of actions to approach this issue.
First, a controversial ﬁx to the problem is to disable au-
thenticated image requests altogether. Instead of relying on,
e.g., cookies to control who can access an image, an image
sharing service could deliver secret links only to those users
that should access an image. Once a user knows the link
she can freely get the image through the link, independent
of whether she is logged into the image sharing service or
not. This strategy corresponds to case 5 in Table 2. Multiple
websites we report about in Table 3 implement such an image
sharing strategy. The most notable examples are Facebook,
which employs this technique in most parts of their website,
and Dropbox, which implements this technique as part of
their link sharing functionality. The drawback of this ﬁx is
that the link’s secrecy might be compromised in several ways
outside of the control of the image sharing service: by using
insecure channels, such as HTTP, through side-channel at-
tacks in the browser, such as cache attacks [20], or simply by
having the users handle the links in an insecure way because
they are not aware of the secrecy requirements.
Second, an alternative ﬁx is to enforce an even stricter
cookie-based access control on the server-side. In this case,
the image sharing service enforces that each user accesses a
shared image through a secret, user-speciﬁc link that is not
shared between users. As a result, the attacker does not know
which link the victim could use to access a shared image, and
therefore the attacker cannot embed such a link in any web-
site. This implementation strategy corresponds to case 3 in
Table 2. On the downside, implementing this defense may
prove challenging due to the additional requirement of guar-
anteeing the mapping between users and URLs, especially
when content delivery networks are involved. Additionally,
it may cause a slowdown for each image request due to the
added access control mechanism.
Third, one may deploy mitigations against CSRF.9 One of
them is to use the origin HTTP header to ensure that the
given image can only be embedded on speciﬁc websites. The
origin HTTP header is sent automatically by the browser
with every request, and it precisely identiﬁes the page that
requests a resource. The server-side can check the request’s
origin and refuse to respond with an authenticated image
to unknown third-party request. For example, facebook.com
could refuse to respond with a valid image to an HTTP re-
quest with the origin set to evil.com. However, this mit-
igation cannot defend against tracking code injected into a
trusted domain. For example, until recently Facebook al-
9https://www.owasp.org/index.php/Cross-Site_
Request_Forgery_(CSRF)_Prevention_Cheat_Sheet
the
server-side
set
Similarly,
lowed users to post custom HTML code on their proﬁle page.
If a user decides to insert leaky image-based tracking code on
the proﬁle page, to be notiﬁed when a target user visits the
proﬁle page, then the CSRF-style mitigation does not pre-
vent the attack. The reason for this is that the request’s ori-
gin would be set to facebook.com, and hence the server-side
code will trust the page and serve the image.
can
the
Cross-Origin-Resource-Policy response header
on authenticated image requests and thus limit which
websites can include a speciﬁc image. Browsers will only
render images for which the origin of the request matches
the origin of the embedding website or if they correspond
to the same site. This solution is more coarse-grained than
the previously discussed origin checking since it does not
allow for cross-origin integration of authenticated images,
but it is easier to deploy since it only requires a header set
instead of a header check. The From-Origin header
was proposed for allowing a more ﬁne-grained integration
policy, but to this date there is no interest from browser
vendors side to implement such a feature.
Another applicable CSRF mitigation is the SameSite
cookie attribute. When set to “strict” for a cookie, the at-
tribute prevents the browser from sending the cookie along
with cross-site requests, which effectively prevents leaky im-
ages. However, the “strict” setting may be too strict for most
image sharing services, because it affects all links to the ser-
vice’s website. For example, a link in a corporate email to a
private GitHub project or to a private Google Doc would not
work anymore, because when clicking the link, the session
cookie is not sent along with the request. The less restric-
tive “lax” setting of the SameSite attribute does not suffer