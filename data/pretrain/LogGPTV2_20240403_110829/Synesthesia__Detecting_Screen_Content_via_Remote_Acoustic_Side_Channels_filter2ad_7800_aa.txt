title:Synesthesia: Detecting Screen Content via Remote Acoustic Side Channels
author:Daniel Genkin and
Mihir Pattani and
Roei Schuster and
Eran Tromer
2019 IEEE Symposium on Security and Privacy
Synesthesia: Detecting Screen Content via Remote
Acoustic Side Channels*
Daniel Genkin
University of Michigan
PI:EMAIL
Mihir Pattani
University of Pennsylvania
PI:EMAIL
Roei Schuster
Tel Aviv University and Cornell Tech
PI:EMAIL
Eran Tromer
Tel Aviv University and Columbia University
PI:EMAIL
Abstract—We show that subtle acoustic noises emanating
from within computer screens can be used to detect the content
displayed on the screens. This sound can be picked up by ordinary
microphones built into webcams or screens, and is inadvertently
transmitted to other parties, e.g., during a videoconference call
or archived recordings. It can also be recorded by a smartphone
or “smart speaker” placed on a desk next to the screen, or from
as far as 10 meters away using a parabolic microphone.
Empirically demonstrating various attack scenarios, we show
how this channel can be used for real-time detection of on-screen
text, or users’ input into on-screen virtual keyboards. We also
demonstrate how an attacker can analyze the audio received
during video call (e.g., on Google Hangout) to infer whether the
other side is browsing the web in lieu of watching the video call,
and which web site is displayed on their screen.
I.
INTRODUCTION
Physical side-channel attacks extract
information from
computing systems by measuring unintended effects of a
system on its physical environment. They have been used to
violate the security of numerous cryptographic implementa-
tions (see [36], [1], [29] and the references therein), both
on small embedded devices and, more recently, on complex
devices such as laptops, PCs, and smartphones [11], [19],
[6], [20], [13], [12], [21]. Physical emanations were used to
recover information from peripheral input/output devices such
as screens [15], [32], [16], printers [4] and keyboards [2], [7],
[48], [25], [5], [26], [51], [14].
Attackers seeking to exploit such channels face a challenge:
attaining physical proximity to the target computer, in order
to acquire physical measurements. In many settings, physical
access is controlled, and attempts to attain proximity will
be blocked or detected. Alternatively, the attacker can seek
to control suitable sensors that are already located in close
proximity to the target;
this may be tractable when there
are ubiquitously deployed commodity devices, with suitable
sensors, that can be adversarially controlled; for example, one
of the low-bandwidth acoustic attacks [22] can be conducted
via a smartphone, using a malicious app that records audio
using the built-in microphone when the smartphone is placed
(for an hour) near the target.
We raise a third possibility: are there physical side-channel
attacks for which the requisite physical measurements are
readily available, and are shared by victims with untrusted
parties as a matter of course, and yet the victims have no reason
to suspect that they inadvertently leak private information?
∗ Authors are ordered alphabetically.
© 2019, Daniel Genkin. Under license to IEEE.
DOI 10.1109/SP.2019.00074
853
We observe a new physical side channel that facilitates
such an attack: content-dependent acoustic leakage from LCD
screens. This leakage can be picked up by adjacent micro-
phones, such as those embedded in webcams and some com-
puter screens. Users commonly share audio recorded by these
microphones, e.g., during Voice over IP and videoconference
calls. Moreover, the pertinent sounds are so faint and high-
pitched that they are well-nigh inaudible to the human ear, and
thus (unlike with mechanical peripherals) users have no reason
to suspect that these emanations exist and that information
about their screen content is being conveyed to anyone who
receives the audio stream, or even a retroactive recording. In
fact, users often make an effort to place their webcam (and
thus, microphone) in close proximity to the screen, in order to
maintain eye contact during videoconference, thereby offering
high quality measurements to would-be attackers.
Exploiting this channel raises many questions: What form
of content-dependent acoustic signals are emitted by screens?
Can these emanations be used to detect screen content? What
measurement equipment and positioning sufﬁces to measure
them? Can they be acquired remotely via Voice over IP
applications, despite the signal conditioning and lossy codecs
employed by such applications?
A. Our results
We observe the existence of the aforementioned synesthetic
side channel: “hearing” on-screen images. We characterize this
content-dependent acoustic leakage on numerous LCD screens
of various models and manufacturers. The leakage has existed
in screens manufactured and sold for at least the past 16 years,
old and new models alike, in both PC and laptop screens, with
both CCFL and LED backlighting. See Appendix C for a list
of screens we experimented with, all of them were found to
exhibit this acoustic leakage.
We show that this leakage can be captured by:
• Webcam microphones (see Figure III.3).
• Mobile phones in proximity to the screen (Figures III.2).
• “Smart speaker” virtual assistant devices (Figure III.4).
• The built-in microphones of some screens.
• A parabolic microphone from a 10-meters line-of-sight to
the back of the screen (see Figure III.1).
Moreover, the leakage can be observed and analyzed:
• In archived audio recordings.
• From the remote side of a Google Hangouts video-
• In the cloud-stored audio saved by virtual assistants.
We demonstrate exploitation of the above attack vectors for
several attack goals:
conference call.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:34 UTC from IEEE Xplore.  Restrictions apply. 
1) Extracting text displayed on the screen (in a large font).
2) Distinguishing between websites displayed on the screen,
or between websites and a videoconference screen.
3) Extracting text entered via Ubuntu’s on-screen keyboard.
(This shows that on-screen keyboards are not an acoustic-
leakage-resistant alternative to mechanical keyboards.)
Our attacks use tailored signal processing combined with deep
neural networks. We demonstrate that leakage characteristics,
and trained neural-networks, often generalize across screens
(even of different models) allowing for training to be done on
one screen while attacking another. Finally, the attacks are ro-
bust to ofﬁce-environment noise-level from nearby equipment
such as computers, other monitors, and human speech.
B. Related work
Physical side channels. Numerous prior works demonstrated
physical side channels. Categorized by channels, these in-
clude electromagnetic radiation [41], [18], [15], [32], [16];
power consumption [28], [29], [36]; ground-potential ﬂuctua-
tions [21]; timing (often observable by any of the above) [30],
[9], [8]; and acoustic emanations from keyboards [2], [7],
[48], [25], [5], [26], [51], [14], printers [4] and CPU power
supplies [22]. Acoustic emanations are also mentioned in
NACSIM 5000 “TEMPEST Fundamentals” [38] and related
US government publications, but only in the context of elec-
tromechanical devices (as described in [38]: “[...] mechanical
operations occur and sound is produced. Keyboards, printers,
relays — these produce sound, and consequently can be
sources of compromise”; see [22] for further discussion).
While some physical side channels have been thoroughly
explored, the only previous work extracting information from
involuntary acoustic leakage of electronic components is
Genkin et al.’s acoustic cryptanalysis [22], which exploits
laptop coil whine, and does not consider leakage from displays.
Screen emanations.
Extracting screen content via elec-
tromagnetic emanations (“Van Eck phreaking” and screen
“TEMPEST”) is well known and studied, originally for CRT
screens [15], and later also for modern ﬂat-panel screens
and digital interfaces [32], [33]. Such electromagnetic attacks
require antennas and radio receivers in physical proximity to
the screen, and tuned to suitable radio frequencies. Acoustic
attacks relying on microphones, which are ubiquitous and open
new attack scenarios, have not been previously addressed.
C. Outline
This paper is organized as follows: Section II charac-
terizes the content-dependent acoustic leakage from various
screens, and suggests a signal processing scheme for producing
clean leakage traces. Section III introduces the attack vec-
tors evaluated in this paper. We then discuss several attack
scenarios, categorized by the attacker’s goal: an on-screen
keyboard snooping attack (Section IV), a text extraction attack
(Section V), and a website-distinguishing attack from various
vantage points, including a remote attack over a Hangouts
VoIP call (Section VI). Section VII explores generalization
of leakage characteristics, as modeled by the attacker, across
screens and screen models. Sections VIII discusses limitations,
Section IX discusses mitigations, and Section X concludes.
II. CHARACTERIZING THE SIGNAL
In this section we explore the acoustic leakage signal
emitted by various LCD computer screens (with both CCFL
and LED backlighting) as well as attempt to characterize the
connections between the leakage signal and the displayed
image. We begin by providing some background about the
process of rendering an image on modern LCD screens as well
as by describing the experimental setup used in this section.
A. Background and experimental setup
Image rendering mechanism. Computer screens display a
rectangular l×n matrix of pixels. Each pixel is typically further
divided into red, green, and blue sub-pixels where the intensity
of each sub-pixel is an integer between 0 and 255, thereby
allowing the color of pixel to be uniquely represented using
24-bit integers. The screen’s refresh rate, r, determines how
many times per second an image to be displayed is sent to
the screen by the computer’s graphics card. The screen then
renders the received image by iterating over the pixel rows
from top to bottom, with the value of the pixels in each row
rendered from left to right. Notice that the screen always
re-renders the image it displays (using the above-described
method) r times per second, even if no changes occurred in
the image to be displayed. Typically, screens are refreshed
approximately 30, 60, or 120 times per second, with a refresh
rate of approximately 60 Hz being the most common.
Experimental setup.
For experiments performed in this
section we captured the acoustic noise emanating from various
monitors using a Brüel & Kjaer 4190 microphone capsule (ef-
fective up to approx. 40 kHz, well beyond its nominal 20 kHz
range), attached to a Brüel & Kjaer 2669 preampliﬁer. For
power supply and further ampliﬁcation, these were connected
to a Brüel & Kjaer 2610 or 5935 ampliﬁer. The resulting
ampliﬁed signal was ﬁltered as necessary using a high-pass
ﬁlter (with a cut off frequency between 10 and 21 kHz) and
digitized using a USB sound card, at a sampling rate of
192 kHz (either a Creative E-MU 0404 or Focusrite Scarlett
2i2). We visualize the spectrograms of these signals using the
Baudline software and (from Section II-C onward) process
them via custom scripts.
Vsync probe. For the purpose of signal exploration, we shall
sometimes utilize a trigger signal marking the start of each
screen refresh period; this allows us to focus on the acoustic
leakage from each screen refresh, separately from the task of
synchronizing to the refresh rate. We implement this trigger by
constructing a VGA tap cable that exposes the VGA’s vsync
line which (as speciﬁed in the VGA standard) carries a short
0.5 Volt pulse at the start of each screen refresh cycle. Note
that the vsync probe is a didactic aid; it is not necessary for
the actual attacks.
Screen selection.
In this paper we analyze acoustic leakage
present from 31 screens of 12 different models from 6 different
manufacturers, with various resolutions and backlight types
(LED or CCFL), as tabulated in Appendix C. The screens used
are those already present in our university lab and ofﬁces at the
time of writing (which, heuristically, offers a sample of popular
models), augmented by ad hoc purchases of current models
sold on Amazon.com. For in-depth investigations throughout
the paper we chose, from the above, the screens that presented
the clearest signal. For cross-screen experiments we purchased
additional screens, chosen primarily by ready availability on
eBay of used instances with diverse usage histories.
854
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:34 UTC from IEEE Xplore.  Restrictions apply. 
(a) covered microphone
(b) uncovered microphone
Fig. II.2:
(right) Spectrogram of acoustic signals emitted
by Soyo DYLM2086 screen while displaying alternating Ze-
bra patterns. Notice the difference in the screen’s acoustic
signature caused by the change in periods of the displayed
Zebra pattern. (left) Spectrogram of a recording in an identical
setting, but with the microphone covered by a thick piece of
cloth. In both spectrograms, the horizontal axis is frequency
(0-43 kHz), the vertical axis is time (10 sec), and intensity is
proportional to instantaneous energy in that frequency band.
The yellow arrow marks the 4 kHz leakage signal expected to
be produced by a Zebra pattern with a period of 16 pixels.
Physical leakage source. Having established the acoustic
nature of the leakage signal, we attempted to locate its source
within the internal display electronics. To that end, we dis-
assembled a ViewSonic VA903b LCD monitor, which has
a simple, modular internal design with a moderate number
of internal components. As can be seen in Figure II.4, in
addition to the LCD panel itself (A) the ViewSonic monitor
has two main boards: a digital board (B) which is responsible
for implementing the monitors logic and picture rendering
functions and a power supply board (C) which provides stable
voltage to the digital circuits and backlight but does not
directly process the screen’s content.
In an attempt
to locate the component producing the
acoustic leakage, we measured the acoustic signals in various
locations on both boards while displaying Zebra patterns on the
LCD panel. We localized the source of emanation to within the
monitor’s power supply board, in the area that is responsible
for supplying power to the monitor’s digital board (circled in
green). We were unable to localize the source down to a single
component, presumably due to acoustic reﬂections, diffraction
and mechanical coupling in the board.2
Leakage Mechanism. We conjecture that the momentary
power draw, induced by the monitor’s digital circuits, varies
as a function of the screen content being processed in raster