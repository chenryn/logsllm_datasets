### Coverage and Evaluation of Directed Grey-Box Fuzzers

The ability to cover specific code locations is a crucial metric for evaluating the capabilities of directed grey-box fuzzers (DGFs). Google’s fuzzing test suite includes three projects specifically designed to assess the effectiveness of fuzzers in discovering hard-to-reach code locations: `libjpeg-turbo-07-2017` (#1), `libpng 1.2.56` (#2, #3), and `freetype2-2017` (#4). In these benchmarks, the target sites are specified by file names and line numbers in the source files. To facilitate the evaluation, we manually added "sentinel" code at the target sites (e.g., `exit(n)`, where `n` uniquely identifies each site) to indicate when the relevant targets have been reached.

#### Benchmark Results

Table 5 summarizes the results from these benchmarks. For cases #1 and #4, Hawkeye demonstrates strong performance in rapidly covering the target sites, as evidenced by the mean time to exposure (µTTE) and the factor columns. The A12 metric also indicates consistent behavior. In cases #2 and #3, all fuzzers, including Hawkeye, were able to reach the target sites quickly. However, the project documentation [14] notes that these targets "currently require too much time to find." We tested this benchmark with libFuzzer using default scripts on two machines, and it failed to reach the target sites, suggesting that the internal mechanisms of different fuzzers can significantly affect their effectiveness. Additionally, HE-Go showed a notably higher µTTE value, primarily due to one run taking 524 seconds, which was much longer than other runs.

It is important to note the distinction between the µTTE for covering target sites (Table 5) and for triggering real-world crashes (Table 4). The former is based on the first-time coverage of specific lines, while the latter is related to branch or path coverage, as bugs often require specific execution paths to be triggered. Although Table 5 shows that Hawkeye's improvements over HE-Go in covering target sites are not always significant (and in some cases, worse), Table 4 reveals a substantial acceleration in crash reproduction, especially for #4 (1.80x, nearly 2 hours faster) and #2 (1.23x). This indicates that dynamic strategies are highly effective in detecting crashes.

### Answers to Research Questions

Based on the experiments conducted in Tables 2, 3, 4, and 5, we can address the following research questions:

**RQ1: Is static analysis worth applying?**
- **Answer:** Yes, static analysis is valuable. As shown in Table 1, the time cost of our static analysis is generally acceptable compared to the runtime cost during fuzzing. Even in the cxxfilt cases (Table 2), which take an average of 735 seconds, Hawkeye outperforms vanilla AFL in most scenarios. Notably, for CVE-2016-4491 and CVE-2016-6131, Hawkeye saves approximately 2000 and 9000 seconds, respectively, in detecting crashes. The A12 metric confirms the consistency of these results across 20 runs. Additionally, Hawkeye demonstrates improved fuzzing performance.

**RQ2: How well does Hawkeye perform in detecting crashes?**
- **Answer:** Hawkeye performs exceptionally well in detecting crashes. From the results in Tables 2, 3, and 4, it is clear that Hawkeye can detect crashes more quickly than other tools, and the results are consistent across multiple runs, as indicated by the A12 metric.

**RQ3: Are the dynamic strategies used in Hawkeye effective?**
- **Answer:** Yes, the dynamic strategies in Hawkeye are highly effective. Across all experiments, Hawkeye outperforms other tools. Specifically, the comparison with HE-Go (Tables 4 and 5) shows that the combination of power scheduling, adaptive mutation strategies, and seed prioritization in Hawkeye leads to faster convergence than AFLGo's simulated annealing-based scheduling.

**RQ4: Does Hawkeye have the capability to reach target sites rapidly?**
- **Answer:** Yes, Hawkeye has demonstrated the capability to reach target sites rapidly, as shown in Table 5.

### Practical Applications

In practice, Hawkeye has proven its effectiveness in exposing crashes with the help of other vulnerability detection tools. For example, in the Oniguruma and MJS projects, the Clang Static Analyzer (both built-in and customized checkers) reported suspicious vulnerability locations, and Hawkeye successfully detected crashes by directing the fuzzing to those locations. For MJS, we marked several newly patched program locations and detected additional crashes. Hawkeye has reported over 28 crashes in the Oniguruma and MJS projects, and multiple vulnerabilities in other projects such as Intel XED x86 encoder decoder (4 crashes) and Espruino JavaScript interpreter (9 crashes). All these crashes have been confirmed and fixed, with 15 assigned CVE IDs.

### Threats to Validity

**Internal Threats:**
1. **Threshold Configuration:** Several components of Hawkeye, such as Algorithms 1 and 2, use predefined thresholds for decision-making. These thresholds (e.g., γ = 0.1, δ = 0.4, σ = 0.2, ζ = 0.8) are currently configured based on preliminary experiments and prior experience. Future systematic research will investigate the impact of these thresholds and determine the best configurations.
2. **Program Analysis Tools:** Hawkeye relies on lightweight program analysis tools like LLVM and SVF to calculate distances. Potential issues with these tools could affect the final results. However, Hawkeye's modular design allows for easy integration with other static analysis tools, providing an alternative solution.

**External Threats:**
- **Evaluation Dataset and CVEs:** The choice of the evaluation dataset and CVEs for crash reproduction may introduce bias. While we used Binutils, which is also used in AFLGo [6], future work should generalize the results through empirical studies on more projects. The tested CVEs in MJS and Oniguruma were chosen because they were recently reported, not to show the superiority of Hawkeye.

### Related Work

**Directed Grey-Box Fuzzing:**
- **AFLGo [6]:** A state-of-the-art directed grey-box fuzzer that uses a simulated annealing-based power schedule to gradually assign more energy to inputs closer to the target sites. AFLGo introduced a novel method for calculating the distance between input traces and target sites. Hawkeye builds on AFLGo but provides significant improvements in both static analysis and dynamic fuzzing, outperforming AFLGo in reaching targets and reproducing crashes.
- **SeededFuzz [45]:** Uses various program analysis techniques to generate and select initial seeds, enhancing directed fuzzing. SeededFuzz focuses on the quality of initial seeds, while Hawkeye emphasizes four desired properties regardless of initial seeds. The techniques in SeededFuzz are orthogonal to Hawkeye.

**Directed Symbolic Execution:**
- **Katch [29]:** Relies on symbolic execution and heuristics to reach target sites systematically. While DSE techniques are effective, they suffer from the path-explosion problem. Hawkeye, in contrast, uses lightweight program analysis, ensuring scalability and efficiency.

**Taint Analysis Aided Fuzzing:**
- **TaintScope [44]:** Uses taint analysis to identify parts of the input that should be mutated with priority, reducing the search space. Taint-based approaches are scalable but do not have the same advantages as Hawkeye when the targets are clearly defined, such as in patch testing and crash reproduction.

**Coverage-Based Grey-Box Fuzzing:**
- **CollAFL [15]:** Solves AFL’s instrumentation collision problem with a novel hash algorithm.
- **Skyfire [43]:** Learns a probabilistic context-sensitive grammar to generate new test seeds.
- **Xu et al. [46]:** Proposes new operating primitives to improve grey-box fuzzer performance.
- **Orthrus [38]:** Applies static analysis on AST, CFG, and CG to extract complex tokens. Hawkeye can benefit from integrating these techniques.

### Conclusions

In this paper, we introduce Hawkeye, a novel directed grey-box fuzzer that combines static analysis and dynamic fuzzing to achieve four desired properties. Hawkeye precisely and adaptively adjusts seed prioritization, power scheduling, and mutation strategies to rapidly reach user-specified target sites. Our evaluation shows that Hawkeye can reach target sites and reproduce crashes much faster than existing state-of-the-art grey-box fuzzers. These promising results indicate that Hawkeye is effective in patch testing, crash exposure, and other scenarios.

### Acknowledgment

This work is supported by the National Research Foundation, Prime Minister's Office, Singapore under its National Cybersecurity R&D Program (Award No. NRF2016NCR-NCR002-026) and administered by the National Cybersecurity R&D Directorate. The research of Dr. Xue is also supported by the CAS Pioneer Hundred Talents Program.

### References

[1] 2018. Pin - A Dynamic Binary Instrumentation Tool. https://software.intel.com/en-us/articles/pin-a-dynamic-binary-instrumentation-tool
[2] AFLGo. 2018. GitHub - AFLGo. https://github.com/aflgo/aflgo/issues
[3] Lars Ole Andersen. 1994. Program Analysis and Specialization for the C Programming Language. Technical Report. DIKU, University of Copenhagen.
[4] Jean-Yves Audibert, Rémi Munos, and Csaba Szepesvári. 2009. Exploration-exploitation tradeoff using variance estimates in multi-armed bandits. Theoretical Computer Science 410, 19 (2009), 1876 – 1902. http://www.sciencedirect.com/science/article/pii/S030439750900067X Algorithmic Learning Theory.
[5] GNU Binutils. 1990. GNU Binutils. https://www.gnu.org/software/binutils/
[6] Marcel Böhme, Van-Thuan Pham, Manh-Dung Nguyen, and Abhik Roychoudhury. 2017. Directed Greybox Fuzzing (CCS ’17). ACM Press, New York, NY, USA, 2329–2344.
[7] Marcel Böhme, Van-Thuan Pham, and Abhik Roychoudhury. 2016. Coverage-based Greybox Fuzzing As Markov Chain (CCS ’16). ACM Press, New York, NY, USA, 1032–1043.
[8] Denny Britz. 2014. Exploitation vs Exploration. @dennybritz/exploration-vs-exploitation-f46af4cf62fe https://medium.com/
[9] Mahinthan Chandramohan, Yinxing Xue, Zhengzi Xu, Yang Liu, Chia Yuan Cho, and Hee Beng Kuan Tan. 2016. BinGo: Cross-architecture cross-OS Binary Search (FSE ’16). ACM Press, New York, NY, USA, 678–689.
[10] Chen Chen, Baojiang Cui, Jinxin Ma, Runpu Wu, Jianchao Guo, and Wenqian Liu. 2018. A systematic review of fuzzing techniques. Computers & Security 75 (2018), 118–137.
[11] Hongxu Chen, Yuekang Li, Bihuan Chen, Yinxing Xue, and Yang Liu. 2018. FOT: A Versatile, Configurable, Extensible Fuzzing Framework (FSE ’18 tool demo). ACM Press, (to appear).
[12] Peng Chen and Hao Chen. 2018. Angora: Efficient Fuzzing by Principled Search. CoRR abs/1803.01307 (2018). arXiv:1803.01307 https://arxiv.org/abs/1803.01307v2 https://lwn.net/
[13] J. B. Crawford. 2018. A survey of some free fuzzing tools. Articles/744269/
[14] fuzzer-test suite. 2018. libpng-1.2.56/test-libfuzzer.sh. https://github.com/google/fuzzer-test-suite/blob/master/libpng-1.2.56/test-libfuzzer.sh
[15] Shuitao Gan, Chao Zhang, Xiaojun Qin, Xuwen Tu, Kang Li, Zhongyu Pei, and Zuoning Chen. 2018. CollAFL: Path Sensitive Fuzzing (SP ’18). IEEE Press, 1–12.
[16] Vijay Ganesh, Tim Leek, and Martin Rinard. 2009. Taint-based Directed Whitebox Fuzzing (ICSE ’09). IEEE Computer Society, Washington, DC, USA, 474–484.
[17] Patrice Godefroid, Nils Klarlund, and Koushik Sen. 2005. DART: Directed Automated Random Testing (PLDI ’05). ACM Press, New York, NY, USA, 213–223.
[18] Google. 2017. Fuzzer Test Suite. https://github.com/google/fuzzer-test-suite
[19] Istvan Haller, Asia Slowinska, Matthias Neugschwandtner, and Herbert Bos. 2013. Dowsing for Overflows: A Guided Fuzzer to Find Buffer Boundary Violations (SEC ’13). USENIX Association, Berkeley, CA, USA, 49–64.
[20] Hex-Rays. 2013. IDA. https://www.hex-rays.com/index.shtml
[21] Wei Jin and Alessandro Orso. 2012. BugRedux: Reproducing Field Failures for In-house Debugging (ICSE ’12). IEEE Press, Piscataway, NJ, USA, 474–484.
[22] Scott Kirkpatrick, C Daniel Gelatt, and Mario P Vecchi. 1983. Optimization by simulated annealing. science 220, 4598 (1983), 671–680.
[23] K. Kosako. 2002. Oniguruma. https://github.com/kkos/oniguruma
[24] C. Lemieux and K. Sen. 2017. FairFuzz: Targeting Rare Branches to Rapidly Increase Greybox Fuzz Testing Coverage. ArXiv e-prints (Sept. 2017). arXiv:cs.SE/1709.07101
[25] Yuekang Li, Bihuan Chen, Mahinthan Chandramohan, Shang-Wei Lin, Yang Liu, and Alwen Tiu. 2017. Steelix: Program-state Based Binary Fuzzing (ESEC/FSE ’17). ACM Press, New York, NY, USA, 627–637.
[26] LLVM. 2015. libFuzzer. https://llvm.org/docs/LibFuzzer.html
[27] LLVM/Clang. 2013. Clang Static Analyzer. https://clang-analyzer.llvm.org/
[28] Kin-Keung Ma, Khoo Yit Phang, Jeffrey S. Foster, and Michael Hicks. 2011. Directed Symbolic Execution (SAS’11). Springer-Verlag, Berlin, Heidelberg, 95–111.
[29] Paul Dan Marinescu and Cristian Cadar. 2013. KATCH: High-coverage Testing of Software Patches (ESEC/FSE 2013). ACM Press, New York, NY, USA, 235–245.
[30] Barton P. Miller, Louis Fredriksen, and Bryan So. 1990. An Empirical Study of the Reliability of UNIX Utilities. Commun. ACM 33, 12 (Dec. 1990), 32–44.
[31] Terence Parr. 2018. ANTLR (ANother Tool for Language Recognition). http://www.antlr.org/
[32] Hui Peng, Yan Shoshitaishvili, and Mathias Payer. 2018. T-Fuzz: Fuzzing by Program Transformation (SP ’18). 697–710.
[33] PHP. 1994. PHP: Hypertext Preprocessor. http://www.php.net/
[34] Sanjay Rawat, Vivek Jain, Ashish Kumar, Lucian Cojocar, Cristiano Giuffrida, and Herbert Bos. 2017. VUzzer: Application-aware Evolutionary Fuzzing (NDSS ’17). 1–14.
[35] Agostino Sarubbo. 2017. cat_filename (dwarf2.c). binutils-null-pointer-dereference-in-concat_filename-dwarf2-c binutils: NULL pointer dereference in con. https://blogs.gentoo.org/ago/2017/10/03/
[36] Agostino Sarubbo. 2017. binutils: NULL pointer dereference in concat_filename (dwarf2.c) https://blogs.gentoo.org/ago/2017/10/24/binutils-null-pointer-dereference-in-concat_filename-dwarf2-c-incomplete-fix-for-cve-2017-15023 (INCOMPLETE FIX FOR CVE-2017-15023).
[37] Konstantin Serebryany and Marcel Böhme. 2017. AFLGo: Directing AFL to reach specific target locations. https://groups.google.com/forum/#!topic/afl-users/qcqFMJa2yn4
[38] Bhargava Shastry, Markus Leutner, Tobias Fiebig, Kashyap Thimmaraju, Fabian Yamaguchi, Konrad Rieck, Stefan Schmid, Jean-Pierre Seifert, and Anja Feldmann. 2017. Static Program Analysis as a Fuzzing Aid. In Research in Attacks, Intrusions, and Defenses, Marc Dacier, Michael Bailey, Michalis Polychronakis, and Manos Antonakakis (Eds.). Springer International Publishing, 26–47.
[39] Cesanta Software. 2016. mjs. https://github.com/cesanta/mjs
[40] Nick Stephens, John Grosen, Christopher Salls, Andrew Dutcher, Ruoyu Wang, Jacopo Corbetta, Yan Shoshitaishvili, Christopher Krügel, and Giovanni Vigna. 2016. Driller: Augmenting Fuzzing Through Selective Symbolic Execution (NDSS ’16). 1–16.
[41] Yulei Sui and Jingling Xue. 2016. SVF: Interprocedural Static Value-flow Analysis in LLVM (CC ’16). ACM Press, New York, NY, USA, 265–266.
[42] Andras Vargha, András Vargha, and Harold D. Delaney. 2000. A critique and improvement of the CL common language effect size statistics of McGraw and Wong. Journal of Educational and Behavioral Statistics 25, 2 (2000), 101–132.
[43] Junjie Wang, Bihuan Chen, Lei Wei, and Yang Liu. 2017. Skyfire: Data-Driven Seed Generation for Fuzzing (SP ’17). 579–594.
[44] T. Wang, T. Wei, G. Gu, and W. Zou. 2010. TaintScope: A Checksum-Aware Directed Fuzzing Tool for Automatic Software Vulnerability Detection (SP ’10). 497–512.
[45] Weiguang Wang, Hao Sun, and Qingkai Zeng. 2016. SeededFuzz: Selecting and Generating Seeds for Directed Fuzzing. 49–56.
[46] Wen Xu, Sanidhya Kashyap, Changwoo Min, and Taesoo Kim. 2017. Designing New Operating Primitives to Improve Fuzzing Performance (CCS ’17). ACM Press, New York, NY, USA, 2313–2328.
[47] Yinxing Xue, Zhengzi Xu, Mahinthan Chandramohan, and Yang Liu. 2018. Accurate and Scalable Cross-Architecture Cross-OS Binary Code Search with Emulation. IEEE Trans Software Engineering (2018), (to appear).
[48] Michal Zalewski. 2014. American Fuzzy Lop. http://lcamtuf.coredump.cx/afl/
[49] Michal Zalewski. 2014. Technical "whitepaper" for afl-fuzz. http://lcamtuf.coredump.cx/afl/technical_details.txt
[50] Michal Zalewski. 2016. "FidgetyAFL" implemented in 2.31b. https://groups.google.com/forum/#!topic/afl-users/1PmKJC-EKZ0