passed to the ASR.
We ran our attacks against ten ASRs shown in Table I. The
attack was successful if the ASR transcribed the entire phrase
correctly. Minor spelling mistakes in the transcriptions were
ignored. In each case, it took a few minutes to ﬁnd the ﬁrst
attack audio that the ASR transcribed correctly. For each model
we were able to produce a sample audio that the ASR correctly
identiﬁed, as seen in Table II, despite having no information
about the ASR’s underlying model or pre-processing steps. In
total, we generated approximately 20,000 correctly transcribed
attack audio samples. By design, modern ASRs are susceptible
to replay attacks. Once an adversary generates an attack audio
that works, they can use it repeatedly against multiple victims
who use the same ASR.
8
Models
Bing Speech API
Google Speech API
Houndify
IBM Speech API
Mozilla DeepSpeech
Kaldi-DNN
Wit.ai Speech API
Over
-the-
Air
4/4
4/4
3/4
3/4
15/15
4/4
2/4
Attack
Type
TDI
TDI
TDI
TDI
TDI
TDI+TS
TDI
Min
TDI
Size (ms)
Max TS
Factor
(%)
3.36
1.47
1.00
2.42
2.00
1.00
1.94
-
-
-
-
-
300
-
TABLE III: For phrases E-H in Table II, we generated 20
attack audio samples. Approximately 80% of those samples
successfully fooled the model for each of the 4 phrases. Man-
ual listening tests revealed that the most obfuscated samples
were generated using TDI and TS. These were then played
Over-the-Air and were able to trick the model in nearly every
case. Ambient noise is believed to have impacted the few non-
passing phrases.
Almost all ASRs employ techniques that fall within the
categories we covered in Table I. We attack a diverse range of
ASRs and all ASRs make similar assumptions about human
speech. That is why it is reasonable to assume that our attack
is effective against other state of the art ASRs, irrespective of
the underlying mechanisms.
the attack was successful
2) Speaker Identiﬁcation Models: Table I shows the results
for the attacks against speaker identiﬁcation models. For this
experiment,
if the identiﬁcation
model classiﬁed the attack audio as that of the original speaker.
In all cases, the models made the correct classiﬁcation. The
speaker models do not return any information about the audio’s
success, other than the classiﬁcation. This means there is no
information an attacker can rely on to improve the attack.
Therefore, an ofﬂine perturbation scheme, like the one we
propose, is preferable.
B. Over-the-Air
In addition to being easy to generate, the attack audio
must be correctly transcribed by the VPS after it has been
played Over-the-Air. To test this against a randomly sampled
set of seven of the ten ASRs, we use the same audio from
the previous section. Figure 5 shows an example of the attack.
The attack is a success if the model completely transcribed
the desired phrase. The attack is unsuccessful if the ASR
transcribes one or more words incorrectly. For example, if
the word “turn” in the phrase “turn on the computer” was
not transcribed, the attack is a failure. This is a conservative
approach as an adversary can overcome this by using any of
the 20,000 other attack audio samples that were created in the
previous section.
For the Over-the-air tests, we used the attack audio samples
generated during the Over-the-Line experiments. For each of
the four phrases E-H in Table II, we picked the single most
distorted audio sample. The attack parameters used to generate
the audio samples are shown in Table III. We used the TDI
method, as this method generated the most audible distortion.
For Kaldi-DNN, we performed TS in addition to TDI. Table III
shows the minimum window size for TDI. Any window size
greater than this would lead to a successful attack Over-the-Air.
Similarly, any TS factor smaller than the one in used Table III
led to a successful attack Over-the-Air.
9
As seen in Table III, almost all phrases are successfully
transcribed. This is expected as the attack is designed to
retain the acoustic properties that a state of the art speaker
model considers most important. The small drop in accuracy
Over-the-Air, like in the case for Wit.ai, can be attributed to
environmental factors (e.g. background noise etc).
Kaldi-DNN is the only model that did not transcribe any
of the initial Over-the-Air attack audio samples successfully.
Upon further inspection, we realized that
the Kaldi-DNN
model was trained using the Fisher English Dataset [27]. We
believe that the audio training data does not contain enough
noisy audio. Therefore, when we introduce our own audio
artifacts, the attack fails. However, when choosing different
attack audio samples that are less perturbed, generated with
larger window sizes as input to PE, we can show that the model
transcribes them correctly. Failure of attack audio transcription
does not mean that the model is immune to the perturbation
attacks that we propose. Rather, it is possible the model is
simply less effective in noisy environments.
C. General Insights
Our preliminary results revealed insights about parameter
values that an attacker can use to reduce the attack generation
time. Accordingly, we have demonstrated our hypothesis to
hold for VPSes.
The experimental results show that perturbation parame-
ters, speciﬁcally window size (used for TDI and RPG), display
three important properties. First, the smaller the window size,
the greater the audible distortion. Second, if an attack audio
is successfully transcribed at a certain window size,
then
all attack audio samples that were generated with greater
window sizes are also successfully transcribed. Third, no
attack audio samples generated with window sizes of below
of 1.00 ms are correctly transcribed. This parameter creates
the approximate upper bound for maximum distortion. Attack
audio ﬁles generated with a smaller window size parameter
did not transcribe correctly by any of the VPSes from Table I.
Adversaries can use these three properties in conjunction to
narrow down the number of attack audio samples they want
to generate. Adversaries can start by setting the window size
to 1.00 ms, when passing the perturbation parameters into the
PE. They can increase the window size until they get the ﬁrst
attack audio that successfully transcribes.
Additionally, an audio sample can only be perturbed up to a
certain threshold before it is distorted beyond VPS recognition.
Attack audio samples that were generated with larger window
sizes could be sped up the most. If an attacker perturbs audio
by a single parameter’s lowest bound (e.g., window size of
1.00 ms), using additional perturbation parameters, like speed,
will reduce the likelihood of the audio being recognizable by
the VPS. Attackers can choose different parameter settings to
tune the attack audio to the victim and speciﬁc attack scenario
to maximize attack efﬁcacy. In our preliminary experiments
we observed the TS factor of 150%, RPG or TDI window size
of near 1.00 ms, and HFA of sine waves of frequency above
8000 Hz produced the ideal attack audio.
As discussed in Section IV-D2, the PE can be used to
generate a large set of attack audio samples for a single
phrase. Each audio sample has a different degree of audible
Fig. 5: The time and frequency domain representation of the original audio sample (TOP), the perturbed audio after being played
Over-the-Line (MIDDLE) and the perturbed audio after being played Over-the-Air (BOTTOM)
distortion. However, picking the single worst attack sample
is not straightforward, as there does not exist any widely
accepted metric to measure the degree of perceived audio
distortion. In our case, we identiﬁed the relationship between
the perturbation parameters and audio distortion. For TDI and
RPG, smaller window sizes correspond to greater distortion
and thus worse sounding audio. For HFA and TS, larger values
corresponded to worse sounding audio. These criteria allowed
us to narrow the space of 20,000 attack audio samples, that
we had generated previously, to less than ten. At this point,
the attacker can manually listen to the ten samples, and pick
the one that sounds the worst.
Some perturbations were more successful than others at
generating attack samples that the model could interpret. Of
the perturbations that we tested, RPG was less successful than
TDI. RPG requires us to take the FFT of the audio, followed
by an inverse FFT. As we treat the models as black-boxes,
we do not know the type or parameters (number of buckets)
of the FFT algorithm that the model employs. In contrast,
when using TDI, all the perturbations happen in the time
domain. During this perturbation, the audio is not converted
via a function like the FFT, though RPG did indeed work many
times. With additional information about the model, we believe
that the RPG mechanism could be tuned precisely; however,
our approach demonstrates that blackbox knowledge is more
than sufﬁcient to launch successful attacks.
Additionally, the TDI perturbation does not require that
the discontinuities align with the time frames of the feature
extraction algorithm. This assumption is buttressed by the
fact that perturbation schemes are successful against black-
box models. In the case of these models, we do not have any
information about the time frame discontinuities.
When attacking an online model, an adversary is limited
by the number of queries they can make. This could be either
due to cost associated per each query or due to threat of being
detected. That is why it is important that an adversary should
be able to generate attack audio with the least number of
queries possible. Our attack algorithm allows for exactly that.
An adversary can use the RPG or TDI methods to generate
ten attack audio samples, starting at the window size of 1.00
ms and using increments of 0.50 ms. We observe that it was
almost always the case that at least one of the generated audio
samples, is correctly interpreted by the VPS. In our case, we
were able to successfully ﬁnd an attack audio that worked for
proprietary models in less than ten queries to the model.
This paper includes the largest evaluation of an attack in
terms of number and variety of models attacked. Our model
list exceeds that of any other published work in the area of
adversarial audio by an order of magnitude. However, due to
the evolving landscape of ML, new models will be released
continuously. We show that the attack is sufﬁciently general-
ized by being effective on the existing, publicly available state-
of-the-art models. The attack is ‘universal’ in that it is designed
to work against any model by only targeting the feature ex-
traction phase. Intuitively, future models will be derived from
the same feature extraction techniques available in the public
domain. An additional obstacle lies in choosing a reasonable
amount of phrases to test against. Running experiments against
every phrase is intractable due to the amount of data ASRs are
normally trained on. Instead we constructed a list of phrases
that mirror the variety of real-world use cases.
VII. DISCUSSION
A. Improvements on Previous Work
Our audio perturbation methods make attack audio samples
difﬁcult for humans to interpret due to psychoacoustic prin-
10
Fig. 6: This ﬁgure displays an STFT of an audio ﬁle containing speech, Carlini’s perturbation of the audio ﬁle, our perturbation
of the audio ﬁle, and white noise. The lighter colors indicates a higher intensity at a given frequency and time. We can see that
Carlini’s perturbed audio has high intensities in lower frequencies and our perturbed audio has high intensities in the higher
frequencies.
ciples. Carlini et al. [24] proposed a method with a similar
goal to ours; however, their work adds background noise to
the audio. Because humans can better recover speech from
noise than our perturbations, our generated speech commands
are comparatively harder for humans to interpret. We reinforce
this claim both quantitatively and qualitatively.
High frequencies Figure 6 displays a Short-time Fourier
Transform (STFT) of original audio sample, white noise, and
both our and Carlini’s attack on this original audio sample.2
The STFT plot provides information about the intensity of
frequencies over time for each audio sample. The higher
the intensity, the lighter the color. By looking at these plots
we can see that the audio produced by Carlini et al. has
greater intensities in the lower frequencies than in the higher
frequencies. In contrast, our attack audio has greater intensities
across the spectrum.
Humans perceive loudness of audio on a logarithmic
scale [30], and higher frequencies are perceived as being
louder [15]. This increase in perceived relative volume will
2We are grateful to these authors, who willingly provided us with a small
number of attack and original samples
lead listeners to concentrate more on high frequency compo-
nents to the exclusion of low frequency components, which
are normally associated with speech. Increasing the volume
may also result in reaching the listener’s pain tolerance [43].
If the volume of the audio is decreased in order to hear the
higher frequencies at a comfortable level, the lower frequencies
become harder to hear.
The addition of higher frequencies in our attack audio also
reduces intelligibility due to the Cocktail Party Effect [26],
[33], [22]. This psychoacoustic phenomenon allows us to
focus on a conversation while ignoring other conversation
and background noise. By the similar concept of selective
attention [57], humans are more likely to properly interpret
speech that is more familiar to them (such as a friendly voice).
These familiar stimuli can cause a listener to switch their
attention to interpreting other speech.
Though normally seen as robust qualities of human hearing,
our attack audio capitalizes on these principles. The dominant
high frequencies in our attacks are above are in the typical
range of human speech [43]. When heard by a human, our
attack audio will most likely be considered background noise,
and thus ignored. Additionally, treating the audio as unimpor-
11
tant background noise will reduce the chance that the speech
will be a familiar stimuli and trigger a listener’s attention. The
high frequencies that exploit these psychoacoustic principles
will be ﬁltered out during the preprocessing stage of a VPS
and will still result in an accurate transcription.
Noise Though adding noise may seem like a reasonable