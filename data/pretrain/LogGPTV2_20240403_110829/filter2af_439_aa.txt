**Author：mengchen@Knownsec 404 Team**  
**Chinese version:**
## 1\. Introduction
I recently studied BlackHat's topic, and one of the topics - "HTTP Desync
Attacks: Smashing into the Cell Next Door" has caused me great interest. The
author talks about the HTTP smuggling attack and shares examples. I have never
heard of this kind of attack before, so I decided to carry out a complete
study of it, and this is why I wrote this article.
Please let me know if there is any mistake.
## 2\. TimeLine
In 2005, a report on the HTTP Request Smuggling attack was completed by Chaim
Linhart, Amit Klein, Ronen Heled and Steve Orrin. Through the analysis of the
entire RFC document and a rich example, they proved the harm of this attack
method.
> 
On 2016's DEFCON 24, @regilero enriched and expanded the attack methods in the
previous report on his topic, Hiding Wookiees in HTTP.
>
>  Hiding-Wookiees-In-Http.pdf>
At BlackHat USA 2019, James Kettle of PortSwigger gave a presentation on the
topic - HTTP Desync Attacks: Smashing into the Cell Next Door. In the current
network environment, he demonstrated using block coding to attack, extended
the attack surface, and proposed a complete set of detection and utilization
process.
>  smashing-into-the-cell-next-door-15153>
## 3\. Causes
The HTTP request smuggling attack is very special. It is not as intuitive as
other Web attack methods. In a complex network environment, different servers
implement different ways of implementing RFC standards. In this way, different
servers may generate different processing results for the same HTTP request,
which creates a security risk.
Before we proceed, let's take a look at the most widely used protocol feature
of `HTTP 1.1`\-- `Keep-Alive&Pipeline`.
In the protocol design before `HTTP1.0`, each time the client makes a HTTP
request, it needs to establish a TCP link with the server. The modern Web site
page is composed of a variety of resources. We need to obtain the content of a
web page, not only requesting HTML documents, but also various resources such
as JS, CSS, and images, so if we design according to the previous agreement.
Will cause the load overhead of the HTTP server to increase. So in `HTTP1.1`,
the two features of `Keep-Alive` and `Pipeline` have been added.
The so-called `Keep-Alive`, is to add a special request header `Connection:
Keep-Alive` in the HTTP request, tell the server, after receiving this HTTP
request, do not close the TCP link, followed by the same target server HTTP
Request, reuse this TCP link, so only need to perform a TCP handshake process,
which can reduce server overhead, save resources, and speed up access. Of
course, this feature is enabled by default in `HTTP1.1`.
With `Keep-Alive`, there will be a `Pipeline`, and the client can send its own
HTTP request like a pipeline without waiting for the response from the server.
After receiving the request, the server needs to follow the first-in first-out
mechanism, strictly correlate the request and response, and then send the
response to the client.
Nowadays, the browser does not enable `Pipeline` by default, but the general
server provides support for `Pipleline`.
In order to improve the user's browsing speed, improve the user experience,
and reduce the burden on the server, many websites use the CDN acceleration
service. The simplest acceleration service is to add a reverse proxy server
with caching function in front of the source station. When the user requests
some static resources, it can be obtained directly from the proxy server
without having to obtain it from the source server. This has a very typical
topology.
In general, TCP links are reused between the reverse proxy server and the
source server on the back end.It is also easy to understand that the user's
distribution range is very extensive, and the time to establish a connection
is also uncertain, so that TCP links are difficult to reuse, and the IP
addresses of the proxy server and the source server of the back-end are
relatively fixed, different users. Request to establish a link with the source
server through the proxy server, it is very easy to reuse the TCP link between
the two servers.
When we send a fuzzy HTTP request to the proxy server, because the
implementation of the two servers is different, the proxy server may consider
this to be a HTTP request and then forward it to the source server of the
back-end. However, after the source server is parsed, only part of it is a
normal request, and the remaining part is a smuggling request. When the part
affects the normal user's request, the HTTP smuggling attack is implemented.
### 3.1 GET Request with CL != 0
GET request is not the only one that get affected. I just use it as an example
because it is typical. All HTTP requests that do not carry the request body
may be affected by this.
In `RFC2616`, there is no provision for the GET request to carry the request
body like the POST request, and only one sentence is mentioned in section
4.3.1 of the latest document `RFC7231`.
> 
>
> sending a payload body on a GET request might cause some existing
> implementations to reject the request
Suppose the front-end proxy server allows the GET request to carry the request
body, and the back-end server does not allow the GET request to carry the
request body. It will directly ignore the `Content-Length` header in the GET
request and will not process it. This may lead to requests smuggling.
We construct the request
    GET / HTTP/1.1\r\n
    Host: example.com\r\n
    Content-Length: 44\r\n
    GET / secret HTTP/1.1\r\n
    Host: example.com\r\n
    \r\n
The front-end server receives the request by reading `Content-Length`, which
determines that this is a complete request and then forwards it to the back-end server. After the back-end server receives it, because it does not process
`Content-Length`, it thinks it is receiving two requests.
    First
    GET / HTTP/1.1\r\n
    Host: example.com\r\n
    Second
    GET / secret HTTP/1.1\r\n
    Host: example.com\r\n
This led to the request smuggling. In Section 4.3.1, there is an example
similar to it.
### 3.2 CL-CL
In the fourth clause of `3.3.3` of `RFC7230`, it is stated that when the
request received by the server contains two `Content-Length`, and the values
of the two are different, it needs to return 400 error.
> 
However, there are always servers that do not strictly implement the
specification. Suppose the intermediate proxy server and the back-end source
server do not return a 400 error when receiving a similar request. The
intermediate proxy server processes the request according to the value of the
first `Content-Length`, and the back-end source server processed according to
the value of the second `Content-Length`.
At this point the attacker can construct a special request.
    POST / HTTP/1.1\r\n
    Host: example.com\r\n
    Content-Length: 8\r\n
    Content-Length: 7\r\n
    12345\r\n
    a
The length of the data packet obtained by the intermediate proxy server is 8,
and then the entire data packet is forwarded to the source server of the back
end intact. The length of the packet obtained by the back-end server is 7.
After reading the first 7 characters, the back-end server considers that the
request has been read, and then generates a corresponding response and sends
it out. At this time, the buffer has one more letter `a` left. For the back-end server, this `a` is part of the next request, but it has not been
transferred yet. At this point, there is a other normal user requesting the
server, assuming the request is as shown.
    GET /index.html HTTP/1.1\r\n
    Host: example.com\r\n
As we also know from the previous, TCP connections are generally reused
between the proxy server and the source server.
At this time, the normal user's request is spliced to the back of the letter
`a`. When the back-end server receives it, the request it actually processes
is actually like this.
    aGET /index.html HTTP/1.1\r\n
    Host: example.com\r\n
At this time, the user will receive an error similar to `aGET request method
not found`.This implements a HTTP smuggling attack, and it also affects the
behavior of normal users, and can be extended to a CSRF-like attack.
However, the two request packages of `Content-Length` are still too
idealistic, and the general server will not accept such a request packet with
two request headers. In Section 4.4 of `RFC2616`, it is stated that: `If you
receive a request packet with both Content-Length and Transfer-Encoding
headers, you must ignore Content-Length during processing`. This actually
means that the request header contains both request headers is not a
violation, and the server does not need to return a `400` error. The
implementation of the server here is more prone to problems.
> 
### 3.3 CL-TE
The `CL-TE` means that when a request packet with two request headers is
received, the front-end proxy server only processes the request header of
`Content-Length`, and the back-end server complies with the provisions of
`RFC2616`, ignoring `Content -Length`, handles the request header of
`Transfer-Encoding`.
The chunk transfer data format is as follows, where the value of size is
represented by hexadecimal.
    [chunk size][\r\n][chunk data][\r\n][chunk size][\r\n][chunk data][\r\n][chunk size = 0][\r\n][\r\n]
Lab URL：
Constructing a packet
    POST / HTTP/1.1\r\n
    Host: ace01fcf1fd05faf80c21f8b00ea006b.web-security-academy.net\r\n
    User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:56.0) Gecko/20100101 Firefox/56.0\r\n
    Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\r\n
    Accept-Language: en-US,en;q=0.5\r\n
    Cookie: session=E9m1pnYfbvtMyEnTYSe5eijPDC04EVm3\r\n
    Connection: keep-alive\r\n
    Content-Length: 6\r\n
    Transfer-Encoding: chunked\r\n
    \r\n
    0\r\n
    \r\n
    G
The response can be obtained by sending the request several times in
succession.
Since the front-end server handles `Content-Length`, this request is a
complete request for it, and the length of the request body is 6, which is:
    0\r\n
    \r\n
    G
When the request packet is forwarded to the back-end server through the proxy
server, the back-end server processes `Transfer-Encoding`. When it reads
`0\r\n\r\n`, it will regard it has come to the end of it, leaving the letter
`G`in the buffer, waiting for the subsequent request to arrive. When we
repeatedly send the request, the sent request is stitched into the request
like this:
    GPOST / HTTP/1.1\r\n
    Host: ace01fcf1fd05faf80c21f8b00ea006b.web-security-academy.net\r\n
    ......
No wonder the server reported an error when parsing.
### 3.4 TE-CL
The `TE-CL` means that when a request packet with two request headers is
received, the front-end proxy server processes the request header of
`Transfer-Encoding`, and the back-end server processes the `Content-Length`
request header.
Lab URL：
Construct a packet:
    POST / HTTP/1.1\r\n
    Host: acf41f441edb9dc9806dca7b00000035.web-security-academy.net\r\n
    User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:56.0) Gecko/20100101 Firefox/56.0\r\n
    Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\r\n
    Accept-Language: en-US,en;q=0.5\r\n
    Cookie: session=3Eyiu83ZSygjzgAfyGPn8VdGbKw5ifew\r\n
    Content-Length: 4\r\n
    Transfer-Encoding: chunked\r\n
    \r\n
    12\r\n
    GPOST / HTTP/1.1\r\n
    \r\n
    0\r\n
    \r\n
Since the front-end server processes `Transfer-Encoding`, when it reads
`0\r\n\r\n`, it is considered to be read. At this time, the request is a
complete request to the proxy server. Then forwarded to the backend server.
The backend server processes the `Content-Length` request header. When it
reads `12\r\n`, it considers that the request has ended. It thinks that the
following data is another request, that is:
    GPOST / HTTP/1.1\r\n
    \r\n
    0\r\n
    \r\n
Successfully reported an error.
### 3.5 TE-TE
`TE-TE`, it is also easy to understand that when receiving a request packet
with two request headers, the front-end server processes the `Transfer-Encoding` request header, which is indeed the standard for implementing RFC
documents. However, the front and rear servers are not the same, but there is