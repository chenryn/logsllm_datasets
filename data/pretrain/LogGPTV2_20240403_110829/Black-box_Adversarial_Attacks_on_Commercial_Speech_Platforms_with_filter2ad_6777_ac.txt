formation. However, considering the query limitation in our attack,
we propose a greedy strategy to produce and update the collabora-
tive information in our attack design. More specifically, we do not
optimize these sub-problems concurrently. Instead, we optimize
them alternatively and iteratively. Therefore, when optimizing a
subproblem, we can evolve its values of the variables, which are
used to replace those related to the current subproblem in the best
solution, and generate a complete solution. The solution is further
evaluated by the objective function L(Â·) to locate a better solu-
tion. After the optimization of each subspace, the collaborative
information will be updated correspondingly. Since CC is a general
framework based on the divide-and-conquer strategy for solving
large-scale black-box optimization problems, it is generalizable to
other black-box methods that are also trapped in these problems,
and CC can also improve their effectiveness.
3.4.4 Adaptive Decomposition. The grouping strategy, which
determines how to assign variables to different groups, plays a
crucial role in CC. However, there is insufficient knowledge about
the correlations between variables, making manually devising or
choosing the most suitable grouping strategy extremely hard when
applying CC. Therefore, we propose an adaptive approach, which
puts several popular grouping strategies into a candidate pool, and
adaptively selects a proper decomposition strategy from it. The
candidate pool includes four grouping strategies: Static grouping
(SG), Random grouping (RG), Min-variance grouping (MiVG) and
Max-variance grouping (MaVG). We adopt SG to preserve the infor-
mation in the time domain, and RG [89] can help randomly allocate
variables to subspaces for improving the probability of placing two
interacting variables in the same subspace. Considering that the co-
variance matrix is used to model the local geometries of the search
directions, thus we adopt MiVG and MaVG, which are devised for
CC-CMA-ES. Actually, they can minimize or maximize the diversity
of the diagonal values of the variables in the same subspace. At
the beginning of each optimization cycle, we randomly select a
decomposition strategy. Based on its performance, we calculate the
selection probabilities of each grouping strategy for the next cycle.
We observe that the levels of interdependency among variables
in the audio vector will change significantly from the natural audio
to the audio AE during the optimization process [88]. Therefore,
we propose to adaptively adjust the group size to capture different
interdependency levels in the dynamic evolution process. Then,
we can make a good trade-off between the effectiveness and the
efficiency of the optimization. The details of the adaptive decompo-
sition algorithm can be seen in Appendix A.
3.4.5 Parameter Adjustment. Our algorithm contains many hyper-
parameters, such as ğ›¿, ğœ‡, ğœ†, ğ‘ğ‘, ğ‘ğ‘ğ‘œğ‘£ and ğ‘. Following [34], we set
ğ›¿ = 0.001 Â· ğ·(ğ‘¥âˆ—, ğ‘¥), ğ‘ğ‘ = 0.01, ğ‘ğ‘ğ‘œğ‘£ = 0.001 and ğ‘ = 15. We further
set ğœ† = 30 and ğœ‡ = 0.08, because ğœ‡ has an important impact on the
search process, we need to carefully tune ğœ‡. Finally, we adopt the
1/5th success rule [15] to update ğœ‡ as
(cid:40)1.5ğœ‡,
ğœ‡ =
1.5âˆ’1/4ğœ‡,
if a better solution is obtained,
otherwise.
(10)
4 NI-OCCAM: A NON-INTERACTIVE
PHYSICAL ATTACK AGAINST VOICE
CONTROL DEVICES
4.1 Threat Model
In this section, our target is commercial voice control devices. We
consider the most rigorous and practical assumption, called non-
interactive physical setting, where the adversary makes no query to
the oracle. Compared to prior physical attacks, the key advantage
of non-interactive physical attacks is that we do not need to query
the target devices for effective audio AE generation, thus saving the
potentially large query cost. In this sense, this attack is the most
practical one in the real world.
4.2 Technical Challenges
Compared to our decision-only adversarial attacks, non-interactive
black-box setting is much more challenging since it further breaks
the dependence on the final decision in the decision-only black-box
scenario. That is to say, the target model is completely unknown
to the adversary. Moreover, voice control devices also present ad-
ditional challenges that the constructed audio AEs should remain
robust even if they are played in the physical world. By physical
attacks against voice control devices, we mean that audio AEs are
played by a speaker and recorded by the device. Since the effective-
ness of audio AEs is greatly affected by the reverberation of the
environment, and perturbations from the speaker and the micro-
phone [75, 86], it is really difficult to launch physical attacks. These
two obstacles pose severe challenges to craft effective audio AEs.
4.3 Our Method
As described in our threat model, the adversary will not issue any
queries to probe the target model and obtain no feedback in the non-
interactive black-box setting. Thus, our Occam cannot be applied
in this case. Intuitively, it is almost impossible to directly construct
an audio adversarial example against the target model by solving
the optimization problem without any interaction. In fact, we are
facing the problem of generating AEs with no information during
the whole attacking process. In the image domain, there have been
works that demonstrated AEs crafted for the target model are able
to attack other unknown models, which is called the transferability
of AEs. However, in the audio domain, the poor transferability
of audio AEs [35, 90] among different ASR systems indicates that
we cannot directly leverage the transferability property especially
when there are no interactions with the target model.
Observing that the ultimate goal of speech recognition systems
is to perform the task of converting natural speech into text, we
Figure 6: The main architecture of the Kaldi model.
believe that the inclusion of the characteristics of natural command
audios in the constructed audio AEs may help improve their trans-
ferability. Inspired by model inversion attacks [29, 36, 94] that aim
to recover input data or its sensitive attributes via the model out-
put, we propose NI-Occam to craft audio AEs, where the command
voice is recreated and implicitly embedded in the original music
via the gradient update. The main reason behind is that it is hard
for people to perform speech separation on our constructed audio
AEs and further recognize the malicious speech commands.
Finally, audio AEs we constructed, just like natural command
audios, will remain robust in the over-the-air attack and naturally
effective in the physical world. Besides, compared to cloud speech
APIs, voice control devices are more vulnerable to audio AEs con-
taining command audios since they are more sensitive to voice com-
mands than speech APIs, which has been demonstrated in Devilâ€™s
Whisper [32]. Thus, we propose NI-Occam, which realizes non-
interactive physical attacks against voice control devices. Notably,
this is the first physical attack that can effectively create audio AEs
without any feedback information. Previous physical attacks, e.g.,
Devilâ€™s Whisper and FakeBob, rely much on returned scores to
generate effective audio AEs, while our attack is a non-interactive
one, i.e., requiring no access to the target devices.
Our proposed NI-Occam is presented in Alg. 2. To be specific, we
choose the open-source Kaldi model (ASpIRE Chain Model) as the
substitute model and the inversion model due to its simple structure
of the neural network and the excellent performance. In Figure 6,
it can be seen that the Kaldi model obtains MFCC feature through
feature extraction and takes these features as the input of DNN,
while the output of DNN is the probability density function (pdf).
According to the idea of â€œpdf-id sequence matchingâ€ proposed
in CommanderSong [90], we can recover the command audios
from their pdf-id sequences via the gradient inversion. Different
from model inversion attacks that start from the Gaussian noise
ğ‘§ âˆ¼ N(0, ğœ2), adversarial attacks start from the original example ğ‘¥.
Therefore, we add Gaussian noise ğ‘§ into the original example ğ‘¥ to
address this problem. The audio AEs can be described as
ğ‘ .ğ‘¡ .(cid:13)(cid:13)ğ‘¥ âˆ’ ğ‘¥âˆ—(cid:13)(cid:13)âˆ < ğœ–,
(11)
ğ‘¥âˆ— = arg min
ğ‘¥âˆ— J(ğ‘§ + ğ‘¥âˆ—, ğ‘¦)
where ğ‘¦ is the probability value of the target pdf-id sequence, J(Â·, Â·)
is the loss function [90]. Note that, the Gaussian noise ğ‘§ we added to
the original example ğ‘¥ is very large. This is to alleviate the impact
of the original example on the model inversion process. To facilitate
convergence, we gradually attenuate the size of Gaussian noise ğ‘§
in the iterative process. Besides, very recent works [83, 87] have
shown that the AdaBelief method [96] is beneficial to improve the
transferability of adversarial examples, so we use the AdaBelief
optimizer to solve Eq. (11). The details of implementation are: the
learning rate ğ›¼ is set to 0.003, the standard deviation ğœ is set to 0.25,
and the size of perturbation ğœ– is set to 0.3.
Algorithm 2 NI-Occam
Input: The original example ğ‘¥, the command audio ğ‘¥â€², the loss
function J(Â·, Â·), the Kaldi model ğ‘“ , the learning rate ğ›¼, the
standard deviation ğœ and the size of perturbation ğœ–.
Output: The produced audio adversarial examples.
1: Obtain the target pdf-id sequence ğ‘¦ through the Kaldi model ğ‘“
2: Initialize ğ‘¥âˆ— with ğ‘¥, ğ‘‹âˆ— with âˆ…, and the learning rate of the
and the command audio ğ‘¥â€²;
AdaBelief Optimizer with ğ›¼;
3: while not converged yet do
4:
5:
Sample ğ‘§ âˆ¼ N(0, ğœ2);
Use the AdaBelief Optimizer to minimize J(ğ‘§ + ğ‘¥âˆ—, ğ‘¦) and
update ğ‘¥âˆ—;
Clip ğ‘¥âˆ— into the ğœ– vicinity of ğ‘¥;
ğœ = 0.998 Ã— ğœ;
ğ‘‹âˆ— = ğ‘‹âˆ— âˆª ğ‘¥âˆ—;
6:
7:
8:
9: end while
10: return ğ‘‹âˆ—.
5 IMPLEMENTATION AND EVALUATIONS
5.1 Experiment Settings
Experiment Design. To evaluate the performance of Occam, i.e.,
our decision-only digital attacks on cloud speech APIs, we design
four sets of experiments: attacks on open-source ASR systems,
attacks on ASR services, attacks on SR services, and human percep-
tion of the audio AEs3. For the attacks on ASR services, we choose
ten frequently-used voice commands4 that are expected to be rec-
ognized by the target systems. The original audios are selected
from three datasets including Common Voice [8], Song [90], and
LibriSpeech [67]. We select ten test samples in each experiment to
evaluate the performance. To generate audio AEs, we need to query
the target commercial speech-to-text cloud services5 in Table 2
and get the final transcription in return according to our proposed
algorithms. To access the commercial cloud APIs, we first register
on the platforms and then use audio AEs to query the speech-to-
text services according to API keys provided by the platforms. For
the attacks against SR services, we conduct our targeted attack on
three systems (also in Table 2). For Microsoft SI and Jingdong SV,
we choose ten people from Voxceleb dataset [64] and enroll four
utterances for each person. Since Microsoft SV is text-dependent,
we collect five volunteersâ€™ voice data, and each volunteer is required
to enroll 10 fixed sentences. To generate AEs, we query the APIs
for 10,000 times for each target person.
To evaluate the performance of NI-Occam, i.e., our non-interactive
physical attacks on voice control devices, we design two sets of
experiments: attacks on popular commercial voice assistants and
human perception of the audio AEs. We evaluate NI-Occam on
Google Assistant, Apple Siri, Microsoft Cortana, iFlytek, and Ama-
zon Echo, as shown in Table 3. We generate 10 sets of audio AEs
locally, whose target phrases of AEs are the same as those in the
3The evaluations of attacks on open-source ASR systems and human perception are
presented in Appendixes D.1 and D.3, respectively
4The target transcripts include call my wife, make it warmer, navigate to my home,
open the door, open the website, play music, send a text, take a picture, turn off the light,
and turn on the airplane mode.
5Details on the datasets, target systems, and hardware are given in Appendix C.
DNNHCLGSpeechTextFeatureextractionTable 2: Details of the commercial speech and speaker recog-
nition services.
Commercial Services
Return results
Task
Speech
Recognition
Speaker
Recognition
Google STTâ€¡ [5]
Microsoft ASR [6]
Alibaba SSRÂ§ [11]
Tencent SSR [10]
iFlytek [3]
Microsoft SIâ™¯ [6]
Microsoft SVâ€  [6]
Jingdong SV [9]
Dâ™­+Sâ™®
D+S
D
D
D
D+S
D+S
D
Note that, (i) â€¡: â€œSTTâ€ means â€œSpeech-to-Textâ€. We use the command_and_search
model in Google STT API. (ii) Â§: â€œSSR" means â€œShort Speech Recognitionâ€. (iii) â™¯: â€œSIâ€
means â€œSpeaker Identificationâ€. (iv) â€ : â€œSVâ€ means â€œSpeaker Verificationâ€. (v) â™­: â€œDâ€
means the model returns the final decision. (vi) â™®: â€œSâ€ means the model returns the
confidence score or confidence level.
Table 3: Details of the commercial voice control devices.
Voice
Assistant
Apple Siri
iFlytek
Microsoft
Cortana
Google
Assistant
Amazon
Echo
Version
13.6.1
10.0.8
3.3.3
2.5.1
631499520
Device
iPhone 11
iPhone 11
Samsung
C9
Nokia
7plus
Echo
1st gen
Audio
Source
Speaker
Default
media
player,
ThinkPad
X1 Carbon
JBL Clip3
evaluation of Occam. We then play them using a JBL Clip 3 portable
speaker near the target devices in a quite laboratory. The distance
between the speaker and the target devices is around 15cm.
Methods for Comparison. We compare Occam with two state-
of-the-art black-box adversarial attacks against ASR and SR ser-
vices, i.e., Devilâ€™s Whisper [32] and FakeBob [26]. Since Devilâ€™s
Whisper originally utilized confidence scores to filter the synthetic
audio data, in the follow-up evaluations, we omit this step to adapt
Devilâ€™s Whisper to the decision-based attack. To better evaluate the
effectiveness of Occam, we also select five decision-based attacks
for comparison: the boundary attack [21], the HopSkipJump attack
(HSJA) [27], the opt-attack [33], the evolutionary attack6 [34], and
the Differential Evolution attack (DEA)7 [68].
We compare NI-Occam with a straightforward non-interactive
attack, i.e., the superposition attack. In this attack, we just directly
superimpose the original example and the command audio. Since
this procedure does not require any knowledge of the target sys-
tems, the superposition attack is non-interactive.
Evaluation Metrics. We use the success rate of attack (SRoA) to
evaluate the effectiveness of AEs. SRoA calculates the proportion
of AEs that can successfully attack ASR or SR services. Besides,
we use SNR8 to describe the perturbation on audio AEs and the
number of queries on the target model to indicate the efficiency of
the attacks. It is worth noting that the success rate or the SNR is not
the only metric that determines whether an AE can successfully
6In our experiments, the bilinear interpolation in the evolutionary attack is removed
in the audio domain as it is not applicable to the time-series speech data.
7We give a detailed description on DEA in Appendix B.
8SNR calculates the ratio of the signal power of the original audio to the noise power.
A higher SNR indicates a lower noise level.
attack the target system. An effective AE should fool both the model
and the human. Hence, we should combine both the SRoA and SNR
when evaluating the effectiveness of AEs. Note that, to illustrate
this statement, we conduct a user study to analyze how SNRs affect
the human perception. The results show that a lower SNR makes it
easier for the users to notice or even recognize the AEs. Due to the
space limit, we present the detailed results in Appendix E.
5.2 Evaluation on Cloud Speech APIs
Effectiveness of Occam on ASR services. Table 4 shows the per-
formance of the targeted attacks on different commercial speech
services after 30,000 queries (10,000 queries on Google). With regard
to SNR, Occam performs the best among the seven attacks, reaching
the best SNR of 17.84dB. Notably, DEA only obtains an average SNR
of 6.37dB, which means that the perturbations of the audio AEs
are very large. The results demonstrate that as the gradient-free
optimization method in Occamâ€™s cooperative co-evolution frame-
work, CMA-ES is a better choice than the differential evolution. The
reason behind this may be that CMA-ES is more suitable than DEA
to solve the non-separable optimization, since CMA can well learn
the dependencies between variables. However, the average SNR of
AEs generated by the evolutionary attack (which is based solely on
CMA-ES) can only achieve 7.11dB, while Occam has an average SNR
of 14.37dB. This indicates that although CMA-ES can solve the non-
separable optimization problem, when regarding to complex speech
data, CMA-ES becomes ineffective to solve the discontinuous large-
scale global optimization problem. Hence, CMA-ES alone cannot
deal with complex speech data well. The above results demonstrate
that Occam can effectively manage high-dimensional audio data.
Compared to Devilâ€™s Whisper, Occam can achieve 100% SRoAs on
all API services, while Devilâ€™s Whisper can only achieve an average
SRoA of 54%. This indicates that Devilâ€™s Whisper is less effective in
fooling the target speech recognition model than Occam. Figure 10
in Appendix D.2 shows the waveforms and spectrograms of the
original audio and the adversarial audios generated from Occam
and Devilâ€™s Whisper. We can see from the waveforms that the audio
AE generated from Occam is almost the same as the original audio.
However, the differences in Devilâ€™s Whisper are more noticeable and
thus more likely to be perceived by humans. Besides, although we
only choose ten commands in the experiments, Occam can generate
AEs of arbitrary phrases9, while Devilâ€™s Whisper can only generate
a limited number of target phrases with a trained model. These
observations suggest our decision-based Occam is more effective,
powerful, and practical. We also evaluate the untargeted attacks.
Due to space limitation, related results are given in Appendix D.2.
Effectiveness of Occam on SR services. We evaluate the SNRs
and SRoAs of the AEs against SR services, as in Table 5. Among
the attacks against SR services, Occam still achieves 100% SRoAs,
indicating that the audio AEs can be successfully recognized as the
target person (or mislead the SR system). FakeBob can only achieve
a 1% SRoA. Note that we tested FakeBob with 200 instead of 10
AEs. Since the success rate of FakeBob is too low, we enlarge the
AE set to create an effective AE. We find that the results given by
FakeBob are higher than those in Table 5. This is probably because
9To illustrate this, we further evaluate Occam on a large group of target phrases.
Related results are presented in Appendix G.
Table 4: Experimental results on targeted attacks on commercial cloud speech-to-text APIs.
Boundary
Attack
Cloud service
SRoA
10/10