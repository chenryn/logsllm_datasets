Section 4) but this will not aﬀect substantially the analysis
we present here (and in fact we drop this assumption in the
system of section 3.2)
Given our assumption that deep fades are uniformly dis-
tributed within the time interval (and assuming for now that
t and k are ﬁxed constants, and n ≥ 2kt), the entropy En,t,k
of the string ρA will be at least:
En,t,k ≥ log2
(n − k + 1 − (l − 1)(2k − 1)) − log2(t!)
l=1
where the product above denotes the number of ways to ar-
range t runs of length k within a bitstring of length k where
the subtraction of the t! is due to the fact that the order of
the placement of such runs is of no importance. Now ob-
serve that for the multifactorial function m!(v) = m(m −
v)(m − 2v) . . . it holds that: vbm/vc(bm/vc)! ≤ m!(v) ≤
vbm/vc+1(bm/vc + 1)!. Based on this, we obtain
bm/vc−t(bm/vc − t)!)/t!)
En,t,k ≥ log2(v
for m = n − k + 1, v = 2k − 1. Next, from Stirling’s
2πnn+1/2e−n+1/(12n+1) 
1
e
(
q
q − w
)q+1/2(
q − w
e
)w
tY
. Using this we obtain:
En,t,k > log2
where
α =
and
(2k − 1)t
”
“ 1
”b(n−k+1)/(2k−1)c+1/2
· α · β
e
t!
“ b n−k+1
2k−1 c
2k−1 c − t
b n−k+1
“b n−k+1
2k−1 c − t
β =
e
”t
.
Based on the above the following theorem is proved:
Theorem 3.3. It holds that
En,t,k = Ω(t log k + (n/k) log(n/(n − kt)) + t log(n/k − t))
Notice that t and n/k are the dominant asymptotic terms
that control the amount of entropy of En,t,k.
In order to achieve agreement between the two parties,
we take advantage of the fact that the runs of ρA and ρB
may be diﬀerent only in the beginning and ending bits of
a deep fade. Suppose that s is a parameter that speciﬁes
Figure 3: A representation of direct key genera-
tion by searching all possible keys.
the maximum number of bits that can be diﬀerent on either
side of a run between ρA and ρB. Recall that we assume
that the sender has t runs of length k. Now suppose that
for some parameter s it holds that k > 2s, and when ρB is
sampled each run may be extended to the left or right by
a number between zero and s bits. This suggests that if a
run is observed in the interval [f, g] by the sender it holds
that there exist r, l ∈ {−s, . . . , s} such that the receiver
observes the same run at locations [f + l, g + r] and the
length of this run is also k, i.e., r − l = k + f − g − 1.
The total number of pairs (r, l) that satisfy the constraint is
2s + 1, so for each run the receiver has a number of 2s + 1
possibilities. Given that there are t runs we have that, the
total space of errors includes at most (2s + 1)t vectors; see
ﬁgure 3. For reasonably small values of s, t this means that
it is possible for the receiver to scan through all possibilities
and recover the exact bitstring that was obtained by the
sender. Note that keeping t small will not necessarily make
the entropy of the channel too low as we can still rely on
the value of n/k to maintain it at a safely high level for
cryptographic key generation cf. theorem 3.3. We remark
that the analysis when there is small variation in k from
one run to the other follows a similar approach. From this
discussion, it follows that the receiver will require some “key
veriﬁcation information” so that it is assisted in ﬁnding the
correct match.
Given the above, the key-generation algorithm will oper-
ate as follows:
(1) the sender and receiver will sample ρA and ρB, respec-
tively;
(2) the sender then, will calculate the key and send a key
veriﬁcation information (KVI) to the receiver;
(3) based on KVI the receiver decides on the correct key
by scanning through all possible error-vectors.
The key veriﬁcation information submitted to the receiver
is obtained by computing a value of the form hµ, κ,Uκ(key)i
where µ, κ are selected at random from a ﬁxed bitstring
size and U is a keyed hash function to be speciﬁed below
in theorem 3.4; ﬁnally, key is computed as key = H(µ, ρA)
where H is a hash function to be speciﬁed below in theorem
3.4. The receiver, using ρB, tries all (2s + 1)t modiﬁcations
and attempts to match the Uκ value using hi = H(µ, ρi
B) as
the key where i = 1, . . . , (2s + 1)t and ρi
B is the i-th possible
version of ρB. If there is a match, the search stops and the
receiver sets his key as hi.
Suppose now that the adversary, through knowledge of
the statistics of the channel, deduces the average number of
deep fades t as well as their average length, k — he cannot
know their locations. We show the following:
senderreceiver00111110001111100000111100011111parameters : n = 16, t = 2, s = 2, k = 500001111000111114 possible placements of a 5-bit run in this range Theorem 3.4. Assume the following three conditions:
1. Suppose key 6= key0 ∈ {0, 1}l0 , then it holds
Prob[Uκ(key) = Uκ(key0)] ≤ 2 where κ is distributed
uniformly over {0, 1}k.
In other words, {Uκ}κ is a
universal hash family.
2. H : R × {0, 1}n → {0, 1}l0 satisﬁes that the random
variable (µ,H(µ, w)) has 1 statistical distance from
(µ, u) that is uniformly distributed over R × {0, 1}l0
and w distributed according to RA conditioned on RC .
In other words, H is an hn, l0, 2i-extractor for the
source RA conditioned on RC .
3. The probabilistic map F(w) = (κ,Uκ(w)) with κ uni-
formly distributed, hides all functions of its input,
i.e., for every PPT A there is a PPT A0 such that
for any f , Prob[A(F(w)) = f (w)] − Prob[A0(1n) =
f (w)]| ≤ 3 where w is uniformly distributed over {0, 1}n.
Given the above, it holds that KG described above is a
(n, l0, 1, 2, 2 + 3)-key-generation-system.
The above theorem suggests that we can construct a key-
generation system as long as the functions H and U satisfy
the stated properties. First, U has to be a universal hash
function family [11, 34]. Second H must be an extractor
for the source RA, i.e., given the random variable ρA that
is distributed according to the triple hρA, ρB, ρCi from Env,
it holds that H(µ, ρA) is 2 away from the uniform distri-
bution of {0, 1}l0 . This needs to happen conditioned on
RC as prescribed in the distribution of Env. To implement
this function we can use a general purpose extractor that
can be constructed based on universal hash functions; this a
standard construction that also applies to the case of condi-
tional entropy as shown in [17]. In this case it will hold that
l0 = En,k,t + 2 − 2 log 
−1
2 where En,k,t is the entropy func-
tion deﬁned in theorem 3.3. Finally regarding security, the
function U needs to additionally (to being a universal hash)
to also hide all functions of its input, (this is possible as e.g.,
described in [15]). We note that it would also be possible to
“throw away” the bits of key that are ﬁxed by Uκ(key) and
use the remaining bits; this would improve security but it
would reduce the eﬃciency of the scheme (as we would need
to extract more bits).
To illustrate the feasibility of the approach, we provide the
details of an (ad-hoc) implementation of the construction:
Example Implementation. As seen from the arguments
leading to Theorem 3.3, we have that for k = 5, t = 12, n =
512 it holds that the conditional entropy of ρA given ρC is
at least 77 bits. Using a universal hash family for H we
can obtain a 55-bit key that is 2−12 away from the uniform
distribution over {0, 1}55. In order for the receiver to recover
this key for s = 2, it will have to execute a brute-force step
of 224 operations, where each one involves one application
of the universal hash family H(ν,·) and one application of
the universal-one-way hash Uκ(·). If H is substituted with
a universal hash of comparable time complexity to that of
MD5 and U is substituted with a universal one-way hash
family comparable to an HMAC, we have that the key can
be recovered in at most 42 seconds in a standard laptop3.
3Based on openssl benchmarks on a Macbook Pro that per-
forms: (i) 2043780 HMAC(MD5) operations in 2.98 seconds,
(ii) 2673300 MD5 operations in 2.98 seconds.
3.2 Key generation using Secure Fuzzy
Information Reconciliators
The solution of the previous section has the major short-
coming that the brute-force error-correcting step requires
too much time to be completed, thus making the protocol
ineﬃcient. Moreover, in the analysis we assumed that the
length of each deep fade is the same. In this section we re-
move these two restrictions by presenting a key-generation
system that relies on secure fuzzy information reconcilia-
tors (SFIR), a primitive we introduce here. We will show
how SFIR can be instantiated and using such primitive we
will present a key generation system that will enable very
fast error-correction that is unconditionally secure; more-
over, our approach in this section will work independently
of the lengths of the deep fades. The beneﬁts of the approach
will come at the expense of sacriﬁcing some additional bits
of entropy.
We recall that a fuzzy extractor [14] is similar to a ran-
domness extractor but it has a built-in error-correcting capa-
bility: any value of an imperfect random source that belongs
to a sphere of a certain ﬁxed radius for a given metric can be
repaired to the same identical randomness extraction (given
some helping information).
Below we deﬁne a variation of the fuzzy extractor prim-
itive that is more suitable to our setting (to be explained
below). We call our primitive a “secure fuzzy information
reconciliator” or SFIR.
Definition 3.5. Let Env = hρA, ρB, ρCi be a joint ran-
dom variable over {0, 1}3n. A (n, l0, 1, 2)-secure-fuzzy-infor-
mation-reconciliator (SFIR) for Env is a pair (Gen, Rep) that
satisﬁes the following: (1) if hf, pi ← Gen(ρA), then it holds
that Prob[Rep(ρB, p) = f ] ≥ 1− 1. (2) the ﬁrst output f of
Gen is 2 away from the uniform distribution over {0, 1}l0
conditioned on ρC as well as the second output p of Gen.
The goal of this section is to design a SFIR scheme and
then employ it to design a key agreement system, that will
enable the sender and the receiver to recover the same key,
key = f , even if they have slight discrepancies in their bit-
vectors due to interference. Note that the deﬁnition of a
fuzzy-extractor as given in [14] would not be a good match
for our setting as we have a-priori knowledge about the
error-distribution and it is unnecessary to mandate the min-
entropy requirement as it is the case for a fuzzy extractor.
Moreover, the metrics considered in [14, 17] are not suitable
for our setting: the type of errors considered there, such as
those that correspond to the Hamming or edit distance are
more suitable for general error-correction of biometric key
extraction, [14]. On the other hand, here, we need to cor-
rect a diﬀerent class of errors that correspond to the shifts
present in the runs within one of the two bitstrings (rela-
tive to the other). Finally, note that we need to incorporate
a type of security into the deﬁnition of SFIR (hence the
“secure” designation) : we require that the reconciliation in-
formation p still leaves suﬃcient entropy in ρA to extract
a random key despite that the adersary knows additionally
the correlated information ρC ; we note that it is possible to
deﬁne security in a more general way but this deﬁnition will
be suﬃcient for our purposes now.
Our construction. The interpretation of the random vari-
able that is produced by the envelope that will be used in this
section is as follows: given the random pattern ρ, one of the
two parties (generically called the sender), records the val-
ues {‘1, . . . , ‘t} ⊆ {1, . . . , L} which are the locations of the
deep fades within the L time slots. Note that ‘i ∈ {0, 1}u
with u = dlog Le.
Our SFIR hGen, Repi uses an error-correction parameter s
and operates as follows. Gen given ρA, computes the values
loc = {‘1, . . . , ‘t} and then calculates the tuple h˜‘1, . . . , ˜‘ti
where ˜‘j = ‘j mod (2s + 1). Then, Gen simply selects µ
to seed an extractor H and produces the output (f, p) =
(H(µ, ρA), (µ,h˜‘1, . . . , ˜‘ti); note that ρA is based on ρA but
it is normalized so that all its runs are of length k where
k is some ﬁxed parameter (and thus note that ρA is not
necessarily of length n); as we will see later this will not
prohibit the reconstruction of ρA by the other transceiver.
The function Rep operates as follows: it receives as input
ρB as well as the value p = (µ,h˜‘1, . . . , ˜‘ti). The receiver will
parse ρB for the locations of the deep fades and will ﬁnd their
t} ⊆ {1, . . . , n}. It wil then attempt to
locations {‘0
correct to the original locations ‘1, . . . , ‘t by computing
1, . . . , ‘0
∗
j = ‘
j − (‘
0
0
j mod (2s + 1)) + ˜‘j
‘
Subsequently, Rep calculates a bitstring ρ∗ with t runs of
t . Then, Rep will feed µ, ρ∗ into
length k at locations ‘∗
1, . . . , ‘∗
the extractor H and will terminate returning f∗ = H(µ, ρ∗).
Observe that as long as |‘j−‘0
j| ≤ s then it holds that ‘∗
j = ‘j
and thus ρ∗ = ρA and thus key agreement is achieved.
Lemma 3.6. The average min-entropy ˜H(ρA | ρC , p) where
p is deﬁned from hf, pi ← Gen(ρA) is at least Dn,t,s =
´ − tdlog(2s + 1)e.
log`n
t
We remark that it is also possible to drop the least sig-
niﬁcant bit information from the fade locations to achieve
agreement on a joint bitstring (so in this case the coordina-
tion information p would only need to agree on how many