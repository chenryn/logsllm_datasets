limit overall memory consumption when a large number of
threads is running in the kernel in parallel, and each thread
has its own kernel stack. Because of the limited stack size,
storing large variables on the kernel stack and creating long call
chains in the kernel space is discouraged. To ensure that the
stack depth is shallow enough to avoid a stack overflow, Linux
provides the checkstack.pl tool for static analysis of the stack.
Although the small size of the Linux kernel stack improves the
success rate of a stack-spraying attack, the shallow stack depth
(or the lack of loops and recursions) limits the spraying range.
Besides normal thread stacks, Linux also has other specialized
stack types. For example, while debug stacks are used for
hardware (interrupt1) and software (INT3) debug interrupts,
interrupt stacks are used for external hardware interrupts or
for processing software interrupts. Since these stacks do not
accept user-controlled data, we do not take them into account
and instead focus on normal per-thread kernel stacks that are
used when syscalls are issued.
C. Stack Usage of Syscalls
The more frequently a stack region is used, the more likely
an uninitialized variable will reside in this region. Therefore,
taking control over frequently used memory regions increases
the success rate of an uninitialized-use attack. We hence analyze
stack usage of syscalls to understand which portions of the
kernel stack are most frequently used.
To profile stack usage of syscalls, we use kprobes to
intercept syscall enters and returns, and scan the stack memory
to check maximum stack usage of these syscalls. Specifically,
upon syscall enter, we zero out the stack memory and continue
the normal execution; upon syscall return, we scan the stack
memory from stack top (i.e., the lowest stack address) until
we find the first non-zero byte. We conservatively treat the
offset of the first non-zero byte into stack base (i.e., the value
of stack pointer upon syscall entry) as the maximum stack
usage of the syscall. We use the Trinity fuzzer to invoke all
50010001500200025003000350040004500Stack usage (byte)01234567Number of syscalls in percentage (%)90% syscalls use <1,260 bytesStack Usage of Syscalls in the Linux Kernelsyscalls to obtain stack usage for all syscalls. Because Trinity
usually takes a long time to explore a syscall or even just
does not terminate, we set five-second timeout for fuzzing each
syscall. Figure 2 summarizes the maximum stack usage for all
syscalls. In particular, we find that (1) the average stack usage
of syscalls is less than 1,000 bytes (aligned to the stack base at
high address) and (2) 90% syscalls use only the highest 1,260
bytes on the stack. It is important to note that the stack usage
represents the maximum stack region a syscall uses. Assuming
stack objects are uniformly distributed in stack regions used by
syscalls, we find that the average location of stack objects is
510 bytes into the stack base and more than 90% stack objects
are allocated in the highest 960-byte stack region. Therefore,
the highest 1KB stack region is frequently used and thus is the
primary target of our spraying.
III. THE TARGETED STACK-SPRAYING APPROACH
The main challenge in exploiting uninitialized uses is
to control data in the uninitialized memory. By planting
malicious pointers in the target memory, an uninitialized pointer
dereference can be turned into arbitrary memory read/write
or code execution. However, unlike heap spraying, in which
the number and the size of allocated heap objects are user-
controlled, stack spraying has the additional problem of stack
objects usually being static and fixed in size. The placement
of the Linux thread_info structure, at the stack top, requires
the stack size to be limited; otherwise, stack buffer overflows
may occur. In addition, kernel space is shared by all threads.
Not limiting the size of stack will easily exhaust memory.
Therefore, Linux kernel developers are encouraged to use
the script (scripts/checkstack.pl) to statically analyze stack
usage. The script in particular checks the stack usage (in byte)
of each function so that developers can find functions that use
too much stack memory. Because of these features—the limited
stack size, the static and fixed-size stack objects, and the stack
usage check, a targeted stack-spraying attack is significantly
more difficult than a heap-spraying attack.
To enable a targeted stack-spraying attack in the kernel
space, we need to prepare malicious data in a specific location
of the kernel stack in the presence of aforementioned difficulties.
Specifically, the location itself needs to be chosen in such a
way that the uninitialized memory will overlap the prepared
data. In general, we can store malicious data in such a location
in two ways: (1) finding an execution path that prepares data
overlapping that of the vulnerability and (2) finding a way to
guide the kernel to allocate stacks on the memory pages with
prepared data. The first method is deterministic: Once such a
path and its triggering inputs are found, we can deterministically
write arbitrary data at the specified location. Since the data
is saved at the target location by normal execution paths, this
method is stealthy and hard to detect. By contrast, the second
method affects the stack allocation of another process/thread
by exhausting memory, which can be reliable but not fully
deterministic. This method can achieve broad control because
the overlapping is at page level. However, since the creation
of a new process/thread executes kernel functions that use the
kernel stack, a portion (near the stack base) of the prepared data
will be overwritten. As a result, the second method loses control
of the stack region at high address. As mentioned in §II-C, our
primary spraying target is the highest 1KB stack region. To
control this region, we have to use the first method. For these
Fig. 3: Overview of the architecture of our deterministic stack spraying
technique that consists of three components. It automatically analyzes
all syscalls and outputs results, including which range of the stack
we can control and how to control the stack.
reasons, we combine both methods so that attackers can achieve
reliable or even deterministic control over a broad stack region.
In this section, we present an overview of both methods.
A. Deterministic Stack Spraying
We design the deterministic stack spraying technique, which
finds an execution path that prepares data overlapping that of
an uninitialized variable. The main challenge of deterministic
stack spraying is to find a syscall with specific parameters
that will trigger an overlapping execution path. An overview
of the technique used for the attack is shown in Figure 3.
The technique consists of three components: a symbolic
execution engine, a guided fuzzer, and a coordinator that handles
communication between the symbolic execution engine and the
guided fuzzer. The goal of the symbolic execution engine is to
explore as many execution paths as possible to find one that
saves user-controlled data on that stack, which will overlap an
uninitialized variable. However, symbolic execution is prone
to the path explosion problem because of that the number of
feasible paths in a program can be infinite when the program
contains unbounded loop iterations. A possible solution for
this problem is to use heuristics for either path-finding or
concretizing the loop condition. To achieve high coverage
in path exploration, we follow the second method: During
symbolic execution, we concretize the loop conditions and at
the same time, identify loops and their symbolic conditions,
and then let the fuzzer selectively explore these loops. To verify
whether a syscall can actually save arbitrary data on the kernel
stack, our guided fuzzer replaces the non-controlling parameters
(that are confirmed not to affect execution paths during symbolic
execution) with a magic code. When the syscall returns, we use
kprobes to intercept the execution and scan the kernel stack to
check which ranges of the stack memory have been polluted
by magic code. These ranges are those we can control.
B. Exhaustive Memory Spraying
The exhaustive memory spraying technique guides the stack
allocation of a new process or thread so that the memory
pages used by the stack overlap those with prepared data.
The main challenge of such a technique is to improve the
reliability of the overlapping. To overcome this challenge, we
design a strategy that reliably controls the memory of the
4
Symbolic ExecutionEngine(Exploring paths)Deterministic Stack SprayingGuided Fuzzer(Verifying spraying)Coordinator(Scheduling and bookkeeping)Concrete parameters and loop informationSpraying ranges and trigger inputsStartpointkernel stack. Specifically, our exhaustive memory spraying
technique includes two steps: (1) occupying the majority of
memory in the target machine and (2) polluting all the available
remaining memory with malicious data (for uninitialized
variables). Memory occupation forces the kernel to use the
remaining memory, which is small, for the newly allocated
kernel stacks. Because the remaining memory is small, the
pollution operation can be done quickly and effectively. Once
we ensure that almost all available memory is polluted by
malicious data, the memory of the newly allocated stacks will
contain the malicious data. Note that in the kernel space, the
kernel does not zero out the allocated memory pages, so the
malicious data will not be cleared.
IV. DESIGN
In this section, we discuss design choices we made for both
deterministic stack spraying and exhaustive memory spraying.
A. Deterministic Stack Spraying
Our primary spraying goal is to deterministically control
the frequently used stack region (the highest 1KB stack region),
which is likely used by uninitialized variables. To this end, we
need to find a suitable syscall and set its parameters such that
its execution will write the data in the location, and to verify
that the data is retained after the syscall returns. We design the
deterministic stack spraying technique, which includes three
parts: symbolic execution that explores execution paths, guided
fuzzing that verifies spraying, and coordination that safely runs
symbolic execution and guided fuzzing in parallel.
1) Symbolic Execution of Syscalls: To find syscalls for
deterministic stack control, we need to iterate over possible
execution paths of syscalls as completely as possible and
generate the concrete parameters that
trigger these paths.
Since symbolic execution can explore execution paths in a
target program and generate concrete inputs to trigger the
respective paths, it is an ideal tool for our purpose. For each
syscall, we use symbolic execution to iterate over its execution
paths and generate concrete inputs that we can then use to
verify if an execution path saves data in a target location on
the kernel stack. To symbolically execute the Linux kernel,
we can adopt two widely used symbolic execution engines,
KLEE [7] and S2E [11], both of which are capable of handling
C/C++ programs. KLEE is built on top of the LLVM compiler
infrastructure while S2E is based on QEMU, which enables S2E
to do full-system symbolic execution. Moreover, compared to
KLEE, S2E can perform analyses in-vivo within a real software
stack (e.g., user programs, libraries, kernel, and drivers) instead
of using abstract models of these layers. Even more importantly,
S2E supports binaries and employs the selective symbolic
execution mechanism to boost performance. Considering these
features, we choose S2E as our symbolic execution engine.
Automatic generation of test cases. Since S2E does not
automatically decide which variables should be symbolized, it
requires as input not only the program to be tested but also a
list of variables it should replace with symbolic values. In our
case, we have to explicitly tell S2E which buffers, including
their address and size, to symbolize. As an example, Figure 4
shows how to symbolically execute the open syscall. Using the
s2e_make_symbolic feature, we explicitly tell S2E to symbolize
1 char pathname[PATH_SIZE];
2 int flags = O_RDWR;
3
4 s2e_enable_forking();
5 /* symbolize the
6 s2e_make_symbolic(pathname, PATH_SIZE, "pathname");
7
8 /* symbolically execute the open syscall */
9 int res = open(pathname, flags);
10
11 s2e_disable_forking();
12 s2e_kill_state(0, "program terminated");
pathname parameter */
Fig. 4: This example shows how to symbolically execute the open
syscall in s2E. Here, we symbolize only the pathname parameter but
not the flag parameter. s2e_enable_forking is a S2E feature that
enables parallel execution upon branches.
the pathname parameter by specifying the pointer of pathname
and its size (i.e., PATH_SIZE).
Given that current Linux kernel has about 300 syscalls
and many of which have up to six parameters, manually
writing test cases would be highly time-consuming and therefore
impractical. Therefore, we opted for an automatic approach to
generate test cases used as input for S2E. However, automatic
test case generation entails two challenges: (1) Some syscalls
depend on other syscalls and therefore have to be called in a
proper order. For example, read/write syscalls cannot be called
before the open syscall; and (2) for pointer-type parameters,
we are usually unable to specify the size of the buffer referred
to by the pointer. To overcome the first challenge, we rely
on the Linux Test Project (LTP) because it properly sets up
execution conditions for each syscall. For the second challenge,
we observe that execution paths (i.e., control flows of the
syscall) are often independent of the number of elements located
by pointer-type parameters and thus the size of the respective
buffer. Therefore, for symbolic execution, we conservatively
assume pointer-type parameters always point to a single element,
but later, we will use the guided fuzzer to explore the syscall
with more elements (see §IV-A2). Apart from these challenges,
the automatic test case generation is intuitive: We generate
the C source code that iteratively symbolizes each parameter
using the syscall definition with type information of parameters.
The syscall definition itself is directly derived from the Linux
kernel source code.
Path Exploration. When running the QEMU virtual machine
in the S2E mode, executing a test case will automatically trigger
symbolic execution. During this phase, each program state
represents an execution path. Whenever a state is terminated,
i.e., execution of a path is finished, we tell S2E to generate and
output sample parameters that trigger this execution path. These
sample parameters are then passed to the guided fuzzer for
further verification described in §IV-A2. Since the verification
process relies on the presence of magic code, which is stored
on the stack using syscall parameters, S2E needs to tell the
fuzzer which parameters can be replaced by magic code and
which need to take on a sample value. The criterion used to
distinguish these two types of parameter is their relevance to the
control flow of the program: If a parameter is used in a control-
flow relevant condition, i.e., it affects the execution path of the
program, it is considered a controlling parameter, and thus the
fuzzer uses a sample value for it; otherwise, it is considered a
5
non-controlling parameter and can be replaced by magic code.
To distinguish controlling and non-controlling parameters, we
obtain the path constraints when a state is terminated; if the
parameter is used as a constraint, it as a controlling parameter;
otherwise, it is a non-controlling parameter.
Identifying Loops. Loops that repeatedly save user-controlled
data on the kernel stack are ideal for targeted stack-spraying
because they may write arbitrary data to a large region of the
stack. Unfortunately, although symbolic execution can help
explore execution paths with a high coverage, it generally
cannot handle loops properly when the looping condition is
also a symbolic value [35]. We address this limitation of
symbolic execution by offloading the path exploration for
loops to the guided fuzzer. Specifically, we identify the loops
during the symbolic execution and provide loop information,
(i.e., the looping condition in the form of the respective
parameter and its value range to the guided fuzzer). The
fuzzer then focuses on exploring this particular parameter in
the particular range. However, identifying loops in S2E is
challenging. Traditional loop detection mechanisms rely on
a dominator tree [22] to extract the dependence relationships
among blocks. The dominator tree, however, is not available in
S2E because it transforms the binary code of a program into
an LLVM IR representation block by block thus losing the
information about dependencies among blocks. Without this
information, a precise identification of loops is infeasible. Since
false positives in identifying potential loops during symbolic
execution only introduce more work for the fuzzer, we use a
two-layered approach to conservatively identify loops during
symbolic execution. The first layer is an execution history-based
identification, and the second is based on the relative offsets
between instructions. Specifically, in the first layer, when given
a function, we maintain the list of executed instructions, and
whenever a conditional jump is executed, we check its target: If
it targets an already executed instruction, we identify it as a loop.
This execution history-based approach, however, is unable to
detect a loop if it is executed only once. In this case, we invoke
the second layer of our approach to further check the address
of the jump target: If the address is lower than the one of the
conditional jump instruction, we also identify it as a loop. It is
important to note that the relative offset-based check is also not
entirely reliable since it is possible that a conditional jump for
a loop may target a higher address, resulting in false negatives.
Nonetheless, our two-layered approach works reasonably well
and can largely solve the loop identification problem in a timely
manner. Once we have successfully identified a conditional
jump that is used for looping, we extract the loop condition
from the comparison instruction. By checking whether the loop
condition is a symbolic value, we are able to determine whether
the loop condition is dependent on the syscall parameters. To
further reduce the search space for the guided fuzzer, we also
query the constraint solver of S2E for the possible value ranges
of the symbolic loop condition. These value ranges are then
used to guide the fuzzing process.
2) Guided Fuzzing: The fuzzing mechanism verifies that
the targeted stack-spraying is indeed achieved when executing
the kernel with the inputs generated by symbolic execution.