### Communication Overhead and Performance Analysis

**Overhead Analysis:**
- The baseline round-trip time experienced an overhead of approximately 90% when parsing GIOP messages. This overhead was necessary to track object keys and request IDs, and to generate the appropriate GIOP messages for forwarding requests to the next available replica.
- The NEEDS ADDRESSING MODE scheme introduced only an 8% overhead compared to the baseline, as it did not require tracking object keys.
- The MEAD message-based scheme added about a 3% overhead over the baseline client-server round-trip time.

**Proactive Recovery Overhead:**
- The communication overhead introduced by proactive schemes depends on the frequency of proactive recovery invocations. In the event of a failure, MEAD's proactive dependability framework typically sends additional messages ranging from 100 to 150 bytes per client-server connection.
- Given that systems generally experience more non-faulty behavior, the overall communication overhead of our approach is reasonable.

**Memory and CPU Usage:**
- The differences in memory and CPU usage for our application were not significant. However, we anticipate that as the server supports more objects, the overhead of the GIOP LOCATION FORWARD scheme will increase significantly, as it maintains an IOR entry for each instantiated object.

### Fail-Over Times

**Average Fail-Over Times:**
- **Reactive Scheme (No Cache):** 
  - When a server replica fails, the client first encounters a COMM FAILURE exception, which takes about 1.8 ms to register. 
  - The client then incurs an 8.4 ms spike to resolve the next server replica’s reference, resulting in a total failover time of 10.2 ms.

- **Reactive Scheme (With Cache):**
  - For every two COMM FAILURE exceptions, there is one TRANSIENT exception.
  - The COMM FAILURE exception takes about 1.1 ms, and the time to fail-over to the next cached replica reference and receive a normal response is 7.9 ms.
  - If the client accesses a stale cache reference, it experiences a TRANSIENT failure in addition to the COMM FAILURE exception, taking about 2.4 ms.
  - The average fail-over time for this scheme is about 10.5 ms, calculated as ((1.1 + 7.9) * 2/3 + (1.1 + 2.4 + 9.7)/3) ms.

- **Proactive Scheme (LOCATION FORWARD Messages):**
  - The average fail-over time was 8.8 ms, which is 13.5% lower than the reactive scheme with no cache. This is because the client ORB resends the request to the next server replica upon receiving the LOCATION FORWARD message.

- **Proactive Scheme (MEAD Messages):**
  - The average fail-over time was about 2.7 ms, representing a 73.9% reduction compared to the reactive scheme with no cache. This is due to avoiding request retransmissions and only incurring overhead when redirecting a connection to a new server.

- **NEEDS ADDRESSING MODE Scheme:**
  - The average fail-over time was about 9.4 ms, which is 7.7% lower than the reactive scheme with no cache. This includes the time to contact the Spread group, redirect the client connection, and retransmit the request to the new server.

### Effect of Varying Thresholds

- For proactive schemes, we analyzed the impact of varying the proactive recovery threshold. Our results showed that setting the threshold too low increases system overhead due to unnecessary client migrations.
- For example, at an 80% threshold, the group communication bandwidth between servers is about 6,000 bytes/sec, but this increases to about 10,000 bytes/sec at a 20% threshold. This increase occurs because servers are restarted more frequently at lower thresholds, consuming more bandwidth for group consensus.
- The best performance is achieved by delaying proactive recovery just enough to allow the proactive dependability framework to redirect clients away from faulty server replicas to non-faulty ones.

### Jitter Analysis

- In both fault-free and faulty (reactive and proactive) schemes, we observed spikes exceeding the average round-trip times by 3-σ, occurring 1-2.5% of the time.
- In the fault-free run, the highest spike was 2.3 ms, possibly due to file system journaling by the operating system.
- A large spike of about 30 ms occurred 0.01% of the time in the GIOP proactive recovery schemes when the rejuvenation threshold was set below 80%. This spike likely happens when a client sends a request to a newly restarted server updating its group membership information.
- The highest spike observed with MEAD proactive messages was 6.9 ms at the 20% rejuvenation threshold.

### Conclusion

In this paper, we describe the development of a transparent proactive recovery framework for CORBA applications, demonstrating that proactive recovery can provide bounded temporal behavior in the presence of certain faults, enabling the development of real-time, fault-tolerant distributed systems.

- **Key Findings:**
  - MEAD's proactive fail-over messages reduce average fail-over times by 73.9% compared to traditional reactive recovery schemes, with a reasonable overhead of about 3% over normal client/server round-trip times.
  - Using GIOP messaging schemes, the fail-over time is about 13.5% lower, but with a 90% round-trip time overhead and the need to maintain additional state at the server.
  - Suppressing exceptions at the client when insufficient time is available for proactive recovery results in a 7.7% lower fail-over time but with a 25% client-side failure rate.
  - Triggering proactive recovery too early can negate its benefits due to the overhead of frequent client migrations. The ideal scenario is to delay proactive recovery just enough to redirect clients and objects to non-faulty server replicas.

### Future Work

- We plan to extend our proactive dependability framework to include more sophisticated failure prediction and integrate adaptive thresholds rather than relying on preset user-supplied thresholds.

### References

[References listed here as in the original text]

---

This revised version aims to improve clarity, coherence, and professionalism while maintaining the technical details and key points of the original text.