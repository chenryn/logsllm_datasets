Wesley task
Jack task
XPFP
Salmon
58%
83%
25%
100%
Table 1: Accuracy rates for the Wesley and Jack tasks on
the XPFP and Salmon interfaces. Salmon showed 43% and
100% improvements in accuracy over XPFP on the Wesley
and Jack tasks, respectively.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:08:40 UTC from IEEE Xplore.  Restrictions apply. 
Goal
Plan Action
Perception
Wesley
XPFP
Salmon
Jack
XPFP
Salmon
5
1
15
1
1
2
0
3
0
1
0
2
3
0
1
0
Table 2: Count of errors by type for Wesley and Jack tasks
on XPFP and Salmon interfaces. Salmon users committed
signiﬁcantly fewer goal errors than did XPFP users for both
the Wesley and Jack tasks.
8.3 Goal Errors
The error analysis revealed a substantial reduction in the
number of goal errors committed by Salmon users, com-
pared to XPFP users. For the Wesley task, XPFP users made
9 total errors, of which 5 were goal errors, while Salmon
users made 4 total errors, of which one was a goal error (see
Table 2). This represents an 80% reduction in average goal
errors per participant for Salmon (M =0.083, sd=0.29) over
XPFP (M =0.42, sd=0.51). A one-sided z-test for equal-
ity of proportions showed this difference to be statistically
signiﬁcant (z=-1.885, p=0.0297) at the 0.05 level. For the
Jack task, XPFP users made 16 total errors, of which 15
were goal errors, while Salmon users made 6 total errors, of
which one was a goal error (see Table 2). This represents
a 94% reduction in goal errors per participant for Salmon
(M =0.083, sd=0.29) over XPFP (M =1.33, sd=0.87). A
one-sided z-test showed this difference to be statistically
signiﬁcant (z=-3.312, p=0.0005) at the 0.05 level. It can be
concluded that Salmon performs better than XPFP in miti-
gating goal errors.
Error analysis results show that the Salmon interface led
users to more plan and action errors than did XPFP. How-
ever, the impact of these errors was not as signiﬁcant as
was the impact of goal errors, because while most goal er-
rors led directly to task failure, most plan and action errors
were recovered from. Nevertheless, plan and action errors
in Salmon bear further investigation.
9 Discussion
The improvement in task-completion successes, and the
dramatic reduction in goal errors achieved in the Salmon
study, can be accounted for primarily by the use of anchor-
based subgoaling in the design of the Salmon interface.
Although Salmon’s design contains numerous superﬁcial
changes from the XPFP design (such as different fonts,
labels, icons, colors, and layout), observation of partic-
ipants’ protocols strongly suggested that it was the ef-
fective permissions display that led users to formulate
the correct goals. For example, one Salmon participant,
about to commit an incorrect solution on the Jack task,
said, “I see Jack over here now [pointing to Jack’s stated
permissions], and he doesn’t have any access rights...
Oh, wait!
Jack has access rights over here [pointing to
Salmon’s effective-permissions display].” After noticing
the effective-permissions display, the participant was able
to correctly complete the task. In contrast, several XPFP
users, looking at Wesley’s stated permissions in the XPFP
window as shown in Figure 1, thought that Wesley was al-
lowed READ permission because his “Allow Read” check-
box is checked, but was not allowed WRITE permission,
because his “Allow Write” checkbox is not checked. They
did not realize that he has effective WRITE permission from
ProjectF. One such XPFP participant, looking at the XPFP
window in the state shown in Figure 1, said, “And appar-
ently his permissions are just READ. That’s what we want.”
He had not explicitly denied WRITE permission to Wes-
ley, and committed his incorrect solution. In the absence
of correct information to conﬁrm that the task was com-
plete, the participant used incorrect information, the stated
permissions, to “conﬁrm” that he had correctly completed
the task.
10 Conclusion
In the course of completing tasks with a user interface,
users look for information to formulate goals and to check
progress. When the necessary information is misleading or
absent, users fail to establish the correct goals and hence
make goal errors. Goal errors may lead to partial or total
task failure, and to the extent that interfaces lead to goal
errors, they are undependable. Many goal errors can be pre-
vented by providing a comprehensive and correct external
representation of the information relevant to completing the
user’s root goal. The design principle which calls for such
a representation has been named anchor-based subgoaling.
The Windows XP ﬁle permissions interface, which does
not use anchor-based subgoaling, was shown to have un-
acceptably low success rates, 58% and 25%, on two rep-
resentative permission-setting tasks. Salmon, an alternative
interface designed in accordance with the anchor-based sub-
goaling principle, was shown to increase the percentage of
successes to 83% and 100%, respectively, on the same tasks.
Furthermore, user tests with Salmon showed a dramatic re-
duction in the occurrence of goal errors compared to XPFP,
with 80% fewer goal errors on one task and 94% fewer goal
errors on the other. These substantial improvements in suc-
cessful task completion and reductions in goal-error occur-
rence were due to anchor-based subgoaling. These success
rates more closely approach what is needed for depend-
able user interfaces in mission-critical systems like those
required for setting security-related conﬁgurations.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:08:40 UTC from IEEE Xplore.  Restrictions apply. 
11 Future work
Anchor-based subgoaling has been demonstrated to be a
successful design technique for reducing goal errors in the
domain of setting ﬁle permissions, but the technique will
need to be tested in other task domains before it is fully
proven. Testing in additional task domains will also help
deﬁne its limits, and potentially reveal areas in which it can-
not by itself reduce goal errors.
The present work attempted only to reduce one type of
user interface error, goal errors. Future work will look at
means to reduce plan, action, and perception errors.
12 Acknowledgements
The authors are grateful for help from our colleagues
Fahd Arshad, David Banks, Patricia Loring and Rachel
Roberts. This work was partially supported by the Army
Research Ofﬁce through grant number DAAD19-02-1-0389
(“Perpetually Available and Secure Information Systems”)
to Carnegie Mellon University’s CyLab, and partially sup-
ported by the Engineering and Physical Sciences Research
Council, United Kingdom, grant number GR/S29911/01.
References
[1] A. Adams and M. A. Sasse. Users are not the enemy. Com-
munications of the ACM, 42(12):41–46, 1999.
[2] D. Balfanz. Usable access control for the World Wide Web.
In Proceedings of 19th Annual Computer Security Applica-
tions Conference, pages 406–415, Los Alamitos, CA, 2003.
IEEE Comp. Society. 08-12 Dec 2003, Las Vegas, NV.
[4] S. Card.
Information visualization.
[3] D. Besnard and B. Arief. Computer security impaired by le-
gitimate users. Computers & Security, 23(3):253–264, 2004.
In J. A. Jacko and
A. Sears, editors, The Human-Computer Interaction Hand-
book: Fundamentals, Evolving Technologies and Emerg-
ing Applications, chapter 28, pages 544–582. Lawrence Erl-
baum Associates, Mahwah, NJ, 2003.
[5] P. Dewan and H. Shen. Controlling access in multiuser inter-
faces. ACM Transactions on Computer-Human Interaction,
5(1):34–62, 1998.
[6] K. A. Ericsson and H. A. Simon. Protocol Analysis: Ver-
bal Reports as Data. MIT Press, Cambridge, MA, Revised
edition, 1993.
[7] N. S. Good and A. Krekelberg. Usability and privacy: a
study of Kazaa P2P ﬁle-sharing. In Proceedings of the ACM
Conference on Human Factors in Computing Systems (CHI
2003), pages 137–144, New York, NY, 2003. ACM Press.
05-10 April 2003, Fort Lauderdale, Florida.
[8] B. Kirwan. A Guide to Practical Human Reliability Assess-
ment. Taylor & Francis, London, United Kingdom, 1994.
[9] A. C. Long, C. Moskowitz, and G. Ganger. A prototype user
interface for coarse-grained desktop access control. Tech-
nical Report CMU-CS-03-200, Comp. Sci. Dept, Carnegie
Mellon University, Pittsburgh, PA, Nov. 2003.
Best practices
for permis-
Available at http://www.
[10] Microsoft Corporation.
rights.
sions and user
microsoft.com/resources/documentation/
windowsserv/2003/stand%ard/proddocs/
en-us/sag_SEconceptsImpACBP.asp, 2005.
[11] Microsoft Corporation. Microsoft Technet: Windows XP
http://www.
ﬁle permissions documentation, 2005.
microsoft.com/technet/treeview/default.
asp?url=/technet/prod%technol/winxppro/
proddocs/acl_special_permissions.asp.
[12] J. Nielsen and R. L. Mack. Usability Inspection Methods.
John Wiley & Sons, Inc., New York, NY, 1994.
[13] D. A. Norman. The Design of Everyday Things. Doubleday,
New York, NY, 1988.
[14] S. Pocock, M. Harrison, P. Wright, and P. Johnson. Thea:
A technique for human error assessment early in design.
In Proceeding of 8th IFIP TC.13 Conference on Human-
Computer Interaction, pages 247–254, Amsterdam, 2001.
IOS Press. 09-13 July 2001, Tokyo, Japan.
[15] J. Reason. Human Error. Cambridge University Press, Cam-
bridge, UK, 1990.
[16] G. Sampemane, P. Naldurg, and R. H. Campbell. Ac-
cess control for active spaces.
In Proceedings of the 18th
Annual Computer Security Applications Conference, pages
343–352, Los Alamitos, CA, 2002. IEEE Computer Society.
09-13 December 2002, Las Vegas, NV.
[17] J. W. Senders and N. P. Moray. Human Error: Cause,
Prediction, and Reduction. Lawrence Erlbaum Associates,
Hillsdale, New Jersey, 1991.
[18] R. Smith. Personal communication, March 2004.
[19] U.S. Senate Sergeant at Arms.
vestigation into improper access
diciary Committees computer system.
http://judiciary.senate.gov/testimony.
cfm?id=1085&wit_id=2514, March 2004.
Report on the in-
to the Senate Ju-
Available at
[20] A. Whitten and J. Tygar. Why Johnny can’t encrypt: A
usability evaluation of PGP 5.0.
In Proceedings of the
8th USENIX Security Symposium, pages 169–184, Berke-
ley, California, 1999. USENIX Association. 23-26 August
1999, Washington, DC.
[21] D. A. Wiegmann and S. A. Shappell. A Human Error Ap-
proach to Aviation Accident Analysis. Ashgate Publishing
Co., Aldershot, Hants, United Kingdom, 2003.
[22] D. D. Woods and E. M. Roth. Cognitive systems engi-
neering.
In M. Helander, editor, Handbook of Human-
Computer Interaction, chapter 1, pages 3–43. Elsevier Sci-
ence Publishers B.V., Amsterdam, The Netherlands, 1st edi-
tion, 1988.
[23] K. Yee. User interaction design for secure systems. In In-
formation and Communications Security, 4th International
Conference, ICICS 2002, Singapore, Lecture Notes in Com-
puter Science, Vol. 2513, pages 278–290, New York, NY,
2002. Springer. 09-12 December 2002, Singapore.
[24] M. E. Zurko, R. Simon, and T. Sanﬁlippo. A user-centered,
modular authorization service built on an RBAC foundation.
In Proceedings 1999 IEEE Symposium on Security and Pri-
vacy, pages 57–71, Los Alamitos, CA, 1999. IEEE Com-
puter Security Press. 09-12 May 1999, Berkeley, California.
In
Proceedings of Workshop on New Security Paradigms, pages
27–33, New York, NY, 1996. ACM Press. 17-20 September
1996, Lake Arrowhead, CA.
[25] M. E. Zurko and R. T. Simon. User-centered security.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:08:40 UTC from IEEE Xplore.  Restrictions apply.