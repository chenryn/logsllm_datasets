mitigation is comparable to no mitigations, as it does not inject
fences after load instructions in the decoding routine, but only for
control flow related instructions.
On the Intel i5-6400, the results with no mitigations applied are
better, but still clearly worse than with LOAD mitigations enabled.
4.2.3 Practical relevance of LVI mitigations. Setting MITIGATION-
CVE-2020-0551 to LOAD has a high performance impact. In general,
it is hard to say whether this mitigation is applied in commercial
enclaves; that also holds for open source software, since the miti-
gations are activated by explictly setting an environment variable.
However, we believe that this mitigation has its value in practical
applications and that should be applied to secret-dependent work-
loads like key loading procedures and cryptographic operations.
In general, Intel recommends applying the MITIGATION-CVE-
2020-0551 on LVI-affected platforms [41]: "Intel SGX Attestation
Service will report a new status code, SW_HARDENING_NEEDED, to
indicate the platform is affected by a security advisory for which
software hardening is recommended". Intel recommends enclave
developers to "determine the level of software hardening that their
environment requires, based on risk analysis and an evaluation of
the performance impacts of mitigation".
The CF (Control-Flow-Mitigation) mitigation level will only pro-
tect against LVI gadgets which use control-flow instructions for
secret transmission. However, secret transmissions with LVI can
100011001200130014001500Measurementsequence number050010001500Eviction time (cycles) - OffsetMeasurements with LVI Mitigation enabled100011001200130014001500Measurement sequence number0500100015002000Eviction time (cycles) - OffsetMeasurements with LVI Mitigation disabledSet 1Set 2Set 1Set 2Session 10A: Crypto, Symbols and Obfuscation CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2464their deployment / Docker files [28].
• SecretNetwork [27] enables the LOAD mitigation level in
• According to a GitHub issue [1], Asylo [9] uses MITIGATION-
• Intel offers a variant of its Crypto API Toolkit with all mitiga-
tions enabled [2]. Additionally, as already stated, by default
intel-sgx-ssl builds versions for each mitigation level.
CVE-2020-0551 set to LOAD by default since May 2020.
5 RSA KEY RECOVERY
In the following, we will adapt the algorithm of Heninger and
Shacham [35] to the setting, where only information about certain
blocks of bits is known. Here, we only give a high-level overview
and refer the reader to the appendix, which contains a complete
formal description of both the setting and the algorithm.
𝑞 , 𝑞★
𝑝
𝑝 , 𝑑★
We first formalize the setting, describe the adapted algorithm,
and analyze its running time. Finally, we discuss optimizations used
in our implementation.
Blockwise Knowledge. We consider the situation that some block-
−1)
wise knowledge about the secret key sk★ = (𝑝★, 𝑞★, 𝑑★, 𝑑★
was obtained. In the following, we focus on the first five variables
and treat sk★ as a quintuple on the variables Vars = {𝑝, 𝑞, 𝑑, 𝑑𝑝, 𝑑𝑞}.
To simplify the notation, for 𝑣 ∈ Vars, we denote the corresponding
entry in some key sk by sk[𝑣]. We show in Sec. A.1 that integrat-
ing the last variable 𝑞−1
𝑝 into the key-recovery approach does not
directly give a usable linear equation in contrast to the other vari-
ables.
From a high-level perspective, our attack gives us the following
information: For each 6-bit block of a variable 𝑣 ∈ Vars, we know
that this block belongs to a certain cache line. This knowledge
allows us to rule out the values of the other cache lines for this
block. For example, we might know that the first 6 bits of 𝑝★ belong
to cache line 𝑖. As we also know the content 𝐶𝑖 ⊆ {0, . . . , 26 − 1}
of cache line 𝑖, we can reduce our search space for these 6 bits
from the complete space {0, . . . , 26 − 1} down to 𝐶𝑖, but we still
have a remaining uncertainty about which concrete value in 𝐶𝑖
was used. In contrast, in the scenarios studied in [34, 35, 65], the
knowledge always was about single bits. Hence, the attacks here
might have given the information that the fifth bit of 𝑝 equals
0. The uncertainty in this scenario comes from the fact that this
information could potentially be wrong (e. g. due to a bit-flip in the
cold-boot scenario).
Modeling the Scenario. As described above, in the situation given
by our attack, we do not have observations on single bits, but
on blocks consisting of 6 bits, the length of a base64 symbol. To
generalize this knowledge, we let 𝑏 ∈ Z>0 be the blocksize, i. e. the
length of the block on which we have obtained our knowledge.
For a variable 𝑣, we denote the 𝑗-th block of length 𝑏 as block𝑗 (𝑣),
e. g. the six least significant bits of 𝑝 are denoted as block0(𝑝). In our
attack, we make use of the fact that the possible values for block𝑗 (𝑣)
are partitioned into different sets to model the different cache lines
used in our attack. To formalize this, we consider a partition part =
(part1, . . . , part| part |) of all possible 𝑏-bit values {0, . . . , 2𝑏 − 1}.
The set part𝑖 would thus correspond to the content of 𝐶𝑖 of cache
line 𝑖. Our algorithm is now given an observation about a certain
key sk★ stating that for each variable 𝑣 ∈ Vars, the block block𝑗 (𝑣)
Figure 5: Number of ambiguous or wrong cache access mea-
surements for 93 executions of the experiment, where we
were able to recover the full trace. The histogram shows that
the majority of executions had less than 10 measurements
where the classification was wrong or ambiguous. This cor-
responds to around 1.2% of the full trace. The measure-
ments were performed on an Intel Xeon E-2286M against
our OpenSSL-based enclave.
Figure 6: Number of ambiguous or wrong cache access mea-
surements across different mitigation levels. Traces with
LOAD mitigation level contain considerably less errors. The
measurements were performed on an Intel Xeon E-2286M
against the intel-sgx-ssl enclave.
also be encoded into the data flow [19], so memory load instructions
have to be protected with LFENCEs as well. Since this is rather impor-
tant in secret-dependent algorithms, there is a practical relevance
for the LOAD mitigation level in this case.
We found several concrete applications using these mitigations
by default or offering a version with mitigations applied:
• Inclavare Containers [4] and the RUST SGX SDK [69] enable
their users to apply the mitigations. For the enclave-tls mod-
ule of the former, it is even stated in the documentation that
the SGX LVI mitigation is enabled by default, but not which
level [5]. Both frameworks consider both levels.
Session 10A: Crypto, Symbols and Obfuscation CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2465belongs to part𝑖. In our concrete application, this translates to the
knowledge that the 𝑗-th base64 symbol of variable 𝑣 belongs to
cache line 𝑖.
5.1 Recovery Algorithm
The main idea of the algorithm is to reconstruct the different bits
of the secret key sk★ iteratively. We build up a set of candidates
iteratively. Each such candidate is a guess for the least significant
bits of the true secret key sk★ compatible with our observation
and the RSA equations. We start our algorithm by producing a
single candidate(cid:101)sk of depth 1, i. e. each variable only consists of
bits each variable has. We then apply the expand operation on(cid:101)sk
to obtain two candidates(cid:101)sk1 and(cid:101)sk2 of depth 2 by using the RSA
a single bit. Informally, the depth of a candidate is the number of
equations described by Heninger and Shacham [35]. Whenever a
candidate has reached depth of a multiple of 𝑏, i. e., 𝑗 · 𝑏 for some 𝑗,
we apply the check operation on this candidate to verify that the
last produced block block𝑗 (𝑣) of each variable 𝑣 is possible under
our observation. If this candidate does not fit to our observation,
we prune it. We repeat these operations until a target depth 𝐷 is
reached. All produced candidates of depth 𝐷 are output. This target
depth is chosen such that the remaining bits can be reconstructed
via the Coppersmith method [23, 37, 52].
Our algorithm first performs these operations in a breadth-first
fashion to utilize parallelisation and then in a depth-first fashion
(see Figure 7). The expand operation uses a set of 4 modular equa-
tions on 5 variables and the check operation compares the generated
candidates to our observations.
Pseudocode of the key-reconstruction algorithm
initialize empty stack 𝑆
while 𝑆 is not empty:
for each possible triple (𝑘, 𝑘𝑝, 𝑘𝑞):
Input: Observation obs(part), target depth 𝐷
1 : find valid triples (𝑘, 𝑘𝑝, 𝑘𝑞)
2 :
3 :
4 :
5 :
6 :
7 :
8 :
9 :
10 :
11 :
add initial candidate(cid:101)sk(𝑘, 𝑘𝑝, 𝑘𝑞) to 𝑆
let(cid:101)sk = 𝑆.pop(); let(cid:101)sk1,(cid:101)sk2 = expand((cid:101)sk)
if depth((cid:101)sk𝛽) ≥ 𝐷: output(cid:101)sk𝛽
if depth((cid:101)sk𝛽) mod 𝑏 = 0 and check(obs,(cid:101)sk𝛽):
𝑆.push((cid:101)sk𝛽)
else : 𝑆.push((cid:101)sk𝛽)
for 𝛽 ∈ {1, 2}:
1−𝛼 log(cid:16)𝑘
𝑖=1 pr[𝑖]𝛼(cid:17).
Rényi entropy 𝐻𝛼 (pr) measures the amount of information given
by pr and is defined as 𝐻𝛼 (pr) = 𝛼
The special case for 𝛼 = 2 is called the collision entropy, which we
will need in the run time analysis of our algorithm, similar to [11].
Intuitively, the usual Shannon-entropy used in Table 1 gives the
complete amount of information available, but we can only use
certain events to discard candidates not belonging to the observed
cache line, namely non-collision events.
To simplify the analysis of our algorithm, we use the heuristical
assumptions of [11, 35], namely
Assumption.
(1) Upon random choice of sk★, for each 𝑣 ∈ {𝑝, 𝑞, 𝑑, 𝑑𝑝, 𝑑𝑞}
and each block block𝑗 (𝑣), we have Pr[block𝑗 (𝑣) ∈ part𝑗] =
| part𝑗 |
(2) Once a bit in a candidate (cid:101)sk is set incorrectly (w. r. t. sk★),
and these probabilities are independent.
the set of satisfying solutions to the four congruences behaves
randomly and independently.
2𝑏
Using these, we can bound the expected number of candidates.
Theorem 1. Let 𝐶 be a set of incorrect candidates with depth 𝑗 · 𝑏.
After expanding these candidates 𝑏 times, the expected number of
incorrect candidates after pruning is |𝐶| · 2𝑏−5·𝐻2(pr) + 2𝑏 − 1, where
pr[𝑖] = | part𝑖 |/2𝑏.
It is easy to see that we have exactly 2𝑏−1 initial candidates of
depth 𝑏. We can thus conclude the following theorem about the
expected number of candidates.
depth 𝑗 · 𝑏 is at most 2𝑏 ·𝑗
Theorem 2. The expected number of incorrect candidates with
𝑖=0(2𝑏−5·𝐻2(pr))𝑖 = 2𝑏 · (2𝑏−5·𝐻2(pr)) 𝑗+1−1
.
2𝑏−5·𝐻2(pr)−1
test for all candidates(cid:101)sk of depth 𝐷, whether(cid:101)sk[𝑝] is a factor of 𝑁 .
algorithm of Boneh, Durfee, and Frankel on all candidates(cid:101)sk[𝑝] out-
5.3 Termination of the Algorithm
Finally, we need to describe how to set the target depth 𝐷 of our
algorithm. In a naive approach, we could set 𝐷 = ⟨sk★[𝑝]⟩ and then
But using a lattice-based approach, we can factor 𝑁 much faster. The
algorithm of Boneh, Durfee, and Frankel shows that it is sufficient
to obtain ⟨sk★[𝑝]⟩/2 bits of 𝑝 to factor 𝑁 in polynomial time [13,
Corollary 1]. By setting our target depth 𝐷 = ⟨𝑁⟩/4 and using the
put by our algorithm, we can reconstruct the correct secret key sk★.
Together with Theorem 2, this shows that (2𝑏−5·𝐻2(pr))⟨𝑁 ⟩/(4𝑏)
calls to the lattice algorithm are sufficient to reconstruct sk★. Ta-
ble 3 contains the total number of calls to the lattice algorithms for
different collision entropies for blocksize 𝑏 = 6 (as in our attack),
compared with the security level in bits.
Figure 7: Concise description of our adapted key-
reconstruction algorithm
5.2 Analyzing the Algorithm
In the following, we analyze the number of candidates of depth 𝑖,
produced by the algorithm. To do so, we need some probability no-
tions. Let pr = (pr[1], . . . , pr[𝑘]) be a probability vector of length 𝑘,
𝑖=1 pr[𝑖] = 1. For 𝛼 ≥ 0 with 𝛼 ≠ 1, the
i. e. pr ∈ [0, 1]𝑘 with𝑘
5.4 Experimental Evaluation
To make the connection between the algorithm described above
and our attack more explicit, the partition part corresponds to the
(usually two) different cache lines and the block length 𝑏 is 6 due
to the base64 encoding. To reconstruct the RSA key completely,
we implemented the adapted algorithm in C++ and implemented
the final reconstruction step via the lattice algorithm small_roots
in Sagemath 9.0. Note that, due to the depth-first approach used
Session 10A: Crypto, Symbols and Obfuscation CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2466Table 3: Overview on the number of calls to the lattice algo-
rithm for blocksize 𝒃 = 6 compared with the security level
of the key length. Here, B denotes bits and L the number of
calls to the lattice algorithm.
Key (B)
1024
2048
level (B) 𝐻2 = 1 (L) 𝐻2 = 1.1 (L) 𝐻2 = 1.15 (L)
280
2112
249
292
229
250
219
229
Table 4: Experimental Evaluation of our implementation on
different key lengths and different cache distributions.
Length Cache Dist.
256
256
512
38/26
32/32
32/32
#Cand.
795,712
31,760
2.08·108
genCands (s)