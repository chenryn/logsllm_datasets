创建插件  
```  
db1=> \c db1 postgres  
You are now connected to database "db1" as user "postgres".  
db1=# create extension postgis;  
CREATE EXTENSION  
Time: 468.662 ms  
db1=# \c db1 r1  
You are now connected to database "db1" as user "r1".  
```  
用户轨迹表  
```  
create unlogged table tbl_tj (  
  uid int,  
  pos geometry,  
  ts timestamp  
);  
```  
生成100万轨迹  
```  
insert into tbl_tj select random()*10000, st_makepoint( 120+random()*2, 30+random() ), now()+ (random()*1000||'second')::interval from generate_series(1,1000000);  
```  
创建空间索引  
```  
create index on tbl_tj using gist (pos);  
```  
选出近期去过某个商圈的用户  
```  
explain select uid from tbl_tj where ST_Within ( pos, ST_MakePolygon( 'LINESTRING(120 30, 120.1 30, 120.1 30.1, 120 30.1, 120 30)') ) ;  
 Index Scan using tbl_tj_pos_idx on tbl_tj  (cost=0.29..52327.65 rows=3895 width=4)  
   Index Cond: (pos @ '010300000001000000050000000000000000005E400000000000003E406666666666065E400000000000003E406666666666065E409A99999999193E400000000000005E409A99999999193E400000000000005E400000000000003E40'::geometry)  
   Filter: st_within(pos, '010300000001000000050000000000000000005E400000000000003E406666666666065E400000000000003E406666666666065E409A99999999193E400000000000005E409A99999999193E400000000000005E400000000000003E40'::geometry)  
(3 rows)  
select count(distinct uid) from tbl_tj where ST_Within ( pos, ST_MakePolygon( 'LINESTRING(120 30, 120.1 30, 120.1 30.1, 120 30.1, 120 30)') )  ;  
 count   
-------  
  3974  
(1 row)  
```  
##### 60.17 空间距离排序查询  
术语  
- postgis, 时空数据库插件  
- gist, 索引  
POI表  
create unlogged table tbl_poi (  
  id int primary key,  
  classid int,  
  pos geometry  
);  
写入100万POI数据  
insert into tbl_poi select id, random()*100, st_makepoint( 120+random()*2, 30+random() ) from generate_series(1,1000000) id;  
创建空间索引  
```  
create extension btree_gist;  
create index on tbl_poi using gist (classid, pos);  
```  
根据位置查找附近的餐馆(假设餐饮类别为`24`, 假设当前位置为`120.1 30.1`)并按距离返回  
```  
select * from tbl_poi where classid=24 order by pos  st_makepoint(120.1, 30.1);    
db1=> explain select *, from tbl_poi where classid=24 order by pos  st_makepoint(120.1, 30.1);  
                                          QUERY PLAN                                             
-----------------------------------------------------------------------------------------------  
 Index Scan using tbl_poi_classid_pos_idx on tbl_poi  (cost=0.29..13263.70 rows=9867 width=48)  
   Index Cond: (classid = 24)  
   Order By: (pos  '01010000006666666666065E409A99999999193E40'::geometry)  
(3 rows)  
```  
```  
db1=> select id,classid from tbl_poi where classid=24 order by pos  st_makepoint(120.1, 30.1) limit 10;  
   id   | classid   
--------+---------  
 455394 |      24  
 898767 |      24  
 273812 |      24  
 936314 |      24  
 735089 |      24  
  92975 |      24  
 871516 |      24  
  95006 |      24  
 681032 |      24  
 993427 |      24  
(10 rows)  
Time: 0.963 ms  
```  
##### 60.18 向量相似查询  
术语  
- vector, 向量插件  
- hnsw, 向量索引  
[《沉浸式学习PostgreSQL|PolarDB 21: 相似图像搜索》](../202310/20231013_01.md)    
[《沉浸式学习PostgreSQL|PolarDB 17: 向量数据库, 通义大模型AI的外脑》](../202309/20230922_02.md)    
[《沉浸式学习PostgreSQL|PolarDB 16: 植入通义千问大模型+文本向量化模型, 让数据库具备AI能力》](../202309/20230914_01.md)    
[《沉浸式学习PostgreSQL|PolarDB 9: AI大模型+向量数据库, 提升AI通用机器人在专业领域的精准度, 完美诠释柏拉图提出的“知识是回忆而不是知觉”》](../202308/20230831_01.md)    
[《沉浸式学习PostgreSQL|PolarDB 8: 电商|短视频|新闻|内容推荐业务(根据用户行为推荐相似内容)、监控预测报警系统(基于相似指标预判告警)、音视图文多媒体相似搜索、人脸|指纹识别|比对 - 向量搜索应用》](../202308/20230829_02.md)    
创建向量索引插件    
```    
db1=> \c db1 r1  
You are now connected to database "db1" as user "r1".  
db1=# create extension vector;    
CREATE EXTENSION  
Time: 32.116 ms  
```    
设计一张向量特征表, 存储已知特征向量, 例如商品、视频、图文、人脸、指纹、监控事件等的特征.    
```    
db1=# \c db1 r1  
You are now connected to database "db1" as user "r1".  
db1=>   
create unlogged table tbl_vector (    
  id serial primary key,  -- 内容ID    
  vec vector(128)    -- 内容ID对应的向量, 例子使用了128维度    
);    
```    
创建一个生成随机N维向量的函数    
```    
create or replace function gen_rand_vector(int) returns vector as $$    
  select array_to_vector(array_agg((random()*1000)::int), $1, true) from generate_series(1,$1);    
$$ language sql strict;    
db1=> select gen_rand_vector(10);    
             gen_rand_vector    
-----------------------------------------    
 [841,286,91,478,961,965,99,132,315,125]    
(1 row)    
```    
写入测试特征向量数据10万条.    
```    
insert into tbl_vector(vec) select gen_rand_vector(128) from generate_series(1,100000);    
```    
创建向量索引 (支持3种距离算法, 本例使用cosine. PGVECTOR 0.5.0开始支持ivfflat和hnsw两种索引算法, 本例使用hnsw.)    
```    
-- 尽量和表一样大, 创建索引可以快一点    
set maintenance_work_mem='256MB';    
CREATE INDEX ON tbl_vector USING hnsw (vec vector_cosine_ops) WITH (m = 12, ef_construction=40);  -- 可以设置不同的参数, 对比一下性能.    
```    
在另一个会话中可以观测索引创建过程:    
```    
SELECT phase, tuples_done, tuples_total FROM pg_stat_progress_create_index;    
             phase              | tuples_done | tuples_total    
--------------------------------+-------------+--------------    
 building index: loading tuples |      61788  |            0    
(1 row)    
```    
测试数据占用空间如下:    
```    
                                    List of relations  
 Schema |    Name    | Type  | Owner | Persistence | Access method | Size  | Description   
--------+------------+-------+-------+-------------+---------------+-------+-------------  
 s1     | tbl_vector | table | r1    | unlogged    | heap          | 56 MB |   
db1=> \di+    
                                                 List of relations    
 Schema |        Name        | Type  |  Owner   |   Table    | Persistence | Access method |  Size   | Description     
--------+--------------------+-------+----------+------------+-------------+---------------+---------+-------------    
 s1     | tbl_vector_pkey         | index | r1       | tbl_vector      | unlogged    | btree         | 2216 kB |   
 s1     | tbl_vector_vec_idx      | index | r1       | tbl_vector      | unlogged    | hnsw          | 78 MB   |   
(2 rows)    
```    
根据特征向量进行搜索    
```    
vacuum analyze tbl_vector;    
-- alter role r1 SET enable_seqscan = off;    
-- alter role r1 SET hnsw.ef_search = 10;  -- 可以设置不同的参数, 对比一下性能.    
alter function gen_rand_vector(int) immutable; -- 为了测试索引的性能, immutable让这个函数产生常数, 强制使用vector索引.    
explain select id,vec  gen_rand_vector(128) from tbl_vector order by vec  gen_rand_vector(128) limit 1;    
 Limit  (cost=9.34..9.43 rows=1 width=12)  
   ->  Index Scan using tbl_vector_vec_idx on tbl_vector  (cost=9.34..9116.64 rows=100000 width=12)  
         Order By: (vec  '[31,886,785,244,168,193,756,265,860,54,262,663,246,558,275,130,112,105,194,461,845,682,766,760,790,765,368,353,753,722,173,172,529,626,246,983,636,755,819,931,860,590,157,535,204,668,995,762,236,106,916,698,288,431,172,668,132,770,761,533,559,376,549,181,200,373,321,433,59,120,873,590,927,228,112,375,482,387,129,54,516,413,936,80,137,327,991,535,711,624,439,562,815,889,667,398,138,469,989,740,400,409,88,331,294,380,981,481,875,874,218,970,710,782,680,449,551,246,656,233,973,824,673,635,755,827,565,931]'::vector)  
(3 rows)   
db1=> select id,vec  gen_rand_vector(128) from tbl_vector order by vec  gen_rand_vector(128) limit 1;    
   id   |      ?column?         
--------+---------------------  
 667676 | 0.16630337200308487  
(1 row)  
Time: 2.685 ms  
```    
##### 60.19 大数据量并行查询加速报表分析和复杂SQL  
建表  
```  
create unlogged table t_big (  
  id int,  
  info text,  
  c1 int,  
  c2 int,  
  ts timestamp  
);  
```  
写入1亿数据  
```  
insert into t_big select generate_series(1,100000000), md5(random()::text), random()*100, random()*10, clock_timestamp();  
db1=> \dt+ t_big  
                                  List of relations  
 Schema | Name  | Type  | Owner | Persistence | Access method |  Size   | Description   
--------+-------+-------+-------+-------------+---------------+---------+-------------  
 s1     | t_big | table | r1    | unlogged    | heap          | 8056 MB |   
(1 row)  
```  
强制并行度执行统计SQL  
```  
db1=> alter table t_big set (parallel_workers =4);  
ALTER TABLE  
db1=> set max_parallel_workers_per_gather =4;  
SET  
db1=> set max_parallel_workers=4;  
SET  
db1=> set min_parallel_index_scan_size =0;  
SET  
db1=> set min_parallel_table_scan_size =0;  
SET      
db1=> set parallel_leader_participation =off;  
SET  
db1=> set parallel_setup_cost =0;  
SET  
db1=> set parallel_tuple_cost =0;  
SET  
db1=> explain select c1,count(*) from t_big group by c1 ;  
                                            QUERY PLAN                                               
---------------------------------------------------------------------------------------------------  
 Finalize GroupAggregate  (cost=1405932.49..1405941.47 rows=101 width=12)  
   Group Key: c1  
   ->  Gather Merge  (cost=1405932.49..1405938.44 rows=404 width=12)  
         Workers Planned: 4  
         ->  Sort  (cost=1405932.43..1405932.68 rows=101 width=12)  
               Sort Key: c1  
               ->  Partial HashAggregate  (cost=1405928.06..1405929.07 rows=101 width=12)  
                     Group Key: c1  
                     ->  Parallel Seq Scan on t_big  (cost=0.00..1280928.04 rows=25000004 width=4)  
 JIT:  
   Functions: 6  
   Options: Inlining true, Optimization true, Expressions true, Deforming true  
(12 rows)  
db1=> explain analyze select c1,count(*) from t_big group by c1 ;  
                                                                      QUERY PLAN                                                                         
-------------------------------------------------------------------------------------------------------------------------------------------------------  
 Finalize GroupAggregate  (cost=1405932.49..1405941.47 rows=101 width=12) (actual time=8170.860..8171.041 rows=101 loops=1)  
   Group Key: c1  
   ->  Gather Merge  (cost=1405932.49..1405938.44 rows=404 width=12) (actual time=8098.056..8098.197 rows=404 loops=1)  
         Workers Planned: 4  
         Workers Launched: 4  
         ->  Sort  (cost=1405932.43..1405932.68 rows=101 width=12) (actual time=8057.777..8057.788 rows=101 loops=4)  
               Sort Key: c1  
               Worker 0:  Sort Method: quicksort  Memory: 29kB  
               Worker 1:  Sort Method: quicksort  Memory: 29kB  
               Worker 2:  Sort Method: quicksort  Memory: 29kB  
               Worker 3:  Sort Method: quicksort  Memory: 29kB  
               ->  Partial HashAggregate  (cost=1405928.06..1405929.07 rows=101 width=12) (actual time=8057.667..8057.678 rows=101 loops=4)  
                     Group Key: c1  
                     Worker 0:  Batches: 1  Memory Usage: 40kB  
                     Worker 1:  Batches: 1  Memory Usage: 40kB  
                     Worker 2:  Batches: 1  Memory Usage: 40kB  
                     Worker 3:  Batches: 1  Memory Usage: 40kB  
                     ->  Parallel Seq Scan on t_big  (cost=0.00..1280928.04 rows=25000004 width=4) (actual time=0.021..3627.108 rows=25000000 loops=4)  
 Planning Time: 0.073 ms  
 JIT:  
   Functions: 33  
   Options: Inlining true, Optimization true, Expressions true, Deforming true  
   Timing: Generation 4.747 ms, Inlining 236.900 ms, Optimization 144.771 ms, Emission 82.932 ms, Total 469.349 ms  
 Execution Time: 8172.490 ms  
(24 rows)  
```
##### 60.20 大对象和bytea的使用  
- [《使用 PostgreSQL 大对象和pgcrypto加解密文件》](../202212/20221215_01.md)        
- [《PostgreSQL 9.0 开始大对象的改进 - 增加 pg_largeobject_metadata 表用于查询大对象oid和对应的owner与权限》](../202105/20210507_03.md)        
- [《PostgreSQL 大对象使用》](../202012/20201205_01.md)        
- [《PostgreSQL psql的元素周期表 - 包括大对象操作》](../201906/20190607_04.md)        
- [《[转] 关于入侵PostgreSQL的那些事儿（文件读取写入、命令执行的办法）  -大对象》](../201802/20180201_03.md)        
- [《大对象 - 数据库common安全自动渗透测试与防范 - sqlmap》](../201702/20170213_01.md)        
- [《大对象攻击 - Hacking PostgreSQL》](../201610/20161018_02.md)        
- [《在java中正确使用PostgreSQL大对象和字节流(bytea)类型的姿势》](../201606/20160614_01.md)        