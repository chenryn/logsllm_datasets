– The average content similarity
– The ratio of mentions sent to non-followers
|mentions|
|total tweets| )
|f ollowings|
|f ollowers| )
The ratio of mentions sent to non-followers is the only relation feature and
the others are account features which are used in previous work. The average con-
tent similarity is computed in the same as Lee et al [5]. They computed content
similarity using the cosine similarity over the bag-of-words vector representation
V (t) of the tweets:
similarity(t1, t2) =
V (t1) · V (t2)
|V (t1)||V (t2)|
Then, they measured the average content similarity over all pairs of tweets:
(cid:88)
t1,t2∈ set of pairs in tweets
similarity(t1, t2)
|set of pairs in tweets|
00.20.40.60.8100.20.40.60.81False positive rateTrue positive rate  Distance, random walk and min−cutDistance and min−cutDistance and random walkDistanceTable 4. The top ﬁve results of spammer detection using Weka classiﬁers
Classiﬁers True Positive (%) False Positive (%)
BayesNet
LogitBoost
J48
Logistic
LibSVM
99.7
99.7
99.6
99.4
98.3
0.6
0.6
0.6
0.9
0.5
Table 5. The results of feature selection
Rank
Information Gain
1 The ratio of mentions sent to non-followers
2 Reputation
3 The ratio of mentions containing URLs
4 The ratio of tweets containing URLs
5 Age
Rank
ReliefF
1 The ratio of mentions sent to non-followers
2 The ratio of tweets containing URLs
3 Age
4 The ratio of mentions containing URLs
5 The average content similarity
Rank
Chi Square
1 The ratio of mentions sent to non-followers
2 Reputation
3 The ratio of mentions containing URLs
4 The ratio of tweets containing URLs
5 Age
We selected 1,000 non-spammers and 300 spammers from our data set and ex-
tracted the most recent 50 tweets from their timelines. The users were classiﬁed
using several classiﬁers in Weka with a 10-fold cross validation option. Table 4
shows the top ﬁve results of classiﬁcation among Weka classiﬁers. The accuracy
is about 99.7% and the false positive is only about 0.6%. The accuracy are better
than the spam classiﬁcation in Section 4.2, but spam account detection methods
cannot detect spam in real-time.
We also ranked the features to verify the importance. The feature selec-
tion methods used are also available on Weka, Information Gain, ReliefF and
ChiSquare. Table 5 shows the ﬁve most important features for each method. All
feature selection methods rank the ratio of mentions sent to non-followers as the
top feature. It means that the relation feature is more powerful than the account
features.
5 Discussion
5.1 Combination of account features and relation features
We only used relation features to detect spam in order to focus on the eﬀect
of the relation features. When a message is being delivered, our system veriﬁes
whether a sender is a spammer or not only using relation information between a
message sender and a message receiver. The results are quite good but if we use
both the account features and the relation features, the spam ﬁltering system
will be more powerful. In Section 4.3, we used both the account features and
the relation feature. The accuracy is better than the results when only used
the relation features. The account features supplement the relation features’
insuﬃciency.
5.2 Live detection
Our system can be applied to both client-side and server-side. When our system
is applied to client-side, the system should collect relation information peri-
odically from Twitter. The distance and the connectivity are computed using
collected data. In these processes, the client needs some bandwidth, computing,
storages resources and time. Most of received messages, however, come from the
client’s friends. The messages coming from the friends do not need to identify
senders. Therefore, there will be only a few cases that crawling the data and
computing relation features for indentifying the sender. Given those facts, the
resource problems are not big. When our system is applied to server-side, it is
more practical. Additional bandwidth and storage resources are not needed be-
cause service managers already have user’s relation information. However, the
service managers should compute all users’ relation features. It may cause a
heavy load to the server, so they should prepare separate computing servers.
Computed relation features will be cached and then only updated when the re-
lation features are changed. Caching technique will help both client-side and
server-side to reduce computing overhead.
5.3 Limitations
Spammers have very few relationships or no relationships with normal users.
This is the reason why our system checks the message sender by computing the
distance and the connectivity from the message receiver to the message sender.
However, this method has two problems. First, if a normal user creates a new
account and sends a message to his friend before the new account has any follow-
ers, the message will be ﬁltered. This is because new account’s characteristics
are same as spammer when the new account is created and it has not estab-
lished any relationships yet. This, however, is a temporal problem because the
new account will get followers soon. The second problem is that our system
will identify the messages as normal even though the messages come from in-
fected friends. Sometimes attackers send spam through normal users’ accounts
by using Cross-Site Request Forgery (CSRF) or password stealing. Also, many
malicious applications use crafty tricks for getting a writing permission of nor-
mal users. The innocent and careless users allow that the applications can write
postings using the user’s own name. Infected users’ friends receive spam from
his infected friends. Only checking relation features cannot solve this problem.
When a user sends the messages using the application that has never been used
by the user, the messages should be suspected. Ultimately, the contents of the
messages should be checked whether the contents are spam or not. Because of
tweet’s short length, identifying only the URLs contained in the messages is a
good solution. There are related work about classifying web pages into spam or
not [31–33].
6 Conclusion
In social networks, traditional spam ﬁltering methods are not eﬀective because
of the characteristics of social networks. We propose a spam ﬁltering method
for social networks using relation information between users. We use distance
and connectivity as the features which are hard to manipulate by spammers
and eﬀective to classify spammers. Moreover, our system identiﬁes spam in real-
time because it does not need a user history data. Services managers or clients
can decide whether or not the messages are spam. We hope that our system
contributes to quarantine a suspected message into spam message box in social
networking services. Also, we showed that user relation concept can be reﬂected
into user account proﬁle to detect spam accounts. We evaluated the system using
Twitter data but the system is also eﬀective for other social networking services
because all such services contain relation features.
Acknowledgement
This research was supported by the MKE(The Ministry of Knowledge Economy),
Korea, under the ITRC(Information Technology Research Center) support pro-
gram supervised by the NIPA(National IT Industry Promotion Agency)” (NIPA-
2011-C1090-1131-0009) and WCU(World Class University) program through the
National Research Foundation of Korea funded by the Ministry of Education,
Science and Technology (R31-2010-000-10100-0)
References
1. Alexa: Top sites in united states (2011) http://www.alexa.com/topsites/
countries/US.
2. NielsenWire: Twitter’s tweet smell of success (2009) http://blog.nielsen.com/
nielsenwire/online_mobile/twitters-tweet-smell-of-success/.
3. TwitterBlog: #numbers (2011) http://blog.twitter.com/2011/03/numbers.
html.
4. Webb, S., Caverlee, J., Pu, C.: Social honeypots: Making friends with a spam-
mer near you. In: Proceedigns of the Fifth Conference on Email and Anti-Spam
(CEAS). (2008)
5. Lee, K., Caverlee, J., Webb, S.: Uncovering social spammers: Social honeypots +
machine learning. In: Proceeding of the 33rd international ACM SIGIR conference
on Research and development in information retreival, ACM (2010)
6. Stringhini, G., Kruegel, C., Vigna, G.: Detecting spammers on social networks.
In: Proceedings of the 26th Annual Computer Security Applications Conference
(ACSAC), ACM (2010)
7. Markines, B., Cattuto, C., Menczer, F.: Social spam detection. In: Proceedings of
the 5th international workshop on Adversarial Information Retrieval on the Web
(AIRWeb), ACM (2009)
8. Yardi, S., Romero, D.: Detecting spam in a twitter network. First Monday 15(1)
(2010)
9. Gayo-Avello, D., Brenes, D.J.: Overcoming spammers in twitter - a tale of ﬁve
algorithms. In: 1st Spanish Conference on Information Retrieval. (2010)
10. Wang, A.H.: Don’t follow me: Spam detection in twitter. In: Proceedings of 5th
International Conference on Security and Cryptography (SECRYPT). (2010) 142–
151
11. Benevenuto, F., Magno, G., Rodrigues, T., Almeida, V.: Detecting spammers on
twitter. In: Proceedings of the 7th Annual Collaboration, Electronic messaging,
Anti-Abuse and Spam Conference (CEAS). (2010)
12. Chu, Z., Gianvecchio, S., Wang, H., Jajodia, S.: Who is tweeting on twitter:
Human, bot, or cyborg? In: Proceedings of Annual Computer Security Applications
Conference (ACSAC). (2010)
13. Thomas, K., Grier, C., Ma, J., Paxson, V., Song, D.: Design and evaluation of a
real-time url spam ﬁltering service. In: Proceedings of the IEEE Symposium on
Security and Privacy. (2011)
14. Blanzieri, E., Bryl, A.: A survey of learning-based techniques of email spam ﬁlter-
ing. Artif. Intell. Rev. 29 (March 2008) 63–92
15. Sahami, M., Dumais, S., Heckerman, D., Horvitz, E.: A bayseian approach to
ﬁltering junk e-mail. In: Learning for Text Categorization: Papers from the 1998
Workshop. AAAI Technical Report, AAAI Technical Report WS-98-05 (1998)
16. Grier, C., Thomas, K., Paxson, V., Zhang, M.: @spam: the underground on 140
characters or less. In: Proceedings of the 17th ACM conference on Computer and
communications security, ACM (2010)
17. TwitterHelpCenter: How to report spam on twitter http://support.twitter.
com/articles/64986-how-to-report-spam-on-twitter.
18. TwitterBlog: State of twitter spam (2010) http://blog.twitter.com/2010/03/
state-of-twitter-spam.html.
19. TwitterBlog: Measuring tweets (2010) http://blog.twitter.com/2010/02/
measuring-tweets.html.
20. Yu, H., Kaminsky, M., Gibbons, P.B., Flaxman, A.: Sybilguard: defending against
sybil attacks via social networks. In: Proceedings of ACM SIGCOMM Conference.
SIGCOMM ’06, ACM (2006)
21. Yu, H., Gibbons, P.B., Kaminsky, M., Xiao, F.: Sybillimit: A near-optimal social
network defense against sybil attacks. In: Proceedings of the 2008 IEEE Sympo-
sium on Security and Privacy, IEEE Computer Society (2008)
22. Kwak, H., Lee, C., Park, H., Moon, S.: What is twitter, a social network or a news
media? In: WWW ’10: Proceedings of the 19th international conference on World
Wide Web, ACM (2010)
23. Menger, K.: Zur allgemeinen kurventheorie. Inventiones Mathematicae 10 (1927)
24. Aharoni, R., Berger, E.: Menger’s theorem for inﬁnite graphs. Inventiones Math-
ematicae 176(1) (2009)
25. Langville, A.N., Meyer, C.D.: A survey of eigenvector methods for web information
retrieval. SIAM Review 47(1) (2005)
26. Perron, O.: Zur theorie der matrices. Mathematicsche Annalen 64(2) (1907)
27. Keener, J.: The perron–frobenius theorem and the ranking of football teams. SIAM
Review 35(1) (1993)
28. TwitterAPIwiki: Rate limiting http://dev.twitter.com/pages/rate-limiting.
29. Paul, R.:
twitter
http://arstechnica.com/software/news/2011/03/
client
twitter-tells-third-party-devs-to-stop-making-twitter-client-apps.
ars.
Twitter
(2011)
stop making
apps
tells
third-party devs
to
30. Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., H., I.: The weka
data mining software: An update. SIGKDD Explorations 11(1) (2009) http://
www.cs.waikato.ac.nz/ml/weka/.
31. Ntoulas, A., Najork, M., Manasse, M., Fetterly, D.: Detecting spam web pages
through content analysis. In: Proceedings of the 15th international conference on
World Wide Web. WWW ’06, ACM (2006)
32. Thomas, K., Grier, C., Ma, J., Paxson, V., Song, D.: Design and evaluation of a
real-time url spam ﬁltering service. In: Proceedings of the IEEE Symposium on
Security and Privacy. (May 2011)
33. Ma, J., Saul, L.K., Savage, S., Voelker, G.M.: Identifying suspicious urls: an ap-
plication of large-scale online learning. In: Proceedings of the 26th Annual Inter-
national Conference on Machine Learning. ICML ’09 (2009)