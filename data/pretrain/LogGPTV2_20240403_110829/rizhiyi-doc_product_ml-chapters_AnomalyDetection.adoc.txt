==== DensityFunction
DensityFunction 用来为数据拟合常见的连续概率密度分布，并提供一种异常检测的方法。日志易机器学习中提供以下特性:
* 支持 by 语句。根据一个或多个字段将数据分组，为每组数据分别拟合各自的概率分布
* 目前支持的概率分布：高斯分布（Normal Distribution），指数分布（Exponential Distribution），高斯核密度估计（Gaussian KDE）
* 支持自动选择最合适的分布
* 支持根据设定的阈值（异常占比）来判断异常
* 支持整体阈值、上限阈值和下限阈值
* 支持给出可能的异常数值范围
* 支持通过拟合的分布重新抽样
* 支持全范围抽样和从正常数值范围内抽样
* 分布拟合效果基于给定数据的质量，建议使用尽可能多、分布尽可能合理的数据拟合。
阈值的设定依靠领域内的知识，建议通过观察效果不断调整到最合适的值。
如果数据的分布随时间变化，建议每隔一段时间重新拟合。
可以根据抽样做概率密度分布函数的图像，并和原数据的分布直方图做效果对比。
语法：
    fit DensityFunction [param1, param2, ...]  [by [, , ...]] [into ] [override=]
params:
* dist=        拟合分布，可选值：auto, norm, expon, gaussian_kde（默认 auto）
* show_density=        是否在结果中显示概率密度（默认 false）
* sample=        是否从正常数值范围内抽样（不包含异常区域）（默认 false）
* full_sample=        是否从整体分布中抽样（包含正常和异常区域）（默认 false）
* threshold=        整体阈值（或异常占比）（默认 0.01）
* upper_threshold=        上限阈值（只考虑高值为异常）（默认 不设置）
* lower_threshold=        下限阈值（只考虑低值为异常）（默认 不设置）
* metric=        衡量拟合程度的距离函数，可选值：wasserstein, kolmogorov_smirnov（默认 wasserstein）
* random_state=        抽样的随机种子（默认 不设置）
语法限制：
* 根据 by 语句分组后，最大组数不能超过 1024 个。例如，根据字段 A 和 B 分组，A 有3 种取值，B有 4 种取值，那么分组后的组数最多可能为 3 * 4 = 12 组。
* 每组分别拟合分布。为了保证效果，每组的数据大小建议不低于 50，且空值不能多于总数的一半。
* 如果 dist=auto，拟合所有分布并选择拟合程度最高的分布
* 所有阈值的取值范围是 (0.0001, 1.0)
* threshold 和 upper_threshold/lower_threshold 不能同时给定
* 如果同时给定 upper_threshold 和 lower_threshold 则两者的加和不能大于 1
* 指数分布不支持 lower_threshold， 若给定则忽略
* 当选择抽样时，抽样数据的大小等于给定数据大小
* 若储存模型，需要给定 into ，模型名称不能和已有模型重复
* 若覆盖已有模型，需要指定 override=true
结果解析：
可能的新字段：ProbabilityDensity，AnomalyBoundary，IsAnomaly，SampledValue，FullSampledValue
ProbabilityDensity：当前数值在拟合的分布下的概率密度
AnomalyBoundary：根据阈值计算出的异常可能取值范围，可能是一个或多个不相邻的数值范围，以列表形式显示，每个范围的格式为：（左界，右界）- 概率
IsAnomaly：当前数值是否为异常，0 表示正常，1 表示异常
SampledValue：当 sample=true 时显示，从正常数值范围内抽样的数值
FullSampledValue：当 full_sample=true 时显示，从全部数值范围内抽样的数值
`summarymodel ` 结果解析：
* 每行表示一个拟合的分布，如果通过 by 分为 N 组，则结果共 N 行，每行以分组的字段作为索引标识
* 可能的新字段：Distribution，MinValue，MaxValue，Mean，StandardDeviation，TrainSize，Score
* Distribution：拟合时选择的分布，若为自动选择则添加 [AUTO] 标识
* MinValue：训练数据集的最小值
* MaxValue：训练数据集的最大值
* Mean：训练数据集的均值
* StandardDeviation：训练数据集的标准差
* TrainSize：训练数据集的大小
* Score：分布的拟合程度（距离），越小拟合的越接近真实数据。格式为：[衡量分布距离的方法] 距离
==== OneClassSVM
OneClassSVM即一类支持向量机，其通常用于异常检测。在这里我们指的聚簇即把正常的数据分到相邻的簇从而识别出异常数据，这样相当于一类classification的问题。
首先介绍一类classification与2类及以上的classification的区别在于：
classification问题一般都是2类及2类以上的，典型的2类问题比如识别一封邮件是不是垃圾邮件，这里就只有2类，“是”或者“不是”，典型的多类classification问题比如说人脸识别，每个人对应的脸就是一个类，然后把待识别的脸分到对应的类去。
而one class classification只有一个类，然后识别的结果就是：“是”或者“不是”这个类。区别在于，在2类classification问题中，training set中有2个类，通常称为正例和负例，例如对于垃圾邮件识别问题，正例就是垃圾邮件，负例就是正常邮件，而在one class classification中，就只有一个类。一般是在的确手头上只有一类样本数据的情况下，或者是别的类数据不好确定的情况下会出现training set中只有一个类的情况。比如现在有一堆某产品的历史销售数据，记录着买该产品的用户的各种信息（这些信息在特征提取时会用到），然后还有些没买过该产品的用户的数据，想通过2类classification预测他们是否会买该产品，也就是弄2个类，一类是“买”，另一类是“不买”。那么不买的这类数据就不好确定，我们并不清楚用户不感兴趣而没买或者用户感兴趣但是因为其他原因没买。
其基本思想是，既然只有一个class，那么就训练出一个最小的超球面（超球面是指3维以上的空间中的球面，对应的2维空间中就是曲线，3维空间中就是球面，3维以上的称为超球面），把这堆数据全都包起来，识别一个新的数据点时，如果这个数据点落在超球面内，就是这个类，否则不是。例如对于2维（维数依据特征提取而定，提取的特征多，维数就高，为方便展示，举2维的例子，实际用时不可能维数这么低）数据，大概像下面这个样子：
image::images/ml-onesvm-model.png[]
Syntax：
    fit OneClassSVM [algo_params] from  [into model_name]
Parameters:
*  ：使用这些特征字段对目标字段进行聚簇和预测的训练，字段个数须>=1
* [into model_name]：保存下来的模型名称，可选，若不填将不做保存
* [algo_params]：针对OneClassSVM模型的参数设置，可选，不填时用默认参数设置
** kernel : string, optional (default=’rbf’)
+
Specifies the kernel type to be used in the algorithm. It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable. If none is given, ‘rbf’ will be used. If a callable is given it is used to precompute the kernel matrix.
** nu : float, optional
+
An upper bound on the fraction of training errors and a lower bound of the fraction of support vectors. Should be in the interval (0, 1]. By default 0.5 will be taken.
** degree : int, optional (default=3)
+
Degree of the polynomial kernel function (‘poly’). Ignored by all other kernels.
** gamma : float, optional (default=’auto’)
+
Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. If gamma is ‘auto’ then 1/n_features will be used instead.
** coef0 : float, optional (default=0.0)
+
Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.
** tol : float, optional
+
Tolerance for stopping criterion.
** shrinking : boolean, optional
+
Whether to use the shrinking heuristic.
** cache_size : float, optional
+
Specify the size of the kernel cache (in MB).
** verbose : bool, default: False
+
Enable verbose output. Note that this setting takes advantage of a per-process runtime setting in libsvm that, if enabled, may not work properly in a multithreaded context.
** max_iter : int, optional (default=-1)
+
Hard limit on iterations within solver, or -1 for no limit.
** random_state : int seed, RandomState instance, or None (default)
+
The seed of the pseudo random number generator to use when shuffling the data for probability estimation.