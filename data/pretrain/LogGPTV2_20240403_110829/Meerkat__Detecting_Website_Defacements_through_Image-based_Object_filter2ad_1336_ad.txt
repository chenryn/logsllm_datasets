samples of the legitimate websites (2,554,905) and defaced
websites (10,053,772), we report the Bayesian detection
rate [45]. The Bayesian detection rate is normalized to the
number of samples and corresponds to the likelihood if we
detect a website as being defaced, it is actually defaced (the
likelihood of a positive prediction being correct, that is a
true positive; i.e., P(true positive|positive)).
4.2 Features Learned
The features that MEERKAT learns depend on the data
it is being trained on. Although one can treat the system as
a black-box and not worry about its internal details, under-
standing how it comes to its ﬁnal decision helps one to rea-
son about its robustness and to understand how difﬁcult the
system is to evade or to estimate when the system must be re-
trained to retain its accuracy. In our experiments, MEERKAT
learned various features automatically and directly from
image data, of which we manually grouped some on a higher,
more conceptual level together. We manually identiﬁed the
learned features by evaluating which representative win-
dows activate the same neuron of the neural network, i.e.,
which windows trigger the same feature to be recognized by
MEERKAT. Note that all the features we discuss hereinafter
have been learned automatically from data and no domain
knowledge whatsoever was required to learn and use these
features; yet, the overlap with features that an analyst with
domain knowledge would use conﬁrms the prospects of fea-
ture/representational learning for website defacement detec-
tion. Some of the learned features can be best described as:
Defacement group logos. MEERKAT learned to recog-
nize the individual logos of some of the most proliﬁc
defacement groups directly (see Figure 4). Clearly, the
8We cannot compare prior work on our dataset directly as they do not
scale to its size, and we cannot compare on their datasets because they
are too small to train MEERKAT accurately (see Section 6.1).
602  24th USENIX Security Symposium 
USENIX Association
8
logos of the defacer groups themselves are extremely
descriptive of website defacements because they are
very unlikely to be included in legitimate websites.
Color combinations. MEERKAT also learned to recog-
nize unique or speciﬁc color combinations indicative
of legitimate and defaced websites, including but not
limited to one of the most prominent combinations:
bright red or green text on a black background, which is
an often used color combination by defacers, but rarely
seen on legitimate websites. On the other hand, small
black text on a white or brightly colored background
is being consulted as a non-deﬁnitive indicator for a
legitimate, non-defaced website.
Letter combinations. Interestingly, defacers often not
only mix colors, but also mix characters from different
alphabets right next to each other, such as Arabic or
Cyrillic script being mixed with Latin script, to promote
their message in both their native language and also in
English as the web’s lingua franca. Additionally, some-
times the defacement contains characters in a character
set encoding speciﬁc to the defacer’s native language,
like ISO-8859-13 for Baltic languages or Windows-1256
for Arabic. As such, characters appear differently or are
replaced by special characters if the browser does not sup-
port it, or if the website does not specify the character set
and if the browser’s fallback is different (like in our case,
as we fall back to UTF-8), resulting in a look and feel
that is descriptive of defacements, and, correspondingly,
it was automatically learned by MEERKAT.
Leetspeak. Similarly to letter combinations, MEERKAT
learned that defacers often use “leetspeak,” an English al-
phabet in which some characters are replaced by numbers
or special characters (e.g., “leetspeak” as “1337sp34k”)
and in which some words are deliberately misspelled
(“owned” as “pwned,” “the” as “teh,” or “hax0red” in-
stead of “hacked”). Defacers often use leetspeak to dis-
cern themselves from “common folks,” and to show that
they are “elite” and special, which, in turn, makes it often
a good indicator that a website has indeed been defaced.
Typographical and grammatical errors. While some
typographical mistakes are deliberate (as in the case
of leetspeak, see above), many defacers make other
unintentional typographical and grammatical mistakes,
which rarely occurred on the legitimate websites in
our dataset. Many defacers make these mistakes most
likely because they are not native English speakers (the
country of the reporter of the defacement, part of the
meta-data in our dataset, suggests that most defacers
do not speak English as their ﬁrst language). MEERKAT
learned to detect some of these mistakes at training
and values them as a supporting indicator of a website
defacement. Some of the examples of (supposedly)
unintentional typographical and grammatical errors
include “greats to” (instead of “greets to”), “goals is”
(instead of “goals are”), or “visit us in our website”
(“visit us at our website” or just “visit our website”).
Note that, since MEERKAT works on image data, the system
is unaware that it analyzes text and the textual features, such
as unique letter combinations, leetspeak, or typographical
and grammatical errors, are actually being evaluated on ren-
dered text. As such, it seems likely that the textual features
are speciﬁc to the font, possibly overﬁtting on the speciﬁc
font type. However, we manually conﬁrmed that the system
actually learned a more robust feature and is not overﬁtting:
it combines slight variances in the font family and size in
a single high-level feature. Furthermore, given the sliding
window approach MEERKAT employs for detection, the
features are also completely independent of the position
of the text in the representative window and website.
While some of the learned features can be evaded
theoretically, evading them almost always contradicts
the defacer’s goal: making a name for themselves in the
most “stylish” and personalized way possible, thus, it is
unlikely that these features will change drastically in the
near future. Furthermore, MEERKAT also consults features
that were not as easy to discern into high-level feature
groups manually, such as artifacts unique to legitimate
or defaced websites, or features that are indicative for one
group but are not deﬁnitive because they might appear more
often in defaced websites, but also sometimes legitimately.
MEERKAT can also be retrained easily and new features are
learned automatically once the old features do not model
defacements accurately anymore (i.e., if the concept of a
defacement drifted signiﬁcantly). Finally, since MEERKAT
uses a non-linear classiﬁer to combine those features, it
can learn more complex models about defacements and
legitimate websites, and simply evading only some features
will not be sufﬁcient to evade detection.
Interestingly, some of the high-level features (letter and
color combinations) that MEERKAT learned automatically
from data have been leveraged to a smaller degree by prior
work [46, 47] (through manual feature engineering), while
others (logos, leetspeak, and typographical mistakes) had
not been utilized yet. Further suggesting that representation
learning and inspection of the learned features can yield
important
into security challenges that were
dominated by feature engineering in the past, such as
intrusion, malware, or phishing detection.
4.3 Traditional Split
insight
First, for an accurate comparison to prior work, we evalu-
ate MEERKAT on our dataset using 10-fold cross-validation,
i.e., we split the dataset into 10 bins that contain 925,817
website defacements and 255,490 legitimate websites each.
Note that we discard 6 website defacements and 5 legitimate
websites from our dataset at random to have the same
number of samples in each bin. Next, for each bin, we train
the system on the other 9 bins (training bins) and measure
its classiﬁcation performance on the 10th bin (test bin).
Considering the 10 different 90% training and 10% test-set
partitions of our dataset separately, MEERKAT achieves
true positive rates between 97.422% and 98.375%, and
false positive rates ranging from 0.547% to 1.419%. The
Bayesian detection rate is between 99.603% and 99.845%.
USENIX Association  
24th USENIX Security Symposium  603
9
Figure 4: Defacement Group Logos. Example representative windows of logos of defacement groups that MEERKAT learned to recognized to be
a signiﬁcant indicator for defacements. Note that MEERKAT also recognizes variations and that there are many other features used for classiﬁcation.
More interestingly, as a partition-independent measure
of the system’s classiﬁcation performance, the average
true positive rate is 97.878%, the average false positive
rate is 1.012%, and the average Bayesian detection rate
is 99.716%. If MEERKAT detects a defacement and raises
an alert, with likelihood 99.716% it is a website defacement.
Therefore, MEERKAT is signiﬁcantly outperforming current
state-of-the-art approaches.
4.4 Reporter Split
For the reporter split, we partition our dataset by the
reporter of the defaced website. We deliberately designed
the experiment this way to show that MEERKAT is not
overﬁtting on speciﬁc defacements, which our results verify.
While a partition by reporter might seem counter-intuitive
at ﬁrst, it becomes clear that such a split is meaningful and
that it can be used to evaluate that a new defacer group
emerges once it is taken into account that these groups
often have unique defacement designs and that defaced
websites are most often reported by the defacers themselves.
Therefore, if we split by reporter, we are practically splitting
by defacer group; meaning, we create the most difﬁcult
scenario for a defacement detection system: detecting a
defacer and his/her defacement style although we have
never seen defacements from him/her before.
In the same way as for the traditional split, we employ
10-fold cross-validation. However, we do so slightly dif-
ferently: ﬁrst, we separate the reporters of the defacements
into 10 bins uniformly at random (each bin containing
7,602 reporters). Second, we construct the corresponding
defacement bins, i.e., we construct a defacement bin for
each reporter bin so that it contains only the defacements
reported by these reporters. For each bin, we then train
MEERKAT on the remaining 9 bins and use the 10th bin for
testing. Note that the defacement bins contain a different
number of samples, simply because the number of reported
defacements varies per reporter (see Appendix A). We
account for the uneven distribution of defacements by
reporting the average true positive and false positive rate
weighted by the number of samples.
Overall, when simulating the emergence of a new defacer,
MEERKAT achieves a true positive rate of 97.882% and
a false positive rate of 1.528% if bins are weighted, and
97.933% and 1.546% if they are not (see Figure 5; the true
positive rate is between 97.061% and 98.465%, the false pos-
itive rate is between 0.661% and 2.564%). The Bayesian de-
tection rates for the reporter split are 99.567% (unweighted)
and 99.571% (weighted) respectively (per split,
the
Bayesian detection rate is between 99.286% and 99.814%).
Reporter Split
e
t
a
R
e
v
i
t
i
s
o
P
e
u
r
T
e
t
a
R
e
v
i
t
i
s
o
P
e
s
l
a
F
0.990
0.985
0.980
0.975
0.970
0.965
0.030
0.025
0.020
0.015
0.010
0.005
0.9794
0.9793
0.9792
0.9791
0.9790
0.9789
0.9788
0.9787
0.0158
0.0157
0.0156
0.0155
0.0154
0.0153
0.0152
0.0151
1
2
3
4
5
6
7
8
9
10
Reporter Bin
n
a
e
M
d
e
t
h
g
i
e
W
Figure 5: True positive and false positive rates for the reporter split,
per bin of the 10-fold cross-validation set. Note that the scales for true
positives and false negatives are the same, but that the y-axis goes from
0.965 to 0.99 for the true positive rate and 0.005 to 0.03 for the false
positive rate. The weighted mean true positive rate is 97.882% and its false
positive rate is 1.528% (weighted by samples per bin). The unweighted
mean true positive rate is 97.933% and its false positive rate is 1.546%.
4.5 Time-wise Split
The time-wise experiment evaluates how well MEERKAT
detects website defacements in the wild, i.e., in a real-world
deployment. Here, we train the system on defacements
seen in the past, and we detect defacements in the present.
Similarly to the reporter split, the time-wise experiment
shows that MEERKAT does not overﬁt on past defacements,
and that it successfully detects present defacements.
Our training set selection follows a simple argument:
it is extremely unlikely that websites today will be defaced
in the same way as they were defaced in 2005 or even
1998. Including those defacements in our training set would
then very likely decrease classiﬁcation performance for
defacement detection in 2014. Equivalently, one would
not include this data to train the system in practice.
We train MEERKAT on all defacements that were
reported between December 2012 and December 2013
(including, i.e., 13 months with 1,778,660 defacements
observed in total), and 1,762,966 legitimate websites that
we sample from all legitimate websites uniformly at random.
We then detect defacements over a ﬁve months time frame,
from January to May 2014, and we report the classiﬁcation
performance for each month. The test data from January to
May 2014 spans a total of 1,538,878 unique samples that are
distributed as follows: 421,758 samples from January 2014,
364,168 samples from February 2014, 474,758 samples
from March 2014, 241,926 samples from April 2014, and
81,268 samples from the beginning of May 2014.
604  24th USENIX Security Symposium 
USENIX Association
10
Time-wise Split, with and without Fine-Tuning
with ﬁne-tuning
without ﬁne-tuning
True Positive Rate
False Positive Rate
e
t
a
R
e
v
i
t
i
s
o
P
e
u
r
T
1.000
0.995
0.990
0.985
0.980
0.975
0.970
e
t
a
R
e
v
i
t
i
s
o
P
e
s
l
a
F
0.040
0.035
0.030
0.025
0.020
0.015
0.010
e
c