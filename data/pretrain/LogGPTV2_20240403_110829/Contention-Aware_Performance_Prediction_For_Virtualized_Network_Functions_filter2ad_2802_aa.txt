title:Contention-Aware Performance Prediction For Virtualized Network Functions
author:Antonis Manousis and
Rahul Anand Sharma and
Vyas Sekar and
Justine Sherry
Contention-Aware Performance Prediction For
Virtualized Network Functions
Antonis Manousis, Rahul Anand Sharma, Vyas Sekar, Justine Sherry
Carnegie Mellon University
ABSTRACT
At the core of Network Functions Virtualization lie Network Func-
tions (NFs) that run co-resident on the same server, contend over
its hardware resources and, thus, might suffer from reduced perfor-
mance relative to running alone on the same hardware. Therefore, to
efficiently manage resources and meet performance SLAs, NFV orches-
trators need mechanisms to predict contention-induced performance
degradation. In this work, we find that prior performance prediction
frameworks suffer from poor accuracy on modern architectures and
NFs because they treat memory as a monolithic whole. In addition, we
show that, in practice, there exist multiple components of the mem-
ory subsystem that can separately induce contention. By precisely
characterizing (1) the pressure each NF applies on the server‚Äôs shared
hardware resources (contentiousness) and (2) how susceptible each
NF is to performance drop due to competing contentiousness (sensi-
tivity), we develop SLOMO, a multivariable performance prediction
framework for Network Functions. We show that relative to prior
work SLOMO reduces prediction error by 2-5√ó and enables 6-14%
more efficient cluster utilization. SLOMO‚Äôs codebase can be found at
https://github.com/cmu-snap/SLOMO.
CCS CONCEPTS
‚Ä¢ Networks ‚Üí Network Performance Evaluation;
ACM Reference Format:
Antonis Manousis, Rahul Anand Sharma, Vyas Sekar, Justine Sherry. 2020.
Contention-Aware Performance Prediction For Virtualized Network Func-
tions. In Annual conference of the ACM Special Interest Group on Data Com-
munication on the applications, technologies, architectures, and protocols for
computer communication (SIGCOMM ‚Äô20), August 10‚Äì14, 2020, Virtual Event,
NY, USA. ACM, New York, NY, USA, 13 pages. https://doi.org/10.1145/
3387514.3405868
KEYWORDS
Network Functions Performance; Packet Processing Software
1 INTRODUCTION
Network Function Virtualization (NFV) entails implementing
Network Functions (NFs) in software on shared, general-purpose
infrastructure [5, 41]. In this vision, NF instances are spun up and
down and migrated between servers. In order to reduce cost and
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
SIGCOMM ‚Äô20, August 10‚Äì14, 2020, Virtual Event, NY, USA
¬© 2020 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-7955-7/20/08.
https://doi.org/10.1145/3387514.3405868
be resource efficient, multiple virtualized NFs are co-resident on the
same server hardware.
Unfortunately, co-resident NFs can interfere with each other
as they share hardware resources, primarily in the memory sub-
system [47‚Äì49]. As a result, NF performance (i.e., throughput and
latency) can degrade relative to when they run alone.
This contention-induced performance drop suggests that to en-
sure that Service Level Agreements are met, NFV orchestration
systems (e.g., AT&T Domain 2.0 [3]) need suitable performance
prediction mechanisms. Such predictions can inform NFV orchestra-
tion tasks such as NF provisioning, deployment, and auto-scaling.
For example, before launching a new NF on a server that is already
running other instances, knowing if and by how much the per-
formance of each one of the co-runners will suffer can help make
better run-time decisions. Given the infeasibility of profiling all
possible combinations of NF configurations ahead of time, we need
systematic contention-aware techniques for performance prediction.
Prior works in NFV performance prediction build on the obser-
vation that the memory subsystem is the root cause of performance
degradation [24, 38, 39]. These works use linear models to correlate
a variable associated with cache utilization of a competitor (e.g.,
working set size or cache access rate) with net slowdown for a com-
peting target NF. However, we observe that under newer hardware
architectures and line rates reaching up to 100Gbps, this line of
prior work proves to be inadequate, with prediction errors as high
as 70% (¬ß2). This motivates us to systematically analyze the mem-
ory subsystem and understand the various sources of contention
to enable better prediction.
Our analysis (¬ß3) indicates that with state-of-the-art servers
and NFs, contention manifests simultaneously and independently
at three different chokepoints across the memory subsystem: the
packet I/O subsystem that delivers packets into the last-level cache
(LLC), evictions from the last-level cache, and the main memory ac-
cess bandwidth. Thus, we argue that we need to revisit contention
aware modeling, exploring both what metrics we use to measure
cache utilization of the competitor and what models we use to cor-
relate these metrics with slowdown ‚Äì now from a more challenging,
multivariable perspective.
To guide our exploration, we follow a blueprint from the archi-
tecture community [38, 39, 49, 50] based on the (1) contentiousness
that captures the pressure a NF places on shared hardware and (2)
sensitivity or how susceptible a NF is to performance degradation
as a function of the competitors‚Äô aggregate contentiousness. The
blueprint, however, leaves open three key technical challenges: iden-
tifying suitable domain-specific metrics for capturing contentious-
ness; evaluating models for measuring sensitivity; and ensuring
composability of the contentiousness metrics, i.e., that given the
traffic profile over which the function is expected to run. For the
rest of this paper, when we refer to NFi, we refer to one software
package along with its expected configuration and a traffic profile.1
We also assume that the cluster has a few server configurations
Archk (e.g., Intel Broadwell, Skylake etc.) [17, 33, 38]. Since most
cluster deployments standardize these configurations in practice
we only have a handful of possible options for Archk.
Network Functions that are scheduled to co-run on shared hard-
ware may experience slowdown as a result of contention for the
hardware‚Äôs shared resources [47‚Äì49]. Figure 1 illustrates the through-
put drop that NFs (presented in Table 1) experience as a result of
resource contention. The performance degradation is measured
relative to the performance each NF achieves when run in isolation
and can sometimes be as high as 35%.2
The NF performance prediction problem is defined as follows.
Given as input a set of NFs ùëÜ = {ùëÅ ùêπùëñ}, a target NFtarget ‚àà ùëÜ (i.e., a NF
whose performance drop we would like to estimate), a competing
workload Compj = {ùëÜ \ NFtarget} (e.g., the set of NFs the target may
be co-located with) and the hardware configuration Archk, our goal
is to estimate the expected throughput of NFtarget when it is run
together with Compj on a server instance of Archk.
What is special about NFV workloads? A large body of prior
work in the architecture community focuses on performance predic-
tion [16]. A natural question then is, why should NF performance
prediction be any different?
General workloads can contend for a wide range of system
resources such as memory capacity, storage bandwidth, CPU re-
sources (integer/floating point compute units), or the CPU-socket
interconnection network [20]. However, given the common NFV
deployment practices (e.g., running NFs on dedicated and isolated
cores, maintaining NUMA- and interrupt-core affinity etc. [25, 51]),
NF performance almost exclusively depends on contention in the
memory subsystem. Furthermore, NFs exhibit idiosyncratic and
extreme interactions with the cache hierarchy, with very little data
reuse for packet data, but very high reuse for data structures (e.g.,
rule or routing tables) which are accessed for every packet.
In short, general-purpose frameworks focus attention on mod-
eling system components which are not important to NFs, while
at the same time paying little attention to the intricacies of mem-
ory. Consequently, we observe in ¬ß2.2 and ¬ß7 that general-purpose
approaches have substantial error when applied to NFV workloads.
2.2 Existing Approaches
Prior work addresses contention-related performance degrada-
tion either through performance prediction or through hardware
resource isolation. Below, we discuss each approach.
Performance Prediction: Dobrescu et al. [24] identified that per-
formance variability is a critical obstacle to the adoption of software-
based packet processing. In this early but forward-looking work,
the authors carefully identified that memory contention was the
key source of slowdown in software NF implementations.
1We use the terms NF and NF instances interchangeably.
2In both cases we run the NF in its own core and dedicate the same amount of resources.
We delay a more detailed description of our setup to ¬ß3.
Figure 1: Contention-induced throughput drop (Maximum observed drop
across experiments with real competitors).
independent contentiousness of an ùëÅ ùêπùê¥ and an ùëÅ ùêπùêµ, one can com-
pute the combined contentiousness of ùëÅ ùêπùê¥ and ùëÅ ùêπùêµ imposed upon
a third ùëÅ ùêπùê∂. Indeed, because this blueprint is so generalizable, prior
NF performance prediction approaches can be viewed as adhering
to this blueprint as well [20, 24, 38].
Using a data-driven approach, we tackle the above technical
challenges as follows.
Contentiousness Metrics: As contention happens simultaneously and
independently at multiple points across the memory subsystem,
contentiousness should be measured across multiple dimensions.
We show that a carefully selected set of hardware counters, mea-
suring resource utilization at CPU-socket- and server-level gran-
ularities are sufficient to quantify the contentiousness of a mix of
competing NFs.
Sensitivity Modeling: While the overall sensitivity of a NF is a non-
linear and non-continuous function of a multivariable contentious-
ness vector, we show that it can be accurately modeled as a piece-
wise function of linear models using ensemble techniques from the
machine learning literature [22, 54].
Composition: Aggregate contentiousness metrics can be composed
using simple (e.g., avg, addition) functions allowing us to estimate
the combined contentiousness of any combination of real NFs.
Building on these insights, we design a new NFV performance
prediction framework called SLOMO. Our results show that SLOMO‚Äôs
throughput predictions are accurate, with an average end-to-end
prediction error ‚â§ 8%, while reducing by half the prediction error
of prior work. Furthermore, we demonstrate that SLOMO‚Äôs predic-
tion can improve cluster efficiency by 6-14% when combined with
cluster schedulers designed to meet SLA guarantees.
2 BACKGROUND AND MOTIVATION
We begin by describing the NFV performance prediction problem
(¬ß2.1). Then, we show that prior work suffers poor accuracy with
modern hardware and line rates (¬ß 2.2).
2.1 NFV and Contention
We consider an operator managing a modern NF cluster frame-
work (e.g., E2 [41], OPNFV [10], AT&T Domain 2.0 [2]). The cluster
framework manages and deploys a library of software-packaged
NFs of different types such as firewalls [40], intrusion detection
systems (IDS) [45], WAN optimizers [36], etc. The operator may
purchase similar software from different vendors (e.g., an IDS by
Palo Alto Networks or an open-source Suricata IDS) and for each
such function, they have a desired configuration and an expected
VPNFirewallFlowStatsIP RouterSuricataSnortpfSense0510152025303540Throughput Drop %64 Bytes1500 BytesApplication
Description
Configuration
Stateless Firewall
IP Router
FlowStats
VPN
Maglev LB
Snort
Suricata
PFSense
Stateless firewall (Click)
IP router with RadixIPLookup (Click)
Flow Statistics with AggregateIPFlows (Click)
VPN with IPSec elements (Click)
Maglev Load Balancer (NetBricks [42])
IDS in Intrusion Detection mode
IDS in Intrusion Detection mode
Open Source stateful Firewall
1K sequential rules
130K rules
3600 sec Flow Timeout
Encryption & Authentication
Default Netbricks configuration [42]
Snort3.0 Community Ruleset [13]
Suricata-5.0.1 Ruleset [15]
1K rules
Mpps
8.70
5.75
0.91
0.36
7.50
0.45
0.97
0.150
Table 1: NFs used in SLOMO. The reported throughput corresponds to a solo run of the NF on a Broadwell architecture with 64B packets and 400K unique flows.
Figure 2: Prediction Error of a general-purpose performance prediction
model [39] and Dobrescu‚Äôs CAR-based prediction framework [24]
Figure 3: LLC partitioning leads to inefficient utilization and does not elim-
inate slowdown
This prior work modeled memory as a monolithic source of con-
tention which could be quantified through a single metric, using the
cache access rate (CAR) of the competing NFs as the only quantifier
of contention. This echoed prior work, BubbleUP, a general-purpose
framework which also modeled memory contention and its rela-
tionship to performance using a single metric, using the working
set size of the competing work loads instead [39]. Figure 2 illus-
trates the corresponding prediction error of these techniques when
replicated on modern servers and NFs. In the following sections, we
explain the differences between NFs that result in different levels
of performance drop.
As we discuss in ¬ß3, modern memory architectures are complex
and hence it is insufficient to represent this contention through a
single metric. Indeed, in ¬ß3.1 we demonstrate that by combining
both metrics proposed by Dobrescu and Mars ‚Äì CAR and working
set size ‚Äì one can achieve better predictions than either metric alone.
Furthermore, these two metrics alone are incomplete ‚Äì in ¬ß3.2 and
¬ß3.3 we show that neither CAR nor working set size can measure
the impact of contention over the DDIO cache, nor contention over
bandwidth to main memory.
Performance Isolation: ResQ by Tootoonchian et al. [51] argues
in favor of isolating shared resources to prevent contention-specific
performance degradation. This work leverages Intel‚Äôs Cache Allo-
cation Technology (CAT) and DPDK packet buffer sizing in order
to provide dedicated, non overlapping LLC partitions to the co-
running NFs. However, we find that isolation is an incomplete
solution to managing contention-induced slowdown because par-
titioning tools (e.g., CAT) fail to completely isolate all sources of
contention. In addition, we show that isolation can lead to ineffi-
cient resource utilization.
Figure 3 illustrates these observations through the aggregate
throughput of co-running Click-based IP routers when run with and
without LLC isolation. Each line indicates the aggregate observed
throughput as a function of the number of co-runners. With only 4
co-running identical NF instances and equally-sized dedicated LLC
partitions, we observe 24% lower aggregate throughput compared
to when the NFs share the entire LLC, highlighting the loss of
Figure 4: System resources traversed by a network packet
statistical multiplexing of the LLC and consequently reduced system
efficiency. Furthermore, we observe that the total throughput can
be up to 11% lower than ideal linear scaling, which we would expect
to observe as a result of perfect isolation among the co-runners.
This shows that even if CAT isolated the LLC perfectly, it does
not isolate all possible sources of contention. In ¬ß7, we show that
ResQ‚Äôs approach can be combined with a performance prediction
technique to predict contention-induced slowdown in the presence
of CAT and, in that case, provides better predictability than either
performance prediction or isolation on its own.
3 SOURCES OF CONTENTION
While prior work argues that the memory subsystem is charac-
terized by one primary source of contention, our analysis shows
that, operating at high rates on a modern architecture, contention is