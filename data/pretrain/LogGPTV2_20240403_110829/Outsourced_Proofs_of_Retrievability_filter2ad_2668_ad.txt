(cid:48)
i.
νiσ
νiσi,
σ
µj ← (cid:88)
σ ← (cid:88)
(i,νi)∈QU
(i,νi)∈QU
(cid:88)
s(cid:88)
j=1
Finally, the service provider sends to the auditor the two re-
s, σ(cid:48)). Both
sponses ρ := (µ1, . . . , µs, σ) and ρ(cid:48) := (µ(cid:48)
responses ρ and ρ(cid:48) are signed by S to offer non-repudiation, de-
noted by SigS. The auditor checks the signature of ρ and ρ(cid:48) and
veriﬁes the latter POR response using τA by checking the follow-
ing equality:
1, . . . , µ(cid:48)
(cid:48) ?=
σ
νifk(cid:48)
prf
(i) +
(i,νi)∈QA
(cid:48)
jµ
α
(cid:48)
j.
(1)
If this veriﬁcation does not pass, the auditor informs the user ac-
cording to the contract about problems with the storage of M∗.
The other POR response ρ cannot be checked by A as the corre-
sponding secret τU is known to the user only.
The auditor ﬁnally creates the log entry comprising of the fol-
lowing information:
Λ := (Blt, ρ, SigS (ρ), ρ
(cid:48)
, SigS (ρ
(cid:48)
)).
(2)
Speciﬁcation of the CheckLog Protocol.
3In case of block forks [9], the auditor can make use of the hashes
of one of the block forks that appear at the same height in the block
chain.
We ﬁrst describe how a single entry in log ﬁle can be veriﬁed.
First, the user checks the syntax and veriﬁes the signature of S on
the values ρ and ρ(cid:48). Then, the user determines QU as described in
the POR protocol using Sample(θ, (cid:96)U ) with pseudo-random coins
θ obtained with Blt. Afterwards, the correctness of ρ is checked,
given QU and ρ = (µ1, . . . , µs, σ) analogous to the veriﬁcation of
ρ(cid:48) by the auditor in the POR protocol. Note that the user cannot
verify ρ(cid:48) without τA—this stronger veriﬁcation of ρ(cid:48) can only be
performed in a “forensic” analysis with the protocol ProveLog.
As a minimal check, the user can check the last entry since this
reﬂects the most recent state of retrievability for the ﬁle or a sub-
set of entries.
In Fortress the user has the possibility to check
the POR accumulated over a batch of log entries. U selects a
random subset B of indices of Bitcoin blocks and sends them to
the auditor. A responds by accumulating the responses: ρ(b) =
(µ(b)
s , σ(b)) for b ∈ B into one response
1 , . . . , µ(b)
(cid:32)
µ(B)
1
:=
µ(b)
1 , . . . , µ(B)
s
:=
µ(b)
s , σ(B) :=
σ(b)
.
(cid:33)
(cid:88)
b∈B
(cid:88)
b∈B
The user reconstructs the challenges QU Blb for the selected entries
from the Bitcoin block Blb with GetRandomness and checks:
b∈B
(cid:88)
(cid:88)
b∈B
(cid:88)
(i,νi)∈Q
BlbU
σ(B) ?=
νifkprf (i)
αjµj
(B).
 +
s(cid:88)
j=1
If the user’s check fails, the user will assume that either A or S
is malicious and takes actions such as attempting to download the
ﬁle or starting an analysis with ProveLog.
Speciﬁcation of the ProveLog Protocol.
The ProveLog algorithm provides stronger means for analyzing
the correct behavior of the auditor when compared to CheckLog.
ProveLog requires that the auditor must reveal his secret token τA
and open the log Λ. In addition to the veriﬁcations in the CheckLog
protocol, every server response ρ(cid:48) to the auditor will be veriﬁed
in ProveLog using τA. Additionally, the correctness of τA will
be veriﬁed, by recomputing commitments and verifying the user’s
signature generated in the Store protocol during the veriﬁcation of
the auditor’s σi values.
If all veriﬁcations pass, the auditor can
prove that it has executed all protocols correctly.
3.3 Security Analysis
In the following, we show that Fortress is secure according to
Deﬁnitions 1 and 2 (cf. Section 2.2) with respect to any constella-
tion of corrupted parties.
ε-extractability: We start by discussing the ε-extractability prop-
erty of Fortress (Deﬁnition 1). Observe that if a scheme is secure
with respect to a set of corrupted parties C, it automatically is se-
cure with respect to any subset C(cid:48) (cid:40) C. Hence, to show our claim
it sufﬁces to consider the three cases where exactly one party is
honest. First, we discuss the scenario where the user (and only the
user) is honest. We want to show that if ρ produced by (A,S) as
output of CheckLog is accepted with some probability ≥ ε by the
user, then the ﬁle can be extracted by a means of an extraction algo-
rithm. Recall that the log ﬁles actually contain the responses of the
service provider S for a POR protocol that has been executed by
the auditor on behalf of the user but without knowing τU . Thus, as
long as the auditor followed the POR protocol, security is directly
inherited from PSW.
More precisely, one can show similar to [35] that if correct re-
sponses to the challenges can be produced, then an extractor can
be described that can extract the ﬁle. As neither the auditor nor
the service provider know τU , this still holds even if both collude.
However, we note an important difference: while in [35] the chal-
lenge (I,{(i, νi)}i∈I ) is randomly sampled, challenges in Fortress
are generated pseudo-randomly using the pseudo-random bit gen-
erator g with a seed extracted with GetRandomness. However, we
argue that this does not bear any practical implication. To see why,
let Chl denote the set of all possible challenges that can be pro-
duced using g. Observe that the seed to the g are coming from
GetRandomness which derives the output from uniquely deter-
mined Bitcoin blocks. This has the consequence that each seed
is possible and none of the seeds can be predicted or the adversary
would gain the power to create Bitcoins at will. Hence, if an at-
tacker wants to exploit the fact that the challenges are created using
g, the attacker could be easily transformed into an efﬁcient distin-
guisher for the g outputs which would contradict the security of g.
Observe that the user checks within the CheckLog procedure that
the correct challenges have been used. Hence, any deviation from
this process, i.e., if other challenges are used, would be detected by
the user who would abort. This concludes the ﬁrst case. The same
argumentation can be applied to the case that the auditor is honest.
It remains to address the ﬁnal case, where the service provider is
honest while the other parties are malicious. We have to show that
from the fact that the service provider does not abort, it follows
that the ﬁle can be reconstructed. First of all, the service provider
does not check any responses. Hence, the only situation where he
may abort is during the initialization phase of Store, e.g., if the
wrong ﬁle has been signed, etc. If this has not happened, then S
will follow honestly the protocol and in particular store the whole
ﬁle M∗. This means of course that the honest party, i.e., the service
provider, is able to recover the ﬁle.
Summing up, we have argued that for any constellation of ma-
licious parties, it holds that if the probability that the honest user
aborts is below a certain threshold, the ﬁle can be reconstructed.
1, . . . , α(cid:48)
s is valid. Likewise, the values fk(cid:48)
Liability: With respect to liability (Deﬁnition 2), we have to show
that an honest auditor can prove the correctness of the log ﬁles with
high probability while a misbehaving auditor will fail. Recall that
the notion of liability is only deﬁned for scenarios where either the
user or the auditor are malicious (but not both). First, we argue
that the values σ(cid:48)
i have been computed correctly. If the auditor is
honest, it follows the protocol and computes the values correctly.
Assume now that the auditor is malicious. Observe that any choice
for α(cid:48)
(i) can safely
be replaced by some random values ri ∈ F. Thus, any choice
of these is correct. Moreover, due to the ZKPs it is ensured that
the auditor knows these values. The only possibility for an auditor
to misbehave is hence to output instead of a correct tuple (σ(cid:48)
i, q(cid:48)
i)
a different tuple (˜σ, ˜q) (cid:54)= (σ(cid:48)
i). Here, output means that the
ﬁrst entry is given out in clear while the other is indirectly given
by a commitment together with an appropriate ZKP. Clearly, this
implies that the auditor knows the tuple (˜σ, ˜q). Moreover, as the
auditor also knows the values α(cid:48)
j and ri, he also knows the correct
tuple (σ(cid:48)
i). Summing up, the auditors knows two different tuples
such that:
i, q(cid:48)
i, q(cid:48)
prf
(cid:48)
i + q
This is equivalent to:
σ
i · p ≡ ˜σ + ˜q · p
(cid:48)
mod ϕ(N ).
i − ˜σ ≡ (˜q − qi) · p
(cid:48)
σ
mod ϕ(N ).
(3)
We show now that this information allows the auditor to factorize
i − ˜σ ≡ 0 modulo ϕ(N ). As both values are
N. Assume ﬁrst that σ(cid:48)
less than p  ˜σ. It holds that 0 < σ(cid:48)
loss of generality that σ(cid:48)
hence (˜q − qi) · p − (σ(cid:48)
i − ˜σ) is a multiple of ϕ(N ). The same ar-
guments then can be applied as above. In conclusion, in both cases
the auditor is either generating the parameters correctly or the user
would abort the protocol.
Observe that from now on, all POR executions conducted by
the auditor are deterministic in the sense that the auditor has no
inﬂuence on the involved parameters. The points in time when
the protocol execution should take place are dictated by the con-
tract. The random bits used at these points in time are coming from
GetRandomness and can be reconstructed later on. The veriﬁca-
tion of the responses are based on the secrets of the auditor only
to which commitments have been done in the beginning. Hence,
any party who knows τA can reconstruct what should have hap-
pened in the respective POR executions and can compare these
with the log ﬁles. Hence, as long as none of the underlying cryp-
tographic building blocks are broken, this yields an objective proof
for a well-behaving auditor that everything has been conducted cor-
rectly while ensuring that any misbehaviour would be detected.
4.
IMPLEMENTATION & EVALUATION
In this section, we evaluate an implementation of Fortress within