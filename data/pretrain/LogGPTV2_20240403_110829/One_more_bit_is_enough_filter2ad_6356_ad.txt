parameter ξ(ρ(t)) based on the load factor ρ(t).
(cid:80)N
i=1 wi(t − T )
γCT
ρ(t) =
,
(11)
1
T
(cid:80)N
where wi(t) is the ﬂow i’s congestion window at time t, C
is the link capacity, and 0  0. We assume the initial condition w(t) = N
(i.e., wi(t) = 1), for all t ∈ [−T, 0]. In [66], we prove the
following global stability result.
Theorem 1. Under the model (9), (10) and (11) where
a single bottleneck is shared by a set of synchronous ﬂows
with the same RTT, if κ ≤ 1
2 , then the delayed diﬀerential
equation (13) is globally asymptotically stable with a unique
equilibrium w∗ = γCT + N α
κ , and all the ﬂows have the
same steady-state rate r∗
i = γC
N + α
κT .
This result has two implications. First, the suﬃcient con-
dition κ ≤ 1
2 holds for any link capacity, any feedback delay,
and any number of ﬂows. Furthermore, the global stability
result does not depend on the network parameters. Second,
this result is optimal in that at the equilibrium, the system
achieves all the design goals: high utilization, fairness, zero
steady-state queue length, and zero packet loss rate—this is
because we can always adjust γ such that the system stabi-
lizes at a steady-state utilization slightly less than 1.
Importance of γ: While (11) deﬁnes γ as the target
utilization, the actual utilization is w∗
κP where
P = CT
N is the per-ﬂow BDP. To achieve a certain target
utilization γ∗, γ should be treated as a control variable and
set to γ = γ∗ − α
κP . For more details on how to make this
adjustment process automatic without even knowing α, κ
and P , we refer the reader to [66].
CT = γ + α
2Theorem 2 actually proves the max-min fairness for a general
multiple-bottleneck topology. For a single link, max-min fairness
means each ﬂow gets an equal share of the link capacity.
Next, we consider a more general multiple-bottleneck net-
work topology. Let ρi(t) denote the maximal link load fac-
tor on ﬂow i’s path Li that includes a subset of links, i.e.,
Li = { l | ﬂow i traverses link l}. The MI parameter of ﬂow
i is then
ξ(ρi(t)) = κ · [
1
ρi(t)
− 1 ],
(cid:80)
i∈Il
wi(t−T )
(14)
where ρi(t) = maxl∈Li ρl(t), ρl(t) =
, and the
subset of ﬂows Il = { i | ﬂow i traverses link l}. We prove
the following fairness result in [66].
γClT
Theorem 2.
In a multiple-bottleneck topology where all
ﬂows have the same round-trip time T , if there exists a
unique equilibrium, then the algorithm deﬁned by (9) and
(14) allocates a set of max-min fair rates r∗
where ρ∗
maxl∈Li
κT (1−
(cid:80)
i =
w∗
i
α
.
l =
i∈Il
γCT
1
)
ρ∗
l
To better understand this result note that a ﬂow’s sending
rate is determined by the most congested bottleneck link
on its path. Thus, the ﬂows traversing the most congested
bottleneck links in the system will naturally experience the
lowest throughputs.
Having established the stability and fairness properties of
the MIAIMD model, we now turn our attention on the con-
vergence of the VCP protocol. The following two theorems,
proved in [66], give the convergence properties.
Theorem 3. The VCP protocol takes O(log C) RTTs to
claim (or release) a major part of any spare (or over-used)
capacity C.
Theorem 4. The VCP protocol takes O(P log ∆P ) RTTs
to converge onto fairness for any link, where P is the per-
ﬂow bandwidth-delay product, and ∆P > 1 is the largest
congestion window diﬀerence between ﬂows sharing that link.
Not surprisingly, due to the use of MI in the low-load
region, VCP converges exponentially fast to high utilization.
On the other hand, VCP’s convergence time to fairness is
similar to other AIMD-based protocols, such as TCP+AQM.
In contrast, explicit feedback schemes like XCP require only
O(log ∆P ) RTTs to converge to fairness. This is because
the end-host based AIMD algorithms improve fairness per
AIMD epoch, which includes O(P ) rounds of AI and one
round of MD, while the equivalent operation in XCP takes
only one RTT.
The VCP protocol can be viewed as an approximation of
the MIAIMD model along three axes. First, the MIAIMD
model uses the exact load factor feedback, ρ(t), while VCP
uses a quantized value of the load factor. Second, in the
MI and AI phases, VCP uses either the multiplicative factor
or the additive factor term, but not both as the MIAIMD
model does. Third, in the overload region, VCP applies a
constant MD parameter β instead of ξ(ρ(t)).
The comparison between the simulation results of VCP
and the analytical results of the MIAIMD model suggests
that the two diﬀer most notably in terms of the fairness
model. While in the case of multiple bottleneck links, the
MIAIMD model achieves max-min fairness [4], VCP tends
to allocate more bandwidth to ﬂows that traverse fewer bot-
tleneck links (see Section 4.2). This is because VCP relies
on the quantized representation of the load factor instead of
the exact value.
routerρξtt−Tsourcedestinationtime6. DISCUSSIONS
Since VCP switches between MI, AI, and MD algorithms
based on the load factor feedback, there are natural concerns
with respect to the impact of these switches on the system
stability, eﬃciency, and fairness, particularly in systems with
highly heterogeneous RTTs. We discuss these concerns in
this section. We discuss VCP’s TCP-friendliness and incre-
mental deployment in [66].
6.1 Stability under Heterogeneous Delays
Although the MIAIMD model presented in Section 5 is
provably stable, it assumes synchronous feedback. To ac-
commodate heterogeneous delays, VCP scales the MI/AI
parameters such that ﬂows with diﬀerent RTTs act as if
they were having the same RTT. This scaling mechanism
is also essential to achieving fair bandwidth allocation, as
discussed in Section 3.4.
In normal circumstances, VCP makes a transition to MD
only from AI. However, even if VCP switches directly from
MD to MI, if the demand traﬃc at the router does not
change signiﬁcantly, VCP will eventually slide back into AI.
Finally, to prevent the system from oscillating between
MI and MD, we set the load factor transition point ˆρl to
80%, and set the MD parameter β to 0.875 > ˆρl. This gives
us a safety margin of 7.5%.
The extensive simulation results presented in Section 4
suggest that VCP is indeed stable over a large variety of net-
work scenarios including per-ﬂow bandwidths from 2Kbps to
100Mbps and RTTs from 1ms to 1.5s.
6.2 Inﬂuences of Mode Sliding
From an eﬃciency perspective, VCP’s goal is to bring and
maintain the system into the high utilization region. While
MI enables VCP to quickly reach the high link utilization,
VCP needs also to make sure that the system remains in this
state. The main mechanisms employed by VCP to achieve
this goal is the scaling of the MI/AI parameters for ﬂows
with diﬀerent RTTs. In addition to improving fairness, this
scaling is essential to avoid oscillations. Otherwise, a ﬂow
with a low RTT may apply MI several times during the
estimation interval, tρ, of the link load factor. Other mech-
anisms employed by VCP to maintain high eﬃciency include
choosing an appropriate value of the MD parameter to re-
main in the high utilization region, using a safety margin be-
tween MI and AI, and bounding the burstiness (Section 4.3).
As discussed in Section 3.4, there are two major concerns
with respect to fairness. First, a ﬂow with a small RTT
probes the network faster than a ﬂow with a large RTT.
Thus, the former may increase its bandwidth much faster
than the latter. Second, it will take longer for a large-RTT
ﬂow to switch from MI to AI than a small-RTT ﬂow. This
may give the large-RTT ﬂow an unfair advantage. VCP ad-
dresses the ﬁrst issue by using the RTT scaling mechanism
(see (6)-(7)). To address the second issue, VCP bounds the
MI gain, as discussed in Section 4.3. To illustrate the eﬀec-
tiveness of limiting the MI gain, Figure 12 shows the con-
gestion window evolution for two ﬂows with RTTs of 50ms
and 500ms, respectively, traversing a single 10Mbps link. At
time 12.06s, the 50ms-RTT ﬂow switches from MI to AI. In
contrast, due to its larger RTT, the 500ms-RTT ﬂow keeps
performing MI until time 12.37s. However, because VCP
limits the MI gain of the 500ms-RTT ﬂow, the additional
Figure 12:
The congestion window dynamics of
two ﬂows with dramatically diﬀerent RTTs (50ms vs.
500ms). Due to its longer delay, the larger-RTT ﬂow al-
ways slides its mode later than the one with smaller RTT
(see the regions labeled as A and B). However, the ef-
fect of this asynchronous switching is accommodated by
VCP and does not prevent it from maintaining stability
and achieving eﬃciency and fairness.
bandwidth acquired by this ﬂow during the 0.31s interval
is only marginal when compared to the bandwidth acquired
by the 50ms-RTT ﬂow.
7. RELATED WORK
This paper builds upon a great body of related work, par-
ticularly XCP [35], TCP [25, 1, 17, 51], AIMD [10, 29],
AQM [18, 2, 42] and ECN [57, 58]. Congestion control is
pioneered by TCP and AIMD. The research on AQM starts
from RED [18, 47], followed by Blue [14], REM [2], PI con-
troller [23], AVQ [21, 42], and CHOKe [54], etc. Below we
relate VCP to three categories of congestion control schemes
and a set of analytical results.
Explicit rate based schemes: XCP regulates source
sending rate with decoupled eﬃciency control and fairness
control and achieves excellent performance. ATM ABR ser-
vice (e.g., see [40, 9, 33, 27, 34]) previously proposes explicit
rate control. VCP learns from these schemes. In contrast,
VCP is primarily an end-host based protocol. This key dif-
ference brings new design challenges not faced by XCP (and
the ATM ABR schemes) and thus VCP is not just a “two-
bit” version of XCP. The idea of classifying network load
into diﬀerent regions is originally presented in [28]. The link
load factor is suggested as a congestion signal in [27], based
on which VCP quantizes and encodes it for a more compact
representation for the degree of congestion. MaxNet [65]
uses the maximal congestion information among all the bot-
tlenecks to achieve max-min fairness. QuickStart [26] oc-
casionally uses several bits per packet to quickly ramp up
source sending rates. VCP is complementary to QuickStart
as it constantly uses two bits per packet.
Congestion notiﬁcation based schemes: For high BDP
networks, according to [35], the performance gap between
XCP and TCP+RED/REM/AVQ/CSFQ [60] with one-bit
ECN support seems large. VCP generalizes one-bit ECN
and applies some ideas from these AQM schemes. For exam-
ple, RED’s queue-averaging idea, REM’s match-rate-clear-
buﬀer idea and AVQ’s virtual-capacity idea obviously ﬁnd
themselves in VCP’s load factor calculation in Equation (1).
This paper demonstrates that the marginal performance gain
from one-bit to two-bit ECN feedback could be signiﬁcant.
On the end-host side, two-bit ECN is also used to choose
diﬀerent decrease parameters for TCP in [13], which is very
diﬀerent from the way VCP uses. GAIMD [68] and the bino-
BAMD  AIMI ==> AI 0 10 20 30 40 50 60 70 80 0 5 10 15 20Congestion Window (packets)Time (sec)flow with rtt =  50msflow with rtt = 500msmial control [3] generalize the AIMD algorithm, while VCP
goes even further to combine MIMD with AIMD.
Pure end-to-end schemes: Recently there have been
many studies on the end-to-end congestion control for high
BDP networks. HighSpeed TCP [15] extends the standard
TCP by adaptively setting the increase/decrease parame-
ters according to the congestion window size. H-TCP [45]
employs an adaptive AIMD with its parameters set as func-
tions of the elapsed time since the last congestion event.
Adaptive TCP [38] also applies dynamic AIMD parameters