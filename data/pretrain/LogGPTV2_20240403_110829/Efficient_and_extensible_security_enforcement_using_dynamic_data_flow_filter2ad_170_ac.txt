attacks, we can supply a custom handler in the form of a C func-
tion that checks the taintedness of the keywords in the query string,
accepting strings with untainted keywords. To ensure soundness,
we require that a user-deﬁned handler never reject an event that the
typestate analysis accepts, which ensures that the typestate analysis
over-approximates the actual policy.
A key advantage of our system is the compiler’s access to the
semantics of the security analysis. Our annotations deﬁne what
analysis to perform, not how to perform the analysis. In addition to
being simpler to reason about, declarative policies allow our system
to perform an efﬁcient static analysis, described in Section 4.4, that
over-approximates dynamic behavior. It is this static analysis that
allows our system to achieve the low overheads that we will discuss
in Section 5
4.3.1
Specifying Taintedness
In this section, we will use taint tracking and format string at-
tacks to brieﬂy illustrate the annotation language in Figure 3. The
annotations on lines 1-16 describe a data ﬂow analysis, in this case
a taint analysis, as we now explain.
On line 1, the property keyword deﬁnes one lattice with two
possible values, Tainted and Untainted. We place Untainted above
Tainted on the lattice so that Tainted and Untainted values combine
to yield Tainted values.
We then annotate the library procedures that introduce tainted-
ness, such as recv on line 4. Here, the on_entry keyword at
line 5 allows us to assign a name, buffer, to the object pointed
to by the pointer buf. The analyze keyword indicates that when
the recv routine is invoked, buffer (not buf, which is a pointer)
becomes tainted. In addition, we inform the compiler that this pro-
cedure modiﬁes buffer.
Similarly, we also annotate library procedures that propagate
taintedness, such as strdup. Again, the on_entry and on_exit
keywords (lines 11–14) describe relations between pointers and the
objects they point to, while the access and modify lines specify
that the function reads from string and writes to string_copy.
The policy itself is deﬁned on line 21 by using the results of the
taint analysis when printf is called. Here, we specify that an er-
ror occurs if format_string (the string that format points to)
could be tainted. This line speciﬁes the entire policy with respect to
the printf procedure–other taint-based policies could be added
that would reuse all the taint tracking annotations as-is.
Similar annotations have been used in other systems for error
checking. For example, CQUAL [42] uses type qualiﬁer annota-
tions on library functions to statically check for format string vul-
nerabilities. Although slightly less verbose than the Broadway an-
notation language, their type system permits “reverse ﬂows” and
other artifacts that increase the false positive rate. Because our sys-
tem is based on a more precise data ﬂow analysis, we are able to
avoid such anomalies while also being able to leverage far more
precise pointer analysis (see Section 4.4.2). The actual annotation
burden—which is only incurred when deﬁning new policies—is
discussed in Section 5.4
4.3.2
Specifying File Disclosure
To illustrate the ﬂexibility of our system, we also apply it to ﬁle
disclosure vulnerabilities. File disclosure can occur when a remote
user can connect and download the contents of arbitrary ﬁles, thus
improperly revealing sensitive information. This vulnerability can
be present when a program behaves unintentionally like an FTP
server; that is, if the remote user can specify the name of a ﬁle
whose contents are then sent over the network. Note that sending
data from ﬁles not directly speciﬁed by the user is ﬁne, as is sending
responses constructed from user input. In essence, ﬁle disclosure
is a simple privacy protection problem where the goal is to ensure
that untrusted users cannot directly specify data to access. These at-
tacks are not well-studied on C programs because overwrite attacks
account for the majority of C vulnerabilities. However, these vul-
nerabilities are common among web applications written in script-
ing languages such as PHP, Python, and Perl. Thus, our techniques
remain relevant and applicable to safe languages.
File disclosure cannot be modeled with only taint tracking be-
cause taint tracking does not distinguish between the source of data
and the trustedness of data. A taint tracking system could disal-
low the transmission of tainted data, but such a policy would also
prevent legitimate echoes of network input. The taint tracker could
also disallow transmission of any ﬁle data, but such a policy also
eliminates legitimate transfers and would even prevent most query
services from operating. To model ﬁle disclosure accurately, the
system must track both the trustedness (whether the data is under
attacker control) and the origin (whether the data comes from a ﬁle)
of data within the system.
File disclosure is straightforward to model in our system. We
ﬁrst deﬁne two properties, Trust and Kind. Trust represents the
trustworthiness of the data source, which can be Internal to the pro-
gram, External to the program but on the local system, or obtained
from a Remote source. Kind denotes the possible source of the data,
be it from a File, standard I/O, the network, or otherwise. A ﬁle dis-
closure attack occurs when File data with Remote trustworthiness
is written to a Remotely opened socket. The required procedure
summary annotations themselves are similar to those for format
string attacks and are omitted here. This policy precisely models
the FTP-like behavior described earlier, disallowing ﬁle disclosure
while permitting other ﬁle data or other user-derived data to be sent.
4.3.3 Other Problems
Although we focus on the above two problems in this paper, our
system can be used to enforce a wide variety of problems. Lat-
tices are a natural model for many security problems [5, 18, 8].
For example, multilevel security can be implemented with a lattice
representing hierarchical levels, such as Unclassiﬁed, Classiﬁed, or
TopSecret, along with properties representing categories, such as
Army, Navy, etc. Library I/O functions would be annotated to call
a user-provided helper function to read the appropriate label from
the ﬁle, while the annotations for operations like string copy would
remain essentially identical to those for taint tracking or ﬁle disclo-
sure. For additional information on the Broadway language and its
capabilities, please refer to prior work [22, 23, 21].
4.4 Static Data Flow Analysis
To avoid the cost of tracking all objects at runtime, our com-
piler statically performs an interprocedural data ﬂow analysis that
identiﬁes program locations where policy violations might occur.
Starting from these possible violations, a subsequent interprocedu-
ral analysis identiﬁes statements in the program that affect the ﬂow
values—and therefore the policy decision—at these violations. Other
statements do not require instrumentation because they cannot af-
fect the relevant ﬂow values and thus cannot affect policy enforce-
ment decisions. This analysis is supported by a fast and precise
pointer analysis, which is critical because a less precise pointer
analysis would identify many more program locations as possibly
violating the speciﬁed policy [23], leading to higher runtime over-
head. We now discuss these steps in detail in the following subsec-
tions.
4.4.1
Static Vulnerability Analysis
The ﬁrst step is to statically check the program to identify all
possible violations of the security policy as deﬁned by the anno-
tations [23]. If the compiler can prove that there are no such vi-
olations in the program, no further analysis or code insertion is
required. However, in cases where the compiler identiﬁes possible
violations, additional analysis is needed to determine where instru-
mentation should be inserted.
To perform this ﬁrst step, our system uses an iterative static data
ﬂow analysis that is performed by the Broadway static analysis sys-
tem [21]. Because the analysis is sound, these locations are the only
locations where violations of the policy can occur. In Section 4.4.3,
we explain how our system ensures that all of these possible viola-
tions are guarded against.
4.4.2 Pointer Analysis
A signiﬁcant obstacle to interprocedural program analysis is the
use of pointers. To reason precisely about the ﬂow of data, the
compiler must know which objects a pointer could point to. The
limited scalability of pointer analysis has stymied previous attempts
to apply interprocedural analysis to dynamic taint tracking [31], so
interprocedural analysis is not commonly used.
Our system uses a scalable and precise client-driven pointer anal-
ysis [23, 21]. The client-driven analysis is able to match the preci-
sion of a fully ﬂow- and context-sensitive pointer analysis without
requiring signiﬁcantly more runtime than a fast and imprecise ﬂow-
and context-insensitive analysis. Unlike most pointer analyses, the
client-driven analysis cannot be used as a stand-alone pointer anal-
ysis. Instead, it requires a client that uses the results of the analysis,
which in our system is the static data ﬂow analysis that identiﬁes
possible policy violations. By identifying locations where impre-
cision in the pointer analysis affects the precision of the client’s
results, the client-driven analysis is able to selectively increase pre-
cision for the pointer analysis in places where it will improve the
results of the client analysis. Because the amount of extra pre-
cision is typically small [23], the client-driven analysis is able to
avoid analyzing pointer relations that do not affect the client, dra-
matically improving scalability without sacriﬁcing precision with
respect to the client. The client itself must be a lattice-based data
ﬂow analysis, so we see now how our annotation language’s declar-
ative speciﬁcation of data ﬂow analysis plays an important role in
minimizing runtime overhead.
Finally, we note that the client-driven approach does not impact
the soundness of the pointer analysis. Precise pointer analysis is
an undecidable problem, so almost all pointer analyses, including
ours, compute a conservative over-approximation of the actual re-
sult. In particular, our pointer analysis is sound under the assump-
tion that displacements between objects are undeﬁned, a necessary
assumption common to C pointer analyses [3].
4.4.3 Data Flow Slicing
The static error checker identiﬁes possible vulnerabilities by lo-
cation and memory object. Our system must ensure that all the
dynamic checks that are required to prevent possible vulnerabili-
ties are performed correctly. We refer to the process of computing
the statements that require instrumentation as data ﬂow slicing, by
analogy with program slicing [47].
We deﬁne a data ﬂow slice with respect to some object o at some
program location l to be the set S of statements and locations that
affect a set O of objects, computed by the transitive closure as fol-
lows:
• l is in S and o is in O.
• If statement s′ deﬁnes the ﬂow value of some v ∈ O, then s′
is in S.
• If statement s ∈ S uses the ﬂow value of some o′, then o′ is
in O.
In contrast with a program slice, which is the portion of the program
necessary for computing the value of o at location l, a data ﬂow
slice is the portion of the program that affects the ﬂow value of o at
l. For example, a statement that increments a counter will change
the counter’s concrete value but not its taintedness. Since the ﬂow
value does not change, this statement is not part of the data ﬂow
slice. Moreover, implicit ﬂows and branch conditions are not part
of the data ﬂow slice because they cannot affect the ﬂow values
for a tag-based data ﬂow analysis, but they are a part of a program
slice.
As long as the underlying pointer analysis is sound, data ﬂow
slicing is a sound method for identifying statements that affect ﬂow
values: A statement can affect ﬂow values only by deﬁning them.
If statement s affects the ﬂow value of object o at location l, it is
by deﬁnition in the data ﬂow slice, and statements that affect o at
l through intermediate assignments are also included because the
data ﬂow slice is a transitive closure.
Data ﬂow slicing is an interprocedural dependence analysis that
tracks dependences in terms of ﬂow values instead of concrete val-
ues. Our compiler computes data ﬂow slices by ﬁrst constructing
interprocedural use-def chains, which allows it to identify all pos-
sible deﬁnitions for any given use of an object. The data ﬂow slice
is always a subset of the locations in the use-def chains, as a ﬂow
value cannot change without a def (but as we have mentioned, not
all defs change the ﬂow value).
Our data ﬂow slicing algorithm is also able to truncate the slice
when ﬂow values are deﬁnitely known. Since the static data ﬂow
analysis is an over-approximation of possible dynamic behavior, a
statically computed exact ﬂow value means that the object will al-
ways have that ﬂow value at that location at runtime. For server
programs and taint tracking, this optimization has the effect of
moving instrumentation away from input functions and closer to
the data directly involved in checks. In several of our programs,
input is read into a buffer, which is immediately copied to another
buffer. The copy is then used for subsequent operations. Our static
analysis can determine that the copy is always tainted, rendering
further backwards tracing unnecessary. The resulting program thus
does not need to instrument the input buffer, instead directly mark-
ing the copy as tainted.
This optimization has an interesting side effect: At times, the
tags of some addresses will not be up-to-date. However, we can
guarantee that any piece of information will be up-to-date when it
is used to make a security decision. Thus, the system is as secure
as a fully instrumented system, but it does not pay the performance
penalty of keeping all tags up-to-date at all times.
Another consequence of our technique is that a more complex
policy or program does not necessarily result in higher overhead.
The actual overhead depends on the policy, the program, and the
way in which the program might violate the policy. A more com-
plex policy can result in lower overhead when the portion of the
program involved is smaller or off the critical path. In Section 5.3,
we see that guarding against ﬁle disclosure vulnerabilities can of-
ten have even lower overhead than taint tracking despite being a
signiﬁcantly more complex problem. Larger programs also do not
necessarily experience higher overhead; in fact, in our results (Sec-
tion 5.1.3), the highest overhead for server programs is for the
smallest program.
Once the data ﬂow slice from a potential vulnerability is com-
puted, it is straightforward to add instrumentation to these program
locations. The data ﬂow slice includes all information that impacts
the ﬂow value at the potential vulnerability, so the check will eval-
uate to the same result as a fully-instrumented system.
4.5 Security Discussion
We now examine the security-related assumptions and advan-
tages of our system.
4.5.1 Trusted Computing Base
As with other software taint tracking solutions, our system in-
creases the size of the TCB, in our case adding the compiler to
the TCB. Although there are security implications [45] to trusting
the compiler, the additional trust required by our approach is mit-
igated by two factors. First, in typical modern environments, the
compiler (usually gcc or some other widely used compiler) is al-
ready trusted to compile the server programs that are actually run.
Second, our source-to-source translator relies on the user’s already
trusted compiler for generating binary code. The changes and mod-
iﬁcations that our system makes to programs are thus transparent
and human-readable, making it difﬁcult to insert undetected ma-
licious code. Thus, our system requires minimal additional trust
beyond that which is already present in most deployed systems.
Like any system based on user-deﬁned policies, the policies them-
selves are also a part of the trusted computing base. If the annota-
tions that summarize the effects of external functions are incorrect
or incomplete, the system may miss important data ﬂow. Such an
error is analogous to a bug or omission in a hardcoded taint track-
ing system. Fortunately, frequently-used external code resides in
libraries like the C Standard Library that are relatively robust and
whose semantics are well-understood, and we have found that pro-
viding accurate annotations for these functions is straightforward.
4.5.2 Attacks Detected
Our system is capable of detecting attacks that depend on the
propagation of data through the system. More speciﬁcally, we can
enforce any typestate policy, which includes traditional taint-based
attacks as well as general information ﬂow tracking [31]. These
attacks include those that do not overwrite control data or violate
data ﬂow integrity and thus are problems even in safe languages.
In our evaluation, we enforce a taint-based policy that prevents
format string attacks, similar to the format string policies used by
existing taint tracking systems, such as TaintCheck [37], as well
as interpreters with taint tracking modes [46, 38]. In addition, our
system can enforce a policy that prevents attacker-controlled data
leaks such as ﬁle disclosure vulnerabilities; this policy cannot be
enforced precisely by an ordinary taint tracking system.
Our system only guarantees that violations of the speciﬁed policy
do not occur. This situation is shared by all enforcement mechanisms—
for example, a memory-safe database server can still be compro-
mised by an SQL injection attack because such attacks do not vi-
olate memory safety. The soundness of our analysis prevents any
attacks that violate the policy. However, if it is possible for the at-
tacker to gain control through an attack that does not violate the
policy, it may be possible to compromise the application.
4.5.3 Alternate Attack Channels
Like other taint tracking systems, we do not concern ourselves