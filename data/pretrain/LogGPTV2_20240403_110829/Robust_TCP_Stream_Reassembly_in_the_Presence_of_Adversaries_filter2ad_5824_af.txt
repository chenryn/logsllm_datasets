### Buffer Management Policy and Its Impact

If the number of out-of-sequence packets for a connection is less than 20,000, no damage occurs, as the buffer is large enough to accommodate these packets (provided none exceeds the threshold of 25 KB).

To summarize, our buffer management policy consists of three rules:
1. **Rule 1:** Limit the reordering buffer consumed by each connection to a predefined threshold (carefully chosen through trace-driven analysis).
2. **Rule 2:** Upon overflow, randomly evict a page to assign to a new packet.
3. **Rule 3:** Do not evict a connection if it has fewer than three packets in the buffer.

Let's reflect on the implications of a naive buffer management policy that only includes Rule 2. If we simply randomly evict a page upon overflow, we note that without Rule 3, the option of not evicting a connection upon its page eviction is ruled out, making the system vulnerable to evasion.

### Comparative Analysis

Figure 8 compares the eviction rates for the devised buffer management policy (Rules 1, 2, and 3) and a naive policy of just random eviction (only Rule 2). The total available memory was assumed to be 512 MB, and the average buffer occupancy of benign connections was assumed to be 30 KB. The zombie rate is 10 Mbps.

![Comparison of Eviction Rates](path_to_figure_8)

Given that a buffer eviction is equivalent to a connection eviction, we lose the improvement provided by Eqn 6 (thus, now \( E = e \)). In the absence of Rules 1 and 3, Cases 1 and 2a do not come into play; the system behaves as it would in Case 2b. Hence, the benign connection eviction rate is the same as given by Eqn 4.

As shown in Figure 8, with the application of Rules 1 and 3, we significantly reduce the damage to legitimate connections.

### Designing for the General Case

Our approach so far has been to design a system that handles the most common case of packet reordering, i.e., the occurrence of a single hole, at the cost of reduced TCP performance (even when not under attack) for the rare case of multiple concurrent holes. In this section, we explore the design space for handling the case of multiple concurrent holes in a single connection.

It is important to note that any mechanism we design will have resource limitations. Therefore, no matter how we configure our system, it is possible to encounter a pathological case (e.g., a very large number of concurrent holes in a connection—a semantically valid case) that will force us to break end-to-end semantics. Our previous trace analysis provides a "reasonable" set of cases that merit engineering consideration. Specifically, the observation that more than 95% of the connections have just a single concurrent sequence hole presents a compelling case for designing for this scenario.

Unfortunately, when we analyze multi-hole connections, no modality appears as sharp as the distinction between single-hole and multi-hole connections. Thus, picking a "reasonable" number of per-connection holes is difficult. For instance, the trace T3 shows that a connection can exhibit 85 concurrent holes, though this reflects pathological behavior where a Web server returned an item in a single, large burst of several hundred six-byte chunks, many of which were lost.

Allowing multiple concurrent holes requires maintaining per-hole state. The key difficulty here is that we cannot afford to use a large, arbitrarily extensible data structure such as a linked list. Once the data structure's size exceeds what we can store in on-chip RAM, an adversary can cause us to consume excessive CPU cycles iteratively traversing it off-chip. On the other hand, if we expand the size of each connection record to accommodate \( N \) holes rather than 1, which allows us to make a small number of off-chip accesses to find the hole, this costs significant additional memory.

Since most connections have zero or one hole, we can realize significant memory savings by differentiating between the two types of connections: connections with at most one hole (per the data structure in our current design) and connections with up to \( N \) holes. We could partition memory to support these two different types. Connections initially exist only in the at-most-one-hole partition. As necessary, we would create an additional record in the multiple-holes partition. We would likely keep the original record, too, so we can easily locate the record for newly-received packets by following a pointer in it to the additional record.

A key issue here is sizing the second partition. If it is too large, it defeats the purpose of saving memory by partitioning. On the other hand, if it is small, it becomes a potential target for attack: an adversary can create a number of connections with multiple holes and flood the second partition. Given this last consideration, we argue that extending the design for handling multiple sequence holes within single connections yields diminishing returns, given the resources it requires and the additional complexity it introduces. This would change, however, if the available memory is much larger than what is needed for the simpler, common-case design.

### Conclusions

TCP packet reassembly is a fundamental building block for analyzing network traffic at higher semantic levels. However, engineering packet reassembly hardware becomes highly challenging when it must resist attempts by adversaries to subvert it. We have presented a hardware-based reassembly system designed for both efficiency and robust performance in the face of such attacks.

First, through trace-driven analysis, we characterized the behavior of out-of-sequence packets seen in benign TCP traffic. By leveraging the results of this analysis, we designed a system that addresses the most commonly observed packet-reordering case in which connections have at most a single sequence hole in only one direction of the stream.

We then focused on the critical problem of buffer exhaustion. An adversary can create sequence holes to cause the system to continuously buffer out-of-order packets until the buffer memory overflows. We showed that through careful design, we can force the adversary to acquire a large number of hosts to launch this attack. We then developed a buffer management policy of randomized eviction in the case of overflow and analyzed its efficacy, deriving Zombie equations that quantify how many hosts the adversary must control to inflict a given level of collateral damage (in terms of forcing the abnormal termination of benign connections) for a given parameterization of the system and bandwidth available to the attacker's hosts.

We also discussed a possible design space for a system that directly handles arbitrary instances of packet resequencing, arguing that due to its complexity, such a system yields diminishing returns for the amount of memory and computational resources we must invest in it.

### Acknowledgments

We sincerely thank Nicholas Weaver, John Lockwood, and Holger Dreger for their helpful discussions and efforts, and Robin Sommer for making the Munich trace available. Sarang Dharmapurikar was partly funded by a grant from Global Velocity, and this work would not have been possible without support from the National Science Foundation under grants ITR/ANI-0205519 and STI-0334088, for which we are grateful.

### Notes

1. Another consideration here concerns SYN flooding attacks filling up the table with bogus connection entries. We can considerably offset this effect by only instantiating connection entries based on packets seen from the local site.
2. If alternate schemes for responding to duplicate-ACKs such as Limited Transmit [2] come into use, then this approach requires reconsideration.

### References

[1] Internet core router test. Light Reading, March 2001. <http://www.lightreading.com/document.asp?doc_id=4009&page_number=8>

[2] Mark Allman, Hari Balakrishnan, and Sally Floyd. Enhancing TCP’s Loss Recovery Using Limited Transmit. RFC 3042, IETF, January 2001.

[3] Mark Allman, Vern Paxson, and W. Richard Stevens. TCP Congestion Control. RFC 2581, IETF, April 1999.

[4] John Bellardo and Stefan Savage. Measuring packet reordering. In Proceedings of the second ACM SIGCOMM Workshop on Internet measurement, pages 97–105. ACM Press, 2002.

[5] Jon C. R. Bennett, Craig Partridge, and Nicholas Shectman. Packet reordering is not pathological network behavior. IEEE/ACM Trans. Netw., 7(6):789–798, 1999.

[6] Ethan Blanton and Mark Allman. On making TCP more robust to packet reordering. SIGCOMM Comput. Commun. Rev., 32(1):20–30, 2002.

[7] Stephan Bohacek, Joo P. Hespanha, Junsoo Lee, Chansook Lim, and Katia Obraczka. TCP-PR: TCP for persistent packet reordering. In Proceedings of the 23rd International Conference on Distributed Computing Systems. IEEE Computer Society, 2003.

[8] Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. Introduction to Algorithms. Prentice Hall, 1998.

[9] Scott Crosby and Dan Wallach. Denial of service via algorithmic complexity attacks. In Proceedings of the 12th USENIX Security Symposium. USENIX, August 2003.

[10] Jianping Xu et al. A 10Gbps Ethernet TCP/IP processor. In Hot Chips, August 2003.

[11] Landan Gharai, Colin Perkins, and Tom Lehman. Packet reordering, high speed networks, and transport protocol performance. In Proceedings of IEEE ICCCN 2004, 2004.

[12] Mark Handley, Christian Kreibich, and Vern Paxson. Network intrusion detection: Evasion, traffic normalization, and end-to-end protocol semantics. In Proceedings of USENIX Security Symposium, 2001.

[13] Sharad Jaiswal, Gianluca Iannaccone, Christophe Diot, Jim Kurose, and Don Towsley. Measurement and classification of out-of-sequence packets in a Tier-1 IP backbone. In Proceedings of IEEE Infocom 2003, 2003.

[14] Michael Laor and Lior Gendel. The effect of packet reordering in a backbone link on application throughput. IEEE Network, September 2002.

[15] Micron Inc. Double data rate (DDR) SDRAM MT8VDDT6464HD 512MB data sheet, 2004.

[16] Vern Paxson. End-to-end Internet packet dynamics. In Proceedings of ACM SIGCOMM, pages 139–154, Cannes, France, 1997.

[17] Vern Paxson. Bro: A system for detecting network intruders in real time. Computer Networks, December 1999.

[18] Thomas Ptacek and Thomas Newsham. Insertion, evasion, and denial of service: Eluding network intrusion detection. Technical Report, Secure Networks, 1998.

[19] Sarang Dharmapurikar and John Lockwood. Synthesizable design of a multi-module memory controller. Technical Report WUCS-01-26, October 2001.

[20] David Schuehler and John Lockwood. TCP-splitter: A TCP/IP flow monitor in reconfigurable hardware. In Hot Interconnects-10, August 2002.

[21] Ming Zhang, Brad Karp, Sally Floyd, and Larry Peterson. RR-TCP: A reordering-robust TCP with DSACK. In Proceedings of the 11th IEEE International Conference on Network Protocols. IEEE Computer Society, 2003.