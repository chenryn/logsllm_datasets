than 20,000, then no damage occurs, since the buffer is
large enough to keep the out-of-sequence packets of each
legitimate connection (provided none exceeds the thresh-
old of 25 KB).
To summarize, our buffer management policy consists
of three rules:
• Rule 1: Limit the reordering buffer consumed by
each connection to a predeﬁned threshold (which is
carefully chosen through a trace-driven analysis).
• Rule 2: Upon overﬂow, randomly evict a page to as-
sign to new packet.
• Rule 3: Do not evict a connection if it has less than
three packets in the buffer.
We pause here and reﬂect: what would have been the
effect of a naive buffer management policy consisting of
only Rule 2? What if we just randomly evict a page on
overﬂow ? First, we note that in the absence of Rule 3,
the option of not evicting a connection upon its page evic-
tion is ruled out, since otherwise the system is evadable.
78
14th USENIX Security Symposium
USENIX Association
10000
9000
8000
7000
6000
5000
4000
3000
2000
1000
d
n
o
c
e
s
r
e
p
d
e
t
i
c
t
v
e
s
n
o
i
t
c
e
n
n
o
c
i
n
g
n
e
B
0
0
with rules (r = 10Mbps)
without rules (r = 10Mbps)
50000
100000
150000
200000
250000
# Zombies
Figure 8: Comparison of eviction rates for the devised buffer
management policy (Rules 1, 2 & 3) and a naive policy of just
random eviction (only Rule 2). The total available memory
was assumed to be M=512 MB and the average buffer occu-
pancy of benign connections was assumed to be Ml=30 KB.
The zombie rate is 10 Mbps.
Now, given that a buffer eviction is equivalent to connec-
tion eviction, we lose out on the improvement given by
Eqn 6 (thus, now E = e). Secondly, in the absence of
Rule 1 and Rule 3, Case 1 and Case 2a do not come into
picture; the system behaves in the same way as it would
in Case 2b. Hence the benign connection eviction rate is
the same as given by Eqn 4.
We contrast the benign connection eviction rate in the
two cases for a given conﬁguration in Figure 8. Clearly,
with the application of Rule 1 and 3, we reduce the dam-
age to legitimate connections a great deal.
5.2 Designing for the general case
Our approach so far has been to design a system that han-
dles the most common case of packet reordering, i.e., the
occurrence of a single hole, at the cost of reduced TCP
performance (even when not under attack) for the rare
case of multiple concurrent holes. In this section we ex-
plore the design space for handling the case of multiple
concurrent holes in a single connection.
It is important to note that any mechanism we design
will ultimately have resource limitations. Hence, no mat-
ter how we conﬁgure our system, it is possible to come up
with a pathological case (e.g., a very large number of con-
current holes in a connection—a semantically valid case)
that will force us to break end-to-end semantics. In this
light, our previous trace analysis provides us with a “rea-
sonable” set of cases that merit engineering consideration.
In particular, the observation that more than 95% of the
connections have just a single concurrent sequence hole
indeed presents a compelling case for designing for this
case. Unfortunately, when we analyze multi-hole connec-
tions in terms of the number of holes in each, no modality
appears that is nearly as sharp as the distinction between
single-hole and multi-hole connections. Thus, picking a
“reasonable” number of per-connection holes is difﬁcult.
(For instance, the trace T3 shows that a connection can ex-
hibit 85 concurrent holes—though this turns out to reﬂect
pathological behavior, in which a Web server returned an
item in a single, large burst of several hundred six-byte
chunks, many of which were lost.)
Allowing multiple concurrent holes requires maintain-
ing per-hole state. The key difﬁculty here is that we can-
not afford to use a large, arbitrarily extensible data struc-
ture such as a linked list. Once the data structure’s size
exceeds what we can store in on-chip RAM, an adversary
can cause us to consume excessive CPU cycles iteratively
traversing it off-chip. On the other hand, if we expand the
size of each connection record to accommodate N holes
rather than 1, which will allow us to make a small number
of off-chip accesses to ﬁnd the hole, this costs signiﬁcant
additional memory.
Since most connections have zero or one hole, we can
realize signiﬁcant memory savings by differentiating be-
tween the two types of connections: connections with at
most one hole (per the data structure in our current de-
sign) and connections with up to N holes. We could par-
tition memory to support these two different types. Con-
nections initially exist only in the at-most-one-hole parti-
tion. As necessary, we would create an additional record
in the multiple-holes partition. We would likely keep the
original record, too, so we can easily locate the record for
newly-received packets by following a pointer in it to the
additional record.
A key issue here is sizing the second partition. If it is
too large, then it defeats the purpose of saving memory
by partitioning. On the other hand, if it is small then it
becomes a potential target for attack: an adversary can
create a number of connections with multiple holes and
ﬂood the second partition. Given this last consideration,
we argue that extending the design for handling multiple
sequence holes within single connections yields diminish-
ing returns, given the resources it requires and the addi-
tional complexity it introduces. This would change, how-
ever, if the available memory is much larger than what is
needed for the simpler, common-case design.
6 Conclusions
TCP packet reassembly is a fundamental building block
for analyzing network trafﬁc at higher semantic levels.
However, engineering packet reassembly hardware be-
comes highly challenging when it must resist attempts by
adversaries to subvert it. We have presented a hardware-
based reassembly system designed for both efﬁciency and
robust performance in the face of such attacks.
First, through trace-driven analysis we characterized
the behavior of out-of-sequence packets seen in benign
USENIX Association
14th USENIX Security Symposium
79
TCP trafﬁc. By leveraging the results of this analysis, we
TCP trafﬁc. By leveraging the results of this analysis, we
designed a system that addresses the most commonly ob-
designed a system that addresses the most commonly ob-
served packet-reordering case in which connections have
served packet-reordering case in which connections have
at most a single sequence hole in only one direction of the
at most a single sequence hole in only one direction of the
stream.
stream.
We then focused on the critical problem of buffer ex-
We then focused on the critical problem of buffer ex-
haustion. An adversary can create sequence holes to cause
haustion. An adversary can create sequence holes to cause
the system to continuously buffer out-of-order packets un-
the system to continuously buffer out-of-order packets un-
til the buffer memory overﬂows. We showed that through
til the buffer memory overﬂows. We showed that through
careful design we can force the adversary to acquire a
careful design we can force the adversary to acquire a
large number hosts to launch this attack. We then devel-
large number hosts to launch this attack. We then devel-
oped a buffer management policy of randomized eviction
oped a buffer management policy of randomized eviction
in the case of overﬂow and analyzed its efﬁcacy, deriving
in the case of overﬂow and analyzed its efﬁcacy, deriving
Zombie equations that quantify how many hosts the adver-
Zombie equations that quantify how many hosts the adver-
sary must control in order to inﬂict a given level of collat-
sary must control in order to inﬂict a given level of collat-
eral damage (in terms of forcing the abnormal termination
eral damage (in terms of forcing the abnormal termination
of benign connections) for a given parameterization of the
of benign connections) for a given parameterization of the
system and bandwidth available to the attacker’s hosts.
system and bandwidth available to the attacker’s hosts.
We also discussed a possible design space for a sys-
We also discussed a possible design space for a sys-
tem that directly handles arbitrary instances of packet re-
tem that directly handles arbitrary instances of packet re-
sequencing, arguing that due to its complexity, such a sys-
sequencing, arguing that due to its complexity, such a sys-
tem yields diminishing returns for the amount of memory
tem yields diminishing returns for the amount of memory
and computational resources we must invest in it.
and computational resources we must invest in it.
We draw two broad conclusions from our work. First,
We draw two broad conclusions from our work. First,
it is feasible to design hardware for boosting a broad class
it is feasible to design hardware for boosting a broad class
of high-level network analysis even in the presence of ad-
of high-level network analysis even in the presence of ad-
versaries attempting to thwart the analysis. Second, to
versaries attempting to thwart the analysis. Second, to
soundly realize such a design it is critical to perform an
soundly realize such a design it is critical to perform an
extensive adversarial analysis. For our design, assessing
extensive adversarial analysis. For our design, assessing
traces of benign trafﬁc alone would have led us to an ap-
traces of benign trafﬁc alone would have led us to an ap-
pealing, SRAM-based design that leverages the property
pealing, SRAM-based design that leverages the property
that in such trafﬁc, holes are small and ﬂeeting. In the
that in such trafﬁc, holes are small and ﬂeeting. In the
presence of an adversary, however, our analysis reveals
presence of an adversary, however, our analysis reveals
that we must switch to a DRAM-based design in order to
that we must switch to a DRAM-based design in order to
achieve robust high-performance operation.
achieve robust high-performance operation.
7 Acknowledgments
7 Acknowledgments
Our sincere thanks to Nicholas Weaver, John Lockwood, and
Our sincere thanks to Nicholas Weaver, John Lockwood, and
Holger Dreger for their helpful discussions and efforts, and to
Holger Dreger for their helpful discussions and efforts, and to
Robin Sommer for making the Munich trace available. Sarang
Robin Sommer for making the Munich trace available. Sarang
Dharmapurikar was partly funded by a grant from Global Veloc-
Dharmapurikar was partly funded by a grant from Global Veloc-
ity, and this work would not have been possible without support
ity, and this work would not have been possible without support
from the National Science Foundation under grants ITR/ANI-
from the National Science Foundation under grants ITR/ANI-
0205519 and STI-0334088, for which we are grateful.
0205519 and STI-0334088, for which we are grateful.
Notes
Notes
1Another consideration here concerns SYN ﬂooding attacks ﬁlling
1Another consideration here concerns SYN ﬂooding attacks ﬁlling
up the table with bogus connection entries. We can considerably offset
up the table with bogus connection entries. We can considerably offset
this effect by only instantiating connection entries based on packets seen
this effect by only instantiating connection entries based on packets seen
from the local site.
from the local site.
2 If alternate schemes for responding to duplicate-ACKs such as Lim-
2 If alternate schemes for responding to duplicate-ACKs such as Lim-
ited Transmit [2] come into use, then this approach requires reconsider-
ited Transmit [2] come into use, then this approach requires reconsider-
ation.
ation.
References
References
[1] Internet core router test
[1] Internet core router test
http://www.lightreading.com/document.asp?doc id ¯4009&
http://www.lightreading.com/document.asp?doc id ¯4009&
page number=8, March 2001.
page number=8, March 2001.
/ packet ordering.
/ packet ordering.
Light Reading,
Light Reading,
[2] Mark Allman, Hari Balakrishnan, and Sally Floyd. Enhancing
[2] Mark Allman, Hari Balakrishnan, and Sally Floyd. Enhancing
TCP’s Loss Recovery Using Limited Transmit. RFC 3042, IETF,
TCP’s Loss Recovery Using Limited Transmit. RFC 3042, IETF,
January 2001.
January 2001.
[3] Mark Allman, Vern Paxson, and W. Richard Stevens. TCP Con-
[3] Mark Allman, Vern Paxson, and W. Richard Stevens. TCP Con-
gestion Control. RFC 2581, IETF, April 1999.
gestion Control. RFC 2581, IETF, April 1999.
[4] John Bellardo and Stefan Savage. Measuring packet reordering. In
[4] John Bellardo and Stefan Savage. Measuring packet reordering. In
Proceedings of the second ACM SIGCOMM Workshop on Internet
Proceedings of the second ACM SIGCOMM Workshop on Internet
measurement, pages 97–105. ACM Press, 2002.
measurement, pages 97–105. ACM Press, 2002.
[5] Jon C. R. Bennett, Craig Partridge, and Nicholas Shectman. Packet
[5] Jon C. R. Bennett, Craig Partridge, and Nicholas Shectman. Packet
reordering is not pathological network behavior. IEEE/ACM Trans.
reordering is not pathological network behavior. IEEE/ACM Trans.
Netw., 7(6):789–798, 1999.
Netw., 7(6):789–798, 1999.
[6] Ethan Blanton and Mark Allman. On making TCP more robust to
[6] Ethan Blanton and Mark Allman. On making TCP more robust to
packet reordering. SIGCOMM Comput. Commun. Rev., 32(1):20–
packet reordering. SIGCOMM Comput. Commun. Rev., 32(1):20–
30, 2002.
30, 2002.
[7] Stephan Bohacek, Joo P. Hespanha, Junsoo Lee, Chansook Lim,
[7] Stephan Bohacek, Joo P. Hespanha, Junsoo Lee, Chansook Lim,
and Katia Obraczka. TCP-PR: TCP for persistent packet reorder-
and Katia Obraczka. TCP-PR: TCP for persistent packet reorder-
ing. In Proceedings of the 23rd International Conference on Dis-
ing. In Proceedings of the 23rd International Conference on Dis-
tributed Computing Systems. IEEE Computer Society, 2003.
tributed Computing Systems. IEEE Computer Society, 2003.
[8] Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest.
[8] Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest.
Introduction to Algorithms. Prentice Hall, 1998.
Introduction to Algorithms. Prentice Hall, 1998.
[9] Scott Crosby and Dan Wallach. Denial of service via algorithmic
[9] Scott Crosby and Dan Wallach. Denial of service via algorithmic
complexity attacks. In Proceedings of the 12th USENIX Security
complexity attacks. In Proceedings of the 12th USENIX Security
Symposium. USENIX, August 2003.
Symposium. USENIX, August 2003.
[10] Jianping Xu et al. A 10Gbps ethernet TCP/IP processor. In Hot
[10] Jianping Xu et al. A 10Gbps ethernet TCP/IP processor. In Hot
Chips, August 2003.
Chips, August 2003.
[11] Landan Gharai, Colin Perkins, and Tom Lehman. Packet reorder-
[11] Landan Gharai, Colin Perkins, and Tom Lehman. Packet reorder-
ing, high speed networks and transport protocol performance. In
ing, high speed networks and transport protocol performance. In
Proceedings of IEEE ICCCN 2004, 2004.
Proceedings of IEEE ICCCN 2004, 2004.
[12] Mark Handley, Christian Kreibich, and Vern Paxson. Network in-
[12] Mark Handley, Christian Kreibich, and Vern Paxson. Network in-
trusion detection: Evasion, trafﬁc normalization, and end-to-end
trusion detection: Evasion, trafﬁc normalization, and end-to-end
protocol semantics. In Proceedings of USENIX Security Sympo-
protocol semantics. In Proceedings of USENIX Security Sympo-
sium, 2001.
sium, 2001.
[13] Sharad Jaiswal, Gianluca Iannaccone, Christophe Diot, Jim
[13] Sharad Jaiswal, Gianluca Iannaccone, Christophe Diot, Jim
Kurose, and Don Towsley. Measurement and classiﬁcation of out-
Kurose, and Don Towsley. Measurement and classiﬁcation of out-
of-sequence packets in a Tier-1 IP backbone. In Proceedings of
of-sequence packets in a Tier-1 IP backbone. In Proceedings of
IEEE Infocom 2003, 2003.
IEEE Infocom 2003, 2003.
[14] Michael Laor and Lior Gendel. The effect of packet reordering in a
[14] Michael Laor and Lior Gendel. The effect of packet reordering in a
backbone link on application throughput. IEEE Network, Septem-
backbone link on application throughput. IEEE Network, Septem-
ber 2002.
ber 2002.
[15] Micron
[15] Micron
Inc.
Inc.
Double
Double
data
data
rate
rate
(DDR)
(DDR)
SDRAM
SDRAM
MT8VDDT6464HD 512MB data sheet, 2004.
MT8VDDT6464HD 512MB data sheet, 2004.
[16] Vern Paxson. End-to-end Internet packet dynamics. In Proceed-
[16] Vern Paxson. End-to-end Internet packet dynamics. In Proceed-
ings of ACM SIGCOMM, pages 139–154, Cannes, France, 1997.
ings of ACM SIGCOMM, pages 139–154, Cannes, France, 1997.
[17] Vern Paxson. Bro: A system for detecting network intruders in real
[17] Vern Paxson. Bro: A system for detecting network intruders in real
time. Computer Networks, December 1999.
time. Computer Networks, December 1999.
[18] Thomas Ptacek and Thomas Newsham.
[18] Thomas Ptacek and Thomas Newsham.
Insertion, evasion, and
Insertion, evasion, and
denial of service: Eluding network intrusion detection. Technical
denial of service: Eluding network intrusion detection. Technical
Report, Secure Networks, 1998.
Report, Secure Networks, 1998.
[19] Sarang Dharmapurikar and John Lockwood. Synthesizable design
[19] Sarang Dharmapurikar and John Lockwood. Synthesizable design
of a multi-module memory controller. Technical Report WUCS-
of a multi-module memory controller. Technical Report WUCS-
01-26, October 2001.
01-26, October 2001.
[20] David Schuehler and John Lockwood. TCP-splitter: A TCP/IP
[20] David Schuehler and John Lockwood. TCP-splitter: A TCP/IP
ﬂow monitor in reconﬁgurable hardware. In Hot Interconnects-10,
ﬂow monitor in reconﬁgurable hardware. In Hot Interconnects-10,
August 2002.
August 2002.
[21] Ming Zhang, Brad Karp, Sally Floyd, and Larry Peterson. RR-
[21] Ming Zhang, Brad Karp, Sally Floyd, and Larry Peterson. RR-
TCP: A reordering-robust TCP with DSACK. In Proceedings of
TCP: A reordering-robust TCP with DSACK. In Proceedings of
the 11th IEEE International Conference on Network Protocols.
the 11th IEEE International Conference on Network Protocols.
IEEE Computer Society, 2003.
IEEE Computer Society, 2003.
80
14th USENIX Security Symposium
USENIX Association