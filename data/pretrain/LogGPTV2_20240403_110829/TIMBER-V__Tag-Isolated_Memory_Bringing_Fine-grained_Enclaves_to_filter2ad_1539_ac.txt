enclaves and untrusted apps. Slots marked as TS cannot be
manipulated from untrusted code and are used to distinguish
TSenter from TUenter, as outlined before. Only TagRoot
can enable these ﬂags. While the untrusted operating system
cannot manipulate TS slots, it can overwrite TU slots, which
will automatically clear the TU ﬂag. This prevents enclave
execution until TagRoot validates changes and reenables TU.
Tag-aware Instructions. We add new instructions for check-
ing and manipulating tags, as listed in Table IV. We duplicate
existing RISC-V load and store instructions to checked variants
with the sufﬁx ct. Checked loads preserve semantics of load-
ing memory from address src into the register dst. Likewise,
checked stores transfer the content of the src register to the
memory address dst. Unlike normal memory accesses, the
checked instructions trigger a trap if the memory tag of the
memory address being accessed does not match the expected
tag, encoded in etag. In addition, checked stores overwrite the
tag at dst with a new tag, encoded in ntag. The accessed
memory address is determined by a base address, stored in
a register, and a 12-bit signed address offset, encoded as
immediate. Also, etag and ntag are encoded as immediate,
stripping the upper bits of the address offset to 10 bits and 8
bits for checked loads and checked stores, respectively.
For cases where memory tags are unknown, we add a
separate load and test tag (LTT) instruction.4 Similar to a
checked load, LTT veriﬁes the tag of a memory location
4Cf. the Test Target (TT) instruction of TrustZone-M [3].
8
1
2
3
4
5
6
1
2
3
4
5
6
7
8
9
lw
lw
t0 , 2 4 ( sp )
t1 , 2 0 4 8 ( a1 )
add
sw
t0 , t0 , t 1
t0 , 2 4 ( sp )
1
2
3
4
5
6
t s , t0 , 2 4 ( sp )
l w c t
a d d i a1 , a1 , 2 0 4 0
l w c t
t s , t1 , 8 ( a1 )
a d d i a1 , a1 ,−2040
add
swct
t0 , t0 , t 1
t s , t s , t0 , 2 4 ( sp )
(a) Original code.
(b) Transformed code.
Fig. 4: Code hardening for TS-mode with overﬂow correction.
f u n c t i o n :
a d d i
sp , sp ,−8
. . .
a d d i
r e t
sp , sp , 8
1
2
3
4
5
6
7
8
9
f u n c t i o n :
sp , sp ,−8
a d d i
swct n , t s , zero , 4 ( sp )
swct n , t s , zero , 0 ( sp )
. . .
swct
swct
a d d i
r e t
t s , n , zero , 4 ( sp )
t s , n , zero , 0 ( sp )
sp , sp , 8
(a) Original code.
(b) Transformed code.
Fig. 5: Stack interleaving for TS-mode.
(src) against a given expected tag (etag). However, instead
of trapping, LTT stores the result in a register (dst), thus
allowing subsequent code to take appropriate action. We utilize
LTT for enclave cleanup, since this discharges TagRoot from
keeping track of the exact enclave layout.
Code Transformations. We implement code transformations
in a separate compilation step, where we compile source code
to assembler code which we then transform using a custom
awk script [24]. The code hardening transformation simply
replaces all memory accesses with their checked instruction
pedants, as shown for TS-mode in Figure 4. In some cases
address overﬂows occur, namely when the encoding space of
memory addresses is insufﬁcient for a direct 1:1 transformation
due to the additional etag and ntag encoding. In these cases,
we insert correcting instructions which shift the overﬂowing
part to the instruction’s base register (lines 2–4). For stack in-
terleaving the script detects stack allocations and deallocations
by searching for manipulations of the stack pointer sp. It then
claims or unclaims the stack frame by inserting checked store
instructions accordingly, as seen in Figure 5 lines 3–4 and 6–7.
Developer Effort. From a developer’s perspective, writing
enclaves boils down to placing memory into distinct linker
sections, for which we provide macros. One can mix enclave
and non-enclave code in the same source ﬁle via annotations.
Entry points are speciﬁed via a simple array. Ocalls in addition
require to invoke an assembler macro. Code transformations
are fully integrated in the macros and the build system.
For memory accesses across security domains we provide
dedicated macros setting etag accordingly. Edge routines
could further reduce efforts, as done in the SGX SDK [30].
Additional CPU registers. We add new control and status
registers (CSRs) for TS-mode (and M-mode). STSTATUS
conﬁgures TIMBER-V and controls enclave execution. It holds
a ﬂag indicating the current security mode (normal or trusted).
Moreover, whenever a running enclave traps due to an interrupt
or exception, STSTATUS will raise a ﬂag that prevents enclave
execution until resumed by TS-mode. To allow TS-mode to
intercept traps, we add a separate trap vector, called STTVEC.
9
Whenever the CPU is in trusted mode, traps are redirected to a
trusted trap handler pointed to by STTVEC. Traps happening
in normal mode are forwarded to the standard trap handler,
stored in STVEC. This is implemented in a small M-mode
trap delegation code. To help the trusted trap handler in setting
up scratch space, we duplicate the supervisor scratch register
for the trusted mode, called STSCRATCH. In addition, we add
a register denoted as SECB to hold a pointer to an enclave
control block, which identiﬁes the currently loaded enclave.
This helps TS-mode in processing trusted enclave service calls.
VIII. SECURITY ANALYSIS
Shielded execution systems like TIMBER-V build upon
various components to protect sensitive data from being leaked
(conﬁdentiality) or corrupted (integrity). In the following, we
discuss how TIMBER-V protects enclaves against direct and
indirect accesses. Furthermore, we discuss security of enclave
shared memory, TagRoot and dynamic memory interleaving.
Direct Access. During runtime, the tag isolation policy pre-
vents N-domains from directly accessing or tampering enclave
memory. Also, our tag update policy does not allow elevating
the current privilege mode. To prevent (malicious) enclaves
from accessing other enclave’s memory, TagRoot ensures that
(i) enclave regions do not overlap upon enclave initialization,
and (ii) the MPU only holds regions of a single enclave at a
time. (i) ensures exclusiveness, i.e., the only way for having
enclave regions overlap is via shared memory, as discussed
later. (ii) ensures that enclaves cannot misuse stale MPU entries
of other enclaves. Also, our shared MPU design prevents
forging of MPU entries. Whenever the untrusted operating
system updates an MPU slot, an enclave cannot use it until
TagRoot acknowledges these changes (cf. Section VII).
Indirect Access. Indirect security violations are prevented by
(i) load-time attestation, (ii) secure entry points and (iii) secure
interruption. During enclave loading,
the operating system
could manipulate an enclave’s code to divulge secret infor-
mation later on. To prevent this, enclave loading is measured
using a cryptographically strong hash function (SHA256).
Thus, whenever the untrusted operating system manipulates
the loading procedure,
this will yield a different enclave
identity (EID) leading to different cryptographic keys, and
subsequent attestation or unsealing of secrets will fail. To pre-
vent direct code-reuse attacks from leaking sensitive enclave
data to an attacker, TIMBER-V enforces secure entry points
via the TC-tag. Since TC-tag can only be set by TagRoot,
they are tamper-proof. Of course, this does not prevent code-
reuse attacks in case of memory safety vulnerabilities in the
enclave code itself. Achieving memory safety is an ongoing
ﬁeld of research [16]. If memory safety cannot be guaranteed,
our code hardening transformation can make potential code-
reuse attacks harder by preventing the attacker from misusing
memory instructions to leak sensitive information. Finally,
indirect information leakage due to enclave interruption is
prevented by TagRoot, which clears sensitive register content
before giving control to the operating system.
Shared Memory. In general, enclave regions cannot be modi-
ﬁed during runtime except for shared memory, where enclaves
willingly accept memory region overlaps with other enclaves.
Since this process involves mutual authentication, it cannot be
misused to open bogus shared memory. Shared memory (shm)
also demands temporal isolation to prevent time-of-check vs
time-of-use (TOCTOU) attacks in two directions. First, if a
shm-offering enclave gets destroyed, a target enclave still has
access to the shm. As long as the target enclave does not
release it, the shm cannot be given to a newly created offering
enclave because TagRoot prevents enclave region overlaps.
Thus, TagRoot supports temporal authenticity of the offering
enclave. Second, if the target enclave gets destroyed after
having accepted a shm offer, it might get reinstantiated and
accept the same shm offer again without the knowledge of the
offering enclave. This allows TOCTOU attacks. To avoid this,
the offering enclave needs to close the shm offer after being
accepted and employ a simple handshake to verify aliveness
of the target enclave. For example, both enclaves could agree
on a session identiﬁer that changes for each enclave restart.
TagRoot. All of the aforementioned analysis critically depends
on the integrity of TagRoot. We assume loading of TagRoot it-
self is protected using secure boot [42]. Once loaded, TagRoot
can protect itself in an isolated execution container similar
to enclaves by using tag isolation via TS-tag and secure entry
points protected via TC-tag together with TS-mode MPU slots.
Dynamic Memory Interleaving. Here, untrusted code offers
N-tag memory to trusted code. To be secure, untrusted argu-
ments need to be validated by trusted code. In particular, one
needs to ensure (i) validity of the memory when claiming it,
and (ii) validity during usage. By claiming dynamic memory
with checked store instructions (etag = N-tag) one can
ensure (i), namely that
trusted code does not accidentally
overwrite trusted data in case of bogus memory pointers,
for example. In addition, vertical stack interleaving crosses
privilege modes and, thus, requires additional enclave region
checks, as explained in Section VI-B. Point (ii) is different
for the various interleaving schemes we presented before. In
general, whenever pointers to trusted memory objects can be
manipulated by untrusted code, one needs means to validate
them. For supervisor heap and stack interleaving we introduced
unforgeable headers, uniquely identifying valid ECBs and
interrupt frames. This voids the need for tracking valid objects.
In contrast, for user heap interleaving we recommended to
track pointers to trusted heap objects inside the enclave. Also,
horizontal user stack interleaving with ocalls needs additional
checks of the stack pointer sp when re-entering the enclave.
Here, we store the last valid stack pointer inside the enclave.
By maintaining (i) and (ii), dynamic memory interleaving is
secure against corruption and direct information leakage.
IX. EVALUATION
A. Methodology
We evaluate TIMBER-V by running various macro- and
micro-benchmarks in the Spike simulator, which we ex-
tended to support TIMBER-V. We conﬁgure Spike for the
RV32IMAFD ISA and use it
to record histograms of all
executed instructions. To estimate the runtime in CPU cycles,
we map executed instructions to actual CPU cycles using
different pipelined CPU models. We ﬁrst deﬁne a simple
baseline model, against which we then compare two possible
realizations of TIMBER-V, namely TIMBER-V Model A, cap-
turing unoptimized implementations, and TIMBER-V Model
TABLE V: Expected CPU cycles per instruction.
CPU model
Baseline Model
TIMBER-V Model A
TIMBER-V Model B
d
l
t
s
t
c
l
t
c
s
g
e
r
1
2
1.1
1
2
1.1
-
2
1.1
-
3
1.1
1
1
1
l
u
m
1
1
1
v
i
d
1
1
1
r
e
h
t
o
1
1
1
l
l
a
t
s
3
4
3.1
B, representing optimized designs with tag caching. It should
be noted that Model B is by no means an upper bound on
the maximum performance achievable. Rather, it presents a
conservative performance estimate based on related work about
tagged memory architectures [31,45,48]. We outline these CPU
models in the following and summarize them in Table V.
Baseline CPU Model. As a baseline we assume that all regis-
ter (reg) or memory instructions (ld/st) take one CPU cycle.
This is reasonable for a load/store architecture as RISC-V
with on-chip SRAM commonly used for embedded processors.
When instructions stall the execution pipeline we assume addi-
tional latency to reﬁll the pipeline. This applies to conditionally
taken branches for indirect jumps as well as to syscalls and
returns and is indicated by the column stall. We assume
that multiplication (mul) and division (div) instructions also
complete within one CPU cycle, which keeps our evaluation
results pessimistic. That is, comparing against this baseline
will show higher overhead than observed in practice, where
multiplication and division typically take multiple cycles.
TIMBER-V CPU Models. Each instruction fetch requires one
additional tag fetch. For the unoptimized Model A, we assume
that this tag fetch can be effectively hidden by the prefetcher.
Thus, linear code fetches do not exhibit overhead and all non-
memory instructions (reg, mul, div and other) take one
cycle. However, when the execution pipeline stalls, the tag
fetching overhead gets visible for the ﬁrst instruction after the
stall. Thus, we add one extra cycle for stalls. For memory loads
and stores we assume one extra cycle to load and check the tag
on the accessed data. A checked memory load (lct) does not
experience additional overhead since the data’s memory tag
is already loaded for enforcement of the tag isolation policy
and can be readily used for the additional tag check. On the
other hand, for checked memory stores (sct) we assume one
additional cycle to store the new tag. This model does not
make use of tag caching, which could signiﬁcantly improve
performance. A tag cache can serve tags in parallel to ordinary
memory accesses and thus, hide the tag checking latency for
all cached tags. By comparing state-of-the-art literature on
tagged memory architectures, we observe that tag caching can
reduce the average overhead of tag accesses into the low single
digit range [31,45,48]. Considering that our work utilizes two
tag bits per word, we conservatively estimate the expected
performance impact of the tag operations with 10%, which
is reﬂected in Model B. The resulting costs for the individual
instruction classes is depicted in the last line of Table V. Again,
the prefetcher hides tag checking latency for instructions, while
a stall is prolonged by 10% of a cycle. Likewise, memory
loads and stores experience 10% overhead. We assume that
checked stores (sct) are not slower than ordinary stores (st)
because the additional tag update latency can be absorbed by
the parallel tag cache.
10
)
%
(
d
a
e
h
r
e
v
O
70
60
50
40
30
20
10
0
)
%
(
d
a
e
h
r
e
v
O
20
15
10
5
0
8
.
0
6 3
.
7
3 1
.
5
1
.
3
8
.
1
4
.
9
9
.
0
5
.
0
3
.
0
4
0
2
7
.
2 4 1
7
1
4
.
9
2
.
4
9
.
0
7
.
1
4