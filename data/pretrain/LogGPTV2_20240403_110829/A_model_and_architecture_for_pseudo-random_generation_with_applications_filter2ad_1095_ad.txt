/dev/random should
suitable
very
pool
need
for
be
is
vulnerable
bytes
When read, /dev/urandom device will return as many
as are requested.
As a result, if there is not sufficient
entropy in the entropy pool, the returned values are theo-
retically
attack on the
algorithms used by the driver.
do
this is not available in the current non-classified liter-
ature, but it
an
attack
If this is a concern in your applica-
tion, use /dev/random instead.
Knowledge of how
theoretically
cryptographic
may exist.
possible
such
that
to
to
a
is
Given this documentation, it is expected that program-
mers will often use /dev/random in a security-related ap-
plications. We strongly disagree with that approach, and
believe that in most situations, security will be enhanced
if both /dev/random and /dev/urandom perform the same
function, which is to run an instance of the general scheme
described in this paper. Our reasons are the following:
1. It is not at all clear that /dev/random, whose imple-
mentation relies on an entropy estimator and the cryp-
tographic hash function SHA1 indeed provides information-
theoretic security.
times does not.
Indeed, we suspect that it some-
2. A design like ours allows for much more conservative
entropy estimates (one needs fresh randomness much
less quickly) than the current design of /dev/random
and thus we believe will result in better chances of
recovering from a leakage of the internal state.
3. The blocking behavior of /dev/random introduces un-
certainty in the scheduling of security-related programs.
This uncertainty may be exploited for attacks by an
adversary.
The manual page from above seem to suggest that secu-
rity of outputs from /dev/urandom relies on unproven as-
sumption, whereas the security of /dev/random does not
and holds even with respect to computationally unbounded
attackers.
In our view, there is nothing further from the
truth. Leaving aside the fact that /dev/random uses SHA1
as an entropy extractor, the “information theoretical secu-
rity” that it provides relies on a heuristic approach to en-
tropy estimation. As we said several times in this note, the
goal of that heuristic is to estimate the entropy from the
attacker’s point of view, and it operates without any clue as
to the environment in which it runs and the capabilities of
the attacker. It all but certain that there are environments
in which this estimation is far too optimistic. We believe
that it is far safer to trust the security of a published cryp-
tographic design such as HMAC-SHA1 or CBC-AES than to
trust the entropy estimation heuristic. We also remark that
the design in this paper can be instantiated with diﬀerent
primitives, and so can be made to rely on security of diﬀer-
ent problems (e.g., symmetric or public-key cryptography)
or diﬀerent key sizes. This can allow to use diﬀerent trade-
oﬀs between security and eﬃciency in diﬀerent systems.
Moreover, we point out that /dev/random may fail to pro-
vide information-theoretic security even if the entropy esti-
mator is correct. For example, in the version or random.c
that was used in the Linux kernel v2.4, both streams used
the same entropy pool, so the output of /dev/urandom leaked
information also about the state of /dev/random. And even
when the two streams use syntactically distinct pools (as in
the Linux kernel v2.6), as long as they are refreshed from
possibly dependent data there is no guarantee of information-
theoretic security for /dev/random.
5.4 Other use cases
We note that there are other scenarios besides /dev/random
where our architecture may be of use. One example is a
smartcard that has no entropy generator of its own and can
get what is supposed to be fresh randomness whenever it is
connected to a reader. The properties of our architecture
ensure that as long as this card gets randomness from an
honest reader every once in a while, there is no harm in let-
ting it act also on “randomness” from a malicious readers.
This may be sometimes safer than including an entropy-
generator in a smart-card, since those are often prone to
attacks or malfunction.
6. CONCLUSIONS
In the course of this work we arrived at the following ob-
servations/recommendations for the design of robust pseudo-
random generators.
1. The generator design should be explicitly split into two
parts, namely the randomness extraction and the output
generation. Moreover, it is possible to provide a modular
design that allows changing the primitives to achieve diﬀer-
ent security/eﬃciency tradeoﬀs.
2. We advise against using run-time entropy estimation, and
believe that having frequent automatic refreshes is almost
never beneﬁcial. Instead, we advocate making the refresh
rate as low as possible, speciﬁcally in the order of once every
few minutes.
3. In a well-designed generator, there is no harm in allowing
refresh data to come from any source, even one that is not
trusted. This can be important, e.g., for smartcards, or
when allowing user-supplied data to be used for refreshing
the state.
Acknowledgments
We thank David Wagner for critically commenting on an
earlier version of this paper. We also thank the partici-
pants of a long thread on pseudorandom generation in the
sci.crypt usenet newsgroup in the fall of 2004, for motivat-
ing us to write this paper. Finally, we thank the ACM-CCS
reviewers for many useful comments.
7. REFERENCES
[1] B. Barak, R. Shaltiel, and E. Tromer. True random
number generators secure in a changing environment.
In Workshop on Cryptographic Hardware and
Embedded Systems (CHES), pages 166–180, 2003.
LNCS no. 2779.
[2] M. Bellare and B. Yee. Forward-security in private-key
cryptography. In Topics in Cryptology - CT-RSA’03,
pages 1–18, 2003.
[3] M. Blum and S. Micali. How to generate
cryptographically strong sequences of pseudo-random
bits. SIAM J. Comput., 13(4):850–864, Nov. 1984.
Preliminary version in FOCS ’82.
[4] R. Canetti and A. Herzberg. Maintaining security in
the presence of transient faults. In Crypto ’94, pages
425–438, 1994. LNCS No. 839.
[5] Y. Dodis, R. Gennaro, J. H˚astad, H. Krawczyk, and
T. Rabin. Randomness extraction and key derivation
using the CBC, Cascade and HMAC modes. In Crypto
’04, pages 494–510, 2004. LNCS No. 3152
[6] Y. Dodis and A. Smith. Entropic security and the
encryption of high entropy messages. In Theory of
Cryptography Conference (TCC) ’05, pages 556–577,
2005.
[7] N. Ferguson and B. Schneier. Practical Cryptography.
Wiley, New York, NY, USA, 2003.
[8] I. Goldberg and D. Wagner. Randomness and the
Netscape browser. Dr. Dobb’s Journal, pages 66–70,
1996.
[9] O. Goldreich and L. A. Levin. A hard-core predicate
for all one-way functions. In Proc. 21st STOC, pages
25–32. ACM, 1989.
[10] O. Goldreich, S. Micali, and A. Wigderson. How to
play any mental game or a completeness theorem for
protocols with honest majority. In Proc. 19th STOC,
pages 218–229. ACM, 25–27 May 1987.
[11] P. Gutmann. Software generation of practically strong
random numbers. In Proceedings of the 7th USENIX
Security Symposium, 1998. Available from
http://www.cs.auckland.ac.nz/~pgut001/.
[12] J. H˚astad, R. Impagliazzo, L. A. Levin, and M. Luby.
A pseudorandom generator from any one-way
function. SIAM J. Comput., 28(4):1364–1396, 1999.
Preliminary versions appeared in STOC’ 89 and
STOC’ 90.
[13] J. Kelsey, B. Schneier, D. Wagner, and C. Hall.
Cryptanalytic attacks on pseudorandom number
generators. In FSE ’98, pages 168–188, 1998. LNCS
No. 1372.
[14] R. Shaltiel. Recent developments in extractors. In
G. Paun, R. I. Virgili, G. Rozenberg, and A. Salomaa,
editors, Current trends in theoretical computer
science., volume 1. World Scientiﬁc, 2004. Preliminary
version in bulletin of the EATCS, 2002. Available on
http://www.cs.haifa.ac.il/∼ronen/.
A. MORE ON RANDOMNESS EXTRACTION
We now return to the issue of extracting “truly random”
strings from high-entropy sources. Recall that in our con-
text, we need a function extract : {0, 1}≥m → {0, 1}m that
returns an almost uniformly distributed string under “nor-
mal conditions” (and we do not care what it does under
“dysfunctional conditions”). These “normal conditions” are
codiﬁed by a family H of distributions on bit strings, such
that we can assume that the refresh data is drawn from some
distribution D ∈ H under “normal conditions”.
The design of the function extract depends on the family
of distributions H that one wishes to extract from, which
depend of course on the type of data that we will use to
refresh the generator. Below we brieﬂy describe the work of
Barak et al.
[1] that sets up a model obtaining essentially
the most general family H and shows a rater eﬃcient com-
binatorial construction that can be proven to work in that
model. Later we describes brieﬂy the work of Dodis et al.
[5] that deals with using constructions such as CBC-AES
and HMAC-SHA1 for extraction.
A.1 The Barak-Shaltiel-Tromer model
The work [1] deals with extracting truly random bits from
sources that have high entropy but are far from uniform.
The goal is to construct H-extractors (cf. Deﬁnition 2.1)
where H includes all the high-entropy distributions that we
likely to see in practice.
Before proceeding further we mention the minor technical
problem that Shannon entropy is not a good measure for the
quality of distribution in our case. For example, a distrib-
ution that outputs the n-bit all-zero string with probability
1/2, and otherwise outputs a uniform n-bit string, has about
n− 1 bits of entropy, but it is easy to see that it is not possi-
ble to extract from it more than one bit of true randomness.
It turns out that the right measure to use is the min-entropy
of a source, which is deﬁned as log(1/p) where p is the prob-
ability of the most likely output of that source.8 Hence, we
require that all the distributions in H will have more than
m bits of min-entropy.
Recall further that the designer of the extraction function
typically knows very little about the environment in which
it will be used. Therefore, the model of Barak et al. lets the
attacker specify the family H, subject to two constraints:
(a) all the distributions in H must have (signiﬁcantly) more
than m bits of min-entropy9, and (b) the family H is not too
large: at most 2t distributions where t is a parameter. The
parameter t can be thought of as the degree of inﬂuence that
the attacker has on the environment under “normal condi-
tions”. Namely, if there are t aspects of the environment
that the attacker can control (and each of these is a boolean
ﬂag) then the attacker can choose one of 2t diﬀerent distri-
butions depending on how it sets these ﬂags.
In more details, the work [1] utilizes randomized extrac-
tion functions, extract : Coins×{0, 1}n → {0, 1}m, (for some
n > m) and considers the following “game” between the
designer and the attacker (with parameter t):
1. The attacker chooses a family of 2t distributions,
H = {D1, . . . ,D2t}
8A closely related measure is the Renyi entropy of order two.
9Recall that H describes the distributions over refresh data
under normal working conditions, so it is reasonable to re-
quire that these distributions have high entropy.
2. The designer chooses “once and for all” the randomness
s ←R Coins for the extraction function. The coins s are
made public (and in particular given to the attacker).
The randomized construction extract is considered good
if for every family H of 2t distributions, for all but a 2−m
fraction of the coins s ∈ Coins, the deterministic function
extracts(·) = extract(s,·) is an H-extractor as per Deﬁn-
ition 2.1. Namely, no matter how the attacker chooses its
family H in Step 1, the resulting extraction function extracts
extracts nearly uniform bits from every distribution in H
(except perhaps with insigniﬁcant probability over the choice
of the coins in Step 2). It was shown in [1] how to construct
eﬃcient randomized extraction functions extract that work
as long as every distribution in H has more than 2t+4m bits
of min-entropy. This construction is not cryptographic, and
in particular it does not rely on any hardness assumption.
Some additional comments. We brieﬂy mention that the
result of Barak et al. from [1] is slightly stronger than what
is implied by the text above. In particular, it can be shown
that any extractor that works for a family H also works for
every distribution in the convex hull of H, so one does not
really have to think of the aspects that the attacker controls
as being just boolean ﬂags. Also, for our purposes we do
not necessarily have to think of the diﬀerent samples from
the sources as independent, as long as we can assume that
the distribution of the outputs conditioned on the previous
samples belong to the family H. Finally, we do not claim
that the model in [1] is necessarily “the right model” to use
in this context. Indeed, we expect that more work has to be
done before we have a model for randomness extraction that
is both theoretically sound and “practically interesting”.
A.2 Using cryptographic modes of operation
Many systems today use cryptographic functions in some
mode of operation for randomness extraction. Although it
is not at all clear what properties are needed from the cryp-
tographic functions themselves for this to work, one can at
least examine the properties of the mode of operation, as-
suming that the cryptographic primitive is replaced by a
truly random function.
Indeed, this was recently studied
by Dodis, Gennaro, H˚astad, Krawczyk and Rabin in [5].
Speciﬁcally, they studied the CBC-Π construction with Π a
truly random permutation over {0, 1}m, and the HMAC-f
construction where f is a truly random “compression func-
tion” from {0, 1}n to {0, 1}m, and analyzed the extraction
properties of these functions.
Their results indicates that CBC-Π for a random permu-
tation Π is a “reasonably good” extractor. Namely, for every
distribution D on {0, 1}mL (for some L > 1) that has more
than 2m bits of min-entropy, and with very high probability
over the choice of Π, the statistical distance between CBC-
Π(D) and Um is bounded by roughly L/2m/2. (This means
more or less that for any m-bit string y, Prx←RD[CBC-Π(x) =
y] = 2−m(1 ± L
2m/2 ). Their results for HMAC-f are some-
what weaker (but similar in spirit).