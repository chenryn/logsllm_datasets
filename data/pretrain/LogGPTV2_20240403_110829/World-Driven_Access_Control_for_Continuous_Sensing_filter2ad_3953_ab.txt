From this, we learned that access control decisions can-
not depend (only) on user actions but should instead be
object-driven: real-world objects around the user must help
determine access control policies.
Distributed organization. The next problem was how
to map from objects to access control policies. We ﬁrst at-
tempted to build a taxonomy of which objects are sensitive
(e.g., whiteboards) or not sensitive (e.g., chairs). Unfor-
tunately, a static taxonomy is not rich enough to capture
the complexities of real-world objects — for example, not all
whiteboards contain sensitive content.
We then attempted to deﬁne a hierarchical naming scheme
for real-world objects. For example, we might name an ob-
ject by referring to the room it is in, then the building,
and ﬁnally the building’s owner. We hoped to build a sys-
tem analogous to the Web’s Domain Name System, where
objects could be recognized in the real world, mapped to
names, and ﬁnally mapped to policies. Unfortunately, be-
cause objects can move from one location to another, poli-
cies may not nest hierarchically, and hierarchies not based
on location quickly become complex.
Though there may be value in further attempting to tax-
onomize the world and its moving objects, we chose to pur-
sue an approach in which policy decisions are not central-
ized. Instead, our design’s access control decisions are dis-
tributed : each object is able to set its own policy and com-
municate it to devices.
Context sensitivity. Finally, we faced the challenge of
specifying an object’s policy. A ﬁrst approach here is to
have static “all-or-nothing” policies. For example, a person
or a whiteboard could have a policy saying to never include
it in a picture, and certain sensitive words might always
mark a conversation as not for recording.
While static policies cover many scenarios, others are more
complex. For example, AdaCamp attendees can opt out of
photos by wearing a red lanyard [3]. At the conference, the
lanyard communicates a policy, but outside it does not. Poli-
cies may also depend on applications (e.g., only company-
approved apps may record a whiteboard). From this, we
learned that policies must be context-sensitive and arbitrar-
ily complex. Thus, in addition to static policies, we support
Microsoft Research Tech Report MSR-TR-2014-67
Figure 3: System Overview. We build on the recognizer abstraction [18], in which applications subscribe to high-level events
generated by object recognition algorithms. Our contribution is the policy module (Section 3.4), which sees all events, detects policies,
and blocks or modiﬁes events accordingly before releasing them to untrusted applications.
policies that are (appropriately sandboxed) executable code
objects, allowing them to evaluate all necessary context.
3.2 Background: Recognizers & Events
A key enabler for world-driven access control is the rec-
ognizer operating system abstraction [18]. A recognizer is
an OS component that processes a sensor stream, such as
video or audio, to “recognize” objects or other triggers. Upon
recognition, the recognizer creates an event, which is dis-
patched by the OS to all registered and authorized appli-
cations. These events expose higher-level objects to appli-
cations, such as a recognized skeleton, face, or QR code.
Applications may also register for lower-level events, like
RGB/depth frames or location updates.
The recognizer abstraction restricts applications’ access to
raw sensor data, limiting the sensitive information an appli-
cation receives with each event. Further, this event-driven
model allows application developers to write code agnostic to
the application’s current permissions [18]. For example, if an
application does not receive camera events, it cannot distin-
guish whether the hardware camera is turned oﬀ or whether
it is currently not authorized to receive camera events.
Previous work on recognizers, however, did not study how
to determine which permissions applications should have [18].
While the authors discuss visualization techniques to inform
users what information is shared, the burden is on users to
manage permissions through prompts or manifests. World-
driven access control removes this burden by dynamically
adjusting permissions based on world-expressed policies.
3.3 Policies and Policy Communication
We now dive more deeply into our design. We seek a gen-
eral, extensible framework for communicating policies from
real-world objects. Our prototype focuses primarily on poli-
cies communicated explicitly by the environment (e.g., by
QR code or ultrasound), not inferred by the system. How-
ever, our system can be extended to support implicit or in-
ferred policies as computer vision and other techniques im-
prove. For example, the recent PlaceAvoider approach [39] —
which can recognize privacy-sensitive locations with train-
ing — can be integrated into our system.
Designed to be a broad framework, world-driven access
control can support a wide range of policy communication
mechanisms on a single platform, including QR codes or
other visual markers, ultrasound, audio (e.g., embedded in
music), location, Bluetooth, or other wireless technologies.
Additionally, world-driven access control supports both poli-
cies that completely block events (e.g., block RGB frames
in the bathroom) and that selectively modify events (e.g.,
remove bystanders from RGB frames). Appendix A summa-
rizes existing real-world policies (e.g., recording bans) that
can be supported by this approach and which motivate the
incentives of establishments to deploy world-driven policies.
A world-driven policy speciﬁes (1) when and for how long
it should be active, (2) to which real-world objects or loca-
tions it applies, (3) how the system should enforce it, and
(4) to which applications it applies, if applicable. Elaborat-
ing on the latter, policies can be application-speciﬁc, such as
by whitelisting known trusted applications. For example, a
corporate building’s policy might block audio input for any
application not signed with the company’s private key.
While conceptually simple, there are numerous challenges
for communicating policies in practice.
In our design, we
aim to quickly recognize a policy, quickly recognize the spe-
ciﬁc objects or locations to which it applies, and accurately
enforce it. A challenge in achieving these goals is that policy
communication technologies diﬀer in range, accuracy, infor-
mation density, and the ability to locate speciﬁc real-world
objects. For example, Bluetooth or WiFi can be detected
accurately across a wide area but cannot easily refer to spe-
ciﬁc objects (without relying on computer vision or other
object detection techniques). By contrast, QR codes can
help the system locate objects relative to their own location
(e.g., the person to whom the QR code is attached), but
their range and detection accuracy is limited (Section 6).
Similarly, a QR code can communicate thousands of bytes
of information, while a speciﬁc color (e.g., a colored shirt or
lanyard [3, 36]) can communicate much less.
We begin to tackle these challenges with several approaches,
and return to additional challenges (like recognition latency
and policy authenticity) in later sections:
Extending policy range. The range of a technology should
not limit the range of a policy. We thus allow a policy to
specify whether it is active (1) while the policy signal itself
is in range, (2) for some speciﬁed time or location, or (3)
until an explicit “end policy” signal is sensed. For example,
a WiFi-based policy for a building might use the ﬁrst op-
tion, and a QR-code-based policy for a bathroom might use
the third option (with “start” and “end” policy QR codes on
either side of the bathroom door). There are challenges even
with these approaches; e.g., the “end policy” signal may be
missed. To overcome missed signals, the QR-code-based pol-
icy can fall back to a timeout (perhaps after ﬁrst notifying
the user) to avoid indeﬁnitely applying the policy.
Increasing information density. Policies need not be
speciﬁed entirely in a real-world signal. Instead, that signal
can contain a pointer (such as a URL) to a more detailed
remote policy. Based in part on this idea, we introduce
passports as a method for dynamically extending the system
with new policy code in Section 4.
Combining technologies. Observing that diﬀerent com-
munications methods have diﬀerent tradeoﬀs, we propose
the use of hybrid techniques: allowing multiple mechanisms
to work together to express a policy. For example, to re-
move bystanders wearing a speciﬁc color from RGB frames, a
wide-range high-density technology like Bluetooth can boot-
strap the policy by informing the system of the opt-out color;
the color helps locate the area to remove from a frame.
Microsoft Research Tech Report MSR-TR-2014-67
3.4 Policy Detection and Enforcement
There is considerable diversity in the types of policies ob-
jects may wish to convey, and hence our solution must be
able to accommodate such diversity. As surfaced in this and
later sections, not all policies are trivial to handle.
World-driven policies are enforced by a trusted policy mod-
ule on the platform (Figure 3). The policy module sub-
scribes to all (or many) of the system recognizers. Any
of these recognizers may produce events that carry policies
(e.g., detected QR codes, WiFi access points, or Bluetooth
signals). The policy module ﬁlters events before they are
delivered to applications. The result of event ﬁltering may
be to block an event or to selectively modify it (e.g., remove
a person from an RGB frame).
In more detail, the policy module keeps the following
state: (1) default permissions for each application (e.g., from
a manifest or other user-set defaults), specifying whether it
may receive events from each recognizer, (2) currently active
policies, and (3) a buﬀer of events from each recognizer.
Before dispatching a recognizer event to an application,
the policy module consults the default permission map and
all active policies. Depending on the result, the policy mod-
ule may block or modify the event.
Event modiﬁcation is complicated by the fact that it may
rely on information in multiple events. For example, if some-
one wearing a QR code should be removed from an RGB
frame, the modiﬁcation relies on (1) the person event, to
isolate the pixels corresponding to a person, and (2) the QR
code event, to pinpoint the person nearest the QR code’s
bounding box (to whom the policy applies).
The policy module thus uses the buﬀer of recognizer events
to identify those needed to enforce a policy. Because corre-
sponding events (those with the same frame number or sim-
ilar timestamps) may arrive at diﬀerent times from diﬀerent
recognizers, the policy module faces a tradeoﬀ between pol-
icy accuracy and event dispatch performance. For example,
consider a QR code that begins an RGB blocking policy. If
the QR code recognizer is slow and the policy module does
not wait for it, an RGB frame containing the QR code may
be mistakenly dispatched before the policy is detected.
Thus, for maximum policy accuracy, the policy module
should wait to dispatch events until all other events on which
a policy may depend have arrived. However, waiting too
long to dispatch an event may be unacceptable, as in an
augmented reality system providing real-time feedback in a
heads-up display. We discuss our implementation choice,
which favors performance, in Section 5.
3.5 Policy Interface
Each world-expressed policy has a ﬁxed interface (Fig-
ure 4), which allows policy writers to extend the system’s
policy module without dictating implementation. We ex-
pect that policies are typically short (those we describe in
Sections 5 and 6 all require under 150 lines of C#) and rely
on events from existing object recognizers, so policy writers
need not implement new recognizers.
The key method is ApplyPolicyToEvent, which is called
once for each event dispatched to each application. This
method takes as input the new event and a buﬀer of previous
events (up to some bound), as well as metadata such as
the application in question and the system’s conﬁguration
(e.g., current permissions). The policy implementation uses
this information to decide whether and how to modify or
public interface IPolicy {
string PolicyName();
void Init();
void ApplyPolicyToEvent(
RecognizerEvent inEv, EventBuffer prevEvents,
out RecognizerEvent outEv, out bool modified);
void Destroy();
}
Figure 4: Policy Interface. Policies implement this interface
to block or modify events before they are passed to applications.
block the event for this application. The resulting event is
returned, with a ﬂag indicating whether it was modiﬁed.
The resulting event is then passed to the next policy,
which may further modify or block it.
In this way, poli-
cies can be composed. Although later modiﬁcations are lay-
ered atop earlier ones, each policy also receives unmodiﬁed
events in the event buﬀer used to make and enforce policy
decisions. Thus, poorly written or malicious policies cannot
confuse the decisions of other policies.
Policy code isolation. Policy code can only use this re-
stricted API to obtain and modify sensor events. Policies
must be written in managed code and may not invoke native
code, call OS methods, or access the ﬁle system, network,
or GPU. (Isolating managed code in .NET is common with
AppDomains [27].) Our restrictions protect the user and
the OS from malicious policy code, but they do impose a
performance penalty and limit policies to making local deci-
sions. Our evaluation shows that we can still express many
realistic policies eﬃciently.
Policy conﬂicts. In the case of policy conﬂicts, the system
must determine an eﬀective global policy. If multiple world-
driven policies conﬂict, the system takes the most restrictive
intersection of these policies. In the case of a conﬂict due to
a user’s policy or explicit action, recall that we cannot force
users or their devices to comply with world-driven policies,
since users can always use hardware not running our sys-
tem. The system can thus let the user override the policy
(e.g., by incorporating access control gadgets [35] to ver-
ify that the action genuinely came from the user, not from
an application) and/or use a conﬁrmation dialog to ensure
that the violation of the world-driven policy is intentional,
not accidental, on the user’s part. This approach also gives
users the ability to override malicious or questionable poli-
cies (e.g., policies that block too much or too little).
4. PASSPORTS: POLICY AUTHENTICITY
AND RUNTIME EXTENSIONS
In this section, we simultaneously address two issues: pol-
icy authenticity and system extensibility. First, an attacker
may attempt to forge, move, or remove an explicit world-
driven policy, requiring a method to verify policy authen-
ticity. Second, new policy communication technologies or
computer vision approaches may become available, and our
system should be easily extensible.
To address both issues, we introduce a new kind of digital
certiﬁcate called a passport.
Inspired by real-world travel
passports, our policy passport is designed to support policy
authenticity by verifying that a passport (1) is issued by a
trusted entity, and (2) is intended to apply to the object
or location where it is observed. To support extensibility, a
passport may additionally contain sandboxed object recog-
nition and/or policy code to dynamically extend the system.
Microsoft Research Tech Report MSR-TR-2014-67
4.1 On the Need for Policy Authenticity
We elaborate here on the need to address attackers who
might wish to make unauthorized modiﬁcations to existing
policies. Attacker modiﬁcations may make policies less re-
strictive (e.g., to trick employees of a company into acci-
dentally taking and distributing photos of conﬁdential in-
formation in conference rooms) or more restrictive (e.g., to
prevent the cameras of surrounding users from recording the
attacker breaking a law). In particular, attackers attempting
to change policies may employ the following methods:
1. Creating a forged policy.
2. Moving a legitimate policy from one object to another
(eﬀectively forging a policy on the second object).
3. Removing an existing policy.
The diﬃculty of mounting such attacks depends on the
policy communication technology. For example, it may be
easy for an attacker to replace, move, or remove a QR code,
but more diﬃcult to do so for an ultrasound or WiFi signal.
Thus, these risks should be taken into account by object or
location owners deploying explicit policies.
The threat of policy inauthenticity also varies by object.
For example, it is likely more diﬃcult for an attacker to forge
a policy (like a QR code) aﬃxed to a person than one aﬃxed
to a wall. Thus, for certain types of objects, such as humans,
the system may trust policies (e.g., colored lanyards as opt-
outs [3]) without requiring additional veriﬁcation, under the
assumption that it is diﬃcult to physically manipulate them.