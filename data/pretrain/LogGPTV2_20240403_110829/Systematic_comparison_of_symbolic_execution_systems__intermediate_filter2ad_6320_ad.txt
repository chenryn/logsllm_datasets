### 4. Query Complexity Analysis

**Figure 4: Comparison of Query Rates for Each System**

The following query rates, measured using a common solver, serve as a proxy for query complexity across 23 CGC programs. Higher rates indicate queries that are easier to solve. Note the differences in median values.

- **Qsym**: 300
- **S2E**: 200
- **Angr**: 100
- **KLEE**: 0

To assess the average solver effort for each tool on identical workloads, isolated from external factors like IR execution speed, we measure the time taken by Z3 to solve all logged queries from successful executions, as described in Section 5.1. The four symbolic execution engines use different versions of Z3 (see Table 1). For comparability, we selected S2E’s build of Z3, which is the most recent and expected to handle the queries generated by other engines gracefully. We deliberately did not set a timeout for individual queries to measure the actual time to completion, thus providing a more accurate measure of query complexity.

**Query Rates and Solver Effort**

Figure 4 illustrates the query rates, defined as the number of queries Z3 can solve in a fixed amount of time. Angr and Qsym exhibit lower query rates compared to KLEE, which has a significantly higher median rate. S2E’s queries fall within a range similar to KLEE’s, which is reasonable given that S2E is based on KLEE. However, S2E’s median rate is considerably lower and more in line with Angr and Qsym. This suggests that the three binary-based symbolic execution systems generate more difficult queries than the source-based system KLEE. Additionally, the observation that both KLEE and S2E issue relatively easy queries in many cases supports the notion that LLVM IR is beneficial for deriving SMT queries. However, it is possible that KLEE generates simpler queries due to implementation details, and since S2E is based on KLEE, it would inherit this advantage.

### 6. Discussion

#### 6.1 Results Interpretation

We have evaluated the impact of IR generation on code size, the suitability of different IRs for symbolic execution, and the complexity of the resulting SMT queries. Our key findings are:

- **Code Size**: The most significant factor is whether IR is generated from source code or binaries. Source-based IR is often more succinct, while binary-based IR inflates the code by a factor of 3 to 7.
- **Execution Speed**: We did not observe a significant difference in execution speed between LLVM bitcode and VEX IR that could not be attributed to implementation aspects. Qsym, however, gains a distinct speed advantage by directly instrumenting machine code, albeit at the cost of portability.
- **Query Complexity**: When generated from machine code, LLVM bitcode and VEX IR lead to queries of similar complexity. S2E generates simpler queries than Angr and Qsym in some cases, but the median query rate is similar. Source-based IR, however, consistently leads to simpler queries during symbolic execution.

These results allow us to address our original research questions:

- **Source vs. Binaries for IR Generation**: Query complexity is lower when IR is generated from source code. While source code is not always available, there are valid reasons for using binary-based symbolic execution, such as the need for low-level information.
- **IR Performance**: The level of abstraction of the IR is crucial for execution speed. Directly executing machine code yields performance benefits. Between LLVM bitcode (generated from binaries) and VEX IR, no significant difference was observed; practical concerns such as API stability and language bindings should guide the choice.

In summary, the most important influence on query complexity is whether the IR is generated from source code or binaries, whereas execution speed is mostly affected by the level of abstraction of the IR, with raw machine code performing best. This creates an interesting tension in the design of symbolic execution engines: for highest execution speed, execution should be based on low-level instructions, while the best solver performance is achieved with queries generated from high-level code.

#### 6.2 Future Work

Our study focuses on the speed of symbolic execution, arguing that faster execution and SMT solving yield more exploration in the same time, increasing the probability of discovering vulnerabilities. Future work could assess the quality of new program inputs generated by symbolic execution, considering factors like code coverage, similarity to existing test cases, redundancy, and directedness towards interesting code segments. A quantifiable definition of test case quality and a sound methodology to measure it would be valuable.

Additionally, evaluating the root causes of query difficulty, such as compiler optimizations, could lead to IR generators that produce more "solver-friendly" IR. Finally, while we analyzed specific aspects of symbolic execution, the overall impact on bug discovery remains an open question. Modularization of symbolic execution components would facilitate end-to-end comparisons.

#### 6.3 Limitations

Comparing design decisions of symbolic execution engines in isolation is challenging. We have made significant efforts to eliminate noise from our experiments, but some effects may remain. Differences in programming languages and the limited set of test programs used may also introduce biases. Follow-up work is encouraged to identify and address these remaining biases.

#### 6.4 Remark: Programming Languages

The choice of programming language plays a critical role in the design of symbolic execution engines. For example, KLEE, written in C++, offers performance advantages over Angr, implemented in Python. However, modifying KLEE is more time-consuming than building on Angr. The ideal choice depends on project goals, such as production use or experimentation.

### 7. Related Work

To our knowledge, the impact of IR and IR generation on symbolic execution has not been studied before. Our work builds on various previous results, focusing on symbolic execution and intermediate representations for static and dynamic analysis.

#### 7.1 Symbolic Execution

Symbolic execution lies between rigorous approaches like model checking and practical techniques like fuzz testing. We analyzed KLEE, S2E, Angr, and Qsym, representing different design categories. Other systems include Manticore, Triton, Mayhem, SAGE, Inception, and extensions of KLEE. Recent work has shown promise in combining symbolic execution with fuzzing.

#### 7.2 Intermediate Representations

Various IRs exist, such as LLVM bitcode, VEX, REIL, and BIL. Kim et al. [21] investigate the semantic correctness of lifters for many IRs, orthogonal to our focus on the impact of IR and its generation on symbolic execution.

### 8. Conclusion

We presented a framework for comparing symbolic execution engines and applied it to the impact of IR and IR generation. Such systematic evaluation provides a better basis for design decisions than anecdotal evidence or common belief. We hope this study lays the groundwork for further comparison of specific design aspects in symbolic execution, leading to more principled and efficient systems.

### Acknowledgements

We thank Insu Yun for detailed information on Qsym's evaluation and Vitaly Chipounov for help with S2E. Experiments were conducted using the Grid'5000 testbed, supported by Inria, CNRS, RENATER, and several universities. This work was supported by the DAPCODS/IOTics ANR 2016 project (ANR-16-CE25-0015).

### References

[References are listed as in the original text, with minor formatting adjustments for clarity and consistency.]