300
200
100
0
Qsym
S2E
Angr
KLEE
Figure 4: Comparison of the query rates for each system
(using a common solver) as a proxy for query complexity,
across 23 CGC programs. Higher rates indicate queries that
are easier to solve. Note the differences in median.
and measure its response time. This allows us to assess the average
solver effort for each tool on identical workloads, isolated from
external factors like IR execution speed.
We measure the time taken by Z3 to solve all the logged queries
of successful executions as per Section 5.1. The four symbolic ex-
ecution engines install different versions of Z3 (see Table 1); for
comparability, we picked one and used it for all measurements. We
chose S2E’s build of Z3 because it is the most recent among the
four, so we expect it to gracefully handle the queries generated by
the other engines. Note that we deliberately do not set a timeout
for individual queries: We are interested in how long a query would
run to completion—i.e., its complexity—instead of just the time that
it would be allowed to run in practice.
Figure 4 shows the query rates we measured, i.e., the number of
queries that Z3 can solve in a fixed amount of time. We see that
angr and Qsym exhibit lower query rates than KLEE, whose median
rate is significantly higher. S2E’s queries fall into a range similar to
KLEE’s (which is sensible because S2E is based on KLEE), but note
that S2E’s median is considerably lower and more in line with angr
and Qsym. In general, it seems that the three binary-based symbolic
execution systems generate more difficult queries than the source-
based system KLEE. Moreover, the observation that both KLEE and
S2E issue relatively easy queries in many cases supports the notion
that LLVM IR is beneficial for deriving SMT queries. However, we
cannot rule out the possibility of KLEE generating simpler queries
than the other systems due to implementation details; since S2E is
based on KLEE, it would inherit the same advantage.
6 DISCUSSION
In this section, we interpret the results of our evaluation and discuss
their significance.
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
Sebastian Poeplau and Aurélien Francillon
6.1 Results
We have measured the impact of IR generation on code size, the
suitability of different IRs for symbolic execution, and the complex-
ity of the resulting SMT queries. In summary, we have found the
following:
• For code size, the most important factor is whether IR is
generated from source code or binaries. While source-based
IR is often more succinct than machine code, binary-based
IR tends to inflate the code by a factor between 3 and 7.
• We do not observe a significant difference in execution speed
between LLVM bitcode and VEX IR that could not be attrib-
uted to implementation aspects. Qsym, however, gains a
distinct advantage in speed by dispensing with a traditional
IR and instrumenting machine code directly, at the expense
of portability.
• When generated from machine code, LLVM bitcode and
VEX IR lead to queries of similar complexity; queries de-
rived directly from machine code are in the same range. S2E
does generate simpler queries than angr and Qsym in some
cases, but the median query rate is similar. Source-based IR,
however, appears to reliably lead to simpler queries during
symbolic execution.
Therefore, we are now in a position to answer our original re-
search questions.
When source is available, should we generate IR from source code or
binaries? We find that query complexity is lower when IR is gener-
ated from source code. Of course, we acknowledge that source code
is not always available and that sometimes low-level information is
exactly what one is interested in; therefore, there are good reasons
for binary-based symbolic execution as well.
Does any IR perform better than others? We find that the level of
abstraction of the IR is important for execution speed; in particular,
executing machine code directly yields performance benefits. When
comparing the “traditional” IRs, there is no observable difference
between LLVM bitcode (generated from binaries) and VEX IR in our
measurements; we believe that, for choosing one or the other, prac-
tical concerns such as API stability and the availability of language
bindings are more important factors than the impact on symbolic
execution.
To summarize, we show that the most important influence on
query complexity is whether the IR is generated from source code or
binaries, whereas execution speed is mostly affected by the level of
abstraction of the IR, with raw machine code performing best. This
creates an interesting tension in the design of symbolic execution
engines: for highest execution speed, execution should be based
on low-level instructions, whereas the best solver performance is
achieved with queries generated from high-level code.
6.2 Future Work
Our study focuses on the speed of symbolic execution, and we argue
that faster execution and SMT solving yield more exploration in
the same time, thus increasing the probability of discovering vul-
nerabilities. An interesting direction for future work, especially in
the context of combined fuzzing and symbolic execution, would be
to assess the quality of new program inputs generated by symbolic
execution. A measurable notion of quality should include factors
like the resulting increase in code coverage, similarity to existing
test cases (for easier bug triage), redundancy of test inputs, and “di-
rectedness” towards interesting pieces of code, among others. After
finding a quantifiable definition of test case quality, one would have
to develop a sound methodology to actually measure it; we believe
that the results could be very interesting for the community.
In a similar vein, it would be interesting to evaluate what makes
queries hard for a solver. We showed in our study that IR gener-
ated from binaries leads to harder SMT queries than IR generated
from source code—what is the root cause of the difference in diffi-
culty? Compiler optimizations come to mind as a possible source of
complexity. However, we expect at least some of them to simplify
reasoning about code rather than making it harder: for instance,
when a multiplication is replaced with a bit shift during strength
reduction, the optimization should not only speed up the program
but also reduce the difficulty of the corresponding queries. A sys-
tematic evaluation of the sources of complexity in the queries that
arise during symbolic execution might lead to IR generators that
produce more “solver-friendly” IR.
Finally, in our study we have analyzed the impact of IR and
IR generation on specific aspects of symbolic execution, but we
have not evaluated the effect on the overall goal: how does the
IR aspect impact bug discovery? While this is a highly interesting
question, we believe that answering it is a hard challenge. The dif-
ferent symbolic execution engines use vastly different strategies to
generate new test cases, involving different choices in the selection
and configuration of the SMT solver, the caching and preprocessing
of queries, the soundness requirements on the analysis, etc. Figura-
tively speaking, all the components of symbolic execution depicted
in Figure 1 would introduce variables in such an end-to-end com-
parison. We would be delighted to see more modularization in this
space: if the individual components of symbolic execution engines
were interchangeable, measuring the impact of a single choice on
the overall goal would become much more feasible.
6.3 Limitations
Comparing design decisions of symbolic execution engines in isola-
tion is a complicated matter: we have discussed numerous ways for
seemingly unrelated design decisions to threaten the accuracy of
our measurements. And while we have invested significant effort
to eliminate such noise from our experiments, there may be effects
that we couldn’t fully remove. Moreover, some differences cannot
be reasonably eliminated, such as the impact of the respective pro-
gramming languages that the systems are built in. Finally, we have
run our experiments on a limited set of test programs that may not
be representative. We would like to explicitly encourage follow-up
work that strives to identify remaining biases in the comparison of
symbolic execution engines.
6.4 Remark: Programming Languages
We note in passing that the choice of programming language plays
an important role in positioning a symbolic execution engine. For
example, KLEE is written in C++, which gives it considerable per-
formance advantages over angr, implemented in Python. However,
we know from experience that modifying the former is much more
Symbolic Execution: IR and its Generation
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
time-consuming than building on top of the latter; we attribute
the difference to the different characteristics of the respective pro-
gramming languages. There is, of course, no perfect solution; the
ideal choice for a given project will vary depending on, among a lot
of other factors, whether production use or experimentation and
exploration are the main goal. However, we think it is important to
consider such aspects upfront and to make a conscious decision.
7 RELATED WORK
To the best of our knowledge, the impact of the choice of IR and
IR generation process on symbolic execution has not been studied
before. However, our work builds on top of various previous results.
In this section, we frame our study in the context of the current
state of the art, focusing in particular on symbolic execution and
intermediate representations for static and dynamic analysis.
7.1 Symbolic Execution
Symbolic execution lies on a spectrum between more rigorous ap-
proaches, such as model checking [18, 31], and techniques that
sacrifice soundness for practicality, such as fuzz testing [17]. Apart
from the four symbolic execution engines that form the basis of our
analysis, namely KLEE [8], S2E [11], angr [38] and Qsym [43], each
representing a design category as described in Section 4, several
others have been proposed and implemented. Manticore [40] is
similar in focus to angr and implemented in Python as well but
does not use any intermediate representation. Triton [36] is based
on dynamic binary translation, like Qsym. Mayhem [10], based
on BAP [5], is the winner of the DARPA CGC competition (but
not freely available, and BAP alone does not support symbolic ex-
ecution in recent versions). SAGE [20] is a closed-source system
developed by Microsoft, following a concolic execution approach.
Inception [14], based on KLEE, is among the few symbolic execu-
tion engines with support for ARM, and it addresses the challenge
of handling inline assembly in source-based symbolic execution.
However, it targets microcontrollers that run their target software
directly, without an operating system. This difference in focus ren-
ders it hard to compare to the four systems in our study. Finally,
various other systems extend KLEE with additional functionality,
e.g., localized vulnerability detection [33], support for floating-point
arithmetic [13], parallel analysis [7], or state merging [24]. Recently,
combining symbolic execution with fuzzing has been shown to hold
great promise [39, 43].
Our study focuses on a particular aspect in the design and im-
plementation of symbolic execution systems. In a similar spirit,
previous work has focused on the choice of SMT solvers [29] and
the impact of incremental SMT solving [27]. A recent survey by Bal-
doni et al. [1] covers the general subject area of symbolic execution,
and Xu et al. survey challenges of the field [41].
7.2 Intermediate Representations
There are a variety of intermediate representations. LLVM bit-
code [25], employed by KLEE and S2E, was originally designed
for use inside compilers. VEX [28], used by angr, targets binary
instrumentation and was conceived for the Valgrind framework.
Others, such as REIL [26] and BIL [5] have been developed specifi-
cally for security analysis. Kim et al. [21] investigate the semantic
correctness of lifters for many intermediate representations. Their
work is orthogonal to ours: we assess the impact of the IR and the
associated generation process on symbolic execution (presupposing
correctness), while they focus on the semantic correctness of the
IR generators.
8 CONCLUSION
We have presented a framework for comparing different symbolic
execution engines and applied it to the question of how IR and
IR generation impact symbolic execution. We believe that such
systematic evaluation forms a much better basis for design decisions
than anecdotal evidence or common belief. It is our hope that this
study lays the groundwork for further comparison of specific design
aspects in symbolic execution, ultimately leading to more principled
decisions and, hopefully, more efficient systems.
ACKNOWLEDGEMENTS
We are grateful to Insu Yun for detailed information on the evalua-
tion of Qsym [43], which greatly simplified its setup for the purpose
of our study. Moreover, we would like to thank Vitaly Chipounov
for his help in debugging problems with S2E [11]. Experiments pre-
sented in this paper were carried out using the Grid’5000 testbed,
supported by a scientific interest group hosted by Inria and includ-
ing CNRS, RENATER and several Universities as well as other orga-
nizations (see https://www.grid5000.fr). This work was supported
by the DAPCODS/IOTics ANR 2016 project (ANR-16-CE25-0015).
REFERENCES
[1] Roberto Baldoni, Emilio Coppa, Daniele Cono D’elia, Camil Demetrescu, and
Irene Finocchi. 2018. A survey of symbolic execution techniques. ACM Computing
Surveys (CSUR) 51, 3 (2018), 50.
[2] Clark Barrett, Aaron Stump, and Cesare Tinelli. 2010. The SMT-LIB standard:
Version 2.0. In Proceedings of the 8th International Workshop on Satisfiability
Modulo Theories (Edinburgh, England), Vol. 13. 14.
[3] Fabrice Bellard. 2005. QEMU, a fast and portable dynamic translator. In USENIX
Annual Technical Conference, FREENIX Track, Vol. 41. 46.
[4] Ella Bounimova, Patrice Godefroid, and David Molnar. 2013. Billions and Billions
of Constraints: Whitebox Fuzz Testing in Production. In Proceedings of the 2013 In-
ternational Conference on Software Engineering (ICSE ’13). IEEE Press, Piscataway,
NJ, USA, 122–131. http://dl.acm.org/citation.cfm?id=2486788.2486805
[5] David Brumley, Ivan Jager, Thanassis Avgerinos, and Edward J Schwartz. 2011.
BAP: A binary analysis platform. In International Conference on Computer Aided
Verification. Springer, 463–469.
[6] Robert Brummayer and Armin Biere. 2009. Boolector: An efficient SMT solver
for bit-vectors and arrays. In International Conference on Tools and Algorithms for
the Construction and Analysis of Systems. Springer, 174–177.
[7] Stefan Bucur, Vlad Ureche, Cristian Zamfir, and George Candea. 2011. Parallel
symbolic execution for automated real-world software testing. In Proceedings of
the 6th ACM SIGOPS/EuroSys Conference on Computer Systems. ACM, 183–198.
[8] Cristian Cadar, Daniel Dunbar, and Dawson R. Engler. 2008. KLEE: Unassisted and
Automatic Generation of High-Coverage Tests for Complex Systems Programs.
In OSDI, Vol. 8. 209–224.
[9] Cristian Cadar, Vijay Ganesh, Peter M. Pawlowski, David L. Dill, and Dawson R.
Engler. 2008. EXE: automatically generating inputs of death. ACM Transactions
on Information and System Security (TISSEC) 12, 2 (2008), 10.
[10] Sang Kil Cha, Thanassis Avgerinos, Alexandre Rebert, and David Brumley. 2012.
Unleashing mayhem on binary code. In 2012 IEEE Symposium on Security and
Privacy. IEEE, 380–394.
[11] Vitaly Chipounov, Volodymyr Kuznetsov, and George Candea. 2011. S2E: A
platform for in-vivo multi-path analysis of software systems. In ACM SIGARCH
Computer Architecture News, Vol. 39. ACM, 265–278.
[12] Cristina Cifuentes and K. John Gough. 1995. Decompilation of binary programs.
Software: Practice and Experience 25, 7 (1995), 811–829.
[13] Peter Collingbourne, Cristian Cadar, Paul H.J. Kelly, et al. 2011. Symbolic cross-
checking of floating-point and SIMD code. In European Conference on Computer
Systems (EuroSys 2011).
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
Sebastian Poeplau and Aurélien Francillon
[14] Nassim Corteggiani, Giovanni Camurati, and Aurélien Francillon. 2018. Inception:
system-wide security testing of real-world embedded systems software. In 27th
USENIX Security Symposium (USENIX Security 18). 309–326.
[15] Leonardo De Moura and Nikolaj Bjørner. 2008. Z3: An efficient SMT solver. In
International conference on Tools and Algorithms for the Construction and Analysis
of Systems. Springer, 337–340.
[16] Artem Dinaburg and Andrew Ruef. 2014. McSema: Static translation of x86
instructions to LLVM. In ReCon 2014 Conference, Montreal, Canada.
[17] Joe W. Duran and Simeon Ntafos. 1981. A Report on Random Testing. In Proceed-
ings of the 5th International Conference on Software Engineering (ICSE ’81). IEEE
Press, Piscataway, NJ, USA, 179–183. http://dl.acm.org/citation.cfm?id=800078.
802530
[18] E. Allen Emerson and Edmund M. Clarke. 1980. Characterizing correctness
properties of parallel programs using fixpoints. In International Colloquium on
Automata, Languages, and Programming. Springer, 169–181.
[19] Free Software Foundation. 2016. Coreutils - GNU core utilities. https://www.gnu.
org/software/coreutils/. Accessed: 2019-02-04.
[20] Patrice Godefroid, Michael Y. Levin, and David Molnar. 2012. SAGE: whitebox
fuzzing for security testing. Commun. ACM 55, 3 (2012), 40–44.
[21] Soomin Kim, Markus Faerevaag, Minkyu Jung, SeungIl Jung, DongYeop Oh,
JongHyup Lee, and Sang Kil Cha. 2017. Testing intermediate representations for
binary analysis. In Proceedings of the 32nd IEEE/ACM International Conference on
Automated Software Engineering. IEEE Press, 353–364.
[22] James C. King. 1976. Symbolic execution and program testing. Commun. ACM
19, 7 (1976), 385–394.
[23] Gergely Kovásznai, Helmut Veith, Andreas Fröhlich, and Armin Biere. 2014. On
the complexity of symbolic verification and decision problems in bit-vector logic.
In International Symposium on Mathematical Foundations of Computer Science.
Springer, 481–492.
[24] Volodymyr Kuznetsov, Johannes Kinder, Stefan Bucur, and George Candea. 2012.
Efficient state merging in symbolic execution. Acm Sigplan Notices 47, 6 (2012),
193–204.
[25] Chris Lattner and Vikram Adve. 2004. LLVM: A compilation framework for
lifelong program analysis & transformation. In Proceedings of the International
Symposium on Code Generation and Optimization: Feedback-Directed and Runtime
Optimization. IEEE Computer Society, 75.
[26] Lixin Li and Chao Wang. 2013. Dynamic analysis and debugging of binary code
for security applications. In International Conference on Runtime Verification.
Springer, 403–423.
[27] Tianhai Liu, Mateus Araújo, Marcelo d’Amorim, and Mana Taghdiri. 2014. A
comparative study of incremental constraint solving approaches in symbolic
execution. In Haifa Verification Conference. Springer, 284–299.
[28] Nicholas Nethercote and Julian Seward. 2007. Valgrind: a framework for heavy-
weight dynamic binary instrumentation. In ACM SIGPLAN 2007 Conference on
Programming Language Design and Implementation (PLDI 2007), Vol. 42. ACM,
89–100.
[29] Hristina Palikareva and Cristian Cadar. 2013. Multi-solver support in symbolic
execution. In International Conference on Computer Aided Verification. Springer,
53–68.
[30] Xiao Qu and Brian Robinson. 2011. A case study of concolic testing tools and their
limitations. In 2011 International Symposium on Empirical Software Engineering
and Measurement. IEEE, 117–126.
[31] Jean-Pierre Queille and Joseph Sifakis. 1982. Specification and verification of
concurrent systems in CESAR. In International Symposium on Programming.
Springer, 337–351.
[32] Nguyen Anh Quynh and Dang Hoang Vu. 2015. Unicorn – The ultimate CPU
emulator. https://www.unicorn-engine.org/. Accessed: 2019-02-26.
[33] David A. Ramos and Dawson Engler. 2015. Under-constrained symbolic execution:
Correctness checking for real code. In 24th USENIX Security Symposium (USENIX
Security 15). 49–64.
[34] Eric F Rizzi, Sebastian Elbaum, and Matthew B. Dwyer. 2016. On the techniques
we create, the tools we build, and their misalignments: a study of KLEE. In 2016
IEEE/ACM 38th International Conference on Software Engineering (ICSE). IEEE,
132–143.
[35] S2E issue tracker. 2019. Add support for symbolic MMX registers. https://github.
com/S2E/s2e-env/issues/144. Accessed: 2019-06-04.
[36] Florent Saudel and Jonathan Salwan. 2015. Triton Dynamic Binary Analysis
Framework. https://github.com/JonathanSalwan/Triton. Accessed: 2019-04-02.
[37] Edward J Schwartz, Thanassis Avgerinos, and David Brumley. 2010. All you ever
wanted to know about dynamic taint analysis and forward symbolic execution
(but might have been afraid to ask). In 2010 IEEE Symposium on Security and
Privacy. IEEE, 317–331.
[38] Yan Shoshitaishvili, Ruoyu Wang, Christopher Salls, Nick Stephens, Mario Polino,
Andrew Dutcher, John Grosen, Siji Feng, Christophe Hauser, Christopher Kruegel,
et al. 2016. SoK: (State of) The Art of War: Offensive Techniques in Binary