appeared in the list of top-ﬁve most probable words.
Error analysis. Our attack often confuses a commonly
used word for a rare one. For example, the word “dream”
is erroneously predicted as “bream”. To avoid such errors,
we can introduce priors on word and character distributions
(increasing our conservatively low base rate). For example,
by assigning a higher probability for frequent words in the
probability-assigning phase. This would likely signiﬁcantly
increase accuracy, especially for commonly used words such
as those in our training set.
VI. WEBSITE DISTINGUISHING
In this attack, the attacker is interested in learning whether
the victim is entering a speciﬁc website, or is just interested
in the victim’s website visiting habits. Website ﬁngerprinting
attacks, often studied in network trafﬁc analysis settings [40],
[42], [10], convey the target user’s browsing behavior and
are very revealing of their hobbies and personality [31]. In
the VoIP setting, the attacker may be interested to learn in
real time what the other parties to the call are doing. For
example, he may wish to learn whether another party to the
call is currently keeping the videoconference app maximized
(presumably focusing his attention on the call), browsing
Facebook, or responding to E-mails.
7To measure this, we introduced sharp pixel
intensity changes in two
different pixel
these
changes affect the signal. Because line rendering time is linear in line numbers,
we can use this to construct an accurate mapping of lines to rendering time.
lines and measured when, during the refresh cycle,
863
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:34 UTC from IEEE Xplore.  Restrictions apply. 
We note here that the classiﬁers described in Section VI-A
accurately distinguish up to 100 websites. Thus, as our method-
ology can accurately classify screen content, it can be lever-
aged for detecting an identiﬁed website visit vs. using common
apps as well as classifying common apps. Finally, we also note
that the collected website traces naturally contain dynamically-
changing content (e.g., ads) affecting measurements, but clas-
siﬁers nevertheles attain the high accuracy (implying that the
general layout of a website is typically static and unique).
In Section VI-B, we directly evaluate a VoIP attacker
whose goal is identifying the victim’s foreground window,
distinguishing between a VoIP app and popular websites.
A. Using the modulated signal
Data collection and preprocessing. We recorded traces
of a Soyo 22" DYLM2248 at the close-range, at-distance,
and phone attack settings (Sections III-A and III-B). Out of
the Moz top-500 list [37], that ranks websites according to
the number of other websites linking to them (which highly
correlates with popularity), we chose 97 websites by ﬁltering
out corner cases. For example, duplicate domains for the same
website (e.g., google.co.in and google.co.jp) and non-US-based
websites because some of them cause Selenium to hang.
We simulated the attack for the smartphone, at-distance,
and close-range vantage points. For each, we iterated over the
collection of websites over 100 times. In each iteration, we
opened a Chrome browser window (controlled by the Selenium
automation library for Python) with the URL of the website.
We then started recording for 5 s. For each vantage point, we
collected traces for 5 consecutive nights (when the recording
machine was not otherwise in use). We stopped when we
had reached 100 samples per website. This resulted in about
130 traces per website in the close-range vantage point, 100
traces from the at-distance vantage point, and 110 traces in
the smartphone vantage point. For each setting, we used 70%
of traces for training. For the close-range setting, we used the
remaining 30% as a validation, which we used to guide our
classiﬁer architecture tuning (e.g., set learning rate, number of
convolutional layers, etc). For the at-distance and smartphone
settings, we used the remaining 30% as test sets. We apply the
signal processing algorithm described in Section II-D.
Machine learning and results. Our task is to ﬁnd which of
97 websites is displayed. We train a CNN directly to solve this
task (see Appendix B3), using the setup from Section IV-B.
In about 8% of traces in the close-range and phone attacks,
and about 16% in the at-distance attack, the signal processing
algorithm returned an error, implying the signal is particularly
noisy. For the close-range setting, the validation set accuracy
was 97.09%. For the smartphone and at-distance test sets, the
accuracy was 91.20% and 90.9% respectively.
Eliminating false positives. Our classiﬁers in this section
work in a closed-world, where the victim visits one out of the
(here, 97) targeted websites. In reality the victim may also visit
other, unknown websites, and the attacker may be interested in
detecting when that occurs. The victim could visit numerous
websites before ever visiting a targeted website, so even an
ostensibly low probability of an alarm on a single non-targeted
site’s trace, can lead to many false alarms. This is so-called
“base rate fallacy” is extensively discussed in ﬁngerprinting
literature [42], [27]. We thus aim to further minimize the
probability of false identiﬁcation (false positive rate).
Neural network classiﬁers assign to all classes values
between 0 to 1, whose sum is 1 (similar to a probability
distribution). The prediction is the class with the highest value,
which can be interpreted as the prediction’s conﬁdence. We can
prioritize precision over recall by dropping predictions where
conﬁdence is below a threshold. By setting the threshold to
0.96, we get precision of 0.996, whereas the recall remains well
above 0.94. Our classiﬁer is conﬁdently erroneous only on 14
out of 3222 validation set samples. Moreover, for every other
sample where a conﬁdent mistake was not made, it successfuly
disqualiﬁes not 1 class, as the attacker above requires, but
96 classes. In other words,
it makes only 14 “conﬁdent”
mistakes out of 3222 × 96 = 309312 possible ones (it is
conﬁdently mistaken at a rate of ≈ 5/100000). Thus, while
we do not directly simulate an open-world setting, our results
do demonstrate the necessary low amount of false positives for
detection in very low base rates.
Cross-screen results.
In Section VII we extensively evaluate
the prospects of this attack in a cross-screen setting, where the
attacker has no access to the victim’s screen.
B. Attack through a Hangouts call
is at
Here, we assume the attacker and victim are sharing a
Hangouts video-chat session, where audio from the victim’s
environment is transmitted directly to the attacker. Leveraging
acoustic leakage from the victim screen, the attacker’s goal
is to distinguish the scenario where video-chat
the
foreground from a scenario where the victim is surﬁng the
Web, and also tell what website they are visiting.
Data collection and preprocessing. We recorded traces using
the setup described in Section III-C. We iteratively switched
the foreground window of the victim screen in a round-robin
fashion between 11 open windows: browser windows for each
of the 10 top websites in Moz, and a (screen-shot) of a video-
chat showing the human face of the attacker sitting in front
of his webcam. We captured a 6 s recording before switching
the next window into the foreground. In this way we collected
300 traces, 6 s each, for each open window.
In previous attack settings, we used the fact that the pattern
of interest is modulated and transmitted, in every refresh pe-
riod, over a carrier signal at 32 kHz. We leveraged this to pro-
duce a relatively clean version of a display-content-dependent
leakage signal (see Section II-D). Here, we only sample at
44 kHz—below the Nyquist rate of the carrier signal. We can
still, however, leverage the effect described in Section II-C—
namely, that pixel intensity directly affects the acoustic signal’s
amplitude. We process traces in a more straightforward way:
we computed the fast Fourier transform of each 6 s trace. This
results in a vector of frequency coefﬁcients, corresponding
with frequencies between 0 kHz and 44100/2 = 22050 kHz.
We take coefﬁcients of frequencies in band 9-15 kHz which,
we found, contain sufﬁcient information, and used them as the
classiﬁer input vector. We split the traces to train (70%) and
validation (30%).
Machine learning and results. Our task is to ﬁnd which of
11 windows was in foreground. As in Section VI-A, we design
a CNN directly trained to solve this task (see Appendix B3).
The CNN reaches 99.4% accuracy on the validation set.
We compare results on over-VoIP acquired traces and traces
acquired in the close-range setting. To facilitate a fair compar-
ison, we need 2 similar datasets of traces, with the difference
864
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:34 UTC from IEEE Xplore.  Restrictions apply. 
that one was collected through the close-range setting and
preprocessed as in Section VI-A, and one colleted via the
VoIP setting and preprocessed as above. We use subsets of the
datasets described in this section and that in Section VI-A; both
subsets contain about 80 5 s training traces per website. We
trained a classiﬁer for each dataset, using the appropriate CNN
architecture (see appendix B3). The through-VoIP classiﬁer
attained an accuracy of 98% on the validation set, slightly
less than the through-VoIP classiﬁer described above (which
handles 1 extra class, but uses x3 more traces per class). The
close-range classiﬁer attained an accuracy of 99.2%.
We conclude there is a minor drop in the attacker’s accu-
racy when sound is recorded using commodity equipment and
is moreover encoded and decoded using a lossy VoIP codec.
However, using a higher amount of traces, we still attain near-
perfect accuracy in the through-VoIP setting.
Cross-screen results. We collected and processed 30 traces
per class (totaling 330) from another Dell 2208WFPt screen,
and tested our classiﬁer on them. Our classiﬁer had an accuracy
of around 0.1, slightly above a random guess, indicating that
the classiﬁer is overﬁtted to the training screen. In Section VII,
we show that overﬁtting can often be mitigated by training
on more than one screen. We leave the task of applying that
methodology for this attack to future work.
VII. CROSS-SCREEN ATTACKS
Thus far, we performed preliminary evaluations of the
cross-screen scenario for most attacks, by training on one
screen and testing on a different one. While this proved highly
effective in some cases, such an attacker does risk training a
model oferﬁtted to the traits of a speciﬁc screen. In this section
we demonstrate how overﬁtting can be mitigated by training
on multiple screens rather than one.
Data collection.
We used a total of ten screens: ﬁve of
model Dell 2208WFPt WD-04 (the Dell4 set), two of model
Dell 2208WFPt WD-05 (Dell5), two of model Dell 2208WFPf
B (DellB), and one of model Soyo 22" DYLM2248. The screen
set was chosen to contain both similarity (nine screens in the
Dell 2208WFP* family) but also variation (including three
different Dell models and one Soyo model). For every screen,
we collected 50 recordings, 5 s each, of each of 25 websites
(similarly to Section VI, the top 25 websites in the Moz top
500), in the close-range setting (see Section III-A).
Data preprocessing. We ﬁrst applied the signal processing
from Section II-D. Then, for each victim screen v, we evaluate
classiﬁers trained using each of its training collections:
• Each single screen (including v).
• Each of same-model sets (Dell4, Dell5 and DellB) deﬁned
above, excluding v from the corresponding set.
• The mixed collection, containing 2 randomly chosen
screens from Dell4, 1 from Dell5, and 1 from DellB,
excluding v.
• The all collection, containing all 10 screens, excluding v.
• The nosoyo collection, with all screens except the Soyo.
For every such collection c, we assembled a training data
containing about 50 samples for each website, by taking 50/|c|
samples for each screen in c.
Machine learning and results. We used our website distin-
guisher architecture similar to that in Section VI, but used the
Adadelta optimizer which converges much faster than SGD
Fig. VII.1: Cross-screen classiﬁcation accuracy.
when using only 25 classes, and thus trained for only 200
epochs. For each v, we trained our classiﬁer on each of its
training collections and evaluated the resulting classiﬁer on v’s
data (re-initializing learned weights at random before the next
training process). The results are summarized in Figure VII.1.
Observations. First, we observe that classiﬁers trained on one
of the 3 Dell models often generalized to a different model
within the Dell 2208WFP* family. This sometimes happens
even when training on just one screen (e.g., several classiﬁers
generalize well on screen Dell4#2), and especially when
training and testing on screens of the same model. Second,
using more screens from the same family improves the intra-
family generalization: training on a single screen yields worse
results than training on two screens (i.e., Dell4 or Dell5);
training on 4 screens yields further improvement (mixed and
Dell4); and training on 9-10 screens (all and nosoyo) gives the
best results. Third, intra-model generalization is slightly higher
than generalization across the Dell models: for classiﬁers
trained on a single Dell screen and tested a different screen of
the same model, the average accuracy is 0.276, compared to
0.233 for screens of other Dell models. Finally, inter-vendor
generalization is poor: classiﬁers trained on the Soyo screen
have low accuracy for Dell screens and vice versa.
Conclusions.
The accuracy of a remote attacker with no
physical access to the screen is limited by inter-screen gen-
eralization. To attain high generalization, the attacker can use
multiple screens from the same model, or even similar models
from the same vendor. Note that this training phase can be done
once, off-line, and utilized for multiple attacks. It can also be
done retroactively, after recording the victim and using this
recording to ﬁngerprint their screen model.
VIII. LIMITATIONS
While the results presented in this paper clearly demon-
strate that screen content can be detected via an acoustic side
channel, the presented attacks have some limitations:
Remote attack accuracy. Accuracy is reduced in a remote
setting where the adversary uses their own screen(s) for
training (see Section VII, Section IV-B, and Section VI-A).
However, in many cases it remains high (e.g., over 90% for
distinguishing between 25 websites, 98% for distinguishing
letters typed on an on-screen keyboard). Our investigation in
Sections II-E and II-B indicates that different screens display
similar signal content-dependence, explaining why attacks
generalize across screens (when enough screens are used for
training).
Attacker’s prior knowledge. The adversary needs to know
the victim’s screen model (or face reduced accuracy). Note
865
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:34 UTC from IEEE Xplore.  Restrictions apply. 
that such knowledge is far less sensitive than the screen’s
actual content, and is often readily deducible from the victim’s
purchasing procedures or trash. Changes in components other
than the screen could also affect the acoustic leakage (e.g., the
attached computer may use the screen at an unusual display
resolution), but we conjecture that in practice this is rare.
Moreover, for on-screen keyboard snooping (Section IV-B),
an attacker needs to know the on-screen layout of the victim,
including text background, font, key size, etc. We consider this
scenario plausible, as website and keyboard layouts as well as
fonts are often ﬁxed (e.g., when the victim uses the OS’s native
on-screen keyboard to type a login password). Similarly, our