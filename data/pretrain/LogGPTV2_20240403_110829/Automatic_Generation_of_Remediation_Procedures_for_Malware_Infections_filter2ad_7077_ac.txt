infection relations. For example, false positives may re-
sult from the overapproximation of resource names with
6
regular expressions, whereas false negatives may result
from the fact that we do not account for all possible exe-
cution paths in the malware. Thus, it is our goal to con-
struct an approximate infection relation that minimizes
false positives and false negatives
4.2 System Details
This section details the speciﬁc algorithms and subsys-
tems used in the three main components of our system
(depicted in Figure 2).
4.2.1 High-Level Behavior Extraction
Intuitively, the problem of high-level behavior extraction
is to derive a concise description of the behavior seman-
tics demonstrated by a malware sample. Given a mal-
ware sample m and a set D of high-level behavior tem-
plates that describe events related to system state modiﬁ-
cation, the goal of this task is to produce a sequence of in-
stances of the members of D, along with a corresponding
low-level description of system events that match each
template instance.
The set of behavior templates used in our prototype
is given in Table 1. To infer high-level behaviors from
a stream of system calls, we use multilayer behavior
speciﬁcations, as proposed in previous work [11]. Al-
though the details of the inference algorithm are beyond
the scope of this paper, we give a brief account of the
main points here. Each high-level behavior is described
in terms of a hierarchical model. Each level of the hierar-
chy is composed of a set of behavior summaries and their
accompanying behavior graphs. The graph for a given
behavior summary encodes the behavior operationally, in
terms of events and the dependencies among them. The
events in a graph at a particular level are deﬁned in terms
of the summaries of levels lower in the hierarchy. The
top level of the hierarchy corresponds to the ﬁnal output
of the inference, and the layers beneath it provide de-
tails of incremental speciﬁcity, until the lowest level is
reached. In our prototype, the lowest level corresponds
to a system call trace collected in a virtual environment.
We use a modiﬁed version of QEMU [3] to monitor an
application for its system call trace.
The nodes in the behavior graphs at each layer cor-
respond to events that are observed by the monitor, and
the edges correspond to data dependencies between the
events. For example, in the graphs at the lowest level,
system calls that operate on the same resource handle
have edges between their representative nodes that re-
ﬂect this dependency. At the highest level, this relation-
ship is preserved by edges that denote the fact that the
corresponding set of high-level behaviors operate on the
same ﬁle. Representing high-level behavior graphs hier-
archically has one crucial advantage: the same high-level
behavior can be described in terms of multiple alterna-
tive intermediate behaviors. For example, our high-level
behavior DropAndAutostart can be represented in terms
of all possible low-level system call sequences that cre-
ate a new ﬁle, write executable content into it, and then
change the system conﬁguration to activate the dropped
ﬁle at boot time. Because there are numerous distinct
ways to accomplish this high-level task in terms of sys-
tem calls, it is important to account for all of them in a
clean and straightforward way. Our heirarchical behavior
model formalism allows this, and thus makes our system
more resilient to this type of evasion.
Figure 3 shows a sample system call trace and two
of the high-level behaviors extracted from it. The ﬁg-
ure shows both the concrete graphs and the template
instances that were matched. The ﬁrst four system
calls in the trace (members s1 through s4) are exe-
cuted by the malware sample to replicate its payload
into a new ﬁle. These calls are associated with the
layer-1 behavior FileCreation. Similarly, the system
calls s11, s13, and s14 are associated with the layer-1
behavior RegistryCreation, and the last system call
(s41) with the behavior FileDeletion. Since the be-
haviors FileCreation and RegistryCreation are re-
lated, the algorithm infers the high-level layer-2 behav-
ior DropAndAutostart, which represents the fact that
the malware replicates and conﬁgures the system to exe-
cute the malicious payload at boot. Note that this high-
level behavior was inferred hierarchically; the fact that
DropAndAutoStart is present in the trace was inferred
only from layer-1 behaviors, which were in turn inferred
from system calls originally found in the trace. By
modularizing the template deﬁnitions in this way, our
high-level behavior inference technique gains a certain
amount of resilience to obfuscations and differences in
malware implementation [11].
4.2.2 Behavior Clustering
Given a set of high-level behavior traces {B1, . . . ,Bm}
corresponding to multiple executions of the same mal-
ware sample, behavior clustering identiﬁes elements of
distinct traces that correspond to the same malicious ac-
tivity. An admissible clustering for a given set of traces is
a set of behavior sets {C1,C2, . . . ,Cn} that satisﬁes two
conditions:
1. All behaviors in a given cluster Ci have the same
type. For example, all behaviors are of type
DropAndAutostart.
2. The clustering partitions the set of all events in ev-
ery execution trace: no behavior is in more than one
cluster, and each behavior is in some cluster.
7
s1
s2
s3
s4
...
s11
s12
s13
s14
...
s21
s22
s23
...
s31
s32
s33
s34
s35
...
s41
NtCreateFile("poqwz.exe") → f
NtWriteFile(f, "...malicious code...")
NtWriteFile(f, "...other malicious code...")
NtClose(f)
NtOpenKey("Run") → r
NtQueryValueKey(r, "vq") → FAILURE
NtSetValueKey(r, "vq", "poqwz.exe")
NtClose(r)
NtOpenFile("...\system32\user32.dll") → g
NtWriteFile(g, "...malicious data...")
NtClose(g)
NtOpenFile("c:\windows\hosts") → h
NtReadFile(h, 1024) → "# Copyright (c)..."
NtWriteFile(h, "67.42.10.3 www.google.com...")
NtWriteFile(h, "67.42.10.3 www.citibank.com...")
NtClose(h)
NtDeleteFile("c:\malware.exe")
(a)
2
r
e
y
a
L
1
r
e
y
a
L
0
r
e
y
a
L
DropAndAutostart
FileDeletion
FileCreation
RegistryCreation
s1
s2
s3
s4
s11
s13
s14
s41
DropAndAutostart("poqwz.exe", data, "Run", "vq",
High-Level Behavior Summaries
"poqwz.exe")
FileCreation("poqwz.exe", data)
FileDeletion("c:\malware.exe")
RegistryCreation("Run", "vq", "poqwz.exe")
(b)
Figure 3: The system call trace for our sample malware.exe (a) and high-level behaviors generated from the trace
(b).
In later stages of the system, it generalizes behaviors
in the same cluster by overapproximating their argument
values. Thus, desirable clusterings are those that lead to
tighter overapproximations, while still grouping related
behaviors together in order to allow generalization. As
an example, Figure 4 shows two high-level traces of our
sample malicious program. We denote the jth behavior
observed in the ith execution trace as bi
j. For these traces,
1 and b2
we want to group behaviors b1
1 because they cor-
respond to the same activity, and generalizing their ar-
guments leads to a tight overapproximation: we can use
regular expressions that match a fairly small set of strings
(namely, po[[: alpha :]]{3}.exe). Similarly, we want to
group b1
3. However, had the sec-
ond trace contained another DropAndAutostart behav-
ior for an executable named avkiller.exe, then cluster-
ing b1
1 with this behavior would have resulted in a poor
generalization. An optimal clustering is one that includes
all related high-level behaviors so that generalization will
create a powerful regular expression that ﬁnds all traces
of a malicious behavior. On the other hand, an optimal
clustering must not include unrelated high-level behav-
iors, as a generalization of such a cluster is likely to
match benign system resources.
3 with b2
2 with b2
2 and b1
Cluster Formation: Exhaustively searching for the
optimal clustering of {B1, . . . ,Bm} is infeasible, as
there are an exponential number of possibilities. Thus,
we do not attempt to ﬁnd an optimal clustering and in-
stead rely on the heuristic method shown in Algorithm 1.
The algorithm begins by ﬁnding the execution trace with
the greatest number of high-level behaviors Bmax , and
creating an initial clustering by placing each bmax
in
its own cluster Ci. Then, for each remaining behavior
i
8
trace Bj, the events are enumerated in execution order
and added to the ﬁrst cluster that satisﬁes the admissibil-
ity criterion discussed above. We discuss the details of
matching event types below. If an event cannot be added
to any existing cluster, then a new cluster is initialized
with the current event. This process is repeated until no
traces remain, at which point the current set of clusters is
returned as the ﬁnal result.
Intuitively, the heuristics in this algorithm rely on two
asssumptions: (1) distinct executions of the malware ex-
hibit similar malicious behaviors, and (2) the ordering of
malicious behaviors between executions is similar. By
selecting the trace with the greatest number of events to
seed the clustering process and assuming that different
executions contain a similar set of behaviors, we seek
clusterings that group as many behaviors together as pos-
sible. By adding events to existing clusters in execution
order and assuming that the order does not vary substan-
tially between executions, we seek clusterings that match
similar argument values, thus resulting in tighter over-
approximations in the behavior generalization phase of
the system. Furthermore, these heuristics allow our al-
gorithm to operate efﬁciently: Algorithm 1 runs in time
linear in the number of execution traces and the length of
the traces.
For an example of how Algorithm 1 works, consider
the two high-level execution traces depicted in Figure 4.
As both traces are of equal length, the ﬁrst is chosen,
in this case B1. Clusters C1, C2, and C3 are initial-
ized with behaviors b1
1 and
b2
1 can then be matched, as they are both instances of
the DropAndAutostart high-level behavior. Simi-
larly, b1
3. Fi-
nally, the algorithm returns clusters {C1,C2,C3} where
2 is matched to b2
3 is matched to b2
3, respectively. b1
2, and b1
1, b1
2, and b1
B1
B2
DropAndAutostart
DropAndAutostart
FileCreation
RegistryCreation
RegistryCreation
FileCreation
b1
1
b2
1
FileInfection
FileDeletion
FileDeletion
FileInfection
b1
3
b1
2
b1
1 :
b1
2 :
b1
3 :
DropAndAutostart("c:\...\poqwz.exe", data, "...\Run",
"vq", "poqwz.exe")
FileDeletion("c:\malware.exe")
FileInfection("...\etc\hosts", "67.42...", data)
b2
2
b2
1 :
b2
2 :
b2
3 :
b2
3
DropAndAutostart("c:\...\pobxz.exe", data, "...\Run",
"vq", "pobxz.exe")
FileDeletion("c:\malware.exe")
FileInfection("...\etc\hosts", "67.42...", data)
Figure 4: High-level behavior clustering.
C1 = {b1
1} represents DropAndAutostart behav-
1, b2
2} represents FileDeletion behav-
iors, C2 = {b1
2, b2
3} represents FileInfection
iors, and C3 = {b1
3, b2
behaviors.
Behavior Comparison: Our clustering algorithm re-
quires a sub-algorithm, isomorphic, to compare two be-
haviors. Intuitively, we perform this comparison by nor-
malizing the graphs corresponding to each behavior and
then checking whether the resulting normalized graphs
are isomorphic. There is an important advantage in com-
paring the behavior graphs rather than their high-level
summaries: nondeterminism in a malicious program typ-
ically affects the summary of the behavior, but not the
low-level operations used to achieve the behavior. There-
fore, this approach is more resilient to nondeterminism
and performs a more thorough comparison, eventually
yielding more precise results.
The normalization we perform on each graph mainly
consists of abstracting away details of the behavior that
are likely affected by nondeterminism. System call ar-
guments that represent resource names are replaced by
constants that denote their type. For example, we use
a different constant for each ﬁle and registry type. Se-
quences of system calls that operate sequentially on the
same resource are replaced with a single, batch call that
is semantically identical. Finally, we ignore system calls
whose effects are later killed, i.e. overwritten or other-
wise reversed. In this way, our normalization step pro-
duces more succinct graph representations of the mal-