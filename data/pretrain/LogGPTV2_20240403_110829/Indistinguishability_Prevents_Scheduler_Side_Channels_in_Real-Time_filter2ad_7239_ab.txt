demonstrated in RTS. Chen et al. [14] have also shown how such in-
formation leakage can be used to launch more deliberating attacks,
e.g., taking control of autonomous systems by precisely injecting
commands to override the system’s periodic PWM updates.
Schedule Obfuscation. Yoon et al. [61] attempted to tackle the
scheduler side-channels by introducing a randomized scheduling
algorithm that obfuscates the task schedules in fixed-priority pre-
emptive RTS. This idea has been extended to multi-core environ-
ments [4]. Similarly, Krüger et al. [36] developed a combined on-
line/offline randomization scheme to reduce determinisms for time-
triggered systems. Nasri et al. [48] conducted a comprehensive
study on the schedule randomization approach and argued that
such techniques can actually expose the fixed-priority preemptive
RTS to more risks. Burow et al. [10] explore several moving-target
defenses (randomization-based) against different types of attacks
2A task in typical real-time systems corresponds to a process/thread in generic operat-
ing systems. In this paper, we will use “task” and “process” interchangeably.
in the context of RTS (including soft RTS). While this existing work
is centered on the problem of scheduler side-channels, they do not
provide analytical guarantees for the protection against such at-
tacks. Additionally, the work targets highly constrained real-time
systems and hence their effectiveness is often limited. In contrast,
we focus on a more realistic RTS model that has flexible and more
tolerable timing requirements. This enables us to explore a more
aggressive defense strategy to achieve higher (and analyzable) pro-
tection against the threats imposed by scheduler side-channels.
2.2 Differential Privacy and Randomized
Mechanisms
Differential Privacy. Differential privacy, along with the theo-
rems and algorithms that build the foundation for protecting data
privacy, was originally introduced [18, 19] in the context of statisti-
cal queries on databases. It can be seen that differential privacy is
used in many subjects addressing the issue of data privacy [13, 18].
There is also a growing trend to extend such concepts to the sys-
tems domain [17, 30, 59] to protect data privacy distributed among a
group of devices. While in this paper we focus on the system security
rather than data privacy, the high-level goal is somewhat similar to
differential privacy and hence relevant techniques may be adopted.
In our context, we define the notion of task/job indistinguisha-
bility that defines the probability of distinguishing the execution
states of one task/job from another in task schedules. Roughly speak-
ing, a low indistinguishability enables an adversary to identify a
task’s execution from an observed schedule with a high confidence
and hence the system is prone to compromises via scheduler side-
channels. To address such a problem, we propose an 𝜖-Scheduler
that offers “𝜖-indistinguishability” at a job level and/or a task level,
subject to system constraints as well as the system designer’s secu-
rity goal. To the best of our knowledge this paper is the first work
that adopts the foundation of differential privacy in the design of
schedulers and especially to address the security issues in RTS.
Laplace Mechanism. There exist many types of distributions that
are used for addressing information leakage issues (e.g., Uniform
distribution [51], Gaussian distribution [28, 41] and Laplace dis-
tribution [19].) The Uniform distribution has been used in the
KeyDrown [51] work to prevent information leakage via keystrokes.
Their work aims to uniformly distribute keystroke interrupts by
injecting fake keystrokes (with no RT requirements). In our con-
text, while using the Uniform distribution would spread the inter-
arrival times more evenly (i.e., better security), it would cause
more deadline misses and a serious degradation of the RT per-
formance. The Laplace distribution has been used in the classic dif-
ferential privacy problems for generating random noise to achieve
desired privacy protections [19]. Conventionally, the Laplace distri-
bution has a probability density function defined as Lap(𝑥 | 𝜇, 𝑏) =
2𝑏 exp(− |𝑥−𝜇|
). In this paper, we use the Laplace distribution to
1
generate randomized inter-arrival times for each job at run-time.
In contrast with the Uniform distribution, the Laplace distribu-
tion, while statistically vulnerable over time, can generate an av-
erage task period that’s close to the designer’s desired value thus
closely matching required RT guarantees. Furthermore, using the
Laplace distribution allows us to reuse existing mathematical and
𝑏
Session 3A: Side Channel CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea668algorithmic components with the theoretical foundations from the
differential privacy domain.
3 SYSTEM AND ADVERSARY MODELS
3.1 Preliminaries
The sets of natural numbers and real numbers are denoted by N and
R. For a given 𝑛 ∈ N, the set [𝑛] represents {1, 2, ..., 𝑛}. We denote
the Laplace distribution with location 𝜇 and scale 𝑏 by Lap(𝜇, 𝑏)
and we write Lap(𝑏) when 𝜇 = 0. For a random variable 𝑥, drawing
values from a Laplace distribution is denoted by 𝑥 ∼ Lap(·). As
conventionally used, we sometimes abuse notation and denote a
random variable 𝑥 ∼ Lap(·) simply by Lap(·).
We consider a discrete time model [32]. In our context, we mainly
focus on the issue that is concerned with the timing in a single node
real-time system. We assume that a unit of time equals a timer tick
governed by the operating system and the corresponding tick count
is an integer. That is, all system and real-time task parameters are
multiples of a time tick. We denote an interval starting from time
point 𝑎 and ending at time point 𝑏 that has a length of 𝑏 − 𝑎 by
[𝑎, 𝑏) or [𝑎, 𝑏 − 1].
3.2 Real-Time System Model
In this paper, we consider a single processor, preemptive real-time
system in which some deadline misses are tolerable [16, 43]. Such
systems are very common3, e.g., the system contains a set of 𝑁
real-time tasks Γ = {𝜏𝑖 | 𝑖 ∈ [𝑁]}, scheduled by a dynamic-priority
scheduler (e.g., Earliest Deadline First, EDF, scheduler [39]). We
assume the real-time tasks are independent (i.e., no dependencies
between tasks). A real-time task can be a periodic task (with a fixed
period) or a flexible task (that has flexible period choices within
a predefined range) [44]. We model a real-time task 𝜏𝑖 by a tuple
(T𝑖, D𝑖, 𝐶𝑖, 𝜂𝑖) where T𝑖 = {𝑇𝑖,𝑘 | 𝑘 ∈ N} is a set of admissible peri-
ods, D𝑖 = {𝐷𝑖,𝑘 | 𝑘 ∈ N} is a set of implicit, relative deadlines (i.e.,
𝐷𝑖,𝑘 = 𝑇𝑖,𝑘,∀𝑘 ∈ N), 𝐶𝑖 is the worst-case execution time (WCET)
and 𝜂𝑖 is a task inter-arrival time function as defined below (a glos-
sary table is provided in Appendix Table 4 for reference). It can
be easily seen that a periodic task is then a flexible task where the
“choice of periods” is limited to a single value. That is, T𝑖 = {𝑇𝑖,1}
when 𝜏𝑖 is a periodic task and we sometimes use 𝑇𝑖 to denote such
a fixed period for simplicity. A task’s execution instance is aborted
upon missing its current deadline and it does not impact the release
of the task’s next execution instance.
To formulate the problem better, let us assume that a task’s
execution behavior is modeled by a task inter-arrival time function
where each task has a dedicated function, as illustrated in Figure 2.
Definition 3.1. (Task Inter-Arrival Time Function.) For a task 𝜏𝑖
the inter-arrival time function is defined as
𝜂𝑖 : N → T𝑖
(1)
where 𝜂𝑖( 𝑗) is the task’s inter-arrival time at the 𝑗𝑡ℎ instance. The
resulting inter-arrival time is one of the values in the task’s inter-
arrival time set, 𝜂𝑖( 𝑗) ∈ T𝑖.
■
3The choice to focus on widely deployed soft RTS allows us to develop the underlying
mathematical models that can then be applied to a wider range of systems such as
weakly hard RTS (e.g., sampling and monitoring systems) and even many IoT systems.
Figure 2: Illustration of the task execution model used in
this paper. Arrows represent the scheduled arrival time in-
stants. The distance between two adjacent arrival times of a
task is modeled by a task-specific function 𝜂𝑖.
Note that a strict periodic task (i.e., T𝑖 = {𝑇𝑖,1}) always gets a
fixed output from its inter-arrival time function, 𝜂𝑖( 𝑗) = 𝑇𝑖,1,∀𝑗 ∈ N.
Then, based on the above function, the system’s timing behavior
(w.r.t. the task deadlines and inter-arrival times) can be modeled
by 𝜂𝑖,∀𝜏𝑖 ∈ Γ. That is, when the 𝑗𝑡ℎ instance of task 𝜏𝑖 arrives,
the scheduler computes its period from 𝜂𝑖( 𝑗) and configures its
deadline as well as the next arrival time accordingly.
The system can also contain other sporadic and aperiodic tasks.
Yet, these types of tasks do not naturally demonstrate periodicity
by design and thus are not of interest in our context. For this reason,
we intentionally exclude these types of tasks in our task model to
instead focus on the periodic components. It’s worth nothing that
our model in fact subsumes sporadic tasks (that have a fixed upper-
bound on the inter-arrival times between two instances). In practice,
to analyze sporadic tasks, one must account for their worst-case
behavior, i.e., when they behave like periodic tasks. Hence, if the
system has sporadic tasks, we can support them.
3.3 Adversary Model
We are mainly concerned about scheduler side channels that are
exposed by the deterministic nature of RTS as introduced in Sec-
tion 2. We assume that an adversary observes the system schedule
via some existing side channels [3, 5, 14, 33, 53]. We further assume
that the adversary does not have access to the scheduler. Without
this assumption, the adversary can undermine the scheduler or
directly obtain the schedule information without using the side
channels. Otherwise, we don’t place any restrictions on where the
adversary might exploit such side channels. As demonstrated by
our evaluation on real applications (Section 7), the attackers can be
resident in the system or at the network interface when carrying
out such attacks. The true reason for the information leakage is
due to the predictability in schedulers and that is the vulnerability
we focus on.
Note that some existing attacks have demonstrated that precise
timing information of target tasks (e.g., task phases, task arrival
times) can be deduced from the deterministic real-time schedules
at runtime. Such information can then be exploited to recreate
a targeted task’s execution state and then launch further, more
critical, attacks on the system with higher precision [14, 42]. For
instance, in a cache timing side-channel attack in which the attacker
attempts to gauge a task’s memory usage, knowing when the target
task may start can significantly aid in differentiating valid data from
noisy data. As demonstrated in ScheduLeak [14], an attacker can
place precise prime and probe operations before and after a target
task and successfully learn its execution behavior. These types of
attacks rely on the fact that periodicity exists in the real-time tasks
being targeted.
𝜂!𝑗𝜂!𝑗+1𝜂!𝑗+2𝜂!𝑗+3…𝜂!:ℕ→𝒯!Regular Task Inter-Arrival Time Function: Session 3A: Side Channel CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea669Figure 3: Illustration of the task execution after injecting
noise. The inter-arrival times become irregular and unpre-
dictable with using a randomized mechanism.
It’s worth pointing out that such the scheduler side-channel
attacks only acquire (arguably insensitive) system timestamp infor-
mation and can operate in the user space [14]. Therefore, traditional
anomaly detection may not work well in defending the system this
scenario. In this paper, we aim to eliminate such scheduler side
channels by obscuring the task periodicity in the schedule. To this
end, our goal in this paper is to achieve schedule indistinguishability
in the system that can be further categorized into:
(i) Job-level indistinguishability refers to the difficulty of distinguish-
ing a task’s job from another of the same task in a task schedule. As
introduced in Section 3.2, a flexible task can have multiple prede-
fined periods that are associated to different execution modes and
purposes. For instance, a feedback control task in a cyber-physical
system can adjust its period based on the severity of error the phys-
ical asset under control is experiencing [44]. Leaking the current
period of the control task reveals the system’s internal state as
well as the physical asset’s external state. Achieving a job-level
indistinguishability for such a task weakens the adversary’s ability
to reason about the task’s internal execution state.
(ii) Task-level indistinguishability, on the other hand, refers to the
difficulty of distinguishing a task from another in a schedule. In a
RTS in which all tasks are strictly periodic, it is generally not hard
to distinguish and identify individual tasks from a schedule (see
Section 8.2.1 for an example and analysis). As a result, tasks are
at risk of leaking critical information. For instance, in the Sched-
uLeak attack [14], the adversary exploits the periodicity to extract
the execution behavior of a critical real-time task. Achieving task-
level indistinguishability weakens the adversary’s ability to glean
information about a specific task from the schedule.
It’s intuitive to see that job-level indistinguishability is a nec-
essary condition for the task-level indistinguishability. That is, if
task-level indistinguishability can be achieved, then job-level in-
distinguishability is also achievable. It’s worth pointing out that
the inverse relation does not hold: achieving individual job-level
indistinguishability does not automatically grant the task-level in-
distinguishability. Yet, in practice, there exist real-time constraints
that restrict the degree of timing that we can tweak. In such cases,
the task-level indistinguishability may be infeasible to achieve. In
this paper, we propose an extended task model and a real-time
scheduler with an inter-arrival time randomized mechanism to
achieve job-level indistinguishability and, when feasible, task-level
indistinguishability.
4 SCHEDULE INDISTINGUISHABILITY
In this section we introduce the components (inter-arrival time
sensitivity and randomized mechanism) that achieve notions of
the job/task-level indistinguishability. These are fundamental to
developing the 𝜖-Scheduler that will be introduced in Section 5.
4.1 Randomizing Inter-Arrival Times
Let’s consider a task 𝜏𝑖 and its inter-arrival time function 𝜂𝑖. The
function produces consistent inter-arrival times. To break this pre-