4
-
1
4
-
1
4
-
1
4
-
1
4
-
2
4
-
2
4
-
2
4
-
2
4
-
2
4
-
2
4
-
2
4
-
2
4
-
2
4
-
2
4
-
3
8
9
0
1
2
3
4
5
6
7
8
9
0
1
2
3
4
5
6
7
8
9
0
Day
Figure 8: Incoming Attacks. We track the number of incoming
connections containing Heartbleed exploit messages seen at ICSI,
LBNL, and the EC2 honeypot per day.
Type
(1) Cleartext attacks
(2) Successful cleartext attacks
(3) Short Heartbeats
(4) Heartbeats before data
(5) Successful attacks after encryption
Total
Sources
628
4
8
61
5
692
Targets
191
10
10
132
6
217
Connections
1,691
26
187
4,070
77
5,948
Table 6: Attack Types. We list different stages of attacks observed
against LBNL, ICSI and the EC2 honeypot.
ination reveals that these hosts belong to two popular Heartbleed
scan services: filippio.io (3,964 attempts from 40 hosts) and
ssllabs.com (16 attempts from 5 hosts).
Examining connection attempts across each site, we ﬁnd only
three sources that attempted to scan all three networks. However,
LBNL aggressively blocks scan trafﬁc, so most hosts scanning it
were likely blocked before they could locate a server against which
to attempt Heartbleed exploits. Considering only the EC2 honeypot
and the ICSI network (neither of which block scanning), we ﬁnd
11 sources that scanned both.
Apart from our scans at the University of Michigan and another
research group at TU Berlin, we found four sources that targeted
more than 100 addresses at ICSI. Two of the sources were located
in CHINANET, one at Nagravision, and one at Rackspace. The re-
maining Heartbleed exploit attempts only targeted smaller numbers
of hosts without performing widespread scanning.
Hosts performing widespread scans exclusively targeted port 443
(HTTPS). We observed a small number of exploit against ports 993
(IMAPS), 995 (POP3S), 465 (SMTPS), as well as GridFTP. We also
found a small number of exploit attempts against services running
on other ports.
While we observed Heartbleed attacks originating from a large
number of sources, we ﬁnd that most hosts did not target more than
one of our sites and likely do not represent Internet-wide scanning.
Given the low volume of widespread scanning, the 201 sources
attempting to exploit the EC2 honeypot appears surprisingly high.
Our hypothesis is that attackers may preferentially scan denser
address spaces, such as those of Amazon EC2, as they will likely
yield a greater number of vulnerable targets.
483AS Name
Amazon.com
China Telecom
China169 Backbone
Chinanet
University of Michigan
SoftLayer
University of Latvia
Rackspace
GoDaddy.com
OVH
ViaWest
Guangdong Mobile
New York Internet Company
ServerStack
Comcast
Global Village Telecom
China Telecom
Turk Telekomunikasyon
DFN
Amazon.com
TekSavvy Solutions
Oversun
HKNet
CariNet
PowerTech
Nagravision
CYBERDYNE
ASN Scans Hosts
206
14618
4812
139
34
4837
23
4134
3
36375
2
36351
1
8605
19994
11
15
26496
9
16276
1
13649
1
9808
11403
1
1
46652
5
7922
4
18881
1
4816
8
9121
680
2
5
16509
2
5645
2
48172
1
4645
10439
8
1
5381
1
42570
37560
1
4,267
507
147
115
92
85
50
47
34
30
30
29
29
27
20
19
16
15
15
12
11
11
11
10
10
10
10
Table 7: ASes Responsible for Attacks. We list the ASNs/ISPs
that sent 10 or more Heartbleed exploit attempts to LBNL, ICSI,
and our EC2 honeypot.
7. NOTIFICATION
Three weeks after the initial disclosure a large number of hosts
remained vulnerable, and we began notifying the system operators
responsible for unpatched systems. This endeavor provided us with
an opportunity to study the impact of large-scale vulnerability notiﬁ-
cation. In this section we describe our notiﬁcation methodology and
analyze the reactions to our notiﬁcations and its impact on patching.
7.1 Methodology
In order to ﬁnd the appropriate operators to contact, we performed
WHOIS lookups for the IP address of each vulnerable host appearing
in our April 24, 2014 scan of the full IPv4 address space. We used
the “abuse” e-mail contact extracted from each WHOIS record as
our point of notiﬁcation. We chose to use WHOIS abuse emails
because they struck us as more reliable than emails from other
sources. There also appeared to be less risk in offending a network
operator through contacting the abuse contact. For example, many
emails extracted from certiﬁcate Subject ﬁelds were not valid emails,
and we observed several WHOIS records with comments instructing
anything related to spam or abuse be sent to the abuse contact rather
than the technical contact.
Our scan found 588,686 vulnerable hosts. However, we excluded
embedded devices—which accounted for 56% of vulnerable hosts—
because administrators likely had no avenue for patching many of
these devices at the time. These devices were detected using the
ﬁngerprints described in Section 3.6. The remaining 212,805 hosts
corresponded to 4,648 distinct abuse contacts. Approximately
30,000 hosts belonged to RIPE and Amazon each. Because nei-
ther of these organizations directly manage hosts, we omitted them
from our notiﬁcations.
To measure the impact of our notiﬁcations, we randomly split
the abuse contacts into two groups, which we notiﬁed in stages.
Figure 9: Patch Rates of Group A vs Group B. The patch rates
for our two notiﬁcation sets show that notiﬁcation had statistically
signiﬁcant impact on patch rate.
We sent notiﬁcations to the ﬁrst half (Group A) on April 28, 2014,
and the second half (Group B) on May 7, 2014. Our notiﬁcation e-
mail introduced our research and provided a list of vulnerable hosts,
information on the vulnerability, and a link to the EFF’s Heartbleed
recovery guide for systems administrators.
7.2 Patching Behavior
To track patching behavior, we conducted regular scans of the
known vulnerable hosts every eight hours. We considered a contact
as having reacted and begun patching if we found at least one host
in the list we sent to the contact as patched. Figure 9 shows a
comparison of the patch rates between the two groups. Within
24 hours of the initial notiﬁcation, 20.6% of the Group A operators
had begun to patch, whereas only 10.8% of Group B contacts (not
yet notiﬁed) had reacted. After eight days (just before the second
group of notiﬁcations), 39.5% of Group A contacts had patched
versus 26.8% in Group B. This is a 47% increase in patching for
notiﬁed operators.
Fisher’s Exact Test yields a one-sided p-value of very nearly zero
for the null hypothesis that both groups reﬂect identical population
characteristics. We thus conclude that our notiﬁcation efforts had
a statistically signiﬁcant positive effect in spurring notiﬁed sites
to patch. Our second round of notiﬁcations followed a similar
pattern as the ﬁrst. As Group A’s rate of patching had decreased
at that point, Group B caught up, resulting in both converging to
around 57% of contacts having reacted within a couple of weeks of
notiﬁcation.
We also investigated the relationship between the reactions of net-
work operators (per Section 7.3) and their patching behavior. First,
we sent our notiﬁcation message in English, possibly creating a lan-
guage barrier between us and the contact. We analyzed the Group A
responses and found that email responses entirely in English had no
statistically signiﬁcant difference in the corresponding patching rate
than for responses containing non-English text (Fisher’s Exact Test
yielded a two-sided p-value of 0.407).
We did, however, ﬁnd statistically signiﬁcant differences between
each of the categories of responses framed below in Section 7.3, as
shown in Figure 10, with human responders patching at the highest
rate. Within the ﬁrst day post-notiﬁcation, 48% of human responders
had begun patching, while none of the other categories had a patch
rate higher than 32%.
The second strongest reactions came from contacts conﬁgured to
send automated responses. 32% had reacted after one day, and 75%
had reacted after three weeks. This indicates that operators using a
(cid:1)(cid:2)(cid:1)(cid:3)(cid:2)(cid:1)(cid:4)(cid:2)(cid:1)(cid:5)(cid:2)(cid:1)(cid:6)(cid:2)(cid:1)(cid:7)(cid:2)(cid:1)(cid:8)(cid:2)(cid:2)(cid:6)(cid:9)(cid:4)(cid:10)(cid:2)(cid:7)(cid:9)(cid:2)(cid:8)(cid:2)(cid:7)(cid:9)(cid:3)(cid:5)(cid:2)(cid:7)(cid:9)(cid:4)(cid:2)(cid:11)(cid:12)(cid:13)(cid:14)(cid:12)(cid:15)(cid:16)(cid:17)(cid:18)(cid:12)(cid:19)(cid:1)(cid:20)(cid:21)(cid:1)(cid:22)(cid:20)(cid:16)(cid:23)(cid:24)(cid:12)(cid:25)(cid:1)(cid:26)(cid:23)(cid:16)(cid:27)(cid:1)(cid:28)(cid:20)(cid:29)(cid:12)(cid:1)(cid:30)(cid:11)(cid:19)(cid:1)(cid:11)(cid:17)(cid:16)(cid:14)(cid:27)(cid:12)(cid:25)(cid:31)(cid:23)(cid:29)(cid:12)(cid:1)(cid:20)(cid:21)(cid:1)(cid:28)(cid:14)(cid:17)(cid:15)(cid:19)(cid:32)(cid:13)(cid:20)(cid:33)(cid:34)(cid:1)(cid:35)(cid:22)(cid:20)(cid:16)(cid:23)(cid:24)(cid:12)(cid:25)(cid:36)(cid:34)(cid:13)(cid:23)(cid:37)(cid:1)(cid:4)(cid:38)(cid:16)(cid:27)(cid:1)(cid:22)(cid:20)(cid:16)(cid:23)(cid:24)(cid:14)(cid:17)(cid:16)(cid:23)(cid:20)(cid:15)(cid:19)(cid:1)(cid:39)(cid:32)(cid:13)(cid:20)(cid:33)(cid:34)(cid:1)(cid:36)(cid:40)(cid:41)(cid:17)(cid:42)(cid:1)(cid:43)(cid:16)(cid:27)(cid:1)(cid:22)(cid:20)(cid:16)(cid:23)(cid:24)(cid:14)(cid:17)(cid:16)(cid:23)(cid:20)(cid:15)(cid:19)(cid:1)(cid:39)(cid:32)(cid:13)(cid:20)(cid:33)(cid:34)(cid:1)(cid:35)(cid:40)4847.4 Network Operator Survey
We sent a brief survey to positive human responders, where all
questions were optional, and received anonymous submissions from
17 contacts. Surprisingly, all 17 expressed awareness of the vulnera-
bility and stated their organizations had performed some remedia-
tion effort prior to our notiﬁcation, typically through informing their
clients/customers and patching machines if accessible. When we
asked why might the hosts we detected still be vulnerable, the most
common responses were that they did not have direct control over
those servers, or their own scans must have missed those hosts. It
appears ignorance of the vulnerability and its threat did not play a
factor in slow patching, although our sample size is small. When
asked if they replaced or revoked vulnerable certiﬁcates, nine said
yes, two said no, and one was unaware of the recommendation. Fi-
nally, we asked if these contacts would like to receive notiﬁcations
of similar vulnerabilities in the future. Twelve said yes, two said
no, and the others did not respond. This again demonstrates that our
notiﬁcations were in general well-received.
8. DISCUSSION
Heartbleed’s severe risks, widespread impact, and costly global
cleanup qualify it as a security disaster. However, by analyzing
such events and learning from them, the community can be better
prepared to address major security failures in the future. In this
section, we use our results to highlight weaknesses in the security
ecosystem, suggest improved techniques for recovery, and identify
important areas for future research.
HTTPS Administration. Heartbleed revealed important short-
comings in the public key infrastructure that underlies HTTPS. One
set of problems concerns certiﬁcate replacement and revocation.
As discussed in Section 5, only 10% of known vulnerable sites
replaced their certiﬁcates, and an astounding 14% of those reused
the existing, potentially leaked, private key. This data suggests that
many server administrators have only a superﬁcial understanding
of how the HTTPS PKI operates or failed to understand the conse-
quences of the Heartbleed information leak. This underscores the
importance for the security community of providing speciﬁc, clear,
and actionable advice for network operators if similar vulnerabili-
ties occur in the future. Certiﬁcate management remains difﬁcult
for operators, highlighting the pressing need for solutions that en-
able server operators to correctly deploy HTTPS and its associated
infrastructure.
One of the ironies of Heartbleed was that using HTTPS, a protocol
intended to provide security and privacy, introduced vulnerabilities
that were in some cases more dangerous than those of unencrypted
HTTP. However, we emphasize that HTTPS is ultimately the more
secure protocol for a wide variety of threat models. Unfortunately,
only 45% of the Top 1 Million websites support HTTPS, despite
efforts by organizations such as the EFF and Google to push for
global HTTPS deployment.
Revocation and Scalability.
Even though only a small fraction