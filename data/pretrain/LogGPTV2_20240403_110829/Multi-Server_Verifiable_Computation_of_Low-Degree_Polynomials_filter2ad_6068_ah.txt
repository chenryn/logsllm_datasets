Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:14:01 UTC from IEEE Xplore.  Restrictions apply. 
14609
[66] Y. Huang and I. Goldberg, “Outsourced private information retrieval,”
in WPES, 2013.
[67] Y. Ishai, E. Kushilevitz, and R. Ostrovsky, “Efficient arguments without
short PCPs,” in IEEE Conference on Computational Complexity, 2007.
[68] G. Karame, M. Strasser, and S. Capkun, “Secure remote execution of
sequential computations,” in ICICS, 2009.
[69] J. Kilian, “A note on efficient zero-knowledge proofs and arguments,”
in STOC, 1992.
[70] J. Kilian, “Improved efficient arguments,” in CRYPTO, 1995.
[71] G. Kol and R. Raz, “Competing-provers protocols for circuit evalua-
tion,” Theory Comput., vol. 10, no. 5, 2014.
[72] B. Kreuter, A. Shelat, and C.H. Shen, “Billion-gate secure computation
with malicious adversaries,” in USENIX Security Symposium, 2012.
[73] K. Kurosawa, “How to correct errors in multi-server PIR,” in ASI-
ACRYPT, 2019.
[74] R.W.F. Lai, G. Malavolta, and D. Schr¨oder, “Homomorphic secret
sharing for low degree polynomials,” in ASIACRYPT, 2018.
[75] C. Lund, L. Fortnow, H.J. Karloff, and N. Nisan, “Algebraic methods
for interactive proof systems,” in FOCS, 1990.
[76] S. Micali, “CS proofs,” in FOCS, 1994.
[77] S. Michielse, N. Coupland, R. Camicioli, R. Carter, P. Seres, J.
Sabino, and N. Malykhin, “Selective effects of aging on brain white
matter microstructure: A diffusion tensor imaging tractography study,”
NeuroImage, vol. 52, no. 4, 2010.
[78] F. Monrose, P. Wyckoff, and A. D. Rubin, “Distributed execution with
remote audit,” in NDSS, 1999.
[79] B. Parno, J. Howell, C. Gentry, and M. Raykova, “Pinocchio: nearly
practical verifiable computation,” in IEEE Symposium on Security and
Privacy, 2013.
[80] B. Parno, M. Raykova, and V. Vaikuntanathan, “How to delegate and
verify in public: verifiable computation from attribute-based encryp-
tion,” in TCC, 2012.
[81] B. Schoenmakers, M. Veeningen, and N. de Vreede, “Trinocchio:
privacy-preserving outsourcing by distributed verifiable computation,”
in ACNS, 2016.
[82] A. Seshadri, M. Luk, E. Shi, A. Perrig, L. van Doorn, and P.K.
Khosla, “Pioneer: verifying code integrity and enforcing untampered
code execution on legacy systems,” in SOSP, 2005.
[83] S. Setty, “Spartan: efficient and general-purpose zkSNARKs without
trusted setup,” in CRYPTO, 2020.
[84] S. Setty, B. Braun, V. Vu, A. J. Blumberg, B. Parno, and M. Walfish,
“Resolving the conflict between generality and plausibility in verified
computation, in EuroSys, 2013.
[85] S. Setty, R. McPherson, A. J. Blumberg, and M. Walfish, “Making
argument systems for outsourced computation practical (sometimes),”
in NDSS, 2012.
[86] S. Setty, V. Vu, N. Panpalia, B. Braun, A. J. Blumberg, and M.
Walfish, “Taking proof-based verified computation a few steps closer
to practicality,” in USENIX Security Symposium, 2012.
[87] A. Shamir, “How to share a secret,” Commun. ACM, vol. 22, no. 11,
1979.
[88] A. Shamir, “IP=PSPACE,” in FOCS, 1990.
[89] Z. Shan, K. Ren, M. Blanton, and C. Wang, “Practical secure com-
putation outsourcing: a survey,” ACM Comput. Surv. vol. 51, no. 2,
2018.
[90] S. W. Smith and S. H. Weingart, “Building a high-performance,
programmable secure coprocessor,” Comput. Networks, vol. 31, no. 8,
1999.
[91] J. Thaler, “Time-optimal interactive proofs for circuit evaluation,” in
CRYPTO, 2013.
[92] J. Thaler: Proofs, arguments, and zero-knowledge. https://people.cs.
georgetown.edu/jthaler/ProofsArgsAndZK.html
[93] J. Thaler, M. Roberts, M. Mitzenmacher, and H. Pfister, “Verifiable
computation with massively parallel interactive proofs,” in HotCloud,
2012.
[94] D.P. Woodruff and S. Yekhanin, “A geometric approach to information-
theoretic private information retrieval,” in IEEE Conference on Com-
putational Complexity, 2005.
[95] B. S. Yee, Using secure coprocessors. PhD thesis, Carnegie Mellon
University, 1994.
[96] M. Yoshida and S. Obana, “Verifiably multiplicative secret sharing,”
IEEE Trans. Inf. Theory, vol. 65, no. 5, 2019.
[97] L.F. Zhang and R. Safavi-Naini, “Verifiable multi-server private infor-
mation retrieval,” in ACNS, 2014.
[98] L. Zhao, X. Wang, and X. Huang, “Verifiable single-server private
information retrieval from LWE with binary errors,” Inf. Sci., vol. 546,
2021.
APPENDIX A
PROOF FOR THEOREM 1
Proof for input privacy. According to Definition 4, we need
to show that for any set T ⊆ [k] of cardinality ≤ t, any
F ∈ P(q, m, d), and any x0, x1 ∈ Fm
q , σΠ1 (T, F, x0) and
σΠ1(T, F, x1) are identically distributed. It suffices to take
T = [t] and show that for any x ∈ Fm
q , σΠ1(T, F, x) is
uniformly distributed over Fmt
q . The specifications of Π1 show
that ProbGen(pkF , x) will output σi = c(i) for every i ∈ [k].
In particular, σT = (σi)i∈T will satisfy the equation system
(cid:124)
···
···
···
···
1 − 1
2 − 2t+1
αt
αt
...
1 − 1
αt−1
22 − 2t+1
αt−1
...
G
αt
t − tt+1
(cid:123)(cid:122)
t2 − tt+1
αt−1
αt+1 (a − x)
αt+1 (a − x)
...
αt+1 (a − x)
σt − x − tt+1
σ1 − x − 1
σ2 − x − 2t+1
 .
1 − 1
2t − 2t+1
α
α
tt − tt+1
α
...
 =
r1
r2
...
rt
(cid:125)
(20)
Note that G is non-singular as α /∈ [t]. For any choice of σT ,
there is a unique set of random vectors r1, r2, . . . , rt such that
(20) is satisfied. Hence, σT is uniformly distributed over Fmt
q .
Proof for security. By Definition 2, it suffices to show that
for any set T ⊆ [k] of cardinality t, any F ∈ P(q, m, d), any
(T, F, λ) = 1] ≤ ϵ. W.l.o.g., we
adversary A, Pr[ExpPriVA,Π1
take T = [t] and consider the Experiment 1:
q
• The challenger mimics KeyGen(λ, F ) as follows: choose
ℓ0, ℓ1 ← Fm
q , let ℓ(u) = ℓ0 + ℓ1u and ρi = F for every
i ∈ [k], compute f (u) = F (ℓ(u)), set pkF = ℓ(u) and
vkF = (ℓ(u), f (u)). It then invokes the adversary A with
(F, pkF , vkF , ρT ).
• Given (F, pkF , vkF , ρT ), A chooses an input x ∈ Fm
• The challenger mimics ProbGen(pkF , x) as follows:
q , compute
s=1 rsαs)), define
s=1 rsus, set vkx = (a, α) and σi = c(i)
a = ℓ(a), rt+1 = α−t−1(a − (x +(cid:80)t
c(u) = x +(cid:80)t+1
and gives it to the challenger.
choose a ← F∗
q \ [k], r1, . . . , rt ← Fm
q, α ← F∗
for all i ∈ [k]. It then gives σT to A.
Compute(i, ρi, σi).
gives them to the challenger.
• A chooses t partial results ˆπT = (ˆπ1, . . . , ˆπt) ∈ Ft
q and
• For every i ∈ [k] \ T , the challenger computes ˆπi ←
• The challenger mimics Verify(vkF , vkx,{ˆπi}k
i=1) as fol-
lows: interpolate a polynomial ˆϕ(u) of degree < k such
that ˆϕ(i) = ˆπi for all i ∈ [k]. If ˆϕ(α) = f (a), set
ˆy = ˆϕ(0); otherwise, set ˆy =⊥.
• If ˆy /∈ {⊥, F (x)}, then outputs 1; otherwise, outputs 0.
For every i ∈ [k], let πi be the output of correctly executing
Compute(i, ρi, σi). Then πi = ˆπi for every i ∈ [k] \ T ; and
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:14:01 UTC from IEEE Xplore.  Restrictions apply. 
15610
ϕ(u) = F (c(u)) is the polynomial of degree < k such that
ϕ(i) = πi for all i ∈ [k]. Note that ˆy ̸=⊥ if and only if
ˆϕ(α) = f (a). As f (a) = ϕ(α), ˆy ̸=⊥ if and only if
ˆϕ(α) = ϕ(α).
(21)
On the other hand, ϕ(0) = F (x). When (21) is true, we have
that ˆy = ˆϕ(0) and thus ˆy ̸= F (x) if and only if
ˆϕ(0) ̸= ϕ(0).
(22)
Equation (22) requires that ∆(u) = ˆϕ(u) − ϕ(u) is a nonzero
polynomial and (21) requires that the random field element α
is a root of the degree < k polynomial ∆(u). As ∆(u) has
at most k − 1 roots in F∗
q \ [k] is randomly
chosen and completely hidden from A (which can be seen
from (20)), we have that
q \ [k] and α ∈ F∗
Pr[ExpPriVA,Π1
(T, F, λ) = 1]
= Pr[(ˆy ̸=⊥) ∧ (ˆy ̸= F (x))]
= Pr[( ˆϕ(α) = ϕ(α)) ∧ ( ˆϕ(0) ̸= ϕ(0))]
≤ Pr[( ˆϕ(α) = ϕ(α)) | ( ˆϕ(0) ̸= ϕ(0))]
≤ (k − 1)/(q − 1 − k).
Hence, Π1 is (t, ϵ)-secure with ϵ = d(t+1)
q−2−d(t+1).
APPENDIX B
PROOF FOR THEOREM 2
Proof for input privacy. By Definition 4, we need to show
that for any set T ⊆ [k] of cardinality t, any F ∈ P(q, m, d),
and any x0, x1 ∈ Fm
q , σΠ2(T, F, x0) and σΠ2(T, F, x1) are
identically distributed. It suffices to set T = [t] and show for
any x ∈ Fm
q , σΠ2(T, F, x) is uniformly distributed over the
set F(m+1)t
. However, this is obvious because the input shares
are all computed with Shamir’s threshold scheme [87].
Proof for security. By Definition 2, it suffices to show that
for any T ⊆ [k] of cardinality t, any F ∈ P(q, m, d), any
(T, F, λ) = 1] ≤ ϵ. W.l.o.g., we
adversary A, Pr[ExpPriVA,Π2
take T = [t] and consider Experiment 1:
q
q
c(u) = x +(cid:80)t
• The challenger mimics KeyGen(λ, F ) as follows: let ρi =
F for all i ∈ [k], and set pkF =⊥ and vkF =⊥. It then
invokes A with (F, pkF , vkF , ρT ).
• Given (F, pkF , vkF , ρT ), A chooses an input x ∈ Fm
and gives it to the challenger.
• The challenger mimics ProbGen(pkF , x) as follows:
choose α ← F∗
q , γ1, . . . , γt ← Fq, let
s=1 γsus,
compute σi = (c(i), b(i)) for all i ∈ [k], and set vkx = α.
It then gives σT to A.
• A chooses t partial results {(ˆvi, ˆwi)}i∈T and gives them
• For every i ∈ [k]\T , the challenger computes (ˆvi, ˆwi) ←
s=1 rsus and b(u) = α +(cid:80)t
q, r1, . . . , rt ← Fm
to the challenger.
Compute(i, ρi, σi).
• The challenger interpolates a polynomial ˆϕ(u) of degree
≤ dt such that ˆϕ(i) = ˆvi for all i ∈ [k]; and a degree
≤ (d + 1)t polynomial ˆψ(u) such that ˆψ(i) = ˆwi for
all i ∈ [k]. If ˆψ(0) = α ˆϕ(0), then it sets ˆy = ˆϕ(0);
otherwise, it sets ˆy =⊥.
• If ˆy /∈ {⊥, F (x)}, then outputs 1; otherwise, outputs 0.
It’s easy to see that ˆy ̸=⊥ if and only if ˆψ(0) = α ˆϕ(0). For
ϕ(u) = F (c(u)) and ψ(u) = ϕ(u)b(u), we always have that
ψ(0) = αϕ(0). Thus, the event ˆy ̸=⊥ occurs if and only if
ˆψ(0) − ψ(0) = α( ˆϕ(0) − ϕ(0)).
(23)
On the other hand, ϕ(0) = F (x). When (23) is true, we
will have that ˆy = ˆϕ(0) and thus ˆy ̸= F (x) if and only
if ˆϕ(0) ̸= ϕ(0). Note that α ∈ F∗
q is randomly chosen and
completely hidden from A (i.e., ST ) due to the security of
Shamir’s threshold scheme. Thus, we have that
(cid:34)
(cid:34)
Pr[ExpPriVA,Π2
(T, F, λ) = 1]
= Pr [(ˆy ̸=⊥) ∧ (ˆy ̸= F (x))]
ˆψ(0) − ψ(0)