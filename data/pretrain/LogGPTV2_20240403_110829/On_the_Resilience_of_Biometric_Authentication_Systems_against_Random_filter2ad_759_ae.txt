2.609× 10−6. This is signiﬁcantly smaller than the AR for all
four classiﬁers. We will return to this observation shortly.
2) Raw Face Inputs: We generated 100,000 images of
size 160x160 pixels, with uniformly sampled RGB values.
Feature embeddings were then extracted from the generated
images with the pre-trained Facenet model (cf. Section IV-A3).
This set of 100,000 raw input vectors, was parsed by a min-
max scaler ﬁtted to real user data. We did not align the
noisy images, as there is no facial information within the
image to align. Note that alignment is normally used in face
authentication to detect facial boundaries within an image.
Again, we aggregate results over 50 repetitions to remove any
potential biases.
The results from these raw inputs are shown in Figure 6c.
We note that the RAR curve behaves much more similarly to
the FPR curve, than what was previously observed for raw
touch inputs. Also, in the particular example of RBFSVM,
we obtain an RAR of 0.09 which is signiﬁcantly higher than
the AR (0.01) at the equal error rate. We again computed the
true positive region and found that the average is 6.562 ×
10−94 ± 6.521 × 10−93. However, the volume covered by the
raw inputs (after feature extraction) is only 4.670 × 10−390,
which is negligible compared to the ARs (0.15, 0.01, 0.78 and
0.10 for all four classiﬁers). Additional analysis shows that
only one other user’s feature space overlapped with the space
of raw inputs, with an overlapped area of 8.317×10−407, many
orders of magnitude smaller than both the positive users and
the raw feature space itself.
Observations
The threat of a random input attack via raw random inputs
is also high, and in some cases greater than the FPR. However,
the region spanned by the feature vectors from these raw inputs
is exponentially small and hence does not span the acceptance
region. Furthermore, the region also does not coincide with any
true positive region. This implies that raw inputs may result in
high raw acceptance rate due to the fact that the training data
does not have representative vectors in the region spanned by
raw inputs. We shall return to this observation when we discuss
mitigation strategies in Section VI.
V. SYNTHETIC DATASET
The analysis in the previous section was limited in the
sense that we could not isolate the reasons behind the dis-
crepancy between AR and FPR. Indeed, we saw that for
some conﬁgurations (dataset-classiﬁer pairs), the AR curve
nicely followed the FPR curve, e.g., the face dataset and DNN
(Figure 5c), where as for others this was not the case. In order
to better understand the factors effecting AR, in this section we
attempt to empirically verify the hypothesized factors effecting
the acceptance region outlined in Section III. Namely, high
10
Fig. 7. A comparison between FPR, AR, four different ML architectures. Trained on synthetic data of 50 features of 50 user, of increasing variance within
features for a singular user, repeated 50 times. Note how the system level AR and FPR remains unchanging, despite the isolated user’s AR increasing substantially.
Fig. 8. A comparison between FPR, AR, four different ML architectures. Trained on synthetic data of 50 features of 50 user, of increasing variance within
features of all other users except a singular user, repeated 50 times. The x-axis denotes the relative SD of the population compared with the isolated user.
feature variance in a target user’s samples is likely to increase
AR, and low feature variance in the user samples in the
negative class is expected to result in high AR. In both these
cases, we expect to achieve a reasonably low EER, but AR
may still be signiﬁcantly greater than FPR. Moreover, if these
factors are indeed true, we expect to see similar behavior across
all classiﬁers. To test this we create a synthetic model of a
biometric dataset.
A. Simulating a Biometric Dataset
Let N (µ, σ2), denote the normal distribution with mean
µ and standard deviation σ. We assume each feature to be
normally distributed across all users with slight variations in
mean and standard deviation across all features and users.
More speciﬁcally, our methodology for generating the syn-
thetic dataset is as follows.
mn) = N (0.5, 0.12). Similarly we model
1) We model the mean of all n features taking values in the
unit interval I as a normally distributed random variable
N (µmn, σ2
the
standard deviation of all n features as another normally
distributed random variable N (µvar, σ2
var) = N (0.1, 0.072).
2) For each feature i ∈ [n], we ﬁrst sample µi ← N (µmn, σ2
mn)
and σi ← N (µvar, σ2
var). The resulting normal distribution
N (µi, σ2
i ) serves as the population distribution of the mean
of the feature i.
3) For each user u, we sample the mean µu,i ← N (µi, σ2
i ).
The variance σ2
u,i is chosen as the control variable. User
u’s samples for the ith feature are generated as i.i.d.
random variables N (µu,i, σ2
u,i), which serves as user u’s
distribution for the ith feature.
We evaluate the same four types of ML architectures,
LinSVM, RBFSVM, RNDF and DNN. Due to the large
number of potential conﬁgurations we evaluate the model
performance at a ﬁxed threshold of 0.5. For the experiments
we choose 50 (synthetic) users, with 50 features in the feature
space. Each experimental run is repeated 50 times to reduce
any potential biases arising from the random process.
B. Effects of Feature Variance on Acceptance Region
1) Variable Isolated User Variance and Fixed Population
Variance: We ﬁrst treat one out of the 50 users as an outlier,
whcih we call the isolated user. The variance σ2
u,i is ﬁxed at
(0.2)2 for all other users u and for all features i ∈ [n]. We
vary the variance σutgt,i of the isolated user utgt from 0.05 to
0.35 in increments of 0.05. Figure 7 plots the user’s standard
deviation (σutgt,i) relative to the ﬁxed population standard
deviation (σu,i) of 0.2. It is clear the overall AR, FRR and
FPR of the users is not affected by changing feature variance
of a single user, despite the isolated user’s samples included
as part of training and testing data of other users. Conversely,
when viewing the AR, FRR and FPR of the isolated user,
we observe a slight increase in FRR and FPR as the relative
variance increases. This is due to the positive samples being
spread out due to increased variance in the isolated user’s
samples. However, this is accompanied by a substantially large
increase in the acceptance region of this user, approaching 1,
i.e., the entire feature space. Furthermore, this trend is visible
for all four classiﬁers.
2) Fixed Isolated User Variance and Variable Population
In this experiment, we ﬁx the variance σ2
Variance:
utgt,i
of the isolated user (utgt) at (0.2)2. The σ2
u,i of the re-
maining population is sampled from a normal distribution
σu,i ← N (µi, σ2
i ). Where µi and σi is sampled from the
following distributions N (µmn, σ2
mn) = N (µmn, 0.052) and
N (µvar, σ2
var) = N (0.03, 0.022), respectively. µmn is varied
between 0.05 and 0.35 in increments on 0.05 This sampling
permits a small amount of variation between features.
The results are shown in Figure 8. Inspecting the average
AR, FRR and FPR of the system, it is evident there is a contin-
ual increase of all 3 metrics as the relative variance increases.
This increase is expected as the majority of users’ feature
values have high variance, presenting an increasingly difﬁcult
problem for the machine learner to reduce misclassiﬁcation
errors. However, in all four classiﬁers the average AR curve is
either comparable or lower than the FPR curve as the relative
11
-0.15-0.1-0.050.00.050.10.15LINSVM Relative Feature Variance0.00.20.40.60.81.0Error-0.15-0.1-0.050.00.050.10.15RBFSVM Relative Feature Variance0.00.20.40.60.81.0Overall FPROverall AROverall FRRIsolated FPRIsolated ARIsolated FRR-0.15-0.1-0.050.00.050.10.15RNDF Relative Feature Variance0.00.20.40.60.81.0-0.15-0.1-0.050.00.050.10.15TFDNN Relative Feature Variance0.00.20.40.60.81.0-0.15-0.1-0.050.00.050.10.15LINSVM Relative Feature Variance0.00.20.40.60.81.0Error-0.15-0.1-0.050.00.050.10.15RBFSVM Relative Feature Variance0.00.20.40.60.81.0Overall FPROverall AROverall FRRIsolated FPRIsolated ARIsolated FRR-0.15-0.1-0.050.00.050.10.15RNDF Relative Feature Variance0.00.20.40.60.81.0-0.15-0.1-0.050.00.050.10.15TFDNN Relative Feature Variance0.00.20.40.60.81.0Fig. 9. ROC Curves versus the AR curve for different ML architectures, including a cosine similarity distance-based classiﬁer. Trained on synthetic data of 50
features of 50 user, with ﬁxed mean and variance for features of all users, repeated 50 times.
Fig. 10. A comparison between FPR and AR of four different ML architectures. Trained on synthetic data of 50 features per user, with a variable number of
users, repeated 50 times.
variance increases. For the isolated user, we see that when the
relative variance of all other users is lower than this user (to the
left), the AR is signiﬁcantly higher even though the FPR and
FRR are minimal in all four classiﬁers. This shows that less
variance in the population samples will result in a high AR,
as the classiﬁer need not tighten AR around the true positive
region, due to lack of high variance negative samples. On the
other hand, AR of the isolated user decreases as the relative
variance of the population increases.
C. On Distance Based Classiﬁers
As noted earlier,
it has been stated that random in-
puts are ineffective against distance-based classiﬁcation al-
gorithms [17]. This is in contrast to the machine learning
based algorithms evaluated in this paper. We take a brief
interlude to experimentally evaluate this claim on the cosine
similarity distance-based classiﬁer. We sample 50 features
mn) = N (0.2, 0.052) and
with means distributed as N (µmn, σ2
var) = N (0.03, 0.022). Cosine
variance distributed as N (µvar, σ2
similarity is computed between two vectors of the same
length. As our positive training data contains more than one
training sample, we use the average of these samples as the
representative template of the user [29]. We use a ﬁxed number
of 50 users, with the experiment repeated 50 times. Recall
that our evaluation at each threshold is best-effort; we use
1,000 threshold bins for the evaluation of the cosine similarity
classiﬁer, since the FRR and FPR rapidly change over a small
range of thresholds.
Figure 9 displays three classical machine learning al-
gorithms of linear SVM, radial SVM, and random forests,
alongside a distance-based cosine similarity classiﬁer. It is
clear from the ﬁgure, that the AR is near zero for cosine
similarity, unlike the other classiﬁers using the same synthetic
dataset. This, however, comes at
the cost of higher EER.
This suggests that distance-based classiﬁers are effective in
minimizing the AR of model, but at the expense of accuracy
of the system. We leave further investigation of distance-based
classiﬁers as future work.
D. Effects of Increasing Synthetic Users
The real-world datasets used in Section IV have a variable
number of users. Our binary classiﬁcation task aggregates
negative user samples into a negative class, resulting in dis-
tributions and variances of the negative class which depend
on the number of users in the datasets. Thus, in this test we
investigate the impact on TPR, FPR and AR by varying the
number of users in the dataset. We use the synthetic dataset
conﬁgured in the same manner as in Section V-C. We increase
the number of users within the synthetic dataset, from 25 to
150, in increments of 25. Note that the split between positive
and negative samples is still balanced (see Remark 4.3).
In Figure 10, we observe that with the addition of more
users, there is a slight increase in the FPR. This is expected as
the likelihood of user features being similar between any two
users will increase with more users in the population. As the
training of the classiﬁer uses samples from other users as a
negative class, the increased number of negative users slightly
lowers the AR of the classiﬁer, with an increased variation of
the negative training set (from additional users) covering more
of the feature space. However, both these changes are relatively
minor despite the multi-fold increase in the number of users.
Thus, the AR of the classiﬁers remains relatively stable with
an increasing number of users.
VI. MITIGATION
In the previous section, we validated that higher variance in
the samples in the negative class as compared to the variance
of samples from the target user class reduces AR. The data
from the negative class is obtained from real user samples,
and therefore scheme designers cannot control the variance.
12
0.00.20.40.60.81.0Linear SVM threshold0.00.20.40.60.81.0Error0.000.08FRR - 0.00FPR - 0.00  AR - 0.080.00.20.40.60.81.0Radial SVM threshold0.000.05FRR - 0.00FPR - 0.00  AR - 0.050.00.20.40.60.81.0Random Forests threshold0.000.01FRR - 0.00FPR - 0.00  AR - 0.010.00.20.40.60.81.0Cosine Similarity threshold0.110.00FRR - 0.11FPR - 0.11  AR - 0.00255075100125150LINSVM Number of Users0.0000.0250.0500.0750.1000.125Error255075100125150RBFSVM Number of Users0.0000.0250.0500.0750.1000.125255075100125150RNDF Number of Users0.0000.0250.0500.0750.1000.125MetricFPRARFRR255075100125150TFDNN Number of Users0.0000.0250.0500.0750.1000.125TABLE I.
EQUAL ERROR RATE AND AR WITH AND WITHOUT THE MITIGATION STRATEGY. GREEN (RESP., RED) SHADES HIGHLIGHT IMPROVEMENT
(RESP., DETERIORATION) IN FPR AND AR. COLOR INTENSITY IS PROPORTIONAL TO DEGREE OF PERFORMANCE CHANGE.
Biometric
Modality
Gait
Touch
Face
Voice
Linear SVM
Normal
FPR
0.160
0.325
0.050
0.030
AR
0.24
0.49
0.15
0.08
Mitigation
AR
0.04
0.01
0.11
0.06
FPR
0.160
0.340