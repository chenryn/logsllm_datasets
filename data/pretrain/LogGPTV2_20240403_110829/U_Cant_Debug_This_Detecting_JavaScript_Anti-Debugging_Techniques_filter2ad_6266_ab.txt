malicious code, a tactic popular in JavaScript rewriting and
sandboxing literature [e.g., 39, 42].
let original = console.log;
console.log = function(arg) {
if (arg == "shellcode") { arg = "benign code"; }
original(arg); }
Figure 3: Redeﬁning the log function to hide malicious code
3.3 Detecting the analysis
Finally, the most subtle of all techniques only try to detect the
presence of the analysis. In contrast to the previous technique
which directly altered the behavior of built-in functions an
analyst would use, these techniques instead aim to alter the
control ﬂow of their own code. This way, attackers could
suppress executing malicious code for any user that opens the
DevTools or had them previously open on the same domain.
Inner vs. OuterWidth (WIDTHDIFF) By default, opening
the DevTools either splits the browser window horizontally or
vertically. In JavaScript, it is possible to obtain both the size
of the whole browser window including all toolbars (outer
size) and the size of the content area without any toolbars (in-
ner size). Thus by constantly monitoring the outerWidth and
innerWidth properties of the window object, we can check if
the DevTools are currently open on the right-hand side. The
same works if the DevTools are attached to the bottom, by
comparing the height instead, as shown in Figure 4. This is
the method used by the popular devtools-detect package [47]
that, at the time of writing, already had over 1000 stars on
Github and is thus probably often used in the wild. This is
also the technique used by the credit card skimming case [44]
from the introduction.
setInterval(() => {
if (outerWidth - innerWidth > threshold ||
outerHeight - innerHeight > threshold) {
//DevTools are open!
}
}, 500);
Figure 4: Monitoring the window size to detect the DevTools
However, this technique does not work if the DevTools are
undocked, i.e., open in a separate, detached window. Addi-
tionally, this technique will report a false positive if any other
kind of sidebar is opened in the browser.
Log Custom Getter (LOGGET) Exactly because of the
just described drawbacks of the WIDTHDIFF technique, some
developers are interested in more reliable alternatives. A
StackOverﬂow question titled "Find out whether Chrome con-
sole is open" [50] back from 2011 so far received 130 upvotes
2938    30th USENIX Security Symposium
USENIX Association
and 14 answers. While many of the suggested approaches
have stopped working over the years, some answers are still
regularly updated and present working alternatives.
In particular, for at least the last three years, some working
variations of what we call the LOGGET technique existed. The
technique works by creating an object with a special getter
that monitors its id property and then calling console.log on
it. If the DevTools are open, its internals cause it to access the
id property of every logged object, but if they are closed, the
property is not accessed. Therefore, this getter was a reliable
way to determine if the DevTools are open. While the origi-
nal approach stopped working sometime in 2019, someone
created a variation of it that uses requestAnimationFrame to
log the element with the custom getter which still works as of
time of writing. As an alternative, it is also possible to over-
write the toString function of an arbitrary function and then
log that function, as shown in Figure 5. Since the DevTools
internally also use toString to create the printed output, we
know that the DevTools are opened whenever this toString
function is called.
var logme = function(){};
logme.toString = function() {
//DevTools are open!
}
console.log('\%c', logme);
Figure 5: Approach from 2018 to detect the DevTools
As long as one of these variations continues to work, this
method is a very reliable way to detect if the DevTools are
open, as it also works if they are detached or already open
when the website is loaded. There is no real countermeasure
except to remove all logging functions of the console object,
an invasive step which by itself also might get detected.
3.4 Systematization I
To put the BADTs seen so far into context, we examine them
based on four properties: Effectiveness, stealth, versatility,
and resilience. An effective technique has a high likelihood
of activation and thus causing an impact on the analyst. As
such, LOGGET is an effective technique while SHORTCUT
might never really affect anyone. A stealthy technique wants
to remain unnoticed, i.e.,WIDTHDIFF is a stealthy technique
(although the measures it takes upon detection of the Dev-
Tools might be not so stealthy) while TRIGBREAK is the very
opposite of stealthy. A versatile technique can be used to
achieve many different outcomes, as opposed to something
very speciﬁc. Therefore, MODBUILT is a versatile technique
as it can redeﬁne a built-in function to anything else and
LOGGET can react in many different ways if it detects the De-
vTools. A resilient technique is not easily circumvented, even
if the user is aware of its existence. For example, LOGGET is
a resilient technique because there is no good countermeasure,
while DEVCUT was easily bypassed by using the menu bar.
Table 1 shows the full results of our systematization for each
technique. As all four properties are desirable from the per-
spective of an attacker, the techniques WIDTHDIFF, LOGGET,
and MODBUILT offer the most potential.
Goal
Effective
Stealthy
Table 1: Systematization of BADTs. The goals are Impede,
Alter, and Detect. A ﬁlled circle means the property fully
applies, a half-ﬁlled circle means it applies with limitations.
Resilient
Technique
SHORTCUT
TRIGBREAK
CONCLEAR
MODBUILT
WIDTHDIFF
LOGGET
I
I
I
A/I
D
D
Versatile
(cid:35)
(cid:71)(cid:35)
(cid:35)
(cid:71)(cid:35)
(cid:35)
(cid:32)
(cid:35)
(cid:32)
(cid:71)(cid:35)
(cid:71)(cid:35)
(cid:71)(cid:35)
(cid:32)
(cid:35)
(cid:35)
(cid:35)
(cid:71)(cid:35)
(cid:32)
(cid:71)(cid:35)
(cid:35)
(cid:35)
(cid:35)
(cid:32)
(cid:32)
(cid:32)
4 Large-Scale Study of BADTs
The previously mentioned devtools-detect package and also
the question on StackOverﬂow already indicated a certain
interest in anti-debugging techniques, in particular in detect-
ing whether the DevTools are opened. However, so far, there
has not been a comprehensive study on the prevalence of
these techniques in the wild. In this section, we will therefore
present a fully automatic methodology to detect each of the
BADTs from the previous section and report on the results of
our measurement on 1 million web sites.
4.1 Study I – Methodology
In the following, we will brieﬂy outline how we can detect
the presence of each technique during a single, short visit to
the website. For this, we use the fact that all basic techniques
have an obvious "signature" that is easy to detect, e.g., log-
ging an object with special properties. While the detection
methodology presented in this section is speciﬁcally tailored
to each technique and only able to detect exactly them, this
methodology is simple, effective, and scales very well. Note
that in contrast to this approach, we will also introduce a
more generic approach to detect sophisticated anti-debugging
techniques in the second half of the paper.
In general, we are using a real Chromium browser for our
experiments which is controlled from Node.js via the De-
vTools Protocol [5]. This means we have many advanced
capabilities, e.g., injecting JavaScript into each context before
the execution of any other code occurs or programmatically
controlling the behavior of the debugger. Yet for any loaded
website, we still appear and behave like a normal browser.
ShortCut To detect intercepted key presses, we ﬁrst collect
all event listeners via the getEventListeners function. For
each collected keydown or contextmenu listener, we create an
USENIX Association
30th USENIX Security Symposium    2939
artiﬁcial keyboard or mouse event to imitate the shortcut or
right click. We pass this event to the listener and then check if
the defaultPrevented property of the event was set, i.e., the
respective normal behavior was blocked by this listener.
TrigBreak By registering the Debugger.paused event of the
DevTools protocol, we can observe the location of each trig-
gered breakpoint. We log this data and immediately resume
execution, to not reveal the presence of the debugger itself.
ConClear To check for attempts at constantly clear-
ing the console, we ﬁrst
register a callback to the
Runtime.consoleAPICalled event of the DevTools protocol.
This API notify us of all invocations of functions of the
console object and thus allows us to observe how often
console.clear is called.
ModBuilt We inject JavaScript code into each website
which is guaranteed to execute before any of the website’s
code. Our injected code then creates a wrapper around each
object and all of its properties we want to observe. This wrap-
per will notify our back-end if someone overwrites them or
one of their properties. We ignore code that only adds new
properties that do not overwrite existing functionality, e.g., a
polyﬁll that adds a new function like String.replaceAll to
browsers that do not yet support this feature.
WidthDiff We use a similar wrapper as described in MOD-
BUILT, only this time we monitor for read accesses instead
of writes to the property innerWidth and its siblings. Since
we expect that tracking and ﬁngerprinting scripts, in particu-
lar, might be interested in some of these values to determine
the screen resolution of all visitors, we only ﬂag scripts that
access all four properties.
LogGet Similarly to the CONCLEAR technique, we observe
all interactions via the console APIs. As the technique re-
quires one to log some speciﬁcally crafted objects that are
unlikely to be logged during normal operations of a website,
we can look out for those. Thus, if we observe a format string
logged together with a function that has a custom toString
function like in Figure 5, we ﬂag the page. The same applies
if we observe the logging of an object that has an id property
which is a function instead of a value.
Triggering breakpoints or clearing the console once or
twice is rather harmless, they only become a problem if they
happen constantly. Therefore, for all these 6 BADTs we not
only detect if they happen but also how often per script. One
disabled shortcut could be a coincidence, but disabling all
ﬁve within the same piece of code is most likely a deliberate
attempt at preventing access to the source. For this, we only
count occurrences in the main frame of the loaded page, since
(usually rotating) advertisements should not inﬂuence the
numbers. Moreover, many techniques lose their effectiveness
in iframes, e.g., SHORTCUT would only prevent the shortcut
while the iframe is focused. We aggregate all numbers by site,
i.e., if a given technique is present on multiple (sub-)pages
of the same site, we only count it once. The same applies if
one site has multiple different scripts that trigger the same
technique. In all cases, we only use the most signiﬁcant oc-
currence of each technique within a site for further analysis,
e.g., the script that cleared the console most often.
4.2 Study I – Experiment Setup
For our large-scale study, we visited the 1 million most popu-
lar websites according to the Tranco list [33] generated on 21
Dec 2020. We started 80 parallel crawlers using Chromium
87.0.4280 on 22 Dec and ﬁnished the crawl three days later.
On each page, our crawler waits up to 30 seconds for the
load event to trigger, otherwise we ﬂag the site as failed and
move on. After the load event, we wait up to 3 more seconds
for pending network requests to resolve to better handle pages
which dynamically load additional content. Finally, we then
stay for an additional 5 seconds on each loaded page, so that
techniques that take repeated actions like TRIGBREAK or
WIDTHDIFF have enough time to trigger multiple times.
Of all the sites of the initial 1 million, about 15% could not
be visited at all, despite having used the most recent Tranco
list. Of these, about 8% were due to network errors, in partic-
ular, the DNS lookup often failed to resolve. In another 4%,
the server returned an HTTP error code and the remaining 3%
failed to load before our 30 seconds timeout hit. In total, we
successfully visited around 2.8M pages on about 846k sites,
where site refers to an entry in the Tranco list which then
consists of one or more pages. We did not only visit the front
page because research on the cryptojacking phenomenon has
shown that a common evasive technique is to not run any ma-
licious code on the front page to avoid detection during brief
inspections. In line with previous research [30, 40], we there-
fore additionally selected three random links to an internal
subpage and visited these as well.
4.3 Study I – Prevalence
First of all, we are interested in the general prevalence of
BADTs in the wild. As can be seen in Table 2, we can ﬁnd
indicators of behavior resembling the six BADTs on over
200k sites. The overwhelming majority of these are caused
by MODBUILT and WIDTHDIFF, which, judging from the
high numbers, seem to be common behavior also in benign
code. Moreover, we can see that visiting subpages did indeed
signiﬁcantly increase the prevalence by about 17% compared
to only crawling the front pages. Interestingly, indicators of
the more desirable techniques (using the properties from our
systematization in Table 1) are also more often hidden in
subpages. Speciﬁcally, TRIGBREAK is a clear outlier here
and breakpoints occurred a lot more often only on subpages.
These results in Table 2 should only be seen as indicators
for behavior resembling those of the six BADTs. Next, we
analyze how conﬁdent we are for each occurrence that it is
2940    30th USENIX Security Symposium
USENIX Association
Table 2: Number of sites with indicators for each technique
and the increase from also visiting subpages.
Technique
SHORTCUT
TRIGBREAK
CONCLEAR
MODBUILT
WIDTHDIFF
LOGGET
TOTAL
# Websites % Total
0.53
0.13
0.36
12.00
13.49
0.36
4525
1128
3061
101587
114154
3044
# Subpages only
818 (+22%)
502 (+80%)
981 (+47%)
15345 (+18%)
18615 (+19%)
756 (+33%)
206676
24.42
30494 (+17%)
used in an intentional and malicious manner. As previously
stated, there is a huge difference between clearing the console
once and clearing it 50 times within a few seconds. On the
other hand, it makes little difference anymore if it is cleared 20,
50, or even 1000 times which are all highly unusual and hard
to cause by accident. In between those two extremes, there
is a window of values that are suspicious but not deﬁnitely
malicious, e.g., clearing it 5 times. As Figure 6 shows, for
many techniques about 50% of all detections were caused
by just a single occurrence. Looking at CONCLEAR, we can
see that of all sites that cleared the console at least once, only
about 4% cleared it between 6 and 10 times and only 1%
cleared it more than 10 times.
Figure 6: Occurrences within each BADTs grouped into 7
bins, e.g., all sites on which a technique triggered 11-20 times
share the same bin. The bins are only used for data visualiza-
tion and not for further analysis.
To compare indicators of different techniques, we ﬁrst need
a normalized value that incorporates these insights from Fig-
ure 6. Therefore, we calculate the conﬁdence score by tak-
ing the squared value of the percentile within that technique.
For example, if we visit a site and see one script that clears
the console twice, we would assign a conﬁdence score of
0.62 = 0.36 to this script. On the other hand, if the same
script would trigger 30 times, we would assign a conﬁdence