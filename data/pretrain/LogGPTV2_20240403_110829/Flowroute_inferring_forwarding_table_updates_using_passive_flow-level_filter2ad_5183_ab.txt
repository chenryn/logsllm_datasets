In this work, we use FlowRoute
to study intra-AS routing using MPLS tunnel endpoints as
destinations. We emphasize, though, that our method does
not depend on the choice of MPLS tunnel endpoints as des-
tinations. An operator is free to choose the appropriate
granularity of D.
4.2 Routing Change vs ECMP
We have assumed that consecutive RFRs with diﬀerent
next hops towards the same destination indicate a rout-
ing change. This may not hold when Equal-Cost Multi-
Path (ECMP) [15] is enabled; a router may have two or
more equal cost paths to the same destination and alter-
nate between them on a per-ﬂow basis. Consider a router
R with two equal cost paths to destination D via next hops
R1 and R2. Consecutive RFRs of the form (R,t1,t2,D,R1),
(R,t3,t4,D,R2), and (R,t5,t6,D,R1) would appear as a change
in R’s next hop from R1 to R2 in the time interval [t2,t3],
and from R2 to R1 in time interval [t4,t5]. Next-hop changes
due to ECMP do not appear as routing changes to a con-
trol plane monitor. Further, the mapping of a ﬂow tuple to
next hop routers can be dynamic, meaning that our oﬄine
analysis cannot leverage known properties of the mapping
function to detect ECMP. We therefore design a method to
distinguish between routing changes and ECMP using the
sequence of RFRs.
We ﬁnd empirically – using data from a day on which a
production control plane monitor reported no routing events
– that in more than 99% of cases, a router forwards fewer
than 20 ﬂows to a certain next hop, before routing a ﬂow
to a diﬀerent equal cost next hop. Using this observation,
we devise the following ECMP ﬁltering algorithm. We keep
track of the current next hop nc(R, D) for router R towards
destination D, and the number of consecutive ﬂows fc(R, D)
that R has routed towards the current next hop nc(R, D).
Let nh(R, D) be the next hop for router R towards destina-
tion D obtained from the latest RFR. If nh(R, D) is diﬀerent
from nc(R, D), and if fc(R, D) > tecmp, then we count this
as a routing change; otherwise we assume it is an instance
of ECMP. For the analysis in this paper, we use tecmp=20.3
4.3 Trafﬁc Rates and Sampling
FlowRoute produces a set of ranges, (R, [t, t′], D), speci-
fying the time window in which we infer a routing change
to have occurred. The temporal resolution of our inference
(the width of these ranges) depends on the frequency with
which ﬂows to destination D traverse router R, which itself
depends on the popularity of D and the distance (in net-
work hops) of R from D. Routers closer to destination D
aggregate traﬃc from more sources on the sink tree towards
D. Packet sampling in NetFlow also aﬀects the temporal
granularity of our inference. This eﬀect is compounded by
further sampling of ﬂow records within the measurement col-
lection infrastructure [7]. To quantify the eﬀect of sampling,
1Gbps of backbone traﬃc would generate hundreds of Net-
3We would need to estimate tecmp speciﬁcally for the net-
work on which we deploy FlowRoute.
317Flow records per second with 1 in 500 packet sampling [11],
giving us a temporal resolution of a few milliseconds. 1Mbps
of traﬃc would yield a temporal resolution of a few seconds,
still suﬃcient for many applications. FlowRoute achieves
high temporal resolution on routes that have the most traf-
ﬁc, which are exactly the routes that operators care most
about monitoring. Also, FlowRoute is not limited to us-
ing ﬂow records generated by existing traﬃc. We can aug-
ment existing traﬃc on low-traﬃc routes with active packet
probes. A router equipped with Flexible NetFlow [5] can in-
stantiate a dedicated packet ﬁlter to select all active probe
packets based on a predetermined IP address/port signa-
ture. The resulting temporal resolution can be as small as
the inter-probe time.
Though the temporal resolution of our inferences depends
on the ﬂow rate and sampling, we emphasize that these fac-
tors do not aﬀect the correctness of the ranges we infer. For
example, the range (R, [t, t′], D) denotes that we last ob-
served a ﬂow at R towards the old next hop (say N1) at
time t, and ﬁrst observed a ﬂow at R towards the new next
hop (say N2) at time t′. Due to sampling, we could have
missed a ﬂow at R towards N1 at time t + δ1, and a ﬂow
towards N2 at time t′
− δ2. A larger ﬂow volume or less sam-
pling would thus lead to narrower ranges. In the absence of
short-lived route ﬂaps, the bounds provided by our inferred
range (R, [t, t′], D) are correct – R was routing ﬂows to N1
at least until t, and R started routing ﬂows to the new next
hop N2 no later than t′.
5. RESULTS
In this section, we use FlowRoute to study how routers
update their forwarding tables in response to routing events
reported by a control plane monitor. We ﬁrst describe our
datasets and verify the consistency of the route change in-
formation obtained across routers.
5.1 Approach and Data
Our study uses two types of data collected from a Tier-1
ISP network during July and August 2008. Our ﬁrst dataset
consists of routing events reported by OSPFMon[16] in the
form of Link State Advertisements (LSAs) that indicate
changes in link status (up/down) or link weights which could
result in routing changes. OSPF events lend themselves to
clustering, since events such as the cost-in or cost-out of
links often result in multiple subsequent events relating to
changes in path metrics. For each OSPF event cluster, a
range [ts, te] indicates the start and end time of the cluster.
We use a clustering threshold of 50 seconds, after which two
events are assigned to separate clusters. Our second dataset
consists of packet sampled Netﬂow records (which were also
subject to ﬂow-level sampling [7]) collected from several hun-
dred backbone routers during the same two month period.
We use FlowRoute to measure the times when routers up-
dated their next hops in response to measured OSPF events
(after ﬁltering out occurrences of ECMP).
5.2 Validation of Inter-Router Consistency
Recall from Section 3 that each Netﬂow record generated
at a router R creates two RFRs: one describing the routing
state at R (towards its next hop) and one describing the
routing state at the previous hop (towards R). We may ob-
serve consecutive RFRs at router R, or two RFRs at diﬀer-
ent routers downstream of R, indicating that R changed its
 24000
 23900
 23800
 23700
e
m
i
t
 23600
 23500
 23400
 23300
 23200
 0
 50
 100
 150
 200
destination index
Figure 3: Router A: Updates of next hop to all
destinations are consistent with OSPF events.
next hop.4 We validate the consistency of routing changes
inferred from the two vantage points, providing assurance
that our methodology is sound, and that NTP time synchro-
nization across routers is suﬃcient for FlowRoute’s purpose.
We separate the stream of RFRs into those obtained using
input interfaces (I stream) and output interfaces (O stream).
We apply the method of Section 3 to infer routing changes
separately from the I and O streams. We compare cases
where we infer a routing change for the same R, D pair us-
ing both I and O streams. For example, for a R, D pair,
we infer the time windows [ti
2] using the I
stream and O stream, respectively. Using data from August
1, 2008, we ﬁnd 2024 R, D pairs for which we inferred a rout-
ing change in both the I and O streams; For each of these
R, D pairs, the time windows are overlapping. Thus, the I
and O streams – which come from two independent sources
– give consistent information about routing changes.
2] and [to
1, ti
1, to
5.3 Delayed Forwarding Table Updates
We use FlowRoute to measure the times at which routers
update forwarding tables in response to routing changes.
Figure 3 shows the set of update ranges for a router A near
the time of an OSPF event cluster on July 9, 2008. The
OSPF event times are indicated by the horizontal band be-
tween 23,514 and 23,549 on the y-axis (denoting seconds
since the start of the day.) The x-axis is the index of a desti-
nation D, and each vertical bar illustrates a range (A, [t1, t2], D).
The lower end of the bar (t1) is the last time that we saw a
ﬂow routed towards to the old next hop, and the upper end
of the bar (t2) is the time we ﬁrst saw a ﬂow routed to the
new next hop. We sort the destination indices in increasing
order of t1. For router A, the range for each destination
overlaps the OSPF events; in this sense the FlowRoute view
is consistent with the OPSFMon view. For some destina-
tions, we obtain ranges that are narrower than one second,
giving a fairly ﬁne temporal resolution with which we can
detect routing changes for those destinations.
Figure 4 shows the case of router B for an OSPF event
4While we may observe a routing change at both vantage
points, often we only see it at one or the other location due
to sampling.
318 21000
 20800
 20600
 20400
 20200
e
m
i
t
 20000
 19800
 19600
 19400
 0
 50
 100
 150
 200
destination index
Figure 4: Router B: Updates of next hop to some
destinations occur after last OSPF event.
cluster on July 4, 2008. The time range in which router
B updated its route to some destinations (indices less than
100) overlaps the OSPF events; updates to these destina-
tions could be consistent with the OSPF event cluster. For
destinations with indices larger than 100, the lower end of
the range is up to 50 seconds after the last OSPF event. The
correctness of this observation is not aﬀected by ﬂow rates
and sampling – the lower end of these ranges is a lower
bound on when the router updated its forwarding table (see
discussion in Section 4.3). We make two observations here.
First, it appears that forwarding table updates for router
B are spread out over time. Second, for destination indices
greater than 100, router B was forwarding ﬂows to the old
next hop at least until the lower end of the range – more than
50 seconds after the OSPF event. This ﬁnding is signiﬁcant
because distributed routing protocols expect forwarding ta-
ble updates to occur at about the same time across routers to
ensure stability. Even a single router updating its forwarding
table over an extended period (10s of seconds) could impact
network-wide convergence. In Section 5.4, we describe cases
where delayed forwarding table updates caused forwarding
loops.
We measured the frequency of delayed forwarding table
updates in the two month dataset from July and August
2008. Let [t1, t2] be the window in which router R changed
its next hop towards destination D in response to an OSPF
event cluster from [ts, te]. We say that a router R shows
delayed forwarding table updates if t1 > te for at least
N destinations. We use N =3 to avoid spurious conclu-
sions due to a failure of our ECMP detection algorithm.5
Across 2666 OSPF event clusters in the dataset, we found
97010 time ranges (one per R, D pair) that were consis-
tent with the event cluster (i.e., like router A). We found
58 event clusters containing 117 time ranges where at least
one router showed delayed forwarding table updates. Most
routers showed this behavior only once over the two months;
two routers, however, did so 14 times. We observed that
most routers that showed delayed updates were of the same
make/model. Discussions with network operators conﬁrmed
5Diﬀerent values of N yield qualitatively similar results.
that those routers did indeed have protocol implementation
bugs causing performance issues. The buggy routers have
since been retired from the network.
5.4 Routing Loops
The delayed forwarding table updates described in the
previous section can cause transient routing loops. We show
how FlowRoute can detect such loops in practice. We use
RFRs to identify routing loops using the following algorithm.
Recall that an RFR (R1, t1, t2, D, R2) indicates that the next
hop for router R1 towards destination D was R2 in the time
interval [t1,t2]. To ﬁnd routing loops, we search for RFRs
of the form (R1, t1, t2, D, R2) and (R2, t3, t4, D, R1), where
the time windows [t1, t2] and [t3, t4] overlap. This pair of
RFRs indicates that a loop between adjacent routers R1 and
R2 aﬀected destination D during the intersection of time
windows [t1, t2] and [t3, t4].6 To study the duration of each
such loop, we measure the number of consecutive seconds in
which we saw overlapping RFRs for a pair of routers towards
the same destination. We found 392 occurrences of one-hop
loops during our two-month dataset. We found that more
than 90% of these loops were short-lived, seen only in one
or two consecutive seconds. We also found long-lived loops
that lasted for 10s of seconds; the longest was seen in 67
consecutive seconds.
A
B
C
D
(b)
E
A
B
A
B
C
D
C
D
(a)
(c)
E
E