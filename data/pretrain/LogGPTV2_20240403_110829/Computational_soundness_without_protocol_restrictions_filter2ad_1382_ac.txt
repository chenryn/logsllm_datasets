cryption keys using their corresponding encryptions
keys). This latter condition is actually already ensured
by never sending decryption keys, but we mention it
explicitly for completeness.
(Similar restrictions occur for signing keys in [4], however,
those restrictions are not due to principal issues, removing
them just adds some cases to the proof.)
We will now explain where these restrictions come from
and how we avoid them in our proof.
5.1 Sending secret keys
The ﬁrst restriction that we encounter in the above proof
is that we are not allowed to send secret keys. For example,
the following simple protocol is not covered by the above
proof:
Alice picks a encryption/decryption key pair (ek , dk ) and
publishes ek . Then Alice sends enc(ek , N ) for some fresh
nonce N . And ﬁnally Alice sends dk .
When applying the above proof to this protocol, the faking
simulator (more precisely, the function τ in that simulator)
will translate enc(ek , N ) into an encryption c of 0 (as op-
posed to an encryption of rN ). But then, when dk is sent
later by the symbolic protocol, the simulator would have to
send the corresponding computational decryption key. But
that would allow the adversary to decrypt c, and the adver-
sary would notice that c is a fake ciphertext.
The following solution springs to mind: We modify the
faking simulator such that he will only produce fake cipher-
texts when encrypting with respect to a key pair whose se-
cret key will never be revealed. Indeed, if we could do so,
it might solve our problem. However, in slightly more com-
plex protocols than our toy example, the simulator may not
know in advance whether a given secret key will be revealed
(this may depend on the adversary’s actions which in turn
may depend on the messages produced by the simulator). Of
course, we might let the simulator guess which keys will be
revealed. That, however, will only work when the number
of keys is logarithmic in the security parameter. Otherwise
the probability of guessing correctly will be negligible.4
(Notice also that the problem is also not solved if the sim-
ulator does not produce fake ciphertexts if in doubt: Then
4This is closely related to selective opening security (SOA)
[14]. However, although selective SOA addresses a similar
problem, it is not clear how SOA could be used to prove
computational soundness.
703our argument that the bitstring mbad is unguessable would
become invalid.)
To get rid of the restriction, we take a diﬀerent approach.
Instead of forcing the simulator to decide right away whether
a given ciphertext should be a fake ciphertext or not, we let
him decide this later. More precisely, we make sure that the
simulator can produce a ciphertext c without knowing the
plaintext, and later may “reprogram” the ciphertext c such
that it becomes an encryption of a message m of his choice.
(But not after revealing the secret key, of course.)
At the ﬁrst glance, this seems impossible. Since the ci-
phertext c may already have been sent to the adversary, c
cannot be changed.
It might be possible to have an en-
cryption scheme where for each encryption key, there can be
many decryption keys; then the simulator could produce a
special decryption key that decrypts c to whatever he wishes.
But simple counting arguments show that then the decryp-
tion key would need to be as long as the plaintexts of all
ciphertexts c produced so far together. This would lead to
a highly impractical scheme, and be impossible if we do not
impose an a-priori bound on the number of ciphertexts. (See
[32].)
However, we can get around this impossibility if we work
in the random oracle model. (In the following, we use the
word random oracle for any oracle chosen uniformly out of
a family of functions; thus also the ideal cipher model or the
generic group model fall under this term. The “standard”
random oracle [15] which is a uniformly randomly chosen
function from the set of all functions we call “random hash
oracle” for disambiguation.)
In the random oracle model, we can see the random oracle
as a function that is initially undeﬁned, and upon access,
the function table is populated as needed (lazy sampling).
This enables the following proof technique: When a certain
random oracle location has not been queried yet, we may
set it to a particular value of our choosing (this is called
“programming the random oracle”). In our case this can be
used to program a ciphertext c: As long as we make sure
that the adversary has not yet queried the random oracle at
the locations needed for decrypting c (e.g., because to ﬁnd
these locations he needs to know the secret key), we can
still change the value of the oracle at these locations. This
in turn may allow us to change the value that c decrypts to.
Summarizing, we look for an encryption scheme with the
following property: There is a strategy for producing (fake)
keys and ciphertexts, and for reprogramming the random
oracle (we will call this strategy the “ciphertext simulator”),
such that the following two things are indistinguishable:
(a) (Normally) encrypting a value m, sending the resulting
ciphertext c, and then sending the decryption key. (b) Pro-
ducing a fake ciphertext c. Choosing m. And sending the
decryption key.
Such a scheme could then be used in our computational
soundness proof: Sim 2 would encrypt messages m normally.
Sim 4 would produce fake ciphertexts c instead, and only
when revealing the decryption key, reprogram the cipher-
texts c to contain the right messages m. Then, we would
consider an additional simulator Sim 5 that does not even
compute m until it is needed. This will then allow us to
argue that the bitstring mbad corresponding to a “bad” sub-
term tbad cannot be guessed because the information needed
for guessing this bitstring was never computed/accessed.
A security deﬁnition for encryption schemes with the re-
quired properties has been presented in [35] (called PROG-
KDM), together with a natural construction satisfying the
deﬁnition. In the following, we present and explain their def-
inition and how it allows us to get computational soundness
for protocols sending secret keys.
In particular,
Formally deﬁning PROG-KDM security turns out to be
more complex than one might expect. We cannot just state
that the ciphertext simulator is indistinguishable from an
honest encryption oracle. The ciphertext simulator has a
completely diﬀerent interface from the honest encryption
oracle.
it expects the plaintext when be-
ing asked for the secret key, while the encryption oracle
would expect these upon encryption. To cope with this
problem, we deﬁne two “wrappers”, the real and the fake
challenger. The real challenger essentially gives us access to
the encryption algorithm while the fake challenger, although
it expects the plaintexts during encryption (to be indistin-
guishable from the real challenger), uses the plaintexts only
when the decryption key is to be produced. These two chal-
lengers should then be indistinguishable. (The challengers
additionally make sure that the adversary does not perform
any forbidden queries such as submitting a ciphertext for
decryption that was produced by the challenger.)
We ﬁrst deﬁne the real challenger. The real challenger
needs to allows us to query the encryption and decryp-
tion keys, to perform encryptions and decryptions, and to
give us access to the underlying random oracle. However,
if we only have these queries, situations like the follow-
ing would lead to problems: The adversary wishes to get
Enc(ek 1, Enc(ek 2, m)). We do not wish the adversary to
have to request Enc(ek 2, m) ﬁrst and then resubmit it for the
second encryption, because this would reveal Enc(ek 2, m),
and we might later wish to argue that Enc(ek 2, m) stays se-
cret. To be able to model such setting, we need to allow the
adversary to evaluate sequences of queries without reveal-
ing their outcome. For this, we introduce queries such as
R := encch(N, R1). This means: Take the value from regis-
ter R1, encrypt it with the key with index N ∈ {0, 1}∗, and
store the result in register R. Also, we need a query to apply
arbitrary functions to registers: R := evalch(C, R1, . . . , Rn)
applies the circuit C to registers R1, . . . , Rn. (This in par-
ticular allows us to load a ﬁxed value into a register by using
a circuit with zero inputs (n = 0). Finally, we have a query
revealch(R1) that outputs the content of a register.
Formally, the deﬁnition of the real challenger is the fol-
lowing:
Definition 2
(Real challenger). Fix an oracle O
and an encryption scheme (K, E, D) relative to that or-
acle. The real challenger RC is an interactive machine
deﬁned as follows. RC has access to the oracle O. RC
maintains a family (ek N , dk N )N∈{0,1}∗ of key pairs (ini-
tialized as (ek N , dk N ) ← K(1η) upon ﬁrst use), a family
(reg N )N∈{0,1}∗ of registers (initially all reg N = ⊥), and a
family of sets cipher N (initially empty). RC responds to the
following queries (when no answer is speciﬁed, the empty
word is returned):
• R := getekch(N ): RC sets reg R := ek N .
• R := getdkch(N ): RC sets reg R := dk N .
• R := evalch(C, R1, . . . , Rn) where C is a Boolean cir-
cuit:5 Compute m := C(reg R1 , . . . , reg Rn ) and set
reg R := m.
5Note that from the description of a circuit, it is possible to
704• R := encch(N, R1): Compute c ← EO(ek N , reg R1 ),
append c to cipher N , and set reg R := c.
• oraclech(x): Return O(x).
• decch(N, c): If c ∈ cipher N , return forbidden where
forbidden is a special symbol (diﬀerent from any bit-
string and from a failed decryption ⊥). Otherwise, in-
voke m ← DO(dk N , c) and return m.
• revealch(R1): Return reg R1 .
Here N and c range over bitstrings, R ranges over bitstrings
with reg R = ⊥ and the Ri range over bitstrings R with
reg Ri
6= ⊥.
Notice that the fact that we can do “hidden evaluations”
of complex expressions, also covers KDM security (security
under key-dependent messages): We can make a register
contain the computation of, e.g., Enc(ek , dk ) where dk is
the decryption key corresponding to ek .
We now proceed to deﬁne the fake challenger. The fake
challenger responds to the same queries, but computes the
plaintexts as late as possible. In order to do this, upon a
query such as R := encch(N, R1), the fake challenger just
stores the symbolic expression “encch(N, R1)” in register R
(instead of an actual ciphertext). Only when the content
of a register is to be revealed, the bitstrings are recursively
computed (using the function FCRetrieve below) by query-
ing the ciphertext simulator. Thus, before deﬁning the fake
challenger, we ﬁrst have to deﬁne formally what a ciphertext
simulator is:
A
deccs(c),
enccs(R, m),
Definition 3
(Ciphertext simulator).
ci-
phertext simulator CS for an oracle O is an inter-
active machine that responds to the following queries:
fakeenccs(R, l),
getekcs(),
getdkcs(), and programcs(R, m). Any query is answered
with a bitstring (except deccs(c) which may also return
⊥). A ciphertext simulator runs in polynomial-time in
the total
length of the queries. A ciphertext simulator is
furthermore given access to an oracle O. The ciphertext
simulator is also allowed to program O (that is, it may
perform assignments of the form O(x) := y). Furthermore,
the ciphertext simulator has access to the list of all queries
made to O so far.6
The interesting queries here are fakeenccs(R, l) and
programcs(R, m). A fakeenccs(R, l)-query is expected to
return a fake ciphertext for an unspeciﬁed plaintext of
length l (associated with a handle R). And a subsequent
programcs(R, m)-query with |m| = l is supposed to pro-
gram the random oracle such that decrypting c will return
m. The ciphertext simulator expects to get all necessary
programcs(R, m)-queries directly after a getdkcs()-query re-
vealing the key. (Formally, we do not impose this rule, but
the PROG-KDM does not guarantee anything if the cipher-
text simulator is not queried in the same way as does the
fake challenger below.) We stress that we allow to ﬁrst ask
for the key and then to program. This is needed to handle
key dependencies, e.g., if we wish to program the plaintext to
be the decryption key. The deﬁnition of the fake challenger
will make sure that although we reveal the decryption key
determine the length of its output. This will be important
in the deﬁnition of FCLen below.
6Our scheme will not make use of the list of the queries to
O, but for other schemes this additional power might be
helpful.
before programming, we do not use its value for anything
but the programming until the programming is done.
Note that we do not ﬁx any concrete behavior of the ci-
phertext simulator since our deﬁnition will just require the
existence of some ciphertext simulator.
We can now deﬁne the real challenger together with its
recursive retrieval function FCRetrieve:
Definition 4
(Fake challenger). Fix an oracle O,
a length-regular encryption scheme (K, E, D) relative to that
oracle, and a ciphertext simulator CS for O. The fake chal-
lenger FC for CS is an interactive machine deﬁned as fol-
lows. FC maintains the following state:
• A family
• A family of instances (CSN )N∈{0,1}∗ of CS (initial-
ized upon ﬁrst use). Each ciphertext simulator is given
(read-write) oracle access to O.
of
(initially
all reg R = ⊥).
Registers reg N are either un-
deﬁned (reg N = ⊥), or bitstrings, or queries
(written
or
“evalch(C, R1, . . . , Rn)” etc.).
(reg R)R∈{0,1}∗
“getekch(N )”
“getdkch(N )”
registers
or