# Detecting Traditional Packers, Decisively

**Authors:**  
Denis Bueno, Kevin J. Compton, Karem A. Sakallah, and Michael Bailey  
Electrical Engineering and Computer Science Department  
University of Michigan  
{dlbueno, kjc, karem, mibailey}@umich.edu

## Abstract
Many significant decidability results in malware analysis are based on Turing machine models of computation. We introduce computational models that use more realistic assumptions about machine and attacker resources. While seminal results such as [1–5] remain true for Turing machines, we demonstrate that under more realistic assumptions, important tasks are decidable rather than undecidable. Specifically, we show that detecting traditional malware unpacking behavior—where a payload is decompressed or decrypted and subsequently executed—is decidable under our assumptions. We then examine the issue of dealing with complex but decidable problems and draw lessons from the hardware verification community, which has been addressing intractable problems for the past three decades.

## 1 Introduction
In recent years, the rate of incoming malware has increased by an order of magnitude [6]. Manual analysis, which takes several hours per sample, cannot keep up with this volume. Therefore, there is a critical need to develop scalable, automated analysis techniques. Currently, a wide variety of automated methods exist for unpacking, malicious code detection, clustering related malware samples, and reverse engineering. However, the possibility of complete, automated analysis has long been hindered by theoretical results in computer science: we simply cannot design algorithms clever enough to solve undecidable problems.

Packing is a common technique used by malware authors to evade antivirus detection. Packers are software programs that obfuscate code, and when the packed binary is executed, it unpacks its original code and then executes it. Packers are effective at avoiding signature-based detection because signatures must be manually created, while packed versions are generated automatically.

Recent papers on practical topics in malware analysis have included some discouraging decidability results. For example, Christodorescu et al. [2] describe a technique for matching malware samples against hand-constructed templates of malicious behavior. They prove that this matching problem is undecidable by exhibiting a template that, if matched, solves the halting problem for Turing machines.

This paper examines the standard approach to decidability and complexity in the context of malware analysis. Our contributions include:

- **Critical Analysis of Theoretical Models:** We critically analyze the theoretical models used to prove prominent undecidability results. We thoroughly examine the widely-held assumptions [1–5] behind these results and find that the assumptions about time and space constraints are unrealistic.
- **New Theoretical Model for Malware Analysis:** We introduce a new theoretical model for malware analysis based on the existing concept of RASP (Random Access Stored Program) machines [8]. In the general case, RASP machines have the computational power of Turing machines. We use RASPs to formalize the problem of detecting traditional unpacking behavior and prove that under certain very loose and realistic time and space assumptions, detecting unpacking is not only decidable but also NP-complete.
- **Dealing with Intractable Problems:** We acknowledge that NP-complete does not mean tractable. For inspiration in dealing with intractable problems, we look to the three-decade-long effort in hardware verification.

## 2 Motivation
"There isn’t (and never will be) a general test to decide whether a piece of software contains malicious code." — IEEE Security & Privacy magazine, 2005 [3]

The belief that malicious code detection is undecidable has permeated the community's consciousness, as the above quote indicates. The article even explains the halting problem reduction typically used to prove undecidability results.

Indeed, the literature is replete with claims that various malware tasks are undecidable. For example, Jang et al. state that "malware analysis often relies on undecidable questions" [9]. Moser et al. describe several attacks against static analyzers and claim that "[static] detection faces the challenge that the problem of deciding whether a certain piece of code exhibits a certain behavior is undecidable in the general case" [10].

The MetaAware paper describes a static analysis for recognizing metamorphic variants of malware [11]. The authors claim that "determining whether a program will exhibit a certain behavior is undecidable" and that checking whether a virus is a polymorphic variant of another virus is undecidable.

In the context of botnet analysis, Brumley et al. have examined "trigger-based behavior" and make similar claims: "deciding whether a piece of code contains trigger-based behavior is undecidable" [4]. Newsome et al. consider the problem of replaying executions, which requires searching for inputs satisfying a program’s control flow. According to them, "finding a satisfying input can be reduced to deciding the halting problem" [5]. Sharif et al. describe a system for analyzing virtualization obfuscators and claim that "theoretically, precisely and completely identifying an emulator's bytecode language is undecidable" [12].

The PolyUnpack paper by Royal et al. describes an automated unpacker that works by comparing any executed code against the executable's static code model [1]. Appendix A in that paper proves that detecting unpacking behavior is undecidable by giving a formal reduction from the halting problem for Turing Machines. Many later papers cite PolyUnpack for this decidability result [13–18].

We emphasize that we do not mean that the respective authors are wrong in their claims. We cite them to support the assertion that undecidability results are a common thread in the automated malware analysis literature, common enough to state without proof. They are part of the community’s collective consciousness and thus potentially influence the work we pursue.

**A Ray of Hope:** Alongside the malware analysis community, some decidability results have emerged. A small article in 2003 proved that a bounded variant of Cohen’s decidability question is NP-complete [19]. Subsequently, another paper showed that detecting whether a program P is a metamorphic variant of Q is NP-complete under a certain kind of metamorphic transformation [20]. While their assumptions are somewhat restrictive, these proofs should give us some hope. If, under suitable restrictions, these tasks are decidable, can we use similar restrictions to obtain decidability for other questions?

We believe so and provide proofs in this paper. Our key insight is that Turing machines are too generous—they allow programs to use potentially infinite amounts of time and space. Digital computers, however, are limited along these dimensions. For comparison, in the cryptographic literature, standard assumptions are much more realistic. The attacker, Eve, is allowed probabilistic polynomial time to accomplish her nefariousness [21]. By analogy, we might consider malware models in which the malware is allowed polynomial time to accomplish its malicious behavior.

## 3 RASP Model and Decidability Results

### Proof Roadmap
The following sections have a somewhat complex structure, which we now explain:

1. **Review of Related Work:** We begin with a review of foundational models in the theoretical malware analysis literature.
2. **Introduction to RASP Machine:** We introduce a Random Access Stored Program (RASP) machine that draws heavily from prior work in algorithmic analysis [8, 22–24]. The RASP has the same computational power as a Turing machine but is more convenient for formalizing unpacking behavior.
3. **RASP Interpreter:** We introduce a novel element, the RASP interpreter. The interpreter is a RASP program that interprets other RASP programs, modeling a dynamic analyzer and playing an important role in our reduction proofs.
4. **Formalizing Unpacking Behavior:** We formalize the malware unpacking problem in terms of the RASP interpreter and prove that detecting unpacking is undecidable for RASPs, complementing decidability results for Turing machines [1].
5. **Space Restriction:** We show that if we restrict the space a RASP program is allowed, detecting unpacking is decidable for RASPs.
6. **Time Restriction:** We show that if we restrict the time a RASP program is allowed, detecting unpacking is not only decidable but also NP-complete.

### 3.1 Related Work
The earliest decidability results for malware are found in Cohen’s classic work on viruses [25, 26]. His work formalizes “viral sets,” pairs (M, V) where M is a Turing machine and for all v in V, there is a v' in V that M can produce when executed on v. Viral sets are inspired by biological virus evolution. Cohen proves that viral set detection is undecidable (Theorem 6) and that viruses are at least as powerful as Turing machines as a means of computation (Theorem 7).

Shortly thereafter, Adleman’s work formalizes aspects of viruses and infection using total recursive functions and Gödel numbering [27]. He shows that the virus problems he considers are Π2-complete. Two years later, Thimbleby et al. [28] describe a general mathematical framework for Trojans, also using recursion theory, and show that Trojan detection is undecidable.

Chess and White [29] extend Cohen’s Theorem 6, showing that some viruses have no error-free detectors. They conclude that it is not possible to create a precise detector for a virus even if you reverse engineer and completely understand it. Filiol et al. [30] provide a statistical variant of Cohen’s result using his definitions, showing that the false positive probability of a series of statistical tests can never go to zero, and thus that one can never write a detector without some false positives.

### 3.2 RASP Machine
Elgot and Robinson [22] developed the RASP out of a desire to have a model of computation more like a real computer than a Turing machine, but with the same computational power. Hartmanis [23] and Cook and Reckhow [8] proved fundamental results concerning RASPs. Aho et al. [24], in an early influential book on algorithms, promoted the RASP as a basic model for algorithm analysis. Our treatment most closely follows Hartmanis [23].

The RASP is a von Neumann machine with an addressable memory that stores programs and data, an instruction pointer (ip) that stores the address of the current instruction, and a simple arithmetical unit—the accumulator register (ac). Our version of the RASP also has simple input/output operations.

RASPs differ from real computers in two ways: they have infinitely many memory locations M[i], where the addresses i are elements of N = {0, 1, 2, ...}, and each M[i] stores an arbitrary integer from Z = {..., -2, -1, 0, 1, 2, ...}. There is no fixed word size. The RASP models program behavior naturally, by reference to addresses and instructions. Unlike universal Turing machines, which must execute a large number of decoding instructions when they emulate other Turing machines, a RASP interpreter emulates other RASPs in a straightforward manner, similar to the operation of virtualization obfuscators [31].

With RASPs, it is easy to describe decidability and complexity results in terms of asymptotic behavior as input size grows. Models of computation with a fixed bound on memory size become obsolete as technology changes because memory storage grows with each successive generation of digital computers. Sometimes word size also grows. Models of computation with a fixed word size also require complicated (and usually irrelevant) multi-precision arithmetic algorithms as input size increases. RASPs strike a balance between a realistic model of computation and models suitable for asymptotic analysis.

In our instruction set architecture (ISA), an instruction consists of an opcode and an operand. Opcodes are integers in the range 0 ≤ r < 16. To interpret any integer n uniquely as an instruction, we write n = 16j + r, where r is the opcode and j is the operand. Table 1 in Appendix A specifies a simple assembly language for the 16 RASP instructions. The opcode associated with a particular assembly language instruction is expressed as a mnemonic (such as load, stor, etc.) and the addressing mode—either immediate, direct, or indirect addressing—indicated by writing the operand j without brackets (j), within single angle brackets (〈j〉), or within double angle brackets (〈〈j〉〉), respectively. For example, the integer 39, viewed as an instruction, is 2 · 16 + 7: its operand is 2 and its opcode is 7. Its assembly language representation is add 〈2〉. Thus, this is a direct add instruction. We consult the operational semantics column in Table 1 to see what should happen when this instruction executes. The table tells us that we must determine the r-value (denoted rval) of the operand. We find this in Table 2 (in Appendix A). Since j is 2, the rvalue of 〈j〉 is the value M[2]. The RASP updates ac to be the value stored in M[2] plus the value in the ac register and then increments the value in the ip register.

The Tables in Appendix A also specify the time cost for each instruction in terms of the function l(i) defined by:
\[ l(i) = \begin{cases} 
\lfloor \log_2 |i| \rfloor + 1, & \text{if } i \neq 0 \\
1, & \text{if } i = 0 
\end{cases} \]
This is the approximate number of bits needed to represent i. Since the RASP does not have a fixed word size, l(i) is roughly proportional to the time required to process i during an instruction execution.