title:Detecting Traditional Packers, Decisively
author:Denis Bueno and
Kevin J. Compton and
Karem A. Sakallah and
Michael Bailey
Detecting Traditional Packers, Decisively
Denis Bueno, Kevin J. Compton, Karem A. Sakallah, and Michael Bailey
Electrical Engineering and Computer Science Department
University of Michigan
{dlbueno,kjc,karem,mibailey}@umich.edu
Abstract. Many important decidability results in malware analysis are
based on Turing machine models of computation. We exhibit computa-
tional models that use more realistic assumptions about machine and
attacker resources. While seminal results such as [1–5] remain true for
Turing machines, we show that under more realistic assumptions impor-
tant tasks are decidable instead of undecidable. Speciﬁcally, we show that
detecting traditional malware unpacking behavior – in which a payload
is decompressed or decrypted and subsequently executed – is decidable
under our assumptions. We then examine the issue of dealing with com-
plex but decidable problems, and look for lessons from the hardware
veriﬁcation community, which has been striving to meet the challenge of
intractable problems for the past three decades.
1
Introduction
In recent years, malware researchers have seen incoming malware rates multiply
by an order of magnitude [6]. By the numbers alone, manual analysis, which
takes a couple of hours per sample, will never be able to keep up. Thus, there
is a critical need to develop scalable, automated analysis techniques. Currently,
a wide variety of automated methods exist for unpacking, for malicious code
detection, for clustering related malware samples, and for reverse engineering.
Unfortunately, the possibility of complete, automated analysis has long been
impeded by theoretical results in Computer Science: we simply can’t design
algorithms clever enough to solve undecidable problems.
Although there are a variety of important malware analysis problems, pack-
ing is one which typiﬁes the analysis challenges. In order to evade anti-virus
detection, malware authors obfuscate their code; packers are software programs
that automate obfuscation [7]. When the packed binary is executed, it unpacks
its original code and then executes that. Packers are indeed eﬀective at avoiding
signature-based detection: signatures must be manually created, while packed
versions are produced automatically.
Recent papers on practical topics in malware analysis have included some
discouraging decidability results. For example, Christodorescu et al. [2] describe
a technique for matching malware samples against hand-constructed templates
of malicious behavior. A program matches a template if and only if the program
contains an instruction sequence that contains the behavior speciﬁed by the
template. Christodorescu et al. prove this matching problem is undecidable: the
proof exhibits a template that, if matched, solves the halting problem for Turing
machines.
This paper examines the standard approach to decidability and complexity
in the context of malware analysis. Speciﬁcally, we make the following contribu-
tions:
– We critically analyze theoretical models used to prove prominent undecid-
ability results. We thoroughly examine the widely-held assumptions [1–5]
behind these results, and ﬁnd that the assumptions about time and space
constraints are unrealistic.
– We introduce a new theoretical model for malware analysis, based on the
existing concept of RASP machines [8]. In the general case, RASP machines
have the computational power of Turing machines. As an example of our
approach, we use RASPs to formalize the problem of detecting traditional
unpacking behavior. We prove that under certain very loose and realistic
time and space assumptions, detecting unpacking is not only decidable, but
NP-complete.
– We acknowledge that NP-complete does not mean tractable. For inspiration
in dealing with intractable problems, we look to the three-decade-long eﬀort
in hardware veriﬁcation.
2 Motivation
There isn’t (and never will be) a general test to decide whether a piece
of software contains malicious code.
— IEEE Security & Privacy magazine, 2005 [3]
The mantra that malicious code detection is undecidable has pervaded the com-
munity’s consciousness, as the quote above indicates. The article even explains
the halting problem reduction that is typically used to prove undecidability re-
sults.
Indeed, we ﬁnd the literature littered with claims that various malware tasks
are undecidable. We give several examples. The purpose of these examples is not
to point out errors in the proofs (most results are claimed without proof) but
to illustrate how widespread the opinion is.
Jang et al. aver that “malware analysis often relies on undecidable ques-
tions” [9]. Moser et al. describe several attacks against static analyzers; they
motivate this work by claiming that “[static] detection faces the challenge that
the problem of deciding whether a certain piece of code exhibits a certain be-
havior is undecidable in the general case” [10].
The MetaAware paper describes a static analysis for recognizing metamor-
phic variants of malware [11]. The authors claim that “determining whether
a program will exhibit a certain behavior is undecidable” and that the task of
checking whether a virus is a polymorphic variant of another virus is undecidable.
In the context of botnet analysis, Brumley et al. have examined “trigger-based
behavior” – code paths that are triggered by environmental conditions, such as
the occurrence of a particular date. They make similar claims: “deciding whether
a piece of code contains trigger-based behavior is undecidable” [4]. Newsome et
al. consider the problem of replaying executions, which requires searching for
inputs satisfying a program’s control ﬂow. According to them, “ﬁnding a sat-
isfying input can be reduced to deciding the halting problem” [5]. Sharif et al.
describe a system for analyzing virtualization obfuscators; they claim that “the-
oretically, precisely and completely identifying an emulators bytecode language
is undecidable” [12].
The PolyUnpack paper, by Royal et al., describes an automated unpacker
which works by comparing any executed code against the executable’s static
code model [1]. Appendix A in that paper proves that detecting unpacking be-
havior is undecidable by giving a formal reduction from the halting problem
for Turing Machines. Many later papers cite PolyUnpack for exactly this de-
cidability result [13–18]. We formally examine packed code analysis in the next
section.
We emphasize that we do not mean that the respective authors are wrong in
their claims. We cite them to support the assertion that undecidability results are
a common thread in the automated malware analysis literature, common enough
to state without proof. They are part of the community’s collective consciousness
and thus potentially inﬂuence the work we pursue.
A ray of hope. Alongside the malware analysis community some decidability
results have slipped by. A small article appeared in 2003 that proved that a
bounded variant of Cohen’s decidability question is NP-complete [19]. Subse-
quently, another paper showed that detecting whether a program P is a meta-
morphic variant of Q is NP-complete, under a certain kind of metamorphic
transformation [20]. While their assumptions are somewhat restrictive, these
proofs should give us some hope – if, under suitable restrictions, these tasks
are decidable, can we use similar restrictions to obtain decidability for other
questions?
We believe so and exhibit proofs in this paper. Our key insight is that Turing
machines are too generous – they allow programs to use potentially inﬁnite
amounts of time and space. But digital computers are not abstract; they are
limited along these most basic dimensions. We oﬀer an example for comparison.
In the cryptographic literature, standard assumptions are much more realistic
than in most of the malware analysis literature. The attacker, Eve, is allowed
probabilistic polynomial time to accomplish her nefariousness [21]. By analogy,
we might consider malware models in which the malware is allowed polynomial
time to accomplish its malicious behavior.1
1 Some malware is persistent, so we might amend this analogy to say that the malware
is allowed polynomial time to accomplish its ﬁrst malicious behavior.
3 RASP Model and Decidability Results
Proof roadmap. The following sections have a somewhat complex structure,
which we now explain.
3.1 We begin with a review of related work, including foundational models in
the theoretical malware analysis literature.
3.2 We introduce a Random Access Stored Program (RASP) machine that draws
heavily from prior work in algorithmic analysis [8, 22–24]. The RASP has the
same computational power as a Turing machine, but is more convenient for
formalizing unpacking behavior.
3.3 We introduce a novel element, the RASP interpreter. The interpreter is a
RASP program that interprets other RASP programs. It models a dynamic
analyzer and plays an important role in our reduction proofs.
3.4 We formalize the malware unpacking problem in terms of the RASP in-
terpreter. We prove that detecting unpacking is undecidable for RASPs –
complementing decidability results for Turing machines [1].
3.5 We show that if we restrict the space a RASP program is allowed, detecting
unpacking is decidable for RASPs.
3.6 We show that if we restrict the time a RASP program is allowed, detecting
unpacking is not only decidable, but NP-complete.
3.1 Related Work
The earliest decidability results for malware are found in Cohen’s classic work
on viruses [25, 26]. His work formalizes “viral sets,” pairs (M, V ) where M is
a Turing machine and for all v in V , there is a v(cid:48) in V that M can produce
when executed on v. Viral sets are clearly inspired by biological virus evolution.
Cohen proves a variety of theorems about viral sets. He proves, for instance, that
viral set detection is undecidable (Theorem 6), and that viruses are at least as
powerful as Turing machines as a means of computation (Theorem 7).
Shortly thereafter, Adleman’s work formalizes aspects of viruses and infection
using total recursive functions and G¨odel numbering [27]. He shows that the virus
problems he considers are Π2-complete. Two years later, Thimbleby et al. [28]
describe a general mathematical framework for Trojans, also using recursion
theory; they show that Trojan detection is undecidable.
Chess and White [29] give an extension of Cohen’s Theorem 6; they show that
some viruses have no error-free detectors. They draw the conclusion that it is not
possible to create a precise detector for a virus even if you reverse engineer and
completely understand it. Filiol et al. [30] give a statistical variant of Cohen’s
result using his deﬁnitions. They show that the false positive probability of a
series of statistical tests can never go to 0, and thus that one can never write a
detector without some false positives.
3.2 RASP Machine
Elgot and Robinson [22] developed the RASP out of a desire to have a model of
computation more like a real computer than is a Turing machine, but with the
same computational power. Hartmanis [23] and Cook and Reckhow [8] proved a
number of fundamental results concerning RASPs. Aho et al. [24], in an early in-
ﬂuential book on algorithms, promoted the RASP as a basic model for algorithm
analysis. Our treatment most closely follows Hartmanis [23].
The RASP is a von Neumann machine. It has an addressable memory that
stores programs and data, an instruction pointer ip that stores the address of the
current instruction, and a simple arithmetical unit – the accumulator register
ac. Our version of the RASP also has simple input/output operations.2
RASPs diﬀer from real computers in two ways: they have inﬁnitely many
memory locations M [i], where the addresses i are elements of N = {0, 1, 2, . . .},
and each M [i] stores an arbitrary integer from Z = {. . . ,−2,−1, 0, 1, 2, . . .}.
There is no ﬁxed word size. The RASP models program behavior in a natural
way, by reference to addresses and instructions. Unlike universal Turing ma-
chines, which must execute a large number of decoding instructions when they
emulate other Turing machines (particularly ones with a large tape alphabet), a
RASP interpreter emulates other RASPs in a straightforward manner (in fact,
in a manner similar to the operation of virtualization obfuscators [31]).
With RASPs it is easy to describe decidability and complexity results in
terms of asymptotic behavior as input size grows. In contrast, models of com-
putation with a ﬁxed bound on memory size become obsolete when technology
changes because memory storage grows with each successive generation of digi-
tal computers. Sometimes word size also grows. Models of computation with a
ﬁxed word size also require complicated (and usually irrelevant) multi-precision
arithmetic algorithms as input size increases. RASPs strike a balance between a
realistic model of computation and models suitable for asymptotic analysis.
In our instruction set architecture (ISA), an instruction consists of an opcode
and an operand. Opcodes are integers in the range 0 ≤ r < 16. To interpret any
integer n uniquely as an instruction, we write n = 16j + r, where r is the
opcode and j is the operand. Table 1 in Appendix A speciﬁes a simple assembly
language for the 16 RASP instructions. The opcode associated with a particular
assembly language instruction is expressed as a mnemonic (such as load, stor,
etc.) and the addressing mode – either immediate, direct, or indirect addressing
– indicated by writing the operand j without brackets (j), within single angle
brackets ((cid:104)j(cid:105)), or within double angle brackets ((cid:104)(cid:104)j(cid:105)(cid:105)), respectively. For example,
the integer 39, viewed as an instruction, is 2 · 16 + 7: its operand is 2 and its
opcode is 7. Its assembly language representation is add (cid:104)2(cid:105). Thus, this is a direct
add instruction. We consult the operational semantics column in Table 1 to see
what should happen when this instruction executes. The table tells us that we
2 The RASP model we use diﬀers from those in the works cited in one inessential
respect: program instructions take one word of memory rather than two; that is,
an instruction is a single integer. This design choice results in somewhat simpler
deﬁnitions of malware behavior.
must determine the r-value (denoted rval) of the operand. We ﬁnd this in Table 2
(in Appendix A). Since j is 2, the rvalue of (cid:104)j(cid:105) is the value M [2]. The RASP
updates ac to be the value stored in M [2] plus the value in the ac register and
then increments the value in the ip register.
The Tables in Appendix A also specify the time cost for each instruction in
terms of the function l(i) deﬁned by:
(cid:26)(cid:98)lg |i|(cid:99) + 1,
l(i) =
1,
if i (cid:54)= 0
if i = 0.
(1)
This is the approximate number of bits needed to represent i. Since the RASP
does not have a ﬁxed word size, l(i) is roughly proportional to the time required
to process i during an instruction execution.