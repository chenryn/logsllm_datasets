 10
s
e
c
r
u
o
s
f
o
r
e
b
m
u
N
 1
 0
 10  20  30  40  50  60  70  80  90  100
Top 100 BGP prefixes for sources that missed the spamtraps
Figure 6: The top 100 BGP preﬁxes for which we failed to blacklist an IP address. Almost all of the IP addresses in these preﬁxes
have previously sent spam.
legitimate sources.
3.3
Implementation
In order to detect these sources that do not hit spamtraps,
we can use the context of local network trafﬁc to determine
bad and good neighborhoods with respect to the network.
For example, consider a /24 network address range that has
75 active sources. If 50 of them are already blacklisted then
it is quite likely that the remaining 25 are also spammers
from the perspective of the network and therefore a heuris-
tic that also looks at the bad neighborhood may be able to
ﬁlter out these sources. In order to enlarge the scope of the
blacklists, we leveraged topological information available
through Border Gateway Protocol (BGP). BGP is used to
exchange routing information between autonomous systems
(AS) and helps identify organizational and logical bound-
aries.
We aggregated trafﬁc from spamtrap feeds and the live
network by BGP preﬁxes and autonomous systems. Then
we used three parameters for deciding to blacklist a network
as opposed to individual sources. First, the ratio of good to
bad e-mails for the network is below the ratio provided in
the ratio-based approach. Second the ratio of bad to active
sources in a network should be above a provided ratio. This
parameter decides when we can speculatively classify an
entire network as bad. However, we may over-aggressively
blacklist networks when we have seen very sources from
that network if we communicate very infrequently with that
network and have little insight into the network’s activities.
Therefore, the ﬁnal parameter is the ratio of the minimum
number of bad sources to total possible sources.
Having described our broad approach, we now discuss
how e-mails from live networks and spamtraps are aggre-
gated, how blacklists are generated, how they are applied,
and how entries are removed from the blacklists.
3.3.1 Aggregating Sources in a Moving Time Window
The two streams of e-mail messages, the spamtrap e-mails
(bad events) and the live network e-mails (good events), are
merged together using the e-mail’s timestamps. Sources are
extracted and fed to the blacklist generation algorithms. We
use a jumping window model to store network history. In
this model, the events are stored for a given time window
and the time window jumps periodically. For example, in
a system with a history window size of 10 hours and a pe-
riodic jump of 15 minutes, the events are kept for 10 hours
and the window jumps by 15 minutes. The counts in the last
(oldest) 15 minutes are then aged out.
Note that we do not process or annotate the network e-
mails (good events) in any way. As a result this live stream
may in fact contain spam e-mails directed at a legitimate
user. While this does not appear to have signiﬁcantly im-
pacted the accuracy of our system (see Section 4), it does
leave open the possibility that an attacker could improve the
reputation of a spam sending source by only sending spam
to legitimate users (hence avoiding our “classiﬁer”). The
use of additional “classiﬁers” (e.g., SpamAssassin) in the
reputation assignment and the corresponding error that the
may be introduced (see Section 4.5) are interesting areas for
further exploration.
3.3.2 Generating Blacklists
For the modeling of existing approaches, we count the num-
ber of bad events (i.e., spamtrap hits) for each source IP
address and send those sources that cross a given thresh-
old. For the dynamic threshold approach, we calculate the
ratio of good events to bad events and send those sources
for which the ratio is below a given ratio. The count for
each address is taken over the history window. To enlarge
blacklists from source IP address to BGP preﬁxes and au-
tonomous systems, we take into account two additional pa-
rameters. A BGP preﬁx or an autonomous system is black-
listed if all three conditions are satisﬁed—the ratio of good
events to bad events for the preﬁx is below the given ratio,
the number of bad IP addresses to active addresses is above
the minimum fraction, and the ratio of bad IP addresses to
total possible addresses is above the speciﬁed threshold.
3.3.3 Applying Blacklists
The blacklists are generated periodically and the lists are re-
freshed each time. To save on messaging, the blacklist gen-
eration technique only emits new entries or instructions to
remove old entries. These blacklists are applied to e-mails
from the live network until a new list is refreshed. In our
implementation, we maintained the blacklist as a list of IP
addresses in the open source database PostgreSql. We used
the Postgres GiST index ip4r for quickly checking whether
a source IP is blacklisted.
3.3.4 Removal from Blacklists
Finally, we need to deﬁne the policy for removing entries
from the blacklist. For existing approaches, an IP address
is not blacklisted until the network has seen enough bad
events from that IP address. When the network history for
an IP address goes lower than the threshold, the IP address
is removed from the blacklist. For the dynamic thresh-
old approach, an IP address is removed from the blacklist
when the ratio of good events to bad events goes above the
speciﬁed ratio. BGP preﬁxes and autonomous systems are
removed from the blacklist if any of the three conditions
fail—the ratio of good to bad events exceeds the speciﬁed
ratio, or if the number of bad IP addresses to active IPs from
the network falls below the provided threshold, or the ratio
of bad IP addresses to total possible addresses falls below
the threshold.
4 Evaluation
In this section, we compare the three approaches to
blacklist generation: the static threshold-based model of ex-
isting approaches, the dynamic thresholding approach, and
the speculative aggregation approach. These approaches are
compared in terms of their false positive rate and false neg-
ative rates as well as time and space performance. In addi-
tion, we compare the stability of the approaches for a variety
of chosen parameters. The comparison is accomplished by
using the deployments described in Section 2.
4.1 Comparing the Three Approaches
We now compare the simple model of existing methods
with the two approaches proposed in the paper: the dynamic
thresholding approach and the speculative aggregation ap-
proach. Recall that in the threshold-based model, an IP
address is blacklisted if it has more spamtrap hits than the
provided threshold. In the dynamic threshold approach, an
IP address is blacklisted if the ratio of the number of good
events (e-mails to the live network) to the number of bad
events (e-mails to the spamtrap) is below the speciﬁed ratio.
In the speculative aggregation approach, the IP addresses
are aggregated by BGP preﬁxes and autonomous systems.
Then BGP preﬁxes or autonomous systems are blacklisted
instead of individual IP addresses if it is found that these
networks are not of importance to one’s network. Since the
speculative approach uses a dynamic threshold technique
for blacklisting individual IP addresses, it is essentially a
combination of the dynamic threshold and speculation ap-
proaches.
Figure 7 shows the trade-off between the false negative
rate and the false positive rate for the three approaches.
First, we ﬁnd that the dynamic thresholding approach yields
a signiﬁcantly better false negative rate for any false posi-
tive rate provided by the static threshold-based model. Con-
versely, the dynamic threshold method provides a signiﬁ-
cantly better false positive rate for any false negative rate
provided by the static threshold-based model. For example,
the false negative rate for the dynamic threshold approach is
roughly 20% better than the existing model for false positive
rates below 0.5%, which is roughly three times the detection
rate of the existing model.
The speculative aggregation further improves detection
rates over the dynamic thresholding approach. The false
negative rate improvement of the speculative approach over
the existing model is between 30-40% for false positive
rates below 0.5%, which is roughly 4-5 times the detec-
tion rate of the existing model. For false positive rates
greater than 0.5%, the dynamic thresholding approach pro-
vides a slight improvement over the existing model. Over
this range, the speculative aggregation approach provides
almost double the detection rate over the existing approach.
The operational point for an approach is usually the knee
in the false negative and false positive curve. For the exist-
ing approach, the knee is at 0.67% of false positives and
71% of false negatives, and for the dynamic threshold ap-
proach, the knee is at 0.31% of false positives and at 67% of
9
8
7
!
3
0
-
6
0
5
4
3
!
!
-
2
0
1
0
/
-
,
.
!)##
!(#
!’#
!&#
!%#
!$#
!"#
!!!!!!/3-34.-3450
!#
!#*+
!#*"
!#*%
!#*’
!)
!)*+
!)*"
!)*%
,-./0!:;/43450!6-30!789
Figure 7: Trade-off curve for the false positive rate and the false negative rate for the three methods for a variety of parameter
values. The speculative aggregation approach outperforms both existing methods and dynamic thresholding approach alone.
Existing Model
Threshold
1
2
3
4
5
10
15
20
25
30
Dynamic Thresholding
Ratio
FN
65.8
100.000
65.8
75.000
65.8
50.000
25.000
65.8
65.8
10.000
65.9
5.000
66.9
1.000
0.010
74.1
76.3
0.005
0.001
76.4
FP
1.30
1.20
1.05
0.83
0.64
0.52
0.31
0.15
0.11
0.09
FN
65.9
70.9
74.6
77.3
79.6
86.8
90.7
92.6
93.7
96.9
FP
1.54
0.67
0.54
0.51
0.50
0.47
0.29
0.28
0.09
0.08
Table 3: The values of the existing static threshold-based
model and the dynamic thresholding approaches and the cor-
responding false positive and false negative rates.
false negatives. For the speculative aggregation approach,
the knee is at 0.40% of false positives and 48% of false neg-
atives.
4.2 The Effects of Existing Model and Dynamic
Thresholding Parameterization
In both the existing approach and the dynamic threshold-
ing approach, a network operator has to choose the thresh-
old or the ratio for blacklisting. Since the thresholds are
chosen by hand, we need to investigate how stable these
schemes are for any given threshold. Table 3 shows the
false positives and false negatives of the two approaches for
different values of the thresholds and the ratios. For the ex-
isting approach, the false positive rate increases suddenly
from 0.67% to 1.54% when the threshold is reduced from 2
to 1. For the dynamic thresholding approach, the increase in
false positives is more gradual. Looking at the data, we ﬁnd
that many mail servers in the network had one spamtrap hit
in the time window of 10 hours.
4.3
Impact of Parameters on Speculative Aggre-
gation
Recall that in speculative aggregation, BGP preﬁxes or
autonomous systems are blacklisted if three conditions are
satisﬁed. The ﬁrst is if the ratio of good events (mails to
the live network) to bad events (mails to the spamtraps) is
below a speciﬁed ratio. The second is if the ratio of bad
sources to total active sources is above a given threshold.
Finally, the third is if the ratio of bad sources to total size of
the BGP preﬁx or the autonomous system is above a given
threshold.
Figure 8 shows the variation in the false positive rate and
false negative rate for the speculative approach when the
above three parameters are varied. The default ratio was
kept at 0.1 and varied from 0.01 to 100. The ratio of bad IPs
to total active sources was kept at 0.4 and varied from 0.1 to
0.99. The minimum ratio of bad IPs to total possible IPs in
the network was kept at 0.01 and varied from 0.001 to 0.1.
First, we ﬁnd that the ﬁrst and third parameters have sig-
niﬁcant impact on the false positive and false negative rates
of the speculative aggregation approach. But varying the
second parameter has very limited impact on the approach.
Second, changing the minimum number of bad IP addresses
provides a much better trade-off between the false positive
rate and the false negative rate when compared to changing
the ratio of good to bad events.
)
%
(
e
t
a
R
e
v
i
t
a
g
e
N
e
s
a
F
l
 80
 75
 70
 65
 60
 55
 50
 45
variation in ratio of good to bad events
varitation in the ratio of good to bad ips
variation in min bad ips
 0
 0.2
 0.6
 0.4
 0.8
False Positive Rate (%)
 1
 1.2
Figure 8: Impact of three parameters on the false positive rate and false negative rate for speculative aggregation.
Blacklist
size
1000
10,000
100,000
1 million
Look up
time (ms)
0.045
0.046
0.050
0.052
Index
size