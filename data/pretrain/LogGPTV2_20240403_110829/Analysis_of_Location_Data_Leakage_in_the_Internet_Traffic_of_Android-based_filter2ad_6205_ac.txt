agent application, we observed that the location was sampled
only 70% of the time (see Figure 4 for the distribution of
the location sampling rate). Possible reasons for this are that
the device was off, the agent was shut down, or the location
service was disabled. Following the above observation, we
deﬁne the active time of a given user as the number of hours
at which the agent observed at least one location sample.
Validating the correctness of leaked samples. Using the
location samples observed by the agent, we validated the ge-
ographic coordinates that were detected within the network
trafﬁc. Speciﬁcally, a location that was observed in network
trafﬁc was classiﬁed as a ’true’ location only if (1) the times-
tamp of the detected coordinate was within a predeﬁned time
threshold to a location sampled by the agent application, and
(2) the measured distance between the two coordinates was
below a predeﬁned distance threshold. If just the timestamp
of the detected coordinate was close enough (within the time
threshold) to a location sampled by the agent application, we
labeled the detected coordinate as ’false’; otherwise, it was
labeled as ’unknown.’
We tested the labeling of the leaked location data when setting
the distance threshold to 250, 500, and 1000 meters and the
time threshold to 10 and 30 minutes (see Table 2). As can be
expected, when increasing the distance and/or time threshold
more leaked location coordinates are labeled as ’true.’ On the
other hand, doing so may result in incorrect labeling. There-
fore, we opted to use the most strict labeling rules in which
the distance threshold was set to 250 meters and the time
threshold to 10 minutes.
Volume of leaked location data. A total of approximately
474K geolocations (complying with the standard API location
regex) were identiﬁed within the network trafﬁc of all of the
monitored mobile devices. After applying the geo-fencing
ﬁlter, approximately 347K geolocations remained.
Time threshold
(minutes)
10
30
Distance threshold (meters)
250
89K/203K
(0.44)
129K/210K
(0.61)
500
(0.60)
(0.61)
121K/203K
157K/203K
129K/210K
165K/210K
1000
(0.77)
(0.79)
Figure 7: The classiﬁcation of geolocations detected within
the network trafﬁc after applying the latitude/longitude pair
ﬁlter and after applying both the latitude/longitude pair and
outgoing trafﬁc ﬁlters.
Figure 7 presents the classiﬁcation of geo-locations de-
tected within the network trafﬁc after applying the lati-
tude/longitude pair ﬁlter (left column) and after applying both
the latitude/longitude pair ﬁlter and the outgoing trafﬁc ﬁl-
ter (right column). Each column presents the distribution of
labels (’true,’ ’false,’ and ’unknown’) of the remaining geo-
locations according to the labeling process described above.
In total, after applying the latitude/longitude pair ﬁlter, 257K
geolocations remained; 36% of them were labeled as ’true,’
47% as ’false,’ and the rest could not be labeled. After also
applying the outgoing trafﬁc ﬁlter, 100K geo-locations re-
mained; 58% of them were labeled as ’true,’ 11% as ’false,’
and the rest could not be labeled.
These results support our hypothesis that incoming trafﬁc
is unlikely to contain relevant geolocations of the mobile
device. We can also see that after applying all three ﬁlters,
85% of the geolocations that could be labeled (either as ’true’
or ’false’) indicated the true location of the mobile device. We
can assume that the same rate also exists for the geolocations
that could not be labeled (i.e., ’unknown’).
Rate of data leakage. By analyzing the validated geo-
locations (i.e., labeled as ’true’) of the 71 users, we could see
that the mobile devices of about 90% of them were leaking lo-
cation traces. The rate of data leakage of a given user (device)
is calculated by dividing the user’s active time by the number
of validated leaked locations. We partitioned the calculated
leakage rate into the following groups: ’high,’ ’medium,’ ’low’
and ’no leakage’ as presented in Table 3. As can be seen in
Table 3, 55% of the devices were leaking location data at a
medium rate (once every one to six hours) or high (once every
one hour) rate.
5.2.1 Leakage coverage
Table 2: The results of labeling leaked location data when
setting the distance threshold to 250, 500, and 1000 meters
and the time threshold to 10 and 30 minutes.
We deﬁne an exposed hour as an hour within the collected
data (network or agent) in which at least two valid location
leaks were detected.
FALSETRUEUnknown0250005000075000100000125000Sum of waypointsLatitude/longitude pairsFALSETRUEUnknownResults summaryOutgoing traffic 250          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX AssociationIn order to analyze the coverage over time of relevant (vali-
dated) leaked location data, we deﬁne the coverage rate mea-
sure as the total number of exposed hours of network trafﬁc
divided by the total number of hours of agent data (i.e., ex-
cluding hours in which the agent was not active):
CoverageRate =
#o f ExposedTra f f icHours
#o f AgentDataHours
We assume that a high coverage rate will result in high expo-
sure and discovery rates of users’ important places. Figure 8
presents the distribution of the coverage rates of the mobile
devices in the collected dataset. As can be seen, for almost
70% of the users the coverage rate is below 0.2.
5.2.2 Leakage inconsistency.
While Table 3 and Figure 8 present the overall average
leakage rate of location data, our manual exploration of the
data showed that the leaked data exhibits inconsistent, non-
uniform, and bursty behavior. As an example, Figure 9 depicts
the number of location samples per hour of a single user ob-
served by the agent application (blue line) and within the
network trafﬁc (black line). It can be seen that while the
agent’s sample rate is relatively stable (around 12 samples
per hour) excluding minor changes (such as phone shutdown
or agent crash), the leaked location data within the network
trafﬁc is unstable, ranging from only a few or no leaks to a
high rate of leakage.
Thus, in order to analyze and understand the inconsistency
in the amount of leaked location data, we computed the rel-
ative standard deviation measure for each mobile device by
dividing the standard deviation of ’leaks per hour’ by the
average number of ’leaks per hour.’
Figure 10 depicts the distribution of the values of the rela-
tive standard deviation measure of the mobile devices; a value
of zero (0) indicates a constant leakage rate.
We were also interested in understanding the distribution
of location leakage data during the day. As can be seen in
Figure 11, the leakage rate during different hours of the day
is correlated with the participants’ normal activity during the
day (e.g., sleeping at night, attending classes, and taking a
lunch break).
Group
High
Medium
Low
No leakage
Leakage rate
Number of devices
Percentage
under 1hr
1-6hrs
6+ hrs
∞
20
19
23
9
28%
27%
32%
13%
Table 3: The leakage rate of different mobile devices. As can
be seen, 55% of the devices were leaking location data at a
medium rate (once every one to six hours) or high (once every
one hour) rate.
Figure 8: The distribution of the coverage rate measure. The
coverage rate measure is deﬁned as the total number of ex-
posed hours of network trafﬁc (i.e., hours in which location
leakage was observed) divided by the total number of hours
of agent application data.
Figure 9: An example of a single user location leakage rate
observed by the agent installed on the device (blue line) and
within the network trafﬁc (black line).
6 Inferring POIs
Traces
from Leaked Location
We are also interested in understanding how an attacker can
infer meaningful insights from the geolocations (coordinates)
that were detected as leaks within the mobile device’s network
trafﬁc. Speciﬁcally, we are interested in identifying a user’s
POIs and differentiating them from transit or noise data [40].
The most common approach for identifying stay points (or
POIs) is by applying clustering algorithms that are not usually
bound to a predetermined number of clusters (e.g., k-means)
and clustering stay points by spatial or spatio-temporal pa-
rameters. In this research we opted to use three different
algorithms: incremental clustering [6], DBSCAN [7], and
ST-DBSCAN [31]. These algorithms usually make some as-
sumptions about the data. Speciﬁcally, it is assumed that the
data arrives at a constant rate, which is not correct in our case.
Therefore, we made several modiﬁcations to the algorithms.
First, for the incremental algorithm, we added the notion
of time by calculating the time between samples and deﬁned
a bound on that time interval. The pseudo-code of the modi-
ﬁed incremental algorithm is presented in Algorithm 1 (see
Cluster procedure). As can be seen, the procedure receive
three inputs: the distance threshold (denoted by D), the time
threshold (denoted by T ), and a list of location samples sorted
by their timestamps (denoted by W P). The distance threshold
speciﬁes the maximal distance (in meters) between the center
00.30.60.91.2Coverage rate00.10.20.30.4Percentage0200400600Timeline (hours)051015Location samplessourceAgentTrafficUSENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 251if distance(cluster.center,wp.location)  T then
clusterList.add(cluster)
cluster ← /0
cluster.add(wp)
if distance(cluster1.center,cluster2.center) < D then
end if
end for
return(clusterList)
end if
end if
end if
end for
return(clusterList)
else
else
for cluster1,cluster2 ∈ W P do
cluster1.merge(cluster2)
clusterList.remove(cluster2)
Note that we did not have any information about the users’
real (conﬁrmed) POIs in order to understand the nature and
validity of the POIs identiﬁed in the network trafﬁc’s leaked
locations. Therefore, as a benchmark (and ground truth) we
used the POIs identiﬁed by applying the incremental cluster-
ing algorithm on the Android agent location data (denoted
as Incremental-agent). Because the location traces collected
by the mobile agent application indicate the true location of
the user with a high degree of accuracy, and POIs clustering
methods have been shown to be effective in previous work,
we found this benchmark sufﬁcient for our purposes.
In Table 4, we present the number of clusters (POIs) de-
tected by the incremental algorithm for different distance and
time threshold values. As can be seen, reducing the distance
and time thresholds resulted in a large number of clusters, and
increasing them resulted in fewer clusters. Nevertheless, it
can be seen that the detection rates are not affected by the
different parameters. For the rest of the evaluation we set the
thresholds for the algorithms at 500 meters and 30 minutes.
The POIs identiﬁed by applying the different clustering
algorithms on the network trafﬁc’s leaked locations (denoted
as Incremental-trafﬁc, DBSCAN-trafﬁc, and STDBSCAN-
trafﬁc) were compared with the agent-based POIs, namely
the Incremental-agent. We calculated the total amount of time
spent at each user POI and assigned a weight representing the
Figure 10: The leakage rate variability as indicated by the
leak relative standard deviation measure.
Figure 11: Location leakage rate (in percentage) within dif-
ferent time (hour) of day.
of a cluster to a given location sample. If this distance is less
than the distance threshold, the location sample is added to
the cluster (lines 13-17); otherwise it is considered an instance
of a different cluster, or as a transition state. The time thresh-
old speciﬁes the minimal time for a list of way points to be
considered as a cluster. If this time is greater than the time
threshold, the list of way points is considered a cluster (lines
18-21); otherwise, it is not considered as cluster.
Second, for both the incremental and ST-DBSCAN algo-
rithms we applied a backtracking procedure, which iterates
over the created clusters and merges clusters that are within
the distance threshold (lines 28-36). The main beneﬁt of the
backtracking procedure is to increase the conﬁdence for re-
peated clusters over time.
Another approach uses semantic data to determine when a
user is at an important place; for example, a location trace at a
famous landmark will identify it as an important place for that
user [33]. This approach is not relevant in our case, because
the POIs are not known in advance; however, we use semantic
data from reverse geocoding to eliminate transit geolocations
(e.g., highways).
One of the main challenges when applying clustering algo-
rithms in fully unsupervised data is selecting the parameters
correctly (namely, the distance and time threshold), since their
values directly affect the number and size of clusters detected
by the algorithm. In order to address this challenge we tested
several time threshold values (15, 30, and 60 minutes) and
distance threshold values (100, 250, and 500 meters).
0123Location leak (RSTD)00.040.080.12Percentage0510152025Time of day00.010.020.03Location leakage252          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX Association15
30
60
Time
threshold
(minutes)
Distance threshold (meters)
100
500
250
238/996
(0.24)
218/847
(0.26)
183/718
(0.25)
184/724
(0.25)
171/627
(0.27)
150/532
(0.28)
(0.26)
317/1162
371/1402
(0.27)
228/906
(0.25)
Table 4: The number of clusters (i.e., POIs) detected by the
incremental algorithm when selecting different distance and
time thresholds.