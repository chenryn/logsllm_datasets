compute this using the simpy package in Python. All
data points are averaged over 50 simulations.
Figure 5 depicts the change of entropy against an in-
creasing rate of incoming mix trafﬁc λ . We simulate the
Figure 5: Entropy versus the changing rate of the incoming
trafﬁc for different delays with mean 1
µ . In order to measure
the entropy we run a simulation of trafﬁc arriving at a single
Loopix mix node.
dependency between entropy and trafﬁc rate for differ-
ent mix delay parameter µ by recording the trafﬁc ﬂow
and changing state of the mix node’s pool. As expected,
we observe that for a ﬁxed delay, the entropy increases
when the rate of trafﬁc increases. Higher delay also re-
sults in an increase in entropy, denoting a larger potential
anonymity set, since more messages are mixed together.
In case the mix node emits loop cover trafﬁc, the ad-
versary with observation on,k,l, tries to estimate the prob-
ability that the observed outgoing message is a particular
target message she observed coming into the mix node.
An outgoing message can be either input message or a
loop message generated by the mix node – resulting in
additional uncertainty for the adversary.
Theorem 2. Let m1 be any of the initial n messages in
the mix node in scenario on,k,l, and let m2 be any of the
l messages that arrive later. Let λM denote the rate at
which mix node generates loop cover trafﬁc. Then,
·
k
n
Pr(m = m1) =
Pr(m = m2) =
µ
(l + k)µ + λM
,
µ
(l + k)µ + λM
.
We refer to Appendix A for the proof. We conclude
that the loops generated by the mix node obfuscate the
adversary’s view and decrease the probability of success-
fully linking input and output of the mix node. In Sec-
tion 4.2 we show that those types of loops also protect
against active attacks.
4.2 Active-attack Resistance
Lemma 1 gives the direct relationship between the ex-
pected number of messages in a mix node, the rate of in-
coming trafﬁc, and the delay induced on a message while
transiting through a mix. By increasing the rate of cover
trafﬁc, λD and λL, users can collectively maintain strong
USENIX Association
26th USENIX Security Symposium    1207
anonymity with low message delay. However, once the
volume of real communication trafﬁc λP increases, users
can tune down the rate of cover trafﬁc in comparison
to the real trafﬁc, while maintaining a small delay and
be conﬁdent their messages are mixed with a sufﬁcient
number of messages.
In the previous section, we analyze the security prop-
erties of Loopix when the adversary observes the state
of a single mix node and the trafﬁc ﬂowing through it.
We show, that the adversary’s advantage is bounded due
to the indistinguishability of messages and the memory-
less property of the Poisson mixing strategy. We now in-
vestigate how Loopix can protect users’ communications
against active adversaries conducting the (n− 1) attack.
4.2.1 Active attacks
We consider an attack at a mix node where an adversary
blocks all but a target message from entering in order
to follow the target message when it exits the mix node.
This is referred to as an (n-1) attack [41].
A mix node needs to distinguish between an active at-
tack and loop messages dropped due to congestion. We
assume that each mix node chooses some public param-
eter r, which is a fraction of the number of loops that
are expected to return. If the mix node does not see this
fraction of loops returning they alter their behavior. In
extremis such a mix could refuse to emit any messages
– but this would escalate this attack to full denial-of-
service. A gentler approach involves generating more
cover trafﬁc on outgoing links [17].
To attempt an (n-1) attack, the adversary could simply
block all incoming messages to the mix node except for a
target message. The Loopix mix node can notice that the
self-loops are not returning and deduce it is under attack.
Therefore, an adversary that wants to perform a stealthy
attack has to be judicious when blocking messages, to
ensure that a fraction r of loops return to the mix node,
i.e. the adversary must distinguish loop cover trafﬁc from
other types of trafﬁc. However, trafﬁc generated by mix
loops is indistinguishable from other network trafﬁc and
they cannot do this better than by chance. Therefore
s ,s ∈ R>1 of expected returning
given a threshold r = λM
loops when a mix observes fewer returning it deploys ap-
propriate countermeasures.
s
s = λR+λM
We analyze this strategy: since the adversary cannot
distinguish loops from other trafﬁc the adversary can do
no better than block trafﬁc uniformly such that a fraction
R = λ
enter the mix, where λR is the rate of
incoming trafﬁc that is not the mix node’s loops. If we
assume a steady state, the target message can expect to
be mixed with λR
s·µ messages that entered this mix, and
λM
µ loop messages generated at the mix node. Thus, the
probability of correctly blocking a sufﬁcient number of
messages entering the mix node so as not to alter the be-
havior of the mix is:
Pr(x = target) =
1
λR/s· µ + λM/µ =
sµ
sλM + λR
Due to the stratiﬁed topology, providers are able to dis-
tinguish mix loop messages sent from other trafﬁc, since
they are unique in not being routed to or from a client.
This is not a substantial attack vector since mix loop
messages are evenly distributed among all providers, of
which a small fraction are corrupt and providers do not
learn which mix node sent the loop to target it.
4.3 End-to-End Anonymity Evaluation
We evaluate the sender-receiver third-party unlinkability
of the full Loopix system through an empirical analysis
of the propagation of messages in the network. Our key
metric is the expected difference in likelihood that a mes-
sage leaving the last mix node is sent from one sender
in comparison to another sender. Given two probabilities
p0 = Pr[S0] and p1 = Pr[S1] that the message was sent by
senders S0 and S1, respectively, we calculate
ε = |log (p0/p1)|.
(3)
To approximate the probabilities p0 and p1, we pro-
ceed as follows. We simulate U = 100 senders that gen-
erate and send messages (both payload and cover mes-
sages) with a rate λ = 2. Among them are two challenge
senders S0 and S1 that send payload messages at a con-
stant rate, i.e, they add one messages to their sending
buffer every time unit.
Whenever a challenge sender S0 or S1 sends a payload
message from its buffer, we tag the message with a la-
bel S0 or S1, respectively. All other messages, including
messages from the remaining 98 clients and the cover
messages of S0 and S1 are unlabeled. At every mix we
track the probability that an outgoing message is labeled
S0 or S1, depending on the messages that entered the mix
node and the number of messages that already left the
mix node, as in Theorem 1. Thus, messages leaving a
mix node carry a probability distribution over labels S0,
S1, or ‘unlabeled’. Corrupt mix nodes, assign to outgoing
messages their input distributions. The probabilities nat-
urally add up to 1. For example, a message leaving a mix
can be labeled as {S0 : 12%,S1 : 15%,unlabeled : 73%}.
In a burn-in phase of 2500 time units, the 98 senders
without S0 or S1 communicate. Then we start the two
challenge senders and then simulate the network for an-
other 100 time units, before we compute the expected
difference in likelihood metric. We pick a ﬁnal mix node
and using probabilities of labels S0 and S1 for any mes-
sage in the pool we calculate ε as in Equation (3).
1208    26th USENIX Security Symposium
USENIX Association
Figure 6: Likelihood difference ε depending on the delay pa-
rameter µ of mix nodes. We use λ = 2, a topology of 3 layers
with 3 nodes per layer and no corruption.
Figure 7: Likelihood difference ε depending on the number of
layers of mix nodes with 3 mix nodes per layer. We use λ = 2,
µ = 1, and no corruption.
This is a conservative approximation: we tell the ad-
versary which of the messages leaving senders S0 and S1
are payload messages; and we do not consider mix or
client loop messages confusing them. 4 However, when
we calculate our anonymity metric at a mix node we as-
sume this mix node to be honest.
4.3.1 Results
We compare our metric for different parameters: depend-
ing on the delay parameter µ, the number of layers in
our topology l and the percentage of corrupt mix nodes
in the network. All simulations are averaged over 100
repetitions and the error bars are the standard deviation.
Delay.
Increasing the average delay (by decreasing pa-
rameter µ) with respect to the rate of message sending
λ immediately increases anonymity (decreases ε) (Fig-
ure 6). For µ = 2.0 and λ /µ = 1, Loopix still provides a
weak form of anonymity. As this fraction increases, the
log likelihood ratio grow closer and closer to zero. We
consider values λ /µ ≥ 2 to be a good choice in terms of
anonymity.
Number of layers. By increasing the number of layers
of mix nodes, we can further strengthen the anonymity of
Loopix users. As expected, using only one or two layers
of mix nodes leads to high values of adversary advantage
ε. For a increasing number of layers, ε approaches zero
(Figure 7). We consider a number of 3 or more layers
to be a good choice. We believe the bump between 5–8
layers is due to messages not reaching latter layers within
100 time units. Results from experiments with increased
duration do not display such a bump.
4The soundness of our simpliﬁcation can be seen by the fact that we
could tell the adversary which messages are loops and the adversary
could thus ignore them. This is equivalent to removing them, as an
adversary could also simulate loop messages.
Figure 8: Likelihood difference ε depending on the percentage
of (passively) corrupted mix nodes. We use λ = 2, µ = 1 and
a topology of 3 layers with 3 nodes per layer.
Corruption. Finally, we analyze the impact that cor-
rupt mix nodes have on the adversary advantage ε (Fig-
ure 8). We assume that the adversary randomly corrupts
mix nodes. Naturally, the advantage ε increases with the
percentage of corrupt mix nodes in the network.
In a
real-world deployment we do not expect a large fraction
of mix nodes to be corrupt. While the adversary may
be able to observe the entire network, to control a large
number of nodes would be more costly.
5 Performance Evaluation
Implementation. We implement the Loopix system
prototype in 4000 lines of Python 2.7 code for mix
nodes, providers and clients, including unit-tests, de-
ployment, and orchestration code. Loopix source code
is available under an open-source license5. We use the
Twisted 15.5.0 network library for networking; as well
as the Sphinx mix packet format6 and the cryptographic
tools from the petlib7 library. We modify Sphinx to
use NIST/SEGS-p224 curves and to accommodate addi-
tional information inside the packet, including the delay
5https://github.com/UCL-InfoSec/loopix
6http://sphinxmix.readthedocs.io/en/latest/
7http://petlib.readthedocs.org
USENIX Association
26th USENIX Security Symposium    1209
for each hop and auxiliary ﬂags. We also optimize the
Sphinx implementation leading to processing times per
packet of less than 1ms.
The most computationally expensive part of Loopix
is messages processing and packaging, which involves
cryptographic operations. Thus, we implement Loopix
as a multi-thread system, with cryptographic processing
happening in a thread pool separated from the rest of the
operations in the main thread loop. To recover from con-
gestion we implement active queue management based
on a PID controller and we drop messages when the size
of the queue reaches a (high) threshold.
Experimental Setup. We present an experimental per-
formance evaluation of the Loopix system running on
the AWS EC2 platform. All mix nodes and providers
run as separate instances. Mix nodes are deployed on
m4.4xlarge instances running EC2 Linux on 2.3GHz
machines with 64GB RAM memory. Providers, since
they handle more trafﬁc, storage and operations, are de-
ployed on m4.16xlarge instances with 256GB RAM.
We select large instances to ensure that the providers
are not the bottleneck of the bandwidth transfer, even
when users send messages at a high rate. This reﬂects
real-world deployments where providers are expected to
be well-resourced. We also run one m4.16xlarge in-
stance supporting 500 clients. We only show results for
500 clients, due to limitations of our experimental hard-
ware setup such as ports and memory. A real world de-
ployment of Loopix would scale to a larger client base.
We believe that our empirical analysis is a more accu-
rate assessment of real-world performance than those re-
ported by other works, e.g. [45, 46], which depend on
simplish extrapolation. In order to measure the system
performance, we run six mix nodes, arranged in a strat-
iﬁed topology with three layers, each layer composed
of two mix nodes. Additionally, we run four providers,
each serving approximately 125 clients. The delays of
all the messages are drawn from an exponential distri-
bution with parameter µ, which is the same for all mix
servers in the network. All measurements are taken from
network trafﬁc dumps using tcpdump.
Bandwidth. First, we evaluate the increase of band-
width of mix nodes by measuring the rate at which a
single mix node processes messages, for an increasing
overall rate at which users send messages.
We set up the ﬁxed delay parameter µ = 1000 (s.t.
the average delay is 1ms). We have 500 clients ac-
tively sending messages at rate λ each, which is the
sum of payload, loop and drop rates, i.e., Pois(λ ) =
Pois(λL + λD + λP). We start our simulation with pa-
rameters λL = λD = 1 and λP = 3 messages per minute
for a single client. Mix nodes send loop cover trafﬁc at
Figure 9: Overall bandwidth and good throughput per second
for a single mix node.
rate starting from λM = 1. Next, we periodically increase
each Poisson rate by another 2 messages per minute.
Each packet sent through the network has a size of a few
kilobytes only, but this size is a parameter that can, of
course, be increased to ﬁt the needs of a particular appli-
cation.
In order to measure the overall bandwidth, i.e. the
number of all messages processed by a single mix node,
we use the network packet analyzer tcpdump. Since
real and cover message packets are indistinguishable, we
measure the good throughput by encapsulating an addi-
tional, temporary, typeFlag in the packet header for this
evaluation, which leaks to the mix the message type—
real or cover—and is recorded. Knowing the parameters
λP, λL, and λD the adversary can try to estimate how
many messages on average in the outgoing stream are
real, loop or drop messages. However, the average es-
timation does not give the adversary any signiﬁcant in-
formation, since the outgoing trafﬁc may contain various
numbers of each type of message which an adversary is
not able to distinguish between.
Figure 9 illustrates the number of total messages and