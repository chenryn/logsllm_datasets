the card. Screen detection detects when a user scans a card
from a screen instead of using a physical card. Card tampering
detection ﬁnds prominent objects on the card, like the bank
logo, and correlates this information with the OCR prediction
to conﬁrm that these objects are consistent with the type of
card that they expect. For instance, if OCR detects a BIN (ﬁrst
six digits of the card number) of a Chase Visa payment card
but the card tampering detection detects a Bank of America
logo or Mastercard logo, Boxer ﬂags this scan as fraudulent.
However, Boxer falls short in the following ways: First,
OCR, as their ﬁrst line of defense, stops the vast majority of
fraudsters as per their evaluation. However, as we describe
in our measurement study (Section III), Boxer’s OCR under
performs on low-end devices. Second, Boxer’s fraud checks
only scan the number side of the card. However, newer card
designs in the wild contain visual design elements on either
side of the card, so by scanning only the number side of the
card Boxer misses out on key information. Third, Boxer only
ﬂags cards scanned off screens and not other fake media.
In the remainder of the paper, we ﬁrst describe our measure-
ment study of Boxer (Section III). We then describe the design
of Daredevil, a new credit card scanning and veriﬁcation
system to improve upon Boxer (Sections IV, V). This is
followed by a detailed evaluation of Daredevil (Section VI).
III. MEASUREMENT STUDY
In this section, we present the ﬁrst large-scale measurement
study of a security challenge using deep learning on mobile
devices. We study the practical characteristics and limitations
of credit card scanning using real apps running on end-user
devices with real people and credit cards, and all the idiosyn-
crasies inherent in large-scale software with live deployments.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:14:08 UTC from IEEE Xplore.  Restrictions apply. 
1624
We believe this study is the ﬁrst of its kind and has
implications for deep learning engineers, app developers, and
hardware vendors. The closest to our study in terms of scale
is presented by Ignatov et. al [24], however, their study is
limited to only 10,000 Android devices and runs pre-deﬁned
images through pre-trained models loaded on each device to
benchmark the hardware.
image processing, ambient
Ours is an in-ﬁeld correlation study and represents a realistic
usage scenario for end-users since we benchmark the usage of
a deep learning driven application where the user, the phone
sensor,
lighting, device surface
temperature, the compute capability of the device and other
production variables determine the performance of the system.
In our study, we protect end-user privacy by limiting the
amount and nature of the statistics that we record, the metrics
have enough ﬁdelity that they inform our end-to-end design
(Section V), resulting in signiﬁcant improvements in the wild
(Section VI).
Our university’s IRB board reviewed our study and ruled it
to be exempt from IRB.
A. Measurement study goals and questions
Our high-level goal
is to understand the practical per-
formance and limitations of camera-based mobile security
challenges in real-world conditions. We perform our study
using Boxer, a widely deployed credit card scanning system
and measure its success rate as the primary metric for success.
To understand the performance and limitations, we focus our
correlation study on three primary questions.
How does the speed of ML predictions inﬂuence end-to-end
metrics for success? The research community and industry
have put a heavy emphasis on performance for ML predictions
through machine learning models designed speciﬁcally for
mobile devices [21], [23], [45], [20] and hardware support
for fast inference [3], [16]. We measure the impact of these
efforts on high-level metrics for success.
How widely do the ML capabilities on modern phones vary
in the ﬁeld? We measure the range of ML capabilities one
is likely to see in practice. By understanding the range of
capabilities, one can anticipate the performance differences for
security challenges in realistic settings. Also, we quantify the
number of devices that are unable to run Boxer ML effectively,
which for a security check blocks the user.
How long are people willing to wait when they try to
scan documents with their phone? As there are many forms
of scanning documents that apps use for security checks,
understanding how long people are willing to wait as they
try to scan informs the overall design of a security check.
Security check designers will know how long they have to
capture relevant information before someone gives up.
B. Measurement Platform
To measure Boxer’s performance, we instrumented Boxer’s
open-source SDK and made it available to third-party app
developers. We then measured the success rate for the users
of their live production apps. We present results from anony-
mous statistics sent by 496 apps that deployed and ran the
instrumented library from July 2019 to late November 2020.
C. Testbed
Our instrumented Android SDK ran on a total of 329,272
Android devices spanning a total of 611 Android device
types. This included 168,658 Samsung devices spanning 281
Samsung device types, 49,329 Huawei devices spanning 91
Huawei device types, 80,351 Xiaomi devices spanning 64
Xiaomi device types, 5,464 LG devices spanning 63 LG device
types, 2,939 Google devices spanning 11 Google device types,
2,501 Motorola devices spanning 27 Motorola device types,
2,560 OnePlus devices spanning 18 OnePlus device types
and tail of 17,470 devices, spanning 56 device types and
23 vendors. Our instrumented iOS SDK ran on a total of
3,175,912 iOS devices spanning a total of 27 iOS device types.
D. Task
Our instrumented SDK prompts users to scan their credit
cards. When invoked, it starts the camera and prompts users
to place their card in the center of the viewport. The OCR
processes the frames obtained from the camera and attempts
to extract the card number and the expiry from the card.
Upon success, the card number and the expiry are displayed to
the user and the SDK sends the scan statistics to our server.
In case, the OCR is unable to extract the number, the ﬂow
doesn’t time-out, instead we let the user cancel the scan which
provides us an additional user-level metric that can guide a
new design.
Boxer uses a two-stage OCR similar to Deep Text Spot-
ter [8], consisting of a detection phase to detect groups of
digits in credit card images and a recognition phase to extract
individual digits from these groups.
Both models use a modiﬁed version of MobileNet [21],
where the detection model occupies 1.75MB and the recogni-
tion model occupies 1.19MB on disk.
The detection model processes an input
image of size
480x302x3 and generates a total of 1,734 proposals. It has
a total of 910,379 parameters of which 901,379 are trainable.
There are 16 2D convolution blocks and 10 Depthwise convo-
lution blocks, each followed by a batch-norm and an activation
layer.
The recognition model processes input
images of size
36x80x3, each corresponding to the proposal generated by the
detection model and generates a feature map of 17x11 for
each proposal. It has a total of 618,540 parameters of which
611,754 are trainable. There are 14 2D convolution blocks and
8 Depthwise convolution blocks, each followed by a batch-
norm and an activation layer.
For inference,
the iOS SDK uses the vendor speciﬁc
CoreML which runs the models on the CPU, the GPU and
the Neural engine depending upon the availability and usage
at any time. The Android SDK uses a generic interpreter
TFlite, where the inference primarily runs on the CPU. Boxer’s
models are quantized using 16-bit ﬂoating point weights.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:14:08 UTC from IEEE Xplore.  Restrictions apply. 
1625
Platform
Count
Avg Success
Avg
Duration (s)
Rate
46.72%
88.60%
Avg
FPS
1.303
10.00
329,272
3,175,912
Android
iOS
Fig. 3: Aggregate results of Boxer on Android and iOS.
14.45
10.02
Platform
Count
Android
iOS
175,435
361,924
Avg
Avg
FPS Duration (s)
1.00
9.28
16.20
20.73
Fig. 4: Failure cases of Boxer on Android and iOS.
Fig. 1: Boxer OCR success rate vs frame rate on Android and
iOS. Each point is the average success rate and frame rate
for a speciﬁc device type. This ﬁgure shows that when using
the same machine learning model, end-to-end success rates
drop off as the frame rate declines. We also see the same
model and system architecture exhibit different performance
characteristics on Android and iOS.
Android FPS
= 2 FPS
Count
Success rate
146,890 (44.61%)
97,798 (29.70%)
84,584 (25.68%)
31.87%
49.97%
68.72%
Fig. 2: Success rates for Android devices running Boxer by
the frame rate. We see that a signiﬁcant portion of devices
operate at frame rates less than 1 FPS.
E. Results
1) Key Performance Metrics: Success rate: We deﬁne
success rate as the ratio of the number of users where the
scanner successfully extracted the card number to the total
number of users using the scanner.
Frame rate: We deﬁne the frame rate as the number
of frames from the camera processed by the OCR pipeline
(detection and recognition) per second.
Figure 1 shows the variation in success rate against the
frame rate for different devices. We omit iPhone 6 and below
devices from our deployment since Boxer does not support
them.
Data from Figure 1 and Figure 2 suggests:
• Both the frame rate and the success rate are higher on iOS
than on Android when using the same machine learning
models and same system architecture.
• Boxer is ineffective on Android devices when the frame
rate is less than 1 FPS. These devices make up 44.61% of
the Android devices in our study and achieve a success
rate of 31.87% compared to 49.97% for devices that run
at 1-2 FPS and 68.72% for devices that run at 2 FPS or
higher.
Figure 3 shows aggregate results for iOS and Android.
While the success rate for iOS is 88.60%, the success rate
for Android is much lower at 46.72%.
2) Further analysis of failure cases: We measure how long
users are willing to wait to scan their cards by measuring how
long people scan for when they are unsuccessful in scanning
their card. Measuring the time that people are willing to wait
while scanning informs our decisions when designing the
system and trading off scan times vs accuracy and fraud signal
ﬁdelity.
From our real-world deployment of 3,505,184 scans, we
observed 537,359 failed attempts where users gave up on
trying to scan their card. We aggregate the duration of these
scans on iOS and Android to report that Android users waited
an average of 16.20s and iOS users waited an average of
20.73s to scan their cards before giving up (Figure 4).
F. Context for the results
For its fraud challenge, Boxer uses OCR to verify the card
number that the app has on record for any user. Thus, anyone
who is unable to scan their number will be unable to pass
the fraud challenge. Additionally, OCR is the ﬁrst model in
the Boxer pipeline and is used to extract data like the ﬁrst
six digits (BIN), which is then correlated with other features
like the credit card design to determine fraud. However, if the
ﬁrst model in the pipeline fails to run, the device is implicitly
denied the service.
Boxer solves the business problem that its designers in-
tended to solve, since it runs OCR successfully on 84.7% of
the devices overall. However, the success rate on devices that
run at a rate of less than 1 FPS is mere 31.87%, and these
devices make up 44.61% of the Android devices we measure,
introducing a potential ethical conundrum by blocking users
solely because they have an inexpensive device.
IV. OVERVIEW
In this paper, we introduce Daredevil, a new system that we
design and implement to realize ethical deep learning powered
user-centric security challenges, with the goal of providing
equal access to all users. Although we built Daredevil to
prevent card-not-present credit card fraud, the insights gained
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:14:08 UTC from IEEE Xplore.  Restrictions apply. 
1626
Frame Rate (Frames Per Second)Success rate(%)025507510005101520androidiosFig. 5: Daredevil scanning one side of a card from a user’s perspective.
from Daredevil can also be applied to design other end-user
security challenges.
To provide equal access, Daredevil must be fast, even on
resource-constrained devices that lack hardware acceleration
for machine learning, Daredevil must respect end user privacy,
and Daredevil must be accurate to avoid incorrectly ﬂagging
otherwise good users as being fraudulent.
Our work on Daredevil builds off recent work from Din
et al. [9] that shows how to scan the number side of a card
and verify that it is genuine using a system called Boxer, as
described in Section II.
We demonstrate the design of an ethical fraud challenge by
improving Boxer in the following ways:
Our machine learning models run client side, where Dare-
devil processes credit card images on the device before passing
a distilled summary of the machine learning output to our
server, where we make the ultimate decision about if a scan
is genuine. As our models run client side, we are susceptible
to attackers who tamper with the app, the video stream, or
our machine learning models. Although we do have some
measures in place to assess the integrity of our client-side soft-
ware (e.g., DeviceCheck on iOS and SafetyNet on Android),
we recognize that this type of assurance is still an ongoing
arms race between app builders, device manufacturers, and
attackers. Our design favors end-user privacy even though it
does open us up to client-side attacks.
• We design a new fast and efﬁcient OCR that also runs
well on resource-constrained devices.
• We propose a machine learning pipeline that combines
the different models to provide efﬁciency and redundancy.
• We introduce a new card detection model that operates in