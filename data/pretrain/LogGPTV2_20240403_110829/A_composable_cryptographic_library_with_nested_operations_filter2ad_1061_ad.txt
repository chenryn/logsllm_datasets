Then the second component of the (tagged) public-key word is the
actual public key pk , while the message l is used as it is. Further, a
fresh random value r is generated for additional randomization as
explained in Section 1.3.
Recall that r has to be included both inside the encryption and in
∗
the ﬁnal tagged ciphertext c
.
• Encryption: chnd ← encrypt(pkhnd, lhnd).
Parse pkhnd and lhnd.
(cid:20)= list,
Du[lhnd].type
Else set pk
Du[pkhnd].word [2],
l
{0, 1}nonce len(k), encrypt c ← Epk ((r, l)), and set c
(enc, pk , c, r). If c
else set chnd := curhndu ++ and Du :⇐ (chnd, c
∗
(cid:20)= pke or
:=
r ←R
∗ :=
∗| > max len(k) then return ↓,
, enc, ()).
If Du[pkhnd].type
return ↓.
:= Du[lhnd].word ,
∗ = ↓ or |c
Parsing a ciphertext veriﬁes that the components and lengths are
above, and outputs the corresponding tagged public key,
∗
as in c
whereas the message is only retrieved by a decryption command.
4.3.2 Send Commands and Network Inputs
network ports. We show this for an insecure channel.
Send commands simply output real messages at the appropriate
• send i(v, lhnd) for v ∈ {1, . . . , n}.
Parse lhnd if necessary.
Du[lhnd].word at port netu,v,i!.
If Du[lhnd].type = list, output
Upon receiving a bitstring l at a network port netw ,u,x ?, machine
Mu parses it and veriﬁes that it is a list. If yes, and if l is new, Mu
stores it in Du using a new handle lhnd, else it retrieves the existing
handle lhnd. Then it outputs (w, x, lhnd) at port outu!.
5. SECURITY PROOF
The security claim is that the real cryptographic library is as se-
cure as the ideal cryptographic library, so that protocols proved on
the basis of the deterministic, Dolev-Yao-like ideal library can be
safely implemented with the real cryptographic library. To formu-
cry,id
late the theorem, we need additional notation: Let Sys
n,L denote
the ideal cryptographic library for n participants and with length
cry,real
n,S,E,L(cid:1) the real cryptographic
functions and bounds L, and Sys
library for n participants, based on a secure signature scheme S
and a secure encryption scheme E, and with length functions and
(cid:2)
. Let RPar be the set of valid parameter tuples for the
bounds L
real system, consisting of the number n ∈ N of participants, secure
signature and encryption schemes S and E, and length functions
(cid:2)
cry,real
and bounds L
n,S,E,L(cid:1) be the
resulting real cryptographic library. Further, let the corresponding
length functions and bounds of the ideal system be formalized by a
function L := R2Ipar(S,E , L
cry,id
n,L be the ideal cryp-
tographic library with parameters n and L. Using the notation of
Deﬁnition 2, we then have
rameters (n,S,E , L
THEOREM 1. (Security of Cryptographic Library) For all pa-
(cid:2)) ∈ RPar, let Sys
. For (n,S,E , L
(cid:2)), and let Sys
(cid:2)) ∈ RPar, we have
n,S,E,L(cid:1) ≥ Sys
Sys
cry,real
cry,id
n,L ,
where L := R2Ipar(S,E , L
(cid:2)).
For proving this theorem, we deﬁne a simulator SimH such that
even the combination of arbitrary polynomial-time users H and an
arbitrary polynomial-time adversary A cannot distinguish the com-
bination of the real machines Mu from the combination TH(H)
and SimH (for all sets H indicating the correct machines). We ﬁrst
sketch the simulator and then the proof of correct simulation.
5.1 Simulator
Basically SimH has to translate real messages from the real ad-
versary A into handles as TH(H) expects them at its adversary
input port ina? and vice versa; see Figure 3.
In both directions,
SimH has to parse an incoming messages completely because it
can only construct the other version (abstract or real) bottom-up.
This is done by recursive algorithms. In some cases, the simulator
cannot produce any corresponding message. We collect these cases
in so-called error sets and show later that they cannot occur at all
or only with negligible probability.
H
SH
inu outu
THH
D
• • •
• Basic cmds
• Adv cmds
• Send cmds
ina
outa
• Results of cmds
• Received msgs
Msg. here:
(u, v, x, lhnd)
SimH
Da
SimH(A)
A
netu,v,x
netu,v,x
(a)
(a)
Msg. here:
word l
Figure 3: Ports and in- and output types of the simulator.
The state of SimH mainly consists of a database Da, similar to
the databases Du , but storing the knowledge of the adversary. The
behavior of SimH is sketched as follows.
• Inputs from TH(H). Assume that SimH receives an input
(u, v, x, lhnd) from TH(H). If a bitstring l for lhnd already
exists in Da, i.e., this message is already known to the adver-
sary, the simulator immediately outputs l at port netu,v,x !.
Otherwise, it ﬁrst constructs such a bitstring l with a recur-
sive algorithm id2real. This algorithm decomposes the ab-
stract term using basic commands and the adversary com-
mand adv parse. At the same time, id2real builds up a cor-
responding real bitstring using real cryptographic operations
and enters all new message parts into Da to recognize them
when they are reused, both by TH(H) and by A.
Mostly, the simulator can construct subterms exactly like the
correct machines would do in the real system. Only for en-
cryptions with a public key of a correct machine, adv parse
does not yield the plaintext; thus there the simulator encrypts
a ﬁxed message of equal length. This simulation presup-
poses that all new message parts are of the standard formats,
not those resulting from local adversary commands; this is
proven correct in the bisimulation.
• Inputs from A. Now assume that SimH receives a bitstring l
from A at a port netu,v,x ?. If l is not a valid list, SimH aborts
the transition. Otherwise it translates l into a corresponding
handle lhnd by an algorithm real2id, and outputs the abstract
sending command adv send x (w, u, lhnd) at port ina!.
If a handle lhnd for l already exists in Da, then real2id reuses
that. Otherwise it recursively parses a real bitstring using the
functional parsing algorithm. At the same time, it builds up a
corresponding abstract term in the database of TH(H). This
ﬁnally yields the handle lhnd. Furthermore, real2id enters all
new subterms into Da. For building up the abstract term,
real2id makes extensive use of the special capabilities of the
adversary modeled in TH(H). In the real system, the bit-
string may, e.g., contain a transformed signature, i.e., a new
signature for a message for which the correct user has al-
ready created another signature. Such a transformation of a
signature is not excluded by the deﬁnition of secure signature
schemes, hence it might occur in the real system. Therefore
the simulator also has to be able to insert such a transformed
signature into the database of TH(H), which explains the
need for the command adv transform signature. Similarly,
the adversary might send invalid ciphertexts or simply bit-
strings that do not yield a valid type when being parsed. All
these cases can be covered by using the special capabilities.
The only case for which no command exists is a forged signa-
ture under a new message. This leads the simulator to abort.
(Such runs fall into an error set which is later shown to be
negligible.)
As all the commands used by id2real and real2id are local,
these algorithms give uninterrupted dialogues between SimH and
TH(H), which do not show up in the views of A and H.
Two important properties have to be shown about the simulator
before the bisimulation. First, the simulator has to be polynomial-
time. Otherwise, the joint machine SimH(A) of SimH and A might
not be a valid polynomial-time adversary on the ideal system. Sec-
ondly, it has to be shown that the interaction between TH(H) and
SimH in the recursive algorithms cannot fail because one of the
machines reaches its runtime bound. The proof of both properties
is quite involved, using an analysis of possible recursion depths de-
pending on the number of existing handles (see [10]).
5.2 Proof of Correct Simulation
Given the simulator, we show that arbitrary polynomial-time
users H and an arbitrary polynomial-time adversary A cannot dis-
tinguish the combination of the real machine Mu from the com-
bination of TH(H) and SimH. The standard technique in non-
cryptographic distributed systems for rigorously proving that two
systems have identical visible behaviors is a bisimulation, i.e., one
deﬁnes a mapping between the respective states and shows that
identical inputs in mapped states retain the mapping and produce
identical outputs. We need a probabilistic bisimulation because the
real system and the simulator are probabilistic, i.e., identical in-
puts should yield mapped states with the correct probabilities and
identically distributed outputs. (For the former, we indeed use map-
pings, not arbitrary relations for the bisimulation.) In the presence
of cryptography and active attacks however, a normal probabilistic
bisimulation is still insufﬁcient for three crucial reasons. First, the
adversary might succeed in attacking the real system with a very
small probability, while this is impossible in the ideal system. This
means that we have to cope with error probabilities. Secondly, en-
cryption only gives computational indistinguishability, which can-
not be captured by a bisimulation, because the actual values in the
two systems may be quite different. Thirdly, the adversary might
guess a random value, e.g., a nonce that has already been created
by some machine but that the adversary has ideally not yet seen.
(Formally, “ideally not yet seen” just means that the bisimulation
fails if the adversary sends a certain value which already exists in
the databases but for which there is no command to give the adver-
sary a handle.) In order to perform a rigorous reduction proof in
this case, we have to show that no partial information about this
SH
SH
H
• • •
Mu
Mv
1. Rewrite
H
• • •
M'u
M'v
EncH
A0
A
6. 
H
SH
• • •
THH
THSimH
5. 
H
• • •
SH
SimH
4b. Bisimulation
CH
3. Combine
4a. Bisimulation
A
A
2. Idealize,
composition theorem
SH
MH
H
• • •
M'u
M'v
A
Encsim,H
Figure 4: Overview of the proof of correct simulation.
value has already leaked to the adversary because the value was
contained in a nested term, or because certain operations would
leak partial information. For instance, here the proof would fail if
we allowed arbitrary signatures according to the deﬁnition of [34],
which might divulge previously signed messages, or if we did not
additionally randomize probabilistic ciphertexts made with keys of
the adversary.