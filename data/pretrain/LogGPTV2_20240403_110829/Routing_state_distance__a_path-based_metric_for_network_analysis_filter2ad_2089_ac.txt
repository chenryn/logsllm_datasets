of RSD (or rsd) on a set of preﬁxes – which we refer to as
nodes.
In practice, we make the adaptations discussed in
Section 2.2 and use D (resp. eD) instead of RSD (resp. rsd).
5.1 The RS-Clustering problem
Given a set X of n preﬁxes, our goal is to produce a parti-
tion P of X; every preﬁx x ∈ X belongs only to one cluster
of P, denoted by P(x). (Note that we will often overload no-
tation and use partition names like P as labeling functions
that map preﬁxes to clusters.)
Intuitively, a good partition satisﬁes the property that
the routing state distance between two preﬁxes x and x!
in the same cluster (P(x) =P (x!)) should be minimized,
while the routing state distance between preﬁxes x and x! in
diﬀerent clusters (P(x) "= P(x!)) should be maximized. This
intuition can be captured in the following formal deﬁnition
of the RS-Clustering problem.
Problem 1
(RS-Clustering). Given a set of nodes
X = {x1, . . . , xn} and the m × n nexthop matrix N, ﬁnd
244150
100
50
0
−50
D
S
R
150
100
50
0
−50
D
S
R
150
100
50
0
−50
D
S
R
−100
−100
−50
0
RSD
(a)
50
100
150
−100
−100
−50
0
50
RSD
(b)
100
150
−100
−100
−50
100
150
0
50
RSD
(c)
Figure 8: Preﬁxes that can be reached from one or more monitor ASes through (a) Level3, (b) Hurricane Electric, or (c)
Sprint.
ϳϬϭϴ
ϯϮϱϳ
ϳϬϭ
ϯϵϳϱϲ
ϭϮϵϵ
ϮϯϯϬϬ
ϮϮϵϮϱ
ϱϬϱϲ
Ϯϵϭϰ
ϭϲϲϴ ϯϯϱϲ
ϭϮϯϵ
ϯϱϰϵ
ϯϱϲϭ
ϭϭϲϴϲ
ϱϰϭϯ
ϲϱϯϵ
ϭϯϬϯϬ
ϴϱϮ
ϲϵϯϵ
Ϯϵϯ
Ϯϴϲ
ϴϰϵϮ
Ϯϰϵϳ
ϴϬϬϭ
ϲϳϲϮ
ϯϭϯϬ
ϰϲϯϳ
ϴϭϮ
ϯϭϱϬϬ
ϭϭϭϲϰ
ϭϮϮϭ
Ϯϱϭϲ
ϳϲϲϬ
ϮϭϱϮ
Figure 9: BGPlay snapshot of preﬁx 64.72.205.0/24 (origin
AS: 23300) which occurs in the smaller cluster.
a partition P of the nodes in X such that
P-Cost(P) =
X
D(x, x!) + X
x,x!:
P(x)=P(x!)
x,x!:
P(x)"=P(x!)
`m − D(x, x!)´ .
is minimized.
Observe that the deﬁnition of the RS-Clustering prob-
lem does not require the number of clusters to be part
of the input. That is, RS-Clustering is parameter-free.
This happens because the objective function of the cluster-
ing problem (i.e., the P-Cost function) is not guaranteed
to decrease as the number of clusters increases. This is
in contrast with the objective functions of many classical
clustering problems (e.g., k-means, k-median etc). Hence,
there exists an optimal number of clusters that minimizes
the P-Cost function. A solution to RS-Clustering pro-
vides both the clusters of the preﬁxes as well as the optimal
number of clusters as part of its output.
Despite the fact that the RS-Clustering problem is pa-
rameter free, its optimal solution cannot be computed in
polynomial time. This is shown in the following proposi-
tion.
D
S
R
120
100
80
60
40
20
0
−20
−40
−60
−100
−50
0
50
RSD
100
150
Figure 10: Pivot clustering of RSD with τ = 120.
Proposition 2. The RS-Clustering problem is NP-
hard.
The proof of the above proposition is by a reduction from
the Clustering Aggregation problem [2, 7, 8].
5.2 The Pivot algorithm
Based on the similarity between the RS-Clustering
problem with the Correlation Clustering [3] and the
Clustering Aggregation [2, 8] problems, we propose
solving the problem using the Pivot algorithm, which was
ﬁrst proposed for solving the Clustering Aggregation
problem.
The pseudocode of Pivot is shown in Algorithm 1. The
algorithm takes as input the set of preﬁxes, their RSD values,
and the value of a threshold parameter τ ∈ [0, m]. The
algorithm works as follows: starting from a random preﬁx
x, it ﬁnds all preﬁxes that are within distance τ from x. All
these preﬁxes are assigned in the same cluster – centered at
preﬁx x. We call x the pivot of cluster Cx. The preﬁxes
that are assigned in the cluster are removed from the set
of preﬁxes X and the Pivot algorithm is reapplied to the
remaining subset of preﬁxes that have not been assigned to
any cluster.
Observe that Pivot requires the precomputation of all
pairwise RSD distances. Given that these distances are
known, the running time of Pivot is O(n2).
245l
e
u
a
v
e
v
i
t
c
e
b
o
j
1.5 x 108
1.4
1.3
1.2
1.1
1
0.9
0
14000
12000
10000
8000
6000
4000
2000
s
r
e
t
s
u
C
#
l
50
100
τ
150
200
250
(a)
0
0
50
100
200
250
150
τ
(b)
Figure 11: (a) Value of P-Cost and (b) number of clusters as clustering threshold τ varies.
Algorithm 1 The Pivot algorithm .
A set of preﬁxes X = {x1, . . . , xn} and a threshold τ ∈
[0, m].
A partition P of the preﬁxes
1: pick a random preﬁx x ∈ X
2: create a cluster Cx = {x! | D(x, x!) ≤ τ }
3: X = X \ Cx
4: Pivot(X, τ )
The quality of the solution output by Pivot can be mea-
sured using the P-Cost function. An interesting observa-
tion is that a small rewriting of the P-Cost function reveals
that it is identical with the optimization function used for
the Correlation Clustering problem [2, 3]. Hence, using
the results of Ailon et al. [2] we can state the following:
Proposition 3. For τ = m/2,
the Pivot algorithm
is is an expected 3-approximation algorithm for the RS-
Clustering problem.
Observe that Pivot is a randomized algorithm since at
every recursive call it picks a random preﬁx to play the role
of a pivot.
6. APPLICATIONS
In this section, we illustrate how the solutions of RS-
Clustering obtained using Pivot, automatically extract
local atoms of N.
We start by applying Pivot using the threshold τ = m/2
as suggested by Proposition 3. This translates into τ = 120
in our data.
Five large clusters identiﬁed by Pivot are shown in Fig-
ure 10. The sharpest separation is shown by the cluster in
the lower left. Upon inspection, we ﬁnd that the lower left
cluster is in fact the Hurricane Electric cluster which was
described in detail in Section 4. Note that whereas pre-
viously the Hurricane Electric cluster was identiﬁed manu-
ally, in this case it is extracted automatically through the
use of Pivot. This provides good validation of the RS-
Clustering problem deﬁnition and our proposed solution
obtained via Pivot.
D
S
R
100
80
60
40
20
0
−20
−40
−60
−100
C1
C2
C3
C4
C5
−50
0
50
RSD
100
150
Figure 12: Pivot clustering of RSD with τ = 50.
While Figure 10 shows that the Hurricane Electric cluster
is clearly separated from the other preﬁxes, the other clus-
ters are not so well separated. In fact, although Pivot with
τ = m/2 has a provable approximation bound, it is entirely
possible that the algorithm may ﬁnd a better solution with
a diﬀerent value of the threshold. We can assess the quality
of a clustering simply by computing the value of the objec-
tive function P-Cost. Figure 11(a) shows how the objective
function varies by decreasing the threshold below τ = 120.
It shows that at a threshold τ of about 50, the quality of
the clustering levels oﬀ, and below 25 or so it starts to climb
again. Furthermore, Figure 11(b) shows the number of clus-
ters found at each threshold, and shows that below a τ value
of 50 the number of clusters becomes very large. In fact, be-
low τ = 50, many clusters are just singletons which are not
interesting as local atoms. Hence we next apply Pivot using
a threshold value of 50.
Five of the largest clusters found with a threshold of 50
are shown in Figure 12. (Note that these clusters are not
the same as those shown in Figure 10; the two ﬁgures show
outputs of diﬀerent clustering runs.) Compared to those in
Figure 10, these clusters show much sharper separation, and
we ﬁnd that each of these corresponds to a local atom. To
246Table 1: Statistics for the clusters in Figure 12.
C1
Size of cluster (C)
Size of source set (S)
Destinations
Dominant Next Hops
Next Hop Density
Coherence
150
16
Ukraine 83%
Czech Rep. 10%
9002
0.26
0.70
21011
0.23