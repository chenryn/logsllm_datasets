blocks in each level of each partition, and can avoid stor-
ing block IDs and contents explicitly.
Since the simulator need not represent blocks individ-
ually, it does not measure the costs of encryption, look-
ing up block IDs, or performing disk reads for blocks.
Thus, measured bandwidth costs and response times de-
pend entirely on network latency, bandwidth capacity, re-
quest arrival times, and the scheme itself.
7.2.1 Extrapolating Results to Real-World Settings
Burst ORAM can achieve near-optimal performance for
realistic bursty trafﬁc patterns.
In particular, in many
real-life cases bandwidth is overprovisioned to ensure
near-optimal response time under bursts – for the inse-
cure baseline. However, in between bursts, most of the
bandwidth is not utilized. Burst ORAM’s idea is leverag-
ing the available bandwidth in between bursts to ensure
near-optimal response time during bursts.
Our simulation applies mainly to scenarios where the
client-server bandwidth is the primary bandwidth bottle-
neck (i.e., client-server bandwidth is the narrowest pipe
in the system), which is likely to be the case in a real-life
outsourced storage scenario, such as a corporate enter-
prise outsourcing its storage to a cloud provider. While
the simulation assumes that there is a single server, in
practice, the server-side architecture could be more com-
plicated and involve multiple servers interacting with
each other. But as long as server-server bandwidth is not
the bottleneck, our simulation results would be applica-
ble. Similarly, we assume that the server’s disk band-
width is not a bottleneck. This is likely the case if fast
Solid State Drives (SSD) are employed. For example,
assuming 4KB blocks and only one such array of SSDs
with a 100µs random 4KB read latency, our single-array
throughput limits us to satisfying 10,000 requests per
second. In contrast, even a 1Gbps network connection
lets us satisfy only 32,000 requests per second. Thus,
with even six such arrays (3log2 N SSDs total), assign-
ing roughly √N/6 partitions to each array, we can expect
the client-server network to be the bottleneck.
Other than bandwidth, another factor is inherent sys-
tem latencies, e.g., network round-trip times, or inherent
i
t
s
o
C
h
t
d
w
d
n
a
B
e
n
i
l
n
O
Endless Burst - Online Bandwidth Cost 
(32 TB ORAM, 100 GB client storage) 
Burst ORAM 
ObliviStore 
Burst ORAM No Job Prioritization 
Burst ORAM No Level Caching 
overhead peaks from extra 
early cache-ins when most 
shuffling jobs delayed 
6X 
5X 
4X 
3X 
2X 
1X 
0X 
1E+0 
1E+2 
1E+4 
Request Index 
1E+6 
1E+8 
1E+10 
Figure 7: Online bandwidth costs as a burst lengthens.
Burst ORAM maintains low online cost regardless of
burst length, unlike ObliviStore.
Endless Burst - Effective Bandwidth Cost 
(32 TB ORAM, 100 GB client storage) 
Burst ORAM 
ObliviStore 
Burst ORAM No Job Prioritization 
Burst ORAM No Level Caching 
i
t
s
o
C
h
t
d
w
d
n
a
B
e
v
i
t
c
e
f
f
E
40X 
35X 
30X 
25X 
20X 
15X 
10X 
5X 
0X 
prioritizing efficient 
jobs defers shuffling 
client space full, 
shuffling begins 
1E+0 
1E+2 
1E+4 
Request Index 
1E+6 
effective cost 
converges to 
overall cost 
1E+8 
1E+10 
Figure 8: Effective bandwidth costs as burst grows. Burst
ORAM handles most bursts with ∼1X effective cost. Ef-
fective costs converge to overall costs for long bursts.
disk latencies. Under the same overall bandwidth conﬁg-
uration, increased latency is unlikely to affect the near-
optimality of Burst ORAM– while they would increase
Burst ORAM’s total response times, we would expect a
comparable increase in response times for the insecure
baseline.
7.3 Endless Burst Experiments
For the endless burst experiments, we use a 32TB
ORAM with N = 233 4KB blocks and 100GB client
space. We issue 233 requests at once, then start satisfy-
ing requests in order using each scheme. We record the
bandwidth costs of each request, averaged over requests
with similar indexes and over three trials. Figures 7 and
8 show online and effective costs, respectively. The in-
secure baseline is not shown, since its online, effective,
and overall bandwidth costs are all 1.
Figure 7 shows that Burst ORAM maintains 5X–
6X lower online cost than ObliviStore for bursts of all
lengths. When Burst ORAM starts to delay shufﬂing, it
incurs more early shufﬂe reads, increasing online cost,
but stays well under 2X on average. Burst ORAM effec-
tive costs can be near 1X because writes associated with
requests are not performed until blocks are shufﬂed.
Burst ORAM defers shufﬂing, so its effective cost
stays close to its online cost until client space ﬁlls, while
ObliviStore starts shufﬂing immediately, so its effective
USENIX Association  
23rd USENIX Security Symposium  759
11
cost stays constant (Figure 8). Thus, response times for
short bursts will be substantially lower in Burst ORAM
than in ObliviStore.
Eventually, client space ﬁlls completely, and even
Burst ORAM must shufﬂe continuously to keep up with
incoming requests. This behavior is seen at the far right
of Figure 8, where each scheme’s effective cost con-
verges to its overall cost. Burst ORAM’s XOR tech-
nique results in slightly higher overall cost than Oblivi-
Store’s level compression, so Burst ORAM is slightly
less efﬁcient for very long bursts. Without local level
caching, Burst ORAM spends much more time shuf-
ﬂing the smallest levels, yielding the poor performance
of Burst ORAM No Level Caching.
If shufﬂe jobs are started in arbitrary order, as for Burst
ORAM No Prioritization, the amount of shufﬂing per re-
quest quickly increases, pushing effective cost toward
overall cost. However, by prioritizing efﬁcient shufﬂe
jobs as in Burst ORAM proper, more shufﬂing can be
deferred, keeping effective costs lower for longer, and
maintaining shorter response times.
7.4 Two-Burst Experiments
Our Two-Burst experiments show how each scheme re-
sponds to idle time between bursts. We show that Burst
ORAM uses the idle time effectively, freeing up as much
client space as possible. The longer the gap between
bursts, the longer Burst ORAM maintains low effective
costs during Burst 2.
Figure 9 shows response times during two closely-
spaced bursts, each of ∼ 227 requests spread evenly over
72 seconds. The ORAM holds N = 225 blocks, and
the client has space for 218 blocks. Since we must also
store early shufﬂe reads and reserve space for the shuf-
ﬂe buffer, the client space is not quite enough to accom-
modate a single burst entirely. We simulate a 100Mbps
network connection with 50ms latency.
All ORAMs start with low response times during
Burst 1. ObliviStore response times quickly increase due
to ﬁxed shufﬂe work between successive requests. Burst
ORAMs delay shufﬂe work, so response times stay low
until client space ﬁlls. Without level caching, additional
early shufﬂe reads cause early shufﬂing and thus pre-
mature spikes in response times.
When Burst 1 ends, the ORAMs continue working,
satisfying pending requests and catching up on shufﬂing
during the idle period. Longer idle times allow more
shufﬂing and lower response times at the start of Burst
2. None of the ORAMs have time to fully catch up, so
response times increase sooner during Burst 2. ObliviS-
tore cannot even satisfy all Burst 1 requests before Burst
2 starts, so response times start high on Burst 2. Burst
ORAM does satisfy all Burst 1 requests, so it uses freed
client space to efﬁciently handle early Burst 2 requests.
)
s
m
i
(
e
m
T
e
s
n
o
p
s
e
R
t
s
e
u
q
e
R
)
s
m
i
(
e
m
T
e
s
n
o
p
s
e
R
t
s
e
u
q
e
R
)
s
m
i
(
e
m
T
e
s
n
o
p
s
e
R
t
s
e
u
q
e
R
1E+7 
1E+6 
1E+5 
1E+4 
1E+3 
1E+2 
1E+1 
1E+0 
1E+7 
1E+6 
1E+5 
1E+4 
1E+3 
1E+2 
1E+1 
1E+0 
1E+7 
1E+6 
1E+5 
1E+4 
1E+3 
1E+2 
1E+1 
1E+0 
Two-Burst Response Times 
80s Split 
Burst ORAM 
ObliviStore 
Burst ORAM No Job Prioritization 
Burst ORAM No Level Caching 
150 
200 
250 
100s Split 
Burst 1 
50 
0 
Gap 
Burst 2 
100 
Time Request Issued (seconds from start) 
Burst 1 
50 
Gap 
100 
0 
Burst 2 
150 
Time Request Issued (seconds from start) 
200 
250 
200s Split 
Burst ORAM response 
times low until client 
space fills again 
Burst 1 
50 
0 
Gap 
Burst 2 
100 
150 
200 
250 
Time Request Issued (seconds from start) 
Figure 9: Response times during two same-size bursts
of just over 217 requests spread evenly over 72 seconds.
Client has space for at most 218 blocks. No level caching
causes early spikes due to extra early shufﬂe reads.
Clearly, Burst ORAM performs better with shufﬂe pri-
oritization, as it allows more shufﬂing to be delayed to