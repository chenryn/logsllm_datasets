edges incident to it.
Deﬁnition 1. Path. Let G = (V, E)
be a graph. A walk w =
(v1, e1, v2, e2, . . . , vn, en, vn+1) in G is an alternating sequence of vertices and
edges in V and E respectively so that for all i = 1, . . . , n: {vi, vi+1} = ei. A path
in G is a walk with no vertex and no edge repeated.
Deﬁnition 2. Cycle. A closed walk or cycle w(cid:3) = (v1, e1, v2, e2, . . . , vn, en, vn+1,
en+1, v1) on a graph G(V, E) is an alternating sequence of vertices and edges in
V and E such that w = (v1, e1, v2, e2, . . . , vn, en, vn+1) is a walk, and the edge
en+1 between vn+1 and v1 does not occur in w.
Deﬁnition 3. Cycle Basis. A closed walk on a graph G(V, E) is an Eulerian
subgraph if it traverses each edge in E exactly once. A cycle space of an undirected
graph is the set of its Eulerian subgraphs. A cycle basis is a minimal set of cycles
that allows every Eulerian subgraph to be expressed as a symmetric diﬀerence of
basis cycles.
Deﬁnition 4. The average shortest-path length (APSL). Let F be the set of all
pairs of nodes of a graph G in between which there is a path, then
ASPL(G) =
1
|F|
(cid:2)
(vi,vj )∈F
dist(vi, vj)
(1)
where dist(vi, vj) is the number of edges on a shortest path between vi and vj.
Deﬁnition 5. A connected component G(cid:3) of a graph G is a subgraph in which
any two vertices are connected to each other by paths, and which is connected to
no additional vertices in G.
4 WordGraph Method
Let C be a set containing q domain name strings {c1, . . . , cq}. Each domain name
string consists of higher level domains (second-level domain, SLD) and a top-
level domain (TLD), separated by a dot. For example, in wikipedia.org, the SLD
is wikipedia and the TLD is org. Within C we have domains that are benign and
domains that are generated by a Dictionary-based DGA. Our goal is to detect
all the Dictionary-AGDs in C and to extract the dictionaries used to produce
these domains.
Extracting Words from Domains. The word extraction method learns words
from the set of domain name strings itself. Since Dictionary-based DGAs are
known to use words repeatedly, we deﬁne a word as a sequence of at least m
characters that appears in two or more SLDs within the set C. In the experi-
mental results section, we use m = 3. We produce a set D of words as follows:
Detection of Algorithmically Generated Domain Names in DNS Traﬃc
301
1. Set D = ∅
2. For every ci and cj in C, i, j ∈ {1, . . . , q}, i (cid:4)= j:
Denote by li,j the largest common substring in ci and cj.
If |li,j| ≥ m, add li,j to the set D.
It is important to point out that the above word extraction algorithm is
applied to the entire set C, including both Dictionary-AGDs and legitimate
domain names. The resulting set D will therefore have many elements that are
not words from a Dictionary-based DGA. We will eliminate these words in a
subsequent phase. To illustrate the word extraction algorithm, consider the fol-
lowing domains:
facetype.com, facetime.com, bedtime.com,
faceboard.com, bedboard.com, bedding.com
The resulting set of common substrings is D = {face, time, bed, board, facet}.
Fig. 1. Diﬀerences in structure of (a) Word graph of Suppobox malware domains [7],
and (b) Word graph of Alexa (benign) domains [2]. In (a) each dark region consists of
words from a diﬀerent malicious dictionary.
Word Graph Construction. We split the set of domains C into partitions
C1, . . . , Cr such that all the domains within each Ci, i ∈ {1, . . . , r} have the
same top-level domain (TLD). For each Ci we deﬁne a graph Gi as follows. The
nodes of Gi are the words from the set D that occur in at least one domain
name in Ci. Two nodes (words) of Gi are connected if they co-occur in the same
domain in Ci, i.e. if there exists at least one domain cj ∈ Ci so that these words
are both substrings of cj. The division by TLD is motivated by the fact building
separate graphs per TLD prevents noise and limit the graph size. Additionally,
based on our observations, Dictionary-based DGAs use a limited number of dif-
ferent TLDs. We can therefore expect the Dictionary-AGDs to be concentrated
in a small number of partitions.
302
M. Pereira et al.
In order to detect malware related words in each of the graphs Gi, we exploit
the fact that subgraphs with words from malicious dictionaries present a diﬀerent
structure from subgraphs with words from benign domains. To illustrate this, in
Fig. 1 we visualize the word graph Gd of a set Cd of known Dictionary-AGDs and
the word graph Gb of a set Cb of known benign domain names respectively. For
more details on how these domain names were obtained, we refer to Sect. 5.1. The
three dark regions in Fig. 1(a) each correspond to a diﬀerent dictionary used by
the DGA algorithm. Note that in reality the partitions Ci, i ∈ {1, . . . , r} contain
a mixture of Dictionary-AGDs and benign domain names, meaning that the
distinction is not as clear-cut as in Fig. 1. Still there are important observations
to be made from Fig. 1 that explain the rationale of our approach for detecting
malware dictionaries in the word graphs Gi.
Our ﬁrst observation is that dictionary words are less likely to have a low
degree. Each individual word from a malicious dictionary is used to form a num-
ber of diﬀerent domains, by combining it with other dictionary words. Therefore,
from each Gi, we ﬁlter out all the nodes (words) with degree less than 3 (a value
experimentally determined). With a high probability, a low degree node (word)
is related to benign domains. We can also point out that word combinations
in Dictionary-AGDs are algorithmically deﬁned. This results in a more uniform
graph structure. On the other hand, words from benign domains present less uni-
form patterns of connectivity in the word graph. To leverage this intuition we
extract the connected components of each graph Gi. We expect that dictionaries
from DGA algorithms will appear as such connected components.
, . . . , G(n)
Feature Vector Construction for Connected Components. Let G(1)
be
the connected components of word graph Gi. For each connected component
, j ∈ {1, . . . , n}, we measure the following structural features (see Fig. 2):
G(j)
i
i
i
1. Dmean: Average vertex degree of G(j)
;
2. Dmax: Maximum vertex degree of G(j)
;
3. C: Cardinality of cycle basis set of G(j)
4. CV : C/|V |, where V is the set of vertices of G(j)
5. ASPL: Average shortest-path length of G(j)
;
.
i
i
i
;
i
i
Note that all steps above are done in a fully unsupervised fashion, i.e. without
knowledge which domains in C are generated by a Dictionary-based DGA and
which ones are not. We apply these preprocessing steps to the training data as
well as to batches of new domain names observed during deployment.
Graph Based Dictionary Finding. Given a set of domains CT rain, we apply all
the previous steps to CT rain and obtain all the connected components of all the
graphs Gi derived from CT rain. We manually label every connected component
in every graph Gi as DGA/non-DGA (indicated as True/False in Fig. 2). Next
we train a decision tree over the training dataset of labeled feature vectors.
The decision tree model is later used for classifying new vectors (connected
Detection of Algorithmically Generated Domain Names in DNS Traﬃc
303
ID Dmean Dmax
ID1
16.0
16.0
ID2
…
…
IDN 3.54
80.7
7.16
6.91
…
C
63
60
…
20
CV
2.62
2.50
…
1.7
ASPL
1.84
1.86
…
3.78
Label
True
True
False
Fig. 2. In order to classify word graph components as DGA/non-DGA, each graph
component is represented as a vector of structural features. Each description vector is
part of a dataset that describes the overall word graph.
components) without human intervention, even if these connected components
stem from word graphs that originate from a completely diﬀerent dictionary.
Each connected component that is classiﬁed as DGA by the decision tree is
subsequently converted into a dictionary in a straightforward manner, i.e. by
treating each node of the connected component as a word in the dictionary. An
overview of the WordGraph dictionary ﬁnding phase is presented in Fig. 3.
Fig. 3. An overview of the proposed WordGraph method. In 1 a dataset containing
malicious and benign domains is analyzed, and frequent words are learned from the
dataset. In 2 a word graph is built, and the structure of each graph component is
analyzed to detect the malware dictionary 3.
Classiﬁcation of Domain Names. From the previous steps, we obtain a set of
detected dictionaries, each one associated with a TLD. We ﬂag a domain as
malicious if it has at least two words from a same discovered dictionary, and it
has the same TLD as the dictionary.
304
M. Pereira et al.
5 Experimental Methodology
We follow a similar approach as [10] and create an experimental setting with
labeled ground truth data obtained from the DGArchive [15], which is a web
database for DGA domains from various families, and from the Alexa top 1
million domains (a snapshot from 2016) [2]. The main goal of our experiments
with labeled data is to compare our methodology with state-of-the-art techniques
for DGA classiﬁcation: classiﬁers based on human engineered lexical features,
and classiﬁers based on deep neural networks. Moreover, we want to observe
how robust these methods are to changes in the dictionary used for generating
malicious domains. This is a question that has not been explored in the literature,
to the best of our knowledge. Our method is based solely on structural features
representing how the words from the dictionary are put together but not on the
speciﬁc words themselves. Therefore, we expect our method to be robust against
changes in the dictionary.
In more details, we analyze the performance of our WordGraph method and
compare with classiﬁcation models based on Random Forests and Deep Learning
methods in three diﬀerent settings:
– Training and testing datasets containing Dictionary-AGDs generated from
the same dictionary. This experimental setting has been used in previous
works [10,20,23].
– Testing datasets containing domains formed from dictionaries that are dis-
tinct from the dictionaries used to generate the domains in the training
dataset. We want to evaluate the robustness of all models in a scenario where
a botnet administrator wants to mislead a trained detection model by updat-
ing the dictionary in the malware code. This question has not been previously
addressed in the literature.
– Small number of training samples. How well does each method perform when
only a very small number of training samples is available?
We also evaluate the performance of the proposed WordGraph method when
facing real traﬃc data. Many of the previous works are evaluated only in sce-
narios of synthetically created datasets. We show that the WordGraph model
achieves similar performance when used for detecting Dictionary-AGDs in real
DNS traﬃc, and moreover, it is able to detect new varieties of dictionaries and
malware seeds due to its nature of pattern discovery.
5.1 Datasets
The evaluation of the proposed approach is conducted on datasets with ground
truth labels and on real traﬃc unlabeled data.
Ground Truth Data. The ground truth data contains 80,000 benign domain
names randomly selected from the Alexa top 1M domains [2]. In our experi-
ments, we 50,000 out of the 80,000 Alexa domain names for training, while the
Detection of Algorithmically Generated Domain Names in DNS Traﬃc
305
Table 1. Description of the datasets used in two experiments: when the train and
test data are both composed of AGDs generated from the same dictionaries (Test-
Familiar), and when the train and test data are composed of AGDs generated from
diﬀerent dictionaries (Test-Unfamiliar).
Dataset Train
Test-Familiar
Test-Unfamiliar
Alexa WL1 WL2 WL3 Alexa WL1 WL2 WL3 Alexa WL1 WL2 WL3
Round 1 50K 20,768 20,768 0
30K 12K 12K 0
30K 0
0