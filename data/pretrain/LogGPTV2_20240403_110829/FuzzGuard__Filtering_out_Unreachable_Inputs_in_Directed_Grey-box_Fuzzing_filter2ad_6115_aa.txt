title:FuzzGuard: Filtering out Unreachable Inputs in Directed Grey-box Fuzzing
through Deep Learning
author:Peiyuan Zong and
Tao Lv and
Dawei Wang and
Zizhuang Deng and
Ruigang Liang and
Kai Chen
FuzzGuard: Filtering out Unreachable Inputs in 
Directed Grey-box Fuzzing through Deep Learning
Peiyuan Zong, Tao Lv, Dawei Wang, Zizhuang Deng, Ruigang Liang, and 
Kai Chen, SKLOIS, Institute of Information Engineering, Chinese Academy of 
Sciences, Beijing, China
https://www.usenix.org/conference/usenixsecurity20/presentation/zong
This paper is included in the Proceedings of the 29th USENIX Security Symposium.August 12–14, 2020978-1-939133-17-5Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.FuzzGuard: Filtering out Unreachable Inputs in Directed Grey-box Fuzzing
through Deep Learning
Peiyuan Zong1,2, Tao Lv1,2, Dawei Wang1,2, Zizhuang Deng1,2, Ruigang Liang1,2, Kai Chen1,2∗
1 SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China
2 School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China
{zongpeiyuan, lvtao, wangdawei, dengzizhuang, liangruigang, chenkai}@iie.ac.cn
Abstract
Recently, directed grey-box fuzzing (DGF) becomes popular
in the ﬁeld of software testing. Different from coverage-based
fuzzing whose goal is to increase code coverage for triggering
more bugs, DGF is designed to check whether a piece of po-
tentially buggy code (e.g., string operations) really contains
a bug. Ideally, all the inputs generated by DGF should reach
the target buggy code until triggering the bug. It is a waste of
time when executing with unreachable inputs. Unfortunately,
in real situations, large numbers of the generated inputs can-
not let a program execute to the target, greatly impacting
the efﬁciency of fuzzing, especially when the buggy code is
embedded in the code guarded by various constraints.
In this paper, we propose a deep-learning-based approach
to predict the reachability of inputs (i.e., miss the target or not)
before executing the target program, helping DGF ﬁltering out
the unreachable ones to boost the performance of fuzzing. To
apply deep learning with DGF, we design a suite of new tech-
niques (e.g., step-forwarding approach, representative data
selection) to solve the problems of unbalanced labeled data
and insufﬁcient time in the training process. Further, we im-
plement the proposed approach called FuzzGuard and equip it
with the state-of-the-art DGF (e.g., AFLGo). Evaluations on
45 real vulnerabilities show that FuzzGuard boosts the fuzzing
efﬁciency of the vanilla AFLGo up to 17.1×. Finally, to un-
derstand the key features learned by FuzzGuard, we illustrate
their connection with the constraints in the programs.
1 Introduction
Fuzzing is an automated program testing technique, which is
usually divided into two categories: coverage-based fuzzing
and directed fuzzing. The goal of the former one is to achieve
high code coverage, hoping to trigger more crashes; while di-
rected fuzzing aims to check whether a given potential buggy
code really contains a bug. In real analysis, directed fuzzing
is very popularly used since the buggy code is often speciﬁed.
For example, security analysts usually pay more attention
∗Corresponding author
to the buffer-operating code or want to generate a proof-of-
concept (PoC) exploit for a given CVE [3] whose buggy
code is known. There are some directed fuzzing tools such as
AFLGo [9], SemFuzz [35] and Hawkeye [12]. As we know,
a random input is less likely to reach the buggy code, not to
mention triggering the bug. Thus, most of the tools instrument
the target program for observing the run-time information and
leveraging the information to generate the inputs that could
reach the buggy code. Such fuzzing method is also referred
to as Directed Grey-box Fuzzing (DGF for short).
An ideal DGF should generate the inputs which can all
reach the buggy code. Unfortunately, in real situations, a large
number of the generated inputs could miss the target, espe-
cially when the buggy code is embedded in the code guarded
by many (complicated) constraints (e.g., thousands). Fac-
ing this situation, various techniques (e.g., Annealing-based
Power Schedules [9]) are designed to generate reachable in-
puts. However, even for the state-of-the-art DGF tools (e.g.,
AFLGo [9]), the ratio of unreachable inputs is still high. Based
on our evaluation using AFLGo, on average, over 91.7% of
the inputs cannot reach the buggy code (Section 6).
Such a large amount of unreachable inputs waste lots of
time in the fuzzing process. Traditional program analysis ap-
proaches such as symbolic execution [20], theoretically, could
use the constraints of all branches in the target program to
infer the execution result of the input. However, the time spent
on solving constraints will dramatically increase together with
the increase of the constraints’ complexity. In other words,
the constraints in the path from the program’s start point to
the buggy code could be very complex, which makes them
difﬁcult or even not possible to be solved in limited time.
Inspired by the success of pattern recognition [11,19,34,36]
which could accurately classify millions of images even if they
are previously unseen, our idea is to view program inputs as a
kind of pattern and identify those which can reach the buggy
code. Basically, by training a model using a large number of
inputs labeled with the reachability to the target code from
previous executions, we could utilize the model to predict the
reachability of the newly generated inputs without running
USENIX Association
29th USENIX Security Symposium    2255
the target program. However, it is challenging to build such
an accurate model for DGF due to the following reasons.
Challenges. C1: Lack of balanced labeled data. It is neces-
sary to acquire enough and balanced labeled data to train a
deep learning model (e.g, classiﬁcation for cats and dogs). In
other words, the number of one object’s images should be
close to the number of the other object’s. However, in the
process of fuzzing, the (un)reachable inputs are usually unbal-
anced. Especially, in the early stage of fuzzing, there is even
no reachable input (e.g., for the bug #7 in GraphicsMagick,
the ﬁrst reachable input is generated after more than 22.6
million executions). Without the balanced labeled data, the
trained model will be prone to over-ﬁtting. One may think of
extending the labeled data just like the way of image transfor-
mation (e.g., resizing, distortion, perspective transformation),
which could increase the number of the object’s images to bal-
ance the training data without changing the identiﬁed object.
However, such transformation cannot be applied to program
inputs since even one bit ﬂip may change the execution paths
of inputs and further impact the labels (i.e., let a reachable
input become unreachable).
C2: Newly generated reachable inputs could look quite
different from the reachable ones in the training set, making
the trained model fail to predict the reachability of the new
inputs. This is mainly because the new inputs may arrive at
the buggy code through a different execution path never seen
before. So simply using the inputs along one execution path
to train a model may not correctly predict the reachability of a
new input. One may think of generating various inputs along
different execution paths to the buggy code before training.
Unfortunately, such generation process is out of our control.
He may also wait for a long time before training, hoping to
collect enough inputs along different paths. However, this
may waste lots of time since many unreachable inputs have
been executed with.
C3: Efﬁciency. In the task of training a model for tradi-
tional pattern recognition, the time spent on training is not
strictly limited. However, in the fuzzing process, if the time
spent on training a model and predicting an input’s reacha-
bility is more than the time spent on executing the program
with the input, the prediction is of no use. So the time cost of
training and prediction should be strictly limited.
Our approach. In this paper, we overcome the challenges
mentioned above and design an approach to build a model
for DGF to ﬁlter out unreachable inputs, called FuzzGuard.
The basic idea of FuzzGuard is to predict whether a program
can execute to the target buggy code with a newly generated
input by learning from previous executions. If the result of
prediction is unreachable, the directed grey-box fuzzer (we
use “the fuzzer” for short in the rest of the paper) shouldn’t
execute this input anymore, which saves the time spent on
real execution. Note that FuzzGuard is not meant to replace
the fuzzer (e.g., AFLGo), but to work together with the fuzzer
to help it ﬁlter out unreachable inputs.
FuzzGuard works in three phases: model initialization,
model prediction, and model updating. (1) In the ﬁrst phase,
the fuzzer generates various inputs and runs the target pro-
gram with them to check whether a bug is triggered. At the
same time, FuzzGuard saves the inputs and their reachabil-
ity, and trains the initial model using the labeled data, which
may be unbalanced (C1). To solve this problem, we design a
step-forwarding approach: choosing the dominators (referred
to as “pre-dominating nodes” [5]) of the buggy code as the
middle-stage targets, and letting the execution reach the pre-
dominating nodes ﬁrst. In this way, the balanced data could
be gained earlier for training some models only targeting the
pre-dominating nodes, which minimizes the time of execution.
(2) In the second phase, after the fuzzer generates a number of
new inputs, FuzzGuard utilizes the model to predict the reach-
ability of each input. As mentioned in C2, the trained model
may not work for the newly generated inputs. To solve this
problem, we design a representative data selection approach
to sample training data from each round of mutation, which
minimizes the number of sampled data to increase efﬁciency.
(3) In the third phase, FuzzGuard updates the model using the
labeled data collected in the second phase to increase its accu-
racy. Note that the time spent on the model updating should
be strictly limited (C3). We tackle this challenge by carefully
choosing the time to update. To the best of our knowledge,
previous studies of fuzzing focus on generating various inputs,
to cover more lines of code (CGF) or to reach buggy code
(DGF). Various mutation strategies on inputs are designed. In
contrast, our study does not directly mutate inputs (we rely on
current mutation strategies, e.g., AFLGo). Instead, we ﬁlter
out unreachable inputs. In this way, a DGF does not need
to run the target program with unreachable inputs (which
deﬁnitely cannot trigger the target bug), which increases the
overall efﬁciency.
We implement FuzzGuard on the base of AFLGo [9] (an
open-source state-of-the-art DGF tool), and evaluate the per-
formance using 45 real vulnerabilities on 10 popular programs.
The results show that FuzzGuard boosts the fuzzing perfor-
mance by 1.3× to 17.1×. Interestingly, we ﬁnd that the more
the unreachable inputs the fuzzer generates, the better Fuzz-
Guard could perform. Also, more time could be saved if the
target node reach a balanced state earlier. At last, we design an
approach to understand the extracted features of FuzzGuard,
and ﬁnd that the features are correlated with the constraints
in the if-statements in target programs, which indeed impacts
the execution on code level.
Contribution. The contributions of this paper are as follows:
• New technique. We design and implement FuzzGuard which
helps DGF to ﬁlter out unreachable inputs and save the time
of unnecessary executions. To the best of our knowledge,
this is the ﬁrst deep-learning-based solution to identify and
remove unreachable inputs. The core of FuzzGuard is the
step-forwarding approach, and representative data selection.
Evaluation results show that up to 88% of fuzzing time can be
2256    29th USENIX Security Symposium
USENIX Association
saved for state-of-the-art tools (e.g., AFLGo). We also release
our FuzzGuard for helping researchers in the community1.
• New understanding. We design an approach to study the
features utilized by the model in FuzzGuard for prediction,
and ﬁnd them correlated with the branches in target programs.
The understanding of such relationship helps to explain the
deep learning model and further helps to improve FuzzGuard.
2 Background
In this section, we give a brief background of directed grey-
box fuzzing and recent studies utilizing deep learning to im-
prove the fuzzing performance.
2.1 Fuzzing
Fuzzing [27] is one of the classical software testing tech-
niques to expose exceptions of a computer program [32]. The
main idea of fuzzing is to feed a massive number of inputs
(i.e., test cases) to the target program, exposing bugs through
observed exceptions. Among all techniques of fuzzing, grey-
box fuzzing [12] recently becomes quite popular due to its
high efﬁciency and reasonable performance overhead. With
different goals, grey box fuzzing can usually be divided into
two types as follows.
Coverage-based Grey-box Fuzzing. One main goal of this
type of fuzzing technique is to achieve the high coverage of
code in the target program. Therefore, some fuzzers [2, 10,
15, 16, 24, 25] aim to achieve high code coverage of the target
program, expecting to accidentally trigger the bug, namely
Coverage-based Grey-box Fuzzing (CGF). Typically, CGF
generates the inputs by mutating the seed inputs which could
traverse previous undiscovered program statements in order
to increase the coverage rate of the code. AFL [2], as a repre-
sentative of CGF, employs light-weight compile-time instru-
mentation technique and genetic algorithms to automatically
discover interesting test cases, selects seed inputs that trig-
ger new internal states in the fuzzing process, and mutates
seed inputs in various ways (e.g., bit and byte ﬂips, simple
arithmetics, stacked tweaks and splicing [22]).
Directed Grey-box Fuzzing. Sometimes, the potential buggy
code is known. So there is no need to increase the code cover-
age. In this situation, fuzzers [9, 12, 35] are designed to gener-
ate inputs that reach the buggy code for triggering a speciﬁed
bug, which is referred to as Directed Grey-box Fuzzing (DGF).
DGF is commonly used since some kinds of code may be
highly possible to contain a bug (e.g., string copy operations)
which should be emphasized more in the fuzzing. Also, some-
times the buggy code is known (e.g., from CVEs). So those
fuzzers are utilized to generate a proof-of-concept exploit
toward the buggy code [35]. With the different goals from
CGF, current DGF aims to generate the inputs which could
reach the speciﬁc potential buggy code, further expecting to
1The release is available at https://github.com/zongpy/FuzzGuard.
trigger the bug. For example, AFLGo [9] calculates the dis-
tance between each basic blocks and the path from the entry
point to the buggy code in the control ﬂow graph; then utilizes
the distance to choose suitable inputs for mutation.
However, even for state-of-the-art fuzzers, still lots of time
is spent on unnecessary executions. In our experiments, we
ﬁnd that for a typical vulnerability whose location is known,
more than 91.7% of the generated inputs cannot reach the
buggy code (unreachable inputs) on average. Running the
target program with the unreachable inputs is highly time-
consuming. If there is a fuzzer that could judge the reach-
ability of an input without executing the program, a huge
amount of time could be saved. In this paper, we design such
a ﬁlter called FuzzGuard, which leverages a deep learning
model to achieve this goal without real execution. Also, it
could be adapted to existing fuzzers (e.g., AFLGo) and work
together with them, without replacing them. To the best of
knowledge, this is the ﬁrst deep-learning-based solution to
ﬁlter out unreachable inputs for DGF.
2.2 Deep Learning
Security researchers apply deep learning to fuzzing, which
provides new insights for solving difﬁcult problems in previ-
ous research. For example, Godefroid et al. utilize RNNs to
generate program inputs that have higher code coverage [17].
Rajpal et al. [29] utilize RNN-guided mutation ﬁlter to locate
which part of an input impacts more on code coverage. In this
way, they could achieve higher code coverage by mutating
the located part. Nichols et al. [28] show that GANs could be
used to predict the executed path of an input to improve the
performance of the AFL [2]. Angora [15] and NEUZZ [31]
adapt the gradient descent algorithm to solve path constraint
and learn a model to improve code coverage respectively. All
these studies concentrate on leveraging the ability of deep
learning to cover more code. Different from them, our goal
is to help directed grey-box fuzzers to ﬁlter out the inputs
that cannot hit the buggy code before real execution. In this
way, the time spent on running the program with unreachable
inputs could be saved, which greatly increases the efﬁciency
of fuzzing. Note that our tool can be adapted to existing DGF
tools (e.g., AFLGo), which means that we could further in-
crease the fuzzing efﬁciency together with the performance
boosted by other fuzzers.
3 Motivation
As mentioned above, current DGF aims to generate the inputs
which could reach the speciﬁc buggy code, further expecting
to trigger the bug. In the fuzzing process, lots of inputs cannot
reach the buggy code in the end (impossible to trigger the
bug). Based on our evaluation, more than 91.7% of the inputs
can’t hit the buggy code on average (see Table 1). Executing
millions of unreachable inputs could cost very long time (e.g.,
76 hours for a million inputs when fuzzing Podofo, a library to
work with the PDF ﬁle format with a few tools [1]). Especially,
USENIX Association
29th USENIX Security Symposium    2257
focuses on ﬁltering out unreachable inputs in DGF. In this
way, lots of necessary time on executing the program with
unreachable inputs could be saved. Note that our approach
is complementary to other DGF tools and can work together
with them, instead of replacing them. Also note that we do not
assume that small mutations in the input will produce similar
or identical behavior. The trained model should characterize
different behaviors of similar-looking inputs.
4 Methodology
We propose the design of FuzzGuard, a deep-learning-based
approach to facilitate DGF to ﬁlter out unreachable inputs
without really executing the target program with them. Such a
data-driven approach avoids using traditional time-consuming
approaches such as symbolic execution for better performance.
Below we elaborate the details of FuzzGuard.
4.1 Overview
The overview of FuzzGuard is illustrated in Figure 1, includ-
ing three main phrases: model initialization (MI), model pre-