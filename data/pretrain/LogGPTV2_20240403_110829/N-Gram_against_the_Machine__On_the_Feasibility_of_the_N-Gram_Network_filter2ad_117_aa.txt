title:N-Gram against the Machine: On the Feasibility of the N-Gram Network
Analysis for Binary Protocols
author:Dina Hadziosmanovic and
Lorenzo Simionato and
Damiano Bolzoni and
Emmanuele Zambon and
Sandro Etalle
N-Gram against the Machine: On the Feasibility
of the N-Gram Network Analysis
for Binary Protocols
Dina Hadˇziosmanovi´c1, Lorenzo Simionato2,(cid:2), Damiano Bolzoni1,
Emmanuele Zambon1, and Sandro Etalle1,3
1 University of Twente, The Netherlands
2 Ca’ Foscari University of Venice, Italy
3 Technical University of Eindhoven, The Netherlands
Abstract. In recent years we have witnessed several complex and high-
impact attacks speciﬁcally targeting “binary” protocols (RPC, Samba
and, more recently, RDP). These attacks could not be detected by current
– signature-based – detection solutions, while – at least in theory – they
could be detected by state-of-the-art anomaly-based systems. This raises
once again the still unanswered question of how eﬀective anomaly-based
systems are in practice. To contribute to answering this question, in this
paper we investigate the eﬀectiveness of a widely studied category of
network intrusion detection systems: anomaly-based algorithms using n-
gram analysis for payload inspection. Speciﬁcally, we present a thorough
analysis and evaluation of several detection algorithms using variants
of n-gram analysis on real-life environments. Our tests show that the
analyzed systems, in presence of data with high variability, cannot deliver
high detection and low false positive rates at the same time.
1
Introduction
While most of the current commercial network intrusion detection systems (NIDS)
are signature-based, i.e., they recognize an attack when it matches a previously
deﬁned signature, there is a large body of literature on anomaly-based detec-
tion. An anomaly-based NIDS raises an alert when the observed input does not
match the behavior that was previously observed; the underlying assumption
being that attack payloads “look diﬀerent” than normal network traﬃc. In prin-
ciple, anomaly-based NIDS have one great advantage over signature-based ones:
they can detect threats for which there exists no signature yet, including zero-day
and targeted attacks. Targeted attacks are so complex and evasive that by deﬁ-
nition cannot be detected by signature-based systems (false negative problem).
One famous example of targeted attack is Stuxnet [14], a malware designed to hit
speciﬁc embedded systems used in Iranian installations for uranium enrichment,
discovered in the late 2010. The subsequent analysis revealed that the malware
(cid:2) The author carried out part of this work while he was a visiting student at the
University of Twente. Current aﬃliation: Google Inc.
D. Balzarotti, S. Stolfo, and M. Cova (Eds.): RAID 2012, LNCS 7462, pp. 354–373, 2012.
c(cid:2) Springer-Verlag Berlin Heidelberg 2012
On the Feasibility of the N-Gram Network Analysis for Binary Protocols
355
exploits two previously unknown vulnerabilities in network services. Thus, while
the ﬁnal target was a component typical of industrial control systems, (some
of) the vulnerabilities aimed at infecting local computers. Hence, those vulner-
abilities could have been used to attack “regular” business and home systems.
Other attacks speciﬁcally designed to target Industrial Control Systems (ICS -
which includes of nuclear power plants, oil and gas extraction and distribution
facilities) have been disclosed recently [3].
Given that signature-based systems are ineﬀective against targeted and zero-
day attacks and that most likely there exists no signature yet for the great
majority of the attacks that one can buy on the black market, an eﬀective
anomaly-based NIDS would be the silver bullet thousands of enterprises and
governments are looking for.
Problem & Contribution. Although the ﬁeld of anomaly detection is well estab-
lished in research, to date there are only few actual deployments of anomaly-
based NIDS worldwide. A common reason used for explaining this is that such
systems show poor performance with respect to false positive rate in real-life en-
vironments. More generally, Sommer and Paxson [29] argue that many machine
learning approaches (which are typically used in anomaly-based IDS) are not
eﬀective enough for real-life deployments.
With this paper we want to shed a new light on the detection capabilities of
anomaly-based NIDS for payload inspection. We do so by focusing on systems
employing a form of n-gram-analysis as anomaly detection engine. To perform
the analysis, we apply selected algorithms to environments that widely utilize
binary protocols. Speciﬁcally,
– We perform thorough benchmarks using real-life data from binary-based
protocols, which have been lately targeted by high-impact cyber attacks,
– We include in the analysis a protocol that is speciﬁc for Industrial Control
Systems (also known as “SCADA”),
– We analyze and discuss the reasons why certain attack instances are (not)
detected by the chosen approaches,
– We discuss the feasibility of deploying such approaches in real-life environ-
ments, in particular w.r.t. the false positive rate, an issue that is seldom
discussed by authors in their work.
Our experiments show that n-gram analysis cannot be indiscriminately applied
to the whole network stream data, and that data with high variability are diﬃcult
to model and analyze, conﬁrming the conclusion of some earlier work on the
matter (see Section 6 for a more detailed discussion).
2 Preliminaries
In this section we introduce the concepts and the terminology that will be used
in the remaining of the paper.
356
D. Hadˇziosmanovi´c et al.
2.1 Anomaly-Based Network Intrusion Detection Systems
A detection system can use diﬀerent sources to extract data features, namely
network traﬃc or system/application activities. In this embodiment we focus
on network-based approaches. These approaches monitor the network traﬃc in
a transparent way, without aﬀecting the host performance and are thus often
preferred over host-based approaches. There are two types of anomaly-based
NIDS: (1) systems that analyse network ﬂows and (2) systems that analyse the
actual payload. A ﬂow-based approach takes into consideration features such
as the number of sent/received bytes, the duration of the connection and the
layer-4 protocol used. A payload-based approach considers features of individual
packet or communication payloads. Despite being complementary, the payload-
based approaches oﬀer higher chances of detecting a broader set of threats and,
unlikely ﬂow-based, these approaches can capture “semantic attacks”. Semantic
attacks exploit “a speciﬁc feature or implementation bug of some protocol or
application installed at the victim” [25]. In addition, most of the top security
risks (such as in the “OWASP Top 10” [33]) require the injection of some data
to exploit the vulnerability. Thus, we focus on payload-based approaches.
2.2 Binary Protocols
In contrast to text-based network protocols (such as HTTP, POP and SMTP),
binary protocols are designed to be processed by a computer rather than a
human. Such protocols are largely used in network services, such as distributed
ﬁle systems, databases, etc. In practical terms, the network payload of a binary
protocol is more compact if compared to text protocols, often unreadable by
a human and may resemble to attack payloads (since malware packets often
consists of binary fragments too). Due to these reasons the challenge of detecting
attacks in binary-based data is typically greater than in text-based data.
2.3 N-Gram Analysis
N-gram analysis is a common technique for capturing features of data content.
This technique is used in various areas, such as monitoring system calls [16], text
analysis [10], packet payload analysis [35]. In the context of network payload
analysis, the current approaches use the concept of n-grams in diﬀerent ways. In
particular, we distinguish two aspects:
1. The way an n-gram builds feature space - The extracted n-grams can be
used for building diﬀerent feature spaces [12]: (a) count embedding (count
the number of diﬀerent n-grams to describe the payload), (b) frequency
embedding (use relative frequency of byte values of an n-gram to describe the
payload, e.g. [1,6,36]) and (c) binary embedding (use the presence/absence
of speciﬁc n-grams to describe the payload, e.g., [35]).
2. The accuracy of payload representation - N-grams can represent the payload
in the following ways: (a) as an exact payload description (n-grams represent
On the Feasibility of the N-Gram Network Analysis for Binary Protocols
357
continuous sequences of bytes, e.g. in [6,35,36]) and (b) as an approximated
payload description (n-grams represent a compression or a reduction of the
exact payload, e.g., [17,28]).
Also, various systems employ diﬀerent architectures and combinations of ap-
proaches to analyze n-grams (e.g., Markov models in [1], Self-Organizing Maps
in [6], hashing in [17]).
For performing our benchmarks we choose algorithms that are conceptually
diﬀerent in the way the n-gram analysis is performed. Unfortunately, our choice
is also limited to the availability of implementations and the level of details in
algorithm descriptions.
2.4 Description of Analysed Systems
In the remaining of the section we introduce four algorithms that we select
for testing: PAYL, POSEIDON, Anagram and McPAD. These algorithms are
1) general-purpose enough to be used with multiple application-level protocols,
2) proposed by often cited papers in the IDS community or 3) claiming to im-
prove over the previous ones. Each algorithm requires as an input only the in-
coming network traﬃc, and does not perform any correlation between diﬀerent
packets.
PAYL. Wang and Stolfo in [36] present their 1-gram-based payload anomaly
detector (PAYL). The system detects anomalies by combining 1-gram analysis
algorithm with a classiﬁcation method based on clustering of packet payload
data length. The system employs a set of models: a model stores incrementally
the resulting values of the 1-gram analysis for packet payloads of length l, thus
each payload length has a diﬀerent model. Each model stores two data series:
mean byte frequency (i.e., relative byte frequencies span across several payloads
of length l) and byte frequency standard deviation for each byte value (i.e., how
relative byte frequencies change across payloads). During the detection phase,
the same values are computed for incoming packets and then compared to model
values: a signiﬁcant diﬀerence from the model parameters produces an alert.
When PAYL fails to detect an attack. Fogla et al. [15] show that PAYL’s detec-
tion can be evaded by mimicry attacks. PAYL is vulnerable to mimicry attacks
since it models only 1-gram byte distributions. By carefully crafting an attack
payload, an attacker is able to deceive the algorithm with additional bytes, which
are useless to carry on the attack, but match the statistics of normal models.
POSEIDON. Bolzoni et al. present POSEIDON [6], a system built upon a
modiﬁed PAYL architecture. PAYL uses data length ﬁeld for choosing the right
model. By contrast, POSEIDON employs a neural network to classify packets
(and thus choose the most similar model) during the preprocessing phase. The
authors use Self-Organizing Maps (SOMs) [19] to implement the unsupervised
358
D. Hadˇziosmanovi´c et al.
clustering. First, the full packet payload is analyzed by the SOM, which returns
the value of the most similar neuron. That neuron model is then used for the
calculation of byte frequency and standard deviation values, as in PAYL.
When POSEIDON fails to detect an attack. Diﬀerently from PAYL, POSEIDON
is more resilient to mimicry attacks due to the combination of SOM and PAYL.
The SOM analyzes the input by taking into consideration byte value at i-th
position within the whole payload. Thus, extra bytes inserted by the attacker
would be taken into consideration as well, resulting in a diﬀerent classiﬁcation
than normal traﬃc. However, the granularity of the classiﬁcation done by the
SOM is coarse. Thus, if the attack portion of the sample payload is small enough,
then the sample could be assigned to one of the clusters containing models
of regular traﬃc, and may go unnoticed because of a similar byte frequency
distribution.
Anagram. Wang et al. [35] present Anagram. The basic idea behind Anagram
is that the usage of higher-order n-grams (i.e., n-grams where n > 1) helps to
perform a more precise analysis. However, the memory needed to store average
and standard deviation values for each n-gram grows exponentially (256n, where
n is the n-gram order). For instance, 640GB of memory would be needed to store
5-grams statistics. To solve this issue, the authors propose to use a binary-based
n-gram analysis and store the occurred n-grams eﬃciently in a Bloom ﬁlters [5].
The binary-based approach implies a simple recording of the presence of distinct
n-grams during training. Since less information is stored in the memory, it be-
comes possible to eﬀectively use higher-order n-grams for the analysis. Authors
show that this approach is more precise than the frequency-based analysis (e.g.,
used in PAYL) in the context of network data analysis. This is because higher-
order n-grams are more sparse than low-order n-grams, and gathering accurate
byte-frequency statistics becomes more diﬃcult as the n-gram order increases.
When in detection mode, the current input is ranked using the number of
previously unseen n-grams.
When Anagram fails to detect an attack. There are two main reasons why Ana-
gram may fail to detect attack attempt. Firstly, the Bloom ﬁlter could saturate
during training. This is because the user may underestimate the number of
unique n-grams and allocates a small Bloom ﬁlter, during testing any n-gram
would be considered as normal. Secondly, Anagram will likely miss the detection
if the attack leverages a sequence of n-grams that have been observed during
testing.
McPAD. Perdisci et al. present “Multiple-classiﬁer Payload-based Anomaly
Detector” (McPAD) [28] with a speciﬁc goal of an accurate detection of shell-
code attacks. The authors use a modiﬁed version of the 2-gram analysis, com-
bined with a group of one-class Support Vector Machine (SVM) classiﬁers [34].
The 2-gram analysis is performed by calculating the frequency of bytes that are
On the Feasibility of the N-Gram Network Analysis for Binary Protocols
359
ν positions apart from each other. By contrast, a typical 2-gram analysis mea-
sures the frequency of 2 consecutive bytes. By varying the parameter ν, McPAD
constructs several representation of the payload in diﬀerent feature spaces. For
example, for ν=0..m, McPAD builds m diﬀerent representations of the packet
payload. When in testing mode, a packet is ﬂagged as anomalous if a combination
(e.g., majority) of SVM outputs acknowledge the payload as anomalous.
When McPAD fails to detect an attack. By design, McPAD tries to give a wide
representation of the payload (i.e. add more context by constructing byte pairs
that are several positions apart). This may represent a diﬃculty in two cases.
First, this is an approximate representation and that may imply a poorly de-
scribed payload in case of slight diﬀerences between the training sample and an
attack [1]. This may lead to a high false positive rate and a low detection rate.
Secondly, McPAD uses diﬀerent classiﬁers that have to come into an “agree-
ment” to decide if a particular packet is anomalous or not. A problem may arise
when, due to an approximate payload representation, several classiﬁers are mis-
led by the byte pair representation and result in outvoting “correct” classiﬁers.
In such case, the system might miss the detection.
3 Approach
We believe that one of the main reasons for poor performance of anomaly-based
NIDS lies in the intrinsic limitation of commonly applied algorithm for con-
tent analysis: n-gram analysis. Since performing a comprehensive test to verify
the ability of an IDS of identifying (all) attacks and to spot its weaknesses is
unfeasible [22], we proceed to experimentally address our claim. We present a
comparative analysis and evaluate the eﬀectiveness of anomaly-based algorithms
that analyse network payloads by using some form of n-gram analysis.
To verify the eﬀectiveness of diﬀerent algorithms we execute a number of
steps: 1) collect network and attack data, 2) obtain a working implementation
of each algorithm, 3) run the algorithms and analyse the results.
Obtaining the data. We acknowledge that optimal conditions for evaluating the
performance of an IDS consist of running tests on unprocessed data from real
networks [2]. Thus we ﬁrst collect real-life data from diﬀerent network environ-
ments, which are currently being operated. The past research is typically focused
on benchmarking the algorithms with the HTTP protocol, although the authors
do not explicitly restrict the scope of their algorithms to this protocol. We fo-
cus on the analysis of binary protocols. In particular, we analyse an example of
a binary protocol found in a typical LAN (such as a Windows-based network
service) and an example of a binary protocol typically found in an ICS.
Windows is the most used OS in the world, and every instance runs by de-
fault certain network services that are often used within LANs. For instance,
the SMB/CIFS protocols [20] are used to exchange ﬁles between two comput-
ers, while other services (e.g. RPC) run on the top of it to provide additional