ACOBE may not be able to identify cyber compromises.
Figure 5(e) depicts the anomaly scores derived by all-in-
one model. The included features are the same features
in device-access, ﬁle-accesses, and HTTP-accesses aspects,
and the model conﬁgurations are identical to the one for
ACOBE. Considering the usage of thumb drives is criti-
cally abnormal under this scenario, this model is not ideal,
Figure 4. Example of Abnormal Behavioral Deviations
tures), during working hours and off hours, respectively. The
lower two sub-ﬁgures are behavioral deviation in the HTTP-
access aspect (with seven features), during working hours
and off hours, respectively. The star markers at the bottom
indicate the labeled abnormal days; however, unlabeled days
are not necessarily normal, as we observed identical events
being both labeled and unlabeled. Behavioral deviations
σf,t,d are in range [−Δ, Δ] = [−3, 3]. We can see in that this
user JPH1910 has abnormal deviation pattern in the HTTP
upload-doc feature (ﬁrst row) starting from January. These
deviations are caused by uploading “resume.doc” to several
websites, and these events also cause noticeable deviation in
the HTTP new-op feature (last row). Dark deviations have
white tails, because sliding history window is applied (as
they change mean and std that were used in deriving latter
σf,t,d; note, the length of tails depends on the window size).
B. Research Questions
ACOBE is different from prior work (e.g., [6], [8]) in
designs, and we are interested in the following questions:
1) How does reconstructing multiple days help with de-
tection of abnormal users in a large-scale organization?
2) How does including group deviations help?
3) How does splitting behavioral aspect help?
To answer these questions, we present r6.1 Scenario 2
in Figure 5. Each sub-ﬁgure depicts the trends of anomaly
scores of 114 users in the department, to which JPH1910
belongs. The black line depicts the score trend of the
abnormal user, and the grey lines depict the score trends of
113 normal users. The star markers at the bottom indicate the
labeled abnormal days. Mean and standard deviation (std)
on top of each sub-ﬁgures are derived by all data points in
each sub-ﬁgure. From Figure 5(a) and Figure 5(b), we can
see that JPH1910 has higher anomaly scores on the dates
when we observe the abnormal patterns shown in Figure 4.
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:27 UTC from IEEE Xplore.  Restrictions apply. 
256
(a) ACOBE (Device)
(b) ACOBE (HTTP)
(c) Single-Day Reconstruction (HTTP)
(d) Excluding Group Deviations (HTTP)
(e) All-in-One Autoencoder
(f) Baseline
Figure 5. Trends of anomaly scores of 114 users in r6.1 Scenario 2 under different model conﬁguration
because the waveform is not as outstanding as shown in
Figure 5(a). Without emphasis on the device-accesses aspect,
this model may wrongly report normal users that have
slightly chaotic behaviors in the other aspects. A common
approach to resolve the drawback is to deploy an ensemble
of autoencoders that each takes responsibility in one aspect
(related work includes [5]–[7], [25]). This approach gives
each autoencoder only necessary features and thus reduces
the unwanted noise.
C. Comparison with Prior Work
We compare our work with a state-of-the-art deep autoen-
coder model that works on the same dataset proposed by Liu
et al. [6]. We refer to their model as the Baseline model.
The differences between ACOBE and Baseline include the
followings. First, for each user, Baseline builds four au-
toencoder for coarse-grained unweighted features from the
numbers of activities (e.g., connect, write, download, logoff)
in four aspects (i.e., device, ﬁle and HTTP, and logon),
whereas ACOBE builds three autoencoders for ﬁne-grained
weighted behavioral deviations that also include new-ops
and ﬁle types. Second, Baseline reconstructs normalized
features on individual days, whereas ACOBE reconstructs
behavioral deviations across multiple days. Third, Baseline
does not take group features into consideration, whereas
ACOBE embeds group deviations into compound behavioral
deviation matrices. Fourth, Baseline splits one day into 24
time-frames (i.e., 24 hours), whereas ACOBE splits one day
into two (i.e., working hours and off hours); yet, the number
of time-frames contribute negligible performance difference
for this dataset.
From the discussions in the previous section, we anticipate
that Baseline may not perform well due to the above
differences. Figure 5(f) depicts the anomaly scores of users
under r6.1 Scenario 2, and the scores of the abnormal user
do not stand out on any dates. To have a fair comparison,
we also build an alternative Baseline model that leverages
our ﬁne-grained features, and we refer to the new detection
model as the Base-FF model. We implement Baseline and
Base-FF with Tensorﬂow 2.0.0. Each fully connected layer
is implemented with tensorﬂow.keras.layers.Dense activated
by ReLU. The numbers of hidden units at each layer in the
encoder are 512, 256, 128, and 64; the numbers of hidden
units in the decoder are 64, 128, ,256, and 512. Between lay-
ers, tensorﬂow.keras.layers.Batch-Normalization is applied;
it serves the purpose of optimizing training procedure [34].
To train the model, Adadelta optimizer is used in minimizing
the Mean-Squared-Error (MSE) loss function.
We leverage the below metrics to compare the models,
where T P , F P, T N, and F N denote the numbers of true
positives, false positives, true negatives, and false negatives,
respectively. These numbers are determined by the number
of how many user investigations the security analysts can
conduct. For example, say security analysts can investigate
1% of the users, and a user Ui has its investigation priority
ranked at less than 1%, then Ui is considered to be abnormal
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:27 UTC from IEEE Xplore.  Restrictions apply. 
257
(a) ROC (TP Rate - FP Rate) Curve
(b) Precision-Recall Curve
(c) Precision-Recall Curve
Figure 6. Comparisons Between Models
and will be investigated. Say, Ui is however normal, then Ui
is a FP case. Similarly, say Uj has its priority ranked greater
than 1% and thus is marked as normal while Uj is indeed
abnormal, then Uj is a FN case.
TP Rate =
Precision =
T P
T P + F N
T P
T P + F P
FP Rate =
Recall =
F P
F P + T N
T P
T P + F N
Previous work was evaluated by the area under Receiver
Operating Characteristic (ROC) curve, where the X-axis rep-
resents the FP Rate, and the Y-axis represents the TP Rate.
Figure 6(a) depicts the ROC curves of different models. The
ROC curve is useful when security experts conduct orderly
investigations upon ordered users, as the curve depicts the
expected trade-offs between TP Rate and FP Rate throughout
the investigation process. Basically, the larger the area under
the curve, the better the anomaly detection approach is. Since
we only have four positive (abnormal) cases, we only have
four data points on each curve. Note that, if a FP and a TP
has the same top N-th rank, the FP is listed before the TP
to illustrate the worst-case investigation order. For reference
purpose, we also include the models we have discussed in
previous subsections in this comparison, namely, Excluding
Group Deviations (No-Group), Single-Day Reconstruction
(1-Day), and All-in-one Autoencoder (All-in-1).
In Figure 6(a), the curve of ACOBE is almost a right-angle
line, and the areas under ROC curves (AUC) is 99.99%.
There are in total 0, and 1 FP (out of 925 normal users)
listed before the 3rd and 4th TPs, respectively (that is, the
users on top of the investigation list are [TP, TP, TP, FP, TP,
. . .] , and recall that there are only four TPs). We can see that
ACOBE outperforms Baseline (with AUC of 99.23%) and
Base-FF (with AUC of 99.54%), as well as other sub-optimal
conﬁgurations. Baseline has 1, 1, 17, and 18 FPs listed
before its 1st, 2nd, 3rd, and 4th TPs, respectively. Base-FF
has 1, 1, 10, and 10 FPs, respectively. If Baseline constantly
provides results with 18/925 FP Rate, security analysts
could be overwhelmed in conducting timely investigation
depends on the scale of the organization.
We also present the Precision-Recall curve in Figure 6(b),
as ROC metric is known to be misleading (overly optimistic)
for imbalanced dataset [35] due to the signiﬁcantly larger
number of negative cases. In Figure 6(b), the X-axis rep-
resents the recall, and the Y-axis represents the precision.
The importance of this curve includes that the calculations
do not make use of the number of TNs, and thus the curve
is concerned with only the correct prediction of the small
number of positive cases. Based on the Precision-Recall
curves, we can differentiate ACOBE from Baseline and
Base-FF by a large margin. For reference, while ACOBE’s
works with N = 3, we also plot the curves of alternative
ACOBE’s that work with N = 2 and N = 1 in Figure 6(c).
Based on the above, we conclude that ACOBE outper-
forms the Baseline model by a large margin in terms of
the Precision-Recall metric, meaning that ACOBE is more
effective in correctly ranking abnormal users before normal
users when providing an ordered investigation list.
VI. CASE STUDIES UPON REAL DATA
We applied ACOBE to a real-world enterprise dataset. We
gathered a set of audit logs that spans seven months. Audit
logs were generated on Windows servers and web proxies,
and they were gathered through the ELK stack [36]; note
that, we do not have audit logs from endpoints. This dataset
spans seven months, including six months of training set and
one month of testing set.
Ethics: It is important to note that our enterprise set is
anonymized where possible privacy concerns are carefully
addressed. All identiﬁable and personal information (e.g.,
user names/IDs and email addresses) are replaced with
securely hashed pseudo information before use.
A. Audit and Attack Scenarios
Our Windows servers provide logs of the following
audit categories: Windows-Event auditing (for application,
security, setup, and system events), PowerShell audit-
ing (Microsoft-Windows-PowerShell/Operational), System-
Monitor auditing (Microsoft-Windows-Sysmon/Operational),
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:27 UTC from IEEE Xplore.  Restrictions apply. 
258
(a) Ransomware’s Anomaly Score
(b) Zeus-Bot’s Anomaly Score
Figure 7. Case Studies: Ranwomware and Zeus-Bot
and DNS-query logs. To reduce daily log size, we discard
events of noisy and redundant event types, including Process
Access (event ID: 10). Web proxies provide its native system
and service logs (including syslog and DHCP logs) and
informative proxy logs (where each entry includes user,
source, destination, resources, and various security verdicts).
For presentation purpose, we present only employee
accounts (say, alice is an employee acount), but em-
ployee
activities
from) computer accounts (e.g., alice$), email accounts
(e.g., PI:EMAIL), and domain accounts (e.g.,
ENT\alice). Note that, we exclude service accounts (e.g.,
httpd), and privileged accounts (e.g., root) from this case
study, because they do not demonstrate habitual patterns like
human. By doing so, we have 246 employees in this dataset.
To work with this dataset, we launched the following two
integrated with (have
attacks in the same environment under control.
accounts
are
• Zeus Botnet: Malicious activities include downloading
Zeus from a downloader app, deleting this downloader
app, and modifying registry values. Our Zeus bot also
made queries to non-existing domains generated by
newGOZ (a domain generation algorithm found in
Gameover Zeus and Peer-to-Peer Zeus [37], [38]).
• Ransomware: We use the WannaCry samples avail-
able in Malware DB [39]. Malicious activities include
modifying registry values and encrypting ﬁles.
B. Behavioral Feature Engineering
We design a set of behavioral features for ACOBE to
work with this real-world dataset. However, note that we
want to emphasize only that “ACOBE can be applied to real
audit logs in practice”, but not that “we have fairly working
features”. It is hard to craft good behavioral features by hand
for a complex dataset, and we are aware that our feature
design is not perfect. For presentation purpose, we split
our features into two categories listed below; for simplicity,
we present only the features that are related to this case
study. That said, we have in total 27 behavioral features,
16 of which from four behavioral aspects (namely, File,
Command, Conﬁg, and Resource) and 11 from statistical
aspects (namely HTTP and Logon). The window size for
our compound behavioral deviation matrix is two weeks.
1) Predictable Behavioral Aspects: When dependency or
causality exists among consecutive events, we may predict
upcoming events based on a sequence of events. To measure
how an event sequence deviates from a user’s habitual
pattern, we may leverage deep-learning based anomaly de-
tection model for discrete events (e.g.,DeepLog [40]). In this
case study, we present two (out of four) predictable aspects
for this dataset: File accesses such as ﬁle-handle operations,
ﬁle shares, and Sysmon ﬁle-related events (event IDs: 2,
11, 4656, 4658-4663, 4670, 5140-5145), and Command ex-
ecutions such as process creation and PowerShell execution
(1, 4100-4104, 4688). For simplicity, we present only the
following three features.
• f1: the number of events during a period
• f2: the number of unique events during a period
• f3: the number of new events during a period
2) Statistical Behavioral Aspects: When we cannot eas-
ily predict upcoming events, we may craft statistical features
for statistically structural behaviors. For example, Siadati
et. al [41] built features for structural logon patterns in an
enterprise. Similarly, we present one (out of two) statistical
behavioral aspect: HTTP trafﬁc. For simplicity, we present
only the following four features.
• f1: # of successful requests during a period P
• f2: # of successful requests to a new domain during P
• f3: # of failure requests during P
• f4: # of failure requests to a new domain during P
C. Detection Results
We showcase how malicious activities impact the victim’s
behavioral matrix and anomaly scores in the two cyber attack
scenario. We have 246 employees, and one of which is under
the aforementioned two attacks on Feb 2nd.
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:27 UTC from IEEE Xplore.  Restrictions apply. 
259
Figure 7(a) and Figure 7(b) show examples of how each
aspect affects the anomaly scores. We see that the waveforms
have signiﬁcant rises after the attack day (i.e., Feb 2nd).
In both attack scenarios, we see positive deviations in the
Command aspect. These deviation are caused by the newly
observed executions of the malware programs. Since the
victim barely has any activities in the Command aspect, such
deviations are signiﬁcant. Though not shown in this paper,
we see the same positive deviation in the Conﬁg aspect, as
two attacks both modiﬁed registry values shortly after being
triggered. In the ransomware scenario, deviations in the File
aspect are caused by newly observed read, write, and delete
operations conducted by the malware. In the botnet scenario,
deviations in the HTTP aspect are caused by successful
connections to the C&C server and failure connections to
newGOZ domains.
Considering all aspects together, our victim is ranked at
1st place in ACOBE’s investigation list from Feb 3rd to Feb
15th with both ransomware and botnet malware. Security
analysts can easily ﬁnd the attacks if periodic investigation
is enforced. In addition, we observe the followings: First,
normal users together demonstrate a main stream of score
trends. We can see that normal users have rises in Command
and drops in HTTP on Jan 26th due to a environmental
change. This again indicates that it is important to examine
behavioral correlation between an individual and its group.
Second, although the attack day is on Feb 2nd, the wave-
forms of File and HTTP do not demonstrate immediate and