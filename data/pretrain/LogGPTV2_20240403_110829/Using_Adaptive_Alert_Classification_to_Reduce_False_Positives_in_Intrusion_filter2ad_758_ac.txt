### Alerts and Intrusions
- Alerts with the same signature.
- Alerts classified as intrusions.

### Aggregation of Attributes
Aggregates 2 and 3 were calculated in a manner similar to the first set of attributes, but within time windows of 5 and 30 minutes, respectively. This choice of background knowledge, motivated by heuristics used in alert correlation systems, is somewhat ad-hoc and reflects the author's expertise in classifying IDS (Intrusion Detection System) attacks. Given that this background knowledge is not specifically tailored to the training data, it is natural to question its utility for alert classification. The following sections address this issue.

### 3.4 Results from the DARPA 1999 Data Set
Our experiments were conducted in two stages. In the first stage, we evaluated the performance of the classifier and the impact of adding background knowledge on the accuracy of classification. The results from this stage allowed us to set some parameters in ALAC. In the second stage, we assessed the performance of ALAC in both recommender and agent modes.

#### Background Knowledge and Setting ALAC Parameters
Here, we present the results of experiments conducted to evaluate the background knowledge and to set ALAC parameters. Note that in these experiments, we used only the machine learning component of ALAC, specifically the RIPPER module, to build classifiers for the entire data set. We refer to these results as batch classification.

Since the behavior of classifiers depends on the assigned costs, we used ROC (Receiver Operating Characteristic) analysis [29] to evaluate the performance of our classifier under different misclassification costs. Figure 2(a) shows the performance of the classifier using data with varying amounts of background knowledge. Each curve was plotted by varying the cost ratio for the classifier. Each point on the curve represents results obtained from 10-fold cross-validation for a given misclassification cost and type of background knowledge.

As expected, the classifier with no background knowledge (plus series) performs worse than the classifier with simple classifications of IP addresses and operating systems running on the machines (cross series) in terms of false positives. Using background knowledge consisting of the classifications and aggregates introduced in Section 3.3 significantly reduces the false positive rate and increases the true positive rate (star series). Full background knowledge (including additional aggregates in multiple time windows) performs comparably to the reduced one (star vs. box series). In our experiments with ALAC, we decided to use full background knowledge.

ROC curves show the performance of the system under different misclassification costs but do not illustrate how the curve was built. Recall from Section 2.2 that we use the inverse cost ratio in weighting to make RIPPER cost-sensitive and varied this parameter to obtain multiple points on the curve. We used this curve to select good parameters for our model.

ALAC is controlled by several parameters, which we had to set to evaluate its performance. To assess the performance of ALAC as an incremental classifier, we first selected the parameters of its base classifier. The performance of the base classifier at various costs and class distributions is depicted by the ROC curve, and it is possible to select an optimal classifier for a certain cost and class distribution [11]. As these values are not defined for our task, we could not select an optimal classifier using the above method. Therefore, we arbitrarily selected a base classifier that provides a good trade-off between false positives and false negatives, for ICR = 50.

The second parameter is the threshold weighted accuracy (WA) for rebuilding the classifier (see Section 2.2). The value of the threshold weighted accuracy should be chosen carefully as it represents a trade-off between classification accuracy and the frequency of running the machine learning algorithm. We chose a value equal to the accuracy of a classifier in batch mode. Experiments not documented here showed that using higher values increases the learning frequency with no significant improvement in classification accuracy.

We assumed that in real-life scenarios, the system would work with an initial model and use new training examples to modify its model. To simulate this, we used 30% of the input data to build the initial classifier and the remaining 70% to evaluate the system.

### ALAC in Recommender Mode
In recommender mode, the analyst reviews each alert and corrects ALAC misclassifications. We plotted the number of misclassifications: false positives (Figure 3(a)) and false negatives (Figure 3(b)) as a function of processed alerts.

The resulting overall false negative rate (FNR = 0.024) is much higher than the false negative rate for the batch classification on the entire data set (FNR = 0.0076), as shown in Figure 2(a). At the same time, the overall false positive rate (FPR = 0.025) is less than half of the false positive rate for batch classification (FPR = 0.06). These differences are expected due to the different learning and evaluation methods used, i.e., batch incremental learning vs. 10-fold cross-validation. Note that both ALAC and a batch classifier have very good classification accuracy and yield comparable results in terms of accuracy.

### ALAC in Agent Mode
In agent mode, ALAC processes alerts autonomously based on criteria defined by the analyst, as described in Section 2.1. We configured the system to forward all alerts classified as true alerts and false alerts classified with low confidence (confidence < cth) to the analyst. The system discarded all other alerts, i.e., false alerts classified with high confidence, except for a fraction k of randomly chosen alerts, which were also forwarded to the analyst.

Similar to the recommender mode, we calculated the number of misclassifications made by the system. We experimented with different values of cth and sampling rates k. We then chose cth = 90% and three sampling rates k: 0.1, 0.25, and 0.5. Our experiments show that sampling rates below 0.1 cause the agent to misclassify too many alerts and significantly change the class distribution in the training examples. On the other hand, with sampling rates much higher than 0.5, the system works similarly to the recommender mode and is less useful for the analyst.

Notice that there are two types of false negatives in agent mode: those corrected by the analyst and those the analyst is not aware of because the alerts have been discarded. We plotted the second type of misclassification as an error bar in Figure 3(a). Intuitively, with lower sampling rates, the agent will have fewer false negatives of the first type but will miss more alerts. As expected, the total number of false negatives is lower with higher sampling rates.

We were surprised to observe that the recommender and the agent have similar false positive rates (FPR = 0.025 for both cases) and similar false negative rates, even with low sampling rates (FNR = 0.026 for k = 0.25 vs. FNR = 0.025). This seemingly counterintuitive result can be explained by noting that the automatic processing of alerts classified as false positives effectively changes the class distribution in training examples in favor of true alerts. As a result, the agent performs comparably to the recommender.

### Summary of Misclassifications
- **DARPA 1999 Data Set, ICR = 50**
  - **False Negatives and False Positives**:
    - **False Negatives**: The false negative rate (FNR) is 0.024 for the recommender mode and 0.026 for the agent mode with a sampling rate of 0.25.
    - **False Positives**: The false positive rate (FPR) is 0.025 for both the recommender and agent modes.
  - **Alerts Processed**: The number of alerts processed is shown in Figures 3(a) and 3(b).

This summary highlights the effectiveness of ALAC in both recommender and agent modes, with comparable performance in terms of false positive and false negative rates.