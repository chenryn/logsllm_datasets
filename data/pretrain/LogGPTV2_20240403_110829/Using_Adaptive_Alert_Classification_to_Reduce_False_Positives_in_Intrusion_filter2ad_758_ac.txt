– alerts with the same signature,
– alerts classiﬁed as intrusions.
Aggregates2,3 were calculated similarly to the ﬁrst set of attributes, but in
time windows of 5 and 30 minutes, respectively.
This choice of background knowledge, which was motivated by heuristics
used in alert correlation systems, is necessarily a bit ad-hoc and reﬂects the
author’s expertise in classifying IDS attacks. As this background knowledge is
not especially tailored to training data, it is natural to ask how useful it is
for alert classiﬁcation. We discuss the answer to this question in the following
sections.
3.4 Results Obtained with DARPA 1999 Data Set
Our experiments were conducted in two stages. In the ﬁrst stage we evaluated the
performance of the classiﬁer and the inﬂuence of adding background knowledge
to alerts on the accuracy of classiﬁcation. The results presented here allowed us to
set some parameters in ALAC. In the second stage we evaluated the performance
of ALAC in recommender and agent mode.
Background Knowledge and Setting ALAC Parameters. Here we describe the
results of experiments conducted to evaluate background knowledge and to set
ALAC parameters. Note that in the experiments we used only the machine
116
Tadeusz Pietraszek
)
P
T
(
e
t
a
R
e
v
i
t
i
s
o
P
e
u
r
T
 1
 0.995
 0.99
 0.985
 0.98
 0.975
 0.97
 0.965
 0.96
 0
 0.02
 0.04
No background knowledge
Limited: Class IP, Hosts
Limited: Class IP, Hosts, Aggr 1
Full: Class IP, host, Aggr 1+2+3
 0.06
 0.1
False Positive Rate (FP)
 0.08
 0.12
 0.14
(a) DARPA1999 data set
)
P
T
(
e
t
a
R
e
v
i
t
i
s
o
P
e
u
r
T
 1
 0.995
 0.99
 0.985
 0.98
 0.975
 0.97
 0.965
 0.96
 0
 0.02
No background knowledge
Limited: Class IP, Hosts
Limited: Class IP, Hosts, Aggr 1
Full: Class IP, host, Aggr 1+2+3
 0.04
 0.08
 0.06
 0.1
False Positive Rate (FP)
(b) Data set B
 0.12
 0.14
Fig. 2. ROC curves for classiﬁer used with diﬀerent types of background knowledge.
learning component of ALAC, namely a RIPPER module, to build classiﬁers for
the entire data set. Hereafter we refer to these results as batch classiﬁcation.
Since the behavior of classiﬁers depends on the assigned costs, we used ROC
(Receiver Operating Characteristic) analysis [29] to evaluate the performance of
our classiﬁer for diﬀerent misclassiﬁcation costs. Figure 2(a) shows the perfor-
mance of the classiﬁer using data with diﬀerent amounts of background knowl-
edge. Each curve was plotted by varying the cost ratio for the classiﬁer. Each
point in the curve represents results obtained from 10-fold cross validation for a
given misclassiﬁcation cost and type of background knowledge.
As we expected, the classiﬁer with no background knowledge (plus series)
performs worse than the classiﬁer with simple classiﬁcations of IP addresses
and operating systems running on the machines (cross series) in terms of false
positives. Using the background knowledge consisting of the classiﬁcations above
and aggregates introduced in Sect. 3.3 signiﬁcantly reduces the false positive rate
and increases the true positive rate (star series). Full background knowledge
(having additional aggregates in multiple time windows) performs comparably
to the reduced one (star vs. box series). In our experiments with ALAC we
decided to use full background knowledge.
ROC curves show the performance of the system under diﬀerent misclassiﬁ-
cation costs, but they do not show how the curve was built. Recall from Sect. 2.2
that we use the inverse cost ratio in Weighting to make RIPPER cost sensitive
and varied this parameter to obtain a multiple points on the curve. We used this
curve to select good parameters of our model.
ALAC is controlled by a number of parameters, which we had to set in
order to evaluate its performance. To evaluate the performance of ALAC as an
incremental classiﬁer we ﬁrst selected the parameters of its base classiﬁer.
The performance of the base classiﬁer at various costs and class distributions
is depicted by the ROC curve and it is possible to select an optimal classiﬁer for
a certain cost and class distribution [11]. As these values are not deﬁned for our
task, we could not select an optimal classiﬁer using the above method. Therefore
Using Adaptive Alert Classiﬁcation
117
we arbitrarily selected a base classiﬁer that gives a good tradeoﬀ between false
positives and false negatives, for ICR = 50.
The second parameter is the threshold weighted accuracy (W A) for rebuild-
ing the classiﬁer (see Sect. 2.2). The value of threshold weighted accuracy should
be chosen carefully as it represents a tradeoﬀ between classiﬁcation accuracy and
how frequently the machine learning algorithm is run. We chose the value equal
to the accuracy of a classiﬁer in batch mode. Experiments not documented here
showed that using higher values increases the learning frequency with no signif-
icant improvement in classiﬁcation accuracy.
We assumed that in real-life scenarios the system would work with an initial
model and only use new training examples to modify its model. To simulate this
we used 30% of input data to build the initial classiﬁer and the remaining 70%
to evaluate the system.
ALAC in Recommender Mode. In recommender mode the analyst reviews each
alert and corrects ALAC misclassiﬁcations. We plotted the number of misclassi-
ﬁcations: false positives (Fig. 3(a)) and false negatives (Fig. 3(b)) as a function
of processed alerts.
The resulting overall false negative rate (F N = 0.024) is much higher than
the false negative rate for the batch classiﬁcation on the entire data set (F N =
0.0076) as shown in Fig. 2(a). At the same time, the overall false positive rate
(F P = 0.025) is less than half of the false positive rate for batch classiﬁcation
(F P = 0.06). These diﬀerences are expected due to diﬀerent learning and evalu-
ation methods used, i.e., batch incremental learning vs. 10-fold cross validation.
Note that both ALAC and a batch classiﬁer have a very good classiﬁcation
accuracy and yield comparable results in terms of accuracy.
)
n
f
(
s
e
v
i
t
a
g
e
N
e
s
a
F
l
 350
 300
 250
 200
 150
 100
 50
 0
 0
Agent - sampling 0.1
Agent - sampling 0.25
Agent - sampling 0.5
Recommender
Batch Classification
 2000
 1500
)
p
f
(
s
e
v
i
t
i
s
o
P
e
s
a
F
l
 1000
 500
 0
 0
 10000
 20000
 30000
 40000
 50000
 60000
Alerts Processed
 10000
 20000
 30000
 40000
 50000
 60000
Alerts Processed
Fig. 3. False negatives and false positives for ALAC in agent and recommender modes
(DARPA1999 data set, ICR=50).
ALAC in Agent Mode. In agent mode ALAC processes alerts autonomously
based on criteria deﬁned by the analyst, described in Sect. 2.1. We conﬁgured
the system to forward all alerts classiﬁed as true alerts and false alerts classiﬁed
118
Tadeusz Pietraszek
with low conﬁdence (conf idence < cth) to the analyst. The system discarded all
other alerts, i.e., false alerts classiﬁed with high conﬁdence, except for a fraction
k of randomly chosen alerts, which were also forwarded to the analyst.
Similarly to the recommender mode, we calculated the number of misclassi-
ﬁcations made by the system. We experimented with diﬀerent values of cth and
sampling rates k. We then chose cth = 90% and three sampling rates k: 0.1,
0.25 and 0.5. Our experiments show that the sampling rates below 0.1 make the
agent misclassify too many alerts and signiﬁcantly changes the class distribution
in the training examples. On the other hand, with sampling rates much higher
than 0.5, the system works similarly to recommender mode and is less useful for
the analyst.
Notice that there are two types of false negatives in agent mode – the ones
corrected by the analyst and the ones the analyst is not aware of because the
alerts have been discarded. We plotted the second type of misclassiﬁcation as an
error bar in Fig. 3(a). Intuitively with lower sampling rates, the agent will have
fewer false negatives of the ﬁrst type, in fact missing more alerts. As expected
the total number of false negatives is lower with higher sampling rates.
We were surprised to observe that the recommender and the agent have sim-
ilar false positive rates (F P = 0.025 for both cases) and similar false negative
rates, even with low sampling rates (F N = 0.026 for k = 0.25 vs. F N = 0.025).
This seemingly counterintuitive result can be explained if we note that auto-
matic processing of alerts classiﬁed as false positives eﬀectively changes the class
distribution in training examples in favor of true alerts. As a result the agent
performs comparably to the recommender.
l
s
t
r
e
A
d
e
d
r
a
c
s
D
i
 30000
 25000
 20000
 15000
 10000
 5000
 0
 0
Agent - sampling 0.1
Agent - sampling 0.25
Agent - sampling 0.5
 10000
 20000
 30000
 40000
 50000
 60000
Alerts Processed
(a) DARPA1999 data set, ICR=50
l
s
t
r
e
A
d
e
d
r
a
c
s
D
i
Agent - sampling 0.1
Agent - sampling 0.25
Agent - sampling 0.5
 30000
 25000
 20000
 15000
 10000
 5000