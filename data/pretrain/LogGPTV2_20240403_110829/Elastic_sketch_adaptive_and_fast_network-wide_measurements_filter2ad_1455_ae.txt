• Flow size distribution: We compare MRAC [17] and Elastic.
• Entropy estimation: We compare UnivMon, Sieving [68],
and Elastic. UnivMon uses the same setting as before. We
use 8 sampling groups in Sieving.
• Cardinality estimation: We compare UnivMon, linear
counting (LC) [59], and Elastic. UnivMon uses the same
setting as before.
7.2 Accuracy
Figure 9(a)-(e) and 10(a)-(b) provide a comparison of the
accuracy of different algorithms for six tasks. Note that Elas-
tic only uses one data structure with memory of 600KB to
handle all six tasks.
Flow size estimation (Figure 9(a)): We find that Elastic of-
fers a better accuracy vs. memory usage trade-off than CM,
CU, and Count sketch. When using 600KB of memory, the
ARE of Elastic is about 3.8, 2.5, and 7.5 times lower than
the one of CM, CU, and Count. We also run the maximum
compression algorithm (§3.2.1) on a CM sketch with initial
16MB memory, and measure its ARE when its memory af-
ter compression (i.e., bandwidth) reaches 0.2, 0.4, ..., 1 MB,
respectively. We find that our compression algorithm signifi-
cantly improves the accuracy of CM sketch, making it nearly
approach the accuracy of Elastic.
Heavy hitter detection (Figure 10(a)-(b)): We find that
Elastic is much more accurate than the other five algorithms
for most memory sizes. Even with less than 200KB of mem-
ory, Elastic is able to achieve 100% precision and recall with
only 0.002 ARE, an ARE much lower than the other five
algorithms.
Heavy change detection (Figure 9(b)): We find that Elas-
tic always achieves above 99.5% F1 score while the best F1
score from the other algorithms is 97%. When using more
than 200KB of memory, the precision and recall rates of Elas-
tic both reach 100%. When using little memory, FlowRadar
can only partially decode the recorded flow IDs and frequen-
cies, causing a low F1 score.
Flow size distribution (Figure 9(c)): We find that Elas-
tic always achieves better accuracy than the state-of-the-
art algorithm (MRAC). When using 600KB of memory, the
(a) Flow size.
(b) Heavy change.
(c) Flow size distribution.
(d) Entropy.
(e) Cardinality.
Figure 9: Accuracy comparison for five tasks. The heavy part in Elastic is 150KB.
each measurement epoch. When measuring the bandwidth
usage of Elastic, we set the original memory to 16MBwith
500KB heavy part, run the maximum compression algorithm
(§3.2.1), and measure the memory usage after compression
(as the bandwidth usage) to achieve the fixed target accuracy.
For the other measurement algorithms, their “memory” is
equal to “bandwidth”.
Monitoring time intervals (Figure 11(a)-(b)): We find
that for flow size estimation, Elastic uses less memory and
bandwidth than other algorithms for most monitoring time
intervals; for heavy change detection, Elastic always uses
much less memory and bandwidth than other algorithms.
Specifically, Elastic uses 150KB memory or bandwidth to
achieve 99% precision and recall rates for heavy change de-
tection, irrespective of the monitoring time interval.
(a) FS: 0.2 ARE.
(b) HC: 0.99 F1 score.
Figure 11: Memory (M.) and bandwidth (B.) usage for flow size
estimation and heavy change detection to achieve target accuracy
under different monitoring time intervals.
(a) FS: 0.2 ARE.
(b) HC: 0.99 F1 score.
Figure 12: Memory (M.) and bandwidth (B.) usage for flow size
estimation and heavy change detection to achieve target accuracy
on different traces.
Traces (Figure 12(a)-(b)): We find that for flow size esti-
mation and heavy change detection, Elastic always uses
less memory and bandwidth than the other algorithms. We
(a) F1 score.
(b) ARE.
Figure 10: Accuracy comparison for heavy hitter detection. The
heavy part in Elastic is 150KB.
WMRE of Elastic is about 3.4 times lower than the one of
MRAC.
Entropy estimation (Figure 9(d)): We find that Elastic of-
fers a better estimation than the other two algorithms for
most memory sizes. When using a memory larger than or
equal to 400KB, Elastic achieves higher accuracy than both
state-of-the-art algorithms.
Cardinality estimation (Figure 9(e)): We find that Elas-
tic achieves comparable accuracy with the state-of-the-art
algorithm (LC).
Observed Worst Cases: Here, we show the observed worst
cases of Elastic in the flow size estimation, instead of the
average errors shown in the above figures. Notice that the
estimation error of Elastic comes from two parts: 1) Some
elephant flows are recorded in the light part due to the hash
collisions in the heavy part, and this may incur overflows of
counters in the light part. 2) Some flows collide at the same
counter in the light part. In our experiments, over different
traces, we observe that at most 2 flows have under-estimation
error, and the maximum absolute error is 254 (i.e., a flow with
size 1 is mapped to an overflowed counter). In each trace,
there are about 110,000 flows and the maximum flow size is
about 17,000. It means Elastic has small relative errors even
in the worst case.
7.3 Memory and Bandwidth Usage
We measure the memory and bandwidth usage of different
algorithms to achieve a fixed target accuracy, using different
traces and different monitoring time intervals. Here, “mem-
ory” refers to the memory that is originally allocated to
and used by the measurement algorithms, while “bandwidth”
refers to the amount of data that needs to be transferred after
 0 2 4 6 8 10 12 14 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1AREMemory/Bandwidth usage (MB)CMCUCountElasticCM (compressed) 0 0.2 0.4 0.6 0.8 1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1F1 scoreMemory usage (MB)ReversibleFlowRadarUnivMonElastic 0 0.05 0.1 0.15 0.2 0.25 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1WMREMemory usage (MB)MRACElastic 0 0.03 0.06 0.09 0.12 0.15 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1REMemory usage (MB)UnivMonSievingElastic 0 0.01 0.02 0.03 0.04 0.05 0.06 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1REMemory usage (MB)UnivMonLCElastic 0 0.2 0.4 0.6 0.8 1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1F1 scoreMemory usage (MB)SSCountHeapCMHeapUnivMonHashPipeElastic0.000100.010001.00000100.00000 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1AREMemory usage (MB)SSCountHeapCMHeapUnivMonHashPipeElastic 0 4 8 12 16 20 24 0 10 20 30 40 50 60Memory / bandwidth (MB)Monitoring time interval (s)CM (M. B.)CU (M. B.)Count (M. B.)Elastic (M.)Elastic (B.) 0 3 6 9 12 0 10 20 30 40 50 60Memory / bandwidth (MB)Monitoring time interval (s)FlowRadar (M. B.)Reversible (M. B.)UnivMon (M. B.)Elastic (M.)Elastic (B.) 0 1 2 3 42015/02/192015/05/212016/01/212016/02/18Memory / bandwidth (MB)CAIDA trace dateCM (M. B.)CU (M. B.)Count (M. B.)Elastic (M.)Elastic (B.) 0 1 2 3 42015/02/192015/05/212016/01/212016/02/18Memory / bandwidth (MB)CAIDA trace dateReversible (M. B.)FlowRadar (M. B.)UnivMon (M. B.)Elastic (M.)Elastic (B.)observe that for flow size estimation, the bandwidth us-
age of Elastic is always less than its memory usage, con-
sistently with Theorem A.7 in Section A.5 of our techni-
cal report [47]. The reason that the bandwidth usage does
not significantly outperform the memory usage is that Elas-
tic itself has achieved extremely high accuracy and thus the
compression algorithm cannot easily improve it further.
7.4 Elasticity
7.4.1 Adaptivity to Bandwidth.
We first evaluate the accuracy of different compression
and merging algorithms. From Figure 13(a)-(b), we find that
the maximum algorithms always achieve better accuracy
than the sum algorithms for both aggregation and merging.
Specifically, maximum compression is between 1.24 and 2.38
times more accurate than sum compression, while maximum
merging is between 1.26 and 1.33 times more accurate than
sum merging.
(a) Compression.
(b) Merge.
Figure 13: Accuracy comparison of different compression and
merging algorithms for CM sketch in flow size estimation.
(a) ARE vs. bandwidth trade-off.
(b) Latency vs. bandwidth trade-off.
Figure 14: ARE and transmission delay comparisons for different
sketch sizes in flow size estimation. We use TCP to transmit data.
Transmitted data refers to the data that needs to be transmitted af-
ter compression (original memory is 16MB with 500KB heavy part).
For more details, please refer to §7.3
Next, we constrain our NIC bandwidth to 0.5Gbps, and
use this 0.5G NIC to evaluate the impact of available band-
width. Figure 14(a)-(b) show the results, where low available
bandwidth means that we transmit sketch data on this 0.5G
NIC with a consistently 0.5Gbps interfered traffic on it, and
high available bandwidth means that we transmit sketch
data without any interference of other traffic. We observe
(a) Packet loss.
(b) Accuracy of HH detection.
Figure 15: Loss rate and accuracy comparisons for heavy hitter
detection under different packet rates. “Elastic (quick)” means Elas-
tic without light part. Due to the constraint of our NIC speed (i.e.,
40Gbps), we simulate the packet arriving process purely in memory
and use ring buffer with multiple threads to do the measurement.
The average number of heavy hitters in each traces is about 397. For
more details, please refer to §6.
that transmitting data under low available bandwidth has a
much longer latency than under high available bandwidth,
and the transmission latency increases almost linearly as the
transmitted data increases. Our Elastic provides a good trade-
off between the accuracy and transmission delay: under low
available bandwidth, we can send high-compression sketch
data with decent accuracy to avoid long transmission delay.
7.4.2 Adaptivity to Packet Rate.
From Figure 15(a)-(b), we find that Elastic can sustain
around 50Mpps packet rate without packet loss and with
perfect accuracy, while Elastic without light part can even
sustain around 70Mpps packet rate. For the other tested algo-
rithms, only Space-Saving (SS) and HashPipe could achieve
zero packet loss and perfect accuracy, but in that case, they
can only sustain 10Mpps packet rate.
7.4.3 Adaptivity to Traffic Distribution.
We change the traffic distribution by changing the per-
centage of true heavy hitters. Specifically, we change the
skewness of zipf distribution [69] and get multiple traces
with different percentages of true heavy hitters. From Fig-
ure 16(a)-(b), we find that the copy operation (§3.4) success-
fully avoids the accuracy degrading when traffic distribution
changes.
(a) Heavy hitter detection.
(b) Flow size distribution.
Figure 16: Benefits of copy operation (§3.4) for heavy hitter detec-
tion and flow size distribution under different traffic distributions.
 0 2 4 6 8 10 12 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1AREMemory usage (MB)SumMaximum 0 2 4 6 8 10 12 14 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1AREMemory usage (MB)SumMaximum 0 1 2 3 4 5 0 2 4 6 8 10 12 14 16ARETransmitted data (MB) 0 0.3 0.6 0.9 1.2 0 2 4 6 8 10 12 14 16Transmission latency (s)Transmitted data (MB)High available bandwidthLow available bandwidth 0 0.2 0.4 0.6 0.8 1 0 20 40 60 80 100 120 140 160Loss ratePacket rate (Mpps)SSCMHeapCountHeapUnivMonHashPipeElastic (normal)Elastic (quick) 0 0.2 0.4 0.6 0.8 1 0 20 40 60 80 100 120 140 160F1 scorePacket rate (Mpps)SSCMHeapCountHeapUnivMonHashPipeElastic (normal)Elastic (quick) 0 0.2 0.4 0.6 0.8 1 0.01 0.02 0.03 0.04 0.05 0.06F1 scoreTrue heavy hitter percentageElastic w/o copyElastic w/ copy 0 0.2 0.4 0.6 0.01 0.02 0.03 0.04 0.05 0.06WMRETrue heavy hitter percentageElastic w/o copyElastic w/ copy7.5 Processing Speed
7.5.1 CPU Platform (single core).
We conduct this experiment on a server with two CPUs
(Intel Xeon PI:EMAIL) and 378GB DRAM. From
Figure 17, we find that Elastic achieves much higher through-
put than all other algorithms. Only three conventional al-
gorithms (i.e., MRAC, Sieving, LC) can reach a throughput
of 30Mpps, while Elastic can reach more than 80Mpps. In
particular, Elastic is 44.9 and 6.2 times faster than UnivMon
and FlowRadar, respectively.
Figure 17: Processing speed comparison for six tasks on CPU plat-
form.
7.5.2 OVS Integration.
We integrate our Elastic into OVS 2.5.1 with DPDK 2.2.
We conduct this experiment on two servers, one for sending
packets and one for OVS. Each server is equipped with two
CPUs (Intel Xeon PI:EMAIL), 64 GB DRAM, and one
Mellanox ConnectX-3 40 Gbit/s NIC. The two servers are
connected directly through the NICs. From Figure 18, we find
that in OVS, the throughput of Elastic gradually increases
as the number of threads increases, while the overhead of
using Elastic gradually decreases. When using a single thread,
Elastic degrades the throughput of OVS by 26.8%; when using
4 threads, by 4.0% only; when using 8 threads, Elastic does
not influence the throughput.
7.5.3 Other Platforms.
From Figure 19, we find that Elastic achieves the highest
processing speed on the P4 switch and the second highest
speed on the GPU. Elastic achieves a comparable processing
speed on the CPU with 16 cores and the FPGA. The pro-
cessing speed of Elastic on CPU (16 cores), GPU (1M batch),
FPGA, and P4 switch is 1.9, 5.9, 1.9, 115.9 times higher than
on the CPU (single core).
8 CONCLUSION
Fast and accurate network measurements are important and
challenging in today’s networks. Indeed, with current highly
variable traffic characteristics, changes in available band-
width, packet rate, and flow size distribution can and do vary
drastically at times. So far, no work had focused on the is-
sue of enabling measurements that are adaptive to changing
traffic conditions.
Figure 18: Processing speed evaluation for Elastic in OVS.
Figure 19: Processing speed comparison for Elastic on different
platforms. For the implementation of CPU with 16 cores, the master
core sends flow IDs to 16 slave cores in a polling manner. We equally
(for both heavy and light parts) divide the 600KB of memory to the
16 slave cores. We deploy the Elastic sketch in P4 switch running
at line-rate of 6.5 Tbps, which translates into 9672Mpps when each
packet has the minimum size of 64 bytes.
We propose the Elastic sketch, which is adaptive in terms
of the three above traffic characteristics. The two key tech-
niques in our sketch are (1) Ostracism to separate elephant
flows from mouse flows and (2) sketch compression to im-
prove scalability. Our sketch is generic to measurement tasks
and works across different platforms. To demonstrate this,
we implement our sketch on six platforms: P4, FPGA, GPU,
CPU, multi-core CPU, and OVS, to process six typical mea-
surement tasks. Experimental results show that Elastic works
well when the traffic characteristics vary, and outperforms
the state-of-the-art in terms of both speed and accuracy for
each of the six typical tasks.
9 ACKNOWLEDGEMENTS
We would like to thank the anonymous reviewers and our
shepherd, Arvind Krishnamurthy, for their thoughtful sug-
gestions. We would like to thank Tao Li and Haiying Du