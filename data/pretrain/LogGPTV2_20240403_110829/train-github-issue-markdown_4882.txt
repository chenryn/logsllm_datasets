#### Description
Unfortunately, I am not 100% sure, that this is a bug, but the LeaveOneOut
cross-validation is at least not behaving as I'd expect.
#### Steps/Code to Reproduce
I use this matrix:  
R A B C D E F G H  
0 149 1 0 0 0 0 0 1 0  
1 98 0 1 0 0 0 0 1 0  
2 72 0 0 1 0 0 0 1 0  
3 74 0 0 0 1 0 0 1 0  
4 124 1 0 0 0 0 0 0 1  
5 71 0 1 0 0 0 0 0 1  
6 53 0 0 1 0 0 0 0 1  
7 64 0 0 0 1 0 0 0 1  
8 186 1 0 0 0 1 1 1 0  
9 127 0 1 0 0 1 1 1 0  
10 121 0 0 1 0 1 1 1 0  
11 104 0 0 0 1 1 1 1 0  
12 98 1 0 0 0 0 1 1 1  
13 64 0 1 0 0 0 1 1 1  
14 38 0 0 1 0 0 1 1 1  
15 17 0 0 0 1 0 1 1 1
and this code to fit R by using A-H:
import pandas as pd  
import numpy as np  
import sklearn  
from sklearn.cross_decomposition import PLSRegression  
from sklearn.metrics import mean_squared_error  
from math import sqrt  
from sklearn.model_selection import LeaveOneOut  
from sklearn.model_selection import cross_val_score
df = pd.read_csv('PSLR.csv', delimiter=';') # I read the matrix from file.
This is the matrix given above  
y = df['R']  
X = df[['A','B','C','D','E','F','G','H']]  
pls2 = PLSRegression(n_components=3)
num_folds = 3  
num_instances = len(X)
loocv = LeaveOneOut()  
results = cross_val_score(pls2, X, y, cv=loocv)  
print("Accuracy: %.3f%% (%.3f%%)" % (results.mean()*100.0,
results.std()*100.0))  
print(results)
#### Expected Results
I expected to get a numerical result from the cross validation
#### Actual Results
Accuracy: 0.000% (0.000%)  
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
#### Versions
System:  
python: 3.7.0 (default, Oct 2 2018, 09:18:58) [Clang 10.0.0
(clang-1000.11.45.2)]  
executable: /usr/local/opt/python/bin/python3.7  
machine: Darwin-18.2.0-x86_64-i386-64bit
BLAS:  
macros: NO_ATLAS_INFO=3, HAVE_CBLAS=None  
lib_dirs:  
cblas_libs: cblas
Python deps:  
pip: 18.1  
setuptools: 40.4.3  
sklearn: 0.20.1  
numpy: 1.15.4  
scipy: 1.1.0  
Cython: None  
pandas: 0.23.4