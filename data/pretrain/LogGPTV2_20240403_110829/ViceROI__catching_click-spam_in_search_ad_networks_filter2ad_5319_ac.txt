 60
 80
 100
Recall (%)
(b) Precision-Recall Curve
e
l
i
t
n
e
c
r
e
P
y
t
i
t
n
a
u
Q
 100
 80
 60
 40
 20
 0
 0
 20
 40
 60
 80
 100
Quality Percentile
(c) Ranking Curve
Figure 3: Performance characteristics of Viceroi, viewed through diﬀerent lenses, as we perform a sweep over threshold values. Arrow
marks the threshold picked by out auto-tuning algorithm given a maximum acceptable false-positive rate of 0.5%.
Figure 4: Bluﬀ ad that we ran to augment the ad network’s
ground-truth heuristic with active measurements.
ad network has two tiers of publishers: premium publishers
(bound by contracts and SLAs), and self-serve publishers
where anyone can sign-up.
Data. We use the premium publishers as our set of eth-
ical publishers to establish Viceroi’s baseline. Viceroi an-
alyzed logs containing millions of ad click records covering
a three week period in January 2013. Each ad click record
contains the publisher, user, revenue, and whether the ad
network’s internal ground-truth heuristic considered it click-
spam. Overall, the raw dataset covers thousands of unique
publishers and millions of unique users.
We augmented the ad network’s internal ground-truth
heuristic using Bluﬀ ads [10]. Bluﬀ ads are ads with nonsense
content (e.g., Figure 4). Few, if any, users are expected to
intentionally click on bluﬀ ads. And since bluﬀ ads haven’t
been adopted yet by any major ad network, click-spam at-
tacks have not yet evolved to avoid them [4]. We ran bluﬀ
ads after we found Viceroi ﬂagging many publishers that
the ad network’s ground-truth heuristic did not ﬂag. After
manual investigation (with some help from the ad network),
we determined the ﬂagged publishers were indeed engaging
in click-spam, and we went about acquiring ground-truth
through Bluﬀ ads to ﬁll gaps in the ad network’s labeling.
Overall our bluﬀ ads had over 4.3M impressions and at-
tracted 7K clicks from 5.6K unique IP addresses and 5.8K
unique referring domains.
Lastly, we use internal ad network metrics on the per-
formance of nearly hundred existing ﬁlters along two axis:
quality and quantity. The lower the false positive score, the
higher the quality. And the more clicks ﬂagged, the higher
the quantity. We use this to benchmark Viceroi against the
industry’s state-of-the-art.
Parameters. The only parameter in our approach is the
maximum acceptable false positive rate (used for automati-
cally tuning the threshold τ ). We perform a full parameter
sweep in our evaluation. The ad network indicated it is
comfortable with a false-positive rate around 0.5%, i.e., the
network is willing to not charge for 0.5% of valid clicks, in
eﬀect giving advertisers a 0.5% discount across the board
as long as Viceroi demonstrates signiﬁcantly higher true-
positive rates.
Evaluation Metrics. We evaluate our approach against
standard metrics for evaluating binary classiﬁers — true
positive rate, false positive rate, precision, and recall. A
true positive (TP) is when both Viceroi and ground-truth
ﬂags a publisher as click-spam; a true negative (TN) is sim-
ilarly when both ﬂag it as not click-spam. A false positive
(FP) is when Viceroi ﬂags a publisher as click-spam while
the ground-truth does not, and vice-versa for false negative
(FN). We take the conservative approach and count all mis-
classiﬁcations against Viceroi even though we are aware that
the ground-truth data is not perfect.
We additionally rank Viceroi’s performance against exist-
ing ad network ﬁlters.
Evaluation. Figure 3 shows the performance character-
istics of our approach through various lenses. Each graph
conducts a parameter sweep on the threshold value τ . The
arrow in each plot marks the optimal value for τ as selected
by our auto-tuning approach given a maximum acceptable
false-positive rate of 0.5%.
Figure 3(a) plots the ROC curve for Viceroi as the thresh-
old parameter is varied. Each point represents some thresh-
old value given a target false positive rate3 (on x-axis); the
y-value is the true positive rate4 at that threshold. The diag-
onal line represents the ROC curve for a completely random
classiﬁer. The ideal operating point is the upper-left corner.
As is evident from the ﬁgure, Viceroi performs quite well —
at 0.5% false positive rate, it achieves 23.6% true positive
rate.
Figure 3(b) plots Viceroi’s Precision-Recall curve as the
threshold parameter is varied. Recall (same as true-positive
rate) tracks what fraction of click-spam we catch. Precision5
tracks the fraction of true positives in everything we catch,
i.e., the more false positives we admit for a given recall, the
lower the precision. The ideal operating point is anywhere
close to the top edge6. Our highest precision on the dataset
is 98.6% at a recall of 2.5%. At the operating point chosen
by our tuning algorithm we have a precision of 88.3% and a
recall of 23.6%.
F P +T N
3False positive rate (F P R) = F P
4Recall = True positive rate (T P R) = T P
5Precision = T P
6Note Viceroi complements existing ad network ﬁlters. A
false-negative for Viceroi, while sub-optimal, is acceptable
because another ﬁlter can still ﬂag it.
T P +F N
T P +F P
Figure 3(c) ranks Viceroi against the existing ad network
ﬁlters. The x-value of any point is its quality percentile, i.e.,
the fraction of ad network ﬁlters with a higher false positive
rate than that approach. The y-value is similarly the quan-
tity percentile, i.e., the fraction of ﬁlters catching fewer clicks
than that approach. The isolated points plot the ranking of
the ad network ﬁlters, and the line plots Viceroi’s ranking as
we vary the threshold. The solid gray diagonal lines divide
the plot into three regions: points in the upper-right region
are high performance ﬁlters that achieve either high quality
percentile and reasonable quantity percentile, or vice versa.
The middle region has moderate performance ﬁlters that
achieve reasonable quality and quantity percentiles. And
the lower-right region has the remaining low performance
ﬁlters. The ideal operating point is the top-right corner,
but there is no approach that simultaneously has the best
rank along both the quality and quantity axis. The ﬁlter
with the highest quality score has quantity percentile of 12,
while the ﬁlter with the highest quantity score has a quality
percentile of 32.
For most threshold values Viceroi operates in the high
performance region of Figure 3(c). At the operating point
chosen by our auto-tuning algorithm, Viceroi has a quality
percentile of 73 and a quantity percentile of 98. There is
only one existing ad network ﬁlter in our dataset that per-
forms better than Viceroi (i.e., to the right of the dotted
diagonal line passing through the arrow). The ﬁlter targets
a very speciﬁc click-spam attack signature in traﬃc origi-
nating from a particular IP address range.
Overall we ﬁnd that Viceroi has very good Precision-Recall
and ROC characteristics, and at the operating point picked
by our auto-tuning algorithm ranks among the best existing
ad network ﬁlters while being far more general.
6. CASE-STUDIES
Viceroi ﬂagged about several hundred publishers out of
the tens of thousands provided. Working with the ad net-
work we manually investigated around hundred websites as-
sociated with the publishers we ﬂagged. Based on manual
investigations Viceroi appears to have caught at least six
(very) diﬀerent classes of click-spam (one of which the ad
network had previously not seen an example of), and caught
at least three diﬀerent publishers in each class. So far we
have manually investigated less than a tenth of the websites
Viceroi ﬂagged. We did not encounter any obvious false
positives out of the publishers we investigated, though there
are several where we do not fully understand their modus
operandi yet.
6.1 Conversion-Spam Enhanced Click-Spam
What: Conversion-spam is a technique used by click-
spammers to increase the potency of their click-spam attacks
as we describe below. Recall from Section 2 that ad conver-
sion events are logged when a user performs some desirable
action on the advertiser’s site, and smart-pricing penalizes
publishers that result in poor conversion rates. Conversion-
spam takes advantage of the fact that smart-pricing, which
reduces the click-spammer’s revenue, relies on the absence
of conversion signals, which simply are HTTP requests ini-
tiated from the user’s browser (Figure 1) that malware can
manipulate.
Conversion-spam. This sets the stage for conversion-spam
as predicted in [29]. A click-spammer who sends clicks, but
not conversions (i.e. buyers), eventually gets smart-priced.
If such a click-spammer were to somehow trigger conversion-
signals on the advertiser’s site, the ad network would be led
to believe that the traﬃc is of good quality and not activate
the smart-pricing discount, thus resulting in higher proﬁts
for the click-spammer.
Viceroi ﬂagged several websites either conﬁrmed or are
highly likely to be engaging in conversion-spam (based on
the evidence we present below). In fact, Viceroi found three
distinct approaches to committing conversion-spam among
the websites we investigated7. Two of these approaches had
previously not been seen operating in the wild. We have
presented our investigation results to multiple ad networks.
Why high ROI: Conversion-spam disproportionately in-
creases the ROI of any given click-spam approach. This
is because the fraudulent conversion-signals deactivate the
publisher smart-pricing discount for not just the advertiser
that suﬀered from conversion-spam, but rather for all adver-
tisers whose ads show up on the publisher’s website. Thus,
a small amount of conversion-spam can cause a signiﬁcant
boost in ROI for the click-spammer. The ingenuity of the
conversion-spam approaches below simply underscores our
insight that click-spammer’s will maximize their proﬁts in
any way they can.
Some that we catch: Proving conversion-spam is hard
because ad networks receive essentially a single-bit conversion-
signal from the advertiser with absolutely no visibility into
what that bit means (i.e., newsletter sign-up or actual sale).
Advertisers typically do not have systems sophisticated enough
to catch conversion-spam in real-time.
We use a novel technique for attracting conversion-spam.
Building upon the Bluﬀ ads approach by Haddadi et al. [10],
we design what we call Bluﬀ forms. Bluﬀ forms are forms on
pages with nonsense content, that ask the user for nonsense
information. These forms are set as the landing page for a
Bluﬀ ad which is known to concentrate click-spam traﬃc.
Figure 5 shows a screenshot of our bluﬀ form — it asks the
user for nonsensical information: mobile pen number, com-
puter eigen name, and eyelid email on a page titled Computer
Repair via Mobile English that users reach after clicking the
overattached zurlite ad (Figure 4) — in other words, complete
nonsense.734 users submitted our bluﬀ form in 26 days.
We heavily instrumented our bluﬀ form using JavaScript
to gather user activity telemetry and logged all HTTP traﬃc
to the server that hosted the bluﬀ form. We then manually
investigated the publishers that sent us these users. We
identiﬁed three distinct classes of conversion-spam. Viceroi
ﬂagged publishers associated with the domains we received
bluﬀ form submissions from.
Type 1: Mostly-Automated (malware driven). We received
315 and 107 bluﬀ form submissions from traﬃc coming from
Reeturn.com and AﬀectSearch.com respectively. Later, in
Section 6.4 we ﬁnd both these publishers use the ZeroAc-
cess malware for click-spam; the ZeroAccess malware family
is known to embed a browser control that allows the malware
to run JavaScript. The time spent on the bluﬀ form by both
sets of traﬃc is uniformly distributed between exactly 60s–
160s; it perfectly ﬁts the line 60 + 100x between x = [0, 1]
(with correlation coeﬃcient r = 0.98 for AﬀectSearch.com
and r = 0.99 for Reeturn.com), i.e., the malware waits ex-
actly 60 + random(100) seconds. After this delay the form is
7We also detected a fourth approach that we are currently
in the process of compiling conclusive evidence about.
Figure 5: Bluﬀ form we used to catch conversion-spam.
submitted without entering any input. We infected a honey-
pot with a ZeroAccess binary we found online and observed
the bot funneling clicks on ads on both AﬀectSearch.com
and Reeturn.com.
Type 2: Semi-automated (potentially, click farm). We re-
ceived 10 bluﬀ form submissions from a family of parked
domain websites like JJBargains.com. Looking among the
domains associated with this publisher that Viceroi ﬂagged,
we noticed that only a small set of users appear (repeatedly)
to be clicking on ads shown by this publisher, and these users
do not appear to click ads for any other publishers in the
dataset.
Interestingly, some (but not all) users present a
malformed user-agent string. All users ﬁlled out neatly for-
matted phone numbers for mobile pen number and a neatly