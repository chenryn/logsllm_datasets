C · l,
qR = q′
T · n and | · | denotes the bit-length of a protocol
message.
2|NC | , where qC = q′
2qC
R · z, qT = q′
R2|NR | + q2
2|σ′
1| +
T
2
than once by any reader.
Proof. This is a game-based proof. By Pr[G], we mean the prob-
ability that A wins in the game G.
G0: This game is the initial game, that is the strong relaying
game against PayBCR. Unlike in this game, we do not use C and R
for the target card and reader; instead, we simply use C and R.
G1: This game is G0, where no NR value is indeed used more
Let qR be the number of NR values issued by readers during
the experiment (this is equal to the number of reader sessions).
The probability that one NR repeats is upper bounded by qR
2|NR | ,
where |NR| is the bitlength of NR. G0 and G1 are identical except
for the failure event that two identical NR values are used. So, we
have Pr[G1] − Pr[G0] ≤ q2
R2|NR | , which is negligible in the security
parameter s if |NR| is in ω (s).
G2: This game is the game G1, with the difference that if the com-
munication between parties R and T is too quick, when NR is sent to
NR←−−− R) < ∆ then
T . Then, Ch aborts the experiment. That is, if t (T
Ch aborts (see Subsection 4.2.2), where ∆ is the communication
time between R and T . If the games continue, then Pr[G2] =Pr[G1].
G3: This game is the game G2, with the difference that if the
communication between parties R and T is too quick, when σ1 is
−−−−−→
t1, σ1
sent to R. Then, Ch aborts the experiment. That is, if t (T
R) < ∆ then Ch aborts (see Subsection 4.2.2). If the games continue,
then Pr[G3]=Pr[G2].
2
2
2
2
T
2|NC | , which is negligible.
G4: This game is the game G3 where σ ′
1 does not repeat itself. Let
qT be the number of σ ′
1 values issued by R during the experiment
as this is equal to the number TPM sessions. The probability that
one σ ′
2
1| , G3 and G4 are identical
1 repeats is upper bounded by qT
2|σ′
except for the failure event that two identical σ ′
1 values are used, so
we have Pr[G4] − Pr[G3] ≤ q2
1| , which is negligible is negligible
2|σ′
in the security parameter s – if |σ ′
1| is in ω (s).
G5: This game is the game G4, with the difference that if the
communication between parties R and C is too quick when σ ′
1 is
σ′
1−−→ C) < t
sent. Then, Ch aborts the experiment. That is, if t (R
B2
then Ch aborts (also, as point (7) in the adversary). If the games
continue, then Pr[G5] = Pr[G4].
G6: This game is the game G5, where no NC value is used
more than once by any card. Let qC be the number of NC val-
ues issued during the experiment, which is equal to the num-
ber of card sessions. The probability that one NC repeats is up-
per bounded by qC
2|NC | . So, G5 and G6 are identical except for the
failure event that two identical NC values are used, so we have
Pr[G6] − Pr[G5] ≤ qC
G7: This game is the game G6, with the difference that if the
communication between parties R and C is too quick when NC is
NC, td←−−−−−− C) <
sent. Then, Ch aborts the experiment. That is, if t (R
B2 then Ch aborts (also, as point (7) in the adversary). If the games
t
continue, then Pr[G7]=Pr[G6].
G8: This is the game G7, except that the card never sends a value
NC that has previously been sent by an adversary through the send
oracle. The idea behind this game transition is to eliminate the event
EG where A can randomly guess a value NC in advance. Note that
the number of calls to the send oracle with respect to NC is bounded
by the number of card sessions, qC. Let qC be the number of calls
to the send oracle. This gives us that Pr[EG] ≤ qC
2|NC | . Therefore,
Pr[G6] − Pr[G5] ≤ qC
G9: This is the final game and is equivalent to the game G8, with
the difference that if the communication between parties R and T
is too quick when NC is sent. Then Ch aborts the experiment. That
NC←−−− R) < ∆ then Ch aborts (see Subsection 4.2.2). If the
is, if t (T
game continues, then Pr[G9]=Pr[G8].
Now we look at the success probability of A in G9, in which
we assume the Out[PC,T ]= 1. Since A controls PC (onboard R), the
output τ[PC,T ] can be tampered with by A.
Note that [W , X] (i.e., the bank) will check σ1, σ2 against t1, t2
and against other inputs that went into σ1, σ2 (e.g., NC which is
part of AC). These would all be provided – in the game– via τ[PC,T ]
to [W , X].
For [W , X] (i.e., the bank) to output 1, the adversary needs to
produce (t′
2 ) that put inside the forged τ[PC,T ] and
with σ∗
Since A controls R, note that A can choose NR (one that has
i
not produced been input to another σ1, given the game in which
we are). Also, even if he does not control C, A can also choose one
such fresh NC – since it controls the channel between C and R. If
he chooses one such fresh NC, it also needs to forge the MAC AC
1, σ∗
being valid signatures by T on t′
i
2|NC | , which is negligible.
(with i ∈ {1, 2}).
1 ) and (t′
2, σ∗
2
Session 2: Authentication ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan99(which will be part of τ[PC,T ]). If the AC is produced with a MAC
that resists existential forgery, then this is negligible.
Further, as per the model, A does not control T , so A can-
not choose t1, t2 or the randomness of T . The former are timed-
structures that are in part fixed prior to the attack starting (e.g., they
contain global-clock value). As such, if σ1 and σ2 are unforgeable
w.r.t. selective unforgeability (i.e., SUF-unforgeable), then (t′
1, σ ′
1)
and (t′
2, σ ′
2) as per the above can only be produced with negligible
probability.
□
R , q′
C , q′
A.2 PayCCR – Security w.r.t. Strong Relaying
Theorem 4.6: Consider the (ℓ, z, n, q′
T , reader−coupled )-v-DB
experiment in the strong relaying game for PayCCR. If σ1, σ2 are signa-
tures unforgeable w.r.t. selective unforgeability (i.e., SUF-unforgeable),
then PayCCR is secure with rwith respect to strong relaying. Con-
cretely, the advantage of the adversary is: q2
2qC
2|NC | , where
C ·l, qR = q′
qC = q′
T ·n and |·| denotes the bit-length
of a protocol message.
R ·z and qT = q′
R2|NR | + q2
T2|σ1| +
2
Proof. This is a game-based proof. By Pr[G], we mean the prob-
more than once by any reader.
ability that A wins in a game G.
G0: This game is the initial game, that is the strong relaying
game against PayCCR. Unlike in this game, we do not use C and R
for the target card and reader; instead, we simply use C and R.
G1: This game is G0, where no where no NR value is indeed used
Let qR be the number of NR values issued by readers during the
experiment (this is equal to the number of reader sessions). The
probability that one NR repeats is upper bounded by q2
R2|NR | . So, G0
and G1 are identical except for the failure event that two identical
NR values are used, so we have Pr[G1] − Pr[G0] ≤ q2
R2|NR | , which is
negligible in the security parameter s – if |NR| is in ω (s).
G2: This game is the game G1, with the difference that if the com-
munication between parties R and T is too quick, when NR is sent to
NR←−−− R) < ∆ then
T . Then, Ch aborts the experiment. That is, if t (T
Ch aborts (see Subsection 4.2.2), where ∆ is the communication
time between R and T . If the games continue, then Pr[G2] =Pr[G1].
G3: This game is the game G2, with the difference that if the com-
munication between parties R and T is too quick, when σ1 is sent
−−−−−→ R) < ∆
t1, σ1
to R. Then, Ch aborts the experiment. That is, if t (T
then Ch aborts (see Subsection 4.2.2), where ∆ is the communication
time between R and T . If the games continue, then Pr[G3] =Pr[G2].
G4: This game is the game G3 where σ1 does not repeat itself. Let
qT be the number of σ1 values issued by R during the experiment
as this is equal to the number TPM sessions. The probability that
one σ1 repeats is upper bounded by qT
2|σ1| . G3 and G4 are identical
except for the failure event that two identical σ1 values are used, so
we have Pr[G4]− Pr[G3] ≤ q2
2|σ1| , which is negligible in the security
parameter s – if |σ1| is in ω (s).
G5: This game is the game G4, with the difference that if the
communication between parties R and C is too quick when σ1 is sent
σ′
1−−→ C) < t
to C. Then, Ch aborts the experiment. That is, if t (R
B2
σ1
2
2
2
σ′
1−−→ C) < t
then Ch aborts (also, as point (7) in the adversary). If the games
continue, then Pr[G5]=Pr[G4].
G6: This game is the game G5, where no NC value is used more
than once by any card. Let qC be the number of NC values issued
by readers during the experiment encapsulating this game as this is
equal to the number of card sessions. The probability that one NC
repeats is upper bounded by qC
2|NC | . G5 and G6 are identical except
for the failure event that two identical NC values are used, so we
have Pr[G6] − Pr[G5] ≤ qC
2|NC | , which is negligible in the security
parameter s – if |NC| is in ω (s).
G7: This game is the game G6, with the difference that if the com-
munication between parties R and C is too quick, then Ch aborts the
experiment when NC is sent to R. Then, Ch aborts the experiment.
That is, if t (R
B2 then Ch aborts (also, as point (7) in the
adversary). If the games continue, then Pr[G7]=Pr[G6].
G8: This is the game G7, except that the card never sends a value
NC that has previously been sent by an adversary through the send
oracle. The idea behind this game transition is to eliminate the
event EG where A can randomly guess a value NC in advance. Note
that the number of calls to the send oracle with respect to NC is
bounded by the number of card sessions, qC. Let qC be the number
of calls to the send oracle. This gives us that Pr[EG] ≤ qC
2|NC | .
Therefore, Pr[G6] − Pr[G5] ≤ qC
2|NC | , which is negligible in the
security parameter s – if |NC| is in ω (s).
G9: This is the final game and is equivalent to the game G8, with
the difference that if the communication between parties R and T
is too quick, when NC is sent to T . Then, Ch aborts the experiment.
NC←−−− R) < ∆ then Ch aborts (see Subsection 4.2.2),
That is, if t (T
where ∆ is the communication time between R and T . If the games
continue, then Pr[G9] =Pr[G0].
Now we look at the success probability of A in G9, in which we
assume the Out[PC,T ]= 1 (since PC on board R is controlled by the
attacker). I.e., since A controls PC, the private output τ[PC,T ] can
be tampered with by A.
Note that [W , C] (i.e., the card) will check σ1, σ2 against t1, t2
and against other inputs that went into σ1, σ2 such as NC. Formally,
in the game, [W , C] get the private output τ[PC,T ]
For [W , C] (i.e., the card) to output 1, the adversary needs to
produce (t′
2 ) to put in the forged τ[PC,T ] and with
σ∗
being valid signatures by T on t′
Since A controls R, note that A can choose NR (one that has
i
i
not produced been input to another σ1, given the game in which
we are). Also, A cannot choose NC – since this is produced by C
within [W , C].
But, as per the model, A does not control T , so A cannot choose
t1, t2 or the randomness of T . The former are timed-structures that
are in part fixed prior to the attack starting (e.g., they contain global-
clock value). As such, if σ1 and σ2 are unforgeable w.r.t. selective
unforgeability (i.e., SUF-unforgeable), then (t′
2, σ ′
2) as
per the above can only be produced with negligible probability.
(with i ∈ {1, 2}).
1 ) and (t′
1) and (t′
2, σ∗
1, σ∗
1, σ ′
2
2
□
Session 2: Authentication ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan100