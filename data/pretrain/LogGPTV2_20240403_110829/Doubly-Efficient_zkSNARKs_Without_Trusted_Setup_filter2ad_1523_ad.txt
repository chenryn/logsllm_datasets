proof-of-sum-check(C0, {αj}, {Mk}, X, Y, Z)
Inputs: C0 = Com(s0; rC0
{αj} are all of P’s messages from a sum-check invocation: at
each round j of the sum-check protocol, P has sent
).
αj ← Com((c3, j, c2, j, c1, j, c0, j); rαj
)

{Mk} is deﬁned as in Equation (5) and Lemma 3. (These
vectors encode V’s random coins {rj} from the sum-check.)
X = Com(v0; rX), Y = Com(v1; rY), Z = Com(v0v1; rZ).
Deﬁnitions: n = bN + 2bG; (cid:17)π is deﬁned as in Equation (5);
{ρk} are chosen by V (see below); (cid:17)J =
ρk · (cid:17)Mk; (JX, JY, JZ)
are the last 3 elements of (cid:17)J; (cid:17)π∗ and (cid:17)J∗ are all but the last three
elements of (cid:17)π and (cid:17)J, respectively.
1. P and V execute proof-of-product (§4) on X, Y, and Z.
2. P picks rδ1
, . . . , rδn
(cid:17)d = (dc3,1
, dc2,1
, dc1,1
P computes and sends
δj ← Com((dc3, j
, dc2, j
∈R F and (cid:17)d ∈R F4b N +6bG where
).
, dc0,1
, dc0, n
, dc1, n
j ∈ {1, . . . , n}
, dc2, n
),
); rδ j
3. V chooses and sends ρ1, . . . , ρn+1 ∈R F.
4. P picks rC ∈R F, then computes and sends
, . . . , dc0, n−1
, dc1, j
, dc0, j
C ← Com((cid:6) (cid:17)J∗, (cid:17)d(cid:7); rC)
5. V chooses and sends challenge c ∈R F.
6. P computes and sends (cid:17)z ← c · (cid:17)π∗ + (cid:17)d,
zδ j
zC ← c · (cid:14)
← c · rαj
+ rδ j
ρ1rC0
,
(cid:15)
j ∈ {1, . . . , n}, and
− JXrX − JYrY − JZrZ
7. V rejects unless the following holds, where we denote
(cid:17)z = (zc3,1
, zc0, n
Com((zc3, j
j ∈ {1, . . . , n}
(cid:14) X−JX (cid:14) Y−JY (cid:14) Z−JZ)c (cid:14) C ?= Com((cid:6) (cid:17)J∗, (cid:17)z(cid:7); zC)
(Cρ1
0
, . . . , zc0, n−1
); zδ j
, zc2, n
, zc1, n
(cid:14) δj
, zc0,1
, zc0, j
, zc1,1
, zc1, j
, zc2,1
, zc2, j
) ?= αc
j
+ rC
):
Figure 1—This protocol proves the statement derived by applying
Lemma 3 to Equation (5), i.e., that the sum-check whose transcript is
encoded in the protocol’s inputs is accepting. Values corresponding to
c3, j are elided for all sum-check rounds j having quadratic sj.
and n=bN +2bG, the protocol proves that C0=Com(s1(0)+s1(1));
sj(0)+sj(1)=sj−1(rj−1), j∈{2, . . . , n}; and sn(rn)=Q...,i evalu-
ated with v0, v1 (per §3.2).
Lemma 4’s proof is standard; we leave it to the full version [106,
Appx. A.4]. Relative to Step 2 of Section 4, the protocol of Figure 1
reduces sum-check communication by ≈3×. It also reduces P’s
and V’s cryptographic costs by ≈4× and ≈5×, respectively.
6 Reducing the cost of the witness
In the protocol of Section 4, P sends a separate commitment to
each element w1, . . . , w(cid:4) of the witness w (§4, “Step 0.”). This
means that handling a circuit relation with |w| witness elements
requires a proof whose size is at least proportional to |w|. In this
section, we describe a new commitment scheme for multilinear
polynomials that reduces witness commitment size (and thus
proof size) to sub-linear in |w|; it also reduces V’s computation
933
(cid:2)
(cid:2)
cost to sub-linear in |w| (§6.1). To begin, we require each sub-
AC to have separate input and witness elements; we relax this
restriction by introducing a redistribution layer that allows input
and witness sharing among sub-ACs (§6.2).
6.1 A commitment scheme for multilinear polynomials
In Section 4, V’s ﬁnal step checks that P’s commitments to w are
consistent with its other messages by evaluating ˜w (the MLE of
w; §3.2, “Multilinear extensions”). Zhang et al. [108] show, in the
non-ZK setting, that V can outsource this evaluation to P. We
apply their idea to the ZK setting,4 reducing communication and
saving V computation, by devising a polynomial commitment
scheme [61] tailored to multilinear polynomials. Informally, such
schemes are hiding and binding (§3.1, Def. 4); they also allow
the sender to evaluate a committed polynomial at any point and
prove that the evaluation is consistent with the commitment.
Our commitment scheme builds on a matrix commitment
idea due to Groth [52] and an inner-product argument due to
Bünz et al. [30]. We begin by describing a simpliﬁed version of
|w|) communication and V runtime;
the scheme that gives O(
we then generalize this to O(Sp) communication and O(Ti)
|w|, Sp · Ti = |w|. We assume WLOG for
V runtime, Ti ≥
notational convenience that 2(cid:4) = |x| = |w|.
Square-root commitment scheme. In its ﬁnal check, V evalu-
ates ˜w(r1, . . . , r(cid:4)) by computing a commitment to the dot product
(cid:6)(w0, . . . , w2(cid:3)−1), ( χ0, . . . , χ2(cid:3)−1)(cid:7) (Eq. (4), §4). Consider the fol-
lowing strawman protocol for computing this commitment: in
Step 0 (§4), P sends one multi-commitment to w. Later, P sends
a commitment ω, and P and V execute proof-of-dot-prod (§5)
on Com(w), ω, and ( χ0, . . .). This protocol convinces V that
ω = Com( ˜w(·)), but does not reduce communication: proof-of-
dot-prod requires P to send O(|w|) messages (Appx. A.2).
To reduce communication, we exploit the structure of the
polynomial ˜w and a matrix commitment due to Groth [52]. At
a high level, this works as follows (details below). In Step 0,
P encodes w as a matrix T, then sends commitments {Tk} to
the rows of T. Then, in the ﬁnal step, P sends a commitment ω
that it claims is to ˜w(r1, . . . , r(cid:4)); V uses {Tk} to compute one
multi-commitment T (cid:16); and P and V execute proof-of-dot-prod
on T (cid:16) and ω. In total, communication cost is O(2(cid:3)/2).
In more detail: T is the 2(cid:3)/2 × 2(cid:3)/2 matrix whose column-major
order is w, i.e., Ti+1, j+1 = wi+2(cid:3)/2· j. Before deﬁning T (cid:16) and the
proof-of-dot-prod invocation, we deﬁne
k=1
χbk
(rk)
ˇχb =
L = ( ˇχ0, ˇχ1, . . . , ˇχ
2(cid:3)/2·(2(cid:3)/2−1))
To compute T (cid:16) from commitments {Tk} to the rows of T, V
evaluates L (in time O(2(cid:3)/2) [104, §3.3]) and uses it to compute
ˆχb =
k=(cid:4)/2+1
R = ( ˆχ0, ˆχ
2(cid:3)/2, . . . , ˆχ
(rk)
2(cid:3)/2−1
χbk
(cid:4)/2
(cid:4)
T (cid:16) =
= Com(L · T)
T ˇχk
k+1
k=0
(6)
Finally, P sends a commitment ω and uses proof-of-dot-prod to
convince V that the dot product of R with the vector committed
in T (cid:16) equals the value committed in ω.
4In concurrent and independent work, Zhang et al. extend to ZK [109]; see §2.
)
2(cid:3)/2−1
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:29:14 UTC from IEEE Xplore.  Restrictions apply. 
=
=
The above proves to V that ω = Com( ˜w(r0, . . . , r(cid:4))), as we
now argue. For 1-indexed L and R, we have
= χ
This is true because ˇχb comprehends the lower (cid:4)/2 bits of b, and
ˆχb the upper (cid:4)/2 bits. Then by the deﬁnition of T, we have
L · T · RT =
Ti+1, j+1 · Li+1 · Rj+1
Li+1 · Rj+1 = ˇχi · ˆχ
2(cid:3)/2−1
2(cid:3)/2−1
2(cid:3)/2−1
2(cid:3)/2−1
2(cid:3)−1
i+2(cid:3)/2· j
2(cid:3)/2· j
j=0
i=0
i=0
j=0
k=0
· χ
i+2(cid:3)/2· j
wi+2(cid:3)/2· j
wk · χk
Equation (6), ω = Com(L ·T · RT) = Com(2(cid:3)−1
If V accepts P’s proof-of-dot-prod on T (cid:16), ω, and R, then by
k=0 wk · χk), which
equals Com( ˜w(r0, . . . , r(cid:4))) (Eq. (4), §4) as claimed.
In total, communication is O(2(cid:3)/2) (for {Tk} plus the proof-of-
dot-prod invocation), and V’s computational cost is O(2(cid:3)/2) (for
computing L, R, and T (cid:16), and executing proof-of-dot-prod).
Reducing the cost of proof-of-dot-prod. In the above protocol,
proof-of-dot-prod establishes a lower bound on communication
cost. To reduce proof-of-dot-prod’s cost, we use an idea due to
Bünz et al. [30], who give a dot-product protocol that has cost
logarithmic in the length of the vectors. Their protocol works
over two committed vectors; we require one that works over one
committed and one public vector. In Appendix A.3, we adapt their
protocol to the syntax of proof-of-dot-prod; we refer to the result
as prooflog-of-dot-prod. Whereas proof-of-dot-prod requires P to
send 4+n elements for vectors of length n, prooflog-of-dot-prod
requires only 4+2 log n. In both protocols, V’s computational
cost is dominated by a multi-exponentiation [83] of length n.
The full commitment scheme diﬀers from the square-root one
in that P and V invoke prooflog-of-dot-prod (rather than proof-
of-dot-prod) on T (cid:16), R, and ω. For T, L, R, ˇχb, ˆχb as deﬁned
above, P sends 4+2(cid:3)/2+2 log 2(cid:3)/2 elements, and V’s runtime is
dominated by two multi-exponentiations of length 2(cid:3)/2, one to
compute T (cid:16) and the other to execute prooflog-of-dot-prod. This
gives the same asymptotics as the square-root scheme with ≈2×
less communication (but with ≈3× more computation for P).
More importantly, prooflog-of-dot-prod gives the freedom to
reduce communication in exchange for increased V runtime. For
a parameter ι, we redeﬁne T to be the 2(cid:3)/ι × 2(cid:4)−(cid:3)/ι matrix whose
column-major order is w; redeﬁne ˇχb to comprehend the lower
(cid:4)/ι bits of b, and ˆχb the upper (cid:5) − (cid:4)/ι bits; and redeﬁne
L = ( ˇχ0, ˇχ1, . . . , ˇχ
2(cid:3)/ι ·(2(cid:3)−(cid:3)/ι−1))
T has 2(cid:3)/ι rows and T (cid:16) is a vector of 2(cid:4)−(cid:3)/ι elements, so P sends
2(cid:3)/ι commitments in Step 0 and 4+ log 2(cid:4)−(cid:3)/ι elements for prooflog-
of-dot-prod, which is O(2(cid:3)/ι) in total. Computing T (cid:16) costs V
one multi-exponentiation of length 2(cid:3)/ι, and executing prooflog-
of-dot-prod costs one of length 2(cid:4)−(cid:3)/ι, which is O(2(cid:3)/ι+2(cid:4)−(cid:3)/ι)
(cid:2)
in total. Since this is at least O(2(cid:3)/2), V’s runtime is at least
|w|). We formalize immediately below.
O(
Lemma 5. Suppose WLOG that w ∈ F2ι·(cid:3)(cid:16)
for ι ≥ 2, and that P
= |w|1/ι multi-com-
commits to w as described above using 2(cid:4)(cid:16)
mitments. Then for any (r1, . . . , rι·(cid:4)(cid:16)), P can send a commitment
ω and argue that it commits to ˜w(r1, . . . , rι·(cid:4)(cid:16)) in communication
) R = ( ˆχ0, ˆχ
2(cid:3)/ι, . . . , ˆχ
2(cid:3)/ι−1
O(|w|1/ι), where V runs in O(|w|(ι−1)/ι) steps. This is a complete,
honest-veriﬁer perfect zero-knowledge argument with witness-
extended emulation under the discrete log assumption.
Completeness and ZK follow from the analysis in Ap-
pendix A.3. We leave analysis of witness-extended emulation
to the full version [106, Appx. A.5] for space reasons. We have
described this protocol in terms of the multilinear extension of
w, but it generalizes to any multilinear polynomial f using the
fact that T comprises the evaluations of f at all binary inputs.
6.2 Sharing witness elements in the data-parallel setting
We have thus far regarded the computation as having one large
input and one large witness. When evaluating a data-parallel
computation, this means that the sub-ACs’ inputs must be disjoint
slices of the full input (and similarly for the witness). However,
this is not suﬃcient in many cases of interest.
Consider a case where P wants to convince V that it knows
leaves of a Merkle tree corresponding to a supplied root. Verifying
a witness with M leaves requires 2M−1 invocations of a hash
function. We encode this as a computation with 2M−1 sub-ACs
laid side-by-side, each encoding the hash function.5 Then, for
sub-ACb processing sub-ACa’s output, P supplies the purported
output to both, and sub-ACa just checks that value and outputs a bit
indicating correctness. This is necessary for zero-knowledge: all
AC outputs are public, whereas sub-ACa’s output (an intermediate
value in the computation) must not be revealed to V.
This arrangement requires sub-ACs to share witness elements—
but duplicating entries in the matrix T (§6.1) is not a solution,
because V cannot detect if a cheating P produces T that gives
diﬀerent values to diﬀerent sub-ACs. One possibility is a hybrid
vector-scalar scheme: P supplies scalar commitments for each
shared witness element and matrix commitment {Tk} for the rest.
Then, for a scalar commitment δ, V “injects” the committed
value into input index b by multiplying the commitment to
˜Vd(r(cid:16), rυ) (§4, “Final step”) by δ−r0·χb .6 (In contrast, the protocol
of Section 6.1 maps each entry of T to a ﬁxed input index.)
This approach works when the number of shared witness
elements is small, but it is ineﬃcient when there are many shared
elements: each shared element requires a separate commitment
and proof-of-opening invocation. For such cases, we enable
sharing of witness elements by modifying the arithmetic circuit
encoding the NP relation. Speciﬁcally, after constructing a data-
parallel AC corresponding to the computation, we add one
non-data-parallel redistribution layer (RDL) whose inputs are
the full input and witness, and whose outputs feed the input layers
of each sub-AC. Since the RDL is not data parallel, there are
no restrictions on how its inputs connect to its outputs, meaning
5The sub-ACs could instead be arranged sequentially. This would avoid the issues
described in this subsection, but would dramatically increase circuit depth, and
thus the proof length and associated costs when applying our argument.
6In fact, this approach works generally for computations over values to which
V holds a commitment whose opening P knows. It also applies to committed
vectors: if V holds a commitment ξ = Com((cid:17)x), it can inject the committed
values into a list of indices (b1, . . .) as follows: P produces a commitment δ and
proves to V that it commits to Com((cid:6)(x1, . . .), (χb1
, . . .)(cid:7)) with prooflog-of-
dot-prod; then V multiplies Com( ˜Vd(r
(cid:16), rυ)) by δ−r0. This approach requires
more communication and V computation than the protocol of Section 6.1,
because it does not assume any particular structure for (b1, . . .).
934
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:29:14 UTC from IEEE Xplore.  Restrictions apply. 