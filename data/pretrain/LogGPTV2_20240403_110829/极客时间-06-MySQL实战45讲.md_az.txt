# 小结这里我再次说明一下，我们上面的所有案例都是在可重复读隔离级别(repeatable-read)下验证的。同时，可重复读隔离级别遵守两阶段锁协议，所有加锁的资源，都是在事务提交或者回滚的时候才释放的。在最后的案例中，你可以清楚地知道 next-key lock实际上是由间隙锁加行锁实现的。如果切换到读提交隔离级别 (read-committed)的话，就好理解了，过程中去掉间隙锁的部分，也就是只剩下行锁的部分。其实读提交隔离级别在外键场景下还是有间隙锁，相对比较复杂，我们今天先不展开。另外，在读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把"不满足条件的行"上的行锁直接释放了，不需要等到事务提交。也就是说，读提交隔离级别下，锁的范围更小，锁的时间更短，这也是不少业务都默认使用读提交隔离级别的原因。不过，我希望你学过今天的课程以后，可以对 next-key lock的概念有更清晰的认识，并且会用加锁规则去判断语句的加锁范围。在业务需要使用可重复读隔离级别的时候，能够更细致地设计操作数据库的语句，解决幻读问题的同时，最大限度地提升系统并行处理事务的能力。经过这篇文章的介绍，你再看一下上一篇文章最后的思考题，再来尝试分析一次。我把题目重新描述和简化一下：还是我们在文章开头初始化的表 t，里面有 6条记录，图 12 的语句序列中，为什么 session B 的 insert操作，会被锁住呢？\![](Images/f19315a2cda76213f86f4e7d56b9a246.png){savepage-src="https://static001.geekbang.org/resource/image/3a/1e/3a7578e104612a188a2d574eaa3bd81e.png"}```{=html}```图 12 锁分析思考题]{.reference}```{=html}```另外，如果你有兴趣多做一些实验的话，可以设计好语句序列，在执行之前先自己分析一下，然后实际地验证结果是否跟你的分析一致。对于那些你自己无法解释的结果，可以发到评论区里，后面我争取挑一些有趣的案例在文章中分析。你可以把你关于思考题的分析写在留言区，也可以分享你自己设计的锁验证方案，我会在下一篇文章的末尾选取有趣的评论跟大家分享。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。
## 上期问题时间上期的问题，我在本期继续作为了课后思考题，所以会在下篇文章再一起公布"答案"。这里，我展开回答一下评论区几位同学的问题。-   \@令狐少侠    说，以前一直认为间隙锁只在二级索引上有。现在你知道了，有间隙的地方就可能有间隙锁。-   \@浪里白条 同学问，如果是 varchar 类型，加锁规则是什么样的。\    回答：实际上在判断间隙的时候，varchar 和 int    是一样的，排好序以后，相邻两个值之间就有间隙。-   有几位同学提到说，上一篇文章自己验证的结果跟案例一不同，就是在    session A 执行完这两个语句：```{=html}```    begin;select * from t where d=5 for update; /*Q1*/以后，session B 的 update 和 session C 的 insert都会被堵住。这是不是跟文章的结论矛盾？其实不是的，这个例子用的是反证假设，就是假设不堵住，会出现问题；然后，推导出session A 需要锁整个表所有的行和所有间隙。评论区留言点赞板：> @ 某、人 、@郭江伟 两位同学尝试分析了上期问题，并给了有启发性的解答。![](Images/48edcb93fb03e3e52d7e7099be6b5cb3.png){savepage-src="https://static001.geekbang.org/resource/image/09/77/09c1073f99cf71d2fb162a716b5fa577.jpg"}
# 22 \| MySQL有哪些"饮鸩止渴"提高性能的方法？不知道你在实际运维过程中有没有碰到这样的情景：业务高峰期，生产环境的MySQL 压力太大，没法正常响应，需要短期内、临时性地提升一些性能。我以前做业务护航的时候，就偶尔会碰上这种场景。用户的开发负责人说，不管你用什么方案，让业务先跑起来再说。但，如果是无损方案的话，肯定不需要等到这个时候才上场。今天我们就来聊聊这些临时方案，并着重说一说它们可能存在的风险。
# 短连接风暴正常的短连接模式就是连接到数据库后，执行很少的 SQL语句就断开，下次需要的时候再重连。如果使用的是短连接，在业务高峰期的时候，就可能出现连接数突然暴涨的情况。我在第 1 篇文章[《基础架构：一条 SQL查询语句是如何执行的？》](https://time.geekbang.org/column/article/68319)中说过，MySQL建立连接的过程，成本是很高的。除了正常的网络连接三次握手外，还需要做登录权限判断和获得这个连接的数据读写权限。在数据库压力比较小的时候，这些额外的成本并不明显。但是，短连接模型存在一个风险，就是一旦数据库处理得慢一些，连接数就会暴涨。max_connections参数，用来控制一个 MySQL实例同时存在的连接数的上限，超过这个值，系统就会拒绝接下来的连接请求，并报错提示"Toomanyconnections"。对于被拒绝连接的请求来说，从业务角度看就是数据库不可用。``{=html}在机器负载比较高的时候，处理现有请求的时间变长，每个连接保持的时间也更长。这时，再有新建连接的话，就可能会超过max_connections 的限制。碰到这种情况时，一个比较自然的想法，就是调高 max_connections的值。但这样做是有风险的。因为设计 max_connections这个参数的目的是想保护MySQL，如果我们把它改得太大，让更多的连接都可以进来，那么系统的负载可能会进一步加大，大量的资源耗费在权限验证等逻辑上，结果可能是适得其反，已经连接的线程拿不到CPU 资源去执行业务的 SQL 请求。那么这种情况下，你还有没有别的建议呢？我这里还有两种方法，但要注意，这些方法都是有损的。**第一种方法：先处理掉那些占着连接但是不工作的线程。**max_connections 的计算，不是看谁在running，是只要连着就占用一个计数位置。对于那些不需要保持的连接，我们可以通过kill connection 主动踢掉。这个行为跟事先设置 wait_timeout的效果是一样的。设置 wait_timeout 参数表示的是，一个线程空闲wait_timeout 这么多秒之后，就会被 MySQL 直接断开连接。但是需要注意，在 show processlist 的结果里，踢掉显示为 sleep的线程，可能是有损的。我们来看下面这个例子。![](Images/ad42632d77feb65bd760c5ee4503fed1.png){savepage-src="https://static001.geekbang.org/resource/image/90/2a/9091ff280592c8c68665771b1516c62a.png"}```{=html}```图 1 sleep 线程的两种状态]{.reference}```{=html}```在上面这个例子里，如果断开 session A 的连接，因为这时候 session A还没有提交，所以 MySQL 只能按照回滚事务来处理；而断开 session B的连接，就没什么大影响。所以，如果按照优先级来说，你应该优先断开像session B 这样的事务外空闲的连接。但是，怎么判断哪些是事务外空闲的呢？session C 在 T 时刻之后的 30 秒执行show processlist，看到的结果是这样的。![](Images/138b5fd3d305c0e61f3c71ba81fbd174.png){savepage-src="https://static001.geekbang.org/resource/image/ae/25/ae6a9ceecf8517e47f9ebfc565f0f925.png"}```{=html}```图 2 sleep 线程的两种状态，show processlist 结果]{.reference}```{=html}```图中 id=4 和 id=5 的两个会话都是 Sleep状态。而要看事务具体状态的话，你可以查 information_schema 库的innodb_trx 表。![](Images/a2308a72c0cc6069ae0e5407e9453da7.png){savepage-src="https://static001.geekbang.org/resource/image/ca/e8/ca4b455c8eacbf32b98d1fe9ed9876e8.png"}```{=html}```图 3 从 information_schema.innodb_trx 查询事务状态]{.reference}```{=html}```这个结果里，trx_mysql_thread_id=4，表示 id=4 的线程还处在事务中。因此，如果是连接数过多，你可以优先断开事务外空闲太久的连接；如果这样还不够，再考虑断开事务内空闲太久的连接。从服务端断开连接使用的是 kill connection + id 的命令， 一个客户端处于sleep状态时，它的连接被服务端主动断开后，这个客户端并不会马上知道。直到客户端在发起下一个请求的时候，才会收到这样的报错"ERROR2013 (HY000): Lost connection to MySQL server during query"。从数据库端主动断开连接可能是有损的，尤其是有的应用端收到这个错误后，不重新连接，而是直接用这个已经不能用的句柄重试查询。这会导致从应用端看上去，"MySQL一直没恢复"。你可能觉得这是一个冷笑话，但实际上我碰到过不下 10 次。所以，如果你是一个支持业务的DBA，不要假设所有的应用代码都会被正确地处理。即使只是一个断开连接的操作，也要确保通知到业务开发团队。**第二种方法：减少连接过程的消耗。**有的业务代码会在短时间内先大量申请数据库连接做备用，如果现在数据库确认是被连接行为打挂了，那么一种可能的做法，是让数据库跳过权限验证阶段。跳过权限验证的方法是：重启数据库，并使用--skip-grant-tables参数启动。这样，整个 MySQL会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内。但是，这种方法特别符合我们标题里说的"饮鸩止渴"，风险极高，是我特别不建议使用的方案。尤其你的库外网可访问的话，就更不能这么做了。在 MySQL 8.0 版本里，如果你启用--skip-grant-tables 参数，MySQL 会默认把\--skip-networking参数打开，表示这时候数据库只能被本地的客户端连接。可见，MySQL 官方对skip-grant-tables 这个参数的安全问题也很重视。除了短连接数暴增可能会带来性能问题外，实际上，我们在线上碰到更多的是查询或者更新语句导致的性能问题。其中，查询问题比较典型的有两类，一类是由新出现的慢查询导致的，一类是由QPS（每秒查询数）突增导致的。而关于更新语句导致的性能问题，我会在下一篇文章和你展开说明。
# 慢查询性能问题在 MySQL 中，会引发性能问题的慢查询，大体有以下三种可能：1.  索引没有设计好；2.  SQL 语句没写好；3.  MySQL 选错了索引。接下来，我们就具体分析一下这三种可能，以及对应的解决方案。**导致慢查询的第一种可能是，索引没有设计好。**这种场景一般就是通过紧急创建索引来解决。MySQL 5.6版本以后，创建索引都支持 Online DDL了，对于那种高峰期数据库已经被这个语句打挂了的情况，最高效的做法就是直接执行alter table 语句。比较理想的是能够在备库先执行。假设你现在的服务是一主一备，主库 A、备库B，这个方案的大致流程是这样的：1.  在备库 B 上执行 set sql_log_bin=off，也就是不写 binlog，然后执行    alter table 语句加上索引；2.  执行主备切换；3.  这时候主库是 B，备库是 A。在 A 上执行 set sql_log_bin=off，然后执行    alter table 语句加上索引。这是一个"古老"的 DDL 方案。平时在做变更的时候，你应该考虑类似 gh-ost这样的方案，更加稳妥。但是在需要紧急处理时，上面这个方案的效率是最高的。**导致慢查询的第二种可能是，语句没写好。**比如，我们犯了在第 18 篇文章[《为什么这些 SQL语句逻辑相同，性能却差异巨大？》](https://time.geekbang.org/column/article/74059)中提到的那些错误，导致语句没有使用上索引。这时，我们可以通过改写 SQL 语句来处理。MySQL 5.7 提供了 query_rewrite功能，可以把输入的一种语句改写成另外一种模式。比如，语句被错误地写成了 select \* from t where id + 1 =10000，你可以通过下面的方式，增加一个语句改写规则。    mysql> insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values ("select * from t where id + 1 = ?", "select * from t where id = ? - 1", "db1"); call query_rewrite.flush_rewrite_rules();这里，call query_rewrite.flush_rewrite_rules()这个存储过程，是让插入的新规则生效，也就是我们说的"查询重写"。你可以用图4 中的方法来确认改写规则是否生效。![](Images/4ba7b911301379bb02526dc235857056.png){savepage-src="https://static001.geekbang.org/resource/image/47/8a/47a1002cbc4c05c74841591d20f7388a.png"}```{=html}```图 4 查询重写效果]{.reference}```{=html}```**导致慢查询的第三种可能，就是碰上了我们在第 10 篇文章****《MySQL为什么有时候会选错索引？》**](https://time.geekbang.org/column/article/71173)**中提到的情况，MySQL选错了索引。**这时候，应急方案就是给这个语句加上 force index。同样地，使用查询重写功能，给原来的语句加上 forceindex，也可以解决这个问题。上面我和你讨论的由慢查询导致性能问题的三种可能情况，实际上出现最多的是前两种，即：索引没设计好和语句没写好。而这两种情况，恰恰是完全可以避免的。比如，通过下面这个过程，我们就可以预先发现问题。1.  上线前，在测试环境，把慢查询日志（slow log）打开，并且把    long_query_time 设置成 0，确保每个语句都会被记录入慢查询日志；2.  在测试表里插入模拟线上的数据，做一遍回归测试；3.  观察慢查询日志里每类语句的输出，特别留意 Rows_examined    字段是否与预期一致。（我们在前面文章中已经多次用到过 Rows_examined    方法了，相信你已经动手尝试过了。如果还有不明白的，欢迎给我留言，我们一起讨论）。不要吝啬这段花在上线前的"额外"时间，因为这会帮你省下很多故障复盘的时间。如果新增的 SQL语句不多，手动跑一下就可以。而如果是新项目的话，或者是修改了原有项目的表结构设计，全量回归测试都是必要的。这时候，你需要工具帮你检查所有的 SQL语句的返回结果。比如，你可以使用开源工具pt-query-digest()。