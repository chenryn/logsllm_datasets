Accepted for Publication, Software Process: Improvement and Practice Journal,
Copyright © 2006 John Wiley & Sons, Ltd.
Complexity Analysis of BPEL Web Processes
Jorge Cardoso
Department of Mathematics and Engineering
University of Madeira, 9050-390 Funchal, Portugal
PI:EMAIL
Phone: +351 291 705 150, Fax: +351 291 705 199
Abstract. Several organizations have already realized the potential of using
WS-BEPL, the Process Execution Language for Web Services, to model the
behavior of Web services in business processes. WS-BPEL provides a model
for describing simple or complex interactions between business partners. In
some cases, WS-BPEL process designs can be highly complex, due, for exam-
ple, to the vast number of Web services carried out in global markets. High
complexity in a process has several undesirable drawbacks, it may result in poor
understandability, more errors, defects, and exceptions leading to processes re-
quiring more time to be developed, tested and maintained. Therefore, excessive
complexity should be avoided. Processes which are highly complex tend be less
flexible, since it is more complicated to make changes to the process. The major
goal of this paper is to present two metrics to analyze the control-flow complex-
ity (CFC) of WS-BPEL Web processes. The metrics are to be used at design-
time to evaluate the complexity of a process design before implementation ac-
tually exists.
Keywords. Web services, Web processes, BPEL, Business processes, work-
flows, complexity.
Accepted for Publication, Software Process: Improvement and Practice Journal,
Copyright © 2006 John Wiley & Sons, Ltd.
1 Introduction
In a competitive e-commerce and e-business market, Web processes can span both
between enterprises and within enterprises (Sheth, Aalst et al. 1999). A Web process
(Cardoso and Sheth 2005) is a process that models complex interactions among or-
ganizations and represents the evolution of workflow technology. While workflows
invoke tasks and activities, Web processes invoke Web services. The most well-
known language to model Web processes is BPEL (WS-BEPL 2005), and the W3C
standard to model Web services is WSDL (Christensen, Curbera et al. 2001). While
organizations want their Web processes to be simple, modular, easy to understand,
easy to maintain and easy to re-engineer, in cross-organizational settings these proc-
esses have an inherent complexity.
To achieve effective process management, one fundamental area of research that
needs to be explored is the complexity analysis of Web processes (Cardoso 2005).
Studies indicate that 38% of process management solutions will be applied to redes-
igning enterprise-wide processes (source Delphi Group 2002). Recently, a new field
of research for processes has emerged. This new field – termed process measurement
– presents a set of approaches to the quantification of specific properties of processes.
Important properties to analyze include the estimation of complexity, defects, process
size, effort of testing, effort of maintenance, understandability, time, resources, and
quality of service. Process measurement is still in its infancy and much work has yet to
be undertaken.
Complexity is closely related to flexibility, one of the key enablers of innovation
for organizations. Flexibility and complexity are guiding principles in the design of
business processes and are in general, inversely related. Processes with a low com-
plexity are normally more flexible since they have the capability to quickly change to
accommodate new products or services to meet the changing needs of customers and
business partners. Complex Web processes are more prone to errors. For example, in
software engineering it has been found that program modules with high complexity
indices have a higher frequency of failures (Lanning and Khoshgoftaar 1994). Surpris-
ingly, in spite of the fact that there is a vast literature on software measurement of
complexity, Zuse (Zuse 1997) has found hundreds of different software metrics pro-
posed and described, while almost no research on process complexity measurement
has yet been carried out. The only significant work that can be mentioned is the cohe-
sion and coupling metric developed to analyze workflows, proposed by Reijers and
Vanderfeesten (Reijers and Vanderfeesten 2004).
In our previous work (Cardoso 2005), we have presented a control-flow complexity
(CFC) metric to analyze tri-logic workflows (Cardoso and Cravo 2006). The metric
was intended to be used during the development of processes to improve their quality
and maintainability. Due to the widespread adoption of WS-BEPL (WS-BEPL 2005),
more than 30 enactment engines and editing tools have already been developed, we
feel however, that it is important to develop complexity metrics to evaluate the com-
plexity of WS-BPEL (or simply BPEL) processes. Since we believe that no holistic
Accepted for Publication, Software Process: Improvement and Practice Journal,
Copyright © 2006 John Wiley & Sons, Ltd.
metric exists to analyze the complexity of Web processes, we recognize that several
metrics need to be developed to characterize specific perspectives of Web processes.
There are three elements that are fundamental for the definition of any measure-
ment: entity, attribute, and metric. The entities involved in our measurements are
BPEL processes. A process can be measured according to different attributes. The
attribute that we will target and study is the complexity associated with BPEL proc-
esses. Attributes such as time, cost, and reliability have already received some atten-
tion from researchers (Cardoso, Miller et al. 2004; Cardoso 2005). The metric that we
will study is the control-flow complexity.
This paper is structured as follows: Section 2 presents the various perspectives of
process complexity. Section 3 gives brief introduction to WSDL Web services and
BPEL Web processes. In section 4, we present the metric that we have developed to
evaluate the control-flow complexity of BPEL processes. Section 5 presents the re-
lated work. It will be seen that while a significant amount of research has been carried
out to quantify the complexity of programs in software engineering, the literature and
work on complexity analysis for business processes are almost inexistent. Finally,
section 6 presents our conclusions.
2 Web process complexity and flexibility
The flexibility of a process is characterized by a ready capability to adapt to new,
different, or changing requirements. According to the IEEE Standard Glossary of
Software Engineering Terminology (IEEE 1992), “flexibility is the ease with which a
system or component can be modified for use in applications or environments other
than those for which it was specifically designed.” Following this definition, we view
flexibility as the ease of change of a process due to modifications in the environment
or in initial requirements. For example, in software engineering, it has been suggested
that a way to measure flexibility relies on measures that compute the impact of
changes in programs (Li and Offutt 1996). Curtis (Curtis 1979) suggests that
“…software complexity determines … how much effort will be required to modify
program modules to incorporate specific changes.” If a process is complex then it may
contain a considerable number of complex components, such as switches, flows,
whiles or picks. Adding, removing, or changing an activity from a process requires
studying a number of particular cases for which the activity may depend on. The study
and analysis of these cases is what makes the process difficult to change, and therefore
inflexible. In our view, the more cases a process has the more difficult is to change a
process. Being able to handle a large number of cases, as the reviewer states, does not
make the process flexible, but makes it complete for a particular domain.
In networked supply chains, process flexibility can be classified into three levels
(Ferrara, Hayden et al. 2003). These levels of flexibility require the ability to modify
and customize processes, and change processes in real time. The basic property of a
process is that it is case-based (Aalst 1998). This means that every task is executed for
a specific case. Complex processes tend to be less flexible since they support more
cases than simple processes and, therefore, having to take into account all the cases
Accepted for Publication, Software Process: Improvement and Practice Journal,
Copyright © 2006 John Wiley & Sons, Ltd.
makes it difficult to make changes. For example, eligibility referral (Anyanwu, Sheth
et al. 2003) and enrollment processes (CAPA 1997) are complex due to the many
cases that exists in each process, which are the results of the complex logic in health-
care and educational organizations. Because of the many tasks that are required to
handle each case, to change such processes requires considering a vast number of
cases which makes the adaptation of the process complex.
Because flexibility should be a concern during development, the control-flow com-
plexity measures should be considered for use during Web process construction or
reengineering to follow complexity trends and maintain predefined flexibility levels. A
significant complexity measure increase during testing may be the sign of a brittle,
nonflexible or high-risk process. Since processes have the tendency to evolve over
time by modification, a process can easily become fragile with age. This compels us to
use techniques, such as complexity analysis, to assess the system’s condition. Com-
plexity metrics can provide information concerning the cost and time required to make
a given change to a process in order to make it more flexible.
We define Web process complexity as the degree to which a process is difficult to
analyze, understand or explain. It may be characterized by the number and intricacy of
Web services’ interfaces, transitions, conditional and parallel branches, the existence
of loops, roles, activity categories, the types of data structures, and other process char-
acteristics (Cardoso 2005).
There is no single metric that can be used to measure the complexity of a process.
Based on previous work which identified recurring, generic patterns in workflows,
namely Workflow Control Patterns (Aalst, Hofstede et al. 2003), Workflow Data
Patterns (Russell, Hofstede et al. 2005), and Workflow Resource Patterns (Russell,
Aalst et al. 2005) which characterize the range of control-flow, data, and resource
constructs that might be encountered when modeling and analyzing workflows, we
identify three main complexity perspectives (Figure 1): control-flow complexity,
data-flow complexity, and resource complexity. Since we consider that the type, inter-
nal structure, and interface of an activity are also important when computing the com-
plexity of a workflow, we also consider the complexity of activities. Activities can
have different levels of complexity since they can be classified into four distinct types
(Russell, Aalst et al. 2005): atomic, block, multiple-instance and multiple-instance
block. While in this paper we will focus on control-flow complexity, we will present
the main ideas behind each complexity perspective as well.
Activity complexity. This view on complexity simply calculates the number of activi-
ties a process has. While this complexity metric is very simple, it is very important to
complement other forms of complexity. The control-flow complexity of a process can
be very low while its activity complexity can be very high. For example, a sequential
process that has a thousand activities has a control-flow complexity of 0, whereas its
activity complexity is 100. This metric was inspired by lines-of-code (LOC) metric
used with a significant success rate in software engineering (Jones 1986).
Control-flow complexity. The control-flow behavior of a process is affected by con-
structs such as splits, joins, loops, and ending and starting points. Splits allow defini-
tion of the possible control paths that exist in a process. Joins have a different role;
Accepted for Publication, Software Process: Improvement and Practice Journal,
Copyright © 2006 John Wiley & Sons, Ltd.
they express the type of synchronization that should be made at a specific point in the
process. A control-flow complexity model needs to take into account the existence of
XOR-split/join, OR-split/join, AND-split/join, loops, etc (Cardoso 2005).
Figure 1. Complexity analysis perspectives
Data-flow complexity. The data-flow complexity of a process increases with the
complexity of its data structures, the number of formal parameters of activities, and
the mappings between activities’ data. A data-flow complexity metric can be com-
posed of several sub-metrics which include: data complexity, interface complexity,
and interface integration complexity (Cardoso 2005). While the first two sub-metrics
are related to static data aspects (data declaration), the third metric is more dynamic in
nature and focuses on data dependencies between the different activities of a process.
Resource complexity. Activities in a process need to access resources during their
executions. A resource is defined to be any entity (e.g. human resources, IS resources,
and IT resources) required by an activity for its execution, such as a document, a data-
base, a printer, an external application, or role (Du, Davis et al. 1999; zur Mühlen
1999). Resources, such as actors and roles, can be structured in the context of an or-
ganization. The structure that is used to shape the different types of resources can be
analyzed to determine its complexity. This analysis can help managers to lower ad-
ministrative costs and better optimize resource utilization.
3 BPEL Web processes
The emergence of e-commerce has changed the foundations of business, forcing man-
agers to rethink their strategies. Organizations are increasingly faced with the chal-
lenge of managing e-business systems, Web services, and Web processes. Web ser-
vices and Web processes promise to ease several current infrastructural challenges,
such as data, application, and process integration. With the emergence of Web ser-
Accepted for Publication, Software Process: Improvement and Practice Journal,
Copyright © 2006 John Wiley & Sons, Ltd.
vices, a process management system becomes essential in order to support, manage,
and enact Web processes, both between enterprises and within the enterprise (Sheth,
Aalst et al. 1999).
A BPEL process is composed of a set of Web services put together to achieve a fi-
nal goal. As the complexity of a process design increases, it can lead to poor quality
and be difficult to reengineer. High complexity in a process may result in limited un-
derstandability and more errors, defects, and exceptions leading processes to needing
more time to be developed, tested and maintained. Therefore, excessive complexity
should be avoided. For instance, critical processes, in which failure can result in the
loss of human life, requires a unique approach to development, implementation and
management. For this type of process, typically found in healthcare applications
(Anyanwu, Sheth et al. 2003), the consequences of failure are very serious. The ability
to produce processes of higher quality and less complexity is a matter of endurance.
3.1 Web services
Web services are modular, self-describing, self-contained applications that are acces-
sible over the Internet (Curbera, Nagy et al. 2001). Currently, Web services are de-
scribed using the Web Services Description Language (Chinnici, Gudgin et al. 2003),
which provide operational information. The Web Services Description Language
(WSDL) specifies the structure of message components using XML Schema con-
structs. A WSDL document contains a set of XML definitions describing Web ser-
vices using four major elements, which include: input and output messages, data types,
port types, and bindings. These elements are illustrated in the following code segment: