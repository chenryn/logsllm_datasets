enclaves, nor does it need to incur more memory accesses
in the background. All memory accesses used to push cache
lines out of the L2 cache and LLC are legitimate accesses
from the victim enclaves. Therefore, cache partitioning can-
not defeat cache squeezing because there is no cross-context
cache sharing. In fact, way-partitioning features such as Intel
CAT [65] can be exploited to further shrink the effective cache
sizes in combination with cache squeezing.
5.4.2 Cross-Core Priming with Cache Squeezing
As we mentioned in § 5.3, cross-core cache priming may not
have sufﬁcient bandwidth to evict the critical cache lines in
time. However, we found that cache squeezing makes the
priming more effective by shrinking the effective cache size.
Instead of priming all the cache sets, the attacker now only
has to prime the sets of the targeted conﬂict groups containing
the critical addresses (Figure 7(2)). Each group of 64 cache
sets contains W × 4KB, allowing the priming process to evict
the part of cache within a millisecond. The priming process
can run in parallel and does not affect the victim execution
except causing cache contention.
5.4.3 Limitation
Although cache squeezing can increase the cache misses
among critical addresses, it could be less effective if the victim
has only a few critical addresses or a small memory footprint.
If the critical addresses can only ﬁll a small part of a conﬂict
group (W × 4 KB), the victim enclave may not be able to
cause enough cache misses to beneﬁt the attacker. For exam-
ple, Memcached only has 2 MB (500 pages) of the critical
address range. To ﬁll all of the 748 pages, we identify the
top 248 frequently-accessed pages (in addition to the critical
addresses) through simulation, and assign these extra pages
to the same conﬂict group.
Note that the LLC of a modern CPU usually has a cache
slice feature that distributes the addresses across multiple
cache banks using an undocumented, model-speciﬁc map-
ping function. Reverse-engineering the slicing function of the
target CPU is useful for further reducing the effective cache
space for an enclave if the enclave has a smaller memory
footprint. Reverse-engineering of slicing functions is already
explored by prior papers [64], so we will not discuss this
technique in this paper.
pinnedpinnedVirtual PagesEPC PagesLLC SetsCritical Pagesconﬂict groupOS Pages(2) Cross-Core Priming(1) Cache Squeezing6 Extracting Sensitive Access Patterns
OS techniques including critical page whitelisting, cache
squeezing, and cross-core priming effectively increase the
cache misses on the cache misses on critical addresses. How-
ever, the traces collected from the memory bus are still full of
noise and contain no marker for splitting the critical memory
accesses into iterations. Unlike controlled-channel attacks,
MEMBUSTER cannot rely on repeated code addresses (e.g.,
from a loop) to mark and then split the critical accesses be-
cause these code addresses tend to be accessed too frequently
to be evicted by our techniques. Therefore, the attacker needs
to deeply analyze the memory traces ofﬂine to distill the sen-
sitive information.
To extract the sensitive access patterns, we identify four
techniques for ﬁltering the critical memory addresses and
matching with a known oracle for the target application: (1)
ofﬂine simulation; (2) searching the beginning of sensitive
accesses; (3) fuzzy pattern matching, and (4) exploiting cache
prefetching. We use the two examples to explain how to
analyze memory bus traces.
6.1 Ofﬂine Simulation
Side-channel attacks often require attackers to have some
knowledge about the behaviors of the victim. For example, the
controlled-channel attack on Hunspell requires the attacker to
extract the virtual page addresses of the linked list nodes of
each dictionary word, during an online training phase while
attacking the victim. However, MEMBUSTER cannot perform
online training with the victim as the analysis of the memory
traces is performed ofﬂine. Instead, the attacker needs to gen-
erate an oracle of the victim behavior, using ofﬂine simulation
of the target application.
We observe that, for each application, we can use a deter-
ministic oracle, given that users have adopted some publicly
available data (e.g., the en_US dictionary). For example, dur-
ing the simulation, we run a modiﬁed Hunspell in an enclave,
which prints out the indexes and the addresses of linked list
nodes visited for each word. Then, we reuse the output as
an oracle, to be used in analyzing any traces based on the
same (cid:127)en_US dictionary. We assume that there are only a ﬁnite
amount of English dictionaries in the world.
As discussed earlier, ASLR in the enclaves does not in-
validate an oracle, since ASLR can be easily defeated by
observing the speciﬁc patterns related to binary loading. The
addresses in the oracle can simply be shifted by a certain
offset to be usable again.
6.2 Searching Sensitive Accesses
Finding the ﬁrst sensitive access is critical for deciding where
to start matching access patterns. Note that not all accesses to
the critical addresses are sensitive. For Hunspell, allocating
nodes for each word emits a long sequence of monotonically
increasing virtual addresses that can be used to identify the
sensitive addresses. We match the virtual addresses to the
Figure 8: Implementation of critical page whitelisting and
cache squeezing in a modiﬁed SGX driver. To ensure no
swapping in the sensitive memory range, EPC pages are set
aside in a separate queue. The attackers can further select the
EPC pages based on set indexes or other logistics.
One can detect the cache squeezing by testing if critical
addresses are mapped in an adversarial way. Since the en-
clave is not aware of physical address mappings by itself, it
needs to experimentally detect such mapping by accessing
the addresses and measure latency. However, we claim that it
is challenging because (1) the victim needs to know the criti-
cal address range to detect the mapping, and (2) the enclave
cannot tell if the mapping was accidental or intentional.
5.4.4 Implementation
We use a modiﬁed SGX driver to implement both critical
page whitelisting and cache squeezing as shown in Figure 8.
The driver accepts parameters to specify a sensitive range
within the victim application, and calculates how many con-
ﬂict groups are required for the attack. 1(cid:13) When the driver
initializes, it inserts conﬂicting EPC pages to a separate queue
(i.e., conflict_list). 2(cid:13) When adding enclave pages, the
driver checks if the virtual page number is in the critical ad-
dress range. 3(cid:13) The driver maps the critical pages to pages
popped from conflict_list. 4(cid:13) All of the mapped pages
are added to the list of loaded pages (load_list). 5(cid:13) When
the driver needs to evict an EPC page, it searches the victim
from the list of loaded pages. 6(cid:13) If the selected page is a
critical page, it searches again. 7(cid:13) Only non-critical pages are
evicted and the enclave continues to run. Other enclaves are
not affected by the modiﬁcation and can function normal with
marginal overheads.
Our change to the SGX driver contains only 290 lines. The
SGX driver uses the fault operation in vm_operations_struct
to handle EPC paging. We use a customized fault function,
which checks the faulting virtual addresses of the enclave
and then applies different paging strategies to critical and
non-critical addresses. We hard-code the range of critical
addresses for each application and thus require switching the
drivers for a different target. Potentially, the driver can export
an API to the attackers for specifying the critical addresses.
Our driver also only supports one single victim enclave at a
time. However, we can extend the driver to target multiple
enclaves simultaneously as long as the total memory usage
can ﬁt into the EPC (required for pinning).
ksgxswapdsgx_add_page_workerfree_listload_list⑥ Victim selection:is it a critical page?conflict_listEPCELRANGECriticalPageskmap_atomic()__eadd()...__ewb()kunmap_atomic()sgx_free_page()NoYes② Page allocation:is it a critical page?NoYes①③④⑤⑦⑧oracle, to ﬁnd the longest increasing subsequence (LIS) of
addresses as accessed in the dictionary order. After ﬁnding the
LIS, the next critical access is the beginning of the sensitive
addresses.
6.3 Fuzzy Pattern Matching
In MEMBUSTER, we observe that a part of memory addresses
in a sensitive access pattern is likely to be missing due to
caching. Even with cache squeezing and cross-core priming,
it is almost impossible to force page misses on every critical
memory access. Therefore, to analyze lossy traces, we use
fuzzy pattern matching to ﬂexibly match the traces with only
parts of access patterns. As long as at least one or a few
accesses of a pattern cause LLC misses, we can identify the
pattern as a possible result for recovery.
In fuzzy pattern matching, one address may be parsed as
different access patterns of the victim for two reasons. First,
within a data structure such as a linked list or a tree, the same
address (an inner node) may be accessed while traversing
or searching other nodes. Second, a cache line may contain
multiple nodes and thus can be accessed when visiting one
of the nodes. For either of the reasons, a single memory trace
may be accounted for multiple possible access patterns in the
oracle.
We use a simple strategy to select the best interpretation for
a set of memory traces. We assign a score to each possibility
based on how complete the traces have matched with an access
pattern in the oracle. For the addresses of a tree or a linked list,
we assign lower scores to the root and the ﬁrst few nodes and
assign higher scores to nodes that are closer to leaves or the
end of the list. By collecting the top-ranking interpretations of
the memory traces, an attacker can generate a list of the most
probable options of the target secret. Potentially, a grammar
checker or any semantic-based heuristic can help to validate or
to rank the recovery results. We leave the exercise of applying
more context-aware heuristics for future work.
6.4 Exploiting Cache Prefetching
Finally, we observe that the cache prefetching features of
CPUs can help increase the accuracy of the attack. For ex-
ample, a recent Intel CPU includes Next-line Prefetcher and
128-byte Spatial Prefetcher. The Next-line Prefetcher, belong-
ing to the L2 cache, will preload the cache line next to the
one that is currently accessed. The 128-bit Spatial Prefetcher,
which also belongs to the L2 cache, prefetches the pairing
cache line that completes the accessed cache line to a 128-
byte aligned chunk into the LLC. Both prefetchers increase
the number of memory accesses relevant to the secret data.
Therefore, we expand the range of pattern matching based
on our knowledge of cache prefetching, including extending
the addresses representing each secret by 64 bytes, both back-
ward and forward. As a result, even if the CPU has cached a
line, the prefetched lines may still cause cache misses and be
observed on the memory bus.
Model
LLC Size
LLC # Slice
LLC # Associativity
LLC # Sets
CPU
Intel i5-8400 (Coffee lake)
9 MB
6 Slices
12-way set associative
2048
Memory
DDR4-2400 UDIMM (Non-ECC)
8 GB
DIMM Type
Capacity
Channel/Rank/Bank/Row 1/1/16/65536
Page Size
Max Bus Frequency
Table 2: Hardware speciﬁcation for the experiment
8 KB (1 KB/package)
1200 MHz
Other cache prefetchers such as Stream Prefetcher can
monitor an ascending or descending sequence of addresses
from the L1 or L2 cache and can prefetch up to 20 cache lines
ahead of the loaded address. Such a prefetcher generally will
not improve the accuracy of the pattern matching. However,
these prefetchers can cause space pressure to caches, making
cache squeezing more effective.
7 Evaluation
In this section we present the evaluation results of the MEM-
BUSTER attack, based on the two vulnerable applications
described in §4. The evaluation mainly answers the following
questions regarding the MEMBUSTER attacks:
• How accurate can MEMBUSTER extract the secrets from
• How do the attack techniques of MEMBUSTER impact
• How much slowdown (or interference) the various tech-
• What is the limitation of MEMBUSTER?
• How sensitive are the attack results of MEMBUSTER to
applications that are vulnerable to such an attack?
niques will incur on the applications?
the attack accuracy?
the last-level cache (LLC) size of the target CPU?
We evaluate the MEMBUSTER attack in various settings:
(1) the basic attack without any techniques (None); (2) the op-
timized attack with cache squeezing (SQ); (3) the optimized
attack with cache squeezing combined with cross-core cache
priming (SQ+PR).
7.1 Experiment Setup
In this section, we describe the experimental setup of the
MEMBUSTER attack. We use both physical and simulated
experiments to evaluate the effectiveness of MEMBUSTER.
7.1.1 Physical Experiment
Hardware Setup. The hardware setup we used for the exper-
iment is shown in Table 2. We use a machine equipped with
an Intel SGX CPU. In the machine, we connect the DIMM to
a signal analyzer via a DIMM interposer. We conﬁgure BIOS
to slightly increase the DRAM supply voltage to offset the
voltage drop caused by the interposer. The bus frequency is
set to 1066 MHz, so the bandwidth of the analyzer is 3.97
GiB/s. With a 64 GiB acquisition depth, we can log the mem-
ory bus for up to ∼ 16 seconds. All of our experiments have
ﬁnished in a few seconds, and thus the acquisition depth is
sufﬁcient for logging all the memory requests. To achieve
a wider time window, the attacker can choose an analyzer
which can ﬁlter the requests by addresses [57], or which has
a higher acquisition depth [55].
Victim Setup. The victim machine is running Ubuntu 16.04
and Linux kernel 4.4. To execute the victim applications in-
side enclaves, we use Graphene-SGX [54] to run unmodiﬁed
binaries with SGX. The victim may also choose other frame-
works [66] or port the applications with the SDK [67], but the
choices of the frameworks do not eliminate the patterns since
they do not change the program logic of the victim.
Sample Size. We collaborate with SK Hynix to use its propri-
etary analyzer for the experiments. Due to the limited access
to the device, we run the attack only once for each setting.
However, we were able to successfully perform the attack
despite the small sample size because the results match well
with our expectations learned from the simulation.
7.1.2 Microarchitectural Simulation
We also implemented a software simulator to simulate the
attack prior to an actual attack because the hardware setup
requires costly devices. We use the simulator for exploring
the attack and getting preliminary results. The results are
then cross-validated with the results from the actual hardware
setup, to verify the functional correctness of the simulation.
The attacker can also use the same strategy to save the ex-
penses for renting the devices. We modify QEMU [38], a
machine emulator, to trace all the physical memory accesses
of the guest. To capture cache misses, we make QEMU emits
all the memory requests to a cache simulator we integrated
from Spike [68]. The cache simulation does not implement
any cycle-accurate hardware model as well as cache slicing
and pseudo-LRU replacement. However, the simulation was
sufﬁciently faithful for developing the attack scripts to analyze
the real memory traces.
7.1.3 Enclave Simulation
We also simulate an enclave environment without memory
encryption, using a modiﬁed Graphene-SGX library OS and a
dummy SGX driver. We consider simulating Intel’s Memory
Encryption Engine (MEE) unnecessary because MEE does
not affect the memory addresses accessed within the EPC.
MEE generates additional access patterns for the integrity tree
or EPC metadata, both of which are stored in the Processor
Reserved Memory outside the EPC. Our attack does not rely
on any access pattern outside the EPC.
The modiﬁed Graphene-SGX library OS and the dummy
SGX driver primarily simulate the transition in and out of the
enclave and the paging of enclave memory, to generate similar
memory access patterns as observed on the memory bus. For
simulating enclave entry and exit, we modify the user-tier
SGX instructions, EENTER and EEXIT, in the Graphene-SGX
runtime, to directly jump to addresses that are originally given
as the enclave entry. We also simulate the AEX.
Technique
None
SQ
Attack Accuracy
34.1%