title:A Generic Attack on Checksumming-Based Software Tamper Resistance
author:Glenn Wurster and
Paul C. van Oorschot and
Anil Somayaji
A generic attack on checksumming-based software tamper resistance
Glenn Wurster P.C. van Oorschot Anil Somayaji
Digital Security Group, School of Computer Science,
E-mail: {gwurster, paulv, soma}@scs.carleton.ca
Carleton University, Canada
Abstract
Self-checking software tamper resistance mecha-
nisms employing checksums, including advanced sys-
tems as recently proposed by Chang and Atallah (2002)
and Horne et al. (2002), have been promoted as an alter-
native to other software integrity veriﬁcation techniques.
Appealing aspects include the promise of being able to
verify the integrity of software independent of the exter-
nal support environment, as well as the ability to auto-
matically integrate checksumming code during program
compilation or linking. In this paper, we show that the
rich functionality of many modern processors, including
UltraSparc and x86-compatible processors, facilitates
automated attacks which defeat such checksumming by
self-checking programs.
1. Introduction and Overview
Application developers have historically found it nec-
essary to protect their code from unauthorized modiﬁ-
cation on untrusted hardware and software. Copy pro-
tection has long been required to prevent illicit duplica-
tion of proprietary applications and content. The need
to protect code from unauthorized modiﬁcation has also
gained increased awareness due to recent interest in digi-
tal rights management e.g. related to distribution of con-
tent such as music and video over the Internet.
In-
creasingly, though, similar types of protection are also
needed by applications, utilities, and operating systems.
Users must now contend with increasingly sophisticated
and ubiquitous malicious software. Such malware fre-
quently changes system state, and sometimes even mod-
iﬁes program binaries and libraries. Given that the un-
derlying operating system frequently cannot provide any
integrity guarantees, “program-level intrusion detection
systems” based on tamper-resistance mechanisms may
eventually help prevent security compromises.
The efﬁciency and ease of use of recently proposed
methods for protecting code integrity through run-time
checksums [4, 12] (see also [7]) have suggested the
potential feasibility of program-level defence systems.
When combined with appropriate code obfuscation tech-
niques, these mechanisms can potentially require an at-
tacker to reverse-engineer signiﬁcant portions of a pro-
gram’s protection mechanisms in order to change even a
small part of the targeted program’s code. What appears
to be particularly appealing about these methods is that
they do not require any hardware support; instead, an
application developer simply has to pass code through
an appropriate transformation engine.
Unfortunately, the use of checksumming as a self-
checking tamper resistance mechanism rests on the as-
sumption that a given virtual address range will trans-
late to the same set of bytes whether accessed as code
or data. While this assumption might seem reasonable,
as we illustrate in this paper, in hostile environments the
design of many modern microprocessors renders it fun-
damentally ﬂawed. In particular, we show that address
translation mechanisms that distinguish between code
and data make it possible for code that is checksummed
to have no relation to the code that is actually executed
by the processor. More speciﬁcally, on vulnerable pro-
cessors it is possible for an attacker with administra-
tive privileges (i.e. in control of the operating system) to
successfully modify a code checksumming application
without reverse-engineering the application’s protection
mechanisms: when running, the processor would exe-
cute the attacker’s modiﬁed instructions; when check-
summing, the application would read a copy of its un-
modiﬁed code. The attacker need not reverse engineer
protection mechanisms; instead, much simpler, on-line
“black box” strategies may be used to achieve desired
functionality. Because such an attack is implemented
with the assistance of the processor, the compromised
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
application runs at full speed (as opposed to attacks in-
volving emulation), which is typically what the attacker
desires.
In this paper we present two variations of an attack
which defeats self-integrity checksumming used by ap-
plications for software tamper resistance. These varia-
tions are speciﬁcally discussed relative to the UltraSparc
and x86 architectures. In essence, the separation of code
and data accesses allows the attack, in one case (the Ul-
traSparc) through a special translation look-aside buffer
(TLB) load mechanism, and in the other (the x86) by
manipulation of processor-level segments.
Editorial note. Since original submission of this pa-
per, we have found other attacks which use techniques
similar to those discussed herein, but are possible on a
wider range of modern processors; see [35].
The remainder of this paper is organized as follows.
Section 2 brieﬂy reviews tamper resistance and check-
summing. Section 3 gives some background on proces-
sor support for paging virtual memory. Section 4 ex-
plores the facilities in a memory management unit which
allow for an attack, and details our implementation and
results for the UltraSparc, x86, and other processors.
Section 5 discusses noteworthy features and implica-
tions of our attack. Section 6 brieﬂy discusses related
work. Finally, Section 7 documents our conclusions.
2. Review: Tamper Resistance Techniques
and Checksumming
Software tamper resistance is the art of crafting a pro-
gram such that it cannot be modiﬁed by a potentially ma-
licious attacker without the attack being detected [2]. In
some respects, it is similar to fault-tolerant computing,
in that potentially dangerous changes in program state
are detected at runtime. For tamper resistance, however,
it is assumed that intelligent, malicious attackers (rather
than hardware ﬂaws or software errors) may be respon-
sible for such changes.
There are many methods for software protection
against tampering (e.g. see [7, 33]). While self-checking
tamper resistance is the focus of our discussion, other
approaches exist which are not susceptible to processor
design choices (see Section 6). The common trend with
these other approaches, however, is that they rely on ei-
ther additional hardware or external trusted third parties.
Self-checking tamper resistance is distinguished in its
ability to run on current unmodiﬁed commodity hard-
ware without requiring third parties. While there are
other techniques for self-checking software tamper re-
sistance (e.g. program or result checking and generating
the executable on the ﬂy – see [2, 7]), we focus on check-
summing.
The standard threat model for software tamper resis-
tance is the hostile host model [25]. The challenge is
to protect an application running on a system controlled
by a malicious, intelligent user. Because such a user can
in theory change any code on the computer, other soft-
ware on such a system, including the operating system,
is untrusted; in the case of particularly determined ad-
versaries, even the hardware is untrusted. This situation
is in contrast with the hostile client problem in which
we assume a trusted host and untrusted application. The
hostile client problem appears to be an easier problem
to solve; numerous solutions have been developed, e.g.
sandboxing (see [25] for further discussion).
Since a single checksum is relatively easy for an at-
tacker to disable, stronger proposals rely on a network
of inter-connected checksums, all of which must be dis-
abled to defeat tamper resistance. For example, Horne
et al. [12] use testers which compute a checksum of a
speciﬁc section of the code (see also [4, 14]). A tester
reads the area of memory occupied by code and read-
only data, building up a checksum result based on the
data read. A subsequent section of the code may oper-
ate on the checksum result, affecting program stability
or correctness in a negative way if a checksum result is
not the same as a known good value pre-computed at
compile time. The sections of code which perform the
checksumming operations may be further hidden using
code obfuscation techniques to prevent static analysis.
Ideally the effects of a bad checksum result in the pro-
gram are subtle (e.g. causing mysterious failures much
later in execution) thus making it much more difﬁcult
for an attacker to locate the checksum code.
Code Segment
Checksum
Checksum
Checksum
Checksum
Checksum
Checksum
Figure 1. Distribution of checksum blocks
within a code segment [12]
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
Figure 1 gives a simpliﬁed view of a typical distribu-
tion of checksum code within an application. In prac-
tise, there may be hundreds of checksum blocks hidden
within the main application code. Each allows veriﬁ-
cation of the integrity of a predetermined section of the
code segment. The read-only data segment may also be
similarly checked. The checksumming code is inserted
at compile time and integrated with regular execution
code. The application also requires a correct checksum
result for each block in order to work properly.
There are several aspects of such checksumming
which a potential attacker must keep in mind:
1. Because of the overlapping network of testers, al-
most every checksumming block must be disabled
at the same time in order for a tampering attack to
be successful.
2. The resulting value from a checksum block must
remain the same as the original value determined
during compilation (or all uses of the checksum
value must be determined and adjusted accord-
ingly), if the results of a checksum are used during
standard program execution as in [12].
3. The checksum values are only computed for static
(i.e. runtime invariant) sections of the program.
Note that a critical (implicit) assumption of check-
summing algorithms is that D(x) = I(x), where D(x)
is the bit-string result of a “data read” from memory
address x, and I(x) is the bit-string result of an “in-
struction fetch” of corresponding length from x. If I(x)
were different from D(x), then the checksumming code
would always check using D(x) while the processor
would always execute I(x). Checksumming aims to ver-
ify that the code the processor executes is the original
code, and thus assumes that the code it reads is the code
the processor executes. While current checksumming
proposals (including e.g. [4, 12] also [14]) critically rely
on this assumption, in what follows we show that it may
be violated on several modern processors, thus allowing
our attack.
3. CPU Support for Virtual Memory
This section provides background information for
those less familiar with the virtual memory subsystems
of modern processors, including translation look-aside
buffers (TLBs). Readers familiar with processor archi-
tecture are encouraged to jump directly to Section 4.
Modern processors do much more than execute a se-
quence of instructions. Advances in processor speed and
ﬂexibility have resulted in a very complex architecture.
A signiﬁcant part of this complexity comes from mech-
anisms designed to efﬁciently support virtual memory.
Virtual memory, ﬁrst introduced in the late 1950’s, in-
volves splitting main memory into an array of frames
(pages) which can be subsequently manipulated. Virtual
addresses used by an application program are mapped
into physical addresses by the virtual memory system
(see Figure 2).
Virtual Address
Page Data
Page Offset
Page Table
Translation Algorithm
Physical Address
Frame Number
Frame Offset
Figure 2. Translation of a Virtual Address
into a Physical Address
Even though the page table translation algorithm may
vary slightly between processors and may sometimes
be implemented in software, modern processors all use
roughly the same method for translating a virtual page
number to a physical frame number. Speciﬁcally, this
translation is performed through the use of page tables,
which are arrays that associate a selected number of vir-
tual page numbers with physical frame numbers. Be-
cause the virtual address spaces of most processes are
both large and sparse, page table entries are only allo-
cated for the portions of the address space that are ac-
tually used. To determine the physical address corre-
sponding to a given virtual address, the appropriate page
table, and the correct entry within that page table must
be located.
For systems that uses 3-level page tables, a virtual
address is divided into four ﬁelds, x1 through x4. The
x1 bits (the directory offset) specify an entry in a per-
process page directory. The entry contains the address
of a page map table. The x2 bits (the map offset) are
used as an offset within the speciﬁed page map table,
giving the address of a page table. The x3 bits (the table
offset) index into the chosen page table, returning the
number of a physical page frame. x4, then, speciﬁes the
offset within a physical frame that contains the data re-
ferred to by the original virtual address. This resolution
process is illustrated in Figure 3. Note that if memory
segments are used, segment translation typically occurs
before operations involving the page table.
TLBs. Because multiple memory locations must be
accessed to resolve each virtual memory address, vir-
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
Virtual Address
Directory Offset
Map Offset
Table Offset
Page Offset
Page Directory
Page Map
Page Table
Page Table
Base Pointer
Physical Address
Physical Frame
Page Offset
Figure 3. Translation of a Virtual to Physi-
cal Address through Page Tables
tual address translation using page tables is a relatively
expensive operation. To speed up these mappings, a
specialized high-speed associative memory store called
a translation look-aside buffer (TLB) is used. A TLB