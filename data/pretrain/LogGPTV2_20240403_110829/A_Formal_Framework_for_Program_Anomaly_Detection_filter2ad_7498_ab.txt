We illustrate our uniﬁed framework in Fig. 1 showing its hierarchical struc-
ture3. In Fig. 1, L-1 to L-4 indicate four major precision levels with decreasing
detection capabilities according to the expressive power of LΛ. The order of
precision levels marks the potential of approaches within these levels, but not
necessarily the practical detection capability of a speciﬁc method4. Our design
is based on both the well-deﬁned levels in Chomsky hierarchy and the existing
milestones in the evolution of program anomaly detection.
L-1: context-sensitive language level (most powerful level)
L-2: context-free language level
L-3: regular language level
L-4: restricted regular language level (least powerful level).
2 Context-sensitive languages correspond to pushdown automata.
3 The hierarchy is reasoned via Chomsky hierarchy [12], which presents the hierarchical
relation among formal grammars/languages.
4 For example, one detection approach Λa in L-2 without argument analysis could be
less capable of detecting attacks than an approach Λb in L-3 with argument analysis.
276
X. Shu et al.
Fig. 1. The hierarchy of our program anomaly detection framework. L-1 to L-4 are
four major precision levels with decreasing detection capabilities.
The restricted regular language corresponding to L-4 does not enforce spe-
ciﬁc adjacent elements for any element in a string (program trace). Two optional
properties within L-1, L-2 and L-3 are path sensitivity and ﬂow sensitivity
(Sect. 5.2). We prove the theoretical accuracy limit (the outmost circle in Fig. 1)
in Sect. 3 with an abstract detection machine ˜M. We abstract existing methods
in Sect. 4 and identify their positions in our uniﬁed framework in Sect. 5. We
present details of our framework and point out the connection between levels in
our framework and grammars in Chomsky hierarchy in Sect. 5. We describe the
evolution from L-4 methods to L-1 methods in Sect. 6.2.
3 Accuracy Limit of Program Anomaly Detection
We describe an abstract detection machine, ˜M, to diﬀerentiate between any two
precise program traces. Thus, ˜M detects any anomalous program traces given a
scope of the norm. A practical program trace ¨T that ˜M consumes is a precise
program trace T. We prove that ˜M has the identical capability of diﬀerentiating
between traces (execution paths) as the program itself. Therefore, ˜M is the
accuracy limit of program anomaly detection models.
3.1 The Ultimate Detection Machine
The abstract machine ˜M is a 9-tuple ˜M = (Q, Σ, Γ, A, Ω, δ, s0, Z, F ) where the
symbols are described in Table 1. ˜M operates from s0. If an input string/trace
¨T reaches a ﬁnal state in F , then ¨T is a normal trace.
˜M consists of three components: a ﬁnite state machine, a stack Π, and
a random-access register Υ . In ˜M, both Π and Υ are of ﬁnite sizes. Indirect
addressing, i.e., the value of a register can be dereferenced as an address of
another register, is supported by Υ and A ⊂ Ω. Because a random-access reg-
ister can simulate a stack, Π can be omitted in ˜M without any computation
A Formal Framework for Program Anomaly Detection
277
Table 1. Descriptions of symbols in ˜M . All sets are of ﬁnite sizes.
Description
Set of states
Set of input symbols
Set of symbols on the stack
Set of addresses of all registers
Name
Q States
Σ Input alphabet
Γ Stack alphabet
A Register addresses
Ω Register alphabet
δ Transition relation
s0 Initial state
Z Initial stack symbol Initial symbol on the stack, Z ⊆ Q
F Final states
ε denotes an empty string.
Ω∗
denotes a string over alphabet Ω or Γ , respectively.
Set of symbols stored in registers
Subset of Q × (Σ ∪ {ε}) × Γ × Ω∗ × Q × Γ ∗ × Ω∗
State to start, s0 ∈ Q
Set of states where ¨T is accepted, F ⊆ Q
or Γ ∗
power loss. We keep Π in ˜M to mimic the execution of a real-world program.
It helps extend ˜M for multi-threading (Sect. 3.3) and unify ˜M in our framework
(Sect. 5.1).
A transition in ˜M is deﬁned by δ, which is a mapping from (Σ ∪ {ε}) ×
Q × Γ × Ω∗ to Q × Γ ∗ × Ω∗. Given an input symbol σ ∈ Σ ∪ {ε}, the current
state q ∈ Q, the stack symbol γ ∈ Γ (stack top), and all symbols in the register
{ωi | ωi ∈ Ω, 0 ≤ i ≤ |A|}, the rules in δ chooses a new state q(cid:3) ∈ Q, pops γ,
pushes zero or more stack symbols γ0γ1γ2 . . . onto the stack, and update {ωi}.
3.2 The Equivalent Abstract Machine of an Executing Program
We state the precision of the abstract detection machine ˜M in Theorem 2 and
interpreter both suﬃciency and necessity aspects of the theorem.
Theorem 2. ˜M is as precise as the target program; ˜M can detect any anom-
alous traces if the scope of the norm is speciﬁed and ˜M is constructed.
Suﬃciency: ˜M has the same computation power as any real-world executing
program so that L ˜M can diﬀerentiate any two precise program traces.
Necessity: detection machines that are less powerful than ˜M cannot diﬀeren-
tiate any two arbitrary precise program traces of the target program.
Although a Turing machine is commonly used to model a real-world program
in execution, an executing program actually has limited resources (the tape
length, the random access memory size or the address symbol count) diﬀerent
from a Turing machine. This restricted Turing machine is abstracted as linear
bounded automaton [34]. We prove Theorem 2 by Lemmas 1 and 2.
Lemma 1. A program that is executing on a real-world machine is equivalent
to a linear bounded automaton (LBA).
278
X. Shu et al.
Lemma 2. ˜M is equivalent to a linear bounded automaton.
Proof. We prove that ˜M is equivalent to an abstract machine ¨M and ¨M is
equivalent to an LBA, so ˜M is equivalent to an LBA.
¨M is an abstract machine similar to ˜M except that Υ (the register) in ˜M is
replaced by two stacks Π0 and Π1. size(Υ ) = size(Π0) + size(Π1).
We prove that ˜M and ¨M can simulate each other below.
– One random-access register can simulate one stack with simple access rules
(i.e., last in, ﬁrst out) enforced. Thus, Υ can be split into two non-overlapping
register sections to simulate Π0 and Π1.
– Π0 and Π1 together can simulate Υ by ﬁlling Π0 with initial stack symbol
Z to its maximum height and leaving Π1 empty. All the elements in Π0 are
counterparts of all the units in Υ . The depth of an element in Π0 maps to the
address of a unit in Υ . To access an arbitrary element e in Π0, one pops all
elements higher than e in Π0 and pushes them into Π1 until e is retrieved.
After the access to e, elements in Π1 are popped and pushed back into Π0.
¨M is equivalent to an LBA: ¨M consists of a ﬁnite state machine and three
stacks, Π (same as Π in ˜M), Π0, Π1 (the two-stack replacement of Υ in ˜M).
¨M with three stacks is equivalent to an abstract machine with two stacks [48].
Two stacks is equivalent to a ﬁnite tape when concatenating them head to head.
Thus, ¨M is equivalent to an abstract machine consisting of a ﬁnite state machine
and a ﬁnite tape, which is a linear bounded automaton.
(cid:6)(cid:7)
In summary, ˜M is equivalent to an LBA and Lemma 2 holds.
3.3 Usage and Discussion
Operation of ˜M: ˜M consists of a random-access register Υ and a stack Π.
The design of ˜M follows the abstraction of an executing program. Π simulates
the call stack of a process and Υ simulates the heap. The transition δ in ˜M
is determined by the input symbol, symbols in Υ and the top of Π, which is
comparable to a real-world process. Given a precise trace T of a program, ˜M
can be operated by emulating all events (instructions) of T through ˜M.
Multi-threading Handling: although ˜M does not model multi-threading pro-
gram executions, it can be easily extended to fulﬁll the job. The basic idea is
to model each thread using an ˜M. Threads creating, forking and joining can be
handled by copying the ﬁnite state machine and stack of an ˜M to a new one or
merging two ˜Ms. δ needs to be extended according to the shared register access
among diﬀerent ˜Ms as well as the joining operation between ˜Ms.
Challenges to Realize ˜M in Practice: ˜M serves as a theoretical accuracy
limit. It cannot be eﬃciently realized in the real world because
1. The number of normal precise traces is inﬁnite.
2. The scope of the norm requires a non-polynomial time algorithm to learn.
A Formal Framework for Program Anomaly Detection
279
The ﬁrst challenge is due to the fact that a trace ¨T of a program can be
of any length, e.g., a continuous (constantly running) program generates traces
in arbitrary lengths until it halts. Most existing approaches do not have the
problem because they only model short segments of traces (e.g., n-grams with a
small n [21], ﬁrst-order automaton transition veriﬁcation [19]).
Pure dynamic analysis cannot provide a complete scope of the norm. The sec-
ond challenge emerges when one performs comprehensive static program analysis
to build ˜M. For example, one well-known exponential complexity task is to dis-
cover induction variables and correlate diﬀerent control-ﬂow branches.
4 Abstractions of Existing Detection Methods
In this section, we analyze existing program anomaly detection models and
abstract them in ﬁve categories. We identify their precision (or detection capa-
bility) in our framework in Sect. 5.
Finite State Automaton (FSA) Methods represent the category of pro-
gram anomaly detection methods that explicitly employs an FSA. Kosoresow
and Hofmeyr ﬁrst utilized a deterministic ﬁnite state automaton (DFA) to char-
acterize normal program traces [36] via black-box level traces (building a DFA
for system call traces). Sekar et al. improved the FSA method by adopting a
limited gray-box view [50]. Sekar’s method retrieves program counter informa-
tion for every traced system call. If two system calls and program counters are
the same, the same automaton state is used in the FSA construction procedure.
Abstraction: all FSA methods explicitly build an FSA for modeling normal
program traces. A transition of such an FSA can be described in (1). pi is an
automaton state that is mapped to one or a set of program states. Each program
state can be identiﬁed by a system call (black-box level traces) or a combination
of system call and program counter (gray-box level traces). s∗ denotes a string
of one or more system calls.
s∗−→ pi+1
pi
(1)
n-gram Methods represent the category of program anomaly detection meth-
ods those utilize sequence fragments to characterize program behaviors. n-grams
are n-item-long5 substrings6 of a long trace, and they are usually generated by
sliding a window (of length n) on the trace. The assumption underlying n-gram
methods is that short trace fragments are good features diﬀerentiating normal
and anomalous long system call traces [23]. A basic n-gram method tests whether
every n-gram is in the known set of normal n-grams [21].
Abstraction: a set of n-gram (of normal program behaviors) is equivalent
to an FSA where each state is an n-gram [60]. A transition of such an FSA can
5 n can be either a ﬁxed value or a variable [45, 63].
6 Lookahead pair methods are subsequent variants of n-gram methods [35].
280
X. Shu et al.
be described in (2). The transition is recognized when there exist two normal
n-grams, (s0, s1, . . . , sn−1) and (s1, . . . , sn−1, sn), in any normal program traces.
(s0, s1, . . . , sn−1) sn−→ (s1, . . . , sn−1, sn)
(2)
Since n-gram methods are built on a membership test, various determinis-
tic [45,62] and probabilistic [17,61] means are developed to deﬁne the scope of the
norm (the set of normal n-grams) and perform the membership test. And system
call arguments were added to describe system calls in more details [7,55,57].
Pushdown Automaton (PDA) Methods represent the category of program
anomaly detection methods those utilize a PDA or its equivalents to model
program behaviors. DPA methods are more precise than FSA methods because
they can simulate user-space call stack activities [18].
An FSA connects control-ﬂow graphs (CFGs) of all procedures into a
monomorphic graph, which lacks the ability to describe direct or indirect recur-
sive function calls [31,59]. A PDA, in contrast, keeps CFGs isolated and utilizes
a stack to record and verify function calls or returns [18,19,29]. Thus, it can
describe recursions. However, only exposing the stack when system calls occur
is not enough to construct a deterministic DPA [19]. There could be multiple
potential paths transiting from one observed stack state Γi to the next stack
state Γi+1. Giﬃn et al. fully exposed all stack activities in Dyck model [30] by
embedding loggers for function calls and returns via binary rewriting.
Abstraction: a typical PDA method consumes white-box level traces [19]
or gray-box level traces [43]. The internal (user-space) activities of the running
program between system calls are simulated by the PDA. Denote a system call
as s and a procedure transition as f. We describe the general PDA transition in
(3) where Γi/Γi+1 is the stack before/after the transition, respectively.
pi, Γi
f or s−−−−→ pi+1, Γi+1
(3)
System call arguments can be added to describe calls in more details like
they are used in previous models. In addition, Bhatkar et al. utilized data-ﬂow
analysis to provide complex system call arguments veriﬁcation, e.g., unary and
binary relations [4]. Giﬃn et al. extended system call arguments to environment
values, e.g., conﬁgurations, and built an environment-sensitive method [28].
Probabilistic Methods diﬀer from deterministic program anomaly detection
approaches that they use stochastic languages to deﬁne the scope of the norm
(Sect. 2.3). Stochastic languages are probabilistic counterparts of deterministic
languages (e.g., regular languages). From the automaton perspective, stochastic
languages correspond to automata with probabilistic transition edges.
Abstraction: existing probabilistic program anomaly detection methods are
probabilistic counterparts of FSA, because they either use n-grams or FSA with
probabilistic transitions edges. Typical probabilistic detection methods include
hidden Markov model (HMM) [61,64], classiﬁcation methods [16,37,41,46], arti-
ﬁcial neural network [27], data mining approaches [40], etc. Gu et al. presented
A Formal Framework for Program Anomaly Detection
281
a supervised statistical learning model, which uses control-ﬂow graphs to help
the training of its probabilistic model [32].
Probabilistic FSA does not maintain call stack structures7, and it constrains
existing probabilistic approaches from modeling recursions precisely. In theory,
FSA and probabilistic FSA only diﬀer in their scopes of the norm; one is deter-
ministic the other is probabilistic. The precision or detection capability of the
two are the same as explained in Sect. 2.3. Diﬀerent thresholds in parametric
probabilistic models deﬁne diﬀerent scopes of the norm, but they do not directly
impact the precision of a model.
N-variant Methods deﬁne the scope of the norm with respect to the current
execution path under detection. They are diﬀerent from the majority of detection
methods that deﬁne the scope of the norm as all possible normal execution paths.
In N-variant methods, a program is executed with n replicas [14]. When one
of them is compromised, others – that are executed with diﬀerent settings or in
diﬀerent environments – could remain normal.
The anomaly detection problem in N-variant methods is to tell whether one