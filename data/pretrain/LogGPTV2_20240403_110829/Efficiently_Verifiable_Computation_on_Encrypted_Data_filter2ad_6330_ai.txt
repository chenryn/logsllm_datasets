By the correctness of the closed-form eﬃcient PRF, Game 1 is identically distributed to Game
0.
Game 2: this game is the same as Game 1, except that the PRF is replaced by a truly random
function R : {0, 1}∗×[1, t] → Rk. Via a simple reduction to the security of the PRF it is possible
to show that Game 2 is computationally indistinguishable from Game 1.
Game 3: this is the same as Game 2 except for changing the distribution of the public key by
sampling y $← Rk. Note that at this point the encryption scheme becomes lossy. Also, by the
Gap-2k-Residuosity assumption Game 3 is computationally indistinguishable from Game 2.
Game 4: this is like Game 3 except that the challenger answers with 0 (reject) every veriﬁcation
query σy = (∆, c, σ) in which ∆ was never chosen in a ProbGen query during the experiment
(and of course the function f is non-zero).
It is possible to show that, information theoretically, Game 4 is statistically close to Game 3.
Game 5: Change as follows the way to check veriﬁcation queries (∆, c, σ) in which ∆ was previ-
ously generated in a ProbGen query (otherwise the query is rejected as well by the modiﬁca-
tion in the previous game). Let ˜c1, ˜σ1, . . . , ˜ct, ˜σt be the corresponding values obtained in that
i as in the Compute
ProbGen query. From such values compute ˜σ =(cid:81)t
i and ˜c =(cid:81)t
i=1 ˜σfi
i=1 ˜cfi
algorithm. Check if
σ/˜σ = (c/˜c)α
Game 6: Simulate all ProbGen queries without using α, i.e., sample directly σi
and if so accept, otherwise reject.
Note that by correctness, the above check is equivalent to the real veriﬁcation. Hence Game 5
is identically distributed to Game 4.
$← Rk. Note
that from Game 3 the ciphertexts ci are in Rk (since y ∈ Rk. Hence, Game 6 is identically
distributed to Game 5.
It is worth noting that now α is used only for veriﬁcation. If we imagine to sample α at the
time of the ﬁrst veriﬁcation query, then at that point α is uniformly distributed over Z∗
φ(N ).
Game 7: All veriﬁcation queries where (c, σ) = (˜c, ˜σ) are directly answered with 1, i.e., without
using α. If c (cid:54)= ˜c, then answer with reject. We claim that Game 7 is statistically close to Game
6.
In particular, if we change only the answer to the ﬁrst query, the distance is  = Pr[(c/˜c)α = σ/˜σ]
taken over the random choice of α that is
2k−1(p(cid:48)−1)(q(cid:48)−1) , which is negligible. By
extending this argument to all possible Q veriﬁcation queries the distance is ≤
1
φ(N )| =
|Z∗
Q
1
φ(N )|−Q .
|Z∗
35
Input privacy follows by deﬁning a hybrid game in which the public element y is sampled
uniformly in Rk. Such change is computationally indistinguishable by the Gap-2k-Residuosity as-
sumption. Then, it is easy to see that the encryption is lossy, and thus no information on the plain
texts is leaked. Moreover, note that in this proof the veriﬁcation oracle can be easily simulated
(cid:117)(cid:116)
without the knowledge of the factorization of N .
9 Applications
9.1 Statistics on Encrypted Data Sets
Consider the problem in which a client stores several large data-sets x1, . . . , xN on a server, and
wants to compute a collection of statistics on the outsourced data in a private and veriﬁable way.
By using our scheme for multi-variate quadratic polynomials of section 5, we can provide eﬃcient
solutions for the computation of several statistical functions, such as average, variance, standard
deviation, RMS, covariance, linear regression, Pearson’s and uncentered correlation coeﬃcient. Be-
low, we show how these statistical functions can be decomposed into simpler non-rational functions
that we can authenticate using our scheme. For vectors x = (x1, . . . , xt), y = (y1, . . . , yt), we deﬁne
the following basic functions:
f1(x) = (cid:107)x(cid:107)1 =
xj,
f2(x, y) = (cid:104)x, y(cid:105) =
xj · yj,
t(cid:88)
j=1
f3(x, y) = f1(x) · f1(y) =
t(cid:88)
 t(cid:88)
j=1
·
yj
(cid:32) t(cid:88)
(cid:33)
xi
We now give a description that explains how to use our scheme in section 5 for the following
i=1
j=1
functions:
Average: Authenticate f1(x), since
(cid:80)t
j=1 xj
t
avg(x) =
Variance: Authenticate f1(x) and f2(x, x), since
var(x) =
(cid:80)t
j=1(xj − avg(x))2
f2(x, x)
t
− f1(x)2
=
f1(x)
t
.
(cid:80)t
j=1 x2
j
t
− ((cid:80)t
i=1 xi)2
t2
=
Standard deviation: Since stdev(x) =(cid:112)var(x), use the method for authenticating variance.
t2
=
t
Root Mean Square: Authenticate f2(x, x), since
(cid:115)(cid:80)t
j=1 x2
j
t
RMS(x) =
36
Covariance: Authenticate f2(x, y) and f3(x, y), since
(cid:80)t
j=1(xj − avg(x))(yj − avg(y))
(cid:80)t
i=1 xi)((cid:80)t
− ((cid:80)t
j=1 xjyj
j=1 yj)
t
t2
t
f2(x, y)
t
− f3(x, y)
t2
cov(x, y) =
=
=
Linear Regression: Given two sets of observations as two vectors (x, y), the linear regression of
y as a function of x is deﬁned by two coeﬃcients ˆα, ˆβ such that
(cid:80)t
(cid:80)t
i=1(xi − avg(x))(yi − avg(y))
i=1(xi − avg(x))2
ˆβ =
ˆα = avg(y) − ˆβ · avg(x) = (f1(y) − ˆβf1(x))/t
=
cov(x, y)
var(x)
f2(x, y) − f3(x, y)/t
f2(x, x) − f1(x)/t
=
Hence, authenticate f1(x), f1(y), f2(x, y), f2(x, x), f3(x, y).
Sample Pearson’s correlation coeﬃcient: Authenticate f1(x), f1(y), f2(x, y), f2(x, x), f2(y, y),
f3(x, y), since
(cid:80)t
(cid:113)(cid:80)t
i=1(xi − avg(x))2 ·(cid:113)(cid:80)t
i=1(xi − avg(x))(yi − avg(y))
t(cid:112)(f2(x, x)/t − f1(x)2/t2)(f2(y, y)/t − f1(y)2/t2)
(cid:112)f2(x, x)f2(y, y) − f2(x, x)f1(y)2/t − f1(x)2f2(y, y)/t + f1(x)2f1(y)2/t2)
f2(x, y) − f3(x, y)/t
f2(x, y) − f3(x, y)/t
i=1(yi − avg(y))2
stdev(x)stdev(y)
cov(x, y)
=
rx,y =
=
=
Uncentered correlation coeﬃcient: Authenticate f2(x, y), f2(x, x), f2(y, y), since
(cid:80)t
i ·(cid:113)(cid:80)t
i=1 xiyi
i=1 x2
(cid:113)(cid:80)t
i=1 y2
i
ru
x,y =
(cid:112)f2(x, x)f2(y, y)
f2(x, y)
=
entry Di =(cid:80)N
9.2 Distance and Correlation Measures on Encrypted Data Sets
Consider the problem in which a client stores a large matrix X ∈ FL×N
on a server, and then wants
p
to compute the Euclidean distance between a given vector y ∈ FN
p and each row of the matrix.
Namely, on input y from the client, the server computes a vector D = (D1, . . . , DL) where every
j=1(Xi,j − yj)2 is the (square of the) Euclidean distance5 between y and the i-th row
of X. For security, we are interested in a solution that guarantees both integrity and privacy, i.e.,
results are eﬃciently veriﬁable by the clients without having to store the matrix X, and the server
does not learn any information about X or the queried vector y.
To achieve a solution for this application we can employ the function-private scheme VC∗
quad for
degree-2 polynomials (by explicitly relying on its split version) as follows:
5 For simplicity, we assume that the ﬁnal square root can be directly computed by the client.
37
– Given the vector y, the client deﬁnes the function fy(z1, . . . , zN ) =(cid:80)N
– First, the client generates the secret key for the input-encoding (P KE, SKE) $← KeyGenE(λ).
$← ProbGen(SKE, X i)
– In a pre-processing phase, given the matrix X, the client computes σx,i
for all the rows of X. Precisely, we can use batching to encode s rows in the same σx,i. The cost
of this phase, which is performed only once, is O(L · N ).
j=1(zj − yj)2, and runs
$← KeyGenV (fy, λ, P KE, SKE). Note that fy is an admissible function for
(EKfy , SKfy )
VC∗
quad as it is of degree-2 and all the constants derived from the yj’s multiply degree-1 terms.
Moreover, notice that the client can compactly send fy to the server by sending ˆH(yi). This
phase costs O(N ).
– The server computes σDi←Compute(EKE, EKfy , σx,i) for every (packed) row of the encrypted
matrix, and returns (σD1, . . . , σDL) to the client.
– Finally, the client obtains the veriﬁed result by running the veriﬁcation algorithm on each σDi.
The cost of verifying each entry is O(1) which sums up to O(L).
To summarize, after the pre computation to outsource the matrix, the work performed by the
client to send y and verify the result is O(N + L), which outperforms the cost of running this
computation, which is O(L · N ). Note also that the pre computation cost can be amortized when
asking many queries y for the same matrix X. For privacy note that by input privacy and function
privacy the server does not learn information about the matrix X or the vector y.
While the protocol above is described for the Euclidean distance, it is easy to see that the same
approach works also for other degree-2 functions with the same properties. Namely, for any f (y, Xi)
such that by ﬁxing y, f is of degree-2 and multiplications by yi involve only degree-1 monomials.
For example, this property holds for the covariance (or correlation coeﬃcients) between y and each
row of X.
9.3 Discrete Fourier Transform
The discrete Fourier transform (DFT) of a t-dimensional vector f is deﬁned as the vector y =
(f (α1), . . . , f (αt)) where f is interpreted as the coeﬃcients vector of a polynomial of degree (t− 1),
and the αi’s are the t roots of unity. It is easy to see that by using our scheme for univariate
polynomials of section 6, a client can store encrypted vectors on a server and then request the DFT
transform of these vectors in a private and veriﬁable way. In particular, note that the delegation
and veriﬁcation cost is optimal: O(t) (i.e., O(1) for every entry of y).