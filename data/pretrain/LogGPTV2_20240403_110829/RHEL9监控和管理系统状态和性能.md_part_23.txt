下面的步骤描述了如何使用 `mcelog`{.literal}
服务在引导过程中更改服务的优先级。
::: orderedlist
**先决条件**
1.  安装 tuned 软件包：
    ``` screen
    # dnf install tuned
    ```
2.  启用并启动 tuned 服务：
    ``` screen
    # systemctl enable --now tuned
    ```
:::
::: orderedlist
**步骤**
1.  查看正在运行的线程的调度优先级：
    ``` literallayout
    # tuna --show_threads
                          thread       ctxt_switches
        pid SCHED_ rtpri affinity voluntary nonvoluntary             cmd
      1      OTHER     0     0xff      3181          292         systemd
      2      OTHER     0     0xff       254            0        kthreadd
      3      OTHER     0     0xff         2            0          rcu_gp
      4      OTHER     0     0xff         2            0      rcu_par_gp
      6      OTHER     0        0         9            0 kworker/0:0H-kblockd
      7      OTHER     0     0xff      1301            1 kworker/u16:0-events_unbound
      8      OTHER     0     0xff         2            0    mm_percpu_wq
      9      OTHER     0        0       266            0     ksoftirqd/0
    [...]
    ```
2.  创建附加 `mcelog`{.literal}
    服务配置文件，并在该文件中插入策略名称和优先级：
    ``` screen
    # cat  /etc/systemd/system/mcelog.system.d/priority.conf
    >
    [SERVICE]
    CPUSchedulingPolicy=_fifo_
    CPUSchedulingPriority=_20_
    EOF
    ```
3.  重新载入 `systemd`{.literal} 脚本配置：
    ``` screen
    # systemctl daemon-reload
    ```
4.  重启 `mcelog`{.literal} 服务：
    ``` screen
    # systemctl restart mcelog
    ```
:::
::: itemizedlist
**验证步骤**
-   显示 `systemd`{.literal} 问题设置的 `mcelog`{.literal} 优先级：
    ``` literallayout
    # tuna -t mcelog -P
    thread       ctxt_switches
      pid SCHED_ rtpri affinity voluntary nonvoluntary             cmd
    826     FIFO    20  0,1,2,3        13            0          mcelog
    ```
:::
::: itemizedlist
**其他资源**
-   `systemd(1)`{.literal} 和 `tuna(8)`{.literal} man page
-   [优先级范围的描述](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9-beta/html-single/monitoring_and_managing_system_status_and_performance/tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance#priority-map_tuning-scheduling-policy){.link}
:::
:::
::: section
::: titlepage
# []{#tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance.html#priority-map_tuning-scheduling-policy}优先级映射 {.title}
:::
优先级在组中定义，有一些组专用于特定内核功能。对于实时调度策略，可以使用
`1`{.literal}（最低优先级）和 `99`{.literal} （最高优先级）之间的整数。
下表描述了优先级范围，可在设置进程的调度策略时使用。
::: table
[]{#tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance.html#idm140048833182032}
**表 14.2. 优先级范围的描述**
::: table-contents
  Priority   线程                     描述
  ---------- ------------------------ -------------------------------------------------------------------------------------------------
  1          低优先级内核线程         此优先级通常为需要超过 `SCHED_OTHER`{.literal} 的任务保留。
  2 - 49     可供使用                 用于典型的应用程序优先级的范围。
  50         默认 hard-IRQ 值          
  51 - 98    高优先级线程             对定期执行的线程使用此范围，且必须快速响应时间。不要将此范围用于 CPU 密集型线程，因为您将中断。
  99         Watchdogs 和 migration   必须以最高优先级运行的系统线程。
:::
:::
:::
::: section
::: titlepage
# []{#tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance.html#tuned-cpu-partitioning-profile_tuning-scheduling-policy}TuneD cpu-partitioning 配置集 {.title}
:::
要为对延迟敏感的工作负载调整 Red Hat Enterprise Linux 9，红帽建议使用
`cpu-partitioning`{.literal} TuneD 配置集。
在 Red Hat Enterprise Linux 9 之前，低延迟 Red Hat
文档描述了实现低延迟调整所需的大量低级别步骤。在 Red Hat Enterprise
Linux 9 中，您可以使用 `cpu-partitioning`{.literal} TuneD
配置集更有效地执行低延迟性能优化。根据个人低延迟应用程序的要求，此配置集可轻松自定义。
下图显示了如何使用 `cpu-partitioning`{.literal} 配置集。这个示例使用 CPU
和节点布局。
::: figure
[]{#tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance.html#cpu-partitioning_tuning-scheduling-policy}
**图 14.1. cpu-partitioning 图**
::: figure-contents
::: mediaobject
![CPU 分区](images/cpu-partitioning.png)
:::
:::
:::
您可以使用以下配置选项在
`/etc/tuned/cpu-partitioning-variables.conf`{.literal} 文件中配置
cpu-partitioning 配置集：
::: variablelist
[带有负载均衡的隔离 CPU]{.term}
:   在 cpu-partitioning 图中，从 4 到 23 编号的块是默认的隔离
    CPU。在这些 CPU
    上启用了内核调度程序的进程负载均衡。它专为需要内核调度程序负载平衡的多个线程的低延迟进程而设计。
    您可以使用 `isolated_cores=cpu-list`{.literal} 选项在
    `/etc/tuned/cpu-partitioning-variables.conf`{.literal} 文件中配置
    cpu-partitioning 配置集，它列出了 CPU
    来隔离将使用内核调度程序负载平衡。
    隔离的 CPU 列表用逗号分开，也可以使用一个短划线（如 `3-5`{.literal}
    ）指定范围。这个选项是必须的。这个列表中缺少的任何 CPU
    会自动被视为内务 CPU。
[没有负载均衡的隔离 CPU]{.term}
:   在 cpu-partitioning 图中，编号为 2 和 3
    的块是不提供任何其他内核调度程序进程负载均衡的隔离 CPU。
    您可以使用 `no_balance_cores=cpu-list`{.literal} 选项在
    `/etc/tuned/cpu-partitioning-variables.conf`{.literal} 文件中配置
    cpu-partitioning 配置集，它列出了不使用内核调度程序负载平衡的 CPU。
    指定 `no_balance_cores`{.literal} 选项是可选的，但此列表中的任何 CPU
    都必须是 `isolated_cores`{.literal} 列表中所列 CPU 的子集。
    使用这些 CPU 的应用程序线程需要单独固定到每个 CPU。
[日常 CPU]{.term}
:   在 `cpu-partitioning-variables.conf`{.literal} 文件中没有隔离的 CPU
    会自动被视为内务 CPU。在内务 CPU
    上，允许执行所有服务、守护进程、用户进程、可移动内核线程、中断处理程序和内核计时器。
:::
::: itemizedlist
**其他资源**
-   `tuned-profiles-cpu-partitioning(7)`{.literal} man page
:::
:::
::: section
::: titlepage
# []{#tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance.html#using-the-tuned-cpu-partitioning-profile-for-low-latency-tuning_tuning-scheduling-policy}使用 TuneD cpu-partitioning 配置集进行低延迟调整 {.title}
:::
这个步骤描述了如何使用 TuneD 的 `cpu-partitioning`{.literal}
配置集为低延迟调整系统。它使用了低延迟应用的示例，它可以使用
`cpu-partitioning`{.literal} 和 CPU 布局，如
[cpu-partitioning](#tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance.html#cpu-partitioning_tuning-scheduling-policy "图 14.1. cpu-partitioning 图"){.link}
图中所述。
本例中的应用程序使用了：
::: itemizedlist
-   从网络读取数据的专用的 reader 线程将固定到 CPU 2。
-   处理此网络数据的大量线程将固定到 CPU 4-23。
-   将处理的数据写入网络的专用写入器线程将固定到 CPU 3。
:::
::: itemizedlist
**先决条件**
-   您已以 root 用户身份，使用
    `dnf install tuned-profiles-cpu-partitioning`{.literal} 命令安装
    `cpu-partitioning`{.literal} TuneD 配置集。
:::
::: orderedlist
**步骤**
1.  编辑 `/etc/tuned/cpu-partitioning-variables.conf`{.literal}
    文件并添加以下信息：
    ``` screen
    # Isolated CPUs with the kernel’s scheduler load balancing:
    isolated_cores=2-23
    # Isolated CPUs without the kernel’s scheduler load balancing:
    no_balance_cores=2,3
    ```
2.  设置 `cpu-partitioning`{.literal} TuneD 配置集：
    ``` screen
    # tuned-adm profile cpu-partitioning
    ```
3.  重启
    重新引导后，将根据 cpu-partitioning
    图中的隔离，为低延迟调优。该应用可以使用 taskset
    将读取器和写入器线程固定到 CPU 2 和 3，以及 CPU 4-23
    上剩余的应用程序线程。
:::
::: itemizedlist
**其他资源**
-   `tuned-profiles-cpu-partitioning(7)`{.literal} man page
:::
:::
::: section
::: titlepage
# []{#tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance.html#customizing-the-cpu-partitioning-tuned-profile_tuning-scheduling-policy}自定义 cpu-partitioning TuneD 配置集 {.title}
:::
您可以扩展 TuneD 配置集，以进行额外的性能优化更改。
例如，`cpu-partitioning`{.literal} 配置集将 CPU 设置为使用
`cstate=1`{.literal}。要使用 `cpu-partitioning`{.literal}
配置集，但额外将 CPU cstate 从 cstate1 更改为
cstate0，以下流程描述了一个新的 TuneD 配置集，名称为
[*my_profile*]{.emphasis}，它继承 `cpu-partitioning`{.literal}
配置集，然后设置 C state-0。
::: orderedlist
**步骤**
1.  创建 `/etc/tuned/my_profile`{.literal} 目录：
    ``` screen
    # mkdir /etc/tuned/my_profile
    ```
2.  在此目录中创建 `tuned.conf`{.literal} 文件并添加以下内容：
    ``` screen
    # vi /etc/tuned/my_profile/tuned.conf
    [main]
    summary=Customized tuning on top of cpu-partitioning
    include=cpu-partitioning
    [cpu]
    force_latency=cstate.id:0|1
    ```
3.  使用新配置集：
    ``` screen
    # tuned-adm profile my_profile
    ```
:::
::: {.note style="margin-left: 0.5in; margin-right: 0.5in;"}
### 注意 {.title}
在共享示例中，不需要重新启动。但是，如果 [*my_profile*]{.emphasis}
配置集中的更改需要重新引导才能生效，则重新启动计算机。
:::
::: itemizedlist
**其他资源**
-   `tuned-profiles-cpu-partitioning(7)`{.literal} man page
:::
:::
:::
[]{#assembly_configuring-resource-management-using-systemd_monitoring-and-managing-system-status-and-performance.html}
::: chapter
::: titlepage
# []{#assembly_configuring-resource-management-using-systemd_monitoring-and-managing-system-status-and-performance.html#assembly_configuring-resource-management-using-systemd_monitoring-and-managing-system-status-and-performance}第 15 章 使用带有 systemd 的 cgroup 版本 2 配置资源管理 {.title}
:::
systemd 的核心是服务管理和规范。systemd
确保正确的服务在正确时间以正确顺序启动。服务运行时，它们必须顺利运行，才能以最佳的方式使用底层硬件平台。因此，systemd
还提供定义资源管理策略和调整各种选项的功能，它们可以提高服务性能。
::: section
::: titlepage
# []{#assembly_configuring-resource-management-using-systemd_monitoring-and-managing-system-status-and-performance.html#_prerequisites}先决条件 {.title}
:::
::: itemizedlist
-   [Linux
    cgroup](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9-beta/html/managing_monitoring_and_updating_the_kernel/setting-limits-for-applications_managing-monitoring-and-updating-the-kernel#understanding-control-groups_setting-limits-for-applications){.link}
    子系统的基础知识.
:::
:::
::: section
::: titlepage
# []{#assembly_configuring-resource-management-using-systemd_monitoring-and-managing-system-status-and-performance.html#con_understanding-resource-management-using-systemd_assembly_configuring-resource-management-using-systemd_monitoring-and-managing-system-status-and-performance}资源分配模型简介 {.title}
:::