tographic keys of the site. As will become relevant below,
we allow the attacker to capture the site’s persistent storage
multiple times, periodically.
We stress that the information captured by the attacker in-
cludes only information stored persistently at the site. Recall
that the principle behind honeywords is to leverage their use
in login attempts to alert the target that its credential database
has been stolen. As such, we must assume that transient in-
formation that arrives in a login attempt but is not stored
persistently at the site is unavailable to the attacker. Other-
wise, the attacker would simply capture the correct password
for an account once the legitimate owner of that account logs
in. Since the site’s breach leaks any long-term secrets, this
USENIX Association
30th USENIX Security Symposium    841
assumption implies that the cryptographic protocol protect-
ing user logins provides perfect forward secrecy [20]3 or that
the attacker simply cannot observe login traﬃc. Similarly,
we assume that despite breaching the target site, the attacker
cannot predict future randomness generated at the site.
We also highlight that, like in Juels and Rivest’s honeyword
design [25], we do not consider the active compromise of the
target. In particular, the integrity of the target’s persistent
storage is maintained despite the attacker’s breach, and the
site always executes its prescribed algorithms. Without this
assumption, having the target detect its own breach is not
possible. We do, however, permit the attacker to submit login
attempts to the target via its provided login interface.
Finally, while the adversary might steal passwords cho-
sen by some legitimate users of the target (e.g., by phishing,
keylogging, or social engineering) and be a user of the site
himself, Amnesia leverages the activity of other account own-
ers, each of whose chosen password is indistinguishable to the
attacker in the set of passwords listed for her account. As such,
when we refer to account owners below, we generally mean
ones who have not been phished or otherwise compromised.
4.2 Algorithm
In this section we detail our algorithm for a target to leverage
honeywords for each of its accounts to detect its own breach.
Somewhat counterintuitively, in our design the honeywords
the target site creates for each account are indistinguishable
from the correct password, even to itself (and so to an attacker
who breaches it)—hence the name Amnesia. However, the
passwords for an account (i.e., both user-chosen and honey)
are marked probabilistically with binary values. Marking en-
sures that the password last used to access the account is
always marked (i.e., its associated binary value is 1). Specif-
ically, upon each successful login to an account, the set of
passwords is remarked with probability premark, in which case
the entered password is marked (with probability 1.0) and
each of the other passwords is marked independently with
probability pmark. As such, if an attacker accesses the account
using a honeyword, then the user-chosen password becomes
unmarked with probability premark(1− pmark). In that case,
the breach will be detected when the user next accesses the
account, since the password she supplies is unmarked.
More speciﬁcally, the algorithm for the target to detect its
own breach works as follows. The algorithm is parameterized
by probabilities pmark and premark, and an integer k > 0. It
leverages a procedure mark shown in Fig. 1, which marks the
given element e with probability 1.0, marks other elements of
DBa .auths for the given account a with probability pmark, and
stores these markings in the credential database for account a
as the function DBa .marks.
mark(a,e):
• X ← DBa .auths
• Choose marked : X → {0,1} subject to:
/* Assumption: e ∈ DBa .auths */
– marked(e) = 1
– ∀e(cid:48) ∈ X\{e} : marked(e(cid:48)) ∼ Bernoulli(pmark)
• DBa .marks ← marked
Figure 1: Procedure mark, used in Secs. 4–5
Password registration: When the user sets (or resets)
the password for her account a, she provides a user-
chosen password π. The password registration system
generates DBa .auths ← HoneyGen(a, π,k) and then in-
vokes mark(a, π).
Login: When a login is attempted to account a with
password π, the outcome is determined as follows:
• If π (cid:60) DBa .auths, then the login attempt is unsuccess-
• If π ∈ DBa .auths and DBa .marks(π) = 0, then the lo-
gin attempt is unsuccessful and a credential database
breach is detected.
• Otherwise (i.e., π ∈ DBa .auths and DBa .marks(π) =
1) the login attempt is successful.4 In this case,
mark(a, π) is executed with probability premark.
ful.
This algorithm requires that a number of considerations
be balanced if an attacker can breach the site repeatedly to
capture its credential database many times. Consider that:
• Repeatedly observing the passwords left marked by user
logins permits the attacker to narrow in on the user-chosen
password as the one that is always marked. This suggests
that legitimate logins should remark the passwords as rarely
as possible (i.e., premark should be small) or that, when
remarking occurs, doing so results in passwords already
marked staying that way (i.e., pmark should be large).
• If the attacker accesses an account between two logins by
the user, a remarking must occur between the legitimate
logins if there is to be any hope of the second legitimate
login triggering a detection (i.e., premark should be large).
• If the attacker is permitted to trigger remarkings many times
between consecutive legitimate logins, however, then it can
do so repeatedly until markings are restored on most of
the passwords that were marked when it ﬁrst accessed the
account. The attacker could thereby reduce the likelihood
that the next legitimate login detects the breach. This sug-
gests that it must be diﬃcult for the attacker to trigger many
remarkings on an account (i.e., premark should be small) or
that when remarkings occur, signiﬁcantly many passwords
3Cohn-Gordon et al. [9] observe that for a passive attacker, perfect forward
secrecy implies protection not only against the future compromise of the
long-term key but also its past compromise.
4Or more precisely, the stage of the login pipeline dealing with the pass-
word is deemed successful. Additional steps, such as a second-factor authen-
tication challenge, could still be required for the login to succeed.
842    30th USENIX Security Symposium
USENIX Association
are left unmarked (i.e., pmark should be small).
All of this is complicated by the fact that the target site can-
not distinguish between legitimate and attacker logins, of
course. While an anomaly detection system (ADS) using fea-
tures of each login attempt other than the password entered
(e.g., [18]) could provide a noisy indication, unfortunately
our threat model permits the attacker to learn all persistent
state that the target site uses to manage logins; this would
presumably include the ADS model for each account, thereby
enabling the adversary to potentially evade it. For this reason,
we eschew this possibility, instead settling for a probability
premark of remarking passwords on a successful login and, if
so, a probability pmark with which each password is marked
(independently), that together balance the above concerns. We
explore such settings in Sec. 4.3.
4.3 Security
Methodology: To evaluate the security of our algorithm, we
model an attack as a Markov decision process (MDP) con-
sisting of a set of states and possible transitions among them.
When the MDP is in a particular state, the attacker can choose
from a set of available actions, which determines a probability
distribution over the possible next states as a function of the
current state and the action chosen. Using probabilistic model
checking, we can evaluate the success of the adversary in
achieving a certain goal (see below) under his best possible
strategy for doing so. In our evaluations below, we use the
Prism model checker [29].
(cid:16)
k,(pmark)(cid:96)(cid:17)
The basic distributions for modeling our algorithm for a
single account are straightforward. Let (cid:142)(cid:96) denote the number
of passwords that the attacker always observes as marked
in (cid:96) breaches of the target, with each pair of breaches sep-
arated by at least one remarking in a legitimate-user login.
(Breaches with no remarking between them will observe the
same marks.) Then, (cid:142)(cid:96) ∼ binomial
+ 1, where
the “+ 1” represents the user-chosen password, which re-
mains marked across these (cid:96) remarkings. Now, letting (cid:129)n
denote the number of these passwords that are marked after
an adversary-induced remarking, conditioned on (cid:142)(cid:96) = n + 1,
we know (cid:129)n ∼ binomial(n, pmark) + 1, where the “+ 1” rep-
resents the marked password that the adversary submitted to
log into the account, which remains marked with certainty. If
(cid:129)n = α + 1 after the adversary’s login, then the probability of
the target detecting its own breach upon the legitimate user’s
next login to this account is 1− α+1
n+1 .
To turn these distributions into a meaningful MDP, however,
we need to specify some additional limits.
• The number of attacker breaches until it achieves (cid:96) that
each follows a distinct remarking induced by a legitimate
user login is dependent not only on premark, but also the rate
of user logins. In our experiments, we model user logins
as Poisson arrivals with an expected number λ = 1 login
per time unit. We permit the attacker to breach the site and
capture all stored state at the end of each time unit.
• Even with this limit on the rate of legitimate user logins, an
attacker that breaches the site arbitrarily many times will
eventually achieve (cid:142)(cid:96) = 1 and so will know the legitimate
user’s password. In practice, however, the attacker cannot
wait arbitrarily long to access an account, since there is a
risk that his breaches will be detected by other means (i.e.,
not by our algorithm). To model this limited window of
vulnerability, we assume that the time unit in which the
breach is discovered by other means (at the end of the time
unit), and so the experiment stops, is represented as a ran-
dom variable (cid:147) distributed normally with mean µstop and
relative standard deviation χstop = 0.2. For example, assum-
ing a seven-month average breach discovery delay [23], an
account whose user accesses it once per week on average,
would have µstop ≈ 30 time units (weeks).
• Once the attacker logs into the account with one of the
n + 1 passwords that it observed as always marked in its
breaches, it can log in repeatedly (i.e., resample (cid:129)n) to
leave the account with marks that minimize its probability
of detection on the next legitimate user login. If allowed
an unbounded number of logins, it can drive its probability
of detection to zero. Therefore, we assume that the site
monitors accounts for an unusually high rate of successful
logins, limiting the adversary to at most Λ per time unit.
Let random variable (cid:140) denote the time unit at which the
attacker logs into the account for the ﬁrst time, and let random
variable (cid:132) ≤ (cid:147) denote the time unit at which the attacker is
detected. That is, (cid:132) < (cid:147) means that our algorithm detected the
attacker before he was detected by other means. Moreover,
note that (cid:140) < (cid:132), since our algorithm can detect the attacker
only after he logs into the account. We deﬁne the beneﬁt of
our algorithm to be the expected number of time units that
our algorithm deprives the attacker of undetectably accessing
the account, expressed as a fraction of the number of time
units it could have done so in the absence of our algorithm.
In symbols:
= 1− E((cid:132)− (cid:140))
E((cid:147)− (cid:140))
(3)
beneﬁt =
E((cid:147)− (cid:140))− E((cid:132)− (cid:140))
E((cid:147)− (cid:140))
When computing beneﬁt, we do so for an attacker strategy
maximizing E((cid:132)− (cid:140)), i.e., against an attacker that maximizes
the time for which it accesses the account before it is detected.
Results: The computational cost of model-checking this MDP
is such that we could complete it for only relatively small
(but still meaningful) parameters. The results we achieved
are reported in Figs. 2–4. To explore how increasing each
of k, Λ, and µstop aﬀects beneﬁt, each of the tables in Fig. 2
corresponds to modifying one parameter from the baseline
table shown in Fig. 2a, where k = 48, Λ = 4, and µstop = 8.
Each number in each table is the beneﬁt of a corresponding
(cid:104)premark, pmark(cid:105) parameter pair, where higher numbers are bet-
ter. When k is increased from 48 to 64 (Fig. 2b), we can see
USENIX Association
30th USENIX Security Symposium    843
pmark
premark
.10 .20 .30 .40 .50 .60 .70 .80 .90
.10 .06 .06 .05 .04 .04 .03 .02 .02 .01
.20 .11 .11 .10 .09 .07 .06 .04 .03 .02
.30 .16 .15 .14 .12 .10 .08 .06 .04 .02
.40 .21 .21 .19 .16 .14 .11 .08 .05 .02
.50 .27 .26 .24 .20 .17 .13 .10 .07 .03
.60 .31 .30 .27 .23 .19 .15 .11 .07 .03
.70 .34 .35 .32 .27 .23 .18 .13 .09 .04
.80 .32 .38 .35 .30 .25 .19 .14 .09 .04
.90 .32 .41 .40 .34 .28 .22 .15 .11 .05
1.0 .33 .40 .42 .38 .31 .24 .17 .12 .05
pmark
.10 .20 .30 .40 .50 .60 .70 .80 .90
.06 .06 .05 .04 .04 .03 .02 .02 .01
.12 .11 .10 .09 .07 .06 .04 .03 .02
.17 .16 .15 .12 .10 .08 .06 .04 .02
.23 .22 .19 .16 .14 .11 .08 .05 .03
.29 .27 .24 .21 .17 .14 .10 .07 .03
.33 .31 .28 .24 .20 .16 .11 .08 .03
.37 .36 .33 .28 .23 .19 .13 .09 .04
.35 .40 .36 .31 .26 .21 .15 .10 .04
.34 .43 .41 .35 .29 .23 .16 .11 .05
.34 .42 .45 .38 .32 .26 .18 .12 .05
(a) Baseline
(b) k = 64
pmark
premark
.10 .20 .30 .40 .50 .60 .70 .80 .90
.10 .06 .06 .05 .04 .04 .03 .02 .02 .01
.20 .11 .10 .10 .08 .07 .05 .04 .03 .01
.30 .15 .15 .14 .12 .10 .08 .05 .04 .02
.40 .20 .19 .18 .15 .12 .10 .07 .05 .02
.50 .25 .24 .22 .19 .15 .12 .08 .06 .03
.60 .29 .28 .26 .22 .18 .14 .10 .07 .03
.70 .29 .32 .30 .25 .21 .16 .11 .08 .03
.80 .29 .35 .33 .28 .23 .18 .12 .08 .03
.90 .28 .38 .37 .31 .25 .19 .13 .09 .04
1.0 .28 .36 .41 .35 .28 .22 .15 .10 .04
pmark
.10 .20 .30 .40 .50 .60 .70 .80 .90
.06 .06 .06 .05 .04 .03 .02 .02 .01
.12 .12 .11 .10 .08 .06 .05 .03 .02
.17 .17 .15 .13 .11 .09 .06 .04 .02
.23 .22 .21 .18 .15 .11 .08 .06 .03
.29 .28 .26 .22 .18 .14 .10 .07 .03
.31 .32 .30 .25 .21 .16 .12 .08 .04
.30 .36 .35 .30 .24 .19 .14 .09 .04
.28 .34 .38 .33 .27 .21 .15 .10 .04
.28 .34 .39 .37 .30 .23 .16 .11 .05
.31 .38 .40 .40 .33 .26 .18 .13 .05
(c) Λ = 8
(d) µstop = 12
Figure 2: beneﬁt of local detection, as k (b), Λ (c), and µstop
(d) are increased individually from the “baseline” (a) of k = 48,
Λ = 4, and µstop = 8
premark = 0.9
premark = 0.7
premark = 0.5
premark = 0.3
pmark = 0.2
pmark = 0.3
pmark = 0.4