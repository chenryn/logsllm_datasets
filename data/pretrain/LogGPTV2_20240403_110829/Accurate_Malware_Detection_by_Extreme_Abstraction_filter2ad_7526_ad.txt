run of layer 2 results in a threshold of 0.67 and a TPR of 98.64%.
While the four path model gives better results (a higher TPR), it
costs roughly 4 times the computing resources used for analyzing
a single path.
We now discuss the funnel results. The rst layer of the funnel
runs on all the samples on one path for one minute. We chose
thresholds of TL = 0.52,TH = 0.92, based on putting a boundary of
±0.2 around the threshold of 0.72 found for the independent run
of layer 1 as discussed above. The second layer runs on only the
undecided samples, using a threshold of 0.47, chosen to keep the
overall FPR rate at the desired 0.1%. The sample count ow through
the system is listed in Table 3: 96.2% of the samples are decided
after the rst layer, the remaining samples are passed for the more
intensive 4-path analysis in the second layer and then classied by
the second model. The results of the funnel are shown in the third
row of Table 2. At the desired false positive rate of 0.1%, we get a
true positive rate of 99.11%, better than the four path layer 2 alone.
This is a happy consequence that we were not necessarily expecting
from the funnel, and seems to indicate that the rst layer is better
at classifying “easy" samples than the second layer. Furthermore,
the funnel saves us a considerable amount of runtime. The average
timeout for the funnel is 1 + 0.038 ⇤ 4 = 1.152 minutes per sample,
vs. 4 minutes per sample had we not used the funnel and instead
run layer 2 on every sample.
Inuence of multiple paths. Table 2 shows that analyzing
multiple paths improves the detection rate. As a sanity check, we
ran experiments to verify that multiple path analysis indeed dis-
covers additional behavior not observed by single path analysis.
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
F. Copty et al.
Table 4: PE packing experiment results
Dataset
DS1
DS2
DS3
DS4
Packer
Unpacked
UPX
VMProtect
Themida
Samples
13,000
12,154
11,783
9,592
Predicted malware
0
120
518
582
(%)
(0%)
(0.98%)
(4.39%)
(6.06%)
Inuence of PE packers. A PE packer is a tool that compresses
a PE le, possibly adding obfuscation and anti-research in the pro-
cess. Use of a packer does not necessarily indicate maliciousness,
as a packer can be used by benign software (e.g., a game) to pro-
tect intellectual property. Nonetheless, many malicious samples
are packed, whereas most benigns are not. The question therefore
arises as to whether the results of Table 2 indicate that TAMALES
is capable of accurately detecting malware, or whether instead it
is merely detecting packing, obfuscation and anti-research. In or-
der to understand this issue, we took a dataset of 13,000 benign
samples randomly chosen from the benign samples in our test set
for which we made a correct prediction (we chose a subset of our
test set due to limited computational resources) and packed them
with three packers: UPX, VMProtect and Themida, using the de-
fault conguration of each packer. UPX [32] is a free open-source
packer; VMProtect [35] and Themida [31] are proprietary packers.
We chose these three because they succeeded in packing most of
the 13, 000 samples, while other packers that we tried failed on too
many of them. Still, not all of the three selected packers succeeded
in packing all of the PE les; some failed due to le size, others
crashed for unknown reasons. Thus we were left with three addi-
tional datasets consisting of subsets of the 13, 000 samples as shown
in Table 4. We ran TAMALES, using a single layer conguration of
one path and three minute timeout, on all four datasets (DS1, DS2,
DS3 and DS4).
If TAMALES was perfect in distinguishing malicious behavior
from mere packing, obfuscation or anti-research (which is not nec-
essarily malicious), we would expect that all of the packed samples
would be classied as benign. The results, shown in Table 4, show
that TAMALES is not perfect but is very good: the majority of the
samples are still correctly predicted to be benign even after packing,
which means that TAMALES is actually distinguishing between
benign vs. malicious samples and not merely between unpacked
vs. packed ones. Note that UPX fools TAMALES very rarely, while
VMProtect and Themida confuse it more. We hypothesize that this
is due to the fact that these packers add many obfuscation tricks
and anti-research checks that our classier “understands" as mali-
cious to a certain extent. We further hypothesize that this eect can
be mitigated by augmenting the training set with packed benign
samples, and plan to test this in the future.
Malware family classication. To further test our system, we
used the features generated by the extremely abstract OS to classify
malware samples into dierent malware families. We used Virus-
Total [34] to nd the labels given by dierent anti-virus engines
to each of the malware samples in our dataset, and then processed
them with AVClass [29] to produce a single-word malware family
name for each sample.
(a) Inuence of the multiple paths on all samples
(b) Inuence of multiple paths, excluding samples with no inuence
Figure 7: Inuence of multiple paths
In order to test this, we counted the number of times that the 4
path analysis observed more behavior than the single path anal-
ysis, where by more behavior we mean a numerical feature (e.g.,
count of a particular API call or n-gram) that changed from zero
to non-zero. We checked the entire data set (as described in Ta-
ble 1); Figure 7 shows the distribution of the samples according to
the number of additional features seen in multiple path analysis.
Figure 7a shows that for most samples (both malware and benign)
we see no additional behavior (0 additional features) when analyz-
ing with multiple paths compared to analyzing with a single path.
However, as shown by Figure 7b, if we focus on samples that do
exhibit some additional behavior, we see that malware samples are
markedly dierent than benign ones: there are many malware sam-
ples that reveal more than 10 additional behaviors when analyzed
with multiple paths, as opposed to benign samples which mostly do
not show such dierence between single and multiple paths anal-
ysis. This experiment shows that the multiple path analysis does
reveal additional behavior among certain malware that probably
deploy some time-based anti-research techniques and explains why
TAMALES multiple path analysis with dierent time models is able
to detect malware more accurately than single path analysis.
108
Accurate Malware Detection by Extreme Abstraction
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Table 5: Malware family classication results of most com-
mon families
Label # Malware family
upatre
allaple
dinwod
virut
browsefox
parite
ramnit
1
2
3
4
5
6
7 multiplug
8
9 mira
10
11
12
13
14
15
16 wajam
loadmoney
unknown
linkular
linkury
elex
onlinegames
Samples in test set Accuracy
99.98%
99.83%
96.14%
99.58%
99.02%
93.11%
99.93%
98.02%
99.91%
98.86%
72.11%
100.00%
99.70%
98.48%
85.17%
99.80%
9195
4575
4213
2380
2012
1823
1437
1187
1138
864
742
714
659
646
511
502
4.2 Lightweight symbols
We view our lightweight symbols as a kind of taint, and the same
analogy is made by [20], which can be understood as using symbolic
execution to explore multiple paths in suspected malware. However,
they use constraints to prevent choosing an infeasible path, and
make sure to perform consistent memory updates. In contrast, we
allow infeasible paths, and our lightweight symbols do not attempt
to keep track of possible memory values.
In [38] the authors describe a tool that performs full symbolic
execution, and they run with a timeout of 6 hours. In contrast, our
goal is to be able to deal with tens of thousands of samples a day,
thus we use a much shorter timeout, of one minute, that gives us
scalability.
The authors of [28] describe a way to use taint analysis to ag an
alert when tainted values are used in an unsafe way. In this context
they are running taint analysis on a benign program to try to guard
against attack. In contrast, we use our lightweight symbols, which
we understand as a kind of taint, in malware analysis.
Several previous works have relaxed the requirement to explore
only feasible paths. In [37], the authors describe a technique they
call ood emulation that forces the program counter to a specic
value, even if this results in an infeasible path. However, they work
by breaking the code into basic blocks discovered dynamically,
while our tool has no such notion, given that tricks of obfuscating
compilers have made the concept of basic block irrelevant to mal-
ware analysis. The authors of [14] describe a JavaScript analysis
tool that works hard to keep track of symbolic values while simul-
taneously allowing infeasible paths. In contrast, our lightweight
symbols do not attempt to keep track of possible memory values.
The work described in [1] allows breaking functionality, but they
do so in the course of obfuscating a program, and only for the set of
inputs that do not obey input invariants specied by the user of the
obfuscation tool. In contrast, we allow breaking functionality in the
analysis of a program, obfuscated or not. Also, [1] is interested in
Figure 8: Confusion matrix for family classication
For proper training and evaluation, we selected only malware
families that had more than 100 samples in our dataset. We ended
up with 154,400 malware samples, spread among 130 families (sam-
ples per family: µ = 1187.7;   = 3388.5; median is 270 samples).
We saved 30% of the samples as a test set and 70% were used for
training, while approximately maintaining the ratios of the dier-
ent families in both sets. The feature vectors were taken from an
abstract analysis of the samples with one path and a timeout of one
minute.
We trained a Decision Tree classier [5] on the training set using
the malware families as the target labels (130 distinct labels). We
evaluated the classier on the test set, and reached an accuracy
of 94.87% and F1-weighted of 94.81%. In Figure 8 we show the
confusion matrix of the model on the largest malware families in
our dataset (those with more than 500 samples in the test set), and
in Table 5 we list the accuracy of the classier on each of those
families. The results show that extreme abstraction provides enough
information for the machine learning model to accurately classify
malware into families.
4 RELATED WORK
4.1 Extreme abstraction