title:DRIVE: Dynamic Runtime Integrity Verification and Evaluation
author:Andre Rein
DRIVE: Dynamic Runtime Integrity Veriﬁcation and
Evaluation
Andre Rein
Huawei Technologies
German Research Center (GRC), Germany
PI:EMAIL | PI:EMAIL
ABSTRACT
Classic security techniques use patterns (e.g., virus scanner)
for detecting malicious software, compiler features (e.g., ca-
naries, tainting) or hardware memory protection features
(e.g., DEP) for protecting software. An alternative approach
is the veriﬁcation of software based on the comparison be-
tween the binary code loaded before runtime and the actual
memory image during runtime. The expected memory image
is predictable based on the ELF-ﬁle, the loading mechanism,
and its allocated memory addresses. Using binary ﬁles as ref-
erences for verifying the memory during execution allows for
the deﬁnition of white-lists based on the actual software used.
This enables a novel way of detecting sophisticated attacks to
executed code, which is not considered by current approaches.
This paper presents the background, design, implementation,
and veriﬁcation of a non-intrusive runtime memory veriﬁca-
tion concept, which is based on the comparison of binary
executables and the actual memory image.
1.
INTRODUCTION AND MOTIVATION
The complexity and number of cyber-attacks are increas-
ing continuously over the last years. Especially during the
last 5 years, very complex attacks were detected targeting a
broad range of industries and governmental institutions (e.g.
StuxNet (2010), Belgacom & Bengal Mobile (2013), Syman-
tec (2014), German Bundestag (2015), Ruag AG (2016)).
Those sophisticated attacks pose a substantial threat for
many infrastructures due to their high complexity, evasive-
ness, and diversity, rendering eﬀective detection exception-
ally hard. Moreover, they are particularly tailored to circum-
vent broadly adopted and widely used counter-measures, such
as ﬁrewalls, virus scanners and intrusion detection systems;
thus, they are usually detected by coincidence after a long
time past their initial deployment, e.g. by analyzing network
traﬃc.
However, the behavior of a computer system, or a device
acting as part of an IT-infrastructure, is deﬁned by the soft-
ware running on it. Thus, nearly every attack exploiting a
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
ASIA CCS ’17, April 02 - 06, 2017, Abu Dhabi, United Arab Emirates
c(cid:13) 2017 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ISBN 978-1-4503-4944-4/17/04. . . $15.00
DOI: http://dx.doi.org/10.1145/3052973.3052975
software vulnerability interacts with the system memory to a
certain extent. Often, devices are attacked by simply replac-
ing or adding malicious software components permanently
and execute them as desired. Those malicious modiﬁcations
may occur both oﬄine, for instance, by ﬁrmware manipu-
lation, and online, usually by exploiting vulnerabilities dur-
ing system runtime. However, the detection of persistent
modiﬁcations on ﬁle system level is well researched; anti-
virus/malware tools are available for more than 30 years and
attestation of system states, based on integrity veriﬁcation
of loaded software, is also well understood.
Still, the objective is not always to apply modiﬁcations
on the ﬁle level; instead, system inﬁltration often utilizes
runtime memory and control-ﬂow manipulation to launch
successful attacks. This means that the manipulation of exe-
cuted software components is only volatile and without evi-
dence permanently visible on the targeted device. However,
even those non-permanent attacks leave trails of evidence,
and thus can be detected. Memory Forensics (MF) enables
the detection of maliciously tampered volatile memory. MF
tools and techniques, capable of detecting even the most so-
phisticated attacks, can be used to analyze suspicious system
behavior. Still, the ﬁeld of MF is not thoroughly researched
and well understood [25]. Nonetheless, certain MF tools exist
[24, 33, 35] that facilitate a detailed systems’ memory analy-
sis. Nevertheless, using these tools require expert knowledge
of MF, such as potential attack vectors, and are usually used
to manually analyze a system after the detection of suspi-
cious behaviors.
This
paper presents Dynamic Runtime
Integrity
Veriﬁcation and Evaluation (DRIVE). DRIVE enhances the
classic onetime software component attestation approaches
from load-time towards continuous and repeated monitoring
and attestation throughout the entire software component’s
lifetime by adapting concepts from MF and System Integrity
Veriﬁcation. This enables
secure software component
runtime attestation and helps to detect advanced malicious
threats. DRIVE also limits the adversary’s capabilities by
reducing the time span of detection of a successful and long
lasting attack.
1.1 Goal and contributions
This work makes the following technical contributions:
• A non-intrusive and practical integrity measurement
and veriﬁcation concept to continuously monitor OS
components’ runtime memory content and meta-data
• A ﬂexible architecture supporting diﬀerent instantia-
tions for secure measurement acquisition, measurement
728anchoring in distinct Security Modules (SM) and in-
tegrity protected system state reports, comprising the
system’s current runtime state
• An signiﬁcant enhancement to established static load-
time measurement processes, enabling granular runtime
measuring of memory artifacts
• A novel attestation scheme and techniques, providing
integrity veriﬁcation based on computable reference
values for predictable runtime memory artifacts and
meta-data analysis
• A complete prototype implementation of the presented
measurement and veriﬁcation concepts, evaluated on
multiple diﬀerent hardware architectures
1.2 Outline
Section 2 describes the adversaries intent, capabilities, and
standard countermeasures of an expected system. After that,
the system architecture is shown in Section 3, especially, the
overall system, the individual architecture components, and
details on instantiated measurement and veriﬁcation architec-
ture are described. Section 4 describes the technical details of
the measurement, reporting and veriﬁcation process. There-
after, the implementation of the instantiated architecture is
discussed in Section 5 providing metrics of the implementa-
tion and performance eﬀects for the sensitive measurement
process. In Section 6, related work is presented and Section 7
provides a conclusion and presents future research directions.
2. THREAT AND TRUST MODEL
2.1 Threat Model
The adversary’s initial goal is the injection and execution
of arbitrary code in volatile memory for further exploitation.
Speciﬁcally, as depicted in Figure 1, the adversary is assumed
to launch an attack with particular long term goals such
as (1) take control of a system (e.g. by launching a shell)
or network; (2) steal conﬁdential data (e.g. cryptographic
keys or passwords); (3) gain higher access permissions (to
circumvent access control mechanisms); or (4) monitor or
alter arbitrary data (e.g. data of a program, network traﬃc,
routing tables, etc.). Consequently, the target of interest is
not the initial code injection but rather long term system
modiﬁcation and monitoring.
Moreover, it is assumed that the adversary wants to remain
hidden in order to carry out malicious actions for as long
as possible. Therefore, the attacks, such as code injection
or control ﬂow manipulation, are injected into the system
memory to carry out their malicious behavior consistently.
We assume the attacker may utilize the following diﬀerent
attack techniques: Create new executable segments, i.e., load
new, map existing and execute shell-code in the virtual ad-
dress space; alter or remove memory protection mechanisms,
e.g. disable or circumvent Data Execution Prevention (DEP)
([1, 14]) mechanisms; modify code segments by changing or
adding instructions or alter function pointers directly1; or
modify data segment jump tables, i.e., altering memory jump
addresses in the Global Oﬀset Table (GOT,.got).
Furthermore, it is assumed that the adversary has access
to a known exploit enabling a successful initial attack on the
1In order to launch a successful code segment manipulation
attack, memory protection must be disabled/circumvented
beforehand
Figure 1: Threat Model: Long Term Goals, Threats
and Attack Techniques
system. This may be enabled by any vulnerability that allows
memory access or code execution, e.g. buﬀer overﬂow, array
over-indexing, or format string vulnerability. The adversary
may, for instance, utilize a successful code reuse attack (e.g.
ROP, JOP or SOP), or facilitate any other kind of attack
in order to inject or load arbitrary data into volatile mem-
ory and exploit it arbitrary times [4, 27, 6]. Additionally, it
is assumed that the adversary can successfully disable or
circumvent other well-known defensive mechanisms such as
Stack Canaries [36] or Address Space Layout Randomization
(ASLR) [34]. As an example for a complex threat scenario,
we assume an attack that overwrites memory addresses to
function pointers in the .got of a user-process in order to
permanently modify the control ﬂow of an application, as
described by Roglia [28].
2.2 Trust Model and Security Assumptions
DRIVE is a non-intrusive solution that aims to improve the
overall system security; thus, previously mentioned security
mechanisms are compatible to DRIVE and should be enabled
as they provide signiﬁcant obstacles for any adversary.
Nonetheless, DRIVE depends on some security require-
ments. Most importantly, DRIVE relies on security mecha-
nisms that successfully detect or prevent execution of illicitly
modiﬁed ELF-Files such as executables, libraries, kernel mod-
ules, and the kernel. In particular, DRIVE assumes that the
system boots into a well known and reliable state. This re-
quirement can be enforced by a secure or, at least, veriﬁed
a measured boot of the OS as described in Trusted Com-
puting [22]. As a result, the adversary must not be able to
modify and load system binaries on disk, tamper or replace
OS components, or disable those mechanisms without be-
ing detected. Although, DRIVE can be enhanced to detect
those modiﬁcations as well, this work focuses solely on the
measurement and veriﬁcation of monitored components’ run-
time memory representations. Similar to well known integrity
protection schemes, such as the Integrity Measurement Archi-
tecture (IMA) initially described by Sailer et. al [29], DRIVE
facilitates a tamper-proof SM, for instance a Trusted Plat-
form Module (TPM), in order to continuously record, track,
and report a system state securely and arbitrarily. Most im-
portantly, DRIVE relies on the tamper-resistance of the SM.
That is, once measurements are anchored in the SM, they
must not be changed.
In addition to that, one security-sensitive part of DRIVE
relies on the measurement accumulation of the system mem-
ory before the measurement is anchored in the SM. For this
reason, we assume that the attacker cannot interfere with the
measurement process or disable it altogether. This means,
the measurement component is considered immutable, i.e.,
isolated from the attacker. A straightforward implementation
may employ OS based process isolation or user/kernel-level
(1) take full control of the system(2) steal confidential data(3) gain higheraccess permissions(4) monitor or alter arbitrary dataControl flowManipulation(function pointer)Alter/remove  memoryprotectionModify code segmentCreate new executable segmentCode  InjectionModify data segmentVulnerabilityInitial AttackContinuous Attack(Long Term Goal)&729isolation; but, as soon as threats are considered that eﬀec-
tively bypass kernel level security protection mechanisms [21,
38, 9], more sophisticated isolation techniques and mecha-
nisms must be used. For instance: (1) Virtualization- or
hypervisor-based approaches; (2) Sandboxing approaches; (3)
Hardware-backed approaches, like ARM TrustZone and Intel
Software Guard Extensions (SGX) ; or (4) discrete hardware
security co-processor based approaches.
DRIVE by itself is not limited to a particular isolation
mechanism; the exact implementation mainly depends on
use-case speciﬁc requirements and conditional architecture
and platform capabilities. As a result, for this work we do
not focus on the exact isolation mechanism and assume that
kernel-level isolation is perfectly suﬃcient.
3. DRIVE HIGH LEVEL CONCEPT AND
ARCHITECTURE
The main objective of DRIVE is to repeatedly measure, re-
port, and verify runtime information present in system mem-
ory. In this section, the high level architecture of DRIVE
is introduced, necessary components identiﬁed, and mecha-
nisms for successful information acquisition, reporting and
veriﬁcation deﬁned and discussed.
Party (TTP) which means the veriﬁcation process can be
base on certain assumptions, i.e. the VS and all its reference
data are considered as reliable.
3.2 Architecture Components
Measurement Agent: Measurement and Reporting of
Measurements. The MA is the core component of the
OBS and responsible for secure measurement and report-
ing. DRIVE’s Measurement and Reporting architecture is
depicted in Figure 3 and will be presented in the following.
In order to conduct a secure measurement process,
DRIVE’s Measurement Component implements following
operations: 1 Measure and receive targeted memory con-
tents; 2 append the individual measurements to an ordered
Dynamic Measurement List (DML); and, 3 generate ﬁnger-
prints, representing and protecting the DMLs integrity and
anchor the ﬁngerprints in the SM.
Figure 2: DRIVE Architecture for Measurement, Re-
porting and Veriﬁcation.
The high level architecture, as depicted in Figure 2, shares
some similarities with the architecture described in [29].
DRIVE utilizes similar conceptual measurement and veri-
ﬁcation agents, and also a SM. The measurements and the
reported data methods utilize cryptographic hash functions;
however, measurement acquisition and veriﬁcation diﬀers sig-
niﬁcantly, because DRIVE repeatedly measures and veriﬁes
the runtime system’s states including dynamic information,
whereas Sailers’ work only considers static one-time measure-
ments taken before the loading process.
3.1 System Overview
The architecture consists of two individual systems: The
Observed System (OBS) and the Veriﬁcation System (VS).
OBS and VS can be implemented either in the same or,
preferably, in diﬀerent logically or physically isolated con-
texts. The OBS implements a Measurement Agent (MA) –
responsible to acquire the desired measurements from the
memory – that produces a Measurement Report, compris-
ing of a list of related measurement, anchored in a Security
Module (SM).
The VS implements the Veriﬁcation Agent (VA), which
receives a Measurement Report for veriﬁcation. The VA im-
plements the actual veriﬁcation process, under the assistance
of Reference Value Data. The veriﬁcation process is called
Remote Attestation (RA) in accordance with TCG terminol-
ogy. Accordingly, the VS can be operated by a Trusted Third
Figure 3: DRIVE Measurement and Reporting Pro-
cess
In addition to the secure measurement process, the MA
also implements one additional operation: 4 generation of
a System State Report (SSR) for the reporting process. The
operation itself generates the SSR by adding the anchored
ﬁngerprint from the SM and the maintained DML. The SSR
is used by the VA during the veriﬁcation process that will
be described next.
Veriﬁcation Agent: Veriﬁcation of Measurements. The
VA implements all necessary functionality to evidently ver-
ify the measurements, securely embedded in the previously
described SSR. Involved operations include receiving a SSR
from an OBS, loading of necessary Reference Value Data and
verifying the SSR based on these information.
The SSR is received by the VA either by direct introspec-
tion of the OBS or, in preferred cases, received during Remote
Attestation, which is done by establishing a secure data chan-
nel between OBS and VS. That means the secure channel
must provide integrity, authenticity, conﬁdentiality and fresh-
ness. Once the SSR was successfully received 5 , SSR data
is veriﬁed against the SM anchored integrity value [cf. Fig-
ure 3]. First of all, the authenticity of the security anchored
ﬁngerprint is veriﬁed by the Fingerprint Veriﬁcation. This
involves: Loading a well known or signed cryptographic key
and verifying the authenticity of the ﬁngerprint. The DML
Integrity Veriﬁcation component calculates a cryptographic
hash sum based on the DML and compares this self calcu-
730lated ﬁngerprint against the previously Veriﬁed Fingerprint.
Only if both values are equal, the integrity of the received
DML is guaranteed; accordingly, the DML is considered un-
tampered and is therefore regarded as a Veriﬁed DML. A
more detailed description of this particular process for the
RV calculation is provided in Section 4.5.
In order to determine whether the measurements were
modiﬁed during runtime, the VA compares every measured
value present in the DML against references. Every success-
fully veriﬁed measurement draws the conclusion that the
measured memory part did not change unexpectedly and
thus can be considered as trustworthy. The process of DML
veriﬁcation is depicted in Figure 3 and brieﬂy described next.
The veriﬁcation of the DML’ measurements is as follows:
6 For every individual measurement in the DML the Veriﬁ-
cation Component tries to generate or ﬁnd valid Reference