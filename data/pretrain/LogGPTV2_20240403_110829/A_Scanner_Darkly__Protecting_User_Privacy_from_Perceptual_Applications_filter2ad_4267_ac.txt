int iNearest = findNearestNeighbor(data,
projectedTestFace);
Listing 5.
closest match to the input image.
Part of face-recognition application code for calculating the
bc_dist_tmpl =
"fscale=2;
leastdistsq = 999999999
inearest = -1
for( itrain = 0; itrain < %d; itrain++ ) {
distsq = 0.0;
for( i = 0; i < %d; ++i ) {
a = iimport(0, i, 0, 0)
b = iimport(1, itrain * 2 + i, 0, 0)
di = a-b
c = iimport(2,i,0,0);
distsq += di * di / c ;
}
if( distsq < leastdistsq ) {
leastdistsq = distsq;
inearest = itrain;
}
}
return inearest;";
cvEigenDecomposite(image,
data.nEigens,
356
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:55:08 UTC from IEEE Xplore.  Restrictions apply. 
Figure 2. Output of the sketching transform on a female face image at different privacy levels.
Figure 3. Output of the sketching transform on a credit card image at different privacy levels.
&(*( data.eigenVectVec.begin())),
0, 0, data.pAvgTrainImg,
projectedTestFace);
snprintf(bc_dist_code, MAX_SIZE, bc_invert_tmpl,
data.nTrainFaces, data.nEigens);
bc_bytecode = bcCompile(bc_dist_code);
int iNearest = cvExecuteUntrustedCode(bc_bytecode,
projectedTestFace, data.projectedTrainFaceMat
, data.eigenValMat);
Listing 6. Modiﬁed face-recognition application code using ibc for
calculating the closest match to the input image.
VII. PRIVACY TRANSFORMS
In Section IX, we show that many OpenCV applications
can work, without any modiﬁcations, on opaque refer-
ences. Some applications, however, call OpenCV functions
like cvMoments, cvFindContours, or cvGoodFeaturesTo-
Track which return information about certain features of the
image. We call these functions declassiﬁers (Section VI-D).
To protect privacy, declassiﬁers transform the features
before releasing them to the application. The results of the
transformation are shown to the user in the DARKLY console
window (Section VIII). The user can control the level of
transformation by adjusting the privacy dial on this screen.
The transformations are speciﬁc to the declassiﬁer but
application-independent. For example, the declassiﬁer for
cvGetImageContent replaces the actual image with a thresh-
olded binary representation (see Fig. 7). The declassiﬁer
for cvGoodFeaturesToTrack, which returns a set of corner
points, applies a higher qualitylevel threshold as the dial
setting increases,
corner points are released to the application.
thus only the strongest candidates for
The declassiﬁers for cvFindContours, cvMoments, and cv-
CalcHist apply the sketching transform from Section VII-A
to the image before performing their main operation (e.g.,
ﬁnding contours) on the transformed image. The application
thus obtains only the features such as contours or moments
and not any other information about the image.
Applying a privacy transform does not affect the accuracy
of OpenCV functions other than the declassiﬁers because
these functions operate on true, unmodiﬁed data.
A. Sketching
The sketch of an image is intended to convey its high-level
features while hiding more speciﬁc, privacy-sensitive details.
A loose analogy is publicly releasing statistical aggregates
of a dataset while withholding individual records.
The key to creating sketches is to ﬁnd the contours of the
image, i.e., the points whose greyscale color value is equal to
a ﬁxed number. In our prototype we use a hardcoded value of
50% (e.g., 127 for 8-bit color). Contours by themselves don’t
always ensure the privacy properties we want. For example,
in Fig. 3, contours reveal a credit card number. Therefore,
the sketching transform uses contours in combination with
two types of low-pass ﬁlters.
First,
the image is blurred5 before contour detection.
Blurring removes small-scale details while preserving large-
scale features. The privacy dial controls the size of the ﬁlter
5We use a box ﬁlter because it is fast: it averages the pixels in a box
surrounding the target pixel. We could also use a Gaussian or another ﬁlter.
357
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:55:08 UTC from IEEE Xplore.  Restrictions apply. 
kernel. Higher kernel values correspond to more blurring
and fewer details remaining after contour detection.
Just as contour detection alone is insufﬁcient, low-pass
ﬁltering alone would have been insufﬁcient. For example,
image deblurring algorithms can undo the effect of box
ﬁlter and other types of blur; in theory, this can be achieved
exactly as long as the resolution of the output image is not
decreased [15]. By returning only the contours of the blurred
image, our sketching transform ensures that blurring cannot
be undone (it also removes all contextual information).
Another low-pass ﬁlter is applied after contour detection.
The transform computes the mean radius of curvature of
each contour (suitably deﬁned for nondifferentiable curves
on discrete spaces) and ﬁlters out the contours whose mean
radius of curvature is greater than a threshold. The threshold
value is controlled by the privacy dial. Intuitively,
this
removes the contours that are either too small or have too
much entropy due to having many “wrinkles.”
Reducing an image to its contours, combined with low-
pass ﬁltering, ensures that not much information remains in
the output of the transform. Due to blurring, no two contour
lines are too close to each other, which upper-bounds the
total perimeter of the contours in an image of a given size.
Fig. 4 illustrates how sketching reduces information avail-
able to the application, as a function of the user-selected
privacy level. We also experimentally estimated the entropy
of sketches on a dataset of 30 frontal face images sampled
from the Color FERET database.6 These were cropped to the
face regions, resulting in roughly 220x220 images. We can
derive an upper bound on entropy by representing contours
as sequences of differences between consecutive points,
which is a more compact representation. Fig. 5 shows that,
for reasonable values of the privacy dial (3–6), the resulting
sketches can be represented in 500-800 bytes.
i
s
t
n
o
p
r
u
o
n
o
c
t
f
o
o
n
l
a
t
o
T
10000
8000
6000
4000
2000
0
0
1
2
3
face
credit card
4
7
8
9
10 11
5
6
Privacy dial value
Figure 4. Sketching: reduction in information available to the application
for images from Figs. 2 and 3.
B. Generalization
In addition to generic image manipulation and feature
extraction functions like cvFindContours, OpenCV also pro-
vides model-based object detectors. An application can load
a Haar classiﬁer using cvLoadHaarClassiﬁerCascade and
6http://www.nist.gov/itl/iad/ig/colorferet.cfm
358
s
r
u
o
t
n
o
c
f
o
#
s
e
t
y
b
f
o
#
16
14
12
10
8
6
4
2
0
0
1200
1000
800
600
400
200
0
0
1
2
3
4
5
6
7
8
9
10 11
1
2
3
5
8
4
Privacy dial value
6
7
9
10 11
Figure 5.
Sketching: reduction in average information available to the
application for facial images in FERET database (size roughly 220x220).
detect objects of a certain class (for example, faces) by
calling cvHaarDetectObjects with a class-speciﬁc model. To
prevent applications from inferring information via mali-
cious models, the current DARKLY prototype only allows
predeﬁned models that ship with OpenCV.
If a match is found, cvHaarDetectObjects returns a rect-
angular bounding box containing the object, but not the
pixels inside the box. This still carries privacy risks. For
example, an application that only has an opaque reference
to the box containing a face can use OpenCV calls to
detect the location of the nose, mouth, etc. and learn enough
information to identify the face. To prevent this, DARKLY
applies a generalization-based privacy transform.
Face generalization. Generalization has a long history in
privacy protection; we explain our approach using face
detection as an example. Our privacy transform replaces
the actual face returned by cvHaarDetectObjects with a
“generic” face selected from a predeﬁned, model-speciﬁc
dictionary of canonical face images. We call our face gen-
eralization algorithm cluster–morph.
The generalization idiom is already familiar to users from
“avatars” in video games, online forums, etc. Sometimes
avatars are picked arbitrarily, but often users choose an
avatar that best represents their own physical characteristics.
In the same way, the generalized face in DARKLY is intended
to be perceptually similar to the actual face, although, unlike
an avatar, it is programmatically generated.
There are two components to generalization: ﬁrst, ﬁxing
(and if necessary, pre-processing) the canonical dictionary,
and second, choosing a representative from this dictionary
for a given input face. The former is a one-time process, the
latter is part of the transform. For the ﬁrst component, one
straightforward approach is to simply pick a small dictionary
of (say) 20 faces and run a face detector on the actual face
to ﬁnd and return its closest match from the dictionary.
Our proposed cluster–morph technique is a promising
but more complex approach to generalization. It works as
follows: start from a large database of images and compute
its eigenfaces by applying a well-known algorithm [26] that
uses Principal Component Analysis to calculate a set of
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:55:08 UTC from IEEE Xplore.  Restrictions apply. 
Finally, to ﬁnd the canonical face “representing” each
cluster, morph the faces in the cluster using standard morph-
ing algorithms [3]. Fig. 6 shows an example from a cluster
of size 2 obtained by hierarchical clustering on a 40-person
ORL dataset [22]. Clustering and morphing are done once
to produce a ﬁxed dictionary of canonical faces.
We propose to use hierarchical agglomerative clustering.
It offers the key advantage that the level of generalization
can be adjusted based on the setting of the privacy dial: as
the dial value increases, the transform selects clusters higher
in the hierarchy. If all clusters have at least k elements, then
the number of clusters is no more than 2N
k where N is the
total number of faces in the database.
basis vectors for the set of all faces. Then compute the
eigen-decomposition of each face,
it as a
linear combination of the basis vectors, and truncate each
decomposition to the ﬁrst (say) 30 principal components.
Next, cluster the set of faces using the Euclidean distance
between decompositions as the distance function.
i.e., represent
At runtime, to generalize a given input face, compute its
eigen-decomposition, calculate its distance to each cluster
center,7 and pick the closest. The transform then returns the
morphed image representing this cluster to the application.
Our DARKLY prototype includes a basic implementation
of cluster–morph. Evaluating the algorithm on the Color
FERET database is work in progress. There are at least three
challenges: measuring the effectiveness of face clustering,
ﬁnding a mapping between privacy dial values and cluster
hierarchy levels (e.g., dial values can be pegged to either
cluster sizes or cluster cohesion thresholds), and developing
metrics for quantifying privacy protection.
canonical representation w.r.t. a globally predeﬁned dataset
(in particular, the input image is not drawn from this dataset).
Further, Newton et al.’s algorithm has some weaknesses
for our purposes: it uses greedy clustering instead of more
principled methods, requires re-clustering if the privacy dial
changes, and, ﬁnally, in our experiments averaging of faces
produced results that were visually inferior to morphing.
Figure 7. Output of the thresholding binary transform on an image of
a street scene with a QR code. QR decoding application works correctly
with the transformed image.
VIII. DARKLY CONSOLE
The DARKLY console is a DARKLY-controlled window
that shows a visual representation of the features and ob-
jects returned to the application by the declassiﬁers. For
applications that operate exclusively on opaque references,
the DARKLY console is blank. For applications that use
declassiﬁers, the DARKLY console shows the outputs of the
corresponding privacy transforms—see examples in Figs. 8
and 9. We assume that this window cannot be spoofed by
the application. In general, constructing trusted UI is a well-
known problem in OS design and not speciﬁc to DARKLY.
Figure 6. Face morphing for generalization. The left and right faces belong
to the same cluster; the morph “representing” this cluster is in the center.
Our cluster–morph algorithm is inspired in part by New-
ton et al.’s algorithm for k-anonymity-based facial de-
identiﬁcation [19], which works as follows: given a database
of images, repeatedly pick a yet-unclustered image from the
database and put it in a cluster with k − 1 of its “closest”
images, according to an eigenface-based distance measure.
For each face in the input database, the average of the faces
in its cluster constitutes its de-identiﬁed version.
The salient differences in our case are as follows: our
goal is not k-anonymity within a database, but ﬁnding a
7A cluster center is the mean of the eigen-decomposites of each image
in the cluster. It does not correspond to the morphed image. Since eigen-
decomposition of a face is a linear transformation, averaging in the
eigenspace is the same as averaging in the original space; thus, the image
corresponding to the cluster center is a plain pixelwise average of the faces
in the cluster. This average would be unsuitable as a canonical representative
due to artifacts such as ghosting, which is why we use the morphed image.
Figure 8. Motion detector: actual image and the DARKLY console view.
Application works correctly with the transformed image.
The DARKLY console is implemented as a separate pro-
cess communicating with DARKLY over UNIX domain sock-
ets. With this design, the application’s declassiﬁer function
calls need not be blocked until the DARKLY console has
ﬁnished rendering. We did not
the DARKLY
console as a thread inside the DARKLY server because both
use OpenCV, and OpenCV functions are not thread-safe.
implement
Consecutive DARKLY console views are stored as a movie
ﬁle in AVI or MPG format. If storage is limited, they can be
compressed and/or stored at reduced resolution. The user can
359
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:55:08 UTC from IEEE Xplore.  Restrictions apply. 
Figure 9.
Application works correctly with the transformed image.
Ball tracker: actual image and the DARKLY console view.
play back the movie and see how the information released
to the application by privacy transforms evolved over time.
Privacy dial. The DARKLY console includes a slider for
adjusting the level of transformation applied by the pri-
vacy transforms. The values on the slider range from 0 to
11. Absolute values are interpreted differently by different
transforms, but higher values correspond to coarser outputs
(more abstract representations, simpler contours, etc.). For
example, higher values cause the sketching declassiﬁer to
apply a larger box ﬁlter to smoothen the image before ﬁnding
the contours, thus removing more information (see Fig. 3).
IX. EVALUATION
We evaluated DARKLY on 20 OpenCV applications, listed
in Table II along with their source URLs. These applications
have been selected from Google Code, GitHub, blogs, and
OpenCV samples for the variety and diversity of their
features and the OpenCV functionality they exercise. With
the exception of OCR, which uses the C++ interface for
nearest-neighbor clustering, they use OpenCV’s C interface.
Our DARKLY prototype is based on OpenCV release
2.1.0. Applications were evaluated on a Segway RMP-50
robot running ROS Fuerte and/or a laptop with a quad-core
2.40GHz Intel Core i3 CPU and 4 GB of RAM running 32
bit Ubuntu 11.10 desktop edition.
Results are summarized in Table III. 18 out of 20 applica-
tions required no modiﬁcations to run on DARKLY, except
very minor formatting tweaks in a couple of cases (removing
some header ﬁles so that the program compiles in Linux).
For the face recognizer, we re-implemented the eigenface
matching algorithm in our ibc language (see Section VI-F)
so that it can run on true images inside the library, returning
only the match/no match answer to the application.
For all tests, we used either a benchmark video dataset of
a person talking,8 or the sample images and videos that came
with the applications, including OpenCV sample programs.9
Depending on the application, frame rates were computed
for the video or over the input images.
8http://www-prima.inrialpes.fr/FGnet/data/01-TalkingFace/talking face.
9https://code.ros.org/trac/opencv/browser/trunk/opencv/samples/c?rev=
html
27
hand-drawn
Application
OCR for
digits
Security cam
Ball tracker
QR decoder
PrivVideo, video back-
ground subtractor
and
streamer
Facial features detector
Face recognizer
Histogram calculator
(RGB)
Histogram calculator
(Hue-Saturation)
Square detector
for
images/
Morphological
transformer
Intensity/contrast
changer
histograms
Pyramidal
downsampler + Canny
edge detector
Image adder
H-S histogram back-
projector
Template matcher
Corner ﬁnder
Hand detector
Laplace edge detector
Ellipse ﬁtter
URL
http://blog.damiles.com/2008/11/
basic-ocr-in-opencv/
http://code.google.com/p/camsecure/
https://github.com/liquidmetal/
AI-Shack--Tracking-with-OpenCV/blob/master/
TrackColour.cpp