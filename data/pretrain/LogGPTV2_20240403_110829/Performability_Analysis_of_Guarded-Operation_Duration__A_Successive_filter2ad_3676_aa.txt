# Title: Performability Analysis of Guarded-Operation Duration: A Successive Model-Translation Approach

## Authors:
- Ann T. Tai
- William H. Sanders
- Leon Alkalai
- Savio N. Chau
- Kam S. Tso

### Affiliations:
- **Ann T. Tai** and **William H. Sanders**: University of Illinois, Urbana, IL 61801
- **Leon Alkalai** and **Savio N. Chau**: Jet Propulsion Laboratory, Pasadena, CA 91109
- **Kam S. Tso**: IA Tech, Inc., Los Angeles, CA 90024

### Abstract
In engineering design, it is essential to consider the implications on both system performance and dependability. This paper presents a performability study focused on the duration of guarded operations for onboard software upgrades. We define a "performability index" \( Y \) that quantifies the extent to which the guarded operation with a duration \( \theta \) reduces the expected total performance degradation. To solve for \( Y \), we progressively translate its formulation into an aggregate of constituent measures, making it amenable to efficient reward model solutions. Based on the intermediate model, we specify reward structures in the composite base model, built on three stochastic activity network (SAN) reward models. We describe the model-translation approach and demonstrate its feasibility for design-oriented performability modeling.

## 1. Introduction
To protect evolvable, distributed embedded systems from design faults introduced by onboard software upgrades, a methodology called Guarded Software Upgrading (GSU) has been developed [1]. GSU is supported by a Message-Driven Confidence-Driven (MDCD) protocol, which efficiently uses checkpointing and acceptance testing techniques for error containment and recovery. The MDCD protocol ensures that the system functions correctly after a software component is replaced by an updated version, while allowing the updated component to interact freely with other components. The period during which the system is under the MDCD protocol's protection is called "guarded operation."

Guarded operation allows an upgraded software component to start its service seamlessly. If the escorting process determines that the upgraded component is not sufficiently reliable, the system can be safely downgraded by reverting to an earlier version. The duration of the guarded operation \( \theta \) is a critical design parameter, as it directly influences the total performance degradation, which includes both the performance penalty due to design-fault-caused failures and the performance reduction due to safeguard activities. Therefore, performability analysis [2] is well-suited for engineering decision-making.

Although we have conducted separate dependability and performance studies for the MDCD protocol [3, 1], performability analysis presents new challenges. First, performability measures for engineering decision-making should be defined from a system designer's perspective, leading to a design-oriented formulation that may not be directly conducive to the final solution. Second, such a model usually covers a broad spectrum of interdependent system attributes, making straightforward evaluation difficult.

To address these challenges, we propose an approach that solves the performability measure through successive model translation. We define a "performability index" \( Y \) that quantifies the extent to which the guarded operation with a duration \( \theta \) reduces the expected total performance degradation. For clarity and simplicity, we formulate \( Y \) at a high level of abstraction. To solve for \( Y \) efficiently, we translate the design-oriented model into an evaluation-oriented model, successively closing the gap between the formulation and the final solution.

We begin with a design-oriented model, translate it analytically into an evaluation-oriented form, and then specify reward structures in the composite base model, built on three SAN reward models. This approach avoids dealing with a model that is too complex for a closed-form solution, similar to behavioral decomposition methods [5, 6] and hierarchical composition techniques [7, 8]. However, our focus is on translating the model progressively until it reaches a simple function of "constituent reward variables," each of which can be directly mapped to a reward structure for solution.

As the translation progresses, we gain additional mathematical insights into the system behavior, enabling efficient model construction and solution. This supports performability studies of engineering problems where mathematical properties or implications may not become apparent until the problem is elaborated to a certain degree. The process of transforming the problem of solving a complex performability measure into evaluating constituent reward variables naturally enables the use of efficient modeling techniques and tools.

The next section provides a review of the GSU methodology and guarded operation. Section 3 defines and formulates the performability measure. Section 4 describes the translation process, followed by Section 5, which shows how the reward structures are specified in SAN models. Section 6 presents an analysis of optimal guarded-operation duration. The paper concludes with Section 7, summarizing our accomplishments.

## 2. Review of GSU Framework
The development of the GSU methodology is motivated by the need to guard embedded systems against the adverse effects of design faults introduced by onboard software upgrades [3, 1]. The performability study assumes an embedded system consisting of three computing nodes, consistent with the current architecture of the Future Deliveries Testbed at JPL. During a non-critical mission phase, only two processes corresponding to two different application software components run concurrently and interact with each other.

To exploit inherent system resource redundancies, the old version, in which we have high confidence due to its long onboard execution time, escorts the new-version software component through two stages of GSU: onboard validation and guarded operation, as illustrated in Figure 1. The third processor, which would otherwise be idle, accommodates the old version, allowing the three processes to run concurrently.

- **Pnew1**: The process corresponding to the new version of an application software component.
- **Pold1**: The process corresponding to the old version of the application software component.
- **P2**: The process corresponding to another application software component (not undergoing upgrade).

During the first stage, onboard validation, the outgoing messages of Pnew1 are suppressed but selectively logged, while Pnew1 receives the same incoming messages as Pold1. By maintaining an onboard error log, we can make decisions regarding the duration of onboard validation and whether Pnew1 can enter mission operation. Onboard extended testing also leads to a better estimation of the fault-manifestation rate of the upgraded software.

If onboard validation is successful, Pnew1 and Pold1 switch roles to enter the guarded operation stage. The time to the next upgrade \( \phi \) is determined upon the completion of onboard validation, based on the planned duty of the flight software and the quality of the software learned through validation.

During guarded operation, Pnew1 influences the external world and interacts with P2 under the MDCD protocol, while the messages of Pold1 conveying its computation results to P2 or external systems are suppressed. The key assumption in the MDCD algorithms is that an erroneous state of a process affects the correctness of its outgoing messages, and an erroneous message received by an application software component results in process state contamination [3].

Upon detecting an erroneous external message, Pold1 takes over Pnew1's active role and prepares to resume normal computation with P2. After error recovery, the system returns to normal mode until the next scheduled upgrade. An undetected, erroneous external message results in system failure. If no error occurs during \( \theta \), guarded operation concludes, and the system returns to normal mode.

The central purpose of this paper is to study how to evaluate a performability measure for determining an optimal \( \theta \). In the following section, we define and formulate the performability measure.

## 3. Performability Measure
... (Continuation of the paper)