posed by Smirnov and Chiueh [31] to classify FLIPS: it detects attacks, identiﬁes
the attack vector, and provides an automatic repair mechanism.
The goal of the system is to provide a modular and compact application-
level ﬁrewall with the ability to automatically learn and drop conﬁrmed zero-
day attacks. In addition, the system should be able to generate zero-day worm
and attack signatures, even for slightly metamorphic attack input. We tune
the anomaly detection by catching code injection attacks with our supervision
component. Only attacks that actually inject and execute code are conﬁrmed
as malicious and fed back to the anomaly detector and ﬁlter. As a result, only
conﬁrmed attacks are dropped in the future.
88
M.E. Locasto et al.
3.1 FLIPS Design
The design of FLIPS is based on two major components: a ﬁltering proxy and an
application supervision framework. A major goal of the design is to keep the sys-
tem modular and deployable on a single host. Figure 1 shows a high-level view of
this design. The protected application can be either a server waiting for requests
or a client program receiving input. Input to a client program or requests to a
server are passed through the ﬁltering proxy and dropped if deemed malicious.
If the supervision framework detects something wrong with the protected appli-
cation, it signals the ﬁlter to update its signatures and models. Although server
replies and outgoing client traﬃc can also be modeled and ﬁltered, our current
implementation does not perform this extra step. Outgoing ﬁltering is useful in
protecting a client application by stopping information leaks or the spread of
self-propagating malware.
The function of the proxy is to grade or score the input and optionally drop
it. The proxy is a hybrid of the two major classiﬁcation schemes, and its subcom-
ponents reﬂect this dichotomy. A chain of signature-based ﬁlters can score and
drop a request if it matches known malicious data, and a chain of anomaly-based
classiﬁers can score and drop the input if it is outside the normal model. Either
chain can allow the request to pass even if it is anomalous or matches previous
malicious input. The default policy for our prototype implementation is to only
drop requests that match a signature ﬁlter. Requests that the anomaly classiﬁer
deems suspicious are copied to a cache and forwarded on to the application.
We adopt this stance to avoid dropping requests that the anomaly component
mislabels (false positives). The current implementation only drops requests that
Input
source
Proxy
Signature
filter
&
classifier
chain
Anomaly
&
filter
classifier
chain
firewall
Protected
Application
Supervision
framework &
feedback source
Fig. 1. General Architecture of FLIPS. Requests are passed through a ﬁltering proxy
and dropped if deemed malicious. The application should be protected by a packet
ﬁltering ﬁrewall that only allows the local proxy instance to contact the application.
The application processes the requests and sends the response back through the proxy.
If the input causes a code injection attack, the supervision framework contacts the
proxy with the injected code and the proxy updates its models and signatures.
FLIPS: Hybrid Adaptive Intrusion Prevention
89
have been conﬁrmed to be malicious to the protected application and requests
that are closely related to such inputs.
The function of the application supervision framework is to provide a way
to stop an exploit, automatically repair the exploited vulnerability, and report
information about an exploit back to the ﬁlters and classiﬁers. Similar to the
ﬁltering and classiﬁcation chains, the supervision framework could include a
number of host-based monitors to provide a wide array of complementary feed-
back information to the proxy. Our prototype implementation is based on one
type of monitor (ISR) and will only provide feedback information related to
code-injection attacks. Many other types of attacks are possible, and whether
something is an attack or not often depends on context. FLIPS’s design allows for
an array of more complicated monitors. STEM allows the application to recover
from a code injection attack by simulating an error return from the emulated
function after notifying the proxy about the injected code.
3.2 Threat Model
In this work, we assume a threat model that closely matches that of previous
ISR eﬀorts. Speciﬁcally, we assume that an attacker does not have access to the
randomized binary or the key used to eﬀect achieve this randomization. These
objects are usually stored on a system’s disk or in system memory; we assume the
attacker does not have local access to these resources. In addition, the attacker’s
intent is to inject code into a running process and thereby gain control over the
process by virtue of the injected instructions. ISR is especially eﬀective against
these types of threats because it interferes with an attacker’s ability to automate
the attack. The entire target population executes binaries encoded under keys
unique to each instance. A successful breach on one machine does not weaken
the security of other target hosts.
3.3 Caveats and Limitations
While the design of FLIPS is quite ﬂexible, the nature of host-based protec-
tion and our choices for a prototype implementation impose several limitations.
First, host-based protection mechanisms are thought to be diﬃcult to manage
because of the potential scale of large deployments. Outside the enterprise en-
vironment, home users are unlikely to have the technical skill to monitor and
patch a complicated system. We purposefully designed FLIPS to require little
management beyond installation and initial training. PayL can perform unsu-
pervised training. One task that should be performed during system installation
is the addition of a ﬁrewall rule that redirects traﬃc aimed at the protected
application to the proxy and only allows the proxy to contact the protected
application.
Second, the performance of such a system is an important consideration in
deployment. We show in Section 5 that the beneﬁt of automatic protection and
repair (as well as generation of zero-day signatures) is worth the performance
impact of the system. If the cost is deemed too high, the system can still be
90
M.E. Locasto et al.
deployed as a honeypot or a “twin system” that receives a copy of input meant
for another host. Third, the proxy should be as simple as possible to promote
conﬁdence in its codebase that it is not susceptible to the same exploits as the
protected application. We implement our proxy in Java, a type-safe language
that is not vulnerable to the same set of binary code injection attacks as a C
program. Our current implementation only considers HTTP request lines. Specif-
ically, it does not train or detect on headers or HTTP entity bodies. Therefore,
it only protects against binary code injection attacks contained in the request
line. However, nothing prevents the scope of training and detecting from being
expanded, and other types of attacks can be detected at the host.
4 Implementation
This section deals with the construction of our prototype implementation. The
proxy was written in Java and includes PayL (400 lines of code) and a simple
HTTP proxy that incorporates the signature matching ﬁlter (about 5000 lines
of code). The supervision framework is provided by STEM (about 19000 lines
of C code). One advantage of writing the proxy in Java is that it provides an
implicit level of diversity for the system. The small codebase of PayL and the
proxy allows for easy auditing.
4.1 HTTP Proxy and PayL
The HTTP proxy is a simple HTTP server that spawns a new thread instance
for each incoming request. During the service routine, the proxy invokes a chain
of Filter objects on the HTTP request. Our default ﬁlter implementation main-
tains three signature-based ﬁlters and a Classiﬁer object. PayL implements the
Classiﬁer interface to provide an anomaly-based score for each HTTP request.
Input
source
Java HTTP Proxy
iptables
Apache HTTPD
Filters
PayL
STEM−ISR
Fig. 2. FLIPS’s Prototype Implementation Components. We constructed an HTTP
proxy to protect HTTP servers (in this example, Apache) from malicious requests.
The proxy invokes a chain of three ﬁltering mechanisms and PayL to decide what to
do with each HTTP request.
FLIPS: Hybrid Adaptive Intrusion Prevention
91
When the proxy starts, it creates an instance of PayL and provides PayL with
a sample traﬃc ﬁle to train on.
The core of the ﬁlter implementation is split between two subcomponents. The
checkRequest() method performs the primary ﬁltering and classiﬁcation work. It
maintains four data structures to support ﬁltering. The ﬁrst is a list of “suspi-
cious” input requests (as determined by PayL). This list is a cache that provides
the feedback mechanism a good starting point for matching conﬁrmed malicious
input. Note that this list is not used to drop requests. The remaining data collec-
tions form a three level ﬁltering scheme that trade oﬀ complexity and cost with
a more aggressive ﬁltering posture. These lists are not populated by PayL, but
rather by the feedback mechanism. The ﬁrst level of ﬁltering is direct match. This
ﬁlter is the least expensive, but it is the least likely to block malicious requests
that are even slightly metamorphic. The second ﬁlter is a reverse lookup ﬁlter
that stores requests by the score they receive from PayL. Finally, a longest com-
mon substring ﬁlter provides a fairly expensive but eﬀective means of catching
malicious requests.
The second component serves as the feedback mechanism in the proxy. It is a
background thread listening for connections from STEM that contains malicious
binary code. This thread simply reads in a sequence of bytes and checks if they
match previously seen “suspicious” input (as classiﬁed by PayL). If not, then the
thread widens its scope to include a small cache of all previously seen requests.
Matching is done using the longest common substring algorithm. If a match is
found, then that request is used in the aforementioned ﬁltering data structures.
If not, then a new request is created and inserted into the ﬁlters based on the
malicious byte sequence.
4.2 STEM
Our supervision framework is an application-level library that provides an emu-
lator capable of switching freely between derandomizing the instruction stream
and normal execution of the instruction stream on the underlying hardware. As
shown in Figure 3, four special tags are wrapped around the segment of code
that will be emulated.
void foo() {
int a = 1;
emulate_init();
emulate_begin(stem_args);
a++;
emulate_end();
emulate_term();
printf("a = %d\n", a);
}
Fig. 3. An example of using STEM tags. The emulate * calls invoke and terminate
execution of STEM. The code inside that region is executed by the emulator. In order
to illustrate the level of granularity that we can achieve, we show only the increment
statement as being executed by the emulator.
92
M.E. Locasto et al.
STEM is an x86 emulator that can be selectively invoked for arbitrary code
segments, allowing us to mix emulated and non-emulated execution inside the
same process. The emulator lets us (a) monitor for derandomization failures
when executing the instruction, (b) undo any memory changes made by the
code function inside which the fault occurred, and (c) simulate an error return
from said function. One of our key assumptions is that we can create a mapping
between the set of errors and exceptions that could occur during a program’s
execution and the limited set of errors that are explicitly handled by the pro-
gram’s code. Due to space limitations, the reader is referred to [29] for details on
the general implementation of STEM. In this section, we describe our additions
to enable STEM to derandomize an instruction stream and provide feedback to
the FLIPS proxy.
4.3 ISR Technique
The main loop of the emulator fetches, decodes, executes, and retires one instruc-
tion at a time. Before fetching an instruction, de-randomization takes place. Since
the x86 architecture contains variable-length instructions, translating enough
bytes in the instruction stream is vital for the success of decoding. Other-
wise, invalid operations may be generated. To simplify the problem, we as-
sume the maximum length (16 bytes) for every instruction. For every itera-
tion of the loop, 16-bit words are XOR’d with a 16-bit key and copied to a
buﬀer. The fetch/decode function reads the buﬀer and extracts one instruc-
tion. The program counter is incremented by the exact length of the processed
instruction. In cases where instructions are ﬁfteen bytes or less, unnecessary
de-randomization takes place, but this is an unavoidable side-eﬀect of variable-
length instructions. If injected code resides anywhere along the execution path,
the XOR function will convert it to an illegal opcode or an instruction which
will access an invalid memory address. If an exception occurs during emulation,
STEM notiﬁes the proxy of the code at the instruction pointer. STEM captures
1KB of code and opens a simple TCP socket to the proxy (the address and
port of the feedback mechanism are included in the startup options for emu-
late begin()). STEM then simulates an error return from the function it was
invoked in.
5 Evaluation
Inserting a detection system into the critical path of an application is a
controversial proposal because of the anticipated performance impact of the
detection algorithms and the correctness of the decision that the detection
component reaches. Our primary aim is to show that the combined beneﬁt of
automatic protection and exploit signature generation is worth the price of even a
fairly unoptimized proxy implementation. Our evaluation has three major aims:
FLIPS: Hybrid Adaptive Intrusion Prevention
93
1. show that the system is good at classiﬁcation
2. show that the system can perform end-to-end (E2E)
3. show that the system has relatively good performance
The ﬁrst aim is accomplished by calculating the ROC curve for PayL. The
second aim is accomplished by an E2E test showing how quickly the system can
detect an attack, register the attack bytes with the ﬁlters, create the appropriate
ﬁlter rules, and drop the next instance of the attack. We send a request stream
consisting of the same attack at the proxy and measure the time (in both number
of ’slipped’ attacks and real time) it takes the proxy to ﬁlter the next instance
of the attack. The third aim is accomplished by measuring the additional time
the proxy adds to the overall processing with two diﬀerent HTTP traces. We
were unable to test how well FLIPS blocked real metamorphic attack instances.
However, the use of the Longest Common Substring algorithm should provided
some measure of protection, as our last experiments showed. We plan to evaluate
this capability in future work on the system.
5.1 Hypotheses and Experiments
We investigate four hypotheses to support our aims.
– Hypothesis 1: The use of ISR imposes a manageable performance overhead.
We evaluate this hypothesis with experiments on STEM that explore the
impact of partial emulation vs. full emulation on Apache requests.
– Hypothesis 2: The eﬃcacy of PayL is good. We evaluate this hypothesis
by showing the ROC curve for PayL.
– Hypothesis 3: The proxy imposes a manageable performance overhead. This
performance overhead is introduced by a few sources:
1. the use of an interpreted language (Java) to implement the proxy and
the anomaly detector.
2. the implementation choices of the proxy (e.g., multi-threaded but syn-
chronized at one ﬁlter manager). Performance can be improved by adding
multiple ﬁlter manager objects.
3. the basic cost of performing proxying, including reading data from the