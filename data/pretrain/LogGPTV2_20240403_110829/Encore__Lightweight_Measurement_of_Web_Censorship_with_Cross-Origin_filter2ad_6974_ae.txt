ally accepted that users already have little control over or
knowledge of much of the trafﬁc that their Web browsers
and devices generate (a point raised by Princeton’s ofﬁce of
664research integrity and assurance), which already gives users
reasonable cover. By analogy, the prevalence of malware and
third-party trackers itself lends credibility to the argument
that a user cannot reasonably control the trafﬁc that their de-
vices send. The more widespread measurements like Encore
become, the less risky they are for users.
Filtering access to Encore infrastructure. Clients can only
use Encore if they can fetch a measurement task. If the do-
main (or URL) that hosts measurement tasks is itself blocked,
clients will not be able to execute measurements. Once a
client retrieves a measurement task, subsequent requests ap-
pear as ordinary cross-origin requests; as a result, the main
concern is ensuring that clients can retrieve measurement
tasks in the ﬁrst place.
The server that dispatches tasks could be replicated across
many domains to make it more difﬁcult for a censor to block
Encore by censoring a single domain. Clients could con-
tact the coordination server indirectly via an intermediary or
create mirrors of the coordination server in shared hosting
environments (e.g., Amazon AWS), thereby increasing the
collateral damage of blocking a mirror. Going further, web-
masters could contact the coordination server on behalf of
clients (e.g., with a WordPress plugin or Django package) by
querying the coordination server and including the returned
measurement task directly in the page it serves to the client;
to increase scalability and decrease latency, servers could
cache several tasks in advance. Similarly, collection of the
results could be distributed across servers hosted in different
domains, to ensure that collection is not blocked.
There are limits to Encore’s ability to withstand such at-
tacks. Because it runs entirely within a Web browser, Encore
cannot leverage stronger security tools like Tor to anony-
mously report measurements [12, 44].
Detecting and interfering with Encore measurements.
Blocking Encore based on the contents of measurement tasks
(e.g., via deep packet inspection) should be difﬁcult, because
we can easily disguise tasks’ code using JavaScript obfus-
cation or detection evasion techniques [13, 25]. Identifying
task behavior is equally difﬁcult because it appears merely as
requests to load a cross-origin object—something many Web
sites do under normal operation. If a single client performs
a sequence of cross-origin requests that appear unrelated to
the content of the host site, a censor may recognize the se-
quence as unusual and either block the subsequent reports
or otherwise attempt to distort the results. We expect such
interference to be relatively difﬁcult, however, since a cen-
sor would ﬁrst have to identify a sequence of requests as a
measurement attempt and interpose on subsequent requests to
interfere with the reports. Although such interference is plau-
sible, censors do not generally interfere with measurements
today, so we leave this consideration to future work.
Attackers may attempt to submit poisoned measurement
results to alter the conclusions that Encore draws about
censorship. We could try to employ reputation systems to
thwart such attacks, although it would be practically impos-
sible to completely prevent such poisoning from untrusted
clients [21].
9 Conclusion
Despite the importance of measuring the extent and nature of
Internet censorship, doing so is difﬁcult because it requires
deploying a large number of geographically diverse vantage
points, and recruiting volunteers for such a deployment is a
signiﬁcant deployment hurdle. This paper presents an alter-
nate approach: rather than requiring users to install custom
measurement software, we take advantage of the fact that
users’ Web browsers can perform certain types of cross-origin
requests, which we can harness to induce measurements of
reachability to arbitrary third-party domains. Although only
a limited amount of information about the success of these
requests leaks across domains, even a small amount of leak-
age turns out to be enough to permit inferences about the
reachability of higher-level Web resources, including both
entire domains and speciﬁc URLs.
Encore shifts the deployment burden from clients to web-
masters. We have designed Encore so that deployment is
simple (in many cases, webmasters only add one line to the
main Web page source). We also point out that many web-
masters are typically interested in monitoring the reachability
of their sites from various client geographies and networks in
any case, so deployment incentives are well-aligned.
Although the types of measurements Encore can perform
may be more deﬁnitive than tools that rely on informal user
reports (e.g., Herdict), Encore may draw far fewer conclusions
about the scope and methods of censorship than tools that
measure censorship methods in detail (e.g., OONI, Centinel).
Ultimately, censorship measurement is a complex, moving
target, and no single measurement method or tool can paint a
complete picture. What is sorely missing from the existing
set of measurement tools, however, is a way to characterize
censorship practices in broad strokes, based on a sizeable
and continuous set of client measurements. By ﬁlling this
important hole in our understanding, Encore can help bridge
the gap between diverse yet inconclusive user reports and
detailed yet narrow or short-term ﬁne-grained measurements.
The prospect of using Encore to collect measurements from
unsuspecting users has already stirred controversy within the
networking community and prompted a wider dialogue on
ethics of network measurement [34]. Forthcoming guide-
lines for ethical measurement will hopefully help determine
whether we can deploy Encore more widely. Our work is
beneﬁcial regardless: If wider deployment is appropriate, this
paper has explained how Encore could yield valuable insight
on Web censorship at a previously unattainable scale; if ethi-
cal concerns make further deployment infeasible, our work is
evidence that attackers could use tools like Encore to place
users in harm’s way and that perhaps cross-origin security
policy should be strengthened to prevent such attacks.
665A Example of a measurement task
This is a complete example of JavaScript code that runs in a
client’s Web browser to measure Web ﬁltering using cross-
origin embedding of a hidden image. It uses jQuery [28]. The
coordination server miniﬁes and obfuscates the source code
before sending it to a client.
See http://goo.gl/l8GU0R for a simple demo of
Encore’s cross-origin request mechanism.
var M = Object();
// A measurement ID is a unique identifier
// linking all submissions of a measurement.
M.measurementId = ... // a UUID.
// This function embeds an image from a remote
// origin, hides it, and sets up callbacks to
// detect success or failure to load the image.
M.measure = function() {
var img = $(’’);
img.attr(’src’, ’//target/image.png’);
img.style(’display’, ’none’);
img.on(’load’, M.sendSuccess);
img.on(’error’, M.sendFailure);
img.appendTo(’html’);
}
// This function submits a result using
// a cross-origin AJAX request. The server
// must allow such cross-origin submissions.
M.submitToCollector = function(state) {
$.ajax({
url: "//collector/submit" +
"?cmh-id=" + this.measurementId +
"&cmh-result=" + state,
});
}
M.sendSuccess = function() {
M.submitToCollector("success");
}
M.sendFailure = function() {
M.submitToCollector("failure");
}
// Submit to the server as soon as the client
// loads the page, regardless of the
// measurement result. This indcates which
// clients attempted to run the measurement,
// even if they don’t submit a final result.
M.submitToCollector("init");
// Run the measurement when the page loads.
$(M.measure);
Acknowledgments
This research was supported by NSF Awards CNS-1409635,
CNS-1540066, and a Google Focused Research Award. We
thank Joss Wright for an insightful discussion about the
ethics of measuring Web censorship without informed con-
sent. Thank you to the many webmasters who have installed
Encore on their Web sites.
References
[1] S. Aryan, H. Aryan, and J. A. Halderman. Internet Censorship
in Iran: A First Look. In USENIX Workshop on Free and
Open Communications on the Internet (FOCI), aug 2013.
[2] A. Barth, J. Caballero, and D. Song. Secure content snifﬁng
for web browsers, or how to stop papers from reviewing
themselves. In IEEE Symposium on Security and Privacy,
pages 360–371, 2009.
[3] M. bin Tariq, M. Motiwala, N. Feamster, and M. Ammar.
Detecting Network Neutrality Violations with Causal
Inference. In Proc. CoNEXT, Dec. 2009.
[4] Bootstrap. http://getbootstrap.com.
[5] A. Bortz and D. Boneh. Exposing private information by
timing web applications. In International Conference on
World Wide Web (WWW), pages 621–628, Banff, Alberta,
Canada, 2007.
[6] Browser Security Handbook: Navigation and Content
Inclusion Across Domains. http://goo.gl/uMfTN5.
[7] M. Casado and M. J. Freedman. Peering through the shroud:
The effect of edge opacity on ip-based client identiﬁcation. In
USENIX Conference on Networked Systems Design and
Implementation (NSDI), Cambridge, MA, Apr. 2007.
[8] Centinel. https://github.com/iclab/centinel.
[9] M. Clark. IRB/Ethics Questions, Sept. 2014. http:
//encore.noise.gatech.edu/irb-mail.txt.
[10] R. Clayton, S. Murdoch, and R. Watson. Ignoring the Great
Firewall of China. In Privacy Enhancing Technologies (PET),
pages 20–35. Springer, 2006.
[11] J. Crandall, D. Zinn, M. Byrd, E. Barr, and R. East.
ConceptDoppler: A Weather Tracker for Internet Censorship.
In Proceedings of the ACM Conference on Computer and
Communications Security (CCS), Arlington, VA, Oct. 2007.
[12] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The
second-generation onion router. In Proc. 13th USENIX
Security Symposium, San Diego, CA, Aug. 2004.
[13] K. P. Dyer, S. E. Coull, T. Ristenpart, and T. Shrimpton.
Protocol misidentiﬁcation made easy with
format-transforming encryption. In ACM Conference on
Computer & Communications Security (CCS), pages 61–72,
2013.
[14] R. Ensaﬁ, J. Knockel, G. Alexander, and J. R. Crandall.
Detecting intentional packet drops on the internet via tcp/ip
side channels. In Passive and Active Measurement, pages
109–118. Springer, 2014.
[15] A. Filast`o and J. Appelbaum. OONI: Open Observatory of
Network Interference. In USENIX Workshop on Free and
Open Communications on the Internet (FOCI), Aug. 2012.
[16] Filbaan. http://filbaan.net.
[17] Google analytics. https://google.com/analytics.
[18] Google Transparency Report. http:
//www.google.com/transparencyreport/.
[19] GreatFire.org: Online Censorship in China.
http://en.greatfire.org/.
666[20] K. P. Gummadi, S. Saroiu, and S. D. Gribble. King:
Estimating latency between arbitrary internet end hosts. In
Proceedings of the 2nd ACM SIGCOMM Workshop on
Internet measurment, pages 5–18. ACM, 2002.
[21] S. Hao, N. Syed, N. Feamster, A. Gray, and S. Krasser.
Detecting Spammers with SNARE: Spatio-temporal
Network-level Automatic Reputation Engine. In Proc. 18th
USENIX Security Symposium, Montreal, Quebec, Canada,
Aug. 2009.
[22] HAR 1.2 spec. http://www.softwareishard.com/
blog/har-12-spec/.
[23] HerdictWeb: The Verdict of the Herd.
http://herdict.org.
[24] Herdict: Browse Lists. http://herdict.org/lists.
Visited 2014-02-26.
[25] F. Howard. Malware with your mocha: Obfuscation and
antiemulation tricks in malicious javascript. Sophos Technical
Papers, 2010.
[26] L.-S. Huang, Z. Weinberg, C. Evans, and C. Jackson.
Protecting browsers from cross-origin CSS attacks. In ACM
Conference on Computer and Communications Security
(CCS), pages 619–629, Chicago, IL, Oct. 2010.
[27] B. Jones, R. Ensaﬁ, N. Feamster, V. Paxson, and N. Weaver.
Ethical concerns for censorship measurement (to appear). In
Ethics in Networked Systems Research, Aug. 2015.
[28] jQuery. http://jquery.com.
[29] M. Karir, G. Huston, G. Michaelson, and M. Bailey.
Understanding IPv6 Populations in the Wild. In Passive and
Active Measurement (PAM), pages 256–259, Hong Kong, Mar.
2013.
[30] V. Lam, S. Antonatos, P. Akritidis, and K. G. Anagnostakis.
Puppetnets: Misusing Web Browsers as a Distributed Attack
Infrastructure. In ACM Conference on Computer and
Communications Security (CCS), pages 221–234, Alexandria,
VA, Oct. 2006.
[31] MaxMind GeoIP Country. http:
//www.maxmind.com/app/geolitecountry.
Retrieved: June 2011.
[32] Z. Nabi. The anatomy of web censorship in Pakistan. In
USENIX Workshop on Free and Open Communications on the
Internet (FOCI13), Washington, DC, Aug. 2013.
[33] Noction: Network Intelligence.
http://www.noction.com.
[34] Workshop on Ethics in Networked Systems Research.
http://conferences.sigcomm.org/sigcomm/
2015/netethics.php.
[35] OpenNet Initiative. http://www.opennet.net/.
[36] OpenNet Initiative Research Publications.
http://www.opennet.net/research/.
[37] Report on China’s Filtering Practices, 2008. Open Net
Initiative. http://opennet.net/sites/opennet.
net/files/china.pdf.
[38] Open Observatory of Network Interference (OONI).
https://ooni.torproject.org.
[39] Phantomjs. http://phantomjs.org.
[40] Same Origin Policy. https://developer.mozilla.
org/en-US/docs/Web/JavaScript/Same_
origin_policy_for_JavaScript. Mozilla
Developer Network.
[41] S. Schechter and C. Bravo-Lillo. Ethical-response survey
report: Fall 2014. Technical Report MSR-TR-2014-140,
November 2014.
[42] A. Sfakianakis, E. Athanasopoulos, and S. Ioannidis.
CensMon: A Web Censorship Monitor. In USENIX Workshop
on Free and Open Communication on the Internet (FOCI),
San Francisco, CA, Aug. 2011.
[43] How to add a favicon to your site.
http://www.w3.org/2005/10/howto-favicon.
[44] P. Winter. Towards a Censorship Analyser for Tor. In USENIX
Workshop on Free and Open Communications on the Internet
(FOCI), Washington, DC, Aug. 2013.
[45] Content security policy.
http://www.w3.org/TR/CSP/, Nov. 2012.
[46] X. Xu, Z. M. Mao, and J. A. Halderman. Internet censorship
in China: Where does the ﬁltering occur? In Passive and
Active Measurement (PAM), pages 133–142, Atlanta, GA,
2011.
[47] J. Zittrain and B. Edelman. Internet ﬁltering in China. IEEE
Internet Computing, 7(2):70–77, 2003.
667