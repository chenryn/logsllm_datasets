from
cache
1141
0
1141
1141
OTA
9392
11796
9392
5025
Time
(min)
11490
15552
14072
N/A∗
Table 5: DIKEUE performance of different components. M =
Membership queries and E = Equivalence queries.
We now evaluate the effect of different components of the adapter
in FSM inference module applying different domain-specific opti-
mizations. The results of these evaluations are shown in Table 5.
10.1.1 RQ3.1. Impact of optimal alphabet set: In case all the feasible
input symbols from the predicates are included in the alphabet set,
the size of the input alphabet set would be 59 (Table 9 shows all the
possible symbols from the predicates and the symbols picked for
the optimized alphabet set). With our optimized design choice, we
reduce the alphabet size to 35. To show the impact of the alphabet
size, we infer the model of two different devices of two different
vendors with an alphabet set of 35 and 59 respectively up to the
attach procedure. Note that with the optimized alphabet set, we are
able to reduce the queries required to learn the attach procedure by
at least 35%. As the number of queries directly correlates to time,
this substantially improves the performance of DIKEUE.
10.1.2 RQ3.2. Adapter
context checking: To eval-
uate the performance
improvement of the con-
text checker, we create
a variation of FSM in-
Figure 6: Impact of alphabet size
ference module with all
the optimizations in the context checker turned off and compare
it with the proposed FSM inference module’s performance. With
optimizations the system found 1620 invariant violations out of
5756 queries up to the attach procedure and thus improved the time
performance by 22%.
10.1.3 RQ3.3. Impact of cache: To evaluate the performance im-
provement of the cache, we turn off caching and compare it with
the original FSM inference module performance. About 19% of the
queries are cached, which reduces the over-the-air queries by 20%
and improves the performance of the system by 26%.
10.1.4 RQ3.4. Impact of inconsistency-resolver: To calculate the
overhead of the inconsistency resolver, we disable the resolver and
compare it with the general system where each query is sent only
once and the result is saved in the cache. However, without the
inconsistency resolver, after a certain time of the learning process,
the learner grinds into complete halt due to inconsistencies in
the responses (shown as N/A in Table 4). At that time, someone
has to manually analyze the queries in the cache and remove the
inconsistent responses, which requires domain knowledge and time.
In our experiments, the learner without inconsistency resolver got
stuck 15 times to learn up to the attach procedure.
10.2 FSM equivalence checker performance
Table 6 presents pairwise all possible deviant behaviors among 14
devices identified by our FSM equivalence checker. For instance,
Nexus 6 and Samsung Galaxy S6 have 11 discrepancies, whereas
Nexus 6 and Nexus 6P has no discrepancy. This is consistent because
Alphabet sizeNumber of queriesGalaxy S6(Exynos)Nexus 6P(Qualcomm)3559Session 4B: Wireless, Mobile, and IoT CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1093Nexus6
HTC1
GalaxyS6
HTC 10
Nexus6P
GalaxyS8+
Pixel 3XL
HuwaeiY5
Honor8X
Huwaei P8
Iphone Xs
Fibocom
MiA1
USB
6
s
u
x
e
N
1
C
T
H
8
6
S
y
x
a
l
a
G
11
7
0
1
C
T
H
0
8
11
P
6
s
u
x
e
N
0
8
11
0
+
8
S
y
x
a
l
a
G
0
8
11
0
0
L
X
3
l
e
x
i
P
0
8
11
0
0
0
5
Y
i
e
w
a
u
H
8
0
6
8
8
8
8
X
8
r
o
n
o
H
9
10
12
9
9
9
9
10
8
P
i
e
a
w
u
H
12
10
12
12
12
12
12
10
6
1
A
M
i
0
8
11
0
0
0
0
8
10
12
s
X
e
n
o
h
p
I
6
8
5
6
6
6
6
8
9
10
6
B
S
U
2
8
12
0
0
2
0
8
10
13
0
6
m
o
c
o
b
i
F
6
8
5
6
6
6
6
8
9
10
6
0
6
Table 6: Number of unique deviants.
Nexus 6 and Nexus 6P have the same vendor (Qualcomm) and a
similar version of baseband. Interestingly, among the devices from
the same vendor, all the devices behave similarly except HiSilicon.
Particularly, two devices from HiSilicon– Huwaei Honor 8X (Kirin
710) and Huwaei P8lite (Kirin 620) behave quite differently and
DIKEUE identifies 6 unique differences among them. We manually
analyze all the discrepancies and report 17 unique issues in Table 3.
To evaluate the timing performance of FSM equivalence checker,
we calculate the time required for all pairwise deviation checking 5
times and report the average, max, min and standard deviation in
Table 10. On an average, FSM equivalence checker takes 42 minutes
to find all the deviations. The timing cost of querying to the model
checker is shown in Figure 8 in Appendix A.2.
11 RELATED WORK
We divide the related work in two broad categories: (i) Model learn-
ing and protocol state fuzzing; (ii) Cellular network security.
Model learning in different domains. Model learning can be
distinguished between a passive and an active approach. In passive
learning, only existing data is used and based on the data, a model
is constructed. For example, in [18], passive learning techniques
are used on observed network traffic to infer a state machine of
the protocol used by a botnet. This approach has been combined
with the automated learning of message formats in [29], which
then also used the model obtained as a basis for fuzz testing. When
using active automated learning techniques, as done in this paper,
an implementation is actively queried by the learning algorithm
and based on the responses, a model is constructed. State machines
learning has lately become a tool for analyzing the security protocol
implementations of various protocols, such as: TLS [21], DTLS [26],
TCP [25], IoT [53], OpenVPN [20], QUIC [46], and SSH [27]. In the
area of cellular networks, recently Chlosta et al. [15] aimed to apply
model learning to a component of the core network (MME). How-
ever, they only apply to open-source MME networks and do not
experiment with real-world implementations and therefore do not
face a lot of challenges that DIKEUE encounters and solves. Stone
et al. [43] extend state learning to analyze implementations of the
802.11 4-way handshake. In practice, model learning often falls to
non-determinism due to unreliable commuinication medium and re-
quires an prohibitively large number of queries to learn an FSM of a
protocol implementation. Several approaches have been developed
by the research community to deal with these issues. HVLearn [52]
and SFADiff [11] uses cache to avoid the communication cost of
repeated queries and improve performance. Furthermore, majority
voting has been used to deal with non-determinism [26, 43, 44].
Cellular network security. Previous work on 4G LTE implemen-
tation security has either been found by complete manual analy-
sis [16, 23, 28, 38, 40, 41, 48, 51] or semi automated testing [39, 47].
Other than protocol implementations, there is another body of
work related to protocol specifications. Rupprecht et al. [49] showed
missing integrity allows the redirection of malicious websites by an
active attacker. Hussain et. al. used manually constructed models
for verifying certain parts of the 4G [30] and 5G [32] protocols.
12 DISCUSSION
Limitations of DIKEUE. Similar to any testing paradigm, our ap-
proach is incomplete and may result in false negatives due to— (1)
not considering all possible message predicates in model learning;
(2) precluding infeasible message sequences from testing; (3) use