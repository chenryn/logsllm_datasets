User: I have two pretty simple Tornado-based websocket handlers running in the same process, each of which function properly on their own. However, when one is receiving a large amount of data (>8MB) the process blocks and the other is unable to process messages until all of the data has been received. Is there any way I can get around this and prevent tornado from blocking here?
Assistant: Tornado works well with large amount of short concurrent requests.
It does not split long request into smaller ones. So process blocks.
Why you passing big amount of data using sockets? Final solution depends on answer to this question. 
If you don't have big requests too often - just use haproxy in front of multiple tornado instances.