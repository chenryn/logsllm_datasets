whole system: reader failures and system failures coincide.
Likewise, the CADT may have false negative failures (not
highlighting the ﬁlm features that indicate a cancer), or false
positive ones (highlighting features in ﬁlms of patients who
do not have cancer).
This system is somewhat unusual for reliability engi-
neers, in two ways:
• the failure probabilities that we will be discussing are
somewhat high. The probabilities of (false negative)
failure of readers in this decision task may be well over
10%;
• failures may not be due to any physical fault, or to any-
thing that we would normally call a design or imple-
mentation ﬂaw in the CADT. A CADT “failure” may
be just the effect of unavoidable limitations of pattern-
matching algorithms; or it might be due to a coding er-
ror in producing the software, and our model would not
make any distinction between the two cases. Likewise,
a reader’s “failure” in this terminology is any wrong
decision, even if it may be the best decision feasible
under the circumstances (e.g. if the mammogram’s ap-
pearance is misleading).
3 A dependability model based on the in-
tended procedure of use of the CADT
The CADT and the reader can be co-ordinated in at least
two ways:
1. the reader examines the ﬁlms alone, then considers
the output of the machine –based on the same ﬁlms–,
and then the reader reviews his/her judgement. Ideally,
whenever the CADT highlights a feature in the ﬁlms,
the readers will examine it with the same attention and
skill as the features that they noticed themselves.
2. the machine processes the ﬁlms ﬁrst, and then the
reader processes together both the original evidence
and the machine’s “annotations” on it.
The ﬁrst procedure seems more consistent with the de-
sign rationale of the CADT, and safeguards better the
reader’s ability to reach a conclusion without being biased
by the machine’s output. By design, this CADT is intended
only to suggest features that the reader should examine. It
is not intended to suggest a decision nor to cause the user to
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:31:04 UTC from IEEE Xplore.  Restrictions apply. 
Human
Detects
Machine
Detects
Human
Classiﬁes
Figure 2. Reliability Block Diagram (RBD) for
the “parallel detection” model of computer-
assisted detection.
ignore those parts of a mammogram that the CADT has not
prompted. Users are emphatically informed of this and dis-
couraged from using the CADT as a diagnostic system, and
the message is reinforced by presenting the CADT’s output
on low-resolution copies of the mammograms.
With this procedure, we can separately consider the two
parts of the decision-producing activity: detecting impor-
tant features in the ﬁlms, for which the reader is helped by
the CADT, and classifying them.
Any feature that the reader should examine in the classi-
ﬁcation part of the task is actually examined, provided that
either the reader or the CADT “notices” it. In the subtask of
detecting features, there is 1-out-of-2, parallel redundancy
between the reader and the CADT. Proper classiﬁcation, in-
stead, depends on the reader alone: if the reader misclassi-
ﬁes the important features, the system fails. Figure 2 depicts
this “parallel detection” scenario. It can be read as show-
ing the ﬂow of information, from left to right, through the
functions of the system components, but also as a reliability
block diagram: the system does not fail on a case if and only
if there is at least one path joining the points at the left-hand
and right-hand ends of the diagram without encountering a
component that fails on that case.
Mathematically, we can describe the probability of a
false negative as follows. Given a case, randomly cho-
sen from the subset of people, within the population to be
screened, who have cancer, we wish to describe the proba-
bility of a [false] negative decision. We write:
P (false negative failure of the system) =
P (M f AND Hmiss)+
P (NOT(M f AND Hmiss) AND Hmisclass)
(1)
Where M f, Hmiss, Hmisclass designate these
events:
• M f (“machine fails”): “false negative” failure of the
CADT: the CADT does not prompt any feature[s] in
the mammogram that would indicate cancer;
• Hmiss (“human misses”): “false negative” failure of
the reader in the detection task, deﬁned in the same
way as for the CADT;
• Hmisclass (“human misclassiﬁes”): “false negative”
failure of the reader in the classiﬁcation task:
the
reader takes the wrong decision on a case although the
relevant features have been identiﬁed for his/her anal-
ysis.
The probabilities of these events can, in principle, be es-
timated from results of evaluation trials. However, there are
complications. This model would be very convenient if:
1. we could estimate the parameters of the various blocks
separately, even when not connected in the system
(e.g., from the abundant data on readers’ performance
without the CADT), as we would expect to do with a
hardware reliability model;
2. we could assume independence between the failures of
the various blocks, so that we could write:
P (false negative failure of the system) =
PMf · PHmiss + PHmisclass · (1 − PMf · PHmiss)
(2)
About point (1), unfortunately, it is not clear that the per-
formance of readers, in either the detection or the classiﬁ-
cation task, is not affected by the presence of the CADT.
About point (2), we do not expect this independence
to hold. It is true that the reader and the CADT perform
the detection step separately, but this only implies that the
probability of the reader detecting the relevant features in a
mammogram depends on the mammogram itself but not on
the CADT’s reaction to it. Given this “conditional indepen-
dence”, the probability of failure of the detection part of the
task could be written as [8]):
P (detectionf ailure) =
PMf · PHmiss + covx(PMf (x), PHmiss(x)).
(3)
where the term PMf · PHmiss is the probability of detec-
tion failure if the CADT and the reader failed independently.
The new term covx(PMf (x), PHmiss(x)) is the covariance
between the probabilities of failure of the CADT and the
reader conditional on each speciﬁc case. If and only if this
term is 0, detection failures by the CADT and the reader are
indeed independent. High covariance would indicate that
cases on which the reader is likely to miss the important
features are those on which the CADT is also likely to miss
them: the advantage given by the CADT is then less than if
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:31:04 UTC from IEEE Xplore.  Restrictions apply. 
it failed with the same probability PMf , but independently
of the reader’s failures. If negative, it indicates the opposite,
i.e. that there is useful “diversity” between the two.
Another problem with this model is that the two steps
“Human detects” and “Human classiﬁes” are not physically
separate. That is, readers may not be consciously perform-
ing two different, separate steps. We do not know how to
identify the information that is the output of the ﬁrst step
and input to the second. So, there are serious difﬁculties in
evaluating the parameters P (Hmiss) and P (Hmisclass).
Last, but not least, we cannot be assured that the pro-
cedure followed actually guarantees even conditional inde-
pendence between failures of the three blocks in Fig. 2.
E.g., can we assume that the reader’s classiﬁcation of a
feature in the mammogram is the same independently of
whether it was detected by the reader him/herself or by the
CADT, or both? If we cannot, i.e. readers violate, at least
unconsciously, our simplifying assumptions, this model is
no longer attractive.
All these doubts imply that it may be desirable to design
the procedures of use with the explicit goal of satisfying the
assumptions that would make this model practical. How-
ever, without evidence that they are indeed satisﬁed we need
a more general model.
4 A less restrictive model: “Sequential” op-
eration
We have seen that, despite the apparent advantages of
the procedure described, it is not clear that it is actually fol-
lowed to the point that the “parallel detection” model can be
considered valid. Procedure 2) on p. 3, with the reader ex-
amining at the same time the mammogram and the CADT’s
output, seems faster and a better use of the machine’s sup-
port to save human labour, at the cost of the CADT’s output
possibly biasing the reader.
It also seems to be the pro-
cedure assumed in some evaluation trials of mammogram-
reading aids. In practice, in clinical trials or actual practice,
the readers can be asked to use the “parallel detection” pro-
cedure, but there are not necessarily constraints in the ex-
perimental or clinical set-up to ensure that they would not
use the other one, perhaps unconsciously. In this scenario,
all that we know is that the reader’s task is affected by the
CADT’s output. We can no longer identify two separate
phases in the reader’s activity, as in Fig. 2, one of which is
unaffected by the CADT’s output, .
We name the events of interest:
• M f (“machine fails”): “false negative” failure of the
CADT, deﬁned as before;
• Hf (“human fails”): “false negative” failure of the
reader and thus system failure: “no recall” decision for
a patient with cancer;
• M s = M f : “machine succeeds”, i.e. the negation of
“machine fails”.
Then,
P (false negative failure of the system) = P (human fails) ,
and to represent the effect of the CADT on the human’s
results, we rewrite this in terms of the conditional probabil-
ities of human failure, given that the CADT fails or that it
succeeds:
P (Hf) = P (Hf|M s) · P (M s) + P (Hf|M f) · P (M f)
(4)
If it happened that P (Hf|M s) = P (Hf|M f), the suc-
cess or failure of the reader would be – on average – inde-
pendent of whether the CADT succeeds or fails.
This model is less restrictive than the “Parallel detec-
tion” one: there are no assumptions constraining how the
behaviour of the CADT affects the reader. By varying the
values of the model’s parameters, any conceivable form of
this inﬂuence of the CADT can be represented.
As a next step, we must take into account the fact that the
failure probabilities of both machine algorithms and readers
vary with the characteristics of their inputs: some cases are
more difﬁcult than others. We describe this variation by ad-
ditional parameters – the probabilities of the various events,
conditional on each possible input case. To emphasise that
each such conditional probability is a function of the input
case, we indicate them as functions. For instance, with ref-
erence to the “sequential operation” model just described:
• pMf (x) designates the probability of false negative
failure of the CADT on a speciﬁc case x;
• pHf|Ms(x) - designates the probability of false nega-
tive failure of the reader on a speciﬁc case x for which
the CADT succeeded (highlighted all features relevant
for a decision).
Mathematically, the meanings of these parameters are,
e.g.:
pMf (x) = P (M f|the given case is x) =
P (M f AND the given case is x)
P (the given case is x)
(5)
and
pHf|Ms(x) =
P (Hf|M s AND the given case is x) =
P (Hf AND M s AND the given case is x)
P (M s AND the given case is x)
(6)
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:31:04 UTC from IEEE Xplore.  Restrictions apply. 
These conditional probabilities can be said to charac-
terise how difﬁcult a case is, for a certain task performed
on it. E.g., pMf (x) > pMf (y) indicates that case x is such
that the CADT is more likely to fail on it than on case y.
The difﬁculty for the CADT may be due to design choices,
perhaps required to reduce false positive failures for some
class of cases, or to design mistakes (bugs in the software),
or to unavoidable limits of image-processing algorithms. A
case that is more difﬁcult than another for the CADT may
or may not be more difﬁcult for the readers as well.
The probability of false negative failures at the system
level depends on how the “difﬁculty” of cases for the CADT
correlates with their “difﬁculty” for the readers, and, cru-
cially, how likely the various cases are. To represent this
latter aspect, we deﬁne the demand proﬁle:
p(x) = P (the input case given to the system is case x)
The probability of system failure on a randomly chosen
case is then:
PHf =
(cid:1)
x