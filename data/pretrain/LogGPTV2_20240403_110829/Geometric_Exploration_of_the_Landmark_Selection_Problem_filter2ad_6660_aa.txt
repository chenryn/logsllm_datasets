title:Geometric Exploration of the Landmark Selection Problem
author:Liying Tang and
Mark Crovella
Geometric Exploration of the Landmark Selection
Problem
Liying Tang and Mark Crovella
Department of Computer Science, Boston University, Boston, MA 02215
{litang,crovella}@cs.bu.edu
Abstract. Internet coordinate systems appear promising as a method for esti-
mating network distance without direct measurement, allowing scalable conﬁgu-
ration of emerging applications such as content delivery networks, peer to peer
systems, and overlay networks. However all such systems rely on landmarks, and
the choice of landmarks has a dramatic impact on their accuracy. Landmark sel-
ection is challenging because of the size of the Internet (leading to an immense
space of candidate sets) and because insight into the properties of good landmark
sets is lacking. In this paper we explore fast algorithms for landmark selection.
Whereas the traditional approach to analyzing similar network-based conﬁgurka-
tion problems employs the graph structure of the Internet, we leverage work in
coordinate systems to treat the problem geometrically, providing an opening for
applying new algorithms. Our results suggest that when employing small numbers
of landmarks (5-10), such geometric algorithms provide good landmarks, while
for larger numbers of landmarks (20-30) even faster methods based on random
selection are equally effective.
1 Introduction
Internet coordinate schemes assign coordinate vectors to hosts in the Internet, and at-
tempt to do so in a manner such that the Euclidean distance between hosts approximates
their network distance, usually taken to be minimum RTT [7]. The power of such co-
ordinate systems is that they allow network distance to be estimated in the absence of
measurement. As a result, applications for which network distance matters (such as con-
tent delivery networks, peer to peer applications, end-system multicast, and others) can
be rapidly conﬁgured in a network-sensitive manner based on static input data (i.e., a
database of nodes and their coordinates).
A number of proposals have been put forward for such systems, ranging from initial
proposals based on expensive nonlinear optimization [7,14] to more recent fast methods
based on Lipschitz embedding and dimensionality reduction [6,13]. All such proposals
start from a set of inter-node measurements. For scalability, it is assumed that all nodes
desiring coordinates cannot measure all distances of interest (i.e., distances to all other
nodes), and so must choose a set of landmarks by which to establish their coordinates.
Thus, the usual arrangement is that all nodes measure their distances to a ﬁxed set (or at
least to a ﬁxed number) of landmarks, and use those measurements to determine their
coordinates, so that measurement load in the network scales linearly with the number
of nodes. Early work assumed a ﬁxed set of landmarks, which recent proposals have
C. Barakat and I. Pratt (Eds.): PAM 2004, LNCS 3015, pp. 63–72, 2004.
c(cid:1) Springer-Verlag Berlin Heidelberg 2004
64
L. Tang and M. Crovella
suggested that measurement load may be distributed by using multiple landmark sets
[13,10].
Thus, in order to deploy coordinate systems, speciﬁc landmarks must be chosen.
There is reason to believe that the accuracy of Internet coordinate systems is sensitive
to the particular choice of landmarks. First, larger landmark sets are generally more
accurate, because they bring more information to bear on the coordinate construction
step. Second, two landmarks that are “close” to each other in the Internet may provide
little discriminatory power – meaurements to both landmarks will be nearly the same
and will therefore add little information in the coordinate construction step.
Because of the large number of possible landmarks (hundreds of millions in the
Internet) and the complex relationship between landmarks used and the accuracy of the
resulting coordinate scheme, optimal landmark selection is a very challenging problem.
A natural approach in seeking heuristics to guide the search is to look for structure in
the distance measurements found in the Internet, and to try to place landmarks in ways
that exploit that structure.
In this paper we examine the structure of Internet distance measurements, and ask
whether that structure can help us select good landmarks in an efﬁcient way. While
network structure is usually throught of as a property of topology, we take a novel
approach that leverages the notion of internet coordinates: we examine the geometric
structure of network distances. We show that this structure is characterized by a high
degree of clustering.
We then proceed to ask what sorts of geometric algorithms, including those expli-
citly making use of clusters, can be used to efﬁcient landmark selections. We study this
question using the Virtual Landmarks embedding method and ﬁnd that the answer de-
pends on the size of the landmark set. Our initial results show that when using a small
number of landmarks (5-10), the proper choice of landmarks is quite important; but
when a larger number of landmarks is used, even random selection is as effective as
geometrically-informed approaches
Our results point the way to the ability to perform landmark selection in very large
datasets (since the geometric methods are relatively scalable) and suggest that if 20-30
landmarks can be used, then landmark selection can be done quite efﬁciently.
2 Related Work
Internet coordinate schemes were ﬁrst proposed in [7]. In this work, we use the Virtual
Landmarks method for forming internet coordinates as described in [13]. The Virtual
Landmarks method is based on two ideas: First, it uses a Lipschitz embedding of nodes
into a high dimensionsal space. In a Lipschitz embedding, the distances to a set of
landmarks are taken as the coordinates of the given node. Second, it uses dimensionality
reduction via Principal Component Analysis to reduce the higher-dimensional space
of Lipshitz embedding to a lower-dimensional space. In this paper, all coordinates are
7-dimensional, which was found in [13] to provide a reasonable tradeoff between low
dimension and accuracy. Thus, the algorithms in this paper are concerned with selecting
landmarks for the Lipschitz embedding, while all error metrics are measured based on
the coordinate assignments after reducing to 7 dimensions.
Geometric Exploration of the Landmark Selection Problem
65
The question of how to select landmarks has not been explicitly addressed in previous
Internet coordinate work. However it has relevance not just for Internet coordinates, but
for all methods that employ Lipschitz embeddings on round-trip times.
A number of papers have used Lipschitz embeddings to assign coordinates to hosts.
In [16], the goal is to map an arbitrary host to a nearby landmark whose geographic
position is known. A landmark whose Lipschitz coordinates are similar to that of the
host is used as the estimated location of the host. A demographic placement approach
was proposed to improve the representativeness of landmarks with respect to the hosts to
be located. Like this work, they also explore placing probe machines in a geographically
distributed manner, to avoid shared paths.
In [9], the authors used a Lipschitz embedding to ﬁnd nearby nodes for the purpose of
geolocation. The number of probe machines and locations was studied in order to improve
accuracy. However, speciﬁc algorithms for landmark selection were not investigated.
Placement of other Internet resources, such as caches and mirrors, has been inve-
stigated (e.g., in [8] and [3]) however these studies have not looked at geometrically
inspired algorithms.
In computer vision, Lipschitz embeddings have been used to generate fast indexing
schemes for images. The problem for the choice of landmarks in this setting has been
studied in [2,15]. The authors in [2] propose four methods, including minimizing average
distortion, which is similar to our Greedy method. Maximum distance methods similar
to those we employ have been studied in [15]. However, the results are mainly relevant
to the kinds of similarities found among images and it is not clear that their conclusions
would apply to the problem of Internet distances.
Finally, a number of papers have proposed scalability methods for Internet coordinate
schemes based on construction of multiple landmark sets [13,10]. Such methods assume
the existence of algorithms for constructing landmark sets on the ﬂy; the work in this
paper can inform the choice of those algorithms.
3 Data
We use 3 datasets in this work, which are the same as used in [13].
NLANR AMP. The NLANR Active Measurement Project [1] collects a variety of
measurements between all pairs of participating nodes. Most participating nodes are at
NSF supported HPC sites, and so have direct connections to the Abilene network; about
10% are outside the US. The dataset we use was collected on January 30, 2003 and
consists of measurements of a 116 × 116 mesh. Each host was pinged once per minute,
and network distance is taken as the minimum of the ping times over the day’s worth of
data.
Skitter. The Skitter project [11] is a large-scale effort to continuously monitor routing
and connectivity across the Internet. It consists of approximately 19 active sites that send
probes to hundreds of thousands of targets. Targets are chosen so as to sample a wide
range of preﬁxes spanning the Internet. Results reported in [5] suggest that about 50%
66
L. Tang and M. Crovella
of the targets in this dataset are outside the US. The dataset we used was collected in
December 2002; each target was pinged approximately once per day. Network distances
are the minimum ping time over 12 days. The set of targets varies among active sites;
selecting the largest set of rows for which complete data is available yields a 12 × 12
symmetric dataset, and a 12 × 196,286 asymmetric dataset with 2,355,565 entries.
Sockeye. Our last dataset was collected at Sockeye Networks [12]. It consists of measu-
rements from 11 active sites to 156,359 locations. Targets were chosen through a scheme
designed to efﬁciently explore as much of the routable Internet as possible. Each active
site sent a ping to each target on an hourly basis. Network distance was taken as the
minimum of all pings over a single day.
4 Algorithms
Each algorithm we consider selects a set of (cid:1) landmarks {Li}, i = 1, .., (cid:1) taken from
datasets containing n hosts H = {hi}, i = 1, ..., n. The network distance (RTT) between
hi and hj is denoted d(hi, hj). Each algorithm takes as input an Internet coordinate
scheme φ : H → IRd and a distance function δ : IRd → R. In this paper φ represents
the mapping obtained from the Virtual Landmarks embedding into Euclidean space with
d = 7, and δ is the Euclidean norm.
Greedy. The most expensive approach is the Greedy algorithm [2]. The Greedy algo-
rithm chooses the set of landmarks that minimizes the average distortion of distances
at each step. We deﬁne the relative error function Q(hi, hj, φ) for a pair of hosts hi,
hj ∈ H as
Q(hi, hj, φ) = δ(φ(hi), φ(hj)) − d(hi, hj)
d(hi, hj)
The accuracy of the embedding φ can be calculated by the average absolute error:
¯Q(φ) = 2/(n2 − n)
|Q(hi, hj, δ)|
(cid:1)
i>j
Exact minimization of ¯Q(φ) is computationally infeasible for large n and (cid:1). A step-
wise approach that is tractable, but still quite expensive, is the Greedy algorithm, which
proceeds iteratively. The ﬁrst landmark L1 is chosen at random. Subsequent landmarks
are chosen so as to give the lowest average absolute error when used together with the
already-chosen landmarks. That is, in step m we choose Lm so as to minimize ¯Q(φ)
when used with landmark set L1, ..., Lm.
K-means. The k-means algorithm is a geometric algorithm that operates on distances
as computed using an Internet coordinate scheme. K-means ﬁnds (cid:1) disjoint clusters in
the data [4]. It starts by choosing (cid:1) hosts to act as centroids (c1, ..., c(cid:1)) at random. Each
centroid cj has an associated cluster Gj. The algorithm then repeatedly performs the
following three steps:
Geometric Exploration of the Landmark Selection Problem
67
1. Assign each host h ∈ H to the cluster Gj with the nearest centroid cj.
2. For each cluster Gj, calculate a new center c =
3. Assign a new centroid cj to Gj as the host nearest to this center c.
h∈Gj
(cid:2)
h|Gj|
These steps are iterated until the centroids and the clusters become stable. Then,
these (cid:1) centroids chosen by the above k-means algorithm are assigned as the landmarks.
Maximum Distance. The Maximum Distance algorithm is also a geometric algorithm.
It attempts to ﬁnd the maximally-distributed landmarks from the set of n hosts, based on
the intuition that landmarks must be spread far apart to give useful location information
[15]. The (cid:1) landmarks are chosen in an iterative manner. The ﬁrst landmark L1 is chosen
from the set H at random. In iteration m (1 < m ≤ (cid:1)) the distance from a host hi to the
set of already chosen landmarks L1, ..., Lm−1 is deﬁned as the minLj δ(φ(hi), φ(Lj)).
The algorithm selects as landmark Lm the host that has the maximum distance to the set
L1, ..., Lm−1.
Random. The Random method is the most efﬁcient and simplest among all four algo-
rithms. The (cid:1) landmarks are randomly chosen from the n hosts.
5 Clusters
One reason for considering geometric algorithms for landmark placement is that Inter-
net hosts show a high degree of clustering. In this section we explore empirically this
clustering in our datasets.
As described in Section 2 our data consists of Internet hosts whose coordinates are
points in IRn with n = 7. We can start to examine the evidence for clustering in our
datasets by looking at projections of the points onto various subspaces. When using the
Virtual Landmarks method for coordinate assignment, coordinates are assigned in order
of signiﬁcance. The ﬁrst coordinate captures the largest amount of variation possible
in a single dimension, the next coordinate captures the largest amount of variation in
the remaining dimensions, and so on [13]. Thus the most signiﬁcant projections of the
resulting data are onto the subspaces spanned by the initial axes of the coordinate system.
In Figure 1(a) we show the projection of the Skitter dataset onto the space spanned
by the ﬁrst two axes. In Figure 1(b) we show the corresponding plot for the Sockeye
dataset. To reduce plot ﬁle size we plot a random sample of 30,000 hosts from each of
our datasets; plots of the entire dataset show exactly the same features.
These plots show the remarkable amount of clustering (as well as other types of
structure) that is present when Internet hosts are embedded in Euclidean space. Although
the two plots represent data that was collected at different times from completely different
measurements infrastructures (having different probes and target locations), they show
very similar structure. The number, sizes, and relative positions of the largest clusters in
each dataset are very similar.
Although these two datasets we collected in different ways, the underlying data
collection strategy in each case was to try to sample all portions of the space of live
68
L. Tang and M. Crovella
e
t
a
n
i
d
r
o
o
C
d
n
o
c
e
S
e
t
a
n
i
d
r
o
o
C
d
n
o
c
e
S
0.008
0.006
0.004
0.002
0
-0.002
-0.004
-0.006
-0.008
0.006
0.004
0.002
0
-0.002
-0.004
-0.006
-0.008
-0.01
-0.012
e
t
a
n
i
d
r
o
o
C
d
n
o
c
e
S
-0.01
-0.012
-0.01
-0.008
-0.006
-0.004
-0.002
0
-0.014
-0.012
-0.01
-0.008
-0.006
-0.004
-0.002
0
First Coordinate
(a)
First Coordinate
(b)
Fig. 1. Clusters in (a) Skitter Data and (b) Sockeye Data
0.002
0.0015
0.001
0.0005
0
-0.0005
-0.001
-0.002
-0.0018
-0.0012
-0.001
-0.0016
-0.0014
First Coordinate
(a)
d
i
o
r
t
n
e
C
o
t
e
c
n
a
t
s
i
D
e
g
a
r
e
v
A
400
350
300
250
200
150
100
50
skitter
sockeye
0
20
40
60
80
100 120 140 160 180 200
Number of clusters
(b)
Fig. 2. (a) Zoom In on Clusters in Sockeye Data (b) Average Distance to Cluster Centroid as a
Function of Number of Clusters
Internet addresses. Thus we interpret the similarity between Figures 1(a) and 1(b) as
evidence that the structure exhibited reﬂects real properties of Internet host connectivity.
We can also observe that clustering is present on smaller scales as well. Figure 2(a)
zooms in on a part of Figure 1(b) corresponding to the largest visible cluster. This ﬁgure
shows that even within a cluster, host density varies across different regions, suggesting
the presence of clustering at multiple scales.
To assess the number of clusters present in our data, we adopted the following ap-
proach. Using the k-means clustering algorithm as described in Section 4, we constructed
clusters for varying values of k and measured the mean cluster diameter. The resulting
curves for the skitters and sockeye datasets are shown in Figure 2(b). This ﬁgure shows
an inﬂection point around 20 clusters, indicating the presence of at least 20 clusters in
both datasets.
It is very likely that these clusters are inﬂuenced by the geographical location of
hosts. This can be seen in Figure 3 where we have identiﬁed the clusters formed with
k = 6 for the AMP dataset. Although the clustering algorithm uses no direct information
about geographical location, it produces clusters that are in fact geographically distinct.
Geometric Exploration of the Landmark Selection Problem
69
Fig. 3. Clusters in AMP data (based on graphic from [1]).
6 Algorithms for Landmark Selection
Motivated by these geometric considerations, in this section we evaluate algorithms for
landmark selection.
for landmark selection, leading to an embedding φ, we report ¯Q(φ).
We average absolute relative error as our principal metric. That is, for each algorithm
In addition, the entire distribution of relative error is of interest. In particular it is
important to know the variability of relative error for various landmark selection methods.