on four FCCE data nodes (CentOS VM with four virtual cores and
16GB memory) on four physical blades.
8Everything is started by init in Linux/FreeBSD with user root.
9Excluding queries with data issues.
We evaluated the fastest and the slowest graph queries to the
τ-calculus database for throughput and scalability. With data lo-
cality tuning built into the low-level key-value store schema, the
fastest/slowest graph queries are the ones associated with tight/loose
data localities. They share similar concepts of sequential/random
data access but in the context of distributed graph retrieval.
7.1 Graph Query by Event Time Range
Temporal locality on stores is one of the key features realized
through the τ-calculus database layer (Section 4.4). Events occur-
ring close in time are stored in one or nearby time slices, and they
can be promptly retrieved for fast temporal reasoning.
We randomly selected time ranges of 60, 300, ..., 28800 seconds,
and issued a simple τ-calculus query to retrieve a graph composed
of all events within the time range (100 runs per each range with
caches cleared between runs). During the DARPA competition, a
monitored host emitted 100k events per hour on average. Figure 12a
shows that it took on average 0.47s to retrieve all these events from
storage across the network, construct, and return the graph.
7.2 Graph Query by Element UUIDs
Data locality does not always exist. For instance, it is difficult to
define locality for a vital CG label—UUID. RFC 4122 defines UUID
as a 128-bit number [48], and it is random and unique for each
element (entity/event) in a CG. Element retrieval by UUID is to
event retrieval by time range what random data access is to sequen-
tial data access. To process a graph query with multiple UUIDs,
τ-calculus database retrieves multiple FCCE buckets that contain
the requested UUIDs. Events and entities are constructed and addi-
tional information may be requested to complete the graph before
return. On average, it took 0.46s to retrieve 128 elements shown in
Figure 12b, and 1.2 million unrelated elements were also fetched by
the FCCE client due to the lack of data locality. In this (graph queried
by UUID) case with no data locality, τ-calculus graph database still
displayed strong scalability in Figure 12b across distributed storage.
 0.01 0.1 1 10603006001800360028800104105106Time (second) [y]Avg. #(event) retrieved [z]Time range requested (second)#(event) [z]min/max [y]mean [y] 0.01 0.1 1 10124816326412825651210242048100101102103104105106107Time (second) [y]Avg. #(element) loaded [z]#(element) requested#(elem) [z]min/max [y]mean [y]Session 9D: VulnDet 1CCS’18, October 15-19, 2018, Toronto, ON, Canada18938 DISCUSSION
Beyond demonstrating the capabilities of threat intelligence com-
puting with τ-calculus, this paper also aims to outline promising
research opportunities enabled by the new security paradigm.
Incomplete Computation Graph. Incomplete data is the hurdle
for any threat discovery procedure, including the ones realized
with threat intelligence computing. It is non-trivial to implement
a monitor that guarantees a complete view of a system at select
monitoring levels. A new line of research pushes the state-of-the-
art monitoring techniques to a new level [2, 26, 38, 49, 57, 72, 96],
yet transmission and long-term storage are still open problems.
Given the realistic assumption that monitoring may not be com-
plete due to implementation limitations, it raises another research
challenge—how to deal with incomplete CGs in threat intelligence
computing. Though analysts may fix missing information in an
ad-hoc manner, e.g., Section 5.2, it is crucial to design a systematic
solution to deal with missing data and strike a balance between
data collection costs, e.g., computing and storage resources, and
data quality, e.g., level of details and completeness.
Multi-Level Computation Graph. Threat intelligence often deals
with data at various granularities and switches between them to
fulfill different tasks. Threat intelligence computing offers a new op-
portunity for analyses that involve granularity switching—folding
or unfolding CGs to easily zoom from one CG level to another.
Graph Pattern Constraint Solving. The current τ-calculus graph
pattern constraint solver implementation employs heuristics to
reorder constraints before solving. It is beneficial to research con-
straint ordering algorithms for achieving optimal constraint-solving
procedure. This is challenging due to two main observations:
on one CG may not be optimal on another CG.
• Data dependence of the problem: the optimal constraint order
• Complex pattern composition: pattern references and applica-
tions may invalidate inlining of constraints.
Machine Learning with Graph Languages. Many useful de-
tection algorithms, especially the ones based on machine learn-
ing [11, 22], do not have straightforward graph language equiva-
lents (even with Turing-complete graph languages like Gremlin).
While the shortcut is to provide external function interfaces as ex-
plained in Section 2.3, it is beneficial to develop native data mining
and machine learning algorithms in graph computation languages.
Higher-Order Graph Computation. Graph computation per-
formed on top of a graph, e.g., CG, can be described as another
graph [73]. One can collect large numbers of threat intelligence com-
puting processes and apply graph computation on the high-order
graphs for knowledge extraction and mining threat intelligence.
such as normal behavior models [16, 20, 50, 92], permitted behavior
models [17], vulnerabilities [77], and specific attack models [98].
An orthogonal view to manual/automatic knowledge acquisi-
tion is static/dynamic threat model development. Threat detection
is a never-ending game where new classes of threats are rapidly
developed as well as variations of threats in different setups. While
designing a detection system targeting a fixed set of threat models
is an effective approach to threat detection, another proven practice
is to dynamically adjust threat models and promptly create and test
new threat hypotheses, a.k.a., threat hunting.
The major enabler from static to dynamic threat discovery is
agility of threat hypotheses creation and verification. The dynamic
paradigm heavily involves human for opaque knowledge and rea-
soning, which does not prohibit threat hunters from specifying new
feature domains, programming automatic learning algorithms, and
obtaining insight from the agilely created automatic detection mod-
ules. Note that no existing approach is fully autonomous: human
knowledge for detection is i) embedded in the machine learning
algorithm designs, and ii) employed to define learning domains —
classification/clustering features or feature domains.
9.1 Static Threat Model Approaches
A large body of effective approaches have been developed with
fixed threat models, which can be incorporated into threat intelli-
gence computing as either security knowledge labels (e.g., anomaly
scores of processes and sensitivity scores of files) or knowledge in
reasoning algorithms (e.g., UDFs discussed in Section 2.2 and 2.3):
• Application of human-defined knowledge [3, 7, 30, 55, 87]
• Modeling trojan/ransomware behaviors [6, 41, 46, 89]
• Modeling botnet behaviors [5, 28, 37, 62, 97]
• Modeling malicious download behaviors [36, 45, 46, 84]
• Modeling malicious browser extension behaviors [40]
• Modeling malware behaviors [4, 18, 44, 51, 60, 86]
• Modeling malicious graph communities [39, 70, 91, 97]
• Modeling permitted behaviors [17, 24, 25, 29, 82, 88]
• Knowledge discovery on graphs [71, 81, 94]
• Attack causality tracking and inference [42, 47, 54, 85]
• Anomaly detection [16, 20, 23, 50, 58, 59, 61, 78, 80, 92]
Anomaly detection is a general threat model for identifying
deviations from the training environment [10, 79]. It is useful but
limited by training data quality (Section 5), manually specified
feature domains, and the misalignment of anomalous and malicious
alerts; and it does not replace other threat models. Though not
existing yet, new anomaly detection algorithms are awaited to be
developed in native Turing-complete graph languages (Section 8).
9 RELATED WORK
Threat discovery is the procedure of acquiring security knowledge
from potential sources and applying it in the monitored environ-
ment to discover the computation steps resulting from attack cam-
paigns. The security knowledge can be manually summarized and
programmed into detection systems such as intrusion detection ex-
pert systems [14]. Some knowledge can also be mined by algorithms
9.2 Dynamic Threat Model Approaches
Approaches with dynamic threat models have been introduced to
deal with rapid threat variation/evolution and the creation/evalua-
tion of new threat models in a prompt manner.
Existing threat hunting practices fulfill this need with a mash-up
solution — importing security and non-security data of all kinds
into a SIEM [31, 34] and employing SOC analysts for connecting the
Session 9D: VulnDet 1CCS’18, October 15-19, 2018, Toronto, ON, Canada1894main () {
g = malloc ()
*g = 1
foo (g)
}
foo (x) {
*x ++
foo (x)
}
(a) network topology
(b) a computation graph
(a) sample code
(b) a computation graph
Figure 13: Example: CG at network level (link layer).
Figure 14: Example: CG at process level (stack and heap).
dots with the human languages/concepts as the universal interface.
The procedure is aided by static threat model approaches for well-
modeled tasks, such as call chain traversal [9, 54] or knowledge
standardization for retrieval and sharing [35, 52, 68, 83, 95].
Performing threat hunting through graph computations estab-
lishes new programmability requirements beyond existing graph
programming platforms [12, 65] (discussed in Section 2). Automa-
tion based on existing threat hunting practices [8, 13, 27, 32, 33,
43, 66, 67], graph-based forensics [53, 63, 90], and temporal graph
retrieval development [56, 93, 99] inspired the design of τ-calculus.
10 CONCLUSION
This paper introduces threat intelligence computing as a method-
ology for agile threat hypotheses composition and validation re-
garding dynamic threat models. By reshaping threat discovery into
a graph computation problem, it eliminates heterogeneous data
representation in different modules and provides an interactive
programming environment for rapid automated task development
and opaque human knowledge codification. We demonstrate the
utility, practicality, and potential of the methodology by present-
ing the design, implementation, and evaluation of τ-calculus — a
domain-specific graph computation platform designed for threat
intelligence computing. Lastly, the paper sheds light on new chal-
lenges and opens further opportunities for future research and
development in the realm of threat intelligence computing.
A COMPUTATION GRAPH AT DIFFERENT
GRANULARITIES
Enterprises and organizations inspect computations at multiple
levels for threat discovery. CG describes computations at a selected
monitoring level, such as network, host, or process level. Given a
monitoring level, e.g., network, the activities within an entity, e.g.,
process communications within a host, are usually out of the moni-
toring scope and not expressed in CG. Finer-grained computation
information is either expressed in a lower-level CG, e.g., CG at the
host level, or embedded into the CG as labels, e.g., provenance la-
bels (Section 2.1). We describe CG examples at network and process
levels in addition to the host-level CG (Figure 1):
(1) CG at network level (Figure 13): the metadata of link layer
communications of a small network is logged for threat
intelligence computing. lb1 is a provenance label linking
four events among enσ 2, enσ 3, enσ 4. lb1 helps identify the
causal chain between enσ 3 and enσ 4 avoiding impossible
paths. Attack steps such as port scans and cross-host lateral
movements can be identified and reasoned on this CG.
(2) CG at process level (Figure 14): activities within a process
are monitored via dynamic program analysis. Entities are
memory addresses of code and data; events are instructions
(e.g., call) or syscalls (e.g., mmap). The infinity of Θ supports
the representation of recursive calls, e.g., instances of foo()
are described as enf oo, en′
, · · · . Software exploit activi-
ties such as return-to-libc and return-oriented programming
(ROP) [76] can be captured and inspected on this CG.
f oo
ACKNOWLEDGMENTS
The authors would like to thank their DARPA teammates Dr. R.
Sekar, Dr. Venkat Venkatakrishnan, and Dr. Yan Chen for collabo-
rative detection and analytics. The authors thank all monitoring
teams in the DARPA program for providing provenance data on
a wide variety of systems. The authors thank the red team in the
DARPA program for their effort in developing stealthy attacks and
the infrastructure team for their responsive support. The authors
would also like to thank the anonymous reviewers for their valuable
comments and helpful suggestions.
This project was sponsored by the Air Force Research Laboratory
(AFRL) and the Defense Advanced Research Agency (DARPA) under
the award number FA8650-15-C-7561. The views, opinions, and/or
findings contained in this article are those of the authors and should
not be interpreted as representing the official views or policies of
the Department of Defense or the U.S. Government.
REFERENCES
[1] Luca Aceto and Andy Gordon. 2005. Algebraic Process Calculi: The First Twenty
Five Years and Beyond. BRICS publications, Bertinoro, Forli, Italy.
[2] Adam Bates, Dave Tian, Kevin R B Butler, and Thomas Moyer. 2015. Trustworthy
Whole-System Provenance for the Linux Kernel. In Proceedings of USENIX Security
Symposium. ACM, Washington, DC, USA, 319–334.
[3] Mick Bauer. 2006. Paranoid Penguin: An Introduction to Novell AppArmor. Linux
Journal 2006, 148 (Aug 2006), 13.
[4] Konstantin Berlin, David Slater, and Joshua Saxe. 2015. Malicious Behavior
Detection Using Windows Audit Logs. In Proceedings of the 8th ACM Workshop
on Artificial Intelligence and Security (AISec ’15). ACM, Denver, Colorado, USA,
35–44.
[5] Leyla Bilge, Davide Balzarotti, William Robertson, Engin Kirda, and Christopher
Kruegel. 2012. Disclosure: Detecting Botnet Command and Control Servers
σ1σ2σ3σ4enσ1enσ2enσ3Timeenσ4lb1lb1: provenance labellb1lb1lb1enfoo’enfooenmainengTimeenmalloclb1: call, lb2: mmaplb1lb1lb1lb2Session 9D: VulnDet 1CCS’18, October 15-19, 2018, Toronto, ON, Canada1895Through Large-scale NetFlow Analysis. In Proceedings of the 28th Annual Com-
puter Security Applications Conference (ACSAC) (ACSAC ’12). ACM, Orlando,
Florida, USA, 129–138.
[6] Kevin Borders and Atul Prakash. 2004. Web Tap: Detecting Covert Web Traffic.
In Proceedings of the 11th ACM Conference on Computer and Communications
Security (CCS ’04). ACM, Washington, DC, USA, 110–120.
[7] Sven Bugiel, Lucas Davi, Alexandra Dmitrienko, Thomas Fischer, Ahmad-Reza
Sadeghi, and Bhargava Shastry. 2012. Towards Taming Privilege-Escalation
Attacks on Android. In Proceedings of the 20th Network and Distributed System
Security Symposium (NDSS). The Internet Society, San Diego, California, USA.
[8] Ahmet Salih Buyukkayhan, Alina Oprea, Zhou Li, and William Robertson. 2017.
Lens on the endpoint: Hunting for malicious software through endpoint data anal-
ysis. In International Symposium on Research in Attacks, Intrusions, and Defenses
(RAID). Springer International Publishing, Atlanta, USA, 73–97.
[9] Carbon Black. 2018. Cb Response | Incident Response & Threat Hunting | Carbon
Black. Retrieved August 10, 2018 from https://www.carbonblack.com/products/
cb-response/
[10] Varun Chandola, Arindam Banerjee, and Vipin Kumar. 2009. Anomaly Detection:
A Survey. ACM Comput. Surv. 41, 3 (July 2009), 15:1–15:58.
[11] Chen Chen, Cindy X. Lin, Matt Fredrikson, Mihai Christodorescu, Xifeng Yan, and
Jiawei Han. 2009. Mining Graph Patterns Efficiently via Randomized Summaries.
Proc. VLDB Endow. 2, 1 (Aug 2009), 742–753.
from http://titan.thinkaurelius.com/
[12] DataStax. 2018. Titan: Distributed Graph Database. Retrieved August 10, 2018
[13] Hervé Debar and Andreas Wespi. 2001. Aggregation and correlation of intrusion-
detection alerts. In Proceedings of the 4th International Symposium on Recent
Advances in Intrusion Detection (RAID). Springer International Publishing, Davis,
CA, USA, 85–103.
[14] Dorothy E. Denning. 1987. An Intrusion-Detection Model. IEEE Transactions on
Software Engineering 13, 2 (February 1987), 222–232.
[15] Sean Dillon. 2017. DoublePulsar Initial SMB Backdoor Ring 0 Shellcode Analy-
sis. Retrieved August 10, 2018 from https://zerosum0x0.blogspot.com/2017/04/
doublepulsar-initial-smb-backdoor-ring.html
[16] Min Du, Feifei Li, Guineng Zheng, and Vivek Srikumar. 2017. DeepLog: Anomaly
Detection and Diagnosis from System Logs through Deep Learning. In Proceedings
of the 2017 ACM Conference on Computer and communications security (CCS). ACM,
Dallas, Texas, USA, 1285–1298.
[17] H.H. Feng, J.T. Giffin, Yong Huang, S. Jha, Wenke Lee, and B.P. Miller. 2004.
Formalizing sensitivity in static analysis for intrusion detection. In Proceedings of
the 2004 IEEE Symposium on Security and Privacy. IEEE Press, Oakland, California,
USA, 194–208.
[18] Yu Feng, Osbert Bastani, Ruben Martins, Isil Dillig, and Saswat Anand. 2017. Au-
tomated Synthesis of Semantic Malware Signatures using Maximum Satisfiability.
In Proceedings of the Network and Distributed System Security Symposium (NDSS).
The Internet Society, San Diego, California, USA.
[19] Stephen Fewer. 2013. Reflective DLL injection library. Retrieved August 10, 2018
from https://github.com/stephenfewer/ReflectiveDLLInjection
[21] Thomas Fox-Brewster. 2017.
[20] Stephanie Forrest, Steven A Hofmeyr, Anil Somayaji, and Thomas A Longstaff.
1996. A sense of self for Unix processes. In Proceedings of the 1996 IEEE Symposium
on Security and Privacy. IEEE Press, Oakland, California, USA, 120–128.
An NSA Cyber Weapon Might Be Be-