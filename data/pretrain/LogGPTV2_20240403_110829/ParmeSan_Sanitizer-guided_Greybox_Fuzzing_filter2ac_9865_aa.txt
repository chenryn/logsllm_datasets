title:ParmeSan: Sanitizer-guided Greybox Fuzzing
author:Sebastian &quot;Osterlund and
Kaveh Razavi and
Herbert Bos and
Cristiano Giuffrida
ParmeSan: Sanitizer-guided Greybox Fuzzing
Sebastian Österlund, Kaveh Razavi, Herbert Bos, and Cristiano Giuffrida, 
Vrije Universiteit Amsterdam
https://www.usenix.org/conference/usenixsecurity20/presentation/osterlund
This paper is included in the Proceedings of the 29th USENIX Security Symposium.August 12–14, 2020978-1-939133-17-5Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.ParmeSan: Sanitizer-guided Greybox Fuzzing
Sebastian Österlund
Vrije Universiteit
Amsterdam
Kaveh Razavi
Vrije Universiteit
Amsterdam
Herbert Bos
Vrije Universiteit
Amsterdam
Cristiano Giuffrida
Vrije Universiteit
Amsterdam
Abstract
One of the key questions when fuzzing is where to look for
vulnerabilities. Coverage-guided fuzzers indiscriminately
optimize for covering as much code as possible given that
bug coverage often correlates with code coverage. Since
code coverage overapproximates bug coverage,
this ap-
proach is less than ideal and may lead to non-trivial time-
to-exposure (TTE) of bugs. Directed fuzzers try to address
this problem by directing the fuzzer to a basic block with a
potential vulnerability. This approach can greatly reduce the
TTE for a speciﬁc bug, but such special-purpose fuzzers can
then greatly underapproximate overall bug coverage.
In this paper, we present sanitizer-guided fuzzing, a new
design point in this space that speciﬁcally optimizes for bug
coverage. For this purpose, we make the key observation that
while the instrumentation performed by existing software
sanitizers are regularly used for detecting fuzzer-induced er-
ror conditions, they can further serve as a generic and effec-
tive mechanism to identify interesting basic blocks for guid-
ing fuzzers. We present the design and implementation of
ParmeSan, a new sanitizer-guided fuzzer that builds on this
observation. We show that ParmeSan greatly reduces the
TTE of real-world bugs, and ﬁnds bugs 37% faster than ex-
isting state-of-the-art coverage-based fuzzers (Angora) and
288% faster than directed fuzzers (AFLGo), while still cov-
ering the same set of bugs.
1 Introduction
Fuzzing is a common technique for automatically discov-
ering bugs in programs. In ﬁnding bugs, many fuzzers try
to cover as much code as possible in a given period of
time [9, 36, 47]. The main intuition is that code coverage is
strongly correlated with bug coverage. Unfortunately, code
coverage is a huge overapproximation of bug coverage which
means that a large amount of fuzzing time is spent covering
many uninteresting code paths in the hope of getting lucky
with a few that have bugs. Recent directed fuzzers [4, 8] try
to address this problem by steering the program towards lo-
cations that are more likely to be affected by bugs [20, 23]
(e.g., newly written or patched code, and API boundaries),
but as a result, they underapproximate overall bug coverage.
We make a key observation that it is possible to detect
many bugs at runtime using knowledge from compiler san-
itizers—error detection frameworks that insert checks for a
wide range of possible bugs (e.g., out-of-bounds accesses or
integer overﬂows) in the target program. Existing fuzzers
often use sanitizers mainly to improve bug detection and
triaging [38]. Our intuition is that we can leverage them
even more by improving our approximation of bug cover-
age in a target program. By applying directed fuzzing to
actively guide the fuzzing process towards triggering san-
itizer checks, we can trigger the same bugs as coverage-
guided fuzzers while requiring less code coverage, result-
ing in a lower time-to-exposure (TTE) of bugs. Moreover,
since compilers such as LLVM [25] ship with a number
of sanitizers with different detection capabilities, we can
steer the fuzzer either towards speciﬁc classes of bugs and
behavior or general classes of errors, simply by selecting
the appropriate sanitizers. For instance, TySan [14] checks
can guide fuzzing towards very speciﬁc bugs (e.g., type
confusion)—mimicking directed fuzzing but with implic-
itly speciﬁed targets—while ASan’s [37] pervasive checks
can guide fuzzing towards more general classes of memory
errors—mimicking coverage-guided fuzzing.
In this paper, we develop this insight to build ParmeSan,
the ﬁrst sanitizer-guided fuzzer. ParmeSan relies on off-the-
shelf sanitizer checks to automatically maximize bug cover-
age for the target class of bugs. This allows ParmeSan to
ﬁnd bugs such as memory errors more efﬁciently and with
lower TTE than existing solutions. Like coverage-guided
fuzzers, ParmeSan does not limit itself to speciﬁc APIs or ar-
eas of the code, but rather aims to ﬁnd these bugs, wherever
they are. Unlike coverage-guided fuzzers, however, it does
not do so by blindly covering all basic blocks in the pro-
gram. Instead, directing the exploration to execution paths
that matter—having the greatest chance of triggering bugs in
USENIX Association
29th USENIX Security Symposium    2289
the shortest time.
To design and implement ParmeSan, we address a num-
ber of challenges. First, we need a way to automatically ex-
tract interesting targets from a given sanitizer. ParmeSan ad-
dresses this challenge by comparing a sanitizer-instrumented
version of a program against the baseline to locate the sani-
tizer checks in a blackbox fashion and using pruning heuris-
tics to weed out uninteresting checks (less likely to contain
bugs). Second, we need a way to automatically construct a
precise (interprocedural) control-ﬂow graph (CFG) to direct
fuzzing to the targets. Static CFG construction approaches
are imprecise by nature [4] and, while sufﬁcient for exist-
ing special-purpose direct fuzzers [4, 8], are unsuitable to
reach the many checks placed by sanitizers all over the pro-
gram. ParmeSan addresses this challenge by using an ef-
ﬁcient and precise dynamically constructed CFG. Finally,
we need a way to design a fuzzer on top of these building
blocks. ParmeSan addresses this challenge by using a two-
stage directed fuzzing strategy, where the fuzzer interleaves
two stages (fuzzing for CFG construction with fuzzing for
the target points) and exploits synergies between the two.
For example, since data-ﬂow analysis (DFA) is required for
the ﬁrst CFG construction stage, we use the available DFA
information to also speed up the second bug-ﬁnding stage.
DFA-based fuzzing not only helps ﬁnd new code, similar to
state-of-the-art coverage-guided fuzzers [9, 36], but can also
efﬁciently ﬂip sanitizer checks and trigger bugs.
In this paper we present the following contributions:
(cid:15) We demonstrate a generic way of ﬁnding interesting
fuzzing targets by relying on existing compiler sanitizer
passes.
(cid:15) We demonstrate a dynamic approach to build a precise
control-ﬂow graph used to steer the input towards our
targets.
(cid:15) We implement ParmeSan,
the ﬁrst sanitizer-guided
fuzzer using a two-stage directed fuzzing strategy to ef-
ﬁciently reach all the interesting targets.
(cid:15) We evaluate ParmeSan, showing that our approach ﬁnds
the same bugs as state-of-the-art coverage-guided and
directed fuzzers in less time.
To foster further research, our ParmeSan prototype is
open source and available at https://github.com/vusec/
parmesan .
2 Background
2.1 Fuzzing strategy
In its most naive form blackbox fuzzing randomly generates
inputs, hoping to trigger bugs (through crashes or other er-
ror conditions). The beneﬁt of blackbox fuzzing is that it is
easily compatible with any program.
On the other side of the spectrum we have whitebox
fuzzing [6,21], using heavyweight analysis, such as symbolic
execution to generate inputs that triggers bugs, rather than
blindly testing a large number of inputs. In practice, white-
box fuzzing suffers from scalability or compatibility issues
(e.g., no support for symbolic execution in libraries/system
calls) in real-world programs.
To date,
the most scalable and practical approach to
fuzzing has been greybox fuzzing, which provides a mid-
dle ground between blackbox and whitebox fuzzing. By
using the same scalable approach as blackbox fuzzing, but
with lightweight heuristics to better mutate the input, grey-
box techniques yield scalable and effective fuzzing in prac-
tice [5, 7, 17, 30].
The best known coverage-guided greybox fuzzer is Amer-
ican Fuzzy Lop (AFL) [47], which uses execution tracing
information to mutate the input. Some fuzzers, such as
Angora [9] and VUzzer [36], rely on dynamic data-ﬂow
analysis (DFA) to quickly generate inputs that trigger new
branches in the program, with the goal of increasing code
coverage. While coverage-guided fuzzing might be a good
overall strategy, ﬁnding deep bugs might take a long time
with this strategy. Directed fuzzers try to overcome this lim-
itation by steering the fuzzing towards certain points in the
target program.
2.2 Directed fuzzing
Directed fuzzing has been applied to steering fuzzing to-
wards possible vulnerable locations in programs [7, 13, 18,
19, 41, 45]. The intuition is that by directing fuzzing to-
wards certain interesting points in the program, the fuzzer
can ﬁnd speciﬁc bugs faster than coverage-guided fuzzers.
Traditional directed fuzzing solutions make use of symbolic
execution, which, as mentioned earlier, suffers from scala-
bility and compatibility limitations.
AFLGo [4] introduces the notion of Directed Greybox
Fuzzing (DGF), which brings the scalability of greybox
fuzzing to directed fuzzing. There are two main problems
with DGFs. The ﬁrst problem is ﬁnding interesting targets.
One possibility is to use specialized static analysis tools to
ﬁnd possible dangerous points in programs [13, 16]. These
tools, however, are often speciﬁc to the bugs and program-
ming languages used. Other approaches use auxiliary meta-
data to gather interesting targets. AFLGo, for example, sug-
gests directing fuzzing towards changes made in the appli-
cation code (based on git commit logs). While an interest-
ing heuristic for incremental fuzzing, it does not answer the
question when fuzzing an application for the ﬁrst time or in
scenarios without a well-structured commit log. The sec-
ond problem is distance calculation to the interesting targets
to guide the DGF. Static analysis might yield a sub-optimal
view of the program. More concretely, the (interprocedural)
CFG is either an overapproximation [8] or an underapproxi-
2290    29th USENIX Security Symposium
USENIX Association
mation [4] of the real one, leading to suboptimal fuzzing.
2.3 Target selection with sanitizers
Modern compilers, such as GCC and Clang+LLVM ship
with a number of so-called sanitizers, that employ runtime
checks to detect possible bugs that cannot always be found
through static analysis. Sanitizers have been successfully
used for ﬁnding bugs [42] and have been used to improve
the bug-ﬁnding ability of fuzzers [38]. Typically these are
mainly deployed during testing, as the overhead can be sig-
niﬁcant.
The sanitizer typically instruments the target program,
adding a number of checks for vulnerabilities such as buffer
overﬂows or use-after-free bugs (see Listing 1 for an exam-
ple of the instrumentation). If a violation occurs, the sanitizer
typically reports the error and aborts the program. ParmeSan
shows that sanitizers are useful not only to enhance a fuzzer’s
bug-ﬁnding capabilities, but also to improve the efﬁciency of
the fuzzing strategy to reduce the time-to-exposure (TTE) of
bugs.
2.4 CFG construction
Directed fuzzers take the distance to the targets into account
when selecting seeds to mutate. For example, AFLGo [4]
and HawkEye [8] use lightweight static instrumentation to
calculate the distance of a certain seed input to the speciﬁed
targets. This instrumentation relies on a static analysis phase
that determines the distance for each basic block to the se-
lected targets.
Many real-world applications, however, rely on indirect
calls for function handlers. A prime example are (web)
servers, where a number of different handlers are registered
based on the server conﬁguration.
AFLgo [4] follows the former strategy, underapproximat-
ing the real CFG. Hawkeye [8] follows the latter strategy,
overapproximating the real CFG. For this purpose, Hawkeye
uses points-to analysis to generate a CFG for indirect calls.
Context-sensitive and ﬂow-sensitive analysis is too expen-
sive to scale to large programs. While complete, context-
insensitive analysis causes an indirect call to have many out-
going edges, possibly yielding execution paths that are not
possible for a given input. For example, if a conﬁguration
ﬁle determines the function handler, the call may in prac-
tice only have one valid target site. We propose a dynamic
CFG construction approach augmented with dynamic data-
ﬂow analysis (DFA) to address this problem.
3 Overview
Figure 1 presents a high-level overview of the ParmeSan
sanitizer-guided fuzzing pipeline, with the different com-
ponents and their interactions. There are three main com-
ponents: the target acquisition, the dynamic CFG and the
fuzzer components. In this section, we brieﬂy present a high-
level overview of each component and defer their design de-
tails to the following sections.
3.1 Target acquisition
The ﬁrst component of our pipeline, target acquisition, col-
lects a number of interesting targets that we want our fuzzer
to reach. The set of targets is generated by the instrumen-
tation operated by the given sanitizer on the given program.
We use a simple static analysis strategy to compare the in-
strumented version of the program with the baseline and au-
tomatically locate the instrumentations placed by the san-
itizer all over the program. Next, target acquisition uses
pruning heuristics to weed out uninteresting instrumenta-
tions (e.g., “hot” paths less likely to contain bugs [44]) and
derive a smaller set of interesting targets for efﬁcient fuzzing.
Section 4 details our target acquisition design.
3.2 Dynamic CFG
The second component of our pipeline, dynamic CFG, main-
tains a precise, input-aware CFG abstraction suitable for
“many-target directed fuzzing” during the execution of the
target program. We add edges to our CFG as we observe
them during the execution, and rely on DFA [1] to track de-
pendencies between the input and the CFG. As a result the
dynamic CFG component can track input-dependent CFG
changes and provide feedback to input mutation on which
input bytes may affect the CFG for a given input. Section 5
details our dynamic CFG design.
3.3 Fuzzer
The ﬁnal component of our pipeline, the ParmeSan fuzzer,
takes an instrumented binary, the set of targets, an initial
distance calculation, and a set of seeds as input. Our fuzzing
strategy starts with input seeds to get an initial set of exe-
cuted basic blocks and the conditions covered by these ba-
sic blocks. It then tries to steer the execution towards tar-
gets from the target acquisition component using the pre-
cise distance information that is provided by the dynamic
CFG component. At each trial, the ParmeSan fuzzer priori-
tizes the solving of that condition from the list of the visited
conditions that results in the best distance to the target basic
blocks.
Since we already need DFA for CFG construction, we
can also use it to solve branch constraints.
In ParmeSan,
this intuition is used not just to ﬁnd new code to reach the
targets efﬁciently—similar to DFA-based coverage-guided
fuzzers [9, 36]—but also to quickly ﬂip the reached target
sanitizer checks and trigger bugs. The output of the fuzzer
USENIX Association
29th USENIX Security Symposium    2291
Figure 1: An overview of the ParmeSan fuzzing pipeline. The target acquisition step automatically obtains fuzzing targets.
These targets are then fed to the ParmeSan fuzzer, which directs the inputs towards the targets by using the continuously
updated dynamic CFG. The inputs to the pipeline consist of a target program, a sanitizer, and seed inputs.
consists of generated error inputs. Section 5 details our
fuzzing design.
4 Target acquisition
Our target acquisition component relies on off-the-shelf
compiler sanitizers to ﬁnd interesting targets to reach. The
key idea is to direct the fuzzer towards triggering error con-
ditions in the sanitizer and ﬁnd real-world bugs in a directed
fashion. By implementing the analysis in a generic way, we
can use any existing or future sanitizer to collect possible
interesting targets. Since our approach is entirely sanitizer-
agnostic, we can easily retarget our fuzzing pipeline to a dif-
ferent class (or classes) of bugs depending on the sanitizer
used.
4.1 Finding instrumented points
Compiler frameworks, such as LLVM [25], transform the
frontend code (written in languages such as C, Rust, etc.)
to a machine-agnostic intermediate representation (IR). The
analysis and transformation passes, such as sanitizers, gen-
erally work at the IR level. Suppose we take an appli-
cation and transform it into LLVM IR. Existing sanitizer
passes can then instrument the IR to add sanitization checks
and enable runtime bug detection. For example, the snip-
pet in Listing 1 has been augmented with UBSan [2] in-
strumentation to detect pointer overﬂows.
The UBSan
pass adds a conditional branch before loading a pointer (at
%6 ). The added branch calls the error handling function
if the added con-
__ubsan_handle_pointer_overflow()
ditional is met (i.e., an overﬂow occurs).
Sanitizers instrument programs in two different ways.
Some instrumentations simply update internal data struc-
tures (e.g., shadow memory), while other instrumentations
;... Non-sanitized
%4 = load i8*, i8** %2 , align 8
%5 = getelementptr inbounds i8, i8* %4 , i64 1
%6 = load i8, i8* %5 , align 1
;..
+
; ... Sanitized with UBSan
%4 = load i8*, i8** %2 , align 8
%5 = getelementptr inbounds i8, i8* %4 , i64 1
%6 = ptrtoint i8* %4 to i64
%7 = add i64 %6 ,
%8 = icmp uge i64 %7 , %6
%9 = icmp ult i64 %7 , %6
%10 = select i1 true, i1 %8 , i1 %9
br i1 %10 , label %12 , label %11
; :11:
call void @__ubsan_handle_pointer_overflow
br label %12
; preds = %1
(...)
; ...
%17 = load i8, i8* %5 , align 1
Listing 1: LLVM IR without and with UBSan instrumenta-
tion to check for pointer overﬂows
are used when the sanitizers detect the actual bug using a
branch condition that either interacts with the internal sani-
tizer data structures (e.g., ASan’s out of bound access detec-
tion) or the immediate state of the program (e.g., Listing 1).
Our goal is to direct fuzzing towards points where the sani-
tizer updates its internal data structure (i.e., interesting code
paths) and the conditional branches that are introduced by
the sanitizers which if solved mean that we have discovered
a bug. We discuss how ParmeSan uses this intuition for efﬁ-
2292    29th USENIX Security Symposium
USENIX Association
TargetacquisitionParmeSanFuzzerSanitizerProgram  GraphextractorInstrumented BinariesInstrumentorStaticCFGTargetsSeed Inputs Dynamic CFG ErrorInputs cient fuzzing in Section 6.
Since there exist numerous different sanitizers, with new
ones being added frequently, we want a sanitizer-agnostic
analysis method to collect these targets. We do this by im-
plementing a blackbox analysis of the IR difference (diff ) of
the target program compiled with and without the sanitizer.
To include the instrumented basic blocks that do not include
a conditional, we add all the predecessor basic blocks instru-
mented by the sanitizer. For instrumented basic blocks that
include a conditional, we include both the instrumented ba-
sic block and the basic block with a taken conditional (i.e.,
often the sanitizer’s bug checking function). We found this a
simple strategy to yield a generic and effective way to obtain
targets that is compatible with all the existing (and future)
LLVM sanitizers.
4.2 Sanitizer effectiveness
To verify that our approach of using sanitization instrumen-
tation as interesting targets is sound, we instrumented a num-
ber of applications, and conﬁrmed that the targeted sanitizer
checks detect the actual bugs. In Table 1, we tested the ef-
fectiveness of three different sanitizers against a number of
known vulnerabilities.
AddressSanitizer (ASan) [37] is able to discover buffer
overﬂows and use-after-free bugs. UndeﬁnedBehaviorSan-
itizer (UBSan) [2] is able to detect undeﬁned behavior, such
as using misaligned or null pointers, integer overﬂows, etc.
The Type Sanitizer (TySan) [14] is able to detect type con-
fusion when accessing C/C++ objects with a pointer of the
wrong type.
Table 1 shows whether the sanitizer catches the bug and
the number of basic blocks of the program not contained
in a path to instrumented basic blocks. For example, if a
deep basic block is considered a target (i.e., contains a target
branch), all its predecessors have to be covered. However,
non-target basic blocks that are not on a path to a target do
not need to be covered, as our analysis estimates there are
no bugs in those blocks. By calculating the number of ba-
sic blocks that we can disregard (non-target) in this way, we
get a metric estimating how many basic blocks are irrelevant
for triggering sanitizer errors, and are thus not necessary to
be covered when fuzzing. This metric gives us an estimate
of how sanitizer-guided fuzzing compares against traditional
coverage-oriented fuzzing for different sanitizers.
In many cases, a signiﬁcant part of the code coverage can
be disregarded. For example in libxml2 using TySan, we
can disregard 80% of the basic blocks and still ﬁnd the bug.
However, as seen in the pruning metric in Table 1, there is
a major variance in how much of the application different
sanitizers instrument. Some sanitizers, such as UBSan and
TySan, are specialized in what they instrument, yielding a
small set of targets. Other sanitizers, such as ASan, instru-
ment so many basic blocks that, if we were to consider every
Sanitizer (% non-target)
ASan
UBSan
TySan
Prog
Bug
Type
LAVA-M BO ✓ (5%) 7
base64
7
LAVA-M BO ✓ (9%) 7
who
7
LAVA-M BO ✓ (15%) 7
uniq
7
md5sum LAVA-M BO ✓ (12%) 7
7
OpenSSL 2014-0160 BO ✓ (8%) 7