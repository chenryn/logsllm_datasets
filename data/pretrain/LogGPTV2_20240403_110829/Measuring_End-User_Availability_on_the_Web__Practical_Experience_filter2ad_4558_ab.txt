### Availability and Timing Analysis

**Availability vs. Waiting Time:**
The graph in Figure 2, titled "Availability versus Time," illustrates the expected availability as a function of the waiting time. The graph remains relatively flat until the availability exceeds 99%, at which point the required waiting time increases exponentially.

**Threshold for Time:**
Similar to size, we established a threshold for time, categorizing sites that exceed this threshold as unavailable. Such errors can indicate network delays or an overloaded server. By ignoring these slow-but-successful errors, we obtained the results presented in the third row of Table 1. In the pie chart, timing issues are divided into "medium" (ten seconds) and "severe" (thirty seconds). A ten-second delay is well above the normal return time for all studied sites. Beyond thirty seconds, even significant changes in the threshold have minimal impact on the final value.

**Error Frequency:**
After client errors, one-time network errors (medium and severe) were the most frequent types of errors.

### The Effect of Retry

**User Behavior:**
When faced with an unavailable website, users often retry. We checked the persistence of each error by re-accessing the site within the next hour. This allowed us to differentiate between one-time failures and persistent problems. This analysis is particularly useful for sites with long delays, as it helps identify the source of the delay. If a single site consistently experiences delays relative to others, it suggests issues near the server. By measuring the availability after retries, we can more accurately assess the total user experience. The final row of Table 1 includes only sites that experienced persistent, unexplained downtime.

**Table 2: The Value of Retry**

| Error Type | All | Retailer | Search Directory |
|------------|-----|----------|------------------|
| Client     | 0.2667 | 0.2706 | 0.2647 |
| Medium Network | 0.8621 | 0.8704 | 0.9286 |
| Severe Network | 0.8318 | 0.7895 | 0.9111 |
| Server     | 0.4210 | 0.9231 | 0.7857 |
| Corporate  | 0.3125 | 1.00 | 1.00 |
| Total      | 1.00 | 1.00 | 0.6889 |

**Figure 2: Time Grows Quickly at High Availability**
This graph plots expected availability against the length of the wait. Users can determine how long to wait for a certain level of availability (e.g., 99.9%) or the availability found at a given wait time.

### Persistent Non-Local Failures

**Error Distribution:**
After removing local and one-time errors, a few severe errors remain. The distribution of these errors is domain-dependent. For example, the directory site was more prone to persistent network problems, suggesting issues with connections to international sites. The retailer site, on the other hand, was more prone to corporate errors due to the complexity of handling user information. The retailer also experienced persistent server issues and occasional global outages.

**Table 3: Persistent Errors by Type**

| Error Type | Retailer | Search Directory |
|------------|----------|------------------|
| Medium Persistent Network | 7 | 3 |
| Severe Persistent Network | 2 | 0 |
| Server Persistent Errors | 3 | 0 |
| Corporate Persistent Errors | 11 | 1 |

### Analysis

**Retry Period:**
Our one-hour retry period is unrealistically long. In practice, the likelihood of retry, number of retries, and the time before stopping are influenced by domain- and user-specific factors. Users may retry immediately to overcome short-term issues but may stop if the problem persists. Economists note that shoppers in physical stores, when unable to make a purchase, often find another source or skip the purchase entirely. E-commerce sites, especially those with easy competition, are no different. However, some sites with unique services, high-value transactions, or loyal users may see extended retries.

**Factors Influencing Retry:**
- **Uniqueness:** Unique services or goods increase the likelihood of retry.
- **Importance:** The value and cost of the transaction to the user influence retry behavior.
- **Loyalty:** User loyalty extends the retry period.
- **Transience:** Sites with highly transient content are less likely to have long-term retries.

### Conclusion

**Experiment Results:**
This experiment aimed to model the user experience and was successful. We found a raw availability of about 93%, with 81% of errors due to local issues. Removing local errors increased availability to 99.9%. Retry reduced local errors by 27% and non-local errors by 83%. Local availability has the largest impact on user experience, and retry is effective in reducing non-local errors.

**Future Work:**
- Continue the experiment to refine availability numbers.
- Distribute the experiment to distant sites to better assess error sources.
- Develop better experiments to measure the efficacy of retry, both short-term and long-term.

**Acknowledgements:**
We thank the students from Mills College and UC Berkeley, members of the ROC research group, referees, and the National Science Foundation for their support.

### References

1. “Building an Internet-centric Monitoring Infrastructure”, ASP News, September 2001.
2. A. Brown and D. A. Patterson, “To Err is Human”, Proceedings of the First Workshop on Evaluating and Architecting System dependabilitY (EASY '01), Göteborg, Sweden, July 2001.
3. A. Brown and D. A. Patterson, “Embracing Failure: A Case for Recovery-Oriented Computing (ROC)”, 2001 High Performance Transaction Processing Symposium, Asilomar, CA, October 2001.
4. R. H. Frank and B. S. Bernanke, Principles of Economics, McGraw-Hill/Irwin, New York, 2001, pp. 92-3.
5. “Topaz: The Complete Solution for Application Management”, Mercury-Interactive, December 2001.
6. “Netcraft: What’s that Site Running?”, Netcraft, December 2001.
7. “Quality of Experience: measuring true end-to-end Web performance”, Porvio, December 2001.