### Potentially Unwanted Programs (PUPs) and Malware Analysis

Out of the 177 applications flagged as malicious by more than one VirusTotal antivirus tool, we identified at least one such application on 183 unique devices: 122 devices controlled by workers and 61 devices used by regular users. Additionally, 70 unique mobile app identifiers, which received at least one review from our participants, were flagged by at least one VirusTotal engine. Of these, 64 apps were reviewed by workers, and 9 apps were reviewed by regular users.

Given that a single VirusTotal flag may be a false positive, we further analyzed the most malicious malware samples (those flagged by more than 7 VirusTotal engines) in both worker and regular user devices. The 7-flag threshold exceeds the value of 4 identified in [64], and most of these samples were later removed from Google Play. Figure 12 illustrates that malicious samples are more likely to appear in multiple worker devices compared to regular user devices.

### Anti-Virus (AV) App Usage

To determine if participants had sufficient security concerns to install anti-virus (AV) apps, we identified 250 AV apps from Google Play by searching the app category on the website. We then compared these apps against the installed apps on each participant's device that sent at least one snapshot. Only 19 devices had 15 different AV apps installed: 8 worker devices, 7 regular user devices, and 4 unknown (either Google testing our infrastructure or participants who bypassed our invitation code).

### Participant Feedback

We asked participants about their concerns regarding:
1. Installing malware apps on their devices.
2. Having anti-virus software installed.
3. Privacy of their device data, including contacts, login information, pictures, videos, text messages, and location.

Two workers were not concerned about malware or privacy leaks and did not have AV apps installed. One worker stated, "I am confident in my phone's ability to prevent any mishap." Five workers reported being concerned about malware; four claimed to use AV apps. One worker mentioned, "I find a lot of apps like this, which contain a lot of viruses," but also stated he was not concerned about privacy leaks because, "I have 5 devices, 3 mobile devices and 2 computers. I use 2 out of the 3 mobiles for app testing and review, and 1 mobile for personal work."

### Summary of Findings

Worker-controlled devices generally have a lower instantaneous malware infection rate compared to regular devices. However, the malware installed on worker devices tends to be flagged by more antivirus engines. Workers exhibited mixed attitudes toward privacy and installing malware and AV apps, suggesting potential vulnerabilities and concerns among workers in keeping apps installed for longer periods.

## Fake Review Detection

In this section, we investigate whether the app usage data collected by RacketStore (§ 5) can identify apps installed for promotional purposes, thereby detecting fake app installs and reviews. We first introduce app usage features (§ 7.1) and then evaluate their ability to train supervised models to distinguish between promotion-related and personal app use (§ 7.2).

### 7.1 App Usage Features

We extracted the following features for each app installed on participant devices:
1. The number of accounts registered on the device that reviewed the app before, during, and after RacketStore was installed.
2. The install-to-review time (§ 6.3).
3. Inter-review times, i.e., statistics over the time difference between consecutive reviews posted for the app from accounts registered on the device.
4. Whether the app was opened on multiple days.
5. The number of snapshots per day when the app was the on-screen app.
6. The number of snapshots collected per day from the device.
7. Inner retention, i.e., the duration over which the app was installed on the device (while RacketStore was installed), and whether the app was installed before RacketStore and still installed when RacketStore was uninstalled.
8. The number of normal and dangerous permissions requested.
9. The number of permissions requested by the app that have been granted and denied by the user.
10. The number of flags raised by VirusTotal AV tools.
11. The number of times the app was installed and uninstalled while RacketStore was installed.

### 7.2 App Classification

We used these features and the datasets from § 5 to train an app classifier that determines if an app has been installed for promotional or personal use.

#### Training and Validation Datasets

We used data from 178 worker and 88 regular devices that provided at least two days of fast and slow snapshots. We randomly set aside 20% (i.e., 38) of the worker-controlled devices and 42% (i.e., 37) of the regular devices for validation. We labeled an app as suspicious if:
1. It was advertised by workers for promotion on the Facebook groups we infiltrated (§ 2).
2. It was installed on at least five worker devices.
3. It was not installed on any regular devices.

We labeled an app as non-suspicious or regular if:
1. It was not installed on any worker-controlled device.
2. It was installed on at least one regular device.
3. It received at least 15,000 reviews.

We identified 1,041 suspicious apps among those installed on the 38 worker-controlled devices and 474 non-suspicious apps among those installed on the 37 training regular devices. This resulted in a train-and-validate app usage dataset consisting of 2,994 suspicious instances and 345 non-suspicious instances.

#### Classifier Performance

We evaluated the performance of supervised learning algorithms trained with the features introduced in § 7.1 on the train-and-validate app usage dataset using repeated 10-fold cross-validation (n=5). Table 1 shows the precision, recall, and F1-measure of tested algorithms. Extreme Gradient Boosting (XGB) outperformed the other algorithms, achieving an F1-measure of 99.72%. K-Nearest Neighbors (KNN) achieved the best performance for K = 5.

Figure 13 shows the top 10 most important features for classifying app usage, measured by the mean decrease in Gini. The number of accounts that have reviewed the app from the device and the average time between install and review were the most important.

### 8 ASO Device Detection

We investigated whether the device usage data collected by RacketStore (§ 5) can be used to identify devices controlled by app search optimization (ASO) workers.

#### 8.1 Device Usage Features

We introduced the following features to model device usage:
1. The number of pre-installed and user-installed apps.
2. App suspiciousness, i.e., the number of apps flagged by the app classifier of § 7 over the total number of apps installed on the device.
3. The number of stopped apps (§ 6.3).
4. The average number of apps installed and uninstalled per day.
5. The number of device-registered Gmail and non-Gmail accounts, and the number of distinct account types.
6. The number of apps installed on the device that have been reviewed from accounts registered on the device.
7. The total number of apps reviewed by accounts registered on the device.

For most features, we considered both user-installed and pre-installed apps, as even the use of pre-installed apps like the app store, email, maps, and browser apps can distinguish regular devices from those controlled by workers.

#### 8.2 Device Classification

We evaluated the ability of these features to train classifiers that differentiate between devices controlled by workers and regular users. We used the 178 worker devices and 88 regular devices that provided snapshots over at least 2 days. We prioritized precision, as low precision could lead to incorrect actions against many regular devices [90].

Table 2 compares the performance of five supervised learning algorithms trained with the device usage features introduced in § 8.1. K-Nearest Neighbors (KNN) achieved the best performance for K = 5. To balance the worker and regular user device classes, we oversampled the minority class using the SMOTE algorithm [33]. We used 10-fold cross-validation over the data from the 178 worker and 88 regular devices. Extreme Gradient Boosting (XGB) outperformed the other algorithms, achieving an F1-measure of 95.29% and AUC of 0.9455. The precision was 96.81%, and the false positive rate was 1.41%.

When we undersampled the majority class, XGB’s recall decreased to 92.97% with an F-1 value of 95.18% and AUC of 0.9074. Without any sampling strategy, the F-1 increased to 96.86%, at the expense of the AUC (0.9083).

Figure 14 shows the top 10 most important features in classifying devices as worker-controlled or regular, as measured by the mean decrease in Gini. Four features stood out, confirming their ability to detect worker-controlled devices:
1. The total number of apps reviewed from accounts registered on the device.
2. The percent of installed apps that were detected to have been used suspiciously by the classifier of § 7.
3. The number of stopped apps on the device.
4. The average number of reviews posted from an account registered on the device.

Figure 15 shows the scatterplot of app suspiciousness versus the total number of reviewed apps for each of the 178 worker-controlled devices. Out of these 178 devices, 123 devices exhibited organic-indicative behaviors, with at least one of the installed apps being predicted to be suspicious.

### Privacy-Preserving Classifiers

Our classifiers require access to sensitive data from user devices, which general users may be reluctant to share. To address this, we propose a privacy-preserving approach where our pre-trained models (§ 7 and § 8) execute on the user device on locally computed features to detect ASO activities [4, 81]. This approach will only report ASO suspicious activities but no private app and device-usage information. A red flag can be raised if the user uninstalls or blocks the pre-installed client (e.g., the Play Store app) and posts suspicious reviews from accounts registered on such a non-consenting device.

### Worker Strategy Evolution

ASO workers may attempt to develop strategies to avoid detection by our classifiers. However, our engagement-based features exploit the lack of genuine interest of workers in promoted apps and introduce a tradeoff between detectability and operational costs and exposure to malware. These features include the number of accounts registered on the device, the interval between app install and first review, and user interaction with the app (opened, daily app usage) (see § 7.1).

Workers may attempt to manipulate these features using existing software. However, they will still need to keep promoted apps installed for longer intervals, wait more before reviewing them, and interact more with them. When promoted apps are malicious and workers use personal devices, this may increase their risk of malware exposure.