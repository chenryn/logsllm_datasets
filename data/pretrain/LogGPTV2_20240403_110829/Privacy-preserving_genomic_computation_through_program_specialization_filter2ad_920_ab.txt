on a program P by specialize(P ). Such operations happen to fol-
lowing program elements:
• Assignment. An assignment a = exp is changed to a = reduce(exp)
if the expression exp involves symbols, where reduce() is a reduc-
tion function.
• Branching. A branching statement is in the form “if exp then
P , else P (cid:2)
”, where exp is the branch condition, and P and
P (cid:2)
are the statements to be executed on the two branches. Such
a statement is transformed to a set of statements that ﬁrst checks
reduce(exp): if the outcome is either true or false, the program
proceeds as normal; otherwise, the following statement is exported
to a residue program: “if reduce(exp) then specialize(P ),
else specialize(P (cid:2))”. Also exported are the state of the pro-
gram prior to the branching, including the values of the variables to
be used in P and P (cid:2)
.
To evaluate specialize() on both P and P (cid:2)
online, we need to
set a checkpoint prior to the branching statement and roll back after
exploring one branch. This can incur signiﬁcant performance over-
head. An alternative is to symbolically execute both branches of-
ﬂine to acquire their symbolic expressions, and replace the symbols
in the expressions with concrete values online. Further complicat-
ing the specialization efforts is the fact that a branch can include
other tainted branching statements, which makes the cost of evalu-
ation high. A simple solution can be exporting all statements of a
branch if it contains other tainted branches.
• Loop. A loop is residualized if its exit condition is symbolic and
cannot be evaluated after proper reduction. When this happens, we
can choose to specialize the body of the loop if it does not involve
tainted branches.
340• Function. When part of input parameters to a function’s are sym-
bols, the function needs to be specialized using the techniques de-
scribed above. When this happens, a symbolic expression can be
returned. If a function is repeatedly called with different parame-
ters, we can choose to residualize it without specialization.
• Tainted address. Programs may read or write a memory loca-
tion whose address depends on the values of sensitive nucleotides.
For example, the index of an array can be determined by unknown
symbols, and a pointer in a C program can be tainted by sensitive in-
puts. When a tainted address is encountered, we can simply export
all the statements that directly or transitively rely on the address to
the residue program.
Another treatment of a tainted address is to explore all possible
values it can take. A nucleotide can only assume four values: A, T,
C and G. Therefore, a read from the address involving one symbol
gives four possible outcomes at most, which can be represented by
a new symbol. Writing to the address is more complicated, as we
need to create four threads, each handling one possible version of
data. This can be problematic when multiple symbols are present,
which causes the number of the threads to increase exponentially.
Further study of this problem is left as our future research.
Reduction. Key to specialization is reduction [35] that serves to
simplify symbolic expressions. A typical reduction technique is
constant folding that combines all the constants in an expression.
This is achieved by taking advantage of the properties of a compu-
tation, such as commutativity, associativity and distributivity. For
example, 10 + a + 6 can be reduced to a + 16. In some cases, an
expression can be simpliﬁed by unfolding a symbol into the expres-
sion it represents. As an example, consider an expression a+b+10
with b = a + 6. Unfolding b reduces it to 2a + 16.
A Boolean expression can be evaluated even when it contains
symbols. For example, we know that a branch condition a + 10 ≥
a+6 is true even when the value of a is unknown, as the symbols on
both sides of the inequality cancel each other and only the concrete
value 4 ≥ 0 is left. This approach can be applied to the compar-
ison between two linear expressions that contain the same set of
symbols and each of them has the same coefﬁcient. More gener-
ally, combining multiple occurrences of the same symbols when
possible can help simplify an expression.
In our research, we design another reduction technique that eval-
uates a Boolean expression using the value ranges of the symbols
it contains. Speciﬁcally, our approach identiﬁes the maximal and
minimal values a symbol can take and then propagate this range to a
symbolic expression. Whenever a comparison between two expres-
sions happens and the ranges of these expressions do not overlap,
its Boolean outcome can be determined. For example, consider ex-
pressions exp= a + 9 and exp’= b + 6. Given the ranges of
a and b are from 0 to 1, we know that exp is between 9 and 10,
while exp’ falls in the range from 6 to 7. As a result, the Boolean
expression exp≥exp’ is true. This technique is particularly ef-
fective on dynamic programming based genome computing, which
we discuss in Section 2.3.
Symbol unfolding. As described above, unfolding a symbol can
help simplify that expression. This, however, does not work al-
ways. Consider the following example: d = min(b + c1, b +
c2, b + c3) with b = min(a1, a2, a3).
If b is unfolded in the
expression of d, we need to compare 9 values to get d. In con-
trast, if we ﬁrst get b and then compute d, only 6 comparisons are
needed. In our research, we propose a new reduction rule that un-
folds a symbol only when an expression does not contain new sym-
In the above example, we can unfold b and ci if ci=1,2,3
bols.
only contains a1, a2, a3 or constants: suppose c1 = a1 + 5,
c2 = a1 + 6 and c3 = a1 + 8, such an unfolding gives us d =
min(2a1 +5, a1 +a2 +5, a1 +a3 +5), which needs only 3 compar-
isons to compute. Application of this rule to a dynamic program-
ming algorithm can reduce it to a much simpler residue program
that is also dynamic programming, as elaborated in Section 2.3.
2.3 Analysis
Dynamic programming [14] is an optimization technique widely
used in bioinformatics, particularly for solving fundamental genome
computing problems such as sequence alignment, structural align-
ment and RNA secondary structure prediction. These problems
typically involve two genome sequences, α[1··· n] and β[1··· m],
and are modeled over an n + 1 by m + 1 matrix D. The objective
is to ﬁnd an optimal path from (0, 0) to (n, m) that maximizes or
minimizes the scores accumulated from those incurred by individ-
ual moves from (i, j) to (i+1, j) or (i, j +1) or (i+1, j +1). Such
a modeling can also be generalized to a multidimensional graph for
the problem such as multiple sequence alignment [26], where the
goal is to ﬁnd an optimal path in the graph. The DPAs for solving
these problems are usually in the following form:
D(i, j) = min(D(i − 1, j) + s1(i, j),
D(i, j − 1) + s2(i, j),
D(i − 1, j − 1) + s3(i, j), C)
(2)
where D(i, j) is the score for the optimal path from (0, 0) to (i, j),
s1(i, j), s2(i, j) and s3(i, j) are the functions that compute a score
given α[i] and β[j], and C is a constant. This form of optimiza-
tion describes many important bioinformatics algorithms, includ-
ing the famous Needleman-Wunsch [56] and the most widely-used
BLAST 2 [66]. Note that throughout this paper we focus on an
improved version of the DPA ﬁrst introduced by Gotoh [30], which
reduces the complexity of the DPAs like Needleman-Wunsch and
Smith-Waterman algorithms from O(mn2) to O(mn), and thus
are commonly used in today’s genome research.
Let ρ be the ratio of sensitive nucleotides on β, and β[xt=1···ρm]
be these nucleotides. The effectiveness of our specialization tech-
niques on a DPA is described by Theorem 1.
Figure 3: Proof illustration.
THEOREM 1. The query q(β[x1],··· , β[xρm]) generated by
specializing a DPA described in Equation 2 is still a DPA. The com-
putational, spatial and communication complexities for answering
the query are at most O(ρmn2).
Figure 3 illustrates the general idea of the proof, whose full con-
tent is presented in a longer version of the paper [68], due to space
limit. Informally, every unknown nucleotide β[xt] corresponds to
one column xt in the (n + 1) × (m + 1) matrix D. Consider two
neighboring columns xt−1 and xt. A path from (0, 0) to (i, xt), a
cell in xt, must go through one of the cells (0, xt−1),··· , (i, xt−1)
341in xt−1. We call a path from (0, 0) a connection path for (l, xt−1)
(0 ≤ l ≤ i) and (i, xt) if the path passes both cells and does
not pass any other cells in column xt−1 or xt between these two
cells. The optimal connection path (the one with the minimal score)
is composed of the optimal path from (0, 0) to (l, xt−1), and the
path segment between (l, xt−1) and (i, xt) with the lowest score.
Its score can be represented as a linear expression with the sym-
bol D(l, xt−1) and the symbol related to xt, and simpliﬁed using
the fact that all nucleotides between the two columns are known.
Particularly, an expression that compares the scores of two differ-
ent connection paths can often be reduced: for example, we know
that a path with a score D(l, xt−1) + C1 + s1(i, xt) is better than
the one with D(l, xt−1) + C2 + s1(i, xt) if the constant C1 is
smaller than C2. The optimal path to (i, xt) is either one of the
i+1 optimal connection paths from (0, xt−1),··· , (i, xt−1) or the
path passing (i − 1, xt). Seeking the optimal path from (0, 0) to
(n, m), we need to ﬁrst ﬁnd values for column xρm, which depends
on column xρm−1 and so on. This forms a DPA (See Equation 3
in [68]). Computing D(i, xt) requires comparing the scores of i+2
paths (i + 1 optimal connection paths and an additional path from
(i − 1, xt)). Therefore, the complexity for computing unknown
column xt is O(n2). Since there are totally ρm unknown columns,
the complexity for answering the query becomes O(ρmn2).
Discussion. The complexities of an unspecialized DPA is O(mn)
for both computation and space. More often than not, the optimal
path with at least m elements needs to be delivered from the DP
to the DC if the whole computation task is delegated to the DP. On
the other hand, most genome computing tasks involve a short α,
on the order of 102, and a long β, from 106 (a chromosome) to
109 (the whole genome sequence of a human). Therefore, given
ρ < 10−4, the query program generated by our approach can be
hundreds of times more efﬁcient than the original program in terms
of computation and space. Our approach incurs extra communica-
tion overheads: the complexity of the communication from the DC
to the DP can be O(ρmn2). This weakness, however, is compen-
sated by the efﬁciency of the communication from the DP to the
DC, which is only O(ρm). This is because to empower the DC to
ﬁgure out the whole optimal path, the DP only needs to disclose
the intersections between the optimal path and unknown columns
x1,··· , xρm, and for every intersection (i, xt), the one of the i + 2
paths that contributes to the value of the cell.
Actually, the theoretic result turns out to be too pessimistic, be-
cause our analysis does not consider the reduction achievable using
the value ranges of expressions: due to the scarcity of unknown
nucleotides, the differences between the constants in the expres-
sions for two optimal connection paths can easily overwhelm the
deviations caused by an unknown symbol; as a result, optimal con-
nection paths from different cells in xt−1 can often be compared
and many of them can be removed from the reduced expression of
D(i, xt). In our experiment, we observed that a query was at least
thousand times more efﬁcient than the original program, in terms
of computation, space and communication (Section 4).
DPA extensions. DPAs used in genome computing can be ex-
tended to improve their performance. Two prominent examples
are Divide-and-Conquer, which is optimized for space efﬁciency,
and BLAST, which is designed for high performance. The Divide-
and-Conquer algorithm (DCA) [54] ﬁrst runs a DPA to compute
the ﬁrst half of matrix D column by column until j, the column in
the middle of the matrix, and then compute the second half back-
wards from column n to j. As a result, the intersection between the
optimal path and column j is identiﬁed. Denote the intersection
by (i, j). The same process happens to the matrix between (0, 0)
and (i, j) and the one between (i, j) and (n, m) to ﬁnd other mem-
bers on the optimal path, which further divides these matrices into
smaller ones. As such, the algorithm can determine every member
on the path. Since computing a column only needs the information
in the prior column, DCA reduces the spatial complexity of a DPA
to O(m + n), at the cost of doubled computation overheads.
The DCA needs to run a DPA over the whole matrix once, which
makes the complexities of the query generated from specialization
stay at O(ρmn2). Apparently, this suggests that the query program
loses the edge in space efﬁciency. Again, such a theoretic result is
deceiving:
the query built upon real data is actually much more
efﬁcient, as observed in our research.
BLAST is a widely-used algorithm for fast searching.
It ﬁrst
searches for high scoring subsequence matchings between the se-
quences α and β by seeking words, a subsequence typically con-
taining 11 nucleotides, with scores above a threshold. Then, the
algorithm extends these words using a DPA to ﬁnd a locally opti-
mal alignment. Our specialization techniques generate queries for
extending words, which is much more efﬁcient than running the
whole algorithm on the DP. A problem is that the score of a word
is usually calculated using exact match. When a word matches a
sequence involving sensitive nucleotides, these nucleotides will be
exposed, which could cause a computation to fail. Fortunately, the
number of sensitive nucleotides in a given β is usually very small,
and as a result, the chance that a word in a short α matches a se-
quence involving such nucleotides is very low.
2.4 Query Auditing
Our framework adopted a simple security policy to control infor-
mation leaks from the outcomes of a computation. The policy spec-
iﬁes a threshold for a query, the maximal number of SNPs whose
values can be revealed. For each query, the DP ﬁrst runs a query
auditor to evaluate the amount of information that could be leaked
out by the answer: if it goes above the threshold, the DP refuses to
respond; otherwise, the query is allowed to be answered. The query
auditor can be as simple as a constraint solver: given a query and
its answer as a constraint, it attempts to determine whether the con-
straint can only be satisﬁed when some SNPs take unique values;
when this happens, these SNPs are deemed disclosed if the answer
is given to the DC. For example, consider a query q for an edit
distance, whose answer is 5; if the auditor ﬁnds that to satisfy the
constraint “q = 5”, a SNP must be ‘A’, it concludes that the SNP
will be disclosed by the answer. In Section 4, we demonstrate that
this simple technique actually worked on realistic computations.
The action of denying a query itself can leak information: at the
very least, an attacker knows that the answer to her query can be
used to determine at least t SNPs, where t is the threshold. How-
ever, by setting the threshold well below the number of SNPs in-
volved, we can make it difﬁcult for the attacker to ﬁnd out exactly
which t SNPs can be determined. In general, however, we do not
want to claim that this approach is a perfect solution. Instead, it is
just a component of our framework and can be replaced with other
existing technologies for query auditing [55, 40] and inference con-
trol [40, 55, 50, 51, 31, 24]. Study of these technologies’ efﬁcacy
under our framework is left as future research.
2.5 Secure Multi-party Computation
The DC’s sequence α may contain sensitive nucleotides that can-
not be revealed to the DP. When this happens, a query needs to be
answered without leaking out sensitive inputs from both α and β,
which can be achieved using secure multi-party computation [69,
29]. Direct application of SMC on α and β, however, can intro-
duce huge performance overheads, making the approach hard to
scale [34]. Our solution is to use nonsensitive data on both α and β
342. Over Q(cid:2)