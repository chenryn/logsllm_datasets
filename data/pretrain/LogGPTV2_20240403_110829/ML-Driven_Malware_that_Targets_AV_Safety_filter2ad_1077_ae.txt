### RoboTack: Evaluating the Safety Potential of Electric Vehicles with and without the Safety Hijacker

#### Introduction
This study examines the safety potential of electric vehicles (EVs) under attack, both with and without the use of a safety hijacker (SH). Our results indicate that the timing of the attack, as chosen by the SH, is critical for causing safety hazards with a high probability of success.

#### Results
- **Attack Success Rates:**
  - With the SH, the number of successful attacks—defined as forced emergency brakings and crashes—was significantly higher. Specifically, the number of successful attacks was up to 5.1× and 7.2× higher, respectively, compared to random timing.
  - For pedestrian trajectory hijacking, the success rates were 14.8× and 24× higher, respectively.

- **Safety Potential Analysis:**
  - Figure 6 shows the boxplot of the minimum safety potential of the EV from the start time of the attack to the end of the driving scenario.
  - An "accident" is defined as any driving scenario where the safety potential falls below 4 meters.
  - Forced emergency braking is determined by reading values directly from the Apollo ADS.
  - "R w/o SH" denotes RoboTack without the SH, while "R" represents RoboTack with the SH.

- **Specific Attack Vectors:**
  - **DS-1-Disappear:** RoboTack caused 7.2× more crashes (31.7% vs. 4.4%) and 4.6× more emergency braking (53.5% vs. 11.6%).
  - **DS-1-Move_Out:** RoboTack caused 6.2× more crashes (17.3% vs. 2.8%) and 5.1× more emergency braking (37.3% vs. 7.3%).
  - **DS-2-Disappear:** RoboTack caused 7.9× more crashes (82.6% vs. 10.4%) and 2.4× more emergency braking (94.4% vs. 39.4%).
  - **DS-2-Move_Out:** RoboTack caused 24× more crashes (84.1% vs. 3.5%) and 14.8× more emergency braking (97.8% vs. 6.6%).
  - **DS-3-Move_In and DS-4-Move_In:** RoboTack caused 1.9× and 1.6× more emergency braking, respectively, but no crashes were observed due to the absence of real obstacles.

- **Summary:**
  - In 1702 experiments (851 "R w/o SH", 851 "R"), RoboTack (R) resulted in 640 emergency brakings (EBs) (75.2%) over 851 "R" experiments, compared to only 230 EBs (27.0%) for "R w/o SH".
  - RoboTack (R) resulted in 299 crashes (52.6%) over 568 "R" experiments excluding DS-3 and DS-4 with Move_In attacks, while "R w/o SH" resulted in only 29 crashes (5.1%).

#### Evading Attack Detection
- The trajectory hijacker perturbs the estimated trajectory for \( K_4 \) time-steps and maintains the faked trajectory for the next \( K - K_4 \) time-steps.
- Different scenarios and attack vectors require varying \( K_4 \) values. For instance, Move_Out and Move_In scenarios required smaller \( K_4 \) values than the Disappear attack vector.
- Changing a pedestrian's location required fewer \( K_4 \) time-steps than changing a vehicle's location.
- Figures 7(a) and 7(b) characterize \( K_4 \) for different scenarios.

#### Characterizing Safety Hijacker Performance
- The neural network (NN) used in the SH predicts the safety potential after the attack with high accuracy.
- On average, the NN’s prediction error for the safety potential was within 5m and 1.5m for vehicles and pedestrians, respectively.
- Figure 8(a) shows the relationship between the probability of success and the NN prediction error, indicating that the success probability decreases as the prediction error increases.

#### Related Work
- **Security Attacks on Autonomous Vehicles (AVs):** AVs are vulnerable to hacking due to easy physical and software access, complex systems, and limited robust detection methods.
- **Gaining Access to AVs:** Hackers can exploit various vulnerabilities, including V2V and V2I communication channels, over-the-air updates, ECUs, infotainment systems, and CAN buses.
- **Adversarial Machine Learning and Sensor Attacks:** Previous studies have explored adversarial ML-based attacks, but none have specifically targeted evading detection or explicitly focused on vehicle safety.
- **RoboTack:** This is the first approach demonstrated on production ADS software with multiple sensors (GPS, IMU, cameras, LiDAR) to achieve both objectives by attacking only one sensor (the camera).

#### Conclusion and Future Work
- **Conclusion:** RoboTack highlights the need for more secure AV systems by demonstrating the efficiency of adversaries in targeting AV safety.
- **Future Work:** The design of countermeasures is a key area for future research. We are investigating dynamic and adaptive tuning of perception system parameters to mitigate adversarial attacks.

#### Acknowledgments
- This work was supported by the National Science Foundation (NSF) under Grant No. 15-35070 and CNS 18-16673.
- We thank our shepherd Kun Sun and other contributors for their valuable feedback and support.

#### References
- [References listed here]

---

This optimized version provides a clearer, more structured, and professional presentation of the original text.