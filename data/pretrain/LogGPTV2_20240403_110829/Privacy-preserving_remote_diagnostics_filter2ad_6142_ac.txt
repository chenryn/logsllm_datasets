model, i.e., under the assumption that participants faithfully follow
the protocol, but may attempt to learn extra information from the
protocol transcript.
(The proof is standard, and omitted to save
space.) Even if the User is malicious rather than semi-honest, he
cannot learn anything about the diagnostic program except the ﬁnal
diagnostic label, since the underlying oblivious transfer protocol is
secure against malicious choosers.
The protocol of Section 4.3 can be transformed, at a constant
cost, to achieve security in the malicious model. We only sketch
the transformation here due to lack of space. Both parties must
commit to their respective protocol inputs, including the Server’s
branching program and blinding values, and the User’s attribute
values. Each instance of oblivious transfer (OT) must be replaced
with an instance of committed oblivious transfer, during which the
parties prove in zero-knowledge that their inputs into OT are con-
sistent with their previous commitments. Similarly, each instance
of Yao’s protocol must be replaced with an instance of secure two-
party computation on committed inputs, during which the Server
proves in zero-knowledge that the offset integer comparison cir-
cuits have been formed correctly, and both parties prove that their
inputs are consistent with their commitments. The homomorphic
encryption scheme must be veriﬁable, i.e., it must enable the en-
cryptor to prove that the plaintext is consistent with a previous
commitment. Finally, the commitment scheme must enable efﬁ-
cient proofs of certain relationships between committed values.
The cryptographic tools which satisfy the above requirements,
i.e., (1) homomorphic, veriﬁable encryption scheme, (2) commit-
ment scheme, (3) committed oblivious transfer protocol, (4) secure
two-party computation protocol on committed inputs, and (5) efﬁ-
cient zero-knowledge proof systems for the required relationships
between protocol components can be found in [20].
Even security in the malicious model does not prevent a mali-
cious User from claiming that his attribute vector has changed and
repeatedly re-running the protocol on different committed inputs
in an attempt to learn the entire diagnostic program. To prevent
this, the Server can rate-limit the number of protocol invocations
with each User. This is easy to enforce by refusing to accept new
commitments from the User until a speciﬁed period expires.
4.5 Efﬁciency and comparison with generic
techniques
In the secure branching program created by Algorithm 1, each
of the decision nodes of the original program is replaced by a gar-
bled Yao circuit for comparing two (offset) (cid:3)-bit integers. Each
such circuit requires log (cid:3) gates, for a total of k · log (cid:3) gates (this
is a conservative estimate, since some of the nodes are classiﬁca-
tion nodes). Note that the size of the circuit is independent of the
number of the User’s attributes n. Algorithm 2 requires k · (cid:3) OT 1
2
oblivious transfers to transfer the wire keys corresponding to the
User’s (blinded) inputs into each of the k nodes.
An alternative to using our protocol from Section 4.3 is to use
generic techniques that enable secure computation of any two-party
functionality, represented either as a boolean circuit [23, 40] or a
binary decision diagram [14] (the latter may be a better choice for
branching diagnostic programs).
A na¨ıve way to implement the secure evaluation of binary
branching programs using generic techniques would be to have
the Server take his speciﬁc branching program, transform it into
an equivalent secure program using, say,
the standard garbled
circuit techniques (see Section 3.3), and have the User evaluate the
garbled circuit on his attribute vector.
This does not satisfy our security requirements. First of all, the
topology of the program is revealed to the User.
In generic se-
cure multi-party computation (SMC), it is usually assumed that the
function to be computed is known to both parties. Yao’s garbled
circuit technique works even if the circuit evaluator does not know
the truth tables associated with the individual gates, but it reveals
the topology of the circuit being evaluated. By contrast, our pro-
tocol only reveals the length of the evaluation path and the total
number of nodes; it leaks no other information about the rest of the
branching program. Even worse, with the na¨ıve approach the User
learns on which of his attributes the program was evaluated, thus
violating one of our core security requirements (see Section 4.2).
To ensure obliviousness of the User’s input selection, the SMC
functionality must be deﬁned so that it takes any branching program
of a given size (as opposed to the speciﬁc Server’s program) and
securely applies it to any attribute vector of a given length.
We have attempted to implement such a functionality using the
Fairplay compiler [24], which converts any two-party functional-
ity into an equivalent garbled circuit. Unfortunately, the Fairplay
compiler is memory-bound, and in our experiments it was unable
to compile functionalities that would allow us to apply branching
programs of realistic size to realistic attribute vectors. On a ma-
chine with 4 Gigabytes of RAM, the compiler runs out of memory
when attempting to compile the functionality that applies a 63-node
branching program to a 400-attribute vector.
Table 1 gives comparative measurements of online computation
and communication for a few sample conﬁgurations. Our experi-
mental setup, along with the detailed performance analysis of our
protocol, can be found in Section 6.
Some of the negative aspects of Fairplay, such as running out of
memory even on relatively small conﬁgurations, may be due to the
particular compiler implementation rather than the inherent ﬂaws
of the generic approach. Nevertheless, our protocol described in
Section 4.3 provides a superior solution for the speciﬁc task of se-
cure branching program evaluation.
4.6 Achieving complete privacy
The protocol of Section 4.3 reveals the total number of nodes in
the branching program and the length of the evaluation path corre-
sponding to the User’s attribute vector. This information appears
harmless in practice, but, if necessary, it can be hidden, provided
that there exist upper bounds B on the number of nodes and P on
the length of the longest evaluation path.
To hide the size of the branching program, the Server can create
B − k random ciphertexts (which will never be decrypted by the
User), and mix them randomly with the real encrypted nodes of the
. Semantic security of the encryption scheme
secure program T
used to encrypt individual nodes guarantees that the User cannot
tell the difference between an encryption of a real node that he did
not reach in his evaluation, and a random ciphertext of the same
size. When padded in this way, secure versions of all branching
programs will contain exactly B ciphertexts.
(cid:2)
To hide the length of evaluation paths, ﬁrst transform the branch-
ing program into a decision tree, so that each node has a ﬁxed depth.
Then transform it into a full tree of depth P by replacing classiﬁca-
tion nodes at depth p < P with full trees of depth (P − p + 1), in
which every leaf contains the original classiﬁcation. In the result-
ing tree, every evaluation path has length P .
5. REMOTE SOFTWARE DIAGNOSTICS
In this section, we give a brief introduction to the problem of re-
mote software fault diagnostics, and then use our protocol of Sec-
tion 4 to implement a privacy-preserving version of Clarify, a prac-
tical system for software fault diagnosis [17].
Microsoft error reporting is an example of a remote software di-
agnosis tool [28]. A Microsoft error report has two purposes. The
ﬁrst purpose is to gather extensive information about a software
failure to enable Microsoft engineers to ﬁx the software problem.
We emphasize that we do not focus on this problem, since there ex-
ist many standard techniques, both privacy-preserving and not, for
creating decision trees (e.g., see [17] and Section 2).
The second purpose is to improve the user’s experience by pro-
Server
User
Nodes Attrib.
100
100
1000
1000
15
63
15
63
Computation
67 vs. 2 sec
72 vs. 7 sec
605 vs. 2 sec
X vs. 7 sec
Communication
1,292 vs. 263 KB
1,799 vs. 1121 KB
11,388 vs. 263 KB
X vs. 1121 KB
Computation
76 vs. 3 sec
79 vs. 14 sec
706 vs. 4 sec
X vs. 12 sec
Communication
528 vs. 98 KB
528 vs. 351 KB
5,277 vs. 255 KB
X vs. 508 KB
Cursive - Fairplay, Bold - our protocol, X - failed to compile
Table 1: Comparison of protocols for the evaluation of branching programs
viding a message describing the user’s problem and how the user
can avoid the problem in the future. Our case study addresses the
second purpose, where a server provides feedback to the user about
the user’s problem. Windows Vista includes a prominent item on
the control panel called “Problem reports and solutions” [27] that
allows users to get the latest information about a particular software
problem from Microsoft’s web site. The Ubuntu Linux distribution
also contains new features to generate more information about soft-
ware failures to help users [39].
Microsoft’s privacy statement about the information it collects
for software problem diagnosis [26] acknowledges that problem re-
ports can compromise users’ privacy. Problem reports contain the
contents of memory for the program that failed, and this memory
“might include your name, part of a document you were working
on or data that you recently submitted to a website.” The policy
says that users concerned about the release of personal or conﬁden-
tial information should not send problem reports. Of course, users
who do not send problem reports cannot beneﬁt from remote fault
diagnostics. Corporate users in particular have expressed concern
that remote diagnostics could reveal their intellectual property [32].
Ubuntu’s documentation also acknowledges security and privacy
risks associated with data-rich fault reports.
The protocol presented in this paper enables the user to obtain a
support message in a privacy-preserving fashion. The user does not
reveal anything to the software manufacturer about his or her local
data, and the software manufacturer does not reveal to the user how
the user’s local data was mapped to a diagnostic message.
Privacy of diagnostic programs.
It may appear that the soft-
ware manufacturer should simply send the diagnostic program to
the user or, better yet, integrate it directly into the supported ap-
plication. Many software manufacturers, however, view their diag-
nostic programs as valuable intellectual property. They state this
explicitly in the legal documents that accompany the diagnostic
software [13] and sue competitors who obtain access to their di-
agnostic programs [33]. Updating widely deployed software with
new support messages and diagnostic tools is not always feasible,
either, since many users simply don’t install patches.
Moreover, diagnostic programs can reveal vulnerabilities in de-
ployed software. For example, a single message from Microsoft’s
Dr. Watson diagnostic tool was sufﬁcient to reveal to any user who
experienced a particular fault an exploitable buffer overﬂow [25]
(had the entire Dr. Watson diagnostic tree been shipped to every
Windows user instead of being evaluated on Microsoft’s servers,
even users who did not experience the fault could discover the
vulnerability by analyzing the diagnostic tree). In the diagnostic
trees produced by the Clarify toolkit for gzprintf, which is one
of our benchmarks, the inner nodes of the diagnostic tree directly
point to the function that contains a security vulnerability. With
a lively, semi-legal market in information about software vulnera-
bilities [37], software manufacturers have a strong disincentive to
completely reveal all known faults and bugs in their applications.
We emphasize that we do not promote “security by obscurity.”
Software manufacturers should patch the bugs and vulnerabilities
in their programs as soon as practicable. From a purely pragmatic
perspective, however, they should not be forced to choose between
not providing diagnostic support, or else revealing every internal
detail of their applications and diagnostic tools. In reality, when
faced with such a stark choice, many will decide to not provide
support at all, resulting in a poorer experience for the users who are
not willing to disclose their own local data.
Runtime data collection and fault diagnosis. Typically, the run-
time environment records some abstraction of the program’s behav-
ior. Different abstractions have different cost and accuracy trade-
offs (e.g., see [9, 17]). For instance, one abstraction counts how
many times each function in the program was called, another counts
function call sites that satisfy a certain predicate (e.g., equal to zero)
on the function’s return value, and so on.
For the purposes of this paper, we abstract from the details of the
program behavior “dumps” generated by the runtime environment,
and refer to individual data items simply as attributes. We assume
that the vector of attributes has a ﬁxed maximum size, which can
be quite large—for example, a vector of function callsite counters
may include dozens of thousands of attributes. Note that the online
computational complexity of the User’s algorithm in the protocol
of Section 4 does not depend on the number of attributes.
Diagnostic programs evaluate the data dump produced by the
runtime environment and diagnose the problem. In this paper, we
use diagnostic programs generated by the Clarify system [17]. We
emphasize that Clarify is a “black-box” diagnostic system, and thus
not simply an alternative to debugging. Commercial applications
are often distributed as packed binaries, compiled without symbols
and not accompanied by source code. Investigation of a fault in
such a binary by manual debugging is a laborious process, whereas
even an unsophisticated user can beneﬁt from fast diagnostics pro-
vided by systems like Clarify.
In general, the diagnostic program can be manually created by
human experts, or constructed automatically by training a machine
learning classiﬁer on previously labeled program behaviors (sup-
plied, for example, by beta testers who are not concerned about
privacy of their data). Clarify takes the latter approach.
If nec-
essary, standard methods for privacy-preserving decision tree con-
struction can be used to protect data suppliers’ privacy [1, 22]. The
number of users whose data are used in constructing the diagnostic
program is typically orders of magnitude lower than the number of
users who apply the resulting program to their data. Therefore, we
focus on privacy-preserving evaluation of diagnostic programs.
The diagnostic program usually has the form of a classiﬁcation
tree or a branching program. In each internal node, one of the at-
tributes is compared with some threshold value. Leaves contain di-
agnostic labels. For example, Figure 1 shows a diagnostic branch-
ing program created by Clarify using function counting for the mp3
player mpg321. The application itself does not give any consistent
error messages for any of these error cases. The model has four di-
agnostic labels, including normal execution (no error), ﬁle format
App.
gcc
latex
mpg321
nfs
iptables
Attributes Nodes
37
1,107
9
17
9
2,920
395
128
292
70
# Errs Accuracy
89.2%
85.1%
87.5%
93.3%
98.5%
5
81
4
5
5
Table 2: For each benchmark, we give the length of the at-
tribute vector, number of nodes in the diagnostic tree, number
of errors distinguished by the decision tree, and the tree’s clas-
siﬁcation accuracy.
Application
foxpro
(7 nodes, 224 attrs)
iptables
(9 nodes, 70 attrs)
mpg321
(9 nodes, 128 attrs)
nfs
(17 nodes, 292 attrs)
gzprintf
(23 nodes, 60 attrs)
gcc
(37 nodes, 2920 attrs)
latex
(1107 nodes, 395 attrs)
Server
User
Time
1s
Bytes
119 KB
Time
2s
2s
2s
2s
3s
5s
155 KB
155 KB
298 KB
506 KB
656 KB
2s
2s
4s
5s
7s
Bytes
78 KB
61 KB
71 KB
142 KB
133 KB
707 KB
113s
19,793 KB
189s
5,908 KB
Table 3: Privacy-preserving evaluation of Clarify diagnostic
programs: computation and communication costs.
while online time includes the calculations that depend on the in-
formation sent by the other party earlier in the protocol. Online
time is the more important metric, since it dictates how long the
two parties must maintain a connection. Ofﬂine calculations can be
performed during idle times when the CPU is in low demand.
We ﬁrst analyze the scaling behavior of the Server algorithm,
as presented in Figures 2 and 3. Here we see that the Server’s
computation and bandwidth requirements are independent of the
number of attributes, which is an attractive property in the software
diagnostic scenario where the attribute vector can be quite large and