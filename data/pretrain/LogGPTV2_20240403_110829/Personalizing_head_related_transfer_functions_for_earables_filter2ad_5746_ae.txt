[23, 24, 34, 35, 37, 39, 41, 43, 47, 56]. Most past works require a
mic array for sound AoA estimation [46, 48, 50]. [18, 30, 32] are
the closest to our work, where the authors attempted to estimate
sound AoA from artificially made robotic ears. Our problem is more
challenging because past authors can design the robot head and
ear entirely by themselves thus have full control and understand-
ing of the accurate robot HRTF. In our case, we need to find the
sound source AoA by extracting features from the not-so-accurate
estimated HRTF, which brings about unique challenges.
7 LIMITATIONS AND OPEN PROBLEMS
■ 3D HRTF: Our UNIQ prototype estimates the 2D HRTF for users.
This may be acceptable, given that human ears exhibit relatively
lower resolution in distinguishing elevation angles. Hence 2D may
suffice for many applications. However, if an application desires
3D HRTF, extending UNIQ is viable – the user would now need
to move the phone on a sphere around the head, and the motion
tracking equations need to be extended to 3D. If this increases the
tracking error, perhaps the phone camera can be utilized, enabling
a fusion between motion, acoustics, and computer vision. We leave
this to future work.
■ Integrating Room Multipath: As discussed earlier, UNIQ re-
moves environmental reverberations through a pre-processing step
in the time domain; this helps minimize the effect of room mul-
tipath on the estimated HRTF. However, rendering realistic 3D
audio, especially in an indoor environment, requires that the room
reverberations be embedded into the HRTF. Said differently, a real
immersive experience can only be achieved by filtering the ear-
phone sound with both the room impulse response (RIR) and the
HRTF. Estimating RIR at home is an interesting but separate re-
search question, outside the scope of this paper.
■ User Experience and Externalization: An estimated HRTF
is accurate when the user is unable to correctly identify whether
the sound she hears came from her earphone or an ambient loud-
speaker. When she mistakes an earphone-played sound to be com-
ing from the ambience, then the ideal goal of “externalization” is
achieved. Of course, testing for externalization requires high quality
earphone hardware and RIR integration. Moreover, optimization
methods may be needed through human feedback, since external-
ization is also a complex function of human perception [14]. This
paper shows that our estimated HRTFs are mathematically close to
true HRTFs, but more work is needed to attain externalization.
8 CONCLUSION
The gap between global and personalized HRTFs remains an open
problem. This paper ushers ideas from motion tracking and sensor
fusion to partly close this gap. We show that simple arm gestures
from users can offer valuable motion information, that in turn helps
in modeling the user’s unique HRTF parameters. As a side effect, we
find that earphones can better estimate the AoA of ambient sounds.
The results are promising and could underpin a range of immersive
applications that are gaining relevance for the post-COVID future.
ACKNOWLEDGMENTS
We sincerely thank our shepherd Prof. Fadel Adib, and anonymous
reviewers for their insightful comments and suggestions. We are
also grateful to NSF (award numbers: 1918531, 1910933, 1909568,
and 1719337), NIH (award number: 1R34DA050262-01), Google, and
Samsung for partially funding this research.
148
050100150200Far-field AoA Error,White Noise (Deg)00.51CDF UNIQ Global HRTF050100150200Far-field AoA Error,Music (Deg)00.51CDF UNIQ Global HRTF050100150200Far-field AoA Error,Speech (Deg)00.51CDF UNIQ Global HRTFWhite NoiseMusicSpeech00.51Accuracy UNIQ Global HRTFPersonalizing Head Related Transfer Functions for Earables
SIGCOMM ’21, August 23–27, 2021, Virtual Event, USA
REFERENCES
[1] 2015. The Sound Professionals.
Retrieved Jan 26, 2021 from https://www.
soundprofessionals.com/cgi-bin/gold/item/SP-TFB-2
[2] 2015. Wave Interactions and Interference.
Retrieved Jan 24, 2021 from
https://www.ck12.org/section/wave-interactions-and-interference-%3a%3aof%
3a%3a-waves-%3a%3aof%3a%3a-ck-12-physical-science-for-middle-school/
[3] 2017. Beyond Surround Sound: Audio Advances in VR. Retrieved Jan 24, 2021
from https://www.oculus.com/blog/beyond-surround-sound-audio-advances-
in-vr/
[4] 2017. Near-field 3D Audio Explained.
Retrieved Jun 11, 2021 from https:
//developer.oculus.com/blog/near-field-3d-audio-explained/
[5] 2018. Simulating Dynamic Soundscapes at Facebook Reality Labs. Retrieved Jan
26, 2021 from https://www.oculus.com/blog/simulating-dynamic-soundscapes-
at-facebook-reality-labs/
[6] 2019. Audio in mixed reality. Retrieved Jan 24, 2021 from https://docs.microsoft.
com/en-us/windows/mixed-reality/design/spatial-sound
[7] 2019. Mach1 will provide spatial audio for Bose’s AR platform. Retrieved Jan
24, 2021 from https://venturebeat.com/2019/12/18/mach1-will-provide-spatial-
audio-for-boses-ar-platform/
[8] 2020. Apple brings surround sound and Dolby Atmos to AirPods Pro.
Re-
trieved Jan 24, 2021 from https://thenextweb.com/plugged/2020/06/22/apple-
brings-surround-sound-and-dolby-atmos-to-airpods-pro/
[9] 2020. Diffraction. Retrieved Jan 24, 2021 from https://en.wikipedia.org/wiki/
Diffraction
[10] 2020. Inside Facebook Reality Labs Research: The Future of Audio. Retrieved Jan
24, 2021 from https://about.fb.com/news/2020/09/facebook-reality-labs-research-
future-of-audio/
[11] 2020. Xiaomi United States. Retrieved Jan 26, 2021 from https://www.mi.com/us/
[12] 2021. DIY HRTF measurement using an iPhone. Retrieved Jun 11, 2021 from
https://www.earfish.eu/sites/default/files/2018-01/DIY_earfish_iPhone_0.pdf
[13] 2021. Equal-loudness contour. Retrieved Jan 24, 2021 from https://en.wikipedia.
org/wiki/Equal-loudness_contour
[14] Ishwarya Ananthabhotla, Vamsi Krishna Ithapu, and W Owen Brimijoin. 2021.
A framework for designing head-related transfer function distance metrics that
capture localization perception. JASA Express Letters 1, 4 (2021), 044401.
[15] Jeffrey R Blum, Mathieu Bouchard, and Jeremy R Cooperstock. 2011. What’s
around me? Spatialized audio augmented reality for blind users with a smart-
phone. In International Conference on Mobile and Ubiquitous Systems: Computing,
Networking, and Services. Springer, 49–62.
[16] C Phillip Brown and Richard O Duda. 1997. An efficient HRTF model for 3-D
sound. In Proceedings of 1997 Workshop on Applications of Signal Processing to
Audio and Acoustics. IEEE, 4–pp.
[17] Thibaut Carpentier, Hélène Bahu, Markus Noisternig, and Olivier Warusfel. 2014.
Measurement of a head-related transfer function database with high spatial
resolution. In 7th Forum Acusticum (EAA).
[18] Jorge Dávila-Chacón, Jindong Liu, and Stefan Wermter. 2018. Enhanced robot
speech recognition using biomimetic binaural sound source localization. IEEE
transactions on neural networks and learning systems 30, 1 (2018), 138–150.
[19] Hossein Falaki, Ratul Mahajan, Srikanth Kandula, Dimitrios Lymberopoulos,
Ramesh Govindan, and Deborah Estrin. 2010. Diversity in smartphone usage.
In Proceedings of the 8th international conference on Mobile systems, applications,
and services. 179–194.
[20] Yang Gao, Wei Wang, Vir V Phoha, Wei Sun, and Zhanpeng Jin. 2019. EarEcho:
Using Ear Canal Echo for Wearable Authentication. Proceedings of the ACM on
Interactive, Mobile, Wearable and Ubiquitous Technologies 3, 3 (2019), 1–24.
[21] William G Gardner. 2005. Spatial audio reproduction: Towards individualized
binaural sound. In Frontiers of Engineering:: Reports on Leading-Edge Engineering
from the 2004 NAE Symposium on Frontiers of Engineering, Vol. 34. 113.
[22] William G Gardner and Keith D Martin. 1995. HRTF measurements of a KEMAR.
The Journal of the Acoustical Society of America 97, 6 (1995), 3907–3908.
[23] Reza Ghaffarivardavagh, Sayed Saad Afzal, Osvy Rodriguez, and Fadel Adib.
2020. Ultra-wideband underwater backscatter via piezoelectric metamaterials. In
Proceedings of the Annual conference of the ACM Special Interest Group on Data
Communication on the applications, technologies, architectures, and protocols for
computer communication. 722–734.
[24] Yasaman Ghasempour, Chia-Yi Yeh, Rabi Shrestha, Yasith Amarasinghe, Daniel
Mittleman, and Edward W Knightly. 2020. LeakyTrack: non-coherent single-
antenna nodal and environmental mobility tracking with a leaky-wave antenna.
In Proceedings of the 18th Conference on Embedded Networked Sensor Systems.
56–68.
[25] Michael M Goodwin and Jean-Marc Jot. 2007. Binaural 3-D audio rendering
based on spatial audio scene coding. In Audio Engineering Society Convention 123.
Audio Engineering Society.
[26] Michael M Goodwin, Jean-Marc Jot, and Mark Dolson. 2013. Spatial audio
analysis and synthesis for binaural reproduction and format conversion. US
Patent 8,374,365.
[27] Corentin Guezenoc and Renaud Seguier. 2020. HRTF individualization: A survey.
arXiv preprint arXiv:2003.06183 (2020).
[28] Nail A Gumerov, Ramani Duraiswami, and Dmitry N Zotkin. 2007. Fast multipole
accelerated boundary elements for numerical computation of the head related
transfer function. In 2007 IEEE International Conference on Acoustics, Speech and
Signal Processing-ICASSP’07, Vol. 1. IEEE, I–165.
[29] Hongmei Hu, Lin Zhou, Hao Ma, and Zhenyang Wu. 2008. HRTF personalization
based on artificial neural network in individual virtual auditory space. Applied
Acoustics 69, 2 (2008), 163–172.
[30] Sungmok Hwang, Youngjin Park, and Younsik Park. 2007. Sound direction estima-
tion using artificial ear. In 2007 International Conference on Control, Automation
and Systems. IEEE, 1906–1910.
[31] C Jackman, M Zampino, D Cadge, R Dravida, V Katiyar, and J Lewis. 2009. Esti-
mating acoustic performance of a cell phone speaker using Abaqus. In SIMULIA
Customer Conference. 14–21.
[32] Cheol-Taek Kim, Tae-Yong Choi, ByongSuk Choi, and Ju-Jang Lee. 2008. Robust
estimation of sound direction for robot interface. In 2008 IEEE International
Conference on Robotics and Automation. IEEE, 3475–3480.
[33] Lin Li and Qinghua Huang. 2013. HRTF personalization modeling based on RBF
neural network. In 2013 IEEE International Conference on Acoustics, Speech and
Signal Processing. IEEE, 3707–3710.
[34] Zhihong Luo, Qiping Zhang, Yunfei Ma, Manish Singh, and Fadel Adib. 2019. 3D
backscatter localization for fine-grained robotics. In 16th {USENIX} Symposium
on Networked Systems Design and Implementation ({NSDI} 19). 765–782.
[35] Wenguang Mao, Wei Sun, Mei Wang, and Lili Qiu. 2020. DeepRange: Acous-
tic Ranging via Deep Learning. Proceedings of the ACM on Interactive, Mobile,
Wearable and Ubiquitous Technologies 4, 4 (2020), 1–23.
[36] Alok Meshram, Ravish Mehra, Hongsheng Yang, Enrique Dunn, Jan-Michael
Franm, and Dinesh Manocha. 2014. P-HRTF: Efficient personalized HRTF com-
putation for high-fidelity spatial sound. In 2014 IEEE International Symposium on
Mixed and Augmented Reality (ISMAR). IEEE, 53–61.
[37] Yan Michalevsky, Aaron Schulman, Gunaa Arumugam Veerapandian, Dan Boneh,
and Gabi Nakibly. 2015. Powerspy: Location tracking using mobile device power
analysis. In 24th {USENIX} Security Symposium ({USENIX} Security 15). 785–800.
[38] Philip M Morse and Pearl J Rubenstein. 1938. The diffraction of waves by ribbons
and by slits. Physical Review 54, 11 (1938), 895.
[39] Rajalakshmi Nandakumar, Krishna Kant Chintalapudi, Venkat Padmanabhan,
and Ramarathnam Venkatesan. 2013. Dhwani: secure peer-to-peer acoustic NFC.
ACM SIGCOMM Computer Communication Review 43, 4 (2013), 63–74.
[40] Takanori Nishino, Sumie Mase, Shoji Kajita, Kazuya Takeda, and Fumitada Itakura.
1996. Interpolating HRTF for auditory virtual reality. Ph.D. Dissertation. Acoustical
Society of America.
[41] Chunyi Peng, Guobin Shen, Yongguang Zhang, Yanlin Li, and Kun Tan. 2007.
Beepbeep: a high accuracy acoustic ranging system using cots mobile devices.
In Proceedings of the 5th international conference on Embedded networked sensor
systems. 1–14.
[42] Ming-Zher Poh, Kyunghee Kim, Andrew D Goessling, Nicholas C Swenson, and
Rosalind W Picard. 2009. Heartphones: Sensor earphones and mobile applica-
tion for non-obtrusive health monitoring. In 2009 International Symposium on
Wearable Computers. IEEE, 153–154.
[43] Swadhin Pradhan, Ghufran Baig, Wenguang Mao, Lili Qiu, Guohai Chen, and Bo
Yang. 2018. Smartphone-based acoustic indoor space mapping. Proceedings of
the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 2, 2 (2018),
1–26.
[44] Jay Prakash, Zhijian Yang, Yu-Lin Wei, and Romit Roy Choudhury. 2019. STEAR:
Robust Step Counting from Earables. In Proceedings of the 1st International Work-
shop on Earable Computing. 36–41.
[45] Niklas Röber, Sven Andres, and Maic Masuch. 2006. HRTF simulations through
acoustic raytracing. Universitäts-und Landesbibliothek Sachsen-Anhalt.
[46] Sheng Shen, Daguan Chen, Yu-Lin Wei, Zhijian Yang, and Romit Roy Choudhury.
2020. Voice localization using nearby wall reflections. In Proceedings of the 26th
Annual International Conference on Mobile Computing and Networking. 1–14.
[47] Tzu-Chun Tai, Kate Ching-Ju Lin, and Yu-Chee Tseng. 2019. Toward reliable local-
ization by unequal AoA tracking. In Proceedings of the 17th Annual International
Conference on Mobile Systems, Applications, and Services. 444–456.
[48] Jelmer Tiete, Federico Domínguez, Bruno Da Silva, Laurent Segers, Kris Steenhaut,
and Abdellah Touhafi. 2014. SoundCompass: a distributed MEMS microphone
array-based sensor for sound source localization. Sensors 14, 2 (2014), 1918–1949.
[49] Edgar A Torres-Gallegos, Felipe Orduna-Bustamante, and Fernando Arámbula-
Cosío. 2015. Personalization of head-related transfer functions (hrtf) based on
automatic photo-anthropometry and inference from a database. Applied Acoustics
97 (2015), 84–95.
[50] J-M Valin, François Michaud, Jean Rouat, and Dominic Létourneau. 2003. Robust
sound source localization using a microphone array on a mobile robot. In Pro-
ceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems
(IROS 2003)(Cat. No. 03CH37453), Vol. 2. IEEE, 1228–1233.
[51] Lars Falck Villemoes and Dirk Jeroen Breebaart. 2012. Method and apparatus for
generating a binaural audio signal. US Patent 8,265,284.
149
SIGCOMM ’21, August 23–27, 2021, Virtual Event, USA
Zhijian Yang and Romit Roy Choudhury
[56] Yanzi Zhu, Yibo Zhu, Ben Y Zhao, and Haitao Zheng. 2015. Reusing 60ghz
radios for mobile radar imaging. In Proceedings of the 21st Annual International
Conference on Mobile Computing and Networking. 103–116.
[57] Harald Ziegelwanger, Wolfgang Kreuzer, and Piotr Majdak. 2016. A priori mesh
grading for the numerical calculation of the head-related transfer functions.
Applied Acoustics 114 (2016), 99–110.
[58] DYN Zotkin, Jane Hwang, R Duraiswaini, and Larry S Davis. 2003. HRTF per-
sonalization using anthropometric measurements. In 2003 IEEE Workshop on
Applications of Signal Processing to Audio and Acoustics (IEEE Cat. No. 03TH8684).
Ieee, 157–160.
[59] Dmitry N Zotkin, Ramani Duraiswami, and Larry S Davis. 2004. Rendering
localized spatial audio in a virtual auditory space. IEEE Transactions on multimedia
6, 4 (2004), 553–564.
[52] Jeff Wilson, Bruce N Walker, Jeffrey Lindsay, Craig Cambias, and Frank Dellaert.
2007. Swan: System for wearable audio navigation. In 2007 11th IEEE international
symposium on wearable computers. IEEE, 91–98.
[53] Jens Windau and Laurent Itti. 2016. Walking compass with head-mounted IMU
sensor. In 2016 IEEE International Conference on Robotics and Automation (ICRA).
IEEE, 5542–5547.
[54] Zhijian Yang, Yu-Lin Wei, Sheng Shen, and Romit Roy Choudhury. 2020. Ear-AR:
indoor acoustic augmented reality on earphones. In Proceedings of the 26th Annual
International Conference on Mobile Computing and Networking. 1–14.
[55] Guangzheng Yu, Ruixing Wu, Yu Liu, and Bosun Xie. 2018. Near-field head-
related transfer-function measurement and database of human subjects. The
Journal of the Acoustical Society of America 143, 3 (2018), EL194–EL198.
150