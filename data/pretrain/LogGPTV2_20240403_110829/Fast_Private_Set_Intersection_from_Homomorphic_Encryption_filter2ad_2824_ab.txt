di = ri
(ci − x) .
Sender return the ciphertexts (d1, . . . , dNy ) to receiver.
4. Reply extraction: Receiver decrypts the ciphertexts (d1, . . . , dNy ) and outputs
X ∩ Y = {yi : FHE.Decrypt(di) = 0} .
Fig. 1: Basic PSI protocol.
We have the following informal theorem with regards to the security and correctness of the basic protocol.
Theorem 1 (informal). The protocol described in Figure 1 securely and correctly computes the private set
intersection of X and Y in the semi-honest security model, provided that the fully homomorphic encryption
scheme is IND-CPA secure and achieves circuit privacy.
Proof (Proof sketch). Receiver’s security is straightforward: the receiver sends an array of ciphertexts, which
looks pseudorandom to the sender since the fully homomorphic encryption scheme is IND-CPA secure. For
sender’s security, we note that the receiver’s view consists of an array of ciphertexts. It follows from circuit
privacy that the receiver only learns the decryptions of these ciphertexts, and nothing more.
For a ﬁxed index i, we have
FHE.Decrypt(di) = ri
(yi − x) ,
(cid:89)
x∈X
which is zero precisely when yi ∈ X (correctness), and otherwise a uniformly random element in Zt \ {0},
because Zt is a ﬁeld. Thus, the receiver learns no additional information beyond the intersection X ∩ Y .
This basic strawman protocol is extremely ineﬃcient: it requires the sender to perform O(NxNy) homo-
morphic multiplications and additions, and the depth of the circuit is high, pushing the FHE parameter sizes
to be huge. In addition, the sender and the receiver need to communicate O(Ny) FHE ciphertexts, which can
be prohibitive even for state-of-the-art fully homomorphic encryption schemes. It is therefore quite surprising
that the protocol becomes very eﬃcient when combined with the enhancements described in the next section.
4 Optimizations
4.1 Batching
Our ﬁrst step to improve performance is through the use of batching, which is a well-known and powerful tech-
nique in fully homomorphic encryption to enable SIMD (Single Instruction, Multiple Data) operations on ci-
phertexts. We give a brief explanation here, and refer the reader to [GHS12,BGH13,SV14,LCP16,GBDL+16]
for more details and example applications.
For suitable choices of the plaintext modulus t, there is a ring isomorphism from the plaintext space Rt
t . As an example, a constant polynomial a ∈ Rt corresponds to the vector (a, . . . , a) ∈ Zn
to Zn
t . Moreover,
this isomorphism translates polynomial additions and multiplications into coeﬃcient-wise additions and
multiplications in each of the n ﬁelds Zt. To simplify the exposition, we use the polynomial and vector
notations for plaintexts interchangeably, omitting the conversions from one representation to the other.
We can apply batching to reduce both the computational and communication cost of the basic protocol
(cid:81)
as follows. The receiver groups its items into vectors of length n, encrypts them, and sends Ny/n ciphertexts
to the sender. Upon seeing each ciphertext ci, the sender samples a vector ri = (ri1, . . . , rin) ∈ (Z∗
t )n of
x∈X (ci − x), and sends it
uniformly random non-zero elements of Zt, homomorphically computes di = ri
back to the receiver. Note that these modiﬁcations do not aﬀect correctness or security, since the exact same
proof can be applied per each vector coeﬃcient.
The batching technique allows the sender to operate on n items from the receiver simultaneously, resulting
in n-fold improvement in both the computation and communication. Since in typical cases n has size several
thousands, this results in a signiﬁcant improvement over the basic protocol.
4.2 Hashing
Even with the batching techniques of Section 4.1, the sender still needs to encode each of its set elements
into separate plaintexts, and individually compare them to the receiver’s items. Instead, it would be nice if
the sender could also take advantage of batching. We will achieve this through the use of hashing techniques.
Speciﬁcally, we use batching in conjunction with cuckoo hashing and permutation-based hashing, which have
been developed and explored in detail in the context of PSI in e.g. [PSZ14,PSSZ15].
Before jumping into the technicalities of cuckoo hashing and permutation-based hashing, we start with
a high-level explanation of why hashing is beneﬁcial in our context. Suppose the two parties hash the items
in their sets into two hash tables using some agreed-upon deterministic hash function. Now they only need
to perform a PSI for each bin, since items in diﬀerent bins are necessarily diﬀerent.
One important point is that all bins must be padded to a ﬁxed size to maintain security. Observe that
the bins prior to padding will have uneven loads, and the load of a speciﬁc bin (the number of items mapped
into the bin) can reveal additional information beyond the intersection. To overcome this, we need to pad
each bin with dummy items up to a pre-determined maximum size.
The simple hashing technique just described signiﬁcantly reduces the complexity of our protocol. It is
well known that hashing d items into a hash table of size m = d results in a maximum load of O(log d) with
high probability. For example, in the case that both parties have d = Nx = Ny items, the overall complexity
of the basic protocol reduces to O(d log2 d), where the log2 d factor comes from performing the basic PSI
protocol on a single bin. Next, we will reduce the complexity even further via better hashing techniques.
Cuckoo hashing Cuckoo hashing [PR01,DM03,FPSS03] is a way to build dense hash tables by using h > 1
hash functions H1, ..., Hh. To insert an item x, we choose a random index i from [h], and insert the tuple
(x, i) at location Hi(x) in the table. If this location was already occupied by a tuple (y, j), we replace (y, j)
with (x, i), choose a random j(cid:48) from [h] \ {j}, and recursively re-insert (y, j(cid:48)) into the table. For m ≈ d
and fairly small h, cuckoo hashing succeeds with very high probability, i.e. the recursive re-insertion process
always succeeds before a pre-determined upper bound on the recursion depth is reached. We will discuss the
success probability of cuckoo hashing in Section 4.2.
In order to apply cuckoo hashing to our PSI protocol, we must ensure that bin-wise comparisons will
always yield the correct intersection. This is done by letting the receiver perform cuckoo hashing with m (cid:38) Ny
bins. The sender must insert each of its items into a two-dimensional hash table using all h hash functions
H1, ..., Hh (simple hashing), because there is no way for it to know which one of the hash functions the
receiver eventually ended up using for the items in the intersection. To determine the maximum load on the
sender’s side, we apply a standard balls-into-bins argument. Concretely, when inserting d = hNx balls into
m bins, we have
(cid:18)d
(cid:19)(cid:18) 1
(cid:19)i(cid:18)
Pr[at least one bin has load > B]
1 − 1
m
≤ m
m
i
d(cid:88)
(cid:19)d−i
.
(1)
In this case B is upper-bounded by d/m + O((cid:112)d log m/m) with high probability [RS98].
Our default assumption is that the sender (who performs simple hashing) has a larger set, so that d > m log m.
i=B+1
Permutation-based hashing Independent of the exact hashing scheme, permutation-based hashing [ANS10]
is an optimization to reduce the length of the items stored in the hash tables by encoding a part of an item
into the bin index. For simplicity, we assume m is a power of two, and describe permutation-based hash-
ing only in connection with cuckoo hashing. To insert a bit string x into the hash table, we ﬁrst parse it
as xL(cid:107)xR, where the length of xR is equal to log2 m. The hash functions H1, ..., Hh are used to construct
location functions as
Loci(x) = Hi(xL) ⊕ xR ,
1 ≤ i ≤ h ,
which we will use in cuckoo hashing. Moreover, instead of inserting the entire tuple (x, i) into the hash table
as in regular cuckoo hashing, we only insert (xL, i) at the location speciﬁed by Loci(x).
The correctness of the PSI protocol still holds after applying permutation-based hashing. The reason is
if (xL, i) = (yL, j) for two items x and y, then i = j and xL = yL. If in addition these are found in the same
location, then Hi(xL)⊕ xR = Hj(yL)⊕ xR = Hj(yL)⊕ yR, so xR = yR, and hence x = y. The lengths of the
strings stored in the hash table are thus reduced by log2 m − (cid:100)log2 h(cid:101) bits. The complete hashing routine is
speciﬁed in Figure 2.
Hashing failures In an unlikely event where cuckoo hashing fails, it could leak some information of the
receiver’s set to the sender. To prevent this, we must ensure that with overwhelming probability the cuckoo
hashing algorithm will succeed. While some asymptotic results exist for estimating the failure probability
of cuckoo hashing [FMM09,DGM+10], the hidden constants are diﬃcult to determine precisely. Instead, to
obtain optimal parameters, we choose to determine the failure probability using empirical methods. The
general technique we use is similar to that of [PSZ16], with two exceptions: ﬁrst, we omit an auxiliary data
structure known as the stash due to its incompatibility with the fully homomorphic encryption approach;
second, we primarily focus on h = 3 in our experiments (see below), whereas [PSZ16] focused on h = 2.
Input: Receiver inputs set Y of size Ny; sender inputs set X of size Nx. Both sets consist of bit strings of
length σ. Nx, Ny, σ are public. Both parties input integers h, m, B and a set of hash function H1, ..., Hh :
{0, 1}σ−log2 m → {0, 1}log2 m. The location functions Loci is deﬁned with respect to Hi for i ∈ [h].
Output: Receiver outputs a permutation-based cuckoo hash table with the items in Y inserted, or ⊥. Sender
outputs a permutation-based hash table with the items in X inserted using simple hashing and all location
functions, or ⊥.
1. [Sender] Let Bx be an array of m bins, each with capacity B, and value {(⊥,⊥)}B. For each x ∈ X
and i ∈ [h], the sender samples j ← [B] s.t. Bx[Loci(x)][j] = ⊥, and sets Bx[Loci(x)][j] := (xL, i). If the
sampling fails due to a bin being full, the sender outputs ⊥. Otherwise it outputs Bx.
2. [Receiver] Let By be an array of m bins, each with capacity 1, and value (⊥,⊥). For each y ∈ Y , the
receiver
(a) sets w = y, and i ← [B];
(b) deﬁnes and calls the function Insert(w, i) as follows: swap (w, i) with the entry at By[Loci(w)]. If
If for any y ∈ Y the recursive calls to Insert exceeds the system limit, the receiver halts and outputs ⊥.
Otherwise it outputs By.
(w, i) (cid:54)= (⊥,⊥), recursively call Insert(w, j), where j ← [h] \ {i}.
Fig. 2: Hashing routine.
Table size m
3 · 28
3 · 212 3 · 216
λ = 30 40 30 40 30 40
Insert size d
3 · 220
30 40
3 · 224
30
40
3 · 228
30
40
Table 1: Simple hashing bin size upper bound B for failure probability 2−λ, with λ ∈ {30, 40}, and h = 3;
8192
16384
8 9 17 20 68 74 536 556 6727 6798 100611 100890
50807 51002
7 8 13 16 46 51 304 318 3492 3543
see equation (1).
We start by ﬁxing the cuckoo hash table consisting of m bins, and vary the number for items d  σmax − log2 m + (cid:100)log2 h(cid:101) + 1
(2)
we can accommodate arbitrarily long strings in our PSI protocol.
Combining with batching It is straightforward to combine hashing techniques introduced in this section
with the batching technique in Section 4.1. After the receiver hashes its items into a table of size m, it
parses the table into m/n vectors of length n. The receiver then encrypts each vector using batching, and
proceeds as usual. Similarly, the sender performs the same batching step for each of the B columns of its two-
dimensional hash table, resulting in Bm/n plaintext vectors. The rest of the protocol remains unchanged,
and we see that adding batching to the hashing techniques provides an n-fold reduction in both computation
and communication.
4.3 Reducing the Circuit Depth
With the optimizations discussed in Section 4.1 and Section 4.2, our protocol already achieves very low com-
munication cost: typically just a few homomorphically encrypted ciphertexts. Unfortunately, the depth of the
arithmetic circuit that needs to be homomorphically evaluated is still O(log Nx), which can be prohibitively
high for currently known fully homomorphic encryption schemes.
We use two tricks—windowing and partitioning—to critically reduce this depth. For simplicity of expo-
sition, we will discuss how these two tricks work over the basic protocol, and brieﬂy explain how to combine
them with previous optimizations.
to the sender, who samples a random element r in Zt \ {0}, homomorphically evaluates r(cid:81)
Windowing We use a standard windowing technique to lower the depth of the arithmetic circuit that
the sender needs to evaluate on the receiver’s homomorphically encrypted data, resulting in a valuable
computation-communication trade-oﬀ.
Recall that in the basic protocol, for each item y ∈ Y , the receiver sends one ciphertext c = FHE.Encrypt(y)
x∈X (c − x), and
sends the result back to the receiver. If the receiver sends encryptions of extra powers of y, the sender can
use these powers to evaluate the same computation with a much lower depth circuit. More precisely, for
a window size of (cid:96) bits, the receiver computes and sends c(i,j) = FHE.Encrypt(yi·2(cid:96)j
) to the sender for all
1 ≤ i ≤ 2(cid:96) − 1, and all 0 ≤ j ≤ (cid:98)log2(Nx)/(cid:96)(cid:99). For example, when (cid:96) = 1, the receiver sends encryptions of
y, y2, y4, . . . , y2(cid:98)log2 Nx(cid:99)
.
This technique results in a signiﬁcant reduction in the circuit depth. To see this, we write
(cid:89)
x∈X
r
(y − x) = ryNx + raNx−1yNx−1 + . . . + ra0 .
(3)