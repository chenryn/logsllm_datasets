we have run the program with options A, B, C, D, and E,
and our analysis group really depends on B and D. Once
the message gets processed, we see that the AG does not
depend on E, so E can be excluded from further analysis.
Since the last observed color, D, has a direct inﬂuence on
the AG, it is a true dependence. By performing a circular
shift and re-trying with the order D, A, B, C, E, Dowser
ﬁnds only the colors corresponding to A, B, D. Thus, we
can leave C out of our analysis. After the next circular
shift, Dowser reduces the colors to B and D only.
The optimization is based on two observations: (1) the
last ﬁeld propagated to the AG has a direct inﬂuence on
the AG, so it needs to be kept, (2) all ﬁelds beyond this
one are guaranteed to have no impact on the AG. By per-
forming circular shifts, and running DTA on the updated
input, Dowser drops the undue dependencies.
Even though this optimization requires some minimal
knowledge of the input, we do not need full understand-
ing of the input grammar, like the contents or effects of
ﬁelds. It is sufﬁcient to identify the ﬁelds whose order is
not ﬁxed. Fortunately, such information is available for
many applications—especially when vendors test their
own code.
5 Exploring candidate instructions
Once we have learnt which part of the program input in-
ﬂuences the analysis group AG(accp), we fuzz this part,
and we try to nudge the program toward using the pointer
p in an illegal way. More technically, we treat the inter-
esting component of the input as symbolic, the remaining
part as ﬁxed (concrete), and we execute the loop associ-
ated with AG(accp) symbolically.
However, since in principle the cost of a complete loop
traversal is exponential, loops present one of the hard-
est problems for symbolic execution [19]. Therefore,
when analyzing a loop, we try to select those paths that
are most promising in our context. Speciﬁcally, Dowser
prioritizes paths that show a potential for knotty pointer
arithmetic. As we show in Section 6, our technique sig-
niﬁcantly optimizes the search for an overﬂow.
Dowser’s loop exploration procedure has two main
phases: learning, and bug ﬁnding. In the learning phase,
Dowser assigns each branch in the loop a weight approx-
imating the probability that a path following this direc-
tion contains new pointer dereferences. The weights are
based on statistics on the variety of pointer values ob-
served during an execution of a short symbolic input.
Next,
in the bug ﬁnding phase, Dowser uses the
weights determined in the ﬁrst step to ﬁlter our unin-
teresting parts of the loop, and prioritize the important
paths. Whenever the weight associated with a certain
branch is 0, Dowser does not even try to explore it fur-
ther. In the vulnerable nginx parsing loop from which
Figure 1 shows an excerpt, only 19 out of 60 branches
scored a non-zero value, so were considered for the ex-
ecution. In this phase, the symbolic input represents a
real world scenario, so it is relatively long. Therefore, it
would be prohibitively expensive to be analyzed using a
popular symbolic execution tool.
In Section 5.1, we brieﬂy review the general con-
cept of concolic execution, and then we discuss the two
phases in Sections 5.2 and 5.3, respectively.
5.1 Baseline: concrete + symbolic execution
Like DART and SAGE [17, 18], Dowser generates new
test inputs by combining concrete and symbolic execu-
tion. This technique is known as concolic execution [33].
It runs the program on a concrete input, while gather-
ing symbolic constraints from conditional statements en-
countered along the way. To test alternative paths, it sys-
tematically negates the collected constraints, and checks
whether the new set is satisﬁable. If so, it yields a new
input. To bootstrap the procedure, Dowser takes a test
input which exercises the analysis group AG(accp).
As mentioned already, a challenge in applying this ap-
proach is how to select the paths to explore ﬁrst. The
USENIX Association  
22nd USENIX Security Symposium  55
7
classic solution is to use depth ﬁrst exploration of the
paths by backtracking [22]. However, since doing so
results in an exponentially growing number of paths to
be tested, the research community has proposed various
heuristics to steer the execution toward unexplored re-
gions. We discuss these techniques in Section 7.
5.2 Phase 1: learning
The aim of the learning phase is to rate the true and
false directions of all conditional branches that depend
on the symbolic input in the loop L. For each branch, we
evaluate the likelihood that a particular outcome will lead
to unique pointer dereferences (i.e., dereferences that we
do not expect to ﬁnd in the alternative outcome). Thus,
we answer the question of how much we expect to gain
when we follow this path, rather than the alternative. We
encode this information into weights.
Speciﬁcally, the weights represent the likelihood of
unique access patterns. An access pattern of the pointer
p is the sequence of all values of p dereferenced during
the execution of the loop. In Figure 1, when we denote
the initial value of u by u0, then the input "//../" trig-
gers the following access pattern of the pointer u: (u0,
u0+1, u0 + 2, u0-2,...).
To compute the weights, we learn about the effects
of individual branches. In principle, each of them may
(a) directly affect the value of a pointer, (b) be a precon-
dition for another important branch, or (c) be irrelevant
from the computation’s standpoint. To distinguish be-
tween these cases, Dowser analyzes all possible execu-
tions of a short symbolic input. By comparing the sets
of p’s access patterns observed for both outcomes of a
branch, it discovers which branches do not inﬂuence the
diversity of pointer dereferences (i.e., are irrelevant).
Symbolic input In Section 4, we identiﬁed which part of
the test input I we need to make symbolic. We denote
this by IS. In the learning phase, Dowser executes the
loop L exhaustively. For performance reasons, we there-
fore further limit the amount of symbolic data and make
only a short fragment of IS symbolic. For instance, for
Figure 1, the learning phase makes only the ﬁrst 4 bytes
of uri symbolic (not enough to trigger the bug), while
scaling up to 50 symbolic bytes in the bug ﬁnding phase.
Algorithm Dowser exhaustively executes L on a short
symbolic input, and records how the decisions taken at
conditional branch statements inﬂuence pointer derefer-
ence instructions. For each branch b along the execu-
tion path, we retain the access pattern of p realized dur-
ing this execution, AP(p). We informally interpret it as
“if you choose the true (respectively, false) direction
of the branch b, expect access pattern AP(p) (respec-
tively, AP′(p))”. This procedure results in two sets of
access patterns for each branch statement, for the taken
and non-taken branch, respectively. The ﬁnal weight of
each direction is the fraction of the access patterns that
were unique for the direction in question, i.e., were not
observed when the opposite one was taken.
The above description explains the intuition behind
the learning mechanism, but the full algorithm is more
complicated. The problem is that a conditional branch b
might be exercised multiple times in an execution path,
and it is possible that all the instances of b inﬂuence the
access pattern observed.
Intuitively, to allow for it, we do not associate access
patterns with just a single decision taken on b (true or
false). Rather, each time b is exercised, we also retain
which directions were previously chosen for b. Thus, we
still collect “expected” access patterns if the true (re-
spectively, false) direction of b is followed, but we aug-
ment them with a precondition. This way, when we com-
pare the true and false sets to determine the weights
for b, we base the scores on a deeper understanding of
how an access pattern was reached.
Discussion It is important for our algorithm to avoid
false negatives: we should not incorrectly ﬂag a branch
as irrelevant—it would preclude it from being explored
in the bug ﬁnding phase. Say that instr is an instruction
that dereferences the pointer p. To learn that a branch
directly inﬂuences instr, it sufﬁces to execute it. Sim-
ilarly, since branches retain full access patterns of p, the
information about instr being executed is also “propa-
gated” to all its preconditions. Thus, to completely avoid
false negatives, the algorithm would require full cover-
age of the instructions in an analysis group. We stress
that we need to exercise all instructions, and not all paths
in a loop. As observed by [7], exhaustive executions of
even short symbolic inputs provide excellent instruction
coverage in practice.
While false positives are undesirable as well, they only
cause Dowser to execute more paths in the second phase
than absolutely necessary. Due to the limited path cov-
erage, there are corner cases, when false positives can
happen. Even so, in nginx, only 19 out of 60 branches
scored a non-zero value, which let us execute the com-
plex loop with a 50-byte-long symbolic input.
5.3 Phase 2: hunting bugs
In this step, Dowser executes symbolically a real-world
sized input in the hope of ﬁnding a value that triggers a
bug. Dowser uses the feedback from the learning phase
(Section 5.2) to steer its symbolic execution toward new
and interesting pointer dereferences. The goal of our
heuristic is to avoid execution paths that do not bring any
new pointer manipulation instructions. Thus, Dowser
shifts the target of symbolic execution from traditional
code coverage to pointer value coverage.
56  22nd USENIX Security Symposium 
USENIX Association
8
Dowser’s strategy is explicitly dictated by the weights.
As a baseline, the execution follows a depth-ﬁrst explo-
ration, and when Dowser is about to select the direction
of a branch b that depends on the symbolic input, it ad-
heres to the following rules:
• If both the true and false directions of b have
weight 0, we do not expect b to inﬂuence the vari-
ety of access patterns. Thus, Dowser chooses the
direction randomly, and does not intend to examine
the other direction.
• If only one direction has a non-zero weight, we ex-
pect to observe unique access patterns only when
the execution paths follows this direction, and
Dowser favors it.
• If both of b’s directions have non-zero weights, both
the true and false options may bring unique ac-
cess patterns. Dowser examines both directions,
and schedules them in order of their weights.
Intuitively, Dowser’s symbolic execution tries to select
paths that are more likely to lead to overﬂows.
Guided fuzzing This concludes our description of
Dowser’s architecture. To summarize, Dowser helps
fuzzing by:
(1) ﬁnding “interesting” array accesses,
(2) identifying the inputs that inﬂuence the accesses, and
(3) fuzzing intelligently to cover the array. Moreover,
the targeted selection procedure based on pointer value
coverage and the small number of symbolic input values
allow Dowser to ﬁnd bugs quickly and scale to larger ap-
plications. In addition, the ranking of array accesses per-
mits us to zoom in on more complicated array accesses.
6 Evaluation
In this section, we ﬁrst zoom in on the running example
of nginx from Figure 1 to evaluate individual compo-
nents of the system in detail (Section 6.1). In Section 6.2,
we consider seven real-world applications. Based on
their vulnerabilities, we evaluate our dowsing mecha-
nism. Finally, we present an overview of the attacks de-
tected by Dowser.
Since Dowser uses a ‘spot-check’ rather than ‘code
coverage’ approach to bug detection, it must analyze
each complex analysis group separately, starting with the
highest ranking one, followed by the second one, and so
on. Each of them runs until it ﬁnds a bug or gets termi-
nated. The question is when we should terminate a sym-
bolic execution run. Since symbolic execution of a single
loop is highly optimized in Dowser, we found each bug
in less than 11 minutes, so we execute each symbolic run
for a maximum of 15 minutes.
)
d
e
r
o
c
s
s
t
i
1200
1200
1000
1000
800
800
600
600
400
400
200
200
0
0
n
o
p
(
y
t
i
x
e
p
m
o
C
l
0
0
20
20
40
40
threshold (26 points)
100
100
120
120
140
140
60
60
80
80
Analysis groups
Fig. 5: Scores of the analysis groups in nginx.
Our test platform is a Linux 3.1 system with an
Intel(R) Core(TM) i7 CPU clocked at 2.7GHz with
4096KB L2 cache. The system has 8GB of memory. For
our experiments we used an OpenSUSE 12.1 install. We
ran each test multiple times and present the median.
6.1 Case study: Nginx
In this section, we evaluate each of the main steps of our
fuzzer by looking at our case study of nginx in detail.
6.1.1 Dowsing for candidate instructions
We measure how well Dowser highlights potentially
faulty code and ﬁlters out the uninteresting fragments.
Our ﬁrst question is whether we can ﬁlter out all the
simple loops and focus on the more interesting ones.
This turns out to be simple. Given the complexity scor-
ing function from Section 3, we ﬁnd that across all appli-
cations all analysis groups with a score less than 26 use
just a single constant and at most two instructions modi-
fying the offset of an array. Thus, in the remainder of our
evaluation, we set our cut-off threshold to 26 points.
As shown in Table 2, nginx has 517 outermost loops,
and only 140 analysis groups that access arrays. Thus,
we throw out over 70% of the loops immediately3. Fig-
ure 5 presents the sorted weights of all the analysis
groups in nginx. The distribution shows a quick drop
after a few highly complex analysis groups. The long
tail represents the numerous simple loops omnipresent in
any code. 55.7% of the analysis groups score too low to
be of interest. This means that Dowser needs to examine
only the remaining 44.3%, i.e., 62 out of 140 analysis
groups, or at most 12% of all loops. Out of these, the
buffer overﬂow in Figure 1 ranks 4th.
6.1.2 Taint analysis in context of hunting for bugs
In Section 4 we mentioned that ‘traditional’ dynamic
taint analysis misses implicit ﬂows, i.e., ﬂows that have
3In principle, if a loop accesses multiple arrays, it also contains
multiple access groups. Thus, these 140 analysis groups are located in
fewer than 140 loops.
USENIX Association  
22nd USENIX Security Symposium  57
9
no direct assignment of a tainted value to a variable. The
problem turns out to be particularly serious for nginx.
It receives input in text format, and transforms it to ex-
tract numerical values or various ﬂags. As such code
employs conditional statements, DTA misses the depen-
dencies between the input and analysis groups.
Next, we evaluate the usefulness of ﬁeld shifting.
First, we implement the taint propagation exactly as pro-
posed by Bao et al. [6], without any further restrictions.
In that case, an index variable in the nginx parser be-
comes tainted, and we mark all HTTP ﬁelds succeeding
the uri ﬁeld as tainted as well. As a result, we introduce
more symbolic data than necessary. Next, we apply ﬁeld
shifting (Section 4.2) which effectively limits taint prop-
agation to just the uri ﬁeld. In general, the ﬁeld shifting
optimization improves the accuracy of taint propagation
in all applications that take multiple input ﬁelds whose