one is to use the snapshot functionality from the Android Emula-
tor [18]. Then, the tool can take the snapshot of the RP login page
after the UI exploration and reload it in the test, whose time cost is
expected to be lower and not affected by the noise.
The second solution is to skip the interactions between the IdP
app and IdP server, e.g., Step 2 to 4 in Fig. 1. From the perspective
of the RP developers, they are only interested in assessing their
own SSO deployments. Then, we may prepare some valid data, e.g.,
access token and user profile, and configure the proxy beforehand.
Consequently, once the requests from the IdP app is detected, Proxy
will impersonate as the real IdP server and respond immediately.
7 RELATED WORK
UI automation for Android app testing. Many projects have
been done in recent years on automated Android app testing. Most
of them aim at exploring the app with larger coverage. In contrast
to traditional random exploration used by Monkey [19], they apply
more systematic strategies. GUIRipper [2], SwiftHand [12], PUMA
[20], and DroidBot [30] crawl an app and dynamically build a fi-
nite state machine to represent the app’s UI model. Among them,
button but turns out it is not, then both algorithms will choose it
first. After clicking the button, Algorithm I will cut off directly as
there is no targeted keyword in the new page. However, the other
will try every new button because its core is depth-first search.
The overall accuracy of UI Explorer is reasonable and failure
cases (19.2%) are mainly due to the imperfection of Noise Reducer.
Our current design cannot handle some corner cases, e.g., UI widgets
with no identifiable characteristics. Some of them can be fixed with
one-time human assistance. For the purpose, we developed a tool
which enables users to navigate the app to the login page and
take snapshots of the emulator via web browsers. Then, MoSSOT
simply reloads that snapshot to reach the login page during the test.
Meanwhile, we plan to apply static analysis on the app (APK) to
extract input constraints and solve them to assist the UI exploration.
Besides, many apps (26.0%) in the sample set cannot be launched.
For example, their backend servers are no longer maintained, which
is unfixable. Some others refuse to run in the emulator and can be
tested with proper setup, as MoSSOT can execute on real devices.
6.3 Obstacles in the Learning Phase
According to Table. 1, only 27% of the apps could pass the whole
testing phases after the UI exploration, which is mainly caused
by the failures in learning app-specific SSO implementations (Sec-
tion 4.2.2). We manually analyzed 60 failure cases, which can be
categorized into four types as shown in Table. 4.
App Error: Although the tool did not tamper any message in
the step, two of the apps crashed frequently. In the other cases, the
backend RP servers responded with error messages.
RP Account Settings: In the category, the RP accounts required
special settings beforehand, e.g., phone number binding, so that the
tool could not finish the whole SSO process.
Failure to Extract User Login Status: MoSSOT relies on the
RP authentication response to identify the RP login status (Sec-
tion 4.3.2). However, MoSSOT may fail to learn it as these RPs use
customized protocols so that our tester cannot capture the message.
Session 4A: Mobile SecurityAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand278Table 5: Comparison with Previous Work on SSO Testing
Selected Work
Zhou et al.(SSOScan) [53]
Sun et al. [43]
Shernan et al. [39]
Li et al. [29]
Shehab et al. (OAuthManager) [38]
Wang et al.(AuthDroid) [47]
Wang et al. [46]
Level of Automation
Automatic
Semi-automatic
Automatic
Manual
Automatic
Semi-automatic
Semi-automatic
Scope of Study
1660 websites
96 websites
10000 websites
103 websites
430 Android apps
100 Android apps
79 websites, 85 Android apps
& 77 iOS apps
Our work (MoSSOT)
Automatic
550 Android apps
Assessing the usage of the state variable
Target
4 specific vulnerabilities
5 specific vulnerabilities
3 specific vulnerabilities
3 specific vulnerabilities *
6 specific vulnerabilities †
5 specific vulnerabilities ‡
General model-based testing (detecting
4 known and 2 unknown vulnerabilities)
* The vulnerabilities are about the improper usage of Android WebView [17] and is out of the scope of our study.
† [47] also takes the inter-app (e.g., Step 1 & 5 in Fig. 1) and server-to-server (e.g., Step 7 & 8 in Fig. 1) communication into account.
‡ [46] considers the usage of access token (instead of id token) in OIDC (Section 2.3) as a vulnerability, which may not be exploitable.
GUIRipper allows the tester to configure inputs to be used during
exploration. SwiftHand uses an exploration strategy that can min-
imize the app restarts. PUMA provides a framework to combine
model-based exploration with random monkey inputs. Instead of
dynamically building the model, some other tools, e.g., A3E [4]
and FraudDroid [13] extract activity transition graph beforehand
with static code analysis to guide the UI testing. More recently,
researchers start to explore advanced strategies like a stochastic
model [42] and machine learning [9, 36]. However, all these tools
try to construct a map of every activity in an app for exploration
while our task is to look for SSO login interfaces. Our algorithms
eliminate the overhead of map construction to achieve better effi-
ciency. Whatsmore, all mentioned tools lack the ability to replay
their recorded UI path reliably as indicated in [27]. To address the
challenge, we packaged three modules, i.e., Explorer, Navigator and
Noice Reducer, into our work to make UI path replay possible.
The projects with more relevant goals to ours are Brahmastra [7]
and AuthScope [54], both focusing on driving apps to the targeted
activity. While [7] looks for activity transition paths with static
analysis, [54] implements prioritized DFS for targeted UI explo-
ration. Nevertheless, [54] only works with Facebook SSO login. In
contrast, our work is more extensible and is capable of handling
multiple IdPs. Although both of our work and [54] utilize DFS for
UI exploration, [54] only uses keywords and action bindings as
prioritization criteria, while our work calculates a score for each
element based on more attributes and a smarter algorithm (Sec-
tion. 4.1.3) for better accuracy and efficiency. Besides, our work
also supports LKS. Since [54] is close-sourced, we did not manage
to make a comparison between their DFS and our LKS algorithm.
However, according to the experiment result (in Table. 3), LKS is
more efficient in finding targeted activity than DFS. Besides, as LKS
is orthogonal to DFS, it helps to increase the success rate further.
OAuth security studies from the protocol perspective. RFC
specifications [21, 31] discuss the security considerations and threat
models for OAuth 2.0. Focusing on the classical web attacks like
XSS, CSRF, and the intentional attacks specifically designed for
OAuth, these standards hope to exclude these common pitfalls. Hu
et al. [22] present the App Impersonation attack. Besides, under
the assumption that the TLS is utilized properly, the authorization
code flow has been proven to be secure cryptographically [10].
On the other hand, the formal method is widely adopted by the
previous work to assess OAuth Security. Bansal et al. [6] model
different configurations of the OAuth protocol and analyze them
by ProVerif [8], which leads to the discovery of Token Redirection
Attack and Social CSRF Attack. Similarly, AuthScan [5] performs a
whitebox code analysis and a blackbox fuzzing to extract the pro-
tocol specifications from real implementations and find 7 security
flaws. Following their work, Fett et al. [15] use an expressive FKS
model to perform an extensive analysis of all four grant flows.
These studies prove/ improve the security for OAuth 2.0 from the
viewpoint of protocol design. However, since the OAuth protocol
was initially designed to serve the authorization need for websites,
the focus of the paper, namely the authentication services on mobile
platforms, is thus not considered by the studies.
Analyses of mobile OAuth-based SSO systems. In contrast
to the wide deployment, there are few security analyses on the mo-
bile OAuth-based SSO systems. Chen et al. [11] show how practical
OAuth system may fall into the common pitfalls when utilizing the
OS-provided components, e.g., Intent, improperly. Shehab et al. [38]
reveal 3 vulnerabilities in WebView, which affect OAuth security.
Ye et al. [51] utilize the model checking method to analyze the
OIDC-like protocol implemented by Facebook on Android platform
and discover a problem on unauthorized storage access. Wang et
al. [46, 47] perform static code analysis and dynamic analysis on
the real-time network messages, leading to the detection of sev-
eral vulnerabilities across both Android and iOS platforms. Using
similar approaches, Yang et al. [49] find Profile Vulnerability.
Previous work relies on the manual discovery of vulnerabilities,
which is not scalable. Compared to the state-of-the-art, MoSSOT
can discover vulnerabilities automatically.
SSO security testing tool. Motivated by the prevalence of vul-
nerabilities in real-world SSO systems, large-scale security test-
ing has received increasing attention. Sun et al. [43] build a semi-
automatic tool to test specific vulnerabilities for 96 applications.
SSOScan [53] investigates five specific attacks on Top 1600 Face-
book websites. Shernan et al. [39] analyze the known CSRF attack
on 10,000 websites by checking the existence of state. Li et al. [29]
report the security quality of 103 Google-enabled RP websites.
Nevertheless, all the work mentioned so far only studies the spec-
ifications/ implementations of SSO in the web applications, where
Session 4A: Mobile SecurityAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand279the interactions for secure authentication are well specified. In con-
trast, we focus on the mobile platform, where such interactions of
our interest are error-prone and overlooked.
The projects most relevant to ours are [50] and [54]. [50] also
utilizes the model-based testing to assess real-world SSO deploy-
ments, but targets web applications instead of mobile apps, where
the situation is not so complicated. For example, [50] may enter
any state in their model by constructing a proper URL request. In
contrast, we are incapable of maintaining the app state directly and
have to rely on UI to trigger SSO-related network messages. On the
other hand, although our method is similar to [54], our target is the
vulnerabilities within the SSO (authentication), while [54] focuses
on the authorization issues after the authentication process.
8 CONCLUSION
In this paper, we present an automated blackbox security testing
tool, MoSSOT, to systematically test the implementations of SSO by
the RPs/ IdPs as well as their backend servers. We implement the
tool and perform the test on 550 RP apps. The tester identified one
previously-unknown vulnerability and a new variant, in addition
to four known ones. All of them can break the authentication of
the RP apps and lead to privacy leakage of the victims.
We have open sourced MoSSOT at [34] and plan to extend it for
other protocols, e.g., mobile payment protocols, in the long run.
ACKNOWLEDGEMENT
We thank our shepherd Dr. Guangdong Bai and the anonymous re-
viewers for their valuable comments and suggestions. We also thank
Yihui Zeng, Ronghai Yang, Zhuowei Zhong, Guanchen Li, and Chak-
man Li for their contributions in the development of MoSSOT. The
work is supported in part by the ITF of HK (project#ITS/216/15), the
CUHK TBF (project#TBF18ENG001), the CUHK PIEF (project#31330
43), and the 2018 Facebook/USENIX Internet Defense Prize.
REFERENCES
[1] 2017. Culebra. https://github.com/dtmilano/AndroidViewClient/wiki/culebra
[2] Domenico Amalfitano, Anna Rita Fasolino, Porfirio Tramontana, Salvatore
De Carmine, and Atif M Memon. 2012. Using GUI ripping for automated testing
of Android applications. In ASE12. ACM.
[3] Apkpure. 2017. Apkpure. https://apkpure.com/.
[4] Tanzirul Azim and Iulian Neamtiu. 2013. Targeted and depth-first exploration
for systematic testing of android apps. In ACM Sigplan Notices, Vol. 48. ACM.
[5] Guangdong Bai, Jike Lei, Guozhu Meng, Sai Sathyanarayan Venkatraman, Prateek
Saxena, Jun Sun, Yang Liu, and Jin Song Dong. 2013. AUTHSCAN: Automatic
Extraction of Web Authentication Protocols from Implementations. In NDSS13.
[6] Chetan Bansal, Karthikeyan Bhargavan, and Sergio Maffeis. 2012. Discovering
Concrete Attacks on Website Authorization by Formal Analysis. In CSF12.
[7] Ravi Bhoraskar, Seungyeop Han, Jinseong Jeon, Tanzirul Azim, Shuo Chen,
Jaeyeon Jung, Suman Nath, Rui Wang, and David Wetherall. 2014. Brahmastra:
Driving Apps to Test the Security of Third-Party Components.. In USENIX14.
[8] Bruno Blanchet. 2014. The ProVerif homepage. http://prosecco.gforge.inria.fr/
personal/bblanche/proverif/
[9] Nataniel P Borges Jr, Maria Gómez, and Andreas Zeller. 2018. Guiding app testing
with mined interaction models. In MOBILESoft18. ACM.
[10] Suresh Chari, Charanjit S. Jutla, and Arnab Roy. 2011. Universally Composable
Security Analysis of OAuth v2.0. Cryptology ePrint Archive, Report 2011/526.
[11] Eric Y Chen, Yutong Pei, Shuo Chen, Yuan Tian, Robert Kotcher, and Patrick
Tague. 2014. OAuth demystified for mobile application developers. In CCS14.
[12] Wontae Choi, George Necula, and Koushik Sen. 2013. Guided gui testing of
android apps with minimal restart and approximate learning. In ACM Sigplan
Notices, Vol. 48. ACM.
[13] Feng Dong, Haoyu Wang, Yuanchun Li, Yao Guo, Li Li, Shaodong Zhang, and
Guoai Xu. 2017. FrauDroid: An Accurate and Scalable Approach to Automated
Mobile Ad Fraud Detection. arXiv preprint arXiv:1709.01213 (2017).
[14] Facebook. 2017. Facebook SSO developer document. https://developers.facebook.
com/docs/facebook-login/.
[15] Daniel Fett, Ralf Küsters, and Guido Schmitz. 2016. A Comprehensive Formal
Security Analysis of OAuth 2.0. CCS16 (2016).
[16] Genymotion. 2017. Genymotion. https://www.genymotion.com/
[17] Google. 2017. Android webview.
http://developer.android.com/reference/
android/webkit/WebView.html
[18] Google. 2017. AVD. https://developer.android.com/studio/run/emulator.
[19] Google. 2017. Monkey. http://developer.android.com/tools/help/monkey
[20] Shuai Hao, Bin Liu, Suman Nath, William GJ Halfond, and Ramesh Govindan.
2014. PUMA: programmable UI-automation for large-scale dynamic analysis of
mobile apps. In MobiSys14. ACM.
[21] Dick Hardt. 2012. The OAuth 2.0 authorization framework.
[22] Pili Hu, Ronghai Yang, Yue Li, and Wing Cheong Lau. 2014. Application im-