title:Preventing Use-After-Free Attacks with Fast Forward Allocation
author:Brian Wickman and
Hong Hu and
Insu Yun and
Daehee Jang and
Jungwon Lim and
Sanidhya Kashyap and
Taesoo Kim
Preventing Use-After-Free Attacks with 
Fast Forward Allocation
Brian Wickman, GTRI; Hong Hu, PennState; Insu Yun, Daehee Jang, and 
JungWon Lim, GeorgiaTech; Sanidhya Kashyap, EPFL; Taesoo Kim, GeorgiaTech
https://www.usenix.org/conference/usenixsecurity21/presentation/wickman
This paper is included in the Proceedings of the 30th USENIX Security Symposium.August 11–13, 2021978-1-939133-24-3Open access to the Proceedings of the 30th USENIX Security Symposium is sponsored by USENIX.Preventing Use-After-Free Attacks with Fast Forward Allocation
Brian Wickman† Hong Hu‡
Insu Yun Daehee Jang
JungWon Lim Sanidhya Kashyap∗ Taesoo Kim
†GTRI
‡PennState GeorgiaTech
∗EPFL
Abstract
Memory-unsafe languages are widely used to implement crit-
ical systems like kernels and browsers, leading to thousands
of memory safety issues every year. A use-after-free bug is
a temporal memory error where the program accidentally
visits a freed memory location. Recent studies show that use-
after-free is one of the most exploited memory vulnerabilities.
Unfortunately, previous efforts to mitigate use-after-free bugs
are not widely deployed in real-world programs due to either
inadequate accuracy or high performance overhead.
In this paper, we propose to resurrect the idea of one-time
allocation (OTA) and provide a practical implementation with
efficient execution and moderate memory overhead. With one-
time allocation, the memory manager always returns a distinct
memory address for each request. Since memory locations
are not reused, attackers cannot reclaim freed objects, and
thus cannot exploit use-after-free bugs. We utilize two tech-
niques to render OTA practical: batch page management and
the fusion of bump-pointer and fixed-size bins memory alloca-
tion styles. Batch page management helps reduce the number
of system calls which negatively impact performance, while
blending the two allocation methods mitigates the memory
overhead and fragmentation issues. We implemented a proto-
type, called FFmalloc, to demonstrate our techniques. We eval-
uated FFmalloc on widely used benchmarks and real-world
large programs. FFmalloc successfully blocked all tested use-
after-free attacks while introducing moderate overhead. The
results show that OTA can be a strong and practical solution
to thwart use-after-free threats.
1 Introduction
Memory-unsafe languages, like C and C++, are widely used to
implement key programs such as web browsers and operating
systems. Therefore, we have seen innumerable memory safety
issues detected and abused in these systems [31]. Among all
memory safety issues, the use-after-free bug is one of the most
commonly reported and exploited security problems [27, 31].
A use-after-free bug occurs when a program tries to defer-
ence a dangling pointer that points to a freed object. The
consequence of a use-after-free bug depends on the imple-
mentation of the memory allocator and the following code
of the program. In the worst case, attackers may reclaim the
freed object and update its content with malformed values.
When the program accidentally uses the content, its behavior
will be under the control of attackers, potentially allowing
arbitrary code execution or sensitive information leakage.
Researchers have proposed different methods to detect or
mitigate use-after-free bugs. The first method is to label each
memory chunk to indicate whether it is allocated or freed.
Before each memory access, a label is checked to detect after-
free use [33–35, 40, 45]. However, this approach introduces
high overhead to program execution and thus has not been
widely adopted in released applications. A second way is to
actively invalidate dangling pointers once the object is freed,
like setting them to a NULL value [18,27,47,49]. These tools
must maintain the inverse points-to relationship between an
object and its references, which significantly slows down the
protected execution. As a special case, Oscar [18] makes
the freed objects inaccessible to achieve the same goal. A
more recent approach ignores the normal free request, and
utilizes spare CPU cores to independently identify and release
garbage objects (i.e., objects without any reference) [12, 29,
42]. This method requires extra computation resources, and
may have limited scalability.
The limitations of previous proposals led us to rethink the
defense against use-after-free bugs. Fundamental to exploit-
ing a use-after-free bug is the attackers’ ability to reclaim the
freed memory and modify its content before the program uses
it. As almost all memory managers reuse released memory
for subsequent requests to improve efficiency [21, 24, 25],
attackers can usually acquire the freed memory with trivial
effort [20, 46, 48]. For example, glibc caches freed chunks in
multiple linked lists (called bins) and reuses them to quickly
respond to future requests. However, if a memory manager
does not reuse any released memory, attackers will lose the
ability to control the memory content associated with a dan-
USENIX Association
30th USENIX Security Symposium    2453
gling pointer. The program may run normally or crash (e.g.,
the freed memory has been unmapped), but all exploitation
of use-after-free bugs will fail.
Inspired by this observation, we propose to resurrect one-
time allocation (OTA) to prevent successful exploitations of
use-after-free bugs. For any virtual address, an OTA allocator
will assign it to the program only once and will never reuse
it for other memory requests. In other words, every request
will get a distinct memory chunk and no one will ever overlap
with another. Note that an OTA allocator does not eliminate
use-after-free bugs, but renders all of them unexploitable.
Although the idea is straightforward, developing a practical
OTA manager is not easy. We identify three challenges that
have to be handled properly. First, OTA may introduce high
memory overhead. As the kernel manages memory at the
page level (i.e., 4096 bytes by default), OTA cannot release
the page as long as any byte is in use. In the worst case,
it may waste 4095 bytes per page. Second, OTA is limited
by the number of VMA structures in kernel. The Linux kernel
creates a VMA structure for each set of continuous pages, and
allows up to 65535 VMAs for each process. As OTA does not
reuse memory, the in-use pages will scatter sparsely, until the
process reaches the VMA limit. After that, the kernel cannot
release any pages that would split a VMA into two. Finally, OTA
may slow down the execution due to frequent system calls.
Without address reuse, the program will continuously exhaust
the pages allocated from the kernel, and have to make more
system calls (e.g., mmap) to request new pages.
Our solution to these challenges is two-fold. First, we blend
two allocation strategies to reduce the waste of memory and
mitigate the VMA issue. For small requests, we use a size-based
binning allocator to group similarly sized objects together;
for large requests, we handle them in a continuous manner
from a discrete region. By coalescing small allocations, we
avoid the worst-case memory usage: tiny islands in between
large allocations that hinder releasing pages and lead to heavy
overhead. Meanwhile, continuously allocating large objects
limits excess allocation to no more than minimal padding to
comply with alignment requirements. Similar solutions are
adopted by existing memory managers. However, we demon-
strate that it makes OTA, a commonly believed impractical
method, possible and useful. Second, we strategically batch
memory mapping and unmapping to minimize the number
of system calls. When FFmalloc requests memory from the
kernel, it will ask for a much larger region than immediately
necessary to handle the application’s requirement. The addi-
tional amount of memory is cached internally to answer future
requests. When the program frees memory, FFmalloc will not
immediately invoke system calls to release the region. Instead,
it will wait for several sequential freed pages and return them
together with one system call.
We implemented Fast Forward Memory Allocation
(FFmalloc), a prototype OTA, in 2,117 lines of C code.
FFmalloc requests 4MB memory at a time from the kernel,
and only releases freed memory when there are eight or more
contiguous pages. For memory requests of less than 2K bytes,
we use the binning allocator to group them together. For larger
requests, we simply return available memory sequentially.
We applied FFmalloc on common benchmarks and real-
world programs to understand its practicality and security.
Specifically, we used FFmalloc to protect nine programs with
eleven exploitable use-after-free bugs. With the protection
of FFmalloc, all exploits failed. Upon manual inspection, we
confirmed no overlap between any allocated objects. This
result shows that FFmalloc can effectively prevent use-after-
free attacks. To measure the overhead, we tested FFmalloc
on SPEC CPU2006 benchmarks, the PARSEC 3 benchmark
suite, the JavaScript engine ChakraCore, and the web server
NGINX. On average (geometric mean), FFmalloc introduces
2.3% CPU overhead and 61.0% memory overhead to SPEC
CPU2006 benchmarks. By comparison, the state-of-the-art
tool, MarkUs, adds 14.8% CPU overhead and 28.1% mem-
ory overhead to the same set of benchmarks. Meanwhile,
FFmalloc has 33.1% CPU overhead and 50.5% memory over-
head on PARSEC 3 benchmarks, while MarkUs introduces
42.9% CPU overhead and 13.0% memory overhead. FFmalloc
brings negligible overhead to ChakraCore, and provides simi-
lar performance as other secure allocators. These results show
that FFmalloc is a practical solution to protect real-world
programs against use-after-free exploits.
In summary, we make the following contributions:
• We propose to revive the idea of one-time allocation
(OTA) to prevent use-after-free attacks. OTA provides
efficient protection with a strong security guarantee.
• We designed and implemented FFmalloc, the first prac-
tical prototype of OTA, which supports both Linux and
Windows applications.
• We extensively evaluated FFmalloc. The results demon-
strate that OTA can be a practical way to protect real-
world applications against use-after-free attacks.
We will release the source code of FFmalloc at https:
//github.com/bwickman97/ffmalloc.
2 Problem Definition
2.1 A Motivating Example
Figure 1 shows an example of the use-after-free vulnerabil-
ity. The code defines two structures: Array to hold the user
input, and Parser for the parser function. Both structures
have the same size while Parser contains a function pointer
handler. Function handle_net_input first dynamically allo-
cates an instance of Parser and initializes its members, like
setting the handler to function net_parser. Then, it tries to
get a command from the client (line 18). If the command
is PARSE, it will allocate an instance of Array (line 23), and
will read untrusted user input from the client to the internal
buffer of array (line 24). Finally, it invokes the parsing func-
2454    30th USENIX Security Symposium
USENIX Association
// 32-byte
// 32-byte
Table 1: Consequences of use-after-free bugs. Depending on the
memory allocator and the program logic, attackers may launch severe
attacks, including code injection and information leakage.
Corresponding memory
After-free use
Exploitable?
S1
S2
S3
Inaccessible
Accessible & never reused
Accessible & reused
Crash
Get old content
Get new content
No
No (w/o metadata writing)
Possible
// allocation
// missing break;
// re-allocation
// content changes
// use-after-free
long status; void *start, *current;
int
(*handler)(void *buf);
Parser *parser = (Parser *)malloc(32);
parser->status = INIT;
parser->start = parser->current = NULL;
parser->handler = &net_parser;
1 typedef struct {long used; char buf[24];} Array;
2
3 typedef struct {
4
5
6 } Parser;
7
8 enum Command { INVALID, PARSE, ... };
9 int net_parser(void *buf);
10
11 int handle_net_input(int client_fd) {
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27 }}
Array *array = (Array *)malloc(32);
read(client_fd, array->buf, 24);
parser->handler(array->buf);
free(parser); break;
enum Command cmd = INVALID;
read(client_fd, &cmd, sizeof(cmd));
switch (cmd) {
case INVALID: free(parser);
case PARSE:
Figure 1: An example of use-after-free bugs. The parser object
is freed at line 23 if the command is INVALID, but is used at line 25
for the indirect call. This bug is exploitable as attackers can change
the object content at line 24 due to the memory reuse.
tion through parser->handler (line 25). If the command is
INVALID, the code will free the object parser (line 21). Due to
the lack of a break statement at line 21, the code at line 25 will
use the freed parser, leading to a use-after-free vulnerability.
This use-after-free bug is exploitable and attackers can
remotely execute arbitrary code. Specifically, when the ob-
ject parser is freed at line 21, the memory manager (e.g.,
glibc) will not immediately return the memory occupied by
parser to the operating system. When the code at line 23
requests an Array object, the memory manager will reallocate
the memory originally used by parser to array, as Array
has the same size as Parser. Now array and parser point to
the same memory location. The read function at line 24 will
fill the array->buf with the untrusted user input, which will
effectively overwrite the members of parser, including the
function pointer handler. When the code invokes the parser
handler, it will jump to any location specified by the attacker,
resulting in a control-flow hijacking attack.
2.2 Use-After-Free Bugs and Exploits
Use-after-free bugs may lead to different consequences de-
pending on the logic of the program and the memory manager.
We summarize the possible consequences in Table 1. If the
system has removed the permission to access the correspond-
ing memory (S1), the after-free use will trigger an access
violation and cause the program to crash. If the memory is
still accessible and the memory has not been reallocated to
other objects (S2), the obsolete content of the freed object
will be used. If in the interim the memory has been allocated
to other objects (S3), the content of the new object will be
used instead. In the last two cases, depending on the retrieved
value and its usage, the program may crash, produce wrong
results, or work “well” without any observable anomaly. The
example in Figure 1 falls into S3, where the new object array
occupies the memory originally allocated to parser.
A use-after-free in S3 is likely to be exploitable. A bug
in S1 is not exploitable as it always causes the program to
crash. In S2, the exploitability of the bug depends on the mem-
ory manager and the program logic. If the memory manager
makes no change to the freed region, the program will remain
well-behaved as the freed region continues to have a validly
formed object. Until the memory manager unmaps the page
(moving into S1), it is as if the application never freed the
object. However, if an allocator alters the freed block, like
storing some metadata, an attacker may abuse this behavior
to exploit the bug. For example, they might be able to modify
free list metadata to achieve arbitrary memory write [41]. By
contrast, in S3, an attacker can reclaim the memory and fill in
new content, thus affecting the following usages.
To exploit a use-after-free bug in S3, attackers have to
follow the pattern of free-reallocate-use. In the first step,
they trigger the program to free a vulnerable object. Then,
they request a similar-sized object to obtain the freed memory.
They fill the memory with contextually appropriate data. For
example, in Figure 1, attackers will overwrite the function
pointer handler in parser to a different address, like system.
Finally, when the program reads the memory, the malicious
content will be retrieved and used to launch the attack. In
Figure 1, the free-reallocate-use pattern can be mapped
to line 21, lines 23-24 and line 25.
2.3 Approach Overview
Of the three steps of a successful use-after-free exploit,
free-reallocate-use, reallocate is the most unique be-
havior triggered by attackers. If we can prevent the reuse
of freed objects, attackers will not be able to re-occupy the
freed memory and cannot change the content. In that case,
an exploitable use-after-free bug will not be exploitable any
more. While the program may run well, abnormally, or even
simply crash, it is out of the attacker’s control. We call this
memory management method one-time allocation (OTA).
Although the idea of OTA is straightforward, it is non-
trivial to build a practical OTA allocator. Previous works
explored ideas similar to OTA, but they either failed to
provide sufficient security or imposed unacceptable perfor-
USENIX Association