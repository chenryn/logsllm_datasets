bedded encryption key that users can download and store
in their browsers. When the bookmarklet is clicked on
the login page of a website, its code is injected into the
page; it retrieves encrypted login data from the password
manager website, decrypts it, and ﬁlls in the login form.
Even if the bookmarklet is accidentally clicked on a ma-
licious page that tampers with the JavaScript builtin ob-
jects and pretends to be a different website, the book-
marklet is meant to at most reveal the user’s password for
the current site. Indeed, several bookmarklets modiﬁed
their designs to guarantee this security goal in response
to previously found attacks [1]. However, we found sev-
eral new attacks on a number of these ﬁxed bookmarklets
that still enabled malicious websites to steal passwords,
the bookmarklet encryption key, and even the user’s mas-
ter encryption key.
Website JavaScript. Cloud storage services and crypto-
graphic web applications use JavaScript in the webpage
to decrypt and display ﬁles downloaded from the cloud.
Some of them (e.g. ConﬁChair ) use Java applets to im-
plement cryptography whereas others (e.g. Mega) rely
on reputed JavaScript libraries such as SJCL [37]. How-
ever, storing encryption keys securely during an ongo-
ing session remains an open challenge. ConﬁChair stores
keys in HTML5 localStorage; SpiderOak stores keys for
shared folders on the server, and Wuala stores encryption
keys in a hidden user ﬁle on the client. We found a CSRF
attack on SpiderOak, a client-side bug on Wuala, and an
XSS attack on ConﬁChair, all three of which allowed
malicious websites to steal a user’s encryption keys if
the user visited the website when logged into the corre-
sponding web application.
2.3 Summary
All the attacks described in this survey were responsi-
bly disclosed; most were found ﬁrst by us and ﬁxed on
our suggestion; a few were reported by us in previous
work [5, 6, 10]; some were reported and ﬁxed indepen-
dently. Our survey is not exhaustive, and many of the at-
tack vectors we employed are quite well-known. While
ﬁnding exploits on individual components took time and
expertise, the ease with which we were able to ﬁnd web
vulnerabilities on which we built these exploits was sur-
prising.
In many cases, these vulnerabilities were not
considered serious until we showed that they enabled un-
intended interactions with speciﬁc security components.
On the evidence of our survey, eliminating all un-
trusted contents and other web vulnerabilities from host-
ing websites seems infeasible.
Instead, security com-
ponents should seek to defend themselves against both
malicious websites and same-origin attackers on trusted
websites. Moreover, security checks in JavaScript com-
ponents are hard to get right, and a number of our attacks
relied on bugs in that part of the application logic. This
motivates a more formal and systematic approach to the
analysis of security-sensitive components.
3 DJS: Defensive JavaScript
In this section we deﬁne DJS, a subset of JavaScript that
enforces a strict defensive programming style using lan-
guage restrictions and static typing. DJS makes it possi-
ble to write JavaScript security components that preserve
their behavior and protect their secrets even when loaded
into an untrusted page after other scripts have tampered
with the execution environment.
We advocate using DJS only for security-critical code;
other code in the component or on the page may remain
in full JavaScript. Hence, our approach is more suited to
658  22nd USENIX Security Symposium 
USENIX Association
6
our target applications than previous proposals that seek
to restrict untrusted code (e.g. [16, 26, 39, 40] or require
trusted code to run ﬁrst (e.g. [2]).
The rest of the section informally describes the DJS
subset and its security properties; full formal deﬁnitions
can be found in the technical report [11].
3.1 Defensiveness
The goal of defensiveness is to protect the behavioral
integrity of sensitive JavaScript functions that will be
invoked in an environment where arbitrary adversarial
code has already run. How do we model the capabili-
ties of an adversary who may be able to exploit browser
and server features that fall outside JavaScript, such as
frames, browser extensions, REST APIs, etc?
We propose a powerful attacker model inspired by
the successful Dolev-Yao attacker [18] for cryptographic
protocols, where the network is the attacker.
In
JavaScript, we claim that the memory is the attacker. We
allow the attacker to arbitrarily change one (well-formed)
JavaScript memory into another,
thus capturing even
non-standard or undocumented features of JavaScript.
Without further assumptions, this attacker is too pow-
erful to state any property of trusted programs. Hence,
like in the Dolev-Yao case where the attacker is as-
sumed unable to break encryption, we make the reason-
able assumptions that the attacker cannot forge pointers
to memory locations it doesn’t have access to, and that it
cannot break into the scope frames of functions. This as-
sumption holds in principle for all known JavaScript im-
plementations, but in practice it may fail to hold because
of use-after-free bugs or prototype hijacking attacks [22].
Let a heap be a map from memory locations to
language values,
including locations themselves (like
pointers). We often reason about equivalent heaps up
to renaming of locations and garbage collection (re-
moval of locations unreachable from the native ob-
jects). Let an attacker memory be any well-formed re-
gion of the JavaScript heap containing at least all na-
tive objects required by the semantics, and without any
dangling pointer. Let a user memory be any region
of the JavaScript heap that only contains user-deﬁned
JavaScript objects. A user memory may contain pointers
to the attacker memory. Let attacker code and user code
be function objects stored respectively in the attacker and
user memories.
Assumption 1 (Memory safety).
In any reasonable
JavaScript semantics, starting from a memory that can
be partitioned in two regions, where one is an attacker
memory and the other a user memory, the execution of
attacker code does not alter the user memory.
User code cannot run in user memory alone because it
lacks native objects and default prototypes necessary for
JavaScript executions. For that reason, we consider user
code that exposes an API in the form of a function that
may be called by the attacker. Let a function wrapper
be an arbitrary JavaScript expression E parametric in a
function deﬁnition F, which returns a wrapped function
GF. GF is meant to safely wrap F, acting as a proxy to
call F. For example:
var F = function(x) {
1 E = (function() {
2
3
4
5
6 })();
var secret = 42, key = 0xC0C0ACAFE;
return x===key ? secret : 0 }
return function G_F(x) {return
F(x>>>0) }
We now informally deﬁne the two properties that cap-
ture defensiveness of function wrappers:
Deﬁnition 1 (Encapsulation). A function wrapper E en-
capsulates F over domain D if no JavaScript program
that runs E can distinguish between running E with F
and running E with an arbitrary function F(cid:31) without call-
ing the wrapped function GF. Moreover, for any tuple
of values ˜v ∈ D, the heap resulting from calling GF( ˜v) is
equivalent to the heap resulting from calling F( ˜v).
In other words, encapsulation states that an attacker
with access to GF should not learn anything more about
F than is revealed by calling F on values from D. For
example, if the above E encapsulates the oracle F (lines
2-4) on numbers, an attacker may not learn secret un-
less it is returned by F, even by trying to tamper with
properties of GF such as arguments, callee...
The next property describes the integrity of the the
input-output behavior of defensive functions:
Deﬁnition 2 (Independence). A function wrapper E pre-
serves the independence of F if any two sequences of
calls to GF, interleaved with arbitrary JavaScript code,
return the same sequence of values whenever corre-
sponding calls to GF received the same parameters and
no call to GF triggered an exception.
This property is different from functional purity [19]:
since F may be stateful, it is not enough to enforce single
calls to GF to return the same value as arbitrary call se-
quences must yield matching results. Note that GF is not
prevented by this deﬁnition form causing side-effects on
its execution environment. For example, E given above
can still satisfy independence even though it will cause
a side effect when GF is passed as argument the object
{valueOf:function(){window.leak=42;return 123}}.
The above F (lines 2-4) returns its secret only when
passed the right key, and does not cause observable side-
effects. If E encapsulates F over numbers and preserves
its independence, then an attacker may not learn this se-
cret without knowing the key.
7
USENIX Association  
22nd USENIX Security Symposium  659
(cid:31)djs-program(cid:30) ::= ‘(function(){’
‘ var _ = ’ (cid:31)function(cid:30) ‘;’
‘ return function(x){’
‘ if(typeof x == "string") return _(x);’
‘}})();’
|
|
|
|
|
|
|
|
|
|
|
|
(cid:31)function(cid:30) ::=
‘function(’ (@identiﬁer ‘,’)*‘){’
(‘var’ (@identiﬁer (‘=’ (cid:31)expression(cid:30))? ‘,’)+)?
((cid:31)statement(cid:30) ‘;’)*
(‘return’ (cid:31)expression(cid:30))? ‘}’
(cid:31)statement(cid:30) ::= ε
‘with(’ (cid:31)lhs expression(cid:30) ‘)’ (cid:31)statement(cid:30)
‘if(’ (cid:31)expression(cid:30) ‘)’ (cid:31)statement(cid:30)
(‘else’ (cid:31)statement(cid:30))?
‘while(’ (cid:31)expression(cid:30) ‘)’ (cid:31)statement(cid:30)
‘{’ ((cid:31)statement(cid:30) ‘;’)* ‘}’
(cid:31)expression(cid:30)
(cid:31)expression(cid:30) ::= (cid:31)literal(cid:30)
(cid:31)lhs expression(cid:30) ‘(’ ((cid:31)expression(cid:30) ‘,’)* ‘)’
(cid:31)expression(cid:30) (cid:31)binop(cid:30) (cid:31)expression(cid:30)
(cid:31)unop(cid:30) (cid:31)expression(cid:30)
(cid:31)lhs expression(cid:30) ‘=’ (cid:31)expression(cid:30)
(cid:31)dyn accessor(cid:30)
(cid:31)lhs expression(cid:30)
(cid:31)lhs expression(cid:30) ::=
| @identiﬁer | ‘this.’ @identiﬁer
(cid:31)lhs expression(cid:30) ‘[’ @number‘]’
|
(cid:31)lhs expression(cid:30) ‘.’ @identiﬁer
|
(cid:31)dyn accessor(cid:30) ::=
((cid:31)x(cid:30) = @identiﬁer) ‘[(’ (cid:31)expression(cid:30)
‘>>> 0) %’ (cid:31)x(cid:30) ‘.length ]’
‘(’ ((cid:31)y(cid:30) = @identiﬁer) ‘>>>=0)>’ | ‘>>’
‘&&’ | ‘||’ | ‘==’ | ‘!=’ | ‘>’ | ‘=’ | ‘;
return function(x){
1 (function(){
2
3
4
5 })();
if(typeof x == "string") return _(x)}
For simplicity, functions must begin with all their local
variables declarations, and end with a return statement:
1 function (,...,){
2
3
4
var  = ,..., = ;
return }
Our type system further restricts DJS statements and ex-
pressions as described below.
Preventing External References. DJS programs may
not access variables or call functions that they do not
deﬁne themselves. For example, they may not access
DOM variables like document.location, call global func-
tions like encodeURIComponent, or access prototype func-
tions of native objects like String.indexOf.
This restriction follows directly from our threat sce-
nario, where every object not in the defensive program is
in attacker memory and may have been tampered with.
So, at the very least, values returned by external refer-
ences must be considered tainted and not used in defen-
sive computations to preserve independence. More wor-
ryingly, in JavaScript, an untrusted function that is called
by defensive code can use the caller chain starting from
its own arguments object to traverse the call stack and ob-
tain direct pointers to defensive objects (inner functions,
their arguments objects, etc.), hence breaking encapsula-
tion. Some countermeasures have been proposed to pro-
660  22nd USENIX Security Symposium 
USENIX Association