access-list 105 ip 0.0.0.0 255.255.255.255 0.0.0.0 255.255.255.255
Figure 11: Real-life example of a multi-match group with multi-match
degree of 8. ip rules will match tcp rules as well, since TCP is an IP-
based protocol.
and the same search key is issued again. The process is repeated till
the required number of (or no more) matches are found.
The total number of cycles taken for (cid:2)nding k matches is
k:(Tinvalidate write cycle +Tsearch cycle +Trevalidate write cycle).
The search operation typically takes a single cycle while writes take
3 cycles. Hence, the total number of cycles per multi-match is 7.
The entry-invalidation scheme alters the state of the database
during the course of the algorithm. Hence, it is infeasible to use this
scheme in a multi-threaded environment such as today’s packet pro-
cessors, where searches are issued from multiple packet processing
threads that have simultaneous access to the TCAM device.
To support multiple threads, the entry-invalidation scheme can
be extended trivially to use many valid bits per TCAM entry, with
each valid bit keeping track of a single thread (independent of the
other bits). However, as the number of threads increases (today’s
packet processing systems support at least 64 threads and the num-
ber is rising), the overhead of the valid bits becomes prohibitive.
For example, the Intel IXP2800 network processor supports up to
256 threads [10]. Since the width of each TCAM entry is (cid:2)xed and
allocated in discrete quantities (72, 144, 288 or 576 bits), allocat-
ing a large number of bits as valid bits might not be feasible as it
would severely affect the size of databases that can be stored.
4.1.2 Geometric Intersection-based Scheme
The scheme described in [25] constructs the set of matching ge-
ometric intersections (cross-products) of (cid:2)elds and places them in
the TCAM. While this elegant scheme has a high search through-
put, it does not scale well in capacity(cid:151)the number of TCAM en-
tries needed per rule in an ACL might be very large. For all the 112
ACLs in our database, we noticed an expansion factor of 25-100.
For example, we found a real-life ACL of 32 rules leading to 11263
TCAM entries.
In the next section, we present our multi-match scheme, which
in multi-threaded systems, provides deterministic
works well
worst-case search bounds and scales in memory usage.
4.2 Multi-match Using Discriminators (MUD)
We (cid:2)rst present the basic idea behind MUD. Let the result of
searching a TCAM with a key be the rule with index j. To get
the next matching result from the TCAM, we need to perform the
search on all the entries after index j. To accomplish this, we use
a simple idea: along with each TCAM entry, store a discriminator
(cid:2)eld that encodes the index of that entry. The TCAM entries after
Multi-Match MUD (key)
Initialize discriminator pre(cid:2)x list:
D   f‘xx : : : xx’g
while (D is not empty)
d   D:pop(). Let d represent the range [s; e].
R   T CAM Search(d; key)
if (R != NULL)
Let i be the index of rule R
Let D0 be the set of discriminator pre(cid:2)xes
for the range [i + 1; e]
D   D:push(D0)
end-while
return TCAM Match List
Figure 12: MUD search logic in the packet processor interfacing with
TCAMs. The control plane software sets up the TCAM entries and
chooses discriminators for each of the entries appropriately.
index j have discriminator (cid:2)eld values that are greater than j. We
expand ‘> j’ to pre(cid:2)xes, and specify these pre(cid:2)xes in the discrimi-
nator (cid:2)eld in subsequent searches to search through the TCAM en-
tries that appear after j. The bene(cid:2)ts that MUD offers(cid:151)support for
multi-threaded environment and low update cost(cid:151)come at the ex-
pense of search cycles; however, as we show in Table 8, MUD can
still support multi-match classi(cid:2)cation at multi-gigabit link speeds.
To specify pre(cid:2)xes in the search key, we use a well-known search
capability called global masking that TCAMs provide. When a key
is searched, TCAMs allow each bit position to be masked out, i.e.,
set to x. If a bit position is masked out, then that bit position in
the key will not be compared against the corresponding bit in each
entry, but will be deemed to have matched. For example, using a
global mask xxxx111 would mean that only the 3 least signi(cid:2)cant
bits are actually compared, and the 4 most signi(cid:2)cant bits are not
compared.
We now describe the algorithm in detail. To the original set of
rules, R1; : : : ; RN, we prepend a discriminator (cid:2)eld of d bits which
indicates the index of the rule within the ACL; i.e., rule Ri will have
the value i in the (cid:2)eld. The minimum number of bits required for
the discriminator (cid:2)eld for a database with N rules is d = log2 N.
When the search for a key S starts, the discriminator (cid:2)eld in the
key is masked out completely, resulting in the entire database being
searched. Let the (cid:2)rst match be rule Rj. The next search has to con-
sider rules with index greater than j, i.e., rules with discriminator
greater than j. By using discriminators we have reduced the multi-
match problem to the range representation problem. In the case of
DIRPE, the rules had ranges that had to be represented as ternary
strings. In the case of MUD, the discriminator in the search key has
a range that needs to be represented as ternary strings.
Let us consider an example in which we use 4 bits for the dis-
criminator (cid:2)eld (i.e., the database has at most 16 entries). Let the
(cid:2)rst match occur at index 5 (i.e., 0101). The discriminator pre(cid:2)xes
needed for searching the rest of the database (starting from index
6) are 011x and 1xxx, representing the ranges [6; 7] and [8; 15] re-
spectively. If any match is found with any of these two pre(cid:2)xes as
the discriminator (cid:2)eld in the search key, then the process is repeated
recursively.
Figure 12 shows the steps that are needed to issue search keys
for locating matches(cid:151)it is very simple and can be easily included
in any device interfacing with the TCAM.
4.3 Improving Performance of MUD
We now describe a few optimizations for improving the perfor-
mance of MUD.
4.3.1 Assigning Discriminators to Sets of Entries
In the baseline MUD scheme, for a database with N rules, each
rule is given unique discriminator values between 0 and N (cid:0)1, re-
sulting in log2 N bits for the discriminator (cid:2)eld. We present an
optimization based on the following intuition: if several rules can
be grouped into a set such that any search key can match at most
one rule in this set, then all the rules in this set can be given the
same discriminator value. For example, for getting all the matches
from a database of pre(cid:2)xes, we would set the discriminator value
to be the length of a pre(cid:2)x. This is because any key can match only
one pre(cid:2)x among the pre(cid:2)xes of the same length.
A mask of a rule is a bit string indicating the location of speci(cid:2)ed
bits (0 or 1) and wildcard bits (x) in the rule. To compute the mask,
a 0/1 in the rule is replaced with a 1 and an x is replaced with
a 0. For example, two rules 10x11xx0 and 11x01xx1 have the
same mask 11011001. In an ACL database, there can only be one
matching entry among rules with the same mask. Hence, the same
discriminator value can be assigned to all entries with the same
mask. This optimization would reduce the number of bits needed
for the discriminator to log2(number of distinct masks). However,
since order of multi-matches is not retained, for obtaining the (cid:2)rst
k matches, one would need to (cid:2)nd all matches and pick the (cid:2)rst k.
Our database has 215183 rules, which when expanded us-
ing range-to-pre(cid:2)x conversion correspond to 1694 distinct masks.
Hence, for our database, the discriminator (cid:2)eld can be encoded us-
ing 11 bits.
4.3.2 Assigning Discriminators using DIRPE
To represent N discriminator values (which could be the number
of unique masks), at least log 2 N bits are needed. We now show
that, by using a wider representation for the discriminator, we can
reduce the worst-case number of searches.
Recall that to address the range expansion problem, we proposed
DIRPE, which reduced the expansion of ranges by using additional
bits. Analogous to the range expansion problem in which ranges
appear in the ACL rules and are mapped to multiple TCAM en-
tries, in the multi-match problem the ranges appear in the search
key leading to multiple TCAM searches. Drawing from the anal-
ogy, for MUD, we can use the DIRPE algorithm to encode the dis-
criminator keys corresponding to searching the range ‘> j’, thus
reducing the worst-case number of searches. Hence, even though
the minimum number of discriminator bits needed is log2(number
of distinct masks), by using DIRPE, we can add extra bits to reduce
the worst-case number of searches.
Furthermore, in the case of MUD, since only ranges of the type
‘> j’ are needed, the worst-case number of ternary entries is equal
to the number of chunks used in DIRPE.
d = log2(number of unique discriminator values) is the mini-
mum number of bits needed for the discriminator (cid:2)eld. Dividing
this into chunks of r bits each gives d=r chunks. Note that MUD
issues several searches to cover all chunks. Hence we use the fol-
lowing encoding for the discriminator (cid:2)eld: log2(d=r) bits to indi-
cate the chunk-id, d (cid:0) r bits to represent the bits leading up to the
chunk and 2r (cid:0) 1 bits to encode the range in the chunk. Thus, the
discriminator width, d0, is log2(d=r) + d (cid:0) r + 2r (cid:0) 1.
Table 8 shows the links speeds that can be supported for vari-
ous values of unique discriminators, number of discriminator bits
using DIRPE and number of matches per multi-match. The main
trend we observe is that for the same number of unique discrimina-
# of Unique
Disc. Values
512
512
512
512
512
512
2048
2048
Max. matches
per multi-match
4
4
4
5
5
5
4
4
9
13
15
9
13
15
11
15
Link Gbps
Disc. width
using DIRPE with MUD
2.40
5.00
7.81
1.84
3.91
6.25
1.95
4.03
Table 8: Link speed for ﬁnding all matches using the MUD scheme
for different values of discriminator bits. We assume a base TCAM
throughput of 125 million searches per second. Minimum size packet
size = 64 bytes for wire speed operation (See [1]). 5MPPS corresponds
to 2:5Gbps.
tors, greater the number of discriminator bits used (using DIRPE),
higher is the link speed that can be supported. For example, com-
pare the (cid:2)rst three rows of the table. Also, the trend is independent
of the number of discriminator values (see last two rows of the ta-
ble for links speeds with 2048 unique discriminators) and the num-
ber of multi-matches (rows 4-6 show the same trend for 5 multi-
matches). Since MUD does not increase the number of TCAM en-
tries, we can replicate the tables if higher search throughput is de-
sired.
4.3.3 A Set Pruning-Based Approach
We also considered an algorithm that is based on set pruning ap-
proach for improving the performance of MUD. The algorithm is
based on the simple idea: When some matches are found, the to-
tal number of entries that can possibly match the search key must
reduce. Hence, after (cid:2)nding the (cid:2)rst few matches, if the list of po-
tential matches is small, then they can be searched quickly by a
linear search.
De(cid:2)ne a pruned set as the list of entries that can potentially
match a key after i matches are found. Denote the size of the largest
such pruned set after i matches by Hi. Using the real-life database,
we found that Hi does not decrease below 10 till several matches
are found (see Figure 13). In addition, the time for precomputation
of pruned sets was also very large. Though this simple heuristic
proved ineffective, our experiments shed some light on the charac-
teristics of real-life databases.
4.4 Comparative Analysis of MUD and Other
Schemes
Table 9 presents the comparison of MUD with earlier approaches
based on the metrics in Section 2.1. The invalidation scheme does
not work well in multi-threaded systems. Both the invalidation
scheme and MUD require only one TCAM entry per rule, but the
geometric intersection scheme does not scale well in the worst-case
number of TCAM entries needed per rule. Even for the real-life
database we used, for all the 112 ACLs, the expansion factor was
between 25 and 100.
When rules change, updating ACL tables has traditionally in-
volved manual intervention, and hence the ability to perform incre-
mental updates has not been a serious requirement. But with the
adoption of automated intrusion detection, there is an increasing
need to update the tables incrementally. For MUD, the discrim-
inator (cid:2)eld in the entries need to be updated with their new in-
dex location. Hence, both the entry-invalidation scheme and the
MUD scheme support high update rates(cid:151)cost of updating N rules
is O(N ) (cid:151)same as that required to maintain the entries for sin-
gle match classi(cid:2)cation. Update rates of few ten thousand up-
 (cid:13)
h
t
i
r
e
t
f
a
t
e
s
d
e
n
u
r
p
e
h
t
f
o
e
z
i
S
=
)
i
(
H
h(cid:13)
c
t
a
m
350(cid:13)
300(cid:13)
250(cid:13)
200(cid:13)
150(cid:13)
100(cid:13)
50(cid:13)
0(cid:13)
1(cid:13)
3(cid:13)
2(cid:13)
5(cid:13)
i = Number of Matches found(cid:13)
4(cid:13)
6(cid:13)
 (cid:13)
h
t
i
r
e
t
f
a
t
e
s
d
e
n
u
r
p
e
h
t
f
o
e
z
i
S
=
)
i
(
H
h(cid:13)
c
t
a
m