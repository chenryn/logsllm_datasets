5
12
6
2
3
2
3
1
2
1
3
Org.
1
0
0
0
0
1
0
0
0
0
9
3
1
0
0
2
0
1
0
0
# ASN
1
1
1
1
1
1
2
1
1
2
1
1
1
2
1
2
1
2
1
2
IPs
Res.
0
0
0
0
0
0
0
0
0
0
0
0
0
1
1
0
1
0
0
0
Bot
1
1
1
1
1
1
3
1
1
5
3
3
1
3
2
1
1
1
1
3
Prov.
1
1
1
1
1
1
2
1
1
2
1
1
1
1
0
2
0
2
1
2
TABLE V: Analysis of access logs considering IP and User-
Agent for each social media platform
by concealing the URL of the ﬁnal page with a redirections.
We implemented both server-side redirections with 303 and
307 status codes, and client-side redirections either via HTML
tags or via JavaScript code. The results of our analysis are not
in Table III, and we report them in this section brieﬂy. All
platforms correctly handle server-side redirections. Facebook
is the only platform supporting client-side redirections (both
HTML and JavaScript ones). Overall, the link preview does
not differ signiﬁcantly from the previews created when posting
direct links.
B. Network Signatures
After analyzing the displayed information, we look for
unique signatures in the incoming HTTP requests. Our goal
is to identify distinguishing features that can be used by the
owner of a web page to determine when the incoming request
originates from a social media platform. For this analysis, we
process the entries in our server log ﬁles to identify such
signatures.
In general, when sharing URLs to our pages on social
networks, we should expect that other users may click on
the link previews, introducing spurious entries in our logs. To
avoid the presence of user activities, we limited the visibility
of our posts whenever a platform supports such a feature. Only
two platforms do not support access restrictions, i.e., Medium
and Plurk; however, upon manual inspection, we veriﬁed our
logs did not contain any user activity but only requests from
both platforms. Finally, we point out that the same concern
does not apply for IMs as messages are visible only to the
recipient, that, in our setting, is another user under our control.
log ﬁles, we parsed all entries and ex-
tracted the user-agent strings and the IPs. We compared
user-agent strings against known strings for browsers, and
we looked for substrings that can be used to identify
a platform uniquely. An example of
these substrings is
From our
6
“facebookexternalhit” for Facebook or “vkShare;
+http://vk.com/dev/Share” for VK. When the user
agent contains such unique strings, we classify the entry as bot.
When the user-agent string matches one of the known user-
agent strings of browsers, we classify the entry as organic.
Then, starting from the collected IPs, we resolved the au-
tonomous system numbers (ASNs) and searched the AS name
strings for unique substrings. For example, Facebook’s re-
quest originate from AS 32934, whose name is “Facebook,
Inc.”. However, not all platforms manage an autonomous
system, but they may be relying on third-party providers. For
example, Pinterest’s requests originate from AS 14618, whose
name is “Amazon AES”. When the autonomous system name
matches the name of a platform or a known network provider,
we classify the entry as a service provider.
Table V summarizes the results of our analysis. All the
20 social media platforms under test use at least one user
agent string linked to the name of the company or the service
itself, allowing for immediate trafﬁc ﬁltering. Of these, 13
platforms use only one user-agent header, and seven platforms
(Xing, Medium, Instagram, Messenger, Snapchat, Whatsapp
and Slack) use multiple ones. Seven platforms (Facebook,
Pinterest, Instagram, Messenger, Skype, Line, and KakaoTalk)
request web pages using user-agent strings that are indis-
tinguishable from browsers, posing a potential problem for
the identiﬁcation. However, the analysis of the IPs and the
ASes provides a stronger signal than user-agents. As a matter
of fact, all platforms perform HTTP requests from IPs of
either one or two autonomous systems that can be linked
to the platforms. Three instant messaging apps (Whatsapp,
Snapchat, Viber) request resources directly from the user’s
phone, slightly increasing the difﬁculty in distinguishing if the
visitor is organic or not, as the AS usually is from a residential
area; nonetheless, all three of them include the app name in the
user-agent string, so we can categorize the respective entries
as bots.
C. Link Preview Coherence
The ﬁnal analysis of this section investigates the coherence
between the link preview and the web page. In particular, we
are interested in studying the ways social media platforms
keep up to date the link previews in which a page changes
over time. To this end, we generated new, unique URLs,
one for each platform, and posted them. Then, we developed
a bot controlling a pool of web browsers which is visiting
periodically (every 30m) the platforms’ pages showing the
preview, over a period of 14 days. As IMs messages are
expected to be short lived, we did not consider them for these
experiments.
The analysis of our logs revealed that eight out of 10 social
networks request the page at least once on the submission
date, and never again. Twitter and Pinterest are two exceptions,
requesting the web page multiple times across a period of 14
days. For what concerns the associated resources, seven social
networks requested them only once at submission time, and
never again. The remaining three platforms, i.e., Facebook,
Twitter and LinkedIn, request the link preview images more
regularly.
D. Takeaway
The analysis of this section shed some light on three key
aspects of social media platforms when creating a link preview.
To summarize, this section makes the following ﬁndings:
•
•
•
Social media platforms rely unconditionally on meta
tags for rendering previews, especially on the Open
Graph markup language. When meta tags are not
present, link previews display ﬁelds in an inconsistent
manner, exposing users to a great variety of heteroge-
neous link preview templates. As a result of all this, we
speculate that users are misled into taking the wrong
security decision. Also, the heterogeneity of templates
and inconsistent use of ﬁelds may fail in building a
secure mental model of link preview outlooks.
Platforms’ requests contain distinguishable signatures
that can be used by web sites owners to determine
when a request originates from social media platforms.
This is a required feature to enable cloaking attacks.
The temporal analysis reveals that platforms tend to
fetch the resources for the link preview very rarely
over a period of 14 days. A longer time window may
show a different behavior, however, it should be noted
that 14 days is sufﬁcient for a successful malicious
campaign.
IV. MALICIOUS CONTENT AND USER AWARENESS
Section III studied the behavior of social media platforms
when sharing links to benign web content. However, as ob-
served by prior work, adversaries can also share malicious
content on social media platforms such as phishing pages (see,
e.g., [29], [32]). Anecdotal evidence suggests that social media
platforms, social networks in particular, may have deployed
defenses to counter the spread of malicious content in their
systems. For example, Twitter claims to match shared links
against a database of potentially harmful URLs [36] and to
additionally use their shortening service to interpose informa-
tive safeguarding pages in between https://t.co links and
their malicious targets. Facebook reports the employment of
dedicated teams and tools against spam on the platform [12],
as well as anti-virus measures in the ﬁle upload and download
processes [10].
The second analysis of this paper studies the presence
and effectiveness of possible deployed countermeasures when
sharing malicious URLs. Also, our analysis reviews the created
link previews to evaluate to what extent users may be aware
of the risk of clicking on previews of malicious links. In this
section, we leverage on the knowledge acquired during the
observations of Section III, which we will use as a behavioral
baseline to compare social media platforms behavior when
dealing with malicious content. Our focus is not built on the
attacker’s perspective, rather on the observation of existing
active or passive countermeasures preventing the distribution
of malicious content; the most ﬁtting scenario is the one of
malware and phishing spread prevention.
Experimental Setup: The experiments of this section
involve sharing links to two types of malicious content to
check for the presence of different countermeasures. First,
7
Sharing Type
Social Networks
Instant Messengers
Test
Direct
Resource
Virut/EICAR
Blacklisted URL
Client Red.
Virut/EICAR
Blacklisted URL
Server Red.
Virut/EICAR
Blacklisted URL
k
o
o
b
e
c
a
r
e
t
t
i
w
T
k
V
n
I
d
e
k
n
i
L
t
s
e
r
e
t
n
i
P
r
l
b
m
u
T
m
u
i
d
e
M
g
n
i
X
k
r
u
l
P
e
W
M
e
Observ. F
Posted
-
-
-
-
(cid:32)
(cid:32)
Posted
Posted
(cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32)
Preview (cid:32) (cid:35) (cid:72)(cid:35) (cid:35) (cid:72)(cid:35) (cid:72)(cid:35) (cid:35) (cid:32) (cid:35) (cid:72)(cid:35)
(cid:32) × (cid:32) (cid:32) (cid:32) (cid:32)
Preview (cid:32) (cid:35) (cid:32) × (cid:32) (cid:72)(cid:35)
(cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32)
Preview (cid:32) (cid:32) (cid:32) (cid:35) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32)
(cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32)
Preview (cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32)
(cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32)
Preview (cid:32) (cid:35) (cid:72)(cid:35) (cid:35) (cid:72)(cid:35) (cid:72)(cid:35) (cid:35) (cid:32) (cid:35) (cid:72)(cid:35)
(cid:32) × (cid:32) (cid:32) (cid:32) (cid:32)
Preview (cid:32) (cid:35) (cid:32) (cid:35) (cid:72)(cid:35) (cid:72)(cid:35)
Posted
Posted
Posted
(cid:32)
(cid:32)
(cid:32)
(cid:32)
-
-
-
-
-
-
-
-
m
a
r
g
a
t