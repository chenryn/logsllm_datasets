optimized TFHE implementation merely improves the ﬁnal
summation of risk factors by using a tree of adders. While
our naive SEAL implementation also uses a ripple-carry-
adder, we also implemented an optimized version where we
implemented a Sklansky-adder, which trades off additional
operations for lower depth. In the optimized version, we also
made heavy use of in-place and plaintext-ciphertext versions of
the homomorphic operations, simpliﬁed expressions as much
as possible, and manually determined optimal parameters.
Finally, we implemented an optimized batched variant, which
required signiﬁcant changes to the computation structure, i.e.,
transforming all ten conditions into the form a && b < c
by introducing dummy values and operations.
Cingulata makes the implementation signiﬁcantly more
straight-forward as it contains built-in circuits for common
operations such as addition, multiplication, and comparisons.
Therefore, the program is virtually identical to its plaintext
counterpart. However, the compilation process is complex,
and the interactions between the compiler and runtime system
are not well documented. This made it hard to integrate the
different mult-depth reduction techniques available, and it
required signiﬁcant amounts of trial-and-error to determine,
e.g., how Cingulata differentiates between secret and plaintext
inputs in the circuits it generates.
E3 offers a similar and even arguably more powerful API
than Cingulata. For example,
it supports both binary and
arithmetic plaintext spaces and can switch ciphertexts between
them. In a similar vein, very few changes were needed to
re-target our SEAL (BFV) implementation to TFHE (CGGI).
However, an initial
lack of documentation and very long
compile times made developing and debugging applications
difﬁcult. While E3 features some support for batching, this
is quite limited. Speciﬁcally,
include rotation
operations that are essential to fully express the program’s
it does not
3https://github.com/MarbleHE/SoK.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:31:21 UTC from IEEE Xplore.  Restrictions apply. 
1101
batched version. Therefore, the E3 batched version remains
somewhat incomplete.
2) Chi-Squared Test: The Chi-Squared test, at least as re-
formulated in our application, uses only addition and multi-
plication over integers, making it ideally suited for integer-
based FHE schemes. Nevertheless, we also consider imple-
mentations targeting binary emulation for comparison. We
manually implemented the application in SEAL, targeting the
BFV schemes and an integer plaintext space. In our optimized
version, we manually select optimal parameters, use in-place
operations where possible and reuse common sub-expressions.
Our manual implementations in SEAL closely match the math-
ematical description as all operations are native operations.
Nevertheless, both the naive and the optimized implementation
required over 100 lines of code. Our TFHE-based manual
implementations additionally required implementing a binary
adder and multiplier to support the computation, resulting in
several hundred lines of code. EVA, in contrast, allowed us to
easily express the same computation in around a dozen lines
of code. While the EVA implementation targets CKKS, the
precision is sufﬁcient to ensure that, when rounding back to
integers, the result perfectly matches the other BFV/integer-
based implementations. While Cingulata supports the BFV
scheme, it only supports binary plaintext spaces. Therefore, it
must also emulate integer multiplications using binary circuits.
However, since it hides the complexity of generating efﬁcient
circuits from the user, this matters only for performance, not
for usability. Both Cingulata and E3 can target integer-based
BFV and binary CGGI with minimal changes required. Note
that batching this application would be trivial but only impacts
throughput, not latency, and is therefore omitted.
3) NN-Inference: The MNIST problem is comparatively
easy to solve, with simple approaches easily achieving more
than 90% accuracy and even small neural networks achiev-
ing around 95% accuracy. State-of-the-art networks achieve
up to 99.5% test accuracy. However,
increasing accuracy
quickly requires exponentially more complex models. In our
evaluation, we used three different model architectures of
increasing complexity. First, we used a simple Multi-Layer
Perceptron (MLP) as a baseline, i.e., two fully connected
layers with a non-linear activation. Next, we consider a more
complicated Convolutional Neural Network (CNN), speciﬁ-
cally the Cryptonets architecture [79] designed speciﬁcally for
FHE, which consists of 5 layers and two activations. Finally,
we also evaluated a LeNet-5-like [80] network, which is a
signiﬁcantly more complex design and more representative
of networks used to solve challenging tasks in practice. This
network consists of 7 layers and three activations. We use
a technique from [67] and learn a degree-two polynomial
approximation of the ReLU activation function during training.
SEALion and nGraph-HE focus exclusively on machine
learning inference, directly using TensorFlow programs or
TensorFlow-like programs as their inputs. While SEALion
can currently only express a simple MLP network, nGraph-
HE seems to support the full TensorFlow feature set. Both
make FHE-based development nearly as easy as working with
standard TensorFlow. While EVA does not directly support
machine learning tasks, the CHET tool can be re-targeted to
EVA, and we consider an EVA program for a LeNet-5 model
generated by CHET, in addition to a manually implemented
MLP. We complemented the comparison between the tools
with a baseline implementation of an MLP in SEAL, using
the CKKS scheme and manually implementing matrix-vector-
product optimizations from [43], which required signiﬁcant
engineering effort.
C. Effects of Optimizations
1) Cardio:
This section presents the results of our benchmarks, with a
particular focus on the effect that automation and optimization
have on runtime. All benchmarks run on an AWS instance
(m5n.xlarge), equipped with 4 vCPUs and 16 GB RAM. The
reported results are mean values computed over 10 test runs.
In Figure 2, we report the run time for the
cardio risk factor assessment application in different setups.
We see a large span of results, between less than 5 seconds for
the manual optimized implementation and over three minutes
for the slowest tool-generated implementations. E3 seems to
introduce signiﬁcant overheads, even when compared to naive
implementations targeting the same library. Cingulata’s BFV
implementation (CinguBFV) seems considerably slower than
SEAL’s, but we can still observe the effect of the different
depth-reduction approaches, with multi-start (E) cutting com-
putation time in half. Comparing our manual implementations,
we see both of our TFHE implementations outperforming the
naive and (non-batched) optimized SEAL implementation as
expected. Cingulata’s TFHE implementation actually further
outperforms our manually optimized TFHE implementation,
even when our manual program uses fewer gates. This speedup
might be due to better memory management or due to slightly
different TFHE environments. However, by far the best perfor-
mance is achieved when using batching in SEAL, even though
this application is inherently binary-based and ten conditions
are a relatively small number to batch in the context of FHE.
2) Chi-Squared Test: In Figure 3, we present the runtimes
for the chi-squared test application, using a logarithmic scale
due to the large range of values. We contrast manually- and
tool-generated implementations targeting SEAL and TFHE
and compare this against Cingulata’s implementation targeting
the built-in BFV implementation. The manually optimized
SEAL implementation and EVA-generated implementation
outperform the others by a large margin, requiring less than
a second. With 16.46 s, a slowdown of more than 10×,
the E3 program targeting SEAL is signiﬁcantly slower, but
the overhead compared to the naive solution is negligible.
Meanwhile, Cingulata targeting CinguBFV suffers from both
using binary emulation unnecessarily and a generally slower
BFV implementation. Since the program already has minimal
depth, we omit a discussion of the different depth-reduction
heuristics here. Similarly, our TFHE optimizations seem to
have no positive effect on this simple program, while Cingulata
is again faster per-gate in TFHE, possibly due to conﬁguration
differences. Finally, we note that the TFHE implementation
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:31:21 UTC from IEEE Xplore.  Restrictions apply. 
1102
Figure 2: Runtime of the cardio benchmark. We group com-
piler generated and manually optimized and naive programs
by the FHE implementation they target. For CinguBFV, we
consider circuits using different depth-optimization approaches
(A: baseline, B: ABC, C: Lobster, D: Cingulata, E: Multi-
Start). * indicates batching was used.
Figure 3: Runtime of the chi-squared test benchmark using
a logarithmic scale. We group compiler generated, optimized
and naive programs by the FHE implementation they target.
generated by E3 is around 9× slower than native implementa-
tions, which are already non-competitive compared to integer-
based solutions. In combination with the cardio benchmarking
results, this indicates that E3 generates binary adder/multiplier
circuits inefﬁciently when using binary emulation.
3) NN Inference: We present the evaluation results for the
neural-network inference task in Figure 4, reporting latency,
i.e., the time to run encrypted prediction on a single image.
Note that SEALion and nGraph-HE use SIMD-style batching
to achieve higher throughput at the same latency. For nGraph-
HE, it was not possible to provide individual sub-timings, as
key-generation, encryption, and decryption are invisible to the
application code. We ﬁrst compare our manual implementation
of an MLP both directly in SEAL and using EVA against
the same network architecture implemented in SEALion and
nGraph-HE, which offer much higher-level
interfaces. All
models achieved around 95% accuracy, nearly identical to
their plaintext equivalents. Note that for SEALion, the overall
runtime is artiﬁcially inﬂated because the tool encrypts the
input against a range of possible parameter sets instead of
only the targeted one. Taking this into account, we can see that
despite us implementing several optimization techniques from
the literature, the higher-level tools clearly outperform the
manual implementation. In the case of SEALion, this appears
to be due to automatic sparsiﬁcation, which reduces the net-
Figure 4: Runtime of the neural network inference benchmark,
i.e., recognizing handwritten digits from the MNIST dataset.
All implementations target SEAL. We implement a simple
multi-layer-perceptron (MLP). For nGraph-HE and EVA, we
also consider more complex models (CryptoNets, LeNet-5).
work’s size. Finally, we explored more complex models using
nGraph-HE and EVA, using CHET-generated programs for the
latter. The Cryptonets CNN architecture signiﬁcantly increases
accuracy (to 98%) at a minimal
increase in computation
cost. However, achieving state-of-the-art network performance
(99+%) requires a considerably more complex LeNet-5-like
network, which takes around 13 seconds to run using EVA
and more than two minutes using nGraph-HE.
VIII. DISCUSSION
In this section, we discuss some key questions in the space
of FHE and FHE tools:
A. What applications can be developed using FHE today?
While FHE can be practical for a wide variety of applica-
tions, there remain many applications that are not yet feasible
using FHE. Applications that make sense for FHE generally
feature a client-server scenario where both the input data and
the algorithm need to be kept private. In addition, there are
practical limits to the complexity of the applications that can
be outsourced. As a very rough heuristic, computations that
take more than a few hundred milliseconds without FHE are
unlikely to be practical once translated into FHE as of today.
However, this very much depends on the application scenario.
Generally, online computations where immediate feedback is
expected are more challenging. For example, face recognition
applications at an airport might tolerate a few seconds of
delay at most. On the other hand, ofﬂine tasks like computing
statistics over the results of a year-long medical study can be
considered practical even if taking considerable time.
For non-expert users, the range of applications that can
be realized in practice also depends signiﬁcantly on the
available tools. Using libraries like SEAL, PALISADE, or
HElib makes it easy to implement simple computations that
can be expressed as low-degree polynomials (e.g., the modiﬁed
χ2 test), and tools like nGraph-HE enable novice users to
easily implement linear ML models, simple statistics, and
neural network inference. For more experienced users, this
question becomes increasingly difﬁcult to address in general
terms. The implementation challenges we describe for our
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:31:21 UTC from IEEE Xplore.  Restrictions apply. 
1103
SEAL(Opt.*/Opt./E3*/E3/Naive)CinguBFV(A/B/C/D/E)TFHE(Opt./Cingulata/E3/Naive)050100150200Time[s]Dec.Comp.Enc.KeyGen.SEAL(Opt./E3/EVA/Naive)CinguBFV(Cingulata)TFHE(Opt./Cingulata/E3/Naive)1101001KTime[s]DecryptionComputationEncryptionKeyGeneration120130Manual(MLP)SEALion(MLP)nGraph-HE(MLP,CryptoNets,LeNet-5)EVA(MLP,LeNet-5)01020Time[s]DecryptionComputationEncryptionKeyGenerationcase studies show that application complexity and FHE im-
plementation complexity do not necessarily correlate. Finally,
some applications require modiﬁcations or extensions of the
underlying cryptographic primitives. These include compu-
tations that require switching between different schemes or
between FHE and MPC homomorphically. Many applications
can already be solved practically using these or other novel
programming paradigms. Frequently, success in implementing
an efﬁcient FHE-based solution for an application depends
less on the performance of the underlying FHE tools but on
how the application is translated. Exploiting the advantage of
SIMD-batching, e.g., using EVA, requires designing heavily
vectorized programs for a setting with signiﬁcantly more
restrictions than, e.g., AVX vector instructions. In addition,
many applications become feasible only after slight modi-
ﬁcations,e.g., using polynomial approximations or rewriting
expressions so that hard-to-compute operations (e.g., square
roots) are delayed until the end to allow them to be performed
client-side after decryption. By presenting these paradigms
more clearly and targeting an audience beyond the crypto
community, the set of applications that developers can expect
to realize successfully using FHE will expand signiﬁcantly.
B. When to use which of the FHE tools?
Given the choice of different tools that each present slightly
different features and strengths, selecting the appropriate tool
for a given application can be non-trivial. However, not all
tools that can implement a solution are necessarily suitable
choices, as demonstrated in our evaluation. Current
tools
generally excel at speciﬁc workloads or application domains,
and here we try to provide some recommendations for tools
to consider for common application scenarios.
For generic applications that compute non-polynomial func-
tions or require binary emulation, there are multiple options
with different tradeoffs. If working primarily with integers,
the programmable bootstrapping offered by the concrete li-
brary is an obvious choice. While compilers like Cingulata
(CinguBFV) or E3 are easier to work with, the performance
overhead they introduce might be unacceptable for many
applications. For applications requiring a true binary plaintext
space, Cingulata (TFHE) is most likely the easiest approach.
For applications that compute (polynomial) statistics over
large amounts of data, we recommend the EVA compiler
targeting CKKS for applications requiring approximate num-
bers. If working with integers only, we recommend working
directly with the SEAL library targeting BFV, since BFV is
less complex to work with and current compilers targeting
it introduce signiﬁcant slowdowns. The batching offered by
these schemes can be a natural ﬁt when computing aggregate
statistics or retrieving information from encrypted databases.
For applications that involve or use machine learning infer-
ence, the recommended approach depends on the complex-
ity of the used ML model. Where training a model with
polynomial activation functions produces sufﬁcient accuracy,
we recommend using the nGraph-HE compiler targeting the
CKKS scheme. nGraph-HE supports virtually all TensorFlow
trivial
features, including the Keras model deﬁnition API, making
it
to port existing models. In addition, nGraph-HE
offers excellent performance that can easily outperform even
a fairly involved manual implementation. Where deeper/recur-
sive networks or standard activation functions (e.g., ReLU) are
required to achieve the desired accuracy, the programmable
bootstrapping functionality offered by the concrete library
makes it the most suitable choice. However, this will require
signiﬁcantly more engineering effort as there are currently no
higher-level compilers targeting concrete.
C. Where should FHE tools go from here?
Both FHE compilers and libraries remain complex to use,
and there are obvious low-hanging fruits in terms of usability
that include better documentation and more extensive exam-
ples. In addition, there is a general lack of interoperability,
not just technically but also conceptually. For example, even
libraries implementing the same scheme can offer surprisingly
different APIs. The ongoing standardization efforts are trying
to create a uniﬁed view of the most popular schemes, including
standardized APIs for the most common operations. However,
this does not address the various extension of the API, e.g.,
optimizations for squaring rather than multiplying or per-
forming operations in-place. This would be solved ideally by
introducing a common intermediate representation language
that compilers can target and libraries can implement.
The existing tools have successfully reduced the complexity
of working with complex FHE schemes. There is a large
choice of libraries providing secure and efﬁcient implementa-
tions of current schemes. In addition, compilers have emerged
that make it signiﬁcantly easier to realize computations efﬁ-
ciently, e.g., by automatically choosing parameters or inserting
ciphertext maintenance operations. However, this still leaves
the user with the signiﬁcant challenge of translating an applica-
tion into an appropriate FHE computation in the ﬁrst place. For
example, tools could automatically vectorize iteratively written
programs or offer suggestions on aspects of the computation
that would be beneﬁcial to extract to the client-side.