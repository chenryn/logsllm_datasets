assessing privacy attacks [5], [25], [15], [23], [6], [26], [28].
To get an overview of the attack and the inﬂuence of
various parameters, we vary the number of bins b from 3 to 20,
and let the attacker submit 10, 100, and 100,000 unique queries
to the respective methylation Beacon. We vary δ between 0.1
and 10−6.
Figure 1 shows the attacker’s performance as a function
of b. Different numbers of queries submitted are displayed
in different colors, and line styles indicate two choices for
δ. As expected, the number of bins inﬂuences the attacker’s
performance. The more bins, the fewer patients’ values are
expected in each of them, which makes the membership
inference easier.
The attacker’s performance is high as soon as the number
of bins is reasonably large (larger than 3), no matter whether
100,000 or just 10 queries are submitted. This demonstrates the
privacy risk of unprotected methylation Beacons. Nevertheless,
the GBM curve for only 10 queries demonstrates that asking
too few queries may just not be enough for a successful
attack. The choice of δ has only little inﬂuence on the attack
performance in case more than 100 queries are submitted.
We observe a different attack performance depending on
the dataset, which is expected because we are testing different
populations, diseases and tissues here. We note that both IBD
datasets provide similar high AUCs, which can be explained
by the fact that they are taken from the same tissue, namely
blood cells.
As the increase in the attacker’s performance is only slight
for more than 10 bins, we ﬁx the number of bins to 10 in
the remainder of the experiments to reduce the number of
parameters and simplify the presentation. Additionally, we ﬁx
10http://gim.unmc.edu/dxtests/roc3.htm
δ to 10−6 to model the worst-case for privacy, even though
the privacy risk differs not much for other choices of δ.
VI. DEFENSE
The results in Section V demonstrate the privacy risks
stemming from unprotected methylation Beacons. To mitigate
this threat, we present our defense mechanism, the double
sparse vector technique (SVT2). We ﬁrst explain the intuition
behind it and then the defense mechanism in detail. In the end,
we prove that our defense mechanism is differentially private.
A. Intuition
Recall
that we assume the background knowledge K
contains the means and standard deviations of the general
population at the methylation positions of interest. That means,
if one judges by the background knowledge that there should
(or should not) be an individual with some value in a MBeacon
and the MBeacon output conﬁrms this, then not much privacy
is lost. Yet, if MBeacon’s answer deviates from the background
knowledge, one learns an additional piece of information about
the real distribution in the MBeacon for the queried position. In
consequence, the privacy of patients in the MBeacon is at risk.
More formally, we consider a MBeacon response as highly
privacy-sensitive if it deviates from the answer we expect from
the general population.
A MBeacon is usually built with data collected from people
with certain disease. According to biomedical research [39],
[41], [43], for data of this kind, only a few methylation regions
differ from the general population. This indicates that just
a few query responses are expected to be privacy-sensitive.
Therefore, we aim for a solution that calibrates the noise
speciﬁcally to those few responses in order to reduce the
overall noise level of MBeacon, thus maintaining utility.
B. Background on SVT
One possible solution in such a scenario is the sparse vector
technique (SVT), a differential privacy mechanism which is
designed to scale noise to a subset of sensitive responses.
6
35101520numberofbins0.50.60.70.80.91.0AUCIBDCD10q,δ=1e-06100q,δ=1e-06100000q,δ=1e-0610q,δ=0.1100q,δ=0.1100000q,δ=0.135101520numberofbins0.50.60.70.80.91.0AUCIBDUC10q,δ=1e-06100q,δ=1e-06100000q,δ=1e-0610q,δ=0.1100q,δ=0.1100000q,δ=0.135101520numberofbins0.50.60.70.80.91.0AUCGBM10q,δ=1e-06100q,δ=1e-06100000q,δ=1e-0610q,δ=0.1100q,δ=0.1100000q,δ=0.1In SVT, whether a response is sensitive or not is determined
by a threshold T deﬁned by the data owner: A response α ≥ T
is considered as privacy-sensitive, and one assumes most re-
sponses will yield α < T . SVT guarantees differential privacy
while scaling noise only to the privacy-sensitive answers. To
this end, SVT has an additional privacy parameter c which
refers to as the maximal amount of answers α ≥ T the
mechanism can give over its whole lifetime. SVT adds noise
to all queries (no matter whether they are privacy sensitive or
not) before comparing to the threshold to ensure differential
privacy. However, this noise is scaled to c instead of the much
larger number of queries in total. For a detailed and formal
description of SVT, we refer the reader to [11].
Algorithm 1: A outputs whether the database and prior
agree on the number of patients in the queried position
being above the threshold in a differentially private
manner.
Input: base threshold T , privacy parameters 1, 2 and
−→
Q , database
Result: sanitized responses R such that ri ∈ {⊥,(cid:62)} for
c, query sensitivity ∆, query vector
I and prior frequency P
each i
);
1 z1 = LAP( ∆
1
2 count = 0;
3 for each query qi in
);
4
5
6
z2 = LAP( ∆
1
);
−→
Q do
y(cid:48)
i = LAP( 2c∆
2
);
yi = LAP( 2c∆
2
get αi from I and βi from P;
if (αi + yi < T + z1 and βi + yi < T + z1) or
i ≥ T + z2) then
(αi + y(cid:48)
else
i ≥ T + z2 and βi + y(cid:48)
ri = ⊥ ;
ri = (cid:62);
count = count + 1 ;
);
z1 = LAP( ∆
1
end
if count ≥ c then
Halt
end
7
8
9
10
11
12
13
14
15
16 end
z2 = LAP( ∆
1
);
Algorithm 2: B transforms the output of Algorithm 1 to
the MBeacon output format.
Input: base threshold T , privacy parameters 1, 2 and
−→
c, query sensitivity ∆, query vector
Q ,
database I and prior frequency P
−→
Result: sanitized MBeacon responses BI(
−→
−→
Q )
R = A(T, 1, 2, c, ∆,
Q , I, P) ;
−→
1
2 for each query qi in
Q do
−→
get βi from P;
R ;
get ri from
3
if ri = ⊥ then
4
5
else
6
7
8
9 end
BI(qi) = βi ≥ T ;
BI(qi) = ¬(βi ≥ T );
end
C. SVT2
However, we cannot directly apply SVT to protect our
methylation Beacon, as our privacy-sensitive responses depend
on whether we expect a “No” or a “Yes” answer, thus cannot
be judged by a simple, ﬁxed threshold. Concretely, suppose
that we expect β patients in the queried bin, then the true
number of patients in the bin, i.e., α, is privacy-sensitive if β
and α lie on opposite sides of a predeﬁned threshold T and
the Beacon gives another answer than the one we expected.
This means we need two comparisons to determine whether
the answer is privacy-sensitive. Therefore, we propose double
sparse vector technique (SVT2) to protect MBeacon. Since
SVT is not applicable, we cannot compare our new technique
SVT2 to SVT.
Formally,
the ith query is not privacy-sensitive if the
following expectation is met:
((αi + yi < T + z1) ∧ (βi < T + z1))
∨((αi + y(cid:48)
i ≥ T + z2) ∧ (βi ≥ T + z2))
(10)
where αi is the number of patients in the MBeacon that corre-
sponds to the query qi, βi is the estimated number of patients
given by the general population,11 and T is the threshold
determining whether the αi and βi agree with each other.
This (dis-)agreement is used to check whether the current
query is privacy-sensitive or not: Only Condition 10 being
false implies the query is privacy-sensitive. Moreover, z1, z2
and yi, y(cid:48)
i are noise variables sampled independently from the
Laplace distribution. The sampling procedure is explained in
detail later in this section.
Similar to the sparse vector technique, SVT2 bounds the
total number of highly privacy-sensitive queries by maintaining
a counter. Each privacy-sensitive query increases the counter. If
a predeﬁned maximal budget c is exceeded, the algorithm stops
answering. In practice, that would mean that the corresponding
MBeacon goes ofﬂine. We study when this is the case and
whether this negatively inﬂuences the MBeacon utility in
Section VIII.
We disassemble our method SVT2 into Algorithms 1 and 2,
also referred to as A and B, for technical reasons of the differ-
ential privacy proof. Algorithm 1 answers whether the Beacon
returns the requested answer in a differentially private way,
Algorithm 2 then transforms this into the desired MBeacon
answer format. Moreover, we formulate the expected answer
as a query to a database to allow practitioners to instantiate
it with the most suitable estimation for their purpose. In our
evaluation, we use the normal distribution ﬁtted to population-
wide means and standard deviations, since the LR test also
relies on their knowledge.
Algorithm 1 determines whether the prior and the MBeacon
database agree on the answer. Condition 10 can be found in its
generalized form in line 6 of Algorithm 1, where noise is added
to the prior as well. This removes the assumption that β is
publicly known from Algorithm 1. In the less privacy relevant
case, answer can be directly given (line 7); in the more privacy
relevant case, the privacy budget has to be decreased and the
noise for the threshold T has to be re-sampled (lines 10 and
11We assume the number of patients in the MBeacon database to be publicly
known, so we can set βi = τ b (qi)N .
7
11) in addition to returning the answer. If the current privacy
budget count exceeds the maximal budget c, the algorithm has
to stop answering (lines 13 and 14).
Algorithm 2 takes the output of Algorithm 1 and provides
the differentially-private MBeacon answer by ﬂipping the
expected answer if necessary (line 7).
Notice that genomic Beacons usually set T = 1, but we
generalize that setting by allowing other threshold values in
a k-anonymity like fashion. For low values of T , the regions
where the MBeacon answer differs from the expected answer
grow, while for higher values they shrink. Furthermore, a user
might not ask all queries at once, but in an adaptive manner.
This is taken into consideration by SVT and consequently
by SVT2, another important aspect in the on-line setting of
MBeacon.
Repeated Queries. All differential privacy mechanisms, in-
cluding our proposed mechanism, assume all queries are
unique. Otherwise, the noise might eventually cancel out. A
single person has no (legitimate) interest in asking the same
query multiple times, but in an online Beacon setting, multiple
users might ask the same question. However, the assumption
is not a limitation: we maintain a database of responses and,
if a question has been asked before, we answer the same way
we did before. Initially, such a database can be empty and it
gets ﬁlled with responses over time. Its size is in O(number of
methylation regions×number of bins), but the total MBeacon
database is O(number of methylation regions×number of
patients) and we expect much more patients than bins, so the
space overhead is acceptable.
D. Differential Privacy Proof
We ﬁrst prove that Algorithm 1, i.e., A, is differentially
private. Then, we show that the transformation of its output
to our desired MBeacon output using Algorithm 2, i.e., B, is
also differentially private. The combination of these arguments
proves that SVT2 is differentially private.
Theorem 1. Algorithm 1 is 2(1 + 2)-differentially private.
We present a proof sketch of Theorem 1 in the following,
the full proof is presented in the appendix.
−→
Proof sketch. Consider any output of A as a vector
R ∈
−→
R = (cid:104)r1, ...., rl(cid:105). We
{(cid:62),⊥}l, we refer to its elements as
deﬁne two sets I(cid:62) = {i : ri = (cid:62)} and I⊥ = {i : ri = ⊥} of
indices for the different answers. For the analysis, let the noise
i for all i ∈ I(cid:62)∪ I⊥ be arbitrary but ﬁxed [11]. We
values yi, y(cid:48)
concentrate on the probabilities over the randomness of z1, z2,
i.e., the noise added to the threshold T . Moreover, let the two
databases I and I(cid:48) be arbitrary but ﬁxed, such that I and I(cid:48) are
neighboring databases.
We begin by disassembling the probability of Algorithm 1
−→
R from I as follows.12
getting a speciﬁc answer
Pr[A(I) =
−→
R ] =
(cid:90) ∞
(cid:90) ∞
−∞
−∞
Pr[ρ1 = z1 ∧ ρ2 = z2]
(11)
fI(z1, z2)gI(z1, z2)dz1dz2
12As the other inputs are ﬁxed, we use A(I) to represent Algorithm 1 in
the proof, omitting the other input parameters for better readability.
8
where
fI(z1, z2) = Pr[∧i∈I⊥ ri = ⊥|ρ1 = z1 ∧ ρ2 = z2]
gI(z1, z2) = Pr[∧i∈I(cid:62) ri = (cid:62)|ρ1 = z1 ∧ ρ2 = z2]
(12)
(13)
To prove the theorem, it is sufﬁcient to show that, for
sensitivity ∆, the following inequalities hold:
fI(z1, z2) ≤ fI(cid:48)(z1 + ∆, z2 − ∆)
gI(z1, z2) ≤ e22gI(cid:48)(z1 + ∆, z2 − ∆)
Pr[ρ1=z1∧ρ2=z2]≤e21 Pr[ρ1 = z1 +∆∧ρ2 = z2−∆]
(14)
(15)
(16)
which gives us the required connection between the two
neighboring databases I and I(cid:48).
i| ≤ ∆ and |βi − β(cid:48)
To prove Inequality 14, we utilize only the sensitivity ∆,
i| ≤ ∆. For Inequality 15,
i.e., |αi − α(cid:48)
as g argues about the negation of the query formulation, if
we simply follow the proof for Inequality 14, we would get