App,User,Π,ξ(A)
Expxx
(γ, ˆγ) ←← App.Init(ξ)
(K, h) ←← Π.Setup(ξ)
BUF ← ε; ws ← ε
b ←← APUSH,Oxx(·)(ˆγ, h)
return b
Oracle Ooc( )
x ←← Userγ (NEXT)
wc ←← App.Sourceγ (x, ws)
(ws, ) ←← App.Sinkγ (wc)
return (wc, ws)
user (K, γ, h, x)
Oracle Occ( )
x ←← Userγ (NEXT)
x ←← Π.EmbedPULL
wc ←← App.Sourceγ (x, ws)
w′
c ←← Π.EmbedPULL
wire (K, γ, h, wc)
(wc, ) ←← Π.Extractwire(K, γ, h, w′
c)
(ws, ) ←← App.Sinkγ (wc)
return (w′
c, ws)
Fig. 3: Generic experiment, along with overt channel (oc) and covert
channel (cc) challenge oracles, used to define passive covert channel
security. The initialization code and message buffer oracle (upper
panel) is common to all experiments.
as a result of unconstrainted execution. In particular,
this
means that reconstruction on the receiver-side is simpler: the
string recovered by Extractuser always comes before the string
recovered by Extractwire.
Trivial implementations. We are unaware of any system that
utilizes both Embeduser and Embedwire: all existing systems
embed and extract only on the user side, or only on the
wire side. To simplify the presentation of these “one-sided”
constructions, we assume trivial
implementations for each
algorithm that pass through the relevant input unmodified.
Any construction of a covert channel which elides an
explicit implementation of one or more algorithms implicitly
implementation(s). More specifically, a
includes the trivial
user-only covert channel
imple-
mentations of Embedwire and Extractwire, while a wire-only
covert channel implicitly uses the trivial implementations of
Embeduser and Extractuser.
implicitly uses the trivial
V. SECURE ABCCS
We model security against a passive eavesdropper through
a game-playing approach, where the two games are relativized
to an application channel App = (Init, Source, Sink), an
environment context ξ, and a pair of users User0 and User1.
In the overt and covert channel experiments (Figure 3), the
adversary is provided with two oracles: the first allows it to
push messages to a message buffer, and the second is the
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:36:38 UTC from IEEE Xplore.  Restrictions apply. 
1977
challenge oracle. This latter oracle takes any input (which
it ignores) and runs one round of the application channel,
where a round corresponds to a message from Source to Sink
and vice versa. The adversary is given as output wc and ws
corresponding to the messages sent over the network.
The overt case is the reference experiment, in which the
challenge oracle exhibits the reference (i.e. normal, honest, or
expected) behavior: a sequence of inputs produced by the user
are fed into Source, which then emits a client message wc.
This is input into Sink which itself emits a server message
ws, and then both client and server4 messages are returned to
the adversary. In the covert experiment, the covert channel is
active: the output of User is fed to Embeduser, and instead of
sending the output of Source directly to Sink, the game runs
Embedwire followed by Extractwire. In particular, this captures
all of the steps executed by a covert channel in a single round
of application execution.
To improve readability, after fixing the appropriate terms
we shall use the shorthand XXn to refer to the game instanti-
ated by Expxx
App,Usern,Π,ξ. For example, CC1 refers to the covert
channel experiment parameterized by User1.
Definition 9 (Passive Covert Channel Security). Fix applica-
tion channel App, reference user User0 and covert user User1,
App-based covert channel Π, and environment context ξ. For
a fixed adversary A, define the passive covert channel (pcc)
advantage as
Advpcc
App,(User0,User1),Π,ξ(A) = ∆(CC1, OC0).
We say Π is passively (t, q, µ, ϵ)-secure relative to
App, User0, User1, ξ if
max
A∈A(t,q,µ)
Advpcc
App,(User0,User1),Π,ξ(A) ≤ ϵ,
where A(t, q, µ) is the set of all adversaries which halt in at
most t time steps and make at most q oracle queries totaling
♢
at most µ bits.
Remark. We track the bitlength of the output of the oracle O,
despite this not being necessarily controllable by the adversary
itself (except as a function of the number of calls to O). We
do so because the total bitlength of the output may affect the
adversary’s success probability, such as when the application
channel utilizes a secure channel.
A. Interpreting the User parameters
A subtle but
important detail of this security notion
is that a (potentially) different user is provided for each
experiment; interpreting the security semantics of this design
choice requires some unpacking.
At a high level, the distinction between users provides a
way to model a challenging feature of covert communication
settings: the party utilizing the covert channel may be the
same party that is driving the application, and this fact itself
may provide some adversarial advantage. In the censorship
4The descriptors “client” and “server” are arbitrarily chosen for conve-
nience; the application need not assume any particular network architecture.
circumvention setting, for example, it is reasonable to assume
that the application user is also providing the inputs to the
covert channel, and therefore the user’s choices about how to
interact with the application may be highly correlated with
the presence of the covert channel. Intuitively, then, one can
interpret User1 as an encapsulation of certain assumptions
about
the expected (or proper) behavior of the subset of
application users that will be utilizing the covert channel in
the target deployment environment.
On a technical level, User0 simply serves as a reference
point for the behavior of User1. With the same experimental
setup used in our notion of passive security, we can also
formalize an intuitive notion of “similarity” between two fixed
users.
Definition 10 (Similar Users). Fix App, User0, User1, ξ, Π,A
as in Definition 9. Define the user advantage of A as
App,(User0,User1),Π,ξ(A) = ∆(OC1, OC0)
Advuser
with probabilities taken over the coins of the adversary A and
component algorithms of App and Π.
We say that users User0 and User1 are (t, q, µ, δ)-similar
relative to application channel App, environment context ξ,
and covert channel Π if, for all A ∈ A(t, q, µ), the user
♢
advantage is bounded from above by δ.
Expressing the pcc advantage in terms of the user advantage,
we have
Advpcc
App,(User0,User1),Π,ξ(A) =
∆(CC1, OC1) + ∆(OC1, OC0),
(1)
which naturally leads to the passive security bound
max
A∈A(t,q,µ)
∆(CC1, OC0) ≤ max
∆(CC1, OC1)
A∈A(t,q,µ)
+ max
A∈A(t,q,µ)
∆(OC1, OC0).
(2)
In general
the bound provided by (2) is not necessarily
tight, and one can easily come up with pathological ex-
amples for which it exceeds 1 (and is therefore vacuous).
The primary benefit to this approach is that it allows for a
more tractable security analysis, since the first term in the
bound—∆(CC1, OC1), which we will informally refer to as
the embedding advantage—is defined relative a single fixed
user. Furthermore, as we will show in §VII, for certain ABCC
constructions—which adequately capture a number of real-
world systems—we can reduce this term to cryptographic
properties of the construction, providing some reassurance that
any “looseness” in the pcc bound from (2) is small.
With an understanding of the technical implications for
one’s choice of User0, we can sketch out an intuition about the
security semantics arising from this choice. First we observe
that in the overt channel experiment, the adversary’s inter-
action is effectively limited to choosing how many samples
to draw from the application before returning a decision. This
suggests an alternative but equivalent experiment which simply
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:36:38 UTC from IEEE Xplore.  Restrictions apply. 