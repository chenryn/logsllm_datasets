system, the priority is assigned to be the higher of the two risk values.
Pa = max(Rh1,t, Rh2,t),
2.4 Parameter Estimation and Learning
The estimation of the appropriate values for the model parameters P, Q, π, and
for the cost vector C can be determined using either training algorithms or ex-
pert knowledge, supported by an appropriate methodology. Notably, a uniform
initial distribution of the P and π parameters is adequate as a basis for train-
ing the parameters, according to [13]. The initial parameters can alternatively
be determined using a risk assessment methodology, such as [2]. These method-
ologies provide a framework for identifying threats and vulnerabilities and for
determining probabilities and consequences of risks.
Based on an HMM with initial parameters, there are several algorithms avail-
able for re-estimating the parameters (i.e., training the models). There is, how-
ever, no analytical solution to the re-estimation problem, and there is no optimal
way of estimating the model parameters based on an observation sequence as
training data [13]. A standard approach for learning HMM parameters is the
Baum-Welch method, which uses iteration to select HMM parameters to maxi-
mize the probability of an observation sequence.
3 System Architecture and Implementation
This section discusses the architecture of the real-time risk assessment system
and how it is integrated into the STAT framework. Some implementation details
are also presented.
3.1 System Architecture
The risk-assessment system receives input events from multiple intrusion detec-
tion sensors throughout the protected network. Both host-based and network-
based sensors are supported. The alerts generated by the sensors are either in
Using Hidden Markov Models to Evaluate the Risks of Intrusions
151
the IDMEF format [3] or in a format native to the sensor. Native alert formats
are converted into IDMEF alerts before further processing. Intrusion detection
alerts from the sensors are collected by the MetaSTAT collector [17,18] through
network connections. MetaSTAT then merges the diﬀerent alert streams and the
aggregate stream is fed to the risk-assessment system.
The output of the system is a stream of prioritized alerts. The main advantage
of this system is that the security administrator can easily identify the most
important alerts by sorting them by the prioritization value. By handling the
important alerts ﬁrst, the administrator can make more eﬃcient use of his time.
The system is implemented as a set of modules in the STAT framework [17,18].
Figure 2 is an overview of the architecture. The system consists of three diﬀerent
modules: Alert Classiﬁcation, Spoof Detection, and Risk Analysis. The operation
of each of the modules is explained in detail below.
Fig. 2. Overview of the System Architecture
The classiﬁcation module augments the incoming alerts with a classiﬁcation
attribute. The classiﬁcation assigned to a given alert is dependent on the im-
pact that the attack referenced in the alert has on the network. The system
utilizes the following classes of attacks: successful recon limited, successful user,
and successful admin.
The IDMEF standard speciﬁes an optional classiﬁcation attribute, and the
classiﬁcation module uses this attribute if it is set by the intrusion detection
sensor. Unfortunately, most sensors do not provide a value for the classiﬁcation
attribute. When the classiﬁcation module encounters alerts with no classiﬁca-
tion, the missing attribute is looked up in a database. The database contains
a mapping from sensor-type/alert-name tuples to the corresponding class. The
mapping database can be created manually by looking at the rules of the de-
ployed intrusion detection sensors and classifying each rule as either referring
to a successful recon limited, successful user, or successful admin attack. The
database can also be created automatically if the rules of the intrusion detection
sensors contain a CVE id, which is often the case. The CVE database can be
queried for the description of the attack and the classiﬁcation can be ﬁlled in
from the description.
A problem that may occur is that some alerts do not contain the real IP of the
host that caused the IDS alert to be generated. This happens when the attacker
152
A. ˚Arnes et al.
host spoofs the source IP of the packets that are part of the attack. A network
IDS monitoring the attack traﬃc sees the attack coming from the spoofed IP
and reports the spoofed IP as the attacker. The spoof detection module detects
spoofed alerts and attempts to infer the real IP of the attacker.
Spoof detection can be performed by keeping track of what IP addresses each
host is utilizing. An anti-spooﬁng tool, such as arpwatch, can be utilized to
create a database of what IPs are associated with each Ethernet address. When
the spoof detection module of the risk assessment system receives an alert, the
database is consulted to check if the attacker IP contained in the alert matches
the Ethernet address in the alert. Some of the problems with this approach are
that most intrusion detection alerts do not contain Ethernet addresses and that
packets with spoofed Ethernet addresses would not be detected. Another way of
performing spoof detection is to check whether the IPs referenced in the alert
are part of the protected network. If neither the attacker nor the victim is part of
the protected network, the attack must either be spoofed or an outside attacker
is attacking another outsider using the protected network. Since most networks
do not allow traﬃc from third parties to transit their network, the second case is
highly unlikely, and one can conclude that spooﬁng has taken place. Note that
this spoof detection mechanism is unable to catch instances of spooﬁng where
the victim of the spooﬁng is within the protected network.
When a spoofed alert is detected, the real IP of the attacker can be fetched
from the IP mapping database if Ethernet addresses are present in the alerts.
In the case of alerts without Ethernet addresses the real attacker cannot easily
be identiﬁed. In this case, any of the hosts in the protected network could be
the attacker. The spoof detection module handles this by forwarding the alert
to every host in the subnet where the attack was detected.
After spoof detection is performed, the alerts are processed by the risk analysis
module. The module keeps one HMM model for each of the protected hosts.
When an alert is received, the models for the hosts referenced in the alert are
looked up. For each of these hosts, the HMM model is updated with the latest
observation. Finally, the risk value for each of the aﬀected hosts is calculated
and the alert is augmented with the maximum of these risk values before the
alert is sent to the administrator.
3.2 Implementation
The real-time risk assessment implementation is based on the algorithms in [1].
Only one observation probability matrix Q is deﬁned for each host. For hosts
with multiple sensors (such as Mill and Pascal in Section 4.1), all sensors have
been incorporated into one Q.
The implementation is integrated into the STAT framework, as described
above. It consists of the following C++ classes: RiskObject (representing a
host), RiskSensor (representing an IDS sensor), and RiskObservation (rep-
resenting a sensor observation). The implementation receives IDMEF messages
from the framework, and processes these based on the source and destination IP
addresses, sensor identities, alert timestamps, and the alert impact values.
Using Hidden Markov Models to Evaluate the Risks of Intrusions
153
As the Hidden Markov Models are discrete time models, the risk is updated
for every second for each host, based on the available alerts relevant to each host.
A relevant alert either has the IP address of the host in question as its source or
destination IP address, or it originates from a host-based IDS on the host. If no
alert is available for a host, the system uses the default observation “no alert”
as input to the HMM computation. If more than one alert is received for a host
during the 1 sec. interval, the ﬁrst alert is processed and the remaining alerts
are queued for the next intervals. For the sake of responsiveness, the maximum
queue size is set to 60 seconds for the purpose of this paper. All new alerts will
be discarded when the maximum queue size has been reached. This approach is
chosen in order to be able to handle alert bursts, such as the outbound DDoS
described in Section 4.1. Note that the problem of alert queues can be mitigated
by choosing a suﬃciently short time interval for the hidden Markov models.
4 Experiments
The purpose of this section is to validate the proposed method and to demon-
strate how the system outlined in Section 3 can be used on real-life data. For the
experiments two diﬀerent data sets were used: the Lincoln Laboratory 2000 data
set and traﬃc data from TU Vienna. The ﬁrst data set contains experimental
data, whereas the second contains data from a real network. The advantage of
using the Lincoln Labs data is that it contains a truth ﬁle [11]. Therefore, the
results can be checked against these values. The TU Vienna data set validates
the feasibility of using the approach on real data.
The basic experimental approach was to determine the HMM parameters Q,
P, π, and C for the Lincoln Laboratory data and to verify that the results
produced by our method correspond to the information gleaned from the truth
ﬁle. The same parameters were then used on the real traﬃc data from TU Vienna
in order to validate the model’s parameters in a realistic setting. By using the
same HMM parameters for both data sets, where applicable, it is possible to
compare the results obtained from the two cases.
The outcome of the experiments are highly dependent on the HMM param-
eters and the alert classiﬁcation, in addition to the alert and traﬃc data used.
The HMM parameters used in these examples were determined manually based
on the authors’ experience with the models. The following general guidelines
were used in determining the appropriate values for the parameters:
– The risk level for a host should be close to zero when there are no alerts.
This implies that the probability of being in state G should be close to 1
when there are no alerts.
– When state C occurs, the model should stay in this state longer than it
would for states P and A.
– In order to make the results comparable, the cost vector for all hosts are
identical. In a real setting, the cost vectors for diﬀerent assets would vary
depending on their value.
154
A. ˚Arnes et al.
Section 4.1 presents the details of the parameters used and the results of ap-
plying the method to the Lincoln Laboratory 2000 data set. Section 4.2 presents
the same for the TU Vienna data.
4.1 Lincoln Laboratory Scenario (DDoS) 1.0
The Lincoln Laboratory 2000 data set [11] is based on experimental network traf-
ﬁc for a network of four class C subnets. The data set contains a network dump,
as well as Solaris BSM [16] system logs. This data has been processed with the
Snort network-based IDS and the USTAT host-based IDS in order to generate ID-
MEF alerts. The resulting data set contains more than three hours of intrusion
detection data for subnets 172.16.112.0/24, 172.16.113.0/24,172.16.114.0/24,and
172.16.115.0/24. The hosts Mill (172.16.115.20), Pascal (172.16.112.50), and Locke
(172.16.112.10) are attacked and compromised, and they are then used to launch
a DDoS attack against an external host using spoofed IP addresses. There are two
Snort network IDS sensors (an outside sensor and a DMZ sensor), and the hosts
Mill and Pascal are equipped with instances of the USTAT host-based IDS.
Attack Phases. The data set contains an attack in ﬁve phases (see [11]). The
phases are outlined below with excerpts from the original description.
IP sweep. approximate time 09:45 to 09:52: “The adversary performs a scripted
IPsweep of multiple class C subnets on the Air Force Base. (...) The attacker
sends ICMP echo-requests in this sweep and listens for ICMP echo-replies to
determine which hosts are up.”
Sadmind ping. approximate time 10:08 to 10:18: “The hosts discovered in the
previous phase are probed to determine which hosts are running the sadmind
remote administration tool. (...) Each host is probed, by the script, using the
ping option of the sadmind exploit program.”
Break in to Mill, Pascal, and Locke. approximate time 10:33 to 10:34: “The
attacker then tries to break into the hosts found to be running the sadmind
service in the previous phase. The attack script attempts the sadmind Remote-
to-Root exploit several times against each host (...) there are 6 exploit attempts
on each potential victim host. To test whether or not a break-in was successful,
the attack script attempts to login.”
Installation of DDoS tools on Mill, Pascal, and Locke. approximate time 10:50:
“Entering this phase, the attack script has built a list of those hosts on which
it has successfully installed the hacker2 user. These are Mill, Pascal, and Locke.
For each host on this list, the script performs a telnet login, makes a directory
(...) and uses rcp to copy the server-sol binary into the new directory. This is the
mstream server software. The attacker also installs a .rhosts ﬁle for themselves.”
Outbound DDoS with spoofed source IP addresses. approximate time 11:27: “In
the ﬁnal phase, the attacker manually launches the DDoS. This is performed
via a telnet login to the victim on which the master is running, and then, from
the victim, a telnet to port 6723 of the localhost. (...) The command mstream
131.84.1.31 5 causes a DDoS attack, of 5 seconds duration (...) to be launched
by all three servers simultaneously.”
Using Hidden Markov Models to Evaluate the Risks of Intrusions
155
Observation Messages. Based on the available alert data and the output
from the alert classiﬁcation preprocessor, we use the following observations in
the implementation:
1. Suspicious Snort alert: All alerts that are not explicitly classiﬁed.
2. Compromise Snort alert: All alerts that are classiﬁed as “successful admin”.
3. Scan Snort alert: All alerts that are classiﬁed as “successful recon limited”.
4. Host-based alert (only available for hosts Mill and Pascal): The data set only
contains the alert types “unauth delete” and “restricted dir write”.
5. Outbound Snort alert: All Snort alerts originating from an internal host.
6. No alert: This observation is assumed whenever there are no other alerts to
be processed for a host.
The classiﬁcation could be made more ﬁne-grained, but it is kept simple in this
paper for demonstration purposes. In particular, the output of the host-based
USTAT IDS in a real setting would generate a wide range of diﬀerent alert
types. In this example, however, we have made the simpliﬁcation of modeling
the USTAT sensor as producing one observation type only. Similarly, we have
made the assumption that outbound Snort alerts reduce the probability of being
in the “good” state.
Model Parameters. The monitored network consists of 1016 IP addresses,
each modeled by an HMM. The transition probability matrices P, observation
probability matrices Q, initial state distribution vectors π, and the cost vectors
C are the same for each host, with the exception of the hosts Mill and Pascal,
which incorporate the possibility of receiving USTAT alerts. As an example, the
host Mill is modeled as follows:
⎛
⎜⎜⎝
⎛
⎜⎜⎝
⎛
⎜⎜⎝
⎛
⎜⎜⎝
PM ill =
=
QM ill =
=
⎞
⎟⎟⎠
pGG pGP pGA pGC
pP G pP P pP A pP C
pAG pAP pAA pAC
pCG pCP pCA pCC
0.992995
0.004
0.004
0.003
⎞
⎟⎟⎠ ,
0.000005
0.000005
0.000005
0.991995
0.003
0.004
0.004
0.992995
⎞
⎟⎟⎠
1 × 10−34 1 × 10−34 1 × 10−34 1 − 3 × 10−34
qG(1) qG(2) qG(3) qG(4) qG(5) qG(6)
qP (1) qP (2) qP (3) qP (4) qP (5) qP (6)
qA(1) qA(2) qA(3) qA(4) qA(5) qA(6)
qC(1) qC(2) qC(3) qC(4) qC(5) qC(6)
⎞
0.05 0.0001 0.02 0.01 0.02 0.8999
⎟⎟⎠ ,
0.05 0.0001 0.25 0.01 0.02 0.6699
0.1 0.005 0.1 0.03 0.03 0.735
0.02 0.05 0.04 0.04 0.05
0.8
πM ill = (πG, πP , πA, πC) = (1, 0, 0, 0),
CM ill = (cG, cP , cA, cC) = (0, 25, 50, 100).
156
A. ˚Arnes et al.
From PMill, we can see that the probability of entering the state C is relatively
low, but that once entered, the probability of leaving this state is very low. From
QMill, we can see that the scan observation is relatively likely to occur in the P
state, that the suspicious and scan observations are relatively likely to occur in
the A state, and that the USTAT and outbound observations have a relatively
high probability in the C state. Note that once entered, the C state is likely to
last for a long time. From πMill and CMill, we can see that the initial state of the
host is G with corresponding cost 0. The maximum cost for the host is 100. Most
of the hosts do not have a host-based IDS and are modeled with the following
observation probability matrix (host Locke is given as an example):
⎛
⎜⎜⎝
QLocke =
0.05 0.0001 0.02 0 0.02 0.9099
0.05 0.0001 0.25 0 0.02 0.6799
0.1 0.005 0.1 0 0.03 0.765
0.02 0.05 0.04 0 0.05 0.84
⎞
⎟⎟⎠
For the purpose of this example all hosts, except the hosts with USTAT, have