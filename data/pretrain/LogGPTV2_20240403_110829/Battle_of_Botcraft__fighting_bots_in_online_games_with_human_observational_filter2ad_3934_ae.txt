### User-Input Stream and Bot Interference

Since the user-input stream is collected on the client side, bots can easily interfere with this process. A bot program may disrupt the collection of user input either by disabling the client-side exporter or by intercepting the network traffic containing the user-input data. However, the server-side analyzer can block any game client that refuses to send the user-input stream. In other words, a simple policy of "no user-input, no game" can effectively thwart such evasion attempts. For bots that attempt to manipulate the user-input stream, their control over mouse and keyboard events limits the additional benefits they might gain from such manipulation.

### Mimicking Human Behavior

A more effective evasion strategy for bots is to mimic human behavior. The most straightforward method would be a replay attack, where a bot records a human's gameplay and replays it. However, the highly dynamic nature of games, especially in Massively Multiplayer Online Games (MMOGs), makes a simple replay attack ineffective. The game environment is constantly changing, and a pre-recorded session cannot adapt to these changes. Additionally, fully controlling the game via replay would require recordings of virtually all possible interactions, which is impractical due to the wide variety of game tasks.

A more sophisticated approach involves using random models to generate different user-input actions. However, this method requires a separate model for each statistic and type of user-input action. With six different action types and seven statistics, over 40 models are needed just to capture the marginal distributions. Furthermore, there are complex inter-relations between different actions, statistics, and game tasks. While new techniques can generate synthetic user-input with some human behavioral characteristics, current methods are limited to generating random mouse movements and capturing only basic statistics [35, 36].

More importantly, the HOP system does not rely on a single metric of human behavior but rather a collection of different behavioral metrics composed by neural networks. Successfully evading the neural network would require a simultaneous attack on several of these metrics. Although mimicking a single metric, such as keystroke inter-arrival time, is relatively easy, fully replicating all aspects of human behavior in a highly dynamic environment like MMOGs is non-trivial.

### Threat of Mimicry Attacks

The threat of mimicry attacks [50] is real for behavior-based intrusion detection systems, including HOPs. We believe that a highly motivated bot creator could build a more complex game bot that mimics multiple aspects of human behavior to evade the HOP system, but at the cost of significant time and effort.

### Exploiting Online Games

Exploiting online games has gained increasing attention in recent years. Yan et al. [56] summarized commonly used exploiting methods in online games and categorized them along three dimensions: vulnerability, consequence, and exploiter. They also emphasized the importance of considering fairness in understanding game exploits. Webb et al. [52] presented a different classification of game exploits, categorizing 15 types into four levels: game, application, protocol, and infrastructure, and discussed countermeasures for both client-server and peer-to-peer architectures. Muttik [34] surveyed security threats in MMOGs and discussed potential solutions from multiple perspectives, including technology, economy, and human factors. Hoglund and McGraw [24] provided a comprehensive overview of game exploits in MMOGs, shedding light on various topics and issues.

### Anti-Cheating

With the growing severity of game exploits, securing online games has received widespread attention. Research on anti-cheating generally falls into two categories: game cheating prevention and game cheating detection. Prevention mechanisms aim to deter cheating, while detection methods identify instances of cheating. For MMOGs, a cheat-proof design, particularly for the game client program and communication protocol, is essential to prevent most exploits. This is because (1) the client program is under the full control of the player, and (2) client-side communication can be manipulated for the player's advantage.

Several works have focused on preventing game exploits. Baughman et al. [2] uncovered the possibility of time cheats through exploiting communication protocols and designed a lockstep protocol to prevent such cheats. Other time-cheat-resistant protocols [9, 13, 15] have been developed. MÃ¶nch et al. [32] proposed a framework to prevent tampering with game client programs, employing mobile guards to validate and protect the game client. Yampolskiy et al. [55] devised a protection mechanism for online card games, embedding CAPTCHA tests in the cards. Golle et al. [22] introduced a special hardware device that implements physical CAPTCHA tests, making it difficult for bots to resolve without human involvement.

In practice, eliminating all potential game exploits is extremely challenging. Therefore, accurate and quick detection of game exploits is crucial. Chen et al. [10] found that the traffic generated by official clients differs from that generated by standalone bot programs, but this approach is not effective against modern bots that interact with official clients. Thawonmas et al. [47] introduced a behavior-based bot detection method, but it has low discriminability and long detection times. Schluessler et al. [45] presented a client-side detection scheme using special hardware to provide a tamper-resistant environment for the detection module.

### Behavioral Biometrics

The idea of HOPs is inspired by behavioral biometrics based on keystroke dynamics [5, 25, 33, 40] and mouse dynamics [1, 20, 43]. Keystroke and mouse dynamics are unique to each person, making them useful for user authentication and identification. Our system leverages the differences in game-playing behaviors, such as keyboard and mouse actions, between human players and game bots to distinguish between them. Unlike traditional biometric systems, which use keystroke or mouse dynamics for identification, our system focuses on detecting game bots.

### Conclusion

In this paper, we presented a game bot defense system that uses HOPs to detect game bots. The HOPs leverage the differences in game-playing behaviors between human players and game bots to identify bot programs. Compared to conventional methods like CAPTCHAs, HOPs are transparent to users and work continuously. We collected 95 hours of user-input traces from World of Warcraft and revealed significant differences between bots and humans in various characteristics derived from game-playing actions, motivating the design of the HOP defense system.

The HOP defense system consists of a client-side exporter and a server-side analyzer. The exporter transmits a stream of user-input actions, and the analyzer processes the action stream to detect bots. The core of the analyzer is a cascade-correlation neural network, which determines if the stream generator is a bot or a human player. We also employed a simple voting algorithm to improve detection accuracy. Based on the collected user-input traces, we conducted experiments to evaluate the system's effectiveness under different configurations. Our results show that the system can detect over 99% of current game bots with no false positives within a minute, with negligible overhead in terms of network traffic, CPU, and memory cost. As our detection engine relies only on user-input information, the HOP system is generic to MMOGs.

### Acknowledgments

We are grateful to our shepherd Paul C. Van Oorschot and the anonymous reviewers for their insightful and detailed comments. This work was partially supported by NSF grants CNS-0627339 and CNS-0627340.

### References

[1] A. A. E. Ahmed and I. Traore. A new biometric technology based on mouse dynamics. IEEE Trans. on Dependable and Secure Computing (TDSC), 4(3), 2007.
[2] N. E. Baughman and B. N. Levine. Cheat-proof playout for centralized and distributed online games. In Proceedings of the 20th IEEE INFOCOM, Anchorage, AK, USA, April 2001.
...
[56] J. Yan and B. Randell. A systematic classification of cheating in online games. In Proceedings of the 4th ACM SIGCOMM NetGames, Hawthorne, NY, USA, October 2005.