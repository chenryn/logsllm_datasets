Since the user-input stream is collected at the client side,
the bots can easily interfere with the user-input collection.
A bot program could hinder the user-input collection either
by disabling the client-side exporter or by intercepting the
network traﬃc containing the user-input data. However, the
server-side analyzer can simply block any game client that
refuses to send the user-input stream. In other words, a sim-
ple policy of “no user-input, no game” can simply thwart this
potential evasion. For those bot programs that attempt to
manipulate the user-input stream, since they already have
total control over the user-input through mouse and key-
board events, the additional beneﬁt provided by the manip-
ulation would be limited.
A more eﬀective evasion for bots is to mimic human be-
haviors. The most obvious approach to mimicking humans
would be a replay attack. That is, a bot could record a
human play of the game and then simply replay the record-
ing. However, the game environment especially in MMOGs
is highly dynamic. A simple replay attack, based on a pre-
recorded game play, cannot successfully adapt to the con-
stantly changing game conditions. Meanwhile, fully control-
ling the game via replay would require separate recordings
of virtually all possible interactions with the game, which is
clearly not feasible due to the large variety of diﬀerent game
tasks.
A more sophisticated approach is to use random models
for generating the diﬀerent user-input actions. However, this
approach would require a separate model for each statistic
and each type of user-input action. With six diﬀerent action
types and seven statistics, it needs more than 40 models just
to capture the marginal distributions. In addition, there are
complicated inter-relations between diﬀerent actions, statis-
tics, and game tasks. While there are new techniques that
can generate synthetic user-input with some human behav-
ioral characteristics, current techniques can merely generate
random mouse movements (not useful for performing spe-
ciﬁc tasks) and are limited to capturing only basic statis-
tics [35, 36].
More importantly, the HOP system is not based on any
single metric of the human behavior, but rather, a collection
of diﬀerent kinds of behavioral metrics composed by neural
networks. A successful evasion of the neural network could
require a simultaneous attack on several of these diﬀerent
metrics. Although it is relatively easy to mimic a single
metric of the human behavior, such as keystroke inter-arrival
time, fully mimicking all aspects of the human behavior in
a highly dynamic environment like MMOGs could require
non-trivial eﬀorts.
The threat of mimicry attacks [50] is real to behavior-
based intrusion detection systems including HOPs. In gen-
eral, we believe that it is possible for a highly motivated bot
creator to build a more complicated game bot, which mim-
ics multiple aspects of human behaviors, to evade the HOP
system but at the cost of signiﬁcant time and eﬀorts.
Exploiting online games has attracted increasing interest
in recent years. Yan et al.
[56] summarized commonly-
used exploiting methods in online games and categorized
them along three dimensions: vulnerability, consequence,
and exploiter.
In addition, they pointed out that fairness
should be taken into account to understand game exploits.
Webb et al. [52] presented a diﬀerent classiﬁcation of game
exploits. They categorized 15 types of exploits into four
levels: game, application, protocol, and infrastructure, and
discussed countermeasures for both client-server and peer-
to-peer architectures. Muttik [34] surveyed security threats
emerging in MMOGs, and discussed potential solutions to
secure online games from multiple perspectives including
technology, economy, and human factor. Hoglund and Mc-
Graw [24] provided a comprehensive coverage of game ex-
ploits in MMOGs, shedding light on a number of topics and
issues.
7.1 Anti-Cheating
With the ever-increasing severity of game exploits, secur-
ing online games has received wide attention. The research
work on anti-cheating generally can be classiﬁed into two
categories: game cheating prevention and game cheating
detection. The former refers to the mechanisms that de-
ter game cheating from happening and the latter comprises
the methods that identify occurrences of cheating in a game.
For MMOGs, a cheat-proof design, especially the design of
the game client program and the communication protocol,
is essential to prevent most of game exploits from occurring.
This is because (1) the client program of an MMOG is under
the full control of a game player and (2) the communication
at the client side might be manipulated for the advantage of
player.
The prevention of game exploits has been the subject of
a number of works. Baughman et al. [2] uncovered the
possibility of time cheats (e.g.,
look-ahead and suppress-
correct cheats) through exploiting communication protocols
for both centralized and distributed online games, and de-
signed a lockstep protocol, which tightly synchronizes the
message communication via two-phase commitment, to pre-
vent cheats. Following their work, a number of other time-
cheat-resistant protocols [9, 13, 15] have been developed. In
[32], M¨onch et al. proposed a framework for preventing game
client programs from being tampered with. The framework
employs mobile guards, small pieces of code dynamically
downloaded from the game server, to validate and protect
the game client. Yampolskiy et al. [55] devised a protection
mechanism for online card games, which embeds CAPTCHA
tests in the cards by replacing the card face with text. Be-
sides software approaches, hardware-based approaches to
countering game exploits have also been proposed. Golle
et al. [22] presented a special hardware device that imple-
ments physical CAPTCHA tests. The device can prevent
game bots based on the premise that physical CAPTCHA
tests such as pressing certain buttons are too diﬃcult for
bots to resolve without human involvement.
In practice, it is extremely hard to eliminate all potential
game exploits. Thus, accurate and quick detection of game
exploits is critical for securing on-line games. Since game
bots are a commonly-used exploit, a fair amount of research
has focused on detecting and countering them. Based on
traﬃc analysis, Chen et al. [10] found that the traﬃc gen-
266erated by the oﬃcial client diﬀers from that generated by
standalone bot programs. Their approach, however, is not
eﬀective against recent game bots, as the majority of cur-
rent MMOG bots interact with oﬃcial clients. In [11, 12],
the diﬀerence of movement paths between human players
and bots in a ﬁrst-person shooter (FPS) game is revealed
and then used for the development of trajectory-based de-
tection methods. However, it is unlikely that this type of
detection method can achieve similar speed and accuracy
in MMOGs, because maps used in MMOGs are much larger
than those in FPS games and avatar trajectories in MMOGs
are far more complicated.
Indeed, Mitterhofer et al. [31]
used movement paths in World of Warcraft and their method
requires from 12 to 60 minutes to detect game bots. Tha-
wonmas et al. [47] introduced a behavior-based bot detection
method, which relies on discrepancies in action frequencies
between human players and bots. However, compared to our
work, the metric used for their detection, action frequency,
is coarse-grained and has low discriminability, resulting in
low detection ratio (0.36 recall ratio on average) and long
detection time (at least 15 minutes).
As game clients in general cannot be trusted, usually the
detection decision is made at servers. Schluessler et al. [45]
presented a client-side detection scheme, which detects input
data generated by game bots by utilizing special hardware.
The hardware is used to provide a tamper-resistant envi-
ronment for the detection module. The detection module
compares the input data generated by input devices (mouse
and keyboard) with those consumed by the game application
and ﬁres an alert once a discrepancy is found.
7.2 Behavioral Biometrics
The idea of HOPs is largely inspired by behavioral bio-
metrics based on keystroke dynamics [5,25,33,40] and mouse
dynamics [1, 20, 43]. Analogous to handwritten signatures,
keystroke dynamics and mouse dynamics are regarded as
unique to each person. Therefore, their applications in user
authentication and identiﬁcation have been extensively in-
vestigated [1,5,20,25,33,40,43]. Generating synthetic mouse
dynamics from real mouse actions has also been studied
[35, 36].
In spite of the fact that our system also utilizes
the characteristics of keystroke and mouse dynamics, it sig-
niﬁcantly diﬀers from aforementioned biometric systems in
that our system leverages the distinction on game play be-
tween human players and game bots, which is reﬂected by
keystroke and mouse dynamics, to distinguish human play-
ers from game bots. In contrast, those biometric systems ex-
ploit the uniqueness of keystroke dynamics or mouse dynam-
ics for identiﬁcation, i.e., matching a person with his/her
identity on the basis of either dynamics.
8. CONCLUSION
In this paper, we presented a game bot defense system
that utilizes HOPs to detect game bots. The proposed HOPs
leverage the diﬀerences of game playing behaviors such as
keyboard and mouse actions between human players and
game bots to identify bot programs. Compared to conven-
tional HIPs such as CAPTCHAs, HOPs are transparent to
users and work in a continuous manner. We collected 95-
hour user-input traces from World of Warcraft. By carefully
analyzing the traces, we revealed that there exist signiﬁcant
diﬀerences between bots and humans in a variety of charac-
teristics derived from game playing actions, which motivate
the design of the proposed HOP defense system.
The HOP defense system comprises a client-side exporter
and a server-side analyzer. The exporter is used to trans-
mit a stream of user-input actions and the analyzer is used
to process the action stream to capture bots. The core of
the analyzer is a cascade-correlation neural network, which
takes an action stream as input and determines if the stream
generator is a bot or a human player. We also employed a
simple voting algorithm to further improve detection accu-
racy. Based on the collected user-input traces, we conducted
a series of experiments to evaluate the eﬀectiveness of the
defense system under diﬀerent conﬁgurations. Our results
show that the system can detect over 99% of current game
bots with no false positives within a minute and the overhead
of the detection is negligible or minor in terms of induced
network traﬃc, CPU, and memory cost. As our detection
engine only relies on user-input information, our HOP sys-
tem is generic to MMOGs.
Acknowledgments
We are very grateful to our shepherd Paul C. Van Oorschot
and the anonymous reviewers for their insightful and de-
tailed comments. This work was partially supported by NSF
grants CNS-0627339 and CNS-0627340.
9. REFERENCES
[1] A. A. E. Ahmed and I. Traore. A new biometric technology
based on mouse dynamics. IEEE Trans. on Dependable and
Secure Computing (TDSC), 4(3), 2007.
[2] N. E. Baughman and B. N. Levine. Cheat-proof playout for
centralized and distributed online games. In Proceedings of
the 20th IEEE INFOCOM, Anchorage, AK, USA, April
2001.
[3] BBC News Staﬀ. Legal battle over warcraft ‘bot’.
http://news.bbc.co.uk/2/hi/technology/7314353.stm
[Accessed: Jan. 30, 2009].
[4] J. Bennett. AutoIt: Automate and script windows tasks.
http://www.autoit.com/ [Accessed: Apr. 20, 2009].
[5] F. Bergadano, D. Gunetti, and C. Picardi. User
authentication through keystroke dynamics. ACM Trans.
on Information and System Security (TISSEC), 5(4), 2002.
[6] Blizzard Entertainment. MDY industries, LLC., vs.
Blizzard Entertainment, Inc., and Vivendi Games, Inc.
http://gamepolitics.com/images/legal/blizz-v-MDY.pdf
[Accessed: Jan. 30, 2009].
[7] Blizzard Entertainment. World of Warcraft subscriber base
reaches 11.5 million worldwide. http://eu.blizzard.com/
en/press/081223.html [Accessed: Jul. 24, 2009].
[8] P. Caldwell. Blizzard bans 59,000 WOW accounts.
http://www.gamespot.com/news/6154708.html [Accessed:
Aug. 13, 2009].
[9] B. D. Chen and M. Maheswaran. A cheat controlled
protocol for centralized online multiplayer games. In
Proceedings of the 3rd ACM SIGCOMM NetGames,
Portland, OR, USA, August 2004.
[10] K.-T. Chen, J.-W. Jiang, P. Huang, H.-H. Chu, C.-L. Lei,
and W.-C. Chen. Identifying MMORPG bots: A traﬃc
analysis approach. In Proceedings of the 2006 ACM
SIGCHI International Conference on Advances in
Computer Entertainment Technology (ACE’06), June 2006.
[11] K.-T. Chen, A. Liao, H.-K. K. Pao, and H.-H. Chu. Game
bot detection based on avatar trajectory. In Proceedings of
the 7th International Conference on Entertainment
Computing, Pittsburgh, PA, USA, September 2008.
[12] K.-T. Chen, H.-K. K. Pao, and H.-C. Chang. Game bot
identiﬁcation based on manifold learning. In Proceedings of
267the 7th ACM SIGCOMM NetGames, Worcester, MA, USA,
October 2008.
2008].
[35] A. Nazar. Synthesis and simulation of mouse dynamics.
[13] E. Cronin, B. Filstrup, and S. Jamin. Cheat-prooﬁng dead
Master’s thesis, University of Victoria, October 2007.
reckoned multiplayer games (extended abstract). In
Proceedings of the 2nd International Conference on
Application and Development of Computer Games, Hong
Kong, China, January 2003.
[36] A. Nazar, I. Traore, and A. A. E. Ahmed. Inverse
biometrics for mouse dynamics. International Journal of
Pattern Recognition and Artiﬁcial Intelligence,
22(3):461–495, 2008.
[14] Diablo 2 Guide. D2 bots. http://www.diablo2guide.com/
[37] P. Neva. Bots back in the box.
bots.php [Accessed: Nov. 2, 2008].
[15] C. G. Dickey, D. Zappala, V. Lo, and J. Marr. Low latency
and cheat-proof event ordering for peer-to-peer games. In
Proceedings of the 14th ACM NOSSDAV, Cork, Ireland,
June 2004.
[16] DMW World. DMW anti-cheat system.
http://www.dmwworld.com/viewfaq/show/374 [Accessed:
Aug. 13, 2009].
[17] Even Balance Inc. PunkBuster online countermeasures.
http://www.evenbalance.com [Accessed: Jul. 9, 2008].
[18] Exploits R Us. Ultima Online bots and cheats. http://www.
exploitsrus.com/uo/bots.html [Accessed: Nov. 2, 2008].
[19] S. E. Fahlman and C. Lebiere. The cascade-correlation
learning architecture. In Advances in Neural Information
Processing Systems 2, 1990.
[20] H. Gamboa and A. Fred. A behavioral biometric system
based on human computer interaction. In Proceedings of
SPIE: Biometric Technology for Human Identiﬁcation,
volume 5404, 2004.
[21] S. Gianvecchio, M. Xie, Z. Wu, and H. Wang. Measurement
and classiﬁcation of humans and bots in internet chat. In
Proceedings of the 17th USENIX Security Symposium, San
Jose, CA, USA, July 2008.
[22] P. Golle and N. Ducheneaut. Preventing bots from playing
online games. Computers in Entertainment, 3(3), 2005.
[23] G. Gu, R. Perdisci, J. Zhang, and W. Lee. BotMiner:
Clustering analysis of network traﬃc for protocol- and
structure-independent botnet detection. In Proceedings of
the 17th USENIX Security Symposium, San Jose, CA,
USA, July 2008.
[24] G. Hoglund and G. McGraw. Exploiting Online Games:
Cheating Massively Distributed Systems. No Starch Press,
2007.
[25] R. Joyce and G. Gupta. Identity authentication based on
keystroke latencies. Communications of the ACM, 33(2),
1990.
[26] E. Kirda, C. Kruegel, G. Banks, G. Vigna, and
R. Kemmerer. Behavior-based Spyware Detection. In
Proceedings of the 15th USENIX Security Symposium,
Vancouver, Canada, August 2006.
[27] U. Kukreja, W. E. Stevenson, and F. E. Ritter. RUI -
recording user input from interfaces under Windows and
Mac OS X. Behavior Research Methods, Instruments, and
Computers, 38(4):656–659, 2006.
[28] C. McSherry. A new gaming feature? spyware.
http://www.eff.org/deeplinks/2005/10/
new-gaming-feature-spyware [Accessed: Jul. 9, 2008].
[29] MDY Industries. MMO glider. http://www.mmoglider.com/
[Accessed: Nov. 2, 2008].
[30] W. Meloni. State of the game industry 2008. In GameOn
Finance Conference, San Diego, CA, USA, October 2008.
[31] S. Mitterhofer, C. Platzer, C. Kruegel, and E. Kirda.
Server-side bot detection in massive multiplayer online
games. IEEE Security and Privacy, 7(3), May/June 2009.
[32] C. M¨onch, G. Grimen, and R. Midtstraum. Protecting
online games against cheating. In Proceedings of the 5th
ACM SIGCOMM NetGames, Singapore, October 2006.
[33] F. Monrose and A. Rubin. Authentication via keystroke
dynamics. In Proceedings of the 4th ACM CCS, Zurich,
Switzerland, April 1997.
[34] I. Muttik. Securing virtual worlds against real attacks.
http://www.mcafee.com/us/local_content/white_papers/
threat_center/wp_online_gaming.pdf [Accessed: Nov. 2,
http://www.secondlifeherald.com/slh/2006/11/bots_
back_in_th.html [Accessed: Nov. 2, 2008].
[38] nProtect. nProtect GameGuard. http://eng.nprotect.
com/nprotect_gameguard.htm [Accessed: Jul. 9, 2008].
[39] M. M. Owned. World of Warcraft bots and programs
forum. http://www.mmowned.com/forums/bots-programs/
[Accessed: Jul. 21, 2009].
[40] A. Peacock, X. Ke, and M. Wilkerson. Typing patterns: A
key to user identiﬁcation. IEEE Security and Privacy, 2(5),
2004.
[41] PiroX. PiroX Bot - World of Warcraft bot.
http://www.piroxbots.com/ [Accessed: Jul. 25, 2009].
[42] M. D. Preda, M. Christodorescu, S. Jha, and S. Debray. A
semantics-based approach to malware detection. In
Proceedings of the 34th ACM POPL, Nice, France, January
2007.
[43] M. Pusara and C. E. Brodley. User re-authentication via
mouse movements. In Proceedings of the 2004 ACM
Workshop on Visualization and Data Mining for Computer
Security, Washington, DC, USA, October 2004.
[44] Rhabot. Rhabot - World of Warcraft bot.
http://www.rhabot.com/ [Accessed: Nov. 2, 2008].
[45] T. Schluessler, S. Goglin, and E. Johnson. Is a bot at the
controls?: Detecting input data attacks. In Proceedings of
the 6th ACM SIGCOMM NetGames, Melbourne,
Australia, September 2007.
[46] Slashdot. Confessions of an Ultima Online gold farmer.
http://slashdot.org/games/05/01/26/1531210.shtml
[Accessed: Jul. 9, 2008].
[47] R. Thawonmas, Y. Kashifuji, and K.-T. Chen. Detection of
MMORPG bots based on behavior analysis. In Proceedings
of 5th ACM International Conference on Advances in
Computer Entertainment Technology (ACE’08),
Yokohama, Japan, December 2008.
[48] The MMO RPG Exchange. World of Warcraft exchange.
http://themmorpgexchange.com/ [Accessed: Jul. 25, 2009].
[49] Valve Corporation. Valve anti-cheat system (VAC).
https://support.steampowered.com/kb_article.php?p_
faqid=370 [Accessed: Jul. 9, 2008].
[50] D. Wagner and P. Soto. Mimicry attacks on host-based
intrusion detection systems. In Proceedings of the 9th ACM
CCS, Washingtion, DC, USA, November 2002.
[51] H. Wang, D. Zhang, and K. G. Shin. Detecting SYN
ﬂooding attacks. In Proceedings of the 21st IEEE
INFOCOM, New York, NY, USA, June 2002.
[52] S. D. Webb and S. Soh. Cheating in networked computer
games – a review. In Proceedings of the 2nd International
Conference on Digital Interactive Media in Entertainment
and Arts, Perth, Australia, September 2007.
[53] W. Willinger, V. Paxson, and M. S. Taqqu. Self-similarity
and heavy tails: Structural modeling of network traﬃc. In
Statistical Techniques and Applications, pages 27–53.
Verlag, 1998.
[54] WoW Panda. ZoloFighter - World of Warcraft bot.
http://www.zolohouse.com/wow/wowFighter/ [Accessed:
Jul. 25, 2009].
[55] R. V. Yampolskiy and V. Govindaraju. Embedded
non-interactive continuous bot detection. Computers in
Entertainment, 5(4), 2007.
[56] J. Yan and B. Randell. A systematic classiﬁcation of
cheating in online games. In Proceedings of the 4th ACM
SIGCOMM NetGames, Hawthorne, NY, USA, October
2005.
268