We then classiﬁed the domains in the evaluation
dataset, with the assistance of a Random Forest classi-
ﬁer, as we already discussed in Section 3. We used a
training period of 30 consecutive days and a testing pe-
riod of m = 21 days immediately following the training
period. The detection threshold θ was set to 0.9 to obtain
a good operational trade-off between false positives and
detection rate. Our primary reasoning behind setting the
threshold θ to 0.9 was to keep the F Prates as low as pos-
sible so that an operator would only have to deal with a
very small number of FPs on a daily basis. We repeated
this evaluation four times during different months within
our eight months of trafﬁc monitoring.
In Figure 9 and Figure 10, we can see the results
of these experiments. From left to right, we can see
the evaluation on 21 days of trafﬁc in February, March,
May and June of 2010. We trained the system based
on one month of trafﬁc from January, February, March
and May 2010, respectively. We chose these months be-
cause we had continuous daily observations (i.e., no data
gaps) from both training and testing datasets. As in the
longterm 10-fold evaluation, we performed the experi-
ments using six different datasets obtained using differ-
ent feature subsets.
We present the results in the same way as in Sec-
tion 5.4. When we used all features we observed the av-
erage F Prates was 0.53% ( ∼ two domains), while the
average T Prates was 73.62% (3,528 domain names). For
the RP+RD Features and IPR Features the aver-
age F Prates were 0.54% (∼ two domains) and 0.79% (∼
two domains), respectively; while the average T Prates
were 69.19% (3,315 domain names) and 87.25% (4,181
domain names), respectively. The RP+RD+AS(IPR)
Features, gave average F Prates = 0.66% (or ∼
two domain names) and average T Prates = 65.05% (or
3,117 domain names).
When we used the combination of all features we see
that for the ﬁrst 42 days of evaluation (February and
March of 2010) Kopis had a virtually zero F Prates and
an average T Prates = 68%. In the following 42 days of
evaluation, Kopis, had better T Prates but with some ex-
10
 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 10 20 30 40 50 60 70 80TP RateIPR FeaturesRP+RD FeaturesAll Features 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 0 10 20 30 40 50 60 70 80TP RateDaysRP FeaturesRD FeaturesRP+RD+AS(IPR) 0 0.005 0.01 0.015 0.02 0.025 0.03 0 10 20 30 40 50 60 70 80FP RateIPR FeaturesRP+RD FeaturesAll Features 0 0.005 0.01 0.015 0.02 0.025 0.03 0 10 20 30 40 50 60 70 80FP RateDaysRP FeaturesRD FeaturesRP+RD+AS(IPR)remove botnets from the Internet before they become a
large security threat.
5.6 Canadian TLD
Thus far, the experiments we have reported were all us-
ing data available at AuthNSs. A TLD server is one level
above AuthNS servers in the DNS hierarchy, and as such,
it has a greater global visibility but with less granular
data on DNS resolution behaviors. In this section we re-
port our experiments of Kopis at the TLD level.
We evaluated Kopis on query data obtained from the
Canadian TLD. We used the same evaluation method in-
troduced in Section 5.5 but with different training win-
dow sizes, testing epochs and classiﬁcation thresholds.
Before we describe the results, we should note that all
TLD trafﬁc needs passive reconstruction of the query
data to identify the IPs addresses in the A-type re-
source records. We used a passive DNS database com-
posed of data from four ISP sensors and the passive DNS
database from SIE [24]. The Canadian TLD’s trafﬁc was
harvested from SIE [24] (channel three).
Unfortunately, due to the fact that we obtained traf-
ﬁc from only 52 days (2010-08-26 until 2010-10-18) we
had to use a smaller training epoch of 14 days (instead of
one month). We evaluated Kopis using the RF classiﬁer,
14 consecutive days as the training epoch, 14 days fol-
lowing the training epoch as the evaluation epoch, and
setting the threshold θ = 0.9. Two sequential training
epochs had seven days in common. The exact training
epochs were 08-27 to 09-11, 09-04 to 09-18, 09-11 to
09-25 and 09-18 to 10-02 while the corresponding eval-
uation epochs were 09-12 to 09-26, 09-19 to 10-03, 09-
26 to 10-10 and 10-03 to 10-17, respectively. Without
changing the data labeling methodology, we assembled
a dataset with 2,199 malware related and 1,018 benign
unique deduplicated domain names.
In Figure 12 and Figure 13, we can see the results of
this experiment. As with the experiments in Section 5.5,
we evaluated Kopis in six modes, using as threshold
θ = 0.5. We should note here that the evaluation of the
RD+RP Features reﬂects the evaluation mode with
datasets that were composed only by the combination of
RD and RP features. Such dataset can be extracted di-
rectly from data readily available at a TLD server (in
other words, the RD+RP Features is the most “efﬁ-
cient” mode that Kopis can operate in and can be com-
puted on the ﬂy at a TLD server).
When we used all features we observed the av-
erage F Prates was 0.52% (∼ six domain names),
while the average T Prates was 94.68% (2,082 do-
main names). For the RP+RD Features and IPR
Features the average F Prates were 3.18% (∼ 33 do-
main names) and 0.36% (∼ four domain names), respec-
Figure 11: Kopis early detection results. The deltas in
days between the Kopis classiﬁcation dates and the date
we’ve received a corresponding malware sample for the
domain name.
tra false positives, always below 0.5%. Investigating the
nature of the false positives, we observed that the domain
names responsible are related to BitTorrent services, on-
demand web-TV services and what appeared to be on-
line gaming sites. We suspect that the main reason why
these domains cause false positives is because the pop-
ulation of similar legitimate services was insufﬁciently
represented during training, and therefore, the RF clas-
siﬁer failed to learn this behavior as being legitimate in
training.
This experiment showed that Kopis — with all fea-
tures used — can detect new and previously unclassiﬁed
domains with an average T Prate of 73.62% and average
F Prate of 0.53%. Although this is worse than the overall
detection performance reported in Section 5.4, it is actu-
ally a good result considering that Kopis has no knowl-
edge of the domains in the testing dataset. It implies that
Kopis has good “real-world value” thanks to its ability to
detect new, previously unseen attacks is at a premium.
Figure 11 shows the difference in days between the
time that Kopis identiﬁes a true positive domain as being
malware-related, and the day we ﬁrst obtained the mal-
ware sample associated with the malware-related domain
from our malware feed. To perform this measurement,
we used malware from a commercial malware feed with
volume between 400 MB to 2 GB of malware samples
every day. Additionally, we used malware captured from
two corporate networks. As we can see, Kopis was able
to identify domain names on the rise even before a cor-
responding malware sample is accessible by the security
community. This result shows that Kopis can provide the
ability to the registrars and TLD operators to preemp-
tively block or take down malware related domains and
11
Figure 12: T Prates achieved during evaluation of trafﬁc
obtained from .ca TLD.
Figure 13: F Prates achieved during evaluation of trafﬁc
obtained from .ca TLD.
tively; while the average T Prates were 63.63% (1,399
domain names) and 10.84% (238 domain names), re-
spectively. The RP+RD+AS(IPR) Features, gave
the average F Prates = 1.03% (or ten domain names)
and average T Prates = 78.95% (or 1,736 domain
names).
During the RP+RD Features evaluation, we ob-
served that the average T Prates reached 63.63% while
the average F Prates were in the range of 3.18%. These
were very promising results despite the relatively high
F Prates because we can operate Kopis using a sequential
classiﬁcation mode, starting with RP+RD Features
followed by All Features. Kopis in this “in-series”
classiﬁcation mode can achieve a good balance of efﬁ-
ciency and accuracy.
More speciﬁcally, at the ﬁrst step in the sequential pro-
cess, Kopis is a “coarse ﬁlter” that operates in RP+RD
Features with only the RP and RD statistical features
and threshold θ = 0.5. Any domain name that passes
this ﬁlter (i.e., with a “malware-related” label) then re-
quires additional feature computation, i.e., reconstruct-
ing the resolved IP address records, and further classi-
ﬁcation at the next step in the sequential process. On
the other hand, domains that are dropped by this ﬁlter
(i.e., with a “legitimate” label) are no longer analyzed by
Kopis. Thus, the ﬁrst step ﬁlter is essentially a data re-
duction tool, and the sequential classiﬁcation process is
a way to delay the expensive computation until the data
volume is reduced. This technique is very important at
the TLD level given the potentially huge volume of data.
In our experiments Kopis operating at the ﬁrst step
with RP+RD Features (and threshold θ = 0.5)
yielded an average data reduction rate5 of 87.95% on
1 −
reduction
T Pmalware+F Pmalware
, where T Pmalware is the true posi-
tives for the malware-related class, F Pmalware is the mis-classiﬁed
follows:
deﬁne
rate
as
5We
the
ALL
the original dataset. After this reduction, at the second
step, we evaluated Kopis on the (remaining) dataset us-
ing all features, and keeping the same threshold θ = 0.5.
The average F Prates reported at this step by Kopis were
zero while the average T Prates were 94.44%. The over-
all F Prates and T Prates for this “in-series” mode were
zero and 60.09% (1,321 domain names), respectively.
At this point we should note that the threshold θ was
set again with the intention to have the F Prates as close
to 1.0% as possible but also not to sacriﬁce much of the
T Prate produced from the ﬁrst classiﬁcation process in
the “in-series” mode. As we saw previously, even when
we had some FPs created by the RP+RD Features
(the ﬁrst classiﬁcation process in the “in-series” mode),
the combination of statistical features in the second “in-
series” mode was able to prune away these FPs. An op-
erator may choose to lower the threshold θ even more
and have as an immediate effect, the increase of domain
names that will be forwarded to the second “in-series”
classiﬁcation process, with a potential increase in the
overall T Prate and F Prates. The experiments in this
section showed that by using an “in-series” classiﬁcation
process where different steps can use different (sub)sets
of features and thresholds, Kopis can achieve a good bal-
ance of detection performance and operation efﬁciency
at the TLD level.
5.7 DDos Botnet Originated in China
As discussed in Section 1, Kopis was designed to have
global visibility so that it can detect domains associ-
ated with malware activities running in an uncooperative
country or networks before the attacks propagate to net-
as malware-related benign domain names and ALL all as the domain
names in the evaluation dataset.
12
 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 10 20 30 40 50TP RateIPR FeaturesRP+RD FeaturesAll Features 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 10 20 30 40 50TP RateDaysRP FeaturesRD FeaturesRP+RD+AS(IPR) 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0 10 20 30 40 50FP RateIPR FeaturesRP+RD FeaturesAll Features 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0 10 20 30 40 50FP RateDaysRP FeaturesRD FeaturesRP+RD+AS(IPR)Figure 14: Various growth trends for the DDoS botnet.
Day zero is 03-20-2010.
Figure 15: A snapshot from the ﬁrst 70 days of the bot-
net’s growth with respect to the country code-based res-
olution attempts for the DDoS botnet’s domain names.
Day zero is 03-20-2010.
works that it protects. In this section, we report a case
study to demonstrate Kopis’s global detection capability.
Kopis was able to identify a commercial DDoS botnet
in the ﬁrst few weeks of its propagation in China and well
before it began propagating within other countries, in-
cluding the US. We alerted the security community, and
the botnet was ﬁnally removed from the Internet in the
middle of September 2010. Next we provide some in-
tuition behind this discovery and why Kopis was able to
detect this threat early.
This DDoS botnet was controlled through 18 domain
names, all of which were registered by the attacker under
the same authority (although with different 2LDs). Kopis
was deployed at the AuthNS server and was able to ob-
serve resolution requests to these domains (even when
the infected machines were initially not in the US) and
classify them as malware-related because their resolution
patterns ﬁt the proﬁles of known malware domains in its
knowledge base.
These domain names were linked with six IP addresses
located in the following autonomous systems: 14745
(US), two in 4837 (CN), 37943 (CN) and two in 4134
(CN), throughout the lifetime of the botnet. We show
the difference between the absolute DNS lookups ver-
sus the daily volume of unique query tuples in Figure 14
(i). The average lookup volume every day was 438,471
with average de-duplicated query tuples in the range of
3,883. Despite this signiﬁcant data reduction, Kopis was
still able to track and identify this emerging threat. In
Figures 14 (ii), (iii) and (iv), we can see the daily growth
of unique CIDRs, AS and CCs related to the RDNSs that
queried the domain names used in the botnet.
An interesting observation can be made from Fig-
ure 15. In this ﬁgure we can see the daily lookup volume
for the domain names of this botnet. Instantly we can see
that the ﬁrst big infection happened in Chinese networks
in a relatively short period of time (in the ﬁrst 2-3 days).
After this initial infection, a number of machines from
several other countries were also infected but nowhere
close to the volume of the infected population in the Chi-
nese networks. As an example we can see in Figure 15
that the ﬁrst time more than 1,000 daily lookups were
observed from the United States was more than 20 days
after the botnet was launched. Also, other countries such
as Poland and Thailand had the ﬁrst infection 21 and 25
days after the botnet were lunched. Furthermore, large
countries such as Italy, Spain and India reached the 100
daily lookup threshold 15 days later than the start of this
botnet. Clearly, for countries like Poland and Thailand
(and even Italy, Spain and India to a large extent) local-
ized DNS reputation techniques could not have been able
to observe a resolution request (or a strong enough sig-
nal) for any of the domain names related to this botnet,
until the botnet had reached global scale, which was sev-
eral weeks after it was launched. Figure 16 shows the
volume of samples correlated with this botnet as they
appeared in our malware feeds. We observe that the
ﬁrst malware sample related to this botnet appeared two
months after the botnet became active.
To demonstrate the contribution of each feature fam-
ily towards the identiﬁcation of the domain names that
were part of this botnet we conducted the following ex-
periment. We trained Kopis with 30 days of data before
the 5th of May 2010. Then we computed vectors for
all the domain names that were part of the botnet. We
computed one vector every day for each domain name