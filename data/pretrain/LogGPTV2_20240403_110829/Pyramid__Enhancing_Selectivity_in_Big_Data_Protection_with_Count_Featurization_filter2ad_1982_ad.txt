query has sensitivity Δ, then adding noise drawn from a
Laplace distribution with scale parameter Δ
 guarantees
that the result is -differentially private [21]. Increasing
√
Δ
increases the standard deviation of the distribution

(stdev of a Laplace distribution with parameter b is b
2).
3. Composability: Differentially private queries are
composable:
the sum of n n-differentially private
queries is (Σn)-differentially private [28]. This lets us
maintain multiple count tables, possibly with different
budgets, and combine them without breaking guarantees.
(Advanced composition theorems allow sublinear loss in
the privacy budget by relaxing the guarantees to (, δ)-
differential privacy [29], but we do not explore that here.)
4. Post-processing resilience: Any computation on a
differentially private data release remains differentially
private [29]. This is a crucial point for Pyramid’s protec-
tion guarantees: it ensures that guarantee P2, the protec-
tion of individual past observations during their lifetime,
holds for each model’s internal state and outputs. As long
as models comply with retrain calls and erase all internal
state when they do, their output is differentially private
with regard to observations outside the hot window.
Basic noise infusion process. We apply these known
properties when creating count tables for the hot window.
Upon creating a count table, we initialize each cell of
the CMS storing that table with a random draw from
a Laplace distribution. This noise is added only once:
the count tables are updated as observations arrive and
are sealed when the hot window rolls over. To determine
the correct parameter for the Laplace distribution, b, we
must account for three factors: (1) the internal structure
of the CMS, (2) the number of observations we want to
hide simultaneously, and (3) the number of count tables
(features or feature combinations) we are maintaining.
table has sensitivity 1 since
adding or removing an observation can only change one
count by 1. For a CMS, each observation is counted
once per hash function; hence, the sensitivity is h, the
number of hash functions. Second, if we aim to hide any
group of k observations with a privacy budget of , then
we make a count table -differentially private by adding
noise from a Laplace distribution of parameter b = hk
in

every cell of the CMS. Third, we must maintain multiple
count tables for the different features and feature groups.
Since each observation affects every count table, we need
to split the privacy budget  among them, e.g., splitting
it evenly by adding noise with b = nhk

First, an exact count
to each table.
The third consideration poses a signiﬁcant challenge
for Pyramid: the amount of noise we apply grows lin-
early with the number of count tables we keep. Since the
amount of noise directly affects application accuracy, this
yields a protection/accuracy tradeoff, which we address
with weighted noise infusion.
Weighted noise infusion process. We note that count
tables are not all equally susceptible to noise. For ex-
ample in our movie recommender, the user table most
likely contains low values, since each user rates only a
few movies (29 for the median user). Moreover, we do
not expect this count to change signiﬁcantly when adding
more data, since single users will not rate signiﬁcantly
more movies. Each genre table however contains higher
values (1M or more), since each genre characterizes
multiple movies, each rated by many users. Sharing noise
equally between tables would pollute all counts by a
standard deviation of 145 ( = 1, h = 5, and k = 1),
a reasonable amount for genres, but devastating for the
user feature, which essentially becomes random.
Pyramid’s weighted noise infusion distributes the
tables, adding
privacy budget unevenly across count
less noise to low-count features. This way, we retain
more utility from those tables, and the composability
property of differential privacy preserves our protection
guarantees. Each table’s share of noise is determined
automatically, based on the count values observed in the
hot window. Speciﬁcally, the user speciﬁes a quantile,
and the privacy budget is shared between each feature
proportionally to this quantile of its counts. For instance
we use the ﬁrst percentile, so that 99% of the counts for
a feature will be less affected by the noise. Sharing the
privacy budget proportionally to the counts is a heuristic
that makes the noise’s standard-deviation proportional to
the typical counts of each feature. This scheme is also
independent of the learning algorithm.
Finally, the weight selection process should be made
differentially private so the weights computed on a
previous hot window do not reveal anything about that
window’s data at a later time. While our implemen-
tation currently does not do this, a design might use
a small portion of one window’s privacy budget and
leverage smooth sensitivity [30] to compute differentially
private count percentiles that can be used as feature
weights. One could compute each weight as a separate
differentially private query, or use the sample-aggregate
framework and the center of attention aggregation [30]
to compute all the weights in one query.
Section V shows that weighted noise infusion is vital
for providing protection while preserving accuracy at
scale: without it, the cost of hiding single observations is
a 15% accuracy loss; with it, the loss is less than 5%. We
leave the evaluation of incorporating differential privacy
into the weight selection method for future work.
Unbiased private count-median sketch. Another factor
that degrades performance when adding differentially
private noise is the interaction between the noise and
the CMS. In the CMS, the ﬁnal estimate for a count is
84
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:25:23 UTC from IEEE Xplore.  Restrictions apply. 
min(hi(key)) for each row i. The minimum makes sense
here since collisions can only increase the counts. The
Laplace distribution however is symmetric around zero,
so we may add negative noise to the counts. Taking the
minimum of multiple draws—each cell is initiated with
a random draw from the distribution—thus selects the
most extreme negative values, creating a downward bias
that can be very large for a small .
We observe that because the mean of the Laplace
distribution is 0, an unbiased estimator would not suffer
from this drawback. For tables with large noise, we thus
use a count-median sketch [27], which differs in two
ways: 1) each row i has another hash function si that
maps the key to a random sign si(key) ∈ {+1,−1}, with
each cell updated with si(key)hi(key); 2) the estimator is
the median of all counts multiplied by their sign, instead
of the minimum. The signed update means that collisions
have an expected impact of zero, since they have an equal
chance of being negative or positive, making the cell an
unbiased estimate of the true count. The median is a
robust estimate that preserves the unbiased property.
Using this count-median sketch reduces the impact
of noise, since values from the Laplace distribution are
exponentially concentrated around the mean of zero. §V
shows that for small , or a large number of features, it
is worth trading the CMS’s better guarantees for reduced
noise impact with the count-median sketch.
III.B.3. Data Retention
While differential privacy provides a reasonable level
of protection for past observations, complete removal
of information remains the cleanest, strongest form of
protection (design R3 in §II-C). Pyramid supports data
expiration with windowed count tables. When an obser-
vation arrives, Pyramid updates the count tables for the
current count window only. To featurize (cid:2)x, Pyramid sums
the relevant counts across windows. Periodically, it drops
the oldest window and invokes retraining of all models
in Velox (retrain method). Our use of count-based
featurization supports such behaviors because retraining
is cheap (§V-E), so we can afford to do it frequently.
III.B.4. Count Selection
Pyramid seeks to support workload evolution (model
changes/additions, such as future model M4 in Fig. 2)
using only the widely accessible stores without tapping
into the historical raw data store. To do so, it uses two
approaches. First, it stores the count tables in a very
compact representation—the count-median sketches—so
it can afford to keep plenty of count tables. Second, it
includes an automatic process of count table selection
that inspects the data to identify feature combinations
worth counting, whether they are used in the current
workloads or not. This technique is useful because
count featurization tends to obscure correlations between
features. For example, different users may have different
opinions about speciﬁc ads. Although that information
could be inferred by a learning algorithm from the raw
data points, it is not accessible in the count-featurized
data unless we explicitly count the joint occurrences of
speciﬁc users with speciﬁc ads, i.e., maintain a table for
the (cid:3)userId, adId(cid:4) group.
We adapted several feature selection techniques [31] to
select feature groups and describe one here. Mutual In-
formation (MI) is a measure of dependence between two
random variables. A common feature selection technique
keeps features of high MI with the label. We extend
this mechanism for group count selection. Our goal is
to identify feature groups that provide more information
about the label than individual features. For each feature
xi, we ﬁnd all other features xj such that xi and xj
together exhibit higher MI with the label than xi alone.
From these groups, we select a conﬁgurable number with
highest MIs. To ﬁnd promising groups of larger sizes,
we apply this process greedily, trying out new features
with existing groups. For each selected group, Pyramid
creates and maintains a count table.
This exploration of promising groups operates on the
hot window of raw data. Because the hot raw data is
limited, the selection may not be entirely reliable. There-
fore, count tables for new groups are added on a “trial
basis.” As more data accumulates in the counts, Pyramid
re-evaluates them by computing the MI metric on the
count tables. With the increased amount of data, Pyramid
can make a more reliable decision regarding which
count tables to keep and which to drop. Because count
selection—like feature selection—is never perfect, we
give engineers an API to specify groups that they know
are worth counting from domain knowledge. Finally, like
the weight selection process, count selection should be
made differentially private so the groups selected in a
particular hot window, which are preserved over time,
do not leak information about the window’s data in the
future. We leave this for future work.
III.C. Supported Workload Evolution
Count featurization is a model-independent prepro-
cessing step, allowing Pyramid to absorb some common
evolutions during an ML application’s life cycle without
tapping the historical raw data store. §V-G gives anecdo-
tal evidence of this claim from a production workload.
This section reviews the types of workload changes
Pyramid currently absorbs.
A developer may want to change four aspects of the
model: (1) the algorithm used to train the model (2)
hyperparameters for the model or for the underlying
optimization algorithm, (3) features used by the model,
and (4) the predicted label. Pyramid supports (1) and (2),
partially supports (3), and usually does not support (4).
85
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:25:23 UTC from IEEE Xplore.  Restrictions apply. 
• Algorithm changes: Supported. Pyramid allows devel-
opers to move between types of models and libraries
used to train those models as long as they are using
features and labels that are already counted. In our eval-
uation we experimented with linear models and neural
networks in Vowpal Wabbit [32] and gradient boosted
trees in scikit-learn [33] using the same count tables.
• Hyperparameter tuning: Supported. By far the most
common type of model change we encountered, both
in our own evaluation and in reports from a produc-
tion setting, was hyperparameter tuning. For example, a
developer may want to change model hyperparameters,
such as the number of hidden units in a neural network,
or tune parameters of the underlying optimization algo-
rithm, such as the learning rate or an L1/L2 regulariza-
tion penalty. Changing hyperparameters is independent
from the underlying features so is supported by Pyramid.
• Feature changes: Partially supported. Pyramid sup-
ports making minimal feature changes. A developer may
want to perform one of three types of feature changes:
adding new features, removing existing features, or
adding interactions between existing features. Pyramid
trivially supports removing existing features, and lets
developers add new features if they are based on existing
ones. For example, the developer could not create an
(cid:3)Age, Location(cid:4) feature interaction if the individual fea-
tures were not already counted together. Introducing new
feature combinations or interactions requires creating
new count tables. This highlights the importance of count
selection to support workload evolution.
• Label changes: Mostly unsupported. Changes in pre-
dicted labels are not supported except if a new label
is a subset of an existing label. For example, a news
recommender could not start predicting retention time
instead of clicks unless retention time was previously
declared as a label. As with features, Pyramid can
support label changes when the new label is a subset of
an existing one. For example, if a label exists that tracks
retention time in time buckets, Pyramid can support new,
coarser labels, such as the three classes “0 seconds,” “less
than a minute,” and “more than a minute.”
III.D. Summary
With these components, Pyramid meets the design re-
quirements noted in §II-C, as follows. R1: By enhancing
the training set with historical statistics gathered over a
longer period of time, we minimize the hot data. R2: By
automatically identifying combinations of features worth
maintaining, we avoid having to access the historical
raw data for workloads that use the same observation
streams to predict the same label. R3: By rolling the
count windows and retraining the application models, we
support data retention policies, albeit at a coarse level.
§V evaluates R4: accuracy and performance impact.