#BHUSA @BlackHatEvents
**Better Privacy Through Offense: How To Build a Privacy Red Team**
Scott Tenaglia, Engineering Manager, Privacy Red Team, Meta

**Information Classification: General**

## Agenda
1. The Case for Offensive Privacy
2. Security and Privacy
3. Meta’s Privacy Red Team
4. Operations Ideas
5. Final Thoughts

---

### Introduction
This talk aims to:
- Initiate a conversation about offensive privacy.
- Provide a blueprint for creating a similar team or offering at your organization.
- Explain how privacy red teaming fits into a holistic privacy program.

This talk is not:
- A product or service pitch.
- A discussion on other aspects of Meta beyond privacy red teaming.
- About absolutes.
- The final word on this topic.

---

### The Case for Offensive Privacy
Have you ever:
- Encountered PII during an operation but didn't know how to handle it?
- Been asked to start recording access to user data as a finding?
- Been tasked with performing a more privacy-focused assessment?
- Had a finding that was dismissed due to insufficient "security" impact?

---

### Security and Privacy
Security and privacy programs help mitigate risk. Red teams identify actual risk by testing mitigations from an adversarial perspective. Mitigations are a combination of people, processes, and technology (i.e., a blue team).

**Red Team Activities:**
- **Scraping, Scanning, Attack Surface Enumeration, Large-Scale Data Access:** These activities help identify the actual risks to systems, networks, and user privacy.

**Key Differences:**
- **Accessing Data:** Security red teams may avoid accessing user data due to regulatory and legal implications. Privacy red teams focus on finding and addressing such access, often partnering with legal teams to mitigate compliance issues.
- **Adversaries:** Adversaries in privacy differ from those in security in terms of timescale, resources, and technical sophistication.
- **Targets:** Security operations target systems and networks, while privacy operations directly access data through products and services where many privacy controls are implemented.
- **Blue Teams:** At Meta, we have developed a privacy "blue team" to mitigate privacy risks. Privacy red team operations often test multiple blue teams.

---

### Meta’s Privacy Red Team
**Mission:**
- Proactively test people, processes, and technology from an adversarial perspective to identify the actual risks to protecting users’ data and their privacy.

**Functions:**
- **Privacy Adversary Modeling**
- **Privacy Weaknesses Cataloging**
- **Technical Assessments**
- **Educate & Inform**

**Key Products/Services:**
- Privacy ATT&CK Framework
- Privacy Weaknesses Taxonomy
- Privacy threat modeling
- Tabletop exercises
- Adversary emulation
- Privacy purple team
- Product compromise tests
- Risk management feedback
- Incident response support
- Engineering support
- Privacy education and training

**Team Composition:**
- An engineering-first discipline focused on technical assessments, not risk assessments.
- Looking for individuals with an adversarial mindset, offensive security skillset, and privacy instincts.
- Recruit from disciplines such as red teamers, pen testers, vulnerability/security researchers, and AppSec engineers.
- Legal, risk, and policy partners are crucial but not part of the team.

---

### Privacy Weakness Taxonomy
- A compendium of weaknesses, faults, flaws, and bad practices that are the root cause of privacy issues, along with a taxonomy for categorizing them.
- Goals:
  - Provide a centralized and authoritative source of knowledge about privacy weaknesses.
  - Provide a common language to discuss privacy weaknesses.
  - Define a new metric for measuring privacy risk.
  - Understand the difference between security vulnerabilities and privacy weaknesses.

---

### Privacy ATT&CK Framework
- An effort to accurately capture privacy-focused adversarial Tactics, Techniques, and Common Knowledge (TTPs).
- Goals:
  - Improve the detection, measurement, and mitigation of threats.
  - Ensure that Red Teams can accurately emulate real-world adversaries.

---

### Privacy Adversary Emulation
- Objective-based, campaign-style operations spanning products, services, and features.
- Goal: Test defenses against real adversary activity.

**Privacy Purple Operations:**
- Working with a blue team to improve defenses using specific TTPs.
- Scope: A specific privacy control or safeguard.
- Goal: Test a particular defense’s resilience to specific TTPs.

**Product Compromise Tests:**
- Compromising a feature, API, etc., from a privacy perspective.
- Scope: Specific product, service, or feature.
- Goal: Enumerate privacy weaknesses and gain access to all the data.

---

### Operations Ideas
**Account Attribution:**
- **Type of Operation:** Adversary emulation
- **Adversarial Profile:** Political campaign digital PR agency, internet troll
- **Objective(s):** Identify the risk of account enumeration and UII scraping associated with contact information and measure the opportunity for scale.
- **Methodology:** Focus on combining functionality (authentication systems, account recovery workflow, contact importer, developer APIs).

**Sensitive Data Leak:**
- **Type of Operation:** Privacy purple operation
- **Adversarial Profile:** Absent-minded developer, insider threat, external actor
- **Objective(s):** Test the effectiveness of detection mechanisms and the ability to track detected streams to owners.
- **Methodology:** 2-week sprint model (develop and release new data streams, blue team hunts, identify undetected streams).

**Data Type Focused:**
- **Type of Operation:** Adversarial emulation
- **Adversarial Profile:** Low-capability and high-capability adversaries
- **Objective(s):** Proactively identify how an adversary would access/use/modify a type of data and improve detection and prevention.
- **Methodology:** Identify valuable data types, enumerate TTPs, and test TTPs and existing defenses.

---

### Findings
- **Security Findings:** More objective, with well-known impacts and industry best practices for mitigation.
- **Privacy Findings:** More subjective, influenced by legal, regulatory environments, and user expectations.
- As privacy matures, findings should become more objective, with better understanding of privacy weaknesses and design.

---

### Metrics
- **Problem:** Traditional red team metrics (time to compromise, time to detection) don’t apply.
- **Goal:** Drive fundamental change in our privacy posture.
- **Things to Measure:**
  - Understanding the space (new weaknesses, new TTPs)
  - Performance (defenses validated, gaps identified)
  - Impact (problems found, bugs, vulnerabilities, weaknesses, roadmap changes, design issues)

---

### Lessons Learned
- **Compliance vs. Assurance:** Compliance ensures meeting requirements, but assurance goes beyond to provide additional confidence.
- **Legal Risks:** Different from security red teams, requiring different mitigations.
- **Early Stages:** Privacy as a technical discipline, separate from but linked to legal and policy, and offensive privacy as a fundamental component of a holistic privacy program.

---

### Let’s Keep Talking
Contact: PI:EMAIL  
Twitter: @scotttenaglia