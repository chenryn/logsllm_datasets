totally different context compared with a photo, which depicts
a person pointing a gun at viewers. Towards this end, we study
this context in-depth, identify its factors in images, and design
techniques that identify cyberbullying content by capturing the
context.
B. Factor Identiﬁcation
Various studies [67], [55], [62] focused on text-based
cyberbullying have tried to understand its nature, and revealed
several personal and situational factors, such as the use of
abusive or harassing words and phrases. However, no existing
research has attempted to understand the factors associated
with cyberbullying in images. To examine cyberbullying in
images, new personal and situational factors related to image
content should be studied. The identiﬁed factors can help
formulate classiﬁer models for detection, and potentially en-
able popular offensive content detectors (e.g., Google Cloud
Vision API and Amazon Rekognition) to automatically detect
cyberbullying in images as an offensive content category.
To study the factors of cyberbullying in images in our
dataset, we conduct an experiment by considering all
the
cyberbullying and non-cyberbullying images in our dataset. In
this experiment, we use existing tools to analyze the nature
of the images considering recurring visual factors we observe
in the dataset, summarised in Table V. We analyze the body-
pose [25] of the subject in an image, as prior research [81]
has shown that threatening poses are a commonly used tool in
cyberbullying. We analyze hand gestures [10] as hand gestures
are popular forms of sign language used to convey meaning
through images. We study the facial emotion [21] of the subject
in images, as facial emotions can convey several meanings to a
viewer. We study the objects [70] that are used by perpetrators
to threaten, or intimidate a victim. Lastly, we study social
factors such as anti-LGBT (lesbian, gay, bisexual, transgender,
and queer) content in images in our dataset. We use the cosine
similarity [48] to compare the differences of these factors with
respect to cyberbullying and non-cyberbullying images.
Body-pose factor. We conduct a preliminary study of
the correlation of the visual factors with images that have
been labeled as cyberbullying vs. non-cyberbullying by ob-
serving the cosine similarity between images depicting the
visual factors (outlined in Table V). We observe that images
depicting persons who pose at the viewer (front pose) had
strong correlation with cyberbullying images (cosine similarity
= 0.86, 74.74% of cyberbullying images). In contrast, these
images with the person posing at the viewer were observed
to have a much lower correlation (cosine similarity = 0.53,
28.29% of non-cyberbullying images) with non-cyberbullying
images (i.e., these images were mostly non-front pose). On
examining such cyberbullying images, we observe that these
images depicted subjects that are directly looking at the image
viewer in order to directly engage the viewer, whereas most
subjects in non-cyberbullying images had posed looking away.
Facial emotion factor. Facial emotions have been known
to convey signiﬁcant meaning regarding what a person is
feeling. Thus, we study the correlation of facial emotions (e.g.,
sorrow, joy, anger, and surprise) with cyberbullying images. We
observe that most cyberbullying images do not have speciﬁc
emotions expressed by a subject. We also observe that even in
cyberbullying images, subjects do not show any strong emo-
tions. In fact, we observe that these subjects generally showed
happy emotions such as joy (cosine similarity = 0.34, 11.39%
of cyberbullying images). Our preliminary observations reveal
that subjects may generally depict themselves mocking the
viewer by showing emotions of joy.
Hand gesture factor. Hand gestures are a popular method
that Internet users use to convey meaning in images [53], [79].
We ﬁnd a high correlation of hand gestures (e.g., loser, middle
ﬁnger, thumbs down and gun point) with cyberbullying images
(cosine similarity = 0.71, 50.6% of cyberbullying images),
indicating that in cyberbullying images, hand gestures may
6
(2) Factor Identification and ExtractionBaseline ModelFine-tuned  Pre-trained modelFactors-only ModelMultimodal Model(3) Classifier Model MeasurementBody-pose FactorFacial Emotion FactorSocial FactorGesture FactorObject FactorLGBT symbolsLoser, Middle finger, Thumbs down, Gun Gun, KnifeBody OrientationJoy, Sorrow, Anger, SurpriseFactorsAttributes(1) Data Collection and AnnotationCyberbullying Keywords CollectionCyberbullying Images CollectionAnnotated DatasetGoogleInstagramCyberbullying StoriesFactor
Body-pose
Emotion
Gesture
Object
Social
Attribute
Cyberbullying
Non-cyberbullying
Description
Front pose
Non-front pose
Joy
Sorrow
Anger
Surprise
Hand gesture
No hand gesture
Threatening object
No threatening object
Anti-LGBT
Anti-black racism
0.86
0.50
0.34
0.02
0.09
0.07
0.71
0.70
0.33
0.94
0.45
0.03
0.53
0.84
0.25
0.02
0.04
0.05
0.32
0.94
0.06
0.99
0.06
0.00
Pose of subject in image is towards the viewer
Facial emotion of subject in image
Hand gesture made by subject in image
Threatening object present in image
Anti-LGBT symbols and anti-black racism in image
TABLE V: Analysis of cyberbullying factors. Higher value of cosine similarity indicates higher correlation.
constitute an important factor.
Object factor. Next, we discuss the correlation of threat-
ening objects (e.g., gun, knife) with the cyberbullying images
in our dataset. We also observe some correlation of threatening
objects (cosine similarity = 0.33, 10.6% of cyberbullying im-
ages) with cyberbullying images, which indicates Internet users
may use these objects to threaten or intimidate a viewer [51].
Although, we also observe that many cyberbullying images
(cosine similarity = 0.94, 89.40% of cyberbullying images)
also do not depict direct use of these objects to cyberbully
their victims. This could be due to the belief that Internet users
generally may use more subtle tools to perpetrate cyberbully-
ing, rather than directly using such threatening objects, which
may risk initiating action by law enforcement agencies.
Social factor. Prior works [30], [50] have shown that
cyberbullying is a deeply concerning social issue. Hence, we
manually analyze the cyberbullying images in our dataset for
current social-related factors, such as anti-LGBT [14] and
racism [11]. We ﬁnd that a small part of images consisted
of anti-LGBT symbolism (cosine similarity = 0.45, 1% of
cyberbullying images), and images depicting “black-face” and
historical references to hanging (cosine similarity = 0.03, <
1% of cyberbullying images).
Next, we study the correlation of a person depicting a hand
gesture or a threatening object with respect to cyberbullying
images (Table VI). We observe a signiﬁcant correlation of
person and hand gestures in cyberbullying images (cosine
similarity = 0.72, 95.31% of cyberbullying images). On further
examination, we observe that many cyberbullying images
depict a person directly showing a gesture towards the image
viewer. We also observe that some images with only a hand
gesture and no person is signiﬁcantly less correlated with cy-
berbullying (cosine similarity = 0.10, 4.69% of cyberbullying
images), which may indicate that presence of person invokes
stronger context in an image, and a factor by itself may not
actually convey cyberbullying. We make a similar observation
involving objects and person regarding cyberbullying images
(cosine similarity = 0.31, 90.4% of cyberbullying images). We
observe that many photos of objects (e.g., guns and knives)
alone were not labeled as cyberbullying (cosine similarity =
0.02, 9.6% of cyberbullying images), but photos depicting a
person holding these objects were overwhelmingly labeled as
cyberbullying.
From our analysis, we observe that cyberbullying in images
Cyberbullying
Person
0.31
0.72
No person
0.09
0.10
Non-cyberbullying
Person
0.02
0.34
No person
0.07
0.07
Object
Gesture
TABLE VI: Analysis of correlation of person with threatening
object and gesture.
is highly contextual in nature, involving very speciﬁc factors
(outlined in Table V). In our work, we use these factors
to train classiﬁer models and demonstrate that they can be
effectively used to detect cyberbullying in images. A crucial
requirement of defense against cyberbullying in images is
to accurately detect cyberbullying based on those images.
The high correlation of cyberbullying with certain factors
may indicate that classiﬁer models based on these factors
could potentially detect cyberbullying in images. Furthermore,
popular offensive content detectors currently do not consider
cyberbullying as a category of offensive content in images and
hence lack the capability to detect it. One of the objectives of
our work is to highlight the importance of cyberbullying in
images, so that it can be included as a category of offensive
content in popular offensive content detectors. In our work,
we use the visual factors of cyberbullying to demonstrate that
they can be used in deep learning models (such as the ones in
these content detectors) to successfully detect cyberbullying in
images with high accuracy.
C. Factor Extraction
Our aim is to identify a set of cyberbullying factors in
images that are minimally correlated and best predict
the
outcome (i.e., presence of cyberbullying in images). How-
ever, cyberbullying in images is a complex problem, and
such factors are not directly derivable from image data with
currently available learning techniques. Therefore, we extract
these factors based on our collected dataset and preliminary
analysis, and catalog them as follows.
•
Body-pose factor extraction. Regarding body pose
of a person appearing in an image, there may be
several aspects of the person, such as orientation,
activity, and posture. Speciﬁcally in our dataset, we
observe that in cyberbullying images, the subject is
predominantly oriented towards the image viewer (i.e.
towards the camera). For example, Figure 5 shows two
image samples from our dataset. Figure 5(i) depicts
7
are not harmful (e.g., the victory sign, thumbs up and
OK sign). We observed that in cyberbullying images
in our dataset, the hand gestures were used as tools
to convey harmful intent by perpetrators of cyberbul-
lying. Such images (e.g., Figure 6) depict subjects
making mocking or threatening hand gestures, such as
the loser gesture (Figure 6 (i)), middle ﬁnger (Figure 6
(ii)), thumbs down (Figure 6 (iii)), and gun gesture
(Figure 6 (iv)). Hence, we were interested in capturing
these harmful gestures we found in cyberbullying
images.
Fig. 5: Cyberbullying Vs. non-cyberbullying body-pose.
a cyberbullying sample and Figure 5(ii) depicts the
pose of the subject. It can be observed that
this
pose of the subject indicates that the subject in this
image is oriented directly at the viewer and pointing a
threatening object (e.g., gun) at the viewer. However,
this is in contrast to Figure 5(iii), whereas the pose
depicted in Figure 5(iv) of a non-cyberbullying sample
indicates the subjects are not oriented towards the
viewer and the threatening object not pointed towards
the viewer. Thus, we wish to capture these orientations
related to body-pose.
We used OpenPose [25] to estimate the body-pose of
a person in the image. OpenPose detects 18 regions
(body joints) of a person (such as nose, ears, elbows
and knees), and outputs the detected regions and
their corresponding detection conﬁdence. We use the
conﬁdence scores of the regions as the factor values
as this indicates the conﬁdence about the appearance
of those regions in the image.
Facial emotion factor extraction. Since cyberbully-
ing may involve the subject in an image expressing
aggression or mocking a victim, we were speciﬁ-
cally interested in capturing facial emotions related to
these expressions, as the facial emotions of subject
in images may be good indicators of the intent of
the person towards conveying such expressions. For
example, an angry expression could indicate an intent
to be aggressive or threatening to a viewer, or a happy
(e.g., sneering, taunting) expression could indicate an
intent to mock the viewer.
We extract
the emotions in our dataset using two
sources, OpenFace [21] and Google Cloud Vision
API [10]. We choose the emotion categories that are
indicated with high conﬁdence by both these sources.
Overall, we use four emotion categories: joy, sorrow,
anger, and surprise.
•
• Gesture factor extraction. There exist several hand
gestures that subjects use in images and most of these
8
Fig. 6: Some hand gestures found in cyberbullying images in
our dataset.
We use the tag suggestions by Google Cloud Vision
API [10] to indicate if an image depicts any hand
gestures. The tags detected by this API do not provide
ﬁne-grained gesture categories. Therefore, we only
use the presence or absence of a hand gesture as the
feature indicative of hand gesture factor.
• Object factor extraction. Different objects depicted
in an image can indicate different intents of the subject
in the image. We observe that a large number of
cyberbullying images portrayed the use of threatening
objects, such as guns and knives, and hence we
are speciﬁcally interested in capturing these objects.
In cyberbullying [50], [49], perpetrators speciﬁcally
use threatening and intimidation to cyberbully their
victims. Speciﬁcally, in cyberbullying in images, per-
petrators can use images of themselves using such
threatening objects to cyberbully the victims and hence
we were interested in capturing these types of objects.
We use an open source object detection system called
YOLO [70] to detect the objects in images of our
dataset. YOLO outputs the object category as well
as the conﬁdence score of detection for each object
depicted in an image. Since YOLO outputs a large set
of categories of images, we limit the objects categories
to only the categories that we are interested in (e.g.,
gun, knife, revolver, etc.). Then, we use the conﬁdence
(i) Cyberbullying Image (ii) Cyberbullying Pose(iii) Non-cyberbullying Image(iv) Non-cyberbullying Pose(i) Loser (ii) Middle Finger(iii) Thumbs Down(iv) Finger Gun•
scores of the subset of objects as features for this
factor.
Social factor extraction. We observe certain social
factors in cyberbullying images that perpetrators could
use to convey intent of cyberbullying. Such factors