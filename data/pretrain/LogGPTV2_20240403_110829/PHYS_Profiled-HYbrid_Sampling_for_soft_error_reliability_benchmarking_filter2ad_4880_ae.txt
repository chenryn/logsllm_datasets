Fig.  2(a)  shows  the  FIT  error  rates  resulting  from 
SMARTS [26] and SimPoint [20]. SMARTS fails to capture 
long  VC intervals, resulting  in 286.06%  average  FIT  error. 
The  FIT  error  rates  of  SimPoint  with  50M  and  10M 
committed instructions are 32.24% and 31.64% respectively. 
As  shown  in  Table  I,  the  average  number  of  instructions 
executed  with  the  reduced  input  sets  is  only  1.43  billion. 
Hence even a 50M  SimPoint captures  a significant fraction 
of the total execution time, as compared to the usual 100M 
SimPoint  chosen  for  SPEC2K  with  reference  inputs  whose 
average instruction count is 215 billion. The FIT error with 
SimPoint  is  due  to  the  bias  introduced  by  focusing  on  the 
most  representative  phase  of  execution  although  other 
phases  can  considerably  contribute  to  FIT  rates  if  they 
access cache blocks residing in L2 for a very long time. Fig. 
2(b)  shows  the  slowdowns  compared  to  base  sim-outorder. 
crafty  and lucas are the only two programs benefiting from 
faster  execution  by  all  three  forms  of  sampling.  Both 
SimPoint-50M and SMARTS have relatively small average 
slowdowns  of  3.37  and  1.15  times.  However,  these 
slowdowns  coupled  with  large  FIT  error  rates  show  that 
performance-centric sampling is inappropriate for reliability 
simulations.  Even  if  one  accelerates  simulations  by  sparser 
sampling,  such  as  SimPoint-10M,  the  FIT  rates  are  still 
unpredictable  using  SimPoint  or  SMARTS.  The  designer 
does  not  know  how  close  the  FIT  rate  obtained  from  a 
sampled run is from that of the complete run.  
C.  Results for set, interval and hybrid sampling 
Fig. 3(a) shows the average  FIT estimation  errors using 
set,  interval  and  hybrid  sampling  as  compared  to  complete 
simulations. Targeted sampling  rates are 1%, 5%, 10% and 
20%. Set sampling with 10% sampled sets yields an average 
FIT  error  of  7.77%.  With  1% set  sampling the error  grows 
to 183.08%. Interval sampling introduces much smaller bias 
and  gives  better  results.  With  10%  sampling  rate  interval 
sampling  introduces  an  average  FIT  error  of  3.03%.  With 
hybrid  sampling,  the  overall  FIT  estimation  accuracy 
improves by  10%  as compared  to interval sampling for  the 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:38:09 UTC from IEEE Xplore.  Restrictions apply. 
Figure 4.   FIT errors and simulation slowdowns in various schemes 
same target sampling rate. With a 5% sampling rate the FIT 
rate error with hybrid sampling is well below 3% in 16 out 
of 21 benchmarks.  
Fig.  3(b)  shows  the  slowdowns  of  set,  interval  and 
hybrid  samplings  as  compared  to  the  base  sim-outorder 
simulation  runs.  With  10%  sampling  rate,  set,  interval  and 
hybrid  samplings  have  slowdowns  of  2.23,  4.85  and  7.02, 
respectively. The worst-case slowdown happens for swim in 
both  sampled  and  complete  simulations,  and  is  only  23.06 
times  in  interval  sampling  for  10%  sampling  rate  as 
compared  to  806.61  times  for  the  complete  simulation. 
Speedups  due  to  sampling  vary  across  benchmarks.  To  a 
first  order  the  speedups  grow  with  the  size  of  the  BST 
memory  footprint  in  the  complete  simulations  (Table  I, 
column  titled  L2  Tracked  Blocks)  and  the  randomness  of 
access patterns to the BST. Sampling reduces the size of the 
BST, which also reduces the number of random accesses to 
TABLE II.  
MINIMUM SAMPLING RATES WITH PROFILING AND 
WITH SMARTS (10% MARGIN OF ERROR, 95% CONFIDENCE LEVEL) 
Scheme  UL2 Size  ammp  facerec 
lucas  mgrid  average 
256KB  6.783% 16.811%38.507%0.279% 5.587% 
Profiling 
1MB  2.762%  1.548%35.936%0.144% 6.794% 
4MB  0.933%  0.802%36.554%0.370% 6.676% 
Modified 
SMARTS
256KB  0.774%  4.109% 0.167%4.524% 0.970% 
1MB  0.830%  3.805% 0.189%8.319% 2.469% 
4MB  0.777%  2.934% 0.217%7.038% 2.312% 
the BST.  
Interval  sampling 
is  consistently  slower 
than  set 
sampling. There are two reasons. First, in interval sampling, 
the BST structure shrinks and expands during a benchmark 
run  by  inserting  and  deleting  nodes  in  the  BST  on  the  fly, 
resulting  in  BST  management  overheads.  By  contrast  the 
data structure in set sampling grows larger most of the time, 
albeit  slowly  with  program  execution  because  nodes  are 
deleted only when a clean block is evicted from L2 without 
being  written  back  to  memory.  Second,  in  set  sampling,  a 
memory  reference  outside  of  the  sampled  sets  is  simply 
ignored and not tracked in the BST. Thus set sampling runs 
faster  than  interval  sampling  by  eliminating  BST  searches 
for many accesses. Our hybrid sampling approach is slightly 
slower as compared to interval sampling and the difference 
becomes  smaller  with  smaller  sampling  rates.  Hybrid 
sampling  reduces  accesses  to  sets  with  smaller  VCs  but 
increases  accesses  to  sets  with  larger  VCs.  Since  the 
contribution of sets holding larger VCs to FIT estimation is 
more  important,  hybrid  sampling  improves  FIT  estimation 
accuracy.  However,  hybrid  sampling  has  additional 
computation  overhead  to  change  the  sampling  rate  of 
individual  set  periodically,  which  results  in  slightly  higher 
slowdowns than interval sampling.  
D.  Sampling results for PHYS 
PHYS  combines  hybrid  sampling  with  sampling  rate 
profiling,  to  obtain  the  best  sampling  rate  for  each 
benchmark.  With  a  10%  margin  of  error  and  95% 
confidence  level,  the  profiled  sampling  rates  are  shown  in 
9
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:38:09 UTC from IEEE Xplore.  Restrictions apply. 
TABLE III.  
RESULTS FOR VARIOUS SAMPLING SCHEMES WITH DIFFERENT L2 CACHE SIZES 
UL2 
SimPoint-50M  SimPoint-10M  SMARTS-INT  LIM-2X 
LIM-0.2X 
PHYS 
256KB 
32.24% 
46.39% 
Average FIT Error 
Average Slowdown 
1MB 
4MB 
256KB 
1MB 
4MB 
31.64% 
45.55% 
272.86% 
141.55% 
3.37 
0.64 
0.79 
0.62 
0.11 
0.05 
the  high  variance  of 
Table II in scheme “profiling” (Section E:SMART_INT will 
comment  on  “Modified  SMARTS”  sampling  rates).  We 
only  show  sampling  rates  for  four  interesting  benchmarks 
due  to  space  limitation,  but  the  average  rates  shown  in  the 
table  are  computed  for  the  21  benchmarks  from  Table  I. 
Most benchmarks require very low sampling rates, less than 
1%. ammp, facerec and lucas have high sampling rates due 
to 
their  VC  distribution.  VC 
distributions  vary  significantly  with  cache  size  and 
accordingly the sampling rate varies, as in facerec and lucas 
(also  in  gcc  and  swim  which  are  not  shown  in  Table  II). 
PHYS  accurately  captures this  variance  and  determines the 
best  sampling  rate  for  each  benchmark  while  confining the 
FIT error within the target margin  of error. In Fig. 4(a) the 
first bar for each benchmark shows FIT errors (for a 256KB 
L2) with PHYS. They all fall within the targeted 10% error 
margin. In Fig. 4(b) the first bar for each benchmark shows 
the  slowdowns  of  PHYS  compared  to  base  sim-outorder. 
PHYS has an average slowdown of only 1.77 and the worst 
slowdown  is  at  most  3.95.  We  didn’t  include  the  profiling 
overhead  in  measuring  slowdown.  If  the  sampling  rate 
obtained after the profiling phase is lower than the sampling 
rate used for profiling, we do not need to redo the sampling 
simulation.  Instead  we  can  use  the  reliability  results 
obtained during profiling. To be fair, we didn’t include any 
overhead  associated  with  other  approaches  that  will  be 
discussed in section E. 
E.  Exploration of other sampling approaches 
We  evaluated  multiple  alternative  approaches 
to 
improve reliability  simulation speed. In this section, simple 
optimization  approaches,  such  as  limiting  the  size  of  the 
BST,  to  more  complex  approaches  such  as  modifying 
SMARTS  are  compared  to  PHYS.  We  do  not  consider 
techniques  to  estimate  AVF  such  as  in  [17][24]  in  our 
comparisons because they don’t involve sampling. We also 
address  the  effect  of  different  random  seeds  in  the  pseudo 
random  number  generator,  the  variations  in  CV  estimation 
when different sampling rates are used in profiling, and the 
sensitivity  of  various  simulation  acceleration  techniques  to 
the L2 cache size.  
LIM-X:  In  this  approach  we  limit  the  size  of  the  BST 
structure to 20% and 200% of the total number of blocks in 
the L2 cache (called LIM-0.2X and LIM-2X respectively in 
Fig. 4). Whenever the BST grows bigger than this limit, the 
oldest node is replaced to make room for the incoming new 
10
61.44% 
15.40% 
68.17% 
3.84% 
254.20% 
225.46% 
1.41 
2.17 
2.14 
6.93% 
7.98% 
8.06 
31.89 
64.98 
54.02% 
3.39% 
46.01% 
2.66% 
2.77 
4.63 
13.53 
1.77 
2.26 
2.11 
request.  LIM-0.2X  reduces  the  memory  overhead  and  the 
simulation  slowdown  is  reduced  to  2.77,  but  the  FIT  error 
grows to 68.18%. In LIM-2X, the slowdown becomes 8.06 
but the FIT error is down to 15.4%. PHYS is better, both in 
terms of accuracy and speed.  
SMARTS-INT:  We  obtained  the  simulation  width  and 
interval  for  all  our  benchmarks  by  running  them  on  the 
SMARTS  simulation  tool  chain  [26]  with  10%  CPI  error 
and 95% confidence interval. We modified SMARTS in the 
following  way:  We  run 
the  detailed  cycle  accurate 
simulation as the baseline and once the simulation enters the 
SMARTS  detailed  window  we  switch  to  full  reliability-
lifetime  tracking.  All  the  VC  intervals  started  inside  a 
detailed simulation window are tracked in the BST. As soon 
as  the  simulation  exits  the  SMARTS  detailed  window,  no 
new  block  enters  the  BST.  However,  any  existing  sample 
taken  in  the  BST  is  correctly  accounted  for  in  the  AVF 
calculation  just  as  we  do  in  interval  sampling.  In  other 
words  SMARTS-INT  is  an  interval  sampling  method  in 
which  all  interval  samples  start  inside  SMARTS’s  detailed 
simulation windows.  
till  now  keep 
The  outcome  of  this  modified  SMARTS  approach  is 
shown in Fig. 4 (bars labeled SMARTS-INT). In SMARTS-
INT,  the  slowdown  is  1.41  but  the  FIT  error  is  61.44%. 
SMARTS  uses  performance  variance  to  set  the  sampling 
rate, and it does not necessarily capture the variance of VCs 
when applied to reliability simulations. Table II rows under 
“Modified SMARTS” show that the sampling rates selected 
by  SMARTS  are  significantly  different  from  the  sampling 
rates selected by our PHYS tool.  
POP-BLK:  All  our  results 
track  of 
timestamps at word granularity. Instead of tracking per word 
reliability-lifetime,  per-block 
reliability-lifetime  keeps 
timestamps  per  entire  blocks  to  further  reduce  memory 
consumption. Results from this method are shown in Fig. 4 
(called  POP-BLK).  Because  the  access  granularity  is 
extended  to  blocks,  the  AVF  analysis  loses  accuracy. 
Updates and accesses are recorded per block instead of per 
word, resulting in 88.02% FIT errors.  
Random  seed:  We  ran  sensitivity  analyses  to  see  how 
different  random  seeds  may  affect  the  results  of  our 
sampling experiments. We ran 5% interval and set sampling 
simulations  on  all  the  benchmarks  using  10  random  seeds 
(seed=1~10).  FIT  estimates  deviated  by  less  than  2%  in 
interval  and  hybrid  sampling  and  5%  in  set  sampling.  In  a 
simulation  with  millions  of  events,  different  random  seeds 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:38:09 UTC from IEEE Xplore.  Restrictions apply. 
TABLE IV.  
 COMPARISON OF DIFFERENT SCHEMES (256KB L2) 
TABLE V.  
PHYS RESULTS OF 2MB UL2: FULL SPEC2K 
Scheme 
FIT Error #1 
Slowdown against 
base sim-outorder #2 
Ranked 
by#1×#2 
PHYS 
INT-10% 
SET-10% 
HYB-10% 
SMARTS-INT 
SimPoints-50M 
LIM-0.2X 