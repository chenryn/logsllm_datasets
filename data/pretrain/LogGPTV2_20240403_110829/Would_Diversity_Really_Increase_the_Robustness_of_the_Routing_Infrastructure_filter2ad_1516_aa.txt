title:Would Diversity Really Increase the Robustness of the Routing Infrastructure
against Software Defects?
author:Juan Caballero and
Theocharis Kampouris and
Dawn Song and
Jia Wang
Would Diversity Really Increase the Robustness of the Routing Infrastructure
against Software Defects?
Juan Caballero∗, Theocharis Kampouris∗, Dawn Song‡∗, Jia Wang†
∗Carnegie Mellon University
‡UC Berkeley
†AT&T Labs-Research
Abstract
1 Introduction
Today’s Internet routing infrastructure exhibits high homo-
geneity. This constitutes a serious threat to the resilience
of the network, since a bug or security vulnerability in an
implementation could make all routers running that imple-
mentation become simultaneously unusable. This situation
could arise as a result of a defective software upgrade or a
denial-of-service attack.
Diversity has been proposed as a solution to increase re-
silience to software defects, but the beneﬁts have not been
clearly studied. In this paper, we use a graph theoretic ap-
proach to study the beneﬁts of diversity for the robustness
of a network, where robustness is the property of a network
staying connected under a software failure. We address
three fundamental questions: 1) How do we measure the
robustness of a network under such failures? 2) How much
diversity is needed to guarantee a certain degree of robust-
ness? 3) Is there enough diversity already in the network or
do we need to introduce more?
We ﬁnd that a small degree of diversity can provide good
In particular, for a Tier-1 ISP network, ﬁve
robustness.
implementations sufﬁce: two for the backbone routers and
three for the access routers. We learn that some networks
may already have enough diversity, but the diversity is not
adequately used for robustness. We observe that the best
way to apply diversity is to partition the network into con-
tiguous regions using the same implementation, separating
backbone and access routers and taking into account if a
router is replicated. We evaluate our approach on multiple
real ISP topologies, including the topology of a Tier-1 ISP.
∗This material is based upon work partially supported by the Na-
tional Science Foundation under Grants No. 0311808, No. 0433540, No.
0448452, No. 0627511, and CCF-0424422. Partial support was also pro-
vided by the U.S. Army Research Ofﬁce under the Cyber-TA Research
Grant No. W911NF-06-1-0316, and under grant DAAD19-02-1-0389
through CyLab at Carnegie Mellon. The views and conclusions contained
here are those of the authors and should not be interpreted as necessarily
representing the ofﬁcial policies or endorsements, either expressed or im-
plied, of ARO, NSF, or the U.S. Government or any of its agencies. This
work was also supported in part by the Korean Ministry of Information
and Communication and the Korean Institute for Information Technology
Advancement under program 2005-S-606-02.
Today’s Internet routing infrastructure exhibits high ho-
mogeneity. A few router vendors dominate the market and
each ISP relies on a very limited number of vendors to build
their infrastructure. Simpliﬁed network operation, uniform
operator training, reduced complexity, and interoperability
are common reasons behind this homogeneity. Such ho-
mogeneity, however, raises serious questions about the re-
silience of the routing infrastructure against software de-
fects. Computer systems are notoriously known for being
laden with bugs and vulnerabilities, and routers are no ex-
ception.
Software defects
in routers are not uncommon.
Markopoulou et al. [23] found that 12% of all failures in a
Tier-1 ISP network were router related, and a NIST-funded
survey [15] in 2002 found that in ﬁnancial services ap-
proximately 16% of reported major bugs were attributed
to router and switch problems. Most vendors acknowledge
these problems and provide search tools or toolkits to ﬁnd
the ﬂaws in speciﬁc software versions. Vulnerabilities in
router software are also frequent and can allow denial-of-
service attacks [2, 4, 5], remote execution of system-level
commands with no authentication [3], unauthorized privi-
leged access [1], or possible remote shell execution [7].
Thus, a real threat lurks. A serious bug in a router soft-
ware implementation could make all routers running that
implementation simultaneously unusable. Due to the router
homogeneity in ISPs and enterprise networks, this would ef-
fectively disconnect their customers and sites, halting their
operation and dealing a major blow to their business and
their perceived quality. This dramatic scenario could appear
as a result of a defective software upgrade, or a security vul-
nerability that opens the door for a denial-of-service attack
on the routing infrastructure.
Diversity, i.e., using different software implementations
from different code bases on different routers, could in-
crease the overall resiliency of a network against some soft-
ware defects but it would also increase the complexity and
cost associated with network deployment and management.
Thus, we need to understand the beneﬁts of diversity. To the
best of our knowledge, this is the ﬁrst paper that systemati-
cally studies the effectiveness of using software diversity to
increase the resiliency of the router infrastructure against si-
multaneous router failures, which might happen due to soft-
ware defects in routers.
In this paper, when we refer to network robustness or
simply to robustness, we mean the property of the network
staying connected under a software failure1 that simultane-
ously disables all routers running a speciﬁc implementation.
We address the following three fundamental questions: 1)
How do we measure the robustness of a network under such
failures? 2) How much diversity is needed to guarantee a
certain degree of robustness? 3) Is there enough diversity
already in the network or do we need to introduce more?
There are many factors contributing to the resiliency of
a network. As a ﬁrst step, in this paper we consider the
most fundamental property to guarantee the resiliency of a
network, the connectivity. Without connectivity no routing
is possible and no quality-of-service can be guaranteed. A
good example was the Sprint network incident on January
9, 2006, when failure of two links led to a network parti-
tion [9]. Other properties such as network capacity, which
will be reduced due to the failure and might lead to an in-
crease in delay and packet loss, are left as future work.
To study whether the network topology will stay largely
connected or will be partitioned into small unconnected
components, when all routers running a certain implemen-
tation become unusable, we propose a graph theoretic ap-
proach and convert the problem into a version of a graph
coloring problem, where routers are colored based on their
implementations and connectivity needs to be maximized
when any color is removed from the graph. A color fail-
ure (i.e., removing a color) is equivalent to disconnecting
all nodes using that color and has two impacts: the discon-
nection of the nodes themselves, which cannot be avoided,
and the disconnection of other nodes who relied on those
nodes to connect to the rest of the graph. Our goal is to
minimize this second factor so that a network is as robust as
a fully connected topology (i.e., full mesh), since removing
any number of nodes from a fully connected topology does
not affect the connectivity of the remaining nodes.
In this paper, we show how to measure the robustness of
the network against software failures, propose a family of
coloring algorithms to best apply the diversity, and evaluate
those algorithms over real topologies, including the topolo-
gies obtained from a large Tier-1 ISP and from the Rock-
etfuel project [28]. Our results show that a small degree
of diversity can provide good robustness against simulta-
neous router failures. A large Tier-1 ISP network can ob-
1A router is a combination of hardware and software. In this paper we
focus on software failures, which are more likely to simultaneously affect
all routers running an implementation, but our approach can also protect
against similar hardware failures.
tain good robustness when using a total of ﬁve implementa-
tions: two for the backbone routers and three for the access
routers. In addition, we show that large networks might al-
ready have enough diversity, since the homogeneity is due
to a large fraction of the nodes using a small number of
implementations, even when the total number of implemen-
tations present might be large. Thus, the existing diversity
is not being adequately used for robustness. To beneﬁt from
the available implementations, ISPs would need to change
the relative number of nodes per implementation and to ge-
ographically distribute the diversity. Furthermore, we show
that our algorithms can apply the available diversity in a
way such that a network achieves robustness near the opti-
mal one that can be achieved with a fully connected topol-
ogy.
Scope and deployment cost: Diversity can protect against
software vulnerabilities that affect one or multiple imple-
mentations from the same vendor. But, some software vul-
nerabilities might be shared across implementations from
multiple vendors. This can happen when there is code reuse
between vendors, e.g., by using a third party library con-
taining a vulnerability. Past examples include the ASN.1
parser vulnerabilities found in OpenSSL that affected many
different platforms using this library [6].
This paper does neither claim that diversity can protect
against all software defects nor that we should redesign all
networks to accommodate for diversity. Rather, we show
that diversity greatly helps with simultaneous router failures
and that many networks already have a signiﬁcant amount
of diversity, due to legacy routers, changes of provider, or
budget restrictions. Our results show that the number of
implementations already present in some large networks
could, if properly used, provide good robustness against
simultaneous router failures. However, the existing diver-
sity is not used adequately for robustness. An adequate use
would require changing the relative number of nodes using
each implementation, and a better geographical distribution.
We argue that a large part of the cost usually assigned to di-
versity, such as interoperability problems, network manage-
ment or operator training is already being paid in networks
where multiple implementations are already present. Thus,
the additional cost introduced by shifting the relative num-
ber of nodes from each implementation and by changing the
geographical distribution of the diversity could be relatively
small in these networks. Our goal is not to evaluate the cost
of redistributing or introducing more diversity in networks
since we lack important data for such evaluation, only avail-
able to ISPs, but to understand the beneﬁts of diversity and
how should such diversity be applied. Our contributions
are summarized below.
Measure the robustness against speciﬁc failures: There
has been previous work on metrics that describe the global
robustness of a graph. Rather, we show how to measure
the robustness of a network against speciﬁc failure types,
modeling the failure’s effect on connectivity. We focus on
one failure type, i.e., simultaneous router failures, which
we convert into a version of a graph coloring problem, but
we believe that our approach can be easily applied to many
other failure types.
Design and implement algorithms that properly apply
diversity: We learn that the best way of applying diversity
is to partition the network into contiguous regions that use
the same implementation, taking into account the node roles
and possibly replicated nodes. Our results show that our
algorithms can apply the diversity in a way that a network
achieves robustness near the optimal that can be achieved
with a fully connected topology.
Demonstrate that a small degree of diversity can achieve
good robustness: We show that using a good coloring al-
gorithm the amount of diversity needed to provide good
robustness is small. A large Tier-1 ISP network can ob-
tain good robustness when using a total of ﬁve implementa-
tions: two for the backbone routers and three for the access
routers.
Expose that the existing diversity could already provide
good robustness: Our data shows that the homogeneity
in Tier-1 ISP networks comes from a large fraction of the
nodes using a few implementations, even when the total
number of implementations present is large. Thus, the ex-
isting diversity is not being adequately used for robustness.
To beneﬁt from the existing diversity, ISPs would need to
change the relative number of nodes per implementation
and to geographically distribute the diversity.
The remainder of the paper is organized as follows. Sec-
tion 2 deﬁnes our graph theoretic approach. In Section 3 we
present the metrics needed to evaluate the robustness of the
network. Then, in Section 4 we present graph coloring algo-
rithms that properly apply the diversity, and in Section 5 we
evaluate them over different topologies. Section 6 presents
the related work. Finally, we discuss extensions and future
work in Section 7 and conclude in Section 8.
2 Problem Statement
In this section, we convert the problem of using router
software diversity to increase network robustness into a
graph coloring algorithm. We represent a given network
topology as a graph G = (V, E), where V is the set of
nodes representing routers in the network, and E is the set
of undirected edges each corresponding to a link between
two routers in the network. Let n = |V | be the number
of nodes, and m = |E| be the number of edges in G. Let
Ck = {c1, c2, . . . , ck} be a set of k distinct colors repre-
senting the available implementations that any router can
utilize. We say a vertex-coloring algorithm takes as input
the graph G and the color set Ck, and outputs a colored
graph Gk = (V, E) where each node in V has been tagged
with a color from Ck. Thus, the coloring algorithm deter-
mines which implementation should be run by each router,
by assigning a color to each router in the network.
A color failure is the simultaneous failure of all the
routers running a speciﬁc implementation, which makes
those routers unusable. This color failure can be caused by
a defective router software upgrade, or a denial of service
attack on the routing infrastructure. A color failure is repre-
sented as a color removal, which takes as input the colored
graph Gk and a color ci ∈ Ck and returns a color-removed
k = (V, E∗) with E∗ ⊆ E, which is the sub-
subgraph Gi
graph of Gk generated by disconnecting all nodes of color
ci from Gk, where disconnecting a node means removing
all edges connected to that node while leaving the node in
the graph. Intuitively, the color-removed subgraph repre-
sents the remaining network topology after a color failure.
Problem deﬁnition: Given a graph G = (V, E) with n
nodes and m edges, a set Ck with k distinct colors, and
a robustness function φ(·), ﬁnd a k-color vertex-coloring of
graph G that maximizes φ(·). Our problem is different from
the most common graph coloring problem, which tries to
ﬁnd a proper coloring, meaning no two adjacent nodes are
assigned the same color [16]. We do not require adjacent
nodes to have different colors. We try to ﬁnd a coloring
of G that maximizes a robustness function φ, where φ is
computed on the subgraphs of G obtained by removing the
colors, one at a time.
Note that the probability of ﬁnding a software defect in
one implementation should be independent of the probabil-
ity of ﬁnding a defect in any other implementation. Thus,
the implementations used to add diversity to the network
should come from different code bases. To summarize, our
problem is composed of two main parts. First, how to de-
ﬁne the function φ, such that it measures the robustness of
the graph upon a color removal. We address this in Sec-
tion 3. Second, how to design an effective vertex-coloring
algorithm, that achieves high robustness for a given graph
with a limited number of colors. We address this in Sec-
tion 4.
3 Measuring Network Robustness
In this section we introduce the metrics used to describe
the robustness of a graph under color failures. First, we
describe connectivity metrics that can be used on any graph,
and then we deﬁne the robustness metric on a colored graph,
as a function of a connectivity metric.
3.1 Connectivity Metrics for a Graph
We use the connectivity of the graph as a measure of
the robustness of the network topology. There have been
numerous previously proposed connectivity metrics for a
graph such as: number of components in the graph2, nor-
malized size of the largest component [10], pair connec-
tivity [27], average size of the components (excluding the
largest component) [10], average distance [10], number of
biconnected components [32], minimum cut-set size for a
balanced bi-partition of the graph [29], and effective diam-
eter [26].
But we are not aware of any in-depth comparison of
these connectivity metrics that allows to select one of them.
Thus, a signiﬁcant part of our work has been to identify the
important characteristics that a connectivity metric should
possess. In this paper, we require the following characteris-
tics to be satisﬁed by a connectivity metric: 1) it has to be
non-negative; 2) it should monotonically decrease as more
nodes are disconnected; 3) it needs to be normalized; 4)
it should represent only binary connectivity, that is, if two
nodes are connected or not, rather than try to measure the
degree of connectivity between them, and 5) it should be as
intuitive as possible.
Note that some of the above metrics, such as those us-
ing shortest path computations or hop counts, attempt to
measure not only if two nodes are connected, but also the
degree of connectivity between them, but in doing so in-
troduce an assumption about shortest path routing being
used in the network, which is not desirable. We believe the
proper approach is to ﬁrst guarantee the physical connectiv-
ity of the network before investigating the impact on routing
and end-to-end performance. We select the following two
connectivity metrics because they satisfy the above require-
ments. Note that, the robustness function is independent of
the connectivity metrics used and other metrics can thus be
selected.
the
The normalized size of
component
(NSLC) [10] is the size of the largest component over
the total number of nodes. Ideally, when removing a color
from the graph, the remaining nodes should all form a
single component and thus be all reachable to each other.
largest
The pair connectivity (PC) [27] is the fraction of con-
nected node pairs in a graph over the total number of distinct
pairs of nodes. It measures for each node, how many other
nodes it can reach. This metric takes into account all the
components in the graph rather than just the largest one and
it is useful when the graph is partitioned into multiple large
components where each component connects a signiﬁcant
number of nodes and should not be ignored.
P C = Pcomp
i=1
1
2|Li|(|Li| − 1)
(cid:0)n
2(cid:1)
where comp is the number of components in the graph and
|Li| is the number of nodes in the ith component. Note
that we need to ﬁrst extract the graph’s components before
calculating any of the two metrics, which takes O(n + m).
Modeling node importance: So far, our connectivity met-
rics consider each node in the graph to be equally important.
However, for a given graph, some nodes can be more impor-
tant than others. For example, a node carrying more traf-
ﬁc would be considered more important than those carrying
less trafﬁc. Alternatively, a node which connects to more
customers or has more capacity can be considered impor-
tant. In this paper, we assign different weights to different
nodes in the graph to reﬂect their importance.
In our setting, we do not need to use link weights because
we only deal with node failures, rather than individual link
failures, and in this case node weights allow dealing with
link weights in a straightforward way. Since a node failure
implies the failure of all the links connected to the node,
then a node can be assigned a weight proportional to the
sum of the weights of all the links it connects to. We now
extend our connectivity metrics to the case where nodes are
associated with weights.
The weighted normalized size of the largest component
(W-NSLC) is the sum of the weights of all nodes that belong
to the largest component, over the total weight of all nodes
in the graph.
The weighted pair connectivity (W-PC) takes into ac-
count the sum of the products of all the node weights that
belong to the same component.
W-PC = Pcomp
i=1 Pj∈Li wj(Pk6=j;k∈Li wk)
Pn
i=1 wi(Pj6=i wj)
where comp is the number of components in the graph and
Li is the ith component of the graph.
Disconnecting a node: To generate Gi