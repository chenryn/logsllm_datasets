approximately 480,000 AND gates per second on a 1Gbps
network with single-core machines. One could therefore ex-
trapolate that on a setup like ours, their protocol could achieve
rates of approximately 5,000,000 AND gates per second. Note
that by [22, Table 3] a single AES circuit of 7200 AND gates
requires sending 750KB, or 104 bytes (832 bits) per gate.
Thus, on a 10Gbps network their protocol cannot process more
than 12 million AND gates per second (even assuming 100%
utilization of the network, which is typically not possible, and
that computation is not a factor). Our protocol is therefore
at least two orders of magnitude faster. We stress, however,
that the latency of [22] is much lower than ours, which makes
sense given that it follows the garbled circuit approach.
The VIFF framework also considers an honest majority and
has an implementation [8]. The ofﬂine time alone for preparing
1000 multiplications is approximately 5 seconds. Clearly, on
modern hardware, this would be considerably faster, but only
by 1-2 orders of magnitude.
II. THE THREE-PARTY PROTOCOL OF [11] –
THE BASELINE
A. An Informal Description
In [11], a three-party protocol for securely computing any
functionality (represented as a Boolean circuit) with security in
845
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:19:59 UTC from IEEE Xplore.  Restrictions apply. 
the presence of malicious adversaries and an honest majority
was presented. The protocol
is extremely efﬁcient; for a
−40 the protocol requires
statistical cheating probability of 2
each party to send only 10 bits per AND gate. In this section,
we describe the protocol and how it works. Our description is
somewhat abstract and omits details about what exact secret
sharing method is used, how values are checked and so on.
This is due to the fact that all the techniques in this paper
are general and work for any instantiation guaranteeing the
properties that we describe below. We refer the reader to
Appendix A for full details of the protocol of [11].
Background – multiplication triples. The protocol follows
the paradigm of generating shares of multiplication triples
([a], [b], [c]) where a, b, c ∈ {0, 1} such that c = ab, and [x]
denotes a sharing of x. As we have mentioned, this paradigm
was introduced by [2] and has been used extensively to achieve
efﬁcient secure computation [20], [9], [16]. These triples have
the following properties: it is possible to efﬁciently validate
if a triple is correct (i.e., if c = ab) by opening it, and it is
possible to efﬁciently verify if a triple ([a], [b], [c]) is correct
without opening it by using another triple ([x], [y], [z]). This
latter check is such that if one triple is correct and the other is
not, then the adversary is always caught. Furthermore, nothing
is learned about the values a, b, c (but the triple ([x], [y], [z])
has been “wasted” and cannot be used again).
Protocol description: The protocol of [11] works in the
following way:
1) Step 1 – generate random multiplication triples: In this
triples
step,
([ai], [bi], [ci]) with the guarantee that [ai], [bi] are random
and all sharings are valid (meaning that the secret sharing
values held by the honest parties are consistent and of a
well-deﬁned value). However, a malicious party can cause
(cid:2)= aibi. In [11] this is achieved in two steps; ﬁrst
ci
generate random sharings of [ai], [bi] and then run the
semi-honest multiplication protocol of [1] to compute [ci].
This multiplication protocol has the property that the result
is always a valid sharing, but an adversary can cause
ci (cid:2)= aibi and thus it isn’t necessarily correct.
2) Step 2 – validate the multiplication triples: In this step, the
parties validate that the triples generated are valid (meaning
that ci = aibi). This is achieved by opening a few of the
triples completely to check that they are valid, and to group
the rest in “buckets” in which some of the triples are used to
validate the others. The validation has the property that all
the triples in a bucket are used to validate the ﬁrst triple,
so that if that triple is bad then the adversary is caught
cheating unless all the triples in the bucket are bad. The
triples are randomly shufﬂed in order to divide them into
buckets, and the bucket-size taken so that the probability
that there exists a bucket with all-bad triples is negligible.
We denote by N the number of triples that need to be
generated (i.e., output from this stage), by C the number
of triples opened initially, and by B the bucket size. Thus,
in order to output N triples in this step, the parties generate
BN + C triples in the previous step.
the parties generate a large number of
3) Step 3 – circuit computation: In this step,
the parties
securely share their input bits, and then run the semi-honest
protocol of [1] up to (but not including) the stage where
outputs are revealed. We note that this protocol reveals
nothing, and so as long as correctness is preserved, then
full security is obtained.
4) Step 4 – validation of circuit computation: As we described
above, the multiplication protocol used in the circuit com-
putation always yields a valid sharing but not necessarily
of the correct result. In this step, each multiplication in the
circuit is validated using a multiplication triple generated in
Step 2. This uses the exact same procedure of validating
“with opening”; as explained above, this reveals nothing
about
the values used in the circuit multiplication but
ensures that the result is correct.
5) Step 5 – output: If all of the veriﬁcations passed, the parties
securely reconstruct the secret sharings on the output wires
in order to obtain the output.
The checks of the multiplication triples requires the parties to
send values and verify that they have the same view. In order
to reduce the bandwidth (which is one of the main aims), in
the protocol of [11] the parties compare their views only at
the end before the output is revealed, by sending a collision-
resistant hash of their view which is very short. (A similar
idea of checking only at the end was used in [20], [9]). Note
that Steps 1–2 can be run in a separate ofﬂine phase, reducing
latency in the online phase of Steps 3–5.
Efﬁciency. The above protocol can be instantiated very
efﬁciently. For example, sharings of random values can be
generated non-interactively, the basic multiplications requires
each party sending only a single bit, and veriﬁcation of
correctness of triples can be deferred to the end. Furthermore,
since multiplication triples can be generated so efﬁciently, it is
possible to generate a huge amount at once (e.g., 220) which
signiﬁcantly reduces the overall number of triples required.
This is due to the combinatorial analysis of the cut-and-choose
game. Concretely, it was shown in [11] that for a cheating
−40, one can generate N = 220 triples using
probability of 2
bucket-size B = 3 and opening only C = 3 triples. Thus,
overall 3N + 3 triples must be generated. The communication
cost of generating each triple initially is a single bit, the cost
of each validation (in Steps 2 and 4) is 2 bits, and the cost
of multiplying in Step 3 is again 1 bit. Thus, the overall
communication per AND gate is just 10 bits per party (3 bits
to generate 3 triples, 4 bits to validate the ﬁrst using the second
and third, 1 bit to multiply the actual gate, and 2 bits to validate
the multiplication).
Shufﬂing and generating buckets. The shufﬂing of Step 2
in [11] works by simply generating a single array of M =
BN + C triples and randomly permuting the entire array.
Then, the ﬁrst C triples are opened, and then each bucket
is generated by taking B consecutive triples in the array.
In our baseline implementation, we modiﬁed this process.
Speciﬁcally, we generate 1 array of length N, and B−1 arrays
of length N +C. The arrays of length N +C are independently
shufﬂed and the last C triples in each of these arrays is
opened and checked. Finally, the ith bucket is generated by the
taking the ith triple in each of the arrays (for i = 1, . . . , N).
This is easier to implement, and will also be needed in our
later optimizations. We remark that this is actually a different
combinatorial process than the one described and analyzed
in [11], and thus must be proven. In Section III-A, we show
−40 is
that this makes almost no difference, and an error of 2
846
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:19:59 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 1. Microbenchmarking of the baseline implementation (the protocol of [11]), using the CxxProf C++ proﬁler
achieved when setting N = 220, B = 3 and C = 1 (practically
the same as [11]).
B. Implementation Results and Needed Optimizations
As we have discussed, the above protocol is highly efﬁcient,
requiring only 10 bits of communication per AND gate, and
requiring only very simple operations. As such, one would
expect that a good implementation could achieve a rate that is
just a factor of 10 slower than the semi-honest protocol of [1]
that computes 7.15 billion AND gates per second. However,
our implementation yielded results which fall short of this.
Speciﬁcally, on a cluster of three mid-level servers (Intel
Xeon E5-2560 v3 2.3GHz with 20 cores) connected by a
10Gbps LAN with a ping time of 0.13 ms, our implementation
of [11] achieves a rate of 503,766,615 AND gates per second.
This is already very impressive for a protocol achieving
malicious security. However, it is 14 times slower than the
semi-honest protocol of [1], which is signiﬁcantly more than
the factor of 10 expected by a theoretical analysis.
In order to understand the cause of the inefﬁciency, see the
microbenchmarking results in Figure 1. This is a slice showing
one full execution of the protocol, with two threads:
the
ﬁrst thread called run_BTG (Beaver Triples Generator) runs
Steps 1–2 of the protocol to generate validated triples; these
are then used in the second thread called MPC while loop
to compute and validate the circuit computation (Steps 3–4
of the protocol). Our implementation works on blocks of 256-
values at once (using the bit slicing described in [1]), and thus
this demonstrates the generation and validation of 256 million
triples and secure computation of the AES circuit approxi-
mately 47,000 times (utilizing 256 million AND gates).1
Observe that over half the time in run_BTG is spent on
just randomly shufﬂing the arrays in Step 2 (dwarﬁng all other
parts of the protocol). In hindsight, this makes sense since no
cache-efﬁcient random shufﬂe is known, and we use the best
known method of Fisher-Yates [10]. Since we shufﬂe arrays of
one million entries of size 256 bits each, this results in either
main memory or L3 cache access at almost every swap (since
L3 cache is shared between cores, it cannot be utilized when
high throughput is targeted via the use of multiple cores). One
attempt to solve this is to work with smaller arrays, and so a
smaller N. However, in this case, a much larger bucket size
will be needed in order to obtain a cheating bound of at most
−40, signiﬁcantly harming performance.
2
Observe also that
the fourth execution of MPC while
loop of the second thread is extremely long. This is due
1The actual times in the benchmark ﬁgure should be ignored since the
benchmarking environment is on a local machine and not on the cluster.
847
the ﬁrst
to the fact that MPC while loop consumes triples gen-
erated by run_BTG. In this slice,
three execu-
tions of MPC while loop use triples generated in pre-
vious executions of run_BTG, while the fourth execution
of MPC while loop is delayed until this run_BTG con-
cludes. Thus, the circuit computation thread actually wastes
approximately half its time waiting, making the entire system
much less efﬁcient.
III. PROTOCOL VARIANTS AND OPTIMIZATIONS
In this section, we present multiple protocol improvements
and optimizations to the protocol of [11]. Our variants are all
focused on the combinatorial checks of the protocol, and thus
do not require new simulation security proofs, but rather new
bounds on the cheating probability of the adversary.
Our presentation throughout will assume subprotocols as
described in Section II-A: (a) generate random multiplication
triples, (b) verify a triple “with opening”, (c) verify one triple
using another “without opening”, and (d) verify semi-honest
multiplication using a multiplication triple.
A. Cache-Efﬁcient Shufﬂing for Cut-and-Choose
As we have discussed, one of the major bottlenecks of
the protocol of [11] is the cost of random shufﬂing. In this
section, we present a new shufﬂing process that is cache
efﬁcient. We stress that our method does not compute a true
random permutation over the array. However, it does yield a
permutation that is “random enough” for the purpose of cut-
and-choose, meaning that the probability that an adversary can
obtain a bucket with all bad triples is below the required error.
Informal description. The idea behind our shufﬂing method
is to break the array into subarrays, internally shufﬂe each
subarray separately, and then shufﬂe the subarrays themselves.
By making each subarray small enough to ﬁt into cache (L2
or possibly even L1), and by making the number of subarrays
not too large, this yields a much more efﬁcient shufﬂe. In
more detail, recall that as described in Section II-A, instead
of shufﬂing one large array in the baseline protocol, we
start with 1 subarray (cid:2)D1 of length N, and B − 1 subarrays
(cid:2)D2, . . . , (cid:2)DB each of size N + C, and we shufﬂe (cid:2)D2, . . . , (cid:2)DB.
Our cache-efﬁcient shufﬂing works by:
1) Splitting each array (cid:2)Dk into L subarrays (cid:2)Dk,1, . . . , (cid:2)Dk,L.
2) Shufﬂing each subarray separately. (i.e., randomly permut-
ing the entries inside each (cid:2)Dk,i).
3) Shufﬂing the subarrays themselves.
This process is depicted in Figure 2.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:19:59 UTC from IEEE Xplore.  Restrictions apply. 
PROTOCOL 3.1 (Generating Valid Triples – Cache-Efﬁciently):
• Input: The number N of triples to be generated.
• Auxiliary input: Parameters B, C, X, L, such that N = (X −
C)L; N is the number of triples to be generated, B is the
number of buckets, C the number of triples opened in each
subarray, and X = N/L + C is the size of each subarray.
• The Protocol:
1) Generate random sharings: The parties generate 2M shar-
ings of random values, for M = 2(N + CL)(B − 1) + 2N;
denote the shares that they receive by [([ai], [bi])]M/2
i=1 .
2) Generate array (cid:2)D of multiplication triples: As in Step 1 of
the informal description in Section II-A (see Protocol A.1).
3) Cut and bucket: In this stage, the parties perform a ﬁrst
the triples were generated correctly, by
veriﬁcation that
opening some of the triples.
a) Each party splits (cid:2)D into vectors (cid:2)D1, . . . , (cid:2)DB such that
(cid:2)D1 contains N triples and each (cid:2)Dj for j = 2, . . . , B
contains N + LC triples.
b) For k = 2 to B: each party splits (cid:2)Dk into L subarrays
of equal size X, denoted by (cid:2)Dk,1, . . . , (cid:2)Dk,L.
c) For k = 2, . . . , B and j = 1, . . . , L:
the parties
jointly and securely generate a random permutation of
the vector (cid:2)Dk,j.
d) For k = 2, . . . , B:
the parties jointly and securely
generate a random permutation of the vector [1, . . . , L]
and permute the subarrays in (cid:2)Dk accordingly.
e) For k = 2, . . . , B and j = 1, . . . , L: The parties open
and check each of the ﬁrst C triples in (cid:2)Dk,j, and remove
them from (cid:2)Dk,j. If a party rejects any check, it sends ⊥
to the other parties and outputs ⊥.
f) The remaining triples are divided into N sets of triples
(cid:2)B1, . . . , (cid:2)BN , each of size B, such that the bucket (cid:2)Bi
contains the i’th triple in (cid:2)D1, . . . , (cid:2)DB.
4) Check buckets: In each bucket, B − 1 triples are used to
validate the ﬁrst (as in Step 2 of the informal description in
Section II-A and as in Protocol A.1).
• Output: The parties output (cid:2)d.
subarray are permuted to the same position (which happens
for each with probability 1/L). The overall probability that the
adversary wins is close to 1
LB which is much too large (note
that L is typically quite small). By opening balls in each (cid:2)Dk,j,
we prevent the adversary from corrupting an entire subarray
(or many triples in a subarray).
Before proceeding, note that if we set L = 1, we obtain
the basic shufﬂing of Section II-A (and its formal description
in Appendix A), and thus the combinatorial analysis provided
next, applies to that case as well.
Proof of security – combinatorial analysis. We now prove
that the adversary can cause the honest parties to output a
N B−1 .
bad triple in Protocol 3.1 with probability at most
This bound is close to tight, and states that it sufﬁces to
take B = 3 for N = 220 exactly as proven in [11] for
the baseline protocol. However, in contrast to the baseline
protocol, here the parties must open (B−1)CL triples (instead
of just (B − 1)C). Nevertheless, observe that the bound is
actually independent of the choice of C and L. Thus, we
can take C = 1 and we can take L to be whatever is
suitable so that N/L + C ﬁts into the cache and L is not too
large (if L is large then many triples are wasted in opening
and the permutation of {1, . . . , L} would become expensive).
Concretely, for N = 220 one could take L = 512 and then
each subarray is of size 2049 (2048 plus one triple to be
1
Fig. 2. Cache-efﬁcient shufﬂing method
it
We remark that in order to further improve efﬁciency, we
do not shufﬂe the actual data but rather just the indices.2 This
is much more efﬁcient since it saves many memory copies;
we elaborate on this further in Section IV.
As we will show,
in order for this to be secure,
is
necessary to open C triples in each subarray. Thus, N/L + C
triples are needed in each subarray, the size of each (cid:2)Dk (for
k = 2, . . . , B) is L · (N/L + C) = N + CL, and the overall
number of triples needed is N +(B−1)(N +CL). In addition,
overall we execute a shufﬂing (B− 1)(L + 1) times: (B− 1)L
times on the subarrays each of size N/L+C and an additional
B − 1 times on an array of size L. Interestingly, this means
that the number of elements shufﬂed is slightly larger than
previously; however, due to the memory efﬁciency, this is
much faster. The formal description appears in Protocol 3.1.