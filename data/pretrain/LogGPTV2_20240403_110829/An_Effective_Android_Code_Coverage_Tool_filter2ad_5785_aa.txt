title:An Effective Android Code Coverage Tool
author:Aleksandr Pilgun and
Olga Gadyatskaya and
Stanislav Dashevskyi and
Yury Zhauniarovich and
Artsiom Kushniarou
DEMO: An Effective Android Code Coverage Tool
Aleksandr Pilgun
SnT, University of Luxembourg
PI:EMAIL
Olga Gadyatskaya
SnT, University of Luxembourg
PI:EMAIL
Stanislav Dashevskyi
SnT, University of Luxembourg
PI:EMAIL
Yury Zhauniarovich
Qatar Computing Research Institute,
HBKU
PI:EMAIL
ABSTRACT
The deluge of Android apps from third-party developers calls for
sophisticated security testing and analysis techniques to inspect
suspicious apps without accessing their source code. Code coverage
is an important metric used in these techniques to evaluate their
effectiveness, and even as a fitness function to help achieving better
results in evolutionary and fuzzy approaches. Yet, so far there are
no reliable tools for measuring fine-grained bytecode coverage of
Android apps. In this work we present ACVTool that instruments
Android apps and measures the smali code coverage at the level
of classes, methods, and instructions.
Tool repository: https://github.com/pilgun/acvtool
ACM Reference Format:
Aleksandr Pilgun, Olga Gadyatskaya, Stanislav Dashevskyi, Yury Zhau-
niarovich, and Artsiom Kushniarou. 2018. DEMO: An Effective Android
Code Coverage Tool. In 2018 ACM SIGSAC Conference on Computer and Com-
munications Security (CCS ’18), October 15–19, 2018, Toronto, ON, Canada.
ACM, New York, NY, USA, 3 pages. https://doi.org/10.1145/3243734.3278484
1 INTRODUCTION
Android is the dominant mobile platform today, with millions of
devices running it and millions of third-party applications (apps for
short) available for its users. Unfortunately, this huge ecosystem
suffers from proliferation of malicious [14] and buggy [10, 11] apps.
Not surprisingly, techniques for automatic detection of malicious
and faulty Android apps are in high demand.
One of the critical aspects in Android app analysis and testing
is that apps are submitted to markets, including the main market
Google Play, being already compiled and packaged. Their source
code is not available for inspection neither to security researchers,
nor to Google. Thus, automated analysis and testing tools need to
operate in the black-box manner, without any knowledge of the
expected behaviors of apps and with no access to their source code.
In this work, we specifically focus on measuring code cover-
age of Android apps. This metric is an integral part of software
development and quality assurance activities for all programming
languages and software ecosystems, and it has become a critical
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
© 2018 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-5693-0/18/10.
https://doi.org/10.1145/3243734.3278484
Artsiom Kushniarou
SnT, University of Luxembourg
PI:EMAIL
metric for Android application analysis. Fellow researchers and
practitioners evaluate the effectiveness of tools for automated test-
ing and security analysis using code coverage (e.g., [3–5, 8, 10, 16]).
However, obtaining this metric is not a trivial task. Without
the source code, code coverage is usually measured by instrument-
ing the bytecode, and this process is not straightforward for An-
droid [8].
Related Work. Today, several tools for measuring code coverage
over the bytecode of Android apps already exist, but they all have
limitations. One of these limitations is the coarse granularity of
the metric. For example, ELLA [6] and InsDal [9] measure code
coverage only at at the method level.
Another limitation of the existing tools is low instrumentation
success rate. For example, the tool by Huang et al. [8] measures
code coverage achieved by popular dynamic analysis tools at the
class, method, basic block and line granularities. However, the
authors reported that they have been able to successfully instru-
ment only 36% of apps to measure code coverage. Another tool for
black-box code coverage measurement is BBoxTester [17] that has
achieved the successful app instrumentation rate of 65%. It reports
coverage at the class, method and basic block granularities.
Furthermore, the existing tools suffer from limited empirical
evaluation, with a typical evaluation dataset of less than 100 apps.
Often, research papers do not even mention the percentage of failed
instrumentation attempts.
Remarkably, in the absence of a reliable fine-grained code cov-
erage measurement tool, some frameworks integrate their own
libraries that perform this task, e.g. [2, 10, 13]. However, as code
coverage measurement is not the core contribution of these works,
the authors have provided no information regarding their instru-
mentation success rates and performance.
Contribution. In this paper we present our ACVTool that mea-
sures code coverage of Android apps without relying upon their
source code. ACVTool produces detailed coverage reports that are
convenient for either visual inspections, or automatic processing.
Our tool also collects crash reports that facilitate the analysis of
faults within apps. We have empirically validated ACVTool against
a large dataset of third-party apps. ACVTool has successfully instru-
mented 96.9% of apps in our experiments. Average time required
to instrument an app with ACVTool is 36 seconds, i.e., it is negli-
gible for the standard testing and analysis purposes. ACVTool is
self-contained and transparent to the testing environment, and can
be integrated with any testing or analysis tool. We have released
ACVTool as an open source project to support the Android research
community.
fast operation in comparison to manipulating string identifiers as
in previous solutions [8, 9]. Moreover, this basic operation is much
faster than creating new class objects or calling the Android API. In
the end, the relatively large amount of the added probe code does
not lead to any visible degradation of the application.
In its core, ACVTool puts a tracking probe right after each origi-
nal instruction and label, excluding some corner cases. For instance,
due to Dalvik-related limitations, the probes could not be inserted
in-between some instruction pairs [7], such as the invoke-* or
filled-new-array instructions followed by move-result*, and
the catch label followed by the move-exception instruction. More-
over, the Android Runtime has the VerifyChecker component,
which ensures that the exception-free part of the Java synchronized
implementation (usually generated by the Android compiler) can-
not raise an exception. The verifier scans the corresponding parts
of the bytecode for unsafe instructions. To avoid failings at run-
time, we wrap our tracking code by a goto/32 call and return the
execution flow straight back after the probe was registered.
Along with the instrumented apk file, the offline phase produces
an instrumentation report, which matches the cells of the binary
array onto smali code. It is a serialized code representation saved
into a binary file with the pickle extension. This report will be
applied in the report generation phase.
Orchestration. ACVTool injects a Reporter class and a special
Instrumentation class in an apk. The first allocates memory to
log probe execution and also enables pulling of code coverage
information from memory into the external memory of the de-
vice. The second class provides the capability to monitor and save
application-level crashes. The Instrumentation class also con-
tains a broadcast receiver. Through this receiver ACVTool can
trigger the Instrumentation class to initiate saving the code cov-
erage information. To enable this functionality, ACVTool adds
the WRITE_EXTERNAL_STORAGE permission and an instrument tag
pointing to the Instrumentation class into the app manifest file.
2.2 Online phase
During this phase, we install the instrumented app on a device or
emulator. We first activate the broadcast receiver implemented in
the Instrumentation class. Then we can exercise the app manually
or automatically, while logging the code coverage data.
After the testing is over, ACVTool generates another specific
broadcast to consolidate the runtime information into a runtime
report stored within the external storage of the device.
2.3 Report Generation phase
During this phase, ACVTool pulls the runtime report from the device
and applies the instrumentation report generated during the offline
phase. ACVTool generates code coverage report in the html and xml
formats. The html report demonstrates the smali representation of
the app code with appropriate coverage information in an easy to
navigate browser view. Figure 2 shows an example of an html report,
where individual smali code files available with the executed code
are highlighted. The report gives the following information by
columns: name of a smali file or a package, visualized numbers
of missed vs. covered instructions, the code coverage value. The
last six columns indicate the amount of the code that was not
Figure 1: The ACVTool workflow