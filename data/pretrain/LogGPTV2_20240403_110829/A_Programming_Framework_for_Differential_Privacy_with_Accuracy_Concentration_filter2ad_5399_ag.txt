| ˜Q(D) − Q(D)| > σ
Pr
2 log (2/β)
(cid:3) β
(6)
(cid:2)
(cid:13)
(cid:3)
Figure 15 shows how concentration bounds are applied
for the case of the Gaussian mechanism—UNION-BOUND
and ADD-UNION are omitted since they are the same as
the ones in Figure 7. In general, the accuracy analysis for
addition of aggregations follows the one presented in Section IV.
The main difference is seen when adding independent values.
In this case, we use the well-known fact the addition of
independent normally distributed random variables is also
normally distributed. This means that after executing the ADD-
CHERNOFF-UNION we do not lose information about the
distribution of our result as we used to do under the Laplacian
setting.
F. Privacy and accuracy trade-off analysis in DPella
We study histograms with certain hierarchical structure
(commonly seen in Census Bureaus analyses) where different
accuracy requirements are imposed per level and where
varying one privacy or accuracy parameter can have a cascade
impact on the privacy or accuracy of others. We consider the
scenario where we would like to generate histograms from the
Authorized licensed use limited to: Carleton University. Downloaded on August 06,2020 at 17:57:38 UTC from IEEE Xplore.  Restrictions apply. 
426
Adult database9 to perform studies on gender balance. The
information that we need to mine is not only an histogram
of the genders (for simplicity, just male and female) but also
how the gender distributes over age, and within that, how
age distributes over nationality—thus exposing a hierarchical
structure of three levels.
1 hierarchical1 [e1, e2, e3 ] dat = do
2
3
4
5
6
7
8
-- h1 :: Map Gen (Value Double)
-- h2 :: Map (Gen, Age) (Value Double)
-- h3 :: Map (Gen, Age, Nationality) (Value Double)
h1 ← byGen
h2 ← byGenAge
h3 ← byGenAgeNat e3 dat
return (h1, h2, h3)
e1 dat
e2 dat
(a) Hierarchical histogram I: distribute budget among the levels
9 hierarchical2 e dat = do
h3 ← byGenAgeNat e dat
10
h2 ← level2 h3
11
h1 ← level1 h3
12
return (h1, h2, h3)
13
(b) Hierarchical histogram II: spend budget only on the most
detailed histogram
Fig. 16: Implementation of hierarchical histograms
Our ﬁrst approach is depicted in Figure 16a, where query
hierarchical1 generates three histograms with different
levels of details. This query puts together the results produced
by queries byGen, byGenAge, and byGenAgeNationality
where each query generates an histogram of the speciﬁed set
of attributes. Observe that these sub-queries are called with
potentially different epsilons, namely e1, e2, and e3, then
under sequential composition, we expect hierarchical1 to
be e1+e2+e3-differentially private.
We proceed to explore the possibilities to tune the privacy
and accuracy parameters to our needs. In this case, we want
a conﬁdence of 95% for accuracy, i.e., β = 0.05, with a total
budget of 3 ( = 3). We could manually try to take the budget
 = 3 and distribute it to the different histograms in many
different ways and analyze the implication for accuracy by
calling accuracy on each sub-query. Instead, we write a small
(simple, brute force) optimizer in Haskell that splits the budget
uniformly among the queries, i.e., e1 = 1, e2 = 1, and e3 = 1,
and tries to ﬁnd the minimum epsilon that meets the accuracy
demands per histogram. In other words, we are interested
in minimizing the privacy loss at each level bounding the
maximum accepted error. The optimizer essentially adjusts the
different epsilons and calls accuracy during the minimization
process. To ensure termination, the optimizer aborts after a
ﬁxed number of calls to accuracy, or when the local budget
ei is exhausted.
Table II shows some of our ﬁndings. The ﬁrst row shows
what happens when we impose an error of 100 at every level
9https://archive.ics.uci.edu/ml/datasets/adult
Histogram
byGen
byGenAge
byGenAgeNat
byGen
byGenAge
byGenAgeNat
byGen
byGenAge
byGenAgeNat
α tolerance
100
100
100
10
50
5
5
5
10
Status
× MaxBud
× MaxBud
(cid:7)
(cid:7)
(cid:7)
(cid:7)
(cid:7)
(cid:7)
(cid:7)

0.06
0.06
0.11
0.41
0.16
1
0.76
1
0.96
α
61.48
96.13
85.74
8.99
36.05
9.43
4.85
5.76
9.82
TABLE II: Budgeting with α tolerances, β = 0.05, & total
 = 3
of detail, i.e., each bar in all the histograms could be at most
+/ − 100 off. Then, we only need to spend a little part of
our budget—the optimizer ﬁnds the minimum epsilons that
adheres to the accuracy constrains. Instead, the second row
shows that if we ask to be gradually more accurate on more
detailed histograms, then the optimizer could fulﬁll the ﬁrst
two demands and aborted on the most detailed histogram
(byGenAgeNat) since it could not ﬁnd an epsilon that fulﬁlls
that requirement—the best we can do is spending all the budget
and obtain and error bound of 9.43. Finally, the last row shows
what happens if we want gradually tighter error bounds on the
less detailed histograms. In this case, the middle layer can be
“almost” fulﬁlled by expending all the budget and obtaining an
error bound of 5.76 instead of 5. While the results from Table
II could be acceptable for some data analysts, they might not
be for others.
We propose an alternative manner to implement the same
query which consists on spending privacy budget only for
the most detailed histogram. As shown in Figure 16b, this
new approach spends all the budget e on calling h3 ←
byGenAgeNat e dat. Subsequently, the algorithm builds the
other histograms based on the information extracted from the
most detailed one. For that, we add the noisy values of h3
(using helper functions level2 and level1) creating the rest of
the histograms representing the Cartesian products of gender
and age, and gender, respectively. These methodology will
use add and norm∞ to compute the derived histograms, and
therefore will not consume more privacy budget. Observe that
the query proceeds in a bottom-up fashion, i.e., it starts with the
most detailed histogram and ﬁnishes with the less detailed one.
Now that we have two implementations, which one is better?
Which one yields the better trade-offs between privacy and
accuracy? Figure 17 shows the accuracy of the different level
of histograms, i.e., h1, h2, and h3, when ﬁxing β = 0.05 and
a global budget of  = 1 (h1-1, h2-2, and h3-3) and  = 3
(h1-3, h2-3, and h3-3)—we obtained all this information by
running repetitively the function accuracy. Form the graphics,
we can infer that the splitting of the privacy budget per level
often gives rise to more accurate histograms. However, observe
the exception when  = 3 for hierarchical2: in this case,
hierarchical1 will use an  = 1 in that histogram so it will
receive a more noisy count than using  = 3.
Authorized licensed use limited to: Carleton University. Downloaded on August 06,2020 at 17:57:38 UTC from IEEE Xplore.  Restrictions apply. 
427
100
50
α
105
hierarchical1
hierarchical2
45
17
29
11
35
9
4
15
6
9
3
h1-1
h2-1
h3-1
h1-3
h2-3
h3-3
h1 = byGen, h2 = byGenAge, h3 = byGenAgeNat
Fig. 17: hierarchical1 vs. hierarchical2
G. K-way marginal queries on synthetic data
We focus on the problem of releasing, in a differentially
private manner, the k-way marginals of a binary dataset D ∈
(0, 1d)n. This is a classical learning problem that has been
[60, 61, 62]
extensively studied in the DP literature, see
among others. A k-marginal query, also called a k-conjunction,
returns the count of how many individual records in D have
k < d attributes set to certain values. For simplicity, we focus
on 3-way marginal queries to compare performance between
DPella and using synthetic data. The goal of our analysis is to
release all the 3-way marginals of a dataset.
This is implemented through the following code:
-- Perform all 3-way combinations up to attribute dim
→ [Query (Value Double)]
(i, j, k) ← combinatory (dim-1) 3
let allOne r = (r !! i) ≡ (r !! j) ≡ (r !! k) ≡ 1
return (do tab ← dpWhere allOne db
1
2 allChecks ::  → Int → Data s {0, 1}d
3
4 allChecks localEps dim db = do
5
6
7
8
9
dpCount localEps tab
)
-- Compute k-way marginals
10
11 threeMarginal ::  → Int → Data s {0, 1}d
12 → Query (Value [Double])
13 threeMarginal localEps dim db = do
14
15
checks ← sequence (allChecks localEps dim db)
return (norm∞ checks)
Function allChecks counts how many records have 3-
attributes set to 1. Auxiliary function combinatory d k
generates k-tuples arising from the combination of indexes
0, 1, . . . , d taken k at the time. In our example, the number
. For each tuple, allChecks
of generated tuples is
ﬁlters the rows which have attributes i, j, and k set to
1 (dpWhere allOne db) for then making a noisy count
(dpCount localEps tab). Function threeMarginal collects
dim
(cid:14)
(cid:15)
3
(cid:14)
(cid:15)
3
the counts for the different considered attributes and places
them into a vector (norm∞ checks).
(cid:15)
(cid:14)
dim
We run threeMarginal considering a synthetic dataset (db)
which has only 1 row with all the attributes set to zeros. Setting
all the attributes to zero produces that all the counts are 0, thus
we are able to measure the noisy on each run and accuracy
accordingly. We run threeMarginal approx. 1000 times for
each dimension to measure the noisy magnitude, where we
took the 1-β percentile with β = 0.05 (as we did in many
queries and
of our case studies). Notice that we have
independent sources of noise, which need an high
so
number of runs to be well-represented. In general, for this kind
of task one is interested in bounding the max error that can
occur in one of the queries (the (cid:7)∞ norm over the output). For
this task, the empirical error is well aligned with the theoretical
one provided by DPella by calling the function accuracy. The
latter is computed by taking a union bound over the error of
each individual query. For each query we have a tight bound
and the union bound gives us a tight bound over the max.
However, we observe a signiﬁcant different in performance.
dim
3
Time(seconds)
102
−2
10
−6
10
accuracy
synthetic
20
5
10
15
Dimension (dim)
Fig. 18: Performance comparison between accuracy (DPella)
and estimating errors using synthetic analysis
Figure 18 shows (in log scale) the time difference when
calculating accuracy by DPella and on synthetic data when the
dimension of the dataset increases. Already in low dimension,
the difference in performance is many orders of magnitude in
favor of DPella—a tendency which does not change when the
dimension goes above 20. The main reason for that comes down
to that DPella, as an static analysis, do not execute the ﬁltering
dpWhere allOne db (as well as any other transformation,
recall Section IV-B) which an approach based on synthetic
data should do and many times—in our case 1000 iterations
for each dimension. We expect that for more complex tasks
this difference is even more evident.
Authorized licensed use limited to: Carleton University. Downloaded on August 06,2020 at 17:57:38 UTC from IEEE Xplore.  Restrictions apply. 
428