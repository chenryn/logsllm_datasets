slowly increasing level of crawler tra(cid:28)c to our infrastructure,
which supports the e(cid:28)cacy of our experimental controls.
55.27% ofthe crawlerrequests were successfulandreturned
an HTTP 200 status code (or 302 for redirection links). The
remaining requests returned a 404 status code: 7.56% were
denied by cloaking and 37.17% requested nonexistent URLs.
Many of the nonexistent URLs represented crawler e(cid:29)orts
to scan for phishing kit archives or credential (cid:27)les, which is
a common way to (cid:27)ngerprint phishing websites and identify
stolen credentials that may linger on the same server [13].
In Figure 9, we show the cumulative distribution of crawler
tra(cid:28)c to our websites. We observe that after an initial burst
within the (cid:27)rst day of deployment, successful tra(cid:28)c remains
fairly consistent for the remainder of the deployment. This
tra(cid:28)c accounts for crawlers that continuously monitor for
the presence of phishing content.
The relative proportion of requests that were denied
through cloaking fell over time. The increased crawling e(cid:29)ort
early on allows crawlers to (cid:27)ngerprint evasion techniques
such that future requests are more likely to be successful. We
believe that this behavior in part helped blacklists deliver the
high coverage we observed, even for websites with combina-
tions of cloaking techniques such as Experiment C.
9 Discussion and Recommendations
Although blacklists are capable of detecting the typical
evasion techniques which we tested—including cloaked
redirection—our tests have shown that these techniques
generally both slow speed and reduce coverage. Notable gaps
in coverage also remain,particularly on mobile devices. Given
attackers’ ability to adapt to the ecosystem by leveraging so-
phisticated evasion strategies, such as those in Experiment F,
we believe that evasion remains a key anti-phishing concern.
Defensive Strategy. To the best of our knowledge, sys-
tematic longitudinal measurements of anti-phishing defenses
390    29th USENIX Security Symposium
USENIX Association
are not currently being performed at the ecosystem level.
The PhishTime framework, combined with deployments of
targeted experiments, can be used as a defensive strategy
to identify gaps in defenses and help address them through
security recommendations. Although our work focuses on
browser blacklists, the scope of future experiments could
also be shifted to evaluate other mitigations (e.g., spam
(cid:27)lters). Moreover, the ecosystem analysis could be aimed
at areas other than evasion techniques, such as identifying
attacker-friendly web hosts or compromised domains [1].
Depending on the objectives of the entity carrying out
the experiments, PhishTime can be used to assess aspects
of the ecosystem as a whole, or the behavior of a speci(cid:27)c
entity or mitigation. We believe this is a crucial (cid:27)rst step
toward achieving consistency in—and perhaps accountability
for—anti-phishing and account protection e(cid:29)orts [57] of the
many di(cid:29)erent organizations that phishers impersonate. We
have proposed this approach to the APWG; subsequently,
e(cid:29)orts are underway to incorporate PhishTime as an
ecosystem-level service which can be used to monitor URLs
reported to the APWG eCrime exchange and drive future
experiments based on this dataset or external reports.
Role of Blacklists. As a supplement to ecosystem de-
fenses, numerous commercial vendors o(cid:29)er phishing website
take-down services for major brands [2, 45]; such websites
are either detected by the vendor’s own scanning e(cid:29)orts or
reported to the brand. Take-downs are performed via requests
sent by the vendor to a hosting provider or domain registrar,
are typically reliant on cooperation, and can be subject to
delays of several hours or even days [1, 7]. In parallel with
our PhishTime experiments, we collaborated with PayPal to
measure the take-down speed(forcriminalphishing websites)
of one major vendor during the same period, and found a me-
dian speed of 23.6 hours: considerably slower than the typical
speed of blacklists observed in Section 8.2. As blacklists are
not subject to the delays inherent to take-downs, we believe
that they can better serve as the (cid:27)rst line of defense against
phishing and may rendertake-downs unnecessary when their
coverage is su(cid:28)cient; this further underscores the bene(cid:27)ts of
sealing gaps in blacklists’ detection of evasive websites.
Reporting Protocols. Given the prevalence of evasive
phishing in the wild and the promising performance of CSSR,
we believe that the adoption and expansion of evidence-based
reporting protocols should be a priority for the ecosystem.
In addition to supporting manual reporting by humans, such
protocols should be made available to vetted automated
anti-phishing systems. A key bene(cid:27)t of such an integration
would be if one entity detects an evasive phishing website,
it could share the parameters used for detection to help other
entities (e.g., blacklists) avoid duplication of e(cid:29)ort while
improving mitigation (e.g., speed and coverage). Moreover,
such evidence can be used to support take-down e(cid:29)orts [1]
or law enforcement intervention if an initial mitigation, such
as blacklisting, proves insu(cid:28)cient. Evidence-based reporting
could also help harden systems against abusive, deliberately
false reports: such reports could be (cid:27)ltered out based on the
evidence itself (e.g., by identifying anomalies within a pool of
related reports, rather than solely relying on attributes that
are easier to fabricate, such as the bare URL).
Beyond the expansion of enhanced reporting protocols,
we believe that standardized methods for reporting phishing
across the ecosystem—rather than to individual entities—
would help improve the ecosystem’s collective response. As
we observed with single-entity reporting in Experiment E,
each anti-phishing entity functioned di(cid:29)erently and, thus,
a(cid:29)ected blacklisting in a di(cid:29)erent way. Additionally, the
drop in coverage we observed during Deployment 3 suggests
that the ecosystem may in some cases be fragile. If one
anti-phishing entity contributes disproportionately to the
mitigation of a particular type of threat, it can become a choke
point, which, in case of a temporary failure or degradation,
could provide an opportunity for phishers to launch a
burst of successful attacks. However, strict centralization of
reporting could carry privacy or legal concerns; therefore,
in a standardized reporting framework, one or more trusted
intermediaries could instead serve to optimally route reports.
Certi(cid:27)cate Revocation. Throughout our deployments,
we monitoredthe OSCP revocation status [40] ofourdomains’
SSL certi(cid:27)cates, which we automatically obtained from Let’s
Encrypt (a free Certi(cid:27)cate Authority with the highest repre-
sentation among phishing websites in the wild [16]). None of
thecerti(cid:27)cateswererevoked. Inaddition,wefoundthatcerti(cid:27)-
cates could also be issued for domains that were already black-
listed, as Let’s Encrypt had discontinued checking domains
in new certi(cid:27)cate requests against GSB in early 2019 [33].
Although the role of Certi(cid:27)cate Authorities as a mitigation
against phishing is subject to debate [16], the ease at which
attackers can obtain certi(cid:27)cates warrants closer scrutiny.
Mobile Blacklists. Mobile users account for a majority of
Internet tra(cid:28)c [14], and prior research has shown that mobile
web browsers are particularly prone to phishing attacks [37].
Yet, our (cid:27)ndings indicate that the anti-phishing protection in
mobile web browsers continues to trail behind that of desktop
browsers. The bandwidth used by mobile devices—which
may be subject to mobile carrier restrictions—was historically
a barrier to desktop-level GSB protection in mobile Chrome
and Safari [44]. However, over a Wi-Fi connection (which
we used for monitoring), the full blacklist should be checked.
Although our experiments were unable to determine ex-
actly how GSB or Opera decide if a URL blacklisted in the
respective desktop browser should also be blacklisted on mo-
bile (e.g., they might rely on manual review or additional
classi(cid:27)cation attributes to determine maliciousness), we ob-
served that the evasive websites we deliberately con(cid:27)gured
to only be accessible in mobile browsers (i.e., Experiment B)
were in factneverblacklistedin these browsers5. We therefore
5This issue does not apply to mobile Firefox: from version 63, mobile
Firefox always checks the full desktop version of the GSB blacklist.
USENIX Association
29th USENIX Security Symposium    391
believe that mobile blacklisting represents a key ecosystem
vulnerability, and that it should be made consistent to better
protect mobile users inevitably targeted by phishers.
Ecosystem Changes. A notable ecosystem development
took place in December 2019: in Chrome 79, Google improved
the speed of GSB by “up to 30 minutes” [4] by incorporating
real-time lookups of phishing URLs for users who opt in. Al-
though not yet enabled by default, this change acknowledges,
and seeks to address, the delay to blacklisting speed possible
in the default implementation of GSB, which caches and
periodically updates a local copy of the URL blacklist. This
change also applies to the mobile version of Chrome and may,
therefore, help address the aforementioned gaps in blacklist-
ing in mobile Chrome. Due to the timing of the release of this
feature, we were not able to evaluate it in our experiments.
9.1 Disclosures
Beyond the disclosures to PayPal and bit.ly discussed in
Section 8, after completing our (cid:27)nal deployment, we sent
a report with our experimental (cid:27)ndings to PayPal, Google,
Opera,Microsoft,and Apple,with a focus on the sophisticated
evasion techniques that we identi(cid:27)ed and the gaps in black-
listing on mobile devices. All the organizations acknowledged
receipt of our report. Google followed up to request details on
the JavaScript cloaking, and acknowledged the gap in mobile
blacklisting, which it is actively working to address. We later
met with Opera who, as a result, incorporated additional
ecosystem data sources to improve its discovery of URLs
(and ultimately increase blacklist coverage). Moreover, Opera
foundthatthese data sources—whichenhancedits server-side
blacklist—also helped eliminate disparities in mobile blacklist
warnings. We described our experimental methodology
in each of our disclosures; the former three organizations
(which followed up) did not express concerns with it.
9.2 Ethical Considerations
We sought to address a number of potential ethical concerns
while conducting this research.
Risk to Human Users. To ensure that our phishing
websites could not harm any potential human visitors, we
utilized random paths and only distributed the full URLs
directly to anti-phishing entities. In the event of form
submission, our websites performed no backend processing
or logging of POST data; the use of HTTPS ensured that data
would not leak in transit.
Infrastructure Usage. We followed the terms of service
of all services and APIs used for this research,and we obtained
permission from Google to report URLs programmatically
to Google Safe Browsing. We informed our hosting provider
(Digital Ocean) about our research and obtained permission
to leverage server infrastructure accordingly.
Adverse Side-e(cid:29)ects. Despite our relatively large sample
size for each deployment, we do not believe that the volume
of URLs we reported hampered the anti-phishing ecosystem’s
ability to mitigate real threats. Based on the overall phishing
volume per the GSB Transparency Report [25], each of our
deployments accounted for less than 1% of all phishing
detections made during the same period. We informed PayPal
of our experiments to ensure that resources were not wasted
on manual investigations of our activity (note that PayPal
stated that this knowledge did not in(cid:30)uence how it treated
the individual phishing URLs we reported). We also obtained
permission to use the PayPal brand and promptly disclosed
the ecosystem vulnerabilities that we discovered.
9.3 Limitations
Despite thecontrolsdiscussedin Section7.4,ourexperimental
(cid:27)ndings should be considered alongside certain limitations.
We did not modify the appearance of our phishing websites
between deployments, and they impersonated a single brand
(PayPal). Therefore, our (cid:27)ndings may be skewed by detection
trends speci(cid:27)c to this brand [48]. Possible (cid:27)ngerprinting of
the websites’ source code over time and the lack of positive
reputation of our domains could increase the speed of black-
listing, while our use of randomized, non-suspicious URLs for
each website may have reduced it [64]. We believe that our
websites still realistically represent phishing in the wild, as at-
tackers extensively re-use phishing kits (some of which share
common backends for multiple brands) and also routinely
leverage fully randomized URLs [45].
Itwasnotfeasibletoachieveaone-to-onemappingbetween
our 2,646 unique domains and the 45 hosting IP addresses
available to us. To mitigate potential skew from IP reuse, we
distributed IP mappings as uniformly as possible within each
batch of websites. Ultimately, URLs on certain IPs were not
signi(cid:27)cantly more likely to be blacklisted than others: across
all experiments, the standard deviation in the distribution of
the average GSB blacklist speed by IP was only 3.8 minutes.
Whenreportingourphishingwebsites,ourgoalwastoguar-
antee timely discovery by blacklists. Given the high baseline
speed and near-perfect coverage we observed in Experiment A,
we believe thatwe succeededin this goal. Nevertheless,unlike
real phishers, we did not spam victims or trigger other actions
that could lead to detection by blacklists (such as signals
from browser-based classi(cid:27)ers [35]). Thus, our reporting
methodology may not fully re(cid:30)ect the continuous indicators
of abuse observable in the wild; it may also be skewed in
favor of GSB: the only blacklist to which we reported directly.
Finally, our experiments were limited in scope to a subset
of the di(cid:29)erent phishing website con(cid:27)gurations available to
attackers. Additionaldeployments can naturallybe adaptedto
test other con(cid:27)gurations or those that appear in the future. Al-
thoughthePhishTimeframeworkitselfmayfailtoidentifycer-
tain attacks that entirely avoid discovery, the use of additional
sources of phishing URLs could address this shortcoming.
Fully Automating PhishTime. In our deployment of
the PhishTime framework, the website analysis ( 3 ) and
experiment generation stages ( 4 ) were mostly done man-
392    29th USENIX Security Symposium
USENIX Association
ually. However, through the addition of a semantic phishing
classi(cid:27)cation engine (not only to (cid:27)ngerprint the server-side
cloaking of each phishing website, but also to analyze its
client-side evasion),end-to-endautomation couldbe achieved
for experiments. Manual intervention would then only be
needed to evaluate anomalous (cid:27)ndings and verify validity.
10 Related Work
To the best of our knowledge, PhishTime is the (cid:27)rst sys-
tematic methodology for the continuous measurement and
enhancement of the protection o(cid:29)ered by the anti-phishing
ecosystem, and it enabled the (cid:27)rst controlled longitudinal
empirical study of the performance of browser blacklists.
Although other controlled studies were previously done,
they focused on individual anti-phishing entities and were
performedovera shortperiod,whichlimitedthe scope oftheir
security recommendations and their ability to validate trends.
The work most similar to ours is that of Oest et al. [44], who
proposed the framework for empirically measuring blacklists
which we adapted. The authors used the framework to deploy
(cid:27)ve batches of 396 arti(cid:27)cial phishing websites over two weeks
to measure (cid:27)ve distinct anti-phishing entities’ response to
websites with di(cid:29)erent sets of cloaking (similar to our Experi-
mentE). Theauthorsfoundanddisclosedthatseveralcloaking
techniques couldsuccessfully defeatblacklists,andthatdue to
a bug, mobile GSB browsers saw no blacklisting whatsoever
(the latterissue has since been addressed). However,by report-
ing to just a single entity per batch, the study did not clearly
di(cid:29)erentiate between blacklist detection and discovery, and
therefore underestimated the ecosystem’s speed, especially
foruncloakedwebsites. Also,unlike ourstudy,itcouldnotpre-
cisely compare the real-world impact of delays in blacklisting
caused by di(cid:29)erent cloaking techniques. Because we guided
our experiments by current ecosystem trends (rather than an
o(cid:31)ine study of cloaking), our experiments more closely emu-
lated real-world attacks and allowed us to evaluate advanced
evasion. Consequently, we found new blacklist detection
vulnerabilities, long-term inconsistencies, and lingering gaps
in blacklisting coverage in mobile browsers. We also found
individual cloaking techniques to be a far lesser threat than
combinations thereof, which the prior work did not evaluate.
Peng et al. [48] deployed 66 arti(cid:27)cial phishing websites
over four weeks to investigate how well VirusTotal and its
sub-vendors are able to detect phishing content. This study
focused on showing that detection models vary greatly across
di(cid:29)erentanti-phishing vendors. These variations help explain
the incremental growth that we observed in the coverage of
evasive phishing websites across di(cid:29)erent blacklists.
Other work has indirectly measured the performance of
blacklists. Oest et al. [46] analyzed a large sample of phishing
tra(cid:28)c to live phishing websites trackable through third-party
web requests and found a high degree of sophistication in
clusters of large attacks. The authors estimated the average
e(cid:29)ect of blacklisting across the entire dataset and showed the
importance of adequate blacklisting speed by quantifying the
potential increase in victims caused by delays; this technique
can also help contextualize our experimental (cid:27)ndings. Han
et al. [26] monitored a honeypot server on which attackers
installed phishing kits. Although this approach enables the
measurement of attacker and victim interactions with the
kits (in addition to the ecosystem’s response), the di(cid:28)culty
of controlling variables such as the sample size, deployment
time, and website con(cid:27)guration highlights the advantages of
our measurement methodology based on arti(cid:27)cial websites.
Earlier studies measured the blacklisting of phishing
websites after they appeared in various feeds [36,50,52,63].
Because feeds have an inherent delay, the resulting measure-
ments of blacklist speed are imprecise. However, they provide
insightinto the coverage ofblacklists across platforms andthe
characteristics of phishing websites: hence, we adapted this
approach in the PhishTime framework and enhanced it with
direct reporting to verify blacklists’ detection capabilities.
11 Conclusion
We have proposed methodology for systematically evaluating
the protection provided by the anti-phishing ecosystem
in the long term, with a focus on browser blacklists and
phishing reporting protocols. By identifying sophisticated
evasion techniques used by phishing websites in the wild