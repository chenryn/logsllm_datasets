### Gradual Increase in Crawler Traffic to Our Infrastructure

We observed a gradual increase in crawler traffic to our infrastructure, which supports the effectiveness of our experimental controls. 55.27% of the crawler requests were successful and returned an HTTP 200 status code (or 302 for redirection links). The remaining requests returned a 404 status code: 7.56% were denied by cloaking, and 37.17% requested nonexistent URLs. Many of these nonexistent URLs represented crawler efforts to scan for phishing kit archives or credential files, a common method for fingerprinting phishing websites and identifying stolen credentials that may linger on the same server [13].

In Figure 9, we present the cumulative distribution of crawler traffic to our websites. After an initial burst within the first day of deployment, successful traffic remained fairly consistent for the remainder of the deployment. This traffic accounts for crawlers that continuously monitor for the presence of phishing content.

The relative proportion of requests that were denied through cloaking decreased over time. The increased crawling effort early on allowed crawlers to fingerprint evasion techniques, making future requests more likely to be successful. We believe this behavior contributed to the high coverage we observed from blacklists, even for websites employing combinations of cloaking techniques, such as those in Experiment C.

### Discussion and Recommendations

#### Evasion Techniques and Blacklist Performance

Although blacklists are capable of detecting typical evasion techniques, including cloaked redirection, our tests have shown that these techniques generally slow down detection and reduce coverage. Notable gaps in coverage remain, particularly on mobile devices. Given attackers' ability to adapt to the ecosystem by leveraging sophisticated evasion strategies, such as those in Experiment F, we believe that evasion remains a key anti-phishing concern.

#### Defensive Strategy

To the best of our knowledge, systematic longitudinal measurements of anti-phishing defenses are not currently being performed at the ecosystem level. The PhishTime framework, combined with targeted experiments, can serve as a defensive strategy to identify and address gaps in defenses through security recommendations. Although our work focuses on browser blacklists, future experiments could evaluate other mitigations, such as spam filters. Additionally, the ecosystem analysis could focus on areas beyond evasion techniques, such as identifying attacker-friendly web hosts or compromised domains [1].

Depending on the objectives of the entity conducting the experiments, PhishTime can be used to assess aspects of the ecosystem as a whole or the behavior of specific entities or mitigations. We believe this is a crucial first step toward achieving consistency and accountability in anti-phishing and account protection efforts [57] across various organizations. We have proposed this approach to the APWG, and efforts are underway to incorporate PhishTime as an ecosystem-level service to monitor URLs reported to the APWG eCrime exchange and drive future experiments based on this dataset or external reports.

#### Role of Blacklists

As a supplement to ecosystem defenses, numerous commercial vendors offer phishing website takedown services for major brands [2, 45]. These websites are either detected by the vendor's own scanning efforts or reported to the brand. Takedowns are typically reliant on cooperation and can be subject to delays of several hours or even days [1, 7]. In parallel with our PhishTime experiments, we collaborated with PayPal to measure the takedown speed for criminal phishing websites of one major vendor during the same period. We found a median speed of 23.6 hours, which is considerably slower than the typical speed of blacklists observed in Section 8.2. Since blacklists are not subject to the delays inherent in takedowns, we believe they can better serve as the first line of defense against phishing and may render takedowns unnecessary when their coverage is sufficient. This further underscores the benefits of sealing gaps in blacklists' detection of evasive websites.

#### Reporting Protocols

Given the prevalence of evasive phishing and the promising performance of CSSR, we believe that the adoption and expansion of evidence-based reporting protocols should be a priority for the ecosystem. Such protocols should support both manual reporting by humans and automated reporting by vetted anti-phishing systems. A key benefit of this integration is that if one entity detects an evasive phishing website, it can share the parameters used for detection, helping other entities avoid duplication of effort while improving mitigation (e.g., speed and coverage). Moreover, such evidence can support takedown efforts [1] or law enforcement intervention if initial mitigations, such as blacklisting, prove insufficient. Evidence-based reporting can also help harden systems against abusive, deliberately false reports by filtering out anomalies within a pool of related reports, rather than relying solely on attributes that are easier to fabricate, such as the bare URL.

#### Standardized Reporting Methods

Beyond the expansion of enhanced reporting protocols, we believe that standardized methods for reporting phishing across the ecosystem—rather than to individual entities—would help improve the collective response. As observed in Experiment E, each anti-phishing entity functions differently, affecting blacklisting in different ways. The drop in coverage during Deployment 3 suggests that the ecosystem may be fragile. If one entity disproportionately contributes to the mitigation of a particular threat, it can become a choke point, and its temporary failure or degradation could provide an opportunity for phishers to launch a burst of successful attacks. However, strict centralization of reporting could carry privacy or legal concerns. Therefore, in a standardized reporting framework, one or more trusted intermediaries could optimally route reports.

#### Certificate Revocation

Throughout our deployments, we monitored the OCSP revocation status [40] of our domains' SSL certificates, which we automatically obtained from Let's Encrypt (a free Certificate Authority with the highest representation among phishing websites in the wild [16]). None of the certificates were revoked. Additionally, we found that certificates could be issued for domains already blacklisted, as Let's Encrypt had discontinued checking domains in new certificate requests against GSB in early 2019 [33]. Although the role of Certificate Authorities in mitigating phishing is debated [16], the ease with which attackers can obtain certificates warrants closer scrutiny.

#### Mobile Blacklists

Mobile users account for a majority of internet traffic [14], and prior research has shown that mobile web browsers are particularly prone to phishing attacks [37]. However, our findings indicate that anti-phishing protection in mobile web browsers lags behind that of desktop browsers. Historically, the bandwidth used by mobile devices, which may be subject to mobile carrier restrictions, was a barrier to desktop-level GSB protection in mobile Chrome and Safari [44]. Over a Wi-Fi connection, the full blacklist should be checked. Although our experiments could not determine exactly how GSB or Opera decide if a URL blacklisted in the desktop browser should also be blacklisted on mobile, we observed that the evasive websites we configured to be accessible only in mobile browsers (i.e., Experiment B) were never blacklisted in these browsers. We, therefore, believe that mobile blacklisting represents a key ecosystem vulnerability and should be made consistent to better protect mobile users.

#### Ecosystem Changes

A notable ecosystem development occurred in December 2019: in Chrome 79, Google improved the speed of GSB by "up to 30 minutes" [4] by incorporating real-time lookups of phishing URLs for users who opt in. Although not yet enabled by default, this change acknowledges and seeks to address the delay in blacklisting speed possible in the default implementation of GSB, which caches and periodically updates a local copy of the URL blacklist. This change also applies to the mobile version of Chrome and may help address the aforementioned gaps in blacklisting in mobile Chrome. Due to the timing of the release, we were not able to evaluate it in our experiments.

### Disclosures

Beyond the disclosures to PayPal and bit.ly discussed in Section 8, after completing our final deployment, we sent a report with our experimental findings to PayPal, Google, Opera, Microsoft, and Apple, focusing on the sophisticated evasion techniques we identified and the gaps in blacklisting on mobile devices. All organizations acknowledged receipt of our report. Google followed up to request details on the JavaScript cloaking and acknowledged the gap in mobile blacklisting, which it is actively working to address. We later met with Opera, who, as a result, incorporated additional ecosystem data sources to improve URL discovery and increase blacklist coverage. These data sources also helped eliminate disparities in mobile blacklist warnings. We described our experimental methodology in each disclosure; the former three organizations did not express concerns with it.

### Ethical Considerations

We addressed several potential ethical concerns while conducting this research:

- **Risk to Human Users**: To ensure that our phishing websites could not harm any potential human visitors, we used random paths and distributed the full URLs directly to anti-phishing entities. In the event of form submission, our websites performed no backend processing or logging of POST data, and the use of HTTPS ensured that data would not leak in transit.
- **Infrastructure Usage**: We followed the terms of service of all services and APIs used for this research and obtained permission from Google to report URLs programmatically to Google Safe Browsing. We informed our hosting provider (Digital Ocean) about our research and obtained permission to leverage server infrastructure accordingly.
- **Adverse Side Effects**: Despite our relatively large sample size for each deployment, we do not believe that the volume of URLs we reported hampered the anti-phishing ecosystem’s ability to mitigate real threats. Based on the overall phishing volume per the GSB Transparency Report [25], each of our deployments accounted for less than 1% of all phishing detections made during the same period. We informed PayPal of our experiments to ensure that resources were not wasted on manual investigations of our activity. We also obtained permission to use the PayPal brand and promptly disclosed the ecosystem vulnerabilities we discovered.

### Limitations

Despite the controls discussed in Section 7.4, our experimental findings should be considered alongside certain limitations. We did not modify the appearance of our phishing websites between deployments, and they impersonated a single brand (PayPal). Therefore, our findings may be skewed by detection trends specific to this brand [48]. Possible fingerprinting of the websites’ source code over time and the lack of positive reputation of our domains could increase the speed of blacklisting, while our use of randomized, non-suspicious URLs for each website may have reduced it [64]. We believe that our websites still realistically represent phishing in the wild, as attackers extensively reuse phishing kits (some of which share common backends for multiple brands) and also routinely leverage fully randomized URLs [45].

It was not feasible to achieve a one-to-one mapping between our 2,646 unique domains and the 45 hosting IP addresses available to us. To mitigate potential skew from IP reuse, we distributed IP mappings as uniformly as possible within each batch of websites. Ultimately, URLs on certain IPs were not significantly more likely to be blacklisted than others: across all experiments, the standard deviation in the distribution of the average GSB blacklist speed by IP was only 3.8 minutes.

When reporting our phishing websites, our goal was to ensure timely discovery by blacklists. Given the high baseline speed and near-perfect coverage we observed in Experiment A, we believe that we succeeded in this goal. Nevertheless, unlike real phishers, we did not spam victims or trigger other actions that could lead to detection by blacklists (such as signals from browser-based classifiers [35]). Thus, our reporting methodology may not fully reflect the continuous indicators of abuse observable in the wild and may be skewed in favor of GSB, the only blacklist to which we reported directly.

Finally, our experiments were limited in scope to a subset of the different phishing website configurations available to attackers. Additional deployments can naturally be adapted to test other configurations or those that appear in the future. Although the PhishTime framework itself may fail to identify certain attacks that entirely avoid discovery, the use of additional sources of phishing URLs could address this shortcoming.

### Fully Automating PhishTime

In our deployment of the PhishTime framework, the website analysis (step 3) and experiment generation stages (step 4) were mostly done manually. However, through the addition of a semantic phishing classification engine (to fingerprint the server-side cloaking of each phishing website and analyze its client-side evasion), end-to-end automation could be achieved for experiments. Manual intervention would then only be needed to evaluate anomalous findings and verify validity.

### Related Work

To the best of our knowledge, PhishTime is the first systematic methodology for the continuous measurement and enhancement of the protection offered by the anti-phishing ecosystem, enabling the first controlled longitudinal empirical study of the performance of browser blacklists. Although other controlled studies have been conducted, they focused on individual anti-phishing entities and were performed over a short period, limiting the scope of their security recommendations and their ability to validate trends.

The work most similar to ours is that of Oest et al. [44], who proposed a framework for empirically measuring blacklists, which we adapted. The authors used the framework to deploy five batches of 396 artificial phishing websites over two weeks to measure five distinct anti-phishing entities’ response to websites with different sets of cloaking (similar to our Experiment E). They found and disclosed that several cloaking techniques could successfully defeat blacklists, and due to a bug, mobile GSB browsers saw no blacklisting whatsoever (the latter issue has since been addressed). However, by reporting to just a single entity per batch, the study did not clearly differentiate between blacklist detection and discovery, underestimating the ecosystem’s speed, especially for uncloaked websites. Unlike our study, it could not precisely compare the real-world impact of delays in blacklisting caused by different cloaking techniques. Because we guided our experiments by current ecosystem trends, our experiments more closely emulated real-world attacks and allowed us to evaluate advanced evasion. Consequently, we found new blacklist detection vulnerabilities, long-term inconsistencies, and lingering gaps in blacklisting coverage in mobile browsers. We also found that individual cloaking techniques were a far lesser threat than combinations thereof, which the prior work did not evaluate.

Peng et al. [48] deployed 66 artificial phishing websites over four weeks to investigate how well VirusTotal and its sub-vendors detect phishing content. This study focused on showing that detection models vary greatly across different anti-phishing vendors. These variations help explain the incremental growth we observed in the coverage of evasive phishing websites across different blacklists.

Other work has indirectly measured the performance of blacklists. Oest et al. [46] analyzed a large sample of phishing traffic to live phishing websites trackable through third-party web requests and found a high degree of sophistication in clusters of large attacks. The authors estimated the average effect of blacklisting across the entire dataset and showed the importance of adequate blacklisting speed by quantifying the potential increase in victims caused by delays. Han et al. [26] monitored a honeypot server on which attackers installed phishing kits. Although this approach enables the measurement of attacker and victim interactions with the kits, the difficulty of controlling variables such as sample size, deployment time, and website configuration highlights the advantages of our measurement methodology based on artificial websites.

Earlier studies measured the blacklisting of phishing websites after they appeared in various feeds [36, 50, 52, 63]. Because feeds have an inherent delay, the resulting measurements of blacklist speed are imprecise. However, they provide insight into the coverage of blacklists across platforms and the characteristics of phishing websites. Hence, we adapted this approach in the PhishTime framework and enhanced it with direct reporting to verify blacklists’ detection capabilities.

### Conclusion

We have proposed a methodology for systematically evaluating the protection provided by the anti-phishing ecosystem in the long term, with a focus on browser blacklists and phishing reporting protocols. By identifying sophisticated evasion techniques used by phishing websites in the wild, we aim to enhance the overall security and resilience of the ecosystem.