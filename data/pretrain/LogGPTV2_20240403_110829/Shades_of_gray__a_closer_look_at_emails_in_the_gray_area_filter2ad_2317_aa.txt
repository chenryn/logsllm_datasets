title:Shades of gray: a closer look at emails in the gray area
author:Jelena Isacenkova and
Davide Balzarotti
Shades of Gray: A Closer Look at Emails in the Gray Area
Jelena Isacenkova
Eurecom
Sophia Antipolis
06410 France
PI:EMAIL
Davide Balzarotti
Eurecom
Sophia Antipolis
06410 France
PI:EMAIL
ABSTRACT
Every day, millions of users spend a considerable amount of
time browsing through the messages in their spam folders.
With newsletters and automated notiﬁcations responsible
for 42% of the messages in the user’s inboxes, inevitably
some important emails get misclassiﬁed as spam. Unfortu-
nately, users are often unable to take security related deci-
sions, and tools provide no assistance to easily distinguish
harmless commercial messages from the ones that are most
certainly malevolent.
Most of the previous studies focused on the detection of
Instead, in this paper we look into the often over-
spam.
looked area of gray emails, i.e., those messages that cannot
be clearly categorized one way or the other by automated
spam ﬁlters. In particular, we analyze real-world emails by
grouping them into clusters of bulk email campaigns. Our
approach is able to automatically classify and reduce by half
the gray emails area with only 0.2% false positives.
Moreover, we identify a number of campaign features that
can be used to predict the campaign category and we dis-
cuss their eﬀectiveness and their limitations. Our experi-
ments show that a large fraction of emails in the gray area
are composed of legitimate bulk emails: newsletters, noti-
ﬁcations, and marketing oﬀers. The latter appears to be a
large e-marketing business industry that has grown into a
complex infrastructure for sending legitimate bulk emails.
To the best of our knowledge, this is the ﬁrst real-world
empirical study of such emails.
Keywords
Gray emails, classiﬁcation, botnet generated campaigns, com-
mercial campaigns, Nigerian scam, newsletters, phishing,
challenge response system
1.
INTRODUCTION
Nowadays, many antispam ﬁlters provide a good level of
protection against large-scale unsolicited email campaigns.
However, as spammers have improved their techniques to
increase the chances of reaching their targets, also antispam
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
ASIA CCS’14, June 4–6, 2014, Kyoto, Japan.
Copyright 2014 ACM 978-1-4503-2800-5/14/06 ...$15.00.
http://dx.doi.org/10.1145/2590296.2590344 .
solutions have become more aggressive in ﬂagging suspicious
emails.
On one side, this arms race has lead to a steady increase
in the detection rate. On the other, it also contributed to
the increase of the false positives, with serious consequences
for the users whenever an important message is erroneously
ﬂagged as spam. Moreover, at the border between legit-
imate user emails and spam lies a gray area of messages
that are hard to automatically classify. This area often con-
tains newsletters and commercial oﬀers which were origi-
nally solicited, but that are not anymore interesting for the
users [9]. More in general, it includes messages that are not
ﬂagged by traditional antispam ﬁlters, but that are not nec-
essarily wanted by the users.
In 2012, Hotmail estimated
that gray emails were the source of 75% of all spam com-
plaints. Another Email Intelligence Report published by
ReturnPath [28] pointed out that 16% of emails contain-
ing advertisements or marketing information are normally
ﬂagged as spam and, therefore, never reach user mailboxes.
At ﬁrst glance, many people would consider this “side-eﬀect”
as an advantage. However, it has been estimated that only
one-third of users consider such messages as spam, while
two-thirds prefer to receive unsolicited commercial emails
from already known senders [7]. A more recent report shows
that despite the mailboxes being overloaded, consumers still
read 18% of subscribed marketing emails, and continue to
sign up for email oﬀers and mailing lists [28], with the result
that newsletters and automated notiﬁcations sum up up to
42% of inbox messages. For these reasons, it is a well known
fact that most of the users regularly check their spam folder
to verify that no important messages have been misclassiﬁed
by the antispam ﬁlter.
Unfortunately, this process is very time-consuming. An-
tispam solutions are not very helpful in this direction, and
do not usually provide any additional information to help
users in quickly identifying marketing emails, newsletters,
or “borderline” cases that may be interesting for the users.
Even worse, when users skim through their spam mes-
sages looking for something that looks legitimate, they need
to take a decision on which email can be trusted, which one is
just annoying, and which can pose a real security threat. Un-
fortunately, several studies showed that most users are very
bad in taking these kind of security-related decisions [19],
and this is one of the reasons why we need automated spam
ﬁlters in the ﬁrst place. For example, a recent survey con-
ducted in 2010 [17] by the Messaging Anti-Abuse Working
Group reported that 57% of the people who have accessed
spam messages admitted to have done so intentionally, be-
377cause they were unsure whether the suspicious message was
spam or not.
While most of the existing research deals with the prob-
lem of eﬃciently and accurately distinguishing spam from
ham, in this paper we focus on the thin line that separates
the two categories. In particular, we limit our study to the
often overlooked area of gray emails [31], i.e., those ambigu-
ous messages that cannot be clearly categorized one way or
the other by automated spam ﬁlters. We start from the as-
sumption that spam ﬁlters are good in detecting most of the
spam, and if the ﬁlter has “good reasons” to believe that a
message is unsolicited or that it contains malicious content
(e.g., by employing an antivirus, a black list, or by matching
a signature of a known scam message), there would be no
reason for most users to double-check that decision.
We start our study by analyzing a real deployment of a
challenge-response antispam solution to measure the extent
of this gray area. We use system’s quarantined emails that
already exclude the majority of the ham and spam messages
as an approximation of the gray emails category. According
to our data, after the obvious spam and ham emails have
been eliminated, users still manually check on average ﬁve
to six messages per day. On average, 1.5% of these mes-
sages have an attachment with 9% of them being malicious.
However, some of these messages also contain interesting
content, as proved by the fact that users read and whitelist
an average of 1.5 messages per day. We also conﬁrm the
belief that ordinary users are not very good in telling spam
and ham apart.
Under these premises, we analyze the messages in the gray
area in order to improve our understanding about them and
the reasons that make them diﬃcult to categorize. In par-
ticular, we adopt a three-phase approach based on message
clustering, classiﬁcation, and graph-based reﬁnement. Ex-
tracted email features are applied in a context of email cam-
paigns instead of individual emails. Our technique is able to
automatically classify half of the gray emails, corresponding
to 15% of all email traﬃc, with only 0.2% of false positives.
Moreover, our results show a number of interesting charac-
teristics of commercial marketing campaigns, which consti-
tute to a large fraction of the gray area. To the best of our
knowledge, this is the ﬁrst empirical study of legitimate bulk
emails.
2. BACKGROUND
Email-based marketing is a common practice for adver-
tisement and sales, and it is used both to maintain com-
munication with current customers, as well as to acquire
new ones. Unfortunately, when users’ inboxes started to
get overloaded with various types of bulk messages, mailbox
maintenance became highly time-consuming. As a result,
email ﬁlters were introduced to protect users from unso-
licited messages, starting a multi-million anti-spam protec-
tion industry and a battle that is far from being over. In
fact, even though direct mail marketing has a higher re-
sponse rate (3.4%) than email marketing (0.12%) [8], the
low cost of emails still makes electronic messages a very at-
tractive solution.
Marketers often use professional marketing tools in order
to maximize their campaign delivery rates. These tools help
to clean non-existing emails from customer lists, to deal with
recipient complaints, to avoid hitting spam traps, and even
provide detailed campaign delivery statistics. Today run-
ning an email marketing campaign is a complex operation,
and more and more solicited bulk emails fall into the recip-
ient spam folders. In fact, these folders often contain mes-
sages that cannot be clearly categorized by automated spam
ﬁlters. This gray area is responsible for 75% of the spam
complaints [9] and it contains both legitimate and harm-
less bulk emails, and malicious messages that can result in
a computer infection or in stolen personal data. However,
users also appear to be ineﬀective in distinguishing one class
from the other [17, 19] and often (70%) take their decision
based only on the sender ﬁeld and subject line.
For clarity, in this study we separate bulk emails into two
categories: legitimate and spam. The ﬁrst includes solicited
(subscribed newsletters and notiﬁcations) or potentially so-
licited (advertisements) messages sent according to legal reg-
ulations (e.g.
the CAN-SPAM Act [1] and the E-Privacy
Directive [3]). The second category contains instead unso-
licited, malicious, or illegal promotion emails.
The distribution of legitimate marketing campaigns be-
came a large business where specialized companies provide
as a service professional email marketing tools, and also sell
categorized email lists for marketers looking for new clients.
The collection of such lists is legal: when users subscribe to
some services and ﬁll out a form, they might – by choice or
by default – agree to share their information with the third-
parties. Hence, at some point users do agree to receive the
advertisements.
Related work
Many ﬁltering solutions, often used in combination with
each other, exist to detect and mitigate spam.
In our approach we focus on the analysis of the senders
behavior. Pathak et al. [20] suggested to analyze the send-
ing behavior of spammers, while Ramachandran et al. [27,
26] used behavioral blacklists to classify sender IP addresses
based on their behavior. Ramachandran observed that spam-
mers exhibit recognizable sending patterns, based on which
behavior ﬁngerprints can be build. Qian et al. [25] proposed
to rely on the reputation of IP clusters, e.g. BGP clusters,
and combine it with DNS information, improving the pre-
cision of public IP-based blacklists by 50%. Hao et al. [10]
built an automated reputation engine, called SNARE, aim-
ing at distinguishing legitimate senders from spammers based
on a number of non-content email features. West et al. [30]
built a reputation model to predict the behavior of spam-
mers. The model relies on spatial and temporal features that
can be especially useful in partial-knowledge situations. The
model managed to classify up to 50% of the spam emails that
were not identiﬁed by the blacklists. The advantage of such
network-level detection techniques is that they tend to react
faster to spam campaigns than typical blacklisting services.
The study closest to our research was performed by Qian
et al. [24], where the authors proposed a content-based un-
supervised email campaign clustering algorithm, and also
recognized the problem of classifying legitimate campaigns
in a real-world dataset.
In particular, they tried to ﬁlter
out legitimate bulk emails by using certain keywords and
a threshold of IPs per campaign. While the latter can be
eﬃcient when dealing with campaigns sent by botnets, it
is ineﬀective against other malevolent campaigns sent from
webmail accounts. We demonstrate in our study that such
campaigns tend to mimic the traits of legitimate campaigns
and are diﬃcult to identify based only on sender character-
istics.
378To our knowledge, there are no known studies performed
on legitimate bulk emails, and only few have studied the
gray emails phenomenon [32, 31, 6]. Yih et al. [31] argued
that ﬁltering gray emails with even an optimal spam ﬁlter
is a very diﬃcult task. Therefore, the authors proposed to
treat gray emails separately and rely on user feedback to
label messages. Their experiments, performed on a dataset
that is similar to the one we used in our study, showed that
classifying emails on per-campaign basis yielded a higher
precision and data coverage compared to a per-email treat-
ment. However, the email or campaign class may depend on
the user [6, 7]. Therefore, Chang et al. [6] studied how to
combine user feedback with user preferences to improve the
classiﬁcation results. Youn et al. [32] proposed an ontology-
based technique to provide personalized gray email ﬁltering
based on user behavior. Although we agree that the per-
sonalization of gray email is crucial, our results also suggest
that user feedback might be unreliable for class prediction.
As spam is primarily sent in bulk emails, many studies
try to identify it through the analysis of bulk email cam-
paigns ( [16, 21, 29, 13]). Kanich et al. [13] studied spam
campaigns by inﬁltrating a botnet and evaluated their con-
version rate from a marketing perspective. Clustering spam
emails by URLs and their redirections was ﬁrst proposed
by Li et al. [16]. Pathak et al.
[21] tried to cluster spam
campaigns using URLs, but it proved to be a challenging
task due to URL obfuscation. Thomas et al. [29] conﬁrmed
the problem and proposed a new technique to ﬁlter URLs
in real-time. Finally, Qian et al.
[24] identiﬁed email cam-
paigns based on their content similarity and Pitsillidis et
al. [23] proposed to automatically extract spam campaign
templates from regular expressions extracted from the mes-
sages.
As we mentioned at the beginning, most of the previous
work on the ﬁeld is focused on identifying spam and its cam-
paigns. In this paper, we exclude most of the spam and le-
gitimate messages and focus instead on the borderline area
between them.
3. METHODOLOGY
This section presents the dataset we used in our exper-
iments and the techniques we adopted to process and an-
alyze the email messages. Since it would be impossible to
classify each email in isolation, we adopted a multi-layered
approach to group them into similar campaigns (a solution
proven to be eﬀective by several previous studies [31, 24,
21]). In particular, we start by clustering them based on the
email headers. We then extract a set of features based on
a number of campaign attributes and we use them to train
a classiﬁer in order to predict the campaign class. Finally,
we employ a graph-based reﬁnement technique to further
increase the coverage and precision of our classiﬁcation.
3.1 Data Collection
The amount and diversity of the available data is cru-
cial in order to successfully identify email campaigns. Mes-
sages should be collected from multiple feeds, cover numer-
ous recipients, several organizations, and for a long period of
time [21, 22]. Our email dataset fulﬁlls these requirements as
it was collected from a commercial Challenge-Response (CR)
spam system deployed in tens of diﬀerent organizations.
A CR ﬁlter is a software that automatically replies with
a challenge (in our case a CAPTCHA) to any previously-
unknown sender of incoming emails. If the sender solves the
challenge, the message is delivered to the recipient and the
sender is added to a whitelist; if not, it remains in a quar-
antined folder, where its recipient can manually view and
whitelist/blacklist it. Since in our study we want to focus
on the borderline area that contains the emails that can-
not be easily classiﬁed as legitimate or spam, we installed a
sensor in the CR system to intercept any quarantined mes-
sage. These emails have successfully passed through a num-
ber of traditional antispam ﬁlters including virus scanners,
reverse DNS, and DNS blacklisting veriﬁcation. Moreover,
users never had any previous conversation with the sender.
Therefore, we can consider this dataset as pre-ﬁltered from
obvious legitimate and spam emails.
Sometimes this set is referred to as a gray zone [6] that
stores emails of uncertain class. Email categories often found
in this group include traditional spam and scam messages,
automated notiﬁcations, newsletters, and commercial oﬀers.
Due this variety, users need to manually check these mes-
sages from time to time looking for any interesting or missing
email.
We also instrumented the CR-system to collect additional
information (see Table 1): opened emails by the users, and
whitelisted messages (thus showing that the user manually
classiﬁed them as legitimate). This provides insights on the
users ability to distinguish harmless from harmful messages.
Finally, our sensor collected the delivery status information,
e.g. sent, bounced, and delivered, for each challenge email
sent back by the CR system.
In our experiments we relied on statistical email data that
we collected from companies of diﬀerent sizes. The monitor-
ing period covered 6 months, from August 2011 to January
2012. During this period around 11 million messages were
delivered to the monitored mail servers (Table 1). 29.4%
of them belonged to the class of gray messages. To protect
the privacy of both the users and the companies involved
in the study, the data we used in our experiments did not
include the email bodies, and the headers were sanitized and
analyzed in an aggregated form.
3.2 Email Clustering
The task of grouping emails into campaigns has already
been covered by several previous studies ( [15, 23, 16, 24,
21]). Previous results were very successful in identifying
email campaigns, but, unfortunately, often relied on the con-
tent of the email body. Our dataset is limited to the email
headers, thus forcing us to use a diﬀerent approach based
only on the email subjects. The main limitation of this
technique is that the email subjects have to be long enough
to minimize the chances of matching diﬀerent messages by
coincidence.
The obvious solution for grouping similar subjects would
be to apply some text mining algorithm, but our input text is
short and it is important to preserve the word order. Hence,
we decided to use a simple approach based on “almost exact”
text matching, extended to include subjects with a variable
part. The latter could be a varying phrase in the subject,
including random words, identiﬁers, or user names. We use
word n-grams of a decreasing length (between 70 and 8),
with a sliding window that permits to skip over varying parts
of the subjects. Our implementation is based on an existing
n-grams extraction library (Ngram Statistics Package [4]), a