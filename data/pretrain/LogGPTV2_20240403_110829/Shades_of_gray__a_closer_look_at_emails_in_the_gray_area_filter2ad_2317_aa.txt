# Shades of Gray: A Closer Look at Emails in the Gray Area

**Authors:**
- Jelena Isacenkova
- Davide Balzarotti

**Affiliation:**
Eurecom, Sophia Antipolis, 06410 France

**Abstract:**
Every day, millions of users spend a considerable amount of time browsing through their spam folders. With newsletters and automated notifications accounting for 42% of inbox messages, it is inevitable that some important emails are misclassified as spam. Unfortunately, users often struggle to make security-related decisions, and current tools offer little assistance in distinguishing harmless commercial messages from potentially malicious ones.

Most previous studies have focused on the detection of spam. In this paper, we examine the often-overlooked area of gray emailsâ€”messages that cannot be clearly categorized by automated spam filters. We analyze real-world emails by clustering them into bulk email campaigns. Our approach can automatically classify and reduce the gray email area by half, with only a 0.2% false positive rate. Additionally, we identify several campaign features that can predict the category of an email and discuss their effectiveness and limitations. Our experiments show that a large fraction of gray emails consists of legitimate bulk emails such as newsletters, notifications, and marketing offers, which form a significant part of the e-marketing industry. To our knowledge, this is the first real-world empirical study of such emails.

**Keywords:**
Gray emails, classification, botnet-generated campaigns, commercial campaigns, Nigerian scam, newsletters, phishing, challenge-response system

## 1. Introduction

Today, many antispam filters provide a good level of protection against large-scale unsolicited email campaigns. However, as spammers refine their techniques to evade these filters, antispam solutions have become more aggressive, leading to an increase in false positives. This has serious consequences for users when important messages are incorrectly flagged as spam. Moreover, there exists a gray area between legitimate user emails and spam, containing messages that are difficult to automatically classify. These often include newsletters and commercial offers that were initially solicited but are no longer of interest to the users.

In 2012, Hotmail estimated that gray emails were the source of 75% of all spam complaints. Another report by ReturnPath [28] indicated that 16% of emails containing advertisements or marketing information are typically flagged as spam. While some users may view this as a benefit, it has been estimated that only one-third of users consider such messages as spam, while two-thirds prefer to receive unsolicited commercial emails from known senders [7]. Despite the overload, consumers still read 18% of subscribed marketing emails and continue to sign up for email offers and mailing lists [28]. As a result, newsletters and automated notifications account for 42% of inbox messages. Consequently, most users regularly check their spam folders to ensure no important messages have been misclassified.

This process is very time-consuming, and antispam solutions do not provide much help in quickly identifying marketing emails, newsletters, or borderline cases. When users skim through their spam messages, they must decide which emails are trustworthy, annoying, or potentially harmful. Several studies have shown that users are generally poor at making these security-related decisions [19], which is why automated spam filters are necessary. For example, a 2010 survey by the Messaging Anti-Abuse Working Group reported that 57% of people who accessed spam messages did so intentionally because they were unsure whether the message was spam [17].

While most existing research focuses on distinguishing spam from legitimate emails, this paper examines the thin line separating the two categories. Specifically, we focus on the often-overlooked area of gray emails [31], which are ambiguous messages that cannot be clearly categorized by automated spam filters. We start from the assumption that spam filters are effective in detecting most spam, and if a filter has "good reasons" to flag a message as unsolicited or malicious, there would be no need for users to double-check that decision.

We begin our study by analyzing a real deployment of a challenge-response antispam solution to measure the extent of this gray area. We use the quarantined emails, which exclude the majority of ham and spam messages, as an approximation of the gray email category. According to our data, after eliminating obvious spam and ham emails, users still manually check an average of five to six messages per day. On average, 1.5% of these messages have attachments, with 9% being malicious. However, some of these messages also contain interesting content, as evidenced by the fact that users read and whitelist an average of 1.5 messages per day. We confirm that ordinary users are not very good at distinguishing spam from ham.

Under these premises, we analyze the gray area to better understand the characteristics of these messages and the reasons they are difficult to categorize. We adopt a three-phase approach based on message clustering, classification, and graph-based refinement. Extracted email features are applied in the context of email campaigns rather than individual emails. Our technique can automatically classify half of the gray emails, corresponding to 15% of all email traffic, with only a 0.2% false positive rate. Furthermore, our results reveal several interesting characteristics of commercial marketing campaigns, which constitute a large fraction of the gray area. To our knowledge, this is the first empirical study of legitimate bulk emails.

## 2. Background

Email-based marketing is a common practice for advertisement and sales, used to maintain communication with current customers and acquire new ones. As users' inboxes became overloaded with various types of bulk messages, email filters were introduced to protect users from unsolicited messages, starting a multi-million anti-spam protection industry. Although direct mail marketing has a higher response rate (3.4%) than email marketing (0.12%) [8], the low cost of emails makes electronic messages a very attractive solution.

Marketers often use professional marketing tools to maximize their campaign delivery rates. These tools help clean non-existing emails from customer lists, handle recipient complaints, avoid spam traps, and provide detailed campaign delivery statistics. Running an email marketing campaign is now a complex operation, and more and more solicited bulk emails fall into recipients' spam folders. These folders often contain messages that cannot be clearly categorized by automated spam filters. This gray area is responsible for 75% of spam complaints [9] and includes both legitimate and harmless bulk emails, as well as malicious messages that can lead to computer infections or stolen personal data. However, users are often ineffective in distinguishing between these classes [17, 19] and frequently (70%) base their decisions on the sender field and subject line.

For clarity, we separate bulk emails into two categories: legitimate and spam. The first category includes solicited (subscribed newsletters and notifications) or potentially solicited (advertisements) messages sent according to legal regulations (e.g., the CAN-SPAM Act [1] and the E-Privacy Directive [3]). The second category contains unsolicited, malicious, or illegal promotion emails.

The distribution of legitimate marketing campaigns has become a large business, with specialized companies providing professional email marketing tools and selling categorized email lists to marketers. The collection of such lists is legal: when users subscribe to services and fill out forms, they may agree to share their information with third parties. Thus, users do agree to receive advertisements at some point.

### Related Work

Many filtering solutions exist to detect and mitigate spam, often used in combination. Our approach focuses on the analysis of senders' behavior. Pathak et al. [20] suggested analyzing the sending behavior of spammers, while Ramachandran et al. [27, 26] used behavioral blacklists to classify sender IP addresses based on their behavior. Qian et al. [25] proposed relying on the reputation of IP clusters, such as BGP clusters, and combining it with DNS information, improving the precision of public IP-based blacklists by 50%. Hao et al. [10] built an automated reputation engine, SNARE, to distinguish legitimate senders from spammers based on non-content email features. West et al. [30] built a reputation model to predict spammers' behavior, using spatial and temporal features, and managed to classify up to 50% of spam emails not identified by blacklists. Network-level detection techniques tend to react faster to spam campaigns than typical blacklisting services.

The study closest to ours was performed by Qian et al. [24], where the authors proposed a content-based unsupervised email campaign clustering algorithm and recognized the problem of classifying legitimate campaigns in a real-world dataset. They tried to filter out legitimate bulk emails using certain keywords and a threshold of IPs per campaign. While this can be effective for campaigns sent by botnets, it is ineffective against other malevolent campaigns sent from webmail accounts. Our study demonstrates that such campaigns mimic the traits of legitimate campaigns and are difficult to identify based solely on sender characteristics.

To our knowledge, there are no known studies on legitimate bulk emails, and only a few have studied the gray email phenomenon [32, 31, 6]. Yih et al. [31] argued that filtering gray emails, even with an optimal spam filter, is very difficult. They proposed treating gray emails separately and relying on user feedback to label messages. Their experiments, conducted on a dataset similar to ours, showed that classifying emails on a per-campaign basis yielded higher precision and data coverage compared to a per-email treatment. However, the email or campaign class may depend on the user [6, 7]. Chang et al. [6] studied how to combine user feedback with user preferences to improve classification results. Youn et al. [32] proposed an ontology-based technique to provide personalized gray email filtering based on user behavior. Although we agree that personalization is crucial, our results suggest that user feedback might be unreliable for class prediction.

As spam is primarily sent in bulk emails, many studies try to identify it through the analysis of bulk email campaigns [16, 21, 29, 13]. Kanich et al. [13] studied spam campaigns by infiltrating a botnet and evaluated their conversion rate from a marketing perspective. Li et al. [16] first proposed clustering spam emails by URLs and their redirections. Pathak et al. [21] tried to cluster spam campaigns using URLs but found it challenging due to URL obfuscation. Thomas et al. [29] confirmed the problem and proposed a new technique to filter URLs in real-time. Finally, Qian et al. [24] identified email campaigns based on content similarity, and Pitsillidis et al. [23] proposed automatically extracting spam campaign templates from regular expressions in the messages.

Most previous work in the field has focused on identifying spam and its campaigns. In this paper, we exclude most spam and legitimate messages and focus instead on the borderline area between them.

## 3. Methodology

This section presents the dataset we used in our experiments and the techniques we adopted to process and analyze the email messages. Since it would be impossible to classify each email in isolation, we adopted a multi-layered approach to group them into similar campaigns, a solution proven effective by several previous studies [31, 24, 21]. Specifically, we start by clustering them based on email headers. We then extract a set of features based on campaign attributes and use them to train a classifier to predict the campaign class. Finally, we employ a graph-based refinement technique to further increase the coverage and precision of our classification.

### 3.1 Data Collection

The amount and diversity of available data are crucial for successfully identifying email campaigns. Messages should be collected from multiple feeds, cover numerous recipients, several organizations, and over a long period [21, 22]. Our email dataset meets these requirements, as it was collected from a commercial Challenge-Response (CR) spam system deployed in tens of different organizations.

A CR filter is a software that automatically replies with a challenge (in our case, a CAPTCHA) to any previously unknown sender of incoming emails. If the sender solves the challenge, the message is delivered to the recipient, and the sender is added to a whitelist; if not, it remains in a quarantined folder, where the recipient can manually view and whitelist or blacklist it. Since we want to focus on the borderline area containing emails that cannot be easily classified as legitimate or spam, we installed a sensor in the CR system to intercept any quarantined message. These emails have passed through traditional antispam filters, including virus scanners, reverse DNS, and DNS blacklisting verification. Moreover, users have never had any previous conversation with the sender. Therefore, we can consider this dataset as pre-filtered from obvious legitimate and spam emails.

This set, sometimes referred to as a gray zone [6], stores emails of uncertain class. Email categories often found in this group include traditional spam and scam messages, automated notifications, newsletters, and commercial offers. Due to this variety, users need to manually check these messages from time to time, looking for any interesting or missing emails.

We also instrumented the CR system to collect additional information, such as opened emails by the users and whitelisted messages, providing insights into the users' ability to distinguish harmless from harmful messages. Finally, our sensor collected delivery status information, such as sent, bounced, and delivered, for each challenge email sent back by the CR system.

In our experiments, we relied on statistical email data collected from companies of different sizes over a six-month period from August 2011 to January 2012. During this period, around 11 million messages were delivered to the monitored mail servers (Table 1). 29.4% of them belonged to the class of gray messages. To protect the privacy of both the users and the companies involved in the study, the data we used in our experiments did not include the email bodies, and the headers were sanitized and analyzed in an aggregated form.

### 3.2 Email Clustering

The task of grouping emails into campaigns has been covered by several previous studies [15, 23, 16, 24, 21]. These studies have been successful in identifying email campaigns, but often rely on the content of the email body. Our dataset is limited to email headers, forcing us to use a different approach based only on email subjects. The main limitation of this technique is that the email subjects must be long enough to minimize the chances of matching different messages by coincidence.

The obvious solution for grouping similar subjects would be to apply text mining algorithms, but our input text is short, and preserving word order is important. Hence, we decided to use a simple approach based on "almost exact" text matching, extended to include subjects with variable parts. The latter could be a varying phrase in the subject, including random words, identifiers, or user names. We use word n-grams of decreasing length (between 70 and 8), with a sliding window that allows skipping over varying parts of the subjects. Our implementation is based on an existing n-grams extraction library (Ngram Statistics Package [4]), which we modified to fit our needs.