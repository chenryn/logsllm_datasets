split is based on the metric of information gain [10]
Δxf = i(τ ) − p(τ(cid:2))i(τ(cid:2)) − p(τr)i(τr),
(5)
where p(τ(cid:2)) = n(cid:2)/(n(cid:2) + nr) and p(τ(cid:2)) = nr/(n(cid:2) + nr). The
function i(τ ) is the Gini impurity measure
i(τ ) = 1 − p(y = +1|τ )
(6)
in which p(y = ±1|τ ) represent the ratio of positive and
negative samples in the node τ respectively.
2 − p(y = −1|τ )
2
,
Note that the tree based ranker also has the stability issue.
Therefore we divide all samples into B number of subsamples
and learn B decision trees from these subsamples, which
lead to the random forest algorithm [2]. After learning all
the trees, we can calculate the importance of each feature f
by accumulating the information gain related to that feature,
Δxf (τ, b) for all nodes τ in all B trees in the forest as
A. Regularization Based Ranker
IG(xf ) =
Δxf (τ, b) .
(7)
One common feature selection strategy is based on (cid:2)1-
regularized regression [7]. It generates a sparse solution with
respect to the regression coefﬁcients, and only features with
non-zero coefﬁcients are selected. Since in our context the out-
put y(t) is binary, we use the (cid:2)1-regularized logistic regression.
It formulates the conditional probability by
1
p(y(t) = ±1|x(t)) =
(3)
and minimizes the following penalized negative log-likelihood:
T(cid:2)
(cid:3)
1 + exp{−y(t)w(cid:2)x(t)}
(cid:4)−y(t)w(cid:2)x(t)
+ λ(cid:5)w(cid:5)1,
(cid:5)(cid:6)
t=1
1 + exp
min
w∈RN
(cid:7)N
i=1 |wi|
log
where (cid:5)w(cid:5)1 =
is the (cid:2)1-norm of regression
coefﬁcients w and λ > 0 is the regularization parameter. The
optimization problem (4) can be solved by a number of ways,
and we use the coordinated descent method [8].
(4)
One problem with (cid:2)1-regularized regression is that
the
solution can be unstable. That is, if we slightly change the
data, the selected features can be drastically different. In order
to address this issue, we randomly select a subset of input
samples and estimate w, and repeat this process many times.
We then summarize the results of all these independent runs,
and obtain the ﬁnal ranking of selected features based on the
frequency and rank they show up in each run. This strategy is
similar in spirit to the boosting algorithm [9].
B. Tree Based Ranker
The tree base ranker estimates the importance of input
features based on information theory, and thus gives us feature
importance in a different aspect from the regression based
feature selection.
It splits the data sets recursively to build a decision tree,
starting from the root node which contains data with all the
532532
B(cid:2)
b=1
(cid:2)
τ∈Tb
where Tb is the set of all nodes in tree b.
C. Nonlinear Ranker
The nonlinear ranker ranks features based on the RE-
LEAFF [3] feature selection method. This method can de-
tect the nonlinear relationships between features and quality
outputs locally. We ﬁrst normalize each series xf (t) in the
feature vector x(t) in equation 2 to have zero mean and unit
variance. The T samples of feature vector x(t), t = 1, . . . , T ,
are then divided into a positive set X + and a negative set X −
according to their corresponding outputs y(t). We include a
(cid:2) for those N
feature importance vector w = [w1, . . . , wN ]
features in vector xt, The RELEAFF feature selection is an
iterative method and requires one iteration for each of the T
samples of x(t). The weight vector w is initialized as all zeros
at the beginning. Given a sample x(t), we select k-nearest
neighbors from each X + and X − (totally 2k neighbors). If we
denote each element in X + and X − as x+
(cid:2)
+
(cid:2),N ]
(cid:2) respectively, where (cid:2) = 1,··· , k,
and x−
we update the importance by
−
(cid:2),1, . . . , x
+
(cid:2),1, . . . , x
−
(cid:2),N ]
(cid:2) = [x
(cid:2) = [x
+
+
(cid:2)=1
(cid:2)=1
(cid:2)=1
wf +
1
kN
1
kN
k(cid:2)
(cid:2),f| +
wf ←
(cid:2),f| − 1
|xf (t) − x
|xf (t) − x
wf − 1
kN
(cid:2),f|
|xf (t) − x
−
(if x(t) ∈ X +)
k(cid:2)
|xf (t) − x
(cid:2),f|
−
(if x(t) ∈ X −
)
(8)
for f = 1, . . . N. The above equation illustrates that
the
weight of any given feature will decrease if it differs from
that feature in nearby instances of the same class more than
nearby instances of the other class, and will increase in the
reverse case. After iterating through all the T samples, we
obtain the ﬁnal importance score for each feature.
kN
(cid:2)=1
⎧⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎩
k(cid:2)
k(cid:2)
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:14:32 UTC from IEEE Xplore.  Restrictions apply. 
V. RANKING SCORE FUSION
Note that our ﬁnal goal is to identify the most important
time series that affects the system quality. It can be achieved
by combining the results of feature rankers described in the
previous section. Such a combination covers two aspects of
ranking scores. We not only aggregate the feature importance
scores for each sensor, but also combine the score ranking
outputs from different rankers. In addition, since the feature
ranking scores from different rankers are in different ranges,
they need to be normalized before the fusion process.
denoted as ‘Aggregate’ in the ﬁgure, aggregates the feature
importance score from each sensor, whereas the second step
combines the aggregated scores across all the rankers. As a
result, we obtain the ﬁnal ranking of sensors according to their
fused importance score.
(a) Regularization based
Feature
1
2
3
4
5
PinBin0::21
ARp1::21
PinBin2::1
PinBin0::1
ARp1::1
Score
0.4479
0.2375
0.9253e-1
0.7997e-1
0.6899e-1
Feature
skew::1
(b) Tree based
Score
0.4869
0.2510e-1
0.1474e-1
0.1026e-1
0.9396e-2
PinBin0::21
ARp1::49
ARp1::1
qt05::48
(c) Nonlinear
Feature
PinBin0::21
PinBin2::21
PinBin0::1
PinBin2::1
ARp1::1
Score
0.9661
0.9502
0.9466
0.9444
0.7259
A. Ranking Scores Normalization
As introduced in section IV,
the three feature rankers
calculate the importance scores of all features from different
perspectives. Therefore, prior to fusing these scores along
different rankers, we have to normalize the ranking scores to
ensure that they are in the same range, e.g., between 0 and
1. In our method, we normalize the feature score by using a
sigmoid function. Let I be the importance score of a certain
ranker, then its normalized score (cid:12)I is calculated by
(cid:12)
I =
1
1 + exp(−a(I − c))
(9)
where the parameter a and c are determined from the distribu-
tion of ranking score for each ranker. Figure 6 shows a sigmoid
Fig. 6. The shape of a sigmoid function
function, in which the x-axis is the original score I and the
y-axis is the normalized score (cid:12)
I.
We use different sigmoid functions for three rankers, each
of which is represented by speciﬁc parameters (a, c). The
values of these two parameters reﬂect the shape of sigmoid
function, in which a is related to the position of normalization
and c relates to the slope of the curve in Figure 6. We determine
their values based on a calibration process. That is, we generate
several synthetic datasets with known ground truth, and then
set (a, c) values for each ranker so that their original ranking
scores can map to our expected values.
B. Ranking Score Fusion
After normalizing the ranking scores, we combine all the
feature ranking scores to locate important sensors related to
quality change. Figure 7 presents the ranking score fusion
process. It contains two main steps. The ﬁrst step, which is
533533
(a’) Regularization based
(b’) Tree based
Sensor
1
2
3
4
5
21
1
49
43
6
Score
0.7448
0.3009
0.3564e-2
0.2547e-5
0.1058e-5
Sensor
1
21
49
48
39
Score
0.5020
0.3903e-1
0.1891e-1
0.1381e-1
0.6204e-2
(c’) Nonlinear
Score
Sensor
2.7371
2.7081
0.1940
0.1723
0.1023
21
1
45
7
41
(d) Fused
Sensor
1
2
3
4
5
21
1
45
7
41
Score
3.5210
3.5109
0.1940
0.1723
0.1023
Fig. 7. Flow of ranking score fusion
(cid:12)
The ﬁrst step is straightforward. For a certain ranker, let
IFj (xi) and I(xi) be the normalized feature importance score
of feature x
and sensor importance score of time series xi
respectively. We calculate I(xi) by
Fj
i
m(cid:2)
(cid:12)
IFj (xi),
I(xi) =
j=0
(10)
where IF0 (xi) is the importance score of original time series
xi. Basically the combined score for each sensor is the
summation of scores from its features.
In the second step,
let Ireg(xi), Itree(xi) and Inon(xi)
respectively be the sensor importance score for the sensor xi of
the regularization based ranker, tree based ranker and nonlinear
ranker. Let Ifused(xi) denote the overall (fused) importance
score for the sensor xi. We calculate Ifused by
Ifused(xi) = wrIreg(xi) + wtItree(xi) + wnInon(xi),
(11)
where wr, wt and wn are the weights associated with each
ranker. We use a separate validation data to determine the
weights. We build a classiﬁer based on the top features
discovered by each ranker, and use it to evaluate the validation
data. The value of w∗ is the accuracy of validation for each
ranker. In our experiments the support vector machine (SVM)
[11] is used as the classiﬁer for validation.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:14:32 UTC from IEEE Xplore.  Restrictions apply. 
VI. EXPERIMENTAL RESULTS
In this section, we perform extensive experiments on both
synthetic time series and datasets from a real system to
demonstrate the effectiveness of proposed framework.
A. Synthetic Dataset
The reason of using synthetic data is that we can know
the ground truth and then fully evaluate our method. In the
experiment we generate 400 datasets to test our algorithm
from various perspectives. Each dataset contains 50 time series
and each time series has 1000 samples. While those datasets
are generated randomly under different settings, they belong
to one of the following categories in terms of the underlying
mechanism that generates time series.
•
•
•
•
Synthetic AR time series generated by
x(t) = a1x(t − 1) + a2x(t − 2) + a3x(t − 3),
where the coefﬁcients a1, a2 and a3 are generated
based on uniform random variables and selected so
that x(t) follows stable AR model.
Time series with ﬁxed frequency distributions
{ai sin(2πfit) + bi cos(2πfit)},
K(cid:2)
x(t) =
i=1
where coefﬁcients ai, bi and frequencies fi are ran-
domly generated based on uniformed random vari-