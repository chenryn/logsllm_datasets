loads/stores from two threads racing against each other, but
relies on a FLUSH + RELOAD [81] covert channel to observe
the loaded value of Y. The synchronization through the lock
variable ensures the desired (problematic) proximity and or-
dering of the memory operations.
As before, in our experiments, we observed two different
hits in the reload buffer for the loaded value of Y, one for
the stale (transient) value and one for the new (architectural)
value. For every double hit in the reload buffer, we also mea-
sured an increase of MACHINE_CLEARS.MEMORY_ORDERING.
We also ran experiments without the load of X. Even though
memory ordering violations are no longer possible since each
processor executes a single memory operation and any order
is permitted, we still observed MO machine clears. The reason
is that Intel CPUs seem to resort to a simple but conservative
approach to memory ordering violation detection, where the
CPU initiates a MO machine clear when a snoop request from
1456    30th USENIX Security Symposium
USENIX Association
another processor matches the source of any load operation
in the pipeline. We obtained the same results with the two
threads running across physical or logical (hyperthreaded)
cores. Similarly, the results are unchanged if the matching
store and load are performed on different addresses—the only
requirement we observed is that the memory operations need
to refer to the same cache line. Overall, our results conﬁrm
the presence of a transient execution window and the ability
of a thread to trigger a transient execution path in another
thread by simply dirtying a cache line used in a ready-to-
commit load. Exploitation-wise, abusing this type of MC is
non-trivial due to the strict synchronization requirements and
the difﬁculty of controlling pending stale data.
8 Memory Disambiguation Machine Clear
As suggested by the MACHINE_CLEARS.DISAMBIGUATION
counter description, memory disambiguation (MD) mis-
predictions are handled via machine clears. Our experi-
ments conﬁrmed this behavior by observing matching in-
creases of MACHINE_CLEARS.COUNT. Moreover, we observed
no changes in microcode assist counters, suggesting mispre-
dictions are resolved entirely in hardware. In case of a mispre-
diction, a stale value is passed to subsequent loads, a primitive
that was previously used to leak secret information with Spec-
tre Variant 4 or Speculative Store Bypass (SSB) [55, 82].
Different from the other machine clears, MD machine
clears trigger only on address aliasing mispredictions, when
the CPU wrongly predicts a load does not alias a preceding
store instruction and can be hoisted. Similar to branch pre-
diction, generating a MD-based transient execution window
requires mistraining the underlying predictor. The latter has
complex, undocumented behavior which has been partially
reverse engineered [18]. For space constraints, we discuss our
full reverse engineering strategy in Appendix A. Our results
show that executing the same load 64 + 15 times with non-
aliasing stores is sufﬁcient to ensure the next prediction to
be “no-alias” (and thus the next load to be hoisted). Upon
reaching the hoisting prediction, one can perform the load
with an aliasing store to trigger the transient path exposed to
the incorrect, stale value.
Finally, we experimentally veriﬁed that 4k aliasing [50]
does not cause any machine clear but only incurs a further
time penalty in case of wrong aliasing predictions. More
details on 4k aliasing results can be found in Appendix A.
9 Other Types of Machine Clear
AVX vmaskmov. The AVX vmaskmov instructions perform
conditional packed load and store operations depending on a
bitmask. For example, a vmaskmovpd load may read 4 packed
doubles from memory depending on a 4-bit mask: each double
will be read only if the corresponding mask bit is set, the
others will be assigned the value 0.
According to the Intel Optimization Reference Man-
ual [36], the instruction does not generate an exception in
face of invalid addresses, provided they are masked out. How-
ever, our experiments conﬁrm that it does incur a machine
clear (and a microcode assist) when accessing an invalid ad-
dress (e.g., with the present bit set to 0) with a loading mask
set to zero (i.e., no bytes should be loaded) to check whether
the bytes in the invalid address have the corresponding mask
bits set or not. We speculate the special handling is needed
because the permission check is very complex, especially in
the absence of memory alignment requirements.
In
our experiments, vmaskmov
instructions with
all-zero masks and invalid addresses
the
OTHER_ASSIST.ANY and MACHINE_CLEARS.COUNT counters,
conﬁrming that the instruction triggers a machine clear.
However, the resulting transient execution window seems
short-lived or absent, as we were unable to observe cache or
other microarchitectural side effects of the execution.
increment
Exceptions. The MACHINE_CLEARS.PAGE_FAULT counter,
present on older microarchitectures, conﬁrms page faults are
another cause of machine clears. Indeed, we veriﬁed each in-
struction incurring a page fault or any other exception such as
“Division by zero” increments the MACHINE_CLEARS.COUNT
counter. We also veriﬁed exceptions do not trigger microcode
assists and software interrupts (traps) do not trigger machine
clears. Indeed, the Intel documentation [37] speciﬁes that
instructions following a trap may be fetched but not specu-
latively executed. Transient execution windows originating
from exceptions—and page faults in particular—have been
extensively used in prior work, with a faulty load instruction
also used as the trigger to leak information [7, 47, 63, 75].
Hardware interrupts. Although hardware interrupts are
an undocumented cause of machine clears, our experiments
with APIC timer interrupts showed they do increment the
MACHINE_CLEARS.COUNT counter. While this conﬁrms hard-
ware interrupts are another root cause of transient execution,
the asynchronous nature of these events yields a less than
ideal vector for transient execution attacks. Nonetheless, hard-
ware interrupts play an important role in other classes of
microarchitectural attacks [73].
Microcode assists. Microcode assists require a pipeline
ﬂush to insert the required µOps in the frontend and represent
a subclass of machine clears (and thus a root cause of transient
execution) for cases where a fast path in hardware is not avail-
able. In this paper, we detailed the behavior of ﬂoating-point
and vmaskmov assists. Prior work has discussed different sit-
uations requiring microcode assists, such as those related to
page table entry Access/Dirty bits, typically in the context of
assisted loads used as the trigger to leak information [8,63,75].
AVX-to-SSE transitions [36] represent another microcode as-
sist which based on our experiments we could not observe
on modern Intel CPUs. Remaining known microcode assists
such as access control of memory pages belonging to SGX
USENIX Association
30th USENIX Security Symposium    1457
Figure 4: Top plot: transient window size vs. mechanism. Each bar reports the number of transient loads that complete and leave
a microarchitectural trace. Bottom plot: leakage rate vs. mechanism for a simple Spectre Bounds-Check-Bypass attack and a
1-bit FLUSH + RELOAD (F+R) cache covert channel. F+R is the leakage rate upper bound (covert channel loop only, no actual
transient window or attack).
secure enclaves and Precise Event Based Sampling (PEBS)
are not presented in this work since already studied [14] or
only related to privileged performance proﬁling respectively.
10 Transient Execution Capabilities
Transient execution attacks rely on crafting a transient win-
dow to issue instructions that are never retired. For this
purpose, state-of-the-art attacks traditionally rely on mech-
anisms based on root causes such as branch mispredictions
(BHT) [41, 43], faulty loads (Fault) [8, 47, 63, 75] or mem-
ory transaction aborts (TSX) [8, 47, 59, 63, 75]. However, the
different machine clears discussed in this paper provide an
attacker with the exact same capabilities.
To compare the capabilities of machine clear-based tran-
sient windows with those of more traditional mechanisms,
we implemented a framework able to run arbitrary attacker-
controlled code in a window generated by a mechanism of
choosing. We now evaluate our framework on recent proces-
sors (with all the microcode updates and mitigations enabled)
to compare the transient window size and leakage rate of the
different mechanisms.
10.1 Transient Window Size
The transient window size provides an indication of the
number of operations an attacker can issue on a transient
path before the results are squashed. Larger windows can,
in principle, host more complex attacks. Using a classic
FLUSH + RELOAD cache covert channel (F+R) as a reference,
we measure the window size by counting how many transient
loads can complete and hit entries in a designated F+R buffer.
Figure 4 (top) presents our results.
As shown in the ﬁgure, the window size varies greatly
across the different mechanisms. Broadly speaking, mecha-
nisms that have a higher detection cost such as XMC and MO
Machine Clear, yield larger window sizes. Not surprisingly,
branch mispredictions yield the largest window sizes, as we
can signiﬁcantly slow down the branch resolution process
(i.e., causing cache misses) and delay detection. FP, on the
other hand, yields the shortest windows, suggesting that de-
normal numbers are efﬁciently detected inside the FPU. Our
results also show that, while our framework was designed for
Intel processors, similar, if not better, results can usually be
obtained on AMD processors (where we use the same con-
servative training code for branch/memory prediction). This
shows that both CPU families share a similar implementation
in all cases except for MD, where the used mistraining pattern
is not valid for pre-Zen3 architectures.
10.2 Leakage Rate
To compare the leakage rates for the different transient exe-
cution mechanisms, we transiently read and repeatedly leak
data from a large memory region through a classic F+R cache
covert channel. We report the resulting leakage rates—as
the number of bits successfully leaked per second—across
different microarchitectures using a 1-bit covert channel to
highlight the time complexity of each mechanism. We con-
sider data to be successfully leaked after a single correct hit
in the reload buffer. In case of a miss for a particular value,
we restart the leak for the same value until we get a hit (or
until we get 100 misses in a row).
As shown in Figure 4 (bottom), different Intel and AMD
microarchitectures generally yield similar leakage rates with
some variations. For instance, FP MC offers better leakage
rates on Intel. This difference stems from the different perfor-
1458    30th USENIX Security Symposium
USENIX Association
020406080100120140160Number ofTransient LoadsCPUIntel Core i7-10700KIntel Xeon Silver 4214Intel Core i9-9900KIntel Core i7-7700KAMD Ryzen 5 5600XAMD Ryzen Threadripper2990WXAMD Ryzen 7 2700XF+RTSXBHTFAULTSMCXMCFPMDMOTransient Execution Management01234Leakage Rate[Mb/s]their security implications. We also present an end-to-end
FPVI exploit disclosing arbitrary memory in Firefox. Later,
we discuss mitigations.
11.1 Speculative Code Store Bypass (SCSB)
Our ﬁrst attack primitive, Speculative Code Store Bypass
(SCSB), allows an attacker to execute stale, controlled code in
a transient execution window originated by a SMC machine
clear. Since the primitive relies on SMC, its primary appli-
cability is on JIT (e.g., JavaScript) engines running attacker-
controlled code—although OS kernels and hypervisors stor-
ing code pages and allowing their execution without ﬁrst
issuing a serializing instruction are also potentially affected.
Figure 6: SCSB primitive example where the instruction
pointer is pointing at the bold code blocks. g code is freed
JIT’ed code (of some g function) under attacker’s control.
(1) Force engine to JIT and execute code of function f caus-
ing desynchronization of code and data views; (2) Execute
stale code and SMC MC; (3) After the SMC MC, code and
data view coherence is restored and the new code is executed.
As exempliﬁed in Figure 6, the operations of the primi-
tive can be broken down into three steps: (1) the JIT engine
compiles a function f, storing the generated code into a JIT
code cache region previously used by a (now-stale) version of
function g; (2) the JIT engine jumps to the newly generated
code for the function f, but due to the temporary desynchro-
nization between the code and data views of the CPU, this
causes transient execution of the stale code of g until the SMC
machine clear is processed; (3) after the pipeline ﬂush, the
code and data views are resynchronized and the CPU restarts
the execution of the correct code of f. For exploitation, the
attacker needs to (i) massage the JIT code cache allocator to
reuse a freed region with a target gadget g of choice; (ii) force
the JIT engine to generate and execute new (f ) code in such
a region, enabling transient, out-of-context execution of the
gadget and spilling secrets into the microarchitectural state.
Our primitive bears similarities with both transient and ar-
chitectural primitives used in prior attacks. On the transient
front, our primitive is conceptually similar to a Speculative-
Store-Bypass (SSB) primitive [55, 82], but can transiently
execute stale code rather than reading stale data. However,
interestingly, the underlying causes of the two primitives are
quite different (MD misprediction vs. SMC machine clear).
On the architectural front, our primitive mimics classic Use-
After-Free (UAF) exploitation on the JIT code cache, also
Figure 5: Leakage rate vs. mechanism with a 1-bit, 4-bit, or
8-bit FLUSH + RELOAD cache covert channel (Intel Core i9)
mance impact of the corresponding machine clears on Intel
vs. AMD microarchitectures.
As shown in Figure 5, the leakage rate varies instead greatly
across the different mechanisms and so does the optimal
covert channel bitwidth. Indeed, while existing attacks typi-
cally rely on 8-bit covert channels, our results suggest 1-bit or
4-bit channels can be much more efﬁcient depending on the
speciﬁc mechanism. Roughly speaking, optimal leakage rates
can be obtained by balancing the time complexity (and hence
bitwidth) of the covert channel with that of the mechanism.
For example, FP is a lightweight and reliable mechanism,
hence using a comparably fast and narrow 1-bit covert chan-
nel is beneﬁcial. In contrast, MD requires a time-consuming
predictor training phase between leak iterations and leaking
more bits per iteration with a 4-bit covert channel is more
efﬁcient. Interestingly, a classic 8-bit covert channel yields
consistently worse and comparable leakage rates across all
the mechanisms, since F+R dominates the execution time.
Our results show that only two mechanisms (TSX and FP)
are close to the maximum theoretical leakage rate of pure
F+R. Moreover, FP performs as efﬁciently as TSX, but, un-
like TSX, is available on both Intel and AMD, is always en-
abled, and can be used from managed code (e.g., JavaScript).
BHT, on the other hand, yield the worst leakage rates due to
the inefﬁcient training-based transient window. BHT leakage
rate can be improved if a tailored mistrain sequence is used
as in MD (Appendix A). Overall, our results show that ma-
chine clear-based windows achieve comparable and, in many
cases (e.g., FP), better leakage rates compared to traditional
mechanisms. Moreover, many machine clears eliminate the
need for mistraining, which, other than resulting in efﬁcient
leakage rates, can escape existing pattern-based mitigations
and disabled hardware extensions (e.g., Intel TSX).
11 Attack Primitives
Building on our reverse engineering results, and focusing on
the unexplored SMC and FP machine clears, we now present
two new transient execution attack primitives and analyze
USENIX Association
30th USENIX Security Symposium    1459
F+RTSXBHTFPSMCXMCMOMDFAULTTransient Execution Management01234Leakage Rate [Mb/s]F+R granularity [bit]1482
Chromium instruction
Listing
(chromium/src/v8/src/codegen/x64/cpu-x64.cc)
void CpuFeatures::FlushICache(void* start, size_t size) {
/* No need to flush the instruction
cache on Intel */ ...}
cache
ﬂush
3
Listing
(mozilla-unified/js/src/jit/FlushICache.h)
inline void FlushICache(void* code, size_t size,
instruction
Firefox
cache
ﬂush
Figure 7: Coding options suggested by the Intel Architectures
Software Developers Manuals to handle SMC and XMC ex-
ecution. Option 1 describes the exact steps required by our
Speculative Code Store Bypass attack primitive, potentially
resulting in exploitable gadgets.
known as Return-After-Free (RAF) in the hackers commu-
nity [19, 25]. An example is CVE-2018-0946, where a use-
after-free vulnerability can be exploited to force the Chakra
JS engine to erroneously execute freed (attacker-controlled)
JIT code, resulting in arbitrary code execution after massaging
the right gadget into the JIT code cache [24].
Indeed, at a high level, SCSB yields a transient use-after-
free primitive on a JIT code cache, with exploitation prop-
erties similar to its architectural counterpart. However, there
are some differences due to the transient nature of SCSB.
First, we need to ﬁnd an out-of-context gadget to transiently
leak data rather than architecturally execute arbitrary code.
In JavaScript engines, similar gadgets have already been ex-
ploited by ret2spec [48], escalating out-of-context transient